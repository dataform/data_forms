PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
J	Kim, MJ; Min, SH; Han, I				Kim, Myoung-Jong; Min, Sung-Hwan; Han, Ingoo			An evolutionary approach to the combination of multiple classifiers to predict a stock price index	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						genetic algorithms; machine-learning-driven classifier; human-driven classifier	UNCONSTRAINED HANDWRITTEN NUMERALS; RECOGNITION	Multiple classifier combination is a technique that combines the decisions of different classifiers. Combination can reduce the variance of estimation errors and improve the overall classification accuracy. However, direct application of combination schemes developed for pattern recognition to solving business problems has some limitations, because business problems cannot be explained completely by the results provided by machine-learning-driven classifiers alone owing to their intrinsic complexity. To solve such problems, this paper proposes an approach that is capable of incorporating the subjective problem-solving knowledge of humans into the results of quantitative models. Genetic algorithms (GAs) are used to combine classifiers stemming from machine learning, experts, and users. We use our GA-based method to predict the Korea stock price index (KOSPI). (C) 2005 Elsevier Ltd. All rights reserved.	Hallym Univ, Dept Business Adm, Chuncheon Gangwon Do 200702, South Korea; Kookin Bank, Seoul 150886, South Korea; Korea Adv Inst Sci & Technol, Grad Sch Management, Seoul 130012, South Korea	Min, SH (reprint author), Hallym Univ, Dept Business Adm, 39 Hallymdaehak Gil, Chuncheon Gangwon Do 200702, South Korea.	shmin@hallym.ac.kr	Han, Ingoo/C-2031-2011				BENEDIKTSSON JA, 1997, IEEE T NEURAL NETWOR, V8, P540; BLATTBERG RC, 1990, MANAGE SCI, V36, P887, DOI 10.1287/mnsc.36.8.887; BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560; CHO SB, 1995, IEEE T NEURAL NETWOR, V6, P497; Dasarathy B. V., 1994, DECISION FUSION; DUBOIS D, 1983, FUZZY SET SYST, V10, P15, DOI 10.1016/S0165-0114(83)80099-2; Franke J, 1992, P 11 INT C PATT REC, P611; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; HOLLAND JH, 1975, ADAPTATION NATURAL A; HU YH, 1977, IEEE T BIOMEDICAL EN, V44, P981; Huang Y.S., 1994, P 4 IWFHR, P235; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; Kim E, 2003, DECIS SUPPORT SYST, V34, P167, DOI 10.1016/S0167-9236(02)00079-9; Klein L., 1999, SENSOR DATA FUSION C; LeHegaratMascle S, 1997, IEEE T GEOSCI REMOTE, V35, P1018, DOI 10.1109/36.602544; Radova V, 1997, INT CONF ACOUST SPEE, P1135, DOI 10.1109/ICASSP.1997.596142; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; Tumer K., 1996, PATTERN RECOGN, V29, P341, DOI DOI 10.1016/0031-3203(95)00085-2; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yamaoka F, 1994, P 4 IWFHR, P255	21	30	32	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2006	31	2					241	247		10.1016/j.eswa.2005.09.020		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	044AT	WOS:000237645100004	
J	Polat, K; Sahan, S; Gunes, S				Polat, Kemal; Sahan, Seral; Guenes, Salih			A new method to medical diagnosis: Artificial immune recognition system (AIRS) with fuzzy weighted pre-processing and application to ECG arrhythmia	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						ECG arrhythmia; artificial immune system; AIRS; fuzzy weighted pre-processing		Changes in the normal rhythm of a human heart may result in different cardiac arrhythmias, which may be immediately fatal or cause irreparable damage to the heart sustained over long periods of time. The ability to automatically identify arrhythmias from ECG recordings is important for clinical diagnosis and treatment. Artificial immune systems (AISs) is a new but effective branch of artificial intelligence. Among the systems proposed in this field so far, artificial immune recognition system (AIRS), which was proposed by A. Watkins, has showed an effective and intriguing performance on the problems it was applied. Previously, AIRS was applied a range of problems including machine-learning benchmark problems and medical classification problems like breast cancer, diabets, liver disorders classification problems. The conducted medical classification task was performed for ECG arrhythmia data taken from UCI repository of machine-learning. Firsly, ECG dataset is normalized in the range of [0,1] and is weighted with fuzzy weighted pre-processing. Then, weighted input values obtained from fuzzy weighted pre-processing is classified by using AIRS classifier system. In this study, fuzzy weighted pre-processing, which can be improved by ours, is a new method and firstly, it is applied to ECG dataset. Classifier system consists of three stages: 50-50% of traing-test dataset, 70-30% of traing-test dataset and 80-20% of traing-test dataset, subsequently, the obtained classification accuries: 78.79, 75.00 and 80.77%. (C) 2005 Elsevier Ltd. All rights reserved.	Selcuk Univ, Engn Architecture Fac, Dept Elect & Elect Engn, TR-42075 Konya, Turkey	Polat, K (reprint author), Selcuk Univ, Engn Architecture Fac, Dept Elect & Elect Engn, TR-42075 Konya, Turkey.	kpolat@selcuk.edu.tr; seral@selcuk.edu.tr; sgunes@selcuk.edu.tr					Abbas A. K., 2003, CELLULAR MOL IMMUNOL; Bortolan G, 2002, ARTIF INTELL MED, V24, P109, DOI 10.1016/S0933-3657(01)00096-3; De Castro L.N., 2002, ARTIFICIAL IMMUNE SY; de la Calleja J, 2004, MON NOT R ASTRON SOC, V349, P87, DOI 10.1111/j.1365-2966.2004.07442.x; DELEN D, IN PRESS ARTIFICIAL; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Goodman DE, 2003, IEEE IJCNN, P1678; MICHIE D, 1991, COMPUT J, V34, P559, DOI 10.1093/comjnl/34.6.559; PAZZANI M, 1992, MACH LEARN, V9, P57, DOI 10.1007/BF00993254; PERELSON AS, 1979, J THEOR BIOL, V81, P645, DOI 10.1016/0022-5193(79)90275-3; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Sahan S, 2004, LECT NOTES COMPUT SC, V3280, P11; SOMAN T, 2005, P 4 INT C SYST SCI E; Watkins AB, 2001, THESIS MISSISSIPPI S; [Anonymous], 2005, UCI MACH LEARN REP	15	46	47	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2006	31	2					264	269		10.1016/j.eswa.2005.09.019		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	044AT	WOS:000237645100006	
J	Ben-David, A; Sterling, L				Ben-David, A; Sterling, L			Generating rules from examples of human multiattribute decision making should be simple	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						neural networks; classification and regression trees; nearest neighbor; exemplar-based learning; data mining; clustering; human multiattribute decision-making	INFORMATION; ALGORITHMS	How many prototypes or clusters are needed to predict real world human multiattribute subjective decision making? Although subjective decision making problems occur daily in our life, they have received relatively little attention in artificial intelligence, machine learning and data mining communities. We claim that for most problems, a simple set of rules derived by a nearest neighbor algorithm is the appropriate approach. A simple version of a nearest neighbor model is tested and compared with two other well-established classification methods: neural networks and classifications and regression trees (CART). The results of the experiments show that the simple nearest neighbor method provides very accurate predictions while using very few prototypes or clusters. Although not always the best in accuracy, the differences are sufficiently slight to not warrant greater complexity in deriving rules. Our research on the effectiveness of parsimonious rule sets suggests that decision trees with more than 7-10 branches are not needed for capturing most human multiattribute decision-making problems, and minimal time or memory resources should be used to generate decision making rules. (C) 2005 Elsevier Ltd. All rights reserved.	Holon Acad Inst Technol, Dept Technol Management, IL-58102 Holon, Israel; Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic, Australia	Ben-David, A (reprint author), Holon Acad Inst Technol, Dept Technol Management, 52 Golomb St,POB 305, IL-58102 Holon, Israel.	hol_abendav@bezeqint.net					Ben-David A., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00314.x; BENDAVID A, 1995, MACH LEARN, V19, P29, DOI 10.1023/A:1022655006810; Breiman L., 1998, CLASSIFICATION REGRE; Cao-Van K, 2002, LECT NOTES COMPUT SC, V2561, P291; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; GANZACH Y, 1993, ORGAN BEHAV HUM DEC, V56, P422, DOI 10.1006/obhd.1993.1062; HOLTE RC, 1993, MACH LEARN, V11, P65; KOTSIANTIS SB, 2004, P SETN 2004 BERL, P220; KRAMER S, 2000, FUNDAMENTA INFORM, V34, P1; LARICHEV OI, 1986, NEW DIRECTIONS RES D, P303; LAST M, 2004, IEEE T KNOWLEDGE DAT, V16; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; MAKINO K, 1999, FUNDAMENTA INFORMATI, V47, P1; McCullagh P., 1983, GEN LINEAR MODELS; MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037//0033-295X.101.2.343; Minsky M, 1969, PERCEPTRONS; Mitchell T, 1997, MACHINE LEARNING; Pao Y., 1989, ADAPTIVE PATTERN REC; Potharst R., 2000, Intelligent Data Analysis, V4; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Simon H., 1978, HDB LEARNING COGNITI, V5, P271; TVERSKY A, 1969, PSYCHOL REV, V76, P31, DOI 10.1037/h0026750; WARY J, 1995, NEURAL NETWORKS, V8, P31; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Witten I. H., 2000, DATA MINING	26	6	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	AUG	2006	31	2					390	396		10.1016/j.eswa.2005.09.066		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	044AT	WOS:000237645100020	
J	Weng, JY; Hwang, WS				Weng, Juyang; Hwang, Wey-Shiuan			From neural networks to the brain: Autonomous mental development	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE			English	Article							INTELLIGENCE; RECOGNITION; NAVIGATION; MODELS	Artificial neural networks can model cortical local learning and signal processing, but they are not the brain, neither are many special purpose systems to which they contribute. Autonomous mental development models all or part of the brain (or the central nervous system) and how it develops and learns autonomously from infancy to adulthood. Like neural network research, suc modeling aims to be biologically plausible. This paper discusses why autonomous development is necessary according to a concept called task muddiness. Then it introduces recent results for a series of research issues, including the new paradigm for autonomous development, mental architectures, developmental algorithm, a refined classification of types of machine learning, spatial complexity and time complexity. Finally, the paper presents some experimental results for applications, including: vision-guided navigation,object finding, object-based attention (eye-pan), and attention-guided pre-reaching, four tasks that infants learn to perform early but very perceptually challenging for robots.	Michigan State Univ, E Lansing, MI 48824 USA	Weng, JY (reprint author), Michigan State Univ, E Lansing, MI 48824 USA.						Almassy N, 1998, CEREB CORTEX, V8, P346, DOI 10.1093/cercor/8.4.346; Anderson J. R., 1993, RULES MIND; Arkin R. C., 1998, BEHAV BASED ROBOTICS; BICHSEL M, 1991, STRATEGIES ROBUST OB; BIRNBAUM L, 1993, P 4 INT C COMP VIS, P49; BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M; BROOKS WP, 1986, LETT APPL MICROBIOL, V2, P1, DOI 10.1111/j.1472-765X.1986.tb01502.x; Cheng XG, 2000, OSTEOPOROSIS INT, V11, P6; Cole M, 1996, DEV CHILDREN; COX DR, 1981, SCAND J STAT, V8, P93; DRESCHER G, 1991, MADE MINDS; Fahlman S. E., 1990, CMUCS90100 SCH COMP; Flavell J. H., 1993, COGNITIVE DEV; Gardner H, 1993, MULTIPLE INTELLIGENC; GROSSBERG S, 1976, BIOL CYBERN, V23, P121, DOI 10.1007/BF00344744; Han J. D., 2002, Proceedings 2nd International Conference on Development and Learning. ICDL 2002, DOI 10.1109/DEVLRN.2002.1011800; Huang X., 2002, P 2 INT WORKSH EP RO, P47; HUANG X, 2004, P 2004 INT JOINT C N; Hwang WS, 2000, IEEE T PATTERN ANAL, V22, P1277, DOI 10.1109/34.888712; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Koenig S, 1996, IEEE INT CONF ROBOT, P2301; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Laird J. E., 1991, Robotics and Autonomous Systems, V8, DOI 10.1016/0921-8890(91)90017-F; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; Martinetz T. M., 1991, ARTIFICIAL NEURAL NE, V1, P397; Miikkulainen R., 1990, Connection Science, V2; PUTEMAN ML, 1994, MARKOV DECISION PROC; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SURTON RS, 1998, REINFORCEMENT LEARNI; Thrun S., 1996, EXPLANATION BASED NE; Touretzky DS, 1997, ADAPT BEHAV, V5, P219, DOI 10.1177/105971239700500302; TURING A, 1936, P LOND MATH SOC, V2, P42; TURK M, 1991, J COGNITIVE SCI, V3, P1; Verschure PFMJ, 1995, ROBOT AUTON SYST, V16, P247, DOI 10.1016/0921-8890(95)00050-X; WALLACE I, 1987, PRODUCTION SYSTEM MO, P359; Wang X., 1995, NATURE, V378, P13; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Weng J., 2004, INT J HUM ROBOT, V1, P199, DOI 10.1142/S0219843604000149; WENG J, 2000, P 1 IEEE C HUM ROB C; Weng J., 2002, AI MAG, V23, P95; WENG J, 1998, VISUAL COMMUNICATION, P431; WENG J, 2007, IN PRESS CONNECTION; Weng J., 2004, P 3 INT C DEV LEARN; Weng J, 1997, INT J COMPUT VISION, V25, P109, DOI 10.1023/A:1007967800668; WENG J, 2002, INT J DOC ANAL RECOG, V5, P118; WENG J, 2005, P 2005 AAAI SPRING S; WENG J, 2002, P 2 INT C DEV LEARN, P131; Weng JY, 1998, NEURAL NETWORKS, V11, P1511, DOI 10.1016/S0893-6080(98)00079-3; Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599; WENG WS, 1999, P 2 INT C HUM ROB TO, P57; ZHANG Y, 2002, P IEEE 2 INT C DEV L, P53	52	15	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1556-603X		IEEE COMPUT INTELL M	IEEE Comput. Intell. Mag.	AUG	2006	1	3					15	31				17	Computer Science, Artificial Intelligence	Computer Science	169UC	WOS:000246616300003	
J	Ling, CX; Sheng, VS; Yang, Q				Ling, CX; Sheng, VS; Yang, Q			Test strategies for cost-sensitive decision trees	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						induction; concept learning; mining methods and algorithms; classification	KNOWLEDGE	In medical diagnosis, doctors must often determine what medical tests ( e. g., X-ray and blood tests) should be ordered for a patient to minimize the total cost of medical tests and misdiagnosis. In this paper, we design cost-sensitive machine learning algorithms to model this learning and diagnosis process. Medical tests are like attributes in machine learning whose values may be obtained at a cost ( attribute cost), and misdiagnoses are like misclassifications which may also incur a cost ( misclassification cost). We first propose a lazy decision tree learning algorithm that minimizes the sum of attribute costs and misclassification costs. Then, we design several novel "test strategies" that can request to obtain values of unknown attributes at a cost ( similar to doctors' ordering of medical tests at a cost) in order to minimize the total cost for test examples ( new patients). These test strategies correspond to different situations in real-world diagnoses. We empirically evaluate these test strategies, and show that they are effective and outperform previous methods. Our results can be readily applied to real-world diagnosis tasks. A case study on heart disease is given throughout the paper.	Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Ling, CX (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	cling@csd.uwo.ca; ssheng@csd.uwo.ca; qyang@cs.ust.hk	Sheng, Victor/A-3099-2009				Blake C.L., 1998, REPOSITORY MACHINE L; Chai X., 2004, P 4 IEEE INT C DAT M; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Elkan C., 2001, P 17 INT JOINT C ART, P973; FRIEDMAN J, 1996, P 13 NAT C ART INT A; GORRY G, 1968, COMPUTERS BIOMEDICAL; Ling C. X., 2004, P 21 INT C MACH LEAR; LIZOTTE D, 2003, P 19 C UNC ART INT A; MELVILLE P, 2004, P 4 INT C DAT MIN; MELVILLE P, 2004, P WORKSH UT BAS DAT; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SHENG VS, 2006, P 21 NAT C ART INT; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; TING KM, 1998, P 2 EUR S PRINC DAT, P23; TURNEY P, 2000, P WORKSH COST SENS L; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540; Zubek V., 2002, P 19 INT C MACH LEAR, P27; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	20	19	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	AUG	2006	18	8					1055	1067		10.1109/TKDE.2006.131		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	053HX	WOS:000238297300005	
J	Verbeek, J				Verbeek, J			Learning nonlinear image manifolds by global alignment of local linear models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature extraction or construction; machine learning; statistical image representation	DIMENSIONALITY REDUCTION; MAXIMUM-LIKELIHOOD; PRINCIPAL CURVES; MIXTURE-MODELS; EM ALGORITHM; RECOGNITION; EIGENMAPS; ANALYZERS; KERNEL	Appearance- based methods, based on statistical models of the pixel values in an image ( region) rather than geometrical object models, are increasingly popular in computer vision. In many applications, the number of degrees of freedom ( DOF) in the image generating process is much lower than the number of pixels in the image. If there is a smooth function that maps the DOF to the pixel values, then the images are confined to a low- dimensional manifold embedded in the image space. We propose a method based on probabilistic mixtures of factor analyzers to 1) model the density of images sampled from such manifolds and 2) recover global parameterizations of the manifold. A globally nonlinear probabilistic two- way mapping between coordinates on the manifold and images is obtained by combining several, locally valid, linear mappings. We propose a parameter estimation scheme that improves upon an existing scheme and experimentally compare the presented approach to self- organizing maps, generative topographic mapping, and mixtures of factor analyzers. In addition, we show that the approach also applies to finding mappings between different embeddings of the same manifold.	GRAVIR INRIA, F-38330 Montbonnot St Martin, France	Verbeek, J (reprint author), GRAVIR INRIA, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	verbeek@inrialpes.fr					Belkin M, 2002, ADV NEUR IN, V14, P585; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bengio Y, 2004, ADV NEUR IN, V16, P177; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Brand M., 2003, ADV NEURAL INFORMATI, V15, P961; Bregler C, 1995, ADV NEURAL INFORMATI, V7, P973; Carr JC, 1997, IEEE T MED IMAGING, V16, P96, DOI 10.1109/42.552059; Chang K, 2001, IEEE T PATTERN ANAL, V23, P22; Chretien S, 2000, IEEE T INFORM THEORY, V46, P1800, DOI 10.1109/18.857792; Costa JA, 2004, IEEE T SIGNAL PROCES, V52, P2210, DOI 10.1109/TSP.2004.831130; de Ridder D, 2003, P BRIT MACH VIS C, P319; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; FODOR IK, 2002, UCRLID148494 LAWR LI; Ghahramani Z., 1996, CRGTR961 U TOR; Ghahramani Z, 2000, ADV NEUR IN, V12, P449; Ghahramani Z., 1994, ADV NEURAL INFORMATI, V6, P120; Ham J., 2005, P ANN C UNC ART INT, V10, P120; HAM JH, 2003, P WORKSH CONT LAB UN; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; He XF, 2004, ADV NEUR IN, V16, P153; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; KAMBHATLA N, 1994, ADV NEURAL INFORMATI, V6, P152; KARGER H, 1977, COMMUN PUR APPL MATH, V3, P509; Kegl B., 2002, ADV NEURAL INFORM PR, V15, P681; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kohonen T., 1995, SELF ORG MAPS; Leonardis A, 2003, PATTERN RECOGN, V36, P1925, DOI 10.1016/S0031-3203(03)00055-4; Levina E., 2005, ADV NEURAL INFORM PR, V17, P777; Meng XL, 1997, J ROY STAT SOC B MET, V59, P511, DOI 10.1111/1467-9868.00082; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; OJA E, 1991, P INT C ART NEUR NET, P737; OLIVER JJ, 1996, P INT C MACH LEARN, V13, P364; Peter M, 2002, SEMIN REPROD MED, V20, P249, DOI 10.1055/s-2002-35389; RITTER H, 1993, ARTIFICIAL NEURAL NE, V3, P568; Roweis S, 2002, ADV NEUR IN, V14, P889; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul LK., 2003, J MACHINE LEARNING R, V4, P119; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Teh YW, 2003, ADV NEURAL INFORMATI, V15, P841; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VERBEEK J, 2004, THESIS U AMSTERDAM; VERBEEK JJ, 2002, P INT C ART NEUR NET, V12, P914; Verbeek JJ, 2004, ADV NEUR IN, V16, P297; Verbeek JJ, 2005, NEUROCOMPUTING, V63, P99, DOI 10.1016/j.neucom.2004.04.008; Webb A.R., 2002, STAT PATTERN RECOGNI; Weinberger KQ, 2004, PROC CVPR IEEE, P988; WIEGHARDT J, 2001, THESIS RUHR U BOCHUM	54	20	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1236	1250		10.1109/TPAMI.2006.166		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	051LK	WOS:000238162400006	
J	Zhao, HT; Yuen, PC; Kwok, JT				Zhao, Haitao; Yuen, Pong Chi; Kwok, James T.			A novel incremental principal component analysis and its application for face recognition	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						error analysis; face recognition; incremental principal component analysis (PCA); singular value decomposition (SVD)	MODELS	Principal component analysis (PCA) has been proven to be an efficient method in pattern recognition and image analysis. Recently, PCA has been extensively employed for face-recognition algorithms, such as eigenface and fisherface. The encouraging results have been reported and discussed in the literature. Many PCA-based face-recognition systems have also been developed in the last decade. However, existing PCA-based face-recognition systems are hard to scale up because of the computational cost and memory-requirement burden. To overcome this limitation, an incremental approach is usually adopted. Incremental PCA (IPCA) methods have been studied for many years in the machine-learning community. The major limitation of existing IPCA methods is that there is no guarantee on the approximation error. In view of this limitation, this paper proposes a new IPCA method based on the idea of a singular value decomposition (SVD) updating algorithm, namely an SVD updating-based IPCA (SVDU-IPCA) algorithm. In the proposed SVDU-IPCA algorithm, we have mathematically proved that the approximation error is bounded. A complexity analysis on the proposed method is also presented. Another characteristic of the proposed SVDU-IPCA algorithm is that it can be easily extended to a kernel version. The proposed method has been evaluated using available public databases, namely FERET, AR, and Yale B, and applied to existing face-recognition algorithms. Experimental results show that the difference of the average recognition accuracy between the proposed incremental method and the batch-mode method is less than 1%. This implies that the proposed SVDU-IPCA method gives a close approximation to the batch-mode PCA method.	Shanghai Jiao Tong Univ, Inst Aerosp Sci & Technol, Shanghai, Peoples R China; Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Zhao, HT (reprint author), Shanghai Jiao Tong Univ, Inst Aerosp Sci & Technol, Shanghai, Peoples R China.	shaoht@sjtu.edu.cn; pcyuen@comp.hkbu.edu.hk; jamesk@cs.ust.hk					ACHLIOPTAS D, 2002, ADV NEURAL INFORM PR, V14; Artac M., 2002, P 16 INT C PATT REC, V3, P781; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BRAND M, 2002, P EUR C COMP VIS COP, V2350, P707; BRUNS P, 1893, BEITR KLIN CHIR, V10, P1; BUNCH J, 1978, NUMER MATH, V32, P131; CHELLAPPA R, 1995, P IEEE, V83, P5; Daugman J, 1997, IEEE T PATTERN ANAL, V19, P675, DOI 10.1109/34.598225; Drineas P, 1999, PROCEEDINGS OF THE TENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P291; Frieze A., 1998, Proceedings 39th Annual Symposium on Foundations of Computer Science (Cat. No.98CB36280), DOI 10.1109/SFCS.1998.743487; Fukunaga K., 1990, INTRO STAT PATTERN R; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GOLUB GH, 2004, LECT MATRIX COMPUTAT; Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525; Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; KWOK JT, 2003, P ICANN IST TURK JUN, P270; Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371; Li YM, 2004, PATTERN RECOGN, V37, P1509, DOI 10.1016/j.patcog.2003.11.010; Martinez A.M., 1998, 24 CVC PURD U; OJA E, 1985, J MATH ANAL APPL, V106, P69, DOI 10.1016/0022-247X(85)90131-3; Parlett B., 1980, SYMMETRIC EIGENVALUE; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; ROSS D, 2004, P EUR C COMP VIS, P470; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Skocaj D., 2003, P 9 IEEE INT C COMP, V2, P1494; Smola A, 2000, P 17 INT C MACH LEAR, P911; TURK M, 1991, J COGNITIVE SCI, V3, P1; Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034; Yang M.H., 2002, P 5 IEEE INT C AUT F, P215, DOI 10.1109/AFGR.2002.4527207; Zha HY, 1999, SIAM J SCI COMPUT, V21, P782, DOI 10.1137/S1064827597329266	35	37	44	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2006	36	4					873	886		10.1109/TSMCB.2006.870645		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	068XN	WOS:000239408100012	
J	Huang, KZ; Yang, H; King, I; Lyu, MR				Huang, Kaizhu; Yang, Haiqin; King, Irwin; Lyu, Michael R.			Imbalanced learning with a biased minimax probability machine	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						fractional programming (FP); imbalanced learning; receiver operating characteristic (ROC) analysis; worst case accuracy	ART CLASSIFICATION TECHNIQUES; PERFORMANCE EVALUATION; ROC CURVE; ALGORITHMS; CLASSIFIERS; ACCURACY; IMAGES	Imbalanced learning is a challenged task in machine learning. In this context, the data associated with one class are far fewer than those associated with the other class. Traditional machine learning methods seeking classification accuracy over a full range of instances are not suitable to deal with this problem, since they tend to classify all the data into a majority class, usually the less important class. In this correspondence, the authors describe a new approach named the biased minimax probability machine (BMPM) to deal with the problem of imbalanced learning. This BMPM model is demonstrated to provide an elegant and systematic way for imbalanced learning. More specifically, by controlling the accuracy of the majority class under all possible choices of class-conditional densities with a given mean and covariance matrix, this model can quantitatively and systematically incorporate a bias for the minority class. By establishing an explicit connection between the classification accuracy and the bias, this approach distinguishes itself from the many current imbalanced-learning methods; these methods often impose a certain bias on the minority data by adapting intermediate factors via the trial-and-error procedure. The authors detail the theoretical foundation, prove its solvability, propose an efficient optimization algorithm, and perform a series of experiments to evaluate the novel model. The comparison with other competitive methods demonstrates the effectiveness of this new model.	Fujitsu Res & Dev Ctr Co Ltd, Informat Technol Lab, Beijing 10016, Peoples R China; Titanium Technol Ltd, Shenzhen 518020, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Sha Tin 100083, Hong Kong, Peoples R China	Huang, KZ (reprint author), Fujitsu Res & Dev Ctr Co Ltd, Informat Technol Lab, Beijing 10016, Peoples R China.	kzhuang@frdc.fujitsu.com; austin.yang@titanium-tech.com; king@cse.cuhk.edu.hk; lyu@cse.cuhk.edu.hk					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Allwein EL, 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Bertsekas DP, 1999, NONLINEAR PROGRAMMIN; Blake C. L., 1998, UCI REPOSITORY MACHI; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Cardie C., 1997, P 14 INT C MACH LEAR, P57; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586; FIRSCHEIN O, 1996, RADIUS IMAGE UNDERST; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Grzymala-Buuse JW, 2003, PATTERN RECOGN LETT, V24, P903, DOI 10.1016/S0167-8655(02)00202-7; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang HJ, 2002, IEEE T SYST MAN CY B, V32, P137, DOI 10.1109/3477.990870; HUANG K., 2004, P 21 INT C MACH LEAR, P401; HUANG K, 2004, P 2004 IEEE COMP SOC, V2, P558; Huang K., 2003, P INT JOINT C NEUR N, V1, P484; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; Huang KZ, 2003, LECT NOTES COMPUT SC, V2714, P115; Jaakola T. S., 1998, P ADV NEUR INF PROC, V11, P487; KOHAVI R, 1995, P 14 INT JOINT C ART, P338; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Lanckriet G. R. G., 2002, J MACHINE LEARNING R, V3, P555; Langley P., 1992, P 10 NAT C ART INT, P223; Lerner B, 2001, NEURAL COMPUT APPL, V10, P39, DOI 10.1007/s005210170016; Lin C, 1998, COMPUT VIS IMAGE UND, V72, P101, DOI 10.1006/cviu.1998.0724; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Liu WY, 1997, MACH VISION APPL, V9, P240; Maloof MA, 2003, MACH LEARN, V53, P157, DOI 10.1023/A:1025623527461; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; MCCLISH DK, 1989, MED DECIS MAKING, V9, P190, DOI 10.1177/0272989X8900900307; POPESCU I, 2001, TM62 INSEAD DEP MATH; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PROVOST F, 2000, P 17 NAT C AAAI WORK; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SCHAIBLE S, 1995, NONCONVEX OPTIMIZATI; Schmidt Peter, 1988, PREDICTING RECIDIVIS; SCHNAIBLE S, 1981, GEN CONCAVITY OPTIMI; Scholkopf B., 2002, LEARNING KERNELS; Swets J. A., 1982, EVALUATION DIAGNOSTI; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Vapnik V.N., 1999, NATURE STAT LEARNING; Viaene S, 2002, J RISK INSUR, V69, P373, DOI 10.1111/1539-6975.00023; Wang B., 2004, P IRIS MACH LEARN WO; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027	45	17	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2006	36	4					913	923		10.1109/TSMCB.2006.870610		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	068XN	WOS:000239408100015	
J	Mitsumori, T; Murata, M; Fukuda, Y; Doi, K; Doi, H				Mitsumori, Tomohiro; Murata, Masaki; Fukuda, Yasushi; Doi, Kouichi; Doi, Hirohumi			Extracting protein-protein interaction information from biomedical text with SVM	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						SVM; information extraction; protein interaction		Automated information extraction systems from biomedical text have been reported. Some systems are based on manually developed rules or pattern matching. Manually developed rules are specific for analysis, however, new rules must be developed for each new domain. Although the corpus must be developed by human effort, a machine-learning approach automatically learns the rules from the corpus. In this article, we present a system for automatically extracting protein-protein interaction information from biomedical text with support vector machines (SVMs). We describe the performance of our system and compare its ability to extract protein-protein interaction information with that of other systems.	Nara Inst Sci & Technol, Grad Sch Informat Sci, Ikoma 6300101, Japan; Natl Inst Informat & Commun Technol, Kyoto 6190289, Japan; Sony Kohara Res Ctr Inc, Tokyo 1410022, Japan	Mitsumori, T (reprint author), Nara Inst Sci & Technol, Grad Sch Informat Sci, Ikoma 6300101, Japan.	mitsumor@is.naist.jp					Bunescu R, 2005, ARTIF INTELL MED, V33, P139, DOI 10.1016/j.artmed.2004.07.016; Huang ML, 2004, BIOINFORMATICS, V20, P3604, DOI 10.1093/bioinformatics/bth451; Koike A, 2003, GENOME RES, V13, P1231, DOI 10.1101/gr.835903; OHTA T, 2002, P 10 INT C INT SYST; Ono T, 2001, BIOINFORMATICS, V17, P155, DOI 10.1093/bioinformatics/17.2.155; Temkin JM, 2003, BIOINFORMATICS, V19, P2046, DOI 10.1093/bioinformatics/btg279; Vapnik V. N, 1995, NATURE STAT LEARNING; Yakushiji A., 2005, P 11 ANN M ASS NAT L, P93	8	18	21	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	AUG	2006	E89D	8					2464	2466		10.1093/ietisy/e89-d.8.2464		3	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	071DL	WOS:000239578100020	
J	Inokuchi, R; Miyamoto, S				Inokuchi, Ryo; Miyamoto, Sadaaki			Kernel methods for clustering: Competitive learning and c-means	INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	2nd International Conference on Modeling Decisions for Artifical Intelligence	JUL, 2005	Tsukuba, JAPAN			competitive learning clustering; c-means; learning vector quantization; self-organizing map; kernel method; sequential algorithm		Recently kernel methods in support vector machines have widely been used in machine learning algorithms to obtain nonlinear models. Clustering is an unsupervised learning method which divides whole data set into subgroups, and popular clustering algorithms such as c-means are employing kernel methods. Other kernel-based clustering algorithms have been inspired from kernel c-means. However, the formulation of kernel c-means has a high computational complexity. This paper gives an alternative formulation of kernel-based clustering algorithms derived from competitive learning clustering. This new formulation obviously uses sequential updating or on-line learning to avoid high computational complexity. We apply kernel methods to related algorithms: learning vector quantization and self-organizing map. We moreover consider kernel methods for sequential c-means and its fuzzy version by the proposed formulation.	Univ Tsukuba, Doctoral Program Risk Engn, Tsukuba, Ibaraki 3058573, Japan; Univ Tsukuba, Dept Risk Engn, Tsukuba, Ibaraki 3058573, Japan	Inokuchi, R (reprint author), Univ Tsukuba, Doctoral Program Risk Engn, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.	inokuchi@soft.risk.tsukuba.ac.jp; miyamoto@risk.tsukuba.ac.jp					Bezdek J. C., 1981, PATTERN RECOGNITION; Duda R.O, 1973, PATTERN CLASSIFICATI; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; GRAEPEL T, 1998, P 5 GI WORKSH FUZZ N, P90; GRESHO A, 1992, VECTOR QUANTIZATION; Kohonen T., 1995, SELF ORG MAPS; Lesot MJ, 2003, LECT NOTES ARTIF INT, V2837, P265; Macqueen J. B., 1967, P 5 BERK S MATH STAT, P281; Miyamoto S., 1997, P 7 INT FUZZ SYST AS, V2, P86; Miyamoto S., 2003, J ADV COMPUTATIONAL, V7, P25; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Vapnik V. N, 1995, NATURE STAT LEARNING	14	0	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-4885		INT J UNCERTAIN FUZZ	Int. J. Uncertainty Fuzziness Knowl.-Based Syst.	AUG	2006	14	4					481	493		10.1142/S0218488506004138		13	Computer Science, Artificial Intelligence	Computer Science	075TY	WOS:000239909300007	
J	Madsen, ST; Widmer, G				Madsen, Soren Tjagvad; Widmer, Gerhard			Exploring pianist performance styles with evolutionary string matching	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						self organizing map; evolutionary algorithm; approximate string matching; expressive music performance	ALGORITHM; MUSIC	We propose novel machine learning methods for exploring the domain of music performance praxis. Based on simple measurements of timing and intensity in 12 recordings of a Schubert piano piece, short performance sequences are fed into a SOM algorithm in order to calculate 'performance archetypes'. The archetypes are labeled with letters and approximate string matching done by an evolutionary algorithm is applied to find similarities in the performances represented by these letters. We present a way of measuring each pianist's habit of playing similar phrases in similar ways and propose a ranking of the performers based on that. Finally, an experiment revealing common expression patterns is briefly described.	Austrian Res Inst Artificial Intelligence, A-1010 Vienna, Austria; Johannes Kepler Univ, Dept Computat Percept, A-4040 Linz, Austria	Madsen, ST (reprint author), Austrian Res Inst Artificial Intelligence, Freyung 6-6, A-1010 Vienna, Austria.	soren.madsen@ofai.at; gerhard.widmer@jku.at					de Mantaras RL, 2002, AI MAG, V23, P43; Deutsch Diana, 1999, PSYCHOL MUSIC, P473, DOI 10.1016/B978-012213564-4/50014-7; DIXON S, 2001, P INT COMP MUS C INT, P215; DIXON S, 2002, P ICMC ICMA, P361; Dixon S, 2001, J NEW MUSIC RES, V30, P39, DOI 10.1076/jnmr.30.1.39.7119; GABRIELSSON A., 1999, PSYCHOL MUSIC, P501, DOI 10.1016/B978-012213564-4/50015-9; GOEBL W, 2004, P 8 INT C MUS PERC C; Lango R, 2004, INT J ARTIF ORGANS, V27, P69; NevillManning CG, 1997, J ARTIF INTELL RES, V7, P67; REPP BH, 1992, J ACOUST SOC AM, V92, P2546, DOI 10.1121/1.404425; SAUNDERS C, 2004, P 15 EUR C MACH LEAR; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; WIDMER G, 2004, P 16 EUR C ART INT; Widmer G, 2003, ARTIF INTELL, V146, P129, DOI 10.1016/S0004-3702(03)00016-X; Widmer G, 2003, AI MAG, V24, P111; Zwicker E., 1999, PSYCHOACOUSTICS FACT	16	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	AUG	2006	15	4					495	513		10.1142/S0218213006002795		19	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	072AS	WOS:000239645600002	
J	Ramirez, R; Hazan, A				Ramirez, Rafael; Hazan, Amaury			A tool for generating and explaining expressive music performances of monophonic jazz melodies	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						machine learning; expressive performance		In this paper we present a machine learning approach to modeling the knowledge applied by a musician when performing a score in order to produce an expressive performance of a piece. We describe a tool for both generating and explaining expressive music performances of monophonic Jazz melodies. The tool consists of three components: (a) a melodic transcription component which extracts a set of acoustic features from monophonic recordings, (b) a machine learning component which induce both an expressive transformation model and a set of expressive performance rules from the extracted acoustic features, and (c) a melody synthesis component which generates expressive monophonic output (MIDI or audio) from inexpressive melody descriptions using the induced expressive transformation model. We compare several machine learning techniques we have explored for inducing the expressive transformation model.	Pompeu Fabra Univ, Mus Technol Grp, Barcelona 08003, Spain; Pompeu Fabra Univ, Mus Technol Grp, Barcelona 08003, Spain	Ramirez, R (reprint author), Pompeu Fabra Univ, Mus Technol Grp, Ocata 1, Barcelona 08003, Spain.	rafael@iua.upf.es; ahazan@iua.upf.es					BRESIN R, 2002, P 2001 INT C MUS C S; Canazza S., 1997, P 1997 INT COMP MUS, P113; COLMENAUER A, 1990, COMMUNICATIONS ACM, V33; Dannenberg RB, 1998, J NEW MUSIC RES, V27, P211, DOI 10.1080/09298219808570747; DEMANTARAS RL, 2002, AI MAG, P23; DOVEY MJ, 1995, EUR C MACH LEARN; FRIBERG A, 1998, J NEW MUSIC RES, V27, P217; Friberg A, 2000, J NEW MUSIC RES, V29, P199, DOI 10.1076/jnmr.29.3.199.3093; GABRIELSSON A, 1999, PSYCHOL MUSIC; GOMEZ E, 2002, THESIS UPF BARCELONA; GOMEZ E, 2003, P 114 AUD ENG SOC CO; GOMEZ E, 2003, STOCKH MUS AC C; IGARASHI S, 2002, P 2 INT C MUS ART IN; Johnson M. L., 1992, READINGS COMPUTER GE, P41; KLAPURI A, 1999, P IEEE INT C AC SPEE; LERDAHL F, 1993, OVERVIEW HIERARCHICA, P289; LERDAHL F, 1991, UNDERLYING MUSICAL S; MAHER RC, 1994, J ACOUST SOC AM, V95, P2254, DOI 10.1121/1.408685; MAKSE T, 1994, THESIS U LJUBLJANA; MCNAB RJ, 1996, SIGNAL PROCESSING ME, V9522; Mitchell T, 1997, MACHINE LEARNING; Morales EF, 1997, MACH LEARN, V26, P227, DOI 10.1023/A:1007373508948; NARMOUR E, 1990, ANAL COGNITION MELOD; Narmour E., 1990, ANAL COGNITION BASIC; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAMIREZ R, 2004, P 10 INT C KNOWL DIS; REPP BH, 1992, J ACOUSTICAL SOC AM, V104; SEASHORE CE, 1936, OBJECTIVE ANAL MUSIC; Srinivasan A., 2001, ALEPH MANUAL; TOBUDIC A, 2003, P INT C IND LOG PROG; TODD N, 1992, J ACOUSTICAL SOC AM, V91; VANBAELEN E, 1996, INT C IND LOG PROGR, P55; Widmer G, 2002, J NEW MUSIC RES, V31, P37, DOI 10.1076/jnmr.31.1.37.8103; WIDMER G, 2001, P 12 EUR C MACH LEAR; WIDMER G, 2002, P 5 INT C DISC SCI D; WITZEN IH, 1999, DATA MINING PRACTICA	36	4	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	AUG	2006	15	4					673	691		10.1142/S0218213006002862		19	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	072AS	WOS:000239645600009	
J	Urban, J				Urban, Josef			MPTP 0.2: Design, implementation, and initial experiments	JOURNAL OF AUTOMATED REASONING			English	Article; Proceedings Paper	20th Workshop on Empirically Successful Classical Automated Reasoning	JUL 22-26, 2005	Tallinn, ESTONIA			MPTP; Mizar; MML; ATP; MPA; re-proving; proof discovery	MIZAR; DEDUCTION; RETRIEVAL; PROVERS; LIBRARY; MML	This paper describes the second version of the Mizar Problems for Theorem Proving (MPTP) system and first experimental results obtained with it. The goal of the MPTP project is to make the large formal Mizar Mathematical Library (MML) available to current first-order automated theorem provers (ATPs) (and vice versa) and to boost the development of domain-based, knowledge-based, and generally AI-based ATP methods. This version of MPTP switches to a generic extended TPTP syntax that adds term-dependent sorts and abstract (Fraenkel) terms to the TPTP syntax. We describe these extensions and explain how they are transformed by MPTP to standard TPTP syntax using relativization of sorts and deanonymization of abstract terms. Full Mizar proofs are now exported and also encoded in the extended TPTP syntax, allowing a number of ATP experiments. This covers, for example, consistent handling of proof-local constants and proof-local lemmas and translating of a number of Mizar proof constructs into the TPTP formalism. The proofs using second-order Mizar schemes are now handled by the system, too, by remembering (and, if necessary, abstracting from the proof context) the first-order instances that were actually used. These features necessitated changes in Mizar, in the Mizar-to-TPTP exporter, and in the problem-creating tools. Mizar has been reimplemented to produce and use natively a detailed XML format, suitable for communication with other tools. The Mizar-to-TPTP exporter is now just a XSLT stylesheet translating the XML tree to the TPTP syntax. The problem creation and other MPTP processing tasks are now implemented in about 1,300 lines of Prolog. All these changes have made MPTP more generic, more complete, and more correct. The largest remaining issue is the handling of the Mizar arithmetical evaluations. We describe several initial ATP experiments, both on the easy and on the hard MML problems, sometimes assisted by machine learning. It is shown that on the nonarithmetical problems, countersatisfiability (completions) is no longer detected by the ATP systems, suggesting that the 'Mizar deconstruction' done by MPTP is in this case already complete. About every fifth nonarithmetical theorem is proved in a fully autonomous mode, in which the premises are selected by a machine-learning system trained on previous proofs. In 329 of these cases, the newly discovered proofs are shorter than the MML originals and therefore are likely to be used for MML refactoring. This situation suggests that even a simple inductive or deductive system trained on formal mathematics can be sometimes smarter than MML authors and usable for general discovery in mathematics.	Charles Univ Prague, Dept Theoret Comp Sci, Prague, Czech Republic	Urban, J (reprint author), Charles Univ Prague, Dept Theoret Comp Sci, Malostranske Nam 25, Prague, Czech Republic.	urban@kti.mff.cuni.cz					ASPERTI A, 2004, LECT NOTES COMPUTER, V3119; Avron A, 2004, LECT NOTES COMPUT SC, V3119, P32; Bancerek G, 2004, LECT NOTES COMPUT SC, V3119, P44; Bancerek G, 2003, LECT NOTES COMPUT SC, V2594, P119; BYLINSKI C, 1990, FORMALIZ MATH, V2; Carlson A., 1999, UIUCDCSR99210; DAHN I, 1998, FTP LNCS SELECTION, P137; Dahn I., 1997, INT WORKSH 1 ORD THE, P58; Ganzinger H, 2003, LECT NOTES ARTIF INT, V2741, P335; GOGUEN JA, 1992, THEOR COMPUT SCI, V105, P217, DOI 10.1016/0304-3975(92)90302-V; HAHNLE R, 1996, 1096 U KARLSR FAK IN; JASKOWSKI S, 1934, STUD LOG, V1; MATUSZEWSKI R, 2004, MKM WORKSH 30 YEARS; Naumowicz A, 2004, LECT NOTES COMPUT SC, V3119, P290; Nonnengart A., 2001, HDB AUTOMATED REASON, P335, DOI 10.1016/B978-044450813-3/50008-4; Pelletier FJ, 1999, HIST PHILOS LOGIC, V20, P1, DOI 10.1080/014453499298165; Riazanov A, 2002, AI COMMUN, V15, P91; RUDNICKI P, 1992, 1992 WORKSH TYP PROO, P311; Schulz S, 2002, AI COMMUN, V15, P111; Sutcliffe G, 1998, J AUTOM REASONING, V21, P177, DOI 10.1023/A:1005806324129; SUTCLIFFE G, 2001, P 2 INT WORKSH IMPL, P92; Rudnicki P, 1999, J AUTOM REASONING, V23, P197, DOI 10.1023/A:1006218513245; Urban J, 2006, LECT NOTES COMPUT SC, V3863, P346; Urban J, 2003, LECT NOTES COMPUT SC, V2594, P203; Urban J, 2006, INT J ARTIF INTELL T, V15, P109, DOI 10.1142/S0218213006002588; Urban J, 2004, J AUTOM REASONING, V33, P319, DOI 10.1007/s10817-004-6245-1; URBAN J, 2005, J APPL LOGIC, DOI DOI 10.1016/J.JAL.2005.10.004; Weidenbach C., 2001, HDB AUTOMATED REASON, P1965, DOI 10.1016/B978-044450813-3/50029-1; WIEDIJK F, 2000, CHECKER NOTES BASIC, P11; Wiedijk F, 2003, LECT NOTES COMPUT SC, V2594, P188	30	21	21	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0168-7433		J AUTOM REASONING	J. Autom. Reasoning	AUG	2006	37	1-2					21	43		10.1007/s10817-006-9032-3		23	Computer Science, Artificial Intelligence	Computer Science	127SW	WOS:000243607600003	
J	Mardin, CY; Peters, A; Horn, F; Junemann, AG; Lausen, B				Mardin, Christian Y.; Peters, Andrea; Horn, Folkert; Junemann, Anselm G.; Lausen, Berthold			Improving glaucoma diagnosis by the combination of perimetry and HRT measurements	JOURNAL OF GLAUCOMA			English	Article						HRT; glaucoma; perimetry; automated diagnosis	HEIDELBERG RETINA TOMOGRAPH; VISUAL-FIELD LOSS; OPTIC DISK; AUTOMATED PERIMETRY; EYES; CUP; DAMAGE; SIZE	Purpose: The aim of this study was to determine, whether the combination of morphologic data of the,optic nerve head and visual field (VF) data would improve diagnosis of glaucoma, on the basis of the measurements alone. Patients and Methods: Eighty-eight perimetric glaucomatous and 88 normal optic discs from the Erlangen Glaucoma Registry were matched for age. All normals and patients were examined in a standardized manner (Slitlamp biomicroscopy, gonioscopy, 24h-applanation tonometry, automated VF testing, 15-degree optic disc stereographs, and Heidelberg Retina Tomograph (HRT)-scanning of the optic disc). The HRT variables were calculated in 4 optic disc sectors. All variables were calculated with the software's standard reference plane. To gain the same allocation of sectors as provided by the HRT software, the VF responses were averaged within 4 sectors. Classification results of these VF responses were compared with the summarized results within 4 sectors. Six different combinations of morphologic and VF data were used to assess their suitability to diagnose the disease. HRT measurements, and the standard output of the Octopus (HRT/PERI1), HRT measurements and the summarized sectors and their standard deviations (HRT/PERI2), HRT measurements, standard output of the octopus and the summarized sectors and their standard deviations (HRT/PERII/PERI2), standard output of the Octopus (PERI1), summarized sectors of the Octopus and their standard deviations (PERI2) and HRT measurements. To assess the diagnostic value of the different data sets machine learning classifiers, stabilized linear discriminant analysis, classification trees, bagging, and double-bagging were applied. Results: Combination of morphologic and VF data improved the automated classification rules. The accuracy to diagnose glaucoma just by VF and HRT indices was maximized for double-bagging using both diagnostic tools. An estimated misclassification probability of less than 0.07 could be achieved for the primary open angle glaucoma patients combining HRT and VF sectors by double bagging. So highest sensitivity was 95% and specificity 91%, achieved by double-bagging and combination of HRT, PERI1, and PERI2. Conclusions: The combination of optic disc measurements and VF data could not only improve glaucoma diagnosis in future, but could also help to find an objective way to diagnose glaucomatous optic atrophy. The limitation of the topographic relationship between structure and function is the individual variability of the optic disc morphology and the subjective variability of VF testing.	Univ Erlangen Nurnberg, Dept Ophthalmol, D-91054 Erlangen, Germany; Univ Erlangen Nurnberg, Hosp Eye, D-91054 Erlangen, Germany; Univ Erlangen Nurnberg, Dept Med Informat Biometry & Epidemiol, D-91054 Erlangen, Germany	Mardin, CY (reprint author), Univ Erlangen Nurnberg, Dept Ophthalmol, Schwabachanlage 6, D-91054 Erlangen, Germany.	christian.mardin@augen.med.uni-erlangen.de	Lausen, Berthold/D-4063-2012				Anton A, 1998, AM J OPHTHALMOL, V125, P436, DOI 10.1016/S0002-9394(99)80183-4; BartzSchmidt KU, 1996, KLIN MONATSBL AUGENH, V209, P292, DOI 10.1055/s-2008-1035321; Boden C, 2002, ARCH OPHTHALMOL-CHIC, V120, P907; Bosworth CF, 1999, J GLAUCOMA, V8, P281; Breiman L, 2001, MACH LEARN, V45, P261, DOI 10.1023/A:1017934522171; BREIMAN L, 1996, OUT OF BAG ESTIMATIO; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Cullinane AB, 2002, BRIT J OPHTHALMOL, V86, P555, DOI 10.1136/bjo.86.5.555; Gordon MO, 2002, ARCH OPHTHALMOL-CHIC, V120, P714; Hothorn T, 2003, PATTERN RECOGN, V36, P1303, DOI 10.1016/S0031-3203(02)00169-3; Ihaka R, 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; JONAS JB, 1990, INVEST OPHTH VIS SCI, V31, P736; JONAS JB, 1988, INVEST OPHTH VIS SCI, V29, P1151; Jonas JB, 1997, AM J OPHTHALMOL, V124, P488; Lauter J, 1998, ANN STAT, V26, P1972; LAUTER S, 1992, STABILE MULTIVARIATE; Mardin CY, 2003, J GLAUCOMA, V12, P340, DOI 10.1097/00061198-200308000-00008; Mardin CY, 1998, GRAEF ARCH CLIN EXP, V236, P641, DOI 10.1007/s004170050135; Peters A, 2002, R NEWS, V2, P33; Weih LM, 2001, ARCH OPHTHALMOL-CHIC, V119, P875; Yamagishi N, 1997, AM J OPHTHALMOL, V123, P667	22	13	15	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	1057-0829		J GLAUCOMA	J. Glaucoma	AUG	2006	15	4					299	305		10.1097/01.ijg.0000212232.03664.ee		7	Ophthalmology	Ophthalmology	069YD	WOS:000239484500005	
J	Kang, JH; Ryu, KR; Kim, KH				Kang, Jaeho; Ryu, Kwang Ryel; Kim, Kap Hwan			Deriving stacking strategies for export containers with uncertain weight information	JOURNAL OF INTELLIGENT MANUFACTURING			English	Article						container terminal; container re-handling; strategy search; simulate annealing; machine learning	RULES; YARDS	In a container terminal, export containers are usually classified into one of a few weight groups and those belonging to the same group are stored together on a same stack. The reason for this stacking by weight groups is that it becomes easy to have heavier containers be loaded onto a ship before lighter ones, which is important for the balancing of the ship. However, since the weight information available at the time of container arrival is only an estimate, containers belonging to different weight groups are often stored together on a same stack. This becomes the cause of extra moves, or re-handlings, of containers at the time of loading to fetch out the heavier containers placed under the lighter ones. In this paper, we propose a method based on a simulated annealing search to derive a good stacking strategy for containers with uncertain weight information. Simulation experiments have shown that our strategies more effectively reduce the number of re-handlings than the traditional same-weight-group-stacking strategy. Also, additional experiments have shown that further improvement can be obtained if we increase the accuracy of the weight classification by applying machine learning.	Pusan Natl Univ, Dept Comp Engn, Pusan 609735, South Korea	Kang, JH (reprint author), Pusan Natl Univ, Dept Comp Engn, San 30,Jangjeon Dong, Pusan 609735, South Korea.	jhkang@pusan.ac.kr					Aarts E., 1989, SIMULATED ANNEALING; Aarts E.H.L., 1997, LOCAL SEARCH COMBINA, P91; Bjorklund P, 2005, COMPUT OPER RES, V32, P169, DOI 10.1016/S0305-0548(03)00210-7; Castilho B., 1993, TRANSPORTATION RES B, V27, P151; Frank E., 1998, P 15 INT C MACH LEAR, P144; FRIEDMAN N, 1997, MACH LEARN, V29, P103; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1997, TABU SEARCH; Glover JA, 1989, EDUC PSYCHOL REV, V1, P1, DOI 10.1007/BF01326547; Ho SY, 2004, IEEE T VLSI SYST, V12, P874, DOI 10.1109/tvlsi.2004.831464; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Kim KH, 1997, COMPUT IND ENG, V32, P701; Kim KH, 2000, EUR J OPER RES, V124, P89, DOI 10.1016/S0377-2217(99)00116-2; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Low C, 2005, COMPUT OPER RES, V32, P2013, DOI 10.1016/j.cor.2004.01.003; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Terzi E, 2004, J SYST SOFTWARE, V73, P467, DOI 10.1016/j.jss.2003.09.020; Triki E, 2005, EUR J OPER RES, V166, P77, DOI 10.1016/j.ejor.2004.03.035; Watanabe I.R., 1991, CONTAINER AGE    MAR, P36; Witten I. H., 2000, DATA MINING PRACTICA	20	18	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0956-5515		J INTELL MANUF	J. Intell. Manuf.	AUG	2006	17	4					399	410		10.1007/s10845-005-0013-x		12	Computer Science, Artificial Intelligence; Engineering, Manufacturing	Computer Science; Engineering	090FG	WOS:000240935400003	
J	Al-Omary, AY; Jamil, MS				Al-Omary, Alauddin Yousif; Jamil, Mohammad Shahid			A new approach of clustering based machine-learning algorithm	KNOWLEDGE-BASED SYSTEMS			English	Article						machine learning; clustering algorithm; unsupervised learning; evidential reasoning; incremental learning; multiple inheritance; overlapping concept		Machine-learning research is to study and apply the computer modeling of learning processes in their multiple manifestations, which facilitate the development of intelligent system. In this paper, we have introduced a clustering based machine-learning algorithm called clustering algorithm system (CAS). The CAS algorithm is tested to evaluate its performance and find fruitful results. We have been presented some heuristics to facilitate machine-learning authors to boost up their research works. The InfoBase of the Ministry of Civil Services is used to analyze the CAS algorithm. The CAS algorithm is compared with other machine-learning algorithms like UNIMEM, COBWEB, and CLASSIT, and was found to have some strong points over them. The proposed algorithm combined advantages of two different approaches to machine learning. The first approach is learning from Examples, CAS supports Single and Multiple Inheritance and Exceptions. CAS also avoids probability assumptions which are well understood in concept formation. The second approach is learning by Observation. CAS applies a set of operators that have proven to be effective in conceptual clustering. We have shown how CAS builds and searches through a clusters hierarchy to incorporate or characterize an object. (c) 2006 Published by Elsevier B.V.	Univ Bahrain, Coll Informat Technol, Dept Comp Engn, Isa Town, Bahrain; Qatar Univ, Dept Math & Comp, Fdn Program Unit, Doha, Qatar	Al-Omary, AY (reprint author), Univ Bahrain, Coll Informat Technol, Dept Comp Engn, Isa Town, Bahrain.	alomary@itc.uob.bh.qa; shahidjamil@yahoo.com					Anderberg M. R, 1973, CLUSTER ANAL APPL; ASELTINE JH, 1999, P AAAI 99 WORKSH MAC; Bay S.D., 1998, P INT C MACH LEARN; BISWAS G, 1991, P 8 INT WORKSH MACH, P591; Brachman R., 1985, AI MAG, V6, P80; Cheng J, 2000, J ARTIF INTELL RES, V13, P155; CIOS KJ, DATA MINING METHOD K; Everitt B. S, 1980, CLUSTER ANAL; Fahlman S., 1979, NETL SYSTEM REPRESEN; Faure D., 1999, P 11 EUR WORKSH KNOW, P329; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5; Gluck M.A., 1985, P 7 ANN C COGN SCI S, P283; HAIPENG G, 2003, THESIS KANSAS STATE; Hanson S. J., 1989, Machine Learning, V3, DOI 10.1007/BF00116838; IOANNIDIS YE, 1992, ACM T INFORM SYST, V10, P265; JAMIL MS, 2005, THESIS VKS U INDIA; KEOGH E, 1999, 7 INT WORKSH ART INT, P225; Lebowitz M., 1987, Machine Learning, V2, DOI 10.1007/BF00114264; LEBOWITZ M, 1987, MACHINE LEARNING ART, V2, P193; MICHALSKI RS, 1983, INT WORKSH MACH LEAR, P156; MICHALSKI RS, 1983, MACH LEARN, P316; Mitchell T, 1997, MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Russell S., 1995, ARTIFICIAL INTELLIGE; SHASTRI L, 1988, RES NOTES ARTIFICIAL; TAN AC, 2003, MACHINE LEARNING ITS; Thrun S.B., 1991, CSCMU91197	28	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	AUG	2006	19	4					248	258		10.1016/j.knosys.2005.10.011		11	Computer Science, Artificial Intelligence	Computer Science	071RX	WOS:000239620700004	
J	Stojmenovic, M				Stojmenovic, Milos			Real time machine learning based car detection in images with fast training	MACHINE VISION AND APPLICATIONS			English	Article							CASCADE	Our primary interest is to build fast and reliable object recognizers in images based on small training sets. This is important in cases where the training set needs to be built mostly manually, as in the case that we studied, the recognition of the Honda Accord 2004 from rear views. We describe a novel variant of the AdaBoost based learning algorithm, which builds a strong classifier by incremental addition of weak classifiers (WCs) that minimize the combined error of the already selected WCs. Each WC is trained only once, and examples do not change their weights. We describe a set of appropriate feature types for the considered recognition problem, including a redness measure and dominant edge orientations. The existing edge orientation bin division was improved by shifting so that all horizontal (vertical, respectively) edges belong to the same bin. We propose to pre-eliminate features whose best threshold value is near the trivial position at the minimum or maximum of all threshold values. This is a novel method that has reduced the training set WC quantity to less than 10% of its original number, greatly speeding up training time, and showing no negative impact on the quality of the final classifier. We also modified the AdaBoost based learning machine. Our experiments indicate that the set of features used by Viola and Jones and others for face recognition was inefficient for our problem, recognizing cars accurately and in real time with fast training. Our training method has resulted in finding a very accurate classifier containing merely 30 WCs after about 1 h of training. Compared to existing literature, we have overall achieved the design of a real time object detection machine with the least number of examples, the least number of WCs, the fastest training time, and with competitive detection and false positive rates.	Univ Ottawa, SITE, Ottawa, ON, Canada	Stojmenovic, M (reprint author), Univ Ottawa, SITE, Ottawa, ON, Canada.	Milos22@gmail.com					Barczak ALC, 2004, LECT NOTES ARTIF INT, V3157, P969; BLASCHKO M, 2005, P IEEE WORKSH APPL C, P5; BURGHARDT T, 2005, UNPUB IEE P VIS IM S; Efford N., 2000, DIGITAL IMAGE PROCES; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; LE D, 2005, IS T SPIE S EL IM; LEVI K, 2004, INT C COMP VISION PA; LUO H, 2004, 17 IEEE INT C PATT R, V2; PETROVIC VS, 2004, P BRIT MACH VIS C, V2, P587; STJOMENOVIC M, 2005, P IEEE INT WORKSH SY, P22; SUNG K, 1998, IEEE T PATTERN ANAL, V30, P39; THURESON J, 2003, P 13 SCAND C IM AN S; Verschae R, 2003, LECT NOTES COMPUT SC, V2686, P742; VIOLA P, 2004, INT J COMPUT VISI, V75, P137; WU J, 2004, P ADV NEUR INF PROC, V16	15	4	4	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0932-8092		MACH VISION APPL	Mach. Vis. Appl.	AUG	2006	17	3					163	172		10.1007/s00138-006-0022-6		10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	063RI	WOS:000239036900002	
J	Jesneck, JL; Nolte, LW; Baker, JA; Floyd, CE; Lo, JY				Jesneck, Jonathan L.; Nolte, Loren W.; Baker, Jay A.; Floyd, Carey E.; Lo, Joseph Y.			Optimized approach to decision fusion of heterogeneous data for breast cancer diagnosis	MEDICAL PHYSICS			English	Article						decision fusion; heterogeneous data; receiver operating characteristic (ROC) curve; area under the curve (AUC); partial area under the curve (pAUC); classification; machine learning; breast cancer	COMPUTER-AIDED DIAGNOSIS; SCREENING MAMMOGRAPHY; MICROCALCIFICATION CLUSTERS; LIKELIHOOD RATIO; MASSES; CLASSIFICATION; LESIONS; LOCALIZATION; PERFORMANCE; SONOGRAPHY	As more diagnostic testing options become available to physicians, it becomes more difficult to combine various types of medical information together in order to optimize the overall diagnosis. To improve diagnostic performance, here we introduce an approach to optimize a decision-fusion technique to combine heterogeneous information, such as from different modalities, feature categories, or institutions. For classifier comparison we used two performance metrics: The receiving operator characteristic (ROC) area under the curve [area under the ROC curve (AUC)] and the normalized partial area under the curve (pAUC). This study used four classifiers: Linear discriminant analysis (LDA), artificial neural network (ANN), and two variants of our decision-fusion technique, AUC-optimized (DF-A) and pAUC-optimized (DF-P) decision fusion. We applied each of these classifiers with 100-fold cross-validation to two heterogeneous breast cancer data sets: One of mass lesion features and a much more challenging one of microcalcification lesion features. For the calcification data set, DF-A outperformed the other classifiers in terms of AUC (p < 0.02) and achieved AUC = 0.85 +/- 0.01. The DF-P surpassed the other classifiers in terms of pAUC (p < 0.01) and reached pAUC = 0.38 +/- 0.02. For the mass data set, DF-A outperformed both the ANN and the LDA (p < 0.04) and achieved AUC = 0.94 +/- 0.01. Although for this data set there were no statistically significant differences among the classifiers' pAUC values (pAUC = 0.57 +/- 0.07 to 0.67 +/- 0.05, p > 0.10), the DF-P did significantly improve specificity versus the LDA at both 98% and 100% sensitivity (p < 0.04). In conclusion, decision fusion directly optimized clinically significant performance measures, such as AUC and pAUC, and sometimes outperformed two well-known machine-learning techniques when applied to two different breast cancer data sets. (C) 2006 American Association of Physicists in Medicine.	Duke Univ, Dept Biomed Engn, Durham, NC 27705 USA; Duke Univ, Duke Adv Imaging Labs, Dept Radiol, Durham, NC 27705 USA; Duke Univ, Dept Elect & Comp Engn, Durham, NC 27705 USA; Duke Univ, Med Phys Grad Program, Durham, NC 27705 USA	Jesneck, JL (reprint author), Duke Univ, Dept Biomed Engn, Durham, NC 27705 USA.	jonathan.jesneck@duke.edu					Bilska-Wolak AO, 2003, MED PHYS, V30, P949, DOI 10.1118/1.1565339; Bilska-Wolak AO, 2004, PHYS MED BIOL, V49, P4219, DOI 10.1088/0031-9155/49/18/003; Bilska-Wolak AO, 2005, ACAD RADIOL, V12, P671, DOI 10.1016/j.acra.2005.02.011; Brem RF, 2003, AM J ROENTGENOL, V181, P687; Burhenne LJW, 2000, RADIOLOGY, V215, P554; Cady B, 2001, CANCER, V91, P1699, DOI 10.1002/1097-0142(20010501)91:9<1699::AID-CNCR1186>3.0.CO;2-W; CHAIR Z, 1986, IEEE T AERO ELEC SYS, V22, P98, DOI 10.1109/TAES.1986.310699; Chan HP, 1997, PHYS MED BIOL, V42, P549, DOI 10.1088/0031-9155/42/3/008; Chan HP, 1998, MED PHYS, V25, P2007, DOI 10.1118/1.598389; Chang YH, 1996, INVEST RADIOL, V31, P146, DOI 10.1097/00004424-199603000-00005; Chen DR, 2000, ULTRASOUND MED BIOL, V26, P405, DOI 10.1016/S0301-5629(99)00156-8; Chen WJ, 2004, MED PHYS, V31, P1076, DOI 10.1118/1.1695652; DASARATHY BV, 1991, IEEE T SYST MAN CYB, V21, P1140, DOI 10.1109/21.120065; Destounis SV, 2004, RADIOLOGY, V232, P578, DOI 10.1148/radiol.2322030034; DRAKOPOULOS E, 1991, IEEE T AERO ELEC SYS, V27, P593, DOI 10.1109/7.85032; Efron B., 1993, INTRO BOOTSTRAP; Freer TW, 2001, RADIOLOGY, V220, P781, DOI 10.1148/radiol.2203001282; Gavrielides MA, 2002, MED PHYS, V29, P475, DOI 10.1118/1.1460874; Heath M, 1998, COMP IMAG VIS, V13, P457; HELVIE MA, 1991, AM J ROENTGENOL, V157, P711; Hong AS, 2005, AM J ROENTGENOL, V184, P1260; Horsch K, 2004, ACAD RADIOL, V11, P272, DOI 10.1016/S1076-6332(03)00719-0; Horsch K, 2002, MED PHYS, V29, P157, DOI 10.1118/1.1429239; JERNAL A, 2005, CA CANC J CLIN, V55, P10; JESNECK JL, IN PRESS RADIOLOGY; Jiang YL, 1996, RADIOLOGY, V201, P745; Kallergi M, 2004, MED PHYS, V31, P314, DOI 10.1118/1.1637972; Lacey JV, 2002, ENVIRON MOL MUTAGEN, V39, P82, DOI 10.1002/em.10062; Lanckriet G R G, 2004, Pac Symp Biocomput, P300; Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294; LIAO Y, 2005, THESIS DUKE U; Liao YW, 2003, P SOC PHOTO-OPT INS, V5089, P1252, DOI 10.1117/12.486834; Markey MK, 2002, RADIOLOGY, V223, P489, DOI 10.1148/radiol.2232011257; MEYER JE, 1984, RADIOLOGY, V150, P335; NIU R, 2004, P 7 INT C INF FUS ST, V1, P21; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Petrick N, 1996, MED PHYS, V23, P1685, DOI 10.1118/1.597756; Petrick N, 2002, RADIOLOGY, V224, P217, DOI 10.1148/radiol.2241011062; REIBMAN AR, 1987, IEEE T AERO ELEC SYS, V23, P24, DOI 10.1109/TAES.1987.313355; ROSENBERG AL, 1987, RADIOLOGY, V162, P167; Sahiner B, 2004, PROC SPIE, V5370, P67, DOI 10.1117/12.535868; TENNEY RR, 1980, P IEEE C DECISION CO, V1, P501; Van Trees H. L., 1968, DETECTION ESTIMATI 1; Veeramachaneni K, 2005, IEEE T SYST MAN CY C, V35, P344, DOI 10.1109/TSMCC.2005.848191; VYBORNY CJ, 1994, RADIOLOGY, V191, P315; Wei J, 2005, MED PHYS, V32, P2827, DOI 10.1118/1.1907327; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; YANKASKAS BC, 1988, RADIOLOGY, V23, P729; Zheng MM, 2005, COMPUT BIOL MED, V35, P259, DOI 10.1016/j.compbiomed.2004.01.002; *BI RADS AM COLL R, 1998, REP DAT SYST	50	19	19	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405		MED PHYS	Med. Phys.	AUG	2006	33	8					2945	2954		10.1118/1.2208934		10	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	074ZZ	WOS:000239852800031	
J	Ghafoor, A; Zhang, ZF; Lew, MS; Zhou, ZH				Ghafoor, Arif; Zhang, Zhongfei (Mark); Lew, Michael S.; Zhou, Zhi-Hua			Guest Editors' introduction to the special issue: machine learning approaches to multimedia information retrieval	MULTIMEDIA SYSTEMS			English	Editorial Material									Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA; SUNY Binghamton, Watson Sch, Dept Comp Sci, Binghamton, NY 13902 USA; Leiden Univ, LIACS Media Lab, Leiden, Netherlands; Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210008, Peoples R China	Ghafoor, A (reprint author), Purdue Univ, Sch Elect & Comp Engn, Engn Adm Bldg,Room 101 400,Centennial Mall Dr, W Lafayette, IN 47907 USA.	ghafoor@ecn.purdue.edu; zhongfei@cs.binghamton.edu; mlew@liacs.nl; zhouzh@nju.edu.cn						0	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0942-4962		MULTIMEDIA SYST	Multimedia Syst.	AUG	2006	12	1					1	2		10.1007/s00530-006-0040-2		2	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	072DB	WOS:000239651700001	
J	Huang, SH; Wu, QJ; Lai, SH				Huang, Szu-Hao; Wu, Qi-Jiunn; Lai, Shang-Hong			Improved AdaBoost-based image retrieval with relevance feedback via paired feature learning	MULTIMEDIA SYSTEMS			English	Article						AdaBoost; image retrieval; relevance feedback; paired feature learning	MULTIMEDIA; SYSTEM	Boost learning algorithm, such as AdaBoost, has been widely used in a variety of applications in multimedia and computer vision. Relevance feedback-based image retrieval has been formulated as a classification problem with a small number of training samples. Several machine learning techniques have been applied to this problem recently. In this paper, we propose a novel paired feature AdaBoost learning system for relevance feedback-based image retrieval. To facilitate density estimation in our feature learning method, we propose an ID3-like balance tree quantization method to preserve most discriminative information. By using paired feature combination, we map all training samples obtained in the relevance feedback process onto paired feature spaces and employ the AdaBoost algorithm to select a few feature pairs with best discrimination capabilities in the corresponding paired feature spaces. In the AdaBoost algorithm, we employ Bayesian classification to replace the traditional binary weak classifiers to enhance their classification power, thus producing a stronger classifier. Experimental results on content-based image retrieval (CBIR) show superior performance of the proposed system compared to some previous methods.	Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan	Lai, SH (reprint author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.	Howard@cs.nthu.edu.tw; legler@cs.nthu.edu.tw; lai@cs.nthu.edu.tw					Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; CHEN B, 2001, INT ARCH PHOTOGRAMME, V34, P37; Ciocca G, 2001, J VISUAL LANG COMPUT, V12, P81, DOI 10.1006/jvlc.2000.0188; Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596; Deok Hwan Kim, 2003, P ACM SIGMOD INT C M, P599; DOULAMIS A, 2003, P INT C IMAGE PROCES, V1, P737; Doulamis ND, 2003, IEEE MULTIMEDIA, V10, P38, DOI 10.1109/MMUL.2003.1237549; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GONG Y, 1994, P INT C MULT COMP SY, P121; HE J, 2004, P IEEE INT C PATTERN, V1, P148; Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; JING F, 2003, P IEEE INT C MULTIME, V2, P21; JING F, 2002, IEEE ICASSP 02, V4, P4088; JING F, 2002, P INT C PATTERN RECO, V14, P672; Jing F., 2002, P IEEE INT S CIRC SY, V4, P145; Kushki A, 2004, IEEE T CIRC SYST VID, V14, P644, DOI 10.1109/TCSVT.2004.826759; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Liu C., 2003, P IEEE C COMP VIS PA, V1, P587; Ma W. Y., 1997, P IEEE INT C IM PROC, V1, P568, DOI 10.1109/ICIP.1997.647976; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Minka TP, 1997, PATTERN RECOGN, V30, P565, DOI 10.1016/S0031-3203(96)00113-6; NATSEV A, 1999, P ACM SIGMOD INT C M, P395, DOI 10.1145/304182.304217; NIBLACK W, 1993, P SPIE STOR RETR IM; RATAN AL, 1999, P IEEE C COMP VIS PA, V1, P23; REUND Y, 1995, P EUR C COMP LEARN T, P23; Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413; Rui Y., 1997, P IEEE INT C IM PROC, V2, P815; Rui Y., 2000, P IEEE INT C COMP VI, V1, P236, DOI 10.1109/CVPR.2000.855825; Salton G., 1983, INTRO MODERN INFORM; Sclaroff Stan, 1997, Proceedings 1997 IEEE Workshop on Content-Based Access of Image and Video Libraries, DOI 10.1109/IVL.1997.629714; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; TAO D, 2004, P IEEE INT C COMP VI, V2, P647; TIEU K, 2000, P IEEE C COMP VIS PA, V1, P228, DOI 10.1109/CVPR.2000.855824; Viola P., 2001, P IEEE C COMP VIS PA, V1, P511; Wang J, 2004, FOOD RES INT, V37, P45, DOI 10.1016/j.foodres.2003.09.004; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; Wood M. E. J., 1998, Proceedings ACM Multimedia 98, DOI 10.1145/290747.290750; ZHOU X, 2004, P CIVR 04 DUBL IR, P353; ZHOU XS, 1999, P INT C IM PROC, V2, P24; ZHOU XS, 2001, P IEEE C COMP VIS PA, V1, P11; Zhou XS, 2005, IEE P-VIS IMAGE SIGN, V152, P927, DOI 10.1049/ip-vis:20045190	41	11	13	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0942-4962		MULTIMEDIA SYST	Multimedia Syst.	AUG	2006	12	1					14	26		10.1007/s00530-006-0028-y		13	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	072DB	WOS:000239651700003	
J	Khan, MKS; Al-Khatib, WG				Khan, M. Kashif Saeed; Al-Khatib, Wasfi G.			Machine-learning based classification of speech and music	MULTIMEDIA SYSTEMS			English	Article						speech music classification; audio signal processing; audio features; neural networks; Hidden Markov Models; fuzzy C-means clustering		The need to classify audio into categories such as speech or music is an important aspect of many multimedia document retrieval systems. In this paper, we investigate audio features that have not been previously used in music-speech classification, such as the mean and variance of the discrete wavelet transform, the variance of Mel-frequency cepstral coefficients, the root mean square of a lowpass signal, and the difference of the maximum and minimum zero-crossings. We, then, employ fuzzy C-means clustering to the problem of selecting a viable set of features that enables better classification accuracy. Three different classification frameworks have been studied:Multi-Layer Perceptron (MLP) Neural Networks, radial basis functions (RBF) Neural Networks, and Hidden Markov Model (HMM), and results of each framework have been reported and compared. Our extensive experimentation have identified a subset of features that contributes most to accurate classification, and have shown that MLP networks are the most suitable classification framework for the problem at hand.	King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, Dhahran 31261, Saudi Arabia	Al-Khatib, WG (reprint author), King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, Dhahran 31261, Saudi Arabia.	wasfi@ccse.kfupm.edu.sa					BEIERHOLM T, 2004, P 17 INT C PATT REC, V2, P379, DOI 52218715,12,1; Bezdek J. C., 1981, PATTERN RECOGNITION; BUGATTI A, 2002, EURASIP J APPL SIG P, V4, P372; CAREY MJ, 1999, P IEEE INT C AC SPEE, V1, P149; CHOU W, 2001, P ICASSP, V2, P865; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; DELFS C, 1998, P INT C AC SPEECH SI, V3, P1569, DOI 10.1109/ICASSP.1998.681751; Duda R. O., 2001, PATTERN CLASSIFICATI; ELMALEH K, 2000, P ICASSP, V4, P2445; HARB H, 2003, P IEEE INT S SIGN PR, V2, P125; HARB H, 2001, P 7 INT C DISTR MULT, P257; HOYT JD, 1994, P INT C NEUR NETW IE, V7, P4493, DOI 10.1109/ICNN.1994.374996; KARNEBACK S, 2001, P EUR C SPEECH COMM, P1891; KHAN MKS, 2005, THESIS KING FAHD U P; LAMBROU T, 1998, P INT C AC SPEECH SI, V6, P3621, DOI 10.1109/ICASSP.1998.679665; Li DG, 2001, PATTERN RECOGN LETT, V22, P533, DOI 10.1016/S0167-8655(00)00119-7; Lipp OV, 2004, EMOTION, V4, P233, DOI 10.1037/1528-3542.4.3.233; LU L, 2003, ACM MULTIMEDIA SYSTE, V8, P482; Lu L., 2001, P 9 ACM INT C MULT, P203; Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546; MAMMONE RJ, 1994, ARTIFICIAL NEURAL NE; PANAGIOTAKIS C, 2004, IEEE T MULTIMEDIA; PARRIS ES, 1999, P EUROSPEECH 99 BUD, P2191; Peltonen V., 2001, THESIS TAMPERE U TEC; PINQUIER J, 2002, P ICSLP 02, V3, P2005; PINQUIER J, 2003, P INT C AC SPEECH SI, V2, P17; PINQUIER J, 2002, P INT C AC SPEECH SI, V4, P4164; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; Saad E. M., 2002, Proceedings of the Nineteenth National Radio Science Conference (NRSC'2002) (IEEE Cat. No.02EX567), DOI 10.1109/NRSC.2002.1022623; Saunders J., 1996, P INT C AC SPEECH SI, VII, P993; Scheirer E, 1997, P ICASSP 97, V2, P1331, DOI 10.1109/ICASSP.1997.596192; SHAO X, 2003, P 4 INT C INF COMM S, V3, P1823; SRINIVASAN SH, 2004, P INT C AC SPEECH SI, V4, P321; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Tzanetakis G., 2001, P INT S MUS INF RETR, P205; TZANETAKIS G, 1999, EUROMICRO WORKSH MUS, V2, P61; WANG WQ, 2003, P 4 PAC RIM C MULT, V3, P1325	37	10	10	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0942-4962		MULTIMEDIA SYST	Multimedia Syst.	AUG	2006	12	1					55	67		10.1007/s00530-006-0034-0		13	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	072DB	WOS:000239651700007	
J	Pendharkar, P; Nanda, S				Pendharkar, Parag; Nanda, Sudhir			A misclassification cost-minimizing evolutionary-neural classification approach	NAVAL RESEARCH LOGISTICS			English	Article						data mining; genetic algorithms; neural networks; misclassification cost; knowledge discovery; classification; medical diagnosis; bankruptcy prediction; machine learning; goal programming; rule induction	LINEAR DISCRIMINANT-ANALYSIS; PROGRAMMING MODELS; FINANCIAL RATIOS; DECISION TREES; NETWORKS; OPTIMIZATION; CLASSIFIERS; PERFORMANCE; ALGORITHMS; BANKRUPTCY	Machine learning algorithms that incorporate misclassification costs have recently received considerable attention. In this paper, we use the principles of evolution to develop and test an evolutionary/genetic algorithm (GA)-based neural approach that incorporates asymmetric Type I and Type II error costs. Using simulated, real-world medical and financial data sets, we compare the results of the proposed approach with other statistical, mathematical, and machine learning approaches, which include statistical linear discriminant analysis, back-propagation artificial neural network, integrated cost preference-based linear mathematical programming-based minimize squared deviations, linear integrated cost preference-based GA, decision trees (C 5.0, and CART), and inexpensive classification with expensive tests algorithm. Our results indicate that the proposed approach incorporating asymmetric error costs results in equal or lower holdout sample misclassification cost when compared with the other statistical, mathematical, and machine learning misclassification cost-minimizing approaches. (C) 2006 Wiley Periodicals, Inc.	Penn State Univ Harrisburg, Sch Business Adm, Middletown, PA 17057 USA; T Rowe Price Associates Inc, Baltimore, MD 21202 USA	Pendharkar, P (reprint author), Penn State Univ Harrisburg, Sch Business Adm, 777 W Harrisburg Pike, Middletown, PA 17057 USA.	paragp@psu.edu; sudhimanda@hotmail.com					ABAD PL, 1993, EUR J OPER RES, V67, P88, DOI 10.1016/0377-2217(93)90324-G; Altman E I, 1977, J BANK FINANC, V1, P29, DOI 10.1016/0378-4266(77)90017-6; ALTMAN EI, 1994, J BANK FINANC, V18, P505, DOI 10.1016/0378-4266(94)90007-8; ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; Anderson T.W., 1958, INTRO MULTIVARIATE S; Berardi VL, 1999, DECISION SCI, V30, P659, DOI 10.1111/j.1540-5915.1999.tb00902.x; Bhattacharyya S, 1998, DECISION SCI, V29, P871, DOI 10.1111/j.1540-5915.1998.tb00880.x; Bhattacharyya S, 2003, EUR J OPER RES, V144, P333, DOI 10.1016/S0377-2217(01)00401-5; Breiman L, 1984, CLASSIFICATION REGRE; Chan PK, 1999, IEEE INTELL SYST APP, V14, P67, DOI 10.1109/5254.809570; DILLA WN, 1991, AUDITING RES BEHAV R, V1, P113; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; DOPUCH N, 1987, ACCOUNT REV, V62, P431; DRAPER BA, 1994, IEEE T PATTERN ANAL, V16, P888, DOI 10.1109/34.310684; Elkan C., 2001, P 17 INT JOINT C ART, P973; ETHRIDGE HL, 2000, DECISION SCI, V31, P531; FREED N, 1986, DECISION SCI, V17, P151, DOI 10.1111/j.1540-5915.1986.tb00218.x; GLOVER F, 1990, DECISION SCI, V21, P771, DOI 10.1111/j.1540-5915.1990.tb01249.x; Goldberg DE, 1991, FDN GENETIC ALGORITH, P69; Gordon D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00317.x; GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288; HOPWOOD W, 1989, ACCOUNT REV, V64, P28; Jain BA, 1995, DECISION SCI, V26, P283, DOI 10.1111/j.1540-5915.1995.tb01430.x; JOACHIMSTHALER EA, 1988, DECISION SCI, V19, P322, DOI 10.1111/j.1540-5915.1988.tb00270.x; KING R, 1994, MACHINE INTELLIGENCE; KNOLL U., 1994, P 8 EUR C MACH LEARN, P383; KOEHLER GJ, 1990, DECISION SCI, V21, P63; Kovalerchuk B, 1997, ARTIF INTELL MED, V11, P75, DOI 10.1016/S0933-3657(97)00021-3; Kumar A, 1999, INFORMS J COMPUT, V11, P267, DOI 10.1287/ijoc.11.3.267; Mannino MV, 2000, DECIS SUPPORT SYST, V29, P283, DOI 10.1016/S0167-9236(00)00077-4; MANNINO MV, 1999, INFORMS J COMPUT, V3, P278; Mookerjee V. S., 1993, INFORMATION SYSTEMS, V4, P111, DOI 10.1287/isre.4.2.111; Mookerjee VS, 2000, INFORM SYST RES, V11, P137, DOI 10.1287/isre.11.2.137.11777; Mookerjee VS, 1997, INFORM SYST RES, V8, P51, DOI 10.1287/isre.8.1.51; Mookerjee VS, 1997, IEEE T KNOWL DATA EN, V9, P675, DOI 10.1109/69.634747; Moore J. C., 1986, Decision Support Systems, V2, DOI 10.1016/0167-9236(86)90001-1; Moore J. C., 1987, Decision Support Systems, V3, DOI 10.1016/0167-9236(87)90035-2; Murphy C. K., 1997, INFORMS Journal on Computing, V9, DOI 10.1287/ijoc.9.4.385; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Nanda S., 2001, International Journal of Intelligent Systems in Accounting, Finance and Management, V10, DOI 10.1002/isaf.203; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; OHLSON JA, 1980, J ACCOUNTING RES, V18, P109, DOI 10.2307/2490395; PARK J, 1997, P 2 INFORMS C INF SY, P1; Pendharkar PC, 1999, EXPERT SYST APPL, V17, P223, DOI 10.1016/S0957-4174(99)00036-6; Pendharkar PC, 2004, COMPUT OPER RES, V31, P481, DOI 10.1016/S0305-0548(02)00229-0; Pendharkar PC, 2002, EUR J OPER RES, V138, P155, DOI 10.1016/S0377-2217(01)00085-6; Pendharkar PC, 2005, DECIS SUPPORT SYST, V41, P228, DOI 10.1016/j.dss.2004.07.001; PROVOST FJ, 1994, AAAI SPRING S GOAL D, P53; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RAGSDALE CT, 1991, DECISION SCI, V22, P296, DOI 10.1111/j.1540-5915.1991.tb00348.x; Rich E., 1991, ARTIFICIAL INTELLIGE; ROBERTS H, 1995, P INT S INT DAT AN I, P149; Schalkoff R., 1997, ARTIFICIAL NEURAL NE; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; TAN M, 1990, IEEE INT C ROB AUT, P858; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; WHITLEY D, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P391; WITTEN IH, 2000, DATA MINING PRACTICA, P128; WRIGHT AH, 1991, P 4 INT C GEN ALG, P205	62	11	11	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0894-069X		NAV RES LOG	Nav. Res. Logist.	AUG	2006	53	5					432	447		10.1002/nav.20154		16	Operations Research & Management Science	Operations Research & Management Science	063SX	WOS:000239041000005	
J	Nanni, L; Lumini, A				Nanni, Loris; Lumini, Alessandra			An approach for improving face recognition in presence of inaccurate detection	NEUROCOMPUTING			English	Article						face recognition; machine learning; classifier combination	EIGENFACES	In this paper, we introduce a new face recognition approach robust to allocation error of face features. We show that combining a "standard method" for face recognition and a new approach based on a "cloud of points" for representing a face image,we obtain a system that not only gives good performance when faces are perfectly detected, but also in the presence of detection errors. Extensive experiments carried out on the ORL and YALE databases of faces prove the advantages of the proposed approach when compared with other well-known techniques. (c) 2006 Elsevier B.V. All rights reserved.	Univ Bologna, CNR, IEIIT, DEIS,Alma Mater Studiorum, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, CNR, IEIIT, DEIS,Alma Mater Studiorum, Viale Risorgimento 2, I-40136 Bologna, Italy.	Lnanni@deis.unibo.it	Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354			Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Duda R., 2000, PATTERN CLASSIFICATI; JESORSKY O, 2001, P 3 INT C AUD VID BA, V2091, P90; Kuncheva LI, 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; Lai C, 2004, INT J PATTERN RECOGN, V18, P867, DOI 10.1142/S0218001404003459; Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572; Pan Z., 2000, P INT JOINT C NEUR N, V3, P149; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; YANG M, 2000, P INT C IM PROC, V1, P37, DOI 10.1109/ICIP.2000.900886; ZHAO W, 1999, P INT JOINT C NEUR N, V5, P3260	10	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	AUG	2006	69	13-15					1678	1682		10.1016/j.neucom.2006.01.019		5	Computer Science, Artificial Intelligence	Computer Science	063JR	WOS:000239015000030	
J	Nanni, L				Nanni, Loris			A reliable method for designing an automatic karyotyping system	NEUROCOMPUTING			English	Article						chromosomes; ensemble of classifiers; karyotype	CLASSIFICATION; CHROMOSOMES	Karyotyping, a standard method for presenting pictures of the human chromosomes for diagnostic purposes, is a long standing, yet common technique in cytogenetics. Karyotype is often used for predicting genetic disorders or possible abnormalities that may occur in the future generations. Performance of the various classifiers was compared by the error rate. The fusion of machine-learning-type classifiers showed improved performance over the best results previously published in the literature. (c) 2006 Elsevier B.V. All rights reserved.	Univ Bologna, CNR, DEIS, IEIIT, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, CNR, DEIS, IEIIT, Via Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it					Conroy JM, 2000, LAB INVEST, V80, P1629, DOI 10.1038/labinvest.3780173; Duda R. O., 2001, PATTERN CLASSIFICATI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hong LM, 2000, MED CYTOGENETICS; Kuncheva LI, 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Moradi M, 2006, PATTERN RECOGN LETT, V27, P19, DOI 10.1016/j.patrec.2005.06.011; Moradi M., 2003, Proceedings 16th IEEE Symposium on Computer-Based Medical Systems. CBMS 2003; PIPER J, 1980, SIGNAL PROCESS, V2, P203, DOI 10.1016/0165-1684(80)90019-5; Ritter G, 1999, PATTERN RECOGN, V32, P997, DOI 10.1016/S0031-3203(98)00131-9; Verma RS, 1995, HUMAN CHROMOSOMES PR; Wu Q, 2005, IEEE T IMAGE PROCESS, V14, P1277, DOI 10.1109/TIP.2005.852468	12	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	AUG	2006	69	13-15					1739	1742		10.1016/j.neucom.2006.01.005		4	Computer Science, Artificial Intelligence	Computer Science	063JR	WOS:000239015000042	
J	Menze, BH; Lichy, MP; Bachert, P; Kelm, BM; Schlemmer, HP; Hamprecht, FA				Menze, B. H.; Lichy, M. P.; Bachert, P.; Kelm, B. M.; Schlemmer, H. -P.; Hamprecht, F. A.			Optimal classification of long echo time in vivo magnetic resonance spectra in the detection of recurrent brain tumors	NMR IN BIOMEDICINE			English	Article						statistical learning; chemometrics; preprocessing; postprocessing; benchmark; magnetic resonance spectroscopy; human brain tumor	MR SPECTROSCOPY QUANTITATION; PATTERN-RECOGNITION; GLIOMATOSIS CEREBRI; COMPONENT ANALYSIS; DOMAIN METHODS; NMR-SPECTRA; LESIONS; QUANTIFICATION; ACCURACY; GRADE	We describe the optimal high-level postprocessing of single-voxel (1)H magnetic resonance spectra and assess the benefits and limitations of automated methods as diagnostic aids in the detection of recurrent brain tumor. In a previous clinical study, 90 long-echo-time single-voxel spectra were obtained from 52 patients and classified during follow-up (30/28/ 32 normal/non-progressive tumor/tumor). Based on these data, a large number of evaluation strategies, including both standard resonance line quantification and algorithms from pattern recognition and machine learning, were compared in a quantitative evaluation. Results from linear and non-linear feature extraction, including ICA, PCA and wavelet transformations, and'also the data from resonance line quantification were combined systematically with different classifiers such as LDA, chemometric methods (PLS, PCR), support vector machines and ensemble methods. Classification accuracy was assessed using a leave-one-out cross-validation scheme and the area under the curve (AUC) of the receiver operator characteristic (ROC). A regularized linear regression on spectra with binned channels reached 91% classification accuracy compared with 83% from quantification. Interpreting the loadings of these regressions, we find that lipid and lactate signals are too unreliable to be used in a simple machine rule. Choline and NAA are the main source of relevant information. Overall, we find that fully automated pattern recognition algorithms perform as well as, or slightly better than, a manually controlled and optimized resonance line quantification. Copyright (C) 2006 John Wiley & Sons, Ltd.	Univ Heidelberg, Interdisciplinary Ctr Sci Comp IWR, D-69120 Heidelberg, Germany; German Canc Res Ctr, Div Radiol, Heidelberg, Germany; German Canc Res Ctr, Div Med Phys Radiol, Heidelberg, Germany	Hamprecht, FA (reprint author), Univ Heidelberg, Interdisciplinary Ctr Sci Comp IWR, D-69120 Heidelberg, Germany.	fred.hamprecht@iwr.uni-heidelberg.de					Bathen TF, 2000, NMR BIOMED, V13, P271, DOI 10.1002/1099-1492(200008)13:5<271::AID-NBM646>3.0.CO;2-7; Bendszus M, 2000, AM J NEURORADIOL, V21, P375; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Butzen J, 2000, AM J NEURORADIOL, V21, P1213; Devos A, 2004, J MAGN RESON, V170, P164, DOI 10.1016/j.jmr.2004.06.010; Duda R., 2000, PATTERN CLASSIFICATI; Dydak U, 2003, MAGNET RESON MED, V50, P196, DOI 10.1002/mrm.10495; ElDeredy W, 1997, NMR BIOMED, V10, P99, DOI 10.1002/(SICI)1099-1492(199705)10:3<99::AID-NBM461>3.0.CO;2-#; Galanaud D, 2003, J NEUROSURG, V98, P269, DOI 10.3171/jns.2003.98.2.0269; Hagberg G, 1998, NMR BIOMED, V11, P148, DOI 10.1002/(SICI)1099-1492(199806/08)11:4/5<148::AID-NBM511>3.0.CO;2-4; Hastie T, 2001, ELEMENTS STAT LEARNI; Herminghaus S, 2003, J NEUROSURG, V98, P74, DOI 10.3171/jns.2003.98.1.0074; Howe FA, 2003, NMR BIOMED, V16, P123, DOI 10.1002/nbm.822; in 't Zandt H, 2001, NMR Biomed, V14, P224, DOI 10.1002/nbm.707; Ladroue C, 2003, MAGNET RESON MED, V50, P697, DOI 10.1002/mrm.10595; Lichy MP, 2005, NEURORADIOLOGY, V47, P826, DOI 10.1007/s00234-005-1434-0; Lisboa PJG, 1998, NMR BIOMED, V11, P225, DOI 10.1002/(SICI)1099-1492(199806/08)11:4/5<225::AID-NBM509>3.0.CO;2-Q; Majos C, 2003, EUR RADIOL, V13, P582, DOI 10.1007/s00330-002-1547-3; MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468; Menze BH, 2005, ST CLASS DAT ANAL, P362, DOI 10.1007/3-540-28084-7_41; Mierisova S, 2001, NMR BIOMED, V14, P247, DOI 10.1002/nbm.697; Moller-Hartmann W, 2002, NEURORADIOLOGY, V44, P371, DOI 10.1007/s00234-001-0760-0; Naressi A, 2001, MAGN RESON MATER PHY, V12, P141, DOI 10.1007/BF02668096; PROVENCHER SW, 1993, MAGNET RESON MED, V30, P672, DOI 10.1002/mrm.1910300604; Schlemmer HP, 2001, AM J NEURORADIOL, V22, P1316; SEEGER U, P ESMRMB 2003 EUR SO, P331; Simonetti AW, 2005, NMR BIOMED, V18, P34, DOI 10.1002/nbm.919; Simonetti AW, 2003, ANAL CHEM, V75, P5352, DOI 10.1021/ac034541t; STADLBAUER A, P ISMRM 2004 INT SOC, P2053; Stoyanova R, 2002, J MAGN RESON, V154, P163, DOI 10.1006/jmre.2001.2486; TATE AR, 1996, THESIS U SUSSEX; Tate AR, 1996, MAGNET RESON MED, V35, P834, DOI 10.1002/mrm.1910350608; Tate AR, 2003, MAGNET RESON MED, V49, P29, DOI 10.1002/mrm.10315; Tzika AA, 2001, NEURORADIOLOGY, V43, P169; Vanhamme L, 2001, NMR BIOMED, V14, P233, DOI 10.1002/nbm.695; Vanhamme L, 1997, J MAGN RESON, V129, P35, DOI 10.1006/jmre.1997.1244; Witjes H, 2000, J MAGN RESON, V144, P35, DOI 10.1006/jmre.2000.2021	37	24	24	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0952-3480		NMR BIOMED	NMR Biomed.	AUG	2006	19	5					599	609		10.1002/nbm.1041		11	Biophysics; Radiology, Nuclear Medicine & Medical Imaging; Spectroscopy	Biophysics; Radiology, Nuclear Medicine & Medical Imaging; Spectroscopy	076DI	WOS:000239936800011	
J	Carreiras, JMB; Pereira, JMC; Shimabukuro, YE				Carreiras, Joao M. B.; Pereira, Jose M. C.; Shimabukuro, Yosio E.			Land-cover mapping in the Brazilian Amazon using SPOT-4 vegetation data and machine learning classification methods	PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING			English	Article							REMOTELY-SENSED DATA; DECISION-TREE CLASSIFICATION; RESOLUTION SATELLITE DATA; SPATIAL-RESOLUTION; ACCURACY ASSESSMENT; AVHRR DATA; MULTISPECTRAL DATA; TROPICAL REGIONS; EASTERN AMAZON; MIXING MODELS	The main objective of this study is to evaluate the feasibility of deriving a land-cover map of the state of Mato Grosso, Brazil, for the year 2000, using data from the 1 km SPOT-4 VEGETATION (vGT) sensor. For this purpose we used a VGT temporal series of 12 monthly composite images, which were further transformed to physical-meaningful fraction images of vegetation, soil, and shade. Classification of fraction images was implemented using several recent machine learning developments, namely, filtering input training data and probability bagging in a classification tree approach. A 10-fold cross validation accuracy assessment indicates that filtering and probability bagging are effective at increasing overall and class-specific accuracy. Overall accuracy and mean probability of class membership were 0.88 and 0.80, respectively. The map of probability of class membership indicates that the larger errors are associated with cerrado savanna and semi-deciduous forest.	Inst Super Agron, Dept Forestry, P-1349017 Lisbon, Portugal; Inst Nacl Pesquisas Espaciais, Remote Sensing Dept, BR-12227010 Sao Jose Dos Campos, SP, Brazil	Carreiras, JMB (reprint author), Inst Super Agron, Dept Forestry, Tapada Ajuda, P-1349017 Lisbon, Portugal.	jmbcarreiras@isa.utl.pt; jmcpereira@isa.utl.pt; yosio@ltid.inpe.br	Carreiras, Joao/B-4520-2008				Achard F, 2001, INT J REMOTE SENS, V22, P2741, DOI 10.1080/01431160010014251; ADAMS JB, 1995, REMOTE SENS ENVIRON, V52, P137, DOI 10.1016/0034-4257(94)00098-8; ADAMS JB, 1986, J GEOPHYS RES-SOLID, V91, P8098, DOI 10.1029/JB091iB08p08098; Aguiar APD, 1999, INT J REMOTE SENS, V20, P647; Batjes NH, 1997, GLOBAL CHANGE BIOL, V3, P161, DOI 10.1046/j.1365-2486.1997.00062.x; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bell JF, 1996, J APPL STAT, V23, P349, DOI 10.1080/02664769624297; BOARDMAN J. W., 1995, JPL PUBLICATION, V1, P23; Boardman J.W., 1993, JPL PUBLICATION, V95-26, P11; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Bruno F, 2004, ENVIRONMETRICS, V15, P141, DOI 10.1002/env.631; Cardille JA, 2003, REMOTE SENS ENVIRON, V87, P551, DOI 10.1016/j.rse.2002.09.001; Carreiras JMB, 2002, INT J REMOTE SENS, V23, P4979, DOI 10.1080/0143116021000016743; Carreiras JMB, 2005, INT J REMOTE SENS, V26, P1323, DOI 10.1080/01431160512331338005; Chang CI, 2000, IEEE T GEOSCI REMOTE, V38, P1144; Cochrane MA, 1998, INT J REMOTE SENS, V19, P3433; Congalton RG, 2001, INT J WILDLAND FIRE, V10, P321, DOI 10.1071/WF01031; CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B; CONGALTON RG, 1988, PHOTOGRAMM ENG REM S, V54, P587; COUTINHO LM, 1990, ECOL STU AN, V84, P82; CROSS AM, 1991, INT J REMOTE SENS, V12, P1119; de Colstoun ECB, 2003, REMOTE SENS ENVIRON, V85, P316, DOI 10.1016/S0034-4257(03)00010-5; De Fries RS, 1998, INT J REMOTE SENS, V19, P3141, DOI 10.1080/014311698214235; DeFries RS, 2000, REMOTE SENS ENVIRON, V74, P503, DOI 10.1016/S0034-4257(00)00142-5; Di Gregorio A., 2000, LAND COVER CLASSIFIC; Eva HD, 2004, GLOBAL CHANGE BIOL, V10, P731, DOI 10.1111/j.1529-8817.2003.00774.x; Fearnside PM, 2003, AMBIO, V32, P343, DOI 10.1639/0044-7447(2003)032[0343:DCIMGA]2.0.CO;2; FEARNSIDE PM, 1993, AMBIO, V22, P537; Fearnside P.M., 2003, WORLD RESOURCE REV, V15, P352; Foody GM, 1999, PHOTOGRAMM ENG REM S, V65, P443; Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4; Franco-Lopez H, 2001, REMOTE SENS ENVIRON, V77, P251, DOI 10.1016/S0034-4257(01)00209-7; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedl MA, 2002, REMOTE SENS ENVIRON, V83, P287, DOI 10.1016/S0034-4257(02)00078-0; Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7; Friedl MA, 1999, IEEE T GEOSCI REMOTE, V37, P969, DOI 10.1109/36.752215; Friedl MA, 2000, INT J REMOTE SENS, V21, P1073, DOI 10.1080/014311600210434; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Goulding MR, 2003, SMITHSONIAN ATLAS AM; GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001; Hansen M, 1996, INT J REMOTE SENS, V17, P1075; Hansen MC, 2000, INT J REMOTE SENS, V21, P1331, DOI 10.1080/014311600210209; HOLBEN BN, 1993, INT J REMOTE SENS, V14, P2231; Houghton RA, 2000, J GEOPHYS RES-ATMOS, V105, P20121, DOI 10.1029/2000JD900041; Houghton RA, 2000, NATURE, V403, P301, DOI 10.1038/35002062; Houghton RA, 2001, GLOBAL CHANGE BIOL, V7, P731, DOI 10.1046/j.1365-2486.2001.00426.x; HUETE AR, 1988, REMOTE SENS ENVIRON, V25, P295, DOI 10.1016/0034-4257(88)90106-X; Ichoku C., 1996, REMOTE SENSING REV, V13, P161; INPE (Instituto Nacional de Pesquisas Espaciais), 2005, MON FLOR AM BRAS SAT; John G. H., 1995, P 1 INT C KNOWL DISC, P174; Kaimowitz D, 2001, AGRICULTURAL TECHNOLOGIES AND TROPICAL DEFORESTATION, P195, DOI 10.1079/9780851994512.0195; Lambin EF, 2003, ANNU REV ENV RESOUR, V28, P205, DOI 10.1146/annurev.energy.28.050302.105459; Lillesand T., 1994, REMOTE SENSING IMAGE; Liu WG, 2004, PHOTOGRAMM ENG REM S, V70, P963; Lu DS, 2003, REMOTE SENS ENVIRON, V87, P456, DOI 10.1016/j.rse.2002.06.001; Maclin Richard, 1997, P 14 NAT C ART INT, P546; McIver DK, 2002, REMOTE SENS ENVIRON, V81, P253, DOI 10.1016/S0034-4257(02)00003-2; McIver DK, 2001, IEEE T GEOSCI REMOTE, V39, P1959, DOI 10.1109/36.951086; MIRANDA AC, 1996, AMAZONIAN DEFORESTAT, P353; MORAN EF, 1993, HUM ECOL, V21, P1, DOI 10.1007/BF00890069; MORAN EF, 1994, BIOSCIENCE, V44, P329, DOI 10.2307/1312383; Muchoney DM, 2002, REMOTE SENS ENVIRON, V81, P290, DOI 10.1016/S0034-4257(02)00006-8; Nepstad Daniel C., 1997, Ciencia e Cultura (Sao Paulo), V49, P73; OLESON KW, 1995, REMOTE SENS ENVIRON, V54, P98, DOI 10.1016/0034-4257(95)00100-F; PASSOT X, 2000, P VEGETATION 2000 2, P15; Perlich C., 2003, J MACHINE LEARNING R, V4, P211; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; QUARMBY NA, 1992, INT J REMOTE SENS, V13, P415; Richards J. A., 1986, REMOTE SENSING DIGIT; Rodriguez-Yi JL, 2000, INT J REMOTE SENS, V21, P167, DOI 10.1080/014311600211055; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; Schulze ED, 2003, SCIENCE, V299, P1669, DOI 10.1126/science.1079024; SHIMABUKURO YE, 1995, CANADIAN J REMOTE SE, V21, P67; SHIMABUKURO YE, 1991, IEEE T GEOSCI REMOTE, V29, P16, DOI 10.1109/36.103288; Smith JD, 1999, AM BOOK REV, V20, P8; Souza C, 2003, REMOTE SENS ENVIRON, V87, P494, DOI 10.1016/j.rse.2002.08.002; Tansey K, 2004, J GEOPHYS RES-ATMOS, V109, DOI 10.1029/2003JD003598; VELOSO HP, 1974, REGIOES FITOECOLOGIC, P1; Vitousek PM, 1997, SCIENCE, V277, P494, DOI 10.1126/science.277.5325.494; *DEP NAC PROD MIN, 1982, LEV REC NAT, V26; *DEP NAC PROD MIN, 1982, LEV REC NAT, V27; *DEP NAC PROD MIN, 1980, LEV REC NAT, V20; *IBGE, 2000, ATL NAC BRAS; *INPE, 2002, MON BRAZ AM FOR SAT; *RES SYST INC, 2000, ENVI VERS 3 4 US GUI; *SEPLAN, 2002, AN EST MAT GROSS 200; *U MD, 2005, GLOB LAND COV FAC	91	10	10	AMER SOC PHOTOGRAMMETRY	BETHESDA	5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA	0099-1112		PHOTOGRAMM ENG REM S	Photogramm. Eng. Remote Sens.	AUG	2006	72	8					897	910				14	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	069AQ	WOS:000239417400006	
J	Terribilini, M; Lee, JH; Yan, CH; Jernigan, RL; Honavar, V; Dobbs, D				Terribilini, Michael; Lee, Jae-Hyung; Yan, Changhui; Jernigan, Robert L.; Honavar, Vasant; Dobbs, Drena			Prediction of RNA binding sites in proteins from amino acid sequence	RNA-A PUBLICATION OF THE RNA SOCIETY			English	Article						bioinformatics; RNA binding site; RNA-protein interactions; RNABindR; telomerase; prediction	TELOMERASE REVERSE-TRANSCRIPTASE; SUPPORT VECTOR MACHINES; RECOGNITION; DOMAIN; COMPLEXES; MOTIFS; INFORMATION; INHIBITOR; RESIDUES; FAMILIES	RNA-protein interactions are vitally important in a wide range of biological processes, including regulation of gene expression, protein synthesis, and replication and assembly of many viruses. We have developed a computational tool for predicting which amino acids of an RNA binding protein participate in RNA-protein interactions, using only the protein sequence as input. RNABindR was developed using machine learning on a validated nonredundant data set of interfaces from known RNA-protein complexes in the Protein Data Bank. It generates a classifier that captures primary sequence signals sufficient for predicting which amino acids in a given protein are located in the RNA-protein interface. In leave-one-out cross-validation experiments, RNABindR identifies interface residues with > 85% overall accuracy. It can be calibrated by the user to obtain either high specificity or high sensitivity for interface residues. RNABindR, implementing a Naive Bayes classifier, performs as well as a more complex neural network classifier ( to our knowledge, the only previously published sequence-based method for RNA binding site prediction) and offers the advantages of speed, simplicity and interpretability of results. RNABindR predictions on the human telomerase protein hTERT are in good agreement with experimental data. The availability of computational tools for predicting which residues in an RNA binding protein are likely to contact RNA should facilitate design of experiments to directly test RNA binding function and contribute to our understanding of the diversity, mechanisms, and regulation of RNA-protein complexes in biological systems. (RNABindR is available as a Web tool from http://bindr.gdcb.iastate.edu.).	Iowa State Univ, Bioinformat & Computat Biol Grad Program, Ames, IA 50010 USA; Iowa State Univ, Dept Genet Dev & Cell Biol, Ames, IA 50010 USA; Utah State Univ, Dept Comp Sci, Logan, UT 84341 USA; Iowa State Univ, Dept Biochem Biophys & Mol Biol, Ames, IA 50010 USA; Iowa State Univ, Laurence H Baker Ctr Bioinformat & Biol Stat, Ames, IA 50010 USA; Iowa State Univ, Dept Comp Sci, Ames, IA 50010 USA; Iowa State Univ, Ctr Computat Intelligence Learning & Discovery, Ames, IA 50010 USA	Terribilini, M (reprint author), Iowa State Univ, Bioinformat & Computat Biol Grad Program, Ames, IA 50010 USA.	terrible@iastate.edu	Lee, Jae-Hyung/E-6827-2011; Jernigan, Robert/A-5421-2012				Allers J, 2001, J MOL BIOL, V311, P75, DOI 10.1006/jmbi.2001.4857; Autexier C, 2006, ANNU REV BIOCHEM, V75, P493, DOI 10.1146/annurev.biochem.75.103004.142412; Bachand F, 2001, MOL CELL BIOL, V21, P1888, DOI 10.1128/MCB.21.5.1888-1897.2001; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Blackburn EH, 2005, FEBS LETT, V579, P859, DOI 10.1016/j.febslet.2004.11.036; BRADFORD JR, 2004, BIOINFORMATICS, V21, P1487, DOI 10.1093/bioinformatics/bti242; Bryan TM, 2000, MOL CELL, V6, P493, DOI 10.1016/S1097-2765(00)00048-4; BUNTINE W, 1991, THEORY REFINEMENT BA; Cai YD, 2003, BBA-PROTEINS PROTEOM, V1648, P127, DOI 10.1016/S1570-9639(03)00112-2; Chen Y, 2005, FEBS J, V272, P2088, DOI 10.1111/j.1742-4658.2005.04650.x; Cusack Stephen, 1999, Current Opinion in Structural Biology, V9, P66, DOI 10.1016/S0959-440X(99)80009-8; de Vries SJ, 2006, PROTEINS, V63, P479, DOI 10.1002/prot.20842; Draper DE, 1999, J MOL BIOL, V293, P255, DOI 10.1006/jmbi.1999.2991; EISENBERG D, 1984, P NATL ACAD SCI-BIOL, V81, P140, DOI 10.1073/pnas.81.1.140; Fischer D, 1999, BIOINFORMATICS, V15, P759, DOI 10.1093/bioinformatics/15.9.759; Gomis-Roth FX, 2003, STRUCTURE, V11, P423, DOI 10.1016/S0969-2126(03)00050-9; Hall KB, 2002, CURR OPIN STRUC BIOL, V12, P283, DOI 10.1016/S0959-440X(02)00323-8; Han LY, 2004, RNA, V10, P355, DOI 10.1261/rna.5890304; Hoffman MA, 2004, COUNS PSYCHOL, V32, P181, DOI 10.1177/0011000003261377; Hoskins J, 2006, PROTEIN SCI, V15, P1017, DOI 10.1110/ps.051589106; HULO N, 2004, NUCLEIC ACIDS RES, V32, P134; Jacobs SA, 2006, NAT STRUCT MOL BIOL, V13, P218, DOI 10.1038/nsmb1054; Jacobs SA, 2005, PROTEIN SCI, V14, P2051, DOI 10.1110/ps.051532105; Jeong E, 2006, T COMPUT SYST BIOL, V4, P123; Jeong Euna, 2004, Genome Inform, V15, P105; Jones S, 2001, NUCLEIC ACIDS RES, V29, P943, DOI 10.1093/nar/29.4.943; Kim H, 2003, FEBS LETT, V552, P231, DOI 10.1016/S0014-5793(03)00930-X; Klein DJ, 2001, EMBO J, V20, P4214, DOI 10.1093/emboj/20.15.4214; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Lai CK, 2001, MOL CELL BIOL, V21, P990, DOI 10.1128/MCB.21.4.990-1000.2001; Lai CK, 2002, GENE DEV, V16, P415, DOI 10.1101/gad.962602; Lustig B, 1997, NUCLEIC ACIDS RES, V25, P2562, DOI 10.1093/nar/25.13.2562; Mitchell T, 1997, MACHINE LEARNING; Moriarty TJ, 2005, MOL BIOL CELL, V16, P3152, DOI 10.1091/mbc.E05-02-0148; Moriarty TJ, 2004, MOL CELL BIOL, V24, P3720, DOI 10.1128/MCB.24.9.3720-3733.2004; Moriarty TJ, 2002, MOL CELL BIOL, V22, P1253, DOI 10.1128/MCB.22.4.1253-1265.2002; Mulder NJ, 2003, NUCLEIC ACIDS RES, V31, P315, DOI 10.1093/nar/gkg046; Neuvirth H, 2004, J MOL BIOL, V338, P181, DOI 10.1016/j.jmb.2004.02.040; Nissink JWM, 2004, ORG BIOMOL CHEM, V2, P3238, DOI 10.1039/b405205f; O'Connor CM, 2005, J BIOL CHEM, V280, P17533, DOI 10.1074/jbc.M501211200; Ofran Y, 2003, FEBS LETT, V544, P236, DOI 10.1016/S0014-5793(03)00456-3; Pan H, 2003, P NATL ACAD SCI USA, V100, P12648, DOI 10.1073/pnas.2135585100; PANG PS, 2004, J EXP ZOOLOG B, V304, P50; Rost B, 2003, CELL MOL LIFE SCI, V60, P2637, DOI 10.1007/s00018-003-3114-8; Ryter JM, 1998, EMBO J, V17, P7505, DOI 10.1093/emboj/17.24.7505; Sen TZ, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-205; Shanahan HP, 2004, NUCLEIC ACIDS RES, V32, P4732, DOI 10.1093/nar/gkh803; Siew N, 2004, J MOL BIOL, V342, P369, DOI 10.1016/j.jmb.2004.06.073; Terribilini Michael, 2006, Pac Symp Biocomput, P415, DOI 10.1142/9789812701626_0038; Tian B, 2004, NAT REV MOL CELL BIO, V5, P1013, DOI 10.1038/nrm1528; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Weiss MA, 1998, BIOPOLYMERS, V48, P167, DOI 10.1002/(SICI)1097-0282(1998)48:2<167::AID-BIP6>3.0.CO;2-8; Witten I. H., 2005, DATA MINING PRACTICA; YAN C, 2004, BIOINFORMATICS, V20, P1371; Yan CH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-262; Yan CH, 2004, NEURAL COMPUT APPL, V13, P123, DOI 10.1007/s00521-004-0414-3; Yu XJ, 2006, J THEOR BIOL, V240, P175, DOI 10.1016/j.jtbi.2005.09.018	58	71	74	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1355-8382		RNA	RNA-Publ. RNA Soc.	AUG	2006	12	8					1450	1462		10.1261/rna.2197306		13	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	068PA	WOS:000239385700003	
J	Davy, M; Desobry, F; Gretton, A; Doncarli, C				Davy, M; Desobry, F; Gretton, A; Doncarli, C			An online support vector machine for abnormal events detection	SIGNAL PROCESSING			English	Article						abnormality detection; support vector machines; sequential optimization; gearbox fault detection; audio thump detection		The ability to detect online abnormal events in signals is essential in many real-world signal processing applications. Previous algorithms require an explicit signal statistical model, and interpret abnormal events as statistical model abrupt changes. Corresponding implementation relies on maximum likelihood or on Bayes estimation theory with generally excellent performance. However, there are numerous cases where a robust and tractable model cannot be obtained, and model-free approaches need to be considered. In this paper, we investigate a machine learning, descriptor-based approach that does not require an explicit descriptors statistical model, based on support vector novelty detection. A sequential optimization algorithm is introduced. Theoretical considerations as well as simulations on real signals demonstrate its practical efficiency. (c) 2005 Elsevier B.V. All rights reserved.	Ecole Cent Lille, Lab Automat Genie Informat & Signal, UMR 8146, CNRS, F-59651 Villeneuve Dascq, France; Univ Cambridge, Dept Engn, Signal Proc Grp, Cambridge CB2 1PZ, England; Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; CNRS, UMR 6597, Inst Rech Cybernet Nantes, F-44321 Nantes 3, France	Davy, M (reprint author), Ecole Cent Lille, Lab Automat Genie Informat & Signal, UMR 8146, CNRS, BP 48, F-59651 Villeneuve Dascq, France.	Manuel.Davy@ec-lille.fr; fd238@eng.cam.ac.uk; arthur@tuebingen.mpg.de; Christian.Doncarli@irccyn.ec-nantes.fr					Basseville M, 1993, DETECTION ABRUPT CHA; BOUBACAR HA, 2005, INT JOINT C NEUR NET; Campbell C., 2000, RADIAL BASIS FUNCTIO, P155; CAUWENBERGHS G, 2001, ADV NEURAL INFORM PR; Cristianini N., 2000, SUPPORT VECTOR MACHI; DAVY M, 2002, SIGNAL PROCESS LETT, V9; DAVY M, 2002, IEEE ICASSP 02 ORL U; DESOBRY F, 2005, IEEE T SIGNAL PROCES, V53; DESOBRY F, 2003, IEEE ICASSP 03; Duda R.O, 1973, PATTERN CLASSIFICATI; Efron B., 1993, INTRO BOOTSTRAP; Godsill S. J., 1998, DIGITAL AUDIO RESTOR; GRETTON A, 2001, BOUND LEAVE ONE OUT; GRETTON A, 2003, THEISIS U CAMBRIDGE; HAYTON P, 2000, NIPS 2000; Herbrich R., 2002, LEARNING KERNEL CLAS; KIVINEN J, 2004, IEEE T SIGNAL PROCES, V58; KIVINEN J, 2002, ADV NEURAL INFORM PR, V14; KIVINEN J, 2004, IEEE ICASSP 02 ORL U, V58; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Manevitz L., 2001, J MACHINE LEARNING R, V2, P139; Mangina EE, 2001, IEEE T POWER SYST, V16, P396, DOI 10.1109/59.932274; RAETSCH G, 2002, IEEE T PATTERN ANAL, V24, P1184; SCHOELKOPF B, 1999, TR87 MICR RES; Schoen RR, 1995, IEEE T IND APPL, V31, P1274, DOI 10.1109/28.475697; Silverman B.W., 1986, DENSITY ESTIMATION S; SMITH N, 2002, IEEE ICASSP 02 ORL U; SMITH N, 2001, CUEDFINFENGTR387 U C; Smola A., 2002, LEARNING KERNELS; TALLAM RM, 2002, IEEE T POWER ELECT, V17; VAN HL, 1968, DETECTION ESTIMATION; Vapnik V. N, 1995, NATURE STAT LEARNING; VISHWANATHAN SVN, 2003, ICML	33	25	28	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684		SIGNAL PROCESS	Signal Process.	AUG	2006	86	8					2009	2025		10.1016/j.sigpro.2005.09.027		17	Engineering, Electrical & Electronic	Engineering	057ZV	WOS:000238634700021	
J	Mucientes, M; Moreno, DL; Bugarin, A; Barro, S				Mucientes, M; Moreno, DL; Bugarin, A; Barro, S			Evolutionary learning of a fuzzy controller for wall-following behavior in mobile robotics	SOFT COMPUTING			English	Article						evolutionary algorithms; fuzzy control; mobile robotics; wall-following behavior	GENETIC ALGORITHMS; NAVIGATION; SYSTEMS; RULES	The design of fuzzy controllers for the implementation of behaviors in mobile robotics is a complex and highly time-consuming task. The use of machine learning techniques such as evolutionary algorithms or artificial neural networks for the learning of these controllers allows to automate the design process. In this paper, the automated design of a fuzzy controller using genetic algorithms for the implementation of the wall-following behavior in a mobile robot is described. The algorithm is based on the iterative rule learning approach, and is characterized by three main points. First, learning has no restrictions neither in the number of membership functions, nor in their values. In the second place, the training set is composed of a set of examples uniformly distributed along the universe of discourse of the variables. This warrantees that the quality of the learned behavior does not depend on the environment, and also that the robot will be capable to face different situations. Finally, the trade off between the number of rules and the quality/accuracy of the controller can be adjusted selecting the value of a parameter. Once the knowledge base has been learned, a process for its reduction and tuning is applied, increasing the cooperation between rules and reducing its number.	Univ Santiago de Compostela, Dept Elect & Comp Sci, Santiago De Compostela 15782, Spain	Mucientes, M (reprint author), Univ Santiago de Compostela, Dept Elect & Comp Sci, Santiago De Compostela 15782, Spain.	manuel@dec.usc.es; dave@dec.usc.es; alberto@dec.usc.es; senen@dec.usc.es	Bugarin Diz, Alberto/B-4268-2009				Arrue BC, 1997, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I - III, P1239, DOI 10.1109/FUZZY.1997.619465; Baker J.E., 1987, P 2 INT C GEN ALG, P14; BRAUNSTINGL R, 1995, P FUZZ IEEE 95, V5, P77, DOI 10.1109/FUZZY.1995.410047; Carse B, 1996, FUZZY SET SYST, V80, P273, DOI 10.1016/0165-0114(95)00196-4; Cordon O, 2001, FUZZY SET SYST, V118, P235, DOI 10.1016/S0165-0114(98)00349-2; Cordon O., 2001, GENETIC FUZZY SYSTEM, V19; Cordon O, 2001, IEEE T FUZZY SYST, V9, P667, DOI 10.1109/91.940977; Herrera F, 1997, FUZZY SET SYST, V92, P21, DOI 10.1016/S0165-0114(96)00179-0; Herrera F, 1998, FUZZY SET SYST, V100, P143, DOI 10.1016/S0165-0114(97)00043-2; IGLESIAS R, 1998, LECT NOTES COMPUTER, V2, P300; LEITCH D, 1996, STUDIES FUZZINESS SO, V8, P306; MAGDALENA L, 1996, STUDIES FUZZINESS, V8, P172; MENDEL JM, 1995, P IEEE, V83, P345, DOI 10.1109/5.364485; MUCIENTES M, 2003, FUZZY SYSTEMS, V2, P373; Mucientes M, 2003, FUZZY SET SYST, V134, P83, DOI 10.1016/S0165-0114(02)00231-2; Mucientes M, 2001, IEEE T SYST MAN CY C, V31, P391, DOI 10.1109/5326.971667; Ng KC, 1998, IEEE T SYST MAN CY B, V28, P829, DOI 10.1109/3477.735392; Pedrycz W., 1996, FUZZY MODELLING PARA, P265; Pratihar DK, 1999, INT J APPROX REASON, V20, P145, DOI 10.1016/S0888-613X(98)10026-9; Urzelai J, 1997, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I - III, P1361, DOI 10.1109/FUZZY.1997.619742	20	8	8	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	AUG	2006	10	10					881	889		10.1007/s00500-005-0014-x		9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	047CO	WOS:000237857600003	
J	Hong, TP; Lin, KY; Wang, SL				Hong, TP; Lin, KY; Wang, SL			Mining fuzzy sequential patterns from quantitative transactions	SOFT COMPUTING			English	Article						data mining; fuzzy set; quantitative data; sequential pattern; transaction	MEMBERSHIP FUNCTIONS; INDUCTION; ATTRIBUTES; SYSTEMS; RULES	Many researchers in database and machine learning fields are primarily interested in data mining because it offers opportunities to discover useful information and important relevant patterns in large databases. Most previous studies have shown how binary valued transaction data may be handled. Transaction data in real-world applications usually consist of quantitative values, so designing a sophisticated data-mining algorithm able to deal with various types of data presents a challenge to workers in this research field. In the past, we proposed a fuzzy data-mining algorithm to find association rules. Since sequential patterns are also very important for real-world applications, this paper thus focuses on finding fuzzy sequential patterns from quantitative data. A new mining algorithm is proposed, which integrates the fuzzy-set concepts and the AprioriAll algorithm. It first transforms quantitative values in transactions into linguistic terms, then filters them to find sequential patterns by modifying the AprioriAll mining algorithm. Each quantitative item uses only the linguistic term with the maximum cardinality in later mining processes, thus making the number of fuzzy regions to be processed the same as the number of the original items. The patterns mined out thus exhibit the sequential quantitative regularity in databases and can be used to provide some suggestions to appropriate supervisors.	Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung 811, Taiwan; Chunghwa Telecom Lab, Taoyuan 320, Taiwan; New York Inst Technol, Dept Comp Sci, Old Westbury, NY USA	Hong, TP (reprint author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung 811, Taiwan.	tphong@nuk.edu.tw; ying120@cht.com.tw; slwang@nyit.edu					Agrawal R., 1995, 11 INT C DAT ENG, P3; AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; Agrawal R., 1994, INT C VER LARG DAT B, P487; Agrawal R., 1993, ACM SIGMOD INT C MAN, P207; BLISHUN AF, 1987, FUZZY SET SYST, V22, P57, DOI 10.1016/0165-0114(87)90006-6; CHANG RLP, 1977, IEEE T SYST MAN CYB, V7, P28, DOI 10.1109/TSMC.1977.4309586; CLAIR C, 1998, 7 INT C INF KNOWL MA, P259; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; DECAMPOS LM, 1993, FUZZY SET SYST, V59, P247, DOI 10.1016/0165-0114(93)90470-3; DELGADO M, 1993, FUZZY SET SYST, V55, P121, DOI 10.1016/0165-0114(93)90125-2; Frawley WJ, 1991, AAAI WORKSH KNOWL DI, P1; GONZALEZ A, 1995, INT J INTELL SYST, V10, P57; Graham I., 1988, EXPERT SYSTEMS KNOWL, P117; Hong TP, 1996, FUZZY SET SYST, V84, P33, DOI 10.1016/0165-0114(95)00305-3; Hong TP, 1997, IEEE T KNOWL DATA EN, V9, P336; Hong TP, 1999, FUZZY SET SYST, V103, P389; Hong TP, 2000, FUZZY SET SYST, V112, P127, DOI 10.1016/S0165-0114(98)00179-1; Hou RH, 1997, J AUTOM REASONING, V18, P5, DOI 10.1023/A:1005726727996; Kandel A, 1992, FUZZY EXPERT SYSTEMS, P8; Mamdani E.H., 1974, IEEE P, P1585; MANNILA H, 1997, INT C DAT THEOR, P41; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1987, 4 INT MACH LEARN WOR, P31; RIVES J, 1990, 1 INT S UNC MOD AN, P457; SRIKANT R, 1997, 3 INT C KNOWL DISC D, P67; Srikant R., 1996, 1996 ACM SIGMOD INT, P1; WANG CH, 1996, 5 IEEE INT C FUZZ SY, P13; Wang Y, 1999, FUZZY SET SYST, V103, P1, DOI 10.1016/S0165-0114(97)00196-6; Weber R., 1992, 2 INT C FUZZ LOG NEU, P265; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z; Zadeh LA, 1988, IEEE COMPUT, V21, P83; Zimmermann H.-J, 1991, FUZZY SET THEORY ITS	32	10	10	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	AUG	2006	10	10					925	932		10.1007/s00500-005-0018-6		8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	047CO	WOS:000237857600007	
J	Rao, AN; Rithesh, S; Sarbadhikari, SN				Rao, A. N.; Rithesh, S.; Sarbadhikari, S. N.			Comparing the efficacies of some supervised machine learning algorithms for screening inborn errors of metabolism	JOURNAL OF INHERITED METABOLIC DISEASE			English	Meeting Abstract									Amrita Vishwa Vidyapeetham, Ctr Excellence Computat Engn & Networking, Coimbatore, Tamil Nadu, India; Amrita Vishwa Vidyapeetham, TIFAC CORE Biomed Technol, Kollam 690525, India								0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0141-8955		J INHERIT METAB DIS	J. Inherit. Metab. Dis.	AUG	2006	29			1			55	55				1	Endocrinology & Metabolism; Genetics & Heredity	Endocrinology & Metabolism; Genetics & Heredity	083OC	WOS:000240467100194	
J	Wilbur, WJ; Rzhetsky, A; Shatkay, H				Wilbur, W. John; Rzhetsky, Andrey; Shatkay, Hagit			New directions in biomedical text annotation: definitions, guidelines and corpus construction	BMC BIOINFORMATICS			English	Article							INFORMATION-RETRIEVAL; DISCOVERY; GENE; KNOWLEDGE	Background: While biomedical text mining is emerging as an important research area, practical results have proven difficult to achieve. We believe that an important first step towards more accurate text-mining lies in the ability to identify and characterize text that satisfies various types of information needs. We report here the results of our inquiry into properties of scientific text that have sufficient generality to transcend the confines of a narrow subject area, while supporting practical mining of text for factual information. Our ultimate goal is to annotate a significant corpus of biomedical text and train machine learning methods to automatically categorize such text along certain dimensions that we have defined. Results: We have identified five qualitative dimensions that we believe characterize a broad range of scientific sentences, and are therefore useful for supporting a general approach to text-mining: focus, polarity, certainty, evidence, and directionality. We define these dimensions and describe the guidelines we have developed for annotating text with regard to them. To examine the effectiveness of the guidelines, twelve annotators independently annotated the same set of 101 sentences that were randomly selected from current biomedical periodicals. Analysis of these annotations shows 70-80% inter-annotator agreement, suggesting that our guidelines indeed present a well-defined, executable and reproducible task. Conclusion: We present our guidelines defining a text annotation task, along with annotation results from multiple independently produced annotations, demonstrating the feasibility of the task. The annotation of a very large corpus of documents along these guidelines is currently ongoing. These annotations form the basis for the categorization of text along multiple dimensions, to support viable text mining for experimental results, methodology statements, and other forms of information. We are currently developing machine learning methods, to be trained and tested on the annotated corpus, that would allow for the automatic categorization of biomedical text along the general dimensions that we have presented. The guidelines in full detail, along with annotated examples, are publicly available.	NIH, Natl Ctr Biotechnol Informat, Natl Lib Med, Bethesda, MD 20892 USA; Columbia Univ, Judith P Sulzberger MD Columbia Genome Ctr, Ctr Computat Biol & Bioinformat, Dept Biomed Informat, New York, NY 10027 USA; Columbia Univ, Dept Biol, New York, NY 10027 USA; Queens Univ, Sch Comp, Kingston, ON K7L 3N6, Canada	Wilbur, WJ (reprint author), NIH, Natl Ctr Biotechnol Informat, Natl Lib Med, Bldg 10, Bethesda, MD 20892 USA.	wilbur@ncbi.nlm.nih.gov; ar345@columbia.edu; shatkay@cs.queensu.ca	rzhetsky, andrey/B-6118-2012				BARUCH JJ, 1965, ANN NY ACAD SCI, V126, P795, DOI 10.1111/j.1749-6632.1965.tb14324.x; CHOI Y, 2005, HUMAN LANGUAGE TECHN, P355; Cohen K.B., 2005, ACL ISMB WORKSHOP LI, P38; COHEN KB, 2005, AI SYSTEMS BIOL; Craven M, 1999, Proc Int Conf Intell Syst Mol Biol, P77; de Bruijn B, 2002, INT J MED INFORM, V67, P7, DOI 10.1016/S1386-5056(02)00050-3; ENGSTROM C, 2004, TOPIC DEPENDENCE SEN; Eskin E, 2004, Pac Symp Biocomput, P288; FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161; Friedman C, 2001, Bioinformatics, V17 Suppl 1, pS74; GAMON M, 2005, ACL WORKSHOP FEATURE, P57; Glenisson P, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-6-r43; HERSH W, 2004, MEDINFO, V11, P773; Jensen LJ, 2006, NAT REV GENET, V7, P119, DOI 10.1038/nrg1768; Kim JD, 2003, BIOINFORMATICS, V19, pi180, DOI 10.1093/bioinformatics/btg1023; Krallinger M, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-7-224; Krauthammer Michael, 2002, Bioinformatics, V18 Suppl 1, pS249; LANGER H, 2004, ACL WORKSHOP DISCOUR; Leek TR, 1997, INFORM EXTRACTION US; Light M, 2004, HLT NACACL BIOLINK 0, P17; Mann W. C., 1987, Natural Language Generation: New Results in Artificial Intelligence, Psychology and Linguistics. Proceedings of the NATO Advanced Research Workshop; McKnight Larry, 2003, AMIA Annu Symp Proc, P440; McNaught J, 2006, TEXT MINING BIOL BIO; MIZUTA Y, 2005, ZONE ANAL SCI ARTICL; MIZUTA Y, 2004, JOINT WORKSH NAT LAN, P29; MIZUTA Y, 2005, INT J MED INFORM; Mukherjea S, 2005, BRIEF BIOINFORM, V6, P252, DOI 10.1093/bib/6.3.252; PANG B, 2004, ACL 2004, P217; READ J, 2005, ACL STUDENT RES WORK, P43; Rindflesch T C, 1994, Proc Annu Symp Comput Appl Med Care, P240; Saracevic T, 1991, P 54 ANN M AM SOC IN, P82; Scherf M, 2005, BRIEF BIOINFORM, V6, P287, DOI 10.1093/bib/6.3.287; Shatkay H, 2003, J COMPUT BIOL, V10, P821, DOI 10.1089/106652703322756104; Shatkay H, 2005, BRIEF BIOINFORM, V6, P222, DOI 10.1093/bib/6.3.222; SHATKAY H, 2000, INTELLIGENT SYSTEMS, P317; Skusa A, 2005, BRIEF BIOINFORM, V6, P263, DOI 10.1093/bib/6.3.263; Spasic I, 2005, BRIEF BIOINFORM, V6, P239, DOI 10.1093/bib/6.3.239; SWANSON DR, 1989, J AM SOC INFORM SCI, V40, P356, DOI 10.1002/(SICI)1097-4571(198909)40:5<356::AID-ASI9>3.0.CO;2-B; Tanabe L, 1999, BIOTECHNIQUES, V27, P1210; Tanabe L, 1999, BIOTECHNIQUES, V27, P1216; Tanabe L, 2002, BIOINFORMATICS, V18, P1124, DOI 10.1093/bioinformatics/18.8.1124; TEUFEL S, 1999, EACL 1999; UEBERSAX JS, 1987, PSYCHOL BULL, V101, P140, DOI 10.1037/0033-2909.101.1.140; Weeber M, 2005, BRIEF BIOINFORM, V6, P277, DOI 10.1093/bib/6.3.277; Wilson T., 2005, HLT 05, P347; Wilson T., 2005, HLT EMNLP, P34	46	34	34	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JUL 25	2006	7								356	10.1186/1471-2105-7-356		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	080GR	WOS:000240236400001	
J	Ren, YY; Liu, HX; Xue, CX; Yao, XJ; Liu, MC; Fan, BT				Ren, Yueying; Liu, Huanxiang; Xue, Chunxia; Yao, Xiaojun; Liu, Mancang; Fan, Botao			Classification study of skin sensitizers based on support vector machine and linear discriminant analysis	ANALYTICA CHIMICA ACTA			English	Article						classification; skin sensitization; linear discriminant analysis; support vector machine	LYMPH-NODE ASSAY; REACTIVITY; POTENCY; BINDING; DEREK	The support vector machine (SVM), recently developed from machine learning community, was used to develop a nonlinear binary classification model of skin sensitization for a diverse set of 131 organic compounds. Six descriptors were selected by stepwise forward discriminant analysis (LDA) from a diverse set of molecular descriptors calculated from molecular structures alone. These six descriptors could reflect the mechanic relevance to skin sensitization and were used as inputs of the SVM model. The nonlinear model developed from SVM algorithm outperformed LDA, which indicated that SVM model was more reliable in the recognition of skin sensitizers. The proposed method is very useful for the classification of skin sensitizers, and can also be extended in other QSAR investigation. (c) 2006 Elsevier B.V. All rights reserved.	Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China; Chinese Acad Sci, Shanghai Inst Mat Med, Shanghai 201203, Peoples R China; Univ Paris 07, ITODYS, F-75005 Paris, France	Yao, XJ (reprint author), Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China.	xjyao@lzu.edu.cn					Aptula AO, 2005, CHEM RES TOXICOL, V18, P324, DOI 10.1021/tx049718w; Aptula AO, 2005, CHEM RES TOXICOL, V18, P1420, DOI 10.1021/tx050075m; BASKETTER DA, 1992, CONTACT DERMATITIS, V27, P137, DOI 10.1111/j.1600-0536.1992.tb05241.x; BENABLES WND, 2003, R DEV CORE TEAM R MA; Bishop C., 1997, NEURAL NETWORKS PATT; Burges C, 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; CAMPBELL C, 2000, ESANN2000 P EUR S AR, P27; EFRON B, 1993, INTRO BOOTSTRAP, P239; Elahi EN, 2004, CHEM RES TOXICOL, V17, P301, DOI 10.1021/tx0341456; Estrada E, 2004, J CHEM INF COMP SCI, V44, P688, DOI 10.1021/ci0342425; ESTRADA E, 2003, CHEM RES TOXICOL, V16, P226; Fedorowicz A, 2005, CHEM RES TOXICOL, V18, P954, DOI 10.1021/tx0497806; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Gerberick GF, 2004, CONTACT DERMATITIS, V50, P274, DOI 10.1111/j.0105-1873.2004.00290.x; Griem P, 2003, REGUL TOXICOL PHARM, V38, P269, DOI 10.1016/j.yrtph.2003.07.001; JENNRICH R, 1979, BMD BIOMEDICAL COMPU; KATRITZKY AR, 1995, CODESSA VERSION 2 0; KIMBER I, 1992, FOOD CHEM TOXICOL, V30, P165, DOI 10.1016/0278-6915(92)90153-C; Li SQ, 2005, J CHEM INF MODEL, V45, P952, DOI 10.1021/ci050049u; Liu HX, 2003, J CHEM INF COMP SCI, V43, P900, DOI 10.1021/ci0256438; Luan F, 2005, CHEM RES TOXICOL, V18, P198, DOI 10.1021/tx049782q; MAJETI VA, 1977, CONTACT DERMATITIS, V3, P16, DOI 10.1111/j.1600-0536.1977.tb03581.x; Meschkat E, 2001, CHEM RES TOXICOL, V14, P118, DOI 10.1021/tx000226f; Miller MD, 2005, J CHEM INF MODEL, V45, P924, DOI 10.1021/ci050018z; Muller KR, 2005, J CHEM INF MODEL, V45, P249, DOI 10.1021/ci049737o; Nikolova N., 2003, QSAR COMB SCI, V22, P1006, DOI DOI 10.1186/1471-2121-8-S1-S6; Nilsson AM, 2005, CHEM RES TOXICOL, V18, P308, DOI 10.1021/tx049758c; Pichler WJ, 2003, ANN INTERN MED, V139, P683; Richard Ann M., 1998, Toxicology Letters (Shannon), V102-103, P611, DOI 10.1016/S0378-4274(98)00257-4; RUBEN AS, 2004, CHEM RES TOXICOL, V17, P1280; SANDERSON DM, 1991, HUM EXP TOXICOL, V10, P261; Serra JR, 2003, CHEM RES TOXICOL, V16, P153, DOI 10.1021/tx020077w; Skold M, 2004, CHEM RES TOXICOL, V17, P1697, DOI 10.1021/tx049831z; Stewart J. P. P., 1989, MOPAC 6 0 QUANTUM CH; Surges C.J.C., 1998, TUTORIAL SUPPORT VEC; [Anonymous], 1990, ISIS DRAW2 3; *HYPE INC, 1995, HYP REL 4 0 WIND	37	18	19	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA	Anal. Chim. Acta	JUL 21	2006	572	2					272	282		10.1016/j.aca.2006.05.027		11	Chemistry, Analytical	Chemistry	066MX	WOS:000239234900016	
J	Moore, JH; Gilbert, JC; Tsai, CT; Chiang, FT; Holden, T; Barney, N; White, BC				Moore, Jason H.; Gilbert, Joshua C.; Tsai, Chia-Ti; Chiang, Fu-Tien; Holden, Todd; Barney, Nate; White, Bill C.			A flexible computational framework for detecting, characterizing, and interpreting statistical patterns of epistasis in genetic studies of human disease susceptibility	JOURNAL OF THEORETICAL BIOLOGY			English	Article						gene-gene interactions; constructive induction; multifactor dimensionality reduction; entropy; machine learning; data mining	MULTIFACTOR-DIMENSIONALITY REDUCTION; DRIVEN CONSTRUCTIVE INDUCTION; RENIN-ANGIOTENSIN SYSTEM; GENOME-WIDE ASSOCIATION; COMPUTER-SIMULATIONS; COMPLEX DISEASES; COMMON DISEASES; HYPERTENSION; TRAITS; OPTIMIZATION	Detecting, characterizing, and interpreting gene-gene interactions or epistasis in studies of human disease susceptibility is both a mathematical and a computational challenge. To address this problem, we have previously developed a multifactor dimensionality reduction (MDR) method for collapsing high-dimensional genetic data into a single dimension (i.e. constructive induction) thus permitting interactions to be detected in relatively small sample sizes. In this paper, we describe a comprehensive and flexible framework for detecting and interpreting gene-gene interactions that utilizes advances in information theory for selecting interesting single-nucleotide polymorphisms (SNPs), MDR for constructive induction, machine learning methods for classification, and finally graphical models for interpretation. We illustrate the usefulness of this strategy using artificial datasets simulated from several different two-locus and three-locus epistasis models. We show that the accuracy, sensitivity, specificity, and precision of a naive Bayes classifier are significantly improved when SNPs are selected based on their information gain (i.e. class entropy removed) and reduced to a single attribute using MDR. We then apply this strategy to detecting, characterizing, and interpreting epistatic models in a genetic study (n = 500) of atrial fibrillation and show that both classification and model interpretation are significantly improved. (c) 2005 Elsevier Ltd. All rights reserved.	Dartmouth Hitchcock Med Ctr, Dept Genet, Computat Gen Lab, Lebanon, NH 03756 USA; Dartmouth Coll Sch Med, Dept Community & Family Med, Lebanon, NH USA; Dartmouth Coll, Dept Biol Sci, Hanover, NH 03755 USA; Univ New Hampshire, Dept Comp Sci, Durham, NH 03824 USA; Univ Vermont, Dept Comp Sci, Burlington, VT USA; Natl Taiwan Univ Hosp, Dept Internal Med, Div Cardiol, Taipei, Taiwan	Moore, JH (reprint author), Dartmouth Hitchcock Med Ctr, Dept Genet, Computat Gen Lab, 1 Med Ctr Dr,706 Rubin Bldg,HB7937, Lebanon, NH 03756 USA.	jason.h.moore@dartmouth.edu					Bateson W, 1909, MENDELS PRINCIPLES H; Bloedorn E, 1998, IEEE INTELL SYST APP, V13, P30, DOI 10.1109/5254.671089; Brodie Edmund D. III, 2000, P3; Cho YM, 2004, DIABETOLOGIA, V47, P549, DOI 10.1007/s00125-003-1321-3; COFFEY CS, 2004, BMC BIOINFORMATICS, V4, P49; Cordell HJ, 2001, GENETICS, V158, P357; CORDELL HJ, 1995, AM J HUM GENET, V57, P920; COX N, 1999, NAT GENET, V2, P213; Cox NJ, 2004, DIABETES, V53, pS19, DOI 10.2337/diabetes.53.2007.S19; Curk T, 2005, BIOINFORMATICS, V21, P396, DOI 10.1093/bioinformatics/bth474; Fisher R. A., 1918, T ROY SOC EDINBURGH, V52, P399; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Gibson G, 2000, BIOESSAYS, V22, P372, DOI 10.1002/(SICI)1521-1878(200004)22:4<372::AID-BIES7>3.0.CO;2-J; Goldberg D. E., 1998, GENETIC ALGORITHMS S; Good P., 2000, PERMUTATION TESTS PR; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; Hahn Lance W, 2004, In Silico Biol, V4, P183; Hastie T, 2001, ELEMENTS STAT LEARNI; Hirschhorn JN, 2005, NAT REV GENET, V6, P95, DOI 10.1038/nrg1521; Hoh J, 2004, CURR OPIN GENET DEV, V14, P229, DOI 10.1016/j.gde.2004.04.006; HOLLANDER W. F., 1955, JOUR HEREDITY, V46, P222; HU YJ, 1998, FEATURE EXTRACTION C, P257; Jakulin A, 2003, LECT NOTES ARTIF INT, V2838, P229; Jakulin A, 2003, LECT NOTES ARTIF INT, V2780, P229; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LENAT DB, 1983, MACHINE LEARNING ART; LENAT DB, 1997, MACHINE INTELLIGENCE, V9; Li WT, 2000, HUM HERED, V50, P334, DOI 10.1159/000022939; Marchini J, 2005, NAT GENET, V37, P413, DOI 10.1038/ng1537; McGill W.J., 1954, PSYCHOMETRIKA, V9, P97; Michalewicz Z., 2000, SOLVE IT MODERN HEUR; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Mitchell T, 1997, MACHINE LEARNING; Moore JH, 2002, ANN MED, V34, P88, DOI 10.1080/07853890252953473; Moore JH, 2004, JAMA-J AM MED ASSOC, V291, P1642, DOI 10.1001/jama.291.13.1642; Moore JH, 2005, MOL GENET METAB, V84, P104, DOI 10.1016/j.ymgme.2004.10.006; Moore JH, 2004, EXPERT REV MOL DIAGN, V4, P795, DOI 10.1586/14737159.4.6.795; Moore JH, 2005, NAT GENET, V37, P13, DOI 10.1038/ng0105-13; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Moore JH, 2005, BIOESSAYS, V27, P637, DOI 10.1002/bias.20236; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Page GP, 2003, AM J HUM GENET, V73, P711, DOI 10.1086/378900; Phillips PC, 1998, GENETICS, V149, P1167; Pierce J. R., 1980, INTRO INFORM THEORY; Proulx SR, 2005, AM NAT, V165, P147, DOI 10.1086/426873; Qin SY, 2005, EUR J HUM GENET, V13, P807, DOI 10.1038/sj.ejhg.5201418; Ritchie MD, 2004, LECT NOTES COMPUT SC, V3102, P438; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Ritchie MD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-28; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Segre D, 2005, NAT GENET, V37, P77, DOI 10.1038/ng1489; Sing CF, 2003, ARTERIOSCL THROM VAS, V23, P1190, DOI 10.1161/01.ATV.0000075081.51227.86; Soares ML, 2005, HUM MOL GENET, V14, P543, DOI 10.1093/hmg/ddi051; Takahashi N, 2004, TRENDS GENET, V20, P136, DOI 10.1016/j.tig.2004.01.004; Takahashi N, 2003, ENDOCRINOLOGY, V144, P2184, DOI 10.1210/en.2002-221045; Templeton A. R., 2000, EPISTASIS EVOLUTIONA, P41; Thornton-Wells TA, 2004, TRENDS GENET, V20, P640, DOI 10.1016/j.tig.2004.09.007; Tsai CT, 2004, CIRCULATION, V109, P1640, DOI 10.1161/01.CIR.0000124487.36586.26; Waddington C. H., 1957, STRATEGY GENES; Waddington CH, 1942, NATURE, V150, P563, DOI 10.1038/150563a0; Wade MJ, 2001, GENETICA, V112, P59, DOI 10.1023/A:1013316611768; Wang WYS, 2005, NAT REV GENET, V6, P109, DOI 10.1038/nrg1522; Wilke RA, 2005, PHARMACOGENET GENOM, V15, P415, DOI 10.1097/01213011-200506000-00007; Wilke RA, 2005, NAT REV DRUG DISCOV, V4, P911, DOI 10.1038/nrd1874; Williams SM, 2004, HUM HERED, V57, P28, DOI 10.1159/000077387; Witten I. H., 2000, DATA MINING; WNEK J, 1994, MACH LEARN, V14, P139, DOI 10.1023/A:1022622132310; Xu JF, 2005, CANCER EPIDEM BIOMAR, V14, P2563, DOI 10.1158/1055-9965.EPI-05-0356; Zupan B, 1998, IEEE INTELL SYST APP, V13, P38, DOI 10.1109/5254.671090	70	212	219	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193		J THEOR BIOL	J. Theor. Biol.	JUL 21	2006	241	2					252	261		10.1016/j.jtbi.2005.11.036		10	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	072RS	WOS:000239691300009	
J	Si, HZ; Wang, T; Zhang, KJ; Hu, ZD; Fan, BT				Si, HZ; Wang, T; Zhang, KJ; Hu, ZD; Fan, BT			QSAR study of 1,4-dihydropyridine calcium channel antagonists based on gene expression programming	BIOORGANIC & MEDICINAL CHEMISTRY			English	Article						QSAR; calcium channel antagonists; gene expression programming	NEURAL-NETWORKS; ALGORITHM; DERIVATIVES; SELECTION	The gene expression programming, a novel machine learning algorithm, is used to develop quantitative model as a potential screening mechanism for a series of 1,4-dihydropyridine calcium channel antagonists for the first time. The heuristic method was used to search the descriptor space and select the descriptors responsible for activity. A nonlinear, six-descriptor model based on gene expression programming with mean-square errors 0.19 was set up with a predicted correlation coefficient (R-2) 0.92. This paper provides a new and effective method for drug design and screening. (c) 2006 Elsevier Ltd. All rights reserved.	Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China; Ctr Dis Control Gansu Prov, Lanzhou 730020, Peoples R China; Lanzhou Univ, First Hosp, Clin Lab, Lanzhou 730000, Peoples R China; JUST, Sch Mech & Elect Engn, Ganzhou 341000, Peoples R China; Univ Paris 07, ITODYS, F-75005 Paris, France	Si, HZ (reprint author), Lanzhou Univ, Dept Chem, Lanzhou 730000, Peoples R China.	sihz03@st.lzu.edu.cn					ALICE B, 2005, BIOORGAN MED CHEM, V13, P5330; Ana BB, 2006, FORENSIC SCI INT, V156, P23; ANDREI IK, 2006, BIOORG MEC CHEM, V14, P352; Baykasoglu A, 2004, CEMENT CONCRETE RES, V34, P2083, DOI 10.1016/j.cemconres.2004.03.028; CLARE BW, 1994, THEOR CHIM ACTA, V87, P415, DOI 10.1007/BF01127805; Costa MCA, 1997, J MOL STRUC-THEOCHEM, V394, P291, DOI 10.1016/S0166-1280(96)04845-2; Csizmadia I.G., 1976, THEORY PRACTICE MO C; FERREIRA C, 2002, GENE EXPRESSION PROG, P635; FERREIRA C, 2001, COMPLEX SYSTEMS, V13, P210; GODFRAIND T, 1997, J CARDIOVASC PHAR S2, V30, pS1; Hemmateenejad B, 2002, CHEMOMETR INTELL LAB, V64, P91, DOI 10.1016/S0169-7439(02)00068-0; Hemmateenejad B, 2003, J CHEM INF COMP SCI, V43, P1328, DOI 10.1021/ci025661p; Karelson M, 2000, MOL DESCRIPTORS QSAR; Katritzky A.R., 1994, REFERENCE MANUAL VER; KIYOSHI H, 1997, J CHEM INF COMP SCI, V37, P306; Li W, 2006, BIOORGAN MED CHEM, V14, P601, DOI 10.1016/j.bmc.2005.08.052; Mitchell M, 1996, INTRO GENETIC ALGORI; Nayler WG, 1999, J CLIN BASIC CARDIOL, V2, P155; Ozlem T., 2005, J APPL SCI, V5, P508; ROHRBAUGH RH, 1987, ANAL CHIM ACTA, V199, P99, DOI 10.1016/S0003-2670(00)82801-9; Schleifer KJ, 2002, QUANT STRUCT-ACT REL, V21, P239, DOI 10.1002/1521-3838(200208)21:3<239::AID-QSAR239>3.0.CO;2-W; Takahata Y, 2003, J CHEM INF COMP SCI, V43, P540, DOI 10.1021/ci010117m; van Zwieten Pieter A., 1998, Blood Pressure, V7, P5, DOI 10.1080/080370598438483; Viswanadhan VN, 2001, J CHEM INF COMP SCI, V41, P505, DOI 10.1021/ci000072+; Yao XJ, 2005, MOL PHARMACEUT, V2, P348, DOI 10.1021/mp050027v; Zamponi GW, 2003, J MED CHEM, V46, P87, DOI 10.1021/jm020354w; 1974, HDB CHEM PHYS, pF112	27	23	25	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0968-0896		BIOORGAN MED CHEM	Bioorg. Med. Chem.	JUL 15	2006	14	14					4834	4841		10.1016/j.bmc.2006.03.019		8	Biochemistry & Molecular Biology; Chemistry, Medicinal; Chemistry, Organic	Biochemistry & Molecular Biology; Pharmacology & Pharmacy; Chemistry	058XV	WOS:000238698800014	
J	Baumes, LA; Serra, JM; Serna, P; Corma, A				Baumes, L. A.; Serra, J. M.; Serna, P.; Corma, A.			Support vector machines for predictive modeling in heterogeneous catalysis: A comprehensive introduction and overfitting investigation based on two real applications	JOURNAL OF COMBINATORIAL CHEMISTRY			English	Article							ARTIFICIAL NEURAL-NETWORKS; OXIDATIVE DEHYDROGENATION; COMBINATORIAL METHODS; EVOLUTIONARY APPROACH; METHANOL SYNTHESIS; OPTIMIZATION; DESIGN; DISCOVERY; LIBRARIES; CLASSIFICATION	This works provides an introduction to support vector machines (SVMs) for predictive modeling in heterogeneous catalysis, describing step by step the methodology with a highlighting of the points which make such technique an attractive approach. We first investigate linear SVMs, working in detail through a simple example based on experimental data derived from a study aiming at optimizing olefin epoxidation catalysts applying high-throughput experimentation. This case study has been chosen to underline SVM features in a visual manner because of the few catalytic variables investigated. It is shown how SVMs transform original data into another representation space of higher dimensionality. The concepts of Vapnik-Chervonenkis dimension and structural risk minimization are introduced. The SVM methodology is evaluated with a second catalytic application, that is, light paraffin isomerization. Finally, we discuss why SVMs is a strategic method, as compared to other machine learning techniques, such as neural networks or induction trees, and why emphasis is put on the problem of overfitting.	Univ Politecn Valencia, CSIC, Inst Tecnol Quim, Valencia 46022, Spain	Corma, A (reprint author), Univ Politecn Valencia, CSIC, Inst Tecnol Quim, Av Naranjos S-N, Valencia 46022, Spain.		Serra, Jose/C-8244-2009; CORMA CANOS, AVELINO/A-3040-2013; baumes, laurent/E-2175-2013	Serra, Jose/0000-0002-1515-1106; baumes, laurent/0000-0001-9363-9089			Bauman Z., 2001, J CONSUM CULT, V1, P9; Baumes L, 2004, QSAR COMB SCI, V23, P767, DOI 10.1002/qsar.200430900; BAUMES LA, 2005, INT C EUR CAT 7; Baumes LA, 2006, J COMB CHEM, V8, P304, DOI 10.1021/cc050130+; BAUMES LA, 2003, LECT NOTES AI LNCS L; Bishop C.M., 1995, NEURAL NETWORKS PATT; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burello E, 2005, ADV SYNTH CATAL, V347, P803, DOI 10.1002/adsc.200404363; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Buyevskaya OV, 2001, CATAL TODAY, V67, P369, DOI 10.1016/S0920-5861(01)00329-7; Buyevskaya OV, 2000, CATAL TODAY, V62, P91, DOI 10.1016/S0920-5861(00)00411-9; Catlett J., 1991, THESIS U SYDNEY AUST; Cestnik B, 1987, PROGR MACHINE LEARNI, P31; CHAUCHAT JH, 2001, DATA MINING MARKETIN, P1; CHENG J, 5 INT C MACHINE LEAR, P100; Corma A, 2002, NATO SCI SER II-MATH, V69, P153; Corma A, 1998, CHEM COMMUN, P1899, DOI 10.1039/a804801k; CORMA A, 2005, J CATAL, V25, P459; CORMA A, 1991, PROCESS OBTAINMENT L; Corma A, 2003, J CATAL, V216, P298, DOI 10.1016/S0021-9517(02)00132-X; Corma A, 2002, CHEMPHYSCHEM, V3, P939, DOI 10.1002/1439-7641(20021115)3:11<939::AID-CPHC939>3.0.CO;2-E; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Efron B., 1993, INTRO BOOTSTRAP; Farrusseng D, 2005, QSAR COMB SCI, V24, P78, DOI 10.1002/qsar.200420066; Fletcher R., 1987, PRACTICAL METHODS OP; Friedman J., 1994, STAT NEURAL NETWORKS, P1; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Goutte C, 1997, NEURAL COMPUT, V9, P1211; Grubert G, 2003, CATAL TODAY, V81, P337, DOI 10.1016/S0920-5861(03)00132-9; Hagemeyer A, 2001, APPL CATAL A-GEN, V221, P23, DOI 10.1016/S0926-860X(01)00886-9; Hjorth JSU, 1994, COMPUTER INTENSIVE S; Holena M, 2003, CATAL TODAY, V81, P485, DOI 10.1016/S0920-5861(03)00147-0; Jemwa GT, 2005, AICHE J, V51, P526, DOI 10.1002/aic.10315; Joachims T., 1999, MAKING LARGE SCALE S; JOACHIMS T., 2002, LEARNING CLASSIFY TE; Klanner C, 2003, QSAR COMB SCI, V22, P729, DOI 10.1002/qsar.200320003; Klanner C, 2004, ANGEW CHEM INT EDIT, V43, P5347, DOI 10.1002/anie.200460731; Liu HM, 2004, ANAL CHIM ACTA, V525, P31, DOI 10.1016/j.aca.2004.07.033; Liu HX, 2003, J CHEM INF COMP SCI, V43, P900, DOI 10.1021/ci0256438; Liu HX, 2004, J CHEM INF COMP SCI, V44, P161, DOI 10.1021/ci034173u; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MAIER WF, 2004, POLYM MAT SCI ENG, V90, P652; Malo N, 2006, NAT BIOTECHNOL, V24, P167, DOI 10.1038/nbt1186; Manallack DT, 1999, EUR J MED CHEM, V34, P195, DOI 10.1016/S0223-5234(99)80052-X; MCCORMICK GP, 1983, LINEAR PROGRAMMING T; Omata K, 2004, IND ENG CHEM RES, V43, P3282, DOI 10.1021/ie034173j; Pereira SRM, 2005, QSAR COMB SCI, V24, P45, DOI 10.1002/qsar.200420058; Plutowski M, 1994, ADV NEURAL INFORMATI, V6, P391; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RAKOTOMALALA R, 1997, P AIDRI 97; RAKOTOMALALA R, 1998, P INT C COMP SCI INF, P25; Senkan S, 2001, ANGEW CHEM INT EDIT, V40, P312, DOI 10.1002/1521-3773(20010119)40:2<312::AID-ANIE312>3.0.CO;2-I; Serra JM, 2003, APPL CATAL A-GEN, V239, P35, DOI 10.1016/S0926-860X(02)00371-X; Serra JM, 2003, CATAL TODAY, V81, P425, DOI 10.1016/S0920-5861(03)00142-1; Shao J., 1995, JACKKNIFE BOOTSTRAP; STONE M, 1977, BIOMETRIKA, V64, P29, DOI 10.1093/biomet/64.1.29; Tompos A, 2005, APPL CATAL A-GEN, V285, P65, DOI 10.1016/j.apcata.2005.02.019; Umegaki T, 2003, ENERG FUEL, V17, P850, DOI 10.1021/ef020241n; VAPNIK V, 1974, THEORY PATTERN TECOG; Vapnik V. N, 1995, NATURE STAT LEARNING; VAUTHEY I, 2002, EUR WORKSH COMB CAT; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Wolf D, 2002, NATO SCI SER II MATH, V69, P125; Wolf D, 2000, APPL CATAL A-GEN, V200, P63, DOI 10.1016/S0926-860X(00)00643-8; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1267, DOI 10.1021/ci049934n; Zhan YQ, 2005, PATTERN RECOGN, V38, P157, DOI 10.1016/j.patcog.2004.06.001; Zhang SW, 2003, BIOINFORMATICS, V19, P2390, DOI 10.1093/bioinformatics/btg331; ZIGHED DA, 2002, LECT NOTES ARTIF INT, V2431, P475; Zighed DA, 2005, APPL STOCH MODEL BUS, V21, P187, DOI 10.1002/asmb.532; ZIGHED DA, 1992, SIPINA METHODE LOGIC	71	24	25	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1520-4766		J COMB CHEM	J. Comb. Chem.	JUL 10	2006	8	4					583	596		10.1021/cc050093m		14	Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Chemistry; Pharmacology & Pharmacy	061CN	WOS:000238848900019	
J	Xu, H; Markatou, M; Dimova, R; Liu, HF; Friedman, C				Xu, Hua; Markatou, Marianthi; Dimova, Rositsa; Liu, Hongfang; Friedman, Carol			Machine learning and word sense disambiguation in the biomedical domain: design and evaluation issues	BMC BIOINFORMATICS			English	Article							INFORMATION	Background: Word sense disambiguation (WSD) is critical in the biomedical domain for improving the precision of natural language processing (NLP), text mining, and information retrieval systems because ambiguous words negatively impact accurate access to literature containing biomolecular entities, such as genes, proteins, cells, diseases, and other important entities. Automated techniques have been developed that address the WSD problem for a number of text processing situations, but the problem is still a challenging one. Supervised WSD machine learning (ML) methods have been applied in the biomedical domain and have shown promising results, but the results typically incorporate a number of confounding factors, and it is problematic to truly understand the effectiveness and generalizability of the methods because these factors interact with each other and affect the final results. Thus, there is a need to explicitly address the factors and to systematically quantify their effects on performance. Results: Experiments were designed to measure the effect of "sample size" (i.e. size of the datasets), "sense distribution" (i.e. the distribution of the different meanings of the ambiguous word) and "degree of difficulty" (i. e. the measure of the distances between the meanings of the senses of an ambiguous word) on the performance of WSD classifiers. Support Vector Machine (SVM) classifiers were applied to an automatically generated data set containing four ambiguous biomedical abbreviations: BPD, BSA, PCA, and RSV, which were chosen because of varying degrees of differences in their respective senses. Results showed that: 1) increasing the sample size generally reduced the error rate, but this was limited mainly to well- separated senses (i. e. cases where the distances between the senses were large); in difficult cases an unusually large increase in sample size was needed to increase performance slightly, which was impractical, 2) the sense distribution did not have an effect on performance when the senses were separable, 3) when there was a majority sense of over 90%, the WSD classifier was not better than use of the simple majority sense, 4) error rates were proportional to the similarity of senses, and 5) there was no statistical difference between results when using a 5- fold or 10-fold cross-validation method. Other issues that impact performance are also enumerated. Conclusion: Several different independent aspects affect performance when using ML techniques for WSD. We found that combining them into one single result obscures understanding of the underlying methods. Although we studied only four abbreviations, we utilized a well- established statistical method that guarantees the results are likely to be generalizable for abbreviations with similar characteristics. The results of our experiments show that in order to understand the performance of these ML methods it is critical that papers report on the baseline performance, the distribution and sample size of the senses in the datasets, and the standard deviation or confidence intervals. In addition, papers should also characterize the difficulty of the WSD task, the WSD situations addressed and not addressed, as well as the ML methods and features used. This should lead to an improved understanding of the generalizablility and the limitations of the methodology.	Columbia Univ, Dept Biomed Informat, New York, NY USA; Columbia Univ, Dept Biostat, New York, NY USA; Georgetown Univ, Med Ctr, Dept Biostat Bioinformat & Biomath, Washington, DC 20007 USA	Friedman, C (reprint author), Columbia Univ, Dept Biomed Informat, 622 168th St, New York, NY USA.	hua.xu@dbmi.columbia.edu; mm168@columbia.edu; rbd2107@columbia.edu; hl224@georgetown.edu; carol.friedman@dbmi.columbia.edu					Aronson A R, 2001, Proc AMIA Symp, P17; Chen LF, 2005, BIOINFORMATICS, V21, P248, DOI 10.1093/bioinformatics/bth496; DJ H, 1997, CONSTRUCTION ASSESSM; DJ H, 1994, J APPL STAT, V21, P3; EHGAL AK, 2004, GENE TERMS ENGLISH W; F G, 2004, J MACHINE LEARNING R, V5, P605; Fukuda K, 1998, Pac Symp Biocomput, P707; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; G H, 2006, IEEE T NEURAL NETWOR, V13, P415; Gaudan S, 2005, BIOINFORMATICS, V21, P3658, DOI 10.1093/bioinformatics/bti586; Hamosh A, 2002, NUCLEIC ACIDS RES, V30, P52, DOI 10.1093/nar/30.1.52; Hatzivassiloglou V, 2001, Bioinformatics, V17 Suppl 1, pS97; Humphrey SM, 2006, J AM SOC INF SCI TEC, V57, P96, DOI 10.1002/asi.20257; JW CW, 1999, MULTICLASS SUPPORT V; Krallinger M, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-7-224; Lee Y.K., 2002, EMNLP 02, P41; Leroy G, 2005, INT J MED INFORM, V74, P573, DOI 10.1016/j.ijmedinf.2005.03.013; LIDDY ED, 1993, STAT GUIDED WORD SEN, P98; Liu HF, 2002, J AM MED INFORM ASSN, V9, P621, DOI 10.1097/jamia.M1101; Liu HF, 2004, J AM MED INFORM ASSN, V11, P320, DOI 10.1197/jamia.M1533; M M, 2005, J MACHINE LEARNING R, V6, P1127; MAGLOTT D, 2005, NUCLEIC ACIDS RES, V3, pD54; MERKEL M, 2001, COMBINATION CONTEXTU, P123; MF, 1937, J AM STAT ASS, V32, P675; MOHAMMAD S, 2004, COMBINING LEXICAL SY; MOONEY RJ, 1996, C EMP METH NAT LANG, P82; NG HT, 1996, INTEGRATING MULTIPLE, P40; PEDERSEN T, 1997, DISTINGUISHING WORD; PODOWSKI RM, 2004, AZURE SCALABLE SYSTE; Pustejovsky J., 2001, MEDINFO, V10, P371; R R, 2004, J MACHINE LEARNING R, V5, P141; Resnik P., 2000, NATURAL LANGUAGE ENG, V5, P113; S C, SENSEVAL 2; Schijvenaars BJA, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-149; Schuemie MJ, 2005, J COMPUT BIOL, V12, P554, DOI 10.1089/cmb.2005.12.554; Schuemie MJ, 2004, BIOINFORMATICS, V20, P2597, DOI 10.1093/bioinformatics/bth291; Shatkay H, 2003, J COMPUT BIOL, V10, P821, DOI 10.1089/106652703322756104; SL S, 1997, DATA MIN KNOWL DISC, V1, P317; SP E, 1996, MINIMIZING MANUAL AN, V34, P319; T G, 1998, NEURAL COMPUT, V10, P1895; WEBER M, 2000, P AMIA S, P903; Weston J., 2005, SPIDER MACHINE LEARN; WILKS Y, 1990, PROVIDING MACHINE TR; YNGVE VH, 1955, MACHINE TRANSLATION, P208; *AR A SES, 2004, AMB UMLS MET; *NLM, 2000, UMLS KNOWL SOURC; 1994, WORD SENSE DISAMBIGU, P139	47	15	15	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JUL 5	2006	7								334	10.1186/1471-2105-7-334		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	074FQ	WOS:000239798500001	
J	Lee, SH; Terzopoulos, D				Lee, Sung-Hee; Terzopoulos, Demetri			Heads up! Biomechanical modeling and neuromuscular control of the neck	ACM TRANSACTIONS ON GRAPHICS			English	Article						neck animation; biomechanical modeling; hierarchical neuromuscular control; neural network learning; facial animation	MUSCLES; MOTION; COACTIVATION; TORSO	Unlike the human face, the neck has been largely overlooked in the computer graphics literature, this despite its complex anatomical structure and the important role that it plays in supporting the head in balance while generating the controlled head movements that are essential to so many aspects of human behavior. This paper makes two major contributions. First, we introduce a biomechanical model of the human head-neck system. Emulating the relevant anatomy, our model is characterized by appropriate kinematic redundancy ( 7 cervical vertebrae coupled by 3-DOF joints) and muscle actuator redundancy ( 72 neck muscles arranged in 3 muscle layers). This anatomically consistent biomechanical model confronts us with a challenging motor control problem, even for the relatively simple task of balancing the mass of the head in gravity atop the cervical spine. Hence, our second contribution is a novel neuromuscular control model for human head animation that emulates the relevant biological motor control mechanisms. Incorporating low-level reflex and high-level voluntary sub-controllers, our hierarchical controller provides input motor signals to the numerous muscle actuators. In addition to head pose and movement, it controls the tone of mutually opposed neck muscles to regulate the stiffness of the head-neck multibody system. Employing machine learning techniques, the neural networks within our neuromuscular controller are trained offline to efficiently generate the online pose and tone control signals necessary to synthesize a variety of autonomous movements for the behavioral animation of the human head and face.	Univ Calif Los Angeles, Los Angeles, CA 90024 USA	Lee, SH (reprint author), Univ Calif Los Angeles, Los Angeles, CA 90024 USA.						Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation; Anderson FC, 2001, J BIOMECH, V34, P153, DOI 10.1016/S0021-9290(00)00155-X; Carpenter RHS, 1988, MOVEMENTS EYES; CHEN DT, 1992, COMP GRAPH, V26, P89; Crago P. E., 2000, BIOMECHANICS NEURAL; DELP SL, 1995, COMPUT BIOL MED, V25, P21, DOI 10.1016/0010-4825(95)98882-E; FALOUTSOS P., 2001, ANN C SERIES, P251; Grzeszczuk R., 1995, ANN C SERIES, P63; Grzeszczuk R., 1998, ANN C SERIES, P9; Hay J. G., 1988, ANATOMY MECH HUMAN M; Hodgins J. K., 1995, ANN C SERIES, P71; HOGAN N, 1984, IEEE T AUTOMAT CONTR, V29, P681, DOI 10.1109/TAC.1984.1103644; Irving G., 2004, ACM SIGGRAPH EUR S C, P131; KAHLER K, 2001, GRAPHICS INTERFACE, P37; Kandel ER, 2000, PRINCIPLES NEURAL SC; Kapandji I.A., 1974, PHYSL JOINTS, V3; KAWATO M, 1987, BIOL CYBERN, V57, P169, DOI 10.1007/BF00364149; KESHNER EA, 1995, J NEUROPHYSIOL, V73, P2293; Kim J, 1998, IEEE T SYST MAN CY B, V28, P653, DOI 10.1109/3477.718516; KOMURA T, 1997, COMPUT GRAPH FORUM, V16, P165; Komura T, 2000, VISUAL COMPUT, V16, P254, DOI 10.1007/s003719900065; Lee Y, 1995, ANN C SERIES, P55; MONHEIT G, 1991, IEEE COMPUT GRAPH, V11, P29, DOI 10.1109/38.75588; NEFF M, 2002, ACM SIGGRAPH S COMP, P81; Ng-Thow-Hing V, 2001, THESIS U TORONTO; PAI DK, 2005, P SKETCH APPL ACM SI; SCHEEPERS F, 1997, ANN C SERIES, P163; Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208; SPELLUCCI P, DONLP2; TERZOPOULOS D, 2004, ACM SIGGRAPH 2004 CO, V60, P119; TSANG W, 2005, ACM SIGGRAPH EUR S C, P319; TU X, 1994, ANN C SERIES, P43; Vasavada AN, 1998, SPINE, V23, P412, DOI 10.1097/00007632-199802150-00002; WARFEL J, 1985, HEAD NECK TRUNK; Wilhelms J., 1997, ANN C SERIES, P173; YAMAZAKI Y, 1994, BRAIN RES BULL, V34, P587, DOI 10.1016/0361-9230(94)90144-9; YIN K, 2003, P 11 PAC C COMP GRAP; ZORDAN VB, 2004, ACM SIGGRAPH EUR S C, P29	38	16	16	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0730-0301		ACM T GRAPHIC	ACM Trans. Graph.	JUL	2006	25	3					1188	1198		10.1145/1141911.1142013		11	Computer Science, Software Engineering	Computer Science	074MV	WOS:000239817400084	
J	Yu, H; Kim, W; Hatzivassiloglou, V; Wilbur, J				Yu, Hong; Kim, Won; Hatzivassiloglou, Vasileios; Wilbur, John			A large scale, corpus-based approach for automatically disambiguating biomedical abbreviations	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						algorithms; languages; word-sense disambiguation; machine learning; data mining; information retrieval	INFORMATION	Abbreviations and acronyms are widely used in the biomedical literature and many of them represent important biomedical concepts. Because many abbreviations are ambiguous (e.g., CAT denotes both chloramphenicol acetyl transferase and computed axial tomography, depending on the context), recognizing the full form associated with each abbreviation is in most cases equivalent to identifying the meaning of the abbreviation. This, in turn, allows us to perform more accurate natural language processing, information extraction, and retrieval. In this study, we have developed supervised approaches to identifying the full forms of ambiguous abbreviations within the context they appear. We first automatically assigned multiple possible full forms for each abbreviation; we then treated the in-context full-form prediction for each specific abbreviation occurrence as a case of word-sense disambiguation. We generated automatically a dictionary of all possible full forms for each abbreviation. We applied supervised machine-learning algorithms for disambiguation. Because some of the links between abbreviations and their corresponding full forms are explicitly given in the text and can be recovered automatically, we can use these explicit links to automatically provide training data for disambiguating the abbreviations that are not linked to a full form within a text. We evaluated our methods on over 150 thousand abstracts and obtain for coverage and precision results of 82% and 92%, respectively, when performed as tenfold cross-validation, and 79% and 80%, respectively, when evaluated against an external set of abstracts in which the abbreviations are not defined.	Univ Wisconsin, Dept Hlth Sci, Milwaukee, WI 53211 USA; Univ Texas, Dept Comp Sci, Richardson, TX 75083 USA; Natl Lib Med, Natl Ctr Biotechnol Informat, Bethesda, MD 20894 USA	Yu, H (reprint author), Univ Wisconsin, Dept Hlth Sci, Milwaukee, WI 53211 USA.	yuh9001@dbmi.columbia.edu					ADAR E, 2002, SIMPLE ROBUST ABBREV; AYER M, 1955, ANN MATH STAT, V26, P641, DOI 10.1214/aoms/1177728423; Blum A., 1998, P WORKSH COMP LEARN; BOWDEN PR, 1998, P COMPUTTERM98 C MON; BRILL E, 1995, P COMP LING; CHANG JT, 2006, IN PRESS JAMIA; CHARNIAK E, 2000, P NAACL 2000 C; CHURCH K, 1988, P 2 C APPL NAT LANG; COLLINS M, 1996, P ACL C; Dubou P. A., 2001, BIOINFORMATICS S1, V17, P97; ENGELSON SP, 1996, P CONN STAT SYMB APP; Fauquet CM, 1999, ARCH VIROL, V144, P1865, DOI 10.1007/s007050050711; Federiuk CS, 1999, ACAD EMERG MED, V6, P292, DOI 10.1111/j.1553-2712.1999.tb00392.x; Fukuda K, 1998, Pac Symp Biocomput, P707; GALE WA, 1992, COMPUT HUMANITIES, V26, P415, DOI 10.1007/BF00136984; Hardle W., 1991, SMOOTHING TECHNIQUES; HEARST MA, 1991, P 7 ANN C UW CTR NEW; HISAMITSU T, 1998, P COMPUTERM98 C MONT; HUMPHREYS BL, 1993, B MED LIBR ASSOC, V81, P170; JELINEK F, 1980, P PWPRP C; Kenneth W. A. G., 1991, STAT COMPUT, V1, P93, DOI 10.1007/BF01889984; KLAVANS J, 1990, P 6 C UW CONTR NEW O; KOPFF M, 1990, ACTA BIOCHIM POL, V37, P227; LANGLEY P, 1992, P 10 NAT C ART INT; Langley P., 1994, P 10 C UNC ART INT S; LESK M, 1986, P SIGDOC C; LIDSTONE G, 1992, T FACULTY ACTUARIES, V8, P182; Liu HF, 2001, J BIOMED INFORM, V34, P249, DOI 10.1006/jbin.2001.1023; McCray AT, 1998, METHOD INFORM MED, V37, P353; Pakhomov S, 2002, P 40 ANN M ASS COMP; Park J C, 2001, Pac Symp Biocomput, P396; Platt J.C., 1999, FAST TRAINING SUPPOR; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; PUSTEJOVSKY J, 2001, P MED C; Ratnaparkhi A., 1998, THESIS U PENNSYLVANI; Rimer M, 1998, BIOINFORMATICS, V14, P888, DOI 10.1093/bioinformatics/14.10.888; Schutze H, 1998, COMPUT LINGUIST, V24, P97; SCHWARTZ AS, 2002, IN PRESS PAC S BIOCO; SINGHAL A, 1996, RES DEV INFORM RETRI, P21; Stapley B J, 2000, Pac Symp Biocomput, P529; Turteltaub Kenneth W., 1998, Toxicology Letters (Shannon), V102-103, P435, DOI 10.1016/S0378-4274(98)00344-0; WELLNER B, 2005, P BIOLINK SIG LINK L; Wilbur W J, 2000, Proc AMIA Symp, P918; WILBUR WJ, 2001, P ASIST ANN M; YANG Y, 1997, P 14 INT ICML 97 C; Yarowsky David, 1995, P 33 ANN M ASS COMP; YEATES S, 2000, P DAT COMPR C; Yoshida M, 2000, BIOINFORMATICS, V16, P169, DOI 10.1093/bioinformatics/16.2.169; Yu H, 2002, J AM MED INFORM ASSN, V9, P262, DOI 10.1197/jamia.M0913; YU H, 2003, BIOINFORMATICS S1, V19, P340; ZEITLHUBER U, 1984, BLUT, V48, P393, DOI 10.1007/BF00319970	51	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	1046-8188		ACM T INFORM SYST	ACM Trans. Inf. Syst.	JUL	2006	24	3					380	404		10.1145/1165774.1165778		25	Computer Science, Information Systems	Computer Science	097GB	WOS:000241433900004	
J	Schaback, R; Werner, J				Schaback, R; Werner, J			Linearly constrained reconstruction of functions by kernels with applications to machine learning	ADVANCES IN COMPUTATIONAL MATHEMATICS			English	Article						positive definite radial basis functions; quadratic programming; kernel machines; machine learning; support vector machines; regression		This paper investigates the approximation of multivariate functions from data via linear combinations of translates of a positive definite kernel from a reproducing kernel Hilbert space. If standard interpolation conditions are relaxed by Chebyshev-type constraints, one can minimize the norm of the approximant in the Hilbert space under these constraints. By standard arguments of optimization theory, the solutions will take a simple form, based on the data related to the active constraints, called support vectors in the context of machine learning. The corresponding quadratic programming problems are investigated to some extent. Using monotonicity results concerning the Hilbert space norm, iterative techniques based on small quadratic subproblems on active sets are shown to be finite, even if they drop part of their previous information and even if they are used for infinite data, e.g., in the context of online learning. Numerical experiments confirm the theoretical results.				Schaback, Robert/B-1794-2013	Schaback, Robert/0000-0001-7828-4355			Barrodale I., 1975, ACM Transactions on Mathematical Software, V1, DOI 10.1145/355644.355651; BRAESS D, 1974, NUMER MATH, P357; DEMARCHI S, 2002, UNPUB OPTIMAL POINT; Fletcher R., 1987, PRACTICAL METHODS OP; Micchelli C. A., 1977, OPTIMAL ESTIMATION A, P1; MICCHELLI CA, 1978, RESULTATE MATH, V3, P25; MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414; MICCHELLI CA, 1984, LECT NOTES MATH, V1129, P12; MICCHELLI CA, 1976, NUMER MATH, V26, P191, DOI 10.1007/BF01395972; SCHABACK R, 2000, CURVE SURFACE FITTIN; Schaback R, 1999, INT S NUM M, V132, P255; Schaback R, 2000, NUMER ALGORITHMS, V24, P239, DOI 10.1023/A:1019105612985; SCHABACK R, 2002, UNPUB MATH RESULTS K; Scholkopf B., 2002, LEARNING KERNELS; Stewart J., 1976, ROCKY MOUNTAIN MATH, V6, P409; Vapnik V. N, 1995, NATURE STAT LEARNING; WERNER J, 1984, OPTIMIZATION THEORY; Wolfe P., 1956, NAVAL RES LOGIST QUA, V1, P95, DOI 10.1002/nav.3800030109	18	3	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1019-7168		ADV COMPUT MATH	Adv. Comput. Math.	JUL	2006	25	1-3					237	258		10.1007/s10444-004-7616-1		22	Mathematics, Applied	Mathematics	058LE	WOS:000238665700013	
J	de Souza, JT; Matwin, S; Japkowicz, N				de Souza, Jerffeson Teixeira; Matwin, Stan; Japkowicz, Nathalie			Parallelizing feature selection	ALGORITHMICA			English	Article						feature selection; hybrid system; parallelism; master-slave design pattern		Classification is a key problem in machine learning/data mining. Algorithms for classification have the ability to predict the class of a new instance after having been trained on data representing past experience in classifying instances. However, the presence of a large number of features in training data can hurt the classification capacity of a machine learning algorithm. The Feature Selection problem involves discovering a subset of features such that a classifier built only with this subset would attain predictive accuracy no worse than a classifier built from the entire set of features. Several algorithms have been proposed to solve this problem. In this paper we discuss how parallelism can be used to improve the performance of feature selection algorithms. In particular, we present, discuss and evaluate a coarse-grained parallel version of the feature selection algorithm FortalFS. This algorithm performs well compared with other solutions and it has certain characteristics that makes it a good candidate for parallelization. Our parallel design is based on the master-slave design pattern. Promising results show that this approach is able to achieve near optimum speedups in the context of Amdahl's Law.	Univ Estadual Ceara, Dept Comp Sci, BR-60740000 Fortaleza, Ceara, Brazil; Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada	de Souza, JT (reprint author), Univ Estadual Ceara, Dept Comp Sci, BR-60740000 Fortaleza, Ceara, Brazil.	jeff@larces.uece.br; stan@site.uottawa.ca; nat@site.uottawa.ca					Almuallim H., 1991, P 9 NAT C ART INT AA, V2, P547; ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Amdahl G., 1967, P AFIPS SPRING JOINT, V30, P483; Bellman R., 1961, ADAPTIVE CONTROL PRO; Blake C. L., 1998, UCI REPOSITORY MACHI; BUSCHMANN F, 1995, PATTERN LANGUAGES OF PROGRAM DESIGN, P133; Freitas A. A, 1998, MINING VERY LARGE DA; Freitas A. A., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; Hall M. A., 2000, P 17 INT C MACH LEAR; HALL MA, 1999, P FLOR ART INT S FLA; HALL MA, 1998, THSIS WAIKATO U HAMI; John G.H., 1994, P 11 INT C MACH LEAR, P121; Kargupta H., 2000, ADV DISTRIBUTED PARA; Kira K, 1992, P 9 INT C MACH LEARN, P249; Kononenko I., 1994, P EUR C MACH LEARN, P171; Kononenko I, 1996, FR ART INT, V35, P31; Liu Huiqing, 2002, Genome Inform, V13, P51; Liu H., 1996, P 13 INT C MACH LEAR, P319; MELAB N, 2002, P 16 INT PAR DISTR P, P245; MILLER BN, 1995, 9555 UMSI; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Rendell L.A., 1992, P 10 NAT C ART INT, P129; Skillicorn D, 1999, IEEE CONCURR, V7, P26, DOI 10.1109/4434.806976; SOUZA JT, 2003, FEATURE SELECTION GE; Vafaie H., 1992, Proceedings. Fourth International Conference on Tools with Artificial Intelligence, TAI '92 (Cat. No. 92CH3203-7), DOI 10.1109/TAI.1992.246402; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; XU L, 1989, P 9 INT C PATT REC, P706; Zaki MJ, 1999, IEEE CONCURR, V7, P14, DOI 10.1109/4434.806975; ZAKI MJ, 2000, LNAI STATE OF THE AR, V1759; *SUN MICR, 2003, JAV REM METH INV RMI	30	4	4	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0178-4617		ALGORITHMICA	Algorithmica	JUL	2006	45	3					433	456		10.1007/s00453-006-1220-3		24	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	051IA	WOS:000238153600008	
J	Coifman, RR; Lafon, S				Coifman, Ronald R.; Lafon, Stephane			Diffusion maps	APPLIED AND COMPUTATIONAL HARMONIC ANALYSIS			English	Article						diffusion processes; diffusion metric; manifold learning; dimensionality reduction; eigenmaps; graph laplacian	WEB SEARCH	In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods. (C) 2006 Published by Elsevier Inc.	Yale Univ, Dept Math, New Haven, CT 06520 USA	Coifman, RR (reprint author), Yale Univ, Dept Math, New Haven, CT 06520 USA.	coifman@math.yale.edu; stephane.lafon@gmail.com					BELKIN M, 2003, NEURAL COMPUTATIONAL, V13, P1373; Belkin M., 2003, THESIS; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Chung F., CBNS AMS, V92; COIFMAN RR, 2004, UNPUB P NATL AC SCI; COIFMAN RR, 2004, IN PRESS APPL COMPUT; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; FOUSS F, 2004, UNPUB APPL NEW CONCE; Ham J., 2003, TR110 M PLANCK I BIO; Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999; HEIN M, 2005, COLT, P470; Hoff PD, 2002, J AM STAT ASSOC, V97, P1090, DOI 10.1198/016214502388618906; HUGGINS PS, 2002, P 7 EUR C COMP VIS C, P384; KAC M, 1966, AM MATH MON, V73, P1, DOI 10.2307/2313748; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Lafon S., 2004, THESIS YALE U; LEMPEL R, 2000, P 9 INT WORLD WID WE, P387; NAHMOD AR, 1991, THESIS YALE U; Page L., 1998, PAGERANK CITATION RA; PEDERSEN KS, 2002, P 7 EUR C COMP VIS, P328; Pedersen M., 1999, FUNCTIONAL ANAL APPL; Rosenberg S., 1997, LAPLACIAN RIEMANNIAN; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAFAROV Y, 1996, ASYMPTOTIC DISTRIBUT; Shi JB, 1997, PROC CVPR IEEE, P731; SINGER A, 2005, GRAPH MANIFOLD LAPLA; Smolyanov O. G., 2000, CAN MATH SOC C P, V29, P589; Stein E. M., 1970, TOPICS HARMONIC ANAL; Szummer M., 2001, NIPS, V14, P945; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790354; White S., 2003, P 9 ACM SIGKDD INT C, P266, DOI 10.1145/956750.956782; Zhang Z., 2002, CSE02019 PENNS STAT	32	254	257	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1063-5203		APPL COMPUT HARMON A	Appl. Comput. Harmon. Anal.	JUL	2006	21	1					5	30		10.1016/j.acha.2006.04.006		26	Mathematics, Applied; Physics, Mathematical	Mathematics; Physics	065KD	WOS:000239157900003	
J	Singer, A				Singer, A.			From graph to manifold Laplacian: The convergence rate	APPLIED AND COMPUTATIONAL HARMONIC ANALYSIS			English	Article							GEOMETRIC DIFFUSIONS; STRUCTURE DEFINITION; HARMONIC-ANALYSIS; TOOL	The convergence of the discrete graph Laplacian to the continuous manifold Laplacian in the limit of sample size N --> infinity while the kernel bandwidth epsilon --> 0, is the justification for the success of Laplacian based algorithms in machine learning, such as dimensionality reduction, semi-supervised learning and spectral clustering. In this paper we improve the convergence rate of the variance term recently obtained by Hein et al. [From graphs to manifolds-Weak and strong pointwise consistency of graph Laplacians, in: P. Auer, R. Meir (Eds.), Proc. 18th Conf. Learning Theory (COLT), Lecture Notes Comput. Sci., vol. 3559, Springer-Verlag, Berlin, 2005, pp. 470-485], improve the bias term error, and find an optimal criteria to determine the parameter E given N. (C) 2006 Elsevier Inc. All rights reserved.	Yale Univ, Dept Math, New Haven, CT 06520 USA	Singer, A (reprint author), Yale Univ, Dept Math, 10 Hillhouse Ave,POB 208283, New Haven, CT 06520 USA.	amit.singer@yale.edu					Belkin M., 2002, ADV NEURAL INFORM PR, V14; Belkin M., 2003, THESIS U CHICAGO; Belkin M, 2005, LECT NOTES COMPUT SC, V3559, P486, DOI 10.1007/11503415_33; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7432, DOI 10.1073/pnas.0500896102; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Hein M., 2005, P 22 INT C MACH LEAR, P289, DOI 10.1145/1102351.1102388; Hein M, 2005, LECT NOTES COMPUT SC, V3559, P470, DOI 10.1007/11503415_32; Lafon S., 2004, THESIS YALE U; Nadler B., 2006, ADV NEURAL INFORM PR, V18; SMOLYANOV OG, 2000, CMS C P, V29	11	28	28	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1063-5203		APPL COMPUT HARMON A	Appl. Comput. Harmon. Anal.	JUL	2006	21	1					128	134		10.1016/j.acha.2006.03.004		7	Mathematics, Applied; Physics, Mathematical	Mathematics; Physics	065KD	WOS:000239157900008	
J	Tang, HX; Arnold, RJ; Alves, P; Xun, ZY; Clemmer, DE; Novotny, MV; Reilly, JP; Radivojac, P				Tang, Haixu; Arnold, Randy J.; Alves, Pedro; Xun, Zhiyin; Clemmer, David E.; Novotny, Milos V.; Reilly, James P.; Radivojac, Predrag			A computational approach toward label-free protein quantification using predicted peptide detectability	BIOINFORMATICS			English	Article; Proceedings Paper	14th Conference on Intelligent Systems for Molecular Biology	AUG 06-10, 2006	Fortaleza, BRAZIL				COMPARATIVE PROTEOMICS; SEQUENCE DATABASES; INTRINSIC DISORDER; ABUNDANCE; MIXTURES; IDENTIFICATION; FLEXIBILITY; TECHNOLOGY; EXPRESSION; YEAST	We propose here a new concept of peptide detectability which could be an important factor in explaining the relationship between a protein's quantity and the peptides identified from it in a high-throughput proteomics experiment. We define peptide detectability as the probability of observing a peptide in a standard sample analyzed by a standard proteomics routine and argue that it is an intrinsic property of the peptide sequence and neighboring regions in the parent protein. To test this hypothesis we first used publicly available data and data from our own synthetic samples in which quantities of model proteins were controlled. We then applied machine learning approaches to demonstrate that peptide detectability can be predicted from its sequence and the neighboring regions in the parent protein with satisfactory accuracy. The utility of this approach for protein quantification is demonstrated by peptides with higher detectability generally being identified at lower concentrations over those with lower detectability in the synthetic protein mixtures. These results establish a direct link between protein concentration and peptide detectability. We show that for each protein there exists a level of peptide detectability above which peptides are detected and below which peptides are not detected in an experiment. We call this level the minimum acceptable detectability for identified peptides (MDIP) which can be calibrated to predict protein concentration. Triplicate analysis of a biological sample showed that these MDIP values are consistent among the three data sets.	Indiana Univ, Sch Informat, Bloomington, IN 47408 USA; Indiana Univ, Ctr Genom & Bioinformat, Bloomington, IN USA; Indiana Univ, Natl Ctr Glycom & Glycoproteom, Bloomington, IN USA; Indiana Univ, Dept Chem, Bloomington, IN USA	Radivojac, P (reprint author), Indiana Univ, Sch Informat, 901 E 10th St, Bloomington, IN 47408 USA.	predrag@indiana.edu					BONNER AJ, 2006, P SIAM INT C DAT MIN, V6, P599; Cagney G, 2002, NAT BIOTECHNOL, V20, P163, DOI 10.1038/nbt0202-163; Chakraborty A, 2002, J CHROMATOGR A, V949, P173, DOI 10.1016/S0021-9673(02)00047-X; EISENBERG D, 1984, P NATL ACAD SCI-BIOL, V81, P140, DOI 10.1073/pnas.81.1.140; Gao J, 2003, J PROTEOME RES, V2, P643, DOI 10.1021/pr034038x; Gygi SP, 1999, NAT BIOTECHNOL, V17, P994, DOI 10.1038/13690; Higgs RE, 2005, J PROTEOME RES, V4, P1442, DOI 10.1021/pr050109b; Ishihama Y, 2005, MOL CELL PROTEOMICS, V4, P1265, DOI 10.1074/mcp.M500061-MCP200; Kuster B, 2005, NAT REV MOL CELL BIO, V6, P577, DOI 10.1038/nrm1683; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Leptos KC, 2006, PROTEOMICS, V6, P1770, DOI 10.1002/pmic.200500201; Liu HB, 2004, ANAL CHEM, V76, P4193, DOI 10.1021/ac0498563; Nesvizhskii AI, 2005, MOL CELL PROTEOMICS, V4, P1419, DOI 10.1074/mcp.R500012-MCP200; Obradovic Z, 2003, PROTEINS, V53, P566, DOI 10.1002/prot.10532; Oda Y, 1999, P NATL ACAD SCI USA, V96, P6591, DOI 10.1073/pnas.96.12.6591; Pang JX, 2002, J PROTEOME RES, V1, P161, DOI 10.1024/pr015518w; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Purvine S, 2004, OMICS, V8, P79, DOI 10.1089/153623104773547507; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Radivojac P, 2004, PROTEIN SCI, V13, P71, DOI 10.1110/ps.03128904; Riedmiller M., 1993, P INT C NEUR NETW, V1, P586; Romero P, 2001, PROTEINS, V42, P38, DOI 10.1002/1097-0134(20010101)42:1<38::AID-PROT50>3.0.CO;2-3; VIHINEN M, 1994, PROTEINS, V19, P141, DOI 10.1002/prot.340190207; Vucetic S, 2003, PROTEINS, V52, P573, DOI 10.1002/prot.10437; Washburn MP, 2001, NAT BIOTECHNOL, V19, P242, DOI 10.1038/85686; Wootton JC, 1996, METHOD ENZYMOL, V266, P554; Zhang RJ, 2002, J PROTEOME RES, V1, P139, DOI 10.1021/pr015516b	27	73	76	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUL	2006	22	14					E481	E488		10.1093/bioinformatics/btl237		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	218GW	WOS:000250005000059	
J	Pillai, SK; Pond, SLK; Liu, Y; Good, BM; Strain, MC; Ellis, RJ; Letendre, S; Smith, DM; Gunthard, HF; Grant, I; Marcotte, TD; McCutchan, JA; Richman, DD; Wong, JK				Pillai, SK; Pond, SLK; Liu, Y; Good, BM; Strain, MC; Ellis, RJ; Letendre, S; Smith, DM; Gunthard, HF; Grant, I; Marcotte, TD; McCutchan, JA; Richman, DD; Wong, JK			Genetic attributes of cerebrospinal fluid-derived HIV-1 env	BRAIN			English	Article						HIV; CNS; neurovirulence; evolution; compartmentalization	HUMAN-IMMUNODEFICIENCY-VIRUS; CENTRAL-NERVOUS-SYSTEM; BLOOD-BRAIN-BARRIER; ANTIRETROVIRAL THERAPY; REVERSE-TRANSCRIPTASE; RESISTANCE MUTATIONS; MACROPHAGE TROPISM; ENDOTHELIAL-CELLS; ENVELOPE PROTEIN; TYPE-1 ENV	HIV-1 often invades the CNS during primary infection, eventually resulting in neurological disorders in up to 50% of untreated patients. The CNS is a distinct viral reservoir, differing from peripheral tissues in immunological surveillance, target cell characteristics and antiretroviral penetration. Neurotropic HIV-1 likely develops distinct genotypic characteristics in response to this unique selective environment. We sought to catalogue the genetic features of CNS-derived HIV-1 by analysing 456 clonal RNA sequences of the C2-V3 env subregion generated from CSF and plasma of 18 chronically infected individuals. Neuropsychological performance of all subjects was evaluated and summarized as a global deficit score. A battery of phylogenetic, statistical and machine learning tools was applied to these data to identify genetic features associated with HIV-1 neurotropism and neurovirulence. Eleven of 18 individuals exhibited significant viral compartmentalization between blood and CSF (P < 0.01, Slatkin-Maddison test). A CSF-specific genetic signature was identified, comprising positions 9, 13 and 19 of the V3 loop. The residue at position 5 of the V3 loop was highly correlated with neurocognitive deficit (P < 0.0025, Fisher's exact test). Antibody-mediated HIV-1 neutralizing activity was significantly reduced in CSF with respect to autologous blood plasma (P < 0.042, Student's t-test). Accordingly, CSF-derived sequences exhibited constrained diversity and contained fewer glycosylated and positively selected sites. Our results suggest that there are several genetic features that distinguish CSF- and plasma-derived HIV-1 populations, probably reflecting altered cellular entry requirements and decreased immune pressure in the CNS. Furthermore, neurological impairment may be influenced by mutations within the viral V3 loop sequence.	Univ Calif San Francisco, Dept Med, NCIRE, San Francisco, CA 94121 USA; Univ Calif San Diego, La Jolla, CA 92093 USA; VA San Diego Healthcare Syst, San Diego, CA USA; VA Med Ctr San Francisco, San Francisco, CA USA; Monogram Biosci Inc, San Francisco, CA USA; HIV Neurobehav Res Ctr, San Diego, CA USA; Univ Zurich Hosp, Div Infect Dis, CH-8091 Zurich, Switzerland; Univ Zurich Hosp, Hosp Epidemiol, CH-8091 Zurich, Switzerland	Pillai, SK (reprint author), Univ Calif San Francisco, Dept Med, NCIRE, 4150 Clement St,111W3, San Francisco, CA 94121 USA.	satish.pillai@ucsf.edu	Infektiologie, USZ/A-6921-2011; gunthard, huldrych/F-1724-2011				ADACHI A, 1986, J VIROL, V59, P284; Argyris EG, 2003, J VIROL, V77, P12140, DOI 10.1128/JVI.77.22.12140-12151.2003; Burdo TH, 2004, DNA CELL BIOL, V23, P261, DOI 10.1089/104454904773819842; Carey CL, 2004, J CLIN EXP NEUROPSYC, V26, P307, DOI 10.1080/13803390490510031; Chesebro B, 1996, J VIROL, V70, P9055; Chohan B, 2005, J VIROL, V79, P6528, DOI 10.1128/JVI.79.10.6528-6531.2005; Cinque P, 2003, J CLIN VIROL, V26, P1, DOI 10.1016/S1386-6532(02)00173-7; Clements JE, 2002, J INFECT DIS, V186, P905, DOI 10.1086/343768; Cunningham PH, 2000, AIDS, V14, P1949, DOI 10.1097/00002030-200009080-00010; Dayhoff MO, 1978, ATLAS PROTEIN SEQ S3, P345; Derdeyn CA, 2004, SCIENCE, V303, P2019, DOI 10.1126/science.1093137; Ellis RJ, 2000, NEUROLOGY, V54, P927; Ellis RJ, 1997, ANN NEUROL, V42, P679, DOI 10.1002/ana.410420503; Felsenstein J., 1993, PHYLIP PHYLOGENY INF; Foudraine NA, 1998, LANCET, V351, P1547, DOI 10.1016/S0140-6736(98)07333-4; GARTNER S, 1986, SCIENCE, V233, P215, DOI 10.1126/science.3014648; Gonzalez-Scarano F, 2005, NAT REV IMMUNOL, V5, P69, DOI 10.1038/nri1527; Gorry PR, 2001, J VIROL, V75, P10073, DOI 10.1128/JVI.75.21.10073-10089.2001; GOUDSMIT J, 1987, P NATL ACAD SCI USA, V84, P3876, DOI 10.1073/pnas.84.11.3876; GRANT I, 1987, ANN INTERN MED, V107, P828; Gunthard HF, 2001, J INFECT DIS, V183, P1318, DOI 10.1086/319864; Heaton R K, 1995, J Int Neuropsychol Soc, V1, P231; HO DD, 1985, NEW ENGL J MED, V313, P1493, DOI 10.1056/NEJM198512123132401; Hogan TH, 2003, J NEUROVIROL, V9, P55, DOI 10.1080/13550280390173292; HUDSON RR, 1992, GENETICS, V132, P583; Hughes ES, 1997, J VIROL, V71, P1272; Kanmogne GD, 2002, J NEUROPATH EXP NEUR, V61, P992; KORBER BTM, 1994, J VIROL, V68, P7467; Pond SLK, 2005, MOL BIOL EVOL, V22, P1208, DOI 10.1093/molbev/msi105; KOYANAGI Y, 1987, SCIENCE, V236, P819, DOI 10.1126/science.3646751; KUIKEN CL, 1995, J GEN VIROL, V76, P175, DOI 10.1099/0022-1317-76-1-175; Leigh-Brown AJ, 1997, P NATL ACAD SCI USA, V94, P1862; LIPTON SA, 1992, NEUROREPORT, V3, P913, DOI 10.1097/00001756-199210000-00023; LJUNGGREN K, 1989, AIDS RES HUM RETROV, V5, P629, DOI 10.1089/aid.1989.5.629; Marshall R D, 1974, BIOCHEM SOC S, P17; McArthur JC, 2003, J NEUROVIROL, V9, P205, DOI 10.1080/13550280390194109; McCrossan M, 2006, BRAIN, V129, P503, DOI 10.1093/brain/awh695; Misra A, 2003, J PHARM PHARM SCI, V6, P252; NEI M, 1986, MOL BIOL EVOL, V3, P418; Nickle DC, 2003, J VIROL, V77, P5540, DOI 10.1128/JVI.77.9.5540-5546.2003; Nickle DC, 2003, CURR OPIN MICROBIOL, V6, P410, DOI 10.1016/S1369-5274(03)00096-1; Ohagen A, 2003, J VIROL, V77, P12336, DOI 10.1128/JVI.77.22.12336-12345.2003; OLSEN GJ, 1994, COMPUT APPL BIOSCI, V10, P41; Pachter JS, 2003, J NEUROPATH EXP NEUR, V62, P593; Page RDM, 1996, COMPUT APPL BIOSCI, V12, P357; Pierson T, 2000, ANNU REV IMMUNOL, V18, P665, DOI 10.1146/annurev.immunol.18.1.665; Pillai S, 2003, AIDS RES HUM RETROV, V19, P145, DOI 10.1089/088922203762688658; Pillai SK, 2005, J VIROL, V79, P1734, DOI 10.1128/JVI.79.3.1734-1724.2005; POND SLK, 2006, IN PRESS PLOS COMPUT; Power C, 1995, CURR TOP MICROBIOL, V202, P89; POWER C, 1994, J VIROL, V68, P4643; Price RW, 1996, LANCET, V348, P445, DOI 10.1016/S0140-6736(95)11035-6; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; Rambaut A., 1996, SE AL SEQUENCE ALIGN; Richman DD, 2003, P NATL ACAD SCI USA, V100, P4144, DOI 10.1073/pnas.0630530100; Ross HL, 2001, J NEUROVIROL, V7, P235; Ruta Simona Maria, 1998, Romanian Journal of Virology, V49, P61; Sanjuan R, 2004, EVOLUTION, V58, P1185; Shieh JTC, 1998, J VIROL, V72, P4243; SLATKIN M, 1989, GENETICS, V123, P603; Smit TK, 2004, J VIROL, V78, P10133, DOI 10.1128/JVI.78.18.10133-10148.2004; Song B, 2004, VIROLOGY, V322, P168, DOI 10.1016/j.virol.2004.02.001; Staprans S, 1999, AIDS, V13, P1051, DOI 10.1097/00002030-199906180-00008; Strain MC, 2005, J VIROL, V79, P1772, DOI 10.1128/JVI.79.3.1772-1788.2005; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; TOGGAS SM, 1994, NATURE, V367, P188, DOI 10.1038/367188a0; Trillo-Pazos G, 2004, NEUROPATH APPL NEURO, V30, P136, DOI 10.1046/j.1365-2990.2003.0519.x; Venturi G, 2000, J INFECT DIS, V181, P740, DOI 10.1086/315249; VONGEGERFELT A, 1992, AIDS RES HUM RETROV, V8, P1133, DOI 10.1089/aid.1992.8.1133; Wei XP, 2003, NATURE, V422, P307, DOI 10.1038/nature01470; Witten I. H., 2000, DATA MINING PRACTICA; Wong JK, 1997, J VIROL, V71, P2059; Zhou NM, 2003, VIROLOGY, V317, P84, DOI 10.1016/j.virol.2003.08.026; Zink MC, 1999, J VIROL, V73, P10480	74	45	48	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0006-8950		BRAIN	Brain	JUL	2006	129		7				1872	1883		10.1093/brain/awl136		12	Clinical Neurology; Neurosciences	Neurosciences & Neurology	059VV	WOS:000238761200027	
J	Henegar, C; Bousquet, C; Louet, ALL; Degoulet, P; Jaulent, MC				Henegar, C; Bousquet, C; Louet, ALL; Degoulet, P; Jaulent, MC			Building an ontology of adverse drug reactions for automated signal generation in pharmacovigilance	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						adverse drug reaction reporting systems; terminology; automatic data processing; knowledge representation (computer); description logic; ontological modeling	DATA MINING APPROACH; MEDICAL DICTIONARY; TERMINOLOGY; SYSTEMS; MEDDRA; DISPROPORTIONALITY; SELECTION; LANGUAGE; DATABASE; SERVER	Automated signal generation in pharmacovigilance implements unsupervised statistical machine learning techniques in order to discover unknown adverse drug reactions (ADR) in spontaneous reporting systems. The impact of the terminology used for coding ADRs has not been addressed previously. The Medical Dictionary for Regulatory Activities (MedDRA) used worldwide in pharmacovigilance cases does not provide formal definitions of terms. We have built an ontology of ADRs to describe semantics of MedDRA terms. Ontological subsumption and approximate matching inferences allow a better grouping of medically related conditions. Signal generation performances are significantly improved but time consumption related to modelization remains very important. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Paris Descartes, INSERM, U729, Fac Med, F-75006 Paris, France; Hop Europeen Georges Pompidou, Ctr Reg Pharmacovigilance, Paris, France	Jaulent, MC (reprint author), Univ Paris Descartes, INSERM, U729, Fac Med, 15 Rue Ecole Med, F-75006 Paris, France.	marie-christine.jaulent@spim.jussieu.fr					Bate A, 2002, EUR J CLIN PHARMACOL, V58, P483, DOI 10.1007/s00228-002-0484-x; Bate A, 1998, EUR J CLIN PHARMACOL, V54, P315, DOI 10.1007/s002280050466; Bate A, 2002, DRUG SAFETY, V25, P393, DOI 10.2165/00002018-200225060-00002; BECHHOFER S, 2001, LNAI; BEGAUD B, 1985, THERAPIE, V40, P111; Bousquet C, 2005, DRUG SAFETY, V28, P19, DOI 10.2165/00002018-200528010-00002; Brown EG, 1999, DRUG SAFETY, V20, P109, DOI 10.2165/00002018-199920020-00002; Brown EG, 2002, DRUG SAFETY, V25, P445, DOI 10.2165/00002018-200225060-00009; Chute CG, 1998, J AM MED INFORM ASSN, V5, P503; Cimino JJ, 1998, METHOD INFORM MED, V37, P394; Cote R.A, 1993, SNOMED INT; DuMouchel W, 1999, AM STAT, V53, P177, DOI 10.2307/2686093; Egberts ACG, 2002, DRUG SAFETY, V25, P453, DOI 10.2165/00002018-200225060-00010; Evans SJW, 2001, PHARMACOEPIDEM DR S, V10, P483, DOI 10.1002/pds.677; FANCONI E, DESCRIPTION LOGICS C; Farquhar A, 1997, INT J HUM-COMPUT ST, V46, P707, DOI 10.1006/ijhc.1996.0121; GILLAM L, 2004, WORKSH TERM ONT KNOW; GOMEZPEREZ A, 2002, SURVEY ONTOLOGY TOOL, P13; GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008; GUARINO N, 2001, 012001 LADSEB CNR; HAARSLEV V, 2001, P INT WORKSH DESCR L, P132; HANLEY JA, 1989, CRIT REV DIAGN IMAG, V29, P307; Hauben M, 2003, DRUG SAFETY, V26, P159, DOI 10.2165/00002018-200326030-00003; Heeley E, 2002, DRUG SAFETY, V25, P423, DOI 10.2165/00002018-200225060-00006; Horrocks I., 2000, P 17 INT C AUT DED, P482; Le Moigno Sophie, 2002, Proc AMIA Symp, P430; LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281; Lindquist M, 2000, DRUG SAFETY, V23, P533, DOI 10.2165/00002018-200023060-00004; Lussier YA, 1998, METHOD INFORM MED, V37, P161; Maedche A, 2001, IEEE INTELL SYST APP, V16, P72, DOI 10.1109/5254.920602; MCGUINNESS DL, 2001, P 2001 INT WORKSH DE; Meyboom RHB, 2002, DRUG SAFETY, V25, P459, DOI 10.2165/00002018-200225060-00011; NAVIGLI R, 2003, IEEE INTELLIGENT JAN, P22; Noy N.F., 2000, 2 INT C KNOWL ENG KN; RECTOR AL, 1995, METHOD INFORM MED, V34, P147; RECTOR AL, 1999, IEEE T INFORMATION T, V2, P229; Rossi Mori A, 1998, Methods Inf Med, V37, P551; SOWA JF, 2000, KNOWLEDGE REPRESENTA, P492; Spackman K A, 1997, Proc AMIA Annu Fall Symp, P640; Szarfman A, 2002, DRUG SAFETY, V25, P381, DOI 10.2165/00002018-200225060-00001; Trombert-Paviot B, 2000, INT J MED INFORM, V58, P71, DOI 10.1016/S1386-5056(00)00077-0; Uschold M, 1996, KNOWL ENG REV, V11, P93; van Puijenbroek EP, 2002, PHARMACOEPIDEM DR S, V11, P3, DOI 10.1002/pds.668; Yokotsuka M, 2000, INT J MED INFORM, V57, P139, DOI 10.1016/S1386-5056(00)00062-9; *CEN TC, 1995, 251 CEN TC; *WHO, 1993, MAN INT STAT CLASS D	46	10	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825		COMPUT BIOL MED	Comput. Biol. Med.	JUL-AUG	2006	36	7-8					748	767		10.1016/j.compbiomed.2005.04.009		20	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	059LW	WOS:000238735300006	
J	Levenson, RM				Levenson, Richard M.			Spectral imaging perspective on cytomics	CYTOMETRY PART A			English	Article						multispectral; imaging; immunohistochemistry; multiplexing; machine-learning	MORPHOMETRIC CHARACTERIZATION; MICROSCOPY; CLASSIFICATION; CELLS; DIFFERENTIATION; CARCINOMA; DIAGNOSIS; CYTOMETRY; NUCLEUS; CANCER	Background: Cytomics involves the analysis of cellular morphology and molecular phenotypes, with reference to tissue architecture and to additional metadata. To this end, a variety of imaging and nonimaging technologies need to be integrated. Spectral imaging is proposed as a tool that can simplify and enrich the extraction of morphological and molecular information. Simple-to-use instrumentation is available that mounts on standard microscopes and can generate spectral image datasets with excellent spatial and spectral resolution; these can be exploited by sophisticated analysis tools. Methods: This report focuses on brightfield microscopy-based approaches. Cytological and histological samples were stained using nonspecific standard stains (Giemsa; hematoxylin and eosin (H&E)) or immunohistochemical (IHC) techniques employing three chromogens plus a hematoxytin counterstain. The samples were imaged using the Nuance (TM) system, a commercially available, liquid-crystal tunable-filter-based multispectral imaging platform. The resulting data sets were analyzed using spectral unmixing algorithms and/or learn-by-example classification tools. Results: Spectral unmixing of Giemsa-stained guinea-pig blood films readily classified the major blood elements. Machine-learning classifiers were also successful at the same task, as well in distinguishing normal from malignant regions in a colon-cancer example, and in delineating regions of inflammation in an H&E-stained kidney sample. In an example of a multiplexed ICH sample, brown, red, and blue chromogens were isolated into separate images without crosstalk or interference from the (also blue) hematoxylin counterstain. Conclusion: Cytomics requires both accurate architectural segmentation as well as multiplexed molecular imaging to associate molecular phenotypes with relevant cellular and tissue compartments. Multispectral imaging can assist in both these tasks, and conveys new utility to brightfield-based microscopy approaches. (c) 2006 International Society for Analytical Cytology.	CRI, Woburn, MA 01801 USA	Levenson, RM (reprint author), CRI, Woburn, MA 01801 USA.	rlevenson@cri-inc.com					Angeletti C, 2005, LAB INVEST, V85, P1555, DOI 10.1038/labinvest.3700357; Barber PR, 2003, J PHYS D APPL PHYS, V36, P1729, DOI 10.1088/0022-3727/36/14/312; Barshack I, 1999, BRIT J CANCER, V79, P1613, DOI 10.1038/sj.bjc.6690257; Bearman G., 2003, BIOMEDICAL PHOTONICS, P81; Eckert RC, 2004, CYTOM PART A, V59A, P182, DOI 10.1002/cyto.a.20052; Ecker RC, 2004, CYTOM PART A, V59A, P172, DOI 10.1002/cyto.a.20053; Farkas DL, 1998, COMPUT MED IMAG GRAP, V22, P89, DOI 10.1016/S0895-6111(98)00011-1; Gao XH, 2002, J BIOMED OPT, V7, P532, DOI 10.1117/1.1506706; Greenspan H, 2002, HISTOL HISTOPATHOL, V17, P767; Harvey AR, 2004, P SOC PHOTO-OPT INS, V5612, P190, DOI 10.1117/12.580059; Hoffbeck JP, 1996, REMOTE SENS ENVIRON, V57, P119, DOI 10.1016/0034-4257(95)00138-7; HOYT C, 1996, BIOPHOTON INT, V3, P49; Hyman T, 2001, EXP HEMATOL, V29, P563, DOI 10.1016/S0301-472X(01)00616-6; Jimenez LO, 1998, IEEE T SYST MAN CY C, V28, P39, DOI 10.1109/5326.661089; Landgrebe D, 1999, INFORMATION PROCESSI, P3; LEVENSON FM, 1997, P SOC PHOTO-OPT INS, V2983, P123; Levenson R, 2003, P SOC PHOTO-OPT INS, V4959, P27, DOI 10.1117/12.485550; Levenson RM, 1998, P SOC PHOTO-OPT INS, V3438, P300, DOI 10.1117/12.328111; Levenson RM, 2000, AM LAB, V32, P26; LEVENSON RM, 1999, APPLICAT OPT ENGN ST, V2, P133; Lin G, 2005, CYTOM PART A, V63A, P20, DOI 10.1002/cyto.a.20099; MAGGIONI M, 2006, P SPIE, V6091; Mai KT, 1999, HISTOPATHOLOGY, V35, P567; Malik Z, 1998, J HISTOCHEM CYTOCHEM, V46, P1113; Mark H.L., 1985, ANAL CHEM, V57, P1449, DOI 10.1021/ac00284a061; Miller Peter J., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4259, DOI 10.1117/12.432485; Montironi R, 2003, HUM PATHOL, V34, P893, DOI 10.1016/S0046-8177(03)00341-1; Mutter GL, 2000, J PATHOL, V190, P462, DOI 10.1002/(SICI)1096-9896(200003)190:4<462::AID-PATH590>3.0.CO;2-D; NAPNIK VN, 1998, STAT LEARNING THEORY; Rothmann C, 1998, HISTOCHEM J, V30, P539, DOI 10.1023/A:1003235201563; Rothmann C, 1997, J HISTOCHEM CYTOCHEM, V45, P1097; Rothmann C, 2000, HISTOL HISTOPATHOL, V15, P1051; Sabbatini M, 2004, CELLS TISSUES ORGANS, V178, P139, DOI 10.1159/000082244; Sack U, 2004, CYTOM PART A, V60A, P189, DOI 10.1002/cyto.a.20002; Shafer-Peltier Karen E, 2002, J Cell Biochem Suppl, V39, P125; Van de Wouwer G, 2000, J MICROSC-OXFORD, V197, P25; Vapnik V. N, 1995, NATURE STAT LEARNING; Weyn B, 1999, J PATHOL, V189, P581, DOI 10.1002/(SICI)1096-9896(199912)189:4<581::AID-PATH464>3.0.CO;2-P; ZHOU R, 1997, MED PHYS, V23, P1977	39	25	26	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1552-4922		CYTOM PART A	Cytom. Part A	JUL	2006	69A	7					592	600		10.1002/cyto.a.20292		9	Biochemical Research Methods; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	063CH	WOS:000238993100006	
J	Cheng, JL; Sweredoski, MJ; Baldi, P				Cheng, Jianlin; Sweredoski, Michael J.; Baldi, Pierre			DOMpro: Protein domain prediction using profiles, secondary structure, relative solvent accessibility, and recursive neural networks	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						protein structure prediction; domain; recursive neural networks	DATABASE; RECOGNITION; DICTIONARY; ALIGNMENTS; SEQUENCES; GENOMES; SERVER	Protein domains are the structural and functional units of proteins. The ability to parse protein chains into different domains is important for protein classification and for understanding protein structure, function, and evolution. Here we use machine learning algorithms, in the form of recursive neural networks, to develop a protein domain predictor called DOMpro. DOMpro predicts protein domains using a combination of evolutionary information in the form of profiles, predicted secondary structure, and predicted relative solvent accessibility. DOMpro is trained and tested on a curated dataset derived from the CATH database. DOMpro correctly predicts the number of domains for 69% of the combined dataset of single and multi-domain chains. DOMpro achieves a sensitivity of 76% and specificity of 85% with respect to the single-domain proteins and sensitivity of 59% and specificity of 38% with respect to the two-domain proteins. DOMpro also achieved a sensitivity and specificity of 71% and 71% respectively in the Critical Assessment of Fully Automated Structure Prediction 4 (CAFASP-4) (Fisher et al., 1999; Saini and Fischer, 2005) and was ranked among the top ab initio domain predictors. The DOMpro server, software, and dataset are available at http://www.igb.uci.edu/servers/psss.html.	Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA	Cheng, JL (reprint author), Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA.	jianlinc@ics.uci.edu; msweredo@ics.uci.edu; pfbaldi@ics.uci.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bryson K, 2005, NUCLEIC ACIDS RES, V33, pW36, DOI 10.1093/nar/gki410; Cheng HL, 2005, COUNS PSYCHOL, V33, P72, DOI 10.1177/0011000004270343; CHENG J, 2005, IN PRESS DATA MINING; Chivian D, 2003, PROTEINS, V53, P524, DOI 10.1002/prot.10529; Fischer D, 1999, Proteins, VSuppl 3, P209; George RA, 2002, J MOL BIOL, V316, P839, DOI 10.1006/jmbi.2001.5387; GEWEHR JE, 2005, IN PRESS BIOINFORMAT; Heger A, 2003, J MOL BIOL, V328, P749, DOI 10.1016/S0022-2836(03)00269-9; Holm L, 1998, PROTEINS, V33, P88, DOI 10.1002/(SICI)1097-0134(19981001)33:1<88::AID-PROT8>3.0.CO;2-H; Holm L, 1998, NUCLEIC ACIDS RES, V26, P316, DOI 10.1093/nar/26.1.316; HOLM L, 1994, PROTEINS, V19, P256, DOI 10.1002/prot.340190309; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; LEVITT M, 1976, NATURE, V261, P552, DOI 10.1038/261552a0; Lexa M, 2003, BIOINFORMATICS, V19, P2486, DOI 10.1093/bioinformatics/btg350; Linding R, 2003, NUCLEIC ACIDS RES, V31, P3701, DOI 10.1093/nar/gkg519; Liu JF, 2004, NUCLEIC ACIDS RES, V32, P3522, DOI 10.1093/nar/gkh684; Marchler-Bauer A, 2003, NUCLEIC ACIDS RES, V31, P383, DOI 10.1093/nar/gkg087; Marsden RL, 2002, PROTEIN SCI, V11, P2814, DOI 10.1110/ps.0209902; Mika S, 2003, NUCLEIC ACIDS RES, V31, P3789, DOI 10.1093/nar/gkg620; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Nagarajan N, 2004, BIOINFORMATICS, V20, P1335, DOI 10.1093/bioinformatics/bth086; Orengo CA, 2002, PROTEOMICS, V2, P11, DOI 10.1002/1615-9861(200201)2:1<11::AID-PROT11>3.3.CO;2-K; Pollastri G, 2002, PROTEINS, V47, P142, DOI 10.1002/prot.10069; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Pollastri G, 2002, Bioinformatics, V18 Suppl 1, pS62; Przybylski D, 2002, PROTEINS, V46, P197, DOI 10.1002/prot.10029; Saini HK, 2005, BIOINFORMATICS, V21, P2917, DOI 10.1093/bioinformatics/bti445; von Ohsen N, 2004, BIOINFORMATICS, V20, P2228, DOI 10.1093/bioinformatics/bth232; Wheelan SJ, 2000, BIOINFORMATICS, V16, P613, DOI 10.1093/bioinformatics/16.7.613; Zdobnov EM, 2001, BIOINFORMATICS, V17, P847, DOI 10.1093/bioinformatics/17.9.847	34	33	34	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2006	13	1					1	10		10.1007/s10618-005-0023-5		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	052YG	WOS:000238269400001	
J	Maruster, L; Weijters, AJMM; Van der Aalst, WMP; Van den Bosch, A				Maruster, L; Weijters, AJMM; Van der Aalst, WMP; Van den Bosch, A			A rule-based approach for process discovery: Dealing with noise and imbalance in process logs	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						rule induction; process mining; knowledge discovery; Petri nets		Effective information systems require the existence of explicit process models. A completely specified process design needs to be developed in order to enact a given business process. This development is time consuming and often subjective and incomplete. We propose a method that constructs the process model from process log data, by determining the relations between process tasks. To predict these relations, we employ machine learning technique to induce rule sets. These rule sets are induced from simulated process log data generated by varying process characteristics such as noise and log size. Tests reveal that the induced rule sets have a high predictive accuracy on new data. The effects of noise and imbalance of execution priorities during the discovery of the relations between process tasks are also discussed. Knowing the causal, exclusive, and parallel relations, a process model expressed in the Petri net formalism can be built. We illustrate our approach with real world data in a case study.	Univ Groningen, NL-9700 AV Groningen, Netherlands; Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands; Tilburg Univ, NL-5000 LE Tilburg, Netherlands	Maruster, L (reprint author), Univ Groningen, POB 800, NL-9700 AV Groningen, Netherlands.	l.maruster@rug.nl; a.j.m.m.weijters@tm.tue.nl; w.m.p.v.d.aalst@tm.tue.nl; antal.vdnbosch@uvt.nl	weijters, ton/D-1779-2010; van den Bosch, Antal/G-5072-2011; van der Aalst, Wil/G-1248-2011	van den Bosch, Antal/0000-0003-2493-656X; van der Aalst, Wil/0000-0002-0955-6940			Agrawal R., 1998, 6 INT C EXT DAT TECH, P469; Cohen W. W., 1995, P 12 INT C MACH LEAR; Cook J. E., 1998, P 6 INT S FDN SOFTW, P35, DOI 10.1145/288195.288214; Cook J. E., 1998, ACM Transactions on Software Engineering and Methodology, V7, DOI 10.1145/287000.287001; de Medeiros A., 2004, BETA WORKING PAPER S; Herbst J., 2000, P 6 EUR CONC ENG C S, P175; HERBST J, 2000, ER CONC ENG C SOC CO; Herbst J., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, DOI 10.1002/1099-1174(200006)9:2<67::AID-ISAF186>3.0.CO;2-7; IDS SCHEER Whitepaper, 2002, ARIS PROC PERF MAN; Keller G., 1998, SAP R 3 PROCESS ORIE; MARUSTER L, 2002, P ECAI WORKSH KNOWL, P32; MARUSTER L, 2002, P 5 INT C DISC SCI D, V2534, P364; MITCHELL TM, 1995, MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Reisig W., 1998, LECT PETRI NETS; Van der Aalst WMP, 1998, J CIRCUIT SYST COMP, V8, P21, DOI 10.1142/S0218126698000043; van der Aalst W, 2004, IEEE T KNOWL DATA EN, V16, P1128, DOI 10.1109/TKDE.2004.47; van der Aalst WMP, 2003, DATA KNOWL ENG, V47, P237, DOI 10.1016/S0169-023X(03)00066-1; van der Aalst WMP, 2004, COMPUT IND, V53, P231, DOI 10.1016/j.compind.2003.10.001; VELD A, 2002, WFM EEN LAST EEN LUS; Weijters A., 2001, P 13 BELG NETH C ART, P283; Weiss S. M., 1998, PREDICTIVE DATA MINI; WEISS SM, 1991, COMPUTER SYSTEMS THA	23	14	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	JUL	2006	13	1					67	87		10.1007/s10618-005-0029-z		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	052YG	WOS:000238269400004	
J	Ahn, H; Kim, KJ; Han, IG				Ahn, H; Kim, KJ; Han, IG			Hybrid genetic algorithms and case-based reasoning systems for customer classification	EXPERT SYSTEMS			English	Article						case-based reasoning; genetic algorithms; feature weighting; instance selection; customer classification; customer relationship management	NEAREST-NEIGHBOR RULE; FEATURE-SELECTION; PROTOTYPE OPTIMIZATION	Because of its convenience and strength in complex problem solving, case-based reasoning (CBR) has been widely used in various areas. One of these areas is customer classification, which classifies customers into either purchasing or non-purchasing groups. Nonetheless, compared to other machine learning techniques, CBR has been criticized because of its low prediction accuracy. Generally, in order to obtain successful results from CBR, effective retrieval of useful prior cases for the given problem is essential. However, designing a good matching and retrieval mechanism for CBR systems is still a controversial research issue. Most previous studies have tried to optimize the weights of the features or the selection process of appropriate instances. But these approaches have been performed independently until now. Simultaneous optimization of these components may lead to better performance than naive models. In particular, there have been few attempts to simultaneously optimize the weights of the features and the selection of instances for CBR. Here we suggest a simultaneous optimization model of these components using a genetic algorithm. To validate the usefulness of our approach, we apply it to two real-world cases for customer classification. Experimental results show that simultaneously optimized CBR may improve the classification accuracy and outperform various optimized models of CBR as well as other classification models including logistic regression, multiple discriminant analysis, artificial neural networks and support vector machines.	Korea Adv Inst Sci & Technol, Grad Sch Management, Seoul 130722, South Korea; Dongguk Univ, Dept Management Informat Syst, Seoul 100715, South Korea	Ahn, H (reprint author), Korea Adv Inst Sci & Technol, Grad Sch Management, 207-43 Cheongrangri Dong, Seoul 130722, South Korea.	hcahn@kaist.ac.kr; kjkim@dongguk.edu; ighan@kgsm.kaist.ac.kr	Han, Ingoo/C-2031-2011				AHN H, 2003, P INT C KOR INT INF, P178; Babu T. R., 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Cardinal BJ, 1997, ADAPT PHYS ACT Q, V14, P65; Chiu CC, 2003, J INTELL MANUF, V14, P287, DOI 10.1023/A:1024693524603; Chiu CC, 2002, EXPERT SYST APPL, V22, P163, DOI 10.1016/S0957-4174(01)00052-5; Domingos P, 1997, ARTIF INTELL REV, V11, P227; HAN J IAW E I, 2001, DATAMINING CONCEPTS; Harnett D. L., 1991, STAT METHODS BUSINES; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Huang YS, 2002, PATTERN RECOGN, V35, P1237, DOI 10.1016/S0031-3203(01)00124-8; Jarmulak J, 2000, PROC INT C TOOLS ART, P376, DOI 10.1109/TAI.2000.889897; KEHOE C, 1998, 9 GVUS WWW USER SURV; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Kim KJ, 2001, EXPERT SYST APPL, V21, P139, DOI 10.1016/S0957-4174(01)00035-5; Kim KJ, 2004, APPL INTELL, V21, P239, DOI 10.1023/B:APIN.0000043557.93085.72; Kim SH, 2000, EXPERT SYST APPL, V18, P201, DOI 10.1016/S0957-4174(99)00062-7; Kolodner J.L., 1993, CASE BASED REASONING; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; LEE HY, 1999, KOREAN J MANAGEMENT, V27, P1239; Liao TW, 2000, ENG APPL ARTIF INTEL, V13, P199, DOI 10.1016/S0952-1976(99)00052-4; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Rozsypal A., 2003, Intelligent Data Analysis, V7; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Shin KS, 2002, EXPERT SYST APPL, V23, P321, DOI 10.1016/S0957-4174(02)00051-9; Shin KS, 1999, EXPERT SYST APPL, V16, P85, DOI 10.1016/S0957-4174(98)00063-3; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3; Turban E., 2001, DECISION SUPPORT SYS; Wang Y, 1997, EXPERT SYST APPL, V12, P89, DOI 10.1016/S0957-4174(96)00083-8; Watson I., 1997, APPL CASE BASED REAS; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; YAN H, 1993, PATTERN RECOGN, V26, P317, DOI 10.1016/0031-3203(93)90040-4; YIN WJ, 2002, P 1 INT C MACH LEARN, V2, P1683; Yu K., 2004, KNOWL INF SYST, V5, P201, DOI 10.1007/s10115-003-0089-6	38	15	16	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0266-4720		EXPERT SYST	Expert Syst.	JUL	2006	23	3					127	144		10.1111/j.1468-0394.2006.00329.x		18	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	050CV	WOS:000238066000001	
J	Chen, AP; Chen, MY				Chen, AP; Chen, MY			Integrating extended classifier system and knowledge extraction model for financial investment prediction: An empirical study	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						learning classifier system; extended classifier system; knowledge extraction; machine learning	GENETIC ALGORITHM; FUZZY	Machine learning methods such as fuzzy logic, neural networks and decision tree induction have been applied to learn rules, however they can get trapped into a local optimal. Based on the principle of natural evolution and global searching, a genetic algorithm is promising for obtaining better results. This article adopts the learning classifier systems (LCS) technique to provide a three-phase knowledge extraction methodology, which makes continues and instant learning while integrates multple rule sets into a centralized knowledge base. This paper makes three important contributions: (1) it represents various rule sets that are derived from different sources and encoded as a fixed-length bit string in the knowledge encoding phase; (2) it uses three criteria (accuracy, coverage, and fitness) to select an optimal set of rules from a large population in the knowledge extraction phase; (3) it applies genetic operations to generate optimal rule sets in the knowledge integration phase. The experiments prove that the rule sets derived by the proposed approach is more accurate than other machine learning algorithm. (c) 2005 Elsevier Ltd. All rights reserved.	Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 30050, Taiwan	Chen, MY (reprint author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 30050, Taiwan.	apc@iim.nctu.edu.tw; mychen@iim.nctu.edu.tw					Baral C., 1991, IEEE Transactions on Knowledge and Data Engineering, V3, DOI 10.1109/69.88001; BOOSE JH, 1987, INT J MAN MACH STUD, V26, P3, DOI 10.1016/S0020-7373(87)80032-9; Giarratano J.C., 1998, EXPERT SYSTEMS PRINC; Goldberg DE, 1989, GENETIC ALGORITHMS S; Hashemi RR, 1998, EUR J OPER RES, V109, P390, DOI 10.1016/S0377-2217(98)00065-4; Holland J. H., 1978, PATTERN DIRECTED INF, P313; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOLMES JH, 1996, THESIS DREXEL U PHIL; Kovalerchuk B., 2000, DATA MINING FINANCE; LIAO PY, 2001, P C EV COMP, P783; McIvor RT, 2004, EXPERT SYST APPL, V27, P533, DOI 10.1016/j.eswa.2004.05.020; Oh KJ, 2005, EXPERT SYST APPL, V28, P371, DOI 10.1016/j.eswa.2004.10.014; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Shin HW, 2003, EXPERT SYST APPL, V25, P63, DOI 10.1016/S0957-4174(03)00006-X; Stolzmann W., 2000, LECT NOTES ARTIF INT, V1813, P175, DOI 10.1007/3-540-45027-0_9; TRIPPI RR, 1992, J PORTFOLIO MANAGE, V19, P27, DOI 10.3905/jpm.1992.409432; Wang YF, 2003, EXPERT SYST APPL, V24, P13, DOI 10.1016/S0957-4174(02)00079-9; WILSON SW, 1996, EVOLUTIONARY COMPUTA, V3, P143; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z; Yuan YF, 1996, FUZZY SET SYST, V84, P1, DOI 10.1016/0165-0114(95)00302-9	20	10	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2006	31	1					174	183		10.1016/j.eswa.2005.09.030		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	034CY	WOS:000236903700020	
J	Nguyen, TT; Willis, CP; Paddon, DJ; Nguyen, SH; Nguyen, HS				Nguyen, Trung Thanh; Willis, Claire P.; Paddon, Derek J.; Nguyen, Sinh Hoa; Nguyen, Hung Son			Learning sunspot classification	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	Meeting on Concurrency Specification and Programming	SEP 28-30, 2005	Ruciana Nida, POLAND			sunspot classification; layered learning; rough sets; machine learning	RULE INDUCTION	Sunspots are the subject of interest to many astronomers and solar physicists. Sunspot observation, analysis and classification form an important part of furthering the knowledge about the Sun. Sunspot classification is a manual and very labor intensive process that could be automated if successfully learned by a machine. This paper presents machine learning approaches to the problem of sunspot classification. The classification scheme attempted was the seven-class Modified Zurich scheme [18]. The data was obtained by processing NASA SOHO/MDI satellite images to extract individual sunspots and their attributes. A series of experiments were performed on the training dataset with an aim of learning sunspot classification and improving prediction accuracy. The experiments involved using decision trees, rough sets, hierarchical clustering and layered learning methods. Sunspots were characterized by their visual properties like size, shape, positions, and were manually classified by comparing extracted sunspots with corresponding active region maps (ARMaps) from the Mees Observatory at the Institute for Astronomy, University of Hawaii.	Univ Bath, Dept Comp Sci, Bath BA2 7AY, Avon, England; Polish Japanese Inst Informat Technol, PL-02008 Warsaw, Poland; Warsaw Univ, Inst Math, PL-02095 Warsaw, Poland	Nguyen, TT (reprint author), Univ Bath, Dept Comp Sci, Bath BA2 7AY, Avon, England.		Nguyen, Hung Son /I-7452-2012; Nguyen, Sinh Hoa/G-8901-2013				Bazan J., 2001, LNAI, V2005; Bray R. J., 1964, SUNSPOTS; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gora G, 2002, FUND INFORM, V51, P369; Grzymala-Busse J. W., 1997, Fundamenta Informaticae, V31; HADJINIAN P, 1998, DISCOVERING DATA MIN; Kohavi R., 1998, MACHINE LEARNING, V30; LANGLEY P, 1995, COMMUN ACM, V38, P55; MCINTOSH PS, 1990, SOL PHYS, V125, P251, DOI 10.1007/BF00158405; NGUYEN SH, 2004, P KNOWL DISC ONT WOR; Nguyen SH, 2005, LECT NOTES ARTIF INT, V3642, P263; Nguyen SH, 2004, LECT NOTES COMPUT SC, V3100, P187; NGUYEN SH, 2005, ADV SOFT COMPUTING, P249; NGUYEN TT, 2005, ROUGH SET TECHNIQUES; Nguyen TT, 2004, ADV SOFT COMP, P59; Phillips K. J. H., 1992, GUIDE SUN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Scherrer PH, 1995, SOL PHYS, V162, P129, DOI 10.1007/BF00733429; Stone P., 2000, LAYERED LEARNING MUL; Witten I. H., 2000, DATA MINING PRACTICA	20	12	12	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	JUL-AUG	2006	72	1-3					295	309				15	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	085KM	WOS:000240603000022	
J	Bouchachia, A; Pedrycz, W				Bouchachia, A; Pedrycz, W			Enhancement of fuzzy clustering by mechanisms of partial supervision	FUZZY SETS AND SYSTEMS			English	Article						semi-supervised clustering; FCM; distance functions; quality of clustering; kernel-based distance; classification	ALGORITHMS; SHELLS	Semi-supervised (or partial) fuzzy clustering plays an important and unique role in discovering hidden structure in data realized in presence of a certain quite limited fraction of labeled patterns. The objective of this Study is to investigate and quantify the effect of various distance functions (distances) on the performance Of the Clustering mechanisms. The underlying goal of endowing the clustering algorithms with a higher level of flexibility is done via the use of various distances. The enhancement of this character is evaluated by means of a comprehensive assessment of quality of clusters, their ensuing discrimination abilities and the accuracy of clusters themselves. In addition to the standard Euclidean distance being commonly exploited in fuzzy clustering, three more versatile and adaptive distance measures are considered such as its weighted version, a full adaptive distance, and a kernel-based distance. Using Fuzzy C-Means (FCM) coming in its generic formal. we show its semi-supervised enhancements. derive detailed formulas and analyze their effectiveness. The improvements of semi-supervised clustering are empirically evaluated and numerically quantified with the use of several Machine Learning data sets. (C) 2006 Elsevier B.V. All rights reserved.	Univ Klagenfurt, Dept Informat, A-9020 Klagenfurt, Austria; Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada; Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland	Bouchachia, A (reprint author), Univ Klagenfurt, Dept Informat, Univ Str 65, A-9020 Klagenfurt, Austria.	hainid@isys.uni-klu.ac.at					AMINI MR, 2002, P 15 EUR C ART INT, P390; BEZDEK JC, 1985, IEEE T SYST MAN CYB, V15, P637; Basu S, 2002, P 19 INT C MACH LEAR, P19; BENSAID A, 1996, P 4 EUR C INT TECHN, P1402; Bezdek J. C., 1981, PATTERN RECOGNITION; BEZDEK JC, 1992, IEEE T NEURAL NETWOR, V3, P787, DOI 10.1109/72.159067; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; BOUCHACHIA A, 2004, P 10 INT C INF PROC, P2085; BOUCHACHIA A, 2003, P IFSA WORLD C, P328; DAVE R, 1990, INT J GEN SYST, P343; Demiriz A., 1999, INTELLIGENT ENG SYST, V9, P809; Duda R., 2000, PATTERN CLASSIFICATI; Frigui H, 1996, IEEE T FUZZY SYST, V4, P193, DOI 10.1109/91.493912; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GATH I, 1995, PATTERN RECOGN LETT, V16, P727, DOI 10.1016/0167-8655(95)00030-K; Ghani R., 2002, P 19 INT C MACH LEAR; Gustafson D. E., 1979, Proceedings of the 1978 IEEE Conference on Decision and Control Including the 17th Symposium on Adaptive Processes; Hoeppner F, 1997, IEEE T FUZZY SYST, V5, P599, DOI 10.1109/91.649912; KLINKENBERG R, 2001, P WORKSH LEARN TEMP, P16; KRISHNAPURAM R, 1995, IEEE T FUZZY SYST, V3, P44, DOI 10.1109/91.366570; KRISHNAPURAM R, 1992, IEEE T NEURAL NETWOR, V3, P663, DOI 10.1109/72.159056; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pedrycz W, 1997, IEEE T SYST MAN CY B, V27, P787, DOI 10.1109/3477.623232; Runkler T. A., 1996, Proceedings of the Fifth IEEE International Conference on Fuzzy Systems. FUZZ-IEEE '96 (Cat. No.96CH35998), DOI 10.1109/FUZZY.1996.552319; SCHOLKOPF B, 2000, NEURAL INFORM PROCES, V28, P781; Scholkopf B., 1999, ADV KERNEL METHODS S; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Vapnik V. N, 1995, NATURE STAT LEARNING; Zhong S, 2003, J MACHINE LEARNING R, V4, P1001, DOI 10.1162/jmlr.2003.4.6.1001	30	19	22	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JUL 1	2006	157	13					1733	1759		10.1016/j.fss.2006.02.015		27	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	054TS	WOS:000238402100001	
J	Zhang, CL; Lu, XS; Zhang, XG				Zhang, Chaolin; Lu, Xuesong; Zhang, Xuegong			Significance of gene ranking for classification of microarray samples	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						significance of gene ranking; gene selection; classification; microarray data analysis	DIFFERENTIALLY EXPRESSED GENES; BREAST-CANCER; STATISTICAL-METHODS; SELECTION; PROFILES; TUMOR	Many methods for classification and gene selection with microarray data have been developed. These methods usually give a ranking of genes. Evaluating the statistical significance of the gene ranking is important for understanding the results and for further biological investigations, but this question has not been well addressed for machine learning methods in existing works. Here, we address this problem by formulating it in the framework of hypothesis testing and propose a solution based on resampling. The proposed r-test methods convert gene ranking results into position p-values to evaluate the significance of genes. The methods are tested on three real microarray data sets and three simulation data sets with support vector machines as the method of classification and gene selection. The obtained position p-values help to determine the number of genes to be selected and enable scientists to analyze selection results by sophisticated multivariate methods under the same statistical inference paradigm as for simple hypothesis testing methods.	SUNY Stony Brook, Cold Spring Harbor Lab, Stony Brook, NY 11794 USA; SUNY Stony Brook, Dept Biomed Engn, Stony Brook, NY 11794 USA; Tsing Hua Univ, MOE Key Lab Bioinformat, Dept Automat, Beijing 100084, Peoples R China	Zhang, CL (reprint author), SUNY Stony Brook, Cold Spring Harbor Lab, Stony Brook, NY 11794 USA.	zhangc@cshl.edu; lxs97@mails.tsinghua.edu.cn; zhangxg@tsinghua.edu.cn					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Broberg P, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-6-r41; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Huang E, 2003, LANCET, V361, P1590, DOI 10.1016/S0140-6736(03)13308-9; Pan W, 2002, BIOINFORMATICS, V18, P546, DOI 10.1093/bioinformatics/18.4.546; Pepe MS, 2003, BIOMETRICS, V59, P133, DOI 10.1111/1541-0420.00016; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Sokal R.R., 1995, BIOMETRY; STOREY JD, 2003, P NATL ACAD SCI USA, V16, P9440; Tsai CA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng052; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang ZGC, 2004, CANCER RES, V64, P64, DOI 10.1158/0008-5472.CAN-03-2570; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Xiong MM, 2001, GENOME RES, V11, P1878; YU H, 2003, P 2003 IEEE BIOINF C; ZHANG X, 2001, RECURSIVE SAMPLE CLA; ZHANG X, 2000, P C GEN INF, P237	21	23	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JUL-SEP	2006	3	3					312	320				9	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	068MM	WOS:000239378400011	
J	Yeu, CWT; Lim, MH; Huang, GB; Agarwal, A; Ong, YS				Yeu, Chee-Wee Thomas; Lim, Meng-Hiot; Huang, Guang-Bin; Agarwal, Amit; Ong, Yew-Soon			A new machine learning paradigm for terrain reconstruction	IEEE GEOSCIENCE AND REMOTE SENSING LETTERS			English	Article						Delaunay triangulation; extreme learning machine; radial basis function (RBF) networks; support vector machine (SVM); terrain mapping		Terrain models that permit multiresolution access are essential for model predictive control of unmanned aerial vehicles in low-level flights. The authors present the extreme learning machine (ELM), a recently proposed learning paradigm, as a mechanism for learning the stored digital elevation information to allow multiresolution access. We give results of simulations designed to compare the performance of our approach with two other approaches for multiresolution access, namely: 1) linear interpolation on Delaunay triangles of the sampled terrain data points and 2) terrain learning using support vector machines (SVMs). The results show that to achieve the same mean square error during access, the memory needed in our approach is significantly lower. Additionally, the offline training time for the ELM network is much less than that for the SVM.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Yeu, CWT (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	emhlim@ntu.edu.sg	Huang, Guang-Bin/A-5035-2011; LIM, MH/A-5135-2011; Ong, YS/A-3733-2011				ARLAND M, 1995, CMUCS95181; Carr J.C., 2003, P ACM GRAPH 2003, P119; Carr J.C., 2001, P ACM SIGGRAPH 2001, P67, DOI DOI 10.1145/383259.383266; CHANG C. C., LIBSVM LIB SUPPORT V; Choset H., 2005, PRINCIPLES ROBOT MOT, P77; Drucker H, 1997, ADV NEUR IN, V9, P155; DUBINS LE, 1957, AM J MATH, V79, P497, DOI 10.2307/2372560; Fowler R. J., 1979, P SIGGRAPH 79 CHIC I, P199, DOI 10.1145/800249.807444; HUANG GB, 2004, P INT JOINT C NEUR N, P985; HUANG GB, 2005, IN PRESS IEEE T NEUR; HUANG GB, 2004, P INT C CONTR AUT RO, P1651; Huang YM, 2005, MULT SCLER, V11, P16, DOI 10.1191/1352458505ms1127oa; LEE C, 1991, J BRIT MUSIC THERAPY, V5, P3; Ortega JM, 1987, MATRIX THEORY; Renka RJ, 1996, ACM T MATH SOFTWARE, V22, P1, DOI 10.1145/225545.225546; Rippa S., 1990, Computer-Aided Geometric Design, V7, DOI 10.1016/0167-8396(90)90011-F; Ruffier F, 2005, ROBOT AUTON SYST, V50, P177, DOI 10.1016/j.robot.2004.09.016; Serre D., 2002, MATRICES THEORY APPL; Smola A. J., 1998, NC2TR1998030 U LOND	19	17	19	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1545-598X		IEEE GEOSCI REMOTE S	IEEE Geosci. Remote Sens. Lett.	JUL	2006	3	3					382	386		10.1109/LGRS.2006.873687		5	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	066XA	WOS:000239262600021	
J	Adeva, JJG; Calvo, R				Garcia Adeva, Juan Jose; Calvo, Rafael			Mining text with Pimiento	IEEE INTERNET COMPUTING			English	Article							FRAMEWORKS	To perform analysis, decision-making and knowledge management tasks, information systems use an increasing amount of unstructured information in the form of text. This data influx, in turn, has spawned a need to improve the text-mining technologies required for information retrieval, filtering, and classification. This article compares some of the options available. In particular, the authors focus on Pimiento, a new object-oriented application framework that lets developers create distributed applications that use machine-learning and statistical techniques to automatically process documents.	Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia; Univ Sydney, Web Engn Grp, Sydney, NSW 2006, Australia; Univ Sydney, Fac Engn, Sydney, NSW 2006, Australia	Adeva, JJG (reprint author), Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.	jjga@ee.usyd.edu.au; rafa@ee.usyd.edu.au					ADEVA JJG, 2006, P 7 INT C INF TECHN; Adeva J. J. G., 2005, Proceedings. Third International Conference on Information Technology and Applications; ADEVA JJG, 2006, IN PRESS INT J ARTIF; ALBI ST, 2003, ART SOFTWARE ARCHITE; Bontcheva K., 2002, Proceedings 13th International Workshop on Database and Expert Systems Applications. DEXA 2002; Cunningham H., 2002, P 40 ANN M ASS COMP; Debole F., 2004, P 4 INT C LANG RES E, P971; Fayad ME, 1997, COMMUN ACM, V40, P32, DOI 10.1145/262793.262798; FERRUCCI D, 2004, IBM SYSTEMS J, V43; Ferrucci D., 2004, Natural Language Engineering, DOI 10.1017/S1351324904003523; Hearst M., 1999, P 37 ANN M ASS COMP, P3, DOI DOI 10.3115/1034678.1034679; Johnson RE, 1997, COMMUN ACM, V40, P39, DOI 10.1145/262793.262799; MOORE C, 2002, INFOWORLD       1025; NYBERG E, 2001, P 1 INT C HUM LANG T, P1, DOI 10.3115/1072133.1072191; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647	15	8	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1089-7801		IEEE INTERNET COMPUT	IEEE Internet Comput.	JUL-AUG	2006	10	4					27	35				9	Computer Science, Software Engineering	Computer Science	061ZT	WOS:000238914300007	
J	Alhammady, H; Ramamohanarao, K				Alhammady, H; Ramamohanarao, K			Using emerging patterns to construct weighted decision trees	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						classification; data mining		Decision trees (DTs) represent one of the most important and popular solutions to the problem of classification. They have been shown to have excellent performance in the field of data mining and machine learning. However, the problem of DTs is that they are built using data instances assigned to crisp classes. In this paper, we generalize decision trees so that they can take into account weighted classes assigned to the training data instances. Moreover, we propose a novel method for discovering weights for the training instances. Our method is based on emerging patterns (EPs). EPs are those itemsets whose supports ( probabilities) in one class are significantly higher than their supports ( probabilities) in the other classes. Our experimental evaluation shows that the new proposed method has good performance and excellent noise tolerance.	Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic 3010, Australia	Alhammady, H (reprint author), Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic 3010, Australia.	hhammady@cs.mu.oz.au; rao@cs.mu.oz.au					ALHAMMADY H, 2004, P 2004 IEEE INT C DA; ALHAMMADY H, 2005, P 2005 SIAM INT C DA; ALHAMMADY H, 2004, P 2004 PAC AS C KNOW; Blake C., 1999, UCI REPOSITORY MACHI; DAMATO C, 2006, EXTENDING K NEAREST; DIETTERICH TG, 1998, J NEURAL COMPUTATION, V10; DONG G, 1999, P 1999 INT C KNOWL D; FAN H, 2003, P 14 AUSTR DAT C ADC; FAN H, 2003, P 4 INT C WEB AG INF; FAN H, 2002, P 2002 PAC AS C KNOW; Fawcett T., 2004, ROC GRAPHS NOTES PRA; Fayyad U. M., 1993, P 13 INT JOINT C ART; GUOZHU D, 1999, P 2 INT C DISC SCI D; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; LI W, 2001, P 2001 IEEE INT C DA; OLARU C, 2003, J FUZZY SETS SYSTEMS, V138; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Witten I. H., 1999, DATA MINING PRACTICA	19	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL	2006	18	7					865	876		10.1109/TKDE.2006.116		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	043CJ	WOS:000237576600001	
J	Chen, YQ; Yang, Q; Yin, J; Chai, XY				Chen, YQ; Yang, Q; Yin, J; Chai, XY			Power-efficient access-point selection for indoor location estimation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining in mobile wireless networks; power efficient computation		An important goal of indoor location estimation systems is to increase the estimation accuracy while reducing the power consumption. In this paper, we present a novel algorithm known as CaDet for power-efficient location estimation by intelligently selecting the number of Access Points (APs) used for location estimation. We show that by employing machine learning techniques, CaDet is able to use a small subset of the APs in the environment to detect a client's location with high accuracy. CaDet uses a combination of information theory, clustering analysis, and a decision tree algorithm. By collecting data and testing our algorithms in a realistic WLAN environment in the computer science department area of the Hong Kong University of Science and Technology, we show that CaDet ( Clustering and Decision Tree-based method) can be much higher in accuracy as compared to other methods. We also show through experiments that, by intelligently selecting APs, we are able to save the power on the client device while achieving the same level of accuracy.	Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Chen, YQ (reprint author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.	yqchen@ict.ac.cn; qyang@cs.ust.hk; yinjie@cs.ust.hk; chai@cs.purdue.edu	Yin, Jessie Jie/B-3850-2011				Bahl P., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), DOI 10.1109/INFCOM.2000.832252; Bahl P., 2000, ENHANCEMENTS RADAR U; Bhasker E. S., 2004, Proceedings. Second IEEE Annual Conference on Pervasive Computing and Communications; DELANEY B, 2004, THESIS GEORGIA I TEC; Duda R. O., 2001, PATTERN CLASSIFICATI; Ebert J.-P., 2002, P EUR WIR 2002 FLOR, P230; FOX D, 2002, IEEE PERVAS COMPUT, V2, P24; Gentile C., 2004, P IEEE INT C COMM, V3, P1360; GURUMURTHI S, 2003, ACM SIGARCH COMPUTER, V31; HASHEMI H, 1993, P IEEE, V81, P943, DOI 10.1109/5.231342; Heinzelman W.R., 2000, P HAW INT C SYST SCI, P1, DOI DOI 10.1109/HICSS.2000.926982; HONG I, 1996, P 1996 IEEE ACM INT, P10; Kravets R., 1998, P 4 INT C MOB COMP N, P157, DOI 10.1145/288235.288276; Ladd A., 2002, P 8 ANN INT C MOB CO, P227; LEE WC, 1996, J DISTRIBUTED PARALL, V4, P205; Lorch JR, 1997, WIREL NETW, V3, P311, DOI 10.1023/A:1019177822227; Mitchell T, 1997, MACHINE LEARNING; Ni LM, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P407, DOI 10.1109/PERCOM.2003.1192765; PAPERS AW, 2003, POWER CONSUMPTION EN; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Roos T., 2002, International Journal of Wireless Information Networks, V9, DOI 10.1023/A:1016003126882; Shivakumar N., 1996, ACM BALTZER MOBILE N, V1, P433; Stemm M, 1997, IEICE T COMMUN, VE80B, P1125; Weiser M., 1994, Proceedings of the First USENIX Symposium on Operating Systems Design and Implementation (OSDI); Xu Y., 2004, P IEEE INT C MOB DAT, P346; Xu Y., 2003, P 1 INT WORKSH MOB D, P434; Yin J, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P578; Youssef M., 2004, P COMM NETW DISTR SY; Youssef M., 2004, P IEEE INFOCOM 2003, V2, P1023; Youssef MA, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P143, DOI 10.1109/PERCOM.2003.1192736	30	38	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL	2006	18	7					877	888				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	043CJ	WOS:000237576600002	
J	Wu, QX; McGinnity, M; Bell, DA; Prasad, G				Wu, QX; McGinnity, M; Bell, DA; Prasad, G			A self-organizing computing network for decision-making in data sets with a diversity of data types	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						information technology and systems; decision support; machine learning; fuzzy sets	FUZZY NEURAL-NETWORK; DISCRETIZATION; SYSTEMS	A self-organizing computing network based on concepts of fuzzy conditions, beliefs, probabilities, and neural networks is proposed for decision-making in intelligent systems which are required to handle data sets with a diversity of data types. A sense-function with a sense-range and fuzzy edges is defined as a transfer function for connections from the input layer to the hidden layer in the network. By generating hidden cells and adjusting the parameters of the sense-functions, the network self-organizes and adapts to a training set. Computing cells in the input layer are designed as data converters so that the network can deal with both symbolic data and numeric data. Hidden computing cells in the network can be explained via fuzzy rules in a similar manner to those in fuzzy neural networks. The values in the output layer can be explained as a belief distribution over a decision space. The final decision is made by means of the winner-take-all rule. The approach was applied to a series of the benchmark data sets with a diversity of data types and comparative results obtained. Based on these results, the suitability of a range of data types for processing by different intelligent techniques was analyzed, and the results show that the proposed approach is better than other approaches for decision-making in information systems with mixed data types.	Queens Univ Belfast, Sch Comp Sci, Belfast BT7 1NN, Antrim, North Ireland; Univ Ulster, Sch Comp & Intelligent Syst, Londonderry BT48 7LJ, North Ireland	Wu, QX (reprint author), Queens Univ Belfast, Sch Comp Sci, Belfast BT7 1NN, Antrim, North Ireland.	q.wu@qub.ac.uk; TM.McGinnity@ulster.ac.uk; da.bell@qub.ac.uk; g.prasad@ulster.ac.uk					Chacron MJ, 2003, NATURE, V423, P77, DOI 10.1038/nature01590; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; COPPOCK S, 2003, P C FUZZ SYST FUZZ 0, V1, P25; Eden UT, 2004, NEURAL COMPUT, V16, P971, DOI 10.1162/089976604773135069; Gerstner W., 2002, SPIKING NEURON MODEL; HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500; JANG JSR, 1993, IEEE T NEURAL NETWOR, V4, P156, DOI 10.1109/72.182710; KASABOV N, 2003, EVOLCING CONNECTIONI; Kurgan LA, 2004, IEEE T KNOWL DATA EN, V16, P145, DOI 10.1109/TKDE.2004.1269594; Leng G, 2005, FUZZY SET SYST, V150, P211, DOI 10.1016/j.fss.2004.03.001; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Tung WL, 2002, IEEE T NEURAL NETWOR, V13, P1075, DOI 10.1109/TNN.2002.1031940; WU QX, 2005, INT J KNOWLEDGE INFO, V7, P246	15	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL	2006	18	7					941	953		10.1109/TKDE.2006.103		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	043CJ	WOS:000237576600007	
J	Perfetti, R; Ricci, E				Perfetti, Renzo; Ricci, Elisa			Analog neural network for support vector machine learning	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						analog circuits; quadratic optimization; recurrent neural networks; support vector machines	CONSTRAINTS	An analog neural network for support vector machine learning is proposed, based on a partially dual formulation of the quadratic programming problem. It results in a simpler circuit implementation with respect to existing neural solutions for the same application. The effectiveness of the proposed network is shown through some computer simulations concerning benchmark problems.	Univ Perugia, Dept Elect & Informat Engn, I-06125 Perugia, Italy	Perfetti, R (reprint author), Univ Perugia, Dept Elect & Informat Engn, I-06125 Perugia, Italy.	perfetti@diei.unipg.it; elisa.ricci@diei.unipg.it					Anguita D, 1998, ELECTRON LETT, V34, P1596, DOI 10.1049/el:19981092; Anguita D, 2002, IEEE T NEURAL NETWOR, V13, P1243, DOI 10.1109/TNN.2002.1031958; Anguita D, 2003, NEUROCOMPUTING, V55, P265, DOI 10.1016/S0925-2312(03)00382-5; Blake C. L., 1998, UCI REPOSITORY MACHI; BOUZERDOUM A, 1993, IEEE T NEURAL NETWOR, V4, P293, DOI 10.1109/72.207617; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cauwenberghs G., 2000, P ADV NEUR INF PROC, P409; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; FORTI M, 1995, IEEE T CIRCUITS-I, V42, P354, DOI 10.1109/81.401145; LaSalle J. P., 1976, STABILITY DYNAMICAL; SCHROEDER C, 1998, INSIDER ORCAD CAPTUR; TAN Y, 2000, P IEEE INT JOINT C N, P411; Xia YS, 2004, IEEE T SYST MAN CY B, V34, P1261, DOI 10.1109/TSMCB.2003.822955; Xia YS, 2005, IEEE T NEURAL NETWOR, V16, P379, DOI 10.1109/TNN.2004.841779; YANAI H, 1990, IEEE T CIRCUITS SYST, V37, P854, DOI 10.1109/31.55052; ZHANG SW, 1992, IEEE T CIRCUITS-II, V39, P441, DOI 10.1109/82.160169	16	15	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JUL	2006	17	4					1085	1091		10.1109/TNN.2006.875967		7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	061IN	WOS:000238865200023	
J	Oh, JH; Choi, KS				Oh, JH; Choi, KS			An ensemble of transliteration models for information retrieval	INFORMATION PROCESSING & MANAGEMENT			English	Article						machine transliteration; ensemble-based transliteration model; web data; information retrieval; machine learning		Transliteration is used to phonetically translate proper names and technical terms especially from languages in Roman alphabets to languages in non-Roman alphabets such as from English to Korean, Japanese, and Chinese. Because transliterations are usually representative index terms for documents, proper handling of the transliterations is important for an effective information retrieval system. However, there are limitations on handling transliterations depending on dictionary lookup, because transliterations are usually not registered in the dictionary. For this reason, many researchers have been trying to overcome the problem using machine transliteration. In this paper, we propose a method for improving machine transliteration using an ensemble of three different transliteration models. Because one transliteration model alone has limitation on reflecting all possible transliteration behaviors, several transliteration models should be complementary used in order to achieve a high-performance machine transliteration system. This paper describes a method about transliteration production using the several machine transliteration models and transliteration ranking with web data and relevance scores given by each transliteration model. We report evaluation results for our ensemble transliteration model and experimental results for its impact on IR effectiveness. Machine transliteration tests on English-to-Korean transliteration and English-to-Japanese transliteration show that our proposed method achieves 78-80% word accuracy. Information retrieval tests on KTSET and NTCIR-1 test collection show that our transliteration model can improve the performance of an information retrieval system about 10-34%. (c) 2005 Elsevier Ltd. All rights reserved.	Korea Adv Inst Sci & Technol, Korea Terminol Res Ctr Language & Knowledge Engn, KORTERM, Dept EECS,Comp Sci Div, Taejon 305701, South Korea	Oh, JH (reprint author), Natl Inst Informat & Commun Technol, Informat & Network Syst Dept, Computat Linguist Grp, 3-5 Hikaridai Seika Cho, Kyoto 6190289, Japan.	rovellia@nict.go.jp; kschoi@world.kaist.ac.kr	Choi, Key-Sun/C-1978-2011				AH DW, 1997, ARTIF INTELL, V11, P710; Aha D., 1991, MACH LEARN, V6, P3766; Al-Onaizan Y., 2002, P ACL 2002; Berger AL, 1996, COMPUT LINGUIST, V22, P39; BILAC S, 2004, P IJCNLP 2004, P542; BREEN J, 2003, EDICT JAPANESE ENGLI; BRILL E, 2001, NIST SPECIAL PUBLICA, P393; COLLIER N, 1997, P NAT LANG PROC PAC, P309; COVER TM, 1967, I ELECT ELECT ENG T, V13, P2127; DAELEMANS W, 2002, TIMBLE TIMBL TILBURG; Devijver P. A., 1982, PATTERN RECOGNITION; Fujii A, 2001, COMPUT HUMANITIES, V35, P389, DOI 10.1023/A:1011856202986; Goto I., 2003, P MT SUMM 9, VIX; GREFENSTETTE G, 1999, P ASLIB 99 TRANSL CO, V21; Jeong KS, 1999, INFORM PROCESS MANAG, V35, P523, DOI 10.1016/S0306-4573(98)00055-7; KANDO N, 1999, P 1 NTCIR WORKSH RES; KANG BJ, 2000, P 2 INT C LANG RES E; KANG BJ, 2001, THESIS COMPUTER SCI; KANG IH, 2000, P 18 INT C COMP LING; KIM JL, 1999, P KOR COGN SCI ASS; KNIGHT K, 1997, P 35 ANN M ASS COMP; KUO JS, 2004, PACLIC, V18; Lee J. S., 1998, COMPUTER PROCESSING, V12, P17; LEE JS, 1999, THESIS COMPUTER SCI; LI HZ, 2004, ACL, P159; LI Y, 2005, CORIA 2005 C; Lin Wei-Hao, 2002, P 6 C NAT LANG LEARN, P139; Manning C. D., 1999, FDN STAT NATURAL LAN; Mitchell T, 1997, MACHINE LEARNING; Miyao Y., 2002, P HUM LANG TECHN C H; NAM YS, 1997, FOREIGN DICT; OH JH, 2002, P COLING 2002; PARK YC, 1996, P 23 KISS SPRING C; PAUL O, 2001, P 10 TEXT RETR C TRE; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Salton G., 1989, AUTOMATIC TEXT PROCE; Tsuji K., 2002, International Journal of Computer Processing of Oriental Languages, V15, DOI 10.1142/S0219427902000649; Vapnik V. N, 1995, NATURE STAT LEARNING; Zhang L., 2004, MAXIMUM ENTROPY MODE; *CMU, 1997, CARN MELL U CMU PRON	41	3	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573		INFORM PROCESS MANAG	Inf. Process. Manage.	JUL	2006	42	4					980	1002		10.1016/j.ipm.2005.09.007		23	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	021ST	WOS:000236006600008	
J	Osei-Bryson, KM; Giles, K				Osei-Bryson, Kweku-Muata; Giles, Kendall			Splitting methods for decision tree induction: An exploration of the relative performance of two entropy-based families	INFORMATION SYSTEMS FRONTIERS			English	Article						decision trees; entropy; splitting methods; classification; machine learning	CLASSIFICATION TREES; CRITERIA	Decision tree (DT) induction is among the more popular of the data mining techniques. An important component of DT induction algorithms is the splitting method, with the most commonly used method being based on the Conditional Entropy (CE) family. However, it is well known that there is no single splitting method that will give the best performance for all problem instances. In this paper we explore the relative performance of the Conditional Entropy family and another family that is based on the Class-Attribute Mutual Information (CAMI) measure. Our results suggest that while some datasets are insensitive to the choice of splitting methods, other datasets are very sensitive to the choice of splitting methods. For example, some of the CAMI family methods may be more appropriate than the popular Gain Ratio (GR) method for datasets which have nominal predictor attributes, and are competitive with the GR method for those datasets where all predictor attributes are numeric. Given that it is never known beforehand which splitting method will lead to the best DT for a given dataset, and given the relatively good performance of the CAMI methods, it seems appropriate to suggest that splitting methods from the CAMI family should be included in data mining toolsets.	Virginia Commonwealth Univ, Informat Syst Res Inst, Richmond, VA 23284 USA	Osei-Bryson, KM (reprint author), Virginia Commonwealth Univ, Informat Syst Res Inst, Richmond, VA 23284 USA.	Kweku.Muata@isy.vcu.edu; KGiles@acm.org					Bradley PS, 1999, INFORMS J COMPUT, V11, P217, DOI 10.1287/ijoc.11.3.217; Breiman L, 1984, CLASSIFICATION REGRE; BRYSON KM, 2000, 2 FAMILIES ENTROPY B; Cheeseman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHING J, 1995, IEEE T PATTERN ANAL, V17, P631; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; Gersten W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347174; Martin JK, 1997, MACH LEARN, V28, P257, DOI 10.1023/A:1007367629006; Murphy P.M., 1994, UCI REPOSITORY MACHI; Piatetsky-Shapiro G, 1999, IEEE INTELL SYST APP, V14, P32, DOI 10.1109/5254.809566; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; Shih YS, 1999, STAT COMPUT, V9, P309, DOI 10.1023/A:1008920224518; TAYLOR PC, 1993, STAT COMPUT, V3, P147, DOI 10.1007/BF00141771; Wu XD, 1999, IEEE T KNOWL DATA EN, V11, P805	16	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1387-3326		INFORM SYST FRONT	Inf. Syst. Front.	JUL	2006	8	3					195	209		10.1007/s10796-006-8779-8		15	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	063DV	WOS:000238997400004	
J	Baca-Garcia, E; Perez-Rodriguez, MM; Basurte-Villamor, I; Saiz-Ruiz, J; Leiva-Murillo, JM; de Prado-Cumplido, M; Santiago-Mozos, R; Artes-Rodriguez, A; de Leon, J				Baca-Garcia, Enrique; Perez-Rodriguez, M. Mercedes; Basurte-Villamor, Ignacio; Saiz-Ruiz, Jeronimo; Leiva-Murillo, Jose M.; de Prado-Cumplido, Mario; Santiago-Mozos, Ricardo; Artes-Rodriguez, Antonio; de Leon, Jose			Using data mining to explore complex clinical decisions: A study of hospitalization after a suicide attempt	JOURNAL OF CLINICAL PSYCHIATRY			English	Article							PREVENTION; CARE	Background: Medical education is moving toward developing guidelines using the evidence-based approach; however, controlled data are missing for answering complex treatment decisions such as those made during suicide attempts. A new set of statistical techniques called data mining (or machine learning) is being used by different industries to explore complex databases and can be used to explore large clinical databases. Method: The study goal was to reanalyze, using data mining techniques a published study, of which variables predicted psychiatrists' decisions to hospitalize in 509 suicide attempters over the age of 18 years who were assessed in the emergency department. Patients were recruited for the study between 1996 and 1998. Traditional multivariate statistics were compared with data mining techniques to determine variables predicting hospitalization. Results: Five analyses done by psychiatric researchers using traditional statistical techniques classified 72% to 88% of patients correctly. The model developed by researchers with no psychiatric knowledge and employing data mining techniques used 5 variables (drug consumption during the attempt, relief that the attempt was not effective, lack of family support, being a housewife, and family history of suicide attempts) and classified 99% of patients correctly (99% sensitivity and 100% specificity). Conclusions: This reanalysis of a published study fundamentally tries to make the point that these new multivariate techniques, called data mining, can be used to study large clinical databases in psychiatry. Data mining techniques may be used to explore important treatment questions and outcomes in large clinical databases and to help develop guidelines for problems where controlled data are difficult to obtain. New opportunities for good clinical research may be developed by using data mining analyses.	Eastern State Hosp, UK Mental Hlth Res Ctr, Lexington, KY 40508 USA; Univ Autonoma Madrid, Dept Psychiat, Fdn Jimenez Diaz, Madrid, Spain; Univ Alcala de Henares, Hosp Ramon y Cajal, Alcala De Henares, Spain; Univ Carlos III Madrid, Dept Signal Theory & Commun, Madrid, Spain	de Leon, J (reprint author), Eastern State Hosp, UK Mental Hlth Res Ctr, 627 W 4th St, Lexington, KY 40508 USA.	jdeleon@uky.edu	Perez Rodriguez, Maria/B-9410-2013; de Leon, Jose/F-2709-2013	Perez Rodriguez, Maria/0000-0001-5137-1993; de Leon, Jose/0000-0002-7756-2314			American Psychiatric Association, 2003, AM J PSYCHIAT S, V160, P1; Baca-Garcia R, 2004, PSYCHIAT SERV, V55, P792; Beck A.T., 1974, PREDICTION SUICIDE, P45; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Choudhry NK, 2005, ANN INTERN MED, V142, P260; Fukunaga F., 1990, INTRO STAT PATTERN R; Gliatto MF, 1999, AM FAM PHYSICIAN, V59, P1500; Goodwin L, 2003, J BIOMED INFORM, V36, P379, DOI 10.1016/j.jbi.2003.09.020; GUNNELL D, 1994, BRIT MED J, V308, P1227; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hamilton NG, 2000, POSTGRAD MED, V108, P81; Hand DJ, 2000, STAT METHODS MED RES, V9, P305, DOI 10.1191/096228000701555172; Hider P., 1998, YOUTH SUICIDE PREVEN; Hirschfeld RMA, 1997, NEW ENGL J MED, V337, P910, DOI 10.1056/NEJM199709253371307; HIRSCHFELD RMA, 1996, PRIM PSYCHIAT, V3, P26; Hirschfeld RMA, 1998, HOSP PRACT, V33, P119; HIRSCHFELD RMA, 1998, HOSP PRACT, V33, P131; HIRSCHFELD RMA, 1998, HOSP PRACT, V33, P127; Hosmer DW, 2000, APPL LOGISTIC REGRES; Isacsson G, 2001, BRIT MED J, V322, P213, DOI 10.1136/bmj.322.7280.213; KACHUR SP, 1996, GUIDE CLIN PREVENTIV; KIRSTEIN L, 1975, AM J PSYCHIAT, V132, P22; MCNAMEE JE, 1996, CANADIAN TASK FORCE; MCNAMEE JE, 1994, CANADIAN GUIDE CLIN, P456; NHS. Centre for Reviews and dissemination, 1998, EFFECTIVE HLTH CARE, V4, P1; Nicholas L M, 2001, Clin Cornerstone, V3, P47, DOI 10.1016/S1098-3597(01)90061-4; OCarroll PW, 1996, SUICIDE LIFE-THREAT, V26, P237; Oosterhuis WP, 2004, CLIN CHEM, V50, P806, DOI 10.1373/clinchem.2003.025528; Rihmer Z, 2002, CURR OPIN PSYCHIATR, V15, P83, DOI 10.1097/00001504-200201000-00014; Shaffer D, 2001, J AM ACAD CHILD PSY, V40, p24S; Smyth P, 2000, STAT METHODS MED RES, V9, P309, DOI 10.1191/096228000701555181; Tukey J., 1977, EXPLORATORY DATA ANA; Vapnik VN, 1998, STAT LEARNING THEORY; World Health Organization, 2000, MENT BEH DIS; *MAG BEH HTLH CLIN, 2000, CLIN PRACT GUID ASS; *ROYAL COLL PSYCH, 1992, GEN HOSP MAN AD DEL; *ROYAL NZ COLL GEN, 1998, GUID PRIM CAR PROV D; *SUIC RISK ADV COM, 1996, GUID ID ASS TREATM P; 2000, NAT BIOTECHNOL S, V18, pIT35	39	18	18	PHYSICIANS POSTGRADUATE PRESS	MEMPHIS	P O BOX 240008, MEMPHIS, TN 38124 USA	0160-6689		J CLIN PSYCHIAT	J. Clin. Psychiatry	JUL	2006	67	7					1124	1132				9	Psychology, Clinical; Psychiatry	Psychology; Psychiatry	070TU	WOS:000239548300016	
J	Cheng, XQ; Tan, SB; Tang, L				Cheng, Xueqi; Tan, Songbo; Tang, Lilian			Using DragPushing to refine concept index for text categorization	JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY			English	Article						text classification; information retrieval; machine learning	PCA	Concept index (CI) is a very fast and efficient feature extraction (FE) algorithm for text classification. The key approach in CI scheme is to express each document as a function of various concepts (centroids) present in the collection. However, the representative ability of centroids for categorizing corpus is often influenced by so-called model misfit caused by a number of factors in the FE process including feature selection to similarity measure. In order to address this issue, this work employs the "DragPushing" Strategy to refine the centroids that are used for concept index. We present an extensive experimental evaluation of refined concept index (RCI) on two English collections and one Chinese corpus using state-of-the-art Support Vector Machine (SVM) classifier. The results indicate that in each case, RCI-based SVM yields a much better performance than the normal CI-based SVM but lower computation cost during training and classification phases.	Chinese Acad Sci, Inst Comp Technol, Div Intelligent Software Syst, Beijing 100080, Peoples R China; Univ Surrey, Dept Comp, Surrey, England	Cheng, XQ (reprint author), Chinese Acad Sci, Inst Comp Technol, Div Intelligent Software Syst, Beijing 100080, Peoples R China.	cxq@ict.ac.cn; tansongbo@software.ict.ac.cn; h.tang@surrey.ac.uk	Cheng, Xueqi/F-1706-2010; Tan, Songbo/A-7450-2012				Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Gilad-Bachrach R., 2004, 21 INT C MACH LEARN, P43, DOI 10.1145/1015330.1015352; Han E.-H., 2000, 4 EUR C PRINC PRACT, P424; HARDIN D, 2004, 21 INT C MACH LEARN, P48, DOI 10.1145/1015330.1015421; Joachims T., 1998, 10 EUR C MACH LEARN, P137; JOLLIFFE IT, 1986, PRINICPAL COMPONENT; KARYPIS G, 2000, 9 ACM INT C INF KNOW, P12; Lewis D.D., 1998, 10 EUR C MACH LEARN, P4; Li H., 2004, P C ADV NEUR INF PRO, P97; Liu H., 1998, FEATURE EXTRACTION C; Malhi A, 2004, IEEE T INSTRUM MEAS, V53, P1517, DOI 10.1109/TIM.2004.834070; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Rijsbergen C.J.V., 1979, INFORM RETRIEVAL; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Salton G., 1983, INTRO MODERN RETRIEV; TAN SB, 2005, 14 ACM INT C INF KNO, P469; VANMUN PPT, TEXT CLASSIFICATION; Yang Y, 1999, 22 ANN INT ACM SIGIR, P42; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412	20	0	0	SCIENCE CHINA PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1000-9000		J COMPUT SCI TECHNOL	J. Comput. Sci. Technol.	JUL	2006	21	4					592	596		10.1007/s11390-006-0592-9		5	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Computer Science	066UI	WOS:000239255200017	
J	Zhao, HM; Sinha, AP; Ram, S				Zhao, Huimin; Sinha, Atish P.; Ram, Sudha			Elitist and ensemble strategies for cascade generalization	JOURNAL OF DATABASE MANAGEMENT			English	Article						cascade generalization; data mining; decision tree; elitist strategy; ensemble method; voting method	NEURAL-NETWORKS; DECISION TREES	Several methods have been proposed for cascading other classification algorithms with decision tree learners to alleviate the representational bias of decision trees and, potentially, to improve classification accuracy. Such cascade generalization of decision trees increases the flexibility of the decision boundaries between classes and promotes better fitting of the training data. However more flexible models may not necessarily lead to more predictive power. Because of polential overfitting problems, the true classification accuracy on test data may not increase. Recently, a generic method for cascade generalization has been proposed. The method uses a parameter-the maximum cascading depth-to constrain the degree that other classification algorithms are cascaded with decision tree learners. A method for efficiently learning a collection (i.e., a forest) of generalized decision trees, each with other classification algorithms cascaded to a particular depth, also has been developed In this article, we propose several new strategies, including elitist and ensemble (weighted or unweighted), for using the various decision trees in such a collection in the prediction phase. Our empirical evaluation using 32 data sets in the UCI machine learning repository shows that, on average, the elitist strategy outperforms the weighted full ensemble strategy, which, in turn, outperforms the unweighted full ensemble strategy. However no strategy is universally superior across all applications. Since the same training process can be used to evaluate the various strategies, we recommend that several promising strategies be evaluated and compared before selecting the one to use for a given application.	Univ Wisconsin, Milwaukee, WI 53201 USA; Univ Arizona, Tucson, AZ 85721 USA	Zhao, HM (reprint author), Univ Wisconsin, Milwaukee, WI 53201 USA.						Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bioch JC, 1997, LECT NOTES ARTIF INT, V1263, P232; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Cohen J, 1977, STAT POWER ANAL BEHA; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Doumpos M, 2002, EUR J OPER RES, V138, P392, DOI 10.1016/S0377-2217(01)00254-5; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gama J., 1999, P 16 INT C MACH LEAR, P134; Gama J, 2000, MACH LEARN, V41, P315, DOI 10.1023/A:1007652114878; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Heath D., 1993, P 13 INT JOINT C ART, P1002; Hosmer DW, 2000, APPL LOGISTIC REGRES; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; JOHN GH, 1996, LEARNING DATA ARTIFI, P375; Kim C. N., 1999, J MANAGEMENT INFORMA, V16, P189; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Lam M, 2004, DECIS SUPPORT SYST, V37, P567, DOI 10.1016/S0167-9236(03)00088-5; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Osei-Bryson KM, 2004, J DATABASE MANAGE, V15, P1, DOI 10.4018/jdm.2004070101; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; Rajagopalan B., 2002, Journal of Database Management, V13, DOI 10.4018/jdm.2002010103; Sarkar S, 2001, MANAGE SCI, V47, P1457, DOI 10.1287/mnsc.47.11.1457.10253; Sinha A.P., 2005, J MANAGEMENT INFORM, V21, P249; Sung T.K., 1999, J MANAGE INFORM SYST, V16, P63; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Witten I. H., 2000, DATA MINING PRACTICA; WOLPERT DH, 1994, P SFI CNLS WORKSH FO, P117; Yildiz O.T., 2000, P 17 INT C MACH LEAR, P1175; Zhao H, 2005, IEEE T SYST MAN CY A, V35, P754, DOI 10.1109/TSMCA.2005.843392; ZHAO H, 2004, IEEE T KNOWL DATA EN, V6, P727; Zhu D, 2001, DECISION SCI, V32, P635, DOI 10.1111/j.1540-5915.2001.tb00975.x	37	1	1	IGI PUBL	HERSHEY	701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA	1063-8016		J DATABASE MANAGE	J. Database Manage.	JUL-SEP	2006	17	3					92	107		10.4018/jdm.2006070105		16	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	043QI	WOS:000237616000006	
J	Chau, KW				Chau, KW			A review on the integration of artificial intelligence into coastal modeling	JOURNAL OF ENVIRONMENTAL MANAGEMENT			English	Article						artificial intelligence; coastal modeling; knowledge-based systems	2-DIMENSIONAL TIDAL FLOW; NEURAL-NETWORK APPROACH; WATER-QUALITY MODELS; PEARL-RIVER ESTUARY; EXPERT-SYSTEM; GENETIC ALGORITHMS; HONG-KONG; RETAINING STRUCTURES; ALGAL BLOOMS; TOLO-HARBOR	With the development of computing technology, mechanistic models are often employed to simulate processes in coastal environments. However, these predictive tools are inevitably highly specialized, involving certain assumptions and/or limitations, and can be manipulated only by experienced engineers who have a thorough understanding of the underlying theories. This results in significant constraints on their manipulation as well as large gaps in understanding and expectations between the developers and practitioners of a model. The recent advancements in artificial intelligence (AI) technologies are making it possible to integrate machine learning capabilities into numerical modeling systems in order to bridge the gaps and lessen the demands on human experts. The objective of this paper is to review the state-of-the-art in the integration of different AI technologies into coastal modeling. The algorithms and methods studied include knowledge-based systems, genetic algorithms, artificial neural networks, and fuzzy inference systems. More focus is given to knowledge-based systems, which have apparent advantages over the others in allowing more transparent transfers of knowledge in the use of models and in furnishing the intelligent manipulation of calibration parameters. Of course, the other AI methods also have their individual contributions towards accurate and reliable predictions of coastal processes. The integrated model might be very powerful, since the advantages of each technique can be combined. (c) 2005 Elsevier Ltd. All rights reserved.	Hong Kong Polytech Univ, Dept Civil & Struct Engn, Kowloon, Hong Kong, Peoples R China	Chau, KW (reprint author), Hong Kong Polytech Univ, Dept Civil & Struct Engn, Kowloon, Hong Kong, Peoples R China.	cekwchau@polyu.edu.hk	Chau, Kwok-wing/E-5235-2011				Abbott M, 1991, HYDROINFORMATICS INF; ABBOTT MB, 1989, HYDRAULIC AND ENVIRONMENTAL MODELLING OF COASTAL, ESTUARINE AND RIVER WATERS, P3; ABBOTT MB, 1993, ADV WATER RESOUR, V16, P21, DOI 10.1016/0309-1708(93)90027-D; BAIRD JI, 1992, WATER QUALITY MODELLING, P119; Barciela RM, 1999, ECOL MODEL, V120, P199, DOI 10.1016/S0304-3800(99)00102-7; Bastarache D, 1997, CAN J CIVIL ENG, V24, P1030, DOI 10.1139/cjce-24-6-1030; BLANPAIN O, 1994, HYDROINFORMATICS 94; Blumberg AF, 1999, J HYDRAUL ENG-ASCE, V125, P799, DOI 10.1061/(ASCE)0733-9429(1999)125:8(799); Bobba AG, 2000, ECOL MODEL, V125, P15, DOI 10.1016/S0304-3800(99)00175-1; Bobbin J, 2001, ENVIRON INT, V27, P237, DOI 10.1016/S0160-4120(01)00095-2; Chang NB, 2001, J ENVIRON MANAGE, V63, P293, DOI 10.1006/jema.2001.0483; Chau KW, 2005, LECT NOTES COMPUT SC, V3498, P1034; Chau K., 2002, LECT NOTES ARTIF INT, V2557, P720; Chau KW, 2001, APPL MATH MODEL, V25, P887, DOI 10.1016/S0307-904X(01)00020-8; CHAU KW, 1995, INT J NUMER METH FL, V21, P1087, DOI 10.1002/fld.1650211106; CHAU KW, 1993, ADV ENG SOFTW, V17, P165, DOI 10.1016/0965-9978(93)90076-6; Chau K.W., 2002, LECT NOTES ARTIF INT, V2557, P715; Chau KW, 1996, J WATER SUPPLY RES T, V45, P96; Chau KW, 2004, APPL MATH MODEL, V28, P849, DOI 10.1016/j.apm.2004.04.002; Chau KW, 1996, APPL MATH MODEL, V20, P321, DOI 10.1016/0307-904X(95)00127-6; CHAU KW, 1991, ADV WATER RESOUR, V14, P106, DOI 10.1016/0309-1708(91)90001-5; Chau KW, 2002, EXPERT SYST APPL, V22, P169, DOI 10.1016/S0957-4174(01)00053-7; Chau KW, 1998, J ENVIRON ENG-ASCE, V124, P628, DOI 10.1061/(ASCE)0733-9372(1998)124:7(628); CHAU KW, 1992, ENG APPL ARTIF INTEL, V5, P363, DOI 10.1016/0952-1976(92)90044-K; CHAU KW, 1995, ADV ENG SOFTW, V22, P139, DOI 10.1016/0965-9978(95)00026-S; Chau KW, 2002, EXPERT SYST APPL, V22, P321, DOI 10.1016/S0957-4174(02)00020-9; Chau KW, 2003, J STRUCT ENG-ASCE, V129, P1312, DOI 10.1061/(ASCE)0733-9445(2003)129:10(1312); Chau KW, 2001, J HYDRAUL ENG-ASCE, V127, P72, DOI 10.1061/(ASCE)0733-9429(2001)127:1(72); Chau KW, 2001, ADV ENG SOFTW, V32, P695, DOI 10.1016/S0965-9978(01)00023-0; Chau KW, 2003, ENVIRON MODELL SOFTW, V18, P99, DOI 10.1016/S1364-8152(02)00072-5; Chau KW, 2002, WATER RES, V36, P2029, DOI 10.1016/S0043-1354(01)00400-6; Chen QW, 2003, ECOL MODEL, V162, P55, DOI 10.1016/S0304-3800(02)00389-7; Cheng CT, 2001, J AM WATER RESOUR AS, V37, P1381, DOI 10.1111/j.1752-1688.2001.tb03646.x; CHENG RT, 1984, WATER RESOUR RES, V20, P944, DOI 10.1029/WR020i007p00944; Cho JH, 2004, J ENVIRON MANAGE, V73, P229, DOI 10.1016/j.jenvman.2004.07.004; Cheng CT, 2002, J HYDROL, V268, P72, DOI 10.1016/S0022-1694(02)00122-1; CUNGE J, 1989, HYDRAULIC ENV MODELL; GARRETT JH, 1994, J COMPUT CIVIL ENG, V8, P129, DOI 10.1061/(ASCE)0887-3801(1994)8:2(129); Goldberg DE, 1989, GENETIC ALGORITHMS S; Jamieson DG, 1996, J HYDROL, V177, P163, DOI 10.1016/0022-1694(95)02957-5; Karul C, 2000, ECOL MODEL, V134, P145, DOI 10.1016/S0304-3800(00)00360-4; KNIGHT B, 1992, ENG APPL ARTIF INTEL, V5, P51, DOI 10.1016/0952-1976(92)90097-4; Kralisch S, 2003, ENVIRON MODELL SOFTW, V18, P815, DOI 10.1016/S1364-8152(03)00081-1; Leendertse J. J., 1967, RM5294PR RAND CORP; RUMELHART DE, 1994, COMMUN ACM, V37, P87, DOI 10.1145/175247.175256; Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7; Liou SM, 2003, WATER RES, V37, P1406, DOI 10.1016/S0043-1354(02)00479-7; Maier HR, 2004, ENVIRON MODELL SOFTW, V19, P485, DOI 10.1016/S1364-8152(03)00163-4; Maier HR, 1998, ECOL MODEL, V105, P257, DOI 10.1016/S0304-3800(97)00161-0; Maier HR, 1997, MATH COMPUT SIMULAT, V43, P377, DOI 10.1016/S0378-4754(97)00022-0; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; Marsili-Libelli S, 2004, ENVIRON MODELL SOFTW, V19, P799, DOI 10.1016/j.envsoft.2003.03.008; MARTIN TL, 1999, HYDRODYNAMICS TRANSP; Mulligan AE, 1998, J ENVIRON ENG-ASCE, V124, P202, DOI 10.1061/(ASCE)0733-9372(1998)124:3(202); Ng AWM, 2003, ENG APPL ARTIF INTEL, V16, P529, DOI 10.1016/j.engappai.2003.09.001; Ragas A.M.J., 1997, EUR WATER POLLUT CON, V7, P59; Recknagel Friedrich, 1998, Lakes Reservoirs Research and Management, V3, P123, DOI 10.1111/j.1440-1770.1998.tb00039.x; RECKNAGEL F, 1994, ECOL MODEL, V71, P17, DOI 10.1016/0304-3800(94)90074-4; Serodes JB, 1996, J WATER SUPPLY RES T, V45, P57; Silvert W, 1997, ECOL MODEL, V96, P1, DOI 10.1016/S0304-3800(96)00051-8; TUCCIARELLI T, 2000, J HYDRAUL ENG-ASCE, V126, P418; Uzel A. R., 1988, Engineering Applications of Artificial Intelligence, V1, DOI 10.1016/0952-1976(88)90005-X; Whitehead PG, 1997, HYDROBIOLOGIA, V349, P39, DOI 10.1023/A:1003089310834; Yabunaka K, 1997, WATER SCI TECHNOL, V36, P89, DOI 10.1016/S0273-1223(97)00464-2; Yu L, 2001, ADV ENG SOFTW, V32, P375, DOI 10.1016/S0965-9978(00)00100-9; Zadeh L., 1992, FUZZY LOGIC MANAGEME; Zou R, 2002, J COMPUT CIVIL ENG, V16, P135, DOI 10.1061/(ASCE)0887-3801(2002)16:2(135); *RUL MACH CORP, 1998, US GUID VIS RUL STUD	68	11	11	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0301-4797		J ENVIRON MANAGE	J. Environ. Manage.	JUL	2006	80	1					47	57		10.1016/j.jenvman.2005.08.012		11	Environmental Sciences; Environmental Studies	Environmental Sciences & Ecology	055XI	WOS:000238484100005	
J	Galitsky, B				Galitsky, Boris			Merging deductive and inductive reasoning for processing textual descriptions of inter-human conflicts	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						hybrid reasoning system; multiagent conflict; reasoning about action; deterministic machine learning	SITUATION CALCULUS	We report on a novel approach to modeling a dynamic domain with limited knowledge. A domain may include participating agents where we are uncertain about motivations and decision-making principles of some of these agents. Our reasoning setting for such domains includes deductive, inductive, and abductive components. The deductive component is based on situation calculus and describes the behavior of agents with complete information. The machine learning-based inductive and abductive components involve the previous experience with the agents, whose actions are uncertain to the system. Suggested reasoning machinery is applied to the problem of processing customer complaints in the form of textual messages that contain a multiagent conflict. The task is to predict the future actions of an opponent agent to determine the required course of action to resolve a multiagent conflict. This study demonstrates that the hybrid reasoning approach outperforms both stand-alone deductive and inductive components. Suggested methodology reflects the general situation of reasoning in dynamic domains in the conditions of uncertainty, merging analytical ( rule-based) and analogy-based reasoning.	Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HFX, England	Galitsky, B (reprint author), Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, Malet St, London WC1E 7HFX, England.	galitsky@dcs.bbk.ac.uk					ANSHAKOV OM, 1989, STUDIA LOGICA, V42, P423; Bacchus F, 1999, ARTIF INTELL, V111, P171, DOI 10.1016/S0004-3702(99)00031-4; BARBER KS, 2001, FRAUD DECEPTION TRUS; CIRAVEGNA F, 2000, ECAI 2000 WORKSH MAC; Davey B.A., 2002, INTRO LATTICES ORDER; DERAEDT L, 1999, LOGIC PROGRAMMING PA; FAGIN R, 1994, J ACM, V41, P340, DOI 10.1145/174652.174658; Fagin R., 1995, REASONING KNOWLEDGE; FINN VK, 1999, NTI SERIES, V2, P8; FURUKAWA K, 1998, LOGIC PROGRAMMING PA; GALITSKY B, 2004, FLAIRS 04 MAY 16 18; GALITSKY B, 2001, LECT NOTES ARTIF INT, V2070, P874; GALITSKY B, 2003, FLAIRS 03 MAY 12 14; GALITSKY B, 2004, P 17 INT FLOR ART IN; Galitsky B, 2003, LECT NOTES ARTIF INT, V2718, P21; GALITSKY B, 2003, P 2003 UK WORKSH COM, P123; Galitsky B, 2003, ADV KNOWLEDGE INT; Ganter B., 1999, MATH FDN; GROSSKREUTZ H, 2003, FUNDAMENTA INFORM, V57, P67; KUZNETSOV SO, 2004, INT C FORM CONC AN, P287; LAKEMEYER G, 1999, LOGICAL FDN COGNITIV; Lavrac N., 1994, INDUCTIVE LOGIC PROG; LEAKE DB, 1997, 14 INT JOINT C ART I; Levesque HJ, 1997, J LOGIC PROGRAM, V31, P59, DOI 10.1016/S0743-1066(96)00121-5; LEVESQUE HL, 2000, P 2 INT COGN ROB WOR, P21; LIU TH, 1997, 5 IASTED INT C ROB M; MCCARTHY J, 2002, 8 INT C PRINC KNOWL; MUELLER ET, 2004, P 17 INT FLOR ART IN; MUGGLETON S., 1992, INDUCTIVE LOGIC PROG; MUGGLETON S, 1999, INDUCTIVE LOGIC PROG; NIKOLOPOULOS C, 1994, APPL INFORM, P61; PATTISONGORDON E, 1996, SMI960628 STANF U; REITER R, 1993, ARTIF INTELL, V64, P337, DOI 10.1016/0004-3702(93)90109-O; Reynolds J.C., 1970, MACH INTELL, V5; Shanahan M., 1997, SOLVING FRAME PROBLE; Singh P., 2003, P 2 INT C KNOWL CAPT; SOUCHANSKY M, 2001, IJCAI 01; VINOGRADOV DV, 1999, NTI SERIES, V2, P61; WOOLDRIDGE M, 2002, REASONING RATIONAL A	39	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	JUL	2006	27	1					21	48		10.1007/s10844-006-1641-0		28	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	082HT	WOS:000240378000002	
J	Bennett, KP; Parrado-Hernandez, E				Bennett, Kristin P.; Parrado-Hernandez, Emilio			The interplay of optimization and machine learning research	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						machine learning; mathematical programming; convex optimization	CLASSIFICATION; BENCHMARKING	The fields of machine learning and mathematical programming are increasingly intertwined. Optimization problems lie at the heart of most machine learning approaches. The Special Topic on Machine Learning and Large Scale Optimization examines this interplay. Machine learning researchers have embraced the advances in mathematical programming allowing new types of models to be pursued. The special topic includes models using quadratic, linear, second-order cone, semi-definite, and semi-infinite programs. We observe that the qualities of good optimization algorithms from the machine learning and optimization perspectives can be quite different. Mathematical programming puts a premium on accuracy, speed, and robustness. Since generalization is the bottom line in machine learning and training is normally done off-line, accuracy and small speed improvements are of little concern in machine learning. Machine learning prefers simpler algorithms that work in reasonable computational time for specific classes of problems. Reducing machine learning problems to well-explored mathematical programming classes with robust general purpose optimization codes allows machine learning researchers to rapidly develop new techniques. In turn, machine learning presents new challenges to mathematical programming. The special issue include papers from two primary themes: novel machine learning models and novel optimization approaches for existing models. Many papers blend both themes, making small changes in the underlying core mathematical program that enable the develop of effective new algorithms.	Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12018 USA; Univ Carlos III Madrid, Dept Signal Proc & Commun, Madrid 28911, Spain	Bennett, KP (reprint author), Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12018 USA.	BENNEK@RPI.EDU; EMIPAR@TSC.UC3M.ES					Bach Francis R., 2004, P 21 INT C MACH LEAR; Bazaraa MS, 2006, NONLINEAR PROGRAMMIN; Bennett K. P., 1993, Computational Optimization and Applications, V2, DOI 10.1007/BF01299449; Bergkvist A, 2006, J MACH LEARN RES, V7, P1339; Bertsekas D.P, 2004, NONLINEAR PROGRAMMIN; Bishop C., 1996, NEURAL NETWORKS PATT; Boyd S, 2004, CONVEX OPTIMIZATION; Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); Bradley PS, 1997, ADV NEUR IN, V9, P368; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; De Bie T, 2006, J MACH LEARN RES, V7, P1409; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dolan ED, 2002, MATH PROGRAM, V91, P201, DOI 10.1007/s101070100263; FAN RE, 2005, J MACHINE LEARNING R, V5, P1889; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; Glasmachers T, 2006, J MACH LEARN RES, V7, P1437; Golub GH, 1997, J COMPUT GRAPH STAT, V6, P1, DOI 10.2307/1390722; Heiler M, 2006, J MACH LEARN RES, V7, P1385; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Keerthi SS, 2006, J MACH LEARN RES, V7, P1493; Laskov P, 2006, J MACH LEARN RES, V7, P1909; Mangasarian OL, 1999, IEEE T NEURAL NETWOR, V10, P1032, DOI 10.1109/72.788643; Mangasarian OL, 2006, J MACH LEARN RES, V7, P1517; Mangasarian OL, 1994, OPTIMIZATION METHODS, V4, P103, DOI 10.1080/10556789408805581; Mittelmann HD, 2003, MATH PROGRAM, V95, P407, DOI 10.1007/s10107-002-0355-5; Nemhauser G. L., 1999, INTEGER COMBINATORIA; NESTEROV Y, 2003, DUAL EXTRAPOLATION I; Niculescu RS, 2006, J MACH LEARN RES, V7, P1357; Nocedal J., 1999, NUMERICAL OPTIMIZATI; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; RADIN R, 1998, OPTIMIZATION OPERATI; Reemtsen R., 1998, SEMIINFINITE PROGRAM; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Rousu J, 2006, J MACH LEARN RES, V7, P1601; RUMMELHART DE, 1986, PARALLEL DISTRIBUTED, P318; Scheinberg K, 2006, J MACH LEARN RES, V7, P2237; Shalev-Shwartz S, 2006, J MACH LEARN RES, V7, P1567; Shivaswamy PK, 2006, J MACH LEARN RES, V7, P1283; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; TASKAR B, 2005, INT C MACH LEARN; Taskar B, 2006, J MACH LEARN RES, V7, P1627; TASKAR B, 2006, J MACHINE LEARNING R, P1627; Yanover C, 2006, J MACH LEARN RES, V7, P1887; Zanni L, 2006, J MACH LEARN RES, V7, P1467; Zhang Y, 2006, J MACH LEARN RES, V7, P1315; [Anonymous], 1998, LINEAR SEMIINFINITE	47	19	19	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2006	7						1265	1281				17	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152UZ	WOS:000245388800005	
J	De Bie, T; Cristianini, N				De Bie, Tijl; Cristianini, Nello			Fast SDP relaxations of graph cut clustering, transduction, and other combinatorial problems	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						convex transduction; normalized graph cut; semi-definite programming; semi-supervised learning; relaxation; combinatorial optimization; max-cut		The rise of convex programming has changed the face of many research fields in recent years, machine learning being one of the ones that benefitted the most. A very recent developement, the relaxation of combinatorial problems to semi-definite programs ( SDP), has gained considerable attention over the last decade (Helmberg, 2000; De Bie and Cristianini, 2004a). Although SDP problems can be solved in polynomial time, for many relaxations the exponent in the polynomial complexity bounds is too high for scaling to large problem sizes. This has hampered their uptake as a powerful new tool in machine learning. In this paper, we present a new and fast SDP relaxation of the normalized graph cut problem, and investigate its usefulness in unsupervised and semi-supervised learning. In particular, this provides a convex algorithm for transduction, as well as approaches to clustering. We further propose a whole cascade of fast relaxations that all hold the middle between older spectral relaxations and the new SDP relaxation, allowing one to trade off computational cost versus relaxation accuracy. Finally, we discuss how the methodology developed in this paper can be applied to other combinatorial problems in machine learning, and we treat the max-cut problem as an example.	Univ Southampton, ECS, ISIS, Southampton SO17 1BJ, Hants, England; Katholieke Univ Leuven, OKP Res Grp, B-3000 Louvain, Belgium; Univ Bristol, Dept Engn Math, Bristol BS8 1TR, Avon, England; Univ Bristol, Dept Comp Sci, Bristol BS8 1TR, Avon, England	De Bie, T (reprint author), Univ Southampton, ECS, ISIS, Southampton SO17 1BJ, Hants, England.	tijl.debie@gmail.com; nello@support-vector.net	De Bie, Tijl/B-2920-2013				Anjos MF, 2002, DISCRETE APPL MATH, V119, P79, DOI 10.1016/S0166-218X(01)00266-9; Blum A., 2001, P 18 INT C MACH LEAR; Boyd S, 2004, CONVEX OPTIMIZATION; Burer S, 2005, MATH PROGRAM, V103, P427, DOI 10.1007/s10107-004-0564-1; Burer S, 2003, MATH PROGRAM, V95, P329, DOI 10.1007/s10107-002-0352-8; CHAPELLE O, 2003, ADV NEURAL INFORM PR, V15; Cristianini N., 2002, ADV NEURAL INFORM PR; de Bie T., 2004, ADV NEURAL INFORM PR, V16; DEBIE T, 2004, P IAPR INT WORKSH ST; DEBIE T, 2004, P INT WORKSH STAT PA; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Helmberg C, 2000, SIAM J OPTIMIZ, V10, P673, DOI 10.1137/S1052623497328987; HELMBERG C, 2000, ZR0034 ZIB TU BERL K; Joachims T., 2002, P INT C MACH LEARN I; KAMVAR SD, 2003, IJCAI; LANG K, 2004, YRL2004036; Ng A.Y., 2002, ADV NEURAL INFORM PR, V14; Shental N., 2004, ADV NEURAL INFORM PR, V16; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; XING EP, 2003, CSD031265 U CAL DIV	22	5	5	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2006	7						1409	1436				28	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152UZ	WOS:000245388800011	
J	Sonnenburg, S; Ratsch, G; Schafer, C; Scholkopf, B				Sonnenburg, Soeren; Raetsch, Gunnar; Schaefer, Christin; Schoelkopf, Bernhard			Large scale multiple kernel learning	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						multiple kernel learning; string kernels; large scale optimization; support vector machines; support vector regression; column generation; semi-infinite linear programming		While classical kernel-based learning algorithms are based on a single kernel, in practice it is often desirable to use multiple kernels. Lanckriet et al. (2004) considered conic combinations of kernel matrices for classification, leading to a convex quadratically constrained quadratic program. We show that it can be rewritten as a semi-infinite linear program that can be efficiently solved by recycling the standard SVM implementations. Moreover, we generalize the formulation and our method to a larger class of problems, including regression and one-class classification. Experimental results show that the proposed algorithm works for hundred thousands of examples or hundreds of kernels to be combined, and helps for automatic model selection, improving the interpretability of the learning result. In a second part we discuss general speed up mechanism for SVMs, especially when used with sparse feature maps as appear for string kernels, allowing us to train a string kernel SVM on a 10 million real-world splice data set from computational biology. We integrated multiple kernel learning in our machine learning toolbox SHOGUN for which the source code is publicly available at http://www.fml.tuebingen.mpg.de/raetsch/projects/shogun.	Fraunhofer FIRST IDA, D-12489 Berlin, Germany; Max Planck Soc, Friedrich Miescher Lab, Tubingen, Germany; Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany	Sonnenburg, S (reprint author), Fraunhofer FIRST IDA, Kekulestr 7, D-12489 Berlin, Germany.	SOEREN.SONNENBURG@FIRST.FRAUNHOFER.DE; GUNNAR.RAETSCH@TUEBINGEN.MPG.DE; CHRISTIN.SCHAEFER@FIRST.FRAUNHOFER.DE; BERNHARD.SCHOELKOPF@TUEBINGEN.MPG.DE	Ratsch, Gunnar/B-8182-2009; Sonnenburg, Soeren/F-2230-2010; Scholkopf, Bernhard/A-7570-2013				Bach F.R., 2004, 21 INT C MACH LEARN; Bennett BC, 2002, J SPORT EXERCISE PSY, V24, P31; Bi J., 2004, P 10 ACM SIGKDD INT, P521, DOI 10.1145/1014052.1014113; Boyd S, 2004, CONVEX OPTIMIZATION; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DAVIS J, 2006, 1551 U WISC MAD; Fawcett T., 2003, HPL20034; FREDKIN E, 1960, COMMUN ACM, V3, P490, DOI 10.1145/367390.367400; Grandvalet Y., 2002, ADV NEURAL INFORM PR, V15, P553; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; Joachims T., 1998, LNCS, V1398, P137; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294; Leslie Christina, 2002, Pac Symp Biocomput, P564; LESLIE C, 2004, MIT PRESS SERIES COM, P95; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Metz C. E., 1978, SEMINARS NUCL MED, V8, P4; Ong C.S., 2003, ADV NEURAL INFORM PR, V15, P478; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Ratsch G, 2005, J MACH LEARN RES, V6, P2131; Ratsch G, 2005, BIOINFORMATICS, V21, pI369, DOI 10.1093/bioinformatics/bti1053; Ratsch G., 2001, THESIS U POTSDAM POT; RATSCH G, 2004, MIT PRESS SERIES COM; RATSCH G, NCTR2000085; RATSCH G, 2002, MACH LEARN, V48, P193; Scholkopf B., 2002, LEARNING KERNELS; SONNENBURG S, 2005, ICML 05, P849; Sonnenburg S, 2005, LECT NOTES COMPUT SC, V3500, P389; WARMUTH MK, 2006, ICML 06	30	292	310	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2006	7						1531	1565				35	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152UZ	WOS:000245388800016	
J	Aphinyanaphongs, Y; Statnikov, A; Aliferis, CF				Aphinyanaphongs, Yindalon; Statnikov, Alexander; Aliferis, Constantin F.			A comparison of citation metrics to machine learning filters for the identification of high quality MEDLINE documents	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							DETECTING CLINICALLY SOUND; OPTIMAL SEARCH STRATEGIES; TEXT CATEGORIZATION; RETRIEVAL	Objective: The present study explores the discriminatory performance of existing and novel gold-standard-specific machine learning (GSS-ML) focused filter models (i.e., models built specifically for a retrieval task and a gold standard against which they ate evaluated) and compares their performance to citation count and impact factors, and non-specific machine learning (NS-ML) models (i.e., models built for a different task and/or different gold standard). Design: Three gold standard corpora were constructed using the SSOAB bibliography, the ACPJ-cited treatment articles, and the ACPJ-cited etiology articles. Citation counts and impact factors were obtained for each article. Support vector machine models were used to classify the articles using combinations of content, impact factors, and citation counts as predictors. Measurements: Discriminatory performance was estimated using the area under the receiver operating characteristic curve and n-fold cross-validation. Results: For all three gold standards and tasks, GSS-ML filters outperformed citation count, impact factors, and NS-ML filters. Combinations of content with impact factor or citation count produced no or negligible improvements to the GSS machine learning filters. Conclusions: These experiments provide evidence that when building information retrieval filters focused on a retrieval task and corresponding gold standard, the filter models have to be built specifically for this task and gold standard. Under those conditions, machine learning filters outperform standard citation metrics. Furthermore, citation counts and impact factors add marginal value to discriminatory performance. Previous research that claimed better performance of citation metrics than machine learning in one of the corpora examined here is attributed to using machine learning filters built for a different gold standard and task.	Vanderbilt Univ, Dept Biomed Informat, Eskind Biomed Lib, Discovery Syst Lab, Nashville, TN 37232 USA	Aliferis, CF (reprint author), Vanderbilt Univ, Dept Biomed Informat, Eskind Biomed Lib, Discovery Syst Lab, Room 412,2209 Garland Ave, Nashville, TN 37232 USA.	constantin.aliferis@vanderbilt.edu					ALIFERIS C, 2003, P AMIA S WASH DC; ALIFERIS CF, 1908, METMBS, P371; Aphinyanaphongs Y, 2005, J AM MED INFORM ASSN, V12, P207, DOI 10.1197/jamia.M1641; APHINYANAPHONGS Y, 2004, MEDINFO; BAEZAYATES R, 1999, MODERN INFORMATION R; BERNSTAM EV, 2005, J AM MED INFORM ASS; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; DUDA S, 2005, AMIA S WASH D C; DUDOIT S, 2003, 126 UC BERK DIV BIOS; DUMAIS S, 1998, P ACM CIKM98 NOV; Fawcett T., 2003, HPL20034; GARFIELD E, 1965, CAN CITATION INDEXIN; Garfield E., 2003, INT J CLIN HLTH PSYC, V3, P363; Garfield E., 1992, SCI PUBL POLICY, V19, P321; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HAYNES RB, 1994, J AM MED INFORM ASSN, V1, P447; Hsu C. W., 2005, PRACTICAL GUIDE SUPP; Jenkins Michelle, 2004, Health Info Libr J, V21, P148, DOI 10.1111/j.1471-1842.2004.00511.x; JOACHIMS T., 2002, LEARNING CLASSIFY TE; KLEINBERG, 1997, P ACM SIAM S DISCR A; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Pagano M., 2000, PRINCIPLES BIOSTATIS; Page L., 1998, PAGERANK CITATION RA; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; PROVOST F, 1998, ICML 98 15 INT C MAC; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SCHEFFER T, 1999, ERROR ESTIMATION MOD; SUN A, 2001, ICDM; TSAMARDINOS I, 2003, AI STAT; Vapnik VN, 1998, STAT LEARNING THEORY; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Wilczynski NL, 2005, J AM MED INFORM ASSN, V12, P481, DOI 10.1197/jamia.M1752; YANG Y, 1999, 22 ANN ACM C RES DEV; 1999, ACP J, V131, pA15; 2005, LIBSVM LIB SUPPORT V; 2005, PUBMED	37	9	10	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1067-5027		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JUL-AUG	2006	13	4					446	455		10.1197/jamia.M2031		10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	064EU	WOS:000239072800013	
J	Aumann, Y; Feldman, R; Liberzon, Y; Rosenfeld, B; Schler, J				Aumann, Yonatan; Feldman, Ronen; Liberzon, Yair; Rosenfeld, Benjamin; Schler, Jonathan			Visual information extraction	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						information extraction; PDF analysis; text analysis; wrapper induction		Typographic and visual information is an integral part of textual documents. Most information extraction (IE) systems ignore most of this visual information, processing the text as a linear sequence of words. Thus, much valuable information is lost. In this paper, we show how to make use of this visual information for IE. We present an algorithm that allows to automatically extract specific fields of the document (such as the title, author, etc.) based exclusively on the visual formatting of the document, without any reference to the semantic content. The algorithm employs a machine learning approach, whereby the system is first provided with a set of training documents in which the target fields are manually tagged and automatically learns how to extract these fields in future documents. We implemented the algorithm in a system for automatic analysis of documents in PDF format. We present experimental results of applying the system on a set of financial documents, extracting nine different target fields. Overall, the system achieved a 90% accuracy.	Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel; ClearForest Ltd, IL-60376 Yehuda, Israel	Aumann, Y (reprint author), Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel.	aumann@cs.biu.ac.il; feldman@cs.biu.ac.il					Altamura O., 2001, International Journal on Document Analysis and Recognition, V4, DOI 10.1007/PL00013569; ANJEWIERDEN A, P 6 INT C DOC AN REC, P374; ASHISH N, 1997, P WORKSH MAN SEM DAT; Berardi M, 2004, LECT NOTES COMPUT SC, V3163, P179; BRIGHT L, 1999, INT J COMPUT SYST SC, V14, P83; Califf M.E., 1999, AAAI 99 IAAI 99, P328; CHAO H, 2001, WORKSH DOC LAYOUT IN; Eikvil L, 1999, 945 NORW COMP CTR; ESPOSITO F, 2000, J INTELL INF SYST, V14, P178; ETZIONI O, 1994, COMMUN ACM, V37, P7; FREITAG D, 1998, P 36 ANN M ASS COMP, P404; FRIEDMAN M, 1997, 15 INT JOINT C ART I, P785; Futrelle RP, 2003, P 7 INT C DOC AN REC, P1007; Hammer J., 1997, P ACM SIGMOD INT C M, P532, DOI 10.1145/253260.253395; Hsu CN, 1998, INFORM SYST, V23, P521, DOI 10.1016/S0306-4379(98)00027-1; Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9; LEWIS JW, 1991, P 2 NAT S CONC ENG, P445; Lovegrove W. S., 1995, Electronic Publishing: Origination, Dissemination and Design, V8; MUSLEA I, 2001, AUTON AGENT MULTI-AG, V4, P1; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; PAPAKONSTANTINO.Y, 1995, LNCS E, V1013, P319; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Rosenfeld B., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; SELBERG E, 1997, IEEE EXPERT, V12, P8; SODERLAND S, 1999, MACH LEARN, V34, P1; 1992, P 4 MESS UND C MUC 4; 1995, P 6 MESS UND C MUC 6; 1991, P 3 MESS UND C MUC 3; 1993, P 5 MESS UND C MUC 5	29	6	6	SPRINGER LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL ROAD, GODALMING GU7 3DJ, SURREY, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	JUL	2006	10	1					1	15		10.1007/s10115-006-0014-x		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	077PA	WOS:000240040900001	
J	Zhang, L; Shao, C; Zheng, DX; Gao, YH				Zhang, Ling; Shao, Chen; Zheng, Dexian; Gao, Youhe			An integrated machine learning system to computationally screen protein databases for protein binding peptide ligands	MOLECULAR & CELLULAR PROTEOMICS			English	Article							AMINO-ACID-RESIDUES; T-CELL EPITOPES; NEURAL-NETWORK; PREDICTION; DOMAINS; SEQUENCE; SENSITIVITY; ALGORITHM; COMPLEX; CHOICE	A fairly large set of protein interactions is mediated by families of peptide binding domains, such as Src homology 2 (SH2), SH3, PDZ, major histocompatibility complex, etc. To identify their ligands by experimental screening is not only labor-intensive but almost futile in screening low abundance species due to the suppression by high abundance species. An ideal way of studying protein-protein interactions is to use high throughput computational approaches to screen protein sequence databases to direct the validating experiments toward the most promising peptides. Predictors with only good cross-validation were not good enough to screen protein databases. In the current study we built integrated machine learning systems using three novel coding methods and screened the Swiss-Prot and GenBank (TM) protein databases for potential ligands of 10 SH3 and three PDZ domains. A large fraction of predictions has already been experimentally confirmed by other independent research groups, indicating a satisfying generalization capability for future applications in identifying protein interactions.	Chinese Acad Med Sci, Peking Union Med Coll, Proteom Res Ctr, Natl Key Lab Med Mol Biol,Inst Basic Med Sci, Beijing 100005, Peoples R China	Gao, YH (reprint author), Chinese Acad Med Sci, Peking Union Med Coll, Proteom Res Ctr, Natl Key Lab Med Mol Biol,Inst Basic Med Sci, 5 Dong Dan San Tiao, Beijing 100005, Peoples R China.	gaoyouhe@pumc.edu.cn					Altuvia Y, 2004, METHODS, V34, P454, DOI 10.1016/j.ymeth.2004.06.008; BALDI P, 2001, BIOINFORMATICS MACHI, P97; Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.151; Benson DA, 2005, NUCLEIC ACIDS RES, V33, pD34, DOI 10.1093/nar/gki063; Berman HM, 2000, NAT STRUCT BIOL, V7, P957, DOI 10.1038/80734; Betancourt MR, 1999, PROTEIN SCI, V8, P361; Beuming T, 2005, BIOINFORMATICS, V21, P827, DOI 10.1093/bioinformatics/bti098; Bhasin M, 2004, BIOINFORMATICS, V20, P421, DOI 10.1093/bioinformatics/btg424; BHASKARAN R, 1984, INT J PEPT PROT RES, V24, P180; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Boisguerin P, 2004, CHEM BIOL, V11, P449, DOI 10.1016/j.chembiol.2004.03.010; Brannetti B, 2000, J MOL BIOL, V298, P313, DOI 10.1006/jmbi.2000.3670; Brusic V, 1998, BIOINFORMATICS, V14, P121, DOI 10.1093/bioinformatics/14.2.121; Brusic V, 2004, METHODS, V34, P436, DOI 10.1016/j.ymeth.2004.06.006; BULL HB, 1974, ARCH BIOCHEM BIOPHYS, V161, P665, DOI 10.1016/0003-9861(74)90352-X; CHOTHIA C, 1975, NATURE, V254, P304, DOI 10.1038/254304a0; Donnes P, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-25; Guo T, 2004, NUCLEIC ACIDS RES, V32, pD122, DOI 10.1093/nar/gkh109; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Honeyman MC, 1998, NAT BIOTECHNOL, V16, P966, DOI 10.1038/nbt1098-966; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Landgraf C, 2004, PLOS BIOL, V2, P94, DOI 10.1371/journal.pbio.0020014; Lo SL, 2005, PROTEOMICS, V5, P876, DOI 10.1002/pmic.200401118; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mayer BJ, 2001, J CELL SCI, V114, P1253; Michielin O, 2002, J MOL BIOL, V324, P547, DOI 10.1016/S0022-2836(02)00880-X; NOURRY C, 2003, SCI STKE; Obenauer JC, 2003, NUCLEIC ACIDS RES, V31, P3635, DOI 10.1093/nar/gkg584; Pawson T, 1997, SCIENCE, V278, P2075, DOI 10.1126/science.278.5346.2075; Pawson T, 2003, SCIENCE, V300, P445, DOI 10.1126/science.1083653; PERRONE M, 1993, NETWORKS DISAGREE EN; Rammensee HG, 1999, IMMUNOGENETICS, V50, P213, DOI 10.1007/s002510050595; Schultz J, 1998, P NATL ACAD SCI USA, V95, P5857, DOI 10.1073/pnas.95.11.5857; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Tong AHY, 2002, SCIENCE, V295, P321, DOI 10.1126/science.1064987; Tong JC, 2004, PROTEIN SCI, V13, P2523, DOI 10.1110/pd.04631204; Vapnik V. N., 2000, NATURE STAT LEARNING; Wiedemann U, 2004, J MOL BIOL, V343, P703, DOI 10.1016/j.jmb.2004.08.064; ZIMMERMAN ZN, 1968, J THEOR BIOL, V21, P170	41	11	12	AMER SOC BIOCHEMISTRY MOLECULAR BIOLOGY INC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3996 USA	1535-9476		MOL CELL PROTEOMICS	Mol. Cell. Proteomics	JUL	2006	5	7					1224	1232		10.1074/mcp.M500346-MCP200		9	Biochemical Research Methods	Biochemistry & Molecular Biology	058OR	WOS:000238674800005	
J	Pireddu, L; Szafron, D; Lu, P; Greiner, R				Pireddu, Luca; Szafron, Duane; Lu, Paul; Greiner, Russell			The Path-A metabolic pathway prediction web server	NUCLEIC ACIDS RESEARCH			English	Article								Pathway Analyst ( Path- A) is a publicly available web server ( http://path-a.cs.ualberta.ca)that predicts metabolic pathways. It takes a FASTA format file containing a set of query protein sequences from a single organism ( a partial or complete proteome) and identifies those sequences that are likely to participate in any of its supported metabolic pathways ( currently 10). Path- A uses a number of machine-learning and sequence analysis techniques ( e. g. SVM, BLAST and HMM) to predict pathways. Each machine- learned classifier exploits similarity between sequences in the pathways of its model organisms and sequences in the query set. It predicts the pathways that are present in the query organism and annotates each predicted reaction and catalyst, using the appropriate sequences from the query set. Path- A also provides a browsable and searchable database of the pathways for the model organisms that are used to make its predictions. Path- A's predictor sets ( using different classifier technologies) have been evaluated using standard cross- validation techniques on a dataset of 10 metabolic pathways across 13 model organisms - a total of 125 organism-specific pathways. The most accurate classifier technology obtained a mean precision of 78.3% andamean recall of 92.6% in predicting all catalyst proteins, of all reactions, in all pathways present in the dataset. Although Path- A currently only supports metabolic pathways, the underlying prediction techniques are general enough for other types of pathways. Consequently, it is our intent to extend Path- A to predict other types of pathways, including signalling pathways.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada	Szafron, D (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.	duane@cs.ualberta.ca					ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; CHRISTIAN L, 2004, NUCLEIC ACIDS RES, V32, pD443; Eddy SR, 1998, BIOINFORMATICS, V14, P755, DOI 10.1093/bioinformatics/14.9.755; Hastie T, 2001, ELEMENTS STAT LEARNI; Kanehisa M., 2004, NUCLEIC ACIDS RES, V32, P277; Karp PD, 2002, BIOINFORMATICS, V18, P225; Karp PD, 2005, NUCLEIC ACIDS RES, V33, P6083, DOI 10.1093/nar/gki892; Pireddu L, 2005, Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology, P243	8	6	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048		NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL 1	2006	34				SI		W714	W719		10.1093/nar/gkl228		6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	156LR	WOS:000245650200144	
J	Vullo, A; Bortolami, O; Pollastri, G; Tosatto, SCE				Vullo, Alessandro; Bortolami, Oscar; Pollastri, Gianluca; Tosatto, Silvio C. E.			Spritz: a server for the prediction of intrinsically disordered regions in protein sequences using kernel machines	NUCLEIC ACIDS RESEARCH			English	Article							SECONDARY STRUCTURE PREDICTION; NATIVELY UNFOLDED PROTEINS; SUPPORT VECTOR MACHINES; AMINO-ACID-COMPOSITION; UNSTRUCTURED PROTEINS; COMPLEXITY	Intrinsically disordered proteins have long stretches of their polypeptide chain, which do not adopt a single native structure composed of stable secondary and tertiary structure in the absence of binding partners. The prediction of intrinsically disordered regions in proteins from sequence is increasingly becoming of interest, as the presence of many such regions in the complete genome sequences are discovered and important functional roles are associated with them. We have developed a machine learning approach based on two support vector machines (SVM) to discriminate disordered regions from sequence. The SVM are trained and benchmarked on two sets, representing long and short disordered regions. A preliminary version of Spritz was shown to perform consistently well at the recent biannual CASP-6 experiment [Critical Assessment of Techniques for Protein Structure Prediction (CASP), 2004]. The fully developed Spritz method is freely available as a web server at http://distill.ucd.ie/spritz/ and http://protein.cribi.unipd.it/spritz/.	Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 2, Ireland; Univ Padua, Dept Biol, I-35100 Padua, Italy; Univ Padua, CRIBI Biotechnol Ctr, I-35100 Padua, Italy	Pollastri, G (reprint author), Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 2, Ireland.	gianluca.pollastri@ucd.ie	Tosatto, Silvio/B-2840-2009				Albrecht M, 2003, PROTEIN ENG, V16, P459, DOI 10.1093/protein/gzg063; ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Bracken C, 2004, CURR OPIN STRUC BIOL, V14, P570, DOI 10.1016/j.sbi.2004.08.003; Coeytaux K, 2005, BIOINFORMATICS, V21, P1891, DOI 10.1093/bioinformatics/bti266; Cuff JA, 1999, PROTEINS, V34, P508, DOI 10.1002/(SICI)1097-0134(19990301)34:4<508::AID-PROT10>3.0.CO;2-4; Deshpande N, 2005, NUCLEIC ACIDS RES, V33, P233; Dosztanyi Z, 2005, J MOL BIOL, V347, P827, DOI 10.1016/j.jmb.2005.01.071; Dunker AK, 2001, NAT BIOTECHNOL, V19, P805, DOI 10.1038/nbt0901-805; Dunker AK, 2002, BIOCHEMISTRY-US, V41, P6573, DOI 10.1021/bi012159+; Dyson HJ, 2002, CURR OPIN STRUC BIOL, V12, P54, DOI 10.1016/S0959-440X(02)00289-0; Dyson HJ, 2005, NAT REV MOL CELL BIO, V6, P197, DOI 10.1038/nrm1589; Fink AL, 2005, CURR OPIN STRUC BIOL, V15, P35, DOI 10.1016/j.sbi.2005.01.002; Jin YM, 2005, PROTEINS, V61, P167, DOI 10.1002/prot.20734; Jones DT, 2003, PROTEINS, V53, P573, DOI 10.1002/prot.10528; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Linding R, 2003, STRUCTURE, V11, P1453, DOI 10.1016/j.str.2003.10.002; Linding R, 2003, NUCLEIC ACIDS RES, V31, P3701, DOI 10.1093/nar/gkg519; Lise S, 2005, PROTEINS, V58, P144, DOI 10.1002/prot.20279; Liu JF, 2002, J MOL BIOL, V322, P53, DOI 10.1016/S0022-2836(02)00736-2; Melamud E, 2003, PROTEINS, V53, P561, DOI 10.1002/prot.10533; Moult J, 2005, PROTEINS, V61, P3, DOI 10.1002/prot.20716; Obradovic Z, 2003, PROTEINS, V53, P566, DOI 10.1002/prot.10532; Obradovic Z, 2005, PROTEINS, V61, P176, DOI 10.1002/prot.20735; Oldfield CJ, 2005, BIOCHEMISTRY-US, V44, P1989, DOI 10.1021/bi047993o; Platt J., 2000, PROBABILISTIC OUTPUT; Pollastri G, 2005, BIOINFORMATICS, V21, P1719, DOI 10.1093/bioinformatics/bti203; Radivojac P, 2004, PROTEIN SCI, V13, P71, DOI 10.1110/ps.03128904; Romero P, 2001, PROTEINS, V42, P38, DOI 10.1002/1097-0134(20010101)42:1<38::AID-PROT50>3.0.CO;2-3; Romero Pedro, 2004, Appl Bioinformatics, V3, P105, DOI 10.2165/00822942-200403020-00005; SHAWETAYLOR, 2004, KERNEL METHODS PATTE; Tompa P, 2002, TRENDS BIOCHEM SCI, V27, P527, DOI 10.1016/S0968-0004(02)02169-2; Uversky VN, 2002, EUR J BIOCHEM, V269, P2, DOI 10.1046/j.0014-2956.2001.02649.x; Uversky VN, 2000, PROTEINS, V41, P415, DOI 10.1002/1097-0134(20001115)41:3<415::AID-PROT130>3.0.CO;2-7; Vucetic S, 2005, BIOINFORMATICS, V21, P137, DOI 10.1093/bioinformatics/bth476; Vucetic S, 2003, PROTEINS, V52, P573, DOI 10.1002/prot.10437; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; Ward JJ, 2004, J MOL BIOL, V337, P635, DOI 10.1016/j.jmb.2004.02.002; WOOTTON JC, 1994, COMPUT CHEM, V18, P269, DOI 10.1016/0097-8485(94)85023-2; Wright PE, 1999, J MOL BIOL, V293, P321, DOI 10.1006/jmbi.1999.3110	39	55	58	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048		NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL 1	2006	34				SI		W164	W168		10.1093/nar/gkl166		5	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	156LR	WOS:000245650200034	
J	Waldispuhl, J; Berger, B; Clote, P; Steyaert, JM				Waldispuhl, J.; Berger, Bonnie; Clote, Peter; Steyaert, Jean-Marc			transFold: a web server for predicting the structure and residue contacts of transmembrane beta-barrels	NUCLEIC ACIDS RESEARCH			English	Article							OUTER-MEMBRANE PROTEINS; REGIONS	Transmembrane beta-barrel (TMB) proteins are embedded in the outermembrane of Gram-negative bacteria, mitochondria and chloroplasts. The cellular location and functional diversity of beta-barrel outer membrane proteins makes them an important protein class. At the present time, very few non-homologous TMB structures have been determined by X-ray diffraction because of the experimental difficulty encountered in crystallizing transmembrane (TM) proteins. The transFold web server uses pairwise inter-strand residue statistical potentials derived from globular (non-outer-membrane) proteins to predict the super-secondary structure of TMB. Unlike all previous approaches, transFold does not use machine learning methods such as hidden Markov models or neural networks; instead, transFold employs multi-tape S-attribute grammars to describe all potential conformations, and then applies dynamic programming to determine the global minimum energy supersecondary structure. The transFold web server not only predicts secondary structure and TMB topology, but is the only method which additionally predicts the side-chain orientation of transmembrane beta-strand residues, inter-strand residue contacts and TM beta-strand inclination with respect to the membrane. The program transFold currently outperforms all other methods for accuracy of beta-barrel structure prediction. Available at http://bioinformatics.bc.edu/clotelab/transFold.	Boston Coll, Dept Biol, Chestnut Hill, MA 02467 USA; MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; MIT, Dept Math, Cambridge, MA 02139 USA; Boston Coll, Dept Comp Sci, Chestnut Hill, MA 02467 USA; Ecole Polytech, Lab Informat LIX, F-91128 Palaiseau, France	Clote, P (reprint author), Boston Coll, Dept Biol, 140 Commonwealth Ave, Chestnut Hill, MA 02467 USA.	clote@bc.edu; bab@mit.edu					Bigelow HR, 2004, NUCLEIC ACIDS RES, V32, P2566, DOI 10.1093/nar/gkh580; Cowen L, 2002, J COMPUT BIOL, V9, P261, DOI 10.1089/10665270252935458; Gromiha MM, 2004, J COMPUT CHEM, V25, P762, DOI 10.1002/jcc.10386; Gromiha MM, 2005, BIOINFORMATICS, V21, P961, DOI 10.1093/bioinformatics/bti126; Gromiha MM, 2005, NUCLEIC ACIDS RES, V33, pW164, DOI 10.1093/nar/gki367; Liu Q, 2003, COMPUT BIOL CHEM, V27, P69, DOI 10.1016/S0097-8485(02)00051-7; Menke M, 2005, J COMPUT BIOL, V12, P777, DOI 10.1089/cmb.2005.12.777; Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092; Tamm LK, 2004, BBA-BIOMEMBRANES, V1666, P250, DOI 10.1016/j.bbamem.2004.06.011; Waldispuhl J, 2005, THEOR COMPUT SCI, V335, P67, DOI 10.1016/j.tcs.2004.12.018; WALDISPUHL J, 2006, IN PRESS PROTEINS	11	14	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048		NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL 1	2006	34				SI		W189	W193		10.1093/nar/gkl205		5	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	156LR	WOS:000245650200040	
J	Sharma, A; Paliwal, KK; Onwubolu, GC				Sharma, A; Paliwal, KK; Onwubolu, GC			Class-dependent PCA, MDC and LDA: A combined classifier for pattern classification	PATTERN RECOGNITION			English	Article						classification accuracy; total parameter requirement; processing time; class-dependent PCA; LDA	MULTIPLE CLASSIFIERS; RECOGNITION; COMBINATION; PERFORMANCE; FEATURES	Several pattern classifiers give high classification accuracy but their storage requirements and processing time are severely expensive. On the other hand, some classifiers require very low storage requirement and processing time but their classification accuracy is not satisfactory. In either of the cases the performance of the classifier is poor. In this paper, we have presented a technique based on the combination of minimum distance classifier (MDC), class-dependent principal component analysis (PICA) and linear discriminant analysis (LDA) which gives improved performance as compared with other standard techniques when experimented on several machine learning corpuses. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Griffith Univ, Signal Proc Lab, Brisbane, Qld 4111, Australia; Univ S Pacific, Dept Engn, Suva, Fiji	Sharma, A (reprint author), Griffith Univ, Signal Proc Lab, Brisbane, Qld 4111, Australia.	sharma_al@usp.ac.fj					ALEXANDRE LA, 2000, ICPR2000 15 INT C PA, V2, P495; ALIMOGLU F, 1997, INT C DOC AN REC, V2, P637; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Blake C. L., 1998, UCI REPOSITORY MACHI; Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223; Datta P., 1997, P 14 NAT C ART INT, P82; Di Maio V, 2003, CYBERNET SYST, V34, P173, DOI 10.1080/01969720390184371; Dony RD, 1997, IEE P-VIS IMAGE SIGN, V144, P73, DOI 10.1049/ip-vis:19971153; Duda R.O, 1973, PATTERN CLASSIFICATI; DUIN RPW, 1995, SCIA 95, V2, P957; FENG C, 1993, COMPARISON MACHINE L, P41; Fukunaga K., 1990, INTRO STAT PATTERN R; GAROFALO SG, 1986, DARPA TIMIT ACOUSTIC; GRIGUOLO S, 1994, INT C AL PREC SUIV E; Haeb-Umbach R., 1992, P IEEE INT C AC SPEE, V1, P13; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JIAN H, 2004, P INT C MACH LEARN C, V6, P3589, DOI 10.1109/ICMLC.2004.1380414; KAMBHATLA N, 1996, THESIS OREGON GRADUA; KITTLER J, 1996, P 13 INT C PATT REC, V2, P897, DOI 10.1109/ICPR.1996.547205; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; LAMBROU T, 2002, MED IMAGE UNDERSTAND; LEI L, 2002, INT C MACH LEARN CYB, V1, P252; LEWENSTEIN K, 2004, MODELLING MECHATRONI; LIEB M, 2000, P INT C AC SPEECH SI, V2, DOI UNSP II1105-II1108; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; Oja E., 1983, SUBSPACE METHODS PAT; OJA E, 1984, 7 INT C PATT REC, V2, P692; Paclik P, 2003, REAL-TIME IMAGING, V9, P237, DOI 10.1016/j.rti.2003.09.002; POTAMIANOS G, 1998, IEEE WORKSH MULT SIG, P221; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; SAHIN F, 2000, THESIS STATE U VIRGI; Senior A, 2001, IEEE T PATTERN ANAL, V23, P1165, DOI 10.1109/34.954606; Sharma A, 2005, AM J APPL SCI, V2, P1445; SIOHAN O, 1995, P ICASSP, V1, P125; Skurichina M, 1999, PATTERN ANAL APPL, V2, P44, DOI 10.1007/s100440050013; Skurichina M., 1996, P 13 INT C PATT REC, V2, P891, DOI 10.1109/ICPR.1996.547204; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TAEKYUN K, 2003, P INT C IM PROC, V3, DOI UNSP III-877-III-880; Taylor C., 1994, MACHINE LEARNING NEU; TOTH D, 2002, 16 C PATT REC ICPR 0, V4, P373; TRESP V, 1995, ADV NEURAL INFORM PR, V7; TURNER K, 1999, COMBINING ARTIFICIAL, P127; Ueda N, 2000, IEEE T PATTERN ANAL, V22, P207, DOI 10.1109/34.825759; VANBREUKELEN M, 1998, INT C PATT REC, V1, P215; WOODS K, 1996, IEEE COMP SOC C COMP, P391; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; Wu X-J, 2004, P INT C PATT REC, V4, P545; Xiaogang Wang, 2004, Proceedings. Sixth IEEE International Conference on Automatic Face and Gesture Recognition; Xiaogang Wang, 2004, IEEE Transactions on Pattern Analysis and Machine Intelligence, V26, DOI 10.1109/TPAMI.2004.57; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230; YAO M, 2002, WORLD C INT CONTR AU, V3, P2445; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982; Young S., 2002, HTK BOOK; Zhao W., 1999, CARTR914 U MAR; Zhao W, 1998, PROC CVPR IEEE, P164, DOI 10.1109/CVPR.1998.698604; ZHOU L, 1996, ICASSP, V6, P3494; ZHOU XS, 2001, P IEEE C COMP VIS PA, V1, P11	60	13	14	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUL	2006	39	7					1215	1229		10.1016/j.patcog.2006.02.001		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	043GR	WOS:000237588800001	
J	Ozertem, U; Erdogmus, D; Jenssen, R				Ozertem, Umut; Erdogmus, Deniz; Jenssen, Robert			Spectral feature projections that maximize Shannon mutual information with class labels	PATTERN RECOGNITION			English	Article						feature extraction; mutual information; optimal subspace projection	DISCRIMINANT-ANALYSIS; PROBABILITY; ENTROPY; ERROR	Determining optimal subspace projections that can maintain task-relevant information in the data is an important problem in machine learning and pattern recognition. In this paper, we propose a nonparametric nonlinear subspace projection technique that maintains class separability maximally under the Shannon mutual information (MI) criterion. Employing kernel density estimates for nonparametric estimation of MI makes possible an interesting marriage of kernel density estimation-based information theoretic methods and kernel machines, which have the ability to determine nonparametric nonlinear solutions for difficult problems in machine learning. Significant computational savings are achieved by translating the definition of the desired projection into the kernel-induced feature space, which leads to obtain analytical solution. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	OHSU, CSEE Dept, Oregon Grad Inst, Portland, OR 97006 USA; Univ Tromso, Dept Phys, N-9037 Tromso, Norway	Ozertem, U (reprint author), OHSU, CSEE Dept, Oregon Grad Inst, 20000 NW Walker Rd, Portland, OR 97006 USA.	ozertemu@csee.ogi.edu	Erdogmus, Deniz/A-8170-2009				BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Beirlant J., 1997, INT J MATH STAT SCI, V6, P17; Bollacker K. D., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.546917; Bonnlander B. V., 1996, P INT S ART NEUR NET, P42; COSTA JA, 2005, P IEEE INT C AC SPEE, V5, P1077, DOI 10.1109/ICASSP.2005.1416494; Cover T. M., 1991, ELEMENT INFORM THEOR; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L., 2001, COMBINATORIAL METHOD; DUIN RPW, 1976, IEEE T COMPUT, V25, P1175; Erdogmus D, 2004, J VLSI SIG PROC SYST, V37, P305, DOI 10.1023/B:VLSI.0000027493.48841.39; ERDOGMUS D, 2002, THESIS U FLORIDA GAI; Erdogmus D, 2002, IEEE T SIGNAL PROCES, V50, P1780, DOI 10.1109/TSP.2002.1011217; Fano R., 1961, TRANSMISSION INFORM; FOWLKES C, 2004, IEEE T PATTERN ANAL, V23, P298; Fukunaga K., 1990, INTRO STAT PATTERN R; Golub G. H., 1996, MATRIX COMPUTATIONS; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Koller D., 1996, P 13 INT C MACH LEAR, P284; Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138; Kumar N, 1998, SPEECH COMMUN, V26, P283, DOI 10.1016/S0167-6393(98)00061-2; LEARNED-MILLER E. G., 2003, J MACHINE LEARNING R, V4, P1271, DOI 10.1162/jmlr.2003.4.7-8.1271; Lee DD, 1999, NATURE, V401, P788; MERCER J, 1909, T LONDON PHILOS SO A, V209, P415; Oja E., 1983, SUBSPACE METHODS PAT; Principe J., 2000, UNSUPERVISED ADAPTIV, P265; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Schraudolph NN, 2004, IEEE T NEURAL NETWOR, V15, P828, DOI 10.1109/TNN.2004.828766; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Silverman B.W., 1986, DENSITY ESTIMATION S; Torkkola K., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753742; VASICEK O, 1976, J ROY STAT SOC B MET, V38, P54; WEINERT HL, 1982, REPRODUCING KERNEL H; Yang HH, 2000, ADV NEUR IN, V12, P687; [Anonymous], UCI MACHINE LEARNING	38	6	8	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUL	2006	39	7					1241	1252		10.1016/j.patcog.2006.01.014		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	043GR	WOS:000237588800003	
J	Eramian, D; Shen, MY; Devos, D; Melo, F; Sali, A; Marti-Renom, MA				Eramian, D; Shen, MY; Devos, D; Melo, F; Sali, A; Marti-Renom, MA			A composite score for predicting errors in protein structure models	PROTEIN SCIENCE			English	Article						model assessment; comparative modeling; fold assignment; statistical potentials; support vector machine; protein structure prediction	SECONDARY STRUCTURE PREDICTION; SUPPORT VECTOR MACHINES; ENERGY FUNCTIONS; FOLD RECOGNITION; STATISTICAL POTENTIALS; NEURAL NETWORKS; ATOMIC-LEVEL; MEAN FORCE; SOLVATION; DECOYS	Reliable prediction of model accuracy is an important unsolved problem in protein structure modeling. To address this problem, we studied 24 individual assessment scores, including physics-based energy functions, statistical potentials, and machine learning-based scoring functions. Individual scores were also used to construct similar to 85,000 composite scoring functions using support vector machine (SVM) regression. The scores were tested for their abilities to identify the most native-like models from a set of 6000 comparative models of 20 representative protein structures. Each of the 20 targets was modeled using a template of < 30% sequence identity, corresponding to challenging comparative modeling cases. The best SVM score outperformed all individual scores by decreasing the average RMSD difference between the model identified as the best of the set and the model with the lowest RMSD (Delta RMSD) from 0.63 angstrom to 0.45 angstrom, while having a higher Pearson correlation coefficient to RMSD (r = 0.87) than any other tested score. The most accurate score is based on a combination of the DOPE non-hydrogen atom statistical potential; surface, contact, and combined statistical potentials from MODPIPE; and two PSIPRED/DSSP scores. It was implemented in the SVMod program, which can now be applied to select the final model in various modeling problems, including fold assignment, target-template alignment, and loop modeling.	Univ Calif San Francisco, Calif Inst Quantitat Biomed Res, San Francisco, CA 94158 USA; Univ Calif San Francisco, Dept Biopharmaceut Sci, San Francisco, CA 94158 USA; Univ Calif San Francisco, Dept Pharmaceut Chem, San Francisco, CA 94158 USA; Univ Calif San Francisco, Grad Grp Biophys, San Francisco, CA 94158 USA; Pontificia Univ Catolica Chile, Fac Ciencias Biol, Dept Mol Genet & Microbiol, Santiago, Chile	Marti-Renom, MA (reprint author), Univ Calif San Francisco, Calif Inst Quantitat Biomed Res, QB3 Mission Bay,Suite 503B, San Francisco, CA 94158 USA.	marcius@salilab.org	Marti-Renom, Marc/A-1836-2010; Melo, Francisco/I-5139-2012				Adamczak R, 2004, PROTEINS, V56, P753, DOI 10.1002/prot.20176; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, P226; Apweiler R., 2004, NUCLEIC ACIDS RES, V32, P115; Bairoch A, 2005, NUCLEIC ACIDS RES, V33, P154; Baker D, 2001, SCIENCE, V294, P93, DOI 10.1126/science.1065659; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Bradley P, 2005, SCIENCE, V309, P1868, DOI 10.1126/science.1113801; BROOKMAN RR, 1983, J ADOLESCENT HEALTH, V4, P187; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Cai CZ, 2003, MATH BIOSCI, V185, P111, DOI 10.1016/S0025-5564(03)00096-8; Cai YD, 2003, PEPTIDES, V24, P665, DOI 10.1016/S0196-9781(03)00133-5; Cristobal S, 2001, BMC Bioinformatics, V2, P5, DOI 10.1186/1471-2105-2-5; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Domingues F S, 1999, Proteins, VSuppl 3, P112; Doniger S, 2002, J COMPUT BIOL, V9, P849, DOI 10.1089/10665270260518317; Eswar N, 2003, NUCLEIC ACIDS RES, V31, P3375, DOI 10.1093/nar/gkg543; Eyrich VA, 2001, BIOINFORMATICS, V17, P1242, DOI 10.1093/bioinformatics/17.12.1242; FELSENSTEIN J, 1985, EVOLUTION, V39, P783, DOI 10.2307/2408678; FISCHER D, 1996, PAC S BIOCOMPUT, V397, P300; Gatchell DW, 2000, PROTEINS, V41, P518, DOI 10.1002/1097-0134(20001201)41:4<518::AID-PROT90>3.0.CO;2-6; Ginalski K, 2005, NUCLEIC ACIDS RES, V33, P1874, DOI 10.1093/nar/gki327; HOLM L, 1992, J MOL BIOL, V225, P93, DOI 10.1016/0022-2836(92)91028-N; JOACHIMS T, 1988, 24 U DORTMUND DORTMU; John B, 2003, NUCLEIC ACIDS RES, V31, P3982, DOI 10.1093/nar/gkg460; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; Jones DT, 1999, J MOL BIOL, V287, P797, DOI 10.1006/jmbi.1999.2583; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Karchin R, 2005, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2005, P397; Kuhlman B, 2003, SCIENCE, V302, P1364, DOI 10.1126/science.1089427; Lazaridis T, 1999, PROTEINS, V35, P133, DOI 10.1002/(SICI)1097-0134(19990501)35:2<133::AID-PROT1>3.0.CO;2-N; Lazaridis T, 1997, SCIENCE, V278, P1928, DOI 10.1126/science.278.5345.1928; Lazaridis T, 2000, CURR OPIN STRUC BIOL, V10, P139, DOI 10.1016/S0959-440X(00)00063-4; Lazaridis T, 1999, J MOL BIOL, V288, P477, DOI 10.1006/jmbi.1999.2685; Marti-Renom MA, 2002, STRUCTURE, V10, P435, DOI 10.1016/S0969-2126(02)00731-1; McGuffin LJ, 2003, PROTEINS, V52, P166, DOI 10.1002/prot.10408; Melo F, 2002, PROTEIN SCI, V11, P430, DOI 10.1110/ps.22802; Melo F, 1998, J MOL BIOL, V277, P1141, DOI 10.1006/jmbi.1998.1665; Melo F, 1997, J MOL BIOL, V267, P207, DOI 10.1006/jmbi.1996.0868; Melo F, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P187; Mirkovic N., 2003, CURRENT PROTOCOLS BI; Miyazawa S, 1996, J MOL BIOL, V256, P623, DOI 10.1006/jmbi.1996.0114; Moult J, 2003, PROTEINS, V53, P334, DOI 10.1002/prot.10556; Park B, 1996, J MOL BIOL, V258, P367, DOI 10.1006/jmbi.1996.0256; Park BH, 1997, J MOL BIOL, V266, P831, DOI 10.1006/jmbi.1996.0809; Pazos F, 1997, J MOL BIOL, V271, P511, DOI 10.1006/jmbi.1997.1198; PEARL F, 2005, NUCLEIC ACIDS RES, V33, P247; Pieper U, 2004, NUCLEIC ACIDS RES, V32, pD217, DOI 10.1093/nar/gkh095; Qiu D, 1997, J PHYS CHEM A, V101, P3005, DOI 10.1021/jp961992r; Rychlewski L, 2005, PROTEIN SCI, V14, P240, DOI 10.1110/ps.04888805; SALI A, 1993, J MOL BIOL, V234, P779, DOI 10.1006/jmbi.1993.1626; Samudrala R, 2000, PROTEIN SCI, V9, P1399; Seok C, 2003, J COMPUT CHEM, V24, P89, DOI 10.1002/jcc.10124; Shindyalov IN, 1998, PROTEIN ENG, V11, P739, DOI 10.1093/protein/11.9.739; Shortle D, 1998, P NATL ACAD SCI USA, V95, P11158, DOI 10.1073/pnas.95.19.11158; Siew N, 2000, BIOINFORMATICS, V16, P776, DOI 10.1093/bioinformatics/16.9.776; SIPPL MJ, 1995, CURR OPIN STRUC BIOL, V5, P229, DOI 10.1016/0959-440X(95)80081-6; SIPPL MJ, 1993, PROTEINS, V17, P355, DOI 10.1002/prot.340170404; SIPPL MJ, 1993, J COMPUT AID MOL DES, V7, P473, DOI 10.1007/BF02337562; STILL WC, 1990, J AM CHEM SOC, V112, P6127, DOI 10.1021/ja00172a038; Topf M, 2005, J STRUCT BIOL, V149, P191, DOI 10.1016/j.jsb.2004.11.004; Tosatto SCE, 2005, J COMPUT BIOL, V12, P1316, DOI 10.1089/cmb.2005.12.1316; Tsai J, 2003, PROTEINS, V53, P76, DOI 10.1002/prot.10454; Vapnik V. N, 1995, NATURE STAT LEARNING; Vorobjev YN, 2001, PROTEIN SCI, V10, P2498, DOI 10.1110/ps.ps.15501; Wallner B, 2003, PROTEIN SCI, V12, P1073, DOI 10.1110/ps.0236803; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; Zhang C, 2004, BIOPHYS J, V86, P3349, DOI 10.1529/biophysj.103.035998; Zhou HY, 2002, PROTEIN SCI, V11, P2714, DOI 10.1110/ps.0217002; Zhu J, 2003, PROTEINS, V52, P598, DOI 10.1002/prot.10444	69	73	75	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	0961-8368		PROTEIN SCI	Protein Sci.	JUL	2006	15	7					1653	1666		10.1110/ps.062095806		14	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	059BB	WOS:000238707200008	
J	Han, LY; Cui, J; Lin, HH; Ji, ZL; Cao, ZW; Li, YX; Chen, YZ				Han, Lianyi; Cui, Juan; Lin, Honghuang; Ji, Zhiliang; Cao, Zhiwei; Li, Yixue; Chen, Yuzong			Recent progresses in the application of machine learning approach for predicting protein functional class independent of sequence similarity	PROTEOMICS			English	Review						machine learning method; neural network; protein function prediction; protein sequence; support vector machine	SUPPORT VECTOR MACHINE; AMINO-ACID-COMPOSITION; ARTIFICIAL NEURAL-NETWORKS; DNA-BINDING PROTEINS; HIDDEN MARKOV MODEL; SVM-BASED METHOD; DOMAIN COMPOSITION; COUPLED RECEPTORS; CELL-CYCLE; SUBCELLULAR LOCATIONS	Protein sequence contains clues to its function. Functional prediction from sequence presents a challenge particularly for proteins that have low or no sequence similarity to proteins of known function. Recently, machine learning methods have been explored for predicting functional class of proteins from sequence-derived properties independent of sequence similarity which showed promising potential for low- and non-homologous proteins. These methods can thus be explored as potential tools to complement alignment- and clustering-based methods for predicting protein function. This article reviews the strategies, current progresses, and underlying difficulties in using machine learning methods for predicting the functional class of proteins. The relevant software and web-servers are described. The reported prediction performances in the application of these methods are also presented, which need to be interpreted with caution as they are dependent on such factors as datasets used and choice of parameters.	Natl Univ Singapore, Dept Computat Sci, Singapore 117543, Singapore; Natl Univ Singapore, Dept Pharm, Singapore 117543, Singapore; Shanghai Ctr Bioinformat Technol, Shanghai, Peoples R China	Chen, YZ (reprint author), Natl Univ Singapore, Dept Computat Sci, Blk S16,Level 8,3 Sci Dr 2, Singapore 117543, Singapore.	yzchen@cz3.nus.edu.sg	Han, Lianyi/D-1499-2009				Albert I, 2004, BIOINFORMATICS, V20, P3346, DOI 10.1093/bioinformatics/bth402; Al-Shahib Ali, 2005, Appl Bioinformatics, V4, P195, DOI 10.2165/00822942-200594030-00004; Al-Shahib A, 2005, INT J NEURAL SYST, V15, P259, DOI 10.1142/S0129065705000281; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, P226; Aravind L, 2000, GENOME RES, V10, P1074, DOI 10.1101/gr.10.8.1074; Attwood TK, 2000, NUCLEIC ACIDS RES, V28, P225, DOI 10.1093/nar/28.1.225; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Barker WC, 1999, NUCLEIC ACIDS RES, V27, P39, DOI 10.1093/nar/27.1.39; Bateman A, 2004, NUCLEIC ACIDS RES, V32, pD138, DOI 10.1093/nar/gkh121; Baxevanis AD, 1998, METHOD BIOCHEM ANAL, V39, P172; BENHUR A, 2005, BIOINFORMATICS S, V1, pI38; Benner SA, 2000, RES MICROBIOL, V151, P97, DOI 10.1016/S0923-2508(00)00123-6; Benson D. A., 2004, NUCLEIC ACIDS RES, V32, P23; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bhardwaj N, 2005, NUCLEIC ACIDS RES, V33, P6486, DOI 10.1093/nar/gki949; Bhasin M, 2004, J BIOL CHEM, V279, P23262, DOI 10.1074/jbc.M401932200; Bhasin M, 2004, VACCINE, V22, P3195, DOI 10.1016/j.vaccine.2004.02.005; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW383, DOI 10.1093/nar/gkh416; Bhaskaran R., 1988, INT J PEPT PROT RES, V32, P242; BIGELOW CC, 1967, J THEOR BIOL, V16, P187, DOI 10.1016/0022-5193(67)90004-5; Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Bork P, 1998, NAT GENET, V18, P313, DOI 10.1038/ng0498-313; Bork P, 1998, J MOL BIOL, V283, P707, DOI 10.1006/jmbi.1998.2144; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BULL HB, 1974, ARCH BIOCHEM BIOPHYS, V161, P665, DOI 10.1016/0003-9861(74)90352-X; Cai CZ, 2004, PROTEINS, V55, P66, DOI 10.1002/prot.20045; Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2005, J PROTEOME RES, V4, P967, DOI 10.1021/pr0500399; Cai YD, 2003, BBA-PROTEINS PROTEOM, V1648, P127, DOI 10.1016/S1570-9639(03)00112-2; Cai YD, 2003, BIOPHYS J, V84, P3257; CARR AM, 1994, MOL GEN GENET, V245, P628; Chalmel F, 2005, BIOINFORMATICS, V21, P2095, DOI 10.1093/bioinformatics/bti252; CHARTON M, 1982, J THEOR BIOL, V99, P629, DOI 10.1016/0022-5193(82)90191-6; CHARTON M, 1981, J THEOR BIOL, V91, P115, DOI 10.1016/0022-5193(81)90377-5; Chen X, 2002, COMPUT CHEM, V26, P661, DOI 10.1016/S0097-8485(02)00050-5; Chen X, 2002, NUCLEIC ACIDS RES, V30, P412, DOI 10.1093/nar/30.1.412; CHOTHIA C, 1976, J MOL BIOL, V105, P1, DOI 10.1016/0022-2836(76)90191-1; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; CID H, 1992, PROTEIN ENG, V5, P373, DOI 10.1093/protein/5.5.373; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cui J, 2005, J MOL MICROB BIOTECH, V9, P86, DOI 10.1159/000088839; DAYHOFF H, 1978, ALTAS PROTEIN SEQUEN, P363; de Lichtenberg U, 2005, BIOINFORMATICS, V21, P1164, DOI 10.1093/bioinformatics/bti093; de Lichtenberg U, 2005, SCIENCE, V307, P724, DOI 10.1126/science.1105103; de Lichtenberg U, 2003, J MOL BIOL, V329, P663, DOI 10.1016/S0022-2836(03)00490-X; des Jardins M, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P92; Dobson PD, 2005, J MOL BIOL, V345, P187, DOI 10.1016/j.jmb.2004.10.024; Dorazilova V, 1992, Cesk Patol, V28, P245; Draghici S, 2003, BIOINFORMATICS, V19, P98, DOI 10.1093/bioinformatics/19.1.98; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; Eisen JA, 1998, GENOME RES, V8, P163; Eisenberg D, 2000, NATURE, V405, P823, DOI 10.1038/35015694; Enright AJ, 2002, NUCLEIC ACIDS RES, V30, P1575, DOI 10.1093/nar/30.7.1575; Enright AJ, 1999, NATURE, V402, P86; Enright AJ, 2000, BIOINFORMATICS, V16, P451, DOI 10.1093/bioinformatics/16.5.451; Feng ZP, 2000, J PROTEIN CHEM, V19, P269, DOI 10.1023/A:1007091128394; Fix E., 1951, DISCRIMINATORY ANAL, P261; Fujiwara Y, 2002, NEC RES DEV, V43, P238; Furlanello C, 2003, NEURAL NETWORKS, V16, P641, DOI 10.1016/S0893-6080(03)00103-5; Gasteiger E, 2005, PROTEOMICS PROTOCOLS, P571, DOI DOI 10.1385/1592598900; GRANTHAM R, 1974, SCIENCE, V185, P862, DOI 10.1126/science.185.4154.862; HALL LH, 2002, USERS GUIDE; Han LY, 2004, RNA, V10, P355, DOI 10.1261/rna.5890304; Han LY, 2005, VIROLOGY, V331, P136, DOI 10.1016/j.virol.2004.10.020; Han LY, 2004, NUCLEIC ACIDS RES, V32, P6437, DOI 10.1093/nar/gkh984; Henikoff S, 1997, SCIENCE, V278, P609, DOI 10.1126/science.278.5338.609; Hodges HC, 2002, FASEB J, V16, pA543; Holm L, 1996, SCIENCE, V273, P595, DOI 10.1126/science.273.5275.595; Honeyman MC, 1998, NAT BIOTECHNOL, V16, P966, DOI 10.1038/nbt1098-966; Horn F, 2003, NUCLEIC ACIDS RES, V31, P294, DOI 10.1093/nar/gkg103; Hou YN, 2004, PROTEINS, V57, P518, DOI 10.1002/prot.20221; Huang N, 2005, PROTEIN ENG DES SEL, V18, P365, DOI 10.1093/protein/gzi041; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Ji ZL, 2003, NUCLEIC ACIDS RES, V31, P255, DOI 10.1093/nar/gkg067; Johnson R.A., 1982, APPL MULTIVARIATE ST; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; King RD, 2004, BIOINFORMATICS, V20, P1110, DOI 10.1093/bioinformatics/bth047; King RD, 2000, YEAST, V17, P283, DOI 10.1002/1097-0061(200012)17:4<283::AID-YEA52>3.0.CO;2-F; Kumar M, 2006, J BIOL CHEM, V281, P5357, DOI 10.1074/jbc.M511061200; Lee TY, 2006, NUCLEIC ACIDS RES, V34, pD622, DOI 10.1093/nar/gkj083; Li H, 2005, CHEM RES TOXICOL, V18, P1071, DOI 10.1021/tx049652h; Lin HH, 2006, J LIPID RES, V47, P824, DOI 10.1194/jlr.M500530-JLR200; Lin HH, 2006, PROTEINS, V62, P218, DOI 10.1002/prot.20605; Lin TY, 1996, PROTEIN SCI, V5, P372; Lipsitz SR, 1996, BIOMETRICS, V52, P291, DOI 10.2307/2533164; Lo SL, 2005, PROTEOMICS, V5, P876, DOI 10.1002/pmic.200401118; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; MORAN PAP, 1950, BIOMETRIKA, V37, P17, DOI 10.2307/2332142; Provost F. J., 1998, P 15 INT C MACH LEAR, P445; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ren QH, 2004, NUCLEIC ACIDS RES, V32, pD284, DOI 10.1093/nar/gkh016; Rost B, 2002, J MOL BIOL, V318, P595, DOI 10.1016/S0022-2836(02)00016-5; Roth BL, 2000, NEUROSCIENTIST, V6, P252; Saier MH, 2006, NUCLEIC ACIDS RES, V34, pD181, DOI 10.1093/nar/gkj001; SCHNEIDER G, 1994, BIOPHYS J, V66, P335; Schomburg I, 2004, NUCLEIC ACIDS RES, V32, pD431, DOI 10.1093/nar/gkh081; Schomburg I, 2002, NUCLEIC ACIDS RES, V30, P47, DOI 10.1093/nar/30.1.47; Schuler GD, 1998, METHOD BIOCHEM ANAL, V39, P145; Shah I, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P276; Smialowski P, 2006, PROTEINS, V62, P343, DOI 10.1002/prot.20789; Smith TF, 1997, NAT BIOTECHNOL, V15, P1222, DOI 10.1038/nbt1197-1222; Sokal RR, 2006, AM J PHYS ANTHROPOL, V129, P121, DOI 10.1002/ajpa.20250; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Sprinzak E, 2001, J MOL BIOL, V311, P681, DOI 10.1006/jmbi.2001.4920; Teichmann SA, 2001, CURR OPIN STRUC BIOL, V11, P354, DOI 10.1016/S0959-440X(00)00215-3; Tenzer S, 2005, CELL MOL LIFE SCI, V62, P1025, DOI 10.1007/s00018-005-4528-2; Todd AE, 2001, J MOL BIOL, V307, P1113, DOI 10.1006/jmbi.2001.4513; Todeschini R., 2002, HDB MOL DESCRIPTORS; Vapnik V. N, 1995, NATURE STAT LEARNING; Veropulos K, 1999, P INT JOINT C ART IN, P55; Wang DC, 2003, J INFECT DIS, V188, P653, DOI 10.1086/377453; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wheeler DL, 2003, NUCLEIC ACIDS RES, V31, P28, DOI 10.1093/nar/gkg033; Whisstock JC, 2003, Q REV BIOPHYS, V36, P307, DOI 10.1017/S0033583503003901; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1630, DOI 10.1021/ci049869h; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Yabuki Y, 2005, NUCLEIC ACIDS RES, V33, pW148, DOI 10.1093/nar/gki; Yan Q, 2000, AAPS PharmSci, V2, pE20; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Zhang JW, 2004, COMPUT BIOL CHEM, V28, P401, DOI 10.1016/j.compbiolchem.2004.09.003; Zhang ZD, 2005, PROTEIN SCI, V14, P431, DOI 10.1110/ps.041035505	132	38	41	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853		PROTEOMICS	Proteomics	JUL	2006	6	14					4023	4037		10.1002/pmic.200500938		15	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	068FR	WOS:000239358600006	
J	Shiue, YR; Guh, RS				Shiue, YR; Guh, RS			Learning-based multi-pass adaptive scheduling for a dynamic manufacturing cell environment	ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING			English	Article						adaptive scheduling; feature selection; generalization ability; artificial neural network; genetic algorithm; machine learning	INTELLIGENT WORKSTATION CONTROLLER; PRODUCTION CONTROL-SYSTEM; NEURAL-NETWORKS; GENETIC ALGORITHMS; JOB SHOP; RULES; OPTIMIZATION; INTEGRATION; SIMULATION; OPERATIONS	Because the essential attributes are uncertain in a dynamic manufacturing cell environment, to select a near-optimal subset of manufacturing attributes to enhance the generalization ability of knowledge bases remains a critical, unresolved issue for classical artificial neural network-based (ANN-based) multi-pass adaptive scheduling (MPAS). To resolve this problem, this Study develops a hybrid genetic/artificial neural network (GA/ANN) approach for ANN-based MPAS systems. The hybrid GA/ANN approach is used to evolve an optimal subset of system attributes from a large set of candidate manufacturing system attributes and, simultaneously, to determine configuration and learning parameters of the ANN according to various performance measures. In the GA/ANN-based MPAS approach, for a given feature subset and the corresponding topology and learning parameters of an ANN decoded by a GA, an ANN was applied to evaluate the fitness in the GA process and to generate the MPAS knowledge base used for adaptive scheduling control mechanisms. The results demonstrate that the proposed GA/ANN-based MPAS approach has, according to various performance criteria, a better system performance over a long period of time than those obtained with classical machine learning-based MPAS approaches and the heuristic individual dispatching rules. (C) 2005 Elsevier Ltd. All rights reserved.	Huafan Univ, Dept Informat Management, Taipei, Taiwan; Natl Formosa Univ, Dept Ind Management, Huwei, Yunlin, Taiwan	Shiue, YR (reprint author), Huafan Univ, Dept Informat Management, Taipei, Taiwan.	yrshiue@cc.hfu.edu.tw					Arifovic J, 2001, PHYSICA A, V289, P574, DOI 10.1016/S0378-4371(00)00479-9; Arzi Y, 2000, INT J PROD RES, V38, P675, DOI 10.1080/002075400189365; Arzi Y, 1999, IIE TRANS, V31, P217, DOI 10.1080/07408179908969822; BAKER KR, 1984, MANAGE SCI, V30, P1093, DOI 10.1287/mnsc.30.9.1093; BILLINGS SA, 1995, NEURAL NETWORKS, V8, P877, DOI 10.1016/0893-6080(95)00029-Y; BLACKSTONE JH, 1982, INT J PROD RES, V20, P27, DOI 10.1080/00207548208947745; Blanco A, 2001, NEURAL NETWORKS, V14, P93, DOI 10.1016/S0893-6080(00)00081-2; Chan FTS, 1999, ROBOT CIM-INT MANUF, V15, P121, DOI 10.1016/S0736-5845(99)00013-7; Chen CC, 1999, INT J PROD RES, V37, P1987, DOI 10.1080/002075499190879; Chen LH, 1996, IEEE COMMUN MAG, V34, P6; CHIU C, 1995, INT J PROD RES, V33, P3217, DOI 10.1080/00207549508904870; CHO H, 1993, INT J PROD RES, V31, P771, DOI 10.1080/00207549308956756; CHO HB, 1995, J MANUF SYST, V14, P252, DOI 10.1016/0278-6125(95)98878-A; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; de Jong K. A., 1975, THESIS U MICHIGAN; Goldberg DE, 1989, GENETIC ALGORITHMS S; Han J, 1996, ENG APPL ARTIF INTEL, V9, P109, DOI 10.1016/0952-1976(95)00001-1; Kim CO, 1998, INT J PROD RES, V36, P2497, DOI 10.1080/002075498192652; LIN YJ, 1991, INT J FLEX MANUF SYS, V3, P189; Medsker L.R., 1995, HYBRID INTELLIGENT S; Mitchell T, 1997, MACHINE LEARNING; MONTAZERI M, 1990, INT J PROD RES, V28, P785, DOI 10.1080/00207549008942754; Park SC, 1997, IEEE T ROBOTIC AUTOM, V13, P486; Patterson D. W., 1996, ARTIFICIAL NEURAL NE; Priore P, 2001, AI EDAM, V15, P251, DOI 10.1017/S0890060401153059; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rumelhart D. K., 1986, LEARNING INTERNAL RE; Sabuncuoglu I, 1998, INT J PROD RES, V36, P527, DOI 10.1080/002075498193877; Sexton RS, 1999, EUR J OPER RES, V114, P589, DOI 10.1016/S0377-2217(98)00114-3; SHAW MJ, 1992, IIE TRANS, V24, P2, DOI 10.1080/07408179208964219; Shiue YR, 2003, INT J COMP INTEG M, V16, P48, DOI 10.1080/0951192021000025689; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; Su CT, 2003, INT J PROD RES, V41, P2619, DOI 10.1080/0020754031000090612; Sun YL, 1996, INT J PROD RES, V34, P2353, DOI 10.1080/00207549608905029; WILHELM WE, 1985, INT J PROD RES, V23, P65, DOI 10.1080/00207548508904691; WU SD, 1988, J MANUF SYS, V7, P1603; WU SYD, 1989, INT J PROD RES, V27, P1603, DOI 10.1080/00207548908942642; *AESOP, 2000, SIMPLE PLUS PLUS REF; *NEUR INC, 2002, NEUR PROF PLUS REF G; *PAL CORP, 1998, EV GUID EV	42	20	20	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0736-5845		ROBOT CIM-INT MANUF	Robot. Comput.-Integr. Manuf.	JUL	2006	22	3					203	216		10.1016/j.rcim.2005.03.004		14	Computer Science, Interdisciplinary Applications; Engineering, Manufacturing; Robotics	Computer Science; Engineering; Robotics	019GC	WOS:000235822600002	
J	Ishibuchi, H; Yamamoto, T; Nakashima, T				Ishibuchi, H; Yamamoto, T; Nakashima, T			An approach to fuzzy default reasoning for function approximation	SOFT COMPUTING			English	Article						fuzzy modeling; fuzzy reasoning; default reasoning; genetics-based machine learning; fuzzy number-valued function	KNOWLEDGE BASES; BELIEF REVISION; RULES; SPECIFICITY; LOGIC; DESIGN	This paper discusses fuzzy reasoning for approximately realizing nonlinear functions by a small number of fuzzy if-then rules with different specificity levels. Our fuzzy rule base is a mixture of general and specific rules, which overlap with each other in the input space. General rules work as default rules in our fuzzy rule base. First, we briefly describe existing approaches to the handling of default rules in the framework of possibility theory. Next, we show that standard interpolation-based fuzzy reasoning leads to counterintuitive results when general rules include specific rules with different consequents. Then, we demonstrate that intuitively acceptable results are obtained from a non-standard inclusion-based fuzzy reasoning method. Our approach is based on the preference for more specific rules, which is a commonly used idea in the field of default reasoning. When a general rule includes a specific rule and they are both compatible with an input vector, the weight of the general rule is discounted in fuzzy reasoning. We also discuss the case where general rules do not perfectly but partially include specific rules. Then we propose a genetics-based machine learning (GBML) algorithm for extracting a small number of fuzzy if-then rules with different specificity levels from numerical data using our inclusion-based fuzzy reasoning method. Finally, we describe how our approach can be applied to the approximate realization of fuzzy number-valued nonlinear functions.	Osaka Prefecture Univ, Dept Comp Sci & Intelligent Syst, Osaka 5998531, Japan	Ishibuchi, H (reprint author), Osaka Prefecture Univ, Dept Comp Sci & Intelligent Syst, Osaka 5998531, Japan.	hisaoi@cs.osakafu-u.ac.jp; yama@ci.cs.osakafu-u.ac.jp; nakashi@cs.osakafu-u.ac.jp	Ishibuchi, Hisao/B-3599-2009	Ishibuchi, Hisao/0000-0001-9186-6472			AGRAWAL R, 1996, ADV KNOWLEDGE DISCOV, P307; Alefeld G, 1983, INTRO INTERVAL COMPU; Bacchus F, 1996, ARTIF INTELL, V87, P75, DOI 10.1016/S0004-3702(96)00003-3; BIEN Z, 1995, FUZZY SET SYST, V71, P95, DOI 10.1016/0165-0114(94)00191-9; Brewka G., 2000, INTELLECTICS COMPUTA, P27; Castillo L, 2001, FUZZY SET SYST, V120, P309, DOI 10.1016/S0165-0114(99)00095-0; Castro JL, 2001, FUZZY SET SYST, V123, P307, DOI 10.1016/S0165-0114(01)00008-2; Cordon O, 1997, FUZZY SET SYST, V86, P15, DOI 10.1016/0165-0114(95)00367-3; Cordon O, 2003, IEEE T FUZZY SYST, V11, P866, DOI 10.1109/TFUZZ.2003.819820; Delgrande JP, 2000, ARTIF INTELL, V123, P41, DOI 10.1016/S0004-3702(00)00049-7; DUBOIS D, 1987, LECT NOTES COMPUT SC, V286, P75; Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8; DUBOIS D, 1994, IEEE T KNOWL DATA EN, V6, P64, DOI 10.1109/69.273026; DUBOIS D, 1988, ARTIF INTELL, V35, P243, DOI 10.1016/0004-3702(88)90014-8; Dubois D., 1994, HDB LOGIC ARTIFICIAL, V3, P439; Dung PM, 2001, ARTIF INTELL, V133, P35, DOI 10.1016/S0004-3702(01)00134-5; Emami MR, 1999, FUZZY SET SYST, V108, P59, DOI 10.1016/S0165-0114(98)00076-1; Goldszmidt M, 1996, ARTIF INTELL, V84, P57, DOI 10.1016/0004-3702(95)00090-9; HOFFMANN F, 1996, GENETIC ALGORITHMS S, P279; Hoffmann F, 1997, INT J APPROX REASON, V17, P447, DOI 10.1016/S0888-613X(97)00005-4; Hong TP, 2001, INT J UNCERTAIN FUZZ, V9, P587, DOI 10.1142/S0218488501001071; Ichihashi H., 1991, P 4 IFSA C ENG, P49; Ishibuchi H., 2004, CLASSIFICATION MODEL; Ishibuchi H, 2001, INFORM SCIENCES, V136, P109, DOI 10.1016/S0020-0255(01)00144-X; ISHIBUCHI H, 1999, P 8 IEEE INT C FUZZ, P198; ISHIBUCHI H, 1999, P 18 INT C N AM FUZZ, P110; Kaufmann A., 1985, INTRO FUZZY ARITHMET; Knorr EM, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P211; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; LEONDES CT, 1999, FUZZY THEORY SYSTEMS, P1; MEES W, 1999, P 8 IEEE INT C FUZZ, P204; Moore R, 1979, SIAM STUDIES APPL MA; POOLE D, 1991, ARTIF INTELL, V49, P281, DOI 10.1016/0004-3702(91)90012-9; REITER R, 1980, ARTIF INTELL, V13, P1; Roubos JA, 2003, IEEE T FUZZY SYST, V11, P861, DOI 10.1109/TFUZZ.2003.819822; Russell S., 1995, ARTIFICIAL INTELLIGE; SUZUKI E, 1998, LECT NOTES COMPUTER, V1510; Suzuki E., 2000, Journal of Japanese Society for Artificial Intelligence, V15; Takagi T., 1985, IEEE T SYST MAN CYB, V15; UEHARA K, 1994, P INT JOINT C 4 IEEE, P2253; Viaene S, 2000, FUZZY SET SYST, V113, P253, DOI 10.1016/S0165-0114(98)00426-6; YAGER RR, 1988, INT J MAN MACH STUD, V29, P685, DOI 10.1016/S0020-7373(88)80074-9; YAGER RR, 1993, IEEE T SYST MAN CYB, V23, P1189, DOI 10.1109/21.247901; YAGER RR, 1991, IEEE T SYST MAN CYB, V21, P790, DOI 10.1109/21.108297; YAGER RR, 1988, INT J GEN SYST, V14, P251, DOI 10.1080/03081078808935007; YAGER RR, 1987, LECT NOTES COMPUT SC, V286, P41; YAGER RR, 1987, ARTIF INTELL, V31, P99, DOI 10.1016/0004-3702(87)90083-X	47	4	4	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	JUL	2006	10	9					850	864		10.1007/s00500-005-0005-y		15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	037CH	WOS:000237123800012	
J	Davel, M; Barnard, E				Davel, M.; Barnard, E.			Bootstrapping pronunciation models	SOUTH AFRICAN JOURNAL OF SCIENCE			English	Article								Bootstrapping techniques can accelerate the development of language technology for resource-scarce languages. We define a framework for the analysis of a general bootstrapping process whereby a model is improved through a controlled series of increments, at each stage using the previous model to generate the next. We apply this framework to the task of creating pronunciation models for resource-scarce languages, iteratively combining machine learning and human knowledge in a way that minimizes the human intervention required during this process. We analyse the effectiveness of such an approach when developing a medium-sized (5000-10 000 word) pronunciation lexicon. We develop such an electronic pronunciation lexicon in Afrikaans, one of South Africa's official languages, and provide initial results obtained for similar lexicons developed in Zulu and Sepedi, two other South African languages. We derive a mathematical model that can be used to predict the amount of time required for the development of a pronunciation lexicon of a given size, demonstrate the various tools that can accelerate the bootstrapping process, and evaluate the efficiency of these tools in practice.	CSIR, Meraka Inst, HLT Res Grp, ZA-0001 Pretoria, South Africa	Davel, M (reprint author), CSIR, Meraka Inst, HLT Res Grp, POB 395, ZA-0001 Pretoria, South Africa.	mdavel@csir.co.za; ebarnard@csir.co.za					Barnard E, 2003, LECT NOTES COMPUT SC, V2739, P37; Black A., 1999, FESTIVAL SPEECH SYNT; COHEN D, 1990, J ARTIFIC INTELL RES, V4, P129; DAVEL M, 2004, P ANN S PATT REC ASS, P119; DAVEL M, 2005, P INTERSPEECH; DAVEL M, 2005, THESIS U PRETORIA S; DAVEL M, 2004, LLSTI ISIZULU TTS EV; Davel M., 2003, P S PATT REC ASS S A, P97; DAVEL M, 2004, LLSTI ISIZULU TTS PR; DAVEL M, 2004, P INTERSPEECH, P2797; LOUW JA, IN PRESS S AFRICAN J; Maskey S., 2004, P INT JEJ KOR OCT, P69; MODIBA TM, 2004, THESIS U N S AFRICA; SEEGER M, 2002, LEARNING LABELED UNL; YOUNG S, 2000, HTK BOOK REVISED HTK	15	2	2	ACAD SCIENCE SOUTH AFRICA A S S AF	LYNWOOD RIDGE	PO BOX 72135, LYNWOOD RIDGE 0040, SOUTH AFRICA	0038-2353		S AFR J SCI	S. Afr. J. Sci.	JUL-AUG	2006	102	7-8					322	329				8	Multidisciplinary Sciences	Science & Technology - Other Topics	125QI	WOS:000243456600010	
J	Lee, BH; Scholz, M				Lee, Byoung-Hwa; Scholz, Miklas			A comparative study: Prediction of constructed treatment wetland performance with K-nearest neighbors and neural networks	WATER AIR AND SOIL POLLUTION			English	Article						biochemical oxygen demand; black box system; constructed treatment wetland; cross-validation; effluent standards; K-nearest-neighbors; neural network; self-organizing map; support vector machine; suspended solids	SUPPORT VECTOR MACHINES; SELF-ORGANIZING MAPS; WATER; SIMULATION; PARAMETERS; SYSTEMS; COPPER; LOADS; STATE	K-nearest neighbors (KNN), support vector machine (SVM) and self-organizing map (SOM) were applied to predict five-day @ 20 degrees C N-Allylthiourea biochemical oxygen demand (BOD) and suspended solids (SS), and to assess novel alternative methods of analyzing water quality performance indicators for constructed treatment wetlands. Concerning the accuracy of prediction, SOM showed a better performance compared to both KNN and SVM. Moreover, SOM had the potential to visualize the relationship between complex biochemical variables. However, optimizing the SOM requires more time in comparison to KNN and SVM because of its trial and error process in searching for the optimal map. The results suggest that BOD and SS can be efficiently estimated by applying machine learning tools with input variables such as redox potential and conductivity, which can be monitored in real time. Their performances are encouraging and support the potential for future use of these models as management tools for the day-to-day process control.	Univ Edinburgh, Inst Infrastruct & Environm, Sch Engn & Elect, Edinburgh EH9 3JL, Midlothian, Scotland	Scholz, M (reprint author), Univ Edinburgh, Inst Infrastruct & Environm, Sch Engn & Elect, Kings Bldg, Edinburgh EH9 3JL, Midlothian, Scotland.	M.Scholz@ed.ac.uk					Aguilera PA, 2001, WATER RES, V35, P4053, DOI 10.1016/S0043-1354(01)00151-8; ALPAYDIN E, 2004, INTRO MACHING LEARNI; Belanche L, 2000, ARTIF INTELL ENG, V14, P307, DOI 10.1016/S0954-1810(00)00012-1; Cao L. J., 2003, IEEE T NEURAL NETWOR, V14; Carpenter GA, 1998, NEURAL NETWORKS, V11, P323, DOI 10.1016/S0893-6080(97)00067-1; Cereghino R, 2001, ECOL MODEL, V146, P167, DOI 10.1016/S0304-3800(01)00304-0; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Dong B, 2005, ENERG BUILDINGS, V37, P545, DOI 10.1016/j.enbuild.2004.09.009; Dong N, 2005, ACTA PHARMACOL SIN, V26, P107, DOI 10.1111/j.1745-7254.2005.00014.x; Dubey A, 2005, J THEOR BIOL, V234, P351, DOI 10.1016/j.jtbi.2004.11.037; Dubois D, 1998, CLIN CHIM ACTA, V270, P3, DOI 10.1016/S0009-8981(97)00232-5; DUCH W, 1999, P INT INF SYST 8 WOR, P32; Garcia HL, 2004, ENG APPL ARTIF INTEL, V17, P215, DOI 10.1016/j.engappai.2004.03.004; Gernaey KV, 2004, ENVIRON MODELL SOFTW, V19, P763, DOI 10.1016/j.envsoft.2003.03.005; Gevrey M, 2004, FRESHWATER BIOL, V49, P208, DOI 10.1046/j.1365-2426.2003.01174.x; Grieu S, 2005, ENG APPL ARTIF INTEL, V18, P559, DOI 10.1016/j.engappai.2004.11.008; Hamed MM, 2004, ENVIRON MODELL SOFTW, V19, P919, DOI 10.1016/j.envsoft.2003.10.005; Hand D., 2001, PRINCIPLES DATA MINI; Hong YST, 2003, WATER RES, V37, P1608, DOI 10.1016/S0043-1354(02)00494-3; HYNDMAN RJ, 2005, 1305 MON EC BUS STAT; IOVINE J, 1998, UNDERSTANDING NEURAL; Joachims T., 1999, ADV KERNEL METHODS; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kohonen T, 2001, SELF ORG MAPS; Lee KD, 2005, EXPERT SYST APPL, V29, P1, DOI 10.1016/j.eswa.2005.01.004; Leflaive J, 2005, J MICROBIOL METH, V62, P89, DOI 10.1016/j.mimet.2005.02.002; Liu HM, 2004, ANAL CHIM ACTA, V525, P31, DOI 10.1016/j.aca.2004.07.033; Lu RS, 2002, WATER RES, V36, P2265, DOI 10.1016/S0043-1354(01)00449-3; Lu WZ, 2005, CHEMOSPHERE, V59, P693, DOI 10.1016/j.chemosphere.2004.10.032; Maier HR, 2004, ENVIRON MODELL SOFTW, V19, P485, DOI 10.1016/S1364-8152(03)00163-4; Mohanty S, 2002, J CHART INST WATER E, V16, P58; Mukherjee A, 1997, J COMPUT CIVIL ENG, V11, P74, DOI 10.1061/(ASCE)0887-3801(1997)11:1(74); Onkal-Engin G, 2005, ENVIRON MODELL SOFTW, V20, P843, DOI 10.1016/j.envsoft.2004.04.012; Pai PF, 2005, ENERG CONVERS MANAGE, V46, P2669, DOI 10.1016/j.enconman.2005.02.004; Ruiz-Jimenez J, 2004, ANAL CHIM ACTA, V525, P159, DOI 10.1016/j.aca.2004.07.059; Scholz M, 2003, WATER RES, V37, P1270, DOI 10.1016/S0043-1354(02)00373-1; Scholz M, 2004, J CHEM TECHNOL BIOT, V79, P153, DOI 10.1002/jctb.955; SCHOLZ M, 2003, BIORESOURCE TECHNOLO, V95, P269; Scholz M, 2002, BIOTECHNOL PROGR, V18, P1257, DOI 10.1021/bp0200503; Vapnik V. N, 1995, NATURE STAT LEARNING; Verdenius F, 1999, ENVIRON MODELL SOFTW, V14, P339, DOI 10.1016/S1364-8152(98)00104-2; Vesanto J., 1999, P MATL DSP C ESP FIN, P35; Werner H, 2001, ECOL MODEL, V146, P289, DOI 10.1016/S0304-3800(01)00314-3	43	18	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0049-6979		WATER AIR SOIL POLL	Water Air Soil Pollut.	JUL	2006	174	1-4					279	301		10.1007/s11270-006-9113-2		23	Environmental Sciences; Meteorology & Atmospheric Sciences; Water Resources	Environmental Sciences & Ecology; Meteorology & Atmospheric Sciences; Water Resources	074MW	WOS:000239817500018	
J	Boeroezky, L; Zhao, LY; Lee, KP				Boeroezky, Lilla; Zhao, Luyin; Lee, K. P.			Feature subset selection for improving the performance of false positive reduction in lung nodule CAD	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article; Proceedings Paper	18th IEEE Symposium on Computer-Based Medical Systems	JUN 23-24, 2005	Dublin, IRELAND	IEEE Comp Soc Tech Comm Computat Med, Trinity Coll Dublin, Dept Comp Sci, Sci Fdn Ireland		computer-aided analysis; genetic algorithms (GAs); medical decision making; supervised machine learning; support vector machines	COMPUTERIZED DETECTION	We propose a feature subset selection method based on genetic algorithms to improve the performance of false positive reduction in lung nodule computer-aided detection (CAD). It is coupled with a classifier based on support vector machines. The proposed approach determines automatically the optimal size of the feature set, and chooses the most relevant features from a feature pool. Its performance was tested using a lung nodule database (52 true nodules and 443 false ones) acquired by multislice CT scans. From 23 features calculated for each detected structure, the suggested method determined ten to be the optimal feature subset size, and selected the most relevant ten features. A support vector machine classifier trained with the optimal feature subset resulted in 100% sensitivity and 56.4% specificity using an independent validation set. Experiments show significant improvement achieved by a system incorporating the proposed method over a system without it. This approach can be also applied to other machine learning problems; e.g. computer-aided diagnosis of lung nodules.	Philips Res N Amer, Briarcliff Manor, NY 10510 USA	Boeroezky, L (reprint author), Philips Res N Amer, Briarcliff Manor, NY 10510 USA.	lilla.boroczky@philips.com; luyin.zhao@philips.com; kp.lee@philips.com					American Cancer Society, 2005, CANC FACTS FIG 2005; Batista G. E. A. P. A., 2004, SIGKDD EXPLORATIONS, V6, P20, DOI DOI 10.1145/1007730.1007735; BEGG R, 2003, P C CONV TECHN AS PA, V1, P354; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; Doak J., 1992, CSE9218 U CAL; Doi K, 2005, BRIT J RADIOL, V78, pS3, DOI 10.1259/bjr/8293343; Eshelman L., 1991, FDN GENETIC ALGORITH, P265; FAN RE, 2005, J MACH LEARN RES, V6, P1855; GE Z, 2004, P MED IM 2004 IM PRO; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LIN JS, 1993, P ANN S COMP APPL ME, P34; MEYER, 2002, BENCHMARKING SUPPORT; MOUSA WAH, 2002, P INT C IM PROC, V3, P153; PAL M, 2003, MAP IND; PASQUARIELLO G, 2002, P IEEE INT C GEOSC R, V1, P509; ROHLICH H, 2003, P 15 IEEE INT C TOOL, P142; SCHAFFER D, 2005, P IEEE S COMP INT BI, P392; Suzuki K, 2003, MED PHYS, V30, P1602, DOI 10.1118/1.1580485; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Wiemker R, 2002, P SOC PHOTO-OPT INS, V4684, P677, DOI 10.1117/12.467210; Wu Y C, 1994, J Digit Imaging, V7, P196; Yang J., 1998, FEATURE EXTRACTION C; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; Yoshida H, 2004, IEEE T BIO-MED ENG, V51, P778, DOI 10.1109/TBME.2004.824136	26	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	JUL	2006	10	3					504	511		10.1109/TITB.2006.872063		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	063PW	WOS:000239033000011	
J	Su, CT; Chen, CY; Ou, YY				Su, Chung-Tsai; Chen, Chien-Yu; Ou, Yu-Yen			Protein disorder prediction by condensed PSSM considering propensity for order or disorder	BMC BIOINFORMATICS			English	Article							INTRINSICALLY UNSTRUCTURED PROTEINS; NATIVELY UNFOLDED PROTEINS; AMINO-ACID-COMPOSITION; ENERGY CONTENT; SEQUENCE; REGIONS; DATABASES; SERVER	Background: More and more disordered regions have been discovered in protein sequences, and many of them are found to be functionally significant. Previous studies reveal that disordered regions of a protein can be predicted by its primary structure, the amino acid sequence. One observation that has been widely accepted is that ordered regions usually have compositional bias toward hydrophobic amino acids, and disordered regions are toward charged amino acids. Recent studies further show that employing evolutionary information such as position specific scoring matrices (PSSMs) improves the prediction accuracy of protein disorder. As more and more machine learning techniques have been introduced to protein disorder detection, extracting more useful features with biological insights attracts more attention. Results: This paper first studies the effect of a condensed position specific scoring matrix with respect to physicochemical properties (PSSMP) on the prediction accuracy, where the PSSMP is derived by merging several amino acid columns of a PSSM belonging to a certain property into a single column. Next, we decompose each conventional physicochemical property of amino acids into two disjoint groups which have a propensity for order and disorder respectively, and show by experiments that some of the new properties perform better than their parent properties in predicting protein disorder. In order to get an effective and compact feature set on this problem, we propose a hybrid feature selection method that inherits the efficiency of uni-variant analysis and the effectiveness of the stepwise feature selection that explores combinations of multiple features. The experimental results show that the selected feature set improves the performance of a classifier built with Radial Basis Function Networks (RBFN) in comparison with the feature set constructed with PSSMs or PSSMPs that adopt simply the conventional physicochemical properties. Conclusion: Distinguishing disordered regions from ordered regions in protein sequences facilitates the exploration of protein structures and functions. Results based on independent testing data reveal that the proposed predicting model DisPSSMP performs the best among several of the existing packages doing similar tasks, without either under-predicting or over-predicting the disordered regions. Furthermore, the selected properties are demonstrated to be useful in finding discriminating patterns for order/disorder classification.	Natl Taiwan Univ, Dept Bioind Mechatron Engn, Taipei 106, Taiwan; Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan; Yuan Ze Univ, Grad Sch Biotechnol & Bioinformat, Chungli 320, Taiwan; Yuan Ze Univ, Dept Comp Sci & Engn, Chungli 320, Taiwan	Su, CT (reprint author), Natl Taiwan Univ, Dept Bioind Mechatron Engn, Taipei 106, Taiwan.	sbb@mars.csie.ntu.edu.tw; cychen@mars.csie.ntu.edu.tw; yien@csie.org					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BOZ O, 2002, ICMLA INT C MACH LEA, pP147; Chen YC, 2004, PROTEINS, V55, P1036, DOI 10.1002/prot.20079; Cheng JL, 2005, DATA MIN KNOWL DISC, V11, P213, DOI 10.1007/s10618-005-0001-y; Coeytaux K, 2005, BIOINFORMATICS, V21, P1891, DOI 10.1093/bioinformatics/bti266; Dosztanyi Z, 2005, J MOL BIOL, V347, P827, DOI 10.1016/j.jmb.2005.01.071; Dosztanyi Z, 2005, BIOINFORMATICS, V21, P3433, DOI 10.1093/bioinformatics/bti541; Dunker AK, 2002, ADV PROTEIN CHEM, V62, P25; Dunker AK, 2002, BIOCHEMISTRY-US, V41, P6573, DOI 10.1021/bi012159+; Dunker AK, 1998, PAC S BIOCOMP, V3, P473; Fink AL, 2005, CURR OPIN STRUC BIOL, V15, P35, DOI 10.1016/j.sbi.2005.01.002; Garner E, 1998, GENOME INFORM, V9, P201; JIN Y, 2005, PROTEINS; JOHN GH, 1994, MACH LEARN P 11 INT, pP121; Jones DT, 2003, PROTEINS, V53, P573, DOI 10.1002/prot.10528; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; Li X., 1999, GENOME INFORMATICS, V10, P30; Linding R, 2003, STRUCTURE, V11, P1453, DOI 10.1016/j.str.2003.10.002; Linding R, 2003, NUCLEIC ACIDS RES, V31, P3701, DOI 10.1093/nar/gkg519; Lise S, 2005, PROTEINS, V58, P144, DOI 10.1002/prot.20279; Melamud E, 2003, PROTEINS, V53, P561, DOI 10.1002/prot.10533; Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092; Obradovic Z, 2003, PROTEINS, V53, P566, DOI 10.1002/prot.10532; Obradovic Z, 1999, GENOME INFORM SER WO, V10, P41; Peng Kang, 2005, Journal of Bioinformatics and Computational Biology, V3, P35, DOI 10.1142/S0219720005000886; Plaxco KW, 1997, NATURE, V386, P657, DOI 10.1038/386657a0; Prilusky J, 2005, BIOINFORMATICS, V21, P3435, DOI 10.1093/bioinformatics/bti537; Radivojac P., 2003, PAC S BIOC, V8, P216; Romero P, 2001, PROTEINS, V42, P38, DOI 10.1002/1097-0134(20010101)42:1<38::AID-PROT50>3.0.CO;2-3; Romero P, 1997, GENOME INFORMATICS, V8, P110; Romero P., 1998, PAC S BIOCOMP, V3, P437; ROMERO P, 1997, P IEEE INT C NEUR NE, V1, P90, DOI 10.1109/ICNN.1997.611643; SCHULZ GE, MOL MECH BIOL RECOGN, P79; SHIMIZU K, 2004, GENOME INFORMATICS, pP150; Uversky VN, 2000, PROTEINS, V41, P415, DOI 10.1002/1097-0134(20001115)41:3<415::AID-PROT130>3.0.CO;2-7; Villafranca E, 1997, PDB NEWSLETTER, V81, P3; Vucetic S, 2005, BIOINFORMATICS, V21, P137, DOI 10.1093/bioinformatics/bth476; Vucetic S, 2003, PROTEINS, V52, P573, DOI 10.1002/prot.10437; Ward JJ, 2004, J MOL BIOL, V337, P635, DOI 10.1016/j.jmb.2004.02.002; Ward JJ, 2004, BIOINFORMATICS, V20, P2138, DOI 10.1093/bioinformatics/bth195; Wright PE, 1999, J MOL BIOL, V293, P321, DOI 10.1006/jmbi.1999.3110; YANG ZR, 2005, BIOINFORMATICS  0609; Zhang QD, 2005, BIOINFORMATICS, V21, P2370, DOI 10.1093/bioinformatics/bti358; QUICKRBF; CHEM CLASSIFICATIONS	47	41	42	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JUN 23	2006	7								319	10.1186/1471-2105-7-319		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	070JX	WOS:000239519200001	
J	Petrova, NV; Wu, CH				Petrova, Natalia V.; Wu, Cathy H.			Prediction of catalytic residues using Support Vector Machine with selected protein sequence and structural properties	BMC BIOINFORMATICS			English	Article							EVOLUTIONARY TRACE ANALYSIS; FUNCTIONAL SITES; ENZYME FUNCTION; ACTIVE-SITES; CONSERVATION; ALIGNMENT; BINDING; SIMILARITY; PARAMETERS; STABILITY	Background: The number of protein sequences deriving from genome sequencing projects is outpacing our knowledge about the function of these proteins. With the gap between experimentally characterized and uncharacterized proteins continuing to widen, it is necessary to develop new computational methods and tools for functional prediction. Knowledge of catalytic sites provides a valuable insight into protein function. Although many computational methods have been developed to predict catalytic residues and active sites, their accuracy remains low, with a significant number of false positives. In this paper, we present a novel method for the prediction of catalytic sites, using a carefully selected, supervised machine learning algorithm coupled with an optimal discriminative set of protein sequence conservation and structural properties. Results: To determine the best machine learning algorithm, 26 classifiers in the WEKA software package were compared using a benchmarking dataset of 79 enzymes with 254 catalytic residues in a 10-fold cross-validation analysis. Each residue of the dataset was represented by a set of 24 residue properties previously shown to be of functional relevance, as well as a label {+ 1/-1} to indicate catalytic/non-catalytic residue. The best-performing algorithm was the Sequential Minimal Optimization ( SMO) algorithm, which is a Support Vector Machine ( SVM). The Wrapper Subset Selection algorithm further selected seven of the 24 attributes as an optimal subset of residue properties, with sequence conservation, catalytic propensities of amino acids, and relative position on protein surface being the most important features. Conclusion: The SMO algorithm with 7 selected attributes correctly predicted 228 of the 254 catalytic residues, with an overall predictive accuracy of more than 86%. Missing only 10.2% of the catalytic residues, the method captures the fundamental features of catalytic residues and can be used as a "catalytic residue filter" to facilitate experimental identification of catalytic residues for proteins with known structure but unknown function.	Georgetown Univ, Med Ctr, Dept Biochem & Mol Biol & Cellular Biol, Washington, DC 20007 USA	Wu, CH (reprint author), Georgetown Univ, Med Ctr, Dept Biochem & Mol Biol & Cellular Biol, Washington, DC 20007 USA.	np6@georgetown.edu; wuc@georgetown.edu	Crozier, Laura/A-4821-2010				Aloy P, 2001, J MOL BIOL, V311, P395, DOI 10.1006/jmbi.2001.4870; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, pD226, DOI 10.1093/nar/gkh039; Bartlett GJ, 2002, J MOL BIOL, V324, P105, DOI 10.1016/S0022-2836(02)01036-7; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Binkowski TA, 2003, NUCLEIC ACIDS RES, V31, P3352, DOI 10.1093/nar/gkg512; Campbell SJ, 2003, CURR OPIN STRUC BIOL, V13, P389, DOI 10.1016/S0958-440X(03)00075-7; Chakravarty S, 2005, J VIROL, V79, P554, DOI 10.1128/JVI.79.1.554-568.2005; Elcock AH, 2001, J MOL BIOL, V312, P885, DOI 10.1006/jmbi.2001.5009; Gutteridge A, 2003, J MOL BIOL, V330, P719, DOI 10.1016/S0022-2836(03)00515-1; HEARST MA, 1998, IEEE INTELLIGENT JUL, P18; Hubbard SJ, 1993, NACCESS COMPUTER PRO; Innis CA, 2000, PROTEIN ENG, V13, P839, DOI 10.1093/protein/13.12.839; Jones S, 2004, CURR OPIN CHEM BIOL, V8, P3, DOI 10.1016/j.cbpa.2003.11.001; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kinoshita K, 2003, PROTEIN SCI, V12, P1589, DOI 10.1110/ps.0368703; KOHAVI R, 1996, WRAPPERS FEATURE SUB, P1; Koradi R, 1996, J MOL GRAPHICS, V14, P51, DOI 10.1016/0263-7855(96)00009-4; Koradi R., 1996, J MOL GRAPHICS, V14, P29; Landgraf R, 2001, J MOL BIOL, V307, P1487, DOI 10.1006/jmbi.2001.4540; LEE B, 1971, J MOL BIOL, V55, P379, DOI 10.1016/0022-2836(71)90324-X; Lichtarge O, 1996, J MOL BIOL, V257, P342, DOI 10.1006/jmbi.1996.0167; Mathews B.W., 1975, BIOCHIM BIOPHYS ACTA, V405, P442; Milton J.S., 1999, STAT METHODS BIOL HL; Ondrechen MJ, 2001, P NATL ACAD SCI USA, V98, P12473, DOI 10.1073/pnas.211436698; Ota M, 2003, J MOL BIOL, V327, P1053, DOI 10.1016/S0022-2836(03)00207-9; Panchenko AR, 2004, PROTEIN SCI, V13, P884, DOI 10.1110/ps.03465504; Parthasarathy S, 2000, PROTEIN ENG, V13, P9, DOI 10.1093/protein/13.1.9; PETROVA NV, PLOS COMP BIOL LAT B, pA3; PLATT JC, 2000, MICROSOFT RES, V12, P41; Rost B, 2003, CELL MOL LIFE SCI, V60, P2637, DOI 10.1007/s00018-003-3114-8; Sjolander K, 1996, COMPUT APPL BIOSCI, V12, P327; Smith DK, 2003, PROTEIN SCI, V12, P1060, DOI 10.1110/ps.0236203; TATUSOV RL, 1994, P NATL ACAD SCI USA, V91, P12091, DOI 10.1073/pnas.91.25.12091; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Tian WD, 2003, J MOL BIOL, V333, P863, DOI 10.1016/j.jmb.2003.08.057; Valdar WSJ, 2002, PROTEINS, V48, P227, DOI 10.1002/prot.10146; Wangikar PP, 2003, J MOL BIOL, V326, P955, DOI 10.1016/S0022-2836(02)01384-0; Witten I. H., 2005, DATA MINING PRACTICA; Wu CH, 2003, NUCLEIC ACIDS RES, V31, P345, DOI 10.1093/nar/gkg040; Yao H, 2003, J MOL BIOL, V326, P255, DOI 10.1016/S0022-2836(02)01336-0; Zhu SY, 2004, PROTEINS, V54, P361, DOI 10.1002/prot.10588	42	60	61	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JUN 21	2006	7								312	10.1186/1471-2105-7-312		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	073IW	WOS:000239737200001	
J	Mitra, AP; Almal, AA; George, B; Fry, DW; Lenehan, PF; Pagliarulo, V; Cote, RJ; Datar, RH; Worzel, WP				Mitra, Anirban P.; Almal, Arpit A.; George, Ben; Fry, David W.; Lenehan, Peter F.; Pagliarulo, Vincenzo; Cote, Richard J.; Datar, Ram H.; Worzel, William P.			The use of genetic programming in the analysis of quantitative gene expression profiles for identification of nodal status in bladder cancer	BMC CANCER			English	Article							ACTIVATED PROTEIN-KINASE; INTERCELLULAR-ADHESION MOLECULE-1; BREAST EPITHELIAL-CELLS; HUMAN ANNEXIN-V; RADICAL CYSTECTOMY; MEDIATOR COMPLEXES; URINARY-BLADDER; LYMPH-NODES; RT-PCR; P38	Background: Previous studies on bladder cancer have shown nodal involvement to be an independent indicator of prognosis and survival. This study aimed at developing an objective method for detection of nodal metastasis from molecular profiles of primary urothelial carcinoma tissues. Methods: The study included primary bladder tumor tissues from 60 patients across different stages and 5 control tissues of normal urothelium. The entire cohort was divided into training and validation sets comprised of node positive and node negative subjects. Quantitative expression profiling was performed for a panel of 70 genes using standardized competitive RT-PCR and the expression values of the training set samples were run through an iterative machine learning process called genetic programming that employed an N-fold cross validation technique to generate classifier rules of limited complexity. These were then used in a voting algorithm to classify the validation set samples into those associated with or without nodal metastasis. Results: The generated classifier rules using 70 genes demonstrated 81% accuracy on the validation set when compared to the pathological nodal status. The rules showed a strong predilection for ICAM1, MAP2K6 and KDR resulting in gene expression motifs that cumulatively suggested a pattern ICAM1> MAP2K6> KDR for node positive cases. Additionally, the motifs showed CDK8 to be lower relative to ICAM1, and ANXA5 to be relatively high by itself in node positive tumors. Rules generated using only ICAM1, MAP2K6 and KDR were comparably robust, with a single representative rule producing an accuracy of 90% when used by itself on the validation set, suggesting a crucial role for these genes in nodal metastasis. Conclusion: Our study demonstrates the use of standardized quantitative gene expression values from primary bladder tumor tissues as inputs in a genetic programming system to generate classifier rules for determining the nodal status. Our method also suggests the involvement of ICAM1, MAP2K6, KDR, CDK8 and ANXA5 in unique mathematical combinations in the progression towards nodal positivity. Further studies are needed to identify more class-specific signatures and confirm the role of these genes in the evolution of nodal metastasis in bladder cancer.	Univ So Calif, Keck Sch Med, Dept Pathol, Los Angeles, CA 90033 USA; Genet Squared Inc, Ann Arbor, MI 48104 USA; Gundersen Lutheran Med Ctr, Dept Internal Med, La Crosse, WI 54601 USA; Univ Bari, Dipartimento Emergenzia & Trapianti Organo, Sez Urol, I-70124 Bari, Italy	Datar, RH (reprint author), Univ So Calif, Keck Sch Med, Dept Pathol, 2011 Zonal Ave,HMR 312, Los Angeles, CA 90033 USA.	amitra@usc.edu; aalmal@genetics2.com; bgeorge@gundluth.org; dfry@genetics2.com; plenehan@genetics2.com; vpagliarulo@urologia.uniba.it; cote_r@ccnt.hsc.usc.edu; datar@usc.edu; bworzel@genetics2.com	Mitra, Anirban/A-9101-2008	Mitra, Anirban/0000-0002-6549-5943			Akoulitchev S, 2000, NATURE, V407, P102; ANDRE D, 1996, P INT C PAR DISTR PR, P1163; Ather M Hammad, 2005, World J Surg Oncol, V3, P43, DOI 10.1186/1477-7819-3-43; Behren A, 2005, EXP CELL RES, V303, P321, DOI 10.1016/j.yexcr.2004.10.004; Belhocine T, 2002, CLIN CANCER RES, V8, P2766; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bonassi S, 2001, MUTAT RES-FUND MOL M, V480, P349, DOI 10.1016/S0027-5107(01)00194-4; Brameier M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-16; COOKSON BT, 1994, GENOMICS, V20, P463, DOI 10.1006/geno.1994.1201; Crawford EL, 2001, MOL DIAGN, V6, P217, DOI 10.1054/modi.2001.29789; Crawford EL, 2002, BIOCHEM BIOPH RES CO, V293, P509, DOI 10.1016/S0006-291X(02)00243-7; Daida JM, 2003, GENET PROGR SER, V6, P99; Deserno WMLLG, 2004, RADIOLOGY, V233, P449, DOI 10.1148/radiol.2332031111; Driscoll JA, 2003, GENET PROGR SER, V6, P25; Dyrskjot L, 2003, NAT GENET, V33, P90, DOI 10.1038/ng1061; Eggermont J., 2004, P 2004 S APPL COMP A, P1001, DOI 10.1145/967900.968104; Esteva FJ, 2004, CANCER, V100, P499, DOI 10.1002/cncr.11940; Ferrer FA, 1999, UROLOGY, V54, P567, DOI 10.1016/S0090-4295(99)00156-9; Gakiopoulou-Givalou H, 2003, HISTOPATHOLOGY, V43, P272, DOI 10.1046/j.1365-2559.2003.01690.x; Greene FL, 2002, AJCC CANC STAGING MA, P367; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T, 2001, ELEMENTS STAT LEARNI; Hawkins TE, 2002, P NATL ACAD SCI USA, V99, P8054, DOI 10.1073/pnas.132598099; Hayes MJ, 2004, TRAFFIC, V5, P571, DOI 10.1111/j.1600-0854.2004.00210.x; Hayes MJ, 2004, BIOCHEM BIOPH RES CO, V322, P1166, DOI 10.1016/j.bbrc.2004.07.124; Hollenbeck BK, 2004, NAT CLIN PRACT UROL, V1, P4, DOI 10.1038/ncpuro0008; Hong JH, 2005, LECT NOTES ARTIF INT, V3558, P294; Hubbard AK, 2000, FREE RADICAL BIO MED, V28, P1379, DOI 10.1016/S0891-5849(00)00223-9; Kawamukai Kenji, 2004, Rays, V29, P373; Kim MS, 2003, CANCER RES, V63, P5454; Koza J. R., 1992, GENETIC PROGRAMMING; Kurahashi T, 2005, CLIN CANCER RES, V11, P3773, DOI 10.1158/1078-0432.CCR-04-2297; Langdon W. B., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030196.55525.f7; Leissner J, 2000, BJU INT, V85, P817, DOI 10.1046/j.1464-410x.2000.00614.x; LIAO SM, 1995, NATURE, V374, P193, DOI 10.1038/374193a0; Lotan Y, 2005, J CLIN ONCOL, V23, P6533, DOI 10.1200/JCO.2005.05.516; Malik S, 2000, MOL CELL, V5, P753, DOI 10.1016/S1097-2765(00)80254-3; Mitra AP, 2005, BJU INT, V96, P7, DOI 10.1111/j.1464-410X.2005.05557.x; MOORE JH, 2001, LECT NOTES ARTIF INT, V2167, P372; Narasimhamurthy A, 2005, IEEE T PATTERN ANAL, V27, P1988, DOI 10.1109/TPAMI.2005.249; Narasimhamurthy AM, 2003, LECT NOTES COMPUT SC, V2749, P268; Ott I, 2005, CIRCULATION, V111, P349, DOI 10.1161/01.CIR.0000153333.52294.42; Ozer G, 2003, UROL INT, V70, P167, DOI 10.1159/000068773; Pagliarulo V, 2004, MOL CANCER, V3, DOI 10.1186/1476-4598-3-5; Palumbo JS, 2002, CANCER RES, V62, P6966; Rachez C, 1999, NATURE, V398, P824; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Roche Y, 2003, THROMB HAEMOSTASIS, V89, P1089; Rosette C, 2005, CARCINOGENESIS, V26, P943, DOI 10.1093/carcin/bgi070; Roux PP, 2004, MICROBIOL MOL BIOL R, V68, P320, DOI 10.1128/MMBR.68.2.320-344.2004; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; Shibuya M, 2003, CANCER SCI, V94, P751, DOI 10.1111/j.1349-7006.2003.tb01514.x; Shin I, 2005, J BIOL CHEM, V280, P14675, DOI 10.1074/jbc.M411625200; Stein JP, 2001, J CLIN ONCOL, V19, P666; Sun XQ, 1998, MOL CELL, V2, P213, DOI 10.1016/S1097-2765(00)80131-8; TASSAN JP, 1995, P NATL ACAD SCI USA, V92, P8871, DOI 10.1073/pnas.92.19.8871; Townson JL, 2003, CURR MOL MED, V3, P631, DOI 10.2174/1566524033479483; TYCZYNSKI JE, 2003, ENCR CANC FACT SHEET, V3, P1; Tzima E, 2000, EUR J BIOCHEM, V267, P4720, DOI 10.1046/j.1432-1327.2000.01525.x; Vapnik V. N, 1995, NATURE STAT LEARNING; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Wang G, 2001, MOL CELL BIOL, V21, P4604, DOI 10.1128/MCB.21.14.4604-4613.2001; Wang Q, 2001, J IMMUNOL, V166, P6877; Willey JC, 1998, AM J RESP CELL MOL, V19, P6; World Health Organization, 2004, WORLD HLTH REP 2004; Zarubin T, 2005, CELL RES, V15, P11, DOI 10.1038/sj.cr.7290257; Zou KH, 1997, STAT MED, V16, P2143, DOI 10.1002/(SICI)1097-0258(19971015)16:19<2143::AID-SIM655>3.3.CO;2-V; *NAT CANC I, 2004, MEDNEWS TREATM STAT	69	26	28	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2407		BMC CANCER	BMC Cancer	JUN 16	2006	6								159	10.1186/1471-2407-6-159		17	Oncology	Oncology	074WV	WOS:000239843400001	
J	Cheng, JL; Baldi, P				Cheng, JL; Baldi, P			A machine learning information retrieval approach to protein fold recognition	BIOINFORMATICS			English	Article							HIDDEN MARKOV-MODELS; MULTIPLE SEQUENCE ALIGNMENT; PROFILE-PROFILE ALIGNMENT; REMOTE HOMOLOGY DETECTION; SECONDARY STRUCTURE; PSI-BLAST; STRUCTURAL CLASSIFICATION; NEURAL-NETWORKS; GAP PENALTIES; PREDICTION	Motivation: Recognizing proteins that have similar tertiary structure is the key step of template-based protein structure prediction methods. Traditionally, a variety of alignment methods are used to identify similar folds, based on sequence similarity and sequence-structure compatibility. Although these methods are complementary, their integration has not been thoroughly exploited. Statistical machine learning methods provide tools for integrating multiple features, but so far these methods have been used primarily for protein and fold classification, rather than addressing the retrieval problem of fold recognition-finding a proper template for a given query protein. Results: Here we present a two-stage machine learning, information retrieval, approach to fold recognition. First, we use alignment methods to derive pairwise similarity features for query-template protein pairs. We also use global profile-profile alignments in combination with predicted secondary structure, relative solvent accessibility, contact map and beta-strand pairing to extract pairwise structural compatibility features. Second, we apply support vector machines to these features to predict the structural relevance (i.e. in the same fold or not) of the query-template pairs. For each query, the continuous relevance scores are used to rank the templates. The FOLDpro approach is modular, scalable and effective. Compared with 11 other fold recognition methods, FOLDpro yields the best results in almost all standard categories on a comprehensive benchmark dataset. Using predictions of the top-ranked template, the sensitivity is similar to 85, 56, and 27% at the family, superfamily and fold levels respectively. Using the 5 top-ranked templates, the sensitivity increases to 90, 70, and 48%.	Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA	Baldi, P (reprint author), Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA.	pfbaldi@ics.uci.edu					ABAGYAN R, 1994, PROTEINS, V19, P132, DOI 10.1002/prot.340190206; ALLAZIKANI B, 1998, P NATL ACAD SCI USA, V98, P14796; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bailey TL, 1997, J COMPUT BIOL, V4, P45, DOI 10.1089/cmb.1997.4.45; BALDI P, 1994, P NATL ACAD SCI USA, V91, P1059, DOI 10.1073/pnas.91.3.1059; BOWIE JU, 1991, SCIENCE, V253, P164, DOI 10.1126/science.1853201; BRYANT SH, 1993, PROTEINS, V16, P92, DOI 10.1002/prot.340160110; Cheng HL, 2005, COUNS PSYCHOL, V33, P72, DOI 10.1177/0011000004270343; Cheng JL, 2005, BIOINFORMATICS, V21, pI75, DOI 10.1093/bioinformatics/bti1004; Davis R, 2000, NEUROMODULATION, V3, P1, DOI 10.1046/j.1525-1403.2000.00001.x; DAYHOFF MO, 1983, METHOD ENZYMOL, V91, P524; Domingues FS, 2000, J MOL BIOL, V297, P1003, DOI 10.1006/jmbi.2000.3615; Eddy SR, 1998, BIOINFORMATICS, V14, P755, DOI 10.1093/bioinformatics/14.9.755; Edgar RC, 2003, BIOINFORMATICS, V19, P1404, DOI 10.1093/bioinformatics/btg158; Edgar RC, 2004, BIOINFORMATICS, V20, P1309, DOI 10.1093/bioinformatics/bth091; Elofsson A, 1996, FOLD DES, V1, P451, DOI 10.1016/S1359-0278(96)00061-2; Fischer D, 2003, PROTEINS, V51, P434, DOI 10.1002/prot.10357; Fischer D, 2000, Pac Symp Biocomput, P119; Ginalski K, 2003, BIOINFORMATICS, V19, P1015, DOI 10.1093/bioinformatics/btg124; Ginalski K, 2003, NUCLEIC ACIDS RES, V31, P3804, DOI 10.1093/nar/gkg504; GODZIK A, 1992, P NATL ACAD SCI USA, V89, P12098, DOI 10.1073/pnas.89.24.12098; Gough J, 2001, J MOL BIOL, V313, P903, DOI 10.1006/jmbi.2001.5080; Griffiths-Jones S, 2002, BIOINFORMATICS, V18, P1243, DOI 10.1093/bioinformatics/18.9.1243; Hargbo J, 1999, PROTEINS, V36, P68, DOI 10.1002/(SICI)1097-0134(19990701)36:1<68::AID-PROT6>3.0.CO;2-1; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Hughey R, 1996, COMPUT APPL BIOSCI, V12, P95; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Jaroszewski L, 1998, PROTEIN SCI, V7, P1431; JOACHIMS T, 1999, MAKING LARGESCALE SV; Jones DT, 1999, J MOL BIOL, V287, P797, DOI 10.1006/jmbi.1999.2583; JONES DT, 1992, NATURE, V358, P86, DOI 10.1038/358086a0; Juan D, 2003, PROTEINS, V50, P600, DOI 10.1002/prot.10322; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; Kelley LA, 2000, J MOL BIOL, V299, P499; Kim D, 2003, PROTEIN ENG, V16, P641, DOI 10.1093/protein/gzg081; Koretke KK, 2001, PROTEINS, P68; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Leslie Christina, 2002, Pac Symp Biocomput, P564; Lindahl E, 2000, J MOL BIOL, V295, P613, DOI 10.1006/jmbi.1999.3377; Lundstrom J, 2001, PROTEIN SCI, V10, P2354, DOI 10.1110/ps.08501; Madera M, 2002, NUCLEIC ACIDS RES, V30, P4321, DOI 10.1093/nar/gkf544; Marti-Renom MA, 2004, PROTEIN SCI, V13, P1071, DOI 10.1110/ps.03379804; MITELMAN D, 2003, BIOINFORMATICS, V19, P1531; Moult J, 2005, PROTEINS, V61, P3, DOI 10.1002/prot.20716; Murzin AG, 1997, PROTEINS, P105; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Notredame C, 2000, J MOL BIOL, V302, P205, DOI 10.1006/jmbi.2000.4042; Ohlson T, 2004, PROTEINS, V57, P188, DOI 10.1002/prot.20184; OHSEN N, 2003, PAC S BIOCOMPUT, P252; O'Sullivan O, 2004, J MOL BIOL, V340, P385, DOI 10.1016/j.jmp.2004.04.056; PAGE L, 1998, PAGE RANK CITATION M; Panchenko AR, 2000, J MOL BIOL, V296, P1319, DOI 10.1006/jmbi.2000.3541; Park J, 1998, J MOL BIOL, V284, P1201, DOI 10.1006/jmbi.1998.2221; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Pettitt CS, 2005, BIOINFORMATICS, V21, P3509, DOI 10.1093/bioinformatics/bti540; POLLASTRI G, 2001, PROTEINS, V47, P142; Pollastri G., 2002, BIOINFORMATICS S1, V18, P62; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; ROCCHIO JJ, 1966, THESIS HARVARD U CAM; Rost B, 1997, J MOL BIOL, V270, P471, DOI 10.1006/jmbi.1997.1101; Rychlewski L, 2000, PROTEIN SCI, V9, P232; Sadreyev R, 2003, J MOL BIOL, V326, P317, DOI 10.1016/S0022-2836(02)01371-2; Schaffer AA, 1999, BIOINFORMATICS, V15, P1000; Scholkopf B., 2002, LEARNING KERNELS SUP; Shan YB, 2001, PROTEINS, V42, P23, DOI 10.1002/1097-0134(20010101)42:1<23::AID-PROT40>3.0.CO;2-K; Shi JY, 2001, J MOL BIOL, V310, P243, DOI 10.1006/jmbi.2001.4762; Skolnick J, 2001, PROTEINS, V42, P319, DOI 10.1002/1097-0134(20010215)42:3<319::AID-PROT30>3.3.CO;2-1; Smith SS, 1998, INT J MOL MED, V1, P147; Soding J, 2005, BIOINFORMATICS, V21, P951, DOI 10.1093/bioinformatics/bti125; Tang CL, 2003, J MOL BIOL, V334, P1043, DOI 10.1016/j.jmb.2003.10.025; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Vapnik VN, 1998, STAT LEARNING THEORY; VINGRON M, 1994, J MOL BIOL, V235, P1, DOI 10.1016/S0022-2836(05)80006-3; Wallner B, 2004, PROTEINS, V54, P342, DOI 10.1002/prot.10565; Wang GL, 2004, PROTEIN SCI, V13, P1612, DOI 10.1110/ps.03601504; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Xu Jinbo, 2003, Pac Symp Biocomput, P264; Xu Y, 1998, J COMPUT BIOL, V5, P597, DOI 10.1089/cmb.1998.5.597; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; Yona G, 2002, J MOL BIOL, V315, P1257, DOI 10.1006/jmbi.2001.5293; Zhou HY, 2005, PROTEINS, V58, P321, DOI 10.1002/prot.20308; Zhou HY, 2004, PROTEINS, V55, P1005, DOI 10.1002/prot.20007	83	80	81	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUN 15	2006	22	12					1456	1463		10.1093/bioinformatics/btl102		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	059YQ	WOS:000238768500009	
J	Montgomerie, S; Sundararaj, S; Gallin, WJ; Wishart, DS				Montgomerie, Scott; Sundararaj, Shan; Gallin, Warren J.; Wishart, David S.			Improving the accuracy of protein secondary structure prediction using structural alignment	BMC BIOINFORMATICS			English	Article							FOLD-RECOGNITION; NEURAL-NETWORKS; SERVER; GENOMICS; SEQUENCE; PROFILES; DATABASE; PHD; EVA	Background: The accuracy of protein secondary structure prediction has steadily improved over the past 30 years. Now many secondary structure prediction methods routinely achieve an accuracy (Q3) of about 75%. We believe this accuracy could be further improved by including structure (as opposed to sequence) database comparisons as part of the prediction process. Indeed, given the large size of the Protein Data Bank (> 35,000 sequences), the probability of a newly identified sequence having a structural homologue is actually quite high. Results: We have developed a method that performs structure-based sequence alignments as part of the secondary structure prediction process. By mapping the structure of a known homologue (sequence ID > 25%) onto the query protein's sequence, it is possible to predict at least a portion of that query protein's secondary structure. By integrating this structural alignment approach with conventional (sequence-based) secondary structure methods and then combining it with a "jury-of-experts" system to generate a consensus result, it is possible to attain very high prediction accuracy. Using a sequence-unique test set of 1644 proteins from EVA, this new method achieves an average Q3 score of 81.3%. Extensive testing indicates this is approximately 4 - 5% better than any other method currently available. Assessments using non sequence-unique test sets (typical of those used in proteome annotation or structural genomics) indicate that this new method can achieve a Q3 score approaching 88%. Conclusion: By using both sequence and structure databases and by exploiting the latest techniques in machine learning it is possible to routinely predict protein secondary structure with an accuracy well above 80%. A program and web server, called PROTEUS, that performs these secondary structure predictions is accessible at http://wishart.biology.ualberta.ca/proteus. For high throughput or batch sequence analyses, the PROTEUS programs, databases (and server) can be downloaded and run locally.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; Univ Alberta, Dept Biol Sci, Edmonton, AB T6G 2E9, Canada	Wishart, DS (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.	montgomerie@shaw.ca; shan@redpoll.pharmacy.ualberta.ca; wgallin@gpu.srv.ualberta.ca; david.wishart@ualberta.ca					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; AMEGBEY GY, IN PRESS J BIOMOL NM; Carter P, 2003, NUCLEIC ACIDS RES, V31, P410, DOI 10.1093/nar/gkg102; CHOU PY, 1974, BIOCHEMISTRY-US, V13, P222, DOI 10.1021/bi00699a002; CLARE A, 2006, IN PRESS BIOINF 0215; Cozzetto D, 2005, FEBS J, V272, P881, DOI 10.1111/j.1742-4658.2005.04549.x; Cuff JA, 2000, PROTEINS, V40, P502, DOI 10.1002/1097-0134(20000815)40:3<502::AID-PROT170>3.0.CO;2-Q; ENGELMAN DM, 1986, ANNU REV BIOPHYS BIO, V15, P321, DOI 10.1146/annurev.biophys.15.1.321; Eyrich VA, 2003, NUCLEIC ACIDS RES, V31, P3308, DOI 10.1093/nar/gkg572; Eyrich VA, 2001, BIOINFORMATICS, V17, P1242, DOI 10.1093/bioinformatics/17.12.1242; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; GARNIER J, 1978, J MOL BIOL, V120, P97, DOI 10.1016/0022-2836(78)90297-8; Gibbs AC, 2002, J AM CHEM SOC, V124, P1203, DOI 10.1021/ja011005e; Ginalski K, 2003, BIOINFORMATICS, V19, P1015, DOI 10.1093/bioinformatics/btg124; Grasselli E, 2003, MOL BIOL REP, V30, P97, DOI 10.1023/A:1023934805326; GUZZO AV, 1965, BIOPHYS J, V5, P809; HEINIG M, 2004, NUCLEIC ACIDS RES, pW500; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; JONES DT, 1992, NATURE, V358, P86, DOI 10.1038/358086a0; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Karplus K, 2001, PROTEINS, P86; Karplus K, 2003, PROTEINS, V53, P491, DOI 10.1002/prot.10540; Kelley LA, 2000, J MOL BIOL, V299, P499; Kernytsky A, 2003, NUCLEIC ACIDS RES, V31, P3642, DOI 10.1093/nar/gkg532; LATTMAN EE, 2003, PROTEINS S6, V53, P33; Lee S, 2004, BIOINFORMATICS, V20, P3500, DOI 10.1093/bioinformatics/bth435; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Lin K, 2005, BIOINFORMATICS, V21, P152, DOI 10.1093/bioinformatics/bth487; Liu JF, 2001, PROTEIN SCI, V10, P1970, DOI 10.1110/ps.10101; McGuffin LJ, 2002, PROTEINS, V48, P44, DOI 10.1002/prot.10129; MEWEW HW, 2006, NUCLEIC ACIDS RES, pD169; Ouali M, 2000, PROTEIN SCI, V9, P1162; PAULING L, 1951, P NATL ACAD SCI USA, V37, P205, DOI 10.1073/pnas.37.4.205; Pieper U, 2002, NUCLEIC ACIDS RES, V30, P255, DOI 10.1093/nar/30.1.255; Pollastri G, 2005, BIOINFORMATICS, V21, P1719, DOI 10.1093/bioinformatics/bti203; ROST B, 1994, COMPUT APPL BIOSCI, V10, P53; Rost B, 1997, J MOL BIOL, V270, P471, DOI 10.1006/jmbi.1997.1101; Rost B, 1996, METHOD ENZYMOL, V266, P525; ROST B, 2004, NUCLEIC ACIDS RES, pW321; Rost B, 2001, J STRUCT BIOL, V134, P204, DOI 10.1006/jsbi.2000.4336; Rost B, 2001, PROTEINS, P192; Schwede T, 2003, NUCLEIC ACIDS RES, V31, P3381, DOI 10.1093/nar/gkg520; STOTHARD P, 2005, NUCLEIC ACIDS RES, pD317; SUTCLIFFE MJ, 1987, PROTEIN ENG, V1, P377, DOI 10.1093/protein/1.5.377; SZAFRON D, 2004, NUCLEIC ACIDS RES, pW365; ULLMAN CG, 1995, FEBS LETT, V371, P199, DOI 10.1016/0014-5793(95)00916-W; Vainshtein I, 1996, PROTEIN SCI, V5, P1785; VANDOMSELAAR GH, 2005, NUCLEIC ACIDS RES, pW455; Wang YJ, 2005, J BIOMOL NMR, V31, P143, DOI 10.1007/s10858-004-7441-3; Westbrook J, 2003, NUCLEIC ACIDS RES, V31, P489, DOI 10.1093/nar/gkg068; Willard L, 2003, NUCLEIC ACIDS RES, V31, P3316, DOI 10.1093/nar/gkg565; Wishart DS, 2001, METHOD ENZYMOL, V338, P3; WISHART DS, 1994, COMPUT APPL BIOSCI, V10, P687; Yee A, 2003, ACCOUNTS CHEM RES, V36, P183, DOI 10.1021/ar010126g; Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K	55	55	62	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JUN 14	2006	7								301	10.1186/1471-2105-7-301		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	074XG	WOS:000239844500001	
J	Rohde, DJ; Gallagher, MR; Drinkwater, MJ; Pimbblet, KA				Rohde, DJ; Gallagher, MR; Drinkwater, MJ; Pimbblet, KA			Matching of catalogues by probabilistic pattern classification	MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY			English	Article						methods : statistical; astronomical data bases : miscellaneous; catalogues	HIPASS CATALOG; INFORMATION; GALAXIES	We consider the statistical problem of catalogue matching from a machine learning perspective with the goal of producing probabilistic outputs, and using all available information. A framework is provided that unifies two existing approaches to producing probabilistic outputs in the literature, one based on combining distribution estimates and the other based on combining probabilistic classifiers. We apply both of these to the problem of matching the HI Parkes All Sky Survey radio catalogue with large positional uncertainties to the much denser SuperCOSMOS catalogue with much smaller positional uncertainties. We demonstrate the utility of probabilistic outputs by a controllable completeness and efficiency trade-off and by identifying objects that have high probability of being rare. Finally, possible biasing effects in the output of these classifiers are also highlighted and discussed.	Univ Queensland, Dept Phys, Brisbane, Qld 4072, Australia; Univ Queensland, Sch ITEE, Brisbane, Qld 4072, Australia	Rohde, DJ (reprint author), Univ Queensland, Dept Phys, Brisbane, Qld 4072, Australia.	djr@physics.uq.edu.au	Drinkwater, Michael/A-2201-2008	Drinkwater, Michael/0000-0003-4867-0022			Bernardo J., 1994, BAYESIAN THEORY; BERNARDO JM, 1979, ANN STAT, V7, P686, DOI 10.1214/aos/1176344689; Bishop C.M., 1995, NEURAL NETWORKS PATT; BRIER GW, 1950, MON WEATHER REV, V1, P1; Budavari T, 2004, ASTR SOC P, V314, P177; CARUANA R, 2005, P 85 AM MET C AMS200; CRISTIANINI N, 2000, SUPPORT VECTOR MACHI, P103; DEGROOT MH, 1983, STATISTICIAN, V32, P12, DOI 10.2307/2987588; Djorgovski SG, 2001, P SOC PHOTO-OPT INS, V4477, P43, DOI 10.1117/12.447189; Doyle MT, 2005, MON NOT R ASTRON SOC, V361, P34, DOI 10.1111/j.1365-2966.2005.09159.x; Duda R., 2000, PATTERN CLASSIFICATI; FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061; Hambly NC, 2001, MON NOT R ASTRON SOC, V326, P1279, DOI 10.1111/j.1365-2966.2001.04660.x; HAND DJ, 1996, CONSTRUCTION ASSESSM; Hastie T, 2001, ELEMENTS STAT LEARNI; Hosmer DW, 2000, APPL LOGISTIC REGRES; Howie D, 2002, INTERPRETING PROBABI; JAYNES ET, 1983, PAPERS PROBABILITY S, P151; Joachims T., 1998, ADV KERNEL METHODS S; LINDLEY DV, 1956, ANN MATH STAT, V27, P986, DOI 10.1214/aoms/1177728069; Mann RG, 1997, MON NOT R ASTRON SOC, V289, P482; McLachlan G, 1997, EM ALGORITHM EXTENSI; Meyer MJ, 2004, MON NOT R ASTRON SOC, V350, P1195, DOI 10.1111/j.1365-2966.2004.07710.x; NABNEY, 2003, NETLAB ALGORITHMS PA; Platt JC, 2000, ADV NEUR IN, P61; Rohde D, 2004, LECT NOTES COMPUT SC, V3177, P702; Rohde DJ, 2005, MON NOT R ASTRON SOC, V360, P69, DOI 10.1111/j.1365-2966.2005.08930.x; Storkey A., 2005, EDIINFRR0318 U ED SC; Suchkov AA, 2004, ASTROPHYS J, V612, P437, DOI 10.1086/422544; SUTHERLAND W, 1992, MON NOT R ASTRON SOC, V259, P413; VAPNIK VN, 1995, NATURE STATISTICAL L; Voisin B, 2001, P SOC PHOTO-OPT INS, V4477, P35, DOI 10.1117/12.447184; Wakamatsu K, 2003, ASTR SOC P, V289, P97	33	7	7	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0035-8711		MON NOT R ASTRON SOC	Mon. Not. Roy. Astron. Soc.	JUN 11	2006	369	1					2	14		10.1111/j.1365-2966.2006.10304.x		13	Astronomy & Astrophysics	Astronomy & Astrophysics	046AI	WOS:000237783400016	
J	Portugaly, E; Harel, A; Linial, N; Linial, M				Portugaly, Elon; Harel, Amir; Linial, Nathan; Linial, Michal			EVEREST: automatic identification and classification of protein domains in all protein sequences	BMC BIOINFORMATICS			English	Article							DATABASE; INFORMATION; ALIGNMENT; FAMILIES; UNIVERSE; SEARCH; SPACE	Background: Proteins are comprised of one or several building blocks, known as domains. Such domains can be classified into families according to their evolutionary origin. Whereas sequencing technologies have advanced immensely in recent years, there are no matching computational methodologies for large-scale determination of protein domains and their boundaries. We provide and rigorously evaluate a novel set of domain families that is automatically generated from sequence data. Our domain family identification process, called EVEREST (EVolutionary Ensembles of REcurrent SegmenTs), begins by constructing a library of protein segments that emerge in an all vs. all pairwise sequence comparison. It then proceeds to cluster these segments into putative domain families. The selection of the best putative families is done using machine learning techniques. A statistical model is then created for each of the chosen families. This procedure is then iterated: the aforementioned statistical models are used to scan all protein sequences, to recreate a library of segments and to cluster them again. Results: Processing the Swiss-Prot section of the UniProt Knoledgebase, release 7.2, EVEREST defines 20,230 domains, covering 85% of the amino acids of the Swiss-Prot database. EVEREST annotates 11,852 proteins (6% of the database) that are not annotated by Pfam A. In addition, in 43,086 proteins (20% of the database), EVEREST annotates a part of the protein that is not annotated by Pfam A. Performance tests show that EVEREST recovers 56% of Pfam A families and 63% of SCOP families with high accuracy, and suggests previously unknown domain families with at least 51% fidelity. EVEREST domains are often a combination of domains as defined by Pfam or SCOP and are frequently sub-domains of such domains. Conclusion: The EVEREST process and its output domain families provide an exhaustive and validated view of the protein domain world that is automatically generated from sequence data. The EVEREST library of domain families, accessible for browsing and download at [1], provides a complementary view to that provided by other existing libraries. Furthermore, since it is automatic, the EVEREST process is scalable and we will run it in the future on larger databases as well. The EVEREST source files are available for download from the EVEREST web site.	Hebrew Univ Jerusalem, Sch Comp Sci & Engn, Jerusalem, Israel; Hebrew Univ Jerusalem, Inst Life Sci, Dept Biol Chem, Jerusalem, Israel	Portugaly, E (reprint author), Hebrew Univ Jerusalem, Sch Comp Sci & Engn, Jerusalem, Israel.	elonp@cs.huji.ac.il; amirhar@alum.cs.huji.ac.il; nati@cs.huji.ac.il; michall@cc.huji.ac.il					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; BARAK A, 2005, P 5 IEEE INT S CLUST, P350; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Chandonia JM, 2002, NUCLEIC ACIDS RES, V30, P260, DOI 10.1093/nar/30.1.260; DEKEL O, 2003, P 16 ANN C COMP LEAR, P433; Eddy S., 2001, HMMER PROFILE HIDDEN; Gracy J, 1998, TRENDS BIOCHEM SCI, V23, P495, DOI 10.1016/S0968-0004(98)01294-8; Gracy J, 1998, BIOINFORMATICS, V14, P164, DOI 10.1093/bioinformatics/14.2.164; Heger A, 2003, J MOL BIOL, V328, P749, DOI 10.1016/S0022-2836(03)00269-9; Hubbard TJP, 1999, NUCLEIC ACIDS RES, V27, P254, DOI 10.1093/nar/27.1.254; Inbar Y, 2003, BIOINFORMATICS, V19, pi158, DOI 10.1093/bioinformatics/btg1020; Kaplan N, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-196; LIU J, 2004, NUCLEIC ACIDS RES, V32, P569; Liu JF, 2003, CURR OPIN CHEM BIOL, V7, P5, DOI 10.1016/S1367-5931(02)00003-0; Mulder Nicola J, 2002, Brief Bioinform, V3, P225; Nagarajan N, 2004, BIOINFORMATICS, V20, P1335, DOI 10.1093/bioinformatics/bth086; Park J, 1998, J MOL BIOL, V284, P1201, DOI 10.1006/jmbi.1998.2221; PORTUGALY E, 2006, EVEREST; PORTUGALY E, 2004, CURRENTS COMPUTATION, P250; Sasson Ori, 2002, Bioinformatics, V18 Suppl 1, pS14; Sasson O, 2003, NUCLEIC ACIDS RES, V31, P348, DOI 10.1093/nar/gkg096; Schultz J, 2000, NUCLEIC ACIDS RES, V28, P231, DOI 10.1093/nar/28.1.231; Servant Florence, 2002, Brief Bioinform, V3, P246, DOI 10.1093/bib/3.3.246; SHACHAR O, 2004, PROTEIN-STRUCT FUNCT, V57, P532; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Wu CH, 2006, NUCLEIC ACIDS RES, V34, pD187, DOI 10.1093/nar/gkj161	30	14	16	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JUN 2	2006	7								277	10.1186/1471-2105-7-277		19	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	070JI	WOS:000239517500001	
J	Bhardwaj, N; Stahelin, RV; Langlois, RE; Cho, WW; Lu, H				Bhardwaj, N; Stahelin, RV; Langlois, RE; Cho, WW; Lu, H			Structural bioinformatics prediction of membrane-binding proteins	JOURNAL OF MOLECULAR BIOLOGY			English	Article						protein-membrane interactions; function annotation; support vector machines; peripheral proteins; protein function prediction	PLECKSTRIN HOMOLOGY DOMAINS; SUPPORT VECTOR MACHINES; KINASE C-EPSILON; PLASMA-MEMBRANE; DELTA; LOCALIZATION; ORGANIZATION; RECOGNITION; ACTIVATION; NETWORKS	Membrane-binding peripheral proteins play important roles in many biological processes, including cell signaling and membrane trafficking. Unlike integral membrane proteins, these proteins bind the membrane mostly in a reversible manner. Since peripheral proteins do not have canonical transmembrane segments, it is difficult to identify them from their amino acid sequences. As a first step toward genome-scale identification of membrane-binding peripheral proteins, we built a kernel-based machine learning protocol. Key features of known membrane-binding proteins, including electrostatic properties and amino acid composition, were calculated from their amino acid sequences and tertiary structures, which were then incorporated into the support vector machine to perform the classification. A data set of 40 membrane-binding proteins and 230 non-membrane-binding proteins was used to construct and validate the protocol. Cross-validation and holdout evaluation of the protocol showed that the accuracy of the prediction reached up to 93.7% and 91.6%, respectively. The protocol was applied to the prediction of membrane-binding properties of four C2 domains from novel protein kinases C. Although these C2 domains have 50% sequence identity only one of them was predicted to bind the membrane, which was verified experimentally with surface plasmon resonance analysis. These results suggest that our protocol can be used for predicting membrane-binding properties of a wide variety of modular domains and may be further extended to genome-scale identification of membrane-binding peripheral proteins. (c) 2006 Elsevier Ltd. All rights reserved.	Univ Illinois, Dept Bioengn, Chicago, IL 60607 USA; Univ Illinois, Dept Chem, Chicago, IL 60607 USA	Cho, WW (reprint author), Univ Illinois, Dept Bioengn, Chicago, IL 60607 USA.	wcho@uic.edu; huilu@uic.edu					Bhardwaj N, 2005, NUCLEIC ACIDS RES, V33, P6486, DOI 10.1093/nar/gki949; BHARDWAJ N, 2005, P 27 ANN INT C ENG M; Blatner NR, 2004, J BIOL CHEM, V279, P53818, DOI 10.1074/jbc.M408408200; Bordner AJ, 2005, PROTEINS, V60, P353, DOI 10.1002/prot.20433; Bretscher A, 2002, NAT REV MOL CELL BIO, V3, P586, DOI 10.1038/nrm882; BROOKS BR, 1983, J COMPUT CHEM, V4, P187, DOI 10.1002/jcc.540040211; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Carroll K, 2004, NAT REV MOL CELL BIO, V5, P55, DOI 10.1038/nrm1278; Chandonia JM, 2004, NUCLEIC ACIDS RES, V32, P189; Cho W, 2001, J BIOL CHEM, V276, P32407, DOI 10.1074/jbc.R100007200; Cho WH, 2005, ANNU REV BIOPH BIOM, V34, P119, DOI 10.1146/annurev.biophys.33.110502.133337; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; De Camilli P, 2002, FEBS LETT, V513, P11, DOI 10.1016/S0014-5793(01)03306-3; DENITTO JP, 2003, SCI STKE; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Ferguson KM, 2000, MOL CELL, V6, P373, DOI 10.1016/S1097-2765(00)00037-X; GILSON MK, 1988, PROTEINS, V3, P32, DOI 10.1002/prot.340030104; Habermann B, 2004, EMBO REP, V5, P250, DOI 10.1038/sj.embor.7400105; Humphrey W., 1996, J MOL GRAPHICS, V14, P27, DOI DOI 10.1016/0263-7855(96)00018-5; Hurley JH, 2001, CURR OPIN CELL BIOL, V13, P146, DOI 10.1016/S0955-0674(00)00191-5; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kohout SC, 2003, BIOCHEMISTRY-US, V42, P1254, DOI 10.1021/bi026596f; Koppensteiner WA, 2000, J MOL BIOL, V296, P1139, DOI 10.1006/jmbi.1999.3501; Langlois Robert E, 2005, Int J Bioinform Res Appl, V1, P319, DOI 10.1504/IJBRA.2005.007909; Lemmon MA, 2000, BIOCHEM J, V350, P1, DOI 10.1042/0264-6021:3500001; Lemmon MA, 2002, FEBS LETT, V513, P71, DOI 10.1016/S0014-5793(01)03243-4; Magee T, 2005, CURR OPIN CELL BIOL, V17, P190, DOI 10.1016/j.ceb.2005.02.003; Malmberg NJ, 2003, BIOCHEMISTRY-US, V42, P13227, DOI 10.1021/bi035119; MCLAUGHLIN S, 1995, TRENDS BIOCHEM SCI, V20, P272, DOI 10.1016/S0968-0004(00)89042-8; McLaughlin S, 2002, ANNU REV BIOPH BIOM, V31, P151, DOI 10.1146/annurev.biophys.31.082901.134259; McLaughlin S, 2005, NATURE, V438, P605, DOI 10.1038/nature04398; Miller JP, 2005, P NATL ACAD SCI USA, V102, P12123, DOI 10.1073/pnas.0505482102; Nalefski EA, 1996, PROTEIN SCI, V5, P2375; Ochoa WF, 2001, J MOL BIOL, V311, P837, DOI 10.1006/jmbi.2001.4910; Okeley NM, 2004, J BIOL CHEM, V279, P21833, DOI 10.1074/jbc.M313469200; Pappa H, 1998, STRUCT FOLD DES, V6, P885, DOI 10.1016/S0969-2126(98)00090-2; Richardson J S, 1981, Adv Protein Chem, V34, P167, DOI 10.1016/S0065-3233(08)60520-3; Rizo J, 1998, J BIOL CHEM, V273, P15879, DOI 10.1074/jbc.273.26.15879; SALI A, 1995, PROTEINS, V23, P318, DOI 10.1002/prot.340230306; Singh SM, 2003, PROTEIN SCI, V12, P1934, DOI 10.1110/ps.0358803; Stahelin RV, 2005, J BIOL CHEM, V280, P19784, DOI 10.1074/jbc.M411285200; Stahelin RV, 2003, J BIOL CHEM, V278, P28993, DOI 10.1074/jbc.M302865200; Stahelin RV, 2004, J BIOL CHEM, V279, P29501, DOI 10.1074/jbc.M403191200; Stahelin RV, 2001, BIOCHEMISTRY-US, V40, P4672, DOI 10.1021/bi0020325; Stawiski EW, 2003, J MOL BIOL, V326, P1065, DOI 10.1016/S0022-2836(03)00031-7; Stenmark H, 2002, FEBS LETT, V513, P77, DOI 10.1016/S0014-5793(01)03308-7; Teruel MN, 2000, CELL, V103, P181, DOI 10.1016/S0092-8674(00)00109-4; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Xu Y, 2001, BIOCHEM J, V360, P513, DOI 10.1042/0264-6021:3600513; Yang CF, 2003, TRENDS PHARMACOL SCI, V24, P602, DOI 10.1016/j.tips.2003.09.003	50	29	29	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-2836		J MOL BIOL	J. Mol. Biol.	JUN 2	2006	359	2					486	495		10.1016/j.jmb.2006.03.039		10	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	047WF	WOS:000237908700021	
J	Sun, XD; Huang, RB				Sun, XD; Huang, RB			Prediction of protein structural classes using support vector machines	AMINO ACIDS			English	Article						support vector machines; CATH; multi-class; protein structural class prediction; jackknifing	AMINO-ACID-COMPOSITION; SUBCELLULAR LOCATION PREDICTION; FUNCTIONAL DOMAIN COMPOSITION; SECONDARY STRUCTURE; NEURAL-NETWORKS; MOLECULAR BIOLOGIST; FOLDING TYPES; CLASSIFICATION	The support vector machine, a machine-learning method, is used to predict the four structural classes, i.e. mainly alpha, mainly beta, alpha-beta and fss, from the topology-level of CATH protein structure database. For the binary classification, any two structural classes which do not share any secondary structure such as alpha and beta elements could be classified with as high as 90% accuracy. The accuracy, however, will decrease to less than 70% if the structural classes to be classified contain structure elements in common. Our study also shows that the dimensions of feature space 20(2) = 400 (for dipeptide) and 20(3) = 8 000 (for tripeptide) give nearly the same prediction accuracy. Among these 4 structural classes, multi-class classification gives an overall accuracy of about 52%, indicating that the multi-class classification technique in support of vector machines may still need to be further improved in future investigation.	Guangxi Univ, Coll Life Sci & Biotechnol, Nanning 530004, Guangxi, Peoples R China	Huang, RB (reprint author), Guangxi Univ, Coll Life Sci & Biotechnol, 100 Univ Rd, Nanning 530004, Guangxi, Peoples R China.	priboh@gxu.edu.cn					Aloy P, 2004, NAT BIOTECHNOL, V22, P1317, DOI 10.1038/nbt1019; ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; ANGUITA D, 2004, P 2004 IEEE INT JOIN, P412; Berman HM, 2002, ACTA CRYSTALLOGR D, V58, P899, DOI 10.1107/S0907444902003451; Branden C., 1999, INTRO PROTEIN STRUCT; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cai YD, 2003, J THEOR BIOL, V221, P115, DOI 10.1006/jtbi.2003.3179; Cai YD, 2002, PEPTIDES, V23, P205, DOI 10.1016/S0196-9781(01)00597-6; Cai YD, 2003, PEPTIDES, V24, P665, DOI 10.1016/S0196-9781(03)00133-5; Cai Yu-Dong, 2000, Molecular Cell Biology Research Communications, V4, P230, DOI 10.1006/mcbr.2001.0285; Cai YD, 2002, COMPUT CHEM, V26, P293, DOI 10.1016/S0097-8485(01)00113-9; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chargaff E., 1979, ANN NY ACAD SCI, V325, P345, DOI 10.1111/j.1749-6632.1979.tb14144.x; CHARGAFF E, 1951, FED PROC, V10, P654; CHOTHIA C, 1992, NATURE, V357, P543, DOI 10.1038/357543a0; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 1998, BIOCHEM BIOPH RES CO, V252, P63, DOI 10.1006/bbrc.1998.9498; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 1998, PROTEINS, V31, P97, DOI 10.1002/(SICI)1097-0134(19980401)31:1<97::AID-PROT8>3.0.CO;2-E; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU PY, 1980, 2 CHEM C N AM CONT L; Creighton TE, 1993, PROTEINS STRUCTURES; Cristianini N., 2000, INTRO SUPPORT VECTOR; DING CHQ, 2001, BIOINFORMATICS, V17, P345; Du QS, 2003, PEPTIDES, V24, P1863, DOI 10.1016/j.peptides.2003.10.012; DUBCHAK I, 1993, PROTEINS, V16, P79, DOI 10.1002/prot.340160109; Fasman G.D., 1989, PREDICTION PROTEIN S, P549; HUA S, 2001, J MOL BIOL, V302, P397; HUBBARD TJ, 1995, PROTEINS, V23, P398, DOI 10.1002/prot.340230313; Isik Z, 2004, LECT NOTES COMPUT SC, V3280, P82; Kecman V., 2001, LEARNING SOFT COMPUT; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Leslie C., 2002, P PAC S BIOC, V7, P566; LEVITT M, 1976, NATURE, V261, P552, DOI 10.1038/261552a0; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Markowetz F, 2003, BIOMETRICAL J, V45, P377, DOI 10.1002/bimj.200390019; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Nakashima H, 1986, J BIOCHEM-TOKYO, V99, P152; Nguyen Minh N, 2003, Genome Inform, V14, P218; Orengo CA, 1997, STRUCTURE, V5, P1093, DOI 10.1016/S0969-2126(97)00260-8; Platt J.C., 1999, ADV KERNEL METHODS S; RECHARDSON JS, 1989, PREDICTION PROTEIN S, P1; ROST B, 1994, PROTEINS, V19, P55, DOI 10.1002/prot.340190108; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; Saxonov S, 2003, GENETICA, V118, P267, DOI 10.1023/A:1024142701533; Scholkopf B., 2002, LEARNING KERNELS; SELA M, 1957, SCIENCE, V125, P691, DOI 10.1126/science.125.3250.691; SUEOKA N, 1961, COLD SPRING HARB SYM, V26, P35; TAYLOR WR, 1989, J MOL BIOL, V208, P1, DOI 10.1016/0022-2836(89)90084-3; THORSTEN J, 2002, LEARNING CLASSIFY TE; Vapnik V.N., 1995, STAT LEARNING THEORY; Yang ZR, 2004, BRIEF BIOINFORM, V5, P328, DOI 10.1093/bib/5.4.328; Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477; ZHANG CT, 1992, PROTEIN SCI, V1, P401; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	65	80	81	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0939-4451		AMINO ACIDS	Amino Acids	JUN	2006	30	4					469	475		10.1007/s00726-005-0239-0		7	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	053FZ	WOS:000238292300015	
J	Zmazek, B; Todorovski, L; Zivcic, M; Dzeroski, S; Vaupotic, J; Kobal, I				Zmazek, B; Todorovski, L; Zivcic, M; Dzeroski, S; Vaupotic, J; Kobal, I			Radon in a thermal spring: Identification of anomalies related to seismic activity	APPLIED RADIATION AND ISOTOPES			English	Article						radon in thermal water; anomalies; environmental parameters; earthquakes; correlation; regression trees; forecasting	EARTHQUAKE PREDICTION; PRECURSORY SIGNALS; SLOVENIA; RADIOACTIVITY; WATERS; YUGOSLAVIA; EMANATION; EXPOSURE; EVENTS; FAULT	Anomalies have been observed in the radon content of thermal spring water at the Italian-Slovenian border. To distinguish the anomalies caused by environmental parameters (air and water temperature, barometric and hydrostatic pressure, rainfall) from those ascribed solely to earthquakes with ML from 1.2 to 2.5 and epicentres, R-E, within 2R(D) (R-D-Dobrovolsky's radius), two approaches have been used: (i) correlation between time gradients of radon concentration and hydrostatic pressure, and (ii) regression trees within machine learning programs. The regression trees approach has been improved by introducing additional environmental parameters and prolonging the measuring period. (c) 2006 Elsevier Ltd. All rights reserved.	Jozef Stefan Inst, Ljubljana 1000, Slovenia; Off Seismol, Ljubljana 1000, Slovenia	Zmazek, B (reprint author), Jozef Stefan Inst, Ljubljana 1000, Slovenia.	boris.zmazek@ijs.si					BELYAEV AA, 2001, GEOCHEM INT, V12, P1245; Biagi PF, 2001, J SEISMOL, V5, P487, DOI 10.1023/A:1012015317086; Breiman L, 1984, CLASSIFICATION REGRE; Cuomo V, 2000, NAT HAZARDS, V21, P247, DOI 10.1023/A:1008157730467; DIBELLO G, 1998, NUOVO CIMENTO, V6, P609; DOBROVOLSKY IP, 1979, PURE APPL GEOPHYS, V117, P1025, DOI 10.1007/BF00876083; DZEROSKI S, 2003, P 6 INT C SAPP JAP O, P87; DZEROSKI S, 2002, HDB DATA MINING KNOW; DZEROSKIS, 2003, WORKSH MIN SCI ENG D, P19; Etiope G, 2002, PHYS EARTH PLANET IN, V129, P185, DOI 10.1016/S0031-9201(01)00292-8; FEDELI G, 2001, P 5 INT C RAR GAS GE, P55; HEINECKE J, 1997, RARE GAS GEOCHEMISTR, P136; HEINICKE J, 1995, GAS GEOCHEMISTRY SCI, P295; Italiano F, 2001, TERRA NOVA, V13, P249, DOI 10.1046/j.1365-3121.2001.00346.x; KING CY, 1978, NATURE, V271, P516, DOI 10.1038/271516a0; KOBAL I, 1990, ENVIRON INT, V16, P141, DOI 10.1016/0160-4120(90)90154-X; KOBAL I, 1979, HEALTH PHYS, V37, P239; KOBAL I, 1978, J RADIOANAL CHEM, V44, P307, DOI 10.1007/BF02519623; KOBAL I, 1987, RADIAT PROT DOSIM, V20, P257; KOBAL I, 1987, HEALTH PHYS, V53, P307; KRISTIANSSON K, 1982, GEOPHYSICS, V47, P1444, DOI 10.1190/1.1441293; MJACHKIN VI, 1975, PURE APPL GEOPHYS, V113, P169, DOI 10.1007/BF01592908; Negarestani A., 2001, J ENVIRON RADIOACTIV, V62, P225, DOI 1016/S0265-931X(01)00165-5; Ohno M, 1996, J PHYS EARTH, V44, P391; PLANINIC J, 2004, J ENVIRON RADIOACTIV, V75, P25; PLANINIC J, 2003, P 5 S CROAT RAD PROT, P349; Planinic J., 2000, Fizika B, V9; Popit A., 2002, RMZ MAT GEOENVIRONME, V49, P487; Pulinets SA, 1997, ADV SPACE RES, V20, P2173, DOI 10.1016/S0273-1177(97)00666-2; SCHOLZ CH, 1973, SCIENCE, V181, P803, DOI 10.1126/science.181.4102.803; Singh M, 1999, RADIAT MEAS, V30, P465, DOI 10.1016/S1350-4487(99)00049-9; Steinitz G, 2003, GEOLOGY, V31, P505, DOI 10.1130/0091-7613(2003)031<0505:SSRBRF>2.0.CO;2; TENG TL, 1980, J GEOPHYS RES, V85, P3089, DOI 10.1029/JB085iB06p03089; Toutain JP, 1999, TECTONOPHYSICS, V304, P1, DOI 10.1016/S0040-1951(98)00295-9; UI H, 1988, TECTONOPHYSICS, V152, P147, DOI 10.1016/0040-1951(88)90034-0; Ulomov V. I, 1971, IZV AKAD NAUK UZB SS, P188; Vaupotic J, 2001, RADIAT PROT DOSIM, V97, P265; Vaupotic J, 2002, HEALTH PHYS, V83, P901, DOI 10.1097/00004032-200212000-00018; VIRK HS, 1995, GAS GEOCHEMISTRY, P221; Virk HS, 2001, RADIAT MEAS, V34, P379, DOI 10.1016/S1350-4487(01)00190-1; VIRK HS, 1997, RARE GAS GEOCHEMISTR, P117; Witten I. H., 1999, DATA MINING PRACTICA; Yasuoka Y, 1997, HEALTH PHYS, V72, P759, DOI 10.1097/00004032-199705000-00012; ZMAZEK B, 2004, ACTA GEOTECH, V1, P12; Zmazek B, 2002, APPL RADIAT ISOTOPES, V57, P919, DOI 10.1016/S0969-8043(02)00200-2; ZMAZEK B, 2000, 2 DRESD S RAD PROT N, P10; Zmazek B., 2000, Fizika B, V9; ZMAZEK B, 2002, P 1 WORKSH NAT RAD H; ZMAZEK B, 2000, 2 DRESD S RAD PROT N; Zmazek B, 2003, APPL RADIAT ISOTOPES, V58, P697, DOI 10.1016/S0969-8043(03)00094-0; Zmazek B, 2002, APPL RADIAT ISOTOPES, V56, P649, DOI 10.1016/S0969-8043(01)00255-X	51	2	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0969-8043		APPL RADIAT ISOTOPES	Appl. Radiat. Isot.	JUN	2006	64	6					725	734		10.1016/j.apradiso.2005.12.016		10	Chemistry, Inorganic & Nuclear; Nuclear Science & Technology; Radiology, Nuclear Medicine & Medical Imaging	Chemistry; Nuclear Science & Technology; Radiology, Nuclear Medicine & Medical Imaging	038CQ	WOS:000237196400014	
J	Krstacic, G; Krstacic, A; Gamberger, D; Jembrek-Gostovic, M				Krstacic, G.; Krstacic, A.; Gamberger, D.; Jembrek-Gostovic, M.			Risk factors analysis by inductive machine learning in coronary heart disease patients	ATHEROSCLEROSIS SUPPLEMENTS			English	Meeting Abstract	14th Meeting of the International-Society-of-Atherosclerosis	JUN 18-22, 2006	Rome, ITALY	Int Soc Atheroscleros					Inst Cardiovasc Dis & Rehabil, Zagreb, Croatia; Univ Hosp Traumatol, Zagreb, Croatia; Rudjer Boskovic Inst, Zagreb, Croatia			Gamberger, Dragan/J-3752-2012					0	0	0	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1567-5688		ATHEROSCLEROSIS SUPP	Atheroscler. Suppl.	JUN	2006	7	3					47	47		10.1016/S1567-5688(06)80143-1		1	Peripheral Vascular Disease	Cardiovascular System & Cardiology	064MN	WOS:000239093900144	
J	Ong, CJ; Sui, D; Gilbert, EG				Ong, C. J.; Sui, D.; Gilbert, E. G.			Enlarging the terminal region of nonlinear model predictive control using the support vector machine method	AUTOMATICA			English	Article						nonlinear model predictive control; support vector machine; constraints; stability; terminal conditions	RECEDING HORIZON CONTROL; SYSTEMS; STABILITY; ALGORITHM	In this paper, receding horizon model predictive control (RHMPC) of nonlinear systems subject to input and state constraints is considered. We propose to estimate the terminal region and the terminal cost off-line using support vector machine learning. The proposed approach exploits the freedom in the choices of the terminal region and terminal cost needed for asymptotic stability. The resulting terminal regions are large and, hence provide for large domains of attraction of the RHMPC. The promise of the method is demonstrated with two examples. (c) 2006 Elsevier Ltd. All rights reserved.	Natl Univ Singapore, Singapore MIT Alliance, Dept Mech Engn, Singapore 117548, Singapore; Univ Michigan, Dept Aerosp Engn, Ann Arbor, MI 48109 USA	Ong, CJ (reprint author), Natl Univ Singapore, Singapore MIT Alliance, Dept Mech Engn, Singapore 117548, Singapore.	mpeongcj@nus.edu.sg					Allgower F, 2000, NONLINEAR MODEL PRED; CANNON M, 2003, AM CONTR C, P4287; Chen H, 1998, AUTOMATICA, V34, P1205, DOI 10.1016/S0005-1098(98)00073-9; CHEN WH, 2001, AM CONTR C, P3067; Fletcher R., 1987, PRACTICAL METHODS OP; Magni L, 2001, AUTOMATICA, V37, P1351, DOI 10.1016/S0005-1098(01)00083-8; MAYNE DQ, 1990, IEEE T AUTOMAT CONTR, V35, P814, DOI 10.1109/9.57020; Mayne DQ, 2000, AUTOMATICA, V36, P789, DOI 10.1016/S0005-1098(99)00214-9; MICHALSKA H, 1993, IEEE T AUTOMAT CONTR, V38, P1623, DOI 10.1109/9.262032; Ong CJ, 2004, AUTOMATICA, V40, P1955, DOI 10.1016/j.automatica.2004.06.005; PARISINI T, 1995, AUTOMATICA, V31, P1443, DOI 10.1016/0005-1098(95)00044-W; Praprost KL, 1996, IEEE T AUTOMAT CONTR, V41, P1605, DOI 10.1109/9.543998; Scholkopf B., 2002, LEARNING KERNELS SUP; Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050; Vapnik V. N, 1995, NATURE STAT LEARNING	15	9	14	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0005-1098		AUTOMATICA	Automatica	JUN	2006	42	6					1011	1016		10.1016/j.automatica.2006.02.023		6	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	047VA	WOS:000237905600015	
J	Yousef, M; Nebozhyn, M; Shatkay, H; Kanterakis, S; Showe, LC; Showe, MK				Yousef, M; Nebozhyn, M; Shatkay, H; Kanterakis, S; Showe, LC; Showe, MK			Combining multi-species genomic data for microRNA identification using a Naive Bayes classifier	BIOINFORMATICS			English	Article							CAENORHABDITIS-ELEGANS/; REGULATORY MOTIFS; SEQUENCE; GENES; PREDICTION; RNAS; ALIGNMENT	Motivation: Most computational methodologies for microRNA gene prediction utilize techniques based on sequence conservation and/or structural similarity. In this study we describe a new technique, which is applicable across several species, for predicting miRNA genes. This technique is based on machine learning, using the Naive Bayes classifier. It automatically generates a model from the training data, which consists of sequence and structure information of known miRNAs from a variety of species. Results: Our study shows that the application of machine learning techniques, along with the integration of data from multiple species is a useful and general approach for miRNA gene prediction. Based on our experiments, we believe that this new technique is applicable to an extensive range of eukaryotes' genomes. Specific structure and sequence features are first used to identify miRNAs followed by a comparative analysis to decrease the number of false positives (FPs). The resulting algorithm exhibits higher specificity and similar sensitivity compared to currently used algorithms that rely on conserved genomic regions to decrease the rate of FPs.	Wistar Inst Anat & Biol, Philadelphia, PA 19104 USA; Queens Univ, Sch Comp, Kingston, ON, Canada	Showe, MK (reprint author), Wistar Inst Anat & Biol, Philadelphia, PA 19104 USA.	showe@wistar.org					Ambros V, 2003, RNA, V9, P277, DOI 10.1261/rna.2183803; Bartel DP, 2004, CELL, V116, P281, DOI 10.1016/S0092-8674(04)00045-5; Grad Y, 2003, MOL CELL, V11, P1253, DOI 10.1016/S1097-2765(03)00153-9; Griffen TD, 2004, J INDO-EUR STUD, V32, P11; Griffiths-Jones S, 2006, NUCLEIC ACIDS RES, V34, pD140, DOI 10.1093/nar/gkj112; Japkowicz N., 2002, Intelligent Data Analysis, V6; Kent WJ, 2002, GENOME RES, V12, P656, DOI [10.1101/gr.229202, 10.1101/gr.229202. Article published online before March 2002]; Kent WJ, 2002, GENOME RES, V12, P996, DOI 10.1101/gr.229102; Lagos-Quintana M, 2001, SCIENCE, V294, P853, DOI 10.1126/science.1064921; Lai EC, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r42; Lau NC, 2001, SCIENCE, V294, P858, DOI 10.1126/science.1065062; Lee RC, 2001, SCIENCE, V294, P862, DOI 10.1126/science.1065329; Lim LP, 2003, GENE DEV, V17, P991, DOI 10.1101/gad.1074403; Lim LP, 2003, SCIENCE, V299, P1540, DOI 10.1126/science.1080372; Mathews DH, 1999, J MOL BIOL, V288, P911, DOI 10.1006/jmbi.1999.2700; McCallum A, 1996, BOW TOOLKIT STAT LAN; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Mignone F, 2005, NUCLEIC ACIDS RES, V33, pD141; MITCHELL T, 1997, MACHINE LEARNING, pCH10; Nam JW, 2005, NUCLEIC ACIDS RES, V33, P3570, DOI 10.1093/nar/gki668; Pasquinelli AE, 2000, NATURE, V408, P86, DOI 10.1038/35040556; SAHAMI M, 1996, P 13 INT C MACH LEAR, P284; Wang XW, 2005, BIOINFORMATICS, V21, P3610, DOI 10.1093/bioinformatics/bti562; Weber MJ, 2005, FEBS J, V272, P59, DOI 10.1111/j.1432-1033.2004.04389.x; Xie XH, 2005, NATURE, V434, P338, DOI 10.1038/nature03441; Zuker M, 2003, NUCLEIC ACIDS RES, V31, P3406, DOI 10.1093/nar/gkg595	26	73	82	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUN 1	2006	22	11					1325	1334		10.1093/bioinformatics/bt/094		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	054DJ	WOS:000238356700007	
J	Tan, KC; Yu, Q; Ang, JH				Tan, K. C.; Yu, Q.; Ang, J. H.			A dual-objective evolutionary algorithm for rules extraction in data mining	COMPUTATIONAL OPTIMIZATION AND APPLICATIONS			English	Article						data mining; evolutionary algorithm; classification; rules extraction	NEURAL-NETWORKS; PATTERN-CLASSIFICATION; KNOWLEDGE DISCOVERY; GENETIC ALGORITHMS; DIAGNOSIS	This paper presents a dual-objective evolutionary algorithm (DOEA) for extracting multiple decision rule lists in data mining, which aims at satisfying the classification criteria of high accuracy and ease of user comprehension. Unlike existing approaches, the algorithm incorporates the concept of Pareto dominance to evolve a set of non-dominated decision rule lists each having different classification accuracy and number of rules over a specified range. The classification results of DOEA are analyzed and compared with existing rule-based and non-rule based classifiers based upon 8 test problems obtained from UCI Machine Learning Repository. It is shown that the DOEA produces comprehensible rules with competitive classification accuracy as compared to many methods in literature. Results obtained from box plots and t-tests further examine its invariance to random partition of datasets.	Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Tan, KC (reprint author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.	eletankc@nus.edu.sg					Arbatli AD, 1997, NONLINEAR ANAL-THEOR, V30, P1639; Banzhaf W., 1998, GENETIC PROGRAMMING; Blake CL, UCI REPOSITORY MACHI; Bojarczuk CC, 2000, IEEE ENG MED BIOL, V19, P38, DOI 10.1109/51.853480; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; Cattral R., 1999, P C EV COMP CEC99, V1, P125; Chambers J, 1983, GRAPHICAL METHODS DA; Coello Coello C.A., 2002, EVOLUTIONARY ALGORIT; CONGDON CB, 2000, P IEEE C EV COMP, V1, P442, DOI 10.1109/CEC.2000.870330; Duda R. O., 2001, PATTERN CLASSIFICATI; Fayyad U., 1997, Proceedings. Ninth International Conference on Scientific and Statistical Database Management (Cat. No.97TB100150), DOI 10.1109/SSDM.1997.621141; FIDELIS MV, 2000, P 2000 C EV COMP, V1, P805, DOI 10.1109/CEC.2000.870381; Frank E., 1998, P 15 INT C MACH LEAR, P144; HOWARD LM, 1995, IEEE EXPERT, V10, P11, DOI 10.1109/64.393137; Ishibuchi H, 2001, INFORM SCIENCES, V136, P109, DOI 10.1016/S0020-0255(01)00144-X; Ishibuchi H, 1997, FUZZY SET SYST, V89, P135, DOI 10.1016/S0165-0114(96)00098-X; John G. H., 1995, P 11 C UNC ART INT, P338; Kim Y., 2002, INTELL DATA ANAL, V6, P531; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; Kohavi R., 1995, P 8 EUR C MACH LEARN, P174; Wong ML, 2000, GENET PROGR SER, V3, P1; Mendes R. R. F., 2001, LECT NOTES ARTIF INT, V2168, P314; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Mitchell T, 1997, MACHINE LEARNING; Montgomery D.C., 2001, ENG STAT; Pena-Reyes CA, 1999, ARTIF INTELL MED, V17, P131, DOI 10.1016/S0933-3657(99)00019-6; POLO AR, 2000, P 20 INT C CHIL COMP, P14; Prechelt L, 1995, NEUROCOMPUTING, V9, P343, DOI 10.1016/0925-2312(95)00084-1; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Setiono R, 1997, NEUROCOMPUTING, V17, P1, DOI 10.1016/S0925-2312(97)00038-6; Tan KC, 2002, P C EV COMP CEC 02, V2, P1302, DOI 10.1109/CEC.2002.1004431; Tan KC, 2005, IEEE T SYST MAN CY C, V35, P131, DOI 10.1109/TSMCC.2004.841911; Taylor C., 1994, MACHINE LEARNING NEU; Van Veldhuizen DA, 2000, EVOL COMPUT, V8, P125; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang CH, 1998, IEEE T SYST MAN CY C, V28, P471; Wang LL, 2000, MOL THER, V1, P154, DOI 10.1006/mthe.2000.0031; Witten I. H., 1999, DATA MINING PRACTICA; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107	39	16	16	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0926-6003		COMPUT OPTIM APPL	Comput. Optim. Appl.	JUN	2006	34	2					273	294		10.1007/s10589-005-3907-9		22	Operations Research & Management Science; Mathematics, Applied	Operations Research & Management Science; Mathematics	052YD	WOS:000238269100006	
J	Peng, YH				Peng, YH			A novel ensemble machine learning for robust microarray data classification	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						microarray data; machine learning; ensemble learning; classification	GENE-EXPRESSION DATA; CLUSTER-ANALYSIS; CANCER; PREDICTION; SELECTION; PATTERNS; TUMOR; ARRAYS	Microarray data analysis and classification has demonstrated convincingly that it provides an effective methodology for the effective diagnosis of diseases and cancers. Although much research has been performed on applying machine learning techniques for microarray data classification during the past years, it has been shown that conventional machine learning techniques have intrinsic drawbacks in achieving accurate and robust classifications. This paper presents a novel ensemble machine learning approach for the development of robust microarray data classification. Different from the conventional ensemble learning techniques, the approach presented begins with generating a pool of candidate base classifiers based on the gene sub-sampling and then the selection of a sub-set of appropriate base classifiers to construct the classification committee based on classifier clustering. Experimental results have demonstrated that the classifiers constructed by the proposed method outperforms not only the classifiers generated by the conventional machine learning but also the classifiers generated by two widely used conventional ensemble learning methods (bagging and boosting). (c) 2005 Elsevier Ltd. All rights reserved.	Univ Bradford, Dept Comp, Bradford BD7 1DP, W Yorkshire, England	Peng, YH (reprint author), Univ Bradford, Dept Comp, Bradford BD7 1DP, W Yorkshire, England.	y.h.peng@bradford.ac.uk	Peng, Yonghong/A-5778-2013	Peng, Yonghong/0000-0002-8806-2075			Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BERRAR D, 2003, P CAMDA2003; Blanco R, 2004, INT J PATTERN RECOGN, V18, P1373, DOI 10.1142/S0218001404003800; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CAO J, 1995, PATTERN RECOGN, V28, P153, DOI 10.1016/0031-3203(94)00094-3; CHO SB, 2003, CAMDA 2003 C; Cho S.-B., 2003, P 1 AS PAC BIOINF C; Coombes KR, 2002, J COMPUT BIOL, V9, P655, DOI 10.1089/106652702760277372; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HO TK, 1998, P 14 INT C PATT REC, P545; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; LI W, 2000, CAMDA 2000 C; MUKHERJEE S, 1999, 182 CBCL; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tan A.C., 2003, APPL BIOINFORMATIC S, V2, P75; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang XJ, 2003, BIOINFORMATICS, V19, P1341, DOI 10.1093/bioinformatics/btg154; Xing E., 2001, P 18 INT C MACH LEAR, P601; Yu L., 2004, P 10 ACM SIGKDD INT, P737, DOI 10.1145/1014052.1014149	37	31	36	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825		COMPUT BIOL MED	Comput. Biol. Med.	JUN	2006	36	6					553	573		10.1016/j.compbiomed.2005.04.001		21	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	047LY	WOS:000237882000001	
J	Joung, JG; O, SJ; Zhang, BT				Joung, JG; O, SJ; Zhang, BT			Protein sequence-based risk classification for human papillomaviruses	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						human papillomavirus; machine learning; kernel methods; hidden Markov models; sequence classification	CERVICAL-CANCER; EXPRESSION DATA; SUPPORT; SITES; E6	Human papillmaviruses (HPVs) are small DNA tumor viruses which infect epithelial tissues and induce hyperproliferative lesions. Infection by high-risk genital HPVs is associated with the development of anogenital cancers. Classification of risk types is important in understanding the mechanisms in infection and in developing novel instruments for medical examination such as DNA microarrays. The sequence-based classification methods are useful in classifying risk types by considering residues in conserved positions. In this paper, we present a machine learning approach to the classification of HPV risk types by using the protein sequences. Our approach is based on the hidden Markov model and the kernel method. The former searches informative subsequence positions and the latter computes efficiently to classify protein sequences. In the experiments, the classifier predicted four unknown HPV types exactly. An additional result shows that the kernel-based classifiers learned with more informative subsequences outperform the classifiers learned with the whole sequence or random subsequences. (c) 2005 Elsevier Ltd. All rights reserved.	Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151742, South Korea; Seoul Natl Univ, Grad Program Bioinformat, Seoul 151742, South Korea; Seoul Natl Univ, Ctr Bioinformat Technol, Seoul 151742, South Korea; Inje Univ, Coll Med, Dept Pharmacol & Pharmacogen Res Ctr, Pusan 614735, South Korea	Zhang, BT (reprint author), Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151742, South Korea.	btzhang@bi.snu.ac.kr					BALDI P, 1994, P NATL ACAD SCI USA, V91, P1059, DOI 10.1073/pnas.91.3.1059; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; EDDY S, 1995, ISMB, V95, P114; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; HAGHEY R, 1996, CABIOS, V12, P95; JAAKKOLA T, 2000, J COMPUT BIOL; Janicek MF, 2001, CA-CANCER J CLIN, V51, P92; Leslie Christina, 2002, Pac Symp Biocomput, P564; Leslie C, 2003, NEURAL INFORM PROCES, P1441, DOI 10.1.1.58.4737; Longuet M, 1996, J CLIN MICROBIOL, V34, P738; Meyer T, 2001, INT J GYNECOL CANCER, V11, P198, DOI 10.1046/j.1525-1438.2001.01009.x; Munoz N, 2003, NEW ENGL J MED, V348, P518, DOI 10.1056/NEJMoa021641; PFISTER H, 1986, CIBA F SYMP, V120, P3; Ristriani T, 2000, J MOL BIOL, V296, P1189, DOI 10.1006/jmbi.2000.3527; Schoonjans F, 1996, CLIN CHEM, V42, P986; Sun YF, 2003, COMPUT BIOL MED, V33, P17, DOI 10.1016/S0010-4825(02)00057-4; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Ullman CG, 1996, BIOCHEM J, V319, P229; Vapnik VN, 1998, STAT LEARNING THEORY; Vert J P, 2002, Pac Symp Biocomput, P649; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; zur Hausen H, 2000, J NATL CANCER I, V92, P690; [Anonymous], 1995, IARC MON EV CARC RIS	23	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825		COMPUT BIOL MED	Comput. Biol. Med.	JUN	2006	36	6					656	667		10.1016/j.compbiomed.2004.04.007		12	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	047LY	WOS:000237882000007	
J	Li, DC; Wu, CS; Tsai, TI; Chang, FMM				Li, DC; Wu, CS; Tsai, TI; Chang, FMM			Using mega-fuzzification and data trend estimation in small data set learning for early FMS scheduling knowledge	COMPUTERS & OPERATIONS RESEARCH			English	Article						small data set; scheduling; flexible manufacturing system; ANFIS; data trend; mega-fuzzification	MANUFACTURING SYSTEMS; NEURAL-NETWORK; DECISION TREE; IDENTIFICATION; ENVIRONMENTS; SIMULATION	Provided with plenty of data (experience), data mining techniques are widely used to extract suitable management skills from the data. Nevertheless, in the early stages of a manufacturing system, only rare data can be obtained, and built scheduling knowledge is usually fragile. Using small data sets, this research's purpose is improving the accuracy of machine learning for flexible manufacturing system (FMS) scheduling. The study develops a data trend estimation technique and combines it with mega-fuzzification and adaptive-network-based fuzzy inference systems (ANFIS). The results of the simulated FMS scheduling problem indicate that learning accuracy can be significantly improved using the proposed method involving a very small data set. (c) 2004 Elsevier Ltd. All rights reserved.	Natl Cheng Kung Univ, Dept Ind & Informat Management, Tainan 701, Taiwan; Diwan Coll Management, Dept Business Adm, Tainan, Taiwan; Tungfang Inst Technol, Dept Ind Engn & Management, Kaohsiung, Taiwan	Li, DC (reprint author), Natl Cheng Kung Univ, Dept Ind & Informat Management, 1 Univ Rd, Tainan 701, Taiwan.	lidc@mail.ncku.edu.tw					Chen CC, 1996, INT J PROD RES, V34, P1739, DOI 10.1080/00207549608904994; Huang CF, 2004, INT J APPROX REASON, V35, P137, DOI 10.1016/j.ijar.2003.06.001; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Li DC, 2003, INT J PROD RES, V41, P4011, DOI 10.1080/0020754031000149211; Li DC, 1997, INT J SYST SCI, V28, P977, DOI 10.1080/00207729708929461; Li DC, 1996, EUR J OPER RES, V88, P404, DOI 10.1016/0377-2217(94)00196-0; LI DC, 2003, IN PRESS INT J ADV M; NAKASUKA S, 1992, INT J PROD RES, V30, P411, DOI 10.1080/00207549208942903; PIERREVAL H, 1990, J OPER RES SOC, V41, P461, DOI 10.2307/2583031; Priore P, 2001, AI EDAM, V15, P251, DOI 10.1017/S0890060401153059; Quinlan JR, 1996, ACM COMPUT SURV, V28, P71, DOI 10.1145/234313.234346; Sabuncuoglu I, 2002, INT J PROD RES, V40, P2483, DOI 10.1080/00207540210135596; SHAW MJ, 1992, IIE TRANS, V24, P156, DOI 10.1080/07408179208964213; LI DC, 1994, INT J PROD RES, V32, P2187; SRINIVASAN M, 1997, INT J PROD RES, V35, P1759; SUGENO M, 1988, FUZZY SET SYST, V28, P15, DOI 10.1016/0165-0114(88)90113-3; Sun YL, 1996, INT J PROD RES, V34, P2353, DOI 10.1080/00207549608905029; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Takagi T., 1983, P IFAC S FUZZ INF KN, P55	19	20	21	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0305-0548		COMPUT OPER RES	Comput. Oper. Res.	JUN	2006	33	6					1857	1869		10.1016/S0305-0548(04)00324-7		13	Computer Science, Interdisciplinary Applications; Engineering, Industrial; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	998SA	WOS:000234338400020	
J	Helma, C; Kazius, J				Helma, Christoph; Kazius, Jeroen			Artificial Intelligence and Data Mining for Toxicity Prediction	CURRENT COMPUTER-AIDED DRUG DESIGN			English	Article						Predictive toxicology; QSAR; artificial intelligence; data mining; machine learning; pattern recognition; data-driven learning; chemoinformatics		Tools for artificial intelligence and data mining can derive (Quantitative) Structure-Activity Relationships ((Q)SARs) for toxicity in an objective and reproducible manner. This review provides a conceptual description of the most important data mining algorithms for the identification of chemical features and the extraction of relationships between these descriptors and toxic activities. We will discuss the compliance of these techniques with the OECD guidelines for (Q)SAR requirements as well as performance implications. Special emphasis will be given to validation procedures for (Q)SAR models.	[Helma, Christoph] Silico Toxicol, D-79102 Freiburg, Germany; [Kazius, Jeroen] Leiden Univ, Div Med Chem, Leiden Amsterdam Ctr Drug Res, NL-2300 RA Leiden, Netherlands	Helma, C (reprint author), Silico Toxicol, Talstr 20, D-79102 Freiburg, Germany.	helma@in-silico.de			Centre for Documentation and Evaluation of Alternatives to Animal Experiments (ZEBET) of the Federal Instiute for Risk Assessment (BfR) [1328-179]	This work was funded by a grant (1328-179) of the Centre for Documentation and Evaluation of Alternatives to Animal Experiments (ZEBET) of the Federal Instiute for Risk Assessment (BfR) to C. Helma. We thank Prof. J. Kok, Prof. T. Back and Prof. A. P. IJzerman for proofreading.	BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Benigni R, 2005, CHEM REV, V105, P1767, DOI 10.1021/cr030049y; CRONIN M, 2005, PREDICTIVE TOXICOLOG; ERIKSSON L, 2005, PREDICTIVE TOXICOLOG; FRASCONI P, 2005, PREDICTIVE TOXICOLOG; Gasteiger J., 1990, TETRAHEDRON COMPUT M, V3, P537, DOI 10.1016/0898-5529(90)90156-3; Guha R, 2005, J CHEM INF MODEL, V45, P800, DOI 10.1021/ci050022a; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472; Helma C, 2003, BIOINFORMATICS, V19, P1179, DOI 10.1093/bioinformatics/btg084; Helma C, 2000, ENVIRON HEALTH PERSP, V108, P1029, DOI 10.1289/ehp.001081029; HELMA C, 2006, MOL DIVERS IN PRESS; Helma C, 2005, PREDICTIVE TOXICOLOG; Jaworska J, 2005, ATLA-ALTERN LAB ANIM, V33, P445; Kazius J, 2005, J MED CHEM, V48, P312, DOI 10.1021/jm040835a; KAZIUS J, 2006, J CHEM INF IN PRESS; Kier L. B, 1990, COMPUTATIONAL CHEM G; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; KLOPMAN G, 1984, J AM CHEM SOC, V106, P7315, DOI 10.1021/ja00336a004; Kohonen T., 1997, SELF ORG MAPS; KRAMER S, 2005, PREDICTIVE TOXICOLOG; KUBINYI H, 1994, QUANT STRUCT-ACT REL, V13, P285, DOI 10.1002/qsar.19940130306; KUHNE R, 1995, CHEMOSPHERE, V30, P2061, DOI 10.1016/0045-6535(95)00084-L; MALACARNE D, 1993, ENVIRON HEALTH PERSP, V101, P332, DOI 10.2307/3431444; Mitchell T, 1997, MACHINE LEARNING; NIJSSEN S, 2004, P 10 ACM SIGKDD INT; NYS GG, 1973, CHIM THER, V8, P521; PARSONS S, 2005, PREDICTIVE TOXICOLOG; Podlogar B L, 2000, Drug Des Discov, V17, P4; Raymond JW, 2002, J COMPUT AID MOL DES, V16, P59, DOI 10.1023/A:1016387816342; Richard A.M, 2006, PRECLINICA, V2, P103; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P854, DOI 10.1021/ci00020a020; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P1912, DOI 10.1021/ci049782w; So SS, 1996, J MED CHEM, V39, P1521, DOI 10.1021/jm9507035; Todeschini R., 2000, HDB MOL DESCRIPTORS; Toivonen H, 2003, BIOINFORMATICS, V19, P1183, DOI 10.1093/bioinformatics/btg130; Tropsha A, 2003, QSAR COMB SCI, V22, P69, DOI 10.1002/qsar.200390007; Vapnik V. N, 1995, NATURE STAT LEARNING; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Witten I. H., 2000, DATA MINING PRACTICA; Zhou ZH, 2003, AI COMMUN, V16, P3; *OECD, 2004, SER TEST ASS OECD, V49	42	3	3	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4099		CURR COMPUT-AID DRUG	Curr. Comput.-Aided Drug Des.	JUN	2006	2	2					123	133		10.2174/157340906777441717		11	Chemistry, Medicinal; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Computer Science	V17TH	WOS:000207959000004	
J	Li, S; Fevens, T; Krzyzak, A; Li, S				Li, Shuo; Fevens, Thomas; Krzyzak, Adam; Li, Song			Automatic clinical image segmentation using pathological modeling, PCA and SVM	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						image segmentation; pathological modeling; dental X-ray	ACTIVE CONTOURS; FRAMEWORK; ALGORITHM; MUMFORD; SETS	Due to the presence of complicated topological and residual features, the segmentation of medical imagery is a difficult problem. In this paper, an automated approach to clinical image segmentation is presented. The processing of these images in our approach is divided into learning and segmentation stages to facilitate the application of principal component analysis with a support vector machine (SVM) classifier. During the initial learning stage, representative images are chosen to represent typical input images. These images are segmented using a variational level set method driven by a modeled energy functional designed to delineate the pathological characteristics of the images. Then a window-based feature extraction is applied to these segmented images. Principal component analysis is applied to these extracted features and the results are used to train an SVM classifier. After training the SVM, any time a clinical image needs to be segmented, it is simply classified with the trained SVM. By the proposed method, we take the strengths of both machine learning and the variational level set method while limiting their weaknesses to achieve automatic and fast clinical segmentation. To test the proposed system, both chest (thoracic) computed tomography (CT) scans (2D and 3D) and dental X-rays are used. Promising results are demonstrated and analyzed. The proposed method can be used during pre-processing for automatic computer-aided diagnosis. (C) 2006 Elsevier Ltd. All rights reserved.	Concordia Univ, Dept Comp Sci & Software Engn, Med Imaging Grp, Montreal, PQ H3G 1M8, Canada; Anhui Med Univ, Sch Stomatol, Hefei, Anhui, Peoples R China	Li, S (reprint author), Concordia Univ, Dept Comp Sci & Software Engn, Med Imaging Grp, 1455 Maisonneuve Blvd W, Montreal, PQ H3G 1M8, Canada.	shuo_li@cs.concordia.ca; fevens@cs.concordia.ca; krzyzak@cs.concordia.ca; xlisong@sohu.com					BERGTHOLDT M, 2005, MATH MODELS COMPUTER; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CHAN T, 2001, IEEE T IMAGE PROCESS, V24, P266; Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; Dong JX, 2003, LECT NOTES ARTIF INT, V2734, P96; Dong JX, 2005, IEEE T PATTERN ANAL, V27, P603; HOLTZMANGAZIT M, 2003, MED IMAGE COMPUTING; Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417; LI S, 2005, IN PRESS COMPUTERIZE; Li S, 2005, LECT NOTES ARTIF INT, V3587, P314; LI S, 2005, SPIE C MED IM SAN DI, V5747, P580; Li S, 2004, LECT NOTES COMPUT SC, V3216, P160; Li S, 2004, INT CONGR SER, V1268, P207, DOI 10.1016/j.ics.2004.03.349; LORIGO LM, 2000, IEEE C COMP VIS PATT, P1444; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Perner P, 1999, ENG APPL ARTIF INTEL, V12, P749, DOI 10.1016/S0952-1976(99)00038-X; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Turk M., 1991, P IEEE C COMP VIS PA; TURK M, 1991, J COGNITIVE SCI, V3, P1; Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; WANG S, 2001, ICCV, P209; Yong X, 2005, PATTERN RECOGN LETT, V26, P1059, DOI 10.1016/j.patrec.2004.09.049; Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167; Zhu S., 1996, IEEE T PATTERN ANAL, V18.9, P884	27	11	13	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	JUN	2006	19	4					403	410		10.1016/j.engappai.2006.01.011		8	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	043GU	WOS:000237589100006	
J	Muruzabal, J				Muruzabal, J			A probabilistic classifier system and its application in data mining	EVOLUTIONARY COMPUTATION			English	Article						rule-based classification; generality; Bayesian learning; predictive scoring; cooperative mixtures	REINFORCEMENT; ALGORITHMS; DISCOVERY; ENSEMBLES; ACCURACY; MODELS; XCS	The article is about a new Classifier System framework for classification tasks called BYP_CS (for BaYesian Predictive Classifier System). The proposed CS approach abandons the focus on high accuracy and addresses a well-posed Data Mining goal, namely, that of uncovering the low-uncertainty patterns of dependence that manifest Often in the data. To attain this goal, BYP_CS uses a fair amount of probabilistic machinery, which brings its representation language closer to other related methods of interest in statistics and machine learning. On the practical side, the new algorithm is seen to yield stable learning of compact populations, and these still maintain a respectable amount of predictive power. Furthermore, the emerging rules self-organize in interesting ways, sometimes providing unexpected solutions to certain benchmark problems.	Univ Rey Juan Carlos, Dept Estadist & Invest Operat, Escuela Super Ciencias Expt & Tecnol, Mostoles 28933, Spain	Muruzabal, J (reprint author), Univ Rey Juan Carlos, Dept Estadist & Invest Operat, Escuela Super Ciencias Expt & Tecnol, Mostoles 28933, Spain.	jorge.muruzabal@urjc.es					AGRAWAL R, 1996, ADV KNOWLEDGE DISCOV, P307; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Au WH, 2003, IEEE T EVOLUT COMPUT, V7, P532, DOI 10.1109/TEVC.2003.819264; BANZHAF W, 1999, P GEN EV COMP C; Bay SD, 2001, DATA MIN KNOWL DISC, V5, P213, DOI 10.1023/A:1011429418057; Bernado-Mansilla E, 2003, EVOL COMPUT, V11, P209, DOI 10.1162/106365603322365289; Blake C. L., 1998, UCI REPOSITORY MACHI; BONARINI A, 2000, SPRINGERVERLAGS LECT, P83; BOOKER LB, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P265; BOOKER LB, 2000, SPRINGERVERLAG LECT, P125; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Bull L, 2004, LECT NOTES COMPUT SC, V3242, P1032; Butz M. V., 2002, Soft Computing, V6, DOI 10.1007/s005000100111; Butz MV, 2004, IEEE T EVOLUT COMPUT, V8, P28, DOI 10.1109/TEVC.2003.818194; Butz M.V., 2001, P GEN EV COMP C GECC, P927; Butz MV, 2003, EVOL COMPUT, V11, P239, DOI 10.1162/106365603322365298; Cheeseman P, 1996, ADV KNOWLEDGE DISCOV, P153; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; DIXON PW, 2003, SPRINGERVERLAGS LECT, P20; Eiben A. E., 2003, INTRO EVOLUTIONARY C; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; FLOCKHART IW, 1996, P 2 INT C KNOWL DISC, P299; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; FRIEDMAN JH, 1999, STAT COMPUT, V9, P1; Gelman A., 1995, BAYESIAN DATA ANAL; Ghosh A, 2003, IEEE T EVOLUT COMPUT, V7, P517, DOI 10.1109/TEVC.2003.819653; GOLDBERG DE, 1990, MACH LEARN, V5, P407, DOI 10.1007/BF00116878; Greene DP, 1994, EVOL COMPUT, V2, P67, DOI 10.1162/evco.1994.2.1.67; Hand D. J., 1997, CONSTRUCTION ASSESSM; HAND DJ, 2001, SPRINGERVERLAGS LECT, V2096, P136; Holland J. H., 1986, INDUCTION PROCESSES; Holland J. H., 1986, MACHINE LEARNING ART, VII, P593; HOLLAND JH, 1986, PHYSICA D, V22, P307; HOLMES JH, 1997, P 7 INT C GEN ALG IC, P426; HOLSHEIMER M, 1996, ADV KNOWLEDGE DISCOV, P447; HURST J, 2001, SPRINGERVERLAGS LECT, P70; JOHANSSON U, 2004, P 7 INT C INF FUS ST, P295; Jong K, 2004, LECT NOTES COMPUT SC, V3242, P1133; KITTLER J, 2001, SPRINGERVERLAGES LEC, V2096; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, P249; KOLCZ A, 2002, P 8 C KNOWL DISC DAT, P307; KOSKO B, 1996, FUZZY LOGIC NEURAL N, P1; Kovacs T., 1996, THESIS U BIRMINGHAM; Kuncheva LI, 2000, IEEE T EVOLUT COMPUT, V4, P327, DOI 10.1109/4235.887233; Lanzi P. L., 1999, P GEN EV COMP C GECC, P345; LANZI PL, 2003, SPRINGERVERLAGS LECT, V2661; LANZI PL, 2002, SPRINGERVERLAGS LECT, V2321; LANZI PL, 2001, SPRINGERVERLAGS LECT; LANZI PL, 2000, SPRINGERVERLAGS LECT, V1813; Lavrac N, 2004, MACH LEARN, V57, P115, DOI 10.1023/B:MACH.0000035474.48771.cd; Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58; Liepins G. E., 1991, P 4 INT C GEN ALG, P318; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; MURUZABAL J, 1999, P GEN EV COMP C GECC, P449; MURUZABAL J, 2001, DATA MINING HEURISTI, P117; Muruzabal J, 2001, COMPUTATION STAT, V16, P341, DOI 10.1007/s001800100071; MURUZABAL J, 2005, ENCY DATA WAREHOUSIN, P487; MURUZABAL J, 1994, SPRINGER VERLAG COMP, V866, P376; MURUZABAL J, 1995, P 2 IEEE INT C EV CO, P262; Packard N. H., 1990, Complex Systems, V4; PARODI A, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P223; RIOLO RL, 1991, P 1 INT C SIM AD BEH, P316; RUTA D, 2001, SPRINGERVERLAGS LECT, P399; SAXON S, 2000, SPRINGER LECT NOTES, V1813, P223; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SIRLANTZIS K, 2001, SPRINGERVERLAGS LECT, V2096, P99; Smith RE, 1994, EVOL COMPUT, V2, P199, DOI 10.1162/evco.1994.2.3.199; Smith RE, 1993, EVOL COMPUT, V1, P127, DOI 10.1162/evco.1993.1.2.127; Tierney L., 1990, LISP STAT OBJECT ORI; Venables W.N., 1999, MODERN APPL STAT S P; Weiss G., 2004, SIGKDD EXPLORATIONS, V6, P7; Westerdale TH, 2001, EVOL COMPUT, V9, P259, DOI 10.1162/106365601750405993; Wilson S. W., 1987, Machine Learning, V2, DOI 10.1007/BF00058679; Wilson S.W., 1998, P 3 ANN GEN PROGR C, P665; WILSON SW, 2001, SPRINGERVERLAGES LEC, P158; WILSON SW, 2002, SPRINGERVERLAGS LECT, V2321, P197; Wilson S. W., 2002, Natural Computing, V1, DOI 10.1023/A:1016535925043; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149	81	0	0	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	1063-6560		EVOL COMPUT	Evol. Comput.	SUM	2006	14	2					183	221		10.1162/evco.2006.14.2.183		39	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	047YN	WOS:000237914700004	
J	Oh, KJ; Kim, TY; Kim, C				Oh, KJ; Kim, TY; Kim, C			An early warning system for detection of financial crisis using financial market volatility	EXPERT SYSTEMS			English	Article						financial crisis; daily financial condition indicator; volatility; artificial neural network; genetic algorithm	OF-PAYMENTS CRISES; CURRENCY CRISIS; NEURAL-NETWORKS; BALANCE; MODEL	This study proposes an early warning system (EWS) for detection of financial crisis with a daily financial condition indicator (DFCI) designed to monitor the financial markets and provide warning signals. The proposed EWS differs from other commonly used EWSs in two aspects: (i) it is based on dynamic daily movements of the financial markets; and (ii) it is established as a pattern classifier, which identifies predefined unstable states in terms of financial market volatility. Indeed it issues warning signals on a daily basis by judging whether the financial market has entered a predefined unstable state or not. The major strength of a DFCI is that it can issue timely warning signals while other conventional EWSs must wait for the next round input of monthly or quarterly information. Construction of a DFCI consists of two steps where machine learning algorithms are expected to play a significant role, i.e. (i) establishing sub-DFCIs on various daily financial variables by an artificial neural network, and (ii) integrating the sub-DFCIs into an integrated DFCI by a genetic algorithm. The DFCI for the Korean financial market is built as an empirical case study.	Yonsei Univ, Dept Informat & Ind Engn, Seoul 120749, South Korea; Keimyung Univ, Dept Stat, Taegu, South Korea	Oh, KJ (reprint author), Yonsei Univ, Dept Informat & Ind Engn, 134 Shinchon Dong, Seoul 120749, South Korea.	johanoh@yonsei.ac.kr; tykim@kmu.ac.kr; chihokim@kdic.or.kr					Adeli H., 1995, MACHINE LEARNING NEU; Ahluwalia P., 2000, WP0014 IMF; BAIG T, 1998, WP98155 IMF; Caramazza Francesco, 2000, WP0055 IMF; CERRA V, 2000, WP0060 IMF; Edison H., 2000, INT FINANCE DISCUSSI; Edwards S., 1998, J APPL EC, V1, P55; Eichengreen B., 1995, ECONOMIC POLICY, V10, P249; Eichengreen B, 1996, SCAND J ECON, V98, P463, DOI 10.2307/3440879; Frankel JA, 1996, J INT ECON, V41, P351, DOI 10.1016/S0022-1996(96)01441-9; Goldberg DE, 1989, GENETIC ALGORITHMS S; GOLDSTEIN M, 1996, EC PAPERS, V46; Goldstein M., 2000, ASSESSING FINANCIAL; HOLLAND JH, 1975, ADAPTATION NATURAL A; Kaminsky G, 1998, INT MONET FUND S PAP, V45, P1; Kaminsky GL, 1999, AM ECON REV, V89, P473, DOI 10.1257/aer.89.3.473; Khalid A.M., 2003, J ASIAN EC, V14, P131, DOI 10.1016/S1049-0078(02)00243-9; Kim JW, 2004, BIOTECHNOL LETT, V26, P585, DOI 10.1023/B:BILE.0000021961.79459.53; KIM K, 2003, HAS KOREAN EC CHANGE; KIM TY, 2004, J DATA SCI, V2, P371; Kim TY, 2004, NEUROCOMPUTING, V61, P439, DOI 10.1016/j.neucom.2004.04.002; KRUGMAN P, 1979, J MONEY CREDIT BANK, V11, P311, DOI 10.2307/1991793; LING CX, 1995, NEUROCOMPUTING, V8, P341, DOI 10.1016/0925-2312(95)00050-G; Masih A.M.M., 1999, PACIFIC BASIN FINANC, V7, P251, DOI 10.1016/S0927-538X(99)00013-X; NAGAYASU J, 2000, WP0039 IMF; Nakashima A, 2001, NEURAL NETWORKS, V14, P79, DOI 10.1016/S0893-6080(00)00075-7; OBSTFELD M, 1986, AM ECON REV, V76, P72; Oh KJ, 2005, LECT NOTES ARTIF INT, V3809, P284; OZKAN FG, 1995, ECON J, V105, P510, DOI 10.2307/2235508; Peters E., 1991, CHAOS ORDER CAPITAL; Reside RE, 1999, MANCH SCH, V67, P460, DOI 10.1111/1467-9957.00169; Schittenkopf C, 1997, NEURAL NETWORKS, V10, P505, DOI 10.1016/S0893-6080(96)00086-X; VELASCO A, 1987, J DEV ECON, V27, P263, DOI 10.1016/0304-3878(87)90018-6; Wong F., 1994, TRADING EDGE	34	7	7	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0266-4720		EXPERT SYST	Expert Syst.	JUN	2006	23	2					83	98		10.1111/j.1468-0394.2006.00326.x		16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	041NZ	WOS:000237464200002	
J	Dorado, A; Djordjevic, D; Pedrycz, W; Izquierdo, E				Dorado, A.; Djordjevic, D.; Pedrycz, W.; Izquierdo, E.			Efficient image selection for concept learning	IEE PROCEEDINGS-VISION IMAGE AND SIGNAL PROCESSING			English	Article							PATTERN-RECOGNITION; CLUSTERING ALGORITHMS; RELEVANCE FEEDBACK; CLASSIFICATION; RETRIEVAL; FRAMEWORK; VALIDITY	In semantic-based image classification, learning concepts from features is an ongoing challenge for researchers and practitioners in different communities such as pattern recognition, machine learning and image analysis, among others. Concepts are used to add knowledge to the image descriptions linking high- and low-level numerical interpretation of the image content. Augmented descriptions are useful to perform more 'intelligent' processing on large-scale image databases. The semantic component casts the classification into the supervised or learning-from-examples paradigm, in which the classifier obtains knowledge by generalising specific facts presented in a number of design samples (or training patterns). Consequently, selection of suitable samples becomes a critical design step. The introduced framework exploits the capability of support vector classifiers to learn from relatively small number of patterns. Classifiers make decisions based on low-level descriptions containing only some image content information (e.g. colour, texture, shape). Therefore there is a clear drawback in collecting image samples by just using random visual observation and ignoring any low-level feature similarity. Moreover, this sort of approach set-up could lead to sub-optimal training data sets. The presented framework uses unsupervised learning to organise images based on low-level similarity, in effort to assist a professional annotator in picking positive and negative samples for a given concept. Active learning to refine the classifier model follows this initial design step. The framework shows promising results as an efficient approach in selecting design samples for semantic image description and classification.	Univ London, Queen Mary, Dept Elect Engn, London E1 4NS, England; Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada	Dorado, A (reprint author), Univ London, Queen Mary, Dept Elect Engn, Mile End Rd, London E1 4NS, England.	andres.dorado@elec.qmul.ac.uk					BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1; Bhanu B, 2002, ENG APPL ARTIF INTEL, V15, P123, DOI 10.1016/S0952-1976(02)00026-X; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Perez-Cruz F, 2004, IEEE SIGNAL PROC MAG, V21, P57, DOI 10.1109/MSP.2004.1296543; Dorai C, 2003, IEEE MULTIMEDIA, V10, P15, DOI 10.1109/MMUL.2003.1195157; Duda R. O., 2001, PATTERN CLASSIFICATI; Duin R. P. W., 2000, P 15 INT C PATT REC, V2, P1, DOI 10.1109/ICPR.2000.906006; Gorkani M.M., 1994, P INT C PAT REC JER, V1, P459, DOI 10.1109/ICPR.1994.576325; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Jain A. K., 1999, ACM COMPUT SURV, V31; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Keerthi S., 1999, IMPROVEMENTS PLATTS; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Nakazato M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P201; Nguyen H.T., 2004, P 21 INT C MACH LEAR; PEDRYCZ W, 1990, PATTERN RECOGN, V23, P121, DOI 10.1016/0031-3203(90)90054-O; Pedrycz W, 2005, KNOWLEDGE-BASED CLUSTERING: FROM DATA TO INFORMATION GRANULES, P1, DOI 10.1002/0471708607; Platt J., 1999, ADV LARGE MARGIN CLA, P61; ROUBENS M, 1982, EUR J OPER RES, V10, P294, DOI 10.1016/0377-2217(82)90228-4; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644; SAITTA L, 1993, IEEE T PATTERN ANAL, V15, P145, DOI 10.1109/34.192486; SIMON JC, 1975, PATTERN RECOGN, V7, P117, DOI 10.1016/0031-3203(75)90022-9; SMITH JR, 2002, P SPIE C STOR RETR M; Tong S., 2001, P ACM INT C MULT, P107, DOI DOI 10.1145/560141.500159; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Vailaya A., 1998, Proceedings. IEEE Workshop on Content-Based Access of Image and Video Libraries (Cat. No.98EX173), DOI 10.1109/IVL.1998.694464; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; XIE Y, 2002, P IEEE INT C FUZZ SY, V1, P627; YOSHIZAWA T, 2004, P 6 ACM SIGMM INT WO, P165, DOI 10.1145/1026711.1026739; Zhang C, 2002, IEEE T MULTIMEDIA, V4, P260	33	4	4	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	1350-245X		IEE P-VIS IMAGE SIGN	IEE Proc.-Vis. Image Signal Process.	JUN	2006	153	3					263	273		10.1049/ip-vis:20050057		11	Engineering, Electrical & Electronic	Engineering	065MB	WOS:000239162900003	
J	Murphey, YL; Abul Masrur, M; Chen, ZH; Zhang, BF				Murphey, YL; Abul Masrur, M; Chen, ZH; Zhang, BF			Model-based fault diagnosis in electric drives using machine learning	IEEE-ASME TRANSACTIONS ON MECHATRONICS			English	Article						electric drives; electric vehicle; field-oriented control (FOC); fuzzy techniques; hybrid vehicle; inverter; machine learning; model-based diagnostics; motor; neural network; power electronics	INDUCTION-MOTOR DRIVES; SYSTEM	Electric motor and power electronics-based inverter, are the major components in industrial and automotive electric drives. In this paper, we present a model-based fault diagnostics system developed using a machine learning technology for detecting and locating multiple classes of faults in an electric drive. Power electronics inverter can be considered to be the weakest link in such a system from hardware failure point of view; hence, this work is focused on detecting faults and finding which switches in the inverter cause the faults. A simulation model has been developed based on the theoretical foundations of electric drives to simulate the normal condition, all single-switch and post-short-circuit faults. A machine learning algorithm has been developed to automatically select a set of representative operating points in the (torque, speed) domain, which in turn is sent to the simulated electric drive model to generate signals for the training of a diagnostic neural network, fault diagnostic neural network (FDNN). We validated the capability of the FDNN on data generated by an experimental bench setup. Our research demonstrates that with a robust machine learning approach, a diagnostic system can be trained based on a simulated electric drive model, which can lead to a correct classification of faults over a wide operating domain.	Univ Michigan, Dearborn, MI 48128 USA; USA, Tank Automot Rs Dev & Engn Ctr, Warren, MI 48397 USA	Murphey, YL (reprint author), Univ Michigan, Dearborn, MI 48128 USA.	yilu@umich.edu; masrura@tacom.army.mil					Allwein EL, 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; BAKHSHAI A, 1997, P APPL POW EL C EXP, V12, P872; Benbouzid MEH, 1999, IEEE T ENERGY CONVER, V14, P1065, DOI 10.1109/60.815029; Chan C. C., 2001, MODERN ELECT VEHICLE; Chow MY, 1997, METHODOLOGIES USING; Crossman JA, 2003, IEEE T VEH TECHNOL, V52, P1063, DOI 10.1109/TVT.2002.807635; Feldkamp LA, 1998, P IEEE, V86, P2259, DOI 10.1109/5.726790; FENTON W, 2000, IEEE T SYST MAN CYB, V31, P269; Filippetti F, 2000, IEEE T IND ELECTRON, V47, P994, DOI 10.1109/41.873207; Fukushima K., 1988, IEEE COMPUT, V21, P65; GERTLER J, 1995, IEEE T CONTR SYST T, V3, P61; HARPELED S, 2002, P 13 INT C ALG LEARN, P365; Hodkinson Ron, 2001, LIGHTWEIGHT ELECT HY; HOLTZ J, 1992, IEEE T IND ELECTRON, V39, P411; Huang W., 1988, NEURAL INFORMATION P, P387; KAO YT, 1992, IEEE T IND ELECTRON, V39, P46; KASTHA D, 1994, IEEE T IND APPL, V30, P1028, DOI 10.1109/28.297920; Kim K, 2002, IEEE-ASME T MECH, V7, P201; Klima J, 2003, IEE P-ELECT POW APPL, V150, P255, DOI 10.1049/ip-epa:20030122; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li X., 2004, P 17 INT C PATT REC, V2, P761; LIAW CM, 1992, IEEE T POWER ELECTR, V7, P411; MASRUR MA, 1995, Patent No. 5469351; Mohan N., 1995, POWER ELECT; Moseler O, 2000, IEEE T IND ELECTRON, V47, P1015, DOI 10.1109/41.873209; Murphey YL, 2003, IEEE T VEH TECHNOL, V52, P1076, DOI 10.1109/TVT.2003.814236; MURPHYE YL, 2002, P IEEE INT JOINT C N, V3, P2304; MURPHYE YL, 2000, IEEE T VEH, V49, P1650; Novotny D., 1996, VECTOR CONTROL DYNAM; Nyberg M, 2002, IEEE T CONTR SYST T, V10, P679, DOI 10.1109/TCST.2002.801873; OU GB, 2004, INT C PATT REC CAMBR; Price D., 1995, ADV NEURAL INFORMATI, P1109; Ribeiro RLD, 2003, IEEE T POWER ELECTR, V18, P587, DOI 10.1109/TPEL.2003.809351; Smith S, 1997, JPN QUART, V44, P4; Zhao L, 2000, IEEE T INTELL TRANSP, V1, P148, DOI 10.1109/6979.892151; ZIDANI F, 2000, IEEE T ENERGY CONVER, V18, P469	36	20	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4435		IEEE-ASME T MECH	IEEE-ASME Trans. Mechatron.	JUN	2006	11	3					290	303		10.1109/TMECH.2006.875568		14	Automation & Control Systems; Engineering, Manufacturing; Engineering, Electrical & Electronic; Engineering, Mechanical	Automation & Control Systems; Engineering	058ZX	WOS:000238704200006	
J	Fan, H; Ramamohanarao, K				Fan, H; Ramamohanarao, K			Fast discovery and the generalization of strong jumping emerging patterns for building compact and accurate classifiers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; machine learning; emerging patterns; classification; frequent patterns; mining methods and algorithms	GENE-EXPRESSION PROFILES; DATABASES	Classification of large data sets is an important data mining problem that has wide applications. Jumping Emerging Patterns ( JEPs) are those itemsets whose supports increase abruptly from zero in one data set to nonzero in another data set. In this paper, we propose a fast, accurate, and less complex classifier based on a subset of JEPs, called Strong Jumping Emerging Patterns ( SJEPs). The support constraint of SJEP removes potentially less useful JEPs while retaining those with high discriminating power. Previous algorithms based on the manipulation of border [ 1] as well as consEPMiner [ 2] cannot directly mine SJEPs. Here, we present a new tree-based algorithm for their efficient discovery. Experimental results show that: 1) the training of our classifier is typically 10 times faster than earlier approaches, 2) our classifier uses much fewer patterns than the JEP-Classifier [ 3] to achieve a similar ( and, often, improved) accuracy, and 3) in many cases, it is superior to other state-of-the-art classification systems such as Naive Bayes, CBA, C4.5, and bagged and boosted versions of C4.5. We argue that SJEPs are high-quality patterns which possess the most differentiating power. As a consequence, they represent sufficient information for the construction of accurate classifiers. In addition, we generalize these patterns by introducing Noise-tolerant Emerging Patterns (NEPs) and Generalized Noise-tolerant Emerging Patterns ( GNEPs). Our tree-based algorithms can be adopted to easily discover these variations. We experimentally demonstrate that SJEPs, NEPs, and GNEPs are extremely useful for building effective classifiers that can deal well with noise.	Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic 3010, Australia	Fan, H (reprint author), Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic 3010, Australia.	hfan@csse.unimelb.edu.au; rao@csse.unimelb.edu.au					AGRAWAL R, 1992, PROC INT CONF VERY L, P560; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAILEY J, 2002, P 6 EUR C PRINC PRAC; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Cheeseman P., 1996, P 2 INT C KNOWL DISC, P153; Christensen Ronald, 1997, LOG LINEAR MODELS LO; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Dong G., 1999, P 2 INT C DISC SCI, P30; Dong G., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Fan H., 2002, P 6 PAC AS C KNOWL D, P456; Fayyad U, 1996, AI MAG, V17, P37; Freitas A., 2002, DATA MINING KNOWLEDG; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J. W, 2000, DATA MINING CONCEPTS; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; Li J., 2003, BIOINFORMATICS S2, V19, pii93; LI J, 2000, P 17 INT C MACH LEAR, P551; Li J, 2001, KNOWL INF SYST, V3, P131, DOI 10.1007/PL00011662; Li JY, 1999, LECT NOTES ARTIF INT, V1704, P406; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58; Liu H, 1998, ELEC SOC S, V98, P86; Mitchell T, 1997, MACHINE LEARNING; MITCHELL T, 1982, ARTIFICIAL INTELLIGE, V18; Pei J., 2001, P 2001 INT C DAT MIN; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ripley B. D, 1996, PATTERN RECOGNITION; Seno M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989558; Witten I. H., 1999, DATA MINING PRACTICA; Yang C., 2001, P 7 ACM SIGKDD INT C, P194, DOI 10.1145/502512.502539; Zhang X., 2000, P 6 INT C KNOWL DISC, P310, DOI 10.1145/347090.347158; [Anonymous], 1993, P 13 INT JOINT C ART, P1022; *RULEQUEST, 2000, SEE5 C5 0 RULEQUEST	39	23	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUN	2006	18	6					721	737		10.1109/TKDE.2006.95		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	033ML	WOS:000236851800001	
J	Yeasin, M; Bullot, B; Sharma, R				Yeasin, Mohammed; Bullot, Baptiste; Sharma, Rajeev			Recognition of facial expressions and measurement of levels of interest from video	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						emotions; face detection; hidden Markov models (HMMs); levels of interest; machine learning; universal facial expressions	EMOTION; UNIVERSALS; FACE	This paper presents a spatio-temporal approach in recognizing six universal facial expressions from visual data and using them to compute levels of interest. The classification approach relies on a two-step strategy on the top of projected facial motion vectors obtained from video sequences of facial expression. First a linear classification bank was applied on projected optical flow vectors and decisions made by the linear classifiers were coalesced to produce a characteristic signature for each universal facial expression. The signatures thus computed from the training data set were used to train discrete hidden Markov models (HMMs) to learn the underlying model for each facial expression. The performances of the proposed facial expressions recognition were computed using five fold cross-validation on Cohn-Kanade facial expressions database consisting of 488 video sequences that includes 97 subjects. The proposed approach achieved an average recognition rate of 90.9% on Cohn-Kanade facial expressions database. Recognized facial expressions were mapped to levels of interest using the affect space and the intensity of motion around apex frame. Computed level of interest was subjectively analyzed and was found to be consistent with "ground truth" information in most of the cases. To further illustrate the efficacy of the proposed approach, and also to better understand the effects of a number of factors that are detrimental to the facial expression recognition, a number of experiments were conducted. The first empirical analysis was conducted on a database consisting of 108 facial expressions collected from TV broadcasts and labeled by human coders for subsequent analysis. The second experiment (emotion elicitation) was conducted on facial expressions obtained from 21 subjects by showing the subjects six different movies clips chosen in a manner to arouse spontaneous emotional reactions that Would produce natural facial expressions.	Univ Memphis, Dept Elect & Comp Engn, Memphis, TN 38152 USA; Amadeus Inc, Paris 75001, France; Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	Yeasin, M (reprint author), Univ Memphis, Dept Elect & Comp Engn, Memphis, TN 38152 USA.	myeasin@memphis.edu					AVENT R, 1994, ANN INT C IEEE; Azoz Y, 2003, MACH VISION APPL, V13, P286, DOI 10.1007/s00138-002-0110-1; BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037//0022-3514.37.11.2049; BLACK M, 1995, INT C COMP VIS; BOYLE EA, 1994, LANG SPEECH, V37, P1; BREAZAL C, 2000, THESIS MIT CAMBRIDGE; BREAZEAL C, 1999, ROBOT SOC FRIEND APP; CASSELL J, 1994, SIGGRAPH 94; Cohen I, 2000, EMOTION RECOGNITION; Cohen I., 2000, NEURAL INFORM PROCES; Cottrell G., 1991, ADV NEURAL INFORMATI, V3, P564; COTTRELL G, 2000, APA TALK; DARRELL T, 1995, P INT WORKSH AUT FAC, P135; Darrell T., 1995, Advances in Neural Information Processing Systems 7; Ekman Paul, 2003, Ann N Y Acad Sci, V1000, P266, DOI 10.1196/annals.1280.013; EKMAN P, 1992, PHILOS T ROY SOC B, V335, P63, DOI 10.1098/rstb.1992.0008; EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037//0003-066X.48.4.384; EKMAN P, 1964, J ABNORM SOC PSYCH, V68, P295, DOI 10.1037/h0040225; EKMAN P, 1976, CONSULTING PSYCHOL; EKMAN P., 1976, PICTURES FACIAL AFFE; Ekman P, 1994, NATURE EMOTION FUNDA; EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037//0033-2909.115.2.268; EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037//0033-295X.99.3.550; EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712; Ekman P, 2003, ANN NY ACAD SCI, V1000, P1, DOI 10.1196/annals.1280.002; EKMAN P, 1980, SCIENCE, V209, P833, DOI 10.1126/science.7403851; ESSA I, 1995, INT C COMP VIS; ESSA I, 1995, IEEE T PATTERN ANAL, P757; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Franco L., 2001, P 2 INT S IM SIGN PR, P628; Haidt J, 1999, COGNITION EMOTION, V13, P225; HOEY J, 2001, IEEE WORKSHOP DETECT; IZARD CE, 1977, HUMAN EMOTION; KANADE T, 2000, IEEE INT C AUT FAC G; KAPOOR A, 2001, AM ASS ART INT; KUMAR V, 2000, IEEE INT C AUT FAC G; LEVENSON RW, 1991, PSYCHOL AGING, V6, P28, DOI 10.1037/0882-7974.6.1.28; LIEN JJ, 1998, IEEE C COMP VIS PATT; LIN D, 1999, INT C NEUR INF PROC; LISETTI C, 1998, INT FLAIRS C; Lisetti C. L., 2000, PRAGMATICS COGNITION, V8, P185, DOI 10.1075/pc.8.1.09lis; LUCAS B, 1981, P DARPA IMAGE UNDERS; LYONS M, INT C AUT FAC GEST R, P98; Matsumura K, 1997, ELECTRON COMM JPN 3, V80, P36, DOI 10.1002/(SICI)1520-6440(199701)80:1<36::AID-ECJC4>3.0.CO;2-5; MOSES Y, 1995, INT C COMP VIS; OLIVER N, 1997, IEEE C COMP VIS PATT; OLIVER N, 1997, LAFTER LIPS FACE REA; PADGETT C, 1997, REPRESENTING FACE IM; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; PICARD R, 1993, P IEEE INT C AC SPEE, P161; PICARD R, 1998, P IMAGINA; Picard R. W., 1997, AFFECTIVE COMPUTING; ROSENBLUM M, 1994, IEEE WORKSHOP MOTION; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; STEPHENSON GM, 1976, BRIT J SOC CLIN PSYC, V15, P113; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414; YEASIN M, 2000, IEEE COMP SOC C COMP; Yoshitomi Y., 2000, IEEE INT WORKSH ROB	59	43	43	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	JUN	2006	8	3					500	508		10.1109/TMM.2006.870737		9	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	046OX	WOS:000237822000007	
J	Li, T; Ogihara, M				Li, T; Ogihara, M			Toward intelligent music information retrieval	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						clustering; FFT; machine learning; music information retrieval; wavelet	TEXT CATEGORIZATION; GENRE	Efficient and intelligent music information retrieval is a very important topic of the 21st century. With the ultimate goal of building personal music information retrieval systems, this paper studies the problem of intelligent music information retrieval. Huron [10] points out that since the preeminent functions of music are social and psychological, the most useful characterization would be based on four types of information: genre, emotion, style, and similarity. This paper introduces Daubechies Wavelet Coefficient Histograms (DWCH) for music feature extraction for music information retrieval. The histograms are computed from the coefficients of the db(8) Daubechies wavelet filter applied to 3 s of music. A comparative study of sound features and classification algorithms on a dataset compiled by Tzanetakis shows that combining DWCH with timbral features (MFCC and FFT), with the use of multiclass extensions of support vector machine, achieves approximately 80% of accuracy, which is a significant improvement over the previously known result on this dataset. On another dataset the combination achieves 75% of accuracy. The paper also studies the issue of detecting emotion in music. Rating of two subjects in the three bipolar adjective pairs are used. The accuracy of around 70% was achieved in predicting emotional labeling in these adjective pairs. The paper also studies the problem of identifying groups of artists based on their lyrics and sound using a semi-supervised classification algorithm. Identification of artist groups based on the Similar Artist lists at All Music Guide is attempted. The semi-supervised learning algorithm resulted in nontrivial increases in the accuracy to more than 70%. Finally, the paper conducts a proof-of-concept experiment on similarity search using the feature set.	Florida Int Univ, Sch Comp Sci, Miami, FL 33199 USA; Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Li, T (reprint author), Florida Int Univ, Sch Comp Sci, Miami, FL 33199 USA.	taoli@cs.flu.edu; ogihara@cs.rochester.edu					Argamon S., 2003, P 9 ACM SIGKDD INT C, P475; BILL E, 1994, P 12 NAT C ART INT, V1, P722; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Daubechies I., 1992, 10 LECT WAVELETS; Dowling WJ, 1986, MUSIC COGNITION; Ellis D. P. W., 2002, P INT S MUS INF RETR, P170; Farnsworth P.R., 1958, SOCIAL PSYCHOL MUSIC; Flandrin P., 1992, IEEE T INFORM THEORY, V38; FUNG G, 2001, 0106 U; Hevner K, 1936, AM J PSYCHOL, V48, P246, DOI 10.2307/1415746; HURON D, 2000, P INT S MUS INF RETR; KESSLER, 1997, P 35 ANN M ASS COMP, P32; LEMAN M, 2003, UNPUB ACOUSTICAL COM; LI G, 2000, P IEEE INT C MULT EX, P885; Li Q., 2003, P 26 ANN INT ACM SIG, P282; LI T, 2003, SIGKDD EXPLORATIONS, V4, P49; LI T., 2003, P INT S MUS INF RETR, P239; LI T, 2004, P 2004 IEEE INT C AC, pV705; LI T, 2004, P 12 ANN ACM INT C M, P364, DOI 10.1145/1027527.1027612; Li T, 2005, KNOWL INF SYST, V7, P289, DOI 10.1007/s10115-004-0155-8; Li Tao, 2003, P IEEE WORKSH APPL S, P143; Logan B., 2000, P INT S MUS INF RETR; Mandal MK, 1999, COMPUT VIS IMAGE UND, V75, P99, DOI 10.1006/cviu.1999.0766; Matias Y, 1998, P 1998 ACM SIGMOD IN, P448, DOI 10.1145/276304.276344; MITTON R, 1987, INFORM PROCESS MANAG, V23, P103; Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2; PERROT D, 1999, P SOC MUS PERC COGN, P88; PYE D, 2000, P 2000 IEEE INT C AC; Rabiner L, 1993, FUNDAMENTALS SPEECH; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SOLTAU H, 1998, P 1998 IEEE INT C AC; Stamatatos E, 2000, COMPUT LINGUIST, V26, P471, DOI 10.1162/089120100750105920; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tweedie FJ, 1998, COMPUT HUMANITIES, V32, P323, DOI 10.1023/A:1001749303137; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Vapnik VN, 1998, STAT LEARNING THEORY; WEISS G, 2001, 44 MLTR; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540	38	36	38	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1520-9210		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	JUN	2006	8	3					564	574		10.1109/TMM.2006.870730		11	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	046OX	WOS:000237822000013	
J	Blankertz, B; Dornhege, G; Krauledat, M; Muller, KR; Kunzmann, V; Losch, F; Curio, G				Blankertz, B; Dornhege, G; Krauledat, M; Muller, KR; Kunzmann, V; Losch, F; Curio, G			The Berlin brain-computer interface: EEG-based communication without subject training	IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING			English	Article; Proceedings Paper	3rd International Meeting on Brain-Computer Interface Technology	JUN, 2005	Rensselaerville, NY		Rensselaerville Inst	brain-computer interface (BCI); classification; common spatial patterns; electroencephalogram (EEG); event-related desynchronization (ERD); information transfer rate; machine learning; readiness potential (RP); single-trial analysis	BOOSTING BIT RATES; SINGLE-TRIAL EEG; INFORMATION-TRANSFER; DESYNCHRONIZATION; MOVEMENT; CLASSIFICATION; POTENTIALS	The Berlin Brain-Computer Interface (BBCI) project develops a noninvasive BCI system whose key features are 1) the use of well-established motor competences as control paradigms, 2) high-dimensional features from 128-channel electroencephalogram (EEG), and 3) advanced machine learning techniques. As reported earlier, our experiments demonstrate that very high information transfer rates can be achieved using the readiness potential (RP) when predicting the laterality of upcoming left-versus right-hand movements in healthy subjects. A more recent study showed that the RP similarily accompanies phantom movements in arm amputees, but the signal strength decreases with longer loss of the limb. In a complementary approach, oscillatory features are used to discriminate imagined movements (left hand versus right hand versus foot). In a recent feedback study with six healthy subjects with no or very little experience with BCI control, three subjects achieved an information transfer rate above 35 bits per minute (bpm), and further two subjects above 24 and 15 bpm, while one subject could not achieve any BCI control. These results are encouraging for an EEG-based BCI system in untrained subjects that is independent of peripheral nervous system activity and does not rely on evoked potentials even when compared to results with very well-trained subjects operating other BCI systems.	Fraunhofer FIRST IDA, D-12489 Berlin, Germany; Univ Potsdam, D-14469 Potsdam, Germany; Charite Univ Med Berlin, Dept Neurol, D-10117 Berlin, Germany	Blankertz, B (reprint author), Fraunhofer FIRST IDA, D-12489 Berlin, Germany.	benjamin.blankertz@first.fraunhofer.de	Muller, Klaus/C-3196-2013				Babiloni C, 1999, NEUROIMAGE, V10, P658, DOI 10.1006/nimg.1999.0504; BLANKERTZ B, 2005, FEEDB SESS FRAUNH FI; Blankertz B, 2003, IEEE T NEUR SYS REH, V11, P127, DOI 10.1109/TNSRE.2003.814456; Cheng M, 2002, IEEE T BIO-MED ENG, V49, P1181, DOI 10.1109/TBME.2002.803536; Cui RQ, 1999, NEUROIMAGE, V9, P124, DOI 10.1006/nimg.1998.0388; Curran EA, 2003, BRAIN COGNITION, V51, P326, DOI 10.1016/0278-2626(03)00036-8; DORNHEGE G, 2006, THESIS U POTSDAM POT; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Dornhege G., 2003, P ADV NEUR INF P SYS, P1115; FERREZ JD, 2005, P 19 INT JOINT C ART, P1413; Haykin S., 1995, ADAPTIVE FILTER THEO; Jankowski T, 2002, J COMPUT APPL MATH, V147, P1, DOI 10.1016/S0377-0427(02)00371-0; KORNHUBE.HH, 1965, PFLUG ARCH GES PHYS, V284, P1, DOI 10.1007/BF00412364; Krausz G, 2003, APPL PSYCHOPHYS BIOF, V28, P233, DOI 10.1023/A:1024637331493; Kubler A, 2001, PSYCHOL BULL, V127, P358, DOI 10.1037//0033-2909.127.3.358; LANG W, 1989, EXP BRAIN RES, V74, P99; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; McFarland DJ, 2003, BIOL PSYCHOL, V63, P237, DOI 10.1016/S0301-0511(03)00073-5; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Muller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484; Parra LC, 2003, IEEE T NEUR SYS REH, V11, P173, DOI 10.1109/TNSRE.2003.814446; Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8; Schalk G, 2000, CLIN NEUROPHYSIOL, V111, P2138, DOI 10.1016/S1388-2457(00)00457-0; TORO C, 1994, ELECTROEN CLIN NEURO, V93, P380, DOI 10.1016/0168-5597(94)90126-0; Vaughan TM, 1998, ELECTROEN CLIN NEURO, V107, P428, DOI 10.1016/S0013-4694(98)00107-2; Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P164, DOI 10.1109/TRE.2000.847807; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	27	84	87	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1534-4320		IEEE T NEUR SYS REH	IEEE Trans. Neural Syst. Rehabil. Eng.	JUN	2006	14	2					147	152		10.1109/TNSRE.2006.875557		6	Engineering, Biomedical; Rehabilitation	Engineering; Rehabilitation	054QW	WOS:000238394700007	
J	Blankertz, B; Muller, KR; Krusienski, DJ; Schalk, G; Wolpaw, JR; Schlogl, A; Pfurtscheller, G; Millan, JDR; Schroder, M; Birbaumer, N				Blankertz, B; Muller, KR; Krusienski, DJ; Schalk, G; Wolpaw, JR; Schlogl, A; Pfurtscheller, G; Millan, JDR; Schroder, M; Birbaumer, N			The BCI competition III: Validating alternative approaches to actual BCI problems	IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING			English	Article; Proceedings Paper	3rd International Meeting on Brain-Computer Interface Technology	JUN, 2005	Rensselaerville, NY		Rensselaerville Inst	augmentative communication; beta rhythm; brain-computer interface (BCI); electroencephalography (EEG); ERP; imagined hand movements; mu rhythm; nonstationarity; P300; rehabilitation; single-trial classification; slow cortical potentials	BRAIN-COMPUTER INTERFACES; MENTAL PROSTHESIS; EEG; COMMUNICATION; TASK	A brain-computer interface (BCI) is a system that allows its users to control external devices with brain activity. Although the proof-of-concept was given decades ago, the reliable translation of user intent into device control commands is still a major challenge. Success requires the effective interaction of two adaptive controllers: the user's brain, which produces brain activity that encodes intent, and the BCI system, which translates that activity into device control commands. In order to facilitate this interaction, many laboratories are exploring a variety of signal analysis techniques to improve the adaptation of the BCI system to the user. In the literature, many machine learning and pattern classification algorithms have been reported to give impressive results when applied to BCI data in offline analyses. However, it is more difficult to evaluate their relative value for actual online use. BCI data competitions have been organized to provide objective formal evaluations of alternative methods. Prompted by the great interest in the first two BCI Competitions, we organized the third BCI Competition to address several of the most difficult and important analysis problems in BCI research. The paper describes the data sets that were provided to the competitors and gives an overview of the results.	Fraunhofer FIRST IDA, D-12489 Berlin, Germany; Univ Potsdam, D-14415 Potsdam, Germany; New York State Dept Hlth, Wadsworth Ctr, Lab Nervous Syst Disorders, Albany, NY 12208 USA; SUNY Albany, Albany, NY 12222 USA; Graz Univ Technol, Inst Human Comp Interfaces, A-8010 Graz, Austria; IDIAP Res Inst, CH-1920 Martigny, Switzerland; Univ Tubingen, Dept Tech Comp Sci, D-72076 Tubingen, Germany; Univ Tubingen, Inst Med Psychol & Behav Neurobiol, D-72076 Tubingen, Germany	Blankertz, B (reprint author), Fraunhofer FIRST IDA, D-12489 Berlin, Germany.	benjamin.blankertz@first.fraunhofer.de	Millan, Jose del R./F-1696-2011; Muller, Klaus/C-3196-2013	Millan, Jose del R./0000-0001-5819-1522; 			Blanco A, 2002, TAPPI J, V1, P14; BLANKERTZ B, 2004, BCI COMPETITION, V3; Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692; BLANKERTZ B, 2003, BCI COMPETITION 2003; BLANKERTZ B, 2005, BCI COMPETITION, V3; Curran EA, 2003, BRAIN COGNITION, V51, P326, DOI 10.1016/0278-2626(03)00036-8; Donchin E, 2000, IEEE T REHABIL ENG, V8, P174, DOI 10.1109/86.847808; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Dornhege G., 2003, ADV NEURAL INF P SYS, V15, P1115; FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6; Kubler A, 2001, PSYCHOL BULL, V127, P358, DOI 10.1037//0033-2909.127.3.358; Lal T., 2005, ADV NEURAL INFORM PR, V17, P737; Millan J, 2002, HDB BRAIN THEORY NEU; Millan J. d. R., 2004, P INT JOINT C NEUR N; Millan JD, 2004, IEEE T BIO-MED ENG, V51, P1026, DOI 10.1109/TBME.2004.827086; Millan JD, 2004, ARTIF INTELL, V159, P241, DOI 10.1016/j.artint.2004.05.008; Muller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484; Muller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8; SAJDA P, 2001, BCI COMPETITION, V3; Sajda P, 2003, IEEE T NEUR SYS REH, V11, P184, DOI 10.1109/TNSRE.2003.814453; Schalk G, 2000, CLIN NEUROPHYSIOL, V111, P2138, DOI 10.1016/S1388-2457(00)00457-0; SCHALK G, 2004, IEEE T BIOMED EN JUN, P1034; SCHLOGL A, 2005, RESULTS BCI COMPETIT; Schlogl A, 2002, BIOMED TECH, V47, P3, DOI 10.1515/bmte.2002.47.1-2.3; SCHLOGL A, 2004, GDF GEN DATAFORMAT B; SCHLOGL A, 2003, BIOSIG OPEN SOURCE S; Wang YH, 1999, CLIN NEUROPHYSIOL, V110, P604, DOI 10.1016/S1388-2457(98)00056-X; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	28	121	132	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1534-4320		IEEE T NEUR SYS REH	IEEE Trans. Neural Syst. Rehabil. Eng.	JUN	2006	14	2					153	159		10.1109/TNSRE.2006.875642		7	Engineering, Biomedical; Rehabilitation	Engineering; Rehabilitation	054QW	WOS:000238394700008	
J	Wang, H				Wang, H			Nearest neighbors by neighborhood counting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; machine learning; nearest neighbors; distance; similarity; neighborhood counting measure	CLASSIFICATION	Finding nearest neighbors is a general idea that underlies many artificial intelligence tasks, including machine learning, data mining, natural language understanding, and information retrieval. This idea is explicitly used in the k- nearest neighbors algorithm ( kNN), a popular classification method. In this paper, this idea is adopted in the development of a general methodology, neighborhood counting, for devising similarity functions. We turn our focus from neighbors to neighborhoods, a region in the data space covering the data point in question. To measure the similarity between two data points, we consider all neighborhoods that cover both data points. We propose to use the number of such neighborhoods as a measure of similarity. Neighborhood can be defined for different types of data in different ways. Here, we consider one definition of neighborhood for multivariate data and derive a formula for such similarity, called neighborhood counting measure or NCM. NCM was tested experimentally in the framework of kNN. Experiments show that NCM is generally comparable to VDM and its variants, the state- of- the- art distance functions for multivariate data, and, at the same time, is consistently better for relatively large k values. Additionally, NCM consistently outperforms HEOM ( a mixture of Euclidean and Hamming distances), the " standard" and most widely used distance function for multivariate data. NCM has a computational complexity in the same order as the standard Euclidean distance function and NCM is task independent and works for numerical and categorical data in a conceptually uniform way. The neighborhood counting methodology is proven sound for multivariate data experimentally. We hope it will work for other types of data.	Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland; Univ Metz, LITA, F-57045 Metz, France	Wang, H (reprint author), Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland.	h.wang@ulster.ac.uk	jia, lp/H-5750-2011				Ash R. B., 2000, PROBABILITY MEASURE; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Blake C. L., 1998, UCI REPOSITORY MACHI; Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1023/A:1022664626993; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DOMINGOS P, 1995, P 1995 INT JOINT C A; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; ELKAN C, 1999, RESULTS KDD 99 CLASS; Fix E., 1951, TR4 US AIR FORC SCH; Gardenfors P., 2000, CONCEPTUAL SPACES GE; Hand D., 2001, PRINCIPLES DATA MINI; HAYASHI H, 2001, OPTIMIZATION NEAREST; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; MITCHELL TM, 1997, MACHINE LEARING; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; OSBORNE H, 1997, P INT WORKSH SIM CAT, P173; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SNEDECOR GW, 2002, STAT METHODS; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STEVENS SS, 1951, MATH MEASUREMENT PSY; TOWELL GG, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P861; Wang H, 2004, INT J APPROX REASON, V36, P223, DOI 10.1016/j.ijar.2003.10.007; Widdows D., 2004, GEOMETRY MEANING; Wikipedia Foundation, WIK FREE ENC; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	29	38	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					942	953				12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	031WB	WOS:000236734400008	
J	Zhao, QF				Zhao, QF			Inducing NNC-Trees with the R-4-rule	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						decision trees; machine learning and understanding; nearest neighbor classifier; neural networks; NNC-trees; R-4-rule	NEIGHBOR PATTERN-CLASSIFICATION; FUZZY DECISION TREES; HIERARCHICAL-CLASSIFICATION; ALGORITHM; RULE; MLP	An NNC-Tree is a decision tree (DT) with each non-terminal node containing a nearest neighbor classifier (NNC). Compared with the conventional axis-parallel DTs (APDTs), the NNC-Trees can be more efficient, because the decision boundary made by an NNC is more complex than an axis-parallel hyperplane. Compared with single-layer NNCs, the NNC-Trees can classify given data in a hierarchical structure that is often useful for many applications. This paper proposes an algorithm for inducing NNC-Trees based on the R-4-rule, which was proposed by tine author for finding the smallest nearest neighbor based multilayer perceptrons (NN-MLPs). There are mainly two contributions here. 1) A heuristic but effective method is given to define the teacher signals (group labels) for the data assigned to each nonterminal node. 2) The R-4-rule is modified so that an NNC with proper size can be designed automatically in each nonterminal node. Experiments with several public databases show that the proposed algorithm can produce NNC-Trees effectively and efficiently.	Univ Aizu, Fukushima 9658580, Japan	Zhao, QF (reprint author), Univ Aizu, Fukushima 9658580, Japan.						Adams RG, 1999, NEURAL NETWORKS, V12, P541, DOI 10.1016/S0893-6080(99)00010-6; Basak J, 2004, NEURAL COMPUT, V16, P1959, DOI 10.1162/0899766041336396; Basak J, 2005, IEEE T KNOWL DATA EN, V17, P121, DOI 10.1109/TKDE.2005.11; Brieman L., 1984, CLASSIFICATION REGRE; Cantu-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GOLEA M, 1990, EUROPHYS LETT, V12, P105; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HENRICHO.EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Janikow CZ, 1998, IEEE T SYST MAN CY B, V28, P1, DOI 10.1109/3477.658573; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kearns MJ, 1994, INTRO COMPUTATIONAL; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LI T, 1993, NEUROCOMPUTING, V5, P119, DOI 10.1016/0925-2312(93)90032-X; LINDE Y, 1980, IEEE T COMMUN, V28, P1; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MIZUNO S, 2002, P IEEE INT C SYST MA, P239; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Suarez A, 1999, IEEE T PATTERN ANAL, V21, P1297, DOI 10.1109/34.817409; Takeda T, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P513; TAKEDA T, 2003, P INT C HYBR INT SYS, P107; Tsukimoto H, 2000, IEEE T NEURAL NETWOR, V11, P377, DOI 10.1109/72.839008; XU QZ, 2004, ON LINE J NEURO INF, V3, P77; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; ZHAO QF, 2004, P IEEE INT C SYST MA, P5702; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240	38	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	JUN	2006	36	3					520	533		10.1109/TSMCB.2005.861868		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	050EB	WOS:000238069200004	
J	Han, SJ; Cho, SB				Han, Sang-Jun; Cho, Sung-Bae			Evolutionary neural networks for anomaly detection based on the behavior of a program	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						anomaly detection; computer security; evolutionary algorithms; intrusion detection system (IDS); neural networks	INTRUSION DETECTION; SYSTEM	The process of learning the behavior of a given program by using machine-learning techniques (based on system-call audit data) is effective to detect intrusions. Rule learning, neural networks, statistics, and hidden Markov models (HMMs) are some of the kinds of representative methods for intrusion detection. Among them, neural networks are known for good performance in learning system-call sequences. In order to apply this knowledge to real-world problems successfully, it is important to determine the structures and weights of these call sequences. However, finding the appropriate structures requires very long time periods because there are no suitable analytical solutions. In this paper, a novel intrusion-detection technique based-on evolutionary neural networks (ENNs) is proposed. One advantage of using ENNs is that it takes less time to obtain superior neural networks than when using conventional approaches. This is because they discover the structures and weights of the neural networks simultaneously. Experimental results with the 1999 Defense Advanced Research Projects Agency (DARPA) Intrusion Detection Evaluation (IDEVAL) data confirm that ENNs are promising tools for intrusion detection.	Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea	Han, SJ (reprint author), Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.	sjhan@sclab.yonsei.ac.kr; sbcho@sclab.yonsei.ac.kr					Cho SB, 2002, IEEE T SYST MAN CY C, V32, P154, DOI 10.1109/TSMCC.2002.801356; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; Eskin E., 2001, Proceedings DARPA Information Survivability Conference and Exposition II. DISCEX'01, DOI 10.1109/DISCEX.2001.932213; Forrest S, 1997, COMMUN ACM, V40, P88, DOI 10.1145/262793.262811; Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675; GHOSH AK, 1999, P 8 USENIX SEC S WAS, P23; Ghosh AK, 1999, PROCEEDINGS OF THE WORKSHOP ON INTRUSION DETECTION AND NETWORK MONITORING (ID '99), P51; GHOSH AK, 2000, P 3 INT S REC ADV IN, P93; GONZALEZ F, 2003, P IEEE INT WORKSH IN, P251; HOFMANN A, 2003, P INT JOINT C NEUR N, V1, P415, DOI 10.1109/IJCNN.2003.1223382; Hofmeyr S. A., 1998, Journal of Computer Security, V6; HU W, 2003, P INT C MACH LEARN A, P168; KENDALL K, 1998, THESIS MIT CAMBRIDGE; Lee W., 1997, P AAAI97 WORKSH AI M, P50; Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X; Lippmann R., 2000, P DARPA INF SURV C E, P12; Lippmann R, 2000, COMPUT NETW, V34, P579, DOI 10.1016/S1389-1286(00)00139-0; Lunt T. F., 1993, Computers & Security, V12, DOI 10.1016/0167-4048(93)90029-5; MIT Lincoln Laboratory, DARPA INTR DET EV; WANG L, 2001, P ICII 2001 BEIJ 200, V5, P13; Warrender C, 1999, P IEEE S SECUR PRIV, P133, DOI 10.1109/SECPRI.1999.766910; Yao X, 1999, P IEEE, V87, P1423; Ye N, 2001, IEEE T SYST MAN CY A, V31, P266; *U NM, COMP IMM SYST DAT SE	25	26	32	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	JUN	2006	36	3					559	570		10.1109/TSMCB.2005.860136		12	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	050EB	WOS:000238069200007	
J	Littlewort, G; Bartlett, MS; Fasel, I; Susskind, J; Movellan, J				Littlewort, Gwen; Bartlett, Marian Stewart; Fasel, Ian; Susskind, Joshua; Movellan, Javier			Dynamics of facial expression extracted automatically from video	IMAGE AND VISION COMPUTING			English	Article						facial action coding; support vector machines; facial expression; Adaboost		We present a systematic comparison of machine learning methods applied to the problem of fully automatic recognition of facial expressions, including AdaBoost, support vector machines, and linear discriminant analysis. Each video-frame is first scanned in real-time to detect approximately upright-frontal faces. The faces found are scaled into image patches of equal size, convolved with a bank of Gabor energy filters, and then passed to a recognition engine that codes facial expressions into 7 dimensions in real time: neutral. anger. disgust, fear. joy, sadness, surprise. We report results on a series of experiments comparing spatial frequency ranges, feature selection techniques, and recognition engines. Best results were obtained by selecting a Subset of Gabor filters using AdaBoost and then training Support Vector Machines on the outputs of the filters selected by AdaBoost. The generalization performance to new Subjects for a 7-way forced choice was 93% or more correct on two publicly available datasets, the best performance reported so far oil these datasets. The Outputs Of the classifier change smoothly as a function of time and thus can be used for unobtrusive expression dynamics capture. We developed an end-to-end system that provides facial expression codes at 24 frames per second and animates a computer-generated character. In real-time this expression mirror operates down to resolutions of 16 pixels front eye to eye. We also applied the system to fully automated facial action coding. (c) 2005 Elsevier B.V. All rights reserved.	Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA	Littlewort, G (reprint author), Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA.	gwen@mplab.ucsd.edu					BARTLETT MS, 2001, AUTOMATIC ANAL SPONT; BARTLETT MS, 2001, KLUWER INT SERIES EN, V612; COHEN I, 2003, COMPUTER VISION PATT; Cristianini N., 2000, SUPPORT VECTOR MACHI; DAILEY MN, 2002, J COGNITIVE NEUROSCI, V14; DATCU D, 2004, P IEEE C SYST MAN CY; DEKEL O, 2003, ADV NEURAL INFORMATI, V15; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Ekman P., 1978, FACIAL ACTION CODING; EKMAN P., 1976, PICTURES FACIAL AFFE; FASEL IR, IN PRESS COMPUTER VI; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Friedman J, 1998, ADDITIVE LOGISTIC RE; HARPELED S, 2003, ADV NEURAL INFORMATI, V15; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), DOI 10.1109/AFGR.2000.840611; KAPOOR A, 2003, IEEE INT WORKSH AN M; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; LITTLEWORT G, ADV NEURAL INFORMATI, V16; Lyons M. J., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), DOI 10.1109/AFGR.2000.840635; MA JY, 2002, P ICSLP 2002; MARKS TK, CVPR04 WORKSH GEN MO; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Platt JC, 2000, ADV NEUR IN, V12, P547; Roth D, 2002, NEURAL COMPUT, V14, P1071, DOI 10.1162/089976602753633394; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Vapnik V. N, 1995, NATURE STAT LEARNING; VIOLA P, 2001, 2000101 CRL; WILHELM T, 2004, P IEEE C SYST MAN CY	29	65	66	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0262-8856		IMAGE VISION COMPUT	Image Vis. Comput.	JUN 1	2006	24	6					615	625		10.1016/j.imavis.2005.09.011		11	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	061NB	WOS:000238878200008	
J	Frias-Martinez, E; Magoulas, G; Chen, S; Macredie, R				Frias-Martinez, E; Magoulas, G; Chen, S; Macredie, R			Automated user modeling for personalized digital libraries	INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT			English	Article						digital libraries; user modeling; personalization; adaptive library services		Digital libraries (DLs) have become one of the most typical ways of accessing any kind of digitalized information. Due to this key role, users welcome any improvements on the services they receive from DLs. One trend used to improve digital services is through personalization. Up to now, the most common approach for personalization in DLs has been user driven. Nevertheless, the design of efficient personalized services has to be done, at least in part, in an automatic way. In this context, machine learning techniques automate the process of constructing user models. This paper proposes a new approach to construct DLs that satisfy a user's necessity for information: Adaptive DLs, libraries that automatically learn user preferences and goals and personalize their interaction using this information. (c) 2006 Elsevier Ltd. All rights reserved.	Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England; Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HX, England	Chen, S (reprint author), Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.	sherry.chen@brunel.ac.uk	Macredie, Robert/F-4928-2013	Macredie, Robert/0000-0001-5066-425X			Agrawal R., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; AIHARA K, 2001, P 8 INT C US MOD LNA, V2109, P207; ANGIULLI F, 1998, DATA MIN KNOWL DISC, V2, P263; BELKIN NJ, 1992, COMMUN ACM, V35, P29, DOI 10.1145/138859.138861; Bezdek J. C., 1981, PATTERN RECOGNITION; Billsus D., 1999, P 7 INT C US MOD, P99; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; Bollacker K.D., 1999, P 4 ACM C DIG LIB, P105, DOI 10.1145/313238.313270; BRUSILOVSKY P, 1997, P 6 INT C US MOD SAR, P177; Callan J., 2003, PERSONALIZATION RECO; CANDELA L, 2003, LCNS, V2924, P156; COHEN S, 2000, D LIB MAGAZINE, V6; CORNELIS B, 2003, THESIS U MAASTRICHT; COSTABILE MF, 1999, INT J DIGITAL LIB, V2, P124, DOI 10.1007/s007990050042; Cristianini N., 2000, INTRO SUPPORT VECTOR; DAVIDSON I, 2003, IEEE DAT MIN WORKSH; DIGIACOMO M, 2001, P 2 DELOS WORKSH PER; Fausett L., 1994, FUNDAMENTALS NEURAL; FERNANDEZ C, 1999, P 5 INT C INF SYST S, P37; FINK J, 1997, P US MOD 97 C NEW YO, P171; Ford N., 2000, Journal of Educational Multimedia and Hypermedia, V9; FRENCH CJ, 1999, D LIB MAGAZINE, V5; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Haykin S., 1999, NEURAL NETWORKS; HICKS DL, 2001, P 2 DELOS NETW EXC W, P56; Horvitz E., 1998, P 14 C UNC ART INT, P256; Jain A.K., 1988, ALGORITHMS CLUSTERIN; JAYAWARDANA C, 2001, J ACAD MEDIA LIB, V8; Kaski S., 1997, ACTA POLYTECHNICA SC, V82; Kobsa A, 2001, USER MODEL USER-ADAP, V11, P49, DOI 10.1023/A:1011187500863; Kohonen T., 1997, SPRINGER SERIES INFO, V30; Krishnapuram R, 2001, IEEE T FUZZY SYST, V9, P595, DOI 10.1109/91.940971; Langley P., 1993, P 13 INT JOINT C ART, P889; MAGOULAS G, 2003, BRIT J EDUC TECHNOL, V34, P1; Manber U, 2000, COMMUN ACM, V43, P35, DOI 10.1145/345124.345136; MARTIN JK, 1995, ICSTR9527 U CAL IRV; McKeown K. R., 2003, Proceedings 2003 Joint Conference on Digital Libraries; Mitchell T, 1997, MACHINE LEARNING; Montaner M, 2003, ARTIF INTELL REV, V19, P285, DOI 10.1023/A:1022850703159; NANOPOULOS A, 2001, LECT NOTES ARTIF INT, V2356, P48; PALIOURAS G, 1999, P 7 INT C US MOD UM, P169; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; Ramsey MC, 1999, J AM SOC INFORM SCI, V50, P826, DOI 10.1002/(SICI)1097-4571(1999)50:9<826::AID-ASI11>3.3.CO;2-8; RAUBER A, 1999, P 4 ACM C DIG LIB DL, P240, DOI 10.1145/313238.313412; Riecken D, 2000, COMMUN ACM, V43, P27; RUVINI J, 2003, P 8 INT C INT US INT, P284; Sarukkai RR, 2000, COMPUT NETW, V33, P377, DOI 10.1016/S1389-1286(00)00044-X; SEMERARO G, 1999, P ACAI 99 WORKSH MAC, P21; Semeraro G, 2001, LECT NOTES ARTIF INT, V2109, P44; SEMERARO G, 2000, P 1 DELOS NETW EXC W, P135; SHEPERD A, 2002, P 35 ANN HAW INT C S, V4, P102; Theng YL, 1999, LECT NOTES COMPUT SC, V1696, P167; TSUKADA M, 2001, LECT NOTES ARTIF INT, V2198, P303; Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175; WIDYANTORO DH, 1999, THESIS TEXAS A M U; WINSTON PH, 1992, ARTIF INTELL, P423; WINTER K, 1999, AM LIB, V30, P57; Witten I. H., 1999, DATA MINING PRACTICA; ZHANG X, 2003, MLIRUM 03 2 WORKSH M, P1; Zukerman I., 1999, P 7 INT C US MOD UM, P275; *ARIADNE, 2004, ARIADNE STRAT WHIT P; *GREENST, 2005, GREENST PROJ HOM PAG; 2005, DUBLIN CORE METADATA; 2004, SCIRUS WORK SCIRUS W	65	15	15	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0268-4012		INT J INFORM MANAGE	Int. J. Inf. Manage.	JUN	2006	26	3					234	248		10.1016/j.ijinfomgt.2006.02.006		15	Information Science & Library Science	Information Science & Library Science	057JG	WOS:000238591500006	
J	Lin, XF; Xiong, Y				Lin, Xiaofan; Xiong, Yan			Detection and analysis of table of contents based on content association	INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION			English	Article; Proceedings Paper	3rd International Workshop on Document Layout Interpretation and its Applications (DLIA 2003)	AUG   02, 2003	Edinburgh, SCOTLAND			table of contents; document structure analysis; table recognition; optical character recognition; algorithm combination		As a special type of table understanding, the detection and analysis of tables of contents (TOCs) play an important role in the digitization of multi-page documents. Most previous TOC analysis methods only concentrate on the TOC itself without taking into account the other pages in the same document. Besides, they often require manual coding or at least machine learning of document-specific models. This paper introduces a new method to detect and analyze TOCs based on content association. It fully leverages the text information throughout the whole multi-page document and can be directly applied to a wide range of documents without the need to build or learn the models for individual documents. In addition, the associations of general text and page numbers are combined to make the TOC analysis more accurate. Natural language processing and layout analysis are integrated to improve the TOC functional tagging. The applications of the proposed method in a large-scale digital library project are also discussed.	Hewlett Packard Labs, Palo Alto, CA 94304 USA; KLA Tencor Corp, Milpitas, CA 95035 USA	Lin, XF (reprint author), Hewlett Packard Labs, 1501 Page Mill Rd,MS 1203, Palo Alto, CA 94304 USA.	xiaofan.lin@hp.com; yan.xiong@kla-tencor.com					ALLISON L, 1991, INFORM PROCESS LETT, V40, P317, DOI 10.1016/0020-0190(91)90200-2; Belaid A., 2001, International Journal on Document Analysis and Recognition, V4, DOI 10.1007/PL00013572; HE F, 2004, P SPIE C DOC REC RET, V9, P6; HU J, 2000, SPIE DOCUMENT RECOGN, V7, P291; Le Bourgeois F., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, DOI 10.1109/ICDAR.2001.953841; Lin CC, 1997, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, P1048; LIN X, 2002, P SPIE C DOC REC RET, V9, P223; LIN X, 2003, P INT C DOC AN REC 2, P284; LIN X, 2003, P 7 INT C DOC AN REC, P1075; LIN XF, 2004, P SPIE C DOC REC RET, V11, P66; LUO Q, 1996, P 13 INT C PATT REC, V3, P696; Mandal S., 2003, Proceedings Seventh International Conference on Document Analysis and Recognition; MYERS G, 1999, IEEE COMPUTATIONAL B, P33; Satoh S., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, DOI 10.1109/ICDAR.1995.598967; Simske S., 2004, Proceedings. First Workshop on Document Image Analysis for Libraries; STORY GA, 1992, IEEE COMPUT      SEP, P17; TSURUOKA S, 2001, WORKSH DOC LAYOUT IN; WANG Y, 2002, P 5 INT WORKSH DAS 2, V5, P272; Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290956	19	5	6	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1433-2833		INT J DOC ANAL RECOG	Int. J. Doc. Anal. Recognit.	JUN	2006	8	2-3					132	143		10.1007/s10032-005-0149-4		12	Computer Science, Artificial Intelligence	Computer Science	185TY	WOS:000247734500006	
J	Drake, JM; Randin, C; Guisan, A				Drake, John M.; Randin, Christophe; Guisan, Antoine			Modelling ecological niches with support vector machines	JOURNAL OF APPLIED ECOLOGY			English	Article						ecological modelling; habitat; presence-only data; species distribution	HABITAT-SUITABILITY; SPECIES DISTRIBUTION; LEARNING ALGORITHMS; ABSENCE DATA; CLIMATE; DISTRIBUTIONS; PREDICTION; REGRESSION; VEGETATION; SELECTION	1. The ecological niche is a fundamental biological concept. Modelling species' niches is central to numerous ecological applications, including predicting species invasions, identifying reservoirs for disease, nature reserve design and forecasting the effects of anthropogenic and natural climate change on species' ranges. 2. A computational analogue of Hutchinson's ecological niche concept (the multidimensional hyperspace of species' environmental requirements) is the support of the distribution of environments in which the species persist. Recently developed machine-learning algorithms can estimate the support of such high-dimensional distributions. We show how support vector machines can be used to map ecological niches using only observations of species presence to train distribution models for 106 species of woody plants and trees in a montane environment using up to nine environmental covariates. 3. We compared the accuracy of three methods that differ in their approaches to reducing model complexity. We tested models with independent observations of both species presence and species absence. We found that the simplest procedure, which uses all available variables and no pre-processing to reduce correlation, was best overall. Ecological niche models based on support vector machines are theoretically superior to models that rely on simulating pseudo-absence data and are comparable in empirical tests. 4. Synthesis and applications. Accurate species distribution models are crucial for effective environmental planning, management and conservation, and for unravelling the role of the environment in human health and welfare. Models based on distribution estimation rather than classification overcome theoretical and practical obstacles that pervade species distribution modelling. In particular, ecological niche models based on machine-learning algorithms for estimating the support of a statistical distribution provide a promising new approach to identifying species' potential distributions and to project changes in these distributions as a result of climate change, land use and landscape alteration.	Natl Ctr Ecol Anal & Synthesis, Santa Barbara, CA 93101 USA; Univ Lausanne, Dept Ecol & Evolut, CH-1501 Lausanne, Switzerland	Drake, JM (reprint author), Natl Ctr Ecol Anal & Synthesis, 735 State St,Suite 300, Santa Barbara, CA 93101 USA.	drake@nceas.ucsb.edu	Drake, John/D-6622-2012				Anderson RP, 2003, ECOL MODEL, V162, P211, DOI 10.1016/S0304-3800(02)00349-6; Augustin NH, 1996, J APPL ECOL, V33, P339, DOI 10.2307/2404755; Boyce MS, 2002, ECOL MODEL, V157, P281, DOI 10.1016/S0304-3800(02)00200-4; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Brotons L, 2004, ECOGRAPHY, V27, P437, DOI 10.1111/j.0906-7590.2004.03764.x; Dirnbock T, 2003, J BIOGEOGR, V30, P401; Drake JM, 2004, BIOSCIENCE, V54, P931, DOI 10.1641/0006-3568(2004)054[0931:TPDOZM]2.0.CO;2; Duin R.P.W., 2004, PRTOOLS4 MATLAB TOOL; Engler R, 2004, J APPL ECOL, V41, P263, DOI 10.1111/j.0021-8901.2004.00881.x; Ferrier S, 2002, SYST BIOL, V51, P331, DOI 10.1080/10635150252899806; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Graham CH, 2004, EVOLUTION, V58, P1781, DOI 10.1554/03-274; Guisan A, 2005, ECOL LETT, V8, P993, DOI 10.1111/j.1461-0248.2005.00792.x; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; Guo QH, 2005, ECOL MODEL, V182, P75, DOI 10.1016/j.ecolmodel.2004.07.012; Gurtz J, 2003, HYDROL PROCESS, V17, P297, DOI 10.1002/hyp.1125; He FL, 2003, J AGRIC BIOL ENVIR S, V8, P205, DOI 10.1198/1085711031508; Hirzel A, 2002, ECOL MODEL, V157, P331, DOI 10.1016/S0304-3800(02)00203-X; Hirzel AH, 2002, ECOLOGY, V83, P2027, DOI 10.1890/0012-9658(2002)083[2027:ENFAHT]2.0.CO;2; HUTCHINSON GE, 1957, COLD SPRING HARB SYM, V22, P415; Keating KA, 2004, J WILDLIFE MANAGE, V68, P774, DOI 10.2193/0022-541X(2004)068[0774:UAIOLR]2.0.CO;2; Korner C., 2003, ALPINE PLANT LIFE; Kumar L, 1997, INT J GEOGR INF SCI, V11, P475, DOI 10.1080/136588197242266; Leathwick JR, 2001, ECOLOGY, V82, P2560, DOI 10.1890/0012-9658(2001)082[2560:CIBTSI]2.0.CO;2; Lusk JJ, 2002, PREDICTING SPECIES OCCURRENCES: ISSUES OF ACCURACY AND SCALE, P345; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Pearson RG, 2002, ECOL MODEL, V154, P289, DOI 10.1016/S0304-3800(02)00056-X; Peterson AT, 2003, Q REV BIOL, V78, P419, DOI 10.1086/378926; Peterson AT, 2002, EMERG INFECT DIS, V8, P662; Phillips SJ, 2004, P 21 INT C MACH LEAR; RANDIN C, IN PRESS J BIOGEOGRA; Robertson M. P., 2001, Diversity and Distributions, V7, P15, DOI 10.1046/j.1472-4642.2001.00094.x; Schoener T.W., 1989, P79; Scholkopf B., 2001, LEARNING KERNELS SUP; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scott J.M., 2002, PREDICTING SPECIES O; Stockwell D, 1999, INT J GEOGR INF SCI, V13, P143, DOI 10.1080/136588199241391; Stockwell DRB, 2002, ECOL MODEL, V148, P1, DOI 10.1016/S0304-3800(01)00388-X; Tax D., 2001, THESIS DELFT U TECHN; Tax DMJ, 2003, INT J PATTERN RECOGN, V17, P333, DOI 10.1142/S021800140300240X; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tax DMJ, 2004, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2004.1334542; TAX DMJ, 2005, DAT DESCR TOOLB MAN; Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121; Zaniewski AE, 2002, ECOL MODEL, V157, P261, DOI 10.1016/S0304-3800(02)00199-0; Zimmermann NE, 1999, J VEG SCI, V10, P469, DOI 10.2307/3237182; *ENV SYST RES I IN, 2004, ARCINFO VERS 9 0	47	52	53	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0021-8901		J APPL ECOL	J. Appl. Ecol.	JUN	2006	43	3					424	432		10.1111/j.1365-2664.2006.01141.x		9	Ecology	Environmental Sciences & Ecology	042GT	WOS:000237516600005	
J	Meinshausen, N				Meinshausen, Nicolai			Quantile regression forests	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						quantile regression; random forests; adaptive neighborhood regression	TREES	Random forests were introduced as a machine learning tool in Breiman (2001) and have since proven to be very popular and powerful for high-dimensional regression and classification. For regression, random forests give an accurate approximation of the conditional mean of a response variable. It is shown here that random forests provide information about the full conditional distribution of the response variable, not only about the conditional mean. Conditional quantiles can be inferred with quantile regression forests, a generalisation of random forests. Quantile regression forests give a non-parametric and accurate way of estimating conditional quantiles for high-dimensional predictor variables. The algorithm is shown to be consistent. Numerical examples suggest that the algorithm is competitive in terms of predictive power.	ETH, Seminar Stat, CH-8092 Zurich, Switzerland	Meinshausen, N (reprint author), ETH, Seminar Stat, CH-8092 Zurich, Switzerland.	nicolai@stat.math.ethz.ch					Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Barnett V, 1994, OUTLIERS STAT DATA; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 2004, 670 U CAL DEP STAT; Chaudhuri P, 2002, BERNOULLI, V8, P561; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; HE X, 1998, J ROYAL STAT SOC B, V3, P537; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9; HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503; Hyndman RJ, 1996, AM STAT, V50, P361, DOI 10.2307/2684934; Koenker R., 2005, QUANTILE REGRESSION; KOENKER R, 1994, BIOMETRIKA, V81, P673, DOI 10.1093/biomet/81.4.673; LE QV, 2005, NONPARAMETRIC QUANTI; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; LIN Y, 2002, 1055 U WISC DEP STAT; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI [10.1016/j.sigpro.2003.07.018, 10.1016/j.sigpro.2003.018]; Portnoy S, 1997, STAT SCI, V12, P279; R DEVELOPMENT CORE TEAM, 2005, R LANG ENV STAT COMP; Schapire RE, 1998, ANN STAT, V26, P1651; Steinwart I, 2005, J MACH LEARN RES, V6, P211; Weisberg S, 2005, APPL LINEAR REGRESSI	23	28	28	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2006	7						983	999				17	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152UV	WOS:000245388400004	
J	Du, XJ				Du, Xiaojiang			Identifying control and management plane poison message failure by K-nearest neighbor method	JOURNAL OF NETWORK AND SYSTEMS MANAGEMENT			English	Article						fault management; fault diagnosis; poison message failure; K-nearest neighbor method		Poison message failure is a mechanism that has been responsible for large-scale failures in both telecommunications and IP networks. The poison message failure can propagate in the network and cause unstable network. In this paper, we apply machine learning, data mining technique in network fault management area. We use k-nearest neighbor method to identify the poison message failure. Also we integrate the k-nearest neighbor method with message filtering approach. We also propose a "probabilistic" k-nearest neighbor method that outputs a probability distribution (rather than the identity) of the poison message. Through extensive simulations, we show that k-nearest neighbor method is very effective in identifying the responsible message type.	N Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA	Du, XJ (reprint author), N Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA.	xiaojiang.du@ndsu.edu					Bramer M. A., 1999, KNOWLEDGE DISCOVERY; DOSSANTOS AL, 2004, J NETWORK SYSTEMS MA, V12; DU X, 2003, P C INF SCI SYST CIS; DU X, 2003, P 8 IFIP IEEE INT S; DU X, 2002, P IEEE MILCOM 2002 A; Freitas A., 2002, DATA MINING KNOWLEDG; HOUCK DJ, 1994, P 14 INT TEL C AMST, P367; HUNG NL, 1994, IEEE J SEL AREA COMM, V12, P533, DOI 10.1109/49.285295; KOUTEPAS G, 2004, J NETWORK SYSTEMS MA, V12; LABOVITZ C, 1997, P ACM SIGCOMM NIC FR; Mitchell T, 1997, MACHINE LEARNING; MOORE A, 1992, ADV NEURAL INFORMATI; MOORE AW, 1994, COMPUTATIONAL LEARNI, V3; NILSSON N, INTRO MACHINE LEARNI; RAZ D, 2001, J NETWORK SYSTEM SEP; SWEENY T, 1999, TECH WEB        0812; TANG Y, 2005, P 9 IFIP IEEE INT S; YOSHIHARA K, 2003, P 8 IFIP IEEE INT S; ZHANG Z, 2002, ASS RULE MINING	19	3	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1064-7570		J NETW SYST MANAG	J. Netw. Syst. Manag.	JUN	2006	14	2					243	259		10.1007/s10922-006-9027-8		17	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	112NL	WOS:000242533000005	
J	Rezaei, S; Tavakolian, K; Nasrabadi, AM; Setarehdan, SK				Rezaei, Siamak; Tavakolian, Kouhyar; Nasrabadi, Ali Moti; Setarehdan, S. Kamaledin			Different classification techniques considering brain computer interface applications	JOURNAL OF NEURAL ENGINEERING			English	Article							COMMUNICATION	In this work the application of different machine learning techniques for classification of mental tasks from electroencephalograph (EEG) signals is investigated. The main application for this research is the improvement of brain computer interface (BCI) systems. For this purpose, Bayesian graphical network, neural network, Bayesian quadratic, Fisher linear and hidden Markov model classifiers are applied to two known EEG datasets in the BCI field. The Bayesian network classifier is used for the first time in this work for classification of EEG signals. The Bayesian network appeared to have a significant accuracy and more consistent classification compared to the other four methods. In addition to classical correct classification accuracy criteria, the mutual information is also used to compare the classification results with other BCI groups.	Univ No British Columbia, Prince George, BC V2L 5P2, Canada; Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada; Shahed Univ, Tehran, Iran; Univ Tehran, Fac Elect & Comp Engn, Control & Intelligent Proc Ctr Excellence, Tehran 14174, Iran	Rezaei, S (reprint author), Univ No British Columbia, Prince George, BC V2L 5P2, Canada.	ktavakol@sfu.ca					Huan Nai-Jen, 2004, J Neural Eng, V1, P142, DOI 10.1088/1741-2560/1/3/003; JENSEN F, 2001, BAYESIAN NETWORKS DE; KEIRN ZA, 1990, IEEE T BIO-MED ENG, V37, P1209, DOI 10.1109/10.64464; LEHTONEN J, 2002, THESIS HELSINKI U TE; McFarland DJ, 2005, CLIN NEUROPHYSIOL, V116, P56, DOI 10.1016/j.clinph.2004.07.004; Moon T. K., 2000, MATH METHODS ALGORIT; Murphy K. P., BAYES NET TOOLBOX MA; Qin Lei, 2004, J Neural Eng, V1, P135, DOI 10.1088/1741-2560/1/3/002; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; TAVAKOLIAN K, 2003, THESIS U TEHRAN IRAN; TAVAKOLIAN K, 2004, P IEEE INT S CIRC SY, P537; TAVAKOLIAN K, 2005, THESIS U NO BRIT COL; TAVAKOLIAN K, 2004, IEEE INT WORKSH BIOM; Theodoridis S, 1999, PATTERN RECOGNITION; Wang T, 2004, CLIN NEUROPHYSIOL, V115, P2744, DOI 10.1016/j.clinph.2004.06.022; Webb A., 1999, STAT PATTERN RECOGNI; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	17	12	13	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	1741-2560		J NEURAL ENG	J. Neural Eng.	JUN	2006	3	2					139	144		10.1088/1741-2560/3/2/008		6	Engineering, Biomedical; Neurosciences	Engineering; Neurosciences & Neurology	072KY	WOS:000239673500008	
J	Kim, SP; Sanchez, JC; Rao, YN; Erdogmus, D; Carmena, JM; Lebedev, MA; Nicolelis, MAL; Principe, JC				Kim, S-P; Sanchez, J. C.; Rao, Y. N.; Erdogmus, D.; Carmena, J. M.; Lebedev, M. A.; Nicolelis, M. A. L.; Principe, J. C.			A comparison of optimal MIMO linear and nonlinear models for brain-machine interfaces	JOURNAL OF NEURAL ENGINEERING			English	Article							PARTIAL LEAST-SQUARES; CORTICAL CONTROL; NEUROPROSTHETIC DEVICES; MOTOR CORTEX; REGRESSION; NEURONS; PROSTHETICS; POPULATION; EXTRACTION; PREDICTION	The field of brain-machine interfaces requires the estimation of a mapping from spike trains collected in motor cortex areas to the hand kinematics of the behaving animal. This paper presents a systematic investigation of several linear (Wiener filter, LMS adaptive filters, gamma filter, subspace Wiener filters) and nonlinear models (time-delay neural network and local linear switching models) applied to datasets from two experiments in monkeys performing motor tasks (reaching for food and target hitting). Ensembles of 100-200 cortical neurons were simultaneously recorded in these experiments, and even larger neuronal samples are anticipated in the future. Due to the large size of the models (thousands of parameters), the major issue studied was the generalization performance. Every parameter of the models (not only the weights) was selected optimally using signal processing and machine learning techniques. The models were also compared statistically with respect to the Wiener filter as the baseline. Each of the optimization procedures produced improvements over that baseline for either one of the two datasets or both.	Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA; Univ Florida, Dept Pediat, Div Neurol, Gainesville, FL 32611 USA; Motorola Inc, Plantation, FL 33322 USA; Oregon Hlth & Sci Univ, Dept Comp Sci, Beaverton, OR 97006 USA; Oregon Hlth & Sci Univ, Dept Biomed Engn, Beaverton, OR 97006 USA; Duke Univ, Dept Neurobiol, Durham, NC 27710 USA; Duke Univ, Ctr Neuroengn, Durham, NC 27710 USA	Kim, SP (reprint author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.	phil@cnel.ufl.edu	Erdogmus, Deniz/A-8170-2009				Bishop C.M., 1995, NEURAL NETWORKS PATT, P371; Carmena JM, 2003, PLOS BIOL, V1, P193, DOI 10.1371/journal.pbio.0000042; Chapin JK, 1999, NAT NEUROSCI, V2, P664, DOI 10.1038/10223; Cover TM, 1991, ELEMENTS INFORMATION, P12; DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X; FANCOURT C, 1997, P ICASSP, V4, P3325; Gage Gregory J, 2005, J Neural Eng, V2, P52, DOI 10.1088/1741-2560/2/2/006; GAO Y, 2002, ADV NEURAL INFORMATI, V14, P221; GEISSER S, 1975, J AM STAT ASSOC, V70, P320, DOI 10.2307/2285815; Gentle JE, 1998, NUMERICAL LINEAR ALG, P93; GEORGOPOULOS AP, 1988, J NEUROSCI, V8, P2928; HAYKIN S, 1996, ADAPTIVE FILTER THEO, P194; HAYKIN S, 1996, NEURAL NETWORKS COMP, P156; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Kennedy PR, 2000, IEEE T REHABIL ENG, V8, P198, DOI 10.1109/86.847815; Kim SP, 2003, NEURAL NETWORKS, V16, P865, DOI 10.1016/S0893-6080(03)00108-4; KIM SP, 2003, P IEEE INT C AC SPEE, V6, P312; Larsen J, 1998, LECT NOTES COMPUT SC, V1524, P113; Lewicki MS, 1998, NETWORK-COMP NEURAL, V9, pR53, DOI 10.1088/0954-898X/9/4/001; Moran DW, 1999, J NEUROPHYSIOL, V82, P2676; Musallam S, 2004, SCIENCE, V305, P258, DOI 10.1126/science.1097938; Neal R. M., 1996, BAYESIAN LEARNING NE, P29; Nicolelis MAL, 2003, P NATL ACAD SCI USA, V100, P11041, DOI 10.1073/pnas.1934665100; PRINCIPE JC, 1993, IEEE T SIGNAL PROCES, V41, P649, DOI 10.1109/78.193206; Sanchez J. C., 2004, THESIS U FLORIDA GAI; Sanchez JC, 2004, IEEE T BIO-MED ENG, V51, P943, DOI 10.1109/TBME.2004.827061; SANCHEZ JC, 2003, P IEEE EMBS NEUR ENG, P59; Schwartz AB, 2001, CURR OPIN NEUROBIOL, V11, P701, DOI 10.1016/S0959-4388(01)00272-0; Serruya MD, 2002, NATURE, V416, P141, DOI 10.1038/416141a; STONE M, 1990, J ROY STAT SOC B MET, V52, P237; Taylor DM, 2003, IEEE T NEUR SYS REH, V11, P195, DOI 10.1109/TNSRE.2003.814451; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; Tillery SIH, 2003, REV NEUROSCIENCE, V14, P107; Wessberg J, 2000, NATURE, V408, P361; WOOD F, P IEEE SHANGHAI CHIN, P1544; Wood F, 2004, IEEE T BIO-MED ENG, V51, P912, DOI 10.1109/TBME.2004.826677; Wu W, 2006, NEURAL COMPUT, V18, P80, DOI 10.1162/089976606774841585; Wu W, 2003, ADV NEURAL INFORMATI, P133	39	39	39	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1741-2560		J NEURAL ENG	J. Neural Eng.	JUN	2006	3	2					145	161		10.1088/1741-2560/3/2/009		17	Engineering, Biomedical; Neurosciences	Engineering; Neurosciences & Neurology	072KY	WOS:000239673500009	
J	Duwairi, RM				Duwairi, Rehab M.			Machine learning for Arabic text categorization	JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article							DOCUMENT CATEGORIZATION	In this article we propose a distance-based classifier for categorizing Arabic text. Each category is represented as a vector of words in an m-dimensional space, and documents are classified on the basis of their closeness to feature vectors of categories. The classifier, in its learning phase, scans the set of training documents to extract features of categories that capture inherent category-specific properties; in its testing phase the classifier uses previously determined category-specific features to categorize unclassified documents. Stemming was used to reduce the dimensionality of feature vectors of documents. The accuracy of the classifier was tested by carrying out several categorization tasks on an in-house collected Arabic corpus. The results show that the proposed classifier is very accurate and robust.	Jordan Univ Sci & Technol, Dept Comp Informat Syst, Irbid, Jordan	Duwairi, RM (reprint author), Jordan Univ Sci & Technol, Dept Comp Informat Syst, POB 3030, Irbid, Jordan.	rehab@just.edu.jo					ALMUBAID H, 2003, INT AR C INF TECHN A; ALSHALABI R, 1998, WORKSH SEM LANG PROC; Al-Shalabi R, 2003, INT AR C INF TECHN; Dumais S, 1998, 7 INT C INF KNOWL MA, P148; Eldos T. M., 2003, International Journal of Modelling and Simulation, V23; ELKOURDI M, 2004, WORKSH COMP APPR AR; ELSADANY TA, 1989, IBM SYST J, V28, P600; EYHERAMENDY S, 2003, ART INT STAT C KEY W; Ganesan P, 2003, ACM T INFORM SYST, V21, P64, DOI 10.1145/635484.635487; GHEITH M, 1987, AR MORPH WORKSH STAN; He J, 2003, APPL INTELL, V18, P311, DOI 10.1023/A:1023202221875; HILAL Y, 1990, AR LANG PROC US COMP; Lam W, 2003, IEEE T PATTERN ANAL, V25, P628; LEWIS DD, 1995, 18 ACM INT C RES DEV, P246; LI T, 2003, CIKM 03 C NEW ORL LA; MERETAKIS D, 2000, 9 ACM INT C INF KNOW; Peng FC, 2004, INFORM RETRIEVAL, V7, P317, DOI 10.1023/B:INRT.0000011209.19643.e2; RAHAL I, 2004, ACM S APPL COMP NIC; Ruiz ME, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P281; SAWAF H, 2001, AR NAT LANG PROC WOR; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Tsay JJ, 2004, INFORM PROCESS MANAG, V40, P223, DOI 10.1016/S0306-4573(02)00089-4	22	10	10	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1532-2882		J AM SOC INF SCI TEC	J. Am. Soc. Inf. Sci. Technol.	JUN	2006	57	8					1005	1010		10.1002/asi.20360		6	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	049GW	WOS:000238005200002	
J	Schatzmann, J; Weilhammer, K; Stuttle, M; Young, S				Schatzmann, Jost; Weilhammer, Karl; Stuttle, Matt; Young, Steve			A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies	KNOWLEDGE ENGINEERING REVIEW			English	Review							SYSTEMS; SELECTION; MODELS	Within the broad field of spoken dialogue systems, the application of machine-learning approaches to dialogue management strategy design is a rapidly growing research area. The main motivation is the hope of building systems that learn through trial-and-error interaction what constitutes a good dialogue strategy. Training of such systems could in theory be done using human users or using corpora of human-computer dialogue, but in practice the typically vast space of possible dialogue states and strategies cannot be explored without the use of automatic user simulation tools. This requirement for training statistical dialogue models has created an interesting new application area for predictive statistical user modelling and a variety of different techniques for simulating user behaviour have been presented in the literature ranging from simple Markov models to Bayesian networks. The development of reliable user simulation tools is critical to further progress on automatic dialogue management design but it holds many challenges, some of which have been encountered in other areas of current research on statistical user modelling, such as the problem of 'concept drift', the problem of combining content-based and collaboration-based modelling techniques, and user model evaluation. The latter topic is of particular interest, because simulation-based learning is currently one of the few applications of statistical user modelling that employs both direct 'accuracy-based' and indirect 'utility-based' evaluation techniques. In this paper, we briefly summarize the role of the dialogue manager in a spoken dialogue system, give a short introduction to reinforcement-learning of dialogue management strategies and review the literature on user modelling for simulation-based strategy learning. We further describe recent work on user model evaluation and discuss some of the current research issues in simulation-based learning from a user modelling perspective.	Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Schatzmann, J (reprint author), Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.	js532@eng.cam.ac.uk; kw278@eng.cam.ac.uk; mns25@eng.cam.ac.uk; sjy@eng.cam.ac.uk					Alspector J, 1997, USER MODEL USER-ADAP, V7, P279, DOI 10.1023/A:1008286413827; ARAKI M, 1997, P IJCAI WORKSH COLL, P13; AUST H, 1995, SPEECH COMMUN, V17, P249, DOI 10.1016/0167-6393(95)00028-M; Bernsen NO, 1998, DESIGNING INTERACTIV; Bernsen N. O., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607465; BERTHOLD A, 1999, P 7 INT C US MOD, P235; BESTAVROS A, 1996, P 1996 INT C DAT ENG; BIERMANN W, 1996, P INT S SPOK DIAL, P97; BILLSUS D, 1995, USER MODELING, P99; BINSTED K, 1995, P AIME, P29; BOHUS D, 2005, P ASRU SAN JUAN PERT; BOHUS D, 2005, P SIGDIAL LISB PORT; BOHUS D, 2004, THESIS CMU; BONTCHEVA K, 2005, LECT NOTES ARTIFICIA, V2109; Bos J., 2003; BRETIER P, 1996, P ATAL SAPP JAP, P189; BUNT H, 1981, 16 IPO, P99; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Carberry S, 1999, COMPUT LINGUIST, V25, P1; Carbone M, 2001, SEMIN CANCER BIOL, V11, P1, DOI 10.1006/scbi.2000.0340; Chiu BC, 1998, USER MODEL USER-ADAP, V8, P131; CUAYAHUITL H, 2005, P IEEE WORKSH AUT SP; Denecke M., 2004, P INTERSPEECH 2004, P325; Devillers L., 1998, P ICSLP, P1187; DOLS FJ, 1992, P 3 INT WORKSH US MO, P3; Eckert W., 1998, TR9891 ATT LABS RES; Eckert W., 1997, P IEEE WORKSH AUT SP, P80; ELZER S, 1994, P 4 INT C US MOD, P19; FILISKO E, 2005, P 6 SIGDIAL WORKSH D; FLEMING M, 2001, P 8 INT C US MOD UM2; GEORGILA K, 2005, P DIALOR; GEORGILA K, 2005, P 9 EUR C SPEECH COM; Gervasio M. T., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Ghahramani Z., 2004, ADV LECT MACHINE LEA; GLASS J, 1999, P 1999 IEEE ASRU WOR; GODDEAU D, 2000, IEEE C AC SPEECH SIG; Gorin A. L., 1996, Proceedings. Third IEEE Workshop on Interactive Voice Technology for Telecommunications Applications. IVTTA-96 (Cat. No.96TH8178), DOI 10.1109/IVTTA.1996.552741; Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X; Guinn CI, 1998, USER MODEL USER-ADAP, V8, P255, DOI 10.1023/A:1008359330641; GURSTON PJ, 2001, P EUR; HARVEY T, 2005, P 10 INT C US MOD UM; HENDERSON J, 2005, P IJCAI WORKSH KRPDS; Horvitz E., 1998, P 14 C UNC ART INT, P256; HUSTADT U, 1994, P 4 INT C US MOD, P87; Ishizaki M, 1999, USER MODEL USER-ADAP, V9, P79, DOI 10.1023/A:1008347908548; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; Jones K.S., 1996, EVALUATING NATURAL L; JURAFSKY D, 1994, P INT C SPOK LANG PR, P2139; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; KAMM C, 1995, VOICE COMMUNICATION; Keeney R.L., 1976, DECISIONS MULTIPLE O; KLINKENBERG R, 1998, AAAI ICML 98 WORKSH; KOMATANI K, 2003, P 41 ANN M ACL SAPP; Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450; Levin E., 1997, P EUR 97 RHOD GREEC, P1883; Lieberman H, 1995, P INT JOINT C ART IN, V1, P924; Lin BS, 2001, IEEE T SPEECH AUDI P, V9, P534; LITMAN D, 2000, P 18 INT C COMP LING; LITMAN DJ, 1999, P 7 INT C US MOD; Lopez-Cozar R, 2003, SPEECH COMMUN, V40, P387, DOI [10.1016/S0167-6393(02)00126-7, 10.1016/S0167-6393902)00126-7]; MOORE RC, 1977, IJCAI 77, P223; NIIMI Y, 1999, P EUR 99, P1535; Pieraccini R, 2004, COMMUN ACM, V47, P47, DOI 10.1145/962081.962104; PIETQUIN O, 2005, P 9 EUR C SPEECH COM; PIETQUIN O, 2005, IEEE T SPEECH AUDIO; PIETQUIN O, 2005, P 5 IEEE INT C MULT; Pietquin O., 2004, THESIS FACULTE POLYT; Polifroni J., 1992, P DARPA SPEECH NAT L, P28, DOI 10.3115/1075527.1075533; POTJER J, 1996, IEEE 3 WORKSH INT VO, P89; Rabiner L, 1993, FUNDAMENTALS SPEECH; Raskutti B, 1997, USER MODEL USER-ADAP, V7, P179, DOI 10.1023/A:1008291330418; Resnick P., 1997, COMMUN ACM, V40; ROSSET S, 1999, P EUR, P1535; RUDNICKY A, 1999, P EUR, V4, P1531; Russell S., 1995, ARTIFICIAL INTELLIGE; SCHATZMANN J, 2005, P ASRU 2005 SAN JUAN; SCHATZMANN J, 2005, P 6 SIGDIAL WORKSH D; SCHEFFLER K, 1999, 355 CUEDFINFENGTR CA; SCHEFFLER K, 2000, P INT C AC SPEECH SI, P1217; Scheffler K., 2002, P 2 INT C HUM LANG T, P12, DOI 10.3115/1289189.1289246; SCHEFFLER K, 2002, THESIS CAMBRIDGE U; Scheffler K, 2001, P NAACL WORKSH AD DI, P64; Searle John R., 1969, SPEECH ACTS ESSAY PH; Seneff S., 1998, P ICSLP, P931; SHIN J, 2002, P ICSLP; SIMPSON A, 1993, P 3 EUR C SPEECH COM, P1423; Singh S., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); SINGH S, 1999, P NIPS DENV CO; Singh S, 2002, J ARTIF INTELL RES, V16, P105; Smith R., 1994, SPOKEN NATURAL LANGU; Smith RW, 1998, INT J HUM-COMPUT ST, V48, P627, DOI 10.1006/ijhc.1997.0184; STOCK O, 1993, INTELLIGENT MULTIMED; Sutton R.S., 1998, REINFORCEMENT LEARNI; TRAUM DR, 1999, FDN RATIONAL AGENCY, P169; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVE; Walker M., 1997, P 5 EUR C SPEECH COM; Walker M., 1998, P 36 ANN M ASS COMP, P1345; Walker M. A, 1993, THESIS U PENNSYLVANI; Walker MA, 2000, J ARTIF INTELL RES, V12, P387; WALLIS JW, 1985, RULE BASED EXPERT SY; WATANABE T, 1998, T IEICE INFORMATIO D, V81, P1025; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; WEBB GI, 1996, USER MODEL USER-ADAP, V5, P117, DOI 10.1007/BF01099758; Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175; WEBBER BL, 1982, P COLING 82 PRAG, P413; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280; Williams J. D., 2005, P 6 SIGDIAL WORKSH D; WILLIAMS JD, 2005, P 4 WORKSH KNOWL REA; WILLIAMS JD, 2003, PROBABILISTIC MODEL; YOUNG S, 2002, CUEDFINFENGTR433 CAM; YOUNG S, 2002, P ICSLP DENV CO; Young S., 2002, HTK BOOK HTK VERSION; ZUE V, 1997, P EUR; Zukerman I, 2001, USER MODEL USER-ADAP, V11, P5, DOI 10.1023/A:1011175525451; Zukerman I, 2001, USER MODEL USER-ADAP, V11, P129, DOI 10.1023/A:1011174108613	115	44	44	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0269-8889		KNOWL ENG REV	Knowl. Eng. Rev.	JUN	2006	21	2					97	126		10.1017/S0269888906000944		30	Computer Science, Artificial Intelligence	Computer Science	084ZI	WOS:000240572500001	
J	Bowling, M; Furnkranz, J; Graepel, T; Musick, R				Bowling, M; Furnkranz, J; Graepel, T; Musick, R			Machine learning and games	MACHINE LEARNING			English	Editorial Material											bowling@cs.ualberta.ca; fuernkranz@informatik.tu-darmstadt.de; thoreg@microsoft.com; musick@ikuni.com					AHA DW, 2005, REASONING REPRESENTA; Billings D, 2002, ARTIF INTELL, V134, P201, DOI 10.1016/S0004-3702(01)00130-8; BOURG DM, 2004, AI GAME DEV CREATING; CHAMPANARD A, 2003, AI GAME DEV; COLLINS M, 2002, ADV AI GAME DEV; Forbus KD, 2002, IEEE INTELL SYST, V17, P15, DOI 10.1109/MIS.2002.1024746; FU D, 2004, CHALLENGES GAME AI; FURNKRANZ J, 2001, MACHINES LEARN PLAY; Ginsberg M. L., 1999, P 16 INT JOINT C ART, P584; GINSBERG ML, 1998, SCI AM PRESENTS, V9; Laird JE, 2001, AI MAG, V22, P15; NUNN J, 1994, ADV COMPUTER CHESS, V7, P19; NUNN J, 1994, SECRETS PAWNLESS END; NUNN J, 1992, SECRETS ROOK ENDINGS; NUNN J, 1995, SECRETS MINOR PIECE; RABIN S, 2003, AI GAME PROGRAMMING, V2; RABIN S, 2006, AI GAME PROGRAMMING, V3; Rabin S., 2002, AI GAME PROGRAMMING; SAMUEL AL, 1967, IBM J RES DEV, V11, P601; SAMUEL AL, 1959, IBM J RES DEV, V3, P211; SCHAEFFER J, 2002, ARTIF INTELL, V134, P1, DOI 10.1016/S0004-3702(01)00165-5; Schaeffer J., 2000, ADV COMPUT, V50, P189; Schwab Brian, 2004, AI GAME ENGINE PROGR; SPALL JC, 1992, IEEE T AUTOMAT CONTR, V37, P332, DOI 10.1109/9.119632; TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343	25	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	JUN	2006	63	3					211	215		10.1007/s10994-006-8919-x		5	Computer Science, Artificial Intelligence	Computer Science	049RX	WOS:000238035300001	
J	Sadikov, A; Bratko, I				Sadikov, A; Bratko, I			Learning long-term chess strategies from databases	MACHINE LEARNING			English	Article						machine learning; computer chess; long-term strategy; chess endgames; chess databases		We propose an approach to the learning of long-term plans for playing chess endgames. We assume that a computer-generated database for an endgame is available, such as the king and rook vs. king, or king and queen vs. king and rook endgame. For each position in the endgame, the database gives the "value" of the position in terms of the minimum number of moves needed by the stronger side to win given that both sides play optimally. We propose a method for automatically dividing the endgame into stages characterised by different objectives of play. For each stage of such a game plan, a stage-specific evaluation function is induced, to be used by minimax search when playing the endgame. We aim at learning playing strategies that give good insight into the principles of playing specific endgames. Games played by these strategies should resemble human expert's play in achieving goals and subgoals reliably, but not necessarily as quickly as possible.	Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia	Sadikov, A (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, Ljubljana 1000, Slovenia.	aleksander.sadikov@fri.uni-lj.si; ivan.bratko@fri.uni-lj.si					Bain M., 1995, MACHINE INTELLIGENCE, V14; Baxter J, 2000, MACH LEARN, V40, P243, DOI 10.1023/A:1007634325138; Blake C. L., 1998, UCI REPOSITORY MACHI; BRATKO I, 1984, ARTIFICIAL HUMAN THI, P119; BRATKO I, 2001, PROLOG PROGRAMMING A; Buro M, 1999, IEEE INTELL SYST APP, V14, P12; Demsar J, 2004, ORANGE EXPT MACHINE; DVORETSKY M, 2003, DVORETSKYS ENDGAME M; FVURNKRANZ J, 2001, MACHINES LEARN PLAY; GEORGE M, 1990, ICCA J, V13, P123; MORALES E, 1994, ICCA J, V17, P15; MUGGLETON S, 1989, P 10 INT JOINT C ART, P287; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan JR, 1983, MACHINE LEARNING ART, P463; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; SAMUEL AL, 1967, IBM J RES DEV, V11, P601; SHAPIRO A, 1982, ADV COMPUTER CHESS, V3, P73; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; THOMAS MLH, 1986, CRITTER TALK, V9, P3; Thompson K, 1996, ICCA J, V19, P215	20	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	JUN	2006	63	3					329	340		10.1007/s10994-006-6747-7		12	Computer Science, Artificial Intelligence	Computer Science	049RX	WOS:000238035300005	
J	Shi, D; Chen, F; Ng, GS; Gao, J				Shi, D; Chen, F; Ng, GS; Gao, J			The construction of wavelet network for speech signal processing	NEURAL COMPUTING & APPLICATIONS			English	Article						wavelet neural network; pruning; orthogonal least square; speech signal processing	ALGORITHM; REPRESENTATION; PREDICTION; KERNELS	Wavelet decomposition reconstructs a signal by a series of scaled and translated wavelets. Incorporating discrete wavelet decomposition theory with neural network techniques, wavelet networks have recently emerged as a powerful tool for many applications in the field of signal processing, such as data compression and function approximation. In this paper, four contributions are claimed: (1) From the point of view of machine learning, we analyse and construct wavelet network to achieve the compact representation of a signal. (2) A new algorithm of constructing wavelet network is proposed. The orthogonal least square (OLS) is employed to prune the wavelet network. (3) Our experiments on speech signal processing results show that the wavelet network pruned by OLS achieves the best approximation and prediction capabilities among the representative speech processing techniques. (4) Our proposed methodology has been successfully applied to speech synthesis for a talking head to read web texts.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; Charles Sturt Univ, Sch Informat Technol, Bathurst, NSW 2795, Australia	Shi, D (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	asdmshi@ntu.edu.sg	Shi, Daming/F-6017-2013				AKAIKE H, 1969, ANN I STAT MATH, V21, P243, DOI 10.1007/BF02532251; Bishop C., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.579; CHEN F, 2005, P INT C CY B SING; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Chen S, 1999, IEEE T NEURAL NETWOR, V10, P1239, DOI 10.1109/72.788663; Chen S, 1996, INT J CONTROL, V64, P829, DOI 10.1080/00207179608921659; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; Gao JB, 2001, NEURAL COMPUT, V13, P1975, DOI 10.1162/089976601750399263; Gomm JB, 2000, IEEE T NEURAL NETWOR, V11, P306, DOI 10.1109/72.839002; Gorriz JM, 2004, NEURAL COMPUT APPL, V13, P101, DOI 10.1007/s00521-004-0412-5; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MCAULAY RJ, 1986, IEEE T ACOUST SPEECH, V34, P744, DOI 10.1109/TASSP.1986.1164910; MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; Salmeron M, 2001, NEUROCOMPUTING, V41, P153, DOI 10.1016/S0925-2312(00)00363-5; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591; Zhang QH, 1997, IEEE T NEURAL NETWOR, V8, P227	20	5	5	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0941-0643		NEURAL COMPUT APPL	Neural Comput. Appl.	JUN	2006	15	3-4					217	222		10.1007/s00521-005-0016-8		6	Computer Science, Artificial Intelligence	Computer Science	053TH	WOS:000238327700004	
J	Villmann, T; Schleif, F; Hammer, B				Villmann, Th.; Schleif, F.; Hammer, B.			Comparison of relevance learning vector quantization with other metric adaptive classification methods	NEURAL NETWORKS			English	Article						learning vector quantization; relevance learning; metric adaptation; classification	CASCADE CORRELATION; NEURAL NETWORKS; GAS	The paper deals with the concept of relevance learning in learning vector quantization and classification. Recent machine learning approaches with the ability of metric adaptation but based on different concepts are considered in comparison to variants of relevance learning vector quantization. We compare these methods with respect to their theoretical motivation and we demonstrate the differences of their behavior for several real world data sets. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Leipzig, Clin Psychotherapy, D-04107 Leipzig, Germany; Bruker Daltonik GmbH, Dept Comp Sci, D-04107 Leipzig, Germany; Univ Leipzig, D-04107 Leipzig, Germany; Tech Univ Clausthal, Dept Math & Comp Sci, D-3392 Clausthal Zellerfeld, Germany	Villmann, T (reprint author), Univ Leipzig, Clin Psychotherapy, Karl Tauchnitz Str 25, D-04107 Leipzig, Germany.	villmann@informatik.uni-leipzig.de	Hammer, Barbara /E-8624-2010				ANDONIE R, 2004, EUR S ART NEUR NETW, P471; Bianchini M, 2001, IEEE T NEURAL NETWOR, V12, P1464, DOI 10.1109/72.963781; Blake C. L., 1998, UCI REPOSITORY MACHI; Bojer T., 2001, P EUR S ART NEUR NET, P271; CRAMMER K, 2002, P NIPS 2002; CRISTAINI N, 2002, J MACHINE LEARNING R, V2, P419; DIEKHANS M, 2000, J COMPUT BIOL, V7, P1; Fano R., 1961, TRANSMISSION INFORM; FLACH PA, 2003, P 16 ANN C COMP LEAR; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; GARTNER T, 2003, SURVEY KERNELS STRUC; Hammer B, 2005, NEURAL PROCESS LETT, V21, P21, DOI 10.1007/s11063-004-3255-2; Hammer B, 2005, NEURAL PROCESS LETT, V21, P109, DOI 10.1007/s11063-004-1547-1; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; Hammer B., 2004, EUR S ART NEUR NETW, P281; HAMMER B, 2003, P EUR S ART NEUR NET, P59; HAMMER B, 2005, BIOINFORMATIC USING, P25; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Kapur J., 1994, MEASURES INFORM THEI; Kapur JN, 1992, ENTROPY OPTIMIZATION; Kearns M., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, DOI 10.1145/225298.225301; Kohonen T., 1995, SPRINGER SERIES INFO, V30; Kohonen T, 2002, NEURAL NETWORKS, V15, P945, DOI 10.1016/S0893-6080(02)00069-2; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Micheli A, 2004, IEEE T NEURAL NETWOR, V15, P1396, DOI 10.1109/TNN.2004.837783; Hammer B, 2005, NEURAL COMPUT, V17, P1109, DOI 10.1162/0899766053491878; ONICESCU O, 1966, CR ACAD SCI A MATH, V263, P841; PASSERINI A, 2003, J VLSI SIGNAL PROC, V35, P287; Press W. H., 1999, NUMERICAL RECIPES C; Principe J. C., 2000, UNSUPERVISED ADAPTIV; Renyi A., 1961, P 4 BERK S MATH STAT; SATO A, 1998, P 14 INT C PATT REC, V1, P322, DOI 10.1109/ICPR.1998.711145; SATO A, 1998, P ICANN98 8 INT C AR, V1, P170; Sato A.S., 1995, ADV NEURAL INFORMATI, P423; Schleif FM, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA'04), P374; SCHOLKOPF B, 2002, LEARNING IEEE PRESS; Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108; TORKKOLA K, 2000, P INT C MACH LEARN I; Torkkola K., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753742; TSANG IW, 2003, P INT C ART NEUR NET, P126; VILLMANN T, 2002, P 5 GERM WORKSH ART, P9; ZHANG Z, 2003, HKUSTCS0302; ZHANG Z, 2002, METHODS MICROARRAY D, P125; Zhang Z., 2003, P 18 INT JOINT C ART, P1450; *NAT CANC I, 2004, PROST CANC DAT SET	45	11	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	JUN	2006	19	5					610	622		10.1016/j.neunet.2005.07.013		13	Computer Science, Artificial Intelligence	Computer Science	070NO	WOS:000239529700007	
J	Zhong, P; Fukushima, M				Zhong, P; Fukushima, M			A new multi-class support vector algorithm	OPTIMIZATION METHODS & SOFTWARE			English	Article						machine learning; multi-class classification; nu-SVM	CLASSIFICATION; MACHINES	Multi-class classification is an important and on-going research subject in machine learning. In this article, we propose a new support vector algorithm, called nu-K-SVCR, for multi-class classification based on nu-support vector machine. nu-K-SVCR has parameters that enable us to control the numbers of support vectors and margin errors effectively, which is helpful in improving the accuracy of each classifier. We give some theoretical results concerning the significance of the parameters and show the robustness of classifiers. In addition, we have examined the proposed algorithm on several benchmark data sets and artificial data sets, and our preliminary experiments confirm our theoretical conclusions.	Kyoto Univ, Grad Sch Informat, Dept Appl Math & Phys, Kyoto 6068501, Japan; China Agr Univ, Fac Sci, Beijing 100083, Peoples R China	Fukushima, M (reprint author), Kyoto Univ, Grad Sch Informat, Dept Appl Math & Phys, Kyoto 6068501, Japan.	fuku@amp.i.kyoto-u.ac.jp	Fukushima, Masao/D-1483-2012	Fukushima, Masao/0000-0002-4372-6376			Allwein EL, 2001, J MACH LEARN RES, V1, P113, DOI 10.1162/15324430152733133; Angulo C, 2003, NEUROCOMPUTING, V55, P57, DOI 10.1016/S0925-2312(03)00435-1; Bennett KP, 1999, ADVANCES IN KERNEL METHODS, P307; Blake C. L., 1998, UCI REPOSITORY MACHI; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Hastie T, 1998, ADV NEUR IN, V10, P507; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; LEE Y, 2001, COMPUTING SCI STAT, V33, P498; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; MOREIRA M, 1998, P 10 EUR C MACH LEAR, P160; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Platt JC, 2000, ADV NEUR IN, V12, P547; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Weston J., 1998, CSDTR9804 U LOND ROY	23	7	9	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1055-6788		OPTIM METHOD SOFTW	Optim. Method Softw.	JUN	2006	21	3					359	372		10.1080/10556780500094812		14	Computer Science, Software Engineering; Operations Research & Management Science; Mathematics, Applied	Computer Science; Operations Research & Management Science; Mathematics	002TK	WOS:000234634200002	
J	Chang, H; Yeung, DY				Chang, H; Yeung, DY			Robust locally linear embedding	PATTERN RECOGNITION			English	Article						nonlinear dimensionality reduction; manifold learning; locally linear embedding; principal component analysis; outlier; robust statistics; M-estimation; handwritten digit; wood texture	NONLINEAR DIMENSIONALITY REDUCTION; LAPLACIAN EIGENMAPS; REGRESSION; FRAMEWORK	In the past few years, some nonlinear dimensionality reduction (NLDR) or nonlinear manifold learning methods have aroused a great deal of interest in the machine learning community. These methods are promising in that they can automatically discover the low-dimensional nonlinear manifold in a high-dimensional data space and then embed the data points into a low-dimensional embedding space, using tractable linear algebraic techniques that are easy to implement and are not prone to local minima. Despite their appealing properties, these NLDR methods are not robust against outliers in the data, yet so far very little has been done to address the robustness problem. In this paper, we address this problem in the context of an NLDR method called locally linear embedding (LLE). Based on robust estimation techniques, we propose an approach to make LLE more robust. We refer to this approach as robust locally linear embedding (RLLE). We also present several specific methods for realizing this general RLLE approach. Experimental results on both synthetic and real-world data show that RLLE is very robust against outliers. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Yeung, DY (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.	dyyeung@cs.ust.hk					Belkin M., 2003, ADV NEURAL INFORM PR, V15, P929; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M, 2002, ADV NEUR IN, V14, P585; BRAND M, 2003, P INT JOINT C ART IN, P547; CHANG H, HKUSTCS0512; DECOSTE D, 2001, P 8 INT C NEUR INF P; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; DERIDDER D, 2003, CTUCMPM200308; DERIDDER D, 2002, PH200201 U TECHN DEL; DESILVA V, 2003, ADV NEURAL INFORM PR, V15, P705; HADID A, 2003, P 3 INT C MACH LEARN, P188; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Horn R. A., 1990, MATRIX ANAL; Huber P. J., 1977, ROBUST STAT PROCEDUR; HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503; KOUROPTEVA O, 2002, MCG012002 U OULU FIN; Polito M, 2002, ADV NEUR IN, V14, P1255; Revow M, 1996, IEEE T PATTERN ANAL, V18, P592, DOI 10.1109/34.506410; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul LK., 2003, J MACHINE LEARNING R, V4, P119; Teh YW, 2003, ADV NEURAL INFORMATI, V15, P841; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; VERBEEK JJ, 2002, P 10 EUR S ART NEUR, P193; Zha H., 2003, P 20 INT C MACH LEAR, P864; ZHANG Z, 2003, CSE03003	25	53	71	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUN	2006	39	6					1053	1065		10.1016/j.patcog.2005.07.011		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	031HX	WOS:000236696400005	
J	Fawcett, T				Fawcett, T			An introduction to ROC analysis	PATTERN RECOGNITION LETTERS			English	Article						ROC analysis; classifier evaluation; evaluation metrics	CLASSIFICATION; CURVE; AREA	Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research. (c) 2005 Elsevier B.V. All rights reserved.	Inst Study Learning & Expertise, Palo Alto, CA 94306 USA	Fawcett, T (reprint author), Inst Study Learning & Expertise, 2164 Staunton Court, Palo Alto, CA 94306 USA.	tfawcett@acm.org	Exarchos, Konstantinos/B-5978-2008				Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L, 1984, CLASSIFICATION REGRE; CLEARWATER SH, 1991, COMPUT PHYS COMMUN, V67, P159, DOI 10.1016/0010-4655(91)90014-C; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; EGAN JP, 1975, SIGNAL DETECTION THE; Fawcett T., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989510; Fawcett T., 1996, P 2 INT C KNOWL DISC, P8; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Flach P., 2003, P 2003 UK WORKSH COM, P38; FORMAN G, 2002, P 1 INT WORKSH DAT M; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; HOLTE R, 2002, COMMUNICATION; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; LANE T, 2000, ICML 2000 WORKSH COS; LEWIS D, 1990, P WORKSH SPEECH NAT, P288, DOI 10.3115/116580.116681; Lewis D., 1991, P SPEECH NAT LANG WO, P312, DOI 10.3115/112405.112471; MACSKASSY S, 2004, P 1 WORKSH ROC AN AI; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; PROVOST F, 2001, IS0004 CEDER NEW YOR; Provost F. J., 1998, P 15 INT C MACH LEAR, P445; Saitta L, 1998, MACH LEARN, V30, P133, DOI 10.1023/A:1007448122119; Spackman K.A., 1989, P 6 INT WORKSH MACH, P160; Srinivasan A., 1999, PRGTR299 OXF U COMP; Swets JA, 2000, SCI AM, V283, P82; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; VANDERPUTTEN P, 2000, 200009 U VANL LEID I; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609; Zou K.H., 2002, RECEIVER OPERATING C	31	1488	1550	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2006	27	8					861	874		10.1016/j.patrec.2005.10.010		14	Computer Science, Artificial Intelligence	Computer Science	041NL	WOS:000237462800002	
J	Martin, R; Yu, K				Martin, R; Yu, K			Assessing performance of prediction rules in machine learning	PHARMACOGENOMICS			English	Article						bootstrap; machine learning; Monte Carlo simulation; prediction rule; split sample; stochastic gradient boosting; true error	CROSS-VALIDATION; CLASSIFICATION	Introduction: An important goal in machine learning is to assess the degree to which prediction rules are robust and replicable, since these rules are used for decision making and for planning follow-up studies. This requires an estimate of a prediction rule's true error rate, a statistic that can be estimated by resampling data. However, there are many possible approaches depending upon whether we draw observations with or without replacement, or sample once, repeatedly, or not at all, and the pros and cons of each are often unclear. This study illustrates and compares different methods for estimating true error with the aim of providing practical guidance to users of machine learning techniques. Methods: We conducted Monte Carlo simulation studies using four different error estimators: bootstrap, split sample, resubstitution and a direct estimate of true error. Here, 'split sample' refers to a single random partition of the data into a pair of training and test samples, a popular scheme. We used stochastic gradient boosting as a learning algorithm, and considered data from two studies for which the underlying data mechanism was known to be complex: a library of 6000 tripeptide substrates collected for analysis of proteasome inhibition as part of anticancer drug design, and a cardiovascular study involving 600 subjects receiving antiplatelet treatment for acute coronary syndrome. Results: There were important differences in the performance of the various error estimators examined. Error estimators for split sample and resubstitution, while being the most transparent in action and the simplest to apply, did not quantify the performance of prediction rules as accurately as the bootstrap. This was true for both types of study data, despite their highly different nature. Conclusions: The robustness and reliability of decisions based on analysis of genomics data could, in many cases, be improved by following best practices for prediction error estimation. For this, techniques such as bootstrap should be considered.	Millennium Pharmaceut, Cambridge, MA 02139 USA; Washington Univ, St Louis, MO 63110 USA	Martin, R (reprint author), Millennium Pharmaceut, Cambridge, MA 02139 USA.	rory.martin.phd@gmail.com					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Friedman J., 2000, ANN STAT, V29, P1189; Hastie T, 2001, ELEMENTS STAT LEARNI; HAWKINS D, 2002, J CHEM INF MODEL, V43, P579; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210	13	2	4	FUTURE MEDICINE LTD	LONDON	UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND	1462-2416		PHARMACOGENOMICS	Pharmacogenomics	JUN	2006	7	4					543	550		10.2217/14622416.7.4.543		8	Pharmacology & Pharmacy	Pharmacology & Pharmacy	056WH	WOS:000238555300001	
J	Nayal, M; Honig, B				Nayal, Murad; Honig, Barry			On the nature of cavities on protein surfaces: Application to the identification of drug-binding sites	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						protein-drug-binding sites; protein-drug; interactions; protein surface cavities; molecular recognition; molecular surface patches; protein function	PATTERN-RECOGNITION STRATEGIES; MOLECULAR-SURFACES; NEURAL-NETWORK; PREDICTION; DESIGN; INHIBITORS; INTERFACES; DISCOVERY; REGIONS; PATCHES	In this article we introduce a new method for the identification and the accurate characterization of protein surface cavities. The method is encoded in the program SCREEN (Surface Cavity REcognition and EvaluatioN). As a first test of the utility of our approach we used SCREEN to locate and analyze the surface cavities of a nonredundant set of 99 proteins cocrystallized with drugs. We find that this set of proteins has on average a-Lout 14 distinct cavities per protein. In all cases, a drug is bound at one (and sometimes more than one) of these cavities. Using cavity size alone as a criterion for predicting drug-binding sites yields a high balanced error rate of 15.7%, with only 71.7% coverage. Here we characterize each surface cavity by computing a comprehensive set of 408 physicochemical, structural, and geometric attributes. By applying modern machine learning techniques (Random Forests) we were able to develop a classifier that can identify drug-binding cavities with a balanced error rate of 7.2% and coverage of 88.9%. Only 18 of the 408 cavity attributes had a statistically significant role in the prediction. Of these 18 important attributes, almost all involved size and shape rather than physicochemical properties of the surface cavity. The implications of these results are discussed. A SCREEN Web server is available at http://interface. bioc.columbia.edu/screen.	Columbia Univ, Howard Hughes Med Inst, Coll Phys & Surg, Dept Biochem & Mol Biophys, New York, NY 10032 USA; Columbia Univ, Howard Hughes Med Inst, Ctr Computat Biol & Bioinformat, New York, NY 10032 USA	Honig, B (reprint author), Columbia Univ, Howard Hughes Med Inst, Coll Phys & Surg, Dept Biochem & Mol Biophys, 1130 St Nicholas Ave,ICRB Mail Box 200, New York, NY 10032 USA.	bh6@columbia.edu					ALKORTA I, 1994, J MOL GRAPHICS, V12, P3, DOI 10.1016/0263-7855(94)80002-2; An JH, 2005, MOL CELL PROTEOMICS, V4, P752, DOI 10.1074/mcp.M400159-MCP200; AQVIST J, 1987, J MOL GRAPHICS, V5, P30, DOI 10.1016/0263-7855(87)80042-5; BADELCHAGNON A, 1994, J MOL GRAPHICS, V12, P193; BADELCHAGNON A, 1994, J MOL GRAPHICS, V12, P162, DOI 10.1016/0263-7855(94)80082-0; Bate P, 2004, J MOL BIOL, V340, P263, DOI 10.1016/j.jmb.2004.04.070; Brady GP, 2000, J COMPUT AID MOL DES, V14, P383, DOI 10.1023/A:1008124202956; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Burnham K. P., 2002, MODEL SELECTION MULT; Cochran AG, 2000, CHEM BIOL, V7, pR85, DOI 10.1016/S1074-5521(00)00106-X; CONNOLLY ML, 1986, J MOL GRAPHICS, V4, P3; Cosgrove DA, 2000, J COMPUT AID MOL DES, V14, P573, DOI 10.1023/A:1008167930625; Cover TM, 1991, ELEMENTS INFORM THEO; DELANEY JS, 1992, J MOL GRAPHICS, V10, P174, DOI 10.1016/0263-7855(92)80052-F; DePristo MA, 2004, STRUCTURE, V12, P831, DOI 10.1016/j.str.2004.02.031; Di L, 2003, CURR OPIN CHEM BIOL, V7, P402, DOI 10.1016/S1367-5931(03)00055-3; DIAMOND R, 1974, J MOL BIOL, V82, P371, DOI 10.1016/0022-2836(74)90598-1; DUNCAN BS, 1993, BIOPOLYMERS, V33, P219, DOI 10.1002/bip.360330204; EDELSBRUNNER H, 1994, ACM T GRAPHIC, V13, P43, DOI 10.1145/174462.156635; Edelsbrunner H, 1998, DISCRETE APPL MATH, V88, P83, DOI 10.1016/S0166-218X(98)00067-5; EDELSBRUNNER H, 1995, DISCRETE COMPUT GEOM, V13, P415, DOI 10.1007/BF02574053; Eisenhaber F, 1996, PROTEIN ENG, V9, P1121, DOI 10.1093/protein/9.12.1121; EISNEBERG D, 1992, PROTEIN SCI, V1, P227; Elcock AH, 2001, J MOL BIOL, V312, P885, DOI 10.1006/jmbi.2001.5009; Exner TE, 2002, J COMPUT CHEM, V23, P1176, DOI 10.1002/jcc.10086; FANNING DW, 1986, BIOPOLYMERS, V25, P863, DOI 10.1002/bip.360250509; Fernandez-Recio J, 2005, PROTEINS, V58, P134, DOI 10.1002/prot.20285; Ferre F., 2004, NUCLEIC ACIDS RES, V32, P240; Glaser F, 2003, BIOINFORMATICS, V19, P163, DOI 10.1093/bioinformatics/19.1.163; HEIDEN W, 1994, J MOL GRAPHICS, V12, P106, DOI 10.1016/0263-7855(94)80075-8; Hendlich M, 1997, J MOL GRAPH MODEL, V15, P359, DOI 10.1016/S1093-3263(98)00002-3; Henry CM, 2001, CHEM ENG NEWS, V79, P69, DOI 10.1021/cen-v079n023.p069; HO CMW, 1990, J COMPUT AID MOL DES, V4, P337, DOI 10.1007/BF00117400; HONIG B, 1995, SCIENCE, V268, P1144, DOI 10.1126/science.7761829; Iversen LF, 2001, BIOCHEMISTRY-US, V40, P14812, DOI 10.1021/bi011389l; Jones S, 1996, P NATL ACAD SCI USA, V93, P13, DOI 10.1073/pnas.93.1.13; Jones S, 1997, J MOL BIOL, V272, P133, DOI 10.1006/jmbi.1997.1233; Jones S, 1997, J MOL BIOL, V272, P121, DOI 10.1006/jmbi.1997.1234; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Keil M, 2004, J COMPUT CHEM, V25, P779, DOI 10.1002/jcc.10361; KLAPPER I, 1986, Proteins Structure Function and Genetics, V1, P47, DOI 10.1002/prot.340010109; KLEYWEGT GJ, 1994, ACTA CRYSTALLOGR D, V50, P178, DOI 10.1107/S0907444993011333; Koenderink JJ., 1990, SOLID SHAPE; KOROLEV S, 1995, P NATL ACAD SCI USA, V92, P9264, DOI 10.1073/pnas.92.20.9264; KUNTZ ID, 1982, J MOL BIOL, V161, P269, DOI 10.1016/0022-2836(82)90153-X; Laskowski RA, 1996, PROTEIN SCI, V5, P2438; LASKOWSKI RA, 1995, J MOL GRAPHICS, V13, P323, DOI 10.1016/0263-7855(95)00073-9; Laurie ATR, 2005, BIOINFORMATICS, V21, P1908, DOI 10.1093/bioinformatics/bti315; LEVITT DG, 1992, J MOL GRAPHICS, V10, P229, DOI 10.1016/0263-7855(92)80074-N; LEWIS M, 1985, SCIENCE, V230, P1163, DOI 10.1126/science.4071040; LEWIS RA, 1989, J COMPUT AID MOL DES, V3, P133, DOI 10.1007/BF01557724; LEWIS RA, 1991, METHOD ENZYMOL, V202, P126, DOI 10.1016/0076-6879(91)02010-7; Liang J, 1998, PROTEIN SCI, V7, P1884; Liang S, 2004, PROTEINS, V57, P548, DOI 10.1002/prot.20238; Lichtarge O, 1996, J MOL BIOL, V257, P342, DOI 10.1006/jmbi.1996.0167; Lijnzaad P, 1996, PROTEINS, V25, P389, DOI 10.1002/(SICI)1097-0134(199607)25:3<389::AID-PROT10>3.3.CO;2-S; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Lo Conte L, 1999, J MOL BIOL, V285, P2177; Maignan S, 2000, J MED CHEM, V43, P3226, DOI 10.1021/jm000940u; Masuya M, 1995, J MOL GRAPHICS, V13, P331, DOI 10.1016/0263-7855(95)00071-2; Nayal M, 1999, PROTEIN SCI, V8, P676; Nayeem A, 2003, BIOPOLYMERS, V70, P201, DOI 10.1002/bip.10434; Neuvirth H, 2004, J MOL BIOL, V338, P181, DOI 10.1016/j.jmb.2004.02.040; NICHOLLS A, 1991, PROTEINS, V11, P281, DOI 10.1002/prot.340110407; Nissink JWM, 2002, PROTEINS, V49, P457, DOI 10.1002/prot.10232; Ofran Y, 2003, J MOL BIOL, V325, P377, DOI 10.1016/S0022-2836(02)01223-8; Ondrechen MJ, 2001, P NATL ACAD SCI USA, V98, P12473, DOI 10.1073/pnas.211436698; Oprea TI, 2002, J COMPUT AID MOL DES, V16, P325, DOI 10.1023/A:1020877402759; Perola E, 2004, PROTEINS, V56, P235, DOI 10.1002/prot.20088; Peters KP, 1996, J MOL BIOL, V256, P201, DOI 10.1006/jmbi.1996.0077; Pettit FK, 1999, J MOL BIOL, V285, P1377, DOI 10.1006/jmbi.1998.2411; PICKETT SD, 1993, J MOL BIOL, V231, P825, DOI 10.1006/jmbi.1993.1329; Preissner R, 1998, J MOL BIOL, V280, P535, DOI 10.1006/jmbi.1998.1878; Pupko T., 2002, BIOINFORMATICS, V18, P71; RADZICKA A., 1988, BIOCHEMISTRY-US, V27, P1644; Rogers C. A, 1964, PACKING COVERING; Ruppert J, 1997, PROTEIN SCI, V6, P524; Schmitt S, 2002, J MOL BIOL, V323, P387, DOI 10.1016/S0022-2836(02)00811-2; SHARP KA, 1990, DNA PROTEIN COMPLEXE, V2, P211; Shehadi IA, 2002, MOL BIOL REP, V29, P329, DOI 10.1023/A:1021220208562; Sheinerman FB, 2002, J MOL BIOL, V318, P161, DOI 10.1016/S0022-2836(02)00030-X; SMITH GM, 1994, PROTEIN SCI, V3, P118; Stahl M, 2000, PROTEIN ENG, V13, P83, DOI 10.1093/protein/13.2.83; Stawiski EW, 2003, J MOL BIOL, V326, P1065, DOI 10.1016/S0022-2836(03)00031-7; VAJDA S, 1994, BIOCHEMISTRY-US, V33, P13977, DOI 10.1021/bi00251a004; VOORINTHOLT R, 1989, J MOL GRAPHICS, V7, P243, DOI 10.1016/0263-7855(89)80010-4; Voronoi G, 1907, J REINE ANGEW MATH, V133, P97; WODAK SJ, 1978, J MOL BIOL, V124, P323, DOI 10.1016/0022-2836(78)90302-9; YOUNG L, 1994, PROTEIN SCI, V3, P717	90	112	117	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	JUN 1	2006	63	4					892	906		10.1002/prot.20897		15	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	047ER	WOS:000237863100016	
J	Gromiha, MM; Suwa, M				Gromiha, M. Michael; Suwa, Makiko			Discrimination of outer membrane proteins using machine learning algorithms	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						transmembrane beta-barrel; outer membrane protein (OMP); discrimination; protein folds; neural network	COBALAMIN TRANSPORTER BTUB; BETA-BARREL PROTEINS; SECONDARY-STRUCTURE; CRYSTAL-STRUCTURE; PREDICTION; SEQUENCE; IDENTIFICATION; CLASSIFICATION; ACCURACY; RESOLUTION	Discriminating outer membrane proteins (OMPs) from other folding types of globular and membrane proteins is an important task both for identifying OMPs from genomic sequences and for the successful prediction of their secondary and tertiary structures. In this work, we have analyzed the performance of different methods, based on Bayes rules, logistic functions, neural networks, support vector machines, decision trees, etc. for discriminating OMPs. We found that most of the machine learning techniques discriminate OMPs with similar accuracy. The neural network-based method could discriminate the OMPs from other proteins [globular/transmembrane helical (TMH)] at the fivefold cross-validation accuracy of 91.0% in a dataset of 1,088 proteins. The accuracy of discriminating globular proteins is 88.8% and that of TMH proteins is 93.7%. Further, the neural network method is tested with globular proteins belonging to 30 different folding types and it could successfully exclude 95% of the considered proteins. The proteins with SAM domain such as knottins, rubredoxin, and thioredoxin folds are eliminated with 100% accuracy. These accuracy levels are comparable to or better than other methods in the literature. We suggest that this method could be effectively used to discriminate OMPs and for detecting OMPs in genomic sequences. Proteins 2006;63:1031-1037. (c) 2006 Wiley-Liss, Inc.	Natl Inst Adv Ind Sci & Technol, Computat Biol Res Ctr, Koto Ku, Tokyo 1350064, Japan	Gromiha, MM (reprint author), Natl Inst Adv Ind Sci & Technol, Computat Biol Res Ctr, Koto Ku, AIST Tokyo Waterfront BioIT Res Bldg,2-42 Aomi, Tokyo 1350064, Japan.	michael-gromiha@aist.go.jp					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ahmad S, 2004, BIOINFORMATICS, V20, P477, DOI 10.1093/bioinformatics/btg432; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bagos PG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-29; Bigelow HR, 2004, NUCLEIC ACIDS RES, V32, P2566, DOI 10.1093/nar/gkh580; Branden C., 1999, INTRO PROTEIN STRUCT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chimento DP, 2003, NAT STRUCT BIOL, V10, P394, DOI 10.1038/nsb914; Chimento DP, 2003, J MOL BIOL, V332, P999, DOI 10.1016/j.jmb.2003.07.005; Chou P Y, 1978, Adv Enzymol Relat Areas Mol Biol, V47, P45; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; Frank E, 1998, MACHINE LEARNING; Garrow AG, 2005, NUCLEIC ACIDS RES, V33, pW188, DOI 10.1093/nat/gki384; Gromiha MM, 2005, BIOPHYS CHEM, V117, P65, DOI 10.1016/j.bpc.2005.04.005; Gromiha MM, 1997, PROTEIN ENG, V10, P497, DOI 10.1093/protein/10.5.497; Gromiha MM, 2003, INT J BIOL MACROMOL, V32, P93, DOI 10.1016/S0141-8130(03)00042-4; Gromiha MM, 1999, PROTEIN ENG, V12, P557, DOI 10.1093/protein/12.7.557; Gromiha MM, 2004, J COMPUT CHEM, V25, P762, DOI 10.1002/jcc.10386; Gromiha MM, 2005, BIOINFORMATICS, V21, P961, DOI 10.1093/bioinformatics/bti126; Gromiha MM, 2004, J MOL BIOL, V337, P285, DOI 10.1016/j.jmb.2004.01.033; Gromiha MM, 2005, COMPUT BIOL CHEM, V29, P135, DOI 10.1016/j.compbiolchem.2005.02.006; Hirokawa T, 1998, BIOINFORMATICS, V14, P378, DOI 10.1093/bioinformatics/14.4.378; Holm L, 1998, BIOINFORMATICS, V14, P423, DOI 10.1093/bioinformatics/14.5.423; Kohavi R, 1996, P 2 INT C KNOWL DISC; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Liu Q, 2003, COMPUT BIOL CHEM, V27, P355, DOI 10.1016/S1476-9271(02)00085-3; MARTELLI PL, 2002, BIOINFORMATICS, V18, P46; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092; Pautsch A, 2000, J MOL BIOL, V298, P273, DOI 10.1006/jmbi.2000.3671; Przybylski D, 2002, PROTEINS, V46, P197, DOI 10.1002/prot.10029; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Robles Víctor, 2004, Artif Intell Med, V31, P117, DOI 10.1016/j.artmed.2004.01.009; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; Schulz GE, 2002, BBA-BIOMEMBRANES, V1565, P308, DOI 10.1016/S0005-2736(02)00577-1; Sun HM, 2005, J MED CHEM, V48, P4031, DOI 10.1021/jm050180t; Vandeputte-Rutten L, 2001, EMBO J, V20, P5033, DOI 10.1093/emboj/20.18.5033; White SH, 1999, ANNU REV BIOPH BIOM, V28, P319, DOI 10.1146/annurev.biophys.28.1.319; Wimley WC, 2002, PROTEIN SCI, V11, P301, DOI 10.1110/ps.29402; Witten I. H., 2005, DATA MINING PRACTICA; Zeth K, 2000, STRUCT FOLD DES, V8, P981, DOI 10.1016/S0969-2126(00)00189-1	43	40	41	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	JUN 1	2006	63	4					1031	1037		10.1002/prot.20929		7	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	047ER	WOS:000237863100029	
J	Ruan, XG; Li, YX; Li, JG; Gong, DX; Wang, JL				Ruan Xiaogang; Li Yingxin; Li Jiangeng; Gong Daoxiong; Wang Jinlian			Tumor-specific gene expression patterns with gene expression proffles	SCIENCE IN CHINA SERIES C-LIFE SCIENCES			English	Article						cancer; informative gene selection; gene expression profile; support vector machine	CANCER; CLASSIFICATION; ATM; PREDICTION; MICROARRAY; DISCOVERY; DIAGNOSIS; SELECTION	Gene expression profiles of 14 common tumors and their counterpart normal tissues were analyzed with machine learning methods to address the problem of selection of tumor-specific genes and analysis of their differential expressions in tumor tissues. First, a variation of the Relief algorithm, "RFE_Relief algorithm" was proposed to learn the relations between genes and tissue types. Then, a support vector machine was employed to find the gene subset with the best classification performance for distinguishing cancerous tissues and their counterparts. After tissue-specific genes were removed, cross validation experiments were employed to demonstrate the common deregulated expressions of the selected gene in tumor tissues. The results indicate the existence of a specific expression fingerprint of these genes that is shared in different tumor tissues, and the hallmarks of the expression patterns of these genes in cancerous tissues are summarized at the end of this paper.	Beijing Univ Technol, Sch Elect Informat & Control Engn, Beijing 100022, Peoples R China	Ruan, XG (reprint author), Beijing Univ Technol, Sch Elect Informat & Control Engn, Beijing 100022, Peoples R China.	adrxg@bjut.edu.cn					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Deng L, 2004, CHINESE SCI BULL, V49, P1652, DOI 10.1360/03we0143; DeRisi J, 1996, NAT GENET, V14, P457; Golding SE, 2004, J BIOL CHEM, V279, P15402, DOI 10.1074/jbc.M314191200; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Groth A, 2003, EMBO J, V22, P1676, DOI 10.1093/emboj/cdg151; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hanahan D, 2000, CELL, V100, P57, DOI 10.1016/S0092-8674(00)81683-9; Huang Y, 2003, INT J CANCER, V104, P735, DOI 10.1002/ijc.11006; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kononenko I., 1994, P EUR C MACH LEARN, P171; Li X, 2004, SCI CHINA SER C, V47, P396, DOI 10.1360/03yc0127; Li Ying-xin, 2004, Acta Electronica Sinica, V32; LI Z, 2002, ACTA BIOPHYS SIN, V18, P413; Lu Y, 2003, INFORM SYST, V28, P243, DOI 10.1016/S0306-4379(02)00072-8; Maillet P, 2002, J MED GENET, V39, P751, DOI 10.1136/jmg.39.10.751; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Ramaswamy S, 2002, J CLIN ONCOL, V20, P1932; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Rendell L.A., 1992, P 10 NAT C ART INT, P129; Vapnik VN, 1998, STAT LEARNING THEORY; WANG R, 2001, INTRO MOL ONCOLOGY; Yeang C H, 2001, Bioinformatics, V17 Suppl 1, pS316	24	2	2	SCIENCE CHINA PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1006-9305		SCI CHINA SER C	Sci. China Ser. C-Life Sci.	JUN	2006	49	3					293	304		10.1007/s11427-006-0293-1		12	Biology	Life Sciences & Biomedicine - Other Topics	061NX	WOS:000238880400011	
J	Poland, J; Hutter, M				Poland, J; Hutter, M			MDL convergence speed for Bernoulli sequences	STATISTICS AND COMPUTING			English	Article							COMPLEXITY; INFORMATION; PRINCIPLE; INDUCTION	The Minimum Description Length principle for online sequence estimation/prediction in a proper learning setup is studied. If the underlying model class is discrete, then the total expected square loss is a particularly interesting performance measure: (a) this quantity is finitely bounded, implying convergence with probability one, and (b) it additionally specifies the convergence speed. For MDL, in general one can only have loss bounds which are finite but exponentially larger than those for Bayes mixtures. We show that this is even the case if the model class contains only Bernoulli distributions. We derive a new upper bound on the prediction error for countable Bernoulli classes. This implies a small bound (comparable to the one for Bayes mixtures) for certain important model classes. We discuss the application to Machine Learning tasks such as classification and hypothesis testing, and generalization to countable classes of i.i.d. models.	Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 060, Japan; IDSIA, CH-6928 Lugano, Switzerland	Poland, J (reprint author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 060, Japan.	jan@ist.hokudai.ac.jp; marcus@idsia.ch					Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; CLARKE BS, 1990, IEEE T INFORM THEORY, V36, P453, DOI 10.1109/18.54897; GACS P, 1983, THEOR COMPUT SCI, V22, P71, DOI 10.1016/0304-3975(83)90139-1; GRUNWALD P, 2004, 17 ANN C LEARN THEOR, P331; HUTTER M, 2003, J MACHINE LEARNING R, V4, P971, DOI 10.1162/jmlr.2003.4.6.971; HUTTER M, 2005, J COMPUTER SYSTEM SC, V72, P95; Hutter M., 2001, P 12 EUR C MACH LEAR, P239; Hutter M, 2003, LECT NOTES ARTIF INT, V2777, P506, DOI 10.1007/978-3-540-45167-9_37; Hutter M, 2003, IEEE T INFORM THEORY, V49, P2061, DOI 10.1109/TIT.2003.814488; Levin Leonid, 1973, SOV MATH DOKL, V14, P1413; Li J., 1999, THESIS YALE U; Li M., 1997, INTRO KOLMOGOROV COM; POLAND J, 2005, BEN 2005 ANN MACH LE; POLAND J, 2004, 17 ANN C LEARN THEOR, P300; POLAND J, 2004, INT C ALG LEARN THEO, P294; Rissanen J, 1999, COMPUT J, V42, P260, DOI 10.1093/comjnl/42.4.260; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; SOLOMONOFF RJ, 1978, IEEE T INFORM THEORY, V24, P422, DOI 10.1109/TIT.1978.1055913; Vitanyi PMB, 2000, IEEE T INFORM THEORY, V46, P446, DOI 10.1109/18.825807; Vovk VG, 1997, J COMPUT SYST SCI, V55, P96, DOI 10.1006/jcss.1997.1502; ZHANG T, 2004, P 17 ANN C LEARN THE, P315; Zvonkin A. K., 1970, RUSS MATH SURV, V25, P83, DOI 10.1070/RM1970v025n06ABEH001269	23	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0960-3174		STAT COMPUT	Stat. Comput.	JUN	2006	16	2					161	175		10.1007/s11222-006-6746-3		15	Computer Science, Theory & Methods; Statistics & Probability	Computer Science; Mathematics	041PO	WOS:000237468300004	
J	Breazeal, C; Berlin, M; Brooks, A; Gray, J; Thomaz, AL				Breazeal, C; Berlin, M; Brooks, A; Gray, J; Thomaz, AL			Using perspective taking to learn from ambiguous demonstrations	ROBOTICS AND AUTONOMOUS SYSTEMS			English	Article; Proceedings Paper	IEEE International Conference on Robotics and Automation (ICRA)	APR 18-22, 2005	Barcelona, SPAIN	IEEE		human-robot interactions; socially guided learning; learning by demonstration; perspective taking		This paper addresses an important issue in learning from demonstrations that are provided by "naive" human teachers-people who do not have expertise in the machine learning algorithms used by the robot. We therefore entertain the possibility that, whereas the average human user may provide sensible demonstrations from a human's perspective, these same demonstrations may be insufficient, incomplete, ambiguous, or otherwise "flawed" from the perspective of the training set needed by the learning algorithm to generalize properly. To address this issue, we present a system where the robot is modeled as a socially engaged and socially cognitive learner. We illustrate the merits of this approach through an example where the robot is able to correctly learn from "flawed" demonstrations by taking the visual perspective of the human instructor to clarify potential ambiguities. (c) 2006 Elsevier B.V. All rights reserved.	MIT, Media Lab, Cambridge, MA 02139 USA	Breazeal, C (reprint author), MIT, Media Lab, 20 Ames St, Cambridge, MA 02139 USA.	cynthiab@media.mit.edu					BARSALOU LW, 2003, PSYCHOL LEARNING MOT, V43; BLUMBERG B, 2002, P ACM SIGGRAN 2002 A, V21; Breazeal C., 2005, IEEE RSJ INT C INT R; BREAZEAL C, 2004, P AAMAS; Carberry S, 2001, USER MODEL USER-ADAP, V11, P31, DOI 10.1023/A:1011118925938; CASSIMATIS NL, 2004, J ROBOTICS AUTONOMOU, V49, P13; Davies M., 1995, FOLK PSYCHOL THEORY; Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5; GLIDEWELL JC, 1977, SOCIAL CONTEXT LEARN; GRAY J, 2005, 14 IEEE INT WORKSH R; Grice H.P., 1975, SYNTAX SEMANTICS, V3, P41; LOCKERD A, 2004, IEEE RSJ INT C INT R; Meltzoff AN, 2003, PHILOS T R SOC B, V358, P491, DOI 10.1098/rstb.2002.1261; NICOLESCU MN, 2003, P 2 INT JOINT C AUT; Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3; VYGOTSKY LS, 1978, SOC DEV HIGHER PSYCH	16	14	14	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0921-8890		ROBOT AUTON SYST	Robot. Auton. Syst.	MAY 31	2006	54	5					385	393		10.1016/j.robot.2006.02.004		9	Automation & Control Systems; Computer Science, Artificial Intelligence; Robotics	Automation & Control Systems; Computer Science; Robotics	045WX	WOS:000237774500005	
J	Jia, PL; Shi, TL; Cai, YD; Li, YX				Jia, Peilin; Shi, Tieliu; Cai, Yudong; Li, Yixue			Demonstration of two novel methods for predicting functional siRNA efficiency	BMC BIOINFORMATICS			English	Article							PROTEIN SIGNAL SEQUENCES; SUPPORT VECTOR MACHINES; RNA INTERFERENCE; CLEAVAGE SITES; DESIGN; GENOME	Background: siRNAs are small RNAs that serve as sequence determinants during the gene silencing process called RNA interference (RNAi). It is well know that siRNA efficiency is crucial in the RNAi pathway, and the siRNA efficiency for targeting different sites of a specific gene varies greatly. Therefore, there is high demand for reliable siRNAs prediction tools and for the design methods able to pick up high silencing potential siRNAs. Results: In this paper, two systems have been established for the prediction of functional siRNAs: (1) a statistical model based on sequence information and (2) a machine learning model based on three features of siRNA sequences, namely binary description, thermodynamic profile and nucleotide composition. Both of the two methods show high performance on the two datasets we have constructed for training the model. Conclusion: Both of the two methods studied in this paper emphasize the importance of sequence information for the prediction of functional siRNAs. The way of denoting a bio-sequence by binary system in mathematical language might be helpful in other analysis work associated with fixed-length bio-sequence.	Chinese Acad Sci, Shanghai Inst Biol Sci, Bioinformat Ctr, Shanghai 200031, Peoples R China; Chinese Acad Sci, Grad Sch, Beijing 100039, Peoples R China; Shanghai Ctr Bioinformat Technol, Shanghai 200235, Peoples R China; Chinese Acad Sci, Shanghai Inst Biol Sci, Partner Inst Computat Biol, CAS MPG, Shanghai, Peoples R China; Shanghai Jiao Tong Univ, Life Sci Sch, Shanghai, Peoples R China; UMIST, Dept Biomol Sci, Manchester M60 1QD, Lancs, England	Jia, PL (reprint author), Chinese Acad Sci, Shanghai Inst Biol Sci, Bioinformat Ctr, 320 Yueyang Rd, Shanghai 200031, Peoples R China.	pljia@sibs.ac.cn; tlshi@sibs.ac.cn; y.cai@manchester.ac.uk; yxli@scbit.org	Jia, Peilin/B-4519-2013				Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cai Y D, 2001, BMC Bioinformatics, V2, P3, DOI 10.1186/1471-2105-2-3; CAI YD, 2001, J COMPUT CHEM, V23, P267; Cai YD, 2003, PEPTIDES, V24, P159, DOI 10.1016/S0196-9781(02)00289-9; Cai Yu-Dong, 2000, Molecular Cell Biology Research Communications, V4, P230, DOI 10.1006/mcbr.2001.0285; Chou KC, 2001, PROTEIN ENG, V14, P75, DOI 10.1093/protein/14.2.75; Chou KC, 2001, PROTEINS, V42, P136, DOI 10.1002/1097-0134(20010101)42:1<136::AID-PROT130>3.0.CO;2-F; FREIER SM, 1986, P NATL ACAD SCI USA, V83, P9373, DOI 10.1073/pnas.83.24.9373; Hannon GJ, 2004, NATURE, V431, P371, DOI 10.1038/nature02870; Henschel A, 2004, NUCLEIC ACIDS RES, V32, pW113, DOI 10.1093/nar/gkh408; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huesken D, 2005, NAT BIOTECHNOL, V23, P995, DOI 10.1038/nbt1118; Khvorova A, 2003, CELL, V115, P209, DOI 10.1016/S0092-8674(03)00801-8; Mello CC, 2004, NATURE, V431, P338, DOI 10.1038/nature02872; Reynolds A, 2004, NAT BIOTECHNOL, V22, P326, DOI 10.1038/nbt936; Saetrom P, 2004, BIOINFORMATICS, V20, P3055, DOI 10.1093/bioinformatics/bth364; SATROM PA, 2004, BIOCHEM BIOPH RES CO, V321, P247, DOI 10.1016/j.bbrc.2004.06.116; Ui-Tei K, 2004, NUCLEIC ACIDS RES, V32, P936, DOI 10.1093/nar/gkh247; Wang LQ, 2004, BIOINFORMATICS, V20, P1818, DOI 10.1093/bioinformatics/bth164	19	25	26	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAY 29	2006	7								271	10.1186/1471-2105-7-271		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	070JH	WOS:000239517400001	
J	Liu, X; Lu, WC; Jin, SL; Li, YW; Chen, NY				Liu, X; Lu, WC; Jin, SL; Li, YW; Chen, NY			Support vector regression applied to materials optimization of sialon ceramics	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article; Proceedings Paper	International Conference on Chemometrics and Bioinformatics in Asia	OCT 16-20, 2004	Shanghai, PEOPLES R CHINA	Natl Nat Sci Fdn China, Near-Infrared Comm Japan, Chinese Chem Soc, Comp Chem Comm, Tongi Univ, Cent S Univ, Hunan Univ		support vector regression; mixture of kernels; materials optimization	ARTIFICIAL NEURAL-NETWORKS	Partial Least Squares (PLS) and Back Propagation Artificial Neural Network (BP-ANN) are widely known machine learning techniques for materials optimization, whereas Support Vector Machine (SVM) is seldom used in materials science. In this paper, Support Vector Regression (SVR), a machine learning technology based on statistical learning theory (SLT), was applied to predict the cold modulus of sialon ceramic with satisfactory results. In a benchmark test, the performances of SVR were compared with those of PLS and BP-ANN. The prediction accuracies of the different models were discussed on the basis of the leave-one-out cross-validation. The results showed that the prediction accuracy of SVR model was higher than those of BP-ANN and PLS models. (c) 2005 Elsevier B.V. All rights reserved.	Shanghai Univ, Coll Sci, Dept Chem, Lab Chem Data Min, Shanghai 200444, Peoples R China; Wuhan Univ Sci & Technol, Hubei Prov Key Lab High Temp Ceram & Refractories, Wuhan 430081, Peoples R China	Lu, WC (reprint author), Shanghai Univ, Coll Sci, Dept Chem, Lab Chem Data Min, Shanghai 200444, Peoples R China.						Amendolia SR, 2003, CHEMOMETR INTELL LAB, V69, P13, DOI 10.1016/S0169-7439(03)00094-7; Bakshi BR, 1998, J ALLOY COMPD, V279, P39, DOI 10.1016/S0925-8388(98)00610-0; Belousov AI, 2002, CHEMOMETR INTELL LAB, V64, P15, DOI 10.1016/S0169-7439(02)00046-1; CEHN NY, 1999, LAB INFORM MANAGEMEN, V45, P329; Chen N., 2004, SUPPORT VECTOR MACHI; HOLDEN SB, 1996, 9 ANN ACM WORKSH COM; KANG DS, 1996, J CHINESE RARE EARTH, V14, P365; Kearns M., 1997, Proceedings of the Tenth Annual Conference on Computational Learning Theory, DOI 10.1145/267460.267491; Kudyba-Jansen AA, 2001, J EUR CERAM SOC, V21, P2153, DOI 10.1016/S0955-2219(00)00289-2; LI YW, 2001, P 44 INT C REFR 26 2, P26; 陆文聪, 2002, [计算机与应用化学, Computers and Applied Chemistry], V19, P697; MacKenzie KJD, 2003, J EUR CERAM SOC, V23, P1069, DOI 10.1016/S0955-2219(02)00269-8; Smits GF, 2002, IEEE IJCNN, P2785, DOI 10.1109/IJCNN.2002.1007589; Smola A., 1998, NCTR98030 U LOND ROY; Vapnik VN, 1998, STAT LEARNING THEORY; Verikas A, 2003, CHEMOMETR INTELL LAB, V67, P187, DOI 10.1016/S0169-7439(03)00093-5; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1; Zhang Z, 2003, COMPOS SCI TECHNOL, V63, P2029, DOI 10.1016/S0266-3538(03)00106-4	18	20	26	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	MAY 26	2006	82	1-2			SI		8	14		10.1016/j.chemolab.2005.08.011		7	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	043GL	WOS:000237588100003	
J	Yu, XJ; Cao, JP; Cai, YD; Shi, TL; Li, YX				Yu, XJ; Cao, JP; Cai, YD; Shi, TL; Li, YX			Predicting rRNA-, RNA-, and DNA-binding proteins from primary structure with support vector machines	JOURNAL OF THEORETICAL BIOLOGY			English	Article						rRNA-binding protein; RNA-binding protein; DNA-binding protein; protein function prediction; support vector machines (SVMs)	FUNCTIONAL DOMAIN COMPOSITION; AMINO-ACID-COMPOSITION; EXPRESSION DATA; SWISS-PROT; SEQUENCE; CLASSIFICATION; RECOGNITION; GENOME; SVM; CONSERVATION	In the post-genome era, the prediction of protein function is one of the most demanding tasks in the study of bioinformatics. Machine learning methods, such as the support vector machines (SVMs), greatly help to improve the classification of protein function. In this work, we integrated SVMs, protein sequence amino acid composition, and associated physicochemical properties into the study of nucleic-acid-binding proteins prediction. We developed the binary classifications for rRNA-, RNA-, DNA-binding proteins that play an important role in the control of many cell processes. Each SVM predicts whether a protein belongs to rRNA-, RNA-, or DNA-binding protein class. Self-consistency and jackknife tests were performed on the protein data sets in which the sequences identity was < 25%. Test results show that the accuracies of rRNA-, RNA-, DNA-binding SVMs predictions are similar to 84%, similar to 78%, similar to 72%, respectively. The predictions were also performed on the ambiguous and negative data set. The results demonstrate that the predicted scores of proteins in the ambiguous data set by RNA- and DNA-binding SVM models were distributed around zero, while most proteins in the negative data set were predicted as negative scores by all three SVMs. The score distributions agree well with the prior knowledge of those proteins and show the effectiveness of sequence associated physicochemical properties in the protein function prediction. The software is available from the author upon request. (c) 2005 Elsevier Ltd. All rights reserved.	UMIST, Dept Biomol Sci, Manchester M60 1QD, Lancs, England; Chinese Acad Sci, Grad Sch, Shanghai Inst Biol Sci, Bioinformat Ctr, Shanghai 200031, Peoples R China; Univ Elect Sci & Technol China, Sch Life Sci & Technol, Dept Biomed Engn, Chengdu 610054, Peoples R China	Cai, YD (reprint author), UMIST, Dept Biomol Sci, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk; tlshi@sibs.ac.cn; yxli@sibs.ac.cn					Ahmad S, 2004, J MOL BIOL, V341, P65, DOI 10.1016/j.jmb.2004.05.058; Ahmad S, 2004, BIOINFORMATICS, V20, P477, DOI 10.1093/bioinformatics/btg432; Bairoch A, 2004, BRIEF BIOINFORM, V5, P39, DOI 10.1093/bib/5.1.39; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Baxevanis AD, 1998, METHOD BIOCHEM ANAL, V39, P172; Benner SA, 2000, RES MICROBIOL, V151, P97, DOI 10.1016/S0923-2508(00)00123-6; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Bork P, 1998, NAT GENET, V18, P313, DOI 10.1038/ng0498-313; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BURBIDGE R, 2000, P AISB 00 S ART INT, P1; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600; Cai CZ, 2003, MATH BIOSCI, V185, P111, DOI 10.1016/S0025-5564(03)00096-8; Cai Y D, 2001, BMC Bioinformatics, V2, P3, DOI 10.1186/1471-2105-2-3; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2004, J THEOR BIOL, V226, P373, DOI 10.1016/j.jtbi.2003.08.015; Cai YD, 2003, BBA-PROTEINS PROTEOM, V1648, P127, DOI 10.1016/S1570-9639(03)00112-2; Cai YD, 2003, BIOPHYS J, V84, P3257; CHOTHIA C, 1990, ANNU REV BIOCHEM, V59, P1007, DOI 10.1146/annurev.biochem.59.1.1007; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dandekar T, 1998, TRENDS BIOCHEM SCI, V23, P324, DOI 10.1016/S0968-0004(98)01274-2; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; Eisen JA, 1998, GENOME RES, V8, P163; Enright AJ, 2002, NUCLEIC ACIDS RES, V30, P1575, DOI 10.1093/nar/30.7.1575; Enright AJ, 1999, NATURE, V402, P86; Falquet L, 2002, NUCLEIC ACIDS RES, V30, P235, DOI 10.1093/nar/30.1.235; Frishman D, 1997, PROTEINS, V27, P329, DOI 10.1002/(SICI)1097-0134(199703)27:3<329::AID-PROT1>3.0.CO;2-8; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Henikoff S, 1997, SCIENCE, V278, P609, DOI 10.1126/science.278.5338.609; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Je HM, 2003, NEURAL PROCESS LETT, V17, P239, DOI 10.1023/A:1026097128675; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Joachims T., 1998, ADV KERNEL METHODS S; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Kaufman L, 1999, ADVANCES IN KERNEL METHODS, P147; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Luscombe NM, 2002, J MOL BIOL, V320, P991, DOI 10.1016/S0022-2836(02)00571-5; Marcotte EM, 1999, NATURE, V402, P83; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Mardia KV, 1979, MULTIVARIATE ANAL; Mucchielli-Giorgi MH, 1999, BIOINFORMATICS, V15, P176, DOI 10.1093/bioinformatics/15.2.176; Osuna E, 1997, NEURAL NETWORKS SIGN, P276; Overbeek R, 1999, P NATL ACAD SCI USA, V96, P2896, DOI 10.1073/pnas.96.6.2896; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Teichmann SA, 2001, CURR OPIN STRUC BIOL, V11, P354, DOI 10.1016/S0959-440X(00)00215-3; Thubthong N, 2001, INT J UNCERTAIN FUZZ, V9, P803, DOI 10.1142/S0218488501001253; Vapnik V. N, 1995, NATURE STAT LEARNING; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	57	49	56	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193		J THEOR BIOL	J. Theor. Biol.	MAY 21	2006	240	2					175	184		10.1016/j.jtbi.2005.09.018		10	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	046RH	WOS:000237828200002	
J	Yan, CH; Terribilini, M; Wu, FH; Jernigan, RL; Dobbs, D; Honavar, V				Yan, Changhui; Terribilini, Michael; Wu, Feihong; Jernigan, Robert L.; Dobbs, Drena; Honavar, Vasant			Predicting DNA-binding sites of proteins from amino acid sequence	BMC BIOINFORMATICS			English	Article							ALANINE-SCANNING MUTAGENESIS; TRANSCRIPTION ACTIVATION; MOLECULAR-SURFACES; IDENTIFICATION; RECOGNITION; RESIDUES; INTERFACE; DATABASE	Background: Understanding the molecular details of protein-DNA interactions is critical for deciphering the mechanisms of gene regulation. We present a machine learning approach for the identification of amino acid residues involved in protein-DNA interactions. Results: We start with a Nave Bayes classifier trained to predict whether a given amino acid residue is a DNA- binding residue based on its identity and the identities of its sequence neighbors. The input to the classifier consists of the identities of the target residue and 4 sequence neighbors on each side of the target residue. The classifier is trained and evaluated (using leave-one-out cross-validation) on a non-redundant set of 171 proteins. Our results indicate the feasibility of identifying interface residues based on local sequence information. The classifier achieves 71% overall accuracy with a correlation coefficient of 0.24, 35% specificity and 53% sensitivity in identifying interface residues as evaluated by leave-one-out cross-validation. We show that the performance of the classifier is improved by using sequence entropy of the target residue (the entropy of the corresponding column in multiple alignment obtained by aligning the target sequence with its sequence homologs) as additional input. The classifier achieves 78% overall accuracy with a correlation coefficient of 0.28, 44% specificity and 41% sensitivity in identifying interface residues. Examination of the predictions in the context of 3-dimensional structures of proteins demonstrates the effectiveness of this method in identifying DNA-binding sites from sequence information. In 33% (56 out of 171) of the proteins, the classifier identifies the interaction sites by correctly recognizing at least half of the interface residues. In 87% (149 out of 171) of the proteins, the classifier correctly identifies at least 20% of the interface residues. This suggests the possibility of using such classifiers to identify potential DNA- binding motifs and to gain potentially useful insights into sequence correlates of protein-DNA interactions. Conclusion: Naive Bayes classifiers trained to identify DNA-binding residues using sequence information offer a computationally efficient approach to identifying putative DNA- binding sites in DNA-binding proteins and recognizing potential DNA-binding motifs.	Utah State Univ, Dept Comp Sci, Logan, UT 84341 USA; Iowa State Univ, Dept Genet Dev & Cell Biol, Ames, IA 50010 USA; Iowa State Univ, Bioinformat & Comp Biol Grad Program, Ames, IA 50010 USA; Iowa State Univ, Artificial Intelligence Res Lab, Ames, IA 50010 USA; Iowa State Univ, Dept Comp Sci, Ames, IA 50010 USA; Iowa State Univ, Ctr Computat Intelligence Learning & Discovery, Ames, IA 50010 USA; Iowa State Univ, Laurence H Baker Ctr Bioinformat & Biol Stat, Ames, IA 50010 USA; Iowa State Univ, Dept Biochem Biophys & Mol Biol, Ames, IA 50010 USA	Yan, CH (reprint author), Utah State Univ, Dept Comp Sci, Logan, UT 84341 USA.	cyan@cc.usu.edu; terrible@iastate.edu; wuflyh@iastate.edu; jernigan@iastate.edu; ddobbs@iastate.edu; honavar@cs.iastate.edu	Jernigan, Robert/A-5421-2012				Ahmad S, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-33; Ahmad S, 2004, BIOINFORMATICS, V20, P477, DOI 10.1093/bioinformatics/btg432; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Blancafort P, 2004, MOL PHARMACOL, V66, P1361, DOI 10.1124/mol.104.002758.; Buntine W, 1991, THEORY REFINEMENT BA, P52; EISENBERG D, 1984, P NATL ACAD SCI US, V81; Gene Ontology Annotation, GENE ONTOLOGY ANNOTA; Geyer H, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh131; Ghosh D, 2005, CURR MED CHEM, V12, P691; Griffith KL, 2002, J MOL BIOL, V322, P237, DOI 10.1016/S0022-2836(02)00782-9; Hubbard S, 1993, NACCESS; Hulo N, 2006, NUCLEIC ACIDS RES, V34, pD227, DOI 10.1093/nar/gkj063; Jones S, 2003, NUCLEIC ACIDS RES, V31, P7189, DOI 10.1093/nar/gkg922; Jones S, 1997, J MOL BIOL, V272, P133, DOI 10.1006/jmbi.1997.1233; Keil M, 2004, J COMPUT CHEM, V25, P779, DOI 10.1002/jcc.10361; Kim JS, 2005, P NATL ACAD SCI USA, V102, P3248, DOI 10.1073/pnas.0409851102; Laity JH, 2001, CURR OPIN STRUC BIOL, V11, P39, DOI 10.1016/S0959-440X(00)00167-6; Lawson CL, 2004, CURR OPIN STRUC BIOL, V14, P10, DOI 10.1016/j.sbi.2004.01.012; Martz E, 2002, TRENDS BIOCHEM SCI, V27, P107, DOI 10.1016/S0968-0004(01)02008-4; Muller CW, 2001, CURR OPIN STRUC BIOL, V11, P26, DOI 10.1016/S0959-440X(00)00163-9; PABO CO, 1992, ANNU REV BIOCHEM, V61, P1053, DOI 10.1146/annurev.biochem.61.1.1053; Radlinska M, 2005, PROTEINS, V58, P263, DOI 10.1002/prot.20297; Rocchia W, 2001, J PHYS CHEM B, V105, P6507, DOI 10.1021/jp010454y; Rocchia W, 2002, J COMPUT CHEM, V23, P128, DOI 10.1002/jcc.1161; SANDER C, 1991, PROTEINS, V9, P56, DOI 10.1002/prot.340090107; SEN TZ, 2005, BMC BIOINFORMATICS, V5, P205; Shanahan HP, 2004, NUCLEIC ACIDS RES, V32, P4732, DOI 10.1093/nar/gkh803; TERRIBILINI M, UNPUB PREDICTION RNA; Tsuchiya Y, 2004, PROTEINS, V55, P885, DOI 10.1002/prot.20111; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Witten I. H., 1999, DATA MINING PRACTICA; Yan Changhui, 2004, Bioinformatics, V20 Suppl 1, pi371, DOI 10.1093/bioinformatics/bth920; Yan CH, 2004, NEURAL COMPUT APPL, V13, P123, DOI 10.1007/s00521-004-0414-3; [Anonymous], WEKA 3 DATA MINING S; *PDB, PDB DAT; PS SCAN PROGRAM; PREDICTION DNA BINDI	38	56	57	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAY 19	2006	7								262	10.1186/1471-2105-7-262		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	073IK	WOS:000239736000001	
J	De Raedt, H; De Raedt, K; Michielsen, K; Miyashita, S				De Raedt, H; De Raedt, K; Michielsen, K; Miyashita, S			Efficient data processing and quantum phenomena: Single-particle systems	COMPUTER PHYSICS COMMUNICATIONS			English	Article						computer simulation; machine learning; quantum interference; quantum theory	EVENT-BASED SIMULATION; DIMENSION	We study the relation between the acquisition and analysis of data and quantum theory using a probabilistic and deterministic model for photon polarizers. We introduce criteria for efficient processing of data and then use these criteria to demonstrate that efficient processing of the data contained in single events is equivalent to the observation that Malus' law holds. A strictly deterministic process that also yields Malus' law is analyzed in detail. We present a performance analysis of the probabilistic and deterministic model of the photon polarizer. The latter is an adaptive dynamical system that has primitive learning capabilities. This additional feature has recently been shown to be sufficient to perform event-by-event simulations of interference phenomena, without using concepts of wave mechanics. We illustrate this by presenting results for a system of two chained Mach-Zehnder interferometers, suggesting that systems that perform efficient data processing and have learning capability are able to exhibit behavior that is usually attributed to quantum systems only. (c) 2006 Elsevier B.V. All rights reserved.	Univ Groningen, Ctr Mat Sci, Dept Appl Phys, NL-9747 AG Groningen, Netherlands; Univ Groningen, Dept Comp Sci, NL-9747 AC Groningen, Netherlands; Univ Tokyo, Grad Sch Sci, Dept Phys, Bunkyo Ku, Tokyo 1138656, Japan	De Raedt, H (reprint author), Univ Groningen, Ctr Mat Sci, Dept Appl Phys, Nijenborgh 4, NL-9747 AG Groningen, Netherlands.	h.a.de.raedt@rug.nl; miya@spin.phys.t.u-tokyo.ac.jp					Baym G, 1974, LECT QUANTUM MECH; Blahut R. E., 1991, PRINCIPLES PRACTICE; Born M., 1964, PRINCIPLES OPTICS; Braig C, 2003, APPL PHYS B-LASERS O, V76, P113, DOI 10.1007/s00340-003-1106-x; De Raedt H, 2005, EUROPHYS LETT, V69, P861, DOI 10.1209/epl/i2004-10443-7; DERAEDT H, 2005, J PHYS SOC JPN S, V74, P16; De Raedt K, 2005, COMPUT PHYS COMMUN, V171, P19, DOI 10.1016/j.cpc.2005.04.012; Feynman R P, 1996, FEYNMAN LECT PHYS, VIII; Frieden B. R., 1999, PHYS FISHER INFORM U; GRANGIER P, 1986, EUROPHYS LETT, V1, P173, DOI 10.1209/0295-5075/1/4/004; GRIMMET GR, 1995, PROBABILITY RANDOM P; Haykin S., 1999, NEURAL NETWORKS; Home D., 1997, CONCEPTUAL FDN QUANT; HUBBARD J, 1978, PHYS REV B, V17, P494, DOI 10.1103/PhysRevB.17.494; Jaynes E. T., 2003, PROBABILITY THEORY L; JENSEN MH, 1983, PHYS REV LETT, V50, P1637, DOI 10.1103/PhysRevLett.50.1637; MICHIELSEN K, 2005, J COMPUT THEOR NANOS, V2, P1; SUMMHAMMER J, 2001, FDN PROBABILITY PHYS; TRIBUS M, 1999, RATIONAL DESCRIPTION; Van Trees H. L., 1968, DETECTION ESTIMATI 1; WOOTTERS WK, 1981, PHYS REV D, V23, P357, DOI 10.1103/PhysRevD.23.357	21	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0010-4655		COMPUT PHYS COMMUN	Comput. Phys. Commun.	MAY 15	2006	174	10					803	817		10.1016/j.cpc.2005.12.013		15	Computer Science, Interdisciplinary Applications; Physics, Mathematical	Computer Science; Physics	043TJ	WOS:000237624200004	
J	D'heyere, T; Goethals, PLM; De Pauw, N				D'heyere, T; Goethals, PLM; De Pauw, N			Genetic algorithms for optimisation of predictive ecosystems models based on decision trees and neural networks	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	3rd Conference of the International-Society-for-Ecological-Informatics (ISEI)	AUG   26, 2002	Rome, ITALY	Int Soc Ecol Informat		predictive modelling; variable selection; machine learning techniques; genetic algorithm; macroinvertebrates	ERRORS; VARIABLES; QUALITY; ECOLOGY; ISSUES	The selection of appropriate input variables in predictive ecological modelling is an important issue since numerous variables can be involved. Most of the input variables cannot be omitted because it results in a significant loss of information. The collection of field data on the other hand is both time-consuming and expensive. Rigorous methods are therefore needed to decide which explanatory variables or combinations of variables should enter the model. Appropriate selection of input variables is not only important for modelling objectives as such, but also to ensure reliable decision-support in river management and policy-making. In this paper, the use of genetic algorithms is explored to automatically select the relevant input variables for classification trees and artificial neural networks (ANNs), predicting the presence or absence of benthic macroinvertebrate taxa. The applied database consisted of measurements from 360 sites in unnavigable watercourses in Flanders, Belgium. The measured variables are a combination of physical-chemical, eco-toxicological and structural ones. The predictive power of the models was assessed on the basis of three performance measures: root mean squared error (RMSE), correctly classified instances (CCI) and Cohen's kappa. The selected genetic algorithm introduced different sets of input variables to the models and compared their predictive power to select the optimal combination of input variables. With this technique, the number of input variables could be reduced from 17 to three to six for classification trees and to five to eleven for ANNs. The prediction success increased significantly based on a statistical test. Overall, a better performance was detected for decision trees. The most appropriate way to assess the performance of the models was a combination of the CCI and Cohen's kappa. By means of this variable selection stage, the key variables that determine the presence or absence of benthic macroinvertebrate taxa in Flanders could also be identified. (c) 2005 Elsevier B.V. All rights reserved.	Univ Ghent, Lab Environm Toxicol & Aquat Ecol, B-9000 Ghent, Belgium	D'heyere, T (reprint author), Univ Ghent, Lab Environm Toxicol & Aquat Ecol, J Plateaustr 22, B-9000 Ghent, Belgium.	tom.dheygere@rug.ac.be	Goethals, Peter/A-1116-2008				ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; ALMUALLIN H, 1922, P CAN C ART INT, P38; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P1; DAKOU E, 2002, UNPUB ECOSYSTEMS; De Pauw Niels, 2001, Aquatic Ecology, V35, P121, DOI 10.1023/A:1011478427152; Dedecker A.P., 2002, THESCIENTIFICWORLDJO, V2, P96, DOI DOI 10.1100/TSW.2002.79; DEPAUW N, 1983, HYDROBIOLOGIA, V100, P153; DHEYGERE T, 2003, UNPUB AQUAT ECOL; D'heygere T, 2003, ECOL MODEL, V160, P291, DOI 10.1016/S0304-3800(02)00260-0; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Goethals Peter, 2001, Journal of Limnology, V60, P7; Goethals P.L.M., 2002, ECOLOGICAL INFORM UN, P432; Goldberg D. E., 1989, GENETIC ALGORITHMS S, P412; Harrell FE, 1996, STAT MED, V15, P361, DOI 10.1002/(SICI)1097-0258(19960229)15:4<361::AID-SIM168>3.0.CO;2-4; HOLLAND JH, 1975, ADAPTATION NATURAL A; JOHN GH, 1997, THESIS STANFORD U CO; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Lek S, 1996, ECOL MODEL, V90, P39, DOI 10.1016/0304-3800(95)00142-5; Liu H., 1996, P 13 INT C MACH LEAR, P319; Maier H. R., 1996, Neural Network World, V6; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; Manel S, 2001, J APPL ECOL, V38, P921, DOI 10.1046/j.1365-2664.2001.00647.x; Manel S, 1999, J APPL ECOL, V36, P734, DOI 10.1046/j.1365-2664.1999.00440.x; Norris RH, 1999, FRESHWATER BIOL, V41, P197, DOI 10.1046/j.1365-2427.1999.00425.x; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Recknagel F, 2001, ECOL MODEL, V146, P303, DOI 10.1016/S0304-3800(01)00316-7; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schleiter IM, 1999, ECOL MODEL, V120, P271, DOI 10.1016/S0304-3800(99)00108-8; WCHOWICZ M, 2002, ECOLOGICAL INFORM UN, P183; Witten I. H., 2000, DATA MINING PRACTICA; *MIN FLEM COMM, 2000, MAN CHAR SED FLEM WA	32	31	32	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	MAY 15	2006	195	1-2			SI		20	29		10.1016/j.ecolmodel.2005.11.005		10	Ecology	Environmental Sciences & Ecology	047QB	WOS:000237892700004	
J	Shan, Y; Paull, D; Mckay, RI				Shan, Y; Paull, D; Mckay, RI			Machine learning of poorly predictable ecological data	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	3rd Conference of the International-Society-for-Ecological-Informatics (ISEI)	AUG   26, 2002	Rome, ITALY	Int Soc Ecol Informat		genetic programming; decision trees; neural networks; support vector machines; southern brown bandicoot; spatial distribution modelling	BANDICOOT ISOODON-OBESULUS	This paper reports on research using a variety of machine learning techniques to a difficult modelling problem, the spatial distribution of an endangered Australian marsupial, the southern brown bandicoot (Isoodon obesulus). Four learning techniques - decision trees/rules, neural networks, support vector machines and genetic programming - were applied to the problem. Support vector and neural network approaches gave marginally better predictivity, but in the context of low overall accuracy, decision trees and genetic programming gave more useful results because of the human comprehensibility of their models. (c) 2005 Elsevier B.V. All rights reserved.	Seoul Natl Univ, Sch Comp Sci & Engn, Seoul, South Korea; Univ New S Wales, Sch Informat Technol & Elect Engn, ADFA, Canberra, ACT 2600, Australia; Univ New S Wales, Sch Phys Environm & Math Sci, ADFA, Canberra, ACT 2600, Australia	Mckay, RI (reprint author), Seoul Natl Univ, Sch Comp Sci & Engn, Seoul, South Korea.	rim@cse.snu.ac.kr					CHANG CC, 2001, LIB SVM LIB SUPPORT; Color Munsell, 1994, MUNS SOIL COL CHARTS; Haykin S., 1994, NEURAL NETWORKS COMP; Koza J. R., 1992, GENETIC PROGRAMMING; McDonald R.C., 1990, AUSTR SOIL LAND SURV; NUNEZ H, 2000, P 2000 EUR S ART NEU, P107; PAULL D, 1995, WILDLIFE RES, V22, P585, DOI 10.1071/WR9950585; PAULL DJ, 1999, 19991 U COLL SCH GEO; PAULL DJ, 1993, THESIS U ADELAIDE; Plunkett K., 1997, EXERCISES RETHINKING; POSSINGHAM HP, 1996, EFFECTS EFFECTIVENES, P14; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ross BJ, 2001, NEW GENERAT COMPUT, V19, P313; STODDART DM, 1979, J ANIM ECOL, V48, P165, DOI 10.2307/4107; Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352; Vapnik VN, 1998, STAT LEARNING THEORY; Whigham PA, 1995, P WORKSH GEN PROGR T, P33; Whigham PA, 2000, ECOL MODEL, V131, P299, DOI 10.1016/S0304-3800(00)00248-9	18	18	20	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	MAY 15	2006	195	1-2			SI		129	138		10.1016/j.ecolmodel.2005.11.015		10	Ecology	Environmental Sciences & Ecology	047QB	WOS:000237892700015	
J	Opfer, R				Opfer, R			Tight frame expansions of multiscale reproducing kernels in Sobolev spaces	APPLIED AND COMPUTATIONAL HARMONIC ANALYSIS			English	Article						reproducing kernels; multiscale kernels; Sobolev spaces; scattered data approximation; error bounds; frame expansions; frame coefficients; refinable functions; recursion formula; data compression		Multiscale kernels are a new type of positive definite reproducing kernels in Hilbert spaces. They are constructed by a superposition of shifts and scales of a single refinable function and were introduced in the paper of R. Opfer [Multiscale kernels, Adv. Comput. Math. (2004), in press]. By applying standard reconstruction techniques occurring in radial basis function- or machine learning theory, multiscale kernels can be used to reconstruct multivariate functions from scattered data. The multiscale structure of the kernel allows to represent the approximant on several levels of detail or accuracy. In this paper we prove that multiscale kernels are often reproducing kernels in Sobolev spaces. We use this fact to derive error bounds. The set of functions used for the construction of the multiscale kernel will turn out to be a frame in a Sobolev space of certain smoothness. We will establish that the frame coefficients of approximants can be computed explicitly. In our case there is neither a need to compute the inverse of the frame operator nor is there a need to compute inner products in the Sobolev space. Moreover we will prove that a recursion formula between the frame coefficients of different levels holds. We present a bivariate numerical example illustrating the mutiresolution and data compression effect. (C) 2005 Elsevier Inc. All rights reserved.	Univ Gottingen, D-37073 Gottingen, Germany	Opfer, R (reprint author), Philips Res, Rontgenstr 24-26, D-22315 Hamburg, Germany.	roland.opfer@philips.com					ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; Buhmann M., 2003, RADIAL BASIS FUNCTIO; CAVARETTA AS, 1991, MEM AM MATH SOC, V453, P1; Christensen O., 2003, INTRO FRAMES RIESZ B; Chui C.K., 1992, INTRO WAVELETS WAVEL, V1; DAHMEN W, 1992, NUMER MATH, V63, P315, DOI 10.1007/BF01385864; DAUBECHIES I, 1986, J MATH PHYS, V27, P1271, DOI 10.1063/1.527388; Daubechies I., 1992, 10 LECT WAVELETS; deBoor C., 2001, PRACTICAL GUIDE SPLI; DeVore R. A., 1992, ACTA NUMERICA, V1, P1, DOI 10.1017/S0962492900002233; DeVore R. A., 1993, CONSTRUCTIVE APPROXI, V303; DYN N, 1971, SIAM J NUMER ANAL, V8, P583; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; GROCHENIG KH, 1993, IEEE T SIGNAL PROCES, V12, P3331; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; ISKE A, 2000, TUTORIALS MULTIRESOL; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Meschkowski H., 1962, HILBERTSCHE RAUME KE; Meyer Y., 1992, CAMBRIDGE STUD ADV M, V37; Micchelli C. A., 1991, Numerical Algorithms, V1, DOI 10.1007/BF02145583; Narcowich FJ, 2005, MATH COMPUT, V74, P743; OPFER R, 2004, IN PRESS ADV COMPUT; Oswald P., 1990, Z ANAL ANWEND, V9, P43; Schaback R., 2001, MULTIVARIATE APPROXI, P1, DOI 10.1017/CBO9780511569616.002; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416; Wendland H., 2005, CAMBRIDGE MONOGR APP, V17; WERNER D, 1997, FUNKTIONALANALYSIS; Young R.M., 1980, INTRO NONHARMONIC FO	29	7	8	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1063-5203		APPL COMPUT HARMON A	Appl. Comput. Harmon. Anal.	MAY	2006	20	3					357	374		10.1016/j.acha.2005.05.003		18	Mathematics, Applied; Physics, Mathematical	Mathematics; Physics	047CS	WOS:000237858000004	
J	Cohen, G; Hilario, M; Sax, H; Hugonnet, S; Geissbuhler, A				Cohen, Gilles; Hilario, Melanie; Sax, Hugo; Hugonnet, Stephane; Geissbuhler, Antoine			Learning from imbalanced data in surveillance of nosocomial infection	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article; Proceedings Paper	4th Industrial Conference on Data Mining (ICDM)	JUL 04-07, 2004	Leipzig, GERMANY	Inst Comp Vis & Appl Comp Sci		nosocomial infection; machine learning; support vector machines; data imbalance	VECTOR MACHINE CLASSIFIERS; KERNEL FUNCTIONS; SUPPORT; HOSPITALS	Objective: An important problem that arises in hospitals is the monitoring and detection of nosocomial or hospital acquired infections (Nis). This paper describes a retrospective analysis of a prevalence survey of Nis done in the Geneva University Hospital. Our goat is to identify patients with one or more Nis on the basis of clinical and other data collected during the survey. Methods and material: Standard surveillance strategies are time-consuming and cannot be applied hospital-wide; alternative methods are required. In NI detection viewed as a classification task, the main difficulty resides in the significant imbalance between positive or infected (11%) and negative (89%) cases. To remedy class imbalance, we explore two distinct avenues: (1) a new resampling approach in which both oversampling of rare positives and undersampling of the noninfected majority rely on synthetic cases (prototypes) generated via class-specific subclustering, and (2) a support vector algorithm in which asymmetrical margins are tuned to improve recognition of rare positive cases. Results and conclusion: Experiments have shown both approaches to be effective for the NI detection problem. Our novel resampling strategies perform remarkably better than classical random resampling. However, they are outperformed by asymmetrical soft margin support vector machines which attained a sensitivity rate of 92%, significantly better than the highest sensitivity (87%) obtained via prototype-based resampling. (C) 2005 Published by Elsevier B.V.	Univ Hosp Geneva, Med Informat Serv, Geneva, Switzerland; Univ Geneva, Artificial Intelligence Lab, Geneva, Switzerland; Univ Hosp Geneva, Dept Internal Med, Geneva, Switzerland	Cohen, G (reprint author), Univ Hosp Geneva, Med Informat Serv, Geneva, Switzerland.	Gilles.Cohen@sim.hcuge.ch					Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Brossette SE, 2000, METHOD INFORM MED, V39, P303; Brossette SE, 1998, J AM MED INFORM ASSN, V5, P373; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CENTOR RM, 1991, MED DECIS MAKING, V11, P102, DOI 10.1177/0272989X9101100205; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Duda R., 2000, PATTERN CLASSIFICATI; EMMERSON AM, 1995, J HOSP INFECT, V30, P7, DOI 10.1016/0195-6701(95)90245-7; Fletcher R., 1987, PRACTICAL METHODS OP; FRENCH G, 1983, LANCET, V2, P1021; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GARNER JS, 1988, AM J INFECT CONTROL, V16, P128, DOI 10.1016/0196-6553(88)90053-3; Harbarth S, 1999, SCHWEIZ MED WSCHR, V129, P1521; Japkowicz N., 2002, Intelligent Data Analysis, V6; Karakoulas G, 1999, ADV NEUR IN, V11, P253; Kubat M., 1997, P 14 INT C MACH LEAR, P179; LAMMA E, 2000, LNCS, P282; Ma Lili, 2003, AMIA Annu Symp Proc, P410; Morik K, 1999, P 16 INT C MACH LEAR, P268; Moser SA, 1999, EMERG INFECT DIS, V5, P454; PERNER P, 2002, DATA MINING MULTIMED; Provost F. J., 1998, P 15 INT C MACH LEAR, P445; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Trick WE, 2004, EMERG INFECT DIS, V10, P1612; Vapnik VN, 1998, STAT LEARNING THEORY; Veropulos K, 1999, P INT JOINT C ART IN, P55; Wu S, 2002, NEURAL PROCESS LETT, V15, P59, DOI 10.1023/A:1013848912046	31	35	37	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	MAY	2006	37	1					7	18		10.1016/j.artmed.2005.03.002		12	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	045LQ	WOS:000237744000002	
J	Smith, AE; Humphreys, MS				Smith, Andrew E.; Humphreys, Michael S.			Evaluation of unsupervised semantic mapping of natural language with Leximancer concept mapping	BEHAVIOR RESEARCH METHODS			English	Article								The Leximancer system is a relatively new method for transforming lexical co-occurrence information from natural language into semantic patterns in an unsupervised manner. It employs two stages of co-occurrence information extraction-semantic and relational-using a different algorithm for each stage. The algorithms used are statistical, but they employ nonlinear dynamics and machine learning. This article is an attempt to validate the output of Leximancer, using a set of evaluation criteria taken from content analysis that are appropriate for knowledge discovery tasks.	Univ Queensland, ARC Key Ctr Human Factors & Appl Cognit Psychol, Brisbane, Qld 4072, Australia	Smith, AE (reprint author), Univ Queensland, ARC Key Ctr Human Factors & Appl Cognit Psychol, Brisbane, Qld 4072, Australia.	asmith@humanfactors.uq.edu.au					Apte C., 1994, P 17 ANN INT ACM SIG, P23; BAHR LS, 1992, COLLIERS ENCY; Bassford Christopher, 1994, CLAUSEWITZ ENGLISH R; Burgess C, 1997, LANG COGNITIVE PROC, V12, P177; Chalmers M., 1992, P 15 ANN INT ACM SIG, P330, DOI DOI 10.1145/133160.133215; Dumais S.T., 1998, CIKM 98, P148; Grant, 1885, PERSONAL MEMOIRS US; Grech M.R., 2002, P HUM FACT ERG SOC 4; KATTER RV, AKTT; Krippendorff K., 2004, CONTENT ANAL INTRO M; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; Lefebvre S., 2004, INT J INTELLIGENCE C, V17, P231; Nelson DL, 2003, J EXP PSYCHOL LEARN, V29, P42, DOI 10.1037/0278-7393.29.1.42; NISBETT RE, 1977, PSYCHOL REV, V84, P231, DOI 10.1037//0033-295X.84.3.231; Osgood C. E., 1957, MEASUREMENT MEANING; Salton G., 1989, AUTOMATIC TEXT PROCE; Smith A.E., 2000, P 5 AUSTR DOC COMP S; SMITH AE, 2000, P INT WORKSH TEXT WE, P72; Smith A.E., 2003, HLT NAACL 2003 HUM L; Sowa J., 2000, KNOWLEDGE REPRESENTA; Stubbs Michael, 1996, TEXT CORPUS ANAL COM; VEEFERMAN D, 1997, P 35 ANN M ASS COMP, P373; VONCLAUSEWITZ C, 1857, WAR; Weber Robert Philip, 1990, BASIC CONTENT ANAL; Yarowsky D., 1995, P 33 ANN M ASS COMP, P189, DOI 10.3115/981658.981684; *INT RUGB BOARD, 2003, LAWS GAM RUGB UN 200; *US MAR CORP, 1997, MAR CORPS DOCTR PUBL	28	77	77	PSYCHONOMIC SOC INC	AUSTIN	1710 FORTVIEW RD, AUSTIN, TX 78704 USA	1554-351X		BEHAV RES METHODS	Behav. Res. Methods	MAY	2006	38	2					262	279		10.3758/BF03192778		18	Psychology, Mathematical; Psychology, Experimental	Psychology	078CN	WOS:000240078900013	
J	Clare, A; Karwath, A; Ougham, H; King, RD				Clare, A; Karwath, A; Ougham, H; King, RD			Functional bioinformatics for Arabidopsis thaliana	BIOINFORMATICS			English	Article							PROTEIN FUNCTION; INSERTION SEQUENCES; GENOME; GENE; ASSIGNMENT; PREDICTION; PROGRAMS	Motivation: The genome of Arabidopsis thaliana, which has the best understood plant genome, still has approximately one-third of its genes with no functional annotation at all from either MIPS or TAIR. We have applied our Data Mining Prediction (DMP) method to the problem of predicting the functional classes of these protein sequences. This method is based on using a hybrid machine-learning/data-mining method to identify patterns in the bioinformatic data about sequences that are predictive of function. We use data about sequence, predicted secondary structure, predicted structural domain, InterPro patterns, sequence similarity profile and expressions data. Results: We predicted the functional class of a high percentage of the Arabidopsis genes with currently unknown function. These predictions are interpretable and have good test accuracies. We describe in detail seven of the rules produced.	Univ Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales; Univ Freiburg, Inst Comp Sci, D-79110 Freiburg, Germany	Clare, A (reprint author), Univ Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.	afc@aber.ac.uk					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Kaul S, 2000, NATURE, V408, P796; Attwood TK, 2000, INT J BIOCHEM CELL B, V32, P139, DOI 10.1016/S1357-2725(99)00106-5; Ashburner M, 2000, NAT GENET, V25, P25; Clare A, 2002, BIOINFORMATICS, V18, P160, DOI 10.1093/bioinformatics/18.1.160; CLARE A, 2003, LECT NOTES COMPUTER, V2562; Clare A., 2003, BIOINFORMATICS, V19, P42; Dzeroski S., 2001, RELATIONAL DATA MINI; EISEN JA, 1994, NUCLEIC ACIDS RES, V22, P2634, DOI 10.1093/nar/22.13.2634; Frishman D, 2001, BIOINFORMATICS, V17, P44, DOI 10.1093/bioinformatics/17.1.44; Gough J, 2001, J MOL BIOL, V313, P903, DOI 10.1006/jmbi.2001.5080; Gutierrez RA, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-8-r53; HVIDSTEN TR, 1908, PAC S BIOCOMPUT, P299; Kell DB, 2000, TRENDS BIOTECHNOL, V18, P93, DOI 10.1016/S0167-7799(99)01407-9; KING R, 2000, COMPUT FUNCT GENOM, V17, P283; KING R, 2000, P ACM INT C KDD 2000; King RD, 2004, BIOINFORMATICS, V20, P1110, DOI 10.1093/bioinformatics/bth047; King RD, 2001, BIOINFORMATICS, V17, P445, DOI 10.1093/bioinformatics/17.5.445; Lehfeldt C, 2000, PLANT CELL, V12, P1295, DOI 10.1105/tpc.12.8.1295; Mahillon J, 1998, MICROBIOL MOL BIOL R, V62, P725; Marcotte EM, 1999, NATURE, V402, P83; Ouali M, 2000, PROTEIN SCI, V9, P1162; PAVLIDIS P, 2001, P RECOMB 2001; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RILEY M, 1993, MICROBIOL REV, V57, P862; SYED U, 2003, P RECOMB 2003; Thornton JM, 2001, SCIENCE, V292, P2095, DOI 10.1126/science.292.5524.2095; Zdobnov EM, 2001, BIOINFORMATICS, V17, P847, DOI 10.1093/bioinformatics/17.9.847	28	12	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 1	2006	22	9					1130	1136		10.1093/bioinformatics/btl051		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	035JR	WOS:000236997600013	
J	Wei, SH; Balch, C; Paik, HH; Kim, YS; Baldwin, RL; Liyanarachchi, S; Li, L; Wang, ZL; Wan, JC; Davuluri, RV; Karlan, BY; Gifford, G; Brown, R; Kim, S; Huang, THM; Nephew, KP				Wei, SH; Balch, C; Paik, HH; Kim, YS; Baldwin, RL; Liyanarachchi, S; Li, L; Wang, ZL; Wan, JC; Davuluri, RV; Karlan, BY; Gifford, G; Brown, R; Kim, S; Huang, THM; Nephew, KP			Prognostic DNA methylation biomarkers in ovarian cancer	CLINICAL CANCER RESEARCH			English	Article							TUMOR-SUPPRESSOR GENES; GSTP1 HYPERMETHYLATION; MICROARRAY ANALYSIS; PROSTATE-CANCER; EXPRESSION; DIAGNOSIS; NEUROBLASTOMA; CARCINOMAS; SIGNATURE; PROFILES	Purpose: Aberrant DNA methylation, now recognized as a contributing factor to neoplasia, often shows definitive gene/sequence preferences unique to specific cancer types. Correspondingly, distinct combinations of methylated loci can function as biomarkers for numerous clinical correlates of ovarian and other cancers. Experimental Design: We used a microarray approach to identify methylated loci prognostic for reduced progression-free survival (PFS) in advanced ovarian cancer patients. Two data set classification algorithms, Significance Analysis of Microarray and Prediction Analysis of Microarray, successfully identified 220 candidate PFS - discriminatory methylated loci. Of those, 112 were found capable of predicting PFS with 95% accuracy, by Prediction Analysis of Microarray, using an independent set of 40 advanced ovarian tumors (from 20 short-PFS and 20 long-PFS patients, respectively). Additionally, we showed the use of these predictive loci using two bioinformatics machine-learning algorithms, Support Vector Machine and Multilayer Perceptron. Conclusion: In this report, we show that highly prognostic DNA methylation biomarkers can be successfully identified and characterized, using previously unused, rigorous classifying algorithms. Such ovarian cancer biomarkers represent a promising approach for the assessment and management of this devastating disease.	Indiana Univ, Sch Med, Dept Cellular & Integrat Physiol, Bloomington, IN 47405 USA; Ohio State Univ, Ctr Comprehens Canc, Dept Mol Virol Immunol & Med Genet, Human Canc Genet Program, Columbus, OH 43210 USA; Ohio State Univ, Math Biosci Inst, Columbus, OH 43210 USA; Indiana Univ, Sch Informat, Ctr Bioinformat & Genom, Bloomington, IN 47405 USA; Inha Univ, Sch Informat & Commun Engn, Inchon, South Korea; Univ Calif Los Angeles, Sch Med, Dept Obstet & Gynecol, Cedars Sinai Med Ctr,Div Gynecol Oncol, Los Angeles, CA 90024 USA; Indiana Univ, Sch Med, Dept Med, Div Biostat, Bloomington, IN 47405 USA; Indiana Univ, Ctr Canc, Bloomington, IN 47405 USA; Univ Glasgow, Beatson Labs, Canc Res UK, Glasgow, Lanark, Scotland	Nephew, KP (reprint author), Indiana Univ, Sch Med, Dept Cellular & Integrat Physiol, Jordan Hall 303,1001 E 3rd St, Bloomington, IN 47405 USA.	knephew@indiana.edu	Davuluri, Ramana/D-7348-2011				Bae YK, 2004, CLIN CANCER RES, V10, P5998, DOI 10.1158/1078-0432.CCR-04-0667; Bastian PJ, 2004, EUR J MED RES, V9, P523; Costello JF, 2000, NAT GENET, V24, P132, DOI 10.1038/72785; Cottrell SE, 2003, ANN NY ACAD SCI, V983, P120; Cristianini N., 2000, INTRO SUPPORT VECTOR; Egger G, 2004, NATURE, V429, P457, DOI 10.1038/nature02625; Esteller M, 2001, CANCER RES, V61, P3225; Glinsky GV, 2005, J CLIN INVEST, V115, P1503, DOI 10.1172/JCI23412; Gourley C, 2005, INT J ONCOL, V26, P1681; Henrique R, 2004, EUR UROL, V46, P660, DOI 10.1016/j.eururo.2004.06.014; House MG, 2003, J GASTROINTEST SURG, V7, P1004, DOI 10.1016/j.gassur.2003.08.002; House MG, 2003, ANN SURG, V238, P423, DOI 10.1097/01.sla.0000086659.49569.9e; Iliopoulos D, 2005, ONCOGENE, V24, P1625, DOI 10.1038/sj.onc.1208398; Jeney V, 2005, CIRC RES, V96, P723, DOI 10.1161/01.RES.0000162001.57896.66; Laird PW, 2003, NAT REV CANCER, V3, P253, DOI 10.1038/nrc1045; Li LC, 2005, J NATL CANCER I, V97, P103, DOI 10.1093/jnci/dji010; LUDWIG JA, 2005, NAT REV CANCER, V11, P845; Mates J.M., 1999, FRONT BIOSCI, V4, P339; Motiwala T, 2003, ONCOGENE, V22, P6319, DOI 10.1038/sj.onc.1206750; SCHOLKOPF B, 2003, COMPUTATIONAL LEARNI; Shao J., 1995, JACKKNIFE BOOTSTRAP; Spentzos D, 2004, J CLIN ONCOL, V22, P4700, DOI 10.1200/JCO.2004.04.070; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Thomas JG, 2001, GENOME RES, V11, P1227, DOI 10.1101/gr.165101; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Ushijima T, 2005, NAT REV CANCER, V5, P223, DOI 10.1038/nrc1571; Wei SH, 2002, CLIN CANCER RES, V8, P2246; Wimmer K, 2002, GENE CHROMOSOME CANC, V33, P285, DOI 10.1002/gcc.10030; Witten I. H., 1999, DATA MINING PRACTICA; YAN PS, 2002, J NUTR, V132, P2430; Yang B, 2003, AM J PATHOL, V163, P1101, DOI 10.1016/S0002-9440(10)63469-4; Yang QW, 2004, CLIN CANCER RES, V10, P8493, DOI 10.1158/1078-0432.CCR-04-1331; Zochbauer-Muller S, 2002, ONCOLOGIST, V7, P451, DOI 10.1634/theoncologist.7-5-451	34	59	63	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432		CLIN CANCER RES	Clin. Cancer Res.	MAY 1	2006	12	9					2788	2794		10.1158/1078-0432.CCR-05-1551		7	Oncology	Oncology	041GI	WOS:000237441900018	
J	Koppel, M; Schler, J				Koppel, M; Schler, J			The importance of neutral examples for learning sentiment	COMPUTATIONAL INTELLIGENCE			English	Article; Proceedings Paper	Workshop on Formal & Informal Information Exchange in Negotiations	MAY 26-27, 2005	Ottawa, CANADA		Univ of Ottawa	sentiment analysis; text categorization; machine learning		Most research on learning to identify sentiment ignores "neutral" examples, learning only from examples of significant (positive or negative) polarity. We show that it is crucial to use neutral examples in learning polarity for a variety of reasons. Learning from negative and positive examples alone will not permit accurate classification of neutral examples. Moreover, the use of neutral training examples in learning facilitates better distinction between positive and negative examples.	Bar Ilan Univ, Dept Comp Sci, Ramat Gan, Israel	Koppel, M (reprint author), Bar Ilan Univ, Dept Comp Sci, Ramat Gan, Israel.						Crammer K, 2001, J MACHINE LEARNING R, V2, P265; Dave K., 2003, P 12 INT C WORLD WID, P519, DOI DOI 10.1145/775152.775226; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Frank E., 2001, P 12 EUR C MACH LEAR, P145; FUERNKRANZ J, 2002, J MACHINE LEARNING R, V2, P721; Hastie T, 1998, ADV NEUR IN, V10, P507; Pang B., 2002, P 2002 C EMP METH NA; Pang Bo, 2005, P 43 ANN M ASS COMP, P115, DOI DOI 10.3115/1219840.1219855; SAVICKY P, 2003, ADV INTELLIGENT DATA, V5, P219; SHANAHAN JG, 2005, COMPUTING ATTITUDE A; Wiebe J, 2004, COMPUT LINGUIST, V30, P277, DOI 10.1162/0891201041850885; Witten I. H., 2000, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	13	9	9	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0824-7935		COMPUT INTELL	Comput. Intell.	MAY	2006	22	2					100	109		10.1111/j.1467-8640.2006.00276.x		10	Computer Science, Artificial Intelligence	Computer Science	043YG	WOS:000237638300003	
J	Kennedy, A; Inkpen, D				Kennedy, Alistair; Inkpen, Diana			Sentiment classification of movie reviews using contextual valence shifters	COMPUTATIONAL INTELLIGENCE			English	Article; Proceedings Paper	Workshop on Formal and Informal Information Exchange in Negotiations	MAY 26-27, 2005	Ottawa, CANADA		Univ of Ottawa	sentiment classification; semantic orientation; valence shifters; machine learning; evaluation		We present two methods for determining the sentiment expressed by a movie review. The semantic orientation of a review can be positive, negative, or neutral. We examine the effect of valence shifters on classifying the reviews. We examine three types of valence shifters: negations, intensifiers, and diminishers. Negations are used to reverse the semantic polarity of a particular term, while intensifiers and diminishers are used to increase and decrease, respectively, the degree to which a term is positive or negative. The first method classifies reviews based on the number of positive and negative terms they contain. We use the General Inquirer to identify positive and negative terms, as well as negation terms, intensifiers, and diminishers. We also use positive and negative terms from other sources, including a dictionary of synonym differences and a very large Web corpus. To compute corpus-based semantic orientation values of terms, we use their association scores with a small group of positive and negative terms. We show that extending the term-counting method with contextual valence shifters improves the accuracy of the classification. The second method uses a Machine Learning algorithm, Support Vector Machines. We start with unigram features and then add bigrams that consist of a valence shifter and another word. The accuracy of classification is very high, and the valence shifter bigrams slightly improve it. The features that contribute to the high accuracy are the words in the lists of positive and negative terms. Previous work focused on either the term-counting method or the Machine Learning method. We show that combining the two methods achieves better results than either method alone.	Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada	Kennedy, A (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.						AIT-MOKHTAR S, 2002, NAT LANG ENG, V8, P121; BAI X, 2004, P INT WORKSH MIN SEM, P24; Beineke P., 2004, P 42 ANN M ASS COMP, P263, DOI 10.3115/1218955.1218989; CLARKE CLA, 2003, P 26 ANN INT ACM SIG, P427; Gamon M., 2004, P 20 INT C COMP LING, P841, DOI 10.3115/1220355.1220476; HAYAKAWA SI, 1994, CHOOSE RIGHT WORD; INKPEN DZ, 2005, INFORMATION RETRIEVA, V20, P187; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI DOI 10.1145/775047.775067; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Manning C. D., 1999, FDN STAT NATURAL LAN; Mckeown K. R., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640; Ogilvie D. M., 1966, GEN INQUIRER COMPUTE; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Pang B., 2004, P 42 ANN M ASS COMP, P271, DOI DOI 10.3115/1218955.1218990; POLANYI L, 2004, INFORM RETRIEVAL SER, V20, P1; Riloff E, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P105; STOYANOV V, 2004, INFORMATION RETRIEVA, V20, P77; Taboada M., 2004, P AAAI SPRING S EXPL, P158; Turney P., 2002, P 40 ANN M ASS COMP, P417; Turney P., 2002, ERB1094 NAT RES COUN; Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013; Wiebe J, 2004, COMPUT LINGUIST, V30, P277, DOI 10.1162/0891201041850885; Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619; Yu H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P129	24	46	51	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0824-7935		COMPUT INTELL-US	Comput. Intell.	MAY	2006	22	2					110	125		10.1111/j.1467-8640.2006.00277.x		16	Computer Science, Artificial Intelligence	Computer Science	043YG	WOS:000237638300004	
J	Ling, CX; Yang, Q				Ling, CX; Yang, Q			Discovering classification from data of multiple sources	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						new solutions for multiple data source mining; learning from multiple sources of data; learning classifications from unlabeled data of multiple sources		In many large e-commerce organizations, multiple data sources are often used to describe the same customers, thus it is important to consolidate data of multiple sources for intelligent business decision making. In this paper, we propose a novel method that predicts the classification of data from multiple sources without class labels in each source. We test our method on artificial and real-world datasets, and show that it can classify the data accurately. From the machine learning perspective, our method removes the fundamental assumption of providing class labels in supervised learning, and bridges the gap between supervised and unsupervised learning.	Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China	Ling, CX (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	cling@csd.uwo.ca; qyang@cs.ust.hk					Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Church Kenneth W., 1989, P 27 ANN M ASS COMP, P76, DOI 10.3115/981623.981633; DESA VR, 1994, PROCEEDINGS OF THE 1993 CONNECTIONIST MODELS SUMMER SCHOOL, P300; DESA VR, 1994, ADV NEURAL INFORMATI, V6, P112; DESA VR, 1998, NEURAL COMPUTATION, V10; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LU SCY, 1987, ARTIF INTELL, V1, P109; Murphy P.M., 1992, UCI REPOSITORY MACHI; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354805; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Raskutti B., 2002, P 8 ACM SIGKDD INT C, P620; Reich Y., 1992, International Journal of Expert Systems Research and Applications, V5; REICH Y, 1992, ECOBWEB PRELIMINARY; REICH Y, 1991, CONCEPT FORMATION KN; SINKKONEN J, 2004, P 15 EUR C MACH LEAR, P396; Turney P.D., 1993, P EUR C MACH LEARN, P402; Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353; YAO Y, 2002, P 9 INT C NEUR INF P, P2228; Zhang Peilin, 2003, Mol Cancer, V2, P1, DOI 10.1186/1476-4598-2-1	21	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					181	201		10.1007/s10618-005-0013-7		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600004	
J	Zhu, XQ; Wu, XD; Chen, QJ				Zhu, XQ; Wu, XD; Chen, QJ			Bridging local and global data cleansing: Identifying class noise in large, distributed data datasets	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						data cleansing; class noise; machine learning	LEARNING ALGORITHMS; RULE	To cleanse mislabeled examples from a training dataset for efficient and effective induction, most existing approaches adopt a major set oriented scheme: the training dataset is separated into two parts (a major set and a minor set). The classifiers learned from the major set are used to identify noise in the minor set. The obvious drawbacks of such a scheme are twofold: (1) when the underlying data volume keeps growing, it would be either physically impossible or time consuming to load the major set into the memory for inductive learning; and (2) for multiple or distributed datasets, it can be either technically infeasible or factitiously forbidden to download data from other sites (for security or privacy reasons). Therefore, these approaches have severe limitations in conducting effective global data cleansing from large, distributed datasets. In this paper, we propose a solution to bridge the local and global analysis for noise cleansing. More specifically, the proposed effort tries to identify and eliminate mislabeled data items from large or distributed datasets through local analysis and global incorporation. For this purpose, we make use of distributed datasets or partition a large dataset into subsets, each of which is regarded as a local subset and is small enough to be processed by an induction algorithm at one time to construct a local model for noise identification. We construct good rules from each subset, and use the good rules to evaluate the whole dataset. For a given instance I-k , two error count variables are used to count the number of times it has been identified as noise by all data subsets. The instance with higher error values will have a higher probability of being a mislabeled example. Two threshold schemes, majority and non-objection, are used to identify and eliminate the noisy examples. Experimental results and comparative studies on both real-world and synthetic datasets are reported to evaluate the effectiveness and efficiency of the proposed approach.	Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA	Zhu, XQ (reprint author), Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA.	xqzhu@cs.uvm.edu; xwu@cs.uvm.edu; qchen@cs.uvm.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Bruha I, 1996, INT J PATTERN RECOGN, V10, P939, DOI 10.1142/S0218001496000530; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; Cestnik B, 1987, PROGR MACHINE LEARNI, P31; CHAN PK, 1996, THESIS COLUMBIA U; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; CLARK P, 1991, P 5 ECML; DIETTERICH T, 2000, LECT NOTES COMPUTER, V1867, P1; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P181; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; Gamberger D., 1999, P 16 INT C MACH LEAR, P143; Gamberger D, 2000, APPL ARTIF INTELL, V14, P205, DOI 10.1080/088395100117124; Grzymala-Busse J. W., 2000, ROUGH SETS CURRENT T, P378; HALL L, 2000, KDD 00 WORKSH DISTR, P79; Holte R.C., 1993, MACHINE LEARNING, V11; HUANG CC, 2001, P 2001 NAT COMP S TA; John G. H., 1995, P 1 INT C KNOWL DISC, P174; Kononenko I., 1984, EXPT AUTOMATIC LEARN; KUBICA J, 2003, P ICDM FL US; Lewis D, 1994, P 11 INT C MACH LEAR, P148; LI, 2002, P INT C DAT MIN ICDM; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; OAK N, 1993, P IEEE INT JOINT C N, P171; OAK N, 1996, P AAAI 96 WORKSH INT, P95; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; SCHAEFER P, 1990, EARTH ISL J, V5, P2; SHAPIRO A, 1983, THESIS U EDINBURGH; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; SRINIVASAN A, 1992, P 2 IND LOG PROGR WO, P97; Teng C.M., 1999, P 16 INT C MACH LEAR, P239; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VERBAETEN S, 2002, P BEN ANN MACH LEARN; Weisberg S., 1980, APPL LINEAR REGRESSI; WEISS G M, 1995, P 12 INT C MACH LEAR, P558; WEISS GM, 1998, P 15 INT C MACH LEAR, P574; WHITAKER A, 1999, CSE573; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Winston P. H., 1975, PSYCHOL COMPUTER VIS; Wu X., 1995, KNOWLEDGE ACQUISITIO; Wu XD, 1998, J AM SOC INFORM SCI, V49, P435, DOI 10.1002/(SICI)1097-4571(19980415)49:5<435::AID-ASI6>3.0.CO;2-R; ZHAO Q, 1995, J ARTIF INTELL RES, V3, P119; ZHU X, 2004, P 19 NAT C ART INT A; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8; *IBM ALM RES, IBM SYNTH DAT	53	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	MAY	2006	12	2-3					275	308		10.1007/s10618-005-0012-8		34	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	039FY	WOS:000237292600008	
J	Shin, HJ; Cho, S				Shin, HJ; Cho, S			Response modeling with support vector machines	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						response modeling; direct marketing; support vector machines (SVMs); pattern selection; class imbalance; scoring	FAST PATTERN SELECTION; NEURAL-NETWORKS; CLASSIFIERS; RECOGNITION	Support Vector Machine (SVM) employs Structural Risk Minimization (SRM) principle to generalize better than conventional machine learning methods employing the traditional Empirical Risk Minimization (ERM) principle. When applying SVM to response modeling in direct marketing, however, one has to deal with the practical difficulties: large training data, class imbalance and scoring from binary SVM output. For the first difficulty, we propose a way to alleviate or solve it through. a novel informative sampling. For the latter two difficulties, we provide guidelines within SVM framework so that one can readily use the paper as a quick reference for SVM response modeling: use of different costs for different classes and use of distance to decision boundary, respectively. This paper also provides various evaluation measures for response models in terms of accuracies, lift chart analysis, and computational efficiency. (c) 2005 Elsevier Ltd. All rights reserved.	Seoul Natl Univ, Coll Engn, Dept Ind Engn, Seoul 151744, South Korea; Max Planck Soc, Friedrich Miescher Lab, D-72076 Tubingen, Germany	Cho, S (reprint author), Seoul Natl Univ, Coll Engn, Dept Ind Engn, 56-1,Shillim Dong, Seoul 151744, South Korea.	hyunjung.shin@tuebingen.mpg.de; zoon@snu.ac.kr					Almeida M.B., 2000, P 6 BRAZ S NEUR NETW, P162; Bentz Y, 2000, J FORECASTING, V19, P177, DOI 10.1002/(SICI)1099-131X(200004)19:3<177::AID-FOR738>3.0.CO;2-6; Bounds D, 1997, HDB NEURAL COMPUTATI, P1; Byun H, 2002, LECT NOTES COMPUT SC, V2388, P213; Cauwenberghs G, 2001, ADV NEUR IN, V13, P409; Cheung KW, 2003, DECIS SUPPORT SYST, V35, P231, DOI 10.1016/S0167-9236(02)00108-2; Chiu CC, 2002, EXPERT SYST APPL, V22, P163, DOI 10.1016/S0957-4174(01)00052-5; Coenen F, 2000, EXPERT SYST APPL, V18, P307, DOI 10.1016/S0957-4174(00)00012-9; COLOMBO R, 1999, J INTERACT MARK, V13, P1; Cristianini N., 2000, INTRO SUPPORT VECTOR; DEICHMANN J, 2002, J INTERACTIVE MARKET, V16, P15, DOI 10.1002/dir.10040; Dumais S, 1998, IEEE INTELL SYST APP, V13, P21; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Ha K, 2005, J INTERACT MARK, V19, P17, DOI 10.1002/dir.20028; HARA K, 2000, P IEEE INNS ENNS INT, V3, P543, DOI 308148295,12,1; Haughton D., 1997, J DIRECT MARKETING, V11, P42, DOI 10.1002/(SICI)1522-7138(199723)11:4<42::AID-DIR7>3.0.CO;2-W; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; HEISELE B, 2000, 1687 AI MIT; Hosmer DW, 1989, APPL LOGISTIC REGRES; Japkowicz N., 2000, AAAI WORKSH LEARN IM; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Lee K. K., 2001, P INNS IEEE INT JOIN, P2410; Levin N., 1997, J DIRECT MARKETING, V11, P76, DOI 10.1002/(SICI)1522-7138(199723)11:4<76::AID-DIR10>3.0.CO;2-D; Lingjaerde O, 1998, ACTA PSYCHIAT SCAND, V98, P73, DOI 10.1111/j.1600-0447.1998.tb10045.x; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Lyhyaoui A, 1999, IEEE T NEURAL NETWOR, V10, P1474, DOI 10.1109/72.809092; Malthouse E. C., 2002, J INTERACTIVE MARKET, V16, P10; Malthouse E. C., 2001, J INTERACTIVE MARKET, V15, P49, DOI 10.1002/1520-6653(200124)15:1<49::AID-DIR1003>3.3.CO;2-6; Malthouse EC, 1999, J INTERACT MARK, V13, P10, DOI 10.1002/(SICI)1520-6653(199923)13:4<10::AID-DIR2>3.0.CO;2-3; Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), DOI 10.1109/AFGR.2000.840651; MOUTINHO L, 1994, NEURAL NETWORK MARKE; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Pontil M, 1998, NEURAL COMPUT, V10, P955, DOI 10.1162/089976698300017575; POTHARST R, 2001, 77 ERIM ER U; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Choi SH, 2002, IEEE T SYST MAN CY B, V32, P202, DOI 10.1109/3477.990876; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B., 1995, P 1 INT C KNOWL DISC, P252; Scholkopf B., 1999, ADV KERNEL METHODS S; Sen A., 1990, SPRINGER TEXTS STAT; Shin H, 2003, LECT NOTES COMPUT SC, V2690, P1008; Shin H., 2001, J KOREAN I IND ENG, V28, P112; Shin H, 2003, IEEE IJCNN, P565; Shin H, 2003, LECT NOTES ARTIF INT, V2637, P376; Shin HJ, 2002, LECT NOTES COMPUT SC, V2412, P469; Suh EH, 1999, EXPERT SYST APPL, V17, P89, DOI 10.1016/S0957-4174(99)00026-3; Vapnik V.N., 1999, NATURE STAT LEARNING; Viaene S., 2001, International Journal of Intelligent Systems in Accounting, Finance and Management, V10, DOI 10.1002/isaf.195; Viaene S, 2001, INT J INTELL SYST, V16, P1023, DOI 10.1002/int.1047; Zahavi J., 1997, J DIRECT MARKETING, V11, P63, DOI 10.1002/(SICI)1522-7138(199723)11:4<63::AID-DIR9>3.0.CO;2-U; *SAS I INC, 1998, ENT MIN PREM	52	26	26	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2006	30	4					746	760		10.1016/j.eswa.2005.07.037		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	022IH	WOS:000236048400019	
J	Tserpes, G; Moutopoulos, DK; Peristeraki, P; Katselis, G; Koutsikopoulos, C				Tserpes, G; Moutopoulos, DK; Peristeraki, P; Katselis, G; Koutsikopoulos, C			Study of swordfish fishing dynamics in the eastern Mediterranean by means of machine-learning approaches	FISHERIES RESEARCH			English	Article; Proceedings Paper	International Workshop on Management of Tropical Coastal Fisheries in Asia	MAR, 2001	Penang, MALAYSIA	Worldfish Ctr		swordfish; machine learning; fishery; Mediterranean	XIPHIAS-GLADIUS; FISHERIES; FLEET; DEFINITION; STRATEGIES; TYPOLOGY; CATCH; AGE; ATLANTIC; TACTICS	We analyzed fisheries data collected in 2000 and 2001 from the Greek swordfish fishing fleets operating in the eastern Mediterranean, by means of machine-learning approaches, in order to define differences in exploitation patterns and fishing strategies. Based on their total annual catch, fishing vessels have been classified in three groups: low, medium and high producers. Decision-tree analysis revealed that group membership could be successfully predicted from the total number of working days per year, the vessel length, the type of gear used, the hook size and the number of hooks per set. Using the data of 2001 as a test data set and assuming that only the average catch of the most productive group was known, total production estimates for that year showed very little difference (7.92%) from the true values. These findings indicate that simple sampling schemes focusing on the high producers may be adequate for the examined fisheries. They also provide evidence that such methodological approaches could be useful for the cross-checking of fisheries estimates obtained through various sampling schemes. (c) 2006 Elsevier B.V. All rights reserved.	Hellen Ctr Marine Res, GR-71003 Iraklion, Greece; Univ Patras, Dept Biol, Sect Anim Biol, GR-26500 Patras, Greece; Technol Educ Inst Messolonghi, Dept Aquaculture & Fisheries Technol, GR-30200 Messolonghi, Greece	Tserpes, G (reprint author), Hellen Ctr Marine Res, POB 2214, GR-71003 Iraklion, Greece.	gtserpes@her.hcmr.gr					Biseau A, 1998, AQUAT LIVING RESOUR, V11, P119, DOI 10.1016/S0990-7440(98)80109-5; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Brookfield K, 2005, FISH RES, V72, P55, DOI 10.1016/j.fishres.2004.10.010; Cavallaro G., 1991, COL VOL SCI PAP ICCA, V35, P502; De la Serna J. M., 1996, COL VOL SCI PAP ICCA, V45, P117; DINATALE A, 2002, COL VOL SCI PAP ICCA, V54, P1529; EHRHARDT NM, 1992, B MAR SCI, V50, P292; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; He X, 1997, FISH RES, V31, P147, DOI 10.1016/S0165-7836(96)00564-4; HILBORN R, 1985, CAN J FISH AQUAT SCI, V42, P51, DOI 10.1139/f85-007; Jabeur C, 2000, AQUAT LIVING RESOUR, V13, P421; KATSELIS G, 2001, P 10 HELL ICHTH C, P17; KATSELIS G, 2000, P 5 HELL C OC, P130; Kotoulas G., 2003, COL VOL SCI PAPERS I, V55, P1632; KOTOULAS G, 1995, MOL ECOL, V4, P473, DOI 10.1111/j.1365-294X.1995.tb00241.x; LALOE F, 1996, FISH RES, V37, P193; LAUREC A, 1991, ICES MAR SC, V193, P225; LAUREC A, 1983, J CONSEIL, V41, P81; Le Pape O, 2001, ICES J MAR SCI, V58, P1232, DOI 10.1006/jmsc.2001.1121; LEWY P, 1994, ICES J MAR SCI, V51, P263, DOI 10.1006/jmsc.1994.1027; Marchal P, 1996, AQUAT LIVING RESOUR, V9, P81, DOI 10.1051/alr:1996011; Maury O, 2001, AQUAT LIVING RESOUR, V14, P203, DOI 10.1016/S0990-7440(01)01115-9; Maynou F, 2003, FISH RES, V65, P257, DOI 10.1016/j.fishres.2003.09.018; MESNIL B, 1990, J CONSEIL, V47, P115; Millischer L, 1999, AQUAT LIVING RESOUR, V12, P89, DOI 10.1016/S0990-7440(99)80019-9; Mitchell T, 1997, MACHINE LEARNING; MURAWSKI SA, 1986, CAN J FISH AQUAT SCI, V43, P90, DOI 10.1139/f86-010; PALKO RJ, 1981, 441 NOAA NMFS; Papaconstantinou C., 2000, Mediterranean Marine Science, V1, P5; Pelletier D, 2000, CAN J FISH AQUAT SCI, V57, P51, DOI 10.1139/cjfas-57-1-51; Peristeraki P., 2004, COL VOL SCI PAP ICCA, V56, P860; Quinlan R, 1992, MACH LEARN, V1, P81; Quinlan R., 1993, C4 5 PROGR MACH LEAR; ROGERS JB, 1992, CAN J FISH AQUAT SCI, V49, P2648, DOI 10.1139/f92-293; Salas S, 2004, FISH FISH, V5, P153, DOI 10.1111/j.1467-2979.2004.00146.x; Silva L, 2002, FISH RES, V59, P117, DOI 10.1016/S0165-7836(01)00420-9; SMITH C L, 1986, North American Journal of Fisheries Management, V6, P88, DOI 10.1577/1548-8659(1986)6<88:SAG>2.0.CO;2; Stergiou KI, 2003, SCI MAR, V67, P283; Taquet M, 1997, AQUAT LIVING RESOUR, V10, P137, DOI 10.1051/alr:1997015; Tserpes G., 2003, CIESM Workshop Monographs, V22, P101; Tserpes G, 1999, AQUAT LIVING RESOUR, V12, P167, DOI 10.1016/S0990-7440(00)88468-5; TSERPES G, 2001, COL VOL SCI PAP ICCA, V52, P733; TSERPES G, 2003, COL VOL SCI PAP ICCA, V55, P94; Tserpes G., 2001, COLLECTIVE VOLUME SC, V52, P740; TSERPES G, 1995, FISH B-NOAA, V93, P594; Tzanatos E, 2005, FISH RES, V73, P147, DOI 10.1016/j.fishres.2004.12.006; Ulrich C, 2001, AQUAT LIVING RESOUR, V14, P267, DOI 10.1016/S0990-7440(01)01132-9; WILLIAMS BK, 1983, ECOLOGY, V64, P1283, DOI 10.2307/1937836; Witten I. H., 2000, DATA MINING PRACTICA; 2003, INT COMMISSION CONSE, P101	51	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-7836		FISH RES	Fish Res.	MAY	2006	78	2-3					196	202		10.1016/j.fishres.2005.11.022		7	Fisheries	Fisheries	040LJ	WOS:000237379800010	
J	Stefanowski, J				Stefanowski, Jerzy			An empirical study of using rule induction and rough sets to software cost estimation	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	Workshop on Theory and Applications of Soft Computing (TASC04)	NOV, 2004	Warsaw, POLAND		Polish/Japanese Inst Informat Technol	software engineering; rough sets; machine learning; preference modeling; software cost prediction; COCOMO model	PREDICTION	This paper concerns problems of applying the approach based on rough sets and rule induction to a software engineering data analysis. More precisely, we focus our interest on a software cost estimation problem, which includes predicting the effort required to develop a software system basing on values of cost factors. The case study of analysing the COCOMO data set, containing descriptions of representative historical projects, allows us to discuss how this approach could be used to: identify the most discriminatory cost factors, extract meaningful rule representation of classification knowledge from data, construct accurate rule based classifiers.	Poznan Univ Technol, Inst Comp Sci, PL-60965 Poznan, Poland	Stefanowski, J (reprint author), Wyzsza Szkola Bankowa Poznaniu, Al Niepodleglosci 2, PL-61874 Poznan, Poland.	Jerzy.Stefanowski@cs.put.poznan.pl					BASILI VR, 1988, IEEE T SOFTWARE ENG, V14, P758, DOI 10.1109/32.6156; BASZCZYNSKI J, 2003, P 3 INT C DEC SUPP T; BAZAN J, 1995, SOFT COMPUTING ROUGH, P276; BOEHM B, 1996, AM PROGRAM, P2; Boehm B.W., 1981, SOFTWARE ENG EC; BRIAND LC, 1992, IEEE T SOFTWARE ENG, V18, P931, DOI 10.1109/32.177363; Greco S, 2002, LECT NOTES ARTIF INT, V2475, P255; Greco S., 2002, HDB DATA MINING KNOW, P318; Greco S., 2000, LECT NOTES ARTIF INT, V2005, P304; GRECO S, 1999, ADV MULTIPLE CRITERI, pCH14; Grzymala-Busse J. W., 1992, INTELLIGENT DECISION, P3; Grzymala-Busse JW, 2001, INT J INTELL SYST, V16, P29, DOI 10.1002/1098-111X(200101)16:1<29::AID-INT4>3.0.CO;2-0; Grzymala-Busse J.W., 1994, P 3 INT S INT SYST, P70; KEMERER CF, 1987, COMMUN ACM, V30, P416, DOI 10.1145/22899.22906; Klosgen W., 2002, HDB DATA MINING KNOW; Komorouski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; LEUNG H, 2002, HDB SOFTWARE ENG KNO, pCH23; Mair C, 2000, J SYST SOFTWARE, V53, P23, DOI 10.1016/S0164-1212(00)00005-4; Michalski R. S., 1998, MACHINE LEARNING DAT; Mitchell T, 1997, MACHINE LEARNING; Pawlak Z., 1991, ROUGH SETS THEORETIC; Peters JF, 2003, SOFTWARE QUAL J, V11, P121, DOI 10.1023/A:1023764510838; Polkowski L., 2002, ADV SOFT COMPUTING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; R Slowinski, 1992, HDB APPL ADV ROUGH S, P445; Ramanna S, 2002, LECT NOTES ARTIF INT, V2475, P602; RUHE G, 1996, P 4 INT WORKSH ROUGH, P293; Ruhe G, 1996, PROCEEDINGS OF THE 3RD INTERNATIONAL SOFTWARE METRICS SYMPOSIUM, P10, DOI 10.1109/METRIC.1996.492439; Skowron A., 1993, LECT NOTES ARTIF INT, V689, P295; Stefanowski J., 1998, P 6 EUR C INT TECHN, P109; Stefanowski J., 1998, ROUGH SETS KNOWLEDGE, V1, P500; STEFANOWSKI J, 2001, INT J INTELL SYST, V16, P11; STEFANOWSKI J, 2001, SERIES ROZPRAWY POZN, V361	33	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	MAY	2006	71	1					63	82				20	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	066SV	WOS:000239251300007	
J	Kung, SY; Mak, MW				Kung, SY; Mak, MW			Machine learning for multimodality genomic signal processing	IEEE SIGNAL PROCESSING MAGAZINE			English	Editorial Material							EXPRESSION		Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA; Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China	Kung, SY (reprint author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.						Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; Cheng Y, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P93; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; GREEN DM, 1988, SIGNAL DETECTION THE; Kasturi J, 2005, BIOINFORMATICS, V21, P423, DOI 10.1093/bioinformatics/bti186; KUNG SY, 2006, J BIOINFORM COMPUTAT, V4; Kung SY, 2005, BIOMETRIC AUTHENTICA; Park PJ, 2002, BIOINFORMATICS, V18, P1576, DOI 10.1093/bioinformatics/18.12.1576; Roth FP, 1998, NAT BIOTECHNOL, V16, P939, DOI 10.1038/nbt1098-939; Vapnik VN, 1998, STAT LEARNING THEORY	10	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-5888		IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	MAY	2006	23	3					117	121				5	Engineering, Electrical & Electronic	Engineering	040FW	WOS:000237365400018	
J	Huang, KZ; Yang, HQ; King, I; Lyu, MR				Huang, KZ; Yang, HQ; King, I; Lyu, MR			Maximizing sensitivity in medical diagnosis using biased minimax probability machine	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						biased classification; medical diagnosis; minimax probability machine; worst case accuracy	ACCURACY	The challenging task of medical diagnosis based on machine learning techniques requires an inherent bias, i.e., the diagnosis should favor the "ill" class over the "healthy" class, since misdiagnosing a patient as a healthy person may delay the therapy and aggravate the illness. Therefore, the objective in this task is not to improve the overall accuracy of the classification, but to focus on improving the sensitivity (the accuracy of the "ill" class) while maintaining an acceptable specificity (the accuracy of the "healthy" class). Some current methods adopt roundabout wavs to impose a certain bias toward the important class, i.e., they try to utilize some intermediate factors to influence the classification. However, it remains uncertain whether these methods can improve the classification performance systematically. In this paper, by engaging a novel learning tool, the biased minimax probability machine (BMPM), we deal with the issue in a more elegant way and directly achieve the objective of appropriate medical diagnosis. More specifically, the BMPM directly controls the worst case accuracies to incorporate a bias toward the "ill" class. Moreover, in a distribution-free way, the BMPM derives the decision rule in such a way as to maximize the worst case sensitivity while maintaining an acceptable worst case specificity. By directly controlling the accuracies, the BMPM provides a more rigorous way to handle medical diagnosis; by deriving a distribution-free decision rule, the BMPM distinguishes itself from a large family of classifiers, namely, the generative classifiers, where an assumption on the data distribution is necessary. We evaluate the performance of the model and compare it with three traditional classifiers: the k-nearest neighbor, the naive Bayesian, and the C4.5. The test results on two medical datasets, the breast-cancer dataset and the heart disease dataset, show that the BMPM outperforms the other three models.	Fujitsu Res & Dev Ctr Co Ltd, Informat Technol Lab, Beijing 100016, Peoples R China; Titanium Technol Ltd, Shenzhen 51820, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Huang, KZ (reprint author), Fujitsu Res & Dev Ctr Co Ltd, Informat Technol Lab, Beijing 100016, Peoples R China.	kzhuang@frdc.fujitsu.com; austin.yang@titanium-tech.com; king@cse.cuhk.edu.hk; lyu@cse.cuhk.edu.hk					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAIRAGI R, 1989, SANKHYA SER B, V51, P263; Bertsekas DP, 1999, NONLINEAR PROGRAMMIN; Blake C. L., 1998, UCI REPOSITORY MACHI; BREIMAN L, 1997, 460 U CAL ARC CLASS; Cardie C., 1997, P 14 INT C MACH LEAR, P57; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; DORFMAN DD, 1992, INVEST RADIOL, V27, P723, DOI 10.1097/00004424-199209000-00015; Grzymala-Buuse JW, 2003, PATTERN RECOGN LETT, V24, P903, DOI 10.1016/S0167-8655(02)00202-7; HINKLEY D, 1983, ENCY STATISTICAL SCI, V4, P280; HUANG K, 2004, P 8 INT S ART INT MA; HUANG K, 2004, NEURAL INFORMATION P, P94; Huang K., 2003, P INT JOINT C NEUR N, V1, P484; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; JAAKKOLA TS, 1998, ADV NEURAL INFORMATI; JORDAN MI, 1995, 9503 MIT COMP COGN S; KOHAVI R, 1995, P 14 INT JOINT C ART, P338; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Lanckriet G. R. G., 2002, J MACHINE LEARNING R, V3, P555; Langley P., 1992, P 10 NAT C ART INT, P223; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; Maloof MA, 2003, MACH LEARN, V53, P157, DOI 10.1023/A:1025623527461; Maloof M. A., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1048273; MCCLISH DK, 1989, MED DECIS MAKING, V9, P190, DOI 10.1177/0272989X8900900307; Nesterov Y., 1994, STUDIES APPL MATH; PROVOST F, 2000, P 17 NAT C ART INT A; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SCHAIBLE S, 1995, FRACTIONAL PROGRAMMI; Scholkopf B., 2002, LEARNING KERNELS; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; West D, 2000, ARTIF INTELL MED, V20, P183, DOI 10.1016/S0933-3657(00)00063-4; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027	35	14	14	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	MAY	2006	53	5					821	831		10.1109/TBME.2006.872819		11	Engineering, Biomedical	Engineering	037LB	WOS:000237147200006	
J	Lu, RZ; Radke, RJ; Hong, L; Chui, CS; Xiong, JP; Yorke, E; Jackson, A				Lu, RZ; Radke, RJ; Hong, L; Chui, CS; Xiong, JP; Yorke, E; Jackson, A			Learning the relationship between patient geometry and beam intensity in breast intensity-modulated radiotherapy	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						IMRT; intensity-modulated radiotherapy; machine learning	RADIATION-THERAPY; OPTIMIZATION; IMRT; DISTRIBUTIONS; IRRADIATION	Intensity modulated radiotherapy (IMRT) has become an effective tool for cancer treatment with radiation. However, even expert radiation planners still need to spend a substantial amount of time adjusting IMRT optimization parameters in order to get a clinically acceptable plan. We demonstrate that the relationship between patient geometry and radiation intensity distributions can be automatically inferred using a variety of machine learning techniques in the case of two-field breast IMRT. Our experiments show that given a small number of human-expert-generated clinically acceptable plans, the machine learning predictions produce equally acceptable plans in a matter of seconds. The machine learning approach has the potential for greater benefits in sites where the IMRT planning process is more challenging or tedious.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; Mem Sloan Kettering Canc Ctr, Dept Med Phys, New York, NY 10021 USA	Radke, RJ (reprint author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.	lur@rpi.edu; rjradke@ecse.rpi.edu; lhong@montefiore.org; chuic@mskcc.org; xiongj@mskcc.org; yorkee@mskcc.org; jacksona@mskcc.org					Alber M, 2002, MED PHYS, V29, P2584, DOI 10.1118/1.1500402; Amols HI, 2002, INT J RADIAT ONCOL, V52, P1, DOI 10.1016/S0360-3016(01)02586-X; Barbiere J, 2002, J Appl Clin Med Phys, V3, P227, DOI 10.1120/1.1492195; Bortfeld T, 2004, MED PHYS, V31, P1761; Chatterjee S., 2000, REGRESSION ANAL EXAM; Cherkassky V, 1998, LEARNING DATA; Chui CS, 2002, MED PHYS, V29, P522, DOI 10.1118/1.1460875; Chui CS, 2005, INT J RADIAT ONCOL, V62, P1217, DOI 10.1016/j.ijrobp.2005.03.040; CHUI CS, 1986, MED PHYS, V13, P409, DOI 10.1118/1.595886; CHUI CS, 1994, MED PHYS, V21, P1231; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Cotrutz C, 2001, PHYS MED BIOL, V46, P2161, DOI 10.1088/0031-9155/46/8/309; de Berg M, 2000, COMPUTATIONAL GEOMET; Duda R. O., 2001, PATTERN CLASSIFICATI; Freedman D, 2005, IEEE T MED IMAGING, V24, P281, DOI 10.1109/TMI.2004.841228; Goodman KA, 2004, INT J RADIAT ONCOL, V60, P95, DOI 10.1016/j.ijrobp.2004.02.016; Hong L, 1999, INT J RADIAT ONCOL, V44, P1155, DOI 10.1016/S0360-3016(99)00132-7; Hunt MA, 2002, INT J RADIAT ONCOL, V54, P953, DOI 10.1016/S0360-3016(02)03004-3; Kestin LL, 2000, INT J RADIAT ONCOL, V48, P1559, DOI 10.1016/S0360-3016(00)01396-1; Khan FM, 2003, PHYS RAD THERAPY; Kutner M. H., 2004, APPL LINEAR REGRESSI; Ling C. C., 2004, PRACTICAL GUIDE INTE; Mackie TR, 2003, INTENSITY MODULATED; Meyer J, 2004, PHYS MED BIOL, V49, P1637, DOI 10.1088/0031-9155/49/9/004; Perez C, 2004, PRINCIPLES PRACTICE; Romeijn HE, 2004, PHYS MED BIOL, V49, P1991, DOI 10.1088/0031-9155/49/10/011; SCHELL M C, 1979, Medical Physics (Woodbury), V6, P65; Strom EA, 2002, INT J RADIAT ONCOL, V54, P1297, DOI 10.1016/S0360-3016(02)03744-6; Thomas SJ, 1999, BRIT J RADIOL, V72, P781; TSAI A, 2003, IEEE T MED IMAG, V22; van Asselen B, 2001, RADIOTHER ONCOL, V58, P341, DOI 10.1016/S0167-8140(00)00278-4; Vapnic V., 1995, NATURE STAT LEARNING; Vicini FA, 2002, INT J RADIAT ONCOL, V54, P1336, DOI 10.1016/S0360-3016(02)03746-X; Xing L, 1999, PHYS MED BIOL, V44, P2525, DOI 10.1088/0031-9155/44/10/311; Yu Y, 1997, MED PHYS, V24, P1445, DOI 10.1118/1.598033; *AM ASS PHYS MED, 2004 SAL SURV PROF R	36	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	MAY	2006	53	5					908	920		10.1109/TBME.2005.863987		13	Engineering, Biomedical	Engineering	037LB	WOS:000237147200015	
J	Yang, Q; Ling, C; Chai, XY; Pan, R				Yang, Q; Ling, C; Chai, XY; Pan, R			Test-cost sensitive classification on data with missing values	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						cost-sensitive learning; decision trees; naive Bayes	KNOWLEDGE	In the area of cost-sensitive learning, inductive learning algorithms have been extended to handle different types of costs to better represent misclassification errors. Most of the previous works have only focused on how to deal with misclassification costs. In this paper, we address the equally important issue of how to handle the test costs associated with querying the missing values in a test case. When an attribute contains a missing value in a test case, it may or may not be worthwhile to take the extra effort in order to obtain a value for that attribute, or attributes, depending on how much benefit the new value will bring about in increasing the accuracy. In this paper, we consider how to integrate test-cost-sensitive learning with the handling of missing values in a unified framework that includes model building and a testing strategy. The testing strategies determine which attributes to perform the test on in order to minimize the sum of the classification costs and test costs. We show how to instantiate this framework in two popular machine learning algorithms: decision trees and naive Bayesian method. We empirically evaluate the test-cost-sensitive methods for handling missing values on several data sets.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Yang, Q (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.	qyang@cs.ust.hk; cling@csd.wuo.ca; chai@cs.purdue.edu; panrong@cs.ust.hk					Blake C. L., 1998, UCI REPOSITORY MACHI; CHAI X, 2004, P 2004 IEEE INT C DA; Cormen T.H., 2001, INTRO ALGORITHMS; Domingos P., 1999, KNOWLEDGE DISCOVERY, P155; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R. O., 2001, PATTERN CLASSIFICATI; Elkan C., 2001, P 17 INT JOINT C ART, P973; Fayyad UM, 1993, MULTIINTERVAL DISCRE, P1022; Greiner R, 2002, ARTIF INTELL, V139, P137, DOI 10.1016/S0004-3702(02)00209-6; Kai M., 1998, PRINCIPLES DATA MINI, P139; LING C, 2004, P 2004 INT C MACH LE; Mitchell T, 1997, MACHINE LEARNING; NORTON S. W., 1989, P 11 INT JOINT C ART, P800; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; NUNEZ M, 1988, P 3 EUR WORK SESS LE, P139; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; TURNEY P, 2000, P WORKSH COST SENS L; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Zubek V., 2002, P 19 INT C MACH LEAR, P27	20	14	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2006	18	5					626	638				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	021MS	WOS:000235987900005	
J	Pedrycz, W; Reformat, M; Li, KW				Pedrycz, W; Reformat, M; Li, KW			OR/AND neurons and the development of interpretable logic models	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						AND logic operations; function decomposition; fuzzy logic network; fuzzy neurons; genetic algorithms; interactive network design; interpretation; OR; OR/AND fuzzy neuron; pruning	FUZZY SET CONNECTIVES; GENETIC ALGORITHMS; SYSTEMS; DESIGN	In this paper, we are concerned with the concept of fuzzy logic networks and logic-based data analysis realized within this framework. The networks under discussion are homogeneous architectures comprising of OR/AND neurons originally introduced by Hirota and Pedrycz. Being treated here as generic processing units, OR/AND neurons are neurofuzzy constructs that exhibit well-defined logic characteristics and are endowed with a high level of parametric flexibility and come with significant interpretation abilities. The composite logic nature of the logic neurons becomes instrumental in covering a broad spectrum of logic dependencies whose character spread in-between between those being captured by plain and and or logic descriptors (connectives). From the functional standpoint, the developed network realizes a logic approximation of multidimensional mappings between unit hypercubes, that is transformations from [0, 1](n) to [0, 1](m). The way in which the structure of the network has been formed is highly modular and becomes reflective of a general concept of decomposition of logic expressions and Boolean functions (as being commonly encountered in two-valued logic). In essence, given a collection of input variables, selected is their subset and transformed into new composite variable, which in turn is used in the consecutive module of the network. These intermediate synthetic variables are the result of the successive problem (mapping) decomposition. The development of the network is realized through genetic optimization. This helps address important issues of structural optimization (where we are concerned with a selection of a subset of variables and their allocation within the network) and reaching a global minimum when carrying out an extensive parametric optimization (adjustments of the connections of the neurons). The paper offers a comprehensive and user-interactive design procedure including a simple pruning mechanism whose intention is to enhance the interpretability of the network while reducing its size. The experimental studies comprise of three parts. First, we demonstrate the performance of the network on Boolean data (that leads to some useful comparative observations considering a wealth of optimization tools available in two-valued logic and digital systems). Second, we discuss synthetic multivalued data that helps focus on the approximation abilities of the network. Finally, show the generation of logic expressions describing selected data sets coming from the machine learning repository.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6R 2V4, Canada; Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada	Pedrycz, W (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6R 2V4, Canada.	pedrycz@ee.ualberta.ca; Marek.Reformat@ualberta.ca; kuwen@ece.ualberta.ca					ASHENHURST RL, 1959, P INT S THEOR SWITCH, P74; BHAT KVS, 1980, IEEE T SYST MAN CYB, V10, P637, DOI 10.1109/TSMC.1980.4308369; Blanco A, 2001, NEURAL NETWORKS, V14, P93, DOI 10.1016/S0893-6080(00)00081-2; Bioch J. C., 1999, Discrete Applied Mathematics, V96-97, DOI 10.1016/S0166-218X(99)00096-7; Carvalho D. R., 2002, Applied Soft Computing, V2, DOI 10.1016/S1568-4946(02)00031-5; Coello CAC, 2001, COMPUT ELECTR ENG, V27, P1; DRECHSLER R, 1998, EVOLUTIONARY ALGORIT; ESHELMAN LJ, 1993, FDN GENETIC ALGORITH, V2, P187; Fernandez F, 2004, MICROPROCESS MICROSY, V28, P363, DOI 10.1016/j.micpro.2004.03.017; Fernandez-Villacanas Martin J.-L., 2003, Future Generation Computer Systems, V19, DOI 10.1016/S0167-739X(02)00108-5; Goldberg DE, 1989, GENETIC ALGORITHMS S; HIROTA K, 1994, IEEE T FUZZY SYST, V2, P151, DOI 10.1109/91.277963; HIROTA K, 1994, FUZZY SET SYST, V68, P157, DOI 10.1016/0165-0114(94)90042-6; Jin YC, 2000, IEEE T FUZZY SYST, V8, P212, DOI 10.1109/91.842154; KANDEL A, 1974, INFORM CONTROL, V26, P141, DOI 10.1016/S0019-9958(74)90440-9; Kandel A., 1979, FUZZY SWITCHING AUTO; KANDEL A, 1976, IEEE T SYST MAN CYB, V6, P215; Michalewicz Z, 1994, GENETIC ALGORITHMS D; Paiva RP, 2004, FUZZY SET SYST, V147, P17, DOI 10.1016/j.fss.2003.11.012; Pedrycz W., 1998, INTRO FUZZY SETS ANA; Pedrycz W., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.251926; Roubos H, 2001, IEEE T FUZZY SYST, V9, P516, DOI 10.1109/91.940965; RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964; Schmitt LM, 1998, THEOR COMPUT SCI, V200, P101, DOI 10.1016/S0304-3975(98)00004-8; Schmitt LM, 2001, THEOR COMPUT SCI, V259, P1, DOI 10.1016/S0304-3975(00)00406-0; SCHWEDE GW, 1977, IEEE T SYST MAN CYB, V7, P669, DOI 10.1109/TSMC.1977.4309805; Wegener I., 1987, COMPLEXITY BOOLEAN F; ZIMMERMANN HJ, 1980, FUZZY SET SYST, V4, P37, DOI 10.1016/0165-0114(80)90062-7; 1991, HDB GENETIC ALGORITH	29	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2006	17	3					636	658		10.1109/TNN.2006.873285		23	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	042IK	WOS:000237521300009	
J	Chong, W; Wang, W				Chong, W; Wang, W			Links between PPCA and subspace methods for complete Gaussian density estimation	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Letter						complete Gaussian density estimation; eigenspace decomposition; probabilistic principal component analysis (PPCA); subspace method		High-dimensional density estimation is a fundamental problem in pattern recognition and machine learning areas. In this letter, we show that. for complete high-dimensional Gaussian density estimation, two widely used methods, probabilistic principal component analysis and a typical subspace method using eigenspace decomposition, actually give the same results. Additionally we present a unified view from the aspect of robust estimation of the covariance matrix.	Tsing Hua Univ, Dept Automat, Inst Informat Proc, Beijing 100084, Peoples R China	Chong, W (reprint author), Tsing Hua Univ, Dept Automat, Inst Informat Proc, Beijing 100084, Peoples R China.	chong99@mails.tsinghua.edu.cn					Campbell N. A., 1980, Applied Statistics, V29, DOI 10.2307/2346896; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Hampel F., 1986, ROBUST STAT APPROACH; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Moghaddam B., 1995, INT C COMP VIS; MOGHADDAM B, 1997, IEEE T PATTERN ANAL, V19, P96; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196	8	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2006	17	3					789	792		10.1109/TNN.2006.871718		4	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	042IK	WOS:000237521300020	
J	Wu, Y; Yu, T				Wu, Y; Yu, T			A field model for human detection and tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object detection; shape; Markov random fields; image models; machine learning; statistical computing; probabilistic algorithms	OBJECT DETECTION; FACE DETECTION; RECOGNITION; TEMPLATES; IMAGES	The large shape variability and partial occlusions challenge most object detection and tracking methods for nonrigid targets such as pedestrians. This paper presents a new approach based on a two-layer statistical field model that characterizes the prior of the complex shape variations as a Boltzmann distribution and embeds this prior and the complex image likelihood into a Markov field. A probabilistic variational analysis of this model reveals a set of fixed-point equations characterizing the equilibrium of the field. It leads to computationally efficient methods for calculating the image likelihood and for training the model. Based on that, effective algorithms for detecting nonrigid objects are developed. This new approach has several advantages. First, it is intrinsically suitable for capturing local nonrigidity. In addition, due to the distributed likelihood, this approach is robust to partial occlusions. Moreover, the two-layer structure provides large flexibility of modeling the image observations, which makes the new method robust to clutters. Extensive experiments demonstrate its effectiveness.	Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA	Wu, Y (reprint author), Northwestern Univ, Dept Elect & Comp Engn, 2145 Sheridan Rd, Evanston, IL 60208 USA.	yingwu@ece.northwestern.edu; tingyu@ece.northwestern.edu	Wu, Ying/B-7283-2009				Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Blake A., 1998, ACTIVE CONTOURS; Chui H., 2000, P IEEE C COMP VIS PA, V2; Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; COUGHLAN J, 2002, ECCV, V3, P453; Dalai N., 2005, P IEEE C COMP VIS PA, V1, P886, DOI DOI 10.1109/CVPR.2005.177; DAVIS L, 1998, P INT C PATT REC, V1, P77; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Gavrila D. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.791202; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Isard M, 1996, P EUR C COMP VIS, P343; Jaakkola T.S., 2000, TUTORIAL VARIATIONAL; JOJIC N, 2000, P IEEE C COMP VIS PA, V2, P26, DOI 10.1109/CVPR.2000.854728; JORDAN M, 2000, MACH LEARN, V37, P183; Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3); Leibe B., 2005, P IEEE C COMP VIS PA, P878; Liu YC, 2001, CHINESE J ASTRON AST, V1, P281; MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.791275; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823; Peterson C., 1987, Complex Systems, V1; RAMANAN D, 2003, P IEEE C COMP VIS PA, V2, P467; RANGARAJAN A, 2003, P IEEE INT C COMP VI, V1, P671; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Schneiderman H., 2000, P IEEE C COMP VIS PA, V1, P746, DOI 10.1109/CVPR.2000.855895; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; Toyama K., 2001, P INT C COMP VIS VAN, V2, P50, DOI 10.1109/ICCV.2001.937599; Viola P., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Viola P., 2001, P IEEE C COMP VIS PA, V1, P511; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; WU Y, 2005, P IEEE C COMP VIS PA, V1, P1023; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59; ZHU S. C, 1998, INT J COMPUT VISION, V27, P1	40	22	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					753	765				13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	020CO	WOS:000235885700007	
J	Kivinen, J; Warmuth, MK; Hassibi, B				Kivinen, J; Warmuth, MK; Hassibi, B			The p-norm generalization of the LMS algorithm for adaptive filtering	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						adaptive filtering; Bregman divergences; H-infinity optimality; least mean squares; online learning	ONLINE LEARNING ALGORITHMS; RELATIVE LOSS BOUNDS; GRADIENT DESCENT; SINGLE NEURONS; CONVERGENCE	Recently much work has been done analyzing online machine learning algorithms in a worst case setting, where no probabilistic assumptions are made about the data. This is analogous to the H-infinity setting used in adaptive linear filtering. Bregman divergences have become a standard tool for analyzing online machine learning algorithms. Using these divergences, we motivate a generalization of the least mean squared (LMS) algorithm. The loss bounds for these so-called p-norm algorithms involve other norms than the standard 2-norm. The bounds can be significantly better if a large proportion of the input variables are irrelevant, i.e., if the weight vector we are trying to learn is sparse. We also prove results for nonstationary targets. We only know how to apply kernel methods to the standard LMS algorithm (i.e., p = 2). However, even in the general p-norm case, we can handle generalized linear models where the output of the system is a linear function combined with a nonlinear transfer function (e.g.,. the logistic sigmoid).	Univ Helsinki, Dept Comp Sci, FI-00014 Helsinki, Finland; Univ Calif Santa Cruz, Dept Comp Sci, Santa Cruz, CA 95064 USA; CALTECH, Dept Elect Engn, Pasadena, CA 91125 USA	Kivinen, J (reprint author), Univ Helsinki, Dept Comp Sci, FI-00014 Helsinki, Finland.	jyrki.kivinen@cs.helsinki.fi; manfred@cse.ucsc.edu; hassibi@systems.caltech.edu					ALNAFFOURI TY, 2000, P ICASSP, V1, P464; Auer P, 1996, ADV NEUR IN, V8, P316; Auer P, 2002, J COMPUT SYST SCI, V64, P48, DOI 10.1006/jcss.2001.1795; Azoury KS, 2001, MACH LEARN, V43, P211, DOI 10.1023/A:1010896012157; Bregman LM, 1967, USSR COMP MATH MATH, V7, P200, DOI 10.1016/0041-5553(67)90040-7; CesaBianchi N, 1996, IEEE T NEURAL NETWOR, V7, P604, DOI 10.1109/72.501719; Cesa-Bianchi N, 2004, IEEE T INFORM THEORY, V50, P2050, DOI 10.1109/TIT.2004.833339; GENTILE C, 1999, 12 COLT, P1; Grove AJ, 2001, MACH LEARN, V43, P173, DOI 10.1023/A:1010844028087; Hassibi B, 1996, IEEE T SIGNAL PROCES, V44, P267, DOI 10.1109/78.485923; Helmbold DP, 1999, IEEE T NEURAL NETWOR, V10, P1291, DOI 10.1109/72.809075; HERBERMAN R B, 1981, Clinical Immunology Reviews, V1, P1; Khardon R, 2005, J ARTIF INTELL RES, V24, P341; Kivinen J, 2001, MACH LEARN, V45, P301, DOI 10.1023/A:1017938623079; KIVINEN J, 2003, 13 IFAC S SYST ID; Kivinen J, 1997, ARTIF INTELL, V97, P325, DOI 10.1016/S0004-3702(97)00039-8; Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; NG AY, 2004, P 21 INT C MACH LEAR, P615; Schapire RE, 1996, MACH LEARN, V22, P95, DOI 10.1023/A:1018060205686; Takimoto E., 2003, J MACHINE LEARNING R, V4, P773; WARMUTH MK, 2005, P 18 ANN C LEARN THE, P366; Widrow B., 1960, 1960 IRE WESCON CONV, P96	23	8	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-587X		IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	MAY	2006	54	5					1782	1793		10.1109/TSP.2006.872551		12	Engineering, Electrical & Electronic	Engineering	037JE	WOS:000237142100021	
J	Rokach, L; Maimon, O; Arbel, R				Rokach, L; Maimon, O; Arbel, R			Selective voting - Getting more for less in sensor fusion	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						decision trees; ensemble methods; selective voting; performance measures; information fusion; machine learning	DECISION TREES; CLASSIFIERS	Many real life problems are characterized by the structure of data derived from multiple sensors. The sensors may be independent, yet their information considers the same entities. Thus, there is a need to efficiently use the information rendered by numerous datasets emanating from different sensors. A novel methodology to deal with such problems is suggested in this work. Measures for evaluating probabilistic classification are used in a new efficient voting approach called "selective voting", which is designed to combine the classification of the models (sensor fusion). Using "selective voting", the number of sensors is decreased significantly while the performance of the integrated model's classification is increased. This method is compared to other methods designed for combining multiple models as well as demonstrated on a real-life problem from the field of human resources.	Ben Gurion Univ Negev, Dept Informat Syst Engn, IL-84105 Beer Sheva, Israel; Tel Aviv Univ, Dept Ind Engn, IL-69978 Tel Aviv, Israel	Rokach, L (reprint author), Ben Gurion Univ Negev, Dept Informat Syst Engn, IL-84105 Beer Sheva, Israel.	liorrk@qu.ac.il; maimon@eng.tau.ac.il; rubishag@zalbav.net.il					Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; AN A, 2001, IEEE INT C DAT MIN, P1; Bahler D., 2000, 17 NAT C ART INT AAA; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chan P. K., 1995, P 12 INT C MACH LEAR, P90; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Levin N, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1261, DOI 10.1007/0-387-25465-X_61; LIU H, 2004, EMPIRICAL STUDY BUIL, P622; Margineantu D, 1997, P 14 INT C MACH LEAR, P211; MCKENDALL R, 1992, DATA FUSION ROBOTICS, P211; MERZ CJ, 1995, P 5 INT WORKSH ART I, P386; ORTEGA J, 1995, AAAI 96 WORKSH INT M; PRODROMODIS L, CUCS01799; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247; Sharkey AJC, 1999, COMBINING ARTIFICIAL, P1; Singhal A, 1997, P SOC PHOTO-OPT INS, V3209, P2, DOI 10.1117/12.287628; SPENGLER M, 2001, INT WORKSH COMP VIS, P94; TING KM, 1997, P 9 EUR C MACH LEARN, P250; TING KM, 1996, 9619 U WAIK DEP COMP; Torra V, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1005, DOI 10.1007/0-387-25465-X_47; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zhou ZH, 2003, LECT NOTES ARTIF INT, V2639, P476	27	25	26	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAY	2006	20	3					329	350		10.1142/S0218001406004739		22	Computer Science, Artificial Intelligence	Computer Science	052XA	WOS:000238266100001	
J	Baumes, LA				Baumes, LA			MAP: An iterative experimental design methodology for the optimization of catalytic search space structure modeling	JOURNAL OF COMBINATORIAL CHEMISTRY			English	Article							DISCOVERY; SOLIDS	One of the main problems in high-throughput research for materials is still the design of experiments. At early stages of discovery programs, purely exploratory methodologies coupled with fast screening tools should be employed. This should lead to opportunities to find unexpected catalytic results and identify the "groups" of catalyst outputs, providing well-defined boundaries for future optimizations. However, very few new papers deal with strategies that guide exploratory studies. Mostly, traditional designs, homogeneous covering, or simple random samplings are exploited. Typical catalytic output distributions exhibit unbalanced datasets for which an efficient learning is hardly carried out, and interesting but rare classes are usually unrecognized. Here is suggested a new iterative algorithm for the characterization of the search space structure, working independently of learning processes. It enhances recognition rates by transferring catalysts to be screened from "performance-stable" space zones to "unsteady" ones which necessitate more experiments to be well-modeled. The evaluation of new algorithm attempts through benchmarks is compulsory due to the lack of past proofs about their efficiency. The method is detailed and thoroughly tested with mathematical functions exhibiting different levels of complexity. The strategy is not only empirically evaluated, the effect or efficiency of sampling on future Machine Learning performances is also quantified. The minimum sample size required by the algorithm for being statistically discriminated from simple random sampling is investigated.	Max Planck Inst Kohlenforsch, D-45470 Mulheim, Germany; Inst Rech Catalyse, CNRS, F-69626 Villeurbanne, France	Baumes, LA (reprint author), Max Planck Inst Kohlenforsch, Kaiser Wilhelm Pl 1, D-45470 Mulheim, Germany.	baumesl@itq.upv.es	baumes, laurent/E-2175-2013	baumes, laurent/0000-0001-9363-9089			Aha D., 1992, P 9 INT C MACH LEARN, P1; BAUMES LA, 2004, QSAR COMB SCI, V29, P767; BAUMES LA, UNPUB J COMB CHEM; BAUMES LA, 2003, LECT NOTES AI LNCS L; BEM DS, 2003, EXPT DESIGN HIGH THR, P89; BLICKLE T, 1995, 6 INT C GEN ALG SAN; CAWSE JN, 2003, EXPT DESIGN COMBINAT, P109; Chakravarti I., 1967, HDB METHODS APPL STA, VI, P392; Christensen L.B., 1994, EXPT METHODOLOGY; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Jong K. A., 1975, THESIS U MICHIGAN; Deming S.N., 1993, EXPT DESIGN CHEMOMET; FARRUSSENG D, 2004, 13 ICC PAR FRANC JUL; Farrusseng D, 2005, QSAR COMB SCI, V24, P78, DOI 10.1002/qsar.200420066; Farrusseng D, 2003, HIGH-THROUGHPUT ANALYSIS: A TOOL OF COMBINATORIAL MATERIALS SCIENCE, P551; Fernandez J, 2002, J PHOTOCH PHOTOBIO A, V151, P213, DOI 10.1016/S1010-6030(02)00153-3; Harmon L, 2003, J MATER SCI, V38, P4479, DOI 10.1023/A:1027325400459; HICKEY RJ, 1992, P 9 INT C MACH LEARN, P196; Klanner C, 2004, ANGEW CHEM INT EDIT, V43, P5347, DOI 10.1002/anie.200460731; Montgomery D. C., 1991, DESIGN ANAL EXPT; SAMMUT C, 1990, 7 INT MACH LEARN C A; Senkan S, 2001, ANGEW CHEM INT EDIT, V40, P312, DOI 10.1002/1521-3773(20010119)40:2<312::AID-ANIE312>3.0.CO;2-I; Serra JM, 2003, CATAL TODAY, V81, P425, DOI 10.1016/S0920-5861(03)00142-1; SJOBLOM J, 2004, 11 NORD S CAT OUL FI; Snedecor G, 1989, STAT METHODS; STEPHENS MA, 1974, J AM STAT ASSOC, V69, P730, DOI 10.2307/2286009; Thierens D., 1997, P 7 INT C GEN ALG MO, P152; TRIBUS M, 1989, QUAL PROG, V22, P46; Whitley D, 1996, ARTIF INTELL, V85, P245, DOI 10.1016/0004-3702(95)00124-7	29	17	17	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1520-4766		J COMB CHEM	J. Comb. Chem.	MAY	2006	8	3					304	314		10.1021/cc050130+		11	Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Chemistry; Pharmacology & Pharmacy	039YG	WOS:000237343900007	
J	Chien, BC; Lin, JY; Yang, WP				Chien, BC; Lin, JY; Yang, WP			A classification tree based on discriminant functions	JOURNAL OF INFORMATION SCIENCE AND ENGINEERING			English	Article; Proceedings Paper	Workshop on Computer Vision, Graphics and Image Processing (CVGIP)	2004	TAIWAN			knowledge discovery; machine learning; genetic programming; classification; discriminant function; decision tree; classifier	SUPPORT VECTOR MACHINES; PATTERN-CLASSIFICATION; NEURAL NETWORKS; FUZZY; RULE	The classification problem is an important topic in knowledge discovery and machine learning. Traditional classification tree methods and their improvements have been discussed widely. This work proposes a new approach to construct decision trees based on discriminant functions which are learned using genetic programming. A discriminant function is a mathematical function for classifying data into a specific class. To learn discriminant functions effectively and efficiently, a distance-based fitness function for genetic programming is designed. After the set of discriminant functions for all classes is generated. a classifier is created as a binary decision tree with the Z-value measure to resolve the problem of ambiguity among discriminant functions. Several popular datasets from the UCI Repository were selected to illustrate the effectiveness of the proposed classifiers by comparing with previous methods. The results show that the proposed classification tree demonstrates high accuracy on the selected datasets.	Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 700, Taiwan; Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 300, Taiwan; Natl Dong Hwa Univ, Dept Informat Management, Hualien 974, Taiwan	Chien, BC (reprint author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 700, Taiwan.						Blake C. L., 1998, UCI REPOSITORY MACHI; Bojarczuk CC, 1999, P GEN EV COMP C ORL, P953; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; Chen KH, 1997, FUZZY SET SYST, V91, P15, DOI 10.1016/S0165-0114(96)00145-5; Chen YX, 2003, IEEE T FUZZY SYST, V11, P716, DOI 10.1109/TFUZZ.2003.819843; Chien BC, 2002, EXPERT SYST APPL, V23, P31, DOI 10.1016/S0957-4174(02)00025-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O, 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FREITAS AA, 1997, P 2 ANN C GEN PROGR, P96; Han J., 2001, DATA MINING CONCEPTS; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; HECKERMAN D, 1995, COMMUN ACM, V38, P27, DOI 10.1145/203330.203336; Karacali B, 2004, PATTERN RECOGN LETT, V25, P63, DOI 10.1016/j.patrec.2003.09.002; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; Koza J. R., 1996, GENETIC PROGRAMMING; Koza J. R., 1992, GENETIC PROGRAMMING; Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536; Lee YJ, 2001, COMPUT OPTIM APPL, V20, P5, DOI 10.1023/A:1011215321374; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Liu B., 1998, P 4 INT C KNOWL DISC, P80; Loveard T, 2001, IEEE C EVOL COMPUTAT, P1070, DOI 10.1109/CEC.2001.934310; Mangasarian OL, 1990, SIAM NEWS, V23, P1; Nauck D, 1997, FUZZY SET SYST, V89, P277, DOI 10.1016/S0165-0114(97)00009-2; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654; SHI HB, 2003, P 7 PAC AS C KNOWL D, P265; SINDHWANI V, 2001, P SIAM INT C DAT MIN; SINGLETON A, 1994, BYTE             FEB, P171; STEFAOWSKI J, 2003, P S METH ART INT AI, P297; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang ZH, 2003, LECT NOTES ARTIF INT, V2903, P453; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	35	2	2	INST INFORMATION SCIENCE	TAIPEI	ACADEMIA SINICA, TAIPEI 115, TAIWAN	1016-2364		J INF SCI ENG	J. Inf. Sci. Eng.	MAY	2006	22	3					573	594				22	Computer Science, Information Systems	Computer Science	047VX	WOS:000237907900008	
J	Sollner, J; Mayer, B				Sollner, J; Mayer, B			Machine learning approaches for prediction of linear B-cell epitopes on proteins	JOURNAL OF MOLECULAR RECOGNITION			English	Article						machine learning; epitope; classification algorithm; peptide descriptor	ANTIGENIC DETERMINANTS; LOCATION; REGIONS; SEQUENCES; DATABASE	Identification and characterization of antigenic determinants on proteins has received considerable attention utilizing both, experimental as well as computational methods. For computational routines mostly structural as well as physicochemical parameters have been utilized for predicting the antigenic propensity of protein sites. However, the performance of computational routines has been low when compared to experimental alternatives. Here we describe the construction of machine learning based classifiers to enhance the prediction quality for identifying linear B-cell epitopes on proteins. Our approach combines several parameters previously associated with antigenicity, and includes novel parameters based on frequencies of amino acids and amino acid neighborhood propensities. We utilized machine learning algorithms for deriving antigenicity classification functions assigning antigenic propensities to each amino acid of a given protein sequence. We compared the prediction quality of the novel classifiers with respect to established routines for epitope scoring, and tested prediction accuracy on experimental data available for HIV proteins. The major finding is that machine learning classifiers clearly outperform the reference classification systems on the HIV epitope validation set. Copyright (c) 2006 John Wiley & Sons, Ltd.	Emergentec Biodev GmbH, A-1010 Vienna, Austria; Intercell AG, A-1030 Vienna, Austria; Univ Vienna, Inst Theoret Chem, A-1090 Vienna, Austria	Mayer, B (reprint author), Emergentec Biodev GmbH, Rathausstr 5-3, A-1010 Vienna, Austria.	bernd.mayer@emergentec.com					Alix AJP, 1999, VACCINE, V18, P311, DOI 10.1016/S0264-410X(99)00329-1; Bhasin M, 2004, VACCINE, V22, P3195, DOI 10.1016/j.vaccine.2004.02.005; Blythe MJ, 2005, PROTEIN SCI, V14, P246, DOI 10.1110/ps.041059505; Etz H, 2002, P NATL ACAD SCI USA, V99, P6573, DOI 10.1073/pnas.092569199; Greenspan NS, 1999, NAT BIOTECHNOL, V17, P936, DOI 10.1038/13590; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; KARPLUS PA, 1985, NATURWISSENSCHAFTEN, V72, P212, DOI 10.1007/BF01195768; KOLASKAR AS, 1990, FEBS LETT, V276, P172, DOI 10.1016/0014-5793(90)80535-Q; Kuiken Carla, 2003, AIDS Reviews, V5, P52; Mayers C, 2003, COMP FUNCT GENOM, V4, P468, DOI 10.1002/cfg.319; MODROW S, 1987, J VIROL, V61, P570; Odorico M, 2003, J MOL RECOGNIT, V16, P20, DOI 10.1002/jmr.602; PELLEQUER JL, 1993, IMMUNOL LETT, V36, P83, DOI 10.1016/0165-2478(93)90072-A; Rammensee HG, 1999, IMMUNOGENETICS, V50, P213, DOI 10.1007/s002510050595; SAHA S, 2005, BMC GENOMICS, V29, P6; Schonbach C, 2000, NUCLEIC ACIDS RES, V28, P222, DOI 10.1093/nar/28.1.222; Van Regenmortel MHV, 2001, BIOLOGICALS, V29, P209, DOI 10.1006/biol.2001.0308; WELLING GW, 1985, FEBS LETT, V188, P215, DOI 10.1016/0014-5793(85)80374-4; WESTHOF E, 1984, NATURE, V311, P123, DOI 10.1038/311123a0; Witten I. H., 2000, DATA MINING PRACTICA; Wootton JC, 1996, METHOD ENZYMOL, V266, P554	22	38	41	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0952-3499		J MOL RECOGNIT	J. Mol. Recognit.	MAY-JUN	2006	19	3					200	208		10.1002/jmr.771		9	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	053RH	WOS:000238322100003	
J	Sollner, J				Sollner, J			Selection and combination of machine learning classifiers for prediction of linear B-cell epitopes on proteins	JOURNAL OF MOLECULAR RECOGNITION			English	Article						machine learning; epitope; classification algorithm; ROC; ensemble; neural network	ANTIGENIC DETERMINANTS; LOCATION	Recently, new machine learning classifiers for the prediction of linear B-cell epitopes were presented. Here we show the application of Receiver Operator Characteristics (ROC) convex hulls to select optimal classifiers as well as possibilities to improve the post test probability (PTP) to meet real world requirements such as high throughput epitope screening of whole proteomes. The major finding is that ROC convex hulls present an easy to use way to rank classifiers based on their prediction conservativity as well as to select candidates for ensemble classifiers when validating against the antigenicity profile of 10 HIV-1 proteins. We also show that linear models are at least equally efficient to model the available data when compared to multi-layer feed-forward neural networks. Copyright (c) 2006 John Wiley & Sons, Ltd.	Intercell AG, A-1030 Vienna, Austria	Sollner, J (reprint author), Keilgasse 11-9, A-1030 Vienna, Austria.	johannes.soellner@gmx.net					Alix AJP, 1999, VACCINE, V18, P311, DOI 10.1016/S0264-410X(99)00329-1; Bhasin M, 2004, VACCINE, V22, P3195, DOI 10.1016/j.vaccine.2004.02.005; Blythe MJ, 2005, PROTEIN SCI, V14, P246, DOI 10.1110/ps.041059505; Etz H, 2002, P NATL ACAD SCI USA, V99, P6573, DOI 10.1073/pnas.092569199; Greenspan NS, 1999, NAT BIOTECHNOL, V17, P936, DOI 10.1038/13590; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Kuiken Carla, 2003, AIDS Reviews, V5, P52; Odorico M, 2003, J MOL RECOGNIT, V16, P20, DOI 10.1002/jmr.602; PELLEQUER JL, 1993, IMMUNOL LETT, V36, P83, DOI 10.1016/0165-2478(93)90072-A; SAHA S, 2005, BMC GENOMICS, V29, P6; SOLLNER J, 2006, UNPUB J MOL RECOGNIT, V19; VANREGENMORTEL MHV, 1994, PEPTIDE RES, V7, P224	12	14	14	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0952-3499		J MOL RECOGNIT	J. Mol. Recognit.	MAY-JUN	2006	19	3					209	214		10.1002/jmr.770		6	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	053RH	WOS:000238322100004	
J	Langseth, H; Nielsen, TD				Langseth, H; Nielsen, TD			Classification using Hierarchical Naive Bayes models	MACHINE LEARNING			English	Article						classification; Naive Bayes models; hierarchical models		Classification problems have a long history in the machine learning literature. One of the simplest, and yet most consistently well-performing set of classifiers is the Naive Bayes models. However, an inherent problem with these classifiers is the assumption that all attributes used to describe an instance are conditionally independent given the class of that instance. When this assumption is violated (which is often the case in practice) it can reduce classification accuracy due to "information double-counting" and interaction omission. In this paper we focus on a relatively new set of models, termed Hierarchical Naive Bayes models. Hierarchical Naive Bayes models extend the modeling flexibility of Naive Bayes models by introducing latent variables to relax some of the independence statements in these models. We propose a simple algorithm for learning Hierarchical Naive Bayes models in the context of classification. Experimental results show that the learned models can significantly improve classification accuracy as compared to other frameworks.	Norwegian Univ Sci & Technol, Dept Math Sci, N-7491 Trondheim, Norway; Univ Aalborg, Dept Comp Sci, DK-9220 Aalborg O, Denmark	Langseth, H (reprint author), SINTEF Technol & Soc, N-7465 Trondheim, Norway.	helgel@math.ntnu.no; tdn@cs.auc.dk					Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Blake C. L., 1998, UCI REPOSITORY MACHI; Boutilier C, 1996, P 12 C UNC ART INT U, P115; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O, 1973, PATTERN CLASSIFICATI; Elidan G., 2001, P 17 C UNC ART INT U, P144; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GREINER R, 1997, P 13 C UNC ART INT S, P198; Grossman D., 2004, P 21 INT C MACH LEAR, P361; JAEGER M, 2003, P 20 INT C MACH LEAR, P266; JENSEN F, 2001, BAYESIAN NETWORKS DE; KOCKA T, 2002, P 18 C UNC ART INT U, P267; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Langley P., 1994, P AAAI FALL S REL; LANGLEY P, 1993, LECT NOTES ART INTEL, V667, P153; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MADSEN AL, 1998, P 14 ANN C UNC ART I, P362; MARTIN JD, 1994, LRDCONR941 U PITTSB; Mitchell T, 1997, MACHINE LEARNING; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; NG AY, 2002, ADV NEURAL INFORMATI, V15, P841; Pazzani M., 1996, LEARNING DATA ARTIFI, P239; PAZZANI MJ, 2006, ISIS INFORMATION STA, P66; Pearl J., 1988, PROBABILISTIC REASON; QUINLAN R, 1998, C5 0 INFORMAL TUTORI; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shafer G.R., 1990, ANN MATH ARTIFICIAL, V2, P327, DOI 10.1007/BF01531015; Spirtes P., 1993, CAUSATION PREDICTION; Wettig H., 2003, P 18 INT JOINT C ART, P491; Whittaker J., 1990, GRAPHICAL MODELS APP; Zhang H., 2004, P 17 FLOR ART INT RE, P562; Zhang NL, 2004, J MACH LEARN RES, V5, P697; ZHANG NL, 2003, ARTIF INTELL, V30, P283; [Anonymous], 1993, P 13 INT JOINT C ART, P1022; *SPSS INC, 2002, CLEM V6 5	43	17	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAY	2006	63	2					135	159		10.1007/s10994-006-6136-2		25	Computer Science, Artificial Intelligence	Computer Science	041RE	WOS:000237472600002	
J	Rimer, M; Martinez, T				Rimer, M; Martinez, T			Classification-based objective functions	MACHINE LEARNING			English	Article						neural networks; backpropagation; classification; objective functions	NEURAL-NETWORKS; VARIANCE; BIAS	Backpropagation, similar to most learning algorithms that can form complex decision Surfaces, is prone to overfitting. This work presents classification-based objective functions, an approach to training artificial neural networks on classification problems. Classification-based learning attempts to guide the network directly to correct pattern classification rather than using common error minimization heuristics, such as sum-squared error (SSE) and cross-entropy (CE), that do not explicitly minimize classification error. CBI is presented here as a novel objective function for learning classification problems. It seeks to directly minimize classification error by backpropagating error only on misclassified patterns from culprit Output nodes. CB1 discourages weight saturation and overfitting and achieves higher accuracy on classification problems than optimizing SSE or CE. Experiments on a large OCR data set have shown CB1 to significantly increase generalization accuracy over SSE or CE optimization, from 97.86% and 98.10%, respectively, to 99.11%. Comparable results are achieved over several data sets from the UC Irvine Machine Learning Database Repository, with an average increase in accuracy from 90.7% and 91.3% using optimized SSE and CE networks, respectively, to 92.1% for CB1. Analysis indicates that CBI performs a fundamentally different search of the feature space than optimizing SSE or CE and produces significantly different solutions.	Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Rimer, M (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.	mrimer@axon.cs.byu.edu; martinez@cs.byu.edu					ANDERSSON S, 2001, AIDS REV, V3, P11; BARNARD E, 1991, IEEE T NEURAL NETWOR, V2, P322, DOI 10.1109/72.80345; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; BIANCHINI M, 1998, NEURAL NETWORK SYSTE, P1; Blake C.L., 1998, UCI MACHINE LEARNING; CARUANA R, 1997, THESIS CMU; CARUANA R, 1993, P 1993 CONN MOD SUMM, P372; CARUANA R, 2001, P NEUR INF PROC SYST, V13; CARUANA R, 1996, ADV NEURAL INFORMATI, V8; Caruana R., 1995, ADV NEURAL INFORMATI, V7, P657; CHAKRABORTY G, 1997, IEICE T FUND ELECTR, V9, P1630; Duda R. O., 1999, PATTERN CLASSIFICATI; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; HAMPSHIRE J, 1990, IEEE T NEURAL NETWOR, V1, P2; HERBERT S, 1959, AM ECON REV, V49, P253; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Joost M, 1998, INT J UNCERTAIN FUZZ, V6, P117, DOI 10.1142/S0218488598000100; LEBLANC M, 1993, NEUROPROSSE; LeCun Y, 1990, ADV NEURAL INFORMATI, V2, P598; Mitchell T, 1997, MACHINE LEARNING; RIMER M, 2001, P IEEE INT JOINT C N, P2007; RIMER M, 2004, P IEEE INT JOINT C N, P979; Rumelhart D. E., 1985, LEARNING INTERNAL RE; SCHIFFMANN W, 1993, EUR S BRUSS; Sharkey A. J. C., 1996, Connection Science, V8, DOI 10.1080/095400996116785; WANG C, 1994, ADV NEURAL INFORMATI, V6, P303; WERBOS P, 1988, P IEEE INT C NEUR NE, P343; ZARNDT F, 1995, THESIS B YOUNG U	29	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAY	2006	63	2					183	205		10.1007/s10994-006-6266-6		23	Computer Science, Artificial Intelligence	Computer Science	041RE	WOS:000237472600004	
J	Zheng, ZG; Padmanabhan, B				Zheng, ZG; Padmanabhan, B			Selectively acquiring customer information: A new data acquisition problem and an active learning-based solution	MANAGEMENT SCIENCE			English	Article						selective information acquisition; active learning; data mining	POPULATION SAMPLING THEORY; EXPERIMENTAL-DESIGN; MODELS; BIOMETRIKA; IMPUTATION; SYSTEM; COSTS	This paper presents a new information acquisition problem motivated by business applications where customer data has to be acquired with a specific modeling objective in mind. In the last two decades, there has been substantial work in two different fields-optimal experimental design and machine learning-that has addressed the issue of acquiring data in a selective manner with a specific objective in mind. We show that the problem presented here is different from the classic model-based data acquisition problems considered thus far in the literature in both fields. Building on work in optimal experimental design and in machine learning, we develop a new active learning technique for the information acquisition problem presented in this paper. We demonstrate that the proposed method performs well based on results from applying this method across 20 Web usage and machine learning data sets.	Univ Calif Riverside, A Gary Anderson Grad Sch Management, Riverside, CA 92521 USA; Univ Penn, Wharton Sch, Philadelphia, PA 19104 USA	Zheng, ZG (reprint author), Univ Calif Riverside, A Gary Anderson Grad Sch Management, 18 Anderson Hall, Riverside, CA 92521 USA.	eric.zheng@ucr.edu; balaji@wharton.upenn.edu					Atkinson A. C., 1992, OPTIMUM EXPT DESIGNS; Atkinson AC, 1996, J ROY STAT SOC B MET, V58, P59; Atkinson AC, 2001, BIOMETRIKA, V88, P53, DOI 10.1093/biomet/88.1.53; Blake L., 1998, UCI REPOSITORY MACHI; Box GEP, 1992, BAYESIAN INFERENCE S; Box G.E.P., 1978, STAT EXPERIMENTERS; Chaloner K, 1995, STAT SCI, V10, P273, DOI 10.1214/ss/1177009939; CHALONER K, 1989, J STAT PLAN INFER, V21, P191, DOI 10.1016/0378-3758(89)90004-9; Chaudhuri A., 1992, SURVEY SAMPLING THEO; Cochran WG, 1977, SAMPLING TECHNIQUES; COHN D, 1996, J ECONOMETRICS, V37, P87; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; COOK R, 1994, J AM STAT ASSOC, V89, P426; Cook T., 1979, QUASIEXPERIMENTATION; DIETTERICH T, 2000, MULTIPLE CLASSIFIER, V18, P1; DOSSANTOS BL, 1993, DECIS SUPPORT SYST, V9, P161, DOI 10.1016/0167-9236(93)90010-Z; DUNN LF, 2004, EMPIRICAL INVEST CRE; ENGELSON S, 1999, J ARTIFICIAL INTELLI, V11, P335; FORD I, 1980, BIOMETRIKA, V67, P381, DOI 10.1093/biomet/67.2.381; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Green W. H., 2000, ECONOMETRIC ANAL; Greiner R, 2002, ARTIF INTELL, V139, P137, DOI 10.1016/S0004-3702(02)00209-6; HASENJAGER M, 1999, ACTIVE LEARNING NEUR; Hu I, 1998, BIOMETRIKA, V85, P496, DOI 10.1093/biomet/85.2.496; Kallberg JG, 2003, J BANK FINANC, V27, P449, DOI 10.1016/S0378-4266(02)00387-4; KIFER JC, 1959, J ROY STAT SOC B MET, V21, P272; KUHFELD WF, 1994, J MARKETING RES, V31, P545, DOI 10.2307/3151882; Kullback S., 1959, INFORM THEORY STAT; Lindley D. V., 1972, BAYESIAN STAT REV; Little R. J., 1987, STAT ANAL MISSING DA; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; MARKOFF J, 2002, NY TIMES        1109; Melville P., 2004, P 4 IEEE INT C DAT M, P483; Mookerjee V. S., 1993, INFORMATION SYSTEMS, V4, P111, DOI 10.1287/isre.4.2.111; Mookerjee VS, 1997, INFORM SYST RES, V8, P51, DOI 10.1287/isre.8.1.51; Moore J. C., 1986, Decision Support Systems, V2, DOI 10.1016/0167-9236(86)90001-1; Moore JC, 1997, INFORM SYST RES, V8, P151, DOI 10.1287/isre.8.2.151; Moore J. C., 1987, Decision Support Systems, V3, DOI 10.1016/0167-9236(87)90035-2; PADMANABHAN B, 2005, UNPUB MIS Q; Padmanabhan B., 2002, P INT C DAT, P562; Park YH, 2004, MARKET SCI, V23, P280, DOI 10.1287/mksc.1040.0050; PERLICH C, 2004, CEDER0404 NEW YORK U; Rosenberger WF, 2002, STAT PROBABIL LETT, V56, P155, DOI 10.1016/S0167-7152(01)00171-7; ROYALL RM, 1976, BIOMETRIKA, V63, P605, DOI 10.1093/biomet/63.3.605; ROYALL RM, 1970, BIOMETRIKA, V57, P377, DOI 10.2307/2334846; RUBIN D, 1994, J AM STAT ASSOC, V89, P426; Rubin D. B., 1987, MULTIPLE IMPUTATION; SAARTSECHANSKY M, 2001, P 17 INT JOINT C ART, P911; Schafer JL, 1998, MULTIVAR BEHAV RES, V33, P545, DOI 10.1207/s15327906mbr3304_5; SCHUIERER S, 1995, ALGORITHMICA, V14, P1, DOI 10.1007/BF01300371; SIMON H, 1974, KNOWLEDGE COGNITION, pCH5; Singh R., 1996, ELEMENTS SURVEY SAMP; Smith TMF, 1993, J R STAT SOC A GEN, V156, P144, DOI 10.2307/2982726; Smith TMF, 2001, BIOMETRIKA, V88, P167, DOI 10.1093/biomet/88.1.167; Steele F, 2002, J ROY STAT SOC A STA, V165, P495, DOI 10.1111/1467-985X.00250; Steuer E., 1986, MULTIPLE CRITERIA OP; TONG S, 2001, P INT JOINT C ART IN; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WU C, 1985, BIOMETRIKA, V72, P552; ZHENG Z, 2005, UNPUB INFORMS J COMP	60	8	8	INST OPERATIONS RESEARCH  MANAGEMENT SCIENCES	LINTHICUM HTS	901 ELKRIDGE LANDING RD, STE 400, LINTHICUM HTS, MD 21090-2909 USA	0025-1909		MANAGE SCI	Manage. Sci.	MAY	2006	52	5					697	712		10.1287/mnsc.1050.0488		16	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	043DT	WOS:000237580500005	
J	Hilario, M; Kalousis, A; Pellegrini, C; Muller, M				Hilario, M; Kalousis, A; Pellegrini, C; Muller, M			Processing and classification of protein mass spectra	MASS SPECTROMETRY REVIEWS			English	Review						MS preprocessing; classification; biomarker discovery; data mining; proteomics; machine learning; dimensionality reduction	ENHANCED LASER-DESORPTION; TIME-OF-FLIGHT; SUPPORT VECTOR MACHINES; MALDI-TOF-MS; HIGH-THROUGHPUT PROTEOMICS; MULTIPLY-CHARGED IONS; GENE-EXPRESSION DATA; SPECTROMETRY DATA; OVARIAN-CANCER; ELECTROSPRAY-IONIZATION	Among the many applications of mass spectrometry, biomarker pattern discovery from protein mass spectra has aroused considerable interest in the past few years. While research efforts have raised hopes of early and less invasive diagnosis, they have also brought to light the many issues to be tackled before mass-spectra-based proteomic patterns become routine clinical tools. Known issues cover the entire pipeline leading from sample collection through mass spectrometry analytics to biomorker pattern extraction, validation, and interpretation. This study focuses on the data-analytical phase, which takes as input mass spectra of biological specimens and discovers patterns of peak masses and intensities that discriminate between different pathological states. We survey current work and investigate computational issues concerning the different stages of the knowledge disco very process: exploratory analysis, quality control, and diverse transforms of mass spectra, followed by further dimensionality reduction, classification, and model evaluation. We conclude after a brief discussion of the critical biomedical task of analyzing discovered discriminatory patterns to identify their component proteins as well as interpret and valid ate their biological implications. (c) 2006 Wiley Periodicals, Inc.	Univ Geneva, Dept Comp Sci, Artificial Intelligence Lab, CH-1211 Geneva 4, Switzerland; ETH Honggerberg, Inst Mol Syst Biol, CH-8093 Zurich, Switzerland	Hilario, M (reprint author), Univ Geneva, Dept Comp Sci, Artificial Intelligence Lab, CH-1211 Geneva 4, Switzerland.	Melanie.Hilario@cui.unige.ch	Muller, Markus/B-4974-2011				Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; Adam BL, 2002, CANCER RES, V62, P3609; Adam PJ, 2003, J BIOL CHEM, V278, P6482, DOI 10.1074/jbc.M210184200; Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Alexe G, 2004, PROTEOMICS, V4, P766, DOI 10.1002/pmic.200300574; Allard L, 2004, PROTEOMICS, V4, P2242, DOI 10.1002/pmic.200300809; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Anderle M, 2004, BIOINFORMATICS, V20, P3575, DOI 10.1093/bioinformatics/bth446; Andreev VP, 2003, ANAL CHEM, V75, P6314, DOI 10.1021/ac0301806; ANDREWS R, 1995, SURVEY CRITIQUE TECH; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Bailey T.L., 1993, P 13 INT JOINT C ART, P895; Banez LL, 2003, J UROLOGY, V170, P442, DOI 10.1097/01.ju.0000069431.95404.56; BARAK P, 1995, ANAL CHEM, V67, P2758, DOI 10.1021/ac00113a006; Beer I, 2004, PROTEOMICS, V4, P950, DOI 10.1002/pmic.200300652; Bern Marshall, 2004, Bioinformatics, V20 Suppl 1, pi49, DOI 10.1093/bioinformatics/bth947; BERNDT P, 1999, ELECTROPHORESIS, V20, P2521; Bienvenut WV, 1999, ANAL CHEM, V71, P4800, DOI 10.1021/ac990448m; Binz PA, 1999, ANAL CHEM, V71, P4981, DOI 10.1021/ac990449e; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blueggel M, 2004, CURR PHARM BIOTECHNO, V5, P79, DOI 10.2174/1389201043489648; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; BRAGANETO U, 2003, BIOINFORMATICS, V20, P374; Breen EJ, 2000, ELECTROPHORESIS, V21, P2243, DOI 10.1002/1522-2683(20000601)21:11<2243::AID-ELPS2243>3.0.CO;2-K; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Bro R, 1997, CHEMOMETR INTELL LAB, V38, P149, DOI 10.1016/S0169-7439(97)00032-4; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Bylund D, 2002, J CHROMATOGR A, V961, P237, DOI 10.1016/S0021-9673(02)00588-5; Campa MJ, 2003, PROTEOMICS, V3, P1659; Carroll JA, 1996, RAPID COMMUN MASS SP, V10, P1683, DOI 10.1002/(SICI)1097-0231(199610)10:13<1683::AID-RCM716>3.3.CO;2-C; Chamrad DC, 2003, ANAL BIOANAL CHEM, V376, P1014, DOI 10.1007/s00216-003-1995-x; Check E, 2004, NATURE, V429, P496, DOI 10.1038/429496a; Chen Y, 1997, J Biomed Opt, V2, P364, DOI 10.1117/1.429838; Chen YD, 2002, BIOINFORMATICS, V18, P1207, DOI 10.1093/bioinformatics/18.9.1207; Christian NP, 2000, ANAL CHEM, V72, P3327, DOI 10.1021/ac991500h; Clarke W, 2003, ANN SURG, V237, P660, DOI 10.1097/00000658-200305000-00008; Clauser KR, 1999, ANAL CHEM, V71, P2871, DOI 10.1021/ac9810516; CLEAVELAND WS, 1979, J AM STAT ASSOC, V74, P829; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Colinge J, 2003, PROTEOMICS, V3, P1434, DOI 10.1002/pmic.200300489; COOMBES KR, 2004, UTMDABTR00104; Coombes KR, 2003, CLIN CHEM, V49, P1615, DOI 10.1373/49.10.1615; Cover TM, 1991, ELEMENTS INFORM THEO; Cristianini N., 2000, INTRO SUPPORT VECTOR; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Diamandis EP, 2003, CLIN CHEM, V49, P1272, DOI 10.1373/49.8.1272; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Duda R., 2000, PATTERN CLASSIFICATI; Durbin B P, 2002, Bioinformatics, V18 Suppl 1, pS105; Egelhofer V, 2000, ANAL CHEM, V72, P2741, DOI 10.1021/ac990686h; Egelhofer V, 2002, ANAL CHEM, V74, P1760, DOI 10.1021/ac011204g; Eilers PHC, 2004, ANAL CHEM, V76, P404, DOI 10.1021/ac034800e; ERFRON B, 1995, TR477 DEPT STAT U; Fawcett T., 2003, ROC GRAPHS NOTES PRA; FEELDERS A, 1995, P 5 INT WORKSH ART I, P219; Felitsyn N, 2002, INT J MASS SPECTROM, V219, P39, DOI 10.1016/S1387-3806(02)00588-2; FENN JB, 1989, SCIENCE, V246, P64, DOI 10.1126/science.2675315; Fleming CM, 1999, J CHROMATOGR A, V849, P71, DOI 10.1016/S0021-9673(99)00553-1; Forshed J, 2003, ANAL CHIM ACTA, V487, P189, DOI 10.1016/S0003-2670(03)00570-1; Fraga CG, 2001, ANAL CHEM, V73, P675, DOI 10.1021/ac0010025; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FUNG ET, 2002, COMPUTATIONAL PROT S, V32, pS34; Gay S, 1999, ELECTROPHORESIS, V20, P3527, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3527::AID-ELPS3527>3.3.CO;2-0; Gentzel M, 2003, PROTEOMICS, V3, P1597, DOI 10.1002/pmic.200300486; Gobom J, 2002, ANAL CHEM, V74, P3915, DOI 10.1021/ac011203o; Graber A, 2004, PROTEOMICS, V4, P474, DOI 10.1002/pmic.200300566; Gras R, 1999, ELECTROPHORESIS, V20, P3535, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3535::AID-ELPS3535>3.3.CO;2-A; Grizzle WE, 2004, UROL ONCOL-SEMIN ORI, V22, P337, DOI 10.1016/j.urolonc.2004.04.008; GRUSHKA E, 1990, ANAL CHEM, V62, P717, DOI 10.1021/ac00206a014; Guyon I., 2003, P BISC FLINT CIBI 20; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastings CA, 2002, RAPID COMMUN MASS SP, V16, P462, DOI 10.1002/rcm.600; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hilario M, 2003, PROTEOMICS, V3, P1716, DOI 10.1002/pmic.200300523; Huang Xiaohong, 2002, Funct Integr Genomics, V2, P126, DOI 10.1007/s10142-002-0066-2; Huber W, 2002, BIOINFORMATICS, V18, P96; Izmirlian G, 2004, ANN NY ACAD SCI, V1020, P154, DOI 10.1196/annals.1310.015; Jain N, 2003, BIOINFORMATICS, V19, P1945, DOI 10.1093/bioinformatics/btg264; Jarman KH, 2003, CHEMOMETR INTELL LAB, V69, P61, DOI 10.1016/S0169-7439(03)00113-8; Johnson KJ, 2003, J CHROMATOGR A, V996, P141, DOI 10.1016/S0021-9673(03)00616-2; JONG K, 2004, APPL EVOLUTIONARY CO; JONG K, 2004, IEEE S COMP INT BIOI, P41, DOI 10.1109/CIBCB.2004.1393930; KARAS M, 1988, ANAL CHEM, V60, P2299, DOI 10.1021/ac00171a028; Kiers HAL, 1999, J CHEMOMETR, V13, P275, DOI 10.1002/(SICI)1099-128X(199905/08)13:3/4<275::AID-CEM543>3.3.CO;2-2; King R, 2000, J AM SOC MASS SPECTR, V11, P942, DOI 10.1016/S1044-0305(00)00163-X; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, P 14 INT JOINT C AI; Kohonen T., 1995, SELF ORG MAPS; KONONEKO I, 2004, P EUR C MACH LEARN; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; Kratzer R, 1998, ELECTROPHORESIS, V19, P1910, DOI 10.1002/elps.1150191109; Kreil DP, 2004, BIOINFORMATICS, V20, P2026, DOI 10.1093/bioinformatics/bth193; Krutchinsky AN, 2002, J AM SOC MASS SPECTR, V13, P129, DOI 10.1016/S1044-0305(01)00336-1; LANGLEY P, 1996, ELEMENTS MACHINGE LE; Lee KR, 2003, PROTEOMICS, V3, P1680, DOI 10.1002/pmic.200300515; LEE TA, 1991, ANAL CHEM, V63, P357, DOI 10.1021/ac00004a011; Li JN, 2002, CLIN CHEM, V48, P1296; Li JW, 1997, ANAL CHEM, V69, P4452, DOI 10.1021/ac970481d; Li JY, 2003, BIOINFORMATICS, V19, pII93, DOI 10.1093/bioinformatics/btg1066; Li LP, 2004, BIOINFORMATICS, V20, P1638, DOI 10.1093/bioinformatics/bth098; Lilien RH, 2003, J COMPUT BIOL, V10, P925, DOI 10.1089/106652703322756159; Liu Huiqing, 2002, Genome Inform, V13, P51; MALMQUIST G, 1994, J CHROMATOGR A, V687, P89, DOI 10.1016/0021-9673(94)00727-6; MANN M, 1989, ANAL CHEM, V61, P1702, DOI 10.1021/ac00190a023; Marchetti N, 2004, ANAL CHEM, V76, P3055, DOI 10.1021/ac035312+; Model Fabian, 2002, Bioinformatics, V18 Suppl 1, pS155; Mohammad-Djafari A, 2002, INT J MASS SPECTROM, V215, P175, DOI 10.1016/S1387-3806(01)00562-0; MUDDIMAN DC, 1995, ANAL CHEM, V67, P4371, DOI 10.1021/ac00119a027; Muller M, 2002, PROTEOMICS, V2, P1413; Muller M, 2002, J AM SOC MASS SPECTR, V13, P221, DOI 10.1016/S1044-0305(01)00358-0; MULLER MJ, 2003, MOL SCANNER DATA ANA; Neville P, 2003, PROTEOMICS, V3, P1710, DOI 10.1002/pmic.200300516; Nielsen NPV, 1998, J CHROMATOGR A, V805, P17, DOI 10.1016/S0021-9673(98)00021-1; Palmblad M, 2001, J AM SOC MASS SPECTR, V12, P1153, DOI 10.1016/S1044-0305(01)00301-4; Papadopoulos MC, 2004, LANCET, V363, P1358, DOI 10.1016/S0140-6736(04)16046-7; Peng WP, 2004, MASS SPECTROM REV, V23, P443, DOI 10.1002/mas.20002; Pepe MS, 2000, J AM STAT ASSOC, V95, P308, DOI 10.2307/2669554; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Petricoin E, 2003, CLIN CHEM, V49, P1276, DOI 10.1373/49.8.1276; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; Powell DA, 2002, J BIOMED OPT, V7, P650, DOI 10.1117/1.1501561; Prados J, 2004, PROTEOMICS, V4, P2320, DOI 10.1002/pmic.200400857; Press W.H., 1995, NUMERICAL RECIPES C; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Purohit PV, 2003, PROTEOMICS, V3, P1699, DOI 10.1002/pmic.200300518; Qu YS, 2003, BIOMETRICS, V59, P143, DOI 10.1111/1541-0420.00017; Qu YS, 2002, CLIN CHEM, V48, P1835; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1994, COMPUTATIONAL LEARNI, V1, P446; Rai AJ, 2002, ARCH PATHOL LAB MED, V126, P1518; REINHOLD BB, 1992, J AM SOC MASS SPECTR, V3, P207, DOI 10.1016/1044-0305(92)87004-I; Rendell L.A., 1992, P 10 NAT C ART INT, P129; ROCKWOOD AL, 1995, ANAL CHEM, V67, P2699, DOI 10.1021/ac00111a031; Rockwood AL, 1996, ANAL CHEM, V68, P2027, DOI 10.1021/ac951158i; Rogers MA, 2003, CANCER RES, V63, P6971; Sadygov RG, 2002, J PROTEOME RES, V1, P211, DOI 10.1021/pr015514r; Samuelsson J, 2004, BIOINFORMATICS, V20, P3628, DOI 10.1093/bioinformatics/bth460; Satten GA, 2004, BIOINFORMATICS, V20, P3128, DOI 10.1093/bioinformatics/bth372; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; Schmidt F, 2003, J AM SOC MASS SPECTR, V14, P943, DOI 10.1016/S1044-0305(03)00345-3; SCHOLFKOPF B, 2004, KERNEL METHODS COMPU; Scholkopf B, 2003, NATO SC S SS III C S, V183, P1; SENKO MW, 1995, J AM SOC MASS SPECTR, V6, P52, DOI 10.1016/1044-0305(94)00091-D; Shackman JG, 2004, J CHROMATOGR A, V1040, P273, DOI 10.1016/j.chroma.2004.04.004; Shao XG, 2003, ACCOUNTS CHEM RES, V36, P276, DOI 10.1021/ar990163w; Shao XG, 1997, ANAL CHEM, V69, P1722, DOI 10.1021/ac9608679; Shi SDH, 1998, P NATL ACAD SCI USA, V95, P11532, DOI 10.1073/pnas.95.20.11532; Simon R, 2003, J NATL CANCER I, V95, P14; Soille P., 2003, MORPHOLOGICAL IMAGE; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Tammen H, 2004, CLIN CHEM, V50, P545, DOI 10.1373/clinchem.2003.028209; Tang KQ, 2004, J AM SOC MASS SPECTR, V15, P1416, DOI 10.1016/j.jasms.2004.04.034; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; TUKEY JW, 1993, CONTROL CLIN TRIALS, V14, P266, DOI 10.1016/0197-2456(93)90225-3; TURNEY P, 1995, MACH LEARN, V20, P23, DOI 10.1007/BF00993473; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik VN, 1998, STAT LEARNING THEORY; Venable JD, 2004, NAT METHODS, V1, P39, DOI 10.1038/NMETH705; Vestal M, 1998, J AM SOC MASS SPECTR, V9, P892, DOI 10.1016/S1044-0305(98)00069-5; WAGNER M, 2004, BMC BIOINFORMATICS, P5; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519; Wallace WE, 2004, ANAL CHEM, V76, P2446, DOI 10.1021/ac0354701; WANG CP, 1987, ANAL CHEM, V59, P649, DOI 10.1021/ac00131a023; Wang MZ, 2003, PROTEOMICS, V3, P1661, DOI 10.1002/pmic.200300513; Washburn MP, 2001, NAT BIOTECHNOL, V19, P242, DOI 10.1038/85686; WATKINS B, 2001, AM LAB, V32, P31; Windig W, 1996, ANAL CHEM, V68, P3602, DOI 10.1021/ac960435y; WOLFKUHLE J, 2003, NATURE REV, V3, P267; WOLPERT DH, 1992, LAUR903460; Won Y, 2003, PROTEOMICS, V3, P2310, DOI 10.1002/pmic.200300590; Wool A, 2002, PROTEOMICS, V2, P1365, DOI 10.1002/1615-9861(200210)2:10<1365::AID-PROT1365>3.0.CO;2-9; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Zhang ZQ, 1998, J AM SOC MASS SPECTR, V9, P225, DOI 10.1016/S1044-0305(97)00284-5; Zhang ZQ, 1999, ANAL CHEM, V71, P39, DOI 10.1021/ac980724h; Zhang ZQ, 1997, J AM SOC MASS SPECTR, V8, P659, DOI 10.1016/S1044-0305(97)82982-0; Zhu HT, 2003, PROTEOMICS, V3, P1673, DOI 10.1002/pmic.200300520; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100; Zien A, 2001, Bioinformatics, V17 Suppl 1, pS323	192	78	82	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0277-7037		MASS SPECTROM REV	Mass Spectrom. Rev.	MAY-JUN	2006	25	3					409	449		10.1002/mas.20072		41	Spectroscopy	Spectroscopy	031GQ	WOS:000236693000003	
J	Diez, J; Alberti, P; Ripoll, G; Lahoz, F; Fernandez, I; Olleta, JL; Panea, B; Sanudo, C; Bahamonde, A; Goyache, F				Diez, J; Alberti, P; Ripoll, G; Lahoz, F; Fernandez, I; Olleta, JL; Panea, B; Sanudo, C; Bahamonde, A; Goyache, F			Using machine learning procedures to ascertain the influence of beef carcass profiles on carcass conformation scores	MEAT SCIENCE			English	Article						bovine carcass; conformation assessment; SEUROP; artificial intelligence; machine learning; relevancy	ARTIFICIAL-INTELLIGENCE TECHNIQUES; CLASSIFICATION; INDUSTRY	In this study, a total of 163 young-bull carcasses belonging to seven Spanish native beef cattle breeds showing substantial carcass variation were photographed in order to obtain digital assessments of carcass dimensions and profiles. This dataset was then analysed using machine learning (ML) methodologies to ascertain the influence of carcass profiles on the grade obtained using the SEUROP system. To achieve this goal, carcasses were obtained using the same standard feeding regime and classified homogeneous conditions in order to avoid non-linear behaviour in grading performance. Carcass weight affects grading to a large extent and the classification error obtained when this attribute was included in the training sets was consistently lower than when it was not. However, carcass profile information was considered non-relevant by the ML algorithm in earlier stages of the analysis. Furthermore.. when carcass weight was taken into account, the ML algorithm used only easy-to-measure attributes to clone the classifiers decisions. Here we confirm the possibility of designing a more objective and easy-to-interpret system to classify the most common types of carcass in the territory of the EU using only a few single attributes that are easily obtained in an industrial environment. (c) 2005 Elsevier Ltd. All rights reserved.	SERIDA Somio, E-33203 Gijon, Asturias, Spain; Univ Oviedo, Ctr Inteligencia Artificial, E-33271 Gijon, Asturias, Spain; CITA Aragon, E-50080 Zaragoza, Spain; Univ Zaragoza, Dept Anim Prod, E-50013 Zaragoza, Spain	Goyache, F (reprint author), SERIDA Somio, C-Camino Claveles 604, E-33203 Gijon, Asturias, Spain.	fgoyache@serida.org	Ripoll, Guillermo/B-5693-2008; Goyache, Felix/B-7764-2009; Alberti, Pere/G-1103-2010				Alberti P, 2005, MEAT SCI, V71, P514, DOI 10.1016/j.meatsci.2005.04.033; ALLEN P, 2001, MECH GRADING BEEF CA; Borggaard C, 1996, MEAT SCI, V43, pS151, DOI 10.1016/0309-1740(96)00062-9; Boer H. de, 1974, Livestock Production Science, V1, P151; DELCOZ JJ, 2004, P 18 ANN C NEUR INF; DIEZ J, 2001, P CAEPIA 01 9 C AS E, V2, P1229; Diez J, 2003, MEAT SCI, V64, P249, DOI 10.1016/S0309-1740(02)00185-7; DIEZ J, 2004, P EUR C ART INT 04 V; Goyache F, 2005, ARCH TIERZUCHT, V48, P138; Goyache F, 2001, TRENDS FOOD SCI TECH, V12, P370, DOI 10.1016/S0924-2244(02)00010-9; KEANE MG, 1999, FARM FOOD        SUM; KEMPSTER AJ, 1988, ANIM PROD, V46, P365; OFERRALL GJM, 1990, ANIM PROD, V50, P19; QUINLAN JR, 1993, P 10 INT MACH LEARN; SAS, 1999, US GUID REL 8 2; VALLEJO M, 1992, ARCH ZOOTECNIA, V42, P29	16	7	7	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0309-1740		MEAT SCI	Meat Sci.	MAY	2006	73	1					109	115		10.1016/j.meatsci.2005.11.015		7	Food Science & Technology	Food Science & Technology	016DU	WOS:000235601700013	
J	Yuan, SF; Chu, FL				Yuan, SF; Chu, FL			Support vector machines-based fault diagnosis for turbo-pump rotor	MECHANICAL SYSTEMS AND SIGNAL PROCESSING			English	Article						fault diagnosis; support vector machines; turbo pump rotor	RECOGNITION; CLASSIFICATION	Most artificial intelligence methods used in fault diagnosis are based on empirical risk minimisation principle and have poor generalisation when fault samples are few. Support vector machines (SVM) is a new general machine-learning tool based on structural risk minimisation principle that exhibits good generalisation even when fault samples are few. Fault diagnosis based on SVM is discussed. Since basic SVM is originally designed for two-class classification, while most of fault diagnosis problems are multi-class cases, a new multi-class classification of SVM named 'one to others' algorithm is presented to solve the multi-class recognition problems. It is a binary tree classifier composed of several two-class classifiers organised by fault priority, which is simple, and has little repeated training amount, and the rate of training and recognition is expedited. The effectiveness of the method is verified by the application to the fault diagnosis for turbo pump rotor. (c) 2005 Elsevier Ltd. All rights reserved.	Tsing Hua Univ, Dept Precis Instruments & Mechanol, Beijing 100084, Peoples R China; So Inst Met, Sch Machinery & Power Generating Equipment Engn, Ganzhou 341000, Jiangxi Prov, Peoples R China	Chu, FL (reprint author), Tsing Hua Univ, Dept Precis Instruments & Mechanol, Beijing 100084, Peoples R China.	chufl@mail.tsinghua.edu.cn					Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; BENNETT KP, 1992, MIDW ART INT COGN SC; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chen Zhenyong, 2002, Journal of Tsinghua University (Science and Technology), V42; DANIEL JS, 2001, IEEE T SIGNAL PROCES, V49, P2865; Erin J., 1999, COMPUTATIONAL OPTIMI, V12, P53; Guo GD, 2001, IMAGE VISION COMPUT, V19, P631, DOI 10.1016/S0262-8856(01)00046-4; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40; Kressel UH-G, 1999, ADV KERNEL METHODS S, P225; LU S, 1996, J PROPULSION TECHNOL, V17, P14; Ma Xiao-xiao, 2003, Control and Decision, V18; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; Pearson K., 1896, PHILOS T R SOC A, V187, P253, DOI DOI 10.1098/RSTA.1896.0007; Platt J. C., 1998, ADV KERNEL METHODS S, P185; Platt JC, 2000, ADV NEUR IN, V12, P547; RIESZ F, 1955, FUNCTTIONAL ANAL, P34; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; SCHOLKOPF B, 2000, STAT TRAINING KERNEL, P18; SCHOLKOPF B, 2002, TRAINING KERNELS SUP, P165; Stevenson Robert Louis, 1998, SUPPORT VECTOR MACHI, P1; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Vapnik V.N., 1999, NATURE STAT LEARNING; Weston J., 1999, P ESANN99, P234; Weston J, 1998, CSDTR9804; WU J, 1997, J PROPULSION TECHNOL, V18, P26; YANG E, 2001, J TSINGHUA U, V41, P104; Yang M.H., 2002, P 5 IEEE INT C AUT F, P215, DOI 10.1109/AFGR.2002.4527207; [张炜 Zhang Wei], 2003, [推进技术, Journal of Propulsion Technology], V24, P17; ZHANG Y, 1997, J PROPULSION TECHNOL, V18, P8	31	63	85	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0888-3270		MECH SYST SIGNAL PR	Mech. Syst. Signal Proc.	MAY	2006	20	4					939	952		10.1016/j.ymssp.2005.09.006		14	Engineering, Mechanical	Engineering	011AJ	WOS:000235239700010	
J	Verzi, SJ; Heileman, GL; Georgiopoulos, M				Verzi, Stephen J.; Heileman, Gregory L.; Georgiopoulos, Michael			Boosted ARTMAP: Modifications to fuzzy ARTMAP motivated by boosting theory	NEURAL NETWORKS			English	Article							NEURAL-NETWORK; ARCHITECTURE	In this paper, several modifications to the Fuzzy ARTMAP neural network architecture are proposed for conducting classification in complex, possibly noisy, environments. The goal of these modifications is to improve upon the generalization performance of Fuzzy ART-based neural networks, such as Fuzzy ARTMAP, in these situations. One of the major difficulties of employing Fuzzy ARTMAP on such learning problems involves over-fitting of the training data. Structural risk minimization is a machine-learning framework that addresses the issue of over-fitting by providing a backbone for analysis as well as an impetus for the design of better learning algorithms. The theory of structural risk minimization reveals a trade-off between training error and classifier complexity in reducing generalization error, which will be exploited in the learning algorithms proposed in this paper. Boosted ART extends Fuzzy ART by allowing the spatial extent of each cluster formed to be adjusted independently. Boosted ARTMAP generalizes upon Fuzzy ARTMAP by allowing non-zero training error in an effort to reduce the hypothesis complexity and hence improve overall generalization performance. Although Boosted ARTMAP is strictly speaking not a boosting algorithm, the changes it encompasses were motivated by the goals that one strives to achieve when employing boosting. Boosted ARTMAP is an on-line learner, it does not require excessive parameter tuning to operate, and it reduces precisely to Fuzzy ARTMAP for particular parameter values. Another architecture described in this paper is Structural Boosted ARTMAP, which uses both Boosted ART and Boosted ARTMAP to perform structural risk minimization learning. Structural Boosted ARTMAP will allow comparison of the capabilities of off-line versus on-line learning as well as empirical risk minimization versus structural risk minimization using Fuzzy ARTMAP-based neural network architectures. Both empirical and theoretical results are presented to enhance the understanding of these architectures. (c) 2005 Elsevier Ltd. All rights reserved.	Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA; Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA; Univ Cent Florida, Dept Elect & Comp Engn, Orlando, FL 32816 USA	Heileman, GL (reprint author), Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.	heileman@ece.unm.edu					ANAGNOSTOPOULOS GC, 2002, P INT JOINT C NEUR N; Baras JS, 1999, IEEE T INFORM THEORY, V45, P1911, DOI 10.1109/18.782112; BLAKE C, 1998, UCI REPOSITORY MACH; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; CARPENTER GA, 1995, IEEE T NEURAL NETWOR, V6, P805, DOI 10.1109/72.392245; Carpenter GA, 1998, NEURAL NETWORKS, V11, P793, DOI 10.1016/S0893-6080(98)00019-7; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; Carpenter GA, 1998, NEURAL NETWORKS, V11, P323, DOI 10.1016/S0893-6080(97)00067-1; CARPENTER KE, 1992, HARVARD LIBR BULL, V3, P5; DAGHER I, 1997, THESIS U CENTRAL FLO; Devroye L., 1996, PROBABILISTIC THEORY; DIBENEDETTO F, 2001, REAL ANAL; GOMEZSANCHEZ E, 2000, P INT JOINT C NEUR N, V6, P47; Gomez-Sanchez E, 2002, IEEE T NEURAL NETWOR, V13, P58, DOI 10.1109/72.977271; HUSH D, 1997, LEARNING EXAMPLES TH; KEARNS M, 1995, BOOSTING ABILITY TOP; Koltchinskii V, 2001, IEEE T INFORM THEORY, V47, P1902, DOI 10.1109/18.930926; LAZANO F, 2000, P 2 ICSC S NEUR COMP; MARRIOTT S, 1995, NEURAL NETWORKS, V8, P619, DOI 10.1016/0893-6080(94)00110-8; Rudin W., 1974, REAL COMPLEX ANAL; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; VERZI SJ, 2003, THESIS U NEW MEXICO; VERZI SJ, 2003, P INT JOINT C NEUR N; Vidyasagar M., 1997, THEORY LEARNING GEN; Wellner J. A., 1996, WEAK CONVERGENCE EMP; Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8	29	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	MAY	2006	19	4					446	468		10.1016/j.neunet.2005.08.013		23	Computer Science, Artificial Intelligence	Computer Science	061PI	WOS:000238884300009	
J	Rani, P; Liu, CC; Sarkar, N; Vanman, E				Rani, P; Liu, CC; Sarkar, N; Vanman, E			An empirical study of machine learning techniques for affect recognition in human-robot interaction	PATTERN ANALYSIS AND APPLICATIONS			English	Article						affect recognition; machine learning; psychophysiology; emotional robotics	HUMAN-COMPUTER INTERACTION; EMOTION RECOGNITION; WORKLOAD; SYSTEM; TASK	Given the importance of implicit communication in human interactions, it would be valuable to have this capability in robotic systems wherein a robot can detect the motivations and emotions of the person it is working with. Recognizing affective states from physiological cues is an effective way of implementing implicit human-robot interaction. Several machine learning techniques have been successfully employed in affect-recognition to predict the affective state of an individual given a set of physiological features. However, a systematic comparison of the strengths and weaknesses of these methods has not yet been done. In this paper, we present a comparative study of four machine learning methods-K-Nearest Neighbor, Regression Tree (RT), Bayesian Network and Support Vector Machine (SVM) as applied to the domain of affect recognition using physiological signals. The results showed that SVM gave the best classification accuracy even though all the methods performed competitively. RT gave the next best classification accuracy and was the most space and time efficient.	Vanderbilt Univ, Dept Elect Engn, Nashville, TN 37235 USA; Vanderbilt Univ, Dept Mech Engn, Nashville, TN 37235 USA; Georgia State Univ, Dept Psychol, Atlanta, GA 30303 USA	Rani, P (reprint author), Vanderbilt Univ, Dept Elect Engn, Nashville, TN 37235 USA.	pramila.rani@vanderbilt.edu; changchun.liu@vanderbilt.edu; nilanjan.sarkar@vanderbilt.edu; evanman@gsu.edu	Liu, Changchun/D-2256-2012				Backs RW, 2003, HUM FACTORS, V45, P525, DOI 10.1518/hfes.45.4.525.27089; Bradley M. M., 2000, HDB PSYCHOPHYSIOLOGY, P602; Breazeal C, 2002, AUTON ROBOT, V12, P83, DOI 10.1023/A:1013215010749; Breiman L, 1984, CLASSIFICATION REGRE; BROWN LE, 2004, P 11 WORLD C MED INF; Brown RM, 1997, SEX ROLES, V36, P793, DOI 10.1023/A:1025631307585; BURGES C, 2000, KNOWLEDGE DISCOVERY, P1; Catlett J., 1991, P EUR WORK SESS LEAR, P164; COHEN I, 2000, A NIPS WORKSH AFF CO; Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390; CONATI C, 2002, P 6 INT C INT TUT SY; Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197; DOWNEY S, 1992, P I AC AUT C SPEECH, V14, P181; HAYAKAWA Y, 1998, ISCIE 1998 JAP US S, P35; Heckerman D., 1999, LEARNING GRAPHICAL M; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Hudlicka E, 2002, USER MODEL USER-ADAP, V12, P1, DOI 10.1023/A:1013337427135; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719; Kokol Peter, 1994, Journal of Medical Systems, V18, P201, DOI 10.1007/BF00996704; Kulic D, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P810; Littlewort GC, 2004, ADV NEUR IN, V16, P1563; MORIYAMA T, 1999, IEICE J, V82, P1710; Nasoz F, 2003, INT J COGN TECHNOL W, V6, P1; Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122; Pecchinenda A, 1996, COGNITION EMOTION, V10, P481, DOI 10.1080/026999396380123; PETRUSHIN VA, 2000, AAAI FALL S SOC INT; Picard R. W., 1997, AFFECTIVE COMPUTING; Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607; QI Y, 2002, P INT C PATT REC CAN; Rani P, 2004, ROBOTICA, V22, P85, DOI 10.1017/S0263574703005319; Reeves B., 1996, MEDIA EQUATION PEOPL; Takahashi K., 2004, P 2 INT C AUT ROB AG; TSAPATSOULIS N, 2000, P EUSIPCO 2000 FINL; Vapnik VN, 1998, STAT LEARNING THEORY; Walter WG, 1963, LIVING BRAIN; Wilson GF, 2003, HUM FACTORS, V45, P635, DOI 10.1518/hfes.45.4.635.27088; Zhao J., 1996, Progress in Neural Information Processing. Proceedings of the International Conference on Neural Information Processing; *WORLD ROB, 2004, GVE04020 WORLD ROB	39	34	34	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.	MAY	2006	9	1					58	69		10.1007/s10044-006-0025-y		12	Computer Science, Artificial Intelligence	Computer Science	047FZ	WOS:000237866500005	
J	Meyer, C; Schramm, H				Meyer, C; Schramm, H			Boosting HMM acoustic models in large vocabulary speech recognition	SPEECH COMMUNICATION			English	Article						boosting; AdaBoost; machine learning; acoustic model training; spontaneous speech; automatic speech recognition		Boosting algorithms have been successfully used to improve performance in a variety of classification tasks. Here, we suggest an approach to apply a popular boosting algorithm (called "AdaBoost.M2") to Hidden Markov Model based speech recognizers, at the level of utterances. In a variety of recognition tasks we show that boosting significantly improves the best test error rates obtained with standard maximum likelihood training. In addition, results in several isolated word decoding experiments show that boosting may also provide further performance gains over discriminative training, when both training techniques are combined. In our experiments this also holds when comparing final classifiers with a similar number of parameters and when evaluating in decoding conditions with lexical and acoustic mismatch to the training conditions. Moreover, we present an extension of our algorithm to large vocabulary continuous speech recognition, allowing online recognition without further processing of N-best lists or word lattices. This is achieved by using a lexical approach for combining different acoustic models in decoding. In particular, we introduce a weighted summation over an extended set of alternative pronunciation models representing both the boosted models and the baseline model. In this way, arbitrarily long utterances can be recognized by the boosted ensemble in a single pass decoding framework. Evaluation results are presented on two tasks: a real-life spontaneous speech dictation task with a 60k word vocabulary and Switchboard. (C) 2005 Elsevier B.V. All rights reserved.	Philips Res Labs, D-52066 Aachen, Germany	Meyer, C (reprint author), Philips Res Labs, Weisshausstr 2, D-52066 Aachen, Germany.	Carsteii.Meyer@philips.com					AUBERT X, 2000, P INT C SPOK LANG PR, V3, P802; AUBERT X, 1999, P EUR C SPEECH COMM, P1559; Bahl L., 1986, P IEEE INT C AC SPEE, P49; BEYERLEIN P, 2001, P EUROSPEECH, P499; Beyerlein P, 2002, SPEECH COMMUN, V37, P109, DOI 10.1016/S0167-6393(01)00062-0; COLLINS M, 2000, P 17 INT C MACH LEAR; Collins M., 2002, P ACL 2002; Cook G., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607852; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; DIMITRAKAKIS D, 2004, P INT C AC SPEECH SI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Godfrey J., 1992, P INT C AC SPEECH SI; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; KOLTCHINSKII V, 2002, ANN STAT, V30; MEYER C, 2002, P 19 INT C MACH LEAR, P419; MEYER C, 2004, P 6 IASTED INT C SIG; MEYER C, 2002, P ICASSP 02 ORL, P109; MEYER C, 2000, P INT C SPOK LANG PR, P632; PETERS J, 2003, P HUM LANG TECHN C H, P82; RAETSCH G, 2003, P EUROSPEECH 03 GEN, P997; Ruber B., 1997, P ESCA EUR 97 RHOD G, P739; Schapire R. E., 2002, P MSRI WORKSH NONL E, P149; Schapire RE, 1998, ANN STAT, V26, P1651; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHLUTER R, 1999, P IEEE ASRU WORKSH K, P119; SCHRAMM H, 2003, P SSPR, P143; SCHRAMM H, 2000, P INT C AC SPEECH SI, V3, P1659; SCHWENK H, 1999, P INT C AC SPEECH SI, P1009; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WOODLAND PC, 2000, P ISCA ITRW ASR2000, P7; ZHANG R, 2003, P EUROSPEECH 03 GEN, V3, P1885; Zheng J., 2000, P INT C AC SPEECH SI, V3, P1775; ZWEIG G, 2000, P INT C AC SPEECH SI, P1527	34	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393		SPEECH COMMUN	Speech Commun.	MAY	2006	48	5					532	548		10.1016/j.specom.2005.09.009		17	Acoustics; Communication; Computer Science, Interdisciplinary Applications; Language & Linguistics	Acoustics; Communication; Computer Science; Linguistics	037QB	WOS:000237160700005	
J	Litman, DJ; Forbes-Riley, K				Litman, DJ; Forbes-Riley, K			Recognizing student emotions and attitudes on the basis of utterances in spoken tutoring dialogues with both human and computer tutors	SPEECH COMMUNICATION			English	Article						emotional speech; predicting user state via machine learning; prosody; empirical study relevant to adaptive spoken dialogue systems; tutorial dialogue systems	AGREEMENT; COMMUNICATION; SPEECH; STATES	While human tutors respond to both what a student says and to how the student says it, most tutorial dialogue systems cannot detect the student emotions and attitudes underlying an utterance. We present an empirical study investigating the feasibility of recognizing student state in two corpora of spoken tutoring dialogues, one with a human tutor, and one with a computer tutor. We first annotate student turns for negative, neutral and positive student states in both corpora. We then automatically extract acoustic-prosodic features from the student speech, and lexical items from the transcribed or recognized speech. We compare the results of machine learning experiments using these features alone, in combination, and with student and task dependent features, to predict student states. We also compare our results across human-human and human-computer spoken tutoring dialogues. Our results show significant improvements in prediction accuracy over relevant baselines, and provide a first step towards enhancing our intelligent tutoring spoken dialogue system to automatically recognize and adapt to student states. (C) 2005 Elsevier B.V. All rights reserved.	Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA; Univ Pittsburgh, Ctr Learning Res & Dev, Pittsburgh, PA 15260 USA	Litman, DJ (reprint author), Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA.	litman@cs.pitt.edu; forbesk@pitt.edu					AIST G, 2002, P INT TUT SYST ITS, P992; ALEVEN V, 2001, P AI ED 2001, P246; ALEVEN V, 2003, P AIED 2003 WORKSH T; ANG J, 2002, P INT C SPOK LANG PR, P203; BATLINER A, 2000, ISCA WORKSH SPEECH E, P195; Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1; BHATT K, 2004, P COGN SCI; BIDDLE ES, 2003, P 3 US MOD WORKSH AS, P65; Black A., 1997, FESTIVAL SPEECH SYNT; CARLETTA J, 1996, COMPUT LINGUISTICS, V22; CAVALLUZZI A, 2003, P US MOD C JOHNST PA, P86; CHI MTH, 1994, COGNITIVE SCI, V18, P439, DOI 10.1016/0364-0213(94)90016-7; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256; COLES G, 1999, LIT EMOTIONS BRAIN; CONATI C, 2003, P 3 US MOD WORKSH AS, P16; CONATI C, 2003, P 3 US MOD WORKSH AS; Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197; CRAIG SD, 2003, ADV TECHNOLOGY BASED, V3, P1903; DEROSIS F, 1999, P US MOD WORKSH ATT; DEROSIS F, 2002, SPECIAL ISSUES USER, V12; DEROSIS F, 2001, SPECIAL ISSUES USER, V11; DEROSIS F, 2001, P US MOD WORKSH ATT; DEVILLERS L, 2003, P IEEE INT C MULT EX; DIEUGENIO B, 1997, P 35 ANN M ASS COMP; DIEUGENIO B, 2004, COMPUT LINGUISTICS, V30; EVENS M, 2001, P 12 MIDW AI COGN SC, P16; FAN C, 2003, P 2 INT C COMP INT R; FISCHER K, 1999, 236 VERBM; FORBESRILEY K, 2004, 4 M N AM CHAP ASS CO, P201; FORBESRILEY K, 2005, P INT C ART INT ED; FOX BA, 1993, HUMAN TUTORIAL DIAGL; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Graesser A. C., 2001, INT J ARTIFICIAL INT, V12, P257; Graesser AC, 2001, AI MAG, V22, P39; HAUSMANN R, 2002, J CONIGITIVE TECHNOL, V7, P4; HUANG X, 1993, COMPUT SPEECH LANG, V2, P137; Izard C. E, 1984, EMOTIONS COGNITION B, P17; JORDAN P, 2002, P 3 SIGDIAL WORKSH D, P74; JORDAN P, 2003, P ART INT ED, P73; JORDAN PW, 2004, P INT TUT SYST C ITS, P346; Kort B, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P43; KRIPPENDORF K, 1980, CONTENT AAL INTRO IT; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; LEE C, 2001, P IEEE AUT SPEECH RE; LEE C, 2002, P INT C SPOK LANG PR; LISCOMBE J, 2003, P EUROSPEECH; LITMAN D, 2004, P INT C INT TUT SYST, P368; LITMAN D, 2004, P SIGDIAL WORKSH DIS, P144; Litman D., 2003, P ASRU VIRG ISL, P25; LITMAN D, 2001, P 39 ANN M 10 C EUR, P362; Litman D. J., 2004, P 42 ANN M ASS COMP, P352; Litman DJ, 1996, J ARTIF INTELL RES, V5, P53; Litman D.J., 2004, P HUM LANG TECHN C 4, P233; MAEIREIZO B, 2004, COMP P ASS COMP LING, P203; MASTERS JC, 1979, J PERS SOC PSYCHOL, V37, P380, DOI 10.1037//0022-3514.37.3.380; Moreno R, 2001, COGNITION INSTRUCT, V19, P177, DOI 10.1207/S1532690XCI1902_02; Mostow J, 2001, SMART MACHINES IN EDUCATION, P169; Mozziconacci SJL, 2001, USER MODEL USER-ADAP, V11, P297, DOI 10.1023/A:1011800417621; NARAYANAN S, 2002, P ISLE WORKSH DIAL T; NASBY W, 1982, J PERS SOC PSYCHOL, V43, P1244, DOI 10.1037/0022-3514.43.6.1244; OUDEYER PY, 2002, INT J HUMAN COMPUTER, V59, P157; OWIE R, 2003, SPEECH COMMUN, V40, P5; Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122; Picard R.W., 2001, IEEE T PATTERN ANAL, V23; POLZIN TS, 1998, P COOP MULT COMM; POTTS R, 1986, MOTIV EMOTION, V10, P39, DOI 10.1007/BF00992149; Rickel J, 2000, EMBODIED CONVERSATIONAL AGENTS, P95; ROSE C, 2005, COMMUNICATION; Rose C. P., 2001, P ART INT ED, P256; ROSE CP, 2000, P 1 M N AM CHAPT ASS, P1129; ROSE CP, 2000, AAAI WORK NOT FALL S; ROSE CP, 2002, P ITS 2002 WORKSH EM; RUSSELL JA, 2003, ANNU REV PSYCHOL, V54, P29; Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5; SCHULTZ K, 2003, AIED S P, P367; Seipp B., 1991, ANXIETY RES, V4, P27, DOI 10.1080/08917779108248762; SHAFRAN I, 2003, P IEEE AUT SPEECH RE, P31; SHAH F, 2002, DISCOURSE PROCESS, V33; Siegel S., 1988, NONPARAMETRIC STAT B; Siegle G. J, 1994, BALANCED AFFECTIVE W; ten Bosch L, 2003, SPEECH COMMUN, V40, P213, DOI 10.1016/S0167-6393(02)00083-3; VanLehn K., 2002, P 6 INT C INT TUT SY, P158; Witten I. H., 1999, DATA MINING PRACTICA; ZINN, 2002, P INT TUT SYST C ITS, P574	85	23	23	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393		SPEECH COMMUN	Speech Commun.	MAY	2006	48	5					559	590		10.1016/j.specom.2005.09.008		32	Acoustics; Communication; Computer Science, Interdisciplinary Applications; Language & Linguistics	Acoustics; Communication; Computer Science; Linguistics	037QB	WOS:000237160700007	
J	Nascimento, DG; Rates, B; Santos, DM; Verano-Braga, T; Barbosa-Silva, A; Dutra, AAA; Biondi, I; Martin-Eauclaire, MF; De Lima, ME; Pimenta, AMC				Nascimento, DG; Rates, B; Santos, DM; Verano-Braga, T; Barbosa-Silva, A; Dutra, AAA; Biondi, I; Martin-Eauclaire, MF; De Lima, ME; Pimenta, AMC			Moving pieces in a taxonomic puzzle: Venom 2D-LC/MS and data clustering analyses to infer phylogenetic relationships in some scorpions from the Buthidae family (Scorpiones)	TOXICON			English	Article						buthidae phylogeny; data clustering analyses; 2D-LC/MS; venom proteomics; Tityus serrulatus; Tityus stigmurus; Tityus bahiensis; Leiurus quinquestriatus	TIME-OF-FLIGHT; PERFORMANCE LIQUID-CHROMATOGRAPHY; TOXINS AFFECTING SODIUM; MASS-SPECTROMETRY; TITYUS-SERRULATUS; TOXINOLOGICAL IMPLICATIONS; TARANTULA VENOMS; K+ CHANNELS; PEPTIDES; INSECT	The Buthidae is the most clinically important scorpion family, with over 500 species distributed worldwide. Taxonomical positions and phylogenetic relationships concerning the representative genera and species of this family have been mostly inferred based upon comparisons between morphological characters. Yet, some authors have performed such inferences by comparing some structural properties of a few selected molecules found in the venoms from these scorpions. Here, we propose a novel methodology pipeline designed to address these issues. We have analyzed the whole venoms from some species that exemplify peculiar cases in the Buthidae family (Tityus stigmurus, Tityus serrulatus, Tityus bahiensis, Leiurus quinquestriatus quinquestriatus and Leiurus quinquestriatus hebraeus), by means of a proteomic approach using a 2D-LC/MS technique. The molecules found in these venoms were clustered according to their physicochemical properties (molecular mass and hydrophobicity), by using the machine learning-based Weka software. The clusters assessment, along with the number of molecules found in a given cluster for each scorpion, which assigns for the venom and structural family complexities, respectively, was used to generate a phenetic correlation tree for positioning these species. Our results were in accordance with the classical taxonomy viewpoint, which places T. serrulatus and T. stigmurus as very close species, T. bahiensis as a less related species in the Tityus genus and L. q. quinquestriatus and L. q. hebraeus with small differences within the same species (L. quinquestriatus). Therefore, we believe that this is a well-suited method to determine venom complexities that reflect the scorpions' evolutionary history, which can be crucial to reconstruct their phylogeny through the molecular evolution of their venoms. (c) 2006 Elsevier Ltd. All rights reserved.	Univ Fed Minas Gerais, Inst Ciencias Biol, Lab Venenos & Toxinas Anim, Dept Bioquim & Imunol, BR-31270901 Belo Horizonte, MG, Brazil; Univ Fed Minas Gerais, Inst Ciencias Biol, Lab Biodados Biol Celular & Desenvolvimento, Dept Bioquim & Imunol, BR-31270901 Belo Horizonte, MG, Brazil; Univ Fed Ouro Preto, Inst Ciencias Exatas & Biol, Dept Farm, Lab Biol Celular & Mol, BR-35400000 Ouro Preto, MG, Brazil; Univ Estadual Feira Santana, Dept Ciencias Biol, Lab Anim Peconhentos & Herpetol, BR-44031060 Feira De Santana, Bahia, Brazil; Univ Mediterranee, UMR6560, IFR Jean Roche, CNRS,FRE 2738, F-13916 Marseille, France	Pimenta, AMC (reprint author), Univ Fed Minas Gerais, Inst Ciencias Biol, Lab Venenos & Toxinas Anim, Dept Bioquim & Imunol, Av Antonio Carlos 6627,Campus Pampulha,Caixa Post, BR-31270901 Belo Horizonte, MG, Brazil.	apimenta@icb.ufmg.br	Barbosa-Silva, Adriano/G-4713-2011				Becerril B, 1997, TOXICON, V35, P821, DOI 10.1016/S0041-0101(96)00198-5; Becerril B, 1996, BIOCHEM J, V313, P753; BONTEMS F, 1991, SCIENCE, V254, P1521, DOI 10.1126/science.1720574; BRADFORD MM, 1976, ANAL BIOCHEM, V72, P248, DOI 10.1006/abio.1976.9999; Ceard B, 2001, FEBS LETT, V494, P246, DOI 10.1016/S0014-5793(01)02336-5; Creer S, 2003, J MOL EVOL, V56, P317, DOI 10.1007/s00239-002-2403-4; DELIMA ME, 1995, J TOXICOL-TOXIN REV, V14, P457; Dyason K, 2002, RAPID COMMUN MASS SP, V16, P768, DOI 10.1002/rcm.637; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Escoubas P, 2002, RAPID COMMUN MASS SP, V16, P403, DOI 10.1002/rcm.595; Escoubas P, 1997, RAPID COMMUN MASS SP, V11, P1891, DOI 10.1002/(SICI)1097-0231(199711)11:17<1891::AID-RCM94>3.0.CO;2-X; Escoubas P, 1999, RAPID COMMUN MASS SP, V13, P1861, DOI 10.1002/(SICI)1097-0231(19990930)13:18<1861::AID-RCM730>3.0.CO;2-7; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Froy O, 2003, TOXICON, V42, P549, DOI 10.1016/S0041-0101(03)00236-8; Froy O, 1999, J MOL EVOL, V48, P187, DOI 10.1007/PL00006457; Fry BG, 2002, RAPID COMMUN MASS SP, V16, P600, DOI 10.1002/rcm.613; Fry BG, 2003, RAPID COMMUN MASS SP, V17, P2047, DOI 10.1002/rcm.1148; Gordon D, 1998, J TOXICOL-TOXIN REV, V17, P131; Gordon D, 2003, EUR J BIOCHEM, V270, P2663, DOI 10.1046/j.1432-1033.2003.03643.x; Legros C, 1998, FEBS LETT, V431, P375, DOI 10.1016/S0014-5793(98)00780-7; Lourenco W.R., 2002, SCORPIONS BRAZIL; LOURENCO WR, 1877, REV BRAS BIOL, V41, P351; Lourenco WR, 1999, J ARACHNOL, V27, P154; OMRAN MAA, 2000, TOXIN REV, V19, P247, DOI 10.1081/TXR-100102322; Pimenta AMC, 2001, RAPID COMMUN MASS SP, V15, P1562, DOI 10.1002/rcm.415; Pimenta AMC, 2005, RAPID COMMUN MASS SP, V19, P31, DOI 10.1002/rcm.1751; Pimenta AMC, 2005, J PEPT SCI, V11, P670, DOI 10.1002/psc.701; Pimenta AMC, 2003, BIOCHEM BIOPH RES CO, V301, P1086, DOI 10.1016/S0006-291X(03)00082-2; Possani LD, 1999, EUR J BIOCHEM, V264, P287, DOI 10.1046/j.1432-1327.1999.00625.x; Possani LD, 2000, BIOCHIMIE, V82, P861, DOI 10.1016/S0300-9084(00)01167-6; RomiLebrun R, 1997, BIOCHEMISTRY-US, V36, P13473, DOI 10.1021/bi971044w; Smertenko A, 2001, J TOXICOL-TOXIN REV, V20, P229, DOI 10.1081/TXR-100108558; Stocklin R, 2000, METH MOL B, V146, P317, DOI 10.1385/1-59259-045-4:317; Tytgat J, 1999, TRENDS PHARMACOL SCI, V20, P444, DOI 10.1016/S0165-6147(99)01398-X; Witten Ian H., 2005, DATA MINIG PRACTICAL; ZLOTKIN E, 1985, ARCH BIOCHEM BIOPHYS, V240, P877, DOI 10.1016/0003-9861(85)90098-0	36	33	54	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0041-0101		TOXICON	Toxicon	MAY	2006	47	6					628	639		10.1016/j.toxicon.2006.01.015		12	Pharmacology & Pharmacy; Toxicology	Pharmacology & Pharmacy; Toxicology	047XM	WOS:000237912000003	
J	Dobson, RJ; Munroe, PB; Caulfield, MJ; Saqi, MAS				Dobson, Richard J.; Munroe, Patricia B.; Caulfield, Mark J.; Saqi, Mansoor A. S.			Predicting deleterious nsSNPs: an analysis of sequence and structural attributes	BMC BIOINFORMATICS			English	Article							SINGLE NUCLEOTIDE POLYMORPHISMS; NON-SYNONYMOUS SNPS; PROTEIN-STRUCTURE; DATABASE; INFORMATION; DISEASE	Background: There has been an explosion in the number of single nucleotide polymorphisms ( SNPs) within public databases. In this study we focused on non- synonymous protein coding single nucleotide polymorphisms (nsSNPs), some associated with disease and others which are thought to be neutral. We describe the distribution of both types of nsSNPs using structural and sequence based features and assess the relative value of these attributes as predictors of function using machine learning methods. We also address the common problem of balance within machine learning methods and show the effect of imbalance on nsSNP function prediction. We show that nsSNP function prediction can be significantly improved by 100% undersampling of the majority class. The learnt rules were then applied to make predictions of function on all nsSNPs within Ensembl. Results: The measure of prediction success is greatly affected by the level of imbalance in the training dataset. We found the balanced dataset that included all attributes produced the best prediction. The performance as measured by the Matthews correlation coefficient ( MCC) varied between 0.49 and 0.25 depending on the imbalance. As previously observed, the degree of sequence conservation at the nsSNP position is the single most useful attribute. In addition to conservation, structural predictions made using a balanced dataset can be of value. Conclusion: The predictions for all nsSNPs within Ensembl, based on a balanced dataset using all attributes, are available as a DAS annotation. Instructions for adding the track to Ensembl are at http:// www. brightstudy. ac. uk/ das_ help. html.	Queen Mary Univ London, Barts & London Sch Med & Dent, William Harvey Res Inst, London EC1M 6BQ, England; Univ London Queen Mary Coll, Inst Cell & Mol Sci, Barts & London Sch Med & Dent, London EC1M 6BQ, England	Saqi, MAS (reprint author), Queen Mary Univ London, Barts & London Sch Med & Dent, William Harvey Res Inst, Charterhouse Sq, London EC1M 6BQ, England.	r.j.dobson@qmul.ac.uk; p.b.munroe@qmul.ac.uk; m.j.caulfield@qmul.ac.uk; m.saqi@qmul.ac.uk	dobson, richard/C-9269-2011				Al-Shahib Ali, 2005, Appl Bioinformatics, V4, P195, DOI 10.2165/00822942-200594030-00004; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bader GD, 2003, NUCLEIC ACIDS RES, V31, P248, DOI 10.1093/nar/gkg056; BAO L, 2005, BIOINFORMATICS; BLACK SD, 1991, ANAL BIOCHEM, V193, P72, DOI 10.1016/0003-2697(91)90045-U; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Ashburner M, 2000, NAT GENET, V25, P25; Cavallo A, 2005, BIOINFORMATICS, V21, P1443, DOI 10.1093/bioinformatics/bti220; Chasman D, 2001, J MOL BIOL, V307, P683, DOI 10.1006/jmbi.2001.4510; Chen J, 2003, NUCLEIC ACIDS RES, V31, P474, DOI 10.1093/nar/gkg086; Dayhoff MO, 1978, ATLAS PROTEIN SEQ S3, P345; Dowell R D, 2001, BMC Bioinformatics, V2, P7, DOI 10.1186/1471-2105-2-7; FREDMAN D, 2004, NUCLEIC ACIDS RES, pD516; Hubbard T, 2002, NUCLEIC ACIDS RES, V30, P38, DOI 10.1093/nar/30.1.38; Karchin R, 2005, BIOINFORMATICS, V21, P2814, DOI 10.1093/bioinformatics/bti442; Krishnan VG, 2003, BIOINFORMATICS, V19, P2199, DOI 10.1093/bioinformatics/btg297; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; MILLER S, 1987, J MOL BIOL, V196, P641, DOI 10.1016/0022-2836(87)90038-6; Ramensky V, 2002, NUCLEIC ACIDS RES, V30, P3894, DOI 10.1093/nar/gkf493; ROST B, 1994, PROTEINS, V20, P216, DOI 10.1002/prot.340200303; SANDER C, 1993, NUCLEIC ACIDS RES, V21, P3105, DOI 10.1093/nar/21.13.3105; Saunders CT, 2002, J MOL BIOL, V322, P891, DOI 10.1016/S0022-2836(02)00813-6; SHANNON CE, 1948, BELL SYSTEM TECH; Sherry ST, 2001, NUCLEIC ACIDS RES, V29, P308, DOI 10.1093/nar/29.1.308; STITZIEL N, 2004, NUCLEIC ACIDS RES, pD520; Sunyaev S, 2000, TRENDS GENET, V16, P198, DOI 10.1016/S0168-9525(00)01988-0; Tsai J, 1999, J MOL BIOL, V290, P253, DOI 10.1006/jmbi.1999.2829; Vitkup D, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-11-r72; Wang Z, 2001, HUM MUTAT, V17, P263, DOI 10.1002/humu.22; WEISS G, 2001, MLTR44 U GLASG DEP C; Witten I. H., 1999, DATA MINING PRACTICA; Wixon J, 2000, YEAST, V17, P48, DOI 10.1002/(SICI)1097-0061(200004)17:1<48::AID-YEA2>3.0.CO;2-H; Yip YL, 2004, HUM MUTAT, V23, P464, DOI 10.1002/humu.20021	33	38	38	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	APR 21	2006	7								217	10.1186/1471-2105-7-217		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	063JA	WOS:000239013300001	
J	Hinsby, AM; Kiemer, L; Karlberg, EO; Lage, K; Fausboll, A; Juncker, AS; Andersen, JS; Mann, M; Brunak, S				Hinsby, AM; Kiemer, L; Karlberg, EO; Lage, K; Fausboll, A; Juncker, AS; Andersen, JS; Mann, M; Brunak, S			A wiring of the human nucleolus	MOLECULAR CELL			English	Article							PROTEIN-PROTEIN INTERACTIONS; PRE-RIBOSOMAL-RNA; INTERACTION NETWORK; FUNCTIONAL-CHARACTERIZATION; INTERACTION MAP; CELL-CYCLE; C-ELEGANS; YEAST; EXOSOME; LOCALIZATION	Recent proteomic efforts have created an extensive inventory of the human nucleolar proteome. However, approximately 30% of the identified proteins lack functional annotation. We present an approach of assigning function to uncharacterized nucleolar proteins by data integration coupled to a machine-learning method. By assembling protein complexes, we present a first draft of the human ribosome biogenesis pathway encompassing 74 proteins and hereby assign function to 49 previously uncharacterized proteins. Moreover, the functional diversity of the nucleolus is underlined by the identification of a number of protein complexes with functions beyond ribosome biogenesis. Finally, we were able to obtain experimental evidence of nucleolar localization of 11 proteins, which were predicted by our platform to be associates of nucleolar complexes. We believe other biological organelles or systems could be "wired" in a similar fashion, integrating different types of data with high-throughput proteomics, followed by a detailed biological analysis and experimental validation.	Tech Univ Denmark, BioCent, Ctr Biol Sequence Anal, DK-2800 Lyngby, Denmark; Dept Biochem & Mol Biol, DK-5230 Odense M, Denmark	Brunak, S (reprint author), Tech Univ Denmark, BioCent, Ctr Biol Sequence Anal, DK-2800 Lyngby, Denmark.	brunak@cbs.dtu.dk	Mann, Matthias/A-3454-2013	Mann, Matthias/0000-0003-1292-4799			Alfarano C, 2005, NUCLEIC ACIDS RES, V33, pD418, DOI 10.1093/nar/gki051; Andersen JS, 2005, NATURE, V433, P77, DOI 10.1038/nature03207; Andersen JS, 2002, CURR BIOL, V12, P1, DOI 10.1016/S0960-9822(01)00650-9; Bader GD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-2; Bader GD, 2002, NAT BIOTECHNOL, V20, P991, DOI 10.1038/nbt1002-991; Bairoch A, 2005, NUCLEIC ACIDS RES, V33, pD154, DOI 10.1093/nar/gki070; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; Barrett T, 2005, NUCLEIC ACIDS RES, V33, pD562; Bassler J, 2001, MOL CELL, V8, P517, DOI 10.1016/S1097-2765(01)00342-2; Bendtsen JD, 2004, PROTEIN ENG DES SEL, V17, P349, DOI 10.1093/protein/gzh037; Chen CY, 2001, CELL, V107, P451, DOI 10.1016/S0092-8674(01)00578-5; Cherry JM, 1998, NUCLEIC ACIDS RES, V26, P73, DOI 10.1093/nar/26.1.73; Dez C, 2004, CURR OPIN MICROBIOL, V7, P631, DOI 10.1016/j.mib.2004.10.007; Dragon F, 2002, NATURE, V417, P967, DOI 10.1038/nature00769; Estevez AM, 2001, EMBO J, V20, P3831, DOI 10.1093/emboj/20.14.3831; Estevez AM, 2003, J BIOL CHEM, V278, P34943, DOI 10.1074/jbc.M305333200; Fatica A, 2002, MOL CELL, V9, P341, DOI 10.1016/S1097-2765(02)00458-6; Fatica A, 2002, CURR OPIN CELL BIOL, V14, P313, DOI 10.1016/S0955-0674(02)00336-8; Fromont-Racine M, 2003, GENE, V313, P17, DOI 10.1016/S0378-1119(03)00629-2; Gavin AC, 2006, NATURE, V440, P631, DOI 10.1038/nature04532; Gerbi SA, 2003, CURR OPIN CELL BIOL, V15, P318, DOI 10.1016/S0955-0674(03)00049-8; Giot L, 2003, SCIENCE, V302, P1727, DOI 10.1126/science.1090289; Grandi P, 2002, MOL CELL, V10, P105, DOI 10.1016/S1097-2765(02)00579-8; Granneman S, 2005, CURR OPIN CELL BIOL, V17, P281, DOI 10.1016/j.ceb.2005.04.001; Harnpicharnchai P, 2001, MOL CELL, V8, P505, DOI 10.1016/S1097-2765(01)00344-6; Hernandez-Verdun D, 2006, HISTOCHEM CELL BIOL, V125, P127, DOI 10.1007/s00418-005-0046-4; Huang T, 2002, EMBO J, V21, P5516, DOI 10.1093/emboj/cdf555; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Jurica MS, 2003, MOL CELL, V12, P5, DOI 10.1016/S1097-2765(03)00270-3; la Cour T, 2004, PROTEIN ENG DES SEL, V17, P527, DOI 10.1093/protein/gzh062; Lehner B, 2004, GENOME RES, V14, P1315, DOI 10.1101/gr.2122004; Lehner B, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-9-r63; Li SM, 2004, SCIENCE, V303, P540, DOI 10.1126/science.1091403; Lund O, 1997, PROTEIN ENG, V10, P1241, DOI 10.1093/protein/10.11.1241; MELESE T, 1995, CURR OPIN CELL BIOL, V7, P319, DOI 10.1016/0955-0674(95)80085-9; Nilsen TW, 2002, MOL CELL, V9, P8, DOI 10.1016/S1097-2765(02)00430-6; Nissan TA, 2002, EMBO J, V21, P5539, DOI 10.1093/emboj/cdf547; Oda T, 2004, J CELL BIOCHEM, V93, P788, DOI 10.1002/jcb.20114; Olson MO, 2004, NUCLEOLUS; Olson MOJ, 2005, HISTOCHEM CELL BIOL, V123, P203, DOI 10.1007/s00418-005-0754-9; Raijmakers R, 2002, J MOL BIOL, V323, P653, DOI 10.1016/S0022-2836(02)00947-6; Remm M, 2001, J MOL BIOL, V314, P1041, DOI 10.1006/jmbi.2001.5197; Rual JF, 2005, NATURE, V437, P1173, DOI 10.1038/nature04209; Saveanu C, 2001, EMBO J, V20, P6475, DOI 10.1093/emboj/20.22.6475; Schafer T, 2003, EMBO J, V22, P1370, DOI 10.1093/emboj/cdg121; Scherl A, 2002, MOL BIOL CELL, V13, P4100, DOI 10.1091/mbc.E02-05-0271; Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303; Song ZY, 2005, ONCOGENE, V24, P2723, DOI 10.1038/sj.onc.1208097; Stelzl U, 2005, CELL, V122, P957, DOI 10.1016/j.cell.2005.08.029; Stevens SW, 2002, MOL CELL, V9, P31, DOI 10.1016/S1097-2765(02)00436-7; Su AI, 2004, P NATL ACAD SCI USA, V101, P6062, DOI 10.1073/pnas.0400782101; Uetz P, 2000, NATURE, V403, P623; Visintin R, 2000, CURR OPIN CELL BIOL, V12, P372, DOI 10.1016/S0955-0674(00)00102-2; Walhout AJM, 2000, SCIENCE, V287, P116, DOI 10.1126/science.287.5450.116; Wolin SL, 1999, GENE DEV, V13, P1, DOI 10.1101/gad.13.1.1	56	44	47	CELL PRESS	CAMBRIDGE	600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA	1097-2765		MOL CELL	Mol. Cell	APR 21	2006	22	2					285	295		10.1016/j.molcel.2006.03.012		11	Biochemistry & Molecular Biology; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	037MG	WOS:000237150400017	
J	Zhang, XG; Lu, X; Shi, Q; Xu, XQ; Leung, HCE; Harris, LN; D Iglehart, J; Miron, A; Liu, JS; Wong, WH				Zhang, XG; Lu, X; Shi, Q; Xu, XQ; Leung, HCE; Harris, LN; D Iglehart, J; Miron, A; Liu, JS; Wong, WH			Recursive SVM feature selection and sample classification for mass-spectrometry and microarray data	BMC BIOINFORMATICS			English	Article							GENE-EXPRESSION PATTERNS; MOLECULAR CLASSIFICATION; PROTEOMIC PATTERNS; BREAST-CANCER; DISCOVERY; SERUM; BIAS	Background: Like microarray-based investigations, high-throughput proteomics techniques require machine learning algorithms to identify biomarkers that are informative for biological classification problems. Feature selection and classification algorithms need to be robust to noise and outliers in the data. Results: We developed a recursive support vector machine (R-SVM) algorithm to select important genes/biomarkers for the classification of noisy data. We compared its performance to a similar, state-of-the-art method (SVM recursive feature elimination or SVM-RFE), paying special attention to the ability of recovering the true informative genes/biomarkers and the robustness to outliers in the data. Simulation experiments show that a 5%-similar to 20% improvement over SVM-RFE can be achieved regard to these properties. The SVM-based methods are also compared with a conventional univariate method and their respective strengths and weaknesses are discussed. R-SVM was applied to two sets of SELDI-TOF-MS proteomics data, one from a human breast cancer study and the other from a study on rat liver cirrhosis. Important biomarkers found by the algorithm were validated by follow-up biological experiments. Conclusion: The proposed R-SVM method is suitable for analyzing noisy high-throughput proteomics and microarray data and it outperforms SVM-RFE in the robustness to noise and in the ability to recover informative features. The multivariate SVM-based method outperforms the univariate method in the classification performance, but univariate methods can reveal more of the differentially expressed features especially when there are correlations between the features.	Tsing Hua Univ, Bioinformat Div, TNLIST, Beijing 100084, Peoples R China; Tsing Hua Univ, Dept Automat, Beijing 100084, Peoples R China; Harvard Univ, Sch Publ Hlth, Dept Biostat, Boston, MA 02115 USA; Dana Farber Canc Inst, Dept Canc Biol, Boston, MA 02115 USA; Genome Inst Singapore, Med Proteom & Bioanal Sect, Singapore, Singapore; Harvard Univ, Dept Stat, Cambridge, MA 02138 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Zhang, XG (reprint author), Tsing Hua Univ, Bioinformat Div, TNLIST, Beijing 100084, Peoples R China.	xgzhang@tsinghua.edu.cn; xinlu@hsph.harvard.edu; Qian_Shi@dfci.harvard.edu; jxu@escellinternational.com; leunge@gis.a-star.edu.sg; lyndsay_harris@dfci.harvard.edu; JIGLEHART@PARTNERS.ORG; Alexander_Miron@dfci.harvard.edu; jliu@stat.harvard.edu; whwong@stanford.edu					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Barash Y, 2004, BIOINFORMATICS, V20, P839, DOI 10.1093/bioinformatics/btg487; Ben-Dor A., 2000, RECOMB 2000. Proceedings of the Fourth Annual International Conference on Computational Molecular Biology; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Duda R.O, 1973, PATTERN CLASSIFICATI; Fung ET, 2002, BIOTECHNIQUES S, V34-8, P40; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gruvberger S, 2001, CANCER RES, V61, P5979; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hulett MD, 2000, IMMUNOL CELL BIOL, V78, P280, DOI 10.1046/j.1440-1711.2000.00940.x; KOU Z, 2001, P 8 INT C NEUR INF P, V2, P883; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; MUKHERJEE S, 1998, 1677 MIT; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Petricoin EF, 2002, NAT REV DRUG DISCOV, V1, P683, DOI 10.1038/nrd891; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Rai AJ, 2004, ANN NY ACAD SCI, V1022, P286, DOI 10.1196/annals.1318.044; SHI Q, 2005, UNPUB CLIN CANC RES; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Wu ZJ, 2004, NAT BIOTECHNOL, V22, P656, DOI 10.1038/nbt0604-656b; Xu XQ, 2004, PROTEOMICS, V4, P3235, DOI 10.1002/pmic.200400839; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698; ZHANG X, 2001, RECURSIVE SAMPLE CLA; Zhang X, 1999, NEURAL NETWORKS SIGN, P3	34	89	100	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	APR 10	2006	7								197	10.1186/1471-2105-7-1-197		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	038XT	WOS:000237263600001	
J	Kislinger, T; Cox, B; Kannan, A; Chung, C; Hu, PZ; Ignatchenko, A; Scott, MS; Gramolini, AO; Morris, Q; Hallett, MT; Rossant, J; Hughes, TR; Frey, B; Emili, A				Kislinger, T; Cox, B; Kannan, A; Chung, C; Hu, PZ; Ignatchenko, A; Scott, MS; Gramolini, AO; Morris, Q; Hallett, MT; Rossant, J; Hughes, TR; Frey, B; Emili, A			Global survey of organ and organelle protein expression in mouse: Combined proteomic and transcriptomic profiling	CELL			English	Article							PREDICTING SUBCELLULAR-LOCALIZATION; SPECTROMETRY-BASED PROTEOMICS; YEAST PROTEOME; MEMBRANE PROTEINS; GENE-EXPRESSION; SCALE; IDENTIFICATION; ABUNDANCE; GENOME; LOCATIONS	Organs and organelles represent core biological systems in mammals, but the diversity in protein composition remains unclear. Here, we combine subcellular fractionation with exhaustive tandem mass spectrometry-based shotgun sequencing to examine the protein content of four major organellar compartments (cytosol, membranes [microsomes], mitochondria, and nuclei) in six organs (brain, heart, kidney, liver, lung, and placenta) of the laboratory mouse, Mus musculus. Using rigorous statistical filtering and machine-learning methods, the subcellular localization of 3274 of the 4768 proteins identified was determined with high confidence, including 1503 previously uncharacterized factors, while tissue selectivity was evaluated by comparison to previously reported mRNA expression patterns. This molecular compendium, fully accessible via a searchable web-browser interface, serves as a reliable reference of the expressed tissue and organelle proteomes of a leading model mammal.	Univ Toronto, Banting & Best Dept Med Res, Toronto, ON M5G 1L6, Canada; Univ Toronto, Dept Med Genet & Microbiol, Toronto, ON M5S 1A8, Canada; Hosp Sick Children, Dept Dev Biol, Toronto, ON M5G 1L7, Canada; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 2E4, Canada; McGill Univ, Ctr Bioinformat, Montreal, PQ H3A 2B4, Canada	Emili, A (reprint author), Univ Toronto, Donnelly Ctr Cellular & Biomol Res, 160 Coll St,Room 914, Toronto, ON M5S 3E1, Canada.	andrew.emili@utoronto.ca	Kislinger, Thomas/A-5934-2008; Scott, Michelle/C-7445-2013	Scott, Michelle/0000-0001-6231-7714			Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Andersen JS, 2002, CURR BIOL, V12, P1, DOI 10.1016/S0960-9822(01)00650-9; Beausoleil SA, 2004, P NATL ACAD SCI USA, V101, P12130, DOI 10.1073/pnas.0404720101; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Bertone P, 2004, SCIENCE, V306, P2242, DOI 10.1126/science.1103388; Brunet S, 2003, TRENDS CELL BIOL, V13, P629, DOI 10.1016/j.tcb.2003.10.006; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; Cox B, 2005, METHODS, V35, P303, DOI 10.1016/j.ymeth.2004.08.021; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Ghaemmaghami S, 2003, NATURE, V425, P737, DOI 10.1038/nature02046; Griffin TJ, 2002, MOL CELL PROTEOMICS, V1, P323, DOI 10.1074/mcp.M200001-MCP200; Gygi SP, 1999, MOL CELL BIOL, V19, P1720; HECHENBICHLER K, 2004, 399 SFB; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; IMAOKA S, 1995, ARCH BIOCHEM BIOPHYS, V321, P255, DOI 10.1006/abbi.1995.1393; Kawai J, 2001, NATURE, V409, P685, DOI 10.1038/35055500; Kislinger T, 2003, MOL CELL PROTEOMICS, V2, P96, DOI 10.1074/mcp.M200074-MCP200; Krapfenbauer K, 2003, ELECTROPHORESIS, V24, P1847, DOI 10.1002/elps.200305401; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; Kumar A, 2002, GENE DEV, V16, P707, DOI 10.1101/gad.970902; Kuo WP, 2002, BIOINFORMATICS, V18, P405, DOI 10.1093/bioinformatics/18.3.405; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Larkin JE, 2005, NAT METHODS, V2, P337, DOI 10.1038/nmeth757; Le Roch KG, 2004, GENOME RES, V14, P2308, DOI 10.1101/gr.2523904; Lian Z, 2001, BLOOD, V98, P513, DOI 10.1182/blood.V98.3.513; Liu HB, 2004, ANAL CHEM, V76, P4193, DOI 10.1021/ac0498563; Lu Z, 2004, BIOINFORMATICS, V20, P547, DOI 10.1093/bioinformatics/btg447; Margulies EH, 2005, P NATL ACAD SCI USA, V102, P4795, DOI 10.1073/pnas.0409882102; Mootha VK, 2003, CELL, V115, P629, DOI 10.1016/S0092-8674(03)00926-7; Mott R, 2002, GENOME RES, V12, P1168, DOI 10.1101/gr.96802; Mulder NJ, 2005, NUCLEIC ACIDS RES, V33, pD201, DOI 10.1093/nar/gki106; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nielsen PA, 2005, MOL CELL PROTEOMICS, V4, P402, DOI 10.1074/mcp.T500002-MCP200; Ong SE, 2005, NAT CHEM BIOL, V1, P252, DOI 10.1038/nchembio736; Pan Q, 2004, MOL CELL, V16, P929, DOI 10.1016/j.molcel.2004.12.004; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Peng JM, 2003, J PROTEOME RES, V2, P43, DOI 10.1021/pr025556v; Phizicky E, 2003, NATURE, V422, P208, DOI 10.1038/nature01512; Rossant J, 2001, NAT REV GENET, V2, P538, DOI 10.1038/35080570; Saldanha AJ, 2004, BIOINFORMATICS, V20, P3246, DOI 10.1093/bioinformatics/bth349; Schirmer EC, 2003, SCIENCE, V301, P1380, DOI 10.1126/science.1088176; Scott MS, 2004, GENOME RES, V14, P1957, DOI 10.1101/gr.2650004; Skarnes WC, 2004, NAT GENET, V36, P543, DOI 10.1038/ng0604-543; Su AI, 2004, P NATL ACAD SCI USA, V101, P6062, DOI 10.1073/pnas.0400782101; Washburn MP, 2001, NAT BIOTECHNOL, V19, P242, DOI 10.1038/85686; Wu CC, 2004, MOL BIOL CELL, V15, P2907, DOI 10.1091/mbc.E04-02-0101; Zhang Wen, 2004, J Biol, V3, P21, DOI 10.1186/jbiol16; Zybailov B, 2005, ANAL CHEM, V77, P6218, DOI 10.1021/ac050846r	50	257	270	CELL PRESS	CAMBRIDGE	600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA	0092-8674		CELL	Cell	APR 7	2006	125	1					173	186		10.1016/j.cell.2006.01.044		14	Biochemistry & Molecular Biology; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	039NY	WOS:000237314200022	
J	Churbanov, A; Rogozin, IB; Deogun, JS; Ali, H				Churbanov, Alexander; Rogozin, Igor B.; Deogun, Jitender S.; Ali, Hesham			Method of predicting Splice Sites based on signal interactions	BIOLOGY DIRECT			English	Article							PRE-MESSENGER-RNA; HIDDEN MARKOV-MODELS; SR PROTEINS; SEQUENCE INFORMATION; GENE STRUCTURE; BINDING-SITES; HNRNP A1; RECOGNITION; MOTIFS; IDENTIFICATION	Background: Predicting and proper ranking of canonical splice sites (SSs) is a challenging problem in bioinformatics and machine learning communities. Any progress in SSs recognition will lead to better understanding of splicing mechanism. We introduce several new approaches of combining a priori knowledge for improved SS detection. First, we design our new Bayesian SS sensor based on oligonucleotide counting. To further enhance prediction quality, we applied our new de novo motif detection tool MHMMotif to intronic ends and exons. We combine elements found with sensor information using Naive Bayesian Network, as implemented in our new tool SpliceScan. Results: According to our tests, the Bayesian sensor outperforms the contemporary Maximum Entropy sensor for 5' SS detection. We report a number of putative Exonic (ESE) and Intronic (ISE) Splicing Enhancers found by MHMMotif tool. T-test statistics on mouse/rat intronic alignments indicates, that detected elements are on average more conserved as compared to other oligos, which supports our assumption of their functional importance. The tool has been shown to outperform the SpliceView, GeneSplicer, NNSplice, Genio and NetUTR tools for the test set of human genes. SpliceScan outperforms all contemporary ab initio gene structural prediction tools on the set of 5' UTR gene fragments. Conclusion: Designed methods have many attractive properties, compared to existing approaches. Bayesian sensor, MHMMotif program and SpliceScan tools are freely available on our web site.	Univ Nebraska, Coll Informat Sci & Technol, Dept Comp Sci, Omaha, NE 68182 USA; Natl Lib Med, Natl Ctr Biotechnol Informat, NIH, Bethesda, MD 20894 USA; Univ Nebraska, Dept Comp Sci & Engn, Lincoln, NE 68588 USA	Churbanov, A (reprint author), Univ Nebraska, Coll Informat Sci & Technol, Dept Comp Sci, Omaha, NE 68182 USA.	achurbanov@mail.unomaha.edu; rogozin@ncbi.nlm.nih.gov; deogun@cse.unl.edu; hesham@unomaha.edu					ARITA M, 2002, BIOINFORMATICS, V1, P1; Bailey T. L., 1994, P 2 INT C INT SYST M, P28; Beaudoing E, 2000, GENOME RES, V10, P1001, DOI 10.1101/gr.10.7.1001; Bejerano G, 2004, SCIENCE, V304, P1321, DOI 10.1126/science.1098119; Bilmes J. A., 1998, TR97021 INT COMP SCI; BRUNAK S, 1990, NUCLEIC ACIDS RES, V18, P4797, DOI 10.1093/nar/18.16.4797; BRUNAK S, 1991, J MOL BIOL, V220, P49, DOI 10.1016/0022-2836(91)90380-O; BURD CG, 1994, EMBO J, V13, P1197; Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951; Caceres JF, 2002, TRENDS GENET, V18, P186, DOI 10.1016/S0168-9525(01)02626-9; Cai DY, 2000, BIOINFORMATICS, V16, P152, DOI 10.1093/bioinformatics/16.2.152; Cartegni L, 2002, NAT REV GENET, V3, P285, DOI 10.1038/nrg775; CARTEGNI L, 2002, GENETICS NATURE REV, V3, P285; Chen TM, 2005, BIOINFORMATICS, V21, P471, DOI 10.1093/bioinformatics/bti025; Churbanov A, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-261; Crooks GE, 2004, GENOME RES, V14, P1188, DOI 10.1101/gr.849004; Dash D., 2001, MODELING DNA SPLICE; Dreyfuss G, 2002, NAT REV MOL CELL BIO, V3, P195, DOI 10.1038/nrm760; Durbin R, 1998, BIOL SEQUENCE ANAL; EDEN E, 2004, NUCLEIC ACIDS RES, V32, P1132; FAIRBROTHER WG, 2004, PLOS BIOL, V2, P1; Fairbrother WG, 2002, SCIENCE, V297, P1007, DOI 10.1126/science.1073774; FELSENSTEIN J, 2004, INFERRING PHYLOGENET, V16, P248; GELFAND MS, 1989, NUCLEIC ACIDS RES, V17, P6369, DOI 10.1093/nar/17.15.6369; Graveley BR, 2000, RNA, V6, P1197, DOI 10.1017/S1355838200000960; Graveley BR, 2001, RNA, V7, P806, DOI 10.1017/S1355838201010317; Graveley BR, 1998, EMBO J, V17, P6747, DOI 10.1093/emboj/17.22.6747; GUIGO R, 1992, J MOL BIOL, V226, P141, DOI 10.1016/0022-2836(92)90130-C; Guigo R, 1998, J COMPUT BIOL, V5, P681, DOI 10.1089/cmb.1998.5.681; Hastings ML, 2001, CURR OPIN CELL BIOL, V13, P302, DOI 10.1016/S0955-0674(00)00212-X; Hebsgaard SM, 1996, NUCLEIC ACIDS RES, V24, P3439, DOI 10.1093/nar/24.17.3439; IIDA Y, 1983, J BIOCHEM-TOKYO, V94, P1731; JUANG BH, 1985, AT&T TECH J, V64, P391; KEL AE, 1993, COMPUT APPL BIOSCI, V9, P617; Kleffe J, 1996, NUCLEIC ACIDS RES, V24, P4709, DOI 10.1093/nar/24.23.4709; KOZAK M, 1987, NUCLEIC ACIDS RES, V15, P8125, DOI 10.1093/nar/15.20.8125; Kozak M, 2002, GENE, V299, P1, DOI 10.1016/S0378-1119(02)01056-9; Krogh Anders, 1998, P261, DOI 10.1016/B978-012102051-4/50012-X; KROGH A, 1993, UCSCCRL9332; Krogh A., 1997, P 5 INT C INT SYST M, P179; KUDO M, 1992, COMPUT APPL BIOSCI, V8, P367; KUDO M, 1987, COMPUT APPL BIOSCI, V3, P319; KULP D, 1996, P 4 INT C INT SYST M, P134; Lam BJ, 2002, RNA, V8, P1233, DOI 10.1017/S1355838202028030; Lim LP, 2001, P NATL ACAD SCI USA, V98, P11193, DOI 10.1073/pnas.201407298; Liu HX, 2000, MOL CELL BIOL, V20, P1063, DOI 10.1128/MCB.20.3.1063-1071.2000; Liu HX, 1998, GENE DEV, V12, P1998, DOI 10.1101/gad.12.13.1998; Liu X, 2001, Pac Symp Biocomput, P127; MACHE N, 1998, RECOMB; Mayeda A, 1999, MOL CELL BIOL, V19, P1853; MENGERITSKY G, 1989, COMPUT APPL BIOSCI, V5, P97; NAKATA K, 1985, NUCLEIC ACIDS RES, V13, P5327, DOI 10.1093/nar/13.14.5327; PENOTTI FE, 1991, J THEOR BIOL, V150, P385, DOI 10.1016/S0022-5193(05)80436-9; Pertea M, 2001, NUCLEIC ACIDS RES, V29, P1185, DOI 10.1093/nar/29.5.1185; QUINQUETON J, 1985, BIOCHIMIE, V67, P541, DOI 10.1016/S0300-9084(85)80274-1; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rahimi A., 2000, ERRATUM TUTORIAL HID; Reed R, 2000, CURR OPIN CELL BIOL, V12, P340, DOI 10.1016/S0955-0674(00)00097-1; Reese MG, 1997, J COMPUT BIOL, V4, P311, DOI 10.1089/cmb.1997.4.311; Rogozin IB, 2001, BIOINFORMATICS, V17, P890, DOI 10.1093/bioinformatics/17.10.890; Rogozin IB, 1997, J MOL EVOL, V45, P50, DOI 10.1007/PL00006200; Roth FP, 1998, NAT BIOTECHNOL, V16, P939, DOI 10.1038/nbt1098-939; SHAPIRO MB, 1987, NUCLEIC ACIDS RES, V15, P7155, DOI 10.1093/nar/15.17.7155; Smith CWJ, 2000, TRENDS BIOCHEM SCI, V25, P381, DOI 10.1016/S0968-0004(00)01604-2; Smyth P, 1997, ADV NEUR IN, V9, P648; SOLOVYEV VV, 1995, P 3 INT C INT SYST M, P367; STADEN R, 1984, NUCLEIC ACIDS RES, V12, P505, DOI 10.1093/nar/12.1Part2.505; STEPHENS RM, 1992, J MOL BIOL, V228, P1124, DOI 10.1016/0022-2836(92)90320-J; SUN S, 2004, P CSB 2004, P173; Tchourbanov A, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P353; Thompson W, 2003, NUCLEIC ACIDS RES, V31, P3580, DOI 10.1093/nar/gkg608; Wang ZF, 2004, CELL, V119, P831, DOI 10.1016/j.cell.2004.11.010; WIERSTRA D, 2004, THEIS IDSIA NEW IMP, V5, P36; Xing Eric P, 2004, J Bioinform Comput Biol, V2, P127, DOI 10.1142/S0219720004000508; Yeo G, 2004, J COMPUT BIOL, V11, P377, DOI 10.1089/1066527041410418; ZHANG MQ, 1993, COMPUT APPL BIOSCI, V9, P499; ZHANG MQ, 1997, P NATL ACAD SCI USA, V94, P95; Zhang XHF, 2003, GENOME RES, V13, P2637, DOI 10.1101/gr.1679003; ZHAO X, 2004, P 8 ANN INT C COMP M, P68, DOI 10.1145/974614.974624; Zhu J, 2001, MOL CELL, V8, P1351, DOI 10.1016/S1097-2765(01)00409-9	80	14	17	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1745-6150		BIOL DIRECT	Biol. Direct	APR 3	2006	1								10	10.1186/1745-6150-1-10		23	Biology	Life Sciences & Biomedicine - Other Topics	133SH	WOS:000244033000001	
J	Zhou, ZH; Chen, KJ; Dai, HB				Zhou, Zhi-Hua; Chen, Ke-Jia; Dai, Hong-Bin			Enhancing relevance feedback in image retrieval using unlabeled data	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						algorithm; design; experimentation; relevance feedback; content-based image retrieval machine learning; learning with unlabeled data; semisupervised learning; active learning	INFORMATION-RETRIEVAL; EM ALGORITHM; CLASSIFIERS	Relevance feedback is an effective scheme bridging the gap between high-level semantics and low-level features in content-based image retrieval (CBIR). In contrast to previous methods which rely on labeled images provided by the user, this article attempts to enhance the performance of relevance feedback by exploiting unlabeled images existing in the database. Concretely, this article integrates the merits of semisupervised learning and active learning into the relevance feedback process. In detail, in each round of relevance feedback two simple learners are trained from the labeled data, that is, images from user query and user feedback. Each learner then labels some unlabeled images in the database for the other learner. After retraining with the additional labeled data, the learners reclassify the images in the database and then their classifications are merged. Images judged to be positive with high confidence are returned as the retrieval result, while those judged with low confidence are put into the pool which is used in the next round of relevance feedback. Experiments show that using semisupervised learning and active learning simultaneously in CBIR is beneficial, and the proposed method achieves better performance than some existing methods.	Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhouzh@lamda.nju.edu.cn; chenkj@lamda.nju.edu.cn; daihb@lamda.nju.edu.cn					Abe N., 1998, P 15 INT C MACH LEAR, P1; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Blum A., 2001, P 18 INT C MACH LEAR, P19; BOOKSTEIN A, 1983, J AM SOC INFORM SCI, V34, P331, DOI 10.1002/asi.4630340504; Chen JY, 2000, IEEE T IMAGE PROCESS, V9, P442, DOI 10.1109/83.826781; Ciocca G, 1999, INFORM PROCESS MANAG, V35, P605, DOI 10.1016/S0306-4573(99)00021-7; Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127; Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596; Cozman F. G., 2002, P 15 INT FLOR ART IN, P327; Dasgupta S, 2002, ADV NEUR IN, V14, P375; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dong AL, 2003, PROC CVPR IEEE, P662; Goldman S., 2000, P 17 INT C MACH LEAR, P327; Huijsmans DP, 2005, IEEE T PATTERN ANAL, V27, P245, DOI 10.1109/TPAMI.2005.30; HWA R, 2003, ICML 03 WORKSH CONT; Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Kherfi M. L., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1048458; Lewis D. D., 1994, P 17 ANN INT ACM SIG, P3; Lewis D. D., 1992, THESIS U MASSACHUSET; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; MEHTRE BM, 1995, PATTERN RECOGN LETT, V16, P325, DOI 10.1016/0167-8655(94)00096-L; Miller DJ, 1997, ADV NEUR IN, V9, P571; Muller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5; Muslea I., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Nastar C, 1998, PROC CVPR IEEE, P547, DOI 10.1109/CVPR.1998.698659; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354805; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Picard R. W., 1996, Proceedings. International Conference on Image Processing (Cat. No.96CH35919), DOI 10.1109/ICIP.1996.561018; Pierce D, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644; Sarkar A., 2001, P 2 ANN M N AM CHAPT, P95; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Steedman M., 2003, P 11 C EUR CHAPT ASS, P331; TIAN Q, 2004, P IEEE INT C MULT EX, P1019; TIEU K, 2000, P IEEE C COMP VIS PA, V1, P228, DOI 10.1109/CVPR.2000.855824; Tong S., 2001, P ACM INT C MULT, P107, DOI DOI 10.1145/560141.500159; Vasconcelos N, 2000, ADV NEUR IN, V12, P977; WANG HF, 2002, J COMPUTER RES DEV, V39, P513; WU Y, 2000, P IEEE C COMP VIS PA, V1, P222, DOI 10.1109/CVPR.2000.855823; YAO J, 2005, P 10 IEEE INT C COMP, P1012; Zhang C, 2002, IEEE T MULTIMEDIA, V4, P260; ZHANG R, 2004, P 8 EUR C COMP VIS P, P355; Zhou XS, 2001, PROC CVPR IEEE, P11; Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3; Zhou Z., 2005, P 19 INT JOINT C ART, P908; Zhou Z.H., 2004, P 15 EUR C MACH LEAR, P525, DOI DOI 10.1007/B100702; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529	50	37	54	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	1046-8188		ACM T INFORM SYST	ACM Trans. Inf. Syst.	APR	2006	24	2					219	244		10.1145/1148020.1148023		26	Computer Science, Information Systems	Computer Science	077GO	WOS:000240017200003	
J	de Lin, S; Knight, K				de Lin, S; Knight, K			Discovering the linear writing order of a two-dimensional ancient hieroglyphic script	ARTIFICIAL INTELLIGENCE			English	Article						ancient script; decipher; Luwian; hieroglyphic; unsupervised learning; estimation-maximization; linear order; discovery; writing system; natural language process		This paper demonstrates how machine learning methods can be applied to deal with a real-world decipherment problem where very little background knowledge is available. The goal is to discover the linear order of a two-dimensional ancient script, Hieroglyphic Luwian. This paper records a complete decipherment process including encoding, modeling, parameter learning, optimization, and evaluation. The experiment shows that the proposed approach is general enough to recover the linear order of various manually generated two-dimensional scripts without needing to know in advance what language they represent and how the two-dimensional scripts were generated. Since the proposed method does not require domain specific knowledge, it can be applied not only to language problems but also order discovery tasks in other domains such as biology and chemistry. (c) 2005 Elsevier B.V. All rights reserved.	Univ So Calif, Inst Informat Sci, Los Angeles, CA 90089 USA	de Lin, S (reprint author), Univ So Calif, Inst Informat Sci, Los Angeles, CA 90089 USA.	sdlin@isi.edu; knight@isi.edu					Baum L. E., 1972, INEQUALITIES, V3, P1; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; HAWKIN JD, 2003, LUWIANS; HAWKINS JD, 1999, CORPUS HIEROGLYPHIC, V1; SHANNON CE, 1948, AT&T TECH J, V27, P379; SPROUT R, 2000, COMPUTATIONAL THEORY; Yamada Kenji, 1999, P ACL WORKSH UNS LEA	7	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	APR	2006	170	4-5					409	421		10.1016/j.artint.2005.12.001		13	Computer Science, Artificial Intelligence	Computer Science	025ZS	WOS:000236307100003	
J	Hlavica, P				Hlavica, P			Functional interaction of nitrogenous organic bases with cytochrome P450: A critical assessment and update of substrate features and predicted key active-site elements steering the access, binding, and orientation of amines	BIOCHIMICA ET BIOPHYSICA ACTA-PROTEINS AND PROTEOMICS			English	Review						cytochrome P450; basic amine; docking site	RABBIT LIVER-MICROSOMES; NONSTEROIDAL AROMATASE INHIBITORS; CYP2C5 CRYSTALLOGRAPHIC TEMPLATE; P450-MEDIATED DRUG-METABOLISM; TOBACCO-SPECIFIC CARCINOGEN; CYP102 CRYSTAL-STRUCTURE; N-OXIDE FORMATION; DIRECTED MUTAGENESIS; CHEMICAL MODIFICATION; ACID-RESIDUES	The widespread use of nitrogenous organic bases as environmental chemicals, food additives, and clinically important drugs necessitates precise knowledge about the molecular principles governing biotransformation of this category of substrates. In this regard, analysis of the topological background of complex formation between amines and P450s, acting as major catalysts in G and N-oxidative attack, is of paramount importance. Thus, progress in collaborative investigations, combining physico-chemical techniques with chemical-modification as well as genetic engineering experiments, enables substantiation of hypothetical work resulting from the design of pharmacophores or homology modelling of P450s. Based on a general, CYP2D6-related construct, the majority of prospective amine-docking residues was found to cluster near the distal heme face in the six known SRSs, made up by the highly variant helices B', F and G as well as the N-terminal portion of helix C and certain beta-structures. Most of the contact sites examined show a frequency of conservation < 20%, hinting at the requirement of some degree of conformational versatility, while a limited number of amino acids exhibiting a higher level of conservation reside close to the heme core. Some key determinants may have a dual role in amine binding and/or maintenance of protein integrity. Importantly, a series of non-SRS elements are likely to be operative via long-range effects. While hydrophobic mechanisms appear to dominate orientation of the nitrogenous compounds toward the iron-oxene species, polar residues seem to foster binding events through H-bonding or salt-bridge formation. Careful uncovering of structure-function relationships in amine-enzyme association together with recently developed unsupervised machine learning approaches will be helpful in both tailoring of novel amine-type drugs and early elimination of potentially toxic or mutagenic candidates. Also, chimeragenesis might serve in the construction of more efficient P450s for activation of amine drugs and/or bioremediation. (c) 2006 Elsevier B.V. All rights reserved.	Wahlther Straub Inst Pharmakol & Toxikol, D-80336 Munich, Germany	Hlavica, P (reprint author), Wahlther Straub Inst Pharmakol & Toxikol, Goethestr 33, D-80336 Munich, Germany.	hlavica@lrz.uni-muenchen.de					Antonovic L, 1999, ARCH BIOCHEM BIOPHYS, V370, P208, DOI 10.1006/abbi.1999.1408; Auvray P, 1998, EUR J MED CHEM, V33, P451, DOI 10.1016/S0223-5234(98)80046-9; BACKES WL, 1986, BIOCHEM PHARMACOL, V35, P4443, DOI 10.1016/0006-2952(86)90761-6; BAHR C, 1971, XENOBIOTICA, V1, P69; BAHR CV, 1972, XENOBIOTICA, V2, P293; BAST A, 1982, BIOCHEM PHARMACOL, V31, P2745, DOI 10.1016/0006-2952(82)90128-9; Baudry J, 2003, PROTEIN ENG, V16, P577, DOI 10.1093/protein/gzg075; BENSOUSSAN C, 1995, BIOCHEM PHARMACOL, V49, P591, DOI 10.1016/0006-2952(94)00477-4; BERNHARDT R, 1984, BIOCHIM BIOPHYS ACTA, V785, P186, DOI 10.1016/0167-4838(84)90143-2; Bhat KL, 2005, QSAR COMB SCI, V24, P831, DOI 10.1002/qsar.200430921; BICKEL MH, 1969, PHARMACOL REV, V21, P325; Bogni A, 2005, TOXICOL IN VITRO, V19, P621, DOI 10.1016/j.tiv.2005.04.001; Bumpus NN, 2005, DRUG METAB DISPOS, V33, P795, DOI 10.1124/dmd.104.003749; BURSTYN JN, 1991, CHEM RES TOXICOL, V4, P70, DOI 10.1021/tx00019a009; Cavalli A, 2000, BIOORGAN MED CHEM, V8, P2771, DOI 10.1016/S0968-0896(00)00203-0; Chang YT, 1997, PROTEIN ENG, V10, P119, DOI 10.1093/protein/10.2.119; Chen S, 1997, J STEROID BIOCHEM, V61, P107; Conley A, 2002, MOL ENDOCRINOL, V16, P1456, DOI 10.1210/me.16.7.1456; Cupp-Vickery J, 2000, P NATL ACAD SCI USA, V97, P3050, DOI 10.1073/pnas.050406897; Cupp-Vickery JR, 2001, J MOL BIOL, V311, P101, DOI 10.1006/jmbi.2001.4803; Davies C, 2004, DRUG METAB DISPOS, V32, P431, DOI 10.1124/dmd.32.4.431; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; de Groot MJ, 1999, J MED CHEM, V42, P1515, DOI 10.1021/jm981118h; de Groot MJ, 1999, J MED CHEM, V42, P4062, DOI 10.1021/jm991058v; DeGroot MJ, 1997, XENOBIOTICA, V27, P357; de Groot MJ, 2004, CURR TOP MED CHEM, V4, P1803, DOI 10.2174/1568026043387061; deGroot MJ, 1996, CHEM RES TOXICOL, V9, P1079, DOI 10.1021/tx960003i; deGroot MJ, 1997, CHEM RES TOXICOL, V10, P41, DOI 10.1021/tx960129f; DICKINS M, 1979, BIOCHEM PHARMACOL, V28, P231, DOI 10.1016/0006-2952(79)90509-4; Dierks EA, 1998, BIOCHEMISTRY-US, V37, P1839, DOI 10.1021/bi972458s; Dierks EA, 1998, J BIOL CHEM, V273, P23055, DOI 10.1074/jbc.273.36.23055; Domanski TL, 2001, CURR DRUG METAB, V2, P117, DOI 10.2174/1389200013338612; Dowers TS, 2004, DRUG METAB DISPOS, V32, P328, DOI 10.1124/dmd.32.3.328; EICHELBAUM M, 1990, PHARMACOL THERAPEUT, V46, P377, DOI 10.1016/0163-7258(90)90025-W; Eiselt R, 2001, PHARMACOGENETICS, V11, P447, DOI 10.1097/00008571-200107000-00008; Ekins S, 2001, DRUG METAB DISPOS, V29, P936; Ekins S, 1999, PHARMACOGENETICS, V9, P477; ELGHOMARI K, 1987, EUR J DRUG METAB PH, V12, P253; Ellis SW, 1996, BIOCHEM J, V316, P647; ELLIS SW, 1995, J BIOL CHEM, V270, P29055; Flanagan JU, 2004, BIOCHEM J, V380, P353, DOI 10.1042/BJ20040062; Flanagan JU, 2003, BIOCHEM J, V370, P921, DOI 10.1042/BJ20021841; Fowler SM, 2000, BIOCHEMISTRY-US, V39, P4406, DOI 10.1021/bi992372u; FRENCH JS, 1980, J BIOL CHEM, V255, P4112; FunckBrentano C, 1997, J PHARMACOL EXP THER, V280, P730; FURET P, 1993, J MED CHEM, V36, P1393, DOI 10.1021/jm00062a012; FURUYA H, 1989, BIOCHEM BIOPH RES CO, V160, P669, DOI 10.1016/0006-291X(89)92485-6; FURUYA H, 1989, BIOCHEMISTRY-US, V28, P6848, DOI 10.1021/bi00443a011; GIBSON GG, 1986, CHEM-BIOL INTERACT, V58, P185, DOI 10.1016/S0009-2797(86)80097-7; Girvan HM, 2004, J BIOL CHEM, V279, P23274, DOI 10.1074/jbc.M401716200; GOLLY I, 1992, ARCH BIOCHEM BIOPHYS, V292, P287, DOI 10.1016/0003-9861(92)90081-7; GORROD J W, 1971, Xenobiotica, V1, P521; GORROD JW, 1991, N OXIDATION DRUGS BI, P157; GORROD JW, 1973, CHEM-BIOL INTERACT, V7, P289, DOI 10.1016/0009-2797(73)90004-5; GORROD JW, 1973, CHEM-BIOL INTERACT, V6, P203, DOI 10.1016/0009-2797(73)90072-0; GOTOH O, 1992, J BIOL CHEM, V267, P83; GRACE JM, 1994, CHEM RES TOXICOL, V7, P286, DOI 10.1021/tx00039a003; Graham SE, 1999, ARCH BIOCHEM BIOPHYS, V369, P24, DOI 10.1006/abbi.1999.1350; Graham SE, 2002, METHOD ENZYMOL, V357, P15; Guengerich FP, 2005, CYTOCHROME P450 STRU, P377, DOI 10.1007/0-387-27447-2_10; Guengerich FP, 1997, MOL PHARMACOL, V51, P147; GUENGERICH FP, 1986, MOL PHARMACOL, V30, P287; Guengerich FP, 2002, BIOCHEMISTRY-US, V41, P11025, DOI 10.1021/bi020341k; Guengerich FP, 2003, BIOCHEMISTRY-US, V42, P1245, DOI 10.1021/bi027085w; Guengerich FP, 2001, CURR DRUG METAB, V2, P93, DOI 10.2174/1389200013338694; HACHINO Y, 1981, CHEM-BIOL INTERACT, V37, P181, DOI 10.1016/0009-2797(81)90175-7; HALPERT J, 1981, BIOCHEM PHARMACOL, V30, P875, DOI 10.1016/S0006-2952(81)80010-X; HALPERT JR, 1985, J BIOL CHEM, V260, P8397; HAMMONS GJ, 1985, CANCER RES, V45, P3578; Hanna IH, 1998, BIOCHEMISTRY-US, V37, P311, DOI 10.1021/bi971528s; Hanna IH, 1998, ARCH BIOCHEM BIOPHYS, V350, P324, DOI 10.1006/abbi.1997.0534; Hanna IH, 2001, ARCH BIOCHEM BIOPHYS, V393, P255, DOI 10.1006/abbi.2001.2510; Harris D, 1996, J COMPUT CHEM, V17, P273, DOI 10.1002/(SICI)1096-987X(199602)17:3<273::AID-JCC2>3.0.CO;2-S; Harris DL, 2004, PROTEINS, V55, P895, DOI 10.1002/prot.20062; HASEMANN CA, 1995, STRUCTURE, V3, P41, DOI 10.1016/S0969-2126(01)00134-4; Hayhurst GP, 2001, BIOCHEM J, V355, P373, DOI 10.1042/0264-6021:3550373; Hays AMA, 2004, J MOL BIOL, V344, P455, DOI 10.1016/j.jmb.2004.09.046; He XY, 2004, DRUG METAB DISPOS, V32, P1516, DOI 10.1124/dmd.104.001370; He YA, 2003, ARCH BIOCHEM BIOPHYS, V409, P92, DOI 10.1016/S0003-9861(02)00484-8; HE YQ, 1995, CHEM RES TOXICOL, V8, P574, DOI 10.1021/tx00046a011; He YQ, 1996, ARCH BIOCHEM BIOPHYS, V335, P152, DOI 10.1006/abbi.1996.0493; HEIDEN W, 1993, J COMPUT AID MOL DES, V7, P503, DOI 10.1007/BF00124359; Hlavica P, 2004, EUR J BIOCHEM, V271, P4335, DOI 10.1111/j.1432-1033.2004.04380.x; HLAVICA P, 1983, BIOCHEM J, V212, P539; HLAVICA P, 1978, BIOCHIM BIOPHYS ACTA, V544, P185, DOI 10.1016/0304-4165(78)90222-2; HLAVICA P, 1994, DRUG METAB REV, V26, P325, DOI 10.3109/03602539409029801; HLAVICA P, 1979, BIOCHEM J, V182, P109; HLAVICA P, 1982, BIOCHEM J, V204, P425; Hlavica P, 1995, J Biochem Toxicol, V10, P275, DOI 10.1002/jbt.2570100508; HLAVICA P, 1997, CHEM DOUBLE BONDE SA, V3, P1625; HLAVICA P, 1982, CRC CR REV BIOCH MOL, V12, P39, DOI 10.3109/10409238209105850; Hlavica P, 2001, EUR J BIOCHEM, V268, P4817, DOI 10.1046/j.1432-1327.2001.02412.x; HLAVICA P, 1970, BIOCHEM BIOPH RES CO, V40, P212, DOI 10.1016/0006-291X(70)91068-5; HLAVICA P, 1993, BIOCHIM BIOPHYS ACTA, V1158, P83, DOI 10.1016/0304-4165(93)90100-M; HLAVICA P, 1976, XENOBIOTICA, V6, P679; Hlavica P, 1997, HUM EXP TOXICOL, V16, P441; Hlavica P, 2002, DRUG METAB REV, V34, P451, DOI 10.1081/DMR-120005646; HLAVICA P, 1984, ARCH BIOCHEM BIOPHYS, V228, P600, DOI 10.1016/0003-9861(84)90028-6; HOFFSTRO.I, 1973, FEBS LETT, V31, P205, DOI 10.1016/0014-5793(73)80104-8; Holm L, 1996, NUCLEIC ACIDS RES, V24, P206, DOI 10.1093/nar/24.1.206; Honma W, 2005, ARCH BIOCHEM BIOPHYS, V435, P157, DOI 10.1016/j.abb.2004.12.014; Howard P. H., 1997, HDB PHYS PROPERTIES; Hutzler JM, 2003, ARCH BIOCHEM BIOPHYS, V417, P165, DOI 10.1016/S0003-9861(03)00350-3; Hutzler JM, 2003, CHEM RES TOXICOL, V16, P450, DOI 10.1021/tx025674x; Ibeanu GC, 1996, J BIOL CHEM, V271, P12496; Ingelman-Sundberg M, 2005, PHARMACOGENOMICS J, V5, P6, DOI 10.1038/sj.tpj.6500285; ISLAM SA, 1991, CARCINOGENESIS, V12, P2211, DOI 10.1093/carcin/12.12.2211; IWASAKI M, 1991, J BIOL CHEM, V266, P3380; Jalas JR, 2004, XENOBIOTICA, V34, P515, DOI 10.1080/00498250410001713131; JANIG GR, 1985, CHYTOCHROME P 450 BI, P53; JANIG GR, 1984, BIOCHIM BIOPHYS ACTA, V787, P8, DOI 10.1016/0167-4838(84)90102-X; JANIG GR, 1985, BIOMED BIOCHIM ACTA, V44, P1071; Jean P, 1997, PROTEINS, V28, P388, DOI 10.1002/(SICI)1097-0134(199707)28:3<388::AID-PROT9>3.0.CO;2-8; JEFCOATE CR, 1969, BIOCHEMISTRY-US, V8, P3455, DOI 10.1021/bi00836a049; JONEN HG, 1974, BIOCHEM PHARMACOL, V23, P1319, DOI 10.1016/0006-2952(74)90334-7; Jones BC, 1998, DRUG METAB DISPOS, V26, P875; JONES JP, 1993, J AM CHEM SOC, V115, P381, DOI 10.1021/ja00055a002; Josephy PD, 2000, ENVIRON MOL MUTAGEN, V35, P328, DOI 10.1002/1098-2280(2000)35:4<328::AID-EM7>3.0.CO;2-C; Kalgutkar AS, 2003, DRUG METAB DISPOS, V31, P596, DOI 10.1124/dmd.31.5.596; Keizers PHJ, 2004, BIOCHEM PHARMACOL, V68, P2263, DOI 10.1016/j.bcp.2004.08.013; Khan KK, 2002, CHEM RES TOXICOL, V15, P843, DOI 10.1021/tx025539k; Khan KK, 2002, MOL PHARMACOL, V61, P495, DOI 10.1124/mol.61.3.495; Kiese M., 1974, METHEMOGLOBINEMIA CO; Kim D, 2005, J BIOL CHEM, V280, P40319, DOI 10.1074/jbc.M508171200; KIM D, 2004, ANN REV PHARM TOXICO, V45, P27; Kirton SB, 2002, PROTEINS, V49, P216, DOI 10.1002/prot.10192; Korhonen LE, 2005, J MED CHEM, V48, P3808, DOI 10.1021/jm0489713; Korolev D, 2003, J MED CHEM, V46, P3631, DOI 10.1021/jm030102a; KOYMANS L, 1992, CHEM RES TOXICOL, V5, P211, DOI 10.1021/tx00026a010; KOYMANS LMH, 1995, J STEROID BIOCHEM, V53, P191, DOI 10.1016/0960-0760(95)00033-V; KRAINEV AG, 1993, BIOCHEMISTRY-US, V32, P1951, DOI 10.1021/bi00059a011; KRAINEV AG, 1991, ARCH BIOCHEM BIOPHYS, V288, P17, DOI 10.1016/0003-9861(91)90159-G; Kriegl JM, 2005, QSAR COMB SCI, V24, P491, DOI 10.1002/qsar.200430925; LAWRENCE SA, 2004, AMINES SYNTHESIS PRO, P265; Lawson RJ, 2004, BIOCHEMISTRY-US, V43, P12410, DOI 10.1021/bi0491321; Lewis DFV, 1996, XENOBIOTICA, V26, P723; Lewis DFV, 2001, CYTOCHROMES P450 STR, P76; LEWIS DFV, 1987, CHEM-BIOL INTERACT, V64, P39, DOI 10.1016/0009-2797(87)90059-7; Lewis DFV, 1998, XENOBIOTICA, V28, P617, DOI 10.1080/004982598239236; Lewis DFV, 1996, XENOBIOTICA, V26, P1067; Lewis DFV, 1997, XENOBIOTICA, V27, P443; Lewis DFV, 2003, TOXICOL IN VITRO, V17, P179, DOI 10.1016/S0887-2333(02)00132-7; Lewis DFV, 2003, CURR MED CHEM, V10, P1955, DOI 10.2174/0929867033456855; Lewis DFV, 1998, XENOBIOTICA, V28, P235; Lewis DFV, 2002, DRUG METAB REV, V34, P69, DOI 10.1081/DMR-120001391; Lewis DFV, 2003, ARCH BIOCHEM BIOPHYS, V409, P32, DOI 10.1016/S0003-9861(02)00349-1; Lewis DFV, 2004, XENOBIOTICA, V34, P549, DOI 10.1080/00498250410001691325; Lewis DFV, 2004, TOXICOL IN VITRO, V18, P89, DOI 10.1016/S0887-2333(03)00134-6; Lewis DFV, 1999, XENOBIOTICA, V29, P361; Lewis DFV, 2003, CURR DRUG METAB, V4, P331, DOI 10.2174/1389200033489343; LEWIS DFV, 1994, DRUG METAB REV, V26, P261, DOI 10.3109/03602539409029797; Lewis DFV, 1998, J STEROID BIOCHEM, V66, P217, DOI 10.1016/S0960-0760(98)00032-6; LEWIS DFV, 1989, CHEM-BIOL INTERACT, V70, P263, DOI 10.1016/0009-2797(89)90049-5; Lewis DFV, 2003, TOXICOL IN VITRO, V17, P93, DOI 10.1016/S0887-2333(02)00098-X; Lewis DFV, 2000, BIOCHEM PHARMACOL, V60, P293, DOI 10.1016/S0006-2952(00)00335-X; Lewis DFV, 1997, XENOBIOTICA, V27, P319; Leys D, 2003, J BIOL CHEM, V278, P5141, DOI 10.1074/jbc.M209928200; Li XC, 2004, P NATL ACAD SCI USA, V101, P2939, DOI 10.1073/pnas.0308691101; Liu JG, 2003, DRUG METAB DISPOS, V31, P412, DOI 10.1124/dmd.31.4.412; Liu JG, 2004, ARCH BIOCHEM BIOPHYS, V424, P33, DOI 10.1016/j.abb.2003.12.040; Liu JP, 1996, ARCH BIOCHEM BIOPHYS, V327, P167, DOI 10.1006/abbi.1996.0105; Lu P, 2005, J PHARMACOL EXP THER, V313, P518, DOI 10.1124/jpet.104.077651; MACDONALD TL, 1989, BIOCHEMISTRY-US, V28, P2071, DOI 10.1021/bi00431a016; MAILMAN RB, 1974, DRUG METAB DISPOS, V2, P301; Marichal P, 1999, MICROBIOL-SGM, V145, P2701; MATSUNAGA E, 1990, J BIOL CHEM, V265, P17197; Mestres J, 2005, PROTEINS, V58, P596, DOI 10.1002/prot.20354; MEYER UA, 1986, XENOBIOTICA, V16, P449; Miles CS, 2000, BBA-PROTEIN STRUCT M, V1543, P383, DOI 10.1016/S0167-4838(00)00236-3; Miller GP, 2001, BIOCHEMISTRY-US, V40, P14215, DOI 10.1021/bi0110037; Modi S, 1997, BIOCHEMISTRY-US, V36, P4461, DOI 10.1021/bi962633p; Modi S, 1996, BIOCHEMISTRY-US, V35, P4540, DOI 10.1021/bi952742o; MOLONEY SJ, 1984, XENOBIOTICA, V14, P803; Nelson David R., 1995, P575; Nelson DR, 1996, PHARMACOGENETICS, V6, P1, DOI 10.1097/00008571-199602000-00002; Nitahara Y, 2001, J BIOCHEM-TOKYO, V129, P761; Noble MA, 1999, BIOCHEM J, V339, P371, DOI 10.1042/0264-6021:3390371; Onderwater RCA, 1999, CHEM RES TOXICOL, V12, P555, DOI 10.1021/tx980248q; Oscarson M, 1997, MOL PHARMACOL, V52, P1034; Otey CR, 2004, CHEM BIOL, V11, P309, DOI 10.1016/j.chembiol.2004.02.018; Paine MJI, 2003, J BIOL CHEM, V278, P4021, DOI 10.1074/jbc.M209519200; Parikh A, 1999, BIOCHEMISTRY-US, V38, P5283, DOI 10.1021/bi990142+; Park SY, 2002, J INORG BIOCHEM, V91, P491, DOI 10.1016/S0162-0134(02)00446-4; PAULSEN MD, 1991, PROTEINS, V11, P184, DOI 10.1002/prot.340110304; PAULSEN MD, 1995, PROTEINS, V21, P237, DOI 10.1002/prot.340210306; Pedras M S, 1998, Bioorg Med Chem Lett, V8, P3037; PETZOLD DR, 1985, BIOCHIM BIOPHYS ACTA, V829, P253, DOI 10.1016/0167-4838(85)90195-5; PIRRWITZ J, 1977, FEBS LETT, V83, P15, DOI 10.1016/0014-5793(77)80631-5; Podust LM, 2004, PROTEIN SCI, V13, P255, DOI 10.1110/ps.03384804; Podust LM, 2001, J INORG BIOCHEM, V87, P227, DOI 10.1016/S0162-0134(01)00388-9; Podust LM, 2001, P NATL ACAD SCI USA, V98, P3068, DOI 10.1073/pnas.061562898; POULOS TL, 1987, BIOCHEMISTRY-US, V26, P8165, DOI 10.1021/bi00399a022; POULOS TL, 1986, BIOCHEMISTRY-US, V25, P5314, DOI 10.1021/bi00366a049; Rahnasto M, 2005, J MED CHEM, V48, P440, DOI 10.1021/jm049536b; Recanatini M, 1998, BIOORGAN MED CHEM, V6, P377, DOI 10.1016/S0968-0896(97)10053-0; Recanatini M, 2002, MED RES REV, V22, P282, DOI 10.1002/med.10010; REMMER H, 1966, MOL PHARMACOL, V2, P187; Riley RJ, 2001, PHARMACEUT RES, V18, P652, DOI 10.1023/A:1011085411050; RISTAU O, 1978, BIOCHIM BIOPHYS ACTA, V536, P226, DOI 10.1016/0005-2795(78)90068-5; ROWLAND P, 2006, J BIOL CHEM, V281; Rupp B, 2005, J COMPUT AID MOL DES, V19, P149, DOI 10.1007/s10822-005-3692-7; SCHENKMAN JB, 1981, PHARMACOL THERAPEUT, V12, P43, DOI 10.1016/0163-7258(81)90075-9; SCHENKMA.JB, 1970, BIOCHEMISTRY-US, V9, P2081, DOI 10.1021/bi00812a009; Schoch GA, 2003, EUR J BIOCHEM, V270, P3684, DOI 10.1046/j.1432-1033.2003.03739.x; SCHWARZE W, 1988, BIOCHEM BIOPH RES CO, V150, P996, DOI 10.1016/0006-291X(88)90727-9; Scott EE, 2004, ARCH BIOCHEM BIOPHYS, V423, P266, DOI 10.1016/j.abb.2003.12.035; Scott EE, 2004, J BIOL CHEM, V279, P27294, DOI 10.1074/jbc.M403349200; SETO Y, 1993, J BIOL CHEM, V268, P9986; SHIMIZU T, 1991, BIOCHEMISTRY-US, V30, P1490, DOI 10.1021/bi00220a007; Sieber V, 2001, NAT BIOTECHNOL, V19, P456, DOI 10.1038/88129; Sielaff B, 2005, FEBS J, V272, P1148, DOI 10.1111/j.1742-4658.2005.04550.x; Snyder R, 2002, QUANT STRUCT-ACT REL, V21, P357, DOI 10.1002/1521-3838(200210)21:4<357::AID-QSAR357>3.0.CO;2-D; Spatzenegger M, 2001, MOL PHARMACOL, V59, P475; Strickler M, 2003, BIOCHEMISTRY-US, V42, P11943, DOI 10.1021/bi034833o; STROBL GR, 1993, J MED CHEM, V36, P1136, DOI 10.1021/jm00061a004; Szklarz GD, 1998, DRUG METAB DISPOS, V26, P1179; Szklarz GD, 1997, J COMPUT AID MOL DES, V11, P265, DOI 10.1023/A:1007956612081; Szklarz GD, 1996, ARCH BIOCHEM BIOPHYS, V327, P308, DOI 10.1006/abbi.1996.0127; TAMBURINI PP, 1983, J BIOL CHEM, V258, P3444; Tehan BG, 2002, QUANT STRUCT-ACT REL, V21, P473, DOI 10.1002/1521-3838(200211)21:5<473::AID-QSAR473>3.0.CO;2-D; TEMPLE D J, 1971, Xenobiotica, V1, P507; Tsao CC, 2001, BIOCHEMISTRY-US, V40, P1937, DOI 10.1021/bi001678u; TSOKOS DC, 1991, BIOCHEMISTRY-US, V31, P7155; TUCK SF, 1992, BIOCHEMISTRY-US, V31, P6911, DOI 10.1021/bi00145a007; TYRAKOWSKA B, 1993, DRUG METAB DISPOS, V21, P508; UEHLEKE H, 1973, DRUG METAB DISPOS, V1, P299; UETRECHT J, 1991, N OXIDATION DRUGS BI, P435; Ulmschneider S, 2005, J MED CHEM, V48, P1796, DOI 10.1021/jm049600p; Upthagrove AL, 2001, DRUG METAB DISPOS, V29, P1377; VAZ ADN, 1992, DRUG METAB DISPOS, V20, P108; Venhorst J, 2000, DRUG METAB DISPOS, V28, P1524; Venhorst J, 2003, J MED CHEM, V46, P74, DOI 10.1021/jm0209578; Vermeulen NPE, 2003, CURR TOP MED CHEM, V3, P1227, DOI 10.2174/1568026033451998; Verras A, 2004, J MED CHEM, V47, P3572, DOI 10.1021/jm030308t; Wang HJ, 2003, CANCER RES, V63, P8057; Wang QM, 2002, DRUG METAB DISPOS, V30, P86, DOI 10.1124/dmd.30.1.86; Williams PA, 2000, J INORG BIOCHEM, V81, P183, DOI 10.1016/S0162-0134(00)00102-1; WILSON BJ, 1972, BIOCHIM BIOPHYS ACTA, V261, P94, DOI 10.1016/0304-4165(72)90318-2; WOLF CR, 1988, BIOCHEMISTRY-US, V27, P1597, DOI 10.1021/bi00405a031; WOLFF T, 1985, CANCER RES, V45, P2116; Wu ZL, 2005, J BIOL CHEM, V280, P41090, DOI 10.1074/jbc.M508182200; Xiao L, 2004, ANTIMICROB AGENTS CH, V48, P568, DOI 10.1128/AAC.48.2.568-574.2004; Xue LL, 2003, ARCH BIOCHEM BIOPHYS, V409, P113, DOI 10.1016/S0003-9861(02)00582-9; Yamaguchi Y, 2004, DRUG METAB DISPOS, V32, P155, DOI 10.1124/dmd.32.1.155; Yano JK, 2004, J BIOL CHEM, V279, P38091, DOI 10.1074/jbc.C400293200; Yano JK, 2000, J BIOL CHEM, V275, P31086, DOI 10.1074/jbc.M004281200; Yano JK, 2005, NAT STRUCT MOL BIOL, V12, P822, DOI 10.1038/nsmb971; Yoon MY, 2004, DRUG METAB REV, V36, P219, DOI 10.1081/DMR-120033998; YUN CH, 1992, BIOCHEMISTRY-US, V31, P10556, DOI 10.1021/bi00158a019; Zhang XL, 2002, J PHARMACOL EXP THER, V302, P416, DOI 10.1124/jpet.302.2.416; Zhou HJ, 2004, ARCH BIOCHEM BIOPHYS, V422, P23, DOI 10.1016/j.abb.2003.11.019	251	17	17	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1570-9639		BBA-PROTEINS PROTEOM	BBA-Proteins Proteomics	APR	2006	1764	4					645	670		10.1016/j.bbapap.2006.01.013		26	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	047KM	WOS:000237878200002	
J	Shah, PK; Bork, P				Shah, PK; Bork, P			LSAT: learning about alternative transcripts in MEDLINE	BIOINFORMATICS			English	Article							BIOMEDICAL LITERATURE; PROTEIN INTERACTIONS; MOLECULAR-BIOLOGY; MICROARRAYS; EXTRACTION; DIVERSITY	Motivation: Generation of alternative transcripts from the same gene is an important biological event due to their contribution in creating functional diversity in eukaryotes. In this work, we choose the task of extracting information around this complex topic using a two-step procedure involving machine learning and information extraction. Results: In the first step, we trained a classifier that inductively learns to identify sentences about physiological transcript diversity from the MEDLINE abstracts. Using a large hand-built corpus, we compared the sentence classification performance of various text categorization methods. Support vector machines (SVMs) followed by the maximum entropy classifier outperformed other methods for the sentence classification task. The SVM with the radial basis function kernel and optimized parameters achieved F-beta-measure of 91% during the 4-fold cross validation and of 74% when applied to all sentences in more than 12 million abstracts of MEDLINE. In the second step, we identified eight frequently present semantic categories in the sentences and performed a limited amount of semantic role labeling. The role labeling step also achieved very high F-beta-measure for all eight categories.	European Mol Biol Lab, D-69117 Heidelberg, Germany; Max Delbruck Ctr Mol Med, Berlin, Germany	Shah, PK (reprint author), European Mol Biol Lab, Meyerhofstr 1, D-69117 Heidelberg, Germany.	shah@embl.de	Bork, Peer/F-1813-2013	Bork, Peer/0000-0002-2627-833X			Black DL, 2000, CELL, V103, P367, DOI 10.1016/S0092-8674(00)00128-8; Blaschke C, 2001, Genome Inform, V12, P123; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Boue S, 2003, BIOESSAYS, V25, P1031, DOI 10.1002/bies.10371; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Craven M, 1999, Proc Int Conf Intell Syst Mol Biol, P77; Daraselia N, 2004, BIOINFORMATICS, V20, P604, DOI 10.1093/bioinformatics/btg452; Donaldson I, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-11; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; EdwaldsGilbert G, 1997, NUCLEIC ACIDS RES, V25, P2547, DOI 10.1093/nar/25.13.2547; Hirschman L, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S1; Joachims T., 2001, LEARNING CLASSIFY TE; Krallinger M, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-7-224; Lee C, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-7-231; Mika S, 2004, BIOINFORMATICS, V20, P241, DOI 10.1093/bioinformatics/bth904; Mitchell T, 1997, MACHINE LEARNING; Nadon R, 2002, TRENDS GENET, V18, P265, DOI 10.1016/S0168-9525(02)02665-3; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; Novichkova S, 2003, BIOINFORMATICS, V19, P1699, DOI 10.1093/bioinformatics/btg207; PRADHAN S, 2004, P NAACL HLT BOST MA; RAY S, 2001, P 17 INT JOINT C ART, P1273; RIBEIRONETO RB, 1999, MODERN INFORM RETRIE; Schmid H., 1994, P INT C NEW METH LAN, P44; Shah PK, 2005, PLOS COMPUT BIOL, V1, P67, DOI 10.1371/journal.pcbi.0010010; Shatkay H, 2003, J COMPUT BIOL, V10, P821, DOI 10.1089/106652703322756104; TAN CM, 2002, J INFORM PROCESS MAN, V30, P529; Thanaraj TA, 2004, NUCLEIC ACIDS RES, V32, pD64, DOI 10.1093/nar/gkh030; Wattarujeekrit T, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-155; Yakushiji A., 2001, PAC S BIOC, V6, P408; YANG XLY, 1999, P ACM SIGIR C RES DE, P42; Yeh AS, 2003, BIOINFORMATICS, V19, P331; Zavolan M, 2003, GENOME RES, V13, P1290, DOI 10.1101/gr.1017303	32	6	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	APR 1	2006	22	7					857	865		10.1093/bioinformatics/btk044		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	025FU	WOS:000236251500013	
J	Bernaille, L; Teixeira, R; Akodkenou, I; Soule, A; Salamatian, K				Bernaille, L; Teixeira, R; Akodkenou, I; Soule, A; Salamatian, K			Traffic classification on the fly	COMPUTER COMMUNICATION REVIEW			English	Article						measurement; algorithms; management; traffic classification; applications; machine learning		The early detection of applications associated with TCP flows is an essential step for network security and traffic engineering. The classic way to identify flows, i.e. looking at port numbers, is not effective anymore. On the other hand, state-of-the-art techniques cannot determine the application before the end of the TCP flow. In this editorial, we propose a technique that relies on the observation of the first five packets of a TCP connection to identify the application. This result opens a range of new possibilities for online traffic classification.	Univ Paris 06, LIP6, F-75252 Paris 05, France; Thomson Paris Lab, Paris, France	Bernaille, L (reprint author), Univ Paris 06, LIP6, F-75252 Paris 05, France.		Salamatian, Kave/I-4670-2012	Salamatian, Kave/0000-0001-5557-9134			HOHN N, 2003, INT MEAS C; Karagiannis T., 2004, IEEE GLOB; Karagiannis T., 2005, ACM SIGCOMM; McGregor A., 2004, PASS ACT MEAS WORKSH; MCQUEEN J, 1967, S MATH STAT PROB; Moore A., 2005, ACM SIGMETRICS; ROUGHAN M, 2004, INT MEAS C; ZUEV D, 2005, PASS ACT MEAS WORKSH	8	41	45	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0146-4833		COMPUT COMMUN REV	Comput. Commun. Rev.	APR	2006	36	2					23	26				4	Computer Science, Information Systems	Computer Science	042SS	WOS:000237550400004	
J	Giangiacomoa, A; Garway-Heath, D; Caprioli, J				Giangiacomoa, A; Garway-Heath, D; Caprioli, J			Diagnosing glaucoma progression: current practice and promising technologies	CURRENT OPINION IN OPHTHALMOLOGY			English	Article						long-term fluctuation; pointwise linear regression; visual-field progression	NERVE-FIBER LAYER; SCANNING LASER POLARIMETRY; VISUAL-FIELD PROGRESSION; HEIDELBERG RETINA TOMOGRAPH; OCULAR HYPERTENSION TREATMENT; FREQUENCY-DOUBLING TECHNOLOGY; OPTICAL COHERENCE TOMOGRAPHY; DIGITIZED IMAGE-ANALYSIS; TEST-RETEST VARIABILITY; OPEN-ANGLE GLAUCOMA	Purpose of review An update on recent work is provided that has broadened our understanding of the evaluation of visual function and structure, and their use in evaluating glaucoma progression. Recent findings The challenge of determining visual-field progression and the implications of long-term fluctuation are reviewed and data to support the magnitude of the fluctuaion are cited. The use of confirmatory testing can limit the over diagnosis of glaucoma progression. Focusing visual-field testing on the locations of present scotomas or using frequency doubling technology may provide new approaches to assessing visual function. New standardized techniques to interpret visual fields, including neural networks, unsupervised machine learning and pointwise linear regression, may provide more quantitative means for visual-field interpretation. These techniques, along with structural evaluation of the optic nerve and nerve fiber layer, are essential in glaucoma management. Optic-nerve-head photography is still a mainstay in evaluating glaucoma progression, although many technologies including scanning laser tomography, scanning laser polarimetry and optical coherence tomography offer more quantitative means to follow structural change. These modalities, in different ways, show promise in providing additional information regarding the stability of glaucoma. Summary Identifying the functional visual component as well as structural changes is essential in evaluating glaucoma progression. New techniques of testing and evaluating visual fields, the optic-nerve head, and the retinal nerve fiber layer offer exciting opportunities to more accurately identify glaucoma progression, and are likely to become more central as imaging devices and software support develop further.	Univ Calif Los Angeles, David Geffen Sch Med, Dept Ophthalmol, Jules Stein Eye Inst, Los Angeles, CA 90095 USA; Moorfields Eye Hosp, London, England	Caprioli, J (reprint author), Univ Calif Los Angeles, David Geffen Sch Med, Dept Ophthalmol, Jules Stein Eye Inst, 2-118 Jules Stein Eye Inst, Los Angeles, CA 90095 USA.	caprioli@ucla.edu					Kim J, 2004, OPHTHALMOLOGY, V111, P2109, DOI 10.1016/j.ophtha.2004.06.029; AIRAKSINEN PJ, 1992, ARCH OPHTHALMOL-CHIC, V110, P206; Drance S, 2001, AM J OPHTHALMOL, V131, P699, DOI 10.1016/S0002-9394(01)00964-3; Artes PH, 2005, PROG RETIN EYE RES, V24, P333, DOI 10.1016/j.preteyeres.2004.10.002; Barry CJ, 2000, BRIT J OPHTHALMOL, V84, P28, DOI 10.1136/bjo.84.1.28; Bayer AU, 2002, OPHTHALMOLOGY, V109, P1009, DOI 10.1016/S0161-6420(02)01015-1; Berger JW, 2000, OPHTHALMOLOGY, V107, P1316, DOI 10.1016/S0161-6420(00)00157-3; Boden C, 2004, AM J OPHTHALMOL, V138, P1029, DOI 10.1016/j.ajo.2004.07.003; Boehm MD, 2003, ARCH OPHTHALMOL-CHIC, V121, P189; Boes DA, 1996, J GLAUCOMA, V5, P9; Brigatti L, 1997, ARCH OPHTHALMOL-CHIC, V115, P725; Budenz DL, 2005, INVEST OPHTH VIS SCI, V46, P2440, DOI 10.1167/iovs.04-1174; BURGOYNE CF, 1995, AM J OPHTHALMOL, V120, P176; BURGOYNE CF, 1994, ARCH OPHTHALMOL-CHIC, V112, P261; Burgoyne CF, 2002, OPHTHALMOLOGY, V109, P455, DOI 10.1016/S0161-6420(01)01005-3; Caprioli J, 1996, AM J OPHTHALMOL, V121, P659; CAPRIOLI J, 1986, ARCH OPHTHALMOL-CHIC, V104, P1035; Chauhan BC, 2001, ARCH OPHTHALMOL-CHIC, V119, P1492; Chauhan BC, 2000, INVEST OPHTH VIS SCI, V41, P775; Colen TP, 2000, AM J OPHTHALMOL, V130, P847, DOI 10.1016/S0002-9394(00)00627-9; Dan JA, 1996, J GLAUCOMA, V5, P1; Ervin JC, 2002, OPHTHALMOLOGY, V109, P467, DOI 10.1016/S0161-6420(01)01004-1; Garway-Heath DF, 1999, BRIT J OPHTHALMOL, V83, P664, DOI 10.1136/bjo.83.6.664; GOLDMANN H, 1984, GRAEF ARCH CLIN EXP, V222, P82, DOI 10.1007/BF02150637; Haymes SA, 2005, INVEST OPHTH VIS SCI, V46, P547, DOI 10.1167/iovs.04-0973; HEIJL A, 1989, INVEST OPHTH VIS SCI, V30, P2376; JANKNECHT P, 1995, GRAEFES ARCH CLIN EX; Kamal DS, 2000, BRIT J OPHTHALMOL, V84, P993, DOI 10.1136/bjo.84.9.993; Kass MA, 2002, ARCH OPHTHALMOL-CHIC, V120, P701; Keltner JL, 2005, ARCH OPHTHALMOL-CHIC, V123, P1201, DOI 10.1001/archopht.123.9.1201; Leske MC, 1999, OPHTHALMOLOGY, V106, P2144, DOI 10.1016/S0161-6420(99)90497-9; Lleo-Perez A, 2004, EUR J OPHTHALMOL, V14, P523; Medeiros FA, 2004, ARCH OPHTHALMOL-CHIC, V122, P827, DOI 10.1001/archopht.122.6.827; Meier FM, 2002, BRIT J OPHTHALMOL, V86, P285, DOI 10.1136/bjo.86.3.285; Miglior S, 2003, OPHTHALMOLOGY, V110, P340, DOI 10.1016/S0161-6420(02)01754-2; MIKELBERG FS, 1984, AM J OPHTHALMOL, V98, P443, DOI 10.1016/0002-9394(84)90128-4; Mohammadi K, 2004, AM J OPHTHALMOL, V138, P592, DOI 10.1016/j.ajo.2004.05.072; Morgan JE, 2005, OPHTHALMOLOGY, V112, P855, DOI 10.1016/j.ophtha.2004.11.056; Morgan JE, 2005, BRIT J OPHTHALMOL, V89, P879, DOI 10.1136/bjo.2004.046169; Moya FJ, 1999, BRIT J OPHTHALMOL, V83, P567, DOI 10.1136/bjo.83.5.567; Nouri-Mahdavi K, 2005, ARCH OPHTHALMOL-CHIC, V123, P193, DOI 10.1001/archopht.123.2.193; Nouri-Mahdavi K, 2004, INVEST OPHTH VIS SCI, V45, P4346, DOI 10.1167/iovs.04-0204; NOURIMAHDAVI K, 2005, S INVEST OPHTHALMOL, V46; Parrish RK, 2005, AM J OPHTHALMOL, V140, P762, DOI 10.1016/j.ajo.2005.04.044; Patterson AJ, 2005, INVEST OPHTH VIS SCI, V46, P1659, DOI 10.1167/iovs.04-0953; Quigley HA, 1996, J GLAUCOMA, V5, P106; QUIGLEY HA, 1992, OPHTHALMOLOGY, V99, P19; Rasker MT, 1997, ARCH OPHTHALMOL-CHIC, V115, P1257; Sample PA, 2005, INVEST OPHTH VIS SCI, V46, P3684, DOI 10.1167/iovs.04-1168; Sihota R, 2002, J GLAUCOMA, V11, P321, DOI 10.1097/01.IJG.0000021868.39905.96; Strouthidis NG, 2005, BRIT J OPHTHALMOL, V89, P1427, DOI 10.1136/bjo.2005.067298; Tan JCH, 2004, INVEST OPHTH VIS SCI, V45, P2279, DOI 10.1167/iovs.03-1243; Tannenbaum DP, 2004, OPHTHALMOLOGY, V111, P259, DOI 10.1016/j.ophtha.2003.05.015; Tezel G, 2001, ARCH OPHTHALMOL-CHIC, V119, P813; Uchida H, 1998, OPHTHALMOLOGY, V105, P1541, DOI 10.1016/S0161-6420(98)98044-7; Viswanathan AC, 2003, BRIT J OPHTHALMOL, V87, P726, DOI 10.1136/bjo.87.6.726; Wollstein G, 2005, ARCH OPHTHALMOL-CHIC, V123, P464, DOI 10.1001/archopht.123.4.464; Wollstein G, 1998, OPHTHALMOLOGY, V105, P1557, DOI 10.1016/S0161-6420(98)98047-2; Yamada N, 1997, J GLAUCOMA, V6, P279; Yamada N, 1998, J GLAUCOMA, V7, P378; Zangwill LM, 2005, ARCH OPHTHALMOL-CHIC, V123, P1188, DOI 10.1001/archopht.123.9.1188	61	16	16	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	1040-8738		CURR OPIN OPHTHALMOL	Curr. Opin. Ophthalmol.	APR	2006	17	2					153	162		10.1097/01.icu.0000193089.52561.ac		10	Ophthalmology	Ophthalmology	047RG	WOS:000237895800007	
J	Elith, J; Graham, CH; Anderson, RP; Dudik, M; Ferrier, S; Guisan, A; Hijmans, RJ; Huettmann, F; Leathwick, JR; Lehmann, A; Li, J; Lohmann, LG; Loiselle, BA; Manion, G; Moritz, C; Nakamura, M; Nakazawa, Y; Overton, JM; Peterson, AT; Phillips, SJ; Richardson, K; Scachetti-Pereira, R; Schapire, RE; Soberon, J; Williams, S; Wisz, MS; Zimmermann, NE				Elith, J; Graham, CH; Anderson, RP; Dudik, M; Ferrier, S; Guisan, A; Hijmans, RJ; Huettmann, F; Leathwick, JR; Lehmann, A; Li, J; Lohmann, LG; Loiselle, BA; Manion, G; Moritz, C; Nakamura, M; Nakazawa, Y; Overton, JM; Peterson, AT; Phillips, SJ; Richardson, K; Scachetti-Pereira, R; Schapire, RE; Soberon, J; Williams, S; Wisz, MS; Zimmermann, NE			Novel methods improve prediction of species' distributions from occurrence data	ECOGRAPHY			English	Review							CLIMATE-CHANGE; LOGISTIC-REGRESSION; DISTRIBUTION MODELS; HABITAT-SUITABILITY; POTENTIAL DISTRIBUTION; SPATIAL PREDICTION; ENVELOPE MODELS; CONSERVATION; BIODIVERSITY; PLANT	Prediction of species' distributions is central to diverse applications in ecology, evolution and conservation science. There is increasing electronic access to vast sets of occurrence records in museums and herbaria, yet little effective guidance on how best to use this information in the context of numerous approaches for modelling distributions. To meet this need, we compared 16 modelling methods over 226 species from 6 regions of the world, creating the most comprehensive set of model comparisons to date. We used presence-only data to fit models, and independent presence-absence data to evaluate the predictions. Along with well-established modelling methods such as generalised additive models and GARP and BIOCLIM, we explored methods that either have been developed recently or have rarely been applied to modelling species' distributions. These include machine-learning methods and community models, both of which have features that may make them particularly well suited to noisy or sparse information, as is typical of species' occurrence data. Presence-only data were effective for modelling species' distributions for many species and regions. The novel methods consistently outperformed more established methods. The results of our analysis are promising for the use of data from museums and herbaria, especially as methods suited to the noise inherent in such data improve.	Univ Melbourne, Sch Bot, Parkville, Vic 3010, Australia; SUNY Stony Brook, Dept Ecol & Evolut, Stony Brook, NY 11794 USA; CUNY City Coll, New York, NY 10031 USA; Princeton Univ, Princeton, NJ 08544 USA; Dept Environm & Conservat, Armidale, NSW, Australia; Univ Lausanne, CH-1015 Lausanne, Switzerland; Univ Calif Berkeley, Berkeley, CA 94720 USA; Univ Alaska Fairbanks, Fairbanks, AK USA; NIWA, Hamilton, New Zealand; Swiss Ctr Faunal Cartog, Neuchatel, Switzerland; CSIRO Atherton, Atherton, Qld, Australia; Univ Sao Paulo, BR-05508 Sao Paulo, Brazil; Univ Missouri, St Louis, MO 63121 USA; CIMAT, Mexico City, DF, Mexico; Univ Kansas, Lawrence, KS 66045 USA; Landcare Res, Hamilton, New Zealand; AT&T Labs Res, Florham Pk, NJ USA; McGill Univ, Montreal, PQ H3A 2T5, Canada; James Cook Univ N Queensland, Townsville, Qld 4811, Australia; Natl Environm Res Inst, Roskilde, Denmark; Swiss Fed Res Inst WSL, Birmensdorf, Switzerland	Elith, J (reprint author), Univ Melbourne, Sch Bot, Parkville, Vic 3010, Australia.	j.elith@unimelb.edu.au	Zimmermann, Niklaus/A-4276-2008; Williams, Stephen/A-7250-2008; Ferrier, Simon/C-1490-2009; Graham, Catherine/A-9560-2011; Lehmann, Anthony/B-1544-2010; Moritz, Craig/A-7755-2012; Lohmann, Lucia/C-9492-2013	Zimmermann, Niklaus/0000-0003-3099-9604; Lohmann, Lucia/0000-0003-4960-0587			Anderson RP, 2003, J BIOGEOGR, V30, P591; Anderson RP, 2002, OIKOS, V98, P3, DOI 10.1034/j.1600-0706.2002.t01-1-980116.x; Araujo MB, 2004, GLOBAL CHANGE BIOL, V10, P1618, DOI 10.1111/j.1365-2486.2004.00828.x; Araujo MB, 2000, BIOL CONSERV, V96, P331, DOI 10.1016/S0006-3207(00)00074-4; Araujo MB, 2005, GLOBAL CHANGE BIOL, V11, P1504, DOI 10.1111/j.1365-2486.2005.001000.x; Austin M. P., 1981, P ECOL SOC AUST, V11, P109; AUSTIN MP, 1994, J VEG SCI, V5, P215, DOI 10.2307/3236154; Austin MP, 2002, ECOL MODEL, V157, P101, DOI 10.1016/S0304-3800(02)00205-3; AUSTIN MP, 1995, DIVISION WILDLIFE EC; Bakkenes M, 2002, GLOBAL CHANGE BIOL, V8, P390, DOI 10.1046/j.1354-1013.2001.00467.x; BARRY SC, IN PRESS J APPL ECOL; BIO AMF, 2000, THESIS UTRECHT U NET; BOJORQUEZTAPIA LA, 1995, ECOL APPL, V5, P215, DOI 10.2307/1942065; Boyce MS, 2002, ECOL MODEL, V157, P281, DOI 10.1016/S0304-3800(02)00200-4; Brotons L, 2004, ECOGRAPHY, V27, P437, DOI 10.1111/j.0906-7590.2004.03764.x; Brown JH, 1998, BIOGEOGRAPHY; Burgman MA, 2005, ECOLOGY, V86, P2007, DOI 10.1890/04-0906; Burnham KP, 2002, MODEL SELECTION INFE; Busby J. R., 1991, NATURE CONSERVATION, P64; CARPENTER G, 1993, BIODIVERS CONSERV, V2, P667, DOI 10.1007/BF00051966; Cawsey EM, 2002, BIODIVERS CONSERV, V11, P2239, DOI 10.1023/A:1021350813586; Cicero C, 2004, EVOLUTION, V58, P1573; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Elith J, 2002, PREDICTING SPECIES OCCURRENCES: ISSUES OF ACCURACY AND SCALE, P303; Ferrier S, 2002, BIODIVERS CONSERV, V11, P2275, DOI 10.1023/A:1021302930424; Ferrier S., 1997, EVALUATION EFFECTIVE; Ferrier S, 2002, BIODIVERS CONSERV, V11, P2309, DOI 10.1023/A:1021374009951; Ferrier S, 2002, SYST BIOL, V51, P331, DOI 10.1080/10635150252899806; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Funk VA, 2002, SYST BIOL, V51, P303, DOI 10.1080/10635150252899789; Gelfand AE, 2006, BAYESIAN ANAL, V1, P41; Goolsby JA, 2004, NAT AREA J, V24, P351; Graham CH, 2006, P NATL ACAD SCI USA, V103, P632, DOI 10.1073/pnas.0505754103; Graham CH, 2004, EVOLUTION, V58, P1781, DOI 10.1554/03-274; Graham CH, 2004, TRENDS ECOL EVOL, V19, P497, DOI 10.1016/j.tree.2004.07.006; Guisan A, 1998, J VEG SCI, V9, P65, DOI 10.2307/3237224; Guisan A, 2003, J BIOGEOGR, V30, P1233, DOI 10.1046/j.1365-2699.2003.00914.x; Guisan A, 2005, ECOL LETT, V8, P993, DOI 10.1111/j.1461-0248.2005.00792.x; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; HANLEY JA, 1982, RADIOLOGY, V143, P29; HANSKI I, 1994, TRENDS ECOL EVOL, V9, P131, DOI 10.1016/0169-5347(94)90177-5; Harrell FE., 2001, REGRESSION MODELING; Hastie T, 2001, ELEMENTS STAT LEARNI; Hijmans RJ, 2000, CONSERV BIOL, V14, P1755, DOI 10.1046/j.1523-1739.2000.98543.x; Hijmans RJ, 2005, INT J CLIMATOL, V25, P1965, DOI 10.1002/joc.1276; Hirzel A, 2002, ECOL MODEL, V157, P331, DOI 10.1016/S0304-3800(02)00203-X; Hirzel AH, 2002, ECOLOGY, V83, P2027, DOI 10.1890/0012-9658(2002)083[2027:ENFAHT]2.0.CO;2; Huettmann F, 2005, J WILDLIFE MANAGE, V69, P466, DOI 10.2193/0022-541X(2005)069[0466:DASMIT]2.0.CO;2; Hugall A, 2002, P NATL ACAD SCI USA, V99, P6112, DOI 10.1073/pnas.092538699; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; Kadmon R, 2003, ECOL APPL, V13, P853, DOI 10.1890/1051-0761(2003)013[0853:ASAOFA]2.0.CO;2; Kadmon R, 2004, ECOL APPL, V14, P401, DOI 10.1890/02-5364; Keating KA, 2004, J WILDLIFE MANAGE, V68, P774, DOI 10.2193/0022-541X(2004)068[0774:UAIOLR]2.0.CO;2; Leathwick JR, 2005, FRESHWATER BIOL, V50, P2034, DOI 10.1111/j.1365-2427.2005.01448.x; Leathwick JR, 2002, BIODIVERS CONSERV, V11, P2177, DOI 10.1023/A:1021394628607; LEATHWICK JR, IN PRESS MAR ECOL PR; Leathwick JR, 2001, ECOLOGY, V82, P2560, DOI 10.1890/0012-9658(2001)082[2560:CIBTSI]2.0.CO;2; Liu CR, 2005, ECOGRAPHY, V28, P385, DOI 10.1111/j.0906-7590.2005.03957.x; Loiselle BA, 2003, CONSERV BIOL, V17, P1591, DOI 10.1111/j.1523-1739.2003.00233.x; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Luoto M, 2005, GLOBAL ECOL BIOGEOGR, V14, P575, DOI 10.1111/j.1466-822x.2005.00186.x; Mac Nally R, 2004, CONSERV BIOL, V18, P646; McCarthy MA, 2005, J APPL ECOL, V42, P1012, DOI 10.1111/j.1365-2664.2005.01101.x; Moilanen A, 2005, P ROY SOC B-BIOL SCI, V272, P1885, DOI 10.1098/rspb.2005.3164; Moisen GG, 2002, ECOL MODEL, V157, P209, DOI 10.1016/S0304-3800(02)00197-7; Munoz J, 2004, J VEG SCI, V15, P285, DOI 10.1658/1100-9233(2004)015[0285:COSMCU]2.0.CO;2; MURPHY AH, 1992, INT J FORECASTING, V7, P435, DOI 10.1016/0169-2070(92)90028-8; Pearce J, 2001, J ENVIRON MANAGE, V62, P171, DOI 10.1006/jema.2001.0425; Pearce J, 2000, ECOL MODEL, V133, P225, DOI 10.1016/S0304-3800(00)00322-7; Pearce J, 2000, ECOL MODEL, V128, P127, DOI 10.1016/S0304-3800(99)00227-6; PEARCE JL, IN PRESS J APPL ECOL; Peterson AT, 2003, Q REV BIOL, V78, P419, DOI 10.1086/378926; PETERSON AT, 2005, SW NAT, P230; Peterson AT, 2004, DIVERS DISTRIB, V10, P237, DOI 10.1111/j.1366-9516.2004.00097.x; Phillips SJ, 2004, P 21 INT C MACH LEAR; Phillips SJ, 2006, ECOL MODEL, V190, P231, DOI 10.1016/j.ecolmodel.2005.03.026; Pielke RA, 2003, MODELS IN ECOSYSTEM SCIENCE, P111; POMPA AG, 1970, ANALES I BIOL UNAM B, V31, P137; RANDIN CF, IN PRESS J BIOGEOGR; RAPOPORT EH, 1982, AEROGRAPHY; Raxworthy CJ, 2003, NATURE, V426, P837, DOI 10.1038/nature02205; Reese GC, 2005, ECOL APPL, V15, P554, DOI 10.1890/03-5374; Ricklefs RE, 2004, ECOL LETT, V7, P1, DOI 10.1046/j.1461-0248.2003.00554.x; Ridgeway G., 1999, COMPUTING SCI STAT, P172; Rosenzweig M.L., 1995, SPECIES DIVERSITY SP; Rushton SP, 2004, J APPL ECOL, V41, P193, DOI 10.1111/j.0021-8901.2004.00903.x; Scotts David, 2003, Pacific Conservation Biology, V8, P235; Segurado P, 2004, J BIOGEOGR, V31, P1555, DOI 10.1111/j.1365-2699.2004.01076.x; Silverman B.W., 1986, DENSITY ESTIMATION S; Skov F, 2004, ECOGRAPHY, V27, P366, DOI 10.1111/j.0906-7590.2004.03823.x; Sneath P. H. A., 1973, NUMERICAL TAXONOMY P; Soberon Jorge, 2005, Biodiversity Informatics, V2, P1; Soberon JM, 2000, BIODIVERS CONSERV, V9, P1441, DOI 10.1023/A:1008987010383; Spiegelhalter D, 2003, WINBUGS USER MANUAL; SPIEGELHALTER DJ, 2003, J ROY STAT SOC B, V64, P583; Stockwell D, 1999, INT J GEOGR INF SCI, V13, P143, DOI 10.1080/136588199241391; Stockwell DRB, 2002, ECOL MODEL, V148, P1, DOI 10.1016/S0304-3800(01)00388-X; Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121; Thornton PE, 1997, J HYDROL, V190, P214, DOI 10.1016/S0022-1694(96)03128-9; Thuiller W, 2004, ECOLOGY, V85, P1688, DOI 10.1890/03-0148; Thuiller W, 2004, GLOBAL CHANGE BIOL, V10, P2020, DOI 10.1111/j.1365-2486.2004.00859.x; Thuiller W, 2005, P NATL ACAD SCI USA, V102, P8245, DOI 10.1073/pnas.0409902102; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Turner W, 2003, TRENDS ECOL EVOL, V18, P306, DOI 10.1016/S0169-5347(03)00070-3; Tyre AJ, 2001, ECOL APPL, V11, P1722, DOI 10.2307/3061091; VANHORNE B, 1983, J WILDLIFE MANAGE, V47, P893; Venier LA, 1999, J BIOGEOGR, V26, P315, DOI 10.1046/j.1365-2699.1999.00273.x; WALKER PA, 1991, GLOBAL ECOL BIOGEOGR, V1, P108, DOI 10.2307/2997706; WINTLE BA, IN PRESS ECOL APPL; YEE TW, 1991, J VEG SCI, V2, P587, DOI 10.2307/3236170; Zaniewski AE, 2002, ECOL MODEL, V157, P261, DOI 10.1016/S0304-3800(02)00199-0; Zheng BY, 2000, STAT MED, V19, P1771, DOI 10.1002/1097-0258(20000715)19:13<1771::AID-SIM485>3.3.CO;2-G	113	1574	1676	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0906-7590		ECOGRAPHY	Ecography	APR	2006	29	2					129	151		10.1111/j.2006.0906-7590.04596.x		23	Biodiversity Conservation; Ecology	Biodiversity & Conservation; Environmental Sciences & Ecology	032IB	WOS:000236767000001	
J	Monch, L; Zimmermann, J; Otto, P				Monch, L; Zimmermann, J; Otto, P			Machine learning techniques for scheduling jobs with incompatible families and unequal ready times on parallel batch machines	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						scheduling; batching; machine learning	SEMICONDUCTOR MANUFACTURING PROCESSES; PROCESSING MACHINE; WEIGHTED TARDINESS; HEURISTIC RULES; NEURAL-NETWORKS; SHOPS	This research is motivated by a scheduling problem found in the diffusion and oxidation areas of semiconductor wafer fabrication facilities, where the machines can be modeled as parallel batch processors. Total weighted tardiness on parallel batch machines with incompatible job families and unequal ready times of the jobs is attempt to minimize. Given that the problem is NP hard, a simple heuristic based on the Apparent Tardiness Cost (ATC) Dispatching Rule is suggested. Using this rule, a look-ahead parameter has to be chosen. Because of the appearance of unequal ready times and batch machines it is hard to develop a closed formula to estimate this parameter. The use of inductive decision trees and neural networks from machine learning is suggested to tackle the problem of parameter estimation. The results of computational experiments based on stochastically generated test data are presented. The results indicate that a successful choice of the look-ahead parameter is possible by using the machine learning techniques. (C) 2005 Elsevier Ltd. All rights reserved.	Tech Univ Ilmenau, Inst Informat Syst, D-98684 Ilmenau, Germany; Tech Univ Ilmenau, Dept Syst Anal, D-98684 Ilmenau, Germany	Monch, L (reprint author), Tech Univ Ilmenau, Inst Informat Syst, D-98684 Ilmenau, Germany.	Lars.Moench@tu-ilmenau.de; Jens.Zimmermann@tu-ilmenau.de; Peter.Otto@tu-ilmenau.de					AYTUG H, 1994, IEEE T ENG MANAGE, V41, P165, DOI 10.1109/17.293383; Azizoglu M, 2001, COMPUT IND ENG, V39, P325, DOI 10.1016/S0360-8352(01)00009-2; Chand S, 1997, ANN OPER RES, V70, P115, DOI 10.1023/A:1018961818782; Chao X., 1992, PARAMETRIC ADJUSTMEN; Cigolini R, 2002, J SCHED, V5, P185, DOI 10.1002/jos.099; DEVPURA A, 2000, P S OP RES DRESD GER, P366; Duenyas I, 1997, ANN OPER RES, V70, P191, DOI 10.1023/A:1018922104670; Dupont L, 2002, COMPUT OPER RES, V29, P807, DOI 10.1016/S0305-0548(00)00078-2; Fowler JW, 2000, IIE TRANS, V32, P167, DOI 10.1080/07408170008963889; FOWLER JW, 1992, IEEE T SEMICONDUCT M, V5, P158, DOI 10.1109/66.136278; GLASSEY CR, 1991, IEEE T SEMICONDUCT M, V4, P77, DOI 10.1109/66.79719; Graham R. L., 1979, ANN DISCRETE MATH, V5, P287; Jain AS, 1998, INT J PROD RES, V36, P1249, DOI 10.1080/002075498193309; KIM SY, 1995, PROD PLAN CONTROL, V6, P445, DOI 10.1080/09537289508930302; Lawler E. L., 1977, ANN DISCRETE MATH, V1, P331; LEE YH, 1997, EUROPEAN J OPERATION, V100, P446; Mason SJ, 2002, J SCHED, V5, P247, DOI 10.1002/jos.102; Mehta SV, 1998, IIE TRANS, V30, P165, DOI 10.1080/07408179808966448; Mitchell T, 1997, MACHINE LEARNING; Monch L, 2005, COMPUT OPER RES, V32, P2731, DOI 10.1016/j.cor.2004.04.001; Monch L, 2003, LECT NOTES ARTIF INT, V2744, P258; MONCH L, 2002, P INT S OP RES KLAG, P205; MONCH L, 2002, P 4 MIDL E SIM S SHA, P192; Otto P., 2002, P E W FUZZ C 2002 10, P351; OTTO P, 1995, P 3 EUR C INT TECHN, P858; Park YS, 2000, COMPUT IND ENG, V38, P189, DOI 10.1016/S0360-8352(00)00038-3; PEREZ TL, 1999, THESIS ARIZONA STATE; Pined M., 2002, SCHEDULING THEORY AL; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; ROBINSON JK, 1995, INT J PROD RES, V33, P1849, DOI 10.1080/00207549508904785; Schlimmer J. C., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; UTGOFF PE, 1998, MIT ENCY COGNITIVE S; VEPSALAINEN APJ, 1987, MANAGE SCI, V33, P1035, DOI 10.1287/mnsc.33.8.1035; Wang CS, 2002, COMPUT OPER RES, V29, P1621, DOI 10.1016/S0305-0548(01)00031-4	35	21	21	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	APR	2006	19	3					235	245		10.1016/j.engappai.2005.10.001		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	025VM	WOS:000236295100001	
J	Priore, P; de la Fuente, D; Puente, J; Parreno, J				Priore, P; de la Fuente, D; Puente, J; Parreno, J			A comparison of machine-learning algorithms for dynamic scheduling of flexible manufacturing systems	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						knowledge-based systems; scheduling; FMS	OPERATION-ALLOCATION PROBLEM; DISPATCHING RULES; JOB SHOP; DECISION RULES; FMS; SIMULATION; FORMULATION; KNOWLEDGE; PERFORMANCE; ATTRIBUTES	Dispatching rules are frequently used to schedule jobs in flexible manufacturing systems (FMSs) dynamically. A drawback, however, to using dispatching rules is that their performance is dependent oil the state of the system, but no single rule exists that is superior to all the others for all the possible states the system might be in. This drawback would be eliminated if the best rule for each particular situation could be used. To do this, this paper presents a scheduling approach that employs machine learning. Using this latter technique, and by analysing the earlier performance of the system, 'scheduling knowledge' is obtained whereby the right dispatching rule at each particular moment can be determined. Three different types of machine-learning algorithms will be used and compared in the paper to obtain 'scheduling knowledge': inductive learning, backpropagation neural networks, and case-based reasoning (CBR). A module that generates new control attributes allowing better identification of the manufacturing system's state at any particular moment in time is also designed in order to improve the 'scheduling knowledge' that is obtained. Simulation results indicate that the proposed approach produces significant performance improvements over existing dispatching rules. (C) 2005 Elsevier Ltd. All rights reserved.	Univ Oviedo, Escuela Tecn Super Ingn Ind, Gijon 33203, Spain	Priore, P (reprint author), Univ Oviedo, Escuela Tecn Super Ingn Ind, Campus Viesques, Gijon 33203, Spain.	priore@cpsig.uniovi.es					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AYTUG H, 1994, IEEE T ENG MANAGE, V41, P165, DOI 10.1109/17.293383; BAKER KR, 1984, MANAGE SCI, V30, P1093, DOI 10.1287/mnsc.30.9.1093; BLACKSTONE JH, 1982, INT J PROD RES, V20, P27, DOI 10.1080/00207548208947745; CESTNIK B, 1987, PROGR MACHINE LEARNI; Chen CC, 1996, INT J PROD RES, V34, P1739, DOI 10.1080/00207549608904994; CHO H, 1993, INT J PROD RES, V31, P771, DOI 10.1080/00207549308956756; CHOI RH, 1988, J MANUF SYST, V7, P33, DOI 10.1016/0278-6125(88)90031-3; DENZLER DR, 1987, INT J PROD RES, V25, P979, DOI 10.1080/00207548708919890; EGBELU PJ, 1984, INT J PROD RES, V22, P359, DOI 10.1080/00207548408942459; FLANAGAN B, 2003, INT MANUFACTURING C, V20; Freeman J.A., 1991, NEURAL NETWORKS ALGO; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; Garey MR, 1979, COMPUTERS INTRACTABI; GLOVER F, 1999, P 1999 WINT SIM C; Goldberg DE, 1989, GENETIC ALGORITHMS S; HAN MH, 1989, INT J PROD RES, V27, P1257, DOI 10.1080/00207548908942621; HENNEKE MJ, 1990, COMPUT IND ENG, V18, P105, DOI 10.1016/0360-8352(90)90046-O; HOLLAND JH, 1975, ADAPTATION NATURAL A; Hunt E.B., 1966, EXPT INDUCTION; HUTCHINSON J, 1989, P 3 ORSA TIMS C FLEX, P161; ISHII N, 1991, INT J PROD RES, V29, P2501, DOI 10.1080/00207549108948099; Jeong KC, 1998, INT J PROD RES, V36, P2609, DOI 10.1080/002075498192733; Kim CO, 1998, INT J PROD RES, V36, P2497, DOI 10.1080/002075498192652; KIM MH, 1994, J MANUF SYST, V13, P85; KIM YD, 1990, INT J PROD RES, V28, P953, DOI 10.1080/00207549008942766; KIMEMIA J, 1985, INT J PROD RES, V23, P81, DOI 10.1080/00207548508904692; LASHKARI RS, 1987, INT J PROD RES, V25, P1267, DOI 10.1080/00207548708919914; Lippman R., 1987, IEEE ASSP MAG, V3, P4; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Michalski R. S., 1983, MACHINE LEARNING ART; Min HS, 1998, INT J PROD RES, V36, P1749, DOI 10.1080/002075498192940; MONTAZERI M, 1990, INT J PROD RES, V28, P785, DOI 10.1080/00207549008942754; NAKASUKA S, 1992, INT J PROD RES, V30, P411, DOI 10.1080/00207549208942903; OKEEFE RM, 1992, INT J PROD RES, V30, P1753, DOI 10.1080/00207549208948120; PANWALKAR SS, 1977, OPER RES, V23, P961; Priore P, 2001, AI EDAM, V15, P251, DOI 10.1017/S0890060401153059; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1979, EXPERT SYSTEM MICROE; Quinlan J.R., 1983, MACHINE LEARNING ART; RAMASESH R, 1990, OMEGA-INT J MANAGE S, V18, P43, DOI 10.1016/0305-0483(90)90017-4; RENDELL L, 1983, ARTIF INTELL, V20, P369, DOI 10.1016/0004-3702(83)90002-4; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; RUSSELL RS, 1987, INT J PROD RES, V25, P1523, DOI 10.1080/00207548708919930; SHANKER K, 1985, INT J PROD RES, V23, P579, DOI 10.1080/00207548508904730; Shanker K., 1989, P 3 ORSA TIMS C FLEX, P99; SHAW MJ, 1992, IIE TRANS, V24, P156, DOI 10.1080/07408179208964213; STECKE KE, 1983, MANAGE SCI, V29, P273, DOI 10.1287/mnsc.29.3.273; STECKE KE, 1981, INT J PROD RES, V19, P481, DOI 10.1080/00207548108956679; TANG LL, 1993, COMPUT IND, V22, P1, DOI 10.1016/0166-3615(93)90076-D; VEPSALAINEN APJ, 1987, MANAGE SCI, V33, P1035, DOI 10.1287/mnsc.33.8.1035; WILSON JM, 1989, INT J PROD RES, V27, P1405, DOI 10.1080/00207548908942630; WU SYD, 1989, INT J PROD RES, V27, P1603, DOI 10.1080/00207548908942642; *AT T ISTEL LTD, 1996, WITN US MAN REL 8 0	55	26	27	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	APR	2006	19	3					247	255		10.1016/j.engappai.2005.09.009		9	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	025VM	WOS:000236295100002	
J	Hansen, JV; McDonald, JB; Turley, RS				Hansen, JV; McDonald, JB; Turley, RS			Partially adaptive robust estimation of regression models and applications	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article						regression; multivariate statistics; applied probability; partially adaptive estimation	GENERALIZED-T DISTRIBUTION	This paper provides an accessible exposition of recently developed partially adaptive estimation methods and their application. These methods are robust to thick-tailed or asymmetric error distributions and should be of interest to researchers and practitioners in data mining, agent learning, and mathematical modeling in a wide range of disciplines. In particular, partially adaptive estimation methods can serve as robust alternatives to ordinary regression analysis, as well as machine learning methods developed by the artificial intelligence and computing communities. Results from analysis of three problem domains demonstrate application of the theory. (c) 2004 Elsevier B.V. All rights reserved.	Brigham Young Univ, Marriott Sch Management, Informat Syst Grp, Provo, UT 84602 USA; Brigham Young Univ, Dept Econ, Provo, UT 84602 USA; Goldman Sachs, New York, NY USA	Hansen, JV (reprint author), Brigham Young Univ, Marriott Sch Management, Informat Syst Grp, POB 23068,540 N Eldon Tanner Bldg, Provo, UT 84602 USA.	james_hansen@byu.edu					Belsely D. A., 1980, REGRESSION DIAGNOSTI; BOX GEP, 1962, BIOMETRIKA, V49, P419, DOI 10.2307/2333976; BOYER BH, 2003, ECONOMETRIC REV, P115; BUTLER RJ, 1990, REV ECON STAT, V72, P321, DOI 10.2307/2109722; Hampel F., 1986, ROBUST STAT APPROACH; HAMPEL FR, 1974, J AM STAT ASSOC, V69, P383, DOI 10.2307/2285666; HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2; Hastie T, 2001, ELEMENTS STAT LEARNI; Huber P. J., 1981, ROBUST STAT; Johnson N. H., 1970, CONTINUOUS UNIVARIAT; JOHNSON NL, 1949, BIOMETRIKA, V36, P149, DOI 10.2307/2332539; KOENKER R, 1982, ECONOMET REV, V1, P213; MCDONALD JB, 1988, ECONOMET THEOR, V4, P428; MCDONALD JB, 1993, ECONOMET REV, V12, P103, DOI 10.1080/07474939308800255; MCDONALD JB, 1995, J ECONOMETRICS, V69, P427, DOI 10.1016/0304-4076(94)01680-X; MCDONALD JB, 1995, J ECONOMETRICS, V66, P133, DOI 10.1016/0304-4076(94)01612-4; NEWEY WK, 1988, J ECONOMETRICS, V38, P301, DOI 10.1016/0304-4076(88)90048-6; RASCH RH, 1992, MIS QUART, V16, P395, DOI 10.2307/249535; Rousseeuw P, 1987, ROBUST REGRESSION OU; STAMEY TA, 1989, J UROLOGY, V16, DOI UNSP 10761083; Subbotin M. T, 1923, MAT SBORNIK, V31, P296; Theodossiou P, 1998, MANAGE SCI, V44, P1650, DOI 10.1287/mnsc.44.12.1650; ZECKHAUSER R, 1970, REV ECON STAT, V50, P280; Zellner A., 1971, INTRO BAYESIAN INFER	24	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217		EUR J OPER RES	Eur. J. Oper. Res.	APR 1	2006	170	1					132	143		10.1016/j.ejor.2004.06.008		12	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	981TA	WOS:000233109700009	
J	Piramuthu, S				Piramuthu, S			On preprocessing data for financial credit risk evaluation	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						feature selection; feature construction; financial credit-risk evaluation; decision tables	FEATURE-SELECTION; DECISION TABLES; NEURAL NETWORKS; CHOICE; INFORMATION; PREDICTION; ALGORITHMS; INDUCTION; DEFAULT; EXAMPLE	Financial credit-risk evaluation is among a class of problems known to be semi-structured, where not all variables that are used for decision-making are either known or captured without error. Machine learning has been successfully used for credit-evaluation decisions. However, blindly applying machine learning methods to financial credit risk evaluation data with minimal knowledge of data may not always lead to expected results. We present and evaluate some data and methodological considerations that are taken into account when using machine learning methods for these decisions. Specifically, we consider the effects of preprocessing of credit-risk evaluation data used as input for machine learning methods. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Florida, Decis & Informat Sci, Gainesville, FL 32611 USA	Piramuthu, S (reprint author), Univ Florida, Decis & Informat Sci, 351 Stuzin Hall,POB 117169, Gainesville, FL 32611 USA.	selwyn@ufl.edu					ABDELKHALIK AR, 1980, J ACCOUNTING RES, V18, P325, DOI 10.2307/2490581; Al-Ani A., 2001, Proceedings of the Sixth International Symposium on Signal Processing and its Applications (Cat.No.01EX467), DOI 10.1109/ISSPA.2001.950184; ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; ANG JS, 1975, J FINANC, V30, P631, DOI 10.2307/2978740; Baesens B, 2003, MANAGE SCI, V49, P312, DOI 10.1287/mnsc.49.3.312.12739; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; BENITEZ JM, 2001, P IFSA WORLD C 20 NA, V2, P1003, DOI 10.1109/NAFIPS.2001.944742; Bradley P. S., 1998, INFORMS Journal on Computing, V10, DOI 10.1287/ijoc.10.2.209; Breiman L, 1984, CLASSIFICATION REGRE; CALLAHAN JD, 1991, J OPER RES SOC, V42, P227, DOI 10.1057/jors.1991.44; CARTER C, 1987, IEEE EXPERT      FAL, P71; CHAMBLESS B, 2001, P INT JOINT C NEUR N, V2, P1443; CHAN KC, 1991, KNOWLEDGE DISCOVERY; Coetzee F. M., 2001, Proceedings 2001 Symposium on Applications and the Internet, DOI 10.1109/SAINT.2001.905163; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; Culberson JC, 1998, EVOL COMPUT, V6, P109, DOI 10.1162/evco.1998.6.2.109; CURRAM SP, 1994, J OPER RES SOC, V45, P440, DOI 10.1057/jors.1994.62; CURRIM IS, 1988, J MARKETING RES, V25, P253, DOI 10.2307/3172528; Devijver P. A., 1982, PATTERN RECOGNITION; Duin RPW, 1996, PATTERN RECOGN LETT, V17, P529, DOI 10.1016/0167-8655(95)00113-1; ELASHOFF JD, 1967, BIOMETRIKA, V54, P668, DOI 10.2307/2335061; ELOMAA T, 1994, P EUR C MACH LEARN, P351; FENG C, 1993, AI STAT, V93, P41; Flach PA, 2001, MACH LEARN, V42, P61, DOI 10.1023/A:1007656703224; GIPLIN EA, 1990, COMP BIOMEDICAL RES, V23, P46; HOPKINS C, 1994, 11 EUR C ART INT, P221; Igel C, 2003, INFORM PROCESS LETT, V86, P317, DOI 10.1016/S0020-0190(03)00222-9; John G.H., 1994, P 11 INT C MACH LEAR, P121; Kira K, 1992, P 9 INT C MACH LEARN, P249; KITTLER J, 1975, INT J MAN MACH STUD, V7, P609, DOI 10.1016/S0020-7373(75)80023-X; Klosgen W., 1996, ADV KNOWLEDGE DISCOV, P249; KOHAVI R, 1994, 3 INT WORKSH ROUGH S; Kohavi R., 1995, P 8 EUR C MACH LEARN, P174; Kohavi R., 1995, THESIS STANFORD U; KOLLER D, 1996, P 13 INT C; Kononenko I., 1994, P EUR C MACH LEARN, P171; KORS JA, 1990, METHOD INFORM MED, V29, P330; Langley P, 1986, MACHINE LEARNING ART, VII, P425; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642; MALKI HA, 1991, IEEE T NEURAL NETWOR, V2, P162, DOI 10.1109/72.80306; Matheus C.J., 1989, P 11 INT JOINT C ART, P645; Meisel W. S., 1972, COMPUTER ORIENTED AP; MESSIER WF, 1988, MANAGE SCI, V34, P1403, DOI 10.1287/mnsc.34.12.1403; MICHAELSEN RH, 1984, EXPERT SYSTEMS   OCT, P149; MILNE L, 1995, AI95 CANB; MODRZEJEWSKI M, 1993, EUR C MACH LEARN, P213; Pagallo G., 1989, P 11 IJCAI, P639; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PIRAMUTHU S, 1994, INT S INT KNOWL NEUR, P67; Piramuthu S, 1999, EUR J OPER RES, V112, P310, DOI 10.1016/S0377-2217(97)00398-6; PUDIL P, 1994, IEEE 12 INT C PATT R, V2, P279; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545; Ragavan H., 1993, P 13 INT JOINT C ART, P946; Rendell L., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00298.x; Schumacher C., 2001, P GEN EV COMP C GECC, P565; Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654; SHAFFER C, 1994, P 1994 INT C MACH LE; SHAW M, 1990, IEEE EXPERT, P47; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Stearns S. D., 1976, 3rd International Joint Conference on Pattern Recognition; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; TOUSSAIN.GT, 1971, IEEE T INFORM THEORY, V17, P618, DOI 10.1109/TIT.1971.1054686; VANTHIENEN J, 1994, DATA KNOWL ENG, V13, P265, DOI 10.1016/0169-023X(94)00020-4; WOLPERT DH, 1995, SFITR05010 SANT FE I; WROBEL S, 1997, P 1 EUR S PRINC DAT; Yang D.S., 1991, P 12 INT JOINT C ART, P699; Yang J., 1997, P GEN PROGR C GP 97, P380; YUAN H, 1999, P IEEE INT C SYST MA, V2, P132	70	12	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2006	30	3					489	497		10.1016/j.eswa.2005.10.06		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	011IG	WOS:000235261000008	
J	Ince, H; Trafalis, TB				Ince, H; Trafalis, TB			Kernel methods for short-term portfolio management	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						support vector machines; minimax probability machine; kernel methods; portfolio management; earning announcements	SUPPORT VECTOR MACHINES; EARNINGS ANNOUNCEMENTS; TRADING VOLUME; SECURITY RETURNS; STOCK RETURNS; PRICE; INFORMATION; NETWORKS; BEHAVIOR; MARKET	Portfolio optimization problem has been studied extensively. In this paper, we look at this problem from a different perspective. Several researchers argue that the USA equity market is efficient. Some of the studies show that the stock market is not efficient around the earning season. Based on these findings, we formulate the problem as a classification problem by using state of the art machine learning techniques such as minimax probability machine (MPM) and support vector machines (SVM). The MPM method finds a bound on the misclassification probabilities. On the other hand, SVM finds a hyperplane that maximizes the distance between two classes. Both methods prove similar results for short-term portfolio management. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Oklahoma, Sch Ind Engn, Norman, OK 73019 USA; Gebze Inst Technol, Sch Business Adm Studies, TR-41400 Kocaeli, Turkey	Trafalis, TB (reprint author), Univ Oklahoma, Sch Ind Engn, 202 W Boyd,Ste 124, Norman, OK 73019 USA.	h.ince@gyte.edu.tr; ttrafalis@ou.edu	Ince, Huseyin/A-9132-2009				Andersen E. D., 2000, HIGH PERFORMANCE OPT, P197; ATIASE RK, 1985, J ACCOUNTING RES, V23, P21, DOI 10.2307/2490905; BALL R, 1991, ACCOUNT REV, V66, P718; BALL R, 1968, J ACCOUNTING RES, V6, P159, DOI 10.2307/2490232; BAMBER LS, 1987, ACCOUNT REV, V62, P510; Bamber LS, 1997, ACCOUNT REV, V72, P575; BARRON OE, 1995, ACCOUNT REV, V70, P581; BEAVER WH, 1968, J ACCOUNTING RES, V6, P67, DOI 10.2307/2490070; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHAMBERS AE, 1984, J ACCOUNTING RES, V22, P21, DOI 10.2307/2490700; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; CHARI VV, 1988, J FINANC ECON, V21, P101, DOI 10.1016/0304-405X(88)90033-5; Chen AS, 2003, COMPUT OPER RES, V30, P901, DOI 10.1016/S0305-0548(02)00037-0; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Conroy RM, 1998, INT J FORECASTING, V14, P227, DOI 10.1016/S0169-2070(98)00029-6; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CRISTIANINI N, 1998, DYNAMICALLY ADAPTING, P204; Dourra H, 2002, FUZZY SET SYST, V127, P221, DOI 10.1016/S0165-0114(01)00169-5; EASTON PD, 1989, J ACCOUNT ECON, V11, P117, DOI 10.1016/0165-4101(89)90003-7; EILIFSEN A, 2001, SCANDINAVIAN J MANAG, V17, P187, DOI 10.1016/S0956-5221(99)00031-7; GALINDO J, 1998, FRAMEWORK COMP ANAL; Gennotte G, 1996, REV FINANC STUD, V9, P665, DOI 10.1093/rfs/9.2.665; HOLTHAUSEN RW, 1990, ACCOUNT REV, V65, P191; HUTCHINSON JM, 1994, J FINANC, V49, P851, DOI 10.2307/2329209; Kothari SP, 2001, J ACCOUNT ECON, V31, P105, DOI 10.1016/S0165-4101(01)00030-1; KROSS W, 1984, J ACCOUNTING RES, V22, P153, DOI 10.2307/2490706; Lanckriet G. R. G., 2002, J MACHINE LEARNING R, V3, P555; Lee Y., 2001, P 1 SIAM INT C DAT M; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; MORSE D, 1981, J ACCOUNTING RES, V19, P374, DOI 10.2307/2490871; Nesterov Y., 1994, INTERIOR POINT POLYN; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; POPESCU I, 2001, TM62 INSEAD; Scholkopf B., 2002, LEARNING KERNELS SUP; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; TRAFALIS TB, 2000, P IEEE INNS ENNS INT, V6, P348; Trueman B, 2003, J ACCOUNT ECON, V34, P249, DOI 10.1016/S0165-4101(02)00092-7; Vapnik V. N, 1995, NATURE STAT LEARNING	38	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2006	30	3					535	542		10.1016/j.eswa.2005.10.008		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	011IG	WOS:000235261000013	
J	Dempster, MAH; Leemans, V				Dempster, MAH; Leemans, V			An automated FX trading system using adaptive reinforcement learning	EXPERT SYSTEMS WITH APPLICATIONS			English	Article							MEAN-RISK MODELS; STOCHASTIC-DOMINANCE	This paper introduces adaptive reinforcement learning (ARL) as the basis for a fully automated trading system application. The system is designed to trade foreign exchange (FX) markets and relies on a layered structure consisting of a machine learning algorithm, a risk management overlay and a dynamic utility optimization layer. An existing machine-learning method called recurrent reinforcement learning (RRL) was chosen as the underlying algorithm for ARL. One of the strengths of our approach is that the dynamic optimization layer makes a fixed choice of model tuning parameters unnecessary. It also allows for a risk-return trade-off to be made by the user within the system. The trading system is able to make consistent gains out-of-sample while avoiding large draw-downs. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Cambridge, Ctr Financial Res, Judge Business Sch, Cambridge CB2 1TN, England; Cambridge Syst Assoc Ltd, Cambridge, England	Dempster, MAH (reprint author), Univ Cambridge, Ctr Financial Res, Judge Business Sch, Cambridge CB2 1TN, England.	mahd2@cam.ac.uk; v1227@cam.ac.uk					Austin M., 2004, QUANTITATIVE FINANCE, V4, P37, DOI DOI 10.1080/14697680400008593; Bates R., 2003, P IEEE INT C COMP IN, P355; Dempster M. A. H., 2001, Quantitative Finance, V1, DOI 10.1088/1469-7688/1/4/301; Dempster MAH, 2001, IEEE T NEURAL NETWOR, V12, P744, DOI 10.1109/72.935088; DEMPSTER MAH, 2002, LECT NOTES COMPUTER, P347; GOLD X, 2003, P IEEE INT C COMP IN, P363; LEEMANS V, 2003, REAL TIME TRADING SY; MOODY J, 1999, 6 INT C COMP FIN 199, P403; Moody J, 2001, IEEE T NEURAL NETWOR, V12, P875, DOI 10.1109/72.935097; Ogryczak W, 2002, SIAM J OPTIMIZ, V13, P60, DOI 10.1137/S1052623400375075; Ogryczak W, 1999, EUR J OPER RES, V116, P33, DOI 10.1016/S0377-2217(98)00167-2; Ruszczynski A, 2003, ECONOMETRICA, V71, P1287, DOI 10.1111/1468-0262.00448; VENTURI S, 2003, THESIS U CAMBRIDGE	13	10	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2006	30	3					543	552		10.1016/j.eswa.2005.10.012		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	011IG	WOS:000235261000014	
J	Dombi, J; Gyorbiro, N				Dombi, J; Gyorbiro, N			Addition of sigmoid-shaped fuzzy intervals using the Dombi operator and infinite sum theorems	FUZZY SETS AND SYSTEMS			English	Article						Zadeh's extension principle; fuzzy intervals; Dombi operator	NORM-BASED ADDITION; NEURAL NETWORKS; T-SUM; NUMBERS; CONVERGENCE; PRODUCT; SETS	The extension principle defines the arithmetic operations on fuzzy intervals. In the extension principle one can use any t-norm, for modeling the conjunction operator. It is therefore important to know, which t-norms are consistent with a particular type of fuzzy intervals. We call a t-norm consistent, if the arithmetic operation is closed. In this paper we investigate the addition of sigmoid and two bell-shaped membership functions which appear in many natural processes and are used in machine learning applications. We prove that the addition is closed if the Dombi operator is used. The calculation of sum is quite simple and can be used in various applications such as fuzzy-neural networks. (C) 2005 Elsevier B.V. All rights reserved.	Univ Szeged, Inst Informat, H-6701 Szeged, Hungary	Dombi, J (reprint author), Univ Szeged, Inst Informat, PF 652, H-6701 Szeged, Hungary.	dombi@inf.u-szeged.hu					BUCKLEY JJ, 1994, FUZZY SET SYST, V66, P1, DOI 10.1016/0165-0114(94)90297-6; Carlsson C., 2002, STUDIES FUZZINESS SO, V82; DOMBI J, 1982, FUZZY SET SYST, V8, P149, DOI 10.1016/0165-0114(82)90005-7; DUBOIS D, 1978, INT J SYST SCI, V9, P613, DOI 10.1080/00207727808941724; Dubois D., 2000, FUNDAMENTALS FUZZY S; Dubois D., 1980, FUZZY SETS SYSTEMS T; FULLER R, 1991, FUZZY SET SYST, V41, P83, DOI 10.1016/0165-0114(91)90158-M; FULLER R, 1991, FUZZY SET SYST, V42, P205, DOI 10.1016/0165-0114(91)90146-H; FULLER R, 1992, FUZZY SET SYST, V51, P155, DOI 10.1016/0165-0114(92)90188-A; GUPTA MM, 1994, FUZZY SET SYST, V61, P1, DOI 10.1016/0165-0114(94)90279-8; Hong DH, 1997, FUZZY SET SYST, V85, P373; HONG DH, 1995, FUZZY SET SYST, V75, P73; HONG DH, 1994, FUZZY SET SYST, V63, P175, DOI 10.1016/0165-0114(94)90347-6; JAIN R, 1976, INT J SYST SCI, V7, P1393, DOI 10.1080/00207727608942013; Mesiar R, 1996, FUZZY SET SYST, V79, P259, DOI 10.1016/0165-0114(95)00178-6; Mizumoto M., 1976, Proceedings of the IEEE International Conference on Cybernetics and Society; Mizumoto M, 1976, SYSTEMS COMPUT CONTR, V7, P73; Nahmias S., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90011-8; NGUYEN HT, 1978, J MATH ANAL APPL, V64, P369, DOI 10.1016/0022-247X(78)90045-8; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; Zurada J. M., 1992, INTRO ARTIFICIAL NEU	23	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	APR 1	2006	157	7					952	963		10.1016/j.fss.2005.09.011		12	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	024RJ	WOS:000236213400008	
J	Danziger, SA; Swamidass, SJ; Zeng, J; Dearth, LR; Lu, Q; Chen, JH; Cheng, JL; Hoang, VP; Saigo, H; Luo, R; Baldi, P; Brachmann, RK; Lathrop, RH				Danziger, SA; Swamidass, SJ; Zeng, J; Dearth, LR; Lu, Q; Chen, JH; Cheng, JL; Hoang, VP; Saigo, H; Luo, R; Baldi, P; Brachmann, RK; Lathrop, RH			Functional census of mutation sequence spaces: The example of p53 cancer rescue mutants	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						biology and genetics; feature extraction or construction; machine learning; medicine and science	CORE DOMAIN; DNA-BINDING; PROTEIN; APOPTOSIS; GENES; TUMOR; CLASSIFICATION; DEFINITION; ACTIVATION; ALGORITHM	Many biomedical problems relate to mutant functional properties across a sequence space of interest, e. g., flu, cancer, and HIV. Detailed knowledge of mutant properties and function improves medical treatment and prevention. A functional census of p53 cancer rescue mutants would aid the search for cancer treatments from p53 mutant rescue. We devised a general methodology for conducting a functional census of a mutation sequence space by choosing informative mutants early. The methodology was tested in a double-blind predictive test on the functional rescue property of 71 novel putative p53 cancer rescue mutants iteratively predicted in sets of three ( 24 iterations). The first double-blind 15-point moving accuracy was 47 percent and the last was 86 percent; r = 0.01 before an epiphanic 16th iteration and r = 0.92 afterward. Useful mutants were chosen early ( overall r = 0.80). Code and data are freely available (http://www.igb.uci.edu/research/research.html, corresponding authors: R. H. L. for computation and R. K. B. for biology).	Univ Calif Irvine, Coll Med, US Natl Inst Hlth Funded Med Sci Training Program, Irvine, CA 92697 USA; SUNY Stony Brook, Stony Brook, NY 11794 USA; Kyoto Univ, Inst Chem Res, Bioinformat Ctr, Uji, Kyoto 6110011, Japan; Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA; Univ Calif Irvine, Dept Biol Chem, Irvine, CA 92697 USA; Univ Calif Irvine, Inst Genom & Bioinformat, Irvine, CA 92697 USA; Univ Calif Irvine, Bren Sch Informat & Comp Sci, Irvine, CA 92697 USA	Danziger, SA (reprint author), Univ Calif Irvine, Coll Med, US Natl Inst Hlth Funded Med Sci Training Program, Irvine, CA 92697 USA.	sdanzige@uci.edu; sswamida@uci.edu; jzeng@uci.edu; ldearth@uci.edu; Qiang.Lu@stonybrook.edu; chenjh@uci.edu; jianlinc@uci.edu; vphoang@uci.edu; hiroto@kuicr.kyoto-u.ac.jp; rluo@uci.edu; pfbaldi@uci.edu; rbrachma@uci.edu; rickl@uci.edu	Luo, Ray/I-6928-2012				Appella E, 2001, EUR J BIOCHEM, V268, P2764, DOI 10.1046/j.1432-1327.2001.02225.x; Baroni TE, 2004, P NATL ACAD SCI USA, V101, P4930, DOI 10.1073/pnas.0401162101; Beerenwinkel N, 2001, IEEE INTELL SYST, V16, P35, DOI 10.1109/5254.972080; Beroud C, 2003, HUM MUTAT, V21, P176, DOI 10.1002/humu.10187; Brachmann RK, 1998, EMBO J, V17, P1847, DOI 10.1093/emboj/17.7.1847; Brooks CL, 2003, CURR OPIN CELL BIOL, V15, P164, DOI 10.1016/S0955-0674(03)00003-6; Bullock AN, 1997, P NATL ACAD SCI USA, V94, P14338, DOI 10.1073/pnas.94.26.14338; Bullock AN, 2000, ONCOGENE, V19, P1245, DOI 10.1038/sj.onc.1203434; Bullock AN, 2001, NAT REV CANCER, V1, P68, DOI 10.1038/35094077; Bush RM, 1999, SCIENCE, V286, P1921, DOI 10.1126/science.286.5446.1921; Bykov VJN, 2002, NAT MED, V8, P282, DOI 10.1038/nm0302-282; CAELLES C, 1994, NATURE, V370, P220, DOI 10.1038/370220a0; Canutescu AA, 2003, PROTEIN SCI, V12, P2001, DOI 10.1110/ps.03154503; Case D. A., 2004, AMBER 8; CHENG J, 2005, PROTEINS STRUCTURE F; CHO YJ, 1994, SCIENCE, V265, P346, DOI 10.1126/science.8023157; ELDEIRY WS, 1992, NAT GENET, V1, P45, DOI 10.1038/ng0492-45; Foster BA, 1999, SCIENCE, V286, P2507, DOI 10.1126/science.286.5449.2507; FUNK WD, 1992, MOL CELL BIOL, V12, P2866; Kannan K, 2001, ONCOGENE, V20, P2225, DOI 10.1038/sj.onc.1204319; Karchin R, 2005, BIOINFORMATICS, V21, P2814, DOI 10.1093/bioinformatics/bti442; Lathrop RH, 1999, J COMB OPTIM, V3, P301, DOI 10.1023/A:1009846028730; Lathrop RH, 1999, AI MAG, V20, P13; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Levine AJ, 1997, CELL, V88, P323, DOI 10.1016/S0092-8674(00)81871-1; Liu Y, 2004, J CHEM INF COMP SCI, V44, P1936, DOI 10.1021/ci049810a; Luo R, 2002, J COMPUT CHEM, V23, P1244, DOI 10.1002/jcc.10120; Manfredi JJ, 2003, MOL CELL, V11, P552, DOI 10.1016/S1097-2765(03)00106-0; Martin ACR, 2002, HUM MUTAT, V19, P149, DOI 10.1002/humu.10032; May P, 1999, ONCOGENE, V18, P7621, DOI 10.1038/sj.onc.1203285; Mihara M, 2003, MOL CELL, V11, P577, DOI 10.1016/S1097-2765(03)00050-9; Mitra P, 2004, IEEE T PATTERN ANAL, V26, P413, DOI 10.1109/TPAMI.2004.1262340; Olivier M, 2002, HUM MUTAT, V19, P607, DOI 10.1002/humu.10081; Polyak K, 1997, NATURE, V389, P300, DOI 10.1038/38525; PRESS WH, 1992, NUMERICAL RECIPES AR; Prives C, 1999, J PATHOL, V187, P112; Qian H, 2002, ONCOGENE, V21, P7901, DOI 10.1038/sj.onc.1205974; Rubin Daniel L, 2002, Bioinformatics, V18 Suppl 1, pS207; RYCKAERT JP, 1977, J COMPUT PHYS, V23, P327, DOI 10.1016/0021-9991(77)90098-5; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; SCHLKOPF B, 2004, KERNEL METHODS COMPU; Tsui V, 2001, BIOPOLYMERS, V56, P275; Vogelstein B, 2000, NATURE, V408, P307, DOI 10.1038/35042675; Vousden KH, 2000, CELL, V103, P691, DOI 10.1016/S0092-8674(00)00171-9; Wahl G.M., 2001, NATURE CELL BIOL, V3, P277; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Witten I. H., 2005, DATA MINING PRACTICA; Wong KB, 1999, P NATL ACAD SCI USA, V96, P8438, DOI 10.1073/pnas.96.15.8438; Xu Yang, 2003, Cell Death and Differentiation, V10, P400, DOI 10.1038/sj.cdd.4401182	49	7	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963		IEEE-ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	APR-JUN	2006	3	2					114	125		10.1109/TCBB.2006.22		12	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	038WO	WOS:000237260400002	
J	Kwon, H; Nasrabadi, NM				Kwon, H; Nasrabadi, NM			Kernel adaptive subspace detector for hyperspectral imagery	IEEE GEOSCIENCE AND REMOTE SENSING LETTERS			English	Article						kernel-based machine learning; kernel subspace; subspace detectors; subspace matched filters; target detection	SUPPORT VECTOR MACHINES	In this letter, we present a kernel-based nonlinear version of the adaptive subspace detector (ASD) that implicitly detects signals of interest in a high-dimensional (possibly infinite) feature space associated with a particular nonlinear mapping. In order to address the high dimensionality of the feature space, ASD is first implicitly formulated in the feature space, which is then converted into an expression in terms of kernel functions via the kernel trick property of the Mercer kernels. Experimental results based on simulated data and real hyperspectral imagery show that the proposed kernel-based ASD outperforms the conventional ASD and a nonlinear anomaly detector so called the kernel RX-algorithm.	USA, Res Lab, Adelphi, MD 20783 USA	Kwon, H (reprint author), USA, Res Lab, Adelphi, MD 20783 USA.	hkwon@arl.army.mil; nnasraba@arl.army.mil					Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Brown M, 2000, IEEE T GEOSCI REMOTE, V38, P2346, DOI 10.1109/36.868891; Chen W., 1991, DIGIT SIGNAL PROCESS, V1, P198, DOI 10.1016/1051-2004(91)90113-Y; CONTE E, 1995, IEEE T AERO ELEC SYS, V31, P617, DOI 10.1109/7.381910; Johnson S, 2002, IEEE T GEOSCI REMOTE, V40, P1326, DOI 10.1109/TGRS.2002.800434; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Kraut S, 1999, IEEE T SIGNAL PROCES, V47, P2538, DOI 10.1109/78.782198; Kraut S, 2001, IEEE T SIGNAL PROCES, V49, P1, DOI 10.1109/78.890324; Kwon H, 2005, IEEE T GEOSCI REMOTE, V43, P388, DOI 10.1109/TGRS.2004.841487; Maeda E., 2002, Systems and Computers in Japan, V33, DOI 10.1002/scj.1098; Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; ROBERTS DJ, 1992, DRUGS TODAY SB, V28, P1; Ruiz A, 2001, IEEE T NEURAL NETWOR, V12, P16, DOI 10.1109/72.896793; Scharf L. L., 1991, STAT SIGNAL PROCESSI; SCHARF LL, 1994, IEEE T SIGNAL PROCES, V42, P2146, DOI 10.1109/78.301849; SCHOKOPF B, 1999, NEURAL COMPUT, P1299; Scholkopf B., 2002, LEARNING KERNELS; STRANG G, 1986, LINEAR ALGEBRA ITS A; Vapnik V.N., 1999, NATURE STAT LEARNING	20	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1545-598X		IEEE GEOSCI REMOTE S	IEEE Geosci. Remote Sens. Lett.	APR	2006	3	2					271	275		10.1109/LGRS.2006.869985		5	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	038HO	WOS:000237210200019	
J	Li, JY				Li, JY			On optimal rule discovery	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; rule discovery; optimal rule set	DATABASES	In machine learning and data mining, heuristic and association rules are two dominant schemes for rule discovery. Heuristic rule discovery usually produces a small set of accurate rules, but fails to find many globally optimal rules. Association rule discovery generates all rules satisfying some constraints, but yields too many rules and is infeasible when the minimum support is small. Here, we present a unified framework for the discovery of a family of optimal rule sets and characterize the relationships with other rule-discovery schemes such as nonredundant association rule discovery. We theoretically and empirically show that optimal rule discovery is significantly more efficient than association rule discovery independent of data structure and implementation. Optimal rule discovery is an efficient alternative to association rule discovery, especially when the minimum support is low.	Univ So Queensland, Dept Math & Comp, Toowoomba, Qld 4350, Australia	Li, JY (reprint author), Univ So Queensland, Dept Math & Comp, Toowoomba, Qld 4350, Australia.	jiuyong@usq.edu.au	Li, Jiuyong/A-8134-2008				Agrawal R., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Bayardo RJ, 2000, DATA MIN KNOWL DISC, V4, P217; BLAKE EKC, UCI REPOSITORY MACHI; Brin S, 1997, P ACM SIGMOD INT C M, V26, P255; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; Fukuda T., 1996, P 1996 ACM SIGMOD IN, P13, DOI 10.1145/233269.233313; Hu H., 2005, P 16 AUSTR DAT C, P47; Li JY, 2002, KNOWL-BASED SYST, V15, P399, DOI 10.1016/S0950-7051(02)00024-2; Liu B., 1998, P 4 INT C KNOWL DISC, P27; Omiecinski ER, 2003, IEEE T KNOWL DATA EN, V15, P57, DOI 10.1109/TKDE.2003.1161582; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Tan PN, 2004, INFORM SYST, V29, P293, DOI 10.1016/S0306-4379(03)00072-3; Webb GI, 2005, DATA MIN KNOWL DISC, V10, P39, DOI 10.1007/s10618-005-0255-4; Webb GI, 1995, J ARTIF INTELL RES, V3, P431; Zaki M. J., 2002, P SIAM INT C DAT MIN; Zaki MJ, 2004, DATA MIN KNOWL DISC, V9, P223, DOI 10.1023/B:DAMI.0000040429.96086.c7	20	29	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2006	18	4					460	471		10.1109/LPT.2005.860398		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	012WO	WOS:000235371800003	
J	Duan, LY; Jin, JS; Tian, Q; Xu, CS				Duan, LY; Jin, JS; Tian, Q; Xu, CS			Nonparametric motion characterization for robust classification of camera motion patterns	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						camera motion; nonparametric motion analysis; video databases; video indexing	SCENE CHANGE DETECTION; VIDEO ANNOTATION; MEAN SHIFT; RETRIEVAL; DATABASES; MODELS	Motion characterization plays a critical role in video indexing. An effective way of characterizing camera motion facilitates the video representation, indexing and retrieval tasks. This paper describes a novel nonparametric motion representation to achieve an effective and robust recognition of parts of the video in which camera is static, or panning, or tilting, or zooming, etc. This representation employs the mean shift filtering and the vector histograms to produce a compact description of a motion field. The basic idea is to perform spatio-temporal mode-seeking in the motion feature space and use the histograms-based spatial distributions of dominant motion modes to represent a motion field. Unlike most existing approaches, which focus on the estimation of a parametric motion model from a dense optical flow field (OFF) or a block matching-based motion vector field (MVF), the proposed method combines the motion representation and machine learning techniques (e.g., support vector machines) to perform camera motion analysis from the classification point of view. The main motivation lies in the impossibility of uniformly securing a proper parametric assumption in a wide range of video scenarios. The diverse camera shot sizes and frequent occurrences of bad OFF[MVF necessitates a learning mechanism, which can not only capture the domain-independent parametric constraints, but also acquire the domain-dependent knowledge to tolerate the influence of bad OFF/MVF. In order to improve performance, we can use this learning-based method to train enhanced classifiers aiming at a certain context (i.e., shot size, neighbor OFF/MVFs, and video genre). Other visual cues (e.g., dominant color) can also be incorporated for further motion analysis. Our main aim is to use a generic feature space analysis method to explore a flexible OFF/MVF representation in a nonparametric technique, which could be fed into a learning framework to robustly capture the global motion by incorporating the context information. Results on videos with various types of content (23 191 MVFs culled from MPEG-7 dataset, and 20 000 MVFs culled from broadcast tennis, soccer, and basketball videos) are reported to validate the proposed approach.	Inst Infocomm Res, Singapore 119613, Singapore; Univ Newcastle, Sch Design Commun & Informat Technol, Callaghan, NSW 2308, Australia	Duan, LY (reprint author), Inst Infocomm Res, Singapore 119613, Singapore.	lingyu@i2r.a-star.edu.sg; Jesse.Jin@newcastle.edu.au; tian@i2r.a-star.edu.sg; xucs@i2r.a-star.edu.sg					Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057; CAELLI T, 1997, MACHINE LEARNING IMA, P189; Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DeMenthon D., 2003, P 11 ACM INT C MULT, P508; DIVARANRAN A, 2000, MPEG99M5030 ISOICE; Duan L, 2003, P 11 ACM INT C MULT, P33; DUAN LY, 2004, P ACM MULT NEW YORK, P754, DOI 10.1145/1027527.1027700; Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395; DUAN LY, 2004, P ACM MULTIMEDIA NEW, P328, DOI 10.1145/1027527.1027603; DUAN LY, 2004, P INT C IM PROC SING, P1597; DUAN LY, 2003, P ACM MULT BERK CA N, P243; DURIC Z, 1995, CARTR778 U MAR; Fablet R, 2002, IEEE T IMAGE PROCESS, V11, P393, DOI 10.1109/TIP.2002.999674; FLICKNER M, 1995, IEEE COMPUT, V28, P9; HAMRAPUR A, 1997, P SOC PHOTO-OPT INS, P188; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279; Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139; Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428; Jin J. S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, DOI 10.1109/6979.869019; KEE KW, 1999, MPEG99M5400 ISOICE; KIM JG, 2000, P 2000 IEEE INT C MU, P1171; Kobla V, 2000, P SOC PHOTO-OPT INS, V3972, P332; LEE S, 2002, P ICASSP, P3664; Ma Y.F., 2002, P 10 ACM INT C MULT, P533; MA YF, 2003, EURASIP J APPL SIG P, P199; MAPHADE M, IBM TRECVID CONCEPT; Mojsilovic A, 2002, IEEE T IMAGE PROCESS, V11, P1238, DOI 10.1109/TIP.2002.804260; Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597; Ngo C. W., 2001, P ACM MULT OTT ON CA, P51; Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699; Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8; PEKER KA, J VIS COMMUN IMAGE R, V14, P2003; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; ROWE LA, ACM SIGMM RETREAT RE; Rubner Y., 1998, P IEEE INT C COMP VI, P59; Silverman B.W., 1986, DENSITY ESTIMATION S; Sudhir G, 1996, J VIS COMMUN IMAGE R, V7, P354, DOI 10.1006/jvci.1996.0031; Szummer M., 1996, Proceedings. International Conference on Image Processing (Cat. No.96CH35919), DOI 10.1109/ICIP.1996.560871; Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133; Vapnik V. N, 1995, NATURE STAT LEARNING; WACTLAR HD, 1996, IEEE COMPUT, V29, P46; Wang R., 2000, P ISCAS, P21; Wolf W, 1996, P IEEE INT C AC SPEE, V2, P1228; Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005; Xiong W, 1998, COMPUT VIS IMAGE UND, V71, P166, DOI 10.1006/cviu.1998.0711; YAO YS, 1995, CARTR790 U MAR; Yu X., 2003, P 11 ACM INT C MULT, P11; Zhang HJ, 1995, P ACM MULT 95 SAN FR, P15, DOI 10.1145/217279.215068; *I INF RES, 12R I INF RES	53	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1520-9210		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	APR	2006	8	2					323	340		10.1109/TMM.2005.864344		18	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	028GY	WOS:000236476300013	
J	Lebanon, G				Lebanon, G			Metric learning for text documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						distance learning; text analysis; machine learning		Many algorithms in machine learning rely on being given a good distance metric over the input space. Rather than using a default metric such as the Euclidean metric, it is desirable to obtain a metric based on the provided data. We consider the problem of learning a Riemannian metric associated with a given differentiable manifold and a set of points. Our approach to the problem involves choosing a metric from a parametric family that is based on maximizing the inverse volume of a given data set of points. From a statistical perspective, it is related to maximum likelihood under a model that assigns probabilities inversely proportional to the Riemannian volume element. We discuss in detail learning a metric on the multinomial simplex where the metric candidates are pull-back metrics of the Fisher information under a Lie group of transformations. When applied to text document classification the resulting geodesic distance resemble, but outperform, the tfidf cosine similarity measure.	Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA	Lebanon, G (reprint author), Purdue Univ, Dept Stat, 150 N Univ St, W Lafayette, IN 47907 USA.	lebanon@stat.purdue.edu					Amari S., 2000, METHODS INFORM GEOME; GOUS A, 1998, EXPONENTIAL SPHERICA; HALL K, 2000, P 17 INT C MACH LEAR, P351; JOACHIMS T, 2000, THESIS DORTMUND U; Kass R., 1997, GEOMETRICAL FDN ASYM; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; LEBANON G, 2005, CMULTI05189; Lee J. M., 2002, INTRO SMOOTH MANIFOL; Lee JM, 2000, INTRO TOPOLOGICAL MA; Murray M.K., 1993, DIFFERENTIAL GEOMETR; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAUL LK, 1997, ADV NEURAL INFORM PR, V9; Xing E. P., 2002, ADV NEURAL INFORMATI, V15, P505	13	20	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					497	508		10.1109/TPAMI.2006.77		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	011FK	WOS:000235253300001	
J	Buczak, AL; Cooper, DG; Hofmann, MO				Buczak, AL; Cooper, DG; Hofmann, MO			Evolutionary agent learning	INTERNATIONAL JOURNAL OF GENERAL SYSTEMS			English	Article						intelligent software agents; machine learning; genetic programming; agent learning; complex systems		Evolutionary Platform for Agent Learning (EPAL) is a novel methodology for agent learning, based on an extension to genetic programming that Lockheed Martin Advanced Technology Laboratories (LM ATL) developed. EPAL allows software agents to learn how to better operate under external conditions, so they do not repeat their mistakes. It creates both subtle and drastic changes to agent behavior. Subtle changes arise from learning task parameters; drastic changes emerge from learning improved workflows containing new programming constructs and tasks. Although EPAL was constructed for learning by LM ATL developed extendible mobile agent architecture agents. it is a suitable learning methodology for any software agent whose behavior can be represented as a workflow and further decomposed into building blocks, such as operators, tasks, and parameters. Our agents learned to solve a real-world problem that is similar to problems encountered in Navy Fleet Battle Experiment-Juliet. Results for both parameter learning and workflow learning are very encouraging.	Sarnoff Corp, Princeton, NJ 08543 USA; Lockheed Martin Adv Technol Labs, Cherry Hill, NJ 08002 USA	Buczak, AL (reprint author), Sarnoff Corp, 201 Washington Rd, Princeton, NJ 08543 USA.	abuczak@samoff.com					BIGUS JP, 2002, IBM SYST J, V41; BUCZAK AL, 2003, EVOLUTIONARY PLATFOR, V13, P201; BUCZAK AL, 2001, P C EV COMP SEOUL KO; BUCZAK AL, 2004, ADV EVOLUTIONARY AGE, V14, P157; FOGARTY TC, 1989, P INT C GEN ALG, P105; GALLUP S, 2003, A279514; HOFMANN MO, 2001, P 2001 NAT FIR CONTR; Hofmann M. O., 1998, Proceedings of the Second International Conference on Autonomous Agents, DOI 10.1145/280765.280805; Koza J., 1994, GENETIC PROGRAMMING; Koza J. R., 1992, GENETIC PROGRAMMING; Montana DJ, 1995, EVOL COMPUT, V3, P199, DOI 10.1162/evco.1995.3.2.199; RAMAMURTHY U, 1998, P 2 AS PAC C SIM EV; SHAW K, 2002, FAST FORWARD FUTURE; SIMON HA, 1989, MODELS THOUGHT, V2, P99; Spears WM., 1995, P 4 ANN C EV PROGR, P367; SRINVAS M, 1994, IEEE T SMC, V4, P656; Stone P., 1998, THESIS CARNEGIE MELL; Sun R, 2001, COGNITIVE SCI, V25, P203, DOI 10.1016/S0364-0213(01)00035-0; Sutton R. S., 1990, P 7 INT C MACH LEARN, P216; WAGMAN M, 1991, COGNITIVE SCI CONCEP; *JSAF, 2000, JOINT SEM FORC	21	1	1	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0308-1079		INT J GEN SYST	Int. J. Gen. Syst.	APR	2006	35	2					231	254		10.1080/03081070500422653		24	Computer Science, Theory & Methods; Ergonomics	Computer Science; Engineering	043TC	WOS:000237623500005	
J	Lappas, G; Frank, RJ; Albrecht, AA				Lappas, G; Frank, RJ; Albrecht, AA			A computational study on circuit size versus circuit depth	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						machine learning; circuit complexity; simulated annealing	MULTILAYER NETWORKS; THRESHOLD FUNCTIONS; NEURAL-NETWORKS; ALGORITHM; DIAGNOSIS; RULES	We investigate the circuit complexity of classification problems in a machine learning setting, i.e. we attempt to find some rule that allows us to calculate a priori the number of threshold gates that is sufficient to achieve a small error rate after training a circuit on sample data S-L. The particular threshold gates are computed by a combination of the classical perceptron algorithm with a specific type of stochastic local search. The circuit complexity is analysed for depth-two and depth-four threshold circuits, where we introduce a novel approach to compute depth-four circuits. For the problems from the UCI Machine Learning Repository we selected and investigated, we obtain approximately the same size of depth-two and depth-four circuits for the best classification rates on test samples, where the rates differ only marginally for the two types of circuits. Based on classical results from threshold circuit theory and our experimental observations on problems that are not linearly separable, we suggest an upper bound of 8. root 2(n)/n threshold gates as sufficient for a small error rate, where n := log vertical bar S-L vertical bar.	TEI Western Macedonia, Kastoria 52100, Greece; Univ Hertfordshire, Sch Comp Sci, Hatfield AL10 9AB, Herts, England	Lappas, G (reprint author), TEI Western Macedonia, POB 30, Kastoria 52100, Greece.	lappas@kastoria.teikoz.gr; R.J.Frank@herts.ac.uk; A.Albrecht@herts.ac.uk					AARTS E, 1998, LOCAL SEARCH COMBINA; AGMON S, 1954, CAN J MATH, V6, P382, DOI 10.4153/CJM-1954-037-2; ALBRECHT A, 2002, P 9 INT C NEUR INF P, P184, DOI DOI 10.1109/ICONIP.2002.1202156; Albrecht A, 2001, NEURAL PROCESS LETT, V14, P75, DOI 10.1023/A:1011369322571; Albrecht AA, 2004, LECT NOTES COMPUT SC, V3102, P642; ALLENDER E, 1996, LECT NOTES COMPUTER, V1090, P127; Anastasladis AD, 2005, NEUROCOMPUTING, V64, P253, DOI 10.1016/j.neucom.2004.11.016; ANTHONY M, 2003, LSECDAM200301; BARTLETT PL, 1992, IEEE T NEURAL NETWOR, V3, P202; BAUM EB, 1990, NEURAL COMPUT, V2, P248, DOI 10.1162/neco.1990.2.2.248; Blum A, 1998, ALGORITHMICA, V22, P35, DOI 10.1007/PL00013833; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; Boutsinas B, 2001, ARTIF INTELL, V132, P1, DOI 10.1016/S0004-3702(01)00126-6; BYLANDER T, 1995, NEURAL COMPUT, V7, P370, DOI 10.1162/neco.1995.7.2.370; Caussinus H, 1998, J COMPUT SYST SCI, V57, P200, DOI 10.1006/jcss.1998.1588; CERNY V, 1985, J OPTIMIZ THEORY APP, V45, P41, DOI 10.1007/BF00940812; CORWIN EM, 1994, IEEE T NEURAL NETWOR, V5, P507, DOI 10.1109/72.286926; Cristianini N., 2000, INTRO SUPPORT VECTOR; Gallant S I, 1990, IEEE Trans Neural Netw, V1, P179, DOI 10.1109/72.80230; GOODMAN R, 1994, P IEEE NEUR NETW SIG, P219, DOI 10.1109/NNSP.1994.366045; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HAJEK B, 1988, MATH OPER RES, V13, P311, DOI 10.1287/moor.13.2.311; HAMPSON SE, 1990, IEEE T SYST MAN CYB, V20, P67, DOI 10.1109/21.47810; Hoffgen K.-U., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130431; HOFFGEN KU, 1992, P 2 INT C ART NEUR N, P109; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Lupanov O. B., 1965, PROBL KIBERN, V14, P31; LUPANOV OB, 1973, PROBL KIBERN, V20, P109; Maass W., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167193; MAASS W, 1994, P COMP LEARN THEOR E, P1; MAASS W, 2005, P ADV NEUR INF PROC; MAGOULAS GD, 1997, KLUWER ACAD PUBLISHE, pCH41; Minsky M, 1969, PERCEPTRONS; Mitchell T, 1997, MACHINE LEARNING; Pena-Reyes CA, 2001, IEEE T FUZZY SYST, V9, P727, DOI 10.1109/91.963759; PLAGIANAKOS VP, 2001, P INNS IEEE INT JOIN, P2805; Plagianakos V. P., 2002, Natural Computing, V1, DOI 10.1023/A:1016545907026; Rampone S, 1998, BIOINFORMATICS, V14, P676, DOI 10.1093/bioinformatics/14.8.676; RAZBOROV A, 1993, INFORM PROCESS LETT, V45, P303, DOI 10.1016/0020-0190(93)90041-7; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Setiono R, 2000, IEEE T NEURAL NETWOR, V11, P512, DOI 10.1109/72.839020; Setiono R, 2000, ARTIF INTELL MED, V18, P205, DOI 10.1016/S0933-3657(99)00041-X; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; SIU KY, 1995, PRENTICE HALL INFORM; Temple G, 1939, PROC R SOC LON SER-A, V169, P476, DOI 10.1098/rspa.1939.0012; TOM DJ, 1990, ELECTRON LETT, V26, P1745; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Vapnik VN, 1998, STAT LEARNING THEORY; VOLLMER H, 1999, THESIS U WURZBURG; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893	51	6	6	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	APR	2006	15	2					143	161		10.1142/S0218213006002606		19	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	031AM	WOS:000236676500002	
J	Shin, HJ; Markey, MK				Shin, HJ; Markey, MK			A machine learning perspective on the development of clinical decision support systems utilizing mass spectra of blood samples	JOURNAL OF BIOMEDICAL INFORMATICS			English	Review						diagnosis; computer-assisted; spectrum analysis; mass spectrometry; neoplasms; blood; artificial intelligence; signal processing; automatic data processing; pattern recognition; classification	LASER-DESORPTION/IONIZATION-TIME; PROTEOMIC PATTERN DIAGNOSTICS; PROSTATE-SPECIFIC ANTIGEN; OVARIAN-CANCER DETECTION; SERUM-PROTEIN PROFILES; SERVICES TASK-FORCE; CELL LUNG-CANCER; COLORECTAL-CANCER; BREAST-CANCER; PANCREATIC-CANCER	Currently, the best way to reduce the mortality of cancer is to detect and treat it in the earliest stages. Technological advances in genomics and proteomics have opened a new realm of methods for early detection that show potential to overcome the drawbacks of Current strategies. In particular, pattern analysis of mass spectra of blood samples has attracted attention as an approach to early detection of cancer. Mass spectrometry provides rapid and precise measurements of the sizes and relative abundances of the proteins present in a complex biological/chemical mixture. This article presents a review of the development of clinical decision support systems using mass spectrometry from a machine learning perspective. The literature is reviewed in an explicit machine learning framework, the components of which are preprocessing, feature extraction, feature selection, classifier training, and evaluation. (c) 2005 Elsevier Inc. All rights reserved.	Univ Texas, Dept Biomed Engn, Austin, TX 78712 USA; Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA	Markey, MK (reprint author), Univ Texas, Dept Biomed Engn, Austin, TX 78712 USA.	mia.markey@mail.utexas.edu					Abbott A, 1999, NATURE, V402, P715, DOI 10.1038/45350; Adam BL, 2002, CANCER RES, V62, P3609; Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Aebersold R, 2001, CHEM REV, V101, P269, DOI 10.1021/cr990076h; Alexe G, 2004, PROTEOMICS, V4, P766, DOI 10.1002/pmic.200300574; American Cancer Society, 2004, CANC FACTS FIG 2004; ANDERLE M, 2004, BIOINFORMATICS, V446; Anderson NL, 2002, MOL CELL PROTEOMICS, V1, P845, DOI 10.1074/mcp.R200007-MCP200; Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; Baggerly KA, 2005, J NATL CANCER I, V97, P307, DOI 10.1093/jnci/dji008; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Barclay VJ, 1997, ANAL CHEM, V69, P78, DOI 10.1021/ac960638m; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Becker S, 2004, ANN SURG ONCOL, V11, P907, DOI 10.1245/ASO.2004.03.557; Bhattacharyya S, 2004, NEOPLASIA, V6, P674, DOI 10.1593/neo.04262; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Boguski MS, 2003, NATURE, V422, P233, DOI 10.1038/nature01515; Brawer MK, 1999, CA-CANCER J CLIN, V49, P264, DOI 10.3322/canjclin.49.5.264; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRODLEY CE, 1996, 13 NAT C ART INT POR, P799; Campa MJ, 2003, CANCER RES, V63, P1652; Cazares LH, 2002, CLIN CANCER RES, V8, P2541; Conrods TP, 2003, EXPERT REV MOL DIAGN, V3, P411, DOI 10.1586/14737159.3.4.411; Conrads TP, 2004, ENDOCR-RELAT CANCER, V11, P163, DOI 10.1677/erc.0.0110163; COOMBES KR, 2004, IMPROVED PEAK DETECT; Coombes KR, 2003, CLIN CHEM, V49, P1615, DOI 10.1373/49.10.1615; Cristianini N., 2000, INTRO SUPPORT VECTOR; CRISTIANINI N, 2002, AI MAGAZINE; DASH M, 1997, INTELL DATA ANAL, V1; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Diamandis EP, 2003, CLIN CHEM, V49, P1272, DOI 10.1373/49.8.1272; Diamandis EP, 2005, CLIN CANCER RES, V11, P963; Diamandis EP, 2004, MOL CELL PROTEOMICS, V3, P367, DOI 10.1074/mcp.R400007-MCP200; Dodd LE, 2004, ACAD RADIOL, V11, P462, DOI 10.1016/S1076-6332(03)00814-6; Duda R., 2000, PATTERN CLASSIFICATI; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1991, SCIENCE, V253; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; ETZIONI R, 2003, NAT REV, V3; FAHEY MT, 1995, AM J EPIDEMIOL, V141, P680; Feng Z, 2004, PHARMACOGENOMICS, V5, P709, DOI 10.1517/14622416.5.6.709; Fukunaga K., 1990, INTRO STAT PATTERN R; FUNG ET, 2002, BIOTECHNIQUES S; Gamberger D., 1999, INT C MACH LEARN ICM, P143; Green BB, 2003, J AM BOARD FAM PRACT, V16, P233; Grizzle WE, 2004, CLIN CHEM, V50, P1475, DOI 10.1373/clinchem.2004.033456; Grizzle WE, 2003, DIS MARKERS, V19, P185; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Gygi SP, 2000, CURR OPIN CHEM BIOL, V4, P489, DOI 10.1016/S1367-5931(00)00121-6; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Han J., 2001, DATA MINING CONCEPTS; Hastie T., 2002, ELEMENTS STAT LEARNI; Hilario M, 2003, PROTEOMICS, V3, P1716, DOI 10.1002/pmic.200300523; Hu Jianhua, 2005, Briefings in Functional Genomics & Proteomics, V3, P322, DOI 10.1093/bfgp/3.4.322; Humphrey LL, 2002, ANN INTERN MED, V137, P347; HUTCHENS TW, 1993, RAPID COMMUN MASS SP, V7, P576, DOI 10.1002/rcm.1290070703; Issaq HJ, 2002, BIOCHEM BIOPH RES CO, V292, P587, DOI 10.1006/bbrc.2002.6678; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JAPKOWICZ N, 2000, WS0005 MENL PARK; Jeffries NO, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-180; Jemal A, 2004, CA-CANCER J CLIN, V54, P8; Johann DJ, 2003, DIS MARKERS, V19, P197; Keller BO, 2000, J AM SOC MASS SPECTR, V11, P88, DOI 10.1016/S1044-0305(99)00126-9; KNUTZEN AM, 1993, MAYO CLIN PROC, V68, P454; Koomen JM, 2005, CLIN CANCER RES, V11, P1110; Koomen JM, 2004, RAPID COMMUN MASS SP, V18, P2537, DOI 10.1002/rcm.1657; Koopmann J, 2004, CLIN CANCER RES, V10, P860, DOI 10.1158/1078-0432.CCR-1167-3; KOPANS DB, 1992, AM J ROENTGENOL, V158, P521; Kotsiantis S, 2003, ANN MATH COMPUT TELE, V1, P46; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; Krieg RC, 2002, TECHNOL CANCER RES T, V1, P263; Krutchinsky AN, 2002, J AM SOC MASS SPECTR, V13, P129, DOI 10.1016/S1044-0305(01)00336-1; Kuerer HM, 2004, SURGERY, V136, P1061, DOI 10.1016/j.surg.2004.04.011; Lancashire Lee J., 2005, Current Proteomics, V2, P15, DOI 10.2174/1570164053507808; Lee CH, 2002, RADIOL CLIN N AM, V40, P395, DOI 10.1016/S0033-8389(01)00015-X; Lee KR, 2003, PROTEOMICS, V3, P1680, DOI 10.1002/pmic.200300515; Li J., 2003, BIOINFORMATICS S2, V19, pii93; Li JN, 2004, J UROLOGY, V171, P1782, DOI 10.1097/01.ju.0000119823.86393.49; Li JN, 2002, CLIN CHEM, V48, P1296; Li LH, 2004, ARTIF INTELL MED, V32, P71, DOI 10.1016/j.artmed.2004.03.006; Lilien RH, 2003, J COMPUT BIOL, V10, P925, DOI 10.1089/106652703322756159; Liotta LA, 2003, NATURE, V425, P905, DOI 10.1038/425905a; Liotta LA, 2005, J NATL CANCER I, V97, P310, DOI 10.1093/jnci/dji053; LIU Q, 2003, ASILOMAR C BIOL ASP; Madi A, 2003, ACTA BIOL HUNG, V54, P1, DOI 10.1556/ABiol.54.2003.1.1; MALETIC JI, 2000, INFORM QUALITY IQ200, P200; MALOOF MA, 2003, LEARNING DATA SETS A; Malyarenko DI, 2005, CLIN CHEM, V51, P65, DOI 10.1373/clinchem.2004.037283; Mann M, 2001, ANNU REV BIOCHEM, V70, P437, DOI 10.1146/annurev.biochem.70.1.437; Markey MK, 2003, PROTEOMICS, V3, P1678, DOI 10.1002/pmic.200300521; Mehta AI, 2003, DIS MARKERS, V19, P1; Merchant M, 2000, ELECTROPHORESIS, V21, P1164, DOI 10.1002/(SICI)1522-2683(20000401)21:6<1164::AID-ELPS1164>3.3.CO;2-S; METZ CE, 1986, INVEST RADIOL, V21, P720; MITCHELL TM, 1997, MACNINE LEARING; Neville P, 2003, PROTEOMICS, V3, P1710, DOI 10.1002/pmic.200300516; Ornstein DK, 2004, J UROLOGY, V172, P1302, DOI 10.1097/01.ju.0000139572.88463.39; Orr K, 1998, COMMUN ACM, V41, P66, DOI 10.1145/269012.269023; ORR K, 1998, DATA QUALITY SYSTEMS, P66; Peek ME, 2004, J GEN INTERN MED, V19, P184; Petricoin EF, 2004, PROTEOMICS, V4, P2357, DOI 10.1002/pmic.200400865; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, J MAMMARY GLAND BIOL, V7, P433, DOI 10.1023/A:1024042200521; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pignone M, 2002, ANN INTERN MED, V137, P132; Pontil M, 1998, NEURAL COMPUT, V10, P955, DOI 10.1162/089976698300017575; Poon TCW, 2003, CLIN CHEM, V49, P752, DOI 10.1373/49.5.752; Prados J, 2004, PROTEOMICS, V4, P2320, DOI 10.1002/pmic.200400857; Preparata F., 1985, COMPUTATIONAL GEOMET; Purohit PV, 2003, PROTEOMICS, V3, P1699, DOI 10.1002/pmic.200300518; Pusch W, 2003, PHARMACOGENOMICS, V4, P463, DOI 10.1517/phgs.4.4.463.22753; Qu YS, 2003, BIOMETRICS, V59, P143, DOI 10.1111/1541-0420.00017; Qu YS, 2002, CLIN CHEM, V48, P1835; Rai AJ, 2004, ANN NY ACAD SCI, V1022, P286, DOI 10.1196/annals.1318.044; Redman TC, 1998, COMMUN ACM, V41, P79, DOI 10.1145/269012.269025; Rennert G, 2001, CANCER EPIDEM BIOMAR, V10, P1165; Robinson E., 1967, STAT COMMUNICATION D; Rodland KD, 2004, CLIN BIOCHEM, V37, P579, DOI 10.1016/j.clinbiochem.2004.05.011; Rosenblatt KP, 2004, ANNU REV MED, V55, P97, DOI 10.1146/annurev.med.55.091902.105237; Satten GA, 2004, BIOINFORMATICS, V20, P3128, DOI 10.1093/bioinformatics/bth372; Semmes OJ, 2005, CLIN CHEM, V51, P102, DOI 10.1373/clinchem.2004.038950; Seraglia R, 2005, J MASS SPECTROM, V40, P123, DOI 10.1002/jms.769; Shao XG, 2003, ACCOUNTS CHEM RES, V36, P276, DOI 10.1021/ar990163w; SHIN H, 2004, AM ASS CANC RES AACR; Sidransky D, 2003, J NATL CANCER I, V95, P1711, DOI 10.1093/jnci/djg099; Siuzdak G., 1996, MASS SPECTROMETRY BI; Slotta DJ, 2003, PROTEOMICS, V3, P1687, DOI 10.1002/pmic.200300517; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; SORACE J, 2003, BMC BIOINFORMATICS, V4; Srinivas PR, 2001, CLIN CHEM, V47, P1901; Stone JH, 2005, ARTHRITIS RHEUM, V52, P902, DOI 10.1002/art.20938; TANG N, 2004, MASS SPECTROM REV, V1, P34; Tatay JW, 2003, PROTEOMICS, V3, P1704, DOI 10.1002/pmic.200300512; Valerio A, 2004, CLIN CHIM ACTA, V343, P119, DOI 10.1016/j.cccn.2003.12.021; Valerio A, 2001, RAPID COMMUN MASS SP, V15, P2420, DOI 10.1002/rcm.528; Vander A, 2001, HUMAN PHYSL; Verma M, 2001, ANN NY ACAD SCI, V945, P103; Vernon SW, 1997, J NATL CANCER I, V89, P1406, DOI 10.1093/jnci/89.19.1406; Vlahou A, 2003, ADV EXP MED BIOL, V539, P47; Vlahou A, 2001, AM J PATHOL, V158, P1491, DOI 10.1016/S0002-9440(10)64100-4; Vlahou A, 2004, CLIN CHEM, V50, P1438, DOI 10.1373/clinchem.2003.028035; Wagner M, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-26; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519; Walsh JME, 2003, JAMA-J AM MED ASSOC, V289, P1297, DOI 10.1001/jama.289.10.1297; Walsh JME, 2003, JAMA-J AM MED ASSOC, V289, P1288, DOI 10.1001/jama.289.10.1288; Wang MZ, 2003, PROTEOMICS, V3, P1661, DOI 10.1002/pmic.200300513; Won Y, 2003, PROTEOMICS, V3, P2310, DOI 10.1002/pmic.200300590; WOOLAS RP, 1993, J NATL CANCER I, V85, P1748, DOI 10.1093/jnci/85.21.1748; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Wu W, 2002, INT J GYNECOL CANCER, V12, P409, DOI 10.1046/j.1525-1438.2002.01200.x; Wulfkuhle JD, 2003, NAT REV CANCER, V3, P267, DOI 10.1038/nrc.1043; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Yates JR, 2000, TRENDS GENET, V16, P5, DOI 10.1016/S0168-9525(99)01879-X; Zhu HT, 2003, PROTEOMICS, V3, P1673, DOI 10.1002/pmic.200300520; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100; Zhukov TA, 2003, LUNG CANCER, V40, P267, DOI 10.1016/S0169-5002(03)00082-5	158	36	41	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	APR	2006	39	2					227	248		10.1016/j.jbi.2005.04.002		22	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	027MQ	WOS:000236420100010	
J	Lawson, JW; Wolpert, DH				Lawson, JW; Wolpert, DH			Adaptive programming of unconventional nano-architectures	JOURNAL OF COMPUTATIONAL AND THEORETICAL NANOSCIENCE			English	Article						nanoelectronics; computer architectures; circuit optimization; fault tolerance; machine learning; learning; adaptive methods; optimization; programmable circuits; control theory		Novel assembly processes for nanocircuits could present compelling alternatives to the detailed design and placement currently used for computers. The resulting architectures however may not be programmable by standard means. In this paper, nanocomputers with unconventional architectures are programmed using adaptive methods. The internals of the device are treated as a "black box" and programming is achieved by manipulating "control voltages. " Learning algorithms are used to set the controls. As examples, logic gates and simple arithmetic circuits are implemented. Additionally, similar methods allow for reconfiguration of the devices, and makes them resistant to certain kinds of faults.	NASA, Ames Res Ctr, Ctr Nanotechnol, Moffett Field, CA 94035 USA	Lawson, JW (reprint author), NASA, Ames Res Ctr, Ctr Nanotechnol, Moffett Field, CA 94035 USA.						Likharev KK, 1999, P IEEE, V87, P606, DOI 10.1109/5.752518; Roychowdhury VP, 1997, P IEEE, V85, P574, DOI 10.1109/5.573742; SCHMID A, 2003, 3 IEEE C NAN, P647; Sutton R.S., 1998, REINFORCEMENT LEARNI; Tour JM, 2003, J AM CHEM SOC, V125, P13279, DOI 10.1021/ja036369g; TOUR JM, 2002, IEEE T NANOTECHNOL, V1, P13279; Wolpert D, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.017701; Wolpert D., 1999, HDB AGENT TECHNOLOGY; WOLPERT DH, 2001, ADV COMPLEX SYST, V4, P265, DOI 10.1142/S0219525901000188; WOLPERT DH, IN PRESS COMPLEX ENG; WOLPERT DH, ADAPTIVE PROGRAMMING; WOLPERT DH, 2000, EUROPHYS LETT, V49, P6; WOLPERT DH, IN PRESS P IEEE 2004	13	3	3	AMER SCIENTIFIC PUBLISHERS	STEVENSON RANCH	25650 NORTH LEWIS WAY, STEVENSON RANCH, CA 91381-1439 USA	1546-1955		J COMPUT THEOR NANOS	J. Comput. Theor. Nanosci.	APR	2006	3	2					272	279		10.1166/jctn.2006.011		8	Chemistry, Multidisciplinary; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied; Physics, Condensed Matter	Chemistry; Science & Technology - Other Topics; Materials Science; Physics	036PQ	WOS:000237087500011	
J	Pollastri, G; Vullo, A; Frasconi, P; Baldi, P				Pollastri, G; Vullo, A; Frasconi, P; Baldi, P			Modular DAG-RNN Architectures for assembling coarse protein structures	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						protein structure prediction; contact maps; recursive neural networks	SECONDARY STRUCTURE PREDICTION; INTERRESIDUE CONTACTS; NEURAL NETWORKS; CLASSIFICATION; DATABASE; NUMBER; MAPS	We develop and test machine learning methods for the prediction of coarse 3D protein structures, where a protein is represented by a set of rigid rods associated with its secondary structure elements (alpha-helices and beta-strands). First, we employ cascades of recursive neural networks derived from graphical models to predict the relative placements of segments. These are represented as discretized distance and angle maps, and the discretization levels are statistically inferred from a large and curated dataset. Coarse 3D folds of proteins are then assembled starting from topological information predicted in the first stage. Reconstruction is carried out by minimizing a cost function taking the form of a purely geometrical potential. We show that the proposed architecture outperforms simpler alternatives and can accurately predict binary and multiclass coarse maps. The reconstruction procedure proves to be fast and often leads to topologically correct coarse structures that could be exploited as a starting point for various protein modeling strategies. The fully integrated rod-shaped protein builder (predictor of contact maps + reconstruction algorithm) can be accessed at http://distill.ucd.ie/.	Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 4, Ireland; Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy; Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA	Pollastri, G (reprint author), Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 4, Ireland.	gianluca.pollastri@ucd.ie	Frasconi, Paolo/G-2944-2010				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ASZODI A, 1995, J MOL BIOL, V251, P308, DOI 10.1006/jmbi.1995.0436; Baker D, 2001, SCIENCE, V294, P93, DOI 10.1126/science.1065659; Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Bonneau R, 2001, Proteins, VSuppl 5, P119; Bridle J.S., 1989, NEUROCOMPUTING ALGOR; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; Eyrich VA, 2001, BIOINFORMATICS, V17, P1242, DOI 10.1093/bioinformatics/17.12.1242; Fariselli P, 2001, PROTEIN ENG, V14, P835, DOI 10.1093/protein/14.11.835; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; Huang ES, 1999, J MOL BIOL, V290, P267, DOI 10.1006/jmbi.1999.2861; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Lesk AM, 2001, PROTEINS, P98; MONGE A, 1995, J MOL BIOL, V247, P995, DOI 10.1006/jmbi.1995.0195; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Orengo CA, 1997, STRUCTURE, V5, P1093, DOI 10.1016/S0969-2126(97)00260-8; Pollastri G, 2002, PROTEINS, V47, P142, DOI 10.1002/prot.10069; POLLASTRI G, 2003, ADV NEURAL INFORMATI, V15, P1449; Pollastri G, 2005, BIOINFORMATICS, V21, P1719, DOI 10.1093/bioinformatics/bti203; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Romeijn H. E., 2002, HDB GLOBAL OPTIMIZAT, V2; Shao Y, 2003, PROTEINS, V53, P497, DOI 10.1002/prot.10539; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Singer MS, 2002, PROTEIN ENG, V15, P721, DOI 10.1093/protein/15.9.721; Snedecor G, 1989, STAT METHODS; Vendruscolo M, 1997, FOLD DES, V2, P295, DOI 10.1016/S1359-0278(97)00041-2; Zaki M. J., 2000, Proceedings IEEE International Symposium on Bio-Informatics and Biomedical Engineering, DOI 10.1109/BIBE.2000.889604	28	15	16	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277		J COMPUT BIOL	J. Comput. Biol.	APR	2006	13	3					631	650		10.1089/cmb.2006.13.631		20	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	048SE	WOS:000237966000003	
J	Yang, CY; Mills, D; Mathee, K; Wang, Y; Jayachandran, K; Sikaroodi, M; Gillevet, P; Entry, J; Narashimhan, G				Yang, CY; Mills, D; Mathee, K; Wang, Y; Jayachandran, K; Sikaroodi, M; Gillevet, P; Entry, J; Narashimhan, G			An ecoinformatics tool for microbial community studies: Supervised classification of Amplicon Length Heterogeneity (ALH) profiles of 16S rRNA	JOURNAL OF MICROBIOLOGICAL METHODS			English	Article						ecoinformatics; supervised classification; machine learning; amplicon length heterogeneity; ecosystem community patterns; support vector machines	SUPPORT VECTOR MACHINES; GENE-EXPRESSION DATA; DIVERSITY; SOILS; DNA; PCR; ENVIRONMENTS; PHYLOGENY	Support vector machines (SVM) and K-nearest neighbors (KNN) are two computational machine learning tools that perform supervised classification. This paper presents a novel application of such supervised analytical tools for microbial Community profiling and to distinguish patterning among ecosystems. Amplicon length heterogeneity (ALH) profiles from several hypervariable regions of 16S rRNA gene of cubacterial communities from Idaho agricultural soil samples and from Chesapeake Bay marsh sediments were separately analyzed. The profiles from all available hypervariable regions were concatenated to obtain a combined profile, which was then provided to the SVM and KNN classifiers. Each profile was labeled with information about the location or time of its sampling. We hypothesized that after a learning phase using feature vectors from labeled ALH profiles, both these classifiers would have the capacity to predict the labels of previously unseen samples. The resulting classifiers were able to predict the labels of the Idaho soil samples with high accuracy. The classifiers were less accurate for the classification of the Chesapeake Bay sediments suggesting greater similarity within the Bay's microbial community patterns in the sampled sites. The profiles obtained from the V1+V2 region were more informative than that obtained from any other single region. However, combining them with profiles from the VI region (with or without the profiles from the V3 region) resulted in the most accurate classification of the samples. The addition of profiles from the V9 region appeared to confound the classifiers. Our results show that SVM and KNN classifiers can be effectively applied to distinguish between eubacterial community patterns from different ecosystems based only on their ALH profiles. (c) 2005 Elsevier B V. All rights reserved.	Florida Int Univ, Sch Comp Sci, BioRG, Miami, FL 33199 USA; Florida Int Univ, Dept Biol Sci, Miami, FL 33199 USA; Florida Int Univ, Dept Environm Sci, Miami, FL 33199 USA; George Mason Univ, Dept Environm Sci & Policy, Manassas, VA USA; USDA ARS, NW Irrigat & Soils Res Lab, Kimberly, ID USA	Narashimhan, G (reprint author), Florida Int Univ, Sch Comp Sci, BioRG, Miami, FL 33199 USA.	giri@cs.fiu.edu					Bernhard AE, 2005, FEMS MICROBIOL ECOL, V52, P115, DOI 10.1016/j.femsec.2004.10.016; Bernhard AE, 2000, APPL ENVIRON MICROB, V66, P1587, DOI 10.1128/AEM.66.4.1587-1594.2000; Blackwood CB, 2003, APPL ENVIRON MICROB, V69, P926, DOI 10.1128/AEM.69.2.926-932.2003; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHANG CC, 2002, PRACTICAL GUIDE SUPP; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Cocolin L, 2001, APPL ENVIRON MICROB, V67, P5113, DOI 10.1128/AEM.67.11.5113-5121.2001; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Cristianini N., 2000, SUPPORT VECTOR MACHI; Dunbar J, 2000, APPL ENVIRON MICROB, V66, P2943, DOI 10.1128/AEM.66.7.2943-2950.2000; Dunbar J, 2002, APPL ENVIRON MICROB, V68, P3035, DOI 10.1128/AEM.68.3035-3045.2002; Dunbar J, 2001, APPL ENVIRON MICROB, V67, P190, DOI 10.1128/AEM.67.1.190-197.2001; Efron B, 1993, INTRO BOOSTRAP; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Griffiths RI, 2000, APPL ENVIRON MICROB, V66, P5488, DOI 10.1128/AEM.66.12.5488-5491.2000; Hastie T., 2001, ELEMENT STAT LEARNIN; Hill JE, 2002, APPL ENVIRON MICROB, V68, P3055, DOI 10.1128/AEM.68.6.3055-3066.2002; Horswell J, 2002, J FORENSIC SCI, V47, P350; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Joachims T., 1999, MAKING LARGE SCALE S; JOACHIMS T, 1997, P 10 EUR C MACH LEAR; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; KNERR S, 1990, P NEUR ALG ARCH APPL; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Lin K, 2002, NUCLEIC ACIDS RES, V30, P2599, DOI 10.1093/nar/30.11.2599; Litchfield CD, 2002, J IND MICROBIOL BIOT, V28, P48, DOI 10.1038/sj.jim.7000175; LUDWIG W, 1994, FEMS MICROBIOL REV, V15, P155, DOI 10.1016/0168-6445(94)90110-4; Maidak BL, 1999, NUCLEIC ACIDS RES, V27, P171, DOI 10.1093/nar/27.1.171; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mills DK, 2003, J MICROBIOL METH, V54, P57, DOI 10.1016/S0167-7012(03)00007-1; Noble W. S., 2004, KERNEL METHODS COMPU; OLSEN GJ, 1986, ANNU REV MICROBIOL, V40, P337, DOI 10.1146/annurev.micro.40.1.337; Osuna E., 1997, P IEEE C COMP VIS PA; PACE NR, 1986, CELL, V45, P325, DOI 10.1016/0092-8674(86)90315-6; Pavlidis P, 2004, BIOINFORMATICS, V20, P586, DOI 10.1093/bioinformatics/btg461; Ritchie NJ, 2000, APPL ENVIRON MICROB, V66, P1668, DOI 10.1128/AEM.66.4.1668-1675.2000; RooneyVarga JN, 1997, APPL ENVIRON MICROB, V63, P3895; RUPING S, 2002, MYSVM; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; Sturn A, 2002, BIOINFORMATICS, V18, P207, DOI 10.1093/bioinformatics/18.1.207; Suzuki M, 1998, APPL ENVIRON MICROB, V64, P4522; Taylor C., 1994, MACHINE LEARNING NEU; Tiirola MA, 2003, WATER RES, V37, P2259, DOI 10.1016/S0043-1354(02)00631-0; VERT JP, 2002, P PAC S BIOC	46	4	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-7012		J MICROBIOL METH	J. Microbiol. Methods	APR	2006	65	1					49	62		10.1016/j.mimet.2005.06.012		14	Biochemical Research Methods; Microbiology	Biochemistry & Molecular Biology; Microbiology	032ZF	WOS:000236814700006	
J	Bies, RR; Muldoon, MF; Pollock, BG; Manuck, S; Smith, G; Sale, ME				Bies, RR; Muldoon, MF; Pollock, BG; Manuck, S; Smith, G; Sale, ME			A genetic algorithm-based, hybrid machine learning approach to model selection	JOURNAL OF PHARMACOKINETICS AND PHARMACODYNAMICS			English	Article						nonlinear mixed effects modeling; covariate selection; automated machine learning; genetic algorithm; population paramacokinetics; model building	POPULATION; NONMEM	We describe a general and robust method for identification of an optimal non-linear mixed effects model. This includes structural, inter-individual random effects, covariate effects and residual error models using machine learning. This method is based on combinatorial optimization using genetic algorithm.	Univ Pittsburgh, Dept Pharmaceut Sci & Psychiat, Pittsburgh, PA 15260 USA; Univ Pittsburgh, Ctr Clin Pharmacol, Pittsburgh, PA USA; Univ Toronto, Rotman Res Inst, Ctr Addict & Mental Hlth, Toronto, ON, Canada; Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA; Zucker Hillside Hosp, Albert Einstein Coll Med, Glen Oaks, NY USA; Next Level Solut, Raleigh, NC USA	Bies, RR (reprint author), Univ Pittsburgh, Dept Pharmaceut Sci & Psychiat, Pittsburgh, PA 15260 USA.	rrb47@pitt.edu					AKAIKE H, 2 INT S INF THEOR; Best NG, 1997, CODA CONVERGENCE DIA; BIES R, 2003, PAGE M; Chambers L., 1995, PRACTICAL HDB GENETI, V1; COFOLGA TA, 2005, COMPUT BIOL CHEM; Givens G. H., 2005, COMPUTATIONAL STAT; Goldberg DE, 1989, GENETIC ALGORITHMS S; HANOVER MD, GLOBOMAX; Heckerling PS, 2005, METHOD INFORM MED, V44, P89; Jonsson EN, 1999, COMPUT METH PROG BIO, V58, P51; JOSE C, 1994, P BIOPH SECT JOINT S; Kowalski KG, 2001, J PHARMACOKINET PHAR, V28, P253, DOI 10.1023/A:1011579109640; Lin HN, 2005, NUCLEIC ACIDS RES, V33, P4593, DOI 10.1093/nar/gki768; LOHN JD, 2004 GEN PROGR THEOR; MAITRE PO, 1991, J PHARMACOKINET BIOP, V19, P377, DOI 10.1007/BF01061662; MANDEMA JW, 1992, J PHARMACOKINET BIOP, V20, P511, DOI 10.1007/BF01061469; MENTRE F, 2005, IN PRESS J PHARMACOK; MICHALEWICZ Z, 1988, SOLVE IT MODERN HEUR; OH IS, 2004, IEEE T PATTERN ANAL, V24, P1424; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; SHAPCOTT J, 1992, EPCCSS9224 JCMB U ED; SHEINER LB, 1981, J PHARMACOKINET BIOP, V9, P503, DOI 10.1007/BF01060893; Steiglitz K., 1998, COMBINATORIAL OPTIMI; Tong T. K., 2001, CONSTRUCTION MANAGEM, V19, P601; WADE JR, 1994, J PHARMACOKINET BIOP, V22, P165, DOI 10.1007/BF02353542; Wahlby U, 2002, AAPS PHARMSCI, V4; Yano Y, 2001, J PHARMACOKINET PHAR, V28, P171, DOI 10.1023/A:1011555016423	27	3	3	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1567-567X		J PHARMACOKINET PHAR	J. Pharmacokinet. Pharmacodyn.	APR	2006	33	2					195	221		10.1007/s10928-006-9004-6		27	Pharmacology & Pharmacy	Pharmacology & Pharmacy	033ET	WOS:000236830200005	
J	McCourt, R; Cui, H; Monique, F; Michael, G				McCourt, R.; Cui, H.; Monique, F.; Michael, G.			Using machine learning environments to extract taxonomic information from text: An example from print and digital texts on algae	JOURNAL OF PHYCOLOGY			English	Meeting Abstract									Natl Acad Sci, Philadelphia, PA USA; Univ Western Ontario, London, ON, Canada; Univ Montpellier, F-34059 Montpellier, France; Natl Univ Galway, Galway, Ireland								0	0	0	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0022-3646		J PHYCOL	J. Phycol.	APR	2006	42			1		115	36	36				1	Plant Sciences; Marine & Freshwater Biology	Plant Sciences; Marine & Freshwater Biology	161HH	WOS:000246004900116	
J	Wu, YFB; Li, QZ; Bot, RS; Chen, X				Wu, YFB; Li, QZ; Bot, RS; Chen, X			Finding nuggets in documents: A machine learning approach	JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article							DIGITAL LIBRARIES	Document keyphrases provide a concise summary of a document's content, offering semantic metadata summarizing a document. They can be used in many applications related to knowledge management and text mining, such as automatic text summarization, development of search engines, document clustering, document classification, thesaurus construction, and browsing interfaces. Because only a small portion of documents have keyphrases assigned by authors, and it is time-consuming and costly to manually assign keyphrases to documents, it is necessary to develop an algorithm to automatically generate keyphrases for documents. This paper describes a Keyphrase Identification Program (KIP), which extracts document keyphrases by using prior positive samples of human identified phrases to assign weights to the candidate keyphrases. The logic of our algorithm is: The more keywords a candidate keyphrase contains and the more significant these keywords are, the more likely this candidate phrase is a keyphrase. KIP's learning function can enrich the glossary database by automatically adding new identified keyphrases to the database. KIP's personalization feature will let the user build a glossary database specifically suitable for the area of his/her interest. The evaluation results show that KIP's performance is better than the systems we compared to and that the learning function is effective.	New Jersey Inst Technol, Dept Informat Syst, Newark, NJ 07102 USA	Wu, YFB (reprint author), New Jersey Inst Technol, Dept Informat Syst, Newark, NJ 07102 USA.	wu@njit.edu; QL23@njit.edu; rsb2@njit.edu; xc7@njit.edu					Anick PG, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P314, DOI 10.1145/258525.258601; Argamon-Engelson S, 1999, J EXP THEOR ARTIF IN, V11, P369, DOI 10.1080/095281399146463; Barker K., 2000, P 13 CAN C ART INT M, P40; Cardie C., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Carletta J, 1996, COMPUT LINGUIST, V22, P249; Cover TM, 1991, ELEMENTS INFORM THEO; CROFT B, 1991, P SIGIR 91, P32; DAVIS GB, 1997, BLACKWELL ENCY DICT; Fellbaum C., 1998, WORDNET ELECT LEXICA; Frank E., 1999, P 16 INT JOINT C ART, P668; Gutwin C, 1999, DECIS SUPPORT SYST, V27, P81, DOI 10.1016/S0167-9236(99)00038-X; Jones S., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312671; Jones S, 2002, J AM SOC INF SCI TEC, V53, P653, DOI 10.1002/asi.10068; Jones S., 2000, P 3 INT AS C DIG LIB, P113; Kamp H., 1981, FORMAL METHODS STUDY, P277; Kosovac B., 2000, ELECT J INFORMATION, P25; KRULWICH B, 1996, AAAI 1996 SPRING S M, P15; Larkey L., 1999, P DL 99 4 ACM C DIG, P179, DOI 10.1145/313238.313304; LI Q, 2004, P 10 AM C INF SYST, P3255; MUNOZ M, 1999, P 1999 JOINT SIGDAT, P168; Ramshaw Lance A., 1995, P 3 WORKSH VER LARG, P82; SANG EFT, 2000, P ANLP NAACL 2000 SE, P50; Siegel S., 1988, NONPARAMETRIC STAT B; SNOW CE, 1997, TALKING CHILDREN LAN; Tolle KM, 2000, J AM SOC INFORM SCI, V51, P352, DOI 10.1002/(SICI)1097-4571(2000)51:4<352::AID-ASI5>3.3.CO;2-#; Tomokiyo T., 2003, P ACL WORKSH MULT EX, P33, DOI 10.3115/1119282.1119287; Turney P. D., 2000, Information Retrieval, V2, DOI 10.1023/A:1009976227802; Witten I.H., 1999, KEA PRACTICAL AUTOMA, P254; Zha H., 2002, P 25 ANN INT ACM SIG, P113	29	3	3	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1532-2882		J AM SOC INF SCI TEC	J. Am. Soc. Inf. Sci. Technol.	APR	2006	57	6					740	752		10.1002/asi.20341		13	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	027FP	WOS:000236400000003	
J	Cui, G; Wong, ML; Lui, HK				Cui, G; Wong, ML; Lui, HK			Machine learning for direct marketing response models: Bayesian networks with evolutionary programming	MANAGEMENT SCIENCE			English	Article						direct marketing; Bayesian networks; evolutionary programming; machine learning; data mining	MINIMUM DESCRIPTION LENGTH; PROBABILITIES; PRINCIPLE; SELECTION; CHOICE	Machine learning methods are powerful tools for data mining with large noisy databases and give researchers the opportunity to gain new insights into consumer behavior and to improve the performance of marketing operations. To model consumer responses to direct marketing, this study proposes Bayesian networks learned by evolutionary programming. Using a large direct marketing data set, we tested the endogeneity bias in the recency, frequency, monetary value (RFM) variables using the control function approach; compared the results of Bayesian networks with those of neural networks, classification and regression tree (CART), and latent class regression; and applied a tenfold cross-validation. The results suggest that Bayesian networks have distinct advantages over the other methods in accuracy of prediction, transparency of procedures, interpretability of results, and explanatory insight. Our findings lend strong support to Bayesian networks as a robust tool for modeling consumer response and other marketing problems and for assisting management decision making.	Lingnan Univ, Dept Mkt & Int Business, Tuen Mun, Hong Kong, Peoples R China; Lingnan Univ, Dept Comp & Decis Sci, Tuen Mun, Hong Kong, Peoples R China	Cui, G (reprint author), Lingnan Univ, Dept Mkt & Int Business, Tuen Mun, Hong Kong, Peoples R China.	gcui@ln.edu.hk; mlwong@ln.edu.hk; hklui@ln.edu.hk					Allenby GM, 1999, J AM STAT ASSOC, V94, P365, DOI 10.2307/2670153; Baesens B, 2002, EUR J OPER RES, V138, P191, DOI 10.1016/S0377-2217(01)00129-1; BERG O, 1992, AM J RHINOL, V6, P13, DOI 10.2500/105065892781976709; Bhattacharyya S, 1999, INFORMS J COMPUT, V11, P248, DOI 10.1287/ijoc.11.3.248; BITRAN G, 1996, MANAGE SCI, V42, P1362; Blodgett J. G., 2000, J SERV RES-US, V2, P321, DOI 10.1177/109467050024002; Blundell RW, 2004, REV ECON STUD, V71, P655, DOI 10.1111/j.1467-937X.2004.00299.x; CHIOGNA M, 1997, MACHINE LEARNING STA; Cooper LG, 2000, J MARKETING, V64, P1, DOI 10.1509/jmkg.64.1.1.17987; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956; Haddawy P., 1999, AI Magazine, V20; Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398; Haughton D., 1997, J DIRECT MARKETING, V11, P42, DOI 10.1002/(SICI)1522-7138(199723)11:4<42::AID-DIR7>3.0.CO;2-W; Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752; Hu MY, 1999, INT J RES MARK, V16, P307, DOI 10.1016/S0167-8116(99)00018-X; JAIN D, 1990, J MARKETING RES, V27, P94, DOI 10.2307/3172555; Jensen F., 1996, INTRO BAYESIAN NETWO; Kohavi R., 1995, P 14 INT JOINT C ART; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; LARRANAGA P, 1996, IEEE T PATTERN ANAL, V18, P9; Levin N., 1997, J DIRECT MARKETING, V11, P76, DOI 10.1002/(SICI)1522-7138(199723)11:4<76::AID-DIR10>3.0.CO;2-D; Malhotra NK, 1999, J ACAD MARKET SCI, V27, P160, DOI 10.1177/0092070399272004; Mitchell T, 1997, MACHINE LEARNING; NAKHAEIZADEH G, 1997, MACHINE LEARNING STA; Neal R., 1996, LECT NOTES STAT; Pearl J, 2000, CAUSALITY MODELS REA; Pearl J., 1988, PROBABILISTIC REASON; Rao V.R., 1995, J DIRECT MARKETING, V9, P20, DOI 10.1002/dir.4000090205; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Shi M., 2000, J INTERACTIVE MARKET, V14, P2; SMITH RJ, 1986, ECONOMETRICA, V54, P679, DOI 10.2307/1911314; Taylor C., 1994, MACHINE LEARNING NEU; Venkatesan R, 2004, J MARKETING, V68, P106, DOI 10.1509/jmkg.68.4.106.42728; WARNER BA, 1997, J AM STAT ASSOC, V92, P791, DOI 10.2307/2965731; West PM, 1997, MARKET SCI, V16, P370, DOI 10.1287/mksc.16.4.370; Wong ML, 1999, IEEE T PATTERN ANAL, V21, P174	36	20	21	INST OPERATIONS RESEARCH  MANAGEMENT SCIENCES	LINTHICUM HTS	901 ELKRIDGE LANDING RD, STE 400, LINTHICUM HTS, MD 21090-2909 USA	0025-1909		MANAGE SCI	Manage. Sci.	APR	2006	52	4					597	612		10.1287/mnsc.1060.0514		16	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	034HG	WOS:000236919300010	
J	Chen, CM; Lu, YF; Hong, CM				Chen, CM; Lu, YF; Hong, CM			Minimal structure of self-organizing HCMAC neural network classifier	NEURAL PROCESSING LETTERS			English	Article						Cerebellar Model Articulation Controller (CMAC); minimal structure of self-organzing HCMAC (MHCMAC) neural network; self-organizing hierarchical CMAC (HCMAC) neural network	LEARNING CONVERGENCE; MATHEMATICAL-THEORY; CMAC; COMMUNICATION; ALGORITHM	The authors previously proposed a self-organizing Hierarchical Cerebellar Model Articulation Controller (HCMAC) neural network containing a hierarchical GCMAC neural network and a self-organizing input space module to solve high-dimensional pattern classification problems. This novel neural network exhibits fast learning, a low memory requirement, automatic memory parameter determination and highly accurate high-dimensional pattern classification. However, the original architecture needs to be hierarchically expanded using a full binary tree topology to solve pattern classification problems according to the dimension of the input vectors. This approach creates many redundant GCMAC nodes when the dimension of the input vectors in the pattern classification problem does not exactly match that in the self-organizing HCMAC neural network. These redundant GCMAC nodes waste memory units and degrade the learning performance of a self-organizing HCMAC neural network. Therefore, this study presents a minimal structure of self-organizing HCMAC (MHCMAC) neural network with the same dimension of input vectors as the pattern classification problem. Additionally, this study compares the learning performance of this novel learning structure with those of the BP neural network,support vector machine (SVM), and original self-organizing HCMAC neural network in terms of ten benchmark pattern classification data sets from the UCI machine learning repository. In particular, the experimental results reveal that the self-organizing MHCMAC neural network handles high-dimensional pattern classification problems better than the BP, SVM or the original self-organizing HCMAC neural network. Moreover, the proposed self-organizing MHCMAC neural network significantly reduces the memory requirement of the original self-organizing HCMAC neural network, and has a high training speed and higher pattern classification accuracy than the original self-organizing HCMAC neural network in most testing benchmark data sets. The experimental results also show that the MHCMAC neural network learns continuous function well and is suitable for Web page classification.	Natl Hualien Univ Educ, Grad Inst Learning Technol, Hualien, Taiwan; Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan; Natl Taiwan Univ, Inst Appl Elect Technol, Taipei 10764, Taiwan	Chen, CM (reprint author), Natl Hualien Univ Educ, Grad Inst Learning Technol, Hualien, Taiwan.	cmchen@mail.nhlue.edu.tw					Albus J. S., 1975, Transactions of the ASME. Series G, Journal of Dynamic Systems, Measurement and Control, V97; Albus J. S., 1975, T ASME, P228; Almeida PEM, 2003, IEEE T IND APPL, V39, P1551, DOI 10.1109/TIA.2003.816543; BAZARAA MS, 1993, NONLINEAR PROGRAMMIN, P270; BERGER CS, 1994, IEE P-CONTR THEOR AP, V141, P277, DOI 10.1049/ip-cta:19941363; CHEN CM, 2004, WEB INTELLIGENCE AGE, V2, P21; Chiang CT, 1996, NEURAL NETWORKS, V9, P1199; COTTER NE, 1992, NEURAL NETWORKS, V5, P221, DOI 10.1016/S0893-6080(05)80021-8; Francis W. N., 1982, FREQUENCY ANAL ENGLI; GLANZ FH, 1991, P 1991 IEEE NEUR NET, P301; HORVATH G, 2004, P IJCNN 2004, V1, P681; HSU YP, 2000, P AS S PAC DES AUT C, P481, DOI 10.1145/368434.368763; Hu J., 1999, P 1999 IEEE INT S IN, P259; HU J, 1999, P 1999 IEEE INT C RO, V2, P1050; HU JS, 2004, P 3 INT C MACH LEARN, V3, P1889; HWANG KS, 2003, IEEE INT C NEUR NETW, V1, P320; Jan JC, 2001, IEEE T NEURAL NETWOR, V12, P598, DOI 10.1109/72.925562; KIM H, 1992, P INT JOINT C NEUR N, V1, P517, DOI 10.1109/IJCNN.1992.287160; Lane S. H., 1992, IEEE Control Systems Magazine, V12, DOI 10.1109/37.126849; Lee HJ, 2003, IEEE T PARALL DISTR, V14, P1; LEE HM, 2001, P JOINT 9 IFSA WORLD, V1, P395; Lewis D. D., 1994, P 17 ANN INT ACM SIG, P3; Lewis D. D., 1996, P 19 ANN INT ACM SIG, P298, DOI 10.1145/243199.243277; Li B, 1997, PROC INT C TOOLS ART, P392; LIN CJ, 2004, P IEEE INT C FUZZ SY, V2, P697; Lin CS, 1997, IEEE T NEURAL NETWOR, V8, P1281; LIN CS, 1995, IEEE T NEURAL NETWOR, V6, P642, DOI 10.1109/72.377969; Lin CS, 2000, NEUROCOMPUTING, V30, P273, DOI 10.1016/S0925-2312(99)00130-7; LIN CS, 1996, P IEEE C SYST MAN CY, V2, P1297; Lin C S, 1999, Int J Neural Syst, V9, P41, DOI 10.1142/S0129065799000058; MENOZZI A, 1997, P IEEE INT S IND EL, V3, P1201; MILLER WT, 1987, INT J ROBOT RES, V6, P84, DOI 10.1177/027836498700600207; Miller W. T.  III, 1990, Proceedings. 5th IEEE International Symposium on Intelligent Control 1990 (Cat. No.90TH0333-5), DOI 10.1109/ISIC.1990.128498; Moody J., 1989, ADV NEURAL INFORMATI, V1, P29; Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salton G., 1989, AUTOMATIC TEXT PROCE; SAYIL S, 2002, P 2002 INT JOINT C N, V1, P165; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHANNON CE, 1948, AT&T TECH J, V27, P623; SHELTON RO, 1992, SIMULATION, V58, P319, DOI 10.1177/003754979205800504; MILLER WT, 1990, P IEEE, V78, P1561, DOI 10.1109/5.58338; Wang Z., 1996, IEEE INT C NEUR NETW, V3, P1698; WERUAGA L, 2004, P IJCNN 2004, V2, P855; WONG YF, 1992, IEEE T NEURAL NETWOR, V3, P115, DOI 10.1109/72.105424; ZHANG K, 2000, P 3 WORLD C INT CONT, P944; Zhang L, 2004, NEURAL PROCESS LETT, V20, P1, DOI 10.1023/B:NEPL.0000039430.04088.78; ZHONG L, 1997, IEEE INT C INT PROC, P419; [Anonymous], LIBSVM	50	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621		NEURAL PROCESS LETT	Neural Process. Lett.	APR	2006	23	2					201	228		10.1007/s11063-006-6277-0		28	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	028PG	WOS:000236499700007	
J	Bunke, H; Dickinson, P; Irniger, C; Kraetzl, M				Bunke, H; Dickinson, P; Irniger, C; Kraetzl, M			Recovery of missing information in graph sequences by means of reference pattern matching and decision tree learning	PATTERN RECOGNITION			English	Article; Proceedings Paper	5th Workshop on Graph-Based Representations	APR, 2005	Poitiers, FRANCE	Sch Engn ENSICAEN, Univ Poitiers, IAPR-TC15		graph sequence analysis; recovery of missing information; computer network analysis; machine learning; decision tree classifier; reference pattern matching	SERIES; PREDICTION	Algorithms for the analysis of graph sequences are proposed in this paper. In particular, we study the problem of recovering missing information and predicting the Occurrence of nodes and edges in time series of graphs. Two different recovery schemes are developed. The first scheme uses reference patterns that are extracted from a training set of graph sequences, while the second method is based on decision tree induction. Our work is motivated by applications in Computer network analysis. However, the proposed recovery and prediction schemes are generic and can be applied in other domains as well. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Bern, Inst Comp Sci & Appl Math, CH-3012 Bern, Switzerland; Def Sci & Technol Org, Intelligence Surveillance & Reconnaissance Div, Edinburgh, SA, Australia	Bunke, H (reprint author), Univ Bern, Inst Comp Sci & Appl Math, Neubruckstr 10, CH-3012 Bern, Switzerland.	bunke@iam.unibe.ch; Peter.Dickinson@dsto.defence.gov.au; irniger@iam.unibe.ch; Miro.Kraetzl@dsto.defense.gov.au					BRUN L, 2005, LECT NOTES COMPUTER, V3434; BUNKE H, 2002, J INTERCONNECTION NE, V3, P85; BUNKE H, 2003, ANAL GRAPH SEQUENCES; Dickinson PJ, 2004, PATTERN ANAL APPL, V7, P243, DOI [10.1007/s10044-004-0222-5, 10.1007/s10044-044-0222-5]; Erdos P., 1960, PUBL MATH I HUNG, V5, P17; FALOOUTSOS M, SIGCOMM 99, P251; Fessant F, 1996, ANN GEOPHYS, V14, P20, DOI 10.1007/s00585-996-0020-z; FUNG GPC, 2002, LECT NOTES ARTIF INT, V2336, P481; GOVINDAN R, 2000, P IEEE INF; KAHVECI T, IEEE T KDE, V16, P418; Keogh E., 2004, DATA MINING TIME SER, P1; KITTLER J, 2000, LECT NOTES COMPUTER, V1857; LAKHINA A, 2003, P IEEE INF; Last M., 2004, DATA MINING TIME SER; Povinelli RJ, 2003, IEEE T KNOWL DATA EN, V15, P339, DOI 10.1109/TKDE.2003.1185838; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Schenker A, 2005, SER MACH PERCEPT ART, V62, P1, DOI 10.1142/9789812569455; Schmidt R, 2001, LECT NOTES ARTIF INT, V2123, P23; Tanaka Y, 2003, LECT NOTES ARTIF INT, V2734, P252; VLACHOS M., 2004, DATA MINING TIME SER, P67; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Yang J, 2003, IEEE T KNOWL DATA EN, V15, P613; ZEIRA G, 2004, DATA MINING TIME SER, P101; 2004, INT J PATTERN RECOGN, V18; 2003, PATTERN RECOGN LETT, V24; 2001, IEEE T PAMI, V23	26	1	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	APR	2006	39	4					573	586		10.1016/j.patcog.2005.10.011		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	019TI	WOS:000235859200008	
J	Nanni, L				Nanni, L			Comparison among feature extraction methods for HIV-1 protease cleavage site prediction	PATTERN RECOGNITION			English	Article						HIV-1 protease; feature extraction; fusion of classifiers		Recently, several works have approached the HIV-1 protease specificity problem by applying a number of methods from the field of machine learning. However, it is still difficult for researchers to choose the best method due to the lack of an effective comparison. For the first time we have made an extensive study on methods for feature extraction for the problem of HIV-1 protease. We show that a fusion of classifiers trained in different feature spaces permits to obtain a drastically error reduction with respect to the performance of the state-of-the-art. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Bologna, DEIS, IEIIT, CNR, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, IEIIT, CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it					Guo J, 2005, P 3 AS PAC BIOINF C, P117, DOI 10.1142/9781860947322_0012; Kuncheva L., 2001, IEEE WORKSH INT SENS; ROGNVALDSSON T, 2003, BIOINFORMATICS, P1702; RUAN J, 2005, ARTIF INTELL; WU C, 1992, PROTEIN SCI, V1, P667	5	19	20	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	APR	2006	39	4					711	713		10.1016/j.patcog.2005.11.002		3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	019TI	WOS:000235859200019	
J	Hu, QH; Yu, DR; Xie, ZX				Hu, QH; Yu, DR; Xie, ZX			Information-preserving hybrid data reduction based on fuzzy-rough techniques	PATTERN RECOGNITION LETTERS			English	Article						attribute reduction; hybrid data; fuzzy-rough set; information measure	FEATURE-SELECTION; KNOWLEDGE REDUCTION; COMPONENT ANALYSIS; SETS; SIMILARITY; ALGORITHM; FEATURES; SYSTEMS; MODEL	Data reduction plays an important role in machine learning and pattern recognition with a high-dimensional data. In real-world applications data usually exists with hybrid formats, and it unified data reducing technique for hybrid data is desirable. In this paper, an information measure is proposed to computing discernibility power of a crisp equivalence relation or a fuzzy one,. which is the key concept in classical rough set model and fuzzy-rough set model. Based on the information measure, a general definition of significance of nominal, numeric and fuzzy attributes is presented. We redefine the independence of hybrid attribute subset, reduct, and relative reduct. Then two greedy reduction algorithms for unsupervised and supervised data dimensionality reduction based on the proposed information measure are constructed. Experiments show the reducts found by the proposed algorithms get a better performance compared with classical rough set approaches. (c) 2005 Elsevier B.V. All rights reserved.	Harbin Inst Technol, Harbin 150001, Heilongjiang, Peoples R China	Hu, QH (reprint author), Harbin Inst Technol, Harbin 150001, Heilongjiang, Peoples R China.	huqinghua@hcms.hit.edu.cn	Hu, Qinghua/B-8857-2008				Beynon M, 2001, EUR J OPER RES, V134, P592, DOI 10.1016/S0377-2217(00)00280-0; Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Chen SC, 2004, PATTERN RECOGN, V37, P1081, DOI 10.1016/j.patcog.2003.09.004; Cheung YM, 2001, NEUROCOMPUTING, V41, P145, DOI 10.1016/S0925-2312(00)00358-1; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; Dubois D., 1992, INTELLIGENT DECISION, P203; Duch W., 2002, P 9 NEUR INF PROC, V4, P1951, DOI 10.1109/ICONIP.2002.1199014; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; H QQ, IN PRESS IEEE T FUZZ; Hand D., 2001, PRINCIPLES DATA MINI; HU Q, IN PRESS INT J UNCER; HU Q, 2005, 5 SIAM C DAT MIN; Hu QH, 2004, INT J UNCERTAIN FUZZ, V12, P575, DOI 10.1142/S0218488504003089; Hwang KF, 2002, PATTERN RECOGN LETT, V23, P1747, DOI 10.1016/S0167-8655(02)00148-4; Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6; Kohavi Ron, 1997, ARTIF INTELL, V97, P73; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Lee HS, 2001, FUZZY SET SYST, V123, P129, DOI 10.1016/S0165-0114(00)00062-2; Li DF, 2002, PATTERN RECOGN LETT, V23, P221, DOI 10.1016/S0167-8655(01)00110-6; Li DY, 2004, INT J UNCERTAIN FUZZ, V12, P651, DOI 10.1142/S0218488504003132; Li HX, 2001, KNOWL-BASED SYST, V14, P253, DOI 10.1016/S0950-7051(01)00103-4; Liu H., 2002, P 19 INT C MACH LEAR, P395; Liu HA, 1998, EXPERT SYST APPL, V15, P333, DOI 10.1016/S0957-4174(98)90049-5; Mi JS, 2004, INFORM SCIENCES, V159, P255, DOI 10.1016/j.ins.2003.07.004; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Moradi H, 1998, INFORM SCIENCES, V104, P31, DOI 10.1016/S0020-0255(97)00074-1; Morsi NN, 1998, FUZZY SET SYST, V100, P327, DOI 10.1016/S0165-0114(97)00104-8; Pawlak Z., 1991, ROUGH SETS THEORETIC; Piramuthu S, 2004, EUR J OPER RES, V156, P483, DOI [10.1016/S0377-2217(02)00911-6, 10.1016/s0377-2217(02)00911-6]; Rendell L.A., 1992, P 10 NAT C ART INT, P129; Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016; Shen Q, 2002, PATTERN RECOGN, V35, P2425, DOI 10.1016/S0031-3203(01)00229-1; SKOWRON R, 1992, INTELLIGENT DECISION, P311; Srinivasan P, 2001, INFORM PROCESS MANAG, V37, P15, DOI 10.1016/S0306-4573(00)00014-5; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Swiniarski RW, 2001, NEUROCOMPUTING, V36, P85, DOI 10.1016/S0925-2312(00)00337-4; Torkkola K., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753742; Tsang ECC, 2003, IEEE T FUZZY SYST, V11, P202, DOI 10.1109/TFUZZ.2003.809895; Wakako H, 2002, SIGNAL PROCESS, V82, P1949; Wang G., 2002, CHINESE J COMPUTERS, V25, P1; WANG GC, 2003, ACTA PHYS SINICA, V52, P4; Wang Jue, 1998, Journal of Computer Science and Technology (English Language Edition), V13, DOI 10.1007/BF02946606; Wang John Q., 2003, Current Neuropharmacology, V1, P1, DOI 10.2174/1570159033360548; WU W, 2004, INFORM SCI, V151, P263; Wu WZ, 2004, INFORM SCIENCES, V159, P233, DOI 10.1016/j.ins.2003.08.005; Yu L., 2003, P 9 ACM SIGKDD INT C, P685; Yu L., 2003, P 20 INT C MACH LEAR, P856	49	137	159	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	APR 1	2006	27	5					414	423		10.1016/patrec.2005.09.004		10	Computer Science, Artificial Intelligence	Computer Science	019UN	WOS:000235862300011	
J	Goertzel, BN; Pennachin, C; Coelho, LD; Gurbaxani, B; Maloney, EM; Jones, JF				Goertzel, BN; Pennachin, C; Coelho, LD; Gurbaxani, B; Maloney, EM; Jones, JF			Combinations of single nucleotide polymorphisms in neuroendocrine effector and receptor genes predict chronic fatigue syndrome	PHARMACOGENOMICS			English	Article						chronic fatigue syndrome; single nucleotide polymorphism; supervised machine learning		Objective: This paper asks whether the presence of chronic fatigue syndrome (CFS) can be more accurately predicted from single nucleotide polymorphism (SNP) profiles than would occur by chance. Methods: Specifically, given SNP profiles for 43 US patients, together with 58 controls, we used an enumerative search to identify an ensemble of conjunctive rules that predict whether a patient has CFS. Results: The accuracy of the rules reached 76.3%, with the highest accuracy rules yielding 49 true negatives, 15 false negatives, 28 true positives and nine false positives (odds ratio [OR] 8.94, p < 0.0001). Analysis of the SNPs used most frequently in the overall ensemble of rules gave rise to a list of 'most important SNPs', which was not identical to the list of 'most differentiating SNPs' that one would calculate via studying each SNP independently. The top three genes containing the SNPS accounting for the highest accumulated importances were neuronal tryptophan hydroxylase (TPH2), catechol-O-methyltransferase (COMT) and nuclear receptor subfamily 3, group C, member 1 glucocorticoid receptor (NR3C1). Conclusion: The fact that only 28 out of several million possible SNPs predict whether a person has US with 76% accuracy indicates that CFS has a genetic component that may help to explain some aspects of the illness.	Virginia Tech, Natl Capital Reg, Arlington, VA 22209 USA; Biomind LLC, Rockville, MD USA; Ctr Dis Control & Prevent, Atlanta, GA USA	Goertzel, BN (reprint author), Virginia Tech, Natl Capital Reg, Arlington, VA 22209 USA.	ben@goertzel.org					Brown SM, 2005, MOL PSYCHIATR, V10, P884, DOI 10.1038/sj.mp.4001716; Craig AD, 2002, NAT REV NEUROSCI, V3, P655, DOI 10.1038/nrn894; Gurbaxani BM, 2006, PHARMACOGENOMICS, V7, P455, DOI 10.2217/14622416.7.3.455; Koza J. R., 1992, GENETIC PROGRAMMING; KWOK PW, 2002, SINGLE NUCL POLYMORP; LEVINSON DF, 2005, BIOL PSYCHIAT; LISTGARTEN J, 2005, CLIN CANCER RES, V10, P2725; Maloney EM, 2006, PHARMACOGENOMICS, V7, P467, DOI 10.2217/14622416.7.3.467; Mitchell T, 1997, MACHINE LEARNING; Reeves WC, 2005, BMC MED, V3, DOI 10.1186/1741-7015-3-19; SERRETTI A, 2005, NEUROPSYCHOBIOLOGY, V53, P9; Smigrodzki R, 2005, ARTIF INTELL MED, V35, P227, DOI 10.1016/j.artmed.2004.11.006; STROUS RD, 2005, NEUROSCI LETT, V393, P170; WADDELL M, 2005, P BIOKDD 05 CHIC IL	14	36	36	FUTURE MEDICINE LTD	LONDON	UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND	1462-2416		PHARMACOGENOMICS	Pharmacogenomics	APR	2006	7	3					475	483		10.2217/14622416.7.3.475		9	Pharmacology & Pharmacy	Pharmacology & Pharmacy	036LF	WOS:000237071900023	
J	Goertzel, BN; Pennachin, C; Coelho, LD; Maloney, EM; Jones, JF; Gurbaxani, B				Goertzel, BN; Pennachin, C; Coelho, LD; Maloney, EM; Jones, JF; Gurbaxani, B			Allostatic load is associated with symptoms in chronic fatigue syndrome patients	PHARMACOGENOMICS			English	Article						allostatic load; bodily pain; chronic fatigue syndrome; genetic programming; machine learning; nonlinear regression	STRESS; MACARTHUR; MARKER; HEALTH	Objectives: To further explore the relationship between chronic fatigue syndrome (CFS) and allostatic load (AL), we conducted a computational analysis involving 43 patients with CFS and 60 nonfatigued, healthy controls (NF) enrolled in a population-based case-control study in Wichita (KS, USA). We used traditional biostatistical methods to measure the association of high AL to standardized measures of physical and mental functioning, disability, fatigue and general symptom severity. We also used nonlinear regression technology embedded in machine learning algorithms to learn equations predicting various CFS symptoms based on the individual components of the allostatic load index (ALI). Methods: An ALI was computed for all study participants using available laboratory and clinical data on metabolic, cardiovascular and hypothalamic-pituitary-adrenal (HPA) axis factors. Physical and mental functioning/impairment was measured using the Medical Outcomes Study 36-item Short Form Health Survey (SF-36); current fatigue was measured using the 20-item multidimensional fatigue inventory (MFI); frequency and intensity of symptoms was measured using the 19-item symptom inventory (SI). Genetic programming, a nonlinear regression technique, was used to learn an ensemble of different predictive equations rather just than a single one. Statistical analysis was based on the calculation of the percentage of equations in the ensemble that utilized each input variable, producing a measure of the 'utility' of the variable for the predictive problem at hand. Traditional biostatistics methods include the median and Wilcoxon tests for comparing the median levels of subscale scores obtained on the SF-36, the MFI and the 51 summary score. Results: Among CFS patients, but not controls, a high level of AL was significantly associated with lower median values (indicating worse health) of bodily pain, physical functioning and general symptom frequency/intensity. Using genetic programming, the ALI was determined to be a better predictor of these three health measures than any subcombination of ALI components among cases, but not controls.	Virginia Tech, Natl Capital Reg, Arlington, VA 22209 USA; Biomind LLC, Rockville, MD USA; Ctr Dis Control & Prevent, Atlanta, GA USA	Goertzel, BN (reprint author), Virginia Tech, Natl Capital Reg, Arlington, VA 22209 USA.	ben@goertzel.org					Bergmann S, 2004, PAIN, V108, P115, DOI 10.1016/j.pain.2003.12.013; FUKUDA K, 1994, ANN INTERN MED, V121, P953; Gurbaxani BM, 2006, PHARMACOGENOMICS, V7, P455, DOI 10.2217/14622416.7.3.455; Hellhammer J, 2004, ANN NY ACAD SCI, V1032, P8, DOI 10.1193/annals.1314.002; Jones James F, 2005, Am J Med, V118, P1415; Karlamangla AS, 2002, J CLIN EPIDEMIOL, V55, P696, DOI 10.1016/S0895-4356(02)00399-2; Koza J.R., 1998, GENETIC PROGRAMMING; LIEBERMAN J, 1993, AM J MED, V95, P407, DOI 10.1016/0002-9343(93)90310-L; Maloney EM, 2006, PHARMACOGENOMICS, V7, P467, DOI 10.2217/14622416.7.3.467; McEwen BS, 1999, ANN NY ACAD SCI, V896, P30, DOI 10.1111/j.1749-6632.1999.tb08103.x; MCEWEN BS, 1993, ARCH INTERN MED, V153, P2093, DOI 10.1001/archinte.153.18.2093; Reeves WC, 2005, BMC MED, V3, DOI 10.1186/1741-7015-3-19; Seeman TE, 2001, P NATL ACAD SCI USA, V98, P4770, DOI 10.1073/pnas.081072698; Vernon SD, 2006, PHARMACOGENOMICS, V7, P345, DOI 10.2217/14622416.7.3,345; WARE JE, 2001, SF 36 PHYSICAL MENTA, P5	15	17	17	FUTURE MEDICINE LTD	LONDON	UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND	1462-2416		PHARMACOGENOMICS	Pharmacogenomics	APR	2006	7	3					485	494		10.2217/14622416.7.3.485		10	Pharmacology & Pharmacy	Pharmacology & Pharmacy	036LF	WOS:000237071900024	
J	Pham, DT; Afify, AA				Pham, DT; Afify, AA			SRI: a scalable rule induction algorithm	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART C-JOURNAL OF MECHANICAL ENGINEERING SCIENCE			English	Article						data mining; knowledge discovery; machine learning; classification learning; inductive learning; rule induction; noise handling	CLASSIFICATION PROBLEMS; ACQUISITION	Rule induction as a method for constructing classifiers is particularly attractive in data mining applications, where the comprehensibility of the generated models is very important. Most existing techniques were designed for small data sets and thus are not practical for direct use on very large data sets because of their computational inefficiency. Scaling up rule induction methods to handle such data sets is a formidable challenge. This article presents a new algorithm for rule induction that can efficiently extract accurate and comprehensible models from large and noisy data sets. This algorithm has been tested on several complex data sets, and the results prove that it scales up well and is an extremely effective learner.	Univ Cardiff Wales, Intelligent Syst Lab, Mfg Engn Ctr, Cardiff CF24 3AA, Wales	Pham, DT (reprint author), Univ Cardiff Wales, Intelligent Syst Lab, Mfg Engn Ctr, Queens Bldg,Newport Rd, Cardiff CF24 3AA, Wales.	phamdt@cardiff.ac.uk	Pham, Duc/H-1516-2011				Afify A.A., 2004, THESIS U WALES CARDI; Apte C, 1997, FUTURE GENER COMP SY, V13, P197, DOI 10.1016/S0167-739X(97)00021-6; ARONIS J, 1997, P 3 INT C KNOWL DISC; BERGADANO F, 1988, IEEE T PATTERN ANAL, V10, P555, DOI 10.1109/34.3917; Blake C. L., 1998, UCI REPOSITORY MACHI; BLOCKEEL H, 2003, ACM SIGKDD EXPLORATI, V5, P17, DOI 10.1145/959242.959246; BRAHA D, DATA MINING DESIGN M; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; CERVONE G, 2001, P 10 INT S INT INF S; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Devijver P. A., 1982, PATTERN RECOGNITION; DOMINGOS P, 1997, THESIS U CALIFORNIA; Efron B., 1993, INTRO BOOTSTRAP; FAYYAD U, 1996, P 2 INT C KNOWL DISC, P50; FAYYAD UM, ADV KNOWLEDGE DISOVE; FRANK E, 2000, THESIS U WAIKATO COM; Furnkranz J, 1997, MACH LEARN, V27, P139, DOI 10.1023/A:1007329424533; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; FURNKRANZ J, 1998, P 11 INT C ART INT A, P453; GRAEFE G, 1998, P 4 INT C KNOWL DISC; Klosgen W., 2002, HDB DATA MINING KNOW; Mehta M., 1996, P 5 INT C EXT DAT TE, P18; Michalski R. S., 1999, P INT ICSE C COMP IN, P369; Michalski RS, 1969, P 5 INT S INF PROC A, VA3, P125; MICHALSKI RS, 1986, AM ASS ARTIFICIAL IN; MICHALSKI RS, 1983, 835 ISG U ILL URB CH; MICHALSKI RS, 2001, ML1012 G MAS U; Mitchell T, 1997, MACHINE LEARNING; Mitchell T.M., 1999, COMMUN ACM, V42, P31; Mitchell TM, 1980, CBMTR117 RUTG U; MONOSTORI L, 2002, P 15 TRIENN WORLD C, P119; MUGGLETON S, 1995, FDN INDUCTIVE LOGIC; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Pham DT, 1997, P I MECH ENG B-J ENG, V211, P239, DOI 10.1243/0954405971516239; Pham DT, 2003, P I MECH ENG C-J MEC, V217, P1273, DOI 10.1243/095440603322769929; PHAM DT, 1995, J SYST ENG, V5, P115; PHAM DT, 2002, P 9 INT WORKSH SYST, P12; PHAM DT, 2004, NEW MDL BASED PRUNIN; Pham DT, 1997, PATTERN RECOGN, V30, P1137, DOI 10.1016/S0031-3203(96)00148-3; PHAM DT, 1995, EXPERT SYST APPL, V8, P59, DOI 10.1016/S0957-4174(99)80008-6; Pham DT, 2005, P I MECH ENG C-J MEC, V219, P1119, DOI 10.1243/095440605X31931; PHAM DT, 1993, ARTIF INTELL, P227; Pham DT, 2005, P I MECH ENG B-J ENG, V219, P395, DOI 10.1243/095440505X32274; PROVOST F, 1999, DATA MIN KNOWL DISC, V2, P1; Quinlan J., 1983, MACHINE LEARNING ART, V1, P463; Quinlan J.R., 1995, P 14 INT JOINT C ART, P1019; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Rastogi R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SEGAL RB, 1997, THESIS U WASHINGTON; Shafer J, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P544; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; WEBB GI, 1993, AI 94 P 6 AUSTR JOIN, P342; Webb GI, 1995, J ARTIF INTELL RES, V3, P431; Weiss G. M., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); WEISS S, 1991, P 12 2NT JOINT C ART; Ye N, 2002, COMPUT IND ENG, V43, P677, DOI 10.1016/S0360-8352(02)00132-8; [Anonymous], 1993, P 13 INT JOINT C ART, P1022; *RULEQUEST, DAT MIN TOOSL C50	61	4	4	PROFESSIONAL ENGINEERING PUBLISHING LTD	WESTMINISTER	1 BIRDCAGE WALK, WESTMINISTER SW1H 9JJ, ENGLAND	0954-4062		P I MECH ENG C-J MEC	Proc. Inst. Mech. Eng. Part C-J. Eng. Mech. Eng. Sci.	APR	2006	220	4					537	552		10.1243/09544062C18304		16	Engineering, Mechanical	Engineering	053MN	WOS:000238309300015	
J	Pham, DT; Afify, AA				Pham, DT; Afify, AA			Three new MDL-based pruning techniques for robust rule induction	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART C-JOURNAL OF MECHANICAL ENGINEERING SCIENCE			English	Article						machine learning; inductive learning; rule induction; pruning; noise handling; minimum description length principle	MINIMUM DESCRIPTION LENGTH; DECISION TREES; PRINCIPLE	Overfitting the training data is a major problem in machine learning, particularly when noise is present. Overfitting increases learning time and reduces both the accuracy and the comprehensibility of the generated rules, making learning from large data sets more difficult. Pruning is a technique widely used for addressing such problems and consequently forms an essential component of practical learning algorithms. An important class of pruning techniques is that based on the minimum description length (MDL) principle. This paper presents three new techniques using the MDL principle for pruning rule sets. An important advantage of these techniques is that all of the training data can be used for both inducing and evaluating rule sets. The performance of the techniques are evaluated using three criteria: classification accuracy, rule set complexity, and execution time. This shows that the new techniques, when incorporated into a rule induction algorithm, are more efficient and lead to accurate rule sets that are significantly smaller in size compared with the case before pruning.	Univ Cardiff Wales, Mfg Engn Ctr, Cardiff CF24 3AA, Wales	Pham, DT (reprint author), Univ Cardiff Wales, Mfg Engn Ctr, Queens Bldg,Newport Rd, Cardiff CF24 3AA, Wales.	phamdt@cardiff.ac.uk	Pham, Duc/H-1516-2011				Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Blake CL, UCI REPOSITORY MACHI; BRESLOW A, 1996, KNOWL ENG REV, V12, P1; BRUNK CA, 1991, P 8 INT WORKSH MACH, P389; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W, 1993, P 13 INT JOINT C ART, P988; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Devijver P. A., 1982, PATTERN RECOGNITION; Efron B., 1993, INTRO BOOTSTRAP; Elomaa T, 2001, J ARTIF INTELL RES, V15, P163; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; FRANK E, 2000, THESIS U WAIKATO HAM; FRANK E, 1999, REDUCED ERROR PRUNIG; FURNKARNZ J, 1994, THESIS TU WIEN; FURNKRANZ J, 1994, P 11 EUR C ART INT A, P453; Furnkranz J, 1997, MACH LEARN, V27, P139, DOI 10.1023/A:1007329424533; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; GEORGEFF MP, 1984, P 6 EUR C ART INT EC, P473; Grunwald P, 2000, J MATH PSYCHOL, V44, P133, DOI 10.1006/jmps.1999.1280; Mehta M., 1995, P 1 INT C KNOWL DISC, P216; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PFHARINGER B, 1997, P 9 EUR C MACH LEARN, P199; PFHARINGER B, 1995, THESIS TU WIEN; PHAM DT, 2004, NEW MDL BASED PRUNIN; Pham DT, 2006, P I MECH ENG C-J MEC, V220, P537, DOI 10.1243/09544062C18304; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J. R., 1995, P 12 INT C MACH LEAR, P464; Quinlan J. R., 1993, C45 PROGRAMS MACHINE; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; QUINLAN JR, P 11 INT C MACH LEAR, P233; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; ROBNIKSIKONJA M, 1998, P 13 EUR C ART INT, P455; TIRRI H, P NEUR INF PROC SYST; *RULEQUEST, 2003, DAT MIN TOOLS C5 0 P	35	1	1	PROFESSIONAL ENGINEERING PUBLISHING LTD	WESTMINISTER	1 BIRDCAGE WALK, WESTMINISTER SW1H 9JJ, ENGLAND	0954-4062		P I MECH ENG C-J MEC	Proc. Inst. Mech. Eng. Part C-J. Eng. Mech. Eng. Sci.	APR	2006	220	4					553	564		10.1243/09544062C18404		12	Engineering, Mechanical	Engineering	053MN	WOS:000238309300016	
J	Strombergsson, H; Prusis, P; Midelfart, H; Lapinsh, M; Wikberg, JES; Komorowski, J				Strombergsson, H; Prusis, P; Midelfart, H; Lapinsh, M; Wikberg, JES; Komorowski, J			Rough set-based proteochemometrics modeling of G-protein-coupled receptor-ligand interactions	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article; Proceedings Paper	19th German Conference on Bioinformatics	OCT 04-06, 2004	Bielefeld, GERMANY			drug design; QSAR; GPCRs; machine learning; rough sets; partial least squares	3-DIMENSIONAL STRUCTURE; MELANOCORTIN RECEPTORS; BIOLOGICAL PROCESS; GENE ONTOLOGY; BINDING; PEPTIDE; IDENTIFICATION; CHEMOMETRICS; MC1	G-Protein-coupled receptors (GPCRs) are among the most important drug targets. Because of a shortage of 3D crystal structures, most of the drug design for GPCRs has been ligand-based. We propose a novel, rough set-based proteochemometric approach to the study of receptor and ligand recognition. The approach is validated on three datasets containing GPCRs. In proteochemometrics, properties of receptors and ligands are used in conjunction and modeled to predict binding affinity. The rough set (RS) rule-based models presented herein consist of minimal decision rules that associate properties of receptors and ligands with high or low binding affinity. The information provided by the rules is then used to develop a mechanistic interpretation of interactions between the ligands and receptors included in the datasets. The first two datasets contained descriptors of melanocortin receptors and peptide ligands. The third set contained descriptors of adrenergic receptors and ligands. All the rule models induced from these datasets have a high predictive quality. An example of a decision rule is "If R1_ligand(Ethyl) and TM helix 2 position 27(Methionine) then Binding(High)." The easily interpretable rule sets are able to identify determinative receptor and ligand parts. For instance, all three models suggest that transmembrane helix 2 is determinative for high and low binding affinity. RS models show that it is possible to use rule-based models to predict ligand-binding affinities. The models may be used to gain a deeper biological understanding of the combinatorial nature of receptor-ligand interactions.	Uppsala Univ, Linnaeus Ctr Bioinformat, SE-75124 Uppsala, Sweden; Uppsala Univ, Dept Pharmaceut Biosci, SE-75124 Uppsala, Sweden; Norwegian Univ Sci & Technol, Dept Biol, N-7034 Trondheim, Norway	Wikberg, JES (reprint author), Uppsala Univ, Linnaeus Ctr Bioinformat, Box 598, SE-75124 Uppsala, Sweden.	jarl.wikberg@farmbio.uu.se; jan.komorowski@lcb.uu.se	Komorowski, Jan/A-9175-2010				Bajorath Jürgen, 2002, Nat Rev Drug Discov, V1, P882, DOI 10.1038/nrd941; Cavasotto CN, 2003, PROTEINS, V51, P423, DOI 10.1002/prot.10362; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; HACID MH, 2003, LIMOS TECHNICAL REPO; Hamaguchi N, 1998, BIOCHEMISTRY-US, V37, P5730, DOI 10.1021/bi972733a; HANLEY JA, 1982, RADIOLOGY, V143, P29; HOLLAND JH, 1962, J ACM, V9, P297, DOI 10.1145/321127.321128; Horn F, 1998, NUCLEIC ACIDS RES, V26, P275, DOI 10.1093/nar/26.1.275; Hvidsten TR, 2005, GENOME RES, V15, P856, DOI 10.1101/gr.3760605; Hvidsten TR, 2003, BIOINFORMATICS, V19, P1116, DOI 10.1093/bioinformatics/btg047; Hvidsten TR, 2003, BIOINFORMATICS, V19, pII81, DOI 10.1093/bioinformatics/btg1064; Johnson D. S., 1973, APPROXIMATION ALGORI; Klabunde Thomas, 2002, Chembiochem, V3, P928, DOI 10.1002/1439-7633(20021004)3:10<928::AID-CBIC928>3.0.CO;2-5; Komorouski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; Laegreid A, 2003, GENOME RES, V13, P965, DOI 10.1101/gr.1144503; Lapinsh M, 2001, BBA-GEN SUBJECTS, V1525, P180, DOI 10.1016/S0304-4165(00)00187-2; Muceniece R, 2001, BBA-PROTEIN STRUCT M, V1544, P278, DOI 10.1016/S0167-4838(00)00227-2; OHRN A, 1998, STUDIES FUZZINESS SO, V18, P376; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1991, ROUGH SETS THEORETIC; Piascik MT, 2001, J PHARMACOL EXP THER, V298, P403; Prusis P, 1997, J MOL GRAPH MODEL, V15, P307, DOI 10.1016/S1093-3263(98)00004-7; Prusis P, 2001, BBA-PROTEIN STRUCT M, V1544, P350, DOI 10.1016/S0167-4838(00)00249-1; Prusis P, 2002, PROTEIN ENG, V15, P305, DOI 10.1093/protein/15.4.305; Baldwin JM, 1997, J MOL BIOL, V272, P144, DOI 10.1006/jmbi.1997.1240; Schioth HB, 1998, MOL PHARMACOL, V54, P154; STROMBERGSSON H, 2004, P GERM C BIO 2004 OC; Szardenings M, 1997, J BIOL CHEM, V272, P27943, DOI 10.1074/jbc.272.44.27943; Varady J, 2003, J MED CHEM, V46, P4377, DOI 10.1021/jm030085p; Wikberg JES, 1999, EUR J PHARMACOL, V375, P295, DOI 10.1016/S0014-2999(99)00298-8	30	15	16	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0887-3585		PROTEINS	Proteins	APR 1	2006	63	1					24	34		10.1002/prot.20777		11	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	023NM	WOS:000236133500004	
J	Flikka, K; Martens, L; Vandekerckhoe, J; Gevaert, K; Eidhammer, I				Flikka, K; Martens, L; Vandekerckhoe, J; Gevaert, K; Eidhammer, I			Improving the reliability and throughput of mass spectrometry-based proteomics by spectrum quality filtering	PROTEOMICS			English	Article						peptide-centric proteomics; protein identification; spectrum quality; tandem mass spectrometry	PROTEIN IDENTIFICATION; PEPTIDES; DATABASE; SEQUEST	In contemporary peptide-centric or non-gel proteome studies, vast amounts of peptide fragmentation data are generated of which only a small part leads to peptide or protein identification. This motivates the development and use of a filtering algorithm that removes spectra that contribute little to protein identification. Removal of unidentifiable spectra reduced both the amount of computational and human time spent on analyzing spectra as well as the chances of obtaining false identifications. Thorough testing on various proteome datasets from different instruments showed that the best suggested machine-learning classifier is, on average, able to recognize half of the unidentified spectra as bad spectra. Further analyses showed that several unidentified spectra classified as good were derived from peptides carrying unanticipated amino acid modifications or contained sequence tags that allowed peptide identification using homology searches. The implementation of the classifiers is available under the GNU General Public License at http://www.bioinfo.no/software/spectrumquality.	Univ Bergen, Berden Ctr Computat Sci, Computat Biol Unit, N-5008 Bergen, Norway; Univ Bergen, Proteom Unit, Bergen, Norway; Univ Bergen, Dept Informat, Bergen, Norway; State Univ Ghent VIB, Dept Med Prot Res, B-9000 Ghent, Belgium; State Univ Ghent VIB, Dept Biochem, B-9000 Ghent, Belgium	Flikka, K (reprint author), Univ Bergen, Berden Ctr Computat Sci, Computat Biol Unit, Hoeyteknologisenteret,Thormoehlensgate 55, N-5008 Bergen, Norway.	flikka@ii.uib.no	Martens, Lennart/E-8816-2010; Gevaert, Kris/H-3637-2013	Martens, Lennart/0000-0003-4277-658X; Gevaert, Kris/0000-0002-4237-0283			Beer I, 2004, PROTEOMICS, V4, P950, DOI 10.1002/pmic.200300652; Bern Marshall, 2004, Bioinformatics, V20 Suppl 1, pi49, DOI 10.1093/bioinformatics/bth947; Carr S, 2004, MOL CELL PROTEOMICS, V3, P531, DOI 10.1074/mcp.T400006-MCP200; Creasy DM, 2004, PROTEOMICS, V4, P1534, DOI 10.1002/pmic.200300744; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Geoghegan KF, 2002, J PROTEOME RES, V1, P181, DOI 10.1021/pr025503d; Gevaert K, 2002, MOL CELL PROTEOMICS, V1, P896, DOI 10.1074/mcp.M200061-MCP200; Gevaert K, 2003, NAT BIOTECHNOL, V21, P566, DOI 10.1038/nbt810; GEVAERT K, 2004, DDT TARGETS, V3, pS16; Holmes G., 1994, Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems (Cat. No.94TH8019), DOI 10.1109/ANZIIS.1994.396988; Keogh E. J., 1999, P 7 INT WORKSH ART I, P225; Kersey PJ, 2004, PROTEOMICS, V4, P1985, DOI 10.1002/pmic.200300721; Langley P., 1992, P 10 NAT C ART INT, P223; Liu HB, 2004, ANAL CHEM, V76, P4193, DOI 10.1021/ac0498563; MacCoss MJ, 2002, ANAL CHEM, V74, P5593, DOI 10.1021/ac025826t; Martens L, 2005, PROTEOMICS, V5, P3537, DOI 10.1002/pmic.200401303; Martens L, 2005, PROTEOMICS, V5, P3193, DOI 10.1002/pmic.200401142; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Purvine S, 2004, OMICS, V8, P255, DOI 10.1089/omi.2004.8.255; QUINIAN JR, 1993, C4 5 PROGRAMS MACHIN; Sadygov RG, 2004, NAT METHODS, V1, P195, DOI 10.1038/NMETH725; Tabb DL, 2003, ANAL CHEM, V75, P2470, DOI 10.1021/ac026424o; Tabb DL, 2001, PRIN PRACT, P125; Taylor JA, 2001, ANAL CHEM, V73, P2594, DOI 10.1021/ac001196o; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; WITTEN IH, 1999, DATA MINING PRACTICA, P91; Zhang H, 2004, CURR OPIN CHEM BIOL, V8, P66, DOI 10.1016/j.cbpa.2003.12.001; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	32	45	46	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853		PROTEOMICS	Proteomics	APR	2006	6	7					2086	2094		10.1002/pmic.200500309		9	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	033EL	WOS:000236829300007	
J	Birattari, M; Zlochin, M; Dorigo, M				Birattari, Mauro; Zlochin, Mark; Dorigo, Marco			Towards a theory of practice in metaheuristics design: A machine learning perspective	RAIRO-THEORETICAL INFORMATICS AND APPLICATIONS			English	Article							OPTIMIZATION; ALGORITHMS; SYSTEM; COLONY	A number of methodological papers published during the last years testify that a need for a thorough revision of the research methodology is felt by the operations research community - see, for example, [Barr et al., J. Heuristics 1 (1995) 9-32; Eiben and Jelasity, Proceedings of the 2002 Congress on Evolutionary Computation (CEC'2002) 582-587; Hooker, J. Heuristics 1 (1995) 33-42; Rardin and Uzsoy, J. Heuristics 7 (2001) 261-304]. In particular, the performance evaluation of nondeterministic methods, including widely studied metaheuristics such as evolutionary computation and ant colony optimization, requires the definition of new experimental protocols. A careful and thorough analysis of the problem of evaluating metaheuristics reveals strong similarities between this problem and the problem of evaluating learning methods in the machine learning field. In this paper, we show that several conceptual tools commonly used in machine learning - such as, for example, the probabilistic notion of class of instances and the separation between the training and the testing datasets - fit naturally in the context of metaheuristics evaluation. Accordingly, we propose and discuss some principles inspired by the experimental practice in machine learning for guiding the performance evaluation of optimization algorithms. Among these principles, a clear separation between the instances that are used for tuning algorithms and those that are used in the actual evaluation is particularly important for a proper assessment.	Univ Libre Brussels, IRIDIA, Brussels, Belgium	Birattari, M (reprint author), Univ Libre Brussels, IRIDIA, Brussels, Belgium.	mbiro@ulb.ac.be; mzlochin@ulb.ac.be; mdorigo@ulb.ac.be	Birattari, Mauro/D-2597-2009; Dorigo, Marco/B-5664-2013	Dorigo, Marco/0000-0002-3971-0507			Barr R. S., 1995, Journal of Heuristics, V1, DOI 10.1007/BF02430363; Birattari M., 2002, P GEN EV COMP C GECC, P11; Birattari M., 2004, THESIS U LIBRE BRUXE; DEMENAGE M, 1998, THEORET COMPUT SCI, V209, P107; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; Dorigo M., 2004, ANT COLONY OPTIMIZAT; Dorigo M, 1999, NEW IDEAS OPTIMIZATI, P11; Dorigo M, 2005, THEOR COMPUT SCI, V344, P243, DOI 10.1016/j.tcs.2005.05.020; Dorigo M, 1999, ARTIF LIFE, V5, P137, DOI 10.1162/106454699568728; Eiben A. E., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1006991; Fogel L. J., 1966, ARTIFICIAL INTELLIGE; Garey MR, 1979, COMPUTERS INTRACTABI; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1989, ORSA Journal on Computing, V1; Goldberg DE, 1989, GENETIC ALGORITHMS S; Hassin R, 2001, J ALGORITHMS, V41, P429, DOI 10.1006/jagm.2001.1187; Holland J., 1975, ADAPTATION NATURAL A; Hooker J. N., 1995, Journal of Heuristics, V1, DOI 10.1007/BF02430364; Johnson RH, 1915, J HERED, V6, P250; Kauffman S. A., 1993, ORIGINS ORDER SELF O; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Liang KH, 2001, APPL INTELL, V15, P171, DOI 10.1023/A:1011286929823; LOURENCO HR, 2002, HDB METAHEURISTICS I, V57, P321; Luenberger DG, 1973, INTRO LINEAR NONLINE; Maron O., 1994, ADV NEURAL INFORMATI, V6, P59; MCGEOGH CC, 1996, INFORMS J COMPUT, V2, P1; Michalewicz Z., 2000, SOLVE IT MODERN HEUR; MOORE AW, 1994, INT C MACH LEARN, P190; Nelson BL, 2001, OPER RES, V49, P950, DOI 10.1287/opre.49.6.950.10019; Rardin RL, 2001, J HEURISTICS, V7, P261, DOI 10.1023/A:1011319115230; Rechenberg I., 1973, EVOLUTIONSSTRATEGIE; Schwefel H.-P., 1981, NUMERICAL OPTIMIZATI; Sommerville I, 2001, SOFTWARE ENG; TOUSSAINT M, 2001, IRINI200105 RUHR U B; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; ZEMEL E, 1981, MATH OPER RES, V6, P319, DOI 10.1287/moor.6.3.319; ZLOCHIN M, 2002, PARALLEL PROBLEM SOL, V7, P651; Zlochin M., 2004, ANN OPER RES, V131, P375	38	6	6	EDP SCIENCES S A	LES ULIS CEDEX A	17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE	0988-3754		RAIRO-THEOR INF APPL	Rairo-Theor. Inform. Appl.	APR-JUN	2006	40	2					353	369		10.1051/ita:2006009		17	Computer Science, Information Systems	Computer Science	074CQ	WOS:000239790500016	
J	Laxman, S; Sastry, PS				Laxman, S; Sastry, PS			A survey of temporal data mining	SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES			English	Article; Proceedings Paper	Meeting on Machine Learning	SEP, 2005	Bangalore, INDIA			temporal data mining; ordered data streams; temporal interdependency; pattern discovery	HIDDEN MARKOV-MODELS; ASSOCIATION RULES; TIME-SERIES; FREQUENT EPISODES; NEURAL NETWORKS; EVENT PATTERNS; SEQUENCE; CLASSIFICATION; RECOGNITION; ALIGNMENT	Data mining, is concerned with analysing large volumes of (often unstructured) data to automatically discover interesting, regularities or relationships which in turn lead to better understanding of the underlying processes. The field of temporal data mining is concerned with such analysis in the case of ordered data streams with temporal interdependencies. Over the last decade many interesting techniques of temporal data mining were proposed and shown to be useful in many applications. Since temporal data-mining brings together techniques from different fields such as statistics, machine learning and databases, the literature is scattered among many different sources. In this article, we present an overview of techniques of temporal data mining. We mainly concentrate on algorithms for pattern discovery in sequential data streams. We also describe some recent results regarding, statistical analysis of pattern discovery methods.	Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Laxman, S (reprint author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.	srivats@ee.iisc.ernet.in; sastry@ee.iisc.ernet.in					AGRAWAL R, 1995, P 11 INT C DAT ENG W; Agrawal R., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072; Agrawal R., 1994, P 20 INT C VER LARG, P487; Agrawal R., 1995, P 21 INT C VER LARG, P490; Agrawal R., 1995, P 21 INT C VER LARG; ALON J, 2003, P 2003 IEEE COMP SOC; ALUR R, 1994, THEOR COMPUT SCI, V126, P183, DOI 10.1016/0304-3975(94)90010-8; Atallah MJ, 2004, P 4 IEEE INT C DAT M, P3; BAEZAYATES RA, 1991, THEOR COMPUT SCI, V78, P363, DOI 10.1016/0304-3975(91)90358-9; BALDI P, 1994, P NATL ACAD SCI USA, V91, P1059, DOI 10.1073/pnas.91.3.1059; BENDER EA, 1993, EUR J COMBIN, V14, P265, DOI 10.1006/eujc.1993.1030; BERBERIDIS C, 2002, LECT NOTES COMPUTER, V2431, P51; Bettini C, 1998, IEEE T KNOWL DATA EN, V10, P222, DOI 10.1109/69.683754; Box G.E.P., 1994, TIME SERIES ANAL; CADEZ I, 2000, 927173425 U CAL DEP; CAO H, 2004, P 8 PAC AS C KNOWL D, P653; Casas-Garriga G, 2003, P 7 EUR C PRINC PRAC, P83; Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602; Chatfield Chris, 1996, ANAL TIME SERIES; Chudova D., 2002, P 8 ACM SIGKDD INT C; Cohen J, 2004, ACM COMPUT SURV, V36, P122, DOI 10.1145/1031120.1031122; CORPET F, 1988, NUCLEIC ACIDS RES, V16, P10881, DOI 10.1093/nar/16.22.10881; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), DOI 10.1109/CVPR.1993.341109; DIETTERICH TG, 1985, ARTIF INTELL, V25, P187, DOI 10.1016/0004-3702(85)90003-7; Duda R.O., 1997, PATTERN CLASSIFICATI; Durbin R, 1998, BIOL SEQUENCE ANAL; Ewens W.J., 2001, STAT METHODS BIOINFO; Fadili MJ, 2000, HUM BRAIN MAPP, V10, P160, DOI 10.1002/1097-0193(200008)10:4<160::AID-HBM20>3.0.CO;2-U; Flajolet P, 2001, LECT NOTES COMPUT SC, V2076, P152; Frenkel K. A., 1991, Communications of the ACM, V34, DOI 10.1145/125490.125492; Garofalakis M, 2002, IEEE T KNOWL DATA EN, V14, P530, DOI 10.1109/TKDE.2002.1000341; GHIAS A, 1995, P ACM MULT 95 SAN FR; Gold B., 2000, SPEECH AUDIO SIGNAL; GRAY RM, 1980, IEEE T ACOUST SPEECH, V28, P367, DOI 10.1109/TASSP.1980.1163421; Gusfield Dan, 1997, ALGORITHMS STRINGS T; GWADERA R, 2005, P 2005 SIAM INT C DA; Gwadera R, 2003, P 3 IEEE INT C DAT M, P67; Han J., 2001, DATA MINING CONCEPTS; Han J, 1998, P 4 INT C KNOWL DISC, P214; Han JW, 1999, PROC INT CONF DATA, P106; Hand D., 2001, PRINCIPLES DATA MINI; Haselsteiner E, 2000, IEEE T REHABIL ENG, V8, P457, DOI 10.1109/86.895948; Hastie T, 2001, ELEMENTS STAT LEARNI; Haykin S., 1992, NEURAL NETWORKS COMP; HIRAO M, 2001, LECT NOTES ARTIF INT, V2226, P435; Juang B., 1993, FUNDAMENTALS SPEECH; KALPAKIS K, 2001, 2001 IEEE INT C DAT; Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347153; Koskela T., 1996, P WORLD C NEUR NETW, P491; KRUSKAL JB, 1983, SIAM REV, V25, P201, DOI 10.1137/1025045; Kundu A., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), DOI 10.1109/CVPR.1988.196275; LAW MH, 2000, P IEEE INT C PATT RE; Laxman S, 2005, IEEE T KNOWL DATA EN, V17, P1505; LAXMAN S, 2004, CL200404MSR GM R D C; LAXMAN S, 2002, TEMP DAT MIN WORKSH; LAXMAN S, 2004, P 3 WORKSH MIN TEMP; Lee CH, 2003, IEEE T KNOWL DATA EN, V15, P1004; Levenshtein V., 1966, SOV PHYS DOKL, V10, P707; LIN MY, 2003, P IEEE 36 ANN HAW IN; Ma S, 2001, PROC INT CONF DATA, P205; MANNILA H, 2001, 1 SIAM INT C DAT MIN; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351; MEGER N, 2004, P 8 EUR C PRINC PRAC; Miller RT, 1999, GENOME RES, V9, P1143, DOI 10.1101/gr.9.11.1143; Miller W., 1994, IEEE Computational Science and Engineering, V1, DOI 10.1109/99.295375; NAG R, 1986, P ICASSP 86, P2071; Nalwa VS, 1997, P IEEE, V85, P215, DOI 10.1109/5.554220; Ng R., 1998, P 1998 ACM SIGMOD IN, P13, DOI 10.1145/276304.276307; Oates T., 2001, LECT NOTES COMPUTER, V1828, P35; Osato N, 2002, GENOME RES, V12, P1127, DOI [10.1101/gr.75202, 10.1101/gr.75202. Article published online before print in June 2002]; OSHAUGHNESSY D, 2003, SPEECH COMMUNICATION; Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804; Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398; PERNG CS, 2000, 16 INT C DAT ENG, P33; PEVZNER PA, 1989, J BIOMOL STRUCT DYN, V6, P1013; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Regnier M, 1998, ALGORITHMICA, V22, P631, DOI 10.1007/PL00009244; Schreiber T, 1997, PHYS REV LETT, V79, P1475, DOI 10.1103/PhysRevLett.79.1475; SCLAROFF S, 2001, LECT NOTES COMPUTER; Sebastiani P, 1999, LECT NOTES COMPUT SC, V1642, P199; Shintani T., 1998, P 2 PAC AS C KNOWL D, P283; Smyth P., 2001, DATA MINING SCI ENG; Smyth P, 1997, ADV NEUR IN, V9, P648; SRIKANTH R, 1996, P 5 INT C EXT DAT TE; STARNER TE, 1995, P 1995 INT WORKSH FA; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Sze S H, 2002, Pac Symp Biocomput, P235; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; TINO P, 2000, TEMPORAL PATTERN REC; TRONICEK Z, 2001, LECT NOTES COMPUTER, V2089, P143; WAN EA, 1990, IEEE INT JOINT C NEU, V1, P575; Wang J, 2004, 20 INT C DAT ENG BOS; Wang JT-L, 1994, P 1994 ACM SIGMOD IN, P115, DOI 10.1145/191839.191863; Witten I. H., 2000, DATA MINING PRACTICA; WU C, 1995, MACH LEARN, V21, P177, DOI 10.1007/BF00993384; WU S, 1992, COMMUN ACM, V35, P83, DOI 10.1145/135239.135244; Wu Y. L., 2000, P 9 ACM CIKM INT C I, P488, DOI 10.1145/354756.354857; Xiong YM, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P717; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), DOI 10.1109/CVPR.1992.223161; YAN X, 2003, P 2003 INT SIAM C DA; YULE GU, 1927, PHIL T, pA226; ZAKI MJ, 1998, P ACM 7 INT C INF KN	102	39	40	INDIAN ACADEMY SCIENCES	BANGALORE	C V RAMAN AVENUE, SADASHIVANAGAR, P B #8005, BANGALORE 560 080, INDIA	0256-2499		SADHANA-ACAD P ENG S	Sadhana-Acad. Proc. Eng. Sci.	APR	2006	31		2				173	198		10.1007/BF02719780		26	Engineering, Multidisciplinary	Engineering	046WM	WOS:000237841800007	
J	Wahba, G				Wahba, G			A statistician thinks about machine learning	STATISTICA SINICA			English	Editorial Material									Univ Wisconsin, Madison, WI 53706 USA	Wahba, G (reprint author), Univ Wisconsin, 716 Langdon St, Madison, WI 53706 USA.							0	0	0	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405		STAT SINICA	Stat. Sin.	APR	2006	16	2					305	306				2	Statistics & Probability	Mathematics	043GH	WOS:000237587700001	
J	Lafferty, J; Wasserman, L				Lafferty, J; Wasserman, L			Challenges in statistical machine learning	STATISTICA SINICA			English	Editorial Material							CLASSIFICATION; REGRESSION; VARIABLES; BOUNDS; LASSO		Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Machine Learning Dept, PhD Program Computat & Stat Learning, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Machine Learning Dept, Sch Comp Sci, Pittsburgh, PA 15213 USA	Lafferty, J (reprint author), Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.						Alekhnovich M., 2004, Proceedings. 45th Annual IEEE Symposium on Foundations of Computer Science; ALTUN Y, 2004, P 21 INT C MACH LEAR, P1; AUDIBERT JY, 2005, PMA998 LAB PROB; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; BELKIN M, 2002, TR200212 U CHIC DEP; BOYKOV Y, 2001, IEEE T PATTERN ANAL, V23, P1; BUHLMANN P, 2006, IN PRESS ANN STAT, V34; Castelli V., 1996, IEEE T INFORM THEORY, V42, P2101; Chapelle O, 2003, ADV NEURAL INFORM PR, P585; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; Donoho D. L., 2004, MOST LARGE UNDERDETE; Doyle P. G., 1984, RANDOM WALKS ELECT N; ELCHANAN M, 2004, J COMPUT SYST SCI, V69, P421; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Kearns M, 1998, J ACM, V45, P983, DOI 10.1145/293347.293351; Kerkyacharian G, 2001, PROBAB THEORY REL, V121, P137, DOI 10.1007/PL00008800; KIVINEN J, 1997, J INFORMATION COMPUT, V132, P1; Kivinen J, 1997, ARTIF INTELL, V97, P325, DOI 10.1016/S0004-3702(97)00039-8; Knight K, 2000, ANN STAT, V28, P1356; Kumar S, 2004, ADV NEUR IN, V16, P1531; KUSHILEVITZ E, 1993, SIAM J COMPUT, V22, P1331, DOI 10.1137/0222080; LAFFERTY J, 2005, RODEO SPARSE NONPARA; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Lepski OV, 1997, ANN STAT, V25, P929; Lepski OV, 1997, ANN STAT, V25, P2512; LINIAL N, 1993, J ACM, V40, P607, DOI 10.1145/174130.174138; McCallum A., 2003, P 19 C UNC ART INT U, P403; Pinto D., 2003, P 26 ANN INT ACM SIG, P235; PITT L, 1988, J ACM, V35, P965, DOI 10.1145/48014.63140; RUPPERT D, 1994, ANN STAT, V22, P1346, DOI 10.1214/aos/1176325632; SCOTT C, 2006, IN PRESS IEEE T INFO; Sha F, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P213; SHEN X, 2006, IN PRESS ANN STAT; Smola A., 2003, P 16 ANN C LEARN THE, P144; Taskar B, 2004, ADV NEUR IN, V16, P25; Tewari A, 2005, LECT NOTES COMPUT SC, V3559, P143, DOI 10.1007/11503415_10; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WAINWRIGHT M, 2003, 649 U CAL DEP STAT; ZHANG H, 2005, J AM STAT ASSOC, V99, P659; Zhu X., 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663	45	9	9	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405		STAT SINICA	Stat. Sin.	APR	2006	16	2					307	321				15	Statistics & Probability	Mathematics	043GH	WOS:000237587700002	
J	Lin, Y; Yuan, M				Lin, Y; Yuan, M			Convergence rates of compactly supported radial basis function regularization	STATISTICA SINICA			English	Article						rnethod of regularization; nonparametric estimation; radial basis functions; rate of convergence; reproducing kernel	GENERALIZED CROSS-VALIDATION; ASYMPTOTIC EQUIVALENCE; VECTOR MACHINES; WHITE-NOISE; INTERPOLATION; REGRESSION; OPTIMALITY; NETWORKS; CL	Regularization with radial basis functions is an effective method in many machine learning applications. In recent years classes of radial basis functions with compact support have been proposed in the approximation theory literature and have become more and more popular due to their computational advantages. In this paper we study the statistical properties of the method of regularization with compactly supported basis functions. We consider three popular classes of compactly supported radial basis functions. In the setting of estimating a periodic function in a white noise problem, we show that regularization with (periodized) compactly supported radial basis functions is rate optimal and adapts to unknown smoothness tip to an order related to the radial basis function used. Due to results on equivalence of the white noise model with many important models including regression and density estimation, our results are Expected to give insight on the performance of such methods in more general settings than the white noise model.	Univ Wisconsin, Dept Stat, Madison, WI 53706 USA; Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA	Lin, Y (reprint author), Univ Wisconsin, Dept Stat, 1300 Univ Ave, Madison, WI 53706 USA.	yilin@stat.wisc.edu; myuan@isye.gatech.edu					BUHMANN MD, 2003, RADIAL BASIC FUNCTIO; Buhmann MD, 1998, P EDINBURGH MATH SOC, V41, P33; Buhmann MD, 2000, MATH COMPUT, V70, P307, DOI 10.1090/S0025-5718-00-01251-5; Cavalier L, 2002, ANN STAT, V30, P843; Cristianini N., 2000, INTRO SUPPORT VECTOR; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Floater MS, 1996, J COMPUT APPL MATH, V73, P65, DOI 10.1016/0377-0427(96)00035-0; FURRER R, 2005, COVARIANCE TAPERING; Gaspari G, 1999, Q J ROY METEOR SOC, V125, P723, DOI 10.1256/smsqj.55416; GIROSI F, 1993, 1430 MIT; Gneiting T, 2002, J MULTIVARIATE ANAL, V83, P493, DOI 10.1006/jmva.2001.2056; GOLUBEV G, 1998, ASYMPTOTIC EQUIVALEN; GRAMA I, 1997, ASYMPTOTIC EQUIVALEN; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; KNEIP A, 1994, ANN STAT, V22, P835, DOI 10.1214/aos/1176325498; LI KC, 1986, ANN STAT, V14, P1101, DOI 10.1214/aos/1176350052; LI KC, 1987, ANN STAT, V15, P958, DOI 10.1214/aos/1176350486; Lin Y, 2004, ANN STAT, V32, P1723, DOI 10.1214/009053604000000454; Nussbaum M, 1996, ANN STAT, V24, P2399; Schaback R., 2001, MULTIVARIATE APPROXI, P1, DOI 10.1017/CBO9780511569616.002; Schaltegger S., 1997, BUSINESS STRATEGY EN, V6, P1, DOI 10.1002/(SICI)1099-0836(199702)6:1<1::AID-BSE84>3.0.CO;2-D; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Wahba G., 1990, SPLINE MODELS OBSERV; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; Wendland H., 1995, Advances in Computational Mathematics, V4, DOI 10.1007/BF02123482; Wendland H, 1998, J APPROX THEORY, V93, P258, DOI 10.1006/jath.1997.3137; Williamson RC, 2001, IEEE T INFORM THEORY, V47, P2516, DOI 10.1109/18.945262; Wu Z, 1995, ADV COMPUT MATH, V4, P283; Zhang H., 2004, COMPACTLY SUPPORTED; Brown LD, 1996, ANN STAT, V24, P2384	30	1	1	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405		STAT SINICA	Stat. Sin.	APR	2006	16	2					425	439				15	Statistics & Probability	Mathematics	043GH	WOS:000237587700008	
J	Shi, T; Yu, B				Shi, T; Yu, B			Binning in Gaussian kernel regularization	STATISTICA SINICA			English	Article						asymptotic minimax risk; binning; Gaussian kernel; rate of convergence; regularization; Sobolev space; support vector machines	SUPPORT VECTOR MACHINES; NETWORKS	Gaussian kernel regularization is widely used in the machine learning literature and has proved successful in many empirical experiments. The periodic version of Gaussian kernel regularization has been shown to be minimax rate optimal in estimating functions in any finite order Sobolev space. However, for a data set with n points, the computation complexity of the Gaussian kernel regularization method is of order O(n(3)). In this paper we propose to use binning to reduce the computation of Gaussian kernel regularization in both regression and classification. For periodic Gaussian kernel regression, we show that the binned estimator achieves the same minimax rates as the unbinned estimator, but the computation is reduced to O(n(3)) with m as the number of bins. To achieve the minimax rate in the kth order Sobolev space, m needs to be in the order of O(kn(1)/((2k+1))), which makes the binned estimator computation of order O(n) for k = 1, and even less for larger k. Our simulations show that the binned estimator (binning 120 data points into 20 bins in our simulation) provides almost the same accuracy with only 0.4% of computation time. For classification, binning with L2-loss Gaussian kernel regularization and Gaussian kernel Support Vector Machines is tested in a polar cloud detection problem.	Ohio State Univ, Dept Stat, Columbus, OH 43210 USA; Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Shi, T (reprint author), Ohio State Univ, Dept Stat, 1958 Neil Ave,404 Cockins Hall, Columbus, OH 43210 USA.	taoshi@stat.ohio-state.edu; binyu@stat.berkeley.edu					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Buhlmann P, 2002, ANN STAT, V30, P927; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; FENG G, 2001, OPTIMIZATION METHODS; GIROSI F, 1993, 1430 MIT ART INT LAB; Hall P, 1998, BIOMETRIKA, V85, P469, DOI 10.1093/biomet/85.2.469; JOHNSTONE IM, 1998, FUNCTION ESTIMATION; Lin Y, 2004, ANN STAT, V32, P1723, DOI 10.1214/009053604000000454; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; SHI T, 2004, 663 U CAL DEP STAT; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Vapnik V. N, 1995, NATURE STAT LEARNING; Wahba G, 1999, ADV LARGE MARGIN CLA; Wahba G., 1990, SPLINE MODELS OBSERV; WILLIAMS C, 2000, INT C MACH LEARN, V17, P1159; Williamson RC, 2001, IEEE T INFORM THEORY, V47, P2516, DOI 10.1109/18.945262; Brown LD, 1996, ANN STAT, V24, P2384	17	2	2	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405		STAT SINICA	Stat. Sin.	APR	2006	16	2					541	567				27	Statistics & Probability	Mathematics	043GH	WOS:000237587700014	
J	Petrovic, S				Petrovic, S			Special issue section on Expert Systems and Machine Learning	JOURNAL OF SCHEDULING			English	Editorial Material																	0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1094-6136		J SCHED	J. Sched.	APR	2006	9	2					95	96		10.1007/s10951-006-6773-0		2	Engineering, Manufacturing; Operations Research & Management Science	Engineering; Operations Research & Management Science	032RS	WOS:000236793000001	
J	Krogan, NJ; Cagney, G; Yu, HY; Zhong, GQ; Guo, XH; Ignatchenko, A; Li, J; Pu, SY; Datta, N; Tikuisis, AP; Punna, T; Peregrin-Alvarez, JM; Shales, M; Zhang, X; Davey, M; Robinson, MD; Paccanaro, A; Bray, JE; Sheung, A; Beattie, B; Richards, DP; Canadien, V; Lalev, A; Mena, F; Wong, P; Starostine, A; Canete, MM; Vlasblom, J; Wu, S; Orsi, C; Collins, SR; Chandran, S; Haw, R; Rilstone, JJ; Gandi, K; Thompson, NJ; Musso, G; St Onge, P; Ghanny, S; Lam, MHY; Butland, G; Altaf-Ui, AM; Kanaya, S; Shilatifard, A; O'Shea, E; Weissman, JS; Ingles, CJ; Hughes, TR; Parkinson, J; Gerstein, M; Wodak, SJ; Emili, A; Greenblatt, JF				Krogan, NJ; Cagney, G; Yu, HY; Zhong, GQ; Guo, XH; Ignatchenko, A; Li, J; Pu, SY; Datta, N; Tikuisis, AP; Punna, T; Peregrin-Alvarez, JM; Shales, M; Zhang, X; Davey, M; Robinson, MD; Paccanaro, A; Bray, JE; Sheung, A; Beattie, B; Richards, DP; Canadien, V; Lalev, A; Mena, F; Wong, P; Starostine, A; Canete, MM; Vlasblom, J; Wu, S; Orsi, C; Collins, SR; Chandran, S; Haw, R; Rilstone, JJ; Gandi, K; Thompson, NJ; Musso, G; St Onge, P; Ghanny, S; Lam, MHY; Butland, G; Altaf-Ui, AM; Kanaya, S; Shilatifard, A; O'Shea, E; Weissman, JS; Ingles, CJ; Hughes, TR; Parkinson, J; Gerstein, M; Wodak, SJ; Emili, A; Greenblatt, JF			Global landscape of protein complexes in the yeast Saccharomyces cerevisiae	NATURE			English	Article							INTERACTION NETWORK; MASS-SPECTROMETRY; RNA-POLYMERASES; GENOME; SCALE; METHYLATION; EXPRESSION; GENES; IDENTIFICATION; LOCALIZATION	Identification of protein - protein interactions often provides insight into protein function, and many cellular processes are performed by stable protein complexes. We used tandem affinity purification to process 4,562 different tagged proteins of the yeast Saccharomyces cerevisiae. Each preparation was analysed by both matrix-assisted laser desorption/ ionization - time of flight mass spectrometry and liquid chromatography tandem mass spectrometry to increase coverage and accuracy. Machine learning was used to integrate the mass spectrometry scores and assign probabilities to the protein - protein interactions. Among 4,087 different proteins identified with high confidence by mass spectrometry from 2,357 successful purifications, our core data set ( median precision of 0.69) comprises 7,123 protein - protein interactions involving 2,708 proteins. A Markov clustering algorithm organized these interactions into 547 protein complexes averaging 4.9 subunits per complex, about half of them absent from the MIPS database, as well as 429 additional interactions between pairs of complexes. The data ( all of which are available online) will help future studies on individual proteins as well as functional genomics and systems biology.	Univ Toronto, Banting & Best Dept Med Res, Terrence Donnelly Ctr Cellular & Biomol Res, Toronto, ON M5S 3E1, Canada; Univ Toronto, Dept Med Genet & Microbiol, Toronto, ON M5S 1A8, Canada; Natl Univ Ireland Univ Coll Dublin, Conway Inst, Dublin 4, Ireland; Yale Univ, Dept Mol Biophys & Biochem, New Haven, CT 06520 USA; Hosp Sick Children, Toronto, ON M4K 1X8, Canada; Affinium Pharmaceut, Toronto, ON M5J 1V6, Canada; Univ Calif San Francisco, Howard Hughes Med Inst, Dept Mol & Cellular Pharmacol, San Francisco, CA 94143 USA; Nara Inst Sci & Technol, Comparat Genom Lab, Nara 6300101, Japan; St Louis Univ, Sch Med, Dept Biochem, St Louis, MO 63104 USA; Harvard Univ, Howard Hughes Med Inst, Dept Mol & Cellular Biol, Cambridge, MA 02138 USA	Greenblatt, JF (reprint author), Univ Toronto, Banting & Best Dept Med Res, Terrence Donnelly Ctr Cellular & Biomol Res, 160 Coll St, Toronto, ON M5S 3E1, Canada.	Andrew.emili@utoronto.ca; jack.Greenblatt@utoronto.ca	Parkinson, John/A-4424-2008; Cagney, Gerard/A-4648-2009; Haw, Robin/D-1393-2009	Parkinson, John/0000-0001-9815-1189; 			ALLISON LA, 1985, CELL, V42, P599, DOI 10.1016/0092-8674(85)90117-5; Aravind L, 2000, TRENDS BIOCHEM SCI, V25, P421, DOI 10.1016/S0968-0004(00)01620-0; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; BRIGATI C, 1993, MOL CELL BIOL, V13, P1306; Butland G, 2005, NATURE, V433, P531, DOI 10.1038/nature03239; Carrozza MJ, 2005, CELL, V123, P581, DOI 10.1016/j.cell.2005.10.023; Eissenberg JC, 2002, P NATL ACAD SCI USA, V99, P9894, DOI 10.1073/pnas.152193699; Enright AJ, 2002, NUCLEIC ACIDS RES, V30, P1575, DOI 10.1093/nar/30.7.1575; Fourel G, 1999, EMBO J, V18, P2522, DOI 10.1093/emboj/18.9.2522; Fraser HB, 2003, BMC EVOL BIOL, V3, DOI 10.1186/1471-2148-3-11; GAVIN AC, 2002, NATURE, V415, P147; Ghaemmaghami S, 2003, NATURE, V425, P737, DOI 10.1038/nature02046; Goffeau A, 1996, SCIENCE, V546, P563; Hampsey M, 2003, CELL, V113, P429, DOI 10.1016/S0092-8674(03)00360-X; Ho Y, 2002, NATURE, V415, P180, DOI 10.1038/415180a; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Jansen R, 2004, CURR OPIN MICROBIOL, V7, P535, DOI 10.1016/j.mib.2004.08.012; Joy MP, 2005, J BIOMED BIOTECHNOL, P96, DOI 10.1155/JBB.2005.96; Keogh MC, 2005, CELL, V123, P593, DOI 10.1016/j.cell.2005.10.025; Korber P, 2004, CELL, V117, P5, DOI 10.1016/S0092-8674(04)00296-X; Krogan NJ, 2004, MOL CELL, V16, P1027, DOI 10.1016/j.molcel.2004.11.033; Krogan NJ, 2002, MOL CELL BIOL, V22, P6979, DOI 10.1128/MCB.22.20.6979-6992.2002; Krogan NJ, 2004, MOL CELL, V13, P225, DOI 10.1016/S1097-2765(04)00003-6; Krogan NJ, 2001, MOL CELL BIOL, V21, P8203, DOI 10.1128/MCB.21.23.8203-8212.2001; Kumar A, 2002, GENE DEV, V16, P707, DOI 10.1101/gad.970902; Link AJ, 1999, NAT BIOTECHNOL, V17, P676; Lord PW, 2003, BIOINFORMATICS, V19, P1275, DOI 10.1093/bioinformatics/btg153; Martzen MR, 1999, SCIENCE, V286, P1153, DOI 10.1126/science.286.5442.1153; McCormack AL, 1997, ANAL CHEM, V69, P767, DOI 10.1021/ac960799q; Mewes HW, 2004, NUCLEIC ACIDS RES, V32, pD41, DOI 10.1093/nar/gkh092; Mitchell T, 1997, MACHINE LEARNING; Regelmann J, 2003, MOL BIOL CELL, V14, P1652, DOI 10.1091/mbc.E02-08-0456; Rigaut G, 1999, NAT BIOTECHNOL, V17, P1030, DOI 10.1038/13732; Ross-Macdonald P, 1999, NATURE, V402, P413; Sampath V, 2005, IUBMB LIFE, V57, P93, DOI 10.1080/15216540500078905; Scholes DT, 2001, GENETICS, V159, P1449; Schuldiner M, 2005, CELL, V123, P507, DOI 10.1016/j.cell.2005.08.031; Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303; Tong AHY, 2001, SCIENCE, V294, P2364, DOI 10.1126/science.1065810; Uetz P, 2000, NATURE, V403, P623; von Mering C, 2002, NATURE, V417, P399; Winzeler EA, 1999, SCIENCE, V285, P901, DOI 10.1126/science.285.5429.901; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Xia Y, 2004, ANNU REV BIOCHEM, V73, P1051, DOI 10.1146/annurev.biochem.73.011303.073950; Zhu H, 2003, CURR OPIN CHEM BIOL, V7, P55, DOI 10.1016/S1367-5931(02)00005-4	48	1257	1296	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	0028-0836		NATURE	Nature	MAR 30	2006	440	7084					637	643		10.1038/nature04670		7	Multidisciplinary Sciences	Science & Technology - Other Topics	026OY	WOS:000236350400036	
J	Wang, GL; Kossenkov, AV; Ochs, MF				Wang, GL; Kossenkov, AV; Ochs, MF			LS-NMF: A modified non-negative matrix factorization algorithm utilizing uncertainty estimates	BMC BIOINFORMATICS			English	Article							GENE-EXPRESSION PROFILES; MICROARRAY DATA; DIMENSIONALITY REDUCTION; COMPONENT ANALYSIS; CLUSTER-ANALYSIS; IDENTIFICATION; DECOMPOSITION; DISTRIBUTIONS; DISCOVERY; PATTERNS	Background: Non- negative matrix factorisation ( NMF), a machine learning algorithm, has been applied to the analysis of microarray data. A key feature of NMF is the ability to identify patterns that together explain the data as a linear combination of expression signatures. Microarray data generally includes individual estimates of uncertainty for each gene in each condition, however NMF does not exploit this information. Previous work has shown that such uncertainties can be extremely valuable for pattern recognition. Results: We have created a new algorithm, least squares non- negative matrix factorization, LS-NMF, which integrates uncertainty measurements of gene expression data into NMF updating rules. While the LS- NMF algorithm maintains the advantages of original NMF algorithm, such as easy implementation and a guaranteed locally optimal solution, the performance in terms of linking functionally related genes has been improved. LS- NMF exceeds NMF significantly in terms of identifying functionally related genes as determined from annotations in the MIPS database. Conclusion: Uncertainty measurements on gene expression data provide valuable information for data analysis, and use of this information in the LS- NMF algorithm significantly improves the power of the NMF technique.	Fox Chase Canc Ctr, Div Populat Sci, Philadelphia, PA 19111 USA	Ochs, MF (reprint author), Fox Chase Canc Ctr, Div Populat Sci, Philadelphia, PA 19111 USA.	guoli.wang@fccc.edu; andrew.kossenkov@fccc.edu; m_ochs@fccc.edu					Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; Bidaut G, 2004, BIOINFORMATICS, V20, P2869, DOI 10.1093/bioinformatics/bth307; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Cherepinsky V, 2003, P NATL ACAD SCI USA, V100, P9668, DOI 10.1073/pnas.1633770100; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Gasch AP, 2002, GENOME BIOL, V3, P0059; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797; GULDENER U, 2005, NUCLEIC ACIDS RES, pD364; Heyer LJ, 1999, GENOME RES, V9, P1106, DOI 10.1101/gr.9.11.1106; Huang E, 2003, NAT GENET, V34, P226, DOI 10.1038/ng1167; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Ideker T, 2000, J COMPUT BIOL, V7, P805, DOI 10.1089/10665270050514945; Kanehisa M, 2002, NUCLEIC ACIDS RES, V30, P42, DOI 10.1093/nar/30.1.42; Kerr MK, 2002, STAT SINICA, V12, P203; Kim PM, 2003, GENOME RES, V13, P1706, DOI 10.1101/gr.903503; LEE DD, 2001, ADV NEURAL INFORMATI, V13; Lee DD, 1999, NATURE, V401, P788; Lee SI, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-11-r76; Lukashin AV, 2001, BIOINFORMATICS, V17, P405, DOI 10.1093/bioinformatics/17.5.405; MEWES HW, 2004, NUCLEIC ACIDS RES, pD41; Moloshok TD, 2002, BIOINFORMATICS, V18, P566, DOI 10.1093/bioinformatics/18.4.566; Newton MA, 2001, J COMPUT BIOL, V8, P37, DOI 10.1089/106652701300099074; OCHS MF, 2003, BIOTECHNIQUES, V34, pS4; OCHS MF, 2003, ANAL GENE EXPRESSION; Pochet N, 2004, BIOINFORMATICS, V20, P3185, DOI 10.1093/bioinformatics/bth383; Sanguinetti G, 2005, BIOINFORMATICS, V21, P3748, DOI 10.1093/bioinformatics/bti617; Sibisi S, 1997, J R STAT SOC B, V59, P217, DOI 10.1111/1467-9868.00065; Tanay Amos, 2002, Bioinformatics, V18 Suppl 1, pS136; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; ZHANG J, 2003, IEEE 13 WORKSH NEUR, P409	34	27	29	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 28	2006	7								175	10.1186/1471-2105-7-175		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	037IE	WOS:000237139500001	
J	Todorovski, L; Dzeroski, S				Todorovski, L; Dzeroski, S			Integrating knowledge-driven and data-driven approaches to modeling	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	4th International Workshop on Environmental Applications of Machine Learning (EAML)	SEP 27-OCT 01, 2004	Bled, SLOVENIA			computational scientific discovery; machine learning; dynamic systems; aquatic ecosystems; hydrodynamics	EQUATION DISCOVERY	In this paper, we present a framework for modeling dynamic systems that integrates the knowledge-based theoretical approach to modeling with the data-driven empirical modeling. The framework allows for integration of modeling knowledge specific to the domain of interest in the process of model induction from measured data. The knowledge is organized around the central notion of basic processes in the domain and it includes models thereof as well as guidelines forcombining models of individual processes into a model of the entire observed system. The presented framework is applied to three tasks of modeling dynamic environmental systems from noisy measurement data in the domains of population and hydro dynamics. in all applications, the models induced with the framework can be used both to accurately predict and explain the behavior of the observed dynamic systems. (c) 2005 Elsevier B.V All rights reserved.	Jozef Stefan Inst, Dept Knowledge Technol, SI-1000 Ljubljana, Slovenia	Dzeroski, S (reprint author), Jozef Stefan Inst, Dept Knowledge Technol, Jamova 39, SI-1000 Ljubljana, Slovenia.	Saso.Dzeroski@ijs.si					BENDORICCHIO G, 1994, ECOL MODEL, V75, P485, DOI 10.1016/0304-3800(94)90042-6; Bradley E, 2001, ARTIF INTELL, V133, P139, DOI 10.1016/S0004-3702(01)00143-6; BUNCH DS, 1993, ACM T MATH SOFTWARE, V19, P109, DOI 10.1145/151271.151279; COFFARO G, 1993, MODEL ULVA RIGIDA GR; COGHILL GM, 2002, P 16 INT WORKSH QUAL; FALKENHAINER B, 1991, ARTIF INTELL, V51, P95, DOI 10.1016/0004-3702(91)90109-W; Gershenfeld N., 1999, NATURE MATH MODELING; JORGENSEN SE, 1986, ECOL MODEL, V32, P165, DOI 10.1016/0304-3800(86)90024-4; KOMPARE B, 1995, P INT C COAST OC SPA, P209; KRIZMAN V, 1998, THESIS U LJUBLJANA L; Kuipers B., 1994, QUALITATIVE REASONIN; Langley P., 2002, P 19 INT C MACH LEAR, P347; LJUNG L, 1993, P 7 INT S METH INT S, P338; Murray J.D., 1993, MATH BIOL; SAITO K, 2001, P 4 INT C DISC SCI, P336; Todorovski L., 1997, P 14 INT C MACH LEAR, P376; Todorovski L, 1998, ECOL MODEL, V113, P71, DOI 10.1016/S0304-3800(98)00135-5; TODOROVSKI L, 2003, THESIS U LJUBLJANA L; TODOROVSKI L, 2000, P 17 INT C MACH LEAR, P991; Todorovski L, 2003, ECOL MODEL, V170, P141, DOI 10.1016/S0304-3800(03)00222-9; Whigham PA, 2001, ECOL MODEL, V146, P243, DOI 10.1016/S0304-3800(01)00310-6	21	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	MAR 25	2006	194	1-3					3	13		10.1016/j.ecolmodel.2005.10.001		11	Ecology	Environmental Sciences & Ecology	024QR	WOS:000236211600002	
J	Jurc, M; Perko, M; Dzeroski, S; Demsar, D; Hrasovec, B				Jurc, M; Perko, M; Dzeroski, S; Demsar, D; Hrasovec, B			Spruce bark beetles (Ips typographus, Pityogenes chalcographus, Col.: Scolytidae) in the Dinaric mountain forests of Slovenia: Monitoring and modeling	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	4th International Workshop on Environmental Applications of Machine Learning (EAML)	SEP 27-OCT 01, 2004	Bled, SLOVENIA			Ips typographus; pityogenes chalcographus; Norway spruce; monitoring linear regression; machine learning; model trees		In this paper, we analyze the phenology of spruce bark beetles (Ips typographus and Pityogenes chalcographus) in the Dinaric mountain forests of southwestern Slovenia. The study of I. typographus took place from 1986 to 2000, while that of P. chalcographus took place from 1993 to 2000 in an area characterized as a Dinaric Fir-Beech forest community (Abieti-Fagetum dinaricum) on the Karst plateau (447-751 In above sea level). On the studied area Norway spruce (Picea abies) has been planted between 60 and 90 years ago on approximately 1000 ha. Frequent catastrophic weather conditions are characteristic for this area, followed by an increased trophic capacity of the forest for the various bark beetle species. The population density of spruce bark beetles was monitored at five locations at varying exposures using commercial pheromones (Pheroprax((R)) and Chalcoprax((R))) in traps under the trade name Theysohn. Both species studied (I. typographus and P. chalcographus) have a relatively high abundance and have two main generations per year; both species may also produce two sister generations. Data on some environmental factors as well as data on bark beetle catches have been collected and then analyzed to model the dependence of spruce bark beetle catches on the environmental factors. The machine learning methodology of liner regression as well as model tree induction was used for this purpose. The following attributes were used to analyze the occurrence of both species of bark beetle: position (NW, NE, W, E, N and S), age of pheromone, number of days since last monitoring, average monthly temperature, monthly precipitation, month and previous number of bark beetles. There was a strong correlation between a high population density of I. typograpus and Northeast (NE) and position and a high density of populations of P. chalcographus and West (W) and North (N) positions. (c) 2005 Elsevier B.V. All rights reserved.	Univ Ljubljana, Biotech Fac, Dept Forestry & Renewable Forest Resources, Ljubljana 1001, Slovenia; Slovenian Forestry Serv, OE Postojna, Postojna, Sweden; Jozef Stefan Inst, Dept Knowledge Technol, SI-1000 Ljubljana, Slovenia; Univ Zagreb, Fac Forestry, Zagreb 10000, Croatia	Jurc, M (reprint author), Univ Ljubljana, Biotech Fac, Dept Forestry & Renewable Forest Resources, Vecna Pot 83, Ljubljana 1001, Slovenia.	maja.jurc@bf.uni-lj.si					BAKKE A, 1995, BEHAV POPULATION DYN, P59; BAKKE A, 1981, 05 NISK NOR I SKOGF, P5; BOTTERWEG PF, 1982, Z ANGEW ENTOMOL, V94, P466; Breiman L, 1984, CLASSIFICATION REGRE; CHALOUPEK W, 1988, OESTERREICHISCHE FOR, V99, P62; Christiansen E., 1988, P479; CHRISTIANSEN E, 1997, P INTEGRATING CULTUR, P163; CIMPERSEK M, 1988, GOZDARSKI VESTNIK, V46, P118; EIDMANN HH, 1992, J APPL ENTOMOL, V114, P193; ESCHERICH K, 1923, FORSTINSEKTEN MITTEL, P663; Flot J.-L., 2001, Journal of Forest Science (Prague), V47, P37; Gall R, 2003, USDA NE EXP, V311, P132; HEDGREN OP, 2002, THESIS SWEDISH U AGR, P20; Hocevar M., 2003, Obmocni gozdnogospodarski nacrti in razvojne perspektive slovenskega gozdarstva: zbornik referatov XXI. gozdarski studijski dnevi, 27-28 marec 2003, P103; JAKUS R, 2003, P ECOLOGY SURVEY MAN, P25; JURC D, 2003, FOREST HLTH SLOVENIA, V69; Jurc M, 2003, USDA NE EXP, V311, P157; KAJFEZBOGATAJ L, 2001, ACTA AGR SLOVENICA B, P299; Lindelow A., 2001, Journal of Forest Science (Prague), V47, P40; LOBINGER G, 1994, ANZ SCHADLINGSKD PFL, V67, P14, DOI 10.1007/BF01906563; NIEMEYER H, 1997, P INT CULT TACT MAN, P80; NUSSLIN O, 1927, FORFTINFEKTENKUNDE, P625; OROZENADAMIC M, 1987, ZBOROVANJA SLOVENSKI, P123; Pavlin R., 1992, Gozdarski Vestnik, V50, P394; PERKO M, 2002, GOZDARSKI VESTNIK, V60, P77; Puhe J, 2003, FOREST ECOL MANAG, V175, P253, DOI 10.1016/S0378-1127(02)00134-2; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Reeve John D., 1995, P339, DOI 10.1016/B978-012159270-7/50018-X; SLANDER J, 1951, GOZDARSKA KNJIZNICA, V3, P60; SPEIGHT MCD, 1989, SAPROXYCLIC INVERTEB, P82; Staack J., 1985, Forst- und Holzwirt, V40, P27; Stergulc E, 2003, USDA NE EXP, V311, P168; TITOVSEK J, 1994, LJUBLJANA, V43, P31; VITE JP, 1989, HOLARCTIC ECOL, V12, P520; WANG Y, 1997, P POST PAP EUR C MAC; WESLIEN J, 1992, J APPL ENTOMOL, V114, P228; Witten I. H., 1999, DATA MINING PRACTICA; Worrell R., 1983, Meddelelser fra Norsk Institutt for Skogforskning, V38, P1; WUGGENIG W, 1988, OSTERREICHISCHE FORS, V99, P22; ZUBER M, 1992, J APPL ENTOMOL, V113, P430; ZUMR V, 1991, Lesnictvi (Prague), V37, P669; *REP SLOV MIN AGR, 1995, NAT FOR DEV PROGR, P49; 1998, STAT YB REPUBLIC SLO; 1986, METEOROLOGICAL DATA; 2002, STAT YB REPUBLIC SLO	45	10	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	MAR 25	2006	194	1-3					219	226		10.1016/j.ecolmodel.2005.10.014		8	Ecology	Environmental Sciences & Ecology	024QR	WOS:000236211600021	
J	Weston, J; Kuang, R; Leslie, C; Noble, WS				Weston, J; Kuang, R; Leslie, C; Noble, WS			Protein ranking by semi-supervised network propagation	BMC BIOINFORMATICS			English	Article; Proceedings Paper	NIPS Workshop on New Problems and Methods in Computational Biology	DEC   18, 2004	Whistle, CANADA	NIPS			PSI-BLAST; DATABASE; SEQUENCES	Background: Biologists regularly search DNA or protein databases for sequences that share an evolutionary or functional relationship with a given query sequence. Traditional search methods, such as BLAST and PSI-BLAST, focus on detecting statistically significant pairwise sequence alignments and often miss more subtle sequence similarity. Recent work in the machine learning community has shown that exploiting the global structure of the network defined by these pairwise similarities can help detect more remote relationships than a purely local measure. Methods: We review RankProp, a ranking algorithm that exploits the global network structure of similarity relationships among proteins in a database by performing a diffusion operation on a protein similarity network with weighted edges. The original RankProp algorithm is unsupervised. Here, we describe a semi-supervised version of the algorithm that uses labeled examples. Three possible ways of incorporating label information are considered: (i) as a validation set for model selection, (ii) to learn a new network, by choosing which transfer function to use for a given query, and (iii) to estimate edge weights, which measure the probability of inferring structural similarity. Results: Benchmarked on a human-curated database of protein structures, the original RankProp algorithm provides significant improvement over local network search algorithms such as PSI-BLAST. Furthermore, we show here that labeled data can be used to learn a network without any need for estimating parameters of the transfer function, and that diffusion on this learned network produces better results than the original RankProp algorithm with a fixed network. Conclusion: In order to gain maximal information from a network, labeled and unlabeled data should be used to extract both local and global structure.	NEC Labs Amer, Princeton, NJ 08540 USA; Columbia Univ, Ctr Computat Learning Syst, Interchurch Ctr, New York, NY USA; Univ Washington, Dept Genome Sci, Seattle, WA USA; Univ Washington, Dept Comp Sci & Engn, Seattle, WA USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Weston, J (reprint author), NEC Labs Amer, 4 Independence Way, Princeton, NJ 08540 USA.	jasonw@nec-labs.com; rkuang@cs.columbia.edu; cleslie@cs.columbia.edu; noble@gs.washington.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Gribskov M, 1996, COMPUT CHEM, V20, P25, DOI 10.1016/S0097-8485(96)80004-0; HANLEY JA, 1982, RADIOLOGY, V143, P29; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; KARPLUS K, 2001, PROTEINS S5, V45, P86, DOI 10.1002/prot.10021; KUANG R, 2005, BIOINFORMATICS; KUANG R, 2004, COMP SYST BIOL C; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Page L., 1998, PAGERANK CITATION RA; Park J, 1998, J MOL BIOL, V284, P1201, DOI 10.1006/jmbi.1998.2221; Schaffer AA, 2001, NUCLEIC ACIDS RES, V29, P2994, DOI 10.1093/nar/29.14.2994; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; WESTON J, 2003, ADV NEURAL INFORMATI, V17; Weston J, 2004, P NATL ACAD SCI USA, V101, P6559, DOI 10.1073/pnas.0308067101; ZHOU D, 2003, NEURAL INFORMATION P	17	9	9	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 20	2006	7			1					S10	10.1186/1471-2105-7-S1-S10		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	032HJ	WOS:000236765200010	
J	Lee, M; Wang, WQ; Yu, H				Lee, M; Wang, WQ; Yu, H			Exploring supervised and unsupervised methods to detect topics in biomedical text	BMC BIOINFORMATICS			English	Article							GENES	Background: Topic detection is a task that automatically identifies topics (e.g., "biochemistry" and "protein structure") in scientific articles based on information content. Topic detection will benefit many other natural language processing tasks including information retrieval, text summarization and question answering; and is a necessary step towards the building of an information system that provides an efficient way for biologists to seek information from an ocean of literature. Results: We have explored the methods of Topic Spotting, a task of text categorization that applies the supervised machine-learning technique naive Bayes to assign automatically a document into one or more predefined topics; and Topic Clustering, which apply unsupervised hierarchical clustering algorithms to aggregate documents into clusters such that each cluster represents a topic. We have applied our methods to detect topics of more than fifteen thousand of articles that represent over sixteen thousand entries in the Online Mendelian Inheritance in Man (OMIM) database. We have explored bag of words as the features. Additionally, we have explored semantic features; namely, the Medical Subject Headings (MeSH) that are assigned to the MEDLINE records, and the Unified Medical Language System (UMLS) semantic types that correspond to the MeSH terms, in addition to bag of words, to facilitate the tasks of topic detection. Our results indicate that incorporating the MeSH terms and the UMLS semantic types as additional features enhances the performance of topic detection and the naive Bayes has the highest accuracy, 66.4%, for predicting the topic of an OMIM article as one of the total twenty-five topics. Conclusion: Our results indicate that the supervised topic spotting methods outperformed the unsupervised topic clustering; on the other hand, the unsupervised topic clustering methods have the advantages of being robust and applicable in real world settings.			ml1065@columbia.edu; wwq318@hotmail.com; hong.yu@dbmi.columbia.edu					Andrade MA, 1998, BIOINFORMATICS, V14, P600, DOI 10.1093/bioinformatics/14.7.600; CORPET F, 1988, NUCLEIC ACIDS RES, V16, P10881, DOI 10.1093/nar/16.22.10881; Ehrler F, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S23; Hamosh A, 2005, NUCLEIC ACIDS RES, V33, pD514; HATZIVASSILOGLO.V, 2000, INVESTIGATION LINGUI; HEARTST M, BIOTEXT PROJECT POWE; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; JOACHIMS T, 1998, TEXT CATEGORIZATION, P137; Wilbur W John, 2002, Pac Symp Biocomput, P386; Raychaudhuri S, 2002, GENOME RES, V12, P203, DOI 10.1101/gr.199701; Rice SB, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S22; Smink LJ, 2005, NUCLEIC ACIDS RES, V33, pD544; Witten I. H., 1999, MANAGING GIGABYTES C; YU H, 2003, ANSWERING OPINION QU; Yu H, 1999, Proc AMIA Symp, P181; *NIST, 1998, TOP DET TRACK PHAS 2	16	11	12	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 16	2006	7								140	10.1186/1471-2105-7-140		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	048YF	WOS:000237981800001	
J	Thompson, J; Gopal, S				Thompson, J; Gopal, S			Genetic algorithm learning as a robust approach to RNA editing site prediction	BMC BIOINFORMATICS			English	Article							HIGHER-PLANT MITOCHONDRIA; GENOME SEQUENCE; RECOGNITION; L.	Background: RNA editing is one of several post-transcriptional modifications that may contribute to organismal complexity in the face of limited gene complement in a genome. One form, known as C -> U editing, appears to exist in a wide range of organisms, but most instances of this form of RNA editing have been discovered serendipitously. With the large amount of genomic and transcriptomic data now available, a computational analysis could provide a more rapid means of identifying novel sites of C -> URNA editing. Previous efforts have had some success but also some limitations. We present a computational method for identifying C -> URNA editing sites in genomic sequences that is both robust and generalizable. We evaluate its potential use on the best data set available for these purposes: C -> U editing sites in plant mitochondrial genomes. Results: Our method is derived from a machine learning approach known as a genetic algorithm. REGAL ( RNA Editing site prediction by Genetic Algorithm Learning) is 87% accurate when tested on three mitochondrial genomes, with an overall sensitivity of 82% and an overall specificity of 91%. REGAL's performance significantly improves on other ab initio approaches to predicting RNA editing sites in this data set. REGAL has a comparable sensitivity and higher specificity than approaches which rely on sequence homology, and it has the advantage that strong sequence conservation is not required for reliable prediction of edit sites. Conclusion: Our results suggest that ab initio methods can generate robust classifiers of putative edit sites, and we highlight the value of combinatorial approaches as embodied by genetic algorithms. We present REGAL as one approach with the potential to be generalized to other organisms exhibiting C -> URNA editing.	Rochester Inst Technol, Dept Biol Sci, Rochester, NY 14623 USA	Gopal, S (reprint author), Rochester Inst Technol, Dept Biol Sci, Rochester, NY 14623 USA.	tex@u.washington.edu; sxgsbi@rit.edu					Adams MD, 2000, SCIENCE, V287, P2185, DOI 10.1126/science.287.5461.2185; Brett D, 2002, NAT GENET, V30, P29, DOI 10.1038/ng803; Bundschuh R, 2004, BIOINFORMATICS, V20, P3214, DOI 10.1093/bioinformatics/bth387; Burset M, 1996, GENOMICS, V34, P353, DOI 10.1006/geno.1996.0298; Chamary JV, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-9-r75; Clutterbuck DR, 2005, BIOINFORMATICS, V21, P2590, DOI 10.1093/bioinformatics/bti411; Cummings MP, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-132; DURBIN R, 1998, BIOL SEQUENCE ANAL C; Furey TS, 2004, GENOME RES, V14, P2034, DOI 10.1101/gr.2467904; Giege P, 1999, P NATL ACAD SCI USA, V96, P15324, DOI 10.1073/pnas.96.26.15324; Goldberg DE, 1989, GENETIC ALGORITHMS S; Handa H, 2003, NUCLEIC ACIDS RES, V31, P5907, DOI 10.1093/nar/gkg795; HOLLAND JH, 1992, ADAPTATION NATURAL A; Collins FS, 2004, NATURE, V431, P931, DOI 10.1038/nature03001; Keegan LP, 2001, NAT REV GENET, V2, P869, DOI 10.1038/35098584; Levanon EY, 2004, NAT BIOTECHNOL, V22, P1001, DOI 10.1038/nbt996; Maier RM, 1996, PLANT MOL BIOL, V32, P343, DOI 10.1007/BF00039390; Mower JP, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-96; Mulligan RM, 1999, J HERED, V90, P338, DOI 10.1093/jhered/90.3.338; Notredame C, 1996, NUCLEIC ACIDS RES, V24, P1515, DOI 10.1093/nar/24.8.1515; Notsu Y, 2002, MOL GENET GENOMICS, V268, P434, DOI 10.1007/s00438-002-0767-1; Smith HC, 1997, RNA, V3, P1105; Sneath P.H.A., 1973, NUMERICAL TAXONOMY; Stajich JE, 2002, GENOME RES, V12, P1611, DOI 10.1101/gr.361602; Strub Caroline, 2004, BMC Biochemistry, V5, P9, DOI 10.1186/1471-2091-5-9; Stuart K, 1997, MICROBIOL MOL BIOL R, V61, P105; Williams MA, 1998, PLANT MOL BIOL, V36, P229, DOI 10.1023/A:1005961718612; YU W, 1995, BIOCHIMIE, V77, P79, DOI 10.1016/0300-9084(96)88108-9	28	10	11	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 16	2006	7								145	10.1186/1471-2105-7-145		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	042ZK	WOS:000237568900001	
J	Huang, JJ; Tzeng, GH; Ong, CS				Huang, JJ; Tzeng, GH; Ong, CS			Two-stage genetic programming (2SGP) for the credit scoring model	APPLIED MATHEMATICS AND COMPUTATION			English	Article						credit scoring model; artificial neural network (ANN); decision trees; rough sets; two-stage genetic programming (2SGP)	BUSINESS FAILURE PREDICTION; ROUGH SET-THEORY; NEURAL-NETWORK; REGRESSION; METHODOLOGY	Credit scoring models have been widely studied in the areas of statistics, machine learning, and artificial intelligence (AI). Many novel approaches such as artificial neural networks (ANNs), rough sets, or decision trees have been proposed to increase the accuracy of credit scoring models. Since an improvement in accuracy of a fraction of a percent might translate into significant savings, a more sophisticated model should be proposed for significantly improving the accuracy of the credit scoring models. In this paper, two-stage genetic programming (2SGP) is proposed to deal with the credit scoring problem by incorporating the advantages of the IF-THEN rules and the discriminant function. On the basis of the numerical results, we can conclude that 2SGP can provide the better accuracy than other models. (c) 2005 Published by Elsevier Inc.	Natl Chiao Tung Univ, Inst Management Technol, Coll Management, Hsinchu 300, Taiwan; Natl Chiao Tung Univ, Inst Traff & Transportat, Coll Management, Hsinchu 300, Taiwan; Natl Taiwan Univ, Dept Informat Management, Taipei 106, Taiwan; Kainan Univ, Dept Business Adm, Tao Yuan 338, Taiwan	Tzeng, GH (reprint author), Natl Chiao Tung Univ, Inst Management Technol, Coll Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.	u5460637@ms16.hinet.net	Tzeng, Gwo-Hshiung/B-2775-2009				Agresti A., 1990, CATEGORICAL DATA ANA; Ahn BS, 2000, EXPERT SYST APPL, V18, P65, DOI 10.1016/S0957-4174(99)00053-6; Beynon MJ, 2001, OMEGA-INT J MANAGE S, V29, P561, DOI 10.1016/S0305-0483(01)00045-7; Bi YX, 2003, KNOWL-BASED SYST, V16, P243, DOI 10.1016/S0950-7051(03)00025-X; BOJARCZUK CC, 2004, ARTIF INTELL, V30, P21; Castillo F, 2003, LECT NOTES COMPUT SC, V2724, P1975; Chung H. M., 1999, J MANAGEMENT INFORMA, V16, P11; Craven M.W., 1997, FUTURE GENER COMP SY, V13, P221; Davidson JW, 2003, INFORM SCIENCES, V150, P95, DOI 10.1016/S0020-0255(02)00371-7; De Falco I., 2002, Applied Soft Computing, V1, DOI 10.1016/S1568-4946(01)00024-2; DeMaris A., 1992, LOGIT MODELING; DESAI VS, 1997, IMA J MATH APPL BUSI, V8, P324; Desai VS, 1996, EUR J OPER RES, V95, P24, DOI 10.1016/0377-2217(95)00246-4; Dimitras AI, 1999, EUR J OPER RES, V114, P263, DOI 10.1016/S0377-2217(98)00255-0; Feraud R, 2002, NEURAL NETWORKS, V15, P237, DOI 10.1016/S0893-6080(01)00127-7; FREITAS AA, 1997, P 2 ANN C GEN PROGR, P96; Haykin S., 1994, NEURAL NETWORKS COMP; Jensen H. L., 1992, MANAGE FINANC, V18, P15; Johnson H. E., 2000, Genetic Programming and Evolvable Machines, V1, DOI 10.1023/A:1010014314078; KNOKE D, 1980, LOGLINEAR MODELINS; Koza J. R., 1992, GENETIC PROGRAMMING; Lee TS, 2002, EXPERT SYST APPL, V23, P245, DOI 10.1016/S0957-4174(02)00044-1; Liao Tim Futing, 1994, INTERPRETING PROBABI; Malhotra R, 2003, OMEGA-INT J MANAGE S, V31, P83, DOI 10.1016/S0305-0483(03)00016-1; MCCULLAGH P, 1980, J ROY STAT SOC B MET, V42, P109; Nath R, 1997, COMPUT OPER RES, V24, P767, DOI 10.1016/S0305-0548(96)00088-3; NGAN P, 1998, P 3 ANN C GEN PROGR, P304; Piramuthu S, 1999, EUR J OPER RES, V112, P310, DOI 10.1016/S0377-2217(97)00398-6; PRESS SJ, 1978, J AM STAT ASSOC, V73, P699, DOI 10.2307/2286261; STEFANO CD, 2002, PATTERN RECOGN, V23, P1439; West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5; Zhang YF, 2004, INFORM SCIENCES, V163, P85, DOI 10.1016/j.ins.2003.03.028	32	34	35	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0096-3003		APPL MATH COMPUT	Appl. Math. Comput.	MAR 15	2006	174	2					1039	1053		10.1016/j.amc.2005.05.027		15	Mathematics, Applied	Mathematics	027HY	WOS:000236407300022	
J	Polacco, BJ; Babbitt, PC				Polacco, BJ; Babbitt, PC			Automated discovery of 3D motifs for protein function annotation	BIOINFORMATICS			English	Article							GRAPH-THEORETIC APPROACH; ENZYME ACTIVE-SITES; STRUCTURAL GENOMICS; DIVERGENT EVOLUTION; ENOLASE SUPERFAMILY; CATALYTIC RESIDUES; DATA-BANK; TEMPLATES; PREDICTION; PATTERNS	Motivation: Function inference from structure is facilitated by the use of patterns of residues (3D motifs), normally identified by expert knowledge, that correlate with function. As an alternative to often limited expert knowledge, we use machine-learning techniques to identify patterns of 3-10 residues that maximize function prediction. This approach allows us to test the assumption that residues that provide function are the most informative for predicting function. Results: We apply our method, GASPS, to the haloacid dehalogenase, enolase, amidohydrolase and crotonase superfamilies and to the serine proteases. The motifs found by GASPS are as good at function prediction as 3D motifs based on expert knowledge. The GASPS motifs with the greatest ability to predict protein function consist mainly of known functional residues. However, several residues with no known functional role are equally predictive. For four groups, we show that the predictive power of our 3D motifs is comparable with or better than approaches that use the entire fold (Combinatorial-Extension) or sequence profiles (PSI-BLAST).	Univ Calif San Francisco, Dept Biopharmaceut Sci, San Francisco, CA 94143 USA	Babbitt, PC (reprint author), Univ Calif San Francisco, Dept Biopharmaceut Sci, San Francisco, CA 94143 USA.	babbitt@cgl.ucsf.edu					Allen KN, 2004, TRENDS BIOCHEM SCI, V29, P495, DOI 10.1016/j.tibs.2004.07.008; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Arakaki AK, 2004, BIOINFORMATICS, V20, P1087, DOI 10.1093/bioinformatics/bth044; ARTYMIUK PJ, 1994, J MOL BIOL, V243, P327, DOI 10.1006/jmbi.1994.1657; Babbitt PC, 2003, CURR OPIN CHEM BIOL, V7, P230, DOI 10.1016/S1367-5931(03)00028-0; Babbitt PC, 1996, BIOCHEMISTRY-US, V35, P16489, DOI 10.1021/bi9616413; Barker JA, 2003, BIOINFORMATICS, V19, P1644, DOI 10.1093/bioinformatics/btg226; Bartlett GJ, 2002, J MOL BIOL, V324, P105, DOI 10.1016/S0022-2836(02)01036-7; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; CHOTHIA C, 1986, EMBO J, V5, P823; DePristo MA, 2004, STRUCTURE, V12, P831, DOI 10.1016/j.str.2004.02.031; Dodson G, 1998, TRENDS BIOCHEM SCI, V23, P347, DOI 10.1016/S0968-0004(98)01254-7; Elcock AH, 2001, J MOL BIOL, V312, P885, DOI 10.1006/jmbi.2001.5009; Fetrow JS, 1998, J MOL BIOL, V281, P949, DOI 10.1006/jmbi.1998.1993; Gerlt JA, 2005, ARCH BIOCHEM BIOPHYS, V433, P59, DOI 10.1016/j.abb.2004.07.034; Gerlt JA, 2001, ANNU REV BIOCHEM, V70, P209, DOI 10.1146/annurev.biochem.70.1.209; Gerlt JA, 2003, CURR OPIN CHEM BIOL, V7, P252, DOI 10.1016/S1367-5931(03)00019-X; Holden HM, 2001, ACCOUNTS CHEM RES, V34, P145, DOI 10.1021/ar000053l; Holm L, 1997, PROTEINS, V28, P72, DOI 10.1002/(SICI)1097-0134(199705)28:1<72::AID-PROT7>3.0.CO;2-L; Kleywegt GJ, 1999, J MOL BIOL, V285, P1887, DOI 10.1006/jmbi.1998.2393; Meng EC, 2004, PROTEINS, V55, P962, DOI 10.1002/prot.20099; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Oldfield TJ, 2002, PROTEINS, V49, P510, DOI 10.1002/prot.10221; Orengo CA, 1997, STRUCTURE, V5, P1093, DOI 10.1016/S0969-2126(97)00260-8; Pegg SCH, 2005, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2005, P358; Porter C.T., 2004, NUCLEIC ACIDS RES, V32, P129; Russell RB, 1998, J MOL BIOL, V279, P1211, DOI 10.1006/jmbi.1998.1844; Shindyalov IN, 1998, PROTEIN ENG, V11, P739, DOI 10.1093/protein/11.9.739; Stark A, 2004, STRUCTURE, V12, P1405, DOI 10.1016/j.str.2004.05.012; Stark A, 2003, NUCLEIC ACIDS RES, V31, P3341, DOI 10.1093/nar/gkg506; Teichmann SA, 2001, CURR OPIN STRUC BIOL, V11, P354, DOI 10.1016/S0959-440X(00)00215-3; Torrance JW, 2005, J MOL BIOL, V347, P565, DOI 10.1016/j.jmb.2005.01.044; Valdar WSJ, 2002, PROTEINS, V48, P227, DOI 10.1002/prot.10146; Wallace AC, 1997, PROTEIN SCI, V6, P2308; Wangikar PP, 2003, J MOL BIOL, V326, P955, DOI 10.1016/S0022-2836(02)01384-0; ZVELEBIL MJJM, 1988, PROTEIN ENG, V2, P127, DOI 10.1093/protein/2.2.127	36	43	46	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 15	2006	22	6					723	730		10.1093/bioinformatics/btk038		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	023FP	WOS:000236111600013	
J	Wang, ZY; Wang, Y; Xuan, JH; Dong, YB; Bakay, M; Feng, YJ; Clarke, R; Hoffman, EP				Wang, ZY; Wang, Y; Xuan, JH; Dong, YB; Bakay, M; Feng, YJ; Clarke, R; Hoffman, EP			Optimized multilayer perceptrons for molecular classification and diagnosis using genomic data	BIOINFORMATICS			English	Article							STATISTICAL PATTERN-RECOGNITION; GENE-EXPRESSION SIGNATURES; CANCER-DIAGNOSIS; BREAST-CANCER; SAMPLE-SIZE; PREDICTION	Motivation: Multilayer perceptrons (MLP) represent one of the widely used and effective machine learning methods currently applied to diagnostic classification based on high-dimensional genomic data. Since the dimensionalities of the existing genomic data often exceed the available sample sizes by orders of magnitude, the MLP performance may degrade owing to the curse of dimensionality and over-fitting, and may not provide acceptable prediction accuracy. Results: Based on Fisher linear discriminant analysis, we designed and implemented an MLP optimization scheme for a two-layer MLP that effectively optimizes the initialization of MLP parameters and MLP architecture. The optimized MLP consistently demonstrated its ability in easing the curse of dimensionality in large microarray datasets. In comparison with a conventional MLP using random initialization, we obtained significant improvements in major performance measures including Bayes classification accuracy, convergence properties and area under the receiver operating characteristic curve (A(z)).	Virginia Polytech Inst & State Univ, Bradley Dept Elect & Comp Engn, Arlington, VA 22203 USA; Childrens Natl Med Ctr, Ctr Med Genet, Washington, DC 20010 USA; Catholic Univ Amer, Dept Elect Engn & Comp Sci, Washington, DC 20064 USA; Georgetown Univ, Lombardi Comprehens Canc Ctr, Dept Oncol, Washington, DC 20007 USA; Georgetown Univ, Lombardi Comprehens Canc Ctr, Dept Physiol & Biophys, Washington, DC 20007 USA	Wang, Y (reprint author), Virginia Polytech Inst & State Univ, Bradley Dept Elect & Comp Engn, Arlington, VA 22203 USA.	yuewang@vt.edu	Clarke, Robert/A-6485-2008	Clarke, Robert/0000-0002-9278-0854			Bittner M, 2000, NATURE, V406, P536, DOI 10.1038/35020115; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Haykin S., 1999, NEURAL NETWORKS COMP; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kohlmann A, 2004, LEUKEMIA, V18, P63, DOI 10.1038/sj.leu.2403167; Linder R, 2004, BIOINFORMATICS, V20, P3544, DOI 10.1093/bioinformatics/bth441; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Metz C. E, 1986, MULTIPLE REGRESSION, P365; Mjolsness E, 2001, SCIENCE, V293, P2051, DOI 10.1126/science.293.5537.2051; O'Neill MC, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-13; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; RAUDYS S, 1992, RNNS IEEE S NEUROINF, V1, P343; RAUDYS S, 1992, P INT C PATT REC, V2, P62; RAUDYS S, 1994, PATTERN RECOGN, V4, P287; Raudys S, 1997, IEEE T PATTERN ANAL, V19, P667, DOI 10.1109/34.601254; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Ripley B. D, 1996, PATTERN RECOGNITION; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang YJ, 2004, PROCEEDINGS OF THE IEEE 6TH CIRCUITS AND SYSTEMS SYMPOSIUM ON EMERGING TECHNOLOGIES: FRONTIERS OF MOBILE AND WIRELESS COMMUNICATION, VOLS 1 AND 2, P273; WEI JS, 2005, CANCER RES, V64, P6883; WEI JS, 2004, CANCER RES, V65, P374; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; XUAN J, 2004, P INT C PATTERN RECO, V2, P291	29	10	11	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 15	2006	22	6					755	761		10.1093/bioinformatics/btk036		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	023FP	WOS:000236111600017	
J	Yue, P; Moult, J				Yue, P; Moult, J			Identification and analysis of deleterious human SNPs	JOURNAL OF MOLECULAR BIOLOGY			English	Article						single nucleotide polymorphisms (SNPs); monogenic disease; human disease; complex traits; support vector machine	SINGLE-NUCLEOTIDE POLYMORPHISMS; AMINO-ACID POLYMORPHISMS; HUMAN-DISEASE GENES; COMPLEX DISEASE; BIOTECHNOLOGY-INFORMATION; FUNCTIONAL CONSEQUENCES; DATABASE RESOURCES; ALZHEIMERS-DISEASE; PROTEIN FUNCTION; CANDIDATE GENES	We have developed two methods of identifying which non-synonomous single base changes have a deleterious effect on protein function in vivo. One method, described elsewhere, analyzes the effect of the resulting amino acid change on protein stability utilizing structural information. The other method, introduced here, makes use of the conservation and type of residues observed at a base change position within a protein family. A machine learning technique, the support vector machine, is trained on single amino acid changes that cause monogenic disease, with a control set of amino acid changes fixed between species. Both methods are used to identify deleterious single nucleotide polymorphisms (SNPs) in the human population. After carefully controlling for errors, we find that approximately one quarter of known non-synonymous SNPs are deleterious by these criteria, providing a set of possible contributors to human complex disease traits. (c) 2006 Elsevier Ltd. All rights reserved.	Univ Maryland, Maryland Biotechnol Inst, Ctr Adv Res Biotechnol, Rockville, MD 20850 USA; Univ Maryland, Mol & Cellular Biol Program, College Pk, MD 20742 USA	Moult, J (reprint author), Univ Maryland, Maryland Biotechnol Inst, Ctr Adv Res Biotechnol, Rockville, MD 20850 USA.	moult@umbi.umd.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Botstein D, 2003, NAT GENET, V33, P228, DOI 10.1038/ng1090; Cargill M, 1999, NAT GENET, V22, P231; Carlson CS, 2004, NATURE, V429, P446, DOI 10.1038/nature02623; Chasman D, 2001, J MOL BIOL, V307, P683, DOI 10.1006/jmbi.2001.4510; Emahazion T, 2001, TRENDS GENET, V17, P407, DOI 10.1016/S0168-9525(01)02342-3; Ferrer-Costa C, 2002, J MOL BIOL, V315, P771, DOI 10.1006/jmbi.2001.5255; Frenette PS, 1996, CELL, V84, P563, DOI 10.1016/S0092-8674(00)81032-6; Halushka MK, 1999, NAT GENET, V22, P239; HENIKOFF S, 1993, PROTEINS, V17, P49, DOI 10.1002/prot.340170108; Hinds DA, 2005, SCIENCE, V307, P1072, DOI 10.1126/science.1105436; Huang H, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-7-r47; Gibbs RA, 2003, NATURE, V426, P789, DOI 10.1038/nature02168; Krishnan VG, 2003, BIOINFORMATICS, V19, P2199, DOI 10.1093/bioinformatics/btg297; Kruglyak L, 2001, NAT GENET, V27, P234, DOI 10.1038/85776; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; MOLCHAN G. M., 1994, COMPUTATIONAL SEISMO, V2, P1; MORI Y, 1990, J CLIN ENDOCR METAB, V70, P804; Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509; Prince JA, 2001, EUR J HUM GENET, V9, P437, DOI 10.1038/sj.ejhg.5200651; Pritchard JK, 2002, HUM MOL GENET, V11, P2417, DOI 10.1093/hmg/11.20.2417; Ramensky V, 2002, NUCLEIC ACIDS RES, V30, P3894, DOI 10.1093/nar/gkf493; SHANNON CE, 1948, AT&T TECH J, V27, P379; Sherry ST, 2001, NUCLEIC ACIDS RES, V29, P308, DOI 10.1093/nar/29.1.308; Smith DJ, 2002, HUM MOL GENET, V11, P2455, DOI 10.1093/hmg/11.20.2455; Smith NGC, 2003, GENE, V318, P169, DOI 10.1016/S0378-1119(03)00772-8; Stenson PD, 2003, HUM MUTAT, V21, P577, DOI 10.1002/humu.10212; Sunyaev S, 2001, HUM MOL GENET, V10, P591, DOI 10.1093/hmg/10.6.591; Sachidanandam R, 2001, NATURE, V409, P928, DOI 10.1038/35057149; Thomas PD, 2003, NUCLEIC ACIDS RES, V31, P334, DOI 10.1093/nar/gkg115; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Verzilli CJ, 2005, J ROY STAT SOC C-APP, V54, P191, DOI 10.1111/j.1467-9876.2005.00478.x; WALTZ MR, 1990, J ENDOCRINOL INVEST, V13, P343; Wang Z, 2003, PROTEINS, V53, P748, DOI 10.1002/prot.10522; Wheeler DL, 2005, NUCLEIC ACIDS RES, V33, pD39, DOI 10.1093/nar/gki062; Wheeler DL, 2004, NUCLEIC ACIDS RES, V32, pD35, DOI 10.1093/nar/gkh073; Yue P, 2005, J MOL BIOL, V353, P459, DOI 10.1016/j.jmb.2005.08.020	38	105	107	ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-2836		J MOL BIOL	J. Mol. Biol.	MAR 10	2006	356	5					1263	1274		10.1016/j.jmb.2005.12.025		12	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	013TM	WOS:000235432400017	
J	Konig, R; Schramm, G; Oswald, M; Seitz, H; Sager, S; Zapatka, M; Reinelt, G; Eils, R				Konig, R; Schramm, G; Oswald, M; Seitz, H; Sager, S; Zapatka, M; Reinelt, G; Eils, R			Discovering functional gene expression patterns in the metabolic network of Escherichia coli with wavelets transforms	BMC BIOINFORMATICS			English	Article							CHAIN AMINO-ACIDS; SACCHAROMYCES-CEREVISIAE; K-12; SYNTHETASE; SEQUENCE; DATABASE; SYSTEMS; ENZYME	Background: Microarray technology produces gene expression data on a genomic scale for an endless variety of organisms and conditions. However, this vast amount of information needs to be extracted in a reasonable way and funneled into manageable and functionally meaningful patterns. Genes may be reasonably combined using knowledge about their interaction behaviour. On a proteomic level, biochemical research has elucidated an increasingly complete image of the metabolic architecture, especially for less complex organisms like the well studied bacterium Escherichia coli. Results: We sought to discover central components of the metabolic network, regulated by the expression of associated genes under changing conditions. We mapped gene expression data from E. coli under aerobic and anaerobic conditions onto the enzymatic reaction nodes of its metabolic network. An adjacency matrix of the metabolites was created from this graph. A consecutive ones clustering method was used to obtain network clusters in the matrix. The wavelet method was applied on the adjacency matrices of these clusters to collect features for the classifier. With a feature extraction method the most discriminating features were selected. We yielded network sub-graphs from these top ranking features representing formate fermentation, in good agreement with the anaerobic response of heterofermentative bacteria. Furthermore, we found a switch in the starting point for NAD biosynthesis, and an adaptation of the l-aspartate metabolism, in accordance with its higher abundance under anaerobic conditions. Conclusion: We developed and tested a novel method, based on a combination of rationally chosen machine learning methods, to analyse gene expression data on the basis of interaction data, using a metabolic network of enzymes. As a case study, we applied our method to E. coli under oxygen deprived conditions and extracted physiologically relevant patterns that represent an adaptation of the cells to changing environmental conditions. In general, our concept may be transferred to network analyses on biological interaction data, when data for two comparable states of the associated nodes are made available.	Univ Heidelberg, Inst Pharm & Mol Biotechnol, Dept Bioinformat & Funct Genom, D-69120 Heidelberg, Germany; German Canc Res Ctr DKFZ, D-69120 Heidelberg, Germany; Univ Heidelberg, Inst Comp Sci, D-69120 Heidelberg, Germany; Univ Heidelberg, Interdisciplinary Ctr Sci Comp, D-69120 Heidelberg, Germany	Konig, R (reprint author), Univ Heidelberg, Inst Pharm & Mol Biotechnol, Dept Bioinformat & Funct Genom, D-69120 Heidelberg, Germany.	r.koenig@dkfz.de; g.schramm@dkfz.de; Marcus.Oswald@Informatik.Uni-Heidelberg.de; Hanna.Seitz@Informatik.Uni-Heidelberg.de; Sebastian.Sager@iwr.uni-heidelberg.de; m.zapatka@dkfz.de; Gerhard.Reinelt@Informatik.Uni-Heidelberg.de; r.eils@dkfz.de	Eils, Roland/B-6121-2009; Sager, Sebastian/F-6732-2013; Zapatka, Marc/G-9896-2013	Zapatka, Marc/0000-0001-8287-5967			ALIZADEH F, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P489; ANDERSON JJ, 1978, J BACTERIOL, V136, P168; Berg J.M., 2002, BIOCHEMISTRY-US, P1050; Blattner FR, 1997, SCIENCE, V277, P1453, DOI 10.1126/science.277.5331.1453; Bonferroni C. E., 1935, STUDI ONORE PROFESSO, P13; BOOTH KS, 1976, J COMPUT SYST SCI, V13, P335; CHRISTOF T, 1998, 6 IPCO C HOUST TEX, P213; Covert MW, 2004, NATURE, V429, P92, DOI 10.1038/nature02456; Datsenko KA, 2000, P NATL ACAD SCI USA, V97, P6640, DOI 10.1073/pnas.120163297; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Glasner JD, 2003, NUCLEIC ACIDS RES, V31, P147, DOI 10.1093/nar/gkg125; Greenberg D S, 1995, J Comput Biol, V2, P219, DOI 10.1089/cmb.1995.2.219; Hanisch Daniel, 2002, Bioinformatics, V18 Suppl 1, pS145; Huber Wolfgang, 2002, Bioinformatics, V18 Suppl 1, pS96; Ideker Trey, 2002, Bioinformatics, V18 Suppl 1, pS233; Jeong H, 2000, NATURE, V407, P651; Karp PD, 2002, NUCLEIC ACIDS RES, V30, P59, DOI 10.1093/nar/30.1.59; Keseler IM, 2005, NUCLEIC ACIDS RES, V33, pD334, DOI 10.1093/nar/gki108; Khodursky AB, 2000, P NATL ACAD SCI USA, V97, P12170, DOI 10.1073/pnas.220414297; Konig R, 2004, BIOINFORMATICS, V20, P1500, DOI 10.1093/bioinformatics/bth109; Neidhardt FC, 1996, ESCHERICHIA COLI SAL; Nelson SW, 2005, BIOCHEMISTRY-US, V44, P766, DOI 10.1021/bi048191w; OHNISHI K, 1988, JPN J GENET, V63, P343, DOI 10.1266/jjg.63.343; Ollagnier-de Choudens S, 2005, FEBS LETT, V579, P3737, DOI 10.1016/j.febslet.2005.05.065; OSWALD M, 2000, 5 C COMP COMB SYDN, P373; Ruschhaupt M, 2004, STAT APPL GENET MOL, V3; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Stephanopoulos G, 2002, BIOINFORMATICS, V18, P1054, DOI 10.1093/bioinformatics/18.8.1054; Stephanopoulos G, 2004, NAT BIOTECHNOL, V22, P1261, DOI 10.1038/nbt1016; Tucker A.C., 1972, J COMBINATORIAL TH B, V12, P153, DOI 10.1016/0095-8956(72)90019-6; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Uetz P, 2000, NATURE, V403, P623; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wiame E, 2004, BIOCHEM J, V378, P1047, DOI 10.1042/BJ20031527; Zien A, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P407; ZYZAK DV, 1995, ARCH BIOCHEM BIOPHYS, V316, P547, DOI 10.1006/abbi.1995.1073	37	10	11	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 8	2006	7								119	10.1186/1471-2105-7-119		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	030ZS	WOS:000236674500002	
J	Wang, HY; Zheng, HR; Simpson, D; Azuaje, F				Wang, HY; Zheng, HR; Simpson, D; Azuaje, F			Machine learning approaches to supporting the identification of photoreceptor-enriched genes based on expression data	BMC BIOINFORMATICS			English	Article							SERIAL ANALYSIS; RETINA; LOCALIZATION; MOUSE; RAT	Background: Retinal photoreceptors are highly specialised cells, which detect light and are central to mammalian vision. Many retinal diseases occur as a result of inherited dysfunction of the rod and cone photoreceptor cells. Development and maintenance of photoreceptors requires appropriate regulation of the many genes specifically or highly expressed in these cells. Over the last decades, different experimental approaches have been developed to identify photoreceptor enriched genes. Recent progress in RNA analysis technology has generated large amounts of gene expression data relevant to retinal development. This paper assesses a machine learning methodology for supporting the identification of photoreceptor enriched genes based on expression data. Results: Based on the analysis of publicly-available gene expression data from the developing mouse retina generated by serial analysis of gene expression ( SAGE), this paper presents a predictive methodology comprising several in silico models for detecting key complex features and relationships encoded in the data, which may be useful to distinguish genes in terms of their functional roles. In order to understand temporal patterns of photoreceptor gene expression during retinal development, a two-way cluster analysis was firstly performed. By clustering SAGE libraries, a hierarchical tree reflecting relationships between developmental stages was obtained. By clustering SAGE tags, a more comprehensive expression profile for photoreceptor cells was revealed. To demonstrate the usefulness of machine learning-based models in predicting functional associations from the SAGE data, three supervised classification models were compared. The results indicated that a relatively simple instance-based model (KStar model) performed significantly better than relatively more complex algorithms, e. g. neural networks. To deal with the problem of functional class imbalance occurring in the dataset, two data re-sampling techniques were studied. A random over-sampling method supported the implementation of the most powerful prediction models. The KStar model was also able to achieve higher predictive sensitivities and specificities using random over-sampling techniques. Conclusion: The approaches assessed in this paper represent an efficient and relatively inexpensive in silico methodology for supporting large-scale analysis of photoreceptor gene expression by SAGE. They may be applied as complementary methodologies to support functional predictions before implementing more comprehensive, experimental prediction and validation methods. They may also be combined with other large-scale, data-driven methods to facilitate the inference of transcriptional regulatory networks in the developing retina. Furthermore, the methodology assessed may be applied to other data domains.	Univ Ulster, Sch Comp & Math, Coleraine BT52 1SA, Londonderry, North Ireland; Queens Univ Belfast, Dept Ophthalmol, Belfast BT7 1NN, Antrim, North Ireland	Azuaje, F (reprint author), Univ Ulster, Sch Comp & Math, Coleraine BT52 1SA, Londonderry, North Ireland.	hy.wang@ulster.ac.uk; h.zheng@ulster.ac.uk; david.simpson@qub.ac.uk; fj.azuaje@ulster.ac.uk					Agrawal R., 1994, P 20 INT C VER LARG, P487; BATISTA G, 2003, P WORKSH BIOINF, P10; Batista G. E. A. P. A., 2004, SIGKDD EXPLORATIONS, V6, P20, DOI DOI 10.1145/1007730.1007735; BECQUET C, 2002, GENOME BIOL, V3; Blackshaw S, 2001, CELL, V107, P579, DOI 10.1016/S0092-8674(01)00574-8; BLACKSHAW S, 2004, PLOS BIOL, V2; BLATT C, 1988, P NATL ACAD SCI USA, V85, P7642, DOI 10.1073/pnas.85.20.7642; Buckhaults P, 2003, CANCER RES, V63, P4144; Cai L, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-7-r51; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Clarke G, 2000, NAT GENET, V25, P67; Clarke G, 2000, CLIN GENET, V57, P313, DOI 10.1034/j.1399-0004.2000.570501.x; D'Cruz PM, 2000, HUM MOL GENET, V9, P645, DOI 10.1093/hmg/9.4.645; John G.C., 1995, P 12 INT C MACH LEAR, P108; Katsanis N, 2002, P NATL ACAD SCI USA, V99, P14326, DOI 10.1073/pnas.222409099; Matsuda A, 1997, J NEUROIMMUNOL, V77, P85, DOI 10.1016/S0165-5728(97)00061-1; Monard MC, 2002, FR ART INT, V85, P173; Morrow EM, 1999, DEVELOPMENT, V126, P23; Patino WD, 2002, CIRC RES, V91, P565, DOI 10.1161/01.RES.0000036018.76903.18; Saeed AI, 2003, BIOTECHNIQUES, V34, P374; Sander J, 2005, ACM T INFORM SYST, V23, P35, DOI 10.1145/1055709.1055712; VELCULESCU VE, 1995, SCIENCE, V270, P484, DOI 10.1126/science.270.5235.484; Witten I. H., 2005, DATA MINING PRACTICA; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309; Yoshida S, 2004, HUM MOL GENET, V13, P1487, DOI 10.1093/hmg/ddh160	25	4	4	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 8	2006	7								116	10.1186/1471-2105-7-116		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	027KZ	WOS:000236415800001	
J	Shan, C; Zhang, L; Gao, Y				Shan, C; Zhang, L; Gao, Y			An integrated machine learning system to computationally screen protein databases for protein binding peptide ligands.	FASEB JOURNAL			English	Meeting Abstract	Experimental Biology 2006 Meeting	APR 01-05, 2006	San Francisco, CA	Amer Assoc Anatomists, Amer Physiol Soc, Amer Soc Biochem & Mol Biol, Amer Soc Investigat Pathol, Amer Soc Nutr, Amer Soc Pharmacol & Expt Therapeut					Chinese Acad Med Sci, Inst Basic Med Sci, Proteom Res Ctr, Natl Key Lab Med Mol Biol, Beijing 100005, Peoples R China								0	0	0	FEDERATION AMER SOC EXP BIOL	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3998 USA	0892-6638		FASEB J	Faseb J.	MAR 6	2006	20	4	1				A529	A529				1	Biochemistry & Molecular Biology; Biology; Cell Biology	Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other Topics; Cell Biology	024OW	WOS:000236206504306	
J	Thaler, ER; Hanson, CW				Thaler, ER; Hanson, CW			Use of an electronic nose to diagnose bacterial sinusitis	AMERICAN JOURNAL OF RHINOLOGY			English	Article								Background: Having previously established that all electronic nose (enose) can distinguish among bacteria samples, between cerebrospinal fluid leak and serum, and can identify patients with ventilator-associated pneumonia, we hypothesized that bacterial sinusitis could be diagnosed by sampling exhaled gas with an enose. Methods: Using a nasal continuous positive airway pressure mask, we sampled gas exhaled through the nose of patients with sinusitis and compared them with controls. Data were first projected onto the principal components and then classified by support vector machine (SVM), a machine learning algorithm for pattern recognition. Results: SVM analysis showed good discrimination using three approaches. First, 11 samples were used to create a training set that was used to predict whether individual samples from each set were a member of the control or infected sets. The enose was correct 98.4% of the time. Second, one-half of the samples from each of the same 11 control and infected groups were used to construct a training set, which was used to predict infection in the remaining samples. The enose was correct 82% of the time. Finally, 68 samples (34 positive and 34 controls) were analyzed using a leave-one-out scheme for creating training sets and testing sets. This method, designed to reflect the generalization property of the SVM classifier, scored a classification rate of 72%. Conclusion: Using the enose to sample nasal exhalation from patients with suspected sinusitis, we were able to predict correctly the diagnosis of sinusitis in at least 72% of the samples. The next step will be to do forward prediction using this model.	Univ Penn, Dept Otorhinolaryngol Head & Neck Surg, Philadelphia, PA 19104 USA; Univ Penn, Dept Anesthesia, Philadelphia, PA 19104 USA	Thaler, ER (reprint author), Univ Penn, Dept Otorhinolaryngol Head & Neck Surg, 5 Silverstein,3400 Spruce St, Philadelphia, PA 19104 USA.	Erica.thaler@uphs.upenn.edu					Lai SY, 2002, LARYNGOSCOPE, V112, P975, DOI 10.1097/00005537-200206000-00007; LANZA DD, 1997, HEAD NECK SURG, V117, pS1; Lonergan MC, 1996, CHEM MATER, V8, P2298, DOI 10.1021/cm960036j; Nagle HT, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.715180; Thaler ER, 2002, LARYNGOSCOPE, V112, P1533, DOI 10.1097/00005537-200209000-00002; Thaler ER, 2001, AM J RHINOL, V15, P291	6	13	13	OCEAN SIDE PUBLICATIONS INC	PROVIDENCE	95 PITMAN ST, PROVIDENCE, RI 02906 USA	1050-6586		AM J RHINOL	Am. J. Rhinol.	MAR-APR	2006	20	2					170	172				3	Otorhinolaryngology	Otorhinolaryngology	035LY	WOS:000237003900009	
J	Ng, SK; McLachlan, GJ; Lee, AH				Ng, SK; McLachlan, GJ; Lee, AH			An incremental EM-based learning approach for on-line prediction of hospital resource utilization	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						EM algorithm; mixture of experts; incremental update; length of stay; machine learning algorithm; on-line prediction	ARTIFICIAL NEURAL-NETWORK; MIXTURES-OF-EXPERTS; RECURRENT GASTROENTERITIS; HIERARCHICAL MIXTURES; MAXIMUM-LIKELIHOOD; WESTERN-AUSTRALIA; INCOMPLETE DATA; ECM ALGORITHM; MODEL; LENGTH	Objective: Inpatient length of stay (LOS) is an important measure of hospital activity, health care resource consumption, and patient acuity. This research work aims at developing an incremental expectation maximization (EM) based learning approach on mixture of experts (ME) system for on-line prediction of LOS. The use of a batchmode learning process in most existing artificial neural networks to predict LOS is unrealistic, as the data become available over time and their pattern change dynamically. In contrast, an on-line process is capable of providing an output whenever a new datum becomes available. This on-the-spot information is therefore more useful and practical for making decisions, especially when one deals with a tremendous amount of data. Methods and material: The proposed approach is illustrated using a real example of gastroenteritis LOS data. The data set was extracted from a retrospective cohort study on all infants born in 1995-1997 and their subsequent admissions for gastroenteritis. The total number of admissions in this data set was n = 692. Linked hospitalization records of the cohort were retrieved retrospectively to derive the outcome measure, patient demographics, and associated co-morbidities information. A comparative study of the incremental learning and the batch-mode learning algorithms is considered. The performances of the learning algorithms are compared based on the mean absolute difference (MAD) between the predictions and the actual LOS, and the proportion of predictions with MAD < 1 day (Prop(MAD < 1)). The significance of the comparison is assessed through a regression analysis. Results: The incremental learning algorithm provides better on-line prediction of LOS when the system has gained sufficient training from more examples (MAD = 1.77 days and Prop(MAD < 1) = 54.3%), compared to that using the batch-mode learning. The regression analysis indicates a significant decrease of MAD (p-value = 0.063) and a significant (p-value = 0.044) increase of Prop(MAD <= 1) with the incremental learning algorithm. Conclusions: The incrementat learning feature and the self-adaptive model-selection ability of the ME network enhance its effective adaptation to non-stationary LOS data. It is demonstrated that the incremental learning algorithm outperforms the batchmode algorithm in the on-tine prediction of LOS. (c) 2005 Elsevier B.V. All rights reserved.	Univ Queensland, Dept Math, Brisbane, Qld 4072, Australia; Univ Queensland, Inst Mol Biosci, Brisbane, Qld 4072, Australia; Curtin Univ Technol, Sch Publ Hlth, Perth, WA 6845, Australia	Ng, SK (reprint author), Univ Queensland, Dept Math, Brisbane, Qld 4072, Australia.	skn@maths.uq.edu.au	McLachlan, Geoffrey/A-1491-2008				Aitkin M, 2003, STAT COMPUT, V13, P227, DOI 10.1023/A:1024218716736; BOX GEP, 1964, J ROY STAT SOC B, V26, P211; Bridle J. S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DOMBI GW, 1995, J TRAUMA, V39, P915, DOI 10.1097/00005373-199511000-00016; Efron B., 1982, JACKKNIFE BOOTSTRAP; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Ishii S, 2001, NEURAL NETWORKS, V14, P1239, DOI 10.1016/S0893-6080(01)00094-6; Jacobs RA, 1997, NEURAL NETWORKS, V10, P231, DOI 10.1016/S0893-6080(96)00050-0; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jiang W, 1999, NEURAL NETWORKS, V12, P1253, DOI 10.1016/S0893-6080(99)00066-0; Jordan MI, 1995, NEURAL NETWORKS, V8, P1409, DOI 10.1016/0893-6080(95)00014-3; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Lai SH, 2005, ARTIF INTELL MED, V33, P89, DOI 10.1016/j.artmed.2004.03.008; Lee A H, 2001, Health Care Manag Sci, V4, P249, DOI 10.1023/A:1011810326113; Lee AH, 2004, ANN EPIDEMIOL, V14, P137, DOI 10.1016/S1047-2797(03)00127-3; Leung KM, 1998, AM J PUBLIC HEALTH, V88, P377, DOI 10.2105/AJPH.88.3.377; LOWELL WE, 1994, J AM MED INFORM ASSN, V1, P459; McLachlan G, 1997, EM ALGORITHM EXTENSI; Ng SK, 2003, STAT COMPUT, V13, P45, DOI 10.1023/A:1021987710829; MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.2307/2337198; MENG XL, 1994, ANN STAT, V22, P326, DOI 10.1214/aos/1176325371; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Ng SK, 2004, PATTERN RECOGN, V37, P1573, DOI 10.1016/j.patcog.2004.02.012; Ng SK, 2004, IEEE T NEURAL NETWOR, V15, P738, DOI 10.1109/TNN.2004.826217; Oigard TA, 2005, SIGNAL PROCESS, V85, P1655, DOI 10.1016/j.sigpro.2005.03.005; Park J, 2001, ARTIF INTELL MED, V23, P277, DOI 10.1016/S0933-3657(01)00086-0; Pofahl WE, 1998, AM SURGEON, V64, P868; Quantin C, 1999, J CLIN EPIDEMIOL, V52, P251, DOI 10.1016/S0895-4356(98)00164-4; Ripley BD, 1993, NETWORKS CHAOS STAT, P40; Sato M, 2000, NEURAL COMPUT, V12, P407, DOI 10.1162/089976600300015853; Spyropoulos CD, 2000, ARTIF INTELL MED, V20, P101, DOI 10.1016/S0933-3657(00)00059-2; TITTERINGTON DM, 1984, J ROY STAT SOC B MET, V46, P257; TRAVEN HGC, 1991, IEEE T NEURAL NETWOR, V2, P366, DOI 10.1109/72.97913; Walczak S, 2003, DECIS SUPPORT SYST, V34, P445, DOI 10.1016/S0167-9236(02)00071-4; Wang K, 2003, METHOD INFORM MED, V42, P251	36	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	MAR	2006	36	3					257	267		10.1016/j.artmed.2005.07.003		11	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	030EL	WOS:000236616800006	
J	Haigh, KZ; Kiff, LM; Ho, G				Haigh, KZ; Kiff, LM; Ho, G			The independent LifeStyle Assistant: Lessons learned	ASSISTIVE TECHNOLOGY			English	Article						elder care; passive monitoring; intent recognition; machine learning; ontology	MONITORING-SYSTEM; OLDER ADULTS; HOME; TECHNOLOGY; HEALTH; RECOGNITION; CAREGIVERS; SENSORS; SPEECH; PEOPLE	The Independent LifeStyle Assistant (I.L.S.A.) is an agent-based monitoring and support system to help elderly people live longer in their homes by reducing caregiver burden. I.L.S.A. is a multiagent system that incorporates a unified sensing model, situation assessments. response planning, real-time responses, and machine learning. This paper describes the six-month study of the system we fielded in elders' homes and the major lessons we learned during development.	BBN Technol, Cambridge, MA 02138 USA; Honeywell Labs, Minneapolis, MN USA	Haigh, KZ (reprint author), BBN Technol, 10 Moulton St, Cambridge, MA 02138 USA.						ABOWD G, 2002, P AAAI WORKSH AUT CA, P1; Al-Gahtani SS, 1999, BEHAV INFORM TECHNOL, V18, P277, DOI 10.1080/014492999119020; Allen B, 1996, MED ENG PHYS, V18, P203, DOI 10.1016/1350-4533(95)00074-7; ALWAN M, 2004, INT C IND AG DIS; BEAUDIN JS, 2004, 2004 C HUM FACT COMP, P1359; BELGRAVE LL, 1994, RES AGING, V16, P115, DOI 10.1177/0164027594162001; BERCK, 2001, STAR TRIBUNE    0416; Black BS, 1999, GERONTOLOGIST, V39, P559; Breznitz S., 1984, CRY WOLF PSYCHOL FAL; CAMPO E, 2002, P AAAI 02 WORKSH AUT, P8; CELLER BG, 1995, INT J BIOMED COMPUT, V40, P147, DOI 10.1016/0020-7101(95)01139-6; COHEN MA, 1986, J GERONTOL, V41, P785; Czaja S. J, 1997, HDB HUMAN FACTORS OL, P311; CZAJA SJ, 1996, AGING SKILLED PERFOR; CZAJA SJ, 1989, BEHAV INFORM TECHNOL, V8, P309; CZAJA SJ, 2001, COMMUNICATION TECHNO; DELANO K, 2001, P HUM FACT ERG SOC 4; DENNO S, 1992, SSDCSYSAIC92009; Duncan RP, 1997, J RURAL HEALTH, V13, P118, DOI 10.1111/j.1748-0361.1997.tb00941.x; Femia EE, 1997, J GERONTOL B-PSYCHOL, V52, P294; FOLSTEIN MF, 2005, MMSE MINIMETAL STATE; Fulmer T T, 1999, J Gerontol Nurs, V25, P6; GALLAGHER D, 1989, GERONTOLOGIST, V29, P449; GALLAGHER EM, 2002, LAYING GROUNDWORK IM; Gallienne R L, 1993, J Gerontol Nurs, V19, P15; GEIB C, 2000, P AAAI 02 WORKSH AUT, P13; Geib C. W., 2001, Proceedings of the Fourteenth International Florida Artificial Intelligence Research Society Conference; GEIB CW, 2003, P IJCAI 2003, P151; Gennari J., 2002, SMI20020943 STANF U; GITLIN LN, 1995, GENERATIONS, V19, P41; Glascock AP, 2000, TELEMED J, V6, P33, DOI 10.1089/107830200311833; Guralnik V., 2002, P AAAI 02 WORKSH AUT, P24; Haigh K. Z., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems; Haigh K.Z., 2002, P AAAI 02 WORKSH AUT, P39; HAIGH KZ, 2002, P AAAI WORKSH AUT CA, P31; HAIGH KZ, 2005, UNPUB AAAI 2005 FALL; HAIGH KZ, 2003, ACSP03023; HO G, 2005, UNPUB AAAI 2005 FALL; INADA H, 1992, P 7 WORLD C MED INF, P349; Kautz H., 2002, P AAAI WORKSH AUT CA, P60; KIFF L, 2003, P INT C AG DIS IND I; Koester HH, 2001, ASSIST TECHNOL, V13, P116; KRICHBAUM K, 2002, IND WORKSHOP TECHNOL; Laguna K, 1997, COMPUT HUM BEHAV, V13, P317, DOI 10.1016/S0747-5632(97)00012-5; LEIKAS J, 1998, P GER 2 INT C, P402; LISETTI CL, 2002, P AAAI 02 WORKSH AUT, P67; LYTLE JM, 2002, BBC NEWS ONLINE 0221; Mann W C, 1992, Assist Technol, V4, P60; MONTGOMERY RJV, 2000, WHO SHOULD CARE ELDE; MONTGOMERY RJV, 1985, FAM RELAT, V34, P19, DOI 10.2307/583753; MORRELL RW, 1996, ADV THEORY APPL; MORRISS R, 1996, INT J GERIATR PSYCH, V11, P242; MORRISSEY W, 2001, P HCI INT, P700; Morrow D, 2000, HUM FACTORS, V42, P523, DOI 10.1518/001872000779698042; Noonan AE, 1999, J GERONTOL SOC WORK, V31, P5, DOI 10.1300/J083v31n03_02; Noury N., 2000, P IEEE EMBS MICR MED, P607, DOI 10.1109/MMB.2000. 893857; PHILIPOSE M, 2004, IEEE PERVASIVE C OCT, P50; Pineau J, 2003, ROBOT AUTON SYST, V42, P271, DOI 10.1016/S0921-8890(02)00381-0; REED WC, 2003, Patent No. 6524239; Rogers WA, 1996, HUM FACTORS, V38, P425, DOI 10.1518/001872096778701935; ROZHON T, 2001, STAR TRIBUNE; SCHWARZ N, 1999, COGNITIVE AGING PRIM, P233; Shugarman L R, 1999, Home Health Care Serv Q, V18, P25; Sixsmith AJ, 2000, J TELEMED TELECARE, V6, P63, DOI 10.1258/1357633001935059; SMITHER JA, 1993, BEHAV INFORM TECHNOL, V12, P330; TAMURA T, 1988, CLIN PHYS PHYSIOL M, V9, P139, DOI 10.1088/0143-0815/9/2/006; Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158; TUN PA, 1997, HDB HUMAN FACTORS OL; VALLES M, 1996, IEEE ENG MED BIOL S, P516; WAGNER TA, 2002, P AAAI 02 WORKSH AUT, P100; WARE JE, 2005, SF 36 HLTH SURVEY UP; WARREN S, 1999, WORKSHOPS FUTURE MED, V2, P667; Yamaguchi A, 1998, P ANN INT IEEE EMBS, V20, P1977; *VIG HLTH MAN INC, 2002, SOL FULL CONT CAR; 2005, INDEPENDENT LIFE STY	75	17	17	R E S N A PRESS	ARLINGTON	1700 MOORE ST, STE 1540, ARLINGTON, VA 22209-1903 USA	1040-0435		ASSIST TECHNOL	Assist. Technol.	SPR	2006	18	1					87	106				20	Rehabilitation	Rehabilitation	046UZ	WOS:000237837900009	
J	Tuikkala, J; Elo, L; Nevalainen, OS; Aittokallio, T				Tuikkala, J; Elo, L; Nevalainen, OS; Aittokallio, T			Improving missing value estimation in microarray data with gene ontology	BIOINFORMATICS			English	Article							SACCHAROMYCES-CEREVISIAE; DNA MICROARRAY; EXPRESSION; IMPUTATION; ANNOTATION; YEAST	Motivation: Gene expression microarray experiments produce datasets with frequent missing expression values. Accurate estimation of missing values is an important prerequisite for efficient data analysis as many statistical and machine learning techniques either require a complete dataset or their results are significantly dependent on the quality of such estimates. A limitation of the existing estimation methods for microarray data is that they use no external information but the estimation is based solely on the expression data. We hypothesized that utilizing a priori information on functional similarities available from public databases facilitates the missing value estimation. Results: We investigated whether semantic similarity originating from gene ontology (GO) annotations could improve the selection of relevant genes for missing value estimation. The relative contribution of each information source was automatically estimated from the data using an adaptive weight selection procedure. Our experimental results in yeast cDNA microarray datasets indicated that by considering GO information in the k-nearest neighbor algorithm we can enhance its performance considerably, especially when the number of experimental conditions is small and the percentage of missing values is high. The increase of performance was less evident with a more sophisticated estimation method. We conclude that even a small proportion of annotated genes can provide improvements in data quality significant for the eventual interpretation of the microarray experiments. Availability: Java and Matlab codes are available on request from the authors. Supplementary material: Available online at http://users.utu.fi/jotatu/GOImpute.htm Contact: jotatu@utu.fi.	Univ Turku, Dept Informat Technol, FIN-20520 Turku, Finland; Univ Turku, Dept Math, FIN-20014 Turku, Finland; TUCS, FIN-20520 Turku, Finland; Turku Ctr Biotechnol, FIN-20521 Turku, Finland	Tuikkala, J (reprint author), Univ Turku, Dept Informat Technol, Lemminkaisenkatu 14A, FIN-20520 Turku, Finland.	jotatu@utu.fi	Aittokallio, Tero/B-6583-2009				Allocco DJ, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-18; Beissbarth T, 2004, BIOINFORMATICS, V20, P1464, DOI 10.1093/bioinformatics/bth088; Bo TH, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh026; Ashburner M, 2000, NAT GENET, V25, P25; Carey J, 2003, NATO SCI SER II MATH, V90, P213; de Brevern AG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-114; DeRisi JL, 1997, SCIENCE, V278, P680, DOI 10.1126/science.278.5338.680; Feten G, 2005, STAT APPL GENET MO B, V4; Gibbons FD, 2002, GENOME RES, V12, P1574, DOI 10.1101/gr.397002; Kim H, 2005, BIOINFORMATICS, V21, P187, DOI 10.1093/bioinformatics/bth499; Kim KY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-160; Lee SG, 2004, BIOINFORMATICS, V20, P381, DOI 10.1093/bioinformatics/btg420; Little R. J., 1987, STAT ANAL MISSING DA; Liu L, 2003, P NATL ACAD SCI USA, V100, P13167, DOI 10.1073/pnas.1733249100; Lockhart DJ, 2000, NATURE, V405, P827, DOI 10.1038/35015701; Lord PW, 2003, BIOINFORMATICS, V19, P1275, DOI 10.1093/bioinformatics/btg153; Oba S, 2003, BIOINFORMATICS, V19, P2088, DOI 10.1093/bioinformatics/btg287; Ogawa N, 2000, MOL BIOL CELL, V11, P4309; Ouyang M, 2004, BIOINFORMATICS, V20, P917, DOI 10.1093/bioinformatics/bth007; Raghava GPS, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-59; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Sehgal MSB, 2005, BIOINFORMATICS, V21, P2417, DOI 10.1093/bioinformatics/bti345; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Wyrick JJ, 1999, NATURE, V402, P418; Zhou XB, 2003, BIOINFORMATICS, V19, P2302, DOI 10.1093/bioinformatics/btg323	26	48	52	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 1	2006	22	5					566	572		10.1093/bioinformatics/btk019		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	016EV	WOS:000235604400008	
J	Amato, R; Ciaramella, A; Deniskina, N; Del Mondo, C; di Bernardo, D; Donalek, C; Longo, G; Mangano, G; Miele, G; Raiconi, G; Staiano, A; Tagliaferri, R				Amato, R; Ciaramella, A; Deniskina, N; Del Mondo, C; di Bernardo, D; Donalek, C; Longo, G; Mangano, G; Miele, G; Raiconi, G; Staiano, A; Tagliaferri, R			A multi-step approach to time series analysis and gene expression clustering	BIOINFORMATICS			English	Article							INDEPENDENT COMPONENT ANALYSIS; CYCLE-REGULATED GENES; SELF-ORGANIZING MAPS; CELL-CYCLE; SACCHAROMYCES-CEREVISIAE; SPECTRAL-ANALYSIS; NEURAL-NETWORKS; PATTERNS; MODELS; IDENTIFICATION	Motivation: The huge growth in gene expression data calls for the implementation of automatic tools for data processing and interpretation. Results: We present a new and comprehensive machine learning data mining framework consisting in a non-linear PCA neural network for feature extraction, and probabilistic principal surfaces combined with an agglomerative approach based on Negentropy aimed at clustering gene microarray data. The method, which provides a user-friendly visualization interface, can work on noisy data with missing points and represents an automatic procedure to get, with no a priori assumptions, the number of clusters present in the data. Cell-cycle dataset and a detailed analysis confirm the biological nature of the most significant clusters. Availability: The software described here is a subpackage part of the ASTRONEURAL package and is available upon request from the corresponding author. Contact: robtag@unisa.it Supplementary information: Supplementary data are available at Bioinformatics online.	Univ Salerno, Dipartimento Matemat & Informat, I-84100 Salerno, Italy; Univ Naples Federico II, Dipartimento Sci Fis, Naples, Italy; Russian Acad Sci, Inst Informat Transmiss Problems, Moscow 101447, Russia; Telethon Inst Genet & Med, Naples, Italy; CALTECH, Dept Astron, Pasadena, CA 91125 USA; Ist Nazl Fis Nucl, I-80125 Naples, Italy; INAF, Ist Nazl Astrofis, Sez Napoli, Naples, Italy; Syracuse Univ, Dept Phys, Syracuse, NY USA	Tagliaferri, R (reprint author), Univ Salerno, Dipartimento Matemat & Informat, I-84100 Salerno, Italy.	robtag@unisa.it	Miele, Gennaro/F-3628-2010; di Bernardo, Diego/I-9440-2012; Staiano, Antonino/B-6781-2013	di Bernardo, Diego/0000-0002-1911-7407; Staiano, Antonino/0000-0002-4708-5860			Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Ando T, 2002, JPN J CANCER RES, V93, P1207; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bussemaker HJ, 2001, NAT GENET, V27, P167, DOI 10.1038/84792; CHANG JH, 2003, GENOM INFORM, V1, P32; CHANG K, 2000, THESIS U TEXAS AUSTI; CHANG K, 2001, IEEE T PATTERN ANAL, V23, pN1; Chen Y, 1997, J Biomed Opt, V2, P364, DOI 10.1117/1.429838; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Christie KR, 2004, NUCLEIC ACIDS RES, V32, pD311, DOI 10.1093/nar/gkh033; Ciaramella A, 2004, ASTRON ASTROPHYS, V419, P485, DOI 10.1051/0004-6361:20035771; de Lichtenberg U, 2005, BIOINFORMATICS, V21, P1164, DOI 10.1093/bioinformatics/bti093; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; di Bernardo D, 2005, NAT BIOTECHNOL, V23, P377, DOI 10.1038/nbt1075; Duda R. O., 2001, PATTERN CLASSIFICATI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Ermolaeva O, 1998, NAT GENET, V20, P19; Hastie T, 2001, ELEMENTS STAT LEARNI; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; KARHUNEN J, 1994, NEURAL NETWORKS, V7, P113, DOI 10.1016/0893-6080(94)90060-4; KARHUNEN J, 1995, NEURAL NETWORKS, V8, P549, DOI 10.1016/0893-6080(94)00098-7; Kerr MK, 2001, GENET RES, V77, P123, DOI 10.1017/S0016672301005055; Kohonen T., 1995, SELF ORG MAPS; Lee SI, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-11-r76; Liebermeister W, 2002, BIOINFORMATICS, V18, P51, DOI 10.1093/bioinformatics/18.1.51; MARTINS A, 2004, P INT JOINT C NEUR N, P1; Misra J, 2002, GENOME RES, V12, P1112, DOI 10.1101/gr.225302; MUKHERJEE M, 1999, SUPPORT VECTOR MACHI, P182; OJA E, 1991, ARTIFICIAL NEURAL NETWORKS, VOLS 1 AND 2, P385; Oja E., 1996, Proceedings of the 7th Italian Workshop on Neural Nets. Neural Nets. WIRN Vietri-95; Purdom E, 2005, STAT APPL GENET MO B, V4; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; STAIANO A, 2005, WORLD SCI SERIES, V17, P63; STAIANO A, 2003, THESIS U SALERNO ITA; Tagliaferri R, 1999, ASTRON ASTROPHYS SUP, V137, P391, DOI 10.1051/aas:1999254; Tagliaferri R, 2001, COMPUT GEOSCI-UK, V27, P535, DOI 10.1016/S0098-3004(00)00166-7; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4; Townsend JP, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-54; Townsend JP, 2002, GENOME BIOL, V3, P71; Tseng GC, 2001, NUCLEIC ACIDS RES, V29, P2549, DOI 10.1093/nar/29.12.2549; Wolfinger RD, 2001, J COMPUT BIOL, V8, P625, DOI 10.1089/106652701753307520; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977	46	28	28	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAR 1	2006	22	5					589	596		10.1093/bioinformatics/btk026		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	016EV	WOS:000235604400011	
J	Larranaga, P; Calvo, B; Santana, R; Bielza, C; Galdiano, J; Inza, I; Lozano, JA; Armananzas, R; Santafe, G; Perez, A; Robles, V				Larranaga, Pedro; Calvo, Borja; Santana, Roberto; Bielza, Concha; Galdiano, Josu; Inza, Inaki; Lozano, Jose A.; Armananzas, Ruben; Santafe, Guzman; Perez, Aritz; Robles, Victor			Machine learning in bioinformatics	BRIEFINGS IN BIOINFORMATICS			English	Review						machine learning; bioinformatics; supervised classification; clustering; probabilistic graphical models; optimisation; heuristic; genomics; proteomics; microarray; system biology; evolution; text mining	GENE-EXPRESSION DATA; FEATURE SUBSET-SELECTION; PROTEIN SECONDARY STRUCTURE; MULTIPLE SEQUENCE ALIGNMENT; SIDE-CHAIN CONFORMATIONS; SPLICE-SITE PREDICTION; MICROARRAY DATA; MAXIMUM-LIKELIHOOD; BAYESIAN NETWORKS; CROSS-VALIDATION	This article reviews machine learning methods for bioinformatics. It presents modelling methods, such as supervised classification, clustering and probabilistic graphical models for knowledge discovery, as well as deterministic and stochastic heuristics for optimization. Applications in genomics, proteomics, systems biology, evolution and text mining are also shown.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, San Sebastian 20018, Spain; Madrid Tech Univ, Sch Comp Sci, Madrid, Spain; Harvard Univ, Sch Med, Cambridge, MA 02138 USA; Univ Politecn Madrid, Dept Comp Syst Architecture & Technol, E-28040 Madrid, Spain	Larranaga, P (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, Paseo Manuel Lardizabal 1, San Sebastian 20018, Spain.	pedro.larranaga@ehu.es	Lozano, Jose/F-5120-2010; Santana, Roberto/B-2799-2009; Calvo, Borja/D-8814-2012; Armananzas, Ruben/C-2735-2013; Bielza, Concha/F-9277-2013; Larranaga, Pedro/F-9293-2013	Santana, Roberto/0000-0002-1005-8535; Armananzas, Ruben/0000-0003-4049-0000; 			Aerts S, 2004, BIOINFORMATICS, V20, P1974, DOI 10.1093/bioinformatics/bth179; AJRDINE N, 1971, MAT TAXONOMY; Allen JE, 2004, GENOME RES, V14, P142, DOI 10.1101/gr.1562804; ALLON G, 1999, SODA 99 P 10 ANN ACM, P955; Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; AMTSUURA T, 2005, IN PRESS P 6 MET INT; Ando S., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1006249; Ando S, 2002, INFORM SCIENCES, V145, P237, DOI 10.1016/S0020-0255(02)00235-9; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Baldi P., 2001, BIOINFORMATICS MACHI; Bao L, 2005, BIOINFORMATICS, V21, P2185, DOI 10.1093/bioinformatics/bti365; Barker D, 2004, BIOINFORMATICS, V20, P274, DOI 10.1093/bioinformatics/btg402; Baumgartner C, 2004, BIOINFORMATICS, V20, P2985, DOI 10.1093/bioinformatics/bth343; Ben-Bassat M., 1982, HDB STATISTICS, V1, P773, DOI 10.1016/S0169-7161(82)02038-0; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Bhandarkar S. M., 2002, Proceedings IEEE Computer Society Bioinformatics Conference, DOI 10.1109/CSB.2002.1039330; BLANCO R, 2001, P WORKSH BAY MOD MED, P29; Blazewicz J, 2005, LECT NOTES COMPUT SC, V3449, P22; Blazewicz J, 2005, BIOINFORMATICS, V21, P2356, DOI 10.1093/bioinformatics/bti351; Blazewicz J, 2005, ARTIF INTELL MED, V35, P135, DOI 10.1016/j.artmed.2005.02.001; Blazewicz J, 2004, COMPUT BIOL CHEM, V28, P11, DOI 10.1016/j.compbiolchem.2003.12.002; Bockhorst J, 2003, BIOINFORMATICS, V19, P1227, DOI 10.1093/bioinformatics/btg147; Bohning D, 2003, COMPUT STAT DATA AN, V41, P349, DOI 10.1016/S0167-9473(02)00161-5; Bower J., 2004, COMPUTATIONAL MODELI; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L., 1993, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; BROWN MPS, 2004, J COMPUT BIOL, V11, P227; Bryan K, 2005, COMP MED SY, P383, DOI 10.1109/CBMS.2005.37; Cai DY, 2000, BIOINFORMATICS, V16, P152, DOI 10.1093/bioinformatics/16.2.152; Carter RJ, 2001, NUCLEIC ACIDS RES, V29, P3928; Castelo R, 2004, BIOINFORMATICS, V20, P69, DOI 10.1093/bioinformatics/bth932; CAWLEY SL, 2003, BIOINFORMATICS S2, V19, P36; Chang MF, 2002, WIREL COMMUN MOB COM, V2, P169, DOI 10.1002/wcm.43; Chen T, 2001, J COMPUT BIOL, V8, P325, DOI 10.1089/10665270152530872; Chickering DM, 1994, LEARNING BAYESIAN NE; Chickering M, 1996, P 12 INT C UNC ART I, P150; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Christof T, 1997, J COMPUT BIOL, V4, P433, DOI 10.1089/cmb.1997.4.433; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Cowell R. G., 1999, PROBABILISTIC NETWOR; DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1; Degroeve S, 2002, BIOINFORMATICS, V18, pS75; de Hoon M J L, 2004, Bioinformatics, V20 Suppl 1, pi101, DOI 10.1093/bioinformatics/bth927; De Maeyer M, 2000, METH MOL B, V143, P265; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DESMET F, 2002, BIOINFORMATICS, V20, P660; Devroye L., 1996, PROBABILISTIC THEORY; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R. O., 2001, PATTERN CLASSIFICATI; Duda R.O, 1973, PATTERN CLASSIFICATI; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Durbin R., 1998, BIOL SEQUENCE ANAL P; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Ellrott K, 2002, BIOINFORMATICS, V18, P100; FALKENAUER E, 2002, EVOLUTIONARY COMPUTA, P219; Fiser A, 2000, PROTEIN SCI, V9, P1753; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, USAF SCH AVIATION ME, V4, P261; Fogel G. B., 2002, EVOLUTIONARY COMPUTA, P195; Fogel GB, 2002, NUCLEIC ACIDS RES, V30, P5310, DOI 10.1093/nar/gkf653; FOGEL GB, 2002, EVOLUTIONARY COMPUTA; FOGEL GB, 2005, IEEE CONNECTIONS, V3, P11; FORGY EW, 1965, BIOMETRICS, V21, P768; FRASCONI P, 2003, NATO SCI SERIES COMP; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; Fukunaga K., 1990, INTRO STAT PATTERN R; Geiger D., 1994, LEARNING GAUSSIAN NE; Gersho A., 1992, VECTOR QUANTIZATION; GILMAN A, 1995, BIOPHYS J, V69, P1321; Glick M, 2002, P NATL ACAD SCI USA, V99, P703, DOI 10.1073/pnas.022418199; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; Goldberg DE, 1989, GENETIC ALGORITHMS S; GREEN DM, 1974, SIGNAL DETECTION THE; Greenspan G, 2004, BIOINFORMATICS, V20, P137, DOI 10.1093/bioinformatics/bth907; Guindon S, 2003, SYST BIOL, V52, P696, DOI 10.1080/10635150390235520; Hartemink AJ, 2001, PAC S BIOCOMPUT, V6, P422; Hastie T, 2001, ELEMENTS STAT LEARNI; Hautaniemi S, 2005, BIOINFORMATICS, V21, P2027, DOI 10.1093/bioinformatics/bti278; HECKERMAN D, 1995, TUTORAL LEARNING BAY; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; Higgins D, 2000, BIOINFORMATICS SEQUE; HIROSAWA M, 1995, COMPUT APPL BIOSCI, V11, P13; HSU HP, 2003, PHYS REV E, V68; Hsu HP, 2003, J CHEM PHYS, V118, P444, DOI 10.1063/1.1522710; Huang JL, 2003, BIOINFORMATICS, V19, P1303, DOI 10.1093/bioinformatics/btg166; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Husmeier D, 2003, BIOCHEM SOC T, V31, P1516; Husmeier D., 2005, PROBABILISTIC MODELI; HUSMEIER D, 2005, INFERRING GENETIC RE, P239; Hwang K.-B., 2001, METHODS MICROARRAY D, P167; Imoto S., 2003, P EUR C COMP BIOL; Imoto S, 2002, GENOME INFORMATICS, V13, P369; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; Inza I, 2002, J INTELL FUZZY SYST, V12, P25; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; ISHIKAWA M, 1993, COMPUT APPL BIOSCI, V9, P267; Jacob E, 2005, BIOINFORMATICS, V21, P1403, DOI 10.1093/bioinformatics/bti156; Jagota A, 2000, DATA ANAL CLASSIFICA; Jarvis RM, 2005, BIOINFORMATICS, V21, P860, DOI 10.1093/bioinformatics/bti102; JENSEN F, 2001, BAYESIAN NETWORKS DE; JIANG T, 2002, CURRENT TOPICS COMPU; Jojic V, 2004, BIOINFORMATICS, V20, P161, DOI 10.1093/bioinformatics/bth917; Jung HY, 2002, BIOINFORMATICS, V18, pS141; Keith JM, 2002, BIOINFORMATICS, V18, P1494, DOI 10.1093/bioinformatics/18.11.1494; Kikuchi S, 2003, BIOINFORMATICS, V19, P643, DOI 10.1093/bioinformatics/btg027; Kim J, 1996, COMPUT APPL BIOSCI, V12, P259; Kim KJ, 2004, NEUROCOMPUTING, V61, P361, DOI 10.1016/j.neucom.2003.11.008; Kim S, 2004, BIOINFORMATICS, V20, P40, DOI 10.1093/bioinformatics/btg368; Kimura S, 2005, BIOINFORMATICS, V21, P1154, DOI 10.1093/bioinformatics/bti071; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kittler J., 1978, Pattern Recognition and Signal Processing; KLEINBAUM DG, 1982, COMMUN STAT A-THEOR, V11, P485, DOI 10.1080/03610928208828251; Knudsen S, 1999, BIOINFORMATICS, V15, P356, DOI 10.1093/bioinformatics/15.5.356; Koehl P, 1998, J CHEM PHYS, V108, P9540, DOI 10.1063/1.476402; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koza J. R., 1992, GENETIC PROGRAMMING; Koza J. R., 2001, PACIFIC S BIOCOMPUTI, P434; Krallinger M, 2005, DRUG DISCOV TODAY, V10, P439, DOI 10.1016/S1359-6446(05)03376-3; Krasnogor N., 2002, LECT NOTES COMPUTER, P769; Krishnapuram B, 2004, J COMPUT BIOL, V11, P227, DOI 10.1089/1066527041410463; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Kumar S, 1996, MOL BIOL EVOL, V13, P584; KUNCHEVA L, 1993, INFORM PROCESS LETT, V46, P163, DOI 10.1016/0020-0190(93)90021-Z; KUNCHEVA LI, 2004, COMBINING PATTERN CL; LAMONT GB, 2002, EVOLUTIONARY COMPUTA, P137; Larranaga P, 2002, ESTIMATION DISTRIBUT; LARRANAGA P, 2003, ARTIF INTELL, V31, pR3; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 2005, DATA ANALYSIS AND VISUALIZATION IN GENOMICS AND PROTEOMICS, P215, DOI 10.1002/0470094419.ch13; Lauritzen S. L., 1996, GRAPHICAL MODELS; LEE C, 1991, J MOL BIOL, V217, P373, DOI 10.1016/0022-2836(91)90550-P; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Lee PH, 2005, BIOINFORMATICS, V21, P2739, DOI 10.1093/bioinformatics/bti406; Leone M, 2005, BIOINFORMATICS, V21, P239, DOI 10.1093/bioinformatics/bth491; Lesh N, 2003, P 7 ANN INT C RES CO, P188, DOI 10.1145/640075.640099; Li HL, 2005, BIOINFORMATICS, V21, P1838, DOI 10.1093/bioinformatics/bti286; LI J, 2005, IEEE INTELLIGENT SYS, V20; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li LP, 2004, BIOINFORMATICS, V20, P1638, DOI 10.1093/bioinformatics/bth098; Liang FM, 2001, J CHEM PHYS, V115, P3374, DOI 10.1063/1.1387478; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Ling CX, 2005, IEEE ACM T COMPUT BI, V2, P81, DOI 10.1109/TCBB.2005.25; Liu H, 1998, FEATURE SELECTION KN; Liu ZJ, 2003, PROTEINS, V50, P49, DOI 10.1002/prot.10253; Looger LL, 2001, J MOL BIOL, V307, P429, DOI 10.1006/jmbi.2000.4424; Lopez-Bigas N, 2004, NUCLEIC ACIDS RES, V32, P3108, DOI 10.1093/nar/gkh605; Lukashin AV, 2001, BIOINFORMATICS, V17, P405, DOI 10.1093/bioinformatics/17.5.405; MacCallum RM, 2004, BIOINFORMATICS, V20, P224, DOI 10.1093/bioinformatics/bth913; Markowetz F., 2003, P EUR C COMP BIOL; Mathe C, 2002, NUCLEIC ACIDS RES, V30, P4103, DOI 10.1093/nar/gkf543; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; McLachlan G. J., 1988, MIXTURE MODELS INFER; McLachlan G.J., 1992, DISCRIMINANT ANAL ST; MCLACHLAN GJ, 2002, P IEEE, V90, P1722; McNaught J, 2006, TEXT MINING BIOL BIO; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Meyer IM, 2004, NUCLEIC ACIDS RES, V32, P776, DOI 10.1093/nar/gkh211; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Middendorf M, 2004, BIOINFORMATICS, V20, P232, DOI 10.1093/bioinformatics/bth923; Minsky M., 1961, T I RADIO ENG, V49, P8; Mitchell T, 1997, MACHINE LEARNING; Moreira A, 2004, THEOR COMPUT SCI, V322, P297, DOI 10.1016/j.tcs.2004.03.014; Murphy K, 1999, MODELLING GENE EXPRE; Nachman I, 2004, Bioinformatics, V20 Suppl 1, pi248, DOI 10.1093/bioinformatics/bth941; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Nariai N, 2004, Pac Symp Biocomput, P336; Neapolitan E, 2003, LEARNING BAYESIAN NE; Neuwald AF, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-157; Nguyen Hung Dinh, 2002, Genome Inform, V13, P123; Noman N., 2005, P 2005 C GEN EV COMP, P439, DOI 10.1145/1068009.1068079; Olshen AB, 2002, BIOINFORMATICS, V18, P961, DOI 10.1093/bioinformatics/18.7.961; Ong Irene M, 2002, Bioinformatics, V18 Suppl 1, pS241; ONG IM, 2001, 1426 U WISC MAD COMP; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; Pan W, 2002, BIOINFORMATICS, V18, P546, DOI 10.1093/bioinformatics/18.4.546; Park LJ, 1997, MED BIOL ENG COMPUT, V35, P47, DOI 10.1007/BF02510391; Pasanen T, 2003, DNA MICROARRAY DATA; Pavlovic V, 2002, BIOINFORMATICS, V18, P19, DOI 10.1093/bioinformatics/18.1.19; PAZZANI MJ, 1997, ARTIFICIAL INTELLIGE, V4; Pe'er D., 2001, BIOINFORMATICS S1, V17, P215; Pearl J, 2000, CAUSALITY MODELS REA; Pearl J., 1988, PROBABILISTIC REASON; Pena JM, 2005, BIOINFORMATICS, V21, P224, DOI 10.1093/bioinformatics/bti1137; Perner P, 2002, ARTIF INTELL MED, V26, P161, DOI 10.1016/S0933-3657(02)00057-X; Pevzner P. A., 2000, COMPUTATIONAL MOL BI; Pollastri G, 2002, Bioinformatics, V18 Suppl 1, pS62; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; RAMASWAMY S, 2001, BIOINFORMATICS, V1, pS316; RANGELAND C, 2005, MODELLING GENETIC RE, P269; Raval A, 2002, BIOINFORMATICS, V18, P788, DOI 10.1093/bioinformatics/18.6.788; RIAZ T, 2004, P 2 AS PAC BIOINF C, P223; Ribeiro C. C., 2005, International Transactions in Operational Research, V12, DOI 10.1111/j.1475-3995.2005.498_1.x; RITCHIE MD, 2003, BMC BIOINFORMATICS, V4, P7; Robles JR, 2004, BIOINFORMATICS, V20, P3244, DOI 10.1093/bioinformatics/bth348; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saeys Y., 2003, BIOINFORMATICS, V19, pii179; Saeys Y, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-64; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Sakamoto E, 2001, IEEE C EVOL COMPUTAT, P720, DOI 10.1109/CEC.2001.934462; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Salzberg S, 1995, J Comput Biol, V2, P473, DOI 10.1089/cmb.1995.2.473; Santana R, 2004, LECT NOTES COMPUT SC, V3337, P388; Satten GA, 2004, BIOINFORMATICS, V20, P3128, DOI 10.1093/bioinformatics/bth372; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; Schneider TD, 1996, DISCRETE APPL MATH, V71, P259, DOI 10.1016/S0166-218X(96)00068-6; Scholkopf B., 1999, ADV KERNEL METHODS S; Scholkopf B, 2004, KERNEL METHODS COMPU; Sebban M, 2002, BIOINFORMATICS, V18, P235, DOI 10.1093/bioinformatics/18.2.235; Segal E., 2001, BIOINFORMATICS S1, V17, pS243; SEIFFERT U, 2005, BIOINFORMATICS USING; Selbig J, 1999, BIOINFORMATICS, V15, P1039, DOI 10.1093/bioinformatics/15.12.1039; SHACHTER RD, 1989, MANAGE SCI, V35, P527, DOI 10.1287/mnsc.35.5.527; Sheng Q., 2003, BIOINFORMATICS S2, V19, pii196; Sheng QZ, 2005, DATA ANALYSIS AND VISUALIZATION IN GENOMICS AND PROTEOMICS, P153, DOI 10.1002/0470094419.ch10; Sherlock G, 2001, Brief Bioinform, V2, P350, DOI 10.1093/bib/2.4.350; SHI W, 2005, BIOINFORMATICS TECHN, P244; SHLOCK D, 2002, EVOLUTIONARY COMPUTA, P231; Shmulevich I, 2002, BIOINFORMATICS, V18, P555, DOI 10.1093/bioinformatics/18.4.555; Sima C, 2005, BIOINFORMATICS, V21, P1046, DOI 10.1093/bioinformatics/bti081; Smith J, 2004, RECENT ADV MEMETIC A, P105; Smith PWF, 1998, NATO ADV SCI I D-BEH, V89, P555; SPELLMAN PT, 1998, MOL BIOL CELL, V9, P3271; Spirtes P., 2000, P ATL S COMP BIOL; Stapley B J, 2002, Pac Symp Biocomput, P374; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Steffen M, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-34; STONE M, 1974, J R STAT SOC B, V36, P111; Sugimoto Naoya, 2004, Genome Inform, V15, P121; TAKAHO A, 2004, BIOINFORMATICS, V20, P2181; Tamada Y., 2003, BIOINFORMATICS, V19, pii227; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tan SN, 2002, C T COL I S, V3, P83; Troyanskaya OG, 2002, BIOINFORMATICS, V18, P1454, DOI 10.1093/bioinformatics/18.11.1454; TUFFERY P, 1991, J BIOMOL STRUCT DYN, V8, P1267; Valafar F, 2002, ANN NY ACAD SCI, V980, P41; Vapnik V. N, 1995, NATURE STAT LEARNING; Vision TJ, 2000, GENETICS, V155, P407; Wang JTL., 2004, DATA MINING BIOINFOR; Wang RS, 2005, BIOINFORMATICS, V21, P2456, DOI 10.1093/bioinformatics/bti352; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; Webb A.R., 2002, STAT PATTERN RECOGNI; Wit E, 2005, J ROY STAT SOC C-APP, V54, P817, DOI 10.1111/j.1467-9876.2005.00519.x; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Won KJ, 2004, BIOINFORMATICS, V20, P3613, DOI 10.1093/bioinformatics/bth454; Wren JD, 2004, DNA CELL BIOL, V23, P695, DOI 10.1089/1044549042476929; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Wu C.H., 2000, NEURAL NETWORKS GENO; Wu JS, 2004, BIOINFORMATICS, V20, P1710, DOI 10.1093/bioinformatics/bth147; Wu X., 2003, BIOKDD03 3 ACM SIGKD, P63; Xing E., 2001, P 18 INT C MACH LEAR, P601; YANG C, 2004, BIOINFORMATICS, V20, P371; Yang JM, 2002, PROTEIN SCI, V11, P1897, DOI 10.1110/ps.4940102; Yanover C., 2002, ADV NEURAL INFORM PR, V15, P1457; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; Zhou GD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S7; Zuker M, 2003, NUCLEIC ACIDS RES, V31, P3406, DOI 10.1093/nar/gkg595	272	82	84	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463		BRIEF BIOINFORM	Brief. Bioinform.	MAR	2006	7	1					86	112		10.1093/bib/bbk007		27	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	090DL	WOS:000240930700007	
J	Mullan, L				Mullan, Lisa			Pairwise sequence alignment - it's all about us!	BRIEFINGS IN BIOINFORMATICS			English	Editorial Material						machine learning; bioinformatics; supervised classification; clustering; probabilistic graphical models; optimisation; heuristic; genomics; proteomics; microarray; system biology; evolution; text mining	LINEAR-SPACE; BLOCKS; DATABASE		EMBL European Bioinformat Inst, Cambridge CB10 1SD, England	Mullan, L (reprint author), EMBL European Bioinformat Inst, Wellcome Trust Genome Campus, Cambridge CB10 1SD, England.	lisa@ebi.ac.uk					Dayhoff MO, 1978, ATLAS PROTEIN SEQ S3, P345; DAYHOFF MO, 1978, ATLAS PROTEIN SEQ S3, V5, P353; Henikoff JG, 2000, NUCLEIC ACIDS RES, V28, P228, DOI 10.1093/nar/28.1.228; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Henikoff S, 1999, BIOINFORMATICS, V15, P471, DOI 10.1093/bioinformatics/15.6.471; HUANG XQ, 1991, ADV APPL MATH, V12, P337, DOI 10.1016/0196-8858(91)90017-D; MURATA M, 1985, P NATL ACAD SCI USA, V82, P3073, DOI 10.1073/pnas.82.10.3073; MYERS EW, 1988, COMPUT APPL BIOSCI, V4, P11; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; WATERMAN MS, 1976, ADV MATH, V20, P367, DOI 10.1016/0001-8708(76)90202-4; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4	11	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463		BRIEF BIOINFORM	Brief. Bioinform.	MAR	2006	7	1					113	115		10.1093/bib/bbk008		3	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	090DL	WOS:000240930700008	
J	Rubin, E				Rubin, Eitan			List mania: interpreting microarray results with the L2L server	BRIEFINGS IN BIOINFORMATICS			English	News Item						machine learning; bioinformatics; supervised classification; clustering; probabilistic graphical models; optimisation; heuristic; genomics; proteomics; microarray; system biology; evolution; text mining		A new server for interpreting microarray results, list to list (L2L), is described. This tool offers a unique approach to understand the meaning of microarray results, based on comparing them to previously identified lists of differentially expressed genes. The usefulness of the server is demonstrated by studying differential expression in primary tumours versus metastases in colon cancer.	Ben Gurion Univ Negev, Natl Inst Biotechnol, IL-84105 Beer Sheva, Israel	Rubin, E (reprint author), Ben Gurion Univ Negev, Natl Inst Biotechnol, IL-84105 Beer Sheva, Israel.		Rubin, Eitan/E-5256-2011					0	1	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463		BRIEF BIOINFORM	Brief. Bioinform.	MAR	2006	7	1					121	122		10.1093/bib/bbk010		2	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	090DL	WOS:000240930700009	
J	Butterfield, J				Butterfield, J			The rotating discs argument defeated	BRITISH JOURNAL FOR THE PHILOSOPHY OF SCIENCE			English	Article						machine learning; network routing; adaptive routing	INSTANTANEOUS VELOCITIES; HUMEAN SUPERVENIENCE; PHILOSOPHY; MATTER	The rotating discs argument (RDA) against perdurantism has been mostly discussed by metaphysicians, though the argument of course appeals to ideas from classical mechanics, especially about rotation. In contrast, I assess the RDA from the perspective of the philosophy of physics. I argue for three main conclusions. The first conclusion is that the RDA can be formulated more strongly than is usually recognized: it is not necessary to 'imagine away' the dynamical effects of rotation. The second is that in general relativity, the RDA fails because of frame-dragging. The third conclusion is that even setting aside general relativity, the strong formulation of the RDA can after all be defeated, namely, by the perdurantist taking objects in classical mechanics (whether point-particles or continuous bodies) to have only temporally extended (i.e. non-instantaneous) temporal parts, which immediately blocks the RDA. Admittedly, this version of perdurantism defines persistence in a weaker sense of 'definition' than pointilliste versions that aim to define persistence assuming only instantaneous temporal parts. But I argue that temporally extended temporal parts (i) can do the jobs within the endurantism-perdurantism debate that the perdurantist wants temporal parts to do and (ii) are supported by both classical and quantum mechanics.	Univ Oxford All Souls Coll, Oxford OX1 4AL, England	Butterfield, J (reprint author), Univ Oxford All Souls Coll, Oxford OX1 4AL, England.	jb56@cus.cam.ac.uk					Abraham R., 1978, FDN MECH; Armstrong DM, 1997, WORLD STATES AFFAIRS; Armstrong D.M, 1980, TIME CAUSE, P67; Arntzenius F, 2003, STUD HIST PHILOS M P, V34B, P281, DOI 10.1016/S1355-2198(03)00008-X; Arntzenius F, 2000, MONIST, V83, P187; Belot G, 1998, BRIT J PHILOS SCI, V49, P531; BIGELOW J, 1989, BRIT J PHILOS SCI, V40, P289, DOI 10.1093/bjps/40.3.289; Bigelow J., 1990, SCI NECESSITY; BUTTERFIELD J, PERSISTENCE HOMOGENO; Butterfield J, 2005, FOUND PHYS, V35, P233, DOI 10.1007/s10701-004-1943-4; BUTTERFIELD J, UNPUB CLASSICAL MECH; Callender C, 2001, MIND, V110, P25, DOI 10.1093/mind/110.437.25; Devlin K., 2002, MILLENNIUM PROBLEMS; Diacu F., 1996, CELESTIAL ENCOUNTERS; Dixon WG, 1978, SPECIAL RELATIVITY; Earman J, 1989, WORLD ENOUGH SPACE T; Grattan-Guinness I, 2002, HIST MATH, V29, P427, DOI 10.1006/hmat.2002.2356; GUILINI D, 2003, DECOHERENCE APPEARAN; HALLIWELL J, 1999, IN PRESS P 4 PEYR C; Hawley K, 2001, THINGS PERSIST; Humberstone IL, 1996, SYNTHESE, V108, P205, DOI 10.1007/BF00413498; Langton R, 1998, PHILOS PHENOMEN RES, V58, P333, DOI 10.2307/2653512; LEIBNIZ G, 1998, GW LEIBNIZ PHILOS PA, P498; Lewis D, 2001, PHILOS PHENOMEN RES, V63, P381, DOI 10.2307/3071071; Lewis D, 1999, AUSTRALAS J PHILOS, V77, P209, DOI 10.1080/00048409912348951; Lewis D., 1986, PHILOS PAPERS, V2; LEWIS D, 1994, MIND, V103, P473, DOI 10.1093/mind/103.412.473; LEWIS D, 1999, PAPERS METAPHYS EPIS; LEWIS D, 1983, PHILOS STUD, V44, P197, DOI 10.1007/BF00354100; Lewis D, 2002, MIND, V111, P1, DOI 10.1093/mind/111.441.1; LEWIS D, 1983, AUSTRALAS J PHILOS, V61, P343, DOI 10.1080/00048408312341131; MALAMENT D, 2003, REVISITING FDN RELAT, P175; MALAMENT D, 2002, READING NATURAL PHIL, P267; Misner C.W., 1973, GRAVITATION; ROBINSON D, 1989, AUSTRALAS J PHILOS, V67, P394, DOI 10.1080/00048408912343921; Schlosshauer M, 2004, REV MOD PHYS, V76, P1267, DOI 10.1103/RevModPhys.76.1267; Sider T., 2001, 4 DIMENSIONALISM; Smith SR, 2003, STUD HIST PHILOS M P, V34B, P261, DOI 10.1016/S1355-2198(03)00007-8; Tooley Michael, 1988, PHILOS TOPICS, V16, P225; Uehling T, 1979, MIDWEST STUD PHILOS, VVI, P321, DOI 10.1111/j.1475-4975.1979.tb00384.x; Wald R. M., 1984, GEN RELATIVITY; WALLACE D, 2004, IN PRESS SYNTHESE; Wallace D, 2003, STUD HIST PHILOS M P, V34B, P87, DOI 10.1016/S1355-2198(02)00085-0; Weatherson B., 2002, STANFORD ENCY PHILOS; Zalta E N, 2003, STANFORD ENCY PHILOS; Zimmerman DW, 1998, AUSTRALAS J PHILOS, V76, P265, DOI 10.1080/00048409812348401	46	3	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0007-0882		BRIT J PHILOS SCI	Br. J. Philos. Sci.	MAR	2006	57	1					1	45		10.1093/bjps/axi150		45	History & Philosophy Of Science	History & Philosophy of Science	018NZ	WOS:000235772600001	
J	Knobe, J; Olum, KD; Vilenkin, A				Knobe, J; Olum, KD; Vilenkin, A			Philosophical implications of inflationary cosmology	BRITISH JOURNAL FOR THE PHILOSOPHY OF SCIENCE			English	Article						machine learning; network routing; adaptive routing	QUANTUM MECHANICS; DOOMSDAY ARGUMENT; UNIVERSE; NUMBER	Recent developments in cosmology indicate that every history having a non-zero probability is realized in infinitely many distinct regions of spacetime. Thus, it appears that the universe contains infinitely many civilizations exactly like our own, as well as infinitely many civilizations that differ from our own in any way permitted by physical laws. We explore the implications of this conclusion for ethical theory and for the doomsday argument. In the infinite universe, we find that the doomsday argument applies only to effects which change the average lifetime of all civilizations, and not those which affect our civilization alone.	Princeton Univ, Dept Philosophy, Princeton, NJ 08544 USA; Tufts Univ, Dept Phys & Astron, Medford, MA 02155 USA	Knobe, J (reprint author), Princeton Univ, Dept Philosophy, Princeton, NJ 08544 USA.	jknobe@Princeton.edu; kdo@cosmos.phy.tufts.edu; vilenkin@cosmos.phy.tufts.edu					ADAMS RM, 1981, SYNTHESE, V49, P3; Bostrom N, 2003, PHILOS QUART, V53, P83, DOI 10.1111/1467-9213.00298; BROWN J, 1993, GHOST ATOM; Castaneda H.-N., 1966, RATIO, V8, P130; Danto Arthur, 1965, NIETZSCHE PHILOS; Dennett D.C., 1984, ELBOW ROOM VARIETIES; Deutsch D., 1998, FABRIC REALITY; DEWITT BS, 1970, PHYS TODAY, V23, P30; ELLIS GFR, 1979, Q J ROY ASTRON SOC, V20, P37; EVERETT H, 1957, REV MOD PHYS, V29, P454, DOI 10.1103/RevModPhys.29.454; Frankfurt H. G., 1999, NECESSITY VOLITION L; Garriga J, 2001, PHYS REV D, V64, DOI 10.1103/PhysRevD.64.043511; GELLMANN M, 1993, PHYS REV D, V47, P3345, DOI 10.1103/PhysRevD.47.3345; GOTT JR, 1993, NATURE, V363, P315, DOI 10.1038/363315a0; Guth AH, 2000, PHYS REP, V333, P555, DOI 10.1016/S0370-1573(00)00037-5; GUTH AH, 1981, PHYS REV D, V23, P347, DOI 10.1103/PhysRevD.23.347; LESLIE J, 1989, B CAN NUC SOC, V10, P10; Leslie J., 1996, END WORLD; LEWIS D, 1979, PHILOS REV, V88, P513, DOI 10.2307/2184843; Lewis D. K., 1986, PLURALITY WORLDS; LINDE AD, 1986, PHYS LETT B, V175, P395, DOI 10.1016/0370-2693(86)90611-8; MARTIN M, 2001, OTHER WORLDS MAY SUR; Nehamas A., 1985, NIETZSCHE LIFE LIT; NIELSEN HB, 1989, ACTA PHYS POL B, V20, P427; NIETZSCHE F, 1969, SPOKE ZARATHUSTRA; Nietzsche Friedrich, 1974, GAY SCI; Olum KD, 2004, ANALYSIS, V64, P1, DOI 10.1111/j.0003-2638.2004.00452.x; Olum KD, 2002, PHILOS QUART, V52, P164, DOI 10.1111/1467-9213.00260; SMOLIN L, 2001, ANTHR ARGUMENTS FUND; Vallentyne P, 1997, J PHILOS, V94, P5, DOI 10.2307/2941011; VILENKIN A, 1983, PHYS REV D, V27, P2848, DOI 10.1103/PhysRevD.27.2848	31	5	5	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0007-0882		BRIT J PHILOS SCI	Br. J. Philos. Sci.	MAR	2006	57	1					47	67		10.1093/bjps/axi155		21	History & Philosophy Of Science	History & Philosophy of Science	018NZ	WOS:000235772600002	
J	Lim, TP; Puthusserypady, S				Lim, TP; Puthusserypady, S			Error criteria for cross validation in the context of chaotic time series prediction	CHAOS			English	Article							STRANGE ATTRACTORS; NEURAL-NETWORKS	The prediction of a chaotic time series over a long horizon is commonly done by iterating one-step-ahead prediction. Prediction can be implemented using machine learning methods, such as radial basis function networks. Typically, cross validation is used to select prediction models based on mean squared error. The bias-variance dilemma dictates that there is an inevitable tradeoff between bias and variance. However, invariants of chaotic systems are unchanged by linear transformations; thus, the bias component may be irrelevant to model selection in the context of chaotic time series prediction. Hence, the use of error variance for model selection, instead of mean squared error, is examined. Clipping is introduced, as a simple way to stabilize iterated predictions. It is shown that using the error variance for model selection, in combination with clipping, may result in better models. (C) 2006 American Institute of Physics.	Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Lim, TP (reprint author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.						Abarbanel H.D.I., 1996, ANAL OBSERVED CHAOTI; ABARBANEL HDI, 1992, J NONLINEAR SCI, V2, P343, DOI 10.1007/BF01208929; CAO L, COMMUNICATION; Duda R., 2000, PATTERN CLASSIFICATI; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; FRASER AM, 1986, PHYS REV A, V33, P1134, DOI 10.1103/PhysRevA.33.1134; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GERSHENFELD NA, 1994, SFI S SCI C, V15, P1; GRASSBERGER P, 1983, PHYS REV LETT, V50, P346, DOI 10.1103/PhysRevLett.50.346; Haykin S., 1999, NEURAL NETWORKS COMP; Haykin S, 1998, IEEE SIGNAL PROC MAG, V15, P66, DOI 10.1109/79.671132; Haykin S, 1996, IEEE SIGNAL PROC MAG, V13, P24, DOI 10.1109/79.487040; HAYKIN S, 1998, C REC 32 AS C SIGN S, V1, P19, DOI 10.1109/ACSSC.1998.750821; Hegger R, 1999, PHYS REV E, V60, P4970, DOI 10.1103/PhysRevE.60.4970; Hegger R, 1999, CHAOS, V9, P413, DOI 10.1063/1.166424; HUBNER U, 1994, SFI S SCI C, V15, P73; Kantz H, 1997, PHYSICA D, V109, P59, DOI 10.1016/S0167-2789(97)00159-0; KUO JM, 1994, P IEEE INT C NEUR NE, V5, P3131; MERKWIRTH C, 1998, P INT WORKSH ADV BLA, P144; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; MOODY J, 1989, P 1988 CONN MOD SUMM, P133; Park J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.246; RUSSELL DA, 1980, PHYS REV LETT, V45, P1175, DOI 10.1103/PhysRevLett.45.1175; SARLE WS, 1997, NEURAL NEWORK FAQ 1; SAUER T, 1991, J STAT PHYS, V65, P579, DOI 10.1007/BF01053745; SCHOUTEN JC, 1994, PHYS REV E, V49, P126, DOI 10.1103/PhysRevE.49.126; Takens F, 1980, DYNAMICAL SYSTEMS TU, V898, P366	27	2	2	AMER INST PHYSICS	MELVILLE	CIRCULATION & FULFILLMENT DIV, 2 HUNTINGTON QUADRANGLE, STE 1 N O 1, MELVILLE, NY 11747-4501 USA	1054-1500		CHAOS	Chaos	MAR	2006	16	1							013106	10.1063/1.2130927		6	Mathematics, Applied; Physics, Mathematical	Mathematics; Physics	028CS	WOS:000236464500006	
J	Dudek, AZ; Arodz, T; Galvez, J				Dudek, AZ; Arodz, T; Galvez, J			Computational methods in developing quantitative structure-activity relationships (QSAR): A review	COMBINATORIAL CHEMISTRY & HIGH THROUGHPUT SCREENING			English	Review						QSAR; molecular descriptors; feature selection; machine learning	SUPPORT VECTOR MACHINES; ARTIFICIAL NEURAL-NETWORKS; PARTIAL LEAST-SQUARES; HUMAN INTESTINAL-ABSORPTION; BRAIN-BARRIER PERMEATION; MOLECULAR-FIELD ANALYSIS; PAIR-CORRELATION METHOD; FEATURE-SELECTION; DRUG DISCOVERY; BIOLOGICAL-ACTIVITY	Virtual filtering and screening of combinatorial libraries have recently gained attention as methods complementing the high-throughput screening and combinatorial chemistry. These chemoinformatic techniques rely heavily on quantitative structure-activity relationship (QSAR) analysis, a field with established methodology and successful history. In this review, we discuss the computational methods for building QSAR models. We start with outlining their usefulness in high-throughput screening and identifying the general scheme of a QSAR model. Following, we focus on the methodologies in constructing three main components of QSAR model, namely the methods for describing the molecular structure of compounds. for selection of informative descriptors and for activity prediction. We present both the well-established methods as well as techniques recently introduced into the QSAR domain.	Univ Minnesota, Sch Med, Div Hematol Oncol & Transplantat, Minneapolis, MN 55455 USA; AGH Univ Sci & Technol, Inst Comp Sci, PL-30059 Krakow, Poland; Univ Valencia, Unit Drug Design & Mol Connect Res, E-46100 Burjassot, Valencia, Spain	Dudek, AZ (reprint author), Univ Minnesota, Sch Med, Div Hematol Oncol & Transplantat, 420 Delaware St SE,MMC 480, Minneapolis, MN 55455 USA.	dudek002@umn.edu					Adenot M, 2004, J CHEM INF COMP SCI, V44, P239, DOI 10.1021/ci034205d; Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; Akamatsu Miki, 2002, Current Topics in Medicinal Chemistry, V2, P1381, DOI 10.2174/1568026023392887; Bai JPF, 2004, J CHEM INF COMP SCI, V44, P2061, DOI 10.1021/ci040023n; Bajorath Jürgen, 2002, Nat Rev Drug Discov, V1, P882, DOI 10.1038/nrd941; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Barnard JM, 1997, J CHEM INF COMP SCI, V37, P141, DOI 10.1021/ci960090k; Baurin N, 2004, J CHEM INF COMP SCI, V44, P276, DOI 10.1021/ci0341565; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; Bleicher KH, 2003, NAT REV DRUG DISCOV, V2, P369, DOI 10.1038/nrd1086; Boser B.E., 1992, COLT 92 P 5 ANN WORK; Bravi G, 1997, J COMPUT AID MOL DES, V11, P79, DOI 10.1023/A:1008079512289; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; BURDEN FR, 1989, J CHEM INF COMP SCI, V29, P225, DOI 10.1021/ci00063a011; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; CAMMARAT.A, 1967, J MED CHEM, V10, P525, DOI 10.1021/jm00316a004; Catana C, 2005, J CHEM INF MODEL, V45, P170, DOI 10.1021/ci049797u; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Chin TL, 2004, J CHEM INF COMP SCI, V44, P154, DOI 10.1021/ci030294i; Cho SJ, 1996, J MED CHEM, V39, P1383, DOI 10.1021/jm9503052; Clark M, 2005, J CHEM INF MODEL, V45, P30, DOI 10.1021/ci049744c; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER T, IEEE T INFORM THEORY, V67, P21; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; Crivori P, 2000, J MED CHEM, V43, P2204, DOI 10.1021/jm990968+; Cruciani G., 2000, THEOCHEM, V503, DOI 10.1016/S0166-1280(99)00360-7; Daszykowski M, 2004, J CHEM INF COMP SCI, V44, P716, DOI 10.1021/ci034170h; de Julian-Ortiz JV, 1998, J MOL GRAPH MODEL, V16, P14, DOI 10.1016/S1093-3263(98)00013-8; DeLisle RK, 2004, J CHEM INF COMP SCI, V44, P862, DOI 10.1021/ci034188s; Deshpande M, 2005, IEEE T KNOWL DATA EN, V17, P1036, DOI 10.1109/TKDE.2005.127; Dove S, 1999, QUANT STRUCT-ACT REL, V18, P329, DOI 10.1002/(SICI)1521-3838(199910)18:4<329::AID-QSAR329>3.0.CO;2-V; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Estrada E, 2001, J CHEM INF COMP SCI, V41, P1015, DOI 10.1021/ci000170v; Estrada E, 1996, J CHEM INF COMP SCI, V36, P844, DOI 10.1021/ci950187r; Estrada E, 2001, SAR QSAR ENVIRON RES, V12, P309, DOI 10.1080/10629360108032919; Farkas O, 2005, J CHEM INF MODEL, V45, P339, DOI 10.1021/ci049827t; Feng J, 2003, J CHEM INF COMP SCI, V43, P1463, DOI 10.1021/ci034032s; Fisher RA, 1936, ANN EUGENIC, V7, P179; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Gallant S I, 1990, IEEE Trans Neural Netw, V1, P179, DOI 10.1109/72.80230; GALLEGOS A, 2004, J CHEM INF COMP SCI, V44, P321; GALVEZ J, 1991, Anales de la Real Academia de Farmacia, V57, P533; GALVEZ J, 1994, J CHEM INF COMP SCI, V34, P520, DOI 10.1021/ci00019a008; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; Gershell LJ, 2003, NAT REV DRUG DISCOV, V2, P321, DOI 10.1038/nrd1064; Gini G, 2004, J CHEM INF COMP SCI, V44, P1897, DOI 10.1021/ci0401219; Goodnow RA, 2003, COMB CHEM HIGH T SCR, V6, P649; Guha R, 2005, J CHEM INF MODEL, V45, P800, DOI 10.1021/ci050022a; Guha R, 2005, J CHEM INF MODEL, V45, P65, DOI 10.1021/ci0497511; Guha R, 2004, J CHEM INF COMP SCI, V44, P2179, DOI 10.1021/ci049849f; Guner Osman F., 2002, Current Topics in Medicinal Chemistry, V2, P1321, DOI 10.2174/1568026023392940; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall LH, 2000, J CHEM INF COMP SCI, V40, P784, DOI 10.1021/ci990140w; HALL LH, 1991, QUANT STRUCT-ACT REL, V10, P43, DOI 10.1002/qsar.19910100108; HANSCH C, 1964, J AM CHEM SOC, V86, P1616, DOI 10.1021/ja01062a035; Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472; Heberger K, 2002, J CHEMOMETR, V16, P436, DOI 10.1002/cem.748; Helma C, 2004, J CHEM INF COMP SCI, V44, P1402, DOI 10.1021/ci034254q; Hemmateenejad B, 2005, J CHEM INF MODEL, V45, P190, DOI 10.1021/ci049766z; HIGO J, 1989, J COMPUT CHEM, V10, P376, DOI 10.1002/jcc.540100311; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hodgson J, 2001, NAT BIOTECHNOL, V19, P722, DOI 10.1038/90761; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hou TJ, 2004, J CHEM INF COMP SCI, V44, P1585, DOI 10.1021/ci049884m; Hou TJ, 2004, J CHEM INF COMP SCI, V44, P266, DOI 10.1021/ci034184n; Itskowitz P, 2005, J CHEM INF MODEL, V45, P777, DOI 10.1021/ci049628+; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Katritzky AR, 1996, J PHYS CHEM-US, V100, P10400, DOI 10.1021/jp953224q; KIER LB, 1981, J PHARM SCI, V70, P583, DOI 10.1002/jps.2600700602; KIER LB, 1993, QUANT STRUCT-ACT REL, V12, P383, DOI 10.1002/qsar.19930120406; KIRKPATRICK S, 1987, READINGS COMPUTER VI; KITTLER J, 1978, PATTERN RECOGNITIO E, V29, P41; KLEBE G, 1994, J MED CHEM, V37, P4130, DOI 10.1021/jm00050a010; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; KLOPMAN G, 1968, J AM CHEM SOC, V90, P223, DOI 10.1021/ja01004a002; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kvasnicka V, 1996, J CHEM INF COMP SCI, V36, P516, DOI 10.1021/ci9500703; Labute P, 2000, J MOL GRAPH MODEL, V18, P464, DOI 10.1016/S1093-3263(00)00068-1; Lemmen C, 2000, J COMPUT AID MOL DES, V14, P215, DOI 10.1023/A:1008194019144; Lewis RA, 2005, J MED CHEM, V48, P1638, DOI 10.1021/jm049228d; Lin TH, 2004, J CHEM INF COMP SCI, V44, P76, DOI 10.1021/ci030295a; Liu HX, 2004, J CHEM INF COMP SCI, V44, P1979, DOI 10.1021/ci049891a; Liu Y, 2004, J CHEM INF COMP SCI, V44, P1823, DOI 10.1021/ci049875d; MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095; Maurer W.D., 1975, ACM COMPUT SURV, V7, P5, DOI 10.1145/356643.356645; Mazzatorta P, 2004, J CHEM INF COMP SCI, V44, P105, DOI 10.1021/ci034193w; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; Molina E, 2004, J CHEM INF COMP SCI, V44, P515, DOI 10.1021/ci0342019; MUELLER KR, 2005, J CHEM INF MODEL, V45, P249; Mulgrew B, 1996, IEEE SIGNAL PROC MAG, V13, P50, DOI 10.1109/79.487041; MULLIKEN RS, 1955, J CHEM PHYS, V23, P1833, DOI 10.1063/1.1740588; Murcia-Soler M, 2004, J CHEM INF COMP SCI, V44, P1031, DOI 10.1021/ci030340e; Pastor M, 2000, J MED CHEM, V43, P3233, DOI 10.1021/jm000941m; PEARLMAN RS, 1988, PHYS CHEM PROPERTIES; Pearlman RS, 1998, PERSPECT DRUG DISCOV, V9-11, P339, DOI 10.1023/A:1027232610247; Phatak A, 1997, J CHEMOMETR, V11, P311, DOI 10.1002/(SICI)1099-128X(199707)11:4<311::AID-CEM478>3.0.CO;2-4; Pirard B, 2004, COMB CHEM HIGH T SCR, V7, P271; Proudfoot Jr, 2002, BIOORG MED CHEM LETT, V12, P1647, DOI 10.1016/S0960-894X(02)00244-5; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rajko R, 2001, CHEMOMETR INTELL LAB, V57, P1, DOI 10.1016/S0169-7439(01)00101-0; RANDIC M, 1975, J AM CHEM SOC, V97, P6609, DOI 10.1021/ja00856a001; Roche O, 2002, J MED CHEM, V45, P137, DOI 10.1021/jm010934d; ROHRBAUGH RH, 1987, ANAL CHIM ACTA, V199, P99, DOI 10.1016/S0003-2670(00)82801-9; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Roy K, 2004, J CHEM INF COMP SCI, V44, P559, DOI 10.1021/ci0342066; Rusinko A, 2002, COMB CHEM HIGH T SCR, V5, P125; Schapire RE, 1998, ANN STAT, V26, P1651; SCHULTZ HP, 1989, J CHEM INF COMP SCI, V29, P227, DOI 10.1021/ci00063a012; Senese CL, 2004, J CHEM INF COMP SCI, V44, P1526, DOI 10.1021/ci049898s; Shoichet BK, 2004, NATURE, V432, P862, DOI 10.1038/nature03197; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; Silverman BD, 1996, J MED CHEM, V39, P2129, DOI 10.1021/jm950589q; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Stahura FL, 2004, COMB CHEM HIGH T SCR, V7, P259; STANTON DT, 1992, J CHEM INF COMP SCI, V32, P306, DOI 10.1021/ci00008a009; Stanton DT, 1999, J CHEM INF COMP SCI, V39, P11, DOI 10.1021/ci980102x; Sun HM, 2004, J CHEM INF COMP SCI, V44, P748, DOI 10.1021/ci030304f; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tino P, 2004, J CHEM INF COMP SCI, V44, P1647, DOI 10.1021/ci034255i; TODESCHINI R, 1994, J CHEMOMETR, V8, P263, DOI 10.1002/cem.1180080405; Todeschini R, 1998, PERSPECT DRUG DISCOV, V9-11, P355, DOI 10.1023/A:1027284627085; Trohalaki S, 2004, J CHEM INF COMP SCI, V44, P1186, DOI 10.1021/ci0342627; CHO SJ, 1995, J MED CHEM, V38, P1060, DOI 10.1021/jm00007a003; van de Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192, DOI 10.1038/nrd1032; Venkatraman V, 2004, J CHEM INF COMP SCI, V44, P1686, DOI 10.1021/ci049933v; Verdu-Andres J, 1998, APPL SPECTROSC, V52, P1425, DOI 10.1366/0003702981942843; VPNIK V, 1995, NATURE STAT LEARNING; Waller CL, 1999, J CHEM INF COMP SCI, V39, P345, DOI 10.1021/ci980405r; Waller CL, 2004, J CHEM INF COMP SCI, V44, P758, DOI 10.1021/ci0342526; Wegner JK, 2004, J CHEM INF COMP SCI, V44, P931, DOI 10.1021/ci034233w; Wegner JK, 2004, J CHEM INF COMP SCI, V44, P921, DOI 10.1021/ci0342324; Weiser J, 1998, J COMPUT CHEM, V19, P797, DOI 10.1002/(SICI)1096-987X(199805)19:7<797::AID-JCC9>3.0.CO;2-L; Wessel MD, 1998, J CHEM INF COMP SCI, V38, P726, DOI 10.1021/ci980029a; WIENER H, 1947, J AM CHEM SOC, V69, P17, DOI 10.1021/ja01193a005; Winkler DA, 1998, QUANT STRUCT-ACT REL, V17, P224, DOI 10.1002/(SICI)1521-3838(199806)17:03<224::AID-QSAR224>3.3.CO;2-Y; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1; WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052; Xue CX, 2004, J CHEM INF COMP SCI, V44, P669, DOI 10.1021/ci034248u; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1267, DOI 10.1021/ci049934n; Xue CX, 2004, J CHEM INF COMP SCI, V44, P950, DOI 10.1021/ci034280o; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1693, DOI 10.1021/ci049820b; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1630, DOI 10.1021/ci049869h; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Yao XJ, 2004, J CHEM INF COMP SCI, V44, P1257, DOI 10.1021/ci049965i; Zhang HB, 2005, J CHEM INF MODEL, V45, P440, DOI 10.1021/ci0498113; ZHOU ZX, 1990, J AM CHEM SOC, V112, P5720, DOI 10.1021/ja00171a007	158	95	98	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1386-2073		COMB CHEM HIGH T SCR	Comb. Chem. High Throughput Screen	MAR	2006	9	3					213	228		10.2174/138620706776055539		16	Biochemical Research Methods; Chemistry, Applied; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	018KP	WOS:000235763400009	
J	Gyorgy, A; Ottucsak, G				Gyorgy, A; Ottucsak, G			Adaptive routing using expert advice	COMPUTER JOURNAL			English	Article						machine learning; network routing; adaptive routing	PREDICTION; ALGORITHMS; TRACKING	Machine learning algorithms for combining expert advice in sequential decision problems are considered. The goal of these algorithms is to perform, for any behavior of the system, asymptotically as well as the best expert. We provide a survey of these algorithms and show how they can be used for adaptive routing in different packet switched networks.	Tech Univ Budapest, Dept Comp Sci & Informat Theory, H-1117 Budapest, Hungary; Hungarian Acad Sci, Comp & Automat Res Inst, Informat Lab, H-1111 Budapest, Hungary	Ottucsak, G (reprint author), Tech Univ Budapest, Dept Comp Sci & Informat Theory, Magyar Tudosok Korutja 2, H-1117 Budapest, Hungary.	oti@szit.bme.hu					Auer P., 1995, Proceedings. 36th Annual Symposium on Foundations of Computer Science (Cat. No.95CB35834), DOI 10.1109/SFCS.1995.492488; Auer P, 2002, J COMPUT SYST SCI, V64, P48, DOI 10.1006/jcss.2001.1795; Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352; Auer P, 1998, MACH LEARN, V32, P127, DOI 10.1023/A:1007472513967; AWERBUCH B, 2005, 31 IEEE INFOCOM 2005; Awerbuch B., 2004, P 36 ANN ACM S THEOR, P45, DOI 10.1145/1007352.1007367; Blackwell D, 1956, PAC J MATH, V6, P1; Bousquet O., 2003, J MACHINE LEARNING R, V3, P363; CESABIANCHI N, 2006, IN PRESS PREDICTION; CesaBianchi N, 1997, J ACM, V44, P427, DOI 10.1145/258128.258179; Cesa-Bianchi N, 2005, IEEE T INFORM THEORY, V51, P2152, DOI 10.1109/TIT.2005.847729; Gelenbe E., 2004, Proceedings of the First International Conference on Autonomic Computing; Gelenbe E, 2001, COMPUT NETW, V37, P691, DOI 10.1016/S1389-1286(01)00253-5; Gelenbe E., 2004, COMPUT MANAGE SCI, V1, P1; GYORGY A, 2005, P 18 ANN C LEARN THE, P204; GYORGY A, UNPUB SHORTTEST PATH; Gyorgy A, 2004, IEEE T SIGNAL PROCES, V52, P2337, DOI 10.1109/TSP.2004.831128; HANNAN J., 1957, CONTRIBUTIONS THEORY, P97; Helmbold DP, 1997, MACH LEARN, V27, P51, DOI 10.1023/A:1007396710653; Herbster M, 1998, MACH LEARN, V32, P151, DOI 10.1023/A:1007424614876; Kalai A., 2003, P 16 ANN C LEARN THE, P26; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; McMahan H. B., 2004, P 17 ANN C LEARN THE, P109; MOHRI M, 1998, 98121910TM ATT; OTTUCSAK G, 2005, COMBINATION LABEL EF; ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8; Steenstrup M., 1995, ROUTING COMMUNICATIO; Takimoto E., 2003, J MACHINE LEARNING R, V4, P773; TAKIMOTO E, 2002, LECT NOTES ARTIF INT, V2375, P74; Vovk V, 1999, MACH LEARN, V35, P247, DOI 10.1023/A:1007595032382; Vovk V, 1998, J COMPUT SYST SCI, V56, P153, DOI 10.1006/jcss.1997.1556; Vovk V.G., 1990, P 3 ANN WORKSH COMP, P372	32	4	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0010-4620		COMPUT J	Comput. J.	MAR	2006	49	2					180	189		10.1093/comjnl/bxh168		10	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	018NP	WOS:000235771500005	
J	Balakin, KV; Savchuk, NP				Balakin, Konstantin V.; Savchuk, Nikolay P.			Computational Methods for Analysis of High-Throughput Screening Data	CURRENT COMPUTER-AIDED DRUG DESIGN			English	Article						High-throughput screening; data mining; quality control; machine learning; visualization; chemogenomics	SUPPORT VECTOR MACHINES; SELF-ORGANIZING MAP; TRUNCATED-NEWTON MINIMIZATION; BIOLOGICALLY-ACTIVE COMPOUNDS; SHANNON ENTROPY ANALYSIS; BINARY QSAR CALCULATIONS; PHYLOGENETIC-LIKE TREES; PARTITIONING PUMP-RP; DRUG DISCOVERY; DATA SET	The huge data sets produced by high-throughput screening (HTS) technologies have created a tremendous challenge for the drug discovery industry. Rapid processing of HTS data and identification of hits are essential in order to accelerate the discovery of quality lead compounds. In addition to finding active compounds among those screened, it is useful to identify the molecular features associated with the activity. To do this, one needs to analyze the initial HTS data to find quantitative relationships between biological activity and specific compound features. There are several challenges in the development of biological activity models from HTS data. First, the hit compounds belonging to different chemotypes may be acting via different mechanisms. Second, many HTS data sets have substantial measurement errors. Third, despite of large exploratory sets which may include thousands of compounds, HTS programs usually provide relatively few active compounds. Powerful and flexible data management systems are key to addressing these challenges. In this review, we elucidate the modern approaches to processing HTS data and developing biological activity models. In our opinion, such systems provide a functional interface between real and virtual screening programs. The synergy of these powerful technologies will increase the efficiency with which high quality clinical candidates are produced, thus providing a great benefit to the industry.	[Balakin, Konstantin V.; Savchuk, Nikolay P.] ChemDiv Inc, San Diego, CA 92121 USA	Balakin, KV (reprint author), ChemDiv Inc, 11558 Sorrento Valley Rd,Ste 5, San Diego, CA 92121 USA.	kvb@chemdiv.com					Abt M, 2001, STAT SCI, V16, P154; Agrafiotis DK, 2000, J CHEM INF COMP SCI, V40, P1356, DOI 10.1021/ci000033y; AGRAFIOTIS DK, 1999, MOL DIVERS, V4, P1; Agrafiotis DK, 1997, PROTEIN SCI, V6, P287; Ahlberg C, 1999, DRUG DISCOV TODAY, V4, P370, DOI 10.1016/S1359-6446(99)01373-2; Ajay, 1999, J MED CHEM, V42, P4942, DOI 10.1021/jm990017w; Ajay A, 1998, J Med Chem, V41, P3314; Bacha PA, 2002, J CHEM INF COMP SCI, V42, P1104, DOI 10.1021/ci020366q; Bezerianos A, 2000, MED BIOL ENG COMPUT, V38, P406, DOI 10.1007/BF02345010; Blower P, 2002, J CHEM INF COMP SCI, V42, P393, DOI 10.1021/ci0101049; Blower P. E., 2002, Pharmacogenomics Journal, V2, P259, DOI 10.1038/sj.tpj.6500116; Bocker A, 2004, QSAR COMB SCI, V23, P207, DOI 10.1002/qsar.200330860; BOYD MR, 1995, DRUG DEVELOP RES, V34, P91, DOI 10.1002/ddr.430340203; Breiman L, 1984, CLASSIFICATION REGRE; Brideau C, 2003, J BIOMOL SCREEN, V8, P634, DOI 10.1177/1087057103258285; Brown RD, 1996, J CHEM INF COMP SCI, V36, P572, DOI 10.1021/ci9501047; Brustle M, 2002, J MED CHEM, V45, P3345, DOI 10.1021/jm011027b; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; BURDEN FR, 1989, J CHEM INF COMP SCI, V29, P225, DOI 10.1021/ci00063a011; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Chen X, 1998, J CHEM INF COMP SCI, V38, P1054, DOI 10.1021/ci980089g; Chen X, 1999, J CHEM INF COMP SCI, V39, P887, DOI 10.1021/ci990327n; Cho SJ, 2000, J CHEM INF COMP SCI, V40, P668, DOI 10.1021/ci9908190; Clark RD, 2000, J MOL GRAPH MODEL, V18, P404, DOI 10.1016/S1093-3263(00)00065-6; Cross KP, 2003, J MED CHEM, V46, P4770, DOI 10.1021/jm0302703; DASARATHY BV, 1990, CHEM ABST, V25, P27; DOMINE D, 1994, J MED CHEM, V37, P981, DOI 10.1021/jm00033a016; DOMINIK A, 2000, COMBINATORIAL CHEM P, P292; DOWNS GM, 1994, ADV COMPUTER ASSISTE, P111; Ekins S, 2003, DRUG METAB DISPOS, V31, P1077, DOI 10.1124/dmd.31.9.1077; Emerson J.D., 1983, UNDERSTANDING ROBUST; Engels M F, 2001, Curr Opin Drug Discov Devel, V4, P275; Ertl P, 2000, J MED CHEM, V43, P3714, DOI 10.1021/jm000942e; Estrada E, 2001, J CHEM INF COMP SCI, V41, P1015, DOI 10.1021/ci000170v; Everitt B. S., 1993, CLUSTER ANAL; Fan Y, 2001, J MED CHEM, V44, P3254, DOI 10.1021/jm0005151; FISANICK W, 1993, J CHEM INF COMP SCI, V33, P548, DOI 10.1021/ci00014a005; Fukunaga K., 1990, INTRO STAT PATTERN R; Gao H, 1999, J CHEM INF COMP SCI, V39, P164, DOI 10.1021/ci980140g; Gao H, 2002, J MOL GRAPH MODEL, V20, P259, DOI 10.1016/S1093-3263(01)00122-X; Gao H, 2001, J CHEM INF COMP SCI, V41, P402, DOI 10.1021/ci000306p; Garrido L, 1999, NEURAL COMPUT, V11, P595, DOI 10.1162/089976699300016584; Gedeck P, 2001, CURR OPIN CHEM BIOL, V5, P389, DOI 10.1016/S1367-5931(00)00219-2; GILL PE, 1978, SIAM J NUMER ANAL, V15, P977, DOI 10.1137/0715063; Godden JW, 2002, J CHEM INF COMP SCI, V42, P885, DOI 10.1021/ci0203693; Godden JW, 2002, J CHEM INF COMP SCI, V42, P1263, DOI 10.1021/ci020372m; Golbraikh A, 2001, J CHEM INF COMP SCI, V41, P147, DOI 10.1021/ci000082a; Golub G. H., 1996, MATRIX COMPUTATIONS; GOOD AC, 1995, J COMPUT AID MOL DES, V9, P373, DOI 10.1007/BF00125178; GOOD AC, 1995, J COMPUT AID MOL DES, V9, P1, DOI 10.1007/BF00117274; Guha R, 2004, J MOL GRAPH MODEL, V23, P1, DOI 10.1016/j.jmgm.2004.03.003; Gunter B, 2003, J BIOMOL SCREEN, V8, P624, DOI 10.1177/1087057103258284; HANCH C, 1973, J MED CHEM, V16, P1217; Hand DJ, 2000, STAT SCI, V15, P111; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; Hawkins D., 1982, TOPICS APPL MULTIVAR, P269; HAWKINS DM, 1995, FIRM FORMAL INFERENC; Hawkins DM, 1997, QUANT STRUCT-ACT REL, V16, P296, DOI 10.1002/qsar.19970160404; HEYSE S, 2002, SBS 8 ANN C EXH SEPT; Jacoby E, 2003, DRUG NEWS PERSPECT, V16, P93, DOI 10.1358/dnp.2003.16.2.829326; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; Jones-Hertzog DK, 1999, J PHARMACOL TOXICOL, V42, P207, DOI 10.1016/S1056-8719(00)00073-3; Kier L.B., 1986, MOL CONNECTIVITY STR; Kier L.B., 1999, MOL STRUCTURE DESCRI; KLOPMAN G, 1992, QUANT STRUCT-ACT REL, V11, P176, DOI 10.1002/qsar.19920110208; Kohonen T., 2000, SELF ORG MAPS; Konig A, 2000, IEEE T NEURAL NETWOR, V11, P615, DOI 10.1109/72.846733; Korolev D, 2003, J MED CHEM, V46, P3631, DOI 10.1021/jm030102a; Sadowski J, 1998, J MED CHEM, V41, P3325, DOI 10.1021/jm9706776; KUBINYI J, 1993, METHODS PRINCIPLES M, V1, P21; Labute P, 2002, COMB CHEM HIGH T SCR, V5, P135; LABUTE P, 1999, PAC S BIOCOMPUT, V7, P444; LADD B, 2004, MOD DRUG DISC, V5, P43; Lam RLH, 2002, TECHNOMETRICS, V44, P99, DOI 10.1198/004017002317375055; LAM RLH, 2002, RR0202 U WAT I IMPR; Lam Raymond L H, 2004, Methods Mol Biol, V275, P301; Livingstone DJ, 2000, J CHEM INF COMP SCI, V40, P195, DOI 10.1021/ci990162i; Lukovits I, 2001, J CHEM INF COMP SCI, V41, P1517, DOI 10.1021/ci0100346; Mason JS, 1997, PERSPECT DRUG DISCOV, V7-8, P85; Matter H, 1997, J MED CHEM, V40, P1219, DOI 10.1021/jm960352+; Maw HH, 2001, J CHEM INF COMP SCI, V41, P1248, DOI 10.1021/ci010037i; Meyer RD, 2000, CURR OPIN BIOTECH, V11, P89, DOI 10.1016/S0958-1669(99)00060-9; Miller DW, 2001, J CHEM INF COMP SCI, V41, P168, DOI 10.1021/ci0000348; Monks A, 1997, ANTI-CANCER DRUG DES, V12, P533; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; MYERS PL, 1997, TODAYS CHEM WORK, V6, P45; Nicolaou CA, 2002, J CHEM INF COMP SCI, V42, P1069, DOI 10.1021/ci010244i; NILAKANTAN R, 1987, J CHEM INF COMP SCI, V27, P82, DOI 10.1021/ci00054a008; Nilakantan R, 1997, J COMPUT AID MOL DES, V11, P447, DOI 10.1023/A:1007937308615; PAL NR, 1998, IEEE T NEURAL NETWOR, V9, P1; PAL NR, 2000, FEATURE ANAL CLUSTER, V3, P1; Parker Christian N, 2004, Methods Mol Biol, V275, P85; PAUL EB, 2004, CURR DRUG DISC TECN, V1, P37; Pearlman RS, 1999, J CHEM INF COMP SCI, V39, P28, DOI 10.1021/ci980137x; Polanski J, 2000, COMB CHEM HIGH T SCR, V3, P481; Proudfoot Jr, 2002, BIOORG MED CHEM LETT, V12, P1647, DOI 10.1016/S0960-894X(02)00244-5; Quinlan J., 1992, C4 5 PROGRAMS MACHIN; Rabow AA, 2002, J MED CHEM, V45, P818, DOI 10.1021/jm010385b; Rao SN, 2003, J CHEM INF COMP SCI, V43, P1614, DOI 10.1021/ci0203803; Richon A, 2000, J MOL GRAPH MODEL, V18, P76; Roberts G, 2000, J CHEM INF COMP SCI, V40, P1302, DOI 10.1021/ci0000631; Root DE, 2003, CHEM BIOL, V10, P881, DOI 10.1016/j.chembiol.2003.08.009; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Rusinko A, 2002, COMB CHEM HIGH T SCR, V5, P125; SADOWSKI J, 1996, ANGEW CHEM INT EDIT, V34, P23; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Savchuk NP, 2004, CURR OPIN CHEM BIOL, V8, P412, DOI 10.1016/j.cbpa.2004.06.003; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; SCHLICK T, 1992, ACM T MATH SOFTWARE, V18, P46, DOI 10.1145/128745.150973; Schneider G, 2003, J COMB CHEM, V5, P233, DOI 10.1021/cc020092j; Schuffenhauer A, 2002, J CHEM INF COMP SCI, V42, P947, DOI 10.1021/co010385k; Schuffenhauer A, 2003, J CHEM INF COMP SCI, V43, P391, DOI 10.1021/ci025569t; Shi LM, 2000, J CHEM INF COMP SCI, V40, P367, DOI 10.1021/ci990087b; Shi LM, 1998, MOL PHARMACOL, V53, P241; Shoemaker Robert H., 2002, Current Topics in Medicinal Chemistry, V2, P229, DOI 10.2174/1568026023394317; Singh J, 1996, J AM CHEM SOC, V118, P1669, DOI 10.1021/ja953172i; Stahura FL, 2004, COMB CHEM HIGH T SCR, V7, P259; Stahura FL, 2000, J CHEM INF COMP SCI, V40, P1245, DOI 10.1021/ci0003303; Stahura FL, 2002, J CHEM INF COMP SCI, V42, P550, DOI 10.1021/ci010243q; Stanton DT, 1999, J CHEM INF COMP SCI, V39, P21, DOI 10.1021/ci9801015; Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Stockfisch TP, 2003, J CHEM INF COMP SCI, V43, P1608, DOI 10.1021/ci0203794; Tamura SY, 2002, J MED CHEM, V45, P3082, DOI 10.1021/jm010535i; Teckentrup A, 2004, J CHEM INF COMP SCI, V44, P626, DOI 10.1021/ci034223v; Todeschini R., 2000, HDB MOL DESCRIPTORS; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; Tropsha A, 2002, COMB CHEM HIGH T SCR, V5, P111; Trotter MWB, 2001, MEAS CONTROL-UK, V34, P235; VANOSDOL WW, 1994, J NATL CANCER I, V86, P1853, DOI 10.1093/jnci/86.24.1853; van Rhee AM, 2003, J CHEM INF COMP SCI, V43, P941, DOI 10.1021/ci034023j; van Rhee AM, 2001, J COMB CHEM, V3, P267, DOI 10.1021/cc0000747; Vapnik VN, 1998, STAT LEARNING THEORY; Wallqvist A, 2002, MOL CANCER THER, V1, P311; WANG Y, 2002, RR0201 U WAT I IMPR; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; WEBER L, 1995, ANGEW CHEM INT EDIT, V34, P2280, DOI 10.1002/anie.199522801; Weinstein JN, 1997, SCIENCE, V275, P343, DOI 10.1126/science.275.5298.343; WILLETT P, 1986, J CHEM INF COMP SCI, V26, P109, DOI 10.1021/ci00051a005; Winkler DA, 2004, MOL BIOTECHNOL, V27, P139, DOI 10.1385/MB:27:2:139; Xie DX, 2000, J CHEM INF COMP SCI, V40, P167, DOI 10.1021/ci990333j; Xue L, 2000, J CHEM INF COMP SCI, V40, P1227, DOI 10.1021/ci000327j; Xue L, 2001, J CHEM INF COMP SCI, V41, P394, DOI 10.1021/ci000305x; Xue Ling, 2004, Methods Mol Biol, V275, P279; YOUNG SS, 1995, J MED CHEM, V38, P2784, DOI 10.1021/jm00014a030; YOUNG SS, 2002, CURR DRUG DISC, V12, P17; Young SS, 1998, SAR QSAR ENVIRON RES, V8, P183, DOI 10.1080/10629369808039140; Zernov VV, 2003, J CHEM INF COMP SCI, V43, P2048, DOI 10.1021/ci0340916; Zhang JH, 1999, J BIOMOL SCREEN, V4, P67, DOI 10.1177/108705719900400206; *BIOREASON INC, CLASSPHARMER SOFTW P; *CAMBRIDGESOFT COR, BIOASSAY HTS; *CHEM COMP GROUP I, QUASAR BIN; *DIS PARTN INT, MOL LIB EXPL MLE SUI; *GENEDATA AG, SCREEN SOFTW PACK; *GOLDENHELIX INC, CHEMTREE HTS AN SOFT; *LEADSCOPE INC, LEADSCOPE SUIT; *PART INC, PATT VIS SYST; *SPOTF INC, DECISIONSITE	157	2	2	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4099		CURR COMPUT-AID DRUG	Curr. Comput.-Aided Drug Des.	MAR	2006	2	1					1	19		10.2174/157340906776056428		19	Chemistry, Medicinal; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Computer Science	V17TG	WOS:000207958900001	
J	Billari, FC; Furnkranz, J; Prskawetz, A				Billari, FC; Furnkranz, J; Prskawetz, A			Timing, sequencing, and quantum of life course events: A machine learning approach	EUROPEAN JOURNAL OF POPULATION-REVUE EUROPEENNE DE DEMOGRAPHIE			English	Article						data mining; event history; life course; machine learning; transition to adulthood	KNOWLEDGE; MARRIAGE; TREES	In this paper we discuss and apply machine learning techniques, using ideas from a core research area in the artificial intelligence literature to analyse simultaneously timing, sequencing, and quantum of life course events from a comparative perspective. We outline the need for techniques which allow the adoption of a holistic approach to life course analysis, illustrating the specific case of the transition to adulthood. We briefly introduce machine learning algorithms to build decision trees and rule sets and then apply such algorithms to delineate the key features which distinguish Austrian and Italian pathways to adulthood, using Fertility and Family Survey data. The key role of sequencing and synchronization between events emerges clearly from the analysis.	Univ Bocconi, Inst Quantitat Methods, I-20135 Milan, Italy; IGIER, I-20135 Milan, Italy; Tech Univ Darmstadt, Knowledge Engn Grp, Dept Comp Sci, D-64289 Darmstadt, Germany; Vienna Inst Demog, A-1040 Vienna, Austria	Billari, FC (reprint author), Univ Bocconi, Inst Quantitat Methods, Viale Isonzo 25, I-20135 Milan, Italy.	francesco.billari@unibocconi.it					Billari F. C., 2005, MATH POPUL STUD, V12, P81, DOI 10.1080/08898480590932287; BILLARI FC, 2000, ANAL BIOGRAFIE TRANS; BILLARI FC, 2002, FERTILITY PARTNERSHI, V2, P17; BILLARI FC, 2003, ENCY POPULATION, V2, P588; BILLARI FC, 2001, INT J POPULATION GEO, V7, P311; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Corijn M., 2001, TRANSITIONS ADULTHOO; CORIJN M, 1999, CBGS WERKDOCUMENT, V4; Courgeau D., 1992, EVENT HIST ANAL DEMO; De Rose A, 1997, EUR J POPUL, V13, P223; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; DOURLEIJN E, 2002, FERTILITY PARTNERSHI, V2, P157; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; Fayyad U.M., 1995, ADV KNOWLEDGE DISCOV; Friedman JH, 1999, STAT COMPUT, V9, P123, DOI 10.1023/A:1008894516817; Furnkranz J, 1997, MACH LEARN, V27, P139, DOI 10.1023/A:1007329424533; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Hastie T, 2001, ELEMENTS STAT LEARNI; HOGAN DP, 1978, AM SOCIOL REV, V43, P573, DOI 10.2307/2094780; Kass G. V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Kiernan K., 1999, POPULATION TRENDS, V98, P11; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; LAVRAC N, 1993, APPL ARTIF INTELL, V7, P273, DOI 10.1080/08839519308949989; LILLARD LA, 1993, J ECONOMETRICS, V56, P189, DOI 10.1016/0304-4076(93)90106-F; MARINI MM, 1987, SOC SCI RES, V16, P1, DOI 10.1016/0049-089X(87)90017-2; Michalski R. S., 1998, MACHINE LEARNING DAT; Mitchell T, 1997, MACHINE LEARNING; MODELL J, 1976, J FAMILY HIST, V38, P7; MULDER CH, 1993, EUR J POPUL, V9, P55, DOI 10.1007/BF01267901; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; NOWAK V, 1998, 8 AUSTR I FAM STUD; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ravanera ZR, 2004, CAN J SOCIOL, V29, P527, DOI 10.1353/cjs.2005.0014; STONE M, 1974, J R STAT SOC B, V36, P111; VANWISSEN LJG, 1999, POPULATION ISSUES IN; Witten I. H., 2000, DATA MINING PRACTICA	39	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0168-6577		EUR J POPUL	Eur. J. Popul.-Rev. Eur. Demogr.	MAR	2006	22	1					37	65		10.1007/s10680-005-5549-0		29	Demography	Demography	044BV	WOS:000237648000002	
J	Cordes, F; Kaiser, R; Selbig, J				Cordes, F; Kaiser, R; Selbig, J			Bioinformatics approach to predicting HIV drug resistance	EXPERT REVIEW OF MOLECULAR DIAGNOSTICS			English	Review						bioinformatics; clustering; drug resistance; genotype; HIV-1; machine learning; phenotype	TYPE-1 REVERSE-TRANSCRIPTASE; IN-VITRO SELECTION; SUSCEPTIBILITY PHENOTYPE; ANTIRETROVIRAL THERAPY; NEURAL-NETWORKS; GENOTYPE; TRIAL; PROTEASE; COMBINATION; INHIBITORS	The emergence of drug resistance remains one of the most challenging issues in the treatment of HIV-1 infection. The extreme replication dynamics of HIV facilitates its escape from the selective pressure exerted by the human immune system and by the applied combination drug therapy. This article reviews computational methods whose combined use can support the design of optimal antiretroviral therapies based on viral genotypic and phenotypic data. Genotypic assays are based on the analysis of mutations associated with reduced drug susceptibility, but are difficult to interpret due to the numerous mutations and mutational patterns that confer drug resistance. Phenotypic resistance or susceptibility can be experimentally evaluated by measuring the inhibition of the viral replication in cell culture assays. However, this procedure is expensive and time consuming.	Univ Potsdam, Inst Biochem & Biol, Max Planck Inst Mol Plant Physiol, D-14476 Potsdam, Germany; Konrad Zuse Zentrum, Div Comp Sci, Dept Numer Anal & Modeling, D-14195 Berlin, Germany; Univ Cologne, Inst Virol, D-50935 Cologne, Germany	Selbig, J (reprint author), Univ Potsdam, Inst Biochem & Biol, Max Planck Inst Mol Plant Physiol, Muhlenberg 1, D-14476 Potsdam, Germany.	selbig@mpimp.golm.mpg.de					Baum D, 2005, LECT NOTES COMPUT SC, V3695, P198; Bazmi HZ, 2000, ANTIMICROB AGENTS CH, V44, P1783, DOI 10.1128/AAC.44.7.1783-1788.2000; Beerenwinkel N, 2005, J INFECT DIS, V191, P1953, DOI 10.1086/430005; Beerenwinkel N, 2005, BIOINFORMATICS, V21, P3943, DOI 10.1093/bioinformatics/bti654; Beerenwinkel N, 2001, IEEE INTELL SYST, V16, P35, DOI 10.1109/5254.972080; Beerenwinkel N, 2002, P NATL ACAD SCI USA, V99, P8271, DOI 10.1073/pnas.112177799; Clavel F, 2004, NEW ENGL J MED, V350, P1023, DOI 10.1056/NEJM2ra025195; Cohen CJ, 2002, AIDS, V16, P579, DOI 10.1097/00002030-200203080-00009; DeGruttola V, 2000, ANTIVIR THER, V5, P41; Deuflhard P, 2003, TRENDS IN NONLINEAR ANALYSIS, P269; DiRienzo AG, 2003, STAT MED, V22, P2785, DOI 10.1002/sim.1516; Draghici S, 2003, BIOINFORMATICS, V19, P98, DOI 10.1093/bioinformatics/19.1.98; Durant J, 1999, LANCET, V353, P2195, DOI 10.1016/S0140-6736(98)12291-2; FARTHING C, 2003, 2 IAS C HIV PATH TRE; Foulkes AS, 2002, BIOMETRICS, V58, P145, DOI 10.1111/j.0006-341X.2002.00145.x; GREEN SM, 1995, TRENDS PHARMACOL SCI, V16, P285, DOI 10.1016/S0165-6147(00)89052-5; Halgren TA, 1996, J COMPUT CHEM, V17, P490, DOI 10.1002/(SICI)1096-987X(199604)17:5/6<490::AID-JCC1>3.0.CO;2-P; Huang XQ, 2002, J MED CHEM, V45, P333, DOI 10.1021/jm0102710; Jenwitheesuk Ekachai, 2005, Antivir Ther, V10, P157; Jenwitheesuk E, 2005, TRENDS MICROBIOL, V13, P150, DOI 10.1016/j.tim.2005.02.003; Johnson Victoria A, 2004, Top HIV Med, V12, P119; JORDAN R, 2002, BRIT MED J, V324, P1; KELLAM P, 1994, ANTIMICROB AGENTS CH, V38, P23; LARDER BA, 1993, NATURE, V365, P451, DOI 10.1038/365451a0; MUELLER SM, 2004, ANTIVIR THER, V9, pS44; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; OETTE M, 2006, IN PRESS AIDS; Perola E, 2004, J MED CHEM, V47, P2499, DOI 10.1021/jm030563w; Perrin L, 1998, SCIENCE, V280, P1871, DOI 10.1126/science.280.5371.1871; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rosin CD, 1999, P NATL ACAD SCI USA, V96, P1369, DOI 10.1073/pnas.96.4.1369; SADOWSKI J, 2003, COMPUTATIONAL MED CH, P151; SCHNEIDER TD, 1990, NUCLEIC ACIDS RES, V18, P6097, DOI 10.1093/nar/18.20.6097; Sevin AD, 2000, J INFECT DIS, V182, P59, DOI 10.1086/315673; Tisdale M, 1997, ANTIMICROB AGENTS CH, V41, P1094; Tural C, 2002, AIDS, V16, P209, DOI 10.1097/00002030-200201250-00010; UNDERWOOD M, 2005, 12 CROI BOST MA US; Vapnik V, 1996, NATURE STAT LEARNING; Wainberg MA, 1999, ANTIVIR THER, V4, P87; Walter H, 1999, J CLIN VIROL, V13, P71, DOI 10.1016/S1386-6532(99)00010-4; Wang DC, 2003, J INFECT DIS, V188, P653, DOI 10.1086/377453; Wang K, 2004, ANTIVIR THER, V9, P343; Wegner SA, 2004, CLIN INFECT DIS, V38, P723, DOI 10.1086/381266; Wolf K, 2003, ANTIMICROB AGENTS CH, V47, P3478, DOI 10.1128/AAC.47.11.3478-3484.2003	44	7	8	FUTURE DRUGS LTD	LONDON	UNITEC HOUSE, 3RD FL, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON N3 1QB, ENGLAND	1473-7159		EXPERT REV MOL DIAGN	Expert Rev. Mol. Diagn.	MAR	2006	6	2					207	215		10.1586/14737159.6.2.207		9	Pathology	Pathology	019GO	WOS:000235823800008	
J	Kell, DB				Kell, DB			Metabolomics, modelling and machine learning in systems biology - towards an understanding of the languages of cells	FEBS JOURNAL			English	Review						hypothesis generation; genetic programming; evolutionary computing; signal processing elements; technology development; systems biology	NF-KAPPA-B; NUCLEIC-ACID APTAMERS; 2-DIMENSIONAL GAS-CHROMATOGRAPHY; NOVO PROTEIN DESIGN; FLUORESCENCE CORRELATION SPECTROSCOPY; MOLECULE DETECTION TECHNOLOGIES; ARTIFICIAL NEURAL-NETWORKS; GENE REGULATORY NETWORKS; FLIGHT MASS-SPECTROMETRY; CHEMICAL GENETICS	The newly emerging field of systems biology involves a judicious interplay between high-throughput 'wet' experimentation, computational modelling and technology development, coupled to the world of ideas and theory. This interplay involves iterative cycles, such that systems biology is not at all confined to hypothesis-dependent studies, with intelligent, principled, hypothesis-generating studies being of high importance and consequently very far from aimless fishing expeditions. I seek to illustrate each of these facets. Novel technology development in metabolomics can increase substantially the dynamic range and number of metabolites that one can detect, and these can be exploited as disease markers and in the consequent and principled generation of hypotheses that are consistent with the data and achieve this in a value-free manner. Much of classical biochemistry and signalling pathway analysis has concentrated on the analyses of changes in the concentrations of intermediates, with 'local' equations - such as that of Michaelis and Menten v=((VmaxS)-S-.)/(S+K-m) - that describe individual steps being based solely on the instantaneous values of these concentrations. Recent work using single cells (that are not subject to the intellectually unsupportable averaging of the variable displayed by heterogeneous cells possessing nonlinear kinetics) has led to the recognition that some protein signalling pathways may encode their signals not (just) as concentrations (AM or amplitude-modulated in a radio analogy) but via changes in the dynamics of those concentrations (the signals are FM or frequency-modulated). This contributes in principle to a straightforward solution of the crosstalk problem, leads to a profound reassessment of how to understand the downstream effects of dynamic changes in the concentrations of elements in these pathways, and stresses the role of signal processing (and not merely the intermediates) in biological signalling. It is this signal processing that lies at the heart of understanding the languages of cells. The resolution of many of the modern and postgenomic problems of biochemistry requires the development of a myriad of new technologies (and maybe a new culture), and thus regular input from the physical sciences, engineering, mathematics and computer science. One solution, that we are adopting in the Manchester Interdisciplinary Biocentre (http://www.mib.ac.uk/) and the Manchester Centre for Integrative Systems Biology (http://www.mcisb.org/), is thus to colocate individuals with the necessary combinations of skills. Novel disciplines that require such an integrative approach continue to emerge. These include fields such as chemical genomics, synthetic biology, distributed computational environments for biological data and modelling, single cell diagnostics/bionanotechnology, and computational linguistics/text mining.	Univ Manchester, Sch Chem, Manchester M60 1QD, Lancs, England; Manchester Interdisciplinary Bioctr, Manchester Ctr Integrat Syst Biol, Manchester, Lancs, England	Kell, DB (reprint author), Univ Manchester, Sch Chem, Faraday Bldg,Sackville St, Manchester M60 1QD, Lancs, England.	dbk@manchester.ac.uk	Kell, Douglas/E-8318-2011				Achard F, 2001, BIOINFORMATICS, V17, P115, DOI 10.1093/bioinformatics/17.2.115; Aldana M, 2003, P NATL ACAD SCI USA, V100, P8710, DOI 10.1073/pnas.1536783100; Alexeeva M, 2003, ORG BIOMOL CHEM, V1, P4133, DOI 10.1039/b311055a; Allen J, 2004, APPL ENVIRON MICROB, V70, P6157, DOI 10.1128/AEM.70.10.6157-6165.2004; Allen J, 2003, NAT BIOTECHNOL, V21, P692, DOI 10.1038/nbt823; Andrews SS, 2004, PHYS BIOL, V1, P137, DOI 10.1088/1478-3967/1/3/001; Arkin AP, 2001, CURR OPIN BIOTECH, V12, P638, DOI 10.1016/S0958-1669(01)00273-7; Arnold FH, 2001, TRENDS BIOCHEM SCI, V26, P100, DOI 10.1016/S0968-0004(00)01755-2; Arnold FH, 2001, NATURE, V409, P253, DOI 10.1038/35051731; Back T., 1997, HDB EVOLUTIONARY COM; BAILEY JE, 1991, SCIENCE, V252, P1668, DOI 10.1126/science.2047876; Bannai M, 2004, ANAL BIOCHEM, V327, P215, DOI 10.1016/j.ab.2004.01.012; BARABASI A-L, 2002, LINKED NEW SCI NETWO; Barkai N, 1997, NATURE, V387, P913; Barrow JD, 1995, LEFT HAND CREATION O; Benner SA, 2005, NAT REV GENET, V6, P533, DOI 10.1038/nrg1637; Bennett ST, 2005, PHARMACOGENOMICS, V6, P373, DOI 10.1517/14622416.6.4.373; Bhalla US, 2003, PROG BIOPHYS MOL BIO, V81, P45, DOI 10.1016/S0079-6107(02)00046-9; Bino RJ, 2004, TRENDS PLANT SCI, V9, P418, DOI 10.1016/j.tplants.2004.07.004; Blake WJ, 2004, TRENDS BIOTECHNOL, V22, P321, DOI 10.1016/j.tibtech.2004.04.008; Blank M, 2005, CURR OPIN CHEM BIOL, V9, P336, DOI 10.1016/j.cbpa.2005.06.011; Blumberg LM, 2003, J CHROMATOGR A, V985, P29, DOI 10.1016/S0021-9673(02)01416-4; Boder ET, 2000, P NATL ACAD SCI USA, V97, P10701, DOI 10.1073/pnas.170297297; Borisy AA, 2003, P NATL ACAD SCI USA, V100, P7977, DOI 10.1073/pnas.1337088100; Borodina I, 2005, GENOME RES, V15, P820, DOI 10.1101/gr.3364705; Bower J., 2004, COMPUTATIONAL MODELI; Bradley P, 2005, SCIENCE, V309, P1868, DOI 10.1126/science.1113801; Brenner C, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-9-240; BRENNER S, 1997, LOOSE ENDS; Brent R, 2005, SCIENCE, V308, P504, DOI 10.1126/science.1110535; Brent R, 1999, CURR BIOL, V9, pR338, DOI 10.1016/S0960-9822(99)80208-5; Brody EN, 1999, MOL DIAGN, V4, P381, DOI 10.1016/S1084-8592(99)80014-9; BROWN M, 2005, METABOLOMICS, V1, P35; BRYANT J, 2001, HEALTH TECHNOL ASSES, V5, P1; Buchanan M., 2002, NEXUS SMALL WORLDS G; Buchler NE, 2003, P NATL ACAD SCI USA, V100, P5136, DOI 10.1073/pnas.0930314100; Carroll PM, 2003, PHARMACOL THERAPEUT, V99, P183, DOI 10.1016/S0163-7258(03)00059-7; Cascante M, 2002, NAT BIOTECHNOL, V20, P243, DOI 10.1038/nbt0302-243; Catchpole GS, 2005, P NATL ACAD SCI USA, V102, P14458, DOI 10.1073/pnas.0503955102; Chalfie M, 1998, GREEN FLUORESCENT PR; Chaves M, 2005, J THEOR BIOL, V235, P431, DOI 10.1016/j.boolean.2005.01.023; Chen BS, 2005, BIOINFORMATICS, V21, P2698, DOI 10.1093/bioinformatics/bti348; Chen W.K., 1986, PASSIVE ACTIVE FILTE; Cheng RP, 2004, CURR OPIN STRUC BIOL, V14, P512, DOI 10.1016/j.sbi.2004.07.001; Clark SL, 2002, ELECTROPHORESIS, V23, P1335, DOI 10.1002/1522-2683(200205)23:9<1335::AID-ELPS1335>3.0.CO;2-E; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; Colas P, 1996, NATURE, V380, P548, DOI 10.1038/380548a0; Conrad RC, 1996, METHOD ENZYMOL, V267, P336; CORNE D, 2001, GECCO P GEN EV COMP; Corne D, 1999, NEW IDEAS OPTIMIZATI; Cornell M, 2003, YEAST, V20, P1291, DOI 10.1002/yea.1047; Corney DPA, 2004, BIOINFORMATICS, V20, P3206, DOI 10.1093/bioinformatics/bth386; Cornish-Bowden A, 1995, FUNDAMENTALS ENZYME; CornishBowden A, 1995, BIOORG CHEM, V23, P439, DOI 10.1006/bioo.1995.1030; Coveney P., 1990, ARROW TIME; Coveney Peter, 1995, FRONTIERS COMPLEXITY; Covert MW, 2005, SCIENCE, V309, P1854, DOI 10.1126/science.1112304; Covert MW, 2003, J THEOR BIOL, V221, P309, DOI 10.1006/jtbi.2003.3071; Cox JC, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/gnf107; Crews CM, 1999, TRENDS BIOCHEM SCI, V24, P317, DOI 10.1016/S0968-0004(99)01425-5; Csete ME, 2002, SCIENCE, V295, P1664, DOI 10.1126/science.1069981; Cubberley MS, 2001, CURR OPIN CHEM BIOL, V5, P650, DOI 10.1016/S1367-5931(01)00261-7; Curcin V, 2005, DRUG DISCOV TODAY, V10, P865, DOI 10.1016/S1359-6446(05)03481-1; Dahiyat BI, 1997, SCIENCE, V278, P82, DOI 10.1126/science.278.5335.82; Daniel C, 2003, SCIENCE, V299, P536, DOI 10.1126/science.1078517; Daraselia N, 2004, BIOINFORMATICS, V20, P604, DOI 10.1093/bioinformatics/btg452; Darvas F, 2004, CURR MED CHEM, V11, P3119; Dasgupta P, 1999, MULTIOBJECTIVE HEURI; Davey HM, 1996, MICROBIOL REV, V60, P641; Davidov EJ, 2003, DRUG DISCOV TODAY, V8, P175, DOI 10.1016/S1359-6446(03)02600-X; Deckard A, 2004, CHEMBIOCHEM, V5, P1423, DOI 10.1002/cbic.200400178; de la Fuente A, 2002, TRENDS GENET, V18, P395, DOI 10.1016/S0168-9525(02)02692-6; Dunn WB, 2005, ANALYST, V130, P606, DOI 10.1039/b418288j; Dunn WB, 2005, TRAC-TREND ANAL CHEM, V24, P285, DOI 10.1016/j.trac.2004.11.021; Ebenhoh O, 2003, B MATH BIOL, V65, P323, DOI 10.1016/S0092-8240(03)00002-8; Edwards JS, 2001, NAT BIOTECHNOL, V19, P125, DOI 10.1038/84379; Endy D, 2001, NATURE, V409, P391, DOI 10.1038/35053181; Famili I, 2005, BIOPHYS J, V88, P1616, DOI 10.1529/biophysj.104.050385; Famulok M, 2004, NATURE, V430, P976, DOI 10.1038/430976a; Famulok M, 2000, ACCOUNTS CHEM RES, V33, P591, DOI 10.1021/ar960167q; Famulok M, 2005, CURR OPIN MOL THER, V7, P137; Famulok M, 2005, CHEMBIOCHEM, V6, P19, DOI 10.1002/cbic.200400299; Fan QW, 2003, CANCER RES, V63, P8930; Fehr M, 2003, J BIOL CHEM, V278, P19127, DOI 10.1074/jbc.M301333200; Fell D., 1996, UNDERSTANDING CONTRO; FELL DA, 1995, BIOCHEM J, V311, P35; Fell DA, 1998, BIOTECHNOL BIOENG, V58, P121, DOI 10.1002/(SICI)1097-0290(19980420)58:2/3<121::AID-BIT2>3.0.CO;2-N; Ferber D, 2004, SCIENCE, V303, P158, DOI 10.1126/science.303.5655.158; Fersht A. R., 1977, ENZYME STRUCTURE MEC; Fiehn O, 2002, PLANT MOL BIOL, V48, P155, DOI 10.1023/A:1013713905833; Finney A, 2003, BIOCHEM SOC T, V31, P1472; Forster J, 2003, GENOME RES, V13, P244, DOI 10.1101/gr.234503; Garwood K, 2004, BMC GENOMICS, V5, DOI 10.1186/1471-2164-5-68; Gellman SH, 1998, ACCOUNTS CHEM RES, V31, P173, DOI 10.1021/ar960298r; German JB, 2003, J NUTR, V133, P4260; Ghosh S., 2002, CELL S, V109, P81; Giaever G, 2003, TRENDS PHARMACOL SCI, V24, P444, DOI 10.1016/S0165-6147(03)00225-6; Gibbs WW, 2004, SCI AM, V290, P74; Gibney MJ, 2005, AM J CLIN NUTR, V82, P497; Goble CA, 2001, IBM SYST J, V40, P532; Gold L, 2002, CHEM BIOL, V9, P1259, DOI 10.1016/S1074-5521(02)00286-7; Goldberg D.E., 2002, DESIGN INNOVATION LE; Goodacre R, 2004, TRENDS BIOTECHNOL, V22, P245, DOI 10.1016/j.tibtech.2004.03.007; Haggarty SJ, 2004, COMB CHEM HIGH T SCR, V7, P669; Hakenberg J, 2004, OMICS, V8, P131, DOI 10.1089/1536231041388366; Han J., 2001, DATA MINING CONCEPTS; Harrigan GG, 2003, METABOLIC PROFILING; HASENJAGER M, 1998, NEURAL P LETT, V7, P110; Hastie T, 2001, ELEMENTS STAT LEARNI; Hasty J, 2002, NATURE, V420, P224, DOI 10.1038/nature01257; Hasty J, 2001, CHAOS, V11, P207, DOI 10.1063/1.1345702; Haupts U, 2003, J BIOMOL SCREEN, V8, P19, DOI 10.1177/1087057102239669; HEINRICH R, 1974, EUR J BIOCHEM, V42, P89, DOI 10.1111/j.1432-1033.1974.tb03318.x; HEINRICH R, 1996, REGULATION CELL SYST; Henry CM, 2003, CHEM ENG NEWS, V81, P45; Hermann T, 2000, SCIENCE, V287, P820, DOI 10.1126/science.287.5454.820; Hermjakob H, 2004, NAT BIOTECHNOL, V22, P177, DOI 10.1038/nbt926; Hicks C. R., 1999, FUNDAMENTAL CONCEPTS; Hill DJ, 2001, CHEM REV, V101, P3893, DOI 10.1021/cr990120t; Hill RB, 2000, ACCOUNTS CHEM RES, V33, P745, DOI 10.1021/ar970004h; Hirschman L, 2002, BIOINFORMATICS, V18, P1553, DOI 10.1093/bioinformatics/18.12.1553; HITCHENS GD, 1983, BIOCHEM J, V212, P25; Hoffmann A, 2002, SCIENCE, V298, P1241, DOI 10.1126/science.1071914; HOFFMANN R, 2005, SCI STKE; Holland John, 1998, EMERGENCE; Hood L, 2003, MECH AGEING DEV, V124, P9, DOI 10.1016/S0047-6374(02)00164-1; Hucka M, 2003, BIOINFORMATICS, V19, P524, DOI 10.1093/bioinformatics/btg015; Iberall A. S., 1972, GEN SCI VIABLE SYSTE; Ideker T, 2001, ANNU REV GENOM HUM G, V2, P343, DOI 10.1146/annurev.genom.2.1.343; Ihekwaba A. E. C., 2004, Systems Biology, V1, P93, DOI 10.1049/sb:20045009; Ihekwaba AEC, 2005, IEE P SYST BIOL, V152, P153, DOI 10.1049/ip-syb:20050050; Isaacs FJ, 2005, SCIENCE, V307, P1886, DOI 10.1126/science.1110797; Jayasena SD, 1999, CLIN CHEM, V45, P1628; Jenkins H, 2004, NAT BIOTECHNOL, V22, P1601, DOI 10.1038/nbt1041; Jhaveri SD, 2000, J AM CHEM SOC, V122, P2469, DOI 10.1021/ja992393b; JOHNSON STEVEN, 2001, EMERGENCE CONNECTED; Jones AR, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-235; JONES DT, 1994, PROTEIN SCI, V3, P567; Joyce GF, 2004, ANNU REV BIOCHEM, V73, P791, DOI 10.1146/annurev.biochem.73.011303.073717; Kacser H, 1973, Symp Soc Exp Biol, V27, P65; KACSER H, 1986, ORG CELL METABOLISM, P327; Kaderbhai NN, 2003, COMP FUNCT GENOM, V4, P376, DOI 10.1002/cfg.302; Kaern M, 2003, ANNU REV BIOMED ENG, V5, P179, DOI 10.1146/annurev.bioeng.5.040202.121553; Kashtan N, 2005, P NATL ACAD SCI USA, V102, P13773, DOI 10.1073/pnas.0503610102; Kauffman S., 1995, HOME UNIVERSE SEARCH; Kauffman S, 2000, J ECON BEHAV ORGAN, V43, P141, DOI 10.1016/S0167-2681(00)00114-1; KAUFFMAN SA, 1993, ORIGINS ORDER; Keasling JD, 1999, TRENDS BIOTECHNOL, V17, P452, DOI 10.1016/S0167-7799(99)01376-1; Keleti T., 1986, BASIC ENZYME KINETIC; Kell DB, 2004, CURR OPIN MICROBIOL, V7, P296, DOI 10.1016/j.mib.2004.04.012; Kell DB, 2005, NAT REV MICROBIOL, V3, P557, DOI 10.1038/nrmicrol177; KELL DB, 1991, TIMES HIGHER ED 0809, P15; KELL DB, 2005, SYSTEM MODELING CELL, P3; KELL DB, 1991, ANTON LEEUW INT J G, V60, P145, DOI 10.1007/BF00430362; KELL DB, 1979, BIOCHIM BIOPHYS ACTA, V549, P55, DOI 10.1016/0304-4173(79)90018-1; Kell DB, 2000, NATO ASI 3 HIGH TECH, V74, P3; Kell DB, 2001, PLANT PHYSIOL, V126, P943, DOI 10.1104/pp.126.3.943; Kell DB, 2004, BIOESSAYS, V26, P99, DOI 10.1002/bies.10385; Kell DB, 2002, TRENDS GENET, V18, P555, DOI 10.1016/S0168-9525(02)02765-8; KELL DB, 1986, FEMS MICROBIOL REV, V39, P305, DOI 10.1111/j.1574-6968.1986.tb01863.x; Kell DB, 2002, MOL BIOL REP, V29, P237, DOI 10.1023/A:1020342216314; Kell DB, 2000, TRENDS BIOTECHNOL, V18, P93, DOI 10.1016/S0167-7799(99)01407-9; KELL DB, 2004, NONLINEAR DIELECTRIC, P335; Kell DB, 2005, BIOCHEM SOC T, V33, P520; Kenny LC, 2005, METABOLOMICS, V1, P227, DOI 10.1007/s11306-005-0003-1; Kholodenko BN, 2002, P NATL ACAD SCI USA, V99, P12841, DOI 10.1073/pnas.192442699; Khosla C, 2003, NAT REV DRUG DISCOV, V2, P1019, DOI 10.1038/nrd1256; King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236; King RD, 2005, BIOINFORMATICS, V21, P2017, DOI 10.1093/bioinformatics/bti255; Kitano H, 2004, NAT REV GENET, V5, P826, DOI 10.1038/nrg1471; Kitano H, 2002, SCIENCE, V295, P1662, DOI 10.1126/science.1069492; Kitano H, 2002, NATURE, V420, P206, DOI 10.1038/nature01254; Klipp E, 2005, SYSTEMS BIOLOGY IN PRACTICE: CONCEPTS, IMPLEMENTATION AND APPLICATION, P1, DOI 10.1002/3527603603; Koza J. R., 2001, PACIFIC S BIOCOMPUTI, P434; Koza JR, 2003, GENETIC PROGRAMMING; KOZA JR, 2001, P GECCO 2001, P57; Kramer BP, 2004, BIOTECHNOL BIOENG, V87, P478, DOI 10.1002/bit.20142; Kriete A, 2005, COMPUTATIONAL SYSTEM; L Agius, 1997, CHANNELLING INTERMED; Langley P., 1987, SCI DISCOVERY COMPUT; Laughlin R. M., 2005, DIFFERENT UNIVERSE R; Lazebnik Y, 2002, CANCER CELL, V2, P179, DOI 10.1016/S1535-6108(02)00133-2; Lindon JC, 2005, NAT BIOTECHNOL, V23, P833, DOI 10.1038/nbt0705-833; Lipton P., 1991, INFERENCE BEST EXPLA; Liu Li-Ping, 1998, Biopolymers, V47, P41, DOI 10.1002/(SICI)1097-0282(1998)47:1<41::AID-BIP6>3.0.CO;2-X; Ljung L., 1987, SYSTEM IDENTIFICATIO; Logothetis N, 1989, QUALITY DESIGN EXPT; Lu Q, 2006, J BIOMED INFORM, V39, P440, DOI 10.1016/j.jbi.2005.09.001; Lutz S, 2004, CURR OPIN BIOTECH, V15, P291, DOI 10.1016/j.copbio.2004.05.004; Luzi E, 2003, TRAC-TREND ANAL CHEM, V22, P810, DOI 10.1016/S0165-9936(03)01208-1; Ma L, 2002, BMC BIOINFORMATICS, P3; MacKay D., 2003, INFORM THEORY INFERE; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; Mangan S, 2003, P NATL ACAD SCI USA, V100, P11980, DOI 10.1073/pnas.2133841100; Mantzaris NV, 2005, COMPUT CHEM ENG, V29, P631, DOI 10.1016/j.compchemeng.2004.08.009; Margulies M, 2005, NATURE, V437, P376, DOI 10.1038/nature03959; Marriott P, 2002, TRAC-TREND ANAL CHEM, V21, P573, DOI 10.1016/S0165-9936(02)00814-2; McCafferty DG, 1999, CURR OPIN CHEM BIOL, V3, P672, DOI 10.1016/S1367-5931(99)00025-3; McNaught J, 2006, TEXT MINING BIOL BIO; Meisner NC, 2004, CURR OPIN CHEM BIOL, V8, P424, DOI 10.1016/j.cbpa.2004.06.011; Mendes P, 1997, TRENDS BIOCHEM SCI, V22, P361, DOI 10.1016/S0968-0004(97)01103-1; Mendes P, 2001, BIOINFORMATICS, V17, P288, DOI 10.1093/bioinformatics/17.3.288; Mendes P, 1998, BIOINFORMATICS, V14, P869, DOI 10.1093/bioinformatics/14.10.869; Mendes P, 1996, BIOSYSTEMS, V38, P15, DOI 10.1016/0303-2647(95)01565-5; MENDES P, 1995, ENZYMOLOGY VIVO, P1; Michalewicz Z., 2000, SOLVE IT MODERN HEUR; MIKULECKY DC, 1983, AM J PHYSIOL, V245, pR1; Mikulecky DC, 2001, COMPUT CHEM, V25, P369, DOI 10.1016/S0097-8485(01)00072-9; Milano M, 2001, LECT NOTES COMPUT SC, V2130, P436; Milo R, 2004, SCIENCE, V303, P1538, DOI 10.1126/science.1089167; Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824; Moles CG, 2003, GENOME RES, V13, P2467, DOI 10.1101/gr.1262503; Montgomery DC, 2001, DESIGN ANAL EXPT; Moore KJ, 1999, J BIOMOL SCREEN, V4, P335, DOI 10.1177/108705719900400609; Morohashi M, 2002, J THEOR BIOL, V216, P19, DOI 10.1006/jtbi.2002.2537; MUTIU R, 2005, ANGEW CHEM INT EDIT, V44, P1061; Myers R.H., 1995, RESPONSE SURFACE MET; Nelson DE, 2004, SCIENCE, V306, P704, DOI 10.1126/science.1099962; Nelson G, 2002, J CELL SCI, V115, P1137; Nenadic G, 2003, BIOINFORMATICS, V19, P938, DOI 10.1093/bioinformatics/btg105; Nicholson JK, 2004, NAT BIOTECHNOL, V22, P1268, DOI 10.1038/nbt1015; Nicholson JK, 2003, NAT REV DRUG DISCOV, V2, P668, DOI 10.1038/nrd1157; NOCOLIS G, 1977, SELF ORG NONEQUILIBR; Nutiu R, 2005, METHODS, V37, P16, DOI 10.1016/j.ymeth.2005.07.001; Nutiu R, 2004, CHEMBIOCHEM, V5, P1139, DOI 10.1002/cbic.200400026; O'Hagan S, 2005, ANAL CHEM, V77, P290, DOI 10.1021/ac049146x; OATES MJ, 2003, RECENT ADV SIMULATED, P215; Oinn T, 2004, BIOINFORMATICS, V20, P3045, DOI 10.1093/bioinformatics/bth361; OLANSKY AS, 1977, ANAL CHIM ACTA, V95, P107, DOI 10.1016/S0003-2670(00)84986-7; OLANSKY AS, 1978, CLIN CHEM, V24, P2115; Oliver SG, 1998, TRENDS BIOTECHNOL, V16, P373, DOI 10.1016/S0167-7799(98)01214-1; Ong RCY, 2002, J CHROMATOGR SCI, V40, P276; Orchard S, 2003, PROTEOMICS, V3, P1374, DOI 10.1002/pmic.200300496; Orchard S, 2004, PROTEOMICS, V4, P490, DOI 10.1002/pmic.200300694; Otten LG, 2005, BIOMOL ENG, V22, P1, DOI 10.1016/j.bioeng.2005.02.002; Ovadi J, 2000, INT REV CYTOL, V192, P255; Ovadi J, 1995, CELL ARCHITECTURE ME; Palsson BO, 2006, SYSTEMS BIOL PROPERT; Papin JA, 2004, TRENDS BIOTECHNOL, V22, P400, DOI 10.1016/j.tibtech.2004.06.010; Park S, 2004, CURR OPIN STRUC BIOL, V14, P487, DOI 10.1016/j.sbi.2004.06.002; Park S, 2005, COMPUT CHEM ENG, V29, P407, DOI 10.1016/j.compchemeng.2004.07.037; Patil KR, 2004, CURR OPIN BIOTECH, V15, P64, DOI 10.1016/j.copbio.2003.11.003; Patil KR, 2005, P NATL ACAD SCI USA, V102, P2685, DOI 10.1073/pnas.0406811102; Patil KR, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-308; Pe'er D., 2001, BIOINFORMATICS S1, V17, P215; Pearl J, 2000, CAUSALITY MODELS REA; PETHIG R, 1987, PHYS MED BIOL, V32, P933, DOI 10.1088/0031-9155/32/8/001; Plumb R, 2004, RAPID COMMUN MASS SP, V18, P2331, DOI 10.1002/rcm.1627; Prigogine I., 1980, BEING BECOMING TIME; Proske D, 2005, APPL MICROBIOL BIOT, V69, P367, DOI 10.1007/s00253-005-0193-5; Raamsdonk LM, 2001, NAT BIOTECHNOL, V19, P45; Raju GK, 1998, AICHE J, V44, P2199, DOI 10.1002/aic.690441009; RAYWARDSMITH VJ, 1976, MODERN HEURISTIC SEA; Reed JL, 2003, J BACTERIOL, V185, P2692, DOI 10.1128/JB.185.9.2692-2699.2003; Reetz MT, 2000, CHEM-EUR J, V6, P407, DOI 10.1002/(SICI)1521-3765(20000204)6:3<407::AID-CHEM407>3.3.CO;2-P; Reetz MT, 2005, ANGEW CHEM INT EDIT, V44, P4192, DOI 10.1002/anie.200500767; Reeves C, 1995, MODERN HEURISTIC TEC; RICHARDSON JS, 1989, TRENDS BIOCHEM SCI, V14, P304, DOI 10.1016/0968-0004(89)90070-4; Richmond A, 2002, NAT REV IMMUNOL, V2, P664, DOI 10.1038/nri887; Rimmele M, 2003, CHEMBIOCHEM, V4, P963, DOI 10.1002/cbic.200300648; Rosenfeld N, 2003, J MOL BIOL, V329, P645, DOI 10.1016/S0022-2836(03)00506-0; Rosi NL, 2005, CHEM REV, V105, P1547, DOI 10.1021/cr030067f; ROTMAN B, 1961, P NATL ACAD SCI USA, V47, P1981, DOI 10.1073/pnas.47.12.1981; Rzhetsky A, 2004, J BIOMED INFORM, V37, P43, DOI 10.1016/j.jbi.2003.10.001; Sachs K, 2005, SCIENCE, V308, P523, DOI 10.1126/science.1105809; Salemme FR, 2003, PHARMACOGENOMICS, V4, P257, DOI 10.1517/phgs.4.3.257.22692; Salis H, 2005, J CHEM PHYS, V122, DOI [10.1063/1.1835951, 10.1069/1.1835951]; Sauro HM, 2004, PROG BIOPHYS MOL BIO, V86, P5, DOI 10.1016/j.pbiomolbio.2004.03.002; Sauro Herbert M., 2003, OMICS A Journal of Integrative Biology, V7, P355, DOI 10.1089/153623103322637670; SAVAGEAU M, 1976, UNDERSTANDING CONTRO; Savageau MA, 1976, BIOCH SYSTEMS ANAL S; Schlesselman JJ, 1982, CASE CONTROL STUDIES; Schmitt BM, 2004, CHEMBIOCHEM, V5, P1384, DOI 10.1002/cbic.200400126; Schreiber SL, 1998, BIOORGAN MED CHEM, V6, P1127, DOI 10.1016/S0968-0896(98)00126-6; Schueler-Furman O, 2005, SCIENCE, V310, P638, DOI 10.1126/science.1112160; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Segel I., 1993, ENZYME KINETICS; Segre D, 2002, P NATL ACAD SCI USA, V99, P15112, DOI 10.1073/pnas.232349399; Segre Daniel, 2003, OMICS A Journal of Integrative Biology, V7, P301, DOI 10.1089/153623103322452413; Shendure J, 2005, SCIENCE, V309, P1728, DOI 10.1126/science.1117389; Shen-Orr SS, 2002, NAT GENET, V31, P64, DOI 10.1038/ng881; Shim JS, 2004, EXPERT OPIN THER TAR, V8, P653, DOI 10.1517/14728222.8.6.653; Shipley B, 2001, CAUSE CORRELATION BI; Sismour AM, 2005, EXPERT OPIN BIOL TH, V5, P1409, DOI 10.1517/14712598.5.11.1409; Smukste I, 2005, ANNU REV GENOM HUM G, V6, P261, DOI 10.1146/annurev.genom.6.080604.162136; SOKLATOVA LN, 2005, NAT BIOTECHNOL, V23, P1095; Sol'e R., 2000, SIGNS LIFE COMPLEXIT; Spasic I, 2005, BRIEF BIOINFORM, V6, P239, DOI 10.1093/bib/6.3.239; SPELLMAN PT, 2002, GENOME BIOL, V3; Spring DR, 2005, CHEM SOC REV, V34, P472, DOI 10.1039/b312875j; Stafford DE, 2002, P NATL ACAD SCI USA, V99, P1801, DOI 10.1073/pnas.032681699; Stark J, 2003, TRENDS BIOTECHNOL, V21, P290, DOI 10.1016/S0167-7799(03)00140-9; Stelling J, 2004, CELL, V118, P675, DOI 10.1016/j.cell.2004.09.008; STEMMER WPC, 1994, P NATL ACAD SCI USA, V91, P10747, DOI 10.1073/pnas.91.22.10747; STEMMER WPC, 1994, NATURE, V370, P389, DOI 10.1038/370389a0; STEPHANOPOULOS G, 1993, TRENDS BIOTECHNOL, V11, P392, DOI 10.1016/0167-7799(93)90099-U; STEPHANOPOULOS G, 1991, SCIENCE, V252, P1675, DOI 10.1126/science.1904627; Stockwell BR, 2000, NAT REV GENET, V1, P116, DOI 10.1038/35038557; Stockwell BR, 2000, TRENDS BIOTECHNOL, V18, P449, DOI 10.1016/S0167-7799(00)01499-2; Stojanovic MN, 2005, J AM CHEM SOC, V127, P6914, DOI 10.1021/ja0430003a; Stojanovic MN, 2001, J AM CHEM SOC, V123, P4928, DOI 10.1021/ja0038171; Stojanovic MN, 2004, J AM CHEM SOC, V126, P9266, DOI 10.1021/ja032013t; Styczynski MP, 2005, COMPUT CHEM ENG, V29, P519, DOI 10.1016/j.compchemeng.2004.08.029; Sumner LW, 2003, PHYTOCHEMISTRY, V62, P817, DOI 10.1016/S0031-9422(02)00708-2; SWANSON DR, 1990, B MED LIBR ASSOC, V78, P29; Sweetlove LJ, 2003, PLANT PHYSIOL, V132, P420, DOI 10.1104/pp.103.022004; Tian B, 2003, RECENT PROG HORM RES, V58, P95, DOI 10.1210/rp.58.1.95; Tian B, 2005, J BIOL CHEM, V280, P17435, DOI 10.1074/jbc.M500437200; Tochtrop GP, 2004, COMB CHEM HIGH T SCR, V7, P677; Tombelli S, 2005, BIOSENS BIOELECTRON, V20, P2424, DOI 10.1016/j.bios.2004.11.006; TROMBACK L, 2005, BIOINFORMATICS, V21, P4401; TUCHSCHERER G, 1995, J BIOTECHNOL, V41, P197, DOI 10.1016/0168-1656(95)00010-N; Twist CR, 2004, ANAL BIOCHEM, V327, P35, DOI 10.1016/j.ab.2003.12.023; Tyson JJ, 2001, NAT REV MOL CELL BIO, V2, P908, DOI 10.1038/35103078; Tyson JJ, 2003, CURR OPIN CELL BIOL, V15, P221, DOI 10.1016/S0955-0674(03)00017-6; Uhlen M, 2005, MOL CELL PROTEOMICS, V4, P384, DOI 10.1074/mcp.R500009-MCP200; ULMER KM, 1983, SCIENCE, V219, P666, DOI 10.1126/science.6572017; Vaidyanathan S, 2005, METABOLOME ANAL STRA; Vaidyanathan S, 2003, ANAL CHEM, V75, P6679, DOI 10.1021/ac034669a; Vaidyanathan S, 2004, ANAL CHEM, V76, P5024, DOI 10.1021/ac049684; VAILAYA A, 2005, BIOINFORMATICS, V21, P340; Voit E. O., 2000, COMPUTATIONAL ANAL B; von Bertalanffy L, 1969, GEN SYSTEM THEORY; von Dassow G, 2000, NATURE, V406, P188, DOI 10.1038/35018085; Wagner A, 2005, P NATL ACAD SCI USA, V102, P11775, DOI 10.1073/pnas.0501094102; Wagner Bridget K, 2004, Am J Pharmacogenomics, V4, P313, DOI 10.2165/00129785-200404050-00004; Wall ME, 2004, NAT REV GENET, V5, P34, DOI 10.1038/nrg1244; Weckwerth W, 2003, ANNU REV PLANT BIOL, V54, P669, DOI 10.1146/annurev.arplant.54.031902.135014; Werner SL, 2005, SCIENCE, V309, P1857, DOI 10.1126/science.1113319; Westerhoff H. V., 1987, THERMODYNAMICS CONTR; WESTERHOFF HV, 1988, COMMENTS MOL CELL BI, V5, P57; WESTERHOFF HV, 1988, FERROELECTRICS, V86, P79, DOI 10.1080/00150198808227005; Westerhoff HV, 2001, METAB ENG, V3, P207, DOI 10.1006/mben.2001.0192; Westerhoff HV, 2004, NAT BIOTECHNOL, V22, P1249, DOI 10.1038/nbt1020; WESTERHOFF HV, 1986, P NATL ACAD SCI USA, V83, P4734, DOI 10.1073/pnas.83.13.4734; Whelan KE, 2004, TRENDS BIOTECHNOL, V22, P440, DOI 10.1016/j.tibtech.2004.07.010; White TA, 2004, COMP FUNCT GENOM, V5, P304, DOI 10.1002/cfg.411; Whitfield PD, 2004, BRIT J NUTR, V92, P549, DOI 10.1079/BJN20041243; Wilkinson Mark, 2005, Plant Physiol, V138, P5, DOI 10.1104/pp.104.059170; Wilkinson Mark D, 2002, Brief Bioinform, V3, P331, DOI 10.1093/bib/3.4.331; Williams GJ, 2004, CELL MOL LIFE SCI, V61, P3034, DOI 10.1007/s00018-004-4234-5; Wilson ID, 2005, J PROTEOME RES, V4, P591, DOI 10.1021/pr049769r; Wilson ID, 2005, J CHROMATOGR B, V817, P67, DOI 10.1016/j.jchromb.2004.07.045; Wilson ID, 2003, J CHROMATOGR A, V1000, P325, DOI 10.1016/S0021-9673(03)00504-1; Wolf DM, 2003, CURR OPIN MICROBIOL, V6, P125, DOI 10.1016/S1369-5274(03)00033-X; Woodward AM, 2004, ANALYST, V129, P542, DOI 10.1039/b403134b; WOODWARD AM, 1990, BIOELECTROCH BIOENER, V24, P83, DOI 10.1016/0302-4598(90)85013-8; Woodward AM, 1996, BIOELECTROCH BIOENER, V40, P99, DOI 10.1016/0302-4598(96)05065-9; Wu L, 2004, EUR J BIOCHEM, V271, P3348, DOI 10.1111/j.1432-1033.2004.04269.x; Xie XS, 1999, J BIOL CHEM, V274, P15967, DOI 10.1074/jbc.274.23.15967; XIRASAGAR S, 2004, BIOINFORMATICS, V20, P15; Yeger-Lotem E, 2004, P NATL ACAD SCI USA, V101, P5934, DOI 10.1073/pnas.0306752101; Zanders ED, 2002, DRUG DISCOV TODAY, V7, P711, DOI 10.1016/S1359-6446(02)02325-5; Zheng X. F. Steven, 2002, Current Issues in Molecular Biology, V4, P33	355	67	72	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1742-464X		FEBS J	FEBS J.	MAR	2006	273	5					873	894		10.1111/j.1742-4658.2006.05136.x		22	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	012IB	WOS:000235330700001	
J	Li, YH; Lee, KK; Walsh, S; Smith, C; Hadingham, S; Sorefan, K; Cawley, G; Bevan, MW				Li, YH; Lee, KK; Walsh, S; Smith, C; Hadingham, S; Sorefan, K; Cawley, G; Bevan, MW			Establishing glucose- and ABA-regulated transcription networks in Arabidopsis by microarray analysis and promoter classification using a Relevance Vector Machine	GENOME RESEARCH			English	Article							DNA-BINDING PROTEIN; GENE-EXPRESSION; ABSCISIC-ACID; ALPHA-AMYLASE; CIS-ELEMENTS; INSENSITIVE MUTANTS; ROOT-MERISTEMS; REDUCTASE GENE; HIGHER-PLANTS; SUGAR	Establishing transcriptional regulatory networks by analysis of gene expression data and promoter sequences shows great promise. We developed a novel promoter classification method using a Relevance Vector Machine (RVM) and Bayesian statistical principles to identify discriminatory features in the promoter sequences of genes that can correctly classify transcriptional responses. The method was applied to microarray data obtained from Arabidopsis seedlings treated with glucose or abscisic acid (ABA). Of those genes showing > 2.5-fold changes in expression level, -70% were correctly predicted as being up- or down-regulated (under 10-fold cross-validation), based on the presence or absence of a small set of discriminative promoter motifs. Many of these motifs have known regulatory functions in Sugar- and ABA-mediated gene expression. One promoter motif that was not known to be involved in glucose-responsive gene expression was identified as the strongest classifier of glucose-up-regulated gene expression. We show it confers glucose-responsive gene expression in conjunction with another promoter motif, thus validating the classification method. We were able to establish a detailed model of glucose and ABA transcriptional regulatory networks and their interactions, which will help us to understand the mechanisms linking metabolism with growth in Arabidopsis. This study shows that machine learning strategies coupled to Bayesian statistical methods hold significant promise for identifying functionally significant promoter sequences.	John Innes Ctr, Dept Cell & Dev Biol, Norwich NR4 7UH, Norfolk, England; John Innes Ctr, Computat Biol Dept, Norwich NR4 7UH, Norfolk, England; Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England	Bevan, MW (reprint author), John Innes Ctr, Dept Cell & Dev Biol, Norwich NR4 7UH, Norfolk, England.	michael.bevan@bbsrc.ac.uk					Abe H, 1997, PLANT CELL, V9, P1859, DOI 10.1105/tpc.9.10.1859; Abe H, 2003, PLANT CELL, V15, P63, DOI 10.1105/tpc.006130; Ahmad M, 1998, PLANT CELL, V10, P197; Arenas-Huertero F, 2000, GENE DEV, V14, P2085; Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; Bender J, 1998, P NATL ACAD SCI USA, V95, P5655, DOI 10.1073/pnas.95.10.5655; Borevitz JO, 2000, PLANT CELL, V12, P2383, DOI 10.1105/tpc.12.12.2383; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Boyes DC, 2001, PLANT CELL, V13, P1499, DOI 10.1105/tpc.13.7.1499; Buche C, 2000, PLANT CELL, V12, P547, DOI 10.1105/tpc.12.4.547; Busk PK, 1997, PLANT J, V11, P1285, DOI 10.1046/j.1365-313X.1997.11061285.x; Busk PK, 1998, PLANT MOL BIOL, V37, P425, DOI 10.1023/A:1006058700720; Bussemaker HJ, 2001, NAT GENET, V27, P167, DOI 10.1038/84792; Chaboute ME, 2000, PLANT CELL, V12, P1987, DOI 10.1105/tpc.12.10.1987; Chattopadhyay S, 1998, PLANT CELL, V10, P673; Cheng WH, 2002, PLANT CELL, V14, P2723, DOI 10.1105/tpc.006494; deVetten N, 1997, GENE DEV, V11, P1422, DOI 10.1101/gad.11.11.1422; Dieterle M, 2001, GENE DEV, V15, P939, DOI 10.1101/gad.197201; Dubouzet JG, 2003, PLANT J, V33, P751, DOI 10.1046/j.1365-313X.2003.01661.x; Eddy SR, 2004, NAT BIOTECHNOL, V22, P1177, DOI 10.1038/nbt0904-1177; Fankhauser C, 1999, SCIENCE, V284, P1539, DOI 10.1126/science.284.5419.1539; Gangal R, 2005, NUCLEIC ACIDS RES, V33, P1332, DOI 10.1093/nar/gki271; Gilmour SJ, 2000, PLANT PHYSIOL, V124, P1854, DOI 10.1104/pp.124.4.1854; Haas BJ, 2005, BMC BIOL, V3, DOI 10.1186/1741-7007-3-7; Higo K, 1999, NUCLEIC ACIDS RES, V27, P297, DOI 10.1093/nar/27.1.297; Himmelbach A, 2002, EMBO J, V21, P3029, DOI 10.1093/emboj/cdf316; Holding DR, 2002, PLANTA, V214, P373, DOI 10.1007/s00425-001-0686-0; Hubbell E, 2002, BIOINFORMATICS, V18, P1585, DOI 10.1093/bioinformatics/18.12.1585; Huijser C, 2000, PLANT J, V23, P577, DOI 10.1046/j.1365-313x.2000.00822.x; Hwang YS, 1998, PLANT MOL BIOL, V36, P331, DOI 10.1023/A:1005956104636; ISHIGURO S, 1994, MOL GEN GENET, V244, P563; IWASAKI T, 1995, MOL GEN GENET, V247, P391, DOI 10.1007/BF00293139; JAAKKOLA T, 1999, ISMB99; Jang JC, 1997, PLANT CELL, V9, P5, DOI 10.1105/tpc.9.1.5; Jiang CZ, 1997, P NATL ACAD SCI USA, V94, P7441, DOI 10.1073/pnas.94.14.7441; Kanehisa M, 2002, NOVART FDN SYMP, V247, P91; Kim DJ, 1997, GENE, V185, P265, DOI 10.1016/S0378-1119(96)00665-8; Kizis D, 2002, PLANT J, V30, P679, DOI 10.1046/j.1365-313X.2002.01325.x; Kleiner O, 1999, PLANT J, V19, P289, DOI 10.1046/j.1365-313X.1999.00535.x; Laby RJ, 2000, PLANT J, V23, P587, DOI 10.1046/j.1365-313x.2000.00833.x; Lacombe E, 2000, PLANT J, V23, P663, DOI 10.1046/j.1365-313x.2000.00838.x; LAM E, 1995, MOL CELL BIOL, V15, P1014; Lavine BK, 2004, COMB CHEM HIGH T SCR, V7, P115; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Leonhardt N, 2004, PLANT CELL, V16, P596, DOI 10.1105/tpc.019000; Li Y, 2002, BIOINFORMATICS, V18, P1332, DOI 10.1093/bioinformatics/18.10.1332; LIN CT, 1995, SCIENCE, V269, P968, DOI 10.1126/science.7638620; Liu WM, 2002, BIOINFORMATICS, V18, P1593, DOI 10.1093/bioinformatics/18.12.1593; Loppes R, 2001, PLANT MOL BIOL, V45, P215, DOI 10.1023/A:1006401312916; Lu CA, 2002, PLANT CELL, V14, P1963, DOI 10.1105/tpc.001735; Lu CA, 1998, J BIOL CHEM, V273, P10120, DOI 10.1074/jbc.273.17.10120; MACKAY D, 1994, BAYESIAN METHODS BAC; Manevski A, 2000, FEBS LETT, V483, P43, DOI 10.1016/S0014-5793(00)02056-1; MARCOTTE WR, 1989, PLANT CELL, V1, P969, DOI 10.2307/3868997; Moore B, 2003, SCIENCE, V300, P332, DOI 10.1126/science.1080585; Mueller LA, 2003, PLANT PHYSIOL, V132, P453, DOI 10.1104/pp.102.017236; NEAL R, 1994, BAYESIAN LEARNING NE; Price J, 2004, PLANT CELL, V16, P2128, DOI 10.1105/tpc.104.022616; Puente P, 1996, EMBO J, V15, P3732; Quattrocchio F, 1999, PLANT CELL, V11, P1433; Rook F, 2001, PLANT J, V26, P421, DOI 10.1046/j.1365-313X.2001.2641043.x; Schluepmann H, 2003, P NATL ACAD SCI USA, V100, P6849, DOI 10.1073/pnas.1132018100; Scholkopf B, 2004, KERNEL METHODS COMPU; Segal E., 2003, BIOINFORMATICS S1, V19, P273; Shahmuradov IA, 2005, NUCLEIC ACIDS RES, V33, P1069, DOI 10.1093/nar/gki247; Shen QX, 1996, PLANT CELL, V8, P1107, DOI 10.1105/tpc.8.7.1107; Smalle J, 1998, P NATL ACAD SCI USA, V95, P3318, DOI 10.1073/pnas.95.6.3318; Smith AD, 2005, P NATL ACAD SCI USA, V102, P1560, DOI 10.1073/pnas.0406123102; Springer PS, 2000, DEVELOPMENT, V127, P1815; Stracke R, 2001, CURR OPIN PLANT BIOL, V4, P447, DOI 10.1016/S1369-5266(00)00199-0; Tatematsu K, 2005, PLANT PHYSIOL, V138, P757, DOI 10.1104/pp.104.057984; Tavazoie S, 1999, NAT GENET, V22, P281; Thimm O, 2004, PLANT J, V37, P914, DOI 10.1111/j.1365-313X.2004.02016.x; Thum KE, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-2-r10; Tipping ME, 2000, ADV NEUR IN, V12, P652; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Toyofuku K, 1998, FEBS LETT, V428, P275, DOI 10.1016/S0014-5793(98)00518-3; Tremousaygue D, 1999, PLANT J, V20, P553, DOI 10.1046/j.1365-313X.1999.00627.x; Tremousaygue D, 2003, PLANT J, V33, P957, DOI 10.1046/j.1365-313X.2003.01682.x; Uimari A, 1997, PLANT J, V12, P1273, DOI 10.1046/j.1365-313x.1997.12061273.x; Vinayagam A, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-116; Yamamoto Y, 2003, PLANT CELL PHYSIOL, V44, P1119, DOI 10.1093/pcp/pcg148; Yanagisawa S, 2003, NATURE, V425, P521, DOI 10.1038/nature01984; Yoshida S, 2002, PLANT J, V29, P427, DOI 10.1046/j.0960-7412.2001.01228.x; Yu HY, 2003, TRENDS GENET, V19, P422, DOI 10.1016/S0168-9525(03)00175-6; Yubero-Serrano EM, 2003, J EXP BOT, V54, P1865, DOI 10.1093/jxb/erg211; Zhang Wen, 2004, J Biol, V3, P21, DOI 10.1186/jbiol16; Zhou L, 1998, P NATL ACAD SCI USA, V95, P10294, DOI 10.1073/pnas.95.17.10294	88	103	107	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1088-9051		GENOME RES	Genome Res.	MAR	2006	16	3					414	427		10.1101/gr.4237406		14	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	018CZ	WOS:000235742700015	
J	Sokolova, M; Shah, M; Szpakowicz, S				Sokolova, M; Shah, M; Szpakowicz, S			Comparative analysis of text data in successful face-to-face and electronic negotiations	GROUP DECISION AND NEGOTIATION			English	Article; Proceedings Paper	Workshop on Formal and Informal Information Exchange in Negotiations	MAY 26-27, 2005	Ottawa, CANADA		Univ of Ottawa	electronic negotiations; face-to-face negotiations; communication process; text data; corpus analysis		Various combination of Natural Language Processing and Machine Learning methods offer ample opportunities wherever texts are an important element of an application or a research area. Such methods discover patterns and regularities in the data, seek generalization and in effect learn new knowledge. We have employed such methods in learning from a large amount of textual data. Our application is electronic negotiations. The genre of texts found in electronic negotiations may seem limited. It is an important research question whether our methods and findings apply equally well to texts that come from face-to-face negotiations. In order to confirm such more general applicability, we have analyzed comparable collections of texts from electronic and face-to-face negotiations. We present our findings on the extent of similarity between these two related but distinct genres. In this study we have analyzed similarities in the text data of electronic and face-to-face negotiations. The results show that - in certain conditions - vocabulary richness, language complexity and text predictability are similar.	Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada	Sokolova, M (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.	sokolova@site.uottawa.ca; mshah@site.uottawa.ca; szpak@site.uottawa.ca					Allen D.E., 1974, CONVERSATION ANAL SO; Brett J. M., 2001, NEGOTIATING GLOBALLY; CELLICH C, 2004, GLOBAL BUSINESS NEGO; Chen S., 1996, P 34 ANN M ASS COMP, P310, DOI 10.3115/981863.981904; Chu-Carroll J, 2000, INT J HUM-COMPUT ST, V53, P969, DOI [10.1006/ijhc.2000.0427, 10.1006/ijhc.2000.1427]; FRANCIS WN, 1979, BROWN CROPUS MANUAL; Hargie O., 2004, SKILLED INTERPERSONA; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; Kersten G, 2003, CENTRAL EUROPEAN J O, V11, P297; KERSTEN GE, 2003, P 36 HAW INT C SYST; Kilgarriff A., 2001, INT J CORPUS LINGUIS, V6, P97, DOI 10.1075/ijcl.6.1.05kil; Oakes M., 1998, STAT CORPUS LINGUIST; Paul DB, 1992, P WORKSH SPEECH NAT, P357, DOI 10.3115/1075527.1075614; Rojot J., 1991, NEGOTIATION THEORY P; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; SCHOOP M, 2003, P LAP 2003, P143; Sebastiani F., 2002, ACM COMPUT SURV, P1; SHAH M, 2004, P 3 INT C NAT LANG P, P99; Sichel H. S., 1986, MATH SCI, V11, P45; SOKOLOVA M, 2005, ISSUES INTELLIGENT S, P197; SOKOLOVA M, 2005, P REC ADV NAT LANG P, P518; Strobel M., 2000, Proceedings of the 8th European Conference on Information Systems; Thomas GH, 2004, BMC EVOL BIOL, V4, DOI 10.1186/1471-2148-4-28; Thompson L, 2002, J SOC ISSUES, V58, P109, DOI 10.1111/1540-4560.00251; Tweedie FJ, 1998, COMPUT HUMANITIES, V32, P323, DOI 10.1023/A:1001749303137	25	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0926-2644		GROUP DECIS NEGOT	Group Decis. Negot.	MAR	2006	15	2					127	140		10.1007/s10726-006-9024-z		14	Management; Social Sciences, Interdisciplinary	Business & Economics; Social Sciences - Other Topics	049NG	WOS:000238022700003	
J	Nastase, V				Nastase, V			Concession curve analysis for inspire negotiations	GROUP DECISION AND NEGOTIATION			English	Article; Proceedings Paper	Workshop on Formal and Informal Information Exchange in Negotiations	MAY 26-27, 2005	Ottawa, CANADA		Univ of Ottawa		SUPPORT	In the course of a negotiation it is often the case that the participants exchange packages of offers, which have, at least in the mind of the negotiators, a certain utility for them. We want to test whether the behaviour of the negotiators is reflected in the topology of the concession curve that plots each offer's utility value in the course of a negotiation. In order to do this, we use data collected with the Inspire electronic negotiation support system, which records utility preference values for all issues under discussion, for each negotiator. We abstract the concession curves using a set of features, such as number of minima and maxima, slope of curve at the beginning and end, and then we use machine learning techniques to test whether we can predict negotiation outcome based on these concessions curve descriptions. We find that there are certain features of this curve, such as the number of minima and maxima, frequency of offers exchanged, that predict with high precision and recall the outcome of negotiations conducted with Inspire.	Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada	Nastase, V (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.	vnastase@site.uottawa.ca					BEROGGI GE, 2000, J MUTLICRITERIA DECI, V1, P76; BORCHERDING K, 1991, MANAGE SCI, V37, P1603, DOI 10.1287/mnsc.37.12.1603; Fischer GW, 1999, MANAGE SCI, V45, P1057, DOI 10.1287/mnsc.45.8.1057; KERSTEN G, 2003, CENTRAL EUROPEAN J O, V3, P297; Kersten GE, 1999, DECIS SUPPORT SYST, V25, P135, DOI 10.1016/S0167-9236(99)00012-3; KIMBROUGH S, 1994, EUR J OPER RES, P617; Schoop M, 2003, DATA KNOWL ENG, V47, P371, DOI 10.1016/S0169-023X(03)00065-X; SHAH M, 2004, ICON 2004; SOKOLOVA M, 2005, ADV AI 18 CAN AI 200, V3, P145; VETSCHERA R, 2004, PREFERENCE STRUCTURE; Zanakis SH, 1998, EUR J OPER RES, V107, P507, DOI 10.1016/S0377-2217(97)00147-1	11	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0926-2644		GROUP DECIS NEGOT	Group Decis. Negot.	MAR	2006	15	2					185	193		10.1007/s10726-006-9028-8		9	Management; Social Sciences, Interdisciplinary	Business & Economics; Social Sciences - Other Topics	049NG	WOS:000238022700007	
J	Nakamura, S; Markov, K; Nakaiwa, H; Kikui, G; Kawai, H; Jitsuhiro, T; Zhang, JS; Yamamoto, H; Sumita, E; Yamamoto, S				Nakamura, S; Markov, K; Nakaiwa, H; Kikui, G; Kawai, H; Jitsuhiro, T; Zhang, JS; Yamamoto, H; Sumita, E; Yamamoto, S			The ATR multilingual speech-to-speech translation system	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						example-based machine translation (EBMT); minimum description length (MDL); multiclass language model; speech-to-speech translation (S2S); statistical machine translation (SMT); successive state splitting (SSS); text-to-speech (TTS) conversion		In this paper, we describe the ATR multilingual speech-to-speech translation (S2ST) system, which is mainly focused on translation between English and Asian languages (Japanese and Chinese). There are three main modules of our S2ST system: large-vocabulary continuous speech recognition, machine text-to-text (T2T) translation, and text-to-speech synthesis. All of them are multilingual and are designed using state-of-the-art technologies developed at ATR. A corpus-based statistical machine learning framework forms the basis of our system design. We use a parallel multilingual database consisting of over 600 000 sentences that cover a broad range of travel-related conversations. Recent evaluation of the overall system showed that speech-to-speech translation quality is high, being at the level of a person having a Test of English for International Communication (TOEIC) score of 750 out of the perfect score of 990.	ATR Spoken Language Translat Res Labs, Kyoto 6190288, Japan	Nakamura, S (reprint author), ATR Spoken Language Translat Res Labs, Kyoto 6190288, Japan.	satoshi.nakamura@atr.jp; konstantin.markov@atr.jp; hiromi.nakaiwa@atr.jp; genichiro.kikui@atr.jp; hisashi.kawai@atr.jp; takatoshi.jitsuhiro@atr.jp; jinsong.zhang@atr.jp; hirofumi.yamamoto@atr.jp; eiichiro.sumita@atr.jp; seiichi.yamamoto@atr.jp					AKIBA Y, 2002, P COL, P8; Alshawi H, 2000, COMPUT LINGUIST, V26, P45, DOI 10.1162/089120100561629; BLACK AW, 1994, P C COMP LING KYOT J, P983; BREEN A, 1998, P 3 ESCA COCOSDA WOR, pG1; BROWN P, 1993, COMPUT LINGUISTICS, V16, P59; Brown P. F., 1992, Computational Linguistics, V18; CALLISONBURCH C, 2001, P MT SUMMIT 8, P63; Campbell N., 1996, P 3 ASA ASJ JOINT M, P1223; COSTANTINI E, 2002, P LREC, P165; Donovan R., 1996, THESIS CAMBRIDGE U C; Hirokawa T., 1990, P ICSLP90, P337; HOGAN C, 1998, P AMTA, P113; Imamura K., 2002, Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-2002); IMAMURA K, 2003, P 41 ANN M ASS COMP, P447; IWAHASHI N, 1993, IEICE T FUND ELECTR, VE76A, P1942; Jitsuhiro T., 2003, P EUR, P2721; Kikui G., 2003, P EUR, P381; Knight K, 1997, AI MAG, V18, P81; LAVIE A, P  HLT WORKSH; LEFEVRE F, 2001, P EUR, P1241; Nagao M., 1984, ARTIFICIAL HUMAN INT, P173; NEY H, 2001, P ACL 2001 WORKSH DD, P33; Och F. J., 1999, P JOINT SIGDAT C EMP, P20; Ostendorf M, 1997, COMPUT SPEECH LANG, V11, P17, DOI 10.1006/csla.1996.0021; Paul DB, 1992, P WORKSH SPEECH NAT, P357, DOI 10.3115/1075527.1075614; Sagisaka Y., 1992, P ICSLP, P483; SAGISAKA Y, 1988, P INT C AC SPEECH SI, P679; SOMERS H, 1999, J MACHINE TRANSLATIO, P113; SUGAYA F, 2000, P INT C SPOK LANG PR, P1105; SUMITA E, 2001, P ACL 2001 WORKSH DA, P1; SUMITA E, 1999, P MT SUMM, P229; Takami J., 1992, P INT C AC SPEECH SI, P573; Takezawa T., 2002, P LREC, P147; TAKEZAWA T, 1998, P 1 INT WORKSH E AS, P148; Taylor Paul, 1998, P 3 ESCA WORKSH SPEE, P147; TODA T, 2004, P IEEE INT C SPEECH, V1, P657; Tokuda K., 2000, P ICASSP, P1315; Venugopal A., 2003, P 41 ANN M ASS COMP, P319; WAHLSTER W, 2000, VERMOBIL FDN SPEECH; WANG YY, 1998, P 5 INT C SPOK LANG, P2775; Ward H.J, 1963, J AM STAT ASSOC, V58, P236; WATANABE T, 2003, P MT SUMM 9, P410; WATANABE T, 2003, P 41 ANN M ASS COMP, P303; Watanabe T., 2002, Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-2002); Yamamoto H, 2003, SPEECH COMMUN, V41, P369, DOI 10.1016/S0167-6393(02)00179-6; Young S., 1994, P ARPA HUM LANG TECH, P307, DOI 10.3115/1075812.1075885; Zhang JS, 2003, IEICE T INF SYST, VE86D, P489; ZHANG JS, 2001, P EUR, V3, P1661; ZHANG JS, 2003, P ASJ M FALL, P167; 1994, P SPOK LANG TECHN WO	50	24	24	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1558-7916		IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	MAR	2006	14	2					365	376		10.1109/TSA.2005.860774		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	016IX	WOS:000235615000001	
J	Ye, SR; Chua, TS				Ye, SR; Chua, TS			Learning object models from semistructured Web documents	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Web mining; machine learning; intelligent web services and Semantic Web; web text analysis; knowledge acquisition; ontology design; computational geometry and object modeling; DOM	KNOWLEDGE; INDUCTION	This paper presents an automated approach to learning object models by means of useful object data extracted from data-intensive semistructured web documents such as product descriptions. Modeling intensive data on the Web involves the following three phrases: First, we identify the object region covering the descriptions of object data when irrelevant contents from the web documents are excluded. Second, we partition the contents of different object data appearing in the object region and construct object data using hierarchical XML outputs. Third, we induce the abstract object model from the analogous object data. This model will match the corresponding object data from a Web site more precisely and comprehensively than the existing handcrafted ontologies. The main contribution of this study is in developing a fully automated approach to extract object data and object model from semistructured web documents using kernel-based matching and View Syntax interpretation. Our system, OnModer, can automatically construct object data and induce object models from complicated web documents, such as the technical descriptions of personal computers and digital cameras downloaded from manufacturers' and vendors' sites. A comparison with the available hand-crafted ontologies and tests on an open corpus demonstrate that our framework is effective in extracting meaningful and comprehensive models.	Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore	Ye, SR (reprint author), Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore.	yesr@comp.nus.edu.sg; chuats@comp.nus.edu.sg					Arasu A., 2003, P 2003 ACM SIGMOD IN, P337; Bar-Yossef Z., 2002, P 11 INT C WORLD WID, P580; Buttler D., 2001, Proceedings 21st International Conference on Distributed Computing Systems, DOI 10.1109/ICDSC.2001.918966; BUTTLER D, 2001, P ACM SIGMOD, P604, DOI 10.1145/375663.375762; Cole R, 2001, LECT NOTES ARTIF INT, V2120, P319; DAVULCU H, 2003, P INT WORKSH SEM WEB, P259; DOAN A, 2000, P 3 INT WORKSH WEB D, P81; Embley D. W., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288641; ESPOSITO F, 2000, P LEARN LANG LOG WOR, P194; Etzioni O, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P391; GARTNER T, 2003, NEWSLETTER ACM SIGKD, V5, P49; Gupta Suhit, 2003, P 12 INT C WORLD WID, P207; Hahn U., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; KIETZ JU, 1994, MACH LEARN, V14, P193, DOI 10.1023/A:1022626200450; Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9; LERMAN K, 2001, P IJCAI WORKSH AD TE; Lin Shian-Hua, 2002, P 8 ACM SIGKDD INT C, P588; LIU B, 2003, P 9 ACM SIGKDD INT C, P49; Maedche A, 2001, IEEE INTELL SYST APP, V16, P72, DOI 10.1109/5254.920602; Maedche A., 2000, P INT C SOFTW ENG KN; Maedche A., 2002, ONTOLOGY LEARNING SE; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; SCHLOBACH S, 2000, P INT WORKSH DESCR L, P237; SHIMADA K, 2003, IEICE INFORM SYSTEMS, P1386; Soderland S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Song R., 2004, P 13 INT C WORLD WID, P203, DOI 10.1145/988672.988700; Studer R, 1998, DATA KNOWL ENG, V25, P161, DOI 10.1016/S0169-023X(97)00056-6; Thelen M., 2002, P C EMP METH NAT LAN; TODIRASCU A, 2000, P WORKSH ONT LEARN E, P31; Uschold M, 1998, KNOWL ENG REV, V13, P5, DOI 10.1017/S0269888998001040; VOLZ R, 2004, WEB SEMANTICS SCI SE, P187; Webb GI, 1999, MACH LEARN, V35, P5, DOI 10.1023/A:1007504102006; YE S, 2004, P INT C WEB INT, P669; YE S, 2004, P WORKSH SEM WEB SIG, P69; Yi L., 2003, P 9 ACM SIGKDD INT C, P296	35	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2006	18	3					334	349		10.1109/TKDE.2006.47		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	003IS	WOS:000234675800004	
J	He, JY; Hu, HJ; Harrison, R; Tai, PC; Pan, Y				He, JY; Hu, HJ; Harrison, R; Tai, PC; Pan, Y			Rule generation for protein secondary structure prediction with support vector machines and decision tree	IEEE TRANSACTIONS ON NANOBIOSCIENCE			English	Article						decision tree; protein structure; rule extraction; support vector machine (SVM)	ACCURACY; C4.5	Support vector machines (SVMs) have shown strong generalization ability in a number of application areas, including protein structure prediction. However, the poor comprehensibility hinders the success of the SVM for protein structure prediction. The explanation of how a decision made is important for accepting the machine learning technology, especially for applications such as bioinformatics. The reasonable interpretation is not only useful to guide the "wet experiments," but also the extracted rules are helpful to integrate computational intelligence with symbolic AI systems for advanced deduction. On the other hand, a decision tree has good comprehensibility. In this paper, a novel approach to rule generation for protein secondary structure prediction by integrating merits of both the SVM and decision tree is presented. This approach combines the SVM with decision tree into a new algorithm called SVM_DT, which proceeds in three steps. This algorithm first trains an SVM. Then, a new training set is generated through careful selection from the output of the SVM. Finally, the obtained training set is used to train a decision tree learning system and to extract the corresponding rule sets. The results of the experiments of protein secondary structure prediction on RS126 data set show that the comprehensibility of SVM_DT is much better than that of the SVM. Moreover, the generalization ability of SVM_DT is better than that of C4.5 decision trees and is similar to that of the SVM. Hence, SVM_DT can be used not only for prediction, but also for guiding biological experiments.	SE Univ, Dept Comp Sci & Engn, Nanjing 210096, Peoples R China; Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA; Georgia State Univ, Dept Biol, Atlanta, GA 30303 USA	Pan, Y (reprint author), SE Univ, Dept Comp Sci & Engn, Nanjing 210096, Peoples R China.	jieyuehe@seu.edu.cn; jpark1808@earthlink.net; rharrison@cs.gsu.edu; biopct@langate.gsu.edu; pan@cs.gsu.edu	jia, lp/H-5750-2011				Barakat N., 2004, 14 INT C COMP THEOR, V2004; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CASBON J, 2002, THESIS U SUSSEX BRIG; CHANG KC, 1993, INT J MATH, V4, P35, DOI 10.1142/S0129167X93000042; Cortes C., 1995, MACH LEARN, V20, P237; Cristianini N., 2000, INTRO SUPPORT VECTOR; He JY, 2006, EXPERT SYST APPL, V30, P64, DOI 10.1016/j.eswa.2005.09.045; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Hu HJ, 2004, IEEE T NANOBIOSCI, V3, P265, DOI 10.1109/TNB.2004.837906; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; KIM H, 2003, PROTIEN SECONDARY ST; Kretschmann E, 2001, BIOINFORMATICS, V17, P920, DOI 10.1093/bioinformatics/17.10.920; Krishnan VG, 2003, BIOINFORMATICS, V19, P2199, DOI 10.1093/bioinformatics/btg297; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Mitchell M., 1997, MACHINE LEARNING; MITSDORFFER R, 9 INT C NEUR INF PRO; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; SCHOLKOPF B, 2004, KERNEL METHODS COMPU, P71; Sikder Abdur Rahman, 2005, Int J Bioinform Res Appl, V1, P121; Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352; Vapnik VN, 1998, STAT LEARNING THEORY; Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477	24	20	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1536-1241		IEEE T NANOBIOSCI	IEEE Trans. Nanobiosci.	MAR	2006	5	1					46	53		10.1109/TNB.2005.864021		8	Biochemical Research Methods; Nanoscience & Nanotechnology	Biochemistry & Molecular Biology; Science & Technology - Other Topics	020GY	WOS:000235897900007	
J	Elizondo, D				Elizondo, D			The linear separability problem: Some testing methods	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						class of separability; computational geometry; convex hull; Fisher linear discriminant; linear programming; linear separability; quadratic programming; simplex; support vector machine	SVM	The notion of linear separability is used widely in machine learning research. Learning algorithms that use this concept to learn include neural networks (single layer perceptron and recursive deterministic perceptron), and kernel machines (support vector machines). This paper presents an overview of several of the methods for testing linear separability between two classes. The methods are divided into four groups: Those based on linear programming, those based on computational geometry, one based on neural networks, and one based on quadratic programming. The Fisher linear discriminant method is also presented. A section on the quantification of the complexity of classification problems is included.	De Montfort Univ, Sch Comp, Ctr Computat Intelligence, Leicester LE1 9BH, Leics, England	Elizondo, D (reprint author), De Montfort Univ, Sch Comp, Ctr Computat Intelligence, Gateway, Leicester LE1 9BH, Leics, England.	elizondo@dmu.ac.uk	Elizondo, David/A-5048-2009				ATIYA A, 2005, IEEE T NEURAL NETWOR, V16, P780; Avis D., 1995, Proceedings of the Eleventh Annual Symposium on Computational Geometry, DOI 10.1145/220279.220282; Bazaraa M.S., 1977, LINEAR PROGRAMMING N; Blair M, 2001, MEM COGNITION, V29, P1153, DOI 10.3758/BF03206385; Blum A, 2002, SIAM PROC S, P905; CHAZELLE RPB, 1996, DEFORMED PRODUCTS MA; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2003, INTRO SUPPORT VECTOR, VI; Dong M, 2001, IEEE T FUZZY SYST, V9, P461; ELIZONDO D, 1997, THESIS U LOUIS PASTE; ELIZONDO D, 2004, P IEEE 2004 INT JOIN, V2, P955; Ferreira LV, 2005, IEEE T NEURAL NETWOR, V16, P501, DOI 10.1109/TNN.2005.844091; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOURIER J, 1824, MEMOIRE ACAD ROYALE, V7; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; HSU CW, 2003, 106 NAT TAIW U; Johnson D. S., 1978, Theoretical Computer Science, V6, DOI 10.1016/0304-3975(78)90006-3; Kuhn H.W., 1956, AM MATH MONTHLY, V63, P217, DOI 10.2307/2310345; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Pang SN, 2005, IEEE T NEURAL NETWOR, V16, P436, DOI 10.1109/TNN.2004.841776; Platt J., 1998, ADV KERNEL METHODS S; Preparata F., 1985, COMPUTATIONAL GEOMET; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; SAKAROVITCH M, 1984, OPTIMIZATION COMBINA; SEDGEWICK R, 1983, ALGORITHMS, V38, P508; Stoer J, 1970, CONVEXITY OPTIMIZATI; Tajine M., 2002, NEUROCOMPUTING, V47, P295; TAJINE M, 1996, 9607 U LOUIS PASTEUR; TARSKI A, 1954, DECISION METHOD ELEM; 1992, TRANING ALGORITHM OP; 1983, SOLVING GEOMETRIC PR	31	17	20	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAR	2006	17	2					330	344		10.1109/TNN.2005.860871		15	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	026SD	WOS:000236361500005	
J	Law, MHC; Jain, AK				Law, MHC; Jain, AK			Incremental nonlinear dimensionality reduction by manifold learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						incremental learning; dimensionality reduction; ISOMAP; manifold learning; unsupervised learning	PRINCIPAL COMPONENT ANALYSIS; NEURAL NETWORKS; CURVES; IMAGES	Understanding the structure of multidimensional patterns, especially in unsupervised cases, is of fundamental importance in data mining, pattern recognition, and machine learning. Several algorithms have been proposed to analyze the structure of high-dimensional data based on the notion of manifold learning. These algorithms have been used to extract the intrinsic characteristics of different types of high-dimensional data by performing nonlinear dimensionality reduction. Most of these algorithms operate in a '' batch '' modeand cannot be efficiently applied when data are collected sequentially. In this paper, we describe an incremental version of ISOMAP, one of the key manifold learning algorithms. Our experiments on synthetic data as well as real world images demonstrate that our modified algorithm can maintain an accurate low-dimensional representation of the data in an efficient manner.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Law, MHC (reprint author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48824 USA.	lawhiu@cse.msu.edu; jain@cse.msu.edu					BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2004, ADV NEURAL INFORM PR, V16; Bernstein M., 2000, GRAPH APPROXIMATIONS; BEYGELZIMER A, 2005, COVER TREES NEAREST; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Brand M., 2003, ADV NEURAL INFORMATI, V15, P961; BRUN A, 2003, P 9 INT C AID SYST T, V2809; Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189; Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212; Chang Y, 2004, PROC CVPR IEEE, P520; Costa J., 2004, P IEEE INT C AC SPEE, V3, P988; Cox T., 2001, MULTIDIMENSIONAL SCA; DeMers D., 1993, ADV NEURAL INFORMATI, P580; Demetrescu C, 2004, J ACM, V51, P968, DOI 10.1145/1039488.1039492; DESILVA V, 2003, ADV NEURAL INFORM PR, V15, P705; Donoho D.L., 2002, 200227 STANF U DEP S; DUDA RO, 2001, PATTERN CLASSIFICAT; Elgamal EA, 2004, CHILD NERV SYST, V20, P489, DOI 10.1007/s00381-003-0891-1; ELGAMMAL A, 2004, P CVPR, V2, P681, DOI 10.1109/CVPR.2004.1315230; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Golub G. H., 1996, MATRIX COMPUTATIONS; Hadid A., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1044625; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Jenkins O., 2004, P 21 INT C MACH LEAR; Kegl B., 2003, ADV NEURAL INFORM PR, V15; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kohonen T, 2001, SELF ORG MAPS; Law MHC, 2004, SIAM PROC S, P33; Levina E., 2005, ADV NEURAL INFORM PR, V17; Li S.Z., 2001, P IEEE ICCV WORKSH R; Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; MARTINEZ A, 1998, 24 U AL BIRM COMP VI; Narvaez P, 2000, IEEE ACM T NETWORK, V8, P734, DOI 10.1109/90.893870; Narvaez P, 2001, IEEE ACM T NETWORK, V9, P706, DOI 10.1109/90.974525; NISKANEN M, 2003, P 6 INT C QUAL CONTR, P178; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25; Roweis S, 2002, ADV NEUR IN, V14, P889; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Simard P. Y., 2003, P INT C DOC AN REC, P958; SJOSTROM E, 1996, THESIS; Smola AJ, 2001, J MACH LEARN RES, V1, P179, DOI 10.1162/15324430152748227; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889678; VERBEEK JJ, 2002, P INT C ART NEUR NET, P914; Weinberger K.Q., 2004, P IEEE C COMP VIS PA, P988, DOI 10.1109/CVPR.2004.1315272; Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034; YANG MH, 2002, P IEEE INT C IM PROC, P117; ZHA HY, 2003, P 20 INT C MACH LEAR; Zhang J., 2004, P 6 INT C AUT FAC GE	53	64	77	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					377	391		10.1109/TPAMI.2006.56		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	001FB	WOS:000234517900004	
J	Yildiz, OT; Alpaydin, E				Yildiz, OT; Alpaydin, E			Ordering and finding the best of K > 2 supervised learning algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						machine learning; classifier design and evaluation; experimental design	CLASSIFICATION	Given a data set and a number of supervised learning algorithms, we would like to find the algorithm with the smallest expected error. Existing pairwise tests allow a comparison of two algorithms only; range tests and ANOVA check whether multiple algorithms have the same expected error and cannot be used for finding the smallest. We propose a methodology, the MultiTest algorithm, whereby we order supervised learning algorithms taking into account 1) the result of pairwise statistical tests on expected error (what the data tells us), and 2) our prior preferences, e. g., due to complexity. We define the problem in graph-theoretic terms and propose an algorithm to find the '' best '' learning algorithm in terms of these two criteria, or in the more general case, order learning algorithms in terms of their '' goodness.'' Simulation results using five classification algorithms on 30 data sets indicate the utility of the method. Our proposed method can be generalized to regression and other loss functions by using a suitable pairwise test.	Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey	Yildiz, OT (reprint author), Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.	yildizol@cmpe.boun.edu.tr; alpaydin@boun.edu.tr	YILDIZ, OLCAY/K-3869-2012; ALPAYDIN, ETHEM/E-6127-2013				Alpaydin E., 1999, NEURAL COMPUT, V11, P1975; Alpaydin E, 2004, INTRO MACHINE LEARNI; Alsing SG, 2002, PATTERN RECOGN, V35, P2397, DOI 10.1016/S0031-3203(01)00192-3; Blake C, 2000, UCI REPOSITORY MACHI; BOUCKAERT RR, 2003, P 20 INT C MACH LEAR; Conover W. J., 1999, PRACTICAL NONPARAMET; Dean AM, 1999, DESIGN ANAL EXPT; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; EFRON B, 1979, SIAM REV, V21, P460, DOI 10.1137/1021092; EVERITT B. S., 1977, ANAL CONTINGENCY TAB; Hastie T, 2001, ELEMENTS STAT LEARNI; Hochberg Y., 1987, MULTIPLE COMPARISON; HOLM S, 1979, SCAND J STAT, V6, P65; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; LOONEY SW, 1988, PATTERN RECOGN LETT, V8, P5, DOI 10.1016/0167-8655(88)90016-5; MILLER RG, 1981, SIMULTANEOUS STAT IN; Provost F., 1998, P 15 INT C MACH LEAR; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; ROSEN KH, 1995, MATH ITS APPL; Ross S.M., 1987, INTRO PROBABILITY ST; Turney P., 2000, P WORKSH COST SENS L, P15; YILDIZ OT, 2005, THESIS BOGAZICI U	23	8	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					392	402		10.1109/TPAMI.2006.61		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	001FB	WOS:000234517900005	
J	Bredeche, N; Shi, ZZ; Zucker, JD				Bredeche, N; Shi, ZZ; Zucker, JD			Perceptual learning and abstraction in machine learning: An application to autonomous robotics	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article; Proceedings Paper	2nd IEEE International Conference on Cognitive Informatics	AUG 18-20, 2003	LONDON, ENGLAND	S Bank Univ London		abstraction; feature selection; machine learning; perceptual learning; real-world data		This paper deals with the possible benefits of perceptual learning in artificial intelligence. On the one hand, perceptual learning is more and more studied in neurobiology and is now considered as an essential part of any living system. In fact, perceptual learning and cognitive learning are both necessary for learning and often depend on each other. On the other hand, many works in machine learning are concerned with "abstraction" in order to reduce the amount of complexity related to some learning tasks. In the abstraction framework, perceptual learning can be seen as a specific process that learns how to transform the data before the traditional learning task itself takes place. In this paper, we argue that biologically inspired perceptual learning mechanisms could be used to build efficient low-level abstraction operators that deal with real-world data. To illustrate this, we present an application where perceptual-learning-inspired metaoperators are used to perform an abstraction on an autonomous robot visual perception. The goal of this work is to enable the robot to learn how to identify objects it encounters in its-environment.	Univ Paris 11, Rech Informat Lab, F-91405 Orsay, France; Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China; Univ Paris 13, Lab Informat Med & Bioinformat, F-91017 Bobigny, France	Bredeche, N (reprint author), Univ Paris 11, Rech Informat Lab, Bat 490, F-91405 Orsay, France.	nicolas.bredeche@lri.fr; shizz@ics.ict.ac.cn; zucker@free.fr					Amarel S., 1968, MACH INTELL, V3, P131; Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.201; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Bredeche N, 2003, ROBOT AUTON SYST, V43, P149, DOI 10.1016/S0921-8890(02)00356-1; BRUCE V, 2002, PERCEPTUAL LEARNING; CHEVALEYRE Y, 2001, EUR C MACH LEARN; CORADESCHI S, 1999, LINKOPING ELECT ART, V4; EDELMAN S, 2002, PERCEPTUAL LEARNING; Fahle M, 2002, PERCEPTUAL LEARNING; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; Gent IP, 1996, ARTIF INTELL, V88, P349, DOI 10.1016/S0004-3702(96)00030-6; Gent I.P., 1995, P 8 INT S ART INT, P356; GIBSON EJ, 1963, ANNU REV PSYCHOL, V14, P29, DOI 10.1146/annurev.ps.14.020163.000333; GIORDANA A, 1990, WORKSH AUT GEN APPR, P245; Giordana A, 2000, MACH LEARN, V41, P217, DOI 10.1023/A:1007620705405; GIUNCHIGLIA F, 1996, ARTIF INTELL, V13, P201; Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585; Harnad S., 1990, PHYSICA D, V42, P335, DOI DOI 10.1016/0167-2789(90)90087-6; HERZOG M, 2002, PERCEPTUAL LEARNING; HUGUES L, 2002, 15 EUR C ART INT ECA; John G.H., 1994, P 11 INT C MACH LEAR, P121; KOHAVI R, 1995, INT C KNOWL DISC DAT; Kohavi R., 1998, FEATURE SELECTION KN, P33; Marr D., 1982, VISION; NAYAK PP, 1995, P 14 INT JOINT C ART, P196; SACERDOT.ED, 1974, ARTIF INTELL, V5, P115, DOI 10.1016/0004-3702(74)90026-5; SAITTA L, 1998, S ABSTR REF APPR SAR; UTGOFF P, 1986, MACHINE LEARNING ART, V2; WALLIS G, 2002, PERCEPTUAL LEARNING; WEISS Y, 1993, NEURAL COMPUT, V5, P695, DOI 10.1162/neco.1993.5.5.695; WNEK J, 1994, MACH LEARN, V14, P139, DOI 10.1023/A:1022622132310; ZENGER B, 2002, PERCEPTUAL LEARNING; ZUCKER JD, 1996, INT C MACH LEARN; ZUCKER JD, 2001, CHANGEMENTS REPRESEN; Saitta L, 2001, APPL ARTIF INTELL, V15, P761, DOI 10.1080/088395101317018591	35	1	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	MAR	2006	36	2					172	181		10.1109/TSMCC.2006.871139		10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	038DB	WOS:000237197600007	
J	Ma, JY; Cole, R; Pellom, B; Ward, W; Wise, B				Ma, JY; Cole, R; Pellom, B; Ward, W; Wise, B			Accurate visible speech synthesis based on concatenating variable length motion capture data	IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS			English	Article						face animation; character animation; visual speech; visible speech; coarticulation effect; virtual human		We present a novel approach to synthesizing accurate visible speech based on searching and concatenating optimal variable- length units in a large corpus of motion capture data. Based on a set of visual prototypes selected on a source face and a corresponding set designated for a target face, we propose a machine learning technique to automatically map the facial motions observed on the source face to the target face. In order to model the long distance coarticulation effects in visible speech, a large- scale corpus that covers the most common syllables in English was collected, annotated and analyzed. For any input text, a search algorithm to locate the optimal sequences of concatenated units for synthesis is desrcribed. A new algorithm to adapt lip motions from a generic 3D face model to a specific 3D face model is also proposed. A complete, end- to- end visible speech animation system is implemented based on the approach. This system is currently used in more than 60 kindergarten through third grade classrooms to teach students to read using a lifelike conversational animated agent. To evaluate the quality of the visible speech produced by the animation system, both subjective evaluation and objective evaluation are conducted. The evaluation results show that the proposed approach is accurate and powerful for visible speech synthesis.	Univ Colorado, Ctr Spoken Language Res, Boulder, CO 80309 USA	Ma, JY (reprint author), Univ Colorado, Ctr Spoken Language Res, Campus Box 594, Boulder, CO 80309 USA.	jiyong@cslr.colorado.edu; cole@cslr.colorado.edu					Beskow J., 1995, P 4 EUR C SPEECH COM, P299; Bregler C., 1997, P ACM SIGGRAPH, P353, DOI 10.1145/258734.258880; CAO Y, 2004, P ACM SIGGRAPH EUR S; Choi SW, 2003, CHEMOMETR INTELL LAB, V65, P191, DOI 10.1016/S0169-7439(02)00109-0; CHUANG ES, 2002, CSTR200202 STANF U; Cohen M. M., 1993, P COMP AN, P139; COLE R, 1999, P ESCA SOCRRATES; Cole R, 2003, P IEEE, V91, P1391, DOI 10.1109/JPROC.2003.817143; Cosatto E, 2000, P INT C MATH ED, V2, P619; Cosi P., 2002, Proceedings Fourth IEEE International Conference on Multimodal Interfaces, DOI 10.1109/ICMI.2002.1167047; Ezzat T., 2002, P ACM SIGGRAPH 2002, P388, DOI 10.1145/566570.566594; Feng G, 1998, IEEE T SIGNAL PROCES, V46, P2790; GEIGER G, 2003, 224AI CBCL; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1145/280814.280822; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Huang X., 2001, SPOKEN LANGUAGE PROC; Hunt A., 1996, P INT C AC SPEECH SI, V1, P373; Jiang JT, 2002, EURASIP J APPL SIG P, V2002, P1174, DOI 10.1155/S1110865702206046; Joshi P., 2003, P 2003 ACM SIGGRAPH, P187; Kent R., 1977, J PHONETICS, V5, P115; Kouadio C., 1998, Proceedings Computer Animation '98 (Cat. No.98EX169), DOI 10.1109/CA.1998.681917; KSHIRSAGAR S, 2002, P COMP GRAPH INT C, P38; LEE M, 2001, P ISCA RES WORKSH SP, P347; Ma J., 2002, P INT C SPOK LANG PR, P197; MA J, 2004, J COMPUTER ANIMATION, V15, P485; Ma JY, 2004, VISUAL COMPUT, V20, P86, DOI 10.1007/s00371-003-0234-y; Magnenat-Thalmann N., 1988, Visual Computer, V3, DOI 10.1007/BF01914864; Noh J., 2001, P ACM SIGGRAPH, P277, DOI DOI 10.1145/383259.383290; Pandzic I.S., 2002, MPEG 4 FACIAL ANIMAT; Parent R, 2002, COMP ANIM CONF PROC, P3; Parke F. I., 1972, P ACM NAT C, P451; PATTERSON EC, 1991, P COMPUTER ANIMATION; PELACHAUD C, 1991, P COMP AN 1 JUN 1991, P15; PELLOM N, 2003, P INT C AC SPEECH SI, V1, P4; Pighin F, 2002, INT J COMPUT VISION, V50, P143, DOI 10.1023/A:1020393915769; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; REVERET L, 1998, P 2 ESCA WORKSH AUD; Roweis S, 1998, ADV NEUR IN, V10, P626; SANCHEZ M, 2003, P VIS VID GRAPH C, P1; Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; Williams L., 1990, Computer Graphics, V24; WISE B, 2005, INTERACTIVE LIT ED	43	11	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1077-2626		IEEE T VIS COMPUT GR	IEEE Trans. Vis. Comput. Graph.	MAR-APR	2006	12	2					266	276		10.1109/TVCG.2006.18		11	Computer Science, Software Engineering	Computer Science	999ZH	WOS:000234430200014	
J	Shahjahan, M; Murase, K				Shahjahan, M; Murase, K			A pruning algorithm for training cooperative neural network ensembles	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						neural network; ensemble; ensemble design; correlation learning; pruning; node decay; over-fitting; generalization	GENETIC ALGORITHMS; CLASSIFIERS; CONSTRUCTION; FUSION	We present a training algorithm to create a neural network (NN) ensemble that performs classification tasks. It employs a competitive decay of hidden nodes in the component NNs as well as a selective deletion of NNs in ensemble, thus named a pruning algorithm for NN ensembles (PNNE). A node cooperation function of hidden nodes in each NN is introduced in order to support the decaying process. The training is based on the negative correlation learning that ensures diversity among the component NNs in ensemble. The less important networks are deleted by a criterion that indicates over-fitting. The PNNE has been tested extensively on a number of standard benchmark problem,; in machine learning, including the Australian credit card assessment, breast cancer, cirlce-in-the-square. diabetes, glass identification, ionosphere, iris identification, and soybean identification problems. The results show that classification performances of NN ensemble produced by the PNNE are better than or competitive to those by the conventional constructive and fixed architecture algorithms. Furthermore, in comparison to the constructive algorithm, NN ensemble produced by the PNNE consists of a smaller number of component NNs, and they are more diverse owing to the uniform training for all component NNs.	Univ Fukui, Dept Human & Artificial Intelligence Syst, Fukui 9108507, Japan	Shahjahan, M (reprint author), Univ Fukui, Dept Human & Artificial Intelligence Syst, Fukui 9108507, Japan.	murase@synapse.his.fukui-u.ac.jp					Benediktsson JA, 1997, NONLINEAR ANAL-THEOR, V30, P1323, DOI 10.1016/S0362-546X(97)00222-8; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Cherkauer K., 1996, P 13 AAAI WORKSH INT, P15; DRUCKER H, 1994, NEURAL COMPUT, V6, P1289, DOI 10.1162/neco.1994.6.6.1289; Gader PD, 1996, PATTERN RECOGN LETT, V17, P577, DOI 10.1016/0167-8655(96)00021-9; Hagiwara M., 1993, P INT JOINT C NEUR N, V1, P351, DOI 10.1109/IJCNN.1993.713929; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; SETIONO R, 1995, IEEE T NEURAL NETWOR, V6, P273, DOI 10.1109/72.363426; INOUE H, 2004, J SYSTEMICS CYBERNET, V1, P72; Islam M, 2003, IEEE T NEURAL NETWOR, V14, P820, DOI 10.1109/TNN.2003.813832; JACOBS RA, 1995, NEURAL COMPUT, V7, P867, DOI 10.1162/neco.1995.7.5.867; Hampshire J B, 1990, IEEE Trans Neural Netw, V1, P216, DOI 10.1109/72.80233; Jiang Y, 2002, IEEE IJCNN, P1416; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Krogh A., 1995, ADV NEURAL INFORM PR, V7; Kuncheva LI, 2000, IEEE T EVOLUT COMPUT, V4, P327, DOI 10.1109/4235.887233; LAZAREVIC A, 2001, P IEEE INT JOINT C N, P796; Lee JS, 2004, IEICE T INF SYST, VE87D, P2489; LIU H, 2004, 5 INT C WEB AG INF M; Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; Liu Y, 1999, IEEE T SYST MAN CY B, V29, P716, DOI 10.1109/3477.809027; Matsumoto T., 2001, SCI STKE, V112, P1; MATSUNAGA Y, 1996, IEICE T, V79, P403; MURASE K, 1991, P IEEE INT C NEUR NE, V1, P783; Opitz D., 1999, J ARTIFICIAL INTELLI, P169; Opitz D. W., 1996, Connection Science, V8, DOI 10.1080/095400996116802; PARTRICK EA, 1970, INFORM CONTR, V16, P128; Prechelt L, 1997, NEUROCOMPUTING, V16, P49, DOI 10.1016/S0925-2312(96)00054-9; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; Rosen B. E., 1996, Connection Science, V8, DOI 10.1080/095400996116820; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; SHAHJAHAN M, 2002, P KES 2002 CREAM IT, P11; Shahjahan M, 2003, IEICE T INF SYST, VE86D, P736; SHAHJAHAN M, 2002, P HART 2002 FUK JAP, P424; Sharkey A. J. C., 1996, Connection Science, V8, DOI 10.1080/095400996116785; SHARKEY AJC, 1995, P 14 INT C COMP SAF, P375; SHARKEY NE, 1995, CONNECT SCI, V7, P313; TUMER K, 1996, ERROR CORRELATION ER; Tumer K., 1996, PATTERN RECOGN, V29, P341, DOI DOI 10.1016/0031-3203(95)00085-2; WILENSKY G, 1990, DARPA NEURAL NETWORK, P29; WITTER I, 2000, DATA MINING PRACTICA; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107; Zhou Z.-H., 2000, KNOWL INF SYST, V2, P115, DOI 10.1007/s101150050006	43	3	4	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	MAR	2006	E89D	3					1257	1269		10.1093/ietisy/e89-d.3.1257		13	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	025TS	WOS:000236290400047	
J	Valentincic, J; Junkar, M				Valentincic, J; Junkar, M			Detection of the eroding surface in the EDM process based on the current signal in the gap	INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY			English	Article						conditional average estimator; EDM; inductive machine learning; modelling; monitoring; rough machining		To achieve high removal rate and low electrode wear in sinking electrical discharge machining process (EDM), rough machining parameters have to be selected according to the size of the eroding surface. In general, the size of the eroding surface varies according to the depth of the machining. Thus, it has to be determined on-line. This paper shows that the electric current signal in the gap depends on the size of the eroding surface. The significance of the process attributes of the electric current signal is established by inductive machine learning and the general decision rules are derived. The size of the eroding surface can be detected on-line by monitoring and evaluating the electric current signal in the gap.	Fac Mech Engn, Ljubljana 1000, Slovenia	Junkar, M (reprint author), Fac Mech Engn, Askereeva 6, Ljubljana 1000, Slovenia.	lat@fs.uni-lj.si					BEHRENS A, 2001, P INT S EL ISEM 13, P161; CESTNIK B, 1987, ASSISTANT 86 KNOWLED, P31; DEHMER JM, 1992, FORTSCHRITT BERICHTE, V2; Grabec I., 1997, SYNERGETICS MEASUREM; IGLEWICZ B, 1983, ROBUST SCALE ESTIMAT; ISHIBASHI Y, 1994, Patent No. 5362936; Ishida T., 2002, International Journal of Advanced Manufacturing Technology, V19, DOI 10.1007/s001700200032; ITOH T, 1994, Patent No. 5276302; ITOH T, 1994, Patent No. 3369239; JUNKAR M, 1999, MANUF SYST, V29, P453; KONONENKO I, 1985, THESIS U LJUBLJANA; KRUTH JP, 1998, P 12 INT S EL ISEM 1, P1; KRUTH JP, 1992, P 10 INT S EL ISEM 1, P121; KYOSHI I, 1982, Patent No. 57138544; Liao YS, 2002, J MATER PROCESS TECH, V121, P252, DOI 10.1016/S0924-0136(01)01252-3; Lin YC, 2001, INT J ADV MANUF TECH, V18, P673, DOI 10.1007/s001700170028; NAKAYAMA J, 1993, Patent No. 5243166; Narumiya H., 1989, P 9 INT S EL ISEM 9, P5; OBARA H, 1985, Patent No. 4510367; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rajurkar K.P., 1994, ANN CIRP, V43, P199; RAJURKAR KP, 1997, ANN CIRP, V47, P147; Ramasawmy H, 2002, INT J MACH TOOL MANU, V42, P567, DOI 10.1016/S0890-6955(01)00154-7; SCHULZE HP, 2000, P 2 INT C MACH MEAS, P295; Tsai KM, 2001, INT J MACH TOOL MANU, V41, P1385, DOI 10.1016/S0890-6955(01)00028-1; VALENTINCIC J, 2001, P 13 INT S EL BILB S, V1, P117; WOLLENBERG G, 1996, ON LINE DETERMINATIO, P7; Yan BH, 2002, INT J MACH TOOL MANU, V42, P1105, DOI 10.1016/S0890-6955(02)00061-5; Yu SF, 2001, INT J ADV MANUF TECH, V17, P339, DOI 10.1007/s001700170168	29	0	0	SPRINGER LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL ROAD, GODALMING GU7 3DJ, SURREY, ENGLAND	0268-3768		INT J ADV MANUF TECH	Int. J. Adv. Manuf. Technol.	MAR	2006	28	3-4					294	301		10.1007/s00170-004-2356-4		8	Automation & Control Systems; Engineering, Manufacturing	Automation & Control Systems; Engineering	018CB	WOS:000235739400010	
J	Fang, JW; Dong, YH; Lushington, GH; Ye, QZ; Georg, GI				Fang, JW; Dong, YH; Lushington, GH; Ye, QZ; Georg, GI			Support vector machines in HTS data mining: Type I MetAPs inhibition study	JOURNAL OF BIOMOLECULAR SCREENING			English	Article						support vector machines; high-throughput screening; MetAP; machine learning	DRUG DISCOVERY; LEAD-DISCOVERY	This article reports a successful application of support vector machines (SVMs) in mining high-throughput screening (HTS) data of a type I methionine aminopeptidases (MetAPs) inhibition study. A library with 43,736 small organic molecules was used in the study, and 1355 compounds in the library with 40% or higher inhibition activity were considered as active. The data set was randomly split into a training set and a test set (3:1 ratio). The authors were able to rank compounds in the test set using their decision values predicted by SVM models that were built on the training set. They defined a novel score PT50, the percentage of the test set needed to be screened to recover 50% of the actives, to measure the performance of the models. With carefully selected parameters, SVM models increased the hit rates significantly, and 50% of the active compounds could be recovered by screening just 7% of the test set. The authors found that the size of the training set played a significant role in the performance of the models. A training set with 10,000 member compounds is likely the minimum size required to build a model with reasonable predictive power.	Univ Kansas, Bioinformat Core Facil, Lawrence, KS 66045 USA; Univ Kansas, Informat & Telecommun Technol Ctr, Lawrence, KS 66045 USA; Univ Kansas, Mol Graph & Modeling Lab, Lawrence, KS 66045 USA; Univ Kansas, High Throughput Screening Lab, Lawrence, KS 66045 USA	Fang, JW (reprint author), Univ Kansas, Bioinformat Core Facil, 2099 Constant Ave, Lawrence, KS 66045 USA.	jwfang@ku.edu	Ye, Qizhuang/B-3147-2009				Bocker A, 2004, QSAR COMB SCI, V23, P207, DOI 10.1002/qsar.200330860; Brank J, 2002, P ICML 02 WORKSH TEX; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; CHANG C. C., LIBSVM LIB SUPPORT V; Erhardt PW, 2002, PURE APPL CHEM, V74, P703, DOI 10.1351/pac200274050703; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1; Liu HX, 2003, J CHEM INF COMP SCI, V43, P1288, DOI 10.1021/ci03040355; Ye Qi-Zhuang, 2004, J Am Chem Soc, V126, P13940, DOI 10.1021/ja045864p; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Muller KR, 2005, J CHEM INF MODEL, V45, P249, DOI 10.1021/ci049737o; Rogati M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Schwardt O, 2003, CURR TOP MED CHEM, V3, P1, DOI 10.2174/1568026033392642; Taira H., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); TROTTER MW, SUPPORT VECTOR MACHI; Vapnik VN, 1998, STAT LEARNING THEORY; Wilton D, 2003, J CHEM INF COMP SCI, V43, P469, DOI 10.1021/ci025586i; Winkler DA, 2004, MOL BIOTECHNOL, V27, P139, DOI 10.1385/MB:27:2:139; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412; YOUNG SS, 2002, CURR DRUG DISC   DEC, P17	23	9	10	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1087-0571		J BIOMOL SCREEN	J. Biomol. Screen	MAR	2006	11	2					138	144		10.1177/1087057105284334		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Chemistry, Analytical	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Chemistry	023SP	WOS:000236146800004	
J	Hert, J; Willett, P; Wilton, DJ; Acklin, P; Azzaoui, K; Jacoby, E; Schuffenhauer, A				Hert, J; Willett, P; Wilton, DJ; Acklin, P; Azzaoui, K; Jacoby, E; Schuffenhauer, A			New methods for ligand-based virtual screening: Use of data fusion and machine learning to enhance the effectiveness of similarity searching	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	7th International Conference on Chemical Structures	JUN 05-09, 2005	Noordwijkerhout, NETHERLANDS	ASC, CINF, CSA Trust, CSJ, GDCh, KNCV			BIOACTIVE REFERENCE STRUCTURES; LEAD-DISCOVERY PROGRAMS; NEAREST-NEIGHBOR; SUBSTRUCTURAL ANALYSIS; MOLECULAR SIMILARITY; BIOLOGICAL-ACTIVITY; MEDICINAL CHEMISTS; DRUG DESIGN; DESCRIPTORS; INFORMATION	Similarity searching using a single bioactive reference structure is a well-established technique for accessing chemical structure databases. This paper describes two extensions of the basic approach. First, we discuss the use of group fusion to combine the results of similarity searches when multiple reference structures are available. We demonstrate that this technique is notably more effective than conventional similarity searching in scaffold-hopping searches for structurally diverse sets of active molecules; conversely, the technique will do little to improve the search performance if the actives are structurally homogeneous. Second, we make the assumption that the nearest neighbors resulting from a similarity search, using a single bioactive reference structure, are also active and use this assumption to implement approximate forms of group fusion, substructural analysis, and binary kernel discrimination. This approach, called turbo similarity searching, is notably more effective than conventional similarity searching.	Univ Sheffield, Krebs Inst Biomolec Res, Sheffield S10 2TN, S Yorkshire, England; Univ Sheffield, Dept Informat Studies, Sheffield S10 2TN, S Yorkshire, England; Novartis Inst BioMed Res, CH-4002 Basel, Switzerland	Willett, P (reprint author), Univ Sheffield, Krebs Inst Biomolec Res, Sheffield S10 2TN, S Yorkshire, England.	p.willett@sheffield.ac.uk	Hert, Jerome/A-8158-2008				AVIDON VV, 1978, KHIM FARM ZH+, V12, P88; Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bohl M, 2002, QUANT STRUCT-ACT REL, V21, P590, DOI 10.1002/qsar.200290001; Bohm HJ, 2004, DRUG DISCOV TODAY, V1, P217, DOI 10.1016/j.ddtec.2004.10.009; Brown RD, 1996, J CHEM INF COMP SCI, V36, P572, DOI 10.1021/ci9501047; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; CHEN B, UNPUB EFFECT NOISY T; Chen X, 2002, J CHEM INF COMP SCI, V42, P1407, DOI 10.1021/ci025531g; Cosgrove DA, 1998, J MOL GRAPH MODEL, V16, P19, DOI 10.1016/S1093-3263(98)00014-X; Cramer RD, 2004, J MED CHEM, V47, P6777, DOI 10.1021/jm049501b; CRAMER RD, 1974, J MED CHEM, V17, P533, DOI 10.1021/jm00251a014; Ginn CMR, 2000, PERSPECT DRUG DISCOV, V20, P1, DOI 10.1023/A:1008752200506; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; He L, 2005, J MOL GRAPH MODEL, V23, P503, DOI 10.1016/j.jmgm.2005.03.003; Hert J, 2005, J MED CHEM, V48, P7049, DOI 10.1021/jm050316n; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; HERT J, 2005, THESIS U SHEFFIELD S; Jenkins JL, 2004, J MED CHEM, V47, P6144, DOI 10.1021/jm049654z; JOHNSON MA, 1990, CONCEPTS APPL MOL SU; Jorissen RN, 2005, J CHEM INF MODEL, V45, P549, DOI 10.1021/ci049641u; Klon AE, 2004, J MED CHEM, V47, P2743, DOI 10.1021/jm030363k; Kubinyi H, 1998, PERSPECT DRUG DISCOV, V9-11, P225, DOI 10.1023/A:1027221424359; Lajiness MS, 2004, J MED CHEM, V47, P4891, DOI 10.1021/jm049740z; Lewell XQ, 2003, J MED CHEM, V46, P3257, DOI 10.1021/jm0300429; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; Nikolova N., 2003, QSAR COMB SCI, V22, P1006, DOI DOI 10.1186/1471-2121-8-S1-S6; ORMEROD A, 1989, QUANT STRUCT-ACT REL, V8, P115, DOI 10.1002/qsar.19890080207; Patani GA, 1996, CHEM REV, V96, P3147, DOI 10.1021/cr950066q; Patterson DE, 1996, J MED CHEM, V39, P3049, DOI 10.1021/jm960290n; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; Schneider G, 1999, ANGEW CHEM INT EDIT, V38, P2894, DOI 10.1002/(SICI)1521-3773(19991004)38:19<2894::AID-ANIE2894>3.0.CO;2-F; Schuffenhauer A, 2002, J CHEM INF COMP SCI, V42, P947, DOI 10.1021/co010385k; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P1912, DOI 10.1021/ci049782w; Sheridan RP, 2002, DRUG DISCOV TODAY, V7, P903, DOI 10.1016/S1359-6446(02)02411-X; Stanton DT, 1999, J CHEM INF COMP SCI, V39, P21, DOI 10.1021/ci9801015; Takaoka Y, 2003, J CHEM INF COMP SCI, V43, P1269, DOI 10.1021/ci0340431; Whittle M, 2004, J CHEM INF COMP SCI, V44, P1840, DOI 10.1021/ci049867x; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; WILLETT P, 1986, J CHEM INF COMP SCI, V26, P36, DOI 10.1021/ci00049a008; Wilton D, 2003, J CHEM INF COMP SCI, V43, P469, DOI 10.1021/ci025586i; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195	44	108	111	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	MAR-APR	2006	46	2					462	470		10.1021/ci050348j		9	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	028XT	WOS:000236522800003	
J	Erhan, D; L'Heureux, PJ; Yue, SY; Bengio, Y				Erhan, D; L'Heureux, PJ; Yue, SY; Bengio, Y			Collaborative filtering on a family of biological targets	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	7th International Conference on Chemical Structures	JUN 05-09, 2005	Noordwijkerhout, NETHERLANDS	ASC, CINF, CSA Trust, CSJ, GDCh, KNCV			INFORMATION; INDEXES; MODEL	Building a QSAR model of a new biological target for which few screening data are available is a statistical challenge. However, the new target may be part of a bigger family, for which we have more screening data. Collaborative filtering or, more generally, multi-task learning, is a machine learning approach that improves the generalization performance of an algorithm by using information from related tasks as an inductive bias. We use collaborative filtering techniques for building predictive models that link multiple targets to multiple examples. The more commonalities between the targets, the better the multi-target model that can be built. We show an example of a multi-target neural network that can use family information to produce a predictive model of an undersampled target. We evaluate JRank, a kernel-based method designed for collaborative filtering. We show their performance on compound prioritization for an HTS campaign and the underlying shared representation between targets. JRank outperformed the neural network both in the single- and multi-target models.	Univ Montreal, Dept IRO, Montreal, PQ H3C 3J7, Canada; AstraZeneca R&D Montreal, St Laurent, PQ H4S 1Z9, Canada	Erhan, D (reprint author), Univ Montreal, Dept IRO, CP 6128,Succ Ctr, Montreal, PQ H3C 3J7, Canada.	erhandum@iro.umontreal.ca					BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; BASILICO J, 2004, ICML 04; Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663; BAXTER J, 1996, ADV NEURAL INFORM PR, V8; BHM H, 2000, VIRTUAL SCREENING BI, V10; Bicerano J., 1996, PREDICTION POLYM PRO; Bishop C., 1996, NEURAL NETWORKS PATT; BISHOP C, 1995, NEURAL NETWORKDS PAT; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; CRAMMER K, 2002, ADV NEURAL INFORM PR, V14; Deng Z, 2004, J MED CHEM, V47, P337, DOI 10.1021/jm030331x; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; FREUND Y, 1998, COLT 98; Ghosn J, 2003, IEEE T NEURAL NETWOR, V14, P748, DOI 10.1109/TNN.2003.810608; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; HALL LH, 1991, REV COMPUTATIONAL CH, V2, P367, DOI 10.1002/9780470125793.ch9; HALL LH, 1995, J CHEM INF COMP SCI, V35, P1039, DOI 10.1021/ci00028a014; HANLEY JA, 1982, RADIOLOGY, V143, P29; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P1, DOI 10.1002/qsar.19860050102; Li M., 1997, INTRO KOLMOGOROV COM; LING CX, 1998, KDD; Malinowski E. R., 2002, FACTOR ANAL CHEM; Oprea TI, 2000, J COMPUT AID MOL DES, V14, P251, DOI 10.1023/A:1008130001697; PETITJEAN M, 1992, J CHEM INF COMP SCI, V32, P331, DOI 10.1021/ci00008a012; RANDIC M, 1984, J CHEM INF COMP SCI, V24, P164, DOI 10.1021/ci00043a009; RESNICK P, 1994, CSCW 9J; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Scholkopf B., 2001, LEARNING KERNELS SUP; Zupan J., 1999, NEURAL NETWORKS CHEM	30	40	40	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	MAR-APR	2006	46	2					626	635		10.1021/ci050367t		10	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	028XT	WOS:000236522800022	
J	Yang, YH; Guergachi, A; Khan, G				Yang, Y. H.; Guergachi, A.; Khan, G.			Support Vector Machines for Environmental Informatics: Application to Modelling the Nitrogen Removal Processes in Wastewater Treatment Systems	JOURNAL OF ENVIRONMENTAL INFORMATICS			English	Article						GPS-X; least-square SVMs; NARX model; nitrogen removal; support vector machines; wastewater treatment	NEURAL-NETWORKS; IDENTIFICATION; CLASSIFIERS	In order to meet the new stringent environmental regulations, it is necessary to investigate the adaptive and optimal control strategies for the biological wastewater treatment processes. Nitrogen removal is one of the essential concerns in wastewater treatment. Nitrogen removal is a nonlinear, dynamic, and time variant complex process as complicated activities of microbial metabolism are involved. The mechanistic models for nitrogen removal are complicated and still uncertain to some extent. A new machine learning approach, Support Vector Machine (SVM) was proposed as black-box modeling technique to model the biological wastewater treatment processes. LS-SVM, a simplified formulation of SVM, has been applied in this study to predict the concentration of nitrate and nitrite (NO) in the Mixed Liquor (ML) of wastewater treatment plant. Nonlinear Autoregressive model with Exogenous inputs (NARX model) can be employed with LS-SVM to extract useful information and improve the prediction performance. In this paper, the premium wastewater treatment plant simulation and optimization software. GPS-X, is used to create virtual plant layout and simulated data. The simulation results indicate that the proposed method has good generalization performance, especially when the input is fluctuated without a usual pattern. We conclude that LS-SVM with NARX modelling could be used as an alternative approach to predict the behaviour of wastewater treatment systems by further studying some essential issues such as the tuning of memory order and training data size.	[Guergachi, A.] Ryerson Univ, Sch Informat Technol, Toronto, ON, Canada; [Yang, Y. H.] Citizens Environm Watch, Toronto, ON, Canada	Guergachi, A (reprint author), Ryerson Univ, Sch Informat Technol, Toronto, ON, Canada.	a2guerga@ryerson.ca			NSERC; CFI	This research has been financially supported by research and equipment grants from NSERC and CFI respectively. This financial support is highly acknowledged. The helpful discussions with J.B. Copp and O. Schraa in Hydromantis Inc. are also gratefully appreciated. The comments from the anonymous reviewers are acknowledged that has improved this paper.	BECK MB, 1986, IEE PROC-D, V133, P254; Beck MB, 1997, STOCH HYDROL HYDRAUL, V11, P229, DOI 10.1007/BF02427917; Copp J.B., 2002, COST SIMULATION BENC; Cristianini N, 2003, INTRO SUPPORT VECTOR; GUERGACHI A, 2004, IEEE T SY A IN PRESS; GUERGACHI A, 2003, J HYDROINFORM, V5, P181; Guergachi A. A., 2003, Complex Systems, V14; GUERGACHI A, 2003, P ISEIS 2003, P386; Guergachi AA, 2002, INT J GEN SYST, V31, P343, DOI 10.1080/03081070290018056; Jeppsson U, 1996, THESIS LUND I TECHNO; Lin TN, 1997, IEEE T SIGNAL PROCES, V45, P2719; Lin TN, 1996, IEEE T NEURAL NETWOR, V7, P1329; MARSILILIBELLI S, 1989, ENCY ENV CONTROL TEC, V3, P229; Metcalf Eddy Inc., 1991, WAST ENG TREATM DISP; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Suykens JAK, 2001, EUR J CONTROL, V7, P311, DOI 10.3166/ejc.7.311-327; TERRILLON TJ, 2000, P 15 INT C PATT REC, V4, P210, DOI 10.1109/ICPR.2000.902897; Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093; Vapnik VN, 1998, STAT LEARNING THEORY; YANG YH, 2004, P 3 INT C UPC ENG TO; 2004, GPS X4 1 2 MODULAR M	23	1	1	INT SOC ENVIRON INFORM SCI	REGINA	4246 ALBERT ST, REGINA, SASKATCHEWAN S4S 3R9, CANADA	1726-2135		J ENVIRON INFORM	J. Environ. Inform.	MAR	2006	7	1					14	23		10.3808/jei.200600063		10	Environmental Sciences	Environmental Sciences & Ecology	V12TG	WOS:000207620900002	
J	Kulic, R; Vukic, Z				Kulic, Ranka; Vukic, Zoran			Methodology of concept control synthesis to avoid unmoving and moving obstacles (II)	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS			English	Article						behavioral cloning; cloning success; linear regression; machine learning; obstacle avoiding; RBF neural network; robot motion planning		Dynamic path generation problem of robot in environment with other unmoving and moving objects is considered. Generally, the problem is known in literature as find path or robot motion planning. In this paper we apply the behavioral cloning approach to design the robot controller. In behavioral cloning, the system learns from control traces of a human operator. The task for the given problem is to find a controller not only in the form of the explicit mathematical expression. So RBF neural network is used also. The goal is to apply controller for the mobile robot motion planning in situation with infinite number of obstacles. The advantage of this approach lies in the fact that a complete path can be defined off-line, without using sophisticated symbolical models of obstacles.	Univ Montenegro, Fac Maritime Studies, Kotor, Montenegro; Fac Elect Engn & Comp, Zagreb, Croatia	Kulic, R (reprint author), Univ Montenegro, Fac Maritime Studies, Kotor, Montenegro.	rkulic2001@yahoo.com; zoran.vukic@fer.hr					AVNAIM F, 1988, P IEEE INT C ROB AUT; BARBEHENN M, 1994, P IEEE INT C ROB AUT; BARBEHENN M, 1993, P IEEE INT C ROB AUT; BARRAQUAND J, 1990, P IEEE INT C ROB AUT; BARRAQUAND J, 1991, INT J ROBOT RES, V10; BARRAQUAND J, 1989, STANCS891285; Breiman L, 1984, CLASSIFICATION REGRE; BROOKS RA, 1983, P INT JOINT C ART IN; Broomhead D. S., 1988, Complex Systems, V2; CAMPA G, 1999, MODEL UNDERWATER VEH; CANNY J, 1988, DISCRETE COMPUT GEOM, V3; CHANY JF, 1988, COMPLEXITY ROBOT MOT; CHEN P, 1991, P IEEE INT C ROB AUT; CHEN P, 1992, P MACH LEARN C AB SC; CHOSET H, 1995, P IEEE INT C ROB AUT; Daubechies I., 1992, 10 LECT WAVELETS; ERDMANN M, 1986, 883 MIT AI LAB; FAVERJO B, 1987, P INT JOINT C ART IN; FUJIMURA K, 1989, IEEE T ROBOT AUT FEB; Fukuda T, 1999, P IEEE, V87, P1448, DOI 10.1109/5.784220; GERKE M, 1999, P AM CONTR C SAN DIE; GLAVINA B, 1990, P IEEE INT C ROB AUT; Goldberg D. E., 1989, GENETIC ALGORITHM SE; HARTMAN EJ, 1990, NEURAL COMPUT, V2, P210, DOI 10.1162/neco.1990.2.2.210; Hopcroft J., 1987, PLANNING GEOMETRY CO; KARALIC A, 1991, THESIS U LJUBLJANA L; Kavraki L. E., 1994, P IEEE INT C ROB AUT; KHATIB O, 1986, INT J ROB RES, V5; Koditschek D., 1987, P IEEE INT C ROB AUT; KRIMAN V, 1993, THESIS U LJUBLJANA L; KULIC R, 2004, SE EUR US JAP EUR CO; KULIC R, 2001, 2 IFAC CIGR S BAL IN; KULIC R, 2004, THESIS FACULTY ELECT; KULIC R, 2003, J INTELL ROBOT SYST, V37; KULIC R, 2001, 7 INT S SAUM VRNJAEK; KWOK KS, 1999, P AM CONTR C SAN DIE; Latombe J.-C., 1991, ROBOT MOTION PLANNIN; LEE S, 1988, P IEEE INT C NEURAL, V1, P161; LEVEN D, 1985, P 1 ACM S COMP GEOM; LOZANOPEREZ T, 1979, COMM ACM, V22; MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414; MICHIE D, 1993, INTELLIGENT SYSTEM; MICHIE D, 1994, MACHINE INTELLIGENCE; Mitchell T, 1997, MACHINE LEARNING; NIRANJAN M, 1988, CUEDIFINFENG17R22; OVERMARS M, 1994, WORKSH ALG FDN ROB S; POGGIO T, 1990, P IEEE, V78, P9; Powell M.J.D., 1987, ALGORITHMS APPROXIMA; QUINLAN JR, 1986, INDUCTION DECISION T, V1; REIF J, 1985, P IEE S FDN COMP SCI; REIF JH, 1987, PLANNING GEOMETRY CO; RIMON E, 1994, P IEEE INT C ROB AUT; RIMON E, 1992, IEEE J ROBOT AUT OCT, V8; SAMAD T, 2001, P 2001 IEEE INT S IN; SAMMUT C, 1992, P 9 INT WORKSH MACH; SIFRONY S, 1987, ALGORITHMICA, V2; STAPPEN F, 1993, COMPUT GEOM, V3; STOJIC R, 1990, SCI TECHNICAL OBSERV, V11; WILFONG G, 1988, P 4 ACM S COMP GEOM; YANG G, 2002, P 41 IEEE C DEC CONT	60	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0921-0296		J INTELL ROBOT SYST	J. Intell. Robot. Syst.	MAR	2006	45	3					267	294		10.1007/s10846-006-9035-7		28	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	071UD	WOS:000239628500004	
J	Plewczynski, D; Tkacz, A; Wyrwicz, L; Godzik, A; Kloczkowski, A; Rychlewski, L				Plewczynski, D; Tkacz, A; Wyrwicz, L; Godzik, A; Kloczkowski, A; Rychlewski, L			Support-vector-machine classification of linear functional motifs in proteins	JOURNAL OF MOLECULAR MODELING			English	Article						kinase substrate prediction; profile-profile sequence similarity; local structural segments; linear functional motifs; Swiss-Prot database; support vector machine (SVM)	PHOSPHORYLATION SITES; STRUCTURE PREDICTION; SEQUENCE MOTIFS; KINASE-C; DATABASE; SUPPLEMENT; ROSETTA	Our algorithm predicts short linear functional motifs in proteins using only sequence information. Statistical models for short linear functional motifs in proteins are built using the database of short sequence fragments taken from proteins in the current release of the Swiss-Prot database. Those segments are confirmed by experiments to have single-residue post-translational modification. The sensitivities of the classification for various types of short linear motifs are in the range of 70%. The query protein sequence is dissected into short overlapping fragments. All segments are represented as vectors. Each vector is then classified by a machine learning algorithm (Support Vector Machine) as potentially modifiable or not. The resulting list of plausible post-translational sites in the query protein is returned to the user. We also present a study of the human protein kinase C family as a biological application of our method.	Univ Warsaw, Interdisciplinary Ctr Math & Computat Modeling, PL-02106 Warsaw, Poland; BioInfoBank Inst, PL-60744 Poznan, Poland; Adam Mickiewicz Univ Poznan, Bioinformat Unit, Dept Phys, PL-61614 Poznan, Poland; Univ Calif San Diego, Bioinformat Core JCSG, La Jolla, CA 92093 USA; Burnham Inst, La Jolla, CA 92037 USA; Iowa State Univ, Baker Ctr Bioinformat & Biol Stat, Ames, IA USA	Plewczynski, D (reprint author), Univ Warsaw, Interdisciplinary Ctr Math & Computat Modeling, Pawinskiego 5A St, PL-02106 Warsaw, Poland.	darman@icm.edu.pl	Kloczkowski, Andrzej/B-9868-2012; Godzik, Adam/A-7279-2009				Attwood TK, 2003, NUCLEIC ACIDS RES, V31, P400, DOI 10.1093/nar/gkg030; Bairoch A, 1999, NUCLEIC ACIDS RES, V27, P49, DOI 10.1093/nar/27.1.49; Blom N, 1999, J MOL BIOL, V294, P1351, DOI 10.1006/jmbi.1999.3310; Bystroff C., 2002, BIOINFORMATICS, V18, pS54; Cristianini N., 2000, SUPPORT VECTOR MACHI; Falquet L, 2002, NUCLEIC ACIDS RES, V30, P235, DOI 10.1093/nar/30.1.235; Gattiker Alexandre, 2002, Appl Bioinformatics, V1, P107; Henikoff S, 1999, BIOINFORMATICS, V15, P471, DOI 10.1093/bioinformatics/15.6.471; Huang JY, 2001, NUCLEIC ACIDS RES, V29, P202, DOI 10.1093/nar/29.1.202; JONASSEN I, 1995, PROTEIN SCI, V4, P1587; Kim H, 2003, PROTEIN ENG, V16, P553, DOI 10.1093/protein/gzg072; Kreegipuu A, 1999, NUCLEIC ACIDS RES, V27, P237, DOI 10.1093/nar/27.1.237; Kreegipuu A, 1998, FEBS LETT, V430, P45, DOI 10.1016/S0014-5793(98)00503-1; LOHMANN R, 1994, PROTEIN SCI, V3, P1597; MINAKUCHI Y, 2003, P INT C MATH ENG TEC, P22; Monigatti F, 2002, BIOINFORMATICS, V18, P769, DOI 10.1093/bioinformatics/18.5.769; Nevill-Manning CG, 1998, P NATL ACAD SCI USA, V95, P5865, DOI 10.1073/pnas.95.11.5865; Newton AC, 1997, CURR OPIN CELL BIOL, V9, P161, DOI 10.1016/S0955-0674(97)80058-0; Obenauer JC, 2003, NUCLEIC ACIDS RES, V31, P3635, DOI 10.1093/nar/gkg584; Parekh DB, 2000, EMBO J, V19, P496, DOI 10.1093/emboj/19.4.496; PLEWCZYNSKI D, 2005, IN PRESS J MOL MODEL; PLEWCZYNSKI D, 2003, COMPUT METHODS SCI T, V9, P93; Plewczynski D, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-98; Puntervoll P, 2003, NUCLEIC ACIDS RES, V31, P3625, DOI 10.1093/nar/gkg545; Rohl CA, 2004, PROTEINS, V55, P656, DOI 10.1002/prot10629; Simons KT, 1999, PROTEINS, P171; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Zavaljevski N, 2002, BIOINFORMATICS, V18, P689, DOI 10.1093/bioinformatics/18.5.689; Zdobnov EM, 2001, BIOINFORMATICS, V17, P847, DOI 10.1093/bioinformatics/17.9.847	30	4	4	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1610-2940		J MOL MODEL	J. Mol. Model.	AUG	2006	12	4					453	461		10.1007/s00894-005-0070-2		9	Biochemistry & Molecular Biology; Biophysics; Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biophysics; Chemistry; Computer Science	018FO	WOS:000235749700011	
J	Skowronski, MD; Harris, JG				Skowronski, MD; Harris, JG			Acoustic detection and classification of microchiroptera using machine learning: Lessons learned from automatic speech recognition	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA			English	Article							ECHOLOCATION CALLS; IDENTIFICATION; BAT; CONSEQUENCES; VERIFICATION; HABITAT; DESIGN	Current automatic acoustic detection and classification of microchiroptera utilize global features of individual calls (i.e., duration, bandwidth, frequency extrema), an approach that stems from expert knowledge of call sonograms. This approach parallels the acoustic phonetic paradigm of human automatic speech recognition (ASR), which relied on expert knowledge to account for variations in canonical linguistic units. ASR research eventually shifted from acoustic phonetics to machine learning, primarily because of the superior ability of machine learning to account for signal variation. To compare machine learning with conventional methods of detection and classification, nearly 3000 search-phase calls were hand labeled from recordings of five species: Pipistrellus bodenheimeri., Molossus molossus, Lasiurus borealis, L. cinereus semotus, and Tadarida brasiliensis. The hand labels were used to train two machine learning models: a Gaussian mixture model (GMM) for detection and classification and a hidden Markov model (HMM) for classification. The GMM detector produced 4% error compared to 32% error for a baseline broadband energy detector, while the GMM and HMM classifiers produced errors of 0.6 +/- 0.2% compared to 16.9 +/- 1.1% error for a baseline discriminant function analysis classifier. The experiments showed that machine learning algorithms produced errors an order of magnitude smaller than those for conventional methods. (c) 2006 Acoustical Society of America.	Univ Florida, Computat Neuroengn Lab, Gainesville, FL 32611 USA	Skowronski, MD (reprint author), Univ Florida, Computat Neuroengn Lab, Gainesville, FL 32611 USA.	markskow@cnel.ufl.edu; harris@cnel.ufl.edu					ATAL BS, 1974, J ACOUST SOC AM, V55, P1304, DOI 10.1121/1.1914702; Bishop C.M., 1995, NEURAL NETWORKS PATT; CHAN YT, 1981, IEEE T ACOUST SPEECH, V29, P214, DOI 10.1109/TASSP.1981.1163543; Duda R. O., 2001, PATTERN CLASSIFICATI; Fenton MB, 2001, J MAMMAL, V82, P721, DOI 10.1644/1545-1542(2001)082<0721:TEAZCP>2.0.CO;2; FENTON MB, 1981, J MAMMAL, V62, P233, DOI 10.2307/1380701; FENTON MB, 1983, CAN J ZOOL, V61, P2503; FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530; Gannon WL, 2003, WILDLIFE SOC B, V31, P45; GRIFFIN DR, 1958, LISTENING DARK ACOUS; Juang BH, 2000, P IEEE, V88, P1142; Krusic RA, 1996, BC MIN FOR RES PROGR, V23, P185; Lance RF, 1996, BC MIN FOR RES PROGR, V23, P175; MASTERS WM, 1991, J ACOUST SOC AM, V89, P1402, DOI 10.1121/1.400660; MURPHY K, 2005, BAYES NETWORK TOOLBO; Obrist MK, 2004, MAMMALIA, V68, P307, DOI 10.1515/mamm.2004.030; OBRIST MK, 1995, BEHAV ECOL SOCIOBIOL, V36, P207, DOI 10.1007/BF00177798; O'Farrell MJ, 1999, J MAMMAL, V80, P11, DOI 10.2307/1383203; Oppenheim AV, 1989, DISCRETE TIME SIGNAL; Parsons S, 2000, J EXP BIOL, V203, P2641; Parsons S, 1997, J MAMMAL, V78, P964, DOI 10.2307/1382956; Parsons S, 2000, J MAMMAL, V81, P927, DOI 10.1644/1545-1542(2000)081<0927:AADOTF>2.0.CO;2; Rabiner L. R., 1990, READINGS SPEECH RECO, P267; Russo D, 2002, J ZOOL, V258, P91, DOI 10.1017/S0952836902001231; SKOWRONSKI MD, 2005, J ACOUST SOC AM, V117, P2552; SKOWRONSKI MD, 2004, J ACOUST SOC AM, V116, P2639; TANG M, 2003, IEEE AUTOMATIC SPEEC, P49; WEINSTEIN CJ, 1975, IEEE T ACOUST SPEECH, VAS23, P54, DOI 10.1109/TASSP.1975.1162651	28	18	18	ACOUSTICAL SOC AMER AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0001-4966		J ACOUST SOC AM	J. Acoust. Soc. Am.	MAR	2006	119	3					1817	1833		10.1121/1.2166948		17	Acoustics; Audiology & Speech-Language Pathology	Acoustics; Audiology & Speech-Language Pathology	023VU	WOS:000236155100049	
J	Bartlett, PL; Jordan, MI; McAuliffe, JD				Bartlett, PL; Jordan, MI; McAuliffe, JD			Convexity, classification, and risk bounds	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						boosting; convex optimization; empirical process theory; machine learning; rademacher complexity; support vector machine	EMPIRICAL PROCESSES; CONCENTRATION INEQUALITIES; LOGISTIC-REGRESSION; SAMPLE COMPLEXITY; NEURAL-NETWORKS; CONSISTENCY; CLASSIFIERS; MARGIN; MINIMIZATION; ADABOOST	Many of the classification algorithms developed in the machine learning literature, including the support vector machine and boosting, can be viewed as minimum contrast methods that minimize a convex surrogate of the 0-1 loss function. The convexity makes these algorithms computationally efficient. The use of a surrogate, however, has statistical consequences that must be balanced against the computational virtues of convexity. To study these issues, we provide a general quantitative relationship between the risk as assessed using the 0-1 loss and the risk as assessed using any nonnegative surrogate loss function. We show that this relationship gives nontrivial upper bounds on excess risk under the weakest possible condition on the loss function-that it satisfies a pointwise form of Fisher consistency for classification. The relationship is based on a simple variational transformation of the loss function that is easy to compute in many applications. We also present a refined version of this result in the case of low noise. and show that in this case, strictly convex loss functions lead to faster rates of convergence of the risk than would be implied by standard uniform convergence arguments. Finally, we present applications of our results to the estimation of convergence rates in function classes that are scaled convex hulls of a finite-dimensional base class, with a variety of commonly used loss functions.	Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA; Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA	Bartlett, PL (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.	bartlett@stat.berkeley.edu; jordan@stat.berkeley.edu; jon@stat.berkeley.edu					Arora S, 1997, J COMPUT SYST SCI, V54, P317, DOI 10.1006/jcss.1997.1472; Bartlett PL, 2005, ANN STAT, V33, P1497, DOI 10.1214/009053605000000282; BARTLETT PL, 2005, IN PRESS PROBABILITY; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; Bousquet O, 2002, CR MATH, V334, P495, DOI 10.1016/S1631-073X(02)02292-6; Boyd S, 2004, CONVEX OPTIMIZATION; Breiman L, 2004, ANN STAT, V32, P1; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Brown L., 1986, FUNDAMENTALS STAT EX; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Devroye L., 1996, PROBABILISTIC THEORY; Dudley R. M., 1999, UNIFORM CENTRAL LIMI; Feder M, 2004, IEEE T SIGNAL PROCES, V52, P2152, DOI 10.1109/TSP.2004.831149; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Jiang WX, 2004, ANN STAT, V32, P13; JOACHIMS T., 2002, LEARNING CLASSIFY TE; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Klein T, 2002, CR MATH, V334, P501, DOI 10.1016/S1631-073X(02)02303-8; KOLTCHINSKII V, 2000, HIGH DIMENSIONAL PRO, V47, P443; Koltchinskii V, 2002, ANN STAT, V30, P1; Lebanon G, 2002, ADV NEUR IN, V14, P447; Ledoux M., 2001, CONCENTRATION MEASUR; Ledoux M., 1991, PROBABILITY BANACH S; Lee WS, 1996, IEEE T INFORM THEORY, V42, P2118; Lin Y, 2004, STAT PROBABIL LETT, V68, P73, DOI 10.1016/j.spl.2004.03.002; Lugosi G, 2004, ANN STAT, V32, P1679, DOI 10.1214/009053604000000463; Lugosi G, 2004, ANN STAT, V32, P30; Mammen E, 1999, ANN STAT, V27, P1808; MANNOR S, 2001, P 14 ANN C COMP LEAR, P461; MANNOR S, 2002, P ANN C COMP LEARN T, P319; MARRON JS, 2002, 1339 CORN U SCH OP R; MASSART P., 2000, ANN FAC SCI TOULOUSE, V9, P245; Massart P, 2000, ANN PROBAB, V28, P863, DOI 10.1214/aop/1019160263; Mendelson S, 2002, IEEE T INFORM THEORY, V48, P1977, DOI 10.1109/TIT.2002.1013137; Nesterov Y., 1994, INTERIOR POINT POLYN; Rio E, 2001, PROBAB THEORY REL, V119, P163, DOI 10.1007/PL00008756; ROCKAFELLAR R. T., 1997, CONVEX ANAL; Schapire RE, 1998, ANN STAT, V26, P1651; SCHOLKOPF B, 2003, KERNEL METHODS COMPU; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Shen XT, 2003, J AM STAT ASSOC, V98, P724, DOI 10.1198/016214503000000639; Steinwart I, 2005, IEEE T INFORM THEORY, V51, P128, DOI 10.1109/TIT.2004.839514; TALAGRAND M, 1994, ANN PROBAB, V22, P28, DOI 10.1214/aop/1176988847; Tsybakov AB, 2004, ANN STAT, V32, P135; Wellner J. A., 1996, WEAK CONVERGENCE EMP; Zhang T, 2004, ANN STAT, V32, P56; Zhang T, 2005, ANN STAT, V33, P1538, DOI 10.1214/009053605000000255; Zhang T, 2003, IEEE T INFORM THEORY, V49, P682, DOI 10.1109/TIT.2002.808136	53	150	152	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459		J AM STAT ASSOC	J. Am. Stat. Assoc.	MAR	2006	101	473					138	156		10.1198/016214505000000907		19	Statistics & Probability	Mathematics	021BU	WOS:000235958400017	
J	Kukar, M				Kukar, M			Quality assessment of individual classifications in machine learning and data mining	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						data mining; machine learning; typicalness; transduction; quality assessment	PROBABILITY	Although in the past machine learning algorithms have been successfully used in many problems, their serious practical use is affected by the fact that often they cannot produce reliable and unbiased assessments of their predictions' quality. In last few years, several approaches for estimating reliability or confidence of individual classifiers have emerged, many of them building upon the algorithmic theory of randomness, such as (historically ordered) transduction-based confidence estimation, typicalness-based confidence estimation, and transductive reliability estimation. Unfortunately, they all have weaknesses: either they are tightly bound with particular learning algorithms, or the interpretation of reliability estimations is not always consistent with statistical confidence levels. In the paper we describe typicalness and transductive reliability estimation frameworks and propose a joint approach that compensates the above-mentioned weaknesses by integrating typicalness-based confidence estimation and transductive reliability estimation into a joint confidence machine. The resulting confidence machine produces confidence values in the statistical sense. We perform series of tests with several different machine learning algorithms in several problem domains. We compare our results with that of a proprietary method as well as with kernel density estimation. We show that the proposed method performs as well as proprietary methods and significantly outperforms density estimation methods.	Univ Ljubljana, Fac Comp & Informat Sci, SI-1001 Ljubljana, Slovenia	Kukar, M (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Trzaska 25, SI-1001 Ljubljana, Slovenia.	matjaz.kukar@fri.uni-lj.si					BAY SD, 2000, P 17 INT C MACH LEAR, P49; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; DIAMOND GA, 1979, NEW ENGL J MED, V300, P1350, DOI 10.1056/NEJM197906143002402; Gammerman A., 1998, P 14 C UNC ART INT M, P148; Gibbs AL, 2002, INT STAT REV, V70, P419, DOI 10.2307/1403865; HALCK OM, 2002, P 13 EUR C MACH LEAR, P124; Hastie T, 2001, ELEMENTS STAT LEARNI; HO SS, 2003, P INT JOINT C NEUR N; John G. H., 1995, P 11 C UNC ART INT; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; KUKAR M, 2001, P ART INT MED EUR AI, P88; Kukar M., 2002, P MACH LEARN ECML 20, P219; KUKAR M, 2001, THESIS U LJUBLJANA L; Li M., 1997, INTRO KOLMOGOROV COM; MELLUISH T, 2001, P ECML 2001, V2167, P350; Nouretdinov I., 2001, P 18 INT C MACH LEAR, P385; Olona-Cabases M., 1994, NUCL CARDIOLOGY EVER, P348; Pfahringer B., 2000, P 17 INT C MACH LEAR; Proedru K., 2002, P 13 EUR C MACH LEAR, p[381, 2002]; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAUNDERS C, 1999, P INT JOINT C ART IN; Seewald A. K., 2001, P 4 INT S ADV INT DA, P115; SMYTH P, 1995, P 12 INT C MACH LEAR, P506; SPECHT DF, 1994, P IEEE INT C NEUR NE; Taneja I.J., 1989, ADV ELEC ELECT PHYS, V76, P327; Vapnik VN, 1998, STAT LEARNING THEORY; VENABLES WN, 2002, MODERN APPL STAT SPL; VOVK V, 1999, P 16 INT C MACH LEAR; Wand MP, 1995, KERNEL SMOOTHING	30	10	10	SPRINGER LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL ROAD, GODALMING GU7 3DJ, SURREY, ENGLAND	0219-1377		KNOWL INF SYST	Knowl. Inf. Syst.	MAR	2006	9	3					364	384		10.1007/s10115-005-0203-z		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	031PS	WOS:000236717100005	
J	Zhou, ZH; Tang, W				Zhou, ZH; Tang, W			Clusterer ensemble	KNOWLEDGE-BASED SYSTEMS			English	Article						machine learning; ensemble learning; clustering; unsupervised learning; selective ensemble	NEURAL-NETWORK ENSEMBLES	Ensemble methods that train multiple learners and then combine their predictions have been shown to be very effective in supervised learning. This paper explores ensemble methods for unsupervised learning. Here, an ensemble comprises multiple clusterers. each of which is trained by k-means algorithm with different initial points. The clusters discovered by different clusterers are aligned, i.e. similar clusters are assigned with the same label, by counting their overlapped data items. Then, four methods are developed to combine the aligned clusterers. Experiments show that clustering performance could be significantly improved by ensemble methods, where utilizing mutual information to select a subset of clusterers for weighted voting is a nice choice. Since the proposed methods work by analyzing the clustering results instead of the internal mechanisms of the component clusterers, they are applicable to diverse kinds of clustering algorithms. (c) 2006 Elsevier B.V. All rights reserved.	Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Natl Lab Novel Software Technol, Hankou Rd 22, Nanjing 210093, Peoples R China.	zhouzh@nju.edu.cn					Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Cherkauer K., 1996, P 13 AAAI WORKSH INT, P15; Dietterich T.G., 2002, HDB BRAIN THEORY NEU; Drucker H., 1993, ADV NEURAL INFORMATI, V5, P42; Estivill-Castro V, 2002, SIGKDD EXPLORATIONS, V4, P65; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Huang F, 2000, P 4 IEEE INT C AUT F, P245; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Modha DS, 2003, MACH LEARN, V52, P217, DOI 10.1023/A:1024016609528; Strehl A., 2000, P AAAI WORKSH AI WEB, P58; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X	14	31	42	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	MAR	2006	19	1					77	83		10.1016/j.knosys.2005.11.003		7	Computer Science, Artificial Intelligence	Computer Science	035YD	WOS:000237036800009	
J	Ko, PC; Lin, PC				Ko, PC; Lin, PC			An evolution-based approach with modularized evaluations to forecast financial distress	KNOWLEDGE-BASED SYSTEMS			English	Article						financial distress; evolutionary computation; particle swarm optimization; genetic algorithm; bankruptcy; neural network	NEURAL-NETWORK; BUSINESS FAILURE; BANKRUPTCY PREDICTIONS; SELECTION; MODELS	Due to the radical changing of the global economy, a more precise forecasting of corporate financial distress helps provide important judgment principles to decision-makers. Although financial statements reflect a firm's business activities, it is very challenging to discover critical information from these statements. Applying machine learning algorithms can be demonstrated to improve forecasting accuracy in predicting corporate bankruptcy. In this paper, we introduce an evolutionary approach with modularized evaluation functions to forecast financial distress, which allows using any evolutionary algorithm to extract the set of critical financial ratios and integrates more evaluation function modules to achieve a better forecasting accuracy by assigning distinct weights. To achieve 4 more precise predicting accuracy, the undesirable forecasting results from some modules are weeded out, if their predicting accuracies are out of the allowable tolerance range as learned from our mechanism. (c) 2005 Elsevier B.V. All fights reserved.	Natl Kaohsiung Univ Appl Sci, Inst Finance & Informat, Dept Informat Management, Kaohsiung 807, Taiwan; Van Nung Inst Technol, Dept Informat Management, Jungli 320, Taiwan	Lin, PC (reprint author), Natl Kaohsiung Univ Appl Sci, Inst Finance & Informat, Dept Informat Management, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.	cobol@cc.kuas.edu.tw; lety@cc.kuas.edu.tw					Ahn BS, 2000, EXPERT SYST APPL, V18, P65, DOI 10.1016/S0957-4174(99)00053-6; ALTMAN E., 1968, J FINANC, P589; ALUALLIM H, 1992, P 9 CAN C ART INT, P38; Back B, 1996, EXPERT SYST APPL, V11, P407, DOI 10.1016/S0957-4174(96)00055-3; Blum M., 1974, J ACCOUNTING RES SPR, P1; BORITZ JE, 1995, EXPERT SYST APPL, V9, P503; Chen JS, 2002, J OPER RES SOC JPN, V45, P373; DEAKIN EB, 1972, J ACCOUNTING RES, V10, P167, DOI 10.2307/2490225; Donato JM, 1999, FUTURE GENER COMP SY, V15, P433, DOI 10.1016/S0167-739X(98)00086-7; Eberhart RC, 1995, P 6 INT S MICR HUM S, P39, DOI DOI 10.1109/MHS.1995.494215; Emmanouilidis C., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), DOI 10.1109/IJCNN.1999.830875; Fogel L. J., 1994, COMPUTATIONAL INTELL; HOLLAND JH, 1975, ADAPTATION NATURAL A; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JO H, 1996, EXPERT SYSTEMS APPL, V4, P415; Johnson W, 2001, FILM QUART, V54, P53, DOI 10.1525/fq.2001.54.3.53; Kennedy J, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P303, DOI 10.1109/ICEC.1997.592326; KENNEDY J, 1997, P INT C SYST MAN CYB; Kennedy J., 1995, P IEEE INT C NEUR NE, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Koza J. R., 1992, GENETIC PROGRAMMING; Laitinen E.K, 2000, INT REV FINANCIAL AN, V9, P327, DOI 10.1016/S1057-5219(00)00039-9; Lee KC, 1996, DECIS SUPPORT SYST, V18, P63, DOI 10.1016/0167-9236(96)00018-8; Leshno M, 1996, NEUROCOMPUTING, V10, P125, DOI 10.1016/0925-2312(94)00060-3; Lin FY, 2001, KNOWL-BASED SYST, V14, P189, DOI 10.1016/S0950-7051(01)00096-X; LIN PC, 2004, ASIAN J INFORM TECHN, V3, P197; Liu H., 1996, P 13 INT C MACH LEAR, P319; OHLSON JA, 1980, J ACCOUNTING RES, V18, P109, DOI 10.2307/2490395; RECHENBERG I, 1994, COMPUTATIOANL INTELL; SHIRATA CY, 2000, 4 INT C KNOWL BAS IN, P663; Simon H., 1999, NEURAL NETWORKS COMP; SRINIVAS M, 1994, IEEE T COMPUT, P18; Sung T.K., 1999, J MANAGE INFORM SYST, V16, P63; Wallrafen J., 1996, Proceedings of the Twenty-Ninth Hawaii International Conference on System Sciences, DOI 10.1109/HICSS.1996.495427; WILSON RL, 1994, DECIS SUPPORT SYST, V11, P545, DOI 10.1016/0167-9236(94)90024-8; ZMIJEWSKI ME, 1984, J ACCOUNTING RES, V22, P59, DOI 10.2307/2490859	35	15	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	MAR	2006	19	1					84	91		10.1016/j.knosys.2005.11.006		8	Computer Science, Artificial Intelligence	Computer Science	035YD	WOS:000237036800010	
J	Ulintz, PJ; Zhu, J; Qin, ZHS; Andrews, PC				Ulintz, PJ; Zhu, J; Qin, ZHS; Andrews, PC			Improved classification of mass spectrometry database search results using newer machine learning approaches	MOLECULAR & CELLULAR PROTEOMICS			English	Article							PROTEIN IDENTIFICATION; SPECTRAL DATA; STATISTICAL SIGNIFICANCE; YEAST PROTEOME; TANDEM; ALGORITHM; MS/MS; VALIDATION; PEPTIDES; MODEL	Manual analysis of mass spectrometry data is a current bottleneck in high throughput proteomics. In particular, the need to manually validate the results of mass spectrometry database searching algorithms can be prohibitively time-consuming. Development of software tools that attempt to quantify the confidence in the assignment of a protein or peptide identity to a mass spectrum is an area of active interest. We sought to extend work in this area by investigating the potential of recent machine learning algorithms to improve the accuracy of these approaches and as a flexible framework for accommodating new data features. Specifically we demonstrated the ability of boosting and random forest approaches to improve the discrimination of true hits from false positive identifications in the results of mass spectrometry database search engines compared with thresholding and other machine learning approaches. We accommodated additional attributes obtainable from database search results, including a factor addressing proton mobility. Performance was evaluated using publically available electrospray data and a new collection of MALDI data generated from purified human reference proteins.	Univ Michigan, Natl Resource Proteom & Pathways, Bioinformat Program, Sch Publ Hlth, Ann Arbor, MI 48109 USA; Univ Michigan, Dept Stat, Sch Publ Hlth, Ann Arbor, MI 48109 USA; Univ Michigan, Dept Biostat, Sch Publ Hlth, Ann Arbor, MI 48109 USA	Ulintz, PJ (reprint author), Univ Michigan, Natl Resource Proteom & Pathways, Bioinformat Program, Sch Publ Hlth, 300 N Ingalls Bldg,Rm 1196, Ann Arbor, MI 48109 USA.	pulintz@umich.edu	Qin, Zhaohui/E-8196-2011				Anderson DC, 2003, J PROTEOME RES, V2, P137, DOI 10.1021/pr0255854; BAFNA V, 2001, BIOINFORMATICS S1, V17, P13; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CARUANA R, 2003, P ANN C AM MED INF A; Craig R, 2004, BIOINFORMATICS, V20, P1466, DOI 10.1093/bioinformatics/bth092; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; ENG JK, 1994, J AM SOC MASS SPECTR, V5, P976, DOI 10.1016/1044-0305(94)80016-2; Eriksson J, 2004, J PROTEOME RES, V3, P32, DOI 10.1021/pr034048y; Fenyo D, 2003, ANAL CHEM, V75, P768, DOI 10.1021/ac0258709; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Geer LY, 2004, J PROTEOME RES, V3, P958, DOI 10.1021/pr0499491; Graumann J, 2004, MOL CELL PROTEOMICS, V3, P226, DOI 10.1074/mcp.M300099-MCP200; Hastie T, 2001, ELEMENTS STAT LEARNI; Havilio M, 2003, ANAL CHEM, V75, P435, DOI 10.1021/ac0258913; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; Kapp EA, 2003, ANAL CHEM, V75, P6251, DOI 10.1021/ac034616t; Keller Andrew, 2002, OMICS A Journal of Integrative Biology, V6, P207, DOI 10.1089/153623102760092805; Keller A, 2002, ANAL CHEM, V74, P5383, DOI 10.1021/ac025747h; Link AJ, 1999, NAT BIOTECHNOL, V17, P676; MacCoss MJ, 2002, ANAL CHEM, V74, P5593, DOI 10.1021/ac025826t; Moore RE, 2002, J AM SOC MASS SPECTR, V13, P378, DOI 10.1016/S1044-0305(02)00352-5; Nesvizhskii AI, 2003, ANAL CHEM, V75, P4646, DOI 10.1021/ac0341261; Peng JM, 2003, J PROTEOME RES, V2, P43, DOI 10.1021/pr025556v; PERKINS D, 1997, ELECTROPHORESIS, V20, P3551; Platt J., 1999, ADV LARGE MARGIN CLA, P61; Sadygov RG, 2003, ANAL CHEM, V75, P3792, DOI 10.1021/ac034157w; STRAHLER JR, 2005, 53 AM SOC MASS SPECT; Sun W, 2004, MOL CELL PROTEOMICS, V3, P1194, DOI 10.1074/mcp.M400120-MCP200; Tabb DL, 2004, ANAL CHEM, V76, P1243, DOI 10.1021/ac0351163; Vapnik V.N., 1999, NATURE STAT LEARNING, P138; Washburn MP, 2001, NAT BIOTECHNOL, V19, P242, DOI 10.1038/85686; Wysocki VH, 2000, J MASS SPECTROM, V35, P1399, DOI 10.1002/1096-9888(200012)35:12<1399::AID-JMS86>3.0.CO;2-R; Zhang N, 2002, PROTEOMICS, V2, P1406, DOI 10.1002/1615-9861(200210)2:10<1406::AID-PROT1406>3.0.CO;2-9	34	39	42	AMER SOC BIOCHEMISTRY MOLECULAR BIOLOGY INC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3996 USA	1535-9476		MOL CELL PROTEOMICS	Mol. Cell. Proteomics	MAR	2006	5	3					497	509		10.1074/mcp.M500233-MCP200		13	Biochemical Research Methods	Biochemistry & Molecular Biology	023RB	WOS:000236142800007	
J	Krasnopolsky, VM; Fox-Rabinovitz, MS				Krasnopolsky, Vladimir M.; Fox-Rabinovitz, Michael S.			Complex hybrid models combining deterministic and machine learning components for numerical climate modeling and weather prediction	NEURAL NETWORKS			English	Article; Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc		neural networks; machine learning; numerical modeling; climate; weather; hybrid model	NEURAL-NETWORK; ATMOSPHERIC MODEL; ACCURATE; RADIATION	A new practical application of neural network (NN) techniques to environmental numerical modeling has been developed. Namely, a new type of numerical model, a complex hybrid environmental model based on a synergetic combination of deterministic and machine learning model components, has been introduced. Conceptual and practical possibilities of developing hybrid models are discussed in this paper for applications to climate modeling and weather prediction. The approach presented here uses NN as a statistical or machine learning technique to develop highly accurate and fast emulations for time consuming model physics components (model physics parameterizations). The NN emulations of the most time consuming model physics components, short and long wave radiation parameterizations or full model radiation, presented in this paper are combined with the remaming deterministic components (like model dynamics) of the original complex environmental model-a general circulation model or global climate model (GCM)-to constitute a hybrid GCM (HGCM). The parallel GCM and HGCM simulations produce very similar results but HGCM is significantly faster. The speed-up of model calculations opens the opportunity for model improvement. Examples of developed HGCMs illustrate the feasibility and efficiency of the new approach for modeling complex multidimensional interdisciplinary systems. (c) 2006 Elsevier Ltd. All rights reserved.	NOAA, SAIC, EMC, NCEP, Camp Springs, MD 20746 USA; Univ Maryland, Earth Syst Sci Interdisciplinary Ctr, College Pk, MD USA	Krasnopolsky, VM (reprint author), NOAA, SAIC, EMC, NCEP, 5200 Auth Rd, Camp Springs, MD 20746 USA.	vladimir.krasnopolsky@noaa.gov					Aires F, 2004, J GEOPHYS RES-ATMOS, V109, DOI 10.1029/2003JD004175; Aires F, 1999, IEEE T NEURAL NETWOR, V10, P1502, DOI 10.1109/72.809096; Chevallier F, 2000, Q J ROY METEOR SOC, V126, P761, DOI 10.1256/smsqj.56317; Chevallier F, 1998, J APPL METEOROL, V37, P1385, DOI 10.1175/1520-0450(1998)037<1385:ANNAFA>2.0.CO;2; Chevallier F, 2001, J APPL METEOROL, V40, P1445, DOI 10.1175/1520-0450(2001)040<1445:EOTJOI>2.0.CO;2; Chou M-D., 2001, TECHNICAL REPORT SER, V19; COLLINS WD, 2002, J GEOPHYS RES, V107, P1; Collins WD, 2001, J ATMOS SCI, V58, P3224, DOI 10.1175/1520-0469(2001)058<3224:POGCOF>2.0.CO;2; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; KRASNOPOLSKY V, 1997, 792 WMO TD CAS JSC; Krasnopolsky V. M., 1999, CANADIAN J REMOTE SE, V25, P486; Krasnopolsky VM, 2005, MON WEATHER REV, V133, P1370, DOI 10.1175/MWR2923.1; KRASNOPOLSKY VM, 1995, J GEOPHYS RES-OCEANS, V100, P11033, DOI 10.1029/95JC00857; Krasnopolsky VM, 2003, NEURAL NETWORKS, V16, P321, DOI 10.1016/S0893-6080(03)00027-3; Krasnopolsky VM, 2002, OCEAN MODEL, V4, P363, DOI 10.1016/S1463-5003(02)00010-0; KRASNOPOLSKY VM, 2000, P 2 C ART INT AMS LO, P27; Krasnopolsky VM, 2005, IEEE IJCNN, P2661; Lee JW, 1997, NEURAL COMPUT, V9, P937, DOI 10.1162/neco.1997.9.5.937; Nguyen D., 1990, P INT JOINT C NEUR N, V3, P21, DOI DOI 10.1109/IJCNN.1990.137819; Schoendorf J, 2003, GEOPHYS RES LETT, V30, DOI 10.1029/2002GL016649; Tolman HL, 2005, OCEAN MODEL, V8, P253, DOI 10.1016/j.ocemod.2003.12.008; TOLMAN HL, 2004, 8 INT WORKSH WAV HIN; WESSELS LFA, 1992, IEEE T NEURAL NETWOR, V3, P899, DOI 10.1109/72.165592; 1998, J CLIMATE, V11	26	11	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	MAR	2006	19	2					122	134		10.1016/j.neunet.2006.01.002		13	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	042KU	WOS:000237527600003	
J	Bhattacharya, B; Solomatine, DP				Bhattacharya, B.; Solomatine, D. P.			Machine learning in soil classification	NEURAL NETWORKS			English	Article; Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc		soil classification; cone penetration testing; machine learning; ANN; decision trees; SVM		In a number of engineering problems, e.g. in geotechnics, petroleum engineering, etc. intervals of measured series data (signals) are to be attributed a class maintaining the constraint of contiguity and standard classification methods could be inadequate. Classification in this case needs involvement of an expert who observes the magnitude and trends of the signals in addition to any a priori information that might be available. In this paper, an approach for automating this classification procedure is presented. Firstly, a segmentation algorithm is developed and applied to segment the measured signals. Secondly, the salient features of these segments are extracted using boundary energy method. Based on the measured data and extracted features to assign classes to the segments classifiers are built; they employ Decision Trees, ANN and Support Vector Machines. The methodology wits tested in classifying sub-surface soil using measured data from Cone Penetration Testing and satisfactory results were obtained. (c) 2006 Elsevier Ltd. All rights reserved.	UNESCO, Hydroinformat & Knowledge Management Dept, IHE, NL-2601 DA Delft, Netherlands	Bhattacharya, B (reprint author), UNESCO, Hydroinformat & Knowledge Management Dept, IHE, POB 3015, NL-2601 DA Delft, Netherlands.	b.bhattacharya@unesco-ihe.org; d.solomatine@unesco-ihe.org					Bhattacharya B, 2003, FR ART INT, V104, P489; Bhattacharya B, 2005, IEEE IJCNN, P2694; COERTS A, 1996, ANAL STAT CONE PENET; Funtoura Costa L., 2001, SHAPE ANAL CLASSIFIC; Gordon AD, 1996, COMPUT STAT DATA AN, V21, P17, DOI 10.1016/0167-9473(95)00005-4; Hawkins DM, 1973, MATH GEOL, V5, P389; HUIJZER GP, 1992, THESIS FREE U AMSTER; Juang CH, 1996, J GEOTECH ENG-ASCE, V122, P1, DOI 10.1061/(ASCE)0733-9410(1996)122:1(1); Kerzner M. H., 1986, IMAGE PROCESSING WEL; Kumar JK, 2000, J GEOTECH GEOENVIRON, V126, P632, DOI 10.1061/(ASCE)1090-0241(2000)126:7(632); VANVLIET LJ, 1993, P 8 SCAND C IM AN, V2, P1403; WAGSTAFF K, 2002, THESIS CORNELL U US; WEBSTER R, 1978, J SOIL SCI, V29, P388; WEERTS HJT, 1996, COMPLEX CONFINING LA; Witten I. H., 2000, DATA MINING PRACTICA; YOUNG IT, 1974, INFORM CONTROL, V25, P357, DOI 10.1016/S0019-9958(74)91038-9; Zhang ZJ, 1999, J GEOTECH GEOENVIRON, V125, P179, DOI 10.1061/(ASCE)1090-0241(1999)125:3(179); *RHUL, 2005, COMP LEARN RES CTR R	18	13	14	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	MAR	2006	19	2					186	195		10.1016/j.neunet.2006.01.005		10	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	042KU	WOS:000237527600009	
J	Bhattacharya, B; Solomatine, DP				Bhattacharya, B; Solomatine, DP			Machine learning in sedimentation modelling	NEURAL NETWORKS			English	Article; Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc		sedimentation; machine learning; ANN; model trees	NEURAL-NETWORKS; TREES	The paper presents machine learning (ML) models that predict sedimentation in the harbour basin of the Port of Rotterdam. The important factors affecting the sedimentation process such as waves, wind, tides, surge, river discharge, etc. are Studied, the corresponding time series data is analysed, missing values are estimated and the most important variables behind the process are chosen as the inputs. Two ML methods are used: MLP ANN and M5 model tree. The latter is a collection of piece-wise linear regression models, each being all expert for a particular region of the input space. The models are trained on the data collected during 1992-1998 and tested by the data of 1999-2000. The predictive accuracy of the models is found to be adequate for the potential use in the operational decision making. (c) 2006 Elsevier Ltd. All rights reserved.	UNESCO, Hydroinformat & Knowledge Management Dept, IHE, NL-2601 DA Delft, Netherlands	Bhattacharya, B (reprint author), UNESCO, Hydroinformat & Knowledge Management Dept, IHE, POB 3015, NL-2601 DA Delft, Netherlands.	b.bhattacharya@unesco-ihe.org; d.solomatine@unesco-ihe.org					Bhattacharya B., 2004, P 6 INT C HYDR, P1663; BHATTACHARYA B, 2003, P 30 IAHR C THESS GR, VD, P209; Bhattacharya B, 2005, NEUROCOMPUTING, V63, P381, DOI 10.1016/j.neucom.2004.04.016; BHATTACHARYA B, 2003, P 11 EUR S ART NEUR, P407; BIERENS RWP, 2002, PIANC B, V109, P43; Breiman L, 1984, CLASSIFICATION REGRE; DEKOK JM, 2002, COMMUNICATION; DEKOK JM, 1994, THESIS UTRECHT U UTR; Haykin S., 1999, NEURAL NETWORKS COMP; MERCKELBACH LM, 1996, NZ9602 MIN TRANSP PU; Nagy HM, 2002, J HYDRAUL ENG-ASCE, V128, P588, DOI 10.1061/(ASCE)0733-9429(2002)128:6(588); Pyle Dorian, 1999, DATA PREPARATION DAT; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Shannon E., 1948, BELL SYST TECH J, V27, P623; SOLOMATINE DP, 2006, NEURAL NETWORKS; Solomatine DP, 2003, HYDROLOG SCI J, V48, P399, DOI 10.1623/hysj.48.3.399.45291; van Rijn LC, 1993, PRINCIPLES SEDIMENT; Verdu S, 1998, IEEE T INFORM THEORY, V44, P2057, DOI 10.1109/18.720531; VUURENS RS, 2001, THESIS DELFT U TECHN; WINTERWERP JC, 2001, COASTAL ESTUARINE FI; Witten I. H., 2000, DATA MINING PRACTICA; *AM SOC CIV ENG TA, 2000, J HYDRAUL ENG-ASCE, V5, P115; *WL DELFT HYDR, 2001, WL2001003 WL DELFT H	23	13	13	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	MAR	2006	19	2					208	214		10.1016/j.neunet.2006.01.007		7	Computer Science, Artificial Intelligence	Computer Science	042KU	WOS:000237527600011	
J	Shrestha, DL; Solomatine, DP				Shrestha, DL; Solomatine, DP			Machine learning approaches for estimation of prediction interval for the model output	NEURAL NETWORKS			English	Article; Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN 2005)	JUL 31-AUG 04, 2005	Montreal, CANADA	Int Neural Network Soc, IEEE Computat Intelligence Soc		prediction interval; model uncertainty; prediction interval coverage probability; mean prediction interval	NEURAL-NETWORK MODELS; UNCERTAINTY; CONFIDENCE	A novel method for estimating prediction uncertaillty using machine learning techniques is presented. Uncertainty is expressed in the form of the two quantiles (constituting the prediction interval) of the underlying distribution of prediction errors. The idea is to partition the input space into different zones or clusters having similar model errors using fuzzy c-means clustering. The prediction interval is constructed for each cluster on the basis of empirical distributions of the errors associated with all instances belonging to the cluster under consideration and propagated from each cluster to the examples according to their membership grades in each cluster. Then a regression model is built for in-sample data using computed prediction limits as targets. and finally. this model is applied to estimate the prediction intervals (limits) for out-of-sample data. The method was tested oil artificial and real hydrologic data sets using various machine learning techniques. Preliminary results show that the method is superior to other methods estimating the prediction interval. A new method for evaluating performance for estimating prediction interval is proposed as well. (c) 2006 Elsevier Ltd. All rights reserved.	UNESCO, Dept Hydroinformat & Knowledge Management, IHE, NL-2601 DA Delft, Netherlands	Shrestha, DL (reprint author), UNESCO, Dept Hydroinformat & Knowledge Management, IHE, POB 3015, NL-2601 DA Delft, Netherlands.	d.shrestha@unesco-ihe.org	Shrestha, Durga/B-5610-2013	Shrestha, Durga/0000-0002-5545-1736			Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BEVEN K, 1992, HYDROL PROCESS, V6, P279, DOI 10.1002/hyp.3360060305; Bezdek J. C., 1981, PATTERN RECOGNITION; BHATTACHARYA B, 2006, NEURAL NETWORKS; Chatfield C., 2000, TIME SERIES FORECAST; Chinnam RB, 1998, IEEE T NEURAL NETWOR, V9, P1515, DOI 10.1109/72.728401; Chryssolouris G, 1996, IEEE T NEURAL NETWOR, V7, P229, DOI 10.1109/72.478409; Dunn J. C., 1973, Journal of Cybernetics, V3; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Harnett D.L., 1980, INTRO STAT ANAL; Heskes T, 1997, ADV NEUR IN, V9, P176; Kottegoda NT, 1980, STOCHASTIC WATER RES; KRZYSZTOFOWICZ R, 2000, J HYDROL, V249, P2; LEONARD JA, 1992, IEEE T NEURAL NETWOR, V3, P624, DOI 10.1109/72.143377; Maskey S, 2004, ADV WATER RESOUR, V27, P889, DOI 10.1016/j.advwatres.2004.07.001; Mitchell TM, 1998, MACHINE LEARNING; NIX D, 1994, P IJCNN 94, P55; PENNY WD, 1997, TR971 DEP EL EL ENG; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Solomatine D P, 2004, P INT JOINT C NEUR N, P1163; SOLOMATINE DP, 2006, NEURAL NETWORKS; SOLOMATINE DP, 2000, P INT JOINT C NEUR N, P1173; Solomatine DP, 2003, HYDROLOG SCI J, V48, P399, DOI 10.1623/hysj.48.3.399.45291; Tibshirani R, 1996, NEURAL COMPUT, V8, P152, DOI 10.1162/neco.1996.8.1.152; Witten I. H., 2000, DATA MINING PRACTICA; WONNACOTT TH, 1996, INTRO STAT; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	28	35	35	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	MAR	2006	19	2					225	235		10.1016/j.neunet.2006.01.012		11	Computer Science, Artificial Intelligence	Computer Science	042KU	WOS:000237527600013	
J	Chandra, A; Yao, X				Chandra, A; Yao, X			Evolving hybrid ensembles of learning machines for better generalisation	NEUROCOMPUTING			English	Article; Proceedings Paper	13th European Symposium on Artificial Neural Networks (ESANN)	APR, 2005	Brugge, BELGIUM			ensemble learning; evolutionary computation; hybrid ensembles; multi-objective optimisation; neuroevolution	MULTIPLE CLASSIFIER SYSTEMS; NEURAL-NETWORKS; NEGATIVE CORRELATION; DIVERSE; COMBINATION; ALGORITHMS; ACCURATE	Ensembles of learning machines have been formally and empirically shown to outperform (generalise better than) single predictors in many cases. Evidence suggests that ensembles generalise better when they constitute members which form a diverse and accurate set. Additionally, there have been a multitude of theories on how one call enforce diversity within a combined predictor setup. We recently attempted to integrate these theories together into a co-evolutionary framework with a view to synthesising new evolutionary ensemble learning algorithms using the fact that multi-objective evolutionary optimisation is a formidable ensemble construction technique. This paper explicates oil the intricacies of the proposed framework in addition to presenting detailed empirical results and comparisons with a wide range of algorithms in tile machine learning literature. The framework treats diversity and accuracy as evolutionary pressures which are exerted at multiple levels of abstraction and is shown to be effective. (c) 2006 Elsevier B.V. All rights reserved,	Univ Birmingham, Sch Comp Sci, Ctr Excellence Res Computat Intelligence & Applic, Birmingham B15 2TT, W Midlands, England	Chandra, A (reprint author), Univ Birmingham, Sch Comp Sci, Ctr Excellence Res Computat Intelligence & Applic, Birmingham B15 2TT, W Midlands, England.	a.chandra@cs.bham.ac.uk; x.yao@cs.bham.ac.uk					Abbass H. A., 2001, P C EV COMP 2001 CEC, P971, DOI 10.1109/CEC.2001.934295; ABBASS HA, 2003, IEEE 2003 C EV COMP, V3, P2074; Abbass HA, 2003, NEURAL COMPUT, V15, P2705, DOI 10.1162/089976603322385126; ABBASS HA, 2000, P 14 AUSTR JOINT C A, P1; ABBASS HA, 2003, P 16 AUSTR JOINT C A, P554; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOERS E, 1995, 9514 LEID U DEP COMP; Breiman L., 1996, 460 U CAL STAT DEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Brown G., 2005, J INFORM FUSION, V6, P5; BROWN G., 2004, THESIS U BIRMINGHAM; CHANDRA A, 2005, P 13 EUR S ART NEUR, P253; Chandra A, 2004, LECT NOTES COMPUT SC, V3177, P619; CHANDRA A, 2005, IN PRESS COMPUTATION; CHANDRA A, 2004, EVOLUTIONARY APPROAC; CHANDRA A, 2006, IN PRESS J MATH MODE; Chandra A., 2004, THESIS U BIRMINGHAM; DARWEN P, 1996, LECT NOTES COMPUTER, V1141, P398; Deb K., 2001, MULTIOBJECTIVE OPTIM; Dietterich T., 1998, AI MAG, V18, P97; Faber V., 1994, LOS ALAMOS SCI, V22, P138; Forrest S, 1993, EVOL COMPUT, V1, P191, DOI 10.1162/evco.1993.1.3.191; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Gutta S, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P164, DOI 10.1109/AFGR.1996.557259; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Jin YC, 2004, LECT NOTES COMPUT SC, V3102, P688; Kottathra K, 1996, J NETW COMPUT APPL, V19, P135, DOI 10.1006/jnca.1996.0011; Krogh A, 1995, NIPS, V7, P231; Langdon W. B., 2002, Genetic Programming. 5th European Conference, EuroGP 2002. Proceedings (Lecture Notes in Computer Science Vol.2278); Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Opitz D., 1999, J ARTIFICIAL INTELLI, P169; Opitz DW, 1996, ADV NEUR IN, V8, P535; Oza N. C., 2001, LECT NOTES COMPUTER, P238; Oza N. C, 2001, THESIS U CALIFORNIA; Sharkey AJC, 2002, LECT NOTES COMPUT SC, V2364, P108; Sharkey AJC, 1999, COMBINING ARTIFICIAL, P1; Sharkey AJC, 1997, KNOWL ENG REV, V12, P231, DOI 10.1017/S0269888997003123; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Taylor C., 1994, MACHINE LEARNING NEU; Tumer K., 1996, PATTERN RECOGN, V29, P341, DOI DOI 10.1016/0031-3203(95)00085-2; UEDA N, 1996, P INT C NEUR NETW, P90; Valentini G, 2002, LECT NOTES COMPUT SC, V2486, P3; WANG W, 2001, P INT JOINT C NEUR N, V4, P2376; Wang WJ, 2000, LECT NOTES COMPUT SC, V1857, P240; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; Yao X, 1999, P IEEE, V87, P1423; Yates WB, 1996, NEURAL COMPUT APPL, V4, P114, DOI 10.1007/BF01413747	53	34	37	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2006	69	7-9					686	700		10.1016/j.neucom.2005.12.014		15	Computer Science, Artificial Intelligence	Computer Science	018XB	WOS:000235797000009	
J	Canu, S; Smola, A				Canu, S; Smola, A			Kernel methods and the exponential family	NEUROCOMPUTING			English	Article; Proceedings Paper	13th European Symposium on Artificial Neural Networks (ESANN)	APR, 2005	Brugge, BELGIUM			kernel methods; exponential families; novelty detection		The success of support vector machine (SVM) has given rise to the development of a new class of theoretically elegant learning machines which use a central concept of kernels and the associated reproducing kernel Hilbert space (RKHS). Exponential families, a standard tool in statistics, can be used to unify many existing machine learning algorithms based on kernels (such as SVM) and to invent novel ones quite effortlessly. A new derivation of the novelty detection algorithm based on the one class SVM is proposed to illustrate the power of the exponential family model in an RKHS. (c) 2005 Published by Elsevier B.V.	INSA, CNRS, FRE 2645, I PSI, St Etienne, France; Australian Natl Univ, RSISE, Canberra, ACT 0200, Australia	Canu, S (reprint author), INSA, CNRS, FRE 2645, I PSI, St Etienne, France.	Stephane.Canu@insa-rouen.fr; Alex.Smola@nicta.com.au					Abdallah F, 2004, IEEE T SIGNAL PROCES, V52, P2798, DOI 10.1109/TSP.2004.834346; ARONSZAJN N, 1944, P CAMBRIDGE PHILOS S, V39, P133; CANU S, 2003, ADV LEARNING THEORY, V3, P89; DESOBRY F, 2005, IEEE T SIGNAL PROCES, V54, P115; DESOBRY F, 2005, KERNEL METHODS MINIM; DESOBRY F, 2003, IEEE ICASSP; Gous A, 1998, J COMPUT GRAPH STAT, V7, P388, DOI 10.2307/1390711; LE QV, 2005, ICML; Scholkopf B, 2001, NEURAL COMPUT, V13; Scholkopf B., 2001, LEARNING KERNELS; Schwartz L., 1964, J ANAL MATH, V13, P115, DOI 10.1007/BF02786620; VERT R, 2005, CONSISTENCY CONVERGE; WACHBA G, 1990, SERIES APPL MATH, V59	13	7	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2006	69	7-9					714	720		10.1016/j.neucom.2005.12.009		7	Computer Science, Artificial Intelligence	Computer Science	018XB	WOS:000235797000011	
J	Nanni, L; Lumini, A				Nanni, L; Lumini, A			A reliable method for HIV-1 protease cleavage site prediction	NEUROCOMPUTING			English	Article						HIV-1 protease; support vector machine; fusion of classifiers		Recently, several works have approached the HIV-1 protease specificity problem by applying techniques from machine learning. In this work, an encoding scheme based on the BLOSUM50 matrix is investigated. We show that combining a linear discriminant classifier and radial basis function support vector machine we obtain performance higher than previously published in the literature. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bologna, DEIS, IEIIT, CNR, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, IEIIT, CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it	Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354			Beck ZQ, 2000, VIROLOGY, V274, P391, DOI 10.1006/viro.2000.0420; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 1998, ADV ENG SOFTW, V29, P119, DOI 10.1016/S0965-9978(98)00046-5; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Duda R. O., 2001, PATTERN CLASSIFICATI; HUANG L, 2005, 3 AS PAC BIOINF C 7, P312; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KRAUSE M, 2000, HDB INFORM SECURITY; Kuncheva LI, 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140; Narayanan A., 2002, BIOINFORMATICS, V18, P5; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Thompson TB, 1995, J THEOR BIOL, V177, P369, DOI 10.1006/jtbi.1995.0254	14	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2006	69	7-9					838	841		10.1016/j.neucom.2005.09.004		4	Computer Science, Artificial Intelligence	Computer Science	018XB	WOS:000235797000022	
J	Nanni, L				Nanni, L			Ensemble of classifiers for protein fold recognition	NEUROCOMPUTING			English	Article						ensemble of classifiers; protein fold recognition		Predicting the three-dimensional structure of a protein from its amino-acid sequence is an important problem in bioinformatics and a challenging task for machine learning algorithms. In this paper, we investigate an ensemble of classifiers, applied for protein fold recognition, and tested it on a real-world dataset. The obtained results are very encouraging, our results improved the average predictive accuracy obtained in previously published work. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bologna, DEIS, IEIIT, CNR, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, IEIIT, CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it					BOLOGNA G, 2002, P 9 INT C NEUR INF P, V5, P2492; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chung IF, 2003, LECT NOTES COMPUT SC, V2714, P1159; Dietterich Thomas G., 2000, P 1 INT WORKSH MULT, P1; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Duda R., 2000, PATTERN CLASSIFICATI; Fierrez-Aguilar J, 2005, LECT NOTES COMPUT SC, V3546, P523; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Okun O., 2004, P 2 EUR WORKSH DAT M, P51; Pal NR, 2003, LECT NOTES COMPUT SC, V2714, P1176	11	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2006	69	7-9					850	853		10.1016/j.neucom.2005.08.006		4	Computer Science, Artificial Intelligence	Computer Science	018XB	WOS:000235797000025	
J	Nanni, L				Nanni, L			A reliable method for the diagnosis of gastric carcinoma	NEUROCOMPUTING			English	Article						gastric carcinoma; ensemble of classifiers; feature selection		Predicting the different levels of gastric carcinoma from clinical and histopathological investigations is an important problem in bioinformatics and a challenging task for machine learning algorithms. In this paper, we have investigated an ensemble of classifiers and tested it oil a real-world dataset. A genetic algorithm is applied to select the most relevant features. The obtained results are very encouraging, our results improve the average predictive accuracy obtained in previously published works. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bologna, DEIS, IEIIT, CNR, Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, IEIIT, CNR, Viale Risorgimento 2, Bologna, Italy.	lnanni@deis.unibo.it					Duda R., 2000, PATTERN CLASSIFICATI; Goldberg DE, 1989, GENETIC ALGORITHMS S; Guvenir HA, 2004, ARTIF INTELL MED, V31, P231, DOI 10.1016/j.artmed.2004.03.003; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Little R. J. A., 2002, STAT ANAL MISSING DA; Yokota T, 1999, CAN J SURG, V42, P371	7	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2006	69	7-9					862	865		10.1016/j.neucom.2005.08.001		4	Computer Science, Artificial Intelligence	Computer Science	018XB	WOS:000235797000028	
J	Nanni, L				Nanni, L			Machine learning algorithms for T-cell epitopes prediction	NEUROCOMPUTING			English	Article						support vector data description; support vector machine; T-cell epitope prediction	NEURAL-NETWORK; SEQUENCES	The T-cell receptor, a major histocompatibility complex (MHC) molecule, and a bound antigenic peptide, play major roles in the process of antigen-specific T-cell activation. Performance of the various classifiers was compared by the area under their receiver operating characteristic curve. The fusion of machine-learning-type classifiers showed improved performance over the best results previously published in the literature. In particular, the best performance is achieved combining support vector machine and support vector data description. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bologna, DEIS, IEIIT, CNR, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, IEIIT, CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it					Duda R. O., 2001, PATTERN CLASSIFICATI; HAMMER J, 1995, CURR OPIN IMMUNOL, V7, P263, DOI 10.1016/0952-7915(95)80013-1; Honeyman MC, 1998, NAT BIOTECHNOL, V16, P966, DOI 10.1038/nbt1098-966; HUANG L, 2005, P 3 AS PAC BIOINF C, P312; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; MADDEN DR, 1995, ANNU REV IMMUNOL, V13, P587, DOI 10.1146/annurev.immunol.13.1.587; Milik M, 1998, NAT BIOTECHNOL, V16, P753, DOI 10.1038/nbt0898-753; ROGNVALDSSON T, 2003, BIOINFORMATICS, V20, P1702; Sturniolo T, 1999, NAT BIOTECHNOL, V17, P555; TAX DMJ, 2001, ONE CLASS CLASSIFICA; Zhao YD, 2003, BIOINFORMATICS, V19, P1978, DOI 10.1093/bioinformatics/btg255	12	13	13	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	MAR	2006	69	7-9					866	868		10.1016/j.neucom.2005.08.005		3	Computer Science, Artificial Intelligence	Computer Science	018XB	WOS:000235797000029	
J	Zhan, YQ; Shen, DG				Zhan, YQ; Shen, DG			An adaptive error penalization method for training an efficient and generalized SVM	PATTERN RECOGNITION			English	Article						support vector machine; training method; computational efficiency; generalization ability	SUPPORT VECTOR MACHINES	A novel training method has been proposed for increasing efficiency and generalization of support vector machine (SVM). The efficiency of SVM in classification is directly determined by the number of the support vectors used, which is often huge in the complicated classification problem in order to represent a highly convoluted separation hypersurface for better nonlinear classification. However, the separation hypersurface of SVM might be unnecessarily over-convoluted around extreme outliers, as these outliers can easily dominate the objective function of SVM. This situation eventually affects the efficiency and generalization of SVM in classifying unseen testing samples. To avoid this problem, we propose a novel objective function for SVM, i.e., an adaptive penalty term is designed to suppress the effects of extreme outliers, thus simplifying the separation hypersurface and increasing the classification efficiency. Since maximization of the margin distance of hypersurface is no longer dominated by those extreme outliers, our generated SVM tends to have a wider margin, i.e., better generalization ability. Importantly, as our designed objective function can be reformulated as a dual problem, similar to that of standard SVM, any existing SVM training algorithm can be borrowed for the training of our proposed SVM. The performances of our method have been extensively tested on the UCI machine learning repository, as well as a real clinical problem, i.e., tissue classification in prostate ultrasound images. Experimental results show that our method is able to simultaneously increase the classification efficiency and the generalization ability of the SVM. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA; Univ Penn, Dept Radiol, Sect Biomed Image Anal, Philadelphia, PA 19104 USA; Johns Hopkins Univ, Ctr Comp Integrated Surg Syst & Technol, Baltimore, MD USA	Zhan, YQ (reprint author), Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.	yzhan@cs.jhu.edu; Dinggang.Shen@uphs.upenn.edu					BROWN MPS, 2004, GENETICS, V97, P262; Burges C. J. C., 1996, P 13 INT C MACH LEAR, P71; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; HETTICH S, 1998, REPOSITORY MACHINE; JOACHIMS T, 2001, P 24 ANN INT ACM SIG; Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027; LeCun Y., 1995, ICANN '95. International Conference on Artificial Neural Networks. Neuronimes '95 Scientific Conference; LEE YJ, 2001, P 1 SIA INT C DAT MI; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Osuna E., 1998, REDUCING RUN TIME CO; Scholkopf B., 2002, LEARNING KERNELS; TIAN Y, 2003, IEEE WORKSH PERF EV; Vapnik V. N., 1995, NATURAL STAT LEARNIN; Wan V, 2005, IEEE T SPEECH AUDI P, V13, P203, DOI 10.1109/TSA.2004.841042; ZHAN Y, 2003, MED IM COMP COMP ASS	17	7	9	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	2006	39	3					342	350		10.1016/j.patcog.2005.09.008		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	007PO	WOS:000234981800003	
J	Nanni, L; Lumini, A				Nanni, L; Lumini, A			FuzzyBagging: A novel ensemble of classifiers	PATTERN RECOGNITION			English	Article						classifier design and evaluation; machine learning		In this work, a new method for the creation of classifier ensembles is introduced. The patterns are partitioned into clusters to group together similar patterns, a training set is built using the patterns that belong to a cluster. Each of the new sets is used to train a classifier. We show that the approach here presented, called FuzzyBagging, obtains performance better than Bagging. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Bologna, DEIS, CNR, IEIIT, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, CNR, IEIIT, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it	Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354			Bezdek J. C., 1981, PATTERN RECOGNITION; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Grandvalet Y, 2004, MACH LEARN, V55, P251, DOI 10.1023/B:MACH.0000027783.34431.42; Watson C. I., 1992, NIST SPECIAL DATABAS	5	17	20	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	2006	39	3					488	490		10.1016/j.patcog.2005.10.002		3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	007PO	WOS:000234981800017	
J	Menze, BH; Ur, JA; Sherratt, AG				Menze, BH; Ur, JA; Sherratt, AG			Detection of ancient settlement mounds: Archaeological survey based on the SRTM terrain model	PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING			English	Article								In the present study we demonstrate the value of the SRTM three arcsecond terrain model for a virtual survey of archaeological sites: the detection and mapping of ancient settlement mounds in the Near East. These so-called "tells" are the result of millennia of occupation within the period from 8000-1000 BC, and form visible landmarks of the world's first farming and urban communities. The SRTM model provides for the first time an opportunity to scan areas not yet surveyed archaeologically on a supra-regional scale and to pinpoint probable tell sites. In order to map these historic monuments for the purpose of settlement-study and conservation, we develop a machine learning classifier which identifies probable tell sites from the terrain model. In a test, point-like elevations of a characteristic tell shape, standing out for more than 5 to 6 m in the DEM were successfully detected (851133 tells). False positives (327/(600*1200) pixels) were primarily due to natural elevations, resembling tells in height and size.	Univ Heidelberg, Interdisciplinary Ctr Sci Comp, Heidelberg, Germany; Harvard Univ, Dept Anthropol, Cambridge, MA 02138 USA; Univ Sheffield, Dept Archaeol, Sheffield, S Yorkshire, England	Menze, BH (reprint author), Univ Heidelberg, Interdisciplinary Ctr Sci Comp, Bergheimer Str 58, Heidelberg, Germany.	bjoern.menze@iwr.uni-hoidelberg.de					BAEK J, 2004, PATTERN RECOGN, V34, P1303; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; MENZE BH, 2005, P CIPA INT S 26 SEPT; MENZE BH, 2005, FILTERING LINEAR SUB; R Development Core Team, 2004, R LANG ENV STAT COMP; Sherratt A., 2004, ANTIQUITY, V78, P301; UR JA, 2004, THESIS U CHICAGO ULL; Ur J.A., 2002, AKKADICA, V123, P57; WILKINSON TJ, 2000, T BEYDAR ENV TECHNIC, V6, P1	10	20	20	AMER SOC PHOTOGRAMMETRY	BETHESDA	5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA	0099-1112		PHOTOGRAMM ENG REM S	Photogramm. Eng. Remote Sens.	MAR	2006	72	3					321	327				7	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	018GX	WOS:000235753500013	
J	Bindewald, E; Shapiro, BA				Bindewald, E; Shapiro, BA			RNA secondary structure prediction from sequence alignments using a network of k-nearest neighbor classifiers	RNA-A PUBLICATION OF THE RNA SOCIETY			English	Article						RNA; secondary structure; mutual information; machine learning; alignment	DYNAMIC-PROGRAMMING ALGORITHM; PARALLEL GENETIC ALGORITHM; CONTEXT-FREE GRAMMARS; WEB SERVER; P RNA; INFORMATION; PSEUDOKNOTS; BINDING; THERMODYNAMICS; IMPLEMENTATION	We present a machine learning method (a hierarchical network of k-nearest neighbor classifiers) that uses an RNA sequence alignment in order to predict a consensus RNA secondary structure. The input to the network is the mutual information, the fraction of complementary nucleotides, and a novel consensus RNAfold secondary structure prediction of a pair of alignment columns and its nearest neighbors. Given this input, the network computes a prediction as to whether a particular pair of alignment columns corresponds to a base pair. By using a comprehensive test set of 49 RFAM alignments, the program KNetFold achieves an average Matthews correlation coefficient of 0.81. This is a significant improvement compared with the secondary structure prediction methods PFOLD and RNAalifold. By using the example of archaeal RNase P, we show that the program can also predict pseudoknot interactions.	NCI, Ctr Canc Res, Nanobiol Program, Frederick, MD 21702 USA; SAIC Frederick Inc, Basic Res Program, Frederick, MD USA	Shapiro, BA (reprint author), NCI, Ctr Canc Res, Nanobiol Program, Bldg 469,Room 150, Frederick, MD 21702 USA.	bshapiro@ncifcrf.gov					Akmaev VR, 2000, BIOINFORMATICS, V16, P501, DOI 10.1093/bioinformatics/16.6.501; Arya S., 1993, P DCC 93 DAT COMPR C, P381, DOI 10.1109/DCC.1993.253111; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; BASHARIN G., 1959, THEOR PROBAB APPL, V4, P333, DOI 10.1137/1104033; Brown JW, 1999, NUCLEIC ACIDS RES, V27, P314, DOI 10.1093/nar/27.1.314; Chen Y, 1999, GENES GENET SYST, V74, P271, DOI 10.1266/ggs.74.271; Fariselli P, 2001, PROTEIN ENG, V14, P835, DOI 10.1093/protein/14.11.835; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gardner PP, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-140; Gorodkin J, 2001, NUCLEIC ACIDS RES, V29, P2135, DOI 10.1093/nar/29.10.2135; Griffith EEH, 2005, J AM ACAD PSYCHIATRY, V33, P12; Griffiths-Jones S, 2003, NUCLEIC ACIDS RES, V31, P439, DOI 10.1093/nar/gkg006; HAAS ES, 1994, P NATL ACAD SCI USA, V91, P2527, DOI 10.1073/pnas.91.7.2527; Harris JK, 2001, RNA, V7, P220, DOI 10.1017/S1355838201001777; HOFACKER IL, 1994, MONATSH CHEM, V125, P167, DOI 10.1007/BF00818163; HOFACKER NL, 2002, J MOL BIOL, V319, P1059; JAEGER JA, 1989, P NATL ACAD SCI USA, V86, P7706, DOI 10.1073/pnas.86.20.7706; Juan V, 1999, J MOL BIOL, V289, P935, DOI 10.1006/jmbi.1999.2801; Knight R, 2004, RNA, V10, P1323, DOI 10.1261/rna.5168504; Knudsen B, 1999, BIOINFORMATICS, V15, P446, DOI 10.1093/bioinformatics/15.6.446; Knudsen B, 2003, NUCLEIC ACIDS RES, V31, P3423, DOI 10.1093/nar/gkg614; Mathews DH, 2004, P NATL ACAD SCI USA, V101, P7287, DOI 10.1073/pnas.0401799101; Mathews DH, 1999, J MOL BIOL, V288, P911, DOI 10.1006/jmbi.1999.2700; MCCASKILL JS, 1990, BIOPOLYMERS, V29, P1105, DOI 10.1002/bip.360290621; Mitchell T, 1997, MACHINE LEARNING; MUSE SV, 1995, GENETICS, V139, P1429; NUSSINOV R, 1978, SIAM J APPL MATH, V35, P68, DOI 10.1137/0135006; NUSSINOV R, 1980, P NATL ACAD SCI-BIOL, V77, P6309, DOI 10.1073/pnas.77.11.6309; Parsch J, 2000, GENETICS, V154, P909; Reeder J, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-104; Rivas E, 1999, J MOL BIOL, V285, P2053, DOI 10.1006/jmbi.1998.2436; Ruan JH, 2004, BIOINFORMATICS, V20, P58, DOI 10.1093/bioinformatics/btg373; Ruan JH, 2004, NUCLEIC ACIDS RES, V32, pW146, DOI 10.1093/nar/gkh444; SCHNEIDER TD, 1986, J MOL BIOL, V188, P415, DOI 10.1016/0022-2836(86)90165-8; Shapiro BA, 2001, J MOL BIOL, V312, P27, DOI 10.1006/jmbi.2001.4931; SHAPIRO BA, 1994, J SUPERCOMPUT, V8, P195, DOI 10.1007/BF01204728; Shapiro BA, 2001, BIOINFORMATICS, V17, P137, DOI 10.1093/bioinformatics/17.2.137; Shapiro BA, 1996, J MOL GRAPH MODEL, V14, P194, DOI 10.1016/S0263-7855(96)00063-X; Smith DR, 1997, J BACTERIOL, V179, P7135; STEPHENS RM, 1992, J MOL BIOL, V228, P1124, DOI 10.1016/0022-2836(92)90320-J; WALTER AE, 1994, P NATL ACAD SCI USA, V91, P9218, DOI 10.1073/pnas.91.20.9218; WATERMAN MS, 1978, MATH BIOSCI, V42, P257, DOI 10.1016/0025-5564(78)90099-8; ZUKER M, 1981, NUCLEIC ACIDS RES, V9, P133, DOI 10.1093/nar/9.1.133; Zuker M, 2003, NUCLEIC ACIDS RES, V31, P3406, DOI 10.1093/nar/gkg595; ZUKER M, 1989, SCIENCE, V244, P48, DOI 10.1126/science.2468181	45	36	41	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1355-8382		RNA	RNA-Publ. RNA Soc.	MAR	2006	12	3					342	352		10.1261/rna.2164906		11	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	018VN	WOS:000235793000004	
J	Burgess, M				Burgess, M			Probabilistic anomaly detection in distributed computer networks	SCIENCE OF COMPUTER PROGRAMMING			English	Article						machine learning; anomaly detection; data-mining	PATTERN-RECOGNITION	Distributed host-based anomaly detection has not yet proven practical due to the excessive computational overhead during training and detection. This paper considers an efficient algorithm for detecting resource anomalies in event streams with either Poisson or long tailed arrival processes. A form of distributed, lazy evaluation is presented, which uses a model for human-computer interaction based on two-dimensional time and a geometrically declining memory to yield orders of magnitude improvements in memory requirements. A three-tiered probabilistic method of classifying anomalous behaviour is discussed. This leads to a computationally and memory economic means of finding probable faults amongst the symptoms of network and system behaviour. (c) 2005 Elsevier B.V. All rights reserved.	Oslo Univ Coll, N-0254 Oslo, Norway	Burgess, M (reprint author), Oslo Univ Coll, Cort Adelers Gate 30, N-0254 Oslo, Norway.	Mark.Burgess@iu.hio.no					ALSHAER E, 2003, P IEEE IFIP 8 INT S, P17; BARFORD P, 2002, SIGNAL ANAL NETWORK; BEGNUM K, 2003, P VIII IFIP IEEE IM; Begnum K, 2005, MACH LEARN, V58, P217, DOI 10.1007/s10994-005-5827-4; Box G.E.P., 1994, TIME SERIES ANAL; BUNKE H, 1995, IEEE T SYST MAN CYB, V25, P202, DOI 10.1109/21.362950; BURGESS M, 2002, IFIP IEEE 13 INT WOR, P169; Burgess M, 1998, PROCEEDINGS OF THE TWELFTH SYSTEMS ADMINISTRATION CONFERENCE (LISA XII), P283; BURGESS M, 1995, COMPUT SYST, V8, P309; BURGESS M, 2004, ANAL NETWORK SYSTEM; BURGESS M, 2001, ACM T COMPUT SYST, V20, P125; Burgess M, 2003, SCI COMPUT PROGRAM, V49, P1, DOI 10.1016/j.scico.2003.08.001; BURGESS M, 2004, INT J INFORM SECURIT, V3, P70, DOI 10.1007/s10207-004-0044-x; Burgess M, 1998, SOFTWARE PRACT EXPER, V28, P1519, DOI 10.1002/(SICI)1097-024X(19981210)28:14<1519::AID-SPE213>3.0.CO;2-N; BURGESS M, 2000, INT J MOD PHYS C, V12, P759; BURGESS M, 1993, CFENGINE; DAMIANOU N, 2000, PONDER LANGUAGE SPEC; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; DHAESELEER PD, 1996, 9 IEEE COMPUTER SECU; DIAO Y, 2002, IFIP IEEE 13 INT WOR, P42; Duda R. O., 2001, PATTERN CLASSIFICATI; Durbin R, 1998, BIOL SEQUENCE ANAL; Forrest S, 1997, COMMUN ACM, V40, P88, DOI 10.1145/262793.262811; Forrest S., 1996, P 1996 IEEE S COMP S; Freeman J.A., 1991, NEURAL NETWORKS ALGO; Grimmett G, 2001, PROBABILITY RANDOM P; HAESELEEER PD, 1996, P 1996 IEEE S COMP S; HAN SH, 2002, IFIP IEEE 13 INT WOR, P16; Hofmeyr S. A., 1998, Journal of Computer Security, V6; HOOGENBOOM P, 1993, PROCEEDINGS OF THE SUMMER 1993 USENIX CONFERENCE, P15; JAVITZ HS, 1991, P IEEE S SEC PRIV MA; Kephart J.O., 1994, P 4 INT WORKSH SYNTH, P130; Kruegel C., 2003, P 10 ACM C COMP COMM, P251; Lane T., 2000, THESIS PURDUE U; Leland W., 1994, IEEE ACM T NETWORK, P1; Lewis H. R., 1997, ELEMENTS THEORY COMP; MATZINGER P, 1994, ANNU REV IMMUNOL, V12, P991, DOI 10.1146/annurev.immunol.12.1.991; MCCOMB WD, 2003, RENORMALIZATION METH; NEUMANN PG, 2000, EXPERIENCE EMERALD, P73; Oommen BJ, 1998, PATTERN RECOGN, V31, P1159, DOI 10.1016/S0031-3203(97)00124-6; PAXSON V, 1995, IEEE ACM T NETWORK, V3, P226, DOI 10.1109/90.392383; PAXSON V, 1998, P 7 SEC S USENIX ASS; Pearl J., 1988, PROBABILISTIC REASON; Porras P., 1997, P 20 NAT INF SYST SE, P353; Ranum MJ, 1997, PROCEEDINGS OF THE ELEVENTH SYSTEMS ADMINISTRATION CONFERENCE (LISA XI), P1; Ripley B. D, 1996, PATTERN RECOGNITION; ROESCH M, SNORT INTRUSION DETE; SATO K., 1999, LEVY PROCESSES INFIN; SEKAR R, 1999, P WORKSH INTR DET NE; SELTZER M, 1997, P 6 WORKSH HOT TOP O; Shannon CE, 1949, MATH THEORY COMMUNIC; Sloman M., 1994, Journal of Network and Systems Management, V2, DOI 10.1007/BF02283186; Somayagji A., 2000, Proceedings of the Ninth USENIX Security Symposium; SOMAYAJI A, 1997, NEW SEC PAR WORKSH, P75; STEINDER M, 2002, IFIP IEEE 13 INT WOR, P195; STEINDER M, 2003, SCI COMPUT PROGRAM, V53, P165	56	10	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6423		SCI COMPUT PROGRAM	Sci. Comput. Program.	MAR	2006	60	1					1	26		10.1016/j.scico.2005.06.001		26	Computer Science, Software Engineering	Computer Science	008MV	WOS:000235045800001	
J	Haffner, P				Haffner, P			Scaling large margin classifiers for spoken language understanding	SPEECH COMMUNICATION			English	Article						spoken language understanding; machine learning; SVM; AdaBoost; maximum entropy	SUPPORT VECTOR MACHINES; ALGORITHMS; REGRESSION	Large margin classifiers, such as SVMs and AdaBoost, have achieved state-of-the-art performance for semantic classification problems that occur in spoken language understanding or textual data mining applications. However, these computationally expensive learning algorithms cannot always handle the very large number of examples, features, and classes that are present in the available training corpora. This paper provides an original and unified presentation of these algorithms within the framework of regularized and large margin linear classifiers, reviews some available optimization techniques, and offers practical solutions to scaling issues. Systematic experiments compare the algorithms according to a number of criteria: performance, robustness, computational and memory requirements, and ease of parallelization. Furthermore, they confirm that the 1-vs-other multiclass scheme is a simple, generic and easy to implement baseline that has excellent scaling properties. Finally, this paper identifies the limitations of the classifiers and the multiclass schemes that are implemented. (c) 2005 Elsevier B.V. All rights reserved.	AT&T Labs Res, Middletown, NJ 07748 USA	Haffner, P (reprint author), AT&T Labs Res, 200 Laurel Ave S, Middletown, NJ 07748 USA.	haffner@research.att.com					ABNEY S, 1999, P JOINT SIGDAT C EMP; AIOLLI F, 2005, ADV NEURAL INFORM PR, V17; BARTLETT PL, 2005, ADV NEURAL INFORM PR, V17, P113; BEGEJA L, 2005, P ICASSP 05 PHIL; BORDES A, 2005, WORKING DOCUMENT FAS; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CHELBA C, 2003, P INTERSPEECH 03 EUR; COLLINS M, 2000, P 13 ANN C COMP LEAR, P158; COLLOBERT R, 2002, NEURAL COMPUT, V14; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; Cortes C, 2004, J MACH LEARN RES, V5, P1035; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Cristianini N., 2000, INTRO SUPPORT VECTOR; DIFABBRIZIO G, 2004, P 5 SIGDIAL WORKSH D; DUDIK M, 2004, P COLT 04 BANFF CAN; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J, 1998, ADDITIVE LOGISTIC RE; Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X; GRAF HP, 2005, ADV NEURAL INFORM PR, V17; GUPTA N, 2002, P EMNLP 02; HAFFNER P, 2005, WORKSH MIN NETW DAT; HAFFNER P, 2003, P ICASSP 03 HONG KON; HAFFNER P, 2005, EFFICIENT MULTICLASS; JOACHIMS T, 1998, P ECML 98; JOACHIMS T, 1998, ADV KERNAL METHODS S; KEERTHI SS, 2002, P INT C MACH LEARN, P299; LEBANON G, 2002, ADV NEURAL INFORM PR, V14; LEVIT M, 2004, P INTERSPEECH 04; Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218; Ng AY, 2002, ADV NEUR IN, V14, P841; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; PHILLIPS S, 2005, UNPUB ACCELERATING S; PHILLIPS S, 2004, P ICML 04 BANFF CAN; Platt J., 1998, ADV KERNEL METHODS S; RATSCH G, 2002, P 15 ANN C COMP LEAR, P334; RIFKIN R, 2004, J MACHINE LEARN RES, V1, P101; Schapire R. E., 1997, P 14 INT C MACH LEAR, P322; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Scholkopf B., 2002, LEARNING KERNELS; STEINWART I, 2004, ADV NEURAL INFORM PR, V16; TANG M, 2003, P ASRU 03; Tipping M. E., 2000, ADV NEURAL INFORM PR, V12; Tsang IW, 2005, J MACH LEARN RES, V6, P363; TUR G, 2004, P ICASSP 04; TUR G, 2002, P ICSLP 02; TUR G, 2003, P INTERSPEECH 03 EUR; Vapnik VN, 1998, STAT LEARNING THEORY; VURAL V, 2004, P ICML 04 BANFF CAN; Weston J, 1998, CSDTR9804 U LOND DEP; ZHANG J, 2003, P ICML 03 WASH DC	52	15	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393		SPEECH COMMUN	Speech Commun.	MAR-APR	2006	48	3-4					239	261		10.1016/j.specom.2005.06.008		23	Acoustics; Communication; Computer Science, Interdisciplinary Applications; Language & Linguistics	Acoustics; Communication; Computer Science; Linguistics	016ZS	WOS:000235664500002	
J	Pavlinic, DZ; Gersak, J; Demsar, J; Bratko, I				Pavlinic, DZ; Gersak, J; Demsar, J; Bratko, I			Predicting seam appearance quality	TEXTILE RESEARCH JOURNAL			English	Article						garment engineering; mechanical properties; garment manufacture; seam quality; prediction; machine learning methods		The appearance of a garment is affected by the quality of the fabrics used in its manufacture, as well as a number of factors determined by the technology of the garment manufacturing process. Since fabric quality, as the most important element of garment appearance., is determined by its mechanical properties, it is obvious that these properties directly impact fabric processing properties. It can be seen through various forms of fabric behavior under the loads that Occur in sewing. Investigations of the correlations of the stress and fabric behavior are aimed at constructing a system to predict fabric behavior in garment manufacturing processes, as well as to predict the appearance of the garment to be manufactured. The investigation presented here deals with the impact of fabric mechanical properties on the quality of seam appearance, as defined by seam Puckering and work-piece flotation. Machine learning methods included in the Orange software package were used to establish the importance of mechanical properties with respect to fabric behavior.	Univ Maribor, Inst Text, Fac Mech Engn, Dept Text, SI-2000 Maribor, Slovenia; Univ Ljubljana, Fac Comp & Informat Sci, Artificial Intelligence Lab, Ljubljana, Slovenia	Pavlinic, DZ (reprint author), Univ Maribor, Inst Text, Fac Mech Engn, Dept Text, SI-2000 Maribor, Slovenia.	daniela.z-pavlinic@uni-mb.si					Breiman L, 1984, CLASSIFICATION REGRE; DEMSAR J, 2004, ORANGE; Gersak J, 2002, INT J CLOTH SCI TECH, V14, P169, DOI 10.1108/09556220210437149; Gersak J, 2003, TEKSTIL, V52, P368; GERSAK J, 1998, EXPERTISE ANAL FABRI; GERSAK J, 1992, P CLOTH ENG 1992 TEC, P49; Hastie T, 2001, ELEMENTS STAT LEARNI; Kawabata S, 1980, STANDARDIZATION ANAL; Lindberg J, 1960, J TEXT I, V51, pT1475; MOROOKA H, 1978, J TEXTILE MACHINERY, V24, P105; Zar J. H., 1998, BIOSTATISTICAL ANAL; ZAVEC D, 2000, INT C INN MOD GARM M, P249; ZAVEC PD, 2004, TEKSTIL, V53, P497; *AATCC, 1996, 88B AATCC	14	16	16	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0040-5175		TEXT RES J	Text. Res. J.	MAR	2006	76	3					235	242		10.1177/0040517506061533		8	Materials Science, Textiles	Materials Science	039GR	WOS:000237294500006	
J	Pal, M				Pal, M			M5 model tree for land cover classification	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article							SUPERVISED CLASSIFICATION	Tree based regression models like a M5 algorithm represent a promising development in machine learning research. A recent study suggests that a M5 model tree algorithm can be used for classification problems after some modification. This letter explores the usefulness of a M5 model tree for classification problems using multispectral (Landsat-7 Enhanced Thematic Mapper Plus (ETM +)) for a test area in eastern England. Classification accuracy achieved by using a M5 model tree is compared with a univariate decision tree with and without using boosting. Results show that the M5 model tree achieves a significantly higher level of classification accuracy than a decision tree and works equally well to a boosted decision tree. Further, a model tree based classification algorithm works well with small as well as noisy datasets.	Natl Inst Technol, Dept Civil Engn, Kurukshetra 136119, Haryana, India	Pal, M (reprint author), Natl Inst Technol, Dept Civil Engn, Kurukshetra 136119, Haryana, India.	mpce_pal@yahoo.co.uk					CAMPBELL JB, 1981, PHOTOGRAMM ENG REM S, V47, P355; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7; Friedl MA, 1999, IEEE T GEOSCI REMOTE, V37, P969, DOI 10.1109/36.752215; Muchoney D, 2000, INT J REMOTE SENS, V21, P1115, DOI 10.1080/014311600210100; Pal M, 2003, REMOTE SENS ENVIRON, V86, P554, DOI 10.1016/S0034-4257(03)00132-9; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Witten I. H., 1999, DATA MINING PRACTICA	10	3	3	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161		INT J REMOTE SENS	Int. J. Remote Sens.	FEB 20	2006	27	4					825	831		10.1080/01431160500256531		7	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	029PJ	WOS:000236576300014	
J	Berrar, D; Bradbury, I; Dubitzky, W				Berrar, D; Bradbury, I; Dubitzky, W			Instance-based concept learning from multiclass DNA microarray data	BMC BIOINFORMATICS			English	Article							GENE-EXPRESSION DATA; FUZZY C-MEANS; CLASSIFICATION METHODS; TISSUE CLASSIFICATION; TUMOR CLASSIFICATION; FEATURE-SELECTION; CLASS PREDICTION; CANCER; DISCOVERY; PROFILES	Background: Various statistical and machine learning methods have been successfully applied to the classification of DNA microarray data. Simple instance-based classifiers such as nearest neighbor (NN) approaches perform remarkably well in comparison to more complex models, and are currently experiencing a renaissance in the analysis of data sets from biology and biotechnology. While binary classification of microarray data has been extensively investigated, studies involving multiclass data are rare. The question remains open whether there exists a significant difference in performance between NN approaches and more complex multiclass methods. Comparative studies in this field commonly assess different models based on their classification accuracy only; however, this approach lacks the rigor needed to draw reliable conclusions and is inadequate for testing the null hypothesis of equal performance. Comparing novel classification models to existing approaches requires focusing on the significance of differences in performance. Results: We investigated the performance of instance-based classifiers, including a NN classifier able to assign a degree of class membership to each sample. This model alleviates a major problem of conventional instance-based learners, namely the lack of confidence values for predictions. The model translates the distances to the nearest neighbors into 'confidence scores'; the higher the confidence score, the closer is the considered instance to a pre-defined class. We applied the models to three real gene expression data sets and compared them with state-of-the-art methods for classifying microarray data of multiple classes, assessing performance using a statistical significance test that took into account the data resampling strategy. Simple NN classifiers performed as well as, or significantly better than, their more intricate competitors. Conclusion: Given its highly intuitive underlying principles - simplicity, ease-of-use, and robustness - the k-NN classifier complemented by a suitable distance-weighting regime constitutes an excellent alternative to more complex models for multiclass microarray data sets. Instance-based classifiers using weighted distances are not limited to microarray data sets, but are likely to perform competitively in classifications of high-dimensional biological data sets such as those generated by high-throughput mass spectrometry.	Univ Ulster, Sch Biomed Sci, Coleraine BT52 1SA, Londonderry, North Ireland	Berrar, D (reprint author), Univ Ulster, Sch Biomed Sci, Cromore Rd, Coleraine BT52 1SA, Londonderry, North Ireland.	dp.berrar@ulster.ac.uk; i.bradbury@ulster.ac.uk; w.dubitzky@ulster.ac.uk					Aggarwal C.C., 2001, P 8 INT C DAT THEOR, P420; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; AMBROISE C, 2002, P NATL ACAD SCI USA, V98, P6562; Asyali MH, 2005, BIOINFORMATICS, V21, P644, DOI 10.1093/bioinformatics/bti036; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Bouckaert RR, 2004, P 8 PAC AS C KNOWL D, P3; CAWLEY GC, SUPPORT VECTOR MACHI; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DUDOIT S, 2002, PRACTICAL APPROACH M, P131; DUDOIT S, 2003, SIGKDD EXPLORATIONS, V5, P56; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; HASTIE T, 2002, ELEMENTS STAT LEARNI, P427; Krishnapuram B, 2004, J COMPUT BIOL, V11, P227, DOI 10.1089/1066527041410463; LI L, 2002, PRACTICAL APPROACH M, P216; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Mardia K, 1980, MULTIVARIATE ANAL; Mukherjee S, 2002, PRACTICAL APPROACH M, P166; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Platt JC, 2000, ADV NEUR IN, V12, P547; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Radmacher MD, 2002, J COMPUT BIOL, V9, P505, DOI 10.1089/106652702760138592; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Rechreche H, 1997, EUR J BIOCHEM, V248, P225, DOI 10.1111/j.1432-1033.1997.00225.x; Ripley B. D, 1996, PATTERN RECOGNITION; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; SIMON R, 2003, SIGKDD EXPLORATIONS, V5, P31; Slonim DK, 2000, P 4 ANN INT C COMP M, P263, DOI 10.1145/332306.332564; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; Tsai CA, 2005, MATH BIOSCI, V193, P79, DOI 10.1016/j.mbs.2004.07.002; Vapnik VN, 1998, STAT LEARNING THEORY; Wang JB, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-60; Yeang C H, 2001, Bioinformatics, V17 Suppl 1, pS316; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	36	11	12	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	FEB 16	2006	7								73	10.1186/1471-2105-7-73		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	022AS	WOS:000236027600001	
J	Linke, SP; Bremer, TM; Herold, CD; Sauter, G; Diamond, C				Linke, SP; Bremer, TM; Herold, CD; Sauter, G; Diamond, C			A multimarker model to predict outcome in tamoxifen-treated breast cancer patients	CLINICAL CANCER RESEARCH			English	Article							ESTROGEN-RECEPTOR STATUS; FALSE DISCOVERY RATES; TERM-FOLLOW-UP; PROGESTERONE-RECEPTOR; PROGNOSTIC RELEVANCE; TISSUE MICROARRAYS; ENDOCRINE THERAPY; BCL-2 EXPRESSION; CROSS-TALK; RESISTANCE	Purpose: This study was designed to produce a model to predict outcome in tamoxifen-treated breast cancer patients based on clinicopathologic features and multiple molecular markers. Experimental Design: This was a retrospective study of 324 stage I to III female breast cancer patients treated with tamoxifen for whom standard clinicopathologic data and tumor tissue microarrays were available. Nine molecular markers were studied by semiquantitative immunohistochemistry and/or fluorescence in situ hybridization. Cox proportional hazards analysis was used to determine the contributions of each variable to disease-specific and overall survival, and machine learning was used to produce a model to predict patient outcome. Results: On a univariate basis, the following features were significantly associated with worse survival: high pathologic tumor or nodal class, histologic grade, epidermal growth factor receptor, ERBB2, MYC, or TP53; absent estrogen receptor (ER) or progesterone receptor; and low BCL2. CCND1 and CDKN1B did not reach statistical significance. On a multivariate basis, nodal class, ER, and MYC were statistically significant as independent factors for survival. However, the benefit of ER-positive status was moderated by BCL2, ERBB2, and progesterone receptor. BCL2 and TP53 also interacted as an independent risk factor. A kernel partial least squares polynomial model was developed with an area under the receiver operating characteristic curve of 0.90. Conclusions: Our data show the predictive value of BCL2, ERBB2, MYC, and TP53 in addition to the standard hormone receptors and clinicopathologic features, and they show the importance of conditional interpretation of certain molecular markers. Our multimarker predictive model performed significantly better than standard guidelines.	Predict Sci, La Jolla, CA 92037 USA; Univ Med Ctr Hamburg Eppendorf, Dept Pathol, Hamburg, Germany	Linke, SP (reprint author), Predict Sci, 9404 Genesee Ave,Suite 210, La Jolla, CA 92037 USA.	slinke@predict.net					Al-Kuraya K, 2004, CANCER RES, V64, P8534, DOI 10.1158/0008-5472.CAN-04-1945; Bardou VJ, 2003, J CLIN ONCOL, V21, P1973, DOI 10.1200/JCO.2003.09.099; Berns EMJJ, 1998, J CLIN ONCOL, V16, P121; Carlomagno C, 1996, J CLIN ONCOL, V14, P2702; Clarke R, 2003, ONCOGENE, V22, P7316, DOI 10.1038/sj.onc.1206937; Cui XJ, 2003, MOL ENDOCRINOL, V17, P575, DOI 10.1210/me.2002-0318; Deming SL, 2000, BRIT J CANCER, V83, P1688, DOI 10.1054/bjoc.2000.1522; Dowsett M, 2001, CANCER RES, V61, P8452; Clarke M, 1998, LANCET, V351, P1451; Eden P, 2004, EUR J CANCER, V40, P1837, DOI 10.1016/j.ejca.2004.02.025; EFFRON T, 1993, INTRO BOOTSTRAP; Eifel P, 2001, J NATL CANCER I, V93, P979; Ein-Dor L, 2005, BIOINFORMATICS, V21, P171, DOI 10.1093/bioinformatics/bth469; Elledge RM, 1997, J CLIN ONCOL, V15, P1916; ELSTON CW, 1991, HISTOPATHOLOGY, V19, P403, DOI 10.1111/j.1365-2559.1991.tb00229.x; GALEA MH, 1992, BREAST CANCER RES TR, V22, P207, DOI 10.1007/BF01840834; GASPARINI G, 1995, CLIN CANCER RES, V1, P189; Goldhirsch A, 2005, ANN ONCOL, V16, P1569, DOI 10.1093/annonc/mdi326; HORWITZ KB, 1978, J BIOL CHEM, V253, P2223; Torhorst J, 2001, AM J PATHOL, V159, P2249, DOI 10.1016/S0002-9440(10)63075-1; Lombardo JF, 2005, NEW ENGL J MED, V353, P1300, DOI 411735787,12,1; Ma XJ, 2004, CANCER CELL, V5, P607, DOI 10.1016/j.ccr.2004.05.015; Mauri FA, 1999, INT J ONCOL, V15, P1137; NICHOLSON RI, 2003, BREAST CANC RES T S1, V80, pS5; Nicholson RI, 2003, BREAST CANCER RES TR, V80, pS29; Osborne CK, 2005, CLIN CANCER RES, V11, p865S; Osborne CK, 2003, J NATL CANCER I, V95, P353; Osborne CK, 1998, BREAST CANCER RES TR, V51, P227, DOI 10.1023/A:1006132427948; Osborne CK, 2003, BREAST, V12, P362, DOI 10.1016/S0960-9776(03)00137-1; Paik S, 2004, NEW ENGL J MED, V351, P2817, DOI 10.1056/NEJMoa041588; Perillo B, 2000, MOL CELL BIOL, V20, P2890, DOI 10.1128/MCB.20.8.2890-2901.2000; Ransohoff DF, 2004, NAT REV CANCER, V4, P309, DOI 10.1038/nrc1322; Reid JF, 2005, J NATL CANCER I, V97, P927, DOI 10.1093/jnci/dji153; Rosipal R, 2001, J MACHINE LEARNING R, V2, P97; Sauter G, 2003, NAT REV DRUG DISCOV, V2, P962, DOI 10.1038/nrd1254; Shou J, 2004, J NATL CANCER I, V96, P926, DOI 10.1093/jnci/djh166; Silvestrini R, 1996, J CLIN ONCOL, V14, P1604; Simon R, 2001, J NATL CANCER I, V93, P1141, DOI 10.1093/jnci/93.15.1141; Simon R, 2003, J NATL CANCER I, V95, P14; Singletary SE, 2002, J CLIN ONCOL, V20, P3628, DOI 10.1200/JCO.2002.02.026; Smith CL, 1997, MOL ENDOCRINOL, V11, P657, DOI 10.1210/me.11.6.657; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; WESTON J, 2004, SPIDER OBJECT ORIENT; *R DEV COR TEAM, R SURV; BREAST CANC PDQ TREA	48	36	37	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432		CLIN CANCER RES	Clin. Cancer Res.	FEB 15	2006	12	4					1175	1183		10.1158/1078-0432.CCR-05-1562		9	Oncology	Oncology	016AD	WOS:000235592000014	
J	Boden, M; Yuan, Z; Bailey, TL				Boden, M; Yuan, Z; Bailey, TL			Prediction of protein continuum secondary structure with probabilistic models based on NMR solved structures	BMC BIOINFORMATICS			English	Article							PROFILES; ACCURACY	Background: The structure of proteins may change as a result of the inherent flexibility of some protein regions. We develop and explore probabilistic machine learning methods for predicting a continuum secondary structure, i.e. assigning probabilities to the conformational states of a residue. We train our methods using data derived from high-quality NMR models. Results: Several probabilistic models not only successfully estimate the continuum secondary structure, but also provide a categorical output on par with models directly trained on categorical data. Importantly, models trained on the continuum secondary structure are also better than their categorical counterparts at identifying the conformational state for structurally ambivalent residues. Conclusion: Cascaded probabilistic neural networks trained on the continuum secondary structure exhibit better accuracy in structurally ambivalent regions of proteins, while sustaining an overall classification accuracy on par with standard, categorical prediction methods.	Univ Queensland, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia; Univ Queensland, Inst Mol Biosci, St Lucia, Qld 4072, Australia	Boden, M (reprint author), Univ Queensland, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia.	mikael@itee.uq.edu.au; z.yuan@imb.uq.edu.au; t.bailey@imb.uq.edu.au	Yuan, Zheng/A-1344-2008; Boden, Mikael/A-6030-2010				Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Carter P, 2003, NUCLEIC ACIDS RES, V31, P3293, DOI 10.1093/nar/gkg626; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Durbin R, 1998, BIOL SEQUENCE ANAL; Eyrich VA, 2003, PROTEINS, V53, P548, DOI 10.1002/prot.10534; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Guermeur Y, 2004, NEUROCOMPUTING, V56, P305, DOI 10.1016/j.neucom.2003.10.004; HOBOHM U, 1992, PROTEIN SCI, V1, P409; HOLM L, 1998, NUCLEIC ACIDS RES, V26, P318; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; John G. H., 1995, P 11 C UNC ART INT S; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; JORDAN MI, 1997, CRC HDB COMPUTER SCI; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kihara D, 2005, PROTEIN SCI, V14, P1955, DOI 10.1110/ps.051479505; NORDAHLPETERSEN T, 2000, PROTEIN-STRUCT FUNCT, V41, P17; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Anderson CAF, 2002, STRUCTURE, V10, P175, DOI 10.1016/S0969-2126(02)00700-1; Rost B, 2001, J STRUCT BIOL, V134, P204, DOI 10.1006/jsbi.2000.4336; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; Solis AD, 2004, POLYMER, V45, P525, DOI 10.1016/j.polymer.2003.10.065; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; Young M, 1999, PROTEIN SCI, V8, P1752; Yuan Z, 2005, PROTEINS, V58, P905, DOI 10.1002/prot.20375; Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K	27	15	16	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	FEB 14	2006	7								68	10.1186/1471-2105-7-68		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	017OE	WOS:000235702100001	
J	Grigoryan, G; Keating, AE				Grigoryan, G; Keating, AE			Structure-based prediction of bZIP partnering specificity	JOURNAL OF MOLECULAR BIOLOGY			English	Article						coiled coil; interaction specificity; computational prediction; protein structure	DEAD-END ELIMINATION; PROTEIN-INTERACTION NETWORKS; LEUCINE-ZIPPER; TRANSCRIPTION FACTORS; COILED-COIL; DNA RECOGNITION; AMINO-ACIDS; SIDE-CHAINS; DIMERIZATION SPECIFICITY; BINDING-SPECIFICITY	Predicting protein interaction specificity from sequence is an important goal in computational biology. We present a model for predicting the interaction preferences of coiled-coil peptides derived from bZIP transcription factors that performs very well when tested against experimental protein microarray data. We used only sequence information to build atomic-resolution structures for 1711 dimeric complexes, and evaluated these with a variety of functions based on physics, learned empirical weights or experimental coupling energies. A purely physical model, similar to those used for protein design studies, gave reasonable performance. The results were improved significantly when helix propensities were used in place of a structurally explicit model to represent the unfolded reference state. Further improvement resulted upon accounting for residue-residue interactions in competing states in a generic way. Purely physical structure-based methods had difficulty capturing core interactions accurately, especially those involving polar residues such as asparagine. When these terms were replaced with weights from a machine-learning approach, the resulting model was able to correctly order the stabilities of over 6000 pairs of complexes with greater than 90% accuracy. The final model is physically interpretable, and suggests specific pairs of residues that are important for bZIP interaction specificity. Our results illustrate the power and potential of structural modeling as a method for predicting protein interactions and highlight obstacles that must be overcome to reach quantitative accuracy using a de novo approach. Our method shows unprecedented performance in predicting protein-protein interaction specificity accurately using structural modeling and suggests that predicting coiled-coil interactions generally may be within reach. (c) 2005 Elsevier Ltd. All rights reserved.	MIT, Dept Biol, Cambridge, MA 02139 USA	Keating, AE (reprint author), MIT, Dept Biol, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	keating@mit.edu					Acharya A, 2002, BIOCHEMISTRY-US, V41, P14122, DOI 10.1021/bi020486r; Aloy P, 2004, SCIENCE, V303, P2026, DOI 10.1126/science.1092645; Aloy P, 2002, P NATL ACAD SCI USA, V99, P5896, DOI 10.1073/pnas.092147999; ANGEL P, 1991, BIOCHIM BIOPHYS ACTA, V1072, P129, DOI 10.1016/0304-419X(91)90011-9; Benos PV, 2002, J MOL BIOL, V323, P701, DOI 10.1016/S0022-2836(02)00917-8; BERGER B, 1995, P NATL ACAD SCI USA, V92, P8259, DOI 10.1073/pnas.92.18.8259; Beroza P, 1996, J COMPUT CHEM, V17, P1229, DOI 10.1002/(SICI)1096-987X(19960730)17:10<1229::AID-JCC4>3.0.CO;2-Q; BLABER M, 1993, SCIENCE, V260, P1637, DOI 10.1126/science.8503008; Blank V, 1997, TRENDS BIOCHEM SCI, V22, P437, DOI 10.1016/S0968-0004(97)01105-5; Bork P, 2004, CURR OPIN STRUC BIOL, V14, P292, DOI 10.1016/j.sbi.2004.05.003; Bradley P, 2001, P NATL ACAD SCI USA, V98, P14819, DOI 10.1073/pnas.251267298; Brannetti B, 2000, J MOL BIOL, V298, P313, DOI 10.1006/jmbi.2000.3670; BROOKS BR, 1983, J COMPUT CHEM, V4, P187, DOI 10.1002/jcc.540040211; CHAKRABARTTY A, 1994, PROTEIN SCI, V3, P843; CRICK FHC, 1953, ACTA CRYSTALLOGR, V6, P689, DOI 10.1107/S0365110X53001964; Dahiyat BI, 1996, PROTEIN SCI, V5, P895; Dahiyat BI, 1997, SCIENCE, V278, P82, DOI 10.1126/science.278.5335.82; Dantas G, 2003, J MOL BIOL, V332, P449, DOI 10.1016/S0022-2836(03)00888-X; Deppmann CD, 2004, NUCLEIC ACIDS RES, V32, P3435, DOI 10.1093/nar/gkh653; DESMET J, 1992, NATURE, V356, P539, DOI 10.1038/356539a0; ELLENBERGER TE, 1992, CELL, V71, P1223, DOI 10.1016/S0092-8674(05)80070-4; Elrod-Erickson M, 1998, STRUCT FOLD DES, V6, P451, DOI 10.1016/S0969-2126(98)00047-1; Fitzkee NC, 2004, P NATL ACAD SCI USA, V101, P12497, DOI 10.1073/pnas.0404236101; Fong JH, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-2-r11; GLOVER JNM, 1995, NATURE, V373, P257, DOI 10.1038/373257a0; GOLDSTEIN RF, 1994, BIOPHYS J, V66, P1335; Gordon DB, 1999, STRUCT FOLD DES, V7, P1089, DOI 10.1016/S0969-2126(99)80176-2; Guerois R, 2002, J MOL BIOL, V320, P369, DOI 10.1016/S0022-2836(02)00442-4; Hai T, 2001, GENE, V273, P1, DOI 10.1016/S0378-1119(01)00551-0; HAI T, 1991, P NATL ACAD SCI USA, V88, P3720, DOI 10.1073/pnas.88.9.3720; Harbury PB, 1998, SCIENCE, V282, P1462, DOI 10.1126/science.282.5393.1462; HARBURY PB, 1995, P NATL ACAD SCI USA, V92, P8408, DOI 10.1073/pnas.92.18.8408; Havranek JJ, 2003, NAT STRUCT BIOL, V10, P45, DOI 10.1038/nsb877; Herdegen T, 1998, BRAIN RES REV, V28, P370, DOI 10.1016/S0165-0173(98)00018-6; Hilser VJ, 1996, PROTEINS, V26, P123, DOI 10.1002/(SICI)1097-0134(199610)26:2<123::AID-PROT2>3.0.CO;2-H; HOROVITZ A, 1992, J MOL BIOL, V227, P560, DOI 10.1016/0022-2836(92)90907-2; Hurst H C, 1995, Protein Profile, V2, P101; Kammerer RA, 1998, P NATL ACAD SCI USA, V95, P13419, DOI 10.1073/pnas.95.23.13419; Kaplan T, 2005, PLOS COMPUT BIOL, V1, P5, DOI 10.1371/journal.pcbi.0010001; Keating AE, 2001, P NATL ACAD SCI USA, V98, P14825, DOI 10.1073/pnas.261563398; Kiel C, 2004, J MOL BIOL, V340, P1039, DOI 10.1016/j.jmb.2004.05.050; Kortemme T, 2002, P NATL ACAD SCI USA, V99, P14116, DOI 10.1073/pnas.202485799; KOUZARIDES T, 1989, NATURE, V340, P568, DOI 10.1038/340568a0; Krylov D, 1998, J MOL BIOL, V279, P959, DOI 10.1006/jmbi.1998.1762; Kuhlman B, 2000, P NATL ACAD SCI USA, V97, P10383, DOI 10.1073/pnas.97.19.10383; Kuhlman B, 2003, SCIENCE, V302, P1364, DOI 10.1126/science.1089427; Lacroix E, 1998, J MOL BIOL, V284, P173, DOI 10.1006/jmbi.1998.2145; LASTERS I, 1995, PROTEIN ENG, V8, P815, DOI 10.1093/protein/8.8.815; Lazaridis T, 1999, PROTEINS, V35, P133, DOI 10.1002/(SICI)1097-0134(19990501)35:2<133::AID-PROT1>3.0.CO;2-N; Leach AR, 1998, PROTEINS, V33, P227, DOI 10.1002/(SICI)1097-0134(19981101)33:2<227::AID-PROT7>3.0.CO;2-F; Lekstrom-Himes J, 1998, J BIOL CHEM, V273, P28545, DOI 10.1074/jbc.273.44.28545; LITTLEWOOD TD, 1995, PROTEIN PROFILE, V2, P621; Liu S, 2004, PROTEINS, V56, P93, DOI 10.1002/prot.20019; Lovell SC, 2000, PROTEINS, V40, P389, DOI 10.1002/1097-0134(20000815)40:3<389::AID-PROT50>3.0.CO;2-2; Lu L, 2002, PROTEINS, V49, P350, DOI 10.1002/prot.10222; LYU PC, 1990, SCIENCE, V250, P669, DOI 10.1126/science.2237416; Malakauskas SM, 1998, NAT STRUCT BIOL, V5, P470, DOI 10.1038/nsb0698-470; Marti DN, 2004, BIOCHEMISTRY-US, V43, P12436, DOI 10.1021/bi048771t; Mendes J, 2002, CURR OPIN STRUC BIOL, V12, P441, DOI 10.1016/S0959-440X(02)00345-7; Mendez R, 2005, PROTEINS, V60, P150, DOI 10.1002/prot.20551; Misura KMS, 2005, PROTEINS, V59, P15, DOI 10.1002/prot.20376; Mok YK, 2001, J MOL BIOL, V307, P913, DOI 10.1006/jmbi.2001.4521; MUNOZ V, 1995, J MOL BIOL, V245, P275, DOI 10.1006/jmbi.1994.0023; Myers JK, 1999, J MOL BIOL, V289, P205, DOI 10.1006/jmbi.1999.2747; Nauli S, 2001, NAT STRUCT BIOL, V8, P602, DOI 10.1038/89638; Newman JRS, 2003, SCIENCE, V300, P2097, DOI 10.1126/science.1084648; Oakley AJ, 1998, BIOCHEMISTRY-US, V37, P9912, DOI 10.1021/bi980323w; Oakley MG, 1998, BIOCHEMISTRY-US, V37, P12603, DOI 10.1021/bi981269m; ONEIL KT, 1990, SCIENCE, V250, P646, DOI 10.1126/science.2237415; Onufriev A, 2002, J COMPUT CHEM, V23, P1297, DOI 10.1002/jcc.10126; Pierce NA, 2000, J COMPUT CHEM, V21, P999, DOI 10.1002/1096-987X(200008)21:11<999::AID-JCC9>3.3.CO;2-1; Ramji DP, 2002, BIOCHEM J, V365, P561; Shifman JM, 2003, P NATL ACAD SCI USA, V100, P13274, DOI 10.1073/pnas.2234277100; Sidhu SS, 2003, CURR OPIN CHEM BIOL, V7, P97, DOI 10.1016/S1367-5931(02)00011-x; SINGH M, 2001, P 5 ANN INT C COMP M, P279, DOI 10.1145/369133.369238; Summa CM, 2002, J MOL BIOL, V321, P923, DOI 10.1016/S0022-2836(02)00589-2; Szilagyi A, 2005, PHYS BIOL, V2, pS1, DOI 10.1088/1478-3975/2/2/S01; Hendsch ZS, 1999, PROTEIN SCI, V8, P1381; Tong AHY, 2002, SCIENCE, V295, P321, DOI 10.1126/science.1064987; Tupler R, 2001, NATURE, V409, P832, DOI 10.1038/35057011; Vinson C, 2002, MOL CELL BIOL, V22, P6321, DOI 10.1128/MCB.22.18.6321-6335.2002; VINSON CR, 1989, SCIENCE, V246, P911, DOI 10.1126/science.2683088; Wernisch L, 2000, J MOL BIOL, V301, P713, DOI 10.1006/jmbi.2000.3984; Wiedemann U, 2004, J MOL BIOL, V343, P703, DOI 10.1016/j.jmb.2004.08.064; Wolfe SA, 1999, J MOL BIOL, V285, P1917, DOI 10.1006/jmbi.1998.2421; Wollacott AM, 2001, J MOL BIOL, V313, P317, DOI 10.1006/jmbi.2001.5035; Zanzoni A, 2002, FEBS LETT, V513, P135, DOI 10.1016/S0014-5793(01)03293-8; Zeng X, 1997, P NATL ACAD SCI USA, V94, P3673, DOI 10.1073/pnas.94.8.3673; Zhang C, 2005, J MED CHEM, V48, P2325, DOI 10.1021/jm049314d; Zhu H, 2001, SCIENCE, V293, P2101, DOI 10.1126/science.1062191	90	37	37	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-2836		J MOL BIOL	J. Mol. Biol.	FEB 3	2006	355	5					1125	1142		10.1016/j.jmb.2005.11.036		18	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	006QU	WOS:000234912800023	
J	Fox, M; Ghallab, M; Infantes, G; Long, D				Fox, M; Ghallab, M; Infantes, G; Long, D			Robot introspection through learned hidden Markov models	ARTIFICIAL INTELLIGENCE			English	Article						stochastic learning; hidden Markov models; robot behaviour	SPEECH RECOGNITION; ARCHITECTURE; NAVIGATION; ALGORITHM; GESTURE	In this paper we describe a machine learning approach for acquiring a model of a robot behaviour from raw sensor data. We are interested in automating the acquisition of bebavioural models to provide a robot with an introspective capability. We assume that the behaviour of a robot in achieving a task can be modelled as a finite stochastic state transition system. Beginning with data recorded by a robot in the execution of a task, we use unsupervised learning techniques to estimate a hidden Markov model (HMM) that can be used both for predicting and explaining the behaviour of the robot in subsequent executions of the task. We demonstrate that it is feasible to automate the entire process of learning a high quality HMM from the data recorded by the robot during execution of its task. The learned HMM can be used both for monitoring and controlling the behaviour of the robot. The ultimate purpose of our work is to learn models for the full set of tasks associated with a given problem domain, and to integrate these models with a generative task planner. We want to show that these models can be used successfully in controlling the execution of a plan. However, this paper does not develop the planning and control aspects of our work, focussing instead on the learning methodology and the evaluation of a learned model. The essential property of the models we seek to construct is that the most probable trajectory through a model, given the observations made by the robot, accurately diagnoses, or explains, the behaviour that the robot actually performed when making these observations. In the work reported here we consider a navigation task. We explain the learning process, the experimental setup and the structure of the resulting learned behavioural models. We then evaluate the extent to which explanations proposed by the learned models accord with a human observer's interpretation of the behaviour exhibited by the robot in its execution of the task. (C) 2005 Elsevier B.V. All rights reserved.	Univ Strathclyde, Dept Comp & Informat Sci, Glasgow G1 1XH, Lanark, Scotland; CNRS, LAAS, F-31500 Toulouse, France	Fox, M (reprint author), Univ Strathclyde, Dept Comp & Informat Sci, 26 Richmond St, Glasgow G1 1XH, Lanark, Scotland.	maria.fox@cis.strath.ac.uk					Alami R, 1998, INT J ROBOT RES, V17, P315, DOI 10.1177/027836499801700402; BASYE K, 1989, P 11 INT JOINT C AI, P663; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; BAUM LE, 1968, PAC J MATH, V27, P211; Beetz M., 1999, Proceedings of the Third International Conference on Autonomous Agents, DOI 10.1145/301136.301201; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bui H., 2003, P INT JOINT C ART IN, P1309; Bui HH, 2002, J ARTIF INTELL RES, V17, P451; Chrisman L., 1992, P 10 NAT C ART INT, P183; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; DEAN TL, 1992, P AAAI 92 SAN JOS CA, P208; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; FIRBY JR, 1996, P 3 INT C AI PLANN S, P78; FLEURY S, 1997, P IEEE RSJ INT C INT, V2, P842, DOI 10.1109/IROS.1997.655108; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Gates Tim, 2000, P 17 NAT C ART INT, P846; INGRAND FF, 1992, IEEE EXPERT, V7, P34, DOI 10.1109/64.180407; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; KIM P, 2001, P 17 INT JOINT C ART, P487; Koenig S., 1996, Proceedings. 1996 IEEE International Conference on Robotics and Automation (Cat. No.96CH35857), DOI 10.1109/ROBOT.1996.506507; KOENIG S, 1996, P 13 INT C MACH LEAR, P266; Kohonen T., 1984, SELF ORG ASS MEMORY; Liao L, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P348; Macqueen J. B., 1967, P 5 BERK S MATH STAT, P281; MAKHOUL J, 1985, P IEEE, V73, P1551, DOI 10.1109/PROC.1985.13340; MINGUEZ J, 2004, P INT C ROB AUT ICRA; Minguez J., 2001, Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164), DOI 10.1109/ROBOT.2001.932526; Minguez J, 2004, IEEE T ROBOTIC AUTOM, V20, P45, DOI 10.1109/TRA.2003.820849; Murphy K.P., 2001, COMPUTING SCI STAT; MUSCETTOLA N, 1998, ARTIF INTELL, V100, P5; Nam Y, 1996, ACM S VIRT REAL SOFT, P51; Oppenheim A. V., 1999, DISCRETE TIME SIGNAL; OSENTOSKI S, 2004, P IEEE RSJ INT C INT; Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Shatkay H, 2002, J ARTIF INTELL RES, V16, P167; Simmons R., 1998, Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190), DOI 10.1109/IROS.1998.724883; Stolcke A., 1993, ADV NEURAL INFORMATI, V5, P11; Theocharous G., 2001, Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164), DOI 10.1109/ROBOT.2001.932601; Williams BC, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P971; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; Wilson AD, 2001, INT J PATTERN RECOGN, V15, P123, DOI 10.1142/S0218001401000812	42	17	17	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	FEB	2006	170	2					59	113		10.1016/j.artint.2005.05.007		55	Computer Science, Artificial Intelligence	Computer Science	004US	WOS:000234778500001	
J	Dong, QW; Wang, XL; Lin, L				Dong, QW; Wang, XL; Lin, L			Application of latent semantic analysis to protein remote homology detection	BIOINFORMATICS			English	Article							HIDDEN MARKOV-MODELS; COMPUTATIONAL BIOLOGY; SEQUENCE ALIGNMENT; LANGUAGE; CLASSIFICATION; RECOGNITION; DISCOVERY; DATABASE; KERNELS	Motivation: Remote homology detection between protein sequences is a central problem in computational biology. The discriminative method such as the support vector machine (SVM) is one of the most effective methods. Many of the SVM-based methods focus on finding useful representations of protein sequence, using either explicit feature vector representations or kernel functions. Such representations may suffer from the peaking phenomenon in many machine-learning methods because the features are usually very large and noise data may be introduced. Based on these observations, this research focuses on feature extraction and efficient representation of protein vectors for SVM protein classification. Results: In this study, a latent semantic analysis (LSA) model, which is an efficient feature extraction technique from natural language processing, has been introduced in protein remote homology detection. Several basic building blocks of protein sequences have been investigated as the 'words' of 'protein sequence language', including N-grams, patterns and motifs. Each protein sequence is taken as a 'document' that is composed of bags-of-word. The word-document matrix is constructed first. The LSA is performed on the matrix to produce the latent semantic representation vectors of protein sequences, leading to noise-removal and smart description of protein sequences. The latent semantic representation vectors are then evaluated by SVM. The method is tested on the SCOP 1.53 database. The results show that the LSA model significantly improves the performance of remote homology detection in comparison with the basic formalisms. Furthermore, the performance of this method is comparable with that of the complex kernel methods such as SVM-LA and better than that of other sequence-based methods such as PSI-BLAST and SVM-pairwise.	Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China	Dong, QW (reprint author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China.	qwdong@insun.hit.edu.cn					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Anand B, 2005, BIOINFORMATICS, V21, P2821, DOI 10.1093/bioinformatics/bti432; Andreeva A, 2004, NUCLEIC ACIDS RES, V32, pD226, DOI 10.1093/nar/gkh039; Bailey T. L., 1994, P 2 INT C INT SYST M, P28; Bailey T.L., 1999, P 3 ANN INT C COMP M, P10, DOI 10.1145/299432.299444; Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084; Ben-Hur A, 2003, BIOINFORMATICS, V19, pi26, DOI 10.1093/bioinformatics/btg1002; Chandonia JM, 2004, NUCLEIC ACIDS RES, V32, P189; Cheng BYM, 2005, PROTEINS, V58, P955, DOI 10.1002/prot.20373; Coin L, 2003, P NATL ACAD SCI USA, V100, P4516, DOI 10.1073/pnas.0737502100; Dong Q, 2005, 4 INT C MACH LEARN C, P3363; Ganapathiraju M, 2005, LECT NOTES COMPUT SC, V3345, P25; GANAPATHIRAJU M, 2002, P HUM LANG TECHN C S; Ganapathiraju MK, 2004, IEEE SIGNAL PROC MAG, V21, P78, DOI 10.1109/MSP.2004.1296545; Gribskov M, 1996, COMPUT CHEM, V20, P25, DOI 10.1016/S0097-8485(96)80004-0; Han SJ, 2005, BIOINFORMATICS, V21, P2667, DOI 10.1093/bioinformatics/bti384; Hou Y, 2003, BIOINFORMATICS, V19, P2294, DOI 10.1093/bioinformatics/btg317; Hou YN, 2004, PROTEINS, V57, P518, DOI 10.1002/prot.20221; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; Leslie Christina, 2002, Pac Symp Biocomput, P564; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; LI L, 2003, J COMPUT BIOL, V10, P857; PEARSON WR, 1990, METHOD ENZYMOL, V183, P63, DOI 10.1016/0076-6879(90)83007-V; Pisanti N, 2003, LECT NOTES COMPUT SC, V2747, P622; Qian B, 2004, BIOINFORMATICS, V20, P2175, DOI 10.1093/bioinformatics/bth181; Rigoutsos I, 1998, BIOINFORMATICS, V14, P55, DOI 10.1093/bioinformatics/14.1.55; Saigo H, 2002, GENOME INFORM, V13, P396; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Vapnik VN, 1998, STAT LEARNING THEORY	35	25	25	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	FEB 1	2006	22	3					285	290		10.1093/bioinformatics/bti801		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	011OE	WOS:000235277100005	
J	Hadjiiski, L; Sahiner, B; Chan, HP				Hadjiiski, Lubomir; Sahiner, Berkman; Chan, Heang-Ping			Advances in computer-aided diagnosis for breast cancer	CURRENT OPINION IN OBSTETRICS & GYNECOLOGY			English	Article						breast cancer; characterization; computer-aided diagnosis; detection; mammography	ARTIFICIAL NEURAL-NETWORK; MACHINE-LEARNING-METHODS; DETECTION SYSTEM; CLUSTERED MICROCALCIFICATIONS; MAMMOGRAPHIC APPEARANCE; SCREENING MAMMOGRAPHY; DIGITIZED MAMMOGRAMS; SERIAL MAMMOGRAMS; PECTORAL MUSCLE; MASS LESIONS	Purpose of review Computer-aided diagnosis (CAD) is a technology used for the detection and characterization of cancer. Although CAD is not limited to a single type of cancer, a large number of CAD systems to date have been designed and used for breast cancer. The aim of this review is to discuss the current state of the CAD systems for breast-cancer diagnosis, their application as a second reader in clinical practice, and studies that have evaluated the effect of CAD on radiologists' performance. Recent findings A large number of CAD applications are being developed for different imaging modalities. Owing to commercially available Food and Drug Administration (FDA) approved systems, the main clinical use of CAD to date is for screen-film mammography. Many studies have shown that CAD improves radiologists' performance. A large number of academic institutions have devoted a substantial research effort to developing CAD methods. Summary CAD systems will play an increasingly important role in the clinic as a second reader. Clinical trials have shown that CAD can improve the accuracy of breast-cancer detection. Preclinical studies have demonstrated the potential of CAD to improve the classification of malignant and benign lesions. An increased number of CAD systems are being developed for different breast-imaging modalities.	Univ Michigan, Dept Radiol, Ann Arbor, MI 48109 USA	Hadjiiski, L (reprint author), Univ Michigan, Dept Radiol, 1500 E Med Ctr Dr,CGC B2101, Ann Arbor, MI 48109 USA.	lhadjisk@umich.edu					ADLER DD, 1992, CURR OPIN RADIOL, V4, P123; American Cancer Society, 2005, CANC FACTS FIG; Baker JA, 2004, RADIOLOGY, V233, P411, DOI 10.1148/radiol.2332031200; Bilska-Wolak AO, 2005, ACAD RADIOL, V12, P671, DOI 10.1016/j.acra.2005.02.011; Birdwell RL, 2005, RADIOLOGY, V236, P451, DOI 10.1148/radiol.2362040864; Brem RF, 2005, AM J ROENTGENOL, V184, P893; Brem RF, 2005, AM J ROENTGENOL, V184, P439; Brem RF, 2005, CANCER, V104, P931, DOI 10.1002/cncr.21255; Butler SA, 2004, AM J ROENTGENOL, V183, P1511; Cady B, 2001, CANCER, V91, P1699, DOI 10.1002/1097-0142(20010501)91:9<1699::AID-CNCR1186>3.0.CO;2-W; Catarious DM, 2004, MED PHYS, V31, P1512, DOI 10.1118/1.1738960; CHAN HP, 2005, RADIOLOGY, V237, P107; CHAN HP, IN PRESS 7 INT WORKS; Chang RF, 2005, BREAST CANCER RES TR, V89, P179, DOI 10.1007/s10549-004-2043-z; Chen WJ, 2004, MED PHYS, V31, P1076, DOI 10.1118/1.1695652; DeMartini WB, 2005, ACAD RADIOL, V12, P806, DOI 10.1016/j.acra.2005.03.055; Destounis SV, 2004, RADIOLOGY, V232, P578, DOI 10.1148/radiol.2322030034; Deurloo EE, 2005, RADIOLOGY, V234, P693, DOI 10.1148/radiol.2343031580; Drukker K, 2005, ACAD RADIOL, V12, P970, DOI 10.1016/j.acra.2005.04.014; Drukker K, 2004, ACAD RADIOL, V11, P526, DOI 10.1016/S1076-6332(03)00723-2; Feig SA, 1998, AM J ROENTGENOL, V171, P29; Ferrari RJ, 2004, IEEE T MED IMAGING, V23, P232, DOI 10.1109/TMI.2003.823062; Filev P, 2005, MED PHYS, V32, P515, DOI 10.1118/1.1851892; Gur D, 2004, J NATL CANCER I, V96, P185, DOI 10.1093/jnci/djh067; Gur D, 2004, RADIOLOGY, V233, P418, DOI 10.1148/radiol.2332040277; Hadjiiski L, 2004, RADIOLOGY, V233, P255, DOI 10.1148/radiol.2331030432; Helvie MA, 2004, RADIOLOGY, V231, P208, DOI 10.1148/radiol.2311030429; Joo S, 2004, IEEE T MED IMAGING, V23, P1292, DOI 10.1109/TMI.2004.834617; Kallergi M, 2004, MED PHYS, V31, P314, DOI 10.1118/1.1637972; KOPANS DB, 1992, AM J ROENTGENOL, V158, P521; Kwok SM, 2004, IEEE T MED IMAGING, V23, P1129, DOI 10.1109/TMI.2004.830529; Leichter I, 2004, AM J ROENTGENOL, V182, P705; Li H, 2005, ACAD RADIOL, V12, P863, DOI 10.1016/j.acra.2005.03.069; Lim WK, 2004, MED PHYS, V31, P1288, DOI 10.1118/1.1708643; Marias K, 2005, IEEE T MED IMAGING, V24, P782, DOI 10.1109/TMI.2005.848374; Marx C, 2004, EUR J RADIOL, V51, P66, DOI 10.1016/S0720-048X(03)00144-X; McLoughlin KJ, 2004, IEEE T MED IMAGING, V23, P313, DOI 10.1109/TMI.2004.824240; Moon WK, 2005, RADIOLOGY, V236, P458, DOI 10.1148/radiol.2362041095; Nakayama R, 2004, MED PHYS, V31, P789, DOI 10.1118/1.1655711; Nattkemper TW, 2005, ARTIF INTELL MED, V34, P129, DOI 10.1016/j.artmed.2004.09.001; Papadopoulos A, 2005, ARTIF INTELL MED, V34, P141, DOI 10.1016/j.artmed.2004.10.001; Paquerault S, 2004, MED PHYS, V31, P2648, DOI 10.1118/1.1767692; Reiser I, 2004, TECHNOL CANCER RES T, V3, P437; SAHINER B, 2004, RADIOLOGICAL SOC N A, P447; Sahiner B, 2004, MED PHYS, V31, P744, DOI 10.1118/1.1649531; SICKLES EA, 1991, RADIOLOGY, V179, P463; Song JH, 2005, ACAD RADIOL, V12, P487, DOI 10.1016/j.acra.2004.12.016; Soo MS, 2005, AM J ROENTGENOL, V184, P887; Timp S, 2004, MED PHYS, V31, P958, DOI 10.1118/1.1688039; Timp S, 2005, MED PHYS, V32, P2629, DOI 10.1118/1.1984323; Wei J, 2005, MED PHYS, V32, P2827, DOI 10.1118/1.1907327; Wei J, 2004, MED PHYS, V31, P933, DOI 10.1118/1.1668512; WEI J, 2004, RSNA PROGRAM BOOK; Wei LY, 2005, IEEE T MED IMAGING, V24, P371, DOI 10.1109/TMI.2004.842457; Zhou Chuan, 2004, Med Phys, V31, P2871, DOI 10.1118/1.1800713; Zhou C, 2001, MED PHYS, V28, P1056, DOI 10.1118/1.1376640	56	3	5	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	1040-872X		CURR OPIN OBSTET GYN	Curr. Opin. Obstet. Gynecol.	FEB	2006	18	1					64	70		10.1097/01.gco.0000192965.29449.da		7	Obstetrics & Gynecology	Obstetrics & Gynecology	225TH	WOS:000250540000013	
J	Grum, DK; Kobal, AB; Arneric, N; Horvat, M; Zenko, B; Dzeroski, S; Osredkar, J				Grum, DK; Kobal, AB; Arneric, N; Horvat, M; Zenko, B; Dzeroski, S; Osredkar, J			Personality traits in miners with past occupational elemental mercury exposure	ENVIRONMENTAL HEALTH PERSPECTIVES			English	Article; Proceedings Paper	7th International Conference on Mercury as a Global Pollutant	JUN 28-JUL 02, 2004	Ljubljana, SLOVENIA	Jozef Stefan Inst, Minist Educ Sci & Sport, Minist Hlth, Minist Environm & Phys Planning, Thermo Powerplant Sostanj, Salonit Anhovo, Slovenian Tourist Board, Ljubljana Turist Boart, Mercury Mind Idrija, Crankarjev Dom, US EPA, Elect Power Res Inst, Tetra Tech Inc, Tekran Inc, Oak Ridge Natl Lab, GKSS Germany, UNEP, Exponent, GEF, UNDP, UNIDO, EUROCHLOR, NIMD, CEBAM Analyt Inc, Lumex, Int Res Dev Ctr Canada		depression; elemental mercury; ex-mercury miners; Hg; negative self-concept; occupational exposure; personality traits	PSYCHOLOGICAL PERFORMANCE; CHLORALKALI WORKERS; INORGANIC MERCURY; REFERENCE VALUES; VAPOR; MELATONIN; SYMPTOMS; ALCOHOLISM; DISORDER; SELENIUM	In this study, we evaluated the impact of long-term occupational exposure to elemental mercury vapor (Hg-0) on the personality traits of ex-mercury miners. Study groups included 53 ex-miners previously exposed to He and 53 age-matched controls. Miners and controls completed the self-reporting Eysenck Personality Questionnaire and the Emotional States Questionnaire. The relationship between the indices of past occupational exposure and the observed personality traits was evaluated using Pearson's correlation coefficient and on a subgroup level by machine learning methods (regression trees). The ex-mercury miners were intermittently exposed to Hg-0 for a period of 7-31 years. The means of exposure-cycle urine mercury (U-Hg) concentrations ranged from 20 to 120 mu g/L. The results obtained indicate that ex-miners tend to be more introverted and sincere, more depressive, more rigid in expressing their emotions and are likely to have more negative self-concepts than controls, but no correlations were found with the indices of past occupational exposure. Despite certain limitations, results obtained by the regression tree suggest that higher alcohol consumption per se and long-term intermittent, moderate exposure to Hg-0 (exposure cycle mean U-Hg concentrations > 38.7 < 53.5 mu g/L) in interaction with alcohol remain a plausible explanation for the depression associated with negative self-concept found in subgroups of ex-mercury miners. This could be one of the reason for the higher risk of suicide among miners of the ldrija Mercury Mine in the last 45 years.	Univ Ljubljana, Fac Arts, Dept Psychol, Ljubljana, Slovenia; Idrija Mercury Mine, Dept Occupat Med, Idrija, Slovenia; Univ Ljubljana, Med Ctr, Clin Inst Occupat Traff & Sports Med, Ljubljana, Slovenia; Jozef Stefan Inst, Dept Environm Sci, Ljubljana, Slovenia; Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana, Slovenia; Univ Ljubljana, Med Ctr, Clin Inst Clin Chem & Biochem, Ljubljana, Slovenia	Grum, DK (reprint author), Univ Ljubljana, Fac Arts, Dept Psychol, Ljubljana, Slovenia.	darja.kobal@ff.uni-lj.si	Zenko, Bernard/A-2891-2008				ALBERS JW, 1988, ANN NEUROL, V24, P651, DOI 10.1002/ana.410240510; ANDERSEN A, 1993, ACTA NEUROL SCAND, V88, P427; APOSHIAN HV, 1992, FASEB J, V6, P2472; BECKFRIIS J, 1985, PSYCHONEUROENDOCRINO, V10, P173, DOI 10.1016/0306-4530(85)90055-1; Boffetta P, 1998, CANCER CAUSE CONTROL, V9, P591, DOI 10.1023/A:1008849208686; Breiman L, 1984, CLASSIFICATION REGRE; BYRNE AR, 1995, ACTA CHIM SLOV, V42, P175; Echeverria D, 1998, FASEB J, V12, P971; ECHEVERRIA D, 1995, NEUROTOXICOL TERATOL, V17, P161, DOI 10.1016/0892-0362(94)00049-J; ELLINGSEN DG, 1993, BRIT J IND MED, V50, P736; EYSENCK HJ, 1975, MANUAL EYSENCK PERS; Falnoga I, 2000, ENVIRON RES, V84, P211, DOI 10.1006/enrs.2000.4116; Grandjean P, 1997, J OCCUP ENVIRON MED, V39, P707, DOI 10.1097/00043764-199708000-00004; GRUM DK, 2003, BEINGS SELF CONCEPT, V2, P173; HALBACH S, 1978, BIOCHIM BIOPHYS ACTA, V523, P522, DOI 10.1016/0005-2744(78)90055-4; Halliwell B., 1989, FREE RADICALS BIOL M; HARTER S, 1994, ROCH S DEV PSYCH, V5, P333; HORVAT M, 1991, TRACE ELEMENTS IN HEALTH AND DISEASE, P83; Horvat M., 1986, VESTN SLOV KEM DRUS, V33, P475; HRIBERNIK I, 1950, ARHIV ZA HIGIJENU RA, V1, P291; JOACHIM H, 1995, DEUT MED WOCHENSCHR, V120, P585; Karalic A., 1992, P ECAI 92, P440; Kasper S, 1996, BIOLOGIC EFFECTS OF LIGHT 1995, P325; KISHI R, 1994, OCCUP ENVIRON MED, V51, P35; Kobal A, 1997, WATER AIR SOIL POLL, V97, P169, DOI 10.1023/A:1018327632039; Kobal Alfred B., 2004, Journal of Trace Elements in Medicine and Biology, V17, P261, DOI 10.1016/S0946-672X(04)80028-2; KOBAL AB, 1999, MERCURY CONTAMINATED, P271; KOBAL AB, 1975, PROFESIONALNA EKSPOZ; KOBAL AB, 1991, POKLICNA IZPOSTAVLJE; KOBAL D, 2000, BASIC ASPECTS SELF C, P87; KOSTA L, 1975, NATURE, V254, P238, DOI 10.1038/254238a0; LAMOVCE T, 1989, EMOCIJE OBRAMNI MEHA; LAMOVEC T, 1988, PRIROCNIK PSIHOLOGIJ, P241; LEIBENLUFT E, 1993, AM J PSYCHIAT, V150, P294; Letz R, 2000, NEUROTOXICOLOGY, V21, P459; LOJK L, 1981, EPQ EYSENCKOV OSEBNO; LUND BO, 1993, BIOCHEM PHARMACOL, V45, P2017, DOI 10.1016/0006-2952(93)90012-L; MAGOS L, 1989, BIOCHIM BIOPHYS ACTA, V99, P85; MARKS DB, 1996, BASIC MED BIOCH; MARUSIC A, 2001, BRIT J PSYCHIAT, V179, P61; Mathiesen T, 1999, SCAND J WORK ENV HEA, V25, P342; MCINTYRE IM, 1986, AUST NZ J PSYCHIAT, V20, P381, DOI 10.3109/00048678609158887; MINOIA C, 1990, SCI TOTAL ENVIRON, V95, P89, DOI 10.1016/0048-9697(90)90055-Y; Mortensen EL, 1996, SCAND J PSYCHOL, V37, P221, DOI 10.1111/j.1467-9450.1996.tb00653.x; Mottet NK, 1997, MET IONS BIOL SYST, V34, P371; NIELSENKUDSK F, 1973, MERCURY MERCURIALS, P355; NORDBERG G, 1992, SCI TOTAL ENVIRON, V120, P17, DOI 10.1016/0048-9697(92)90213-C; PIIKIVI L, 1989, SCAND J WORK ENV HEA, V15, P69; PIIKIVI L, 1984, SCAND J WORK ENV HEA, V10, P35; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; ROELS H, 1985, AM J IND MED, V7, P45, DOI 10.1002/ajim.4700070106; SCHALLER KH, 1983, ARZTL LAB, V29, P325; SCHUCKIT MA, 1986, AM J PSYCHIAT, V143, P140; SCOPOLI JA, 1771, HYDRORGYRO IDRIENSI; SJOBERG L, 1976, POLARITY DIMENSIONAL; SOLEO L, 1990, BRIT J IND MED, V47, P105; United Nations Environment Programme, 2002, GLOB MERC ASS; van Heeringen C, 2001, Crisis, V22, P66, DOI 10.1027//0227-5910.22.2.66; VOGT WP, 1993, DICT STAT METH NONT; Wang Y., 1997, P 9 EUR C MACH LEARN, P128; WETTERBERG L, 1985, CIBA F SYMP, V117, P253; Witten I. H., 1999, DATA MINING PRACTICA; YAMAMURA Y, 1990, BIOL MONITORING EXPO, P113; *WHO, 2003, EL MERC IN MERC COMP; *WHO, 1991, IN MERC ENV HLTH CRI, V118; *WHO, 1976, MERC ENV HLTH CRIT, V1	66	9	9	US DEPT HEALTH HUMAN SCIENCES PUBLIC HEALTH SCIENCE	RES TRIANGLE PK	NATL INST HEALTH, NATL INST ENVIRONMENTAL HEALTH SCIENCES, PO BOX 12233, RES TRIANGLE PK, NC 27709-2233 USA	0091-6765		ENVIRON HEALTH PERSP	Environ. Health Perspect.	FEB	2006	114	2					290	296		10.1289/ehp.7863		7	Environmental Sciences; Public, Environmental & Occupational Health	Environmental Sciences & Ecology; Public, Environmental & Occupational Health	010VP	WOS:000235226300053	
J	Calvo-Flores, MD; Contreras, WF; Galindo, ELG; Perez-Perez, R				Calvo-Flores, MD; Contreras, WF; Galindo, ELG; Perez-Perez, R			XKey: A tool for the generation of identification keys	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						dichotomous keys; decision trees; XML; division criteria; interactivity	SYSTEM	This paper presents the development of XKey, a tool for generating taxonomical identification keys by means of decision tree construction. The tool is based on an XML standard for the representation of general taxonomical information, which makes it ideal for different fields of application. The article analyses the problem by examining the adaptation of machine learning techniques to the sphere of biology so as to incorporate the viewpoints of biologists and computer science experts. It also analyses the effect of using various division criteria on a set of real data: the Gymnosperm plant groups present in the Iberian peninsula. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Cordoba, Dept Informat & Anal Numer, Escuela Politecn Super, E-14071 Cordoba, Spain; Univ Granada, ETS Ingn Informat, Dept Ciencias Comp & Inteligencia Artificial, E-18071 Granada, Spain	Galindo, ELG (reprint author), Univ Cordoba, Dept Informat & Anal Numer, Escuela Politecn Super, Campus Rabanales,Edificio Albert Einstein,3A Plan, E-14071 Cordoba, Spain.	mdelgado@dccsai.ugr.es; egibaja@uco.es; egibaja@uco.es	Fajardo Contreras, Waldo/D-9981-2012				BARTLEY M, 2000, NAVIKEY 2 0; Breiman L., 1984, CLASSICATION REGRESS; Cabrero-Canosa M, 2003, EXPERT SYST APPL, V24, P335, DOI 10.1016/S0957-4174(02)00184-7; DALLWITZ MJ, 1974, SYST ZOOL, V23, P50, DOI 10.2307/2412239; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; DOMINGOS P, 1998, P 4 INT C KNOWL DISC, P34; DUNCAN T, 1986, TAXON, V35, P492, DOI 10.2307/1221902; FAJARDO W, 2003, EXPERT SYSTEMS APPL, P425; FORTUNER R, 1989, NEMATODE IDENTIFICAT; GIARRATANO JC, 1998, CLIPS USERS GUIDE; GONZALEZ GL, 1986, GYNMNOSPERMAE FLORA, V1, P161; LOPEZ GONZALEZ G. A., 2001, ARBOLES ARBUSTOS PEN, VI y II; HARRISON PR, 1998, HDB APPL EXPT SYST, P1; MADDISON DR, 1997, SYST BIOL, P46; Mahaman BD, 2002, COMPUT ELECTRON AGR, V36, P17, DOI 10.1016/S0168-1699(02)00069-8; MEACHAM CA, 1986, MEKA VERSION 3 0; MORALES C, 2001, GUIAS NATURALEZA ARB; Paine T.A., 2000, USERS GUIDE DELTA SY; Pankhurst RJ, 1991, PRACTICAL TAXONOMIC; PANKHURST RJ, 1994, PANDORA USER GUIDE V; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Schalk PH, 1999, NATURE RESOUR, V35, P31; SCHALK PH, 1996, ETIS LINNAEUS 2 TAX, V3; Shafer Glenn, 1976, MATH THEORY EVIDENCE; Shortliffe E. H., 1975, Mathematical Biosciences, V23, DOI 10.1016/0025-5564(75)90047-4; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; *CBIT, 1994, LUCLD VERS 2 1; *INT INC, 2000, XID AUTH SYST 3 0 DE; *TDWG SDD, 2005, SDD; *U TOR, 1996, POLL MULT ID KEY VER; *UBIO, 2003, X ID VERS	33	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2006	30	2					337	351		10.1016/j.eswa.2005.07.034		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	005TJ	WOS:000234846400018	
J	Esposito, F; Fanizzi, N; Ferilli, S; Basile, TMA; Di Mauro, N				Esposito, Floriana; Fanizzi, Nicola; Ferilli, Stefano; Basile, Teresa M. A.; Di Mauro, Nicola			Multistrategy operators for relational learning and their cooperation	FUNDAMENTA INFORMATICAE			English	Article						inductive learning; abstraction; abduction; multistrategy learning	ABSTRACTION	Traditional Machine Learning approaches based on single inference mechanisms have reached their limits. This causes the need for a framework that integrates approaches based on abduction and abstraction capabilities in the inductive learning paradigm, in the light of Michalski's Inferential Theory of Learning (ITL). This work is intended as a survey of the most significant contributions that are present in the literature, concerning single reasoning strategies and practical ways for bringing them together and making them cooperate in order to improve the effectiveness and efficiency of the learning process. The elicited role of an abductive proof procedure is tackling the problem of incomplete relevance in the incoming examples. Moreover, the employment of abstraction operators based on (direct and inverse) resolution to reduce the complexity of the learning problem is discussed. Lastly, a case study that implements the combined framework into a real multistrategy learning system is briefly presented.	Univ Bari, Dipartimento Informat, I-70125 Bari, Italy	Di Mauro, N (reprint author), Univ Bari, Dipartimento Informat, Via Orabona 4, I-70125 Bari, Italy.	esposito@di.uniba.it; fanizzi@di.uniba.it; ferilli@di.uniba.it; basile@di.uniba.it; ndm@di.uniba.it	Fanizzi, Nicola/A-4517-2010; Esposito, Floriana/H-1217-2011; Di Mauro, Nicola/B-7719-2008	Fanizzi, Nicola/0000-0001-5319-7933; 			BOSTROM H, 1994, GMD STUDIEN, V237, P31; BOURNAUD I, 2000, LECT NOTES COMPUTER, V1864, P87; BOURNAUD I, 2002, P 12 INT C IND LOG P; Bredeche N., 2003, Proceedings the Second IEEE International Conference on Cognitive Informatics; Carpineto C, 1993, P 10 INT C MACH LEAR, P33; Ceri S, 1990, LOGIC PROGRAMMING DA; Clark K. L., 1978, Logic and data bases; COHEN PR, 1981, HDB ARTIFICIAL INTEL, V3; De Raedt L., 1992, INTERACTIVE THEORY R; Dimopoulos Y., 1996, ADV INDUCTIVE LOGIC, P144; Dzeroski S., 2001, RELATIONAL DATA MINI; Eshghi K., 1989, P 6 INT C LOG PROGR, P234; Esposito F, 2001, FUND INFORM, V47, P15; Esposito F, 2000, MACH LEARN, V38, P133, DOI 10.1023/A:1007638124237; Esposito F, 2003, APPL ARTIF INTELL, V17, P859, DOI 10.1080/08839510390225203; GIORDANA A, 1990, WORKSH AUT GEN APPR, P245; GIORDANA A, 1991, P 8 INT WORKSH MACH, P142; GIUNCHIGLIA F, 1992, ARTIF INTELL, V57, P323, DOI 10.1016/0004-3702(92)90021-O; KAKAS AC, 1990, P 1 PAC RIM INT C AR, P438; KAKAS AC, 1993, J LOGIC COMPUT, V2, P718; Khardon R, 1999, MACH LEARN, V37, P241, DOI 10.1023/A:1007610422992; Kramer S, 2001, RELATIONAL DATA MINING, P262; LAMMA E, 2000, ABDUCTIVE INDUCTIVE, P233; Lloyd J.W., 1987, FDN LOGIC PROGRAMMIN; MANCARELLA P, 2003, LECT NOTES COMPUTER, V2829; Michalski R. S, 1994, MACH LEARN, VIV, P3; Michalski R. S., 1983, MACH LEARN, V1, P83; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; Nienhuys-Cheng S.-H., 1997, LECT NOTES ARTIFICIA, V1228; PLAISTED DA, 1981, ARTIF INTELL, V16, P47, DOI 10.1016/0004-3702(81)90015-1; REITER R, 1980, J ACM, V27, P235, DOI 10.1145/322186.322189; ROUVEIROL C, 1990, P 7 INT C MACH LEARN, P122; Semeraro G., 1998, LECT NOTES COMPUTER, V1463, P300, DOI 10.1007/3-540-49674-2_16; Stahl I., 1996, ADV INDUCTIVE LOGIC, P34; STONE P, 2000, MACHINE LEARNING ECM, V1810, P369, DOI 10.1007/3-540-45164-1_38; SUBRAMANIAN D, 1987, P IJCAI 87, P416; TECUCI G, 1990, MACHINE LEARNING ART, V3, P514; TENENBERG J, 1987, P IJCAI 87 MIL, P1011; Utgoff P., 1986, MACHINE LEARNING ART, VII, P107; VANDERLAAG P, 1995, THESIS ERASMUS U ROT; ZUCKER JD, 2002, LECT NOTES ARTIF INT, V2371, P256; Zucker J.D., 1998, P 4 INT WORKSH MULT, P157	43	3	3	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	FEB	2006	69	4					389	409				21	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	109IS	WOS:000242302000002	
J	Won, KJ; Prugel-Bennett, A; Krogh, A				Won, KJ; Prugel-Bennett, A; Krogh, A			Evolving the structure of hidden Markov Models	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						biological sequence analysis; genetic algorithm (GA); hidden Markov model (HMM); hybrid algorithm; machine learning	BIOLOGICAL SEQUENCE-ANALYSIS; SPEECH RECOGNITION; MAXIMUM-LIKELIHOOD; NEURAL-NETWORKS; ALGORITHM	A genetic algorithm (GA) is proposed for finding the structure of hidden Markov Models (HMMs) used for biological sequence analysis. The GA is designed to preserve biologically meaningful building blocks. The search through the space of HMM structures is combined with optimization of the emission and transition probabilities using the classic Baum-Welch algorithm. The system is tested on the problem of finding the promoter and coding region of C jejuni. The resulting HMM has a superior discrimination ability to a handcrafted model that has been published in the literature.	Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England; Univ Copenhagen, Bioinformat Ctr, DK-2100 Copenhagen, Denmark	Won, KJ (reprint author), Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.	j.won@ecs.soton.ac.uk					BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179; Baker J.E., 1987, P 2 INT C GEN ALG, P14; Berg JM, 2002, BIOCHEMISTRY; Chaw C. W., 1997, P INT C AUC SPEECH S, P1727; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Durbin R, 1998, BIOL SEQUENCE ANAL; FRIEDMAN CR, 2000, EPIDEMIOLOGY CAMPYLO, P121; Fujiwara Y., 1995, Pacific Symposium on Biocomputing '96; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Jordan MI, 1999, LEARNING GRAPHICAL M; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; KROGH A, 1998, COMPUTATIONAL METHOD, P45; Krogh A, 1999, NEURAL COMPUT, V11, P541, DOI 10.1162/089976699300016764; Petersen L, 2003, J MOL BIOL, V326, P1361, DOI 10.1016/S0022-2836(03)00034-2; POLI I, 1998, J ITALIAN STAT SOC, V2, P197; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rissanen J., 1999, Stochastic Complexity in Statistical Inquiry; Sjolander K, 1996, COMPUT APPL BIOSCI, V12, P327; Stolcke A., 1994, THESIS U CALIFORNIA; Won KJ, 2004, BIOINFORMATICS, V20, P3613, DOI 10.1093/bioinformatics/bth454; Won KJ, 2004, LECT NOTES COMPUT SC, V3213, P64; Wosten MMSM, 1998, J BACTERIOL, V180, P594; Yada T., 1994, GENOME INFORMATICS, V5, P178; Yao X, 1999, P IEEE, V87, P1423	24	8	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	FEB	2006	10	1					39	49		10.1109/TEVC.2005.851271		11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	017XB	WOS:000235725500004	
J	Cloete, I; van Zyl, J				Cloete, I; van Zyl, J			Fuzzy mule induction in a set covering framework	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						alpha complement; concept learning; exclusion; fuzzy rule induction; fuzzy set covering; lattice; most general conjunction; partial order; separate-and-conquer general-to-specific search; specialization method	DECISION TREES; ALGORITHM; KNOWLEDGE; RULES	Classes of algorithms and their corresponding knowledge representations for the induction of fuzzy logic classification rules include, for example, clustering and fuzzy decision trees. This paper introduces a new class of induction algorithms based on fuzzy set covering principles. We present a set covering framework for concept learning using fuzzy sets, and develop an algorithm, FUZZYBEXA, based on this approach to induce fuzzy classification rules from data. Unlike the induction of fuzzy decision trees that follow a divide-and-conquer strategy, this algorithm performs a separate-and-conquer general-to-specific search of the instance space. We show that the description language allows a partial ordering of candidate hypotheses leading to a lattice of conjunctions to be searched. Properties of the lattice allow the develoment of new heuristics to guide the search for good concept descriptions and to terminate the search early enough in the induction process. The operation of the algorithm is illustrated and then compared with other well-known crisp and fuzzy machine learning algorithms. The results show that highly accurate and comprehensible rules are induced, and that this methodology is an important new tool in the arsenal of fuzzy machine learning algorithms.	Int Univ, D-76646 Bruchsal, Germany; Sun Space & Informat Syst, Stellenbosch, South Africa	Cloete, I (reprint author), Int Univ, D-76646 Bruchsal, Germany.	ian.cloete@I-u.de; jacobus.vanzyl@gmail.com					Alander JT, 1997, FUZZY EVOLUTIONARY COMPUTATION, P299; Baraldi A, 1999, IEEE T SYST MAN CY B, V29, P786, DOI 10.1109/3477.809033; Blake C. L., 1998, UCI REPOSITORY MACHI; CASTRO JL, 1993, P 1 EUR C FUZZ INT T, P804; Castro JL, 1997, FUZZY SET SYST, V89, P193, DOI 10.1016/S0165-0114(96)00106-6; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; CIIOS KJ, 1992, P IEEE INT C FUZZ SY, P469; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Cox E., 1998, FUZZY SYSTEMS HDB; Cristianini N., 2000, INTRO SUPPORT VECTOR; DASGUPTA D, 2001, P GEN EV COMP C GECC, P299; Davey B.A., 2002, INTRO LATTICES ORDER; DEKLEER J, 1986, ARTIF INTELL, V28, P127, DOI 10.1016/0004-3702(86)90080-9; Dong M, 2001, IEEE T FUZZY SYST, V9, P461; Dunn J., 1974, J CYBERNETICS, V3, P32; Fertig CS, 1999, LECT NOTES ARTIF INT, V1704, P341; Goldberg DE, 1989, GENETIC ALGORITHMS S; Gomez J, 2002, P NAFIPS FLINT JOINT, P469; GRAY NAB, 1990, IEEE EXPERT, V5, P41, DOI 10.1109/64.54672; Guetova M, 2002, LECT NOTES ARTIF INT, V2479, P67; Herrera F., 1994, P 5 INT C INF PROC M, P675; HERRERA F, 1998, DECSAI98, P116; Janikov CZ, 1999, P 18 INT C N AM FUZZ, P467; Kalbfleisch J, 1979, PROBABILITY STAT INF; KLAWONN F, 1997, IFSA 97, V1, P193; Klir G.J., 1995, FUZZY SETS FUZZY LOG; Kruse R., 1995, ADV INTELLIGENT DATA, P90; Leski J., 2001, International Journal of Applied Mathematics and Computer Science, V11; MCALLESTER D, 1990, 8 NAT C ART INT, V2, P1109; MICHALSKI R, 1986, IMAL; Michalski R. S., 1998, MACHINE LEARNING DAT; MICHALSKI RS, 1972, GRAPHIC LANGUAGES; Mitchell T, 1997, MACHINE LEARNING; Mitra S, 2002, IEEE T SYST MAN CY C, V32, P328, DOI 10.1109/TSMCC.2002.806060; PAGALLO G, 1990, MACHINE LEARN, V5; Pena-Reyes CA, 2001, IEEE T FUZZY SYST, V9, P727, DOI 10.1109/91.963759; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Roubos H., 2000, P 9 IEEE INT C FUZZ, V2, P762; Ruspini E.H., 1998, HDB FUZZY COMPUTATIO; Russell S. J., 2003, ARTIFICIAL INTELLIGE; STORR HP, 2002, P INTECH VJFUZZY, P172; SURMANNH, 2000, P 2 ICSC S NEUR COMP, P349; Takagi T., 1985, IEEE T SYST MAN CYB, V15; Theron H, 1996, MACH LEARN, V24, P5, DOI 10.1023/A:1018077511624; Todorovski L., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Tsang E. C. C., 2003, Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693), DOI 10.1109/ICMLC.2003.1259643; YUAN YF, 1995, FUZZY SET SYST, V69, P125, DOI 10.1016/0165-0114(94)00229-Z	48	10	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	FEB	2006	14	1					93	110		10.1109/TFUZZ.2005.861616		18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	012YY	WOS:000235378000008	
J	Zhong, YF; Zhang, LP; Huang, B; Li, PX				Zhong, YF; Zhang, LP; Huang, B; Li, PX			An unsupervised artificial immune classifier for multi/hyperspectral remote sensing imagery	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						artificial immune system (AIS); clustering; pattern recognition; remote sensing; unsupervised classificationd	SYSTEM; MODEL	A new method in computational intelligence namely artificial immune systems (AIS), which draw inspiration from the vertebrate immune system, have strong capabilities of pattern recognition. Even though AIS have been successfully utilized in several fields, few applications have been reported in remote sensing. Modern commercial imaging satellites, owing to their large volume of high-resolution imagery, offer greater opportunities for automated image analysis. Hence, we propose a novel unsupervised machine-learning algorithm namely unsupervised artificial immune classifier (UAIC) to perform remote sensing image classification. In addition to their nonlinear classification properties, UAIC possesses biological properties such as clonal selection, immune network, and immune memory. The implementation of UAIC comprises two steps: initially, the first clustering centers are acquired by randomly choosing from the input remote sensing image. Then, the classification task is carried out. This assigns each pixel to the class that maximizes stimulation between the antigen and the antibody. Subsequently, based on the class, the antibody population is evolved and the memory cell pool is updated by immune algorithms until the stopping criterion is met. The classification results are evaluated by comparing with four known algorithms: K-means, ISODATA, fuzzy K-means, and self-organizing map. It is shown that UAIC is an adaptive clustering algorithm, which outperforms other algorithms in all the three experiments we carried out.	Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China; Univ Calgary, Calgary, AB T2N 1N4, Canada; Chinese Acad Sci, Inst Remote Sensing Applicat, Beijing, Peoples R China	Zhong, YF (reprint author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.	zlp62@public.wh.hb.cn	Zhong, Yanfei/F-3532-2010; jia, lp/H-5750-2011				BARALDI A, 1995, IEEE T GEOSCI REMOTE, V33, P305, DOI 10.1109/36.377930; BOUCHER JM, 1993, P IGARSS, V2, P737; BURNET F, 1959, CLONAL SELECTION THE; CARPENTER KE, 1992, HARVARD LIBR BULL, V3, P5; Carter JH, 2000, J AM MED INFORM ASSN, V7, P28; Dasgupta D., 1999, ARTIFICIAL IMMUNE SY; De Castro L.N., 2002, ARTIFICIAL IMMUNE SY; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; DECASTRO LN, 2000, 020065 RT DCA STAT U; DECASTRO LN, 1999, 0199 RT DCA STAT U C; Duda R. O., 2001, PATTERN CLASSIFICATI; HALL D., 1965, ISODATA NOVEL METHOD; Hofmeyr S., 1999, P GEN EV COMP C GECC, P1289; Huang B, 2005, INT J REMOTE SENS, V26, P1145, DOI 10.1080/01431160512331326747; Jerne N K, 1973, SCI AM, V229, P51; Kaufman L., 1990, FINDING GROUPS DATA; KILPATRICK D, 1995, P IEEE INT C NEUR NE, V1, P32, DOI 10.1109/ICNN.1995.487872; Kim J., 2001, P 2001 C EV COMP, V2, P1244; KUMAR KK, 1997, P IEEE INT C COMP CY, V1, P856; Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718; Macqueen J. B., 1967, P 5 BERK S MATH STAT, P281; MOHAMED RM, 2003, P 6 INT C INF FUS JU, V2, P951; Solberg AHS, 1996, IEEE T GEOSCI REMOTE, V34, P100, DOI 10.1109/36.481897; TARAKANOV A, 2002, P C EV COMP CEC 02, V1, P938, DOI 10.1109/CEC.2002.1007051; THITIMAJSHIMA P, 2000, P IGARSS, V4, P1684; Timmis J, 2000, BIOSYSTEMS, V55, P143, DOI 10.1016/S0303-2647(99)00092-1; Watkins A., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004472; YUHAS RH, 1992, 4 JPL AIRB EARTH SCI, P147; ZHANG LP, 2004, P 20 C INT SOC PHOT, V35, P397; ZHONG YF, 2005, CHINESE J IMAGE GRAP, V10, P18	30	48	62	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	FEB	2006	44	2					420	431		10.1109/TGRS.2005.861548		12	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	006MX	WOS:000234902700017	
J	Hsu, CC; Wang, SH				Hsu, CC; Wang, SH			An integrated framework for visualized and exploratory pattern discovery in mixed data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						attribute-oriented induction; clustering; data mining; pattern discovery; self-organizing map	SELF-ORGANIZING MAP; CLUSTERING CATEGORICAL-DATA; DATABASES; ALGORITHM; SELECTION; NETWORK	Data mining uncovers hidden, previously unknown, and potentially useful information. from large amounts of data. Compared to the traditional statistical and machine learning data analysis techniques, data mining emphasizes providing a convenient and complete environment for the data analysis. In this paper, we propose an integrated framework for visualized, exploratory data clustering, and pattern extraction from mixed data. We further discuss its implementation techniques: a generalized self-organizing map (GSOM) and an extended attribute-oriented induction (EAOI), which not only overcome the drawbacks of their original algorithms, but also provide additional analysis capabilities. Specifically, the GSOM facilitates the direct handling of mixed data, including categorical and numeric values The EAOI enables exploration for major values hidden in the data and, in addition, offers an alternative for processing numeric attributes, instead of generalizing them. A prototype was developed for experiments with synthetic and real data sets, and comparison with those of the traditional approaches. The results confirmed the feasibility of the framework and the superiority of the extended techniques.	Natl Yunlin Univ Sci & Technol, Dept Informat Management, Douliu 640, Yunlin, Taiwan	Hsu, CC (reprint author), Natl Yunlin Univ Sci & Technol, Dept Informat Management, Douliu 640, Yunlin, Taiwan.	hsucc@yuntech.edu.tw; g9223722@yuntech.edu.tw					Barbara D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Catlett J., 1991, THESIS U SYDNEY; Chen WR, 2000, P SOC PHOTO-OPT INS, V1, P26; DASH M, 1997, INTELLIGENT DATA ANA, V1; DEBOECK GJ, 2000, NEURAL NETW WORLD, V1, P3; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; Gluck M.A., 1985, P 7 ANN C COGN SCI S, P283; GROTH G, 1998, DATA MINING HANDS ON; Han J., 2001, DATA MINING CONCEPTS; Han J., 1994, P AAAI 94 WORKSH KNO, P157; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; Hsu CC, 2004, EXPERT SYST APPL, V27, P187, DOI 10.1016/j.eswa.2004.01.002; HUANG Z, 1998, DATA MINING KNOWLEDG, V2; Huang ZX, 1999, IEEE T FUZZY SYST, V7, P446; Jain A. K., 1999, ACM COMPUT SURV, V31; Jain A.K., 1988, ALGORITHMS CLUSTERIN; KASABOV N, 2000, P ICSC S NEUR COMP; Kaski S., 1996, Neural Networks in Financial Engineering. Proceedings of the Third International Conference on Neural Networks in the Capital Markets; KASSLIN M, 1992, ARTIFICIAL NEURAL NE, P1532; Kerber R., 1992, P 10 NAT C ART INT, P123; Kiang MY, 2001, COMPUT STAT DATA AN, V38, P161, DOI 10.1016/S0167-9473(01)00040-8; KIANG MY, 1995, DECIS SUPPORT SYST, V15, P351, DOI 10.1016/0167-9236(94)00046-1; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105; Kohonen T., 1997, SELF ORG MAPS; Kohonen T., 1996, A31 HELS U TECHN LAB; Kramer AA, 2000, PERSP NEURAL COMP, P192; Liu H, 1998, FEATURE SELECTION KN; Liu H, 1995, PROC INT C TOOLS ART, P388; MANTYSALO J, 1994, SPEECH COMMUN, V14, P119, DOI 10.1016/0167-6393(94)90003-5; Mitchell T, 1997, MACHINE LEARNING; Murphy P.M., 1992, UCI REPOSITORY MACHI; Ng MK, 2002, PATTERN RECOGN, V35, P2783, DOI 10.1016/S0031-3203(02)00021-3; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SIMULA O, 1995, NEURAL NETWORKS CHEM; VAPOLA M, 1994, P ICANN 94 INT C ART, V1, P246; Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731; VISA A, 1990, P INT JOINT C NEURAL, P491; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	41	7	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2006	18	2					161	173				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	003AD	WOS:000234653100002	
J	Hammami, M; Chahir, Y; Chen, LM				Hammami, M; Chahir, Y; Chen, LM			WebGuard: A Web filtering engine combining textual, structural, and visual content-based analysis	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Web classification and categorization; data mining; Web textual and structural content; visual content analysis; skin color model; pornographic Web site filtering		Along with the ever-growing Web comes the proliferation of objectionable content, such as sex, violence, racism, etc. We need efficient tools for classifying and filtering undesirable Web content. In this paper, we investigate this problem and describe WebGuard, an automatic machine learning-based pornographic Web site classification and filtering system. Unlike most commercial filtering products, which are mainly based on textual content-based analysis such as indicative keywords detection or manually collected black list checking, WebGuard relies on several major data mining techniques associated with textual, structural content-based analysis, and skin color related visual content-based analysis as well. Experiments conducted on a testbed of 400 Web sites including 200 adult sites and 200 nonpornographic ones showed WebGuard's filtering effectiveness, reaching a 97.4 percent classification accuracy rate when textual and structural content-based analysis was combined with visual content-based analysis. Further experiments on a black list of 12,311 adult Web sites manually collected and classified by the French Ministry of Education showed that Web(Guard scored a 95.62 percent classification accuracy rate. The basic framework of WebGuard can apply to other categorization problems of Web sites which combine, as most of them do today,textual and visual content.	Ecole Cent Lyon, LIRIS, CNRS, UMR 5205, F-69134 Ecully, France; Univ Caen, CNRS, URA 6072, GREYC, F-14032 Caen, France	Hammami, M (reprint author), Ecole Cent Lyon, LIRIS, CNRS, UMR 5205, 36 Av Guy de Collongue, F-69134 Ecully, France.	mohamed.hammami@ec-lyon.fr; youssef.chahir@info.unicaen.fr; liming.chen@ec-lyon.fr					ALBIOL A, 2000, P IEEE INT C IM PROC, V2, P239; Breiman L, 1984, CLASSIFICATION REGRE; BRIN S, 1998, P WWW7; Chahir Y, 2000, J VIS COMMUN IMAGE R, V11, P302, DOI 10.1006/jvic.1999.0428; CHAKRABARTI S, 1998, P 1998 ACM SIGMOD IN; Cho J, 1998, COMPUT NETWORKS ISDN, V30, P161, DOI 10.1016/S0169-7552(98)00108-1; Efron B., 1993, INTRO BOOTSTRAP; Flake G. W., 2000, P 6 INT C KNOWL DISC; FLAKE GW, 2003, WEB DYNAMICS; FURNKRANZ J, 1999, INTELLIGENT DATA ANA, P487; GLOVER EJ, 2002, P WWW2002; GRALLA P, 2001, INTERNET ENFANTS, P74; HAMMAMI M, 2003, P 3 INT WORKSH CONT, P157; HAMMAMI M, 2003, REV RIA ECA, V17, P219; Hammami M., 2003, Proceedings IEEE/WIC International Conference on Web Intelligence (WI 2003); HAMMAMI M, 2002, DEFINITION MODELE PE, P186; Jones M. J., 1998, 9811 CRL; KARPOVA E, 2003, P IAPR INT C IM SIGN, P47; LEE PY, 2002, IEEE INTELLIGENT SEP, P48; MAHDI W, 2002, Patent No. 0302406; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SCHUPP S, 2002, MEDIANET2002, P73; Sebastian F., 1999, P THAI 99 EUR S TEL, V99, P105; STAYRYNKEVITCH B, 2002, POESIA SOFTWARE ARCH; Wang YP, 1999, ACTA PHARMACOL SIN, V20, P10; Wang HL, 1997, IEEE T CIRC SYST VID, V7, P615; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; YANG MH, 1998, P IEEE INT C IM PROC, P127; YANG Y, 2001, J INTELLIGENT INFORM; Zighed D.A., 1996, METHOD NONARBORESCEN, P2; *BIONET SYST LLC, 2005, NET NANN 4 04; *ICOGNITO TECHN LT, 2005, PUR HOM 1 6; *SOL OAK SOFTW INC, 2002, CYB 2002; *SURFCONTROL PLC, 2005, CYB PATR 5 0; *SYM CORP, 2005, NORT INT SEC 2003	36	38	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2006	18	2					272	284		10.1109/TKDE.2006.34		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	003AD	WOS:000234653100010	
J	Krause, A; Smailagic, A; Siewiorek, DP				Krause, A; Smailagic, A; Siewiorek, DP			Context-aware mobile computing: Learning context-dependent personal preferences from a wearable sensor array	IEEE TRANSACTIONS ON MOBILE COMPUTING			English	Article						location-dependent and sensitive; wearable computers; mobile computing; machine learning; wearable Al; statistical models	NETWORKS	Context-aware computing describes the situation where a wearable/ mobile computer is aware of its user's state and surroundings and modifies its behavior based on this information. We designed, implemented, and evaluated a wearable system which can learn context-dependent personal preferences by identifying individual user states and observing how the user interacts with the system in these states. This learning occurs online and does not require external supervision. The system relies on techniques from machine learning and statistical analysis. A case study integrates the approach in a context-aware mobile phone. The results indicate that the method is able to create a meaningful user context model while only requiring data from comfortable wearable sensor devices.	Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Inst Complex Engineered Syst, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15213 USA	Krause, A (reprint author), Carnegie Mellon Univ, Dept Comp Sci, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	krausea@cs.cmu.edu; asim@cs.cmu.edu; dps@cs.cmu.edu					Bellman R., 1961, ADAPTIVE CONTROL PRO; Clarkson B., 2002, THESIS MIT MEDIA LAB; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; DEVAUL R, 2003, P 7 INT S WEAR COMP; FARRINGDON J, 1999, P 3 INT S WEAR COMP, P77; Feldman Barrett L., 2001, Social Science Computer Review, V19; French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2; Gansner ER, 2000, SOFTWARE PRACT EXPER, V30, P1203, DOI 10.1002/1097-024X(200009)30:11<1203::AID-SPE338>3.0.CO;2-N; Gemperle F, 1998, P 2 INT S WEAR COMP, P116; Heckerman D, 1998, NATO ADV SCI I D-BEH, V89, P301; HUDSON S, 2003, P SIGCHI C HUM FACT; HUDSON SE, 2004, P SIGCHI C HUM FACT; Kohonen T., 1993, P IEEE INT C NEUR NE, P1147; KOHONEN T, 1995, SELF ORG MAP, P27; KRAUSE A, 2003, P 7 INT S WEAR COMP; MORAVEJI N, 2003, ANAL INTERRUPTIBILIT; SMAILAGIC A, 2002, IEEE WIRELESS COMM O; Smailagic A., 2002, IEEE Pervasive Computing, V1, DOI 10.1109/MPRV.2002.1158275; STAGER M, 2003, P 7 INT S WEAR COMP; Van Laerhoven K, 2001, LECT NOTES COMPUT SC, V2130, P464; VANLAERHOVEN K, 2000, P 4 INT S WEAR COMP; WIEWIOREK DP, 2003, P 7 INT S WEAR COMP	23	51	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1536-1233		IEEE T MOBILE COMPUT	IEEE. Trans. Mob. Comput.	FEB	2006	5	2					113	127		10.1109/TMC.2006.18		15	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	993FL	WOS:000233939900002	
J	Kurgan, LA; Cios, KJ; Dick, S				Kurgan, LA; Cios, KJ; Dick, S			Highly scalable and robust rule learner: Performance evaluation and comparison	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						complexity; data mining; DataSqueezer; machine learning; missing data; rule induction; rule learner	KNOWLEDGE DISCOVERY; CLASSIFICATION; ALGORITHM; DISCRETIZATION	Business intelligence and bioinformatics applications increasingly require the mining of datasets consisting of millions of data points, or crafting real-time enterprise-level decision support systems for large corporations and drug companies. In all cases, there needs to be an underlying data mining system, and this mining system must be highly scalable. To this end, we describe a new rule learner called DataSqueezer. The learner belongs to the family of inductive supervised rule extraction algorithms. DataSqueezer is a simple, greedy, rule builder that generates a set of production rules from labeled input data. In spite of its relative simplicity, DataSqueezer is a very effective learner. The rules generated by the algorithm are compact, comprehensible, and have accuracy comparable to rules generated by other state-of-the-art rule extraction algorithms. The main advantages of DataSqueezer are very high efficiency, and missing data resistance. DataSqueezer exhibits log-linear asymptotic complexity with the number of training examples, and it is faster than other state-of-the-art rule learners. The learner is also robust to large quantities of missing data, as verified by extensive experimental comparison with the other learners. DataSqueezer is thus well suited to modern data mining and business intelligence tasks, which commonly involve huge datasets with a large fraction of missing data.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2VF, Canada; Univ Colorado, Dept Comp Sci & Engn, Denver, CO 80217 USA; Hlth Sci Ctr, Denver, CO 80217 USA; Univ Colorado, Dept Comp Sci, Boulder, CO 80309 USA; LLC, Golden, CO 80401 USA	Kurgan, LA (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2VF, Canada.		Kurgan, Lukasz/B-5721-2009	Kurgan, Lukasz/0000-0002-7749-0314			ABRAHAM T, 1999, P 1 INT WORKSH DAT W, P41; Bay SD, 2001, DATA MIN KNOWL DISC, V5, P213, DOI 10.1023/A:1011429418057; BLACKARD JA, 1998, THESIS COLORADO STAT; BLAKE C, 1998, UCI REPOSITORY ML DA; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; Brachman R., 1996, ADV KNOWLEDGE DISCOV; Breiman L, 1984, CLASSIFICATION REGRE; Catlett J., 1991, P 8 INT WORKSH MACH, P596; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008640732416; Chawla NV, 2004, J MACH LEARN RES, V5, P421; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; CHISHOLM M, 2002, P INT C MACH LEARN, P75; CHIU D, 1991, KNOWLEDGE DISCOVERY; Cios K, 1998, DATA MINING METHODS; Cios KJ, 2004, INFORM SCIENCES, V163, P37, DOI 10.1016/j.ins.2003.03.015; CIOS KJ, 2002, NEW LEARNING PARADIG, P276; Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0; Cios KJ, 2005, ADV INFO KNOW PROC, P1, DOI 10.1007/1-84628-183-0_1; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cohen W, 1993, P 13 INT JOINT C ART, P988; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); COHEN WW, 1994, ARTIF INTELL, V68, P303, DOI 10.1016/0004-3702(94)90070-1; Cohen WW, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P709; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dain O, 2004, SIAM PROC S, P138; DIETTERICH TG, 1981, ARTIF INTELL, V16, P257, DOI 10.1016/0004-3702(81)90002-3; DOMINGOS P, 1994, PROC INT C TOOLS ART, P704, DOI 10.1109/TAI.1994.346421; Duda R.O, 1973, PATTERN CLASSIFICATI; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV; Freitas A. A., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Furnkranz Johannes, 1994, MACH LEARN, P70; HALL L, 1999, P WORKSH LARG SCAL P, P77; Hettich S., 1999, UCI KDD ARCH; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KAUFMAN KA, 1999, P 11 INT S METH INT, P411; Kerber R., 1992, P 10 NAT C ART INT, P123; KODRATOFF Y, 1988, INTRO MACHINE LEARNI; KUFRIN R, 1997, P 14 NAT C ART INT A, P565; KURGAN L, 2001, P 2001 INT C ART INT, P980; KURGAN L, 2005, NEXT GENERATION DATA, P415; KURGAN LA, 2003, THESIS U COLORADO BO; KURGAN LA, 2002, P SPIE INT C SENS FU, V6, P22; Kurgan LA, 2004, IEEE T KNOWL DATA EN, V16, P145, DOI 10.1109/TKDE.2004.1269594; KURGAN LA, 2003, P 2003 INT C MACH LE, P30; KURGAN LA, 2004, P 7 INT WORKSH HIGH, P18; Langley P., 1996, ELEMENTS MACHINE LEA; LANGLEY P, 1995, COMMUN ACM, V38, P55; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Mitchell T, 1997, MACHINE LEARNING; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Paliouras G., 2001, LECT NOTES COMPUTER, P2049; PAZZANI M, 1992, MACH LEARN, V9, P57, DOI 10.1007/BF00993254; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PROVOST F, 1999, DATA MIN KNOWL DISC, V2, P131; Provost FJ, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P74; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; QUINLAN JR, 1999, P 16 INT C MACH LEAR, P523; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; RANKA S, 2004, 7 INT WORKSH HIGH PE; Roddick JF, 2002, IEEE T KNOWL DATA EN, V14, P750, DOI 10.1109/TKDE.2002.1019212; Schapire R. E., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279960; Sebag M., 1996, P 13 INT C MACH LEAR, P444; SPILIOPOULOU M, 2000, DATA MINING, V1, P309; Theron H, 1996, MACH LEARN, V24, P5, DOI 10.1023/A:1018077511624; Vapnik V. N, 1995, NATURE STAT LEARNING; VLACHOS P, 2000, STATLIB PROJECT REPO; Webb G. I., 1992, ARTIF INTELL, V4, P3; Weiss S. M., 1991, P 12 INT JOINT C ART, P678; WINTER R, 2004, INTEL ENTERPRISE MAY; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	80	9	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	FEB	2006	36	1					32	53		10.1109/TSMCB.2005.852983		22	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	006FT	WOS:000234882600004	
J	Kalman, M; Havasi, F; Gyimothy, T				Kalman, M; Havasi, F; Gyimothy, T			Compacting XML documents	INFORMATION AND SOFTWARE TECHNOLOGY			English	Article						XML; SRML; XML compaction; XML semantics		Nowadays, one of the most common formats for storing information is XML. The biggest drawback of XML documents is that their size is rather large compared to the information they store. XML documents may contain redundant attributes, which can be calculated from others. These redundant attributes can be deleted from the original XML document if the calculation rules can be stored somehow. In an Attribute Grammar environment there is an analog description for these rules: semantic rules. In order to use this technique in an XML environment we defined a new metalanguage called SRML. We have developed a method, which enables us to use this SRML metalanguage for compacting XML documents. After compaction it is possible to use XML compressors to make the compacted document much smaller. By using this combined approach we could achieve a significant size reduction compared to the compressed size of the XML specific compressors. This article extends the method published earlier to provide the possibility of automatically generating rules using machine learning techniques, with which it can find relationships between attributes which might not have been noticed by the user beforehand. (c) 2005 Elsevier B.V. All rights reserved.	Dept Software Engn, H-6720 Szeged, Hungary	Kalman, M (reprint author), Dept Software Engn, Aradi Vet Tere 1, H-6720 Szeged, Hungary.	kalman@inf.u-szeged.hu					ALBLAS H, 1991, LECT NOTES COMPUT SC, V545, P1; BRAY T, EXTENSIBLE MARKUP LA; CANNATARO M, 2001, SEMANTIC LOSSY COMPR; CHENEY J, 2001, P DAT COMPR C IEEE C; COKUS M, 2002, XML C EXP BALT CONV; Ferenc R., 2001, Proceedings Eighth Working Conference on Reverse Engineering, DOI 10.1109/WCRE.2001.957809; Ferenc R, 2002, PROC IEEE INT CONF S, P172, DOI 10.1109/ICSM.2002.1167764; GOLDFARB CF, 2001, XML HDB; Gyimothy T., 1997, Nordic Journal of Computing, V4; Havasi F., 2002, Acta Cybernetica, V15; Hirakawa M, 2002, NUCLEIC ACIDS RES, V30, P158, DOI 10.1093/nar/30.1.158; KALMAN M, 2003, P 8 S PROGR LANG SOF, P137; Knuth D. E., 1968, Mathematical Systems Theory, V2, DOI 10.1007/BF01692511; Lanza M., 2003, Proceedings Seventh European Conference on Software Maintenance and Reengineering; LEVENE M, 2002, XML STRUCTURE COMPRE; Liefke H., 2000, P 2000 ACM SIGMOD IN, P153, DOI 10.1145/342009.335405; Mitchell T, 1997, MACHINE LEARNING; PASILA G, P 2 WORKSH ATTR GRAM, P113; QUINLAN JR, 1990, READINGS MACHINE LEA, P57; SCHAFNER B, 2003, MODEL XML DTDS RATIO; TOLANI P, 2002, P 18 INT C DAT ENG I	21	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-5849		INFORM SOFTWARE TECH	Inf. Softw. Technol.	FEB	2006	48	2					90	106		10.1016/j.infsof.2005.03.001		17	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	999OD	WOS:000234398100002	
J	Ciaramella, A; Tagliaferri, R; Pedrycz, W; Di Nola, A				Ciaramella, A; Tagliaferri, R; Pedrycz, W; Di Nola, A			Fuzzy relational neural network	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article; Proceedings Paper	5th International Workshop on Fuzzy Logic and Applications	OCT 09-11, 2003	Naples, ITALY			fuzzy relations; neural networks; neuro-fuzzy systems; classification and approximation tasks		In this paper a fuzzy neural network based on a fuzzy relational "IF-THEN" reasoning scheme is designed. To define the structure of the model different t-norms and t-conorms are proposed. The fuzzification and the defuzzification phases are then added to the model so that we can consider the model like a controller. A learning algorithm to time the parameters that is based on a back-propagation algorithm and a recursive pseudoinverse matrix technique is introduced. Different experiments on synthetic and benchmark data are made. Several results using the UCl repository of Machine learning database are showed for classification and approximation tasks. The model is also compared with some other methods known in literature. (C) 2005 Elsevier Inc. All rights reserved.	Univ Salerno, DMI, I-84081 Baronissi, SA, Italy; Univ Salerno, INFM, I-84081 Baronissi, SA, Italy; Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2G6, Canada; Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland	Ciaramella, A (reprint author), Univ Salerno, DMI, I-84081 Baronissi, SA, Italy.	ciaram@unisa.it; robtag@unisa.it; pedrycz@ee.ualberta.ca; adinola@unisa.it					BABUSKA R, 2001, DISC COURSE LECT NOT; BALDWIN JF, 1979, INT J MAN MACH STUD, V11, P351, DOI 10.1016/S0020-7373(79)80030-9; Bishop C.M., 1995, NEURAL NETWORKS PATT; CIARAMELLA A, 2001, P 10 IEEE INT C FUZZ; Ciaramella A, 2005, FUZZY SET SYST, V151, P303, DOI 10.1016/j.fss.2004.07.003; CIARAMELLA A, 2003, P WILF C NAP OCT 9 1; CIARAMELLA A, 2002, THESIS U SALERNO ITA; Jang J.-S. R., 1997, NEUROFUZZY SOFT COMP; Lin C. T., 1996, NEURAL FUZZY SYSTEMS; Nabney I T, 2002, NETLAB ALGORITHMS PA; NAUCK D, 1996, P BIENN C N AM FUZZ; Nauck D., 1995, APPL COMPUTING 1995, P461; Pedrycz W, 1993, FUZZY CONTROL FUZZY; Penrose R, 1955, P CAMBRIDGE PHILOS S, V51, P406; PRECHELT L, 1994, 2194; TAGLIAFERRI R, 2004, FUZZY PARTIAL DIFFER; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	17	20	20	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X		INT J APPROX REASON	Int. J. Approx. Reasoning	FEB	2006	41	2					146	163		10.1016/j.ijar.2005.06.016		18	Computer Science, Artificial Intelligence	Computer Science	007CR	WOS:000234945900006	
J	Abdel-Aal, RE				Abdel-Aal, RE			Modeling and forecasting electric daily peak loads using abductive networks	INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS			English	Article						abductive networks; neural networks; GMDH; machine learning; modeling; forecasting; load forecasting; peak load; STLF; power system planning	ARTIFICIAL NEURAL NETWORKS; SAUDI-ARABIA; TEMPERATURE	Forecasting the daily peak load is important for secure and profitable operation of modern power utilities. Machine learning techniques including neural networks have been used for this purpose. This paper proposes the alternative modeling approach of abductive networks, which offers simpler and more automated model synthesis. Resulting analytical input-output models automatically select influential inputs, give better insight and explanations, and allow comparison with other empirical models. Developed using peak load and extreme temperature data for 5 years and evaluated on the sixth year, a model forecasts next-day peak loads with an overall mean absolute percentage error (MAPE) of 2.50%, outperforming neural network models and flat forecasting for the same data. Two methods are described for forecasting daily peak loads up to 1 week ahead through iterative use of the next-day model or using seven dedicated models. Effects; of varying model complexity are considered, and simplified analytical expressions are derived for the peak load. Proposals are made for further improving the forecasting accuracy. (C) 2005 Elsevier Ltd. All rights reserved.	King Fahd Univ Petr & Minerals, Dept Comp Engn, Dhahran 31261, Saudi Arabia	Abdel-Aal, RE (reprint author), King Fahd Univ Petr & Minerals, Dept Comp Engn, POB 1759, Dhahran 31261, Saudi Arabia.	radwan@kfupm.edu.sa					ABDELAAL RE, 1995, WEATHER FORECAST, V10, P310, DOI 10.1175/1520-0434(1995)010<0310:MAFTDM>2.0.CO;2; AbdelAal RE, 1997, ENERGY, V22, P911, DOI 10.1016/S0360-5442(97)00019-4; ABDELAAL RE, 1994, ENERGY, V19, P739, DOI 10.1016/0360-5442(94)90012-4; Abdel-Aal RE, 2004, IEEE T POWER SYST, V19, P164, DOI 10.1109/TPWRS.2003.820695; ABOULMAGD MA, 2001, P LARG ENG SYST C PO, P105; AbTech Corporation, 1990, AIM US MAN; AlFuhaid AS, 1997, IEEE T POWER SYST, V12, P1524, DOI 10.1109/59.627852; Asar A.-U., 1994, IEEE Transactions on Control Systems Technology, V2, DOI 10.1109/87.294341; Barron A., 1984, SELF ORG METHODS MOD, P87; CHARYTONIUK W, 2000, P INT C EL UT DER RE, P554; DASILVA APA, 2001, IEEE POW TECHN C POR; DILLON TS, 1975, 5TH P PSCC, P1; DILLON TS, 1991, INT J ELEC POWER, V13, P186, DOI 10.1016/0142-0615(91)90021-M; DILLON TS, 1996, NEURAL NETWORKS APPL, P387; El Desouky AA, 2000, IEE P-GENER TRANSM D, V147, P213, DOI 10.1049/ip-gtd:20000521; Farlow SJ, 1984, SELF ORG METHODS MOD, P1; Frost F., 1999, Proceedings Third International Conference on Computational Intelligence and Multimedia Applications. ICCIMA'99 (Cat. No.PR00300), DOI 10.1109/ICCIMA.1999.798499; GROSS G, 1987, P IEEE, V75, P1558, DOI 10.1109/PROC.1987.13927; HAIDA T, 1994, IEEE T POWER SYST, V9, P1788, DOI 10.1109/59.331433; Hippert HS, 2001, IEEE T POWER SYST, V16, P44, DOI 10.1109/59.910780; HSU YY, 1991, IEE PROC-C, V138, P414; Khotanzad A, 1998, IEEE T POWER SYST, V13, P1413, DOI 10.1109/59.736285; LAM HK, 2001, 27 ANN C IEEE IND EL, P25; LEWIS HW, 2001, P MOUNT WORKSH SOFT, P25; MATSUI T, 2001, P IEEE POW ENG SOC W, P405; Montgomery GJ, 1990, P SPIE C APPL ART NE, P56; MORIOKA Y, 1993, P 2 INT FOR APPL NEU, P60; ONODA T, 1993, P 2 INT FOR APPL NEU, P284; Saini LM, 2002, IEEE T POWER SYST, V17, P907, DOI 10.1109/TPWRS.2002.800992; Senjyu T, 2002, IEEE T POWER SYST, V17, P113, DOI 10.1109/59.982201; Tenorio M F, 1990, IEEE Trans Neural Netw, V1, P100, DOI 10.1109/72.80209	31	6	6	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0142-0615		INT J ELEC POWER	Int. J. Electr. Power Energy Syst.	FEB	2006	28	2					133	141		10.1016/j.ijepes.2005.11.006		9	Engineering, Electrical & Electronic	Engineering	024RF	WOS:000236213000008	
J	Ozawa, S; Pang, SN; Kasabov, N				Ozawa, Seiichi; Pang, Shaoning; Kasabov, Nikola			On-line feature selection for adaptive evolving connectionist systems	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL			English	Article; Proceedings Paper	International Workshop on Fuzzy Systems and Innovational Computing	JUN 02-03, 2004	Kitalyushu, JAPAN			one-line learning; incremental learning; pattern recognition; feature selection	NEURAL NETWORK; RECOGNITION	A new concept for pattern classification systems is proposed in which the feature selection and the learning classifier are simultaneously carried out on-line. An advantage of this concept is that classification systems can improve their performance constantly even if insufficient training samples are given when the learning starts, often resulting in inappropriate feature selection and poor classifier performance. To implement this concept, we propose an adaptive evolving connectionist model in which Incremental Principal Component Analysis and Evolving Clustering Method are effectively combined. The proposed on-line learning scheme has two major desirable properties. First, the performance is improved as the learning proceeds and it converges to an acceptable level from any initial conditions. Second, the learning is sequentially carried out without retaining all the training data given so far; thus, the learning is conducted efficiently in term of the computation and memory costs. To evaluate the proposed model, the recognition performance is investigated using three standard datasets in the UCI machine learning repository. From the experimental results, we verify that the proposed scheme possesses the above two characteristics.	Kobe Univ, Grad Sch Sci & Technol, Kobe, Hyogo 6578501, Japan; Auckland Univ Technol, Knowledge Engn & Design Res Inst, Auckland 1020, New Zealand	Ozawa, S (reprint author), Kobe Univ, Grad Sch Sci & Technol, 1-1 Rokkodai, Kobe, Hyogo 6578501, Japan.	ozawasei@kobe-u.ac.jp; spang@aut.ac.nz; nkasabov@aut.ac.nz					Atkeson CG, 1997, ARTIF INTELL REV, V11, P75, DOI 10.1023/A:1006511328852; CARPENTER GA, 1988, COMPUTER, V21, P77, DOI 10.1109/2.33; Chandrasekaran S, 1997, GRAPH MODEL IM PROC, V59, P321, DOI 10.1006/gmip.1997.0425; FU HC, 2001, IEEE T NEURAL NETWOR, V2, P250; Hall P, 1998, P BRIT MACH VIS C, V1, P286; Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525; Kasabov N., 2002, EVOLVING CONNECTIONI; Kasabov NK, 2002, IEEE T FUZZY SYST, V10, P144, DOI 10.1109/91.995117; KOBAYASHI M, 2001, P INT JOINT C NEUR N, P1989; Kotani M, 2004, NEUROCOMPUTING, V62, P427, DOI 10.1016/j.neucom.2004.06.002; LIN R, 2004, P 17 INT C PATT REC, V2, P757; LIU C, 2000, P INT C PATT REC, P1249; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511; OJA E, 1985, J MATH ANAL APPL, V106, P69, DOI 10.1016/0022-247X(85)90131-3; Ozawa S, 2005, NEURAL NETWORKS, V18, P575, DOI 10.1016/j.neunet.2005.06.016; Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Schaal S, 1998, NEURAL COMPUT, V10, P2047, DOI 10.1162/089976698300016963; Thrun S, 1998, LEARNING LEARN; Toh S. L., 2003, Proceedings of the Eighth Australian and New Zealand Intelligent Information Systems Conference (ANZIIS 2003); VERMEULEN PJE, 1991, OPT ENG, V30, P415, DOI 10.1117/12.55812; WENG J, 1993, IEEE T PATTERN ANAL, V25, P1034; Weng J., 2000, P 4 IEEE INT C AUT F, P251; Yamauchi K, 1999, IEEE T NEURAL NETWOR, V10, P1351, DOI 10.1109/72.809080; Yan J., 2004, P 10 ACM SIGKDD INT, P725, DOI 10.1145/1014052.1014147; [Anonymous], UCI MACH LEARN REP	27	9	9	ICIC INTERNATIONAL	KUMAMOTO	KYUSHU TOKAI UNIV, 9-1-1, TOROKU, KUMAMOTO, 862-8652, JAPAN	1349-4198		INT J INNOV COMPUT I	Int. J. Innov. Comp. Inf. Control	FEB	2006	2	1					181	192				12	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	108QV	WOS:000242255200015	
J	Beynon, MJ				Beynon, MJ			An introduction of the condition class space with continuous value discretization and rough set theory	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article								The granularity of an information system has an incumbent effect on the efficacy of the analysis from many machine learning algorithms. An information system contains a universe of objects characterized and categorized by condition and decision attributes. To manage the concomitant granularity, a level of continuous value discretization (CVD) is often undertaken. In the case of the rough set theory (RST) methodology for object classification, the granularity contributes to the grouping of objects into condition classes with the same condition attribute values. This article exposits the effect of a level of CVD on the subsequent condition classes constructed, with the introduction of the condition class space-the domain within which the condition classes exist. This domain elucidates the association of the condition classes to the related decision outcomes-reflecting the inexactness incumbent when a level of CVD is undertaken. A series of measures is defined that quantify this association. Throughout this study and without loss of generality, the findings are made through the RST methodology. This further offers a novel exposition of the relationship between all the condition attributes and the RST-related reducts (subsets of condition attributes). (c) 2006 Wiley Periodicals, Inc.	Cardiff Univ, Cardiff Business Sch, Cardiff CF10 3EU, Wales	Beynon, MJ (reprint author), Cardiff Univ, Cardiff Business Sch, Colum Dr, Cardiff CF10 3EU, Wales.	BeynonMJ@cardiff.ac.uk					BAZAN TG, 1998, ROUGH SETS KNOWLEDGE, V1, P451; Beynon MJ, 2001, OMEGA-INT J MANAGE S, V29, P561, DOI 10.1016/S0305-0483(01)00045-7; Beynon MJ, 2004, INT J APPROX REASON, V35, P29, DOI 10.1016/S0888-613X(03)00057-4; BROWNE C, 1998, ROUGH SETS KNOWLEDGE, V2, P345; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; DUNSTCH I, 1997, INT J HUM-COMPUT ST, V46, P589; Forina M, 1988, PARVUS EXTENDABLE PA; Liu H, 1996, KNOWL-BASED SYST, V9, P67, DOI 10.1016/0950-7051(95)01030-0; Nguyen H. S., 1998, ROUGH SETS KNOWLEDGE, P451; NGUYEN H S, 1998, P 1 INT C ROUGH SETS, P545; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1991, ROUGH SETS THEORETIC; SLOWINSKI K, 1990, INT J MAN MACH STUD, V32, P693, DOI 10.1016/S0020-7373(05)80108-7; TEGHEM J, 1992, HDB APPL ADV ROUGH S, V11, P267; Wright G, 1992, EXPERTISE DECISION S	18	1	1	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0884-8173		INT J INTELL SYST	Int. J. Intell. Syst.	FEB	2006	21	2					173	191		10.1002/int.20126		19	Computer Science, Artificial Intelligence	Computer Science	011VL	WOS:000235296500004	
J	Liang, NY; Saratchandran, P; Huang, GB; Sundararajan, N				Liang, NY; Saratchandran, P; Huang, GB; Sundararajan, N			Classification of mental tasks from EEG signals using extreme learning machine	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS			English	Article						Brain Computer Interfaces (BCIs); electroencephalogram (EEG); mental task classification; Support Vector Machines (SVMs); Backpropagation Neural Networks (BPNNs); Extreme Learning Machine (ELM)	COMPUTER INTERFACE TECHNOLOGY; NETWORKS	In this paper, a recently developed machine learning algorithm referred to as Extreme Learning Machine (ELM) is used to classify five mental tasks from different subjects using electroencephalogram (EEG) signals available from a well-known database. Performance of ELM is compared in terms of training time and classification accuracy with a Backpropagation Neural Network (BPNN) classifier and also Support Vector Machines (SVMs). For SVMs, the comparisons have been made for both 1-against-1 and I-against-all methods. Results show that ELM needs an order of magnitude less training time compared with SVMs and two orders of magnitude less compared with BPNN. The classification accuracy of ELM is similar to that of SVMs and BPNN. The study showed that smoothing of the classifiers' outputs can significantly improve their classification accuracies.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Liang, NY (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.	lny@pmail.ntu.edu.sg; epsarat@ntu.edu.sg; egbhuang@ntu.edu.sg; ensundara@ntu.edu.sg	Huang, Guang-Bin/A-5035-2011				Anderson C.W., 1996, P C ENG APPL NEUR NE, P407; ANDERSON CW, 2003, CLASSIFICATION ELECT; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; Baum E. B., 1988, Journal of Complexity, V4, DOI 10.1016/0885-064X(88)90020-9; Celka P, 2001, IEEE ENG MED BIOL, V20, P30, DOI 10.1109/51.956817; Garrett D, 2003, IEEE T NEUR SYS REH, V11, P141, DOI 10.1109/TNSRE.2003.814441; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hinterberger T, 2003, CLIN NEUROPHYSIOL, V114, P416, DOI 10.1016/S1388-2457(02)00411-X; Hsu C. W., 2003, PRACTICAL GUIDE SUPP; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; HUANG GB, 2004, P INT JOINT C NEUR N, V2, P985; HUANG GB, 2004, BENCHMARKING ELM; HUANG GB, 2006, IN PRESS NEUROCOMPUT; KEIRN ZA, 1998, THESIS PURDUE U; Muller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484; Pardey J, 1996, MED ENG PHYS, V18, P2, DOI 10.1016/1350-4533(95)00024-0; Serre D., 2002, MATRICES THEORY APPL; Vapnik VN, 1998, STAT LEARNING THEORY; Vaughan TM, 2003, IEEE T NEUR SYS REH, V11, P94, DOI 10.1109/TNSRE.2003.814799; Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P164, DOI 10.1109/TRE.2000.847807	20	26	28	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657		INT J NEURAL SYST	Int. J. Neural Syst.	FEB	2006	16	1					29	38		10.1142/S0129065706000482		10	Computer Science, Artificial Intelligence	Computer Science	017LI	WOS:000235694700003	
J	Baumgartner, C; Baumgartner, D				Baumgartner, C; Baumgartner, D			Biomarker discovery, disease classification, and similarity query processing on high-throughput MS/MS data of inborn errors of metabolism	JOURNAL OF BIOMOLECULAR SCREENING			English	Article						biomarker discovery; disease classification; similarity query processing; tandem mass spectrometry; metabolic disorders	TANDEM MASS-SPECTROMETRY; COA DEHYDROGENASE-DEFICIENCY; DISORDERS; IDENTIFICATION; PATTERNS; NEWBORNS; SERUM	In newborn errors of metabolism, biomarkers are urgently needed for disease screening, diagnosis, and monitoring of therapeutic interventions. This article describes a 2-step approach to discover metabolic markers, which involves (1) the identification of marker candidates and (2) the prioritization of them based on expert knowledge of disease metabolism. For step 1, the authors developed a new algorithm, the biomarker identifier (BMI), to identify markers from quantified diseased versus normal tandem mass spectrometry data sets. BMI produces a ranked list of marker candidates and discards irrelevant metabolites based on a quality measure, taking into account the discriminatory performance, discriminatory space, and variance of metabolites' concentrations at the state of disease. To determine the ability of identified markers to classify subjects, the authors compared the discriminatory performance of several machine-learning paradigms and described a retrieval technique that searches and classifies abnormal metabolic profiles from a screening database. Seven inborn errors of metabolism-phenylketonuria (PKU), glutaric acidemia type I (GA-I), 3-methylcrotonylglycinemia deficiency (3-MCCD), methylmalonic acidernia (MMA), propionic acidernia (PA), medium-chain acyl CoA dehydrogenase deficiency (MCADD), and 3-OH long-chain acyl CoA dehydrogenase deficiency (LCHADD)-were investigated. All primarily prioritized marker candidates could be confirmed by literature. Some novel secondary candidates were identified (i.e., C 16:1 and C4DC for PKU, C4DC for GA-I, and C18:1 for MCADD), which require further validation to confirm their biochemical role during, health and disease.	Univ Hlth Sci Med Informat & Technol, Inst Biomed Engn, Res Grp Clin Bioinformat, Eduard Wallnofer Zentrum 1, A-6060 Hall In Tyrol, Austria; Innsbruck Med Univ, Dept Pediat, A-6020 Innsbruck, Austria	Baumgartner, C (reprint author), Univ Hlth Sci Med Informat & Technol, Inst Biomed Engn, Res Grp Clin Bioinformat, Eduard Wallnofer Zentrum 1, A-6060 Hall In Tyrol, Austria.	christian.baumgartner@umit.at					Baggerly KA, 2004, BIOINFORMATICS, V20, P777, DOI 10.1093/bioinformatics/btg484; Ball G, 2002, BIOINFORMATICS, V18, P395, DOI 10.1093/bioinformatics/18.3.395; Baumgartner C, 2005, J BIOMED INFORM, V38, P89, DOI 10.1016/j.jbi.2004.08.009; Baumgartner C, 2004, BIOINFORMATICS, V20, P2985, DOI 10.1093/bioinformatics/bth343; BLAU N, 2001, METABOLIC MOL BASES; Chace DH, 1999, ACTA PAEDIATR, V88, P45, DOI 10.1080/080352599750029367; Charrow Joel, 2000, Genetics in Medicine, V2, P267; Clayton PT, 1998, ARCH DIS CHILD, V79, P109; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dezateux C, 2003, EUR J PEDIATR, V162, pS25, DOI 10.1007/s00431-003-1346-0; DONLON J, 2004, METABOLIC MOL BASES; Duda R. O., 2001, PATTERN CLASSIFICATI; Dunn WB, 2005, ANALYST, V130, P606, DOI 10.1039/b418288j; Gamache PH, 2004, J AM SOC MASS SPECTR, V15, P1717, DOI 10.1016/j.jasms.2004.08.016; Gao J, 2005, METHODS, V35, P291, DOI 10.1016/j.ymeth.2004.08.020; Gelman A., 2004, BAYESIAN DATA ANAL; German JB, 2004, J NUTR, V134, P2729; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hoffmann GF, 1999, J INHERIT METAB DIS, V22, P381, DOI 10.1023/A:1005543904484; Hosmer DW, 2000, APPL LOGISTIC REGRES; Lee JW, 2005, PHARM RES, V22, P499, DOI 10.1007/s11095-005-2484-z; Mitchell T, 1997, MACHINE LEARNING; Neville P, 2003, PROTEOMICS, V3, P1710, DOI 10.1002/pmic.200300516; Purohit PV, 2003, PROTEOMICS, V3, P1699, DOI 10.1002/pmic.200300518; Rinaldo P, 2002, ANNU REV PHYSIOL, V64, P477, DOI 10.1146/annurev.physiol.64.082201.154705; Roschinger W, 2003, EUR J PEDIATR, V162, pS67, DOI 10.1007/s00431-003-1356-y; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Strauss AW, 2004, J CLIN INVEST, V113, P354, DOI 10.1172/JCI200420924; Vlahou A, 2003, J BIOMED BIOTECHNOL, P308; Wilcken B, 2003, NEW ENGL J MED, V348, P2304, DOI 10.1056/NEJMoa025225; Yu JS, 2005, BIOINFORMATICS, V21, P2200, DOI 10.1093/bioinformatics/bti370; *AM COLL MED GEN A, 2000, GENET MED, V2, P267	32	13	14	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1087-0571		J BIOMOL SCREEN	J. Biomol. Screen	FEB	2006	11	1					90	99		10.1177/1087057105280518		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Chemistry, Analytical	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Chemistry	016GT	WOS:000235609400011	
J	Hamerly, G; Perelman, E; Lau, J; Calder, B; Sherwood, T				Hamerly, G; Perelman, E; Lau, J; Calder, B; Sherwood, T			Using machine learning to guide architecture simulation	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						K-means; random projection; Bayesian information criterion; simulation; SimPoint	MODEL	An essential step in designing a new computer architecture is the careful examination of different design options. It is critical that computer architects have efficient means by which they may estimate the impact of various design options on the overall machine. This task is complicated by the fact that different programs, and even different parts of the same program, may have distinct behaviors that interact with the hardware in different ways. Researchers use very detailed simulators to estimate processor performance, which models every cycle of an executing program. Unfortunately, simulating every cycle of a real program can take weeks or months. To address this problem we have created a tool called SimPoint that uses data clustering algorithms from machine learning to automatically find repetitive patterns in a program's execution. By simulating one representative of each repetitive behavior pattern, simulation time can be reduced to minutes instead of weeks for standard benchmark programs, with very little cost in terms of accuracy. We describe this important problem, the data representation and preprocessing methods used by SimPoint, the clustering algorithm at the core of SimPoint, and we evaluate different options for tuning SimPoint.	Baylor Univ, Dept Comp Sci, Waco, TX 76798 USA; Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA; Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA	Hamerly, G (reprint author), Baylor Univ, Dept Comp Sci, 1 Bear Pl,97356, Waco, TX 76798 USA.	HAMERLY@CS.BAYLOR.EDU; EPERELMA@CS.UCSD.EDU; JL@CS.UCSD.EDU; CALDER@CS.UCSD.EDU; SHERWOOD@CS.UCSB.EDU					Achlioptas D., 2001, P ACM S PRINC DAT SY, P274, DOI 10.1145/375551.375608; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; ANNAVARAM M, 2004, INT S MICR DEC; Bellman R., 1961, ADAPTIVE CONTROL PRO; Burger D. C., 1997, CSTR971342 U WISC; CHENG DY, 1984, P IEEE INT C AC SPEE; Dasgupta S., 2000, UNCERTAINTY ARTIFICI, P143; DASGUPTA S, 2003, COLT, P735; Elkan C., 2003, ICML, P147; Farnstrom F, 2000, SIGKDD EXPLORATIONS, V2, P51; Fayyad U., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; HAMERLY G, 2006, P 2006 IEEE INT S PE; HAMERLY G, 2003, ADV NIPS; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; INDYK P, 1999, P ANN S FDN COMP SCI, P160; LAU J, 2005, 11 INT S HIGH PERF C; LAU J, 2004, IEEE INT S PERF AN S; LAU J, 2005, IEEE INT S PERF AN S; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; MCNAMES J, 2000, IEEE SIGNAL PROCESSI, V7; Moore A.W., 2000, P 12 C UNC ART INT, P397; PATIL H, 2004, INT S MICR DEC; Pelleg D., 2000, P 17 INT C MACH LEAR, P727; PERELMAN E., 2006, P INT S COD GEN OPT; PERELMAN E, 2003, INT C PAR ARCH COMP; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SANGHAI K, 2005, KDD, P808; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHERWOOD T, 2003, 30 ANN INT S COMP AR; Sherwood T., 2001, INT C PAR ARCH COMP; Sherwood T., 2002, 10 INT C ARCH SUPP P; Sherwood T., 1999, UCSDCS99630; SMYTH P, 1996, P 2 INT C KNOWL DISC; VANBIESBROUCK M, 2004, IEEE INT S PERF AN S; VANBIESBROUCK M, 2005, INT C HIGH PERF EMB	37	5	5	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2006	7						343	378				36	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026ID	WOS:000236331700006	
J	Zhang, ML; Zhou, ZH				Zhang, ML; Zhou, ZH			Adapting RBF neural networks to multi-instance learning	NEURAL PROCESSING LETTERS			English	Article						content-based image retrieval; Hausdorff distance; machine learning; multi-instance learning; neural networks; principle component analysis; radial basis function; singular value decomposition	GEOMETRIC PATTERNS; RECTANGLES; EXAMPLES	In multi-instance learning, the training examples are bags composed of instances without labels, and the task is to predict the labels of unseen bags through analyzing the training bags with known labels. A bag is positive if it contains at least one positive instance, while it is negative if it contains no positive instance. In this paper, a neural network based multi-instance learning algorithm named RBF-MIP is presented, which is derived from the popular radial basis function (RBF) methods. Briefly, the first layer of an RBF-MIP neural network is composed of clusters of bags formed by merging training bags agglomeratively, where Hausdorff metric is utilized to measure distances between bags and between clusters. Weights of second layer of the RBF-MIP neural network are optimized by minimizing a sum-of-squares error function and worked out through singular value decomposition (SVD). Experiments on real-world multi-instance benchmark data, artificial multi-instance benchmark data and natural scene image database retrieval are carried out. The experimental results show that RBF-MIP is among the several best learning algorithms on multi-instance problems.	Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China	Zhou, ZH (reprint author), Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China.	zhangml@lamda.nju.edu.cn; zhouzh@nju.edu.cn					Alphonse E, 2004, J INTELL INF SYST, V22, P23, DOI 10.1023/A:1025876613117; Amar R. A., 2001, P 18 INT C MACH LEAR, P3; Andrews S., 2002, ADV NEURAL INFORM PR, V15, P561; Auer P, 1998, J COMPUT SYST SCI, V57, P376, DOI 10.1006/jcss.1998.1593; Auer P., 1997, P 14 INT C MACH LEAR, P21; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; Blum A, 1998, MACH LEARN, V30, P23, DOI 10.1023/A:1007402410823; Chevaleyre YZ, 2001, LECT NOTES ARTIF INT, V2056, P204; De Raedt L., 1998, LECT NOTES ARTIF INT, V1446, P1; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DOLLY DR, 2001, LECT NOTES ARTIF INT, V2225, P167; Edgar GA, 1995, MEASURE TOPOLOGY FRA; Gartner T, 2002, P 19 INT C MACH LEAR, P179; Goldman SA, 2003, ANN MATH ARTIF INTEL, V39, P259, DOI 10.1023/A:1024671512350; Goldman SA, 2001, J COMPUT SYST SCI, V62, P123, DOI 10.1006/jcss.2000.1723; JOLLIFE IT, 1986, PRINCIPLE COMPONENT; Kearns M., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167200; KEARNS MJ, 1994, J COMPUT SYST SCI, V48, P464, DOI 10.1016/S0022-0000(05)80062-5; Lindsay RK, 1980, APPL ARTIFICIAL INTE; Long PM, 1998, MACH LEARN, V30, P7, DOI 10.1023/A:1007450326753; MARON O, 1998, THESIS MIT CAMBRIDTE; Maron O, 1998, P 15 INT C MACH LEAR, P341; Maron O, 1998, ADV NEUR IN, V10, P570; Press WH, 1992, NUMERICAL RECIPES C; Ray S, 2001, P 18 INT C MACH LEAR, P425; RUFFO G, 2000, THESIS U TURIN ITALY; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P318; SEBAG M, 1997, P 15 INT JOINT C ART, P888; Wang J., 2000, P 17 INT C MACH LEAR, P1119; Yang C., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839416; Zhang ML, 2004, NEURAL PROCESS LETT, V19, P1, DOI 10.1023/B:NEPL.0000016836.03614.9f; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Zhang Q., 2002, P 19 INT C MACH LEAR, P682; Zhou ZH, 2003, LECT NOTES ARTIF INT, V2837, P492; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zhou Z.-H., 2002, NEURAL NETWORKS MULT; ZUCKER JD, 1998, LECT NOTES ARTIF INT, V1446, P235; ZUCKER JD, 1996, P 13 INT C MACH LEAR, P543	40	12	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621		NEURAL PROCESS LETT	Neural Process. Lett.	FEB	2006	23	1					1	26		10.1007/s11063-005-2192-z		26	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	012DL	WOS:000235318300001	
J	Gallinat, J; Heinz, A				Gallinat, J; Heinz, A			Combination of multimodal imaging and molecular genetic information to investigate complex psychiatric disorders	PHARMACOPSYCHIATRY			English	Article; Proceedings Paper	Workshop on Systems Theory and Neurobiology Schizophrenia	2005	Munich, GERMANY				GAMMA-BAND RESPONSES; TO-NOISE RATIO; NUCLEUS-ACCUMBENS; DOPAMINE RELEASE; SCHIZOPHRENIA; GLUTAMATE; STIMULATION; BRAIN; ACTIVATION; RESONANCE	Multimodal imaging, the combination of several brain imaging techniques in one subject, provides a wealth of parameters and favours the interpretation of complex models in schizophrenia research. Moreover, new imaging tools allow the investigation of distinct neurotransmitter systems and their modulation by pharmacological intervention. An important feature of multimodal imaging is the possibility to characterize the activation dependencies of different neurotransmitters and provide the experimental tool to test system models of brain function and dysfunction. The combination of measurement techniques with high temporal resolution (e.g. MEG, EEG) and high spatial resolution (e.g. fMRI) facilitate the understanding of local and global systems as well as time characteristics. Moreover, the association of imaging parameters with genetic variations of neurotransmitter systems allows the investigation of neurotransmitter activity and its role in the pathophysiology of schizophrenia. To overcome the limitations of standard statistical methods, new approaches in machine learning have to be adapted to handle multiple parameters obtained from brain imaging and genetic measurements.	Charite Univ Berlin, Klin Psychiat & Psychotherapy, Berlin, Germany	Gallinat, J (reprint author), St Hedwig Krankenhaus, Clin Psychiat & Psychotherapy, Charite Med Berlin, Turmstr 21, D-10559 Berlin, Germany.	juergen.gallinat@charite.de					Alonso JM, 1996, NATURE, V383, P815, DOI 10.1038/383815a0; BasarEroglu C, 1996, INT J PSYCHOPHYSIOL, V24, P101, DOI 10.1016/S0167-8760(96)00051-7; BEARDSLEY PM, 1990, J PHARMACOL EXP THER, V252, P953; BRESSLER SL, 1993, NATURE, V366, P153, DOI 10.1038/366153a0; Buchsbaum MS, 1998, NEUROREPORT, V9, P425, DOI 10.1097/00001756-199802160-00013; CARLEZON WA, 1995, PSYCHOPHARMACOLOGY, V122, P194, DOI 10.1007/BF02246095; Carlezon WA, 1996, J NEUROSCI, V16, P3112; Chen YI, 1999, NEUROREPORT, V10, P2881, DOI 10.1097/00001756-199909290-00001; CIABARRA AM, 1995, J NEUROSCI, V15, P6498; Das S, 1998, NATURE, V393, P377; DOLAN RJ, 1995, NATURE, V378, P180, DOI 10.1038/378180a0; Drevets WC, 2001, BIOL PSYCHIAT, V49, P81, DOI 10.1016/S0006-3223(00)01038-6; Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565; Fletcher P, 1999, NEUROIMAGE, V9, P337, DOI 10.1006/nimg.1998.0411; Foong J, 2000, J NEUROL NEUROSUR PS, V68, P242, DOI 10.1136/jnnp.68.2.242; Ford JM, 2002, BIOL PSYCHIAT, V51, P485, DOI 10.1016/S0006-3223(01)01335-X; FRISTON KJ, 1995, CLIN NEUROSCI, V3, P89; GALLINAT J, 2005, UNPUB HIPPOCAMPAL GL; GALLINAT J, 2005, UNPUB GENETIC VARIAT; Gallinat J, 2003, BIOL PSYCHIAT, V54, P40, DOI 10.1016/S0006-3223(02)01973-X; Gallinat J, 2004, CLIN NEUROPHYSIOL, V115, P1863, DOI 10.1016/j.clinph.2004.03.013; Graepel T, 1999, NEURAL COMPUT, V11, P139, DOI 10.1162/089976699300016854; Haig AR, 2000, CLIN NEUROPHYSIOL, V111, P1461, DOI 10.1016/S1388-2457(00)00347-3; Heinz A, 2005, NAT NEUROSCI, V8, P20, DOI 10.1038/nn1366; Hochreiter S, 1999, NEURAL COMPUT, V11, P679, DOI 10.1162/089976699300016629; HYDE TM, 1992, ARCH NEUROL-CHICAGO, V49, P401; JOLIOT M, 1994, P NATL ACAD SCI USA, V91, P11748, DOI 10.1073/pnas.91.24.11748; JUCKEL G, 2005, IN PRESS NEUROIMAGE; Kubicki M, 2002, AM J PSYCHIAT, V159, P813, DOI 10.1176/appi.ajp.159.5.813; Lee KH, 2001, CLIN NEUROPHYSIOL, V112, P1499, DOI 10.1016/S1388-2457(01)00584-3; Marota JJA, 2000, NEUROIMAGE, V11, P13, DOI 10.1006/nimg.1999.0520; Norman RMG, 1997, BRIT J PSYCHIAT, V170, P411, DOI 10.1192/bjp.170.5.411; Reid MS, 2000, SYNAPSE, V35, P129, DOI 10.1002/(SICI)1098-2396(200002)35:2<129::AID-SYN5>3.0.CO;2-D; Schubert F, 2004, NEUROIMAGE, V21, P1762, DOI 10.1016/j.neuroimage.2003.11.014; Senkowski D, 2002, CLIN NEUROPHYSIOL, V113, P1742, DOI 10.1016/S1388-2457(02)00266-3; SINGER W, 1995, ANNU REV NEUROSCI, V18, P555, DOI 10.1146/annurev.neuro.18.1.555; Singer W, 1999, NEURON, V24, P49, DOI 10.1016/S0896-6273(00)80821-1; SUCHER NJ, 1995, J NEUROSCI, V15, P6509; Volkow ND, 1999, J PHARMACOL EXP THER, V291, P409; Vorel SR, 2001, SCIENCE, V292, P1175, DOI 10.1126/science.1058043; Winterer G, 2000, CLIN NEUROPHYSIOL, V111, P837, DOI 10.1016/S1388-2457(99)00322-3; Winterer G, 1999, CLIN NEUROPHYSIOL, V110, P1193, DOI 10.1016/S1388-2457(99)00059-0; You ZB, 1998, J NEUROSCI, V18, P6492; Zangen A, 2002, NEUROREPORT, V13, P2401, DOI 10.1097/01.wnr.0000048021.74602.f2	44	9	9	GEORG THIEME VERLAG KG	STUTTGART	RUDIGERSTR 14, D-70469 STUTTGART, GERMANY	0176-3679		PHARMACOPSYCHIATRY	Pharmacopsychiatry	FEB	2006	39			1			S76	S79		10.1055/s-2006-931500		4	Pharmacology & Pharmacy; Psychiatry	Pharmacology & Pharmacy; Psychiatry	020KC	WOS:000235906700016	
J	Smialowski, P; Schmidt, T; Cox, J; Kirschner, A; Frishman, D				Smialowski, P; Schmidt, T; Cox, J; Kirschner, A; Frishman, D			Will my protein crystallize? A sequence-based predictor	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						structural genomics; protein structure determination; protein crystallization; machine learning; sequence comparison	ACID INDEX DATABASE; STRUCTURAL GENOMICS; NMR-SPECTROSCOPY; IDENTIFICATION; PROTEOMICS; ALGORITHM; SELECTION; SOFTWARE; AAINDEX; SYSTEM	We propose a machine-learning approach to sequence-based prediction of protein crystallizability in which we exploit subtle differences between proteins whose structures were solved by X-ray analysis [or by both X-ray and nuclear magnetic resonance (NMR) spectroscopy] and those proteins whose structures were solved by NMR spectroscopy alone. Because the NMR technique is usually applied on relatively small proteins, sequence length distributions of the X-ray and NMR datasets were adjusted to avoid predictions biased by protein size. As feature space for classification, we used frequencies of mono-, di-, and tripeptides represented by the original 20-letter amino acid alphabet as well as by several reduced alphabets in which amino acids were grouped by their physicochemical and structural properties. The classification algorithm was constructed as a two-layered structure in which the output of primary support vector machine classifiers operating on peptide frequencies was combined by a second-level Naive Bayes classifier. Due to the application of metamethods for cost sensitivity, our method is able to handle real datasets with unbalanced class representation. An overall prediction accuracy of 67% [65% on the positive (crystallizable) and 69% on the negative (noncrystallizable) class] was achieved in a 10-fold cross-validation experiment, indicating that the proposed algorithm may be a valuable tool for more efficient target selection in structural genomics.	Tech Univ Munich, Dept Genome Oriented Bioinformat, Wissensch Zentrum Weihenstephan, D-85350 Freising Weihenstephan, Germany; Genedata GmbH, Martinsried, Germany	Frishman, D (reprint author), Tech Univ Munich, Dept Genome Oriented Bioinformat, Wissensch Zentrum Weihenstephan, D-85350 Freising Weihenstephan, Germany.	d.frishman@wzw.tum.de	Cox, Jurgen/B-9481-2008	Cox, Jurgen/0000-0001-8597-205X			Adams PD, 2004, J SYNCHROTRON RADIAT, V11, P53, DOI 10.1107/S0909049503024130; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Burley SK, 2000, NAT STRUCT BIOL, V7, P932, DOI 10.1038/80697; Canaves JM, 2004, J MOL BIOL, V344, P977, DOI 10.1016/j.jmb.2004.09.076; Chen L, 2004, BIOINFORMATICS, V20, P2860, DOI 10.1093/bioinformatics/bth300; Christendat D, 2000, NAT STRUCT BIOL, V7, P903; Cristianini N., 2000, INTRO SUPPORT VECTOR; CUNNINGHAM P, 2000, TCDCS200007 DEP COMP; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DOMINGOS P, 1999, METACOST GEN METHOD, P155; Domingos P., 1996, P 13 INT C MACH LEAR, P105; DOWNING AK, 2004, PROTEIN NMR TECHNIQU; DUBES RC, 1993, CLUSTER ANLA RELATED; Edwards AM, 2000, NAT STRUCT BIOL, V7, P970, DOI 10.1038/80751; ENGELMAN DM, 1986, ANNU REV BIOPHYS BIO, V15, P321, DOI 10.1146/annurev.biophys.15.1.321; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Gadek TR, 2003, BIOTECHNIQUES, P21; Gilis D, 2001, GENOME BIOL, V2; GILIS D, 2004, COMMUNICATION; Goh CS, 2004, J MOL BIOL, V336, P115, DOI 10.1016/j.jmb.2003.11.053; HOBOHM U, 1992, PROTEIN SCI, V1, P409; Holton T, 2000, ACTA CRYSTALLOGR D, V56, P722, DOI 10.1107/S0907444900003450; Ioerger TR, 2003, METHOD ENZYMOL, V374, P244, DOI 10.1016/S0076-6879(03)74012-9; JAIN AK, 1988, ALGORITHMS CLUSERING; John G. H., 1995, P 11 C UNC ART INT, P338; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kawashima S, 1999, NUCLEIC ACIDS RES, V27, P368, DOI 10.1093/nar/27.1.368; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kimber MS, 2003, PROTEINS, V51, P562, DOI 10.1002/prot.10340; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Korzhnev DM, 2004, NATURE, V430, P586, DOI 10.1038/nature02655; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; MAJUMDAR S, 2005, COMMUNCATION; McPherson A., 1999, CRYSTALLIZATION BIOL; McPhillips TM, 2002, J SYNCHROTRON RADIAT, V9, P401, DOI 10.1107/S0909049502015170; Meila M, 2001, MACH LEARN, V42, P9, DOI 10.1023/A:1007648401407; Monleon Daniel, 2002, Journal of Structural and Functional Genomics, V2, P93, DOI 10.1023/A:1020499629298; Montelione GT, 2000, NAT STRUCT BIOL, V7, P982, DOI 10.1038/80768; Nei M, 2000, MOL EVOLUTION PHYLOG; Pervushin K, 2002, J AM CHEM SOC, V124, P12898, DOI 10.1021/ja027149q; PLATT J, 1999, ADV KERNAL METHODS, P182; Riek R, 2002, J AM CHEM SOC, V124, P12144, DOI 10.1021/ja026763z; ROSE GD, 1985, SCIENCE, V229, P834, DOI 10.1126/science.4023714; RZHETSKY A, 1992, J MOL EVOL, V35, P367, DOI 10.1007/BF00161174; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; Ting KM, 2002, LECT NOTES COMPUT SC, V2534, P98; TING KM, 2002, HEURISTIC OPTIMIZATI; Valafar H, 2002, ANN NY ACAD SCI, V980, P13; Vitkup D, 2001, NAT STRUCT BIOL, V8, P559, DOI 10.1038/88640; Witten I. H., 1999, DATA MINING PRACTICA; Yee A, 2003, ACCOUNTS CHEM RES, V36, P183, DOI 10.1021/ar010126g	56	38	42	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0887-3585		PROTEINS	Proteins	FEB 1	2006	62	2					343	355		10.1002/prot.20789		13	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	000CP	WOS:000234438800006	
J	Pedrycz, A; Reformat, M				Pedrycz, A; Reformat, M			Hierarchical FCM in a stepwise discovery of structure in data	SOFT COMPUTING			English	Article						hierarchical FCM; mapping criterion; clustering tree; computing aspects; data analysis; FCM tree structure; stepwise structure discovery; computational complexity; problem decomposition; refinement	VECTOR QUANTIZATION	This paper is concerned with a stepwise mode of objective function-based fuzzy clustering. A revealed structure in data becomes refined in a successive manner by starting with the most dominant relationships and proceeding with its more detailed characterization. Technically, the proposed process develops a so-called hierarchy of clusters. Given the underlying clustering mechanism of the fuzzy C means (FCM), the produced architecture is referred to as a hierarchical FCM or hierarchical FCM tree (HFCM tree). We discuss the design of the tree demonstrating how its growth is guided by a certain mapping criterion. It is also shown how a structure at the higher level is effectively used to build clusters at the consecutive level by making use of the conditional FCM. Detailed investigations of computational complexity contrast a stepwise development of clusters with a single-step clustering completed for the equivalent number of clusters occurring in total at all final nodes of the HFCM tree. The analysis quantifies a significant reduction of the stepwise refinement of the clusters. Experimental studies include synthetic data as well as those coming from the machine learning repository.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada	Reformat, M (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.						Anderberg M. R, 1973, CLUSTER ANAL APPL; Bezdek J. C., 1981, PATTERN RECOGNITION; Campos MM, 2001, NEURAL NETWORKS, V14, P505, DOI 10.1016/S0893-6080(01)00020-X; CHENG TW, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P2289; CUCCHIARA R, 2002, P INT C PATT REC ICP, V1, P759; Delgado M, 1996, INT J APPROX REASON, V14, P237, DOI 10.1016/0888-613X(95)00116-X; Devillez A, 2002, FUZZY SET SYST, V128, P323, DOI 10.1016/S0165-0114(01)00187-7; Duda R. O., 2001, PATTERN CLASSIFICATI; EQUITZ WH, 1989, IEEE T ACOUST SPEECH, V37, P1568, DOI 10.1109/29.35395; FREEMAN RT, 2004, IN PRESS NEURAL NETW; Gersho A., 1992, VECTOR QUANTIZATION; Gomez-Skarmeta AF, 1999, FUZZY SET SYST, V106, P179, DOI 10.1016/S0165-0114(97)00276-5; Hoppner F, 2002, FUZZY SET SYST, V128, P365, DOI 10.1016/S0165-0114(01)00204-4; Hoppner F., 1999, FUZZY CLUSTER ANAL; Kim E, 1997, IEEE T FUZZY SYST, V5, P328; Pedrycz W, 1998, IEEE T NEURAL NETWOR, V9, P601, DOI 10.1109/72.701174	16	3	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	FEB	2006	10	3					244	256		10.1007/s00500-005-0478-8		13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	987KW	WOS:000233517800009	
J	Schetinin, V; Schult, J				Schetinin, V; Schult, J			Learning polynomial networks for classification of clinical electroencephalograms	SOFT COMPUTING			English	Article						classification; electroencephalogram; polynomial network; group method of data handling	NEURAL-NETWORK; EEG; ARTIFACTS; DIAGNOSIS; REMOVAL; RULES	We describe a polynomial network technique developed for learning to classify clinical electroencephalograms (EEGs) presented by noisy features. Using an evolutionary strategy implemented within group method of data handling, we learn classification models which are comprehensively described by sets of short-term polynomials. The polynomial models were learnt to classify the EEGs recorded from Alzheimer and healthy patients and recognize the EEG artifacts. Comparing the performances of our technique and some machine learning methods we conclude that our technique can learn well-suited polynomial models which experts can find easy-to-understand.	Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England; Univ Jena, TheorieLab, D-07740 Jena, Germany	Schetinin, V (reprint author), Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England.	V.Schetinin@ex.ac.uk; Joachim_Schult@web.de					Anderson C. W., 1995, Neural Networks for Signal Processing V. Proceedings of the 1995 IEEE Workshop (Cat. No.95TH8094), DOI 10.1109/NNSP.1995.514922; BERG P, 1991, CLIN PHYS PHYSIOL M, V12, P49, DOI 10.1088/0143-0815/12/A/010; BONDARKO VA, 1992, INT J ADAPT CONTROL, V6, P141, DOI 10.1002/acs.4480060303; Breidbach O, 1998, THEOR BIOSCI, V117, P377; Brunner DP, 1996, J SLEEP RES, V5, P155, DOI 10.1046/j.1365-2869.1996.00009.x; Galicki M, 1997, NEURAL NETWORKS, V10, P1153, DOI 10.1016/S0893-6080(97)00033-6; GARZES A, 1998, TR98014 IMP COLL LON; Hayashi Y, 2000, ARTIF INTELL MED, V20, P205, DOI 10.1016/S0933-3657(00)00064-6; HIBINO S, 2000, ARTIFICIAL NEURAL NE; HOLSHEIMER M, 1994, CSR9406 CWI AMST; Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259; MADALA HR, 1994, INDUCTIVE LEARNING A; Makeig S, 1996, ADV NEUR IN, V8, P145; Muller J.-A., 1998, Mathematical and Computer Modelling of Dynamical Systems, V4, DOI 10.1080/13873959808837083; MULLER JA, 2003, SELF ORG DATA MINING; Nikolaev N, 1999, LECT NOTES ARTIF INT, V1704, P456; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RIDDINGTON E, 1994, NEURAL NETWORKS EXPE, P291; Schetinin V, 2004, IEEE T INF TECHNOL B, V8, P28, DOI 10.1109/TITB.2004.824735; Setiono R, 2000, ARTIF INTELL MED, V18, P205, DOI 10.1016/S0933-3657(99)00041-X; SILVESTRIHOBSON R, 2000, ABNORMAL NEONATAL EE; TOWELL GG, 1993, MACH LEARN, V13, P71, DOI 10.1007/BF00993103; WHITTON JL, 1978, ELECTROEN CLIN NEURO, V44, P735, DOI 10.1016/0013-4694(78)90208-0; WOESTENBURG JC, 1983, BIOL PSYCHOL, V16, P127, DOI 10.1016/0301-0511(83)90059-5	24	5	6	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	FEB	2006	10	4					397	403		10.1007/s00500-005-0499-3		7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	990EH	WOS:000233725500015	
J	Yhao, Y; Kwoh, CK				Yhao, Y; Kwoh, CK			Fast leave-one-out evaluation for dynamic gene selection	SOFT COMPUTING			English	Article							SUPPORT VECTOR MACHINES; PREDICTION; EXPRESSION; CLASSIFICATION; CANCER; TUMOR	Gene selection procedure is a necessary step to increase the accuracy of machine learning algorithms that help in disease diagnosis based on gene expression data. This is commonly known as a feature subset selection problem in machine learning domain. A fast leave-one-out (LOO) evaluation formula for least-squares support vector machines (LS-SVMs) is introduced here that can guide our backward feature selection process. Based on that, we propose a fast LOO guided feature selection (LGFS) algorithm. The gene selection step size is dynamically adjusted according to the LOO accuracy estimation. For our experiments, the application of LGFS to the gene selection process improves the classifier accuracy and reduces the number of features required as well. The least number of genes that can maximize the disease classification accuracy is automatically determined by our algorithm.	BIRC, Bioinformat Res Ctr, Singapore 637553, Singapore	Yhao, Y (reprint author), BIRC, Bioinformat Res Ctr, 50 Nanyang Dr,Res Technol Plaza, Singapore 637553, Singapore.	zhaoying2000@163.com					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; DUAN K, 2001, CD0111 NAT U SING; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; JOACHIMS T, 2000, THESIS U DORTMUND; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Lee KE, 2003, BIOINFORMATICS, V19, P90, DOI 10.1093/bioinformatics/19.1.90; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; Vapnik VN, 1998, STAT LEARNING THEORY; Wahba G, 2000, ADV NEUR IN, P297; Weston J, 1998, MULTICLASS SUPPORT V	15	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-7643		SOFT COMPUT	Soft Comput.	FEB	2006	10	4					346	350		10.1007/s00500-005-0493-9		5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	990EH	WOS:000233725500009	
J	Dzeroski, S; Zenko, B; Debeljak, M				Dzeroski, S; Zenko, B; Debeljak, M			The Fourth International Workshop on Environmental Applications of Machine Learning, 27 September 1 October 2004, Bled, Slovenia	ECOLOGICAL MODELLING			English	Editorial Material									Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia	Dzeroski, S (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova 39, Ljubljana 1000, Slovenia.	Saso.Dzeroski@ijs.si	Zenko, Bernard/A-2891-2008					0	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JAN 27	2006	191	1			SI		1	3		10.1016/j.ecolmodel.2005.08.008		3	Ecology	Environmental Sciences & Ecology	002RM	WOS:000234629100001	
J	Krasnopolsky, VM; Fox-Rabinovitz, MS				Krasnopolsky, VM; Fox-Rabinovitz, MS			A new synergetic paradigm in environmental numerical modeling: Hybrid models combining deterministic and machine learning components	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	4th International Workshop on Environmental Applications of Machine Learning (EAML)	SEP 27-OCT 01, 2004	Bled, SLOVENIA			environmental modeling; neural networks; machine learning; complex systems; climate modeling	NEURAL-NETWORK APPLICATIONS; NONLINEAR ENERGY-TRANSFER; GRAVITY-WAVE SPECTRUM; PARAMETERIZATIONS; COMPUTATIONS; SCIENCES; CLIMATE	A new type of environmental numerical models, hybrid environmental numerical models (HEMs) based on combining deterministic modeling and machine learning components, is introduced and formulated. Conceptual and practical possibilities of developing HEM, as an optimal synergetic combination of the traditional deterministic/first principles modeling (like that used for solving PDEs on the sphere representing model dynamics of global climate models) and machine learning components (like accurate and fast neural network emulations of model physics or chemistry processes), are discussed. Examples of developed HEMs (hybrid climate models and a hybrid wind-wave ocean model) illustrate the feasibility and efficiency of the new approach for modeling extremely complex multidimensional systems. (c) 2005 Elsevier B.V. All rights reserved.	Univ Maryland, Earth Syst Sci Interdisciplinary Ctr, College Pk, MD 20742 USA; NOAA, Sci Appl Int Corp, Natl Ctr Environm Predict, Camp Springs, MD 20746 USA	Krasnopolsky, VM (reprint author), Univ Maryland, Earth Syst Sci Interdisciplinary Ctr, College Pk, MD 20742 USA.	Vladimir.Krasnopolsky@noaa.gov; foxrab@essic.umd.edu					Chevallier F, 2000, Q J ROY METEOR SOC, V126, P761, DOI 10.1256/smsqj.56317; Chevallier F, 1998, J APPL METEOROL, V37, P1385, DOI 10.1175/1520-0450(1998)037<1385:ANNAFA>2.0.CO;2; Chou M-D., 2001, TECHNICAL REPORT SER, V19; Collins WD, 2001, J ATMOS SCI, V58, P3224, DOI 10.1175/1520-0469(2001)058<3224:POGCOF>2.0.CO;2; Duffy PB, 2003, CLIM DYNAM, V21, P371, DOI 10.1007/s00382-003-0339-z; Fox-Rabinovitz MS, 2002, J GEOPHYS RES-ATMOS, V107, DOI 10.1029/2002JD002177; HASSELMANN S, 1985, J PHYS OCEANOGR, V15, P1378, DOI 10.1175/1520-0485(1985)015<1378:CAPOTN>2.0.CO;2; HASSELMANN S, 1985, J PHYS OCEANOGR, V15, P1369, DOI 10.1175/1520-0485(1985)015<1369:CAPOTN>2.0.CO;2; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; KRASNOPOLKSY VM, 2005, P INT JOINT C NEUR N; KRASNOPOLSKY V, 1997, RES ACTIVITIES ATMOS; KRASNOPOLSKY VM, 2004, P 84 AMS ANN M 15 S; Krasnopolsky VM, 2003, NEURAL NETWORKS, V16, P335, DOI 10.1016/S0893-6080(03)00026-1; KRASNOPOLSKY VM, 1995, J GEOPHYS RES-OCEANS, V100, P11033, DOI 10.1029/95JC00857; Krasnopolsky VM, 2003, NEURAL NETWORKS, V16, P321, DOI 10.1016/S0893-6080(03)00027-3; KRASNOPOLSKY VM, 2001, 359 ECMWF; Krasnopolsky VM, 2002, OCEAN MODEL, V4, P363, DOI 10.1016/S1463-5003(02)00010-0; KRASNOPOLSKY VM, 1999, RES ACTIVITIES ATMOS; KRASNOPOLSKY VM, 2005, MON WEA REV; Lorenz E. N, 1956, EMPIRICAL ORTHOGONAL; RIPLEY BD, 1997, PATTERN RECOGNITION; Schoendorf J, 2003, GEOPHYS RES LETT, V30, DOI 10.1029/2002GL016649; STOGRYN AP, 1994, J GEOPHYS RES, V90, P981; Tolman HL, 2005, OCEAN MODEL, V8, P253, DOI 10.1016/j.ocemod.2003.12.008; 1998, J CLIM, V11	25	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JAN 27	2006	191	1			SI		5	18		10.1016/j.ecolmodel.2005.08.009		14	Ecology	Environmental Sciences & Ecology	002RM	WOS:000234629100002	
J	Vladusic, D; Kompare, B; Bratko, I				Vladusic, D; Kompare, B; Bratko, I			Modelling Lake Glumso with Q(2) learning	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	4th International Workshop on Environmental Applications of Machine Learning (EAML)	SEP 27-OCT 01, 2004	Bled, SLOVENIA			qualitative modelling; qualitative reasoning; machine learning	SYSTEM-IDENTIFICATION; PREDICTION; BOUNDS	In this paper, we describe an application of Q(2) learning, a recently developed approach to machine learning in numerical domains, to the automated modelling of an aquatic ecosystem from measured data. We modelled the time behaviour of phytoplankton and zooplankton in Danish Lake Glumso using data collected by SE. Jorgensen. The novelty of Q(2) learning is in its paying attention to the qualitative correctness of induced numerical models. We assessed the results by, first, performing a comparison of numerical accuracy between our approach and some state-of-the-art numerical machine learning algorithms applied to the Glumso data, and second, we obtained expert evaluation of the induced models. The results show that Q(2) approach is at least comparable to competing methods in terms of numerical accuracy and gives good insight into domain phenomena. (c) 2005 Elsevier B.V. All rights reserved.	Fac Comp & Informat Sci, Ljubljana 1000, Slovenia; Fac Civil & Geodet Engn, Ljubljana 1000, Slovenia	Vladusic, D (reprint author), Fac Comp & Informat Sci, Trzaska 25, Ljubljana 1000, Slovenia.	daniel.vladusic@fri.uni-lj.si; bkompare@fgg.uni-lj.si; ivan.bratko@fri.uni-lj.si					Abu-Mostafa Y. S., 1990, Journal of Complexity, V6, DOI 10.1016/0885-064X(90)90006-Y; ATANASOVA N, 2005, 5 EUR C EC MOD ECEM5; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BELLAZZI R, 2001, J BIOMEDICAL INFORM, V24, P221; Bellazzi R, 1998, ARTIF INTELL MED, V14, P5, DOI 10.1016/S0933-3657(98)00014-1; BRATKO I, 1991, P INT WORKSH IND LOG, P207; Breiman L, 1984, CLASSIFICATION REGRE; COGHILL G, 2002, P QR 2 WORKSH QUAL R; COIERA E, 1989, 8901 U NEW S WAL; Coleman TF, 1996, SIAM J OPTIMIZ, V6, P1040, DOI 10.1137/S1052623494240456; Dormand J. R., 2006, J COMPUT APPL MATH, V6, P19, DOI DOI 10.1016/0771-050X(80)90013-3; Dzeroski S., 1995, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V4, DOI 10.1007/BF00962824; FORBUS KD, 1984, ARTIF INTELL, V24, P85, DOI 10.1016/0004-3702(84)90038-9; Gill P.E., 1981, PRACTICAL OPTIMIZATI; JORGENSEN SE, 1986, ECOL MODEL, V32, P165, DOI 10.1016/0304-3800(86)90024-4; Kay H, 2000, ARTIF INTELL, V119, P103, DOI 10.1016/S0004-3702(00)00012-6; Kay H, 2000, AICHE J, V46, P2426, DOI 10.1002/aic.690461211; KOMPARE B, 1995, THESIS ROYAL DANISH; Kuipers B., 1994, QUALITATIVE REASONIN; PAZZANI M, 1992, MACH LEARN, V9, P57, DOI 10.1007/BF00993254; Pazzani MJ, 1997, PROCEEDINGS OF THE NINETEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P596; Pazzani MJ, 1999, PROCEEDINGS OF THE TWENTY FIRST ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P525; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; RAMACHANDRAN S, 1994, 8 INT WORKSH QUAL RE, P212; RICHARDS B, 1992, P NAT C ART INT, P295; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Say ACC, 1996, ARTIF INTELL, V83, P75, DOI 10.1016/0004-3702(95)00016-X; SILL J, 1996, NIPS, P634; Suc D, 2004, ARTIF INTELL, V158, P189, DOI 10.1016/j.artint.2004.05.002; SUC D, 2003, P 14 EUR C MACH LEAR, P385; SUC D, 2003, P 18 INT JOINT C ART, P1052; Suc D., 2003, FRONTIERS ARTIFICIAL, V99; Todorovski L, 1998, ECOL MODEL, V113, P71, DOI 10.1016/S0304-3800(98)00135-5; TODOROVSKI L, 2003, THESIS U LJUBLJANA L; Witten I. H., 2000, DATA MINING PRACTICA	35	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JAN 27	2006	191	1			SI		33	46		10.1016/j.ecolmodel.2005.08.005		14	Ecology	Environmental Sciences & Ecology	002RM	WOS:000234629100004	
J	Kobler, A; Dzeroski, S; Keramitsoglou, L				Kobler, A; Dzeroski, S; Keramitsoglou, L			Habitat mapping using machine learning-extended kernel-based reclassification of an Ikonos satellite image	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	4th International Workshop on Environmental Applications of Machine Learning (EAML)	SEP 27-OCT 01, 2004	Bled, SLOVENIA			habitat mapping; classification; satellite imagery	LAND-USE; CLASSIFICATION	The spatial resolution of satellite imagery suitable for earth resources studies has improved from 80 m (Landsat-MSS, launched in 1972) to 0.6 m (QuickBird, launched in 2001). The conventional pixel-based methods developed for medium resolution satellite images are not suitable for classification of very high spatial resolution images, because the spectral responses of particular habitat classes are much more variable. On the other hand, in the original Barnsley-Barr kernel-based reclassification algorithm not only the spectral information of a pixel but also the textural information in the vicinity of the pixel is used when the pixel labeling decision is made. The first step of the kernel reclassification algorithm is to perform an initial classification of the original image. In the second step, the adjacency-event matrices are computed for each pixel according to co-occurrence frequencies of the initial classes in the kernel window. The degree of matching between an adjacency-event matrix corresponding to specific pixel and the set of class-specific template matrices produced during training is the criterion for pixel re-labeling. We extend the original kernel-based reclassification algorithm with a decision tree-based reclassification, simultaneously taking into account the class-specific similarity images, which are a side-product of the original algorithm. The advantage of decision tree-extended approach over the original approach seems to be the ability of the former to consider more input information, thus increasing the Kappa classification accuracy for an Ikonos image of our study area from 0.56 to 0.60, using a nomenclature containing 10 habitat classes. (c) 2005 Elsevier B.V. All rights reserved.	Slovenian Forestry Inst, Dept Forest Inventory & Spatial Informat Syst, SI-1000 Ljubljana, Slovenia; Jozef Stefan Inst, Dept Knowledge Technol, SI-1000 Ljubljana, Slovenia; Univ Athens, Dept Appl Phys, Remote Sensing & Image Proc Team, Athens 15784, Greece	Kobler, A (reprint author), Slovenian Forestry Inst, Dept Forest Inventory & Spatial Informat Syst, Vecna Pot 2, SI-1000 Ljubljana, Slovenia.	andrej.kobler@gozdis.si	Keramitsoglou, Iphigenia/F-3076-2011				Barnsley MJ, 1996, PHOTOGRAMM ENG REM S, V62, P949; Bock Michael, 2005, Journal for Nature Conservation (Jena), V13, P75, DOI 10.1016/j.jnc.2004.12.002; GONG P, 1992, REMOTE SENS ENVIRON, V40, P137, DOI 10.1016/0034-4257(92)90011-8; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; KERAMITSOGLOU I, 2003, P 10 INT S REM SENS, V5232, P276; Keramitsoglou Iphigenia, 2005, Journal for Nature Conservation (Jena), V13, P91, DOI 10.1016/j.jnc.2005.02.004; Kontoes CC, 2000, INT J REMOTE SENS, V21, P3145, DOI 10.1080/01431160050145027; LILLESAND TM, 1994, REMOTE SENSING IMAGE, P616; Richards J. A., 1999, REMOTE SENSING DIGIT; Tou J., 1974, PATTERN RECOGNITION; *EEA, 2002, EUNIS HAB CLASS WEB	11	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JAN 27	2006	191	1			SI		83	95		10.1016/j.ecolmodel.2005.08.002		13	Ecology	Environmental Sciences & Ecology	002RM	WOS:000234629100008	
J	Demsar, D; Dzeroski, S; Larsen, T; Struyf, J; Axelsen, J; Pedersen, MB; Krogh, PH				Demsar, D; Dzeroski, S; Larsen, T; Struyf, J; Axelsen, J; Pedersen, MB; Krogh, PH			Using multi-objective classification to model communities of soil microarthropods	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	4th International Workshop on Environmental Applications of Machine Learning (EAML)	SEP 27-OCT 01, 2004	Bled, SLOVENIA			multi-objective classification; modelling; soil microarthropods		In agricultural soil, a suite of anthropogenic events shape the ecosystem processes and populations. However, the impact from anthropogenic sources on the soil environment is almost exclusively assessed for chemicals, although other factors like crop and tillage practices have an important impact as well. Thus, the farming system as a whole should be evaluated and ranked according to its environmental benefits and impacts. Our starting point is a data set describing agricultural events and soil biological parameters. Using machine learning methods for inducing regression and model trees, we produce empirical models able to predict the soil quality from agricultural measures in terms of quantities describing the soil microarthropod community. We are also interested in discovering additional higher level knowledge. In particular, we have identified the most important factors influencing the population densities of springtails and mites and their biodiversity. We also identify to which agricultural actions different microarthropods react distinctly. To obtain this higher level knowledge, we employ multi-objective regression trees. (c) 2005 Elsevier B.V. All rights reserved.	Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana, Slovenia; Natl Environm Engn Res Inst, Dept Terrestrial Ecol, Roskilde, Denmark; Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium	Demsar, D (reprint author), Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana, Slovenia.	damjan.demsar@ijs.si; saso.dzeroski@ijs.si; thl@dmu.dk; jan.struyf@cs.kuleuven.be; phk@dmu.dk	Larsen, Thomas/D-3105-2012	Larsen, Thomas/0000-0002-0311-9707			BLOCKEEL H, 2002, J MACHINE LEARNING R, V3, P621, DOI DOI 10.1162/JMLR.2003.3.4-5.621; Blockeel H, 1998, P 15 INT C MACH LEAR, P55; Breiman L, 1984, CLASSIFICATION REGRE; DEMSAR D, 2003, P INT EL COMP SCI C; Garofalakis M, 2003, DATA MIN KNOWL DISC, V7, P187, DOI 10.1023/A:1022445500761; KROGH PH, 1994, THESIS NAT ENV RES I; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; STEEN E, 1983, SWED J AGR RES, V13, P157; WANG Y, 1997, P POST PAP ECML 97 U; Witten I. H., 1999, DATA MINING PRACTICA	10	15	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JAN 27	2006	191	1			SI		131	143		10.1016/j.ecolmodel.2005.08.017		13	Ecology	Environmental Sciences & Ecology	002RM	WOS:000234629100012	
J	Znidarsic, M; Jakulin, A; Dzeroski, S; Kampichler, C				Znidarsic, M; Jakulin, A; Dzeroski, S; Kampichler, C			Automatic construction of concept hierarchies: The case of foliage-dwelling spiders	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	4th International Workshop on Environmental Applications of Machine Learning (EAML)	SEP 27-OCT 01, 2004	Bled, SLOVENIA			data-based hierarchy construction; interaction analysis; feature construction; hierarchical models; spiders; field margins	MANAGEMENT	In this paper, we present the hierarchical variable dependencies that were obtained from raw data with the use of two machine learning techniques on an ecological data set. The data set contains features of field margins and the corresponding number of spider species inhabiting them. This data set was used before by domain experts to construct a fuzzy qualitative model with hierarchical variable dependencies, which we use for comparison with our results. One of the machine learning methods constructs a hierarchical structure similar to the one in the experts' model, while revealing some additional interesting relations of environmental features with respect to the number of spider species. The other method constructs a different hierarchy from the one proposed by the experts, which, according to our classification performance experiments, might be even more appropriate. (c) 2005 Elsevier B.V. All rights reserved.	Jozef Stefan Inst, Dept Knowledge Technol, Dhaka 1000, Bangladesh; Univ Judrez Auton Tabasco, Div Acad Ciencias Biol, Villahermosa, Mexico	Znidarsic, M (reprint author), Jozef Stefan Inst, Dept Knowledge Technol, Janova 39, Dhaka 1000, Bangladesh.	martin.znidarsic@ijs.si	Kampichler, Christian/A-9603-2011				Anderlik-Wesinger G., 1996, Verhandlungen der Gesellschaft für Ökologie, V26, P711; Baines M, 1998, ECOGRAPHY, V21, P74, DOI 10.1111/j.1600-0587.1998.tb00395.x; Barthel J, 1996, REV SUISSE ZOOL, P45; CHANG CC, 2001, LIBSVM LIBR SUPPORT; DEMSAR J, 2004, ORANGE EXPT MACHING; Ellenberg H., 1992, SCRIPTA GEOBOTANICA, V18, P1; GIBSON CWD, 1992, J APPL ECOL, V29, P132, DOI 10.2307/2404356; Jakulin A, 2004, P 21 INT C MACH LEAR, P409; JAKULIN A, 2003, P 7 EUR C PRINC PRAC, P229; Kampichler C, 2000, ECOL MODEL, V129, P87, DOI 10.1016/S0304-3800(00)00224-6; Mackey BG, 2001, J BIOGEOGR, V28, P1147, DOI 10.1046/j.1365-2699.2001.00626.x; McGill W.J., 1954, PSYCHOMETRIKA, V9, P97; Poff NL, 1997, J N AM BENTHOL SOC, V16, P391, DOI 10.2307/1468026; RAJSKI C, 1961, INFORM CONTR, V4, P373; SCHRODER B, 2004, HABITATMODELLE METHO, P5; Struyf A, 1997, COMPUT STAT DATA AN, V26, P17, DOI 10.1016/S0167-9473(97)00020-0; THOMAS MB, 1992, J APPL ECOL, V29, P524, DOI 10.2307/2404521; ZNIDARSIC M, 2004, P 2004 IFIP INT C DE, P881; Zupan B, 1999, ARTIF INTELL, V109, P211, DOI 10.1016/S0004-3702(99)00008-9; Zupan B, 1998, IEEE INTELL SYST APP, V13, P38, DOI 10.1109/5254.671090; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	21	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JAN 27	2006	191	1			SI		144	158		10.1016/j.ecolmodel.2005.08.023		15	Ecology	Environmental Sciences & Ecology	002RM	WOS:000234629100013	
J	Jeraj, M; Dzeroski, S; Todorovski, L; Debeljak, M				Jeraj, M; Dzeroski, S; Todorovski, L; Debeljak, M			Application of machine learning methods to palaeoecological data	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	4th International Workshop on Environmental Applications of Machine Learning (EAML)	SEP 27-OCT 01, 2004	Bled, SLOVENIA			palaeoecology; vegetation dynamics; machine learning; equation discovery; hierarchical clustering		A palaeoecological study was conducted to investigate past environmental conditions and vegetation dynamics around the southwestern Ljubljana Moor. In order to find potential regularities and/or dependencies among co-existent plant species through time, different machine learning methods were applied to pollen records from the cores taken at Bistra and Hocevarica. The data comprised relative pollen frequencies of the most common plant genera/families at particular core depths that correspond to particular ages in the Early and Mid Holocene periods. The applied methods include equation discovery and hierarchical clustering. Both methods have found plausible and explainable relationships among identified plant genera/families. (c) 2005 Elsevier B.V. All rights reserved.	Univ Wisconsin, Dept Bot, Madison, WI 53706 USA; Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana, Slovenia	Jeraj, M (reprint author), Univ Wisconsin, Dept Bot, Madison, WI 53706 USA.	mjeraj@wisc.edu					BELL M, 1992, LATE QUATERNARY ENV, P273; Birks HJB, 1980, QUATERNARY PALAEOECO, P289; BRATKO I, 2003, ANAL ENV DATA MACHIN, P220; Dzeroski S., 1995, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V4, DOI 10.1007/BF00962824; DZEROSKI S, 1999, MACHINE LEARNING MET, P185; Jeraj M, 2002, VEG HIST ARCHAEOBOT, V11, P277, DOI 10.1007/s003340200040; JERAJ M, 2004, THESIS NOVA GORICA, P136; Lowe JJ, 1997, RECONSTRUCTING QUATE, P446; MANILLA H, 1998, DISCOVERY SCI, P12; TODOROVSKI L, 2002, P 5 INT MULT C INF S, P143	10	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JAN 27	2006	191	1			SI		159	169		10.1016/j.ecolmodel.2005.08.018		11	Ecology	Environmental Sciences & Ecology	002RM	WOS:000234629100014	
J	Chagoyen, M; Carmona-Saez, P; Shatkay, H; Carazo, JM; Pascual-Montano, A				Chagoyen, M; Carmona-Saez, P; Shatkay, H; Carazo, JM; Pascual-Montano, A			Discovering semantic features in the literature: a foundation for building functional associations	BMC BIOINFORMATICS			English	Article							NONNEGATIVE MATRIX FACTORIZATION; GENE-EXPRESSION; INFORMATION; IDENTIFICATION; NETWORK	Background: Experimental techniques such as DNA microarray, serial analysis of gene expression (SAGE) and mass spectrometry proteomics, among others, are generating large amounts of data related to genes and proteins at different levels. As in any other experimental approach, it is necessary to analyze these data in the context of previously known information about the biological entities under study. The literature is a particularly valuable source of information for experiment validation and interpretation. Therefore, the development of automated text mining tools to assist in such interpretation is one of the main challenges in current bioinformatics research. Results: We present a method to create literature profiles for large sets of genes or proteins based on common semantic features extracted from a corpus of relevant documents. These profiles can be used to establish pair-wise similarities among genes, utilized in gene/protein classification or can be even combined with experimental measurements. Semantic features can be used by researchers to facilitate the understanding of the commonalities indicated by experimental results. Our approach is based on non-negative matrix factorization (NMF), a machine-learning algorithm for data analysis, capable of identifying local patterns that characterize a subset of the data. The literature is thus used to establish putative relationships among subsets of genes or proteins and to provide coherent justification for this clustering into subsets. We demonstrate the utility of the method by applying it to two independent and vastly different sets of genes. Conclusion: The presented method can create literature profiles from documents relevant to sets of genes. The representation of genes as additive linear combinations of semantic features allows for the exploration of functional associations as well as for clustering, suggesting a valuable methodology for the validation and interpretation of high-throughput experimental data.	CSIC, Biocomp Unit, Ctr Nacl Biotecnol, Madrid, Spain; Queens Univ, Sch Comp, Kingston, ON, Canada; Univ Complutense Madrid, Dpto Arquitectura Comp, Madrid, Spain	Chagoyen, M (reprint author), CSIC, Biocomp Unit, Ctr Nacl Biotecnol, Madrid, Spain.	monica.chagoyen@cnb.uam.es; pcarmona@cnb.uam.es; shatkay@cs.queensu.ca; carazo@cnb.uam.es; pascual@fis.ucm.es					Blaschke Christian, 2001, Functional and Integrative Genomics, V1, P256, DOI 10.1007/s101420000036; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Chaussabel D, 2002, GENOME BIOL, V3; DEERWESTER S, 1988, P ASIS ANNU MEET, V25, P36; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DOBROKHOTOV PB, 2003, BIOINFORMATICS S1, V19, P91; Glenisson P, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-6-r43; Glenisson P, 2003, Pac Symp Biocomput, P391; Hearst M., 1999, P 37 ANN M ASS COMP, P3, DOI DOI 10.3115/1034678.1034679; HEGER A, 2003, BIOINFORMATICS S1, V19, P130; Hoffman Thomas, 1999, P 22 ANN INT ACM SIG, P50; Homayouni R, 2005, BIOINFORMATICS, V21, P104, DOI 10.1093/bioinformatics/bth464; Iliopoulos I, 2001, Pac Symp Biocomput, P384; Jelier R, 2005, BIOINFORMATICS, V21, P2049, DOI 10.1093/bioinformatics/bti268; Jenssen TK, 2001, NAT GENET, V28, P21, DOI 10.1038/ng0501-21; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Kanehisa M, 1997, TRENDS GENET, V13, P375, DOI 10.1016/S0168-9525(97)01223-7; Kim PM, 2003, GENOME RES, V13, P1706, DOI 10.1101/gr.903503; Kuffner R, 2005, BIOINFORMATICS, V21, P259, DOI 10.1093/bioinformatics/bti1143; Landauer TK, 2004, P NATL ACAD SCI USA, V101, P5214, DOI 10.1073/pnas.0400341101; Lee D.D., 2000, P NEUR INF PROC SYST, P556; Lee DD, 1999, NATURE, V401, P788; Maglott D, 2005, NUCLEIC ACIDS RES, V33, pD54, DOI 10.1093/nar/gki031; Mao Wenlei, 2002, Proc AMIA Symp, P489; Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60; Pehkonen P, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-162; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Raychaudhuri S, 2002, GENOME RES, V12, P1582, DOI 10.1101/gr.116402; Renner A, 2000, Pac Symp Biocomput, P54; SALTON G, 1975, COMMUN ACM, V18, P617; Salton G, 1968, AUTOMATIC INFORM ORG; Shahnaz F, 2006, INFORM PROCESS MANAG, V42, P373, DOI 10.1016/j.ipm.2004.11.005; Shatkay H, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P317; Shatkey H., 2000, Proceedings IEEE Advances in Digital Libraries 2000, DOI 10.1109/ADL.2000.848381; Shatkay H, 2003, J COMPUT BIOL, V10, P821, DOI 10.1089/106652703322756104; SINGHAL A, 2001, IEEE DATA ENG B, V24, P35; SPARCKJONES K, 1972, J DOC, V28, P11; TSUGE S, 2001, P IEEE INT C SYST MA, V2, P960; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Wren JD, 2004, BIOINFORMATICS, V20, P191, DOI 10.1093/bioinformatics/btg390; Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; [Anonymous], SACCHAROMYCES GENOME; [Anonymous], ENTREZ GENE; SGD GENE ONTOLOGY SL	44	36	39	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JAN 26	2006	7								41	10.1186/1471-2105-7-41		19	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	017NW	WOS:000235701300001	
J	Phillips, SJ; Anderson, RP; Schapire, RE				Phillips, SJ; Anderson, RP; Schapire, RE			Maximum entropy modeling of species geographic distributions	ECOLOGICAL MODELLING			English	Article						maximum entropy; distribution; modeling; niche; range	OPERATING CHARACTERISTIC CURVES; GENERALIZED ADDITIVE-MODELS; SPINY POCKET MICE; BIODIVERSITY INFORMATICS; SPATIAL PREDICTION; CLIMATE-CHANGE; ABSENCE DATA; NICHE; CONSERVATION; ECOLOGY	The availability of detailed environmental data, together with inexpensive and powerful computers, has fueled a rapid increase in predictive modeling of species environmental requirements and geographic distributions. For some species, detailed presence/absence occurrence data are available, allowing the use of a variety of standard statistical techniques. However, absence data are not available for most species. In this paper, we introduce the use of the maximum entropy method (Maxent) for modeling species geographic distributions with presence-only data. Maxent is a general-purpose machine learning method with a simple and precise mathematical formulation, and it has a number of aspects that make it well-suited for species distribution modeling. In order to investigate the efficacy of the method, here we perform a continental-scale case study using two Neotropical mammals: a lowland species of sloth, Bradypus variegatus, and a small montane murid rodent, Microryzomys minutus. We compared Maxent predictions with those of a commonly used presence-only modeling method, the Genetic Algorithm for Rule-Set Prediction (GARP). We made predictions on 10 random subsets of the occurrence records for both species, and then used the remaining localities for testing. Both algorithms provided reasonable estimates of the species' range, far superior to the shaded outline maps available in field guides. All models were significantly better than random in both binomial tests of omission and receiver operating characteristic (ROC) analyses. The area under the ROC curve (AUC) was almost always higher for Maxent, indicating better discrimination of suitable versus unsuitable areas for the species. The Maxent modeling approach can be used in its present form for many applications with presence-only datasets, and merits further research and development. (c) 2005 Elsevier B.V. All rights reserved.	AT&T Labs Res, Florham Pk, NJ 07932 USA; CUNY City Coll, Dept Biol, New York, NY 10031 USA; Amer Museum Nat Hist, Div Vertebrate Zool Mammal, New York, NY 10024 USA; Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA	Phillips, SJ (reprint author), AT&T Labs Res, 180 Pk Ave, Florham Pk, NJ 07932 USA.	phillips@research.att.com; anderson@sci.ccny.cuny.edu; schapire@cs.princeton.edu					Anderson RP, 2003, J BIOGEOGR, V30, P591; Anderson RP, 2002, GLOBAL ECOL BIOGEOGR, V11, P131, DOI 10.1046/j.1466-822X.2002.00275.x; Anderson RP, 2004, BIOL CONSERV, V116, P167, DOI 10.1016/S0006-3207(03)00187-3; Anderson RP, 2003, ECOL MODEL, V162, P211, DOI 10.1016/S0304-3800(02)00349-6; Anderson RP, 2001, P BIOL SOC WASH, V114, P1; Anderson RP, 2002, OIKOS, V98, P3, DOI 10.1034/j.1600-0706.2002.t01-1-980116.x; ANDERSON S, 1963, P C DAT ACQ PROC BIO, P55; AOKI I, 1989, ECOL MODEL, V45, P81, DOI 10.1016/0304-3800(89)90085-9; ASPINALL R, 1992, INT J GEOGR INF SYST, V6, P105, DOI 10.1080/02693799208901899; Austin MP, 2002, ECOL MODEL, V157, P101, DOI 10.1016/S0304-3800(02)00205-3; Baker Robert J., 1998, Occasional Papers Museum of Texas Tech University, V187, P1; Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4; Bisby FA, 2000, SCIENCE, V289, P2309, DOI 10.1126/science.289.5488.2309; Brodley CE, 2004, P 21 INT C MACH LEAR, P903; Brown JH, 1998, BIOGEOGRAPHY; BUSBY JR, 1986, AUST J ECOL, V11, P1, DOI 10.1111/j.1442-9993.1986.tb00912.x; Carleton M.D., 1989, B AM MUS NAT HIST, V119, P1; CARPENTER G, 1993, BIODIVERS CONSERV, V2, P667, DOI 10.1007/BF00051966; Corsi Fabio, 2000, P389; Corsi F, 1999, CONSERV BIOL, V13, P150, DOI 10.1046/j.1523-1739.1999.97269.x; Della Pietra S., 1997, IEEE T PATTERN ANAL, V19, P1; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; DINESTEIN E, 1995, CONSERVATION ASSESSM; Dudik M., 2004, P 17 ANN C COMP LEAR, P655; Eisenberg J. F., 1999, MAMMALS NEOTROPICS, V3; Elith Jane, 2002, P39; Emmons Louise, 1997, NEOTROPICAL RAINFORE; Engler R, 2004, J APPL ECOL, V41, P263, DOI 10.1111/j.0021-8901.2004.00881.x; Fawcett T., 2003, HPL20034; Ferrier S, 2002, BIODIVERS CONSERV, V11, P2275, DOI 10.1023/A:1021302930424; FERRIER S, 1996, EVALUATION EFFECTIVE; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; GOUVEA E, 1999, REV CIENTIFICA CENTR, V1, P11; Graham CH, 2004, TRENDS ECOL EVOL, V19, P497, DOI 10.1016/j.tree.2004.07.006; Guisan A, 2002, ECOL MODEL, V157, P89, DOI 10.1016/S0304-3800(02)00204-1; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; HANLEY JA, 1982, RADIOLOGY, V143, P29; HANLEY JA, 1983, RADIOLOGY, V148, P839; Hershkovitz Philip, 1998, Bonner Zoologische Beitraege, V47, P193; Hirzel AH, 2002, ECOLOGY, V83, P2027, DOI 10.1890/0012-9658(2002)083[2027:ENFAHT]2.0.CO;2; Holdridge LR, 1971, FOREST ENV TROPICAL; HUTCHINSON GE, 1957, COLD SPRING HARB SYM, V22, P415; JAYNES ET, 1990, FUND THEOR, V39, P1; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Jensen J.R., 1996, INTRO DIGITAL IMAGE; Joseph Leo, 2002, Ornitologia Neotropical, V13, P1; Karl JW, 2002, PREDICTING SPECIES OCCURRENCES: ISSUES OF ACCURACY AND SCALE, P573; Mackey BG, 2001, J BIOGEOGR, V28, P1147, DOI 10.1046/j.1365-2699.2001.00626.x; MCPHERSON AB, 1985, BRENESIA, V23, P97; New M, 1999, J CLIMATE, V12, P829, DOI 10.1175/1520-0442(1999)012<0829:RTCSTC>2.0.CO;2; NG A, 2001, ADV NEURAL INFORMATI, V14, P605; NIX HA, 1986, BIOGEOGRAPHIC ANAL A, P4; Patterson B., 2003, DIGITAL DISTRIBUTION; Paynter Jr R. A., 1982, ORNITHOLOGICAL GAZET; Pearson RG, 2004, ECOGRAPHY, V27, P285, DOI 10.1111/j.0906-7590.2004.03740.x; Perez-Hernandez Roger, 1997, Acta Cientifica Venezolana, V48, P177; Peterson A. T., 1999, ECOL MODEL, V117, P154; Peterson AT, 2003, ANIM CONSERV, V6, P47, DOI 10.1017/S136794300300307X; Peterson AT, 2003, ECOL LETT, V6, P774, DOI 10.1046/j.1461-0248.2003.00502.x; Peterson AT, 2003, CONSERV BIOL, V17, P1161, DOI 10.1046/j.1523-1739.2003.02206.x; Peterson AT, 1999, SCIENCE, V285, P1265, DOI 10.1126/science.285.5431.1265; Peterson AT, 2003, INT J PARASITOL, V33, P919, DOI 10.1016/S0020-7519(03)00094-8; Phillips SJ, 2004, P 21 INT C MACH LEAR, P655, DOI DOI 10.1145/1015330.1015412; Ponder WF, 2001, CONSERV BIOL, V15, P648, DOI 10.1046/j.1523-1739.2001.015003648.x; Provost F.J., 1997, KNOWLEDGE DISCOVERY, P43; Pulliam HR, 2000, ECOL LETT, V3, P349, DOI 10.1046/j.1461-0248.2000.00143.x; Ratnaparkhi A., 1998, THESIS U PENNSYLVANI; Reddy S, 2003, J BIOGEOGR, V30, P1719, DOI 10.1046/j.1365-2699.2003.00946.x; ROOT T, 1988, J BIOGEOGR, V15, P489, DOI 10.2307/2845278; SCHNEIDER ED, 1994, MATH COMPUT MODEL, V19, P25, DOI 10.1016/0895-7177(94)90188-0; Scott J.M., 2002, PREDICTING SPECIES O; Shannon E., 1948, BELL SYST TECH J, V27, P623; Soberon J, 1999, TRENDS ECOL EVOL, V14, P291, DOI 10.1016/S0169-5347(99)01617-1; Soberon J, 2004, PHILOS T ROY SOC B, V359, P689, DOI 10.1098/rstb.2003.1439; Stockwell D, 1999, INT J GEOGR INF SCI, V13, P143, DOI 10.1080/136588199241391; Stockwell DRB, 2002, ECOL MODEL, V148, P1, DOI 10.1016/S0304-3800(01)00388-X; Stockwell DRB, 2002, PREDICTING SPECIES OCCURRENCES: ISSUES OF ACCURACY AND SCALE, P537; STOCKWELL DRB, 1992, MATH COMPUT SIMULAT, V33, P385, DOI 10.1016/0378-4754(92)90126-2; Suarez AV, 2004, BIOSCIENCE, V54, P66, DOI 10.1641/0006-3568(2004)054[0066:TVOMCF]2.0.CO;2; TATE G. H. H., 1939, BULL AMER MUS NAT HIST, V76, P151; Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121; VIDA S, 1993, COMPUT METH PROG BIO, V40, P95, DOI 10.1016/0169-2607(93)90004-5; Welk E, 2002, DIVERS DISTRIB, V8, P219, DOI 10.1046/j.1472-4642.2002.00144.x; Stein Barbara R., 2004, Biodiversity Informatics, V1, P14; Wiley E. O., 2003, OCEANOGRAPHY, V16, P120; WILLIAMS TF, 1995, AGING-CLIN EXP RES, V7, P1; YEE TW, 1991, J VEG SCI, V2, P587, DOI 10.2307/3236170; Yom-Tov Yoram, 1998, Diversity and Distributions, V4, P63, DOI 10.1046/j.1472-4642.1998.00012.x; Zaniewski AE, 2002, ECOL MODEL, V157, P261, DOI 10.1016/S0304-3800(02)00199-0; ZWEIG MH, 1993, CLIN CHEM, V39, P561	90	1531	1678	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	JAN 25	2006	190	3-4					231	259		10.1016/j.ecolmodel.2005.03.026		29	Ecology	Environmental Sciences & Ecology	992BR	WOS:000233859600001	
J	Hao, G; Derakhshan, B; Shi, L; Campagne, F; Gross, SS				Hao, G; Derakhshan, B; Shi, L; Campagne, F; Gross, SS			SNOSID, a proteomic method for identification of cysteine S-nitrosylation sites in complex protein mixtures	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						mass spectrometry; nitric oxide	NEURONAL NITRIC-OXIDE; NITROSOGLUTATHIONE; MODEL; MODULATION; SYNTHASE; SIGNAL; THIOL	Reversible addition of NO to Cys-sulfur in proteins, a modification termed S-nitrosylation, has emerged as a ubiquitous signaling mechanism for regulating diverse cellular processes. A key first-step toward elucidating the mechanism by which S-nitrosylation modulates a protein's function is specification of the targeted Cys (SNO-Cys) residue. To date, S-nitrosylation site specification has been laboriously tackled on a protein-by-protein basis. Here we describe a high-throughput proteomic approach that enables simultaneous identification of SNO-Cys sites and their cognate proteins in complex biological mixtures. The approach, termed SNOSID (SNO Site Identification), is a modification of the biotin-swap technique [Jaffrey, S. R., Erdjument-Bromage, H., Ferris, C. D., Tempst, P. & Snyder, S. H. (2001) Nat. Cell. Biol. 3, 193-197], comprising biotinylation of protein SNO-Cys residues, trypsinolysis, affinity purification of biotinylated-peptides, and amino acid sequencing by liquid chromatography tandem MS. With this approach, 68 SNO-Cys sites were specified on 56 distinct proteins in S-nitrosoglutathione-treated (2-10 mu M) rat cerebellum lysates. In addition to enumerating these S-nitrosylation sites, the method revealed endogenous SNO-Cys modification sites on cerebellum proteins, including alpha-tubulin, beta-tubulin, GAPDH, and dihydropyrimidinase-related protein-2. Whereas these endogenous SNO proteins were previously recognized, we extend prior knowledge by specifying the SNO-Cys modification sites. Considering all 68 SNO-Cys sites identified, a machine learning approach failed to reveal a linear Cys-flanking motif that predicts stable transnitrosation by S-nitrosoglutathione under test conditions, suggesting that undefined 3D structural features determine S-nitrosylation specificity. SNOSID provides the first effective tool for unbiased elucidation of the SNO proteome, identifying Cys residues that undergo reversible S-nitrosylation.	Cornell Univ, Weill Med Coll, Dept Pharmacol, New York, NY 10021 USA; Cornell Univ, Weill Med Coll, Dept Physiol, New York, NY 10021 USA; Cornell Univ, Weill Med Coll, Dept Biophys, New York, NY 10021 USA; Cornell Univ, Weill Med Coll, Inst Computat Biomed, New York, NY 10021 USA	Gross, SS (reprint author), Cornell Univ, Weill Med Coll, Dept Pharmacol, 1300 York Ave,Room LC-428, New York, NY 10021 USA.	ssgross@med.cornell.edu	Campagne, Fabien/F-5158-2010				Bogumil R, 2000, EUR J BIOCHEM, V267, P1407, DOI 10.1046/j.1432-1327.2000.01133.x; Choi YB, 2000, NAT NEUROSCI, V3, P15; Eu JP, 2000, BIOCHEMISTRY-US, V39, P1040, DOI 10.1021/bi992046e; Fang M, 2000, NEURON, V28, P183, DOI 10.1016/S0896-6273(00)00095-7; Foster MW, 2004, J BIOL CHEM, V279, P25891, DOI 10.1074/jbc.M313853200; Gow AJ, 2002, J BIOL CHEM, V277, P9637, DOI 10.1074/jbc.C100746200; Hao G, 2004, J BIOL CHEM, V279, P36192, DOI 10.1074/jbc.M404866200; HOPE BT, 1991, P NATL ACAD SCI USA, V88, P2811, DOI 10.1073/pnas.88.7.2811; Jaffrey SR, 2001, NAT CELL BIOL, V3, P193, DOI 10.1038/35055104; Kim YJ, 2004, ANAL BIOCHEM, V332, P376, DOI 10.1016/j.ab.2004.06.033; Kluge I, 1997, J NEUROCHEM, V69, P2599; Kuncewicz T, 2004, CONTRIB NEPHROL, V141, P221; Liu L, 2004, CELL, V116, P617, DOI 10.1016/S0092-8674(04)00131-X; Martinez-Ruiz A, 2004, CARDIOVASC RES, V62, P43, DOI 10.1016/j.cardiores.2004.01.013; Mayer B, 1998, J BIOL CHEM, V273, P3264, DOI 10.1074/jbc.273.6.3264; McStay GP, 2002, BIOCHEM J, V367, P541, DOI 10.1042/BJ20011672; Nogales E, 1999, CELL, V96, P79, DOI 10.1016/S0092-8674(00)80961-7; Perez-Mato I, 1999, J BIOL CHEM, V274, P17075, DOI 10.1074/jbc.274.24.17075; Roychowdhury M, 2000, EUR J BIOCHEM, V267, P3469, DOI 10.1046/j.1432-1327.2000.01369.x; Stamler JS, 2001, CELL, V106, P675, DOI 10.1016/S0092-8674(01)00495-0; Sun JH, 2001, P NATL ACAD SCI USA, V98, P11158, DOI 10.1073/pnas.201289098; Webster KA, 2001, ANTIOXID REDOX SIGN, V3, P535, DOI 10.1089/15230860152542916; Wolosker H, 1996, FEBS LETT, V392, P274, DOI 10.1016/0014-5793(96)00829-0	23	164	173	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	JAN 24	2006	103	4					1012	1017		10.1073/pnas.0508412103		6	Multidisciplinary Sciences	Science & Technology - Other Topics	007AC	WOS:000234938300033	
J	He, YJ; Chen, DZ; Zhao, WX				He, YJ; Chen, DZ; Zhao, WX			Ensemble classifier system based on ant colony algorithm and its application in chemical pattern classification	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						ant colony algorithm; group recruitment; mass recruitment; rule extraction; ensemble classifier system	PIECEWISE-LINEAR DISCRIMINANTS; ARTIFICIAL NEURAL-NETWORKS; ROUGH SETS; OPTIMIZATION	A novel ant colony algorithm, mass recruitment and group recruitment based continuous ant colony optimization (MG-CACO), is proposed to solve continuous optimization problems. MG-CACO, which can capture the interdependencies between attributes and does not need discretization as a preprocessing step for optimization, was applied to extract classification rules from samples. To improve the predictive performance of the classifier, the ensemble strategy was adopted and the MG-CACO based ensemble classifier system called MG-CACO-ECS was built. Several datasets, obtained from UCI (University of California, Irvine) machine learning repository, were employed to illustrate the validity of MG-CACO-ECS. The results indicated that MG-CACO-ECS has satisfactory prediction accuracy. Furthermore, the problem of the producing area discrimination of olive oil was studied, and the obtained results demonstrated that MG-CACO-ECS has better prediction accuracy than the reported results. (c) 2005 Elsevier B.V. All rights reserved.	Zhejiang Univ, Dept Chem Engn & Biol Engn, Hangzhou 310027, Peoples R China; Clarkson Univ, Ctr Air Resources Engn & Sci, Potsdam, NY 13699 USA	Chen, DZ (reprint author), Zhejiang Univ, Dept Chem Engn & Biol Engn, Hangzhou 310027, Peoples R China.	dzc@cmsce.zju.edu.cn					BECKERS R, 1989, Psyche (Cambridge), V96, P239, DOI 10.1155/1989/94279; Bilchev G., 1995, LECT NOTES COMPUTER, V993, P25; Bonabeau E, 1998, J THEOR BIOL, V195, P157, DOI 10.1006/jtbi.1998.0789; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Carlos CCA, 2002, COMPUT METHODS APPL, V191, P1245; Colorni A, 1991, P 1 EUR C ART LIF, P134; DeLisle RK, 2004, J CHEM INF COMP SCI, V44, P862, DOI 10.1021/ci034188s; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Dreo J., 2002, LNCS, V2463, P216; Freitas A., 2001, ADV EVOLUTIONARY COM, P819; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GAMBARDELLA ML, 1995, P 12 MACH LEARN C, P252; Han J. W, 2000, DATA MINING CONCEPTS; He P, 2004, CHEMOMETR INTELL LAB, V70, P39, DOI 10.1016/j.chemolab.2003.10.001; Herrera F., 2000, P 2 INT WORKSH ANT A, P13; HOPKE PK, 1993, CHEMOMETR INTELL LAB, V19, P35, DOI 10.1016/0169-7439(93)80080-2; Huan Liu, 2002, Data Mining and Knowledge Discovery, V6; KINDT VT, 2002, EUR J OPER RES, V142, P250; Kwedlo W, 1999, LECT NOTES ARTIF INT, V1704, P392; Optiz D, 1999, J ARTIFICIAL INTELLI, V11, P169; Parpinelli RS, 2002, DATA MINING: A HEURISTIC APPROACH, P191; Qi YH, 1999, CHEMOMETR INTELL LAB, V45, P287, DOI 10.1016/S0169-7439(98)00133-6; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Shaffer RE, 1996, CHEMOMETR INTELL LAB, V35, P87, DOI 10.1016/S0169-7439(96)00014-7; Shaffer RE, 1996, CHEMOMETR INTELL LAB, V32, P95, DOI 10.1016/0169-7439(95)00069-0; Shelokar PS, 2004, COMPUT CHEM ENG, V28, P1577, DOI 10.1016/j.compchemeng.2003.12.004; Shu ZH, 2004, CHINESE J ANAL CHEM, V32, P879; THOMAS G, 2000, LECT NOTES COMPUTER, V1857, P1; Walczak B, 1999, CHEMOMETR INTELL LAB, V47, P1, DOI 10.1016/S0169-7439(98)00200-7; Wu W, 1996, CHEMOMETR INTELL LAB, V35, P127; Yu IK, 2001, INT J ELEC POWER, V23, P471, DOI 10.1016/S0142-0615(00)00065-X	31	4	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	JAN 20	2006	80	1					39	49		10.1016/j.chemolab.2005.06.003		11	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	007LB	WOS:000234969400004	
J	Suzuki, Y; Shoudai, T; Uchida, T; Miyahara, T				Suzuki, Y; Shoudai, T; Uchida, T; Miyahara, T			Ordered term tree languages which are polynomial time inductively inferable from positive data	THEORETICAL COMPUTER SCIENCE			English	Article; Proceedings Paper	13th Annual International Conference on Algorithmic Learning Theory	NOV 24-26, 2002	LUBECK, GERMANY	DFKI GmbH, CorpoBase, JessenLenz		machine learning; inductive inference; tree structured pattern	CONTRACTILE VARIABLES; INFERENCE; PATTERNS; QUERIES	In the fields of data mining and knowledge discovery, many semistructured data such as HTML/XML files are represented by rooted trees t such that all children of each internal vertex of t are ordered and t has edge labels. In order to represent structural features common to such semistructured data, we propose a linear ordered term tree, which is a rooted tree pattern consisting of ordered tree structures and internal structured variables with distinct variable labels. For a set of edge labels Lambda, let partial derivative TTLambda be the set of all linear ordered term trees. For a linear ordered term tree t in partial derivative TTLambda, the term tree language of t, denoted by L-Lambda(t), is the set of all ordered trees obtained from t by substituting arbitrary ordered trees for all variables in t. Given a set of ordered trees S, the minimal language problem for partial derivative TLLambda = {L-Lambda(t) vertical bar t is an element of partial derivative TTLambda} is to find a linear ordered term tree t in partial derivative TTLambda such that LA (t) is minimal among all term tree languages which contain all ordered trees in S. We show that the class partial derivative TTLambda is polynomial time inductively inferable from positive data, by giving a polynomial time algorithm for solving the minimal language problem for partial derivative TTLambda (c) 2005 Elsevier B.V All rights reserved.	Hiroshima City Univ, Fac Informat Sci, Hiroshima 7313194, Japan; Kyushu Univ, Dept Informat, Kasuga, Fukuoka 8168580, Japan	Suzuki, Y (reprint author), Hiroshima City Univ, Fac Informat Sci, Hiroshima 7313194, Japan.	y-suzuki@cs.hiroshima-cu.ac.jp					Abiteboul S., 2000, DATA WEB RELATIONS S; Amoth T. R., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279980; Amoth T. R., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307486; ANGLUIN D, 1980, J COMPUT SYST SCI, V21, P46, DOI 10.1016/0022-0000(80)90041-0; ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; Arimura H., 1994, LECT NOTES COMPUTER, V775, P649; ARIMURA H, 2001, LECT NOTES ARTIF INT, V2225, P315; Matsumoto S, 1997, LECT NOTES ARTIF INT, V1316, P212; Matsumoto S, 2004, LECT NOTES ARTIF INT, V3244, P425; Matsumoto S, 2002, LECT NOTES ARTIF INT, V2557, P523; MIYAHARA T, 2002, LECT NOTES ARTIF INT, V2336, P341; SHINOHARA T, 1983, LECT NOTES COMPUT SC, V147, P115; Shinohara T., 1995, LECT NOTES ARTIF INT, V961, P259; SHOUDAI T, 2001, LNCS, V2138, P335; SHOUDAI T, 2000, INFORMATION MODELLIN, V11, P85; Suzuki Y, 2003, LECT NOTES ARTIF INT, V2842, P114; SUZUKI Y, 2002, LECT NOTES ARTIF INT, V2375, P169; Suzuki Y, 2003, LECT NOTES ARTIF INT, V2583, P270; Suzuki Y, 2003, LECT NOTES ARTIF INT, V2835, P347; Suzuki Y, 2004, LECT NOTES ARTIF INT, V3157, P211; UCHIDA T, 1995, IEICE T INF SYST, VE78D, P99	22	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975		THEOR COMPUT SCI	Theor. Comput. Sci.	JAN 18	2006	350	1					63	90		10.1016/j.tcs.2005.10.022		28	Computer Science, Theory & Methods	Computer Science	004VE	WOS:000234779800007	
J	Fronhofer, B; Yamamoto, A				Fronhofer, B; Yamamoto, A			Hypothesis finding with proof theoretical appropriateness criteria	THEORETICAL COMPUTER SCIENCE			English	Article; Proceedings Paper	13th Annual International Conference on Algorithmic Learning Theory	NOV 24-26, 2002	LUBECK, GERMANY	DFKI GmbH, CorpoBase, JessenLenz		hypothesis finding; connection method; relevance logic; residue hypotheses; inductive logic; abduction and knowledge discovery	INVERSE ENTAILMENT; RESIDUE HYPOTHESES; RESOLUTION; LOGIC	For two given formulae B and C with B does not satisfy C, hypothesis finding means to produce a formula S such that B boolean AND S satisfies C. Hypothesis finding, or variants thereof, is central to various types of inference, e.g., abductive inference, inductive inference, machine learning, and machine discovery. Clarifying the nature of hypothesis finding is still in its infancy, a situation similar to the establishment of logical foundations of inference related to induction and discovery. Although trivial solutions to hypothesis finding are easy to give, finding appropriate hypotheses still remains as a great challenge. A central role in this context plays the question, what it means for a hypothesis to be appropriate? In this paper we propose an answer to this question, which is based on proof theoretical criteria. This is in contrast to most previous approaches where appropriateness of hypotheses was based on concepts of semantical weakness in classical logic. More precisely, we use provability in Relevance Logic instead of classical semantical entailment, we demand utmost exploitation of the inferential potential (deductive content) inherent in B -> C and we demand S to be a minimal deductive supplement to B -> C. Along these lines we developed the concept of a minimized residue hypothesis which also constitutes an interesting trade-off between 'logical smallness' and 'syntactical smallness'. Published by Elsevier B.V.	Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan; Tech Univ Dresden, Dept Comp Sci, D-01062 Dresden, Germany	Yamamoto, A (reprint author), Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan.	fronhoef@inf.tu-dresden.de; akihiro@i.kyoto-u.ac.jp					ANDERSON AR, 1975, LOGIC RELEVANCE NECE, V1; Arimura H, 1997, LECT NOTES ARTIF INT, V1316, P432; Bibel W, 1987, AUTOMATED THEOREM PR; Dunn J. M., 1986, HDB PHILOS LOGIC, V3, P117; FRAZIER M, 1993, P 10 INT C MACH LEAR, P120; Fronhofer B, 2002, LECT NOTES ARTIF INT, V2533, P278; FRONHOFER B, 1996, COMPUTER SCI MONOGRA, V1; Furukawa K, 1998, LECT NOTES ARTIF INT, V1532, P315; INOUE K, 1992, ARTIF INTELL, V56, P301, DOI 10.1016/0004-3702(92)90030-2; Kakas A. C., 1992, Journal of Logic and Computation, V2, DOI 10.1093/logcom/2.6.719; Kreitz C., 1999, J UNIVERS COMPUT SCI, V5, P88; Lavrac N, 1999, J LOGIC PROGRAM, V40, P215, DOI 10.1016/S0743-1066(99)00019-9; Lin F., 2000, P 7 INT C PRINC KNOW, P167; Midelfart B, 1999, LECT NOTES ARTIF INT, V1634, P210; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Plotkin G. D., 1971, THESIS EDINBURGH U; POOLE David, 1987, KNOWLEDGE FRONTIER E, P331; ROUVEIROL C, 1992, INDUCTIVE LOGIC PROG, P63; SAKAMA C, 2000, LECT NOTES ARTIF INT, V1866, P209; Shinohara T., 1991, New Generation Computing, V8; Wallen L, 1990, AUTOMATED DEDUCTION; Yamamoto A, 1999, NEW GENERAT COMPUT, V17, P119; Yamamoto A, 2000, LECT NOTES ARTIF INT, V1968, P156; Yamamoto A, 1999, NEW GENERAT COMPUT, V17, P99; [Anonymous], 1973, P 3 INT JOINT C ART, P147	25	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975		THEOR COMPUT SCI	Theor. Comput. Sci.	JAN 18	2006	350	1					140	162		10.1016/j.tcs.2005.10.020		23	Computer Science, Theory & Methods	Computer Science	004VE	WOS:000234779800011	
J	Buturovic, LJ				Buturovic, LJ			PCP: a program for supervised classification of gene expression profiles	BIOINFORMATICS			English	Article							ERROR ESTIMATION; PREDICTION; CANCER	PCP (Pattern Classification Program) is an open-source machine learning program for supervised classification of patterns (vectors of measurements). The principal use of PCP in bioinformatics is design and evaluation of classifiers for use in clinical diagnostic tests based on measurements of gene expression. PCP implements leading pattern classification and gene selection algorithms and incorporates cross-validation estimation of classifier performance. Importantly, the implementation integrates gene selection and class prediction stages, which is vital for computing reliable performance estimates in small-sample scenarios. Additionally, the program includes automated and efficient model selection (optimization of parameters) for support vector machine (SVM) classifier. The distribution includes Linux and Windows/ Cygwin binaries. The program can easily be ported to other platforms.	San Francisco State Univ, San Francisco, CA 94132 USA	Buturovic, LJ (reprint author), San Francisco State Univ, 1600 Holloway Ave, San Francisco, CA 94132 USA.	ljubomir@sfsu.edu					ANDERSON E., 1999, LAPACK USERS GUIDE; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Irizarry RA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng015; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; MORALEDA J, 2004, P AM SOC CLIN ONC AN, V23, P862; Press WH, 1992, NUMERICAL RECIPES; SOONMYUNG P, 2004, NEW ENGL J MED, V351, P2817; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Theodoridis S., 2003, PATTERN RECOGNITION; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967	11	10	11	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JAN 15	2006	22	2					245	247		10.1093/bioinformatics/bit760		3	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	010ST	WOS:000235218900019	
J	Nanni, L				Nanni, L			Multi-resolution subspace for financial trading	PATTERN RECOGNITION LETTERS			English	Article						subspace classifier; stock trend prediction; machine learning		In this paper, we introduce a new stock trend prediction approach based on subspace classifier and a new feature representation. Our goal is not price prediction but rather trend prediction, which can be formulated as a problem of pattern classification. Recently, several works have approached this problem by applying machine learning techniques. We show that this problem con be efficiently solved using a new method of anchoring. From the feature extracted by technical indicators, we apply an anchoring method to create different features spaces, and a subspace classifier is trained in each feature space. A cascade of classifiers is developed to classify the patterns as "downward trend" or "upward trend". Extensive experiments, carried out on various dataset, confirm the robustness of our approach. We show, that our method permit to obtain a gain higher than standard machine learning classifiers in all the tests. (c) 2005 Elsevier B.V. All rights reserved.	Univ Bologna, DEIS, CNR, IEIIT, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, CNR, IEIIT, Viale Risorgimento 2, I-40136 Bologna, Italy.	lnanni@deis.unibo.it					Bezdek J. C., 1981, PATTERN RECOGNITION; BHALERAO A, 2003, P BRIT MACH VIS C BM; CLOETE I, 2001, P 13 EUR SIM S SIM I, P713; DUIN RPW, 2002, P PRIS 2002 2002 INT, P20; Edwards R., 2001, TECHNICAL ANAL STOCK; HELLSTRM T, 1998, TECHNICAL REPORT SER; Hiemstra Y., 1994, Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences. Vol.III: Information Systems: Decision Support and Knowledge-Based Systems (Cat. No.94TH0607-2), DOI 10.1109/HICSS.1994.323343; Kuncheva LI, 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; Natsev A., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), DOI 10.1109/ICME.2002.1035628; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Schierholt K, 1996, PROCEEDINGS OF THE IEEE/IAFE 1996 CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR FINANCIAL ENGINEERING (CIFER), P72, DOI 10.1109/CIFER.1996.501826; Tax D., 2001, THESIS; Van der Heijden F, 2004, CLASSIFICATION PARAM; VANEYDEN RJ, 1996, APPL NEURA NETWORKS; VIOLA P, 2002, ADV NEURAL INFORMATI, V14	15	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN 15	2006	27	2					109	115		10.1016/j.patrec.2005.07.008		7	Computer Science, Artificial Intelligence	Computer Science	991CY	WOS:000233791100004	
J	Brameier, M; Haan, J; Krings, A; MacCallum, RM				Brameier, M; Haan, J; Krings, A; MacCallum, RM			Automatic discovery of cross-family sequence features associated with protein function	BMC BIOINFORMATICS			English	Article							SUBCELLULAR-LOCALIZATION; SORTING SIGNALS; PREDICTION; GENE; ORGANIZATION; HISTIDINE; SITE	Background: Methods for predicting protein function directly from amino acid sequences are useful tools in the study of uncharacterised protein families and in comparative genomics. Until now, this problem has been approached using machine learning techniques that attempt to predict membership, or otherwise, to predefined functional categories or subcellular locations. A potential drawback of this approach is that the human-designated functional classes may not accurately reflect the underlying biology, and consequently important sequence-to-function relationships may be missed. Results: We show that a self-supervised data mining approach is able to find relationships between sequence features and functional annotations. No preconceived ideas about functional categories are required, and the training data is simply a set of protein sequences and their UniProt/Swiss-Prot annotations. The main technical aspect of the approach is the co-evolution of amino acid-based regular expressions and keyword-based logical expressions with genetic programming. Our experiments on a strictly non-redundant set of eukaryotic proteins reveal that the strongest and most easily detected sequence-to-function relationships are concerned with targeting to various cellular compartments, which is an area already well studied both experimentally and computationally. Of more interest are a number of broad functional roles which can also be correlated with sequence features. These include inhibition, biosynthesis, transcription and defence against bacteria. Despite substantial overlaps between these functions and their corresponding cellular compartments, we find clear differences in the sequence motifs used to predict some of these functions. For example, the presence of polyglutamine repeats appears to be linked more strongly to the "transcription" function than to the general "nuclear" function/location. Conclusion: We have developed a novel and useful approach for knowledge discovery in annotated sequence data. The technique is able to identify functionally important sequence features and does not require expert knowledge. By viewing protein function from a sequence perspective, the approach is also suitable for discovering unexpected links between biological processes, such as the recently discovered role of ubiquitination in transcription.	Stockholm Univ, Stockholm Bioinformat Ctr, S-10691 Stockholm, Sweden; Univ Aarhus, Bioinformat Res Ctr, DK-8000 Aarhus C, Denmark; Univ London Imperial Coll Sci Technol & Med, Div Cell & Mol Biol, London SW7 2AZ, England	MacCallum, RM (reprint author), Stockholm Univ, Stockholm Bioinformat Ctr, S-10691 Stockholm, Sweden.	brameier@birc.au.dk; josien@sbc.su.se; akr@sbc.su.se; maccallr@sbc.su.se					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Barak D, 2002, BIOCHEMISTRY-US, V41, P8245, DOI 10.1021/bi020143t; Bateman A, 2004, NUCLEIC ACIDS RES, V32, pD138, DOI 10.1093/nar/gkh121; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Bogdanov Y, 2000, EUR J NEUROSCI, V12, P894, DOI 10.1046/j.1460-9568.2000.00981.x; Bromme D, 1996, BIOCHEMISTRY-US, V35, P3970, DOI 10.1021/bi9523015; Camon E., 2004, NUCLEIC ACIDS RES, V32, P262; Cokol M, 2000, EMBO REP, V1, P411, DOI 10.1093/embo-reports/kvd092; Devos D, 2000, PROTEINS, V41, P98, DOI 10.1002/1097-0134(20001001)41:1<98::AID-PROT120>3.0.CO;2-S; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; HARRIS MA, 2004, NUCLEIC ACIDS RES, V32, P258; Heddad A, 2004, LECT NOTES COMPUT SC, V3005, P31; Hegyi H, 1999, J MOL BIOL, V288, P147, DOI 10.1006/jmbi.1999.2661; Hempel J, 2001, EUR J BIOCHEM, V268, P722, DOI 10.1046/j.1432-1327.2001.01926.x; Herold A, 1998, J CELL BIOL, V143, P309, DOI 10.1083/jcb.143.2.309; Herrera FJ, 2004, CURR BIOL, V14, P622; HUNTER GK, 1993, P NATL ACAD SCI USA, V90, P8562, DOI 10.1073/pnas.90.18.8562; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Kanehisa M., 2004, NUCLEIC ACIDS RES, V32, P277; Kannan N, 2004, PROTEIN SCI, V13, P2059, DOI 10.1110/ps.04637904; King RD, 2000, YEAST, V17, P283, DOI 10.1002/1097-0061(200012)17:4<283::AID-YEA52>3.0.CO;2-F; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Koizumi K, 2003, P NATL ACAD SCI USA, V100, P3119, DOI 10.1073/pnas.0438043100; Koza J. R., 1992, GENETIC PROGRAMMING; MacCallum R.M., 2003, LNCS, V2610, P369; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P4442; NAGAI A, 1995, BIOCHEM BIOPH RES CO, V211, P960, DOI 10.1006/bbrc.1995.1905; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; PAGES G, 1995, J BIOL CHEM, V270, P26986; Puntervoll P, 2003, NUCLEIC ACIDS RES, V31, P3625, DOI 10.1093/nar/gkg545; Reichert J, 2002, NUCLEIC ACIDS RES, V30, P253, DOI 10.1093/nar/30.1.253; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Tompa P, 2002, TRENDS BIOCHEM SCI, V27, P527, DOI 10.1016/S0968-0004(02)02169-2; Triezenberg Steven J., 1995, Current Opinion in Genetics and Development, V5, P190, DOI 10.1016/0959-437X(95)80007-7; Waites CL, 2001, J CELL BIOL, V152, P1159, DOI 10.1083/jcb.152.6.1159	37	6	6	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JAN 12	2006	7								16	10.1186/1471-2105-7-16		19	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	019GW	WOS:000235824600001	
J	Matukumalli, LK; Grefenstette, JJ; Hyten, DL; Choi, IY; Cregan, PB; Van Tassell, CP				Matukumalli, LK; Grefenstette, JJ; Hyten, DL; Choi, IY; Cregan, PB; Van Tassell, CP			Application of machine learning in SNP discovery	BMC BIOINFORMATICS			English	Article							SINGLE-NUCLEOTIDE POLYMORPHISMS; SEQUENCE TAG DATA; HUMAN GENOME; PREDICTION; CLASSIFICATION	Background: Single nucleotide polymorphisms (SNP) constitute more than 90% of the genetic variation, and hence can account for most trait differences among individuals in a given species. Polymorphism detection software PolyBayes and PolyPhred give high false positive SNP predictions even with stringent parameter values. We developed a machine learning (ML) method to augment PolyBayes to improve its prediction accuracy. ML methods have also been successfully applied to other bioinformatics problems in predicting genes, promoters, transcription factor binding sites and protein structures. Results: The ML program C4.5 was applied to a set of features in order to build a SNP classifier from training data based on human expert decisions (True/False). The training data were 27,275 candidate SNP generated by sequencing 1973 STS (sequence tag sites) (12 Mb) in both directions from 6 diverse homozygous soybean cultivars and PolyBayes analysis. Test data of 18,390 candidate SNP were generated similarly from 1359 additional STS (8 Mb). SNP from both sets were classified by experts. After training the ML classifier, it agreed with the experts on 97.3% of test data compared with 7.8% agreement between PolyBayes and experts. The PolyBayes positive predictive values (PPV) (i.e., fraction of candidate SNP being real) were 7.8% for all predictions and 16.7% for those with 100% posterior probability of being real. Using ML improved the PPV to 84.8%, a 5- to 10-fold increase. While both ML and PolyBayes produced a similar number of true positives, the ML program generated only 249 false positives as compared to 16,955 for PolyBayes. The complexity of the soybean genome may have contributed to high false SNP predictions by PolyBayes and hence results may differ for other genomes. Conclusion: A machine learning (ML) method was developed as a supplementary feature to the polymorphism detection software for improving prediction accuracies. The results from this study indicate that a trained ML classifier can significantly reduce human intervention and in this case achieved a 5-10 fold enhanced productivity. The optimized feature set and ML framework can also be applied to all polymorphism discovery software. ML support software is written in Perl and can be easily integrated into an existing SNP discovery pipeline.	ARS, USDA, Beltsville Agr Res Ctr, Bovine Funct Genom Lab, Beltsville, MD 20705 USA; George Mason Univ, Manassas, VA 20110 USA; ARS, USDA, Beltsville Agr Res Ctr, Soybean Genom & Improvement Lab, Beltsville, MD 20705 USA	Van Tassell, CP (reprint author), ARS, USDA, Beltsville Agr Res Ctr, Bovine Funct Genom Lab, Beltsville, MD 20705 USA.	lmatukum@gmu.edu; jgrefens@gmu.edu; hytend@ba.ars.usda.gov; choii@ba.ars.usda.gov; creganp@ba.ars.usda.gov; curtvt@anri.barc.usda.gov	CHOI, Ik-Young/H-3366-2012				Altshuler D, 2000, NATURE, V407, P513; Barker G, 2003, BIOINFORMATICS, V19, P421, DOI 10.1093/bioinformatics/btf881; Batley J, 2003, PLANT PHYSIOL, V132, P84, DOI 10.1104/pp.102.019422; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2003, PEPTIDES, V24, P665, DOI 10.1016/S0196-9781(03)00133-5; Dobrokhotov Pavel B, 2003, Stud Health Technol Inform, V95, P421; FRANK E, 2004, BIOINFORMATICS; Hadley H. H., 1973, AGRON MONOGR, V16, P97; Han LY, 2004, RNA, V10, P355, DOI 10.1261/rna.5890304; LACKEY JA, 1980, AM J BOT, V67, P595, DOI 10.2307/2442301; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Marth GT, 1999, NAT GENET, V23, P452, DOI 10.1038/70570; Nickerson DA, 1997, NUCLEIC ACIDS RES, V25, P2745, DOI 10.1093/nar/25.14.2745; Pavlidis P, 2004, BIOINFORMATICS, V20, P586, DOI 10.1093/bioinformatics/btg461; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Schlueter JA, 2004, GENOME, V47, P868, DOI 10.1139/G04-047; Smit AFA, 1996, REPEAT MASKER OPEN 3; Zhang LV, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-38; Zhao Z, 2002, GENOME RES, V12, P1679, DOI 10.1101/gr.287302; Zhu YL, 2003, GENETICS, V163, P1123	20	14	15	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	JAN 6	2006	7								4	10.1186/1471-2105-7-4		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	008ZN	WOS:000235081000001	
S	Tomas, D; Vicedo, JL; Saiz, M; Izquierdo, R		Peters, C; Gey, FC; Gonzalo, J; Muller, H; Jones, GJF; Kluck, M; Magnini, B; DeRijke, M		Tomas, David; Vicedo, Jose L.; Saiz, Maximiliano; Izquierdo, Ruben			An XML-based system for Spanish question answering	ACCESSING MULTILINGUAL INFORMATION REPOSITORIES	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Workshop of the Cross-Language Evaluation Forum	SEP 21-23, 2005	Vienna, AUSTRIA					As Question Answering is a major research topic at the University of Alicante, this year two separate groups participated in the QA@CLEF track using different approaches. This paper describes the work of Alicante 1 group. Thinking of future developments, we have designed a modular framework based on XML that will easily let us integrate, combine and test system components based on different approaches. In this context, several modifications have been introduced, such as a new machine learning based question classification module. We took part in the monolingual Spanish task.	Univ Alicante, Dept Software & Comp Syst, E-03080 Alicante, Spain	Tomas, D (reprint author), Univ Alicante, Dept Software & Comp Syst, E-03080 Alicante, Spain.	dtomas@dlsi.ua.es; vicedo@dlsi.ua.es; max@dlsi.ua.es; ruben@dlsi.ua.es					TOMAS D, 2005, P APROXIMACION MULTI, P391; VALLIN A, CLEF 2005 WORKSH; VICEDO JL, 2003, LECT NOTES COMPUTER; VICEDO JL, 2004, LECT NOTES COMPUTER	4	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45697-X	LECT NOTES COMPUT SC			2006	4022						347	350				4	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFE01	WOS:000241359000039	
S	Rahman, MM; Desai, BC; Bhattacharya, P		Peters, C; Gey, FC; Gonzalo, J; Muller, H; Jones, GJF; Kluck, M; Magnini, B; DeRijke, M		Rahman, Md. Mahmudur; Desai, Bipin C.; Bhattacharya, Prabir			Supervised machine learning based medical image annotation and retrieval in ImageCLEFmed 2005	ACCESSING MULTILINGUAL INFORMATION REPOSITORIES	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Workshop of the Cross-Language Evaluation Forum	SEP 21-23, 2005	Vienna, AUSTRIA				SUPPORT VECTOR MACHINES; CLASSIFICATION	This paper presents the methods and experimental results for the automatic medical image annotation and retrieval task of Image-CLEFmed 2005. A supervised machine learning approach to associate low-level image features with their high level visual and/or semantic categories is investigated. For automatic image annotation, the input images are presented as a combined feature vector of texture, edge and shape features. A multi-class classifier based on pairwise coupling of several binary support vector machine is trained on these inputs to predict the categories of test images. For visual only retrieval, a combined feature vector of color, texture and edge features is utilized in low dimensional PCA sub-space. Based on the online category prediction of query and database images by the classifier, pre-computed category specific first and second order statistical parameters are utilized in a Bhattacharyya distance measure. Experimental results of both image annotation and retrieval are reported in this paper.	Concordia Univ, Dept Comp Sci, Montreal, PQ, Canada; Concordia Univ, Inst Informat Syst Engn, Montreal, PQ, Canada	Rahman, MM (reprint author), Concordia Univ, Dept Comp Sci, Montreal, PQ, Canada.						AKSOY S, 2000, P IEEE C COMP VIS PA, V2, P357, DOI 10.1109/CVPR.2000.854847; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Chang C.C., 2001, LIBSVM LIB SUPPORT; CLOUGH P, 2006, IN PRESS SPRINGER LE; Fukunaga K., 1990, INTRO STAT PATTERN R; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HU MK, 1962, IRE T INFORM THEORY, V8; Jain A, 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Muller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Wu TF, 2004, J MACH LEARN RES, V5, P975	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45697-X	LECT NOTES COMPUT SC			2006	4022						692	701				10	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFE01	WOS:000241359000076	
S	Mueller, H; Geissbuhler, A; Marty, J; Lovis, C; Ruch, P		Peters, C; Gey, FC; Gonzalo, J; Muller, H; Jones, GJF; Kluck, M; Magnini, B; DeRijke, M		Mueller, Henning; Geissbuehler, Antoine; Marty, Johan; Lovis, Christian; Ruch, Patrick			The use of MedGIFT and EasyIR for ImageCLEF 2005	ACCESSING MULTILINGUAL INFORMATION REPOSITORIES	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Workshop of the Cross-Language Evaluation Forum	SEP 21-23, 2005	Vienna, AUSTRIA				CONTENT-BASED RETRIEVAL; DATABASES	This article describes the use of medGIFT and easyIR for three of four ImageCLEF 2005 tasks. All results rely on two systems: the GNU Image Finding Tool (GIFT) for visual retrieval, and easyIR for text. For ad-hoc retrieval, two visual runs were submitted. No textual retrieval was attempted, resulting in lower scores than those using text retrieval. For medical retrieval, visual retrieval was performed with several configurations of Gabor filters and grey level/color quantisations as well as combinations of text and visual features. Due to a lack of resources no feedback runs were created, an area where medGIFT performed best in 2004. For classification, a retrieval with the target image was performed and the first N = 1; 5; 10 results used to calculate scores for classes by simply adding up the scores for each class. No machine learning was performed, so results were surprisingly good and only topped by systems with optimised learning strategies.	Univ Geneva, CH-1211 Geneva 14, Switzerland; Univ Hosp Geneva, Serv Med Informat, CH-1211 Geneva, Switzerland	Mueller, H (reprint author), Univ Geneva, 24 Micheli Crest, CH-1211 Geneva 14, Switzerland.	henning.mueller@sim.hcuge.ch	Lovis, Christian/D-2634-2012	Lovis, Christian/0000-0002-2681-8076			Agrawal R., 1994, P 20 INT C VER LARG, P487; CLOUGH P, 2005, LECT NOTES COMPUTER; CLOUGH P, 2006, IN PRESS LNCS; CLOUGH P, 2004, SPRINGER LNCS, V3115; HERSH W, 2005, SLICE LIFE C MULTIME; LACASCIA M, 1998, IEEE WORKSH CONT ACC; Lehmann TM, 2005, COMPUT MED IMAG GRAP, V29, P143, DOI 10.1016/j.compmedimag.2004.09.010; Muller H, 2004, INT J COMPUT VISION, V56, P65, DOI 10.1023/B:VISI.0000004832.02269.45; Muller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024; MULLER H, 2005, P WORKSH BILD MED HE; MULLER H, 2003, P MED INFORM EUR C; RUCH P, 2004, P C COMP LING COLING; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Squire DM, 2000, PATTERN RECOGN LETT, V21, P1193, DOI 10.1016/S0167-8655(00)00081-7; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45697-X	LECT NOTES COMPUT SC			2006	4022						724	732				9	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFE01	WOS:000241359000079	
S	Ferrandez, O; Kozareva, Z; Toral, A; Noguera, E; Montoyo, A; Munoz, R; Llopis, F		Peters, C; Gey, FC; Gonzalo, J; Muller, H; Jones, GJF; Kluck, M; Magnini, B; DeRijke, M		Ferrandez, Oscar; Kozareva, Zornitsa; Toral, Antonio; Noguera, Elisa; Montoyo, Andres; Munoz, Rafael; Llopis, Fernando			University of Alicante at GeoCLEF 2005	ACCESSING MULTILINGUAL INFORMATION REPOSITORIES	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Workshop of the Cross-Language Evaluation Forum	SEP 21-23, 2005	Vienna, AUSTRIA					For our participation in GeoCLEF 2005 we have developed a system made up of three modules. One of them is an Information Retrieval module and the others are Named Entity Recognition modules based on machine learning and based on knowledge. We have carried out several runs with different combinations of these modules for resolving the proposed tasks. The system scored second position for the tasks against German collections and third position for the tasks against English collections.	Univ Alicante, Nat Language Proc & Informat Syst Grp, Dept Software & Comp Syst, E-03080 Alicante, Spain	Ferrandez, O (reprint author), Univ Alicante, Nat Language Proc & Informat Syst Grp, Dept Software & Comp Syst, E-03080 Alicante, Spain.	ofe@dlsi.ua.es; zkozareva@dlsi.ua.es; atoral@dlsi.ua.es; elisa@dlsi.ua.es; montoyo@dlsi.ua.es; rafael@dlsi.ua.es; llopis@dlsi.ua.es					FERRANDEZ O, 2005, PROCESAMIENTO LENGUA, V35, P37; KASKZIEL M, 1997, P 20 ANN INT ACM PHI, P178; LLOPIS F, 2004, LECT NOTES COMPUTER, V3491; SAVOY J, 2003, LECT NOTES COMPUTER; Toral A., 2005, P 1 FREE SOFTW TECHN, P27	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45697-X	LECT NOTES COMPUT SC			2006	4022						924	927				4	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFE01	WOS:000241359000103	
J	Turmo, J; Ageno, A; Catala, N				Turmo, Jordi; Ageno, Alicia; Catala, Neus			Adaptive information extraction	ACM COMPUTING SURVEYS			English	Review						algorithms; experimentation; information extraction; machine learning	WRAPPER INDUCTION; TEXT	The growing availability of online textual sources and the potential number of applications of knowledge acquisition from textual data has lead to an increase in Information Extraction (IE) research. Some examples of these applications are the generation of data bases from documents, as well as the acquisition of knowledge useful for emerging technologies like question answering, information integration, and others related to text mining. However, one of the main drawbacks of the application of IE refers to its intrinsic domain dependence. For the sake of reducing the high cost of manually adapting IE applications to new domains, experiments with different Machine Learning (ML) techniques have been carried out by the research community. This survey describes and compares the main approaches to IE and the different ML techniques used to achieve Adaptive IE technology.	Univ Politecn Catalunya, Dept Llenguatges & Sistemes Informat, TALP Res Ctr, ES-08034 Barcelona, Spain	Turmo, J (reprint author), Univ Politecn Catalunya, Dept Llenguatges & Sistemes Informat, TALP Res Ctr, C Jordi Girona Salgado 1-3, ES-08034 Barcelona, Spain.	turmo@lsi.upc.edu; ageno@lsi.upc.edu; ncatala@lsi.upc.edu					ABERDEEN J, 1993, P 5 MESS UND C MUC 5; ABERDEEN J, 1995, P 6 MESS UND C MUC 5; ABNEY S, 1996, PRINCIPLE BASED PARS, P257; AGICHTEIN E, 2000, P 5 ACM INT C DIG LI; AGIRRE E, 1996, P 16 INT C COMP LING; AONE C, 1996, LECT NOTES ARTIFICIA, V1040; AONE C, 1998, P 7 MESS UND C MUC 7; APPELT D, 1992, P 4 MESS UND C MUC 4; APPELT D, 1995, P 6 MESS UND C MUC 6; APPELT DE, 1993, P 13 INT JOINT C ART; APPELT DE, 1993, P 5 MESS UND C MUC 5; ASELTINE J, 1999, P AAAI WORKSH MACH L; Baeza-Yates R.A., 1999, MODERN INFORM RETRIE; Baluja S., 1999, P INT C PAC ASS COMP; BASILI R, 2000, P ECAI WORKSH MACH L; Baum L. E., 1972, INEQUALITIES, V3, P1; BIKEL D, 2004, P 5 C APPL NAT LANG; Borthwick A., 1999, THESIS NEW YORK U; Borthwick A., 1998, P 6 ACL WORKSH VER L; BRIN S, 1998, WEBDB WORKSH 6 INT C; CALIFF ME, 1998, THESIS U TEXAS AUSTI; Cardie C., 2000, P 4 C COMP NAT LANG; Cardie C., 1999, P JOINT SIGDAT C EMP; CARROLL J, 1998, P 1 INT C LANG RES E, P447; CATALA N, 2000, P 14 EUR C ART INT E, P411; CATALA N, 2003, THESIS TU CATALONIA; CHAI J, 1999, P 16 AAAI NAT C ART; CHAI J, 1997, P ACL WORKSH NAT LAN; CHIDLOVSKII B, 2000, P ECAI WORKSH MACH L; Chieu H. L., 2003, P 41 ANN M ACL JUL, P216; CHIEU HL, 2002, P 18 NAT C ART INT A; CHILDS L, 1995, P 6 MESS UND C MUC 6; CIRAVEGNA F., 2001, P IJCAI WORKSH AD TE; Cohen W., 2001, P IJCAI WORKSH AD TE; COHEN W, 2002, P 11 INT WORLD WID W; Cohen WW, 2000, ARTIF INTELL, V118, P163, DOI 10.1016/S0004-3702(99)00102-2; COLLINS M, 1997, P 35 ANN M ASS COMP; COX C, 2005, 1 PASCAL CHALL WORKS; CRAVEN M, 1998, P 15 AAAI NAT C ART; CRAVEN M, 1999, P AAAI WORKSH MACH L; EIKVIL L, 1999, INFORM EXTRACTION WO; FINN A, 2004, P AAAI WORKSH AD TEX; FISHER D, 1995, P 6 MESS UND C MUC 6; FREITAG D, 1998, P JOINT 17 INT C COM; FREITAG D, 2000, P 17 AAAI NAT C ART; FREITAG D, 2000, P ECAI WORKSH MACH L; Freitag D., 1999, P AAAI WORKSH MACH L; Freitag D., 1998, THESIS CARNEGIE MELL; GAIZAUSAKAS R, 1995, CS9525 U SHEFF DEP C; GAIZAUSKAS R, 1995, P 6 MESS UND C MUC 6; GARIGLIANO R, 1998, P 7 MESS UND C MUC 7; Glasgow B, 1998, AI MAG, V19, P59; GLICKMAN O, 1999, P AAAI WORKSH MACH L; Grefenstette G., 1998, CROSS LANGUAGE INFOR; GRISHMAN R, 1993, P 5 MESS UND C MUC 5; Grishman R., 2005, P 43 ANN M ASS COMP, P419, DOI 10.3115/1219840.1219892; GRISHMAN R, 1995, P 6 MESS UND C MUC 6; HARABAGIU S, 2000, P 3 INT C LANG RES E; HOBBS J, 1993, P 5 MESS UND C MUC 5; HOLOWCZAK RD, 1997, P 9 C INN APPL ART I, P992; Hsu C., 1998, P C AUT LEARN DISC; HSU CN, 1998, P AAAI WORKSH AI INF; HUFFMAN S, 1995, P IJCAI WORKSH NEW A; HUMPHREYS K, 1998, P 7 MESS UND C MUC 7; Jacobs P.S., 1992, TEXT BASED INTELLIGE; KAMBHATLA N., 2004, P 42 ANN M ASS COMP; KIM J, 1995, IEEE T KNOWL DATA EN; Knoblock C.A., 2001, P IJCAI WORKSH AD TE; KO H, 1998, MACHINE LEARNING DAT; KRUPKA G, 1995, P 6 MESS UND C MUC 6; Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9; Kushmerick N., 1997, THESIS U WASHINGTON; Lafferty J., 2001, P 18 INT C MACH LEAR; LAVELLI A, 2004, P AAAI WORKSH AD TEX; LEHNERT W, 1993, P 3 MESS UND C MUC 5; LEHNERT W, 1992, P 3 MESS UND C MUC 4; LEHNERT W, 1991, P 3 MESS UND C MUC 3; LIN D, 1995, P 6 MESS UND C MUC 6; Manning C. D., 1999, FDN STAT NATURAL LAN; Marcus M., 1993, COMPUTATIONAL LINGUI, V19, P313; MCCALLUM A, 2000, P 17 INT C MACH LEAR; MCCALLUM A, 2003, P IJCAI 03 WORKSH LE; McCarthy J.F., 1995, P 14 INT JOINT C ART; MICHALSKI RS, 1993, READINGS KNOWLEDGE A; Miller G. A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; MILLER S, 2000, P 1 M N AM CHAPT ASS; MILLER S, 1998, P 7 MESS UND C MUC 7; Mitkov R., 1998, P 36 ANN M ASS COMP, P869; MOONEY R, 1999, TUT AAAI WORKSH MACH; MORGAN R, 1995, P 6 MESS UND C MUC 6; MUGGLETON S., 1992, INDUCTIVE LOGIC PROG; MUGGLETON S, 1988, P 5 INT C MACH LEARN; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muslea I, 2001, AUTON AGENT MULTI-AG, V4, P93, DOI 10.1023/A:1010022931168; MUSLEA I, 2003, P 3 ANN C AUT AG; Muslea I., 1999, P AAAI WORKSH MACH L; Ng V., 2003, P 2003 C EMP METH NA; PASCA M, 2003, CSLI STUDIES COMPUTA; PESHKIN L, 2003, P 18 INT JOINT C ART; Quinlan J. R., 1993, P EUR C MACH LEARN, P3; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; RADEV D, 2004, 27 ANN INT C RES DEV; RAY S, 2001, P 17 INT JOINT C ART; Riloff E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1044; RILOFF E, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P811; Roth D., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; ROTH D, 2001, P 15 INT C ART INT I; SEKINE S, 1998, P SIG NL SI INF PROC; SEYMORE K, 1999, P 16 AAAI NAT C ART; SKOUNAKIS M, 2003, P 18 INT JOINT C ART; Soderland S., 1995, P 14 INT JOINT C ART, P1314; Soderland S, 1999, MACH LEARN, V34, P233, DOI 10.1023/A:1007562322031; Soderland S., 1997, P 3 INT C KNOWL DISC; Strzalkowski T., 1999, NATURAL LANGUAGE INF; SUN A, 2003, P 1 NSF NIJ S INT SE, P1; TAKEUCHI K, 2002, P 4 C COMP NAT LANG; THOMAS B, 1999, P AAAI WORKSH MACH L; Thompson C.A., 1999, P 16 INT C MACH LEAR, P406; TURMO J, 2002, THESIS TU CATALONIA; TURMO J, 2002, NATURAL LANG ENG SPE, V8, P167; VILAIN M, 1999, INFORM EXTRACTION SC, V1714; WEISCHEDEL R, 1991, P 6 MESS UND C MUC 3; WEISCHEDEL R, 1993, P 6 MESS UND C MUC 5; WEISCHEDEL R, 1995, P 6 MESS UND C MUC 6; WEISCHEDEL R, 1992, P 6 MESS UND C MUC 4; YANGARBER R, 1998, P 7 MESS UND C MUC 5; YANGARBER R, 2003, P 41 AN M ASS COMP L; YANGARBER R, 2000, THEIS NEW YORK U; YANGARBER R, 2000, P ECAI WORKSH MACH L; YANGARBER R., 2000, P 18 INT C COMP LING; YAROWSKY D, 2003, P ACL WORKSH MULT MI; YOUNG S, 1997, CORPUS BASED METHODS; Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205; ZELLE JM, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P748	134	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0360-0300		ACM COMPUT SURV	ACM Comput. Surv.		2006	38	2								10.1145/1132956/1132957		47	Computer Science, Theory & Methods	Computer Science	076TJ	WOS:000239980300002	
S	Barnich, O; Jodogne, S; Van Droogenbroeck, M		BlancTalon, J; Philips, W; Popescu, D; Scheunders, P		Barnich, Olivier; Jodogne, Sebastien; Van Droogenbroeck, Marc			Robust analysis of silhouettes by morphological size distributions	ADVANCED CONCEPTS FOR INTELLIGENT VISION SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Advanced Concepts for Intelligent Vision Systems	SEP 18-21, 2006	Antwerp, BELGIUM	Univ Antwerp, Ghent Univ, Faculty Engn Sci, Philips Res, IEEE Benelux Signal Proc Chapter, Eurasip, Barco, DSP Valley, FWO Res Comm Audiovisual Syst			REAL-TIME TRACKING	We address the topic of real-time analysis and recognition of silhouettes. The method that we propose first produces object features obtained by a new type of morphological operators, which can be seen as an extension of existing granulometric filters, and then insert them into a tailored classification scheme. Intuitively, given a binary segmented image, our operator produces the set of all the largest rectangles that can be wedged inside any connected component of the image. The latter are obtained by a standard background subtraction technique and morphological filtering. To classify connected components into one of the known object categories, the rectangles of a connected component are submitted to a machine learning algorithm called EXtremely RAndomized trees (Extra-trees). The machine learning algorithm is fed with a static database of silhouettes that contains both positive and negative instances. The whole process, including image processing and rectangle classification, is carried out in real-time. Finally we evaluate our approach on one of today's hot topics: the detection of human silhouettes. We discuss experimental results and show that our method is stable and computationally effective. Therefore, we assess that algorithms like ours introduce new ways for the detection of humans in video sequences.	Univ Liege, Dept Elect Elect & Comp Sci, Inst Montefiore, B-4000 Liege, Belgium	Barnich, O (reprint author), Univ Liege, Dept Elect Elect & Comp Sci, Inst Montefiore, B-28, B-4000 Liege, Belgium.						BAGDANOV A, 2002, P INT C PATT REC, V1, P478; Boulgouris NV, 2005, IEEE SIGNAL PROC MAG, V22, P78, DOI 10.1109/MSP.2005.1550191; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; GEURTS P, 2006, IN PRESS MACHINE LEA; Hadwiger H, 1957, VORLESUNGEN UBER INH; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Maree R., 2005, IEEE C COMP VIS PATT, P34; MATHES T, 2005, P BRIT MACH VIS C OX, P849; Mikolajczyk K., 2003, P IEEE C COMP VIS PA, V2, P257; Nene S. A., 1996, COLUMBIA OBJECT IMAG; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Power P. W., 2002, P IM VIS COMP AUCKL; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Serra J., 1982, IMAGE ANAL MATH MORP; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; STAUFFER C, 1999, P IEEE C COMP VIS PA, P264; Van Droogenbroeck M, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P197; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236	21	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-44630-3	LECT NOTES COMPUT SC			2006	4179						734	745				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE67	WOS:000241489100067	
S	Gama, J; Castillo, G		Li, X; Zaiane, OR; Li, ZH		Gama, Joao; Castillo, Gladys			Learning with local drift detection	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Advanced Data Mining and Applications	AUG 14-16, 2006	Xian, PEOPLES R CHINA	Xian Software Pk, Web Informat Syst Engn Soc, IEEE Queensland Sect, Univ Queensland				Most of the work in Machine Learning assume that examples are generated at random according to some stationary probability distribution. In this work we study the problem of learning when the distribution that generates the examples changes over time. We present a method for detection of changes in the probability distribution of examples. The idea behind the drift detection method is to monitor the online error-rate of a learning algorithm looking for significant deviations. The method can be used as a wrapper over any learning algorithm. In most problems, a change affects only some regions of the instance space, not the instance space as a whole. In decision models that fit different functions to regions of the instance space, like Decision Trees and Rule Learners, the method can be used to monitor the error in regions of the instance space, with advantages of fast model adaptation. In this work we present experiments using the method as a wrapper over a decision tree and a linear model, and in each internal-node of a decision tree. The experimental results obtained in controlled experiments using artificial data and a real-world problem show a good performance detecting drift and in adapting the decision model to the new concept.	Univ Porto, LIACC, P-4050 Oporto, Portugal; Univ Porto, Fac Econ, P-4050 Oporto, Portugal; Univ Aveiro, Aveiro, Portugal	Gama, J (reprint author), Univ Porto, LIACC, Rua Ceuta 118-6, P-4050 Oporto, Portugal.	jgama@liacc.up.pt; gladys@mat.ua.pt	Gama, Joao/A-2070-2008				BASSEVILLE M, 1987, DETECTION ABRUPT CHA; Blake C., 1999, UCI REPOSITORY MACHI; DAWID AP, 1984, J ROY STAT SOC A STA, V147, P278, DOI 10.2307/2981683; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347107; FAN W, 2004, P 10 INT C KNOWL DIS; Gama J, 2006, INTELL DATA ANAL, V10, P23; Gama J., 2005, P 2005 ACM S APPL CO, P573, DOI 10.1145/1066677.1066809; HARRIES M., 1999, SPLICE 2 COMP EVALUA; Harries MB, 1998, MACH LEARN, V32, P101, DOI 10.1023/A:1007420529897; Hulten Geoff, 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; KIFER D, 2004, VLDB 04 P 30 INT C V; Klinkenberg R., 2004, INTELLIGENT DATA ANA; KLINKENBERG R, 1998, LEARNING TEXT CATEGO, P33; Klinkenberg R., 2000, P 17 INT C MACH LEAR, P487; KOLTER J, 2005, MACH LEARN P 22 INT; KOLTER JZ, 2003, P 3 IEEE INT C DAT M, P123; Koychev I., 2000, P ECAI 2000 WORKSH C, P101; KOYCHEV I, 2001, P MACH LEARN US MOD; LANQUILLON C, 2001, THESIS U MADGDEBURG; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; Mitchell T, 1997, MACHINE LEARNING; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280	23	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37025-0	LECT NOTES ARTIF INT			2006	4093						42	55				14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEY19	WOS:000240088200004	
S	Wang, SQ; Wei, JM; You, JP; Liu, DY		Li, X; Zaiane, OR; Li, ZH		Wang, Shuqin; Wei, Jinmao; You, Junping; Liu, Dayou			ComEnVprs: A novel approach for inducing decision tree classifiers	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Advanced Data Mining and Applications	AUG 14-16, 2006	Xian, PEOPLES R CHINA	Xian Software Pk, Web Informat Syst Engn Soc, IEEE Queensland Sect, Univ Queensland			ROUGH SETS	This paper presents a new approach for inducing decision trees by combining information entropy criteria with VPRS based methods. From the angle of rough set theory, when inducing decision trees, entropy based methods emphasize the effect of class distribution. Whereas the rough set based approaches emphasize the effect of certainty. The presented approach takes the advantages of both criteria for inducing decision trees. Comparisons between the presented approach and the fundamental information entropy based method on some data sets from the UCI Machine Learning Repository are also reported.	NE Normal Univ, Sch Math & Stat, Changchun 130024, Peoples R China; NE Normal Univ, Inst Computat Intelligence, Changchun 130024, Peoples R China; Jilin Univ, Open Symbol Comp & Knowledge Engn Lab State Educ, Jilin 130024, Peoples R China	Wang, SQ (reprint author), NE Normal Univ, Sch Math & Stat, Changchun 130024, Peoples R China.	wangsq562@nenu.edu.cn; weijm374@nenu.edu.cn					Berzal F, 2003, DATA KNOWL ENG, V44, P31, DOI 10.1016/S0169-023X(02)00062-9; Breiman L, 1984, CLASSIFICATION REGRE; CHEN SC, 2004, IEEE INT C MULT EXP; Cheng J., 1997, P 6 ACM INT C INF KN, P325, DOI 10.1145/266714.266920; Fayyad UM, 1993, P 10 INT C MACH LEAR, P112; Gehrke J, 2000, DATA MIN KNOWL DISC, V4, P127, DOI 10.1023/A:1009839829793; Hunt E.B., 1966, EXPT INDUCTION; JERZY W, 2000, COMMUN ACM, V43, P108; Michalski R. S., 1983, MACHINE LEARNING ART; Mingers J., 1989, Machine Learning, V3, DOI 10.1007/BF00116837; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PAWLAK Z, 1988, INT J MAN MACH STUD, V29, P81, DOI 10.1016/S0020-7373(88)80032-4; PAWLAK Z, 1994, EUR J OPER RES, V72, P443, DOI 10.1016/0377-2217(94)90415-4; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; Rastogi R, 2000, DATA MIN KNOWL DISC, V4, P315, DOI 10.1023/A:1009887311454; Wei J.M., 2003, INT J COMPUTATIONAL, V1, P25; ZBIGNIEW W, 1989, P 6 INT WORKSH MACH; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37025-0	LECT NOTES ARTIF INT			2006	4093						126	134				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEY19	WOS:000240088200013	
S	Yan, GH; Li, ZH; Yuan, L		Li, X; Zaiane, OR; Li, ZH		Yan, Guanghui; Li, Zhanhuai; Yuan, Liu			The practical method of fractal dimensionality reduction based on z-ordering technique	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Advanced Data Mining and Applications	AUG 14-16, 2006	Xian, PEOPLES R CHINA	Xian Software Pk, Web Informat Syst Engn Soc, IEEE Queensland Sect, Univ Queensland			SELECTION; ALGORITHM	Feature selection, the process of selecting a feature subset from the original feature set, plays an important role in a wide variety of contexts such as data mining, machine learning, and pattern recognition. Recently, fractal dimension has been exploited to reduce the dimensionality of the data space. FDR(Fractal Dimensionality Reduction) is one of the most famous fractal dimension based feature selection algorithm proposed by Traina in 2000. However, it is inefficient in the high dimensional data space for multiple scanning the dataset. Take advantage of the Z-ordering technique, this paper proposed an optimized FDR, ZBFDR(Z-ordering Based FDR), which can select the feature subset through scanning the dataset once except for preprocessing. The experimental results show that ZBFDR algorithm achieves better performance.	Northwestern Polytech Univ, Dept Comp Sci & Software, Xian 710072, Peoples R China; Lanzhou Jiaotong Univ, Minist Educ, Key Lab Optoelect Technol & Intelligent Control, Lanzhou 730070, Peoples R China	Yan, GH (reprint author), Northwestern Polytech Univ, Dept Comp Sci & Software, Xian 710072, Peoples R China.	yangh@mail.nwpu.edu.cn; yuanl@mail.nwpu.edu.cn; lizhh@nwpu.edu.cn; yuanl@mail.nwpu.edu.cn					AHA DW, 1996, ARTIF INTELL, V5, P199; Baeza-Yates R., 1997, Proceedings of the Sixth International Conference on Information and Knowledge Management. CIKM'97, DOI 10.1145/266714.266719; Bao YB, 2004, LECT NOTES COMPUT SC, V3129, P739; Bellman R., 1961, ADAPTIVE CONTROL PRO; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Camastra F, 2003, PATTERN RECOGN, V36, P2945, DOI 10.1016/S0031-3203(03)00176-6; Chakraborty D., 2004, International Journal of Network Management, V14, DOI 10.1002/nem.512; David BL., 1993, P 4 INT C FDN DAT OR, P69; FALOUTSOS C, 2000, ACM SIGMOD INT C MA, P177; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; KAMEL I, 1994, 20 INT C VER LARG DA, P500; LANGLEY P, 1997, COMPUTATIONAL LEARNI, V4; LIEBOVITCH LS, 1989, PHYS LETT A, V141, P386, DOI 10.1016/0375-9601(89)90854-2; Orenstein J. A., 1984, P 3 ACM SIGACT SIGMO, P181; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; SCHERF M, 1997, FKI22197 TU MUNCH; TRAINA C, 2000, 15 BRAZ DAT S JOAO P, P158; VAFAIE H, 1993, INT C TOLLS AI, P356	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37025-0	LECT NOTES ARTIF INT			2006	4093						542	549				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEY19	WOS:000240088200060	
S	Degemmis, M; Lops, P; Semeraro, G		Li, X; Zaiane, OR; Li, ZH		Degemmis, M.; Lops, P.; Semeraro, G.			Learning semantic user profiles from text	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Advanced Data Mining and Applications	AUG 14-16, 2006	Xian, PEOPLES R CHINA	Xian Software Pk, Web Informat Syst Engn Soc, IEEE Queensland Sect, Univ Queensland		user profiles; text categorization; word sense disambiguation; WordNet		This paper focuses on the problem of choosing a representation of documents that can be suitable to induce more advanced semantic user profiles, in which concepts are used instead of keywords to represent user interests. We propose a method which integrates a word sense disambiguation algorithm based on the WordNet IS-A hierarchy, with two machine learning techniques to induce semantic user profiles, namely a relevance feedback method and a probabilistic one. The document representation proposed, that we called Bag-Of-Synsets improves the classic Bag-Of-Words approach, as shown by an extensive experimental session.	Univ Bari, Dipartimento Informat, I-70125 Bari, Italy	Degemmis, M (reprint author), Univ Bari, Dipartimento Informat, Via E Orabona 4, I-70125 Bari, Italy.	degemmis@di.uniba.it; lops@di.uniba.it; semeraro@di.uniba.it					ASNICAR F, 1997, P 1 INT WORKSH AD SY; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Bloehdorn S., 2004, P 10 ACM SIGKDD INT, P70; DEGEMMIS M, 2005, P 2 EUR WEB MIN FOR; Degemmis M, 2005, LECT NOTES ARTIF INT, V3584, P370; MAGNINI B, 2001, P 8 INT C US MOD, P74; MANNING CD, 1984, FDN STAT NATURAL LAN; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; Miller G. A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; Mitchell T, 1997, MACHINE LEARNING; Orkin M., 1990, VITAL STAT; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Rocchio Jr J. J., 1971, SMART RETRIEVAL SYST, P313; SCOTT S, 1998, COLING ACL WORKSH US, P45; Sebastiani F, 2002, ACM COMPUTING SURVEY, V34; WITTEN IH, 1991, IEEE T INFORM THEORY, V37; YAO YY, 1995, J AM SOC INFORM SCI, V46, P133, DOI 10.1002/(SICI)1097-4571(199503)46:2<133::AID-ASI6>3.0.CO;2-Z	17	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37025-0	LECT NOTES ARTIF INT			2006	4093						661	672				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEY19	WOS:000240088200073	
S	Hardoon, DR; Saunders, C; Szedmak, S; Shawe-Taylor, J		Li, X; Zaiane, OR; Li, ZH		Hardoon, David R.; Saunders, Craig; Szedmak, Sandor; Shawe-Taylor, John			A correlation approach for automatic image annotation	ADVANCED DATA MINING AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Advanced Data Mining and Applications	AUG 14-16, 2006	Xian, PEOPLES R CHINA	Xian Software Pk, Web Informat Syst Engn Soc, IEEE Queensland Sect, Univ Queensland				The automatic annotation of images presents a particularly complex problem for machine learning researchers. In this work we experiment with semantic models and multi-class learning for the automatic annotation of query images. We represent the images using scale invariant transformation descriptors in order to account for similar objects appearing at slightly different scales and transformations. The resulting descriptors are utilised as visual terms for each image. We first aim to annotate query images by retrieving images that are similar to the query image. This approach uses the analogy that similar images would be annotated similarly as well. We then propose an image annotation method that learns a direct mapping from image descriptors to keywords. We compare the semantic based methods of Latent Semantic Indexing and Kernel Canonical Correlation Analysis (KCCA), as well as using a recently proposed vector label based learning method known as Maximum Margin Robot.	Univ Southampton, ISIS Res Grp, Southampton, Hants, England; Univ Helsinki, Dept Comp Sci, SF-00510 Helsinki, Finland	Hardoon, DR (reprint author), Univ Southampton, ISIS Res Grp, Southampton, Hants, England.		Hardoon, David/A-9546-2010				Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; BLEI D, 2003, P 26 INT ASS COMP MA; FYFE C, 2001, INT J NEURAL SYSTEMS; Hardoon D.R., 2006, THESIS U SOUTHAMPTON; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hare J., 2005, P MULT SEM WEB EUR S; HARE JS, 2005, IMAGE VIDEO RETRIEVA; JASON DR, 2005, ADV NEURAL INFORM PR, V19; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790410; MIKOLAJCZYK K, 2003, INT C COMP VIS PATT, P257; Mikolajczyk K., 2002, P EUR C COMP VIS, P128; Mikolajczyk K., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937561; MONAY F, 2003, MULTIMEDIA 03 P 11 A; Pan J., 2004, P 4 INT WORKSH MULT; ROUSU J, 2005, ICML; Salton G., 1983, INTRO MODERN INFORM; Sebe N, 2003, IMAGE VISION COMPUT, V21, P1087, DOI 10.1016/j.imavis.2003.08.012; XING EP, 2005, UNCERTAINTY ARTIFICI	18	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37025-0	LECT NOTES ARTIF INT			2006	4093						681	692				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEY19	WOS:000240088200075	
J	Raman, B; Naderi, JR				Raman, B; Naderi, JR			Computer based pedestrian landscape design using decision tree templates	ADVANCED ENGINEERING INFORMATICS			English	Article						machine learning; decision tree templates; pedestrian landscape design; simulation	BRIDGES	Machine Learning algorithms can act as a valuable analytical tool in design research. In this paper, we demonstrate the application of a decision tree learning algorithm for designing pedestrian landscapes that encourage walking for health. The domain knowledge was captured using intercept surveys that queried responses to cognitive, physical and social attributes that influence pedestrian spatial analysis. Decision trees extracted from the knowledge base were used in the design of pedestrian landscapes, which were tested in a transportation simulator. The observed match between the change in the participants' response to manipulation of physical variables in the simulated world with those predicted by the decision rules indicate the appropriateness of applying decision tree rules as guidelines during the process of pedestrian landscape design and research. (c) 2005 Elsevier Ltd. All rights reserved.	Texas A&M Univ, Dept Comp Sci, College Stn, TX 77840 USA; Texas A&M Univ, Dept Landscape Architecture & Urban Planning, College Stn, TX 77840 USA	Raman, B (reprint author), Texas A&M Univ, Dept Comp Sci, 520 Harvey R Bright Bldg, College Stn, TX 77840 USA.	barani@tamu.edu; jnaderi@tamu.edu					Appleton J., 1975, EXPERIENCE LANDSCAPE; ARCISZEWSKI T, 1991, CONCEPT FORMATION KN, P323; BUHYOFF GJ, 1994, AI APPLICATIONS, V8, P1; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Coyne R.D., 1993, MODELING CREATIVITY, P177; Duffy AHB, 1997, IEEE INTELL SYST APP, V12, P71, DOI 10.1109/64.590079; FORMAN RTT, 1995, LANDSCAPE ECOL, V10, P133, DOI 10.1007/BF00133027; Jacobs A. B., 1993, GREAT STREETS; KAPLAN R, 1985, LANDSCAPE PLAN, V12, P161, DOI 10.1016/0304-3924(85)90058-9; KWEON BS, 2004, 1677221 TEX TRANSP I; LYNCH K, 1960, IMAGES CITY; Maher ML, 1997, IEEE EXPERT, V12, P34, DOI 10.1109/64.585102; Mitchell T, 1997, MACHINE LEARNING; NADERI JR, 2002, ARCHITECTURAL RES CT; NADERI JR, 2002, DESIGN CONSIDERATION; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; REICH Y, 1995, J STRUCT ENG-ASCE, V121, P1090, DOI 10.1061/(ASCE)0733-9445(1995)121:7(1090); REICH Y, 1993, ARTIF INTELL ENG, V8, P165, DOI 10.1016/0954-1810(93)90003-X; Rosenman M, 1999, EVOLUTIONARY DESIGN BY COMPUTERS, P345; Wang WY, 1997, J COMPUT CIVIL ENG, V11, P37, DOI 10.1061/(ASCE)0887-3801(1997)11:1(37)	20	4	4	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1474-0346		ADV ENG INFORM	Adv. Eng. Inform.	JAN	2006	20	1					23	30		10.1016/j.aei.2005.08.002		8	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Computer Science; Engineering	025FC	WOS:000236249700004	
S	Yang, W; Yun, XC; Li, JH		Shen, HT; Li, JB; Li, ML; Ni, J; Wang, W		Yang, W; Yun, XC; Li, JH			An efficient SVM-based method to detect malicious attacks for web servers	ADVANCED WEB AND NETWORK TECHNOLOGIES, AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	8th Asia-Pacific Web Conference and Workshops (APWeb 2006)	JAN 16-18, 2006	Harbin, PEOPLES R CHINA	Natl Nat Sci Fdn China, Australian Res Council Res Network EII, Harbin Inst Technol, Heilongjiang Univ, Hohai Univ, Yellow River Conservat Commiss				In recent years, with the rapid development of network technique and network bandwidth, the network attacking events for web servers such as DOS/PROBE are becoming more and more frequent. In order to detect these types of intrusions in the new network environment more efficiently, this paper applies new machine learning methods to intrusion detection and proposes an efficient algorithm based on vector quantization and support vector machine for intrusion detection (VQ-SVM). The algorithm Firstly reduces the network auditing dataset by using VQ techniques, produces a codebook as the training example set, and then adopts fast training algorithm for SVM to build intrusion detection model on the codebook. The experiment results indicate that the combined algorithm of VQ-SVM can greatly improve the learning and detecting efficiency of the traditional SVM-based intrusion detection model.	Harbin Engn Univ, Informat Secur Res Ctr, Harbin 150001, Peoples R China; Harbin Inst Technol, Comp Network & Informat Secur Technique Res Ctr, Harbin 150001, Peoples R China; Shanghai Jiao Tong Univ, Coll Informat Secur Engn, Shanghai 200030, Peoples R China	Yang, W (reprint author), Harbin Engn Univ, Informat Secur Res Ctr, Harbin 150001, Peoples R China.	yangwu@hrbeu.edu.cn; yxc@hit.edu.cn; lijh888@sjtu.edu.cn					ANDERSON JP, 1995, DETECTION UNUSUAL PR; APN JS, 2000, SIGNAL PROCESS, V7, P1513; Debar H., 1992, Proceedings. 1992 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.92CH3157-5), DOI 10.1109/RISP.1992.213257; ILLGUN K, 1995, IEEE T SOFTWARE ENG, V2, P181; KARLTON S, 2002, P 8 ACM SIGKDD INT C, P386; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Mukkamala S, 2002, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2002.1007774; Platt J.C., 1999, ADV KERNEL METHODS S; Taylor C, 2002, P NEW SEC PAR WORKSH, P89; Vapnik V. N, 1995, NATURE STAT LEARNING; YANG JY, 2003, J NANJING U SCI TECH, V5, P530; Zhang X., 1999, P IEEE NNSP 99, P3	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-31158-0	LECT NOTES COMPUT SC			2006	3842						835	841				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Remote Sensing; Telecommunications	Computer Science; Remote Sensing; Telecommunications	BDV63	WOS:000235659100114	
S	Bosin, A; Dessi, N; Pes, B		Ali, M; Dapoigny, R		Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara			High-dimensional micro-array data classification using minimum description length and domain expert knowledge	ADVANCES IN APPLIED ARTICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	19th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems	JUN 27-30, 2006	Annecy, FRANCE	Univ Savoie, Dept Comp Sci, Int Soc Appl Intelligence, LISTIC/ESIA, AIAA, ACM SIGART, AFIA, CSCSI/SCEIO, ECCAI, ENNS, INNS, JSAI, TAAI, Texas State Univ		data mining & knowledge discovery; machine learning; bioinformatics	PREDICTION; SELECTION; CANCER; DISCOVERY	This paper reports on three machine learning methods, i.e. Naive Bayes (NB), Adaptive Bayesian Network (ABN) and Support Vector Machines (SVM) for multi-target classification on nucro-array datasets involving a large feature space and very few samples. By adopting the Minimum Description Length criterion for ranking and selecting relevant features, experiments are carried out to investigate the accuracy and effectiveness of the above methods in classifying many targets as well as to study the effects of feature selection on the sensitivity of each classifier. The paper also shows how the knowledge of a domain expert makes it possible to decompose the multi-target classification in a set of binary classifications, one for each target, with a substantial improvement in accuracy. The effectiveness of the MDL criterion to decide on particular feature subsets is asserted by empirical results showing that MDL is comparable with entropy based feature selection methodologies reported by earlier works.	Univ Cagliari, Dipartimento Matemat & Informat, I-09124 Cagliari, Italy	Bosin, A (reprint author), Univ Cagliari, Dipartimento Matemat & Informat, Via Osped 72, I-09124 Cagliari, Italy.	andrea.bosin@dsf.unica.it; dessi@unica.it; pes@unica.it					Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BOSIN A, 2005, LEARNING BAYESIAN CL; CHENG G, 1999, P 15 C UNC ART INT S; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HARDIMANN G, 2003, MICROARRAY METHODS A; Keogh E. J., 2002, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V11, DOI 10.1142/S0218213002001052; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Liu Huiqing, 2002, Genome Inform, V13, P51; MUKHERJEE S, 2003, CLASSIFYING MICROARR; VALENTINI G, 2002, ARTIFICIAL INTELLIGE; Vapnik VN, 1998, STAT LEARNING THEORY; YARMUS JS, 2003, ABN FAST GREEDY BAYE; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	19	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35453-0	LECT NOTES COMPUT SC			2006	4031						790	799				10	Computer Science, Artificial Intelligence	Computer Science	BEV62	WOS:000239623800085	
S	Clifton, DA; Bannister, PR; Tarassenko, L		Ali, M; Dapoigny, R		Clifton, David A.; Bannister, Peter R.; Tarassenko, Lionel			Application of an intuitive novelty metric for jet engine condition monitoring	ADVANCES IN APPLIED ARTICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	19th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems	JUN 27-30, 2006	Annecy, FRANCE	Univ Savoie, Dept Comp Sci, Int Soc Appl Intelligence, LISTIC/ESIA, AIAA, ACM SIGART, AFIA, CSCSI/SCEIO, ECCAI, ENNS, INNS, JSAI, TAAI, Texas State Univ		novelty detection; jet engine application; machine learning		Application of novelty detection to a new class of jet engine is considered within this paper, providing a worked example of the steps necessary for constructing a model of normality. Abnormal jet engine vibration signatures are automatically identified with respect to a training set of normal examples. Pre-processing steps suitable for this area of application are investigated. An intuitive metric for assigning novelty scores to patterns is introduced, with benefits for reducing model sensitivity to noise, and in pruning patterns from the model training set.	Univ Oxford, Dept Engn Sci, Oxford, England; Oxford BioSignals Ltd, Oxford OX4 4GA, England	Clifton, DA (reprint author), Univ Oxford, Dept Engn Sci, S Parks Rd, Oxford, England.	davidc@robots.ox.ac.uk; prb@robots.ox.ac.uk; lionel@robots.ox.ac.uk					Bishop C.M., 1995, NEURAL NETWORKS PATT; CLIFTON DA, 2005, CONDITION MONITORING; HAYTON P, 2006, P ROYAL SOC; HAYTON P, 2000, NIPS P; HAYTON P, 2003, QUOTE PROJECT FINAL; LOWE D, 1996, NEURAL COMPUTING APP; Nabney I T, 2002, NETLAB ALGORITHMS PA; NAIRAC A, 1999, INT COMPUTER AIDED E; NAIRAC A, 1997, IEE 5 INT C ART NEUR; Rolls-Royce plc, 2005, JET ENG; SAMMON JW, 1969, IEEE T COMPUTERS; TARASSENKO L, P NCAF NSYN; TARASSENKO L, 1988, GUIDE NEURAL COMPUTI	13	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35453-0	LECT NOTES COMPUT SC			2006	4031						1149	1158				10	Computer Science, Artificial Intelligence	Computer Science	BEV62	WOS:000239623800122	
S	Kang, JH; Ryu, KR; Kim, KH		Ali, M; Dapoigny, R		Kang, Jaeho; Ryu, Kwang Ryel; Kim, Kap Hwan			Determination of storage locations for incoming containers of uncertain weight	ADVANCES IN APPLIED ARTICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	19th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems	JUN 27-30, 2006	Annecy, FRANCE	Univ Savoie, Dept Comp Sci, Int Soc Appl Intelligence, LISTIC/ESIA, AIAA, ACM SIGART, AFIA, CSCSI/SCEIO, ECCAI, ENNS, INNS, JSAI, TAAI, Texas State Univ			YARDS	In container terminals, heavier containers are loaded onto a ship before lighter ones to keep the ship balanced. To achieve efficient loading, terminal operators usually classify incoming export containers into a few weight groups and group containers belonging to the same weight group in the same stack. However, since the weight information available at the time of the container's arrival is only an estimate, a stack often includes containers belonging to different weight groups. This mix of weight groups necessitates extra crane works or container re-handlings during the loading process. This paper employs a simulated annealing algorithm to derive a more effective stacking strategy to determine the storage locations of incoming containers of uncertain weight. It also presents a method of using machine learning to reduce occurrences of re-handling by increasing classification accuracy. Experimental results have shown that the proposed methods effectively reduce the number of re-handlings than the traditional same-weight-group-stacking (SWGS) strategy.	Pusan Natl Univ, Dept Comp Engn, Pusan 609735, South Korea; Pusan Natl Univ, Dept Ind Engn, Pusan 609735, South Korea	Kang, JH (reprint author), Pusan Natl Univ, Dept Comp Engn, 30,Jangjeon Dong, Pusan 609735, South Korea.	jhkang@pusan.ac.kr; krryu@pusan.ac.kr; kapkim@pusan.ac.kr					AARTS EH, 1997, SIMULATED ANNEALING, P91; Castilho B., 1993, TRANSPORTATION RES B, V27, P151; KANG J, 2005, J KOREAN NAVIGATIONS, V29, P573; Kim KH, 1997, COMPUT IND ENG, V32, P701; Kim KH, 2000, EUR J OPER RES, V124, P89, DOI 10.1016/S0377-2217(99)00116-2; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Watanabe I.R., 1991, CONTAINER AGE    MAR, P36; Witten I. H., 2000, DATA MINING PRACTICA	8	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35453-0	LECT NOTES COMPUT SC			2006	4031						1159	1168				10	Computer Science, Artificial Intelligence	Computer Science	BEV62	WOS:000239623800123	
S	Murphey, YL; Abu Masrur, M; Chen, ZH		Ali, M; Dapoigny, R		Murphey, Yi L.; Abu Masrur, M.; Chen, ZhiHang			Fault diagnostics in electric drives using machine learning	ADVANCES IN APPLIED ARTICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	19th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems	JUN 27-30, 2006	Annecy, FRANCE	Univ Savoie, Dept Comp Sci, Int Soc Appl Intelligence, LISTIC/ESIA, AIAA, ACM SIGART, AFIA, CSCSI/SCEIO, ECCAI, ENNS, INNS, JSAI, TAAI, Texas State Univ		intelligent systems; neural networks; machine learning	MOTOR	Electric motor and power electronics based inverter are the major components in industrial and automotive electric drives. In this paper we present a fault diagnostics system developed using machine learning technology for detecting and locating multiple classes of faults in an electric drive. A machine learning algorithm has been developed to automatically select a set of representative operating points in the (torque, speed) domain, which in turn is sent to the simulated electric drive model to generate signals for the training of a diagnostic neural network, "Fault Diagnostic Neural Network" (FDNN). We presented our study on two different neural network systems and show that a well-designed hierarchical neural network system is robust in detecting and locating faults in electric drives.								CROSSMAN J, 2003, IEEE T VEHICULAR, V52, P1076; FENTON W, 2000, IEEE T SYST MAN CYB, V31, P269; GERTLER J, 1995, IEEE T CONTR SYST T, V3, P61; HUANG WM, NEURAL INFORMATION P, P387; Kim K, 2002, IEEE-ASME T MECH, V7, P201; Klima J, 2003, IEE P-ELECT POW APPL, V150, P255, DOI 10.1049/ip-epa:20030122; MASRUR MA, 2005, IN PRESS IEEE T MECH; MASRUR MA, 1995, Patent No. 5469351; Moseler O, 2000, IEEE T IND ELECTRON, V47, P1015, DOI 10.1109/41.873209; MURPHEY YL, 2000, IEEE T VEHICULAR NOV; OU GB, 2004, INT C PATT REC CAMBR	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35453-0	LECT NOTES COMPUT SC			2006	4031						1169	1178				10	Computer Science, Artificial Intelligence	Computer Science	BEV62	WOS:000239623800124	
S	Mukkamala, S; Xu, D; Sung, AH		Ali, M; Dapoigny, R		Mukkamala, Srinivas; Xu, Dennis; Sung, Andrew H.			Intrusion detection based on behavior mining and machine learning techniques	ADVANCES IN APPLIED ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	19th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems	JUN 27-30, 2006	Annecy, FRANCE	Univ Savoie, Dept Comp Sci, Int Soc Appl Intelligence, LISTIC/ESIA, AIAA, ACM SIGART, AFIA, CSCSI/SCEIO, ECCAI, ENNS, INNS, JSAI, TAAI, Texas State Univ				This paper describes results concerning the classification capability of unsupervised and supervised machine learning techniques in detecting intrusions using network audit trails. In this paper we investigate well known machine learning techniques: Frequent Pattern Tree mining (FP-tree), classification and regression tress (CART), multivariate regression splines (MARS) and TreeNet. The best model is chosen based on the classification accuracy (ROC curve analysis). The results show that high classification accuracies can be achieved in a fraction of the time required by well known support vector machines and artificial neural networks. TreeNet performs the best for normal, probe and denial of service attacks (DoS). CART performs the best for user to super user (U2su) and remote to local (R2L).	New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA; Inst Complex Addit Syst & Anal, Socorro, NM 87801 USA	Mukkamala, S (reprint author), New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA.	srinivas@cs.nmt.edu; dennisxu@cs.nmt.edu; sung@cs.nmt.edu					Breiman L., 1986, CLASSIFICATION REGRE; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Fugate M, 2003, INT J PATTERN RECOGN, V17, P441, DOI 10.1142/S0218001403002459; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Hastie T, 2001, ELEMENTS STAT LEARNI; HELLER KA, 2003, P IEEE C DAT MIN WOR; HU W, 2003, INT C MACH LEARN, P168; Kendall K., 1998, THESIS MIT; Lazarevic A, 2003, P 3 SIAM C DAT MIN; Lee W., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382914; MUKKAMALA S, 2005, P INT C AD NAT COMP, P458; Mukkamala S., 2003, J TRANSPORT RES BOAR, P33; Mukkamala S, 2002, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2002.1007774; STOLFO SJ, 1999, COST BASED MODELING; WEBSTER SE, 1998, THESIS MIT	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35453-0	LECT NOTES COMPUT SC			2006	4031						619	628				10	Computer Science, Artificial Intelligence	Computer Science	BEV62	WOS:000239623800067	
S	Flach, PA		Sichman, JS; Coelho, H; Rezende, SO		Flach, Peter A.			Reinventing machine learning with ROC analysis	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA-SBIA 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th Ibero-American Conference on Artificial Intelligence/18th Brazilian Symposium on Artificial Intelligence	OCT 23-27, 2006	Riberiao Preto, BRAZIL	FAPESP, CNPq, CAPES, FINEP					Univ Bristol, Dept Comp Sci, Bristol BS8 1TH, Avon, England	Flach, PA (reprint author), Univ Bristol, Dept Comp Sci, Bristol BS8 1TH, Avon, England.	Peter.Flach@bristol.ac.uk					EGAN JP, 1975, SIGNAL DETECTION THE; Ferri C., 2002, P 19 INT C MACH LEAR, P139; FERRI C, 2005, P 2 WORKSH ROC AN MA; Flach P. A., 2003, P 20 INT C MACH LEAR, P194; FLACH PA, 2005, P 19 INT JOINT C ART, P702; FLACH PA, 2004, MANY FACES ROC ANAL; Furnkranz J., 2003, P 20 INT C MACH LEAR, P202; Furnkranz J, 2005, MACH LEARN, V58, P39, DOI 10.1007/s10994-005-5011-x; GREEN DM, 1966, SIGNAL DETECTION THE; PRATI RC, 2005, P 19 INT JOINT C ART, P823; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; WU S, 2005, ICML 05 WORKSH	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45462-4	LECT NOTES COMPUT SC			2006	4140						4	5				2	Computer Science, Artificial Intelligence	Computer Science	BFI98	WOS:000242128100003	
S	Lee, HD; Monard, MC; Wu, FC		Sichman, JS; Coelho, H; Rezende, SO		Lee, Huei Diana; Monard, Maria Carolina; Wu, Feng Chung			A Fractal dimension based filter algorithm to select features for supervised learning	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA-SBIA 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th Ibero-American Conference on Artificial Intelligence/18th Brazilian Symposium on Artificial Intelligence	OCT 23-27, 2006	Riberiao Preto, BRAZIL	FAPESP, CNPq, CAPES, FINEP				Feature selection plays an important role in machine learning and is often applied as a data pre-processing step. Its objective is to choose a subset from the original set of features that describes a data set, according to some importance criterion, by removing irrelevant and/or redundant features, as they may decrease data quality and reduce the comprehensibility of hypotheses induced by supervised learning algorithms. Most of the state-of-art feature selection algorithms mainly focus on finding relevant features. However, it has been shown that relevance alone is not sufficient to select important features. It is also important to deal with the problem of features redundancy. For the purpose of selecting features and discarding others, it is necessary to measure the features' goodness (importance), and many importance measures have been proposed. This work proposes a filter algorithm that decouples relevance and redundancy analysis, and introduces the use of Fractal Dimension to deal with redundant features. Empirical results on several data sets show that Fractal Dimension is an appropriate criterion to filter out redundant features for supervised learning.	Univ Sao Paulo, LABIC, ICMC, BR-13560970 Sao Carlos, SP, Brazil; W Parana State Univ, UNIOESTE, LABI, BR-85856970 Foz Do Iguacu, PR, Brazil	Lee, HD (reprint author), Univ Sao Paulo, LABIC, ICMC, POB 668, BR-13560970 Sao Carlos, SP, Brazil.	huei@unioeste.br; mcmonard@icmc.usp.br	Monard, Maria/F-4835-2011				Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Faloutsos C., 1994, Proceedings of the Thirteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1994, DOI 10.1145/182591.182593; Hall M., 2000, P 17 INT C MACH LEAR, P359; JOHN G, 1994, P 11 INT C MACH LEAR, P167; Kira K, 1992, P 9 INT C MACH LEARN, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LEE HD, 2005, 264 ICMC USP; LEE HD, 2005, THESIS U SAO PAULO S; Liu H., 1996, P 13 INT C MACH LEAR, P319; Liu H, 1998, FEATURE SELECTION KN; Merz C.J., 1998, UCI REPOSITORY MACHI; Quinlan J.R., 1988, C4 5 PROGRAMS MACHIN; SOUSA EPM, 2002, WORKSH NOT KDD 2002, P26; TRAINA C, 2005, USING FRACTALS DATA, V1, P599; Witten I. H., 2000, DATA MINING PRACTICA; Yu L, 2004, J MACH LEARN RES, V5, P1205	16	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45462-4	LECT NOTES COMPUT SC			2006	4140						278	288				11	Computer Science, Artificial Intelligence	Computer Science	BFI98	WOS:000242128100032	
S	Rueda, L; Herrera, M		Sichman, JS; Coelho, H; Rezende, SO		Rueda, Luis; Herrera, Myriam			A new linear dimensionality reduction technique based on Chernoff distance	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA-SBIA 2006, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	10th Ibero-American Conference on Artificial Intelligence/18th Brazilian Symposium on Artificial Intelligence	OCT 23-27, 2006	Ribeirao Preto, BRAZIL	FAPESP, CNPq, CAPES, FINEP			DISCRIMINANT-ANALYSIS; CLASSIFICATION; CLASSIFIERS; LDA	A new linear dimensionality reduction (LDR) technique for pattern classification and machine learning is presented, which, though linear, aims at maximizing the Chernoff distance in the transformed space. The corresponding two-class criterion, which is maximized via a gradient-based algorithm, is presented and initialization procedures are also discussed. Empirical results of this and traditional LDR approaches combined with two well-known classifiers, linear and quadratic, on synthetic and real-life data show that the proposed criterion outperforms the traditional schemes.	Univ Concepcion, Dept Comp Sci, Concepcion 4030000, Chile; Univ Concepcion, Ctr Biotechnol, Concepcion 4030000, Chile; Natl Univ San Juan Cereceto & Meglioli, Dept Informat, RA-5400 San Juan, Argentina; Natl Univ San Juan Cereceto & Meglioli, Inst Informat, RA-5400 San Juan, Argentina	Rueda, L (reprint author), Univ Concepcion, Dept Comp Sci, Edmundo Larenas 215, Concepcion 4030000, Chile.	lrueda@inf.udec.cl; mherrera@iinfo.unsj.edu.ar					Aladjem M, 1997, IEEE T PATTERN ANAL, V19, P187, DOI 10.1109/34.574805; Chong EKP, 2001, INTRO OPTIMIZATION; Cooke T, 2002, IEEE T PATTERN ANAL, V24, P268, DOI 10.1109/34.982904; Du Q, 2001, PATTERN RECOGN, V34, P361, DOI 10.1016/S0031-3203(99)00215-0; Duda R., 2000, PATTERN CLASSIFICATI; Gao H, 2006, PATTERN RECOGN, V39, P1002, DOI 10.1016/j.patcog.2005.11.016; HERRERA M, 1999, REV SOC ARGENTINA ES, V3, P64; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Lotlikar R, 2000, PATTERN RECOGN, V33, P185, DOI 10.1016/S0031-3203(99)00053-9; Newman D. J., 1998, UCI REPOSITORY MACHI; Rao AV, 1999, IEEE T PATTERN ANAL, V21, P159, DOI 10.1109/34.748824; Raudys S, 1998, NEURAL NETWORKS, V11, P283, DOI 10.1016/S0893-6080(97)00135-4; Rueda L, 2004, PATTERN RECOGN LETT, V25, P49, DOI 10.1016/j.patrec.2003.09.001; Rueda L, 2002, IEEE T PATTERN ANAL, V24, P274, DOI 10.1109/34.982905; RUEDA L, 2006, UNPUB LINEAR DISCRIM	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45462-4	LECT NOTES COMPUT SC			2006	4140						299	308				10	Computer Science, Artificial Intelligence	Computer Science	BFI98	WOS:000242128100034	
S	Freitas, MC; Duarte, JC; Santos, CN; Milidiu, RL; Renteria, RP; Quental, V		Sichman, JS; Coelho, H; Rezende, SO		Freitas, Maria Claudia; Duarte, Julio C.; Santos, Cicero N.; Milidiu, Ruy L.; Renteria, Raul P.; Quental, Violeta			A machine learning approach to the identification of appositives	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA-SBIA 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th Ibero-American Conference on Artificial Intelligence/18th Brazilian Symposium on Artificial Intelligence	OCT 23-27, 2006	Riberiao Preto, BRAZIL	FAPESP, CNPq, CAPES, FINEP				Appositives are structures composed by semantically related noun phrases. In Natural Language Processing, the identification of appositives contributes to the building of semantic lexicons, noun phrase coreference resolution and information extraction from texts. In this paper, we present an appositive identifier for the Portuguese language. We describe experimental results obtained by applying two machine learning techniques: Transformation-based learning (TBL) and Hidden Markov Models (HMM). The results obtained with these two techniques are compared with that of a full syntactic parser, PALAVRAS. The TBL-based system outperformed the other methods. This suggests that a machine learning approach can be beneficial for appositive identification, and also that TBL performs well for this language task.	Pontificia Univ Catolica Rio de Janeiro, Dept Letras, Rio De Janeiro, Brazil; Ctr Tecnol Exercito, Rio De Janeiro, Brazil; Pontificia Univ Catolica Rio de Janeiro, Dept Informat, Rio De Janeiro, Brazil	Freitas, MC (reprint author), Pontificia Univ Catolica Rio de Janeiro, Dept Letras, Rio De Janeiro, Brazil.	claudiaf@let.puc-rio.br; jduarte@ctex.eb.br; nogueira@inf.puc-rio.br; milidiu@inf.puc-rio.br; renteria@inf.puc-rio.br; violetaq@rdc.puc-rio.br					BICK E, 2000, THESIS AARHUS U; Brill E, 1995, COMPUT LINGUIST, V21, P543; CARABALLO S, 1999, AUTOMATIC CONSTRUCTI; Cardie C., 1999, P 1999 JOINT SIGDAT, P82; FREITAS MC, 2005, P 3 TIL 15 C SBC SO; Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102; PHILLIPS W, 2002, P EMNLP; Quirk R., 1985, COMPREHENSIVE GRAMMA; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SANTOS CN, 2005, THESIS IME RIO JANEI; Soon W.M., 2001, MACHINE LEARNING APP	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45462-4	LECT NOTES COMPUT SC			2006	4140						309	318				10	Computer Science, Artificial Intelligence	Computer Science	BFI98	WOS:000242128100035	
S	Paes, A; Revoredo, K; Zaverucha, G; Costa, VS		Sichman, JS; Coelho, H; Rezende, SO		Paes, Aline; Revoredo, Kate; Zaverucha, Gerson; Costa, Vitor Santos			PFORTE: Revising probabilistic FOL theories	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA-SBIA 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th Ibero-American Conference on Artificial Intelligence/18th Brazilian Symposium on Artificial Intelligence	OCT 23-27, 2006	Riberiao Preto, BRAZIL	FAPESP, CNPq, CAPES, FINEP				There has been significant recent progress in the integration of probabilistic reasoning with first order logic representations (SRL). So far, the learning algorithms developed for these models all learn from scratch, assuming an invariant background knowledge. As an alternative, theory revision techniques have been shown to perform well on a variety of machine learning problems. These techniques start from an approximate initial theory and apply modifications in places that performed badly in classification. In this work we describe the first revision system for SRL classification, PFORTE, which addresses two problems: all examples must be classified, and they must be classified well. PFORTE uses a two step-approach. The completeness component uses generalization operators to address failed proofs and the classification component addresses classification problems using generalization and specialization operators. Experimental results show significant benefits from using theory revision techniques compared to learning from scratch.	Univ Fed Rio de Janeiro, Dept Syst Engn & Comp Sci, COPPE, BR-21945970 Rio De Janeiro, Brazil	Paes, A (reprint author), Univ Fed Rio de Janeiro, Dept Syst Engn & Comp Sci, COPPE, POB 68511, BR-21945970 Rio De Janeiro, Brazil.	ampaes@cos.ufrj.br; kate@cos.ufrj.br; gerson@cos.ufrj.br; vitor@cos.ufrj.br	Santos Costa, Vitor/B-2859-2012; INESC-TEC, CRACS/F-7527-2012; FCUP, DCC/F-5042-2012				Baiao F, 2003, LECT NOTES ARTIF INT, V2835, P57; Buntine W., 1991, P 7 C UNC ART INT, P52; Costa V.S., 2003, P 19 C UNC ART INT, P517; Friedman N., 1999, P 16 INT JOINT C ART, P1300; Grossman D., 2004, P 21 INT C MACH LEAR, P361; Haddawy P., 1999, AI Magazine, V20; KERSTING K, 2002, 174 U FREIB; KERSTING K, 2001, LNAI, V2157; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KOLLER D, 1997, P 15 INT JOINT C ART, P1316; Muggleton S, 2002, LECT NOTES ARTIF INT, P198; MURPHY KP, 2001, COMPUTING SCI STAT, P33; Paes A, 2005, LECT NOTES ARTIF INT, V3625, P295; Pearl J., 1988, PROBABILISTIC REASON; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; RAMACHANDRAN S, 1998, P INT C MACH LEARN M, P454; REVOREDO K, 2002, LECT NOTES ARTIF INT, V2583, P223; RICHARDS BL, 1995, MACH LEARN, V19, P95, DOI 10.1007/BF01007461; Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1; Sato T., 1997, P 15 INT JOINT C ART, P1330; Srinivasan A., 2001, ALEPH MANUAL; WOGULIS J, 1993, P IJCAI 93, P1128; Wrobel S, 1996, ADV INDUCTIVE LOGIC, P14	23	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45462-4	LECT NOTES COMPUT SC			2006	4140						441	450				10	Computer Science, Artificial Intelligence	Computer Science	BFI98	WOS:000242128100048	
S	Garat, D		Sichman, JS; Coelho, H; Rezende, SO		Garat, Diego			Shallow parsing based on comma values	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA-SBIA 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th Ibero-American Conference on Artificial Intelligence/18th Brazilian Symposium on Artificial Intelligence	OCT 23-27, 2006	Riberiao Preto, BRAZIL	FAPESP, CNPq, CAPES, FINEP		punctuation; shallow parsing; decision trees; boosting		In the belief that punctuation can aid in the process of sentence structure analysis, our work focuses on a prior assignment of values to commas in Spanish texts. Supervised machine learning techniques are applied for learning commas classifiers, taking as input attributes positional information and part of speech tags. One of these comma classifiers and a rule-based analyzer are combined in order to recognize and label text structures. The prior assignment of values to commas allowed the simplification of recognition rules, with very encouraging results.	Univ Republica, Inst Computac, Fac Ingn, Montevideo 11300, Uruguay	Garat, D (reprint author), Univ Republica, Inst Computac, Fac Ingn, Herrera & Reissig 565, Montevideo 11300, Uruguay.	dgarat@fing.edu.uy					Bayraktar Murat, 1998, International Journal of Corpus Linguistics, V3, P33, DOI 10.1075/ijcl.3.1.03bay; BRISCOE T, 1995, P INT WORKSH PARS TE, P48; Carreras X., 2004, P 4 INT C LANG RES E; JONES B, 1994, 29 CAMBR U; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Van Delden S., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, DOI 10.1142/S0218213004001636; WHITE M, 1995, P 5 EUR WORKSH NAT L, P107; Wonsever D, 2001, LECT NOTES COMPUT SC, V2004, P509; *REAL AC ESP, 2005, DICC PANH DUD	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45462-4	LECT NOTES COMPUT SC			2006	4140						492	501				10	Computer Science, Artificial Intelligence	Computer Science	BFI98	WOS:000242128100053	
S	Sokolova, M; Szpakowicz, S		Lamontagne, L; Marchand, M		Sokolova, Marina; Szpakowicz, Stan			Language patterns in the learning of strategies from negotiation texts	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	19th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	JUN 07-09, 2006	Quebec City, CANADA	Canadian Soc Computat Studies Intelligence, Univ Laval, Dept Comp Sci & Software Engn				The paper shows how to construct language patterns that signal influence strategies. and tactical moves corresponding to such strategies. We apply corpus analysis methods to the extraction of certain multi-word patterns from the text data of electronic negotiations. The patterns thus acquired become features in the task of classifying those texts. A series of machine learning experiments predicts the negotiation outcome from the texts associated with first halves of negotiations. We compare the results with the classification of complete negotiations.	Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada; Polish Acad Sci, Inst Comp Sci, PL-00901 Warsaw, Poland	Sokolova, M (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada.	sokolova@site.uottawa.ca; szpak@site.uottawa.ca					Brett J. M., 2001, NEGOTIATING GLOBALLY; Burrell NA, 1998, PERSUASION ADV METAA, P203; CELLICH C, 2004, GLOBAL BUSINESS NEGO; Cristianini N., 2000, INTRO SUPPORT VECTOR; Duda R., 2000, PATTERN CLASSIFICATI; GABRILOVICH E, 2005, P 19 INT JOINT C ART, P1048; KERSTEN G, 2002, ELECT NEGOTIATIONS M; Kersten G, 2003, CENTRAL EUROPEAN J O, V11, P297; Leech G, 2002, COMMUNICATIVE GRAMMA; Leech G. N., 1983, PRINCIPLES PRAGMATIC; Leech Geoffrey, 2004, MEANING ENGLISH VERB; Mullen T., 2004, P C EMP METH NAT LAN, P412; NASTASE V, 2006, GROUP DECISIONS NEGO, V15; Pang B., 2004, P 42 ANN M ASS COMP, P271, DOI DOI 10.3115/1218955.1218990; Putnam Linda, 1992, COMMUNICATION NEGOTI; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SOKOLOVA M, 2005, P 18 CAN AI SPRING, P145; SOKOLOVA M, 2005, P REC ADV NAT LANG P, P518; Strobel M., 2000, Proceedings of the 8th European Conference on Information Systems; Sudo K., 2003, P 41 ANN M ASS COMP, P224; Summers D., 2003, LONGMAN DICT CONT EN; Thompson L., 2005, MIND HEART NEGOTIATO; TOHKURA Y, 2004, 18 INT C AC KYOT JAP; VIDRASCU L, 2005, P 9 EUR C SPEECH COM; Witten I. H., 2005, DATA MINING	25	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34628-7	LECT NOTES ARTIF INT			2006	4013						288	299				12	Computer Science, Artificial Intelligence	Computer Science	BEV24	WOS:000239589600025	
S	Caropreso, MF; Matwin, S		Lamontagne, L; Marchand, M		Caropreso, Maria Fernanda; Matwin, Stan			Beyond the bag of words: A text representation for sentence selection	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	19th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	JUN 07-09, 2006	Quebec City, CANADA	Canadian Soc Computat Studies Intelligence, Univ Laval, Dept Comp Sci & Software Engn				Sentence selection shares some but not all the characteristics of Automatic Text Categorization. Therefore some but not all the same techniques should be used. In this paper we study a syntactic and semantic enriched text representation for the sentence selection task in a genomics corpus. We show that using technical dictionaries and syntactic relations is beneficial for our problem when using state of the art machine learning algorithms. Furthermore, the syntactic relations can be used by a first order rule learner to obtain even better performance.	Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada; Polish Acad Sci, Inst Comp Sci, PL-00901 Warsaw, Poland	Caropreso, MF (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.	caropres@site.uottawa.ca; stan@site.uottawa.ca					Caropreso MF, 2001, TEXT DATABASES AND DOCUMENT MANAGEMENT: THEORY AND PRACTICE, P78; Cohen WW, 1999, ACM T INFORM SYST, V17, P141, DOI 10.1145/306686.306688; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; FAGAN J, 1987, THESIS CORNELL U ITH; Fillmore Charles J., 1968, UNIVERSALS LINGUIST, P1; FURNKRANZ J, 1998, P 1 AAAI WORKSH LEAR, V5; FURNKRANZ J, 1998, TR9830 OEST FORSCH A; FURNKRANZ J, INDUCTIVE LOGIC PROG; GOADRICH M, 2004, P 14 INT C IND LOG P; HACHEY B, 2005, P 2005 ACM S APPL CO; Jacquemin C, 1996, INFORM PROCESS MANAG, V32, P445, DOI 10.1016/0306-4573(95)00078-X; KRAMER S, 1999, THESIS VIENNA U TECH; Lewis D. D., 1992, THESIS U MASSACHUSET; Lewis David D., 1990, P 13 ANN INT ACM SIG, P385, DOI 10.1145/96749.98244; LEWIS K, 1992, CAREER DEV EXCEPTION, V15, P37; MAAREK Y, 1994, LANDMARK CONTRIBUTIO; MITRA M, 1997, 5 RIAO C COMP ASS IN, P200; Mladenic Dunja, 1998, P ERK 98 7 EL COMP S, P145; NEDELLEC C, 2001, LECT NOTES ARTIF INT, V2167, P326; OULD M, 2003, INFORM LEANALYSE TRA; OULD M, 2005, THESIS U PARIS SUD F; RAY S, P 17 INT JOINT C ART; SCOTT S, 1999, P ICML 99 16 INT C M; SIOLAS G, 2003, THESIS U PARIS; Sleator D, 1991, CMUCS91196; SRINIVASAN A, 1993, ALEPH MANUAL; Temkin JM, 2003, BIOINFORMATICS, V19, P2046, DOI 10.1093/bioinformatics/btg279; Witten I. H., 2005, DATA MINING PRACTICA; ZELIKOVITZ S, 2001, P CIKM 01 10 ACM INT	29	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34628-7	LECT NOTES ARTIF INT			2006	4013						324	335				12	Computer Science, Artificial Intelligence	Computer Science	BEV24	WOS:000239589600028	
S	Aimeur, E; Brassard, G; Gambs, S		Lamontagne, L; Marchand, M		Aimeur, Esma; Brassard, Gilles; Gambs, Sebastien			Machine Learning in a quantum world	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	19th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	JUN 07-09, 2006	Quebec City, CANADA	Canadian Soc Computat Studies Intelligence, Univ Laval, Dept Comp Sci & Software Engn				Quantum Information Processing (QIP) performs wonders in a world that obeys the laws of quantum mechanics, whereas Machine Learning (ML) is generally assumed to be done in a classical world. We initiate an investigation of the encounter of ML with QIP by defining and studying novel learning tasks that correspond to Machine Learning in a world in which the information is fundamentally quantum mechanical. We shall see that this paradigm shift has a profound impact on the learning process and that our classical intuition is often challenged.	Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Aimeur, E (reprint author), Univ Montreal, Dept Informat & Rech Operat, CP 6128, Montreal, PQ H3C 3J7, Canada.	aimeur@iro.umontreal.ca; brassard@iro.umontreal.ca; gambsseb@iro.umontreal.ca					Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; Barenco A, 1997, SIAM J COMPUT, V26, P1541, DOI 10.1137/S0097539796302452; Bennett C. H., 1984, P IEEE INT C COMP SY, P175; Buhrman H, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.167902; CHIRIBELLA G, 2004, PHYS REV A, V70, DOI ARTN 061205; Chuang I. L., 2000, QUANTUM COMPUTATION; Ezhov A.A., 2003, INTRO QUANTUM NEURAL; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Grover LK, 1997, PHYS REV LETT, V79, P325, DOI 10.1103/PhysRevLett.79.325; Hayashi A, 2005, PHYS REV A, V72, DOI 10.1103/PhysRevA.72.032325; Helstrom C. W., 1976, QUANTUM DETECTION ES; Herzog U, 2005, PHYS REV A, V71, DOI 10.1103/PhysRevA.71.050301; Holevo A. S., 1973, PROBL INF T, V9, P177; HORN D, 2001, P ADV NEUR INF P SYS, P769; PERES A, 1991, PHYS REV LETT, V66, P1119, DOI 10.1103/PhysRevLett.66.1119; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sasaki M, 2002, PHYS REV A, V66, DOI 10.1103/PhysRevA.66.022303; SEN P, 2006, IN PRESS P 21 ANN IE; SERVEDIO R, 2001, P 28 EATCS INT C AUT, P1065; Servedio RA, 2004, SIAM J COMPUT, V33, P1067, DOI 10.1137/S0097539704412910; Shor PW, 1997, SIAM J COMPUT, V26, P1484, DOI 10.1137/S0097539795293172; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WOOTTERS WK, 1982, NATURE, V299, P802, DOI 10.1038/299802a0; ZIMAN M, 2005, PHYS REV A, V71, DOI UNSP 022106	24	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34628-7	LECT NOTES ARTIF INT			2006	4013						431	442				12	Computer Science, Artificial Intelligence	Computer Science	BEV24	WOS:000239589600037	
S	Kotsiantis, SB; Kanellopoulos, D; Pintelas, PE		Antoniou, G; Potamias, G; Spyropoulos, C; Plexousakis, D		Kotsiantis, SB; Kanellopoulos, D; Pintelas, PE			Local additive regression of decision stumps	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th Helenic Conference on Artifical Intelligence	MAY 18-20, 2006	Heraklion, GREECE	EETN	Univ Crete		LEARNING ALGORITHMS	Parametric models such as linear regression can provide useful, interpretable descriptions of simple structure in data. However, sometimes such simple structure does not extend across an entire data set and may instead be confined more locally within subsets of the data. Nonparametric regression typically involves local averaging. In this study, local averaging estimator is coupled with a machine learning technique - boosting. In more detail, we propose a technique of local boosting of decision stumps. We performed a comparison with other well known methods and ensembles, on standard benchmark datasets and the performance of the proposed technique was greater in most cases.	Univ Patras, Dept Math, Educat Software Dev Lab, GR-26110 Patras, Greece	Kotsiantis, SB (reprint author), Univ Patras, Dept Math, Educat Software Dev Lab, GR-26110 Patras, Greece.	sotos@math.upatras.gr; dkanellop@teipat.gr; pintelas@math.upatras.gr	kotsiantis, sotiris/C-5640-2009	kotsiantis, sotiris/0000-0002-2247-3082			Aha D.W., 1997, LAZY LEARNING; Atkeson CG, 1997, ARTIF INTELL REV, V11, P75, DOI 10.1023/A:1006511328852; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Blake CL, UCI REPOSITORY MACHI; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COHEN S, 2001, 2 INT WORKSH MCS, P349; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Duffy N, 2002, MACH LEARN, V47, P153, DOI 10.1023/A:1013685603443; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Iba W., 1992, P 9 INT C MACH LEARN, P233; JOHN C, 1995, P 12 INT C ML, P108; Kleinberg EM, 2000, LECT NOTES COMPUT SC, V1857, P67; Kohavi R., 1995, P 8 EUR C MACH LEARN, P174; Loader C, 1999, LOCAL REGRESSION LIK; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Pfahringer B., 2003, P C UNC ART INT, P249; VAPNIK VN, 1998, STAT LEARNING THEORY, pCH2; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten I. H., 2000, DATA MINING PRACTICA	22	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34117-X	LECT NOTES COMPUT SC			2006	3955						148	157				10	Computer Science, Artificial Intelligence	Computer Science	BEL89	WOS:000238053100015	
S	Maragoudakis, M; Fakotakis, N		Antoniou, G; Potamias, G; Spyropoulos, C; Plexousakis, D		Maragoudakis, M; Fakotakis, N			Bayesian feature construction	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th Helenic Conference on Artifical Intelligence	MAY 18-20, 2006	Heraklion, GREECE	EETN	Univ Crete			The present piper discusses the issue of enhancing classification performance by means oiber than improving the ability of certain Machine Learning algorithms to construct a precise classification model. On the contrary, we approach this; significant problem from the scope of an extended coding of training data. More specifically, our method attempts to generate more features in order to reveal the hidden aspects of the domain, modeled by the available training examples. We propose a novel feature construction algorithm, based on the ability of Bayesian networks to represent the conditional independence assumptions of a set of features, thus projecting relational attributes which are not always obvious to a classifier when presented in their original format. I he augmented set of features results in a significant increase in terms of classification performance, a fact that is depicted to a plethora of machine learning domains (i.e. data sets from the UCI ML repository and the Artificial Intelligence group) using a variety of classifiers, based on different theoretical backgrounds.	Univ Patras, Artificial Intelligence Grp, GR-26500 Patras, Greece	Maragoudakis, M (reprint author), Univ Patras, Artificial Intelligence Grp, GR-26500 Patras, Greece.	mmarag@wcl.ee.upatras.gr; fakotaki@wcl.ee.upatras.gr					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; JENSEN R, 1996, INTRO BAYESIAN NETWO; John G. H., 1995, P 11 C UNC ART INT, P338; KAVALLIERATOU E, 2000, THESIS; KOHAVI R, 1995, 1 INT C KNOWL DISC D; Lam W., 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Markovitch S, 2002, MACH LEARN, V49, P59, DOI 10.1023/A:1014046307775; Murphy M A, 1994, J Clin Neurosci, V1, P257, DOI 10.1016/0967-5868(94)90066-3; MURPHY PM, 1993, UCI REPOSITORY MACHI; Pearl J., 1988, PROBABILISTIC REASON; QUINLAN J, 1993, ARTIF INTELL, V13, P81; SALZBERG S, 1993, MACH LEARN, P99; TASIKAS A, 2002, THESIS U PATRAS; ZERVAS P, 2004, LREC 2004, P2139	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34117-X	LECT NOTES COMPUT SC			2006	3955						235	245				11	Computer Science, Artificial Intelligence	Computer Science	BEL89	WOS:000238053100023	
S	Moustakis, VS		Antoniou, G; Potamias, G; Spyropoulos, C; Plexousakis, D		Moustakis, VS			Post supervised based learning of feature weight values	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th Helenic Conference on Artifical Intelligence	MAY 18-20, 2006	Heraklion, GREECE	EETN	Univ Crete			The article presents in duta I a model for the assessment of feature weight values in context of inductive machine learning. Weight assessment is done based on learned knowledge and can not be used to assess feature values prior to learning. The model is based on Ackoff's theory of behavioral communication. The model is also us I to assess rule value importance. We present model heuristics and present a simple application based on the "play" vs. "not play" golf application. Implications about decision making modeling are discussed.	FORTH, Inst Comp Sci, Iraklion 71110, Crete, Greece; Tech Univ Crete, Dept Prod & Management Engn, Iraklion 73100, Greece	Moustakis, VS (reprint author), FORTH, Inst Comp Sci, POB 1385, Iraklion 71110, Crete, Greece.	moustaki@cs.forth.gr	Moustakis, Vassilis/C-4484-2011				ACKOFF RL, 1958, MANAGE SCI, V4, P218, DOI 10.1287/mnsc.4.3.218; CARTER C, 1987, IEEE EXPERT      FAL, P71; Fujarewicz K., 2003, International Journal of Applied Mathematics and Computer Science, V13; Gaga L, 1996, APPL ARTIF INTELL, V10, P79, DOI 10.1080/088395196118605; Kahneman D, 1979, TIMS STUDIES MANAGEM, V12, P313; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; MACLIN R, 1993, MACH LEARN, V11, P195, DOI 10.1007/BF00993077; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; STARR MK, 1977, TIMS STUDIES MANAGEM, P5; [Anonymous], 2002, MULTICRITERIA DECISI	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34117-X	LECT NOTES COMPUT SC			2006	3955						279	289				11	Computer Science, Artificial Intelligence	Computer Science	BEL89	WOS:000238053100027	
S	Gkiokas, A; Demiros, I; Piperidis, S		Antoniou, G; Potamias, G; Spyropoulos, C; Plexousakis, D		Gkiokas, A; Demiros, I; Piperidis, S			An analysis of linear weight updating algorithms for text classification	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th Helenic Conference on Artifical Intelligence	MAY 18-20, 2006	Heraklion, GREECE	EETN	Univ Crete			This paper addresses the problem of text classification in high dimensionality spaces by applying linear weight updating classifiers that have been highly studied in the domain of machine learning. Our experimental results are based on the Winnow fan-Lily of algorithms that are simple to implement and efficient in terms of computation time and storage requirements. We applied an exponential multiplication function to weight updates and we experimentally calculated the optimal values of the learning rate and the separating surface parameters. Our results are at the level of the best results that were reported on the family of linear algorithms and perform nearly as well as the top performing methodologies in the literature.	Inst Language & Speech Proc, Athens 15125, Greece; Natl Tech Univ Athens, Athens, Greece	Gkiokas, A (reprint author), Inst Language & Speech Proc, Artemidos 6 & Epidavrou, Athens 15125, Greece.	agkiokas@ilsp.gr; iason@ilsp.gr; spip@ilsp.gr					Aas K, 1999, TEXT CATEGORIZATION; APTE C, 1994, P SIGIR 94; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dagan I, 1997, P 2 C EMP METH NAT L, P55; Kivinen J, 1997, ARTIF INTELL, V97, P325, DOI 10.1016/S0004-3702(97)00039-8; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34117-X	LECT NOTES COMPUT SC			2006	3955						508	511				4	Computer Science, Artificial Intelligence	Computer Science	BEL89	WOS:000238053100054	
S	Kotsiantis, S; Koumanakos, E; Tzelepis, D; Tampakas, V		Antoniou, G; Potamias, G; Spyropoulos, C; Plexousakis, D		Kotsiantis, S; Koumanakos, E; Tzelepis, D; Tampakas, V			Predicting fraudulent financial statements with machine learning techniques	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th Helenic Conference on Artifical Intelligence	MAY 18-20, 2006	Heraklion, GREECE	EETN	Univ Crete			This paper explores the effectiveness of machine learning techniques in detecting firms that issue fraudulent financial statements (FFS) and deals with the identification of factors associated to FFS. To this end, a number of experiments have been conducted using representative learning algorithms, which were trained using a data set of 164 fraud and non-fraud Greek firms in the recent period 2001-2002. This study indicates that a decision tree can be successfully used in the identification of FFS and underline the importance of financial ratios.	Technol Educ Inst Patras, Dept Accounting, Patras, Greece	Kotsiantis, S (reprint author), Technol Educ Inst Patras, Dept Accounting, Patras, Greece.	sotos@math.upatras.gr; koumanak@upatras.gr; tzelepis@upatras.gr; tarnpakas@teipat.gr	kotsiantis, sotiris/C-5640-2009	kotsiantis, sotiris/0000-0002-2247-3082			Aha D.W., 1997, LAZY LEARNING; ALBRECHT C, 2001, J FORENSIC ACCOUNTIN, V2, P1; ANSAH SO, 2002, MANAGERIAL AUDITING, V17, P192; BELL T, 2000, AUDITING-J PRACT TH, V9, P169; Calderon T.G., 2002, INT J ACCOUNTING INF, V3, P203, DOI DOI 10.1016/S1467-0895(02)00068-4; Coderre G.D., 1999, FRAUD DETECTION USIN; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Fanning K. M., 1998, International Journal of Intelligent Systems in Accounting, Finance and Management, V7, DOI 10.1002/(SICI)1099-1174(199803)7:1<21::AID-ISAF138>3.3.CO;2-B; Green BP, 1997, AUDITING-J PRACT TH, V16, P14; Jensen F., 1996, INTRO BAYESIAN NETWO; KIRKOS S, 2005, P 2 INT C ENT SYST A, P310; Mitchell T, 1997, MACHINE LEARNING; Nieschwietz R. J., 2000, J ACCOUNTING LIT, V19, P190; Platt J.C., 1999, ADV NEURAL INFORM PR, V11; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Sikonja M.R., 1997, P 14 INT C ICML 97, P296; Spathis C., 2002, EUROPEAN ACCOUNTING, V11, P509, DOI 10.1080/0963818022000000966; Spathis C.T., 2002, MANAGERIAL AUDITING, V17, P179, DOI 10.1108/02686900210424321; Witten I. H., 2000, DATA MINING PRACTICA	19	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34117-X	LECT NOTES COMPUT SC			2006	3955						538	542				5	Computer Science, Artificial Intelligence	Computer Science	BEL89	WOS:000238053100061	
S	Mitrokotsa, A; Douligeris, C		Antoniou, G; Potamias, G; Spyropoulos, C; Plexousakis, D		Mitrokotsa, A; Douligeris, C			Intrusion detection using Emergent Self-Organizing Maps	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th Helenic Conference on Artifical Intelligence	MAY 18-20, 2006	Heraklion, GREECE	EETN	Univ Crete			In this paper, we analyze the potential of using Emergent Self-Organizing Maps (ESOMs) based on Kohonen Self -Organizing maps in order to detect intrusive behaviours. The)proposed approach combines machine learning and information visualization techniques to analyze network traffic and is based on classifying "normal" versus "abnormal" traffic. The results are promising as they show the. ability of eSOMs to classify normal against abnormal behaviour regarding false alarms and detection probabilities.	Univ Piraeus, Dept Informat Cs, Piraeus 18534, Greece	Mitrokotsa, A (reprint author), Univ Piraeus, Dept Informat Cs, 80 Karaoli & Dimitriou Str, Piraeus 18534, Greece.	mitrokat@unipi.gr; cdculig@unipi.gr					Haykin S, NEURAL NETWORKS COMP; MUKKAMALA S, 2003, INT J DIGITAL EVIDEN, P4; Ultsch A, 1999, KOHONEN MAPS, P33, DOI 10.1016/B978-044450270-4/50003-6; Ultsch A., 2003, P WORKSH SELF ORG MA, P225; 2002, 3 INT KNOWL DISC DAT	5	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34117-X	LECT NOTES COMPUT SC			2006	3955						559	562				4	Computer Science, Artificial Intelligence	Computer Science	BEL89	WOS:000238053100066	
S	Papachristos, E; Tselios, N; Avouris, N		Antoniou, G; Potamias, G; Spyropoulos, C; Plexousakis, D		Papachristos, E; Tselios, N; Avouris, N			Modeling perceived value of color in web sites	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th Helenic Conference on Artifical Intelligence	MAY 18-20, 2006	Heraklion, GREECE	EETN	Univ Crete		EMOTIONAL DIMENSIONS	Color plays an important role in web site design. The selection of effective chromatic combinations and the relation of color to the perceived aesthetic and emotional value, of a web site is the focus of this paper. The subject of the reported research has been to define a model through which to be able to associate color combinations with specific desirable emotional and aesthetic values. The presented approach involves application of machine learning techniques on a rich data set collected during a number of empirical studies.	Univ Patras, Human Comp Interact Grp, Dept Elect & Comp Engn, GR-26500 Patras, Greece	Papachristos, E (reprint author), Univ Patras, Human Comp Interact Grp, Dept Elect & Comp Engn, GR-26500 Patras, Greece.	epap@ee.upatras.gr; nitse@ee.upatras.gr; avouris@upatras.gr					Danielson D.R., 2003, IT SOC, V1, P131; Kim J, 2003, INT J HUM-COMPUT ST, V59, P899, DOI 10.1016/j.ijhcs.2003.06.002; Lavie T, 2004, INT J HUM-COMPUT ST, V60, P269, DOI 10.1016/j.ijhcs.2003.09.002; Papachristos E, 2005, LECT NOTES COMPUT SC, V3585, P1075; Pirolli P, 1999, PSYCHOL REV, V106, P643, DOI 10.1037/0033-295X.106.4.643; WANG P, 2001, P 2001 HUM COMP INT, V1, P183	6	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34117-X	LECT NOTES COMPUT SC			2006	3955						567	570				4	Computer Science, Artificial Intelligence	Computer Science	BEL89	WOS:000238053100068	
S	McDonnell, N; Cunningham, P		RothBerghofer, TR; Goker, MH; Guvenir, HA		McDonnell, Neil; Cunningham, Padraig			A knowledge-light approach to regression using case-based reasoning	ADVANCES IN CASE-BASED REASONING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th European Conference on Case-Based Reasoning	SEP 04-07, 2006	Fethiye, TURKEY	DaimlerChrysler, DFKI GmbH, Empolis, Kaidara Software, Microsoft, PricewaterhouseCoopers				Most CBR systems in operation today are 'retrieval-only' in that they do not adapt the solutions of retrieved cases. Adaptation is, in general, a difficult problem that often requires the acquisition and maintenance of a large body of explicit domain knowledge. For certain machine-learning tasks, however, adaptation can be performed successfully using only knowledge contained within the case base itself. One such task is regression (i.e. predicting the value of a numeric variable). This paper presents a knowledge-light regression algorithm in which the knowledge required to solve a query is generated from the differences between pairs of stored cases. Experiments show that this technique performs well relative to standard algorithms on a range of datasets.	Univ Dublin Trinity Coll, Dept Comp Sci, Dublin 2, Ireland	McDonnell, N (reprint author), Univ Dublin Trinity Coll, Dept Comp Sci, Dublin 2, Ireland.	neil.mcdonnell@cs.tcd.ie; padraig.cunningham@cs.tcd.ie					AAMODT A, 1994, AI COMMUN, V7, P39; Atkeson C., 1996, AI REV; CRAW S, 2003, P 3 INT C MACH LEARN, P1; HANNEY K, 1996, P 3 EUR WORKSH CAS B, P179; Hettich S., 1998, UCI REPOSITORY MACHI; Jarmulak J., 2001, P 17 INT JOINT C ART, P1011; LEAKE D, 1995, P 1 INT C CAS BAS RE, P229; MCDONNELL N, 2005, P 25 ANN INT C BCS S, P219; MCSHERRY D, 1998, P 4 EUR WORKSH CAS B, P184; Richter M. M., 1998, LNAI, V1400; Smyth B, 1998, ARTIF INTELL, V102, P249, DOI 10.1016/S0004-3702(98)00059-9; Wilke W., 1997, P 5 GERM WORKSH CAS; WITTEN IH, 2000, DATA MINING PRACTICA, P246	13	2	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-36843-4	LECT NOTES ARTIF INT			2006	4106						91	105				15	Computer Science, Artificial Intelligence	Computer Science	BFB81	WOS:000240904600009	
S	Mendez, JR; Fdez-Riverola, F; Iglesias, EL; Diaz, F; Corchado, JM		RothBerghofer, TR; Goker, MH; Guvenir, HA		Mendez, J. R.; Fdez-Riverola, F.; Iglesias, E. L.; Diaz, F.; Corchado, J. M.			Tracking concept drift at feature selection stage in SpamHunting: An anti-spam instance-based reasoning system	ADVANCES IN CASE-BASED REASONING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th European Conference on Case-Based Reasoning	SEP 04-07, 2006	Fethiye, TURKEY	DaimlerChrysler, DFKI GmbH, Empolis, Kaidara Software, Microsoft, PricewaterhouseCoopers			MATHEMATICAL-THEORY; COMMUNICATION	In this paper we propose a novel feature selection method able to handle concept drift problems in spam filtering domain. The proposed technique is applied to a previous successful instance-based reasoning e-mail filtering system called SpamHunting. Our achieved information criterion is based on several ideas extracted from the well-known information measure introduced by Shannon. We show how results obtained by our previous system in combination with the improved feature selection method outperforms classical machine learning techniques and other well-known lazy learning approaches. In order to evaluate the performance of all the analysed models, we employ two different corpus and six well-known metrics in various scenarios.	Univ Vigo, Escuela Super Ingn Informat, Dept Informat, Orense 32004, Spain; Univ Valladolid, Dept Informat, Escuela Univ Informat, Segovia 40005, Spain; Univ Salamanca, Dept Informat & Automat, E-37008 Salamanca, Spain	Mendez, JR (reprint author), Univ Vigo, Escuela Super Ingn Informat, Dept Informat, Edificio Politecn,Campus Univ As Lagoas S-N, Orense 32004, Spain.	moncho.mendez@uvigo.es; riverola@uvigo.es; eva@uvigo.es; fdiaz@infor.uva.es; corchado@usal.es	Corchado Rodriguez, Juan/D-3229-2013	Corchado Rodriguez, Juan/0000-0002-2829-1829			Androutsopoulos I., 2004, 20042 NCSR DEM; Baeza-Yates R.A., 1999, MODERN INFORM RETRIE; Carreras X., 2001, P 4 INT C REC ADV NA, P58; Cunningham P., 2003, P ICCBR 03 WORKSH LO; Delany S.J., 2004, P 15 IR C ART INT CO, P9; Druker H., 1999, IEEE T NEURAL NETWOR, V10, P1048; FDEZRIVEROLA F, 2006, IN PRESS SPAM HUNTIN; GAMA J, 2002, P 8 IB AM C AI IBERA, P765; GRAHAM P, 2003, P MIT SPAM C; HOVOLD J, 2005, P 2 C EM ANT CEAS; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KOLCZ A, 2001, P ICDM WORKSH TEXT M; LEE H, 2005, P 2 C E MAIL ANT CEA; LENZ M, 1998, LECT NOTES ARTIF INT, V1400, P51; Mendez J.R., 2005, RES COMPUTING SCI, V17, P129; Oard DW, 1997, USER MODEL USER-ADAP, V7, P141, DOI 10.1023/A:1008287121180; OLIVER JJ, 1994, P EUR C MACH LEARN E, P231; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; RIGOUTSOS I, 2004, P 1 C E MAIL ANT CEA; Sahami M., 1998, AAAI WORKSH MAD WISC, P55; Salton G., 1983, INTRO MODERN INFORM; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Scholz M., 2005, P 2 INT WORKSH KNOWL, P53; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHANNON CE, 1948, AT&T TECH J, V27, P623; Syed N., 1999, P 5 ACM SIGKDD INT C, P317, DOI 10.1145/312129.312267; Vapnik V.N., 1999, NATURE STAT LEARNING; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280; WITTEL GL, 2004, P 1 C E MAIL ANT CEA; Yang Yiming, 1997, P 14 INT C MACH LEAR, P412	30	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-36843-4	LECT NOTES ARTIF INT			2006	4106						504	518				15	Computer Science, Artificial Intelligence	Computer Science	BFB81	WOS:000240904600037	
B	Eschrich, SA; Hall, LO	Wang, FY; Liu, D			Eschrich, Steven A.; Hall, Lawrence O.	Wang, FY; Liu, D		Slicing: A Distributed Learning Approach	ADVANCES IN COMPUTATIONAL INTELLIGENCE: THEORY AND APPLICATIONS	Series in Intelligent Control and Intelligent Automation		English	Article; Book Chapter							ALGORITHM	Data mining is an active area of research involving many large-scale machine learning issues. Ever-increasing dataset sizes and ever-larger problems have spurred research into efficient learning methods [4,5,7,32,37,41,45], including the traditional computer science method of divide and conquer. Distributed learning involves multiple learners working in a distributed fashion to solve the same problem. Distributed learning can lead to better scalability and is generally well-suited to the parallel and massively distributed architectures provided by the modern Internet. Slicing, or partitioning and learning, is a new learning algorithm that embodies the principles of distributed learning, not only to simplify a learning problem overall but also to simplify the individual learning tasks. It can be seen as a method in which the training set is partitioned into disjoint regions of feature space. These disjoint regions can be treated as a set of learning tasks that can be run in a distributed environment, without extensive communication. Classification takes place by assigning a test example to the classifier built from the corresponding region of feature space. Both the base learner and the partitioning strategy can be varied in this approach. Thus, slicing can be used as a general meta-learning technique for distributed learning. The slicing algorithm is examined with respect to a series of real-world datasets, including a biologically-motivated problem. Potential difficulties can occur with the slicing algorithm, however, solutions exist within the literature for mitigating the instability that arises when learning from less data. Slicing is demonstrated to be more accurate than using a single classifier, can reduce the individual learning task size and provides a mechanism to distribute the data mining task.	[Eschrich, Steven A.] Univ S Florida, Coll Med, H Lee Moffitt Canc Ctr & Res Inst, Tampa, FL 33612 USA; [Hall, Lawrence O.] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	Eschrich, SA (reprint author), Univ S Florida, Coll Med, H Lee Moffitt Canc Ctr & Res Inst, Tampa, FL 33612 USA.	eschris@moffitt.usf.edu; hall@csee.usf.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bezdek JC, 1991, FUZZY MODELS PATTERN; Blake CL, UCI REPOSITORY MACHI; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331; Chan P., 1995, P 1 INT C KNOWL DISC, P39; Chan P. K., 1996, Proceedings of the Ninth Florida Artificial Intelligence Research Symposium, FLAIRS-96; Chan P. K., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Eschrich S., 2002, P FUZZ INF PROC SOC, P406; Eschrich S., 2002, P WORKSH DAT MIN BIO; Farnstrom F, 2000, SIGKDD EXPLORATIONS, V2, P51; Forman G., 2000, SIGKDD EXPLORATIONS, V2, P34; Gibson D., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3; Hall M., 1998, THESIS WAIKATO U HAM; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Haykin S., 1999, NEURAL NETWORKS COMP; Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Hulten G., 2001, P 18 INT C MACH LEAR, P106; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jolliffe I. T., 1986, PRINCIPLE COMPONENT; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kohavi R., 1995, THESIS STANFORD U; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; Krishnapuram R, 1996, IEEE T FUZZY SYST, V4, P385, DOI 10.1109/91.531779; Likas A., 2000, P INNS IEEE INT JOIN, V4, P238; Liu H., 2001, INSTANCE SELECTION C; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Mitchell T, 1997, MACHINE LEARNING; Moerland P., 1999, P ICANN, V2, P838; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Moore A, 1998, J ARTIF INTELL RES, V8, P67; Ng R.T., 1994, P 20 INT C VER LARG, P144; Oates T., 1997, P 14 INT C MACH LEAR, P254; Powell MJD, 1987, ALGORITHMS APPROXIMA, P143; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Quinlan J., 1992, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; Shafer J., 1996, P 22 VLDB C MUMB BOM, P1; Tantrum J., 2002, P 8 ACM SIGKDD INT C, P183; Witten I. H., 1999, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; Zhang T., 1996, SIGMOD REC, V25, P103	51	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		978-981-277-392-0	SER INT CONTR INTELL			2006	5						55	97				43	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BZF03	WOS:000301297300004	
B	Tao, Q; Wang, J	Wang, FY; Liu, D			Tao, Qing; Wang, Jue	Wang, FY; Liu, D		Marginal Learning Algorithms in Statistical Machine Learning	ADVANCES IN COMPUTATIONAL INTELLIGENCE: THEORY AND APPLICATIONS	Series in Intelligent Control and Intelligent Automation		English	Article; Book Chapter							SUPPORT VECTOR MACHINES; COMPONENT ANALYSIS	It is now commonly known that the margin-driven algorithms play a crucial role in statistical machine learning. In this chapter, we summarize our investigation on margin methods for both supervised and unsupervised learning problems. As for supervised learning, we first describe the nature of SVMs (support vector machines) in terms of margin-based generalization bound. Based on this nature, a complete framework of posterior probability support vector machines (PPSVMs) is proposed for weighted training samples using modified concepts of risk, linear separability, margin and optimal hyperplane. Within this framework, a new optimization problem for unbalanced classification problems is formulated and a new concept of support vectors is established. Furthermore, a soft PPSVM with an interpretable parameter nu is obtained which is similar to the nu-SVM developed by Scholkopf et al., and an empirical method for determining the posterior probability is proposed as a new approach to determine nu. The main advantage of a PPSVM classifier lies in that fact that it is closer to the Bayes optimal without knowing the distributions. To validate the proposed method, two synthetic classification examples are used to illustrate the logical correctness of PPSVMs and their relationship to regular SVMs and Bayesian methods. Compared with fuzzy support vector machines (FSVMs), the proposed PPSVM is a natural and analytical extension of regular SVMs based on the statistical learning theory. As for supervised learning, to extend the margin idea to unsupervised learning problems and establish a universal framework for one-class, clustering and PCA (principal component analysis) problems, an unsupervised learning problem with predefined threshold eta is formally described and the intuitive margin is introduced. Then, one-class, clustering and PCA are formulated as three specific eta-unsupervised learning problems. By defining a specific hypothesis space in eta-one-class problems, the significant minimal sphere algorithm for regular one-class problems is proved to be a maximum margin algorithm. Furthermore, some new one-class, clustering and PCA marginal algorithms can be achieved in different hypothesis spaces. Since the nature in SVM is employed successfully, the proposed algorithms have robustness, flexibility and high performance. To verify our formulation, some experiments are conducted. They demonstrate that the proposed framework is not only of theoretical interest, but they also have potentials in the family of practical unsupervised learning techniques.	[Tao, Qing; Wang, Jue] Chinese Acad Sci, Lab Complex Syst & Intelligence Sci, Inst Automat, Beijing 100080, Peoples R China; [Tao, Qing] Univ Missouri, Dept Elect & Comp Engn, Rolla, MO 65409 USA	Tao, Q (reprint author), Chinese Acad Sci, Lab Complex Syst & Intelligence Sci, Inst Automat, Beijing 100080, Peoples R China.	qing.tao@mail.ia.ac.cn; Jue.wang@mail.ia.ac.cn					Boyd S., 2003, LECT NOTES STANFORD; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Camastra F, 2005, IEEE T PATTERN ANAL, V27, P801, DOI 10.1109/TPAMI.2005.88; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; Duda R. O., 2001, PATTERN CLASSIFICATI; Elzinga J., 1972, MANAGE SCI, V19, P96; Fletcher R., 1987, PRACTICAL METHODS OP; Garter B., LECT NOTES COMPUTER, V1643, P325; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Higuchi I, 2004, J MACH LEARN RES, V5, P453; Horn D., 2001, J MACHINE LEARNING R, V2, P135; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Kegl B., 1999, THESIS CONCORDIA U C; Kinderlerer D, 1980, INTRO VARIATIONAL IN; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432; Lin Y., 2000, SUPPORT VECTOR MACHI; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Mangasarian OL, 1999, OPER RES LETT, V24, P15, DOI 10.1016/S0167-6377(98)00049-2; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Overton M., 1991, SIAM J OPTIMIZATION; Platt J., 1999, ADV LARGE MARGIN CLA; Ratsch G., 2001, THESIS U POSDAM; Ratsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211; Schapire RE, 1998, ANN STAT, V26, P1651; Schawe-Taylor J., 2002, IEEE T INFORM THEORY, V48, P2721; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2000, NEURAL COMPUT, V12, P1083; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Smola AJ, 2001, J MACH LEARN RES, V1, P179, DOI 10.1162/15324430152748227; Sollich P, 2002, MACH LEARN, V46, P21, DOI 10.1023/A:1012489924661; Suykens JAK, 2003, IEEE T NEURAL NETWOR, V14, P447, DOI 10.1109/TNN.2003.809414; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tao Q., 2005, LECT NOTES COMPUTER, V3495; Tao Q, 2005, IEEE T NEURAL NETWOR, V16, P1561, DOI 10.1109/tnn.2005.857955; Tao Q., 2004, LEARNING ROBUST FLEX; Tao Q., 2004, NEURAL PROCESS LETT, V20, P139, DOI 10.1007/s11063-004-1640-5; Tao Q, 2005, PATTERN RECOGN, V38, P1071, DOI 10.1016/j.patcog.2004.10.010; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY	48	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		978-981-277-392-0	SER INT CONTR INTELL			2006	5						99	143				45	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BZF03	WOS:000301297300005	
S	Orfila, A; Carbo, J; Ribagorda, A		Perner, P		Orfila, Agustin; Carbo, Javier; Ribagorda, Arturo			Effectiveness evaluation of data mining based IDS	ADVANCES IN DATA MINING: APPLICATIONS IN MEDICINE, WEB MINING, MARKETING, IMAGE AND SIGNAL MINING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th Industrial Conference on Data Mining (ICDM 2006)	JUL 14-15, 2006	Leipzig, GERMANY				INTRUSION DETECTION	Data mining has been widely applied to the problem of Intrusion Detection in computer networks. However, the misconception of the underlying problem has led to out of context results. This paper shows that factors such as the probability of intrusion and the costs of responding to detected intrusions must be taken into account in order to compare the effectiveness of machine learning algorithms over the intrusion detection domain. Furthermore, we show the advantages of combining different detection techniques. Results regarding the well known 1999 KDD dataset are shown.	Univ Carlos III Madrid, Dept Comp Sci, Leganes 28911, Spain	Orfila, A (reprint author), Univ Carlos III Madrid, Dept Comp Sci, Leganes 28911, Spain.	adiaz@inf.uc3m.es; jcarbo@inf.uc3m.es; arturo@inf.uc3m.es					Athanasiades N., 2003, Proceedings First IEEE International Workshop on Information Assurance. IWIA 2003; Axelsson S., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/357830.357849; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; ELKAN C, 1999, RESULTS KDD 99 CLASS; Gaffney JE, 2001, P IEEE S SECUR PRIV, P50, DOI 10.1109/SECPRI.2001.924287; GIACINTO G, ALARM CLUSTERING INT, P184; Giacinto G, 2003, PATTERN RECOGN LETT, V24, P1795, DOI 10.1016/S0167-8655(03)00004-7; KATZ RW, 1997, EC VALUE WEATHER CLI; Laskov P, 2005, LECT NOTES COMPUT SC, V3617, P50; Lee W., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382914; Lippmann R, 2000, P DARPA INF SURV C E; Lippmann R, 2000, COMPUT NETW, V34, P579, DOI 10.1016/S1389-1286(00)00139-0; Mahoney MV, 2003, LECT NOTES COMPUT SC, V2820, P220; MALOOF MA, 2005, MACHINE LEARNING DAT; McHugh J., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/382912.382923; MELL P, 2003, 7007 NAT I STAND TEC; ORFILA A, 2005, INT J COMPUTER SCI A, V2, P1; ORFILA A, 2003, P 12 IEEE INT C FUZZ, V2, P1237; PERNER P, 2005, LECT NOTES COMPUTER, V3587; Sabhnani M, 2003, SAM'03: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SECURITY AND MANAGEMENT, VOLS 1 AND 2, P310; SEN AK, 1971, REV ECON STUD, V38, P307, DOI 10.2307/2296384; Swets JA, 2000, PSYCHOL SCI PUBLIC I, V1, P1, DOI DOI 10.1111/1529-1006.001; SY BK, SIGNATURE BASED APPR, P526; Ulvila J., 2004, DECIS ANAL, V1, P35, DOI 10.1287/deca.1030.0001; Ulvila JW, 2003, J RES NATL INST STAN, V108, P453, DOI 10.6028/jres.108.040; Witten I. H., 2005, DATA MINING PRACTICA; *ISO, 2002, 15947 ISOIEC TR	27	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-36036-0	LECT NOTES ARTIF INT			2006	4065						377	388				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEV61	WOS:000239623700030	
S	Helmy, T; Shahab, SA		Chung, YC; Moreira, JE		Helmy, T; Shahab, SA			Machine learning-based adaptive load balancing framework for distributed object computing	ADVANCES IN GRID AND PERVASIVE COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Grid and Pervasive Computing	MAY 03-05, 2006	Taichung, TAIWAN			distributed object computing; Jini; load balancing; middleware layer; reinforcement learning; Q-learning		Distributed object computing is widely envisioned to be the desired distributed software development paradigm due to the higher modularity and the capability of handling machine and operating system heterogeneity. In this paper, we address the issue of judicious load balancing in distributed object computing systems. In order to decrease response time and to utilize services effectively, we have proposed and implemented a new technique based on machine learning for adaptive and flexible load balancing mechanism within the framework of distributed middleware. We have chosen Jini 2.0 to build our experimental middleware platform, on which our proposed approach as well as other related techniques are implemented and compared. Extensive experiments are conducted to investigate the effectiveness of the proposed technique, which is found to be consistently better in comparison with existing techniques.	King Fahd Univ Petr & Minerals, Coll Comp Sci & Engn, Dhahran 31261, Saudi Arabia	Helmy, T (reprint author), King Fahd Univ Petr & Minerals, Coll Comp Sci & Engn, Dhahran 31261, Saudi Arabia.	helmy@ccse.kfupm.edu.sa; sadnans@ccse.kfupm.edu.sa					CHEUNG YKK, 2004, J PARALLEL DISTRIBUT, V64, P238; CIUHANDU O, 2003, OOPSLA 03       1026; GALSTYAN A, 2004, RESOURCE ALLOCATION; KRUEGER P, 1994, IEEE T SOFTWARE ENG, V20, P432, DOI 10.1109/32.295892; Othman O, 2001, IEEE DISTRIBUTED SYS, V2; PAGE AJ, 2005, 8 INT WORKSH NAT INS; RUSSELL N, 2003, ARTIFICIAL INTELLIGE; WALDSPURGER CA, 1992, IEEE T SOFTWARE ENG, V18, P103, DOI 10.1109/32.121753	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33809-8	LECT NOTES COMPUT SC			2006	3947						488	497				10	Computer Science, Theory & Methods	Computer Science	BEK24	WOS:000237540300048	
S	Awde, A; Hina, MD; Tadj, C; Ramdane-Cherif, A; Bellik, Y		Chung, YC; Moreira, JE		Awde, A; Hina, MD; Tadj, C; Ramdane-Cherif, A; Bellik, Y			A paradigm of a pervasive multimodal multimedia computing system for the visually-impaired users	ADVANCES IN GRID AND PERVASIVE COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Grid and Pervasive Computing	MAY 03-05, 2006	Taichung, TAIWAN					Incorporating multimodality in a computing system makes computing more accessible to a wide range of users, including those with impairments. This work presents a paradigm of a multimodal multimedia computing system to make informatics accessible to visually-impaired users. The system's infrastructure determines the suitable applications to be used. The user's context and user data type are considered in determining the types of applications, media and modalities that are appropriate to use. The system design is pervasive, fault-tolerant and capable of self-adaptation under varying conditions (e.g. missing or defective components). It uses machine learning so that the system would behave in a pre-defined manner given a pre-conceived scenario. Incremental learning is adapted for added machine knowledge acquisition. A simulation of system's behaviour, using a test case scenario, is presented in this paper. This work is our original contribution to an ongoing research to make informatics more accessible to handicapped users.	Univ Quebec, LATIS Lab, Ecole Technol Super 1100, Montreal, PQ H3C 1K3, Canada; Univ Versailles, PRISM Lab, CRNS, F-78035 Versailles, France; Univ Paris 11, LIMSI, CRNS, F-91043 Orsay, France	Awde, A (reprint author), Univ Quebec, LATIS Lab, Ecole Technol Super 1100, Rue Notre Dame Ouest, Montreal, PQ H3C 1K3, Canada.	ali.awde.1@ens.etsmt1.ca; manolo-dulva.hina.1@ens.etsmt1.ca; ctadj@ele.etsmt1.ca; rca@prism.uvsq.fr; yacine.bellik@limsi.fr					ANTONIOL G, 2004, 8 EUR C SOFTW MAINT; ARCHAMBAULT D, 1999, BRAILLESURF HTML BRO; BELLIK Y, 1995, THESIS U DORSAY PARI; Bougant F, 2003, IEEE COMMUN MAG, V41, P93, DOI 10.1109/MCOM.2003.1166662; BOURBAKIS NG, 2001, 2 IEEE INT S BIOINF; DJENIDI H, 2004, EURASIP J APPL SIGNA; EDWARDS A, 1997, MATHS MATH ACCESS TE; FERREIRA H, 2004, ICCHP C PAR FRANC; Giraud-Carrier C, 2000, AI COMMUN, V13, P215; HAN T, 2005, 6 INT C SOFTW ENG AR; HERBORDT W, 2005, AUT M AC SOC JAP; HINA MD, 2005, WORKSH MULT INF P RE; Horn P., 2001, AUTONOMIC COMPUTING; KING A, 2004, 2 CWUAAT WORKSH CAMB; McCullough Malcolm, 2004, DIGITAL GROUND ARCHI; MEIJER P, 2005, VOICE VISION TECHNOL; Mitchell T., MACHINE LEARNING; MOCO V, 2004, ICCHP C PAR FRANC; OKAMOTO M, 2003, THESIS KYOTO U; Ross DA, 2004, IEEE PERVAS COMPUT, V3, P30, DOI 10.1109/MPRV.2004.1316815; Wooldridge M. J., 2001, INTRO MULTIAGENT SYS; *ROY NATL I BLIND, FIN REP TID	22	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33809-8	LECT NOTES COMPUT SC			2006	3947						620	633				14	Computer Science, Theory & Methods	Computer Science	BEK24	WOS:000237540300061	
S	Yin, L; Power, R		Lalmas, M; MacFarlane, A; Ruger, S; Tombros, A; Tsikrika, T; Yavlinsky, A		Yin, Ling; Power, Richard			Adapting the naive Bayes classifier to rank procedural texts	ADVANCES IN INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	28th European Conference on Information Retrieval (ECIR 2006)	APR   10, 2005-APR 12, 2006	London, ENGLAND	Queen Mary Univ London, City Univ, Engn & Phys Sci Res Council, CEPIS, Google, GCHQ, Microsoft Res, Yahoo Res, Sharp, Apriorie, Lemur Consulting, MMKM, Elsevier	Imperial Coll London, S Kensington			This paper presents a machine-learning approach for ranking web documents according to the proportion of procedural text they contain. By 'procedural text' we refer to ordered lists of steps, which are very common in some instructional genres such as online manuals. Our initial training corpus is built up by applying some simple heuristics to select documents from a large collection and contains only a few documents with a large proportion of procedural texts. We adapt the Naive Bayes classifier to better fit this less than ideal training corpus. This adapted model is compared with several other classifiers in ranking procedural texts using different sets of features and is shown to perform well when only highly distinctive features are used.	Univ Brighton, NLTG, Brighton BN2 4GJ, E Sussex, England; Open Univ, Fac Math & Comp, Milton Keynes MK7 6AA, Bucks, England	Yin, L (reprint author), Univ Brighton, NLTG, Watts Bldg,Lewes Rd, Brighton BN2 4GJ, E Sussex, England.	Y.Ling@brighton.ac.uk; r.power@open.ac.uk					CLARKE C, 1998, P 25 ANN INT ACM SIG; Freund Y., 1999, P 16 INT C MACH LEAR, P124; John G. H., 1995, P 11 C UNC ART INT, P338; Kelly D., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; SANTINI M, 2004, P 7 ANN C UK SPEC IN; SCHWITTER R, 2004, QUEST ANSW WORKSH TA; SEBASTIANI F, 1999, ACM COMPUT SURV, V34, P1; STRICKER M, 2000, CL0007016 CORR CS; TAKECHI M, 6 INT WORKSH INF RET, P49; Witten I. H., 2000, DATA MINING PRACTICA; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Yang Yiming, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; YIN L, 2006, P 11 C EUR CHAPT ASS	13	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33347-9	LECT NOTES COMPUT SC			2006	3936						179	190				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEM01	WOS:000238083200017	
S	Siersdorfer, S; Sizov, S		Lalmas, M; MacFarlane, A; Ruger, S; Tombros, A; Tsikrika, T; Yavlinsky, A		Siersdorfer, Stefan; Sizov, Sergej			Automatic document organization in a P2P environment	ADVANCES IN INFORMATION RETRIEVAL	Lecture Notes in Computer Science		English	Article; Proceedings Paper	28th European Conference on Information Retrieval (ECIR 2006)	APR 10-12, 2005-2006	London, ENGLAND	Queen Mary Univ London, City Univ, Engn & Phys Sci Res Council, CEPIS, Google, GCHQ, Microsoft Res, Yahoo Res, Sharp, Apriorie, Lemur Consulting, MMKM, Elsevier	Imperial Coll London, S Kensington			This paper describes an efficient method to construct reliable machine learning applications in peer-to-peer (P2P) networks by building ensemble based meta methods. We consider this problem in the context of distributed Web exploration applications like focused crawling. Typical applications are user-specific; classification of retrieved Web contents into personalized topic hierarchies as well as automatic refinements of such taxonomies using unsupervised machine-learning methods (e.g. clustering). Our approach is to combine models from multiple peers and to construct the advanced decision model that takes the generalization performance of multiple 'local' peer models into account. In addition, meta algorithms can be applied in a restrictive manner, i.e. by leaving out some 'uncertain' documents. The results of our systematic evaluation show the viability of the proposed approach.			stesi@mpi-sb.mpg.de; sizov@mpi-sb.mpg.de					Baeza-Yates R.A., 1999, MODERN INFORM RETRIE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Burges C. J. C., 1998, DATA MINING KNOWLEDG, V2; Chakrabarti S., 2003, MINING WEB; Chan Philip, 1996, THESIS COLUMBIA U NE; CRAVEN M, 1998, 15 NAT C ART INT AAA; DEMERS A, 1987, 6 ANN ACM S PRINC DI; Dhillon IS, 2000, LECT NOTES ARTIF INT, V1759, P245, DOI 10.1007/3-540-46502-2_13; FRED A, 2003, P C COMP VIS PATT RE; FREUND Y, 1999, WORKSH COMP LEARN TH; GORUNOVA K, 2005, WISE; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Kargupta H., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011677; Lewis D., 1991, P SPEECH NAT LANG WO, P312, DOI 10.3115/112405.112471; LI T, 2003, INTELLIGEN DATA ANAL, V7; LITTLESTEON N, 1989, FOCS; MERUGU S, 2003, INT C DAT MIN ICDM 0; Platt J., 1999, ADV LARGE MARGIN CLA; PORTER M, AUTOMATED LIB INFORM, V14; Rivest R., 1992, 1321 RFC; SIERSDORFER S, 2004, SIGIR; SIERSDORFER S, 2004, CIK WASH US; Strehl A., 2003, J MACHINE LEARNING R, V3, P583, DOI DOI 10.1162/153244303321897735; VAIDYA J, 2004, SDM; WANG H, 2003, SIGKDD; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; YU H, 2002, ICDM	27	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33347-9	LECT NOTES COMPUT SC			2006	3936						265	276				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEM01	WOS:000238083200024	
S	Vittaut, JN; Gallinari, P		Lalmas, M; MacFarlane, A; Ruger, S; Tombros, A; Tsikrika, T; Yavlinsky, A		Vittaut, Jean-Noel; Gallinari, Patrick			Machine learning ranking for structured information retrieval	ADVANCES IN INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	28th European Conference on Information Retrieval (ECIR 2006)	APR   10, 2005-APR 12, 2006	London, ENGLAND	Queen Mary Univ London, City Univ, Engn & Phys Sci Res Council, CEPIS, Google, GCHQ, Microsoft Res, Yahoo Res, Sharp, Apriorie, Lemur Consulting, MMKM, Elsevier	Imperial Coll London, S Kensington			We consider the Structured Information Retrieval task which consists in ranking nested textual units according to their relevance for a given query, in a collection of structured documents. We propose to improve the performance of a baseline Information Retrieval system by using a learning ranking algorithm which operates on scores computed from document elements and from their local structural context. This model is trained to optimize a Ranking Loss criterion using a training set of annotated examples composed of queries and relevance judgments on a subset of the document elements. The model can produce a ranked list of documents elements which fulfills a given information need expressed in the query. We analyze the performance of our algorithm on the INEX collection and compare it to a baseline model which is an adaptation of Okapi to Structured Information Retrieval.	Lab Informat Paris 6, F-75015 Paris, France	Vittaut, JN (reprint author), Lab Informat Paris 6, 8,Rue Capitaine Scott, F-75015 Paris, France.	vittaut@poleia.lip6.fr; gallinari@poleia.lip6.fr					AMINI MR, 2005, ECIR, P142; AUER P, 2005, LECT NTOES COMPUTER, V3559; BAEZAYATES R, 2004, SIGIR FORUM, P245; BARTELL BT, 1994, RES DEV INF RETR, P173; COHEN WW, 1998, ADV NEURAL INFORMATI, V10; Cooper W. S., 1992, P 15 ANN INT ACM SIG, P198, DOI 10.1145/133160.133199; Craswell N., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Freund Y., 1998, P 15 INT C MACH LEAR, P170; Fuhr N, 2005, LECT NOTES COMPUTER, V3493; JARVELIN K, 2002, ACM T INFORM SYST, P422; KAZAI G, 2005, TECHNICAL DOCUMENT; KAZAI G, 2001, SPIRE, P123; LALMAS M, 2000, DEMPSTER SHAFER INDE; LALMAS M, 1997, DEMPSTER SHAFERS THE; OGILVIE P, 2004, P INEX, V2003, P12; PIWOWARSKI B, 2004, BAYESIAN NETWORK XML; Robertson S.E., 1992, TEXT RETR C, P21	17	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33347-9	LECT NOTES COMPUT SC			2006	3936						338	349				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEM01	WOS:000238083200030	
S	Eitrich, T; Lang, B		Yakhno, T; Neuhold, EJ		Eitrich, Tatjana; Lang, Bruno			Data mining with parallel support vector machines for classification	ADVANCES IN INFORMATION SYSTEMS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	4th International Conference on Advances in Information Systems	OCT 18-20, 2006	Izmir, TURKEY	Dokuz Eylul Univ Presidents Off, TUBITAK, Gonen Bilgi Teknolojileri Danismanlik Ltd		data mining; classification; support vector machine; parallelization	ALGORITHM	The increasing amount of data used for classification, as well as the demand for complex models with a large number of well tuned parameters, naturally lead to the search for efficient approaches making use of massively parallel systems. We describe the parallelization of support vector machine learning for shared memory systems. The support vector machine is a powerful and reliable data mining method. Our learning algorithm relies on a decomposition scheme, which in turn uses a special variable projection method, for solving the quadratic program associated with support vector machine learning. By using hybrid parallel programming, our parallelization approach can be combined with the parallelism of a distributed cross validation routine and parallel parameter optimization methods.	Res Ctr Juelich, Cent Inst Appl Math, Julich, Germany; Univ Gesamthsch Wuppertal, Dept Math, Appl Comp Sci & Sci Comp Grp, D-5600 Wuppertal, Germany	Eitrich, T (reprint author), Res Ctr Juelich, Cent Inst Appl Math, Julich, Germany.	t.eitrich@fz-juelich.de; lang@math.uni-wuppertal.de					Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CELIS S., 2002, WEKA PARALLEL MACHIN; Collobert R, 2002, NEURAL COMPUT, V14, P1105, DOI 10.1162/089976602753633402; Cristianini N., 2000, INTRO SUPPORT VECTOR; DETERT U, 2004, INTRO JUMP ARCHITECT; Dhillon IS, 2000, LECT NOTES ARTIF INT, V1759, P245, DOI 10.1007/3-540-46502-2_13; DONGARRA JJ, 1988, ACM T MATH SOFTWARE, V14, P1, DOI 10.1145/42288.42291; Eitrich T, 2005, LECT NOTES COMPUT SC, V3695, P253; EITRICH T, 2005, IN PRESS J COMPUTATI; ELIKOFF S, 2003, SVM TREE ALGORITHM; Graf HP, 2005, ADV NEURAL INFORM PR, V18, P521; Han H, 2003, JCDL 03 P 3 ACM IEEE, P37; Hettich S., 1998, UCI REPOSITORY MACHI; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Hsu CW, 2002, MACH LEARN, V46, P291, DOI 10.1023/A:1012427100071; Jin RM, 2005, IEEE T KNOWL DATA EN, V17, P71; Kless A, 2004, LECT NOTES ARTIF INT, V3303, P191; Lawson C. L., 1979, ACM Transactions on Mathematical Software, V5, DOI 10.1145/355841.355847; PARDALOS PM, 1990, MATH PROGRAM, V46, P321, DOI 10.1007/BF01585748; Runarsson T.P., 2004, NEURAL INFORMATION P, V3, P59; SCHOLKOPF B, 2002, LEARNING KEARNELS; Scholkopf B, 2000, NIPS, P301; Serafini T, 2004, ADV PAR COM, V13, P259; Serafini T., 2005, OPTIMIZATION METHODS, V20, P353, DOI 10.1080/10556780512331318182; YU H, 2003, 2 IEEE COMP SOC BIOI, P220; ZAKI MJ, 1999, IEEE INT C DAT ENG M, P198; Zoutendijk G., 1960, METHODS FEASIBLE DIR; *OPENMP ARCH REV B, 1999, OPENMP FORTR APPL PR	28	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-46291-0	LECT NOTES COMPUT SC			2006	4243						197	206				10	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFG62	WOS:000241754200021	
S	Webb, GI		Li, Y; Looi, M; Zhong, N		Webb, Geoffrey I.			Anytime learning and classification for online applications	Advances in Intelligent IT: Active Media Technology 2006	FRONTIERS IN ARTIFICIAL INTELLIGENCE AND APPLICATIONS		English	Proceedings Paper	4th International Conference on Active Media Technology	JUN 07-09, 2006	Brisbane, AUSTRALIA	IEEE Syst, Man & Cybernet Soc	Queensland Univ Technol	machine learning; anytime algorithms; anytime learning; anytime classification		Many online applications of machine learning require fast classification and hence utilize efficient classifiers such as nave Bayes. However, outside periods of peak computational load, additional computational resources will often be available. Anytime classification can use whatever computational resources may be available at classification time to improve the accuracy of the classifications made.	Monash Univ, Clayton, Vic 3800, Australia	Webb, GI (reprint author), Monash Univ, Clayton, Vic 3800, Australia.						CERQUIDES J, 2005, P 16 EUR C MACH LEAR, P72; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Keogh E. J., 1999, P 7 INT WORKSH ART I, P225; Kohavi R, 1996, P 2 INT C KNOWL DISC, P202; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1993, P 1993 EUR C MACH LE, P153; LANGLEY P, 1994, P 10 C UNC ART INT, P399; Lewis D.D., 1998, EUR C MACH LEARN, P4; Pazzani M. J, 1996, ISIS INFORM STAT IND, P66; Sahami M, 1996, P 2 INT C KNOWL DISC, P334; Singh M., 1996, P 13 INT C MACH LEAR, P453; Webb G I, 1998, P 11 AUSTR JOINT C A, P285; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; WEBB GI, 2001, P 14 AUSTR JOINT C A, P545; WEBB GI, 2006, LEARNING ANYTIME CLA; XIE Z, 2002, P 6 PAC AS C KDD, P104; YANG Y, 2006, UNPUB EFFECTIVELY OR; ZHENG Z, 1999, P 16 INT C MACH LEAR, P493; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	19	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	978-1-58603-615-7	FR ART INT			2006	138						7	12				6	Computer Science, Information Systems	Computer Science	BFP40	WOS:000243592900002	
S	Qin, ZX; Zhang, SC; Zhang, CQ		Li, Y; Looi, M; Zhong, N		Qin, Zhenxing; Zhang, Shichao; Zhang, Chengqi			Missing or absent? A question in cost-sensitive decision tree	Advances in Intelligent IT: Active Media Technology 2006	FRONTIERS IN ARTIFICIAL INTELLIGENCE AND APPLICATIONS		English	Proceedings Paper	4th International Conference on Active Media Technology	JUN 07-09, 2006	Brisbane, AUSTRALIA	IEEE Syst, Man & Cybernet Soc	Queensland Univ Technol	induction; knowledge acquisition; machine learning		One common source of error in data is the existence of missing value fields. Imputation method has been a widely used technique in preprocessing phase of data mining, in which missing values are replaced by some estimated values. Previous work is trying to seek the "original" values according to specific criteria, such as statistics measure. However, in domain of cost-sensitive leaning, minimal overall cost is the most important issue, i.e. a value which can minimize total cost is prefer than the "best" value upon common sense. For example, in medical domains, some data fields usually are left as absent and known information is enough for a decision. In this paper, we proposed a new method to study the problem of "missing or absent values?" in the domain cost-sensitive learning. Experiment results show some improvements with distinguished missing and absent data in cost-sensitive decision tree.	Univ Technol Sydney, Fac Informat Technol, Sydney, NSW 2007, Australia	Qin, ZX (reprint author), Univ Technol Sydney, Fac Informat Technol, POB 123, Sydney, NSW 2007, Australia.						Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Greiner R, 2002, ARTIF INTELL, V139, P137, DOI 10.1016/S0004-3702(02)00209-6; Ling C. X., 2004, P 21 INT C MACH LEAR; Little R.J.A., 1987, WILEY SERIES PROBABI; LIU WZ, 1997, 2 INT S INT DAT AN L; Mitchell T, 1997, MACHINE LEARNING; QIN Z, 2004, P 17 AUSTR JOINT C A; Qin Z.X., 2005, P FSKD 2005 CHANGS C, P402; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R, 1989, P 6 INT WORKSH MACH; RAGEL A, 1999, KNOWL-BASED SYST, P285; TENG CM, 2004, IEEE INTELLIGENT MAR, P34; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; TURNEY PD, 2000, 17 INT C MACH LEARN; Zhang SC, 2005, IEEE T KNOWL DATA EN, V17, P1689; Zubek V., 2002, P 19 INT C MACH LEAR, P27; [Anonymous], 1993, P 13 INT JOINT C ART, P1022	18	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	978-1-58603-615-7	FR ART INT			2006	138						118	125				8	Computer Science, Information Systems	Computer Science	BFP40	WOS:000243592900019	
S	Busch, P; Richards, D		Hoffmann, A; Kang, BH; Richards, D; Tsumoto, S		Busch, Peter; Richards, Debbie			Acquiring innovation knowledge	Advances in Knowledge Acquisition and Management	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	Pacific Rim Knowledge Acquisition Workshop	AUG 07-08, 2006	Guilin, PEOPLES R CHINA			innovation knowledge; knowledge acquisition		There are few possibilities for acquiring knowledge related to innovation. Firstly, acquiring knowledge using machine learning typically requires structured and classified data and/or cases, and lots of them. Secondly, manual acquisition of knowledge requires human expertise. Both approaches seem impractical when it comes to innovation knowledge. While innovation is recognized as a vital part of sustainability within organizations, there is little assistance with how we can acquire, reuse or share the innovation knowledge that may exist. We suggest a technique and present preliminary results of an evaluation study using this approach.	Macquarie Univ, Div Informat & Commun Sci, Comp Dept, N Ryde, NSW, Australia	Busch, P (reprint author), Macquarie Univ, Div Informat & Commun Sci, Comp Dept, N Ryde, NSW, Australia.						BELL G, 1991, MCHIGH TECH VENTURES; BUSCH P, 2003, P 14 AUSTR C INF SYS; BUSCH P, 2005, P 15 AUSTR C INF SYS; BUSCH P, 2004, P PAC KNOWL ACQ WORK, P87; FENWICK, 2003, J WORKPLACE LEARNING, V15, P123; GANTER R, 1999, FORMAL CONCEPT ANAL; GOUGH HG, 1981, 4 NAT C MYERSBR TYP; KIRTON M, 2001, CREATIVE MANAGEMENT, P169; LEONARD D, 1998, CALIFORNIA MANAGEMEN, V40; SCHWEIZER TS, 2004, ERIM PH D SERIES, V48; STERNBERG RJ, 1995, AM PSYCHOL, V50, P912, DOI 10.1037/0003-066X.50.11.912	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68955-3	LECT NOTES COMPUT SC			2006	4303						252	257				6	Computer Science, Artificial Intelligence	Computer Science	BFU78	WOS:000244722700025	
S	Driessens, K; Reutemann, P; Pfahringer, B; Leschi, C		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Driessens, K; Reutemann, P; Pfahringer, B; Leschi, C			Using weighted nearest neighbor to benefit from unlabeled data	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				The development of, data-mining applications such as text-classification and molecular profiling has shown the need for machine learning algorithms that can benefit from both labeled and unlabeled data, where often the unlabeled examples greatly outnumber the labeled examples. In this paper we present a two-stage classifier that improves its predictive accuracy by making use of the available unlabeled data. It uses a weighted nearest neighbor classification algorithm using the combined example-sets as a knowledge base. The examples from the unlabeled set are "pre-labeled" by an initial classifier that is build using the limited available training data. By choosing appropriate weights for this prelabeled data, the nearest neighbor classifier consistently improves on the original classifier.	Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium; Univ Waikato, Dept Comp Sci, Hamilton, New Zealand; Inst Natl Sci Appliquees, Lyon, France	Driessens, K (reprint author), Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium.						Blum A., 1998, COLT, P92; Blum A., 2001, P 18 INT C MACH LEAR; Blum PR, 2001, STUD EUROP JUDAISM, V1, P19; CHAPELLE O, 2002, ADV NEURAL INFORM PR, V15, P585; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Joachims T., 1999, P 16 INT C MACH LEAR, P200; JOACHIMS T, 2003, MACH LEARN, P290; NEVILLE J, 2003, P 2 INT WORKSH MULT; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Omohundro S. M., 1987, Complex Systems, V1; Rosenberg C., 2005, 7 IEEE WORKSH APPL C, P29; Seeger M., 2001, LEARNING LABELED UNL; Szummer M., 2001, ADV NEURAL INFORM PR, V14, P945; ZHOU D, 2004, P ANN C NEUR INF PRO; Zhou ZH, 2004, IEEE T KNOWL DATA EN, V16, P770; Zhu X., 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663; Zhu X., 2005, THESIS CARNEGIE MELL	17	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						60	69				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600010	
S	Frank, E; Pfahringer, B		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Frank, E; Pfahringer, B			Improving on bagging with input smearing	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				Bagging is an ensemble learning method that has proved to be a useful tool in the arsenal of machine learning practitioners. Commonly applied in conjunction with decision tree learners to build an ensemble of decision trees, it often leads to reduced errors in the predictions when compared to using a single tree. A single tree is built from a training set of size N. Bagging is based on the idea that, ideally, we would like to eliminate the variance due to a particular training set by combining trees built from all training sets of size N. However, in practice, only one training set is available, and bagging simulates this platonic method by sampling with replacement from the original training data to form new training sets. In this paper we pursue the idea of sampling from a kernel density estimator of the underlying distribution to form new training sets, in addition to sampling from the data itself. This can be viewed as "smearing out" the resampled training data to generate new datasets, and the amount of "smear" is controlled by a parameter. We show that the resulting method, called "input smearing", can lead to improved results when compared to bagging. We present results for both classification and regression problems.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Frank, E (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.	eibe@cs.waikato.ac.nz; bernhard@cs.waikato.ac.nz	Frank, Eibe/A-1434-2008				Achlioptas D, 2001, 20 ANN S PRINC DAT S, P274; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 2000, MACH LEARN, V40, P229, DOI 10.1023/A:1007682208299; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domingos P., 1997, P 14 INT C MACH LEAR, P98; Freund Y., 1996, 13 INT C MACH LEARN, P148; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; MELVILLE P, 2004, CREATING DIVERSITY E, V6, P99; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Newman D. J., 1998, UCI REPOSITORY MACHI; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Rennie J. D., 2003, P 20 INT C MACH LEAR, P616; Ting K.M., 1997, 14 INT C MACH LEARN, P367; TORGO L, 2005, REGRESSION DATASETS; WANG Y, 1997, P POST PAP EUR C MAC	19	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						97	106				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600014	
S	Nguyen, PC; Ohara, K; Mogi, A; Motoda, H; Washio, T		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Nguyen, PC; Ohara, K; Mogi, A; Motoda, H; Washio, T			Constructing decision trees for graph-structured data by Chunkingless Graph-Based Induction	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				Chunkingless Graph-Based Induction (CI-GBI) is a machine learning technique proposed for the purpose of extracting typical patterns from graph-structured data. This method is regarded as an improved version of Graph-Based Induction (GBI) which employs stepwise pair expansion (pairwise chunking) to extract typical patterns from graph-structured data, and can find overlapping patterns that cannot not be found by GBI. In this pap er, we propose an algorithm for constructing decision trees for graph-structured data using Cl-GBI. This decision tree construction algorithm, called Decision Tree Chunkingless GraphBased Induction (DT-CIGBI), can construct decision trees from graphstructured datasets while simultaneously constructing attributes useful for classification using Cl-GBI internally. Since patterns extracted by CI-GBI are considered as attributes of a graph, and their existence/nonexistence are used as attribute values, DT-CIGBI can be conceived as a tree generator equipped with feature construction capability. Experiments were conducted on synthetic and real-world graph-structured datasets showing the effectiveness of the algorithm.	Osaka Univ, Inst Sci & Ind Res, Ibaraki, Osaka 5670047, Japan	Nguyen, PC (reprint author), Osaka Univ, Inst Sci & Ind Res, 8-1 Mihogaoka, Ibaraki, Osaka 5670047, Japan.	chien@ar.sanken.osaka-u.ac.jp; ohara@ar.sanken.osaka-u.ac.jp; mogi@ar.sanken.osaka-u.ac.jp; motoda@ar.sanken.osaka-u.ac.jp; washio@ar.sanken.osaka-u.ac.jp					Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Geamsakul W, 2005, FUND INFORM, V66, P131; MATSUDA T, 2002, P 5 INT C DISC SCI, P422; NGUYEN PC, 2005, P PAKDD 2005, P639; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; YAMADA Y, 2003, P 20 INT C MACH LEAR, P840; YOSHIDA K, 1995, ARTIF INTELL, V75, P63, DOI 10.1016/0004-3702(94)00066-A	8	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						390	399				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600045	
S	Zou, B; Ma, X; Kemme, B; Newton, G; Precup, D		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Zou, B; Ma, X; Kemme, B; Newton, G; Precup, D			Data mining using relational database management systems	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				Software packages providing a whole set of data mining and machine learning algorithms are attractive because they allow experimentation with many kinds of algorithms in an easy setup. However, these packages are often based on main-memory data structures, limiting the amount of data they can handle. In this paper we use a relational database as secondary storage in order to eliminate this limitation. Unlike existing approaches, which often focus on optimizing a single algorithm to work with a database backend, we propose a general approach, which provides a database interface for several algorithms at once. We have taken a popular machine learning software package, Weka, and added a relational storage manager as back-tier to the system. The extension is transparent to the algorithms implemented in Weka, since it is hidden behind Weka's standard main-memory data structure interface. Furthermore, some general mining tasks are transfered into the database system to speed up execution. We tested the extended system, refered to as WekaDB, and our results show that it achieves a much higher scalability than Weka, while providing the same output and maintaining good computation time.	McGill Univ, Montreal, PQ, Canada; Natl Res Council Canada, Ottawa, ON K1A 0R6, Canada	Zou, B (reprint author), McGill Univ, Montreal, PQ, Canada.						AGRAWAL R, 1993, IEEE T KNOWLEDGE DAT, V5; DUMOUCHEL W, 1999, ACM INT C KNOW DISC; GEHRKE J, 1998, INT C VER LARG DAT B; MOORE A, 1998, J ARTIFICIAL INTELLI, V8; ORDONEZ C, 2004, ACM INT C KNOW DISC; Pyle Dorian, 1999, DATA PREPARATION DAT; ROSS BJ, 2002, GEN EV COMP C; Sarawagi S., 1998, ACM SIGMOD INT C MAN; SHAFER J, 1996, INT C VER LARG DAT B; WITTEN IH, DATA MINING SOFTWARE	10	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						657	667				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600075	
S	Xu, Z; Song, BH		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Xu, Zhen; Song, Binheng			A machine learning application for human resource data mining problem	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR 09-12, 2005-2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				Apply machine learning methods to data mining domain can be more helpful to extract useful knowledge for problems with changing conditions. Human resource allocation is a kind of problem in data mining domain. It presents machine learning techniques to dissolve it. First, we construct a new model which optimizes the multi-objectives allocation problem by using fuzzy logic strategy. One of the most important problems in the model is how to get the precise individual capability matrixes. Machine learning method by being told is well used to settle the problem in this paper. In the model, appraisal values about employees are saved in knowledge warehouse. Before tasks allocation, machine learning approach provides the capability matrixes based on the existing data sets. Then Task-Affange or Hungarian Algorithm provides the final solution with our proposed matrixes. After present tasks are finished, machine learning method by being told can update the matrixes according to the suggestions on employees' performance provided by the specialists. Useful knowledge can be well mined in cycles by learning approach. As a numerical example demonstrated, it is helpful to make a realistic decision on human resource allocation under a dynamic environment for organizations.	Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China; Tsinghua Univ, Dept Math, Beijing 100084, Peoples R China	Xu, Z (reprint author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.	z-xu03@mails.tsinghua.edu.cn; bsong@math.tsinghua.edu.cn					Chen HC, 1996, J VIS COMMUN IMAGE R, V7, P88, DOI 10.1006/jvci.1996.0008; Cloete I, 2004, IEEE SYS MAN CYBERN, P3199, DOI 10.1109/ICSMC.2004.1400832; GRANT EW, 1987, J HLTH CARE MARKET, V1, P69; Hand D., 2001, PRINCIPLES DATA MINI; Keyser TK, 1998, IIE TRANS, V30, P379, DOI 10.1080/07408179808966477; Kwak W, 2003, REV QUANTITATIVE FIN, V20, P277, DOI 10.1023/A:1023676529552; LIU YH, 1994, FUZZY SET SYST, V65, P117, DOI 10.1016/0165-0114(94)90252-6; LU KC, 1999, SINGLE OBJECTIVE MUL, P171; Mitchell T, 1997, MACHINE LEARNING; OMER K, 1998, APPL FUZZY SETS THEO, V2, P3; SHAW MJ, 1987, TI TECH J        WIN, P54; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Vigo D., 1997, Journal of Heuristics, V3, DOI 10.1023/A:1009676913040; WANG CF, 1994, J NW NORMAL U, V30, P26; Welling P, 1977, ACCOUNT ORG SOC, V2, P307, DOI 10.1016/0361-3682(77)90020-4; ZEBDA A, 1998, APPL FUZZY SETS THEO, V2, P15; Zhang D, 2003, SOFTWARE QUAL J, V11, P87, DOI 10.1023/A:1023760326768	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						847	856				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600099	
S	Jiang, QS; Abidi, SSR		Yeung, DS; Liu, ZQ; Wang, XZ; Yan, H		Jiang, Qingshuang; Abidi, Syed Sible Raza			From clusters to rules: A hybrid framework for generalized symbolic rule induction	ADVANCES IN MACHINE LEARNING AND CYBERNETICS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	Guangzhou, PEOPLES R CHINA	IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany				Rule induction is a data mining process for acquiring knowledge in terms of symbolic decision rules that explain the data in terms of causal relationship between conditional factors and a given decision/outcome. We present a Decision Rule Acquisition Workbench (DRAW) that discovers symbolic decision rules, in CNF form, from un-annotated data-sets. Our rule-induction strategy involves three phases: (a) conceptual clustering to cluster and generate a conceptual hierarchy of the data-set; (b) rough sets based rule induction algorithm to generate decision rules from the emergent data clusters; and (c) attribute oriented induction to generalize the derived decision rules to yield high-level decision rules and a minimal rule-set size. We evaluate DRAW with five standard machine learning datasets and apply to derive decision rules to understand optic nerve images in the realm of glaucoma decision support.	Dalhousie Univ, Fac Comp Sci, Halifax, NS B3H 1W5, Canada	Jiang, QS (reprint author), Dalhousie Univ, Fac Comp Sci, Halifax, NS B3H 1W5, Canada.	sraza@cs.dal.ca					ABIDI SSR, 2001, LECT NOTES COMPUTER, V2189, P248; Arabie P., 1996, CLUSTERING CLASSIFIC, P5; BAZAN JG, 1996, P 6 INT C INF PROC M, V3, P1147; BISWAS G, 1995, ARTIF INTELL, P111; CHAN CC, 1994, FDN COMPUTING DECISI, V19, DOI UNSP 185204; FAYYAD UM, 1996, INT C KNOWL DISC DAT, P82; GOODALL DW, 1966, BIOMETRICS, V22, P882, DOI 10.2307/2528080; Grzymala-Busse J. W., 1992, INTELLIGENT DECISION, P3; HAN JW, 1992, PROC INT CONF VERY L, P547; HU X, 1997, P 9 INT C TOOLS ART; KOMOROWSKI J, 1997, P 15 IMACS WORLD C S; OHRN A, LNAI, V1704, P462; Pawlak Z., 1997, ROUGH SETS DATA MINI, P3; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Shavlik J. W., 1990, READINGS MACHINE LEA; SKOWRON A, 1997, ROUGH SETS DATA MINI, P289; SLOWINSKI K, 1988, MED INFORM, V13, P143; Wroblewski J., 1995, P 2 ANN JOINT C INF, P186	18	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33584-6	LECT NOTES ARTIF INT			2006	3930						219	228				10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BEN35	WOS:000238282100023	
B	Hao, ZF; Liu, B; Yang, XW		Jiang, EX; Huang, TZ; Yang, CS		Hao, Zhifeng; Liu, Bo; Yang, Xiaowei			The application of least squares support vector machine for classification	Advances in Matrix Theory and Applications			English	Proceedings Paper	7th International Conference on Matrix Theory and Its Applications in China	JUL, 2006	Chengdu, PEOPLES R CHINA			support vector machine; least squares support vector machine; machine learning		In the training of stand support vector machine, the issue is reformulated and represented in such a way so as to obtain a quadratic programming problem. In order to solve the problems expediently, the Least squares support vector machines (LS-SVMs) was introduced. In which, one uses the equality constraints instead of inequality in the conventional SVMs, in this way the optimal solution can be obtained by solving a set of linear equations instead of solving a quadratic programming problem. In the paper, we imply the LS-SVMs into a real dataset, the results show the good performance of the LS-SVMs.	S China Univ Technol, Sch Math Sci, Guangzhou 510640, Peoples R China	Hao, ZF (reprint author), S China Univ Technol, Sch Math Sci, Guangzhou 510640, Peoples R China.						Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; CHUA KS, 2003, PATTERN RECOGN, P75; Fine S, 2002, J MACH LEARN RES, V2, P243, DOI 10.1162/15324430260185619; Keerthi SS, 2003, NEURAL COMPUT, V15, P487, DOI 10.1162/089976603762553013; KreBel U.H.G., 1999, ADV KERNEL METHODS S, P255; Murphy P.M., 1992, UCI REPOSITORY MACHI; Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Suykens JAK, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL II, P757; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640	12	0	0	WORLD ACAD UNION-WORLD ACAD PRESS	LIVERPOOL	113, ACADEMIC HOUSE, MILL LANE, WAVERTREE TECHNOLOGY PARK, LIVERPOOL, L13 4 AH, ENGLAND		1-84626-007-8				2006							24	27				4	Mathematics, Applied; Mathematics	Mathematics	BFD59	WOS:000241191000007	
B	Liu, B; Hao, ZF; Yang, XW		Jiang, EX; Huang, TZ; Yang, CS		Liu, Bo; Hao, Zhifeng; Yang, Xiaowei			The application of least squares support vector machine for classification	Advances in Matrix Theory and Applications			English	Proceedings Paper	7th International Conference on Matrix Theory and Its Applications in China	JUL, 2006	Chengdu, PEOPLES R CHINA			support vector machine; least squares support vector machine; machine learning		In the training of stand support vector machine, the issue is reformulated and represented in such a way so as to obtain a quadratic programming problem. In order to solve the problems expediently, the Least squares support vector machines (LS-SVMs) was introduced. In which, one uses the equality constraints instead of inequality in the conventional SVMs, in this way the optimal solution can be obtained by solving a set of linear equations instead of solving a quadratic programming problem. In the paper, we imply the LS-SVMs into a real data set, the results show the good performance of the LS-SVMs.	S China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510640, Peoples R China	Liu, B (reprint author), S China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510640, Peoples R China.						Boser B, 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; CHUA KS, 2003, PATTERN RECOGN, P75; Fine S, 2002, J MACH LEARN RES, V2, P243, DOI 10.1162/15324430260185619; Keerthi SS, 2003, NEURAL COMPUT, V15, P487, DOI 10.1162/089976603762553013; KreBel U.H.G., 1999, ADV KERNEL METHODS S, P255; Murphy P.M., 1992, UCI REPOSITORY MACHI; Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Suykens JAK, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL II, P757; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640	12	0	0	WORLD ACAD UNION-WORLD ACAD PRESS	LIVERPOOL	113, ACADEMIC HOUSE, MILL LANE, WAVERTREE TECHNOLOGY PARK, LIVERPOOL, L13 4 AH, ENGLAND		1-84626-007-8				2006							265	268				4	Mathematics, Applied; Mathematics	Mathematics	BFD59	WOS:000241191000070	
S	Shim, J; Hwang, C; Nau, S		Jiao, L; Wang, L; Gao, X; Liu, J; Wu, F		Shim, Jooyong; Hwang, Changha; Nau, Sungkyun			Robust LS-SVM regression using fuzzy C-means clustering	ADVANCES IN NATURAL COMPUTATION, PT 1	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Conference on Natural Computation (ICNC 2006)	SEP 24-28, 2006	Xian, PEOPLES R CHINA	Xidian Univ, Natl Nat Sci Fdn China, Int Neural Network Soc, Asia Pacific Neural Network Assembly, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Computat Intelligence Singapore Chapter, Chinese Assoc Artificial Intelligence				The least squares support vector machine(LS-SVM) is a widely applicable and useful machine learning technique for classification and regression. The solution of LS-SVM is easily obtained from the linear Karush-Kuhn-Tucker conditions instead of a quadratic programming problem of SVM. However, LS-SVM is less robust due to the assumption of the errors and the use of a squared loss function. In this paper we propose a robust LS-SVM regression method which imposes the robustness on the estimation of LS-SVM regression by assigning weight to each data point, which represents the membership degree to cluster. In the numerical studies, the robust LS-SVM regression is compared with the ordinary LS-SVM regression.	Dankook Univ, Div Informat & Comp Sci, Seoul 140714, South Korea; Catholic Univ Daegu, Dept Appl Stat, Kyungbuk 702701, South Korea	Hwang, C (reprint author), Dankook Univ, Div Informat & Comp Sci, Seoul 140714, South Korea.	jyshim@cu.ac.kr; chwang@dankook.ac.kr; nuhsam@nate.com					Bezdek J. C., 1981, PATTERN RECOGNITION; DABRABANTER J, 2003, ROBUST CROSS VALIDAT; Dunn J. C., 1973, Journal of Cybernetics, V3; Kecman V., 2001, LEARNING SOFT COMPUT; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Sarbu C, 2000, J AOAC INT, V83, P1463; Smola AJ, 1998, ALGORITHMICA, V22, P211, DOI 10.1007/PL00013831; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang L, 2005, SUPPORT VECTOR MACHI	10	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45901-4	LECT NOTES COMPUT SC			2006	4221						157	166				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFH67	WOS:000241891600026	
S	Yusiong, JPT; Naval, PC		Jiao, L; Wang, L; Gao, X; Liu, J; Wu, F		Yusiong, John Paul T.; Naval, Prospero C., Jr.			Training neural networks using Multiobjective Particle Swarm Optimization	ADVANCES IN NATURAL COMPUTATION, PT 1	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Conference on Natural Computation (ICNC 2006)	SEP 24-28, 2006	Xian, PEOPLES R CHINA	Xidian Univ, Natl Nat Sci Fdn China, Int Neural Network Soc, Asia Pacific Neural Network Assembly, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Computat Intelligence Singapore Chapter, Chinese Assoc Artificial Intelligence				This paper suggests an approach to neural network training through the simultaneous optimization of architectures and weights with a Particle Swarm Optimization (PSO)-based multiobjective algorithm. Most evolutionary computation-based training methods formulate the problem in a single objective manner by taking a weighted sum of the objectives from which a single neural network model is generated. Our goal is to determine whether Multiobjective Particle Swarm Optimization can train neural networks involving two objectives: accuracy and complexity. We propose rules for automatic deletion of unnecessary nodes from the network based on the following idea: a connection is pruned if its weight is less than the value of the smallest bias of the entire network. Experiments performed on benchmark datasets obtained from the UCI machine learning repository show that this approach provides an effective means for training neural networks that is competitive with other evolutionary computation-based methods.	Univ Philippines, Div Nat Sci & Math, Tacloban City, Leyte, Philippines; Univ Philippines, Dept Comp Sci, Quezon City 1101, Philippines	Yusiong, JPT (reprint author), Univ Philippines, Div Nat Sci & Math, Tacloban City, Leyte, Philippines.	jtyusiong@up.edu.ph; pcnaval@up.edu.ph					Abbass HA, 2002, ARTIF INTELL MED, V25, P265, DOI 10.1016/S0933-3657(02)00028-3; ALKAZEMI B, 2002, P 9 INT C NEUR INF P; Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Coello CA, 2002, P IEEE C EV COMP CEC; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; Fieldsend J. E., 2004, 419 U EX DEP COMP SC; Grimaldi E., 2004, P ICCEA 2004 3 INT C, P557; Grunwald P., 2004, ADV MINIMUM DESCRIPT; Gudise V.G., 2003, IEEE SWARM INT S APR, P110; HINTON G, 1993, P COLT 93; Jin YC, 2005, LECT NOTES COMPUT SC, V3410, P752; Kennedy J., 1995, P IEEE INT C NEUR NE, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Liu Yong, 1996, Chinese Journal of Advanced Software Research, V3; Newman D. J., 1998, UCI REPOSITORY MACHI; Palmes PP, 2005, IEEE T NEURAL NETWOR, V16, P587, DOI 10.1109/TNN.2005.844858; Raquel CR, 2005, P GEN EV COMP C GECC, P257, DOI 10.1145/1068009.1068047; SHAHIN M, 2004, INT E C MOD TRENDS F; Sugisaka M, 2005, IEICE T INF SYST, VE88D, P214, DOI 10.1093/ietisy/E88-D.2.214; VANDENBERGH F, 1999, PARTICLE SWARM WEIGH, P41; Yao X, 1999, P IEEE, V87, P1423; Yao X, 1998, APPL MATH COMPUT, V91, P83, DOI 10.1016/S0096-3003(97)10005-4; YAO X, 1996, 5 ANN C EV PROGR, P257; ZHAO F, 2005, P 2005 INT C NEUR NE, V3, P1693	23	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45901-4	LECT NOTES COMPUT SC			2006	4221						879	888				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFH67	WOS:000241891600116	
S	Zhang, YN; Yuan, HJ; Pan, J; Li, Y; Xi, RP; Yao, L		Jiao, L; Wang, L; Gao, X; Liu, J; Wu, F		Zhang, Yanning; Yuan, Hejin; Pan, Jin; Li, Ying; Xi, Runping; Yao, Lan			A fuzzy integral method of applying support vector machine for multi-class problem	ADVANCES IN NATURAL COMPUTATION, PT 2	Lecture Notes in Computer Science		English	Article; Proceedings Paper	2nd International Conference on Natural Computation (ICNC 2006)	SEP 24-28, 2006	Xian, PEOPLES R CHINA	Xidian Univ, Natl Nat Sci Fdn China, Int Neural Network Soc, Asia Pacific Neural Network Assembly, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Computat Intelligence Singapore Chapter, Chinese Assoc Artificial Intelligence				This paper proposed a novel method of applying support vector machine for multi-class problem based on fuzzy integral. Firstly, the fuzzy measure of each binary classifier is constructed based on its classification accuracy during training and its agreement degrees to other support vector machines. Then the testing instances are classified by calculating the fuzzy integral between the fuzzy measures and the outputs of the binary support vector machines. The experiment results on iris and glass datasets from UCI machine learning repository and real plane dataset show that the new method is effective. And the experiment results ulteriorly indicate that the method with Choquet fuzzy integral has better performance than that with Sugeno integral.	Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China; Xian Commun Inst, Lab Network Secur & Countermeasure, Xian 710106, Peoples R China	Zhang, YN (reprint author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.						ANGULO C, 2003, NEUROCOMPUTING, P55; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Cortes, 1995, MACH LEARN, V20, P273; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; GUERMEUR Y, 2000, P IJCNN 00 COM IT; Kecman V., 2001, LEARNING SOFT COMPUT; MOREIRA M, 1998, P 10 EUR C MACH LEAR, P160; MUROFUSHI T, 1991, J MATH ANAL APPL, V159, P532, DOI 10.1016/0022-247X(91)90213-J; Platt J., 1999, ADV LARGE MARGIN CLA; Platt JC, 2000, ADV NEUR IN, V12, P547; Sugeno M., 1977, FUZZY AUTOMATA DECIS, P89; Sungmoon C, 2004, NEURAL INFORM PROCES, V2, P47; TAKAHASHI F, 2002, P 9 INT C NEUR INF P, P1418, DOI 10.1109/ICONIP.2002.1202854; Vapnik, 1995, NATURE STAT LEARNING; Wang L, 2005, SUPPORT VECTOR MACHI; WESTON J, 1998, CSDTR9804 ROY HOLL U; YONG D, 2003, J SHANGHAI JIAOTONG, V37, P1	17	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45907-3	LECT NOTES COMPUT SC			2006	4222						839	846				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFH68	WOS:000241892100107	
S	Tomas, D; Vicedo, JL; Bisbal, E; Moreno, L		Salakoski, T; Ginter, F; Pyysalo, S; Pahikkala, T		Tomas, David; Vicedo, Jose L.; Bisbal, Empar; Moreno, Lidia			Automatic feature extraction for question classification based on dissimilarity of probability distributions	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th International Conference on Natural Language Processing	AUG 23-25, 2006	Turku, FINLAND	Turku Ctr Comp Sci, Univ Turku, Abo Akademi Univ, Turku, NOKIA, Lingsoft, Parc, Sanako				Question classification is one of the first tasks carried out in a Question Answering system. In this paper we present a multilingual question classification system based on machine learning techniques. We use Support Vector Machines to classify the questions. All the features needed to train and test this method are automatically extracted through statistical information in an unsupervised way, comparing Poisson distributions of single words in two plain corpora of questions and documents. Thus, we need nothing but plain text to train the system, obtaining a flexible approach easy to adapt to new languages and domains. We have tested it on a bilingual corpus of questions in English and Spanish.	Univ Alicante, Dept Lenguajes & Sistemas Informat, E-03080 Alicante, Spain; Univ Politecn Valencia, Dept Sistemas Informat & Computac, E-46071 Valencia, Spain	Tomas, D (reprint author), Univ Alicante, Dept Lenguajes & Sistemas Informat, E-03080 Alicante, Spain.	dtomas@dlsi.ua.es; vicedo@dlsi.ua.es; ebisbal@dsic.upv.es; lmoreno@dsic.upv.es					BISBAL E, 2005, P MICAI; HERMJAKOB U, 2001, P ACL 2001 WORKSH OP; LI X, 2002, P COLING; MAGNINI B, CREATING DISEQUA COR; Manning C. D., 1999, FDN STAT NATURAL LAN; TOMAS D, 2005, P APROXIMACION MULTI, P391; Vapnik V., NATURE STAT LEARNING; Witten I. H., 2005, DATA MINING PRACTICA	8	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37334-9	LECT NOTES ARTIF INT			2006	4139						133	140				8	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Computer Science; Linguistics	BEZ38	WOS:000240270400013	
S	Tongchim, S; Sornlertlamvanich, V; Isahara, H		Salakoski, T; Ginter, F; Pyysalo, S; Pahikkala, T		Tongchim, Shisanu; Sornlertlamvanich, Virach; Isahara, Hitoshi			Classification of news web documents based on structural features	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th International Conference on Natural Language Processing	AUG 23-25, 2006	Turku, FINLAND	Turku Ctr Comp Sci, Univ Turku, Abo Akademi Univ, Turku, NOKIA, Lingsoft, Parc, Sanako			PAGE CLASSIFICATION	The motivation of this work comes from the need of a Thai web corpus for testing our information retrieval algorithm. Two collections of news web documents are gathered from two different Thai newspaper web sites. Our goal is to find a simple yet effective method to extract news articles from these web collections. We explore the use of machine learning methods to distinguish article pages from non-article pages, e.g. table of contents, advertisements. Then, the selected web articles are compared in a fine-grained manner in order to find informative structures. Both steps of information extraction utilize the structural features of web documents rather than the extracted keywords or terms. Thus, the inherent errors of word segmentation, one of the major problems in Thai text processing, do not affect to this method.	Natl Inst Informat & Commun Technol, Thai Computat Linguist Lab, Klongluang 12120, Pathumthani, Thailand	Tongchim, S (reprint author), Natl Inst Informat & Commun Technol, Thai Computat Linguist Lab, 112 Paholyothin Rd,Klong 1, Klongluang 12120, Pathumthani, Thailand.	shisanu@tcllab.org; virach@tcllab.org; isahara@nict.go.jp					An AJ, 2004, LECT NOTES COMPUT SC, V3135, P1; COOLEY R, 1997, INT C TOOLS ART INT, P558; CRUZ IF, 1998, LECT NOTES COMPUTER, V1375, P513; GETOOR L, 2003, P 9 ACM SIGKDD INT C; HE J, 2000, ACL 2000, P93; Holden N, 2004, LECT NOTES COMPUT SC, V3242, P1092; SUN A, 2002, WORKSH WEB INF DAT M, P96; Tombros A, 2005, LECT NOTES COMPUT SC, V3408, P487; Witten I. H., 2005, DATA MINING PRACTICA; WONG WC, 2000, ACM SIGMOD WORKSH RE, P96	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37334-9	LECT NOTES ARTIF INT			2006	4139						153	160				8	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Computer Science; Linguistics	BEZ38	WOS:000240270400015	
S	Sass, B		Salakoski, T; Ginter, F; Pyysalo, S; Pahikkala, T		Sass, Balint			Extracting idiomatic Hungarian verb frames	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th International Conference on Natural Language Processing	AUG 23-25, 2006	Turku, FINLAND	Turku Ctr Comp Sci, Univ Turku, Abo Akademi Univ, Turku, NOKIA, Lingsoft, Parc, Sanako				We describe a machine learning method for collecting idiomatic fixed stem verb frames. Firstly we collect frequent frame candidates from the output of a partial parser, secondly we apply a certain idiomaticity metric to the list to get the most idiomatic frames. Running our implemented system we get a list of ten thousand frames of more than 900 verbs which will be translated to English and used as a resource in a Hungarian-to-English machine translation system.	Hungarian Acad Sci, Res Inst Linguist, H-1051 Budapest, Hungary	Sass, B (reprint author), Hungarian Acad Sci, Res Inst Linguist, H-1051 Budapest, Hungary.	joker@nytud.hu					Abney S., 1996, P ESSLLI 96 ROB PARS, P8; BOJAR O, 2005, P MOD APPR TRANSL TE, P2; Brent M. R., 1993, Computational Linguistics, V19; BRISCOE T, 1997, P 5 C APPL NAT LANG; KIS B, 2004, P 4 INT C LANG RES E, V5, P1677; Manning Christopher, 1993, P 31 ANN M ASS COMP, P235, DOI 10.3115/981574.981606; McCarthy D., 2003, P ACL 2003 WORKSH MU, P73; MEGYESI B, 1998, HUNGARIAN LANGUAGE; SASS B, 2005, P 3 MAGY SZAM NYEL K, P257; TAPANAINEN P, 1998, P COLING ACL 98, P1289; VARADI T, 2002, P 3 INT C LANG RES E, P385; ZEMAN D, 2000, P 2 INT C LANG RES E	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37334-9	LECT NOTES ARTIF INT			2006	4139						303	309				7	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Computer Science; Linguistics	BEZ38	WOS:000240270400029	
S	Goddard, J; MacKinney-Romero, R		Salakoski, T; Ginter, F; Pyysalo, S; Pahikkala, T		Goddard, John; MacKinney-Romero, Rene			Finding Spanish syllabification rules with decision trees	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th International Conference on Natural Language Processing	AUG 23-25, 2006	Turku, FINLAND	Turku Ctr Comp Sci, Univ Turku, Abo Akademi Univ, Turku, NOKIA, Lingsoft, Parc, Sanako		automatic syllabification; decision trees; machine learning		Syllables have been proposed as a viable alternative to phonemes for automatic speech recognition, and for use in text-to-speech systems as a way to enhance the speech quality. The question then arises of how to obtain the correct syllabification rules for a particular language. Even for a language like Spanish, which has well defined syllabification rules, linguistic knowledge is often required to discover them. It is interesting to ask whether machine learning techniques can produce effective syllabification algorithms, and our aim here is to test the usefulness of classification trees for this task. Additionally, we would like to understand the sort of problems that arise in the process, with a view to applying it to other languages.	Univ Autonoma Metropolitana, Dept Ingn Elect, Mexico City 09950, DF, Mexico	Goddard, J (reprint author), Univ Autonoma Metropolitana, Dept Ingn Elect, Mexico City 09950, DF, Mexico.	jgc@xanum.uam.mx; rene@xanum.uam.mx					BELZ A, 2000, THESIS U SUSSEX; FIGUEROA K, 1998, THESIS U MICHOACANA; Ganapathiraju A, 2001, IEEE T SPEECH AUDI P, V9, P358, DOI 10.1109/89.917681; GODDARD J, 2005, 10 INT C SPEECH COMP, P251; Greenberg S, 1999, SPEECH COMMUN, V29, P159, DOI 10.1016/S0167-6393(99)00050-3; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; LOPEZGONZALO E, 1996, ICSLP 96, V3; MacKinney-Romero R, 2005, LECT NOTES ARTIF INT, V3789, P800; MULLER K, AIMS 2002, V8; Nerbonne J, 2004, ADV SOFT COMP, P493; OLIVEIRA C, 2005, INTERSPEECH, P2933; OSTENDORF M, 1999, P ASRU KEYST COL; RAO MN, 2005, P NATL C COMM IIT IN, P277; SAAVEDRA MD, 2005, WORKS M DECERVANTES; TIAN J, 2004, INTERSPEECH 2004, P61	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37334-9	LECT NOTES ARTIF INT			2006	4139						333	340				8	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Computer Science; Linguistics	BEZ38	WOS:000240270400032	
S	Izumi, E; Uchimoto, K; Isahara, H		Salakoski, T; Ginter, F; Pyysalo, S; Pahikkala, T		Izumi, Emi; Uchimoto, Kiyotaka; Isahara, Hitoshi			Measuring intelligibility of Japanese learner English	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th International Conference on Natural Language Processing	AUG 23-25, 2006	Turku, FINLAND	Turku Ctr Comp Sci, Univ Turku, Abo Akademi Univ, Turku, NOKIA, Lingsoft, Parc, Sanako				Although pursuing accuracy is important in language learning or teaching, knowing what types of errors interfere with communication and what types do not would be more beneficial for efficiently enhancing communicative competence. Language learners could be greatly helped by a system that detected errors in learner language and automatically measured their effect on intelligibility. In this paper, we reported our attempt, based on machine learning, to measure the intelligibility of learner language. In the learning process, the system referred to the BLEU and NIST scores between the learners' original sentences and their back translation (or corrected sentences), the log-probability of the parse, sentence length, and error types (manually or automatically assigned) as a key feature. We found that the system can distinguish between intelligible sentences and others (unnatural and unintelligible) rather successfully, but still has a lot of difficulties in distinguishing the three levels of intelligibility.	Natl Inst Informat & Commun Technol, Computat Linguist Grp, Kyoto 6190289, Japan	Izumi, E (reprint author), Natl Inst Informat & Commun Technol, Computat Linguist Grp, 3-5 Hikaridai, Kyoto 6190289, Japan.	emi@nict.go.jp; uchimoto@nict.go.jp; isahara@nict.go.jp					Briscoe E., 2002, P 3 INT C LANG RES E, P1499; BURNSTEIN J, 2003, AUTOMATED ESSAY SCOR, P113; Canale M., 1980, APPLIED LINGUISTICS, V1, P1, DOI DOI 10.1093/APPLIN/I.1.1; Ellis R., 2003, TASK BASED LANGUAGE; Izumi E., 2003, P 41 ANN M ASS COMP, P145; Izumia E., 2004, ICAME J, V28, P31; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Kudo T., 2001, P 2 M N AM CHAPT ASS, P192; Larkey L. S., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290965; NIST, 2002, AUT EV MACH TRANSL Q; PAGE EB, 1995, PHI DELTA KAPPAN, V76, P561; PAGE EB, 1994, J EXP EDUC, V62, P127; Papineni K., 2002, P 40 ANN M ASS COMP, P311; Shermis MD, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, pXIII; Skehan P., 1998, COGNITIVE APPROACH L; UCHIMOTO K, 2005, P MT SUMM 10 THAIL, P235; WILLE R, 2001, P INT WORKSH LATT BA, P7	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37334-9	LECT NOTES ARTIF INT			2006	4139						476	487				12	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Computer Science; Linguistics	BEZ38	WOS:000240270400046	
S	Kozareva, Z; Montoyo, A		Salakoski, T; Ginter, F; Pyysalo, S; Pahikkala, T		Kozareva, Zornitsa; Montoyo, Andres			Paraphrase identification on the basis of supervised machine learning techniques	ADVANCES IN NATURAL LANGUAGE PROCESSING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th International Conference on Natural Language Processing	AUG 23-25, 2006	Turku, FINLAND	Turku Ctr Comp Sci, Univ Turku, Abo Akademi Univ, Turku, NOKIA, Lingsoft, Parc, Sanako				This paper presents a machine learning approach for paraphrase identification which uses lexical and semantic similarity information. In the experimental studies, we examine the limitations of the designed attributes and the behavior of three machine learning classifiers. With the objective to increase the final performance of the system, we scrutinize the influence of the combination of lexical and semantic information, as well as techniques for classifier combination.	Univ Alicante, Dept Lenguajes & Sistemas Informat, Alicante, Spain	Kozareva, Z (reprint author), Univ Alicante, Dept Lenguajes & Sistemas Informat, Alicante, Spain.	zkozareva@dlsi.ua.es; montoyo@dlsi.ua.es					Barzilay R, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P16; Barzilay R, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P50; BROCKETT C, 2 INT JOINT C NAT LA; COHEN J, 1960, ED PSYCHOL MEAS; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; CORLEY C, P ACL WORKSH EMP MOD; DAELEMANS W, 2003, 0310 ILK TILB U; DAGAN I, P PASCAL CHALL WORKS; DAGAN I, PASCAL WORKSH LEARN; DOLAN WB, INT C COMP LING COLI; GLICKMAN O, RECENT ADV NATURAL L, V3; KOZAREVA Z, 2006, 11 INT C APPL NAT LA; LIN CY, 2003, C N AM CHAPT ASS COM, P71; Lin D, 1998, P 15 INT C MACH LEAR, P296; PASCA M, 2005, IJCNLP, P119; PATWARDHAN S, P 4 INT C INT TEXT P; PEDERSEN T, P 40 ANN M ASS COMP; QUIRK C, P C EMP METH NAT LAN; Schmid H., 1994, INT C NEW METH LANG; SHINYAMA Y, 2002, AUTOMATIC PARAPHRASE; SUAREZ A, 2002, COLING	21	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37334-9	LECT NOTES ARTIF INT			2006	4139						524	533				10	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Computer Science; Linguistics	BEZ38	WOS:000240270400050	
S	Liu, HB; Xiong, SW; Niu, XX		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, HJ		Liu, Hong-Bing; Xiong, Sheng-Wu; Niu, Xiao-Xiao			Fuzzy support vector machines based on spherical regions	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 1	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISSN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong				Fuzzy Support Vector Machines (FSVMs) based on spherical regions are proposed in this paper. Firstly, the center of the spherite is determined by all the training data. Secondly, the membership functions are defined with the distances between each data and the center of the spherite. Thirdly, using the suitable parameter A, FSVMs are formed on the spherical regions. One-against-one decision strategy of FSVMs is adopted so that the proposed FSVMs can be extended to solve multi-class problems. In order to verify the superiority of the proposed FSVMs, the traditional two-class and multi-class problems of machine learning benchmark datasets are used to test the feasibility and performance of the proposed FSVMs. The experiment results indicate that the new approach not only has higher precision but also downsizes the number of training data and reduces the running time.	Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430070, Peoples R China; Xinyang Normal Univ, Dept Comp Sci, Xinyang 464000, Peoples R China	Liu, HB (reprint author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430070, Peoples R China.	liuhbing@sohu.com; xiongsw@mail.whut.edu.cn; archer_nxx@hotmail.com					Abe S., 2003, P INT C COMP INT MOD, P385; Buciu L., 2001, Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205), DOI 10.1109/ICIP.2001.959230; Huang H. P., 2002, INT J FUZZY SYST, V4, P826; INOUE T, 2001, P IJCNN 01, P1449; MONTGOMEY DC, 2001, DESIGN ANAL EXPT; Vapnik VN, 1998, STAT LEARNING THEORY; Wee JW, 2004, LECT NOTES COMPUT SC, V3316, P1129; XIONG SW, 2005, P 2005 INT C MACH LE, V5, P2608; XIONG SW, 2005, P INT C MACH LEARN C, V9, P4345	9	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34439-X	LECT NOTES COMPUT SC			2006	3971		1				949	954				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEM20	WOS:000238112000139	
S	Yu, S; Yang, XW; Hao, ZF; Liang, YC		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, HJ		Yu, Shu; Yang, Xiaowei; Hao, Zhifeng; Liang, Yanchun			An adaptive support vector machine learning algorithm for large classification problem	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 1	Lecture Notes in Computer Science		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISNN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Elect Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn, Hong Kong			SMO ALGORITHM; SVM; CONVERGENCE; CLASSIFIERS; DESIGN	Based on the incremental and decreniental learning stratecies. an adaptive support vector machine learning algorithm (ASVM) is presented for large classification problems in this paper. In the proposed algorithm, the incremental and decremental procedures are performed alternatively, and a small scale working set, which can cover most of the information in the training set and overcome the drawback of losing the sparseness in least squares support vector machine (LS-SVM), can be formed adaptively. The classifier can be constructed by using this working set. In general, the number of the elements in the working set is much smaller than that in the training set. Therefore the proposed algorithm can be used not only to train the data sets quickly but also to test them effectively with losing little accuracy. In order to examine the training speed and the generalization performance of the proposed algoorithm. we apply both ASVM and LS-SVM to seven UCI datasets and a benchmark problem. Experimental results show that the novel algorithm is very faster than LS-SVM and loses little accuracy in solving large classification problems.	S China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510640, Peoples R China; S China Univ Technol, Sch Math Sci, Guangzhou 510640, Peoples R China; Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China	Yu, S (reprint author), S China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510640, Peoples R China.						Cauwenberghs G, 2001, ADV NEUR IN, V13, P409; Chua KS, 2003, PATTERN RECOGN LETT, V24, P75, DOI 10.1016/S0167-8655(02)00190-3; Fine S, 2002, J MACH LEARN RES, V2, P243, DOI 10.1162/15324430260185619; Sun Jian, 2002, Journal of Software, V13; Joachims T., 1998, ADV KERNEL METHODS S, P169; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Keerthi SS, 2002, MACH LEARN, V46, P351, DOI 10.1023/A:1012431217818; Lau KW, 2003, PATTERN RECOGN, V36, P1913, DOI 10.1016/S0031-3203(03)00038-4; Li Jian-Min, 2003, Journal of Software, V14; Lin CJ, 2001, IEEE T NEURAL NETWOR, V12, P1288, DOI 10.1109/72.963765; Liu JH, 2003, J UNIV SCI TECHNOL B, V10, P73; Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218; Mangasarian OL, 1999, IEEE T NEURAL NETWOR, V10, P1032, DOI 10.1109/72.788643; Murphy P.M., 1992, UCI REPOSITORY MACHI; Osuna E., 1997, IEEE WORKSH NEUR NET, P276; Platt J. C., 1998, ADV KERNEL METHODS S, P185; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Suykens JAK, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL II, P757; Van G. T., 2004, MACH LEARN, V54, P5; Vapnik V. N, 1995, NATURE STAT LEARNING; Yang XW, 2004, PROG NAT SCI, V14, P519, DOI 10.1080/10020070412331343881	21	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34439-X	LECT NOTES COMPUT SC			2006	3971		1				981	990				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEM20	WOS:000238112000144	
S	Wei, XK; Li, YH; Feng, Y		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, HJ		Wei, Xun-Kai; Li, Ying-Hong; Feng, Yue			Comparative study of extreme learning machine and support vector machine	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 1	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISSN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong				Comparative study of extreme learning machine (ELM) and support vector machine (SVM) is investigated in this paper. A cross validation method for determining the appropriate number of neurons in the hidden layer is also proposed in this paper. ELM proposed by Huang, et al [3] is a novel machine-learning algorithm for single hidden-layer feedforward neural network (SLFN), which randomly chooses the input weights and hidden-layer bias, and analytically determines the output weights optimally instead of tuning them. This algorithm tends to produce good generalization ability and obtain least experience risk simultaneously with solid foundations. Benchmark tests of a real Tennessee Eastman Process (TEP) are carried out to validate its superiority. Compared with SVM, this proposed algorithm is much faster and has better generalization performance than SVM in the case studied in this paper.	AF Engn Univ, Sch Engn, Xian 710038, Peoples R China	Wei, XK (reprint author), AF Engn Univ, Sch Engn, Xian 710038, Peoples R China.	skyhawkf119@163.com; yinghong_li@163.com; fengy1228@163.com					Chapelle O, 2000, ADV NEUR IN, V12, P230; HUANG B, 2004, P INT JOINT C NEUR N, P25; Huang GB, 2003, IEEE T NEURAL NETWOR, V14, P274, DOI 10.1109/TNN.2003.809401; Vapnik VN, 1998, STAT LEARNING THEORY	4	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34439-X	LECT NOTES COMPUT SC			2006	3971		1				1089	1095				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEM20	WOS:000238112000160	
S	Attik, M		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, HJ		Attik, Mohammed			Using ensemble feature selection approach in selecting subset with relevant features	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 1	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISSN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong				This study discusses the problem of feature selection as one of the most fundamental problems in the field of the machine learning. Two novel approaches for feature selection in order to select a subset with relevant features are proposed. These approaches can be considered as a direct extension of the ensemble feature selection approach. The first one deals with identifying relevant features by using a single feature selection method. While, the second one uses different feature selection methods in order to identify more correctly the relevant features. An illustration shows the effectiveness of the proposed methods on artificial databases where we have a priori the informations about the relevant features.	Inst Natl Rech Informat & Automat Lorraine, LORIA, F-54506 Vandoeuvre Les Nancy, France	Attik, M (reprint author), Inst Natl Rech Informat & Automat Lorraine, LORIA, Campus Sci,BP 239, F-54506 Vandoeuvre Les Nancy, France.	Mohammed.Attik@loria.fr					ATTIK M, 2004, IJCNN 04; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Hassibi B, 1993, ADV NEURAL INFORMATI, V5, P164; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LECUN Y, 1990, P 1989 C, P598; PIRAMUTHU S, 1995, HICSS, P294; Rendell L.A., 1992, P 10 NAT C ART INT, P129; Stahlberger A, 1997, ADV NEUR IN, V9, P655; VALENTINI G, 2002, ENSEMBLES LEARNING M	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34439-X	LECT NOTES COMPUT SC			2006	3971		1				1359	1366				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEM20	WOS:000238112000202	
S	Wang, XD; Zhang, HR; Zhang, CJ; Cai, XS; Wang, JS; Ye, MY		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, H		Wang, Xiaodong; Zhang, Haoran; Zhang, Changjiang; Cai, Xiushan; Wang, Jinshan; Ye, Meiying			Time series prediction using LS-SVM with particle swarm optimization	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISNN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong				Time series analysis is an important and complex problem in machine learning. In this paper, least squares support vector machine (LS-SVM) combined with particle swarm optimization (PSO) is used to time series prediction. The LS-SVM can overcome some shortcoming in the multilayer perceptron (MLP) and the PSO is used to tune the LS-SVM parameters automatically. A benchmark problem, Henon map time series, has been used as an example for demonstration. It is showed this approach can escape from the blindness of man-made choice of the LS-SVM parameters. It enhances the efficiency and the capability of prediction.	Zhejiang Normal Univ, Coll Informat Sci & Engn, Jinhua 321004, Peoples R China; Zhejiang Normal Univ, Coll Math & Phys, Jinhua 321004, Peoples R China	Wang, XD (reprint author), Zhejiang Normal Univ, Coll Informat Sci & Engn, Jinhua 321004, Peoples R China.	Wxd@zjnu.cn; Hylt@zjnu.cn; Zcj74922@zjnu.cn; Xiushan@zjnu.cn; Dz66@zjnu.cn; Ymy@zjnu.cn					Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X; Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81; Kennedy J., 2001, SWARM INTELLIGENCE; Kennedy J., 1995, P IEEE INT C NEUR NE, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742	6	6	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34437-3	LECT NOTES COMPUT SC			2006	3972						747	752				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BET84	WOS:000239483000110	
S	Xu, R; Venayagamoorthy, G; Wunsch, DC		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, H		Xu, Rui; Venayagamoorthy, Ganesh; Wunsch, Donald C., II			A study of particle swarm optimization in gene regulatory networks inference	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISNN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong			MODELS	Gene regulatory inference from time series gene expression data, generated from DNA microarray, has become increasingly important in investigating genes functions and unveiling fundamental cellular processes. Computational methods in machine learning and neural networks play an active role in analyzing the obtained data. Here, we investigate the performance of particle swarm optimization (PSO) on the reconstruction of gene networks, which is modeled with recurrent neural networks (RNN). The experimental results on a synthetic data set are presented to show the parameter effects of PSO on RNN training and the effectiveness of the proposed method in revealing the gene relations.	Univ Missouri, Appl Computat Intelligence Lab, Rolla, MO 65409 USA; Univ Missouri, Real Time Power & Intelligent Syst Lab, Dept Elect & Comp Engn, Rolla, MO 65409 USA	Xu, R (reprint author), Univ Missouri, Appl Computat Intelligence Lab, Rolla, MO 65409 USA.	rxu@umr.edu; ganeshv@umr.edu; dwunsch@umr.edu					De Jong H, 2002, J COMPUT BIOL, V9, P67, DOI 10.1089/10665270252833208; DHAESELEER P, 2000, THESIS U NEW MEXICO; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Gudise VG, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P110, DOI 10.1109/SIS.2003.1202255; Jaeger H., 2002, 159 GMD GERM NAT RES; Kennedy J., 2001, SWARM INTELLIGENCE; Kolen J. F., 2001, FIELD GUIDE DYNAMICA; McLachlan G. J., 2004, ANAL MICROARRAY GENE; MURPHY K., 1999, MODELING GENE EXPRES; Perrin B., 2003, BIOINFORMATICS, V19, pII138; Shmulevich I, 2002, P IEEE, V90, P1778, DOI 10.1109/JPROC.2002.804686; Wahde M, 2000, BIOSYSTEMS, V55, P129, DOI 10.1016/S0303-2647(99)00090-8; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; Xu R, 2004, P ANN INT IEEE EMBS, V26, P2905; Yao X, 1999, P IEEE, V87, P1423	16	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34482-9	LECT NOTES COMPUT SC			2006	3973						648	653				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BET87	WOS:000239485300095	
S	Yang, Y; Lu, BL		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, H		Yang, Yang; Lu, Bao-Liang			Prediction of protein subcellular multi-locations with a min-max modular support vector machine	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 3, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISNN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Elect Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn, Hong Kong			AMINO-ACID-COMPOSITION; LOCALIZATION	How to predict subcellular multi-locations of proteins with machine learning techniques is a challenging problem in computational biology community. Regarding the protein multi-location problem as a multi-label pattern classification problem, we propose a new predicting method for dealing with the protein subcellular localization problem in this paper. Two key points of the proposed method are to divide a seriously unbalanced multi-location problem into a number of more balanced two-class subproblems by using the part-versus-part task decomposition approach, and learn all of the subproblems by using the min-max modular support vector machine (M3-SVM). To evaluate the effectiveness of the proposed method, we perform experiments on yeast protein data set by using two kinds of task decomposition strategies and three kinds of feature extraction methods. The experimental results demonstrate that our method achieves the highest prediction accuracy, which is much better than that obtained by the existing approach based on the traditional support vector machine.	Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China	Lu, BL (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dong Chuan Rd, Shanghai 200240, Peoples R China.	alayman@sjtu.edu.cn; bllu@sjtu.edu.cn; bllu@sjtu.edu.cn					Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHEN K, 2005, BCMITR0501 SHANGH JI; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; FUJIWARA Y, 1997, GENOME INFORMATICS, P53; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; JOACHIMS T., 2002, LEARNING CLASSIFY TE; Liu FY, 2005, IEEE IJCNN, P570; LU BL, 2005, P INT JOINT C NEUR N, P735; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Yang Y, 2005, Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology, P288	14	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34482-9	LECT NOTES COMPUT SC			2006	3973						667	673				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BET87	WOS:000239485300098	
S	Handoko, SD; Keong, KC; Soon, OY; Zhang, GL; Brusic, V		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, H		Handoko, Stephanus Daniel; Keong, Kwoh Chee; Soon, Ong Yew; Zhang, Guang Lan; Brusic, Vladimir			Extreme learning machine for predicting HLA-peptide binding	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISNN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong			CLASS-I MOLECULES; NEURAL-NETWORK; EPITOPES	Machine learning techniques have been recognized as powerful tools for learning from data. One of the most popular learning techniques, the Back-Propagation (BP) Artificial Neural Networks, can be used as a computer model to predict peptides binding to the Human Leukocyte Antigens (HLA). The major advantage of computational screening is that it reduces the number of wet-lab experiments that need to be performed, significantly reducing the cost and time. A recently developed method, Extreme Learning Machine (ELM), which has superior properties over BP has been investigated to accomplish such tasks. In our work, we found that the ELM is as good as, if not better than, the BP in term of time complexity, accuracy deviations across experiments, and most importantly - prevention from over-fitting for prediction of peptide binding to HLA.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; Inst Infocomm Res, Singapore 1196131, Singapore; Univ Queensland, Sch Land & Food Sci, Brisbane, Qld 4072, Australia; Univ Queensland, Inst Mol Biosci, Brisbane, Qld 4072, Australia	Handoko, SD (reprint author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.		Ong, YS/A-3733-2011				Albert A., 1972, REGRESSION MOOREPENR; Brusic V, 1998, BIOINFORMATICS, V14, P121, DOI 10.1093/bioinformatics/14.2.121; Brusic V, 2002, IMMUNOL CELL BIOL, V80, P280, DOI 10.1046/j.1440-1711.2002.01088.x; BRUSIC V, 2004, COMPUTATIONAL METHOD, V34, P436; Donnes P, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-25; Duda R. O., 2001, PATTERN CLASSIFICATI; Hattotuwagama CK, 2004, J MOL GRAPH MODEL, V22, P195, DOI 10.1016/S1093-3263(03)00160-8; Honeyman MC, 1998, NAT BIOTECHNOL, V16, P966, DOI 10.1038/nbt1098-966; HUANG GB, 2004, EXTREME LEARNING MAC; Janeway C. A., 2001, IMMUNOBIOLOGY; Marsh SGE, 2005, TISSUE ANTIGENS, V65, P301, DOI 10.1111/j.1399-0039.2005.00379.x; Peters B, 2003, BIOINFORMATICS, V19, P1765, DOI 10.1093/bioinformatics/btg24; SAVOIE CJ, 1999, USE BONSAI DECISION, P182; Schueler-Furman O, 2000, PROTEIN SCI, V9, P1838; Williams TM, 2001, J MOL DIAGN, V3, P98, DOI 10.1016/S1525-1578(10)60658-7; Yu K, 2002, MOL MED, V8, P137; Zhang Guang Lan, 2005, Journal of Bioinformatics and Computational Biology, V3, P1207, DOI 10.1142/S0219720005001466; Zurada J.M., 1999, INTRO ARTIFICIAL NEU	18	5	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34482-9	LECT NOTES COMPUT SC			2006	3973						716	721				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BET87	WOS:000239485300105	
S	Han, SS; Hong, SJ		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, H		Han, Seung-Soo; Hong, Sang Jeen			Polynomial neural network modeling of reactive ion etching process using GMDH method	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISNN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong				The construction of models for prediction and control of initially unknown, potentially nonlinear system is a difficult, fundamental problem in machine learning and engineering control. Since the neural network as a tool for machine learning was introduced, significant progress has been made on data handling and learning algorithms. Currently, the most popular learning algorithm in neural network training is feed forward error back-propagation (FFEBP) algorithm. Aside from the success of the FFEBP algorithm, a polynomial neural networks (PNN) learning has been proposed as a new learning method. The PNN learning is a self-organizing process designed to determine an appropriate set of Ivakhnenko polynomials that allow the activation of many neurons to achieve a desired state of activation that mimics a given set of sampled patterns. These neurons are interconnected in such a way that the knowledge is stored in Ivakhnenko coefficients. In this paper, PNN model has been developed using the nonlinear reactive ion etching (RIE) experimental data utilizing Group Method of Data Handling (GMDH). To characterize the RIE process using PNN, a low-k dielectric polymer benzocyclobutene (BCB) is etched in an SF6 and O-2 plasma in parallel plate system. Data from 2(4) factorial experimental design to characterize etch process variation with controllable input factors consisting of the two gas flows, RF power and chamber pressure are used to build PNN models of etch rate, uniformity, selectivity and anisotropy. The modeling and prediction performance of PNN is compared with those of FFEBP. The results show that the prediction capability of the PNN models is at least 16.9% better than that of the conventional neural network models.	Myongji Univ, Dept Informat Engn, Yongin, Gyeonggi, South Korea; Myongji Univ, NPT Ctr, Yongin, Gyeonggi, South Korea; Myongji Univ, Nanbio Res Ctr, Yongin, Gyeonggi, South Korea	Han, SS (reprint author), Myongji Univ, Dept Informat Engn, Yongin, Gyeonggi, South Korea.	shan@mju.ac.kr; samhong@mju.ac.kr					Box GEP, 1978, STAT EXPT; Farlow J., 1984, SELF ORG METHODS MOD; HAN SS, 1994, IEEE T COMPON PACK A, V17, P174, DOI 10.1109/95.296398; HIMMEL CD, 1993, IEEE T SEMICONDUCT M, V6, P103, DOI 10.1109/66.216928; Ivakhnenko A., 1968, SOVIET AUTOMAT CONTR, V13; Kim B, 2003, IEEE T PLASMA SCI, V31, P317, DOI 10.1109/TPS.2003.812348; Madala H., 1944, INDUCTIVE LEARNING A, P1; MAY G, 1991, IEEE T SEMI MANUFAC, V4; Mocella M., 1991, SPIE P MODULE METROL, V1594, P232; ROGER B, 1994, INT J MICRO ELECT PA, V17	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34482-9	LECT NOTES COMPUT SC			2006	3973						1043	1052				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BET87	WOS:000239485300152	
S	Han, B; Kang, LS; Song, HZ		Wang, J; Yi, Z; Zurada, JM; Lu, BL; Yin, H		Han, Bo; Kang, Lishan; Song, Huazhu			A fast cloud detection approach by integration of image segmentation and support vector machine	ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Symposium on Neural Networks (ISNN 2006)	MAY 28-31, 2006	Chengdu, PEOPLES R CHINA	Univ Electr Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn Hong Kong			CLASSIFICATION; MODIS	We proposed a fast cloud detection approach for the geophysical data from Moderate Resolution Imaging Spectroradiometer (MODIS), a premium instrument aboard on NASA's satellite Terra to study clouds and aerosols. Previous pixel-based classifiers have been developed for remote-sensing instruments using various machine learning techniques, such as artificial neural networks (ANNs), support vector machines (SVMs). However, their computational costs are very expensive. Our novel approach integrated image segmentation and SVMs together to achieve the similar classification accuracy while using much less computation costs. It exploited the homogeneous property in local spatial sub-regions and used radiance information from sub-regions, rather than pixels, to build classifiers. The experimental results showed the proposed approach not only greatly speed up the classification training procedure, but also provide insights for domain experts to reveal different cloud types.	Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China; Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430070, Peoples R China	Han, B (reprint author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.	hanboemail@yahoo.com					Ackerman SA, 1998, J GEOPHYS RES-ATMOS, V103, P32141, DOI 10.1029/1998JD200032; AZIMISADJADI MR, 2000, P IEEE GEOSC REM SEN, V2, P669; BANKERT R, 2005, NAVAL RES LAB MONTER; HAN B, 2005, 8 INT C INF FUS; Lee Y, 2004, J ATMOS OCEAN TECH, V21, P159, DOI 10.1175/1520-0426(2004)021<0159:CCOSRD>2.0.CO;2; Li J, 2003, J APPL METEOROL, V42, P204, DOI 10.1175/1520-0450(2003)042<0204:HSRSAC>2.0.CO;2; MAZZONI AH, 2005, P 8 WORKSH MIN SCI E; Tian B, 2000, IEEE T NEURAL NETWOR, V11, P903, DOI 10.1109/72.857771; Vapnik V. N, 1995, NATURE STAT LEARNING	9	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34482-9	LECT NOTES COMPUT SC			2006	3973						1210	1215				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BET87	WOS:000239485300176	
S	Ittycheriah, A		Strzalkowski, T; Harabagiu, S	Springer	Ittycheriah, Abraham			A STATISTICAL APPROACH FOR OPEN DOMAIN QUESTION ANSWERING	ADVANCES IN OPEN DOMAIN QUESTION ANSWERING	Text Speech and Language Technology		English	Article; Book Chapter							NATURAL-LANGUAGE; MODELS	This chapter investigates a statistical approach to open domain question answering. Although the work presented in this chapter centers around maximum entropy models, the models required can be modelled using any machine learning approach. To perform question answering, as has been discussed in previous chapters, questions are first analyzed and a prediction is made as to what type of answer the user is expecting. Secondly, a fast search of the text database is performed and the top documents relevant to the query are retrieved. These documents have been annotated automatically using a named entity tagger. Finally, the answer tag prediction and the annotated documents are input to the answer selection stage. Results obtained from a trainable answer selection algorithm are reported.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Ittycheriah, A (reprint author), IBM Corp, Thomas J Watson Res Ctr, 1101 Kitchawan Rd,Bldg 801, Yorktown Hts, NY 10598 USA.	abei@us.ibm.com					BERGER A, 2000, RES DEV INFORM RETRI, P192; BERGER A, 1998, P 3 C EMP METH NAT L, P97; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Borthwick A., 1998, P 6 WORKSH VER LARG, P152; BRILL E, 2001, TREC2001, P393; BRILL E, 1993, P 31 ANN M ACL COL O, P543; BROWN K, 1999, CONCISE ENCY GRAMMAT; Brown P. F., 1993, Computational Linguistics, V19; BURKE R, 1997, TR9705 U CHIC; CLARKE C, 2001, TREC 10 P, P673; Collins M., 1996, P 34 ANN M ASS COMP, P184, DOI 10.3115/981863.981888; Cover TM, 1991, ELEMENTS INFORM THEO; CSISZAR I, 1989, ANN STAT, V17, P1409, DOI 10.1214/aos/1176347279; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Frakes W.B., 1992, INFORM RETRIEVAL DAT; GE N, 2000, THESIS BROWN U; Green B., 1963, COMPUT THOUGHT, P207; HARABAGIU S, 2000, TREC 9 P, P50; HOBBS J, 1976, TR761 CUNY CIT COLL; ITTYCHERIAH A, 2000, TREC 9 P, P60; Ittycheriah A, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P33; Jaynes E. T., 1983, PAPERS PROBABILITY S; KOELING R, 2000, P CONLL 2000 LLL 200, P139; LI X, 2002, COLING 2002 19 INT C, P556; Marcus M. P., 1993, COMPUTATIONAL LINGUI, V19, P313; MIKHEEV A, 1997, ONL P MUC 7, P1; Miller G. A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; MOLDOVAN D, 1999, TREC 8 P, P65; MORTON T, 1999, ACL WORKSH COR ITS A, P173; Ng HT, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P124; PAPINENI K, 2001, 2 M N AM CHAPT ASS C, V10, P25; PIETRA SD, 1995, CMUCS95144 DEP COMP; Ratnaparkhi A., 1998, THESIS U PENNSYLVANI; RATNAPARKHI A, 1998, COLING ACL 1998, P1079; Ratnaparkhi A., 1994, P INT C SPOK LANG PR, P803; Ratnaparkhi A, 1999, MACH LEARN, V34, P151, DOI 10.1023/A:1007502103375; Ravichandran D., 2002, P 40 ANN M ASS COMP, P41; Reynar J., 1997, P 5 C APPL NAT LANG, P16, DOI 10.3115/974557.974561; Robertson S., 1995, NIST SPECIAL PUBLICA; SOUBBOTIN MM, 2001, TREC 10 P, P293; SRIHARI R, 1999, TREC8 P, P75; XU J, 1996, RES DEV INFORM RETRI, P4; YANG H, 2002, TREC 11 NOT P	43	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1386-291X	978-1-4020-4746-6	TEXT SPEECH LANG TEC			2006	32						35	69			10.1007/978-1-4020-4746-6	35	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Language & Linguistics	Computer Science; Linguistics	BLA56	WOS:000269770600004	
S	Riloff, E; Mann, GS; Phillips, W		Strzalkowski, T; Harabagiu, S	Springer	Riloff, Ellen; Mann, Gideon S.; Phillips, William			REVERSE-ENGINEERING QUESTION/ANSWER COLLECTIONS FROM ORDINARY TEXT	ADVANCES IN OPEN DOMAIN QUESTION ANSWERING	Text Speech and Language Technology		English	Article; Book Chapter								Researchers have begun to investigate the use of statistical and machine learning methods for question answering. These techniques require training data, usually in the form of question/answer sets. In this chapter, we describe a reverse-engineering procedure that can be used to generate question/answer sets automatically from ordinary text corpora. Our technique identifies sentences that are good candidates for question/answer extraction, extracts the portions of the sentence corresponding to the question and the answer, and then transforms the information into an actual question and answer. Using this procedure, a collection of questions and answers can be automatically generated from any text corpus. One key benefit of this automatic procedure is that question/answer sets can be easily generated from domain-specific corpora, creating training data which could be used to build a Q/A system tailored for a specific domain.	[Riloff, Ellen; Phillips, William] Univ Utah, Salt Lake City, UT 84112 USA; [Mann, Gideon S.] Univ Massachusetts, Amherst, MA 01003 USA	Riloff, E (reprint author), Univ Utah, Salt Lake City, UT 84112 USA.	riloff@cs.utah.edu; gideon.mann@gmail.com; phillips@cs.utah.edu					BARZILAY R, 2001, P ACL EACL TOUL FRAN; BERGER A., 2000, P 23 ANN INT ACM SIG, P192, DOI 10.1145/345508.345576; Brill E, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P257; Caraballo S. A., 1999, P 37 ANN M ASS COMP; CHARNIAK E, 2000, ANLP NAACL WORKSH RE; Charniak E., 1993, STAT LANGUAGE LEARNI; CHURCH K, 1989, P 2 C APPL NAT LANG; FLEISCHMAN M, 2003, ANN M ASS C IN PRESS; FUJII A, 2001, WORKSH OP DOM QUEST; GIRJU R, 2001, STUD RES WORKSH P 2; HARABAGIU S, 2000, P TREC 9; Hearst M. A., 1992, P 14 INT C COMP LING; HERMJAKOB U, 2001, WORKSH OP DOM QUEST; HIRSCHMAN L, 1999, P 37 ANN M ASS COMP; ITTYCHERIAH A, 2003, ADV OPEN DOMAIN QUES; ITTYCHERIAH A, 2001, P 2 M N AM CHAPT ASS, P33; JACQUEMIN C, 1997, P ACL EACL BARC SPAI; LIGHT M, 2001, J NATURAL LANGUAGE E; LIN DK, 2002, J NATURAL LANGUAGE E; MACDONALD G, 1999, PHISHY WEB TRIVIA; MANN GS, 2001, WORKSH OP DOM QUEST, P23; MANN GS, 2002, P SEMANET02 BUILD US; MANN GS, 2002, P 19 INT C COMP LING; Marcus M., 1993, COMPUTATIONAL LINGUI, V19, P313; Miller G. A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; MOLDOVAN D, 2003, P HLT NAACL 2003, P166; National Institute of Standards and Technology, 2002, SPEC PUBL NAT I STAN; NG HT, 2000, P EMNLP VLC 2000 ACL; NG HT, 2001, P C EMP METH NAT LAN; Ng HT, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P124; PHILLIPS W, 2002, P 2002 C EMP METH NA; PRAGER J, 2002, HUM LANG TECHN C; PRAGER JM, 2003, ADV OPEN DOMAIN QUES; RADEV DR, 2000, P 6 C APPL NAT LANG, P150, DOI 10.3115/974147.974168; Ravichandran D, 2002, P 40 ANN M ASS COMP; Riloff E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1044; Riloff E., 1999, P 16 NAT C ART INT; RILOFF E, 2000, ANLP NAACL WORKSH RE; RILOFF E, 1999, J NATURAL LANGUAGE E, V5, P147; Roark Brian, 1998, P 36 ANN M ASS COMP, P1110; STRZALKOWSKI T, 1997, ANLP, P299; Thelen M., 2002, P 2002 C EMP METH NA; Turtle H., 1991, P RIA0 91 C, P644; Wang W., 2000, ANLP NAACL WORKSH RE; Weischedel R., 1993, Computational Linguistics, V19; YANGARBER R., 2000, P 18 INT C COMP LING; Yarowsky D., 1992, P 14 INT C COMP LING, P454; Yarowsky David, 1995, P 33 ANN M ASS COMP; [Anonymous], 1992, P 4 MESS UND C MUC 4; *NAT I STAND TECHN, 1999, SPEC PUBL NAT I STAN; *NAT I STAND TECHN, 2001, SPEC PUBL NAT I STAN; *NAT I STAND TECHN, 2000, SPEC PUBL NAT I STAN; *REUT LTD, 1997, REUTERS21578	53	1	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1386-291X	978-1-4020-4746-6	TEXT SPEECH LANG TEC			2006	32						505	531			10.1007/978-1-4020-4746-6	27	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Language & Linguistics	Computer Science; Linguistics	BLA56	WOS:000269770600019	
S	Kim, SJ; Kim, EY; Jeong, K; Kim, JI		Bebis, G; Boyle, R; Parvin, B; Koracin, D; Remagnino, P; Nefian, A; Meenakshisundaram, G; Pascucci, V; Zara, J; Molineros, J; Theisel, H; Malzbender, T		Kim, Soo-jeong; Kim, Eun Yi; Jeong, Karpjoo; Kim, Jee-in			Emotion-based textile indexing using colors, texture and patterns	Advances in Visual Computing, Pt 2	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	2nd International Symposium on Visual Computing	NOV 06-08, 2006	Lake Tahoe, NV	UNR Comp Vis Lab, Desert Res Inst, NASA, Siemens, Intel, DigitalPersona, Equinox Corp, HP, nVIDA, Ford Corp, Mitsubish, UtopiaCompression			SYSTEM	We propose a textile indexing system which can classify textile images based on human emotions. The emotions can be regarded as emotional reactions of human beings when they view specific textile images. The evaluation system starts with extracting features of textile images such as colors, texture and patterns using various image processing techniques. The proposed system utilizes both fuzzy rules and neural networks. The fuzzy rules are determined for six emotional features which can be formulated with respect to color and texture. On the other hand, the neural network is used for recognizing patterns which can be used in classifying textile images based on the 4 other emotional features. For the machine learning component of the system, we selected 70 subjects so that they could view and annotate 160 textile images using ten pairs of emotional features. The fuzzy rule based component of the system uses color features and texture features in order to predict six pairs of emotional features such as (warm, cold), (gay, sober), (cheerful, dismal), (light, dark), (strong, weak), and (hard, soft). The neural-network based component of the system can predict four pairs of emotional features such as (natural, unnatural), (dynamic, static), (unstable, stable) and (gaudy, plain). Our experimental results showed that the proposed system was effective for predicting human emotions based on textile images and improving the accuracy of indexing the textile images based on emotional features.	Konkuk Univ, Dept Comp Engn, Seoul, South Korea; Konkuk Univ, CAESIT, Seoul, South Korea	Kim, SJ (reprint author), Konkuk Univ, Dept Comp Engn, Seoul, South Korea.						Bianchi-Berthouze N, 2003, IEEE MULTIMEDIA, V10, P103, DOI 10.1109/MMUL.2003.1218262; Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197; DONATO G, 1999, IEEE T PATTERN ANAL, V21, P947; Duda R. O., 2001, PATTERN CLASSIFICATI; GONZALEZ, 2002, DIGITAL IMAGE PROCES; GUNES H, 2005, IEEE INT WORKSH ROB; HORI T, 2003, WORKSH MULT INF RET, P31; Jinwoo Kim, 2003, International Journal of Human-Computer Studies, V59, DOI 10.1016/j.ijhcs.2003.06.002; KAWAMOTO N, 1993, COLOR RES APPL, V18, P260, DOI 10.1002/col.5080180409; Kim EY, 2005, LECT NOTES ARTIF INT, V3613, P1077; KOBAYASHI S, 1981, COLOR RES APPL, V6, P93; KOBAYASHI S, 1991, COLOR IMAGE SCALE; Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010; PALA P, 1999, PATREC PATTERN RECOG, P517; RAO VB, 1995, CPLUSPLUS NEURAL NET; SCHULLER B, 2004, IEEE INT C JUN, V2, P1215; TANCHAREON D, 2005, CARPE 05 NOV 11, P61; Um J, 2002, COLOR RES APPL, V27, P208, DOI 10.1002/col.10052; VANDOORN MGL, 2000, P 5 DIG LIB C SAN AN; Ververidis D., 2004, P 12 EUR SIGN PROC C, P341; Zhang P, 2005, COMMUN ACM, V48, P105, DOI 10.1145/1081992.1081997	21	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		LECT NOTES COMPUT SC			2006	4292						9	18				10	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BFN05	WOS:000243132300002	
S	Ling, YY; Meng, XF; Meng, WY		Yu, JX; Kitsuregawa, M; VaLeong, H		Ling, Yanyan; Meng, Xiaofeng; Meng, Weiyi			Automated extraction of hit numbers from search result pages	ADVANCES IN WEB-AGE INFORMATION MANAGEMENT, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Web-Age Information Management	JUN 17-19, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, City Univ Hong Kong, Hong Kong Baptist Univ, Hong Kong Polytech Univ, Hong Kong Univ Sci & Technol, Univ Hong Kong, Hong Kong Web Soc, Hong Kong Pei Hua Educ Fdn Ltd, IEEE Hong Kong Sect Comp Sci Chapter				When a query is submitted to a search engine, the search engine returns a dynamically generated result page that contains the number of hits (i.e. the number of matching results) for the query. Hit number is a very useful piece of information in many important applications such as obtaining document frequencies of terms, estimating the sizes of search engines and generating search engine summaries. In this paper, we propose a novel technique for automatically identifying the hit number for any search engine and any query. This technique consists of three steps: first segment each result page into a set of blocks, then identify the block(s) that contain the hit number using a machine learning approach, and finally extract the hit number from the identified block(s) by comparing the patterns in multiple blocks from the same search engine. Experimental results indicate that this technique is highly accurate.	Renmin Univ China, Sch Informat, Beijing, Peoples R China; SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA	Ling, YY (reprint author), Renmin Univ China, Sch Informat, Beijing, Peoples R China.	lingyy@ruc.edu.cn; xfmeng@ruc.edu.cn; meng@cs.binghamton.edu	ruc, comp_xinxi/E-4212-2012				Can L., 2005, WIRI, P40; COPE J, 2003, ADC, V17, P181; DOORENBOS RB, 1997, AGENTS 97, P39; Liu B, 2004, IEEE INTELL SYST, V19, P49, DOI 10.1109/MIS.2004.68; PANAGIOTIS G, 2001, SIGMOD C; Witten I. H., 2005, DATA MINING PRACTICA; Zhao H., 2005, WWW, P66	7	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35225-2	LECT NOTES COMPUT SC			2006	4016						73	84				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEV90	WOS:000239658700007	
S	Ben-Shimon, D; Shmilovici, A		Last, M; Szczepaniak, PS; Kandel, A; Volkovich, Z		Ben-Shimon, David; Shmilovici, Armin			Kernels for the Relevance Vector Machine - An empirical study	Advances in Web Intelligence and Data Mining	STUDIES IN COMPUTATIONAL INTELLIGENCE		English	Proceedings Paper	4th International Atlantic Web Intelligence Conference (AWIC 2006)	JUN 05-07, 2006	Beer Sheva, ISRAEL	Ben Gurion Univ Negev		machine learning; Relevance Vector Machine; kernel regression; Matern kernel		The Relevance Vector Machine (RVM) is a generalized linear model that can use kernel functions as basis functions. Experiments with the Matern kernel indicate that the kernel choice has a significant impact on the sparsity of the solution. Furthermore, not every kernel is suitable for the RVM. Our experiments indicate that the Matern kernel of order 3 is a good initial choice for many types of data.	Ben Gurion Univ Negev, Dept Informat Syst Engn, IL-84105 Beer Sheva, Israel	Ben-Shimon, D (reprint author), Ben Gurion Univ Negev, Dept Informat Syst Engn, POB 653, IL-84105 Beer Sheva, Israel.		SHMILOVICI, ARMIN/F-2136-2012				BENSHIMON D, 2006, J COMPUTING DECISION; Cristianini N., INTRO SUPPORT VECTOR; Genton M. G., 2001, J MACHINE LEARNING R, V2, P299; GILBERT JR, 1992, SIAM J MATRIX ANAL A, V13, P333, DOI 10.1137/0613024; Juditsky A, 1995, AUTOMATICA, V31, P1725, DOI 10.1016/0005-1098(95)00119-1; Matern B., 1960, SPATIAL VARIATION; RASMUSSEN C.E., 2005, P 22 INT C MACH LEAR; SHMILOVICI A, 2005, DATA MINING KNOWLEDG; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; WIPF DP, 2004, ADV NEURAL INFORM PR, V16	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	3-540-33879-9	STUD COMP INTELL			2006	23						253	263				11	Computer Science, Artificial Intelligence	Computer Science	BET90	WOS:000239486700026	
S	Chakrabarti, S		Mobasher, B; Nasraoui, O; Liu, B; Masand, B		Chakrabarti, Soumen			Discovering links between lexical and surface features in questions and answers	ADVANCES IN WEB MINING AND WEB USAGE ANALYSIS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	6th International Workshop on Knowledge Discovery on the Web (WEBKDD 2004)	AUG 22-25, 2004	Seattle, WA					Information retrieval systems, based on keyword match, are evolving to question answering systems that return short passages or direct answers to questions, rather than URLs pointing to whole pages. Most open-domain question answering systems depend on manually designed hierarchies of question types. A question is first classified to a fixed type, and then hand-engineered rules associated with the type yield keywords and/or predictive annotations that are likely to match indexed answer passages. Here we seek a more data-driven approach, assisted by machine learning. We propose a simple log-linear model over a pair of feature vectors, one derived from the question and the other derived from the a candidate passage. Features are extracted using a lexical network and surface context as in named entity extraction, except that there is no direct supervision available in the form of fixed entity types and their examples. Using the log-linear model, we filter candidate passages and see substantial improvement in the mean rank at which the first answer is found. The model parameters distill and reveal linguistic artifacts coupling questions and their answers, which can be used for better annotation and indexing.	Indian Inst Technol, Bombay, Maharashtra, India	Chakrabarti, S (reprint author), Indian Inst Technol, Bombay, Maharashtra, India.	soumen@cse.iitb.ac.in					AGICHTEIN E, 2001, WWW C, P169; BRECK E, 1999, AAAI FALL S QUEST AN; Chen Stanley F., 1999, CMUCS99108; Clarke C. L. A., 2001, SIGIR Forum; DUMAIS S, 2002, SIGIR, P291; ETZIONI O, 2004, WWW C NEW YORK ACM; HARABAGIU S, 2000, TREC, V9, P479; HOVY E, 2001, TREC, V9; KATZ B, 2003, EACL WORKSH NATURAL; KWOK C, 2001, WWW C HONG KONG, V10, P150; LIGHT M, 2001, NATURAL LANGUAGE ENG, V7, P325; McCallum A., 2003, UAI; MILLER G, 1993, INT J LEXICOGRAPHY; NYBERG E, 2003, TREC, V12; Pantel Patrick, 2001, NAT LANG ENG, V7, P343; Prager J., 2000, SIGIR, P184; RADEV D, 2002, WWW2002, P408; RAMAKRISHNAN G, 2004, WWW C NEW YORK, P111; SUZUKI J, 2003, ACL, P32; Tellex S., 2003, SIGIR 03, P41, DOI DOI 10.1145/860435.860445; VOORHEES E, 2001, NIST SPECIAL PUBLICA, P42; YAROWSKY D, 1994, ACL, V32, P88; ZHANG D, 2003, TEXT RETR C TREC NIS, V12; ZHANG D, 2003, SIGIR; ZHANG J, 2003, SIGIR, P190; ZHENG Z, 2002, HLT	26	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-47127-8	LECT NOTES ARTIF INT			2006	3932						116	134				19	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFM22	WOS:000243032800008	
S	Bloehdorn, S; Hotho, A		Mobasher, B; Nasraoui, O; Liu, B; Masand, B		Bloehdorn, Stephan; Hotho, Andreas			Boosting for text classification with semantic features	ADVANCES IN WEB MINING AND WEB USAGE ANALYSIS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	6th International Workshop on Knowledge Discovery on the Web (WEBKDD 2004)	AUG 22-25, 2004	Seattle, WA				CATEGORIZATION	Current text classification systems typically use term stems for representing document content. Semantic Web technologies allow the usage of features on a higher semantic level than single words for text classification purposes. In this paper we propose such an enhancement of the classical document representation through concepts extracted from background knowledge. Boosting, a successful machine learning technique is used for classification. Comparative experimental evaluations in three different settings support our approach through consistent improvement of the results. An analysis of the results shows that this improvement is due to two separate effects.	Univ Karlsruhe, Inst AIFB, Knowledge Management Res Grp, Karlsruhe, Germany; Univ Kassel, Knowledge & Data Engn Grp, D-3500 Kassel, Germany	Bloehdorn, S (reprint author), Univ Karlsruhe, Inst AIFB, Knowledge Management Res Grp, Karlsruhe, Germany.	sbl@aifb.uni-karlsruhe.de; hotho@cs.uni-kassel.de					BODNER RC, 1996, ADV ARTIFICIAL INTEL; Bozsak E, 2002, LECT NOTES COMPUT SC, V2455, P304; CAI L, 2003, P 26 ANN INT ACM SIG; Freund Y., 1995, 2 EUR C COMP LEARN T, P23; Handschuh S., 2003, ANNOTATION SEMANTIC; Hersh W., 1994, P 17 ANN INT ACM SIG; Hotho A, 2003, P SEM WEB WORKSH 26; Ide N, 1998, COMPUT LINGUIST, V24, P1; JOACHIMS T, 1998, P ECML 98; Kehagias A, 2003, J INTELL INF SYST, V21, P227, DOI 10.1023/A:1025554732352; LAUSER B, 2003, THESIS U KARLSRUHE; Meir R, 2002, LECT NOTES ARTIF INT, V2600, P118; Miller G. A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Salton G., 1989, AUTOMATIC TEXT PROCE; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Wang CY, 2003, J SEP SCI, V26, P69, DOI 10.1002/jssc.200390017; Yang Y., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; Yang Yiming, 1999, P SIGIR 99 22 ACM IN	20	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-47127-8	LECT NOTES ARTIF INT			2006	3932						149	166				18	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFM22	WOS:000243032800010	
S	Airoldi, E; Bai, X; Padman, R		Mobasher, B; Nasraoui, O; Liu, B; Masand, B		Airoldi, Edoardo; Bai, Xue; Padman, Rema			Markov blankets and meta-heuristics search: Sentiment extraction from unstructured texts	ADVANCES IN WEB MINING AND WEB USAGE ANALYSIS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th International Workshop on Knowledge Discovery on the Web (WEBKDD 2004)	AUG 22-25, 2004	Seattle, WA				CLASSIFICATION	Extracting sentiments from unstructured text has emerged as an important problem in many disciplines. An accurate method would enable us, for example, to mine online opinions from the Internet and learn customers' preferences for economic or marketing research, or for leveraging a strategic advantage. In this paper, we propose a two-stage Bayesian algorithm that is able to capture the dependencies among words, and, at the same time, finds a vocabulary that is efficient for the purpose of extracting sentiments. Experimental results on online movie reviews and online news show that our algorithm is able to select a parsimonious feature set with substantially fewer predictor variables than in the full data set and leads to better 'predictions about sentiment orientations than several state-of-the-art machine learning methods. Our findings suggest that sentiments are captured by conditional dependence relations among words, rather than by keywords or high-frequency words.	Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Sch Publ Policy & Management John Heinz III, Pittsburgh, PA 15213 USA	Bai, X (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.	eairoldi@cs.cmu.edu; xbai@andrew.cmu.edu; rpadman@andrew.cmu.edu					AIROLDI E, 2005, UNPUB BAYESIAN MODEL; AIROLDI E, 2005, IN PRESS J BAYESIAN; Airoldi EM, 2006, BAYESIAN ANAL, V1, P289; BAI X, 2004, P KDD WORKSH MIN SEM; BAI X, 2005, CMUCALD05101 SCH COM; Bishop YMM, 1975, DISCRETE MULTIVARIAT; Carletta J, 1996, COMPUT LINGUIST, V22, P249; Chickering D. M., 2003, P 19 C UNC ART INT, P124; COHEN W, 2004, MINOR 3 METHODS IDEN; DAS SR, 2001, P 8 AS PAC FIN ASS A; Dave K., 2003, P 12 INT C WORLD WID, P519, DOI DOI 10.1145/775152.775226; ENGSTROM C, 2004, 07222004 U CAMBR ST; FINN A, 2003, IJCAI 03 WORKSH COMP; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Glover F., 1997, TABU SEARCH; GOLBECK J, 2004, P 14 INT C KNOWL ENG; Huettner A., 2000, ACL 2000 COMPANION V, P26; Joachims T, 2001, P 24 ANN INT ACM SIG, P128, DOI 10.1145/383952.383974; Koller D., 1996, P 13 INT C MACH LEAR, P284; KOMAREK P, 2005, UNPUB MAKING LOGISTI; Lafferty J., 2001, P 18 INT C MACH LEAR, P282; Lewis D., 1991, P SPEECH NAT LANG WO, P312, DOI 10.3115/112405.112471; Liu H., 2003, P 8 INT C INT US INT, P125; MARGARITIS D, 1999, ADV NEURAL INFORM PR; Mckeown K. R., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640; Mitchell T, 1997, MACHINE LEARNING; MONTGOMERY A, 2002, LEARNING CUSTOMERS A; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Osgood C. E., 1957, MEASUREMENT MEANING; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Pearl J, 2000, CAUSALITY MODELS REA; PIATETSKYSHAPIR.G, 2000, SIGKDD EXPLORATIONS, V2, P7680; Provost F. J., 1998, P 15 INT C MACH LEAR, P445; RAMSEY J, 2004, MB FAN SEARCH CLASSI; Spirtes P, 2000, CAUSATION PREDICTION; Spirtes P, 1995, P 1 INT C KNOWL DISC, P294; Turney P., 2002, P 40 ANN M ASS COMP, P417; TURNEY P, 2002, EGB1094 NAT RES COUN; XING EP, 2001, P 18 IN C MACH LEARN	39	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-47127-8	LECT NOTES ARTIF INT			2006	3932						167	187				21	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFM22	WOS:000243032800011	
S	Vittaut, JN; Gallinari, P		Fuhr, N; Lalmas, M; Malik, S; Kazai, G		Vittaut, Jean-Noel; Gallinari, Patrick			Machine Learning ranking and INEX'05	ADVANCES IN XML INFORMATION RETRIEVAL AND EVALUATION	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th International Workshop of the Initiative for the Evaluation of XML Retrieval	NOV 28-30, 2005	Dagstuhl, GERMANY	DELOS Network Digital Lib				We present a Machine Learning based ranking model which can automatically learn its parameters using a training set of annotated examples composed of queries and relevance judgments on a subset of the document elements. Our model improves the performance of a baseline Information. Retrieval system by optimizing a ranking loss criterion and combining scores computed from doxels and from their local structural context. We analyze the performance of our algorithm on CO-Focussed and CO-Thourough tasks and compare it to the baseline model which is an adaptation of Okapi to Structured Information Retrieval.	Lab Informat Paris 6, F-75015 Paris, France	Vittaut, JN (reprint author), Lab Informat Paris 6, 8 Rue Capitaine Scott, F-75015 Paris, France.	vittaut@poleia.lip6.fr; gallinari@poleia.lip6.fr					AMINI MR, 2005, ECIR, P142; BARTELL BT, 1994, RES DEV INF RETR, P173; Clemencon S, 2005, LECT NOTES COMPUT SC, V3559, P1, DOI 10.1007/11503415_1; Cohen W.W., 1998, ADV NEURAL INFORM PR, V10; CRASWELL N, 2005, SIGIR 05 P 28 ANN IN; FREUND Y, 1998, P ICML 98 15 INT C M; Robertson S.E., 1992, TEXT RETR C, P21; VITTAUT JN, 2004, ADV XML INFORM RETRI	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34962-6	LECT NOTES COMPUT SC			2006	3977						336	343				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BET37	WOS:000239425500025	
S	Fischer, F; Rovatsos, M; Weiss, G		Dignum, F; VanEijk, RM; Flores, R		Fischer, Felix; Rovatsos, Michael; Weiss, Gerhard			Adaptiveness in agent communication: Application and adaptation of conversation patterns	Agent Communication II	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	International Workshop on Agent Communication	MAY   09, 2006	Hakodate, JAPAN					Communication in multi-agent systems (MASs) is usually governed by agent communication languages (ACLs) and communication protocols carrying a clear cut semantics. With an increasing degree of openness, however, the need arises for more flexible models of communication that can handle the uncertainty associated with the fact that adherence to a supposedly agreed specification of possible conversations cannot be ensured on the side of other agents. In this paper, we argue for adaptiveness in agent communication. We present a particular approach that combines conversation patterns as a generic way of describing the available means of communication in a MAS with a decision-theoretic framework and various different machine learning techniques for applying these patterns in and adapting them from actual conversations.	Univ Munich, Dept Informat, D-80538 Munich, Germany	Fischer, F (reprint author), Univ Munich, Dept Informat, D-80538 Munich, Germany.						Austin John Langshaw, 1962, DO THINGS WORDS; Barto AG, 2003, DISCRETE EVENT DYN S, V13, P41, DOI 10.1023/A:1022140919877; Cohen P, 1995, P 1 INT C MULT SYST, P65; FISCHER F, 2005, P 4 INT JOINT C AUT, P106, DOI 10.1145/1082473.1082490; Fischer F., 2004, P 3 INT JOINT C AUT, P1334; Fischer F, 2005, ENG APPL ARTIF INTEL, V18, P809, DOI 10.1016/j.engappai.2005.06.005; FORNARA N, 2002, P 1 INT JOINT C AUT, P536; GOFFMAN E, 1974, FRAMEANAL ESSAY ORG; HUGET MP, 2003, LECT NOTES ARTIFICIA, V2650; Jain A.K., 1988, ALGORITHMS CLUSTERIN; Kolodner J.L., 1993, CASE BASED REASONING; Kone M. T., 2000, Knowledge and Information Systems, V2, DOI 10.1007/PL00013712; Luhmann Niklas, 1995, SOCIAL SYSTEMS; NICKLES M, 2004, P 3 INT JOINT C AUT; PAUROBALLY S, FORMAL FRAMEWORK AGE; PLOTKIN G, 1971, MACH INTELL, V5, P153; Precup D., 2000, THESIS U MASSACHUSET; Ramon J, 2001, ACTA INFORM, V37, P765, DOI 10.1007/PL00013304; RAO AS, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P439; Rovatsos M., 2002, P 1 INT JOINT C AUT; ROVATSOS M, 2005, P 2 INT WORKSH ARG M; ROVATSOS M, 2004, P 2 EUR WORKSH MULT, P593; ROVATSOS M, 2003, P 2 INT JOINT C AUT; SEBAG M, 1997, P 7 INT WORKSH IND L; SINGH MP, 2000, P IJCAI WORKSH AG CO; Singh M. P., 1993, Annals of Mathematics and Artificial Intelligence, V8, DOI 10.1007/BF02451549; VERDICCHIO M, COMMITMENT BASED COM; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	28	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68142-7	LECT NOTES COMPUT SC			2006	3859						211	226				16	Computer Science, Artificial Intelligence	Computer Science	BFV52	WOS:000244816700015	
S	Boshoff, WH; Ehlers, EM		Shi, ZZ; Sadananda, R		Boshoff, W. H.; Ehlers, E. M.			Reusable component oriented agents: A new architecture	AGENT COMPUTING AND MULTI-AGENT SYSTEMS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific Rim International Workshop on Multi-Agents	AUG 07-08, 2006	Guilin, PEOPLES R CHINA			agent architecture; mobile agent; learning agent; agent plug-in		This research paper will outline the new Plug-in Oriented Agent Architecture (POAA) and describe the agents that make use of the POAA architecture. POAA agents make heavy use of functional and controller based plug-ins in order to extend the functionality and behavior of the agent. The architecture was designed to facilitate machine learning and agent mobility techniques. POAA agents are created by mounting newly created dynamic plug-in components into the static structure of the agent. The use of plug-ins will greatly improve the effectiveness of researchers, as only a single, standard architecture will exist. Researchers only need to design and develop the plug-in required for their specific agent to function as desired. This will also facilitate the comparison of various tools and methods, as only the components being reviewed need to be interchanged to measure system performance.	Univ Johannesburg, Acad Informat Technol, ZA-2006 Auckland Pk, South Africa	Boshoff, WH (reprint author), Univ Johannesburg, Acad Informat Technol, POB 524, ZA-2006 Auckland Pk, South Africa.	willem.boshoff@ey.com; eme@rau.ac.za					HELSINGER A, 2004, P IASTED C COMP INT; KENNION T, 1999, COMMUNITY EXPERT SYS; PRINCE CG, 2000, SCIP SOC COMP PSYCH; WANG AI, 2000, 4 IASTED INT C SOFTW; WITTEN I, 2000, WEKA MACHINE LEARNIN, P265; 2005, ASK IT GLOSSARY O Z	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-36707-1	LECT NOTES ARTIF INT			2006	4088						632	637				6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BEV65	WOS:000239626100071	
S	Rogers, A; David, E; Schiff, J; Kraus, S; Jennings, NR		Poutre, HL; Sadeh, NM; Janson, S		Rogers, A.; David, E.; Schiff, J.; Kraus, S.; Jennings, N. R.			Learning environmental parameters for the design of optimal English auctions with discrete bid levels	AGENT-MEDIATED ELECTRONIC COMMERCE: DESIGNING TRADING AGENTS AND MECHANISMS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th Workshop on Agent-Mediated Electronic Commerce - Designing Mechanisms and Systems	JUL, 2005	Utrecht, NETHERLANDS				ENTRY	In this paper we consider the optimal design of English auctions with discrete bid levels. Such auctions are widely used in online internet settings and our aim is to automate their configuration in order that they generate the maximum revenue for the auctioneer. Specifically, we address the problem of estimating the values of the parameters necessary to perform this optimal auction design by observing the bidding in previous auctions. To this end, we derive a general expression that relates the expected revenue of the auction when discrete bid levels are implemented, but the number of participating bidders is unknown. We then use this result to show that the characteristics of these optimal bid levels are highly dependent on the expected number of bidders and on their valuation distribution. Finally, we derive and demonstrate an online algorithm based on Bayesian machine learning, that allows these unknown parameters to be estimated through observations of the closing price of previous auctions. We show experimentally that this algorithm converges rapidly toward the true parameter values and, in comparison with an auction using the more commonly implemented fixed bid increment, results in an increase in auction revenue.	Univ Southampton, Southampton SO17 1BJ, Hants, England; Bar Ilan Univ, Dept Math, IL-52900 Ramat Gan, Israel; Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel	Rogers, A (reprint author), Univ Southampton, Southampton SO17 1BJ, Hants, England.	acr@ecs.soton.ac.uk; ed@ecs.soton.ac.uk; schiff@math.biu.ac.il; sarit@cs.biu.ac.il; nrj@ecs.soton.ac.uk	Jennings, Nicholas/F-7358-2011	Jennings, Nicholas/0000-0003-0166-248X			Bajari P, 2003, RAND J ECON, V34, P329, DOI 10.2307/1593721; BICHLER M, 2003, ACM C EL COMM 2003, P254; CHWE MSY, 1989, ECON LETT, V31, P303, DOI 10.1016/0165-1765(89)90019-0; David E., 2005, P 6 ACM C EL COMM EC, P98, DOI 10.1145/1064009.1064020; Hageman L. A., 1981, APPL ITERATIVE METHO; LAFFONT JJ, 1995, ECONOMETRICA, V63, P953, DOI 10.2307/2171804; LEVIN D, 1994, AM ECON REV, V84, P585; Lucking-Reiley D, 2000, J IND ECON, V48, P227; MacKay D., 2003, INFORM THEORY INFERE; MYERSON RB, 1981, MATH OPER RES, V6, P58, DOI 10.1287/moor.6.1.58; PRESS WH, 1992, NUMERICAL RECIPES AR; RILEY JG, 1981, AM ECON REV, V71, P381; ROTHKOPF MH, 1990, J POLIT ECON, V98, P94, DOI 10.1086/261670; ROTHKOPF MH, 1994, EUR J OPER RES, V74, P572, DOI 10.1016/0377-2217(94)90232-1; YAMEY BS, 1972, J POLIT ECON, V80, P1323, DOI 10.1086/259977; Yu J., 1999, THESIS CALTECH	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-46242-2	LECT NOTES ARTIF INT			2006	3937						1	15				15	Computer Science, Artificial Intelligence	Computer Science	BFF48	WOS:000241593000001	
S	Cheng, B; Guo, ZY; Bai, ZF; Cao, BG		Sattar, A; Kang, BH		Cheng Bo; Guo Zhenyu; Bai Zhifeng; Cao Binggang			Parallel chaos immune evolutionary programming	AI 2006: Advances in Artificial Intelligence, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	19th Australian Joint Conference on Artificial Intelligence	DEC 04-08, 2006	Hobart, AUSTRALIA			immune algorithm; chaos search; evolution programming; parallel evolution		Based on Clonal Selection Theory, Parallel Chaos Immune Evolutionary Programming (PCIEP) is presented. On the grounds of antigen-antibody affinity, the original antibody population can be divided into two subgroups. Correspondingly, two new immune operators, Chaotic Clonal Operator (CCO) and Super Mutation Operator (SMO), are proposed. The former has strong search ability in the small space while the latter has better search ability in large space. Thus, combination searching local optimum with maintaining population diversity can be actualized by concurrently operating CCO and SMO. Compared with the Classical Evolutionary Programming (CEP) and Evolutionary Algorithms with Chaotic Mutations (EACM), experimental results show that PCIEP is of high efficiency and can effectively prevent premature convergence. Therefore, it can be employed to solve complicated machine learning problems.	Xian Jiaotong Univ, Res & Dev Ctr Elect Vehicle, Xian 710049, Peoples R China	Cheng, B (reprint author), Xian Jiaotong Univ, Res & Dev Ctr Elect Vehicle, Xian 710049, Peoples R China.						ADA GL, 1987, SCI AM, V257, P50; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; FUKUDA T, 1999, DASGUPTA DIPANKAR AR, P210; LIU RC, 2003, 5 INT C COMP INT MUL, P290; LUO CZ, 2000, CONTROL DECISION, V15, P557; LUO YS, 2005, J SYSTEM SIMULATION, V2, P319; Schwefel H. P., 1995, EVOLUTION OPTIMUM SE; TONG Z, 1999, CONTROL DECISION, V14, P285; WANG XJ, 2004, ACTA ELECT SINICA, V11, P1824; WATKINS A, 2004, 3 INT C ART IMM SYST, P427; Watkins A., 2003, INTELLIGENT ENG SYST, V13, P225; YAN ZJ, 1996, P SIM EV LERN SEAL 9, P53; Yang Kong-yu, 2005, Control and Decision, V20	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-49787-5	LECT NOTES COMPUT SC			2006	4304						224	232				9	Computer Science, Artificial Intelligence	Computer Science	BFV69	WOS:000244891200026	
S	Sokolova, M; Japkowicz, N; Szpakowicz, S		Sattar, A; Kang, BH		Sokolova, Marina; Japkowicz, Nathalie; Szpakowicz, Stan			Beyond accuracy, F-Score and ROC: A family of discriminant measures for performance evaluation	AI 2006: Advances in Artificial Intelligence, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	19th Australian Joint Conference on Artificial Intelligence	DEC 04-08, 2006	Hobart, AUSTRALIA					Different evaluation measures assess different characteristics of machine learning algorithms. The empirical evaluation of algorithms and classifiers is a matter of on-going debate among researchers. Most measures in use today focus on a classifier's ability to identify classes correctly. We note other useful properties, such as failure avoidance or class discrimination, and we suggest measures to evaluate such properties. These measures - Youden's index, likelihood, Discriminant power - are used in medical diagnosis. We show that they are interrelated, and we apply them to a case study from the field of electronic negotiations. We also list other learning problems which may benefit from the application of these measures.	Univ Montreal, DIRO, Montreal, PQ, Canada	Sokolova, M (reprint author), Univ Montreal, DIRO, Montreal, PQ, Canada.						Biggerstaff BJ, 2000, STAT MED, V19, P649, DOI 10.1002/(SICI)1097-0258(20000315)19:5<649::AID-SIM371>3.0.CO;2-H; BLAKELEY DD, 1995, ANN INTERN MED, V122, P360; BOPARAI J, 2002, P 7 AUSTR DOC COMP S; CHERKASSKY V, 1998, LEARNIGN DATA; Cohen J., 1988, STAT POWER ANAL BEHA; Demsar J, 2006, J MACH LEARN RES, V7, P1; DUDA RO, 2000, PATTERN CLASSIFICATO; Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073; ISSELBACHER KJ, 1994, HARRISONS PRINCIPLES; KERSTEN G, 2006, ELECT NEGOTIATIONS M; Kolcz A., 2004, ACM SIGKDD EXPLORATI, V<IT>6</IT>; MISHNE G, 2005, P 1 WORKSH STYL AN T; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; SOKOLOVA M, 2005, P REC ADV NAT LANG P, P518; WITTEN I, 2005, DATA MINIG; YOUDEN WJ, 1950, CANCER, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3	16	37	37	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-49787-5	LECT NOTES COMPUT SC			2006	4304						1015	1021				7	Computer Science, Artificial Intelligence	Computer Science	BFV69	WOS:000244891200114	
S	Zheng, G; Li, WQ; Ogunbona, P; Dong, LJ; Kharitorienko, I		Sattar, A; Kang, BH		Zheng, Gang; Li, Wanqing; Ogunbona, Philip; Dong, Liju; Kharitorienko, Igor			Simulation of human motion for learning and recognition	AI 2006: Advances in Artificial Intelligence, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	19th Australian Joint Conference on Artificial Intelligence	DEC 04-08, 2006	Hobart, AUSTRALIA				IMAGES	Acquisition of good quality training samples is becoming a major issue in machine learning based human motion analysis. This paper presents a method to simulate human body motion with the intention to establish a human motion corpus for learning; and recognition. The simulation is achieved by a unique temporal-spatial-temporal decomposition of human body motion into actions, joint actions and actionlets based on the human kinematic model. The actionlet models the primitive moving phase of a joint and can be simulated based on the kinesiological study. A joint action is formed by proper concatenation of actionlets and an action is a group of synchronized joint actions. Methods for concatenation and synchronization are proposed in this paper for realistic simulation of human motion. Results on simulafing "running" verifies the feasibility of the proposed method.	Univ Wollongong, Sch Informat Technol & Comp Sci, Wollongong, NSW 2500, Australia	Zheng, G (reprint author), Univ Wollongong, Sch Informat Technol & Comp Sci, Wollongong, NSW 2500, Australia.						Boulic R., 1990, Visual Computer, V6, DOI 10.1007/BF01901021; Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286; FARAWAY J, 2002, 382 U MICH DEP STAT; Green RD, 2004, IEEE T CIRC SYST VID, V14, P179, DOI 10.1109/TCSVT.2003.821976; Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274; IJSPEERT A, 2002, P IEEE INT C ROB AUT, V2, P1398; PETTRE J, 2002, PLANNING HUMAN WALK, V3, P3049; SODERBERG GL, 1986, KINESIOLOGY APPL PAT; TOZEREN A, 1999, HUMAN BODY DYNAMICS; XIAO Z, 2005, IEEE P 9 INT C INF V, P571; Zatsiorsky V. M., 1998, KINEMATICS HUMAN MOT; Zhang XY, 2006, IEEE T PATTERN ANAL, V28, P625	12	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-49787-5	LECT NOTES COMPUT SC			2006	4304						1168	1172				5	Computer Science, Artificial Intelligence	Computer Science	BFV69	WOS:000244891200142	
J	Lora, AT				Lora, Alicia Troncoso			Advances in optimization and prediction techniques: Real-world applications	AI COMMUNICATIONS			English	Article						Machine Learning; forecasting; nonconvex nonlinear optimization	INTERIOR-POINT METHODS	This paper describes a time-series prediction method based on the k-Weighted Nearest Neighbours (k-WNN) algorithm and a simple technique to deal with nonconvex, nonlinear optimization problems by solving a sequence of Interior Point (IP) subproblems. The proposed prediction methodology is applied to obtain the 24-hour forecasts of two real time series: the demand and the energy prices in the competitive Spanish Electricity Market. The proposed optimization method is applied to the optimal scheduling of the electric energy production in the short-term.	Univ Pablo Olavide, Area Comp Sci, Seville, Spain	Lora, AT (reprint author), Univ Pablo Olavide, Area Comp Sci, Seville, Spain.	atrolor@upo.es	Troncoso, Alicia/B-8606-2012				DASARATHY BV, 1991, IEEE COMPUTER SOC PR; KENNEL MB, 1992, PHYS REV A, V45, P3403, DOI 10.1103/PhysRevA.45.3403; LORA AT, 2003, LECT NOTES ARTIF INT, V2902, P187; LORA AT, 2002, LNCS, V2453, P321; LORA AT, 2004, LECT NOTES ARTIF INT, V3040, P656; Medina J, 1999, IEEE T POWER SYST, V14, P266, DOI 10.1109/59.744542; Quinlan J. R, 1992, 5 AUSTR JOINT C ART, P343; Santos JR, 2003, IEEE T POWER SYST, V18, P238, DOI 10.1109/TPWRS.2002.807097; Takens F, 1981, LECT NOTES MATH, V898, P336; Vanderbei RJ, 1999, COMPUT OPTIM APPL, V13, P231, DOI 10.1023/A:1008677427361; Wang Y., 1997, EUR C MACH LEARN PRA, P128; Yamashita H, 1996, MATH PROGRAM, V75, P377, DOI 10.1007/BF02592190	12	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2006	19	3					295	297				3	Computer Science, Artificial Intelligence	Computer Science	085JT	WOS:000240601100007	
J	Kersting, K				Kersting, Kristian			An inductive logic programming approach to statistical relational learning	AI COMMUNICATIONS			English	Article						machine learning; statistical learning; reinforcement learning; relational learning; inductive logic programming; statistical relational learning		Statistical relational learning (SRL) addresses one of the central open questions of AI: the combination of relational or first-order logic with principled probabilistic and statistical approaches to inference and learning. This thesis approaches SRL from an inductive logic programming (ILP) perspective and starts with developing a general framework for SRL: probabilistic ILP. Based on this foundation, the thesis shows how to incorporate the logical concepts of objects and relations among these objects into Bayesian networks. As time and actions are not just other relations, it afterwards develops approaches to probabilistic ILP over time and for making complex decision in relational domains. Finally, it is shown that SRL approaches naturally yield kernels for structured data. The resulting approaches are illustrated using examples from genetics, bioinformatics, and planning domains.	Univ Freiburg, Inst Informat, D-79110 Freiburg, Germany	Kersting, K (reprint author), Univ Freiburg, Inst Informat, Georges Kohler Allee,Bldg 079, D-79110 Freiburg, Germany.	kersting@informatik.uni-freiburg.de					De Raedt L, 2004, LECT NOTES ARTIF INT, V3244, P19; KERSTING K, 2005, P 21 C UNC ART INT U, P300; Kersting K, 2006, J ARTIF INTELL RES, V25, P425; MUGGLETON S, 1994, J LOGIC PROGRAM, V20, P629	4	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2006	19	4					389	390				2	Computer Science, Artificial Intelligence	Computer Science	120KI	WOS:000243083200006	
B	Deng, D; Simmermacher, C; Cranefield, S		Ong, KL; SmithMiles, K; Lee, V; Ng, WK		Deng, Da; Simmermacher, Christian; Cranefield, Stephen			Finding the right features for instrument classification of classical music	AIDM 2006: International Workshop on Integrating AI and Dating Mining			English	Proceedings Paper	1st International Workshop International AI and Data Mining	DEC 04-05, 2006	Hobart, AUSTRALIA				SOUND-RECOGNITION	In tackling data mining and pattern recognition tasks, finding a compact but effective set of features is often a crucial step in the whole problem solving process. In this paper we present an empirical study on feature selection for classical instrument recognition, using machine learning techniques to select and evaluate features extracted from a number of different feature schemes in terms of their classification performance. It is revealed that there is significant redundancy in existing feature schemes commonly used in practice. Our results suggest that further feature analysis research is necessary for optimising feature selection for the instrument recognition problem.	Univ Otago, Dept Informat Sci, Dunedin, New Zealand	Deng, D (reprint author), Univ Otago, Dept Informat Sci, POB 56, Dunedin, New Zealand.		Deng, Jeremiah/A-1287-2008; Cranefield, Stephen/A-6605-2008				AGOSTINI G, 2003, EURASIP J APPL SIGNA; AUCOUTURIER J, 2002, P ICME, V1, P105; Brown JC, 2001, J ACOUST SOC AM, V109, P1064, DOI 10.1121/1.1342075; Casey M, 2001, IEEE T CIRC SYST VID, V11, P737, DOI 10.1109/76.927433; Crima-Idi NI., 2003, WORKSH MULT DISC MIN; Divakaran A, 2003, P SOC PHOTO-OPT INS, V5021, P160, DOI 10.1117/12.476294; Eggink J., 2004, P ICASSP, V4, P217; Eronen A, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P19, DOI 10.1109/ASPAA.2001.969532; ESSID S, 2004, P AUD ENG SOC 25 INT; Foote J, 1999, MULTIMEDIA SYST, V7, P2, DOI 10.1007/s005300050106; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Livshin A.A., 2004, P 7 INT C DIG AUD EF; MARQUES J, 1999, 994 CRL COMP COMP CO; PEETERS G, 2000, P INT COMP MUS C, P166; Press WH, 1988, NUMERICAL RECIPES C; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Slaney M, 1998, AUDITORY TOOLBOX; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TSENG YH, 1999, P 22 INT ACM SIGIR C, P176, DOI 10.1145/312624.312675; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Witten I. H., 2005, DATA MINING PRACTICA; XIONG Z, 2003, P ICME, V3, P397; Yu L, 2004, J MACH LEARN RES, V5, P1205; Yu L., 2003, P 20 INT C MACH LEAR, P856; *IPEM, IPEM TOOLB; *ISO IEC WORK GROU, 2004, MPEG 7 OV	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-2730-7				2006							34	41				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BFW74	WOS:000245154100005	
S	Meyerhenke, H; Sauerwald, T		Asano, T		Meyerhenke, Henning; Sauerwald, Thomas			Analyzing disturbed diffusion on networks	Algorithms and Computation, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	17th International Symposium on Algorithms and Computation (ISAAC 2006)	DEC 18-20, 2006	Calcutta, INDIA	Govt India, Dept Sci & Technol, Govt India, Council Sci & Ind Res, Reserve Bank India, Govt W Bengal, Dept Informat Technol, Capemini Consulting India Private Ltd, Tata Consultancy Serv, IBM India Software Lab, Cognizant Technol Solut, Anshin Software		disturbed diffusion; diffusion distance; random walks		This work provides the first detailed investigation of the disturbed diffusion scheme FOS/C introduced in [17] as a type of diffusion distance measure within a graph partitioning framework related to Lloyd's k-means algorithm [14]. After outlining connections to distance measures proposed in machine learning, we show that FOS/C can be related to random walks despite its disturbance. Its convergence properties regarding load distribution and edge flow characterization are examined on two different graph classes, namely torus graphs and distancetransitive graphs (including hypercubes) representatives of which are frequently used as interconnection networks.	Univ Paderborn, Fak Elektrotech Informat & Math, D-33102 Paderborn, Germany	Meyerhenke, H (reprint author), Univ Paderborn, Fak Elektrotech Informat & Math, Furstenallee 11, D-33102 Paderborn, Germany.						Adamek J., 1991, FDN CODING; Alon N., 2000, PROBABILISTIC METHOD; Biggs N. L., 1993, ALGEBRAIC GRAPH THEO; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; CYBENKO G, 1989, J PARALLEL DISTR COM, V7, P279, DOI 10.1016/0743-7315(89)90021-X; Diekmann R, 1999, PARALLEL COMPUT, V25, P789, DOI 10.1016/S0167-8191(99)00018-6; Doyle P. G., 1984, RANDOM WALKS ELECT N; ELLIS RB, 2001, AMS NATL C INVITED T; Grimmett GS, 1992, PROBABILITY RANDOM P; Gross J. L., 2004, HDB GRAPH THEORY; Hu YF, 1999, PARALLEL COMPUT, V25, P417, DOI 10.1016/S0167-8191(99)00002-2; Leighton F. T., 1992, INTRO PARALLEL ALGOR; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Lovasz L., 1993, COMBINATORICS P ERDO, V2, P1; Meyerhenke H, 2006, P 20 IEEE INT PAR DI, P57, DOI 10.1109/IPDPS.2006.1639295; Nadler B., 2005, NIPS; SAERENS M, 2004, ECML 2004 EUR C MACH, P371; SCHAMBERGER S, 2005, PACT 05, V2763, P263; SHEWCHUK JR, 1994, CMUCS94125 CARN MELL; Shi J., 2001, 8 INT WORKSH ART INT; Snell J. L., 1976, FINITE MARKOV CHAINS; TISHBY N, 2000, NIPS, P640; Trottenberg U., 2000, MULTIGRID; van Dongen S, 2000, THESIS U UTRECHT; Xu C., 1997, LOAD BALANCING PARAL; YEN L, 2005, ESANN 2005 EUR S ART	26	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-49694-6	LECT NOTES COMPUT SC			2006	4288						429	438				10	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BFT31	WOS:000244494700042	
S	Drineas, P; Mahoney, MW; Muthukrishnan, S		Azar, Y; Erlebach, T		Drineas, Petros; Mahoney, Michael W.; Muthukrishnan, S.			Subspace sampling and relative-error matrix approximation: Column-row-based methods	ALGORITHMS - ESA 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	14th Annual European Symposium on Algorithms (ESA 2006)	SEP 11-13, 2006	Zurich, SWITZERLAND	European Assoc Theoret Comp Sci			NYSTROM METHOD	Much recent work in the theoretical computer science, linear algebra, and machine learning has considered matrix decompositions of the following form: given an m x n matrix A, decompose it as a product of three matrices, C, U, and R, where C consists of a small number of columns of A. R consists of a small number of rows of A, and U is a small carefully constructed matrix that guarantees that the product CUR is "close" to A. Applications of such decompositions include the computation of matrix "sketches", speeding up kernel-based statistical learning, preserving sparsity in low-rank matrix representation, and improved interpretability of data analysis methods. Our main result is a randomized, polynomial algorithm which, given as input an m x n matrix A, returns as output matrices C, U, R such that vertical bar vertical bar A - CUR vertical bar vertical bar(F) <= (1+epsilon) vertical bar vertical bar A -A(k)vertical bar vertical bar(F) with probability at least 1-delta. Here, A(k) is the "best" rank-k approximation (provided by truncating the Singular Value Decomposition of A), and vertical bar vertical bar X vertical bar vertical bar(F) is the Frobenius norm of the matrix X. The number of columns in C and rows in R is a low-degree polynomial in k, 1/epsilon, and log(1/delta). Our main result is obtained by an extension of our recent relative error approximation algorithm for l(2) regression from over-constrained problems to general l(2) regression problems. Our algorithm is simple, and it takes time of the order of the time needed to compute the top k right singular vectors of A. In addition, it samples the columns and rows of A via the method of "subspace sampling," so-named since the sampling probabilities depend on the lengths of the rows of the top singular vectors, and since they ensure that we capture entirely a certain subspace of interest.	Rutgers State Univ, Dept Comp Sci, RPI, Piscataway, NJ 08855 USA; Rutgers State Univ, Yahoo Res Labs, Piscataway, NJ 08855 USA	Drineas, P (reprint author), Rutgers State Univ, Dept Comp Sci, RPI, Piscataway, NJ 08855 USA.						BERRY MW, 2004, TR200432 UMIACS; Bhatia R, 1997, MATRIX ANAL; Deshpande A, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1117, DOI 10.1145/1109557.1109681; DRINEAS P, IN PRESS SIAM J COMP; DRINEAS P, 2006, 200604 DIMACS; Drineas P, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1127, DOI 10.1145/1109557.1109682; Drineas P, 2005, J MACH LEARN RES, V6, P2153; Golub G. H., 1989, MATRIX COMPUTATIONS; Goreinov SA, 1997, LINEAR ALGEBRA APPL, V261, P1; Goreinov S.A., 2001, CONT MATH, V208, P47; Horn R. A., 1985, MATRIX ANAL; Lin Z, 2004, AM J HUM GENET, V75, P850, DOI 10.1086/425587; Nashed M. Z., 1976, GEN INVERSES APPL; PASCHOU P, UNPUB; RADEMACHER L, 2005, MITLCSTR983; Stewart GW, 1999, NUMER MATH, V83, P313, DOI 10.1007/s002110050451; STEWART GW, 2004, TR200417 UMIACS; Williams CKI, 2001, ADV NEUR IN, V13, P682	18	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-38875-3	LECT NOTES COMPUT SC			2006	4168						304	314				11	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BFE55	WOS:000241478200027	
S	Cai, Y		Cai, Y; Abascal, J		Cai, Yang			Empathic computing	AMBIENT INTELLIGENCE IN EVERDAY LIFE	Lecture Notes in Computer Science		English	Article; Proceedings Paper	Workshop of Ambient Intelligence in Everyday Life	JUL 21-22, 2005	Donostia San Sebastian, SPAIN	Univ Basque Country-Euskal, Herriko Unibertsitatea, Kutxa, Univ Pais Vasco, Gipuzkoako Fern Aldundia Diputac Foral Gipuzkoa, Robotiker, Ikerlan, NASA ESTO-AIST Program, NASA LaRC C&I Initiat, ARO			SENSOR NETWORKS; SOUNDS	Empathic computing is an emergent paradigm that enables a system to understand human states and feelings and to share this intimate information. The new paradigm is made possible by the convergence of affordable sensors, embedded processors and wireless ad-hoc networks. The power law for multi-resolution channels and mobile-stationary sensor webs is introduced to resolve the information avalanche problems. As empathic computing is sensor-rich computing, particular models such as semantic differential expressions and inverse physics are discussed. A case study of a wearable sensor network for detection of a falling event is presented. It is found that the location of the wearable sensor is sensitive to the results. From the machine learning algorithm, the accuracy reaches up to 90% from 21 simulated trials. Empathic computing is not limited to healthcare. It can also be applied to solve other everyday-life problems such as management of emails and stress.	Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Cai, Y (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	ycai@cmu.edu; ycai@cmu.edu					AARTS E, 2003, NEW EVERYDAY VIEWS A; AKGUL YS, 1999, IEEE T MED IMAGING, V18; Akyildiz I.F., 2001, WIRELESS SENSOR NETW; ALBOWICZ J, RECURSIVE POSITION E; Anderson K, 2001, LANCET, V358, P1343, DOI 10.1016/S0140-6736(01)06451-0; BACKHAUS WG, 1998, COLOR VISION; BISHIP CM, 1995, NEURAL NETWORKS PATT; BOSSERT WH, 1963, RECENT PROGR HORMONE, V19, P673; CAI Y, 2005, LECT NOTES ARTIF INT, V3345, P248; CAIY, 2005, P AMBIENT INTELLIGEN; CHAN M, 1995, INT SYST 21 CENT IEE; CHANEY GR, DO YOU SNORE; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; CHONG C, 2003, SENSOR NETWORKS EVOL; Delin KA, 2005, SENSORS-BASEL, V5, P103, DOI 10.3390/s5010103; DREWSBURRY G, DESIGNING SAFE SMART; Farringdon J, 2005, LECT NOTES COMPUT SC, V3345, P202; FIGUEIREDO M, 1999, NASAS DATA PROCESSIN; GALSTYAN A, 2004, DISTRIBUTED ONLINE L; GIST YJ, 2004, WE ARE PEOPLE AGING; Gunarathne GPP, 2002, IEEE IMTC P, P1249, DOI 10.1109/IMTC.2002.1007136; Hayes P., 1995, P 14 INT JOINT C ART, P972; HERZOG A, 2003, NETWORK SOLUTIONS HO; HU Y, UNPUB REMOTE SENSING; JANG JH, 2002, P 2 JOINT EMBS BMES; KAISER R, 2000, CHICAGO TRIBUNE 1223; KAISER WJ, 2000, COMMUNICATION AC MAY, P51; KOHONEN T, STAT PATTERN RECOGNI; Kohonen T., 1988, SELF ORG ASS MEMORY; LANSING F, 2002, 2002 IGARSS C P; LEGG G, 2004, WIRELESS TECHNOLOGY; Lewin ME, 2000, AM HLTH CARE SAFETY; LI Q, 2003, DISTRIBUTED ALGORITH; LI WB, 2001, ERGONOMICS INTERIOR; Mainwaring A., 2002, WIRELESS SENSOR NETW; MCCLINTOCK MK, 1984, PHYSIOL BEHAV, V32, P701, DOI 10.1016/0031-9384(84)90181-1; McDermott MM, 2004, JAMA-J AM MED ASSOC, V292, P453, DOI 10.1001/jama.292.4.453; MCNABB R, 2005, PHILOSOPHY NOW; MERIBOUT M, 2002, PATTERN RECOGNITION, V35; Michell T.M., 1997, MACHINE LEARNING; Moore Gordon, 1965, ELECTRONICS, V38; ORDONEZ J, 2005, NEWSWEEK        1128; Pasterkamp H, 1997, AM J RESP CRIT CARE, V156, P974; PATHIRANA PN, 2005, NODE LOCALIZATION US; Perrig A, 2002, WIREL NETW, V8, P521, DOI 10.1023/A:1016598314198; Picton P., 2000, NEURAL NETWORKS; POPPLE AV, 1996, PSYCHOLOGY, V7; Rinberg D, 2000, NATURE, V406, P368, DOI 10.1038/35019161; RODGERS CD, 2002, WORLD SCI; SCHNORRENBERGER C, 2005, POCKET ATLAS TONGUE; Shah Rahul C., 2002, ENERGY AWARE ROUTING; SILVERSTRIM JE, 2005, Patent No. 33051; Sinha A, 2001, IEEE DES TEST COMPUT, V18, P62, DOI 10.1109/54.914626; Smith R.J.F., 1992, Reviews in Fish Biology and Fisheries, V2, P33, DOI 10.1007/BF00042916; Spath H., 1980, CLUSTER ANAL ALGORIT; SPITERI MA, 1988, LANCET, V1, P873; STARNER T, NEW SCI; SUNG, J NEUROENGINEERIGN R; Sung M., 2004, WORKSH APPL MOB EMB; SUNG M, 2005, HCI INT; Tanz O, 2005, LECT NOTES COMPUT SC, V3345, P248; TAYLOR C, 2005, SIMULTANEOUS LOCALIZ; TESSIER R, 2001, J VLSI SIGNAL PROCES, V28; TREDENNICK N, 1998, COMPUT DES, P55; Turing A.M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433; VANN L, 2002 IEEE IMTC; Wang JJ, 1999, IEEE T NUCL SCI, V46, P1728, DOI 10.1109/23.819146; Wasserman P. D., 1993, ADV METHODS NEURAL C; WATSUJI T, 1999, IEEE INT FUZZ SYST C, P145; WATT SNK, 1996, PSYCHOLOGY, V7; WEIZENBA.J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/365153.365168; Weizenbaum J., 1976, COMPUTER POWER HUMAN; WEST BW, WIRELESS SENSOR NETW; WILLIAMS JA, IEEE ICFPT 2002; WINSTON R, 2004, HUMAN; WU H, 1999, P IMTC 1998 IEEE T I, V48, P1005; WU H, P IMTC 2002 ANCH AK; Wyatt TD, 2003, PHEROMONES ANIMAL BE; Xu L, 1999, IMAGE VISION COMPUT, V17, P65, DOI 10.1016/S0262-8856(98)00091-2; YAO P, 1996, COMP TCM TONGUE IMAG; YU ZS, 2005, FEED NEURAL NETWORK; ZBIBOWSKI R, 2005, IEEE SPECTRUM    NOV; ZHANG E, 1990, DIAGNOSTICS TRADITIO; ZHAO J, 2003, DENSE WIRELESS SENSO; Zhou X.S., 2003, EXPLORATION VISUAL D; *CROSSB TECHN INC, 2005, CROSSB MOTE KIT 5X4X	86	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37785-9	LECT NOTES COMPUT SC			2006	3864						67	85				19	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEY99	WOS:000240189200003	
S	Goldman, BB; Walters, WP		Spellmeyer, DC		Goldman, Brian B.; Walters, W. Patrick			Machine Learning in Computational Chemistry	ANNUAL REPORTS IN COMPUTATIONAL CHEMISTRY, VOL 2	Annual Reports in Computational Chemistry		English	Article; Book Chapter							SUPPORT VECTOR MACHINES; HIGH-THROUGHPUT DOCKING; NAIVE BAYES CLASSIFIER; AQUEOUS SOLUBILITY; FEATURE-SELECTION; RANDOM FOREST; COMPOUND CLASSIFICATION; DIHYDROFOLATE-REDUCTASE; CYTOCHROME-P450 3A4; MOLECULAR-STRUCTURE		[Goldman, Brian B.; Walters, W. Patrick] Vertex Pharmaceut Inc, Cambridge, MA 02139 USA	Goldman, BB (reprint author), Vertex Pharmaceut Inc, 130 Waverley St, Cambridge, MA 02139 USA.						Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Bender A, 2005, J BIOMOL SCREEN, V10, P658, DOI 10.1177/1087057105281048; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; Bender A, 2004, J MED CHEM, V47, P6569, DOI 10.1021/jm049611i; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Cristianini N., 2000, INTRO SUPPORT VECTOR; Crivori P, 2000, J MED CHEM, V43, P2204, DOI 10.1021/jm990968+; DANNENFELSER R, 1989, COMPUT APPL BIOSCI, V5, P235; Dietterich T. G., 2002, ENSEMBLE LEARNING HD; Dimitrov S, 2005, J CHEM INF MODEL, V45, P839, DOI 10.1021/ci0500381; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GHOSE AK, 1987, J CHEM INF COMP SCI, V27, P21, DOI 10.1021/ci00053a005; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; Guha R, 2005, J CHEM INF MODEL, V45, P65, DOI 10.1021/ci0497511; Guner O. F., 2000, PHARMACOPHORE PERCEP; Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472; He L, 2005, J MOL GRAPH MODEL, V23, P503, DOI 10.1016/j.jmgm.2005.03.003; Huuskonen J, 2000, J CHEM INF COMP SCI, V40, P773, DOI 10.1021/ci9901338; Izmirlian G, 2004, ANN NY ACAD SCI, V1020, P154, DOI 10.1196/annals.1310.015; Jorissen RN, 2005, J CHEM INF MODEL, V45, P549, DOI 10.1021/ci049641u; Katritzky AR, 1998, J CHEM INF COMP SCI, V38, P720, DOI 10.1021/ci980022t; KING RD, 1992, P NATL ACAD SCI USA, V89, P11322, DOI 10.1073/pnas.89.23.11322; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; Klon AE, 2004, J MED CHEM, V47, P4356, DOI 10.1021/jm049970d; Klon AE, 2004, J MED CHEM, V47, P2743, DOI 10.1021/jm030363k; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Sadowski J, 1998, J MED CHEM, V41, P3325, DOI 10.1021/jm9706776; Labute P, 2000, J MOL GRAPH MODEL, V18, P464, DOI 10.1016/S1093-3263(00)00068-1; Lind P, 2003, J CHEM INF COMP SCI, V43, P1855, DOI 10.1021/ci034107s; Mahe P, 2005, J CHEM INF MODEL, V45, P939, DOI 10.1021/ci050039t; Marchand-Geneste N, 2002, J MED CHEM, V45, P399, DOI 10.1021/jm0155244; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mitchell T. M., 1997, MACH LEARN, P20; Muller KR, 2005, J CHEM INF MODEL, V45, P249, DOI 10.1021/ci049737o; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Omega, OPENEYE SCI SOFTW; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Saeh JC, 2005, J CHEM INF MODEL, V45, P1122, DOI 10.1021/ci049732r; Scholkopf B., 1999, ADV KERNEL METHODS S; SDK Accord, 2005, ACC SDK; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P1912, DOI 10.1021/ci049782w; Shi T, 2005, MODERN PATHOL, V18, P547, DOI 10.1038/modpathol.3800322; Sun HM, 2005, J MED CHEM, V48, P4031, DOI 10.1021/jm050180t; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Todeschini R., 2000, HDB MOL DESCRIPTORS; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; Vapnik V. N, 1995, NATURE STAT LEARNING; Walters WP, 2005, CURR OPIN DRUG DISC, V8, P329; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Weston J, 2003, BIOINFORMATICS, V19, P764, DOI 10.1093/bioinformatics/btg054; Wiitten I. H., 2005, DATA MINING, P315; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Zupan J., 1999, NEURAL NETWORKS CHEM; [Anonymous], 2005, MDL DRUG DAT REP; [Anonymous], 2005, PHYS PROP DAT PHYSPR	62	14	14	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1574-1400	978-0-08-046542-5	ANN REP COMP CHEM			2006	2						127	140		10.1016/S1574-1400(06)02008-1		14	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	BCU02	WOS:000311389000009	
S	Sajda, P				Sajda, Paul			Machine learning for detection and diagnosis of disease	ANNUAL REVIEW OF BIOMEDICAL ENGINEERING	ANNUAL REVIEW OF BIOMEDICAL ENGINEERING		English	Review; Book Chapter						blind source separation; support vector machine; Bayesian network; medical imaging; computational biology	INDEPENDENT COMPONENT ANALYSIS; ARTIFICIAL NEURAL-NETWORK; HIDDEN MARKOV-MODELS; NONNEGATIVE MATRIX FACTORIZATION; BLIND SOURCE SEPARATION; BENIGN CLUSTERED MICROCALCIFICATIONS; MAGNETIC-RESONANCE-SPECTROSCOPY; COMPUTER-AIDED DIAGNOSIS; SUPPORT VECTOR MACHINES; PATTERN-RECOGNITION	Machine learning offers a principled approach for developing sophisticated, automatic, and objective algorithms for analysis of high-dimensional and multimodal biomedical data. This review focuses on several advances in the state of the art that have shown promise in improving detection, diagnosis, and therapeutic monitoring of disease. Key in the advancement has been the development of a more ill-depth understanding and theoretical analysis of critical issues related to algorithmic construction and learning theory. These include trade-offs for maximizing generalization performance, use of physically realistic constraints, and incorporation of prior knowledge and uncertainty. The review describes recent developments in machine learning, focusing on supervised and unsupervised linear methods and Bayesian inference, which have made significant impacts in the detection and diagnosis of disease in biomedicine. We describe the different methodologies and, for each, provide examples of their application to specific domains in biomedical diagnostics.	Columbia Univ, Dept Biomed Engn, New York, NY 10027 USA	Sajda, P (reprint author), Columbia Univ, Dept Biomed Engn, New York, NY 10027 USA.	ps629@columbia.edu					Aizerman M.A., 1964, AUTOMAT REM CONTR, P821; Andreassen S, 1987, P 10 INT JOINT C ART, P366; Baumgartner C, 2005, J BIOMED INFORM, V38, P89, DOI 10.1016/j.jbi.2004.08.009; Beckwith-Hall BM, 1998, CHEM RES TOXICOL, V11, P260, DOI 10.1021/tx9700679; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307; BIRD RE, 1990, RADIOLOGY, V177, P8; Bishop C.M., 1995, NEURAL NETWORKS PATT; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CARDOSO JF, 1993, IEE PROC-F, V140, P362; Chan HP, 1998, MED PHYS, V25, P2007, DOI 10.1118/1.598389; Cheng H, 2001, IEEE T IMAGE PROCESS, V10, P511, DOI 10.1109/83.913586; COI H, 2001, IEEE T IMAGE PROCESS, V10, P1309; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cover TM, 1991, ELEMENTS INFORM THEO; CRAMMER K, 2000, P ANN C COMP LEARN T; Cristianni N., 2000, INTRO SUPPORT VECTOR; Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; Dempster NM, 1977, J R STAT SOC B, V39, P185; Diez FJ, 1997, ARTIF INTELL MED, V10, P59, DOI 10.1016/S0933-3657(97)00384-9; DOI K, 1993, ACTA RADIOL, V34, P426; Duda R. O., 2001, PATTERN CLASSIFICATI; EDELENYI FS, 2000, NAT MED, V6, P1287; El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569; FLOYD CE, 1994, CANCER, V74, P2944, DOI 10.1002/1097-0142(19941201)74:11<2944::AID-CNCR2820741109>3.0.CO;2-F; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Furuya S, 1997, NMR BIOMED, V10, P25, DOI 10.1002/(SICI)1099-1492(199701)10:1<25::AID-NBM445>3.0.CO;2-M; Ghahramani Z., 1998, LECT NOTES ARTIF INT, P168; Giger M, 2000, HDB MED IMAGING, V2, P917; Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GUILLAMET D, 2002, P 16 INT C PATT REC, V2, P116; GUILLAMET D, 2001, IEEE COMP SOC C VIS, P942; HAWKINS J, 2004, INTELLIGENCE NEW UND; HECKERMAN DE, 1992, COMPUT BIOMED RES, V25, P56, DOI 10.1016/0010-4809(92)90035-9; Hojen-Sorensen PADFR, 2002, NEURAL COMPUT, V14, P889, DOI 10.1162/089976602317319009; Hoyer P.O., 2002, NEURAL NETWORKS SIGN, P557; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huo ZM, 1998, ACAD RADIOL, V5, P155, DOI 10.1016/S1076-6332(98)80278-X; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Inamura K, 2005, ONCOGENE, V24, P7105, DOI 10.1038/sj.onc.1208858; Jebara T., 2003, MACHINE LEARNING DIS; Jiang YL, 1996, RADIOLOGY, V198, P671; Jolliffe I.T., 1989, PRINCIPAL COMPONENT; Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026; Kao KC, 2004, P NATL ACAD SCI USA, V101, P641, DOI 10.1073/pnas.0305287101; Kapetanovic IM, 2004, ANN NY ACAD SCI, V1020, P10, DOI 10.1196/annals.1310.003; Keun HC, 2002, CHEM RES TOXICOL, V15, P1380, DOI 10.1021/tx0255774; KRESSEL U, 1999, ADV KERNEL METHODS S, pCH15; Ladroue C, 2003, MAGNET RESON MED, V50, P697, DOI 10.1002/mrm.10595; Lee DD, 1997, ADV NEUR IN, V9, P515; Lee DD, 1999, NATURE, V401, P788; LEE JS, 2001, INT C IND COMP AN BL, P629; Lee N, 2001, FOOD AGR IMMUNOL, V13, P5, DOI 10.1080/09540100051074149; LI L, 1997, ACAD RADIOL, V11, P724; Liao JC, 2003, P NATL ACAD SCI USA, V100, P15522, DOI 10.1073/pnas.2136632100; Liu Y, 2004, J CHEM INF COMP SCI, V44, P1936, DOI 10.1021/ci049810a; Lo JY, 1996, P SOC PHOTO-OPT INS, V2710, P725, DOI 10.1117/12.237977; Lo SCB, 1995, NEURAL NETWORKS, V8, P1201, DOI 10.1016/0893-6080(95)00061-5; Majumder SK, 2005, J BIOMED OPT, V10, DOI 10.1117/1.1897396; METZ CE, 1992, MED DECIS MAKING, V12, P60, DOI 10.1177/0272989X9201200110; Mierisova S, 2001, NMR BIOMED, V14, P247, DOI 10.1002/nbm.697; MILLER RA, 1982, NEW ENGL J MED, V307, P468, DOI 10.1056/NEJM198208193070803; Moler EJ, 2000, PHYSIOL GENOMICS, V4, P109; MOLGEDEY L, 1994, PHYS REV LETT, V72, P3634, DOI 10.1103/PhysRevLett.72.3634; MUKHERJEE S, 1999, 1677 AI MIT; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Negendank WG, 1996, J NEUROSURG, V84, P449, DOI 10.3171/jns.1996.84.3.0449; Netsch T, 1999, IEEE T MED IMAGING, V18, P774, DOI 10.1109/42.802755; Ng AY, 2002, ADV NEUR IN, V14, P841; Nicholls AW, 2001, CHEM RES TOXICOL, V14, P975, DOI 10.1021/tx000231j; Nicholson JK, 1999, XENOBIOTICA, V29, P1181; Nikovski D, 2000, IEEE T KNOWL DATA EN, V12, P509, DOI 10.1109/69.868904; NISHIKAWA RM, 1996, RADIOLOGY, V201, P256; NISHIKAWA RM, 1995, RAD SOC N AM CHIC IL, P425; Nuzillard D, 1998, J MAGN RESON, V133, P358, DOI 10.1006/jmre.1998.1481; Ochs MF, 1999, J MAGN RESON, V137, P161, DOI 10.1006/jmre.1998.1639; Parra L, 2000, ADV NEUR IN, V12, P942; Parra L., 2003, J MACHINE LEARNING R, V4, P1261, DOI 10.1162/jmlr.2003.4.7-8.1261; Parra L, 2000, IEEE T SPEECH AUDI P, V8, P320, DOI 10.1109/89.841214; PARRA LC, 2000, ADV NEURAL INFORM PR, P786; Pearl J., 1988, PROBABILISTIC REASON; PEARLMUTTER B, 1995, ADV NEURAL INFORM PR, V9; Platt JC, 2000, ADV NEUR IN, V12, P547; Plumbley M, 2002, IEEE SIGNAL PROC LET, V9, P177, DOI 10.1109/LSP.2002.800502; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Rao R. P. N., 2002, PROBABILISTIC MODELS; Robertson DG, 2000, TOXICOL SCI, V57, P326, DOI 10.1093/toxsci/57.2.326; Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100; SAJDA P, 1998, ADV NEURAL INFORM PR, V11, P938; Sajda P, 2003, MED IMAGE ANAL, V7, P187, DOI 10.1016/S1361-8415(03)00003-3; Sajda P, 2005, INT J IMAG SYST TECH, V15, P1, DOI 10.1002/ima.20032; SAJDA P, 1996, DIGITAL MAMMOGRAPHY, V96, P291; Sajda P, 2002, DIS MARKERS, V18, P339; SAJDA P, 2003, P 4 INT S IND COMP A, P71; Sajda P, 2002, IEEE T MED IMAGING, V21, P239, DOI 10.1109/42.996342; Sajda P, 2004, IEEE T MED IMAGING, V23, P1453, DOI 10.1109/TMI.2004.834626; Scholkopf B., 2000, NEURAL COMPUT, V12, P1083; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B., 1998, ADV KERNEL METHODS S; Scholkopf B, 2004, KERNEL METHODS COMPU; Segal NH, 2003, AM J PATHOL, V163, P691, DOI 10.1016/S0002-9440(10)63696-6; Segal NH, 2003, J CLIN ONCOL, V21, P1775, DOI 10.1200/JCO.2003.10.108; Shortliffe E. H., 1975, Mathematical Biosciences, V23, DOI 10.1016/0025-5564(75)90047-4; Smyth P, 1997, PATTERN RECOGN LETT, V18, P1261, DOI 10.1016/S0167-8655(97)01050-7; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Stoyanova R, 2004, J MAGN RESON, V170, P329, DOI 10.1016/j.jmr.2004.07.009; Stoyanova R, 2004, ANAL CHEM, V76, P3666, DOI 10.1021/ac049849e; THURFJELL EL, 1994, RADIOLOGY, V191, P241; Vanhamme L, 1999, J MAGN RESON, V140, P120, DOI 10.1006/jmre/1999.1835; Vapnik V.N., 1999, NATURE STAT LEARNING; Wells W M 3rd, 1996, Med Image Anal, V1, P35, DOI 10.1016/S1361-8415(96)80004-1; Wainwright M. J., 1999, NEURAL INFORMATION P, V12, P855; Wainwright MJ, 2001, APPL COMPUT HARMON A, V11, P89, DOI 10.1006/acha.2000.0350; WANG B, 2005, P DMRN SUMM C GLASG; Wei LY, 2005, IEEE T MED IMAGING, V24, P371, DOI 10.1109/TMI.2004.842457; Weston J, 1999, P EUR S ART NEUR NET; Xu W., 2003, SIGIR 03, P267; Yedidia J. S., 2003, EXPLORING ARTIFICIAL, P239; ZHANG W, 1994, MED PHYS, V21, P517; Zhang W, 1996, MED PHYS, V23, P595, DOI 10.1118/1.597891; Zheng BY, 1996, IEEE T MED IMAGING, V15, P589	127	24	25	ANNUAL REVIEWS	PALO ALTO	4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0139 USA	1523-9829	978-0-8243-3508-3	ANNU REV BIOMED ENG	Annu. Rev. Biomed. Eng.		2006	8						537	565		10.1146/annurev.bioeng.8.061505.095802		29	Engineering, Biomedical	Engineering	081CI	WOS:000240294400017	
B	Howley, T; Madden, MG; O'Connell, ML; Ryder, AG		Macintosh, A; Ellis, R; Allen, T		Howley, T; Madden, MG; O'Connell, ML; Ryder, AG			The effect of principal component analysis on machine learning accuracy with high dimensional spectral data	Applications and Innovations in Intelligent Systems XIII	B C S CONFERENCE SERIES		English	Proceedings Paper	25th International Conference on Innovative Techniques and Applications of Artificial Intelligence	DEC, 2005	Cambridge, ENGLAND	SGAI			CLASSIFICATION	This paper presents the results of an investigation into the use of machine learning methods for the identification of narcotics from Raman spectra. The classification of spectral data and other high dimensional data, such as images, gene-expression data and spectral data, poses an interesting challenge to machine learning, as the presence of high numbers of redundant or highly correlated attributes can seriously degrade classification accuracy. This paper investigates the use of Principal Component Analysis (PCA) to reduce high dimensional spectral data and to improve the predictive performance of some well known machine learning methods. Experiments are carried out on a high dimensional spectral dataset. These experiments employ the NIPALS (Non-Linear Iterative Partial Least Squares) PCA method, a method that has been used in the field of chemometrics for spectral classification, and is a more efficient alternative than the widely used eigenvector decomposition approach. The experiments show that the use of this PCA method can improve the performance of machine learning in the classification of high dimensionsal data.	Natl Univ Ireland Univ Coll Galway, Galway, Ireland	Howley, T (reprint author), Natl Univ Ireland Univ Coll Galway, Galway, Ireland.		Ryder, Alan /C-1297-2009				BULIN B, 1991, RAMAN EFFECT INTRO; CHENG C, 1995, J FORENSIC SCI, V40, P31; COHEN W, 2002, P 12 INT C MACH LEAR, P115; CONROY J, 2005, IN PRESS P SPIE INT, V5826; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Hastie T, 2001, ELEMENTS STAT LEARNI; Joachims T., 1998, P EUR C MACH LEARN E; NADEAU C, 2000, ADV NEURAL INFORM PR, V12; OCONNELL M, 2005, IN PRESS P SPIE INT, V5826; Peng SH, 2003, FEBS LETT, V555, P358, DOI 10.1016/S0014-5793(03)01275-4; POPELINSKY L, 2000, P PKDD WORKSH DAT MI; POPELINSKY L, 2001, P ECML PKDD IDDM WOR; QUINLAN R, 1990, MACHINE LEARNING, V5; Ryder AG, 2002, J FORENSIC SCI, V47, P275; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; Scholkopf B., 2002, LEARNING KERNELS SUP; SIGURDSSON S, 2004, IEEE T BIOM ENG, V51; WANG J, 2005, IN PRESS P INT JOINT; Witten I. H., 2000, DATA MINING PRACTICA	19	0	0	SPRINGER-VERLAG LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL RD FARNCOMBE, GODALMING GU7 1NH, SURREY, ENGLAND		1-84628-223-3	BCS CONF SERIES			2006							209	222		10.1007/1-84628-224-1_16		14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BED49	WOS:000236883700016	
S	Bakir, B; Sezerman, OU		Rothlauf, F		Bakir, B; Sezerman, OU			Functional classification of G-Protein Coupled Receptors, based on their specific ligand coupling patterns	APPLICATIONS OF EVOLUTIONARY COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	EvoWorkshops 2006	APR 10-12, 2006	Budapest, HUNGARY	EvoNet, Artpool Art Res Ctr			SUPPORT VECTOR MACHINES; AMINO-ACID-COMPOSITION; TOPOLOGY PREDICTION; SEQUENCES	Functional identification of C-Protein Coupled Receptors (GPCRs) is one of the current focus areas of pharmaceutical research. Although thousands of GPCR sequences are known, many of them remain as orphan sequences (the activating ligand is unknown). Therefore, classification methods for automated characterization of orphan GPCRs are imperative. In this study, for predicting Level 2 subfamilies of Amine GPCRs, a novel method for obtaining fixed-length feature vectors, based on-the existence of activating ligand specific patterns, has been developed and utilized for a Support Vector Machine (SVM)-based classification. Exploiting the fact that there is a non-promiscuous relationship between the specific binding of GPCRs into their ligands and their functional classification, our method classifies Level 2 subfamilies of Amine GPCRs with a high predictive accuracy of 97.02% in a ten-fold cross validation test. The presented machine learning approach, bridges the gulf between the excess amount of GPCR sequence data and their poor functional characterization.	Georgia Inst Technol, Sch Biol, Atlanta, GA 30332 USA; Sabanci Univ, Istanbul, Turkey	Bakir, B (reprint author), Georgia Inst Technol, Sch Biol, Atlanta, GA 30332 USA.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Attwood TK, 2003, NUCLEIC ACIDS RES, V31, P400, DOI 10.1093/nar/gkg030; BAHSIN M, 2004, NUCLEIC ACIDS RES, V32, P383; Chalmers DT, 2002, NAT REV DRUG DISCOV, V1, P599, DOI 10.1038/nrd872; Brazma A., 1996, P 4 INT C INT SYST M, P34; Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Horn F, 1998, NUCLEIC ACIDS RES, V26, P275, DOI 10.1093/nar/26.1.275; Hsu C.-W., 2004, PRACTICAL GUIDE SUPP; JONASSEN I, 1995, PROTEIN SCI, V4, P1587; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; KRZYSTOF P, 2000, SCIENCE, V4, P739; Lin H.-T., 2003, STUDY SIGMOID KERNEL; Mulder NJ, 2003, NUCLEIC ACIDS RES, V31, P315, DOI 10.1093/nar/gkg046; NEUWALD AF, 1994, J MOL BIOL, V239, P698, DOI 10.1006/jmbi.1994.1407; Otaki JM, 2001, J THEOR BIOL, V211, P77, DOI 10.1006/jtbi.2001.2272; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; QUINLAN JR, 1988, C45 PROGRAMS MACHINE; SAKDA T, 2005, BIOINFORMATICS, V21, P378; Schoneberg T, 2002, REV PHYSIOL BIOCH P, V144, P143; Sreekumar KR, 2004, BIOINFORMATICS, V20, P3490, DOI 10.1093/bioinformatics/bth434; Tusnady GE, 2001, BIOINFORMATICS, V17, P849, DOI 10.1093/bioinformatics/17.9.849; Tusnady GE, 1998, J MOL BIOL, V283, P489, DOI 10.1006/jmbi.1998.2107; Vapnik V. N, 1995, NATURE STAT LEARNING; Vert J.P., 2001, INTRO SUPPORT VECTOR; VILO J, 2001, BIOINFORMATICS, V17, P174; Yang ZR, 2004, BRIEF BIOINFORM, V5, P328, DOI 10.1093/bib/5.4.328; Ying Huang, 2004, Computational Biology and Chemistry, V28, DOI 10.1016/j.compbiolchem.2004.08.001; YING H, 2004, LECT NOTES COMPUT SC, V3174, P448	32	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33237-5	LECT NOTES COMPUT SC			2006	3907						1	12				12	Computer Science, Theory & Methods	Computer Science	BEG67	WOS:000237228900001	
S	Marchiori, E; Jimenez, CR; West-Nielsen, M; Heegaard, NHH		Rothlauf, F		Marchiori, E; Jimenez, CR; West-Nielsen, M; Heegaard, NHH			Robust SVM-based biomarker selection with noisy mass spectrometric proteomic data	APPLICATIONS OF EVOLUTIONARY COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	EvoWorkshops 2006	APR 10-12, 2006	Budapest, HUNGARY	EvoNet, Artpool Art Res Ctr			PROSTATE-CANCER; OVARIAN-CANCER; SERUM; PATTERNS; ALGORITHMS	Computational analysis of mass spectrometric (MS) proteomic data from sera is of potential relevance for diagnosis, prognosis, choice of therapy, and study of disease activity. To this aim, feature selection techniques based on machine learning can be applied for detecting potential biomarkes and biomaker patterns. A key issue concerns the interpretability and robustness of the output results given by such techniques. In this paper we propose a robust method for feature selection with MS proteomic data. The method consists of the sequentail application of a filter feature selection algorithm, RELIEF, followed by multiple runs of a wrapper feature selection technique based on support vector machines (SVM), where each run is obtained by changing the class label of one support vector. Frequencies of features selected over the runs are used to identify features which are robust with respect to perturbations of the data. This method is tested on a dataset produced by a specific MS technique, called MALDI-TOF MS. Two classes have been artificially generated by spiking. Moreover, the samples have been collected at different storage durations. Leave-one-out cross validation (LOOCV) applied to the resulting dataset, indicates that the proposed feature selection method is capable of identifying highly discriminatory proteomic patterns.	Vrije Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands; Vrije Univ Amsterdam, Dept Mol & Cellular Neurobiol, Amsterdam, Netherlands; Statens Serum Inst, Dept Autoimmunol, DK-2300 Copenhagen, Denmark	Marchiori, E (reprint author), Vrije Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands.	elena@cs.vu.nl; connie.jimenez@falw.vu.nl; MWN@ssi.dk; NHE@ssi.dk					Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Cristianini N., 2000, SUPPORT VECTOR MACHI; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Evgeniou T, 2004, MACH LEARN, V55, P71, DOI 10.1023/B:MACH.0000019805.88351.60; GEORGE H, 1994, INT C MACH LEARN, P121; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; JONG K, 2004, IEEE S COMP INT BIOI; KIRA K, 1992, 10 NAT C ART INT, P129; Li JN, 2002, CLIN CHEM, V48, P1296; LIE H, 1998, INT SERIES ENG COMPU; Liu Huiqing, 2002, Genome Inform, V13, P51; Marchiori E, 2005, Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology, P385; Marshall E, 2004, SCIENCE, V306, P630, DOI 10.1126/science.306.5696.630; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; OH IS, 2002, 16 INT C PATT REC IC; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Issaq HJ, 2003, ANAL CHEM, V75, p148A, DOI 10.1021/ac031249c; Qu YS, 2002, CLIN CHEM, V48, P1835; Ransohoff DF, 2005, J NATL CANCER I, V97, P315, DOI 10.1093/jnci/dji054; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; RENDELL LA, 1992, INT C MACH LEARN, P249; Vapnik VN, 1998, STAT LEARNING THEORY; WESTNIELSEN M, 2005, ANAL CHEM, V11, P5114; XING E, 2003, PRACTICAL APPROACH M; Yu L, 2003, ICML, P856; Zhu W, 2003, P NATL ACAD SCI USA, V100, P14666, DOI 10.1073/pnas.2532248100	28	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33237-5	LECT NOTES COMPUT SC			2006	3907						79	90				12	Computer Science, Theory & Methods	Computer Science	BEG67	WOS:000237228900008	
S	Stout, M; Bacardit, J; Hirst, JD; Krasnogor, N; Blazewicz, J		Rothlauf, F		Stout, M; Bacardit, J; Hirst, JD; Krasnogor, N; Blazewicz, J			From HP lattice models to real proteins: Coordination number prediction using learning classifier systems	APPLICATIONS OF EVOLUTIONARY COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	EvoWorkshops 2006	APR 10-12, 2006	Budapest, HUNGARY	EvoNet, Artpool Art Res Ctr			SEQUENCE; DATABASE; ALGORITHMS	Prediction of the coordination number (CN) of residues in proteins based solely on protein sequence has recently received renewed attention. At the same time, simplified protein models such as the HP model have been used to understand protein folding and protein structure prediction. These models represent the sequence of a protein using two residue types: hydrophobic and polar, and restrict the residue locations to those of a lattice. The aim of this paper is to compare CN prediction at three levels of abstraction a) 3D Cubic lattice HP model proteins, b) Real proteins represented by their HP sequence and c) Real proteins using residue sequence alone. For the 3D HP lattice model proteins the CN of each residue is simply the number of neighboring residues on the lattice. For the real proteins, we use a recent real-valued definition of CN proposed by Kinjo et al. To perform the predictions we use GAssist, a recent evolutionary computation based machine learning method belonging to the Learning Classifier System (LCS) family. Its performance was compared against some alternative learning techniques. Predictions using the HP sequence representation with only two residue types were only a little worse than those using a full 20 letter amino acid alphabet (64% vs 68% for two state prediction, 45% vs 50% for three state prediction and 30% vs 33% for five state prediction). That HP sequence information alone can result in predictions accuracies that are within 5% of those obtained using full residue type information indicates that hydrophobicity is a key determinant of CN and further justifies studies of simplified models.	Univ Nottingham, Automated Scheduling Optimizat & Planning Res Grp, Sch Comp Sci & IT, Nottingham NG8 1BB, England; Univ Nottingham, Sch Chem, Nottingham NG7 2RD, England; Poznan Univ Technol, Inst Comp Sci, PL-60965 Poznan, Poland	Stout, M (reprint author), Univ Nottingham, Automated Scheduling Optimizat & Planning Res Grp, Sch Comp Sci & IT, Jubilee Campus,Wollaton Rd, Nottingham NG8 1BB, England.	mqs@cs.nott.ac.uk; jqb@cs.nott.ac.uk; jonathan.hirst@nottingham.ac.uk; nxk@cs.nott.ac.uk; jb1azewicz@cs.put.poznan.pl	Hirst, Jonathan/G-7681-2011				ABE H, 1981, BIOPOLYMERS, V20, P1013, DOI 10.1002/bip.1981.360200512; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bacardit J, 2004, LECT NOTES COMPUT SC, V3242, P1021; BACARDIT J, 2004, THESIS R LULL U BARC; Baldi P, 2003, J MACHINE LEARNING R, V4, P575; Broome BM, 2000, J MOL BIOL, V296, P961, DOI 10.1006/jmbi.2000.3514; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; ESCUELA G, 2005, LECT NOTES COMPUTER, V3447, P73; HART W, 1997, J COMPUT BIOL, P1; HART WE, 1995, SAND951294; HINDS DA, 1992, P NATL ACAD SCI USA, V89, P2536, DOI 10.1073/pnas.89.7.2536; HOLLAND JH, 1975, ADAPTATION NATURAL A; John G. H., 1995, P 11 C UNC ART INT, P338; Kinjo AR, 2005, PROTEINS, V58, P158, DOI 10.1002/prot.20300; KRASNOGOR N, 1998, AID98 P WORKSH ART I; Krasnogor N., 2002, LECT NOTES COMPUTER, P769; KRASNOGOR N, 1999, GECCO99 P GEN EV COM; KRASNOGOR N, 2002, FUZZY SETS BASED HEU; KRASNOGOR N, 1998, P FRONT EV ALG 1998; Li TP, 2003, PROTEIN ENG, V16, P323, DOI 10.1093/protein/gzg044; MacCallum Robert M, 2004, Bioinformatics, V20 Suppl 1, pi224, DOI 10.1093/bioinformatics/bth913; MILLER RG, 1981, SIMULTANEOUS STAT IN; MILLER S, 1987, J MOL BIOL, V196, P641, DOI 10.1016/0022-2836(87)90038-6; Noguchi T, 2001, NUCLEIC ACIDS RES, V29, P219, DOI 10.1093/nar/29.1.219; Quinlan J. R., 1993, C45 PROGRAMS MACHINE; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SANDER C, 1991, PROTEINS, V9, P56, DOI 10.1002/prot.340090107; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; Witten I. H., 2000, DATA MINING PRACTICA; YUE K, 1995, P NATL ACAD SCI USA, V92, P325, DOI 10.1073/pnas.92.1.325; Zhao Y., 2003, P IEEE S BIOINF BIOE, P26	31	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33237-5	LECT NOTES COMPUT SC			2006	3907						208	220				13	Computer Science, Theory & Methods	Computer Science	BEG67	WOS:000237228900019	
S	Archetti, F; Messina, E; Toscani, D; Vanneschi, L		Rothlauf, F		Archetti, F; Messina, E; Toscani, D; Vanneschi, L			Classifying and counting vehicles in traffic control applications	APPLICATIONS OF EVOLUTIONARY COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	EvoWorkshops 2006	APR 10-12, 2006	Budapest, HUNGARY	EvoNet, Artpool Art Res Ctr				This paper presents a machine learning system to handle traffic control applications. The input of the system is a set of image sequences coming from a fixed camera. The system can be divided into two main subsystems: the first one, based on Artificial Neural Networks classifies the typology of vehicles moving within a limited image area for each frame of the sequence; the second one, based on Genetic Algorithms, takes as input the frame-by-frame classifications and reconstructs the global traffic scenario by counting the number of vehicles of each typology. This task is particularly hard when the frame rate is low. The results obtained by our system are reliable even for very low frame rate (i.e. four frames per second). Our system is currently used by a company for real-time traffic control.	Univ Milano Bicocca, DISCo, Milan, Italy	Archetti, F (reprint author), Univ Milano Bicocca, DISCo, Milan, Italy.	archetti@disco.unimib.it; messina@disco.unimib.it; toscani@disco.unimib.it; vanneschi@disco.unimib.it					EIKVIL L, 2001, SCAND C IM AN SCIA01; GIULIANO G, 2004, RAPIDLY DEPLOYABLE S; Goldberg DE, 1989, GENETIC ALGORITHMS S; Haykin S., 1999, NEURAL NETWORKS COMP; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOURDAKIS J, 2005, 0507 CTS INT TRANSP; KWIGIZILE V, 2004, P 17 INT FLOR ART IN; Mitchell T., 1996, MACHINE LEARNING; OJA E, 1995, HDB BRAIN THEORY NEU, P753; PAPANIKOLOPOULO.N, 2004, 0405 CTS INT TRANSP; VANESCHI L, 2005, P 7 INT C ART EV EA	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33237-5	LECT NOTES COMPUT SC			2006	3907						495	499				5	Computer Science, Theory & Methods	Computer Science	BEG67	WOS:000237228900044	
S	Gounaropoulos, A; Johnson, C		Rothlauf, F		Gounaropoulos, Alex; Johnson, Colin			Synthesising timbres and timbre-changes from adjectives/adverbs	APPLICATIONS OF EVOLUTIONARY COMPUTING, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	EvoWorkshops 2006	APR 10-12, 2006	Budapest, HUNGARY	EvoNet, Artpool Art Res Ctr				Synthesising timbres and changes to timbres from natural language descriptions is an interesting challenge for computer music. This paper describes the current state of an ongoing project which takes a machine learning approach to this problem. We discuss the challenges that are presented by this, discuss various strategies for tackling this problem, and explain some experimental work. In particular our approach is focused on the creation of a system that uses an analysis-synthesis cycle to learn and then produce such timbre changes.	Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England	Gounaropoulos, A (reprint author), Univ Kent, Comp Lab, Canterbury CT2 7NF, Kent, England.	ag84@kent.ac.uk; cgj@kent.ac.uk					DISLEY AC, 2004, SPEECH MUSIC HEARING, V46; ETHERINGTON R, 1994, COMPUT MUSIC J, V18, P30; FITZGERALD RA, 2004, P 2 MUS COMP 2004; Freitas A., 2002, DATA MINING KNOWLEDG; Grey J. M., 1975, THESIS STANFORD U; Howard D.M., 1997, ORG SOUND, V2, P65, DOI 10.1017/S1355771897009011; JOHNSON CG, 1999, P AISB WORKSH ART IN; KOSTEK B, 1999, SOFT COMPUTING ACOUS; MCADAMS S, 1995, PSYCHOL RES-PSYCH FO, V58, P177, DOI 10.1007/BF00419633; McDermott J, 2005, LECT NOTES COMPUT SC, V3449, P517; MIRANDA ER, 1995, COMPUT MUSIC J, V19, P59, DOI 10.2307/3680600; MITCHELL M, 1996, SERIES COMPLEX ADAPT; Mitchell T, 1997, MACHINE LEARNING; RIIONHEIMO J, 2003, EURASIP J APPL SIG P, V8, P791; SEAGO A, 2004, P 18 BRIT HCI GROUP; SLOMAN A, 1995, 5 SCAND C AI; WESSEL DL, 1979, COMPUTER MUSIC J, V3; WISHART T, 1994, AUDIBLE DESIGN; Wishart Trevor, 1996, SONIC ART; Yuen J, 1997, J AUDIO ENG SOC, V45, P316	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33237-5	LECT NOTES COMPUT SC			2006	3907						664	675				12	Computer Science, Theory & Methods	Computer Science	BEG67	WOS:000237228900063	
S	Barrett, SJ; Langdon, WB		Tiwari, A; Knowles, J; Avineri, E; Dahal, K; Roy, R		Barrett, S. J.; Langdon, W. B.			Advances in the application of machine learning techniques in drug discovery, design and development	Applications of Soft Computing: Recent Trends	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	10th Online World Conference on Soft Computing in Industrial Applications (WSC10)	SEP 19-OCT 07, 2005	ELECTR NETWORK	World Federat Soft Comp, Springer, BT, Elsevier, European Neural Network Soc, N Amer Fuzzy Log & Technol, Int Fuzzy Syst Assoc			SUPPORT VECTOR MACHINES; SINGLE NUCLEOTIDE POLYMORPHISMS; PARTICLE SWARM OPTIMIZATION; GENE-EXPRESSION DATA; MICROARRAY DATA; CANCER CLASSIFICATION; FEATURE-SELECTION; NEURAL-NETWORK; PHARMACEUTICAL-INDUSTRY; BREAST-CANCER	Machine learning tools, in particular support vector machines (SVM), Particle Swarm Optimisation (PSO) and Genetic Programming (GP), are increasingly used in pharmaceuticals research and development. They are inherently suitable for use with 'noisy', high dimensional (many variables) data, as is commonly used in cheminformatic (i.e. In silico screening), bioinformatic (i.e. bio-marker studies, using DNA chip data) and other types of drug research studies. These aspects are demonstrated via review of their current usage and future prospects in context with drug discovery activities.	GlaxoSmithKline Inc, Anal Applicat Res & Technol, R&D, Greenford UB6 0HE, Middx, England	Barrett, SJ (reprint author), GlaxoSmithKline Inc, Anal Applicat Res & Technol, R&D, Greenford Rd, Greenford UB6 0HE, Middx, England.						Agrafiotis DK, 2002, J MED CHEM, V45, P1098, DOI 10.1021/jm0104668; AMBOISE, 2002, PNAS, V99, P6562; ANDO, 2004, GP EM, V5, P145; Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; Bains W, 2004, PROG BIOPHYS MOL BIO, V86, P205, DOI 10.1016/j.pbiomolbio.2003.09.001; BANZHAF, 1998, GENETIC PROGRAMMING; Bao L, 2002, FEBS LETT, V521, P109, DOI 10.1016/S0014-5793(02)02835-1; BARRETT SJ, 2005, COLL INN CTR ADV INS; BHASIN, 2004, NUCL ACIDS RES, V32, pW383; Bhasin M, 2004, J BIOL CHEM, V279, P23262, DOI 10.1074/jbc.M401932200; BIESHEUVEL, 2005, THESIS U UTRECHT; Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; BOSER, 1992, 5 ANN ACM WORKSH COL; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BRENEMAN, 2002, ADME TOX S ORL ACS M; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BURBIDGE, 2001, 6 INT WORK C ART N 1, V2084; BURBIDGE, 2001, COMPUTERS IND, V26, P4; Butte A, 2002, NAT REV DRUG DISCOV, V1, P951, DOI 10.1038/nrd.961; Byvatov E, 2005, CHEMBIOCHEM, V6, P997, DOI 10.1002/cbic.200400400; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; Cedeno W, 2003, J COMPUT AID MOL DES, V17, P255, DOI 10.1023/A:1025338411016; CHEN, 2004, WORLD SCI; Chen HF, 2004, QSAR COMB SCI, V23, P603, DOI 10.1002/qsar.200430884; CONGDOM, 2003, CEC, P320; CRISTIANINI, 2000, INTRO SUPPORT VECTOR; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; Dobson PD, 2005, J MOL BIOL, V345, P187, DOI 10.1016/j.jmb.2004.10.024; Doniger S, 2002, J COMPUT BIOL, V9, P849, DOI 10.1089/10665270260518317; Dubey A, 2005, J THEOR BIOL, V234, P351, DOI 10.1016/j.jtbi.2004.11.037; EBERHART, 2001, SWARM INTELLIGENCE; EBERHART, 1999, CEC, P1927; FRADKIN, 2005, SVM ANAL CROSS SECTI; FUJAREWICZ, 2003, INT J APPL MATH COMP, V13, P327; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; Guo T, 2005, PROTEIN ENG DES SEL, V18, P65, DOI 10.1093/protein/gzi006; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hand D. J., 1999, SIGKDD EXPLORATIONS, V1, P16; HARDLE, 2004, SURVIVAL ANAL SUPPOR; Heddad A, 2004, LECT NOTES COMPUT SC, V3005, P31; Hong JH, 2004, LECT NOTES COMPUT SC, V3003, P78; Hou TJ, 2004, CURR PHARM DESIGN, V10, P1011, DOI 10.2174/1381612043452721; HOWARD, 2003, BIOSYSTEMS, V72, P19; HOWLEY, 2005, IN PRESS ARTIFICIAL; Huang YL, 2005, CLIN IMAG, V29, P179, DOI 10.1016/j.clinimag.2004.08.002; Igel C, 2005, LECT NOTES COMPUT SC, V3410, P534; Jerebko AK, 2005, ACAD RADIOL, V12, P479, DOI 10.1016/j.acra.2004.04.024; Johnson HE, 2003, PHYTOCHEMISTRY, V62, P919, DOI 10.1016/S0031-9422(02)00722-7; JONES, 1999, ENCY COMPUTATIONAL C; Jong K, 2004, LECT NOTES COMPUT SC, V3005, P41; Jorissen RN, 2005, J CHEM INF MODEL, V45, P549, DOI 10.1021/ci049641u; KELL, 2002, BIOINFORMATICS WORLD, P16; Kim JH, 2004, BIOINFORMATICS, V20, P3179, DOI 10.1093/bioinformatics/bth382; Kless A, 2004, LECT NOTES ARTIF INT, V3303, P191; KOZA, 2001, PAC S BIOCOMP, P434; Koza, 1992, GENETIC PROGRAMMING; LANGDON, 2001, SOFT COMPUTING IND R, P597; LANGDON, 2002, LNCS, V2278, P60; LANGDON, 2004, EVOLUTIONARY COMPUTI, P211; LANGDON, 2003, LNCS, V2611, P87; LI, 2005, IN PRESS COMPUTERS B; LI, 2005, GENOMICS, V85, P16; Lin WQ, 2005, J CHEM INF MODEL, V45, P535, DOI 10.1021/ci049642m; Listgarten J, 2004, CLIN CANCER RES, V10, P2725, DOI 10.1158/1078-0432.CCR-1115-03; LIU, 2005, DRUG DISCOVERY TODAY, V2, P179; Liu HX, 2004, J COMPUT AID MOL DES, V18, P389, DOI 10.1007/s10822-004-2722-1; LU, 2004, J PHARM BIOMED ANAL, V35, P679; MALOSSINI, 2004, P 2 EUR WORKSH DAT M; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Miwakeichi F, 2001, COMPUT BIOL MED, V31, P41, DOI 10.1016/S0010-4825(00)00021-4; Moore JH, 2002, GENET EPIDEMIOL, V23, P57, DOI 10.1002/gepi.01117; Moore JH, 2004, LECT NOTES COMPUT SC, V3005, P63; MUCHNIK, 2004, INFLUENCES BREAST CA; NG, 2004, DRUGS DISCOVERY APPR; Nicolotti O, 2002, J MED CHEM, V45, P5069, DOI 10.1021/jm020919o; Norinder U, 2003, NEUROCOMPUTING, V55, P337, DOI 10.1016/S0925-2312(03)00374-6; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; Prados J, 2004, PROTEOMICS, V4, P2320, DOI 10.1002/pmic.200400857; Ratti E, 2001, PURE APPL CHEM, V73, P67, DOI 10.1351/pac200173010067; Reif DM, 2004, EXPERT REV PROTEOMIC, V1, P67, DOI 10.1586/14789450.1.1.67; Roses AD, 2002, NAT REV DRUG DISCOV, V1, P541, DOI 10.1038/nrd840; RUNARSSON, 2004, NEURAL INFORM PROCES, V3, P59; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; Schneider G, 2004, PROTEOMICS, V4, P1571, DOI 10.1002/pmic.200300786; Schneider G, 2005, NAT REV DRUG DISCOV, V4, P649, DOI 10.1038/nrd1799; SCHRATTENHOLZ, 2004, DRUG DISCOVERY TODAY, V1, P1; SEBAG, 2004, LNCS, P384; Seike M, 2004, PROTEOMICS, V4, P2776, DOI 10.1002/pmic.200300795; SHAWETAYLOR, 2000, INTRO SUPPORT VECTOR; Shen Q, 2004, J COMPUT CHEM, V25, P1726, DOI 10.1002/jcc.20094; SHYU, 2004, GP EM, V5, P121; Simek K, 2004, ENG APPL ARTIF INTEL, V17, P417, DOI 10.1016/j.engappai.2004.04.015; SMITS, 2005, GENETIC PROGRAMMING, V3; SOLMAJER, 2004, DRUG DISCOVERY TODAY, V1, P247; SUWA, 2004, GPCR G PROTEIN COUPL; TAKAHASHI, 2005, J COMPUT CHEM JPN, V4, P43; Takaoka Y, 2003, J CHEM INF COMP SCI, V43, P1269, DOI 10.1021/ci0340431; Teramoto R, 2005, FEBS LETT, V579, P2878, DOI 10.1016/j.febslet.2005.04.045; Thukral SK, 2005, TOXICOL PATHOL, V33, P343, DOI 10.1080/01926230590927230; Tobita M, 2005, BIOORG MED CHEM LETT, V15, P2886, DOI 10.1016/j.bmcl.2005.03.080; Tsai KY, 2005, BIOINFORMATICS, V21, P1180, DOI 10.1093/bioinformatics/bti099; Vapnik V. N, 1995, NATURE STAT LEARNING; Vinayagam A, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-116; Wachowiak MP, 2004, IEEE T EVOLUT COMPUT, V8, P289, DOI [10.1109/TEVC.2004.826068, 10.1109/tevc.2004.826068]; WANG, 2004, HICOMB; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Watkins SM, 2002, CURR OPIN MOL THER, V4, P224; XIAO, 2003, HICOMB; XU, 2002, MOLECULES, V7, P566; Xue CX, 2004, J CHEM INF COMP SCI, V44, P1693, DOI 10.1021/ci049820b; Xue Y, 2004, J CHEM INF COMP SCI, V44, P1497, DOI 10.1021/ci049971e; Yang ZR, 2004, BIOINFORMATICS, V20, P735, DOI 10.1093/bioinformatics/btg477; YAP, 2005, IN PRESS J CHEM INF; Yap CW, 2004, TOXICOL SCI, V79, P170, DOI 10.1093/toxsci/kfh082; Yoon Y, 2003, CLIN CHEM LAB MED, V41, P529, DOI 10.1515/CCLM.2003.080; Zhao CY, 2004, J CHEM INF COMP SCI, V44, P2040, DOI 10.1021/ci049877y	118	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871	3-540-29123-7	ADV SOFT COMP			2006							99	110				12	Computer Science, Artificial Intelligence	Computer Science	BEV85	WOS:000239657900010	
J	Drummond, C; Matwin, S; Gaffield, C				Drummond, C; Matwin, S; Gaffield, C			Inferring and revising theories with confidence: Analyzing bilingualism in the 1901 Canadian census	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							TREE INDUCTION	This paper shows how machine learning can help in analyzing and understanding historical change. Using data from the Canadian census of 1901, we discover the influences on bilingualism in Canada at the beginning of the lost century. The discovered theories parity agree with, and partly complement, the existing views of historians on this question. Our approach, based around a decision tree, not only infers theories directly from data, but also evaluates existing theories and revises them to improve their consistency with the data. One novel aspect of this work is the use of confidence intervals to determine which factors are both statistically and practically significant, and thus contribute appreciably to the overall accuracy of the theory. When inducing a decision tree directly from data, confidence interrvals determine when new tests should be added. If an existing theory is being evaluated, confidence intervals also determine when old tests should be replaced, or deleted, to improve the theory. Our aim is to minimize the changes made to an existing theory to accommodate the new data. To this end, we propose a semantic measure of similarity between trees and demonstrate how this can be used to limit the changes made.	Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A OR6, Canada; Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada; Polish Acad Sci, Inst Comp Sci, PL-00901 Warsaw, Poland; Univ Ottawa, Inst Canadian Studies, Ottawa, ON, Canada	Drummond, C (reprint author), Natl Res Council Canada, Inst Informat Technol, M-50,1200 Montreal Rd, Ottawa, ON K1A OR6, Canada.	chris.drummond@nrc-cnrc.gc.ca					Baskerville Peter, 1998, UNWILLING IDLERS URB; Breiman L, 1984, CLASSIFICATION REGRE; Darroch G., 1994, PROPERTY INEQUALITY; DRUMMOND C, 2002, P ECML PKDD 02 WORKS, P40; Drummond C., 2000, P 17 INT C MACH LEAR, P239; Efron B., 1993, INTRO BOOTSTRAP; FRANK E, 2000, THESIS U WAIKATO HAM; GAFFIELD C, 2000, HIST METHOD, V33, P255; HANLEY JA, 1982, RADIOLOGY, V143, P29; HARLOW LL, 1997, WHAT IF WERE NO SIGN; JENSEN D, 1991, P 1991 KNOWL DISC DA, P148; MADIGAN D, 1995, COMMUN STAT THEORY, V24, P2271, DOI 10.1080/03610929508831616; MARGINEANTU DD, 2000, P INT C MACH LEARN I, P582; MOONEY RJ, 1993, MACH LEARN, V10, P79, DOI 10.1007/BF00993482; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Oates T., 1997, P 14 INT C MACH LEAR, P254; Ornstein M, 2000, HIST METHOD, V33, P195; Perlich C., 2003, J MACHINE LEARNING R, V4, P211; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Utgoff PE, 1997, MACH LEARN, V29, P5, DOI 10.1023/A:1007413323501; ZADROZNY B, 2002, P 8 INT C KNOWL DISC; Zadrozny B., 2001, P 18 INT C MACH LEAR	25	2	2	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	JAN	2006	20	1					1	33		10.1080/08839510500313711		33	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	005OB	WOS:000234832600001	
B	Rocco, CM; Muselli, M		Ruan, D; DHondt, P; Fantoni, PF; DeCock, M; Nachtegael, M; Kerre, EE		Rocco, Claudio M.; Muselli, Marco			Assessing the reliability of complex networks: Empirical models based on machine learning	Applied Artificial Intelligence			English	Proceedings Paper	7th International Conference on Fuzzy Logic and Intelligent Technologies in Nuclear Science	AUG 29-31, 2006	Genoa, ITALY					In this paper three models derived using Machine Learning techniques (Support Vector Machines, Decision Trees and Shadow Clustering) are compared for approximating the reliability of real complex networks, such as for water supply, electric power or gas distribution systems or telephone systems, using different reliability criteria.	Cent Univ Venezuela, Fac Ingn, Caracas, Venezuela	Rocco, CM (reprint author), Cent Univ Venezuela, Fac Ingn, Caracas, Venezuela.						Billinton R., 1992, RELIABILITY EVALUATI; Billinton R., 1994, RELIABILITY ASSESSME; BREMAN L, 1994, CLASSFICATION REGRES; CHATURVEDI SK, 2002, INT J RELIAB QUALITY, V3, P237; Cristianini N., INTRO SUPPORT VECTOR; DAGAMA JMP, 1999, THESIS FACULDADE CIE; DUBI A, 2001, P ANN REL MAINT S; Manzi E, 2001, IEEE T RELIAB, V50, P41, DOI 10.1109/24.935016; MUSELLI M, 2005, P 16 IT WORKSH NEUR; MUSELLI M, 2005, P 17 EUR C CIRC THEO; PEREIRA MVF, 1991, IEEE POW SYST ENG SO; POHL EA, 2000, P ANN REL MAINT S; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; ROCCO CM, UNPUB IEEE T NEURAL; Veropulos K, 1999, P INT JOINT C ART IN, P55; YOO YB, 1988, IEEE T RELIAB, V37, P210, DOI 10.1109/24.3743	16	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		981-256-690-2				2006							267	274		10.1142/9789812774118_0040		8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEU34	WOS:000239525200040	
B	Schleif, FM; Villmann, T; Elssner, T; Decker, J; Kostrzewa, M		Ruan, D; DHondt, P; Fantoni, PF; DeCock, M; Nachtegael, M; Kerre, EE		Schleif, F. -M.; Villmann, T.; Elssner, T.; Decker, J.; Kostrzewa, M.			Machine learning and soft-computing in bioinformatics - A short journey	Applied Artificial Intelligence			English	Proceedings Paper	7th International Conference on Fuzzy Logic and Intelligent Technologies in Nuclear Science	AUG 29-31, 2006	Genoa, ITALY				GENE-EXPRESSION; NEURAL-GAS; SELECTION; CANCER; CLASSIFICATION; SIMILARITY; ALGORITHM; NETWORK	Bioinformatics is a promising and innovative research field which gains hope to develop new approaches for e.g. medical diagnostics. Appropriate methods for pre processing as well as high level analysis are needed. In this overview we highlight some aspects in the light of machine learning and neural networks. Thereby, we indicate crucial problems like the curse of dimensionality and give possibilities for overcoming. In an examplary application we shortly demonstrate a possible scenario in the field of mass spectrometry analysis in cancer detection. Despite of a high number of techniques dedicated to bioinformatic research as well as many successful applications, we are in the beginning of a process to massively integrate the aspects and experiences in the different core subjects such as biology, medicine, computer science, chemistry, physics, and mathematics.	Frank Michael Schleif Bruker Daltonik GmbH, D-04318 Leipzig, Germany	Schleif, FM (reprint author), Frank Michael Schleif Bruker Daltonik GmbH, Permoserstr 15, D-04318 Leipzig, Germany.						Adam BL, 2002, CANCER RES, V62, P3609; Amos M, 2005, THEORETICAL EXPT DNA; Benoudjit N, 2004, CHEMOMETR INTELL LAB, V74, P243, DOI 10.1016/j.chemolab.2004.04.015; Bezdek J. C., 1981, PATTERN RECOGNITION; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BRUSS C, 2006, P OF EUR S ART NEUR, P563; Cheng V, 2004, PATTERN RECOGN, V37, P1471, DOI 10.1016/j.patcog.2003.12.015; Dopazo J, 1997, J MOL EVOL, V44, P226, DOI 10.1007/PL00006139; Drummond A, 2001, BIOINFORMATICS, V17, P662, DOI 10.1093/bioinformatics/17.7.662; Duda R.O, 1973, PATTERN CLASSIFICATI; GRANITTO PM, 2006, P FLINS 2006; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hammer B, 2005, NEURAL PROCESS LETT, V21, P21, DOI 10.1007/s11063-004-3255-2; HAMMER B, 2005, P EUR S ART NEUR NET, P303; HAMMER B, 2005, BIOINFORMATIC USING, P25; HYVARINEN A, 2001, INDEPENEDENT COMPONE; JEFFREY S, 2006, BAYESIAN ANAL MASS S; Kaski S, 2001, ADVANCES IN SELF-ORGANISING MAPS, P124; Kaski S, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-48; Kohonen T., 1995, SELF ORG MAPS, V30; KRIER C, 2006, P FLINS 2006; Kussmann M, 2005, COMB CHEM HIGH T SCR, V8, P679, DOI 10.2174/138620705774962526; Li LH, 2004, ARTIF INTELL MED, V32, P71, DOI 10.1016/j.artmed.2004.03.006; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Lio P, 2003, BIOINFORMATICS, V19, P2, DOI 10.1093/bioinformatics/19.1.2; MAREKY MK, 2003, PROTEOMICS, V3, P1678; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ritter H., 1992, NEURAL COMPUTATION; SAMSONOVA EV, 2003, LECT NOTES COMPUTER, V2810; Sato A., 1996, P 1995 C CAMBR MA US, P423; SCHAFFELER E, 2004, 52 ASMS C 2004; SCHLEIF FM, 2006, IN PRESS P CBMS; Schreiber F, 2003, J VISUAL LANG COMPUT, V14, P327, DOI 10.1016/S1045-926X(03)00030-2; SEIFFERT U, 2006, P EUR S ART NEUR NET, P521; SEIFFERT U, 2004, BIOINFORMATICS USING; STRICKERT M, 2006, P FLINS 2006; STRICKERT M, 2006, P EUR S ART NEUR NET, P265; Strickert M, 2006, NEUROCOMPUTING, V69, P651, DOI 10.1016/j.neucom.2005.12.004; STUTTGART IKP, 2004, MHH HANNOVER BRUKER; TIMM W, 2006, P FLINS 2006; Vannucci M, 2005, CHEMOMETR INTELL LAB, V77, P139, DOI 10.1016/j.chemolab.2004.10.009; Vapnik Vladimir N., 1995, NATURE STAT LEARNING; Villmann T, 2003, NEURAL NETWORKS, V16, P389, DOI 10.1016/S0893-6080(03)00021-2; Villmann T, 1998, NEUROCOMPUTING, V21, P91, DOI 10.1016/S0925-2312(98)00037-X; VILLMANN T, 2005, P WORKSH SELF ORG MA, P283; VILLMANN T, 2004, AKTUELLE ENTWICKLUNG, P99; Villmann T, 2006, NEURAL COMPUT, V18, P446, DOI 10.1162/089976606775093918	48	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		981-256-690-2				2006							541	548		10.1142/9789812774118_0077		8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEU34	WOS:000239525200077	
B	Stout, M; Bacardit, J; Hirst, JD; Blazewicz, J; Krasnogor, N		Ruan, D; DHondt, P; Fantoni, PF; DeCock, M; Nachtegael, M; Kerre, EE		Stout, Michael; Bacardit, Jaume; Hirst, Jonathan D.; Blazewicz, Jacek; Krasnogor, Natalio			Prediction of residue exposure and contact number for simplified HP lattice model proteins using Learning Classifier Systems	Applied Artificial Intelligence			English	Proceedings Paper	7th International Conference on Fuzzy Logic and Intelligent Technologies in Nuclear Science	AUG 29-31, 2006	Genoa, ITALY				ALGORITHMS; EVOLUTION	The performance of a Learning Classifier System (LCS) applied to the classification of simplified hydrophobic/polar (HP) lattice model proteins was compared to other machine learning (ML) algorithms. The GAssist LCS classified functional HP model proteins on the 3D diamond lattice as folding or non-folding at 88.3% accuracy, outperforming significantly three out of the four other methods. GAssist correctly classified HP model protein instances on the basis of Contact Number (CN) and Residue Exposure (RE) on both 2D square and 3D cubic lattices at a level of between 27.8% and 80.9%. Again, the LCS performed at a level comparable to the other ML technologies in this task outperforming significantly them in 24 out of 180 cases, and being outperformed just six times. The benefits of using LCS for this problem domain are discussed and examples of the LCS generated rules are described.	Univ Nottingham, Sch Comp Sci & IT, Optimisat & Planning Res Grp, Nottingham NG8 1BB, England	Stout, M (reprint author), Univ Nottingham, Sch Comp Sci & IT, Optimisat & Planning Res Grp, Jubilee Campus,Wollaton Rd, Nottingham NG8 1BB, England.		Hirst, Jonathan/G-7681-2011				BACARDIT J, 2004, THESIS RAMON LLULL U; Blackburne BP, 2003, J CHEM PHYS, V119, P3453, DOI 10.1063/1.1590310; Blackburne BP, 2001, J CHEM PHYS, V115, P1935, DOI 10.1063/1.1383051; Blazewicz J, 2005, ARTIF INTELL MED, V35, P135, DOI 10.1016/j.artmed.2005.02.001; BLAZEWICZ J, COMPUTATIONAL METHOD; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DILL KA, 1995, PROTEIN SCI, V4, P561; Hart WE, 1996, J COMPUT BIOL, V3, P53, DOI 10.1089/cmb.1996.3.53; Hirst JD, 1999, PROTEIN ENG, V12, P721, DOI 10.1093/protein/12.9.721; Krasnogor N., 2002, LECT NOTES COMPUTER, P769; MILLER RG, 1981, SIMULTANEOUS STAT IN; STOUT M, 2006, IN PRESS 4 EUR WORKS; YUE K, 1995, P NATL ACAD SCI USA, V92, P325, DOI 10.1073/pnas.92.1.325	13	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		981-256-690-2				2006							601	608		10.1142/9789812774118_0085		8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEU34	WOS:000239525200085	
S	Tantug, AC; Eryigit, G		Abraham, A; DeBaets, B; Koppen, M; Nickolay, B		Tantug, A. C. neyd; Eryigit, G. lsen			Performance analysis of Naive Bayes classification, support vector machines and neural networks for spam categorization	APPLIED SOFT COMPUTING TECHNOLOGIES: THE CHALLENGE OF COMPLEXITY	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	9th Online Conference on Soft Computing in Industrial Applications	SEP 20-OCT 08, 2004	ELECTR NETWORK	World Federat Soft Comp, Elsevier, Springer, IEEE Syst, Man & Cybernet Soc, NAFIPS, European Soc Fuzzy Log & Technol, Int Fuzzy Syst Assoc		spam recognition; support vector machines; neural networks; Naive Bayes classification		Spam mail recognition is a new growing field which brings together the topic of natural language processing and machine learning as it is in essence a two class classification of natural language texts. An important feature of spam recognition is that it is a cost-sensitive classification: misclassification of a nonspam mail as spam is generally a more severe error than misclassifying a spam mail as non-spam. In order to be compared, the methods applied to this field should be all evaluated with the same corpus and within the same cost-sensitive framework. In this paper, the performances of Support Vector Machines (SVM), Neural Networks (NN) and Naive Bayes (NB) techniques are compared using a publicly available corpus (LINGSPAM) for different cost scenarios. The training time complexities of the methods are also evaluated. The results show that NN has significantly better performance than the two other, having acceptable training times. NB gives better results than SVM when the cost is extremely high while in all other cases SVM outperforms NB.	Istanbul Tech Univ, Dept Comp Engn, TR-34469 Istanbul, Turkey	Tantug, AC (reprint author), Istanbul Tech Univ, Dept Comp Engn, TR-34469 Istanbul, Turkey.	cuneyd@cs.itu.edu.tr; gulsen@cs.itu.edu.tr	ERYIGIT, GULSEN/C-7709-2009				Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; Carreras X., 2001, P 4 INT C REC ADV NA, P58; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; DUDA RO, 2001, PATTERN CLASSIFICATI, P10; EFE OM, 2000, ARTIFICIAL NEURAL NE; Kohonen T, 1980, CONTENT ADDRESSABLE; Osuna E., 1997, P IEEE NNSP 97 AM IS, V24; Platt J. C., 1998, ADV KERNEL METHODS S, P185; SAHAMI M, 1998, WS9805 AAAI, P55; Sakkis G, 2003, INFORM RETRIEVAL, V6, P49, DOI 10.1023/A:1022948414856; SCHNEIDER KM, 2003, P 10 C EUR CHAPT ASS, P207; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V. N, 1995, NATURE STAT LEARNING; ZURADDA JM, 1992, INTRO ARTIFICIAL NEU	15	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871	3-540-31649-3	ADV SOFT COMP			2006	34						495	504		10.1007/3-540-31662-0_38		10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEN47	WOS:000238287700038	
S	Zhang, JP; He, L; Zhou, ZH		Abraham, A; DeBaets, B; Koppen, M; Nickolay, B		Zhang, Junping; He, Li; Zhou, Zhi-Hua			Analyzing magnification factors and principal spread directions in manifold learning	APPLIED SOFT COMPUTING TECHNOLOGIES: THE CHALLENGE OF COMPLEXITY	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	9th Online Conference on Soft Computing in Industrial Applications	SEP 20-OCT 08, 2004	ELECTR NETWORK	World Federat Soft Comp, Elsevier, Springer, IEEE Syst, Man & Cybernet Soc, NAFIPS, European Soc Fuzzy Log & Technol, Int Fuzzy Syst Assoc		SVD-based magnification factors; SVD-based principal spread directions; manifold learning; locally linear embedding algorithm	NONLINEAR DIMENSIONALITY REDUCTION; CURVES	Great amount of data under varying intrinsic features is thought of as high dimensional nonlinear manifold in the observation space. How to analyze the mapping relationship between the high dimensional manifold and the corresponding intrinsic low dimensional one quantitatively is important to machine learning and cognitive science. In this paper, we propose SVD (singular value decomposition) based magnification factors and spread direction for quantitative analyzing the relationship. The result of conducting experiments on several databases show the advantages of this proposed SVD-based approach in manifold learning.	Fudan Univ, Shanghai Key Lab Intellignet Informat Proc, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China	Zhang, JP (reprint author), Fudan Univ, Shanghai Key Lab Intellignet Informat Proc, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China.	jpzhang@fudan.edu.cn; demonstrate@163.com; zhouzh@nju.edu.cn					Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bishop C. M., 1997, P IEE 5 INT C ART NE, P64; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; BRAND M, 2003, NEURAL INFORM PROCES, V15; Chang K, 2001, IEEE T PATTERN ANAL, V23, P22; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hinton G., 2003, NEURAL INFORM PROCES, V15, P833; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Lu HM, 1998, P SOC PHOTO-OPT INS, V3307, P52, DOI 10.1117/12.304659; NAYAR SK, 1995, CUCS0695; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; SILVA VS, 2002, NONLINEAR ESTIMATION; SMOLA AJ, 1999, LECT NOTES ARTIF INT, V1572, P251; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Zhang J., 2004, INTELLIGENT MULTIMED; ZHANG JP, 2004, 6 INT C AUT FAC GEST	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1615-3871	3-540-31649-3	ADV SOFT COMP			2006	34						651	664		10.1007/3-540-31662-0_49		14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEN47	WOS:000238287700049	
S	Polat, K; Kara, S; Latifoglu, F; Gunes, S		Bersini, H; Carneiro, J		Polat, Kemal; Kara, Sadik; Latifoglu, Fatma; Gunes, Salih			A novel approach to resource allocation mechanism in Artificial Immune Recognition System: Fuzzy resource allocation mechanism and application to diagnosis of atherosclerosis disease	ARTIFICIAL IMMUNE SYSTEMS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	5th International Conference on Artificial Immune Systems	SEP 04-06, 2006	Oeiras, PORTUGAL	Univ Libre Bruxelles, RIDIA Lab, Inst Gulbenkian Cienc		Artificial Immune Recognition System (AIRS); fuzzy resource allocation mechanism; atherosclerosis disease; carotid artery; Fast Fourier Transformation	CORONARY-ARTERY DISEASE; DOPPLER ULTRASOUND; DISTENSIBILITY	Artificial Immune Recognition System (AIRS) has showed an effective performance on several problems such as machine learning benchmark problems and medical classification problems like breast cancer, diabets, liver disorders classification. In this study, the resource allocation mechanism of AIRS was changed with a new one determined by Fuzzy-Logic. This system, named as Fuzzy-AIRS was used as a classifier in the diagnosis of atherosclerosis, which are of great importance in medicine. The proposed system consists of the following parts: first, we obtained features that are used as inputs for Fuzzy-AIRS from Carotid Artery Doppler Signals using Fast Fourier Transform (FFT), then these obtained inputs used as inputs in Fuzzy-AIRS. While AIRS algorithm obtained 75% maximum classification accuracy for 150 resources using 10-fold cross validation, Fuzzy-AIRS obtained 100% maximum classification accuracy in the same conditions. These results show that Fuzzy-AIRS proved that it could be used as an effective classifier for the medical problems.	Elcuk Univ, Dept Elect & Elect Engn, TR-42075 Konya, Turkey; Erciyes Univ, Dept Elect Engn, TR-38039 Kayseri, Turkey	Polat, K (reprint author), Elcuk Univ, Dept Elect & Elect Engn, TR-42075 Konya, Turkey.	kpolat@selcuk.edu.tr; kara@erciyes.edu.tr; fdirgenali@tse.org.tr; sgunes@selcuk.edu.tr					DART AM, 1991, LANCET, V338, P270, DOI 10.1016/0140-6736(91)90415-L; EVANS D, 2000, ULTRASOUND MED BIOL, V26, P13; Evans DH, 1989, DOPPLER ULTRASOUND P; Goodman DE, 2003, IEEE IJCNN, P1678; HIRAI T, 1989, CIRCULATION, V80, P78; KOHAVI R, 1998, APPL MACHINE LEARNIN, V30, P2; Muller M, 2001, J VASC SURG, V34, P1090, DOI 10.1067/mva.2001.118581; Saini V. D., 1993, BASIC PRINCIPLES ULT; Sigel B, 1998, ULTRASOUND MED BIOL, V24, P169, DOI 10.1016/S0301-5629(97)00264-0; STEFANADIS C, 1990, EUR HEART J, V11, P990; VAITKUS PJ, 1988, ULTRASOUND MED BIOL, V14, P673, DOI 10.1016/0301-5629(88)90024-5; VANASTEN WNJC, 1991, SURGERY, V109, P633; WATKINS A, 2002, P INT C ART IMM SYST, P99; Watkins AB, 2001, THESIS MISSISSIPPI S	14	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37749-2	LECT NOTES COMPUT SC			2006	4163						244	255				12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Immunology	Computer Science; Immunology	BFE52	WOS:000241472800019	
S	Kim, EM; Jeong, JC; Lee, BH		Rutkowski, L; Tadeusiewicz, R; Zadeh, LA; Zurada, J		Kim, Eun-Mi; Jeong, Jong Cheol; Lee, Bae-Ho			A new approach for finding an optimal solution and regularization by learning dynamic momentum	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING - ICAISC 2006, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	8th International Conference on Artificial Intelligence and Soft Computing (ICAISC 2006)	JUN 25-29, 2006	Zakopane, POLAND	Polish Neural Network Soc, Acad Humanities & Econ, Czestochowa Univ, Dept Comp Engn, IEEE Computat Intelligence Soc, Poland Chapter				Regularization and finding optimal solution for the classification problems are well known issue in the machine learning, but most of researches have been separately studied or considered as a same problem about these two issues. However, it is obvious that these approaches are not always possible because the evaluation of the performance in classification problems is mostly based on the data distribution and learning methods; therefore this paper suggests a new approach to simultaneously deal with finding optimal regularization parameter and solution in classification and regression problems by introducing dynamically rescheduled momentum with modified SVM in kernel space.	Univ Kansas, Dept Elect Engn & Comp Sci, Lawrence, KS 66045 USA		koreaeunmi@yahoo.com; korjcjeong@yahoo.com; bhlee@chonnam.ac.kr	Zurada, Jacek/B-8687-2013				Duda R. O., 2001, PATTERN CLASSIFICATI; Hansen P. C., 2001, REGULARIZATION TOOLS; Haykin S., 1999, NEURAL NETWORKS COMP; JEONG JC, 2002, THESIS YOSU NATL U R; Joachims T., 1998, P ECML 98 10 EUR C M; KIM EM, 2004, HYBRID INTELLIGENT S, P442; Mangasarian OL, 2001, ADV NEUR IN, V13, P577; PLATT JC, 1998, ADV KERNELS METHODS; TIKHONOV AN, 1963, DOKL AKAD NAUK SSSR+, V151, P501; Vapnik VN, 1998, STAT LEARNING THEORY; YOO JH, 2002, J FUZZY LOGIC INTELL, V11, P817	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35748-3	LECT NOTES COMPUT SC			2006	4029						29	36				8	Computer Science, Artificial Intelligence	Computer Science	BEV54	WOS:000239600000004	
S	Cappelletto, J; Estevez, P; Medina, W; Fermin, L; Bogado, JM; Grieco, JC; Fernandez-Lopez, G		Rutkowski, L; Tadeusiewicz, R; Zadeh, LA; Zurada, J		Cappelletto, Jose; Estevez, Pablo; Medina, Wilfredis; Fermin, Leonardo; Bogado, Juan M.; Grieco, Juan C.; Fernandez-Lopez, Gerardo			Gait synthesis and modulation for quadruped robot locomotion using a simple feed-forward network	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING - ICAISC 2006, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Artificial Intelligence and Soft Computing (ICAISC 2006)	JUN 25-29, 2006	Zakopane, POLAND	Polish Neural Network Soc, Acad Humanities & Econ, Czestochowa Univ, Dept Comp Engn, IEEE Computat Intelligence Soc, Poland Chapter				This paper describes a technique for statically stable gait synthesis for a quadruped robot using a simple Feed Forward Neural Networks (FFNN). A common approach for gait synthesis based on neural networks, is to use an implementation with Continuous Time Recurrent Neural Network (CTRNN) of arbitrary complex architecture as pattern generator for rhythmic limb motion. The preferred training method is implemented using genetic algorithms (GAs). However, to achieve the desired trajectory becomes an obstacle during the training process. This paper presents a much more simpler process converting a statically stable gait into actuator's space via inverse kinematics; the training of the network is done with those references. By doing so, the training problem becomes a spatio-temporal machine learning problem. It is described a solution for trajectory generation combining a simple oscillator model with a Multilayer Feedforward Neural Network (MFNN) to generate the desired trajectory.	Univ Simon Bolivar, Mechatron Grp, LabC 302, Miranda 1080A, Venezuela	Cappelletto, J (reprint author), Univ Simon Bolivar, Mechatron Grp, LabC 302, Miranda 1080A, Venezuela.		Medina-Melendez, Wilfredis/A-1288-2008; Zurada, Jacek/B-8687-2013				AMARI S, 1972, IEEE T SYST MAN CYB, VSMC2, P643, DOI 10.1109/TSMC.1972.4309193; BUCHLI J, 2004, P 1 INT WORKSH BIOAD; Fukuoka Y, 2003, INT J ROBOT RES, V22, P187, DOI 10.1177/0278364903022003004; HILLEL J, 1999, J COMPUTATIONAL NEUR, V7, P99; Kimura H., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013563; Kistler, 2002, SPIKING NEURON MODEL; LEWIS MA, 1994, GENETIC ALGORITHMS G, P317; MOLTER C, 2004, CHAOS SMALL RECURREN; NISHII J, 1994, P IFAC S, P501; Todd D. J., 1985, WALKING MACHINES INT; TSUNG FS, 1994, THESIS U CALIFORNIA; XU G, 2004, 2 INT C AUT ROB AG N	12	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35748-3	LECT NOTES COMPUT SC			2006	4029						731	739				9	Computer Science, Artificial Intelligence	Computer Science	BEV54	WOS:000239600000076	
S	Semitekos, D; Avouris, N		Maglogiannis, I; Karpouzis, K; Bramer, M		Semitekos, Dimitrios; Avouris, Nikolaos			Steady state contingency analysis of electrical networks using machine learning techniques	Artificial Intelligence Applications and Innovations	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	3rd IFIP Conference on Artificial Intelligence Applications and Innovation (AIAI 2006)	JUN 07-09, 2006	Athens, GREECE	IFIP, Univ Aegean, Dept Informat & Commun Syst Engn, Athens Informat Technol			SELECTION	Steady state contingency analysis aims at the assessment of the risk certain contingencies may pose to an electrical network. This is a particularly important task of network operators, especially as network stability issues become of prime importance in the current era of electricity deregulation. The article focuses on the analysis of experimental data that are produced through operating point simulation; contingency application, machine-teaming cross validation (based on pre-contingency network index selection algorithms) to point out the "nature" of given contingencies. Experimental statistical results of contingency prediction and selected network state indicators are translated to electric network data in an effort to further interpret the "nature" of each contingency and produce effective predicting algorithms that support operators.	Univ Patras, Dept Elect & Comp Engn, HCI Grp, Patras 26500, Greece	Semitekos, D (reprint author), Univ Patras, Dept Elect & Comp Engn, HCI Grp, Patras 26500, Greece.						ALBUYEH F, 1982, IEEE T POWER AP SYST, V101, P107, DOI 10.1109/TPAS.1982.317327; CHOLLEY P, 1998, BULK POWER SYSTEMS 4; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; EJEBE GC, 1979, IEEE T POWER AP SYST, V98, P97, DOI 10.1109/TPAS.1979.319518; HATZIARGYRIOU ND, 1994, IEEE T POWER SYST, V9, P1052, DOI 10.1109/59.317626; HSU YY, 1992, T POWER SYSTEMS, V7; Langley P., 1994, P 10 C UNC ART INT S; LAUBY MG, 1983, IEEE T POWER AP SYST, V102, P3899, DOI 10.1109/TPAS.1983.317928; Martin B., 1995, THESIS U WAIKATO HAM; MIKOLINNAS TA, 1981, IEEE T POWER AP SYST, V100, P608, DOI 10.1109/TPAS.1981.316917; Minsky M, 1969, PERCEPTRONS; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SEMITEKOS D, 2004, INT J ENG INTELLIGEN; Wehenkel L., 1998, AUTOMATIC LEARNING T; WITTEN IH, 2000, PRACTICAL MACHINE LE	15	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	0-387-34223-0	INT FED INFO PROC			2006	204						281	289				9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEL94	WOS:000238056900033	
S	Zafiropoulos, E; Maglogiannis, I; Anagnostopoulos, I		Maglogiannis, I; Karpouzis, K; Bramer, M		Zafiropoulos, Elias; Maglogiannis, Ilias; Anagnostopoulos, Ioannis			A support vector machine approach to breast cancer diagnosis and prognosis	Artificial Intelligence Applications and Innovations	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	3rd IFIP Conference on Artificial Intelligence Applications and Innovation (AIAI 2006)	JUN 07-09, 2006	Athens, GREECE	IFIP, Univ Aegean, Dept Informat & Commun Syst Engn, Athens Informat Technol			NUCLEAR FEATURES; NEURAL-NETWORKS	In recent years, computational diagnostic tools and artificial intelligence techniques provide automated procedures for objective judgments by making use of quantitative measures and machine learning. The paper presents a Support Vector Machine (SVM) approach for the prognosis and diagnosis of breast cancer implemented on the Wisconsin Diagnostic Breast Cancer (WDBC) and the Wisconsin Prognostic Breast Cancer (WPBC) datasets found in literature. The SVM algorithm performs excellently in both problems for the case study datasets, exhibiting high accuracy, sensitivity and specificity indices.	Univ Aegean, Dept Informat & Commun Syst Engn, GR-83200 Karlovassi, Samos, Greece	Zafiropoulos, E (reprint author), Univ Aegean, Dept Informat & Commun Syst Engn, GR-83200 Karlovassi, Samos, Greece.						Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y; Campbell C., KERNEL METHODS SURVE; Choong PL, 1996, IEEE T NEURAL NETWOR, V7, P568; CHRISTOPHER J.C.BURGES, TUTORIAL SUPPORT VEC; Hoya T, 2001, IEEE T NEURAL NETWOR, V12, P91, DOI 10.1109/72.896798; KABAN A, 2000, 15 INT C PATT REC SE, V2, P744; Maglogiannis Ilias G, 2004, BMC Med Inform Decis Mak, V4, P4, DOI 10.1186/1472-6947-4-4; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; SCHOLKOPF B, STAT LEARNING KERNEL; STREET WN, 1998, P 15 INT C MACH LEAR; Tourassi GD, 2001, MED PHYS, V28, P804, DOI 10.1118/1.1367861; WOLBERG WH, 1994, CANCER LETT, V77, P163, DOI 10.1016/0304-3835(94)90099-X; WOLBERG WH, 1995, HUM PATHOL, V26, P792, DOI 10.1016/0046-8177(95)90229-5; WOLBERG WH, 1995, ANAL QUANT CYTOL, V17, P77	14	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	0-387-34223-0	INT FED INFO PROC			2006	204						500	507				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEL94	WOS:000238056900058	
S	Bibi, S; Stamelos, I		Maglogiannis, I; Karpouzis, K; Bramer, M		Bibi, Stamatia; Stamelos, Ioannis			Selecting the appropriate machine learning techniques for the prediction of software development costs	Artificial Intelligence Applications and Innovations	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	3rd IFIP Conference on Artificial Intelligence Applications and Innovation (AIAI 2006)	JUN 07-09, 2006	Athens, GREECE	IFIP, Univ Aegean, Dept Informat & Commun Syst Engn, Athens Informat Technol			MODELS	This paper suggests several estimation guidelines for the choice of a suitable machine teaming technique for software development effort estimation. Initially, the paper presents a review of relevant published studies, pointing out pros and cons of specific machine teaming methods. The techniques considered are Association Rules, Classification and Regression Trees, Bayesian Belief Networks, Neural Networks and Clustering, and they are compared in terms of accuracy, comprehensibility, applicability, causality and sensitivity. Finally the study proposes guidelines for choosing the appropriate technique, based on the size of the training data and the desirable features of the extracted estimation model.	Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 65124, Greece	Bibi, S (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 65124, Greece.						BIBI S, 2003, P 1 BALK C INF THESS, P585; BIBI S, 2004, P 1 SOFTW MEAS EUR F, P237; BIBI S, 2004, P 11 EUR SOFTW PROC, pA13; Briand L. C., 1999, Proceedings of the 1999 International Conference on Software Engineering (IEEE Cat. No.99CB37002), DOI 10.1109/ICSE.1999.841022; Chulani S, 1999, IEEE T SOFTWARE ENG, V25, P573, DOI 10.1109/32.799958; Huang X. L., 2003, P 3 INT C QUAL SOFTW, P126; Jeffery R, 2001, P 7 INT SOFTW METR S, P16; Kitchenham B, 1998, IEEE T SOFTWARE ENG, V24, P278, DOI 10.1109/32.677185; Lee A, 1998, INFORM MANAGE, V34, P1, DOI 10.1016/S0378-7206(98)00041-X; MacDonell SG, 2003, J SYST SOFTWARE, V66, P91, DOI 10.1016/S0164-1212(02)00067-5; Mair C, 2000, J SYST SOFTWARE, V53, P23, DOI 10.1016/S0164-1212(00)00005-4; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Stamelos I, 2003, INFORM SOFTWARE TECH, V45, P51, DOI 10.1016/S0950-5849(02)00163-5; Tadayon N., 2005, P INT C INF TECHN LA, V2, P815; Xu ZW, 2004, FUZZY SET SYST, V145, P141, DOI 10.1016/j.fss.2003.10.008	15	1	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	0-387-34223-0	INT FED INFO PROC			2006	204						533	540				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEL94	WOS:000238056900062	
S	Yu, T; Debenham, J; Jan, T; Simoff, S		Bramer, M		Yu, Ting; Debenham, John; Jan, Tony; Simoff, Simeon			Combine Vector Quantization and Support Vector Machine for imbalanced datasets	Artificial Intelligence in Theory and Practice	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	Conference on Artificial Intelligence in Theory and Practice held at the 19th World Computer Congress	AUG 21-24, 2006	Santiago, CHILE	IFIP TC 12				In cases of extremely imbalanced dataset with high dimensions, standard machine learning techniques tend to be overwhelmed by the large classes. This paper rebalances skewed datasets by compressing the majority class. This approach combines Vector Quantization and Support Vector Machine and constructs a new approach, VQ-SVM, to rebalance datasets without significant information loss. Some issues, e.g. distortion and support vectors, have been discussed to address the trade-off between the information loss and undersampling. Experiments compare VQ-SVM and standard SVM on some imbalanced datasets with varied imbalance ratios, and results show that the performance of VQ-SVM is superior to SVM, especially in case of extremely imbalanced large datasets.	Univ Technol Sydney, Fac Informat Technol, Inst Informat & Commun Technol, Broadway, NSW 2007, Australia	Yu, T (reprint author), Univ Technol Sydney, Fac Informat Technol, Inst Informat & Commun Technol, POB 123, Broadway, NSW 2007, Australia.						Akbani R., 2004, P 15 EUR C MACH LEAR; Chang C. C., 2004, LIBSVM LIB SUPPORT V; CHAWLA NV, 2004, SIGKDD EXPLORATIONS, P6; Gersho A., 1992, VECTOR QUANTIZATION; JANG JSR, 2005, DCPR MATLAB TOOLBOX; KARAKOULAS G, 1998, OPTIMIZING CLASSIFIE; Kubat M, 1997, P 14 INT C MACH LEAR; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; LINDE Y, 1980, ALGORITHM VECTOR QUA, P702; Scholkopf B., 2002, LEARNING KERNELS SUP; Vapnik V. N, 1995, NATURE STAT LEARNING; VEROPOULOS K, 1999, INT JOINT C ART INT; Wang Jianxue, 2005, INT J BUSINESS INTEL, P1; Weston J., 2005, SPIDER OBJECT ORIENT; Wu G, 2005, IEEE T KNOWL DATA EN, V17, P786, DOI 10.1109/TKDE.2005.95; YU T, 2004, AISTA 2004 INT C ADV; YU T, 2005, 4 AUSTR C DAT MIN 20	17	1	2	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	0-387-34654-6	INT FED INFO PROC			2006	217						81	88				8	Computer Science, Artificial Intelligence	Computer Science	BEZ59	WOS:000240380300009	
S	Carrascal, A; Couchet, J; Ferreira, E; Manrique, D		Bramer, M		Carrascal, Alberto; Couchet, Jorge; Ferreira, Enrique; Manrique, Daniel			Anomaly Detection using prior knowledge: application to TCP/IP traffic	Artificial Intelligence in Theory and Practice	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	Conference on Artificial Intelligence in Theory and Practice held at the 19th World Computer Congress	AUG 21-24, 2006	Santiago, CHILE	IFIP TC 12				This article introduces an approach to anomaly intrusion detection based on a combination of supervised and unsupervised machine learning algorithms. The main objective of this work is an effective modeling of the TCP/IP network traffic of an organization that allows the detection of anomalies with an efficient percentage of false positives for a production environment. The architecture proposed uses a hierarchy of Self-Organizing Maps for traffic modeling combined with Learning Vector Quantization techniques to ultimately classify network packets. The architecture is developed using the known SNORT intrusion detection system to preprocess network traffic. In comparison to other techniques, results obtained in this work show that acceptable levels of compromise between attack detection and false positive rates can be achieved.				Carrascal, Alberto/E-5803-2010; Manrique, Daniel/F-9625-2013				CARTER E, 2001, CISCO SECURE INTRUSI; Eskin E, 2002, GEOMETRIC FRAMEWORK; KAYACIK HG, 2003, THESIS DALHOUSIE U; Kim D.S., 2005, 19 INT C ADV INF NET, V2, P155; Kohonen T, 2001, SELF ORG MAPS; KRUEGEL C, 2005, INTRUSION DETECTION; LICHODZIJEWSKI P, 2002, IEEE WORLD C COMP IN; Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019; Mitchell T, 1997, MACHINE LEARNING; Tanenbaum Andrew, 1989, COMPUTER NETWORKS; *CSI, 2004, 2004 CS FBI COMP CRI	11	3	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	0-387-34654-6	INT FED INFO PROC			2006	217						139	148				10	Computer Science, Artificial Intelligence	Computer Science	BEZ59	WOS:000240380300015	
S	Martinez, C; Lopez, AL		Bramer, M		Martinez, Carmen; Lopez, A. Lopez			Analysing definition questions by two machine learning approaches	Artificial Intelligence in Theory and Practice	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	Conference on Artificial Intelligence in Theory and Practice held at the 19th World Computer Congress	AUG 21-24, 2006	Santiago, CHILE	IFIP TC 12				In automatic question answering, the identification of the correct target term (i.e. the term to define) in a definition question is critical since if the target term is not correctly identified, then all subsequent modules have no chance of providing relevant nuggets. In this paper, we present a method to tag a question sentence experimenting with two learning approaches: QTag and Hidden Markov Model. We tested the methods in five collections of questions, PILOT, TREC 2003, TREC 2004, CLEF 2004 and CLEF 2005. We performed ten fold cross validation for each collection and we also tested with all questions together. The best accuracy rates for each collection were obtained using QTag, but with all questions together the best accuracy rate is obtained using HMM.	Inst Nacl Astrofis Opt & Elect, Puebla 72840, Mexico	Martinez, C (reprint author), Inst Nacl Astrofis Opt & Elect, Luis Enrique Erro 1 Santa Maria Tonanzintla, Puebla 72840, Mexico.						Daelemans W, 1996, P 4 WORKSH VER LARG, P14; HARABAGIU S., 2004, P WORKSH PRAGM QUEST, P1; Hildebrandt W., 2004, P HUM LANG TECHN C N, P49; MANNING CD, 1999, FDN STAT NATURAL LOG; MANSON O, 1997, QTAG A PORTABLE PROB; MODOLVAN D, 2002, P 40 ANN M ASS COMP, P33; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; TSUR O, 2003, DEFINITIONAL QUESTIO; Voorhees E., 2003, NIST SPECIAL PUBLICA, P1; XU JX, 2003, 12 TEXT RETR C TREC, P28	10	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	0-387-34654-6	INT FED INFO PROC			2006	217						277	284				8	Computer Science, Artificial Intelligence	Computer Science	BEZ59	WOS:000240380300029	
S	Li, DL; Zhu, W; Duan, YQ; Fu, ZT		Bramer, M		Li, Daoliang; Zhu, Wei; Duan, Yanqing; Fu, Zetian			Toward developing a tele-diagnosis system on fish disease	Artificial Intelligence in Theory and Practice	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	Conference on Artificial Intelligence in Theory and Practice held at the 19th World Computer Congress	AUG 21-24, 2006	Santiago, CHILE	IFIP TC 12		machine learning; Group Decision Support System; expert system; call centre	EXPERT-SYSTEM; WEB	Fish disease diagnosis is a complicated process and requires high level of expertise, an expert system for fish disease diagnosis is considered as an effective tool to help fish farmers. However, many farmers have no computers and are not able to access the Internet. Telephone and mobile uses increase rapidly, so, the provision of call centre service appears as a sound alternative support channel for farmer to acquire counseling and support. This paper presents a research attempt to develop and evaluate a call center oriented Hybrid disease diagnosis & consulting system (H-Vet) in aquaculture in China. This paper looks at why H-Vet is needed and what are the advantages and difficulties in the developing and using such a system. A machine learning approach is adopted, which helps to acquire knowledge when enhancing expert systems with the user information collected through call center. This paper also proposes a fuzzy Group Support Systems (GSS) framework for acquiring knowledge from individual expert and aggregating knowledge into workgroup knowledge by H-Vet in the situation of difficult disease diagnosis. The system's architecture and components are described.	China Agr Univ, Key Lab Modern Precis Agr Syst Integrat, Beijing 100083, Peoples R China	Li, DL (reprint author), China Agr Univ, Key Lab Modern Precis Agr Syst Integrat, POB 121, Beijing 100083, Peoples R China.		Duan, Yanqing/I-3163-2012				Aksin OZ, 2003, EUR J OPER RES, V147, P464, DOI 10.1016/S0377-2217(02)00274-6; Bendoly E, 2003, EUR J OPER RES, V148, P534, DOI 10.1016/S0377-2217(02)00442-3; Duan YQ, 2003, EXPERT SYST APPL, V25, P247, DOI 10.1016/S0957-4174(03)00050-2; Grove R, 2000, EXPERT SYST, V17, P129, DOI 10.1111/1468-0394.00135; GUO Z, 2000, ANAL PROSPECTS CHINA; Li D., 2002, EXPERT SYSTEMS APPL, V23, P311, DOI 10.1016/S0957-4174(02)00050-7; LIM SS, 2001, INT TEL S 14 MARCH B; Magrabi F, 1999, INT J MED INFORM, V54, P145, DOI 10.1016/S1386-5056(98)00177-4; Potter WD, 2000, COMPUT ELECTRON AGR, V27, P95, DOI 10.1016/S0168-1699(00)00100-9; POWER DJ, 2000, P AM C INF SYST AMCI; Rajani R., 1999, Virtual Reality, V4, DOI 10.1007/BF01421807; RIVA A, 1998, IEE COLL WEB BAS KNO; Sedbrook TA, 1998, DATA BASE ADV INF SY, V29, P19; STOHR EA, 1992, INFOR SYSTEMS DECISI; Tung LL, 1998, DECIS SUPPORT SYST, V23, P175, DOI 10.1016/S0167-9236(98)00040-2	15	5	5	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	0-387-34654-6	INT FED INFO PROC			2006	217						445	454				10	Computer Science, Artificial Intelligence	Computer Science	BEZ59	WOS:000240380300046	
S	Martinez-Otzeta, JM; Sierra, B; Lazkano, E; Jauregi, E		Euzenat, J; Domingue, J		Martinez-Otzeta, J. M.; Sierra, B.; Lazkano, E.; Jauregi, E.			On a unified framework for sampling with and without replacement in decision tree ensembles	ARTIFICIAL INTELLIGENCE: METHODOLOGY, SYSTEMS, AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	12th International Conference on Artificial Intelligence - Methodology, Systems, and Applications	SEP 12-15, 2006	Varna, BULGARIA	Bulgarian Artificial Intelligence Assoc, Inst Informat Technol		ensemble methods; decision trees	CLASSIFIER; COMBINATION	Classifier ensembles is an active area of research within the machine learning community. One of the most successful techniques is bagging, where an algorithm (typically a decision tree inducer) is applied over several different training sets, obtained applying sampling with replacement to the original database. In this paper we define a framework where sampling with and without replacement can be viewed as the extreme cases of a more general process, and analyze the performance of the extension of bagging to such framework.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Basque 20018, Spain	Martinez-Otzeta, JM (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, P Manuel Lardizabal 1, Basque 20018, Spain.	ccbmaotj@si.ehu.es					Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655; Dietterich TG, 1997, AI MAG, V18, P97; GAMA JM, 2000, THESIS U PORTO; Gunes V, 2003, INT J PATTERN RECOGN, V17, P1303, DOI 10.1142/S0218001403002897; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Kohavi R, 1996, P 2 INT C KNOWL DISC; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Lu Y, 1996, APPL INTELL, V6, P75, DOI 10.1007/BF00117809; Newman D. J., 1998, UCI REPOSITORY MACHI; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Sierra B, 2001, ARTIF INTELL MED, V22, P233, DOI 10.1016/S0933-3657(00)00111-1; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40930-0	LECT NOTES COMPUT SC			2006	4183						118	127				10	Computer Science, Artificial Intelligence	Computer Science	BFI88	WOS:000242122400012	
S	Ben Hariz, S; Elouedi, Z; Mellouli, K		Euzenat, J; Domingue, J		Ben Hariz, Sarra; Elouedi, Zied; Mellouli, Khaled			Clustering approach using belief function theory	ARTIFICIAL INTELLIGENCE: METHODOLOGY, SYSTEMS, AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	12th International Conference on Artificial Intelligence - Methodology, Systems, and Applications	SEP 12-15, 2006	Varna, BULGARIA	Bulgarian Artificial Intelligence Assoc, Inst Informat Technol		machine learning; clustering; K-modes method; uncertainty; belief function theory	CLASSIFICATION; MODEL; RULE	Clustering techniques are considered as efficient tools for partitioning data sets in order to get homogeneous clusters of objects. However, the reality is connected to uncertainty by nature, and these standard algorithms of clustering do not deal with this uncertainty pervaded in their parameters. In this paper we develop a clustering method in an uncertain context based on the K-modes method and the belief function theory. This so-called belief K-modes method (BKM) provides a new clustering technique handling uncertainty in the attribute values of objects in both the clusters' construction task and the classification one.	LARODEC, Inst Super Gest Tunis, Le Bardo 2000, Tunisia	Ben Hariz, S (reprint author), LARODEC, Inst Super Gest Tunis, 41 Ave Liberte, Le Bardo 2000, Tunisia.	sarra.benhariz@gmail.com; zied.eloued@gmx.fr; khaled.mellouli@ihec.rnu.tn					BAUER M, 1993, ARTTIF INTELL, V61, P315; Bosse E., 2001, INFORM FUSION, V2, P91; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Elouedi Z, 2001, INT J APPROX REASON, V28, P91, DOI 10.1016/S0888-613X(01)00045-7; Elouedi Z, 2004, IEEE T SYST MAN CY B, V34, P782, DOI 10.1109/TSMCB.2003.817056; Fixen D., 1997, IEEE T SYST MAN CYB, V27, P96; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain A.K., 1988, ALGORITHMS CLUSTERIN; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Quinlan JR, 1983, MACHINE LEARNING ART, P463; Rumelhart D., 1986, PARALLEL DISTRIBUTED; Shafer G., 1976, MATH THEORY EVIDENCE, V30; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smets P., 1998, HDB DEFEASIBLE REASO, V1, P267; TESSEM B, 1997, INT J APPROX REASON, V17, P217; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	17	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40930-0	LECT NOTES COMPUT SC			2006	4183						162	171				10	Computer Science, Artificial Intelligence	Computer Science	BFI88	WOS:000242122400016	
S	Pietquin, O		Euzenat, J; Domingue, J		Pietquin, Olivier			Machine learning for spoken dialogue management: An experiment with speech-based database querying	ARTIFICIAL INTELLIGENCE: METHODOLOGY, SYSTEMS, AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	12th International Conference on Artificial Intelligence - Methodology, Systems, and Applications	SEP 12-15, 2006	Varna, BULGARIA	Bulgarian Artificial Intelligence Assoc, Inst Informat Technol		spoken dialogue systems; reinforcement learning; dialogue management		Although speech and language processing techniques achieved a relative maturity during the last decade, designing a spoken dialogue system is still a tailoring task because of the great variability of factors to take into account. Rapid design and reusability across tasks of previous work is made very difficult. For these reasons, machine learning methods applied to dialogue strategy optimization has become a leading subject of researches since the mid 90's. In this paper, we describe an experiment of reinforcement learning applied to the optimization of speech-based database querying. We will especially emphasize on the sensibility of the method relatively to the dialogue modeling parameters in the framework of the Markov decision processes, namely the state space and the reinforcement signal. The evolution of the design will be exposed as well as results obtained on a simple real application.	Supelec, F-57070 Metz, France	Pietquin, O (reprint author), Supelec, Campus Metz Rue Edouard Belin 2, F-57070 Metz, France.	olivier.pietquin@supelec.fr					Levin E., 1997, P ASRU 97 SANT BARB; PIETQUIN O, 2005, P INT EUR 2005 LISB; Pietquin O, 2006, IEEE T AUDIO SPEECH, V14, P589, DOI 10.1109/TSA.2005.855836; SCHEFFLER K, 2001, P NAACL WORKSH AD DI; SINGH S, 1999, REINFORCEMENT LEARNI; Sutton R.S., 1998, REINFORCEMENT LEARNI; Walker M., 1997, P 35 ANN M ASS COMP, P271	7	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40930-0	LECT NOTES COMPUT SC			2006	4183						172	180				9	Computer Science, Artificial Intelligence	Computer Science	BFI88	WOS:000242122400017	
S	Ruiz, F; Angulo, C; Agell, N		Polit, M; Talbert, T; Lopez, B; Melendez, J		Ruiz, Francisco; Angulo, Cecilio; Agell, Nuria			Support Vector Machines for color adjustment in automotive basecoat	ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	9th International Conference of the Catalan-Association-for-Artificial-Intelligence	OCT 26-27, 2006	Perpignan, FRANCE	Catalan Assoc Artificial Intelligence		Artificial Intelligence; Decision Support Systems; Support Vector Machine; Color adjustment; Color formulation		Traditionally, Computer Colorant Formulation has been implemented using a theory of radiation transfer known as the Kubelka-Munk (K-M) theory. In recent studies, Artificial Neural Networks (ANNs) has been put forward for dealing with color formulation problems. This paper investigates the ability of Support Vector Machines (SVMs), a particular machine learning technique, to help color adjustment processing in the automotive industry. Imitating 'color matcher' employees, SVMs based on a standard Gaussian kernel are used in an iterative color matching procedure. Two experiments were carried Out to validate our proposal, the first considering objective color measurements as output in the training set, and a second where expert criterion was used to assign the output. The comparison of the two experiments reveals some insights about the complexity of the color adjustment analysis and suggests the viability of the method presented.	[Ruiz, Francisco; Agell, Nuria] Fundacio ESADE, Barcelona, Spain	Ruiz, F (reprint author), Fundacio ESADE, Avda Pedralbes 60-62, Barcelona, Spain.		Angulo, Cecilio/A-7953-2010	Angulo, Cecilio/0000-0001-9589-8199			Billmeyer F. W., 1981, PRINCIPLES COLOR TEC; BISHOP J, 1990, RES DEV EXPERT SYSTE, V7, P70; Boser B. E., 1992, COMPUTATIONAL LEARNI, P144; Cheetham W, 2005, AI MAG, V26, P51; Cheetham W, 1997, LECT NOTES ARTIF INT, V1266, P1; Cheetham W, 2001, LECT NOTES ARTIF INT, V2080, P589; Cristianini N., 2000, INTRO SUPPORT VECTOR; Kubelka P., 1931, Zeitschrift fur Technische Physik, V12; R DEVELOPMENT CORE TEAM, 2005, R LANG ENV STAT COMP; Seaborn M, 2005, PATTERN RECOGN, V38, P165, DOI 10.1016/j.patcog.2004.05.001	10	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	978-1-58603-663-8	FR ART INT			2006	146						19	27				9	Computer Science, Artificial Intelligence	Computer Science	BMS60	WOS:000273477100002	
S	Gibert, K; Perez-Bonilla, A; Rodriguez-Silva, G		Polit, M; Talbert, T; Lopez, B; Melendez, J		Gibert, Karina; Perez-Bonilla, Alejandra; Rodriguez-Silva, Gustavo			A Comparative Analysis of different classes-interpretation support techniques	ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	9th International Conference of the Catalan-Association-for-Artificial-Intelligence	OCT 26-27, 2006	Perpignan, FRANCE	Catalan Assoc Artificial Intelligence		Machine Learning; Clusters; Interpretation; Validation; Characterizing variable; Knowledge Base; Rule induction; Artificial Learning; Reasoning models; Information systems; data mining		In this work, the application of some traditional statistical or AI techniques (Logistic Regression, Decision Trees and Discriminant Analysis) used to assist interpretation of a set of classes is presented together with a new methodology Conceptual characterization by embedded conditioning (CCEC)[7] based on combination of statistics and some knowledge induction. All of them are applied to a set of real data coming from a WasteWater Treatment Plant (WWTP) previously, classified [8] to identify the characteristic situations that can be found in.	[Gibert, Karina; Perez-Bonilla, Alejandra; Rodriguez-Silva, Gustavo] Univ Politen Catalunya, Dept Stat & Operat Res, Barcelona 08034, Spain	Gibert, K (reprint author), Univ Politen Catalunya, Dept Stat & Operat Res, Campus Nord,Edif C5,C Jordi Girona 1-3, Barcelona 08034, Spain.	karina.gibert@upc.edu					ABRAMS, 2003, WASTEWATER ENG TREAT; Breiman L, 1984, CLASSIFICATION REGRE; FAYYAD UM, 1996, ADV KNOWLEDGEDISCOVE; FISHER, 1987, KNOWL ACQUISITION VI, P139; GIBERT K, 2006, 20062 DR EIOUPC; GIBERT K, 2005, VENTAJAS ESTRUCTURA, P67; GIBERT K, 2004, AICOMM, V18, P319; Gibert K, 1998, COMPUTACION SISTEMAS, V1, P213; GIBERT K, 2000, WORKSH BESA1 ECAI200, V6, P1; GORDON AD, 1999, CLUSTER DESCRIPTION; GORDON AD, 1994, COMPUT STAT DATA AN, V18, P561, DOI 10.1016/0167-9473(94)90085-X; HO TB, 1988, PATTERN RECOGN LETT, V7, P265, DOI 10.1016/0167-8655(88)90066-9; Kleinbaum DG, 1994, LOGISTIC REGRESSION; Lebart L., 1997, STAT EXPLORATOIRE MU; LEVI J, 2003, ANALISIS MULTIVARIAB; Michalski R. S., 1983, MACHINE LEARNING ART; Nakache J.-P., 2003, STAT EXPLICATIVE APP; RIQUELME, 2004, TENDENCIAS MINERIA D, P119; Therneau TM, 1997, 61 MAY CLIN; Tukey J., 1977, EXPLORATORY DATA ANA; VAZQUEZ F, 2001, P CAEPIA01, V6, P143	21	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	978-1-58603-663-8	FR ART INT			2006	146						37	46				10	Computer Science, Artificial Intelligence	Computer Science	BMS60	WOS:000273477100004	
S	Puertas, E; Armengol, E		Polit, M; Talbert, T; Lopez, B; Melendez, J		Puertas, Eloi; Armengol, Eva			Learning from cooperation using justifications	ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	9th International Conference of the Catalan-Association-for-Artificial-Intelligence	OCT 26-27, 2006	Perpignan, FRANCE	Catalan Assoc Artificial Intelligence		Machine Learning; Multi-agent System; Cooperation; Justifications	CBR	In multi-agent systems, individual problem solving capabilities can be improved thanks to the interaction with other agents. In the classification problem solving task each agent is able to solve the problems alone, but ill a collaborative scenario, an agent call take advantage of the knowledge of others. In our approach, when an agent decides to collaborate with other agents, in addition to the solution for the current problem, it acquires new domain knowledge. This domain knowledge consists on explanations (or justifications) that other agents done for the Solution they proposed. In that way, the first agent call store these justifications and use them like some kind of domain rules for solving new problems. As a consequence, the agent acquires experience and it is capable to solve on its own problems that initially were outside of his experience.	[Puertas, Eloi] IIIA CSIC, Artificial Intelligence Res Inst, Bellaterra 08193, Catalonia, Spain	Puertas, E (reprint author), IIIA CSIC, Artificial Intelligence Res Inst, Campus UAB, Bellaterra 08193, Catalonia, Spain.	eva@iiia.csic.cs					ARMENGOL E, 2001, LECT NOTES ARTIF INT, V2167, P13; Armengol E, 2003, LECT NOTES ARTIF INT, V2734, P121; Berthold M., 1999, INTELLIGENT DATA ANA; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; KALBFLEISH J, 1979, PROBABILITY STAT INF, V2; Muggleton S., 1991, New Generation Computing, V8; Newman D. J., 1998, UCI REPOSITORY MACHI; Perrone M.P., 1993, NEURAL NETWORKS SPEE, P126; Plaza E, 2001, LECT NOTES ARTIF INT, V2080, P437; PLAZA E, 2003, ICML; Prodromidis A., 2000, BOOK ADV DISTRIBUTED; PROVOST FJ, 1996, AAAI IAAI, V1, P74; Sen S, 1999, MULTIAGENT SYSTEMS, P259; SIAN SS, 1991, MACHINE LEARNING EWS, V482, P440, DOI 10.1007/BFb0017036	15	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	978-1-58603-663-8	FR ART INT			2006	146						47	54				8	Computer Science, Artificial Intelligence	Computer Science	BMS60	WOS:000273477100005	
S	Prudencio, R; Ludermir, T		Kollias, S; Stafylopatis, A; Duch, W; Oja, E		Prudencio, Ricardo; Ludermir, Teresa			A machine learning approach to define weights for linear combination of forecasts	ARTIFICIAL NEURAL NETWORKS - ICANN 2006, PT 1	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	16th International Conference on Artificial Neural Networks (ICANN 2006)	SEP 10-14, 2006	Athens, GREECE	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc			TIME-SERIES MODELS	The linear combination of forecasts is a procedure that has improved the forecasting accuracy for different time series. In this procedure, each method being combined is associated to a numerical weight that indicates the contribution of the method in the combined forecast. We present the use of machine learning techniques to define the weights for the linear combination of forecasts. In this paper, a machine learning technique uses features of the series at hand to define the adequate weights for a pre-defined number of forecasting methods. In order to evaluate this solution, we implemented a prototype that uses a MLP network to combine two widespread methods. The experiments performed revealed significantly accurate forecasts.	Univ Fed Pernambuco, Dept Informat Sci, BR-50670901 Recife, PE, Brazil; Univ Fed Pernambuco, Ctr Informat, BR-50732970 Recife, PE, Brazil	Prudencio, R (reprint author), Univ Fed Pernambuco, Dept Informat Sci, Av Reitores S-N, BR-50670901 Recife, PE, Brazil.		Ludermir, Teresa/F-6766-2012	Ludermir, Teresa/0000-0002-8980-6742			Adya M, 2001, INT J FORECASTING, V17, P143, DOI 10.1016/S0169-2070(01)00079-6; ARINZE B, 1994, OMEGA-INT J MANAGE S, V22, P647, DOI 10.1016/0305-0483(94)90054-X; ARMSTRONG J, 2005, FINDINGS EVIDENCE BA; ASKU C, 1992, J FORECASTING, V8, P27; CHU CH, 1994, DECIS SUPPORT SYST, V12, P13, DOI 10.1016/0167-9236(94)90071-X; de Menezes LM, 2000, EUR J OPER RES, V120, P190, DOI 10.1016/S0377-2217(98)00380-4; DEMUTH H, 2003, NEURAL NETOWRKS TOOL; FLORES BE, 1986, INT J FORECASTING, V2, P477, DOI 10.1016/0169-2070(86)90093-2; Giraud-Carrier C, 2004, MACH LEARN, V54, P187, DOI 10.1023/B:MACH.0000015878.60765.42; GRANGER CWJ, 1984, J FORECASTING, V3, P197, DOI 10.1002/for.3980030207; Harvey AC, 1993, TIME SERIES MODELS; HIBON M, 2004, INT J FORECASTING, V21, P15; Makridakis S, 2000, INT J FORECASTING, V16, P451, DOI 10.1016/S0169-2070(00)00057-1; PRECHETL L, 1994, 2194 FAK INF; Prudencio R, 2004, LECT NOTES ARTIF INT, V3339, P1122; Prudenico RBC, 2004, NEUROCOMPUTING, V61, P121, DOI 10.1016/j.neucom.2004.03.008; Prudencio RBC, 2004, PATTERN RECOGN LETT, V25, P911, DOI 10.1016/j.patrec.2004.02.004; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; VENKATACHALAN AR, 1999, J FORECASTING, V18, P1674; *MATHW INC, 2003, MATHW OPT TOOLB US G	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-38625-4	LECT NOTES COMPUT SC			2006	4131						274	283				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE51	WOS:000241472100029	
S	Chatzis, S; Doulamis, A; Kosmopoulos, D; Varvarigou, T		Kollias, S; Stafylopatis, A; Duch, W; Oja, E		Chatzis, Sotirios; Doulamis, Anastasios; Kosmopoulos, Dimitrios; Varvarigou, Theodora			Video representation and retrieval using spatio-temporal descriptors and region relations	ARTIFICIAL NEURAL NETWORKS - ICANN 2006, PT 2	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	16th International Conference on Artificial Neural Networks (ICANN 2006)	SEP 10-14, 2006	Athens, GREECE	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc		spatio-temporal; graph matching; region; machine learning; ARVQ		This paper describes a novel methodology for video summarization and representation. The video shots are processed in space-time as 3D volumes of pixels. Pixel regions with consistent color and motion properties are extracted from these 3D volumes by a space-time segmentation technique based on a novel machine learning algorithm. Each region is then described by a high-dimensional point whose components represent the average position, motion velocity and color of the region. Subsequently, the spatio-temporal relations of the regions are deduced and a concise, graph-based description of them is generated. This graph-based description of the video shot's content, along with the region centroids, comprises a concise yet powerful description of the video-shot and is used for retrieval applications. The retrieval problem is formulated as an inexact graph matching problem between the data video shots and the query input which is also a video segment. Experimental results on action recognition and video retrieval are illustrated and discussed.	Natl Tech Univ Athens, Dept Elect & Comp Engn, Athens, Greece; Demokritos Natl Ctr Sci Res, Inst Informat & Telecommun, GR-15310 Athens, Greece	Chatzis, S (reprint author), Natl Tech Univ Athens, Dept Elect & Comp Engn, Athens, Greece.	Stchat@telecom.ntua.gr; Adoulam@telecom.ntua.gr; dkosmo@iit.demokritos.gr; Dora@telecom.ntua.gr					ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; DEMENTHON D, 2003, P 11 ACM INT C MULT; Doulamis A, 2003, IEEE T NEURAL NETWOR, V14, P616, DOI 10.1109/TNN.2003.810605; Gepshtein S, 2000, P NATL ACAD SCI USA, V97, P8186, DOI 10.1073/pnas.97.14.8186; HAMPAPUR A, 1998, MULTIMEDIA DATA MANA; Sato A.S., 1995, ADV NEURAL INFORMATI, P423; Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-38871-0	LECT NOTES COMPUT SC			2006	4132						94	103				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE53	WOS:000241475200010	
S	Kouzas, G; Anagnostopoulos, I; Maglogiannis, I; Anagnostopoulos, C		Kollias, S; Stafylopatis, A; Duch, W; Oja, E		Kouzas, Georgios; Anagnostopoulos, Ioannis; Maglogiannis, Ilias; Anagnostopoulos, Christos			Bridging the syntactic and the semantic web search	ARTIFICIAL NEURAL NETWORKS - ICANN 2006, PT 2	Lecture Notes in Computer Science		English	Article; Proceedings Paper	16th International Conference on Artificial Neural Networks (ICANN 2006)	SEP 10-14, 2006	Athens, GREECE	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc			OPTIMIZATION	This paper proposes an information system, which aims to bridge the semantic gap in web search. The system uses multiple domain ontological structures expanding the user's query with semantically related concepts, enhancing in parallel the quality of retrieval to a large extend. Query analyzers broaden the user's information needs from classical term-based to conceptually representations, using knowledge from relevant ontologies and theirs' properties. Besides the use of semantics, the system employs machine learning techniques from the field of swarm intelligence through the Ant Colony algorithm, where ants are considered as web agents capable of collecting and processing relevant information. Furthermore, the effectiveness of the approach is verified experimentally, by observing that the retrieval precision for the enhanced queries is in higher levels, in comparison with the results derived from the classical term-based retrieval procedure.	Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece; Univ Aegean, Dept Informat & Commun Syst Engn, Karlovassi 83200, Samos, Greece; Univ Aegean, Dept Cultural Technol & Commun, Mytiline 81100, Lesvos, Greece	Kouzas, G (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Heroon Polytech 9, GR-15773 Athens, Greece.	gkouzas@ece.ntua.gr; janag@aegean.gr; imaglo@aegean.gr; canag@ct.aegean.gr					Anagnostopoulos I., 2004, IEE Proceedings-Software, V151, DOI 10.1049/ip-sen:20040121; ANAGNOSTOPOULOS I, 2002, 24 INT C INF TECHN I, P79; Anagnostopoulos I, 2004, NEURAL COMPUT APPL, V13, P229, DOI 10.1007/s00521-004-0409-0; BIANCHI L, 2002, P PPSN 7 7 INT 17 NA; Bonabeau E., 1999, INTELLIGENCE NATURAL; BRICKLEY D, RDF SCHEMA; Brin Sergey, 1998, WWW7 P 7 INT C WORLD; CHEN S, 1996, CMURITR9627; CRASWELL N, 1999, 10 AUSTR DAT C AUCKL; Ding L., 2004, P 13 ACM C INF KNOWL; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; Dorigo M, 1999, NEW IDEAS OPTIMIZATI, P11; Dorigo M, 1999, ARTIF LIFE, V5, P137, DOI 10.1162/106454699568728; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; YUWONO B, DASFAA 97, P41	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-38871-0	LECT NOTES COMPUT SC			2006	4132						104	112				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE53	WOS:000241475200011	
S	Pateritsas, C; Stafylopatis, A		Kollias, S; Stafylopatis, A; Duch, W; Oja, E		Pateritsas, Christos; Stafylopatis, Andreas			A nearest features classifier using a self-organizing map for memory base evaluation	ARTIFICIAL NEURAL NETWORKS - ICANN 2006, PT 2	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	16th International Conference on Artificial Neural Networks (ICANN 2006)	SEP 10-14, 2006	Athens, GREECE	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc			LEARNING ALGORITHMS	Memory base learning is one of main fields in the area of machine learning. We propose a new methodology for addressing the classification task that relies on the main idea of the k - nearest neighbors algorithm, which is the most important representative of this field. In the proposed approach, given an unclassified pattern, a set of neighboring patterns is found, but not necessarily using all input feature dimensions. Also, following the concept of the naive Bayesian classifier, we adopt the hypothesis of the independence of input features in the outcome of the classification task. The two concepts are merged in an attempt to take advantage of their good performance features. In order to further improve the performance of our approach, we propose a novel weighting scheme of the memory base. Using the self-organizing maps model during the execution of the algorithm, dynamic weights of the memory base patterns are produced. Experimental results have shown superior performance of the proposed method in comparison with the aforementioned algorithms and their variations.	Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece	Pateritsas, C (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Iroon Polytexneiou 9, Athens 15780, Greece.	pater@softlab.ntua.gr; andreas@cs.ntua.gr; andreas@cs.ntua.gr					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C. L., 1998, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1023/A:1022664626993; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DEMIROZ G, 1997, P 9 EUR C MACH LEARN; FAN H, 2003, P 14 AUSTR DAT C AD; GUVENIR HA, 1997, P 12 INT S COMP INF; HAMMERTON J, 2001, C COMP NAT LANG LEAR, P9; Kohonen T., 1997, SELF ORG MAPS; KONONENKO I, 1992, INFORMATICA, V16, P1; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PATERITSAS C, 2005, INT C COMP INT MOD C, V2, P781, DOI 10.1109/CIMCA.2005.1631563; PATERITSAS C, 2004, P IEEE INT C SYST MA, P4832; RAUBER A, 1999, P INT JOINT C NEUR N; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vesanto J., 2000, THESIS HELSINKI U TE; WETTSCHERECK D, 1995, 1 INT C CAS BAS REAS, P347; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; XIN T, 2004, P 2004 INT C MACH LE, V4, P2406, DOI 10.1109/ICMLC.2004.1382206; Yang Y., 2001, P 12 EUR C MACH LEAR, P564	23	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-38871-0	LECT NOTES COMPUT SC			2006	4132						391	400				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE53	WOS:000241475200040	
S	Howley, T; Madden, MG		Kollias, S; Stafylopatis, A; Duch, W; Oja, E		Howley, Tom; Madden, Michael G.			An evolutionary approach to automatic kernel construction	ARTIFICIAL NEURAL NETWORKS - ICANN 2006, PT 2	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	16th International Conference on Artificial Neural Networks (ICANN 2006)	SEP 10-14, 2006	Athens, GREECE	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc				Kernel-based learning presents a unified approach to machine learning problems such as classification and regression. The selection of a kernel and associated parameters is a critical step in the application of any kernel-based method to a problem. This paper presents a data-driven evolutionary approach for constructing kernels, named KTree. An application of KTree to the Support Vector Machine (SVM) classifier is described. Experiments on a synthetic dataset are used to determine the best evolutionary strategy, e.g. what fitness function to use for kernel evaluation. The performance of an SVM based on KTree is compared with that of standard kernel SVMs on a synthetic dataset and on a number of real-world datasets. KTree is shown to outperform or match the best performance of all the standard kernels tested.	Natl Univ Ireland Univ Coll Galway, Galway, Ireland	Howley, T (reprint author), Natl Univ Ireland Univ Coll Galway, Galway, Ireland.	thowley@vega.it.nuigalway.ie; michael.madden@nuigalway.ie	Madden, Michael/C-7113-2011				Bahlmann C., 2002, P 8 INT WORKSH FRONT; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cristianini N, 2004, KERNEL METHODS PATTE; Friedrichs F, 2004, P 12 EUR S ART NEUR, P519; FROLICH H, 2003, P INT IEEE C TOOLS A, V1, P142; HOWLEY T, 2005, ARTIFICIAL INTELLIGE, V24; LESSMANN S, 2005, P GERM OP RES GOR; Lin H.-T., 2003, STUDY SIGMOID KERNEL; Lodhi H., 2002, J MACHINE LEARNING R, V2; LUKE S, 1997, GENETIC PROGRAMMING; MANGASARIAN O, 2001, J MACHINE LEARNING R, V1; Newman D. J., 1998, UCI REPOSITORY MACHI; RUNARSSON T, 2004, NERUAL INFORM PROCES, V3; SCHOLKOPF B, 2000, MSRTR200023 MICR COR; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968	15	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-38871-0	LECT NOTES COMPUT SC			2006	4132						417	426				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE53	WOS:000241475200043	
S	Martin-Merino, M; Roman, J		Kollias, S; Stafylopatis, A; Duch, W; Oja, E		Martin-Merino, Manuel; Roman, Jesus			Electricity load forecasting using self organizing maps	ARTIFICIAL NEURAL NETWORKS - ICANN 2006, PT 2	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	16th International Conference on Artificial Neural Networks (ICANN 2006)	SEP 10-14, 2006	Athens, GREECE	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc			NEURAL-NETWORKS	Electricity load forecasting has become increasingly important for the industry. However, the accurate load prediction remains a challenging task due to several issues such as the nonlinear character of the time series or the seasonal patterns it exhibits. Several non-linear techniques such as the SVM have been applied to this problem. However, the properties of the load time series change strongly with the seasons, holidays and other factors. Therefore global models such as the SVM are not suitable to predict accurately the load demand. In this paper we propose a model that first splits the time series into homogeneous regions using the Self Organizing Maps (SOM). Next, an SVM is locally trained in each region. The algorithm proposed has been applied to the prediction of the maximum daily electricity demand. The experimental results show that our model outperforms several statistical and machine learning forecasting techniques.	Univ Salamanca, Salamanca 37002, Spain	Martin-Merino, M (reprint author), Univ Salamanca, C Compania 5, Salamanca 37002, Spain.	manuel@upsa.es; jaromanga.eui@upsa.es					CHANG MW, 2001, EUNITE NETWORK COMPE; Chatfield C., 1996, ANAL TIME SERIES INT; Cherkassky V, 1996, IEEE T NEURAL NETWOR, V7, P969, DOI 10.1109/72.508939; DABLEMONT S, 2003, WORKSH SELF ORG MAPS, P340; Hippert HS, 2001, IEEE T POWER SYST, V16, P44, DOI 10.1109/59.910780; Khotanzad A, 1997, IEEE T NEURAL NETWOR, V8, P835, DOI 10.1109/72.595881; Kohonen T., 1995, SELF ORG MAPS; Lamedica R, 1996, IEEE T POWER SYST, V11, P1749, DOI 10.1109/59.544638; Lendasse A, 2002, P AMER CONTR CONF, P3684, DOI 10.1109/ACC.2002.1024500; MARIN FJ, 2001, PEAK LOAD FORECASTIN; MULIER F, 1995, NEURAL COMPUT, V7, P1165, DOI 10.1162/neco.1995.7.6.1165; OJA E, 1999, KOHONEN MAPS, P303; Papadakis SE, 1998, IEEE T POWER SYST, V13, P480, DOI 10.1109/59.667372; ROJAS I, 2004, P EUR S ART NEUR NET, P93; SCHLKOPF B, 1999, ADV KERNEL METHODS S, P243; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vapnik VN, 1998, STAT LEARNING THEORY; Vesanto J., 1997, P WORKSH SELF ORG MA, P209; Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731; Wu ST, 2004, PATTERN RECOGN, V37, P175, DOI 10.1016/S0031-3203(03)00237-1	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-38871-0	LECT NOTES COMPUT SC			2006	4132						709	716				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE53	WOS:000241475200074	
S	Kim, BJ; Kim, IK		Kollias, S; Stafylopatis, A; Duch, W; Oja, E		Kim, Byung-Joo; Kim, Il Kon			Improved kernel based intrusion detection system	ARTIFICIAL NEURAL NETWORKS - ICANN 2006, PT 2	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	16th International Conference on Artificial Neural Networks (ICANN 2006)	SEP 10-14, 2006	Athens, GREECE	European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc			COMPONENT ANALYSIS	Computer security has become a critical issue with the rapid development of business and other transaction systems over the Internet. The application of artificial intelligence, machine learning and data mining techniques to intrusion detection systems has been increasing recently. But most research is focused on improving the classification performance of a classifier. Selecting important features from input data leads to simplification of the problem, and faster and more accurate detection rates. Thus selecting important features is an important issue in intrusion detection. Another issue in intrusion detection is that most of the intrusion detection systems are performed by off-line and it is not a suitable method for a real-time intrusion detection system. In this paper, we develop the real-time intrusion detection system, which combines an on-line feature extraction method with the on-line Least Squares Support Vector Machine classifier. Applying the proposed system to KDD CUP 99 data, experimental results show that it has a remarkable feature feature extraction, classification performance and reducing detection time compared to existing off-line intrusion detection system.	Youngsan Univ, Dept Network & Informat Engn, Yangsan 626847, Kyoungnam, South Korea; Kyungpook Natl Univ, Dept Comp Sci, Kyungpook, South Korea	Kim, BJ (reprint author), Youngsan Univ, Dept Network & Informat Engn, 150,Junamri, Yangsan 626847, Kyoungnam, South Korea.	bjkim@ysu.ac.kr; ikkim@knu.ac.kr					Cheng BL, 2003, J ELECTROCERAM, V10, P5, DOI 10.1023/A:1024007407033; Diamantaras K. I., 1996, PRINCIPAL COMPONENT; ESKIN E, 2000, P 17 INT C MACH LEAR, P443; GESTEL V, 0065 ESAT SISTA KU L; GHOSH A, 1999, P 8 USENIX SEC S, P443; GUPTA H, EXPERIMENTAL EVALUAT; Hall P., 1998, BRIT MACH VIS C SEPT, V1, P286; Kim BJ, 2003, LECT NOTES ARTIF INT, V2871, P440; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; LEE W, 1999, P 1999 C KNOWL DISC; MIKA S, 1998, THESIS TU BERLIN; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SOFTKY WR, 1991, NEURAL NETWORKS, V4, P337, DOI 10.1016/0893-6080(91)90070-L; Suykens J., 1999, P INT JOINT C NEUR N; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TSUDA K, 1999, P ESANN; Vapnik VN, 1998, STAT LEARNING THEORY; Winkeler J., 1999, CVPR, V2, P511	19	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-38871-0	LECT NOTES COMPUT SC			2006	4132						863	871				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFE53	WOS:000241475200090	
S	Gross, P; Kaiser, G			IEEE COMPUTER SOC	Gross, Philip; Kaiser, Gail			Automated information aggregation for scaling scale-resistant services	ASE 2006: 21st IEEE International Conference on Automated Software Engineering, Proceedings	IEEE International Conference on Automated Software Engineering		English	Proceedings Paper	21st IEEE International Conference on Automated Software Engineering	SEP   22, 2006	Tokyo, JAPAN	IEEE Comp Soc TCSE, ACM SIGSOFT, ACM SIGART, ACM Japan Chapter, Informat Proc Soc Japan, ASE Program Comm, Natl Inst Informat Japan, Univ Toronto, CSK Holdings Corp, Hatachi Ltd, NEC Corp, NTT Data Corp, Toshiba Corp, Toshiba Informat Syst Corp				Machine learning provides techniques to monitor system behavior and predict failures from sensor data. However, such algorithms are "scale resistant" - high computational complexity and not parallelizable. The problem then becomes identifying and delivering the relevant subset of the vast amount of sensor data to each monitoring node, despite the lack of explicit "relevance" labels. The simplest solution is to deliver only the "closest" data items under some distance metric. We demonstrate a better approach using a more sophisticated architecture: a scalable data aggregation and dissemination overlay network uses an influence metric reflecting the relative influence of one node's data on another, to efficiently deliver a mix of raw and aggregated data to the monitoring components, enabling the application of machine learning tools on real-world problems. We term our architecture Level of Detail after an analogous computer graphics technique.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Gross, P (reprint author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.						ALMANAC CI, 2005, PCS USE SURPASSED 82; BANERJEE S, 2002, C APPL TECHN ARCH PR; BANERJEE S, 2003, IEEE INF SAN FRANC; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CLARK JH, 1976, COMMUN ACM, V19, P547, DOI 10.1145/360349.360354; FIECHTER CN, 1994, EFFICIENT REINFORCEM; Freund Y., 1997, J COMPUTER SYSTEM SC, V55; Freund Y., 2003, J MACHINE LEARNING R, V4; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hoppe H., 1996, P 23 ANN C COMP GRAP; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kaelbling L. P., 1996, J ARTIFICIAL INTELLI, V4; LONG P, 2005, 18 ANN C LEARN THEOR; LUEBKE D, 1997, P 24 ANN C COMP GRAP; Massie M.L., 2004, PARALLEL COMPUTING, V30; RATNASAMY S, 2001, C APPL TECHN ARCH PR, P161; Renesse R. V, 2003, ACM T COMPUT SYST, V21, P164; ROWSTRON A, 2001, NGC2001 LOND; Schapire R.E., 2001, MSRI WORKSH NONL EST; SINGH K, 2006, CUCS00706 COL U; Stoica I., 2001, ACM SIGCOMM, P149; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Xu X, 2002, J ARTIF INTELL RES, V16, P259; YALAGANDULA P, 2004, P 2004 C APPL TECHN; Zhuang S.Q., 2001, 11 INT WORKSH NETW O	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366	0-7695-2579-2	IEEE INT CONF AUTOM			2006							15	24				10	Computer Science, Software Engineering	Computer Science	BFI73	WOS:000242043600004	
J	Beal, MJ; Ghahramani, Z				Beal, Matthew J.; Ghahramani, Zoubin			Variational Bayesian Learning of Directed Graphical Models with Hidden Variables	BAYESIAN ANALYSIS			English	Article						Approximate Bayesian Inference; Bayes Factors; Directed Acyclic Graphs; EM Algorithm; Graphical Models; Markov Chain Monte Carlo; Model Selection; Variational Bayes		A key problem in statistics and machine learning is inferring suitable structure of a model given some observed data. A Bayesian approach to model comparison makes use of the marginal likelihood of each candidate model to form a posterior distribution over models; unfortunately for most models of interest, notably those containing hidden or latent variables, the marginal likelihood is intractable to compute. We present the variational Bayesian (VB) algorithm for directed graphical models, which optimises a lower bound approximation to the marginal likelihood in a procedure similar to the standard EM algorithm. We show that for a large class of models, which we call conjugate exponential, the VB algorithm is a straightforward generalisation of the EM algorithm that incorporates uncertainty over model parameters. In a thorough case study using a small class of bipartite DAGs containing hidden variables, we compare the accuracy of the VB approximation to existing asymptotic-data approximations such as the Bayesian Information Criterion (BIC) and the Cheeseman-Stutz (CS) criterion, and also to a sampling based gold standard, Annealed Importance Sampling (AIS). We find that the VB algorithm is empirically superior to CS and BIC, and much faster than AIS. Moreover, we prove that a VB approximation can always be constructed in such a way that guarantees it to be more accurate than the CS approximation.	[Beal, Matthew J.] SUNY Buffalo, Buffalo, NY 14260 USA; [Ghahramani, Zoubin] UCL, Gatsby Computat Neurosci Unit, London, England	Beal, MJ (reprint author), SUNY Buffalo, Buffalo, NY 14260 USA.	mbeal@cse.buffalo.edu; zoubin@gatsby.ucl.ac.uk					Attias H, 2000, ADV NEURAL INFORM PR, V12; Attias H, 1999, P 15 C UNC ART INT; Attias H, 1999, NEURAL COMPUT, V11, P803, DOI 10.1162/089976699300016458; BEAL MJ, 2003, THESIS GATSBY COMPUT; BISHOP CM, 1999, P 9 INT C ART NEUR N; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Chickering DM, 1997, MACH LEARN, V29, P181; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Friedman N., 1998, P 14 C UNC ART INT U; Gelman A, 1998, STAT SCI, V13, P163; Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087; Ghahramani Z., 2001, ADV NEURAL INFORM PR, V13; Ghahramani Z., 2000, ADV NEURAL INFORM PR, V12; GHAHRAMANI Z, 2000, NEURAL COMPUTATION, V12; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Heckerman D., 1996, MSRTR9506; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Hinton G. E., 1994, ADV NEURAL INFORM PR, V6; Hinton G.E., 1993, 6 ACM C COMP LEARN T; Jaakkola T., 1997, THESIS MIT CAMBRIDGE; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; MacKay D., 1997, ENSEMBLE LEARNING HI; MACKAY DJC, 1998, MACHINE LEARNING, V33; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Minka T. P., 2001, USING LOWER BOUNDS A; Neal R. M., 1996, BAYESIAN LEARNING NE; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Neal R.M., 1993, CRGTR931 U TOR DEP C; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Rusakov D, 2005, J MACH LEARN RES, V6, P1; SAUL LK, 1996, ADV NEURAL INFORM PR; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; TORRIE GM, 1977, J COMPUT PHYS, V23, P187, DOI 10.1016/0021-9991(77)90121-8; WATERHOUSE S, 1996, ADV NEURAL INFORM PR, V8	37	15	15	INT SOC BAYESIAN ANALYSIS	PITTSBURGH	CARNEGIE MELLON UNIV, DEPT STTISTICS, PITTSBURGH, PA 15213 USA	1931-6690		BAYESIAN ANAL	Bayesian Anal.		2006	1	4					793	831				39	Mathematics, Interdisciplinary Applications; Statistics & Probability	Mathematics	V10EK	WOS:000207447100011	
B	Yang, MQ; Yang, JY			IEEE COMPUTER SOC	Yang, Mary Qu; Yang, Jack Y.			IUP: Intrinsically unstructured protein predictor - A software tool for analyzing polypeptide sequences	BIBE 2006: SIXTH IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS			English	Proceedings Paper	6th IEEE Syposium on BioInformatics and BioEngineering (BIBE 2006)	OCT 16-18, 2006	Arlington, VA	IEEE Comp Soc, Biol & Artificial Intelligence Soc, ITRI		intrinsically unstructured proteins (IUP); feature selection; classification; ensemble methods	DISORDER	Many protein regions and some entire proteins have no definite tertiary structure, presenting instead as dynamic, disorder ensembles under different physiochemical circumstances. These proteins and regions are known as Intrinsically Unstructured Proteins (IUP). IUP have been associated with a wide range of protein functions and play essential roles in diseases characterized by protein misfolding and aggregation. Identifying IUP is an important but difficult task in today's structural and functional genomics. We exact useful features from polypeptide sequences and develop machine learning algorithms for the above task. We compare our IUP predictor with PONDR (R) (mainly neural-network-based predictors), disEMBL (also based on neural networks) and Globplot (based on IUP propensity). We find that augmenting features derived from physiochemical properties of amino acids (such as 9-gram encoding scheme and hydrophobicity) and using ensemble methods proved beneficial. The IUP predictor is a viable alternative software tool for identifying IUP regions and proteins.	US Dept HHS, NHGRI, Natl Inst Hlth, Bethesda, MD 20852 USA	Yang, MQ (reprint author), US Dept HHS, NHGRI, Natl Inst Hlth, Bethesda, MD 20852 USA.	yangma@mail.NIH.gov; jyang@hadron.mgh.Harvard.edu					CODRINIGTON C, 2001, ICML; Daughdrill GW, 2005, PROTEIN FOLDING HANDBOOK; Duda R., 2000, PATTERN CLASSIFICATI; Dunker AK, 2001, NAT BIOTECHNOL, V19, P805, DOI 10.1038/nbt0901-805; Dunker AK, 2002, BIOCHEMISTRY-US, V41, P6573, DOI 10.1021/bi012159+; FREUND Y, 2003, NONLINEAR ESTIMATION; KYTC J, J MOL BIOL, V157, P105; Linding R, 2003, NUCLEIC ACIDS RES, V31, P3701, DOI 10.1093/nar/gkg519; LINDING R, 2001, PROTEIN STRUCTURE, P11; Radivojac P, 2004, J BIOMED INFORM, V37, P224, DOI 10.1016/j.jbi.2004.07.008; ROMERO P, 1997, P IEEE INT C NEUR NE, V1, P90, DOI 10.1109/ICNN.1997.611643; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; YANG JY, 2004, 1 IND BIOINF C IU SC; YANG JY, P 2005 COMPUTATIONAL; YANG MQ, 2004, INTELLIGENT ENG SYST, V14, P527; YANG MQ, 2005, THESIS PURDUE U W LA	16	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2727-2				2006							3	11				9	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BFK64	WOS:000242503800001	
B	Yang, JY; Yang, MQ			IEEE COMPUTER SOC	Yang, Jack Y.; Yang, Mary Qu			Assessing protein function using a combination of supervised and unsupervised learning	BIBE 2006: Sixth IEEE Symposium on Bioinformatics and BioEngineering, Proceedings			English	Proceedings Paper	6th IEEE Syposium on BioInformatics and BioEngineering (BIBE 2006)	OCT 16-18, 2006	Arlington, VA	IEEE Comp Soc, Biol & Artificial Intelligence Soc, ITRI				The determination of protein function using experimental techniques is time-consuming and expensive; the use of machine learning techniques to rapidly assess protein function may be useful in streamlining this process. The problem of assigning functional classes to proteins is complicated by the fact that a single protein can participate in several different pathways and thus can have multiple functions. It follows that the instances in the resulting classification problem can carry multiple class labels. We have developed a tree-based classifier that capable of handling multiply-labeled data: we call the resulting tree a Recursive Maximum-Contrast Tree (RMCT). The name derives from the way in which nodes in the tree are split; this is done by selecting the two training instances with maximum contrast (that is, the two training instances with maximum separation according to some distance measure) and using them as seeds in a clustering algorithm to form a partition of the training instances and hence of the feature space. We test our algorithm on protein phylogenetic profiles generated from 60 completely sequenced genomes, and we compare our results to those achieved using existing algorithms such as support vector machines and decision trees.	Harvard Univ, Sch Med, Dept Radiat Oncol, Boston, MA 02114 USA	Yang, JY (reprint author), Harvard Univ, Sch Med, Dept Radiat Oncol, Boston, MA 02114 USA.						Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; CHO S, 1993, IEEE T CIRCUITS-II, V40, P556, DOI 10.1109/82.257333; CODRINGTON CW, 1997, THESIS PURDUE U; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIX E, 1951, 2149004 USAF SCH AV; JOACHIMS T., 2002, LEARNING CLASSIFY TE; Pavlidis P., 2001, RECOMB 2001, P249; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Quinlan J. R, DATA MINING TOOLS SE; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Vert Jean-Philippe, 2002, Bioinformatics, V18 Suppl 1, pS276; Williamson M. P., 2000, NUCL OVERHAUSER EFFE; YANG JY, 2003, P ART NEUR NETW ENG; YANG MQ, 2004, P ART NEUR NETW ENG	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2727-2				2006							35	41				7	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BFK64	WOS:000242503800005	
B	Wu, XM; Wang, JTL; Herbert, KG			IEEE COMPUTER SOC	Wu, Xiaoming; Wang, Jason T. L.; Herbert, Katherine G.			A new kernel method for RNA classification	BIBE 2006: Sixth IEEE Symposium on Bioinformatics and BioEngineering, Proceedings			English	Proceedings Paper	6th IEEE Syposium on BioInformatics and BioEngineering (BIBE 2006)	OCT 16-18, 2006	Arlington, VA	IEEE Comp Soc, Biol & Artificial Intelligence Soc, ITRI			DNA-SEQUENCE CLASSIFICATION; PROTEIN SEQUENCES; MOTIFS	Support vector machines (SVMs) are a state-of-the-art machine learning tool widely used in speech recognition, image processing and biological sequence analysis. An essential step in SVMs is to devise a kernel function to compute the similarity between two data points in Euclidean space. In this paper we present a new kernel that takes advantage of both global and local structural information in RNAs and uses the information together to classify RNAs with support vector machines. Experimental results demonstrate the good performance of the new kernel and show that it outperforms existing kernels when applied to classifying non-coding RNA sequences.	Montclair State Univ, Dept Comp Sci, Montclair, NJ 07043 USA	Herbert, KG (reprint author), Montclair State Univ, Dept Comp Sci, Montclair, NJ 07043 USA.						Bailey T. L., 1994, P 2 INT C INT SYST M, P28; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Brazma A., 1996, P 4 INT C INT SYST M, P34; Burges C.J.C., 1998, DATA MIN KNOWL DISC, V2, P955; Durbin R, 1998, BIOL SEQUENCE ANAL; Gan HH, 2003, NUCLEIC ACIDS RES, V31, P2926, DOI 10.1093/nar/gkg365; Gartner T., 2003, ACM SIGKDD EXPLORATI, V5, P49, DOI 10.1145/959242.959248; GRIGGITHSJONES S, 2003, NUCLEIC ACIDS RES, V31, P439; HART R, 2000, P 4 ANN INT C COMP M, P147, DOI 10.1145/332306.332360; HUI LCK, 1992, LECT NOTES COMPUT SC, V644, P230; JONASSEN I, 1995, PROTEIN SCI, V4, P1587; KARKLIN Y, 2005, P PAC S BIOC, P5; Kashima H., 2003, P 20 INT C MACH LEAR, P321; LIU J, 2005, BMC INFORMATICS, V6; Ma B, 2002, THEOR COMPUT SCI, V276, P111, DOI 10.1016/S0304-3975(01)00192-X; Ma QC, 2001, IEEE T SYST MAN CY C, V31, P468; Noble W. S., 2004, KERNEL METHODS COMPU, P71; PLATT J, 1998, 9814 MICR RES; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHAPIRO BA, 2003, COMPUTATIONAL BIOL D, P1, DOI 10.1142/9789812564498_0001; SHAPIRO BA, 1999, PATTERN DISCOVERY BI, P183; Smith T., 1981, ADV APPL MATH, V2, P482, DOI 10.1016/0196-8858(81)90046-4; TSUDA K, 2002, P 10 INT C INT SYST, P268; Tsuda Koji, 2002, BIOINFORMATICS, V18, P268; Vapnik V. N, 1995, NATURE STAT LEARNING; Wang J., 1999, PATTERN DISCOVERY BI; Wang J., 2005, DATA MINING BIOINFOR; Wang JTL, 1996, PROTEIN ENG, V9, P381, DOI 10.1093/protein/9.5.381; WANG JTL, 2003, COMPUTATIONAL BIOL G; Wang J. T. L., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347157; WANG JTL, 1994, NUCLEIC ACIDS RES, V22, P2769, DOI 10.1093/nar/22.14.2769; Wang JTL, 1999, J COMPUT BIOL, V6, P209, DOI 10.1089/cmb.1999.6.209; Wang JTL, 2001, IBM SYST J, V40, P426; Wuchty S, 1999, BIOPOLYMERS, V49, P145, DOI 10.1002/(SICI)1097-0282(199902)49:2<145::AID-BIP4>3.0.CO;2-G; Yin MM, 2001, INFORM SCIENCES, V139, P139, DOI 10.1016/S0020-0255(01)00160-8; Yin MM, 2004, INFORM SCIENCES, V163, P201, DOI 10.1016/j.ins.2003.03.016; ZHANG K, 2005, DATA MINING BIOINFOR, P59, DOI 10.1007/1-84628-059-1_4	38	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2727-2				2006							201	208				8	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BFK64	WOS:000242503800027	
B	Giardina, M; Azuaje, F; McCullagh, P; Harper, R			IEEE COMPUTER SOC	Giardina, Marisol; Azuaje, Francisco; McCullagh, Paul; Harper, Roy			A supervised learning approach to predicting coronary heart disease complications in type 2 diabetes mellitus patients	BIBE 2006: SIXTH IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS			English	Proceedings Paper	6th IEEE Syposium on BioInformatics and BioEngineering (BIBE 2006)	OCT 16-18, 2006	Arlington, VA	IEEE Comp Soc, Biol & Artificial Intelligence Soc, ITRI			RISK-FACTORS	A supervised machine learning approach that incorporates Genetic Algorithms (GA) and Weighted k-Nearest Neighbours (WkNN) was applied to classify type 2 diabetes mellitus (T2DM) patients according to the presence or absence of Coronary Heart Disease (CHD) complications. The investigation was carried out by analyzing potential risk factors recorded at the Ulster Hospital in Northern Ireland A GA initialization technique that integrates medical expert knowledge was compared with traditional data-driven GA initialization techniques. The results indicate that the incorporation of expert knowledge provides only a small improvement of CHD classification performance compared with models based on data-driven initialization techniques. This may be due to data incompleteness and noise or due to the beneficial effects of treatment, which masks the complication of CHD in the dataset. Further incorporation of expert knowledge at dtfferent levels of the GA need to be addressed to improve decision support in this domain.	Univ Ulster, Sch Comp & Math, Jordanstown, North Ireland	Giardina, M (reprint author), Univ Ulster, Sch Comp & Math, Jordanstown, North Ireland.	m.giardina@ulster.ac.uk; fj.azuaje@ulster.ac.uk; pj.mccullagh@ulster.ac.uk; roy.harper@ucht.n-i.nhs.uk					Armengol E, 2001, METHOD INFORM MED, V40, P46; Donnelly R, 2000, BRIT MED J, V320, P1062, DOI 10.1136/bmj.320.7241.1062; GABEL T, 2004, P 7 EUR C CAS BAS RE, P169; Giardina M, 2005, COMP MED SY, P347, DOI 10.1109/CBMS.2005.13; GIRALDEZ CR, 2005, IEEE T SYST MAN CY C, V35; Goldberg DE, 1989, GENETIC ALGORITHMS S; GURGEN F, 2003, BIOMEDICAL ENG ONLIN, P1; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Kelly J.D., 1991, P 12 INT JOINT C ART, P645; KOPELMAN PG, 1995, DIABETIC MED, V12, P83; Louis SJ, 1995, INT J EXPERT SYST, V8, P195; Michalewicz Z, 1996, GENETIC ALGORITHMS D; ROSENGREN A, 1989, BRIT MED J, V299, P1127; Stevens RJ, 2001, CLIN SCI, V101, P671, DOI 10.1042/CS20000335; Turner RC, 1998, BRIT MED J, V316, P823; WETTSCHERECK D, 1997, ARTIF INTELL, V10, P1; YANG H, 1993, P ACM ANN COMP SCI C, P378	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2727-2				2006							325	331				7	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BFK64	WOS:000242503800044	
J	Desai, K; Badhe, Y; Tambe, SS; Kulkarni, BD				Desai, K; Badhe, Y; Tambe, SS; Kulkarni, BD			Soft-sensor development for fed-batch bioreactors using support vector regression	BIOCHEMICAL ENGINEERING JOURNAL			English	Article						artificial neural networks; bioreactor; soft-sensors; support vector regression; multilayer perceptron; radial basis function network	NEURAL-NETWORKS; FERMENTATION; OPTIMIZATION; MACHINES; STREPTOKINASE; CULTURES; GROWTH; NOISE	In the present paper, a state-of-the-art machine learning based modeling formalism known as "support vector regression (SVR)", has been introduced for the soft-sensor applications in the fed-batch processes. The SVR method possesses a number of attractive properties such as a strong statistical basis, convergence to the unique global minimum and an improved generalization performance by the approximated function. Also, the structure and parameters of an SVR model can be interpreted in terms of the training data. The efficacy of the SVR formalism for the soft-sensor development task has been demonstrated by considering two simulated bio-processes namely, invertase and streptokinase. Additionally, the performance of the SVR based soft-sensors is rigorously compared with those developed using the multilayer perceptron and radial basis function neural networks. The results presented here clearly indicate that the SVR is an attractive alternative to artificial neural networks for the development of soft-sensors in bioprocesses. (c) 2005 Elsevier B.V. All rights reserved.	Natl Chem Lab, Chem Engn & Proc Dev Div, Pune 411008, Maharashtra, India	Tambe, SS (reprint author), Natl Chem Lab, Chem Engn & Proc Dev Div, Dr Homi Bhabha Rd, Pune 411008, Maharashtra, India.	sstambe@che.ncl.res.in	KULKARNI, B/C-1371-2009				ACURA G, 1998, J FERMENT BIOENG, V85, P615; Adilson J., 2000, COMPUT CHEM ENG, V24, P1099; Albert S, 2001, TRENDS BIOTECHNOL, V19, P53, DOI 10.1016/S0167-7799(00)01528-6; BASTIN G, 1990, ON LINE ESTIMATION A; BEEJHERK HE, 1977, BIOTECHNOL BIOENG, V19, P267; BISHOP CM, 1995, NEURAL NETWORKS PATT, V4; Burges C, 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Chang C.-C., 2001, LIBSVM LIB SUPPORT V; Chang MW, 2004, IEEE T NEURAL NETWOR, V15, P720, DOI 10.1109/TNN.2004.824270; CHEN BJ, 2001, LOAD FORECASTING USI; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2; DEDERN GV, 1975, BIOTECHNOL BIOENG, V17, P1301; Dibike Y.B., 2000, P 2 JOINT WORKSH APP; Dochain D, 1997, ADV BIOCHEM ENG, V56, P149; Drucker H, 1997, ADV NEUR IN, V9, P155; EERIKAINEN T, 1993, TRENDS FOOD SCI TECH, V4, P237, DOI 10.1016/0924-2244(93)90137-Y; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Feyo de Azevedo S., 1997, COMPUT CHEM ENG, V21, P751; Freeman J.A., 1991, NEURAL NETWORKS ALGO; GEORGIOU G, 1985, BIOTECHNOL PROGR, V1, P75, DOI 10.1002/btpr.5420010114; Haykins S., 1999, NEURAL NETWORKS COMP; Hertz J., 1991, INTRO THEORY NEURAL; HODGE D, 2002, P AM CONTR C, V4, P2879, DOI 10.1109/ACC.2002.1025226; James S, 2002, J PROCESS CONTR, V12, P113, DOI 10.1016/S0959-1524(00)00065-2; JAMES SC, 2000, CAN REV CHEM ENG, V16, P311; Joachims T., 1998, ADV KERNEL METHODS S; Jose L, 1999, CAN J CHEM ENG, V77, P707; KARIM MN, 1992, COMPUT CHEM ENG, V16, P369; KROGH A, 1992, ADV NEUR IN, V4, P950; LEE SB, 1984, BIOTECHNOL BIOENG, V26, P66, DOI 10.1002/bit.260260113; Linko S, 1999, TRENDS BIOTECHNOL, V17, P155, DOI 10.1016/S0167-7799(98)01299-2; MEHER M, 1995, J CHEM TECHNOL BIOT, V63, P153; MONTAGUE GA, 1986, IEE PROC-D, V133, P240; MONTAGUE GA, 1998, MONITORING CONTROL F; MONTAGUE GA, 1992, J BIOTECHNOL, V25, P183, DOI 10.1016/0168-1656(92)90114-O; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Muller K.R, 1997, LECT NOTES COMPUTER, V1327, P999; Nandi S, 2001, AICHE J, V47, P126, DOI 10.1002/aic.690470113; Oliveira R, 2004, COMPUT CHEM ENG, V28, P755, DOI 10.1016/j.compchemeng.2004.02.014; Patnaik PR, 1999, PROCESS BIOCHEM, V35, P309, DOI 10.1016/S0032-9592(99)00073-4; PATNAIK PR, 1995, BIOPROCESS ENG, V13, P109, DOI 10.1007/BF00420437; Platt J., 1998, ADV KERNEL METHODS S; Pons M. N., 1988, CHEM ENG SCI, V8, P1909; PYUN Y R, 1989, Biotechnology and Bioengineering, V33, P1, DOI 10.1002/bit.260330102; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; RYAN W, 1989, BIOTECHNOL BIOENG, V34, P309, DOI 10.1002/bit.260340306; RYAN W, 1991, BIOTECHNOL BIOENG, V37, P415, DOI 10.1002/bit.260370504; Sarkar D, 2003, CHEM ENG SCI, V58, P2283, DOI 10.1016/S0009-2509(03)00095-2; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; SEO J-H, 1985, Biotechnology and Bioengineering, V27, P1668, DOI 10.1002/bit.260271207; Shimizu K, 1996, COMPUT CHEM ENG, V20, P915, DOI 10.1016/0098-1354(95)00188-3; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Tambe S. S., 1996, ELEMENTS ARTIFICIAL; THISSEN U, 2003, CHEMOM INTELL LAB SY, V1, P35; TODA K, 1980, BIOTECHNOL BIOENG, V22, P1805, DOI 10.1002/bit.260220904; Vapnik V. N., 1996, ADV NEURAL INFORMATI, V9, P281; Vapnik V. N, 1995, NATURE STAT LEARNING; Vapnik VN, 1998, STAT LEARNING THEORY; XU AK, 1993, IEEE T NEURAL NETWOR, V4, P636; Zhao Y., 1996, THESIS NORWEGIAN U S; ZHU YH, 1996, BIOCH ENG J, V62, P207	62	41	55	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	1369-703X		BIOCHEM ENG J	Biochem. Eng. J.	JAN	2006	27	3					225	239		10.1016/j.bej.2005.08.002		15	Biotechnology & Applied Microbiology; Engineering, Chemical	Biotechnology & Applied Microbiology; Engineering	985AO	WOS:000233348700005	
B	Myasnikova, E; Samsonova, A; Surkova, S; Samsonova, M; Reinitz, J		Kolchanov, N; Hoffestaedt, R; Milanesi, L		Myasnikova, E; Samsonova, A; Surkova, S; Samsonova, M; Reinitz, J			Determination of the developmental age of a Drosophila embryo from confocal images of its segmentation gene expression patterns	Bioinformatics of Genome Regulation and Structure II			English	Proceedings Paper	4th International Conference on Bioinformatics of Genome Regulation and Structure (BGRS 2004)	JUL 25-30, 2004	Novosibirsk, RUSSIA	Russian Acad Sci, Siberian Branch, Inst Cytol & Genet, Lab Theoret Genet		gene expression; embryo staging; Drosophila; support vector regression		In the paper, we address the problem of the temporal characterization of Drosophila embryos. We have developed a method for automated staging of an embryo on the basis of a confocal image of its gene expression pattern. Phases of spectral Fourier coefficients were used as the features characterizing temporal changes in expression patterns. The age detection is implemented by applying support vector regression, which is a machine learning method for creating regression functions of arbitrary type from a set of training data. The training set is composed of embryos for which the precise developmental age was determined by measuring the degree of membrane invagination. Testing the quality of regression on the training set showed a good prediction accuracy.	St Petersburg State Univ, St Petersburg 195257, Russia	Myasnikova, E (reprint author), St Petersburg State Univ, 29,Politehnicheskaya, St Petersburg 195257, Russia.							0	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES		0-387-29450-3				2006							467	478		10.1007/0-387-29455-4_44		12	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Genetics & Heredity; Mathematics, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Genetics & Heredity; Mathematics	BDN75	WOS:000234508700045	
S	Tzanis, G; Berberidis, C; Vlahavas, I		Maglaveras, N; Chouvarda, I; Koutkias, V; Brause, R		Tzanis, George; Berberidis, Christos; Vlahavas, Ioannis			A novel data mining approach for the accurate prediction of translation initiation sites	Biological and Medical Data Analysis, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	7th International Symposium on Biological and Medical Data Analysis	DEC 07-08, 2006	Thessaloniki, GREECE				SEQUENCES	In an mRNA sequence, the prediction of the exact codon where the process of translation starts (Translation Initiation Site - TIS) is a particularly important problem. So far it has been tackled by several researchers that apply various statistical and machine learning techniques, achieving high accuracy levels, often over 90%. In this paper we propose a mahine learning approach that can further improve the prediction accuracy. First, we provide a concise review of the literature in this field. Then we propose a novel feature set. We perform extensive experiments on a publicly available, real world dataset for various vertebrate organisms using a variety of novel features and classification setups. We evaluate our results and compare them with a reference study and show that our approach that involves new features and a combination of the Ribosome Scanning Model with a meta-classifier shows higher accuracy in most cases.	Aristotle Univ Thessaloniki, Dept Informat, GR-54124 Thessaloniki, Greece	Tzanis, G (reprint author), Aristotle Univ Thessaloniki, Dept Informat, GR-54124 Thessaloniki, Greece.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Benson DA, 1997, NUCLEIC ACIDS RES, V25, P1, DOI 10.1093/nar/25.1.1; COHEN W, 1995, P 12 INT C MACH LEAR, P80; Hatzigeorgiou AG, 2002, BIOINFORMATICS, V18, P343, DOI 10.1093/bioinformatics/18.2.343; John G. H., 1995, P 11 C UNC ART INT, P338; Kohavi R., 1995, P 14 INT JOINT C ART; Kohavi R, 1995, LECT NOTES ARTIF INT, P174; KOZAK M, 1987, NUCLEIC ACIDS RES, V15, P8125, DOI 10.1093/nar/15.20.8125; KOZAK M, 1989, J CELL BIOL, V108, P229, DOI 10.1083/jcb.108.2.229; KOZAK M, 1978, J BIOL CHEM, V253, P6568; Li G., 2005, IEEE T KNOWL DATA EN, V8, P1152; Liu Huiqing, 2003, J Bioinform Comput Biol, V1, P139, DOI 10.1142/S0219720003000216; Liu Huiqing, 2004, In Silico Biol, V4, P255; Nadershahi A., 2004, BMC BIOINFORMATICS, V5; Nishikawa T, 2000, BIOINFORMATICS, V16, P960, DOI 10.1093/bioinformatics/16.11.960; Pedersen AG, 1997, P 5 INT C INT SYST M, P226; Platt J., 1998, ADV KERNEL METHODS S; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Salamov AA, 1998, BIOINFORMATICS, V14, P384, DOI 10.1093/bioinformatics/14.5.384; STORMO GD, 1982, NUCLEIC ACIDS RES, V10, P2997, DOI 10.1093/nar/10.9.2997; Tzanis G, 2006, LECT NOTES COMPUT SC, V3955, P367; TZANIS G, 2005, P 10 PANH C INF PCI, P426; Witten I. H., 2000, DATA MINING PRACTICA; Zeng F., 2002, P 13 INT C GEN INF, P192; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	25	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-68063-5	LECT NOTES COMPUT SC			2006	4345						92	103				12	Biology; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Medicine, Research & Experimental	Life Sciences & Biomedicine - Other Topics; Computer Science; Research & Experimental Medicine	BFT86	WOS:000244560100009	
B	Baldi, P		Mondaini, R; Dilao, R		Baldi, Pierre			Exploring chemical space with computers: Informatics challenges for ai and machine learning	BIOMAT 2005			English	Proceedings Paper	International Symposium on Mathematical and Computational Biology (BIOMAT 2005)	DEC 03-08, 2005	Petropolis, BRAZIL	CAPES, FINEP, Natl Lab Sci Comp			BIOLOGY; PREDICTION; MOLECULES; CHEMISTRY; GENOMICS; DATABASE; DRUGS	The penetration of informatics and modern computer metods in chemistry lags far behind their penetration in physics and biology. Rather than resulting from intrinsic peculiarities of chemistry as a science, this unfortunate state of affairs is more likely to be the product of historical accidents. As was the case for bioinformatics, we argue that two key ingredients are essential for the large-scale development of chemoinformatics. First, the development of large-scale, publicly available, database and data sets of chemical information, including compounds, reactions, and annotations. Second the development of algorithms and resulting open source software for a variety of computational tasks, prominently including the mathematical quantification and efficient implementaton of methods for measuring chemical similarity.	Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA	Baldi, P (reprint author), Univ Calif Irvine, Sch Informat & Comp Sci, Inst Genom & Bioinformat, Irvine, CA 92697 USA.						Agrafiotis DK, 2002, NAT REV DRUG DISCOV, V1, P337, DOI 10.1038/nrd791; Baldi P., 2001, BIOINFORMATICS MACHI; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bohacek RS, 1996, MED RES REV, V16, P3, DOI 10.1002/(SICI)1098-1128(199601)16:1<3::AID-MED1>3.0.CO;2-6; CHEN J, 2005, IN PRESS BIOINFORMAT; Dobson CM, 2004, NATURE, V432, P824, DOI 10.1038/nature03192; Houghten RA, 2000, ANNU REV PHARMACOL, V40, P273, DOI 10.1146/annurev.pharmtox.40.1.273; Irwin JJ, 2005, J CHEM INF MODEL, V45, P177, DOI 10.1021/ci049714+; Jonsdottir SO, 2005, BIOINFORMATICS, V21, P2145, DOI 10.1093/bioinformatics/bti314; Lipinski C, 2004, NATURE, V432, P855, DOI 10.1038/nature03193; Marris E, 2005, NATURE, V435, P718, DOI 10.1038/435718a; MICHELI A, 2003, SOFT COMPUTING APPRO, P265; RALAIVOLA L, 2005, IN PRESS NEURAL NETW; Schreiber SL, 2003, CHEM ENG NEWS, V81, P51; Schreiber SL, 2000, SCIENCE, V287, P1964, DOI 10.1126/science.287.5460.1964; Shoichet BK, 2004, NATURE, V432, P862, DOI 10.1038/nature03197; Stockwell BR, 2004, NATURE, V432, P846, DOI 10.1038/nature03196; Strausberg RL, 2003, SCIENCE, V300, P294, DOI 10.1126/science.1083395; Swamidass SJ, 2005, BIOINFORMATICS, V21, pI359, DOI 10.1093/bioinformatics/bti1055	19	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		978-981-256-797-0				2006							343	350		10.1142/9789812773685_0020		8	Mathematical & Computational Biology	Mathematical & Computational Biology	BGE68	WOS:000246340600020	
J	Chun, HW; Tsuruoka, Y; Kim, JD; Shiba, R; Nagata, N; Hishiki, T; Tsujii, J				Chun, Hong-Woo; Tsuruoka, Yoshimasa; Kim, Jin-Dong; Shiba, Rie; Nagata, Naoki; Hishiki, Teruyoshi; Tsujii, Jun'ichi			Automatic recognition of topic-classified relations between prostate cancer and genes using MEDLINE abstracts	BMC BIOINFORMATICS			English	Article; Proceedings Paper	2nd International Symposium on Semantic Mining in Biomedicine	APR 09-12, 2006	Jena, GERMANY					Background: Automatic recognition of relations between a specific disease term and its relevant genes or protein terms is an important practice of bioinformatics. Considering the utility of the results of this approach, we identified prostate cancer and gene terms with the ID tags of public biomedical databases. Moreover, considering that genetics experts will use our results, we classified them based on six topics that can be used to analyze the type of prostate cancers, genes, and their relations. Methods: We developed a maximum entropy-based named entity recognizer and a relation recognizer and applied them to a corpus-based approach. We collected prostate cancer-related abstracts from MEDLINE, and constructed an annotated corpus of gene and prostate cancer relations based on six topics by biologists. We used it to train the maximum entropy-based named entity recognizer and relation recognizer. Results: Topic-classified relation recognition achieved 92.1% precision for the relation (an increase of 11.0% from that obtained in a baseline experiment). For all topics, the precision was between 67.6 and 88.1%. Conclusion: A series of experimental results revealed two important findings: a carefully designed relation recognition system using named entity recognition can improve the performance of relation recognition, and topic-classified relation recognition can be effectively addressed through a corpus-based approach using manual annotation and machine learning techniques.	Univ Tokyo, Dept Comp Sci, Grad Sch Informat Sci & Technol, Tokyo, Japan; Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England; NaCTeM, Manchester, Lancs, England	Chun, HW (reprint author), Univ Tokyo, Dept Comp Sci, Grad Sch Informat Sci & Technol, Tokyo, Japan.	chun@is.s.u-tokyo.ac.jp; yoshimasa.tsuruoka@manchester.ac.uk; jdkim@is.s.u-tokyo.ac.jp; rshiba@jbirc.aist.go.jp; nnagata@jbirc.aist.go.jp; hishiki@jbirc.aist.go.jp; tsujii@is.s.u-tokyo.ac.jp					Berger AL, 1996, COMPUT LINGUIST, V22, P39; Chun Hong-Woo, 2006, Pac Symp Biocomput, P4, DOI 10.1142/9789812701626_0002; Gaudan S, 2005, BIOINFORMATICS, V21, P3658, DOI 10.1093/bioinformatics/bti586; Kim J, 2004, P INT WORKSH NAT LAN, P70, DOI 10.3115/1567594.1567610; NINOMIYA T, 2005, P 9 INT WORKSH PARS; ROSARIO B, 2004, P ANN M ASS COMP LIN; SANG E, 2003, P COMP NAT LANG LEAR; *U TOK TSUJ GROUP, 2004, ENJ VERS 2 1	8	5	5	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics		2006	7			3					S4	10.1186/1471-2105-7-S3-S4		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	144IK	WOS:000244789500004	
