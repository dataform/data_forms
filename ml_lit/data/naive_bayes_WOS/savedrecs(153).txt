PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
J	Kohavi, R; John, GH				Kohavi, R; John, GH			Wrappers for feature subset selection	ARTIFICIAL INTELLIGENCE			English	Review						classification; feature selection; wrapper; filter	LEARNING ALGORITHMS; IRRELEVANT	In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes. (C) 1997 Elsevier Science B.V.	Silicon Graph Inc, Data Min & Visualizat, Mt View, CA 94043 USA; Epiphany Mkt Software, Mt View, CA 94043 USA	Kohavi, R (reprint author), Silicon Graph Inc, Data Min & Visualizat, 2011 N Shoreline Blvd, Mt View, CA 94043 USA.						Aha D.W., 1995, P 5 INT WORKSH ART I, P1; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; ANDERSON JR, 1992, MACH LEARN, V9, P275, DOI 10.1023/A:1022697317482; Atkeson C. G., 1991, Proceedings. 1991 IEEE International Conference on Robotics and Automation (Cat. No.91CH2969-4), DOI 10.1109/ROBOT.1991.131713; Bala J., 1995, P 14 INT JOINT C ART, P719; Bankert R.L., 1994, AAAI94 WORKSH CAS BA, P106; Ben-Bassat M., 1982, HDB STATISTICS, V1, P773, DOI 10.1016/S0169-7161(82)02038-0; BERLINER H, 1979, ARTIF INTELL, V12, P23, DOI 10.1016/0004-3702(79)90003-1; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; Boddy M., 1989, P 11 INT JOINT C ART, P979; Brazdil P., 1994, P EUR C MACH LEARN; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Caruana R., 1994, P 11 INT C MACH LEAR, P28; Cestnik B, 1990, P EUR C ART INT, P147; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Dasarathy B. V., 1990, NEAREST NEIGHBOR NN; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; Devijver P., 1982, PATTERN RECOGNITION; Doak J., 1992, CSE9218 U CAL DAV; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Draper N.R., 1981, APPL REGRESSION ANAL; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U., 1992, P 10 NAT C ART INT S, P104; FAYYAD UM, 1991, THESIS MICHIGAN U; Fisher D., 1995, P 5 INT WORKSH ART I; Fong P., 1995, P 12 INT C MACH LEAR, P226; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; Freund Y., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; FREUND Y, IN PRESS INFORM COMP; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5; Ginsberg M., 1993, ESSENTIALS ARTIFICIA; Goldberg D., 1989, GENETIC ALGORITHMS S; Good I, 1965, ESTIMATION PROBABILI; Greiner R., 1992, Proceedings of the Ninth Biennial Conference of the Canadian Society for Computational Studies of Intelligence; HANCOCK T, 1989, UNPUB DIFFICULTY FIN; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; HOLLAND JH, 1992, ADAPTATION NATURAL A; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; John G., 1994, P 11 INT C MACH LEAR, P121; JOHN GH, 1997, THESIS STANFORD U CA; Judd S., 1988, Journal of Complexity, V4, DOI 10.1016/0885-064X(88)90019-2; Kaelbling L.P., 1993, LEARNING EMBEDDED SY; Kira K, 1992, P 10 NAT C ART INT, P129; Kira K., 1992, P 9 INT C MACH LEARN; KITTLER J, 1986, FEATURE SELECTION EX, P59; KITTLER J, 1978, P C REC FORM TRAIT I; Kohav R., 1996, P 13 INT C MACH LEAR, P275; KOHAVI R, 1994, P AAAI FALL S REL, P122; KOHAVI R, 1996, TOOLS ARTIFICIAL INT, P234; Kohavi R., 1995, P 1 INT C KNOWL DISC, P192; Kohavi R., 1995, P 12 INT C MACH LEAR, P304; KOHAVI R, 1994, P 3 INT WORKSH ROUGH, P310; Kohavi R, 1995, LECT NOTES ARTIF INT, P174; KOHAVI R, 1995, STANCSTR951560 STANF; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kononenko I., 1995, P 14 INT JOINT C ART, P1034; Kononenko I., 1994, P EUR C MACH LEARN; Koza J., 1992, GENETIC PROGRAMMING; KROGH AS, 1995, ADV NEURAL INFORMATI, V7; Kwok SW, 1990, UNCERTAINTY ARTIFICI, V4, P327; Laarhoven PJM, 1987, SIMULATED ANNEALING; Langley P, 1994, AAAI 94 WORKSH CAS B, P113; Langley P., 1994, P AAAI FALL S REL, P140; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; Linhart H., 1986, MODEL SELECTION; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; MARILL T, 1963, IEEE T INFORM THEORY, V9, P11, DOI 10.1109/TIT.1963.1057810; MARON O, 1994, ADV NEURAL INFORMATI, V6; Merz CJ, 1996, UCI REPOSITORY MACHI; Miller A. J., 1990, SUBSET SELECTION REG; MILLER AJ, 1984, J ROY STAT SOC A STA, V147, P389, DOI 10.2307/2981576; Minsky M., 1988, PERCEPTRONS INTRO CO; MLADENIC D, 1995, ECML WORKSH KNOWL LE; Modrzejewski M., 1993, P EUR C MACH LEARN, P213; Moore A, 1994, P 11 INT C MACH LEAR; MORET BME, 1982, COMPUT SURV, V14, P593; Murthy SK, 1995, P 14 INT JOINT C ART, P1025; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Neter J, 1990, APPL LINEAR STAT MOD; Pawlak Z., 1993, Foundations of Computing and Decision Sciences, V18; Pawlak Z., 1991, ROUGH SETS; Perrone M.P., 1993, THESIS BROWN U PROVI; PROVAN GM, 1995, P 5 INT WORKSH ART I, P450; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; PROVOST FJ, 1992, 9234 U PITTSB COMP S; Quinlan J.R., 1995, P 14 INT JOINT C ART, P1019; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rendell L., 1990, Computational Intelligence, V6, DOI 10.1111/j.1467-8640.1990.tb00298.x; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Russell S., 1995, ARTIFICIAL INTELLIGE; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; Singh M, 1995, P 12 INT C MACH LEAR, P497; SKALAK D, 1994, P 11 INT C MACH LEAR; STREET WN, 1995, P 12 INT C MACH LEAR; TAYLOR C, 1994, MACHINE LEARNING NEU; THRUN, 1991, CMUCS91197; Turney P., 1996, P ICML 96 WORKSH LEA, P53; Turney P. D., 1993, P EUR C MACH LEARN, P402; UTGOFF PE, 1995, 0518 U MASS; Utgoff PE, 1994, P 11 INT C MACH LEAR, P318; Vafaie H., 1993, Proceedings. Fifth International Conference on Tools with Artificial Intelligence TAI '93 (Cat. No.93CH3325-8), DOI 10.1109/TAI.1993.633981; Vafaie H., 1992, Proceedings. Fourth International Conference on Tools with Artificial Intelligence, TAI '92 (Cat. No. 92CH3203-7), DOI 10.1109/TAI.1992.246402; Wolpert D. H., 1992, Complex Systems, V6; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XU L, 1989, P 9 INT C PATT REC, P706; YAN D, 1992, SIAM J CONTROL OPTIM, V30, P594, DOI 10.1137/0330034; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z; Ziarko W., 1991, KNOWLEDGE DISCOVERY	122	1831	1917	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702			ARTIF INTELL	Artif. Intell.	DEC	1997	97	1-2					273	324		10.1016/S0004-3702(97)00043-X		52	Computer Science, Artificial Intelligence	Computer Science	YP845	WOS:000071321500009	
J	Friedman, N; Geiger, D; Goldszmidt, M				Friedman, N; Geiger, D; Goldszmidt, M			Bayesian network classifiers	MACHINE LEARNING			English	Article						Bayesian networks; classification	PROBABILISTIC NETWORKS; MISSING DATA; KNOWLEDGE; INFERENCE	Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes is competitive with state-of-the-art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we evaluate approaches for inducing classifiers from data, based on the theory of learning Bayesian networks. These networks are factored representations of probability distributions that generalize the naive Bayesian classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness that characterize naive Bayes. We experimentally rested these approaches, using problems from the University of California at Irvine repository, and compared them to C4.5, naive Bayes, and wrapper methods for feature selection.	Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; SRI Int, Menlo Park, CA 94025 USA	Friedman, N (reprint author), Univ Calif Berkeley, Div Comp Sci, 387 Soda Hall, Berkeley, CA 94720 USA.		Friedman, Nir/H-9692-2012				Bouckaert R. R., 1994, P 10 C UNC ART INT S, P102; Buntine W., 1991, P 7 C UNC ART INT, P52; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Cestnik B, 1990, P EUR C ART INT, P147; CHICKERING DM, 1995, LEARNING DATA; CHICKERING DM, 1996, P 12 C UNC ART INT S, P158; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cormen T. H., 1990, INTRO ALGORITHMS; Cover T. M., 1991, ELEMENTS INFORMATION; DAWID AP, 1976, BIOMETRICS, V32, P647, DOI 10.2307/2529753; DeGroot M., 1970, OPTIMAL STAT DECISIO; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Duda R., 1973, PATTERN CLASSIFICATI; Ezawa K.J., 1995, P 11 C UNC ART INT, P157; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Fisher D., 1995, P 5 INT WORKSH ART I; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N., 1996, P 12 C UNC ART INT, P252; Friedman N., 1996, P 13 INT C MACH LEAR, P157; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; Friedman N., 1997, P 14 INT C MACH LEAR, P125; Geiger D., 1996, P 12 C UNC ART INT, P283; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; Geiger D., 1992, P 8 C UNC AI, P92; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Heckerman D., 1995, P 11 C UNC ART INT, P274; Heckerman D, 1991, PROBABILISTIC SIMILA; Heckerman D., 1995, MSRTR9506 MICR RES; JOHN G, 1997, P 11 INT C MACH LEAR, P121; JOHN GH, 1995, P 11 C UNC ART INT, P338; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Kullback S, 1951, ANN MATH STAT, V22, P76; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; LAURITZEN SL, 1995, COMPUT STAT DATA AN, V19, P191, DOI 10.1016/0167-9473(93)E0056-A; LEWIS PM, 1959, INFORM CONTR, V2, P214, DOI 10.1016/S0019-9958(59)90207-4; Murphy P. M., 1995, UCI REPOSITORY MACHI; Pearl J., 1988, PROBABILISTIC REASON; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ripley B., 1996, PATTERN RECOGNITION; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; Singh M, 1995, P 12 INT C MACH LEAR, P497; Singh M., 1996, P 13 INT C MACH LEAR, P453; SPIEGELHALTER DJ, 1993, STAT SCI, V8, P219, DOI 10.1214/ss/1177010888; Suzuki J., 1993, P 9 C UNC ART INT, P266	51	1023	1169	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	NOV-DEC	1997	29	2-3					131	163		10.1023/A:1007465528199		33	Computer Science, Artificial Intelligence	Computer Science	YN352	WOS:000071159300003	
J	Peng, HC; Long, FH; Ding, C				Peng, HC; Long, FH; Ding, C			Feature selection based on mutual information: Criteria of max-dependency, max-relevance, and min-redundancy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature selection; mutual information; minimal redundancy; maximal relevance; maximal dependency; classification	WRAPPERS; CANCER	Feature selection is an important problem for pattern classification systems. We study how to select good features according to the maximal statistical dependency criterion based on mutual information. Because of the difficulty in directly implementing the maximal dependency condition, we first derive an equivalent form, called minimal-redundancy-maximal-relevance criterion (mRMR), for first-order incremental feature selection. Then, we present a two-stage feature selection algorithm by combining mRMR and other more sophisticated feature selectors (e. g., wrappers). This allows us to select a compact set of superior features at very low cost. We perform extensive experimental comparison of our algorithm and other methods using three different classifiers (naive Bayes, support vector machine, and linear discriminate analysis) and four different data sets (handwritten digits, arrhythmia, NCI cancer cell lines, and lymphoma tissues). The results confirm that mRMR leads to promising improvement on feature selection and classification accuracy.	Univ Calif Berkeley, Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA; Lawrence Berkeley Lab, Computat Res Div, Berkeley, CA 94720 USA	Peng, HC (reprint author), Univ Calif Berkeley, Lawrence Berkeley Natl Lab, 1 Cyclotron Rd,MS 84-171, Berkeley, CA 94720 USA.	hpeng@lbl.gov; flong@lbl.gov; CHQDing@lbl.gov	Peng, Hanchuan/A-1798-2011				Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Burgess C., 1998, KNOWLEDGE DISCOVERY, V2, P1; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523; DUIN RPW, 2000, P 1 INT WORKSH MULT, P16; HADLEY SW, 1996, P ANN M AM ASS PHYS; HERSKOVITS E, 2004, IEEE T MEDICAL IMAGI, V24, P723; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Iannarilli FJ, 2003, IEEE T PATTERN ANAL, V25, P779, DOI 10.1109/TPAMI.2003.1201827; Jaeger J, 2003, Pac Symp Biocomput, P53; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krantz S.G., 1999, HDB COMPLEX VARIABLE, P118; Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861; Langley P., 1994, P AAAI FALL S REL; LI W, 2000, P CRIT ASS MICR DAT, P137; Mitchell T.M., 1997, MACHINE LEARNING; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PENG HC, 2002, P INT S BIOM IM NAN, P485; Peng H.C., 2003, P 3 IEEE INT C DAT M, P621; PENG HC, 1997, J CIRCUITS SYSTEMS, V2, P1; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Vapnik V., 1995, NATURE STAT LEARNING; Webb A. R., 1999, STAT PATTERN RECOGNI; XING EP, 2001, P 18 INT C MACH LEAR; Xiong MM, 2001, GENOME RES, V11, P1878	31	929	987	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1226	1238				13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	934HW	WOS:000229700900004	
J	Yang, ZH; Wong, WSW; Nielsen, R				Yang, ZH; Wong, WSW; Nielsen, R			Bayes empirical Bayes inference of amino acid sites under positive selection	MOLECULAR BIOLOGY AND EVOLUTION			English	Article						positive selection; codon-substitution models; Bayes empirical Bayes	CODON-SUBSTITUTION MODELS; ADAPTIVE EVOLUTION; NUCLEOTIDE SUBSTITUTION; MAXIMUM-LIKELIHOOD; CONFIDENCE-INTERVALS; MOLECULAR EVOLUTION; DARWINIAN SELECTION; STATISTICAL-METHODS; RAPID EVOLUTION; GENE FAMILY	Codon-based substitution models have been widely used to identify amino acid sites under positive selection in comparative analysis of protein-coding DNA sequences. The non synonymous-synonymous substitution rate ratio (d(N)/d(S), denoted omega) is used as a measure of selective pressure at the protein level, with omega > 1 indicating positive selection. Statistical distributions are used to model the variation in omega among sites, allowing a subset of sites to have omega > 1 while the rest of the sequence may be under purifying selection with omega < 1. An empirical Bayes (EB) approach is then used to calculate posterior probabilities that a site comes from the site class with omega > 1. Current implementations, however, use the naive EB (NEB) approach and fail to account for sampling errors in maximum likelihood estimates of model parameters, such as the proportions and omega ratios for the site classes. In small data sets lacking information, this approach may lead to unreliable posterior probability calculations. In this paper, we develop a Bayes empirical Bayes (BEB) approach to the problem, which assigns a prior to the model parameters and integrates over their uncertainties. We compare the new and old methods on real and simulated data sets. The results suggest that in small data sets the new BEB method does not generate false positives as did the old NEB approach, while in large data sets it retains the good power of the NEB approach for inferring positively selected sites.	UCL, Dept Biol, London, England; Cornell Univ, Dept Biol Stat & Computat Biol, Ithaca, NY 14853 USA; Univ Copenhagen, Ctr Bioinformat, Copenhagen, Denmark	Yang, ZH (reprint author), UCL, Dept Biol, Mortimer St, London, England.	rasmus@binf.ku.dk	Yang, Ziheng/C-1358-2008; Nielsen, Rasmus/D-4405-2009	Nielsen, Rasmus/0000-0003-0513-6591			Anisimova M, 2003, GENETICS, V164, P1229; Anisimova M, 2002, MOL BIOL EVOL, V19, P950; Anisimova M, 2001, MOL BIOL EVOL, V18, P1585; Bielawski JP, 2004, J MOL EVOL, V59, P121, DOI 10.1007/s00239-004-2597-8; Bielawski JP, 2001, MOL BIOL EVOL, V18, P523; Bishop JG, 2000, P NATL ACAD SCI USA, V97, P5322, DOI 10.1073/pnas.97.10.5322; Carlin BP, 2000, BAYES EMPIRICAL BAYE; CARLIN BP, 1990, J AM STAT ASSOC, V85, P105, DOI 10.2307/2289531; DEELY JJ, 1981, J AM STAT ASSOC, V76, P833, DOI 10.2307/2287578; Filip LC, 2004, MOL BIOL EVOL, V21, P1504, DOI 10.1093/molbev/msh111; Ford MJ, 2001, MOL BIOL EVOL, V18, P639; Forsberg R, 2003, MOL BIOL EVOL, V20, P1252, DOI 10.1093/molbev/msg149; GOLDMAN N, 1994, MOL BIOL EVOL, V11, P725; Guindon S, 2004, P NATL ACAD SCI USA, V101, P12957, DOI 10.1073/pnas.0402177101; Haydon DT, 2001, GENETICS, V157, P7; Huelsenbeck JP, 2004, J MOL EVOL, V58, P661, DOI 10.1007/s00239-004-2588-9; KOSAKOVSKY PSL, 2004, IN PRESS BIOINFORMAT; LAIRD NM, 1987, J AM STAT ASSOC, V82, P739, DOI 10.2307/2288778; Lane RP, 2004, GENOME RES, V14, P603, DOI 10.1101/gr.2117004; LI WH, 1985, MOL BIOL EVOL, V2, P150; MIYATA T, 1979, J MOL EVOL, V12, P219, DOI 10.1007/BF01732340; Mondragon-Palomino M, 2002, GENOME RES, V12, P1305, DOI 10.1101/gr.159402; MORRIS CN, 1983, J AM STAT ASSOC, V78, P47, DOI 10.2307/2287098; Moury B, 2004, MOL BIOL EVOL, V21, P1602, DOI 10.1093/molbev/msh164; MUSE SV, 1994, MOL BIOL EVOL, V11, P715; Nielsen R, 1998, GENETICS, V148, P929; Suzuki Y, 1999, MOL BIOL EVOL, V16, P1315; Suzuki Y, 2004, MOL BIOL EVOL, V21, P914, DOI 10.1093/molbev/msh098; Suzuki Y, 2002, MOL BIOL EVOL, V19, P1865; Swanson WJ, 2001, P NATL ACAD SCI USA, V98, P2509, DOI 10.1073/pnas.051605998; Takebayashi N, 2003, MOL BIOL EVOL, V20, P1778, DOI 10.1093/molbev/msg209; Twiddy SS, 2002, J GEN VIROL, V83, P1679; Wong WSW, 2004, GENETICS, V168, P1041, DOI 10.1534/genetics.104.031153; Yang ZH, 2000, GENETICS, V155, P431; Yang ZH, 1997, COMPUT APPL BIOSCI, V13, P555; Yang ZH, 2002, MOL BIOL EVOL, V19, P908; Yang ZH, 2002, MOL BIOL EVOL, V19, P49; Yang ZH, 2000, J MOL EVOL, V51, P423; Zanotto PMD, 1999, GENETICS, V153, P1077	39	767	788	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0737-4038			MOL BIOL EVOL	Mol. Biol. Evol.	APR	2005	22	4					1107	1118		10.1093/molbev/msi097		12	Biochemistry & Molecular Biology; Evolutionary Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Evolutionary Biology; Genetics & Heredity	913GK	WOS:000228139400031	
J	Bauer, E; Kohavi, R				Bauer, E; Kohavi, R			An empirical comparison of voting classification algorithms: Bagging, boosting, and variants	MACHINE LEARNING			English	Article; Proceedings Paper	AAAI 1996 Workshop on Integrating Multiple Learned Models for Improving and Scaling Machine Learning Algorithms	AUG   05, 1996	PORTLAND, OREGON			classification; boosting; Bagging; decision trees; Naive-Bayes; mean-squared error	BIAS	Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets. We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer. The purpose of the study is to improve our understanding of why and when these algorithms, which use perturbation, reweighting, and combination techniques, affect classification error. We provide a bias and variance decomposition of the error to show how different methods and variants influence these two terms. This allowed us to determine that Bagging reduced variance of unstable methods, while boosting methods (AdaBoost and Arc-x4) reduced both the bias and variance of unstable methods but increased the variance for Naive-Bayes, which was very stable. We observed that Arc-x4 behaves differently than AdaBoost if reweighting is used instead of resampling, indicating a fundamental difference. Voting variants, some of which are introduced in this paper, include: pruning versus no pruning, use of probabilistic estimates, weight perturbations (Wagging), and backfitting of data. We found that Bagging improves when probabilistic estimates in conjunction with no-pruning are used, as well as when the data was backfit. We measure tree sizes and show an interesting positive correlation between the increase in the average tree size in AdaBoost trials and its success in reducing the error. We compare the mean-squared error of voting methods to non-voting methods and show that the voting methods lead to large and significant reductions in the mean-squared errors. Practical problems that arise in implementing boosting algorithms are explored, including numerical instabilities and underflows. We use scatterplots that graphically show how AdaBoost reweights instances, emphasizing not only "hard" areas but also outliers and noise.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; Blue Martini Software, San Mateo, CA 94403 USA	Bauer, E (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.						ALI KM, 1996, LEARNING PROBABILIST; Becker B., 1997, KDD WORKSH ISS INT D; Bernardo J., 1993, BAYESIAN THEORY; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L., 1996, ARCING CLASSIFIERS; BREIMAN L, 1997, 486 U CAL STAT DEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 1994, HEURISTICS INSTABILI; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Buntine W. L., 1992, THESIS U TECHNOLOGY; Cestnik B, 1990, P EUR C ART INT, P147; CHAN P, 1996, AAAI WORKSH; Craven M.W., 1993, P 10 INT C MACH LEAR, P73; DIETTERICH TG, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P572; Dietterich T.G., 1998, NEURAL COMPUTATION; Domigos P., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Drucker H, 1996, ADV NEUR IN, V8, P479; Duda R., 1973, PATTERN CLASSIFICATI; Efron B, 1993, INTRO BOOTSTRAP; Elkan C., 1997, BOOSTING NAIVE BAYES; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; Freund Y., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Good I, 1965, ESTIMATION PROBABILI; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Iba W., 1992, P 9 INT C MACH LEARN, P233; Kohavi R, 1997, 9 EUR C MACH LEARN, P78; Kohavi R., 1995, 1 INT C KNOWL DISC D, P192; KOHAVI R, 1995, STANCSTR951560; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; Kohavi R., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; Kohavi Ron, 1997, MACH LEARN, P161; Kong E., 1995, MACH LEARN, P313; Kwok SW, 1990, UNCERTAINTY ARTIFICI, V4, P327; LANGLEY P, 1997, COMPUTATIONAL LEARNI, V4; Langley P., 1992, P 10 NAT C ART INT, P223; OATES T, 1997, MACH LEARN, P254; Oliver J. J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; PAZZANI M, 1994, MACHINE LEARNING; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1994, COMPUTATIONAL LEARNI, V1, P445; RIDGEWAY G, 1998, P 4 INT C KNOWL DISC; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schaffer C., 1994, MACH LEARN, P259; Schapire R. E., 1997, MACH LEARN, p322{330; Wolpert D. H., 1994, MATH GEN; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	55	740	770	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JUL	1999	36	1-2					105	139		10.1023/A:1007515423169		35	Computer Science, Artificial Intelligence	Computer Science	215PC	WOS:000081389200006	
J	Chawla, NV; Bowyer, KW; Hall, LO; Kegelmeyer, WP				Chawla, NV; Bowyer, KW; Hall, LO; Kegelmeyer, WP			SMOTE: Synthetic minority over-sampling technique	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article								An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of normal examples with only a small percentage of abnormal or interesting examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitvity of a classier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.	Univ S Florida, Dept Comp Sci & Engn, ENB 118, Tampa, FL 33620 USA; Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA; Sandia Natl Labs, Biosyst Res Dept, Livermore, CA 94551 USA	Chawla, NV (reprint author), Univ S Florida, Dept Comp Sci & Engn, ENB 118, 4202 E Fowler Ave, Tampa, FL 33620 USA.	CHAWLA@CSEE.USF.EDU; KWB@CSE.NDU.EDU; HALL@CSEE.USF.EDU; WPK@CALIFORNIA.SANDIA.GOV					Blake C. L., 1998, UCI REPOSITORY MACHI; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; CHAWLA N, 2000, INT C KNOWL BAS COMP, P46; CHAWLA N, 1999, ISL9901 U S FLOR COM; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cohen W.W., 1996, P 19 ANN INT ACM SIG, P307, DOI 10.1145/243199.243278; COHEN WW, 1995, P 5 INT WORKSH IND L, P3; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; DEROUIN E, 1991, INTELLIGENT ENG SYST, P135; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; Duda R.O., 2001, PATTERN CLASSIFICATI; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Ezawa K., 1996, P 13 INT C MACH LEAR, P139; FAWCETT T., 1996, P 2 INT C KNOWL DISC, P8; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P535, DOI 10.1109/34.589216; HALL LH, 1991, J CHEM INF COMP SCI, V31, P76, DOI 10.1021/ci00001a012; Japkowicz N., 2000, P 2000 INT C ART INT; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, P 14 INT C MACH LEAR, P179; LEE S, 2000, COMPUTATIONAL STAT D, V34; Lewis D., 1994, P 11 INT C MACH LEAR, P148; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Ling CX, 1998, P 4 INT C KNOWL DISC; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; O'Rourke J, 1998, COMPUTATIONAL GEOMET; Pazzani M., 1994, P 11 INT C MACH LEAR; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1998, P 15 INT C MACH LEAR, P445; QUINLAN J, 1992, C4 5 PROGRAMA MACHIN; Solberg AHS, 1996, INT GEOSCI REMOTE SE, P1484; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TURNEY P, 1996, COST SENSITIVE BIBLI; VANRIJSBERGEN CJ, 1981, INFORM PROCESS MANAG, V17, P77, DOI 10.1016/0306-4573(81)90029-7; Woods K. S., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000698	37	738	830	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757			J ARTIF INTELL RES	J. Artif. Intell. Res.		2002	16						321	357				37	Computer Science, Artificial Intelligence	Computer Science	559KL	WOS:000176025300001	
J	Nigam, K; McCallum, AK; Thrun, S; Mitchell, T				Nigam, K; McCallum, AK; Thrun, S; Mitchell, T			Text classification from labeled and unlabeled documents using EM	MACHINE LEARNING			English	Article						text classification; Expectation-Maximization; integrating supervised and unsupervised learning; combining labeled and unlabeled data; Bayesian learning	SAMPLES	This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents. This is important because in many text classification problems obtaining training labels is expensive, while large quantities of unlabeled documents are readily available. We introduce an algorithm for learning from labeled and unlabeled documents based on the combination of Expectation-Maximization (EM) and a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents. It then trains a new classifier using the labels for all the documents, and iterates to convergence. This basic EM procedure works well when the data conform to the generative assumptions of the model. However these assumptions are often violated in practice, and poor performance can result. We present two extensions to the algorithm that improve classification accuracy under these conditions: (1) a weighting factor to modulate the contribution of the unlabeled data, and (2) the use of multiple mixture components per class. Experimental results, obtained using text from three different real-world tasks, show that the use of unlabeled data reduces classification error by up to 30%.	Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; Just Res, Pittsburgh, PA 15213 USA	Nigam, K (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.						Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; CASTELLI V, 1995, PATTERN RECOGN LETT, V16, P105, DOI 10.1016/0167-8655(94)00074-D; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Cohen W. W., 1996, SIGIR Forum; Cover T. M., 1991, ELEMENTS INFORMATION; Craven M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Dagan I., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Ghahramani Z., 1994, ADV NEURAL INFORMATI, V6, P120; JAAKKOLA TS, 1998, LEARNING GRAPHICAL M; Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings; Joachims T., 1997, P 14 INT C MACH LEAR, P143; Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Larkey L. S., 1996, SIGIR Forum; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings; Lewis D. D., 1995, SIGIR Forum, V29; LEWIS DD, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P37; Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval; Lewis DD, 1997, INFORM PROCESS MANAG, V33, P209, DOI 10.1016/S0306-4573(96)00063-5; Li H., 1997, P ACL 97, P39; Liere R., 1997, P 14 C AM ASS ART IN, P591; McCallum A., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); McCallum A, 1998, AAAI 98 WORKSH LEARN; MCCALLUM AK, 1998, MACH LEARN, P350; McLachlan G., 1997, EM ALGORITHM EXTENSI; McLachlan G., 1988, MIXTURE MODELS; Miller DJ, 1997, ADV NEUR IN, V9, P571; Mitchell T.M., 1997, MACHINE LEARNING; NG AY, 1997, MACH LEARN, P245; Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; ROCCHIO J., 1971, SMART RETRIEVAL SYST; Sahami M., 1997, P 14 INT C MACH LEAR, P170; Sahami M., 1998, AAAI 98 WORKSH LEARN; SALTON G, 1991, SCIENCE, V253, P974, DOI 10.1126/science.253.5023.974; SCHUURMANS D, 1997, P 14 NAT C ART INT A, P552; SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897; SHAVLIK J, 1998, AAAI 98 WORKSH LEARN; STOLCKE A, 1994, TR94003 ICSI U CAL B; YANG Y, 1994, SIGIR 94 P 17 ANN IN, P13; Yang Y, 1999, J INFORMATION RETRIE, V1, P69; Yang Y., 1997, MACH LEARN, P412	47	636	680	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	MAY	2000	39	2-3					103	134		10.1023/A:1007692713085		32	Computer Science, Artificial Intelligence	Computer Science	295HF	WOS:000085960100002	
J	Brudey, K; Driscoll, JR; Rigouts, L; Prodinger, WM; Gori, A; Al-Hajoj, SA; Allix, C; Aristimuno, L; Arora, J; Baumanis, V; Binder, L; Cafrune, P; Cataldi, A; Cheong, S; Diel, R; Ellermeier, C; Evans, JT; Fauville-Dufaux, M; Ferdinand, S; Garcia de Viedma, D; Garzelli, C; Gazzola, L; Gomes, HM; Guttierez, MC; Hawkey, PM; van Helden, PD; Kadival, GV; Kreiswirth, BN; Kremer, K; Kubin, M; Kulkarni, SP; Liens, B; Lillebaek, T; Ly, HM; Martin, C; Martin, C; Mokrousov, I; Narvskaia, O; Ngeow, YF; Naumann, L; Niemann, S; Parwati, I; Rahim, Z; Rasolofo-Razanamparany, V; Rasolonavalona, T; Rossetti, ML; Rusch-Gerdes, S; Sajduda, A; Samper, S; Shemyakin, IG; Singh, UB; Somoskovi, A; Skuce, RA; van Soolingen, D; Streicher, EM; Suffys, PN; Tortoli, E; Tracevska, T; Vincent, V; Victor, TC; Warren, RM; Yap, SF; Zaman, K; Portaels, F; Rastogi, N; Sola, C				Brudey, Karine; Driscoll, Jeffrey R.; Rigouts, Leen; Prodinger, Wolfgang M.; Gori, Andrea; Al-Hajoj, Sahal A.; Allix, Caroline; Aristimuno, Liselotte; Arora, Jyoti; Baumanis, Viesturs; Binder, Lothar; Cafrune, Patricia; Cataldi, Angel; Cheong, Soonfatt; Diel, Roland; Ellermeier, Christopher; Evans, Jason T.; Fauville-Dufaux, Maryse; Ferdinand, Severine; Garcia de Viedma, Dario; Garzelli, Carlo; Gazzola, Lidia; Gomes, Harrison M.; Guttierez, M. Cristina; Hawkey, Peter M.; van Helden, Paul D.; Kadival, Gurujaj V.; Kreiswirth, Barry N.; Kremer, Kristin; Kubin, Milan; Kulkarni, Savita P.; Liens, Benjamin; Lillebaek, Troels; Ly, Ho Minh; Martin, Carlos; Martin, Christian; Mokrousov, Igor; Narvskaia, Olga; Ngeow, Yun Fong; Naumann, Ludmilla; Niemann, Stefan; Parwati, Ida; Rahim, Zeaur; Rasolofo-Razanamparany, Voahangy; Rasolonavalona, Tiana; Rossetti, M. Lucia; Ruesch-Gerdes, Sabine; Sajduda, Anna; Samper, Sofia; Shemyakin, Igor G.; Singh, Urvashi B.; Somoskovi, Akos; Skuce, Robin A.; van Soolingen, Dick; Streicher, Elisabeth M.; Suffys, Philip N.; Tortoli, Enrico; Tracevska, Tatjana; Vincent, Veronique; Victor, Tommie C.; Warren, Robin M.; Yap, Sook Fan; Zaman, Khadiza; Portaels, Francoise; Rastogi, Nalin; Sola, Christophe			Mycobacterium tuberculosis complex genetic diversity: mining the fourth international spoligotyping database (SpoIDB4) for classification, population genetics and epidemiology	BMC MICROBIOLOGY			English	Article							DIRECT REPEAT LOCUS; TANDEM DNA REPEATS; VARIABLE-NUMBER; NUCLEOTIDE POLYMORPHISMS; SPACER OLIGONUCLEOTIDES; MOLECULAR EPIDEMIOLOGY; PULMONARY TUBERCULOSIS; STRAIN DIFFERENTIATION; GLOBAL DISTRIBUTION; COPY NUMBERS	Background: The Direct Repeat locus of the Mycobacterium tuberculosis complex (MTC) is a member of the CRISPR (Clustered regularly interspaced short palindromic repeats) sequences family. Spoligotyping is the widely used PCR-based reverse-hybridization blotting technique that assays the genetic diversity of this locus and is useful both for clinical laboratory, molecular epidemiology, evolutionary and population genetics. It is easy, robust, cheap, and produces highly diverse portable numerical results, as the result of the combination of (1) Unique Events Polymorphism (UEP) ( 2) Insertion-Sequence-mediated genetic recombination. Genetic convergence, although rare, was also previously demonstrated. Three previous international spoligotype databases had partly revealed the global and local geographical structures of MTC bacilli populations, however, there was a need for the release of a new, more representative and extended, international spoligotyping database. Results: The fourth international spoligotyping database, SpoIDB4, describes 1939 shared-types (STs) representative of a total of 39,295 strains from 122 countries, which are tentatively classified into 62 clades/lineages using a mixed expert-based and bioinformatical approach. The SpoIDB4 update adds 26 new potentially phylogeographically-specific MTC genotype families. It provides a clearer picture of the current MTC genomes diversity as well as on the relationships between the genetic attributes investigated (spoligotypes) and the infra-species classification and evolutionary history of the species. Indeed, an independent Naive-Bayes mixture-model analysis has validated main of the previous supervised SpoIDB3 classification results, confirming the usefulness of both supervised and unsupervised models as an approach to understand MTC population structure. Updated results on the epidemiological status of spoligotypes, as well as genetic prevalence maps on six main lineages are also shown. Our results suggests the existence of fine geographical genetic clines within MTC populations, that could mirror the passed and present Homo sapiens sapiens demographical and mycobacterial co-evolutionary history whose structure could be further reconstructed and modelled, thereby providing a large-scale conceptual framework of the global TB Epidemiologic Network. Conclusion: Our results broaden the knowledge of the global phylogeography of the MTC complex. SpoIDB4 should be a very useful tool to better define the identity of a given MTC clinical isolate, and to better analyze the links between its current spreading and previous evolutionary history. The building and mining of extended MTC polymorphic genetic databases is in progress.	New York State Dept Hlth, Wadsworth Ctr, Albany, NY USA; Inst Trop Med Prince Leopold, Mycobacteriol Unit, B-2000 Antwerp, Belgium; Univ Innsbruck, Dept Hyg Microbiol & Social Med, A-6020 Innsbruck, Austria; Inst Infect Dis, Dept Infect Dis, Milan, Italy; King Faisal Specialist Hosp & Res Ctr, Dept Comparat Med, Riyadh 11211, Saudi Arabia; Inst Pasteur, Lab TB, Brussels, Belgium; Univ Centrooccidental Lisandro Alvarado, Barquisimeto, Venezuela; Univ Zaragoza, Zaragoza, Spain; All India Inst Med Sci, New Delhi, India; Biomed Res & Study Ctr, Riga, Latvia; Univ Fed Rio Grande do Sul, BR-90046900 Porto Alegre, RS, Brazil; INTA, Inst Biotecnol, Castelar, Argentina; Univ Malaya, Fac Med, Sch Publ Hlth, Dept Med Microbiol & Pathol, Kuala Lumpur, Malaysia; Univ Dusseldorf, D-4000 Dusseldorf, Germany; Univ Regensburg, Dept Internal Med 2, D-8400 Regensburg, Germany; Birmingham Heartlands Hosp, Publ Hlth Lab, Birmingham B9 5ST, W Midlands, England; Hosp Gen Gregorio Maranon, Dept Clin Microbiol & Infect Dis, E-28007 Madrid, Spain; Univ Pisa, Dept Expt Pathol Med Biotechnol Infect & Epidemio, Pisa, Italy; Inst Oswaldo Cruz, Dept Mycobacteriosis, Lab Mol Biol Appl Mycobacteria, BR-20001 Rio De Janeiro, Brazil; Inst Pasteur, Ctr Natl Reference Mycobacteries, Paris, France; Univ Stellenbosch, MRC, Ctr Cellular & Mol Biol, Dept Biochem Med, ZA-7505 Tygerberg, South Africa; Bhabha Atom Res Ctr, Lab Nucl Med Sect, Isotope Grp, Bombay 400012, Maharashtra, India; Publ Hlth Res Inst, Newark, NJ USA; Natl Inst Publ Hlth & Environm, Mycobacteria Reference Unit, Diagnost Lab Infect Dis & Perinatal Screening, NL-3720 BA Bilthoven, Netherlands; Municipal Inst Hyg, Prague, Czech Republic; Statens Serum Inst, Int Ref Lab Mycobacteriol, DK-2300 Copenhagen, Denmark; Inst Hyg & Epidemiol, Hanoi, Vietnam; Univ Zaragoza, Zaragoza, Spain; CHU Dupuytren, Lab Bacteriovirol Hyg, Limoges, France; Inst Pasteur St Petersbourg, St Petersburg, Russia; Bavarian Hlth & Food Safety Author, Oberschleissheim, Germany; Forschungszentrum, Natl Reference Cr Mycobacteria, Borstel, Germany; Padjadjaran State Univ, Dr Hasan Sadikin Hosp, Dept Clin Pathol, Bandung, Indonesia; Int Ctr Diarrhoeal Res, TB Lab, Dhaka 1000, Bangladesh; Inst Pasteur Madagascar, Taranarive, Madagascar; Univ Lodz, Dept Genet Microorganisms, PL-90131 Lodz, Poland; Univ Zaragoza, Hosp Miguel Servet, Microbiol Serv, Zaragoza, Spain; State Res Ctr Appl Microbiol, Obolensk, Russia; Semmelweis Univ, Sch Med, Dept Resp Med, H-1085 Budapest, Hungary; Dept Agr No Ireland, Vet Sci Div, Belfast BT9 5PX, Antrim, North Ireland; Osped Careggi, Ctr Reg Riferimento Micobatteri, Lab Microbiol & Virol, Florence, Italy			Martin, Carlos/A-7283-2008; Gutierrez, Cristina/B-5597-2012; Niemann, Stefan/C-9327-2011; suffys, philip/E-3009-2013				Aranaz A, 1999, INT J SYST BACTERIOL, V49, P1263; AVISE JC, 1987, ANNU REV ECOL SYST, V18, P489, DOI 10.1146/annurev.ecolsys.18.1.489; Baker L, 2004, EMERG INFECT DIS, V10, P1568; Berkhin P., 2002, SURVEY CLUSTERING DA; Blackwood KS, 2003, BMC INFECT DIS, V3, DOI 10.1186/1471-2334-3-18; Brudey K, 2004, J CLIN MICROBIOL, V42, P5053, DOI 10.1128/JCM.42.11.5053-5057.2004; Cruciani F, 2002, AM J HUM GENET, V70, P1197, DOI 10.1086/340257; Dale JW, 2003, J BACTERIOL, V185, P2555, DOI 10.1128/JB.185.8.2555-2562.2003; Dale JW, 2001, INT J TUBERC LUNG D, V5, P216; Douglas JT, 2003, J CLIN MICROBIOL, V41, P2723, DOI 10.1128/JCM.41.6.2723-2726.2003; Duchene V, 2004, INFECT GENET EVOL, V4, P5, DOI 10.1016/j.meegid.2003.09.001; Easterbrook PJ, 2004, J CLIN MICROBIOL, V42, P4536, DOI 10.1128/JCM.42.10.4536-4544.2004; Enright AJ, 2001, BIOINFORMATICS, V17, P853, DOI 10.1093/bioinformatics/17.9.853; Ewen KR, 2000, AM J HUM GENET, V67, P727, DOI 10.1086/303048; Fabre M, 2004, J CLIN MICROBIOL, V42, P3248, DOI 10.1128/JCM.42.7.3248-3255.2004; Farnia P, 2004, J INFECTION, V49, P94, DOI 10.1016/j.jinf.2003.11.015; Feil EJ, 2000, GENETICS, V154, P1439; Filliol I, 2003, J CLIN MICROBIOL, V41, P1963, DOI 10.1128/JCM.41.5.1963.1970.2003; Filliol I, 2002, EMERG INFECT DIS, V8, P1347; FILLIOL I, 2006, IN PRESS J BACTERIOL; Frothingham R, 1998, MICROBIOL-UK, V144, P1189; Garcia de Viedma D., 2005, J CLIN MICROBIOL, V43, P1797, DOI DOI 10.1128/JCM.43.4.1797-1806.2005; Gascoyne-Binzi DM, 2002, INT J TUBERC LUNG D, V6, P492; Gibson A, 2005, APPL ENVIRON MICROB, V71, P8207, DOI 10.1128/AEM.71.12.8207-8213.2005; Glynn JR, 2002, EMERG INFECT DIS, V8, P843; Gori A, 2005, EMERG INFECT DIS, V11, P1242; GROENEN PMA, 1993, MOL MICROBIOL, V10, P1057, DOI 10.1111/j.1365-2958.1993.tb00976.x; Gutacker MM, 2002, GENETICS, V162, P1533; Gutacker MM, 2006, J INFECT DIS, V193, P121, DOI 10.1086/498574; Gutierrez MC, 2005, PLOS PATHOG, V1, P55, DOI 10.1371/journal.ppat.0010005; HERMANS PWM, 1995, J INFECT DIS, V171, P1504; Hirsh AE, 2004, P NATL ACAD SCI USA, V101, P4871, DOI 10.1073/pnas.0305627101; HOPCROFT J, 2004, P NATL ACAD SCI U S1, V101, P5242; Hopcroft J, 2004, P NATL ACAD SCI USA, V101, P5249, DOI 10.1073/pnas.0307750100; JANSEN R, 2002, GENOMICS, V6, P23; Kamerbeek J, 1997, J CLIN MICROBIOL, V35, P907; Kaufmann SHE, 2005, TRENDS MICROBIOL, V13, P469, DOI 10.1016/j.tim.2005.08.003; Kempf MC, 2005, J CLIN MICROBIOL, V43, P870, DOI 10.1128/JCM.43.2.870-878.2005; Kinsella RJ, 2003, P NATL ACAD SCI USA, V100, P10320, DOI 10.1073/pnas.1737230100; Klovdahl AS, 2001, SOC SCI MED, V52, P681, DOI 10.1016/S0277-9536(00)00170-2; Knowles LL, 2004, J EVOLUTION BIOL, V17, P1, DOI 10.1046/j.1420-9101.2003.00644.x; Kovalev SY, 2005, INT J TUBERC LUNG D, V9, P746; Kulkarni S, 2005, RES MICROBIOL, V156, P588, DOI 10.1016/j.resmic.2005.01.005; Lari N, 2005, J CLIN MICROBIOL, V43, P1617, DOI 10.1128/JCM.43.4.1617-1624.2005; LIENS B, 2005, 26 ANN C EUR SOC MYC, P65; Lindstedt BA, 2005, ELECTROPHORESIS, V26, P2567, DOI 10.1002/elps.200500096; Malik AN, 2005, LANCET INFECT DIS, V5, P174, DOI 10.1016/S1473-3099(05)01310-1; McHugh TD, 2005, TUBERCULOSIS, V85, P127, DOI 10.1016/j.tube.2004.06.002; Mojica FJM, 2005, J MOL EVOL, V60, P174, DOI 10.1007/s00239-004-0046-3; Mokrousov I, 2005, GENOME RES, V15, P1357, DOI 10.1101/gr.3840605; Mostowy S, 2005, CLIN CHEST MED, V26, P207, DOI 10.1016/j.ccm.2005.02.004; Namwat W, 1998, INT J TUBERC LUNG D, V2, P153; Niobe-Eyangoh SN, 2003, J CLIN MICROBIOL, V41, P2547, DOI 10.1128/JCM.41.6.2547-2553.2003; Ohata Ritsuko, 2004, Kekkaku, V79, P47; Phyu S, 2003, J CLIN MICROBIOL, V41, P4907, DOI 10.1128/JCM.41.10.4907-4908.2003; Pourcel C, 2005, MICROBIOL-SGM, V151, P653, DOI 10.1099/mic.0.27437-0; PRITCHARD JK, 2005, GENETICS, V155, P948; Qian LS, 1999, J CLIN MICROBIOL, V37, P471; Quitugua TN, 2002, J CLIN MICROBIOL, V40, P2716, DOI 10.1128/JCM.40.8.2716-2724.2002; Scott AN, 2005, J CLIN MICROBIOL, V43, P89, DOI 10.1128/JCM.43.1.89-94.2005; Sebban M, 2002, BIOINFORMATICS, V18, P235, DOI 10.1093/bioinformatics/18.2.235; SHAMPUTA IC, 2003, 3 M ACT PROJ NEW GEN, P22; Singh UB, 2004, EMERG INFECT DIS, V10, P1138; SMITH N, 2003, P NATL ACAD SCI US; Soini H, 2001, J CLIN MICROBIOL, V39, P217, DOI 10.1128/JCM.39.1.217-221.2001; Soini H, 2000, J CLIN MICROBIOL, V38, P669; Sola C, 2001, EMERG INFECT DIS, V7, P390; SOLA C, 2006, MOL EPIDEMILLOGY POP, P23; SOLA C, 2005, 26 ANN C EUR SOC MYC, P91; Sola C, 2001, J MOL EVOL, V53, P680, DOI 10.1007/s002390010255; Sola C, 1999, EMERG INFECT DIS, V5, P404; Sola C, 2001, J CLIN MICROBIOL, V39, P1559, DOI 10.1128/JCM.39.4.1559-1565.2001; Sreevatsan S, 1997, P NATL ACAD SCI USA, V94, P9869, DOI 10.1073/pnas.94.18.9869; Sun YJ, 2004, J CLIN MICROBIOL, V42, P1986, DOI 10.1128/JCM.42.5.1986-1993.2004; Supply P, 2003, MOL MICROBIOL, V47, P529, DOI 10.1046/j.1365-2958.2003.03315.x; Supply P, 2000, MOL MICROBIOL, V36, P762, DOI 10.1046/j.1365-2958.2000.01905.x; Supply P, 2001, J CLIN MICROBIOL, V39, P3563, DOI 10.1128/JCM.39.10.3563-3571.2001; van Belkum A, 2001, CLIN MICROBIOL REV, V14, P547, DOI 10.1128/CMR.14.3.547-560.2001; van der Zanden AGM, 2002, J CLIN MICROBIOL, V40, P4628, DOI 10.1128/JCM.40.12.4625-4639.2002; van Embden JDA, 2000, J BACTERIOL, V182, P2393, DOI 10.1128/JB.182.9.2393-2401.2000; VANSOOLINGEN D, 1995, J CLIN MICROBIOL, V33, P3234; van Soolingen D, 1998, J CLIN MICROBIOL, V36, P1840; Vijaya-Bhanu N, 2002, TUBERCULOSIS, V82, P105; VITOL I, 2005, RECOMB 2005; Warren RM, 2004, J CLIN MICROBIOL, V42, P5774, DOI 10.1128/JCM.42.12.5774-5782.2004; Warren RM, 2002, J CLIN MICROBIOL, V40, P4457, DOI 10.1128/JCM.40.12.4457-4465.2002; Zozio T, 2005, BMC MICROBIOL, V5, DOI 10.1186/1471-2180-5-44	87	430	449	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2180			BMC MICROBIOL	BMC Microbiol.	MAR 23	2006	6								23	10.1186/1471-2180-6-23		17	Microbiology	Microbiology	045JA	WOS:000237737200001	
J	Pond, SLK; Frost, SDW				Pond, SLK; Frost, SDW			Not so different after all: A comparison of methods for detecting amino acid sites under selection	MOLECULAR BIOLOGY AND EVOLUTION			English	Article						positive and negative selection; codon substitution models; substitution rates; parallel algorithms	MAXIMUM-LIKELIHOOD-ESTIMATION; POSITIVELY SELECTED SITES; MUTATION-RATE VARIES; NUCLEOTIDE SUBSTITUTION; DNA POLYMORPHISM; NONSYNONYMOUS SUBSTITUTION; THALASSIOSIRA-WEISSFLOGII; TRANSMISSION HISTORY; STATISTICAL-METHODS; ADAPTIVE EVOLUTION	We consider three approaches for estimating the rates of nonsynonymous and synonymous changes at each site in a sequence alignment in order to identify sites under positive or negative selection: (1) a suite of fast likelihood-based "counting methods" that employ either a single most likely ancestral reconstruction, weighting across all possible ancestral reconstructions, or sampling from ancestral reconstructions; (2) a random effects likelihood (REL) approach, which models variation in nonsynonymous and synonymous rates across sites according to a predefined distribution, with the selection pressure at an individual site inferred using an empirical Bayes approach; and (3) a fixed effects likelihood (FEL) method that directly estimates nonsynonymous and synonymous substitution rates at each site. All three methods incorporate flexible models of nucleotide substitution bias and variation in both nonsynonymous and synonymous substitution rates across sites, facilitating the comparison between the methods. We demonstrate that the results obtained using these approaches show broad agreement in levels of Type I and Type 11 error and in estimates of substitution rates. Counting methods are well suited for large alignments, for which there is high power to detect positive and negative selection, but appear to underestimate the substitution rate. A REL approach, which is more computationally intensive than counting methods, has higher power than counting methods to detect selection in data sets of intermediate size but may suffer from higher rates of false positives for small data sets. A FEL approach appears to capture the pattern of rate variation better than counting methods or random effects models, does not suffer from as many false positives as random effects models for data sets comprising few sequences, and can be efficiently parallelized. Our results suggest that previously reported differences between results obtained by counting methods and random effects models arise due to a combination of the conservative nature of counting-based methods, the failure of current random effects models to allow for variation in synonymous substitution rates, and the naive application of random effects models to extremely sparse data sets. We demonstrate our methods on sequence data from the human immunodeficiency virus type 1 env and pol genes and simulated alignments.	Univ Calif San Diego, Antiviral Res Ctr, San Diego, CA 92103 USA	Frost, SDW (reprint author), Univ Calif San Diego, Antiviral Res Ctr, San Diego, CA 92103 USA.	sdfrost@ucsd.edu	Frost, Simon/F-3648-2010				Anisimova M, 2002, MOL BIOL EVOL, V19, P950; Anisimova M, 2001, MOL BIOL EVOL, V18, P1585; Comeron JM, 1995, J MOL EVOL, V41, P1152; Deng HW, 1996, GENETICS, V144, P1271; DURRETT R, 2005, IN PRESS MOL BIOL EV; Fay JC, 2000, GENETICS, V155, P1405; FELSENSTEIN J, 1981, J MOL EVOL, V17, P368, DOI 10.1007/BF01734359; FITZGIBBON JE, 1991, AIDS RES HUM RETROV, V7, P265, DOI 10.1089/aid.1991.7.265; Fu YX, 1997, GENETICS, V147, P915; FU YX, 1993, GENETICS, V134, P1261; FU YX, 1993, GENETICS, V133, P693; GOLDMAN N, 1994, MOL BIOL EVOL, V11, P725; GREEN DM, 1966, SIGNAL DETECTION THE; Huelsenbeck JP, 2004, MOL BIOL EVOL, V21, P1123, DOI 10.1093/molbev/msh123; Huelsenbeck JP, 2004, J MOL EVOL, V58, P661, DOI 10.1007/s00239-004-2588-9; Pond SLK, 2005, BIOINFORMATICS, V21, P676, DOI 10.1093/bioinformatics/bti079; LANAVE C, 1984, J MOL EVOL, V20, P86, DOI 10.1007/BF02101990; LARDER BA, 1989, SCIENCE, V246, P1155, DOI 10.1126/science.2479983; Leitner T, 1999, P NATL ACAD SCI USA, V96, P10752, DOI 10.1073/pnas.96.19.10752; Leitner T, 1997, J VIROL, V71, P4761; LI WH, 1985, MOL BIOL EVOL, V2, P150; LI WH, 1993, J MOL EVOL, V36, P96, DOI 10.1007/BF02407308; Misawa K, 1997, GENETICS, V147, P1959; Muse SV, 1999, EVOLUTION OF HIV, P122; MUSE SV, 1994, MOL BIOL EVOL, V11, P715; NEI M, 1986, MOL BIOL EVOL, V3, P418; Nielsen R, 1997, SYST BIOL, V46, P346, DOI 10.2307/2413628; Nielsen R, 1998, GENETICS, V148, P929; Nielsen R., 2002, PAC S BIOCOMPUT, V7, P576; Nielsen R, 2002, SYST BIOL, V51, P729, DOI 10.1080/10635150290102393; Pagel M, 1999, SYST BIOL, V48, P612, DOI 10.1080/106351599260184; PAMILO P, 1993, MOL BIOL EVOL, V10, P271; POND SK, 2005, IN PRESS MOL BIOL EV; Pond SL, 2005, BIOINFORMATICS; Pond SLK, 2005, MOL BIOL EVOL, V22, P223, DOI 10.1093/molbev/msi009; Pupko T, 2000, MOL BIOL EVOL, V17, P890; RODRIGUEZ F, 1990, J THEOR BIOL, V142, P485, DOI 10.1016/S0022-5193(05)80104-3; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; SANKOFF D, 1975, SIAM J APPL MATH, V28, P35, DOI 10.1137/0128004; Sorhannus U, 2003, MOL BIOL EVOL, V20, P1326, DOI 10.1093/molbev/msg145; Suzuki Y, 1999, MOL BIOL EVOL, V16, P1315; Suzuki Y, 2004, MOL BIOL EVOL, V21, P914, DOI 10.1093/molbev/msh098; Suzuki Y, 2004, J MOL EVOL, V59, P11, DOI 10.1007/s00239-004-2599-6; Suzuki Y, 2001, MOL BIOL EVOL, V18, P2179; Suzuki Y, 2002, MOL BIOL EVOL, V19, P1865; Tajima F, 1996, GENETICS, V143, P1457; TAJIMA F, 1989, GENETICS, V123, P585; TAMURA K, 1993, MOL BIOL EVOL, V10, P512; Tavare S., 1986, LECTURES MATH LIFE S, P57; Winters MA, 2001, ANTIMICROB AGENTS CH, V45, P2276, DOI 10.1128/AAC.45.8.2276-2279.2001; Wong WSW, 2004, GENETICS, V168, P1041, DOI 10.1534/genetics.104.031153; Yang T, 2002, BIOMOL ENG, V19, P1, DOI 10.1016/S1389-0344(02)00002-3; Yang ZH, 2000, GENETICS, V155, P431; Yang ZH, 2000, MOL BIOL EVOL, V17, P32; Yang ZH, 1997, COMPUT APPL BIOSCI, V13, P555; Yang ZH, 2000, J MOL EVOL, V51, P423; YANG ZH, 1995, GENETICS, V141, P1641	57	394	397	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0737-4038			MOL BIOL EVOL	Mol. Biol. Evol.	MAY	2005	22	5					1208	1222		10.1093/molbev/msi105		15	Biochemistry & Molecular Biology; Evolutionary Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Evolutionary Biology; Genetics & Heredity	920OO	WOS:000228700200006	
J	Wu, XD; Kumar, V; Quinlan, JR; Ghosh, J; Yang, Q; Motoda, H; McLachlan, GJ; Ng, A; Liu, B; Yu, PS; Zhou, ZH; Steinbach, M; Hand, DJ; Steinberg, D				Wu, Xindong; Kumar, Vipin; Quinlan, J. Ross; Ghosh, Joydeep; Yang, Qiang; Motoda, Hiroshi; McLachlan, Geoffrey J.; Ng, Angus; Liu, Bing; Yu, Philip S.; Zhou, Zhi-Hua; Steinbach, Michael; Hand, David J.; Steinberg, Dan			Top 10 algorithms in data mining	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article							NEAREST NEIGHBOR RULES; ASSOCIATION RULES; CLASSIFICATION; QUANTIZATION; CLASSIFIERS; CONFIDENCE; REGRESSION; FRAMEWORK; PATTERNS; TREES	This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development.	[Wu, Xindong] Univ Vermont, Dept Comp Sci, Burlington, VT USA; [Kumar, Vipin] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN USA; [Quinlan, J. Ross] Rulequest Res pty Ltd, St Ives, NSW, Australia; [Ghosh, Joydeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Yang, Qiang] Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Peoples R China; [Motoda, Hiroshi] Osaka Univ, AFORS AOARD, Tokyo 10600326, Japan; [McLachlan, Geoffrey J.] Univ Queensland, Dept Math, Brisbane, Qld, Australia; [Ng, Angus] Griffith Univ, Sch Med, Brisbane, Qld, Australia; [Liu, Bing] Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA; [Yu, Philip S.] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA; [Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210008, Peoples R China; [Steinbach, Michael] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; [Hand, David J.] Univ London Imperial Coll Sci & Technol, Dept Math, London, England; [Steinberg, Dan] Maxwell Labs Inc, Salford Syst, San Diego, CA 92123 USA	Wu, XD (reprint author), Univ Vermont, Dept Comp Sci, Burlington, VT USA.	xwu@cs.uvm.edu; kumar@cs.umn.edu; quinlan@rulequest.com; ghosh@ece.utexas.edu; qyang@cs.ust.hk; motoda@ar.sanken.osaka-u.ac.jp; gjm@maths.uq.edu.au; psyu@us.ibm.com; steinbac@cs.umn.edu; d.j.hand@imperial.ac.uk; dsx@salford-systems.com	Adams, Niall/D-2472-2010; McLachlan, Geoffrey/A-1491-2008; Liu, Bing/C-5758-2014				Agrawal R., 1994, P 20 INT C VER LARG, P487; Ahmed S, 2006, KNOWL INF SYST, V10, P315, DOI 10.1007/s10115-006-0010-1; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bloch DA, 2002, J COMPUT GRAPH STAT, V11, P263, DOI 10.1198/106186002760180509; Bonchi F, 2006, KNOWL INF SYST, V9, P180, DOI 10.1007/s10115-005-0201-1; BREIMAN L, 1968, CLASSICS MATH; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Brin S., 1998, COMPUTER NETWORKS IS, V30, P1; Chen JR, 2007, KNOWL INF SYST, V11, P369, DOI 10.1007/s10115-006-0042-6; CHEUNG DW, 1996, P ACM SIGMOD INT C D, P13; Chi Y, 2006, KNOWL INF SYST, V10, P265, DOI 10.1007/s10115-006-0003-0; COST S, 1993, MACH LEARN, V10; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NN PATTERN CLASSIFIC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devroye L., 1996, PROBABILISTIC THEORY; Dhillon I. S., 2004, KDD, P551; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Faust Katherine, 1994, SOCIAL NETWORK ANAL; Fix E., 1951, 4 USAF SCH AV MED; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Golub GH, 1983, MATRIX COMPUTATIONS; Gondek D, 2007, KNOWL INF SYST, V12, P1, DOI 10.1007/s10115-006-0009-7; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Han E.H., 1999, THESIS U MINNESOTA; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Herbrich R, 2000, ADV NEUR IN, P115; Hu TM, 2006, KNOWL INF SYST, V10, P505, DOI 10.1007/s10115-006-0017-7; Hunt E.B, 1966, EXPT INDUCTION; Inokuchi A, 2005, FUND INFORM, V66, P53; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Jin RM, 2006, KNOWL INF SYST, V10, P17, DOI 10.1007/s10115-005-0210-0; Kobayashi M, 2006, KNOWL INF SYST, V10, P295, DOI 10.1007/s10115-006-0005-y; Koga H, 2007, KNOWL INF SYST, V12, P25, DOI 10.1007/s10115-006-0027-5; Kriegel H.-P., 1998, P ACM SIGMOD INT C M, P154, DOI 10.1145/276304.276319; Kukar M, 2006, KNOWL INF SYST, V9, P364, DOI 10.1007/s10115-005-0203-z; Kuramochi M, 2005, INT J ARTIF INTELL T, V14, P641, DOI 10.1142/S0218213005002302; Leung CKS, 2007, KNOWL INF SYST, V11, P287, DOI 10.1007/s10115-006-0032-8; Leung CWK, 2006, KNOWL INF SYST, V10, P357, DOI 10.1007/s10115-006-0002-1; Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y; Liu B., 2007, WEB DATA MINING EXPL; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; MCLACHLAN GJ, 1987, APPL STAT-J ROY ST C, V36, P318, DOI 10.2307/2347790; McLachlan G., 1997, EM ALGORITHM EXTENSI; McLachlan G., 2000, FINITE MIXTURE MODEL; MESSENGE.R, 1972, J AM STAT ASSOC, V67, P768, DOI 10.2307/2284634; Meyer C.D., 2006, GOOGLES PAGE RANK SC; Morishita S., 2000, P 19 ACM SIGACT SIGM, P226, DOI 10.1145/335168.335226; Olshen R, 2001, STAT SCI, V16, P184, DOI 10.1214/ss/1009213290; PAGE L, 1999, 19990120 STANF U; Quinlan J.R., 1979, EXPERT SYSTEMS MICRO; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN R, 1989, UNKNOWN ATTRIBUTE VA, P164; Reyzin L., 2006, P 23 INT C MACH LEAR, P753, DOI 10.1145/1143844.1143939; Ridgeway G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scholkopf B, 2002, LEARNING KERNELS; Srikant R, 1995, P 21 INT C VER LARG, P407; STEINBACH M, 2000, P KDD WORKSH TEXT MI; Steinbach M, 2007, KNOWL INF SYST, V12, P279, DOI 10.1007/s10115-006-0041-7; Fung G, 2007, KNOWL INF SYST, V11, P243, DOI 10.1007/s10115-006-0043-5; Tan P.-N., 2006, INTRO DATA MINING; Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6; Thabtah FA, 2006, KNOWL INF SYST, V9, P109, DOI 10.1007/s10115-005-0213-x; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659; TOUSSAINT G, 2002, INT 2002 34 S COMP S; TOUSSAINT GT, 2002, JCDCG, P273; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Uno T, 2004, LECT NOTES COMPUT SC, V3245, P16; Vapnik V., 1995, NATURE STAT LEARNING; Viola P, 2001, PROC CVPR IEEE, P511; Washio T, 2005, LECT NOTES ARTIF INT, V3721, P692; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yan X., 2002, P 2002 IEEE INT C DA, P721; Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258; YU PS, 2005, P WEB INT WI 05; Zhang J, 2006, KNOWL INF SYST, V9, P157, DOI 10.1007/s10115-005-0211-z	92	273	295	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	JAN	2008	14	1					1	37		10.1007/s10115-007-0114-2		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	243KS	WOS:000251795900001	
B	Pang, B; Lee, L; Vaithyanathan, S		Hajic, J; Matsumoto, Y		Pang, B; Lee, L; Vaithyanathan, S			Thumbs up? Sentiment classification using machine learning techniques	PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING			English	Proceedings Paper	Conference on Empirical Methods in Natural Language Processing	JUL 06-07, 2002	Philadelphia, PA	Justsystem Corp, CLAIRVOYANCE Corp				We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA							Argamon-Engelson S., 1998, P AAAI WORKSH LEARN, P1; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Biber D, 1988, VARIATION SPEECH WRI; Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452; DAS SR, 2001, P 8 AS PAC FIN ASS A; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; FINN A, 2002, P 24 EUR C INF RETR, P353; Hatzivassiloglou V., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640; HATZIVASSILOGLO.V, 2000, P COLING; Hearst M.A., 1992, TEXT BASED INTELLIGE; Huettner A., 2000, ACL 2000 COMPANION V, P26; JOACHIMS T, 1999, ADV KERNEL METHODS S, P44; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; KARLGREN J, 1994, P COLING; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; MAYFIELD TL, 2001, P 2 NAACL, P239; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; Mosteller F., 1984, APPL BAYESIAN CLASSI; Nigam K., 1999, P IJCAI 99 WORKSH MA, P61; Pederson T., 2001, P 2 M N AM CHAPT ASS, P79; SACK W, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1488; Schutze Hinrich, 1997, P 35 ANN M ASS COMP, P32; Spertus E., 1997, P INN APPL ART INT I, P1058; Tatemura J, 2000, P 5 INT C INT US INT, P272, DOI 10.1145/325737.325870; Terveen L, 1997, COMMUN ACM, V40, P59, DOI 10.1145/245108.245122; TONG R, 2001, SIGIR 2001 WORKSH OP; Turney P., 2002, P ACL; Turney P. D., 2002, EGB1094 NAT RES COUN; Wiebe J. M., 2001, P ACL EACL WORKSH CO; Wilks Y., 1998, J NATURAL LANGUAGE E, V4, P135	31	258	333	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA							2002							79	86				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAO63	WOS:000223079900011	
J	Wulfsohn, MS; Tsiatis, AA				Wulfsohn, MS; Tsiatis, AA			A joint model for survival and longitudinal data measured with error	BIOMETRICS			English	Article						EM algorithm; longitudinal data; repeated measures; survival	TIME; AIDS	The relationship between a longitudinal covariate and a failure time process can be assessed using the Cox proportional hazards regression model. We consider the problem of estimating the parameters in the Cox model when the longitudinal covariate is measured infrequently and with measurement error. We assume a repeated measures random effects model for the covariate process. Estimates of the parameters are obtained by maximizing the joint likelihood for the covariate process and the failure time process. This approach uses the available information optimally because we use both the covariate and survival data simultaneously. Parameters are estimated using the expectation-maximization algorithm. We argue that such a method is superior to naive methods where one maximizes the partial likelihood of the Cox model using the observed covariate values. It also improves on two-stage methods where, in the first stage, empirical Bayes estimates of the covariate process are computed and then used as time-dependent covariates in a second stage to find the parameters in the Cox model that maximize the partial likelihood.	N CAROLINA STATE UNIV,DEPT STAT,RALEIGH,NC 27695	Wulfsohn, MS (reprint author), GILEAD SCI INC,333 LAKESIDE DR,FOSTER CITY,CA 94404, USA.						COX DR, 1972, J R STAT SOC B, V34, P187; DAFNI U, 1993, THESIS HARVARD SCH P; DEGRUTTOLA V, 1994, BIOMETRICS, V50, P1003; DEGRUTTOLA V, 1993, J ACQ IMMUN DEF SYND, V6, P359; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; LAIRD NM, 1982, BIOMETRICS, V38, P963, DOI 10.2307/2529876; LINDSTROM MJ, 1988, J AM STAT ASSOC, V83, P1004; PAWITAN Y, 1993, J AM STAT ASSOC, V88, P719, DOI 10.2307/2290756; PRENTICE RL, 1982, BIOMETRIKA, V69, P331, DOI 10.1093/biomet/69.2.331; Press W., 1992, NUMERICAL RECIPES FO; TSIATIS AA, 1995, J AM STAT ASSOC, V90, P27, DOI 10.2307/2291126	11	242	244	INTERNATIONAL BIOMETRIC SOC	WASHINGTON	808 17TH ST NW SUITE 200, WASHINGTON, DC 20006-3910	0006-341X			BIOMETRICS	Biometrics	MAR	1997	53	1					330	339		10.2307/2533118		10	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	WN180	WOS:A1997WN18000027	
J	Moore, JH; Gilbert, JC; Tsai, CT; Chiang, FT; Holden, T; Barney, N; White, BC				Moore, Jason H.; Gilbert, Joshua C.; Tsai, Chia-Ti; Chiang, Fu-Tien; Holden, Todd; Barney, Nate; White, Bill C.			A flexible computational framework for detecting, characterizing, and interpreting statistical patterns of epistasis in genetic studies of human disease susceptibility	JOURNAL OF THEORETICAL BIOLOGY			English	Article						gene-gene interactions; constructive induction; multifactor dimensionality reduction; entropy; machine learning; data mining	MULTIFACTOR-DIMENSIONALITY REDUCTION; DRIVEN CONSTRUCTIVE INDUCTION; RENIN-ANGIOTENSIN SYSTEM; GENOME-WIDE ASSOCIATION; COMPUTER-SIMULATIONS; COMPLEX DISEASES; COMMON DISEASES; HYPERTENSION; TRAITS; OPTIMIZATION	Detecting, characterizing, and interpreting gene-gene interactions or epistasis in studies of human disease susceptibility is both a mathematical and a computational challenge. To address this problem, we have previously developed a multifactor dimensionality reduction (MDR) method for collapsing high-dimensional genetic data into a single dimension (i.e. constructive induction) thus permitting interactions to be detected in relatively small sample sizes. In this paper, we describe a comprehensive and flexible framework for detecting and interpreting gene-gene interactions that utilizes advances in information theory for selecting interesting single-nucleotide polymorphisms (SNPs), MDR for constructive induction, machine learning methods for classification, and finally graphical models for interpretation. We illustrate the usefulness of this strategy using artificial datasets simulated from several different two-locus and three-locus epistasis models. We show that the accuracy, sensitivity, specificity, and precision of a naive Bayes classifier are significantly improved when SNPs are selected based on their information gain (i.e. class entropy removed) and reduced to a single attribute using MDR. We then apply this strategy to detecting, characterizing, and interpreting epistatic models in a genetic study (n = 500) of atrial fibrillation and show that both classification and model interpretation are significantly improved. (c) 2005 Elsevier Ltd. All rights reserved.	Dartmouth Hitchcock Med Ctr, Dept Genet, Computat Gen Lab, Lebanon, NH 03756 USA; Dartmouth Coll Sch Med, Dept Community & Family Med, Lebanon, NH USA; Dartmouth Coll, Dept Biol Sci, Hanover, NH 03755 USA; Univ New Hampshire, Dept Comp Sci, Durham, NH 03824 USA; Univ Vermont, Dept Comp Sci, Burlington, VT USA; Natl Taiwan Univ Hosp, Dept Internal Med, Div Cardiol, Taipei, Taiwan	Moore, JH (reprint author), Dartmouth Hitchcock Med Ctr, Dept Genet, Computat Gen Lab, 1 Med Ctr Dr,706 Rubin Bldg,HB7937, Lebanon, NH 03756 USA.	jason.h.moore@dartmouth.edu					Bateson W., 1909, MENDELS PRINCIPLES H; Bloedorn E, 1998, IEEE INTELL SYST APP, V13, P30, DOI 10.1109/5254.671089; Brodie Edmund D. III, 2000, P3; Cho YM, 2004, DIABETOLOGIA, V47, P549, DOI 10.1007/s00125-003-1321-3; COFFEY CS, 2004, BMC BIOINFORMATICS, V4, P49; Cordell HJ, 2001, GENETICS, V158, P357; CORDELL HJ, 1995, AM J HUM GENET, V57, P920; COX N, 1999, NAT GENET, V2, P213; Cox NJ, 2004, DIABETES, V53, pS19, DOI 10.2337/diabetes.53.2007.S19; Curk T, 2005, BIOINFORMATICS, V21, P396, DOI 10.1093/bioinformatics/bth474; Fisher R. A., 1918, T ROY SOC EDINBURGH, V52, P399; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Gibson G, 2000, BIOESSAYS, V22, P372, DOI 10.1002/(SICI)1521-1878(200004)22:4<372::AID-BIES7>3.0.CO;2-J; Goldberg David E, 1998, GENETIC ALGORITHMS S; Good P., 2000, PERMUTATION TESTS PR; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; Hahn Lance W, 2004, In Silico Biol, V4, P183; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Hirschhorn JN, 2005, NAT REV GENET, V6, P95, DOI 10.1038/nrg1521; Hoh J, 2004, CURR OPIN GENET DEV, V14, P229, DOI 10.1016/j.gde.2004.04.006; HOLLANDER W. F., 1955, JOUR HEREDITY, V46, P222; HU YJ, 1998, FEATURE EXTRACTION C, P257; Jakulin A, 2003, LECT NOTES ARTIF INT, V2838, P229; Jakulin A, 2003, LECT NOTES ARTIF INT, V2780, P229; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Lenat D. B., 1983, MACHINE LEARNING ART; LENAT DB, 1997, MACHINE INTELLIGENCE, V9; Li WT, 2000, HUM HERED, V50, P334, DOI 10.1159/000022939; Marchini J, 2005, NAT GENET, V37, P413, DOI 10.1038/ng1537; McGill W.J., 1954, PSYCHOMETRIKA, V9, P97; Michalewicz Z., 2000, SOLVE IT MODERN HEUR; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Mitchell T.M., 1997, MACHINE LEARNING; Moore JH, 2002, ANN MED, V34, P88, DOI 10.1080/07853890252953473; Moore JH, 2004, JAMA-J AM MED ASSOC, V291, P1642, DOI 10.1001/jama.291.13.1642; Moore JH, 2005, MOL GENET METAB, V84, P104, DOI 10.1016/j.ymgme.2004.10.006; Moore JH, 2004, EXPERT REV MOL DIAGN, V4, P795, DOI 10.1586/14737159.4.6.795; Moore JH, 2005, NAT GENET, V37, P13, DOI 10.1038/ng0105-13; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Moore JH, 2005, BIOESSAYS, V27, P637, DOI 10.1002/bias.20236; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Page GP, 2003, AM J HUM GENET, V73, P711, DOI 10.1086/378900; Phillips PC, 1998, GENETICS, V149, P1167; PIERCE JOHN R., 1980, INTRO INFORM THEORY, P8; Proulx SR, 2005, AM NAT, V165, P147, DOI 10.1086/426873; Qin SY, 2005, EUR J HUM GENET, V13, P807, DOI 10.1038/sj.ejhg.5201418; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Ritchie MD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-28; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Ritchie MD, 2004, LECT NOTES COMPUT SC, V3102, P438; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Segre D, 2005, NAT GENET, V37, P77, DOI 10.1038/ng1489; Sing CF, 2003, ARTERIOSCL THROM VAS, V23, P1190, DOI 10.1161/01.ATV.0000075081.51227.86; Soares ML, 2005, HUM MOL GENET, V14, P543, DOI 10.1093/hmg/ddi051; Takahashi N, 2004, TRENDS GENET, V20, P136, DOI 10.1016/j.tig.2004.01.004; Takahashi N, 2003, ENDOCRINOLOGY, V144, P2184, DOI 10.1210/en.2002-221045; Templeton A., 2000, EPISTASIS EVOLUTIONA, P41; Thornton-Wells TA, 2004, TRENDS GENET, V20, P640, DOI 10.1016/j.tig.2004.09.007; Tsai CT, 2004, CIRCULATION, V109, P1640, DOI 10.1161/01.CIR.0000124487.36586.26; Waddington CH, 1942, NATURE, V150, P563, DOI 10.1038/150563a0; Waddington CH, 1957, STRATEGY GENES; Wade MJ, 2001, GENETICA, V112, P59, DOI 10.1023/A:1013316611768; Wang WYS, 2005, NAT REV GENET, V6, P109, DOI 10.1038/nrg1522; Wilke RA, 2005, PHARMACOGENET GENOM, V15, P415, DOI 10.1097/01213011-200506000-00007; Wilke RA, 2005, NAT REV DRUG DISCOV, V4, P911, DOI 10.1038/nrd1874; Williams SM, 2004, HUM HERED, V57, P28, DOI 10.1159/000077387; Witten I. H., 2000, DATA MINING; WNEK J, 1994, MACH LEARN, V14, P139, DOI 10.1023/A:1022622132310; Xu JF, 2005, CANCER EPIDEM BIOMAR, V14, P2563, DOI 10.1158/1055-9965.EPI-05-0356; Zupan B, 1998, IEEE INTELL SYST APP, V13, P38, DOI 10.1109/5254.671090	70	237	243	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193			J THEOR BIOL	J. Theor. Biol.	JUL 21	2006	241	2					252	261		10.1016/j.jtbi.2005.11.036		10	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	072RS	WOS:000239691300009	
J	Friedman, JH				Friedman, JH			On bias, variance, 0/1 - Loss, and the curse-of-dimensionality	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						classification; bias; variance; curse-of-dimensionality; bagging; naive Bayes; nearest-neighbors		The classification problem is considered in which an output variable y assumes discrete values with respective probabilities that depend upon the simultaneous values of a set of input variables x = {x(1),..., x(n)}. At issue is how error in the estimates of these probabilities affects classification error when the estimates are used in a classification rule. These effects are seen to be somewhat counter intuitive in both their strength and nature. In particular the bias and variance components of the estimation error combine to influence classification in a very different way than with squared error on the probabilities themselves. Certain types of (very high) bias can be canceled by low variance to produce accurate classification. This can dramatically mitigate the effect of the bias associated with some simple estimators like "naive" Bayes, and the bias induced by the curse-of-dimensionality on nearest-neighbor procedures. This helps explain why such simple methods are often competitive with and sometimes superior to more sophisticated ones for classification, and why "bagging/aggregating" classifiers can often improve accuracy. These results also suggest simple modifications to these procedures that can (sometimes dramatically) further improve their classification performance.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Univ, Stanford Linear Accelerator Ctr, Stanford, CA 94305 USA	Friedman, JH (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.						Bellman R.E., 1961, ADAPTIVE CONTROL PRO; Breiman L., 1996, BIAS VARIANCE ARCING; Breiman L., 1984, CLASSIFICATION REGRE; BREIMAN L, 1995, BAGGING PREDICTORS; CHOW WS, 1992, PATTERN RECOGN, V25, P423; Dietterich TG, 1995, MACHINE LEARNING BIA; Efron B., 1995, CROSS VALIDATION BOO; Fix E, 1951, 4 US AIRF SCH AV MED; FRIEDMAN JH, 1985, LCS012 STANF U DEP S; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Good I, 1965, ESTIMATION PROBABILI; Hand D. J., 1982, KERNEL DISCRIMINANT; Heckerman David, 1994, P 10 C UNC ART INT, P293; Henley WE, 1996, STATISTICIAN, V45, P77, DOI 10.2307/2348414; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1996, BIAS PLUS VARIANCE D; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Langley P., 1992, P 10 NAT C ART INT, P223; LIPPMANN RP, 1989, IEEE COMMUNICATION M, V11, P47; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; ROSEN DB, 1995, WORKSH MACH LEARN NE; Tibshirani Robert, 1996, BIAS VARIANCE PREDIC; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918	24	232	235	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1384-5810			DATA MIN KNOWL DISC	Data Min. Knowl. Discov.		1997	1	1					55	77		10.1023/A:1009778005914		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	ZA826	WOS:000072405900004	
J	Cohen, I; Sebe, N; Garg, A; Chen, LS; Huang, TS				Cohen, I; Sebe, N; Garg, A; Chen, LS; Huang, TS			Facial expression recognition from video sequences: temporal and static modeling	COMPUTER VISION AND IMAGE UNDERSTANDING			English	Article							SPEECH RECOGNITION; OPTICAL-FLOW; NETWORK; TRACKER; LAFTER; LIPS; FACE	The most expressive way humans display emotions is through facial expressions. In this work we report on several advances we have made in building a system for classification of facial expressions from continuous video input. We introduce and test different Bayesian network classifiers for classifying expressions from video, focusing on changes in distribution assumptions, and feature dependency structures. In particular we use Naive-Bayes classifiers and change the distribution from Gaussian to Cauchy, and use Gaussian Tree-Augmented Naive Bayes (TAN) classifiers to learn the dependencies among different facial motion features. We also introduce a facial expression recognition from live video input using temporal cues. We exploit the existing methods and propose a new architecture of hidden Markov models (HMMs) for automatically segmenting and recognizing human facial expression from video sequences. The architecture performs both segmentation and recognition of the facial expressions automatically using a multi-level architecture composed of an HMM layer and a Markov model layer. We explore both person-dependent and person-independent recognition of expressions and compare the different methods. (C) 2003 Elsevier Inc. All rights reserved.	Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA; Univ Amsterdam, Fac Sci, Amsterdam, Netherlands; IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA; Eastman Kodak Co, Imaging Sci & Technol Lab, Rochester, NY 14650 USA	Cohen, I (reprint author), Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA.						BALUJA S, 1998, NEURAL INFORMATION P, P854; Black M. J., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466915; CACIOPPO JT, 1990, AM PSYCHOL, V45, P16, DOI 10.1037/0003-066X.45.1.16; Chen L. S., 2000, THESIS U ILLINOIS UR; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cohen I., 2000, THESIS U ILLINOIS UR; Cormen T. H., 1990, INTRO ALGORITHMS; De Silva L. C., 1997, Proceedings of ICICS, 1997 International Conference on Information, Communications and Signal Processing. Theme: Trends in Information Systems Engineering and Wireless Multimedia Communications (Cat. No.97TH8237), DOI 10.1109/ICICS.1997.647126; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Ekman P., 1978, FACIAL ACTION CODING; EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037//0033-2909.115.2.268; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GARG A, 2001, P 12 EUR C MACH LEAR, P179; Goleman D., 1995, EMOTIONAL INTELLIGEN; HAAS G, 1970, BIOMETRIKA, V57, P403, DOI 10.2307/2334849; IZARD CE, 1994, PSYCHOL BULL, V115, P288, DOI 10.1037/0033-2909.115.2.288; KANADE T, 2000, COMPREHENSIVE DATABA; KAY RM, 1990, ENTROPY INFORMATION; Lanitis A., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466919; LEVINSON SE, 1983, AT&T TECH J, V62, P1035; Lien J.J.J., 1998, THESIS CARNEGIE MELL; Martinez A, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P35; MASE K, 1991, IEICE TRANS COMMUN, V74, P3474; NEFIAN A, 1999, IEEE C AUD VID BAS B, P19; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Oliver N, 1997, PROC CVPR IEEE, P123, DOI 10.1109/CVPR.1997.609309; Oliver N, 2000, PATTERN RECOGN, V33, P1369, DOI 10.1016/S0031-3203(99)00113-2; Otsuka T., 1997, STUDY TRANSFORMATION; Otsuka T., 1997, Proceedings. International Conference on Image Processing (Cat. No.97CB36144), DOI 10.1109/ICIP.1997.638829; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Rabiner L., 1993, FUNDAMENTALS SPEECH; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rosenblum M, 1996, IEEE T NEURAL NETWOR, V7, P1121, DOI 10.1109/72.536309; Salovey P., 1990, IMAGINATION COGNITIO, V9, P185, DOI DOI 10.2190/DUGG-P24E-52WK-6CDG; Sebe N, 2000, IEEE T PATTERN ANAL, V22, P1132, DOI 10.1109/34.879793; STARKS H, 1994, PROBABILITY RANDOM P; Tao H, 1998, PROC CVPR IEEE, P735; UEKI N, 1994, SYST COMPUT JPN, V25, P95; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414	41	221	233	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1077-3142			COMPUT VIS IMAGE UND	Comput. Vis. Image Underst.	JUL-AUG	2003	91	1-2					160	187		10.1016/S1077-3142(03)00081-X		28	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	721XN	WOS:000185343900008	
J	Rogers, D; Hahn, M				Rogers, David; Hahn, Mathew			Extended-Connectivity Fingerprints	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							SIGNATURE MOLECULAR DESCRIPTOR; THROUGHPUT SCREENING DATA; NAIVE BAYES CLASSIFIER; DATA FUSION; DRUGLIKENESS CLASSIFICATION; VALENCE SEQUENCES; NEAREST-NEIGHBOR; MDL KEYS; SIMILARITY; PREDICTION	Extended-connectivity fingerprints (ECEPs) are a novel class of topological fingerprints for molecular characterization. Historically, topological fingerprints were developed for substructure and similarity searching. ECEPs were developed specifically for structure activity modeling. ECEPs are circular fingerprints with a number of useful qualities: they can be very rapidly calculated; they are not predefined and can represent an essentially infinite number of different molecular features (including stereochemical information); their features represent the presence of particular substructures, allowing easier interpretation of analysis results; and the ECFP algorithm can he tailored to generate different types of circular fingerprints, optimized for different uses. While the use of ECEPs has been widely adopted and validated, a description of their implementation has not previously been presented in the literature.	[Hahn, Mathew] Accelrys Inc, San Diego, CA 92121 USA	Rogers, D (reprint author), 3429 N Mt View Dr, San Diego, CA 92116 USA.	drogers@unterhund.com					[Anonymous], 1984, MACCS 2 DAT SYST VER; [Anonymous], 2000, PIP PIL VERS 7 5; *AS INC, AS CAT; ATTIAS R, 1983, J CHEM INF COMP SCI, V23, P102, DOI 10.1021/ci00039a003; Baldi P, 2007, J CHEM INF MODEL, V47, P2098, DOI 10.1021/ci700200n; Bender A, 2006, J CHEM INF MODEL, V46, P2445, DOI 10.1021/ci600197y; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bender A, 2009, J CHEM INF MODEL, V49, P108, DOI 10.1021/ci800249s; Breiman L., 1984, CLASSIFICATION REGRE; Briem H, 2000, PERSPECT DRUG DISCOV, V20, P231, DOI 10.1023/A:1008793325522; Briem H, 1996, J MED CHEM, V39, P3401, DOI 10.1021/jm950800y; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Cheng KS, 2007, HYDROL PROCESS, V21, P51, DOI 10.1002/hyp.6176; CHRISTIE BD, 1993, J CHEM INF COMP SCI, V33, P545, DOI 10.1021/ci00014a004; CLARK M, 1989, J COMPUT CHEM, V10, P982, DOI 10.1002/jcc.540100804; Cloutier LM, 2008, DRUG DISCOV TODAY, V13, P536, DOI 10.1016/j.drudis.2008.03.022; Costache AD, 2007, XENOBIOTICA, V37, P221, DOI 10.1080/00498250601089162; *DAYL CHEM INF SYS, 1987, DAYL TOOLK VERS 1; de Graaf C, 2008, J MED CHEM, V51, P4978, DOI 10.1021/jm800710x; *DERW INF AM, WORLD DRUG IND; Dubios JE, 1973, J CHEM DOC, V13, P8, DOI 10.1021/c160048a004; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Faulon JL, 2003, J CHEM INF COMP SCI, V43, P707, DOI 10.1021/ci020345w; FAULON JL, 1994, J CHEM INF COMP SCI, V34, P1204, DOI 10.1021/ci00021a031; Faulon JL, 2003, J CHEM INF COMP SCI, V43, P721, DOI 10.1021/ci020346o; Flahive E, 2007, QSAR COMB SCI, V26, P679, DOI 10.1002/qsar.200610124; FREEDMAN D, 1991, STATISTICS; Gedeck P, 2006, J CHEM INF MODEL, V46, P1924, DOI 10.1021/ci050413p; Ghose AK, 1998, J PHYS CHEM A, V102, P3762, DOI 10.1021/jp980230o; Glen RC, 2006, IDRUGS, V9, P199; Glick M, 2003, MOL PHYS, V101, P1325, DOI 10.1080/0026897031000099862; Glick M, 2006, J CHEM INF MODEL, V46, P193, DOI 10.1021/ci050374h; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Good AC, 2007, J CHEM INF MODEL, V47, P110, DOI 10.1021/ci6003493; GREENE J, 1994, J CHEM INF COMP SCI, V34, P1297, DOI 10.1021/ci00022a012; Hassan M, 2006, MOL DIVERS, V10, P283, DOI 10.1007/s11030-006-9041-5; Hattori K, 2008, J CHEM INF MODEL, V48, P135, DOI 10.1021/ci7002686; HERMAN W, 1985, PARTIAL LEAST SQUARE, P581; Hert J, 2006, J CHEM INF MODEL, V46, P462, DOI 10.1021/ci050348j; Hert J, 2005, J MED CHEM, V48, P7049, DOI 10.1021/jm050316n; Hert J, 2008, J CHEM INF MODEL, V48, P755, DOI 10.1021/ci8000259; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; HURST JR, 1998, Patent No. 5751605; Jensen BF, 2007, J MED CHEM, V50, P501, DOI 10.1021/jm060333; Johnson MA, 1990, CONCEPTS APPL MOL SI; Keiser MJ, 2009, NATURE, V462, P175, DOI 10.1038/nature08506; Kellenberger E, 2007, J MED CHEM, V50, P1294, DOI 10.1021/jm061389p; Klon AE, 2004, J MED CHEM, V47, P4356, DOI 10.1021/jm049970d; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; Klon AE, 2006, J CHEM INF MODEL, V46, P1945, DOI 10.1021/ci0601315; Klon AE, 2009, COMB CHEM HIGH T SCR, V12, P469; Klon AE, 2004, J MED CHEM, V47, P2743, DOI 10.1021/jm030363k; Krier M, 2006, J CHEM INF MODEL, V46, P512, DOI 10.1021/ci050352v; *LEADSCOPE INC, 1997, LEADSCOPE VERS 1; Lee PH, 2007, J COMPUT AID MOL DES, V21, P665, DOI 10.1007/s10822-007-9124-0; Li QL, 2007, J CHEM INF MODEL, V47, P1776, DOI 10.1021/ci700107y; Liu RF, 2008, J CHEM INF MODEL, V48, P542, DOI 10.1021/ci700372s; Lounkine E, 2009, J CHEM INF MODEL, V49, P561, DOI 10.1021/ci800377n; LOWIS DR, 1998, HQSAR HEW HIGHLY PRE, V1, P3; Marcou G, 2007, J CHEM INF MODEL, V47, P195, DOI 10.1021/ci600342e; Martin YC, 2009, QSAR COMB SCI, V28, P797, DOI 10.1002/qsar.200810176; *MAYBR PLC, MAYBR CAT; McGregor MJ, 1997, J CHEM INF COMP SCI, V37, P443, DOI 10.1021/ci960151e; MCINTYRE TA, 2009, XENOBIOTICA, V39, P1; Metz JT, 2007, J COMPUT AID MOL DES, V21, P139, DOI 10.1007/s10822-007-9109-z; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Muchmore SW, 2008, J CHEM INF MODEL, V48, P941, DOI 10.1021/ci7004498; Nettles JH, 2006, J MED CHEM, V49, P6802, DOI 10.1021/jm060902w; Nidhi Glick M., 2006, J CHEM INF MODEL, V46, P1124; Nigsch F, 2008, J CHEM INF MODEL, V48, P2313, DOI 10.1021/ci800079x; Nisius B, 2009, J CHEM INF MODEL, V49, P1347, DOI 10.1021/ci900087y; NORINDER U, 1995, QSAR MOL MODELLING C, P433; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Papadatos G, 2009, J CHEM INF MODEL, V49, P195, DOI 10.1021/ci800302g; Pelletier DJ, 2007, J CHEM INF MODEL, V47, P1196, DOI 10.1021/ci6004542; Prathipati P, 2008, J CHEM INF MODEL, V48, P2362, DOI 10.1021/ci800143n; Rhodes N, 2006, J CHEM INF MODEL, V46, P615, DOI 10.1021/ci0503863; Rogers D, 2005, J BIOMOL SCREEN, V10, P682, DOI 10.1177/1087057105281365; Rumelhart D., 1986, PARALLEL DISTRIBUTED; Scheiber J, 2009, J MED CHEM, V52, P3103, DOI 10.1021/jm801546k; Schuffenhauer A, 2006, J CHEM INF MODEL, V46, P525, DOI 10.1021/ci0503558; Schuffenhauer A, 2007, J CHEM INF MODEL, V47, P47, DOI 10.1021/ci600338x; Sciabola S, 2007, J CHEM INF MODEL, V47, P76, DOI 10.1021/ci060143q; Selzer P, 2005, CURR OPIN CHEM BIOL, V9, P310, DOI 10.1016/j.cbpa.2005.04.001; Sheridan RP, 2007, EXPERT OPIN DRUG DIS, V2, P423, DOI 10.1517/17460441.2.4.423; SHERIDAN RP, 1989, J CHEM INF COMP SCI, V29, P255, DOI 10.1021/ci00064a005; Sprague PW, 1995, PERSPECT DRUG DISCOV, V3, P1, DOI 10.1007/BF02174464; Steindl TM, 2007, J CHEM INF MODEL, V47, P563, DOI 10.1021/ci600321m; Steindl TM, 2006, J CHEM INF MODEL, V46, P2146, DOI 10.1021/ci6002043; Sullivan DC, 2008, J CHEM INF MODEL, V48, P817, DOI 10.1021/ci700439z; Sun HM, 2005, J MED CHEM, V48, P4031, DOI 10.1021/jm050180t; Sun HM, 2006, CHEMMEDCHEM, V1, P315, DOI 10.1002/cmdc.200500047; Todeschini R., 2000, HDB MOL DESCRIPTORS; van Hoorn WP, 2009, J CHEM INF MODEL, V49, P2211, DOI 10.1021/ci900072g; Visco DP, 2002, J MOL GRAPH MODEL, V20, P429, DOI 10.1016/S1093-3263(01)00144-9; Wale N, 2008, J CHEM INF MODEL, V48, P730, DOI 10.1021/ci700369e; Wale N, 2009, J CHEM INF MODEL, V49, P2190, DOI 10.1021/ci9000376; WEININGER D, 1989, J CHEM INF COMP SCI, V29, P97, DOI 10.1021/ci00062a008; WEINSTEIN JN, 1992, SCIENCE, V258, P447, DOI 10.1126/science.1411538; Whittle M, 2006, J CHEM INF MODEL, V46, P2206, DOI 10.1021/ci0496144; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Xing L, 2002, J CHEM INF COMP SCI, V42, P796, DOI 10.1021/ci010315d; Yang H, 2003, J BIOL CHEM, V278, P35079, DOI 10.1074/jbc.M303098200; Yoon S, 2005, J COMPUT AID MOL DES, V19, P483, DOI 10.1007/s10822-005-9002-6; Zhang Q, 2006, J MED CHEM, V49, P1536, DOI 10.1021/jm050468i; Zhou DS, 2007, LETT DRUG DES DISCOV, V4, P192, DOI 10.2174/157018007780077462; Zhou DS, 2008, J CHEM INF MODEL, V48, P981, DOI 10.1021/ci800024c	107	218	218	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAY	2010	50	5					742	754		10.1021/ci100050t		13	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	599KS	WOS:000277911600004	
J	Hall, MA; Holmes, G				Hall, MA; Holmes, G			Benchmarking attribute selection techniques for discrete class data mining	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						attribute selection; classification; benchmarking		Data engineering is generally considered to be a central issue in the development of data mining applications. The success of many learning schemes, in their attempts to construct models of data, hinges on the reliable identification of a small set of highly predictive attributes. The inclusion of irrelevant, redundant, and noisy attributes in the model building process phase can result in poor predictive performance and increased computation. Attribute selection generally involves a combination of search and attribute utility estimation plus evaluation with respect to specific learning schemes. This leads to a large number of possible permutations and has led to a situation where very few benchmark studies have been conducted. This paper presents a benchmark comparison of several attribute selection methods for supervised classification. All the methods produce an attribute ranking, a useful devise for isolating the individual merit of an attribute. Attribute selection is achieved by cross-validating the attribute rankings with respect to a classification learner to find the best attributes. Results are reported for a selection of standard data sets and two diverse learning schemes C4.5 and naive Bayes.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Hall, MA (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.						ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; Blake C. L., 1998, UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; DASH M, 1997, INTELLIGENT DATA ANA, V1; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Hall M.A., 2000, P 17 INT C MACH LEAR; Hall MA, 1998, THESIS U WAIKATO HAM; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1994, P EUR C MACH LEARN, P171; Langley P., 1992, P 10 NAT C ART INT, P223; Liu H, 1996, P 13 INT C MACH LEAR, P319; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Sikonja M.R., 1997, P 14 INT C ICML 97, P296; Yang Y., 1997, P 14 INT C MACH LEAR, P412	16	200	203	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV-DEC	2003	15	6					1437	1447		10.1109/TKDE.2003.1245283		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	737UC	WOS:000186249300007	
J	Hand, DJ; Yu, KM				Hand, DJ; Yu, KM			Idiot's Bayes - Not so stupid after all?	INTERNATIONAL STATISTICAL REVIEW			English	Article						supervised classification; independence model; naive Bayes; simple Bayes; diagnosis	ACUTE ABDOMINAL-PAIN; COMPUTER-AIDED DIAGNOSIS; ASSUMING INDEPENDENCE; ASSISTED DIAGNOSIS; ACUTE ABDOMEN; CLASSIFICATION; DECISION; THEOREM; IDENTIFICATION; DISTRIBUTIONS	Folklore has it that a very simple supervised classification rule, based on the typically false assumption that the predictor variables are independent, can be highly effective, and often more effective than sophisticated rules. We examine the evidence for this, both empirical, as observed in real data applications, and theoretical, summarising explanations for why this simple rule might be effective.	Univ London Imperial Coll Sci Technol & Med, Dept Math, London, England; Univ Plymouth, Plymouth PL4 8AA, Devon, England	Hand, DJ (reprint author), Univ London Imperial Coll Sci Technol & Med, Dept Math, Huxley Bldg, London, England.						ADAMS ID, 1986, BRIT MED J, V293, P800; Adams NM, 1999, PATTERN RECOGN, V32, P1139, DOI 10.1016/S0031-3203(98)00154-X; ALTHAM PME, 1984, J ROY STAT SOC B MET, V46, P118; BAILEY NTJ, 1964, MATH COMPUTER SCI BI, P103; BARKER DJP, 1970, BRIT J PREV SOC MED, V24, P193; BOYLE JA, 1966, Q J MED, V35, P565; BRUNK HD, 1975, PERSPECTIVES BIOMETR, V1; CESTNIK B, 1990, P 9 EUR C ART INT ST; CESTNIK G, 1987, PROGR MACHINE LEARNI; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; COOMANS D, 1983, METHOD INFORM MED, V22, P93; CORNFIEL.J, 1973, COMPUT BIOMED RES, V6, P97, DOI 10.1016/0010-4809(73)90065-7; CORNFIELD J, 1971, P S DIAGNOSTIC PROCE; CRICHTON NJ, 1987, STAT MED, V6, P945, DOI 10.1002/sim.4780060809; CRICHTON NJ, 1988, P IMA C APPL STAT ME, P235; CRICHTON NJ, 1989, STAT MED, V8, P1351, DOI 10.1002/sim.4780081107; CROFT D, 1987, ANN BIOMED ENG, V2, P69; DAWID AP, 1976, BIOMETRICS, V32, P647, DOI 10.2307/2529753; DEDOMBAL FT, 1991, ANN CHIR, V45, P273; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Du Boulay G H, 1977, Br J Radiol, V50, P849; EDWARDS FH, 1984, SURG GYNECOL OBSTET, V158, P219; EFRON B, 1975, J AM STAT ASSOC, V70, P892, DOI 10.2307/2285453; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOX J, 1980, METHOD INFORM MED, V19, P210; FREUND Y, 1996, P 13 INT C MACH LEAR, P256; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FRYBACK DG, 1978, COMPUT BIOMED RES, V11, P423, DOI 10.1016/0010-4809(78)90001-0; GAMMERMAN A, 1991, METHOD INFORM MED, V30, P15; Goldberg D. P., 1972, MAUDSLEY MONOGRAPH, V21; Good I, 1965, ESTIMATION PROBABILI; GUNN AA, 1991, BAILLIERE CLIN GASTR, V5, P639, DOI 10.1016/0950-3528(91)90046-4; Hand D., 1997, CONSTRUCTION ASSESSM; Hand D. J., 1982, KERNEL DISCRIMINANT; Hand D J, 1992, Stat Methods Med Res, V1, P49, DOI 10.1177/096228029200100104; Hand DJ, 2000, J APPL STAT, V27, P527; HECKERMAN DE, 1992, COMPUT BIOMED RES, V25, P56, DOI 10.1016/0010-4809(92)90035-9; HILDEN J, 1976, P365; HILDEN J, 1984, COMPUT BIOL MED, V14, P429, DOI 10.1016/0010-4825(84)90043-X; Jeffreys H., 1961, THEORY PROBABILITY; JOHN GH, 1995, P 11 C UNC ART INT, P338; KELLY MG, 2000, TR0015 IMP COLL DEP; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Kononenko I., 1990, CURRENT TRENDS KNOWL; Kontkanen P, 2000, STAT COMPUT, V10, P39, DOI 10.1023/A:1008984400380; KONTKANEN P, 1999, P 15 INT C UNC ART I; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; DEDOMBAL FT, 1972, BRIT MED J, V2, P9; Lowe D, 1990, NETWORK-COMP NEURAL, V1, P299, DOI 10.1088/0954-898X/1/3/002; Mani S, 1997, LECT NOTES ARTIF INT, V1211, P130; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Michie D., 1994, MACHINE LEARNING NEU; MONTI S, 1999, P 15 C UNC AI STOCKH; NORDYKE RA, 1971, COMPUT BIOMED RES, V4, P374, DOI 10.1016/0010-4809(71)90022-X; OCONNOR GT, 1991, MED DECIS MAKING, V11, P107, DOI 10.1177/0272989X9101100206; OHMANN C, 1986, STAT MED, V5, P503, DOI 10.1002/sim.4780050515; OHMANN C, 1988, METHOD INFORM MED, V27, P73; Ohmann C, 1996, ARTIF INTELL MED, V8, P23, DOI 10.1016/0933-3657(95)00018-6; OTT J, 1976, J AM STAT ASSOC, V71, P391, DOI 10.2307/2285321; PATERSONBROWN S, 1989, BRIT J SURG, V76, P1011, DOI 10.1002/bjs.1800761007; Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54; Penny WD, 1997, COMPUT BIOMED RES, V30, P1, DOI 10.1006/cbmr.1997.1432; Ridgeway G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Ripley B., 1996, PATTERN RECOGNITION; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; RUSSEK E, 1983, COMPUT BIOMED RES, V16, P537, DOI 10.1016/0010-4809(83)90040-X; Singh M., 1996, P 13 INT C MACH LEAR, P453; SPIEGELHALTER DJ, 1984, J ROY STAT SOC A STA, V147, P35, DOI 10.2307/2981737; SUTTON GC, 1989, BRIT J SURG, V76, P82, DOI 10.1002/bjs.1800760126; THORNTON JG, 1991, AM J OBSTET GYNECOL, V164, P154; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918; TODD BS, 1994, METHOD INFORM MED, V33, P402; VANWOER.A, 1961, BIOMETRICS, V17, P299, DOI 10.2307/2527995; WARNER HR, 1961, JAMA-J AM MED ASSOC, V177, P177; Webb A. R., 1999, STAT PATTERN RECOGNI; WELLWOOD JM, 1989, BRIT J HOSP MED, V41, P564; WILLCOX WR, 1973, J GEN MICROBIOL, V77, P317; WILLCOX WR, 1975, BIOL IDENTIFICATION, P103; WILLCOX WR, 1980, A VAN LEEUW J MICROB, V46, P233, DOI 10.1007/BF00453024	83	177	181	INT STATISTICAL INST	VOORBURG	428 PRINSES BEATRIXLAAN, 2270 AZ VOORBURG, NETHERLANDS	0306-7734			INT STAT REV	Int. Stat. Rev.	DEC	2001	69	3					385	398		10.2307/1403452		14	Statistics & Probability	Mathematics	526YN	WOS:000174157500003	
J	Huang, J; Ling, CX				Huang, J; Ling, CX			Using AUC and accuracy in evaluating learning algorithms	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						evaluation of learning algorithms; ROC; AUC of ROC; accuracy	ROC CURVE; AREA	The area under the ROC ( Receiver Operating Characteristics) curve, or simply AUC, has been traditionally used in medical diagnosis since the 1970s. It has recently been proposed as an alternative single-number measure for evaluating the predictive ability of learning algorithms. However, no formal arguments were given as to why AUC should be preferred over accuracy. In this paper, we establish formal criteria for comparing two different measures for learning algorithms and we show theoretically and empirically that AUC is a better measure ( defined precisely) than accuracy. We then reevaluate well-established claims in machine learning based on accuracy using AUC and obtain interesting and surprising new results. For example, it has been well-established and accepted that Naive Bayes and decision trees are very similar in predictive accuracy. We show, however, that Naive Bayes is significantly better than decision trees in AUC. The conclusions drawn in this paper may make a significant impact on machine learning and data mining applications.	Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada	Huang, J (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.	jhuang@csd.uwo.ca; cling@csd.uwo.ca					Blake C. L., 1998, UCI REPOSITORY MACHI; Boser B., 1992, P 5 ANN WORKSH COMP, V21, P144, DOI DOI 10.1145/130385.130401; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C. C., 2003, LIBSVM LIB SUPPORT V; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; Cristianini N., 2000, INTRO SUPPORT VECTOR; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; EGAN JP, 1975, SIGNAL DETECTION THE; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Ferri C., 2002, P 19 INT C MACH LEAR, P139; GREEN DM, 1966, SIGNAL DETECTION THE; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Hsu C., 2001, COMPARISON METHODS M; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P., 1992, P 10 NAT C ART INT, P223; Ling CX, 2003, P 18 INT C ART INT I, P329; Lingjaerde O, 1998, ACTA PSYCHIAT SCAND, V98, P73, DOI 10.1111/j.1600-0447.1998.tb10045.x; LINGNER J, 2002, MOL B INT U, V22, P123; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; MEYER D, 2002, BENCKMARKING SUPPORT; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; PROVOST F, 2000, 0004IS CDER STERN SC; Provost F., 1998, P 15 INT C MACH LEAR, P445; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Scholkopf B, 2002, LEARNING KERNELS; SMYTH P, 1995, P 12 INT C MACH LEAR, P506; Spackman K., 1989, P 6 INT WORKSH MACH, P160; Suykens J.A.K., 1999, P INT JOINT C NEUR N; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Vapnik V., 1998, STAT LEARNING THEORY	36	157	166	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2005	17	3					299	310				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	888EY	WOS:000226358200001	
J	Kuncheva, LI				Kuncheva, LI			Switching between selection and fusion in combining classifiers: An experiment	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						classifier combination; classifier selection and fusion; confidence intervals (CIs); decision templates (DTs); discriminant analysis; multiple classifier systems; pattern recognition; supervised learning	MULTIPLE CLASSIFIERS; COMBINATION; RECOGNITION; SYSTEMS	This paper presents a combination of classifier selection and fusion by using statistical inference to switch between the two. Selection is applied in those regions of the feature space where one classifier strongly dominates the others from the pool [called clustering-and-selection or (CS)] and fusion is applied in the remaining regions. Decision templates (DT) method is adopted for the classifier fusion part. The proposed combination scheme (called CS+DT) is compared experimentally against its two components, and also against majority vote, naive Bayes, two joint-distribution methods (BKS and a variant due to Wernecke), the dynamic classifier selection (DCS) algorithm DCS_LA based on local accuracy (Woods et al.), and simple fusion methods such as maximum, minimum, average, and product. Based on the results with five data sets with homogeneous ensembles [multilayer perceptrons (MLPs)] and ensembles of different classifiers, we offer a discussion on when to combine classifiers and how classifier selection (static or dynamic) can be misled by the differences in the classifier team.	Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales	Kuncheva, LI (reprint author), Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales.						ALADJEM ME, 1991, BIOCYBERNETICS, V8, P57; Alpaydin E, 1996, IEEE T NEURAL NETWOR, V7, P788, DOI 10.1109/72.501737; Bezdek J.C., 1999, FUZZY MODELS ALGORIT; Dasarathy BV, 1978, P IEEE, V67, P708; Duda R., 1973, PATTERN CLASSIFICATI; Duin RPW, 1996, PATTERN RECOGN LETT, V17, P529, DOI 10.1016/0167-8655(95)00113-1; Erenstein R. H., 1981, METHOD COLLECTIVE RE; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Kang HJ, 1997, ENG APPL ARTIF INTEL, V10, P379, DOI 10.1016/S0952-1976(97)00020-1; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KUNCHEVA LI, 1993, PATTERN RECOGN LETT, V14, P619, DOI 10.1016/0167-8655(93)90046-G; Kuncheva L. I., 2000, P 4 INT C KNOWL BAS, P185; Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X; Kuncheva L.I., 2000, STUDIES FUZZINESS SO; LOONEY SW, 1988, PATTERN RECOGN LETT, V8, P5, DOI 10.1016/0167-8655(88)90016-5; NG KC, 1992, IEEE T SYST MAN CYB, V22, P916, DOI 10.1109/21.179832; Ripley B., 1996, PATTERN RECOGNITION; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Verikas A, 1999, PATTERN RECOGN LETT, V20, P429, DOI 10.1016/S0167-8655(99)00012-4; Wang WJ, 2000, LECT NOTES COMPUT SC, V1857, P240; WERNECKE KD, 1992, BIOMETRICS, V48, P497, DOI 10.2307/2532305; Wernecke K.-D., 1988, Classification and Related Methods of Data Analysis. Proceedings of the First Conference of the International Federation of Classification Societies (IFCS); WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	27	153	161	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2002	32	2					146	156		10.1109/3477.990871		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	532DE	WOS:000174455700002	
J	Fleuret, F				Fleuret, F			Fast binary feature selection with conditional mutual information	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						classification; mutual information; feature selection; naive Bayes; information theory; fast learning		We propose in this paper a very fast feature selection technique based on conditional mutual information. By picking features which maximize their mutual information with the class to predict conditional to any feature already picked, it ensures the selection of features which are both individually informative and two-by-two weakly dependant. We show that this feature selection method outperforms other classical algorithms, and that a naive Bayesian classifier built with features selected that way achieves error rates similar to those of state-of-the-art methods such as boosting or SVMs. The implementation we propose selects 50 features among 40,000, based on a training set of 500 examples in a tenth of a second on a standard 1Ghz PC.	EPFL, CVLAB, Stn 14, CH-1015 Lausanne, Switzerland	Fleuret, F (reprint author), EPFL, CVLAB, Stn 14, CH-1015 Lausanne, Switzerland.	FRANCOIS.FLEURET@EPFL.CH					Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; BATTIT R, 1994, IEEE T NEURAL NETWOR, V5; BONNLANDER BV, 1996, P ISANN; Boser B., 1992, P 5 ANN WORKSH COMP, V21, P144, DOI DOI 10.1145/130385.130401; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 1999, 567 U CAL DEP STAT; Christiani N., 2000, INTRO SUPPORT VECTOR; Cover T. M., 1991, ELEMENTS INFORM THEO; Das S., 2001, P 18 INT C MACH LEAR, P74; Duda R., 1973, PATTERN CLASSIFICATI; FLEURET F, 2002, P ICPR2002, V1, P235; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; FLEURET F, 2003, RR4941 INRIA; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRUEND Y, 1996, P 13 INT C MACH LEAR, P148; FRUEND Y, 1996, P 9 ANN C COMP LEARN, P325; FUREY TS, 2000, BIOINFORMATICS, V16; GUYON I, 2004, P NIPS2004 C; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie Trevor, 1998, ADV NEURAL INFORM PR, V10; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, P 13 INT C MACH LEAR, P284; Langley P., 1992, P 10 NAT C ART INT, P223; Mason L., 2000, NIPS, P512; Miyahara K., 2000, PRICAI 2000. Topics in Artificial Intelligence. 6th Pacific Rim International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol.1886); NOVIKOFF A, 1962, S MATH THEORY AUTOMA, P615; Ratanamahatana C, 2003, APPL ARTIF INTELL, V17, P475, DOI 10.1080/08839510390219327; RATSCH G, 1998, P NIPS, P564; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Torkkola K., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753742; Vapnik V.N., 1998, NATURE STAT LEARNING; Vidal-Naquet M., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Yu L, 2003, P 20 INT C MACH LEAR, P856	33	151	155	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	NOV	2004	5						1531	1555				25	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GW	WOS:000236328400005	
J	Johnson-Laird, PN; Legrenzi, P; Girotto, V; Legrenzi, MS; Caverni, JP				Johnson-Laird, PN; Legrenzi, P; Girotto, V; Legrenzi, MS; Caverni, JP			Naive probability: A mental model theory of extensional reasoning	PSYCHOLOGICAL REVIEW			English	Article							3 PRISONERS; FREQUENCY; JUDGMENT; FALLACY; LOGIC	This article outlines a theory of naive probability. According to the theory, individuals who are unfamiliar with the probability calculus can infer the probabilities of events in an extensional way: They construct mental models of what is true in the various possibilities. Each model represents an equiprobable alternative unless individuals have beliefs to the contrary, in which case some models will have higher probabilities than others. The probability of an event depends on the proportion of models in which it occurs. The theory predicts several phenomena of reasoning about absolute probabilities, including typical biases. It correctly predicts certain cognitive illusions in inferences about relative probabilities. It accommodates reasoning based on numerical premises, and it explains how naive reasoners can infer posterior probabilities without relying on Bayes's theorem. Finally, it dispels some common misconceptions of probabilistic reasoning.	Princeton Univ, Dept Psychol, Princeton, NJ 08544 USA; Univ Milan, Ist Psicol, Fac Lettere & Filosofia, Milan, Italy; Univ Aix Marseille 1, Ctr Rech Psychol Cognit, CREPCO, Aix En Provence, France; Univ Padua, Dipartimento Psicol Gen, Padua, Italy	Johnson-Laird, PN (reprint author), Princeton Univ, Dept Psychol, Princeton, NJ 08544 USA.						Bell VA, 1998, COGNITIVE SCI, V22, P25, DOI 10.1207/s15516709cog2201_2; BRAINE MDS, 1984, PSYCHOL LEARN MOTIV, V18, P313, DOI 10.1016/S0079-7421(08)60365-5; BRAINE MDS, 1991, PSYCHOL REV, V98, P182, DOI 10.1037//0033-295X.98.2.182; CASSCELLS W, 1978, NEW ENGL J MED, V299, P999, DOI 10.1056/NEJM197811022991808; COLLINS A, 1989, COGNITIVE SCI, V13, P1; Cosmides L, 1996, COGNITION, V58, P1, DOI 10.1016/0010-0277(95)00664-8; de Laplace Pierre Simon, 1951, PHILOS ESSAY PROBABI; Eddy D. M., 1982, JUDGMENT UNCERTAINTY, P249; Edwards W., 1967, DECISION MAKING; Evans J. S. B., 1993, HUMAN REASONING PSYC; BARHILLEL M, 1982, COGNITION, V11, P109, DOI 10.1016/0010-0277(82)90021-X; FALK R, 1992, COGNITION, V43, P197, DOI 10.1016/0010-0277(92)90012-7; Feller W, 1957, INTRO PROBABILITY TH; FISHER RA, 1932, DESIGN EXPT; Garnham A., 1987, MENTAL MODELS REPRES; Gigerenzer G, 1996, PSYCHOL REV, V103, P592, DOI 10.1037/0033-295X.103.3.592; GIGERENZER G, 1995, PSYCHOL REV, V102, P684, DOI 10.1037/0033-295X.102.4.684; GIROTTO V, IN PRESS STRATEGIES; GIROTTO V, 1996, 3 INT C THINK U COLL; Hacking I., 1975, EMERGENCE PROBABILIT; HAMMERTON M, 1997, MARCH M EXP PSYCH SO; Howson C., 1993, SCI REASONING BAYESI; Johnson-Laird P. N., 1991, DEDUCTION; Johnson-Laird P. N., 1983, MENTAL MODELS; JohnsonLaird PN, 1996, ACTA PSYCHOL, V93, P69, DOI 10.1016/0001-6918(96)00022-4; KAHNEMAN D, 1973, PSYCHOL REV, V80, P237, DOI 10.1037/h0034747; Kahneman D, 1996, PSYCHOL REV, V103, P582, DOI 10.1037//0033-295X.103.3.582; Keynes J. M., 1943, TREATISE PROBABILITY; Koehler JJ, 1996, BEHAV BRAIN SCI, V19, P1; LEGRENZI P, 1993, COGNITION, V49, P37, DOI 10.1016/0010-0277(93)90035-T; LEWONTIN RC, 1990, THINKING INVITATION, V3, P229; MACCHI L, 1994, ANN M SOC JUDG DEC M; Marr D., 1982, VISION COMPUTATIONAL; MIYAMOTO J, 1995, DECISION MAKING PERS, V32, P319; MYNATT CR, 1993, Q J EXP PSYCHOL-A, V46, P759; Nickerson RS, 1996, PSYCHOL BULL, V120, P410, DOI 10.1037//0033-2909.120.3.410; OAKSFORD M, 1992, J EXP PSYCHOL LEARN, V18, P835, DOI 10.1037/0278-7393.18.4.835; Osherson D.N., 1976, LOGICAL ABILITIES CH, V4; OSHERSON DN, 1996, INVITATION COGNITIVE, V3, P35; PHILLIPS LD, 1966, J EXP PSYCHOL, V72, P346, DOI 10.1037/h0023653; Rips L. J., 1994, PSYCHOL PROOF; Savage L.J., 1954, FDN STAT; SHIMOJO S, 1989, COGNITION, V32, P1, DOI 10.1016/0010-0277(89)90012-7; STEVENSON RJ, 1995, Q J EXP PSYCHOL-A, V48, P613; STEVENSON RJ, 1993, LANGAUGE THOUGHT REP; TVERSKY A, 1983, PSYCHOL REV, V90, P293, DOI 10.1037/0033-295X.90.4.293; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; TVERSKY A, 1994, PSYCHOL REV, V101, P547, DOI 10.1037//0033-295X.101.4.547; Von Mises R., 1957, PROBABILITY STAT TRU; Von Winterfeldt D, 1986, DECISION ANAL BEHAV; Wason P., 1966, NEW HORIZONS PSYCHOL	51	147	154	AMER PSYCHOLOGICAL ASSOC	WASHINGTON	750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA	0033-295X			PSYCHOL REV	Psychol. Rev.	JAN	1999	106	1					62	88		10.1037/0033-295X.106.1.62		27	Psychology; Psychology, Multidisciplinary	Psychology	175QW	WOS:000079107200003	
J	Webb, GI; Boughton, JR; Wang, ZH				Webb, GI; Boughton, JR; Wang, ZH			Not so naive Bayes: Aggregating one-dependence estimators	MACHINE LEARNING			English	Article						naive Bayes; semi-naive Bayes; attribute independence assumption; probabilistic prediction		Of numerous proposals to improve the accuracy of naive Bayes by weakening its attribute independence assumption, both LBR and Super-Parent TAN have demonstrated remarkable error performance. However, both techniques obtain this outcome at a considerable computational cost. We present a new approach to weakening the attribute independence assumption by averaging all of a constrained class of classifiers. In extensive experiments this technique delivers comparable prediction accuracy to LBR and Super-Parent TAN with substantially improved computational efficiency at test time relative to the former and at training time relative to the latter. The new algorithm is shown to have low variance and is suited to incremental learning.	Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia	Webb, GI (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia.	geoff.webb@infotec.monash.edu	Webb, Geoffrey/A-1347-2008				ALI K, 1994, PROC INT C TOOLS ART, P476, DOI 10.1109/TAI.1994.346454; Brain D., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Kohav R., 1996, P 13 INT C MACH LEAR, P275; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; LANGLEY P, 1993, P 1993 EUR C MACH LE, V153; Langley P., 1994, P 10 C UNC ART INT, P399; NOCK R, 1995, P 12 INT C MACH LEAR, P413; OLIVER JJ, 1995, P 12 INT C MACH LEAR, P430; Pazzani M. J, 1996, ISIS INFORM STAT IND, P66; Sahami M., 1996, P 2 INT C KNOWL DISC, P334; Singh M., 1996, P 13 INT C MACH LEAR, P453; WANG Z, 2002, P IEEE INT C DAT MIN, P75; Webb G I, 1998, P 11 AUSTR JOINT C A, P285; WEBB GI, 2001, P 14 AUSTR JOINT C A, P545; Witten I.H., 2000, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XIE Z, 2002, ADV KNOWLEDGE DISCOV, P104; YANG Y, 2003, 2003131 SCH COMP SCI; Zheng Z., 1999, P 16 INT C MACH LEAR, P493; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	28	145	157	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JAN	2005	58	1					5	24		10.1007/s10994-005-4258-6		20	Computer Science, Artificial Intelligence	Computer Science	897XV	WOS:000227041100001	
J	Menzies, T; Greenwald, J; Frank, A				Menzies, Tim; Greenwald, Jeremy; Frank, Art			Data mining static code attributes to learn defect predictors	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						data mining detect prediction; McCabe; Halstead; artifical intelligence; empirical; naive Bayes	SELECTION	The value of using static code attributes to learn defect predictors has been widely debated. Prior work has explored issues like the merits of "McCabes versus Halstead versus lines of code counts" for generating defect predictors. We show here that such debates are irrelevant since how the attributes are used to build predictors is much more important than which particular attributes are used. Also, contrary to prior pessimism, we show that such defect predictors are demonstrably useful and, on the data studied here, yield predictors with a mean probability of detection of 71 percent and mean false alarms rates of 25 percent. These predictors would be useful for prioritizing a resource-bound exploration of code that has yet to be inspected.	W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA; Portland State Univ, Dept Comp Sci, Portland, OR 97207 USA	Menzies, T (reprint author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.	tim@menzies.us; jegreen@cecs.pdx.edu; arf@cs.pdx.edu					ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; BASILI V, 2002, P 24 INT C SOFTW ENG; Blake C. L., 1998, UCI REPOSITORY MACHI; BOUCKAERT R, 2003, P INT C MACH LEARN I; CHAPMAN M, 2002, P NASA SOFTW ASS S; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; FAGAN M, 1986, IEEE T SOFTWARE  JUL, P744; FAGAN ME, 1976, IBM SYSTEMS J, V15; FENTON N, 2000, IEEE T SOFTWARE ENG, P797; FENTON NE, 1995, SOFTWARE METRICS RIG; Fenton NE, 1997, SOFTWARE METRICS RIG; Fisher D, 1992, P 9 INT C MACH LEARN; Goldberg D., 1989, GENETIC ALGORITHMS S; HALL G, 2000, J SYST SOFTWARE, P111; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hall MA, 1998, THESIS U WAIKATO HAM; Halstead M.H., 1977, ELEMENTS SOFTWARE SC; HEEGER D, 1998, SIGNAL DETECTION THE; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Khoshgoftaar T. M., 2001, Proceedings 12th International Symposium on Software Reliability Engineering, DOI 10.1109/ISSRE.2001.989459; KHOSHGOFTAAR TM, 2001, RECENT ADV RELIABILI, P247; Khoshgoftaar TM, 2003, EMPIR SOFTW ENG, V8, P255, DOI 10.1023/A:1024424811345; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kononenko I., 1994, P EUR C MACH LEARN, P171; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; MENZIES T, 2003, P 2004 IEEE C HIGH A; Menzies T., 2002, P 27 NASA SEL WORKSH; Menzies T, 2003, IEEE INTELL SYST, V18, P18, DOI 10.1109/MIS.2003.1200723; MENZIES T, 2004, P INT WORKSH MIN SOF; MENZIES T, 2003, P IEEE SOFTW METR S; MENZIES T, 2002, P IEEE AUT SOFTW ENG; Menzies T., P WORKSH PRED SOFTW; NAGAPPAN N, 2005, P INT C SOFTW ENG; Nagappan N, 2005, PROC INT CONF SOFTW, P580, DOI 10.1145/1062455.1062558; Nikora A. P., 2003, P 9 INT SOFTW METR S; PORTER AA, 1990, IEEE SOFTWARE    MAR, P46; Quinlan R., 1992, C4 5 PROGRAMS MACHIN; Rakitin S.R., 2001, SOFTWARE VERIFICATIO; Rumelhart D., 1986, NATURE, P533; SHEPPERD M, 1994, J SYST SOFTWARE, V26, P197, DOI 10.1016/0164-1212(94)90011-6; Shull F., 2002, Proceedings Eighth IEEE Symposium on Software Metrics, DOI 10.1109/METRIC.2002.1011343; Shull F, 2000, COMPUTER, V33, P73, DOI 10.1109/2.869376; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Tang W, 2004, PROC INT C TOOLS ART, P373; TIAN J, 1995, IEEE T SOFTWARE ENG, V21, P641, DOI 10.1109/32.403788; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Witten I. H., 2005, DATA MINING	47	129	137	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589			IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	JAN	2007	33	1					2	13		10.1109/TSE.2007.256941		12	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	109ML	WOS:000242312200001	
J	Qi, YJ; Bar-Joseph, Z; Klein-Seetharaman, J				Qi, YJ; Bar-Joseph, Z; Klein-Seetharaman, J			Evaluation of different biological data and computational classification methods for use in protein interaction prediction	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						protein-protein interaction; high-throughput data; joint learning	YEAST; NETWORKS; GENOMES; GENES; TOOL	Protein-protein interactions play a key role in many biological systems. High-throughput methods can directly detect the set of interacting proteins in yeast, but the results are often incomplete and exhibit high false-positive and false-negative rates. Recently, many different research groups independently suggested using supervised learning methods to integrate direct and indirect biological data sources for the protein interaction prediction task. However, the data sources, approaches, and implementations varied. Furthermore, the protein interaction prediction task itself can be subdivided into prediction of (1) physical interaction, (2) co-complex relationship, and (3) pathway co-membership. To investigate systematically the utility of different data sources and the way the data is encoded as features for predicting each of these types of protein interactions, we assembled a large set of biological features and varied their encoding for use in each of the three prediction tasks. Six different classifiers were used to assess the accuracy in predicting interactions, Random Forest (RF), RF similarity-based k-Nearest-Neighbor, Naive Bayes, Decision Tree, Logistic Regression, and Support Vector Machine. For all classifiers, the three prediction tasks had different success rates, and co-complex prediction appears to be an easier task than the other two. Independently of prediction task, however, the RF classifier consistently ranked as one of the top two classifiers for all combinations of feature sets. Therefore, we used this classifier to study the importance of different biological datasets. First, we used the splitting function of the RF tree structure, the Gini index, to estimate feature importance. Second, we determined classification accuracy when only the top-ranking features were used as an input in the classifier. We find that the importance of different features depends on the specific prediction task and the way they are encoded. Strikingly, gene expression is consistently the most important feature for all three prediction tasks, while the protein interactions identified using the yeast-2-hybrid system were not among the top-ranking features under any condition.	Univ Pittsburgh, Sch Med, Dept Biol Struct, Pittsburgh, PA 15260 USA; Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Klein-Seetharaman, J (reprint author), Univ Pittsburgh, Sch Med, Dept Biol Struct, Biomed Sci Tower 3,Room 2051, Pittsburgh, PA 15260 USA.	judithks@cs.cmu.edu					Ashburner M, 2000, NAT GENET, V25, P25; BADER GD, 2003, NAT BIOTECHNOL, V20, P991; Bader JS, 2004, NAT BIOTECHNOL, V22, P78, DOI 10.1038/nbt924; Bar-Joseph Z, 2003, NAT BIOTECHNOL, V21, P1337, DOI 10.1038/nbt890; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Deng MH, 2002, GENOME RES, V12, P1540, DOI 10.1101/gr.153002; DOLINSKI K, SACCHAROMYCES GENOME; FLACH P, 2004, ICML04; Gavin AC, 2002, NATURE, V415, P141, DOI 10.1038/415141a; GEORGE H, 1995, P 11 C UNC ART INT, P338; Ghaemmaghami S, 2003, NATURE, V425, P737, DOI 10.1038/nature02046; Gilchrist MA, 2004, BIOINFORMATICS, V20, P689, DOI 10.1093/bioinformatics/btg469; GUYON I, 2003, J MACHINE LEARN RES, V5, P1157; Harbison CT, 2004, NATURE, V431, P99, DOI 10.1038/nature02800; HO Y, 2002, NATURE, V415, P6868; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; JOACHIMS T, 2002, THESIS NEW YORK; JONES KS, 1981, INFORM RETRIEVAL EXP, P213; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; Lin N, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-154; Mewes HW, 2004, NUCLEIC ACIDS RES, V32, pD41, DOI 10.1093/nar/gkh092; Qi Y., 2005, PAC S BIOCOMPUT, V10, P531; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Salwinski L, 2003, CURR OPIN STRUC BIOL, V13, P377, DOI 10.1016/S0959-440X(03)00070-8; Sprinzak E, 2003, J MOL BIOL, V327, P919, DOI 10.1016/S0022-2836(03)00239-0; Tong AHY, 2004, SCIENCE, V303, P808, DOI 10.1126/science.1091317; Uetz P, 2000, NATURE, V403, P623; von Mering C, 2002, NATURE, V417, P399; Witten I.H., 2000, DATA MINING PRACTICA; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Yamanishi Y, 2004, BIOINFORMATICS, V20, P363, DOI 10.1093/bioinformatics/bth910; Zhang LV, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-38	34	124	130	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585			PROTEINS	Proteins	MAY 15	2006	63	3					490	500		10.1002/prot.20865		11	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	034QR	WOS:000236946200008	
J	McCallum, AK; Nigam, K; Rennie, J; Seymore, K				McCallum, AK; Nigam, K; Rennie, J; Seymore, K			Automating the construction of internet portals with machine learning	INFORMATION RETRIEVAL			English	Article						spidering; crawling; reinforcement learning; information extraction; hidden Markov models; text classification; naive Bayes; expectation-maximization; unlabeled data		Domain-specific internet portals are growing in popularity because they gather content from the Web and organize it for easy access, retrieval and search. For example, www.campsearch.com allows complex queries by age location, cost and specialty over summer camps. This functionality is nor possible with general, Web-wide search engines. Unfortunately these portals are difficult and time-consuming to maintain. This paper advocates the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific Internet portals. Ws describe new research in reinforcement learning, information extraction and text classification that enables efficient spidering, the identification of informative text segments, and the population of topic hierarchies. Using these techniques, we have built a demonstration system: a portal for computer science research papers. It already contains over 50,000 papers and is publicly available at www.cora.justresearch.com. These techniques are widely applicable to portal creation in other domains.	Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; MIT, Cambridge, MA 02139 USA	McCallum, AK (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.						BAKER D, 1999, HIERARCHICAL PROBABI; Baum L.E., 1972, INEQUALITIES, V3, P1; Bellman R., 1957, DYNAMIC PROGRAMMING; Bikel D.M., 1997, P 5 C APPL NAT LANG, P194, DOI 10.3115/974557.974586; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Boyan J., 1996, AAAI 96 WORKSH INT B; Chakrabarti S., 1999, P 8 INT WORLD WID WE; CHANG H, 1999, CREATING CUSTOMIZED; Chen S. F., 1998, TR1098 HARV U COMP S; Cho J., 1998, P 7 WORLD WID WEB C; COHEN WW, 1999, AAAI SPRING S INT AG; Cohen W. W., 1998, Proceedings of the Second International Conference on Autonomous Agents, DOI 10.1145/280765.280870; Craven M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; FREITAG D, 1999, P AAAI 99 WORKSH MAC; Giles C. L., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries; HOFMANN T, 1998, 1625 AI MIT; Joachims T., 1997, P 15 INT JOINT C ART, P770; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; KEARNS M, 2000, ADV NEURAL INFORMATI, V12; Kleinberg J. M., 1999, J ACM, P46; Kupiec J., 1992, Computer Speech and Language, V6, DOI 10.1016/0885-2308(92)90019-Z; Lawrence S, 1999, COMPUTER, V32, P67, DOI 10.1109/2.769447; Leek T. R., 1997, THESIS UC SAN DIEGO; Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings; McCallum A., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); McCallum A, 1998, AAAI 98 WORKSH LEARN; McLachlan G., 1988, MIXTURE MODELS; Menczer F., 1997, MACH LEARN, P227; Merialdo B., 1994, Computational Linguistics, V20; Mitchell T.M., 1997, MACHINE LEARNING; NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001; NIGAM K, 2000, MACH LEARN, P39; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Riloff E., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Stolcke A., 1998, Applying Machine Learning to Discourse Processing. Papers from the 1998 AAAI Symposium; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Tesauro G, 1997, ADV NEUR IN, V9, P1068; Torgo L, 1997, INTELLIGENT DATA ANA, V4, P275, DOI 10.1016/S1088-467X(97)00013-9; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Witten IH, 1998, COMMUN ACM, V41, P71, DOI 10.1145/273035.273057; YAMRON J, 1998, P INT C AC SPEECH SI; Yarowsky D., 1995, P 33 ANN M ASS COMP, P189, DOI 10.3115/981658.981684	43	120	126	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1386-4564			INFORM RETRIEVAL	Inf. Retr.	JUL	2000	3	2					127	163		10.1023/A:1009953814988		37	Computer Science, Information Systems	Computer Science	407RC	WOS:000167283700003	
J	Tan, AC; Naiman, DQ; Xu, L; Winslow, RL; Geman, D				Tan, AC; Naiman, DQ; Xu, L; Winslow, RL; Geman, D			Simple decision rules for classifying human cancers from gene expression profiles	BIOINFORMATICS			English	Article							PROSTATE-CANCER; MOLECULAR CLASSIFICATION; MICROARRAY DATA; LEUKEMIA; PREDICTION; TUMOR; SIGNATURES; ADENOCARCINOMA; CARCINOMAS; DIAGNOSIS	Motivation: Various studies have shown that cancer tissue samples can be successfully detected and classified by their gene expression patterns using machine learning approaches. One of the challenges in applying these techniques for classifying gene expression data is to extract accurate, readily interpretable rules providing biological insight as to how classification is performed. Current methods generate classifiers that are accurate but difficult to interpret. This is the trade-off between credibility and comprehensibility of the classifiers. Here, we introduce a new classifier in order to address these problems. It is referred to as k-TSP (k-Top Scoring Pairs) and is based on the concept of 'relative expression reversals'. This method generates simple and accurate decision rules that only involve a small number of gene-to-gene expression comparisons, thereby facilitating follow-up studies. Results: In this study, we have compared our approach to other machine learning techniques for class prediction in 19 binary and multi-class gene expression datasets involving human cancers. The k-TSP classifier performs as efficiently as Prediction Analysis of Microarray and support vector machine, and outperforms other learning methods (decision trees, k-nearest neighbour and naive Bayes). Our approach is easy to interpret as the classifier involves only a small number of informative genes. For these reasons, we consider the k-TSP method to be a useful tool for cancer classification from microarray gene expression data.	Whitaker Biomed Engn Inst, Ctr Cardiovasc Bioinformat & Modeling, Baltimore, MD 21218 USA; Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA	Tan, AC (reprint author), Whitaker Biomed Engn Inst, Ctr Cardiovasc Bioinformat & Modeling, 3400 N Charles St, Baltimore, MD 21218 USA.	actan@jhu.edu	Naiman, Daniel/A-3304-2010; Geman, Donald/A-3325-2010; Tan, Aik Choon/A-3135-2011	Naiman, Daniel/0000-0001-6504-9081; 			Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; BERNSTEIN ID, 1992, BLOOD, V79, P1811; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bo T., 2002, GENOME BIOL, V3, P11; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chang MS, 2000, BIOCHEM BIOPH RES CO, V279, P732, DOI 10.1006/bbrc.2000.3992; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; GEMAN D, 2004, STAT APPL GENETI MOL, V3; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; GRIFFIN JD, 1983, BLOOD, V62, P557; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Haste H, 1997, PSYCHOLOGIST, V10, P507; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Long PM, 2003, MACH LEARN, V52, P31, DOI 10.1023/A:1023937123600; Mutis T, 1999, BLOOD, V93, P2336; Pavlidis P, 2003, BIOINFORMATICS, V19, P295, DOI 10.1093/bioinformatics/19.2.295; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Stuart RO, 2004, P NATL ACAD SCI USA, V101, P615, DOI 10.1073/pnas.2536479100; Su AI, 2001, CANCER RES, V61, P7388; Tan Aik Choon, 2003, Appl Bioinformatics, V2, pS75; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tsutsumi S, 2003, CANCER RES, V63, P4882; Welsh JB, 2001, CANCER RES, V61, P5974; Witten I.H., 2000, DATA MINING PRACTICA; Yang XJ, 2004, NUCLEIC ACIDS RES, V32, P959, DOI 10.1093/nar/gkh252; YEOH AEJ, 2002, CANCER CELL, V1, P133	43	119	124	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	OCT 15	2005	21	20					3896	3904		10.1093/bioinformatics/bti631		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	974MQ	WOS:000232596300013	
J	Chickering, DM; Heckerman, D				Chickering, DM; Heckerman, D			Efficient approximations for the marginal likelihood of Bayesian networks with hidden variables	MACHINE LEARNING			English	Article						Bayesian model averaging; model selection; multinomial mixtures; clustering; unsupervised learning; Laplace approximation	PROBABILISTIC NETWORKS; MODEL; ALGORITHM; EM	We discuss Bayesian methods for model averaging and model selection among Bayesian-network models with hidden variables. In particular, we examine large-sample approximations for the marginal likelihood of naive-Bayes models in which the root node is hidden. Such models are useful for clustering or unsupervised learning. lire consider a Laplace approximation and the less accurate but more computationally efficient approximation known as the Bayesian Information Criterion (BIG), which is equivalent to Rissanen's (1987) Minimum Description Length (MDL). Also, we consider approximations that ignore some off-diagonal elements of the observed information matrix and an approximation proposed by Cheeseman and Stutz (1995). We evaluate the accuracy of these approximations using a Monte-Carlo gold standard. In experiments with artificial and real examples, we find that (1) none of the approximations are accurate when used for model averaging, (2) all of the approximations, with the exception of BIC/MDL, are accurate for model selection, (3) among the accurate approximations, the Cheeseman-Stutz and Diagonal approximations are the most computationally efficient, (4) all of the approximations, with the exception of BIC/MDL, can be sensitive to the prior distribution over model parameters, and (5) the Cheeseman-Stutz approximation can be more accurate than the other approximations, including the Laplace approximation, in situations where the parameters in the maximum a posteriori configuration are near a boundary.	Microsoft Corp, Redmond, WA 98052 USA	Chickering, DM (reprint author), Microsoft Corp, Redmond, WA 98052 USA.						AZEVEDO A, 1994, P 10 C UNC ART INT S, P28; Bareiss E. R., 1987, Proceedings of the Fourth International Workshop on Machine Learning; Becker S., 1989, P 1988 CONN MOD SUMM, P29; Berger J.O., 1985, STAT DECISION THEORY; Bernardo J. M., 1994, BAYESIAN THEORY; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Buntine W. L., 1994, J ARTIFICIAL INTELLI, V2, P159; BUNTINE WL, 1994, IEEE T NEURAL NETWOR, V5, P480, DOI 10.1109/72.286919; Cheeseman P, 1995, ADV KNOWLEDGE DISCOV, P153; Chib S, 1995, J AM STAT ASSOC, V90, P1313, DOI 10.2307/2291521; CHICKERING DM, 1996, P 12 C UNC ART INT S, P158; Clogg C, 1995, HDB STAT MODELING SO; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DRAPER D, 1995, J R STAT SOC B, V57, P45; Geiger D, 1994, P 10 C UNC ART INT, P235; Geiger D., 1996, P 12 C UNC ART INT, P283; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Gilks W.R., 1996, MARKOV CHAIN MONTE C; Good I, 1965, ESTIMATION PROBABILI; GULL SF, 1991, QUANTIFIED MAXIMUM E; HAUGHTON DMA, 1988, ANN STAT, V16, P342, DOI 10.1214/aos/1176350709; HECKERMAN D, 1996, MSRTR9506 MICR RES; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; HECKERMAN D, 1995, MSRTR9554 MICR RES; HONG Z, 1994, PATTERN RECOGN, V24, P317; Jeffreys H, 1939, THEORY PROBABILITY; Jensen F.V., 1990, COMPUTATIONAL STATIS, V4, P269; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; KASS RE, 1995, J AM STAT ASSOC, V90, P928, DOI 10.2307/2291327; Kass R.E., 1988, BAYESIAN STATISTICS, V3, P261; MACKAY D, 1996, CHOICE BASIS LAPLACE; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; MENG XL, 1991, J AM STAT ASSOC, V86, P899, DOI 10.2307/2290503; Merz CJ, 1996, UCI REPOSITORY MACHI; MICHALSKI RS, 1980, INT J POLICY ANAL IN, V4; Neal R. M., 1993, CRGTR931 U TOR DEP C; NEAL RM, 1991, CRGTR912 U TOR DEP C; RAFTERY A, 1996, HYPOTHESIS TESTING M, pCH10; Raftery A. E., 1995, SOCIOLOGICAL METHODO; RAFTERY AE, 1994, 255 U WASH DEP STAT; RISSANEN J, 1987, J ROYAL STAT SOC B, V49, P253; RISSANEN J, 1987, J ROY STAT SOC B MET, V49, P223; Rubin D., 1976, BIOMETRIKA, V3, P581; Russell S., 1995, P 14 INT JOINT C ART, P1146; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SPIEGELHALTER DJ, 1993, STAT SCI, V8, P219, DOI 10.1214/ss/1177010888; Spirtes P., 1993, CAUSATION PREDICTION; THIESSON B, 1997, P 13 C UNC ART INT S	52	119	137	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	NOV-DEC	1997	29	2-3					181	212				32	Computer Science, Artificial Intelligence	Computer Science	YN352	WOS:000071159300005	
J	Lu, LJ; Xia, Y; Paccanaro, A; Yu, HY; Gerstein, M				Lu, LJ; Xia, Y; Paccanaro, A; Yu, HY; Gerstein, M			Assessing the limits of genomic data integration for predicting protein networks	GENOME RESEARCH			English	Article							TRANSCRIPTIONAL REGULATORY NETWORKS; MESSENGER-RNA EXPRESSION; SACCHAROMYCES-CEREVISIAE; BINDING SITES; SCALE DATA; YEAST; GENES; ORGANIZATION; COEVOLUTION; INTERACTOME	Genomic data integration-the process of statistically combining diverse Sources of information from functional genomics experiments to make large-scale predictions-is becoming increasingly prevalent. One might expect that this process should become progressively more powerful With the integration of more evidence. Here, we explore the limits of genomic data integration, assessing the degree to which predictive power increases with the addition of more features. We focus oil a predictive context that has been extensively investigated and benchmarked in the past-the prediction of protein-protein interactions in yeast. We start by using a simple Naive Bayes classifier for integrating diverse Sources of genomic evidence, ranging from coexpression relationships to similar phylogenetic profiles. We expand the number of features considered for prediction to 16, significantly more than previous Studies. Overall, we observe a small, but measurable improvement in prediction performance over previous benchmarks, based on four strong features. This allows us to identify new yeast interactions with high confidence. It also allows us to quantitatively assess the inter-relations amongst different genomic features. It is known that subtle correlations and dependencies between features call confound the strength of interaction predictions. We investigate this issue in detail through calculating mutual information. To Our Surprise, we find no appreciable statistical dependence between the many possible pairs of features. We further explore feature dependencies by comparing the performance Of Our simple Naive Bayes classifier with a boosted version of the same classifier, which is fairly resistant to feature dependence. We find that boosting does not improve performance, indicating that, at least for prediction purposes, Our genomic features are essentially independent. In Summary, by integrating a few (i.e., four) good features, we approach the maximal predictive power of current genomic data integration; moreover, this limitation does not reflect (potentially removable) inter-relationships between the features.	Yale Univ, Dept Mol Biophys & Biochem, New Haven, CT 06520 USA; Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA; Yale Univ, Program Computat Biol & Bioinformat, New Haven, CT 06520 USA	Gerstein, M (reprint author), Yale Univ, Dept Mol Biophys & Biochem, POB 6666, New Haven, CT 06520 USA.	Mark.Gerstein@yale.edu					Alberts B., 2002, MOL BIOL CELL; Ashburner M, 2000, NAT GENET, V25, P25; Baker D, 2001, SCIENCE, V294, P93, DOI 10.1126/science.1065659; Berger JM, 1996, NATURE, V379, P225, DOI 10.1038/379225a0; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bowers PM, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-5-r35; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Drawid A, 2000, TRENDS GENET, V16, P426, DOI 10.1016/S0168-9525(00)02108-9; Duda R.O., 2001, PATTERN CLASSIFICATI; Eisenberg D, 2000, NATURE, V405, P823, DOI 10.1038/35015694; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Gavin AC, 2002, NATURE, V415, P141, DOI 10.1038/415141a; Ge H, 2001, NAT GENET, V29, P482, DOI 10.1038/ng776; Gerstein M, 2002, SCIENCE, V295, P284, DOI 10.1126/science.1068664; Goh CS, 2000, J MOL BIOL, V299, P283, DOI 10.1006/jmbi.2000.3732; Goh CS, 2002, J MOL BIOL, V324, P177, DOI 10.1016/S0022-2836(02)01038-0; Greenbaum D, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-9-117; Greenbaum D, 2002, BIOINFORMATICS, V18, P585, DOI 10.1093/bioinformatics/18.4.585; Hartwell L. H., 1999, NATURE, V402, P47; Ho Y, 2002, NATURE, V415, P180, DOI 10.1038/415180a; Horak CE, 2002, METHOD ENZYMOL, V350, P469; Ideker T, 2001, SCIENCE, V292, P929, DOI 10.1126/science.292.5518.929; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2002, GENOME RES, V12, P37, DOI 10.1101/gr.205602; Jansen Ronald, 2002, Journal of Structural and Functional Genomics, V2, P71, DOI 10.1023/A:1020495201615; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; JOACHIMS T, 1997, 14 INT C MACH LEARN; Kemmeren P, 2002, MOL CELL, V9, P1133, DOI 10.1016/S1097-2765(02)00531-2; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Letovsky S, 2003, BIOINFORMATICS S1, V19, pi197; Lin N, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-154; Lu L, 2002, PROTEINS, V49, P350, DOI 10.1002/prot.10222; Lu L, 2003, GENOME RES, V13, P1146, DOI 10.1101/gr.1145203; Marcotte EM, 1999, NATURE, V402, P83; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Martone R, 2003, P NATL ACAD SCI USA, V100, P12247, DOI 10.1073/pnas.2135255100; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Mewes HW, 2002, NUCLEIC ACIDS RES, V30, P31, DOI 10.1093/nar/30.1.31; Pazos F, 2002, PROTEINS, V47, P219, DOI 10.1002/prot.10074; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schwikowski B, 2000, NAT BIOTECHNOL, V18, P1257, DOI 10.1038/82360; Skolnick J, 2002, ADV CHEM PHYS, V120, P131; Strong M, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-9-r59; Tamames J, 1997, J MOL EVOL, V44, P66, DOI 10.1007/PL00006122; Thatcher JW, 1998, P NATL ACAD SCI USA, V95, P253, DOI 10.1073/pnas.95.1.253; Tong AHY, 2004, SCIENCE, V303, P808, DOI 10.1126/science.1091317; Tong AHY, 2001, SCIENCE, V294, P2364, DOI 10.1126/science.1065810; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Uetz P, 2000, NATURE, V403, P623; Valencia A, 2002, CURR OPIN STRUC BIOL, V12, P368, DOI 10.1016/S0959-440X(02)00333-0; Vazquez A, 2003, NAT BIOTECHNOL, V21, P697, DOI 10.1038/nbt825; von Mering C, 2002, NATURE, V417, P399; Wong SL, 2004, P NATL ACAD SCI USA, V101, P15682, DOI 10.1073/pnas.0406614101; Xia Y, 2004, ANNU REV BIOCHEM, V73, P1051, DOI 10.1146/annurev.biochem.73.011303.073950; Yu HY, 2003, TRENDS GENET, V19, P422, DOI 10.1016/S0168-9525(03)00175-6; Yu HY, 2004, GENOME RES, V14, P1107, DOI 10.1101/gr.1774904; Yu HY, 2004, TRENDS GENET, V20, P227, DOI 10.1016/j.tig.2004.04.008; Zhang LV, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-38	64	115	121	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1088-9051			GENOME RES	Genome Res.	JUL	2005	15	7					945	953		10.1101/gr.3610305		9	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	944JQ	WOS:000230424000005	
J	Bickel, PJ; Levina, E				Bickel, PJ; Levina, E			Some theory for Fisher's linear discriminant function, 'naive Bayes', and some alternatives when there are many more variables than observations	BERNOULLI			English	Article; Proceedings Paper	Workshop on High-Dimensional Data	SEP 09-20, 2002	Leiden, NETHERLANDS			Fisher's linear discriminant; Gaussian coloured noise; minimax regret; naive Bayes		We show that the 'naive Bayes' classifier which assumes independent covariates greaty ourperforms the Fisher linear discriminant rule under broad conditions when the number of variable grows,; faster than the number of observations, in the classical problem of discriminating between two normal populations. We also introduce a class of rules spanning the range between independence and arbitrary dependence. These rules are shown to achieve Bayes consistency for the Gaussian 'coloured noise' model and to adapt to a spectrum of convergence rates, which we Conjecture to be minimax.	Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA; Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA	Bickel, PJ (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.	bickel@stat.berkeley.edu; elevina@umich.edu					Bottcher A., 1996, LECT OPERATOR THEORY; Bradley RC, 2002, BERNOULLI, V8, P175; DeVore R. A., 1993, CONSTRUCTIVE APPROXI; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; Grenander U., 1984, TOEPLITZ FORMS THEIR; JOHNSTONE IM, 2002, UNPUB FUNCTION ESTIM; Levina E., 2002, THESIS U CALIFORNIA; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; Luenberger D, 1984, LINEAR NONLINEAR PRO; McLachlan G. J., 1992, DISCRIMINANT ANAL ST	13	105	105	INT STATISTICAL INST	VOORBURG	428 PRINSES BEATRIXLAAN, 2270 AZ VOORBURG, NETHERLANDS	1350-7265			BERNOULLI	Bernoulli	DEC	2004	10	6					989	1010		10.3150/bj/1106314847		22	Statistics & Probability	Mathematics	886BU	WOS:000226202300005	
J	Zhang, SW; Pan, Q; Zhang, HC; Shao, ZC; Shi, JY				Zhang, SW; Pan, Q; Zhang, HC; Shao, ZC; Shi, JY			Prediction of protein homo-oligomer types by pseudo amino acid composition: Approached with an improved feature extraction and Naive Bayes Feature Fusion	AMINO ACIDS			English	Article						Naive Bayes Feature Fusion; support vector machine; pseudo amino acid composition; weighted auto-correlation function; homo-oligomer	STRUCTURAL CLASS PREDICTION; SECONDARY STRUCTURE-CONTENT; SUPPORT VECTOR MACHINE; SUBCELLULAR LOCATION; QUATERNARY STRUCTURE; SEQUENCE; LOCALIZATION; INSIGHTS; CLASSIFICATION; REPRESENTATION	The interaction of non-covalently bound monomeric protein subunits forms oligomers. The oligomeric proteins are superior to the monomers within the scope of functional evolution of biomacromolecules. Such complexes are involved in various biological processes, and play an important role. It is highly desirable to predict oligomer types automatically from their sequence. Here, based on the concept of pseudo amino acid composition, an improved feature extraction method of weighted auto-correlation function of amino acid residue index and Naive Bayes multi-feature fusion algorithm is proposed and applied to predict protein homo-oligomer types. We used the support vector machine (SVM) as base classifiers, in order to obtain better results. For example, the total accuracies of A, B, C, D and E sets based on this improved feature extraction method are 77.63, 77.16, 76.46, 76.70 and 75.06% respectively in the jackknife test, which are 6.39, 5.92, 5.22, 5.46 and 3.82% higher than that of G set based on conventional amino acid composition method with the same SVM. Comparing with Chou's feature extraction method of incorporating quasi-sequence-order effect, our method can increase the total accuracy at a level of 3.51 to 1.01%. The total accuracy improves from 79.66 to 80.83% by using the Naive Bayes Feature Fusion algorithm. These results show: 1) The improved feature extraction method is effective and feasible, and the feature vectors based on this method may contain more protein quaternary structure information and appear to capture essential information about the composition and hydrophobicity of residues in the surface patches that buried in the interfaces of associated subunits; 2) Naive Bayes Feature Fusion algorithm and SVM can be referred as a powerful computational tool for predicting protein homo-oligomer types.	Northwestern Polytech Univ, Coll Automat Control, Xian 710072, Peoples R China; Northwestern Polytech Univ, Coll Life Sci, Xian 710072, Peoples R China	Zhang, SW (reprint author), Northwestern Polytech Univ, Coll Automat Control, Xian 710072, Peoples R China.	zhangsw@nwpu.edu.cn					ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; ANFINSEN CB, 1961, P NATL ACAD SCI USA, V47, P1309, DOI 10.1073/pnas.47.9.1309; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 1996, NUCLEIC ACIDS RES, V24, P21, DOI 10.1093/nar/24.1.21; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 2004, BIOCHEM BIOPH RES CO, V316, P636, DOI 10.1016/j.bbrc.2004.02.098; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2004, J PROTEOME RES, V3, P856, DOI 10.1021/pr049931q; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, BIOCHEM BIOPH RES CO, V319, P433, DOI 10.1016/j.bbrc.2004.05.016; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2004, J CELL BIOCHEM, V91, P1197, DOI 10.1002/jcb.10790; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; Chou KC, 2004, J PROTEOME RES, V3, P1284, DOI 10.1021/pr049849v; CHOU KC, 1988, BIOPHYS CHEM, V30, P3, DOI 10.1016/0301-4622(88)85002-6; CORNETTE JL, 1987, J MOL BIOL, V195, P659, DOI 10.1016/0022-2836(87)90189-6; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Fasman G.D., 1976, HDB BIOCH MOL BIOL; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Garian R, 2001, BIOINFORMATICS, V17, P551, DOI 10.1093/bioinformatics/17.6.551; Glaser F, 2001, PROTEINS, V43, P89, DOI 10.1002/1097-0134(20010501)43:2<89::AID-PROT1021>3.3.CO;2-8; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Jones S, 1997, J MOL BIOL, V272, P133, DOI 10.1006/jmbi.1997.1233; Jones S, 1997, J MOL BIOL, V272, P121, DOI 10.1006/jmbi.1997.1234; Kuncheva LI, 2002, IEEE T SYST MAN CY B, V32, P146, DOI 10.1109/3477.990871; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; MEEK JL, 1981, J CHROMATOGR, V211, P15, DOI 10.1016/S0021-9673(00)81169-3; MUSKAL SM, 1992, J MOL BIOL, V225, P713, DOI 10.1016/0022-2836(92)90396-2; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Oxenoid K, 2005, P NATL ACAD SCI USA, V102, P10870, DOI 10.1073/pnas.0504920102; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; ROBSON B, 1979, J MOL BIOL, V132, P19, DOI 10.1016/0022-2836(79)90494-7; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; SHUICHI K, 1999, NUCLEIC ACIDS RES, V27, P368; SNEATH PHA, 1966, J THEOR BIOL, V12, P157, DOI 10.1016/0022-5193(66)90112-3; Tomii K, 1996, PROTEIN ENG, V9, P27, DOI 10.1093/protein/9.1.27; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V., 1995, NATURE STAT LEARNING; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Xiao X, 2005, AMINO ACIDS, V28, P29, DOI 10.1007/s00726-004-0154-9; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Xiao ZJ, 2006, LEUKEMIA RES, V30, P54, DOI 10.1016/j.leukres.2005.05.012; Zhang CT, 1998, FEBS LETT, V440, P153, DOI 10.1016/S0014-5793(98)01433-1; Zhang SW, 2003, BIOINFORMATICS, V19, P2390, DOI 10.1093/bioinformatics/btg331; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	61	102	104	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0939-4451			AMINO ACIDS	Amino Acids	JUN	2006	30	4					461	468		10.1007/s00726-006-0263-8		8	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	053FZ	WOS:000238292300014	
J	Raychaudhuri, S; Chang, JT; Sutphin, PD; Altman, RB				Raychaudhuri, S; Chang, JT; Sutphin, PD; Altman, RB			Associating genes with gene ontology codes using a maximum entropy analysis of biomedical literature	GENOME RESEARCH			English	Article							SINGLE-NUCLEOTIDE POLYMORPHISMS; SACCHAROMYCES-CEREVISIAE; GENOME SEQUENCE; DATABASE; BIOLOGY; TOOL; PROTEINS; PATTERNS; PRODUCTS	Functional characterizations of thousands of gene products from many species are described in the published literature. These discussions are extremely Valuable for characterizing the functions not only of these gene products, but also of their homologs in other organisms. The Gene Ontology (GO) is ail effort to create a controlled terminology for labeling gene functions in a more precise, reliable, computer-readable manner. Currently, the best annotations of gene function with the GO are performed by highly trained biologists who read the literature and select appropriate codes. In this study, we explored the possibility that statistical natural language processing techniques can be used to assign GO codes. We compared three document classification methods (maximum entropy modeling, naive Bayes classification, and nearest-neighbor classification) to the problem of associating a set of GO codes (for biological process) to literature abstracts and thus to the genes associated with the abstracts. We showed that maximum entropy modeling outperforms the other methods and achieves ail accuracy of 72% when ascertaining the function discussed within ail abstract. The maximum entropy method provides confidence measures that correlate well with performance. We conclude that statistical methods may be used to assign GO codes and may be useful for the difficult task of reassignment as terminology standards evolve over time.	Stanford Univ, Dept Genet, Stanford, CA 94305 USA; Stanford Univ, Dept Radiat Oncol, Stanford, CA 94305 USA	Altman, RB (reprint author), Stanford Med Informat, 251 Campus Dr,MSOB X-215, Stanford, CA 94305 USA.						Adams MD, 2000, SCIENCE, V287, P2185, DOI 10.1126/science.287.5461.2185; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; ANDRADE MA, 1997, ISMB, V5, P25; Ashburner M, 2000, NAT GENET, V25, P25; BACHRACH CA, 1978, MED INFORM, V3, P237; Bairoch A, 1999, NUCLEIC ACIDS RES, V27, P49, DOI 10.1093/nar/27.1.49; Cargill M, 1999, NAT GENET, V22, P231; Chee M, 1996, SCIENCE, V274, P610, DOI 10.1126/science.274.5287.610; Cherry JM, 1998, NUCLEIC ACIDS RES, V26, P73, DOI 10.1093/nar/26.1.73; Cole ST, 1998, NATURE, V393, P537; CRAVEN M, 1999, P INT C INT SYST MOL, V10, P77; Eisenhaber F, 1999, BIOINFORMATICS, V15, P528, DOI 10.1093/bioinformatics/15.7.528; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; FUNK ME, 1983, B MED LIBR ASSOC, V71, P176; Halushka MK, 1999, NAT GENET, V22, P239; HISHIKI T, 1998, GEN INF WORKSH, V9, P81; Horton P, 1997, INTELLIGENT SYSTEMS, V5, P147; Huang JY, 2001, NUCLEIC ACIDS RES, V29, P202, DOI 10.1093/nar/29.1.202; HUTCHINSON D, 1998, MEDLINE HLTH PROFESS; KERNIGHAN BW, 1988, C PROGRAMMING LANGUA, V2; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; LUTZ M, 1999, LEARNING PHYTON HELP, V1; Manning C.D., 1999, FDN STAT NATURAL LAN; Martzen MR, 1999, SCIENCE, V286, P1153, DOI 10.1126/science.286.5442.1153; Mewes HW, 2000, NUCLEIC ACIDS RES, V28, P37, DOI 10.1093/nar/28.1.37; Ng SK, 1999, GENOME INFORM SER WO, V10, P104; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; Proux D, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P279; RATNAPARKHI A, 1997, SIMPLE INTRO MAXIMUM, P97; RILEY M, 1993, MICROBIOL REV, V57, P862; Roberts RJ, 2001, SCIENCE, V291, P2318; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Ross-Macdonald P, 1999, NATURE, V402, P413; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; SCHWARTZ RL, 1997, LEARNING PERL, V2; Shatkay H, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P317; STEPHENS M, 2001, P S BIOC, V52, P483; Tamames J, 1998, BIOINFORMATICS, V14, P542, DOI 10.1093/bioinformatics/14.6.542; THOMAS J, 2000, P S BIOC, V1, P541; Tissier AF, 1999, PLANT CELL, V11, P1841, DOI 10.1105/tpc.11.10.1841; Uetz P, 2000, NATURE, V403, P623; Winzeler EA, 1999, SCIENCE, V285, P901, DOI 10.1126/science.285.5429.901	42	100	101	COLD SPRING HARBOR LAB PRESS	PLAINVIEW	1 BUNGTOWN RD, PLAINVIEW, NY 11724 USA	1088-9051			GENOME RES	Genome Res.	JAN	2002	12	1					203	214		10.1101/gr.199701		12	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	508AN	WOS:000173064900022	
J	Wang, Y; Tetko, IV; Hall, MA; Frank, E; Facius, A; Mayer, KFX; Mewes, HW				Wang, Y; Tetko, IV; Hall, MA; Frank, E; Facius, A; Mayer, KFX; Mewes, HW			Gene selection from microarray data for cancer classification - a machine learning approach	COMPUTATIONAL BIOLOGY AND CHEMISTRY			English	Article						microarray; gene selection; machine learning; cancer classification; feature selection	DIFFERENTIALLY EXPRESSED GENES; TUMOR-SUPPRESSOR; ZYXIN; IDENTIFICATION; PATTERNS; PROFILES; PROTEINS; TARGETS; CELLS	A DNA microarray can track the expression levels of thousands of genes simultaneously. Previous research has demonstrated that this technology can be useful in the classification of cancers. Cancer microarray data normally contains a small number of samples which have a large number of gene expression levels as features. To select relevant genes involved in different types of cancer remains a challenge. In order to extract useful gene information from cancer microarray data and reduce dimensionality, feature selection algorithms were systematically investigated in this study. Using a correlation-based feature selector combined with machine learning algorithms such as decision trees, naive Bayes and support vector machines, we show that classification performance at least as good as published results can be obtained on acute leukemia and diffuse large B-cell lymphoma microarray data sets. We also demonstrate that a combined use of different classification and feature selection approaches makes it possible to select relevant genes with high confidence. This is also the first paper which discusses both computational and biological evidence for the involvement of zyxin in leukaemogenesis. (c) 2004 Elsevier Ltd. All rights reserved.	German Res Ctr Environm & Hlth, Inst Bioinformat, D-85764 Neuherberg, Germany; Univ Waikato, Dept Comp Sci, Hamilton, New Zealand; Tech Univ Munich, Wissenschaftszentrum Weihenstephan, Dept Genome Oriented Bioinformat, D-85354 Freising Weihenstephan, Germany	Wang, Y (reprint author), German Res Ctr Environm & Hlth, Inst Bioinformat, Ingolstadter Landstr 1, D-85764 Neuherberg, Germany.	yu.wang@gsf.de	Tetko, Igor/B-1540-2010; Frank, Eibe/A-1434-2008	Tetko, Igor/0000-0002-6855-0012; 			Agathanggelou A, 2003, CANCER RES, V63, P5344; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Antoniadis A, 2003, BIOINFORMATICS, V19, P563, DOI 10.1093/bioinformatics/btg062; Antonov AV, 2004, BIOINFORMATICS, V20, P644, DOI 10.1093/bioinformatics/btg462; CRAWFORD AW, 1991, J BIOL CHEM, V266, P5847; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hall M.A., 1999, THESIS U WAIKATO; Harada K, 2002, ONCOGENE, V21, P4345, DOI 10.1038/sj.onc.1205446; HERO A, 2003, P INT C SIGN PROC AP; Hirota T, 2000, J CELL BIOL, V149, P1073, DOI 10.1083/jcb.149.5.1073; Hwang DH, 2002, BIOINFORMATICS, V18, P1184, DOI 10.1093/bioinformatics/18.9.1184; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kononenko I., 1994, EUR C MACH LEARN, P171; Langley P., 1994, P AAAI FALL S REL, P140; Li JY, 2003, BIOINFORMATICS, V19, pII93, DOI 10.1093/bioinformatics/btg1066; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li W, 2002, METHODS MICROARRAY D, P137; Platt J. C., 1998, ADV KERNEL METHODS S; Press W. H., 1988, NUMERICAL RECIPES C; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Salgia R, 1996, J BIOL CHEM, V271, P25198; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Tavor S, 2003, J BIOL CHEM, V278, P52651, DOI 10.1074/jbc.M307077200; Thomas JG, 2001, GENOME RES, V11, P1227, DOI 10.1101/gr.165101; Tsai CA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng052; van der Gaag EJ, 2002, J INVEST DERMATOL, V118, P246, DOI 10.1046/j.0022-202x.2001.01657.x; Vapnik V., 1998, STAT LEARNING THEORY; Wang Y, 2003, BBA-MOL CELL RES, V1593, P115, DOI 10.1016/S0167-4889(02)00349-X; Witten I.H., 1999, DATA MINING PRACTICA; XING EP, 2001, P 18 INT C MACH LEAR; Xiong MM, 2001, GENOME RES, V11, P1878; Yagi T, 2003, BLOOD, V102, P1849, DOI 10.1182/blood-2003-02-0578; Yi JS, 2002, J BIOL CHEM, V277, P9580, DOI 10.1074/jvc.M106922200	38	96	103	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1476-9271			COMPUT BIOL CHEM	Comput. Biol. Chem.	FEB	2005	29	1					37	46		10.1016/j.compbiolchem.2004.11.001		10	Biology; Computer Science, Interdisciplinary Applications	Life Sciences & Biomedicine - Other Topics; Computer Science	905ZV	WOS:000227611200004	
J	Inza, I; Larranaga, P; Etxeberria, R; Sierra, B				Inza, I; Larranaga, P; Etxeberria, R; Sierra, B			Feature Subset Selection by Bayesian network-based optimization	ARTIFICIAL INTELLIGENCE			English	Article						machine learning; supervised learning; Feature Subset Selection; wrapper; predictive accuracy; Estimation of Distribution Algorithm; Estimation of Bayesian Network Algorithm; Bayesian network; overfitting	CLASSIFICATION LEARNING ALGORITHMS; DESCRIPTION LENGTH PRINCIPLE; GENETIC ALGORITHMS; CONTROL PARAMETERS; DECISION TREES; PERFORMANCE	A new method for Feature Subset Selection in machine learning, FSS-EBNA (Feature Subset Selection by Estimation of Bayesian Network Algorithm), is presented. FSS-EBNA is an evolutionary, population-based, randomized search algorithm, and it can be executed when domain knowledge is not available. A wrapper approach, over Naive-Bayes and ID3 learning algorithms, is used to evaluate the goodness of each visited solution. FSS-EBNA, based on the EDA (Estimation of Distribution Algorithm) paradigm, avoids the use of crossover and mutation operators to evolve the populations, in contrast to Genetic Algorithms. In absence of these operators, the evolution is guaranteed by the factorization of the probability distribution of the best solutions found in a generation of the search. This factorization is carried out by means of Bayesian networks. Promising results are achieved in a variety of tasks where domain knowledge is not available. The paper explains the main ideas of Feature Subset Selection, Estimation of Distribution Algorithm and Bayesian networks, presenting related work about each concept. A study about the 'overfitting' problem in the Feature Subset Selection process is carried out, obtaining a basis to define the stopping criteria of the new algorithm. (C) 2000 Elsevier Science B.V. All rights reserved.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, E-20080 San Sebastian, Basque Country, Spain	Inza, I (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, POB 649, E-20080 San Sebastian, Basque Country, Spain.		Larranaga, Pedro/F-9293-2013				AHA DW, 1999, COMMUNICATION; Aha D.W., 1994, P AAAI 94 WORKSH CAS, P106; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; Bala J., 1995, P 14 INT JOINT C ART, P719; Baluja S., 1997, P 14 INT C MACH LEAR, P30; Baluja S., 1994, CMUCS94163; Ben-Bassat M., 1982, HDB STATISTICS, V1, P773, DOI 10.1016/S0169-7161(82)02038-0; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BODDY M, 1994, ARTIF INTELL, V67, P245, DOI 10.1016/0004-3702(94)90054-X; Bouckaert R. R., 1994, P 10 C UNC ART INT S, P102; Boyce D. E., 1974, OPTIMAL SUBSET SELEC; Breiman L., 1984, CLASSIFICATION REGRE; Buntine W., 1991, P 7 C UNC ART INT, P52; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Caruana R., 1994, P 11 INT C MACH LEAR, P28; CASTILLO E, 1997, EXPERT SYSTEMS PROB; Cestnik B, 1990, P EUR C ART INT, P147; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; Chickering D., 1995, 5 INT WORKSH ART INT, P112; Chickering D.M., 1994, MSRTR9417 MICR CORP; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1; DEBONET JS, 1997, ADV NEURAL INFORMATI; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Doak J., 1992, CSE9218 U CAL; Etxeberria R, 1997, PATTERN RECOGN LETT, V18, P1269, DOI 10.1016/S0167-8655(97)00106-2; Etxeberria R., 1999, P 2 S ART INT CIMAF, P332; FERRI FJ, 1993, P IEE IEEE WORKSH NA; FERRI FJ, 1994, MULTIPLE PARADIGMS C, P403; Friedman N., 1996, P 12 C UNC ART INT, P274; GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288; HARIK GR, 1997, 97006 U ILL ILL GEN; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Henrion M., 1988, UNCERTAINTY ARTIFICI, V2, P149; HOLLAND JH, 1975, ADAPTATION NATURAL A; INZA I, 1999, P STUD SESS ADV COUR, P33; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; John G., 1994, P 11 INT C MACH LEAR, P121; Kira K, 1992, P 10 NAT C ART INT, P129; Kittler J., 1978, Pattern Recognition and Signal Processing; KOHAVI R, 1994, P AAAI FALL S REL, P122; Kohavi R., 1995, P 1 INT C KNOWL DISC, P192; KOHAVI R, 1999, COMMUNICATION; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; Koller D., 1996, P 13 INT C MACH LEAR, P284; KUNCHEVA L, 1993, INFORM PROCESS LETT, V46, P163, DOI 10.1016/0020-0190(93)90021-Z; Langley P., 1994, P 10 C UNC ART INT, P399; LARRANAGA P, 1999, P 2 S ART INT CIMAF, P314; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; Lauritzen S. L., 1996, GRAPHICAL MODELS; Liu H., 1996, P 9 INT C IND ENG AP, P284; Liu H., 1998, FEATURE SELECTION KN; Liu HA, 1998, APPL INTELL, V9, P217, DOI 10.1023/A:1008363719778; Madigan D., 1996, P AAAI WORKSH INT MU, P77; MENDENHALL W, 1998, STAT ENG SCI; Miller A. J., 1990, SUBSET SELECTION REG; Mladenic D., 1998, P 10 EUR C MACH LEAR, P95; Moore A., 1994, P 11 INT C MACH LEAR, P190; Muhlenbein H., 1996, LECT NOTES COMPUTER, V1141, P178; Muhlenbein H, 1997, EVOL COMPUT, V5, P303, DOI 10.1162/evco.1997.5.3.303; Muhlenbein H, 1999, J HEURISTICS, V5, P215, DOI 10.1023/A:1009689913453; Murphy P. M., 1995, UCI REPOSITORY MACHI; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Ng AY, 1997, P 14 INT C MACH LEAR, P245; Pearl J., 1988, PROBABILISTIC REASON; PELIKAN M, 1999, UNPUB BIVARIATE MARG; PELIKAN M, 1999, 99003 U ILL ILL GEN; PELIKAN M, 1999, 99018 U ILL ILL GEN; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan J.R., 1993, PROGRAMS MACHINE LEA; QUINLAN JR, 1989, INFORM COMPUT, V80, P227; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Stearns SD, 1976, P 3 INT C PATT REC C, P71; SYSWERDA G, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P2; TAYLOR C, 1994, MACHINE LEARNING NEU; Vafaie H., 1993, Proceedings. Fifth International Conference on Tools with Artificial Intelligence TAI '93 (Cat. No.93CH3325-8), DOI 10.1109/TAI.1993.633981; Wong ML, 1999, IEEE T PATTERN ANAL, V21, P174; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; Yang Y., 1997, P 14 INT C MACH LEAR, P412	88	90	91	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702			ARTIF INTELL	Artif. Intell.	OCT	2000	123	1-2					157	184		10.1016/S0004-3702(00)00052-7		28	Computer Science, Artificial Intelligence	Computer Science	373ZQ	WOS:000165320300005	
J	Kumar, A; Zhang, D				Kumar, Ajay; Zhang, David			Personal recognition using hand shape and texture	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article						biometrics; feature level fusion; feature subset selection and combination; hand-shape recognition; palmprint recognition	IDENTIFICATION; BIOMETRICS; VERIFICATION; FUSION	This paper proposes a new bimodal biometric system using feature-level fusion of hand shape and palm texture. The proposed combination is of significance since both the palmprint and hand-shape images are proposed to be extracted from the single hand image acquired from a digital camera. Several new hand-shape features that can be used to represent the hand shape and improve the performance are investigated. The new approach for palmprint recognition using discrete cosine transform coefficients, which can be directly obtained from the camera hardware, is demonstrated. None of the prior work on hand-shape or palmprint recognition has given any attention on the critical issue of feature selection. Our experimental results demonstrate that while majority of palmprint or hand-shape features are useful in predicting the subjects identity, only a small subset of these features are necessary in practice for building an accurate model for identification. The comparison and combination of proposed features is evaluated on the diverse classification schemes; naive Bayes (normal, estimated, multinomial), decision trees (C4.5, LMT), k-NN, SVM, and FFN. Although more work remains to be done, our results to date indicate that the combination of selected hand-shape and palmprint features constitutes a promising addition to the biometrics-based personal recognition systems.	Indian Inst Technol, Dept Elect Engn, New Delhi 110016, India; Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China	Kumar, A (reprint author), Indian Inst Technol, Dept Elect Engn, New Delhi 110016, India.	ajaykr@ieee.org; csdzhang@comp.polyu.edu.hk					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Cristianini N., 2001, INTRO SUPPORT VECTOR; ELBADAWY O, 2002, INT J IMAGE GRAPHICS, V2, P375, DOI 10.1142/S021946780200069X; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hall MA, 1998, AUST COMP S, V20, P181; HALL MA, 2000, 7 INT C MACH LEARN S; HARALICK RM, 1991, COMPUTER VISION ROBO; Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Jain A. K., 1999, P 2 INT C AUD VID BA, P166; Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349; JOHN GH, 2000, 11 C UNC ART INT; KIM SB, 2002, P SIGIR TAMP FINL AU, P391; KUMAR A, 2003, P 4 INT C AUD VID BA, P668; KUMAR A, 2005, P AVBPA NEW YORK JUL, P813; Landwehr N, 2003, LECT NOTES ARTIF INT, V2837, P241; Lu X., 2003, PATTERN RECOGN, V24, P2829; Mccallum A., 1998, AAAI WORKSH LEARN TE; Oden C, 2003, PATTERN RECOGN LETT, V24, P2145, DOI 10.1016/S0167-8655(03)00087-4; Otsu N., 1978, IEEE T SYST MAN CYB, VSMC-8, P62; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Riedmiller M, 1993, P IEEE INT C NEUR NE, V1, P586, DOI DOI 10.1109/ICNN.1993.298623; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; Russ JC, 1999, IMAGE PROCESSING HDB; Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796; Toh KA, 2004, IEEE T SYST MAN CY B, V34, P1196, DOI 10.1109/TSMCB.2003.821868; Vapnik V., 1998, STAT LEARNING THEORY; Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805; Wang ZH, 1999, IEEE T CIRCUITS-II, V46, P617; Witten I.H., 1999, DATA MINING PRACTICA; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008	33	85	91	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1057-7149			IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	AUG	2006	15	8					2454	2461		10.1109/TIP.2006.875214		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	067FJ	WOS:000239286900032	
J	Zheng, ZJ; Webb, GI				Zheng, ZJ; Webb, GI			Lazy learning of Bayesian rules	MACHINE LEARNING			English	Article						Bayesian classification; semi-naive Bayesian classification; decision trees; decision rules; lazy learning		The naive Bayesian classifier provides a simple and effective approach to classifier learning, but its attribute independence assumption is often violated in the real world. A number of approaches have sought to alleviate this problem. A Bayesian tree learning algorithm builds a decision tree, and generates a local naive Bayesian classifier at each leaf. The tests leading to a leaf can alleviate attribute inter-dependencies for the local naive Bayesian classifier. However, Bayesian tree learning still suffers from the small disjunct problem of tree learning. While inferred Bayesian trees demonstrate low average prediction error rates, there is reason to believe that error rates will be higher for those leaves with few training examples. This paper proposes the application of lazy learning techniques to Bayesian tree induction and presents the resulting lazy Bayesian rule learning algorithm, called LBR. This algorithm can be justified by a variant of Bayes theorem which supports a weaker conditional attribute independence assumption than is required by naive Bayes. For each test example, it builds a most appropriate rule with a local naive Bayesian classifier as its consequent. It is demonstrated that the computational requirements of LBR are reasonable in a wide cross-section of natural domains. Experiments with these domains show that, on average, this new algorithm obtains lower error rates significantly more often than the reverse in comparison to a naive Bayesian classifier, C4.5, a Bayesian tree learning algorithm, a constructive Bayesian classifier that eliminates attributes and constructs new attributes using Cartesian products of existing nominal attributes, and a lazy decision tree learning algorithm. It also outperforms, although the result is not statistically significant, a selective naive Bayesian classifier.	Deakin Univ, Sch Comp & Math, Geelong, Vic 3217, Australia	Zheng, ZJ (reprint author), Deakin Univ, Sch Comp & Math, Geelong, Vic 3217, Australia.	zijian@deakin.edu.au; webb@deakin.edu.au	Webb, Geoffrey/A-1347-2008				Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C. L., 1998, UCI RESPOSITORY MACH; Breiman L., 1984, CLASSIFICATION REGRE; BRIAND LC, 1992, IEEE T SOFTWARE ENG, V18, P931, DOI 10.1109/32.177363; Cestnik B, 1990, P EUR C ART INT, P147; Cestnik B., 1987, PROGR MACHINE LEARNI, P31; CHATFIELD C, 1978, STAT TECHNOLOGY COUR; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; Fulton T, 1996, P 2 INT C KNOWL DISC, P14; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Geiger D., 1992, P 8 C UNC AI, P92; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Holte R.C., 1989, P 11 INT JOINT C ART, P813; John G., 1994, P 11 INT C MACH LEAR, P121; Kittler J., 1986, HDB PATTERN RECOGNIT, P59; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; Kononenko I., 1990, CURRENT TRENDS KNOWL; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; KUBAT M, 1993, P 8 EUR C MACH LEARN, P366; Langley P., 1993, P 1993 EUR C MACH LE, P153; Langley P., 1994, P 10 C UNC ART INT, P339; Langley P., 1992, P 10 NAT C ART INT, P223; Pazzani M. J., 1996, Proceedings ofthe Conference, ISIS '96. Information, Statistics and Induction in Science; Pearl J., 1988, PROBABILISTIC REASON; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; Sahami M., 1996, P 2 INT C KNOWL DISC, P334; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Singh M, 1995, P 12 INT C MACH LEAR, P497; Singh M., 1996, P 13 INT C MACH LEAR, P453; TING KM, 1994, 491 U SYDN BASS DEP; Ting K.M., 1994, P 10 CAN C ART INT, P91; VISWANATHAN M, 1998, P 10 EUR C MACH LEAR, P149; Webb G I, 1998, P 11 AUSTR JOINT C A, P285; Webb G. I., 1996, Proceedings ofthe Conference, ISIS '96. Information, Statistics and Induction in Science; Wolpert D. H., 1994, MATH GEN	47	85	98	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	OCT	2000	41	1					53	84		10.1023/A:1007613203719		32	Computer Science, Artificial Intelligence	Computer Science	342PL	WOS:000088654300003	
J	Azzaoui, K; Hamon, J; Faller, B; Whitebread, S; Jacoby, E; Bender, A; Jenkins, JL; Urban, L				Azzaoui, Kamal; Hamon, Jacques; Faller, Bernard; Whitebread, Steven; Jacoby, Edgar; Bender, Andreas; Jenkins, Jeremy L.; Urban, Laszlo			Modeling promiscuity based on in vitro safety pharmacology profiling data	CHEMMEDCHEM			English	Article							BIOACTIVE REFERENCE STRUCTURES; DRUG DISCOVERY; TARGET-FAMILY; DESIGN; PREDICTION; INHIBITORS	This study describes a method for mining and modeling binding data obtained from a large panel of targets (in vitro safety pharmacology) to distinguish differences between promiscuous and selective compounds. Two naive Bayes models for promiscuity and selectivity were generated and validated on a test set as well as publicly available drug databases. The model shows a higher score (lower promiscuity) for marketed drugs than for compounds in early development or compounds that failed during clinical development. Such models can be used in triaging high-throughput screening data or for lead optimization.		Azzaoui, K (reprint author), Novartis Pharma AG, Novartis Inst Biomed Res, CPC LFP MLI, CH-4002 Basel, Switzerland.	kamal.azzaoui@novartis.com	Bender, Andreas/C-6942-2009	Bender, Andreas/0000-0002-6683-7546			Bender A, 2007, CHEMMEDCHEM, V2, P861, DOI 10.1002/cmdc.200700026; De Ponti F, 2000, EUR J CLIN PHARMACOL, V56, P1, DOI 10.1007/s002280050714; Espinoza-Fonseca LM, 2006, BIOORGAN MED CHEM, V14, P896, DOI 10.1016/j.bmc.2005.09.011; Fliri AF, 2005, NAT CHEM BIOL, V1, P389, DOI 10.1038/nchembio747; Glick M, 2006, J CHEM INF MODEL, V46, P193, DOI 10.1021/ci050374h; Glick M., 2006, J CHEM INF MODEL, V46, P1124; Hamon J, 2006, EUR PHARM REV, V1, P60; Hampton T, 2004, JAMA-J AM MED ASSOC, V292, P419, DOI 10.1001/jama.292.4.419; Hann MM, 2001, J CHEM INF COMP SCI, V41, P856, DOI 10.1021/ci000403i; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; Hopkins AL, 2006, CURR OPIN STRUC BIOL, V16, P127, DOI 10.1016/j.sbi.2006.01.013; Jacoby E, 2005, CURR TOP MED CHEM, V5, P397, DOI 10.2174/1568026053828376; Keiser MJ, 2007, NAT BIOTECHNOL, V25, P197, DOI 10.1038/nbt1284; Kola I, 2004, NAT REV DRUG DISCOV, V3, P711, DOI 10.1038/nrd1470; McGovern SL, 2002, J MED CHEM, V45, P1712, DOI 10.1021/jm010533y; Mencher Simon K, 2005, BMC Clin Pharmacol, V5, P3, DOI 10.1186/1472-6904-5-3; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Morphy R, 2006, J MED CHEM, V49, P2969, DOI 10.1021/jm0512185; Paolini GV, 2006, NAT BIOTECHNOL, V24, P805, DOI 10.1038/nbt1228; Roche O, 2002, J MED CHEM, V45, P137, DOI 10.1021/jm010934d; Rolland C, 2005, J MED CHEM, V48, P6563, DOI 10.1021/jm0500673; Roth BL, 2004, NAT REV DRUG DISCOV, V3, P353, DOI 10.1038/nrd1346; Rothman RB, 2000, CIRCULATION, V102, P2836; Schnur DM, 2006, J MED CHEM, V49, P2000, DOI 10.1021/jm0502900; Stephenson VC, 2005, FEBS LETT, V579, P1338, DOI 10.1016/j.febslet.2005.01.019; Whitebread S, 2005, DRUG DISCOV TODAY, V10, P1421, DOI 10.1016/S1359-6446(05)03632-9; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Zhu BY, 2006, BIOORG MED CHEM LETT, V16, P5507, DOI 10.1016/j.bmcl.2006.08.039	29	81	82	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1860-7179			CHEMMEDCHEM	ChemMedChem	JUN	2007	2	6					874	880		10.1002/cmdc.200700036		7	Chemistry, Medicinal; Pharmacology & Pharmacy	Pharmacology & Pharmacy	180UY	WOS:000247392900014	
J	Yang, YM; Slattery, S; Ghani, R				Yang, YM; Slattery, S; Ghani, R			A study of approaches to hypertext categorization	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						hypertext classification; machine learning; web mining; text mining	TEXT	Hypertext poses new research challenges for text classification. Hyperlinks, HTML tags, category labels distributed over linked documents, and meta data extracted from related Web sites all provide rich information for classifying hypertext documents. How to appropriately represent that information and automatically learn statistical patterns for solving hypertext classification problems is an open question. This paper seeks a principled approach to providing the answers. Specifically, we define five hypertext regularities which may (or may not) hold in a particular application domain, and whose presence (or absence) may significantly influence the optimal design of a classifier. Using three hypertext datasets and three well-known learning algorithms (Naive Bayes, Nearest Neighbor, and First Order Inductive Learner), we examine these regularities in different domains, and compare alternative ways to exploit them. Our results show that the identification of hypertext regularities in the data and the selection of appropriate representations for hypertext in particular domains are crucial, but seldom obvious, in real-world problems. We find that adding the words in the linked neighborhood to the page having those links (both inlinks and outlinks) were helpful for all our classifiers on one data set, but more harmful than helpful for two out of the three classifiers on the remaining datasets. We also observed that extracting meta data from related Web sites was extremely useful for improving classification accuracy in some of those domains. Finally, the relative performance of the classifiers being tested provided insights into their strengths and limitations for solving classification problems involving diverse and often noisy Web pages.	Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; Accenture Technol Labs Res, Northbrook, IL 60062 USA	Yang, YM (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.						Chakrabarti S., 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; COHEN W, 1995, ADV INDUCTIVE LOGIC; COHEN W, 2000, 17 INT C MACH LEARN; COHEN WW, 1995, ADV INDUCTIVE LOGIC, P124; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; CRAVEN M, 1998, 10 EUR C MACH LEARN; Dasarathy B., 1991, MCGRAWHILL COMPUTER; Dumais Susan T., 2000, P ACM SIGCHI C HUM F, P145, DOI 10.1145/332040.332418; FREITAG D, 1998, P 15 INT C MACH LEAR, P161; Furnkranz J, 1999, LECT NOTES COMPUT SC, V1642, P487; GHANI R, 2001, P ICML 01 18 INT C M; GHANI R, 2000, WORKSH TEXT MIN 6 AC; JOACHIMS T, 2001, P ICML 01 18 INT C M; Joachims T., 1998, LNCS, V1398, P137; Kleinberg J.M., 1998, P 9 ANN ACM SIAM S D; Lewis D., 1998, LECT NOTES COMPUTER, V1398, P4, DOI DOI 10.1007/BFB0026666; McCallum A, 1998, AAAI 98 WORKSH LEARN; Oh H. J., 2000, P 23 ANN INT ACM SIG, P264, DOI 10.1145/345508.345594; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SLATTERY S, 2000, P ICML 00 17 INT C M; SLATTERY S, 2001, THESIS CARNEGIE MELL; SLATTERY S, 1998, P 8 INT C IND LOG PR; Van Rijsbergen C.J., 1979, INFORMATION RETRIEVA; Yang Y., 1994, P 17 ANN INT ACM SIG, P13; Yang Y., 2001, P 24 ANN INT ACM SIG, P137, DOI 10.1145/383952.383975; Yang Y., 2000, P 17 INT C MACH LEAR, P1167; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Yang Y, 1999, J INFORMATION RETRIE, V1, P69	29	80	95	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902			J INTELL INF SYST	J. Intell. Inf. Syst.	MAR-MAY	2002	18	2-3					219	241		10.1023/A:1013685612819		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	508XA	WOS:000173114000007	
J	Yousef, M; Nebozhyn, M; Shatkay, H; Kanterakis, S; Showe, LC; Showe, MK				Yousef, M; Nebozhyn, M; Shatkay, H; Kanterakis, S; Showe, LC; Showe, MK			Combining multi-species genomic data for microRNA identification using a Naive Bayes classifier	BIOINFORMATICS			English	Article							CAENORHABDITIS-ELEGANS/; REGULATORY MOTIFS; SEQUENCE; GENES; PREDICTION; RNAS; ALIGNMENT	Motivation: Most computational methodologies for microRNA gene prediction utilize techniques based on sequence conservation and/or structural similarity. In this study we describe a new technique, which is applicable across several species, for predicting miRNA genes. This technique is based on machine learning, using the Naive Bayes classifier. It automatically generates a model from the training data, which consists of sequence and structure information of known miRNAs from a variety of species. Results: Our study shows that the application of machine learning techniques, along with the integration of data from multiple species is a useful and general approach for miRNA gene prediction. Based on our experiments, we believe that this new technique is applicable to an extensive range of eukaryotes' genomes. Specific structure and sequence features are first used to identify miRNAs followed by a comparative analysis to decrease the number of false positives (FPs). The resulting algorithm exhibits higher specificity and similar sensitivity compared to currently used algorithms that rely on conserved genomic regions to decrease the rate of FPs.	Wistar Inst Anat & Biol, Philadelphia, PA 19104 USA; Queens Univ, Sch Comp, Kingston, ON, Canada	Showe, MK (reprint author), Wistar Inst Anat & Biol, Philadelphia, PA 19104 USA.	showe@wistar.org					Ambros V, 2003, RNA, V9, P277, DOI 10.1261/rna.2183803; Bartel DP, 2004, CELL, V116, P281, DOI 10.1016/S0092-8674(04)00045-5; Grad Y, 2003, MOL CELL, V11, P1253, DOI 10.1016/S1097-2765(03)00153-9; Griffen TD, 2004, J INDO-EUR STUD, V32, P11; Griffiths-Jones S, 2006, NUCLEIC ACIDS RES, V34, pD140, DOI 10.1093/nar/gkj112; Japkowicz N., 2002, Intelligent Data Analysis, V6; Kent WJ, 2002, GENOME RES, V12, P656, DOI [10.1101/gr.229202, 10.1101/gr.229202. Article published online before March 2002]; Kent WJ, 2002, GENOME RES, V12, P996, DOI 10.1101/gr.229102; Lagos-Quintana M, 2001, SCIENCE, V294, P853, DOI 10.1126/science.1064921; Lai EC, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r42; Lau NC, 2001, SCIENCE, V294, P858, DOI 10.1126/science.1065062; Lee RC, 2001, SCIENCE, V294, P862, DOI 10.1126/science.1065329; Lim LP, 2003, GENE DEV, V17, P991, DOI 10.1101/gad.1074403; Lim LP, 2003, SCIENCE, V299, P1540, DOI 10.1126/science.1080372; Mathews DH, 1999, J MOL BIOL, V288, P911, DOI 10.1006/jmbi.1999.2700; McCallum A. K., 1996, BOW TOOLKIT STAT LAN; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Mignone F, 2005, NUCLEIC ACIDS RES, V33, pD141; MITCHELL T, 1997, MACHINE LEARNING, pCH10; Nam JW, 2005, NUCLEIC ACIDS RES, V33, P3570, DOI 10.1093/nar/gki668; Pasquinelli AE, 2000, NATURE, V408, P86, DOI 10.1038/35040556; SAHAMI M, 1996, P 13 INT C MACH LEAR, P284; Wang XW, 2005, BIOINFORMATICS, V21, P3610, DOI 10.1093/bioinformatics/bti562; Weber MJ, 2005, FEBS J, V272, P59, DOI 10.1111/j.1432-1033.2004.04389.x; Xie XH, 2005, NATURE, V434, P338, DOI 10.1038/nature03441; Zuker M, 2003, NUCLEIC ACIDS RES, V31, P3406, DOI 10.1093/nar/gkg595	26	77	86	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JUN 1	2006	22	11					1325	1334		10.1093/bioinformatics/bt/094		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	054DJ	WOS:000238356700007	
J	Sakkis, G; Androutsopoulos, I; Paliouras, G; Karkaletsis, V; Spyropoulos, CD; Stamatopoulos, P				Sakkis, G; Androutsopoulos, I; Paliouras, G; Karkaletsis, V; Spyropoulos, CD; Stamatopoulos, P			A memory-based approach to anti-spam filtering for mailing lists	INFORMATION RETRIEVAL			English	Article						text categorization; machine learning; unsolicited commercial e-mail; spam	LEARNING ALGORITHMS; TEXT CATEGORIZATION; CLASSIFICATION	This paper presents an extensive empirical evaluation of memory-based learning in the context of anti-spam filtering, a novel cost-sensitive application of text categorization that attempts to identify automatically unsolicited commercial messages that flood mailboxes. Focusing on anti-spam filtering for mailing lists, a thorough investigation of the effectiveness of a memory-based anti-spam filter is performed using a publicly available corpus. The investigation includes different attribute and distance-weighting schemes, and studies on the effect of the neighborhood size, the size of the attribute set, and the size of the training corpus. Three different cost scenarios are identified, and suitable cost-sensitive evaluation functions are employed. We conclude that memory-based anti-spam filtering for mailing lists is practically feasible, especially when combined with additional safety nets. Compared to a previously tested Naive Bayes filter, the memory-based filter performs on average better, particularly when the misclassification cost for non-spam messages is high.	Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece; Athens Univ Econ & Business, Dept Informat, GR-10434 Athens, Greece; Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece; Univ Athens, Dept Informat, GR-15771 Athens, Greece	Sakkis, G (reprint author), Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece.	gsakis@iit.demokritos.gr; ion@aueb.gr; paliourg@iit.demokritos.gr; vangelis@iit.demokritos.gr; costass@iit.demokritos.gr; T.Stamatopoulos@di.uoa.gr					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Andren N, 2000, J STRATEGIC STUD, V23, P167; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P1; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Cohen W. W., 1996, P AAAI SPRING S MACH, P18; Cohen WW, 1999, ACM T INFORM SYST, V17, P141, DOI 10.1145/306686.306688; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cranor LF, 1998, COMMUN ACM, V41, P74, DOI 10.1145/280324.280336; Cristianini N., 2000, INTRO SUPPORT VECTOR; Daelemans W, 1997, ARTIF INTELL REV, V11, P407, DOI 10.1023/A:1006506017891; DAELEMANS W, 2000, TIMBL TILBURG MEMORY; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Duda R.O., 1973, PATTERN CLASSIFICATI, P10; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; GIRAUDCARRIER C, 1995, THEO DECI L, V15, P341; Hall RJ, 1998, COMMUN ACM, V41, P88, DOI 10.1145/272287.272329; HIDALGO JMG, 2000, 4 COMP NAT LANG LEAR, P99; HULL DA, 2000, NIST SP, P35; Joachims T., 1997, P 14 INT C MACH LEAR, P143; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; LANG K, 1995, P 12 INT C MACH LEAR, P331; Lewis David D., 1995, P 18 ANN INT ACM SIG, P246, DOI 10.1145/215206.215366; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Mitchell T.M., 1997, MACHINE LEARNING; PANTEL P, 1998, AAAI WORKSH MAD WISC; Payne TR, 1997, APPL ARTIF INTELL, V11, P1, DOI 10.1080/088395197118325; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; Sahami M., 1998, AAAI WORKSH MAD WISC, P55; Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44; SALTON G, 1983, INTRO MODERN INFORMA; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SEBASTIANI F, 2001, IEIB4311999 CONS NAZ; Wettschereck D., 1994, THESIS OREGON STATE; WETTSCHERECK D, 1995, AIC95012 NAV RES LAB; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WILSON DR, 1997, THESIS B YOUNG U; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yang Y., 1997, P 14 INT C MACH LEAR, P412; ZAVREL J, 1997, P 7 BELG DUTCH C MAC	44	77	82	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-4564			INFORM RETRIEVAL	Inf. Retr.	JAN	2003	6	1					49	73		10.1023/A:1022948414856		25	Computer Science, Information Systems	Computer Science	660FM	WOS:000181823200003	
J	Terribilini, M; Lee, JH; Yan, CH; Jernigan, RL; Honavar, V; Dobbs, D				Terribilini, Michael; Lee, Jae-Hyung; Yan, Changhui; Jernigan, Robert L.; Honavar, Vasant; Dobbs, Drena			Prediction of RNA binding sites in proteins from amino acid sequence	RNA-A PUBLICATION OF THE RNA SOCIETY			English	Article						bioinformatics; RNA binding site; RNA-protein interactions; RNABindR; telomerase; prediction	TELOMERASE REVERSE-TRANSCRIPTASE; SUPPORT VECTOR MACHINES; RECOGNITION; DOMAIN; COMPLEXES; MOTIFS; INFORMATION; INHIBITOR; RESIDUES; FAMILIES	RNA-protein interactions are vitally important in a wide range of biological processes, including regulation of gene expression, protein synthesis, and replication and assembly of many viruses. We have developed a computational tool for predicting which amino acids of an RNA binding protein participate in RNA-protein interactions, using only the protein sequence as input. RNABindR was developed using machine learning on a validated nonredundant data set of interfaces from known RNA-protein complexes in the Protein Data Bank. It generates a classifier that captures primary sequence signals sufficient for predicting which amino acids in a given protein are located in the RNA-protein interface. In leave-one-out cross-validation experiments, RNABindR identifies interface residues with > 85% overall accuracy. It can be calibrated by the user to obtain either high specificity or high sensitivity for interface residues. RNABindR, implementing a Naive Bayes classifier, performs as well as a more complex neural network classifier ( to our knowledge, the only previously published sequence-based method for RNA binding site prediction) and offers the advantages of speed, simplicity and interpretability of results. RNABindR predictions on the human telomerase protein hTERT are in good agreement with experimental data. The availability of computational tools for predicting which residues in an RNA binding protein are likely to contact RNA should facilitate design of experiments to directly test RNA binding function and contribute to our understanding of the diversity, mechanisms, and regulation of RNA-protein complexes in biological systems. (RNABindR is available as a Web tool from http://bindr.gdcb.iastate.edu.).	Iowa State Univ, Bioinformat & Computat Biol Grad Program, Ames, IA 50010 USA; Iowa State Univ, Dept Genet Dev & Cell Biol, Ames, IA 50010 USA; Utah State Univ, Dept Comp Sci, Logan, UT 84341 USA; Iowa State Univ, Dept Biochem Biophys & Mol Biol, Ames, IA 50010 USA; Iowa State Univ, Laurence H Baker Ctr Bioinformat & Biol Stat, Ames, IA 50010 USA; Iowa State Univ, Dept Comp Sci, Ames, IA 50010 USA; Iowa State Univ, Ctr Computat Intelligence Learning & Discovery, Ames, IA 50010 USA	Terribilini, M (reprint author), Iowa State Univ, Bioinformat & Computat Biol Grad Program, Ames, IA 50010 USA.	terrible@iastate.edu	Lee, Jae-Hyung/E-6827-2011; Jernigan, Robert/A-5421-2012				Allers J, 2001, J MOL BIOL, V311, P75, DOI 10.1006/jmbi.2001.4857; Autexier C, 2006, ANNU REV BIOCHEM, V75, P493, DOI 10.1146/annurev.biochem.75.103004.142412; Bachand F, 2001, MOL CELL BIOL, V21, P1888, DOI 10.1128/MCB.21.5.1888-1897.2001; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Blackburn EH, 2005, FEBS LETT, V579, P859, DOI 10.1016/j.febslet.2004.11.036; BRADFORD JR, 2004, BIOINFORMATICS, V21, P1487, DOI 10.1093/bioinformatics/bti242; Bryan TM, 2000, MOL CELL, V6, P493, DOI 10.1016/S1097-2765(00)00048-4; BUNTINE W, 1991, THEORY REFINEMENT BA; Cai YD, 2003, BBA-PROTEINS PROTEOM, V1648, P127, DOI 10.1016/S1570-9639(03)00112-2; Chen Y, 2005, FEBS J, V272, P2088, DOI 10.1111/j.1742-4658.2005.04650.x; Cusack Stephen, 1999, Current Opinion in Structural Biology, V9, P66, DOI 10.1016/S0959-440X(99)80009-8; de Vries SJ, 2006, PROTEINS, V63, P479, DOI 10.1002/prot.20842; Draper DE, 1999, J MOL BIOL, V293, P255, DOI 10.1006/jmbi.1999.2991; EISENBERG D, 1984, P NATL ACAD SCI-BIOL, V81, P140, DOI 10.1073/pnas.81.1.140; Fischer D, 1999, BIOINFORMATICS, V15, P759, DOI 10.1093/bioinformatics/15.9.759; Gomis-Roth FX, 2003, STRUCTURE, V11, P423, DOI 10.1016/S0969-2126(03)00050-9; Hall KB, 2002, CURR OPIN STRUC BIOL, V12, P283, DOI 10.1016/S0959-440X(02)00323-8; Han LY, 2004, RNA, V10, P355, DOI 10.1261/rna.5890304; Hoffman MA, 2004, COUNS PSYCHOL, V32, P181, DOI 10.1177/0011000003261377; Hoskins J, 2006, PROTEIN SCI, V15, P1017, DOI 10.1110/ps.051589106; Hulo N, 2004, NUCLEIC ACIDS RES, V32, P134; Jacobs SA, 2006, NAT STRUCT MOL BIOL, V13, P218, DOI 10.1038/nsmb1054; Jacobs SA, 2005, PROTEIN SCI, V14, P2051, DOI 10.1110/ps.051532105; Jeong E, 2006, T COMPUT SYST BIOL, V4, P123; Jeong Euna, 2004, Genome Inform, V15, P105; Jones S, 2001, NUCLEIC ACIDS RES, V29, P943, DOI 10.1093/nar/29.4.943; Kim H, 2003, FEBS LETT, V552, P231, DOI 10.1016/S0014-5793(03)00930-X; Klein DJ, 2001, EMBO J, V20, P4214, DOI 10.1093/emboj/20.15.4214; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Lai CK, 2001, MOL CELL BIOL, V21, P990, DOI 10.1128/MCB.21.4.990-1000.2001; Lai CK, 2002, GENE DEV, V16, P415, DOI 10.1101/gad.962602; Lustig B, 1997, NUCLEIC ACIDS RES, V25, P2562, DOI 10.1093/nar/25.13.2562; Mitchell T.M., 1997, MACHINE LEARNING; Moriarty TJ, 2005, MOL BIOL CELL, V16, P3152, DOI 10.1091/mbc.E05-02-0148; Moriarty TJ, 2004, MOL CELL BIOL, V24, P3720, DOI 10.1128/MCB.24.9.3720-3733.2004; Moriarty TJ, 2002, MOL CELL BIOL, V22, P1253, DOI 10.1128/MCB.22.4.1253-1265.2002; Mulder NJ, 2003, NUCLEIC ACIDS RES, V31, P315, DOI 10.1093/nar/gkg046; Neuvirth H, 2004, J MOL BIOL, V338, P181, DOI 10.1016/j.jmb.2004.02.040; Nissink JWM, 2004, ORG BIOMOL CHEM, V2, P3238, DOI 10.1039/b405205f; O'Connor CM, 2005, J BIOL CHEM, V280, P17533, DOI 10.1074/jbc.M501211200; Ofran Y, 2003, FEBS LETT, V544, P236, DOI 10.1016/S0014-5793(03)00456-3; Pan H, 2003, P NATL ACAD SCI USA, V100, P12648, DOI 10.1073/pnas.2135585100; PANG PS, 2004, J EXP ZOOLOG B, V304, P50; Rost B, 2003, CELL MOL LIFE SCI, V60, P2637, DOI 10.1007/s00018-003-3114-8; Ryter JM, 1998, EMBO J, V17, P7505, DOI 10.1093/emboj/17.24.7505; Sen TZ, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-205; Shanahan HP, 2004, NUCLEIC ACIDS RES, V32, P4732, DOI 10.1093/nar/gkh803; Siew N, 2004, J MOL BIOL, V342, P369, DOI 10.1016/j.jmb.2004.06.073; Terribilini Michael, 2006, Pac Symp Biocomput, P415, DOI 10.1142/9789812701626_0038; Tian B, 2004, NAT REV MOL CELL BIO, V5, P1013, DOI 10.1038/nrm1528; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Weiss MA, 1998, BIOPOLYMERS, V48, P167, DOI 10.1002/(SICI)1097-0282(1998)48:2<167::AID-BIP6>3.0.CO;2-8; Witten IH, 2005, DATA MINING PRACTICA; YAN C, 2004, BIOINFORMATICS, V20, P1371; Yan CH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-262; Yan CH, 2004, NEURAL COMPUT APPL, V13, P123, DOI 10.1007/s00521-004-0414-3; Yu XJ, 2006, J THEOR BIOL, V240, P175, DOI 10.1016/j.jtbi.2005.09.018	58	74	77	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1355-8382			RNA	RNA-Publ. RNA Soc.	AUG	2006	12	8					1450	1462		10.1261/rna.2197306		13	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	068PA	WOS:000239385700003	
J	Li, YH; Jain, AK				Li, YH; Jain, AK			Classification of text documents	COMPUTER JOURNAL			English	Article								The exponential growth of the internet has led to a great deal of interest in developing useful and efficient tools and software to assist users in searching the Web. Document retrieval, categorization, routing and filtering can all be formulated as classification problems. However, the complexity of natural languages and the extremely high dimensionality of the feature space of documents have made this classification problem very difficult. We investigate four different methods for document classification: the naive Bayes classifier, the nearest neighbour classifier, decision trees and a subspace method. These were applied to seven-class Yahoo news groups (business, entertainment, health, international, politics, sports and technology) individually and in combination. We studied three classifier combination approaches: simple voting, dynamic classifier selection and adaptive classifier combination. Our experimental results indicate that the naive Bayes classifier and the subspace method outperform the other two classifiers on our data sets. Combinations of multiple classifiers did not always improve the classification accuracy compared to the best individual classifier. Among the three different combination approaches, our adaptive classifier combination method introduced here performed the best. The best classification accuracy that we are able to achieve on this seven-class problem is approximately 83%, which is comparable to the performance of other similar studies. However, the classification problem considered here is more difficult because the pattern classes used in our experiments have a large overlap of words in their corresponding documents.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Li, YH (reprint author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.						Chakrabarti S, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P446; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; FALOUTSOS C, 1995, CSTR3541 U MAR; Fox C., 1992, INFORMATION RETRIEVA, P102; FREUND F, 1995, P 2 EUR C COMP LEARN, P23; GIACINTO G, 1997, SPRINGER VERLAG LECT, V1310, P38; HULL D, 1996, AAAI SPRING S MACH L; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JAIN A, 1982, HDB STAT, P835; Jain A. K., 1988, ALGORITHMS CLUSTERIN; JOACHIMS T, 1997, P IJCAI97; LANG K, 1995, P 12 INT C MACH LEAR, P331; LARKEY S, 1996, P SIGIR, P81; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; Mitchell T.M., 1997, MACHINE LEARNING; MLADENIC D, 1996, IJSDP7472 CARN U; Oja E., 1983, SUBSPACE METHODS PAT; PAZZANI M, 1996, AAAI SPRING S MACH L; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ristad E., 1995, CSTR49595 PRINC U; SALTON G, 1983, INTRO MODERN INFORMA; Schutze H., 1995, P 18 ANN INT ACM SIG, P229, DOI 10.1145/215206.215365; WEISS S, 1996, AAAI SPRING S MACH L; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; WULFEKUHLER M, 1997, 6 INT WORLD WID WEB; YAN TW, 1995, PROCEEDINGS OF THE 1995 USENIX TECHNICAL CONFERENCE, P177	28	71	78	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0010-4620			COMPUT J	Comput. J.		1998	41	8					537	546		10.1093/comjnl/41.8.537		10	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	213FZ	WOS:000081263200003	
J	Listgarten, J; Damaraju, S; Poulin, B; Cook, L; Dufour, J; Driga, A; Mackey, J; Wishart, D; Greiner, R; Zanke, B				Listgarten, J; Damaraju, S; Poulin, B; Cook, L; Dufour, J; Driga, A; Mackey, J; Wishart, D; Greiner, R; Zanke, B			Predictive models for breast cancer susceptibility from multiple single nucleotide polymorphisms	CLINICAL CANCER RESEARCH			English	Article							NONPOLYPOSIS COLORECTAL-CANCER; PROSTATE-CANCER; GENETIC PREDISPOSITION; MUTATIONS; RISK; REPAIR; ASSOCIATION; PROMOTER; BRCA2; IDENTIFICATION	Hereditary predisposition and causative environmental exposures have long been recognized in human malignancies. In most instances, cancer cases occur sporadically, suggesting that environmental influences are critical in determining cancer risk. To test the influence of genetic polymorphisms on breast cancer risk, we have measured 98 single nucleotide polymorphisms (SNPs) distributed over 45 genes of potential relevance to breast cancer etiology in 174 patients and have compared these with matched normal controls. Using machine learning techniques such as support vector machines (SVMs), decision trees, and naive Bayes, we identified a subset of three SNPs as key discriminators between breast cancer and controls. The SVMs performed maximally among predictive models, achieving 69% predictive power in distinguishing between the two groups, compared with a 50% baseline predictive power obtained from the data after repeated random permutation of class labels (individuals with cancer or controls). However, the simpler naive Bayes model as well as the decision tree model performed quite similarly to the SVM. The three SNP sites most useful in this model were (a) the +4536T/C site of the aldosterone synthase gene CYP11B2 at amino acid residue 386 Val/Ala (T/C) (rs4541); (b) the +4328C/G site of the aryl hydrocarbon hydroxylase CYP1B1 at amino acid residue 293 Leu/Val (C/G) (rs5292); and (c) the +4449C/T site of the transcription factor BCL6 at amino acid 387 Asp/Asp (rs1056932). No single SNP site on its own could achieve more than 60% in predictive accuracy. We have shown that multiple SNP sites from different genes over distant parts of the genome are better at identifying breast cancer patients than any one SNP alone. As high-throughput technology for SNPs improves and as more SNPs are identified, it is likely that much higher predictive accuracy will be achieved and a useful clinical tool developed.	Univ Alberta, Fac Med, Edmonton, AB, Canada; Univ Alberta, Fac Sci, Edmonton, AB, Canada; Univ Alberta, Fac Pharmaceut Sci, Edmonton, AB, Canada; Alberta Canc Board, Cross Canc Inst, Edmonton, AB, Canada	Zanke, B (reprint author), Canc Care Ontario, 1324-620 Univ Ave, Toronto, ON M5G 2L7, Canada.	Brent.Zanke@cancercare.on.ca					Becker N, 2003, MUTAT RES-FUND MOL M, V525, P11, DOI 10.1016/S0027-5107(02)00283-X; Ben-Dor A, 2000, SCORING GENES RELEVA; Bharaj BB, 2002, PROSTATE, V51, P35, DOI 10.1002/pros.10076; Biros E, 2001, NEOPLASMA, V48, P407; Breen G., 2000, BIOTECHNIQUES, V28, P470; Breen G., 2000, BIOTECHNIQUES, V28, P468; Breen G, 2000, BIOTECHNIQUES, V28, P464; BREIMAN L, 1995, CLASSIFICATION REGRE; Brennan P, 2002, CARCINOGENESIS, V23, P381, DOI 10.1093/carcin/23.3.381; Carney JP, 1998, CELL, V93, P477, DOI 10.1016/S0092-8674(00)81175-7; Carroll BT, 1999, J MED GENET, V36, P94; Charames GS, 2000, HUM GENET, V107, P623, DOI 10.1007/s004390000417; Coumoul X, 2001, CANCER RES, V61, P3942; Cover T. M., 1991, ELEMENTS INFORMATION; Cristianini N., 2000, INTRO SUPPORT VECTOR; de Amorim LMD, 2002, CANCER LETT, V181, P179; Duda R., 1973, PATTERN CLASSIFICATI; ELLIS NA, 1995, CELL, V83, P655, DOI 10.1016/0092-8674(95)90105-1; Flores-Rozas H, 2000, NAT GENET, V26, P375; Goode EL, 2002, CANCER RES, V62, P3052; Haiman CA, 2003, BREAST CANCER RES TR, V77, P27, DOI 10.1023/A:1021112121782; Halushka MK, 1999, NAT GENET, V22, P239; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hemminki K, 2002, CARCINOGENESIS, V23, P379, DOI 10.1093/carcin/23.3.379; Joachims T., 1999, MAKING LARGE SCALE S; Kariola R, 2002, HUM MOL GENET, V11, P1303, DOI 10.1093/hmg/11.11.1303; Kerr P, 2001, CURR BIOL, V11, pR668, DOI 10.1016/S0960-9822(01)00389-X; Kinzler KW, 1997, NATURE, V386, P761, DOI 10.1038/386761a0; Kokoris M, 2000, MOL DIAGN, V5, P329; Kumar R, 2001, INT J CANCER, V95, P388, DOI 10.1002/1097-0215(20011120)95:6<388::AID-IJC1069>3.0.CO;2-6; Lehman TA, 2000, CANCER RES, V60, P1062; Lesueur F, 2002, J MED GENET, V39, P260, DOI 10.1136/jmg.39.4.260; Lichtenstein P, 2000, NEW ENGL J MED, V343, P78, DOI 10.1056/NEJM200007133430201; MALKIN D, 1990, SCIENCE, V250, P1233, DOI 10.1126/science.1978757; Meijers-Heijboer H, 2002, NAT GENET, V31, P55, DOI 10.1038/ng879; Meinhardt U, 2002, SEMIN REPROD MED, V20, P277, DOI 10.1055/s-2002-35374; Olshen AB, 2002, BIOINFORMATICS, V18, P961, DOI 10.1093/bioinformatics/18.7.961; Peto J, 2002, CANCER CELL, V1, P411, DOI 10.1016/S1535-6108(02)00079-X; Rebbeck Timothy R, 2002, Breast Cancer Res, V4, P85, DOI 10.1186/bcr430; Rebbeck TR, 1999, CANCER, V86, P2493, DOI 10.1002/(SICI)1097-0142(19991201)86:11+<2493::AID-CNCR6>3.0.CO;2-Z; SAVITSKY K, 1995, SCIENCE, V268, P1749, DOI 10.1126/science.7792600; Schwab M, 2002, CANCER LETT, V175, P1, DOI 10.1016/S0304-3835(01)00752-2; Sheweita SA, 2000, CURR DRUG METAB, V1, P107, DOI 10.2174/1389200003339117; Shin KH, 2002, CANCER RES, V62, P38; Staudt L M, 1999, Int Rev Immunol, V18, P381, DOI 10.3109/08830189909088490; Stewart GS, 1999, CELL, V99, P577, DOI 10.1016/S0092-8674(00)81547-0; Tanaka Y, 2002, BIOCHEM BIOPH RES CO, V296, P820, DOI 10.1016/S0006-291X(02)02004-1; Tayeb MT, 2002, ONCOL REP, V9, P653; Tsukada K, 2002, J HUM HYPERTENS, V16, P789, DOI 10.1038/sj.jhh.1001484; Turchetti D, 2002, J EXP CLIN CANC RES, V21, P17; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Verma L, 1999, J MED GENET, V36, P678; Wang LZ, 2002, CARCINOGENESIS, V23, P257, DOI 10.1093/carcin/23.2.257; Weber TK, 1997, CANCER RES, V57, P3798; WEEDA G, 1990, CELL, V62, P777, DOI 10.1016/0092-8674(90)90122-U; Wiley JS, 2002, LANCET, V359, P1114, DOI 10.1016/S0140-6736(02)08156-4; Wu MS, 2002, INT J COLORECTAL DIS, V17, P338, DOI 10.1007/s00384-001-0383-2; Xu JF, 2002, CANCER RES, V62, P2253; Zhu Y, 2001, CANCER RES, V61, P7825	59	70	71	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	APR 15	2004	10	8					2725	2737		10.1158/1078-0432.CCR-1115-03		13	Oncology	Oncology	813VE	WOS:000220933800021	
J	Glick, M; Jenkins, JL; Nettles, JH; Hitchings, H; Davies, JW				Glick, M; Jenkins, JL; Nettles, JH; Hitchings, H; Davies, JW			Enrichment of high-throughput screening data with increasing levels of noise using support vector machines, recursive partitioning, and Laplacian-modified naive Bayesian classifiers	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	4th Indo-US Workshop on Mathematical Chemistry	JAN 08-12, 2005	Pune, INDIA				STOCHASTIC RESONANCE; CHEMICAL-STRUCTURES; DRUG DISCOVERY; DESCRIPTORS; DIVERSE; CLASSIFICATION; FINGERPRINTS; SELECTION; DOCKING; MODELS	High-throughput screening (HTS) plays a pivotal role in lead discovery for the pharmaceutical industry. In tandem, cheminformatics approaches are employed to increase the probability of the identification of novel biologically active compounds by mining the HTS data. HTS data is notoriously noisy, and therefore, the selection of the optimal data mining method is important for the success of such an analysis. Here, we describe a retrospective analysis of four HTS data sets using three mining approaches: Laplacian-modified naive Bayes, recursive partitioning, and support vector machine (SVM) classifiers with increasing stochastic noise in the form of false positives and false negatives. All three of the data mining methods at hand tolerated increasing levels of false positives even when the ratio of misclassified compounds to true active compounds was 5: 1 in the training set. False negatives in the ratio of 1: 1 were tolerated as well. SVM outperformed the other two methods in capturing active compounds and scaffolds in the top 1%. A Murcko scaffold analysis could explain the differences in enrichments among the four data sets. This study demonstrates that data mining methods can add a true value to the screen even when the data is contaminated with a high level of stochastic noise.	Novartis Inst Biomed Res Inc, Lead Discovery Ctr, Cambridge, MA 02139 USA; Equbits LLC, Palo Alto, CA 94306 USA	Glick, M (reprint author), Novartis Inst Biomed Res Inc, Lead Discovery Ctr, 250 Massachusetts Ave, Cambridge, MA 02139 USA.	meir.glick@novartis.com					Bemis GW, 1996, J MED CHEM, V39, P2887, DOI 10.1021/jm9602928; Blower P, 2002, J CHEM INF COMP SCI, V42, P393, DOI 10.1021/ci0101049; Breiman L., 1984, CLASSIFICATION REGRE; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Brown RD, 1996, J CHEM INF COMP SCI, V36, P572, DOI 10.1021/ci9501047; Diller DJ, 2004, J MED CHEM, V47, P6373, DOI 10.1021/jm049902r; Dixon SL, 2001, J MED CHEM, V44, P3795, DOI 10.1021/jm010137f; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Godden JW, 2003, QSAR COMB SCI, V22, P487, DOI 10.1002/qsar.200310001; Hastie T., 2005, ELEMENTS STAT LEARNI; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; Karnachi PS, 2004, J BIOMOL SCREEN, V9, P678, DOI 10.1177/1087057104269570; Kelley BP, 2004, CHEM BIOL, V11, P1495, DOI 10.1016/j.chembiol.2004.08.026; Klon AE, 2004, J MED CHEM, V47, P4356, DOI 10.1021/jm049970d; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Matter H, 1999, J CHEM INF COMP SCI, V39, P1211, DOI 10.1021/ci980185h; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Russell DF, 1999, NATURE, V402, P291; Schuffenhauer A, 2000, J CHEM INF COMP SCI, V40, P295, DOI 10.1021/ci990263g; Schuffenhauer A, 2004, COMB CHEM HIGH T SCR, V7, P771, DOI 10.2174/1386207043328238; Shi LM, 2001, J CHEM INF COMP SCI, V41, P186, DOI 10.1021/ci000066d; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; Valler MJ, 2000, DRUG DISCOV TODAY, V5, P286, DOI 10.1016/S1359-6446(00)01517-8; Vapnik V., 1998, STAT LEARNING THEORY; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; WIESENFELD K, 1995, NATURE, V373, P33, DOI 10.1038/373033a0; Witten I.H., 1999, DATA MINING PRACTICA; Wu X, 2003, J BIOMOL SCREEN, V8, P381, DOI 10.1177/1087057103256466; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195	32	68	69	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	JAN-FEB	2006	46	1					193	200		10.1021/ci050374h		8	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	008DU	WOS:000235021200024	
J	Doan, A; Domingos, P; Halevy, A				Doan, A; Domingos, P; Halevy, A			Learning to match the schemas of data sources: A multistrategy approach	MACHINE LEARNING			English	Article						schema matching; multistrategy learning; data integration	STACKED GENERALIZATION	The problem of integrating data from multiple data sources-either on the Internet or within enterprises-has received much attention in the database and AI communities. The focus has been on building data integration systems that provide a uniform query interface to the sources. A key bottleneck in building such systems has been the laborious manual construction of semantic mappings between the query interface and the source schemas. Examples of mappings are "element location maps to address" and "price maps to listed-price". We propose a multistrategy learning approach to automatically find such mappings. The approach applies multiple learner modules, where each module exploits a different type of information either in the schemas of the sources or in their data, then combines the predictions of the modules using a meta-learner. Learner modules employ a variety of techniques, ranging from Naive Bayes and nearest-neighbor classification to entity recognition and information retrieval. We describe the LSD system, which employs this approach to find semantic mappings. To further improve matching accuracy, LSD exploits domain integrity constraints, user feedback, and nested structures in XML data. We test LSD experimentally on several real-world domains. The experiments validate the utility of multistrategy learning for data integration and show that LSD proposes semantic mappings with a high degree of accuracy.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Doan, A (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.						Ashish N., 1997, SIGMOD Record, V26; BRAZDIL P, 1991, LECT NOTES ARTIFICIA, V482; Castano S., 1999, Proceedings. IDEAS'99. International Database Engineering and Applications Symposium (Cat. No.PR00265), DOI 10.1109/IDEAS.1999.787251; CHALUPSKY H, 2000, PRINCIPLES KNOWLEDGE; CLIFTON C, 1997, P IFIP WORK C DAT SE, V7; Do H., 2002, P 2 INT WORKSH WEB D; DOAN A, 2002, UWCSE2002 U WASH; DOAN A, 2002, P WORLD WID WEB C WW; Doan AnHai, 2001, P ACM SIGMOD C; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DONOHO S, 1996, P 13 INT C MACH LEAR, P113; DUDA RO, 1974, PATTERN CLASSIFICATI; Freitag D., 1998, THESIS CARNEGIE MELL; FRIEDMAN M, 1997, P INT JOINT C AI IJC; GARCIAMOLINA H, 1997, J INTELL INF SYST, V8, P2; HAMMER J, 1998, ACM SIGMOND RECORD; Hart PE, 1972, SIGART NEWSL, V37, P28; Hirsh H., 1998, P 4 INT C KNOWL DISC; IVES ZG, 1999, P SIGMOD; Keim G. A., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); KNOBLOCK C, 1998, P NAT C ART INT AAAI; Kushmerick N., 2000, World Wide Web, V3, DOI 10.1023/A:1019229612909; Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9; LACHER M, 2001, P 14 INT FLAIRS C; LAMBRECHT E, 1999, P INT JOINT C AI IJC; LEVY A, 1996, P VLDB; Li WS, 2000, DATA KNOWL ENG, V33, P49, DOI 10.1016/S0169-023X(99)00044-0; MADHAVAN J, 2002, P NAT AI C AAAI 02; McCallum A., 1998, P AAAI 98 WORKSH LEA; MCGUINNESS D, 2000, P 17 NAT C ART INT; MELNIK S, 2002, P INT C DAT ENG; Michalski R., 1994, MACHINE LEARNING MUL; MILLER R, 2000, P VLDB; MILO T, 1998, P VLDB; MITRA P, 1998, P FUSION 99; Noy N., 2000, P NAT C ART INT AAAI; Noy N, 2001, P WORKSH ONT INF SHA; Palopoli L., 1998, Proceedings. IDEAS'98. International Database Engineering and Applications Symposium (Cat. No.98EX156), DOI 10.1109/IDEAS.1998.694384; PERKOWITZ M, 1995, P INT JOINT C AI IJC; PUNYAKANOK V, 2001, P C NEUR INF PROC SY; RAHM E, 2001, MSRTR200117 MICR RES; RYUTARO I, 2001, P 2 WORKSH ONT LEARN; Ting KM, 1999, J ARTIF INTELL RES, V10, P271; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; 1998, EXTENSIBLE MARKUP LA	45	68	73	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	MAR	2003	50	3					279	301		10.1023/A:1021765902788		23	Computer Science, Artificial Intelligence	Computer Science	627QJ	WOS:000179944600004	
J	Gama, J; Brazdil, P				Gama, J; Brazdil, P			Cascade generalization	MACHINE LEARNING			English	Article						multiple models; constructive induction; combining classifiers; merging classifiers	CLASSIFIER	Using multiple classifiers for increasing learning accuracy is an active research area. In this paper we present two related methods for merging classifiers. The first method, Cascade Generalization, couples classifiers loosely. It belongs to the family of stacking algorithms. The basic idea of Cascade Generalization is to use sequentially the set of classifiers, at each step performing an extension of the original data by the insertion of new attributes. The new attributes are derived from the probability class distribution given by a base classifier. This constructive step extends the representational language for the high level classifiers, relaxing their bias. The second method exploits tight coupling of classifiers, by applying Cascade Generalization locally. At each iteration of a divide and conquer algorithm, a reconstruction of the instance space occurs by the addition of new attributes. Each new attribute represents the probability that an example belongs to a class given by a base classifier. We have implemented three Local Generalization Algorithms. The first merges a linear discriminant with a decision tree, the second merges a naive Bayes with a decision tree, and the third merges a linear discriminant and a naive Bayes with a decision tree. All the algorithms show an increase of performance, when compared with the corresponding single models. Cascade also outperforms other methods for combining classifiers, like Stacked Generalization, and competes well against Boosting at statistically significant confidence levels.	Univ Porto, FEP, LIACC, P-8234150 Porto, Portugal	Gama, J (reprint author), Univ Porto, FEP, LIACC, Rua Campo Alegre 823, P-8234150 Porto, Portugal.		Gama, Joao/A-2070-2008	Gama, Joao/0000-0003-3357-1195			Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C., 1999, UCI REPOSITORY MACHI; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; BUNTINE W, 1990, THESIS U SYDNEY; CHAN P, 1995, MACHINE LEARNING; CHAN PK, 1995, P 1 INT C KNOWL DISC; Dillon WR, 1984, MULTIVARIATE ANAL ME; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, MACHINE LEARNING; Fahlman SE, 1991, ADV NEURAL INFORMATI, P190; Freund Y., 1996, MACHINE LEARNING; GAMA J, 1998, LNAI, V1398; Gama J., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00002-5; HENERY B, 1997, MACHINE LEARNING STA; KOHAVI R, 1996, MACHINE LEARNING; LANGLEY P, 1993, LNAI, V667; Langley P, 1996, ELEMENTS MACHINE LEA; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T.M., 1997, MACHINE LEARNING; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; Pearl J., 1988, PROBABILISTIC REASON; QUINLAN R, 1986, MACH LEARN, V1, P89; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN R, 1996, P 13 AM ASS ART INT; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; Skalak D. B., 1997, THESIS U MASSACHUSET; TING K, 1997, P INT JOINT C ARTIFI; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	34	65	70	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	DEC	2000	41	3					315	343		10.1023/A:1007652114878		29	Computer Science, Artificial Intelligence	Computer Science	368GP	WOS:000090109600003	
J	Klon, AE; Glick, M; Thoma, M; Acklin, P; Davies, JW				Klon, AE; Glick, M; Thoma, M; Acklin, P; Davies, JW			Finding more needles in the haystack: A simple and efficient method for improving high-throughput docking results	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							PROTEIN-TYROSINE-PHOSPHATASE; MOLECULAR DOCKING; SCORING FUNCTIONS; DATABASES; GENERATION; 1B	The technology underpinning high-throughput docking (HTD) has developed over the past few years to where it has become a vital tool in modern drug discovery. Although the performance of various docking algorithms is adequate, the ability to accurately and consistently rank compounds using a scoring function remains problematic. We show that by employing a simple machine learning method (naive Bayes) it is possible to significantly overcome this deficiency. Compounds from the Available Chemical Directory (ACD), along with known active compounds, were docked into two protein targets using three software packages. In cases where HTD alone was able to show some enrichment, the application of naive Bayes was able to improve upon the enrichment. The application of this methodology to enrich HTD results can be carried out without a priori knowledge of the activity of compounds and results in superior enrichment of known actives compared to the use of scoring methods alone.	Novartis Inst Biomed Res, Cambridge, MA 02139 USA	Davies, JW (reprint author), Novartis Inst Biomed Res, 100 Technol Sq, Cambridge, MA 02139 USA.	john.davies@pharma.novartis.com					Abagyan R, 2001, CURR OPIN CHEM BIOL, V5, P375, DOI 10.1016/S1367-5931(00)00217-9; Akamatsu M, 1997, BIOORGAN MED CHEM, V5, P157, DOI 10.1016/S0968-0896(96)00195-2; ANDERSEN HS, 2001, Patent No. 0100451; Berman HM, 2002, ACTA CRYSTALLOGR D, V58, P899, DOI 10.1107/S0907444902003451; Bissantz C, 2000, J MED CHEM, V43, P4759, DOI 10.1021/jm001044l; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; Clark RD, 2002, J MOL GRAPH MODEL, V20, P281, DOI 10.1016/S1093-3263(01)00125-5; Ewing TJA, 2001, J COMPUT AID MOL DES, V15, P411, DOI 10.1023/A:1011115820450; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; GLICK M, 2003, J BIOMOL SCREEN, V9, P32; Gohlke H, 2001, CURR OPIN STRUC BIOL, V11, P231, DOI 10.1016/S0959-440X(00)00195-0; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Iversen LF, 2000, J BIOL CHEM, V275, P10300, DOI 10.1074/jbc.275.14.10300; Johnson TO, 2002, NAT REV DRUG DISCOV, V1, P696, DOI 10.1038/nrd895; LEBLANC Y, 2000, Patent No. 9900864; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Rarey M, 1996, J MOL BIOL, V261, P470, DOI 10.1006/jmbi.1996.0477; Schneider G, 2002, DRUG DISCOV TODAY, V7, P64, DOI 10.1016/S1359-6446(02)00004-1; VLATTAS I, 1998, P EUR PEPT S AK KIAD, P766; Wang RX, 2003, J MED CHEM, V46, P2287, DOI 10.1021/jm0203783; Wang RX, 2001, J CHEM INF COMP SCI, V41, P1422, DOI 10.1021/ci010025x; Witten I.H., 1999, DATA MINING PRACTICA; Yang J, 2002, NAT STRUCT BIOL, V9, P940, DOI 10.1038/nsb870	23	64	66	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	MAY 20	2004	47	11					2743	2749		10.1021/jm030363k		7	Chemistry, Medicinal	Pharmacology & Pharmacy	821JQ	WOS:000221456700005	
J	Misaki, M; Kim, Y; Bandettini, PA; Kriegeskorte, N				Misaki, Masaya; Kim, Youn; Bandettini, Peter A.; Kriegeskorte, Nikolaus			Comparison of multivariate classifiers and response normalizations for pattern-information fMRI	NEUROIMAGE			English	Article						Multi-voxel pattern analysis; decoding; classification analysis; fMRI; normalization; pattern-information analysis	SUPPORT VECTOR MACHINES; HUMAN BRAIN ACTIVITY; TEMPORAL CORTEX; VISUAL-CORTEX; CLASSIFICATION; STATES; REPRESENTATIONS; RECOGNITION; ALGORITHMS; ACTIVATION	A popular method for investigating whether stimulus information is present in fMRI response patterns is to attempt to "decode" the stimuli from the response patterns with a multivariate classifier. The sensitivity for detecting the information depends on the particular classifier used. However, little is known about the relative performance of different classifiers on fMRI data. Here we compared six multivariate classifiers and investigated how the response-amplitude estimate used (beta- or t-value) and different pattern normalizations affect classification performance. The compared classifiers were a pattern-correlation classifier, a k-nearest-neighbors classifier, Fisher's linear discriminant, Gaussian naive Bayes, and linear and nonlinear (radial-basis-function kernel) support vector machines. We compared these classifiers' accuracy at decoding the category of visual objects from response patterns in human early visual and inferior temporal cortex acquired in an event-related design with BOLD fMRI at 3 T using SENSE and isotropic voxels of about 2-mm width. Overall, Fisher's linear discriminant (with an optimal-shrinkage covariance estimator) and the linear support vector machine performed best. The pattern-correlation classifier often performed similarly as those two classifiers. The nonlinear classifiers never performed better and sometimes significantly worse than the linear classifiers, suggesting overfitting. Defining response patterns by t-values (or in error-standard-deviation units) rather than by beta estimates (in % signal change) to define the patterns appeared advantageous. Cross-validation by a leave-one-stimulus-pair-out method gave higher accuracies than a leave-one-run-out method, suggesting that generalization to independent runs (which more safely ensures independence of the test set) is more challenging than generalization to novel stimuli within the same category. Independent selection of fewer more visually responsive voxels tended to yield better decoding performance for all classifiers. Normalizing mean and standard deviation of the response patterns either across stimuli or across voxels had no significant effect on decoding performance. Overall our results suggest that linear decoders based on t-value patterns may perform best in the present scenario of visual object representations measured for about 60 min per subject with 3T fMRI. Published by Elsevier Inc.	[Misaki, Masaya; Kim, Youn; Bandettini, Peter A.; Kriegeskorte, Nikolaus] NIMH, Lab Brain & Cognit, NIH, Bethesda, MD 20892 USA; [Kim, Youn] Univ Calif San Diego, Dept Elect Engn, San Diego, CA 92103 USA; [Kriegeskorte, Nikolaus] MRC, Cognit & Brain Sci Unit, Cambridge CB2 7EF, England	Misaki, M (reprint author), NIMH, Lab Brain & Cognit, NIH, 10 Ctr Dr MSC 1148, Bethesda, MD 20892 USA.	misakim@mail.nih.gov; nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk			NIMH	This work was supported by the NIMH Intramural Research Program. This study utilized the high performance computational capabilities of the Biowulf Linux cluster at the National Institutes of Health, Bethesda, MD (http://biowulf.nih.gov).	ABERG MB, 2008, BIOSIGNALS, V2, P302; Bishop C. M., 2007, PATTERN RECOGNITION; Boynton GM, 1996, J NEUROSCI, V16, P4207; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cox DD, 2003, NEUROIMAGE, V19, P261, DOI 10.1016/S1053-8119(03)00049-1; Cristianini N., 2000, INTRO SUPPORT VECTOR; De Martino F, 2008, NEUROIMAGE, V43, P44, DOI 10.1016/j.neuroimage.2008.06.037; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R. O., 2000, PATTERN CLASSIFICATI; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hanson SJ, 2004, NEUROIMAGE, V23, P156, DOI 10.1016/j.neuroimage.2004.05.020; Hastie T, 2009, ELEMENTS STAT LEARNI; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Haynes JD, 2005, NAT NEUROSCI, V8, P686, DOI 10.1038/nn1445; Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931; Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444; Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713; Kriegeskorte N, 2007, P NATL ACAD SCI USA, V104, P20600, DOI 10.1073/pnas.0705654104; Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303; Kriegeskorte N, 2008, INT J IMAG SYST TECH, V18, P345, DOI 10.1002/ima.20166; Kriegeskorte N., 2008, FRONT SYST NEUROSCI, V2, P1; Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103; Kriegeskorte N, 2007, NEUROIMAGE, V38, P649, DOI 10.1016/j.neuroimage.2007.02.022; Kriegeskorte N, 2008, NEURON, V60, P1126, DOI 10.1016/j.neuron.2008.10.043; Kriegeskorte N., 2004, THESIS U MAASTRICHT; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Krzanowski W, 1988, PRINCIPLES MULTIVARI; Ku SP, 2008, MAGN RESON IMAGING, V26, P1007, DOI 10.1016/j.mri.2008.02.016; LaConte S, 2005, NEUROIMAGE, V26, P317, DOI 10.1016/j.neuroimage.2005.01.048; Ledoit O., 2003, J EMPIR FINANC, V10, P603, DOI DOI 10.1016/S0927-5398(03)00007-0; Martinez-Ramon M, 2006, NEUROIMAGE, V31, P1129, DOI 10.1016/j.neuroimage.2006.01.022; Mitchell T.M., 1997, MACHINE LEARNING; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Mitchell TM, 2008, SCIENCE, V320, P1191, DOI 10.1126/science.1152876; Mourao-Miranda J, 2005, NEUROIMAGE, V28, P980, DOI 10.1016/j.neuroimage.2005.06.070; Mur M, 2009, SOC COGN AFFECT NEUR, V4, P101, DOI 10.1093/scan/nsn044; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005; Pereira F, 2009, NEUROIMAGE, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007; Quiroga RQ, 2009, NAT REV NEUROSCI, V10, P173, DOI 10.1038/nrn2578; Schafer J, 2005, STAT APPL GENET MOL, V4; Scholkopf B., 2001, LEARNING KERNELS SUP; Vapnik V., 1995, NATURE STAT LEARNING	44	62	64	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119			NEUROIMAGE	Neuroimage	OCT 15	2010	53	1					103	118		10.1016/j.neuroimage.2010.05.051		16	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	637LJ	WOS:000280818900012	
S	Ng, AY; Jordan, MI		Dietterich, TG; Becker, S; Ghahramani, Z		Ng, AY; Jordan, MI			On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 14, VOLS 1 AND 2	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	15th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 03-08, 2001	VANCOUVER, CANADA					We compare discriminative and generative learning as typified by logistic regression and naive Bayes. We show, contrary to a widely-held belief that discriminative classifiers are almost always to be preferred, that there can often be two distinct regimes of performance as the training set size is increased, one in which each algorithm does better. This stems from the observation-which is borne out in repeated experiments-that while discriminative learning has lower asymptotic error, a generative classifier may also approach its (higher) asymptotic error much faster.	Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA	Ng, AY (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.						Anthony M, 1999, NEURAL NETWORK LEARN; EFRON B, 1975, J AM STAT ASSOC, V70, P892, DOI 10.2307/2285453; GOLDBERG PW, 1995, MACH LEARN, V18, P131, DOI 10.1007/BF00993408; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Rubinstein Y. D., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Vapnik V., 1998, STAT LEARNING THEORY	6	62	63	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-04208-8	ADV NEUR IN			2002	14						841	848				8	Computer Science, Artificial Intelligence	Computer Science	BV95T	WOS:000180520100105	
J	Founds, SA; Conley, YP; Lyons-Weiler, JF; Jeyabalan, A; Hogge, WA; Conrad, KR				Founds, S. A.; Conley, Y. P.; Lyons-Weiler, J. F.; Jeyabalan, A.; Hogge, W. Allen; Conrad, K. R.			Altered Global Gene Expression in First Trimester Placentas of Women Destined to Develop Preeclampsia	PLACENTA			English	Article						Oligonucleotide; Microarray; Chorionic villus sampling; Maternal-fetal interface; immune regulation; Decidualization; Cell motility; Hypoxia inducible factor; Oxidative stress	OXIDATIVE STRESS; MICROARRAY ANALYSIS; WORKING GROUP; PREGNANCY; TROPHOBLAST; CELLS; HYPOXIA; TISSUE; ONSET; DECIDUALIZATION	Background: Preeclampsia is a pregnancy-specific disorder that remains a leading cause of maternal, fetal and neonatal morbidity and mortality, and is associated with risk for future cardiovascular disease. There are no reliable predictors, specific preventative measures or treatments other than delivery. A widely held view is that the antecedents of preeclampsia lie with impaired placentation in early pregnancy. Accordingly, we hypothesized dysregulation of global gene expression in first trimester placentas of women who later manifested preeclampsia. Methods: Surplus chorionic villus sampling (CVS) tissues were collected at 10-12 weeks gestation in 160 patients with singleton fetuses. Four patients developed preeclampsia, and their banked CVS specimens were matched to 8 control samples from patients with unaffected pregnancies. Affymetrix HG-U133 Plus 2.0 GeneChips were utilized for microarray analysis. Naive Bayes prediction modeling and pathway analysis were conducted. qRT-PCR examined three of the dysregulated genes. Results: Thirty-six differentially expressed genes were identified in the preeclampsia placentas. qRT-PCR verified the microarray analysis. Thirty-one genes were down-regulated. Many were related to inflammation/immunoregulation and cell motility. Decidual gene dysregulation was prominent. No evidence was found for alterations in hypoxia and oxidative stress regulated genes. Conclusions: To our knowledge, this is the first study to show dysregulation of gene expression in the early placentas of women similar to 6 months before developing preeclampsia, thereby reinforcing a placental origin of the disorder. We hypothesize that placentation in preeclampsia is compromised in the first trimester by maternal and fetal immune dysregulation, abnormal decidualization, or both, thereby impairing trophoblast invasion. Several of the genes provide potential targets for the development of clinical biomarkers in maternal blood during the first trimester. Supplementary materials are available for this article via the publisher's online edition. (C) 2008 Elsevier Ltd. All rights reserved.	[Founds, S. A.; Conley, Y. P.] Univ Pittsburgh, Sch Nursing, Dept Hlth Promot & Dev, Pittsburgh, PA 15261 USA; [Conley, Y. P.] Univ Pittsburgh, Grad Sch Publ Hlth, Dept Human Genet, Pittsburgh, PA 15261 USA; [Lyons-Weiler, J. F.] Univ Pittsburgh, Genom & Prote Core Lab, Pittsburgh, PA 15261 USA; [Jeyabalan, A.; Hogge, W. Allen] Univ Pittsburgh, Sch Med, Dept Obstet & Gynecol, Pittsburgh, PA 15261 USA; [Hogge, W. Allen] Univ Florida, Coll Med, Dept Physiol & Funct Gen, Gainesville, FL 32611 USA; [Conrad, K. R.] Univ Florida, Coll Med, Dept Obstet & Gynecol, Gainesville, FL 32611 USA	Founds, SA (reprint author), Univ Pittsburgh, Sch Nursing, Dept Hlth Promot & Dev, 440 Victoria Bldg,3500 Victoria St, Pittsburgh, PA 15261 USA.	foundss@pitt.edu			NIH/NINR Summer Genetics Institute; University of Pittsburgh School of Nursing Center for Research and Evaluation; American Nurses Foundation; Eastern Nurses Research Society & Rita Chow & Yaye Togaski-Breitenbach Scholar Award; NIH [R01 HL67937]; National Center for Research Resources (NCRR) [1 UL1 RR024153]	We gratefully acknowledge the Genetics Counselors of Magee-Womens Hospital for recruitment; Anna Linares and Debbie Hollingshead of the University of Pittsburgh Genomics and Proteomics Core Lab for conducting the RNA extractions and microarrays, respectively; Ketah Doty and Julianna Debrah for sample processing, storage and clinical data entry; Dr. Robert Pijnenborg of the Katholieke Universiteit Leuven, Leuven, Belgium for his kind consultation on placental anatomy; Dr. Eleanor Feingold of the University of Pittsburgh Graduate School of Public Health for her assessment of the microarray data and for her review. Dr. Founds was supported by the NIH/NINR Summer Genetics Institute, the University of Pittsburgh School of Nursing Center for Research and Evaluation, and the 2007 American Nurses Foundation Grant through the Eastern Nurses Research Society & Rita Chow & Yaye Togaski-Breitenbach Scholar Award. The CVS processing and storage, clinical data entry, RNA extraction and microarray analyses were underwritten by National Institutes of Health (NIH) P01 HD30367 Project 2 (to KPC). Dr. Conrad's effort on this project was also supported by NIH R01 HL67937. This publication was made possible by Grant Number 1 UL1 RR024153 from the National Center for Research Resources (NCRR), a component of the NIH, and NIH Roadmap for Medical Research. Its contents are solely the responsibility of the authors and do not necessarily represent the official view of NCRR or NIH. Individual author contributions are in Supplement.	Allen RG, 2000, FREE RADICAL BIO MED, V28, P463, DOI 10.1016/S0891-5849(99)00242-7; American College of Obstetrics and Gynecology A, 2002, OBSTET GYNECOL, V99, P159; Gifford RW, 2000, AM J OBSTET GYNECOL, V183, pS1, DOI 10.1067/mob.2000.107928; Apps R, 2007, EUR J IMMUNOL, V37, P1924, DOI 10.1002/eji.200737089; Benirschke K, 2006, PATHOLOGY HUMAN PLAC; BISCHOF P, 1989, AM J PERINAT, V6, P110, DOI 10.1055/s-2007-999559; Caniggia I, 2000, PLACENTA, V21, pS25, DOI 10.1053/plac.1999.0522; Caniggia I, 2002, PLACENTA, V23, pS47, DOI 10.1053/plac.2002.0815; Chappell S, 2006, CLIN SCI, V110, P443, DOI 10.1042/CS20050323; Christopoulos A, 2006, ACTA PHARMACOL SIN, V27, P9; DAMSKY CH, 1992, J CLIN INVEST, V89, P210, DOI 10.1172/JCI115565; DHARMARAJ S, 2007, RT PCR BASICS; Evans MI, 2008, CURR OPIN OBSTET GYN, V20, P164, DOI 10.1097/GCO.0b013e3282f7321f; Founds SA, 2008, JOGNN-J OBST GYN NEO, V37, P146, DOI 10.1111/j.1552-6909.2008.00232.x; Guleria I, 2000, NAT MED, V6, P589; Huppertz B, 2007, SEMIN IMMUNOPATHOL, V29, P83, DOI 10.1007/s00281-007-0070-7; Ilekis JV, 2007, REPROD SCI, V14, P508, DOI 10.1177/1933719107306232; *ING, 2007, ING PATHW AN 5 5; IRVING JA, 1995, EXP CELL RES, V217, P419, DOI 10.1006/excr.1995.1105; JAFARI P, 2006, BMC MED INFORM DECIS, V21, P27; Jauniaux E, 2000, AM J PATHOL, V157, P2111, DOI 10.1016/S0002-9440(10)64849-3; Jeschke U, 2005, VIRCHOWS ARCH, V446, P360, DOI 10.1007/s00428-004-1201-3; Jones RL, 2002, MOL HUM REPROD, V8, P363, DOI 10.1093/molehr/8.4.363; KHONG TY, 1986, BRIT J OBSTET GYNAEC, V93, P1049, DOI 10.1111/j.1471-0528.1986.tb07830.x; Lethe B, 1998, INT J CANCER, V76, P903, DOI 10.1002/(SICI)1097-0215(19980610)76:6<903::AID-IJC22>3.0.CO;2-1; Li C., 2001, GENOME BIOL, V2, DOI [10.1186/gb-2001-2-8-research0032, DOI 10.1186/GB-2001-2-8-RESEARCH0032]; Lofstedt T, 2007, CELL CYCLE, V6, P919, DOI 10.4161/cc.6.8.4133; Many A, 2000, AM J PATHOL, V156, P321, DOI 10.1016/S0002-9440(10)64733-5; Mincheva-Nilsson L, 2000, INT IMMUNOL, V12, P585, DOI 10.1093/intimm/12.5.585; Mohaupt M, 2007, MOL ASPECTS MED, V28, P169, DOI 10.1016/j.mam.2007.02.005; MOR GA, 2006, IMMUNOLOGY PREGNANCY, P215, DOI 10.1007/0-387-34944-8_19; Nishizawa H, 2007, PLACENTA, V28, P487, DOI 10.1016/j.placenta.2006.05.010; Patel Satish, 2004, Appl Bioinformatics, V3, P49; Petty HR, 2006, J IMMUNOL, V176, P3205; PIJNENBORG R, 1983, PLACENTA, V4, P397, DOI 10.1016/S0143-4004(83)80043-5; Rajakumar A, 2007, AM J PHYSIOL-REG I, V293, pR766, DOI 10.1152/ajpregu.00097.2007; Rajakumar A, 2004, PLACENTA, V25, P763, DOI 10.1016/j.placenta.2004.02.011; Rajakumar A, 2001, BIOL REPROD, V64, P1019; Redman CW, 2005, SCIENCE, V308, P1592, DOI 10.1126/science.1111726; Redman CWG, 1999, AM J OBSTET GYNECOL, V180, P499, DOI 10.1016/S0002-9378(99)70239-5; Reimer T, 2002, MOL HUM REPROD, V8, P674, DOI 10.1093/molehr/8.7.674; Roberts JM, 2002, PLACENTA, V23, P359, DOI 10.1053/plac.2002.0819; ROBERTS JM, 1993, LANCET, V341, P1447, DOI 10.1016/0140-6736(93)90889-O; ROBERTS JM, 1993, LANCET, V342, P504; Roberts JM, 2001, LANCET, V357, P53, DOI 10.1016/S0140-6736(00)03577-7; Roberts JM, 2003, HYPERTENSION, V41, P437, DOI 10.1161/01.HYP.0000054981.03589.E9; Shyu MK, 2007, HUM REPROD, V22, P2723, DOI 10.1093/humrep/dem249; Sibai B, 2005, LANCET, V365, P785, DOI 10.1016/S0140-6736(05)17987-2; SIMON R, 2007, INFORMATICS, V2, P11; Soleymanlou N, 2005, J CLIN ENDOCR METAB, V90, P4299, DOI 10.1210/jc.2005-0078; Stella CL, 2006, J MATERN-FETAL NEO M, V19, P381, DOI 10.1080/14767050600678337; Tazuke SI, 1998, P NATL ACAD SCI USA, V95, P10188, DOI 10.1073/pnas.95.17.10188; Telgmann R, 1998, HUM REPROD UPDATE, V4, P472, DOI 10.1093/humupd/4.5.472; Trundley A, 2004, TISSUE ANTIGENS, V63, P1, DOI 10.1111/j.1399-0039.2004.00170.x; Wenger Roland H, 2005, Sci STKE, V2005, pre12, DOI 10.1126/stke.3062005re12; 2007, NETAFFX	56	61	64	W B SAUNDERS CO LTD	LONDON	32 JAMESTOWN RD, LONDON NW1 7BY, ENGLAND	0143-4004			PLACENTA	Placenta	JAN	2009	30	1					15	24		10.1016/j.placenta.2008.09.015		10	Developmental Biology; Obstetrics & Gynecology; Reproductive Biology	Developmental Biology; Obstetrics & Gynecology; Reproductive Biology	396EJ	WOS:000262574700004	
J	Yan, CH; Terribilini, M; Wu, FH; Jernigan, RL; Dobbs, D; Honavar, V				Yan, Changhui; Terribilini, Michael; Wu, Feihong; Jernigan, Robert L.; Dobbs, Drena; Honavar, Vasant			Predicting DNA-binding sites of proteins from amino acid sequence	BMC BIOINFORMATICS			English	Article							ALANINE-SCANNING MUTAGENESIS; TRANSCRIPTION ACTIVATION; MOLECULAR-SURFACES; IDENTIFICATION; RECOGNITION; RESIDUES; INTERFACE; DATABASE	Background: Understanding the molecular details of protein-DNA interactions is critical for deciphering the mechanisms of gene regulation. We present a machine learning approach for the identification of amino acid residues involved in protein-DNA interactions. Results: We start with a Nave Bayes classifier trained to predict whether a given amino acid residue is a DNA- binding residue based on its identity and the identities of its sequence neighbors. The input to the classifier consists of the identities of the target residue and 4 sequence neighbors on each side of the target residue. The classifier is trained and evaluated (using leave-one-out cross-validation) on a non-redundant set of 171 proteins. Our results indicate the feasibility of identifying interface residues based on local sequence information. The classifier achieves 71% overall accuracy with a correlation coefficient of 0.24, 35% specificity and 53% sensitivity in identifying interface residues as evaluated by leave-one-out cross-validation. We show that the performance of the classifier is improved by using sequence entropy of the target residue (the entropy of the corresponding column in multiple alignment obtained by aligning the target sequence with its sequence homologs) as additional input. The classifier achieves 78% overall accuracy with a correlation coefficient of 0.28, 44% specificity and 41% sensitivity in identifying interface residues. Examination of the predictions in the context of 3-dimensional structures of proteins demonstrates the effectiveness of this method in identifying DNA-binding sites from sequence information. In 33% (56 out of 171) of the proteins, the classifier identifies the interaction sites by correctly recognizing at least half of the interface residues. In 87% (149 out of 171) of the proteins, the classifier correctly identifies at least 20% of the interface residues. This suggests the possibility of using such classifiers to identify potential DNA- binding motifs and to gain potentially useful insights into sequence correlates of protein-DNA interactions. Conclusion: Naive Bayes classifiers trained to identify DNA-binding residues using sequence information offer a computationally efficient approach to identifying putative DNA- binding sites in DNA-binding proteins and recognizing potential DNA-binding motifs.	Utah State Univ, Dept Comp Sci, Logan, UT 84341 USA; Iowa State Univ, Dept Genet Dev & Cell Biol, Ames, IA 50010 USA; Iowa State Univ, Bioinformat & Comp Biol Grad Program, Ames, IA 50010 USA; Iowa State Univ, Artificial Intelligence Res Lab, Ames, IA 50010 USA; Iowa State Univ, Dept Comp Sci, Ames, IA 50010 USA; Iowa State Univ, Ctr Computat Intelligence Learning & Discovery, Ames, IA 50010 USA; Iowa State Univ, Laurence H Baker Ctr Bioinformat & Biol Stat, Ames, IA 50010 USA; Iowa State Univ, Dept Biochem Biophys & Mol Biol, Ames, IA 50010 USA	Yan, CH (reprint author), Utah State Univ, Dept Comp Sci, Logan, UT 84341 USA.	cyan@cc.usu.edu; terrible@iastate.edu; wuflyh@iastate.edu; jernigan@iastate.edu; ddobbs@iastate.edu; honavar@cs.iastate.edu	Jernigan, Robert/A-5421-2012				Ahmad S, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-33; Ahmad S, 2004, BIOINFORMATICS, V20, P477, DOI 10.1093/bioinformatics/btg432; [Anonymous], WEKA 3 DATA MINING S; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Blancafort P, 2004, MOL PHARMACOL, V66, P1361, DOI 10.1124/mol.104.002758.; Buntine W, 1991, THEORY REFINEMENT BA, P52; EISENBERG D, 1984, P NATL ACAD SCI US, V81; Gene Ontology Annotation, GENE ONTOLOGY ANNOTA; Geyer H, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh131; Ghosh D, 2005, CURR MED CHEM, V12, P691; Griffith KL, 2002, J MOL BIOL, V322, P237, DOI 10.1016/S0022-2836(02)00782-9; Hubbard S. J., 1993, NACCESS; Hulo N, 2006, NUCLEIC ACIDS RES, V34, pD227, DOI 10.1093/nar/gkj063; Jones S, 2003, NUCLEIC ACIDS RES, V31, P7189, DOI 10.1093/nar/gkg922; Jones S, 1997, J MOL BIOL, V272, P133, DOI 10.1006/jmbi.1997.1233; Keil M, 2004, J COMPUT CHEM, V25, P779, DOI 10.1002/jcc.10361; Kim JS, 2005, P NATL ACAD SCI USA, V102, P3248, DOI 10.1073/pnas.0409851102; Laity JH, 2001, CURR OPIN STRUC BIOL, V11, P39, DOI 10.1016/S0959-440X(00)00167-6; Lawson CL, 2004, CURR OPIN STRUC BIOL, V14, P10, DOI 10.1016/j.sbi.2004.01.012; Martz E, 2002, TRENDS BIOCHEM SCI, V27, P107, DOI 10.1016/S0968-0004(01)02008-4; Muller CW, 2001, CURR OPIN STRUC BIOL, V11, P26, DOI 10.1016/S0959-440X(00)00163-9; *PDB, PDB DAT; Radlinska M, 2005, PROTEINS, V58, P263, DOI 10.1002/prot.20297; Rocchia W, 2001, J PHYS CHEM B, V105, P6507, DOI 10.1021/jp010454y; Rocchia W, 2002, J COMPUT CHEM, V23, P128, DOI 10.1002/jcc.1161; SANDER C, 1991, PROTEINS, V9, P56, DOI 10.1002/prot.340090107; PABO CO, 1992, ANNU REV BIOCHEM, V61, P1053, DOI 10.1146/annurev.bi.61.070192.005201; SEN TZ, 2005, BMC BIOINFORMATICS, V5, P205; Shanahan HP, 2004, NUCLEIC ACIDS RES, V32, P4732, DOI 10.1093/nar/gkh803; TERRIBILINI M, UNPUB PREDICTION RNA; Tsuchiya Y, 2004, PROTEINS, V55, P885, DOI 10.1002/prot.20111; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Witten I.H., 1999, DATA MINING PRACTICA; Yan Changhui, 2004, Bioinformatics, V20 Suppl 1, pi371, DOI 10.1093/bioinformatics/bth920; Yan CH, 2004, NEURAL COMPUT APPL, V13, P123, DOI 10.1007/s00521-004-0414-3; PS SCAN PROGRAM; PREDICTION DNA BINDI	38	61	62	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAY 19	2006	7								262	10.1186/1471-2105-7-262		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	073IK	WOS:000239736000001	
J	Peng, Y; Kou, G; Wang, GX; Wu, WS; Shi, Y				Peng, Yi; Kou, Gang; Wang, Guoxun; Wu, Wenshuai; Shi, Yong			ENSEMBLE OF SOFTWARE DEFECT PREDICTORS: AN AHP-BASED EVALUATION METHOD	INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING			English	Article						Ensemble; classification; software defect prediction; the analytic hierarchy process (AHP)	ANALYTIC HIERARCHY PROCESS; MODELS; DECISION; QUALITY; CLASSIFIERS; TREES; FRAMEWORK; MODULES; ANALOGY	Classification algorithms that help to identify software defects or faults play a crucial role in software risk management. Experimental results have shown that ensemble of classifiers are often more accurate and robust to the effects of noisy data, and achieve lower average error rate than any of the constituent classifiers. However, inconsistencies exist in different studies and the performances of learning algorithms may vary using different performance measures and under different circumstances. Therefore, more research is needed to evaluate the performance of ensemble algorithms in software defect prediction. The goal of this paper is to assess the quality of ensemble methods in software defect prediction with the analytic hierarchy process (AHP), which is a multicriteria decision-making approach that prioritizes decision alternatives based on pairwise comparisons. Through the application of the AHP, this study compares experimentally the performance of several popular ensemble methods using 13 different performance metrics over 10 public-domain software defect datasets from the NASA Metrics Data Program (MDP) repository. The results indicate that ensemble methods can improve the classification results of software defect prediction in general and AdaBoost gives the best results. In addition, tree and rule based classifiers perform better in software defect prediction than other types of classifiers included in the experiment. In terms of single classifier, K-nearest-neighbor, C4.5, and Naive Bayes tree ranked higher than other classifiers.	[Peng, Yi; Kou, Gang; Wang, Guoxun; Wu, Wenshuai] Univ Elect Sci & Technol China, Sch Management & Econ, Chengdu 610054, Peoples R China; [Shi, Yong] Univ Nebraska, Coll Informat Sci & Technol, Omaha, NE 68182 USA; [Shi, Yong] CAS Res Ctr Fictitious Econ & Data Sci, Beijing 100080, Peoples R China	Peng, Y (reprint author), Univ Elect Sci & Technol China, Sch Management & Econ, Chengdu 610054, Peoples R China.	kougang@uestc.edu.cn			National Natural Science Foundation of China [70901011, 70901015, 70921061]	The authors would like to thank the anonymous reviewers for their insightful comments and the NASA MDP for providing the software defect datasets. This research has been partially supported by grants from the National Natural Science Foundation of China (Nos. 70901011, 70901015, and 70921061).	Baeza-Yates R., 1999, MODERN INFORM RETRIE; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, ANN STAT, V24, P2350; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Challagulla VUB, 2008, INT J ARTIF INTELL T, V17, P389, DOI 10.1142/S0218213008003947; CHAPMAN M., 2004, METRICS DATA PROGRAM; Cohen W.W., 1995, INT C MACH LEARN, P115; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; Despotis DK, 2008, INT J INF TECH DECIS, V7, P175, DOI 10.1142/S0219622008002867; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; El Emam K, 2001, J SYST SOFTWARE, V55, P301, DOI 10.1016/S0164-1212(00)00079-0; Elish KO, 2008, J SYST SOFTWARE, V81, P649, DOI 10.1016/j.jss.2007.07.040; Fenton NE, 1999, IEEE T SOFTWARE ENG, V25, P675, DOI 10.1109/32.815326; Ferri C., 2009, PATTERN RECOGNIT JAN, P27; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Ganesan K, 2000, INT J SOFTW ENG KNOW, V10, P139, DOI 10.1142/S0218194000000092; Guo L., 2004, P 15 INT S SOFTW REL; Han Jiawei, 2006, DATA MINING CONCEPTS; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HO W, EUROPEAN J OPERATION, V186, P211; Khoshgoftaar TM, 2003, EMPIR SOFTW ENG, V8, P325, DOI 10.1023/A:1025316301168; Khoshgoftaar TM, 2002, IEEE T RELIAB, V51, P455, DOI 10.1109/TR.2002.804488; Khoshgoftaar T. M., 1995, Annals of Software Engineering, V1, DOI 10.1007/BF02249049; Khoshgoftaar TM, 1997, IEEE T NEURAL NETWOR, V8, P902, DOI 10.1109/72.595888; Khoshgoftaar TM, 2000, IEEE T RELIAB, V49, P4, DOI 10.1109/24.855532; Kohavi R., 1995, P 8 EUR C MACH LEARN, P174; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Krogh A., 1995, ADV NEURAL INFORMATI, V7, P231; Kuncheva L. I., 2004, COMBINING PATTERN CL; LECESSIE S, 1992, J R STAT SOC C-APPL, V41, P191, DOI DOI 10.2307/2347628; Lessmann S, 2008, IEEE T SOFTWARE ENG, V34, P485, DOI 10.1109/TSE.2008.35; Li HL, 2008, INT J INF TECH DECIS, V7, P241, DOI 10.1142/S0219622008002922; Mair C, 2000, J SYST SOFTWARE, V53, P23, DOI 10.1016/S0164-1212(00)00005-4; Menzies T., P WORKSH PRED SOFTW; MUNSON JC, 1992, IEEE T SOFTWARE ENG, V18, P423, DOI 10.1109/32.135775; Myrtveit I, 2005, IEEE T SOFTWARE ENG, V31, P380, DOI 10.1109/TSE.2005.58; Myrtveit I, 1999, IEEE T SOFTWARE ENG, V25, P510, DOI 10.1109/32.799947; Opitz D., 1999, ARTIF INTELL, V11, P169; PENG Y, 2010, INFORM SCI, DOI DOI 10.1016/J.INS.2010.04.019; Peng Y, 2009, INT J INF TECH DECIS, V8, P749, DOI 10.1142/S0219622009003715; Peng Y, 2008, INT J INF TECH DECIS, V7, P639; Platt J., 1998, ADV KERNEL METHODS S, P185; PORTER AA, 1990, J SYST SOFTWARE, V12, P209, DOI 10.1016/0164-1212(90)90041-J; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Saaty T. L., 1980, ANAL HIERARCHY PROCE; Saaty Thomas L, 2008, International Journal of Services Science, V1, DOI 10.1504/IJSSCI.2008.017590; SAATY TL, 1990, EUR J OPER RES, V48, P9, DOI 10.1016/0377-2217(90)90057-I; SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5; Saaty TL, 2009, INT J INF TECH DECIS, V8, P7; Schapire R. E., 1996, 13 INT C MACH LEARN, P148; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Shepperd M, 2001, IEEE T SOFTWARE ENG, V27, P1014, DOI 10.1109/32.965341; Sugihara K, 2001, COMPUT INTELL, V17, P567, DOI 10.1111/0824-7935.00163; Ting KM, 2003, COMPUT INTELL-US, V19, P186, DOI 10.1111/1467-8640.00219; *US DEP COMM, 2002, 023 NIST US DEP COMM; Vapnik V., 1995, NATURE STAT LEARNING; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Wilson T, 2006, COMPUT INTELL-US, V22, P73, DOI 10.1111/j.1467-8640.2006.00275.x; Witten IH, 2005, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; ZAHEDI F, 1986, INTERFACES, V16, P96, DOI 10.1287/inte.16.4.96	66	59	59	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-6220			INT J INF TECH DECIS	Int. J. Inf. Technol. Decis. Mak.	JAN	2011	10	1					187	206		10.1142/S0219622011004282		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	706NJ	WOS:000286224800009	
J	Terribilini, M; Sander, JD; Lee, JH; Zaback, P; Jernigan, RL; Honavar, V; Dobbs, D				Terribilini, Michael; Sander, Jeffry D.; Lee, Jae-Hyung; Zaback, Peter; Jernigan, Robert L.; Honavar, Vasant; Dobbs, Drena			RNABindR: a server for analyzing and predicting RNA-binding sites in proteins	NUCLEIC ACIDS RESEARCH			English	Article							RECOGNITION; SEQUENCE	Understanding interactions between proteins and RNA is key to deciphering the mechanisms of many important biological processes. Here we describe RNABindR, a web-based server that identifies and displays RNA-binding residues in known protein-RNA complexes and predicts RNA-binding residues in proteins of unknown structure. RNABindR uses a distance cutoff to identify which amino acids contact RNA in solved complex structures (from the Protein Data Bank) and provides a labeled amino acid sequence and a Jmol graphical viewer in which RNA-binding residues are displayed in the context of the three-dimensional structure. Alternatively, RNABindR can use a Naive Bayes classifier trained on a non-redundant set of protein-RNA complexes from the PDB to predict which amino acids in a protein sequence of unknown structure are most likely to bind RNA. RNABindR automatically displays 'high specificity' and 'high sensitivity' predictions of RNA-binding residues. RNABindR is freely available at http://bindr.gdcb.iastate.edu/RNABindR.	[Terribilini, Michael; Sander, Jeffry D.; Lee, Jae-Hyung; Zaback, Peter; Dobbs, Drena] Iowa State Univ, Dept Genet Dev & Cell Biol, Ames, IA 50011 USA; [Terribilini, Michael; Sander, Jeffry D.; Lee, Jae-Hyung; Zaback, Peter; Jernigan, Robert L.; Honavar, Vasant; Dobbs, Drena] Iowa State Univ, Bioinformat & Computat Biol Program, Ames, IA 50011 USA; [Jernigan, Robert L.] Iowa State Univ, Dept Biochem Biophys & Mol Biol, Ames, IA 50011 USA; [Honavar, Vasant] Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA	Terribilini, M (reprint author), Iowa State Univ, Dept Genet Dev & Cell Biol, Ames, IA 50011 USA.	terrible@iastate.edu	Lee, Jae-Hyung/E-6827-2011; Jernigan, Robert/A-5421-2012				ALLERS J, 2001, J MOL BIOL, V311, P2746; Auweter SD, 2006, NUCLEIC ACIDS RES, V34, P4943, DOI 10.1093/nar/gkl620; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bechara E, 2007, NUCLEIC ACIDS RES, V35, P299, DOI 10.1093/nar/gkl1021; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Brodersen DE, 2005, FEBS J, V272, P2098, DOI 10.1111/j.1742-4658.2005.04651.x; Chen Y, 2005, FEBS J, V272, P2088, DOI 10.1111/j.1742-4658.2005.04650.x; Draper DE, 1999, J MOL BIOL, V293, P255, DOI 10.1006/jmbi.1999.2991; Fedor MJ, 2005, NAT REV MOL CELL BIO, V6, P399, DOI 10.1038/nrm1647; Freed EO, 2006, RETROVIROLOGY, V3, DOI 10.1186/1742-4690-3-77; Jeong E, 2006, T COMPUT SYST BIOL, V4, P123; Jones S, 2001, NUCLEIC ACIDS RES, V29, P943, DOI 10.1093/nar/29.4.943; Jurica MS, 2003, MOL CELL, V12, P5, DOI 10.1016/S1097-2765(03)00270-3; Kim H, 2003, FEBS LETT, V552, P231, DOI 10.1016/S0014-5793(03)00930-X; Kim OTP, 2006, NUCLEIC ACIDS RES, V34, P6450, DOI 10.1093/nar/gkl819; Kim VN, 2005, NAT REV MOL CELL BIO, V6, P376, DOI 10.1038/nrm1644; Mitchell T.M., 1997, MACHINE LEARNING; Moore MJ, 2005, SCIENCE, V309, P1514, DOI 10.1126/science.1111443; Noller HF, 2005, SCIENCE, V309, P1508, DOI 10.1126/science.1111771; Terribilini Michael, 2006, Pac Symp Biocomput, P415, DOI 10.1142/9789812701626_0038; Terribilini M, 2006, RNA, V12, P1450, DOI 10.1261/rna.2197306; Treger M, 2001, J MOL RECOGNIT, V14, P199, DOI 10.1002/jmr.534; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang LJ, 2006, NUCLEIC ACIDS RES, V34, pW243, DOI 10.1093/nar/gkl298; Witten IH, 2005, DATA MINING PRACTICA	25	57	57	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048			NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL	2007	35			S			W578	W584		10.1093/nar/gkm294		7	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	293CD	WOS:000255311500108	
J	Kuncheva, LI				Kuncheva, LI			"Fuzzy" versus "Nonfuzzy" in combining classifiers designed by boosting	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						Adaboost; classifier combination; decision templates; ensembles of classifiers created by Boosting; fuzzy integral; weighted majority vote	NEURAL-NETWORKS; FUSION; CLASSIFICATION; RECOGNITION; COMBINATION; ALGORITHMS; CONNECTIVES; OPERATORS; ACCURACY; LOGIC	Boosting is recognized as one of the most successful techniques for generating classifier ensembles. Typically, the classifier outputs are combined by the weighted majority vote. The purpose of this study is to demonstrate the advantages of some fuzzy combination methods for ensembles of classifiers designed by Boosting. We ran two-fold cross-validation experiments on six benchmark data sets to compare the fuzzy and nonfuzzy combination methods. On the "fuzzy side" we used the fuzzy integral and the decision templates with different similarity measures. On the "nonfuzzy side" we tried the weighted majority vote as well as simple combiners such as the majority vote, minimum, maximum, average, product, and the Naive-Bayes combination. In our experiments, the fuzzy combination methods performed consistently better than the nonfuzzy methods. The weighted majority vote showed a stable performance, though slightly inferior to the performance of the fuzzy combiners.	Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales	Kuncheva, LI (reprint author), Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales.	L.i.kuncheva@bangor.ac.uk					BARABASH YL, 1983, COLLECTIVE STAT DECI; BATTITI R, 1994, NEURAL NETWORKS, V7, P691, DOI 10.1016/0893-6080(94)90046-9; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Benediktsson JA, 1997, NONLINEAR ANAL-THEOR, V30, P1323, DOI 10.1016/S0362-546X(97)00222-8; Bloch I, 1996, IEEE T SYST MAN CY A, V26, P52, DOI 10.1109/3468.477860; BouchonMeunier B, 1996, FUZZY SET SYST, V84, P143, DOI 10.1016/0165-0114(96)00067-X; Breiman L, 1999, COMBINING ARTIFICIAL, P31; CHO SB, 1995, IEEE T NEURAL NETWOR, V6, P497; CHO SB, 1995, IEEE T SYST MAN CYB, V25, P380; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dubois D, 1997, FUZZY SET SYST, V90, P141, DOI 10.1016/S0165-0114(97)00080-8; Duda R.O., 2001, PATTERN CLASSIFICATI; DUOBIS D, 1985, INFORM SCI, V36, P85; DUOBIS D, 1980, FUZZY SETS SYSTEMS T; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FUMERA G, 2002, 16 INT C PATT REC; Gader PD, 1996, PATTERN RECOGN LETT, V17, P577, DOI 10.1016/0167-8655(96)00021-9; Grabisch M., 1992, P 1 IEEE C FUZZ SYST, P47; GRABISCH M, 1995, IEEE T FUZZY SYST, V3, P96, DOI 10.1109/91.366561; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; KITTLER J, 2002, P 3 INT WORKSH MULT, V2364, P314; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KUHNCHEVA LI, 2003, MACHINE LEARN, V51, P181; Kuncheva LI, 2001, PATTERN RECOGN, P427, DOI 10.1142/9789812386533_0015; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X; LAM L, 1994, INT C PATT RECOG, P418, DOI 10.1109/ICPR.1994.576970; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; PIERCE W, 1961, THESIS STANFORD U ST; RUTA D, 2000, 11 U PAISL DEP COM I; Schapire R., 1999, P 4 EUR C COMP LEARN, P1; Schapire R. E., 2002, MSRI WORKSH NONL EST; SHAPLEY L, 1984, PUBLIC CHOICE, V43, P329, DOI 10.1007/BF00118940; Tumer K., 1996, PATTERN RECOGN, V29, P341, DOI DOI 10.1016/0031-3203(95)00085-2; Tumer K., 1996, CONNECT SCI, V8, P385; TURNER K, 1999, COMBINING ARTIFICIAL, P127; Verikas A, 1999, PATTERN RECOGN LETT, V20, P429, DOI 10.1016/S0167-8655(99)00012-4; Wang DY, 1998, IEEE T SYST MAN CY B, V28, P583, DOI 10.1109/3477.704297; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; YAGER RR, 1980, FUZZY SET SYST, V4, P235, DOI 10.1016/0165-0114(80)90013-5; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; 2002, LECT NOTES COMPUTER, V2364; 2000, LECT NOTES COMPUTER, V1857; 2001, LECT NOTES COMPUTER, V2096	47	57	57	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1063-6706			IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	DEC	2003	11	6					729	741		10.1109/TFUZZ.2003.819842		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	761DW	WOS:000187885700003	
J	Manevitz, LM; Yousef, M				Manevitz, LM; Yousef, M			One-class SVMs for document classification	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article; Proceedings Paper	Workshop on Kernel Methods	DEC   01, 2000	BRECKENRIDGE, COLORADO			support vector machine; SVM; neural network; compression neural network; text retrieval; positive information		We implemented versions of the SVM appropriate for one-class classification in the context of information retrieval. The experiments were conducted on the standard Reuters data set. For the SVM implementation we used both a version of Scholkopf et al. and a somewhat different version of one-class SVM based on identifying "outlier" data as representative of the second-class. We report on experiments with different kernels for both of these implementations and with different representations of the data, including binary vectors, tf-idf representation and a modification called "Hadamard" representation. Then we compared it with one-class versions of the algorithms prototype (Rocchio), nearest neighbor, naive Bayes, and finally a natural one-class neural network classification method based on "bottleneck" compression generated filters. The SVM approach as represented by Scholk-opf was superior to all the methods except the neural network one, where it was, although occasionally worse, essentially comparable. However, the SVM methods turned out to be quite sensitive to the choice of representation and kernel in ways which are not well understood; therefore, for the time being leaving the neural network approach as the most robust.	Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel	Manevitz, LM (reprint author), Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel.						BALABANOVIC A, 1995, AAAI SPRING S SER IN; DATTA P, 1997, THESIS U CALIFORNIA; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Japkowicz N., 1995, P 14 JOINT C ART INT, P518; JOACHIMS T, 1996, CMUCS96118 SCH COMP; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; LANG K, 1995, 12 INT C MACH LEARN, P331; Lewis D., REUTERS 21578 TEXT C; MANEVITZ LM, 2001, DOCUMENT CLASSIFICAT; MUNRO P, 1988, ADV COGNITIVE SCI, V3; Pazzani M., 1996, AAAI96 P 13 NAT C AR, P54; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Scholkopf B., 1999, MSRTR9987; Van Rijsbergen C.J., 1979, INFORMATION RETRIEVA; YANG Y, P SIGIR 99 22 ACM IN	15	57	63	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	SPR	2002	2	2					139	154		10.1162/15324430260185574		16	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	559YZ	WOS:000176055300004	
J	Meila, M; Heckerman, D				Meila, M; Heckerman, D			An experimental comparison of model-based clustering methods	MACHINE LEARNING			English	Article						clustering; model-based clustering; naive-Bayes model; multinomial-mixture model; EM algorithm; agglomerative clustering; initialization	EM ALGORITHM; LIKELIHOOD	We compare the three basic algorithms for model-based clustering on high-dimensional discrete-variable datasets. All three algorithms use the same underlying model: a naive-Bayes model with a hidden root node, also known as a multinomial-mixture model. In the first part of the paper, we perform an experimental comparison between three batch algorithms that learn the parameters of this model: the Expectation-Maximization (EM) algorithm, a "winner take all" version of the EM algorithm reminiscent of the K-means algorithm, and model-based agglomerative clustering. We find that the EM algorithm significantly outperforms the other methods, and proceed to investigate the effect of various initialization methods on the final solution produced by the EM algorithm. The initializations that we consider are (1) parameters sampled from an uninformative prior, (2) random perturbations of the marginal distribution of the data, and (3) the output of agglomerative clustering. Although the methods are substantially different, they lead to learned models that are similar in quality.	Microsoft Res, Redmond, WA 98052 USA	Meila, M (reprint author), Univ Washington, Dept Stat, Box 354322, Seattle, WA 98195 USA.						BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; BAUER E, 1997, P 13 C UNC ART INT P; CELEUX G, 1992, COMPUT STAT DATA AN, V14, P315, DOI 10.1016/0167-9473(92)90042-E; Cheeseman P, 1995, ADV KNOWLEDGE DISCOV, P153; Chickering DM, 1997, MACH LEARN, V29, P181; Clogg C., 1995, HDB STAT MODELING SO, P311; DeGroot M., 1970, OPTIMAL STAT DECISIO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dobson A., 1990, INTRO GEN LINEAR MOD; Duda R., 1973, PATTERN CLASSIFICATI; FISHER D, 1996, J ARTIFICIAL INTELLI, V4, P270; Fraley C, 1998, SIAM J SCI COMPUT, V20, P270, DOI 10.1137/S1064827596311451; Frey BJ, 1996, ADV NEUR IN, V8, P661; Jain A. K., 1988, ALGORITHMS CLUSTERIN; MEILA M, 1989, MSRTR9806; Thiesson B., 1995, P 1 INT C KNOWL DISC, P306; Thiesson B., 1999, BAYESIAN STAT, V6, P631; Zipf G. K., 1949, HUMAN BEHAV PRINCIPL	18	57	57	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JAN	2001	42	1-2					9	29		10.1023/A:1007648401407		21	Computer Science, Artificial Intelligence	Computer Science	387GD	WOS:000166114100002	
J	Szafron, D; Lu, P; Greiner, R; Wishart, DS; Poulin, B; Eisner, R; Lu, Z; Anvik, J; Macdonell, C; Fyshe, A; Meeuwis, D				Szafron, D; Lu, P; Greiner, R; Wishart, DS; Poulin, B; Eisner, R; Lu, Z; Anvik, J; Macdonell, C; Fyshe, A; Meeuwis, D			Proteome Analyst: custom predictions with explanations in a web-based tool for high-throughput proteome annotations	NUCLEIC ACIDS RESEARCH			English	Article							DATABASE	Proteome Analyst (PA) (http://www.cs.ualberta.ca/similar tobioinfo/PA/) is a publicly available, high-throughput, web-based system for predicting various properties of each protein in an entire proteome. Using machine-learned classifiers, PA can predict, for example, the GeneQuiz general function and Gene Ontology (GO) molecular function of a protein. In addition, PA is currently the most accurate and most comprehensive system for predicting subcellular localization, the location within a cell where a protein performs its main function. Two other capabilities of PA are notable. First, PA can create a custom classifier to predict a new property, without requiring any programming, based on labeled training data (i.e. a set of examples, each with the correct classification label) provided by a user. PA has been used to create custom classifiers for potassium-ion channel proteins and other general function ontologies. Second, PA provides a sophisticated explanation feature that shows why one prediction is chosen over another. The PA system produces a Naive Bayes classifier, which is amenable to a graphical and interactive approach to explanations for its predictions; transparent predictions increase the user's confidence in, and understanding of, PA.	Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada	Lu, P (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.	duane@cs.uslberta.ca; paullu@cs.ualberta.ca					Andrade MA, 1999, BIOINFORMATICS, V15, P391, DOI 10.1093/bioinformatics/15.5.391; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Frishman D, 2001, BIOINFORMATICS, V17, P44, DOI 10.1093/bioinformatics/17.1.44; Gaasterland T, 1996, TRENDS GENET, V12, P76, DOI 10.1016/0168-9525(96)81406-5; Gallin WJ, 2001, POTASSIUM CHANNELS IN CARDIOVASCULAR BIOLOGY, P3; Harris NL, 1997, GENOME RES, V7, P754; Hubbard T, 2002, NUCLEIC ACIDS RES, V30, P38, DOI 10.1093/nar/30.1.38; Kitson David H, 2002, Brief Bioinform, V3, P32, DOI 10.1093/bib/3.1.32; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Lu Z, 2004, BIOINFORMATICS, V20, P547, DOI 10.1093/bioinformatics/btg447; Mitchell T.M., 1997, MACHINE LEARNING; Overton G C, 1998, Pac Symp Biocomput, P291; SZAFRON D, 2003, 0309 U ALB DEP COMP; SZAFRON D, 2003, 12 INT C MACH LEARN, P2	14	56	58	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048			NUCLEIC ACIDS RES	Nucleic Acids Res.	JUL 1	2004	32			2			W365	W371		10.1093/nar/gkh485		7	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	832NB	WOS:000222273100074	
J	Korpipaa, P; Koskinen, M; Peltola, J; Makela, SM; Seppanen, T				Korpipaa, Panu; Koskinen, Miika; Peltola, Johannes; Makela, Satu-Marja; Seppanen, Tapio			Bayesian approach to sensor-based context awareness	PERSONAL AND UBIQUITOUS COMPUTING			English	Article						Audio context; Bayesian networks; Context awareness; Context recognition; Mobile computing; Sensor		The usability of a mobile device and services can be enhanced by context awareness. The aim of this experiment was to expand the set of generally recognizable constituents of context concerning personal mobile device usage. Naive Bayesian networks were applied to classify the contexts of a mobile device user in her normal daily activities. The distinguishing feature of this experiment in comparison to earlier context recognition research is the use of a naive Bayes framework, and an extensive set of audio features derived partly from the algorithms of the upcoming MPEG-7 standard. The classification was based mainly on audio features measured in a home scenario. The classification results indicate that with a resolution of one second in segments of 5-30 seconds, situations can be extracted fairly well, but most of the contexts are likely to be valid only in a restricted scenario. Naive Bayes framework is feasible for context recognition. In real world conditions, the recognition accuracy using leave-one-out cross validation was 87% of true positives and 95% of true negatives, averaged over nine eight-minute scenarios containing 17 segments of different lengths and nine different contexts. Respectively, the reference accuracies measured by testing with training data were 88% and 95%, suggesting that the model was capable of covering the variability introduced in the data on purpose. Reference recognition accuracy in controlled conditions was 96% and 100%, respectively. However, from the applicability viewpoint, generalization remains a problem, as from a wider perspective almost any feature may refer to many possible real world situations.	[Korpipaa, Panu; Koskinen, Miika; Peltola, Johannes; Makela, Satu-Marja] VTT Elect, VTT Tech Res Ctr Finland, FIN-90571 Oulu, Finland; [Seppanen, Tapio] Univ Oulu, Elect & Informat Engn Dept, Oulu, Finland	Korpipaa, P (reprint author), VTT Elect, VTT Tech Res Ctr Finland, Kaitovayla 1,POB 1100, FIN-90571 Oulu, Finland.	Panu.Korpipaa@vtt.fi	Koskinen, Miika/A-7001-2013	Koskinen, Miika/0000-0002-7267-5811	NOKIA	The authors would like to acknowledge the funding provided by NOKIA.	BROWN J, 1989, J ACOUST SOC AM, V4, P1595; CLARKSON B, 1998, P 2 INT S WEAR COMP, P154; CLARKSON B., 2000, P 4 INT S WEAR COMP, P69; HIMBERG J., 2001, P IEEE C MULT FUS IN, P127; HINCKLEY K, 2000, CHI LETT, V2, P91; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; Madabhushi A., 1999, Proceedings Second IEEE Workshop on Visual Surveillance (VS'99) (Cat. No.98-89223), DOI 10.1109/VS.1999.780265; MANTYJARVI J, 2001, IFAC IFIP IFORS IEA, P445; MANTYJARVI J., 2001, P IEEE INT C SYST MA, P747; Minsky M, 2000, COMMUN ACM, V43, P67; Mitchell T.M., 1997, MACHINE LEARNING; MONTI S, 1998, ISSP9801 U PITTSB; Pearl J., 1988, PROBABILISTIC REASON; Peltonen V., 2002, P INT C AC SPEECH SI; Peltonen VTK, 2001, P 110 AUD ENG SOC CO; Penttil J., 2001, P INF OUL INT WORKSH, P125; SAUNDERS J, 1996, P INT C AC SPEECH SI, V2, P993; Van Laerhoven K., 2000, P ISWC2000, P77; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; BAYES NET TOOLBOX DO	21	56	58	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	1617-4909			PERS UBIQUIT COMPUT	Pers. Ubiquitous Comput.	JUL	2003	7	2					113	124		10.1007/s00779-003-0237-8		12	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	V11VN	WOS:000207559200005	
J	Belgard, TG; Marques, AC; Oliver, PL; Abaan, HO; Sirey, TM; Hoerder-Suabedissen, A; Garcia-Moreno, F; Molnar, Z; Margulies, EH; Ponting, CP				Belgard, T. Grant; Marques, Ana C.; Oliver, Peter L.; Abaan, Hatice Ozel; Sirey, Tamara M.; Hoerder-Suabedissen, Anna; Garcia-Moreno, Fernando; Molnar, Zoltan; Margulies, Elliott H.; Ponting, Chris P.			A Transcriptomic Atlas of Mouse Neocortical Layers	NEURON			English	Article							LONG NONCODING RNAS; CAT VISUAL-CORTEX; GENE-EXPRESSION; CEREBRAL-CORTEX; PARKINSONS-DISEASE; ALZHEIMERS-DISEASE; NMDA RECEPTORS; HUMAN BRAIN; CELL-TYPES; NEURONS	In the mammalian cortex, neurons and glia form a patterned structure across six layers whose complex cytoarchitectonic arrangement is likely to contribute to cognition. We sequenced transcriptomes from layers 1-6b of different areas (primary and secondary) of the adult (postnatal day 56) mouse somatosensory cortex to understand the transcriptional levels and functional repertoires of coding and noncoding loci for cells constituting these layers. A total of 5,835 protein-coding genes and 66 noncoding RNA loci are differentially expressed ("patterned") across the layers, on the basis of a machine-learning model (naive Bayes) approach. Layers 2-6b are each associated with specific functional and disease annotations that provide insights into their biological roles. This new resource (http://genserv.anat.ox.ac.uk/layers) greatly extends currently available resources, such as the Allen Mouse Brain Atlas and microarray data sets, by providing quantitative expression levels, by being genome-wide, by including novel loci, and by identifying candidate alternatively spliced transcripts that are differentially expressed across layers.	[Belgard, T. Grant; Sirey, Tamara M.; Hoerder-Suabedissen, Anna; Garcia-Moreno, Fernando; Molnar, Zoltan] Univ Oxford, Dept Physiol Anat & Genet, Oxford OX1 3QX, England; [Belgard, T. Grant; Marques, Ana C.; Oliver, Peter L.; Sirey, Tamara M.; Ponting, Chris P.] Univ Oxford, MRC Funct Genom Unit, Oxford OX1 3QX, England; [Belgard, T. Grant; Abaan, Hatice Ozel; Margulies, Elliott H.] NHGRI, Genome Technol Branch, NIH, Bethesda, MD 20892 USA	Molnar, Z (reprint author), Univ Oxford, Dept Physiol Anat & Genet, Oxford OX1 3QX, England.	zoltan.molnar@dpag.ox.ac.uk; emargulies@illumina.com; chris.ponting@dpag.ox.ac.uk	Hoerder-Suabedissen, Anna/G-7053-2011		Marshall Scholarship; New College, Oxford; NIH-Oxford-Cambridge; Marie Curie Fellowship; National Human Genome Research Institute; MRC; BBSRC; MAC; Wellcome Trust; St. John's College, Oxford; ERC	We thank W.Z. Wang, A.F. Cheung, and the NIH Intramural Sequencing Center for technical assistance; R.A. Chodroff, E.D. Green, A. Heger, L. Goodstadt, M. Goodson, C. Webber and J. Becker for helpful discussions. T.G.B. was supported by a Marshall Scholarship; New College, Oxford; and the NIH-Oxford-Cambridge Scholars Program. A.C.M. was supported by a Marie Curie Fellowship. E.H.M. and H.O.A. were supported by the Intramural Research Program of the National Human Genome Research Institute. A.H-S. was supported by a MRC Programme Grant to ZM. T.M.S. was supported by a BBSRC Project Grant to ZM and C.P.P. Z.M. was supported by MAC, BBSRC, Wellcome Trust and St. John's College, Oxford. P.L.O. was supported by the MRC and C.P.P. was supported by the MRC, BBSRC and ERC.	Abou-Sleiman PM, 2006, NAT REV NEUROSCI, V7, P207, DOI 10.1038/nrn1868; Arlotta P, 2005, NEURON, V45, P207, DOI 10.1016/j.neuron.2004.12.036; Ashburner M, 2000, NAT GENET, V25, P25; BEEN MS, 2006, NEUROLOGY, V66, P1399; BELGARD TG, 2011, TRANSCRIPTOMIC ATLAS; Biskup S, 2006, ANN NEUROL, V60, P557, DOI 10.1002/ana.21019; Blake JA, 2011, NUCLEIC ACIDS RES, V39, pD842, DOI 10.1093/nar/gkq1008; Bradford JR, 2010, BMC GENOMICS, V11, DOI 10.1186/1471-2164-11-282; Brodmann K., 1909, VERGLEICHENDE LOKALI; Burbulla LF, 2010, EUR J CLIN INVEST, V40, P1048, DOI 10.1111/j.1365-2362.2010.02354.x; Cahoy JD, 2008, J NEUROSCI, V28, P264, DOI 10.1523/JNEUROSCI.4178-07.2008; Chen YA, 2010, BMC GENOMICS, V11, DOI 10.1186/1471-2164-11-293; Conti F, 1997, MOL NEUROBIOL, V14, P1, DOI 10.1007/BF02740618; Cucchiarini M, 2003, GENE THER, V10, P657, DOI 10.1038/sj.gt.3301925; CURRIE SN, 1994, BRAIN RES, V662, P103, DOI 10.1016/0006-8993(94)90801-X; Demsar J, 2004, LECT NOTES ARTIF INT, V3202, P537; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; Doyle JP, 2008, CELL, V135, P749, DOI 10.1016/j.cell.2008.10.029; GILBERT CD, 1979, NATURE, V280, P120, DOI 10.1038/280120a0; Gregg C, 2010, SCIENCE, V329, P643, DOI 10.1126/science.1190830; Guillemot F, 2006, EUR J NEUROSCI, V23, P857, DOI 10.1111/j.1460-9568.2006.04626.x; Hasan MR, 2006, FEBS LETT, V580, P3505, DOI 10.1016/j.febslet.2006.05.028; Hawrylycz M, 2010, METHODS, V50, P113, DOI 10.1016/j.ymeth.2009.09.005; Heintz N, 2004, NAT NEUROSCI, V7, P483, DOI 10.1038/nn0504-483; Hevner RF, 2006, NEUROSCI RES, V55, P223, DOI 10.1016/j.neures.2006.03.004; Hoerder-Suabedissen A, 2009, CEREB CORTEX, V19, P1738, DOI 10.1093/cercor/bhn195; Isaacs AM, 2003, J NEUROSCI, V23, P1631; Jones EG, 2010, CEREB CORTEX, V20, P2261, DOI 10.1093/cercor/bhq127; Jones EG, 2000, ANNU REV NEUROSCI, V23, P1, DOI 10.1146/annurev.neuro.23.1.1; Kaas JH, 2008, BRAIN RES BULL, V75, P384, DOI 10.1016/j.brainresbull.2007.10.009; Kall L., 2008, BIOINFORMATICS, V24, pi42; Kanehisa M, 2004, NUCLEIC ACIDS RES, V32, pD277, DOI 10.1093/nar/gkh063; Kanold PO, 2010, ANNU REV NEUROSCI, V33, P23, DOI 10.1146/annurev-neuro-060909-153244; Kim TK, 2010, NATURE, V465, P182, DOI 10.1038/nature09033; Knobloch M, 2008, MOL NEUROBIOL, V37, P73, DOI 10.1007/s12035-008-8018-z; Kong L, 2007, NUCLEIC ACIDS RES, V35, pW345, DOI 10.1093/nar/gkm391; Lein ES, 2007, NATURE, V445, P168, DOI 10.1038/nature05453; Lorente de No R., 1949, PHYSL NERVOUS SYSTEM, P288; Markram H, 2004, NAT REV NEUROSCI, V5, P793, DOI 10.1038/nrn1519; Marques AC, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-11-r124; Maruyama T, 2008, DEV NEUROBIOL, V68, P317, DOI 10.1002/dneu.20592; Melot T, 2001, EUR J BIOCHEM, V268, P3483, DOI 10.1046/j.1432-1327.2001.02251.x; Miller JA, 2010, P NATL ACAD SCI USA, V107, P12698, DOI 10.1073/pnas.0914257107; Molnar Z, 2006, NEUROSCI RES, V55, P105, DOI 10.1016/j.neures.2006.02.008; Molyneaux BJ, 2007, NAT REV NEUROSCI, V8, P427, DOI 10.1038/nrn2151; Mortazavi A, 2008, NAT METHODS, V5, P621, DOI 10.1038/nmeth.1226; Nelson SB, 2006, TRENDS NEUROSCI, V29, P339, DOI 10.1016/j.tins.2006.05.004; Neuwelt EA, 2011, NAT REV NEUROSCI, V12, P169, DOI 10.1038/nrn2995; Ng L, 2010, METHODS, V50, P55, DOI 10.1016/j.ymeth.2009.10.001; Oeschger F.M., 2011, CEREB CORTE IN PRESS, DOI DOI 10.1093/CERCOR/BHR197; Orom UA, 2010, CELL, V143, P46, DOI 10.1016/j.cell.2010.09.001; Pedersen JS, 2006, PLOS COMPUT BIOL, V2, P251, DOI 10.1371/journal.pcbi.0020033; PERRY VH, 1985, NEUROSCIENCE, V15, P313, DOI 10.1016/0306-4522(85)90215-5; PETERS A, 1993, CEREB CORTEX, V3, P49, DOI 10.1093/cercor/3.1.49; Ponjavic J, 2009, PLOS GENET, V5, DOI 10.1371/journal.pgen.1000617; Ponting CP, 2010, HUM MOL GENET, V19, pR162, DOI 10.1093/hmg/ddq362; Ponting CP, 2009, CELL, V136, P629, DOI 10.1016/j.cell.2009.02.006; Rakic P, 2009, NAT REV NEUROSCI, V10, P724, DOI 10.1038/nrn2719; Ray M, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-10-r148; Rhead B, 2010, NUCLEIC ACIDS RES, V38, pD613, DOI 10.1093/nar/gkp939; Rowell JJ, 2010, J COMP NEUROL, V518, P3272, DOI 10.1002/cne.22399; Santos M, 2009, BRAIN RES REV, V62, P19, DOI 10.1016/j.brainresrev.2009.08.003; Strand AD, 2007, PLOS GENET, V3, DOI 10.1371/journal.pgen.0030059; Tan SS, 2009, GLIA, V57, P1024, DOI 10.1002/glia.20826; THOMSON KM, 2003, CEREB CORTEX, V13, P5; Toyama M, 1974, Brain Res, V79, P139; Trapnell C, 2009, BIOINFORMATICS, V25, P1105, DOI 10.1093/bioinformatics/btp120; Trapnell C, 2010, NAT BIOTECHNOL, V28, P511, DOI 10.1038/nbt.1621; Underwood JG, 2005, MOL CELL BIOL, V25, P10005, DOI 10.1128/MCB.25.22.10005-10016.2005; Uziel D, 2006, ANAT REC PART A, V288A, P135, DOI 10.1002/ar.a.20286; Winden KD, 2009, MOL SYST BIOL, V5, DOI 10.1038/msb.2009.46; Yamamoto N., 2007, NOVART FDN SYMP, V288, P276; Yamamoto Nobuhiko, 2007, Novartis Found Symp, V288, P199; Yamamoto N., 2007, NOVART FDN SYMP, V288, P208; Yoneshima H, 2006, NEUROSCIENCE, V137, P401, DOI 10.1016/j.neuroscience.2005.08.075; Zilles K, 2010, NAT REV NEUROSCI, V11, P139, DOI 10.1038/nrn2776	76	55	55	CELL PRESS	CAMBRIDGE	600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA	0896-6273			NEURON	Neuron	AUG 25	2011	71	4					605	616		10.1016/j.neuron.2011.06.039		12	Neurosciences	Neurosciences & Neurology	815JJ	WOS:000294521600007	
B	Yang, YM; Liu, X		Hearst, M; Gey, F; Tong, R		Yang, YM; Liu, X			A re-examination of text categorization methods	SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL			English	Proceedings Paper	22nd International Conference on Research and Development in Information Retrieval	AUG, 1999	BERKELEY, CA	British Comp Soc, Info Retriev Special Grp, Gesell Info Germany, Microsoft, West Grp, AT&T Labs, Sun Microsyst, Verity, Xerox Parc, IBM, Lexis-Nexis	UNIV CA			This paper reports a controlled study with statistical significance tests on five text categorization methods: the Support Vector Machines (SVM), a k-Nearest Neighbor (kNN) classifier, a neural network (NNet) approach, the Linear Least-squares Fit (LLSF) mapping and a Naive Bayes (NB) classifier. We focus on the robustness of these methods in dealing with a skewed category distribution, and their performance as function of the training-set category frequency. Our results show that SVM, kNN and LLSF significantly outperform NNet and NE when the number of positive training instances per category are small (less than ten), and that all the methods perform comparably when the categories are sufficiently common (over 300 instances).	Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Yang, YM (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.						APTE C, 1994, P 17 ANN ACM SIGIR C; Apte C., 1998, P C AUT LEARN DISC W; Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290970; BELUR V, 1991, NEARST NEIGHBOR NN N; Berry D. A., 1990, STAT THEORY METHODS; Cohen W. W., 1996, SIGIR Forum; COHEN WW, 1995, 12 INT C MACH LEAR I; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Fuhr N., 1991, P RIAO 91, P606; HAYES P, 1990, 2 ANN C INN APPL ART; Iwayama M., 1995, P 18 ANN INT ACM SIG, P273, DOI 10.1145/215206.215371; JAOCHIMS T, 1998, EUR C MACH LEARN ECM; KOLLER D, 1997, 14 INT C MACH LEARN, P170; LAM WW, 1996, SIGIR 96, V81, P307; Lewis D. D., 1996, SIGIR Forum; LEWIS DD, 1994, P 3 ANN S DOC AN INF; MASAND B, 1992, 15 ANN INT ACM SIGIR, P59; McCallum A, 1998, AAAI 98 WORKSH LEARN; Mitchell T., 1996, MACHINE LEARNING; Moulinier I, 1997, LAFORIALIP6 U PAR 6; MOULINIER I, 1996, P 5 ANN S DOC AN INF; NG HT, 1997, 20 ANN INT ACM SIGIR, P67; OSUNA RF, 1996, SUPPORT VECTOR MACHI; Platt J.C., 1998, MSTTR9814 MICR RES; Tzeras K., 1993, P 16 ANN INT ACM SIG, P22, DOI 10.1145/160688.160691; Vapnic V, 1995, NATURE STAT LEARNING; VONRIJSBERGEN C, 1979, INFORMATION RETRIEVA; WIENER E, 1995, P 4 ANN S DOC AN INF; Yang Y, 1997, 14 INT C MACH LEARN, P412; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; YANG Y, 1999, IN PRESS J INFORMATI; Yang Y., 1994, 17 ANN INT ACM SIGIR, P13; YANG Y, 1996, AAAI SPRING S MACH L, P88	33	55	61	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			1-58113-096-1				1999							42	49				8	Computer Science, Information Systems	Computer Science	BN86U	WOS:000083284000007	
J	Peng, FC; Schuurmans, D; Wang, SJ				Peng, FC; Schuurmans, D; Wang, SJ			Augmenting naive Bayes classifiers with statistical language models	INFORMATION RETRIEVAL			English	Article; Proceedings Paper	25th European Conference on Information Retrieval Research (ECIR 2003)	APR 14-16, 2003	PISA, ITALY	Elsevier, Assoc Italiana Informat Calcolo Automat, CEPIS, LIBERO, Microsoft Res, CRE, fast, Sharp, IBM, Data Port		naive Bayes; text classification; n-gram language models; smoothing	TEXT CATEGORIZATION; TERMS	We augment naive Bayes models with statistical n-gram language models to address short-comings of the standard naive Bayes text classifier. The result is a generalized naive Bayes classifier which allows for a local Markov dependence among observations; a model we refer to as the Chain Augmented Naive Bayes (CAN) Bayes classifier. CAN models have two advantages over standard naive Bayes classifiers. First, they relax some of the independence assumptions of naive Bayes - allowing a local Markov chain dependence in the observed variables - while still permitting efficient inference and learning. Second, they permit straightforward application of sophisticated smoothing techniques from statistical language modeling, which allows one to obtain better parameter estimates than the standard Laplace smoothing used in naive Bayes classification. In this paper, we introduce CAN models and apply them to various text classification problems. To demonstrate the language independent and task independent nature of these classifiers, we present experimental results on several text classification problems - authorship attribution, text genre classification, and topic detection - in several languages - Greek, English, Japanese and Chinese. We then systematically study the key factors in the CAN model that can influence the classification performance, and analyze the strengths and weaknesses of the model.	Univ Massachusetts, Dept Comp Sci, Ctr Intelligent Informat Retrieval, Amherst, MA 01003 USA; Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada	Peng, FC (reprint author), Univ Massachusetts, Dept Comp Sci, Ctr Intelligent Informat Retrieval, 140 Governors Dr, Amherst, MA 01003 USA.	fuchun@cs.umass.edu; dale@cs.ualberta.ca; swang@cs.ualberta.ca					AIZAWA A, 2001, P 6 NAT LANG PROC PA, P307; Bell T. C., 1990, TEXT COMPRESSION; Benedetto D., 2002, PHYS REV LETT, V88; CAVNAR WB, 1994, 3 ANN S DOC AN INF R; Chen S. F., 1998, TR1098 HARV U COMP S; CHURCH K, 1991, COMPUTER SPEECH LANG, V5; Cohen WW, 1999, ACM T INFORM SYST, V17, P141, DOI 10.1145/306686.306688; DAMASHEK M, 1995, SCIENCE, V267, P843, DOI 10.1126/science.267.5199.843; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; EYHERAMENDY S, 2003, P ART INT STAT 2003; FEDERICO M, 1998, SPOKEN DIALOGUES COM, pCH7; FRIEDMAN N, 1997, MACH LEARN, V29, P31; GOODMAN J, 2002, UNPUB COMMENT LANGUA; HE J, 2001, APPL INTELLIGENCE; HE J, 2000, P PRICAI 2000 INT WO, P24; Hiemstra D., 2001, THESIS U TWENTE; Holmes D. I., 1995, LIT LINGUISTIC COMPU, V10, P111, DOI 10.1093/llc/10.2.111; Howard P.G., 1993, THESIS BROWN U; HUFFMAN S, 1995, P TREC 4 4 TEXT RETR, P359; Jelinek F., 1990, READINGS SPEECH RECO, P450; Joachims T., 1998, P 10 EUR C MACH LEAR; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; KEOGH E, 1999, P ART INT STAT 1999; KESSLER B, 1997, P 35 ANN M ASS COMP; Kneser R., 1995, P IEEE INT C AC SPEE, V1, P181; Kwok KL, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P34, DOI 10.1145/258525.258531; Kwok KL, 1999, J AM SOC INFORM SCI, V50, P709, DOI 10.1002/(SICI)1097-4571(1999)50:8<709::AID-ASI8>3.0.CO;2-V; LANG K, 1995, P 12 INT C MACH LEAR, P331; LEE Y, 2002, P 25 ANN INT ACM SIG; LEWIS D, 1998, P 10 EUR C MACH LEAR; Lewis D. D., 1992, THESIS U MASSACHUSET; MANNING C, 1999, FDN STAT NASTURAL LA; McCallum A., 1998, P AAAI 98 WORKSH LEA; MOFFAT A, 1990, IEEE T COMMUN, V38, P1917, DOI 10.1109/26.61469; NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Ponte J. M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.291008; Rennie J.D.M., 2001, THESIS MIT; Rish I., 2001, P IJCAI 01 WORKSH EM; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; SCHMITT JC, 1991, Patent No. 5062143; Scott Sam, 1999, P 16 INT C MACH LEAR, P379; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Stamatatos E, 2000, COMPUT LINGUIST, V26, P471, DOI 10.1162/089120100750105920; Stamatatos E, 2001, COMPUT HUMANITIES, V35, P193, DOI 10.1023/A:1002681919510; TEAHAN W, 2003, IN PRESS LANGUAGE MO; TEAHAN WJ, 2001, P WORKSH LANG MOD IN; TEAHAN WJ, 1998, THESIS U WAIKATO; Turney P. D., 2002, P 40 ANN M ASS COMP; TURPIN A, 1999, 22 ACM SIGIR C RES D; WITTEN I, 1991, IEEE T INFORMATION T, V37; WITTEN I, 1999, P IEEE DAT COMPR C 1; Yang Y., 1999, INFORMATION RETRIEVA, V1, P67; ZHANG H, 2001, P 18 INT C MACH LEAR	56	54	57	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-4564			INFORM RETRIEVAL	Inf. Retr.	SEP-DEC	2004	7	3-4					317	345		10.1023/B:INRT.0000011209.19643.e2		29	Computer Science, Information Systems	Computer Science	761RP	WOS:000187927500005	
J	Todorovski, L; Dzeroski, S				Todorovski, L; Dzeroski, S			Combining classifiers with meta decision trees	MACHINE LEARNING			English	Article						ensembles of classifiers; meta-level learning; combining classifiers; stacking; decision trees		The paper introduces meta decision trees (MDTs), a novel method for combining multiple classifiers. Instead of giving a prediction, MDT leaves specify which classifier should be used to obtain a prediction. We present an algorithm for learning MDTs based on the C4.5 algorithm for learning ordinary decision trees (ODTs). An extensive experimental evaluation of the new algorithm is performed on twenty-one data sets, combining classifiers generated by five learning algorithms: two algorithms for learning decision trees, a rule learning algorithm, a nearest neighbor algorithm and a naive Bayes algorithm. In terms of performance, stacking with MDTs combines classifiers better than voting and stacking with ODTs. In addition, the MDTs are much more concise than the ODTs and are thus a step towards comprehensible combination of multiple classifiers. MDTs also perform better than several other approaches to stacking.	Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana, Slovenia	Todorovski, L (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova 39, Ljubljana, Slovenia.	Ljupco.Todorovski@ijs.si; Saso.Dzeroski@ijs.si					Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; ALI KM, 1996, AAAI 96 WORKSH INT M; Blake C. L., 1998, UCI REPOSITORY MACHI; BRAZDIL PB, 1994, MACHINE LEARNING NEU; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chan P. K., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008640732416; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Dietterich TG, 1997, AI MAG, V18, P97; Freund Y, 1996, P 13 INT C MACH LEAR; GAMA J, 2000, LINEAR BAYES CLASSIF; Gama J., 1999, P 16 INT C MACH LEAR, P134; Gama J, 2000, MACH LEARN, V41, P315, DOI 10.1023/A:1007652114878; KOPPEL M, 1996, AAAI 96 WORKSH INT M; Merz CJ, 1999, MACH LEARN, V36, P33, DOI 10.1023/A:1007559205422; ORTEGA J, 1996, AAAI 96 WORKSH INT M; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Todorovski L, 1999, LECT NOTES ARTIF INT, V1704, P98; TODOROVSKI L, 2000, P 5 INT WORKSH MULT, P221; Wettschereck D., 1994, THESIS OREGON STATE; Witten I.H., 1999, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	22	54	57	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	MAR	2003	50	3					223	249		10.1023/A:1021709817809		27	Computer Science, Artificial Intelligence	Computer Science	627QJ	WOS:000179944600002	
J	Glick, M; Klon, AE; Acklin, P; Davies, JW				Glick, M; Klon, AE; Acklin, P; Davies, JW			Enrichment of extremely noisy high-throughput screening data using a naive Bayes classifier	JOURNAL OF BIOMOLECULAR SCREENING			English	Article						high-throughput screening; compound mixtures; molecular similarity; extended-connectivity fingerprints; naive Bayes		The noise level of a high-throughput screening (HTS) experiment depends on various factors such as the quality and robustness of the assay itself and the quality of the robotic platform. Screening of compound mixtures is noisier than screening single compounds per well. A classification model based on naive Bayes (NB) may be used to enrich such data. The authors studied the ability of the NB classifier to prioritize noisy primary HTS data of compound mixtures (5 compounds/well) in 4 campaigns in which the percentage of noise presumed to be inactive compounds ranged between 81% and 91%. The top 10% of the compounds suggested by the classifier captured between 26% and 45% of the active compounds. These results are reasonable and useful, considering the poor quality of the training set and the short computing time that is needed to build and deploy the classifier.	Novartis Inst Biomed Res, Cambridge, MA 02139 USA	Glick, M (reprint author), Novartis Inst Biomed Res, 100 Technol Sq, Cambridge, MA 02139 USA.	meir.glick@pharma.novartis.com					Glick M, 2003, MOL PHYS, V101, P1325, DOI 10.1080/0026897031000099862; Hann M, 1999, J CHEM INF COMP SCI, V39, P897, DOI 10.1021/ci990423o; Hastie T. J., 2001, ELEMENTS STAT LEARNI; *INS CORP, 2001, INS MIN 2 US GUID; Labute P, 1999, Pac Symp Biocomput, P444; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; ROGERS D, UNPUB HIGH THROUGHPU; Witten I.H., 1999, DATA MINING PRACTICA; Zhang JH, 2000, J COMB CHEM, V2, P258, DOI 10.1021/cc9900706	11	53	53	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1087-0571			J BIOMOL SCREEN	J. Biomol. Screen	FEB	2004	9	1					32	36		10.1177/1087057103260590		5	Biochemical Research Methods; Biotechnology & Applied Microbiology; Chemistry, Analytical	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Chemistry	775GY	WOS:000189033400004	
J	Degroeve, S; De Baets, B; Van de Peer, Y; Rouze, P				Degroeve, S; De Baets, B; Van de Peer, Y; Rouze, P			Feature subset selection for splice site prediction	BIOINFORMATICS			English	Article; Proceedings Paper	European Conference on Computational Biology (ECCB 2002)	OCT 06-09, 2002	SAARBRUCKEN, GERMANY				GENOMIC DNA; SEQUENCES	Motivation: The large amount of available annotated Arabidopsis thaliana sequences allows the induction of splice site prediction models with supervised learning algorithms (see Haussler (1998) for a review and references). These algorithms need information sources or features from which the models can be computed. For splice site prediction, the features we consider in this study are the presence or absence of certain nucleotides in close proximity to the splice site. Since it is not known how many and which nucleotides are relevant for splice site prediction, the set of features is chosen large enough such that the probability that all relevant information sources are in the set is very high. Using only those features that are relevant for constructing a splice site prediction system might improve the system and might also provide us with useful biological knowledge. Using fewer features will of course also improve the prediction speed of the system. Results: A wrapper-based feature subset selection algorithm using a support vector machine or a naive Bayes prediction method was evaluated against the traditional method for selecting features relevant for splice site prediction. Our results show that this wrapper approach selects features that improve the performance against the use of all features and against the use of the features selected by the traditional method.	Flanders Interuniv Inst Biotechnol, Dept Plant Syst Biol, B-9000 Ghent, Belgium; State Univ Ghent, Dept Appl Math Biometr & Proc Control, B-9000 Ghent, Belgium; INRA France, Lab Associe, B-9000 Ghent, Belgium	Degroeve, S (reprint author), Flanders Interuniv Inst Biotechnol, Dept Plant Syst Biol, KL Ledeganckstr 35, B-9000 Ghent, Belgium.		Van de Peer, Yves/D-4388-2009; De Baets, Bernard/E-8877-2010	Van de Peer, Yves/0000-0003-4327-3730; De Baets, Bernard/0000-0002-3876-620X			Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; BROWNELL WE, 1999, VOLTA REV, V99, P9; Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951; CHAPELLE O, 2000, CHOOSING KERNEL PARA; Duda R., 1973, PATTERN CLASSIFICATI; Florea L, 1998, GENOME RES, V8, P967; GUYON I, 2000, MACH LEARNING; HAUSSLER D, 1998, TRENDS BIOCH SCI S, VS, P12; HOBOHM U, 1992, PROTEIN SCI, V1, P409; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Langley P., 1994, P 10 C UNC ART INT, P399; Lim LP, 2001, P NATL ACAD SCI USA, V98, P11193, DOI 10.1073/pnas.201407298; MUKHERJEE S, 2000, 182 AI; Pavy N, 1999, BIOINFORMATICS, V15, P887, DOI 10.1093/bioinformatics/15.11.887; Pertea M, 2001, NUCLEIC ACIDS RES, V29, P1185, DOI 10.1093/nar/29.5.1185; STADEN R, 1984, NUCLEIC ACIDS RES, V12, P505, DOI 10.1093/nar/12.1Part2.505; Vapnik V., 1995, NATURE STAT LEARNING; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; ZHANG MQ, 1993, COMPUT APPL BIOSCI, V9, P499	19	53	54	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	OCT	2002	18			S			S75	S83				9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	608GC	WOS:000178836800012	
J	Freitag, D				Freitag, D			Machine learning for information extraction in informal domains	MACHINE LEARNING			English	Article						information extraction; multistrategy learning	CLASSIFICATION	We consider the problem of learning to perform information extraction in domains where linguistic processing is problematic, such as Usenet posts, email, and finger plan files. In place of syntactic and semantic information, other sources of information can be used, such as term frequency, typography, formatting, and mark-up. We describe four learning approaches to this problem, each drawn from a different paradigm: a rote learner, a term-space learner based on Naive Bayes, an approach using grammatical induction, and a relational rule learner. Experiments on 14 information extraction problems defined over four diverse document collections demonstrate the effectiveness of these approaches. Finally, we describe a multistrategy approach which combines these learners and yields performance competitive with or better than the best of them. This technique is modular and flexible, and could find application in other machine learning problems.	Justsyst Pittsburgh Res Ctr, Pittsburgh, PA 15213 USA	Freitag, D (reprint author), Justsyst Pittsburgh Res Ctr, 4616 Henry St, Pittsburgh, PA 15213 USA.	dayne@justresearch.com					Aone C., 1996, Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing; Appelt D., 1993, P 13 INT JOINT C ART, P1172; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; AUGUST SE, 1992, P 4 MESS UND C MUC 4, P189, DOI 10.3115/1072064.1072094; Bikel D.M., 1997, P 5 C APPL NAT LANG, P194, DOI 10.3115/974557.974586; CALIFF ME, 1998, THESIS U TEXAS AUSTI; Cardie C, 1997, AI MAG, V18, P65; CARDIE C, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P798; CARRASCO RC, 1994, GRAMMATICAL INFERENC; CHAN PK, 1993, P 2 INT C INF KNOWL, P314; CLARK P, 1991, LECT NOTES ARTIF INT, V482, P151; Cohen W.W., 1996, P 19 ANN INT ACM SIG, P307, DOI 10.1145/243199.243278; COWIE J, 1993, P 5 MESS UND C MUC 5, P161, DOI 10.3115/1072017.1072035; CRAVEN M, 1998, P 15 NAT C ART INT A; *DEF ADV RES PROJ, 1993, P 5 MESS UND C MUC 5; *DEF ADV RES PROJ, 1995, P 6 MESS UND C MUC 6; *DEF ADV RES PROJ, 1992, P 4 MESS UND C MUC 4; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Domingos P, 1996, MACH LEARN, V24, P141; DOORENBOS R, 1997, P 1 INT C AUT AG; DUDA RO, 1973, PATTERN CLASSIFIATIO; FREITAG D, 1998, P 15 INT MACH LEARN; FREITAG D, 1999, THESIS CARNEGIE MELL; GOAN T, 1996, AAAI 96 SPRING S MAC; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; KIM JT, 1995, IEEE T KNOWL DATA EN, V7, P713; Kohavi R., 1995, P 8 EUR C MACH LEARN, P174; KUSHMERICK N, 1997, UWCSE971104; LEWIS DD, 1992, 9193 U MASS; LEWIS DD, 1997, REFERENCE LIST ACCOM; MARON ME, 1961, J ACM, V8, P404, DOI 10.1145/321075.321084; McCarthy J.F., 1995, P 14 INT JOINT C ART; Michalski R., 1994, MACHINE LEARNING MUL; Michalski R.S., 1983, MACHINE LEARNING ART, P83; Mitchell T.M., 1997, MACHINE LEARNING; MURAKI K, 1993, P 5 MESS UND C MUC 5, P147, DOI 10.3115/1072017.1072034; NOAH WW, 1993, P 5 MESS UND C MUC 5, P237, DOI 10.3115/1072017.1072040; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RABINOWICZ E, 1986, TRIBOLOGY MECHANICS, V3, P1; Riloff E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1044; RILOFF E, 1994, ACM T INFORM SYST, V12, P296, DOI 10.1145/183422.183428; RULOT H, 1988, SYNTACTIC STRUCTURAL; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; Soderland S., 1997, P 3 INT C KNOWL DISC; SODERLAND S, 1996, 96087 U MASS; Van Rijsbergen C.J., 1979, INFORMATION RETRIEVA; VIDAL E, 1994, GRAMMATICAL INFERENC, P1; WEISCHEDEL R, 1993, P 5 MESS UND C MUC 5, P93, DOI 10.3115/1072017.1072030	49	53	60	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	MAY	2000	39	2-3					169	202		10.1023/A:1007601113994		34	Computer Science, Artificial Intelligence	Computer Science	295HF	WOS:000085960100004	
J	Klon, AE; Glick, M; Davies, JW				Klon, AE; Glick, M; Davies, JW			Combination of a naive Bayes classifier with consensus scoring improves enrichment of high-throughput docking results	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							LIGAND INTERACTIONS; FLEXIBLE DOCKING; ALGORITHM	We have previously shown that a machine learning technique can improve the enrichment of high-throughput docking (HTD) results. In the previous cases studied, however, the application of a naive Bayes classifier failed to improve enrichment for instances where HTD alone was unable to generate an acceptable enrichment. We present here a protocol to rescue poor docking results a priori using a combination of rank-by-median consensus scoring and naive Bayesian categorization.	Novartis Inst Biomed Res, Cambridge, MA 02139 USA	Klon, AE (reprint author), Novartis Inst Biomed Res, 250 Massachusetts Ave, Cambridge, MA 02139 USA.	anthony.klon@pharma.novartis.com					BOHM HJ, 2002, REV COMP CH, P41; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; Clark RD, 2002, J MOL GRAPH MODEL, V20, P281, DOI 10.1016/S1093-3263(01)00125-5; Eldridge MD, 1997, J COMPUT AID MOL DES, V11, P425, DOI 10.1023/A:1007996124545; Jacobsson M, 2003, J MED CHEM, V46, P5781, DOI 10.1021/jm030896t; Jones G, 1997, J MOL BIOL, V267, P727, DOI 10.1006/jmbi.1996.0897; Klon AE, 2004, J MED CHEM, V47, P2743, DOI 10.1021/jm030363k; KUNTZ ID, 1982, J MOL BIOL, V161, P269, DOI 10.1016/0022-2836(82)90153-X; Muegge I, 1999, J MED CHEM, V42, P791, DOI 10.1021/jm980536j; Rarey M, 1996, J MOL BIOL, V261, P470, DOI 10.1006/jmbi.1996.0477; *SEIT INC, 2003, PIP PIL 3 0; Wang RX, 2001, J CHEM INF COMP SCI, V41, P1422, DOI 10.1021/ci010025x; Witten I.H., 1999, DATA MINING PRACTICA	13	52	53	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	AUG 26	2004	47	18					4356	4359		10.1021/jm049970d		4	Chemistry, Medicinal	Pharmacology & Pharmacy	847YN	WOS:000223434100003	
J	Amit, Y; Geman, D; Fan, XD				Amit, Y; Geman, D; Fan, XD			A coarse-to-fine strategy for multiclass shape detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape detection; multiple classes; statistical model; spread edges; coarse-to-fine search; online competition	COMPUTATIONAL MODEL; OBJECT RECOGNITION; FACE DETECTION; NEOCOGNITRON; SELECTION; ATTENTION; CORTEX	Multiclass shape detection, in the sense of recognizing and localizing instances from multiple shape classes, is formulated as a two-step process in which local indexing primes global interpretation. During indexing a list of instantiations ( shape identities and poses) is compiled, constrained only by no missed detections at the expense of false positives. Global information, such as expected relationships among poses, is incorporated afterward to remove ambiguities. This division is motivated by computational efficiency. In addition, indexing itself is organized as a coarse-to-fine search simultaneously in class and pose. This search can be interpreted as successive approximations to likelihood ratio tests arising from a simple ("naive Bayes") statistical model for the edge maps extracted from the original images. The key to constructing efficient "hypothesis tests" for multiple classes and poses is local ORing; in particular, spread edges provide imprecise but common and locally invariant features. Natural tradeoffs then emerge between discrimination and the pattern of spreading. These are analyzed mathematically within the model-based framework and the whole procedure is illustrated by experiments in reading license plates.	Univ Chicago, Dept Stat, Chicago, IL 60637 USA; Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA; Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA; Johns Hopkins Univ, Whitaker Biomed Engn Inst, Baltimore, MD 21218 USA; Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA	Amit, Y (reprint author), Univ Chicago, Dept Stat, Chicago, IL 60637 USA.	amit@marx.uchicago.edu; geman@jhu.edu; xdfan@cis.jhu.edu	Geman, Donald/A-3325-2010				Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; AMIT Y, 2003, VISION RES; Amit Y, 2002, 2D OBJECT DETECTION; Amit Y., 2000, NEURAL COMPUT, V12, P1059; Barrow HG, 1977, P 5 INT JOINT C ART, P659; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BLANCHARD G, 2005, IN PRESS ANN STAT; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; FUKUSHIMA K, 1991, IEEE T NEURAL NETWOR, V2, P355, DOI 10.1109/72.97912; GAVRILA DM, 2003, P IEEE INT C PATT RE; Geman S, 2002, Q APPL MATH, V60, P707; GEMAN S, 1995, COARSE TO FINE SEARC; Grimson W. E. L., 1990, OBJECT RECOGNITION C; Hubel H. David, 1988, EYE BRAIN VISION; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; KANADE T, 1998, COMPUTER VISION PATT; Lamdan Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), DOI 10.1109/CVPR.1988.196257; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773; Lowe D., 2003, DISTINCTIVE IMAGE FE; Mikolajczyk K, 2003, PROC CVPR IEEE, P257; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; NAVALPAKKAM V, 2003, P INT WORKSH ATT PER; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; ROJER AS, 1992, NEURAL NETWORKS VISI; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Rucklidge W. J., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466904; SOCOLINSKY D, 2002, FAST FACE DETECTION; Torralba A., 2003, INT J COMPUT VISION, V53, P153; ULLMAN S, 1995, CEREB CORTEX, V5, P1, DOI 10.1093/cercor/5.1.1; Viola P., 2001, P INT C COMP VIS, V2, P747, DOI 10.1109/ICCV.2001.937709; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235	37	51	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1606	1621		10.1109/TPAMI.2004.111		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	861AO	WOS:000224388700006	
J	Moler, EJ; Chow, ML; Mian, IS				Moler, EJ; Chow, ML; Mian, IS			Analysis of molecular profile data using generative and discriminative methods	PHYSIOLOGICAL GENOMICS			English	Article						microarrays; biological networks; graphical models; support vector machines; decision support systems; comparative molecular; profile data analysis	SELF-ORGANIZING MAPS; GENE-EXPRESSION DATA; CANCER CELL-LINES; SACCHAROMYCES-CEREVISIAE; PROTEIN EXPRESSION; TUMOR; PATTERNS; BIOLOGY; ADENOCARCINOMA; KNOWLEDGE	A modular framework is proposed for modeling and understanding the relationships between molecular profile data and other domain knowledge using a combination of generative (here, graphical models) and discriminative [Support Vector Machines (SVMs)] methods. As illustration, naive Bayes models, simple graphical models, and SVMs were applied to published transcription profile data for 1,988 genes in 62 colon adenocarcinoma tissue specimens labeled as tumor or nontumor. These unsupervised and supervised learning methods identified three classes or subtypes of specimens, assigned tumor or nontumor labels to new specimens and detected six potentially mislabeled specimens. The probability parameters of the three classes were utilized to develop a novel gene relevance, ranking, and selection method. SVMs trained to discriminate nontumor from tumor specimens using only the 50-200 top-ranked genes had the same or better generalization performance than the full repertoire of 1,988 genes. Approximately 90 marker genes were pinpointed for use in understanding the basic biology of colon adenocarcinoma, defining targets for therapeutic intervention and developing diagnostic tools. These potential markers highlight the importance of tissue biology in the etiology of cancer. Comparative analysis of molecular profile data is proposed as a mechanism for predicting the physiological function of genes in instances when comparative sequence analysis proves uninformative, such as with human and yeast translationally controlled tumour protein. Graphical models and SVMs hold promise as the foundations for developing decision support systems for diagnosis, prognosis, and monitoring as well as inferring biological networks.	Univ Calif Berkeley, Lawrence Berkeley Natl Lab, Dept Cell & Mol Biol, Life Sci Div,Radiat Biol & Environm Toxicol Grp, Berkeley, CA 94720 USA	Mian, IS (reprint author), Univ Calif Berkeley, Lawrence Berkeley Natl Lab, Dept Cell & Mol Biol, Life Sci Div,Radiat Biol & Environm Toxicol Grp, MS 74-197,1 Cyclotron Rd, Berkeley, CA 94720 USA.	SMian@lbl.gov					Agata Y, 1999, J BIOL CHEM, V274, P16412, DOI 10.1074/jbc.274.23.16412; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ashburner M, 2000, NAT GENET, V25, P25; Bendik I, 1998, CANCER RES, V58, P626; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Bult CJ, 2000, NUCLEIC ACIDS RES, V28, P112, DOI 10.1093/nar/28.1.112; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; CHOW ML, IN PRESS PHYSL GENOM; D'Haeseleer P, 1999, PAC S BIOC, V4, P41; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Epstein CB, 2000, CURR OPIN BIOTECH, V11, P36, DOI 10.1016/S0958-1669(99)00065-8; Franchetti P, 1999, CURR MED CHEM, V6, P599; Freije JMP, 1998, BIOCHEM SOC SYMP, P261; FRIEDMAN N, 2000, USING BAYESIAN NETWO; Fuhrman S., 1998, PAC S BIOCOMPUT, V3, P18; Gazit G, 1999, BREAST CANCER RES TR, V54, P135, DOI 10.1023/A:1006102411439; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Goss PJE, 1998, P NATL ACAD SCI USA, V95, P6750, DOI 10.1073/pnas.95.12.6750; Gygi SP, 1999, MOL CELL BIOL, V19, P1720; HASTIE T, 2000, GENE SHAVING NEW CLA; HSU PI, 1995, ANTICANCER RES, V15, P1087; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Jensen V.F., 1996, INTRO BAYESIAN NETWO; Joachims T., 1999, ADV KERNEL METHODS S; Jordan M.I., 1998, LEARNING GRAPHICAL M; Kauffman S., 1993, ORIGINS ORDER SELF O; Kim WH, 1998, BRIT J CANCER, V77, P15, DOI 10.1038/bjc.1998.3; Kitayama J, 1999, BRIT J CANCER, V80, P1927, DOI 10.1038/sj.bjc.6690622; Lee JG, 1998, AM J GASTROENTEROL, V93, P772; Matsuno H., 2000, PAC S BIOC, V5, P338; Mewes HW, 1999, NUCLEIC ACIDS RES, V27, P44, DOI 10.1093/nar/27.1.44; MIAN IS, IN PRESS J COMPUTATI; Moler EJ, 2000, PHYSIOL GENOMICS, V4, P127; Murphy K., 1999, MODELLING GENE EXPRE; Navarro E, 1999, BBA-MOL CELL RES, V1450, P254, DOI 10.1016/S0167-4889(99)00051-8; Nelson PS, 1998, CANCER RES, V58, P232; Nicchitta CV, 1998, CURR OPIN IMMUNOL, V10, P103, DOI 10.1016/S0952-7915(98)80039-3; Pearl J., 1988, PROBABILISTIC REASON; Prasad SC, 1999, ELECTROPHORESIS, V20, P1065, DOI 10.1002/(SICI)1522-2683(19990101)20:4/5<1065::AID-ELPS1065>3.3.CO;2-D; RAYCHAUDHURI R, 2000, PAC S BIOC, V5, P452; Ryu DDY, 2000, BIOTECHNOL PROGR, V16, P2, DOI 10.1021/bp088059d; Sanchez JC, 1997, ELECTROPHORESIS, V18, P150, DOI 10.1002/elps.1150180127; SOMOGYI R., 1996, COMPLEXITY, V1, P45; Sotiropoulos A, 1999, CELL, V98, P159, DOI 10.1016/S0092-8674(00)81011-9; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Streit M, 1996, Recent Results Cancer Res, V142, P19; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tavazoie S, 1999, NAT GENET, V22, P281; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4; Vapnik V., 1998, STAT LEARNING THEORY; Weaver DC, 1999, PAC S BIOCOMPUT, P112; Williams K, 1998, ELECTROPHORESIS, V19, P333, DOI 10.1002/elps.1150190231	52	51	51	AMER PHYSIOLOGICAL SOC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA	1094-8341			PHYSIOL GENOMICS	Physiol. Genomics	DEC 18	2000	4	2					109	126				18	Cell Biology; Genetics & Heredity; Physiology	Cell Biology; Genetics & Heredity; Physiology	383WR	WOS:000165908100002	
J	Davies, JW; Glick, M; Jenkins, JL				Davies, John W.; Glick, Meir; Jenkins, Jeremy L.			Streamlining lead discovery by aligning in silico and high-throughput screening	CURRENT OPINION IN CHEMICAL BIOLOGY			English	Review							NAIVE BAYES CLASSIFIER; DRUG DISCOVERY; CHEMICAL SPACE; LIBRARY DESIGN; MOLECULAR COMPLEXITY; BIOLOGICAL-ACTIVITY; KINASE INHIBITORS; FOCUSED LIBRARIES; FLEXIBLE DOCKING; GENERATION	Lead discovery in the pharmaceutical environment is largely an industrial-scale process in which it is typical to screen 1-5 million compounds in a matter of weeks using High Throughput Screening (HTS). This process is a very costly endeavor. Typically a HITS campaign of 1 million compounds will cost anywhere from $500 000 to $1 000 000. There is consequently a great deal of pressure to maximize the return on investment by finding fast and more effective ways to screen. A panacea that has emerged over the past few years to help address this issue is in silico screening. In silico screening is now incorporated in all areas of lead discovery; from target identification and library design, to hit analysis and compound profiling. However, as lead discovery has evolved over the past few years, so has the role of in silico screening.	Novartis Inst Biomed Res Inc, Lead Discovery Ctr, Cambridge, MA 02139 USA	Davies, JW (reprint author), Novartis Inst Biomed Res Inc, Lead Discovery Ctr, 250 Massachusetts Ave, Cambridge, MA 02139 USA.	john-w.davies@novartis.com					ABAGYAN R, 1994, J COMPUT CHEM, V15, P488, DOI 10.1002/jcc.540150503; Baringhaus K. H., 2004, DRUG DISCOV TODAY, V1, P197, DOI DOI 10.1016/J.DDTEC.2004.11.001; Barker EJ, 2006, J CHEM INF MODEL, V46, P503, DOI 10.1021/ci050347r; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; Bender A, 2004, J MED CHEM, V47, P6569, DOI 10.1021/jm049611i; Bleicher KH, 2003, NAT REV DRUG DISCOV, V2, P369, DOI 10.1038/nrd1086; Burke MD, 2004, ANGEW CHEM INT EDIT, V43, P46, DOI 10.1002/anie.200300626; Burke MD, 2003, SCIENCE, V302, P613, DOI 10.1126/science.1089946; Cases M, 2005, CURR TOP MED CHEM, V5, P763, DOI 10.2174/1568026054637665; Chen HM, 2006, J CHEM INF MODEL, V46, P401, DOI 10.1021/ci0503255; Chin DN, 2004, MINI-REV MED CHEM, V4, P1053; Clardy J, 2004, NATURE, V432, P829, DOI 10.1038/nature03194; Deng Z, 2006, J MED CHEM, V49, P490, DOI 10.1021/jm050381x; Deng Z, 2004, J MED CHEM, V47, P337, DOI 10.1021/jm030331x; DeSimone RW, 2004, COMB CHEM HIGH T SCR, V7, P473; Doman TN, 2002, J MED CHEM, V45, P2213, DOI 10.1021/jm010548w; Engels M F, 2001, Curr Opin Drug Discov Devel, V4, P275; Fink T, 2005, ANGEW CHEM INT EDIT, V44, P1504, DOI 10.1002/anie.200462457; Fishman MC, 2005, NATURE, V437, P491, DOI 10.1038/437491a; Fliri AF, 2005, P NATL ACAD SCI USA, V102, P261, DOI 10.1073/pnas.0407790101; Friesner RA, 2004, J MED CHEM, V47, P1739, DOI 10.1021/jm0306430; Glick M, 2006, J CHEM INF MODEL, V46, P193, DOI 10.1021/ci050374h; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Good AC, 2004, J COMPUT AID MOL DES, V18, P529, DOI 10.1007/s10822-004-4067-1; Haigh JA, 2005, J CHEM INF MODEL, V45, P673, DOI 10.1021/ci049651v; Hamon J, 2006, EUR PHARM REV, V1, P60; HANN M, 2005, METHODS PRINCIPLES M, P43; Hann MM, 2004, CURR OPIN CHEM BIOL, V8, P255, DOI 10.1016/j.cbpa.2004.04.003; Hann MM, 2001, J CHEM INF COMP SCI, V41, P856, DOI 10.1021/ci000403i; Harper G, 2004, J CHEM INF COMP SCI, V44, P2145, DOI 10.1021/ci049860f; Hert J, 2006, J CHEM INF MODEL, V46, P462, DOI 10.1021/ci050348j; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Jenkins JL, 2004, J MED CHEM, V47, P6144, DOI 10.1021/jm049654z; Jilek RJ, 2004, J CHEM INF COMP SCI, V44, P1221, DOI 10.1021/ci049961d; Jimonet P, 2004, CURR OPIN DRUG DISC, V7, P325; Jones G, 1997, J MOL BIOL, V267, P727, DOI 10.1006/jmbi.1996.0897; Karnachi PS, 2004, J BIOMOL SCREEN, V9, P678, DOI 10.1177/1087057104269570; Klon AE, 2004, J MED CHEM, V47, P4356, DOI 10.1021/jm049970d; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; Klon AE, 2004, J MED CHEM, V47, P2743, DOI 10.1021/jm030363k; Koch MA, 2005, P NATL ACAD SCI USA, V102, P17272, DOI 10.1073/pnas.0503647102; Lipinski C, 2004, NATURE, V432, P855, DOI 10.1038/nature03193; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Low CMR, 2005, J MED CHEM, V48, P6790, DOI 10.1021/jm049069y; Makino S, 1997, J COMPUT CHEM, V18, P1812, DOI 10.1002/(SICI)1096-987X(19971115)18:14<1812::AID-JCC10>3.3.CO;2-X; NIDHI N, 2006, J CHEM INF MODEL, V46, P1124; Nilakantan R, 2002, COMB CHEM HIGH T SCR, V5, P105; Nobeli I, 2005, J MOL BIOL, V347, P415, DOI 10.1016/j.jmb.2005.01.061; OPREA TI, 2003, HDB CHEMINFORMATICS, P1508, DOI 10.1002/9783527618279.ch44b; Oprea TI, 2001, J CHEM INF COMP SCI, V41, P1308, DOI 10.1021/ci010366a; Orry AJW, 2006, DRUG DISCOV TODAY, V11, P261, DOI 10.1016/S1359-6446(05)03717-7; Pearce BC, 2006, J CHEM INF MODEL, V46, P1060, DOI 10.1021/ci050504m; Rarey M, 1996, J MOL BIOL, V261, P470, DOI 10.1006/jmbi.1996.0477; Reayi A, 2005, CURR OPIN CHEM BIOL, V9, P240, DOI 10.1016/j.cbpa.2005.04.007; Renner S, 2006, CHEMMEDCHEM, V1, P181, DOI 10.1002/cmdc.200500005; Renner S, 2004, J MED CHEM, V47, P4653, DOI 10.1021/jm031139y; Rogers D, 2005, J BIOMOL SCREEN, V10, P682, DOI 10.1177/1087057105281365; Rusinko A, 1999, J CHEM INF COMP SCI, V39, P1017, DOI 10.1021/ci9903049; Schnecke V, 2006, DRUG DISCOV TODAY, V11, P43, DOI 10.1016/S1359-6446(05)03703-7; Schuffenhauer A, 2006, J CHEM INF MODEL, V46, P525, DOI 10.1021/ci0503558; Schuffenhauer A, 2005, CURR TOP MED CHEM, V5, P751, DOI 10.2174/1568026054637700; Schuffenhauer A, 2004, COMB CHEM HIGH T SCR, V7, P771, DOI 10.2174/1386207043328238; Shanmugasundaram V, 2005, J MED CHEM, V48, P240, DOI 10.1021/jm0493515; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P727, DOI 10.1021/ci034245h; Shoichet BK, 2004, NATURE, V432, P862, DOI 10.1038/nature03197; Stiefl N, 2006, J CHEM INF MODEL, V46, P208, DOI 10.1021/ci050457y; Tan DS, 2004, COMB CHEM HIGH T SCR, V7, P631; ter Haar E, 2004, MINI-REV MED CHEM, V4, P235; Vapnik V., 1998, STAT LEARNING THEORY; Vieth M, 2004, BBA-PROTEINS PROTEOM, V1697, P243, DOI 10.1016/j.bbapap.2003.11.028; Wallqvist A, 2005, MOL CANCER THER, V4, P1559, DOI 10.1158/1535-7163.MCT-05-0224; Walters WP, 2003, NAT REV DRUG DISCOV, V2, P259, DOI 10.1038/nrd1063; Wang RX, 2001, J CHEM INF COMP SCI, V41, P1422, DOI 10.1021/ci010025x; Weaver DC, 2004, CURR OPIN CHEM BIOL, V8, P264, DOI 10.1016/j.cbpa.2004.04.005; WEBER L, 2005, CURRENT STATUS VIRTU; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Young SS, 2002, CURR OPIN DRUG DI DE, V5, P422; Zhang Q, 2006, J MED CHEM, V49, P1536, DOI 10.1021/jm050468i	78	49	51	CURRENT BIOLOGY LTD	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	1367-5931			CURR OPIN CHEM BIOL	Curr. Opin. Chem. Biol.	AUG	2006	10	4					343	351		10.1016/j.cbpa.2006.06.022		9	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	077UQ	WOS:000240056600009	
J	Li, JY; Liu, HQ; Downing, JR; Yeoh, AEJ; Wong, LS				Li, JY; Liu, HQ; Downing, JR; Yeoh, AEJ; Wong, LS			Simple rules underlying gene expression profiles of more than six subtypes of acute lymphoblastic leukemia (ALL) patients	BIOINFORMATICS			English	Article							CLASSIFICATION; PREDICTION; DISCOVERY; PATTERNS	Motivations and Results: For classifying gene expression profiles or other types of medical data, simple rules are preferable to non-linear distance or kernel functions. This is because rules may help us understand more about the application in addition to performing an accurate classification. In this paper, we discover novel rules that describe the gene expression profiles of more than six subtypes of acute lymphoblastic leukemia (ALL) patients. We also introduce a new classifier, named PCL, to make effective use of the rules. PCL is accurate and can handle multiple parallel classifications. We evaluate this method by classifying 327 heterogeneous ALL samples. Our test error rate is competitive to that of support vector machines, and it is 71% better than C4.5, 50% better than Naive Bayes, and 43% better than k-nearest neighbour. Experimental results on another independent data sets are also presented to show the strength of our method.	Labs Informat Technol, Singapore 119613, Singapore; St Jude Childrens Res Hosp, Memphis, TN 38105 USA; Natl Univ Singapore, Singapore 119074, Singapore	Li, JY (reprint author), Labs Informat Technol, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@lit.a-star.edu.sg	Wong, Limsoon/E-5033-2010				Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dong G., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Langley P., 1992, P 10 NAT C ART INT, P223; Li J., 2000, P 17 INT C MACH LEAR, P551; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Setiono R., 1995, P IEEE 7 INT C TOOLS, P338; Witten H, 2000, DATA MINING PRACTICA; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	14	49	59	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JAN	2003	19	1					71	78		10.1093/bioinformatics/19.1.71		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	636PA	WOS:000180463900011	
J	Tan, CM; Wang, YF; Lee, CD				Tan, CM; Wang, YF; Lee, CD			The use of bigrams to enhance text categorization	INFORMATION PROCESSING & MANAGEMENT			English	Article						information retrieval.; text categorization; text classification; machine learning		In this paper, we present an efficient text categorization algorithm that generates bigrams selectively by looking for ones that have an especially good chance of being useful. The algorithm uses the information gain metric, combined with various frequency thresholds. The bigrams, along with unigrams, are then given as features to two different classifiers: Naive Bayes and maximum entropy. The experimental results suggest that the bigrams can substantially raise the quality of feature sets, showing increases in the break-even points and F I measures. The McNemar test shows that in most categories the increases are very significant. Upon close examination of the algorithm, we concluded that the algorithm is most successful in correctly classifying more positive documents, but may cause more negative documents to be classified incorrectly. (C) 2002 Elsevier Science Ltd. All rights reserved.	Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA; Taejon Univ, Dept Informat & Commun Engn, Taejon 300716, South Korea	Tan, CM (reprint author), Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.						APTE C, 1998, C AUT LEARN DISC PIT; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; BILLSUS D, 1997, WORKSH NOT MACH LEAR; DIETTERICH T, 1997, NEURAL COMPUT, V10, P1895; JENSEN L, 2000, KDD2000 WORKSH TEXT; Johannes Furnkranz, 1998, OEFAITR9830 AUSTR RE; LEWIS D, 1992, UMCS1991093 U MASS D; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; Lewis D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; Lewis David D., 1992, P 15 ANN INT ACM SIG, P37, DOI 10.1145/133160.133172; McCallum A. K., 1996, BOW TOOLKIT STAT LAN; Mladenic Dunja, 1998, P ERK 98 7 EL COMP S, P145; SALTON G, 1983, INTRO MODERN INFORMA; Schapire R. E., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290996; Schutze H., 1995, P 18 ANN INT ACM SIG, P229, DOI 10.1145/215206.215365; SEBASTIANI F, 1999, IEIB4311999 CONS NAZ; TAN CM, 2000, THESIS U CALIFORNIA; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y., 1997, P 14 INT C MACH LEAR, P412	19	49	53	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573			INFORM PROCESS MANAG	Inf. Process. Manage.	JUL	2002	38	4					529	546		10.1016/S0306-4573(01)00045-0		18	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	549ZX	WOS:000175479100005	
J	Aksoy, S; Koperski, K; Tusk, C; Marchisio, G; Tilton, JC				Aksoy, S; Koperski, K; Tusk, C; Marchisio, G; Tilton, JC			Learning Bayesian classifiers for scene classification with a visual grammar	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article; Proceedings Paper	IEEE Workshop on Advances in Techniques for Analysis of Remotely Sensed Data held in Honor of David A Landgrebe	OCT 27-28, 2003	Greenbelt, MD	IEEE	NASA Goddard Space Flight Visitor Ctr	data fusion; image classification; image segmentation; spatial relationships; visual grammar	RETRIEVAL; FEATURES	A challenging problem in image content extraction and classification is building a system that automatically learns high-level semantic interpretations of images. We describe a Bayesian framework for a visual grammar that aims to reduce the gap between low-level features and high-level user semantics. Our approach includes modeling image pixels using automatic fusion of their spectral, textural, and other ancillary attributes; segmentation of image regions using an iterative split-and-merge algorithm; and representing scenes by decomposing them into prototype regions and modeling the interactions between these regions in terms of their spatial relationships. Naive Bayes classifiers are used in the learning of models for region segmentation an classification using positive and negative examples for user-defined semantic land cover labels. The system also automatically learns representative region groups that can distinguish different scenes and builds visual grammar models. Experiments using Landsat scenes show that the visual grammar enables creation of high-level classes that cannot be modeled by individual pixels or regions. Furthermore, learning of the classifiers requires only a few training examples.	Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey; Insightful Corp, Seattle, WA 98109 USA; NASA Goddard Space Flight Ctr, Greenbelt, MD USA	Aksoy, S (reprint author), Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.	saksoy@cs.bilkent.edu.tr; krisk@insightful.com; ctusk@insightful.com; giovanni@insightful.com; James.C.Tilton@nasa.gov	Aksoy, Selim/C-3365-2008	Aksoy, Selim/0000-0003-4185-0565			AKSOY S, 2002, P IEEE INT GEOSC REM, V2, P1041; Aksoy S., 2003, FRONTIERS REMOTE SEN, P35, DOI 10.1142/9789812796752_0003; AKSOY S, 2003, P IEEE GRSS WORKSH A, P212; BISOP CM, 1995, NEURAL NETWORKS PATT; Chu WW, 1998, IEEE T KNOWL DATA EN, V10, P872, DOI 10.1109/69.738355; DeGroot M., 1970, OPTIMAL STAT DECISIO; Geiger D, 1997, ANN STAT, V25, P1344; Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Haralick RM, 1992, COMPUTER ROBOT VISIO; HAY SI, 2002, PHOTOGRAMM ENG REMOT, V68; Koperski K., 2002, P IGARSS TOR ON CAN, V3, P1810; Krichevskiy RE, 1998, IEEE T INFORM THEORY, V44, P296, DOI 10.1109/18.651051; MITCHELL TM, 1997, MACHINE LEARING; NEAL PJ, 1998, P AM MED INF ASS ANN; Petrakis EGM, 1997, IEEE T KNOWL DATA EN, V9, P435, DOI 10.1109/69.599932; Schroder M, 2000, IEEE T GEOSCI REMOTE, V38, P2288, DOI 10.1109/36.868886; SHAW AC, 1970, J ACM, V17, P453, DOI 10.1145/321592.321598; Smith J. R., 1996, Proceedings ACM Multimedia 96, DOI 10.1145/244130.244151; Tang LH, 1999, P SOC PHOTO-OPT INS, V3662, P360, DOI 10.1117/12.352767; TILTON JC, 2002, P IEEE INT GEOSC REM, V2, P1029	21	47	56	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	MAR	2005	43	3					581	589		10.1109/TGRS.2004.839547		9	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	899FJ	WOS:000227130000017	
J	Kolter, JZ; Maloof, MA				Kolter, J. Zico; Maloof, Marcus A.			Learning to detect and classify malicious executables in the wild	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						data mining; concept learning; computer security; invasive software	CLASSIFICATION; RECOGNITION; ALGORITHMS	We describe the use of machine learning and data mining to detect and classify malicious executables as they appear in the wild. We gathered 1; 971 benign and 1; 651 malicious executables and encoded each as a training example using n-grams of byte codes as features. Such processing resulted in more than 255 million distinct n-grams. After selecting the most relevant n-grams for prediction, we evaluated a variety of inductive methods, including naive Bayes, decision trees, support vector machines, and boosting. Ultimately, boosted decision trees outperformed other methods with an area under the ROC curve of 0.996. Results suggest that our methodology will scale to larger collections of executables. We also evaluated how well the methods classified executables based on the function of their payload, such as opening a backdoor and mass-mailing. Areas under the ROC curve for detecting payload function were in the neighborhood of 0.9, which were smaller than those for the detection task. However, we attribute this drop in performance to fewer training examples and to the challenge of obtaining properly labeled examples, rather than to a failing of the methodology or to some inherent difficulty of the classification task. Finally, we applied detectors to 291 malicious executables discovered after we gathered our original collection, and boosted decision trees achieved a true-positive rate of 0.98 for a desired false-positive rate of 0.05. This result is particularly important, for it suggests that our methodology could be used as the basis for an operational system for detecting previously undiscovered malicious executables.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA; Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA	Kolter, JZ (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	KOLTER@CS.STANFORD.EDu; MALOOF@CS.GEORGETOWN.EDU					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AIKEN A, 1994, MOSS SYSTEM DETECTIN; [Anonymous], 2003, MAXIMUM SECURITY; Baconian, 1910, BACON IS SHAKESPEARE; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Breiman L, 1998, ANN STAT, V26, P801; CHRISTODORESCU M, 2003, P 12 USENIX SEC S BE; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Fisher RA, 1936, ANN EUGENIC, V7, P179; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Gray A., 1997, P 3 BIANN C INT ASS; Hand DJ, 2001, PRINCIPLES DATA MINI; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JANKOWITZ HT, 1988, COMPUT J, V31, P1, DOI 10.1093/comjnl/31.1.1; Joachims T., 1998, P 10 EUR C MACH LEAR, P487; Kephart Jeffrey O., 1995, P IJCAI 95 MONTR AUG, P985; KJELL B, 1994, INFORM PROCESS MANAG, V30, P141, DOI 10.1016/0306-4573(94)90029-9; Kolter JZ, 2004, P 10 ACM SIGKDD INT, P470, DOI 10.1145/1014052.1014105; KRSUL I, 1994, THESIS PURDUE U W LA; KRSUL I, 1995, P 18 NAT INF SYST SE, P514; LO RW, 1995, COMPUT SECUR, V14, P541, DOI 10.1016/0167-4048(95)00012-W; MARON ME, 1960, J ACM, V7, P216, DOI 10.1145/321033.321035; MCGRAW G, 2000, IEEE SOFTWARE    SEP, P33; METZ CE, 2003, ROC SOFTWARE; MILLER P, 1999, HEXDUMP 1 4 SOFTWARE; Mitchell T.M., 1997, MACHINE LEARNING; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; Platt JC, 2000, ADV NEUR IN, P61; Platt J. C., 1998, ADV KERNEL METHODS S; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Sahami M, 1998, LEARNING TEXT CATEGO; Schultz MG, 2001, P IEEE S SECUR PRIV, P38, DOI 10.1109/SECPRI.2001.924286; SOMAN S, 2003, P 12 USENIX SEC S BE; Spafford E. H., 1993, Computers & Security, V12, DOI 10.1016/0167-4048(93)90055-A; Swets JA, 1982, EVALUATION DIAGNOSTI; Tesauro GJ, 1996, IEEE EXPERT, V11, P5, DOI 10.1109/64.511768; Witten IH, 2005, DATA MINING PRACTICA; Yang Y., 1997, P 14 INT C MACH LEAR, P412	44	46	54	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	DEC	2006	7						2721	2744				24	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152VT	WOS:000245390800009	
J	Sun, HM				Sun, Hongmao			An accurate and interpretable Bayesian classification model for prediction of hERG liability	CHEMMEDCHEM			English	Article								Drug-induced QT interval prolongation has been identified as a critical side-effect of non-cardiovascular therapeutic agents and has resulted in the withdrawal of many drugs from the market. As almost all cases of drug-induced QT prolongation can be traced to the blockade of a voltage-dependent potassium ion channel encoded by the hERG (the human ether-a-go-go-related gene), early identification of potential hERG channel blockers will decrease the risk of cardiotoxicity-induced attritions in the later and more expensive development stage. Presented herein is a naive Bayes classifier to categorize hERG blockers into active and inactive classes, by using a universal, generic molecular descriptor system. The naive Bayes classifier was built from a training set containing 1979 corporate compounds, and exhibited an ROC accuracy of 0.87. The model was validated on an external test set of 66 drugs, of which 58 were correctly classified. The cumulative probabilities reflected the confidence of prediction and were proven useful for the identification of hERG blockers. Relative performance was compared for two classifiers constructed from either on atom-type-based molecular descriptor or the long range functional class fingerprint descriptor FCFP_6. The combination of an atom-typing descriptor and the naive Bayes classification technique enables the interpretation of the resulting model, which offers extra information for the design of compounds free of undesirable hERG activity.		Sun, HM (reprint author), Hoffmann La Roche Inc, Discovery Chem, 340 Kingsland St, Nutley, NJ 07110 USA.	hongmao.sun@roche.com					Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Berger JO, 1993, STAT DECISION THEORY; Cavalli A, 2002, J MED CHEM, V45, P3844, DOI 10.1021/jm0208875; Crumb W, 1999, PHARM SCI TECHNOL TO, V2, P270, DOI 10.1016/S1461-5347(99)00172-8; De Ponti F, 2002, DRUG SAFETY, V25, P263; Domingos P, 1996, 13 INT C MACH LEARN, P105; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Ekins S, 2002, J PHARMACOL EXP THER, V301, P427, DOI 10.1124/jpet.301.2.427; Fermini B, 2003, NAT REV DRUG DISCOV, V2, P439, DOI 10.1038/nrd1108; Godden JW, 2000, J CHEM INF COMP SCI, V40, P163, DOI 10.1021/ci990316u; Gulbis JM, 2000, SCIENCE, V289, P123, DOI 10.1126/science.289.5476.123; Jiang YX, 2003, NATURE, V423, P33, DOI 10.1038/nature01580; Jiang YX, 2001, NEURON, V29, P593, DOI 10.1016/S0896-6273(01)00236-7; Keseru GM, 2003, BIOORG MED CHEM LETT, V13, P2773, DOI 10.1016/S0960-894X(03)00492-X; Klon AE, 2004, J MED CHEM, V47, P2743, DOI 10.1021/jm030363k; Kuo AL, 2003, SCIENCE, V300, P1922, DOI 10.1126/science.1085028; Mitcheson JS, 2000, P NATL ACAD SCI USA, V97, P12329, DOI 10.1073/pnas.210244497; Pearlstein R, 2003, J MED CHEM, V46, P2017, DOI 10.1021/jm0205651; Pearlstein RA, 2003, BIOORG MED CHEM LETT, V13, P1829, DOI 10.1016/S0960-894X(03)00196-3; Rajamani R, 2005, BIOORG MED CHEM LETT, V15, P1737, DOI 10.1016/j.bmcl.2005.01.008; Recanatini M, 2005, MED RES REV, V25, P133, DOI 10.1002/med.20019; Redfern WS, 2003, CARDIOVASC RES, V58, P32, DOI 10.1016/S0008-6363(02)00846-5; Rish I, 2001, EMPIRICAL STUDY NAIV; Roche O, 2002, CHEMBIOCHEM, V3, P455, DOI 10.1002/1439-7633(20020503)3:5<455::AID-CBIC455>3.0.CO;2-L; Sanchez-Chapula JA, 2003, MOL PHARMACOL, V63, P1051, DOI 10.1124/mol.63.5.1051; Scherer CR, 2002, BRIT J PHARMACOL, V137, P892, DOI 10.1038/sj.bjp.0704873; Smith PL, 1996, NATURE, V379, P833, DOI 10.1038/379833a0; Sun HM, 2005, J MED CHEM, V48, P4031, DOI 10.1021/jm050180t; Sun HM, 2004, J CHEM INF COMP SCI, V44, P748, DOI 10.1021/ci030304f; Sun HM, 2005, CURR COMPUT-AID DRUG, V1, P179, DOI 10.2174/1573409053585708; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195	31	46	47	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1860-7179			CHEMMEDCHEM	ChemMedChem	MAR	2006	1	3					315	322		10.1002/cmdc.200500047		8	Chemistry, Medicinal; Pharmacology & Pharmacy	Pharmacology & Pharmacy	V43OZ	WOS:000202945700005	
B	Friedman, N; Goldszmidt, M			AMER ASSOC ARTIFICIAL INTELLIGENCE; AMER ASSOC ARTIFICIAL INTELLIGENCE	Friedman, N; Goldszmidt, M			Building classifiers using Bayesian networks	PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2			English	Proceedings Paper	13th National Conference on Artificial Intelligence (AAAI 96) / 8th Conference on Innovative Applications of Artificial Intelligence (IAAI 96)	AUG 04-08, 1996	PORTLAND, OR	Amer Assoc Artificial Intelligence				Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state of the art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we examine and evaluate approaches for inducing classifiers from data, based on recent results in the theory of learning Bayesian networks. Bayesian networks are factored representations of probability distributions that generalize the naive Bayes classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness which are characteristic of naive Bayes. We experimentally tested these approaches using benchmark problems from the U. C. Irvine repository, and compared them against C4.5, naive Bayes, and wrapper-based feature selection methods.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Friedman, N (reprint author), Stanford Univ, Dept Comp Sci, Gates Bldg 1A, Stanford, CA 94305 USA.						CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cormen T. H., 1990, INTRO ALGORITHMS; DOUGHERTY J, 1995, ML 95; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; Fisher D., 1995, P 5 INT WORKSH ART I; FRIEDMAN N, 1996, ML 96; GEIGER D, 1992, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P92; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; HECKERMAN D, 1995, MRSTR9506 MICR RES; JOHN G, 1995, ML 94, P121; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223; Langley P., 1994, Uncertainty in Artificial Intelligence. Proceedings of the Tenth Conference (1994); Pearl J., 1988, PROBABILISTIC REASON; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SINGH M, 1995, ML 95	18	45	50	AMER ASSOC ARTIFICIAL INTELLIGENCE	MENLO PK	445 BURGESS DR, MENLO PK, CA 94025 USA			0-262-51091-X				1996							1277	1284				8	Computer Science, Artificial Intelligence	Computer Science	BN59H	WOS:000082323300189	
J	Frank, E; Trigg, L; Holmes, G; Witten, IH				Frank, E; Trigg, L; Holmes, G; Witten, IH			Naive Bayes for regression	MACHINE LEARNING			English	Article						naive Bayes; regression; model trees; linear regression; locally weighted regression	CLASSIFICATION	Despite its simplicity, the naive Bayes learning scheme performs well on most classification tasks, and is often significantly more accurate than more sophisticated methods. Although the probability estimates that it produces can be inaccurate, it often assigns maximum probability to the correct class. This suggests that its good performance might be restricted to situations where the output is categorical. It is therefore interesting to see how it performs in domains where the predicted value is numeric, because in this case, predictions are more sensitive to inaccurate probability estimates. This paper shows how to apply the naive Bayes methodology to numeric prediction (i.e., regression) tasks by modeling the probability distribution of the target value with kernel density estimators, and compares it to linear regression, locally weighted linear regression, and a method that produces "model trees"-decision trees with linear regression functions at the leaves. Although we exhibit an artificial dataset for which naive Bayes is the method of choice, on real-world datasets it is almost uniformly worse than locally weighted linear regression and model trees. The comparison with linear regression depends on the error measure: for one measure naive Bayes performs similarly, while for another it is worse. We also show that standard naive Bayes applied to regression problems by discretizing the target value performs similarly badly. We then present empirical evidence that isolates naive Bayes' independence assumption as the culprit for its poor performance in the regression setting. These results indicate that the simplistic statistical assumption that naive Bayes makes is indeed more restrictive for regression than for classification.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Frank, E (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.		Frank, Eibe/A-1434-2008; Witten, Ian/A-3366-2012	Witten, Ian/0000-0001-6428-8988			Akaike H., 1973, P 2 INT S INF THEOR, P267; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Blake C. L., 1998, UCI RESPOSITORY MACH; Cestnik B, 1990, P EUR C ART INT, P147; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; *DEP STAT, 1999, STATL; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Ghahramani Z., 1994, ADV NEURAL INFORMATI, V6, P120; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JOHN GH, 1995, P 11 C UNC ART INT, P338; Johnson PRE, 1997, BRIT J HAEMATOL, V97, P1, DOI 10.1046/j.1365-2141.1997.00984.x; KASIF S, 1998, ARTIF INTELL, V104, P297; Kilpatrick D, 1998, PROGRESS IN CONNECTIONIST-BASED INFORMATION SYSTEMS, VOLS 1 AND 2, P984; KONONENKO I, 1998, COMMUNICATION; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1993, P 1993 EUR C MACH LE, P153; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; Lehmann E. L., 1983, THEORY POINT ESTIMAT; PAZZANI M, 1996, LEARNING DATA ARTIFI, V5, P343; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Silverman B. W., 1986, DENSITY ESTIMATION S; Simonoff JS, 1996, SMOOTHING METHODS ST; SMYTH P, 1995, P 12 INT C MACH LEAR, P506; Wang Y., 1997, P 9 EUR C MACH LEARN, P128	32	44	46	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	OCT	2000	41	1					5	25		10.1023/A:1007670802811		21	Computer Science, Artificial Intelligence	Computer Science	342PL	WOS:000088654300001	
J	Smialowski, P; Martin-Galiano, AJ; Mikolajka, A; Girschick, T; Holak, TA; Frishman, D				Smialowski, Pawel; Martin-Galiano, Antonio J.; Mikolajka, Aleksandra; Girschick, Tobias; Holak, Tad A.; Frishman, Dmitrij			Protein solubility: sequence based prediction and experimental verification	BIOINFORMATICS			English	Article							AMINO-ACID-RESIDUES; ESCHERICHIA-COLI; STRUCTURAL GENOMICS; STRUCTURE DETERMINANT; LOCAL INTERACTIONS; GLOBULAR-PROTEINS; INCLUSION-BODY; SIDE-CHAINS; EXPRESSION; DATABASE	Motivation: Obtaining soluble proteins in sufficient concentrations is a recurring limiting factor in various experimental studies. Solubility is an individual trait of proteins which, under a given set of experimental conditions, is determined by their amino acid sequence. Accurate theoretical prediction of solubility from sequence is instrumental for setting priorities on targets in large-scale proteomics projects. Results: We present a machine-learning approach called PROSO to assess the chance of a protein to be soluble upon heterologous expression in Escherichia coli based on its amino acid composition. The classification algorithm is organized as a two-layered structure in which the output of primary support vector machine (SVM) classifiers serves as input for a secondary Naive Bayes classifier. Experimental progress information from the TargetDB database as well as previously published datasets were used as the source of training data. In comparison with previously published methods our classification algorithm possesses improved discriminatory capacity characterized by the Matthews Correlation Coefficient (MCC) of 0.434 between predicted and known solubility states and the overall prediction accuracy of 72% (75 and 68% for positive and negative class, respectively). We also provide experimental verification of our predictions using solubility measurements for 31 mutational variants of two different proteins.	Tech Univ Munich, Dept Genome Oriented Bioinformat, Wissenschaftszentrum, D-85350 Freising Weihenstephan, Germany; Max Planck Inst Biochem, D-82152 Martinsried, Germany	Frishman, D (reprint author), Tech Univ Munich, Dept Genome Oriented Bioinformat, Wissenschaftszentrum, D-85350 Freising Weihenstephan, Germany.						Armstrong N, 1999, PROTEIN SCI, V8, P1475; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bertone P, 2001, NUCLEIC ACIDS RES, V29, P2884, DOI 10.1093/nar/29.13.2884; BIOU V, 1988, PROTEIN ENG, V2, P185, DOI 10.1093/protein/2.3.185; CHARTON M, 1982, J THEOR BIOL, V99, P629, DOI 10.1016/0022-5193(82)90191-6; Chen L, 2004, BIOINFORMATICS, V20, P2860, DOI 10.1093/bioinformatics/bth300; Chow MKM, 2006, NUCLEIC ACIDS RES, V34, pD207, DOI 10.1093/nar/gkj080; Christendat D, 2000, NAT STRUCT BIOL, V7, P903; DALE GE, 1994, PROTEIN ENG, V7, P933, DOI 10.1093/protein/7.7.933; Davis GD, 1999, BIOTECHNOL BIOENG, V65, P382, DOI 10.1002/(SICI)1097-0290(19991120)65:4<382::AID-BIT2>3.0.CO;2-I; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Domingos P., 1996, INT C MACH LEARN, P105; Edwards AM, 2000, NAT STRUCT BIOL, V7, P970, DOI 10.1038/80751; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Frydman J, 2001, ANNU REV BIOCHEM, V70, P603, DOI 10.1146/annurev.biochem.70.1.603; Gasteiger E, 2003, NUCLEIC ACIDS RES, V31, P3784, DOI 10.1093/nar/gkg563; Gasteiger E., 2005, PROTEOMICS PROTOCOLS, P571, DOI DOI 10.1385/1592598900; Georgiou G, 1996, CURR OPIN BIOTECH, V7, P190, DOI 10.1016/S0958-1669(96)80012-7; GILL SC, 1989, ANAL BIOCHEM, V182, P319, DOI 10.1016/0003-2697(89)90602-7; Goh CS, 2004, J MOL BIOL, V336, P115, DOI 10.1016/j.jmb.2003.11.053; Golovanov AP, 2004, J AM CHEM SOC, V126, P8933, DOI 10.1021/ja049297h; GURUPRASAD K, 1990, PROTEIN ENG, V4, P155, DOI 10.1093/protein/4.2.155; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; HARRISON RG, 1999, RECOMBINANAT PROTEIN; Idicula-Thomas S, 2006, BIOINFORMATICS, V22, P278, DOI 10.1093/bioinformatics/bti810; Idicula-Thomas S, 2005, PROTEIN SCI, V14, P582, DOI 10.1110/ps.041009005; IKAI A, 1980, J BIOCHEM-TOKYO, V88, P1895; JANIN J, 1978, J MOL BIOL, V125, P357, DOI 10.1016/0022-2836(78)90408-4; Jones DT, 2005, PROTEINS, V61, P143, DOI 10.1002/prot.20731; Kapust RB, 1999, PROTEIN SCI, V8, P1668; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KRIGBAUM WR, 1979, BIOCHIM BIOPHYS ACTA, V576, P204, DOI 10.1016/0005-2795(79)90498-7; KRIGBAUM WR, 1979, BIOCHIM BIOPHYS ACTA, V576, P229, DOI 10.1016/0005-2795(79)90499-9; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; LAYNE E, 1957, METHOD ENZYMOL, V3, P447, DOI 10.1016/S0076-6879(57)03413-8; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; Liu JF, 2004, NUCLEIC ACIDS RES, V32, P3522, DOI 10.1093/nar/gkh684; Luan CH, 2004, GENOME RES, V14, P2102, DOI 10.1101/gr.2520504; Makrides SC, 1996, MICROBIOL REV, V60, P512; Meila M, 2001, MACH LEARN, V42, P9, DOI 10.1023/A:1007648401407; Motulsky H., 1995, INTUITIVE BIOSTATIST; NOZAKI Y, 1971, J BIOL CHEM, V246, P2211; Onuchic JN, 2004, CURR OPIN STRUC BIOL, V14, P70, DOI 10.1016/j.sbi.2004.01.009; PEARL F, 2005, NUCLEIC ACIDS RES, V33, P247; Pedelacq JD, 2002, NAT BIOTECHNOL, V20, P927, DOI 10.1038/nbt732; PLATT J, 1999, ADV KERNAL METHODS, P182; PONNUSWAMY PK, 1980, BIOCHIM BIOPHYS ACTA, V623, P301, DOI 10.1016/0005-2795(80)90258-5; Prilusky J, 2005, BIOINFORMATICS, V21, P3435, DOI 10.1093/bioinformatics/bti537; ROSEMAN MA, 1988, J MOL BIOL, V200, P513, DOI 10.1016/0022-2836(88)90540-2; SECKLER R, 1992, FASEB J, V6, P2545; Singh SM, 2005, J BIOSCI BIOENG, V99, P303, DOI 10.1263/jbb.99.303; Smialowski P, 2006, PROTEINS, V62, P343, DOI 10.1002/prot.20789; STOSCHECK CM, 1990, METHOD ENZYMOL, V182, P50; Tresaugues Lionel, 2004, Journal of Structural and Functional Genomics, V5, P195, DOI 10.1023/B:JSFG.0000029017.46332.e3; Tsumoto K, 2004, BIOTECHNOL PROGR, V20, P1301, DOI 10.1021/bp0498793; Waldo GS, 2003, CURR OPIN CHEM BIOL, V7, P33, DOI 10.1016/S1367-5931(02)00017-0; WILKINSON DL, 1991, BIO-TECHNOL, V9, P443, DOI 10.1038/nbt0591-443; Zhou HY, 2004, PROTEINS, V54, P315, DOI 10.1002/prot.10584	62	43	46	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	OCT 1	2007	23	19					2536	2542		10.1093/bioinformatics/btl623		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	227QV	WOS:000250673800005	
J	Muscatello, DJ; Churches, T; Kaldor, J; Zheng, W; Chiu, C; Correll, P; Jorm, L				Muscatello, DJ; Churches, T; Kaldor, J; Zheng, W; Chiu, C; Correll, P; Jorm, L			An automated, broad-based, near real-time public health surveillance system using presentations to hospital Emergency Departments in New South Wales, Australia	BMC PUBLIC HEALTH			English	Article							PREVENTION	Background: In a climate of concern over bioterrorism threats and emergent diseases, public health authorities are trialling more timely surveillance systems. The 2003 Rugby World Cup ( RWC) provided an opportunity to test the viability of a near real-time syndromic surveillance system in metropolitan Sydney, Australia. We describe the development and early results of this largely automated system that used data routinely collected in Emergency Departments ( EDs). Methods: Twelve of 49 EDs in the Sydney metropolitan area automatically transmitted surveillance data from their existing information systems to a central database in near real-time. Information captured for each ED visit included patient demographic details, presenting problem and nursing assessment entered as free-text at triage time, physician-assigned provisional diagnosis codes, and status at departure from the ED. Both diagnoses from the EDs and triage text were used to assign syndrome categories. The text information was automatically classified into one or more of 26 syndrome categories using automated "naive Bayes" text categorisation techniques. Automated processes were used to analyse both diagnosis and free text-based syndrome data and to produce web-based statistical summaries for daily review. An adjusted cumulative sum ( cusum) was used to assess the statistical significance of trends. Results: During the RWC the system did not identify any major public health threats associated with the tournament, mass gatherings or the influx of visitors. This was consistent with evidence from other sources, although two known outbreaks were already in progress before the tournament. Limited baseline in early monitoring prevented the system from automatically identifying these ongoing outbreaks. Data capture was invisible to clinical staff in EDs and did not add to their workload. Conclusion: We have demonstrated the feasibility and potential utility of syndromic surveillance using routinely collected data from ED information systems. Key features of our system are its nil impact on clinical staff, and its use of statistical methods to assign syndrome categories based on clinical free text information. The system is ongoing, and has expanded to cover 30 EDs. Results of formal evaluations of both the technical efficiency and the public health impacts of the system will be described subsequently.	New S Wales Dept Hlth, Ctr Epidemiol & Res, Sydney, NSW 2059, Australia; Australian Ctr Asthma Monitoring, Camperdown, NSW 2050, Australia	Muscatello, DJ (reprint author), New S Wales Dept Hlth, Ctr Epidemiol & Res, 73 Miller St, Sydney, NSW 2059, Australia.	dmusc@doh.health.nsw.gov.au; tchur@doh.health.nsw.gov.au; jkald@doh.health.nsw.gov.au; wzhen@doh.health.nsw.gov.au; cchiu@doh.health.nsw.gov.au; patriciac@woolcock.org.au; ljorm@doh.health.nsw.gov.au					Armitage P, 2002, STAT METHODS MED RES; *AUSTR BUR STAT, 2005, SHROT TERM VIS ARR A; *AUSTR BUR STAT, 2005, NEW S WAL FOC; Bow Andrew McCallum, BOW TOOLKIT STAT LAN; BROWNE AC, 2003, UMLS LANGUAGE VOCABU, P798; Campbell A., 2004, SARS COMMISSION INTE; Chatfield C, 2004, ANAL TIME SERIES INT; Espino Jeremy U, 2004, MMWR Morb Mortal Wkly Rep, V53 Suppl, P32; Gesteland PH, 2003, J AM MED INFORM ASSN, V10, P547, DOI 10.1197/jamia.M1352; HEFFERNAN R, 2004, EMERG INFECT DIS, V10, P258; Hutwagner L, 2005, EMERG INFECT DIS, V11, P314; Hutwagner LC, 1997, EMERG INFECT DIS, V3, P395; Jorm LR, 2003, J EPIDEMIOL COMMUN H, V57, P102, DOI 10.1136/jech.57.2.102; Kaufmann AF, 1997, EMERG INFECT DIS, V3, P83; Lewis D.D., 1998, EUR C MACH LEARN, P4; Lombardo J, 2003, J URBAN HEALTH, V80, pI32; LUCAS JM, 1985, TECHNOMETRICS, V27, P129, DOI 10.2307/1268761; *MICR CORP, 2003, MICR WIND; Mitchell T.M., 1997, MACHINE LEARNING; Olson Karen L, 2005, BMC Med Inform Decis Mak, V5, P19, DOI 10.1186/1472-6947-5-19; *US GEN ACC OFF, 2003, GAO04152; van Rossum G., PYTHON REFERENCE MAN; 2004, NSW PUBLIC HLTH B, V15, P25	23	43	43	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2458			BMC PUBLIC HEALTH	BMC Public Health	DEC 22	2005	5								141	10.1186/1471-2458-5-141		12	Public, Environmental & Occupational Health	Public, Environmental & Occupational Health	010PR	WOS:000235207100001	
J	Sutherland, JJ; Higgs, RE; Watson, I; Vieth, M				Sutherland, Jeffrey J.; Higgs, Richard E.; Watson, Ian; Vieth, Michal			Chemical fragments as foundations for understanding target space and activity prediction	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							DRUG DISCOVERY; PRIVILEGED SUBSTRUCTURES; KINASE INHIBITORS; CHEMISTRY; FINGERPRINTS; DESCRIPTORS; SIMILARITY; FRAMEWORK; KINOMICS; PROTEOME	The use of small inhibitors' fragment frequencies for understanding kinase potency and selectivity is described. By quantification of differences in the frequency of occurrence of fragments, similarities between small molecules and their targets can be determined. Naive Bayes models employing fragments provide highly interpretable and reliable means for predicting potency in individual kinases, as demonstrated in retrospective tests and prospective selections that were subsequently screened. Statistical corrections for prospective validation allowed us to accurately estimate success rates in the prospective experiment. Selectivity relationships between kinase targets are substantially explained by differences in the fragment composition of actives. By application of fragment similarities to the broader proteome, it is shown that targets related by sequence exhibit similar fragment preferences in small molecules. Of greater interest, certain targets unrelated by sequence are shown to have similar fragment preferences, even when the chemical similarity of ligands active at each target is low.	[Sutherland, Jeffrey J.] Eli Lilly & Co, Lilly Corp Ctr, Lilly Res Labs, Discovery Informat, Indianapolis, IN 46285 USA; [Higgs, Richard E.] Eli Lilly & Co, Lilly Corp Ctr, Lilly Res Labs, Discovery Stat, Indianapolis, IN 46285 USA; [Watson, Ian; Vieth, Michal] Eli Lilly & Co, Lilly Corp Ctr, Lilly Res Labs, Discovery Chem, Indianapolis, IN 46285 USA	Vieth, M (reprint author), Eli Lilly & Co, Lilly Corp Ctr, Lilly Res Labs, Discovery Chem, Indianapolis, IN 46285 USA.	m.vieth@lilly.com					Baroni M, 2007, J CHEM INF MODEL, V47, P279, DOI 10.1021/ci600253e; Bemis GW, 1999, J MED CHEM, V42, P5095, DOI 10.1021/jm9903996; Bemis GW, 1996, J MED CHEM, V39, P2887, DOI 10.1021/jm9602928; Bender A, 2006, J CHEM INF MODEL, V46, P2445, DOI 10.1021/ci600197y; Berk SC, 1999, J COMB CHEM, V1, P388, DOI 10.1021/cc990017h; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Chen JP, 2007, BIOINFORMATICS, V23, P563, DOI 10.1093/bioinformatics/btl666; Erlanson DA, 2006, CURR OPIN BIOTECH, V17, P643, DOI 10.1016/j.copbio.2006.10.007; EVANS BE, 1988, J MED CHEM, V31, P2235, DOI 10.1021/jm00120a002; Fabian MA, 2005, NAT BIOTECHNOL, V23, P329, DOI 10.1038/nbt1068; Fernandez A, 2006, J MED CHEM, V49, P3092, DOI 10.1021/jm060163j; Frye SV, 1999, CHEM BIOL, V6, pR3, DOI 10.1016/S1074-5521(99)80013-1; Givehchi A, 2006, J CHEM INF MODEL, V46, P1078, DOI 10.1021/ci0500233; Hanessian S, 2005, CURR OPIN DRUG DISC, V8, P798; Hodges PE, 2002, NUCLEIC ACIDS RES, V30, P137, DOI 10.1093/nar/30.1.137; Izrailev S, 2004, PROTEINS, V57, P711, DOI 10.1002/prot.20277; Keiser MJ, 2007, NAT BIOTECHNOL, V25, P197, DOI 10.1038/nbt1284; Lewell XQ, 1998, J CHEM INF COMP SCI, V38, P511, DOI 10.1021/ci970429i; Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1; Mason JS, 1999, J MED CHEM, V42, P3251, DOI 10.1021/jm9806998; Muller G, 2003, DRUG DISCOV TODAY, V8, P681, DOI 10.1016/S1359-6446(03)02781-8; NILAKANTAN R, 1987, J CHEM INF COMP SCI, V27, P82, DOI 10.1021/ci00054a008; Paolini GV, 2006, NAT BIOTECHNOL, V24, P805, DOI 10.1038/nbt1228; Schnur DM, 2006, J MED CHEM, V49, P2000, DOI 10.1021/jm0502900; Seel M, 1999, QUANT STRUCT-ACT REL, V18, P245, DOI 10.1002/(SICI)1521-3838(199907)18:3<245::AID-QSAR245>3.0.CO;2-O; Sheridan RP, 2002, DRUG DISCOV TODAY, V7, P903, DOI 10.1016/S1359-6446(02)02411-X; Siegel MG, 2007, DRUG DISCOV TODAY, V12, P71, DOI 10.1016/j.drudis.2006.11.011; Stouch TR, 2003, J COMPUT AID MOL DES, V17, P83, DOI 10.1023/A:1025358319677; Swindells MB, 2002, DRUG DISCOV TODAY, V7, P516, DOI 10.1016/S1359-6446(02)02250-X; Vieth M, 2004, BBA-PROTEINS PROTEOM, V1697, P243, DOI 10.1016/j.bbapap.2003.11.028; Vieth M, 2005, DRUG DISCOV TODAY, V10, P839, DOI 10.1016/S1359-6446(05)03477-X; Wermuth CG, 2006, DRUG DISCOV TODAY, V11, P160, DOI 10.1016/S1359-6446(05)03686-X; ZARTLER ER, 2005, CURR OPIN CHEM BIOL, P66370	33	42	42	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	MAY 8	2008	51	9					2689	2700		10.1021/jm701399f		12	Chemistry, Medicinal	Pharmacology & Pharmacy	295US	WOS:000255500000015	
J	Chen, B; Harrison, RF; Papadatos, G; Willett, P; Wood, DJ; Lewell, XQ; Greenidge, P; Stiefl, N				Chen, Beining; Harrison, Robert F.; Papadatos, George; Willett, Peter; Wood, David J.; Lewell, Xiao Qing; Greenidge, Paulette; Stiefl, Nikolaus			Evaluation of machine-learning methods for ligand-based virtual screening	JOURNAL OF COMPUTER-AIDED MOLECULAR DESIGN			English	Article						group fusion; kernel discrimination; ligand-based virtual screening; machine learning; naive Bayesian classifier; similarity searching; virtual screening	BIOACTIVE REFERENCE STRUCTURES; BINARY KERNEL DISCRIMINATION; STATISTICAL-HEURISTIC METHOD; FRAGMENT WEIGHTING SCHEMES; NAIVE BAYES CLASSIFIER; SUBSTRUCTURAL ANALYSIS; DRUG DISCOVERY; NONPARAMETRIC REGRESSION; MOLECULAR SIMILARITY; BIOLOGICAL-ACTIVITY	Machine-learning methods can be used for virtual screening by analysing the structural characteristics of molecules of known (in)activity, and we here discuss the use of kernel discrimination and naive Bayesian classifier (NBC) methods for this purpose. We report a kernel method that allows the processing of molecules represented by binary, integer and real-valued descriptors, and show that it is little different in screening performance from a previously described kernel that had been developed specifically for the analysis of binary fingerprint representations of molecular structure. We then evaluate the performance of an NBC when the training-set contains only a very few active molecules. In such cases, a simpler approach based on group fusion would appear to provide superior screening performance, especially when structurally heterogeneous datasets are to be processed.	Univ Sheffield, Krebs Inst Biomolec Res, Sheffield S1 4DP, S Yorkshire, England; Univ Sheffield, Dept Informat Studies, Sheffield S1 4DP, S Yorkshire, England; GlaxoSmithKline Res & Dev Ltd, Stevenage SG1 2NY, Herts, England; Novartis Pharma AG, CH-4056 Basel, Switzerland; Univ Sheffield, Krebs Inst Biomolec Res, Sheffield S10 2TN, S Yorkshire, England; Univ Sheffield, Dept Informat Studies, Sheffield S10 2TN, S Yorkshire, England; Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S1 3JD, S Yorkshire, England; Univ Sheffield, Dept Chem, Sheffield S3 7HF, S Yorkshire, England	Willett, P (reprint author), Univ Sheffield, Krebs Inst Biomolec Res, 211 Portobello St, Sheffield S1 4DP, S Yorkshire, England.	p.willett@sheffield.ac.uk	Harrison, Robert/B-9034-2008				AITCHISON J, 1976, BIOMETRIKA, V63, P413, DOI 10.1093/biomet/63.3.413; Anzali S, 2001, J MED CHEM, V44, P2432, DOI 10.1021/jm0010670; Bajorath Jürgen, 2002, Nat Rev Drug Discov, V1, P882, DOI 10.1038/nrd941; Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; Berman HM, 2002, ACTA CRYSTALLOGR D, V58, P899, DOI 10.1107/S0907444902003451; Bohm H.-J, 2000, VIRTUAL SCREENING BI; Brown RD, 1997, J CHEM INF COMP SCI, V37, P1, DOI 10.1021/ci960373c; Brown RD, 1996, J CHEM INF COMP SCI, V36, P572, DOI 10.1021/ci9501047; Capelli AM, 2006, J CHEM INF MODEL, V46, P659, DOI 10.1021/ci050353n; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Chen BN, 2006, J CHEM INF MODEL, V46, P478, DOI 10.1021/ci0505426; Christianini N., 2000, INTRO SUPPORT VECTOR; Clark DE, 2003, DRUG DISCOV TODAY, V8, P927, DOI 10.1016/S1359-6446(03)02827-7; Congreve M, 2005, DRUG DISCOV TODAY, V10, P895, DOI 10.1016/S1359-6446(05)03484-7; Constans P, 2000, J CHEM INF COMP SCI, V40, P452, DOI 10.1021/ci990082e; Cosgrove DA, 1998, J MOL GRAPH MODEL, V16, P19, DOI 10.1016/S1093-3263(98)00014-X; CRAMER RD, 1974, J MED CHEM, V17, P533, DOI 10.1021/jm00251a014; Delaney J, 2006, DRUG DISCOV TODAY, V11, P839, DOI 10.1016/j.drudis.2006.07.002; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R. O., 2000, PATTERN CLASSIFICATI; Eckert H, 2006, J MED CHEM, V49, P2284, DOI 10.1021/jm051110p; Glick M, 2006, J CHEM INF MODEL, V46, P193, DOI 10.1021/ci050374h; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Guner O. F., 2000, PHARMACOPHORE PERCEP; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hand DJ, 2001, PRINCIPLES DATA MINI; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; Hawkins DM, 1997, QUANT STRUCT-ACT REL, V16, P296, DOI 10.1002/qsar.19970160404; Hert J, 2006, J CHEM INF MODEL, V46, P462, DOI 10.1021/ci050348j; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; HODES L, 1981, J CHEM INF COMP SCI, V21, P132, DOI 10.1021/ci00031a004; HODES L, 1977, J MED CHEM, V20, P469, DOI 10.1021/jm00214a002; HODES L, 1981, J CHEM INF COMP SCI, V21, P128, DOI 10.1021/ci00031a003; Johnson MA, 1990, CONCEPTS APPL MOL SI; Kitchen DB, 2004, NAT REV DRUG DISCOV, V3, P935, DOI 10.1038/nrd1549; Klebe G, 2000, VIRTUAL SCREENING AL; Klon AE, 2004, J MED CHEM, V47, P4356, DOI 10.1021/jm049970d; Kubinyi H, 1998, PERSPECT DRUG DISCOV, V9-11, P225, DOI 10.1023/A:1027221424359; Leach AR, 2006, J MED CHEM, V49, P5851, DOI 10.1021/jm060999m; Martin Y. C., 1998, DESIGNING BIOACTIVE, P121; MARTIN YC, 1992, J MED CHEM, V35, P2145, DOI 10.1021/jm00090a001; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; McNeany TJ, 2005, J CHEM INF MODEL, V45, P768, DOI 10.1021/cit049631t; Mitchell T.M., 1997, MACHINE LEARNING; Nikolova N, 2003, QSAR COMB SCI, V22, P1006, DOI DOI 10.1002/QSAR.200330831; ORMEROD A, 1990, QUANT STRUCT-ACT REL, V9, P302, DOI 10.1002/qsar.19900090403; ORMEROD A, 1989, QUANT STRUCT-ACT REL, V8, P115, DOI 10.1002/qsar.19890080207; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; REDL G, 1974, CHEM SOC REV, V3, P273, DOI 10.1039/cs9740300273; Rogers D, 2005, J BIOMOL SCREEN, V10, P682, DOI 10.1177/1087057105281365; Saeh JC, 2005, J CHEM INF MODEL, V45, P1122, DOI 10.1021/ci049732r; Schneider G, 2005, NAT REV DRUG DISCOV, V4, P649, DOI 10.1038/nrd1799; Sheridan RP, 2002, DRUG DISCOV TODAY, V7, P903, DOI 10.1016/S1359-6446(02)02411-X; Stahura FL, 2002, DRUG DISCOV TODAY, V7, pS41, DOI 10.1016/S1359-6446(02)02271-7; Wagener M, 2000, J CHEM INF COMP SCI, V40, P280, DOI 10.1021/ci990266t; Whittle M, 2004, J CHEM INF COMP SCI, V44, P1840, DOI 10.1021/ci049867x; Willett P, 1995, J MOL RECOGNIT, V8, P290, DOI 10.1002/jmr.300080503; WILLETT P, 1986, J CHEM INF COMP SCI, V26, P36, DOI 10.1021/ci00049a008; Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211; Willett P, 1987, SIMILARITY CLUSTERIN; Willett P, 2006, QSAR COMB SCI, V25, P1143, DOI 10.1002/qsar.200610084; Williams C, 2006, MOL DIVERS, V10, P311, DOI 10.1007/s11030-006-9039-z; Wilton D, 2003, J CHEM INF COMP SCI, V43, P469, DOI 10.1021/ci025586i; Wilton DJ, 2006, J CHEM INF MODEL, V46, P471, DOI 10.1021/ci050397w; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Zhang Q, 2006, J MED CHEM, V49, P1536, DOI 10.1021/jm050468i	69	42	46	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-654X			J COMPUT AID MOL DES	J. Comput.-Aided Mol. Des.	JAN	2007	21	1-3					53	62		10.1007/s10822-006-9096-5		10	Biochemistry & Molecular Biology; Biophysics; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biophysics; Computer Science	144UN	WOS:000244821900005	
J	Viaene, S; Derrig, RA; Baesens, B; Dedene, G				Viaene, S; Derrig, RA; Baesens, B; Dedene, G			A comparison of state-of-the-art classification techniques for expert automobile insurance claim fraud detection	JOURNAL OF RISK AND INSURANCE			English	Article; Proceedings Paper	5th International Congress on Insurance	JUL 23-25, 2001	UNIVERSITY PK, PENNSYLVANIA		PENN STATE UNIV		LEARNING ALGORITHMS; ROC CURVE; CLASSIFIERS; NETWORK; MARKET; AREA	Several state-of-the-art binary classification techniques are experimentally evaluated in the context of expert automobile insurance claim fraud detection. The predictive power of logistic regression, C4.5 decision tree, k-nearest neighbor, Bayesian learning multilayer perceptron neural network, least-squares support vector machine, naive Bayes, and tree-augmented naive Bayes classification is contrasted. For most of these algorithm types, we report on several operationalizations using alternative hyperparameter or design choices. We compare these in terms of mean percentage correctly classified (PCC) and mean area under the receiver operating characteristic (AUROC) curve using a stratified, blocked, ten-fold cross-validation experiment. We also contrast algorithm type performance visually by means of the convex hull of the receiver operating characteristic (ROC) curves associated with the alternative operationalizations per algorithm type. The study is based on a data set of 1,399 personal injury protection claims from 1993 accidents collected by the Automobile Insurers Bureau of Massachusetts. To stay as close to real-life operating conditions as possible, we consider only predictors that are known relatively early in the life of a claim. Furthermore, based on the qualification of each available claim by both a verbal expert assessment of suspicion of fraud and a ten-point-scale expert suspicion score, we can compare classification for different target/class encoding schemes. Finally, we also investigate the added value of systematically collecting nonflag predictors for suspicion of fraud modeling purposes. From the observed results, we may state that: (1) independent of the target encoding scheme and the algorithm type, the inclusion of nonflag predictors allows us to significantly boost predictive performance; (2) for all the evaluated scenarios, the performance difference in terms of mean PCC and mean AUROC between many algorithm type operationalizations turns out to be rather small; visual comparison of the algorithm type ROC curve convex hulls also shows limited difference in performance over the range of operating conditions; (3) relatively simple and efficient techniques such as linear logistic regression and linear kernel least-squares support vector machine classification show excellent overall predictive capabilities, and (smoothed) naive Bayes also performs well; and (4) the C4.5 decision tree operationalization results are rather disappointing; none of the tree operationalizations are capable of attaining mean AUROC performance in line with the best. Visual inspection of the evaluated scenarios reveals that the C4.5 algorithm type ROC curve convex hull is often dominated in large part by most of the other algorithm type hulls.	Katholieke Univ Leuven, Dept Appl Econ Sci, Louvain, Belgium; Automobile Insurers Bur Massachusetts, Boston, MA USA	Viaene, S (reprint author), Katholieke Univ Leuven, Dept Appl Econ Sci, Louvain, Belgium.		Viaene, Stijn/C-2981-2009				Agresti A, 1990, CATEGORICAL DATA ANA; Artis M, 1999, INSUR MATH ECON, V24, P67, DOI 10.1016/S0167-6687(98)00038-9; ARTIS M, 2000, 4 INT C INS MATH EC; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Belhadji E., 2000, GENEVA PAP RISK INS, V25, P517, DOI 10.1111/1468-0440.00080; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brockett PL, 1998, J RISK INSUR, V65, P245, DOI 10.2307/253535; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Caron L, 1999, AUTOMOBILE INSURANCE; CLARKE M, 1986, BESTS REV, P51; CLARKE M, 1990, BRIT J CRIMINOL, V30, P1; *COM EUR ASS, 1996, EUR INS ANT FRAUD GU; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cummins J.D., 1996, J RISK UNCERTAINTY, V12, P26; CUMMINS JD, 1992, J ECON PERSPECT, V6, P95; CUSSENS J, 1993, 6 EUR C MACH LEARN V; Derrig RA, 1995, J RISK INSUR, V62, P447, DOI 10.2307/253819; DERRIG RA, 1994, J RISK INSUR, V61, P245, DOI 10.2307/253710; DERRIG RA, 1998, D9841 AIB MASS; DERRIG RA, 1999, CONTINGENCIES    SEP, P40; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DIONNE G, 1993, EC ANAL INSURANCE FR; DIONNE G, 1996, ASSURANCES, V64, P365; Doherty N. A., 2000, INTEGRATED RISK MANA; DOMINGOS P, 1999, 5 ACM SIGKDD INT C K; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O., 2001, PATTERN CLASSIFICATI; Duin RPW, 1996, PATTERN RECOGN LETT, V17, P529, DOI 10.1016/0167-8655(95)00113-1; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FRIEDMAN JH, 1995, 12 INT C MACH LEARN; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GHEZZI SG, 1983, SOC PROBL, V30, P521, DOI 10.1525/sp.1983.30.5.03a00040; Hand D., 1997, CONSTRUCTION ASSESSM; Hand D J, 1992, Stat Methods Med Res, V1, P49, DOI 10.1177/096228029200100104; HANLEY JA, 1982, RADIOLOGY, V143, P29; HANLEY JA, 1983, RADIOLOGY, V148, P839; *INS BUR CAN, 1994, INS FRAUD CAN; *INS RES COUNC, 1997, FIGHT FRAUD INS IND; *INS RES COUNC, 1996, FRAUD BUILD AUT INJ; Kass G.V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; KNOLL U, 1994, 8 EUR C MACH LEARN C; KOHAVI R, 1995, 14 INT JOINT C AI MO; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; MacKay D., 1992, THESIS CALTECH PASAD; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; MICHIE D, 1994, MAHCINE LEARNING NEU; MURPHY K, 2001, 33 S INT COMP SCI ST; Nabney I. T., 2001, NETLAB ALGORITHMS PA; Neal R., 1998, NEURAL NETWORKS MACH; OLIVER JJ, 1995, 12 INT C MACH LEARN; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; Pearl J., 1988, PROBABILISTIC REASON; Penny WD, 1999, NEURAL NETWORKS, V12, P877, DOI 10.1016/S0893-6080(99)00040-4; Picard P, 1996, J PUBLIC ECON, V63, P27, DOI 10.1016/0047-2727(95)01569-8; Platt J., 2000, ADV LARGE MARGIN CLA; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; PROVOST F, 2000, CDER WORKING PAPER; PROVOST F, 1998, 15 INT C MACH LEARN; Quinlan J.R., 1993, PROGRAMS MACHINE LEA; Sharma S., 1996, APPL MULTIVARIATE TE; Simonoff JS, 1998, INT STAT REV, V66, P137; SUYKENS JAK, 1999, EUR C CIRC THEOR DES; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; SWETS JA, 1979, INVEST RADIOL, V14, P109, DOI 10.1097/00004424-197903000-00002; Swets JA, 1982, EVALUATION DIAGNOSTI; TURNEY P, 1996, COST SENSITIVE LEARN; VANGESTEL T, 2000, 37 ESAT SISTA K U LE; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V., 1995, NATURE STAT LEARNING; VERRELST H, 1997, NEUR INF PROC SYST; Webb A. R., 1999, STAT PATTERN RECOGNI; Weisberg Herbert W., 1991, J INSURANCE REGULATI, V9, P497; WEISBERG HI, 1995, R9512 AIB COST CONT; WEISBERG HI, 1998, RISQUES, V35, P75; ZADROZNY B, 2001, 18 INT C MACH LEARN; ZADROZNY B, 2001, 7 ACM SIGKDD C KNOWL	81	42	43	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	0022-4367			J RISK INSUR	J. Risk Insur.	SEP	2002	69	3					373	421		10.1111/1539-6975.00023		49	Business, Finance; Economics	Business & Economics	608QX	WOS:000178859100006	
J	Zaffalon, M				Zaffalon, M			The naive credal classifier	JOURNAL OF STATISTICAL PLANNING AND INFERENCE			English	Article						credal sets; classification; pattern recognition; naive Bayes classifier; imprecise probabilities		Convex sets of probability distributions are also called credal sets. They generalize probability theory by relaxing the requirement that probability values be precise. Classification, i.e. assigning class labels to instances described by a set of attributes, is an important domain of application of Bayesian methods, where the naive Bayes classifier has a surprisingly good performance. This paper proposes a new method of classification which involves extending the naive Bayes classifier to credal sets, Exact and effective solution procedures for naive credal classification are derived, and the related dominance criteria are discussed. Credal classification appears as a new method, based on more realistic assumptions and in the direction of more reliable inferences. (C) 2002 Elsevier Science B.V. All rights reserved.	Ist Dalle Molle Studi Intelligenza Artif, IDSIA, CH-6928 Manno, Switzerland							Campos L., 1994, INT J UNCERTAIN FUZZ, V2, P167; Charnes A, 1962, NAVAL RES LOG QUART, V9, P181, DOI DOI 10.1002/NAV.3800090303; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GIRI NC, 1996, MULTIVARIATE STAT AN; Graham R., 1989, CONCRETE MATH FDN CO; HUBERTY C, 1994, APPL DISCRIMINANT AN; Johnson R.A., 1988, APPL MULTIVARIATE ST; KHACHIIAN LG, 1979, DOKL AKAD NAUK SSSR+, V244, P1093; Levi I., 1980, ENTERPRISE KNOWLEDGE; Luce R. D., 1957, GAMES DECISIONS; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Schaible S, 1995, HDB GLOBAL OPTIMIZAT, P495; Tessem B., 1992, International Journal of Approximate Reasoning, V7, DOI 10.1016/0888-613X(92)90006-L; WALLEY P, 1982, ANN STAT, V10, P741, DOI 10.1214/aos/1176345868; Walley P, 1996, ARTIF INTELL, V83, P1, DOI 10.1016/0004-3702(95)00009-7; Walley P, 1996, J ROY STAT SOC B MET, V58, P3; Walley P., 1991, STAT REASONING IMPRE; Walley P, 1981, COHERENT LOWER UPPER; ZAFFALON M, 1999, IDSIA1199	22	42	43	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3758			J STAT PLAN INFER	J. Stat. Plan. Infer.	JUN 15	2002	105	1					5	21		10.1016/S0378-3758(01)00201-4		17	Statistics & Probability	Mathematics	559EJ	WOS:000176012400002	
J	Hu, WM; Wu, O; Chen, ZY; Fu, ZY; Maybank, S				Hu, Weiming; Wu, Ou; Chen, Zhouyao; Fu, Zhouyu; Maybank, Steve			Recognition of pornographic web pages by classifying texts and images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						web pages; pornographic texts; pornographic images; data fusion; recognition	ENGINE	With the rapid development of the World Wide Web, people benefit more and more from the sharing of information. However, Web pages with obscene, harmful, or illegal content can be easily accessed. It is important to recognize such unsuitable, offensive, or pornographic Web pages. In this paper, a novel framework for recognizing pornographic Web pages is described. A C4.5 decision tree is used to divide Web pages, according to content representations, into continuous text pages, discrete text pages, and image pages. These three categories of Web pages are handled, respectively, by a continuous text classifier, a discrete text classifier, and an algorithm that fuses the results from the image classifier and the discrete text classifier. In the continuous text classifier, statistical and semantic features are used to recognize pornographic texts. In the discrete text classifier, the naive Bayes rule is used to calculate the probability that a discrete text is pornographic. In the image classifier, the object's contour-based features are extracted to recognize pornographic images. In the text and image fusion algorithm, the Bayes theory is used to combine the recognition results from images and texts. Experimental results demonstrate that the continuous text classifier outperforms the traditional keyword-statistics-based classifier, the contour-based image classifier outperforms the traditional skin-region-based image classifier, the results obtained by our fusion algorithm outperform those by either of the individual classifiers, and our framework can be adapted to different categories of Web pages.	Chinese Acad Sci, Inst Automat, NLPR, Beijing 100080, Peoples R China; Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HT, England	Hu, WM (reprint author), Chinese Acad Sci, Inst Automat, NLPR, POB 2728, Beijing 100080, Peoples R China.	wmhu@nlpr.ia.ac.cn; owu@nlpr.ia.ac.cn; zychen82@nlpr.ia.ac.cn; zyfu@nlpr.ia.ac.cn; sjmaybank@dcs.bbk.ac.uk					Arentz WA, 2004, COMPUT VIS IMAGE UND, V94, P295, DOI 10.1016/j.cviu.2003.10.007; BOSSON A, 2002, P INT C IM VID RETR, P50; Brin S, 1998, P 7 INT WORLD WID WE, P107; BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560; CHAN Y, 2000, P EUR SIGN PROC C, V3; Du R., 2003, P 11 IEEE INT C NETW, P325; EYSENBACH G, 2000, J MED INTERNET RES, V2; Fleck M., 1996, P EUR C COMP VIS, V2, P592; Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462; FORSYTH DA, 1998, P 32 AS C SIGN SYST, V1, P905; FORSYTH DA, 1997, P INT C IM PROC, V3, P5, DOI 10.1109/ICIP.1997.631955; Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399; McKenna SJ, 1998, PATTERN RECOGN, V31, P1883, DOI 10.1016/S0031-3203(98)00066-1; Hammami M, 2006, IEEE T KNOWL DATA EN, V18, P272, DOI 10.1109/TKDE.2006.34; Hammami M., 2003, Proceedings IEEE/WIC International Conference on Web Intelligence (WI 2003); HO WH, 2004, P IEEE INT C SYST MA, V5, P4792; HUNTER CD, 1999, THESIS U PENNSYLVANI; Ioffe S, 2001, INT J COMPUT VISION, V43, P45, DOI 10.1023/A:1011179004708; Ioffe S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790398; IOFFE S, 1999, ADV NEURAL INFORM PR; Jiao F., 2001, P IEEE INT C INF TEC, V3, P378; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Jones M. J., 1999, P IEEE C COMP VIS PA, V1, P274; Keller D., 2000, FINAL REPORT DVB REG; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; KOKAR MM, 2001, P 4 INT C INF FUS, V1; LALMAS M, P 20 ANN INT ACM SIG, P110; Lee PY, 2005, IEEE T MULTIMEDIA, V7, P1183, DOI 10.1109/TMM.2005.858414; Lee PY, 2002, IEEE INTELL SYST, V17, P48, DOI 10.1109/MIS.2002.1039832; Liang K. M., 2004, P AS C COMP VIS, P497; LUKIANIUK A, 1996, P IEEE INT WORKSH CE, P3740; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; MILANOVA MG, 2000, P 11 PORT C PATT REC, P49; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; ROTTA AL, 2001, WP223V1023 NETPROTEC; SMITH D, 1999, P IEE EUR WORKSH DIS, V99; Song R., 2004, P 13 INT C WORLD WID, P203, DOI 10.1145/988672.988700; Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), DOI 10.1109/AFGR.2000.840612; Wang JZ, 1998, COMPUT COMMUN, V21, P1355; Wang J.Z., 1997, P INT WORKSH INT DIS, P20; Yang J., 2004, P INT C PATT REC, V4, P479; Yang Y., 1997, P 14 INT C MACH LEAR, P412; ZHENG H, 2004, P IEEE INT C MULT EX, V2, P1223	43	40	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					1019	1034		10.1109/TPAMI.2007.1133		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	155TJ	WOS:000245600800008	
J	Schwacke, R; Fischer, K; Ketelsen, B; Krupinska, K; Krause, K				Schwacke, Rainer; Fischer, Karsten; Ketelsen, Bernd; Krupinska, Karin; Krause, Kirsten			Comparative survey of plastid and mitochondrial targeting properties of transcription factors in Arabidopsis and rice	MOLECULAR GENETICS AND GENOMICS			English	Article						AP2; EREBP proteins; chloroplasts; dual-targeting; mitochondria; nucleus; transcription factors	APOPTOSIS-INDUCING FACTOR; SET-DOMAIN PROTEINS; DNA-BINDING DOMAIN; NUCLEAR-LOCALIZATION SIGNALS; CHLOROPLAST TRANSIT PEPTIDES; SUBCELLULAR-LOCALIZATION; SORTING SIGNALS; GENE-EXPRESSION; CLEAVAGE SITES; PHYTOCHROME-B	A group of nuclear transcription factors, the Whirly proteins, were recently shown to be targeted also to chloroplasts and mitochondria. In order to find out whether other proteins might share this feature, an in silico-based screening of transcription factors from Arabidopsis and rice was carried out with the aim of identifying putative N-terminal chloroplast and mitochondrial targeting sequences. For this, the individual predictions of several independent programs were combined to a consensus prediction using a naive Bayes method. This consensus prediction shows a higher specificity at a given sensitivity value than each of the single programs. In both species, transcription factors from a variety of protein families that possess putative N-terminal plastid or mitochondrial target peptides as well as nuclear localization sequences, were found. A search for homologues within members of the AP2/EREBP protein family revealed that target peptide-containing proteins are conserved among monocotyledonous and dicotyledonous species. Fusion of one of these proteins to GFP revealed, indeed, a dual targeting activity of this protein. We propose that dually targeted transcription factors might be involved in the communication between the nucleus and the organelles in plant cells. We further discuss how recent results on the physical interaction between the organelles and the nucleus could have significance for the regulation of the localization of these proteins.	Univ Tromso, Inst Biol, N-9037 Tromso, Norway; Univ Cologne, Inst Bot, D-50931 Cologne, Germany	Krause, K (reprint author), Univ Tromso, Inst Biol, N-9037 Tromso, Norway.	Kirsten.Krause@ib.uit.no					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bae MS, 2003, PLANT J, V36, P652, DOI 10.1046/j.1365-313X.2003.01907.x; Bannai H, 2002, BIOINFORMATICS, V18, P298, DOI 10.1093/bioinformatics/18.2.298; Baumbusch LO, 2001, NUCLEIC ACIDS RES, V29, P4319, DOI 10.1093/nar/29.21.4319; Beck CF, 2005, PLANTA, V222, P743, DOI 10.1007/s00425-005-0021-2; Boden M, 2005, BIOINFORMATICS, V21, P2279, DOI 10.1093/bioinformatics/bti372; BOGUTA M, 1994, MOL CELL BIOL, V14, P2298; Bomsztyk K, 2004, BIOESSAYS, V26, P629, DOI 10.1002/bies.20048; Boyle B, 2001, PLANT CELL, V13, P2525, DOI 10.1105/tpc.13.11.2525; Bruce BD, 2000, TRENDS CELL BIOL, V10, P440, DOI 10.1016/S0962-8924(00)01833-X; Chen M, 2005, CURR BIOL, V15, P637, DOI 10.1016/j.cub.2005.02.028; Choi Y, 2004, P NATL ACAD SCI USA, V101, P7481, DOI 10.1073/pnas.0402328101; Claros MG, 1996, EUR J BIOCHEM, V241, P779, DOI 10.1111/j.1432-1033.1996.00779.x; Cokol M, 2000, EMBO REP, V1, P411, DOI 10.1093/embo-reports/kvd092; Cregan SP, 2002, J CELL BIOL, V158, P507, DOI 10.1083/jcb.200202130; Curaba J, 2003, PLANT J, V33, P305, DOI 10.1046/j.1365-313X.2003.01622.x; Desveaux D, 2000, PLANT CELL, V12, P1477, DOI 10.1105/tpc.12.8.1477; Desveaux D, 2004, DEV CELL, V6, P229, DOI 10.1016/S1534-5807(04)00028-0; ELLIS SR, 1989, MOL CELL BIOL, V9, P1611; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Emanuelsson O, 1999, PROTEIN SCI, V8, P978; Davuluri RV, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-25; Guda C, 2004, BIOINFORMATICS, V20, P1785, DOI 10.1093/bioinformatics/bth171; Hao DY, 2002, BIOCHEMISTRY-US, V41, P4202, DOI 10.1021/bi015979v; Harrison CJ, 2006, PLANT J, V45, P561, DOI 10.1111/j.1365-313X.2005.02611.x; Heazlewood JL, 2005, PLANT PHYSIOL, V139, P598, DOI 10.1104/pp.105.065532; Heidstra R, 2004, GENE DEV, V18, P1964, DOI 10.1101/gad.305504; Horton P, 2006, SER ADV BIOINFORM, V3, P39, DOI 10.1142/9781860947292_0007; Karniely S, 2005, EMBO REP, V6, P420, DOI 10.1038/sj.embor.7400394; Kircher S, 2002, PLANT CELL, V14, P1541, DOI 10.1105/tpc.001156; Koroleva OA, 2005, PLANT J, V41, P162, DOI 10.1111/j.1365-313X.2004.02281.x; Krause K, 2005, FEBS LETT, V579, P3707, DOI 10.1016/j.febslet.2005.05.059; KRUPINSKA K, 2005, STRUCTURE FUNCTION P, P433; Kwok EY, 2004, PLANT CELL REP, V23, P188, DOI 10.1007/s00299-004-0824-9; Liu LS, 1999, EUR J BIOCHEM, V262, P247, DOI 10.1046/j.1432-1327.1999.00349.x; Luo MZ, 1997, PLANT MOL BIOL, V33, P709, DOI 10.1023/A:1005798207693; Magnani E, 2004, PLANT CELL, V16, P2265, DOI 10.1105/tpc.104.023135; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nakano T, 2006, PLANT PHYSIOL, V140, P411, DOI 10.1104/pp.105.073783; NEGRUTIU I, 1987, PLANT MOL BIOL, V8, P363, DOI 10.1007/BF00015814; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; Nuhse TS, 2003, MOL CELL PROTEOMICS, V2, P1234, DOI 10.1074/mcp.T300006-MCP200; Petsalaki Evangelia I., 2006, Genomics Proteomics & Bioinformatics, V4, P48, DOI 10.1016/S1672-0229(06)60016-8; Raynaud C, 2006, PLANT J, V47, P395, DOI 10.1111/j.1365-313X.2006.02799.x; Richly E, 2003, EMBO REP, V4, P491, DOI 10.1038/sj.embor.embor828; Riechmann JL, 1998, BIOL CHEM, V379, P633; Ruchalski K, 2006, J BIOL CHEM, V281, P7873, DOI 10.1074/jbc.M513728200; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; Sakamoto K, 2002, PLANT CELL, V14, P1723, DOI 10.1105/tpc.003293; Sakuma Y, 2002, BIOCHEM BIOPH RES CO, V290, P998, DOI 10.1006/bbrc.2001.6299; SCHEIN AI, 2001, NUCLEIC ACIDS RES, V29, P82; Schneider M, 2005, PLANT PHYSIOL, V138, P59, DOI 10.1104/pp.104.058933; Selga T, 2005, CELL BIOL INT, V29, P1050, DOI 10.1016/j.cellbi.2005.10.004; Shigyo M, 2006, GENE, V366, P256, DOI 10.1016/j.gene.2005.08.009; Silva-Filho MC, 2003, CURR OPIN PLANT BIOL, V6, P589, DOI 10.1016/j.pbi.2003.09.008; SLUPPHAUG G, 1993, NUCLEIC ACIDS RES, V21, P2579, DOI 10.1093/nar/21.11.2579; Small I, 2004, PROTEOMICS, V4, P1581, DOI 10.1002/pmic.200300776; Small I, 1998, PLANT MOL BIOL, V38, P265, DOI 10.1023/A:1006081903354; Springer NM, 2003, PLANT PHYSIOL, V132, P907, DOI 10.1104/pp.102.013722; Strand A, 2004, CURR OPIN PLANT BIOL, V7, P621, DOI 10.1016/j.ppi.2004.09.004; Stribinskis V, 2005, MOL CELL BIOL, V25, P6546, DOI 10.1128/MCB.25.15.6546-6558.2005; Sunderland PA, 2006, PLANT J, V47, P356, DOI 10.1111/j.1365-313X.2006.02791.x; Sunderland PA, 2004, BIOCHEM SOC T, V32, P614; Susin SA, 1999, NATURE, V397, P441; Thompson JD, 1997, NUCLEIC ACIDS RES, V25, P4876, DOI 10.1093/nar/25.24.4876; Wagner R, 2006, GENE, V381, P62, DOI 10.1016/j.gene.2006.06.022; WEIGEL D, 1995, PLANT CELL, V7, P388; Wessler SR, 2005, TRENDS PLANT SCI, V10, P54, DOI 10.1016/j.tplants.2004.12.007; Wissing S, 2004, J CELL BIOL, V166, P969, DOI 10.1083/jcb.200404138; WOLFE CL, 1994, J BIOL CHEM, V269, P13361; Wolfe CL, 1996, J BIOL CHEM, V271, P4679; Xiong YQ, 2005, PLANT MOL BIOL, V59, P191, DOI 10.1007/s11103-005-6503-6	72	40	43	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1617-4615			MOL GENET GENOMICS	Mol. Genet. Genomics	JUN	2007	277	6					631	646		10.1007/s00438-007-0214-4		16	Biochemistry & Molecular Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Genetics & Heredity	169TL	WOS:000246614500003	
J	Koprinska, I; Poon, J; Clark, J; Chan, J				Koprinska, Irena; Poon, Josiah; Clark, James; Chan, Jason			Learning to classify e-mail	INFORMATION SCIENCES			English	Article						e-mail classification into folders; spam e-mail filtering; random forest; co-training; machine learning		In this paper we study supervised and semi-supervised classification of e-mails. We consider two tasks: filing e-mails into folders and spam e-mail filtering. Firstly, in a supervised learning setting, we investigate the use of random forest for automatic e-mail filing into folders and spam e-mail filtering. We show that random forest is a good choice for these tasks as it runs fast on large and high dimensional databases, is easy to tune and is highly accurate, outperforming popular algorithms such as decision trees, support vector machines and naive Bayes. We introduce a new accurate feature selector with linear time complexity. Secondly, we examine the applicability of the semi-supervised co-training paradigm for spam e-mail filtering by employing random forests, support vector machines, decision tree and naive Bayes as base classifiers. The study shows that a classifier trained on a small set of labelled examples can be successfully boosted using unlabelled examples to accuracy rate of only 5% lower than a classifier trained on all labelled examples. We investigate the performance of co-training with one natural feature split and show that in the domain of spam e-mail filtering it can be as competitive as co-training with two natural feature splits. (C) 2006 Elsevier Inc. All rights reserved.	Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia	Koprinska, I (reprint author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.	irena@it.usyd.edu.au; josiah@it.usyd.edu.au; jclark@it.usyd.edu.au; jchan3@it.usyd.edu.au					Androutsopoulos I., 2000, P WORKSH MACH LEARN, P1; Androutsopoulos I., 2000, P 23 ANN INT ACM SIG, P160, DOI 10.1145/345508.345569; Blum A, 1998, P WORKSH COMP LEARN; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P49; Carreras X., 2001, P 4 INT C REC ADV NA; Chen C, 2004, USING RANDOM FOREST; Clark J., 2003, Proceedings IEEE/WIC International Conference on Web Intelligence (WI 2003); Cohen W. W., 1996, P AAAI SPRING S MACH, P18; CRAWFORD E, 2002, P 7 AUSTR DOC COMP S; DUCHENEAUT N, 2004, HUMAN COMPUTER INTER, V20, P11; DUMAIS S, 1998, MICROSOFT RES; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; FEGER F, 2005, THESIS MIT U SYDNEY; Freund Y., 1996, P 13 INT C MACH LEAR, P146; Graham P., 2003, BETTER BAYESIAN FILT; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; JOASCHIMS T, 1998, P 10 EUR C MACH LEAR; KIRITCHENKO S, 2001, P CASCON; KOPRINSKA I, 2003, P 8 AUSTR DOC COMP S; KOTCZ A, 2002, P ACM SIGKDD 02, P307; KROGH A, 1995, ADV NEURAL INFORM PR, V2, P650; Kuncheva L.I., 2004, P 5 INT WORKSH MULT, P1; Manning C.D., 1999, FDN STAT NATURAL LAN; Mitchell T.M., 1997, MACHINE LEARNING; NIGAM K, 2000, P 9 INT C INF KNOW M; PANTEL P, 1998, P AAAI WORKSH LEARN; Platt J. C., 1998, ADV KERNEL METHODS S; PROVOST J, 1999, NAIVE BAYES RULE LEA; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; RENNE J, 2000, P KDD 2000 TEXT MIN; RIOS G, 2004, P 1 INT C EM ANT SPA; Sahami M., 1998, P AAAI WORKSH LEARN; Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SEGAL R, 1999, P 3 INT C AUT AG; TAN PN, 2005, INGRO DATA MINING; Vapnik V., 1998, STAT LEARNING THEORY; Whittaker S, 2005, HUM-COMPUT INTERACT, V20, P1, DOI 10.1207/s15327051hci2001&2_1; Yang Y, 1997, P 4 INT C MACH LEARN	41	40	41	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	MAY 15	2007	177	10					2167	2187		10.1016/j.ins.2006.12.005		21	Computer Science, Information Systems	Computer Science	158ML	WOS:000245795500010	
J	Smialowski, P; Schmidt, T; Cox, J; Kirschner, A; Frishman, D				Smialowski, P; Schmidt, T; Cox, J; Kirschner, A; Frishman, D			Will my protein crystallize? A sequence-based predictor	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						structural genomics; protein structure determination; protein crystallization; machine learning; sequence comparison	ACID INDEX DATABASE; STRUCTURAL GENOMICS; NMR-SPECTROSCOPY; IDENTIFICATION; PROTEOMICS; ALGORITHM; SELECTION; SOFTWARE; AAINDEX; SYSTEM	We propose a machine-learning approach to sequence-based prediction of protein crystallizability in which we exploit subtle differences between proteins whose structures were solved by X-ray analysis [or by both X-ray and nuclear magnetic resonance (NMR) spectroscopy] and those proteins whose structures were solved by NMR spectroscopy alone. Because the NMR technique is usually applied on relatively small proteins, sequence length distributions of the X-ray and NMR datasets were adjusted to avoid predictions biased by protein size. As feature space for classification, we used frequencies of mono-, di-, and tripeptides represented by the original 20-letter amino acid alphabet as well as by several reduced alphabets in which amino acids were grouped by their physicochemical and structural properties. The classification algorithm was constructed as a two-layered structure in which the output of primary support vector machine classifiers operating on peptide frequencies was combined by a second-level Naive Bayes classifier. Due to the application of metamethods for cost sensitivity, our method is able to handle real datasets with unbalanced class representation. An overall prediction accuracy of 67% [65% on the positive (crystallizable) and 69% on the negative (noncrystallizable) class] was achieved in a 10-fold cross-validation experiment, indicating that the proposed algorithm may be a valuable tool for more efficient target selection in structural genomics.	Tech Univ Munich, Dept Genome Oriented Bioinformat, Wissensch Zentrum Weihenstephan, D-85350 Freising Weihenstephan, Germany; Genedata GmbH, Martinsried, Germany	Frishman, D (reprint author), Tech Univ Munich, Dept Genome Oriented Bioinformat, Wissensch Zentrum Weihenstephan, D-85350 Freising Weihenstephan, Germany.	d.frishman@wzw.tum.de	Cox, Jurgen/B-9481-2008	Cox, Jurgen/0000-0001-8597-205X			Adams PD, 2004, J SYNCHROTRON RADIAT, V11, P53, DOI 10.1107/S0909049503024130; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Burley SK, 2000, NAT STRUCT BIOL, V7, P932, DOI 10.1038/80697; Canaves JM, 2004, J MOL BIOL, V344, P977, DOI 10.1016/j.jmb.2004.09.076; Chen L, 2004, BIOINFORMATICS, V20, P2860, DOI 10.1093/bioinformatics/bth300; Christendat D, 2000, NAT STRUCT BIOL, V7, P903; Cristianini N., 2000, INTRO SUPPORT VECTOR; CUNNINGHAM P, 2000, TCDCS200007 DEP COMP; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DOMINGOS P, 1999, METACOST GEN METHOD, P155; Domingos P., 1996, P 13 INT C MACH LEAR, P105; DOWNING AK, 2004, PROTEIN NMR TECHNIQU; DUBES RC, 1993, CLUSTER ANLA RELATED; Edwards AM, 2000, NAT STRUCT BIOL, V7, P970, DOI 10.1038/80751; ENGELMAN DM, 1986, ANNU REV BIOPHYS BIO, V15, P321, DOI 10.1146/annurev.bb.15.060186.001541; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Frishman D, 1995, PROTEINS, V23, P566, DOI 10.1002/prot.340230412; Gadek TR, 2003, BIOTECHNIQUES, P21; Gilis D, 2001, GENOME BIOL, V2; GILIS D, 2004, COMMUNICATION; Goh CS, 2004, J MOL BIOL, V336, P115, DOI 10.1016/j.jmb.2003.11.053; HOBOHM U, 1992, PROTEIN SCI, V1, P409; Holton T, 2000, ACTA CRYSTALLOGR D, V56, P722, DOI 10.1107/S0907444900003450; Ioerger TR, 2003, METHOD ENZYMOL, V374, P244, DOI 10.1016/S0076-6879(03)74012-9; JAIN AK, 1988, ALGORITHMS CLUSERING; JOHN GH, 1995, P 11 C UNC ART INT, P338; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kawashima S, 1999, NUCLEIC ACIDS RES, V27, P368, DOI 10.1093/nar/27.1.368; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kimber MS, 2003, PROTEINS, V51, P562, DOI 10.1002/prot.10340; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Korzhnev DM, 2004, NATURE, V430, P586, DOI 10.1038/nature02655; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; MAJUMDAR S, 2005, COMMUNCATION; McPherson A., 1999, CRYSTALLIZATION BIOL; McPhillips TM, 2002, J SYNCHROTRON RADIAT, V9, P401, DOI 10.1107/S0909049502015170; Meila M, 2001, MACH LEARN, V42, P9, DOI 10.1023/A:1007648401407; Monleon Daniel, 2002, Journal of Structural and Functional Genomics, V2, P93, DOI 10.1023/A:1020499629298; Montelione GT, 2000, NAT STRUCT BIOL, V7, P982, DOI 10.1038/80768; Nei M., 2000, MOL EVOLUTION PHYLOG; Pervushin K, 2002, J AM CHEM SOC, V124, P12898, DOI 10.1021/ja027149q; PLATT J, 1999, ADV KERNAL METHODS, P182; Riek R, 2002, J AM CHEM SOC, V124, P12144, DOI 10.1021/ja026763z; ROSE GD, 1985, SCIENCE, V229, P834, DOI 10.1126/science.4023714; RZHETSKY A, 1992, J MOL EVOL, V35, P367, DOI 10.1007/BF00161174; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; Ting KM, 2002, LECT NOTES COMPUT SC, V2534, P98; TING KM, 2002, HEURISTIC OPTIMIZATI; Valafar H, 2002, ANN NY ACAD SCI, V980, P13; Vitkup D, 2001, NAT STRUCT BIOL, V8, P559, DOI 10.1038/88640; Witten I.H., 1999, DATA MINING PRACTICA; Yee A, 2003, ACCOUNTS CHEM RES, V36, P183, DOI 10.1021/ar010126g	56	40	44	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0887-3585			PROTEINS	Proteins	FEB 1	2006	62	2					343	355		10.1002/prot.20789		13	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	000CP	WOS:000234438800006	
S	Bernado, E; Llora, X; Garrell, JM		Lanzi, P; Stolzmann, W; Wilson, SW		Bernado, E; Llora, X; Garrell, JM			XCS and GALE: A comparative study of two learning classifier systems on data mining	ADVANCES IN LEARNING CLASSIFIER SYSTEMS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Workshop on Learning Classifier Systems	JUL 07-08, 2001	SAN FRANCISCO, CALIFORNIA				ALGORITHMS	This paper compares the learning performance, in terms of prediction accuracy, of two genetic-based learning systems, XCS and GALE, with six well-known learning algorithms, coming from instance based learning, decision tree induction, rule-learning, statistical modeling and support vector machines. The experiments, performed on several datasets, show the suitability of the genetic-based learning classifier systems for classification tasks. Both XCS and GALE significantly achieved better results than IB1 and Naive Bayes. Besides, any method could not outperform XCS and GALE significantly.	Engn & Arquitectura La Salle, Barcelona 08022, Spain	Bernado, E (reprint author), Engn & Arquitectura La Salle, Psg Bonanova 8, Barcelona 08022, Spain.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Altenberg L., 1995, FDN GENETIC ALGORITH, V3, P23; Blake C. L., 1998, UCI REPOSITORY MACHI; BONELLI P, 1991, 4 INT C GEN ALG ICGA, P288; BUTZ MV, 2000, 2000017 ILLIGAL U IL; CANTUPAZ E, 2000, GENETIC EVOLUTIONARY, P1053; Conover WJ., 1971, PRACTICAL NONPARAMET, P206; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DIEFERSON LA, 2000, WORKSH DAT MIN EV CO, P89; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; FLOCKHART IW, 1995, 10 EPCC AIKMS GA MIN; Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Goldberg D., 1989, GENETIC ALGORITHMS S; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Han J., 2001, DATA MINING CONCEPTS; HARTLEY A, 1999, P GEN EV COMP C 1999, P266; Holland J. H., 1986, MACHINE LEARNING ART, V2, P593; Holland J. H., 1978, PATTERN DIRECTED INF, P313; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOLMES JH, 1997, P 7 INT C GEN ALG IC, P426; HOLMES JH, 2000, 3 INT WORKSH LEARN C; Janikow C. Z., 1993, MACH LEARN, V13, P198; John G. H., 1995, 11 C UNC ART INT, P338; Kovacs T., 1999, P GEN EV COMP C GECC, P329; Kovacs T., 1997, SOFT COMPUTING ENG D, P59; Koza J., 1992, GENETIC PROGRAMMING; LANZI PL, 1999, P GEN EV COMP C GECC, P353; Lanzi P-L., 2000, LEARNING CLASSIFIER, P223; LLORA X, 2000, P GEN EV COMP C GECC, P868; LLORA X, 2001, IN PRESS P 18 INT C; LLORA X, 2001, IN PRESS P GEN EV CO; LLORA X, 2000, P LEARN 00 WORKSH; Marti J, 1998, P SOC PHOTO-OPT INS, V3338, P1215, DOI 10.1117/12.310849; MARTIN JK, 1996, 9621 U CAL DEP INF C; MARTINEZ E, 1996, 8 MED EL C IND APPL, P1067; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; Platt J. C., 1998, ADV KERNEL METHODS S; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Smith S. F., 1983, P 8 INT JOINT C ART, P422; WILSON SW, 1999, FESTSCHRIFT HONOR JH; WILSON SW, 1999, 9911 PRED DYN; WILSON SW, 1998, GEN PROGR P 3 ANN C; WILSON SW, 2000, 3 INT WORKSH LEARN C; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; Witten I.H., 2000, DATA MINING PRACTICA	49	40	40	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-43793-2	LECT NOTES ARTIF INT			2002	2321						115	132				18	Computer Science, Artificial Intelligence	Computer Science	BW13N	WOS:000180978300008	
J	Aphinyanaphongs, Y; Tsamardinos, I; Statnikov, A; Hardin, D; Aliferis, CF				Aphinyanaphongs, Y; Tsamardinos, I; Statnikov, A; Hardin, D; Aliferis, CF			Text categorization models for high-quality article retrieval in internal medicine	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							SUPPORT VECTOR MACHINES; SEARCH STRATEGY; MEDLINE; TRIALS; CURVES	Objective: Finding the best scientific evidence that applies to a patient problem is becoming exceedingly difficult due to the exponential growth of medical publications. The objective of this study was to apply machine learning techniques to automatically identify high-quality, content-specific articles for one time period in internal medicine and compare their performance with previous Boolean-based PubMed clinical query filters of Haynes et al. Design: The selection criteria of the ACP journal Club for articles in internal medicine were the basis for identifying high-quality articles in the areas of etiology, prognosis, diagnosis, and treatment. Naive Bayes, a specialized AdaBoost algorithm, and linear and polynomial support vector machines were applied to identify these articles. Measurements: The machine learning models were compared in each category with each other and with the clinical query filters using area under the receiver operating characteristic curves, 11-point average recall precision, and a sensitivity/specificity match method. Results: In most categories, the data-induced models have better or comparable sensitivity, specificity, and precision than the clinical query filters. The polynomial support vector machine models perform the best among all learning methods in ranking the articles as evaluated by area under the receiver operating curve and 11-point average recall precision. Conclusion: This research shows that, using machine learning methods, it is possible to automatically build models for retrieving high-quality, content-specific articles using inclusion or citation by the ACP journal Club as a gold standard in a given time period in internal medicine that perform better than the 1994 PubMed clinical query filters.	Vanderbilt Univ, Dept Biomed Informat, Eskind Biomed Lib, Nashville, TN 37232 USA; Vanderbilt Univ, Dept Math, Nashville, TN 37232 USA	Aphinyanaphongs, Y (reprint author), Vanderbilt Univ, Dept Biomed Informat, Eskind Biomed Lib, 4th Floor,2209 Garland Ave, Nashville, TN 37232 USA.	ping.pong@vanderbilt.edu	Hardin, Douglas/C-3386-2013	Hardin, Douglas/0000-0003-0867-2146			Aliferis C.F., 2003, P 2003 AM MED INF AS, P21; Aphinyanaphongs Y, 2004, ST HEAL T, V107, P263; APHINYANAPHONGS Y, ON LINE SUPPL TEXT C; APHINYANAPHONGS Y, 2003, P AMIA S, P31; Bachmann LM, 2002, J AM MED INFORM ASSN, V9, P653, DOI 10.1197/jamia.M1124; Bigby M, 1998, ARCH DERMATOL, V134, P1609, DOI 10.1001/archderm.134.12.1609; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CENTOR RM, 1991, MED DECIS MAKING, V11, P102, DOI 10.1177/0272989X9101100205; Cooper H., 1994, HDB RES SYNTHESIS; Cristianini N., 2000, INTRO SUPPORT VECTOR; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; HAYNES B, 1999, ACP J CLUB, V131, pA15; HAYNES RB, 1994, J AM MED INFORM ASSN, V1, P447; Joachims T., 1997, 14 INT C MACH LEARN, P143; Joachims T., 1999, ADV KERNEL METHODS; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Mitchell T.M., 1997, MACHINE LEARNING; Nwosu CR, 1998, OBSTET GYNECOL, V91, P618, DOI 10.1016/S0029-7844(97)00703-5; Pagano M, 2000, PRINCIPLES BIOSTATIS; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Robinson KA, 2002, INT J EPIDEMIOL, V31, P150, DOI 10.1093/ije/31.1.150; Sackett DL, 1998, EVIDENCE BASED MED P; SCHAPIRE RE, 1999, 10 INT C ALG LEARN T, P13; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Shojania K G, 2001, Eff Clin Pract, V4, P157; Vapnik V., 1998, STAT LEARNING THEORY; Wilczynski NL, 2003, P AMIA ANN S, P719; WONG SSL, 2003, P AMIA ANN S, P728	28	39	41	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1067-5027			J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAR-APR	2005	12	2					207	216		10.1197/jamia.M1641		10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	909EC	WOS:000227842000011	
J	Cheng, BYM; Carbonell, JG; Klein-Seetharaman, J				Cheng, BYM; Carbonell, JG; Klein-Seetharaman, J			Protein classification based on text document classification techniques	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						Naive Bayes; Decision Tree; chi-square; n-grams; feature selection	MULTIPLE SEQUENCE ALIGNMENT; HIDDEN MARKOV-MODELS; COUPLED RECEPTORS; FAMILY CLASSIFICATION; SIMILARITY SEARCHES; NEURAL NETWORKS; DATABASE; IDENTIFICATION; ANNOTATION; DOMAIN	The need for accurate, automated protein classification methods continues to increase as advances in biotechnology uncover new proteins. G-protein coupled receptors (GPCRs) are a particularly difficult superfamily of proteins to classify due to extreme diversity among its members. Previous comparisons of BILAST, k-nearest neighbor (k-NN), hidden markov model (HMM) and support vector machine (SVM) using alignment-based features have suggested that classifiers at the complexity of SVM are needed to attain high accuracy. Here, analogous to document classification, we applied Decision Tree and Naive Bayes classifiers with chi-square feature selection on counts of n-grams (i.e. short peptide sequences of length n) to this classification task. Using the GPCR dataset and evaluation protocol from the previous study, the Naive Bayes classifier attained an accuracy of 93.0 and 92.4% in level I and level II subfamily classification respectively, while SVM has a reported accuracy of 88.4 and 86.3%. This is a 39.7 and 44.5% reduction in residual error for level I and level II subfamily classification, respectively. The Decision Tree, while inferior to SVM, outperforms HMM in both level I and level II subfamily classification. For those GPCR families whose profiles are stored in the Protein FAMilies database of alignments and HMMs (PFAM), our method performs comparably to a search against those profiles. Finally, our method can be generalized to other protein families by applying it to the superfamily of nuclear receptors with 94.5, 97.8 and 93.6% accuracy in family, level I and level II subfamily classification respectively. (C) 2005 Wiley-Liss, Inc.	Univ Pittsburgh, Dept Pharmacol, Sch Med, Pittsburgh, PA 15261 USA; Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA	Klein-Seetharaman, J (reprint author), Univ Pittsburgh, Dept Pharmacol, Sch Med, Biomed Sci Tower E1058, Pittsburgh, PA 15261 USA.	judithks@cs.cmu.edu					Altschul S. F., 1990, J MOL BIOL, V215, P403; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P33; Attwood TK, 2002, NUCLEIC ACIDS RES, V30, P239, DOI 10.1093/nar/30.1.239; Baldi P., 2001, BIOINFORMATICS MACHI; BARTON GJ, 1987, J MOL BIOL, V198, P327, DOI 10.1016/0022-2836(87)90316-0; Bateman A, 2004, NUCLEIC ACIDS RES, V32, pD138, DOI 10.1093/nar/gkh121; Birney E, 2004, GENOME RES, V14, P988, DOI 10.1101/gr.1865504; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Bucher P, 1996, COMPUT CHEM, V20, P3, DOI 10.1016/S0097-8485(96)80003-9; Corpet F, 2000, NUCLEIC ACIDS RES, V28, P267, DOI 10.1093/nar/28.1.267; DESHPANDE M, 2002, 6 PAC AS C KNOWL DIS, P417; Eskin E, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P134; Eskin E, 2003, J COMPUT BIOL, V10, P187, DOI 10.1089/106652703321825964; Falquet L, 2002, NUCLEIC ACIDS RES, V30, P235, DOI 10.1093/nar/30.1.235; FERRAN EA, 1992, COMPUT APPL BIOSCI, V8, P39; Gether U, 2000, ENDOCR REV, V21, P90, DOI 10.1210/er.21.1.90; Gough J, 2001, J MOL BIOL, V313, P903, DOI 10.1006/jmbi.2001.5080; Grundy WN, 1997, COMPUT APPL BIOSCI, V13, P397; Henikoff JG, 2000, NUCLEIC ACIDS RES, V28, P228, DOI 10.1093/nar/28.1.228; Henikoff S, 1995, GENE, V163, P17; Henikoff S, 1999, BIOINFORMATICS, V15, P471, DOI 10.1093/bioinformatics/15.6.471; Horn F, 1998, NUCLEIC ACIDS RES, V26, P275, DOI 10.1093/nar/26.1.275; Horn F, 2001, NUCLEIC ACIDS RES, V29, P346, DOI 10.1093/nar/29.1.346; Huang JY, 2001, NUCLEIC ACIDS RES, V29, P202, DOI 10.1093/nar/29.1.202; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Kim J, 2000, BIOINFORMATICS, V16, P767, DOI 10.1093/bioinformatics/16.9.767; KOLAKOWSKI LF, 1994, RECEPTOR CHANNEL, V2, P1; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Lapinsh M, 2002, PROTEIN SCI, V11, P795, DOI 10.1110/ps.2500102; Leslie Christina, 2002, Pac Symp Biocomput, P564; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Letunic I, 2002, NUCLEIC ACIDS RES, V30, P242, DOI 10.1093/nar/30.1.242; LEVCHENKO ME, 2001, GENOME INFORMATICS, P352; Liu AH, 2001, IBM SYST J, V40, P379; Lynch M, 2002, P NATL ACAD SCI USA, V99, P6118, DOI 10.1073/pnas.092595699; MCCALLUM A, 2002, AII 98 WORKSH LEARN; Mitchell T. M., 1997, MACH LEARN; MITSUKE H, 2002, GENOME INFORMATICS, V13, P418; Morgenstern B, 1998, BIOINFORMATICS, V14, P290, DOI 10.1093/bioinformatics/14.3.290; Morgenstern B, 1999, BIOINFORMATICS, V15, P211, DOI 10.1093/bioinformatics/15.3.211; MORIYAMA EN, 2003, DATA MINING GENOMES; Muller G, 2000, CURR MED CHEM, V7, P861; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; NEUWALD AF, 1994, J MOL BIOL, V239, P698, DOI 10.1006/jmbi.1994.1407; Neuwald AF, 1997, NUCLEIC ACIDS RES, V25, P1665, DOI 10.1093/nar/25.9.1665; Notredame C, 2000, J MOL BIOL, V302, P205, DOI 10.1006/jmbi.2000.4042; Notredame C, 1996, NUCLEIC ACIDS RES, V24, P1515, DOI 10.1093/nar/24.8.1515; PARDO L, 1992, P NATL ACAD SCI USA, V89, P4009, DOI 10.1073/pnas.89.9.4009; Park J, 1997, J MOL BIOL, V273, P349, DOI 10.1006/jmbi.1997.1288; Pearson WR, 1998, J MOL BIOL, V276, P71, DOI 10.1006/jmbi.1997.1525; Pearson W R, 2000, Methods Mol Biol, V132, P185; Pearson WR, 1996, METHOD ENZYMOL, V266, P227; Ponting CP, 1999, NUCLEIC ACIDS RES, V27, P229, DOI 10.1093/nar/27.1.229; Qu K, 1998, Proc Int Conf Intell Syst Mol Biol, V6, P131; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SCHULER GD, 1991, PROTEINS, V9, P180, DOI 10.1002/prot.340090304; Sebastiani F., 1999, P ASAI 99 1 ARG S AR, P7; Servant Florence, 2002, Brief Bioinform, V3, P246, DOI 10.1093/bib/3.3.246; Sigrist Christian J A, 2002, Brief Bioinform, V3, P265, DOI 10.1093/bib/3.3.265; SMITH HO, 1990, P NATL ACAD SCI USA, V87, P826, DOI 10.1073/pnas.87.2.826; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; TAYLOR WR, 1988, J MOL EVOL, V28, P161, DOI 10.1007/BF02143508; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; VANSCHOENWINKEL B, 2002, KNOWLEDGE DISCOVERY; Vinga S, 2003, BIOINFORMATICS, V19, P513, DOI 10.1093/bioinformatics/btg005; Wang J. T. L., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347157; WU C, 1995, MACH LEARN, V21, P177, DOI 10.1007/BF00993384; Wu CH, 2003, COMPUT BIOL CHEM, V27, P37, DOI 10.1016/S1476-9271(02)00098-1; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Yona G, 1999, PROTEINS, V37, P360, DOI 10.1002/(SICI)1097-0134(19991115)37:3<360::AID-PROT5>3.0.CO;2-Z; YUAN X, 2003, COMP STUDY DECISION; Zhang YX, 2002, NATURE, V415, P644, DOI 10.1038/415644a; Zhang Z, 1998, NUCLEIC ACIDS RES, V26, P3986, DOI 10.1093/nar/26.17.3986	76	39	39	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585			PROTEINS	Proteins	MAR 1	2005	58	4					955	970		10.1002/prot.20373		16	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	898WE	WOS:000227106100019	
J	KING, RD; FENG, C; SUTHERLAND, A				KING, RD; FENG, C; SUTHERLAND, A			STATLOG - COMPARISON OF CLASSIFICATION ALGORITHMS ON LARGE REAL-WORLD PROBLEMS	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							LEARNING ALGORITHMS	This paper describes work in the StatLog project comparing classification algorithms on large real-world problems. The algorithms compared were from symbolic learning (CART, C4.5, NewlD, AC(2), ITrule, Cal5, CN2), statistics (Naive Bayes, k-nearest neighbor, kernel density, linear discriminant, quadratic discriminant, logistic regression, projection pursuit, Bayesian networks), and neural networks (backpropagation, radial basis functions). Twelve datasets were used:five from image analysis, three from medicine, and two each from engineering and finance. We found that which algorithm performed best depended critically on the data set investigated. We therefore developed a set of data set descriptors to help decide which algorithms are suited to particular data sets. For example, data sets with extreme distributions (skew > 1 and kurtosis > 7) and with many binary/categorical attributes (> 38%) tend to favor symbolic learning algorithms. We suggest how classification algorithms can be extended in a number of directions.	UNIV STRATHCLYDE,DEPT STAT,GLASGOW G1 1XW,LANARK,SCOTLAND; TURING INST LTD,GLASGOW,LANARK,SCOTLAND							AHA DW, 1992, 9 INT C MACH LEARN A, P1; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ATLAS L, 1991, SYSTEMS MAN CYBERNET, P915; BONELLI P, 1991, ICGA 91 GENETIC ALGO, P288; Breiman L., 1984, CLASSIFICATION REGRE; BUNTINE W, 1989, 6TH P INT WORKSH MAC, P94; CASID S, 1991, 1991 ESPR C; CHERKAOUI O, 1991, 1991 P INT C SAN MAT; Clark P., 1991, EWSL 91, P151; CLARK P, 1988, MACH LEARN, V3, P261; COX DR, 1966, RES PAPERS STATISTIC, V45; DAY NE, 1967, BIOMETRICS, V23, P313, DOI 10.2307/2528164; ERSOY OK, 1991, INTELLIGENT MOTION C; FAHLMAN S, 1989, CONCEPTS CHARACTERIS, P23; FAHLMAN S, 1991, MONKS PROBLEMS PERFO, P107; FENG C, 1993, P INT C ARTIFICIAL I; FISHER D, 1989, 6TH P WORKSH MACH LE, P169; FISHER DH, 1989, IJCAI 89, V7, P788; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; GOODMAN RM, 1989, 6TH P INT WORKSH MAC, P129; GORDON L, 1978, ANN STAT, V6, P515, DOI 10.1214/aos/1176344197; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; Hand D.J., 1981, DISCRIMINATION CLASS; HERMANS J, 1974, B INT STATISTICS I, V45, P523; HUANG HH, 1991, P ARTIFICIAL NEURAL; Huang W. Y., 1987, IEEE First International Conference on Neural Networks; KENDALL MG, 1983, ADV THEORY STATISTIC, V3; KING R, 1994, MACHINE INTELLIGENCE, V13; KIRKWOOD CA, 1989, J BIOMED ENG, V11, P511, DOI 10.1016/0141-5425(89)90046-0; KRESSEL U, 1991, P INT C ARTIFICIAL N; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; McClelland J., 1986, PARALLEL DISTRIBUTED, V2; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; MCCLELLAND JL, 1986, PARALLEL DISTRIBUTED, V3; MEYERBROETZ G, 1970, METHODEN AUTOMATISCH; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Michie D., 1994, MACHINE LEARNING NEU; Mooney R., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence; Pearl J., 1988, PROBABILISTIC REASON; POGGIO T, 1991, P IEEE, V78, P1481; Preparata F. P., 1985, COMPUTATIONAL GEOMET; QUINLAN J, 1986, 2ND P AUSTR C APPL E, P183; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, 10TH P INT JOINT C A, P304; READ TRC, 1988, GOODNESS FIT STATIST; REMME J, 1980, J STAT COMPUT SIM, V11, P87, DOI 10.1080/00949658008810396; RENALS S, 1989, P INT JOINT C NEURAL, V1, P461; RIPLEY BD, 1992, SEMSAT SANDBJERG DEN; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; RUMELHART DE, 1986, NEUROCOMPUTING F RES, P696; SAMMUT C, 1988, 5TH P INT C MACH LEA, P437; SEGRE AM, 1989, 6TH P INT MACH LEARN; SETHI JK, 1990, IJCNN 90, P63; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1007/BF00114160; SIEBERT JP, 1987, TIRM87018 TUR I REP; SMITH JW, 1991, P S COMPUTER APPLICA, P261; SPIEGELHALTER DJ, 1990, C REASONING UNCERTAI; SPIKOVSKA L, 1990, TAI 90 TOOLS ARTIFIC; STONE M, 1974, J R STAT SOC B, V36, P111; SUTHERLAND A, 1992, C NEW TECHNIQUES TEC; THRUN SB, 1991, MONKS PROBLEMS PERFO, P1; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918; TSAPTSINOS D, 1990, APPLICATION ARTIFICI, V5; UNGER S, 1981, METHODEN AUTOMATISCH; VANCUTSEM T, 1991, 2ND INT WORKSH BULK; Weiss S. M., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence; WEISS SM, 1990, ARTIF INTELL, V45, P47, DOI 10.1016/0004-3702(90)90037-Z; WEISS SM, 1991, COMPUTER SYSTEMS LER; Xu L., 1991, INT J NEURAL SYSTEMS, V2, P169, DOI 10.1142/S0129065791000169	70	39	42	TAYLOR & FRANCIS	BRISTOL	1900 FROST ROAD, SUITE 101, BRISTOL, PA 19007-1598	0883-9514			APPL ARTIF INTELL	Appl. Artif. Intell.	MAY-JUN	1995	9	3					289	333		10.1080/08839519508945477		45	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	RF068	WOS:A1995RF06800002	
J	Dafni, UG; Tsiatis, AA				Dafni, UG; Tsiatis, AA			Evaluating surrogate markers of clinical outcome when measured with error	BIOMETRICS			English	Article						AIDS; measurement error; proportional hazards; surrogate markers; time-varying covariates	COVARIATE MEASUREMENT ERRORS; LONGITUDINAL DATA; HIV-INFECTION; REGRESSION-MODELS; PROGRESSION; ZIDOVUDINE; SURVIVAL; COHORT; AIDS; TIME	In most clinical trials, markers are measured periodically with error. In the presence of measurement error, the naive method of using the observed marker values in the Cox model to evaluate the relationship between the marker and clinical outcome can produce biased estimates and lead to incorrect conclusions when evaluating a potential surrogate. We propose a two-stage approach to account for the measurement error and reduce the bias of the estimate. In the first stage, an empirical Bayes estimate of the time-dependent covariate is computed at each event time. In the second stage, these estimates are imputed in the Cox proportional hazards model to estimate the regression parameter of interest. We demonstrate through extensive simulations that this methodology reduces the bias of the regression estimate and correctly identifies good surrogate markers more often than the naive approach. An application evaluating CD4 count as a surrogate of disease progression in an AIDS clinical trial is presented.	Harvard Univ, Sch Publ Hlth, Dept Biostat, Boston, MA 02115 USA	Dafni, UG (reprint author), Harvard Univ, Sch Publ Hlth, Dept Biostat, 677 Huntington Ave, Boston, MA 02115 USA.						BRESLOW N, 1974, BIOMETRICS, V30, P89, DOI 10.2307/2529620; CHOI SS, 1993, ANN INTERN MED, V118, P674; COX DR, 1975, BIOMETRIKA, V62, P269, DOI 10.1093/biomet/62.2.269; COX DR, 1972, J R STAT SOC B, V34, P187; DEGRUTTOLA V, 1991, J AM STAT ASSOC, V86, P569, DOI 10.2307/2290384; FISCHL MA, 1990, ANN INTERN MED, V112, P727; GUTTMAN I, 1982, LINEAR MODELS; HUGHES MD, 1993, BIOMETRICS, V49, P1056, DOI 10.2307/2532247; JONES RH, 1990, BIOMETRIKA, V77, P721, DOI 10.1093/biomet/77.4.721; LAGAKOS SW, 1992, ANN INTERN MED, V116, P599; LAIRD NM, 1982, BIOMETRICS, V38, P963, DOI 10.2307/2529876; PEPE MS, 1989, STAT MED, V8, P1167, DOI 10.1002/sim.4780080918; PRENTICE RL, 1982, BIOMETRIKA, V69, P331, DOI 10.1093/biomet/69.2.331; PRENTICE RL, 1989, STAT MED, V8, P431, DOI 10.1002/sim.4780080407; PRENTICE RL, 1983, ANN STAT, V11, P804, DOI 10.1214/aos/1176346247; TSIATIS AA, 1995, J AM STAT ASSOC, V90, P27, DOI 10.2307/2291126; TSIATIS AA, 1992, AIDS EPIDEMIOLOGY ME, P256; VITTINGHOFF E, 1994, STAT MED, V13, P1101, DOI 10.1002/sim.4780131103	18	38	38	INTERNATIONAL BIOMETRIC SOC	WASHINGTON	1441 I ST, NW, SUITE 700, WASHINGTON, DC 20005-2210 USA	0006-341X			BIOMETRICS	Biometrics	DEC	1998	54	4					1445	1462		10.2307/2533670		18	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	154PZ	WOS:000077898700020	
J	Acharya, UR; Sree, SV; Chattopadhyay, S; Yu, WW; Alvin, APC				Acharya, U. Rajendra; Sree, Vinitha S.; Chattopadhyay, Subhagata; Yu, Wenwei; Alvin, Ang Peng Chuan			APPLICATION OF RECURRENCE QUANTIFICATION ANALYSIS FOR THE AUTOMATED IDENTIFICATION OF EPILEPTIC EEG SIGNALS	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS			English	Article						Epilepsy; recurrence plot; RQA; non-linear methods; classifiers; seizure	FUNCTION NEURAL-NETWORK; WAVELET-CHAOS METHODOLOGY; HIGHER-ORDER SPECTRA; ALZHEIMERS-DISEASE; SEIZURE DETECTION; CLASSIFICATION; SYNCHRONIZATION; DIAGNOSIS; PLOTS; OPTIMIZATION	Epilepsy is a common neurological disorder that is characterized by the recurrence of seizures. Electroencephalogram (EEG) signals are widely used to diagnose seizures. Because of the non-linear and dynamic nature of the EEG signals, it is difficult to effectively decipher the subtle changes in these signals by visual inspection and by using linear techniques. Therefore, non-linear methods are being researched to analyze the EEG signals. In this work, we use the recorded EEG signals in Recurrence Plots (RP), and extract Recurrence Quantification Analysis (RQA) parameters from the RP in order to classify the EEG signals into normal, ictal, and interictal classes. Recurrence Plot (RP) is a graph that shows all the times at which a state of the dynamical system recurs. Studies have reported significantly different RQA parameters for the three classes. However, more studies are needed to develop classifiers that use these promising features and present good classification accuracy in differentiating the three types of EEG segments. Therefore, in this work, we have used ten RQA parameters to quantify the important features in the EEG signals. These features were fed to seven different classifiers: Support vector machine (SVM), Gaussian Mixture Model (GMM), Fuzzy Sugeno Classifier, K-Nearest Neighbor (KNN), Naive Bayes Classifier (NBC), Decision Tree (DT), and Radial Basis Probabilistic Neural Network (RBPNN). Our results show that the SVM classifier was able to identify the EEG class with an average efficiency of 95.6%, sensitivity and specificity of 98.9% and 97.8%, respectively.	[Acharya, U. Rajendra; Alvin, Ang Peng Chuan] Ngee Ann Polytech, Dept Elect & Comp Engn, Singapore 599489, Singapore; [Sree, Vinitha S.] Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore 639798, Singapore; [Chattopadhyay, Subhagata] Natl Inst Sci & Technol, Dept Comp Sci & Engn, Berhampur 761008, Orissa, India; [Yu, Wenwei] Chiba Univ, Chiba, Japan	Acharya, UR (reprint author), Ngee Ann Polytech, Dept Elect & Comp Engn, Singapore 599489, Singapore.	aru@np.edu.sg					Acharya UR, 2009, J MECH MED BIOL, V9, P539, DOI 10.1142/S0219519409003152; Adeli H, 2005, CLIN EEG NEUROSCI, V36, P131; Adeli H, 2008, NEUROSCI LETT, V444, P190, DOI 10.1016/j.neulet.2008.08.008; Adeli H, 2007, IEEE T BIO-MED ENG, V54, P205, DOI 10.1109/TBME.2006.886855; Adeli H, 2010, AUTOMATED EEG-BASED DIAGNOSIS OF NEUROLOGICAL DISORDERS: INVENTING THE FUTURE OF NEUROLOGY, P1, DOI 10.1201/9781439815328; Adeli H, 2003, J NEUROSCI METH, V123, P69, DOI 10.1016/S0165-0270(02)00340-0; Adeli H, 2009, NEURAL NETWORKS, V22, P1018, DOI 10.1016/j.neunet.2009.05.003; Adeli H, 2005, J ALZHEIMERS DIS, V7, P187; Ahmadlou A., 2011, ALZ DIS ASSOC DIS, V25, P85; Ahmadlou M, 2010, J CLIN NEUROPHYSIOL, V27, P328, DOI 10.1097/WNP.0b013e3181f40dc8; Ahmadlou M, 2011, CLIN EEG NEUROSCI, V42, P6; Ahmadlou M, 2010, J NEURAL TRANSM, V117, P1099, DOI 10.1007/s00702-010-0450-3; Ahmadlou M, 2010, INTEGR COMPUT-AID E, V17, P197, DOI 10.3233/ICA-2010-0345; Ahmadlou M, 2010, CLIN EEG NEUROSCI, V41, P1; Anand P, 2009, INT J NEURAL SYST, V19, P127, DOI 10.1142/S0129065709001896; Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907; Bai D., 2007, J BIOMEDICAL ENG, P200; Chua KC, 2011, J MED SYST, V35, P1563, DOI 10.1007/s10916-010-9433-z; Chua K. C., 2009, Journal of Medical Engineering & Technology, V33, P42, DOI 10.1080/03091900701559408; Chua KC, 2009, P I MECH ENG H, V223, P485, DOI 10.1243/09544119JEIM484; ECKMANN JP, 1987, EUROPHYS LETT, V4, P973, DOI 10.1209/0295-5075/4/9/004; Faust O, 2010, INT J NEURAL SYST, V20, P159, DOI 10.1142/S0129065710002334; Ghosh-Dastidar S, 2009, NEURAL NETWORKS, V22, P1419, DOI 10.1016/j.neunet.2009.04.003; Ghosh-Dastidar S, 2007, IEEE T BIO-MED ENG, V54, P1545, DOI 10.1109/TBME.2007.891945; Ghosh-Dastidar S, 2007, INTEGR COMPUT-AID E, V14, P187; Ghosh-Dastidar S, 2008, IEEE T BIO-MED ENG, V55, P512, DOI 10.1109/TBME.2007.905490; Good LB, 2009, INT J NEURAL SYST, V19, P173, DOI 10.1142/S0129065709001951; Guler NF, 2005, EXPERT SYST APPL, V29, P506, DOI 10.1016/j.eswa.2005.04.011; Han J., 2005, DATA MINING CONCEPTS; Huang LY, 2006, LECT NOTES COMPUT SC, V4234, P58; Kannathal N., 2004, BIOMEDICAL ONLINE J, V3; Kannathal N, 2005, COMPUT METH PROG BIO, V80, P187, DOI 10.1016/j.cmpb.2005.06.012; Kannathal N, 2005, COMPUT METH PROG BIO, V80, P17, DOI 10.1016/j.cmpb.2005.06.005; Karim A, 2003, J TRANSP ENG-ASCE, V129, P494, DOI 10.1061/(ASCE)0733-947X(2003)129:5(494); Lehnertz K., 2008, J BIOL PHYS, V33, P253; Li XL, 2004, PHYS LETT A, V333, P164, DOI 10.1016/j.physleta.2004.10.028; Lian HC, 2009, INT J NEURAL SYST, V19, P457; Marwan N, 2007, PHYS REP, V438, P237, DOI 10.1016/j.physrep.2006.11.001; Ocak H, 2009, EXPERT SYST APPL, V36, P2027, DOI 10.1016/j.eswa.2007.12.065; Osorio I, 2009, INT J NEURAL SYST, V19, P149, DOI 10.1142/S0129065709001926; Ouyang G, 2006, C P IEEE ENG MED BIO, P153; Pijn JPM, 1997, BRAIN TOPOGR, V9, P249, DOI 10.1007/BF01464480; Polat K., 2007, APPL MATH COMPUT, V32, P625; Raiesdana S, 2009, COMPUT BIOL MED, V39, P1073, DOI 10.1016/j.compbiomed.2009.09.001; Rajendra Acharya U., 2005, COMPUT METH PROG BIO, V80, P37, DOI DOI 10.1016/J.CMPB.2005.06.011; SADATI N, 2006, P IEEE INT C FUZZ SY, P596; Sankari Z, 2011, CLIN NEUROPHYSIOL, V122, P897, DOI 10.1016/j.clinph.2010.09.008; Sankari Z., 2011, J NEUROSCIE IN PRESS; Shoeb A, 2009, INT J NEURAL SYST, V19, P157, DOI 10.1142/S0129065709001938; SONG LH, 2004, NEUROSCI LETT, V366, P148; Srinivasan V, 2005, J Med Syst, V29, P647, DOI 10.1007/s10916-005-6133-1; Subasi A, 2007, EXPERT SYST APPL, V32, P1084, DOI 10.1016/j.eswa.2006.02.005; Subha DP, 2010, J MED SYST, V34, P195, DOI 10.1007/s10916-008-9231-z; Wu DF, 2010, INT J NEURAL SYST, V20, P109, DOI 10.1142/S0129065710002292; Yang Y, 2010, INT J NEURAL SYST, V20, P13, DOI 10.1142/S0129065710002206; ZBILUT JP, 1992, PHYS LETT A, V171, P199, DOI 10.1016/0375-9601(92)90426-M; Zhu TQ, 2008, LECT NOTES COMPUT SC, V5226, P438	57	37	38	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657			INT J NEURAL SYST	Int. J. Neural Syst.	JUN	2011	21	3					199	211		10.1142/S0129065711002808		13	Computer Science, Artificial Intelligence	Computer Science	799NR	WOS:000293293900003	
J	Kim, SB; Han, KS; Rim, HC; Myaeng, SH				Kim, Sang-Bum; Han, Kyoung-Soo; Rim, Hae-Chang; Myaeng, Sung Hyon			Some effective techniques for naive Bayes text classification	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						text classification; naive Bayes classifier; Poisson model; feature weighting	CATEGORIZATION	While naive Bayes is quite effective in various data mining tasks, it shows a disappointing result in the automatic text classification problem. Based on the observation of naive Bayes for the natural language text, we found a serious problem in the parameter estimation process, which causes poor results in text classification domain. In this paper, we propose two empirical heuristics: per-document text normalization and feature weighting method. While these are somewhat ad hoc methods, our proposed naive Bayes text classifier performs very well in the standard benchmark collections, competing with state-of-the-art text classifiers based on a highly complex learning method such as SVM.	Korea Univ, Coll Informat & Commun, Dept Comp Sci & Engn, Seoul 136701, South Korea; Informat & Commun Univ, Taejon 305732, South Korea	Kim, SB (reprint author), Korea Univ, Coll Informat & Commun, Dept Comp Sci & Engn, Anam Dong 1 Ka, Seoul 136701, South Korea.	sbkim@nlp.korea.ac.kr; kshan@nlp.korea.ac.kr; rim@nlp.korea.ac.kr; myaeng@icu.ac.kr					Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; HOW BC, 2004, P IEEE WIC ACM INT C, P599; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Joachims T., 1997, P 14 INT C MACH LEAR, P143; Koller D., 1996, P 13 INT C MACH LEAR, P284; Lewis D. D., 1992, THESIS U MASSACHUSET; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; McCallum A., 1998, P 15 INT C MACH LEAR, P350; Mladenic D., 1998, P 10 EUR C MACH LEAR, P95; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Robertson S., 1998, P TEXT RETRIEVAL C T, P199; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SEBASTIANI F, 2001, IEIB4311999 CONS NAZ; SINGHAL A, 1998, P 7 TEXT RETR C TREC, P186; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Zhang J, 1998, JAMA-J AM MED ASSOC, V280, P1690, DOI 10.1001/jama.280.19.1690	19	37	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2006	18	11					1457	1466				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	084OZ	WOS:000240544500002	
J	Roos, T; Wettig, H; Grunwald, P; Myllymaki, P; Tirri, H				Roos, T; Wettig, H; Grunwald, P; Myllymaki, P; Tirri, H			On discriminative Bayesian network classifiers and logistic regression	MACHINE LEARNING			English	Article						Bayesian classifiers; Bayesian networks; discriminative learning; logistic regression	DISTRIBUTIONS	Discriminative learning of the parameters in the naive Bayes model is known to be equivalent to a logistic regression problem. Here we show that the same fact holds for much more general Bayesian network models, as long as the corresponding network structure satisfies a certain graph-theoretic property. The property holds for naive Bayes but also for more complex structures such as tree-augmented naive Bayes (TAN) as well as for mixed diagnostic-discriminative structures. Our results imply that for networks satisfying our property, the conditional likelihood cannot have local maxima so that the global maximum can be found by simple local optimization methods. We also show that if this property does not hold, then in general the conditional likelihood can have local, non-global maxima. We illustrate our theoretical results by empirical experiments with local optimization in a conditional naive Bayes model. Furthermore, we provide a heuristic strategy for pruning the number of parameters and relevant features in such models. For many data sets, we obtain good results with heavily pruned submodels containing many fewer parameters than the original naive Bayes model.	Helsinki Inst Informat Technol, Complex Syst Computat Grp, FI-02015 Helsinki, Finland; Ctr Wiskunde & Informat, NL-1090 GB Amsterdam, Netherlands	Roos, T (reprint author), Helsinki Inst Informat Technol, Complex Syst Computat Grp, POB 9800, FI-02015 Helsinki, Finland.	teemu.roos@hiit.fi					BARNDORFFNIELSE.O, 1978, INFORMATION EXPONENT; Bernardo J. M., 1994, BAYESIAN THEORY; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; Buntine W. L., 1994, J ARTIFICIAL INTELLI, V2, P159; Cowell R., 2001, P 8 INT C ART INT ST, P175; DAWID AP, 1976, BIOMETRICS, V32, P647, DOI 10.2307/2529753; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; FAYYAD U, 1993, P 13 INT JOINT C ART, P102; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GREINER R, 1997, P 13 C UNC ART INT S, P198; Greiner R., 2002, P 18 NAT C ART INT, P167; Grossman D., 2004, P 21 INT C MACH LEAR, P361; Grunwald P, 2002, 7 VAL INT M BAYES ST; Heckerman D., 1996, MSRTR9506; HECKERMAN D, 1997, P 13 ANN C UNC ART I, P198; Heckerman D., 1997, MSRTR9706; Jebara T., 2003, MACHINE LEARNING DIS; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Kontkanen P., 1999, P 15 INT C UNC ART I, P334; Kontkanen P., 2001, P 17 C UNC ART INT S, P277; Kontkanen P, 2000, STAT COMPUT, V10, P39, DOI 10.1023/A:1008984400380; Lauritzen S. L., 1996, GRAPHICAL MODELS; Little RJA, 1987, STAT ANAL MISSING DA; Madden M. G., 2003, ECMUPKDD03 WORKSH PR, P59; McLachlan G., 1997, EM ALGORITHM EXTENSI; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; MINKA T, 2003, 758 CARN U DEP STAT; Myllymaki P., 2002, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V11, DOI 10.1142/S0218213002000940; NG A, 2001, ADV NEURAL INFORMATI, V14, P605; PEARL J, 1987, ARTIF INTELL, V32, P245, DOI 10.1016/0004-3702(87)90012-9; Pearl J., 1988, PROBABILISTIC REASON; RAINA R, 2003, ADV NEURAL INFORMATI, V16; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; Russell S., 1995, P 14 INT JOINT C ART, P1146; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shen B, 2003, PROC INT C TOOLS ART, P296; Thiesson B., 1995, P 1 INT C KNOWL DISC, P306; WETTIG H, 2000, P 18 INT JOINT C ART, P491; WETTIG H, 2002, P 10 FINN ART INT C, P72	40	37	41	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JUN	2005	59	3					267	296				30	Computer Science, Artificial Intelligence	Computer Science	933FG	WOS:000229613700004	
J	Zhu, Y; Hollmen, J; Raty, R; Aalto, Y; Nagy, B; Elonen, E; Kere, J; Mannila, H; Franssila, K; Knuutila, S				Zhu, Y; Hollmen, J; Raty, R; Aalto, Y; Nagy, B; Elonen, E; Kere, J; Mannila, H; Franssila, K; Knuutila, S			Investigatory and analytical approaches to differential gene expression profiling in mantle cell lymphoma	BRITISH JOURNAL OF HAEMATOLOGY			English	Article						mantle cell lymphoma; blastoid variant; array analysis; differential expression	PIM-1 TRANSGENIC MICE; C-MYC; ANNEXIN II; INTERMEDIATE DIFFERENTIATION; LYMPHOCYTIC LYMPHOMA; AGGRESSIVE VARIANTS; ADHESION MOLECULES; BLASTOID VARIANTS; B-LYMPHOCYTES; ZONE LYMPHOMA	Mantle cell lymphoma (MCL) is a non-Hodgkin's lymphoma of B-cell lineage. The blastoid variant of MCL, characterized by high mitotic rate, is clinically more aggressive than common MCL. We used the cDNA array technology to examine the gene expression profiles of both blastoid variant and common MCL. The data was analysed by regression analysis, principal component analysis and the naive Bayes' classifier. Eight genes were identified as differentially deregulated between the two groups. Oncogenes CMYC, BCL2 and PIM1 were upregulated more frequently in the blastoid variant than in common MCL. This implied that the gp130-mediated signal transducer and activator of transcription 3 (STAT3) signalling pathway was involved in the blastoid variant transformation of MCL. Other differentially deregulated genes were TOP1, CD23, CD45, CD70 and NFATC. By using the eight differentially deregulated genes, we created a classifier to distinguish the blastoid variant from common MCL with high accuracy. We also identified 18 genes that were deregulated in both groups. Among them, BCL1, CALLA/CD10 and GRN were suggested to be oncogenes. The products of RGS1, RGS2, ANX2 and CD44H were suggested to promote tumour metastasis. CD66D was suggested to be a tumour suppressor gene.	Haartman Inst, Dept Med Genet, FIN-00014 Helsinki, Finland; Haartman Inst, Dept Pathol, FIN-00014 Helsinki, Finland; Univ Helsinki, Cent Hosp, Helsinki, Finland; Aalto Univ, Lab Comp & Informat Sci, Helsinki, Finland; Univ Helsinki, Cent Hosp, Dept Med, Helsinki, Finland; Semmelweis Univ, Fac Med, Dept Obstet & Gynaecol 1, Genet Lab, H-1085 Budapest, Hungary; Univ Helsinki, Cent Hosp, Dept Pathol, Helsinki, Finland	Knuutila, S (reprint author), Haartman Inst, Dept Med Genet, POB 21, FIN-00014 Helsinki, Finland.	sakari.knuutila@helsinki.fi	Kere, Juha/A-9179-2008; Nagy, Balint/F-6943-2012				AMASON R, 1989, P NATL ACAD SCI USA, V86, P8857; Bea S, 1999, BLOOD, V93, P4365; Bowman EP, 1998, J BIOL CHEM, V273, P28040, DOI 10.1074/jbc.273.43.28040; BREUER M, 1989, NATURE, V340, P61, DOI 10.1038/340061a0; CESARMAN GM, 1994, J BIOL CHEM, V269, P21198; Chung CY, 1996, MOL BIOL CELL, V7, P883; Dang CV, 1999, EXP CELL RES, V253, P63, DOI 10.1006/excr.1999.4686; Duda R.O., 2001, PATTERN CLASSIFICATI; FISHER RI, 1995, BLOOD, V85, P1075; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Greiner TC, 1996, BLOOD, V87, P4302; Hilsenbeck SG, 1999, J NATL CANCER I, V91, P453, DOI 10.1093/jnci/91.5.453; JAFFE ES, 1987, HUM PATHOL, V18, P877, DOI 10.1016/S0046-8177(87)80262-9; Kehrl JH, 1998, IMMUNITY, V8, P1, DOI 10.1016/S1074-7613(00)80453-7; Kiuchi N, 1999, J EXP MED, V189, P63, DOI 10.1084/jem.189.1.63; KLEINERMAN DI, 1995, CANCER RES, V55, P1215; Kleinerman DI, 1996, CANCER RES, V56, P3431; Kunath T, 1995, ONCOGENE, V11, P2375; LARDELLI P, 1990, AM J SURG PATHOL, V14, P752, DOI 10.1097/00000478-199008000-00007; Lens SMA, 1996, EUR J IMMUNOL, V26, P1007, DOI 10.1002/eji.1830260508; Lens SMA, 1999, BRIT J HAEMATOL, V106, P491, DOI 10.1046/j.1365-2141.1999.01573.x; Luo WP, 1997, ONCOGENE, V14, P1697, DOI 10.1038/sj.onc.1200999; Mai Jianxin, 2000, Journal of Biological Chemistry, V275, P12806, DOI 10.1074/jbc.275.17.12806; Mai JX, 2000, BBA-PROTEIN STRUCT M, V1477, P215, DOI 10.1016/S0167-4838(99)00274-5; Monni O, 1999, BRIT J HAEMATOL, V104, P665, DOI 10.1046/j.1365-2141.1999.01257.x; Moratz C, 2000, J IMMUNOL, V164, P1829; Obrink B, 1997, CURR OPIN CELL BIOL, V9, P616, DOI 10.1016/S0955-0674(97)80114-7; Oliferenko S, 1999, J CELL BIOL, V146, P843, DOI 10.1083/jcb.146.4.843; Ott G, 1997, BLOOD, V89, P1421; OTT MM, 1994, HISTOPATHOLOGY, V24, P329, DOI 10.1111/j.1365-2559.1994.tb00533.x; Pinyol M, 1997, BLOOD, V89, P272; Pinyol M, 1998, BLOOD, V91, P2977; POMMIER Y, 1994, CANCER INVEST, V12, P530, DOI 10.3109/07357909409021413; PONTA H, 1998, FRONT BIOSCI, V3, P650; Rao A, 1997, ANNU REV IMMUNOL, V15, P707, DOI 10.1146/annurev.immunol.15.1.707; Reif K, 2000, J IMMUNOL, V164, P4720; Schaffner C, 2000, P NATL ACAD SCI USA, V97, P2773, DOI 10.1073/pnas.050400997; Sembries S, 1999, BLOOD, V93, P624; Shirogane T, 1999, IMMUNITY, V11, P709, DOI 10.1016/S1074-7613(00)80145-4; Smid-Koopman E, 2000, BRIT J CANCER, V83, P246; THOMPSON JA, 1991, J CLIN LAB ANAL, V5, P344, DOI 10.1002/jcla.1860050510; VANLOHUIZEN M, 1991, CELL, V65, P737, DOI 10.1016/0092-8674(91)90382-9; VANLOHUIZEN M, 1989, CELL, V56, P673, DOI 10.1016/0092-8674(89)90589-8; Yatabe Y, 2000, BLOOD, V95, P2253; Zhu Y, 2000, HAEMATOLOGICA, V85, P908; ZUKERBERG LR, 1993, AM J CLIN PATHOL, V100, P373	46	37	39	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0007-1048			BRIT J HAEMATOL	Br. J. Haematol.	DEC	2002	119	4					905	915		10.1046/j.1365-2141.2002.03931.x		11	Hematology	Hematology	623FR	WOS:000179693100006	
J	Ramoni, M; Sebastiani, P				Ramoni, M; Sebastiani, P			Robust Bayes classifiers	ARTIFICIAL INTELLIGENCE			English	Article						Bayes classifier; missing data; probability intervals	ALGORITHM	Naive Bayes classifiers provide an efficient and scalable approach to supervised classification problems. When some entries in the training set are missing, methods exist to learn these classifiers under some assumptions about the pattern of missing data. Unfortunately, reliable information about the pattern of missing data may be not readily available and recent experimental results show that the enforcement of an incorrect assumption about the pattern of missing data produces a dramatic decrease in accuracy of the classifier. This paper introduces a Robust Bayes Classifier (RBC) able to handle incomplete databases with no assumption about the pattern of missing data. In order to avoid assumptions, the RBC bounds all the possible probability estimates within intervals using a specialized estimation method. These intervals are then used to classify new cases by computing intervals on the posterior probability distributions over the classes given a new case and by ranking the intervals according to some criteria. We provide two scoring methods to rank intervals and a decision theoretic approach to trade off the risk of an erroneous classification and the choice of not classifying unequivocally a case. This decision theoretic approach can also be used to assess the opportunity of adopting assumptions about the pattern of missing data. The proposed approach is evaluated on twenty publicly available databases. (C) 2001 Elsevier Science B.V. All rights reserved.	Harvard Univ, Sch Med, Childrens Hosp, Informat Program, Boston, MA 02115 USA; Univ Massachusetts, Dept Math & Stat, Amherst, MA 01003 USA	Ramoni, M (reprint author), Harvard Univ, Sch Med, Childrens Hosp, Informat Program, 300 Longwood Ave, Boston, MA 02115 USA.						Blake C. L., 1998, UCI REPOSITORY MACHI; Campos L., 1994, INT J UNCERTAIN FUZZ, V2, P167; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda R., 1973, PATTERN CLASSIFICATI; Fagiuoli E, 1998, ARTIF INTELL, V106, P77, DOI 10.1016/S0004-3702(98)00089-7; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; KOHAVI R, 1995, P IJCAI 95 MONTR QUE, P1146; Kohavi R., 1997, P 9 EUR C MACH LEARN, P78; KYBURG HE, 1983, BEHAV BRAIN SCI, V6, P231; Langley P., 1992, P 10 NAT C ART INT, P223; Levi I., 1974, J PHILOS, V71, P391, DOI 10.2307/2025161; LITTLE RJA, 1987, STAT ANAL MISSING; PITTARELLI M, 1994, IEEE T KNOWL DATA EN, V6, P293, DOI 10.1109/69.277772; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAMONI M, 1999, INTELL DATA ANAL, P129; RAMONI M, 2000, IN PRESS MACHINE LEA; Ramoni M., 1995, P 14 INT JOINT C ART, P1808; Rockafellar R. T., 1970, CONVEX ANAL; Russell S., 1995, P 14 INT JOINT C ART, P1146; SPIEGELHALTER DJ, 1990, NETWORKS, V20, P157; SPIEGELHALTER DJ, 1992, BAYESIAN STATISTICS, V4, P447	22	37	63	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702			ARTIF INTELL	Artif. Intell.	JAN	2001	125	1-2					209	226		10.1016/S0004-3702(00)00085-0		18	Computer Science, Artificial Intelligence	Computer Science	397UZ	WOS:000166717100006	
J	Zhang, ML; Pena, JM; Robles, V				Zhang, Min-Ling; Pena, Jose M.; Robles, Victor			Feature selection for multi-label naive Bayes classification	INFORMATION SCIENCES			English	Article						Multi-label learning; Naive Bayes; Feature selection; Principal component analysis; Genetic algorithm	TEXT CATEGORIZATION; NETWORKS	In multi-label learning, the training set is made up of instances each associated with a set of labels, and the task is to predict the label sets of unseen instances. In this paper, this learning problem is addressed by using a method called MLNB which adapts the traditional naive Bayes classifiers to deal with multi-label instances. Feature selection mechanisms are incorporated into MLNB to improve its performance. Firstly, feature extraction techniques based on principal component analysis are applied to remove irrelevant and redundant features. After that, feature subset selection techniques based on genetic algorithms are used to choose the most appropriate subset of features for prediction. Experiments on synthetic and real-world data show that MLNB achieves comparable performance to other well-established multi-label learning algorithms. (C) 2009 Elsevier Inc. All rights reserved.	[Zhang, Min-Ling] Hohai Univ, Coll Comp & Informat Engn, Nanjing 210098, Peoples R China; [Zhang, Min-Ling] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210093, Peoples R China; [Pena, Jose M.; Robles, Victor] Tech Univ Madrid, Dept Comp Architecture & Technol, Madrid, Spain	Zhang, ML (reprint author), Hohai Univ, Coll Comp & Informat Engn, Nanjing 210098, Peoples R China.	zhangml@hhu.edu.cn; jmpena@fi.upm.es; vrobles@fi.upm.es			National Science Foundation of China [60805022]; Programs Foundation of Ministry of Education of China for Young Faculties [200802941009]; Open Foundation of National Key Laboratory for Novel Software Technology of China [KFKT2008B12]; Startup Foundation for Excellent New Faculties of Hohai University; Spanish Ministry of Science [TIN2007-67148]	The authors thankfully acknowledge also the computer resources, technical expertise and assistance provided by the Centro de Supercomputacion y Visualizacion de Madrid (CeSViMa) and the Spanish Supercomputing Network.	Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Brinker K., 2006, P 17 EUR C ART INT E, P489; BRINKER K, 2007, P 20 INT JOINT C ART, P702; Cai L., 2004, P 13 ACM INT C INF K, P78, DOI 10.1145/1031171.1031186; Catal C, 2009, INFORM SCIENCES, V179, P1040, DOI 10.1016/j.ins.2008.12.001; Chen G., 2008, P SIAM INT C DAT MIN, P410; Clare A., 2001, LECT NOTES COMPUTER, V2168, P42; Comite F. D., 2003, LECT NOTES COMPUTER, V2734, P35; Crammer K., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Gao S., 2003, P 26 ANN INT ACM SIG, P174; Gao S., 2004, P 21 INT C MACH LEAR, P329; GHAMRAWI N., 2005, P 14 ACM INT C INF K, P195, DOI 10.1145/1099554.1099591; Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22; Goldberg D., 1989, GENETIC ALGORITHMS S; Gunal S, 2008, INFORM SCIENCES, V178, P3716, DOI 10.1016/j.ins.2008.06.001; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Jollife I. T., 1986, PRINCIPAL COMPONENT; Kang F., 2006, P IEEE COMP SOC C CO, P1719; Kazawa H., 2005, ADV NEURAL INFORM PR, V17, P649; Liu Y., 2006, P 21 NAT C ART INT, P421; Maldonado S, 2009, INFORM SCIENCES, V179, P2208, DOI 10.1016/j.ins.2009.02.014; McCallum A. K., 1999, AAAI 99 WORKSH TEXT; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; Qi G.-J., 2007, P 15 ACM INT C MULT, P17, DOI DOI 10.1145/1291233.1291245; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAK R, 2005, P 4 INT C MACH LEARN, P177; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; ROUSU J, 2005, P 22 INT C MACH LEAR, P774; Rumelhart D., 1986, PARALLEL DISTRIBUTED, V1, P318; Saito K., 2003, ADV NEURAL INFORMATI, V15, P721; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; Slezak D, 2009, INFORM SCIENCES, V179, P197, DOI 10.1016/j.ins.2008.09.007; Thabtah F., 2004, P 4 IEEE INT C DAT M, P217; Trohidis K., 2008, P 9 INT C MUS INF RE, P325; Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406; Veloso A, 2007, LECT NOTES ARTIF INT, V4702, P605; Vens C, 2008, MACH LEARN, V73, P185, DOI 10.1007/s10994-008-5077-3; Yu K, 2005, P 28 ANN INT ACM SIG, P258, DOI 10.1145/1076034.1076080; Zhang ML, 2009, NEURAL PROCESS LETT, V29, P61, DOI 10.1007/s11063-009-9095-3; Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhu S., 2005, P 28 ANN INT ACM SIG, P274, DOI 10.1145/1076034.1076082	47	36	40	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	SEP 9	2009	179	19					3218	3229		10.1016/j.ins.2009.06.010		12	Computer Science, Information Systems	Computer Science	485JI	WOS:000269116700002	
J	Chen, K; Kurgan, L; Rahbari, M				Chen, Ke; Kurgan, Lukasz; Rahbari, Mandana			Prediction of protein crystallization using collocation of amino acid pairs	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						protein crystallization; X-ray crystallography; collocated amino acid pairs; classification; CRYSTALP; Naive Bayes	STRUCTURAL CLASS; CLASSIFIER; SEQUENCE	While above 80% of protein structures in PDB were determined using X-ray crystallography, in some cases only 42% of soluble purified proteins yield crystals. Since experimental verification of protein's ability to crystallize is relatively expensive and time-consuming, we propose a new in silico prediction system, called CRYSTALP, which is based on the protein's sequence. CRYSTALP uses a novel feature-based sequence representation and applies a Naive Bayes classifier. It was compared with recent, competing in silico method, SECRET [P. Smialowski, T. Schmidt, J. Cox, A. Kirschner, D. Frishman, Will my protein crystallize'? A sequence-based predictor, Proteins 62 (2) (2006) 343-355], and other state-of-the-art classifiers. Based on experimental tests, CRYSTALP is shown to predict crystallization with 77.5% accuracy, which is better by over 10% than the SECRET's accuracy, and better than accuracy of the other considered classifiers. CRYSTALP uses different and over 50% less features to represent sequences than SECRET. Additionally, features used by CRYSTALP may help to discover intra-molecular markers that influence protein crystallization. (c) 2007 Elsevier Inc. All rights reserved.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada	Kurgan, L (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.	lkurgan@ece.ualberta.ca	Kurgan, Lukasz/B-5721-2009	Kurgan, Lukasz/0000-0002-7749-0314			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen K, 2006, Proceedings of the 2006 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology, P366; HALL M, 1999, THESIS U WAKIATO; JOHN GH, 1995, P 11 C UNC ART INT, P338; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; KURGAN L, 2006, PATTERN RECOGN, V398, P2323; Le CS, 1992, APPL STAT, V41, P191; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; Palmer AG, 2002, STRUCTURE, V10, P1603, DOI 10.1016/S0969-2126(02)00915-2; Perman B, 2000, CELL MOL BIOL, V46, P895; ROSS Q, 1993, C 45 PROGRAMS MACHIN; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Smialowski P, 2006, PROTEINS, V62, P343, DOI 10.1002/prot.20789; Witten IH, 2005, DATA MINING PRACTICA; Yee A, 2003, ACCOUNTS CHEM RES, V36, P183, DOI 10.1021/ar010126g; Yuan Z, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-248	19	36	38	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	APR 13	2007	355	3					764	769		10.1016/j.bbrc.2007.02.040		6	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	147KG	WOS:000245001300027	
J	Sierra, B; Larranaga, P				Sierra, B; Larranaga, P			Predicting survival in malignant skill melanoma using Bayesian networks automatically induced by genetic algorithms. An empirical comparison between different approaches	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article; Proceedings Paper	6th Conference on Artificial Intelligence in Medicine Europe (AIME 97)	MAR 23-26, 1997	GRENOBLE, FRANCE	Univ Joseph fourier, Grenoble, CNRS, Grenoble Isere Dev, France, Assoc Francaise Intelligence Artificielle		Bayesian network; genetic algorithm; structure learning; model search; 10-fold cross-validation		In this work we introduce a methodology based on genetic algorithms for the automatic induction of Bayesian networks from a file containing cases and variables related to the problem. The structure is learned by applying three different methods: The Cooper and Herskovits metric for a general Bayesian network, the Markov blanket approach and the relaxed Markov blanket method. The methodologies are applied to the problem of predicting survival of people after 1, 3 and 5 years of being diagnosed as having malignant skin melanoma. The accuracy of the obtained models, measured in terms of the percentage of well-classified subjects, is compared to that obtained by the so-called Naive-Bayes. In the four approaches, the estimation of the model accuracy is obtained from the 10-fold cross-validation method. (C) 1998 Elsevier Science B.V. All rights reserved.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, E-20080 San Sebastian, Spain	Sierra, B (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, POB 649, E-20080 San Sebastian, Spain.		Larranaga, Pedro/F-9293-2013				ANDERSEN SK, 1989, 11 INT JOINT C ART I, P1128; Beinlich IA, 1989, P 2 EUR C ART INT ME, P247; BOUCKAERT RR, 1992, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P9; Bouckaert R. R., 1994, Uncertainty in Artificial Intelligence. Proceedings of the Tenth Conference (1994); COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Goldberg GE, 1989, GENETIC ALGORITHMS S; Heckerman D., 1994, MSRTR9409; IZARZUGAZA MI, 1994, OSASUNKARIA, P8; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; Larranaga P., 1996, LECT NOTES STAT, V112, P165; Lauritzen S. L., 1996, GRAPHICAL MODELS; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; PEARL J, 1987, ARTIF INTELL; Pearl J., 1988, PROBABILISTIC REASON; PROVAN GM, 1996, LECT NOTES STAT, V112, P291; Robinson R. W., 1977, LECT NOTES MATH, V622, P28; STONE M, 1974, J R STAT SOC B, V36, P111	19	36	36	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	SEP-OCT	1998	14	1-2					215	230		10.1016/S0933-3657(98)00024-4		16	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	124QJ	WOS:000076193000012	
J	Pant, G; Srinivasan, P				Pant, G; Srinivasan, P			Learning to crawl: Comparing classification schemes	ACM TRANSACTIONS ON INFORMATION SYSTEMS			English	Article						topical crawlers; focused crawlers; classifiers; machine learning	SUPPORT VECTOR MACHINES; NEURAL NETWORKS; WEB; TUTORIAL	Topical crawling is a young and creative area of research that holds the promise of benefiting from several sophisticated data mining techniques. The use of classification algorithms to guide topical crawlers has been sporadically suggested in the literature. No systematic study, however, has been done on their relative merits. Using the lessons learned from our previous crawler evaluation studies, we experiment with multiple versions of different classification schemes. The crawling process is modeled as a parallel best-first search over a graph defined by the Web. The classifiers provide heuristics to the crawler thus biasing it towards certain portions of the Web graph. Our results show that Naive Bayes is a weak choice for guiding a topical crawler when compared with Support Vector Machine or Neural Network. Further, the weak performance of Naive Bayes can be partly explained by extreme skewness of posterior probabilities generated by it. We also observe that despite similar performances, different topical crawlers cover subspaces on the Web with low overlap.	Univ Utah, Sch Accounting & Informat Syst, Salt Lake City, UT 84112 USA; Univ Iowa, Sch Lib & Informat Sci, Iowa City, IA 52242 USA; Univ Iowa, Dept Management Sci, Iowa City, IA 52242 USA	Pant, G (reprint author), Univ Utah, Sch Accounting & Informat Syst, Salt Lake City, UT 84112 USA.	gautam.pant@business.utah.edu; padmini-srinivasan@uiowa.edu					Aggarwal C. C., 2001, P 10 INT WORLD WID W; BENSHAUL I, 1999, COMPUTER NETWORKS IS, V31, P11; Ben-Shaul I, 1999, COMPUT NETW, V31, P1653, DOI 10.1016/S1389-1286(99)00045-6; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P2, DOI DOI 10.1023/A:1009715923555; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chakrabarti S., 1999, P 8 INT WORLD WID WE; Chakrabarti S., 2002, P 11 INT WORLD WID W; CHAU M, 2001, P 1 ACM IEEE CS JOIT; CHEN H, 2002, DECIS SUPPORT SYST, P1; Chen HC, 1998, J AM SOC INFORM SCI, V49, P604; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CRASWELL N, 2003, P TREC 2003; Cristianini N, 2002, AI MAG, V23, P31; DAVISON BD, 2000, P 23 ANN INT ACM SIG; DAY M, 2003, COLLECTING PRESERVIN; DEBRA PME, 1994, P 1 INT WORLD WIDE W; Dietterich TG, 1997, AI MAG, V18, P97; Diligenti M., 2000, P 26 INT C VER LARG, P527; Duda R. O., 2000, PATTERN CLASSIFICATI; DUMAIS ST, 1998, IEEE INTELL SYST APP, V13, P4; ELKAN C, 1997, INT C KNOWL DISC DAT; Hersovici M., 1998, P 7 INT WORLD WID WE; Hogg R. V., 2004, INTRO MATH STAT; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Joachims T., 2002, THESIS KLUWER; JOHN GH, 1995, P 11 C UNC ART INT, P338; Johnson J., 2003, P 20 INT C MACH LEAR; Katzer J., 1982, Information Technology: Research and Development, V1; Lawrence S, 1998, SCIENCE, V280, P98, DOI 10.1126/science.280.5360.98; LeCun Y., 1986, DISORDERED SYSTEMS B, P233; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; LIPPMANN RP, 1988, ARTIFICIAL NEURAL NE, V36; MCCALLUM A, 1998, P AAAI 98 WORKSH LER; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; MCLACHLAN G, 1992, DISCRIMINATN ANAL ST; Menczer F, 2000, MACH LEARN, V39, P203, DOI 10.1023/A:1007653114902; Menczer F., 2004, ACM T INTERNET TECHN, V4, P378, DOI 10.1145/1031114.1031117; Menczer F., 2001, P 24 ANN INT ACM SIG; Mitchell T.M., 1997, MACHINE LEARNING; MMAREK YS, 1997, COMPUTER NETWORKS IS, V29, P1269; MMAREK YS, 1997, COMPUTER NETWORKS IS, V29, P8; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Pant G., 2003, P 7 EUR C RES ADV TE; PANT G, 2002, P 11 WORLD WID WEB W; Pant G., 2004, WEB DYNAMICS; Pant G., 2004, P 4 ACM IEEE CS JOIN, P142, DOI 10.1145/996350.996384; Pant G, 2002, AUTON AGENT MULTI-AG, V5, P221, DOI 10.1023/A:1014853428272; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Qin J., 2004, P 4 ACM IEEE CS JOIN; Rennie J., 1999, P 16 INT C MACH LEAR, P335; Rumelhart D., 1986, PARALLEL DISTRIBUTED, V1, P318; RUMELHART DE, 1994, COMMUN ACM, V37, P87, DOI 10.1145/175247.175256; Salton G., 1983, INTRO MODERN INFORM; Salton G., 1971, SMART RETRIEVAL SYST; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; Scholkopf B., 1999, ADV KERNEL METHODS S; SCHOLKOPF B, 2003, LECT NOTES ARTIF INT, P41; SRINIVASAN P, 2003, SIGIR 2003 WORKSH DE; Srinivasan P, 2005, INFORM RETRIEVAL, V8, P417, DOI 10.1007/s10791-005-6993-5; Theodoridis S., 2003, PATTERN RECOGNITION; Vapnik V., 1995, NATURE STAT LEARNING; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323; WRIGHT S, 1999, NUMERICAL OPTIMIZATI; Yang Y., 1997, P 14 INT C MACH LEAR, P412	67	35	39	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	1046-8188			ACM T INFORM SYST	ACM Trans. Inf. Syst.	OCT	2005	23	4					430	462		10.1145/1095872.1095875		33	Computer Science, Information Systems	Computer Science	987TP	WOS:000233540500003	
J	Maloof, MA; Langley, P; Binford, TO; Nevatia, R; Sage, S				Maloof, MA; Langley, P; Binford, TO; Nevatia, R; Sage, S			Improved rooftop detection in aerial images with machine learning	MACHINE LEARNING			English	Article						supervised learning; learning for computer vision; evaluation of algorithms; applications of learning	OBJECT RECOGNITION; ROC CURVE; FACE DETECTION; AREA; MODELS; ALGORITHMS; ACCURACY; GRAPH	In this paper, we examine the use of machine learning to improve a rooftop detection process, one step in a vision system that recognizes buildings in overhead imagery. We review the problem of analyzing aerial images and describe an existing system that detects buildings in such images. We briefly review four algorithms that we selected to improve rooftop detection. The data sets were highly skewed and the cost of mistakes differed between the classes, so we used ROC analysis to evaluate the methods under varying error costs. We report three experiments designed to illuminate facets of applying machine learning to the image analysis task. One investigated learning with all available images to determine the best performing method. Another focused on within-image learning, in which we derived training and testing data from the same image. A final experiment addressed between-image learning, in which training and testing sets came from different images. Results suggest that useful generalization occurred when training and testing on data derived from images differing in location and in aspect. They demonstrate that under most conditions, naive Bayes exceeded the accuracy of other methods and a handcrafted classifier, the solution currently used in the building detection system.	Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA; Inst Study Learning & Expertise, Palo Alto, CA 94306 USA; Stanford Univ, Dept Comp Sci, Robot Lab, Stanford, CA 94305 USA; Univ So Calif, Sch Engn, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	Maloof, MA (reprint author), Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALI K, 1998, P IM UND WORKSH, P479; BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; BEIDEN S, 2002, IMAGE PROCESSING, V4684; Beiden SV, 2000, ACAD RADIOL, V7, P341, DOI 10.1016/S1076-6332(00)80008-2; Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905; BINFORD T, 1987, P 3 ANN C UNC ART IN, P73; Blake C. L., 1998, UCI RESPOSITORY MACH; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Burl MC, 1998, MACH LEARN, V30, P165, DOI 10.1023/A:1007400206189; Cardie C., 1997, P 14 INT C MACH LEAR, P57; Chan LCA, 1996, PROC CVPR IEEE, P114, DOI 10.1109/CVPR.1996.517062; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; CONKLIN D, 1993, AAAI FALL S MACH LEA, P10; CONNELL JH, 1987, ARTIF INTELL, V31, P159, DOI 10.1016/0004-3702(87)90018-X; COOK D, 1993, AAAI FALL S MACH LEA, P139; CROMWELL RL, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P710; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; DORFMAN DD, 1969, J MATH PSYCHOL, V6, P487, DOI 10.1016/0022-2496(69)90019-4; DORFMAN DD, 1992, INVEST RADIOL, V27, P723, DOI 10.1097/00004424-199209000-00015; DRAPER B, 1996, P DARPA IUW, P1447; DRAPER BA, 1997, SYMBOLIC VISUAL LEAR, P49; DRAPER BA, 1994, IEEE T PATTERN ANAL, V16, P888, DOI 10.1109/34.310684; Duda R., 1973, PATTERN CLASSIFICATI; EGAN JP, 1975, SIGNAL DETECTION THE; Ezawa K., 1996, P 13 INT C MACH LEAR, P139; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FAYYAD U, 1996, EARLY VISUAL LEARNIN, P237; Firschein O., 1997, RADIUS IMAGE UNDERST; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GREEN DM, 1974, SIGNAL DETECTION THE; GROS P, 1993, AAAI FALL S MACH LEA, P40; Gutta S, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P164, DOI 10.1109/AFGR.1996.557259; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hinkley D. V., 1983, ENCY STATISTICAL SCI, V4, P280; JOHN GH, 1995, P 11 C UNC ART INT, P338; KEPPEL G, 1992, INTRO DESIGN ANAL; KIM Z, 2000, P INT C MACH LEARN, P479; Kim ZW, 1999, COMPUT VIS IMAGE UND, V76, P278, DOI 10.1006/cviu.1999.0803; KUBAT M, 1996, P 1997 EUR C MACH LE, P146; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Langley P., 1995, Communications of the ACM, V38, DOI 10.1145/219717.219768; Langley P., 1992, P 10 NAT C ART INT, P223; LEVITT T, 1989, P 5 ANN C UNC ART IN, P371; Lewis D., 1994, P 11 INT C MACH LEAR, P148; Lin C, 1998, COMPUT VIS IMAGE UND, V72, P101, DOI 10.1006/cviu.1998.0724; MALOOF M, 1997, P IM UND WORKSH, P835; MALOOF M, 2000, P 17 INT C MACH LEAR, P567; MALOOF M, 2002, CS0201 GEORG U DEP C; MALOOF M, 2002, P 16 INT C PATT REC; MALOOF M, 1998, 981 I STUD LEARN EXP; Maloof M. A., 1998, Proceedings Fourth IEEE Workshop on Applications of Computer Vision. WACV'98 (Cat. No.98EX201), DOI 10.1109/ACV.1998.732879; MALOOF MA, 1996, P 1996 IM UND WORKSH, P1257; Maloof MA, 1997, EXPERT SYST APPL, V12, P11, DOI 10.1016/S0957-4174(96)00076-0; METZ CE, 1989, INVEST RADIOL, V24, P234, DOI 10.1097/00004424-198903000-00012; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MILLER D, 1997, ADV NEURAL INFORMATI, V9; Mohammad R. M., 1989, Arid Soil Research and Rehabilitation, V3, P11; Mossman D, 1999, MED DECIS MAKING, V19, P78, DOI 10.1177/0272989X9901900110; NAYAR SK, 1996, EARLY VISUAL LEARNIN; Noronha S, 1997, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.1997.609385; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; POMERLEAU D, 1996, EARLY VISUAL LEARNIN, P161; POPE AR, 1996, EARLY VISUAL LEARNIN, P67; Pope AR, 2000, INT J COMPUT VISION, V40, P149, DOI 10.1023/A:1026502202780; PROVAN G, 1996, P IM UND WORKSH, P1403; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F., 1998, P 15 INT C MACH LEAR, P445; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rowley HA, 1996, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1996.517075; Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006; SEGEN J, 1994, MACH LEARN, V4, P621; SENGE PM, 1993, HUMAN RESOURCE DEV Q, V4, P5, DOI 10.1002/hrdq.3920040103; SHEPHERD BA, 1983, P IJCAI 83, P473; SODERLAND S, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P827; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Swets JA, 1982, EVALUATION DIAGNOSTI; Teller A., 1997, SYMBOLIC VISUAL LEAR, P77; THOMPSON M, 1986, STAT MED, V18, P452; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; VIOLA P, 1993, AAAI FALL S MACH LEA, P60; Wagner RF, 2001, ACAD RADIOL, V8, P328, DOI 10.1016/S1076-6332(03)80502-0; Walpole R.E., 1998, PROBABILITY STAT ENG; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Woods K, 1995, J ARTIF INTELL RES, V3, P187; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; Zurada J, 1992, INTRO ARTIFICIAL NEU	95	35	38	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	OCT-NOV	2003	53	1-2					157	191		10.1023/A:1025623527461		35	Computer Science, Artificial Intelligence	Computer Science	718HH	WOS:000185138700005	
J	Chen, JN; Huang, HK; Tian, SF; Qu, YL				Chen, Jingnian; Huang, Houkuan; Tian, Shengfeng; Qu, Youli			Feature selection for text classification with Naive Bayes	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Text classification; Feature selection; Text preprocessing; Naive Bayes	NEAREST-NEIGHBOR; CATEGORIZATION	As an important preprocessing technology in text classification, feature selection can improve the scalability, efficiency and accuracy of a text classifier. In general, a good feature selection method should consider domain and algorithm characteristics. As the Naive Bayesian classifier is very simple and efficient and highly sensitive to feature selection, so the research of feature selection specially for it is significant. This paper presents two feature evaluation metrics for the Naive Bayesian classifier applied on multi-class text datasets: Multi-class Odds Ratio (MOR), and Class Discriminating Measure (CDM). Experiments of text classification with Naive Bayesian classifiers were carried out on two multi-class texts collections. As the results indicate, CDM and MOR gain obviously better selecting effect than other feature selection approaches. (C) 2008 Elsevier Ltd. All rights reserved.	[Chen, Jingnian; Huang, Houkuan; Tian, Shengfeng; Qu, Youli] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China; [Chen, Jingnian] Shandong Univ Finance, Dept Informat & Comp Sci, Jinan 250014, Shandong, Peoples R China	Chen, JN (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	jnchen06@163.com			National Natural Science Foundation of China [60503017, 60673089]	This research is supported by National Natural Science Foundation of China under Grant Nos. 60503017 and 60673089.	COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Frank E., 2006, P 10 EUR C PRINC PRA, P503; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; John G., 1994, P 11 INT C MACH LEAR, P121; Kim SB, 2006, IEEE T KNOWL DATA EN, V18, P1457; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; McCallum A, 1998, AAAI 98 WORKSH LEARN; Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Shang WQ, 2007, EXPERT SYST APPL, V33, P1, DOI 10.1016/j.eswa.2006.04.001; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Wiener E., 1995, P 4 ANN S DOC AN INF, P317; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; Yang Y., 1999, INFORMATION RETRIEVA, V1, P76; Yang Y., 1997, P 14 INT C MACH LEAR, P412; [周茜 Zhou Qian], 2004, [中文信息学报, Journal of Chinese Information Processing], V18, P17	18	34	40	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					5432	5435		10.1016/j.eswa.2008.06.054		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	410NJ	WOS:000263584100156	
J	McQuiggan, SW; Mott, BW; Lester, JC				McQuiggan, Scott W.; Mott, Bradford W.; Lester, James C.			Modeling self-efficacy in intelligent tutoring systems: An inductive approach	USER MODELING AND USER-ADAPTED INTERACTION			English	Article						affective user modeling; affective student modeling; self-efficacy; intelligent tutoring systems; inductive learning; human-computer interaction	DISCOVERY; COMPANION; EMOTIONS	Self-efficacy is an individual's belief about her ability to perform well in a given situation. Because self-efficacious students are effective learners, endowing intelligent tutoring systems with the ability to diagnose self-efficacy could lead to improved pedagogy. Self-efficacy is influenced by (and influences) affective state. Thus, physiological data might be used to predict a student's level of self-efficacy. This article investigates an inductive approach to automatically constructing models of self-efficacy that can be used at runtime to inform pedagogical decisions. It reports on two complementary empirical studies. In the first study, two families of self-efficacy models were induced: a static self-efficacy model, learned solely from pre-test (non-intrusively collected) data, and a dynamic self-efficacy model, learned from both pre-test data as well as runtime physiological data collected with a biofeedback apparatus. In the second empirical study, a similar experimental design was applied to an interactive narrative-centered learning environment. Self-efficacy models were induced from combinations of static and dynamic information, including pre-test data, physiological data, and observations of student behavior in the learning environment. The highest performing induced naive Bayes models correctly classified 85.2% of instances in the first empirical study and 82.1% of instances in the second empirical study. The highest performing decision tree models correctly classified 86.9% of instances in the first study and 87.3% of instances in the second study.	[McQuiggan, Scott W.; Lester, James C.] N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA; [Mott, Bradford W.] Emergent Game Technologies, Chapel Hill, NC USA	McQuiggan, SW (reprint author), N Carolina State Univ, Dept Comp Sci, Raleigh Campus Box 8206, Raleigh, NC 27695 USA.	swmcquig@ncsu.edu; bradford.mott@emergent.net; lester@ncsu.edu					Aimeur E, 2000, APPL ARTIF INTELL, V14, P465, DOI 10.1080/088395100403388; ALEVEN V, 2004, 7 INT C INT TUT SYST, P227; Allanson J, 2004, INTERACT COMPUT, V16, P857, DOI 10.1016/j.intcom.2004.08.001; ANDRE E, 2003, 10 INT C HUM COMP IN, P512; Bandura A., 2006, SELF EFFICACY BELIEF, P307; Bandura A, 1995, SELF EFFICACY CHANGI, P1, DOI 10.1017/CBO9780511527692.003; BANDURA A, 1986, SOCIAL FDN THOUGHT; Bandura Albert, 1997, SELF EFFICACY EXERCI; BATLINER A, 2008, J PERSONAL RES, V18; BAYLOR A, 2004, 7 INT C INT TUT SYST, P592; Beal C. R., 2005, WORKSH MOT AFF ED SO, P39; Beer JS, 2003, J PERS SOC PSYCHOL, V85, P594, DOI 10.1037/0022-3514.85.4.594; Bloom BS, 1984, EDUC RES, V13, P4, DOI 10.2307/1175554; Branigan E., 1992, NARRATIVE COMPREHENS; Bruner J., 1990, ACTS MEANING; BURLESON W, 2004, WORKSH SOC EM INT LE; Burleson W., 2006, THESIS MIT; CAVAZZA M, 2002, 1 INT JOINT C AUT AG, P318; CHAN TW, 1990, INTELLIGENT TUTORING SYSTEMS : AT THE CROSSROAD OF ARTIFICIAL INTELLIGENCE AND EDUCATION, P6; CHEN M, 2001, EXTENDED ABSTRACTS C, P281; Chou CY, 2003, COMPUT EDUC, V40, P255, DOI 10.1016/S0360-1315(02)00130-6; Clark R. E., 1999, COGNITION MULTMEDIA, P73; CONATI C, 2005, 10 INT C US MOD, P40; Conati C, 2002, APPL ARTIF INTELL, V16, P555, DOI 10.1080/08839510290030390; CORBETT AT, 2001, P CHI LETT, V3, P245; CSIKSZENTMIHALY.M, 1990, PSYCHOL OPTIMAL EXPE; Delcourt M. A. B, 1993, J RES DEV EDUC, V27, P35; DEVICENTE A, 2002, 6 INT C INT TUT SYST, P933; DMELLO S, 2008, J PERSONAL RES, V18; Ekman P., 1978, FACIAL ACTION CODING; FORBESRILEY K, 2008, J PERSONAL RES, V18; FRIJDA NH, 1996, EMOTIONS; Gerrig Richard J., 1993, EXPERIENCING NARRATI; Gilleade K., 2003, P HUM COMP INT INT, P370; Glaser R., 1992, Computer-Based Learning Environments and Problem Solving. Proceedings of the NATO Advanced Research Workshop; Goleman D., 1995, EMOTIONAL INTELLIGEN; GOODMAN B, 1998, INT J ARTIFICIAL INT, V9, P237; Graesser A., 2006, 28 ANN C COGN SCI SO, P285; Graham S, 1996, HDB ED PSYCHOL, P63; Gratch J., 2004, J COGNITIVE SYSTEMS, V5, P269, DOI DOI 10.1016/J.C0GSYS.2004.02.002; Han J., 2005, DATA MINING CONCEPTS; HANLEY JA, 1982, RADIOLOGY, V143, P29; Healey J. A., 2000, THESIS MIT; Johnson L., 2004, 7 INT C INT TUT SYST, P67; Kapoor A., 2005, MULTIMODAL AFFECT RE, P677; KIM Y, 2004, THESIS FLORIDA STATE; KIM Y, 2005, WORKSH MOT AFF ED SO, P9; LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037//0003-066X.50.5.372; Lazarus R. S., 1991, EMOTION ADAPTATION; Lepper M. R., 1993, COMPUTERS COGNITIVE, P75; Lester JC, 2000, EMBODIED CONVERSATIONAL AGENTS, P123; Litman DJ, 2006, SPEECH COMMUN, V48, P559, DOI 10.1016/j.specom.2005.09.008; Machado I., 2001, 10 INT C ART INT ED, P334; Malone T., 1987, APTITUDE LEARNING IN, P223; Malone T. W., 1981, COGNITIVE SCI, V4, P333, DOI 10.1207/s15516709cog0504_2; MCQUIGGAN S, 2006, 5 INT JOINT C AUT AG, P961; MCQUIGGAN S, 2006, 8 INT C INT TUT SYST, P565; MCQUIGGAN S, 2006, 2 C ART INT INT DIG, P60; Mekeig S., 1993, ELECTROENCEPHALOGRAP, V86, P23; Moreno R, 2004, INSTR SCI, V32, P99, DOI 10.1023/B:TRUC.0000021811.66966.1d; MOTA S, 2003, 1 IEEE WORKSH COMP V; MOTT B, 1999, P 1999 FALL S NARR I, P78; MOTT B, 2006, WORKSH AG BAS SYST H, P22; MOTT B, 2006, 8 INT C INT TUT SYST, P675; MOTT B, 2006, 5 INT C AUT AG MULT, P977; NAU D, 2001, 17 INT JOINT C ART I, P999; Ortony A, 1988, COGNITIVE STRUCTURE; PADILLA M, 2000, SCI EXPLORER CELLS H; Paiva A, 2005, APPL ARTIF INTELL, V19, P235, DOI 10.1080/08839510590910165; PAJARES F, 1995, CONTEMP EDUC PSYCHOL, V20, P426, DOI 10.1006/ceps.1995.1029; Partala T, 2003, INT J HUM-COMPUT ST, V59, P185, DOI 10.1016/S1071-5819(03)00017-X; PICARD R, 2001, IEEE T PATTERN ANAL, V23, P1185; Picard R. W., 1997, AFFECTIVE COMPUTING; POPE AT, 1995, BIOL PSYCHOL, V40, P187, DOI 10.1016/0301-0511(95)05116-3; PORAYSKAPOMSTA K, 2008, J PERSONAL RES, V18; PORAYSKAPOMSTA K, 2004, 7 INT C INT TUT SYST, P77; Prendinger H, 2005, INT J HUM-COMPUT ST, V62, P231, DOI 10.1016/j.ijhcs.2004.11.009; Prendinger H, 2005, APPL ARTIF INTELL, V19, P267, DOI 10.1080/08839510590910174; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RIEDL M, 2005, WORKSH NARR LEARN EN, P23; RIEDL M, 2004, 3 INT JOINT C AUT AG, P186; Russell S., 2003, ARTIFICIAL INTELLIGE; Schunk D. H., 2002, DEV ACHIEVEMENT MOTI, P15, DOI 10.1016/B978-012750053-9/50003-6; SCHUNK DH, 1987, J READING BEHAV, V19, P285; SCHUNK DH, 1987, REV EDUC RES, V57, P149; SI M, 2005, 4 INT C AUT AG MULT, P21; Smith C. A., 1990, HDB PERSONALITY THEO, P609; Verwey WB, 1996, J EXP PSYCHOL-APPL, V2, P270, DOI 10.1037/1076-898X.2.3.270; Wells C. G., 1986, MEANING MAKERS CHILD; Wiederhold B. K., 2003, CYBERPSYCHOLOGY MIND, P175; Witten IH, 2005, DATA MINING PRACTICA; YANNAKAKIS G, 2008, J PERSONAL RES, V18; Zachos P, 2000, J RES SCI TEACH, V37, P938, DOI 10.1002/1098-2736(200011)37:9<938::AID-TEA5>3.0.CO;2-S; Zimmerman BJ, 2000, CONTEMP EDUC PSYCHOL, V25, P82, DOI 10.1006/ceps.1999.1016	94	34	34	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-1868			USER MODEL USER-ADAP	User Model. User-Adapt. Interact.	FEB	2008	18	1-2					81	123		10.1007/s11257-007-9040-y		43	Computer Science, Cybernetics	Computer Science	255SP	WOS:000252678000004	
J	Katsikopoulos, KV; Martignon, L				Katsikopoulos, Konstantinos V.; Martignon, Laura			Naive heuristics for paired comparisons: Some results on their relative accuracy	JOURNAL OF MATHEMATICAL PSYCHOLOGY			English	Article						paired comparison; cue; tallying; lexicographic; Take The Best; Minimalist; naive Bayes; social choice; condorcet jury theorems	DECISION-MAKING; PROBABILISTIC INFERENCE; THE-BEST; MODELS; FRUGAL; CHOICE; INFORMATION	We study three heuristics for paired comparisons based on binary cues, which are all naive in that they ignore possible dependencies between cues, but take different approaches: linear (tallying) and lexicographic (Take The Best, Minimalist). There is empirical evidence on the heuristics' descriptive adequacy and some first results on their accuracy. We present new analytical results on their relative accuracy. When cues are independent given the values of the objects on the criterion, there exists a linear decision rule, equivalent to naive Bayes, which is optimal; we use this result to characterize the optimality of Take The Best and tallying. Also, tallying and Take The Best are more accurate than Minimalist. When cues are dependent and the number of cues and objects is psychologically plausible, Take The Best tends to be more accurate than tallying, but it is also possible that tallying, and Minimalist, are more accurate than Take The Best. (c) 2006 Elsevier Inc. All rights reserved.	Max Planck Inst Human Dev, Ctr Adapt Behav & Cognit, D-14195 Berlin, Germany; Pedagog Univ Ludwigsburg, Inst Math, D-71634 Ludwigsburg, Germany	Katsikopoulos, KV (reprint author), Max Planck Inst Human Dev, Ctr Adapt Behav & Cognit, Lentzeallee 94, D-14195 Berlin, Germany.	katsikop@mpib-berlin.mpg.de	Katsikopoulos, Konstantinos/B-6356-2012				BAUCELLS M, 2005, UNPUB CUMULATIVE DOM; Ben-Yashar R, 2000, SOC CHOICE WELFARE, V17, P189, DOI 10.1007/s003550050014; Broder A, 2000, J EXP PSYCHOL LEARN, V26, P1332, DOI 10.1037/0278-7393.26.5.1332; Broder A, 2003, J EXP PSYCHOL GEN, V132, P277, DOI 10.1037/0096-3445.132.2.277; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; DAWES RM, 1974, PSYCHOL BULL, V81, P95, DOI 10.1037/h0037613; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; EINHORN HJ, 1975, ORGAN BEHAV HUM PERF, V13, P171, DOI 10.1016/0030-5073(75)90044-6; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GIGERENZER G, 2002, HEURISTICS BIASES PS, P559; Gigerenzer G, 1996, PSYCHOL REV, V103, P650, DOI 10.1037//0033-295X.103.4.650; GROFMAN B, 1986, INFORMATION POOLING, P93; Gulliksen H., 1950, THEORY MENTAL TESTS; HASHER L, 1984, AM PSYCHOL, V39, P1372, DOI 10.1037/0003-066X.39.12.1372; Hogarth RM, 2005, J MATH PSYCHOL, V49, P115, DOI 10.1016/j.jmp.2005.01.001; Hogarth RM, 2005, MANAGE SCI, V51, P1860, DOI 10.1287/mnsc.1050.0448; KATSIKOPOULOS KV, 2006, IEEE T SYSTEMS MAN C; KURZMILCKE E, 2002, MODEL BASED REASONIN, P127; Lee MD, 2004, PSYCHON B REV, V11, P343, DOI 10.3758/BF03196581; Martignon L, 2002, THEOR DECIS, V52, P29, DOI 10.1023/A:1015516217425; Martignon L., 2003, THINKING PSYCHOL PER, P189; MARTIGNON L, 2003, EMERGING PERSPECTIVE, P108; Newell BR, 2003, ORGAN BEHAV HUM DEC, V91, P82, DOI 10.1016/S0749-5978(02)00525-3; Newell BR, 2003, J EXP PSYCHOL LEARN, V29, P53, DOI 10.1037/0278-7393.29.1.53; NITZAN S, 1982, INT ECON REV, V23, P289, DOI 10.2307/2526438; PAYNE JW, 1993, ADPATIVE DECISION MA; Rakow T, 2004, THINK REASONING, V10, P1, DOI [10.1080/13546780342000016, 10.1080/134546780342000016]; Rieskamp J., 1999, SIMPLE HEURISTICS MA, P141; RIESKAMP J, 2004, UNPUB INFORM REDUNDA; TVERSKY A, 1969, PSYCHOL REV, V76, P31, DOI 10.1037/h0026750	30	34	34	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-2496			J MATH PSYCHOL	J. Math. Psychol.	OCT	2006	50	5					488	494		10.1016/j.jmp.2006.06.001		7	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Psychology, Mathematical	Mathematics; Mathematical Methods In Social Sciences; Psychology	087PB	WOS:000240753200005	
J	Farhangfar, A; Kurgan, L; Dy, J				Farhangfar, Alireza; Kurgan, Lukasz; Dy, Jennifer			Impact of imputation of missing values on classification error for discrete data	PATTERN RECOGNITION			English	Article						missing values; classification; imputation of missing values; single imputation; multiple imputations	DATABASES	Numerous industrial and research databases include missing values. It is not uncommon to encounter databases that have LIP to a half of the entries missing, making it very difficult to mine them using data analysis methods that can work only with complete data. A common way of dealing with this problem is to impute (fill-in) the missing values. This paper evaluates how the choice of different imputation methods affects the performance of classifiers that are subsequently used with the imputed data. The experiments here focus on discrete data. This paper studies the effect of missing data imputation using five single imputation methods (a mean method, a Hot deck method, a Naive-Bayes method, and the latter two methods with a recently proposed imputation framework) and one multiple imputation method (a polytomous regression based method) on classification accuracy for six popular classifiers (RIPPER, C4.5, K-nearest-neighbor, support vector machine with polynomial and RBF kernels, and Naive-Bayes) on 15 datasets. This experimental study shows that imputation with the tested methods on average improves classification accuracy when compared to classification without imputation. Although the results show that there is no universally best imputation method, Naive-Bayes imputation is shown to give the best results for the RIPPER classifier for datasets with high amount (i.e., 40% and 50%) of missing data, polytomous regression imputation is shown to be the best for support vector machine classifier with polynomial kernel, and the application of the imputation framework is shown to be superior for the support vector machine with RBF kernel and K-nearest-neighbor. The analysis of the quality of the imputation with respect to varying amounts of missing data (i.e., between 5% and 50%) shows that all imputation methods, except for the mean imputation, improve classification error for data with more than 10% of missing data. Finally, some classifiers such as C4.5 and Naive-Bayes were found to be missing data resistant, i.e., they can Produce accurate classification in the presence of missing data, while other classifiers such as K-nearest-neighbor, SVMs and RIPPER benefit from the imputation. (C) 2008 Elsevier Ltd. All rights reserved.	[Kurgan, Lukasz] Univ Alberta, ECERF, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada; [Farhangfar, Alireza] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2V4, Canada; [Dy, Jennifer] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA	Kurgan, L (reprint author), Univ Alberta, ECERF, Dept Elect & Comp Engn, 9107-116 St, Edmonton, AB T6G 2V4, Canada.	farhang@cs.ualberta.ca; lkurgan@ece.ualberta.ca; jdy@ece.neu.edu	Kurgan, Lukasz/B-5721-2009	Kurgan, Lukasz/0000-0002-7749-0314			Alzola C, 1999, INTRO S PLUS HMISC D; Acuna E, 2004, ST CLASS DAT ANAL, P639; Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI 10.1080/08839510390219309; BELLO AL, 1995, COMPUT STAT DATA AN, V20, P45, DOI 10.1016/0167-9473(94)00024-D; BUUREN S, 1999, 99045 TNOVGZPG; BUUREN S, 1994, P 7 INT WORK C SCI S, P74; CASELLA G, 1992, AM STAT, V46, P167, DOI 10.2307/2685208; Chan KL, 2003, NEURAL COMPUT, V15, P1991, DOI 10.1162/08997660360675116; Chen HY, 1999, BIOMETRIKA, V86, P1, DOI 10.1093/biomet/86.1.1; Cios K., 1998, DATA MINING METHODS; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cohen WW, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P709; Cristianini N., 2000, INTRO SUPPORT VECTOR; DIXON JK, 1979, IEEE T SYST MAN CYB, V9, P617, DOI 10.1109/TSMC.1979.4310090; Duda R., 1973, PATTERN CLASSIFICATI; Farhangfar A, 2007, IEEE T SYST MAN CY A, V37, P692, DOI 10.1109/TSMCA.2007.902631; Farhangfar A, 2004, PROC SPIE, V5421, P172, DOI 10.1117/12.542509; Feelders A, 1999, LECT NOTES ARTIF INT, V1704, P329; Ghahramani Z., 1997, Computational learning theory and natural learning systems. Vol.IV: making learning systems practical; Grzymala-Busse J. W., 2000, P 2 INT C ROUGH SETS, P340; Grzymala-Busse J.W, 1992, HDB APPL ADV ROUGH S, P3; Hettich S., 1999, UCI KDD ARCH; Kohav R., 1996, P 13 INT C MACH LEAR, P275; KURGAN L, 2005, NEXT GENERATION DATA, P415; Lakshminarayan K, 1999, APPL INTELL, V11, P259, DOI 10.1023/A:1008334909089; Li KH, 1988, J STATISTICAL COMPUT, V30, P57, DOI 10.1080/00949658808811085; Little RJA, 1987, STAT ANAL MISSING DA; Mundfrom D. J., 1998, MULTIPLE LINEAR REGR, V25, P13; Newman DJ, 1998, UCI REPOSITORY MACHI; Oh H. L., 1983, INCOMPLETE DATA SAMP, V2, P143; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RUBIN DB, 1977, J AM STAT ASSOC, V72, P538, DOI 10.2307/2286214; RUBIN DB, 1996, J AM STAT ASSOC, V91, P473, DOI DOI 10.2307/2291635; Rubin DB, 1978, P SURV RES METH SECT, P20; RUBIN DB, 1990, P STAT COMP SECT AM; SANDE G, 1983, HOT DECK IMPUTATION, V3; Shafer J., 1997, ANAL INCOMPLETE MULT; Snedecor G. W., 1989, STAT METHODS; TANG N, 2004, P IEEE WIC ACM INT J, P124; Vapnik V., 1995, NATURE STAT LEARNING; Witten IH, 2005, DATA MINING PRACTICA; ZHANG W, 2000, P 16 ICDE, P310	43	33	34	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	DEC	2008	41	12					3692	3705		10.1016/j.patcog.2008.05.019		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	353EC	WOS:000259547900017	
J	Sun, LL; Shenoy, PP				Sun, Lili; Shenoy, Prakash P.			Using Bayesian networks for bankruptcy prediction: Some methodological issues	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article						bankruptcy prediction; Bayesian networks; naive Bayes; variable selection; discretization of continuous variables	NEURAL NETWORKS; DISCRIMINANT-ANALYSIS; FINANCIAL RATIOS; ROUGH SETS; APPROXIMATIONS; MODELS; FAILURE	This study provides operational guidance for building naive Bayes Bayesian network (BN) models for bankruptcy prediction. First, we suggest a heuristic method that guides the selection of bankruptcy predictors. Based on the correlations and partial correlations among variables, the method aims at eliminating redundant and less relevant variables. A naive Bayes model is developed using the proposed heuristic method and is found to perform well based on a 10-fold validation analysis. The developed naive Bayes model consists of eight first-order variables, six of which are continuous. We also provide guidance on building a cascaded model by selecting second-order variables to compensate for missing values of first-order variables. Second, we analyze whether the number of states into which the six continuous variables are discretized has an impact on the model's performance. Our results show that the model's performance is the best when the number of states for discretization is either two or three. Starting from four states, the performance starts to deteriorate, probably due to over-fitting. Finally, we experiment whether modeling continuous variables with continuous distributions instead of discretizing them can improve the model's performance. Our finding suggests that this is not true. One possible reason is that continuous distributions tested by the study do not represent well the underlying distributions of empirical data. Finally, the results of this study could also be applicable to business decision-making contexts other than bankruptcy prediction. (c) 2006 Elsevier B.V. All rights reserved.	Rutgers State Univ, Newark, NJ 07102 USA; Univ Kansas, Sch Business, Lawrence, KS 66045 USA	Sun, LL (reprint author), Rutgers State Univ, 180 Univ Ave, Newark, NJ 07102 USA.	sunlili@rbsmail.rutgers.edu					ALTMAN E, 1977, J BANK FINANC, V10, P29; ALTMAN EI, 1994, J BANK FINANC, V18, P505, DOI 10.1016/0378-4266(94)90007-8; ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; Anderson RD, 2004, DECISION SCI, V35, P665, DOI 10.1111/j.1540-5915.2004.02575.x; Back B, 1996, EXPERT SYST APPL, V11, P407, DOI 10.1016/S0957-4174(96)00055-3; Barth ME, 1998, J ACCOUNT ECON, V25, P1, DOI 10.1016/S0165-4101(98)00017-2; BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171; Begley J., 1996, REV ACCOUNT STUD, V1, P267, DOI 10.1007/BF00570833; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; EMERY GW, 1982, J ACCOUNTING RES, V20, P290, DOI 10.2307/2490741; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1023/A:1022638503176; Hall M.A., 1999, THESIS U WAIKATO; HOPWOOD W, 1989, ACCOUNT REV, V64, P28; Hopwood W. S., 1994, CONTEMP ACCOUNT RES, V10, P409; Jones F. L., 1987, J ACCOUNTING LIT, V6, P131; Karels G., 1987, J BUSINESS FINANCE A, V14, P573, DOI 10.1111/j.1468-5957.1987.tb00113.x; KEEFER DL, 1992, CERTAINTY EQUIVALENT; KEEFER DL, 1994, MANAGE SCI, V40, P760, DOI 10.1287/mnsc.40.6.760; KEEFER DL, 1983, MANAGE SCI, V29, P595, DOI 10.1287/mnsc.29.5.595; Koller D., 1996, P 13 INT C MACH LEAR, P284; Kononenko I., 1990, CURRENT TRENDS KNOWL; Kotsiantis S., 2005, 2 INT C ENT SYST ACC; Langley P., 1992, P 10 NAT C ART INT, P223; McKee TE, 2002, EUR J OPER RES, V138, P436, DOI 10.1016/S0377-2217(01)00130-8; McKee TE, 2003, J FORECASTING, V22, P569, DOI 10.1002/for.875; McKee TE, 2000, J FORECASTING, V19, P219, DOI 10.1002/(SICI)1099-131X(200004)19:3<219::AID-FOR752>3.3.CO;2-A; MCKEE TE, 1998, 7 ANN RES WORKSH ART; MILLER AC, 1983, MANAGE SCI, V29, P352, DOI 10.1287/mnsc.29.3.352; Ohlson J., 1980, J ACCOUNT RES, V19, P109; Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54; Pearl J., 1988, PROBABILISTIC REASON; Poland W. B., 1993, Uncertainty in Artificial Intelligence. Proceedings of the Ninth Conference (1993); Sarkar S, 2001, MANAGE SCI, V47, P1457, DOI 10.1287/mnsc.47.11.1457.10253; SENETTI JT, 1995, AUDITING-J PRACT TH, V13, P193; Shumway T, 2001, J BUS, V74, P101, DOI 10.1086/209665; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918; VOMLEL J, 2003, P 6 WORKSH UNC PROC, P291; ZMIJEWSKI ME, 1984, J ACCOUNTING RES, V22, P59, DOI 10.2307/2490859	39	33	36	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217			EUR J OPER RES	Eur. J. Oper. Res.	JUL 16	2007	180	2					738	753		10.1016/j.ejor.2006.04.019		16	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	143WY	WOS:000244758300017	
J	Liu, ZP; Wu, LY; Wang, Y; Zhang, XS; Chen, LN				Liu, Zhi-Ping; Wu, Ling-Yun; Wang, Yong; Zhang, Xiang-Sun; Chen, Luonan			Prediction of protein-RNA binding sites by a random forest method with combined features	BIOINFORMATICS			English	Article							STRUCTURAL-ANALYSIS; PATTERNS; SEQUENCE; RESIDUE; INTERFACE; DATABASE	Motivation: Protein-RNA interactions play a key role in a number of biological processes, such as protein synthesis, mRNA processing, mRNA assembly, ribosome function and eukaryotic spliceosomes. As a result, a reliable identification of RNA binding site of a protein is important for functional annotation and site-directed mutagenesis. Accumulated data of experimental protein-RNA interactions reveal that a RNA binding residue with different neighbor amino acids often exhibits different preferences for its RNA partners, which in turn can be assessed by the interacting interdependence of the amino acid fragment and RNA nucleotide. Results: In this work, we propose a novel classification method to identify the RNA binding sites in proteins by combining a new interacting feature (interaction propensity) with other sequence- and structure-based features. Specifically, the interaction propensity represents a binding specificity of a protein residue to the interacting RNA nucleotide by considering its two-side neighborhood in a protein residue triplet. The sequence as well as the structure-based features of the residues are combined together to discriminate the interaction propensity of amino acids with RNA. We predict RNA interacting residues in proteins by implementing a well-built random forest classifier. The experiments show that our method is able to detect the annotated protein-RNA interaction sites in a high accuracy. Our method achieves an accuracy of 84.5%, F-measure of 0.85 and AUC of 0.92 prediction of the RNA binding residues for a dataset containing 205 non-homologous RNA binding proteins, and also outperforms several existing RNA binding residue predictors, such as RNABindR, BindN, RNAProB and PPRint, and some alternative machine learning methods, such as support vector machine, naive Bayes and neural network in the comparison study. Furthermore, we provide some biological insights into the roles of sequences and structures in protein-RNA interactions by both evaluating the importance of features for their contributions in predictive accuracy and analyzing the binding patterns of interacting residues.	[Liu, Zhi-Ping; Chen, Luonan] Chinese Acad Sci, Shanghai Inst Biol Sci, SIBS Novo Nordisk Translat Res Ctr PreDiabet, Key Lab Syst Biol, Shanghai 200031, Peoples R China; [Wu, Ling-Yun; Wang, Yong; Zhang, Xiang-Sun] Chinese Acad Sci, Acad Math & Syst Sci, Beijing 100190, Peoples R China	Chen, LN (reprint author), Chinese Acad Sci, Shanghai Inst Biol Sci, SIBS Novo Nordisk Translat Res Ctr PreDiabet, Key Lab Syst Biol, Shanghai 200031, Peoples R China.	lnchen@sibs.ac.cn	Wu, Ling-Yun/C-4222-2008; Liu, Zhi-Ping/C-9846-2010; Wang, Yong/J-9193-2012		Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences [2009CSP002]; National Natural Science Foundation of China [10631070, 60873205]; Ministry of Science and Technology of China [2006CB503905]	The Chief Scientist Program of Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences (grant no. 2009CSP002); National Natural Science Foundation of China (grant no. 10631070 and 60873205); Ministry of Science and Technology of China (grant no. 2006CB503905).	Allers J, 2001, J MOL BIOL, V311, P75, DOI 10.1006/jmbi.2001.4857; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; BERMAN HM, 1992, BIOPHYS J, V63, P751; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen YC, 2008, NUCLEIC ACIDS RES, V36, DOI 10.1093/nar/gkn008; Cheng CW, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S12-S6; Doherty EA, 2001, NAT STRUCT BIOL, V8, P339, DOI 10.1038/86221; Ellis JJ, 2007, PROTEINS, V66, P903, DOI 10.1002/prot.21211; Glisovic T, 2008, FEBS LETT, V582, P1977, DOI 10.1016/j.febslet.2008.03.004; Hall KB, 2002, CURR OPIN STRUC BIOL, V12, P283, DOI 10.1016/S0959-440X(02)00323-8; Jeong Euna, 2004, Genome Inform, V15, P105; Jones S, 2001, NUCLEIC ACIDS RES, V29, P943, DOI 10.1093/nar/29.4.943; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kim H, 2003, FEBS LETT, V552, P231, DOI 10.1016/S0014-5793(03)00930-X; Kim OTP, 2006, NUCLEIC ACIDS RES, V34, P6450, DOI 10.1093/nar/gkl819; Kumar M, 2008, PROTEINS, V71, P189, DOI 10.1002/prot.21677; Li N, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-553; Liaw A, 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Liu ZP, 2008, AMINO ACIDS, V35, P627, DOI 10.1007/s00726-008-0088-8; Lunde BM, 2007, NAT REV MOL CELL BIO, V8, P479, DOI 10.1038/nrm2178; Morozova N, 2006, BIOINFORMATICS, V22, P2746, DOI 10.1093/bioinformatics/btl470; Nelson DL, 2004, LEHNINGER PRINCIPLES, P75; ROST B, 1994, PROTEINS, V20, P216, DOI 10.1002/prot.340200303; Shulman-Peleg A, 2008, J MOL BIOL, V379, P299, DOI 10.1016/j.jmb.2008.03.043; Spriggs RV, 2009, BIOINFORMATICS, V25, P1492, DOI 10.1093/bioinformatics/btp257; SWEET RM, 1983, J MOL BIOL, V171, P479, DOI 10.1016/0022-2836(83)90041-4; Terribilini M, 2007, NUCLEIC ACIDS RES, V35, pW578, DOI 10.1093/nar/gkm294; Terribilini M, 2006, RNA, V12, P1450, DOI 10.1261/rna.2197306; Bairoch A, 2008, NUCLEIC ACIDS RES, V36, pD190, DOI 10.1093/nar/gkm895; Wang LJ, 2006, NUCLEIC ACIDS RES, V34, pW243, DOI 10.1093/nar/gkl298; Wang L, 2007, J BIOMOL NMR, V39, P247, DOI 10.1007/s10858-007-9193-3; Weigt M, 2009, P NATL ACAD SCI USA, V106, P67, DOI 10.1073/pnas.0805923106	33	32	32	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JUL 1	2010	26	13					1616	1622		10.1093/bioinformatics/btq253		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	613GN	WOS:000278967500006	
J	Consonni, R; Cagliani, LR; Benevelli, F; Spraul, M; Humpfer, E; Stocchero, M				Consonni, R.; Cagliani, L. R.; Benevelli, F.; Spraul, M.; Humpfer, E.; Stocchero, M.			NMR and Chemometric methods: A powerful combination for characterization of Balsamic and Traditional Balsamic Vinegar of Modena	ANALYTICA CHIMICA ACTA			English	Article						Traditional Balsamic Vinegar of Modena; principal component analysis; Projection to Latent Structures; Discriminant Analysis; Naive Bayes; H-1 NMR; vinegar; ageing process	ORGANIC-ACIDS; H-1-NMR SPECTROSCOPY; REGGIO-EMILIA; ACETIC-ACID; OLIVE OIL; DESIGN; HPLC; MS; QUANTIFICATION; IDENTIFICATION	This work presents the capability of NMR spectroscopy combined with Chemometrics in predicting the ageing of Balsamic and Traditional Balsamic Vinegar of Modena. The need of an analytical method is an important requirement for both research oriented and commercial evaluation of these very valuable products. H-1 NMR spectroscopy, based on the advantage of rapid sample analysis without any manipulation or derivatization, is here proposed as a valid tool to describe Balsamic and Traditional Balsamic Vinegar of Modena. For this purpose, 72 reliable samples, were divided into three different groups according to their ageing process: young (<12 years), old (>12 and <25 years) and extra old (>25 years). Hierarchical Projection to Latent Structures Discriminant Analysis (PLS-DA) allowed us to characterize the ageing process. Variables showing the largest VIP (Variable Importance in the Projection) were extracted from PLS-DA model, thus shedding lights onto the role played by specific compounds in this complex ageing process. Two robust classification models, were built by PLS-DA and Naive Bayes classifier and compared to prove the accuracy of the representation on both training and test sets. The predictions obtained for 41 "unknown" vinegar samples with these both methods gave more than 80% agreement among them. (c) 2008 Published by Elsevier B.V.	[Consonni, R.; Cagliani, L. R.] CNR, Ist Studio Macromol, Lab NMR, I-20133 Milan, Italy; [Benevelli, F.] Bruker Biospin srl, I-20133 Milan, Italy; [Spraul, M.; Humpfer, E.] Bruker Biospin GmbH, Karlsruhe, Germany; [Stocchero, M.] S IN Soluzioni Informat, I-36100 Vicenza, Italy	Consonni, R (reprint author), CNR, Ist Studio Macromol, Lab NMR, Bassini 15, I-20133 Milan, Italy.	roberto.consonni@ismac.cnr.it	Consonni, Roberto/G-5257-2013				Almeida C, 2006, J AGR FOOD CHEM, V54, P700, DOI 10.1021/jf0526947; Caligiani A, 2007, ANAL CHIM ACTA, V585, P110, DOI 10.1016/j.aca.2006.12.016; Carlavilla D, 2006, ELECTROPHORESIS, V27, P2551, DOI 10.1002/elps.200500909; Chiavaro E, 1998, ITAL J FOOD SCI, V10, P329; Cocchi M, 2002, J AGR FOOD CHEM, V50, P5255, DOI 10.1021/jf020155l; Cocchi M, 2006, TALANTA, V69, P1166, DOI 10.1016/j.talanta.2005.12.032; COHEN J, 1960, ED PHYSL MEAS, P20; Consonni R, 2004, J AGR FOOD CHEM, V52, P3446, DOI 10.1021/jf0355147; Consonni R, 2007, TALANTA, V73, P332, DOI 10.1016/j.talanta.2007.03.045; Dais P, 2007, J AGR FOOD CHEM, V55, P577, DOI 10.1021/jf061601y; Del Signore A, 2000, ITAL J FOOD SCI, V12, P317; Duarte I, 2002, J AGR FOOD CHEM, V50, P2475, DOI 10.1021/jf011345j; Eriksson L., 2002, MULTI MEGAVARIATE DA; Goldber D. E., 1988, Machine Learning, V3, DOI 10.1023/A:1022602019183; Gullo M, 2006, INT J FOOD MICROBIOL, V106, P209, DOI 10.1016/j.ijfoodmicro.2005.06.024; Hermann A, 2001, EUR FOOD RES TECHNOL, V212, P683, DOI 10.1007/s002170100308; Langseth H, 2006, MACH LEARN, V63, P135, DOI 10.1007/s10994-006-6136-2; Liang YZ, 2001, CHEMOMETR INTELL LAB, V58, P43, DOI 10.1016/S0169-7439(01)00139-3; MARENGO E, 1992, CHEMOMETR INTELL LAB, V16, P37, DOI 10.1016/0169-7439(92)80076-G; Masino F, 2005, FOOD CHEM, V92, P673, DOI 10.1016/j.foodchem.2004.08.029; Ogrinc N, 2003, ANAL BIOANAL CHEM, V376, P424, DOI 10.1007/s00216-003-1804-6; Olsson IM, 2004, CHEMOMETR INTELL LAB, V73, P37, DOI 10.1016/j.chemolab.2004.04.001; Plessi M, 2006, J FOOD COMPOS ANAL, V19, P49, DOI 10.1016/J.JFCA.2004.10.008; REMAUD G, 1992, FRESEN J ANAL CHEM, V342, P457, DOI 10.1007/BF00322207; Saiz-Abajo MJ, 2005, ANAL CHIM ACTA, V528, P63, DOI 10.1016/j.aca.2004.06.027; Sanarico D, 2003, J LIQ CHROMATOGR R T, V26, P2177, DOI 10.1081/JLC-120022402; Solieri L, 2006, J APPL MICROBIOL, V101, P63, DOI 10.1111/j.1365-2672.2006.02906.x; Theobald A, 1998, J AGR FOOD CHEM, V46, P1850, DOI 10.1021/jf970912t; Tiziani S, 2006, J AGR FOOD CHEM, V54, P6094, DOI 10.1021/jf061154m; Wold S., 1993, ESCOM SCI LEIDEN, P523; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1; Wold S, 1996, J CHEMOMETR, V10, P463	32	32	33	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670			ANAL CHIM ACTA	Anal. Chim. Acta	MAR 17	2008	611	1					31	40		10.1016/j.aca.2008.01.065		10	Chemistry, Analytical	Chemistry	285KS	WOS:000254776300003	
J	Yager, RR				Yager, RR			An extension of the naive Bayesian classifier	INFORMATION SCIENCES			English	Article						OWA operators; classification; naive Bayes classifier; t-norms	OPERATORS	Our objective here is to provide an extension of the naive Bayesian classifier in a manner that gives LIS more parameters for matching data. We first describe the naive Bayesian classifier, and then discuss the ordered weighted averaging (OWA) aggregation operators. We introduce a new class of OWA operators which are based on a combining the OWA operators with t-norm's operators. We show that the naive Bayesian classifier can seen as a special case of this. We use this to Suggest an extended version of the naive Bayesian classifier which involves a weighted summation of products of the probabilities. An algorithm is suggested to obtain the weights associated with this extended naive Bayesian classifier. (C) 2005 Elsevier Inc. All rights reserved.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, 715 N Ave, New Rochelle, NY 10801 USA.	ryager@iona.edu	Yager, Ronald/A-2960-2013				Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R.O., 2001, PATTERN CLASSIFICATI; Filev D, 1998, FUZZY SET SYST, V94, P157, DOI 10.1016/S0165-0114(96)00254-0; FILEV D, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P468, DOI 10.1109/FUZZY.1994.343740; Han J., 2001, DATA MINING CONCEPTS; Haykin S., 1994, NEURAL NETWORKS COMP; Klement E.P., 2000, TRIANGULAR NORMS; O'Hagan M, 1988, P 22 ANN IEEE AS C S, P681; Torra V., 1999, MATHWARE SOFT COMPUT, V6, P249; Yager R. R., 1997, ORDERED WEIGHTED AVE; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; YAGER RR, 2004, MII2406 ION COLL; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; ZARUDA JM, 1992, INTRO ARTIFICIAL NEU	15	32	35	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	MAR 6	2006	176	5					577	588		10.1016/j.ins.2004.12.006		12	Computer Science, Information Systems	Computer Science	007CB	WOS:000234944200006	
J	Ren, L; Patrick, A; Efros, AA; Hodgins, JK; Rehg, JM				Ren, L; Patrick, A; Efros, AA; Hodgins, JK; Rehg, JM			A data-driven approach to quantifying natural human motion	ACM TRANSACTIONS ON GRAPHICS			English	Article; Proceedings Paper	ACM SIGGRAPH 2005 Conference	JUL 31-AUG 04, 2005	Los Angeles, CA	ACM SIGGRAPH		human animation; natural motion; machine learning; motion evaluation	BALLISTIC MOTION; INTERPOLATION; ANIMATION	In this paper, we investigate whether it is possible to develop a measure that quantifies the naturalness of human motion (as defined by a large database). Such a measure might prove useful in verifying that a motion editing operation had not destroyed the naturalness of a motion capture clip or that a synthetic motion transition was within the space of those seen in natural human motion. We explore the performance of mixture of Gaussians (MoG), hidden Markov models (HMM), and switching linear dynamic systems (SLDS) on this problem. We use each of these statistical models alone and as part of an ensemble of smaller statistical models. We also implement a Naive Bayes (NB) model for a baseline comparison. We test these techniques on motion capture data held out from a database, keyframed motions, edited motions, motions with noise added, and synthetic motion transitions. We present the results as receiver operating characteristic (ROC) curves and compare the results to the judgments made by subjects in a user study.	Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; Georgia Inst Technol, Atlanta, GA 30332 USA	Ren, L (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	liuren@cs.cmu.edu; apatrick@cc.gatech.edu; efros@cs.cmu.edu; jkh@cs.cmu.edu; rehg@cc.gatech.edu					Arikan O, 2002, ACM T GRAPHIC, V21, P483; ASSA J, 2005, ACM T GRAPHICS, V24; BRAND M, 2000, P SIGGRAPH 2000, P183, DOI 10.1145/344779.344865; COLE Ronald A., 1996, SURVEY STATE ART HUM; FARID H, 2003, IEEE WORKSH STAT AN; Gleicher M, 2001, GRAPH MODELS, V63, P107, DOI 10.1006/gmod.2001.0549; HAMID R, 2005, IN PRESS IEEE C COMP; Hara K, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P697, DOI 10.1109/NNSP.2002.1030081; Harrison J, 2004, ACM T GRAPHIC, V23, P569, DOI 10.1145/1015706.1015761; Ikemoto L., 2004, P 2004 ACM SIGGRAPH, P99, DOI 10.1145/1028523.1028537; Kovar L, 2002, ACM T GRAPHIC, V21, P473; Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760; Lee JH, 2002, ACM T GRAPHIC, V21, P491; Lerner U.N., 2002, THESIS STANFORD U; Li Y, 2002, ACM T GRAPHIC, V21, P465; O'Sullivan C, 2003, ACM T GRAPHIC, V22, P527, DOI 10.1145/882262.882303; Pavlovic V., 2000, P ADV NEUR INF PROC, P981; PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392; POLLICK F, 2003, P 3 INT WORKSH EP RO, V101, P107; Rabiner L., 1993, FUNDAMENTALS SPEECH; Reitsma PSA, 2003, ACM T GRAPHIC, V22, P537, DOI 10.1145/882262.882304; Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559; Sulejmanpasic A, 2005, ACM T GRAPHIC, V24, P165, DOI 10.1145/1037957.1037966; Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2; Van Trees H. L., 1968, DETECTION ESTIMATION, V1; Wang J., 2003, P 2003 ACM SIGGRAPH, P232; Wang J., 2004, P ACM SIGGRAPH EUR S, P335, DOI 10.1145/1028523.1028568; Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968; Wu Y. N., 2001, INT C COMP VIS VANC, V2, P439; ZHONG H, 2004, IEEE C COMP VIS PATT, V2, P819	30	32	36	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0730-0301			ACM T GRAPHIC	ACM Trans. Graph.	JUL	2005	24	3					1090	1097		10.1145/1073204.1073316		8	Computer Science, Software Engineering	Computer Science	955KB	WOS:000231223700092	
J	Granitto, PM; Verdes, PF; Ceccatto, HA				Granitto, PM; Verdes, PF; Ceccatto, HA			Large-scale investigation of weed seed identification by machine vision	COMPUTERS AND ELECTRONICS IN AGRICULTURE			English	Article						machine vision; seed identification; classification; artificial neural networks	DIGITAL IMAGE-ANALYSIS; GRAIN COLOR ANALYSIS; FEATURE-SELECTION; WHEAT CLASS; DISCRIMINATION; CLASSIFICATION; QUALITY; SAMPLES	We explore the feasibility of implementing fast and reliable computer-based systems for the automatic identification of weed seeds from color and black and white images. Seeds size, shape, color and texture characteristics are obtained by standard image-processing techniques, and their discriminating power as classification features is assessed. These investigations are performed on a database much larger than those used in previous studies, containing 10,310 images of 236 different weed species. We consider the implementation of a simple Bayesian approach (naive Bayes classifier) and (single and bagged) artificial neural network systems for seed identification. Our results indicate that the naive Bayes classifier based on an adequately selected set of classification features has an excellent performance, competitive with that of the comparatively more sophisticated neural network approach. In addition, we discuss the possibility of using only morphological and textural characteristics as classification features, which would reduce the operational complexity and hardware cost of a commercial system since they can be obtained from black and white images. We find that, under particular operational conditions, this would result in a relatively small loss in performance when compared to the implementation based on color images. (c) 2004 Published by Elsevier B.V.	Consejo Nacl Invest Cient & Tecn, Inst Fis, RA-2000 Rosario, Santa Fe, Argentina; UNR, RA-2000 Rosario, Santa Fe, Argentina	Ceccatto, HA (reprint author), Consejo Nacl Invest Cient & Tecn, Inst Fis, Blvd 27 Febrero 210 Bis, RA-2000 Rosario, Santa Fe, Argentina.	ceccatto@ifir.edu.ar	Granitto, Pablo/A-3645-2013				Ahmad IS, 1999, PLANT DIS, V83, P320, DOI 10.1094/PDIS.1999.83.4.320; Chtioui Y, 1998, J SCI FOOD AGR, V76, P77, DOI 10.1002/(SICI)1097-0010(199801)76:1<77::AID-JSFA948>3.0.CO;2-9; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHEN C, 1989, CEREAL CHEM, V66, P466; Chtioui Y, 1996, J SCI FOOD AGR, V71, P433, DOI 10.1002/(SICI)1097-0010(199608)71:4<433::AID-JSFA596>3.3.CO;2-2; CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X; DRAPER S R, 1984, Journal of the National Institute of Agricultural Botany, V16, P387; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6; Granitto PM, 2002, COMPUT ELECTRON AGR, V33, P91, DOI 10.1016/S0168-1699(02)00004-2; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JANSEN PI, 1995, SEED SCI TECHNOL, V23, P353; KEEFE PD, 1986, SEED SCI TECHNOL, V14, P715; Mitchell T.M., 1997, MACHINE LEARNING; NEUMAN M, 1987, J CEREAL SCI, V6, P125; NEUMAN MR, 1989, J CEREAL SCI, V10, P183; NEUMAN MR, 1989, J CEREAL SCI, V10, P175; PETERSEN PEH, 1992, SEED SCI TECHNOL, V20, P193; SAPIRSTEIN HD, 1987, J CEREAL SCI, V6, P3; SYMONS SJ, 1988, J CEREAL SCI, V8, P211, DOI 10.1006/jcrs.1993.1048; ZAYAS I, 1986, CEREAL CHEM, V63, P52; ZAYAS I, 1989, CEREAL CHEM, V66, P233	24	32	41	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0168-1699			COMPUT ELECTRON AGR	Comput. Electron. Agric.	APR	2005	47	1					15	24		10.1016/j.compag.2004.10.003		10	Agriculture, Multidisciplinary; Computer Science, Interdisciplinary Applications	Agriculture; Computer Science	908XR	WOS:000227824000002	
J	Tsuruoka, Y; Tsujii, J				Tsuruoka, Y; Tsujii, J			Improving the performance of dictionary-based approaches in protein name recognition	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						protein name recognition; naive Bayes classifier; approximate string search; spelling variant generator	GENE	Dictionary-based protein name recognition is often a first step in extracting information from biomedical documents because it can provide ID information on recognized terms. However, dictionary-based approaches present two fundamental difficulties: (1) false recognition mainly caused by short names; (2) low recall due to spelling variations. In this paper, we tackle the former problem using machine learning to filter out false positives and present two alternative methods for alleviating the latter problem of spelling variations. The first is achieved by using approximate string searching, and the second by expanding the dictionary with a probabilistic variant generator, which we propose in this paper. Experimental results using the GENIA corpus revealed that filtering using a naive Bayes classifier greatly improved precision with only a slight loss of recall, resulting in 10.8% improvement in F-measure, and dictionary expansion with the variant generator gave further 1.6% improvement and achieved an F-measure of 66.6%. (C) 2004 Elsevier Inc. All rights reserved.	JST Agcy, CREST, Kawaguchi, Saitama 3320012, Japan; Univ Tokyo, Dept Comp Sci, Bunkyo Ku, Tokyo 1130033, Japan	Tsuruoka, Y (reprint author), JST Agcy, CREST, Honcho 4-1-8, Kawaguchi, Saitama 3320012, Japan.	tsuruoka@is.s.u-tokyo.ac.jp; tsujii@is.s.u-tokyo.ac.jp					Berger AL, 1996, COMPUT LINGUIST, V22, P39; COLLIER N, 2001, J TERMINOL, V7, P239; ESCUDERO G, 2000, P 14 EUR C ART INT E, P421; Humphreys B. L., 1989, Proceedings: The Thirteenth Annual Symposium on Computer Applications in Medical Care (Cat. No.89TH0286-5); Jurafsky D, 2000, SPEECH LANGUAGE PROC; Kazama J., 2002, P ACL WORKSH NAT LAN, P1; KIM JD, 2002, TEXT DATA MINING SIG; Krauthammer M, 2000, GENE, V259, P245, DOI 10.1016/S0378-1119(00)00431-5; Lee K J, 2003, P ACL 2003 WORKSH NA, P33; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; Marcotte EM, 2001, BIOINFORMATICS, V17, P359, DOI 10.1093/bioinformatics/17.4.359; MCCALLUM A, 1998, AAAI98 WORKSH LEARN; Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365; NAVARRO G, 2001, P 16 BRAZ S DAT SBBD, P228; Nigam K., 2000, CIKM, P86; OHTA T, 2002, P HUM LANG TECHN C H; Ono T, 2001, BIOINFORMATICS, V17, P155, DOI 10.1093/bioinformatics/17.2.155; Pedersen T., 2000, P 1 ANN M N AM CHAPT, P63; Ristad ES, 1998, IEEE T PATTERN ANAL, V20, P522, DOI 10.1109/34.682181; TAKEUCHI K, 2002, P 6 C NAT LANG LEARN, P119; Tanabe L, 2002, BIOINFORMATICS, V18, P1124, DOI 10.1093/bioinformatics/18.8.1124; THOMAS J, 2000, P PAC S BIOC PSB 200, V5, P502; Vapnik V., 1995, NATURE STAT LEARNING	23	32	33	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	DEC	2004	37	6					461	470		10.1016/j.jbi.2004.08.003		10	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	874EX	WOS:000225334800007	
B	Lee, YK; Ng, HT		Hajic, J; Matsumoto, Y		Lee, YK; Ng, HT			An empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation	PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING			English	Proceedings Paper	Conference on Empirical Methods in Natural Language Processing	JUL 06-07, 2002	Philadelphia, PA	Justsystem Corp, CLAIRVOYANCE Corp				In this paper, we evaluate a variety of knowledge sources and supervised learning algorithms for word sense disambiguation on SENSEVAL-2 and SENSEVAL-1 data. Our knowledge sources include the part-of-speech of neighboring words, single words in the surrounding context, local collocations, and syntactic relations. The learning algorithms evaluated include Support Vector Machines (SVM), Naive Bayes, AdaBoost, and decision tree algorithms. We present empirical results showing the relative contribution of the component knowledge sources and the different learning algorithms. In particular, using all of these knowledge sources and SVM (i.e., a single learning algorithm) achieves accuracy higher than the best official scores on both SENSEVAL-2 and SENSEVAL-1 test data.	Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117543, Singapore							CABEZAS C, 2001, P 2 INT WORKSH EV WO, P59; Charniak Eugene, 2000, P 1 C N AM CHAPT ASS, P132; Duda R., 1973, PATTERN CLASSIFICATI; Edmonds P., 2001, P 2 INT WORKSH EV WO, P1; Escudero G, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P172; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Kilgarriff A, 2000, COMPUT HUMANITIES, V34, P1, DOI 10.1023/A:1002619001915; Martin Y, 2000, GEOMORPHOLOGY, V34, P1, DOI 10.1016/S0169-555X(99)00127-0; Mihalcea R.F., 2001, P 2 INT WORKSH EV WO, P127; Mooney R. J., 1996, P C EMP METH NAT LAN, P82; PEDERSEN T, 2001, P SENS 2 WORKSH TOUL, P139; PEDERSEN T, 1997, P 14 NAT C ART INT P, P604; Pederson T., 2001, P 2 M N AM CHAPT ASS, P79; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ratnaparkhi A., 1996, P C EMP METH NAT LAN, P133; Reynar JC, 1997, P 5 C APPL NAT LANG, P16, DOI 10.3115/974557.974561; SEO HC, P 2 INT WORKSH EV WO, P147; Stevenson M, 2001, COMPUT LINGUIST, V27, P321, DOI 10.1162/089120101317066104; TOU NH, 1996, P 34 ANN M ASS COMP, P40; TOU NH, 1997, P 2 C EMP METH NAT L, P208; Vapnik V., 1995, NATURE STAT LEARNING; Veenstra J, 2000, COMPUT HUMANITIES, V34, P171, DOI 10.1023/A:1002459020102; Witten I.H., 2000, DATA MINING PRACTICA; Yarowsky D., 2001, P SENSEVAL2, P163; Yarowsky D, 2000, COMPUT HUMANITIES, V34, P179, DOI 10.1023/A:1002674829964; ZAVREL J, 2000, TWLT 18 LEARNING BEH, P201	26	32	32	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA							2002							41	48				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAO63	WOS:000223079900006	
J	Chen, K; Kurgan, LA; Ruan, JS				Chen, Ke; Kurgan, Lukasz A.; Ruan, Jishou			Prediction of flexible/rigid regions from protein sequences using k-spaced amino acid pairs	BMC STRUCTURAL BIOLOGY			English	Article							CONTINUUM SECONDARY STRUCTURE; STRUCTURAL CLASS; WEB SERVER; PSI-BLAST; DOMAIN; FLEXIBILITY; INFORMATION; CALMODULIN; ALGORITHM; ALIGNMENT	Background: Traditionally, it is believed that the native structure of a protein corresponds to a global minimum of its free energy. However, with the growing number of known tertiary (3D) protein structures, researchers have discovered that some proteins can alter their structures in response to a change in their surroundings or with the help of other proteins or ligands. Such structural shifts play a crucial role with respect to the protein function. To this end, we propose a machine learning method for the prediction of the flexible/rigid regions of proteins (referred to as FlexRP); the method is based on a novel sequence representation and feature selection. Knowledge of the flexible/ rigid regions may provide insights into the protein folding process and the 3D structure prediction. Results: The flexible/ rigid regions were defined based on a dataset, which includes protein sequences that have multiple experimental structures, and which was previously used to study the structural conservation of proteins. Sequences drawn from this dataset were represented based on feature sets that were proposed in prior research, such as PSI-BLAST profiles, composition vector and binary sequence encoding, and a newly proposed representation based on frequencies of k-spaced amino acid pairs. These representations were processed by feature selection to reduce the dimensionality. Several machine learning methods for the prediction of flexible/ rigid regions and two recently proposed methods for the prediction of conformational changes and unstructured regions were compared with the proposed method. The FlexRP method, which applies Logistic Regression and collocation-based representation with 95 features, obtained 79.5% accuracy. The two runner-up methods, which apply the same sequence representation and Support Vector Machines (SVM) and Naive Bayes classifiers, obtained 79.2% and 78.4% accuracy, respectively. The remaining considered methods are characterized by accuracies below 70%. Finally, the Naive Bayes method is shown to provide the highest sensitivity for the prediction of flexible regions, while FlexRP and SVM give the highest sensitivity for rigid regions. Conclusion: A new sequence representation that uses k-spaced amino acid pairs is shown to be the most efficient in the prediction of the flexible/ rigid regions of protein sequences. The proposed FlexRP method provides the highest prediction accuracy of about 80%. The experimental tests show that the FlexRP and SVM methods achieved high overall accuracy and the highest sensitivity for rigid regions, while the best quality of the predictions for flexible regions is achieved by the Naive Bayes method.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada; Nankai Univ, Chern Inst Math, Coll Math Sci, Tianjin 300071, Peoples R China; Nankai Univ, LPMC, Tianjin 300071, Peoples R China	Kurgan, LA (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.	kchen1@ece.ualberta.ca; lkurgan@ece.ualberta.ca; jsruan@nankai.edu.cn	Kurgan, Lukasz/B-5721-2009	Kurgan, Lukasz/0000-0002-7749-0314			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Boden M, 2006, BIOINFORMATICS, V22, P1809, DOI 10.1093/bioinformatics/btl198; Boden M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-68; Bonneau R, 2001, PROTEINS, V43, P1, DOI 10.1002/1097-0134(20010401)43:1<1::AID-PROT1012>3.0.CO;2-A; Brooks CL, 2002, ACCOUNTS CHEM RES, V35, P447, DOI 10.1021/ar0100172; Carney DS, 2006, TRENDS CELL BIOL, V16, P27, DOI 10.1016/j.tcb.2005.11.001; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen K, 2006, Proceedings of the 2006 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology, P366; Chen K, 2006, PROTEIN J, V25, P57, DOI 10.1007/s10930-006-0011-7; Chew LP, 1999, J COMPUT BIOL, V6, P313, DOI 10.1089/106652799318292; Conti E, 2006, CURR OPIN STRUC BIOL, V16, P237, DOI 10.1016/j.sbi.2006.03.010; Dosztanyi Z, 2005, BIOINFORMATICS, V21, P3433, DOI 10.1093/bioinformatics/bti541; Dunker AK, 2001, NAT BIOTECHNOL, V19, P805, DOI 10.1038/nbt0901-805; Fitzgerald KA, 2006, CELL, V125, P834, DOI 10.1016/j.cell.2006.05.014; Geeves MA, 2005, CELL MOL LIFE SCI, V62, P1462, DOI 10.1007/s00018-005-5015-5; Gerstein M, 1998, NUCLEIC ACIDS RES, V26, P4280, DOI 10.1093/nar/26.18.4280; Grabarek Z, 2006, J MOL BIOL, V359, P509, DOI 10.1016/j.jmb.2006.03.066; Gu J, 2006, PLOS COMPUT BIOL, V2, P769, DOI 10.1371/journal.pcbi.0020090; GUTIN AM, 1995, BIOCHEMISTRY-US, V34, P3066, DOI 10.1021/bi00009a038; HERTZ T, 2006, BMC BIOINFORMAT 0320, pS3; JOHN GH, 1995, P 11 C UNC ART INT, P338; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; King AE, 2006, TRENDS PHARMACOL SCI, V27, P416, DOI 10.1016/j.tips.2006.06.004; Kofler MM, 2006, FEBS J, V273, P245, DOI 10.1111/j.1742-4658.2005.05078.x; Krebs WG, 2003, METHOD ENZYMOL, V374, P544, DOI 10.1016/S0076-6879(03)74023-3; Le CS, 1992, APPL STAT, V41, P191; Li HZ, 2006, PROTEINS, V64, P985, DOI 10.1002/prot.21084; Li MS, 2006, MOL MICROBIOL, V60, P469, DOI 10.1111/j.1365-2958.2006.05108.x; Liu JF, 2003, NUCLEIC ACIDS RES, V31, P3833, DOI 10.1093/nar/gkg515; Liu JP, 2006, J BIOPHARM STAT, V16, P1, DOI 10.1080/10543400500406421; Morra G, 2003, PROTEINS, V53, P597, DOI 10.1002/prot.10344; Obradovic Zoran, 2003, Proteins Supplement, P566; Pappu RV, 1999, NAT STRUCT BIOL, V6, P50; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ruan JS, 2006, PROTEIN J, V25, P301, DOI 10.1007/s10930-006-9016-5; Sadqi M, 2006, NATURE, V442, P317, DOI 10.1038/nature04859; Schlessinger A, 2005, PROTEINS, V61, P115, DOI 10.1002/prot.20587; Schumacher MA, 2001, NATURE, V410, P1120, DOI 10.1038/35074145; Sellers JR, 2006, CURR OPIN CELL BIOL, V18, P68, DOI 10.1016/j.ceb.2005.12.014; Shatsky M, 2004, J COMPUT BIOL, V11, P83, DOI 10.1089/106652704773416902; Song JN, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-124; Tai CH, 2005, PROTEINS, V61, P183, DOI 10.1002/prot.20736; UDGAONKAR JB, 1988, NATURE, V335, P694, DOI 10.1038/335694a0; Uversky VN, 2000, PROTEINS, V41, P415, DOI 10.1002/1097-0134(20001115)41:3<415::AID-PROT130>3.0.CO;2-7; Witten IH, 2005, DATA MINING PRACTICA; Yap KL, 2003, J MOL BIOL, V328, P193, DOI 10.1016/S0022-2836(03)00271-7; Ye YZ, 2004, NUCLEIC ACIDS RES, V32, pW582, DOI 10.1093/nar/gkh430; Yeagle PL, 2003, BIOCHEMISTRY-US, V42, P1365, DOI 10.1021/bi0270539; YU L, 2003, P 10 INT C MACH LEAR; Yuan Z, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-248; Zaman Muhammad H, 2004, Mech Chem Biosyst, V1, P291	56	31	32	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2237			BMC STRUCT BIOL	BMC Struct. Biol.	APR 16	2007	7								25	10.1186/1472-6807-7-25		13	Biophysics	Biophysics	166OA	WOS:000246387200001	
J	Kotsiantis, SB; Zaharakis, ID; Pintelas, PE				Kotsiantis, S. B.; Zaharakis, I. D.; Pintelas, P. E.			Machine learning: a review of classification and combining techniques	ARTIFICIAL INTELLIGENCE REVIEW			English	Review						classifiers; data mining techniques; intelligent data analysis; learning algorithms	NAIVE-BAYES CLASSIFIERS; DECISION TREES; NEURAL-NETWORKS; INSTANCE SELECTION; RULE EXTRACTION; ALGORITHMS; INDUCTION; LOGIC; CONSTRUCTION; ATTRIBUTES	Supervised classification is one of the tasks most frequently carried out by so-called Intelligent Systems. Thus, a large number of techniques have been developed based on Artificial Intelligence (Logic-based techniques, Perceptron-based techniques) and Statistics (Bayesian Networks, Instance-based techniques). The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. This paper describes various classification algorithms and the recent attempt for improving classification accuracy-ensembles of classifiers.	[Kotsiantis, S. B.; Pintelas, P. E.] Univ Peloponnese, Dept Comp Sci & Technol, Peloponnese, Greece; [Kotsiantis, S. B.; Pintelas, P. E.] Univ Patras, Dept Math, Educ Software Dev Lab, GR-26110 Patras, Greece; [Zaharakis, I. D.] Comp Technol Inst, GR-26110 Patras, Greece	Kotsiantis, SB (reprint author), Univ Peloponnese, Dept Comp Sci & Technol, Peloponnese, Greece.	sotos@math.upatras.gr; jzaharak@cti.gr; pintelas@math.upatras.gr	kotsiantis, sotiris/C-5640-2009	kotsiantis, sotiris/0000-0002-2247-3082			Acid S, 2003, J ARTIF INTELL RES, V18, P445; Aha D.W., 1997, LAZY LEARNING; AN A, 1999, 3 PAC AS C METH KNOW, P509; AN A, 2000, LECT NOTES COMPUTER, V1932, P119; Auer P, 1998, MACH LEARN, V32, P127, DOI 10.1023/A:1007472513967; Baik S, 2004, LECT NOTES COMPUT SC, V3046, P206; Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI 10.1080/08839510390219309; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C. L., 1998, UCI REPOSITORY MACHI; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; Blum A, 1997, MACH LEARN, V26, P5, DOI 10.1023/A:1007335615132; Bonarini A., 2000, LECT NOTES ARTIF INT, V1813, P83, DOI 10.1007/3-540-45027-0_4; Bouckaert RR, 2003, P 20 INT C MACH LEAR, P51; Bouckaert RR, 2004, LECT NOTES ARTIF INT, V3339, P1089; Brazdil PB, 2003, MACH LEARN, V50, P251, DOI 10.1023/A:1021713901879; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breslow LA, 1997, KNOWL ENG REV, V12, P1, DOI 10.1017/S0269888997000015; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Burgess C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Camargo LS, 2001, NEURAL COMPUT, V13, P2673, DOI 10.1162/089976601317098484; Castellano G, 1997, IEEE T NEURAL NETWOR, V8, P519, DOI 10.1109/72.572092; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Cheng J., 2001, LECT NOTES COMPUTER, V2056, P141, DOI DOI 10.1007/3-540-45153-6_14; Chickering DM, 2002, J MACHINE LEARNING R, V11, P507; Cohen W., 1995, P 12 INT C MACH LEAR, P115; COWELL RG, 2001, P 17 INT C UNC ART I; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dantsin E, 2001, ACM COMPUT SURV, V33, P374, DOI 10.1145/502807.502810; De Raedt L., 1996, ADV INDUCTIVE LOGIC; de Mantaras RL, 1998, DATA KNOWL ENG, V25, P99; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domeniconi C., 2001, ADV NEURAL INFORM PR, V14, P665; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dutton D.M., 1996, KNOWL ENG REV, V12, P341; Dzeroski S., 2001, RELATIONAL DATA MINI; Elomaa T, 1999, LECT NOTES COMPUT SC, V1642, P63; Elomaa T, 1999, MACH LEARN, V36, P201, DOI 10.1023/A:1007674919412; FIDELIS MV, 1999, P CEC 2000 C EV COMP, V1, P805; FLACH PA, 2000, P ICML2000 WORKSH AT; FLANK E, 1998, MACHINE LEARNING; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Furnkranz J., 2001, P 18 INT C MACH LEAR, P146; Furnkranz J, 1997, MACH LEARN, V27, P139, DOI 10.1023/A:1007329424533; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Gama J., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00002-5; Gama J, 2000, MACH LEARN, V41, P315, DOI 10.1023/A:1007652114878; Gehrke J, 2000, DATA MIN KNOWL DISC, V4, P127, DOI 10.1023/A:1009839829793; Genton M., 2001, J MACHINE LEARNING R, V2, P299; Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HALL L, 2000, P 6 ACM SIGKDD INT C, P79; Heckerman D, 1999, COMPUTATION, CAUSATION, AND DISCOVERY, P141; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1007/s10462-004-4304-y; Jain A. K., 1999, ACM COMPUT SURV, V31; Japkowicz N., 2002, Intelligent Data Analysis, V6; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Jordan M.I., 1998, LEARNING GRAPHICAL M; Kalousis A, 2004, MACH LEARN, V54, P275, DOI 10.1023/B:MACH.0000015882.38031.85; Keerthi SS, 2002, MACH LEARN, V46, P351, DOI 10.1023/A:1012431217818; Kivinen J, 2002, LECT NOTES ARTIF INT, V2600, P235; Klusch M, 2003, LECT NOTES ARTIF INT, V2586, P104; Kon MA, 2000, NEURAL NETWORKS, V13, P365, DOI 10.1016/S0893-6080(00)00015-0; KOTSIANTIS S, 2004, P 4 INT C INT SYST D, P397; KUNCHEVA LI, 2001, LNCS, V2096, P228; Lazkano E, 2003, LECT NOTES ARTIF INT, V2902, P171; LiMin W., 2004, LECT NORES COMPUT SC, V3288, P327; Lindgren T, 2004, LECT NOTES COMPUT SC, V3201, P262; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; Liu H., 2001, INSTANCE SELECTION C; Maclin R., 1995, P 14 INT JOINT C ART, P524; MADDEN M, 2003, P EUR C MACH LEARN W, P59; Markovitch S, 2002, MACH LEARN, V49, P59, DOI 10.1023/A:1014046307775; McSherry D, 1999, KNOWL-BASED SYST, V12, P269, DOI 10.1016/S0950-7051(99)00024-6; Melville P, 2003, P 18 INT JOINT C ART, P505; Mitchell T.M., 1997, MACHINE LEARNING; Muggleton S, 1999, ARTIF INTELL, V114, P283, DOI 10.1016/S0004-3702(99)00067-3; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Neocleous C, 2002, LECT NOTES ARTIF INT, V2308, P300; Okamoto S, 2003, THEOR COMPUT SCI, V298, P207, DOI 10.1016/S0304-3975(02)00424-3; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; Parekh R, 2000, IEEE T NEURAL NETWOR, V11, P436, DOI 10.1109/72.839013; PLATT JC, 1999, ADV NEURAL INFORM PR; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; QUINLAN JR, 1995, NEW GENERAT COMPUT, V13, P287; Quinlan J.R., 1993, C4 5 PROGRAM MACHINE; Ratanamahatana C, 2003, APPL ARTIF INTELL, V17, P475, DOI 10.1080/08839510390219327; Reeves C. R., 2003, GENETIC ALGORITHMS P; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; ROBERT J, 2001, RADIAL BASIS FUNCTIO; Roli F., 2001, LNCS, V2096, P78; Roy A, 2000, IEEE T FUZZY SYST, V8, P222, DOI 10.1109/91.842155; Saad D., 1998, ONLINE LEARNING NEUR; SAITTA L, 1998, MACH LEARN, V30, P313; Sanchez JS, 2002, LECT NOTES ARTIF INT, V2504, P239; Schapire R.E., 1998, SIGIR 98 P 21 ANN IN, P215; SCHOLKOPF C, 1999, ADV KERNEL METHODS; Setiono R, 2000, APPL INTELL, V12, P15, DOI 10.1023/A:1008307919726; Siddique M.N.H., 2001, P IEEE INT JOINT C N, V4, P2673; Ting KM, 1999, J ARTIF INTELL RES, V10, P271; Todorovski L, 2003, MACH LEARN, V50, P223, DOI 10.1023/A:1021709817809; TS L, 2000, MACH LEARN, V40, P203; VEROPOULOS K, 1999, P INT JOINT C ART IN; VILLADA R, 2002, ARTIF INTELL REV, V18, P77; Vivarelli F, 2001, NEURAL NETWORKS, V14, P427, DOI 10.1016/S0893-6080(01)00024-7; Wall R, 2003, ARTIF INTELL MED, V28, P191, DOI 10.1016/S0933-3657(03)00056-3; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; WETTSCHERECK D, 1997, ARTIF INTELL, V10, P1; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten IH, 2005, DATA MINING PRACTICA; Yam JYF, 2001, IEEE T NEURAL NETWOR, V12, P430, DOI 10.1109/72.914538; Yang Y, 2003, LECT NOTES ARTIF INT, V2903, P440; YEN GG, 2000, IEEE S COMB EV COMP, P168; Yu L, 2004, J MACH LEARN RES, V5, P1205; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072; Zhang S., 2002, APPL ARTIF INTELL, V17, P375; Zheng ZJ, 1998, KNOWL-BASED SYST, V10, P421, DOI 10.1016/S0950-7051(98)00036-7; Zheng ZJ, 2000, MACH LEARN, V40, P35, DOI 10.1023/A:1007626017208; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719; Zhou ZH, 2004, J COMPUT SCI TECHNOL, V19, P249, DOI 10.1007/BF02944803; Zhou ZH, 2002, KNOWL-BASED SYST, V15, P515, DOI 10.1016/S0950-7051(02)00038-2	128	31	34	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821			ARTIF INTELL REV	Artif. Intell. Rev.	NOV	2006	26	3					159	190		10.1007/s10462-007-9052-3		32	Computer Science, Artificial Intelligence	Computer Science	249IX	WOS:000252222600001	
J	Guzella, TS; Caminhas, WM				Guzella, Thiago S.; Caminhas, Walmir M.			A review of machine learning approaches to Spam filtering	EXPERT SYSTEMS WITH APPLICATIONS			English	Review						Spam filtering; Online learning; Bag-of-words (BoW); Naive Bayes; Image spam	ARTIFICIAL IMMUNE-SYSTEM; SUPPORT VECTOR MACHINES; E-MAIL; TEXT CATEGORIZATION; FEATURE-SELECTION; CONCEPT DRIFT; MODELS; CLASSIFICATION; EXTRACTION; ALGORITHMS	In this paper, we present a comprehensive review of recent developments in the application of machine learning algorithms to Spam filtering, focusing on both textual- and image-based approaches. Instead of considering Spam filtering as a standard classification problem, we highlight the importance of considering specific characteristics of the problem, especially concept drift, in designing new filters. Two particularly important aspects not widely recognized in the literature are discussed: the difficulties in updating a classifier based on the bag-of-words representation and a major difference between two early naive Bayes models. Overall, we conclude that while important advancements have been made in the last years, several aspects remain to be explored, especially under more realistic evaluation settings. (C) 2009 Elsevier Ltd. All rights reserved.	[Guzella, Thiago S.; Caminhas, Walmir M.] Univ Fed Minas Gerais, Dept Elect Engn, BR-31270910 Belo Horizonte, MG, Brazil	Guzella, TS (reprint author), Univ Fed Minas Gerais, Dept Elect Engn, Ave Antonio Carlos 6627, BR-31270910 Belo Horizonte, MG, Brazil.	tguzella@igc.gulbenkian.pt; caminhas@cpdee.ufmg.br	caminhas, walmir/F-4332-2010		Bolsa Pesquisa program [20060519110414a]; FAPEMIG; CNPq	This work was supported by grants from UOL, through its Bolsa Pesquisa program (process number 20060519110414a), FAPEMIG and CNPq.	AAMODT A, 1994, AI COMMUN, V7, P39; ABIHAIDAR A, 2008, LECT NOTES COMPUTER, V5132; Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; ANDROUTSOPOULOS I, 2004, 20042 NCSR; ANDROUTSOPOULOS I, 2000, P 11 EUR C MACH LEAR; ANDROUTSOPOULOS I, 2000, P ANN INT ACM SIGIR; ARADHYE H, 2005, P INT C DOC AN REC, V2; Asuncion A., 2007, UCI MACHINE LEARNING; BEKKERMAN R, 2005, EMAIL CLASSIFICATION; Bezerra GB, 2006, LECT NOTES COMPUT SC, V4163, P446; Bickel S., 2007, ADV NEURAL INFORM PR, V19, P161; BIGGIO B, 2008, P 5 C EM ANT; BIGGIO B, 2007, P INT C IM AN PROC; Blanzieri E., 2008, DIT06056 U TRENT INF; Bratko A, 2006, J MACH LEARN RES, V7, P2673; BYUN B, 2007, P 4 C EM ANT; Camastra F, 2005, IEEE T PATTERN ANAL, V27, P801, DOI 10.1109/TPAMI.2005.88; Carpinter J, 2006, COMPUT SECUR, V25, P566, DOI 10.1016/j.cose.2006.06.001; Carreras X., 2001, P 4 INT C REC ADV NA; Ciltik A, 2008, PATTERN RECOGN LETT, V29, P19, DOI 10.1016/j.patrec.2007.07.018; CLARK J, 2003, P IEEE WIC INT C WEB; Cormack G. V., 2007, P TREC 2007 16 TEXT; Cormack GV, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1247715.1247717; CORMACK GV, 2005, P TREC 2005 14 TEXT; CORMACK GV, 2006, P TREC 2006 15 TEXT; Culotta A, 2006, ARTIF INTELL, V170, P1101, DOI 10.1016/j.artint.2006.08.001; Decastro L. N., 2002, ARTIFICIAL IMMUNE SY; Delany SJ, 2005, KNOWL-BASED SYST, V18, P187, DOI 10.1016/j.knosys.2004.10.002; Delany SJ, 2005, ARTIF INTELL REV, V24, P359, DOI 10.1007/s10462-005-9006-6; Delany SJ, 2006, ARTIF INTELL REV, V26, P75, DOI 10.1007/s10462-007-9041-6; DENIS F, 2002, P INT C INF PROC MAN; DORNBOS J, 2002, SPAM WHAT CAN YOU DO; Dredze M., 2007, P 4 C EM ANT; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Fawcett T., 2003, SIGKDD EXPLORATIONS, V5, P140; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fdez-Riverola F, 2007, DECIS SUPPORT SYST, V43, P722, DOI 10.1016/j.dss.2006.11.012; Fdez-Riverola F, 2007, EXPERT SYST APPL, V33, P36, DOI 10.1016/j.eswa.2006.04.011; Fumera G, 2006, J MACH LEARN RES, V7, P2699; Gabrilovich E, 2007, J MACH LEARN RES, V8, P2297; Gadat S, 2007, J MACH LEARN RES, V8, P509; Gomes LH, 2007, PERFORM EVALUATION, V64, P690, DOI 10.1016/j.peva.2006.11.001; Goodman J., 2007, Communications of the ACM, V50, DOI 10.1145/1216016.1216017; Goodman J., 2006, P 3 C EM ANT; Gordillo J, 2007, EXPERT SYST APPL, V33, P667, DOI 10.1016/j.eswa.2006.06.016; Graham P., 2002, PLAN SPAM; GUENTER B, 2008, SPAM ARCH; Guzella TS, 2008, BIOSYSTEMS, V92, P215, DOI 10.1016/j.biosystems.2008.02.006; Gyongyi Z., 2005, P 1 INT WORKSH ADV I; HAIDER P, 2007, P INT C MACH LEARN; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Hayes B, 2007, AM SCI, V95, P298, DOI 10.1511/2007.66.3748; Haykin S., 1998, NEURAL NETWORKS COMP; HE J, 2007, P 4 C EM ANT; Hoanca B, 2006, IEEE TECHNOL SOC MAG, V25, P22, DOI 10.1109/MTAS.2006.1607720; Hsiao WF, 2008, EXPERT SYST APPL, V34, P1599, DOI 10.1016/j.eswa.2007.01.018; JONES R, 2003, SPAM; JORGENSEN Z, 2008, J MACHINE LEARNING R, V8, P993; Kanaris I, 2007, INT J ARTIF INTELL T, V16, P1047, DOI 10.1142/S0218213007003692; Kim J, 2007, IEEE SECUR PRIV, V5, P33, DOI 10.1109/MSP.2007.95; Kohonen T, 2001, SELF ORGANIZING MAPS; Kolari P., 2006, P 21 NAT C ART INT; Koprinska I, 2007, INFORM SCIENCES, V177, P2167, DOI 10.1016/j.ins.2006.12.005; KRASSER S, 2007, IEEE SMC INF ASS SEC; Lai CC, 2007, KNOWL-BASED SYST, V20, P249, DOI 10.1016/j.knosys.2006.05.016; LAM HY, 2007, P 4 C EM ANT; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; LUO X, 2005, P INT C NEUR NETW, V4; Marsono MN, 2008, IET COMPUT DIGIT TEC, V2, P56, DOI 10.1049/iet-cdt:20050180; Martin-Herran G, 2008, AUTOMATICA, V44, P361, DOI 10.1016/j.automatica.2007.06.009; MEDLOCK B, 2006, P 3 C EM ANT; Mendez JR, 2009, EXPERT SYST APPL, V36, P1601, DOI 10.1016/j.eswa.2007.11.037; METSIS V, 2006, P C EM ANT; Mitchell T.M., 1997, MACHINE LEARNING; Oda T, 2005, LECT NOTES COMPUT SC, V3627, P276; ODA T, 2003, P IEEE C EV COMP, V1; Oda T, 2003, LECT NOTES COMPUT SC, V2723, P231; Ozgur L, 2004, PATTERN RECOGN LETT, V25, P1819, DOI 10.1016/j.patrec.2004.07.004; Pampapathi R, 2006, MACH LEARN, V65, P309, DOI 10.1007/s10994-006-9505-y; PU C, 2006, P 3 C EM ANT; Qin YS, 2008, PATTERN RECOGN LETT, V29, P803, DOI 10.1016/j.patrec.2007.12.010; ROBINSON G, 2003, LINUX J, V107, P6467; RUAN G, 2007, P INT C NAT COMP, V3; SAHAMI M, 1998, WS9805; Sakkis G, 2003, INFORM RETRIEVAL, V6, P49, DOI 10.1023/A:1022948414856; SARAFIJANOVIC S, 2007, LCAREPORT2007008 EC; SCHNEIDER K, 2003, P 10 C EUR CHAPT ASS; Scholkopf B, 2002, LEARNING KERNELS; SCULLEY D, 2007, P CEAS; SCULLEY D, 2008, P 5 C EM ANT; SCULLEY D, 2007, P ANN INT ACM SIGIR; SCULLEY D, 2007, P TREC 2007 16 TEXT; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; Seewald AK, 2007, INTELL DATA ANAL, V11, P497; SEGAL R, 2007, P 4 C EM ANT; SEGAL R, 2006, P 3 C EM ANT; SHIH DH, 2008, EXPERT SYSTEMS APPL, V34, P1555; SIRISANYALAK B, 2007, IEEE C EV COMP; Song FX, 2007, INT J PATTERN RECOGN, V21, P1085, DOI 10.1142/S0218001407005831; *SPAMASSASSIN, 2005, SPAM PUBL CORP; STERN H, 2008, P 5 C EM ANT; Talbot D, 2008, TECHNOL REV, V111, P28; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; TZORTZIS G, 2007, P IEEE INT C TOOLS A, V2; Vapnik V., 1998, STAT LEARNING THEORY; VELOSO A, 2006, P LAT AM WEB C; Wang B, 2006, PATTERN ANAL APPL, V9, P339, DOI 10.1007/s10044-006-0045-7; Wang CC, 2007, COMPUT SECUR, V26, P381, DOI 10.1016/j.cose.2006.12.012; WANG XL, 2005, P INT C MACH LEARN C, V9; Wang Z., 2007, P 4 C EM ANT; WEBB S, 2005, P INT C COLL COMP NE; Wei CP, 2008, DECIS SUPPORT SYST, V45, P491, DOI 10.1016/j.dss.2007.06.010; WOUTERS P, 2004, WHY SPAM IS BAD; Wu CH, 2009, EXPERT SYST APPL, V36, P4321, DOI 10.1016/j.eswa.2008.03.002; WU CT, 2005, P IEEE INT C IM PROC, V3; Yih W., 2006, P 3 C EM ANT; Yu B, 2008, KNOWL-BASED SYST, V21, P355, DOI 10.1016/j.knosys.2008.01.001; Yu HJ, 2004, IEEE T KNOWL DATA EN, V16, P70; Yue X, 2007, SOFT COMPUT, V11, P729, DOI 10.1007/s00500-006-0116-0; Zhang L., 2004, ACM T ASIAN LANGUAGE, V3, P243, DOI 10.1145/1039621.1039625; ZHAO W, 2005, P INT C ACT MED TECH; Zhou Y, 2007, INT J ARTIF INTELL T, V16, P627, DOI 10.1142/S0218213007003473; Zorkadis V, 2006, J EXP THEOR ARTIF IN, V18, P523, DOI 10.1080/09528130600975873; Zorkadis V, 2005, NEURAL NETWORKS, V18, P799, DOI 10.1016/j.neunet.2005.06.045	124	30	34	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	SEP	2009	36	7					10206	10222		10.1016/j.eswa.2009.02.037		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	456MO	WOS:000266851000001	
J	Xue, Y; Chen, H; Jin, CJ; Sun, ZR; Yao, XB				Xue, Yu; Chen, Hu; Jin, Changjiang; Sun, Zhirong; Yao, Xuebiao			NBA-Palm: prediction of palmitoylation site implemented in Naive Bayes algorithm	BMC BIOINFORMATICS			English	Article							SECONDARY STRUCTURE PREDICTION; PROTEIN PALMITOYLATION; LIPID RAFTS; TRAFFICKING; TUBULIN; PSD-95	Background: Protein palmitoylation, an essential and reversible post-translational modification (PTM), has been implicated in cellular dynamics and plasticity. Although numerous experimental studies have been performed to explore the molecular mechanisms underlying palmitoylation processes, the intrinsic feature of substrate specificity has remained elusive. Thus, computational approaches for palmitoylation prediction are much desirable for further experimental design. Results: In this work, we present NBA-Palm, a novel computational method based on Nave Bayes algorithm for prediction of palmitoylation site. The training data is curated from scientific literature (PubMed) and includes 245 palmitoylated sites from 105 distinct proteins after redundancy elimination. The proper window length for a potential palmitoylated peptide is optimized as six. To evaluate the prediction performance of NBA-Palm, 3-fold cross-validation, 8-fold cross-validation and Jack-Knife validation have been carried out. Prediction accuracies reach 85.79% for 3-fold cross-validation, 86.72% for 8-fold cross-validation and 86.74% for Jack-Knife validation. Two more algorithms, RBF network and support vector machine (SVM), also have been employed and compared with NBA-Palm. Conclusion: Taken together, our analyses demonstrate that NBA-Palm is a useful computational program that provides insights for further experimentation. The accuracy of NBA-Palm is comparable with our previously described tool CSS-Palm. The NBA-Palm is freely accessible from: http://www.bioinfo.tsinghua.edu.cn/NBA-Palm.	Tsing Hua Univ, Inst Bioinformat & Syst Biol, MOE Key Lab Bioinformat, State Key Lab Biomembrane & Membrane Biotechnol,D, Beijing 100084, Peoples R China; Hefei Natl Lab Phys Sci, Lab Cellular Dynam, Hefei 230027, Peoples R China; Univ Sci & Technol China, Hefei 230027, Peoples R China; Morehouse Sch Med, Dept Physiol, Atlanta, GA 30310 USA; Morehouse Sch Med, Canc Res Program, Atlanta, GA 30310 USA	Xue, Y (reprint author), Tsing Hua Univ, Inst Bioinformat & Syst Biol, MOE Key Lab Bioinformat, State Key Lab Biomembrane & Membrane Biotechnol,D, Beijing 100084, Peoples R China.	yxue@mail.ustc.edu.cn; tiger@mails.bioinfo.tsinghua.edu.cn; Jincj@ustc.edu.cn; sunzhr@tsinghua.edu.cn; yaoxb@ustc.edu.cn	Xue, Yu/G-5929-2011	Xue, Yu/0000-0002-9403-6869			Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bijlmakers MJ, 2003, TRENDS CELL BIOL, V13, P32, DOI 10.1016/S0962-8924(02)00008-9; Borgelt C., 2002, GRAPHICAL MODELS MET; Caron JM, 2001, MOL BIOL CELL, V12, P2672; Clark KL, 2004, J BIOL CHEM, V279, P19401, DOI 10.1074/jbc.M312626200; Crooks GE, 2004, GENOME RES, V14, P1188, DOI 10.1101/gr.849004; Dietrich LEP, 2004, EMBO REP, V5, P1053, DOI 10.1038/sj.embor.7400277; Durbin R, 1998, BIOL SEQUENCE ANAL P; El-Husseini AED, 2002, NAT REV NEUROSCI, V3, P791, DOI 10.1038/nrn940; Fukata M, 2004, NEURON, V44, P987, DOI 10.1016/j.neuron.2004.12.005; Guo J, 2004, PROTEINS, V54, P738, DOI 10.1002/prot.10634; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Huang K, 2004, NEURON, V44, P977, DOI 10.1016/j.neuron.2004.11.027; Huang K, 2005, CURR OPIN NEUROBIOL, V15, P527, DOI 10.1016/j.conb.2005.08.001; Kalinina EV, 2003, J BIOL CHEM, V278, P9244, DOI 10.1074/jbc.M209379200; Kleuss C, 2003, EMBO J, V22, P826, DOI 10.1093/emboj/cdg095; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Linder ME, 2003, BIOCHEMISTRY-US, V42, P4311, DOI 10.1021/bi034159a; Mitchell T.M., 1997, MACHINE LEARNING; Navarro-Lerida I, 2004, J BIOL CHEM, V279, P55682, DOI 10.1074/jbc.M406621200; Salaun C, 2005, J BIOL CHEM, V280, P1236, DOI 10.1074/jbc.M410674200; Smotrys JE, 2004, ANNU REV BIOCHEM, V73, P559, DOI 10.1146/annurev.biochem.73.011303.073954; Vapnik V., 1995, NATURE STAT LEARNING; Vazquez P, 2005, J ENDOCRINOL, V185, P35, DOI 10.1677/joe.1.06031; Wang DA, 2005, J BIOL CHEM, V280, P19243, DOI 10.1074/jbc.M411472200; Witten IH, 2005, DATA MINING PRACTICA; Wolff J, 2000, PROTEIN SCI, V9, P1357; Wong W, 2004, J BIOL CHEM, V279, P444, DOI 10.1074/jbc.M304675200; XUE Y, 2005, NUCLEIC ACIDS RES, V3, pW184; Yang XW, 2004, J CELL BIOL, V167, P1231, DOI 10.1083/jcb.200404100; Zhou B, 2004, CANCER RES, V64, P7455, DOI 10.1158/0008-5472.CAN-04-1574; Zhou FF, 2006, BIOINFORMATICS, V22, P894, DOI 10.1093/bioinformatics/btl013; Zhou FF, 2004, BIOCHEM BIOPH RES CO, V325, P1443, DOI 10.1016/j.bbrc.2004.11.001	33	30	32	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	OCT 17	2006	7								458	10.1186/1471-2105-7-458		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	098QQ	WOS:000241538300001	
J	Sun, HM				Sun, HM			A naive Bayes classifier for prediction of multidrug resistance reversal activity on the basis of atom typing	JOURNAL OF MEDICINAL CHEMISTRY			English	Article							STRUCTURALLY RELATED-COMPOUNDS; P-GLYCOPROTEIN; AGENTS; INHIBITORS; DRUGS; CANCER; MODEL; PHENOTHIAZINES; TRANSPORTERS; SELECTION	Multidrug resistance (MDR), the ability of cancer cells to become simultaneously resistant to different drugs, remains an unsolved challenge in cancer chemotherapy. The use of MDR reversal (MDRR) agents is a promising approach to overcome this problem. For the design and development of such agents, it would be desirable to have a reliable model to estimate the MDRR activity of compounds. Presented here is a naive Bayes classifier to categorize MDRR agents into active and inactive classes, which uses a universal, generic molecular-descriptor system.(1) The naive Bayes classifier was built from a 424 compound training set, selected from 609 druglike compounds in the publicly available "Klopman set". The model correctly predicted MDRR activities for 82.2% of 185 compounds in a testing set. The cumulative probabilities were proven useful for prioritizing the compounds for testing. The impact of attribute dependences on the performance of the classifier was examined. As an unsupervised learner with no tuning parameters, a naive Bayes classifier is capable of providing an objective comparison of the effectiveness of different molecular descriptors. The relative performance of the classifiers constructed from either an atom-type-based molecular descriptor or the long-range functional-class fingerprint descriptors FCFP_6 or FCFP_2 was compared. Employing an atom typing descriptor with the naive Bayes classification, it enables the interpretability of the resulting model, which offers extra information for the rational design of MDRR agents.	Hoffmann La Roche Inc, Discovery Chem, Nutley, NJ 07110 USA	Sun, HM (reprint author), Hoffmann La Roche Inc, Discovery Chem, 340 Kingsland St, Nutley, NJ 07110 USA.	hongmao.sun@roche.com					Ambudkar SV, 1999, ANNU REV PHARMACOL, V39, P361, DOI 10.1146/annurev.pharmtox.39.1.361; Avendano C, 2002, CURR MED CHEM, V9, P159; Bakken GA, 2000, J MED CHEM, V43, P4534, DOI 10.1021/jm000244u; Balzarini J, 1999, BIOCHEM PHARMACOL, V58, P1; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Beresford AP, 2004, CURR OPIN DRUG DISC, V7, P36; Berger D, 1999, J MED CHEM, V42, P2145, DOI 10.1021/jm9804477; Berger JO, 1993, STAT DECISION THEORY; Borst P, 1999, BBA-BIOMEMBRANES, V1461, P347, DOI 10.1016/S0005-2736(99)00167-4; Chang G, 2001, SCIENCE, V293, P1793, DOI 10.1126/science.293.5536.1793; Domingos P, 1996, 13 INT C MACH LEARN, P105; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Ecker G, 1999, MOL PHARMACOL, V56, P791; Ekins S, 2002, MOL PHARMACOL, V61, P974, DOI 10.1124/mol.61.5.974; Ekins S, 2002, MOL PHARMACOL, V61, P964, DOI 10.1124/mol.61.5.964; FORD JM, 1990, PHARMACOL REV, V42, P155; Garrigues A, 2002, MOL PHARMACOL, V62, P1288, DOI 10.1124/mol.62.6.1288; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Golbraikh A, 2003, J COMPUT AID MOL DES, V17, P241, DOI 10.1023/A:1025386326946; Gottesman MM, 2002, NAT REV CANCER, V2, P48, DOI 10.1038/nrc706; Hipfner DR, 1999, BBA-BIOMEMBRANES, V1461, P359, DOI 10.1016/S0005-2736(99)00168-6; Klon AE, 2004, J MED CHEM, V47, P2743, DOI 10.1021/jm030363k; Klopman G, 2003, J COMPUT AID MOL DES, V17, P291, DOI 10.1023/A:1026124505322; KLOPMAN G, 1992, CANCER RES, V52, P4121; Klopman G, 1997, MOL PHARMACOL, V52, P323; Osterberg T, 2000, EUR J PHARM SCI, V10, P295, DOI 10.1016/S0928-0987(00)00077-4; Pajeva I, 1998, J MED CHEM, V41, P1815, DOI 10.1021/jm970786k; Pajeva IK, 2004, J MED CHEM, V47, P2523, DOI 10.1021/jm031009p; PAWAGI AB, 1994, J MOL BIOL, V235, P554, DOI 10.1006/jmbi.1994.1013; Penzotti JE, 2002, J MED CHEM, V45, P1737, DOI 10.1021/jm0255062; RAMU A, 1994, CANCER CHEMOTH PHARM, V34, P423, DOI 10.1007/BF00685568; RAMU A, 1992, CANCER CHEMOTH PHARM, V30, P165, DOI 10.1007/BF00686306; RISH I, 2001, EMPIRICAL STUDY NAIV, P41; Robert J, 2003, J MED CHEM, V46, P4805, DOI 10.1021/jm030183a; Seelig A, 1998, EUR J BIOCHEM, V251, P252, DOI 10.1046/j.1432-1327.1998.2510252.x; Seigneuret M, 2003, J BIOL CHEM, V278, P30115, DOI 10.1074/jbc.M302443200; Sonneveld Pieter, 1997, Current Opinion in Oncology, V9, P543, DOI 10.1097/00001622-199711000-00009; Stouch TR, 2002, ADV DRUG DELIVER REV, V54, P315, DOI 10.1016/S0169-409X(02)00006-6; Sun HM, 2004, J CHEM INF COMP SCI, V44, P748, DOI 10.1021/ci030304f; Suzuki T, 1997, J MED CHEM, V40, P2047, DOI 10.1021/jm960869l; Wiese M, 2001, CURR MED CHEM, V8, P685; Wright GD, 2003, CURR OPIN CHEM BIOL, V7, P563, DOI 10.1016/j.cbpa.2003.08.004; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Young S Stanley, 2004, Methods Mol Biol, V275, P317	44	30	30	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0022-2623			J MED CHEM	J. Med. Chem.	JUN 16	2005	48	12					4031	4039		10.1021/jm050180t		9	Chemistry, Medicinal	Pharmacology & Pharmacy	935SZ	WOS:000229805000010	
J	Abellan, J; Moral, S				Abellan, J; Moral, S			Upper entropy of credal sets. Applications to credal classification	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article; Proceedings Paper	3rd International Symposium on Imprecise Probabilities and Their Applications	JUL   14, 2003	Lugano, SWITZERLAND			imprecise probabilities; uncertainty; upper entropy; imprecision; non-specificity; classification; classification trees; credal sets	DEMPSTER-SHAFER THEORY; MATHEMATICAL-THEORY; TOTAL UNCERTAINTY	We present an application of the measure of entropy for credal sets: as a branching criterion for constructing classification trees based on imprecise probabilities which are determined with the imprecise Dirichlet model. We also justify the use of upper entropy as a global uncertainty measure for credal sets and present a deduction of this measure. We have carried out several experiments in which credal classification trees are built taking a global uncertainty measure as a basis. The results show how the introduced methodology improves the performance of traditional methods (Naive Bayes and C4.5), by providing a much lower error rate. (c) 2004 Elsevier Inc. All rights reserved.	Univ Granada, Dipartimento Ciencias Computac, E-18071 Granada, Spain	Moral, S (reprint author), Univ Granada, Dipartimento Ciencias Computac, E-18071 Granada, Spain.	jabemu@teleline.es; smc@decsai.ugr.es	Abellan Mulero, Joaquin/C-2397-2012; Moral Callejon, Serafin/C-2416-2012				ABELLAN J, 2003, THESIS U GRANADA; Abellan J, 1999, INT J GEN SYST, V28, P299, DOI 10.1080/03081079908935240; ABELLAN J, 2001, ACTAS C AS ESPANOLA, V2, P1035; ABELLAN J, 2001, P 2 INT S IMPR PROB, P1; Abellan J, 2003, INT J UNCERTAIN FUZZ, V11, P587, DOI 10.1142/S021848850300234X; Abellan J, 2000, INT J UNCERTAIN FUZZ, V8, P357, DOI 10.1142/S0218488500000253; ACID S, 1999, THESIS U GRANADA; Breiman L., 1984, CLASSIFICATION REGRE; Choquet G, 1953, ANN I FOURIER GRENOB, V5, P131; De Campos LM, 1994, INT J UNCERTAIN FUZZ, V2, P167, DOI DOI 10.1142/S0218488594000146; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DUBOIS D, 1984, BUSEFAL, V19, P83; DUBOIS D, 1987, FUZZY SET SYST, V24, P183; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; HARMANEC D, 1994, INT J GEN SYST, V22, P405, DOI 10.1080/03081079408935225; Hartley RVL, 1928, BELL SYST TECH J, V7, P535; Higashi M., 1983, INT J GEN SYST, V9, P43; JAYNES ET, 1963, STAT PHYSICS, V3, P182; KLIR GJ, 1998, UNCERTAINITY BASED I; Meyerowitz A., 1994, INT J UNCERTAIN FUZZ, V2, P377, DOI 10.1142/S0218488594000316; Quinlan J.R., 1993, PROGRAMS MACHINE LEA; Quinlan J. R., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; Shafer G., 1976, MATH THEORY EVIDENCE; SHANNON CE, 1948, AT&T TECH J, V27, P379; Walley P, 1996, J ROY STAT SOC B MET, V58, P3; Walley P., 1991, STAT REASONING IMPRE; YAGER RR, 1983, INT J GEN SYST, V9, P249, DOI 10.1080/03081078308960825; Zaffalon M, 2002, J STAT PLAN INFER, V105, P5, DOI 10.1016/S0378-3758(01)00201-4; ZAFFALON M, 2001, P 2 INT S IMPR PROB, P384	30	30	31	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X			INT J APPROX REASON	Int. J. Approx. Reasoning	JUN	2005	39	2-3					235	255		10.1016/j.ijar.2004.10.001		21	Computer Science, Artificial Intelligence	Computer Science	922ZW	WOS:000228879400007	
J	Ko, Y; Park, J; Seo, J				Ko, Y; Park, J; Seo, J			Improving text categorization using the importance of sentences	INFORMATION PROCESSING & MANAGEMENT			English	Article						text categorization; importance of sentence; text summarization techniques; indexing technique; text classifier	RETRIEVAL	Automatic text categorization is a problem of assigning text documents to pre-defined categories. In order to classify text documents, we must extract useful features. In previous researches, a text document is commonly represented by the term frequency and the inverted document frequency of each feature. Since there is a difference between important sentences and unimportant sentences in a document, the features from more important sentences should be considered more than other features. In this paper, we measure the importance of sentences using text summarization techniques. Then we represent a document as a vector of features with different weights according to the importance of each sentence. To verify our new method, we conduct experiments using two language newsgroup data sets: one written by English and the other written by Korean. Four kinds of classifiers are used in our experiments: Naive Bayes, Rocchio, k-NN, and SVM. We observe that our new method makes a significant improvement in all these classifiers and both data sets. (C) 2002 Elsevier Ltd. All rights reserved.	Sogang Univ, Dept Comp Sci, NLP Lab, Seoul 121742, South Korea	Ko, Y (reprint author), Sogang Univ, Dept Comp Sci, NLP Lab, Sinsu Dong 1, Seoul 121742, South Korea.						Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; Duda R.O., 2001, PATTERN CLASSIFICATI; ENDRESNIGGEMEYE.B, 1998, SUMMARIZING INFORMAT, P307; GOLDSTEIN J, 1999, P 23 INT ACM SIGIR C; Joachims Th., 1998, EUR C MACH LEARN ECM, P137; Ko Y., 2000, P 18 INT C COMP LING, P453; Lewin GR, 1996, ANNU REV NEUROSCI, V19, P289, DOI 10.1146/annurev.ne.19.030196.001445; LI H, 1997, P 35 ANN M ASS COMP; Marcu D, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P123; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; MOCK KJ, 1996, P NAT C ART INT AAAI; MURATA M, 2000, J ASS NATURAL LANGUA, V7; RADEV D, 2000, P ANLP NACCL WORKSH; SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Vapnic V, 1995, NATURE STAT LEARNING; WESTON V, 1999, P 7 EUR S ART NEUR N; Yang Y, 1997, 14 INT C MACH LEARN, P412; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Yang Y., 2002, J INTELLIGENT INFORM, V18	22	30	36	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573			INFORM PROCESS MANAG	Inf. Process. Manage.	JAN	2004	40	1					65	79		10.1016/S0306-4573(02)00056-0		15	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	759LC	WOS:000187738300005	
J	Craven, M; Slattery, S				Craven, M; Slattery, S			Relational learning with statistical predicate invention: Better models for hypertext	MACHINE LEARNING			English	Article; Proceedings Paper	8th International Conference on Inductive Logic Programming (ILP98)	JUL 22-24, 1998	MADISON, WISCONSIN			relational learning; text categorization; predicate invention; Naive Bayes		We present a new approach to learning hypertext classifiers that combines a statistical text-learning method with a relational rule learner. This approach is well suited to learning in hypertext domains because its statistical component allows it to characterize text in terms of word frequencies, whereas its relational component is able to describe how neighboring documents are related to each other by hyperlinks that connect them. We evaluate our approach by applying it to tasks that involve learning definitions for (i) classes of pages, (ii) particular relations that exist between pairs of pages, and (iii) locating a particular class of information in the internal structure of pages. Our experiments demonstrate that this new approach is able to learn more accurate classifiers than either of its constituent methods alone.	Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA; Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Craven, M (reprint author), Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA.						Cestnik B, 1990, P EUR C ART INT, P147; COHEN W, 1995, ADV INDUCTIVE LOGIC; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Craven M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; CRAVEN M, 1998, P 10 EUR C MACH LEAR, P250; DiPasquo D., 1998, THESIS CARNEGIE MELL; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DZEROSKI S, 1992, P 2 INT WORKSH IND L, P109; EHRENFEUCHT A, 1989, INFORM COMPUT, V82, P247, DOI 10.1016/0890-5401(89)90002-3; Friedman N., 1999, P 16 INT JOINT C ART, P1300; Joachims T., 1997, P 15 INT JOINT C ART, P770; KIJSIRIKUL B, 1992, P 10 NAT C ART INT S, P44; KOLLER D, 1997, P 15 INT JOINT C ART, P1316; KRAMER S, 1995, OFAITR9532 AUSTR RES; KUSHMERICK N, 1997, P 15 INT JOINT C ART, P729; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Lewis D.D., 1996, P 19 ANN INT ACM SIG, P298, DOI 10.1145/243199.243277; Mitchell T.M., 1997, MACHINE LEARNING; MLADENIC D, 1996, IJSDP7472 J STEF I D; MOULINIER I, 1996, P 6 ANN S DOC AN INF; Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Quinlan J. R., 1993, P EUR C MACH LEARN, P3; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Richards B. L., 1992, P AAAI C SAN JOS, P50; Silverstein G., 1991, P 8 INT WORKSH MACH, P203; Soderland S., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Srinivasan A, 1999, J LOGIC PROGRAM, V40, P185, DOI 10.1016/S0743-1066(99)00018-7; SRINIVASAN A, 1992, P 2 INT WORKSH IND L; STAHL I, 1996, ADV INDUCTIVE LOGIC; Van Rijsbergen C.J., 1979, INFORMATION RETRIEVA; WROBEL S, 1994, MACH LEARN, V14, P169, DOI 10.1023/A:1022674116380; Yang Y., 1997, P 14 INT C MACH LEAR, P412; ZELLE JM, 1994, P 11 INT C MACH LEAR, P343	34	30	34	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	APR-MAY	2001	43	1-2					97	119		10.1023/A:1007676901476		23	Computer Science, Artificial Intelligence	Computer Science	417AY	WOS:000167814200005	
J	Madden, MG				Madden, Michael G.			On the classification performance of TAN and general Bayesian networks	KNOWLEDGE-BASED SYSTEMS			English	Article						Bayesian networks; TAN; Naive Bayes; Classification; Inductive learning; Parameter estimation	CLASSIFIERS	Over a decade ago, Friedman et al. introduced the Tree Augmented Naive Bayes (TAN) classifier, with experiments indicating that it significantly outperformed Naive Bayes (NB) in terms of classification accuracy, whereas general Bayesian network (GBN) classifiers performed no better than NB. This paper challenges those claims, using a careful experimental analysis to show that GBN classifiers significantly outperform NB on datasets analyzed, and are comparable to TAN performance. It is found that the poor performance reported by Friedman et al. are not attributable to the GBN per se, but rather to their use of simple empirical frequencies to estimate GBN parameters, whereas basic parameter smoothing (used in their TAN analyses but not their GBN analyses) improves GBN performance significantly. It is concluded that, while GBN classifiers may have some limitations, they deserve greater attention, particularly in domains where insight into classification decisions, as well as good accuracy, is required. (C) 2009 Elsevier B.V. All rights reserved.	Natl Univ Ireland, Coll Engn & Informat, Galway, Ireland	Madden, MG (reprint author), Natl Univ Ireland, Coll Engn & Informat, Univ Rd, Galway, Ireland.	michael.madden@nuigalway.ie	Madden, Michael/C-7113-2011		EU [CT-2005-029611]	This research has been supported by a Marie Curie Transfer of Knowledge Fellowship of the EU 6th Framework Programme, contract CT-2005-029611.	Asuncion A., 2007, UCI MACHINE LEARNING; BAESENS B, 2002, P 2002 INT C PATT RE; BOUCKAERT RR, 2004, 142004 U WAIK COMP S; Bouckaert R.R., 2004, P 21 INT C MACH LEAR; BUNTINE W, 1991, P 7 INT C UNC ART IN; Cerquides J, 2005, MACH LEARN, V59, P323, DOI 10.1007/s10994-005-0470-7; CHEN J, 2001, P 14 CAN C ART INT; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Chickering DM, 2006, ARTIF INTELL, V170, P653, DOI 10.1016/j.artint.2006.03.001; Chickering DM, 2002, J MACHINE LEARNING R, V11, P507; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Dougherty J, 1995, P 12 INT C MACH LEAR; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GARG A, 2001, P 12 EUR C MACH LEAR; Grossman D., 2004, P 21 INT C MACH LEAR; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Keogh E. J., 2002, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V11, DOI 10.1142/S0218213002001052; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; LING CX, 2002, J MACHINE LEARNING R, V3; Madden M., 2003, P EUR C MACH LEARN W; NADEAU C, 2000, ADV NEURAL INFORM PR, V12; Silander T., 2006, P 22 C UNC ART INT; ZHANG H, 2001, P 5 PAC AS C KNOWL D	24	29	31	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	OCT	2009	22	7					489	495		10.1016/j.knosys.2008.10.006		7	Computer Science, Artificial Intelligence	Computer Science	513TQ	WOS:000271346900002	
J	Ye, Q; Zhang, ZQ; Law, R				Ye, Qiang; Zhang, Ziqiong; Law, Rob			Sentiment classification of online reviews to travel destinations by supervised machine learning approaches	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Sentiment classification; Online reviews; Travel destinations; Supervised machine learning algorithm	WORD-OF-MOUTH	The rapid growth in Internet applications in tourism has lead to an enormous amount of personal reviews for travel-related information on the Web. These reviews can appear in different forms like BBS, blogs, Wiki or forum websites. More importantly, the information in these reviews is valuable to both travelers and practitioners for various understanding and planning processes. An intrinsic problem of the overwhelming information on the Internet, however, is information overloading as users are simply unable to read all the available information. Query functions in search engines like Yahoo and Google can help users find some of the reviews that they needed about specific destinations. The returned pages from these search engines are still beyond the visual capacity of humans. In this research, sentiment classification techniques were incorporated into the domain of mining reviews from travel blogs. Specifically, we compared three supervised machine learning algorithms of Naive Bayes, SVM and the character based N-gram model for sentiment classification of the reviews on travel blogs for seven popular travel destinations in the US and Europe. Empirical findings indicated that the SVM and N-gram approaches outperformed the Naive Bayes approach, and that when training datasets had a large number of reviews, all three approaches reached accuracies of at least 80%. (C) 2008 Elsevier Ltd. All rights reserved.	[Ye, Qiang; Zhang, Ziqiong] Harbin Inst Technol, Sch Management, Harbin 150006, Peoples R China; [Ye, Qiang; Law, Rob] Hong Kong Polytech Univ, Sch Hotel & Tourism Management, Hong Kong, Hong Kong, Peoples R China	Ye, Q (reprint author), Harbin Inst Technol, Sch Management, Harbin 150006, Peoples R China.	hmye@intet.polyu.edu.hk; ziqiong@hit.edu.cn; hmroblaw@polyu.edu.hk			Research Funding of Hong Kong Polytechnic University [G-YX93]; Internet Research Center of China and NSFC [70771032, 70501009]	This study was partially supported by Research Funding of Hong Kong Polytechnic University (G-YX93), Internet Research Center of China and NSFC grant (70771032, 70501009).	*AL I, 2006, LINGPIPE NAT LANG TO, P83006; Anderson E. W., 1998, J SERV RES-US, V1, P5, DOI 10.1177/109467059800100102; Beineke P., 2004, P 42 ANN M ASS COMP, P263, DOI 10.3115/1218955.1218989; Carpenter B., 2005, P 2005 ASS COMP LING, P1; Chaovalit P., 2005, P 38 HAW INT C SYST, P1; Cheung C, 2004, P 8 PAC AS C INF SYS, P2100; Choi S, 2007, TOURISM MANAGE, V28, P118, DOI 10.1016/j.tourman.2006.03.002; Conrad J. G., 2007, P 11 INT C ART INT L, P231, DOI 10.1145/1276318.1276363; Dave K., 2003, P 12 INT C WORLD WID, P519, DOI DOI 10.1145/775152.775226; Dellarocas C, 2003, MANAGE SCI, V49, P1407, DOI 10.1287/mnsc.49.10.1407.17308; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; *DOUBLECLICK INC, 2005, SEARCH PURCH UND BUY, P83006; GODBOLE N, 2007, INT C WEBL SOC MED I, P83006; Godes D, 2005, MARKET LETT, V16, P415, DOI 10.1007/s11002-005-5902-4; Goldenberg J, 2001, MARKET LETT, V12, P211, DOI 10.1023/A:1011122126881; Govers R., 2005, INFORM TECHNOLOGY TO, V7, P73, DOI 10.3727/1098305054517327; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Klein LR, 1998, J BUS RES, V41, P195, DOI 10.1016/S0148-2963(97)00062-3; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; Liu B., 2005, P 14 INT WORLD WID W, P10; Lo A., 2002, Journal of Travel & Tourism Marketing, V13, P61, DOI 10.1300/J073v13n03_04; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; MORINO S, 2002, P 1 FIB C 2002, P1; Okanohara D, 2005, LECT NOTES ARTIF INT, V3651, P314; Pan B., 2007, Journal of Travel Research, V46, P35, DOI 10.1177/0047287507302378; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Pudliner B. A., 2007, Journal of Tourism and Cultural Change, V5, P46; Stokes D., 2002, J SMALL BUSINESS ENT, V9, P349, DOI 10.1108/14626000210450531; Turney P., 2002, P 40 ANN M ASS COMP, P417, DOI DOI 10.3115/1073083.1073153; Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013; VAPNIK V, 1995, NATURE STAT LEARNING, P83006; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; ZHU F, 2006, 27 INT C INF SYST IC, P83006	34	29	32	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					6527	6535		10.1016/j.eswa.2008.07.035		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	413UD	WOS:000263817100095	
J	Kossin, JP; Sitkowski, M				Kossin, James P.; Sitkowski, Matthew			An Objective Model for Identifying Secondary Eyewall Formation in Hurricanes	MONTHLY WEATHER REVIEW			English	Article							PREDICTION SCHEME SHIPS; NUMERICAL-SIMULATION; CONCENTRIC EYEWALLS; ANNULAR HURRICANES; TROPICAL CYCLONES; INTENSITY CHANGES; WIND MAXIMA; PART I; EVOLUTION; SKILL	Hurricanes, and particularly major hurricanes, will often organize a secondary eyewall at some distance around the primary eyewall. These events have been associated with marked changes in the intensity and structure of the inner core, such as large and rapid deviations of the maximum wind and significant broadening of the surface wind field. While the consequences of rapidly fluctuating peak wind speeds are of great importance, the broadening of the overall wind field also has particularly dangerous consequences in terms of increased storm surge and wind damage extent during landfall events. Despite the importance of secondary eyewall formation in hurricane forecasting, there is presently no objective guidance to diagnose or forecast these events. Here a new empirical model is introduced that will provide forecasters with a probability of imminent secondary eyewall formation. The model is based on environmental and geostationary satellite features applied to a naive Bayes probabilistic model and classification scheme. In independent testing, the algorithm performs skillfully against a defined climatology.	[Kossin, James P.; Sitkowski, Matthew] Univ Wisconsin, Cooperat Inst Meteorol Satellite Studies, Madison, WI 53706 USA	Kossin, JP (reprint author), Univ Wisconsin, Cooperat Inst Meteorol Satellite Studies, Madison, WI 53706 USA.	kossin@ssec.wisc.edu	Kossin, James/D-3929-2011		NOAA GOES-R [N00014-07-1-0163]; NOAA Hurricane Supplemental Research Program; NRL-MRY Satellite Applications [N00173-01-C-2024]	We thank Jeff Hawkins for providing an earlier version of his secondary eyewall database and for his assistance with the microwave imagery. The microwave imagery is provided by the Naval Research Laboratory in Monterey, California. We're grateful to Dave Nolan, Chris Rozoff, John Knaff, Mark DeMaria, and Chris Velden for many useful discussions; and to Howard Berger for his contributions to an earlier version of this work. We also thank Mark DeMaria for providing the SHIPS developmental dataset. This work is supported under the NOAA GOES-R Risk Reduction project and by the Office of Naval Research under Grant N00014-07-1-0163. Earlier work related to this project was funded by the NOAA Hurricane Supplemental Research Program and NRL-MRY Satellite Applications Grant N00173-01-C-2024.	Bellman R., 1957, DYNAMIC PROGRAMMING; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bister M, 1998, METEOROL ATMOS PHYS, V65, P233, DOI 10.1007/BF01030791; BLACK ML, 1992, MON WEATHER REV, V120, P947, DOI 10.1175/1520-0493(1992)120<0947:TCECOH>2.0.CO;2; Briggs W, 2005, MON WEATHER REV, V133, P3382, DOI 10.1175/MWR3032.1; Briggs W, 2005, BIOMETRICS, V61, P799, DOI 10.1111/j.1541-0420.2005.00347.x; Camp JP, 2001, MON WEATHER REV, V129, P1704, DOI 10.1175/1520-0493(2001)129<1704:HMIPAP>2.0.CO;2; DEMARIA M, 1994, WEATHER FORECAST, V9, P209, DOI 10.1175/1520-0434(1994)009<0209:ASHIPS>2.0.CO;2; DeMaria M, 2005, WEATHER FORECAST, V20, P531, DOI 10.1175/WAF862.1; DeMaria M, 1999, WEATHER FORECAST, V14, P326, DOI 10.1175/1520-0434(1999)014<0326:AUSHIP>2.0.CO;2; Dodge P, 1999, MON WEATHER REV, V127, P987, DOI 10.1175/1520-0493(1999)127<0987:TKSOAH>2.0.CO;2; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; ELSNER JB, 1994, WEATHER FORECAST, V9, P619, DOI 10.1175/1520-0434(1994)009<0619:AFSTCV>2.0.CO;2; Fortner L. E., 1958, B AM METEOROL SOC, V30, P633; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hawkins J. D., 2006, 27 C HURR TROP MET M; Hawkins J.D., 2004, 26 C HURR TROP MET M, p[2004, 17]; Houze RA, 2007, SCIENCE, V315, P1235, DOI 10.1126/science.1135650; Knaff JA, 2003, WEATHER FORECAST, V18, P204, DOI 10.1175/1520-0434(2003)018<0204:AH>2.0.CO;2; Knaff JA, 2008, WEATHER FORECAST, V23, P17, DOI 10.1175/2007WAF2007031.1; Knapp KR, 2007, J APPL REMOTE SENS, V1, DOI 10.1117/1.2712816; Kossin JP, 2000, J ATMOS SCI, V57, P3893, DOI 10.1175/1520-0469(2001)058<3893:UIBAHS>2.0.CO;2; Kossin JP, 2007, GEOPHYS RES LETT, V34, DOI 10.1029/2006GL028836; Kossin JP, 2007, WEATHER FORECAST, V22, P89, DOI 10.1175/WAF985.1; Kuo HC, 2004, J ATMOS SCI, V61, P2722, DOI 10.1175/JAS3286.1; Kwon YC, 2008, J ATMOS SCI, V65, P106, DOI 10.1175/2007JAS2132.1; Landsea CW, 2004, B AM METEOROL SOC, V85, P1699, DOI 10.1175/BAMS-85-11-1699; MOLINARI J, 1989, J ATMOS SCI, V46, P1093, DOI 10.1175/1520-0469(1989)046<1093:EIOHIP>2.0.CO;2; Montgomery MT, 1997, Q J ROY METEOR SOC, V123, P435, DOI 10.1002/qj.49712353810; Nong SY, 2003, Q J ROY METEOR SOC, V129, P3323, DOI 10.1256/qj.01.132; OOYAMA K, 1969, J ATMOS SCI, V26, P3, DOI 10.1175/1520-0469(1969)026<0003:NSOTLC>2.0.CO;2; Rozoff CM, 2008, Q J ROY METEOR SOC, V134, P583, DOI 10.1002/qj.237; Rozoff CM, 2006, J ATMOS SCI, V63, P325, DOI 10.1175/JAS3595.1; SAMSURY CE, 1995, MON WEATHER REV, V123, P3502, DOI 10.1175/1520-0493(1995)123<3502:SWMIHA>2.0.CO;2; SHAPIRO LJ, 1982, J ATMOS SCI, V39, P378, DOI 10.1175/1520-0469(1982)039<0378:TROBHT>2.0.CO;2; TERWEY WD, 2006, 27 C HURR TROP MET M; Wang YQ, 2008, J ATMOS SCI, V65, P1158, DOI 10.1175/2007JAS2426.1; Wilks DS, 2006, INT GEOPHYS SERIES, V91; WILLOUGHBY HE, 1982, J ATMOS SCI, V39, P395, DOI 10.1175/1520-0469(1982)039<0395:CEWSWM>2.0.CO;2; Willoughby HE, 1996, B AM METEOROL SOC, V77, P543, DOI 10.1175/1520-0477(1996)077<0543:HAIFDO>2.0.CO;2; Wu LG, 2006, J ATMOS SCI, V63, P65, DOI 10.1175/JAS3597.1; ZHANG H, 2006, PATTERN RECOGN LETT, V27, P830; Zhu T, 2004, MON WEATHER REV, V132, P225, DOI 10.1175/1520-0493(2004)132<0225:NSOHBP>2.0.CO;2	43	29	29	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	0027-0644			MON WEATHER REV	Mon. Weather Rev.	MAR	2009	137	3					876	892		10.1175/2008MWR2701.1		17	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	435TS	WOS:000265366800006	
J	Wang, XW; Qu, HB; Liu, P; Cheng, YY				Wang, XW; Qu, HB; Liu, P; Cheng, YY			A self-learning expert system for diagnosis in traditional Chinese medicine	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						traditional Chinese medicine; expert system; Bayesian network; data mining; diagnosis	BAYESIAN NETWORKS	A novel self-learning expert system for diagnosis in Traditional Chinese medicine (TCM) was constructed by incorporating several data mining techniques, mainly including an improved hybrid Bayesian network learning algorithm, Naive-Bayes classifiers with a novel score-based strategy for feature selection and a method for mining constrained association rules. The data-driven nature distinguished the system from those existing TCM expert systems based on if-then rules to address knowledge elicitation problem. Moreover, the learned knowledge was provided in multiple forms including causal diagram, association rule and reasoning rules derived from classifiers. Finally, five representative cases were diagnosed to evaluate the performance of the system and the encouraging results were obtained. The results show that the prototype system performs well in diagnosis of TCM, and could be expected to be useful in the practice of TCM. (C) 2003 Elsevier Ltd. All rights reserved.	Zhejiang Univ, Coll Pharmaceut Sci, Pharmaceut Informat Inst, Hangzhou 310027, Peoples R China	Qu, HB (reprint author), Zhejiang Univ, Coll Pharmaceut Sci, Pharmaceut Informat Inst, POX, Hangzhou 310027, Peoples R China.	quhb@zju.edu.cn	wang, xuewei/C-7773-2009				Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Chen W, 2002, J NANOSCI NANOTECHNO, V2, P47, DOI 10.1166/jnn.2002.067; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; CHENG J, 2001, P 14 BIENN C CAN SOC, P141; Cheng J., 1999, P 15 C UNC ART INT U, P101; CHICKERING D., 1995, P 5 C ART INT STAT F, P112; DONG Y, 2002, J ZHEJIANG U, V7, P445; Duda R., 1973, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Han J., 2001, DATA MINING CONCEPTS; HAN JW, 2000, P 2000 ACM SIGMOD IN; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; HECKERMAN D, 1995, COMMUN ACM, V38, P24, DOI 10.1145/203330.203334; IGOR K, 2001, ARTIF INTELL, V23, P89; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; MA B, 1994, EXPERT SYSTEMS KNOWL; PAL SK, 2002, CURRENT SCI, V5, P518; Pearl J., 1988, PROBABILISTIC REASON; Spirtes P., 1993, LECT NOTES STAT, V81; Spirtes P, 1995, P 1 INT C KNOWL DISC, P294; ZHU WF, 2001, CHINESE J BASIC MED, V4, P4	23	29	30	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	MAY	2004	26	4					557	566		10.1016/j.eswa.2003.10.004		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	804DL	WOS:000220279300009	
J	Granitto, PM; Navone, HD; Verdes, PF; Ceccatto, HA				Granitto, PM; Navone, HD; Verdes, PF; Ceccatto, HA			Weed seeds identification by machine vision	COMPUTERS AND ELECTRONICS IN AGRICULTURE			English	Article						machine vision; seed identification; classification; neural networks	DIGITAL IMAGE-ANALYSIS; GRAIN COLOR ANALYSIS; FEATURE-SELECTION; WHEAT CLASS; DISCRIMINATION; QUALITY; SAMPLES	The implementation of new methods for reliable and fast identification and classification of seeds is of major technical and economical importance in the agricultural industry. As in ocular inspection, the automatic classification of seeds should be based on knowledge of seed size, shape, color and texture. In this work, we assess the discriminating power of these characteristics for the unique identification of seeds of 57 weed species. Using the performance of a naive Bayes classifier as selection criterion, we identified a nearly optimal set of 12 (six morphological + four color + two textural) seed characteristics to be used as classification parameters. We found that, as expected, size and shape characteristics have larger discriminating power than color and textural ones. However, all these features are required to reach an identification performance acceptable for practical applications. In spite of its simplicity, the naive Bayes classifier reveals itself surprisingly good for the identification of seed species. This might be due to the careful selection of the feature set, leading to nearly independent parameters as assumed by this method. We also found that, using the same feature set, a more sophisticated classifier based on an artificial neural network committee performs only slightly better than this simple Bayesian approach. (C) 2002 Elsevier Science B.V. All rights reserved.	Consejo Nacl Invest Cient & Tecn, Inst Fis Rosario, IFIR, RA-2000 Rosario, Santa Fe, Argentina; Univ Nacl Rosario, RA-2000 Rosario, Santa Fe, Argentina	Ceccatto, HA (reprint author), Consejo Nacl Invest Cient & Tecn, Inst Fis Rosario, IFIR, Blvd 27 Febrero 210 Bis, RA-2000 Rosario, Santa Fe, Argentina.		Granitto, Pablo/A-3645-2013				Ahmad IS, 1999, PLANT DIS, V83, P320, DOI 10.1094/PDIS.1999.83.4.320; Chtioui Y, 1998, J SCI FOOD AGR, V76, P77, DOI 10.1002/(SICI)1097-0010(199801)76:1<77::AID-JSFA948>3.0.CO;2-9; Bishop C.M., 1995, NEURAL NETWORKS PATT; CHEN C, 1989, CEREAL CHEM, V66, P466; Chtioui Y, 1996, J SCI FOOD AGR, V71, P433, DOI 10.1002/(SICI)1097-0010(199608)71:4<433::AID-JSFA596>3.3.CO;2-2; CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X; DIETTERICH TG, 1996, PROPER STAT TESTS CO; DRAPER S R, 1984, Journal of the National Institute of Agricultural Botany, V16, P387; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JANSEN PI, 1995, SEED SCI TECHNOL, V23, P353; KEEFE PD, 1986, SEED SCI TECHNOL, V14, P715; NAVONE HD, 2000, P 6 INT C INF ENG U; NEUMAN M, 1987, J CEREAL SCI, V6, P125; NEUMAN MR, 1989, J CEREAL SCI, V10, P183; NEUMAN MR, 1989, J CEREAL SCI, V10, P175; PETERSEN PEH, 1992, SEED SCI TECHNOL, V20, P193; SAPIRSTEIN HD, 1987, J CEREAL SCI, V6, P3; SYMONS SJ, 1988, J CEREAL SCI, V8, P211, DOI 10.1006/jcrs.1993.1048; ZAYAS I, 1986, CEREAL CHEM, V63, P52; ZAYAS I, 1989, CEREAL CHEM, V66, P233	22	29	33	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0168-1699			COMPUT ELECTRON AGR	Comput. Electron. Agric.	FEB	2002	33	2					91	103		10.1016/S0168-1699(02)00004-2		13	Agriculture, Multidisciplinary; Computer Science, Interdisciplinary Applications	Agriculture; Computer Science	538QP	WOS:000174826800002	
J	Moler, EJ; Radisky, DC; Mian, IS				Moler, EJ; Radisky, DC; Mian, IS			Integrating naive Bayes models and external knowledge to examine copper and iron homeostasis in S-cerevisiae	PHYSIOLOGICAL GENOMICS			English	Article						molecular profile matrix; gene profile vectors; naive Bayes model; copper and iron metabolism; Bayesian networks	SELF-ORGANIZING MAPS; GENE-EXPRESSION; PATTERNS; PROTEIN; DATABASE; TUMOR	A novel suite of analytical techniques and visualization tools are applied to 78 published transcription profiling experiments monitoring 5,687 Saccharomyces cerevisiae genes in studies examining cell cycle, responses to stress, and diauxic shift. A naive Bayes model discovered and characterized 45 classes of gene profile vectors. An enrichment measure quantified the association between these classes and specific external knowledge defined by four sets of categories to which genes can be assigned: 106 protein functions, 5 stages of the cell cycle, 265 transcription factors, and 16 chromosomal locations. Many of the 38 genes in class 42 are known to play roles in copper and iron homeostasis. The 17 uncharacterized open reading frames in this class may be involved in similar homeostatic processes; human homologs of two of them could be associated with as yet undefined disease states arising from aberrant metal ion regulation. The Met4, Met31, and Met32 transcription factors may play a role in coregulating genes involved in copper and iron metabolism. Extensions of the simple graphical model used for clustering to learning more complex models of genetic networks are discussed.	Univ Calif Berkeley, Lawrence Berkeley Natl Lab, Dept Cell & Mol Biol, Radiat Biol & Environm Toxicol Grp,Life Sci Div, Berkeley, CA 94720 USA	Mian, IS (reprint author), Univ Calif Berkeley, Lawrence Berkeley Natl Lab, Dept Cell & Mol Biol, Radiat Biol & Environm Toxicol Grp,Life Sci Div, MS 74-197,1 Cyclotron Rd, Berkeley, CA 94720 USA.						Aach J, 2000, GENOME RES, V10, P431, DOI 10.1101/gr.10.4.431; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; D'haeseleer P, 1999, Pac Symp Biocomput, P41; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FRIEDMAN N, 2000, USING BAYESIAN NETWO; Fuhrman S., 1998, PAC S BIOCOMPUT, V3, P18; Goss PJE, 1998, P NATL ACAD SCI USA, V95, P6750, DOI 10.1073/pnas.95.12.6750; HASTIE T, 2000, GENE SHAVING NEW CLA; Hodges PE, 1999, NUCLEIC ACIDS RES, V27, P69, DOI 10.1093/nar/27.1.69; Jensen V.F., 1996, INTRO BAYESIAN NETWO; Jordan M.I., 1998, LEARNING GRAPHICAL M; Kauffman S., 1993, ORIGINS ORDER SELF O; Matsuno H., 2000, PAC S BIOC, V5, P338; Mewes HW, 1999, NUCLEIC ACIDS RES, V27, P44, DOI 10.1093/nar/27.1.44; Moler EJ, 2000, PHYSIOL GENOMICS, V4, P109; MURPHY K, 1999, MODELLNG GENE EXPRES; Pearl J., 1988, PROBABILISTIC REASON; Radisky D, 1999, J BIOL CHEM, V274, P4481, DOI 10.1074/jbc.274.8.4481; RAYCHAUDHURI R, 2000, PAC S BIOC, V5, P452; Sanchez JC, 1997, ELECTROPHORESIS, V18, P150, DOI 10.1002/elps.1150180127; Sjolander K, 1996, COMPUT APPL BIOSCI, V12, P327; SOMOGYI R., 1996, COMPLEXITY, V1, P45; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tavazoie S, 1999, NAT GENET, V22, P281; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4; Weaver D C, 1999, Pac Symp Biocomput, P112; Wen XL, 1998, P NATL ACAD SCI USA, V95, P334, DOI 10.1073/pnas.95.1.334; YUN CY, IN PRESS J BIOL CHEM	31	29	29	AMER PHYSIOLOGICAL SOC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA	1094-8341			PHYSIOL GENOMICS	Physiol. Genomics	DEC 18	2000	4	2					127	135				9	Cell Biology; Genetics & Heredity; Physiology	Cell Biology; Genetics & Heredity; Physiology	383WR	WOS:000165908100003	
J	Acharya, UR; Molinari, F; Sree, SV; Chattopadhyay, S; Ng, KH; Suri, JS				Acharya, U. Rajendra; Molinari, Filippo; Sree, S. Vinitha; Chattopadhyay, Subhagata; Ng, Kwan-Hoong; Suri, Jasjit S.			Automated diagnosis of epileptic EEG using entropies	BIOMEDICAL SIGNAL PROCESSING AND CONTROL			English	Article						Epilepsy; Preictal; Entropy; EEG; Feature extraction; Classifiers	TEMPORAL-LOBE EPILEPSY; TIME-SERIES ANALYSIS; HIGHER-ORDER SPECTRA; APPROXIMATE ENTROPY; SEIZURE DETECTION; NEURAL-NETWORKS; SIGNALS; CLASSIFICATION; IDENTIFICATION; DYNAMICS	Epilepsy is a neurological disorder characterized by the presence of recurring seizures. Like many other neurological disorders, epilepsy can be assessed by the electroencephalogram (EEG). The EEG signal is highly non-linear and non-stationary, and hence, it is difficult to characterize and interpret it. However, it is a well-established clinical technique with low associated costs. In this work, we propose a methodology for the automatic detection of normal, pre-ictal, and ictal conditions from recorded EEG signals. Four entropy features namely Approximate Entropy (ApEn), Sample Entropy (SampEn), Phase Entropy 1 (Si), and Phase Entropy 2 (S2) were extracted from the collected EEG signals. These features were fed to seven different classifiers: Fuzzy Sugeno Classifier (FSC), Support Vector Machine (SVM), K-Nearest Neighbour (KNN), Probabilistic Neural Network (PNN), Decision Tree (DT), Gaussian Mixture Model (GMM), and Naive Bayes Classifier (NBC). Our results show that the Fuzzy classifier was able to differentiate the three classes with a high accuracy of 98.1%. Overall, compared to previous techniques, our proposed strategy is more suitable for diagnosis of epilepsy with higher accuracy. (C) 2011 Elsevier Ltd. All rights reserved.	[Acharya, U. Rajendra] Ngee Ann Polytech, Dept Elect & Comp Engn, Singapore 599489, Singapore; [Molinari, Filippo] Politecn Torino, Dept Elect, I-10129 Turin, Italy; [Sree, S. Vinitha] Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore 639798, Singapore; [Chattopadhyay, Subhagata] Natl Inst Sci & Technol, Dept Comp Sci & Engn, Berhampur, Orissa, India; [Ng, Kwan-Hoong] Univ Malaya, Dept Biomed Imaging, Kuala Lumpur, Malaysia; [Ng, Kwan-Hoong] Univ Malaya, Res Imaging Ctr, Kuala Lumpur, Malaysia; [Suri, Jasjit S.] Global Biomed Technol, CTO, San Diego, CA USA; [Suri, Jasjit S.] Idaho State Univ, Dept Biomed Engn, Pocatello, ID USA	Acharya, UR (reprint author), Ngee Ann Polytech, Dept Elect & Comp Engn, Singapore 599489, Singapore.	aru@np.edu.sg	Ng, Kwan-Hoong/D-2231-2009				Acharya UR, 2011, INT J NEURAL SYST, V21, P199, DOI 10.1142/S0129065711002808; Acharya U.R., 2004, PHYSL MEASUREMENT J, V25, P1130; Acharya UR, 2009, J MECH MED BIOL, V9, P539, DOI 10.1142/S0219519409003152; Andrzejak RG, 2001, EPILEPSY RES, V44, P129, DOI 10.1016/S0920-1211(01)00195-4; Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907; [Anonymous], WHO REP; [Anonymous], PHYSIOTOOLKIT; [Anonymous], EEG TIM SER DAT; BABLOYANTZ A, 1985, PHYS LETT A, V111, P152, DOI 10.1016/0375-9601(85)90444-X; Chua C. K., 2011, J MED SYST, V35, P1563, DOI DOI 10.1007/S10916-010-9433-Z; Chua K. C., 2009, Journal of Medical Engineering & Technology, V33, P42, DOI 10.1080/03091900701559408; Chua KC, 2009, P I MECH ENG H, V223, P485, DOI 10.1243/09544119JEIM484; Coyle D, 2010, BIOMED SIGNAL PROCES, V5, P196, DOI 10.1016/j.bspc.2010.03.004; Faust O, 2010, INT J NEURAL SYST, V20, P159, DOI 10.1142/S0129065710002334; Fisher RS, 2005, EPILEPSIA, V46, P470, DOI 10.1111/j.0013-9580.2005.66104.x; Ghosh-Dastidar S, 2009, NEURAL NETWORKS, V22, P1419, DOI 10.1016/j.neunet.2009.04.003; Ghosh-Dastidar S, 2007, IEEE T BIO-MED ENG, V54, P1545, DOI 10.1109/TBME.2007.891945; Ghosh-Dastidar S, 2007, INTEGR COMPUT-AID E, V14, P187; Ghosh-Dastidar S, 2008, IEEE T BIO-MED ENG, V55, P512, DOI 10.1109/TBME.2007.905490; Grossberger P., 1983, PHYSICA D, V9, P189; Guler NF, 2005, EXPERT SYST APPL, V29, P506, DOI 10.1016/j.eswa.2005.04.011; Han J., 2005, DATA MINING CONCEPTS; Iasemidis L.D., 2004, IEEE T BIOMED ENG, V51, P493; Ince NF, 2009, BIOMED SIGNAL PROCES, V4, P236, DOI 10.1016/j.bspc.2009.03.005; Kannathal N, 2005, COMPUT METH PROG BIO, V80, P187, DOI 10.1016/j.cmpb.2005.06.012; Kannathal N, 2005, COMPUT METH PROG BIO, V80, P17, DOI 10.1016/j.cmpb.2005.06.005; Kapetanovic IM, 2004, ANN NY ACAD SCI, V1020, P10, DOI 10.1196/annals.1310.003; KAPLAN DT, 1991, BIOPHYS J, V59, P945; KENNEL MB, 1992, PHYS REV A, V45, P3403, DOI 10.1103/PhysRevA.45.3403; Lehnertz K, 1998, PHYS REV LETT, V80, P5019, DOI 10.1103/PhysRevLett.80.5019; Lehnertz K., 2008, J BIOL PHYS, V33, P253; Martinerie J, 1998, NAT MED, V4, P1173, DOI 10.1038/2667; Mormann F, 2005, CLIN NEUROPHYSIOL, V116, P569, DOI 10.1016/j.clinph.2004.08.025; Mormann F, 2003, EPILEPSY RES, V53, P173, DOI 10.1016/S0920-1211(03)00002-0; Motulsky H, 2010, INTUITIVE BIOSTATIST; Nigam VP, 2004, NEUROL RES, V26, P55, DOI 10.1179/016164104225013590; Nikias C.L., 1993, HIGHER ORDER SPECTRA; Ocak H, 2009, EXPERT SYST APPL, V36, P2027, DOI 10.1016/j.eswa.2007.12.065; Petitmengin C, 2006, EPILEPSY BEHAV, V9, P298, DOI 10.1016/j.yebeh.2006.05.013; PINCUS SM, 1992, AM J PHYSIOL, V262, pE741; PINCUS SM, 1991, P NATL ACAD SCI USA, V88, P2297, DOI 10.1073/pnas.88.6.2297; Polat K., 2007, APPL MATH COMPUT, V32, P625; Rajendra Acharya U., 2005, COMPUT METH PROG BIO, V80, P37, DOI DOI 10.1016/J.CMPB.2005.06.011; RAVELLI F, 1992, BIOL CYBERN, V67, P57, DOI 10.1007/BF00201802; Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039; Ross TJ, 2004, FUZZY LOGIC ENG APPL; Ruiz R. A. S., 2010, BIOSIGNAL PROCESSING, V6, P77; Sadati N, 2006, IEEE INT CONF FUZZY, P596, DOI 10.1109/FUZZY.2006.1681772; Sleigh J.W., 2001, P 5 INT C MEM AW CON; Song Y., 2010, J BIOMEDICAL SCI ENG, V3, P556; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Srinivasan V, 2007, IEEE T INF TECHNOL B, V11, P288, DOI 10.1109/TITB.2006.884369; Srinivasan V, 2005, J Med Syst, V29, P647, DOI 10.1007/s10916-005-6133-1; Subasi A, 2007, EXPERT SYST APPL, V32, P1084, DOI 10.1016/j.eswa.2006.02.005; Subasi A, 2010, EXPERT SYST APPL, V37, P8659, DOI 10.1016/j.eswa.2010.06.065; Subha DP, 2010, J MED SYST, V34, P195, DOI 10.1007/s10916-008-9231-z; Thakor NV, 2004, ANNU REV BIOMED ENG, V6, P453, DOI 10.1146/annurev.bioeng.5.040202.121601; Tzallas A.T., 2007, COMPUTATIONAL INTELL, V18; Yaari Y, 2002, BRAIN PATHOL, V12, P234; Zhuo S.M., 2008, INF SCI, V178, P1629	60	28	29	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1746-8094			BIOMED SIGNAL PROCES	Biomed. Signal Process. Control	JUL	2012	7	4					401	408		10.1016/j.bspc.2011.07.007		8	Engineering, Biomedical; Medical Laboratory Technology	Engineering; Medical Laboratory Technology	953CB	WOS:000304843400011	
J	Liu, Y; Loh, HT; Sun, AX				Liu, Ying; Loh, Han Tong; Sun, Aixin			Imbalanced text classification: A term weighting approach	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Text classification; Imbalanced data; Term weighting scheme	CATEGORIZATION	The natural distribution of textual data used in text classification is often imbalanced. Categories with fewer examples are under-represented and their classifiers often perform far below satisfactory. We tackle this problem using a simple probability based term weighting scheme to better distinguish documents in minor categories. This new scheme directly utilizes two critical information ratios, i.e. relevance indicators. Such relevance indicators are nicely supported by probability estimates which embody the category membership. Our experimental study using both Support Vector Machines and Naive Bayes classifiers and extensive comparison with other classic weighting schemes over two benchmarking data sets, including Reuters-21578, shows significant improvement for minor categories, while the performance for major categories are not jeopardized. Our approach has suggested a simple and effective solution to boost the performance of text classification over skewed data sets. (C) 2007 Elsevier Ltd. All rights reserved.	[Liu, Ying] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Kowloon, Hong Kong, Peoples R China; [Loh, Han Tong] Natl Univ Singapore, Dept Mech Engn, Singapore 117576, Singapore; [Sun, Aixin] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Liu, Y (reprint author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Kowloon, Hong Kong, Peoples R China.	mfyliu@polyu.edu.hk	Sun, Aixin/A-9852-2008	Sun, Aixin/0000-0003-0764-4258	Research Grants Council of the Hong Kong Polytechnic University, Hong Kong Special Administrative Region, China [G-YF59]	The work described in this paper was partially supported by a grant from the Research Grants Council of the Hong Kong Polytechnic University, Hong Kong Special Administrative Region, China (Project No. G-YF59).	Baeza-Yates R., 1999, MODERN INFORM RETRIE; Baoli L., 2004, ACM T ASIAN LANGUAGE, V3, P215, DOI 10.1145/1039621.1039623; Blum A., 1998, COLT, P92; Brank J., 2003, MSRTR200334; Castle S, 2004, CULT HEALTH SEX, V6, P1, DOI 10.1080/13691050310001622460; CHAWLA N, 2003, P ICML2003 WORKSH LE; Debole F., 2003, P SAC 03 18 ACM S AP, P784; DIETTERICH T, 2000, P ICML2000 WORKSH CO; Dumais Susan, 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593; Elkan C., 2001, P 17 INT JOINT C ART, P973; Fan W, 2004, LECT NOTES COMPUT SC, V2992, P801; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; GHANI R, 2002, INT C MACH LEARN ICM; Goldman S., 2000, P 17 INT C MACH LEAR, P327; Japkowicz N., 1995, P 14 JOINT C ART INT, P518; JAPKOWICZ N, 2000, P AAAI2000 WORKSH LE; Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings; Joachims T., 2001, P 24 ANN INT ACM SIG, P128, DOI 10.1145/383952.383974; Kolcz A., 2004, ACM SIGKDD EXPLORATI, V<IT>6</IT>; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Lewis D., 1994, P 17 ANN INT ACM SIG, P3; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Liu AY, 2004, THESIS U TEXAS AUSTI; Liu B., 2003, P 3 IEEE INT C DAT M; Liu Y, 2007, LECT NOTES COMPUT SC, V4692, P542; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; NG HT, 1997, ACM SIGIR FOR P 20 A, P67; Nickerson A.S., 2001, P 8 INT WORKSH AI ST, P261; Nigam K., 2001, THESIS CARNEGIE MELL; Raskutti B., 2004, SIGKDD EXPLORATIONS, V6, P60, DOI DOI 10.1145/1007730.1007739; Rennie J, 2003, P 20 INT C MACH LEAR, P616; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Salton G., 1983, INTRO MODERN INFORM; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Sun AX, 2004, IEEE T KNOWL DATA EN, V16, P1305, DOI 10.1109/TKDE.2004.50; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; Vapnik V., 1999, NATURE STAT LEARNING; Weiss G., 2004, ACM SIGKDD EXPLORATI, V6, P7, DOI 10.1145/1007730.1007734; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Witten IH, 2005, DATA MINING PRACTICA; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y., 1996, P AAAI SPRING S MACH, P88; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Yu H., 2003, P 2003 ACM CIKM INT, P232; ZELIKOVITZ S, 2000, P 17 INT C MACH LEAR; Zheng Z., 2004, ACM SIGKDD EXPLORATI, V6, P80, DOI DOI 10.1145/1007730.1007741	49	28	31	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	JAN	2009	36	1					690	701		10.1016/j.eswa.2007.10.042		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	418XI	WOS:000264182800069	
J	Yang, Y; Webb, GI				Yang, Ying; Webb, Geoffrey I.			Discretization for naive-Bayes learning: managing discretization bias and variance	MACHINE LEARNING			English	Article						Discretization; Naive-Bayes Learning; Bias; Variance	NETWORK CLASSIFIERS; ASSUMPTION	Quantitative attributes are usually discretized in Naive-Bayes learning. We establish simple conditions under which discretization is equivalent to use of the true probability density function during naive-Bayes learning. The use of different discretization techniques can be expected to affect the classification bias and variance of generated naive-Bayes classifiers, effects we name discretization bias and variance. We argue that by properly managing discretization bias and variance, we can effectively reduce naive-Bayes classification error. In particular, we supply insights into managing discretization bias and variance by adjusting the number of intervals and the number of training instances contained in each interval. We accordingly propose proportional discretization and fixed frequency discretization, two efficient unsupervised discretization methods that are able to effectively manage discretization bias and variance. We evaluate our new techniques against four key discretization methods for naive-Bayes classifiers. The experimental results support our theoretical analyses by showing that with statistically significant frequency, naive-Bayes classifiers trained on data discretized by our new methods are able to achieve lower classification error than those trained on data discretized by current established discretization methods.	[Yang, Ying] Australian Taxat Off, Box Hill, Vic 3128, Australia; [Webb, Geoffrey I.] Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia	Yang, Y (reprint author), Australian Taxat Off, 990 Whitehorse Rd, Box Hill, Vic 3128, Australia.	ying.yang@ato.gov.au; geoff.webb@infotech.monash.edu.au					A An, 1999, P 3 PAC AS C KNOWL D, P509; Acid S, 2005, MACH LEARN, V59, P213; Androutsopoulos I., 2000, P 23 ANN INT ACM SIG, P160, DOI 10.1145/345508.345569; BAY SD, 1999, UCI KDD ARCH; Blake C. L., 1998, UCI REPOSITORY MACHI; BLUMAN AG, 1992, ELEMENTARY STAT STEP; BREIMAN L, 1996, 460 U CAL STAT DEP, P460; Casella G, 1990, STAT INFERENCE; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Cerquides J, 2005, MACH LEARN, V59, P323, DOI 10.1007/s10994-005-0470-7; Cestnik B, 1990, P EUR C ART INT, P147; Cestnik B., 1987, PROGR MACHINE LEARNI, P31; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Crawford E., 2002, P 19 INT C MACH LEAR, P83; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; FREITAS AA, 1996, P 14 BRIT NAT C DAT, P124; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372; Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Gama J, 1998, LECT NOTES ARTIF INT, V1484, P160; Hsu C., 2000, P 17 INT C MACH LEAR, P309; Hsu CN, 2003, MACH LEARN, V53, P235, DOI 10.1023/A:1026367023636; Hussain F., 1999, TRC699 NAT U SING SC; JOHN GH, 1995, P 11 C UNC ART INT, P338; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Kerber R., 1992, NAT C ART INT, P123; Kohav R., 1996, P 13 INT C MACH LEAR, P275; Kong E. B., 1995, P 12 INT C MACH LEAR, P313; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; KONONENKO I, 1990, COMP INDUCTIVE NAIVE; KONONENKO I, 1992, INFORMATICA, V16, P1; Langley P., 1993, P 1993 EUR C MACH LE, P153; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; Lavrac N., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; LAVRAC N, 2000, ENCY COMP S S27, V42, P113; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; MARON ME, 1960, J ACM, V7, P216, DOI 10.1145/321033.321035; Mitchell T.M., 1997, MACHINE LEARNING; Miyahara K., 2000, PRICAI 2000. Topics in Artificial Intelligence. 6th Pacific Rim International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol.1886); Mooney R.J., 2000, P 5 ACM C DIG LIB, P195, DOI DOI 10.1145/336597.336662; Moore D.S., 2002, INTRO PRACTICE STAT; MORA L, 2000, P 11 EUR C MACH LEAR, P280; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Pazzani M.J., 1995, P 1 INT C KNOWL DISC, P228; PERNER P, 1998, P JOINT IAPR INT WOR, P475; Provost FJ, 1996, MACH LEARN, V23, P33; Sahami M., 1996, P 2 INT C KNOWL DISC, P334; Samuels ML, 1999, STAT LIFE SCI; Singh M., 1996, P 13 INT C MACH LEAR, P453; STARR B, 1996, P ACM C HUM FACT COM, P273; Torgo L., 1997, P 9 EUR C MACH LEARN, P266; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Weiss N, 2002, INTRO STAT; YANG Y, 2003, P 16 AUSTR C AI AI 0, P440; Yang Y., 2001, P 12 EUR C MACH LEAR, P564; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	64	28	28	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JAN	2009	74	1					39	74		10.1007/s10994-008-5083-5		36	Computer Science, Artificial Intelligence	Computer Science	389WO	WOS:000262125400003	
J	Hong, JH; Min, JK; Cho, UK; Cho, SB				Hong, Jin-Hyuk; Min, Jun-Ki; Cho, Ung-Keun; Cho, Sung-Bae			Fingerprint classification using one-vs-all support vector machines dynamically ordered with naive Bayes classifiers	PATTERN RECOGNITION			English	Article						fingerprint classification; support vector machine; FingerCode; naive bayes classifier; singularity; pseudo ridges; dynamic classification	DECISION TEMPLATES; NEURAL NETWORKS; FUSION; STRATEGIES; EXTRACTION	Fingerprint classification reduces the number of possible matches in automated fingerprint identification systems by categorizing fingerprints into predefined classes. Support vector machines (SVMs) are widely used in pattern classification and have produced high accuracy when performing fingerprint classification. In order to effectively apply SVMs to multi-class fingerprint classification systems, we propose a novel method in which the SVMs are generated with the one-vs-all (OVA) scheme and dynamically ordered with naive Bayes classifiers. This is necessary to break the ties that frequently occur when working with multi-class classification systems that use OVA SVMs. More specifically, it uses representative fingerprint features as the FingerCode, singularities and pseudo ridges to train the OVA SVMs and naive Bayes classifiers. The proposed method has been validated on the NIST-4 database and produced a classification accuracy of 90.8% for five-class classification with the statistical significance. The results show the benefits of integrating different fingerprint features as well as the usefulness of the proposed method in multi-class fingerprint classification. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Yonsei Univ, Biometr Engn Res Ctr, Dept Comp Sci, Seoul 120749, South Korea	Hong, JH (reprint author), Yonsei Univ, Biometr Engn Res Ctr, Dept Comp Sci, 134 Shinchon Dong, Seoul 120749, South Korea.	hjinh@sclab.yonsei.ae.kr; loomlike@sclab.yonsei.ac.kr; bearoot@sclab.yonsei.ac.kr; sbeho@cs.yonsei.ac.kr					BOLAND P, 1998, STATISTICIAN, V38, P181; Bredensteiner EJ, 1999, COMPUT OPTIM APPL, V12, P53, DOI 10.1023/A:1008663629662; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; Chang JH, 2002, PATTERN RECOGN, V35, P1209, DOI 10.1016/S0031-3203(01)00121-2; Chong MMS, 1997, PATTERN RECOGN, V30, P1475, DOI 10.1016/S0031-3203(96)00178-1; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; GESTEL T, 2002, NEURAL PROCESS LETT, V15, P45; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; Kuncheva LI, 2001, FUZZY SET SYST, V122, P401, DOI 10.1016/S0165-0114(99)00161-X; Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X; Liu JNK, 2001, IEEE T SYST MAN CY C, V31, P249, DOI 10.1109/5326.941848; Nagaty KA, 2001, NEURAL NETWORKS, V14, P1293, DOI 10.1016/S0893-6080(01)00086-7; Nyongesa HO, 2004, J INTELL ROBOT SYST, V40, P103, DOI 10.1023/B:JINT.0000034344.58449.fd; Park CH, 2005, PATTERN RECOGN, V38, P495, DOI 10.1016/j.patcog.2004.08.013; Ramoni M, 2001, ARTIF INTELL, V125, P209, DOI 10.1016/S0004-3702(00)00085-0; Raudys A, 2003, LECT NOTES COMPUT SC, V2709, P55; Ruta D., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.008; Sebald DJ, 2001, IEEE T SIGNAL PROCES, V49, P2865, DOI 10.1109/78.960434; Senior A, 2001, IEEE T PATTERN ANAL, V23, P1165, DOI 10.1109/34.954606; WATSON CI, 1992, FINGERPRINT DATABASE, P4; Wu TF, 2004, J MACH LEARN RES, V5, P975; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yager N, 2004, PATTERN ANAL APPL, V7, P77, DOI 10.1007/s10044-004-0204-7; Yao Y, 2003, PATTERN RECOGN, V36, P397; Zhang QZ, 2004, PATTERN RECOGN, V37, P2233, DOI 10.1016/j.patcog.2003.12.020	31	28	31	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	FEB	2008	41	2					662	671		10.1016/j.patcog.2007.07.004		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	227ZC	WOS:000250695500020	
J	Mitra, V; Wang, CJ; Banerjee, S				Mitra, Vikramjit; Wang, Chia-Jiu; Banerjee, Satarupa			Text classification: A least square support vector machine approach	APPLIED SOFT COMPUTING			English	Article						least square support vector machines; latent semantic indexing; text classification; kernel based learning algorithms	LATENT SEMANTIC ANALYSIS	This paper presents a least square support vector machine ( LS-SVM) that performs text classification of noisy document titles according to different predetermined categories. The system's potential is demonstrated with a corpus of 91,229 words from University of Denver's Penrose Library catalogue. The classification accuracy of the proposed LS-SVM based system is found to be over 99.9%. The final classifier is an LS-SVM array with Gaussian radial basis function ( GRBF) kernel, which uses the coefficients generated by the latent semantic indexing algorithm for classification of the text titles. These coefficients are also used to generate the confidence factors for the inference engine that present the final decision of the entire classifier. The system is also compared with a K-nearest neighbor ( KNN) and Naive Bayes ( NB) classifier and the comparison clearly claims that the proposed LS-SVM based architecture outperforms the KNN and NB based system. The comparison between the conventional linear SVM based classifiers and neural network based classifying agents shows that the LS-SVM with LSI based classifying agents improves text categorization performance significantly and holds a lot of potential for developing robust learning based agents for text classification. (c) 2006 Elsevier B. V. All rights reserved.	Univ Colorado, ECE Dept, Colorado Springs, CO 80309 USA; Univ Maryland, ECE Dept, College Pk, MD 20742 USA; Villanova Univ, CS Dept, Villanova, PA 19085 USA	Wang, CJ (reprint author), Univ Colorado, ECE Dept, Colorado Springs, CO 80309 USA.	vmitra@umd.edu; cwang@eas.uccs.edu; satarupa.banerjee@villanova.edu					Bellegarda JR, 1998, IEEE T SPEECH AUDI P, V6, P456, DOI 10.1109/89.709671; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cristianini N, 2002, J INTELL INF SYST, V18, P127, DOI 10.1023/A:1013625426931; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Foltz P., 1990, P C OFF INF SYST CAM, P40, DOI 10.1145/91474.91486; Foltz PW, 1998, DISCOURSE PROCESS, V25, P285; Gunn S. R., 1998, SUPPORT VECTOR MACHI; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHOLKOPF B, 1998, ADV KERN METH SUPP; Schunn C. D., 1995, THINK REASONING, V1, P237, DOI 10.1080/13546789508256910; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Van Gestel T., 2001, P EUR S ART NEUR NET, P13; VANGESTEL T, 2001, NEURAL PROCESS LETT, V54, P5; Van Gestel T, 2002, IEEE IJCNN, P2779, DOI 10.1109/IJCNN.2002.1007588; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V., 1995, NATURE STAT LEARNING; WAHBA G, 1990, CBMS NSF REG C SER A, V59; WERMTER S, 1999, P 9 INT C ART NEUR N, V2, P898; Yang S, 2002, J MATER SCI LETT, V21, P1, DOI 10.1023/A:1014211022224; Yang Y., 1999, 22 ANN INT ACM SIGIR, P42; Zheng Z., 2004, SIGKDD EXPLORATIONS, V6, P80	26	28	32	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946			APPL SOFT COMPUT	Appl. Soft. Comput.	JUN	2007	7	3					908	914		10.1016/j.asoc.2006.04.002		7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	157UU	WOS:000245747700024	
J	Williams, N; Zander, S; Armitage, G				Williams, Nigel; Zander, Sebastian; Armitage, Grenville			A preliminary performance comparison of five machine learning algorithms for practical IP traffic flow classification	ACM SIGCOMM COMPUTER COMMUNICATION REVIEW			English	Review						algorithms; measurement; traffic classification; machine learning		The identification of network applications through observation of associated packet traffic flows is vital to the areas of network management and surveillance. Currently popular methods such as port number and payload-based identification exhibit a number of shortfalls. An alternative is to use machine learning (ML) techniques and identify network applications based on per-flow statistics, derived from payload-independent features such as packet length and inter-arrival time distributions. The performance impact of feature set reduction, using Consistency-based and Correlation-based feature selection, is demonstrated on Naive Bayes, C4.5, Bayesian Network and Naive Bayes Tree algorithms. We then show that it is useful to differentiate algorithms based on computational performance rather than classification accuracy alone, as although classification accuracy between the algorithms is similar, computational performance can differ significantly.	Swinburne Univ Technol, CAIA, Melbourne, Vic, Australia	Williams, N (reprint author), Swinburne Univ Technol, CAIA, Melbourne, Vic, Australia.	niwilliams@swin.edu.au; szander@swin.edu.au; garmitage@swin.edu.au					BOUCKAERT R, 2002, BAYESIAN NETWORK CLA; Brownlee N., 1999, NETRAMET NEMAC REFER; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; DUNNIGAN T, 2000, FLOW CHARACTERIZATIO; Hall M., 1998, THESIS WAIKATO U HAM; JOHN GH, 1995, P 11 C UNC ART INT, P338; KARAGIANNIS T, 2005, P ACM SIGCOMM COMPUT; KARATIANNIS A, 2004, P GLOBECOM NOV DEC; Kohavi R., 1996, P 2 INT C KNOWL DISC; Kohavi R., 2002, HDB DATA MINING KNOW, P267; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; McGregor A., 2004, PASSIVE ACTIVE MEASU; Mitchell T.M., 1997, MACHINE LEARNING; Moore A., 2005, P ACM SIGMETRICS; ROUGHAN M, 2004, P ACM SIGCOMM INTERN; ZANDER S, 2005, P IEEE LCN AUST	16	28	30	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0146-4833	1943-5819		ACM SIGCOMM COMP COM	ACM SIGCOMM Comp. Commun. Rev.	OCT	2006	36	5					7	15				9	Computer Science, Information Systems	Computer Science	096RA	WOS:000241393300002	
J	Cao, J; Panetta, R; Yue, SY; Steyaert, A; Young-Bellido, M; Ahmad, S				Cao, J; Panetta, R; Yue, SY; Steyaert, A; Young-Bellido, M; Ahmad, S			A naive Bayes model to predict coupling between seven transmembrane domain receptors and G-proteins	BIOINFORMATICS			English	Article							MELANIN-CONCENTRATING HORMONE; IDENTIFICATION; SEQUENCE; ALIGNMENT; SUBTYPE; CLONING	Motivation: An understanding of the coupling between a G-protein coupled receptor (GPCR) and a specific class of heterotrimeric GTP-binding proteins (G-proteins) is vital for further comprehending the function of the receptor within a cell. However, predicting G-protein coupling based on the amino acid sequence of a receptor has been a daunting task. While experimental data for G-protein coupling exist, published models that rely on sequence based prediction are few. In this study, we have developed a Naive Bayes model to successfully predict G-protein coupling specificity by training over 80 GPCRs with known coupling. Each intracellular domain of GPCRs was treated as a discrete random variable, conditionally independent of one another. In order to determine the conditional probability distributions of these variables, ClustalW-gene rated phylogenetic trees were used as an approximation for the clustering of the intracellular domain sequences. The sampling of an intracellular domain sequence was achieved by identifying the cluster containing the homologue with the highest sequence similarity. Results: Out of 55 GPCRs validated, the model yielded a correct classification rate of 72%. Our model also predicted multiple G-protein coupling for most of the GPCRs in the validation set. The Bayesian approach in this work offers an alternative to the experimental approach in order to answer the biological problem of GPCR/G-protein coupling selectivity. Availability: Academic users should send their request for the perl program for calculating likelihood probabilities at jack.cao@astrazeneca.com. Supplementary Information: The materials can be viewed at http://www.astrazeneca-montreal.com/ AZRDM-info/supporting_info.pdf.	AstraZeneca R&D, Dept Mol Sci, St Laurent, PQ H4S 1Z9, Canada	Cao, J (reprint author), AstraZeneca R&D, Dept Mol Sci, 7171 Frederick Banting St, St Laurent, PQ H4S 1Z9, Canada.	jack.cao@astrazeneca.com					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bonini JA, 2000, J BIOL CHEM, V275, P39324, DOI 10.1074/jbc.M004385200; Borowsky B, 2001, P NATL ACAD SCI USA, V98, P8966, DOI 10.1073/pnas.151105198; Bourne HR, 1997, CURR OPIN CELL BIOL, V9, P134, DOI 10.1016/S0955-0674(97)80054-3; Cao J, 1998, J BIOL CHEM, V273, P32281, DOI 10.1074/jbc.273.48.32281; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Greasley PJ, 2001, J BIOL CHEM, V276, P46485, DOI 10.1074/jbc.M105791200; Hamm HE, 1998, J BIOL CHEM, V273, P669, DOI 10.1074/jbc.273.2.669; HECKERMAN D, 1999, ADAPTIVE COMPUTATION, P301; Horn F, 2000, PROTEINS, V41, P448, DOI 10.1002/1097-0134(20001201)41:4<448::AID-PROT30>3.0.CO;2-C; Howard AD, 2000, NATURE, V406, P70, DOI 10.1038/35017610; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; JENSEN FV, 2001, BAYESIAN NETWORKS DE, P14; Kukkonen JP, 2001, TRENDS PHARMACOL SCI, V22, P616, DOI 10.1016/S0165-6147(00)01864-2; Lembo PMC, 1999, NAT CELL BIOL, V1, P267; Möller S, 2001, Bioinformatics, V17 Suppl 1, pS174; Mori M, 2001, BIOCHEM BIOPH RES CO, V283, P1013, DOI 10.1006/bbrc.2001.4893; Oliveira L, 1999, PROTEIN ENG, V12, P1087, DOI 10.1093/protein/12.12.1087; Pearl J., 1995, HDB BRAIN THEORY NEU, P149; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; *TIPS, 2001, NOM SUPPL; Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040; Wess J, 1998, PHARMACOL THERAPEUT, V80, P231, DOI 10.1016/S0163-7258(98)00030-8	25	28	31	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JAN 22	2003	19	2					234	240		10.1093/bioinformatics/19.2.234		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	644JF	WOS:000180913600010	
J	Pigeon, S; Druyts, P; Verlinde, P				Pigeon, S; Druyts, P; Verlinde, P			Applying logistic regression to the fusion of the NIST'99 1-speaker submissions	DIGITAL SIGNAL PROCESSING			English	Article; Proceedings Paper	5th Annual NIST Speaker Recognition Workshop	JUN 03-04, 1999	BALTIMORE, MARYLAND	NIST	UNIV MARYLAND	decision fusion; Bayes; logistic regression		This contribution formulates the decision fusion problem encountered in the design of a multiexpert identity verification system. For this purpose, a Bayesian classifier is used and the influence of the a priori class probabilities is investigated. Logistic regression is introduced as a particular case of the naive Bayesian classifier and is applied to the fusion of all submitted data of the 1-speaker recognition task, part of the NIST'99 campaign. (C) 2000 Academic Press.	Royal Mil Acad, SIC Lab, B-1000 Brussels, Belgium	Pigeon, S (reprint author), Royal Mil Acad, SIC Lab, Av Renaissance 30, B-1000 Brussels, Belgium.						BIMBOT F, 1997, HDB STANDARDS RESOUR; Bishop C.M., 1995, NEURAL NETWORKS PATT; Dasarathy B. V., 1994, DECISION FUSION; Devijver P., 1982, PATTERN RECOGNITION; DRUYTS P, 1997, ANNIE 97; FRENCH S, 1997, PRACTICE BAYESIAN AN; HOSNER DW, 1989, APPL LOGISTIC REGRES; Jordan M. I., 1995, WHY LOGISTIC FUNCTIO; Mitchell T.M., 1997, MACHINE LEARNING; PIGEON S, 1999, THESIS U CATHOLIQUE; Ripley B., 1996, PATTERN RECOGNITION; Verlinde P., 1999, P 2 INT C AUD VID BA, P188; VERLINDE P, 1999, THESIS ECOLE NATL SU	13	28	28	ACADEMIC PRESS INC	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1051-2004			DIGIT SIGNAL PROCESS	Digit. Signal Prog.	JAN-JUL	2000	10	1-3					237	248		10.1006/dspr.1999.0358		12	Engineering, Electrical & Electronic	Engineering	323UP	WOS:000087583600016	
J	Bifet, A; Holmes, G; Kirkby, R; Pfahringer, B				Bifet, Albert; Holmes, Geoff; Kirkby, Richard; Pfahringer, Bernhard			MOA: Massive Online Analysis	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						data streams; classification; ensemble methods; java; machine learning software		Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams. MOA includes a collection of offline and online methods as well as tools for evaluation. In particular, it implements boosting, bagging, and Hoeffding Trees, all with and without Naive Bayes classifiers at the leaves. MOA supports bi-directional interaction with WEKA, the Waikato Environment for Knowledge Analysis, and is released under the GNU GPL license.	[Bifet, Albert; Holmes, Geoff; Kirkby, Richard; Pfahringer, Bernhard] Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Bifet, A (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.	ABIFET@CS.WAIKATO.AC.NZ; GEOFF@CS.WAIKATO.AC.NZ; RKIRKBY@CS.WAIKATO.AC.NZ; BERNHARD@CS.WAIKATO.AC.NZ					BIFET A, 2009, 1 AS C MACH LEARN AC; BIFET A., 2010, ADAPTIVE STREAM MINI; Bifet A., 2009, 15 ACM SIGKDD INT C; GAMA J, 2009, 15 ACM SIGKDD INT C; Kirkby R., 2007, THESIS U WAIKATO; PFAHRINGER B, 2008, PAKDD PAC AS C KNOWL, P206	6	27	29	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAY	2010	11						1601	1604				4	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	658WB	WOS:000282522000001	
J	Yuan, Y; Guo, L; Shen, L; Liu, JS				Yuan, Yuan; Guo, Lei; Shen, Lei; Liu, Jun S.			Predicting gene expression from sequence: A reexamination	PLOS COMPUTATIONAL BIOLOGY			English	Article							CIS-REGULATORY ELEMENTS; SACCHAROMYCES-CEREVISIAE; MOTIF DISCOVERY; CELL-CYCLE; IDENTIFICATION; ORGANIZATION; REGRESSION; NETWORKS; MODULES	Although much of the information regarding genes' expressions is encoded in the genome, deciphering such information has been very challenging. We reexamined Beer and Tavazoie's (BT) approach to predict mRNA expression patterns of 2,587 genes in Saccharomyces cerevisiae from the information in their respective promoter sequences. Instead of fitting complex Bayesian network models, we trained naive Bayes classifiers using only the sequence-motif matching scores provided by BT. Our simple models correctly predict expression patterns for 79% of the genes, based on the same criterion and the same cross-validation (CV) procedure as BT, which compares favorably to the 73% accuracy of BT. The fact that our approach did not use position and orientation information of the predicted binding sites but achieved a higher prediction accuracy, motivated us to investigate a few biological predictions made by BT. We found that some of their predictions, especially those related to motif orientations and positions, are at best circumstantial. For example, the combinatorial rules suggested by BT for the PAC and RRPE motifs are not unique to the cluster of genes from which the predictive model was inferred, and there are simpler rules that are statistically more significant than BT's ones. We also show that CV procedure used by BT to estimate their method's prediction accuracy is inappropriate and may have overestimated the prediction accuracy by about 10%.	Harvard Univ, Dept Stat, Cambridge, MA 02138 USA	Liu, JS (reprint author), Harvard Univ, Dept Stat, Cambridge, MA 02138 USA.	jliu@stat.harvard.edu					Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; Bussemaker HJ, 2001, NAT GENET, V27, P167, DOI 10.1038/84792; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; Das D, 2004, P NATL ACAD SCI USA, V101, P16234, DOI 10.1073/pnas.0407365101; DEQUARDCHABLAT M, 1991, J BIOL CHEM, V266, P15300; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Hughes JD, 2000, J MOL BIOL, V296, P1205, DOI 10.1006/jmbi.2000.3519; Hvidsten TR, 2005, GENOME RES, V15, P856, DOI 10.1101/gr.3760605; Iyer VR, 1999, SCIENCE, V283, P83, DOI 10.1126/science.283.5398.83; Jensen ST, 2005, BIOINFORMATICS, V21, P3832, DOI 10.1093/bioinformatics/bti628; Keles S, 2004, BIOINFORMATICS, V20, P2799, DOI 10.1093/bioinformatics/bth333; Keles S, 2002, BIOINFORMATICS, V18, P1167, DOI 10.1093/bioinformatics/18.9.1167; Lascaris RF, 1999, BIOINFORMATICS, V15, P267, DOI 10.1093/bioinformatics/15.4.267; LAWRENCE CE, 1993, SCIENCE, V262, P208, DOI 10.1126/science.8211139; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Liu X., 2001, PAC S BIOCOMPUT, V6, P127; MacIsaac KD, 2006, PLOS COMPUT BIOL, V2, P201, DOI 10.1371/journal.pcbi.0020036; MADIGAN D, 2005, P 25 INT WORKSH BAY; Makeev VJ, 2003, NUCLEIC ACIDS RES, V31, P6016, DOI 10.1093/nar/gkg799; NEUWALD AF, 1995, PROTEIN SCI, V4, P1618; Roth FP, 1998, NAT BIOTECHNOL, V16, P939, DOI 10.1038/nbt1098-939; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Terai G, 2004, BIOINFORMATICS, V20, P1119, DOI 10.1093/bioinformatics/bth049; Tompa M, 2005, NAT BIOTECHNOL, V23, P137, DOI 10.1038/nbt1053; Yuan GC, 2005, SCIENCE, V309, P626, DOI 10.1126/science.1112178; Zhong WX, 2005, BIOINFORMATICS, V21, P4169, DOI 10.1093/bioinformatics/bti680	29	27	27	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-734X			PLOS COMPUT BIOL	PLoS Comput. Biol.	NOV	2007	3	11					2391	2397	e243	10.1371/journal.pcbi.0030243		7	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	236NP	WOS:000251310000031	
J	Kuritzkes, DR; Ribaudo, HJ; Squires, KE; Koletar, SL; Santana, J; Riddler, SA; Reichman, R; Shikuma, C; Meyer, WA; Klingman, KL; Gulick, RM				Kuritzkes, Daniel R.; Ribaudo, Heather J.; Squires, Kathleen E.; Koletar, Susan L.; Santana, Jorge; Riddler, Sharon A.; Reichman, Richard; Shikuma, Cecilia; Meyer, William A., III; Klingman, Karin L.; Gulick, Roy M.		ACTG Protocol Team	Plasma HIV-1 RNA dynamics in antiretroviral-naive subjects receiving either triple-nucleoside or efavirenz-containing regimens: ACTG A5166s	JOURNAL OF INFECTIOUS DISEASES			English	Article							BASE-LINE FACTORS; IN-VIVO; VIRAL DYNAMICS; VIROLOGICAL RESPONSES; COMBINATION THERAPY; INITIAL TREATMENT; SEX-DIFFERENCES; INFECTION; PROGRESSION; DECAY	Objective. We sought to compare clearance rates of plasma human immunodeficiency virus type 1 (HIV-1) RNA in men and women starting triple-nucleoside-based versus efavirenz (EFV)-based regimens. Methods. First- and second-phase decay rates of plasma HIV-1 were compared in men and women initiating a triple nucleoside reverse-transcriptase inhibitor (NRTI) regimen versus regimens that included EFV plus an NRTI. Subjects (n=64) were randomized to receive zidovudine/lamivudine/abacavir (triple-nucleoside regimen), zidovudine/ lamivudine plus EFV (3-drug EFV regimen) or zidovudine/lamivudine/abacavir plus EFV (4-drug EFV regimen). Plasma HIV-1 RNA levels were fitted to a biexponential viral-dynamics model using a nonlinear mixedeffects model. Nonparametric Wilcoxon tests compared empirical Bayes estimates of first- and second-phase viral decay rates between treatment arms and sex. Results. Median first- phase viral decay rates were significantly faster in subjects receiving the 3-drug EFV regimen (0.67/day), compared with those receiving the triple-nucleoside regimen (0.56/day; P=.02). The second-phase viral decay rate was also faster in the 3-drug EFV group than in the triple-nucleoside group (P=.09). Decay rates in the 4-drug EFV group were intermediate. Viral decay rates were not significantly different in men and women. Conclusions. Faster initial viral decay in subjects randomized to a 3-drug EFV-based regimen corresponded to the overall superior efficacy of that regimen. Viral decay rates did not differ by sex.	Harvard Univ, Brigham & Womens Hosp, Sch Med, Sect Retroviral Therapeut, Cambridge, MA 02139 USA; Harvard Univ, Sch Med, Div Aids, Cambridge, MA 02139 USA; Harvard Univ, Sch Publ Hlth, Ctr Biostat & AIDS Res, Cambridge, MA 02138 USA; Univ So Calif, Div Infect Dis, Los Angeles, CA 90089 USA; Ohio State Univ, Columbus, OH 43210 USA; Univ Puerto Rico, San Juan, PR 00936 USA; Univ Pittsburgh, Dept Med, Pittsburgh, PA 15260 USA; Univ Rochester, Med Ctr, Rochester, NY 14642 USA; Cornell Univ, Weill Med Coll, New York, NY 10021 USA; Univ Hawaii, Honolulu, HI 96822 USA; Quest Diagnost, Baltimore, MD USA; NIAID, Treatment Res Program, Div Aids, Bethesda, MD 20892 USA	Kuritzkes, DR (reprint author), Harvard Univ, Brigham & Womens Hosp, Sch Med, Sect Retroviral Therapeut, 65 Landsdowne St,Rm 449, Cambridge, MA 02139 USA.	dkuritzkes@partners.org					Anastos K, 1999, AIDS, V13, P1717, DOI 10.1097/00002030-199909100-00016; Anastos K, 2000, J ACQ IMMUN DEF SYND, V24, P218; Ding AA, 1999, MATH BIOSCI, V160, P63, DOI 10.1016/S0025-5564(99)00021-8; WEI XP, 1995, NATURE, V373, P117, DOI 10.1038/373117a0; Farzadegan H, 1998, LANCET, V352, P1510, DOI 10.1016/S0140-6736(98)02372-1; Finzi D, 1999, NAT MED, V5, P512; GAO WY, 1993, J CLIN INVEST, V91, P2326, DOI 10.1172/JCI116463; Gulick RM, 2006, JAMA-J AM MED ASSOC, V296, P769, DOI 10.1001/jama.296.7.769; Gulick RM, 2004, NEW ENGL J MED, V350, P1850, DOI 10.1056/NEJMoa031772; HO DD, 1995, NATURE, V373, P123, DOI 10.1038/373123a0; Junghans C, 1999, LANCET, V353, P589, DOI 10.1016/S0140-6736(05)75645-2; LINDSTROM MJ, 1990, BIOMETRICS, V46, P673, DOI 10.2307/2532087; Louie M, 2003, AIDS, V17, P1151, DOI 10.1097/01.aids.0000060362.78202.97; Louie M, 2003, J INFECT DIS, V187, P896, DOI 10.1086/368164; Markowitz M, 2003, J VIROL, V77, P5037, DOI 10.1128/JVI.77.8.5037-5038.2003; Molto J, 2006, ANTIVIR THER, V11, P47; Moroni M, 1999, LANCET, V353, P589, DOI 10.1016/S0140-6736(05)75646-4; Perelson AS, 1997, NATURE, V387, P188, DOI 10.1038/387188a0; Perelson AS, 1996, SCIENCE, V271, P1582, DOI 10.1126/science.271.5255.1582; Ramratnam B, 1999, LANCET, V354, P1782, DOI 10.1016/S0140-6736(99)02035-8; Ramratnam B, 2000, NAT MED, V6, P82; Rezza G, 2000, J ACQ IMMUN DEF SYND, V25, P56, DOI 10.1097/00126334-200009010-00008; Rousseau FS, 2001, J ANTIMICROB CHEMOTH, V48, P507, DOI 10.1093/jac/48.4.507; Sterling TR, 2001, NEW ENGL J MED, V344, P720, DOI 10.1056/NEJM200103083441003; Wu HL, 2003, JAIDS-J ACQ IMM DEF, V33, P557, DOI 10.1097/00126334-200308150-00002; Wu HL, 2004, J INFECT DIS, V189, P593, DOI 10.1086/381500; Wu HL, 1999, J INFECT DIS, V179, P799, DOI 10.1086/314670; Wu HL, 1999, BIOMETRICS, V55, P410, DOI 10.1111/j.0006-341X.1999.00410.x; Zhang H, 1996, J VIROL, V70, P628	29	27	27	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0022-1899			J INFECT DIS	J. Infect. Dis.	APR 15	2007	195	8					1169	1176		10.1086/512619		8	Immunology; Infectious Diseases; Microbiology	Immunology; Infectious Diseases; Microbiology	153AW	WOS:000245405100013	
J	Song, QB; Shepperd, M; Cartwright, M; Mair, C				Song, QB; Shepperd, M; Cartwright, M; Mair, C			Software defect association mining and defect correction effort prediction	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						software defect prediction; defect association; defect isolation effort; defect correction effort	CAPTURE-RECAPTURE MODELS; PROCESS IMPROVEMENT; INSPECTION	Much current software defect prediction work focuses on the number of defects remaining in a software system. In this paper, we present association rule mining based methods to predict defect associations and defect correction effort. This is to help developers detect software defects and assist project managers in allocating testing resources more effectively. We applied the proposed methods to the SEL defect data consisting of more than 200 projects over more than 15 years. The results show that, for defect association prediction, the accuracy is very high and the false-negative rate is very low. Likewise, for the defect correction effort prediction, the accuracy for both defect isolation effort prediction and defect correction effort prediction are also high. We compared the defect correction effort prediction method with other types of methods-PART, C4.5, and Naive Bayes-and show that accuracy has been improved by at least 23 percent. We also evaluated the impact of support and confidence levels on prediction accuracy, false-negative rate, false-positive rate, and the number of rules. We found that higher support and confidence levels may not result in higher prediction accuracy, and a sufficient number of rules is a precondition for high prediction accuracy.	Xian Jiaotong Univ, Dept Comp Sci & Technol, Xian 710049, Shaanxi, Peoples R China; Brunel Univ, Sch Informat Sci Comp & Math, Uxbridge UB8 3PH, Middx, England	Song, QB (reprint author), Xian Jiaotong Univ, Dept Comp Sci & Technol, 28 Xian Ning W Rd, Xian 710049, Shaanxi, Peoples R China.	qbsong@mail.xjtu.edu.cn; martin.shepperd@brunel.ac.uk; michelle.cartwright@brunel.ac.uk; carolyn.mair@brunel.ac.uk	Shepperd, Martin/F-9683-2013	Shepperd, Martin/0000-0003-1874-6145			Agrawal R., 1993, P ACM SIGMOD C MAN D; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; BHANDARI I, 1993, IEEE T SOFTWARE ENG, V19, P1157, DOI 10.1109/32.249661; BHANDARI I, 1994, IBM SYST J, V33, P182; BHANDARI IS, 1993, P WORKSH KNOWL DISC; Briand LC, 2000, IEEE T SOFTWARE ENG, V26, P518, DOI 10.1109/32.852741; COMPTON BT, 1990, J SYST SOFTWARE, V12, P199, DOI 10.1016/0164-1212(90)90040-S; Dong G., 1999, P 2 INT C DISC SCI, P30; Ebrahimi NB, 1997, IEEE T SOFTWARE ENG, V23, P529, DOI 10.1109/32.624308; El Emam K, 2001, IEEE T SOFTWARE ENG, V27, P851, DOI 10.1109/32.950319; FENTON N, 1999, IEEE T SOFTWARE ENG, V25, P676; Fenton N. E., 1996, SOFTWARE METRICS RIG; FRANK E, 2000, MACH LEARN, V411, P5; Frank E., 1998, P 15 INT C MACH LEAR, P144; HELLER G, 1992, SEL92002; KENNEY GQ, 1993, IEEE T RELIAB, V42, P107, DOI 10.1109/24.210280; Liu B., 1998, P 4 INT C KNOWL DISC, P80; MUNSON JC, 1990, INFORM SOFTWARE TECH, V32, P106, DOI 10.1016/0950-5849(90)90109-5; Padberg F, 2004, IEEE T SOFTWARE ENG, V30, P17, DOI 10.1109/TSE.2004.1265733; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Runeson P., 1998, Empirical Software Engineering, V3, DOI 10.1023/A:1009728205264; She R., 2003, P 9 ACM SIGKDD INT C; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; WANG K, 2000, P 6 INT C KNOWL DISC; Wang K, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P363; WIEL SAV, 1993, IEEE T SOFTWARE ENG, V19, P1045; Wohlin C, 1998, PROC INT CONF SOFTW, P400, DOI 10.1109/ICSE.1998.671393; YANG Q, 2001, P 7 ACM SIGKDD INT C; Yin X., 2003, P 2003 SIAM INT C DA; YING ATT, 2004, P 1 INT WORKSH MIN S; Zimmermann T., 2004, P 26 INT C SOFTW ENG	31	27	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589			IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	FEB	2006	32	2					69	82				14	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	012AD	WOS:000235309700001	
J	Blanco, R; Inza, M; Merino, M; Quiroga, J; Larranaga, P				Blanco, R; Inza, M; Merino, M; Quiroga, J; Larranaga, P			Feature selection in Bayesian classifiers for the prognosis of survival of cirrhotic patients treated with TIPS	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Bayesian classification models; filter approach; wrapper approach; transjugular intrahepatic portosystemic shunt; survival prediction	MACHINE-LEARNING-METHODS; FEATURE SUBSET-SELECTION; ESOPHAGEAL-VARICES; DIAGNOSIS; MORTALITY	The transjugular intrahepatic portosystemic shunt (TIPS) is a treatment for cirrhotic patients with portal hypertension. A subgroup of patients dies in the first 6 months and another subgroup lives a long period of time. Nowadays, no risk factors have been identified in order to determine how long a patient will survive. An empirical study for predicting the survival rate within the first 6 months after TIPS placement is conducted using a clinical database with 107 cases and 77 variables. Applications of Bayesian classification models, based on Bayesian networks, to medical problems have become popular in the last years. Feature subset selection is useful due to the heterogeneity of the medical databases where not all the variables are required to perform the classification. In this paper, filter and wrapper approaches based on the feature subset selection are adapted to induce Bayesian classifiers (naive Bayes, selective naive Bayes, semi naive Bayes, tree augmented naive Bayes, and k-dependence Bayesian classifier) and are applied to distinguish between the two subgroups of cirrhotic patients. The estimated accuracies obtained tally with the results of previous studies. Moreover, the medical significance of the subset of variables selected by the classifiers along with the comprehensibility of Bayesian models is greatly appreciated by physicians. (c) 2005 Elsevier Inc. All rights reserved.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, E-20080 San Sebastian, Spain; Basque Hlth Serv Osakidetza, E-20013 San Sebastian, Spain; Univ Navarra Clin, Fac Med, E-31080 Pamplona, Spain	Blanco, R (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, POB 649, E-20080 San Sebastian, Spain.	rosa@si.ehu.es	Larranaga, Pedro/F-9293-2013				BAILEY NTJ, 1964, MATH COMPUTER SCI BI, P103; BAYES T, 1764, ESSAY SOLVING PROBLE; BORNMAN PC, 1994, LANCET, V343, P1079, DOI 10.1016/S0140-6736(94)90186-4; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; Castillo E., 1997, EXPERT SYSTEMS PROBA; CATTLET J, 1999, P EUR WORK SESS LEAR, P164; Chalasani N, 2000, GASTROENTEROLOGY, V118, P138, DOI 10.1016/S0016-5085(00)70422-7; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0; CONN HO, 1981, HEPATOLOGY, V1, P1; Cooper GF, 1997, ARTIF INTELL MED, V9, P107, DOI 10.1016/S0933-3657(96)00367-3; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Draper D, 2000, J GLOBAL OPTIM, V18, P399, DOI 10.1023/A:1026504402220; Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GAMEZ J, 2002, P 1 EUR WORKSH PROB, P222; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HANLEY JA, 1982, RADIOLOGY, V143, P29; Inza I, 2001, ARTIF INTELL MED, V23, P187, DOI 10.1016/S0933-3657(01)00085-9; JELONEK J, 1997, ARTIF INTELL MED, V20, P1202; JENSEN F, 2001, BAYESIAN NETWORKS DE; Keogh E.J., 1999, 7 INT WORKSH ART INT, P225; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1984, P INT SCH SYNTH EXP; KONONENKO I, 1991, P 6 EUR WORK SESS LE, pS206; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P., 1994, P 10 C UNC ART INT, P399; LAPLACE PS, 1995, PHILOS ESSAYS PROBAB; Malinchoc M, 2000, HEPATOLOGY, V31, P864, DOI 10.1053/he.2000.5852; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Minsky M., 1961, T I RADIO ENG, V49, P8; Neapolitan RE, 2003, LEARNING BAYESIAN NE; NORDYKE RA, 1971, COMPUT BIOMED RES, V4, P374, DOI 10.1016/0010-4809(71)90022-X; Ohmann C, 1996, ARTIF INTELL MED, V8, P23, DOI 10.1016/0933-3657(95)00018-6; PAZZANI M, 1997, LECT NOTES STAT; Pearl J., 1988, PROBABILISTIC REASON; PUGH RNH, 1973, BRIT J SURG, V60, P646, DOI 10.1002/bjs.1800600817; RUSSEK E, 1983, COMPUT BIOMED RES, V16, P537, DOI 10.1016/0010-4809(83)90040-X; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; SAUNDERS JB, 1981, BRIT MED J, V282, P263; STONE M, 1974, J R STAT SOC B, V36, P111; VANDERGAAG LC, 2001, P 13 BELG NETH C ART, P109; VINTERBO S, 1999, THESIS NORWEGIAN U S	43	27	28	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	OCT	2005	38	5					376	388		10.1016/j.jbi.2005.05.004		13	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	976MV	WOS:000232738600004	
J	Helman, P; Veroff, R; Atlas, SR; Willman, C				Helman, P; Veroff, R; Atlas, SR; Willman, C			A Bayesian network classification methodology for gene expression data	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Review						Bayesian networks; classification; feature selection; gene expression; microarray data; normalization	PARTIAL LEAST-SQUARES; MICROARRAY DATA; PRIORITIZING INFORMATION; OLIGONUCLEOTIDE ARRAYS; PROBABILISTIC NETWORKS; CANCER CLASSIFICATION; SAMPLE CLASSIFICATION; TUMOR CLASSIFICATION; CLUSTERING ANALYSIS; GRAPHICAL MODELS	We present new techniques for the application of a Bayesian network learning framework to the problem of classifying gene expression data. The focus on classification permits us to develop techniques that address in several ways the complexities of learning Bayesian nets. Our classification model reduces the Bayesian network learning problem to the problem of learning multiple subnetworks, each consisting of a class label node and its set of parent genes. We argue that this classification model is more appropriate for the gene expression domain than are other structurally similar Bayesian network classification models, such as Naive Bayes and Tree Augmented Naive Bayes (TAN), because our model is consistent with prior domain experience suggesting that a relatively small number of genes, taken in different combinations, is required to predict most clinical classes of interest. Within this framework, we consider two different approaches to identifying parent sets which are supported by the gene expression observations and any other currently available evidence. One approach employs a simple greedy algorithm to search the universe of all genes; the second approach develops and applies a gene selection algorithm whose results are incorporated as a prior to enable an exhaustive search for parent sets over a restricted universe of genes. Two other significant contributions are the construction of classifiers from multiple, competing Bayesian network hypotheses and algorithmic methods for normalizing and binning gene expression data in the absence of prior expert knowledge. Our classifiers are developed under a cross validation regimen and then validated on corresponding out-of-sample test sets. The classifiers attain a classification rate in excess of 90% on out-of-sample test sets for two publicly available datasets. We present an extensive compilation of results reported in the literature for other classification methods run against these same two datasets. Our results are comparable to, or better than, any we have found reported for these two sets, when a train-test protocol as stringent as ours is followed.	Univ New Mexico, Dept Comp Sci, Farris Engn Ctr, Albuquerque, NM 87131 USA; Univ New Mexico, Dept Phys & Astron, Albuquerque, NM 87131 USA; Univ New Mexico, Ctr Adv Studies, Albuquerque, NM 87131 USA; Univ New Mexico, Sch Med, Dept Pathol, Albuquerque, NM 87131 USA; Univ New Mexico, Sch Med, Canc Res & Treatment Ctr, Albuquerque, NM 87131 USA	Helman, P (reprint author), Univ New Mexico, Dept Comp Sci, Farris Engn Ctr, Room 157, Albuquerque, NM 87131 USA.	helman@cs.unm.edu					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; BENDOR A, 2001, P 5 ANN INT C COMP M, P31, DOI DOI 10.1145/369133.369167; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bishop C., 1996, NEURAL NETWORKS PATT; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Buntine W., 1991, P 7 C UNC ART INT, P52; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Cheng J., 1999, P 15 C UNC ART INT U, P101; Chickering D., 1997, P 13 C UNC ART INT U, P80; Chow ML, 2001, PHYSIOL GENOMICS, V5, P99; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; D'haeseleer P., 2000, THESIS U NEW MEXICO; Dawid A. P., 1992, Statistics and Computing, V2, DOI 10.1007/BF01890546; DAWID AP, 1993, ANN STAT, V21, P1272, DOI 10.1214/aos/1176349260; Dechter R., 1996, P 12 C UNC ART INT U, P211; DeRisi JL, 1997, SCIENCE, V278, P680, DOI 10.1126/science.278.5338.680; DING J, 2004, THESIS; Duda R., 1973, PATTERN CLASSIFICATI; Duda R. O., 2000, PATTERN CLASSIFICATI; DUDOIT S, 2000, 576 U CAL DEP STAT; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Friedman N., 1996, P 13 INT C MACH LEAR, P157; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N, 1999, P 15 C UNC ART INT U, P196; FRIEDMAN N, 1996, P 12 C UNC ART INT U, P211; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gander W, 2000, BIT, V40, P84, DOI 10.1023/A:1022318402393; Getz G, 2000, P NATL ACAD SCI USA, V97, P12079, DOI 10.1073/pnas.210134797; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HAN C, 2000, MCMC METHODS COMPUTI; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Helman P, 1998, J INTELL INF SYST, V11, P99, DOI 10.1023/A:1008628802726; Helman P, 1997, IEEE T SYST MAN CY A, V27, P449, DOI 10.1109/3468.594912; HELMAN P, 2004, UNPUB NEW ENGL J MED; Ibrahim JG, 2002, J AM STAT ASSOC, V97, P88, DOI 10.1198/016214502753479257; JENSEN F, 2001, BAYESIAN NETWORKS DE; Jensen F.V., 1990, COMPUTATIONAL STATIS, V4, P269; KANG H, 2003, METHODS EVALUATING P; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Korenberg MJ, 2002, J PROTEOME RES, V1, P55, DOI 10.1021/pr015510m; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Langley P., 1992, P 10 NAT C ART INT, P223; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LEE Y, 2002, 1051R U WISC DEP STA; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li Y, 2002, BIOINFORMATICS, V18, P1332, DOI 10.1093/bioinformatics/18.10.1332; Lockhart DJ, 1996, NAT BIOTECHNOL, V14, P1675, DOI 10.1038/nbt1296-1675; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; MADDEN M, 2002, NUIGIT0110002 NATL U; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; Madsen AL, 1999, ARTIF INTELL, V113, P203, DOI 10.1016/S0004-3702(99)00062-4; Moler EJ, 2000, PHYSIOL GENOMICS, V4, P109; MOSQUERACARO M, 2003, 45 ANN AM SOC HEM M; MUKHERJEE S, 1999, 1677 AI MIT; MUKHERJEE S, 1999, 1677 MIT; Murphy K., 1999, MODELLING GENE EXPRE; Nguyen DV, 2002, BIOINFORMATICS, V18, P1216, DOI 10.1093/bioinformatics/18.9.1216; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Pearl J., 1988, PROBABILISTIC REASON; PEARL J, 1991, P 2 INT C, P411; Pe'er D, 2001, Bioinformatics, V17 Suppl 1, pS215; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Rigoutsos I, 2000, METAB ENG, V2, P159, DOI 10.1006/mben.2000.0151; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Shafer G. R., 1990, ANN MATH ARTIFICIAL, V2, P327, DOI 10.1007/BF01531015; SPIEGELHALTER DJ, 1993, STAT SCI, V8, P219, DOI 10.1214/ss/1177010888; Szabo A, 2002, MATH BIOSCI, V176, P71, DOI 10.1016/S0025-5564(01)00103-1; Tavazoie S, 1999, NAT GENET, V22, P281; TOBIN F, 1999, P 1999 INT C MOD SIM; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1998, STAT LEARNING THEORY; Weston J, 2001, ADV NEUR IN, V13, P668; Woolf PJ, 2000, PHYSIOL GENOMICS, V3, P9; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698	83	27	32	MARY ANN LIEBERT INC	LARCHMONT	2 MADISON AVENUE, LARCHMONT, NY 10538 USA	1066-5277			J COMPUT BIOL	J. Comput. Biol.		2004	11	4					581	615		10.1089/1066527041887294		35	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	855LL	WOS:000223974700004	
J	Catal, C; Diri, B				Catal, Cagatay; Diri, Banu			Investigating the effect of dataset size, metrics sets, and feature selection techniques on software fault prediction problem	INFORMATION SCIENCES			English	Article						Machine learning; Artificial Immune Systems; Software fault prediction; J48; Random Forests; Naive Bayes	QUALITY ESTIMATION; IMMUNE-SYSTEM; CLASSIFICATION; PRONENESS; CLASSIFIERS; ALGORITHM; RULES	Software quality engineering comprises of several quality assurance activities such as testing, formal verification, inspection, fault tolerance, and software fault prediction. Until now, many researchers developed and validated several fault prediction models by using machine learning and statistical techniques. There have been used different kinds of software metrics and diverse feature reduction techniques in order to improve the models' performance. However, these studies did not investigate the effect of dataset size, metrics set, and feature selection techniques for software fault prediction. This study is focused on the high-performance fault predictors based on machine learning such as Random Forests and the algorithms based on a new computational intelligence approach called Artificial Immune Systems. We used public NASA datasets from the PROMISE repository to make our predictive models repeatable, refutable, and verifiable. The research questions were based on the effects of dataset size, metrics set, and feature selection techniques. In order to answer these questions, there were defined seven test groups. Additionally, nine classifiers were examined for each of the five public NASA datasets. According to this study, Random Forests provides the best prediction performance for large datasets and Naive Bayes is the best prediction algorithm for small datasets in terms of the Area Under Receiver Operating Characteristics Curve (AUC) evaluation parameter. The parallel implementation of Artificial Immune Recognition Systems (AIRS2Parallel) algorithm is the best Artificial Immune Systems paradigm-based algorithm when the method-level metrics are used. (C) 2008 Elsevier Inc. All rights reserved.	[Catal, Cagatay; Diri, Banu] TUBITAK Marmara Res Ctr, Inst Informat Technol, TR-41470 Gebze, Kocaeli, Turkey	Catal, C (reprint author), TUBITAK Marmara Res Ctr, Inst Informat Technol, TR-41470 Gebze, Kocaeli, Turkey.	cagatay.catal@bte.mam.gov.tr			The Scientific and Technological Research Council of TURKEY (TUBITAK) [107E213]	This research project is supported by The Scientific and Technological Research Council of TURKEY (TUBITAK) under Grant 107E213. The findings and opinions in this study belong solely to the authors, and are not necessarily those of the sponsor. We thank to Elda Dedja for her constructive suggestions.	BERETA M, 2008, INFORM SCI; BROWNLEE J, 2005, 202 SWINB U TECHN; Brownlee J., 2005, 102 SWINB U TECHN; BROWNLEE J, 2005, 301 SWINB U TECHN; Carter JH, 2000, J AM MED INFORM ASSN, V7, P28; CATAL C, 2008, P 2 IEEE INT S THEOR; CATAL C, 2008, LECT NOTES COMPUTER, P244; Catal C, 2007, Proceedings of the IASTED International Conference on Software Engineering, P285; CATAL C, 2007, LECT NOTES COMPUTER, P300; De Castro L.N., 2000, GECCO 00 WORKSH P, P36; Ding YS, 2008, INFORM SCIENCES, V178, P4619, DOI 10.1016/j.ins.2008.08.010; El Emam K, 2001, J SYST SOFTWARE, V55, P301, DOI 10.1016/S0164-1212(00)00079-0; Elish KO, 2008, J SYST SOFTWARE, V81, P649, DOI 10.1016/j.jss.2007.07.040; Evett M., 1998, P 3 ANN GEN PROGR C, P60; Gondra I, 2008, J SYST SOFTWARE, V81, P186, DOI 10.1016/j.jss.2007.05.035; Guo L., 2003, Proceedings 18th IEEE International Conference on Automated Software Engineering; Halstead M.H., 1977, ELEMENTS SOFTWARE SC; Hu QH, 2008, INFORM SCIENCES, V178, P3577, DOI 10.1016/j.ins.2008.05.024; Janes A, 2006, INFORM SCIENCES, V176, P3711, DOI 10.1016/j.ins.2005.12.002; Jin Xin, 2006, C DAT MIN LAS VEG NE, P414; Kanmani S, 2007, INFORM SOFTWARE TECH, V49, P483, DOI 10.1016/j.infsof.2006.07.005; Khoshgoftaar TM, 2002, PROC INT C TOOLS ART, P365, DOI 10.1109/TAI.2002.1180826; Khoshgoftaar TM, 2006, SOFTWARE QUAL J, V14, P85, DOI 10.1007/s11219-006-7597-z; Koprinska I, 2007, INFORM SCIENCES, V177, P2167, DOI 10.1016/j.ins.2006.12.005; KORU AG, 2005, WORKSH PRED MOD SOFT, P1; Lei Z, 2008, INFORM SCIENCES, V178, P1836, DOI 10.1016/j.ins.2007.11.019; Liu JF, 2008, INFORM SCIENCES, V178, P1235, DOI 10.1016/j.ins.2007.10.002; Ma Y., 2006, ADV MACHINE LEARNING, P237; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P2, DOI 10.1109/TSE.2007.256941; Munson J. C, 2003, SOFTWARE ENG MEASURE; Olague HM, 2007, IEEE T SOFTWARE ENG, V33, P402, DOI 10.1109/TSE.2007.1015.; Pai GJ, 2007, IEEE T SOFTWARE ENG, V33, P675, DOI [10.1109/TSE.2007.70722., 10.1109/TSE.2007.70722]; Powers ST, 2008, INFORM SCIENCES, V178, P3024, DOI 10.1016/j.ins.2007.11.028; QUAH T, 2008, INFORM SCI IN PRESS; Sayyad S.J., 2005, PROMISE REPOSITORY S; Seliya N, 2007, SOFTWARE QUAL J, V15, P327, DOI 10.1007/s11219-007-9013-8; Seliya N, 2004, PROC INT C TOOLS ART, P183; Tavakkoli-Moghaddam R, 2007, INFORM SCIENCES, V177, P5072, DOI 10.1016/j.ins.2007.06.001; Thwin M. M, 2003, P 19 INT C SOFTW MAI, P113; TIMMIS J, 2000, GENETIC EVOLUTIONARY, P40; TIMMIS J, 2001, ARTIFICIAL IMMUNE SY; Watkins A., 2001, THESIS MISSISSIPPI S; WATKINS A, 2002, ICARIS 2002, P173; Watkins A. B., 2005, THESIS MISSISSIPPI S; Wohlin C, 2000, EXPT SOFTWARE ENG IN; Yuan X., 2000, Proceedings 3rd IEEE Symposium on Application-Specific Systems and Software Engineering Technology, DOI 10.1109/ASSET.2000.888052; Zhong S., 2004, P 10 ISSAT INT C REL, P149; Zolghadri MJ, 2007, INFORM SCIENCES, V177, P2296, DOI 10.1016/j.ins.2006.12.009	49	26	28	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	MAR 29	2009	179	8					1040	1058		10.1016/j.ins.2008.12.001		19	Computer Science, Information Systems	Computer Science	415OR	WOS:000263944000002	
J	Pattin, KA; White, BC; Barney, N; Gui, J; Nelson, HH; Kelsey, KT; Andrew, AS; Karagas, MR; Moore, JH				Pattin, Kristine A.; White, Bill C.; Barney, Nate; Gui, Jiang; Nelson, Heather H.; Kelsey, Karl T.; Andrew, Angeline S.; Karagas, Margaret R.; Moore, Jason H.			A Computationally Efficient Hypothesis Testing Method for Epistasis Analysis Using Multifactor Dimensionality Reduction	GENETIC EPIDEMIOLOGY			English	Article						extreme value distribution; permutation testing; power; type I error; bladder cancer; data mining	GENE-GENE INTERACTIONS; HUMAN-DISEASE; SUSCEPTIBILITY; ENVIRONMENT; CANCER; MODELS; GENOME	Multifactor dimensionality reduction (MDR) was developed as a nonparametric and model-free data mining method for detecting, characterizing, and interpreting epistasis in the absence of significant main effects in genetic and epidemiologic studies of complex traits Such as disease susceptibility The goal of MDR is to change the representation of the data using a constructive induction algorithm to make nonadditive interactions easier to detect using my classification method such as naive Bayes or logistic regression. Traditionally, MDR constructed variables have been evaluated with a naive Bayes classifier that is combined with 10-fold cross validation to obtain an estimate of predictive accuracy or generalizability of epistasis models. Traditionally, we have used permutation testing to statistically evaluate the significance of models obtained through MDR. The advantage of permutation testing is that it controls for false positives due to multiple testing. The disadvantage is that permutation testing is computationally expensive. This is an important issue that arises in the context of detecting epistasis on a genome-wide scale. The goal of the present study was to develop and evaluate several alternatives to large-scale permutation testing for assessing the statistical significance of MDR models. Using data simulated from 70 different epistasis models, we compared the power and type I error rate of MDR using a 1,000-fold permutation test with hypothesis testing using an extreme value distribution ( VD). We find that this new hypothesis testing method provides a reasonable alternative to the computationally expensive 1,000-fold permutation test and is 50 times faster. We then demonstrate this new method by applying it to a genetic epidemiology study of bladder cancer susceptibility that v,,as previously analyzed using MDR and assessed using a 1,000-fold permutation test. Genet. Epidemiol. 33:87-94, 2009. (C) 2008 Wiley-Liss, Inc.	[Pattin, Kristine A.; White, Bill C.; Barney, Nate; Gui, Jiang; Moore, Jason H.] Dartmouth Med Sch, Dept Genet, Computat Genet Lab, Lebanon, NH USA; [Gui, Jiang; Andrew, Angeline S.; Karagas, Margaret R.; Moore, Jason H.] Dartmouth Med Sch, Dept Community & Family Med, Lebanon, NH USA; [Nelson, Heather H.] Harvard Univ, Sch Publ Hlth, Dept Environm Hlth, Boston, MA 02115 USA; [Kelsey, Karl T.] Brown Univ, Dept Community Hlth, Providence, RI 02912 USA; [Andrew, Angeline S.; Karagas, Margaret R.; Moore, Jason H.] Dartmouth Med Sch, Norris Cotton Canc Ctr, Lebanon, NH USA; [Moore, Jason H.] Univ New Hampshire, Dept Comp Sci, Durham, NH 03824 USA; [Moore, Jason H.] Univ Vermont, Dept Comp Sci, Burlington, VT USA; [Moore, Jason H.] Translat Genom Res Inst, Phoenix, AZ USA	Moore, JH (reprint author), Dartmouth Hitchcock Med Ctr, HB 7937,1 Med Ctr Dr, Lebanon, NH 03756 USA.	jason.h.moore@darthmouth.edu			National Institute of Health [LM009012, AI59694, CA099500, CA82354, CA57494, ES00002, ES05947, RR018787, ES07373]	This publication was funded in part by National Institute of Health grants LM009012, AI59694, CA099500, CA82354, CA57494, ES00002, ES05947, RR018787, and ES07373. We would like to thank the anonymous reviewers for their very thoughtful critiques and suggestions that greatly improved the paper.	Andrew AS, 2006, CARCINOGENESIS, V27, P1030, DOI 10.1093/carcin/bgi284; Bateson W., 1909, MENDELS PRINCIPLES H; Coles S., 2001, INTRO STAT MODELING; Cordell HJ, 2002, HUM MOL GENET, V11, P2463, DOI 10.1093/hmg/11.20.2463; Dudbridge F, 2004, AM J HUM GENET, V75, P424, DOI 10.1086/423738; Fisher R. A., 1918, T ROY SOC EDINBURGH, V52, P399; Good P., 2000, PERMUTATION TESTS PR; Gumbel EJ, 1958, STAT EXTREMES; Hahn LW, 2003, BIOINFORMATICS, V19, P376, DOI 10.1093/bioinformatics/btf869; HAHN LW, 2004, IN SILICO BIOL, V4, P16; Altshuler D, 2005, NATURE, V437, P1299, DOI 10.1038/nature04226; LEADBETTER MR, 1983, Z WAHRSCHEINLICHKEIT, V65, P291, DOI 10.1007/BF00532484; Li WT, 2000, HUM HERED, V50, P334, DOI 10.1159/000022939; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Moore JH, 2002, ANN MED, V34, P88, DOI 10.1080/07853890252953473; Moore JH, 2004, JAMA-J AM MED ASSOC, V291, P1642, DOI 10.1001/jama.291.13.1642; Moore JH, 2004, EXPERT REV MOL DIAGN, V4, P795, DOI 10.1586/14737159.4.6.795; MOORE JH, 2007, KNOWLEDGE DISCOVERY, P17; Moore JH, 2005, NAT GENET, V37, P13, DOI 10.1038/ng0105-13; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Moore JH, 2006, J THEOR BIOL, V241, P252, DOI 10.1016/j.jtbi.2005.11.036; Moore JH, 2005, BIOESSAYS, V27, P637, DOI 10.1002/bias.20236; Rea TJ, 2006, PERSPECT BIOL MED, V49, P490, DOI 10.1353/pbm.2006.0063; RISCH N, 1996, SCIENCE, V273, P1517; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Sing CF, 2003, ARTERIOSCL THROM VAS, V23, P1190, DOI 10.1161/01.ATV.0000075081.51227.86; STEVENSON AG, 2002, R NEWS, V2, P31; Templeton A., 2000, EPISTASIS EVOLUTIONA; Thornton-Wells TA, 2004, TRENDS GENET, V20, P640, DOI 10.1016/j.tig.2004.09.007; Velez DR, 2007, GENET EPIDEMIOL, V31, P306, DOI 10.1002/gepi.20211	31	26	26	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0741-0395			GENET EPIDEMIOL	Genet. Epidemiol.	JAN	2009	33	1					87	94		10.1002/gepi.20360		8	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	391PJ	WOS:000262244900010	
B	Moser, R; Pedrycz, W; Succi, G			ACM	Moser, Raimund; Pedrycz, Witold; Succi, Giancarlo			A Comparative Analysis of the Efficiency of Change Metrics and Static Code Attributes for Defect Prediction	ICSE'08 PROCEEDINGS OF THE THIRTIETH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING			English	Proceedings Paper	30th International Conference on Software Engineering	MAY 10-18, 2008	Leipzig, GERMANY	ACM SIGOFT, IEEE CSE, Univ Paderborn, Univ Leipzig, SIEMENS, Zuhlke, Adesso, Deutsch Telekom Lab, sd&m, Werum, Microsoft Res, IBM, i nemis, dSPACE		Defect prediction; software metrics; cost-sensitive classification	EMPIRICAL-ANALYSIS; SOFTWARE; MODELS; FAULTS	In this paper we present a comparative analysis of the predictive power of two different sets of metrics for defect prediction. We choose one set of product related and one set of process related software metrics and use them for classifying Java files of the Eclipse project as defective respective defect-free. Classification models are built using three common machine learners: logistic regression, Naive Bayes, and decision trees. To allow different costs for prediction errors we perform cost-sensitive classification, which proves to be very successful: >75% percentage of correctly classified files, a recall of >80%, and a false positive rate <30%. Results indicate that for the Eclipse data, process metrics are more efficient defect predictors than code metrics.	[Moser, Raimund; Succi, Giancarlo] Free Univ Bolzano Bozen, I-39100 Bolzano, Italy	Moser, R (reprint author), Free Univ Bolzano Bozen, Piazza Domenicani 3, I-39100 Bolzano, Italy.	Raimund.Moser@unibz.it; pedrycz@ee.ualberta.ca; Giancarlo.Succi@unibz.it					BASILI V, 1996, IEEE T SOFTWARE ENG, V22, P267; BELL RM, 2006, INT S SOFTW TEST AN; Duda R. O., 2002, PATTERN CLASSIFICATI; Fenton NE, 1999, IEEE T SOFTWARE ENG, V25, P675, DOI 10.1109/32.815326; Fenton NE, 2000, IEEE T SOFTWARE ENG, V26, P797, DOI 10.1109/32.879815; Gall H., 2003, Proceedings. Sixth International Workshop on Principles of Software Evolution; Graves TL, 2000, IEEE T SOFTWARE ENG, V26, P653, DOI 10.1109/32.859533; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hassan A., 2005, P 21 IEEE INT C SOFT; Hollander M, 1973, NONPARAMETRIC STAT M; KHOSHGOFTAAR TM, 2002, P 7 IEEE INT S HIGH; KHOSHGOFTAAR TM, 1992, IEEE T RELIAB, V41, P390, DOI 10.1109/24.159804; KNAB P, 2006, P INT WORKSH MIN SOF; Lanubile F, 1997, J SYST SOFTWARE, V38, P225, DOI 10.1016/S0164-1212(96)00153-7; MENZIES T, 2007, IEEE T SOFTWARE ENG, V32, P1; Moser R, 2007, P 19 INT C SOFTW ENG, P519; Nagappan N., 2005, P 27 INT C SOFTW ENG; Nagappan N., 2006, P 28 INT C SOFTW ENG; Ohlsson N, 1996, IEEE T SOFTWARE ENG, V22, P886, DOI 10.1109/32.553637; Ostrand TJ, 2005, IEEE T SOFTWARE ENG, V31, P340, DOI 10.1109/TSE.2005.49; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; RATZINGER J, 2007, P FUND APPR SOFTW EN, P12; SCHROTER A, 2006, P ACM IEEE 5 INT S E, V2; SCHROTER A, 2006, P ACM IEEE 5 INT S E; Shull F., 2002, Proceedings Eighth IEEE Symposium on Software Metrics, DOI 10.1109/METRIC.2002.1011343; Subramanyam R, 2003, IEEE T SOFTWARE ENG, V29, P297, DOI 10.1109/TSE.2003.1191795; WEYUKER EJ, 2007, P 3 INT WORKSH PRED; Witten IH, 2005, DATA MINING PRACTICA; Zhou YM, 2006, IEEE T SOFTWARE ENG, V32, P771; Zimmermann T., 2004; Zimmermann T., 2007, P 3 INT WORKSH PRED	31	26	26	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-079-1				2008							181	190				10	Computer Science, Software Engineering	Computer Science	BJI63	WOS:000266158500019	
J	Degemmis, M; Lops, P; Semeraro, G				Degemmis, Marco; Lops, Pasquale; Semeraro, Giovanni			A content-collaborative recommender that exploits WordNet-based user profiles for neighborhood formation	USER MODELING AND USER-ADAPTED INTERACTION			English	Article						user modeling; collaborative filtering; content-based filtering; hybrid recommenders; machine learning; neighborhood formation in recommender systems; WordNet	SENSE DISAMBIGUATION; SYSTEMS	Collaborative and content-based filtering are the recommendation techniques most widely adopted to date. Traditional collaborative approaches compute a similarity value between the current user and each other user by taking into account their rating style, that is the set of ratings given on the same items. Based on the ratings of the most similar users, commonly referred to as neighbors, collaborative algorithms compute recommendations for the current user. The problem with this approach is that the similarity value is only computable if users have common rated items. The main contribution of this work is a possible solution to overcome this limitation. We propose a new content-collaborative hybrid recommender which computes similarities between users relying on their content-based profiles, in which user preferences are stored, instead of comparing their rating styles. In more detail, user profiles are clustered to discover current user neighbors. Content-based user profiles play a key role in the proposed hybrid recommender. Traditional keyword-based approaches to user profiling are unable to capture the semantics of user interests. A distinctive feature of our work is the integration of linguistic knowledge in the process of learning semantic user profiles representing user interests in a more effective way, compared to classical keyword-based profiles, due to a sense-based indexing. Semantic profiles are obtained by integrating machine learning algorithms for text categorization, namely a naive Bayes approach and a relevance feedback method, with a word sense disambiguation strategy based exclusively on the lexical knowledge stored in the WordNet lexical database. Experiments carried out on a content-based extension of the EachMovie dataset show an improvement of the accuracy of sense-based profiles with respect to keyword-based ones, when coping with the task of classifying movies as interesting (or not) for the current user. An experimental session has been also performed in order to evaluate the proposed hybrid recommender system. The results highlight the improvement in the predictive accuracy of collaborative recommendations obtained by selecting like-minded users according to user profiles.	Univ Bari, Dept Informat, I-70126 Bari, Italy	Degemmis, M (reprint author), Univ Bari, Dept Informat, Via E Orabona 4, I-70126 Bari, Italy.	degemmis@di.uniba.it; lops@di.uniba.it; semeraro@di.uniba.it					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714; Asnicar F., 1997, P 1 INT WORKSH AD SY, P3; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Billsus D., 1998, P 15 INT C MACH LEAR, P46; Bloehdorn S., 2004, P 10 ACM SIGKDD INT, P70; Bradley P.S., 1998, P 15 INT C MACH LEAR, P91; Breese JS, 1998, P 14 C UNC ART INT, P43; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; CLAYPOOL M, 1999, P ACM SIGIR WORKSH R; Cutting Douglass R., 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; DEGEMMIS M, 2005, THESIS U BARI; DEGEMMIS M, 2005, P 2 EUR WEB MIN FOR, P16; DEGEMMIS M, 2004, DESIGNING PERSONALIZ, P253; DELGADO J, 1999, P ACM SIGIR SORKSH R; Fellbaum C., 1998, WORDNET ELECT LEXICA; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Herlocker J. L., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312682; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Herlocker Jonathan L., 2000, P 2000 ACM C COMP SU, P241, DOI DOI 10.1145/358916.358995; Hirst G., 2001, P WORKSH WORDNET OTH, P29; Hotho A., 2003, P SEM WEB WORKSH SIG; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Larsen B., 1999, P 5 ACM SIGKDD INT C, P16, DOI 10.1145/312129.312186; LEACOCK C, 1998, WORDNET ELECT LEXICA, P266; Lee WS, 2001, P 18 INT C MACH LEAR, P314; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; LOPS P, 2005, THESIS U BARI; MAGNINI B, 2001, P 8 INT C US MOD, P74; MANNING C, 1999, WORD SENSE DISAMBIGU, P229; MASSA P, 2006, THESIS U TRENTO; Mavroeidis D, 2005, LECT NOTES ARTIF INT, V3721, P181; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; Melville P., 2002, P 18 NAT C ART INT, P187; Miller George A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; Mitchell T.M., 1997, MACHINE LEARNING; Mladenic D, 1999, IEEE INTELL SYST APP, V14, P44, DOI 10.1109/5254.784084; Mooney R.J., 2000, P 5 ACM C DIG LIB, P195, DOI DOI 10.1145/336597.336662; Nakamura A., 1998, P 15 INT C MACH LEAR, P395; Orkin M., 1990, VITAL STAT; Patwardhan S, 2003, LECT NOTES COMPUT SC, V2588, P241; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Resnick P., 1994, P ACM C COMP SUPP CO, Vpp, P175, DOI DOI 10.1145/192844.192905; RESNIK P, 1998, WORDNET ELECT LEXICA, P239; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; RODRIGUEZ MDB, 1997, 2 INT C REC ADV NLP, P150; Rosso P., 2004, P 2 INT WORDNET C RE, P299; Sarwar B., 2002, P 5 INT C COMP INF T; SARWAR B, 2000, P WEBKDD 2000 WORKSH; Sarwar B. M., 2000, ACM C EL COMM, P158; Schwab I., 2001, LEARNING USER INTERE; SCOTT S, 1998, COLING ACL WORKSH US, P45; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SEMERARO G, 2007, IN PRESS 20 INT JOIN; Shardanand U., 1995, P ACM CHI 95 C HUM F, V1, P210; SOBOROFF I, 1999, IJCAI 99 WORKSH MACH, P86; Stevenson M., 2003, WORD SENSE DISAMBIGU; TERVEEN L, 2001, HCI NEW MILLENNIUM, P223; THEOBALD M, 2004, P 7 INT WORKSH WEB D; Ungar L., 1998, P WORKSH REC SYST; Vozalis E., 2003, P 6 HELL EUR C COMP; WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000; Yang Y., 1997, P 14 INT C MACH LEAR, P412; YAO YY, 1995, J AM SOC INFORM SCI, V46, P133, DOI 10.1002/(SICI)1097-4571(199503)46:2<133::AID-ASI6>3.0.CO;2-Z	68	26	33	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-1868			USER MODEL USER-ADAP	User Model. User-Adapt. Interact.	JUL	2007	17	3					217	255		10.1007/s11257-006-9023-4		39	Computer Science, Cybernetics	Computer Science	171TZ	WOS:000246759600001	
J	Fan, H; Ramamohanarao, K				Fan, H; Ramamohanarao, K			Fast discovery and the generalization of strong jumping emerging patterns for building compact and accurate classifiers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; machine learning; emerging patterns; classification; frequent patterns; mining methods and algorithms	GENE-EXPRESSION PROFILES; DATABASES	Classification of large data sets is an important data mining problem that has wide applications. Jumping Emerging Patterns ( JEPs) are those itemsets whose supports increase abruptly from zero in one data set to nonzero in another data set. In this paper, we propose a fast, accurate, and less complex classifier based on a subset of JEPs, called Strong Jumping Emerging Patterns ( SJEPs). The support constraint of SJEP removes potentially less useful JEPs while retaining those with high discriminating power. Previous algorithms based on the manipulation of border [ 1] as well as consEPMiner [ 2] cannot directly mine SJEPs. Here, we present a new tree-based algorithm for their efficient discovery. Experimental results show that: 1) the training of our classifier is typically 10 times faster than earlier approaches, 2) our classifier uses much fewer patterns than the JEP-Classifier [ 3] to achieve a similar ( and, often, improved) accuracy, and 3) in many cases, it is superior to other state-of-the-art classification systems such as Naive Bayes, CBA, C4.5, and bagged and boosted versions of C4.5. We argue that SJEPs are high-quality patterns which possess the most differentiating power. As a consequence, they represent sufficient information for the construction of accurate classifiers. In addition, we generalize these patterns by introducing Noise-tolerant Emerging Patterns (NEPs) and Generalized Noise-tolerant Emerging Patterns ( GNEPs). Our tree-based algorithms can be adopted to easily discover these variations. We experimentally demonstrate that SJEPs, NEPs, and GNEPs are extremely useful for building effective classifiers that can deal well with noise.	Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic 3010, Australia	Fan, H (reprint author), Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic 3010, Australia.	hfan@csse.unimelb.edu.au; rao@csse.unimelb.edu.au					AGRAWAL R, 1992, PROC INT CONF VERY L, P560; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAILEY J, 2002, P 6 EUR C PRINC PRAC; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 1984, CLASSIFICATION REGRE; Cheeseman P., 1996, P 2 INT C KNOWL DISC, P153; Christensen R, 1997, LOG LINEAR MODELS LO; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Dong G., 1999, P 2 INT C DISC SCI, P30; Dong G., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Fan H., 2002, P 6 PAC AS C KNOWL D, P456; Fayyad U, 1996, AI MAG, V17, P37; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Freitas A. A., 2002, DATA MINING KNOWLEDG; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han J., 2000, DATA MINING CONCEPTS; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; LI J, 2003, BIOINFORMATICS S2, V19, P93; Li J., 2000, P 17 INT C MACH LEAR, P551; Li J., 2001, KNOWL INF SYST, V3, P131, DOI 10.1007/PL00011662; Li JY, 1999, LECT NOTES ARTIF INT, V1704, P406; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58; Liu H, 1998, ELEC SOC S, V98, P86; MITCHELL T, 1982, ARTIFICIAL INTELLIGE, V18; Mitchell T.M., 1997, MACHINE LEARNING; Pei J., 2001, P 2001 INT C DAT MIN; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ripley B., 1996, PATTERN RECOGNITION; *RULEQUEST, 2000, SEE5 C5 0 RULEQUEST; Seno M., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989558; Witten I.H., 1999, DATA MINING PRACTICA; Yang C., 2001, P 7 ACM SIGKDD INT C, P194, DOI 10.1145/502512.502539; Zhang X., 2000, P 6 INT C KNOWL DISC, P310, DOI 10.1145/347090.347158	39	26	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUN	2006	18	6					721	737		10.1109/TKDE.2006.95		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	033ML	WOS:000236851800001	
J	Chakrabarti, S; Roy, S; Soundalgekar, MV				Chakrabarti, S; Roy, S; Soundalgekar, MV			Fast and accurate text classification via multiple linear discriminant projections	VLDB JOURNAL			English	Article; Proceedings Paper	28th International Conference on Very Large Data Bases	AUG 20-23, 2002	HONG KONG, PEOPLES R CHINA			text classification; discriminative learning; linear discriminants		Support vector machines (SVMs) have shown superb performance for text classification tasks. They are accurate, robust, and quick to apply to test instances. Their only potential drawback is their training time and memory requirement. For n training instances held in memory, the best-known SVM implementations take time proportional to n(a), where a is typically between 1.8 and 2.1. SVMs have been trained on data sets with several thousand instances, but Web directories today contain millions of instances that are valuable for mapping billions of Web pages into Yahoo!-like directories. We present SIMPL, a nearly linear-time classification algorithm that mimics the strengths of SVMs while avoiding the training bottleneck. It uses Fisher's linear discriminant, a classical tool from statistical pattern recognition, to project training instances to a carefully selected low-dimensional subspace before inducing a decision tree on the projected instances. SIMPL uses efficient sequential scans and sorts and is comparable in speed and memory scalability to widely used naive Bayes (NB) classifiers, but it beats NB accuracy decisively. It not only approaches and sometimes exceeds SVM accuracy, but also beats the running time of a popular SVM implementation by orders of magnitude. While describing SIMPL, we make a detailed experimental comparison of SVM-generated discriminants with Fisher's discriminants, and we also report on an analysis of the cache performance of a popular SVM implementation. Our analysis shows that SIMPL has the potential to be the method of choice for practitioners who want the accuracy of SVMs and the simplicity and speed of naive Bayes classifiers.	Indian Inst Technol, Bombay, Maharashtra, India	Chakrabarti, S (reprint author), Indian Inst Technol, Bombay, Maharashtra, India.	soumen@cse.iitb.ac.in					AGRAWAL R, 2000, P 7 INT C EXT DAT TE; Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; CHAKRABARTI S, 1998, SCALABLE FEATURE SEL; Cooke T, 2002, IEEE T PATTERN ANAL, V24, P268, DOI 10.1109/34.982904; DASGUPTA S, 2000, UAI, V16, P143; Dasgupta S., 1999, FOCS, P634, DOI [10.1109/SFFCS.1999.814639, DOI 10.1109/SFFCS.1999.814639]; Duda R., 1973, PATTERN CLASSIFICATI; DUMAIS S, 1998, P 7 C INF KNOWL MAN; FRANKL P, 1988, J COMB THEORY B, V44, P355, DOI 10.1016/0095-8956(88)90043-3; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI 10.1145/502512.502527; Fung G, 2002, SIAM PROC S, P247; GRAEFE G, 1998, KNOWLEDGE DISCOVERY, V4, P204; JOACHIMS T, ADV KERNEL METHODS V; JOACHIMS T, 2001, P INT C RES DEV INF, V24, P128; Joachims T., 1998, LNCS, V1398, P137; Johnson R. A., 2001, APPL MULTIVARIATE ST; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; LeCun Y., 1993, ADV NEURAL INFORMATI, V5, P156; Lee Y.-J., 2001, P 1 SIAM INT C DAT M; Lewis D. D., 1997, REUTERS 21578 TEXT C; Lewis FD, 1996, J PHOTOCH PHOTOBIO A, V96, P19, DOI 10.1016/1010-6030(95)04285-7; Mangasarian OL, 1999, IEEE T NEURAL NETWOR, V10, P1032, DOI 10.1109/72.788643; MANGASARIAN OL, 2000, 0003 U WISC DAT MIN; McCallum A., 1998, AAAI ICML 98 WORKSH; MCCALLUM A, 1998, BOW TOOLKIT STAT LAN; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; NIGAM K, 1999, IJCAI 99 WORKSH MACH; PAVLOV D, 2000, P INT C PATT REC ICP; Platt J. C., 1998, MSRTR9814 MICR RES; SAHAMI M, 1998, 1998 WORKSH MAD WI; Schapire R.E., 2001, P MSRI WORKSH NONL E; Schutze H., 1995, SIGIR Forum; SHAFER JC, 1996, SPRINT SCALABLE PARA, P544; Shashua A, 1999, NEURAL PROCESS LETT, V9, P129, DOI 10.1023/A:1018677409366; SWAYNE DF, 1998, J COMPUTAT GRAPH STA, V7; VAPNIK V, 1996, ADV NEURAL INFORMATI; Witten I.H., 1999, DATA MINING PRACTICA	38	26	27	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1066-8888			VLDB J	VLDB J.	AUG	2003	12	2					170	185		10.1007/s00778-003-0098-9		16	Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	719KL	WOS:000185202200007	
J	Liggett, T; Melnikov, A; Yi, QL; Replogle, C; Brand, R; Kaul, K; Talamonti, M; Abrams, RA; Levenson, V				Liggett, Thomas; Melnikov, Anatoliy; Yi, Qi-long; Replogle, Charles; Brand, Randall; Kaul, Karen; Talamonti, Mark; Abrams, Ross A.; Levenson, Victor			Differential Methylation of Cell-Free Circulating DNA Among Patients With Pancreatic Cancer Versus Chronic Pancreatitis	CANCER			English	Article						DNA; methylation; plasma; pancreatitis; cancer	ABERRANT METHYLATION; DUCTAL ADENOCARCINOMA; MULTIPLE GENES; CA-19-9 LEVELS; CPG ISLAND; P16 GENES; INFLAMMATION; HYPERMETHYLATION; PROMOTER; INDUCTION	BACKGROUND: Although patients with chronic pancreatitis (CP) have an increased risk of pancreatic cancer (PanCa), the timely detection of PanCa often is difficult, because the symptoms of CP and PanCa are very similar. Moreover, secondary inflammation may be identified in PanCa, further complicating diagnosis. To improve the survival of patients with PanCa, a reliable test to differentiate CP from PanCa is needed. In this article, the authors describe a methylation profile of cell-free plasma DNA that distinguished CP from PanCa with >90% accuracy. METHODS: Methylation in cell-free, plasma DNA was compared among 30 samples from patients with CP, 30 samples from patients with PanCa, and 30 samples from healthy controls (N) using a microarray-mediated methylation analysis of 56 fragments in each sample (MethDet56). Statistical analysis was done by using the Fisher exact test, a naive Bayes algorithm, and 25 rounds of 5-fold cross-validation. RESULTS: The MethDet56 methylation analysis technique identified 17 gene promoters as informative (8 for distinguishing N from CP and 14 for distinguishing CP from PanCa). It achieved 81.7% sensitivity and 78% specificity (P<.01) in the detection of CP (N vs CP) and 91.2% sensitivity and 90.8% specificity (P<.01) in the differential detection of PanCa (PanCa vs CP). CONCLUSIONS: The current data suggested that, among patients with pancreatic disease, the methylation profiles of inflammatory disease and cancer are different and open a new venue for the development of biomarkers for differential diagnosis. Further investigation of diagnostic biomarkers for pancreatic cancer based on methylation in cell-free, circulating DNA appears to be warranted. Cancer 2010;116:1674-80. (C) 2010 American Cancer Society.	[Melnikov, Anatoliy; Abrams, Ross A.; Levenson, Victor] Rush Univ, Med Ctr, Dept Radiat Oncol, Chicago, IL 60612 USA; [Liggett, Thomas] Rush Univ, Med Ctr, Dept Neurol Sci, Chicago, IL 60612 USA; [Yi, Qi-long; Replogle, Charles] ScienceDocs Inc, Portland, OR USA; [Brand, Randall] Univ Pittsburgh, Med Ctr, Divis Gastroenterol Hepatol & Nutr, Pittsburgh, PA USA; [Kaul, Karen] NorthShore Univ Hlth Syst, Dept Pathol & Lab Med, Evanston, IL USA; [Talamonti, Mark] NorthShore Univ Hlth Syst, Dept Surg, Evanston, IL USA	Levenson, V (reprint author), Rush Univ, Med Ctr, Dept Radiat Oncol, 1750 W Harrison St,Jelke 1303, Chicago, IL 60612 USA.	victor_levenson@rush.edu					Balkwill F, 2004, NATURE, V431, P405, DOI 10.1038/431405a; Brand RE, 2007, GUT, V56, P1460, DOI 10.1136/gut.2006.108456; Brand RE, 2000, MED CLIN N AM, V84, P665, DOI 10.1016/S0025-7125(05)70249-2; Chen R, 2007, MOL CELL PROTEOMICS, V6, P1331, DOI 10.1074/mcp.M700072-MCP200; Coussens LM, 2002, NATURE, V420, P860, DOI 10.1038/nature01322; Cwik Grzegorz, 2004, Ann Univ Mariae Curie Sklodowska Med, V59, P213; Dammann R, 2003, ONCOGENE, V22, P3806, DOI 10.1038/sj.onc.1206582; Farrow B, 2002, SURG ONCOL, V10, P153, DOI 10.1016/S0960-7404(02)00015-4; Fukushima N, 2002, AM J PATHOL, V160, P1573, DOI 10.1016/S0002-9440(10)61104-2; Fukushima N, 2003, BRIT J CANCER, V89, P338, DOI 10.1038/sj.bjc.6601039; Fukushima N, 2003, CANCER BIOL THER, V2, P78; GENTLEMAN RC, 2004, GENOME BIOL, V5, P80; Goggins M, 1999, ANN ONCOL, V10, P4, DOI 10.1023/A:1008307913019; Goggins M, 2005, J CLIN ONCOL, V23, P4524, DOI 10.1200/JCO.2005.193=.711; Guerra C, 2007, CANCER CELL, V11, P291, DOI 10.1016/j.ccr.2007.01.012; Hodge DR, 2001, J BIOL CHEM, V276, P39508, DOI 10.1074/jbc.C100343200; Hruban RH, 2000, AM J PATHOL, V156, P1821, DOI 10.1016/S0002-9440(10)65054-7; Iordache Sevasti, 2008, J Gastrointestin Liver Dis, V17, P279; Jansen M, 2002, CANCER BIOL THER, V1, P293; Jemal A, 2008, CA-CANCER J CLIN, V58, P71, DOI 10.3322/CA.2007.0010; Kang GH, 2003, AM J PATHOL, V163, P1551, DOI 10.1016/S0002-9440(10)63511-0; Kim JE, 2004, J GASTROEN HEPATOL, V19, P182, DOI 10.1111/j.1440-1746.2004.03219.x; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kuroki T, 2004, SURG TODAY, V34, P981, DOI 10.1007/s00595-004-2858-6; Lowe D, 2006, SOUTH MED J, V99, P306, DOI 10.1097/01.smj.0000202695.97123.2b; Lu HT, 2006, MOL CANCER RES, V4, P221, DOI 10.1158/1541-7786.MCR-05-0261; Maitra A, 2005, ADV ANAT PATHOL, V12, P81, DOI 10.1097/01.pap.0000155055.14238.25; Martin ST, 2005, CANCER BIOL THER, V4, P728; Matsubayashi H, 2003, CLIN CANCER RES, V9, P1446; Matsubayashi H, 2006, CANCER RES, V66, P1208, DOI 10.1158/0008-5472.CAN-05-2664; Melnikov A, 2009, J MOL DIAGN, V11, P60, DOI 10.2353/jmoldx.2009.080072; Melnikov AA, 2008, J MOL DIAGN, V10, P93, DOI [10.2353/jmoldx.2008.070077, 10.2353/jmoldx2008070077]; MELNIKOV AA, 2008, J SURG ONCOL, V99, P119; Melnikov Anatoliy A, 2005, Nucleic Acids Res, V33, pe93, DOI 10.1093/nar/gni092; Murray MD, 2007, J CLIN GASTROENTEROL, V41, P115, DOI 10.1097/MCG.0b013e31802dd094; Omura N, 2008, CANCER BIOL THER, V7, P1146, DOI 10.4161/cbt.7.7.6208; Philip M, 2004, SEMIN CANCER BIOL, V14, P433, DOI 10.1016/j.semcancer.2004.06.006; Sato N, 2006, J HEPATO-BILIARY-PAN, V13, P286, DOI 10.1007/s00534-005-1057-1; Sato N, 2003, CANCER RES, V63, P4158; Sato N, 2006, CANCER, V107, P251, DOI 10.1002/cncr.21977; Schneider Gunter, 2003, Mol Cancer, V2, P15, DOI 10.1186/1476-4598-2-15; Schumacher M, 1997, STAT MED, V16, P2813, DOI 10.1002/(SICI)1097-0258(19971230)16:24<2813::AID-SIM701>3.0.CO;2-Z; SHIMOMURA C, 1989, J RHEUMATOL, V16, P1410; Sullivan KE, 2007, MOL CELL BIOL, V27, P5147, DOI 10.1128/MCB.02429-06; Ueki T, 2000, CANCER RES, V60, P1835; Ueki T, 2001, CANCER RES, V61, P8540; Ujiki MB, 2007, SEMIN ONCOL, V34, P311, DOI 10.1053/j.seminoncol.2007.05.004; van Gulik TM, 1999, ANN ONCOL, V10, P85, DOI 10.1023/A:1008353223014; Waki T, 2002, AM J PATHOL, V161, P399, DOI 10.1016/S0002-9440(10)64195-8; Whitcomb DC, 2004, AM J PHYSIOL-GASTR L, V287, pG315, DOI 10.1152/ajpgi.00115.2004	50	25	27	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0008-543X			CANCER-AM CANCER SOC	Cancer	APR 1	2010	116	7					1674	1680		10.1002/cncr.24893		7	Oncology	Oncology	574IV	WOS:000275983500009	
J	Cannon, EO; Amini, A; Bender, A; Sternberg, MJE; Muggleton, SH; Glen, RC; Mitchell, JBO				Cannon, Edward O.; Amini, Ata; Bender, Andreas; Sternberg, Michael J. E.; Muggleton, Stephen H.; Glen, Robert C.; Mitchell, John B. O.			Support vector inductive logic programming outperforms the naive Bayes classifier and inductive logic programming for the classification of bioactive chemical compounds	JOURNAL OF COMPUTER-AIDED MOLECULAR DESIGN			English	Article						classification; feature selection; machine learning; molecular similarity; screening	DRUG DISCOVERY; MOLECULAR SIMILARITY; FEATURE-SELECTION; DESCRIPTORS; FINGERPRINTS; INFORMATICS; MODEL	We investigate the classification performance of circular fingerprints in combination with the Naive Bayes Classifier (MP2D), Inductive Logic Programming (ILP) and Support Vector Inductive Logic Programming (SVILP) on a standard molecular benchmark dataset comprising 11 activity classes and about 102,000 structures. The Naive Bayes Classifier treats features independently while ILP combines structural fragments, and then creates new features with higher predictive power. SVILP is a very recently presented method which adds a support vector machine after common ILP procedures. The performance of the methods is evaluated via a number of statistical measures, namely recall, specificity, precision, F-measure, Matthews Correlation Coefficient, area under the Receiver Operating Characteristic (ROC) curve and enrichment factor (EF). According to the F-measure, which takes both recall and precision into account, SVILP is for seven out of the 11 classes the superior method. The results show that the Bayes Classifier gives the best recall performance for eight of the 11 targets, but has a much lower precision, specificity and F-measure. The SVILP model on the other hand has the highest recall for only three of the 11 classes, but generally far superior specificity and precision. To evaluate the statistical significance of the SVILP superiority, we employ McNemar's test which shows that SVILP performs significantly (p < 5%) better than both other methods for six out of 11 activity classes, while being superior with less significance for three of the remaining classes. While previously the Bayes Classifier was shown to perform very well in molecular classification studies, these results suggest that SVILP is able to extract additional knowledge from the data, thus improving classification results further.	Univ Cambridge, Unilever Ctr Mol Sci Informat, Dept Chem, Cambridge CB2 1EW, England; Univ London Imperial Coll Sci Technol & Med, Fac Nat Sci, Div Mol Biosci, London SW7 2AZ, England	Mitchell, JBO (reprint author), Univ Cambridge, Unilever Ctr Mol Sci Informat, Dept Chem, Lensfield Rd, Cambridge CB2 1EW, England.	jbom1@cam.ac.uk	Bender, Andreas/C-6942-2009; Mitchell, John/F-9863-2010	Bender, Andreas/0000-0002-6683-7546; Mitchell, John/0000-0002-0379-6097			A-RAZZAK M, 1992, Journal of Computer-Aided Molecular Design, V6, P349, DOI 10.1007/BF00125944; BARRETT SJ, 2006, APPL SOFT COMPUT, V19, P99; Bender A, 2006, ANN REP COMP CHEM, V2, P141, DOI 10.1016/S1574-1400(06)02009-3; Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; Bender A, 2005, J CHEM INF MODEL, V45, P1369, DOI 10.1021/ci05000177; Bohm H.-J, 2000, VIRTUAL SCREENING BI; Briem H, 2000, PERSPECT DRUG DISCOV, V20, P231, DOI 10.1023/A:1008793325522; Buttingsrud B, 2006, J COMPUT AID MOL DES, V20, P361, DOI 10.1007/s10822-006-9058-y; Cannon EO, 2006, J CHEM INF MODEL, V46, P2369, DOI 10.1021/ci0601160; DOWNS GM, 1994, J CHEM INF COMP SCI, V34, P1094, DOI 10.1021/ci00021a011; Dutra ID, 2003, LECT NOTES ARTIF INT, V2583, P48; Estrada E, 2001, CURR MED CHEM, V8, P1573; Gasteiger J., 2003, HDB CHEMOINFORMATICS; Glen RC, 2006, IDRUGS, V9, P199; Guha R, 2006, J CHEM INF MODEL, V46, P991, DOI 10.1021/ci050400b; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; HOCHE S, 2001, LECT NOTES ARTIF INT, V2157, P51; Joachims T., 1999, ADV KERNEL METHODS S; Johnson A. M., 1990, CONCEPTS APPL MOL SI; KING RD, 1992, P NATL ACAD SCI USA, V89, P11322, DOI 10.1073/pnas.89.23.11322; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; Leach A.R., 2003, INTRO CHEMOINFORMATI; Liu Y, 2004, J CHEM INF COMP SCI, V44, P1823, DOI 10.1021/ci049875d; Mason JS, 2001, CURR PHARM DESIGN, V7, P567, DOI 10.2174/1381612013397843; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Mitchell T.M., 1997, MACHINE LEARNING; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muggleton SH, 2000, P 10 INT WORKSH IND, P130; MUGGLETON SH, 2006, INNOVATIONS MACHINE, P113; MUGGLETON SH, 2005, P 8 INT C DISC SCI, V3735, P163; Patterson DE, 1996, J MED CHEM, V39, P3049, DOI 10.1021/jm960290n; Pompe Uros, 1995, P 5 INT WORKSH IND L, P417; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rodgers S, 2006, J CHEM INF MODEL, V46, P569, DOI 10.1021/ci0504418; Siegel S, 1988, NONPARAMETRIC STAT B	38	25	27	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-654X			J COMPUT AID MOL DES	J. Comput.-Aided Mol. Des.	MAY	2007	21	5					269	280		10.1007/s10822-007-9113-3		12	Biochemistry & Molecular Biology; Biophysics; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biophysics; Computer Science	159SM	WOS:000245886800004	
J	De Ferrari, L; Aitken, S				De Ferrari, Luna; Aitken, Stuart			Mining housekeeping genes with a Naive Bayes classifier	BMC GENOMICS			English	Article							NORMAL HUMAN TISSUES; EXPRESSION; DATABASE; IDENTIFICATION; COMPENDIUM	Background: Traditionally, housekeeping and tissue specific genes have been classified using direct assay of mRNA presence across different tissues, but these experiments are costly and the results not easy to compare and reproduce. Results: In this work, a Naive Bayes classifier based only on physical and functional characteristics of genes already available in databases, like exon length and measures of chromatin compactness, has achieved a 97% success rate in classification of human housekeeping genes ( 93% for mouse and 90% for fruit fly). Conclusion: The newly obtained lists of housekeeping and tissue specific genes adhere to the expected functions and tissue expression patterns for the two classes. Overall, the classifier shows promise, and in the future additional attributes might be included to improve its discriminating power.	Univ Edinburgh, Sch Informat, Edinburgh EH8 9LE, Midlothian, Scotland	De Ferrari, L (reprint author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9LE, Midlothian, Scotland.	ldeferra@inf.ed.ac.uk; stuart@aiai.ed.ac.uk					Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; Butte AJ, 2001, PHYSIOL GENOMICS, V7, P95; Castillo-Davis CI, 2002, NAT GENET, V31, P415, DOI [10.1038/ng940, 10.1038/ng1011]; DEFERRARI L, 2005, THESIS U EDINBURGH; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Eisenberg E, 2003, TRENDS GENET, V19, P362, DOI 10.1016/S0168-9525(03)00140-9; *EMSMART, ENSMART BIOMART EBI; Faure D, 2002, APPL ENVIRON MICROB, V68, P1485, DOI 10.1128/AEM.68.4.1485-1490.2002; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; GANAPATHI M, 2005, BMC BIOINFORMATICS, V6126, P126; Ge XJ, 2005, GENOMICS, V86, P127, DOI 10.1016/j.ygeno.2005.04.008; Harris MA, 2004, NUCLEIC ACIDS RES, V32, pD258, DOI 10.1093/nar/gkh036; Haverty PM, 2002, NUCLEIC ACIDS RES, V30, P214, DOI 10.1093/nar/30.1.214; Hsiao LL, 2001, PHYSIOL GENOMICS, V7, P97; Kasprzyk A, 2004, GENOME RES, V14, P160; Kiratisin P, 2005, DIAGN MICR INFEC DIS, V51, P297, DOI 10.1016/j.diagmicrobio.2004.12.001; Kothapalli R, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-22; Pancholi V, 2003, INT J MED MICROBIOL, V293, P391, DOI 10.1078/1438-4221-00283; Rice P, 2000, TRENDS GENET, V16, P276, DOI 10.1016/S0168-9525(00)02024-2; Shippy R, 2004, BMC GENOMICS, V5, DOI 10.1186/1471-2164-5-61; Su AI, 2002, P NATL ACAD SCI USA, V99, P4465, DOI 10.1073/pnas.012025199; Suter B, 2000, NUCLEIC ACIDS RES, V28, P4083, DOI 10.1093/nar/28.21.4083; Tan PK, 2003, NUCLEIC ACIDS RES, V31, P5676, DOI 10.1093/nar/gkg763; Tanabe K, 2004, J MOL EVOL, V59, P687, DOI 10.1007/s00239-004-2662-3; Wang YH, 1996, P NATL ACAD SCI USA, V93, P8863, DOI 10.1073/pnas.93.17.8863; Warrington JA, 2000, PHYSIOL GENOMICS, V2, P143; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Webb G.I., 2002, P AUSTR DAT MIN WORK, P65; Wheeler DL, 2003, NUCLEIC ACIDS RES, V31, P28, DOI 10.1093/nar/gkg033; Witten IH, 2005, DATA MINING PRACTICA	31	25	25	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics	OCT 30	2006	7								277	10.1186/1471-2164-7-277		14	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	105PM	WOS:000242044800001	
J	Pakhomov, SVS; Buntrock, JD; Chute, CG				Pakhomov, Serguei V. S.; Buntrock, James D.; Chute, Christopher G.			Automating the assignment of diagnosis codes to patient encounters using example-based and machine learning techniques	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							CHIEF COMPLAINTS; LANGUAGE; CLASSIFICATION; RADIOLOGY; SYSTEM	Objective: Human classification of diagnoses is a labor intensive process that consumes significant resources. Most medical practices use specially trained medical coders to categorize diagnoses for billing and research purposes. Methods: We have developed an automated coding system designed to assign codes to clinical diagnoses. The system uses the notion of certainty to recommend subsequent processing. Codes with the highest certainty are generated by matching the diagnostic text to frequent examples in a database of 22 million manually coded entries. These code assignments are not subject to subsequent manual review. Codes at a lower certainty level are assigned by matching to previously infrequently coded examples. The least certain codes are generated by a naive Bayes classifier. The latter two types of codes are subsequently manually reviewed. Measurements: Standard information retrieval accuracy measurements of precision, recall and f-measure were used. Micro- and macro-averaged results were computed. Results: At least 48% of all EMR problem list entries at the Mayo Clinic can be automatically classified with macro-averaged 98.0% precision, 98.3% recall and an f-score of 98.2%. An additional 34% of the entries are classified with macro-averaged 90.1% precision, 95.6% recall and 93.1% f-score. The remaining 18% of the entries are classified with macro-averaged 58.5%. Conclusion: Over two thirds of all diagnoses are coded automatically with high accuracy. The system has been successfully implemented at the Mayo Clinic, which resulted in a reduction of staff engaged in manual coding from thirty-four coders to seven verifiers.	Mayo Clin, Div Biomed Informat, Dept Hlth Sci Res, Rochester, MN USA	Pakhomov, SVS (reprint author), 200 1st St SW, Rochester, MN 55905 USA.	pakhomov.serguei@mayo.edu					ARONOW D, 1995, MED 1995 VANC CAN, P1; Aronow DB, 1999, J AM MED INFORM ASSN, V6, P393; ARONSKY D, 2000, AM MED INF ASS S AMI, P12; Chapman WW, 2005, ARTIF INTELL MED, V33, P31, DOI 10.1016/j.artmed.2004.04.001; CHUTE C, 1994, J AM MED INF ASS S S, V18, P162; *CPHA, 1973, H ICDA HOSP AD ICD A; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fiszman M, 2000, J AM MED INFORM ASSN, V7, P593; FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161; Friedman C., 2000, AMIA S, P270; GIORGETTI D, 2003, 18 ACM S APPL COMP 2, P798; Gundersen ML, 1996, COMPUT BIOMED RES, V29, P351, DOI 10.1006/cbmr.1996.0026; HARPELED S, 2003, C ADV NEUR INF PROC, P785; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Johnson DE, 2002, IBM SYST J, V41, P428; KURLAND LT, 1981, SCI AM, V245, P63; Lewis D.D., 1998, 10 EUR C MACH LEARN, P4; Manning C.D., 1999, FDN STAT NATURAL LAN; Melton LJ, 1996, MAYO CLIN PROC, V71, P266; Nigam K., 1999, P61; Pakhomov SV, 2004, ST HEAL T, V107, P411; PAYNE TH, 2003, AM MED INF ASS FALL; SAGER N, 1994, J AM MED INFORM ASSN, V1, P142; Travers DA, 2003, J BIOMED INFORM, V36, P260, DOI 10.1016/j.jbi.2003.09.007; WILCOX A, 2000, THESIS COLUMBIA U NY; Wilcox AB, 2003, J AM MED INFORM ASSN, V10, P330, DOI 10.1197/jamia.M1157; YANG Y, 1992, 14TH P INT C COMP LI, P447; Yang Y., 1994, 17 ANN INT ACM SIGIR, P13; YANG Y, 1994, J AM MED INFORM AS S, V18, P157	29	25	25	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1067-5027			J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	SEP-OCT	2006	13	5					516	525		10.1197/jamia.M2077		10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	085ME	WOS:000240607400008	
J	Liu, HF; Teller, V; Friedman, C				Liu, HF; Teller, V; Friedman, C			A multi-aspect comparison study of supervised word sense disambiguation	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							TERMS; TEXT	Objective: The aim of this study was to investigate relations among different aspects in supervised word sense disambiguation (WSD; supervised machine learning for disambiguating the sense of a term in a context) and compare supervised WSD in the biomedical domain with that in the general English domain. Methods: The study involves three data sets (a biomedical abbreviation data set, a general biomedical term data set, and a general English data set). The authors implemented three machine-learning algorithms, including (1) naive Bayes (NBL) and decision lists (TDLL), (2) their adaptation of decision lists (ODLL), and (3) their mixed supervised learning (MSL). There were six feature representations (various combinations of collocations, bag of words, oriented bag of words, etc.) and five window sizes (2, 4, 6, 8, and 10). Results: Supervised WSD is suitable only when there are enough sense-tagged instances with at least a few dozens of instances for each sense. Collocations combined with neighboring words are appropriate selections for the context. For terms with unrelated biomedical senses, a large window size such as the whole paragraph should be used, while for general English words a moderate window size between 4 and 10 should be used. The performance of the authors' implementation of decision list classifiers for abbreviations was better than that of traditional decision list classifiers. However, the opposite held for the other two sets. Also, the authors' mixed supervised learning was stable and generally better than others for all sets. Conclusion: From this study, it was found that different aspects of supervised WSD depend on each other. The experiment method presented in the study can be used to select the best supervised WSD classifier for each ambiguous term.	Univ Maryland Baltimore Cty, Dept Informat Syst, Baltimore, MD 21250 USA; CUNY Hunter Coll, Dept Comp Sci, New York, NY 10021 USA; Columbia Univ, Dept Biomed Informat, New York, NY USA	Liu, HF (reprint author), Univ Maryland Baltimore Cty, Dept Informat Syst, 1000 Hilltop Circle, Baltimore, MD 21250 USA.	hfliu@umbc.edu					AHA D, 1991, MACH LEARN, V7, P33; Bruce R.F., 1994, P 32 ANN M ASS COMP, P139, DOI 10.3115/981732.981752; Duda R., 1973, PATTERN CLASSIFICATI; ENGELSON SP, 1996, P 34 ANN M ASS COMP, V34, P319; ESCUDERO G, 2000, P 14 EUR C ART INT E, P421; Escudero G., 2000, P 12 EUR C MACH LEAR, P129; Fujii A, 1998, COMPUT LINGUIST, V24, P573; Ide N, 1998, COMPUT LINGUIST, V24, P1; JORGENSEN JC, 1990, J PSYCHOLINGUIST RES, V19, P167, DOI 10.1007/BF01077415; KILGARRIFF A, 1999, COMPUT HUMANITIES, V34, P1; LACOCK C, 1993, P ADV RES PROJ AG AR, P260; Leacock C, 1998, COMPUT LINGUIST, V24, P147; Liu HF, 2002, J AM MED INFORM ASSN, V9, P621, DOI 10.1097/jamia.M1101; Liu HF, 2001, J BIOMED INFORM, V34, P249, DOI 10.1006/jbin.2001.1023; MARQUEZ L, 2000, LSI0045R U POL CAT D; MOONEY R, 1997, INDUCTIVE LOGIC PROG; Mooney R. J., 1996, P C EMP METH NAT LAN, P82; Ng H.T., 1996, P 34 ANN M ASS COMP, P40, DOI 10.3115/981863.981869; NG HT, 1997, AI MAGAZINE      WIN, P45; Ng H.T., 1997, P 2 C EMP METH NAT L, P208; Ng H.T., 1997, P ACL SIGLEX WORKSH, P1; Towell G, 1998, COMPUT LINGUIST, V24, P125; VERONIS J, 1990, P EUR C ART INT, P366; Weeber M, 2001, Proc AMIA Symp, P746; WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000; Yarowsky David, 1994, P 32 ANN M ASS COMP, P88, DOI 10.3115/981732.981745	26	25	26	HANLEY & BELFUS INC	PHILADELPHIA	210 S 13TH ST, PHILADELPHIA, PA 19107 USA	1067-5027			J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JUL-AUG	2004	11	4					320	331		10.1197/jamia.M1533		12	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	837UZ	WOS:000222667800014	
J	Qi, F; Zhu, AX				Qi, F; Zhu, AX			Knowledge discovery from soil maps using inductive learning	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article							FOREST ECOSYSTEM PROCESSES; LEAF-AREA INDEX; WATERSHED SCALE; EXTRACTION; NETWORKS; MODEL	This paper develops a knowledge discovery procedure for extracting knowledge of soil-landscape models from a soil map. It has broad relevance to knowledge discovery from other natural resource maps. The procedure consists of four major steps: data preparation, data preprocessing, pattern extraction, and knowledge consolidation. In order to recover true expert knowledge from the error-prone soil maps, our study pays specific attention to the reduction of representation noise in soil maps. The data preprocessing step has exhibited an important role in obtaining greater accuracy. A specific method for sampling pixels based on modes of environmental histograms has proven to be effective in terms of reducing noise and constructing representative sample sets. Three inductive learning algorithms, the See5 decision tree algorithm, Naive Bayes, and artificial neural network, are investigated for a comparison concerning learning accuracy and result comprehensibility. See5 proves to be an accurate method and produces the most comprehensible results, which are consistent with the rules (expert knowledge) used in producing the soil map. The incorporation of spatial information into the knowledge discovery process is found not only to improve the accuracy of the extracted knowledge, but also to add to the explicitness and extensiveness of the extracted soil-landscape model.	Univ Wisconsin, Dept Geog, Madison, WI 53706 USA; Chinese Acad Sci, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China; Chinese Acad Sci, Inst Geog Sci & Nat Resources, Beijing 100101, Peoples R China	Qi, F (reprint author), Univ Wisconsin, Dept Geog, 550 N Park St, Madison, WI 53706 USA.						BAND LE, 1993, AGR FOREST METEOROL, V63, P93, DOI 10.1016/0168-1923(93)90024-C; BRUIN SD, 1999, GEODERMA, V91, P151; Craven MW, 1997, INT J NEURAL SYST, V8, P373, DOI 10.1142/S0129065797000380; Deka B, 1995, ARID SOIL RES REHAB, V10, P149; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Ester M., 2001, GEOGRAPHIC DATA MINI, P160, DOI 10.4324/9780203468029_chapter_7; Fassnacht KS, 1997, REMOTE SENS ENVIRON, V61, P229, DOI 10.1016/S0034-4257(97)00005-9; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Gahegan M, 2000, GEOGR ANAL, V32, P113; GLINKA KD, 1927, GREAT SOIL GROUPS WO; HUDSON BD, 1992, SOIL SCI SOC AM J, V56, P836; Hudson B. D., 1990, Soil Survey Horizons, V31, P63; Jenny H., 1961, EW HILGARD BIRTH MOD; KOPERSKI K, 1999, MINING KNOWLEDGE GEO; Malerba D., 2001, GEOGRAPHIC DATA MINI, P291, DOI 10.4324/9780203468029_chapter_12; MCLEOD M, 1995, AUST J SOIL RES, V33, P381, DOI 10.1071/SR9950381; McSweeney K., 1994, SSSA SPEC PUBL, P127; Mennis JL, 2000, INT J GEOGR INF SCI, V14, P501, DOI 10.1080/136588100415710; Miller H. J., 2001, GEOGRAPHIC DATA MINI, P3, DOI 10.4324/9780203468029_chapter_1; Minsky M. A., 1975, PSYCHOL COMPUTER VIS; Mitchell T.M., 1997, MACHINE LEARNING; MOORE ID, 1993, SOIL SCI SOC AM J, V57, P443; Moran CJ, 2002, INT J GEOGR INF SCI, V16, P533, DOI 10.1080/13658810210138715; MULDER JA, 1996, GIS APPL NATURAL RES, V2, P392; Murray AT, 1998, INT J GEOGR INF SCI, V12, P431; NEMANI R, 1993, INT J REMOTE SENS, V14, P2519; OCALLAGHAN JF, 1984, COMPUT VISION GRAPH, V28, P323, DOI 10.1016/S0734-189X(84)80011-0; QUINLAN JR, 2001, SEE5 INFORMAL TUTORA; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Russell S., 1995, ARTIFICIAL INTELLIGE; Eklund PW, 1998, INT J GEOGR INF SCI, V12, P247, DOI 10.1080/136588198241888; Wright RL, 1996, CATENA, V27, P1, DOI 10.1016/0341-8162(96)00004-5; Zadeh LA, 1965, INFORM CONTR, V8, P353; ZHU A. X., 1994, CAN J REMOTE SENS, V20, P408; Zhu AX, 1999, INT J GEOGR INF SCI, V13, P119, DOI 10.1080/136588199241382; Zhu AX, 1997, GEODERMA, V77, P217, DOI 10.1016/S0016-7061(97)00023-2; Zhu AX, 2001, SOIL SCI SOC AM J, V65, P1463	39	25	33	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816			INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	DEC	2003	17	8					771	795		10.1080/13658810310001596049		25	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	734QR	WOS:000186068500003	
B	Kolter, JZ; Maloof, MA		Wu, XD; Tuzhilin, A; Shavlik, J		Kolter, JZ; Maloof, MA			Dynamic weighted majority: A new ensemble method for tracking concept drift	THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	MELBOURNE, FL	IEEE Comp Soc TCCI, IEEE Comp Soc TCPAMI			ALGORITHMS	Algorithms for tracking concept drift are important for many applications. We present a general method based on the Weighted Majority algorithm for using any online learner for concept drift. Dynamic Weighted Majority (DWM) maintains an ensemble of base learners, predicts using a weighted-majority vote of these "experts", and dynamically creates and deletes experts in response to changes in performance. We empirically evaluated two experimental systems based on the method using incremental naive Bayes and Incremental Tree Inducer (ITI) as experts. For the sake of comparison, we also included Blum's implementation of Weighted Majority. On the STAGGER Concepts and on the SEA Concepts, results suggest that the ensemble method learns drifting concepts almost as well as the base algorithms learn each concept individually Indeed, we report the best overall results for these problems to date.	Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA	Kolter, JZ (reprint author), Georgetown Univ, Dept Comp Sci, Washington, DC 20057 USA.	jzk@cs.georgetown.edu; maloof@cs.georgetown.edu					Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C. L., 1998, UCI REPOSITORY MACHI; Blum A, 1997, MACH LEARN, V26, P5, DOI 10.1023/A:1007335615132; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; DOMINGOS P, 2000, P 6 ACM INT C KNOWL; Fan W, 1999, P 5 ACM SIGKDD INT C, P362, DOI 10.1145/312129.312283; FERN A, 2003, MACHINE LEARNING, V53; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Hulten G., 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; JOHN GH, 1995, P 11 C UNC ART INT, P338; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Maclin R., 1997, P 14 NAT C ART INT, P546; MALOOF M, IN PRESS ARTIFICIAL; Maloof MA, 2003, IEEE IJCNN, P2764; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; MICHALSKI RS, 1983, UIUCDCSF83905; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Schlimmer J. C., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Street W.N., 2001, P 7 ACM SIGKDD INT C, P377, DOI DOI 10.1145/502512.502568; Utgoff PE, 1997, MACH LEARN, V29, P5, DOI 10.1023/A:1007413323501; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900	26	25	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1978-4				2003							123	130				8	Computer Science, Artificial Intelligence	Computer Science	BY34Z	WOS:000188999400016	
J	CARLIN, BP; GELFAND, AE				CARLIN, BP; GELFAND, AE			A SAMPLE REUSE METHOD FOR ACCURATE PARAMETRIC EMPIRICAL BAYES CONFIDENCE-INTERVALS	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-METHODOLOGICAL			English	Article						BIAS CORRECTION; CONDITIONAL CALIBRATION; CONFIDENCE INTERVAL; PARAMETRIC BOOTSTRAP; PARAMETRIC EMPIRICAL BAYES METHODS		Parametric empirical Bayes (EB) methods of point estimation for a vector of unknown parameters data to the landmark paper of James and Stein (1961). The usual approach is to use the mean of the estimated posterior distribution of each parameter, where the estimation of the prior parameters ('hyperparameters') is accomplished through the marginal distribution of the data. While point estimates computed this way usually perform well, interval estimates based on the estimated posterior (called 'naive' EB intervals) do not. They fail to account for the variability in the estimation of the hyperparameters, generally resulting in subnominal coverage probability in the EB sense defined in Morris (1983a). In this paper we extend our earlier work in which we proposed a conditional bias correction method for developing EB intervals which corrects the deficiencies in the naive intervals. We show how bias correction can be implemented in general via a type III parametric bootstrap procedure, a sample reuse method first employed by Laird and Louis (1987). Theoretical and simulation work indicates that the resulting intervals are accurate with respect to nominal coverage. We give a specific application (to Poisson failure rate data) where we compute simultaneous point and bias-corrected interval estimates.	UNIV CONNECTICUT,DEPT STAT,BOX U-120,STORRS,CT 06269							CARLIN BP, 1990, IN PRESS J AM STATIS; DEELY JJ, 1981, J AM STAT ASSOC, V76, P833, DOI 10.2307/2287578; GAVER DP, 1987, TECHNOMETRICS, V29, P1, DOI 10.2307/1269878; GELFAND AE, IN PRESS J AM STATIS; HILL JR, 1990, IN PRESS BIOMETRIKA; James W., 1961, 4TH P BERK S MATH ST, V1, P361; KASS RE, 1988, 386 CARN MELL U DEP; LAIRD NM, 1987, J AM STAT ASSOC, V82, P739, DOI 10.2307/2288778; Morris C, 1983, SCI INFERENCE DATA A, P25; MORRIS CN, 1983, J AM STAT ASSOC, V78, P47, DOI 10.2307/2287098; MORRIS CN, 1987, 46 U TEX CTR STAT SC; NAYLOR JC, 1982, APPL STAT-J ROY ST C, V31, P214, DOI 10.2307/2347995; RUBIN DB, 1984, ANN STAT, V12, P751; RUBIN DB, 1982, J EDUC STATIST, V6, P377; SMITH AFM, 1985, COMMUN STAT-THEOR M, V14, P1079, DOI 10.1080/03610928508828963; SMITH AFM, 1987, STATISTICIAN, V36, P75, DOI 10.2307/2348499; TIERNEY L, 1986, J AM STAT ASSOC, V81, P82, DOI 10.2307/2287970; WORLEDGE DH, 1982, NP2592 EL POW RES I	18	25	25	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD, OXON, ENGLAND OX4 1JF	0035-9246			J ROY STAT SOC B MET	J. R. Stat. Soc. Ser. B-Methodol.		1991	53	1					189	200				12	Statistics & Probability	Mathematics	FA447	WOS:A1991FA44700008	
J	Rosen, GL; Reichenberger, ER; Rosenfeld, AM				Rosen, Gail L.; Reichenberger, Erin R.; Rosenfeld, Aaron M.			NBC: the Naive Bayes Classification tool webserver for taxonomic classification of metagenomic reads	BIOINFORMATICS			English	Article							COMMUNITY	Motivation: Datasets from high-throughput sequencing technologies have yielded a vast amount of data about organisms in environmental samples. Yet, it is still a challenge to assess the exact organism content in these samples because the task of taxonomic classification is too computationally complex to annotate all reads in a dataset. An easy-to-use webserver is needed to process these reads. While many methods exist, only a few are publicly available on webservers, and out of those, most do not annotate all reads. Results: We introduce a webserver that implements the naive Bayes classifier (NBC) to classify all metagenomic reads to their best taxonomic match. Results indicate that NBC can assign next-generation sequencing reads to their taxonomic classification and can find significant populations of genera that other classifiers may miss.	[Rosen, Gail L.] Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA; [Reichenberger, Erin R.] Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, Philadelphia, PA 19104 USA; [Rosenfeld, Aaron M.] Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA	Rosen, GL (reprint author), Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA.	gailr@ece.drexel.edu			National Science Foundation [0845827]; Department of Energy [DE-SC0004335]	Supported in part by the National Science Foundation CAREER award #0845827 and Department of Energy award DE-SC0004335.	ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Foster B, 2010, STAND GENOMIC SCI, V2, P1, DOI 10.4056/sigs.571102; Gerlach W, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-430; Hery M, 2010, WATER RES, V44, P6133, DOI 10.1016/j.watres.2010.07.003; Huson DH, 2007, GENOME RES, V17, P377, DOI 10.1101/gr.5969107; McHardy AC, 2007, NAT METHODS, V4, P63, DOI 10.1038/NMETH976; Meyer F, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-386; Overbeek R, 2005, NUCLEIC ACIDS RES, V33, P5691, DOI 10.1093/nar/gki866; Pond SK, 2009, GENOME RES, V19, P2144, DOI 10.1101/gr.094508.109; Rosen G, 2008, ADV BIOINFORMATICS, V2008; Rosen GL, 2009, CURR GENOMICS, V10, P493, DOI 10.2174/138920209789208255; Schluter A, 2008, J BIOTECHNOL, V136, P77, DOI 10.1016/j.jbiotec.2008.05.008; SESHADRI R, 2007, PLOS BIOL, V5; Vinneras B, 2006, SCI TOTAL ENVIRON, V367, P606, DOI 10.1016/j.scitotenv.2006.02.008	14	24	25	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JAN	2011	27	1					127	129		10.1093/bioinformatics/btq619		3	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	698WV	WOS:000285626300017	
J	Dale, JM; Popescu, L; Karp, PD				Dale, Joseph M.; Popescu, Liviu; Karp, Peter D.			Machine learning methods for metabolic pathway prediction	BMC BIOINFORMATICS			English	Article							DATABASES; GENOMES; NETWORKS; ENZYMES; METACYC; MODEL	Background: A key challenge in systems biology is the reconstruction of an organism's metabolic network from its genome sequence. One strategy for addressing this problem is to predict which metabolic pathways, from a reference database of known pathways, are present in the organism, based on the annotated genome of the organism. Results: To quantitatively validate methods for pathway prediction, we developed a large "gold standard" dataset of 5,610 pathway instances known to be present or absent in curated metabolic pathway databases for six organisms. We defined a collection of 123 pathway features, whose information content we evaluated with respect to the gold standard. Feature data were used as input to an extensive collection of machine learning (ML) methods, including naive Bayes, decision trees, and logistic regression, together with feature selection and ensemble methods. We compared the ML methods to the previous PathoLogic algorithm for pathway prediction using the gold standard dataset. We found that ML-based prediction methods can match the performance of the PathoLogic algorithm. PathoLogic achieved an accuracy of 91% and an F-measure of 0.786. The ML-based prediction methods achieved accuracy as high as 91.2% and F-measure as high as 0.787. The ML-based methods output a probability for each predicted pathway, whereas PathoLogic does not, which provides more information to the user and facilitates filtering of predicted pathways. Conclusions: ML methods for pathway prediction perform as well as existing methods, and have qualitative advantages in terms of extensibility, tunability, and explainability. More advanced prediction methods and/or more sophisticated input features may improve the performance of ML methods. However, pathway prediction performance appears to be limited largely by the ability to correctly match enzymes to the reactions they catalyze based on genome annotations.	[Dale, Joseph M.; Popescu, Liviu; Karp, Peter D.] SRI Int, Bioinformat Res Grp, Menlo Pk, CA 94025 USA	Karp, PD (reprint author), SRI Int, Bioinformat Res Grp, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA.	pkarp@ai.sri.com			National Institutes of Health [LM009651]	We are grateful to Ron Caspi for extensive discussions of the pathway prediction problem, review of the gold standard dataset, and assistance with examination of pathway prediction errors. This work was funded by grant LM009651 from the National Institutes of Health. The contents of this publication are solely the responsibility of the authors and do not necessarily represent the official views of the National Institutes of Health.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; BUNTINE W, 1991, FIA9128 NASA AM RES; Cakmak A, 2007, BIOINFORMATICS, V23, P2775, DOI 10.1093/bioinformatics/btm409; Caspi R, 2008, NUCLEIC ACIDS RES, V36, pD623, DOI 10.1093/nar/gkm900; DeJongh M, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-139; Feist AM, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100155; Green ML, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-76; Green ML, 2006, NUCLEIC ACIDS RES, V34, P3687, DOI 10.1093/nar/gkl438; Karp Peter D, 2002, Bioinformatics, V18 Suppl 1, pS225; KASTENMULLER G, 2008, BIOINFORMATICS, V24, P56; Kastenmuller G, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-3-r28; Keseler IM, 2009, NUCLEIC ACIDS RES, V37, pD464, DOI 10.1093/nar/gkn751; Liao L., 2002, P 6 INT C KNOWL BAS, P469; Matthews L, 2009, NUCLEIC ACIDS RES, V37, pD619, DOI 10.1093/nar/gkn863; McShan DC, 2003, BIOINFORMATICS, V19, P1692, DOI 10.1093/bioinformatics/btg217; Okuda S, 2008, NUCLEIC ACIDS RES, V36, pW423, DOI 10.1093/nar/gkn282; Overbeek R, 2005, NUCLEIC ACIDS RES, V33, P5691, DOI 10.1093/nar/gki866; Paley SM, 2002, BIOINFORMATICS, V18, P715, DOI 10.1093/bioinformatics/18.5.715; Pinney JW, 2005, NUCLEIC ACIDS RES, V33, P1399, DOI 10.1093/nar/gki285; PIREDDU L, 2005, CIBCS 05 P 2005 IEEE, P1; Pireddu L, 2006, NUCLEIC ACIDS RES, V34, pW714, DOI 10.1093/nar/gkl228; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Stone C. J., 1996, COURSE PROBABILITY S; Sun JB, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-112; VARMA A, 1994, BIO-TECHNOL, V12, P994, DOI 10.1038/nbt1094-994; Yamanishi Y., 2005, BIOINFORMATICS S1, V21, P468; YE Y, 2005, BIOINFORMATICS, V21, P478; Zhang PF, 2005, PLANT PHYSIOL, V138, P27, DOI 10.1104/pp.105.060376	31	24	24	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JAN 8	2010	11								15	10.1186/1471-2105-11-15		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	564FN	WOS:000275198800001	
J	Tan, SB; Zhang, J				Tan, Songbo; Zhang, Jin			An empirical study of sentiment analysis for chinese documents	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						sentiment analysis; information retrieval; machine learning		Up to now, there are very few researches conducted on sentiment classification for Chinese documents. In order to remedy this deficiency, this paper presents an empirical study of sentiment categorization on Chinese documents. Four feature selection methods (MI, IG, CHI and DF) and five learning methods (centroid classifier, K-nearest neighbor, winnow classifier, Naive Bayes and SVM) are investigated on a Chinese sentiment corpus with a size of 1021 documents. The experimental results indicate that IG performs the best for sentimental terms selection and SVM exhibits the best performance for sentiment classification. Furthermore, we found that sentiment classifiers are severely dependent on domains or topics. (c) 2007 Elsevier Ltd. All rights reserved.	[Tan, Songbo; Zhang, Jin] Chinese Acad Sci, Inst Comp Technol, Intelligent Software Dept, Beijing 100080, Peoples R China	Tan, SB (reprint author), Chinese Acad Sci, Inst Comp Technol, Intelligent Software Dept, POB 2704, Beijing 100080, Peoples R China.	tansongbo@software.ict.ac.cn	Tan, Songbo/A-7450-2012				CHAOVALIT P, 2005, IEEE P 38 HAW INT C, P1; GALAVOTTI L, 2000, P KDD; Gamon M., 2004, P 20 INT C COMP LING; HAN E, 2000, PKDD; Hatzivassiloglou V., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640; Joachims Th., 1998, EUR C MACH LEARN ECM, P137; KENNEDY A, 2005, WORKSH AN INF FORM I; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Mullen T., 2004, P C EMP METH NAT LAN, P412; Pang B., 2002, P EMNLP 2002; STONE PJ, 1966, GEN INQUIRER COMPTER; TURNEY DP, 2002, EGB1094 NAT RES COUN; TURNEY PD, 2002, P ASS COMP LING 4 AN; Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; VANMUN PPT, TEXT CLASSIFICATION; Vapnik V., 1995, NATURE STAT LEARNING; Whitelaw C., 2005, CIKM, P625, DOI DOI 10.1145/1099554.1099714; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42; Yang Y., 2001, SIGIR, P137; Yang Y., 1997, ICML 97, P412; YE Q, 2005, 4 INT C MACH LEARN C; YE Q, 2006, P HICSS 39 HAW INT C; Zhang Huaping, 2003, 2 SIGHAN WORKSH AFF, P63; Zhang T, 2001, ADV NEUR IN, V13, P703	25	24	29	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	MAY 4	2008	34	4					2622	2629		10.1016/j.eswa.2007.05.028		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	267PO	WOS:000253521900038	
J	Huang, Y; McCullagh, P; Black, N; Harper, R				Huang, Yue; McCullagh, Paul; Black, Norman; Harper, Roy			Feature selection and classification model construction on type 2 diabetic patients' data	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						type 2 diabetes; blood glucose; data mining; classification; feature selection	CIGARETTE-SMOKING; RISK-FACTORS; MELLITUS; DISEASE; GLUCOSE; COMPLICATIONS; ADOLESCENTS; POPULATION; DEFINITION; MANAGEMENT	Objective: Diabetes affects between 2% and 4% of the global population (up to 10% in the over 65 age group), and its avoidance and effective treatment are undoubtedly crucial public health and health economics issues in the 21st century. The aim of this research was to identify significant factors influencing diabetes control, by applying feature selection to a working patient management system to assist with ranking, classification and knowledge discovery. The classification models can be used to determine individuals in the population with poor diabetes control status based on physiological and examination factors. Methods: The diabetic patients' information was collected by Ulster Community and Hospitals Trust (UCHT) from year 2000 to 2004 as part of clinical management. In order to discover key predictors and latent knowledge, data mining techniques were applied. To improve computational efficiency, a feature selection technique, feature selection via supervised model construction (FSSMC), an optimisation of ReliefF, was used to rank the important attributes affecting diabetic control. After selecting suitable features, three complementary classification techniques (Naive Bayes, IB1 and C4.5) were applied to the data to predict how well the patients' condition was controlled. Results: FSSMC identified patients' 'age', 'diagnosis duration', the need for 'insulin treatment', 'random blood glucose' measurement and 'diet treatment' as the most important factors influencing blood glucose control. Using the reduced features, a best predictive accuracy of 95% and sensitivity of 98% was achieved. The influence of factors, such as 'type of care' delivered, the use of 'home monitoring', and the importance of 'smoking' on outcome can contribute to domain knowledge in diabetes control. Conclusion: In the care of patients with diabetes, the more important factors identified: patients' 'age', 'diagnosis duration' and 'family history', are beyond the control of physicians. Treatment methods such as 'insulin', 'diet' and 'tablets' (a variety of oral medicines) may be controlled. However lifestyle indicators such as 'body mass index' and 'smoking status' are also important and may be controlled by the patient. This further underlines the need for public health education to aid awareness and prevention. More subtle data interactions need to be better understood and data mining can contribute to the clinical evidence base. The research confirms and to a lesser extent challenges current thinking. Whilst fully appreciating the requirement for clinical verification and interpretation, this work supports the use of data mining as an exploratory tool., particularly as the domain is suffering from a data explosion due to enhanced monitoring and the (potential) storage of this data in the electronic health record, FSSMC has proved a useful feature estimator for large data sets, where processing efficiency is an important factor. (c) 2007 Elsevier B.V. All rights reserved.	Univ London Imperial Coll Sci Technol & Med, Fac Engn, Dept Comp, London SW7 2AZ, England; Univ Ulster, Fac Engn, Sch Comp & Math, Jordanstown BT37 0QB, North Ireland; Ulster Hosp, Belfast BT16 0RH, Antrim, North Ireland	Huang, Y (reprint author), Univ London Imperial Coll Sci Technol & Med, Fac Engn, Dept Comp, London SW7 2AZ, England.	y.huang@imperial.ac.uk					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AIRES R, 2004, NILCTR0409 U SAO PAU; Alberti KGMM, 1998, DIABETIC MED, V15, P539, DOI 10.1002/(SICI)1096-9136(199807)15:7<539::AID-DIA668>3.0.CO;2-S; *AM COLL PHYS, 2006, ANN INTERN MED, V138, P1; Bakris GL, 1998, KIDNEY INT, V54, P1283, DOI 10.1046/j.1523-1755.1998.00083.x; BENNET PH, 1990, ELLENBERG RIFKINS DI, P363; Brug J, 1999, PATIENT EDUC COUNS, V36, P145, DOI 10.1016/S0738-3991(98)00131-1; Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866; CHERASKIN E, 1993, J ORTHOMOL MED, V8, P6; CORNFORTH D, 2002, P 6 AUSTR JAP JOINT, P141; CRONE S, 2004, P INT JOINT C NEURAL, P443; CROXSON SCM, 1991, DIABETIC MED, V8, P28; Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1; Demsar J, 2001, INT J MED INFORM, V63, P41, DOI 10.1016/S1386-5056(01)00170-8; Department of Health, 2005, SUPP PEOPL LONG TERM; Department of health, 2005, SELF CAR REAL CHOIC; Knowler WC, 2002, NEW ENGL J MED, V346, P393; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; FONTBONNE A, 1992, DIABETOLOGIA, V35, P464, DOI 10.1007/BF02342445; FRANZ MJ, 2001, CLIN DIABETES, V19, P105, DOI 10.2337/diaclin.19.3.105; Gan D, 2003, DIABETES ATLAS; GRZYMALABUSSE J, 2003, DATA MINING BIOINFOR; GUTHRIE RA, 2002, NURSING MANAGEMENT D; Hall LO, 2002, PROC INT C TOOLS ART, P233, DOI 10.1109/TAI.2002.1180809; HALL M, 1999, THESIS U WAIKATO DEP; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; HANSEN BC, 1993, DIABETES, V42, P1809, DOI 10.2337/diabetes.42.12.1809; HARRIS MI, 1991, DIABETES CARE, V14, P639, DOI 10.2337/diacare.14.7.639; HUANG Y, 2004, P 4 IEEE INT C DAT M, P411; Inza I, 2002, J INTELL FUZZY SYST, V12, P25; Kantardzic M, 2002, DATA MINING CONCEPTS; KAUDERER K, 1997, CLASSIFICATION DATA; KNOWLER WC, 1990, DIABETES METAB REV, V6, P1; KONONENKO I, 1995, P ISSEK WORKSH MATH, P199; Kononenko I., 1994, P EUR C MACH LEARN, P171; Lavrac N., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; Lewis D., 1994, P 17 ANN INT ACM SIG, P3; Liu H, 2004, ARTIF INTELL, V159, P49, DOI 10.1016/j.artini.2004.05.009; Lorig KR, 2003, ANN BEHAV MED, V26, P1, DOI 10.1207/S15324796ABM2601_01; Marcovecchio M, 2005, J ENDOCRINOL INVEST, V28, P853; MARTIN B, 1995, THESIS U WAIKATO DEP; Mitchell M., 1997, MACHINE LEARNING; Molina L. C., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183917; NEWMAN B, 1987, DIABETOLOGIA, V30, P763; Newman DJ, 1998, UCI REPOSITORY MACHI; NISSEN SE, 2007, N ENGL J MED, V365; Perner P, 2001, APPL ARTIF INTELL, V15, P747, DOI 10.1080/088395101317018582; Pickup JC, 2003, TXB DIABETES; Pinhas-Hamiel O, 2007, LANCET, V369, P1823, DOI 10.1016/S0140-6736(07)60821-6; RIMM EB, 1995, BRIT MED J, V310, P555; RISH I, 2002, ANAL DATA CHARACTERI; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Roy N., 2001, P 18 INT C MACH LEAR, P441; Sairenchi T, 2004, AM J EPIDEMIOL, V160, P158, DOI 10.1093/aje/kwh183; Schohn G., 2000, P 17 INT C MACH LEAR, P839; SIERRA B, 2003, KNOWLEDGE BASED INTE, P932; SMITH R, 2003, BR MED J, V327; Snow V, 2003, ANN INTERN MED, V138, P587; STANDL E, 1988, DIABETES METAB, V14, P505; Su CT, 2006, COMPUT MATH APPL, V51, P1075, DOI 10.1016/j.camwa.2005.08.034; TOPON KP, 2004, 041105A1 U TOK DEP F; VANBEMMEL J, 1997, HDB MED FEATURE PRES; Veropoulos K, 1999, P INT JOINT C ART IN, P55; Vijan S, 2003, ANN INTERN MED, V138, P593; Wannamethee SG, 2001, DIABETES CARE, V24, P1590, DOI 10.2337/diacare.24.9.1590; WEST KM, 1983, DIABETES CARE, V6, P361, DOI 10.2337/diacare.6.4.361; Wong TY, 2005, AM J OPHTHALMOL, V140, P1157, DOI 10.1016/j.ajo.2005.07.030	67	24	24	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	NOV	2007	41	3					251	262		10.1016/j.artmed.2007.07.002		12	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	236SK	WOS:000251323500006	
J	Blanco, R; Larranaga, P; Inza, I; Sierra, B				Blanco, R; Larranaga, P; Inza, I; Sierra, B			Gene selection for cancer classification using wrapper approaches	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						feature subset selection; DNA microarrays; supervised classification; naive-Bayes; estimation of distribution algorithms	FEATURE SUBSET-SELECTION; CLASS PREDICTION	Despite the fact that cancer classification has considerably improved, nowadays a general method that classifies known types of cancer has not yet been developed. In this work, we propose the use of supervised classification techniques, coupled with feature subset selection algorithms, to automatically perform this classification in gene expression datasets. Due to the large number of features of gene expression datasets, the search of a highly accurate combination of features is done by means of the new Estimation of Distribution Algorithms paradigm. In order to assess the accuracy level of the proposed approach, the naive-Bayes classification algorithm is employed in a wrapper form. Promising results are achieved, in addition to a considerable reduction in the number of genes. Stating the optimal selection of genes as a search task, an automatic and robust choice in the genes finally selected is performed, in contrast to previous works that research the same types of problems.	Univ Basque Country, Comp Sci & Artificial Intelligence Dept, San Sebastian 20080, Spain	Blanco, R (reprint author), Univ Basque Country, Comp Sci & Artificial Intelligence Dept, POB 649, San Sebastian 20080, Spain.	rosa@si.ehu.es; ccplamup@si.ehu.es; inza@si.ehu.es; ccpsiarb@si.ehu.es	Larranaga, Pedro/F-9293-2013				Aha D.W., 1994, P AAAI 94 WORKSH CAS, P106; ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; BEIBEL M, 2000, P 1 INT S MED DAT AN, P300; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Bo T., 2002, GENOME BIOL, P3; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Inza I, 2002, J INTELL FUZZY SYST, V12, P25; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; Keller A. D., 2000, UWCSE20000801; Kittler J., 1978, Pattern Recognition and Signal Processing; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583; Langley P., 1994, P 10 C UNC ART INT, P399; Larranaga P., 2002, ESTIMATION DISTRIBUT; Larranaga P., 2000, P 16 C UNC ART INT, P343; LI W, 2000, P 1 C CRIT ASS MICR; LIN SM, 2000, METHODS MICROARRAY D; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Muhlenbein H., 1996, LECT NOTES COMPUTER, V1141, P178; Muhlenbein H, 1997, EVOL COMPUT, V5, P303, DOI 10.1162/evco.1997.5.3.303; PEREZ O, 2002, ACUMA03ABR02 U MAL; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; STONE M, 1974, J R STAT SOC B, V36, P111; Xing EP, 2001, P 18 INT C MACH LEAR, P601	30	24	24	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	DEC	2004	18	8					1373	1390		10.1142/S0218001404003800		18	Computer Science, Artificial Intelligence	Computer Science	889KB	WOS:000226440800001	
J	Bressan, M; Vitria, J				Bressan, M; Vitria, J			On the selection and classification of independent features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature selection; divergence; independent component analysis; naive Bayes		This paper is focused on the problems of feature selection and classification when classes are modeled by statistically independent features. We show that, under the assumption of class-conditional independence, the class separability measure of divergence is greatly simplified, becoming a sum of unidimensional divergences, providing a feature selection criterion where no exhaustive search is required. Since the hypothesis of independence is infrequently met in practice, we also provide a framework making use of class-conditional Independent Component Analyzers where this assumption can be held on stronger grounds. Divergence and the Bayes decision scheme are adapted to this class-conditional representation. An algorithm that integrates the proposed representation, feature selection technique, and classifier is presented. Experiments on artificial, benchmark, and real-world data illustrate our technique and evaluate its performance.	Univ Autonoma Barcelona, Dept Informat, CVC, Bellaterra 08193, Spain	Bressan, M (reprint author), Univ Autonoma Barcelona, Dept Informat, CVC, Bellaterra 08193, Spain.		Vitria, Jordi/C-7072-2008				BELL A, 1999, NEURAL COMPUT, V11, P1739; Blake C. L., 1998, UCI REPOSITORY MACHI; BRESSAN M, 2001, P IEEE COMP SOC C CO, V1, P1004; Cardoso J.-F., 1996, P ISCAS 96, V2, P93; Choi JW, 2000, ENDOCR RES, V26, P1; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; *COR CORP, 1990, COR STOCK PHOT LIB; DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1; DECELL HP, 1972, P PURD U C MACH PROC, V1; Duda R.O., 2001, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532; KULLBACK S, 1968, INFORMATION THEORY S; Lee T.-W., 2000, IEEE T PATTERN ANAL, V22, P1; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; MARILL T, 1963, IEEE T INFORMATION T, V9, P1; MISKIN J, 2000, THESIS SELWYN COLL C; SIMPSON EH, 1951, J ROY STAT SOC B, V13, P238; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306; YANG Y, 2002, J INTELLIGENT INFORM	22	24	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1312	1317		10.1109/TPAMI.2003.1233904		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	723ZE	WOS:000185460800010	
J	Zaffalon, M; Wesnes, K; Petrini, O				Zaffalon, M; Wesnes, K; Petrini, O			Reliable diagnoses of dementia by the naive credal classifier inferred from incomplete cognitive data	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article; Proceedings Paper	8th Conference on Artificial Intelligence in Medicine in Europe (AIME 2001)	JUL 01-04, 2001	CASCAIS, PORTUGAL	IPE, Investimentos Participaco Empresariais, SA, Fdn Cienc Technol, Fdn Calouste Gulbenkian		credal classification; dementia; cognitive tests; naive credal classifier; imprecise probabilities; missing data; data mining	COMPUTERIZED ASSESSMENT SYSTEM; ALZHEIMERS-DISEASE; LEWY BODIES; DOUBLE-BLIND; RIVASTIGMINE; FLUCTUATION; TESTS; TRIAL	Dementia is a serious personal, medical and social problem. Recent research indicates early and accurate diagnoses as the key to effectively cope with it. No definitive cure is available but in some cases when the impairment is still mild the disease can be contained. This paper describes a diagnostic tool that jointly uses the naive credal classifier and the most widely used computerized system of cognitive tests in dementia research, the Cognitive Drug Research system. The naive credal classifier extends the discrete naive Bayes classifier to imprecise probabilities. The naive credal classifier models both prior ignorance and ignorance about the likelihood by sets of probability distributions. This is a new way to deal with small and incomplete datasets that departs significantly from most established classification methods. In the empirical study presented here, the naive credal classifier provides reliability and unmatched predictive performance. It delivers up to 95% correct predictions while being very robust with respect to the partial ignorance due to the largely incomplete data. The diagnostic tool also proves to be very effective in discriminating between Alzheimer's disease and dementia with Lewy bodies. (C) 2003 Elsevier Science B.V. All rights reserved.	IDSIA, CH-6928 Lugano, Switzerland; CDR Ltd, Reading RG30 1EA, Berks, England; Pharmaton SA, CH-6934 Bioggio, Switzerland	Zaffalon, M (reprint author), IDSIA, Galleria 2, CH-6928 Lugano, Switzerland.						ABELLAN J, 2001, P 2 INT S IMPR PROB, P1; Allain H, 1997, J AM GERIATR SOC, V45, P125; Bernardo J. M., 1996, BAYESIAN THEORY; Blake C. L., 1998, UCI REPOSITORY MACHI; Duda R., 1973, PATTERN CLASSIFICATI; Duda R.O., 2001, PATTERN CLASSIFICATI; FAGIUOLI E, 2000, P 8 INF PROC MAN UNC, P1320; FAKOUHI TD, 1995, J GERIATR PSYCH NEUR, V8, P226; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Ferris SH, 1997, ALZ DIS ASSOC DIS, V11, P34; HOROWITZ JL, 2001, P 2 INT S IMPR PROB, P213; Horowitz JL, 1998, J ECONOMETRICS, V84, P37, DOI 10.1016/S0304-4076(97)00077-8; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; KYBURG HE, 1983, BEHAV BRAIN SCI, V6, P231; LeBars PL, 1997, JAMA-J AM MED ASSOC, V278, P1327, DOI 10.1001/jama.278.16.1327; Levi I., 1980, ENTERPRISE KNOWLEDGE; Lewis D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; Little RJA, 1987, STAT ANAL MISSING DA; Luce R. D., 1957, GAMES DECISIONS; Mani S, 1999, LECT NOTES ARTIF INT, V1620, P326; MANSKI C, 2003, PARTIAL INDENTIFICAT; MANSKI C, 1993, HDB STAT, V11, P73, DOI 10.1016/S0169-7161(05)80038-0; McKeith I, 2000, LANCET, V356, P2031, DOI 10.1016/S0140-6736(00)03399-7; McKeith IG, 1997, ALZHEIMER'S DISEASE: BIOLOGY, DIAGNOSIS AND THERAPEUTICS, P167; MOHR E, 1995, CLIN NEUROPSYCHOPHAR, V18, P23; MOHR E, 1996, INT PSYCHOGERIATR, V3, P397; NICHOLL CG, 1995, INT J GERIATR PSYCH, V10, P199, DOI 10.1002/gps.930100306; NIVLET P, 2001, P 2 INT S IMPR PROB, P284; Ramoni M, 2001, MACH LEARN, V45, P147, DOI 10.1023/A:1010968702992; Ramoni M, 2001, ARTIF INTELL, V125, P209, DOI 10.1016/S0004-3702(00)00085-0; Ramoni M, 2001, METHOD INFORM MED, V40, P39; Siegfried K R, 1993, Acta Neurol Scand Suppl, V149, P26; SIMPSON PM, 1991, INT J GERIATR PSYCH, V6, P95, DOI 10.1002/gps.930060208; Templeton L, 1999, HUM PSYCHOPHARM CLIN, V14, P239, DOI 10.1002/(SICI)1099-1077(199906)14:4<239::AID-HUP94>3.0.CO;2-R; Walker MP, 1999, HUM PSYCHOPHARM CLIN, V14, P483, DOI 10.1002/(SICI)1099-1077(199910)14:7<483::AID-HUP133>3.0.CO;2-T; Walker MP, 2000, BRIT J PSYCHIAT, V177, P252, DOI 10.1192/bjp.177.3.252; Walker MP, 2000, NEUROLOGY, V54, P1616; Walker MP, 2000, DEMENT GERIATR COGN, V11, P327, DOI 10.1159/000017262; Walley P, 1996, J ROY STAT SOC B MET, V58, P3; Walley P., 1991, STAT REASONING IMPRE; WESNES K, 2000, RES PRACTICE ALZHEIM, V3, P59; Wesnes KA, 1999, DIAGNOSIS MANAGEMENT, P124; Wesnes KA, 2002, DEMENT GERIATR COGN, V13, P183, DOI 10.1159/000048651; Witten I.H., 1999, DATA MINING PRACTICA; Zaffalon M, 2002, J STAT PLAN INFER, V105, P5, DOI 10.1016/S0378-3758(01)00201-4; Zaffalon M, 2002, J STAT PLAN INFER, V105, P105, DOI 10.1016/S0378-3758(01)00206-3; Zaffalon M., 1999, IMPRECISE PROBABILIT, P405; ZAFFALON M, 2001, P 2 INT S IMPR PROB, P384	48	24	24	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	SEP-OCT	2003	29	1-2					61	79		10.1016/S0933-3657(03)0046-0		19	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	722RH	WOS:000185389700005	
J	Kumar, A; Zhang, D				Kumar, Ajay; Zhang, David			Hand-geometry recognition using entropy-based discretization	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						biometrics; feature discretization; feature representation; hand geometry; personal recognition		The hand-geometry-based recognition systems proposed in the literature have not yet exploited user-specific dependencies in the feature-level representation. We investigate the possibilities to improve the performance of the existing hand-geometry systems using the discretization of extracted features. This paper proposes employing discretization of hand-geometry features, using entropy-based heuristics, to achieve the performance improvement. The performance improvement due to the unsupervised and supervised discretization schemes is compared on a variety of classifiers: k-NN, naive Bayes, SVM, and FFN. Our experimental results on the database of 100 users achieve significant improvement in the recognition accuracy and confirm the usefulness of discretization in hand-geometry-based systems.	Indian Inst Technol, Biometr Res Lab, Dept Elect Engn, New Delhi, India; Hong Kong Polytech Univ, Biometr Res Ctr, Dept Comp, Kowloon, Hong Kong, Peoples R China	Kumar, A (reprint author), Indian Inst Technol, Biometr Res Lab, Dept Elect Engn, New Delhi, India.	ajaykr@ieee.org; csdzhang@comp.polyu.edu.hk					BULATOV Y, 2002, DIMACS WORKSH COMP G; Carletta J, 1996, COMPUT LINGUIST, V22, P249; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Cristianini N., 2001, INTRO SUPPORT VECTOR; DOUGHERTY D, 1995, P 12 INT C MACH LEAR, P194; Ernst R. H., 1971, US Patent, Patent No. 3576537; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1023/A:1022638503176; GUNTHER M, 2002, Patent No. DE10119329; JACOBY IH, 1972, Patent No. 3648240; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; Jain A. K., 1999, P 2 INT C AUD VID BA, P166; Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349; JANG BJ, 2002, Patent No. TW476917; Kononenko I., 1995, P 14 INT JOINT C ART, P1034; KUMAR A, 2006, INT J IMAGE GRAPHICS, V6, P1; Kumar A, 2006, PATTERN RECOGN LETT, V27, P1478, DOI 10.1016/j.patrec.2006.02.021; MILLER RP, 1971, Patent No. 3576538; MITRA S, 2003, IEEE T NEURAL NETWOR, V13, P1; Oden C, 2003, PATTERN RECOGN LETT, V24, P2145, DOI 10.1016/S0167-8655(03)00087-4; Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796; SIDLAUSKAS DP, 1988, Patent No. 4763203; Wayman J.L., 2005, BIOMETRIC SYSTEMS TE; Witten I.H., 1999, DATA MINING PRACTICA; Yoruk E, 2006, IMAGE VISION COMPUT, V24, P483, DOI 10.1016/j.imavis.2006.01.020	24	23	24	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1556-6013			IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.	JUN	2007	2	2					181	187		10.1109/TIFS.2007.896915		7	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	171MS	WOS:000246740700007	
J	Block, P; Paern, J; Hullermeier, E; Sanschagrin, P; Sotriffer, CA; Klebe, G				Block, Peter; Paern, Juri; Huellermeier, Eyke; Sanschagrin, Paul; Sotriffer, Christoph A.; Klebe, Gerhard			Physicochemical descriptors to discriminate protein-protein interactions in permanent and transient complexes selected by means of machine learning algorithms	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						classification; protein interfaces; feature selection; support vector machines; decision trees	RECOGNITION SITES; PREDICTION; INTERFACES; VALIDATION; NETWORKS	Analyzing protein-protein interactions at the atomic level is critical for our understanding of the principles governing the interactions involved in protein-protein recognition. For this purpose, descriptors explaining the nature of different protein-protein complexes are desirable. In this work, the authors introduced Epic Protein Interface Classification as a framework handling the preparation, processing, and analysis of protein-protein complexes for classification with machine learning algorithms. We applied four different machine learning algorithms: Support Vector Machines, C4.5 Decision Trees, K Nearest Neighbors, and Naive Bayes algorithm in combination with three feature selection methods, Filter (Relief F), Wrapper, and Genetic Algorithms, to extract discriminating features from the protein-protein complexes. To compare protein-protein complexes to each other, the authors represented the physicochemical characteristics of their interfaces in four different ways, using two different atomic contact vectors, DrugScore pair potential vectors and SFCscore descriptor vectors. We classified two different datasets: (A) 172 protein-protein complexes comprising 96 monomers, forming contacts enforced by the crystallographic packing environment (crystal contacts), and 76 biologically functional homodimer complexes; (B) 345 protein-protein complexes containing 147 permanent complexes and 198 transient complexes. We were able to classify up to 94.8% of the packing enforced/functional and up to 93.6% of the permanent/transient complexes correctly. Furthermore, we were able to extract relevant features from the different protein-protein complexes and introduce an approach for scoring the importance of the extracted features.	Univ Marburg, Dept Pharmaceut Chem, D-35032 Marburg, Germany	Klebe, G (reprint author), Univ Marburg, Dept Pharmaceut Chem, Marbacher Weg 6, D-35032 Marburg, Germany.	klebe@staff.uni-marburg.de	Sanschagrin, Paul/G-2179-2011				Bahadur RP, 2004, J MOL BIOL, V336, P943, DOI 10.1016/j.jmb.2003.12.073; BERMAN HM, 2000, PROTEIN DATA BANK NU, V28, P235; BLUM LP, 1997, ARTIF INTELL, V7, P245; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Bradford JR, 2005, BIOINFORMATICS, V21, P1487, DOI 10.1093/bioinformatics/bti242; Briem H, 2005, CHEMBIOCHEM, V6, P558, DOI 10.1002/cbic.200400109; Chakrabarti P, 2002, PROTEINS, V47, P334, DOI 10.1002/prot.10085; Chang C.C., 2001, LIBSVM LIB SUPPORT V; CLARK M, 1989, J COMPUT CHEM, V10, P982, DOI 10.1002/jcc.540100804; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; DILL KA, 1990, SCIENCE, V250, P297, DOI 10.1126/science.2218535; Fariselli P, 2002, EUR J BIOCHEM, V269, P1356, DOI 10.1046/j.1432-1033.2002.02767.x; Gohlke H, 2000, J MOL BIOL, V295, P337, DOI 10.1006/jmbi.1999.3371; Hubbard S, 1993, NACCESS COMPUTER PRO; JONES S, 1996, P NATL ACAD SCI USA, V93, P3; Larsen TA, 1998, STRUCT FOLD DES, V6, P421, DOI 10.1016/S0969-2126(98)00044-6; Liddington Robert C, 2004, Methods Mol Biol, V261, P3; Lo SL, 2005, PROTEOMICS, V5, P876, DOI 10.1002/pmic.200401118; Lo Conte L, 1999, J MOL BIOL, V285, P2177; Mintseris J, 2003, PROTEINS, V53, P629, DOI 10.1002/prot.10432; Mitchell T.M., 1997, MACHINE LEARNING; Nooren IMA, 2003, EMBO J, V22, P3486, DOI 10.1093/emboj/cdg359; Ofran Y, 2003, J MOL BIOL, V325, P377, DOI 10.1016/S0022-2836(02)01223-8; Ponstingl H, 2000, PROTEINS, V41, P47; Quinlan J., 1993, C4 5 PROGRAMS MACHIN, P302; Sanner MF, 1996, BIOPOLYMERS, V38, P305, DOI 10.1002/(SICI)1097-0282(199603)38:3<305::AID-BIP4>3.0.CO;2-Y; SCHOELKOPF B, 2002, LEARNING KERNELS, P644; Sheinerman FB, 2000, CURR OPIN STRUC BIOL, V10, P153, DOI 10.1016/S0959-440X(00)00065-8; Siepen JA, 2003, PROTEIN SCI, V12, P2348, DOI 10.1110/ps.03234503; SOTRIFFER CA, UNPUB SFC SCORE SCOR; Tsai CJ, 1997, PROTEIN SCI, V6, P1793; Tsai CJ, 1997, PROTEIN SCI, V6, P53; Valdar WSJ, 2001, PROTEINS, V42, P108; Vapnik V., 1998, STAT LEARNING THEORY; Wang RX, 2002, J COMPUT AID MOL DES, V16, P11, DOI 10.1023/A:1016357811882; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Yan Changhui, 2004, Bioinformatics, V20 Suppl 1, pi371, DOI 10.1093/bioinformatics/bth920; Zhang C, 1997, J MOL BIOL, V267, P707, DOI 10.1006/jmbi.1996.0859; Zhou HX, 2001, PROTEINS, V44, P336, DOI 10.1002/prot.1099	40	23	23	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585			PROTEINS	Proteins	NOV 15	2006	65	3					607	622		10.1002/prot.21104		16	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	094NV	WOS:000241247100008	
J	Bigdely-Shamlo, N; Vankov, A; Ramirez, RR; Makeig, S				Bigdely-Shamlo, Nima; Vankov, Andrey; Ramirez, Rey R.; Makeig, Scott			Brain Activity-Based Image Classification From Rapid Serial Visual Presentation	IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING			English	Article						Brain-computer interface (BCI); classification; electroencephalogram (EEG); independent component analysis (ICA); rapid serial visual presentation (RSVP); real-time systems; target detection	ALERTNESS; SPECTRUM	We report the design and performance of a brain-computer interface (BCI) system for real-time single-trial binary classification of viewed images based on participant-specific dynamic brain response signatures in high-density (128-channel) electroencephalographic (EEG) data acquired during a rapid serial visual presentation (RSVP) task. Image clips were selected from a broad area image and presented in rapid succession (12/s) in 4.1-s bursts. Participants indicated by subsequent button press whether or not each burst of images included a target airplane feature. Image clip creation and search path selection were designed to maximize user comfort and maintain user awareness of spatial context. Independent component analysis (ICA) was used to extract a set of independent source time-courses and their minimally-redundant low-dimensional informative features in the time and time-frequency amplitude domains from 128-channel EEG data recorded during clip burst presentations in a training session. The naive Bayes fusion of two Fisher discriminant classifiers, computed from the 100 most discriminative time and time-frequency features, respectively, was used to estimate the likelihood that each clip contained a target feature. This estimator was applied online in a subsequent test session. Across eight training/test session pairs from seven participants, median area under the receiver operator characteristic curve, by tenfold cross validation, was 0.97 for within-session and 0.87 for between-session estimates, and was nearly as high (0.83) for targets presented in bursts that participants mistakenly reported to include no target features.	[Bigdely-Shamlo, Nima; Vankov, Andrey; Ramirez, Rey R.; Makeig, Scott] Univ Calif San Diego, Swartz Ctr Computat Neurosci, La Jolla, CA 92037 USA	Bigdely-Shamlo, N (reprint author), Univ Calif San Diego, Swartz Ctr Computat Neurosci, La Jolla, CA 92037 USA.						BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Delorme A, 2003, IEEE T NEUR SYS REH, V11, P133, DOI 10.1109/TNSRE.2003.814428; EINHAUSERTREYER W, 2006, COMMUNICATION    JUL; Einhuser W., 2007, J VISION, V7, P1, DOI DOI 10.1167/7.10.6; Gerson AD, 2006, IEEE T NEUR SYS REH, V14, P174, DOI 10.1109/TNSRE.2006.875550; GUITTON D, 1984, J NEUROPHYSIOL, V52, P1030; Jung TP, 1997, IEEE T BIO-MED ENG, V44, P60; Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719; MAKEIG S, 1993, ELECTROEN CLIN NEURO, V86, P23, DOI 10.1016/0013-4694(93)90064-3; Osterberg G., 1935, ACTA OPHTHALMOL    S, V6, P1; Parra LC, 2008, IEEE SIGNAL PROCESSI, V25, P95; Sajda P., 2003, P 1 INT IEEE EMBS C; Yarbus A. L., 1967, EYE MOVEMENTS VISION	13	22	23	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1534-4320			IEEE T NEUR SYS REH	IEEE Trans. Neural Syst. Rehabil. Eng.	OCT	2008	16	5					432	441		10.1109/TNSRE.2008.2003381		10	Engineering, Biomedical; Rehabilitation	Engineering; Rehabilitation	373FN	WOS:000260956500002	
J	Corani, G; Zaffalon, M				Corani, Giorgio; Zaffalon, Marco			Learning reliable classifiers from small or incomplete data sets: The naive credal classifier 2	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						naive Bayes; naive credal classifier; imprecise probabilities; missing values; conservative inference rule; missing at random	IGNORABILITY; INFERENCE	In this paper, the naive credal classifier, which is a set-valued counterpart of naive Bayes, is extended to a general and flexible treatment of incomplete data, yielding a new classifier called naive credal classifier 2 (NCC2). The new classifier delivers classifications that are reliable even in the presence of small sample sizes and missing values. Extensive empirical evaluations show that, by issuing set-valued classifications, NCC2 is able to isolate and properly deal with instances that are hard to classify (on which naive Bayes accuracy drops considerably), and to perform as well as naive Bayes on the other instances. The experiments point to a general problem: they show that with missing values, empirical evaluations may not reliably estimate the accuracy of a traditional classifier, such as naive Bayes. This phenomenon adds even more value to the robust approach to classification implemented by NCC2.	[Corani, Giorgio; Zaffalon, Marco] IDSIA, Ist Dalle Molle Studi Sull Intelligenza Artificia, CH-6928 Lugano, Switzerland	Corani, G (reprint author), IDSIA, Ist Dalle Molle Studi Sull Intelligenza Artificia, CH-6928 Lugano, Switzerland.	giorgio@idsia.ch; zaffalon@idsia.ch					Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; HEITJAN DF, 1991, ANN STAT, V19, P2244, DOI 10.1214/aos/1176348396; Jaeger M, 2005, J ARTIF INTELL RES, V24, P889; KOTZ S, 2000, SERIES PROBABILITY S; Little RJA, 1987, STAT ANAL MISSING DA; Manski CF, 2003, PARTIAL IDENTIFICATI; Press W. H., 1993, NUMERICAL RECIPES C; Ramoni M, 2001, ARTIF INTELL, V125, P209, DOI 10.1016/S0004-3702(00)00085-0; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; Walley P, 1996, J ROY STAT SOC B MET, V58, P3; Walley P., 1991, STAT REASONING IMPRE; Witten IH, 2005, DATA MINING PRACTICA; Zaffalon M, 2002, J STAT PLAN INFER, V105, P5, DOI 10.1016/S0378-3758(01)00201-4; Zaffalon M, 2003, ARTIF INTELL MED, V29, P61, DOI [10.1016/S0933-3657(03)00046-0, 10.1016/S0933-3657(03)0046-0]; Zaffalon M., 2001, ISIPTA 01, P384; Zaffalon M, 2005, ISIPTA 05-PROCEEDINGS OF THE FOURTH INTERNATIONAL SYMPOSIUM ON IMPRECISE PROBABILITIES AND THEIR APPLICATIONS, P406; Zaffalon M, 2005, ENVIRON MODELL SOFTW, V20, P1003, DOI 10.1016/j.envsoft.2004.10.006	17	22	22	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	APR	2008	9						581	621				41	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312AS	WOS:000256642100002	
J	Pakhomov, SV; Buntrock, J; Chute, CG				Pakhomov, SV; Buntrock, J; Chute, CG			Prospective recruitment of patients with congestive heart failure using an ad-hoc binary classifier	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						automatic classification; naive Bayes; perceptron; machine learning; congestive heart failure; natural language processing; medical informatics		This paper addresses a very specific problem of identifying patients diagnosed with a specific condition for potential recruitment in a clinical trial or an epidemiological study. We present a simple machine learning method for identifying patients diagnosed with congestive heart failure and other related conditions by automatically classifying clinical notes dictated at Mayo Clinic. This method relies on an automatic classifier trained on comparable amounts of positive and negative samples of clinical notes previously categorized by human experts. The documents are represented as feature vectors, where features are a mix of demographic information as well as single words and concept mappings to MeSH and HICDA classification systems. We compare two simple and efficient classification algorithms (Naive Bayes and Perceptron) and a baseline term spotting method with respect to their accuracy and recall on positive samples. Depending on the test set, we find that Naive Bayes yields better recall on positive samples (95 vs. 86%) but worse accuracy than Perceptron (57 vs. 65%). Both algorithms perform better than the baseline with recall on positive samples of 71% and accuracy of 54%. (c) 2004 Elsevier Inc. All rights reserved.	Mayo Clin & Mayo Fdn, Coll Med, Div Biomed Informat, Rochester, MN 55905 USA	Pakhomov, SV (reprint author), Mayo Clin & Mayo Fdn, Coll Med, Div Biomed Informat, 200 1st St SW, Rochester, MN 55905 USA.	pakhomov@mayo.edu; buntrock@mayo.edu; chute@mayo.edu					AFRIN B, 2003, P AM MED INF ASS FAL, P16; Anderson J, 1995, INTRO NEURAL NETWORK; ARONOW D, 1995, P MED S, V199, P8; Aronow DB, 1999, J AM MED INFORM ASSN, V6, P393; Aronsky D, 2000, Proc AMIA Symp, P12; CARLSON AJ, SNOW USERS GUIDE COG; Chapman W W, 2001, Proc AMIA Symp, P105; Commission on Professional and Hospital Activities, 1973, HOSP AD ICDA, V1; Damerau F. J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Horn Laurence, 1989, NATURAL HIST NEGATIO; Jain N L, 1997, Proc AMIA Annu Fall Symp, P829; Johnson DE, 2002, IBM SYST J, V41, P428; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; Manning C.D., 1999, FDN STAT NATURAL LAN; Nigam K., 1999, P IJCAI 99 WORKSH MA, P61; *NLM, 2000, FACT SHEET MED SUBJ; WILCOX A, 2000, THESIS COLUMBIA U NY; Yang Y., 1992, P 14 INT C COMP LING, P447; YANG YM, 1994, P 17 ANN INT ACM SIG, P11	19	22	22	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	APR	2005	38	2					145	153		10.1016/j.jbi.2004.11.016		9	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	915OO	WOS:000228313800005	
J	Flach, PA; Lachiche, N				Flach, PA; Lachiche, N			Naive Bayesian classification of structured data	MACHINE LEARNING			English	Article						bayesian classifier; structured data; inductive logic programming; knowledge representation; first-order features		In this paper we present 1BC and 1BC2, two systems that perform naive Bayesian classification of structured individuals. The approach of 1BC is to project the individuals along first-order features. These features are built from the individual using structural predicates referring to related objects ( e. g., atoms within molecules), and properties applying to the individual or one or several of its related objects ( e. g., a bond between two atoms). We describe an individual in terms of elementary features consisting of zero or more structural predicates and one property; these features are treated as conditionally independent in the spirit of the naive Bayes assumption. 1BC2 represents an alternative first-order upgrade to the naive Bayesian classifier by considering probability distributions over structured objects ( e. g., a molecule as a set of atoms), and estimating those distributions from the probabilities of its elements ( which are assumed to be independent). We present a unifying view on both systems in which 1BC works in language space, and 1BC2 works in individual space. We also present a new, efficient recursive algorithm improving upon the original propositionalisation approach of 1BC. Both systems have been implemented in the context of the first-order descriptive learner Tertius, and we investigate the differences between the two systems both in computational terms and on artificially generated data. Finally, we describe a range of experiments on ILP benchmark data sets demonstrating the viability of our approach.	Univ Bristol, Dept Comp Sci, Bristol BS8 1TH, Avon, England; Univ Strasbourg 1, LSIIT, Strasbourg, France	Flach, PA (reprint author), Univ Bristol, Dept Comp Sci, Bristol BS8 1TH, Avon, England.	peter.flach@bristol.ac.uk; lachiche@lsiit.u-strasbg.fr					BADEA L, 1999, P 9 INT WORKSH IND L, P21; BOSTROM H, 1999, P 9 INT WORKSH IND L, P33; CECI M, 2003, P 7 EUR C PRINC PRAC, P95; CUSSENS J, 2001, MACH LEARN, V43, P245; Date C.J., 1995, INTRO DATABASE SYSTE; DEHASPE L, 1997, P 7 INT WORKSH IND L, P109; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Dolsak B., 1992, INDUCTIVE LOGIC PROG; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dzeroski S., 2001, RELATIONAL DATA MINI; Dzeroski S, 1998, APPL ARTIF INTELL, V12, P363, DOI 10.1080/088395198117686; FAWCETT T, 2003, HPL20034 HP LAB; FLACH P, IN PRESS LINKOPING E; FLACH P, 1999, P 9 INT WORKSH IND L, P92; FLACH P, 1998, P 8 INT C IND LOG PR, P185; Flach P. A., 1999, Symbolic and Quantitative Approaches to Reasoning and Uncertainty. European Conference, ECSQARU'99. Proceedings (Lecture Notes in Artificial Intelligence Vol.1638); Flach PA, 2001, MACH LEARN, V42, P61, DOI 10.1023/A:1007656703224; Gartner T, 2004, MACH LEARN, V57, P205, DOI 10.1023/B:MACH.0000039777.23772.30; Getoor L., 2001, RELATIONAL DATA MINI; GYFTODIMOS E, 2003, P WORK IN PROGR TRAC, P12; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; JOHN GH, 1995, P 11 C UNC ART INT, P338; KERSTING K, 2000, CEUR WORKSHOP P SERI, V35, P138; KERSTING K, 2001, P 11 INT C IND LOG P, P118; Knobbe A., 2001, P 5 EUR C PRINC DAT, P277; Kramer S., 2001, RELATIONAL DATA MINI; Krogel M.-A., 2001, P 11 INT C IND LOG P, P142; Lachiche N., 2003, P 20 INT C MACH LEAR, P416; LACHICHE N, 2002, P 12 INT C IND LOG P, P133; LAVRAC N, 2002, P 12 INT C IND LOG P, P149; Lavrac N., 2001, ACM T COMPUT LOG, V2, P458, DOI 10.1145/383779.383781; Lloyd J.W., 2003, LOGIC LEARNING LEARN; LLOYD JW, 1999, J FUNCTIONAL LOGIC P; Lu Q., 2003, P 20 INT C MACH LEAR, P496; Muggleton S., 1996, ADV INDUCTIVE LOGIC; Muggleton S., 1994, Journal of Logic Programming, V19-20, DOI 10.1016/0743-1066(94)90035-3; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; MUGGLETON S, 1998, P 1 INT C DISC SCI, P326; Muggleton S.H., 1992, INDUCTIVE LOGIC PROG; Pompe Uros, 1995, P 5 INT WORKSH IND L, P417; ROUVEIROL C, 1994, MACH LEARN, V14, P219, DOI 10.1023/A:1022678217288; Sato T, 2001, J ARTIF INTELL RES, V15, P391; Sato T., 1997, P 15 INT JOINT C ART, P1330; SLATTERY S., 1998, P 8 INT C IND LOG PR, P38; Srinivasan A., 1994, P 4 INT WORKSH IND L, P217; Taskar B., 2001, P 17 INT JOINT C ART, P870	46	22	25	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	DEC	2004	57	3					233	269		10.1023/B:MACH.0000039778.69032.ab		37	Computer Science, Artificial Intelligence	Computer Science	850EA	WOS:000223592800003	
J	Inza, I; Sierra, B; Blanco, R				Inza, I; Sierra, B; Blanco, R			Gene selection by sequential search wrapper approaches in microarray cancer class prediction	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS			English	Article							FEATURE SUBSET-SELECTION; LEARNING ALGORITHMS; CLASSIFICATION	In the last years, there has been a large growth in gene expression profiling technologies, which are expected to provide insight into cancer related cellular processes. Machine Learning algorithms, which are extensively applied in many areas of the real world, are not still popular in the Bioinformatics community. We report on the successful application of four well known supervised Machine Learning methods (IB1, Naive-Bayes. C4.5 and CN2) to cancer class prediction problems in three DNA microarray datasets of huge dimensionality (Colon, Leukemia and NCI-60). The essential gene selection process in microarray domains is performed by a sequential search engine, evaluating the goodness of each gene subset by a wrapper approach which executes, by a leave-one-out process, the supervised algorithm to obtain its accuracy estimation. By the use of the gene selection procedure, the accuracy of supervised algorithms is significantly improved and the number of genes of the classification models is notably reduced for all datasets.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, E-20080 San Sebastian, Spain	Inza, I (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, POB 649, E-20080 San Sebastian, Spain.		Larranaga, Pedro/F-9293-2013				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ARIS V, 2000, P 1 C CRIT ASS MICR; Beibel M, 2000, LECT NOTES COMPUT SC, V1933, P300; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; BLANCO R, 2001, WORKSH BAYES MOD MED, P29; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; Cestnik B, 1990, P EUR C ART INT, P147; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DING C, 2000, P 1 C CRIT ASS MICR; Doak J., 1992, CSE9218 U CAL DAV; DUBITZKY W, 2000, P 1 C CRIT ASS MICR; Duda R., 1973, PATTERN CLASSIFICATI; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hwang K.B., 2000, P 1 C CRIT ASS MICR; Inza I, 2001, ARTIF INTELL MED, V23, P187, DOI 10.1016/S0933-3657(01)00085-9; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; Kittler J., 1978, Pattern Recognition and Signal Processing; KOHAVI R, 1995, P INT JOINT C ART IN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, THESIS STANFORD U; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; Langley P., 1994, P 10 C UNC ART INT, P399; Larranaga P., 2001, ESTIMATION DISTRIBUT; LI L, 2000, P 1 C CRIT ASS MICR, pA6061; LI W, 2000, P 1 C CRIT ASS MICR; Liu H., 1998, FEATURE SELECTION KN; MATEOS A, 2001, P 2 C CRIT ASS MICR; MICHIE D, 1990, J STAT PLAN INFER, V25, P381, DOI 10.1016/0378-3758(90)90083-7; Mitchell T.M., 1997, MACHINE LEARNING; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; Xing EP, 2001, P 18 INT C MACH LEAR, P601	35	22	22	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1064-1246			J INTELL FUZZY SYST	J. Intell. Fuzzy Syst.		2002	12	1					25	33				9	Computer Science, Artificial Intelligence	Computer Science	629UU	WOS:000180070200004	
J	Cheng, FX; Yu, Y; Shen, J; Yang, L; Li, WH; Liu, GX; Lee, PW; Tang, Y				Cheng, Feixiong; Yu, Yue; Shen, Jie; Yang, Lei; Li, Weihua; Liu, Guixia; Lee, Philip W.; Tang, Yun			Classification of Cytochrome P450 Inhibitors and Noninhibitors Using Combined Classifiers	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							DRUG DISCOVERY; IN-VITRO; PREDICTION; QSAR; MODELS; 2D; FINGERPRINTS; DESCRIPTORS; SOLUBILITY; METABOLISM	Adverse side effects of drug drug interactions induced by human cytochrome P450 (CYP) inhibition is an important consideration, especially, during the research phase of drug discovery. It is highly desirable to develop computational models that can predict the inhibitive effect of a compound against a specific CYP isoform. In this study, inhibitor predicting models were developed for five major CYP isoforms, namely 1A2, 2C9, 2C19, 2D6, and 3A4, using a combined classifier algorithm on a large data set containing more than 24,700 unique compounds, extracted from PubChem. The combined classifiers algorithm is an ensemble of different independent machine learning classifiers including support vector machine, C4.5 decision tree, k-nearest neighbor, and naive Bayes, fused by a back-propagation artificial neural network (BP-ANN). All developed models were validated by 5-fold cross-validation and a diverse validation set composed of about 9000 diverse unique compounds. The range of the area under the receiver operating characteristic curve (AUC) for the validation sets was 0.764 to 0.815 for CYP1A2, 0.837 to 0.861 for CYP2C9, 0.793 to 0.842 for CYP2C19, 0.839 to 0.886 for CYP2D6, and 0.754 to 0.790 for CYP3A4, respectively, using the new developed combined classifiers. The overall performance of the combined classifiers fused by BP-ANN was superior to that of three classic fusion techniques (Mean, Maximum, and Multiply). The chemical spaces of data sets were explored by multidimensional scaling plots, and the use of applicability domain improved the prediction accuracies of models. In addition, some representative substructure fragments differentiating CYP inhibitors and noninhibitors were characterized by the substructure fragment analysis. These classification models are applicable for virtual screening of the five major CYP isoforms inhibitors or can be used as simple filters of potential chemicals in drug discovery.	[Cheng, Feixiong; Yu, Yue; Shen, Jie; Li, Weihua; Liu, Guixia; Lee, Philip W.; Tang, Yun] E China Univ Sci & Technol, Sch Pharm, Dept Pharmaceut Sci, Shanghai 200237, Peoples R China; [Lee, Philip W.] Kyoto Univ, Grad Sch Agr, Sakyo Ku, Kyoto 6068502, Japan; [Yang, Lei] E China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China	Li, WH (reprint author), E China Univ Sci & Technol, Sch Pharm, Dept Pharmaceut Sci, 130 Meilong Rd, Shanghai 200237, Peoples R China.	whli@ecust.edu.cn; ytang234@ecust.edu.cn	Shen, Jie/H-5258-2011; Cheng, Feixiong/D-9922-2013; LI, Weihua/G-7190-2011	Cheng, Feixiong/0000-0002-1251-3116; 	National Natural Science Foundation of China [21072059]; Shanghai Natural Science Foundation [10ZR1407000]; Fundamental Research Funds for the Central Universities [WY1014010]; Program for New Century Excellent Talents in University [NCET-08-0774]; 111 Project [B07023]; National S&T Major Project of China [2009ZX09501-001]	We thank Dr. Douglas Auld (Genomic Assay Technologies, NIH Chemical Genomics Center, USA) in sharing their data sets with us. This work was supported by the National Natural Science Foundation of China (Grant No. 21072059), Shanghai Natural Science Foundation (Grant No. 10ZR1407000), the Fundamental Research Funds for the Central Universities (Grant No. WY1014010), the Program for New Century Excellent Talents in University (Grant No. NCET-08-0774), the 111 Project (Grant No. B07023), and the National S&T Major Project of China (Grant No. 2009ZX09501-001).	Accelrys Software Inc, 2004, DISC STUD MOD ENV RE; Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bjornsson TD, 2003, DRUG METAB DISPOS, V31, P815, DOI 10.1124/dmd.31.7.815; Boethling RS, 2010, SAR QSAR ENVIRON RES, V21, P415, DOI 10.1080/1062936X.2010.501816; Chang C.-C., LIBSVM LIB SUPPORT V; Cheng FX, 2011, CHEMOSPHERE, V82, P1636, DOI 10.1016/j.chemosphere.2010.11.043; Corinna Cortes, 1995, MACH LEARN, V20, P273; Culp M, 2010, J CHEM INF MODEL, V50, P309, DOI [10.1021/ci9003392, 10.1021/69003392]; Dagliyan O, 2009, J CHEM INF MODEL, V49, P2403, DOI [10.1021/ci900247t, 10.1021/ci00247t]; Didziapetris R, 2010, J COMPUT AID MOL DES, V24, P891, DOI 10.1007/s10822-010-9381-1; du Souich P, 2001, Can J Clin Pharmacol, V8, P153; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Dutta D, 2007, J CHEM INF MODEL, V47, P989, DOI 10.1021/ci600563w; Eitrich T, 2007, J CHEM INF MODEL, V47, P92, DOI 10.1021/ci60026l9; Friedman MA, 1999, JAMA-J AM MED ASSOC, V281, P1728, DOI 10.1001/jama.281.18.1728; Gupta RR, 2010, DRUG METAB DISPOS, V38, P2083, DOI 10.1124/dmd.110.034918; Hammann F, 2009, MOL PHARMACEUT, V6, P1920, DOI 10.1021/mp900217x; HANLEY JA, 1982, RADIOLOGY, V143, P29; Huang Y.S., 1994, P 4 IWFHR, P235; Hutzler Matthew, 2005, Curr Opin Drug Discov Devel, V8, P51; Jensen BF, 2007, J MED CHEM, V50, P501, DOI 10.1021/jm060333; John M.B., 1998, J CHEM INF COMP SCI, V38, P983; Kontijevskis A, 2008, J CHEM INF MODEL, V48, P1840, DOI 10.1021/ci8000953; Kramer C, 2010, J CHEM INF MODEL, V50, P404, DOI 10.1021/ci900377e; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; Lasser KE, 2002, JAMA-J AM MED ASSOC, V287, P2215, DOI 10.1001/jama.287.17.2215; Lazarou J, 1998, JAMA-J AM MED ASSOC, V279, P1200, DOI 10.1001/jama.279.15.1200; Lee Dar-Shyang, 1995, THESIS SUNY BUFFALO; Lewis D.F.V., 2001, GUIDE CYTOCHROME P45; Lewis DFV, 1998, CHEM-BIOL INTERACT, V115, P175, DOI 10.1016/S0009-2797(98)00068-4; Lin JH, 1997, PHARMACOL REV, V49, P403; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Merkwirth C, 2004, J CHEM INF COMP SCI, V44, P1971, DOI 10.1021/ci049850e; Michielan L, 2009, J CHEM INF MODEL, V49, P2588, DOI 10.1021/ci900299a; Mishra Nitish K., 2010, BMC Pharmacology, V10, P8, DOI 10.1186/1471-2210-10-8; *OP BAB, OP BAB VERSION2 2 3; Palmer DS, 2007, J CHEM INF MODEL, V47, P150, DOI 10.1021/ci060164k; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; ROBERT HN, 1990, NEUROCOMPUTING; Shen J, 2010, J CHEM INF MODEL, V50, P1034, DOI 10.1021/ci100104j; Shukla SJ, 2010, DRUG DISCOV TODAY, V15, P997, DOI 10.1016/j.drudis.2010.07.007; Simmons K, 2008, J CHEM INF MODEL, V48, P2196, DOI 10.1021/ci800164u; Simon Haykin McMaster, 2009, NEURAL NETWORKS LEAR; Teramoto R, 2007, J CHEM INF MODEL, V47, P526, DOI 10.1021/ci6004993; TING FW, 2004, J MACHINE LEARN RES, V5, P975; Tulyakov S, 2008, STUD COMPUT INTELL, V90, P361; Vasanthanathan P, 2009, DRUG METAB DISPOS, V37, P658, DOI 10.1124/dmd.108.023507; Veith H, 2009, NAT BIOTECHNOL, V27, P1050, DOI 10.1038/nbt.1581; WANG Y, 2009, NUCLEIC ACIDS RES, P1; Watson P, 2008, J CHEM INF MODEL, V48, P166, DOI 10.1021/ci7003253; Weaver S, 2008, J MOL GRAPH MODEL, V26, P1315, DOI 10.1016/j.jmgm.2008.01.002; Wienkers LC, 2005, NAT REV DRUG DISCOV, V4, P825, DOI 10.1038/nrd1851; Willett P, 2006, DRUG DISCOV TODAY, V11, P1046, DOI 10.1016/j.drudis.2006.10.005; Williams JA, 2004, DRUG METAB DISPOS, V32, P1201, DOI 10.1124/dmd.104.000794; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Zhang L, 2009, MOL PHARMACEUT, V6, P1766, DOI 10.1021/mp900132e; Zhang Q, 2006, J MED CHEM, V49, P1536, DOI 10.1021/jm050468i; Zhu H, 2008, J CHEM INF MODEL, V48, P766, DOI 10.1021/ci700443v	59	21	21	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAY	2011	51	5					996	1011		10.1021/ci200028n		16	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	765ZG	WOS:000290747300003	
J	Rodriguez, JD; Perez, A; Lozano, JA				Diego Rodriguez, Juan; Perez, Aritz; Antonio Lozano, Jose			Sensitivity Analysis of k-Fold Cross Validation in Prediction Error Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						k-fold cross validation; prediction error; error estimation; bias and variance; decomposition of the variance; sources of sensitivity; supervised classification	VARIANCE; BIAS	In the machine learning field, the performance of a classifier is usually measured in terms of prediction error. In most real-world problems, the error cannot be exactly calculated and it must be estimated. Therefore, it is important to choose an appropriate estimator of the error. This paper analyzes the statistical properties, bias and variance, of the k-fold cross-validation classification error estimator (k-cv). Our main contribution is a novel theoretical decomposition of the variance of the k-cv considering its sources of variance: sensitivity to changes in the training set and sensitivity to changes in the folds. The paper also compares the bias and variance of the estimator for different values of k. The experimental study has been performed in artificial domains because they allow the exact computation of the implied quantities and we can rigorously specify the conditions of experimentation. The experimentation has been performed for two classifiers (naive Bayes and nearest neighbor), different numbers of folds, sample sizes, and training sets coming from assorted probability distributions. We conclude by including some practical recommendation on the use of k-fold cross validation.	[Diego Rodriguez, Juan; Perez, Aritz; Antonio Lozano, Jose] Univ Basque Country UPV EHU, Fac Comp Sci, Intelligent Syst Grp, E-20018 Donostia San Sebastian, Gipuzkoa, Spain	Rodriguez, JD (reprint author), Univ Basque Country UPV EHU, Fac Comp Sci, Intelligent Syst Grp, Paseo Manuel de Lardizabal 1, E-20018 Donostia San Sebastian, Gipuzkoa, Spain.	juandiego.rodriguez@ehu.es; aritz.perez@ehu.es; ja.lozano@ehu.es	Lozano, Jose/F-5120-2010		Saiotek and Research Groups, Basque Government [2007-2012 (IT-242-07)]; Spanish Ministry of Science and Innovation [TIN2008-06815-C02-01, Consolider Ingenio 2010-CSD2007-00018]; Carlos III Health Institute	This work has been partially supported by the Saiotek and Research Groups 2007-2012 (IT-242-07) programs (Basque Government), TIN2008-06815-C02-01 and Consolider Ingenio 2010-CSD2007-00018 projects (Spanish Ministry of Science and Innovation), and COMBIOMED network in computational biomedicine (Carlos III Health Institute).	Bengio Y, 2004, J MACH LEARN RES, V5, P1089; Bengio Y, 2005, GERAD 25TH ANNIV SER, V1, P75; Bishop CM, 2006, PATTERN RECOGNITION; BRAGA UM, 2005, P SOC PHOTO-OPT INS, P304; Braga-Neto U, 2004, BIOINFORMATICS, V20, P253, DOI 10.1093/bioinformatics/btg399; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; Demsar J, 2006, J MACH LEARN RES, V7, P1; DEVROYE LP, 1979, IEEE T INFORM THEORY, V25, P208, DOI 10.1109/TIT.1979.1056018; Devroye L., 1985, NONPARAMETRIC DENSIT; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Duda R. O., 2000, PATTERN CLASSIFICATI; Efron B., 1993, MONOGRAPHS STAT APPL, V57; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Ide J. S., 2004, P EUR C ART INT; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Kohav R., 1996, P 13 INT C MACH LEAR, P275; Kohavi R., 1995, THESIS STANFORD U; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Langley P., 1992, P 10 NAT C ART INT, P223; Lucas PJF, 2004, STUD FUZZ SOFT COMP, V146, P217; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Minsky M., 1961, T I RADIO ENG, V49, P8; Mitchell T.M., 1997, MACHINE LEARNING; Pearl J., 1988, PROBABILISTIC REASON; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; STONE M, 1974, J R STAT SOC B, V36, P111; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Witten I.H., 2000, DATA MINING PRACTICA	28	21	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					569	575		10.1109/TPAMI.2009.187		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	543WG	WOS:000273609600013	
S	Yuan, JS; Liu, ZC; Wu, Y			IEEE	Yuan, Junsong; Liu, Zicheng; Wu, Ying			Discriminative Subvolume Search for Efficient Action Detection	CVPR: 2009 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-4	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE-Computer-Society Conference on Computer Vision and Pattern Recognition Workshops	JUN 20-25, 2009	Miami Beach, FL	IEEE Comp Soc				Actions are spatio-temporal patterns which can be characterized by collections of spatio-temporal invariant features. Detection of actions is to find the re-occurrences (e.g. through pattern matching) of such spatio-temporal patterns. This paper addresses two critical issues in pattern matching-based action detection: (1) efficiency of pattern search in 3D videos and (2) tolerance of intra-pattern variations of actions. Our contributions are two-fold First, we propose a discriminative pattern matching called naive-Bayes based mutual information maximization (NBMIM) for multi-class action categorization. It improves the state-of-the-art results on standard KTH dataset. Second, a novel search algorithm is proposed to locate the optimal subvolume in the 3D video space for efficient action detection. Our method is purely data-driven and does not rely on object detection, tracking or background subtraction. It can well handle the intra-pattern variations of actions such as scale and speed variations, and is insensitive to dynamic and clutter backgrounds and even partial occlusions. The experiments on versatile datasets including KM and CMU action datasets demonstrate the effectiveness and efficiency of our method.	[Yuan, Junsong; Wu, Ying] Northwestern Univ, Dept EECS, Evanston, IL 60208 USA	Yuan, JS (reprint author), Northwestern Univ, Dept EECS, Evanston, IL 60208 USA.	j-yuan@u.northwestern.edu; zliu@microsoft.com; yingwu@eecs.northwestern.edu	Wu, Ying/B-7283-2009; Yuan, Junsong/A-5171-2011				ALI S, 2007, P IEEE INT C COMP VI, P2; Bentley J., 1984, Communications of the ACM, V27, DOI 10.1145/358234.381162; BLANK M, 2005, P IEEE INT C COMP VI, P2; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Datar M, 2004, P 20 ANN S COMP GEOM, P253, DOI 10.1145/997817.997857; EFROS AA, 2003, P IEEE INT C COMP VI, P2; Galata A, 2001, COMPUT VIS IMAGE UND, V81, P398, DOI 10.1006/cviu.2000.0894; Ke Y., 2007, P IEEE INT C COMP VI; Lampert C.H., 2008, P IEEE C COMP VIS PA; Laptev I., 2005, INT J COMPUTER VISIO; Laptev I., 2008, P IEEE C COMP VIS PA; Liu J., 2009, P IEEE INT C COMP VI; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; NATARAJAN P, 2008, P IEEE INT C COMP VI; Nguyen N.T., 2005, P IEEE INT C COMP VI; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Rodriguez M. D., 2008, P IEEE INT C COMP VI; Scovanner P., 2007, P ACM MULT; SHECHTMAN BE, 2008, P IEEE INT C COMP VI, V2, P3; SHECHTMAN E, 2005, P IEEE INT C COMP VI; VITALADEVUNI SN, 2008, P IEEE C COMP VIS PA; Yilmaz A., 2005, P IEEE INT C COMP VI	22	21	21	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-3992-8	PROC CVPR IEEE			2009							2434	2441				8	Computer Science, Artificial Intelligence	Computer Science	BPK14	WOS:000279038001121	
J	Ku, SP; Gretton, A; Macke, J; Logothetis, NK				Ku, Shih-pi; Gretton, Arthur; Macke, Jakob; Logothetis, Nikos K.			Comparison of pattern recognition methods in classifying high-resolution BOLD signals obtained at high magnetic field in monkeys	MAGNETIC RESONANCE IMAGING			English	Article; Proceedings Paper	International School on Magnetic Resonance and Brain Function	MAY 06-13, 2007	Erice, ITALY			multivariate analysis; brain imaging; functional MRI; monkey; SVM; naive Bayes; linear discriminant analysis; correlation analysis; feature selection; high field; high resolution	VISUAL-CORTEX; BRAIN; OBJECTS; MACAQUE; FMRI; REPRESENTATIONS; STIMULI; HUMANS; FACES; AREA	Pattern recognition methods have shown that functional magnetic resonance imaging (fMRI) data can reveal significant information about brain activity. For example, in the debate of how object categories are represented in the brain, multivariate analysis has been used to provide evidence of a distributed encoding scheme [Science 293:5539 (2001) 2425-2430] Many follow-up studies have employed different methods to analyze human fMRI data with varying degrees of success [Nature reviews 7:7 (2006) 523-534]. In this study, we compare four popular patient recognition methods: correlation analysis, support-vector machines (SVM), linear discriminant analysis (LDA) and Gaussian naive Bayes (GNB), using data collected at high field (7 Tesla) with higher resolution than usual fMRI studies. We investigate prediction performance on single trials and for averages across varying numbers of stimulus presentations. The performance of the various algorithms depends on the nature of the brain activity being categorized: for several tasks, many of the methods work well, whereas for others, no method performs above chance level. An important factor in overall classification performance is careful preprocessing of the data, including dimensionality reduction, voxel selection and Outlier elimination. (C) 2008 Elsevier Inc. All rights reserved.	[Ku, Shih-pi; Gretton, Arthur; Macke, Jakob; Logothetis, Nikos K.] Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany	Ku, SP (reprint author), Max Planck Inst Biol Cybernet, Spemannstr 38, D-72076 Tubingen, Germany.	shihpi@tuebingen.mpg.de					Aguirre GK, 1998, NEURON, V21, P373, DOI 10.1016/S0896-6273(00)80546-2; Carlson TA, 2003, J COGNITIVE NEUROSCI, V15, P704, DOI 10.1162/089892903322307429; Cox DD, 2003, NEUROIMAGE, V19, P261, DOI 10.1016/S1053-8119(03)00049-1; DESIMONE R, 1985, VISION RES, V25, P441, DOI 10.1016/0042-6989(85)90069-0; DESIMONE R, 1986, J COMP NEUROL, V248, P164, DOI 10.1002/cne.902480203; Epstein R, 1998, NATURE, V392, P598, DOI 10.1038/33402; FRAHM J, 1986, J COMPUT ASSIST TOMO, V10, P363; FRISTON KJ, 1994, HUM BRAIN MAPP, V214, P7; Gati JS, 1997, MAGNET RESON MED, V38, P296, DOI 10.1002/mrm.1910380220; GOENSE J, 2008, NEUROIMAGE; Golland Polina, 2003, Inf Process Med Imaging, V18, P330; GRUETTER R, 1993, MAGNET RESON MED, V29, P804, DOI 10.1002/mrm.1910290613; GUYON I, 2003, J MACH LEARN RES, V3, P26; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Haynes JD, 2005, NAT NEUROSCI, V8, P686, DOI 10.1038/nn1445; Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931; Kanwisher N, 1997, J NEUROSCI, V17, P4302; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Keliris GA, 2007, NEUROIMAGE, V36, P550, DOI 10.1016/j.neuroimage.2007.02.057; LaConte SM, 2007, HUM BRAIN MAPP, V28, P1033, DOI 10.1002/hbm.20326; Logothetis NK, 1999, NAT NEUROSCI, V2, P555, DOI 10.1038/9210; Mitchell Tom M, 2003, AMIA Annu Symp Proc, P465; NG AY, 2001, DISCRIMINATIVE GENER; PEREIRA F, 2006, P ICML PITTSB PA; Pfeuffer J, 2004, MAGN RESON IMAGING, V22, P1343, DOI 10.1016/j.mri.2004.10.004; Scholkopf B., 2002, LEARNING KERNELS, P187; Song L., 2007, BIOINFORMATICS, V23, P490; Tsao DY, 2003, NAT NEUROSCI, V6, P989, DOI 10.1038/nn1111; Ugurbil K, 2003, TRENDS NEUROSCI, V26, P108, DOI 10.1016/S0166-2236(02)00039-5; Yacoub E, 2003, MAGNET RESON MED, V49, P655, DOI 10.1002/mrm.10433	30	21	22	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0730-725X			MAGN RESON IMAGING	Magn. Reson. Imaging	SEP	2008	26	7					1007	1014		10.1016/j.mri.2008.02.016		8	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	342TN	WOS:000258806500020	
J	Sewell, C; Morris, D; Blevins, NH; Dutta, S; Agrawal, S; Barbagli, F; Salisbury, K				Sewell, Christopher; Morris, Dan; Blevins, Nikolas H.; Dutta, Sanjeev; Agrawal, Sumit; Barbagli, Federico; Salisbury, Kenneth			Providing metrics and performance feedback in a surgical simulator	COMPUTER AIDED SURGERY			English	Article						simulation; metrics; feedback; performance evaluation; mastoidectomy; validation	PROBABILISTIC FUNCTIONS; SURGERY; SKILLS	One of the most important advantages of computer simulators for surgical training is the opportunity they afford for independent learning. However, if the simulator does not provide useful instructional feedback to the user, this advantage is significantly blunted by the need for an instructor to supervise and tutor the trainee while using the simulator. Thus, the incorporation of relevant, intuitive metrics is essential to the development of efficient simulators. Equally as important is the presentation of such metrics to the user in such a way so as to provide constructive feedback that facilitates independent learning and improvement. This paper presents a number of novel metrics for the automated evaluation of surgical technique. The general approach was to take criteria that are intuitive to surgeons and develop ways to quantify them in a simulator. Although many of the concepts behind these metrics have wide application throughout surgery, they have been implemented specifically in the context of a simulation of mastoidectomy. First, the visuohaptic simulator itself is described, followed by the details of a wide variety of metrics designed to assess the user's performance. We present mechanisms for presenting visualizations and other feedback based on these metrics during a virtual procedure. We further describe a novel performance evaluation console that displays metric-based information during an automated debriefing session. Finally, the results of several user studies are reported, providing some preliminary validation of the simulator, the metrics, and the feedback mechanisms. Several machine learning algorithms, including Hidden Markov Models and a Naive Bayes Classifier, are applied to our simulator data to automatically differentiate users' expertise levels.	[Sewell, Christopher; Morris, Dan; Barbagli, Federico; Salisbury, Kenneth] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Blevins, Nikolas H.; Agrawal, Sumit] Stanford Univ, Dept Otolaryngol, Stanford, CA 94305 USA; [Dutta, Sanjeev; Salisbury, Kenneth] Stanford Univ, Dept Surg, Stanford, CA 94305 USA	Sewell, C (reprint author), 1325 Mills St,Apt 9, Menlo Pk, CA 94025 USA.	csewell@cs.stanford.edu					Agus M., 2002, Computing and Visualization in Science, V5, DOI 10.1007/s00791-002-0085-5; Agus M., 2004, Proceedings. 12th International Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems; Anastakis DJ, 2003, AM J SURG, V185, P378, DOI 10.1016/S0002-9610(02)01403-4; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; Bridges M, 1999, AM J SURG, V177, P28, DOI 10.1016/S0002-9610(98)00289-X; Bryan J., 2001, Proceedings Visualization 2001 (Cat. No.01CH37269), DOI 10.1109/VISUAL.2001.964561; Cotin S, 2002, LECT NOTES COMPUT SC, V2488, P35; Dosis A, 2005, ST HEAL T, V111, P115; FEYGIN D, 2002, P 10 IEEE HAPT S ORL; Gates EA, 1997, AM J OBSTET GYNECOL, V176, P1293, DOI 10.1016/S0002-9378(97)70348-X; GATES EA, 1997, AM J OBSTET GYNECOL, V176, P98; KAHOL K, 2007, IEEE MULTIM IN PRESS; KERNODLE MW, 1992, J MOTOR BEHAV, V24, P187; LUPERFOY S, 2006, PLEN SESS MED M VIRT; MACKEL T, 2006, STUDIES HLTH TECHNOL, V119, P355; MORRIS D, 200606 STANF U DEP C; Morris D, 2006, IEEE COMPUT GRAPH, V26, P48, DOI 10.1109/MCG.2006.140; Morris D., 2007, P 2 JOINT EUROHAPTIC, P21; Murphy TE, 2004, THESIS J HOPKINS U; Paisley AM, 2005, MED TEACH, V27, P634, DOI 10.1080/01421590500251175; PETERSIK A, 2002, P IEEE VIRT REAL VR; Pflesser Bernhard, 2002, Comput Aided Surg, V7, P74; Renz M, 2001, P EUR C, P149; Reznick R, 1996, AM J SURG, V172, P226; Rissanen MJ, 2007, ST HEAL T, V125, P388; Ritter E Matt, 2005, Surg Innov, V12, P233, DOI 10.1177/155335060501200308; Rosen J, 2001, IEEE T BIO-MED ENG, V48, P579, DOI 10.1109/10.918597; ROTH AM, 1976, METAB PEDIATR SYST O, V1, P35; Sewell C, 2005, ST HEAL T, V111, P451; Sewell C, 2006, ST HEAL T, V119, P497; Sewell C, 2007, ST HEAL T, V125, P427; Sidhu RS, 2004, SURGERY, V135, P6, DOI 10.1016/S0039-6060(03)00154-5; Silverstein J, 2007, ST HEAL T, V125, P436; STREDNEY D, 2003, OH LEARN NETW WIND F; TUCHSCHMID S, 2007, STUDIES HLTH TECHNOL, V125, P473; WINSTEIN CJ, 1990, J EXP PSYCHOL LEARN, V16, P677, DOI 10.1037//0278-7393.16.4.677; Yang UY, 2002, PRESENCE-TELEOP VIRT, V11, P304, DOI 10.1162/105474602317473240	38	21	21	INFORMA HEALTHCARE	LONDON	TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND	1092-9088			COMPUT AIDED SURG	Comput. Aided Surg.	MAR	2008	13	2					63	81		10.1080/10929080801957712		19	Surgery	Surgery	308VK	WOS:000256418000001	
J	Nguyen, D; Halupka, D; Aarabi, P; Sheikholeslami, A				Nguyen, Duy; Halupka, David; Aarabi, Parham; Sheikholeslami, Ali			Real-time face detection and lip feature extraction using field-programmable gate arrays	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						edge information; face detection; field-programmable gate array (FPGA); lip feature extraction; lip tracking; naive Bayes classifier; Sobel	RECOGNITION	This paper proposes a new technique for face detection and lip feature extraction. A real-time field-programmable gate array (FPGA) implementation of the two proposed techniques is also presented. Face detection is based on a naive Bayes classifier that classifies an edge-extracted representation of an image. Using edge representation significantly reduces the model's size to only 5184 B, which is 2417 times smaller than a comparable statistical modeling technique, while achieving an 86.6% correct detection rate under various lighting conditions. Lip feature extraction uses the contrast around the lip contour to extract the height and width of the mouth, metrics that are useful for speech filtering. The proposed FPGA system occupies only 15 050 logic cells, or about six times less than a current comparable FPGA face detection system.	Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 2E4, Canada	Nguyen, D (reprint author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 2E4, Canada.	halupka@eecg.toronto.edu					Aarabi P., 2004, Information Fusion, V5, DOI 10.1016/j.inffus.2003.10.006; Aarabi P., 2004, Information Fusion, V5, DOI 10.1016/j.inffus.2004.02.001; COOTES TF, 1932, COMPUT VIS IMAGE UND, V12; DENG L, 2000, P ICSLP, V3, P806; Feraud R, 2001, IEEE T PATTERN ANAL, V23, P42, DOI 10.1109/34.899945; FITZGERALD MP, 2002, CBCL FACE DATABASE 1; Georghiades A. S., 1997, YALE FACE DATABASE; Gonzalez R. C., 1992, DIGITAL IMAGE PROCES; Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696; HUNKE M, 1994, P 28 AS C SIGN SYST, P1277; Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3); MARIO D, 2000, PATTERN RECOGN, V33, P1525; MATHEWS I, 2002, IEEE T PATTERN ANAL, V24, P198; MATHEWS I, 2001, P IEEE INT C MULT EX, P1032; McCready R, 2000, THESIS U TORONTO TOR; NAKAMURA K, 2002, P IEEE ASIC, P303, DOI 10.1109/APASIC.2002.1031592; Papageorgiou C. P., 1998, P INT C COMP VIS, P555; Paschalakis S., 2003, Proceedings. 2003 IEEE International Conference on Field-Programmable Technology (FPT) (IEEE Cat. No.03EX798), DOI 10.1109/FPT.2003.1275750; Potamianos G., 1998, Proceedings 1998 International Conference on Image Processing. ICIP98 (Cat. No.98CB36269), DOI 10.1109/ICIP.1998.999008; Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150; Potamianos G., 2001, Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205), DOI 10.1109/ICIP.2001.958098; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Sahbi H., 2002, Proceedings 2002 International Conference on Image Processing (Cat. No.02CH37396), DOI 10.1109/ICIP.2002.1039124; Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; SCHNEIDERMAN H, 2003, P CAIP GRON NETH, P434; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Theocharides T., 2004, Proceedings. 17th International Conference on VLSI Design; Yang J., 1996, P 3 IEEE WORKSH APPL, P142; ZHANG X, 2002, EURASIP J APPL SIG P, V1, P1228	31	21	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2006	36	4					902	912		10.1109/TSMCB.2005.862728		11	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	068XN	WOS:000239408100014	
S	Ling, CX; Huang, J; Zhang, H		Xiang, Y; ChaibDraa, B		Ling, CX; Huang, J; Zhang, H			AUC: A better measure than accuracy in comparing learning algorithms	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	JUN 11-13, 2003	HALIFAX, CANADA	Canadian Soc Computat Studies Intelligence, Natl Res Council Canada			ROC CURVE; AREA	Predictive accuracy has been widely used as the main criterion for comparing the predictive ability of classification systems (such as C4.5, neural networks, and Naive Bayes). Most of these classifiers also produce probability estimations of the classification, but they are completely ignored in the accuracy measure. This is often taken for granted because both training and testing sets only provide class labels. In this paper we establish rigourously that, even in this setting, the area under the ROC (Receiver Operating Characteristics) curve, or simply AUC, provides a better measure than accuracy. Our result is quite significant for three reasons. First, we establish, for the first time, rigourous criteria for comparing evaluation measures for learning algorithms. Second, it suggests that AUC should replace accuracy when measuring and comparing classification systems. Third, our result also prompts us to re-evaluate many well-established conclusions based on accuracy in machine learning. For example, it is well accepted in the machine learning community that, in terms of predictive accuracy, Naive Bayes and decision trees axe very similar. Using AUC, however, we show experimentally that Naive Bayes is significantly better than the decision-tree learning algorithms.	Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Ling, CX (reprint author), Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.						Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P., 1992, P 10 NAT C ART INT, P223; LING CX, 2002, IN PRESS P 6 PAC AS; Merz C.J., UCI REPOSITORY MACHI; PROVOST F, 2003, IN PRESS MACHINE LEA; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F., 1998, P 15 INT C MACH LEAR, P445; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615	14	21	21	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40300-0	LECT NOTES ARTIF INT			2003	2671						329	341				13	Computer Science, Artificial Intelligence	Computer Science	BX29V	WOS:000184853500023	
J	Bengio, S; Bengio, Y				Bengio, S; Bengio, Y			Taking on the curse of dimensionality in joint distributions using neural networks	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Bayesian networks; curse of dimensionality; data mining; density estimation; graphical models; high dimensionality; multilayer neural networks; probabilistic models	MODELS	The curse of dimensionality is severe when modeling high-dimensional discrete data: the number of possible combinations of the variables explodes exponentially, In this paper, we propose a new architecture for modeling high-dimensional data that requires resources (parameters and computations) that grow at most as the square of the number of variables, using a multilayer neural network to represent the joint distribution of the variables as the product of conditional distributions. The neural network can be interpreted as a graphical model without hidden random variables, but in which the conditional distributions are tied through the hidden units. The connectivity of the neural network can be pruned by using dependency tests between the variables (thus reducing significantly the number of parameters). Experiments on modeling the distribution of several discrete data sets show statistically significant improvements over other methods such as naive Bayes and comparable Bayesian networks and show that significant improvements can be obtained by pruning the network.	IDIAP, Martigny, Switzerland; CIRANO, Montreal, PQ, Canada	Bengio, S (reprint author), IDIAP, Martigny, Switzerland.						Bahadur R. R., 1961, STUDIES ITEM ANAL PR, P158; BISHOP C, 1995, NEURAL NETWORKS RECO; Brand M, 1999, NEURAL COMPUT, V11, P1155, DOI 10.1162/089976699300016395; Chow C.K., 1962, Institute of Radio Engineers Transactions on Electronic Computers, VEC-11; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R., 1973, PATTERN CLASSIFICATI; Frey B. J., 1998, GRAPHICAL MODELS MAC; KOLMOGOROV A, 1933, G I ITAL ATTUARI, V4; KOLMOGOROV AN, 1992, BREAKTHROUGHS STAT; LAURITZEN SL, 1995, COMPUT STAT DATA AN, V19, P191, DOI 10.1016/0167-9473(93)E0056-A; NADEAU C, 2000, ADV NEURAL INFORMATI, V12; Pearl J., 1988, PROBABILISTIC REASON; PEARL J, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P441; SCHEINES R, 1994, SELECTING MODELS DAT, V4, P197; Spirtes P., 1991, Social Science Computer Review, V9, DOI 10.1177/089443939100900106; Spirtes P., 1993, CAUSATION PREDICTION	16	21	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2000	11	3					550	557		10.1109/72.846725		8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	326JM	WOS:000087732100002	
J	Broos, PS; Getman, KV; Povich, MS; Townsley, LK				Broos, Patrick S.; Getman, Konstantin V.; Povich, Matthew S.; Townsley, Leisa K.			A NAIVE BAYES SOURCE CLASSIFIER FOR X-RAY SOURCES	ASTROPHYSICAL JOURNAL SUPPLEMENT SERIES			English	Article						methods: data analysis; methods: statistical; stars: pre-main sequence; X-rays: general; X-rays: stars	YOUNG STELLAR OBJECTS; CARINA COMPLEX PROJECT; T-TAURI STARS; LUMINOSITY FUNCTIONS; NEBULA; VARIABILITY; ALGORITHM; EMISSION; CATALOG; SPITZER	The Chandra Carina Complex Project (CCCP) provides a sensitive X-ray survey of a nearby starburst region over > 1 deg(2) in extent. Thousands of faint X-ray sources are found, many concentrated into rich young stellar clusters. However, significant contamination from unrelated Galactic and extragalactic sources is present in the X-ray catalog. We describe the use of a naive Bayes classifier to assign membership probabilities to individual sources, based on source location, X-ray properties, and visual/infrared properties. For the particular membership decision rule adopted, 75% of CCCP sources are classified as members, 11% are classified as contaminants, and 14% remain unclassified. The resulting sample of stars likely to be Carina members is used in several other studies, which appear in this special issue devoted to the CCCP.	[Broos, Patrick S.; Getman, Konstantin V.; Povich, Matthew S.; Townsley, Leisa K.] Penn State Univ, Dept Astron & Astrophys, University Pk, PA 16802 USA	Broos, PS (reprint author), Penn State Univ, Dept Astron & Astrophys, 525 Davey Lab, University Pk, PA 16802 USA.	patb@astro.psu.edu			Chandra X-ray Observatory [GO8-9131X]; ACIS Instrument Team [SV4-74018]; NASA [NAS8-03060]; NSF [AST-0901646]; National Aeronautics and Space Administration; National Science Foundation	We appreciate the time and useful suggestions contributed by our anonymous referee. This work is supported by Chandra X-ray Observatory grant GO8-9131X (PI: L. Townsley) and by the ACIS Instrument Team contract SV4-74018 (PI: G. Garmire), issued by the Chandra X-ray Center, which is operated by the Smithsonian Astrophysical Observatory for and on behalf of NASA under contract NAS8-03060. M. S. P. is supported by an NSF Astronomy and Astrophysics Postdoctoral Fellowship under award AST-0901646. This publication makes use of data products from the Two Micron All Sky Survey, which is a joint project of the University of Massachusetts and the Infrared Processing and Analysis Center/California Institute of Technology, funded by the National Aeronautics and Space Administration and the National Science Foundation. The HAWK-I near-infrared observations were collected with the High Acuity Wide-field K-band Imager instrument (Kissler-Patig et al. 2008) on the ESO 8 m Very Large Telescope (VLT) at Paranal Observatory, Chile, under ESO programme 60.A-9284(K). This work is based in part on observations made with the Spitzer Space Telescope, which is operated by the Jet Propulsion Laboratory, California Institute of Technology under a contract with NASA.	Allen LE, 2004, ASTROPHYS J SUPPL S, V154, P363, DOI 10.1086/422715; Bazell D, 2001, ASTROPHYS J, V548, P219, DOI 10.1086/318696; Brandt WN, 2001, ASTRON J, V122, P2810, DOI 10.1086/324105; Broos PS, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/2; Broos PS, 2010, ASTROPHYS J, V714, P1582, DOI 10.1088/0004-637X/714/2/1582; Burnett B, 2010, MON NOT R ASTRON SOC, V407, P339, DOI 10.1111/j.1365-2966.2010.16896.x; Duda R.O., 2001, PATTERN CLASSIFICATI; Feigelson ED, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/9; Gagne M, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/5; Getman KV, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/3; Getman KV, 2010, ASTROPHYS J, V708, P1760, DOI 10.1088/0004-637X/708/2/1760; Gudel M, 2009, ASTRON ASTROPHYS REV, V17, P309, DOI 10.1007/s00159-009-0022-4; Guedel M., 1997, APJ, V483, P947; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Harvey P, 2007, ASTROPHYS J, V663, P1149, DOI 10.1086/518646; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Kissler-Patig M, 2008, ASTRON ASTROPHYS, V491, P941, DOI 10.1051/0004-6361:200809910; Mahabal A, 2008, ASTRON NACHR, V329, P288, DOI 10.1002/asna.200710943; MAHABAL AA, 2008, CLASSIFICATION, V1082, P287; Meyer MR, 1997, ASTRON J, V114, P288, DOI 10.1086/118474; Norman C, 2004, ASTROPHYS J, V607, P721, DOI 10.1086/383487; Paolillo M, 2004, ASTROPHYS J, V611, P93, DOI 10.1086/421967; Picaud S, 2005, ESA SP PUBL, V576, P467; Povich MS, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/14; Preibisch T, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/10; Ptak A, 2007, ASTROPHYS J, V667, P826, DOI 10.1086/520824; Ripley B., 1996, PATTERN RECOGNITION; Robitaille TP, 2008, ASTRON J, V136, P2413, DOI 10.1088/0004-6256/136/6/2413; Shemmer O, 2005, ASTROPHYS J, V630, P729, DOI 10.1086/432050; Telleschi A, 2007, ASTRON ASTROPHYS, V468, P425, DOI 10.1051/0004-6361:20066565; Townsley LK, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/1; Wolk SJ, 2005, ASTROPHYS J SUPPL S, V160, P423, DOI 10.1086/432099; Zhang YX, 2004, P SOC PHOTO-OPT INS, V5493, P483, DOI 10.1117/12.550982	33	20	20	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0067-0049			ASTROPHYS J SUPPL S	Astrophys. J. Suppl. Ser.	MAY	2011	194	1								10.1088/0067-0049/194/1/4		12	Astronomy & Astrophysics	Astronomy & Astrophysics	757MC	WOS:000290088300004	
J	Seo, HJ; Milanfar, P				Seo, Hae Jong; Milanfar, Peyman			Training-Free, Generic Object Detection Using Locally Adaptive Regression Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; image representation; correlation and regression analysis	BAYES DECISION RULE; CORRELATION-COEFFICIENT; SIMILARITY MEASURE; IMAGE; RECOGNITION; RESEMBLANCE; FEATURES; SCENE; SHAPE	We present a generic detection/localization algorithm capable of searching for a visual object of interest without training. The proposed method operates using a single example of an object of interest to find similar matches, does not require prior knowledge (learning) about objects being sought, and does not require any preprocessing step or segmentation of a target image. Our method is based on the computation of local regression kernels as descriptors from a query, which measure the likeness of a pixel to its surroundings. Salient features are extracted from said descriptors and compared against analogous features from the target image. This comparison is done using a matrix generalization of the cosine similarity measure. We illustrate optimality properties of the algorithm using a naive-Bayes framework. The algorithm yields a scalar resemblance map, indicating the likelihood of similarity between the query and all patches in the target image. By employing nonparametric significance tests and nonmaxima suppression, we detect the presence and location of objects similar to the given query. The approach is extended to account for large variations in scale and rotation. High performance is demonstrated on several challenging data sets, indicating successful detection of objects in diverse contexts and under different imaging conditions.	[Seo, Hae Jong; Milanfar, Peyman] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA	Seo, HJ (reprint author), Univ Calif Santa Cruz, 1156 High St,Mailcode SOE2, Santa Cruz, CA 95064 USA.	rokaf@soe.ucsc.edu; milanfar@soe.ucsc.edu			US Air Force Office [FA 9550-07-01-0365]	This work was supported in part by US Air Force Office of Scientific Research Grant FA 9550-07-01-0365.	Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Ahlgren P, 2003, J AM SOC INF SCI TEC, V54, P550, DOI 10.1002/asi.10242; Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BENGIO Y, 2005, ADV NEURAL INFORM PR, V18, P115; Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9; Boiman O., 2008, P IEEE C COMP VIS PA, P1; Brox T., 2007, P 2 INT WORKSH HUM M, P152; Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1; Calinski T, 2006, COMMUN STAT-SIMUL C, V35, P727, DOI 10.1080/03610910600716290; CHANDRASEKHAR V, 2009, P C VIS COMM IM PROC; CHEN DM, 2009, P IEEE DAT COMPR C M; DEVERNAY F, 1995, RR2724 I NAT RECH IN; Duda R. O., 2000, PATTERN CLASSIFICATI; ESCOUFIER Y, 2006, P 17 S COMP STAT, P285; Everingham M., 2009, PASCAL VISUAL OBJECT; FEI-FEI L., 2004, P IEEE C COMP VIS PA; Fergus R., 2005, P 10 IEEE INT C COMP, V2, P1816; Fu Y, 2008, IEEE T IMAGE PROCESS, V17, P226, DOI 10.1109/TIP.2007.914203; Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154; Grauman K, 2007, J MACH LEARN RES, V8, P725; HAN S, 2008, P INT C IM PROC, P1700; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; HORST P, 1963, MATRIX ALGEBRA SOCIA; Julie F., 2005, P IEEE INT C COMP VI, V1, P604; KAPPOR A, 2006, P EUR C COMP VIS, V3954, P302; Kay S.M., 1993, FUNDAMENTALS STAT SI, Vi; Ke Y, 2004, P IEEE C COMP VIS PA, V2, P506, DOI DOI 10.1109/CVPR.2004.1315206; Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529; Kim T., 2007, P IEEE C COMP VIS PA, P1; KUMAR N, 2008, P ECCV 08, P364; Lampert C. H., 2008, P IEEE C COMP VIS PA, P1; Lazebnik S, 2006, P IEEE C COMP VIS PA, P2169; LIN D., 2005, P IEEE INT C IM PROC, V3, P764; Liu CJ, 2008, IEEE T PATTERN ANAL, V30, P1116, DOI 10.1109/TPAMI.2008.66; Liu CJ, 2007, IEEE T PATTERN ANAL, V29, P1086, DOI 10.1109/TPAMI.2007.1063; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma Y., 2007, P 24 INT C MACH LEAR, V227, P577; Masnadi-Shirazi H., 2007, P IEEE INT C COMP VI, P1; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Mutch J., 2006, P IEEE C COMP VIS PA, P11; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Phillips PJ, 2005, PROC CVPR IEEE, P947; PONCE J, 2007, CATEGORY LEVEL OBJEC; RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263; Roweis S. T., 2000, SCIENCE, V290, P5500; ROWLEY H, 1998, IEEE PATT ANAL MACH, V20, P22; Rummel RJ., 1970, APPL FACTOR ANAL; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Schneider JW, 2007, J AM SOC INF SCI TEC, V58, P1586, DOI 10.1002/asi.20643; Shechtman E., 2007, P IEEE C COMP VIS PA, P1; Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119; Silverman BW, 1986, MONOGRAPHS STAT APPL, V26; Takeda H, 2008, IEEE T IMAGE PROCESS, V17, P550, DOI 10.1109/TIP.2007.918028; Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330; Takeda H, 2009, IEEE T IMAGE PROCESS, V18, P1958, DOI 10.1109/TIP.2009.2023703; TAKEDA H, 2008, P IEEE INT C IM PROC, P637; Tatsuoka M. M., 1988, MULTIVARIATE ANAL; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Tuytelaars T., 2007, P IEEE INT C COMP VI, P1; Vasconcelos M, 2009, IEEE T PATTERN ANAL, V31, P228, DOI 10.1109/TPAMI.2008.77; VINCENT P, 2003, ADV NEURAL INFORM PR, V15, P825; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wu B., 2007, P IEEE C COMP VIS PA, P1; Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112; Zhang H., 2006, P CVPR, V2, P2126	67	20	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1688	1704		10.1109/TPAMI.2009.153		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	626MB	WOS:000279969000011	
J	Murakami, Y; Mizuguchi, K				Murakami, Yoichi; Mizuguchi, Kenji			Applying the Naive Bayes classifier with kernel density estimation to the prediction of protein-protein interaction sites	BIOINFORMATICS			English	Article							BINDING-SITES; SOLVENT ACCESSIBILITY; SECONDARY STRUCTURE; SEQUENCE PROFILE; DATA-BANK; DATABASE; INFORMATION; INTERFACES; NETWORKS	Motivation: The limited availability of protein structures often restricts the functional annotation of proteins and the identification of their protein-protein interaction sites. Computational methods to identify interaction sites from protein sequences alone are, therefore, required for unraveling the functions of many proteins. This article describes a new method (PSIVER) to predict interaction sites, i.e. residues binding to other proteins, in protein sequences. Only sequence features (position-specific scoring matrix and predicted accessibility) are used for training a Naive Bayes classifier (NBC), and conditional probabilities of each sequence feature are estimated using a kernel density estimation method (KDE). Results: The leave-one out cross-validation of PSIVER achieved a Matthews correlation coefficient (MCC) of 0.151, an F-measure of 35.3%, a precision of 30.6% and a recall of 41.6% on a non-redundant set of 186 protein sequences extracted from 105 heterodimers in the Protein Data Bank (consisting of 36 219 residues, of which 15.2% were known interface residues). Even though the dataset used for training was highly imbalanced, a randomization test demonstrated that the proposed method managed to avoid overfitting. PSIVER was also tested on 72 sequences not used in training (consisting of 18 140 residues, of which 10.6% were known interface residues), and achieved an MCC of 0.135, an F-measure of 31.5%, a precision of 25.0% and a recall of 46.5%, outperforming other publicly available servers tested on the same dataset. PSIVER enables experimental biologists to identify potential interface residues in unknown proteins from sequence information alone, and to mutate those residues selectively in order to unravel protein functions.	[Murakami, Yoichi; Mizuguchi, Kenji] Natl Inst Biomed Innovat, Osaka, Japan	Murakami, Y (reprint author), Natl Inst Biomed Innovat, Osaka, Japan.	yoichi@nibio.go.jp; kenji@nibio.go.jp			New Energy and Industrial Technology Development Organization (NEDO) of Japan	Industrial Technology Research Grant Program in 2007 from New Energy and Industrial Technology Development Organization (NEDO) of Japan in part.	Adamczak R, 2005, PROTEINS, V59, P467, DOI 10.1002/prot.20441; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Burgoyne NJ, 2006, BIOINFORMATICS, V22, P1335, DOI 10.1093/bioinformatics/bt/079; Chen XW, 2009, BIOINFORMATICS, V25, P585, DOI 10.1093/bioinformatics/btp039; Dodge C, 1998, NUCLEIC ACIDS RES, V26, P313, DOI 10.1093/nar/26.1.313; Ezkurdia Iakes, 2009, Brief Bioinform, V10, P233, DOI 10.1093/bib/bbp021; Fariselli P, 2002, EUR J BIOCHEM, V269, P1356, DOI 10.1046/j.1432-1033.2002.02767.x; Fernandez-Recio J, 2005, PROTEINS, V58, P134, DOI 10.1002/prot.20285; Hripcsak G, 2005, J AM MED INFORM ASSN, V12, P296, DOI 10.1197/jamia.M1733; Hubbard S, 1993, NACCESS COMPUTER PRO; Hwang H, 2008, PROTEINS, V73, P705, DOI 10.1002/prot.22106; Jones S, 1997, J MOL BIOL, V272, P133, DOI 10.1006/jmbi.1997.1233; Jones S, 1997, J MOL BIOL, V272, P121, DOI 10.1006/jmbi.1997.1234; LEE B, 1971, J MOL BIOL, V55, P379, DOI 10.1016/0022-2836(71)90324-X; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mintseris J, 2005, PROTEINS, V60, P214, DOI 10.1002/prot.20560; Mitchell T.M., 1997, MACHINE LEARNING; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Neuvirth H, 2004, J MOL BIOL, V338, P181, DOI 10.1016/j.jmb.2004.02.040; Nooren IMA, 2003, J MOL BIOL, V325, P991, DOI 10.1016/S0022-2836(02)01281-0; Ofran Y, 2003, FEBS LETT, V544, P236, DOI 10.1016/S0014-5793(03)00456-3; Ofran Y, 2007, BIOINFORMATICS, V23, pE13, DOI 10.1093/bioinformatics/btl303; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Porollo A, 2007, PROTEINS, V66, P630, DOI 10.1002/prot.21248; Qi YJ, 2006, PROTEINS, V63, P490, DOI 10.1002/prot.20865; Res I, 2005, BIOINFORMATICS, V21, P2496, DOI 10.1093/bioinformatics/bti340; Russell RB, 2008, NAT CHEM BIOL, V4, P666, DOI 10.1038/nchembio.119; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Sikic M, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000278; Terribilini M, 2007, NUCLEIC ACIDS RES, V35, pW578, DOI 10.1093/nar/gkm294; Tusnady GE, 2004, BIOINFORMATICS, V20, P2964, DOI 10.1093/bioinformatics/bth340; Wagner M, 2005, J COMPUT BIOL, V12, P355, DOI 10.1089/cmb.2005.12.355; Wang B, 2006, FEBS LETT, V580, P380, DOI 10.1016/j.febslet.2005.11.081; Yan CH, 2004, BIOINFORMATICS, V20, P371, DOI 10.1093/bioinformatics/bth920; Yan CH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-262; Zhou HX, 2007, BIOINFORMATICS, V23, P2203, DOI 10.1093/bioinformatics/btm323; Zhou HX, 2001, PROTEINS, V44, P336, DOI 10.1002/prot.1099	39	20	20	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	AUG 1	2010	26	15					1841	1848		10.1093/bioinformatics/btq302		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	630HH	WOS:000280263400005	
J	Van Hulse, J; Khoshgoftaar, T				Van Hulse, Jason; Khoshgoftaar, Taghi			Knowledge discovery from imbalanced and noisy data	DATA & KNOWLEDGE ENGINEERING			English	Article						Data sampling; Class noise; Labeling errors; Class imbalance; Skewed class distribution	ATTRIBUTE NOISE; TRAINING DATA; CLASSIFICATION; SMOTE; COST	Class imbalance and labeling errors present significant challenges to data mining and knowledge discovery applications. Some previous work has discussed these important topics, however the relationship between these two issues has not received enough attention. Further, much of the previous work in this domain is fragmented and contradictory, leading to serious questions regarding the reliability and validity of the empirical conclusions. In response to these issues, we present a comprehensive suite of experiments carefully designed to provide conclusive, reliable, and significant results on the problem of learning from noisy and imbalanced data. Noise is shown to significantly impact all of the learners considered in this work, and a particularly important factor is the class in which the noise is located (which, as discussed throughout this work, has very important implications to noise handling). The impacts of noise, however, vary dramatically depending on the learning algorithm and simple algorithms such as naive Bayes and nearest neighbor learners are often more robust than more complex learners such as support vector machines or random forests. Sampling techniques, which are often used to alleviate the adverse impacts of imbalanced data, are shown to improve the performance of learners built from noisy and imbalanced data. In particular, simple sampling techniques such as random undersampling are generally the most effective. (C) 2009 Elsevier B.V. All rights reserved.	[Van Hulse, Jason; Khoshgoftaar, Taghi] Florida Atlantic Univ, Dept Comp Sci & Engn, Empir Software Engn Lab, Boca Raton, FL 33431 USA	Khoshgoftaar, T (reprint author), Florida Atlantic Univ, Dept Comp Sci & Engn, Empir Software Engn Lab, Boca Raton, FL 33431 USA.	taghi@cse.fau.edu					Asuncion A., 2007, UCI MACHINE LEARNING; Barandela R, 2004, LECT NOTES COMPUT SC, V3138, P806; Batista G.E.A.P.A., 2004, SIGKDD EXPLORATIONS, V6, P20, DOI DOI 10.1145/1007730.1007735; Berenson M.L., 1983, INTERMEDIATE STAT ME; BRADLEY CE, 1996, P 13 NAT C ART INT, P799; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Cao LB, 2008, IEEE T KNOWL DATA EN, V20, P1053, DOI 10.1109/TKDE.2007.190635; Chawla NV, 2008, DATA MIN KNOWL DISC, V17, P225, DOI 10.1007/s10618-008-0087-0; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Fan W., 1999, P 16 INT C MACH LEAR, P97; FENG Y, 2006, 6 IEEE INT C DAT MIN, P754, DOI 10.1109/ICDMW.2006.70; Fenton NE, 1997, SOFTWARE METRICS RIG; Folleco A, 2008, PROCEEDINGS OF THE 2008 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P190; Gamberger D, 1999, P 16 INT C MACH LEAR, P143; Han H, 2005, LECT NOTES COMPUT SC, V3644, P878; Hand DJ, 2005, J OPER RES SOC, V56, P1109, DOI 10.1057/palgrave.jors.2601932; Holte R. C., 2003, WORKSH LEARN IMB DAT; Japkowicz N., 2002, Intelligent Data Analysis, V6; Japkowicz N., 2000, AAAI 00 WORKSH LEARN, P10; JAPKOWICZ N, 2003, WORKSH LEARN IMB DAT, V2; JO T, 2004, SIGKDD EXPLORATIONS, V6, P40, DOI DOI 10.1145/1007730.1007737; Joshi M. V., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989527; Khoshgoftaar T. M., 2007, P 6 INT C MACH LEARN, P348; Khoshgoftaar T. M., 1998, Empirical Software Engineering, V3, DOI 10.1023/A:1009736205722; Khoshgoftaar TM, 2005, INTELL DATA ANAL, V9, P3; Khoshgoftaar TM, 2005, INTELL DATA ANAL, V9, P347; Khoshgoftaar T. M., 2004, Proceedings. 10th International Symposium on Software Metrics; Khoshgoftaar TM, 2004, EMPIR SOFTW ENG, V9, P229, DOI 10.1023/B:EMSE.0000027781.18360.9b; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Li DF, 2008, PATTERN RECOGN LETT, V29, P1175, DOI 10.1016/j.patrec.2008.01.009; Little Roderick J. A., 2002, STAT ANAL MISSING DA; Maloof M., 2003, P ICML 03 WORKSH LEA; Prati RC, 2004, LECT NOTES ARTIF INT, V3171, P296; Provost F., 1998, P 15 INT C MACH LEAR; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; SAS Institute Inc, 2004, SAS STAT US GUID; Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009; Teng CM, 1999, P 16 INT C MACH LEAR, P239; Thomas L. C., 2002, SIAM MONOGRAPHS MATH; Van Hulse J., 2007, P 24 INT C MACH LEAR, P935, DOI 10.1145/1273496.1273614; VANHULSE J, 2007, P IEEE INT C DAT MIN, P477; Van Hulse J, 2006, INTELL DATA ANAL, V10, P487; Van Hulse JD, 2007, KNOWL INF SYST, V11, P171, DOI 10.1007/s10115-006-0022-x; Weiss G. M., 2004, SIGKDD EXPLORATIONS, V6, P7, DOI DOI 10.1145/1007730.1007734; Weiss Gary M, 2007, Proceedings of the International Conference on Data Mining. DMIN 2007; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Witten IH, 2005, DATA MINING PRACTICA; Wohlin C., 2000, EXPT SOFTWARE ENG, pRuneson; Zhu XQ, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P297; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8; ZHUANG L, 2006, 6 IEEE INT C DAT MIN, P770, DOI 10.1109/ICDMW.2006.139	52	20	20	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X			DATA KNOWL ENG	Data Knowl. Eng.	DEC	2009	68	12					1513	1542		10.1016/j.datak.2009.08.005		30	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	527KK	WOS:000272365800012	
J	Elvik, R				Elvik, Rune			The predictive validity of empirical Bayes estimates of road safety	ACCIDENT ANALYSIS AND PREVENTION			English	Article						Road safety; Before-and-after study; Accident prediction; Empirical Bayes method; Test		This paper examines the predictive validity of empirical Bayes (EB) estimates of road safety. The predictive performance of EB-estimates was tested by applying five versions of EB-estimates of road safety: (1) A simple estimate derived from the empirical distribution of accidents in a population of sites, by which the number of accidents predicted for period 2 for sites that recorded k accidents in period 1 equals the number of accidents for sites that recorded k + 1 accidents in period 1. (2) Estimates derived from the parameters of a negative binomial distribution fitted to an empirical distribution of accidents in a population of sites by means of the method of moments. (3) Estimates derived from the parameters of a negative binomial distribution fitted to an empirical distribution of accidents in a population of sites by means of the maximum likelihood technique. (4) Estimates derived by combining the predictions of an accident prediction model and the recorded number of accidents for a site. (5) Estimates derived by combining the predictions of a different version of an accident prediction model and the recorded number of accidents for a site. All versions of EB-estimates are compared to the traditional, naive assumption of treating the recorded number of accidents as an unbiased estimate of the expected number of accidents. To test the predictive performance of EB-estimates, data for two periods was used. EB-estimates based on data for the first period were treated as predictions of the number of accidents in the second period for road sections that had 0, 1, 2, etc., accidents in the first period, the idea being that the more accurate the prediction, the more accurate the result of a before-and-after study. All versions of EB-estimates were found to give considerably more correct predictions of the number of accidents in the second period than relying on the count of accidents in the first period as a prediction of the count in the second period. Smaller prediction errors were associated with predictions based on accident prediction models than predictions not based on such models. (C) 2008 Elsevier Ltd. All rights reserved.	Inst Transport Econ, NO-0349 Oslo, Norway	Elvik, R (reprint author), Inst Transport Econ, Gaustadalleen 21, NO-0349 Oslo, Norway.	re@toi.no					Cheng W, 2005, ACCIDENT ANAL PREV, V37, P870, DOI 10.1016/j.aap.2005.04.015; Elvik R., 2007, 883 I TRANSP EC; ELVIK R, 2002, 572 TRANSP I; ELVIK R, 2004, TRANSPORT RES REC, V1897, P200, DOI 10.3141/1897-26; FRIDSTROM L, 1995, ACCIDENT ANAL PREV, V27, P1; HARWOOD DW, 2002, SAFETY ANAL SOFTWARE, V1; HAUER E, 1986, ACCIDENT ANAL PREV, V18, P1, DOI 10.1016/0001-4575(86)90031-X; HAUER E, 1980, ACCIDENT ANAL PREV, V12, P113, DOI 10.1016/0001-4575(80)90049-4; Hauer E., 1997, OBSERVATIONAL BEFORE; Hauer E., 1983, TRANSPORT RES REC, V905, P164; Hauer E., 2002, TRANSPORT RES REC, P126, DOI 10.3141/1784-16; Higle J. L., 1989, TRANSPORT RES REC, P10; Lord D, 2006, ACCIDENT ANAL PREV, V38, P751, DOI 10.1016/j.aap.2006.02.001; Miaou S.P., 2003, TRANSPORT RES REC, V1840, P31, DOI 10.3141/1840-04; PERSAUD B, 1999, TRANSPORT RES REC, V1665, P7, DOI 10.3141/1665-02; Persaud B, 2007, ACCIDENT ANAL PREV, V39, P546, DOI 10.1016/j.aap.2006.09.009; Persaud B. N., 1984, TRANSPORT RES REC, P43	17	20	20	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0001-4575			ACCIDENT ANAL PREV	Accid. Anal. Prev.	NOV	2008	40	6					1964	1969		10.1016/j.aap.2008.07.007		6	Ergonomics; Public, Environmental & Occupational Health; Social Sciences, Interdisciplinary; Transportation	Engineering; Public, Environmental & Occupational Health; Social Sciences - Other Topics; Transportation	378UN	WOS:000261349800023	
J	Judson, R; Elloumi, F; Setzer, RW; Li, Z; Shah, I				Judson, Richard; Elloumi, Fathi; Setzer, R. Woodrow; Li, Zhen; Shah, Imran			A comparison of machine learning algorithms for chemical toxicity classification using a simulated multi-scale data model	BMC BIOINFORMATICS			English	Article							PREDICTIVE TOXICOLOGY CHALLENGE; ORPHAN NUCLEAR RECEPTORS; SUPPORT VECTOR MACHINES; MOLECULAR LIBRARIES; FEATURE-SELECTION; CANCER; MICROARRAYS; DISCOVERY; PATTERNS; TARGET	Background: Bioactivity profiling using high-throughput in vitro assays can reduce the cost and time required for toxicological screening of environmental chemicals and can also reduce the need for animal testing. Several public efforts are aimed at discovering patterns or classifiers in high-dimensional bioactivity space that predict tissue, organ or whole animal toxicological endpoints. Supervised machine learning is a powerful approach to discover combinatorial relationships in complex in vitro/in vivo datasets. We present a novel model to simulate complex chemical-toxicology data sets and use this model to evaluate the relative performance of different machine learning (ML) methods. Results: The classification performance of Artificial Neural Networks (ANN), K-Nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Naive Bayes (NB), Recursive Partitioning and Regression Trees (RPART), and Support Vector Machines (SVM) in the presence and absence of filter-based feature selection was analyzed using K-way cross-validation testing and independent validation on simulated in vitro assay data sets with varying levels of model complexity, number of irrelevant features and measurement noise. While the prediction accuracy of all ML methods decreased as non-causal (irrelevant) features were added, some ML methods performed better than others. In the limit of using a large number of features, ANN and SVM were always in the top performing set of methods while RPART and KNN (k = 5) were always in the poorest performing set. The addition of measurement noise and irrelevant features decreased the classification accuracy of all ML methods, with LDA suffering the greatest performance degradation. LDA performance is especially sensitive to the use of feature selection. Filter-based feature selection generally improved performance, most strikingly for LDA. Conclusion: We have developed a novel simulation model to evaluate machine learning methods for the analysis of data sets in which in vitro bioassay data is being used to predict in vivo chemical toxicology. From our analysis, we can recommend that several ML methods, most notably SVM and ANN, are good candidates for use in real world applications in this area.	[Judson, Richard; Elloumi, Fathi; Setzer, R. Woodrow; Shah, Imran] US EPA, Natl Ctr Computat Toxicol, Off Res & Dev, Res Triangle Pk, NC 27711 USA; [Li, Zhen] Univ N Carolina, Dept Biostat, Chapel Hill, NC 27599 USA	Judson, R (reprint author), US EPA, Natl Ctr Computat Toxicol, Off Res & Dev, Res Triangle Pk, NC 27711 USA.	judson.richard@epa.gov; elloumi.fathi@epa.gov; setzer.woodrow@epa.gov; zli@bios.unc.edu; shah.imran@epa.gov					ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; Ancona N, 2006, BMC Bioinformatics, V7, P387, DOI 10.1186/1471-2105-7-387; Austin CP, 2004, SCIENCE, V306, P1138, DOI 10.1126/science.1105511; Baker SG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-407; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Benigni R, 2003, BIOINFORMATICS, V19, P1194, DOI 10.1093/bioinformatics/btg099; Bhogal N, 2005, TRENDS BIOTECHNOL, V23, P299, DOI 10.1016/j.tibtech.2005.04.006; Bredel M, 2004, NAT REV GENET, V5, P262, DOI 10.1038/nrg1317; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Dix DJ, 2007, TOXICOL SCI, V95, P5, DOI 10.1093/toxsci/kfl103; Fliri AF, 2005, NAT CHEM BIOL, V1, P389, DOI 10.1038/nchembio747; Fliri AF, 2005, P NATL ACAD SCI USA, V102, P261, DOI 10.1073/pnas.0407790101; Helma C, 2003, BIOINFORMATICS, V19, P1179, DOI 10.1093/bioinformatics/btg084; Inglese J, 2006, P NATL ACAD SCI USA, V103, P11473, DOI 10.1073/pnas.0604348103; Japkowicz N., 2002, Intelligent Data Analysis, V6; Kikkawa Rie, 2006, Journal of Toxicological Sciences, V31, P23, DOI 10.2131/jts.31.23; Klekota J, 2006, J CHEM INF MODEL, V46, P1549, DOI 10.1021/ci050495h; Kohavi R, 1995, INT JOINT C ART INT; KREWSKI D, 2007, TOXICITY TESTING 21; Lamb J, 2006, SCIENCE, V313, P1929, DOI 10.1126/science.1132939; Lepp Z, 2006, J CHEM INF MODEL, V46, P158, DOI 10.1021/ci05030ly; LI LH, 2005, 2005 IEEE INT C NAT, V10, P371; MARTIN MT, 2007, TOXICOLOGIST CD J SO, V96, P219; McMillian M, 2004, BIOCHEM PHARMACOL, V67, P2141, DOI 10.1016/j.bcp.2004.01.029; Melnick JS, 2006, P NATL ACAD SCI USA, V103, P3153, DOI 10.1073/pnas.0511292103; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; Moore LB, 2000, J BIOL CHEM, V275, P15122, DOI 10.1074/jbc.M001215200; Ntzani EE, 2003, LANCET, V362, P1439, DOI 10.1016/S0140-6736(03)14686-7; O'Brien PJ, 2006, ARCH TOXICOL, V80, P580, DOI 10.1007/s00204-006-0091-3; Okey AB, 2007, TOXICOL SCI, V98, P5, DOI 10.1093/toxsci/kfm096; Paolini GV, 2006, NAT BIOTECHNOL, V24, P805, DOI 10.1038/nbt1228; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Sima C, 2006, BIOINFORMATICS, V22, P2430, DOI 10.1093/bioinformatics/btl407; Smith SC, 2005, COMB CHEM HIGH T SCR, V8, P577, DOI 10.2174/138620705774575346; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Strausberg RL, 2003, SCIENCE, V300, P294, DOI 10.1126/science.1083395; Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009; Tietjen K, 2005, COMB CHEM HIGH T SCR, V8, P589, DOI 10.2174/138620705774575300; Toivonen H, 2003, BIOINFORMATICS, V19, P1183, DOI 10.1093/bioinformatics/btg130; Vanden Heuvel J.P., 2006, TOXICOL SCI, V92, P476; Walum Erik, 2005, Toxicol Appl Pharmacol, V207, P393, DOI 10.1016/j.taap.2005.01.056; Wang HB, 2003, CLIN PHARMACOKINET, V42, P1331, DOI 10.2165/00003088-200342150-00003; Williams GM, 2002, TOXICOL PATHOL, V30, P41, DOI 10.1080/01926230252824699; Zhang J., 2003, ICML; MLINTERFACE UNIFROM; E1071 PACKAGE; PREDICTIVE TOXICOLOG	48	20	20	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAY 19	2008	9								241	10.1186/1471-2105-9-241		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	308XG	WOS:000256423400001	
J	Lin, JH; Haug, PJ				Lin, Jau-Huei; Haug, Peter J.			Exploiting missing clinical data in Bayesian network modeling for predicting medical problems	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						missing data; problem list; clinical decision support system; Bayesian network	PROBLEM-ORIENTED APPROACH; SYSTEM; VALIDATION; REGRESSION; RECORD; GUIDE	When machine learning algorithms are applied to data collected during the course of clinical care, it is generally accepted that the data has not been consistently collected. The absence of expected data elements is common and the mechanism through which a data element is missing often involves the clinical relevance of that data element in a specific patient. Therefore, the absence of data may have information value of its own. In the process of designing an application intended to support a medical problem list, we have studied whether the "missingness" of clinical data can provide useful information in building prediction models. In this study, we experimented with four methods of treating missing values in a clinical data set-two of them explicitly model the absence or "missingness" of data. Each of these data sets were used to build four different kinds of Bayesian classifiers-a naive Bayes structure, a human-composed network structure, and two networks based on structural learning algorithms. We compared the performance between groups with and without explicit models of missingness using the area under the ROC curve. The results showed that in most cases the classifiers trained using the explicit missing value treatments performed better. The result suggests that information may exist in "missingness" itself. Thus, when designing a decision support system, we suggest one consider explicitly representing the presence/absence of data in the underlying logic. (C) 2007 Elsevier Inc. All rights reserved.	[Lin, Jau-Huei] Univ Utah, Dept Biomed Informat, Salt Lake City, UT 84112 USA; LDS Hosp, Salt Lake City, UT 84143 USA	Lin, JH (reprint author), Univ Utah, Dept Biomed Informat, 26 South,2000 East,Romm 5775 HSEB, Salt Lake City, UT 84112 USA.	jauhuei.lin@utah.edu					BABBOTT D, 1983, ACAD MED, V58, P947, DOI 10.1097/00001888-198312000-00005; BOLENS M, 1992, M D COMPUT, V9, P149; Bui AAT, 2004, ST HEAL T, V107, P587; Bui AAT, 2001, J AM MED INFORM ASSN, V8, P242; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Campbell J R, 1998, Proc AMIA Symp, P285; Chickering D. M., 2002, MSRTR2002103; Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Edgington E. S., 1995, RANDOMIZATION TESTS; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Enders CK, 2006, PSYCHOSOM MED, V68, P427, DOI 10.1097/01.psy.0000221275.75056.d8; FOLLMANN D, 1995, BIOMETRICS, V51, P151, DOI 10.2307/2533322; Friedman N, 1998, P 14 C UNC ART INT, P129; Gardner RM, 1999, INT J MED INFORM, V54, P169, DOI 10.1016/S1386-5056(99)00013-1; Goldman L, 2003, CECIL TXB MED; HANLEY JA, 1982, RADIOLOGY, V143, P29; Heckerman D., 1995, MSRTR9506; HESTERBERG T, 2002, BOOSTRAP METHODS PER, pCH18; HUST JW, 1971, ARCH INTERN MED, V128, P818; Jensen F.V., 2001, BAYESIAN NETWORKS DE; Jones MP, 1996, J AM STAT ASSOC, V91, P222, DOI 10.2307/2291399; Kasper DL, 2005, HARRISONS PRINCIPLES; Lavrac N., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; Little Roderick J. A., 2002, STAT ANAL MISSING DA; MARGOLIS CZ, 1984, AM J PUBLIC HEALTH, V74, P1410, DOI 10.2105/AJPH.74.12.1410; MEYSTRE S, 2005, BMC MED INFORM DECIS, V5; *NORS SOFTW CORP, NETICA; Pearl J., 1988, PROBABILISTIC REASON; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; RUSSELL IJ, 1990, ACAD MED, V65, P333, DOI 10.1097/00001888-199005000-00015; STARMER JM, 1998, P AMIA S; Steyerberg EW, 2001, J CLIN EPIDEMIOL, V54, P774, DOI 10.1016/S0895-4356(01)00341-9; Tufo H M, 1977, JAMA, V238, P414, DOI 10.1001/jama.238.5.414; TUFO HM, 1977, JAMA-J AM MED ASSOC, V238, P502, DOI 10.1001/jama.238.6.502; WEED LL, 1968, NEW ENGL J MED, V278, P52; WEED LL, 1968, NEW ENGL J MED, V278, P593, DOI 10.1056/NEJM196803142781105; WU MC, 1988, BIOMETRICS, V44, P175, DOI 10.2307/2531905	38	20	20	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	FEB	2008	41	1					1	14		10.1016/j.jbi.2007.06.001		14	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	292IR	WOS:000255260200001	
J	Melnikov, AA; Scholtens, DM; Wiley, EL; Khan, SA; Levenson, VV				Melnikov, Anatoliy A.; Scholtens, Denise M.; Wiley, Elizabeth L.; Khan, Seema A.; Levenson, Victor V.			Array-based multiplex analysis of DNA methylation in breast cancer tissues	JOURNAL OF MOLECULAR DIAGNOSTICS			English	Article							P53 PROTEIN; GENE; HYPERMETHYLATION; EXPRESSION; CELLS; ASSOCIATION; EPIGENETICS; CARCINOMA; METASTASIS; PROGNOSIS	Abnormal DNA methylation is well established for cancer cells, but a methylation-based diagnostic test is yet to be developed. one of the problems is insufficient accuracy of cancer detection in heterogeneous clinical specimens when only a single gene is analyzed. A new technique was developed to produce a multigene methylation signature in each sample, and its potential for selection of informative genes was tested using DNA from formalin-fixed, paraffin-embedded breast cancer tissues. Fifty-six promoters were analyzed in each of 138 clinical specimens by a microarray-based modification of the previously developed technique. Specific methylation signatures were identified for atypical ductal hyperplasia, ductal carcinoma in situ, and invasive ductal carcinoma. informative promoters selected by Fisher's exact test were used for composite biomarker design using naive Bayes algorithm. All informative promoters were unmethylated in disease compared with normal tissue. Cross-validation showed 72.4% sensitivity and 74.7% specificity for detection of ductal carcinoma in situ and invasive ductal carcinoma, and 87.5% sensitivity and 95% specificity for detection of atypical ductal hyperplasia. These results indicate that informative cancer-specific methylation signatures can be detected in heterogeneous tissue specimens, suggesting that a diagnostic assay can then be developed.	[Scholtens, Denise M.] Northwestern Univ, Feinberg Sch Med, Dept Prevent Med, Chicago, IL 60611 USA; [Wiley, Elizabeth L.] Northwestern Univ, Feinberg Sch Med, Dept Pathol, Chicago, IL 60611 USA; [Khan, Seema A.] Northwestern Univ, Feinberg Sch Med, Dept Surg, Chicago, IL 60611 USA; [Melnikov, Anatoliy A.; Scholtens, Denise M.; Levenson, Victor V.] Northwestern Univ, Feinberg Sch Med, Robert H Lurie Comprehens Canc Ctr, Chicago, IL 60611 USA	Levenson, VV (reprint author), 710 N Fairbanks Ct,Olson 8-424, Chicago, IL 60611 USA.	levenson@northwestern.edu					Albo D, 2002, J SURG RES, V108, P51, DOI 10.1006/jsre.2002.6452; BARNES WM, 1994, P NATL ACAD SCI USA, V91, P2216, DOI 10.1073/pnas.91.6.2216; Baylin SB, 2006, NAT REV CANCER, V6, P107, DOI 10.1038/nrc1799; Beitzinger M, 2006, ONCOGENE, V25, P813, DOI 10.1038/sj.onc.1209125; Berg WA, 2004, RADIOLOGY, V233, P830, DOI 10.1148/radiol.2333031484; Bhandare Deepa J, 2006, Clin Chim Acta, V367, P211, DOI 10.1016/j.cca.2005.12.022; Brena RM, 2006, J MOL MED-JMM, V84, P365, DOI 10.1007/s00109-005-0034-0; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fackler MJ, 2006, CLIN CANCER RES, V12, P3306, DOI 10.1158/1078-0432.CCR-05-2733; Feinberg AP, 2004, NAT REV CANCER, V4, P143, DOI 10.1038/nrc1279; Fiegl H, 2006, CANCER RES, V66, P29, DOI 10.1158/0008-5472.CAN-05-2508; Fiegl H, 2005, CANCER RES, V65, P1141, DOI 10.1158/0008-5472.CAN-04-2438; Gentleman RC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-10-r80; Grunau C, 2001, NUCLEIC ACIDS RES, V29, pE65; Hashimoto T, 2004, PATHOBIOLOGY, V71, P267, DOI 10.1159/000080061; Herman JG, 2004, CHEST, V125, p119S, DOI 10.1378/chest.125.5_suppl.119S; HERMAN JG, 1995, CANCER RES, V55, P4525; Iyer NG, 2004, P NATL ACAD SCI USA, V101, P7386, DOI 10.1073/pnas.0401002101; Jensen R A, 1993, J Cell Biochem Suppl, V17G, P59; Jones PA, 2005, SEMIN HEMATOL, V42, pS3, DOI 10.1053/j.seminhematol.2005.05.001; Knutson D, 2007, AM FAM PHYSICIAN, V75, P1660; Leonard Gregory D, 2004, Breast J, V10, P146, DOI 10.1111/j.1075-122X.2004.21374.x; Lewis CM, 2005, CLIN CANCER RES, V11, P166; Li LC, 2004, BIOCHEM BIOPH RES CO, V321, P455, DOI 10.1016/j.bbrc.2004.06.164; Li SY, 2006, CANCER LETT, V237, P272, DOI 10.1016/j.canlet.2005.06.011; MacGrogan G, 2003, VIRCHOWS ARCH, V443, P609, DOI 10.1007/s00428-003-0888-x; Melnikov Anatoliy A, 2005, Nucleic Acids Res, V33, pe93, DOI 10.1093/nar/gni092; Model F, 2001, Bioinformatics, V17 Suppl 1, pS157; Munson K, 2007, NUCLEIC ACIDS RES, V35, P2893, DOI 10.1093/nar/gkm055; Rajan PB, 1997, BREAST CANCER RES TR, V42, P283, DOI 10.1023/A:1005741723479; Scholtens D, 2005, STAT BIOL HEALTH, P229; Shinozaki M, 2005, CLIN CANCER RES, V11, P2156, DOI 10.1158/1078-0432.CCR-04-1810; Taback B, 2004, ANN NY ACAD SCI, V1022, P1, DOI 10.1196/annals.1318.002; Tan PH, 1999, ONCOL REP, V6, P1159; Umbricht CB, 2001, ONCOGENE, V20, P3348, DOI 10.1038/sj.onc.1204438; Warnecke PM, 1997, NUCLEIC ACIDS RES, V25, P4422, DOI 10.1093/nar/25.21.4422; Widschwendter M, 2002, ONCOGENE, V21, P5462, DOI 10.1038/sj.onc.1205606; Worm J, 2001, J BIOL CHEM, V276, P39990, DOI 10.1074/jbc.M103181200; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15	39	20	21	AMER SOC INVESTIGATIVE PATHOLOGY, INC	BETHESDA	9650 ROCKVILLE PIKE, BETHESDA, MD 20814-3993 USA	1525-1578			J MOL DIAGN	J. Mol. Diagn.	JAN	2008	10	1					93	101		10.2353/jmoldx2008070077		9	Pathology	Pathology	253MB	WOS:000252521200012	
J	Murray, JF; Hughes, GF; Kreutz-Delgado, K				Murray, JF; Hughes, GF; Kreutz-Delgado, K			Machine learning methods for predicting failures in hard drives: A multiple-instance application	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						hard drive failure prediction; rank-sum test; support vector machines (SVM); exact nonparametric statistics; multiple instance naive-Bayes	VECTOR MACHINE; CLASSIFIER; TIME	We compare machine learning methods applied to a difficult real-world problem: predicting computer hard-drive failure using attributes monitored internally by individual drives. The problem is one of detecting rare events in a time series of noisy and nonparametrically-distributed data. We develop a new algorithm based on the multiple-instance learning framework and the naive Bayesian classifier (mi-NB) which is specifically designed for the low false-alarm case, and is shown to have promising performance. Other methods compared are support vector machines (SVMs), unsupervised clustering, and non-parametric statistical tests (rank-sum and reverse arrangements). The failure-prediction performance of the SVM, rank-sum and mi-NB algorithm is considerably better than the threshold method currently implemented in drives, while maintaining low false alarm rates. Our results suggest that nonparametric statistical tests should be considered for learning problems involving detecting rare events in time series data. An appendix details the calculation of rank-sum significance probabilities in the case of discrete, tied observations, and we give new recommendations about when the exact calculation should be used instead of the commonly-used normal approximation. These normal approximations may be particularly inaccurate for rare event problems like hard drive failures.	Univ Calif San Diego, Jacobs Sch Engn, La Jolla, CA 92093 USA; Univ Calif San Diego, Ctr Magnet Recording Res, La Jolla, CA 92093 USA	Murray, JF (reprint author), Univ Calif San Diego, Jacobs Sch Engn, La Jolla, CA 92093 USA.	JFMURRAY@JFMURRAY.ORG; GFHUGHES@UCSD.EDU; KREUTZ@ECE.UCSD.EDU					ANDREWS S, 2003, ADV NEURAL INFORM PR, V15, P1; Bendat J., 2000, RANDOM DATA; Bickel P. J., 1977, MATH STAT; Bridge PD, 1999, J CLIN EPIDEMIOL, V52, P229, DOI 10.1016/S0895-4356(98)00168-1; Brunner E, 2002, J STAT PLAN INFER, V108, P37, DOI 10.1016/S0378-3758(02)00269-0; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Catlett J., 1991, P EUR WORK SESS LEAR, P164; CHEESEMAN P, 1995, ADV KNOWLEDGE DISCOV, P158; Cherkassky V., 1998, LEARNING DATA CONCEP; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DIETZ EJ, 1981, J AM STAT ASSOC, V76, P169, DOI 10.2307/2287063; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; EMERSON JD, 1985, BIOMETRICS, V41, P303, DOI 10.2307/2530667; FRANK E, 1999, P 16 INT C MACH LEAR, P115; HAMERLY G, 2001, 18 INT C MACH LEARN, P1; Hettmansperger T. P., 1984, STAT INFERENCE BASED; Hughes GF, 2002, IEEE T RELIAB, V51, P350, DOI [10.1109/TR.2002.802886, 10.1109/tTR.2002.802886]; Kendall M. G., 1969, ADV THEORY STAT, V1; KLOTZ JH, 1966, J AM STAT ASSOC, V61, P772, DOI 10.2307/2282786; LEHMAN SY, 1961, J AM STAT ASSOC, V56, P293, DOI 10.2307/2282254; Lehmann E.L., 1998, NONPARAMETRICS STAT; Liang FM, 2003, NEURAL COMPUT, V15, P1959, DOI 10.1162/08997660360675107; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Mann HB, 1945, ECONOMETRICA, V13, P245, DOI 10.2307/1907187; MEHTA CR, 1988, J AM STAT ASSOC, V83, P999; MEHTA CR, 1988, BIOMETRIKA, V75, P295; Murray J. F., 2003, P INT C ART NEUR NET; Ng A., 2002, ADV NEURAL INFORM PR, V14; Orlitsky A, 2003, SCIENCE, V302, P427, DOI 10.1126/science.1088284; PAGANO M, 1983, J AM STAT ASSOC, V78, P435, DOI 10.2307/2288653; Preusser B. E., 1991, Proceedings of the American Power Conference; ROTHMAN KJ, 2000, MODERN EPIDEMIOLOGY; Ruping S., 2000, MYSVM MANUAL, P8; THEODOSSIOU PT, 1993, J AM STAT ASSOC, V88, P441, DOI 10.2307/2290323; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik V., 1995, NATURE STAT LEARNING; Vincent P, 2002, MACH LEARN, V48, P165, DOI 10.1023/A:1013955821559; Wang J., 2000, P 17 INT C MACH LEAR, P1119; WEISS GM, 1998, P 4 INT C KNOWL DISC; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Xu X, 2003, THESIS U WAIKATO HAM	42	20	21	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAY	2005	6						783	816				34	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HJ	WOS:000236329700003	
J	Dash, D; Cooper, GF				Dash, D; Cooper, GF			Model averaging for prediction with discrete Bayesian networks	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						Bayesian networks; Bayesian model averaging; classification; naive Bayes classifiers; feature selection	GRAPHICAL MODELS; CLASSIFIERS; SELECTION	In this paper(1) we consider the problem of performing Bayesian model-averaging over a class of discrete Bayesian network structures consistent with a partial ordering and with bounded in-degree k. We show that for N nodes this class contains in the worst-case at least Omega(((N/2)(k))(N/2))distinct network structures, and yet model averaging over these structures can be performed using O(((N)(k)) (.) N) operations. Furthermore we show that there exists a single Bayesian network that defines a joint distribution over the variables that is equivalent to model averaging over these structures. Although constructing this network is computationally prohibitive, we show that it can be approximated by a tractable network, allowing approximate model-averaged probability calculations to be performed in O( N) time. Our result also leads to an exact and linear-time solution to the problem of averaging over the 2(N) possible feature sets in a naive Bayes model, providing an exact Bayesian solution to the troublesome feature-selection problem for naive Bayes classifiers. We demonstrate the utility of these techniques in the context of supervised classification, showing empirically that model averaging consistently beats other generative Bayesian-network-based models, even when the generating model is not guaranteed to be a member of the class being averaged over. We characterize the performance over several parameters on simulated and real-world data.	Intel Res, Santa Clara, CA 95054 USA; Univ Pittsburgh, Ctr Biomed Informat, Pittsburgh, PA 15260 USA	Dash, D (reprint author), Intel Res, SC12-303,3600 Juliette Lane, Santa Clara, CA 95054 USA.	DENVER.H.DASH@INTEL.COM; GFC@CBMI.UPMC.EDU					Blake C. L., 1998, UCI REPOSITORY MACHI; Buntine W., 1991, P 7 C UNC ART INT, P52; CERQUIDES J, 2003, THESIS TU CATALONIA; Cerquides J., 2003, P 20 INT C MACH LEAR, P75; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; DASH D, 2003, P 9 INT WORKSH ART I; Dash D., 2002, P 19 INT C MACH LEAR, P91; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos P., 2000, P 17 INT C MACH LEAR, P223; Druzdzel M. J., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Duda R., 1973, PATTERN CLASSIFICATI; EGAN JP, 1975, SIGNAL DETECTION THE; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Langley P., 1994, P 10 C UNC ART INT, P399; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; MEILA M, 2000, UNCERTAINTY ARTIFICI, P380; Moore A, 1998, J ARTIF INTELL RES, V8, P67; Ng AY, 2002, ADV NEUR IN, V14, P841; Pearl J., 1988, PROBABILISTIC REASON; Spirtes P., 1993, CAUSATION PREDICTION; VERMA T, 1991, UNCERTAINTY ARTIFICI, V6, P255; VOLINSKY C, 1997, THESIS U WASHINGTON	28	20	20	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	SEP	2004	5						1177	1203				27	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GT	WOS:000236328100005	
S	Cantu-Paz, E		Deb, K; Poli, R; Banzhaf, W; Beyer, HG; Burke, E; Darwen, P; Dasgupta, D; Floreano, D; Foster, O; Harman, M; Holland, O; Lanzi, PL; Spector, L; Tettamanzi, A; Thierens, D; Tyrrell, A		Cantu-Paz, E			Feature subset selection, class separability, and genetic algorithms	GENETIC AND EVOLUTIONARY COMPUTATION - GECCO 2004, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Annual Genetic and Evolutionary Computation Conference (GECCO 2004)	JUN 26-30, 2004	Seattle, WA					The performance of classification algorithms in machine learning is affected by the features used to describe the labeled examples presented to the inducers. Therefore, the problem of feature subset selection has received considerable attention. Genetic approaches to this problem usually follow the wrapper approach: treat the inducer as a black box that is used to evaluate candidate feature subsets. The evaluations might take a considerable time and the traditional approach might be impractical for large data sets. This paper describes a hybrid of a simple genetic algorithm and a method based on class separability applied to the selection of feature subsets for classification problems. The proposed hybrid was compared against each of its components and two other feature selection wrappers that are used widely. The objective of this paper is to determine if the proposed hybrid presents advantages over the other methods in terms of accuracy or speed in this problem. The experiments used a Naive Bayes classifier and public-domain and artificial data sets. The experiments suggest that the hybrid usually finds compact feature subsets that give the most accurate results, while beating the execution time of the other wrappers.	Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94551 USA	Cantu-Paz, E (reprint author), Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, POB 5508, Livermore, CA 94551 USA.	cantupaz@llnl.gov					Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; Bala J, 1996, EVOL COMPUT, V4, P297, DOI 10.1162/evco.1996.4.3.297; Blake C. L., 1998, UCI REPOSITORY MACHI; BRILL, 2000, IPCTR90004 U VIRG I; BROTHERTON TW, 1995, EVOLUTIONARY PROGRAM, V4, P83; Cantu-Paz E., 2002, P GEN EV COMP C SAN, P303; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Harik G, 1999, EVOL COMPUT, V7, P231, DOI 10.1162/evco.1999.7.3.231; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; INZA I, 2001, ESTIMATION DISTRIBUT; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; John G., 1994, P 11 INT C MACH LEAR, P121; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Lanzi P., 1997, IEEE INT C EV COMP, P537; Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, DOI 10.1145/272991.272995; Miller BL, 1996, EVOL COMPUT, V4, P113, DOI 10.1162/evco.1996.4.2.113; Oh IS, 1999, IEEE T PATTERN ANAL, V21, P1089; OZDEMIR M, 2001, IEEE MOUNT WORKSH SO, P53; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; RAYMER ML, 1997, P 7 INT C GEN ALG IC, P561; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Vafaie H., 1993, Proceedings. Fifth International Conference on Tools with Artificial Intelligence TAI '93 (Cat. No.93CH3325-8), DOI 10.1109/TAI.1993.633981	26	20	20	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22344-4	LECT NOTES COMPUT SC			2004	3102		1				959	970				12	Computer Science, Theory & Methods	Computer Science	BBE15	WOS:000225101200096	
J	Lertnattee, V; Theeramunkong, T				Lertnattee, V; Theeramunkong, T			Effect of term distributions on centroid-based text categorization	INFORMATION SCIENCES			English	Article						centroid-based classifier; text categorization; term distribution	RETRIEVAL; CLASSIFICATION	Most of traditional text categorization approaches utilize term frequency (tf) and inverse document frequency (idf) for representing importance of words and/or terms in classifying a text document. This paper describes an approach to apply term distributions, in addition to tf and idf, to improve performance of centroid-based text categorization. Three types of term distributions, called inter-class, intra-class and in-collection distributions, are introduced. These distributions are useful to increase classification accuracy by exploiting information of (1) term distribution among classes, (2) term distribution within a class and (3) term distribution in the whole collection of training data. In addition, this paper investigates how these term distributions contribute to weight each term in documents, e.g., a high term distribution of a word promotes or demotes importance or classification power of that word. To this end, several centroid-based classifiers are constructed with different term weightings. Using various data sets, their performances are investigated and compared to a standard centroid-based classifier (TDIDF) and a centroid-based classifier modified with information gain. Moreover, we also compare them to two well-known methods: k-NN and naive Bayes. In addition to a unigram model of document representation, a bigram model is also explored. Finally, the effectiveness of term distributions to improve classification accuracy is explored with regard to the training set size and the number of classes. (C) 2003 Elsevier Inc. All rights reserved.	Sirindhorn Int Inst Technol, Informat Technol Program, Muang 12000, Pathumthani, Thailand	Theeramunkong, T (reprint author), Sirindhorn Int Inst Technol, Informat Technol Program, Bangkadi Campus,131 Moo 5 Tiwanont Rd, Muang 12000, Pathumthani, Thailand.		Theeramunkong, Thanaruk/A-3459-2009				APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; Chuang WT, 2000, LECT NOTES COMPUT SC, V1874, P409; COHEN WW, 1995, ADV INDUCTIVE LOGIC, P124; Craven M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; DEBOLE F, P SAC 03 18 ACM S AP; DENG ZH, 2002, P ICADL 02 5 INT C A, P88; FUHR N, 1989, INFORM PROCESS MANAG, V25, P55, DOI 10.1016/0306-4573(89)90091-5; Han E H, 2001, P 5 PAC AS C KNOWL D, p53 ; Han E.-H., 2000, PRINCIPLES DATA MINI, P424; Hull D. A., 1994, P 17 ACM SIGIR C, P282; Ittner DJ, 1995, P SDAIR 95 4 ANN S D, P301; Joachims T., 1997, P 14 INT C MACH LEAR, P143; Joachims T., 1998, LNCS, V1398, P137; Larkey L. S., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290965; Lee K.-H., 2002, LECT NOTES COMPUTER, V2417, P414; Lertnattee V, 2001, P INTECH 01 2 INT C, P349; McCallum A., 1998, P 15 INT C MACH LEAR, P359; Ng HT, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P67, DOI 10.1145/258525.258537; Nigam K., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Salton Gerard, 1989, AUTOMATIC TEXT PROCE; Schapire R. E., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290996; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SINGHAL A, 1995, TR951507; SINGHAL A, 1996, RES DEV INFORM RETRI, P21; Siolas G., 2000, Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium, DOI 10.1109/IJCNN.2000.861458; Skalak D. B., 1994, INT C MACH LEARN, P293; SORENSEN H, 1995, P CIKM 95 INT INF AG; THEERAMUNKONG T, 2001, P ISCIT 01 2 INT S C, P1167; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; Yang Y, 1999, J INFORMATION RETRIE, V1, P69	35	20	28	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	JAN	2004	158						89	115		10.1016/j.ins.2003.07.007		27	Computer Science, Information Systems	Computer Science	758JC	WOS:000187629900005	
J	Hilario, M; Kalousis, A; Muller, M; Pellegrini, C				Hilario, M; Kalousis, A; Muller, M; Pellegrini, C			Machine learning approaches to lung cancer prediction from mass spectra	PROTEOMICS			English	Article; Proceedings Paper	1st Annual Proteomics Data Mining Conference	SEP   23, 2002	DURHAM, NORTH CAROLINA		DUKE UNIV MED CTR	classification; diagnosis; lung cancer; mass spectra; variable selection		We addressed the problem of discriminating between 24 diseased and 17 healthy specimens on the basis of protein mass spectra. To prepare the data, we performed mass to charge ratio m/z) normalization, baseline elimination, and conversion of absolute peak height measures to height ratios. After preprocessing, the major difficulty encountered was the extremely large number of variables (1676 m/z values) versus the number of examples (41). Dimensionality reduction was treated as an integral part of the classification process; variable selection was coupled with model construction in a single ten-fold cross-validation loop. We explored different experimental setups involving two peak height representations, two variable selection methods, and six induction algorithms, all on both the original 1676-mass data set and on a prescreened 124-mass data set. Highest predictive accuracies (1-2 off-sample misclassifications) were achieved by a multilayer perceptron and Naive Bayes, with the latter displaying more consistent performance (hence greater reliability) over varying experimental conditions. We attempted to identify the most discriminant peaks (proteins) on the basis of scores assigned by the two variable selection methods and by neural network based sensitivity analysis. These three scoring schemes consistently ranked four peaks as the most relevant discriminators.	Univ Geneva, CUI, Dept Comp Sci, CH-1211 Geneva, Switzerland; Swiss Inst Bioinformat, Geneva, Switzerland	Hilario, M (reprint author), Univ Geneva, CUI, Dept Comp Sci, 24 Rue Gen Dufour, CH-1211 Geneva, Switzerland.						Cohen W., 1995, P 12 INT C MACH LEAR, P115; Cover T. M., 1991, ELEMENTS INFORMATION; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; GAMA J, 1999, INTELLIGENT DATA ANA, V2, P1; Kononenko I., 1994, EUR C MACH LEARN, P171; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; WOLPERT D, 1996, NEURAL COMPUT, V8, P1381	7	20	22	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1615-9853			PROTEOMICS	Proteomics	SEP	2003	3	9					1716	1719		10.1002/pmic.200300523		4	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	722YB	WOS:000185404700012	
J	Sun, A; Lim, EP; Ng, WK				Sun, A; Lim, EP; Ng, WK			Performance measurement framework for hierarchical text classification	JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article								Hierarchical text classification or simply hierarchical classification refers to as signing a document to one or more suitable categories from a hierarchical category space. In our literature survey, we have found that the existing hierarchical classification experiments used a variety of measures to evaluate performance. These performance measures often assume independence between categories and do not consider documents misclassified into categories that are similar or not far from the correct categories in the category tree. In this paper, we therefore propose new performance measures for hierarchical classification. The proposed performance measures consist of categoty similarity measures and distance-based measures that consider the contributions of misclassified documents. Our experiments on hierarchical classification methods based on SVM classifiers and binary Naive Bayes classifiers showed that SVM classifiers perform better than Naive Bayes classifiers on Reuters-21578 collection according to the extended measures. A new classifier-centric measure called blocking measure is also defined to examine the performance of subtree classifiers in a top-down level-based hierarchical classification method.	Nanyang Technol Univ, Sch Comp Engn, Ctr Adv Informat Syst, Singapore 639798, Singapore	Sun, A (reprint author), Nanyang Technol Univ, Sch Comp Engn, Ctr Adv Informat Syst, Nanyang Ave, Singapore 639798, Singapore.		Sun, Aixin/A-9852-2008; LIM, Ee Peng/E-8562-2012	Sun, Aixin/0000-0003-0764-4258; LIM, Ee Peng/0000-0003-0065-8665			Chakrabarti S., 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; Cohen W., 1995, P 12 INT C MACH LEAR, P115; D'Alessio S., 2000, P 6 INT C RECH INF A, P302; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Dumais Susan, 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593; GAUSSIER E, 2002, P 24 EUR C INF RETR, P229; GREINER R, 1997, LEARNING HIERARCHICA; JOACHIMS T, 1998, SVMLIGHT IMPLEMENTAT, P137; Labrou Y, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P180, DOI 10.1145/319950.319976; Larkey L., 1996, P SIGIR 96 19 ACM IN, P289, DOI 10.1145/243199.243276; Lewis David D., 1995, P 18 ANN INT ACM SIG, P246, DOI 10.1145/215206.215366; LEWIS K, 1992, CAREER DEV EXCEPTION, V15, P37; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; McCallum A., 1998, P 15 INT C MACH LEAR, P359; McCallum A. K., 1996, BOW TOOLKIT STAT LAN; MITCHELL TM, 1997, MACH LEARN, P155; MLADENIC D, 1998, P 13 EUR C ART INT E, P473; RIJSBERGEN CJV, 1979, INFORMATION RETRIEVA, P174; Robertson S., 2000, P 9 TEXT RETR C, P25; Sahami M., 1997, P 14 INT C MACH LEAR, P170; SASAKI M, 1998, P IEEE INT C SYST MA, P2827; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Toutanova K., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management; Vinokourov A, 2002, J INTELL INF SYST, V18, P153, DOI 10.1023/A:1013677411002; Wang K, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P363; Wang k, 2001, P 1 SIAM INT C DAT M; Weigend A. S., 1999, Information Retrieval, V1, DOI 10.1023/A:1009983522080; Yang Y, 1999, J INFORMATION RETRIE, V1, P69	28	20	24	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1532-2882			J AM SOC INF SCI TEC	J. Am. Soc. Inf. Sci. Technol.	SEP	2003	54	11					1014	1028		10.1002/asi.10298		15	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	712DA	WOS:000184780500004	
J	Yang, L; Agarwal, P				Yang, Lun; Agarwal, Pankaj			Systematic Drug Repositioning Based on Clinical Side-Effects	PLOS ONE			English	Article							BLOOD-PRESSURE; THERAPY; DISEASE; GLUCOSE; STROKE; MECHANISMS; DISCOVERY; TRIAL; RAT	Drug repositioning helps fully explore indications for marketed drugs and clinical candidates. Here we show that the clinical side-effects (SEs) provide a human phenotypic profile for the drug, and this profile can suggest additional disease indications. We extracted 3,175 SE-disease relationships by combining the SE-drug relationships from drug labels and the drug-disease relationships from PharmGKB. Many relationships provide explicit repositioning hypotheses, such as drugs causing hypoglycemia are potential candidates for diabetes. We built Naive Bayes models to predict indications for 145 diseases using the SEs as features. The AUC was above 0.8 in 92% of these models. The method was extended to predict indications for clinical compounds, 36% of the models achieved AUC above 0.7. This suggests that closer attention should be paid to the SEs observed in trials not just to evaluate the harmful effects, but also to rationally explore the repositioning potential based on this "clinical phenotypic assay''.	[Yang, Lun; Agarwal, Pankaj] GlaxoSmithKline Inc, Computat Biol, Quantitat Sci, Med Discovery & Dev, Philadelphia, PA USA	Yang, L (reprint author), GlaxoSmithKline Inc, Computat Biol, Quantitat Sci, Med Discovery & Dev, Philadelphia, PA USA.	Lun.Yang@gmail.com	Yang, Lun/B-4859-2012				Abolfazli R, 2011, DEPRESS ANXIETY, V28, P297, DOI 10.1002/da.20801; Albayram S, 2002, AM J NEURORADIOL, V23, P618; Altman RB, 2007, NAT GENET, V39, P426, DOI 10.1038/ng0407-426; Andersson C, 1999, J INTERN MED, V245, P193, DOI 10.1046/j.1365-2796.1999.0448e.x; Ashburn TT, 2004, NAT REV DRUG DISCOV, V3, P673, DOI 10.1038/nrd1468; Blazer-Yost BL, 2010, PPAR RES, DOI 10.1155/2010/785369; Bosch J, 2002, BRIT MED J, V324, P699, DOI 10.1136/bmj.324.7339.699; Buchan NS, 2011, DRUG DISCOV TODAY, V16, P426, DOI 10.1016/j.drudis.2011.03.002; Burnett AL, 2006, UROLOGY, V67, P1043, DOI 10.1016/j.urology.2005.11.045; Burns P, 2003, BRIT MED J, V326, P584, DOI 10.1136/bmj.326.7389.584; Campillos M, 2008, SCIENCE, V321, P263, DOI 10.1126/science.1158140; Capers Q, 1997, CIRC RES, V80, P838; Chiang AP, 2009, CLIN PHARMACOL THER, V86, P507, DOI 10.1038/clpt.2009.103; Chiba S, 2010, PSYCHOPHARMACOLOGY, V211, P291, DOI 10.1007/s00213-010-1894-8; Dechanet J, 1999, J INFECT DIS, V179, P1, DOI 10.1086/314568; DOCHERTY JR, 1988, N-S ARCH PHARMACOL, V337, P1; Ekins Sean, 2005, Expert Opin Drug Metab Toxicol, V1, P303, DOI 10.1517/17425255.1.2.303; FELEKE E, 1983, ACTA MED SCAND, V213, P381; Fernandez HH, 2003, NEUROLOGIST, V9, P16, DOI 10.1097/01.nrl.0000038585.58012.97; Gottlieb A, 2011, MOL SYST BIOL, V7, DOI 10.1038/msb.2011.26; Gross U, 2000, J INHERIT METAB DIS, V23, P641, DOI 10.1023/A:1005645624262; Hall M, 2009, SIGKDD EXPL; Hu GH, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006536; Ibarra-Lara L, 2010, EUR J PHARMACOL, V627, P185, DOI 10.1016/j.ejphar.2009.10.039; Iorio F, 2010, P NATL ACAD SCI USA, V107, P14621, DOI 10.1073/pnas.1000138107; Keiser MJ, 2009, NATURE, V462, P175, DOI 10.1038/nature08506; Kendig EL, 2008, BIOCHEM PHARMACOL, V76, P216, DOI 10.1016/j.bcp.2008.05.001; Kernohan AFB, 2007, CLIN ENDOCRINOL, V66, P27, DOI 10.1111/j.1365-2265.2006.02679.x; Landriscina M, 2009, PROSTATE, V69, P744, DOI 10.1002/pros.20923; Luo H, 2011, NUCL ACIDS RES; Mallat Z, 2009, CIRC RES, V105, P827, DOI 10.1161/CIRCRESAHA.109.208595; Nemets B, 2005, J CLIN PSYCHIAT, V66, P586; Nidhi, 2006, J CHEM INF MODEL, V46, P1124, DOI 10.1021/ci060003g; Nijland HMJ, 2006, CLIN INFECT DIS, V43, P848, DOI 10.1086/507543; Ong C S, 2000, Australas J Dermatol, V41, P242, DOI 10.1046/j.1440-0960.2000.00445.x; O'Regan C, 2008, AM J MED, V121, P24, DOI 10.1016/j.amjmed.2007.06.033; Pouliot Y, 2011, CLIN PHARMACOL THER, V90, P90, DOI 10.1038/clpt.2011.81; Quan MN, 2011, NEUROSCIENCE, V182, P88, DOI 10.1016/j.neuroscience.2011.03.026; Sardana D, 2011, BRIEF BIOINFORM; SCHWARTZ E, 1988, CLIN CARDIOL, V11, P53; Smoot ME, 2011, BIOINFORMATICS, V27, P431, DOI 10.1093/bioinformatics/btq675; STEVENSON JG, 1984, DRUG INTEL CLIN PHAR, V18, P113; Sun RCF, 2008, THESCIENTIFICWORLDJO, V8, P1063, DOI 10.1100/tsw.2008.126; Suthram S, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000662; Swinney DC, 2011, NAT REV DRUG DISCOV, V10, P507, DOI 10.1038/nrd3480; Tatonetti NP, 2011, CLIN PHARMACOL THER, V90, P133, DOI 10.1038/clpt.2011.83; Terasmaa A, 2011, J PHYSL BIOCH; van Dokkum RPE, 2002, J HYPERTENS, V20, P2351, DOI 10.1097/01.hjh.0000042895.83309.7c; Vogelgesang A, 2011, J NEUROIMMUNOL, V231, P105, DOI 10.1016/j.jneuroim.2010.09.023; Wallach I, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012063; Xie L, 2007, PLOS COMPUT BIOL, V3, P2324, DOI 10.1371/journal.pcbi.0030217; YALOURIS AG, 1987, BRIT MED J, V295, P1237; Yang L, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002016; Yang L, 2009, BIOINFORMATICS, V25, P2244, DOI 10.1093/bioinformatics/btp369; Yang L, 2009, NUCLEIC ACIDS RES, V37, pW406, DOI 10.1093/nar/gkp312; Yang L, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000441	56	19	20	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203			PLOS ONE	PLoS One	DEC 21	2011	6	12							e28025	10.1371/journal.pone.0028025		9	Multidisciplinary Sciences	Science & Technology - Other Topics	876NF	WOS:000299113600008	
J	Hall, M				Hall, Mark			A decision tree-based attribute weighting filter for naive Bayes	KNOWLEDGE-BASED SYSTEMS			English	Article; Proceedings Paper	26th SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence	DEC 11-13, 2006	Cambridge, ENGLAND	British Comp Soc, Specialist Grp Artificial Intelligence, European Co Ordinating Comm Artificial Intelligence		machine learning; Bayesian learning; attribute weighting	LEARNING ALGORITHMS; FEATURE-SELECTION; CLASSIFIER	The naive Bayes classifier continues to be a popular learning algorithm for data mining applications due to its simplicity and linear run-time. Many enhancements to the basic algorithm have been proposed to help mitigate its primary weakness - the assumption that attributes are independent given the class. All of them improve the performance of naive Bayes at the expense (to a greater or lesser degree) of execution time and/or simplicity of the final model. In this paper we present a simple filter method for setting attribute weights for use with naive Bayes. Experimental results show that naive Bayes with attribute weights rarely degrades the quality of the model compared to standard naive Bayes and, in many cases, improves it dramatically. The main advantages of this method compared to other approaches for improving naive Bayes is its run-time complexity and the fact that it maintains the simplicity of the final model. (c) 2006 Elsevier B.V. All rights reserved.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Hall, M (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.	mhall@cs.waikato.ac.nz					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Blake C. L., 1998, UCI REPOSITORY MACHI; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Cardinal BJ, 1997, ADAPT PHYS ACT Q, V14, P65; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; Domingos P, 1997, ARTIF INTELL REV, V11, P227; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; FERREIRA JTA, 2001, P 4 INT C ADV INT DA, P167; Hall MA, 2000, P 17 INT C MACH LEAR, P359; Howe N, 1997, LECT NOTES ARTIF INT, V1266, P455; John G., 1994, P 11 INT C MACH LEAR, P121; KIM S, 2003, P 6 INT WORKSH INF R, P33; Kira K., 1992, P 9 INT C MACH LEARN, P249; KOHAVI R, 1997, UNPUB 9 EUR C MACH L; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; KUBAT M, 1993, P 1993 EUR C MACH LE, P367; Langley P., 1994, P 10 C UNC ART INT, P399; Nadeau C., 1999, ADV NEURAL INFORMATI, P307; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Ratanamahatana C, 2003, APPL ARTIF INTELL, V17, P475, DOI 10.1080/08839510390219327; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Witten I.H., 2000, DATA MINING PRACTICA; Zhang H., 2004, P 4 IEEE INT C DAT M, P567; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	28	19	24	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	MAR	2007	20	2			SI		120	126		10.1016/j.knosys.2006.11.008		7	Computer Science, Artificial Intelligence	Computer Science	150ER	WOS:000245198900003	
J	Kotsiantis, S; Pierrakeas, C; Pintelas, P				Kotsiantis, S; Pierrakeas, C; Pintelas, P			Predicting students' performance in distance learning using machine learning techniques	APPLIED ARTIFICIAL INTELLIGENCE			English	Article								The ability to predict a student's performance could be useful in a great number of different ways associated with university-level distance learning. Students' key demographic characteristics and their marks on a few written assignments can constitute the training set for a supervised machine learning algorithm. The learning algorithm could then be able to predict the performance of new students, thus becoming a useful tool for identifying predicted poor performers. The scope of this work is to compare some of the state of the art learning algorithms. Two experiments have been conducted with six algorithms, which were trained using data sets provided by the Hellenic Open University. Among other significant conclusions, it was found that the Naive Bayes algorithm is the most appropriate to be used for the construction of a software support tool, has more than satisfactory accuracy, its overall sensitivity is extremely satisfactory, and is the easiest algorithm to implement.	Univ Patras, Dept Math, Educ Software Dev Lab, Patras 26500, Greece; Hellen Open Univ, Sch Sci & Technol, Patras, Greece	Kotsiantis, S (reprint author), Univ Patras, Dept Math, Educ Software Dev Lab, PA Box 1399, Patras 26500, Greece.	sotos@math.upatras.gr	kotsiantis, sotiris/C-5640-2009	kotsiantis, sotiris/0000-0002-2247-3082			Aha D.W., 1997, LAZY LEARNING; BAATH J, 1994, EPISTOLODIDAKTIKA, V1, P13; Burgess C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Gaga L, 1996, APPL ARTIF INTELL, V10, P79, DOI 10.1080/088395196118605; KOTSIANTIS S, 2002, TR0202 U PATR DEP MA, P28; KOTSIANTIS S, 2002, TR0203 U PATR DEP MA, P42; Long J., 1997, REGRESSION MODELS CA; Mitchell T.M., 1997, MACHINE LEARNING; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; NARASIMHARAO B, 1999, ISSUES PREPARING OPE; PLATT J, 1999, ADV NEURAL INFORMATI; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SCHAFFER C, 1994, P 11 INT C MACH LEAR, P153; Siegel S, 1988, NONPARAMETRIC STAT B; WETTSCHERECK D, 1997, ARTIF INTELL, V10, P1; WHITTINGTON LA, 1995, FACTORS IMPACTING SU; Witten I.H., 2000, DATA MINING PRACTICA; Xenos M, 2002, COMPUT EDUC, V39, P361, DOI 10.1016/S0360-1315(02)00072-6	20	19	19	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514			APPL ARTIF INTELL	Appl. Artif. Intell.	MAY-JUN	2004	18	5					411	426		10.1080/08839510490442058		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	819CT	WOS:000221291500002	
J	Maxion, RA; Townsend, TN				Maxion, RA; Townsend, TN			Masquerade detection augmented with error analysis	IEEE TRANSACTIONS ON RELIABILITY			English	Article						anomaly detection; classifiers; fraud detection; masquerade detection; Naive Bayes; user command data		A masquerade attack, in which one user impersonates another, may be one of the most serious forms of computer abuse. Automatic discovery of masqueraders is sometimes undertaken by detecting significant departures from normal user behavior, as represented by a user profile formed from system audit data. A major obstacle for this type of research is the difficulty in obtaining such system audit data, largely due to privacy concerns. An immense contribution in this regard has been made by Schonlau et al., who have made available UNIX command-line data from 50+ users collected over a number of months. Most of the research in this area has made use of this dataset, so this paper takes as its point of departure the Schonlau et al. dataset and a recent series of experiments with this data framed by the same researchers [1]. In extending that work with a new classification algorithm, a 56% improvement in masquerade detection was achieved at a corresponding false-alarm rate of 1.3%. In addition, encouraging results were obtained at a more realistic sequence length of 10 commands (as opposed to sequences of 100 commands used by Schonlau et al.). A detailed error analysis, based on an alternative configuration of the same data, reveals a serious flaw in this type of data which hinders masquerade detection and indicates some steps that need to be taken to improve future results. The error analysis also demonstrates the insights that can be gained by inspecting decision errors, instead of concentrating only on decision successes.	Carnegie Mellon Univ, Dept Comp Sci, Dependable Syst Lab, Pittsburgh, PA 15213 USA; Yale Univ, Sch Law, New Haven, CT 06520 USA	Maxion, RA (reprint author), Carnegie Mellon Univ, Dept Comp Sci, Dependable Syst Lab, Pittsburgh, PA 15213 USA.	maxion@cs.cmu.edu					Cestnik B., 1987, PROGR MACHINE LEARNI, P31; DAVISON BD, 1998, 1998 AAAI WORKSH 27; Domingos P, 1996, 13 INT C MACH LEARN, P105; Duda R.O., 2001, PATTERN CLASSIFICATI; DUMOUCHEL W, 1999, 91 NAT I STAT SCI, P32316; Ju W. H., 1999, 92 NAT I STAT SCI; Kotz S., 1985, ENCY STAT SCI, V5; Lane T., 1999, ACM T INFORM SYST, V2, P295, DOI 10.1145/322510.322526; Langley P., 1992, P 10 NAT C ART INT, P223; LOEB V, 2001, SPY CASE PROMPTS COM, P32316; Lunt T. F., 1993, Computers & Security, V12, DOI 10.1016/0167-4048(93)90029-5; Manning C.D., 2000, FDN STAT NATURAL LAN; McCallum A., 1998, 1998 AAAI WORKSH 27, P41; Mitchell T.M., 1997, MACHINE LEARNING; Schofield PE, 2001, PSYCHOL HEALTH, V16, P1, DOI 10.1080/08870440108405486; Schonlau M, 2000, INFORM PROCESS LETT, V76, P33, DOI 10.1016/S0020-0190(00)00122-8; SWETS JA, 1992, EVALUATION DIAGNOSTI	17	19	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9529			IEEE T RELIAB	IEEE Trans. Reliab.	MAR	2004	53	1					124	147		10.1109/TR.2004.824828		24	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	810MC	WOS:000220707400017	
S	Hess, A; Kushmerick, N		Fensel, D; Sycara, K; Mylopoulos, J		Hess, A; Kushmerick, N			Learning to attach semantic metadata to web services	SEMANTIC WEB - ISWC 2003	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Semantic Web Conference	OCT 20-23, 2003	SANIBEL, FLORIDA	ist, DAML, network inference, Springer Sci Online, DERI, Tontotext, Semantic Web Enabled Serv, AKT, Knowledge Management Solut, ENIGMATEC Corp, Elsevier, SWAP, ESPERONTO, Nokia, MONDECA, France Telecom R&D				Emerging Web standards promise a network of heterogeneous yet interoperable Web Services. Web Services would greatly simplify the development of many kinds of data integration and knowledge management applications. Unfortunately, this vision requires that services describe themselves with large amounts of semantic metadata "glue". We explore a variety of machine learning techniques to semiautomatically create such metadata. We make three contributions. First, we describe a Bayesian learning and inference algorithm for classifying HTML forms into semantic categories, as well as assigning semantic labels to the form's fields. These techniques are important as legacy HTML interfaces are migrated to Web Services. Second, we describe the application of the Naive Bayes and SVM algorithms to the task of Web Service classification. We show that an ensemble approach that treats Web Services as structured objects is more accurate than an unstructured approach. Finally, we describe a clustering algorithm that automatically discovers the semantic categories of Web Services. All of our algorithms are evaluated using large collections of real HTML forms and Web Services.	Univ Coll Dublin, Dept Comp Sci, Dublin 2, Ireland	Hess, A (reprint author), Univ Coll Dublin, Dept Comp Sci, Dublin 2, Ireland.	andreas.hess@ucd.ie; nick@ucd.ie					Blum A., 1998, COLT; Cardoso J, 2002, THESIS U GEORGIA ATH; CIRAVEGNA F, 2001, 17 INT JOINT C ART I; Cutting Douglass R., 1992, P 15 ANN INT ACM SIG, P318, DOI 10.1145/133160.133214; DOAN A, 2001, P SIGMOD C; KERSCHBERG L, 2002, INTELLIGENT WEB SEAR, P1345; Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9; MELNIK S, 2002, P INT C DAT ENG ICDE; Muslea I, 1999, P 3 INT C AUT AG, P190, DOI 10.1145/301136.301191; PAOLUCCI M, 2002, INT SEM WEB C; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; SALTON G, 1983, INTRO MODERN INFORMA; Strehl A, 2002, THESIS U TEXAS AUSTI; Van Rijsbergen C.J., 1979, INFORMATION RETRIEVA; Witten I.H., DATA MINING PRACTICA; Zamir O., 1997, KDD 97, P287	16	19	19	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20362-1	LECT NOTES COMPUT SC			2003	2870						258	273				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BY18Y	WOS:000188096900017	
J	Xia, R; Zong, CQ; Li, SS				Xia, Rui; Zong, Chengqing; Li, Shoushan			Ensemble of feature sets and classification algorithms for sentiment classification	INFORMATION SCIENCES			English	Article						Sentiment classification; Text classification; Ensemble learning; Classifier combination; Comparative study	COMBINING CLASSIFIERS; COMBINATIONS; INFORMATION	In this paper, we make a comparative study of the effectiveness of ensemble technique for sentiment classification. The ensemble framework is applied to sentiment classification tasks, with the aim of efficiently integrating different feature sets and classification algorithms to synthesize a more accurate classification procedure. First, two types of feature sets are designed for sentiment classification, namely the part-of-speech based feature sets and the word-relation based feature sets. Second, three well-known text classification algorithms, namely naive Bayes, maximum entropy and support vector machines, are employed as base-classifiers for each of the feature sets. Third, three types of ensemble methods, namely the fixed combination, weighted combination and meta-classifier combination, are evaluated for three ensemble strategies. A wide range of comparative experiments are conducted on five widely-used datasets in sentiment classification. Finally, some in-depth discussion is presented and conclusions are drawn about the effectiveness of ensemble technique for sentiment classification. (C) 2010 Elsevier Inc. All rights reserved.	[Xia, Rui; Zong, Chengqing] Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Li, Shoushan] Soochow Univ, Dept Comp Sci & Technol, Suzhou 215006, Peoples R China	Xia, R (reprint author), Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	rxia@nlpr.ia.ac.cn; cqzong@nlpr.ia.ac.cn; shoushan.li@gmail.com					Benamara F, 2007, P INT C WEBL SOC MED, P203; Blitzer J., 2007, P ASS COMP LING ACL; BRIDLE J, 1990, NEUROCOMPUTING ALGOR, V227, P236; Cui H, 2006, P 21 NAT C ART INT A; Dave K., 2003, P 12 INT C WORLD WID, P519, DOI DOI 10.1145/775152.775226; Dong YS, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING, PROCEEDINGS, P419; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Fujino A, 2007, INFORM PROCESS MANAG, V43, P379, DOI 10.1016/j.ipm.2006.07.013; Gamon M., 2004, P INT C COMP LING CO; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; Hatzivassiloglou V., 2000, P 18 INT C COMP LING, P299; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; JOACHIMS T, 1998, TEXT CATEGORIZATION, P137; Joshi Mahesh, 2009, P ACL IJCNLP 2009 C, P313, DOI 10.3115/1667583.1667680; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Kittler J, 1998, PATTERN ANAL APPL, V1, P18, DOI 10.1007/BF01238023; Larkey L., 1996, P SIGIR 96 19 ACM IN, P289, DOI 10.1145/243199.243276; Lewis D., 1998, LECT NOTES COMPUTER, V1398, P4, DOI DOI 10.1007/BFB0026666; Li SS, 2007, Proceedings of the 2007 IEEE International Conference on Natural Language Processing and Knowledge Engineering (NLP-KE'07), P135; Liu B, 2010, IEEE INTELL SYST, V25, P76; Liu CL, 2005, PATTERN RECOGN, V38, P11, DOI 10.1016/j.patcog.2004.05.013; Liu WY, 2010, INFORM SCIENCES, V180, P4031, DOI 10.1016/j.ins.2010.06.021; McCallum A., 1998, P AAAI WORKSH LEARN; McDonald Ryan, 2005, P HUM LANG TECHN C C, P523, DOI 10.3115/1220575.1220641; Ng A., 2002, ADV NEURAL INFORM PR, V2, P841; Nigam K., 1999, P IJCAI 99 WORKSH MA, P61; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Pang B., 2004, P 42 ANN M ASS COMP, P271, DOI DOI 10.3115/1218955.1218990; Pang Bo, 2008, FDN TRENDS INFORM RE, V2, P1, DOI DOI 10.1561/1500000011; Platt J.C., 1999, ADV LARGE MARGIN CLA; Raina R, 2004, ADV NEUR IN, V16, P545; Ratnaparkhi A., 1996, P C EMP METH NAT LAN, P133; Riloff E., 2006, P C EMP METH NAT LAN, P440, DOI 10.3115/1610075.1610137; Riloff E., 2003, P 7 C NAT LANG LEARN, P25; Subrahmanian VS, 2008, IEEE INTELL SYST, V23, P43, DOI 10.1109/MIS.2008.57; Sutton C., 2007, INTRO STAT RELATIONA; WHITEHEAD M, 2008, INT C SYST COMP SCI; Xia R., 2010, P 23 INT C COMP LING, P1336; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Zheng HT, 2009, INFORM SCIENCES, V179, P2249, DOI 10.1016/j.ins.2009.02.019	41	18	20	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	MAR 15	2011	181	6					1138	1152		10.1016/j.ins.2010.11.023		15	Computer Science, Information Systems	Computer Science	717RA	WOS:000287063900008	
J	Lim, LH; Comon, P				Lim, Lek-Heng; Comon, Pierre			Nonnegative approximations of nonnegative tensors	JOURNAL OF CHEMOMETRICS			English	Article						nonnegative tensors; nonnegative hypermatrices; nonnegative tensor decompositions; nonnegative tensor rank; low-rank tensor approximations; probabilistic latent semantic indexing; CANDECOMP; PARAFAC, tensor norm; tensor Bregman divergence	LEAST-SQUARES ALGORITHM; LOW-RANK APPROXIMATION; MATRIX FACTORIZATION; MODEL	We study the decomposition of a nonnegative tensor into a minimal sum of outer product of nonnegative vectors and the associated parsimonious naive Bayes probabilistic model. We show that the corresponding approximation problem, which is central to nonnegative PARAFAC, will always have optimal solutions. The result holds for any choice of norms and, under a mild assumption, even Bregman divergences. Copyright (C) 2009 John Wiley & Sons, Ltd.	[Lim, Lek-Heng] Univ Calif Berkeley, Dept Math, Berkeley, CA 94720 USA; [Comon, Pierre] Univ Nice, Nice, France	Lim, LH (reprint author), Univ Calif Berkeley, Dept Math, Berkeley, CA 94720 USA.	lekheng@math.berkeley.edu			 [ANR-06-BLAN-0074]	We thank the reviewers for their many helpful comments. This work has been partially supported by contract ANR-06-BLAN-0074 'Decotes'.	BINI D, 1980, SIAM J COMPUT, V9, P692, DOI 10.1137/0209053; BINI D, 1979, INFORM PROCESS LETT, V8, P234, DOI 10.1016/0020-0190(79)90113-3; Bregman L. M., 1967, USSR COMP MATH MATH, V7, P620; Brinkhuis J, 2005, PRINC SER APPL MATH, P1; Bro R, 1998, J CHEMOMETR, V12, P223, DOI 10.1002/(SICI)1099-128X(199807/08)12:4<223::AID-CEM511>3.3.CO;2-U; Bro R, 1997, J CHEMOMETR, V11, P393, DOI 10.1002/(SICI)1099-128X(199709/10)11:5<393::AID-CEM483>3.0.CO;2-L; BURGISSER P, 1996, ALGEBRAIC COMPLEXITY, V315; CARROLL JD, FITTING LATENT CLASS, P463; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Comon P, 2008, SIAM J MATRIX ANAL A, V30, P1254, DOI 10.1137/060661569; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COPPI R., 1989, MULTIWAY DATA ANAL; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; de Silva V, 2008, SIAM J MATRIX ANAL A, V30, P1084, DOI 10.1137/06066518X; Dhillon IS, 2007, SIAM J MATRIX ANAL A, V29, P1120, DOI 10.1137/060649021; Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367; Garcia LD, 2005, J SYMB COMPUT, V39, P331, DOI 10.1016/j.jsc.2004.11.007; GAUSSIER E, 2005, P ANN INT SIGIR C RE, V28, P601; Gelfand I. M., 1994, DISCRIMINANTS RESULT; Harshman R.A., 1970, UCLA WORKING PAPERS, V16, P1; Harshman R.A., 1984, RES METHODS MULTIMOD, P216; Hitchcock F. L., 1927, J MATH PHYS, V6, P164; Hitchcock F. L., 1927, J MATH PHYS, V7, P39; HOFMANN T, 1999, P ANN INT SIGIR C RE, V22, P50; IUSEM AN, 1997, ENCY MATH, P152; Knuth D.E., 1998, ART COMPUTER PROGRAM, V2; KRIJNEN WP, 1991, KWANTITATIEVE METHOD, V12, P87; KRUSKAL JB, 2008, 3 MFA DATA CAN CAUSE, P115; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lee DD, 1999, NATURE, V401, P788; LIM LH, 2005, WORKSH TENS DEC APPL; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Paatero P, 2000, J CHEMOMETR, V14, P285, DOI 10.1002/1099-128X(200005/06)14:3<285::AID-CEM584>3.3.CO;2-T; Paatero P, 1997, CHEMOMETR INTELL LAB, V38, P223, DOI 10.1016/S0169-7439(97)00031-2; SHASHUA A, 2005, P INT C MACH LEARN I, V22, P792; Stegeman A, 2008, SIAM J MATRIX ANAL A, V30, P988, DOI 10.1137/050644677; STRASSEN V, 1969, NUMER MATH, V13, P354, DOI 10.1007/BF02165411	37	18	19	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0886-9383	1099-128X		J CHEMOMETR	J. Chemometr.	JUL-AUG	2009	23	7-8			SI		432	441		10.1002/cem.1244		10	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	488QQ	WOS:000269365200013	
J	Sinha, AR; Zhao, HM				Sinha, Atish R.; Zhao, Huimin			Incorporating domain knowledge into data mining classifiers: An application in indirect lending	DECISION SUPPORT SYSTEMS			English	Article						Data mining; Classification; Supervised learning; Domain knowledge; Expert system	SUPPORT VECTOR MACHINES; LEARNING ALGORITHMS; DECISION TREES; CLASSIFICATION; PREDICTION; DISCOVERY	Data mining techniques have been applied to solve classification problems for a variety of applications such as credit scoring, bankruptcy prediction, insurance underwriting, and management fraud detection. In many of those application domains, there exist human experts whose knowledge Could have a bearing on the effectiveness of the classification decision. The lack of research in combining data mining techniques with domain knowledge has prompted researchers to identify the fusion of data mining and knowledge-based expert systems as an important future direction. In this paper, we compare the performance of seven data mining classification methods-naive Bayes, logistic regression, decision tree, decision table, neural network, k-nearest neighbor, and support vector machine-with and without incorporating domain knowledge. The application we focus on is in the domain of indirect bank lending. An expert system capturing a lending expert's knowledge of rating a borrower's credit is used in combination with data mining to study if the incorporation of domain knowledge improves classification performance. We use two performance measures: misclassification cost and AUC (area under the curve). A 2 x 7 factorial, repeated-measures ANOVA, with the two factors being domain knowledge (present or absent) and data mining method (seven methods), as well as a special statistical test for comparing AUCs, is used for analyzing the results. Analysis of the results reveals that incorporation of domain knowledge significantly improves classification performance with respect to both misclassification cost and AUC. There is interaction between classification method and domain knowledge. Incorporation of domain knowledge has a higher influence on performance for some methods than for others. Both measures-misclassification cost and AUC-yield similar results, indicating that the findings of the study are robust. (c) 2008 Elsevier B.V. All rights reserved.	[Sinha, Atish R.; Zhao, Huimin] Univ Wisconsin, Sheldon B Lubar Sch Business, Milwaukee, WI 53201 USA	Zhao, HM (reprint author), Univ Wisconsin, Sheldon B Lubar Sch Business, POB 742, Milwaukee, WI 53201 USA.	sinha@uwm.edu; hzhao@uwm.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ambrosino R, 1999, Proc AMIA Symp, P192; Barakat NH, 2007, IEEE T KNOWL DATA EN, V19, P729, DOI [10.1109/TKDE.2007.1023., 10.1109/TKDE.2007.1023]; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Buchanan B.G., 1984, RULE BASED EXPERT SY; Chauvin Y., 1995, BACKPROPAGATION THEO; CHUNG HM, 1993, INTELLIGENT SYSTEMS, V2, P3; DANIELS H, 2002, P 8 INT C SOC COMP E; Doumpos M, 2002, EUR J OPER RES, V138, P392, DOI 10.1016/S0377-2217(01)00254-5; Dybowski R., 2003, J MACHINE LEARNING R, P293, DOI 10.1162/jmlr.2003.4.3.293; Elkan C., 2001, P 17 INT JOINT C ART, P973; Fan W, 2006, DECIS SUPPORT SYST, V42, P362, DOI 10.1016/j.dss.2005.01.007; Fan WG, 2006, DECIS SUPPORT SYST, V42, P1338, DOI 10.1016/j.dss.2005.11.002; Fawcett T., 2003, HPL20034 INT ENT TEC; Fayyad U, 1996, AI MAG, V17, P37; Hand DJ, 2001, PRINCIPLES DATA MINI; HANLEY JA, 1983, RADIOLOGY, V148, P839; Hayes-Roth F, 1983, BUILDING EXPERT SYST; HIRSH H, 1994, IEEE EXPERT, V10, P3; HOFFMAN RR, 1987, AI MAG, V8, P53; Hosmer Jr DW, 2000, APPL LOGISTIC REGRES; Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299; Huang Z, 2004, DECIS SUPPORT SYST, V37, P543, DOI 10.1016/S0167-9236(03)00086-1; JOHN GH, 1995, P 11 C UNC ART INT, P338; JOHNSON PE, 1983, J MED PHILOS, V8, P77; KEERTHI SS, 1999, CD9914 NAT U SING DE; Kim C. N., 1999, J MANAGEMENT INFORMA, V16, P189; Kohavi R, 1995, P EUR C MACH LEARN; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kopanas I, 2002, LECT NOTES ARTIF INT, V2308, P288; Lam M, 2004, DECIS SUPPORT SYST, V37, P567, DOI 10.1016/S0167-9236(03)00088-5; LANGSETH H, 2003, J MACHINE LEARNING R, V4, P339, DOI 10.1162/jmlr.2003.4.3.339; Lee G., 1999, J MANAGE INFORM SYST, P63; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; PAZZANI M, 1992, MACH LEARN, V9, P57, DOI 10.1007/BF00993254; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Platt J., 1998, ADV KERNEL METHODS S, P185; POHLE C, 2003, P VLDB 2003 PHD WORK; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1998, P 15 INT C MACH LEAR, P445; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; Rumelhart D., 1986, PARALLEL DISTRIBUTED, V1, P318; Russell S., 1995, ARTIFICIAL INTELLIGE; Ryu YU, 2005, IEEE T SYST MAN CY A, V35, P727, DOI 10.1109/TSMCA.2005.843393; Siegel S., 1956, NONPARAMETRIC STAT B; SINHA AP, 2005, J MANAGEMENT INFORM, V21, P253; Waterman D., 1986, GUIDE EXPERT SYSTEMS; Weiss GM, 2001, MLTR44 RUTG U DEP CO; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Weiss S. M., 2003, P 9 ACM SIGKDD INT C, P456; WEISS S.M., 1998, PREDICTIVE DATA MINI; Witten IH, 2005, DATA MINING PRACTICA; Zhao H, 2005, IEEE T SYST MAN CY A, V35, P754, DOI 10.1109/TSMCA.2005.843392; Zhao HM, 2004, IEEE T KNOWL DATA EN, V16, P727, DOI 10.1109/TKDE.2004.3; Zhu D, 2001, DECISION SCI, V32, P635, DOI 10.1111/j.1540-5915.2001.tb00975.x	56	18	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236			DECIS SUPPORT SYST	Decis. Support Syst.	DEC	2008	46	1					287	299		10.1016/j.dss.2008.06.013		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	412EH	WOS:000263706000023	
J	Sanchez, IE; Beltrao, P; Stricher, F; Schymkowitz, J; Ferkinghoff-Borg, J; Rousseau, F; Serrano, L				Sanchez, Ignacio E.; Beltrao, Pedro; Stricher, Francois; Schymkowitz, Joost; Ferkinghoff-Borg, Jesper; Rousseau, Frederic; Serrano, Luis			Genome-wide prediction of SH2 domain targets using structural information and the FoldX algorithm	PLOS COMPUTATIONAL BIOLOGY			English	Article							PROTEIN-INTERACTION NETWORK; GROWTH-FACTOR RECEPTOR; PHOSPHOPEPTIDE-BINDING; MOLECULAR-BASIS; TYROSYL-PHOSPHOPEPTIDE; SIGNAL-TRANSDUCTION; FORCE-FIELD; SRC KINASE; VHS DOMAIN; RECOGNITION	Current experiments likely cover only a fraction of all protein-protein interactions. Here, we developed a method to predict SH2-mediated protein-protein interactions using the structure of SH2-phosphopeptide complexes and the FoldX algorithm. We show that our approach performs similarly to experimentally derived consensus sequences and substitution matrices at predicting known in vitro and in vivo targets of SH2 domains. We use our method to provide a set of high-confidence interactions for human SH2 domains with known structure filtered on secondary structure and phosphorylation state. We validated the predictions using literature-derived SH2 interactions and a probabilistic score obtained from a naive Bayes integration of information on coexpression, conservation of the interaction in other species, shared interaction partners, and functions. We show how our predictions lead to a new hypothesis for the role of SH2 domains in signaling.	[Sanchez, Ignacio E.; Beltrao, Pedro; Stricher, Francois; Serrano, Luis] European Mol Biol Lab, Heidelberg, Germany; [Stricher, Francois; Serrano, Luis] CRG Ctr Regulac Genom, EMBL CRG Syst Bio Unit, Barcelona, Spain; [Schymkowitz, Joost; Rousseau, Frederic] Vrije Univ Brussel VIB, SWITCH Lab, B-1050 Brussels, Belgium; [Ferkinghoff-Borg, Jesper] NORDITA, DK-2100 Copenhagen, Denmark	Serrano, L (reprint author), European Mol Biol Lab, Heidelberg, Germany.	serrano@embl.de	Beltrao, Pedro/B-3342-2010				ABAGYAN R, 1994, J MOL BIOL, V235, P983, DOI 10.1006/jmbi.1994.1052; Arnold R, 2005, MOL CELL BIOL, V25, P2364, DOI 10.1128/MCB.25.6.2364-2383.2005; Beltrao P, 2005, PLOS COMPUT BIOL, V1, P202, DOI 10.1371/journal.pcbi.0010026; Bradshaw JM, 1999, J MOL BIOL, V293, P971, DOI 10.1006/jmbi.1999.3190; Bradshaw JM, 2003, ADV PROTEIN CHEM, V61, P161; Bradshaw JM, 1998, BIOCHEMISTRY-US, V37, P15400, DOI 10.1021/bi9814991; Browaeys-Poly E, 2000, EUR J BIOCHEM, V267, P6256, DOI 10.1046/j.1432-1327.2000.01710.x; CANTLEY LC, 1994, J CELL SCI, P121; Castagnoli L, 2004, FEBS LETT, V567, P74, DOI 10.1016/j.febslet.2004.03.116; Cho SW, 2004, EMBO J, V23, P1441, DOI 10.1038/sj.emboj.7600168; Clements A, 2003, MOL CELL, V12, P461, DOI 10.1016/S1097-2765(03)00288-0; Diella F, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-79; Elia AEH, 2003, CELL, V115, P83, DOI 10.1016/S0092-8674(03)00725-6; Gram H, 1997, EUR J BIOCHEM, V246, P633, DOI 10.1111/j.1432-1033.1997.00633.x; Gu CP, 2006, P NATL ACAD SCI USA, V103, P14447, DOI 10.1073/pnas.0606624103; Guerois R, 2002, J MOL BIOL, V320, P369, DOI 10.1016/S0022-2836(02)00442-4; Hama J, 2002, J BIOL CHEM, V277, P19806, DOI 10.1074/jbc.M110637200; He XY, 2003, BIOCHEMISTRY-US, V42, P12174, DOI 10.1021/bi035199h; Henriques DA, 2000, PROTEIN SCI, V9, P1975; Hu YF, 2004, J BIOL CHEM, V279, P29325, DOI 10.1074/jbc.M311144200; Hwang PM, 2002, EMBO J, V21, P314, DOI 10.1093/emboj/21.3.314; Iakoucheva LM, 2004, NUCLEIC ACIDS RES, V32, P1037, DOI 10.1093/nar/gkh253; Jones RB, 2006, NATURE, V439, P168, DOI 10.1038/nature04177; Joughin BA, 2005, PROTEIN SCI, V14, P131, DOI 10.1110/ps.04964705; Kato Y, 2002, NAT STRUCT BIOL, V9, P532, DOI 10.1038/nsb807; Keilhack H, 2005, J BIOL CHEM, V280, P30984, DOI 10.1074/jbc.M504699200; Kiel C, 2007, J MOL BIOL, V370, P1020, DOI 10.1016/j.jmb.2007.05.015; Kiel C, 2005, J MOL BIOL, V348, P759, DOI 10.1016/j.jmb.2005.02.046; Kimber MS, 2000, MOL CELL, V5, P1043, DOI 10.1016/S1097-2765(00)80269-5; Kolsch V, 2007, SCIENCE, V315, P384, DOI 10.1126/science.1134833; Lee JK, 2003, BIOCHEM BIOPH RES CO, V306, P225, DOI 10.1016/S0006-291X(03)00932-X; LEMMON MA, 1994, BIOCHEMISTRY-US, V33, P5070, DOI 10.1021/bi00183a010; Lubman OY, 2003, J MOL BIOL, V328, P655, DOI 10.1016/S0022-2836(03)00344-9; MARENGERE LEM, 1994, NATURE, V369, P502, DOI 10.1038/369502a0; McLaughlin WA, 2006, J MOL BIOL, V357, P1322, DOI 10.1016/j.jmb.2006.01.005; MILARSKI KL, 1993, J BIOL CHEM, V268, P23634; Morra M, 2001, EMBO J, V20, P5840, DOI 10.1093/emboj/20.21.5840; Nadassy K, 2001, NUCLEIC ACIDS RES, V29, P3362, DOI 10.1093/nar/29.16.3362; Nash P, 2001, NATURE, V414, P514, DOI 10.1038/35107009; O'Brien KP, 2005, NUCLEIC ACIDS RES, V33, pD476, DOI 10.1093/nar/gki107; Obenauer JC, 2003, NUCLEIC ACIDS RES, V31, P3635, DOI 10.1093/nar/gkg584; Olsen JV, 2006, CELL, V127, P635, DOI 10.1016/j.cell.2006.09.026; Pawson T, 2004, CELL, V116, P191, DOI 10.1016/S0092-8674(03)01077-8; PAYNE G, 1993, P NATL ACAD SCI USA, V90, P4902, DOI 10.1073/pnas.90.11.4902; Peri S, 2003, GENOME RES, V13, P2363, DOI 10.1101/gr.1680803; Poy F, 1999, MOL CELL, V4, P555, DOI 10.1016/S1097-2765(00)80206-3; Rhodes DR, 2005, NAT BIOTECHNOL, V23, P951, DOI 10.1038/nbt1103; Rittinger K, 1999, MOL CELL, V4, P153, DOI 10.1016/S1097-2765(00)80363-9; Salmeen A, 2000, MOL CELL, V6, P1401, DOI 10.1016/S1097-2765(00)00137-4; Schymkowitz J, 2005, NUCLEIC ACIDS RES, V33, pW382, DOI 10.1093/nar/gki387; Schymkowitz JWH, 2005, P NATL ACAD SCI USA, V102, P10147, DOI 10.1073/pnas.0501980102; Seet BT, 2006, NAT REV MOL CELL BIO, V7, P473, DOI 10.1038/nrm1960; Shi N, 2004, J BIOL CHEM, V279, P4962, DOI 10.1074/jbc.M311030200; Songyang Zhou, 1995, Trends in Biochemical Sciences, V20, P470, DOI 10.1016/S0968-0004(00)89103-3; Songyang Z, 1993, Cell, V72, P767; Suenaga A, 2003, BIOCHEMISTRY-US, V42, P5195, DOI 10.1021/bi034113h; Suetsugu S, 2002, DEV CELL, V3, P645, DOI 10.1016/S1534-5807(02)00324-6; Tzeng SR, 2000, PROTEIN SCI, V9, P2377; Van der Sloot AM, 2006, P NATL ACAD SCI USA, V103, P8634, DOI 10.1073/pnas.0510187103; Verdecia MA, 2000, NAT STRUCT BIOL, V7, P639, DOI 10.1038/77929; Verderame MF, 1997, MOL BIOL CELL, V8, P843; Verkhivker GM, 2001, PROTEINS, V45, P456, DOI 10.1002/prot.10019; VOGEL HJ, 1989, METHOD ENZYMOL, V177, P263; Warren D, 2000, J VIROL, V74, P4495, DOI 10.1128/JVI.74.10.4495-4504.2000; Wiederkehr-Adam M, 2003, J BIOL CHEM, V278, P16117, DOI 10.1074/jbc.M300261200; Yu XC, 2003, SCIENCE, V302, P639, DOI 10.1126/science.1088753; Zhou YY, 1998, FOLD DES, V3, P513, DOI 10.1016/S1359-0278(98)00067-4	67	18	18	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-734X			PLOS COMPUT BIOL	PLoS Comput. Biol.	APR	2008	4	4							e1000052	10.1371/journal.pcbi.1000052		10	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	294MY	WOS:000255411400021	
J	Graham, MW; Miller, DJ				Graham, MW; Miller, DJ			Unsupervised learning of parsimonious mixtures on large spaces with integrated feature and component selection	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						Bayesian information criterion (BIC); document clustering; EM algorithm; mixture models; model order selection; unsupervised feature selection	EM ALGORITHM; MODEL	Estimating the number of components (the order) in a mixture model is often addressed using criteria such as the Bayesian information criterion (BIC) and minimum message length. However, when the feature space is very large, use of these criteria may grossly underestimate the order. Here, it is suggested that this failure is not mainly attributable to the criterion (e.g., BIC), but rather to the lack of '' structure '' in standard mixtures-these models trade off data fitness and model complexity only by varying the order. The authors of the present paper propose mixtures with a richer set of tradeoffs. The proposed model allows each component its own informative feature subset, with all other features explained by a common model (shared by all components). Parameter sharing greatly reduces complexity at a given order. Since the space of these parsimonious modeling solutions is vast, this space is searched in an efficient manner, integrating the component and feature selection within the generalized expectation-maximization (GEM) learning for the mixture parameters. The quality of the proposed (unsupervised) solutions is evaluated using both classification error and test set data likelihood. text data, the proposed multinomial version-learned without labeled examples, without knowing the '' true '' number of topics, and without feature preprocessing-compares quite favorably with both alternative unsupervised methods and with a supervised naive Bayes classifier. A Gaussian version compares favorably with a recent method introducing '' feature saliency '' in mixtures.	Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA	Graham, MW (reprint author), Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA.	mwg129@psu.edu; millerdj@ee.psu.edu					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Breese JS, 1998, P 14 C UNC ART INT, P43; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devaney M., 1997, P 14 INT C MACH LEAR, P92; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; DUDA RO, 1973, PATTERN CLASSIFICAIT; Dy J, 2000, P 17 INT C MACH LEAR, P247; Dy JG, 2004, J MACH LEARN RES, V5, P845; El-Yaniv R., 2001, P 12 EUR C MACH LEAR, P121; FANTY M, 1990, NEURAL INF PROCESS S, V3, P220; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Ghahramani Z, 2000, ADV NEUR IN, V12, P449; GRAHAM MW, 2004, UNSUPERVISED LEARNIN; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Kim Y, 2000, P 6 ACM SIGKDD INT C, P365, DOI 10.1145/347090.347169; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; LEWIS DD, 1997, REUTERS 21 578 TEXT; Liu X., 2002, P 25 ANN INT ACM SIG, P191; McCallum Andrew, 1998, P AAAI 98 WORKSH LEA, P137; McLachlan G., 2000, FINITE MIXTURE MODEL; Meng XL, 1997, J ROY STAT SOC B MET, V59, P511, DOI 10.1111/1467-9868.00082; Miller DJ, 2003, IEEE T PATTERN ANAL, V25, P1468, DOI 10.1109/TPAMI.2003.1240120; Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975; Novovicova J, 1996, IEEE T PATTERN ANAL, V18, P218, DOI 10.1109/34.481557; PEREIRA F, 1993, M ASS COMP LING, P189; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Segal E, 2003, P 19 C UNC ART INT, P525; SLONIM N, 2002, P 25 ACM C RES DEV I, P208; Smyth P., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining; Tishby N., 1999, P 37 ANN ALL C COMM, P368; VAITHYANATHAN S, 1999, ADV NEURAL INF PROCE, V11, P970	32	18	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-587X			IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	APR	2006	54	4					1289	1303		10.1109/TSP.2006.870586		15	Engineering, Electrical & Electronic	Engineering	027DV	WOS:000236394800010	
J	Delany, SJ; Cunningham, P; Coyle, L				Delany, SJ; Cunningham, P; Coyle, L			An assessment of case-based reasoning for spam filtering	ARTIFICIAL INTELLIGENCE REVIEW			English	Article; Proceedings Paper	15th Artificial Intelligence and Cognitive Science Conference (AICS 2004)	SEP, 2004	Castlebar, IRELAND			case base reasoning; spam filtering	LEARNING ALGORITHMS	Because of the changing nature of spam, a spam filtering system that uses machine learning will need to be dynamic. This suggests that a case-based (memory-based) approach may work well. Case-Based Reasoning (CBR) is a lazy approach to machine learning where induction is delayed to run time. This means that the case base can be updated continuously and new training data is immediately available to the induction process. In this paper we present a detailed description of such a system called ECUE and evaluate design decisions concerning the case representation. We compare its performance with an alternative system that uses Naive Bayes. We find that there is little to choose between the two alternatives in cross-validation tests on data sets. However, ECUE does appear to have some advantages in tracking concept drift over time.	Dublin Inst Technol, Dublin 8, Ireland; Univ Dublin Trinity Coll, Dublin 2, Ireland; Natl Univ Ireland Univ Coll Dublin, Dublin 4, Ireland	Delany, SJ (reprint author), Dublin Inst Technol, Kevin St, Dublin 8, Ireland.	sarahjane.delany@comp.dit.ie					Andrieu B, 2000, BIOFUTUR, V2000, P13; ANDROUTSOPOULOS I, 2000, 200402 NCSR; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cuadrado J., 2003, SEMANTIC SEARCH UNST; Cunningham P., 2003, ICCBR 2003 WORKSH LO; Delany SJ, 2004, LECT NOTES COMPUT SC, V3155, P128; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; GEE KR, 2003, SAC 03 P 2003 ACM S, P460; Kohavi R., 1997, P 9 EUR C MACH LEARN; Lenz M., 1998, Case-based reasoning technology. From foundations to applications; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; McKenna E, 2000, FR ART INT, V54, P60; Niblett T, 1987, PROGR MACHINE LEARNI, P67; PANTEL P, 1988, P WORKSH TEXT CAT AA, P95; Quinlan J.R., 1997, C4 5 PROGRAMS MACHIN; Sahami M., 1998, P AAAI WORKSH LEARN, P55; Sakkis G, 2003, INFORM RETRIEVAL, V6, P49, DOI 10.1023/A:1022948414856; WILSON D, 1997, ICML 97, P403; Yang Y., 1997, ICML 97, P412; 2000, Patent No. 6161130	23	18	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821			ARTIF INTELL REV	Artif. Intell. Rev.	NOV	2005	24	3-4					359	378		10.1007/s10462-005-9006-6		20	Computer Science, Artificial Intelligence	Computer Science	994GI	WOS:000234018800008	
J	Leroy, G; Rindflesch, TC				Leroy, G; Rindflesch, TC			Effects of information and machine learning algorithms on word sense disambiguation with small datasets	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						word sense disambiguation; machine learning; naive Bayes; decision tree; neural network; UMLS	TERMS	Current approaches to word sense disambiguation use (and often combine) various machine learning techniques. Most refer to characteristics of the ambiguity and its surrounding words and are based on thousands of examples. Unfortunately, developing large training sets is burdensome, and in response to this challenge, we investigate the use of symbolic knowledge for small datasets. A naive Bayes classifier was trained for 15 words with 100 examples for each. Unified Medical Language System (UMLS) semantic types assigned to concepts found in the sentence and relationships between these semantic types form the knowledge base. The most frequent sense of a word served as the baseline. The effect of increasingly accurate symbolic knowledge was evaluated in nine experimental conditions. Performance was measured by accuracy based on 10-fold cross-validation. The best condition used only the semantic types of the words in the sentence. Accuracy was then on average 10% higher than the baseline; however, it varied from 8% deterioration to 29% improvement. To investigate this large variance, we performed several follow-up evaluations, testing additional algorithms (decision tree and neural network), and gold standards (per expert), but the results did not significantly differ. However, we noted a trend that the best disambiguation was found for words that were the least troublesome to the human evaluators. We conclude that neither algorithm nor individual human behavior cause these large differences, but that the structure of the UMLS Metathesaurus (used to represent senses of ambiguous words) contributes to inaccuracies in the gold standard, leading to varied performance of word sense disambiguation techniques. (C) 2005 Elsevier Ireland Ltd. All rights reserved.	Claremont Grad Univ, Sch Informat Sci, Claremont, CA 91711 USA; Natl Lib Med, Bethesda, MD USA	Leroy, G (reprint author), Claremont Grad Univ, Sch Informat Sci, 130 E 9th St, Claremont, CA 91711 USA.	gondy.leroy@cgu.edu					ARONSON AR, 2001, AMIA S; FLORIAN R, 2002, NATURAL LANGUAGE ENG, V1, P1; Ginter F, 2004, J MACH LEARN RES, V5, P605; HAN H, 2004, 4 ACM IEEE CS JOINT; HATZIVASSILOGLO.V, 2001, BIOINFORMATICS, V1, P1; Hoste V., 2002, Natural Language Engineering, DOI 10.1017/S1351324902003005; Humphreys BL, 1998, J AM MED INFORM ASSN, V5, P1; Ide N, 1998, COMPUT LINGUIST, V24, P1; INKPEN DZ, 2003, 4 C INT TEXT PROC CO; LEROY G, 2004, MEDINFO SAN FRANC; Liu HF, 2002, J AM MED INFORM ASSN, V9, P621, DOI 10.1097/jamia.M1101; Liu HF, 2001, J BIOMED INFORM, V34, P249, DOI 10.1006/jbin.2001.1023; Magnini B., 2002, Natural Language Engineering, DOI 10.1017/S1351324902003029; McCray AT, 1993, ADV INFORMATION MANA, P45; MIHALCEA R, 1998, COL ACL 98 WIRJFSH U; MILLER GA, 1998, INTRO WORDNET ON LIN; MOONEY RJ, 1996, C EMP METH NAT LANG; PEDERSEN T, 1997, 2 C EMP METH NAT LAN; PEDERSEN T, 2001, 2 ANN M N AM CHAPT A; Ruch P, 2003, ARTIF INTELL MED, V29, P169, DOI 10.1016/S0933-3657(03)00052-6; RUCH P, 1999, AMIA S; Santamaria C, 2003, COMPUT LINGUIST, V29, P485, DOI 10.1162/089120103322711613; Florian R., 2002, Natural Language Engineering, DOI 10.1017/S1351324902002978; Schutze H, 1998, COMPUT LINGUIST, V24, P97; WEEBER M, 2001, AMIA S; Witten I.H., 2000, DATA MINING PRACTICA	26	18	18	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056			INT J MED INFORM	Int. J. Med. Inform.	AUG	2005	74	7-8					573	585		10.1016/j.ijmedinf.2005.03.013		13	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	954VY	WOS:000231184500009	
J	Hutter, M; Zaffalon, M				Hutter, M; Zaffalon, M			Distribution of mutual information from complete and incomplete data	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						dirichlet distribution; expectation and variance of mutual information; feature selection; filters; naive bayes classifier; Bayesian statistics	PROBABILITY-DISTRIBUTIONS; SELECTION	Mutual information is widely used, in a descriptive way, to measure the stochastic dependence of categorical random variables. In order to address questions such as the reliability of the descriptive value, one must consider sample-to-population inferential approaches. This paper deals with the posterior distribution of mutual information, as obtained in a Bayesian framework by a second-order Dirichlet prior distribution. The exact analytical expression for the mean, and analytical approximations for the variance, skewness and kurtosis are derived. These approximations have a guaranteed accuracy level of the order O(n(-3)), where n is the sample size. Leading order approximations for the mean and the variance are derived in the case of incomplete samples. The derived analytical expressions allow the distribution of mutual information to be approximated reliably and quickly. In fact, the derived expressions can be computed with the same order of complexity needed for descriptive mutual information. This makes the distribution of mutual information become a concrete alternative to descriptive mutual information in many applications which would benefit from moving to the inductive side. Some of these prospective applications are discussed, and one of them, namely feature selection, is shown to perform significantly better when inductive mutual information is used. (C) 2004 Elsevier B.V. All rights reserved.	IDSIA, CH-6928 Lugano, Switzerland	Zaffalon, M (reprint author), IDSIA, Galleria 2, CH-6928 Lugano, Switzerland.	marcus@idsia.ch; zaffalon@idsia.ch					Abramowitz M., 1974, HDB MATH FUNCTIONS; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Chen T. T., 1974, BIOMETRICS, V32, P133; CHENG J, 2001, ACM SIGKDD EXPLORATI, V3; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Duda R.O., 2001, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Gelman A, 1995, BAYESIAN DATA ANAL; HCKERMAN D, 1998, LEARNING GRAPHICAL M, P301; Hutter M, 2002, ADV NEUR IN, V14, P399; Hutter M, 2003, LECT NOTES ARTIF INT, V2821, P396; John G., 1994, P 11 INT C MACH LEAR, P121; KENDALL M.A., 1967, ADV THEORY STAT; Kleiter G. D., 1999, Soft Computing, V3, DOI 10.1007/s005000050065; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; Koller D., 1996, P 13 INT C MACH LEAR, P284; KULLBACK S, 1968, INFORMATION THEORY S; Lewis D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; Little RJA, 1987, STAT ANAL MISSING DA; Liu H., 1998, FEATURE SELECTION KN; Murphy P. M., 1995, UCI REPOSITORY MACHI; Neapolitan R. E., 2004, LEARNING BAYESIAN NE; Pearl J., 1988, PROBABILISTIC REASON; PELLEG D, 2003, ADV NEURAL INFORMATI, V15, P825; Press W.H., 1992, NUMERICAL RECIPES AR; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Witten I.H., 1999, DATA MINING PRACTICA; WOLPERT DH, 1995, PHYS REV E, V52, P6841, DOI 10.1103/PhysRevE.52.6841; ZAFFALON M, 2003, IDSIA1103; Zaffalon M., 2002, P 18 INT C UNC ART I, P577	35	18	19	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAR 1	2005	48	3					633	657		10.1016/j.csda.2004.03.010		25	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	889XJ	WOS:000226475800012	
J	Rokach, L; Maimon, O				Rokach, Lior; Maimon, Oded			Feature set decomposition for decision trees	INTELLIGENT DATA ANALYSIS			English	Article						decision trees; naive Bayes; Vapnik-Chervonenkis; decomposition		This paper presents practical aspects of feature set decomposition in classification problems using decision trees. Feature set decomposition generalizes the task of feature selection which is extensively used in data mining. Feature selection aims to provide a representative set of features from which a classifier is constructed. On the other hand, feature set decomposition decomposes the original set of features into several subsets, and builds a classifier for each subset. The classifiers are then combined for classifying new instances. In order to examine the idea, a general framework that searches for helpful decomposition structures is proposed. This framework nests many algorithms, two of which are tested empirically over a set of benchmark datasets. The first algorithm performs a serial search while using a new Vapnik-Chervonenkis dimension bound for multiple oblivious trees as an evaluating schema. The second algorithm performs a multi-search while using wrapper evaluating schema. This work indicates that feature set decomposition can increase the accuracy of decision trees.	Tel Aviv Univ, Dept Ind Engn, Tel Aviv, Israel	Rokach, L (reprint author), Tel Aviv Univ, Dept Ind Engn, Tel Aviv, Israel.	liorr@eng.tau.ac.il; maimon@eng.tau.ac.il	Rokach, Lior/F-8247-2010				Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Bellman R.E., 1961, ADAPTIVE CONTROL PRO; Blum A., 1998, COLT, P92; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chen K, 1997, INT J PATTERN RECOGN, V11, P417, DOI 10.1142/S0218001497000196; CHERKAUER KJ, 1996, INT MULT LEARN MOD I; Dietterich T.G., 1983, MACHINE LEARNING ART, V1, P41; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Dunteman G. H., 1989, PRINCIPAL COMPONENTS; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Freund Y, 1996, EXPT NEW BOOSTING AL, P148; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fukunaga K., 1990, INTRO STAT PATTERN R; GAMA J, 2000, LNAI, V1952; HU X, 2001, ICDM01, P233; HWANG JN, 1994, IEEE T SIGNAL PROCES, V42, P2795; Jimenez LO, 1998, IEEE T SYST MAN CY C, V28, P39, DOI 10.1109/5326.661089; John G. H., 1994, IRRELEVANT FEATURES; Kim J-O, 1978, FACTOR ANAL STAT MET; Kononenko I., 1990, CURRENT TRENDS KNOWL; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Kusiak A, 2000, IEEE T ELECTRON PA M, V23, P345, DOI 10.1109/6104.895081; Langley P, 1994, AAAI 94 WORKSH CAS B, P113; Langley P., 1994, P AAAI FALL S REL, P140; Langley P., 1994, P 10 C UNC ART INT, P399; Last M, 2002, INT J PATTERN RECOGN, V16, P145, DOI 10.1142/S0218001402001599; LIAO Y, 2000, ADV NEURAL INFORM PR; Liu H., 1998, FEATURE SELECTION KN; MAIMON O, 2001, DATA MINING DESIGN M, P311; MANSOUR Y, 2000, P 13 ANN C COMP LEAR, P69; MERETAKIS D, 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Merz C. J., 1998, UCI REPOSITORY MACHI; MICHIE D, 1995, P EUR C MACH LEARN S, P17; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PFAHRINGER B, 1994, P 7 EUR C MACH LEARN, P242; Quinlan J. R., 1993, C45 PROGRAMS MACHINE; Ragavan H., 1993, P 10 INT C MACH LEAR, P252; Schlimmer J.C., 1993, P 10 INT C MACH LEAR, P284; Schmitt M, 2002, NEURAL COMPUT, V14, P241, DOI 10.1162/08997660252741121; Sharkey A. J. C., 1996, Connection Science, V8, DOI 10.1080/095400996116785; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839; Vapnik V., 1995, NATURE STAT LEARNING; Wallace C. S., 1996, COMPUTATIONAL LEARNI, P43	50	18	19	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1088-467X			INTELL DATA ANAL	Intell. Data Anal.		2005	9	2					131	158				28	Computer Science, Artificial Intelligence	Computer Science	V43YA	WOS:000202969200002	
J	Van der Putten, P; Van Someren, M				Van der Putten, P; Van Someren, M			A bias-variance analysis of a real world learning problem: The CoIL Challenge 2000	MACHINE LEARNING			English	Article						bias-variance decomposition; real world applications; overfitting		The CoIL Challenge 2000 data mining competition attracted a wide variety of solutions, both in terms of approaches and performance. The goal of the competition was to predict who would be interested in buying a specific insurance product and to explain why people would buy. Unlike in most other competitions, the majority of participants provided a report describing the path to their solution. In this article we use the framework of bias-variance decomposition of error to analyze what caused the wide range of prediction performance. We characterize the challenge problem to make it comparable to other problems and evaluate why certain methods work or not. We also include an evaluation of the submitted explanations by a marketing expert. We find that variance is the key component of error for this problem. Participants use various strategies in data preparation and model development that reduce variance error, such as feature selection and the use of simple, robust and low variance learners like Naive Bayes. Adding constructed features, modeling with complex, weak bias learners and extensive fine tuning by the participants often increase the variance error.	Leiden Univ, Leiden Inst Adv Comp Sci, NL-2300 RA Leiden, Netherlands; Univ Amsterdam, Dept Social Sci Informat, NL-1018 WB Amsterdam, Netherlands	Van der Putten, P (reprint author), Leiden Univ, Leiden Inst Adv Comp Sci, POB 9512, NL-2300 RA Leiden, Netherlands.	putten@liacs.nl; maarten@swi.psy.uva.nl					[Anonymous], 2001, P 7 ACM SIGKDD INT C, P426, DOI 10.1145/502512.502576; BERKA P, 1999, PKDD99 U EC LAB INT; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L., 1996, BIAS VARIANCE ARCING; CHAPMAN P, 1999, CRISP DM PROCESS MOD; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M. A., 1998, THESIS U WAIKATO; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Kohavi R., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Quinlan J. R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Tsamardinos I., 2003, P 9 INT WORKSH ART I; VANDERPUTTEN P, 2000, 200009 U LEID LEID I; Witten I.H., 2000, DATA MINING PRACTICA; Wolpert D.H., 1995, SFITR9502010	21	18	18	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	OCT-NOV	2004	57	1-2					177	195		10.1023/B:MACH.0000035476.95130.99		19	Computer Science, Artificial Intelligence	Computer Science	839QS	WOS:000222800200008	
S	Yang, Y; Webb, GI		Gedeon, TD; Fung, LCC		Yang, Y; Webb, GI			On why discretization works for naive-Bayes classifiers	AI 2003: ADVANCES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	16th Australian Conference on Artificial Intelligence	DEC 03-05, 2003	PERTH, AUSTRALIA	Natl Comm Artificial Intellignece & Expert Syst	UNIV WESTERN AUSTRALIA			We investigate why discretization can be effective in naive-Bayes learning. We prove a theorem that identifies particular conditions under which discretization will result in naive-Bayes classifiers delivering the same probability estimates as would be obtained if the correct probability density functions were employed. We discuss the factors that might affect naive-Bayes classification error under discretization. We suggest that the use of different discretization techniques can affect the classification bias and variance of the generated classifiers. We argue that by properly managing discretization bias and variance, we can effectively reduce naive-Bayes classification error.	Monash Univ, Sch Comp Sci & Software Engn, Melbourne, Vic 3800, Australia	Yang, Y (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Melbourne, Vic 3800, Australia.	yyang@csse.monash.edu.au; webb@csse.monash.edu.au	Webb, Geoffrey/A-1347-2008				BAY SD, 1999, UCI KDD; Blake C. L., 1998, UCI REPOSITORY MACHI; BLUMAN AG, 1992, ELEMENTARY STAT STEP; Breiman L., 1996, BIAS VARIANCE ARCING; Casella G, 1990, STAT INFERENCE; Cestnik B, 1990, P EUR C ART INT, P147; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Duda R., 1973, PATTERN CLASSIFICATI; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Gama J, 1998, LECT NOTES ARTIF INT, V1484, P160; Hsu C., 2000, P 17 INT C MACH LEAR, P309; HSU CN, IN PRESS MACHINE LEA; Hussain F., 1999, TRC699 NAT U SING SC; JOHN GH, 1995, P 11 C UNC ART INT, P338; Kohav R., 1996, P 13 INT C MACH LEAR, P275; Kong E. B., 1995, P 12 INT C MACH LEAR, P313; KONONENKO I, 1992, INFORMATICA, V16, P1; Mitchell T.M., 1997, MACHINE LEARNING; Moore D.S., 2002, INTRO PRACTICE STAT; MORA L, 2000, P 11 EUR C MACH LEAR, P280; Pazzani M.J., 1995, P 1 INT C KNOWL DISC, P228; SAMUELS ML, 1999, STAT LIFE SCI, P10; Torgo L., 1997, P 9 EUR C MACH LEARN, P266; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Yang Y., 2001, P 12 EUR C MACH LEAR, P564; YANG Y, 2003, 2003131 MON U SCH CO; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	27	18	18	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20646-9	LECT NOTES ARTIF INT			2003	2903						440	452				13	Computer Science, Artificial Intelligence	Computer Science	BY08N	WOS:000187551700037	
J	Maetschke, SR; Yuan, Z				Maetschke, Stefan R.; Yuan, Zheng			Exploiting structural and topological information to improve prediction of RNA-protein binding sites	BMC BIOINFORMATICS			English	Article							RESIDUES; NETWORK; RECOGNITION; ALGORITHMS; SEQUENCE; DATABASE; DNA	Background: RNA-protein interactions are important for a wide range of biological processes. Current computational methods to predict interacting residues in RNA-protein interfaces predominately rely on sequence data. It is, however, known that interface residue propensity is closely correlated with structural properties. In this paper we systematically study information obtained from sequences and structures and compare their contributions in this prediction problem. Particularly, different geometrical and network topological properties of protein structures are evaluated to improve interface residue prediction accuracy. Results: We have quantified the impact of structural information on the prediction accuracy in comparison to the purely sequence based approach using two machine learning techniques: Naive Bayes classifiers and Support Vector Machines. The highest AUC of 0.83 was achieved by a Support Vector Machine, exploiting PSI-BLAST profile, accessible surface area, betweenness-centrality and retention coefficient as input features. Taking into account that our results are based on a larger non-redundant data set, the prediction accuracy is considerably higher than reported in previous, comparable studies. A protein-RNA interface predictor (PRIP) and the data set have been made available at http://www.qfab.org/PRIP. Conclusion: Graph-theoretic properties of residue contact maps derived from protein structures such as betweenness-centrality can supplement sequence or structure features to improve the prediction accuracy for binding residues in RNA-protein interactions. While Support Vector Machines perform better on this task, Naive Bayes classifiers also have been found to achieve good prediction accuracies but require much less training time and are an attractive choice for large scale predictions.	[Maetschke, Stefan R.; Yuan, Zheng] Univ Queensland, Inst Mol Biosci, Brisbane, Qld 4072, Australia; [Yuan, Zheng] Univ Queensland, ARC Ctr Excellence Bioinformat, Brisbane, Qld 4072, Australia	Yuan, Z (reprint author), Univ Queensland, Inst Mol Biosci, Brisbane, Qld 4072, Australia.	s.maetschke@imb.uq.edu.au; z.yuan@imb.uq.edu.au					Allers J, 2001, J MOL BIOL, V311, P75, DOI 10.1006/jmbi.2001.4857; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Amitai G, 2004, J MOL BIOL, V344, P1135, DOI 10.1016/j.jmb.2004.10.055; Bahadur RP, 2008, NUCLEIC ACIDS RES, V36, P2705, DOI 10.1093/nar/gkn102; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; CHEN Y, 2008, NUCL ACIDS IN PRESS; Cheng CW, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S12-S6; del Sol A, 2005, PROTEINS, V58, P672, DOI 10.1002/prot.20348; del Sol A, 2005, BIOINFORMATICS, V21, P1311, DOI 10.1093/bioinformatics/bti167; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; GUO D, J J CHROMATOGR, V359, P499; GUO D, J J CHROMATOGR, V9, P499; GUY HR, 1985, BIOPHYS J, V47, P61; Jeong Euna, 2004, Genome Inform, V15, P105; Jeong EN, 2006, LECT NOTES COMPUT SC, V3939, P123; Jones S, 1997, J MOL BIOL, V272, P121, DOI 10.1006/jmbi.1997.1234; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kim OTP, 2006, NUCLEIC ACIDS RES, V34, P6450, DOI 10.1093/nar/gkl819; KUMAR M, 2007, PROTEINS, V1, P189; Press WH, 1995, NUMERICAL RECIPES C; SELIN I, 1965, DETECTION THEORY; Shazman S, 2008, PLOS COMPUT BIOL, V4; Spriggs RV, 2009, BIOINFORMATICS, V25, P1492, DOI 10.1093/bioinformatics/btp257; TANAKA S, 1977, MACROMOLECULES, V10, P9, DOI 10.1021/ma60055a002; TERRIBILINI M, 2007, NUCL ACIDS RES; Terribilini M, 2006, RNA, V12, P1450, DOI 10.1261/rna.2197306; Thibert B, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-213; Tjong H, 2007, NUCLEIC ACIDS RES, V35, P1465, DOI 10.1093/nar/gkm008; Wang LJ, 2006, NUCLEIC ACIDS RES, V34, pW243, DOI 10.1093/nar/gkl298; Wang L, 2006, P 26 IEEE EMBS ANN I, P5830; Witten IH, 2005, DATA MINING PRACTICA	34	17	17	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	OCT 18	2009	10								341	10.1186/1471-2105-10-341		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	519JV	WOS:000271763500001	
J	Jiang, LX; Zhang, H; Cai, ZH				Jiang, Liangxiao; Zhang, Harry; Cai, Zhihua			A Novel Bayes Model: Hidden Naive Bayes	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Naive Bayes; Bayesian network classifiers; learning algorithms; classification; class probability estimation; ranking	ROC CURVE; AREA	Because learning an optimal Bayesian network classifier is an NP-hard problem, learning-improved naive Bayes has attracted much attention from researchers. In this paper, we summarize the existing improved algorithms and propose a novel Bayes model: hidden naive Bayes (HNB). In HNB, a hidden parent is created for each attribute which combines the influences from all other attributes. We experimentally test HNB in terms of classification accuracy, using the 36 UCI data sets selected by Weka, and compare it to naive Bayes (NB), selective Bayesian classifiers (SBC), naive Bayes tree (NBTree), tree-augmented naive Bayes (TAN), and averaged one-dependence estimators (AODE). The experimental results show that HNB significantly outperforms NB, SBC, NBTree, TAN, and AODE. In many data mining applications, an accurate class probability estimation and ranking are also desirable. We study the class probability estimation and ranking performance, measured by conditional log likelihood (CLL) and the area under the ROC curve (AUC), respectively, of naive Bayes and its improved models, such as SBC, NBTree, TAN, and AODE, and then compare HNB to them in terms of CLL and AUC. Our experiments show that HNB also significantly outperforms all of them.	[Jiang, Liangxiao; Cai, Zhihua] China Univ Geosci, Fac Comp Sci, Wuhan 430074, Peoples R China; [Zhang, Harry] Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Jiang, LX (reprint author), China Univ Geosci, Fac Comp Sci, Wuhan 430074, Peoples R China.	ljiang@cug.edu.cn; hzhang@unb.ca; zhcai@cug.edu.cn	Jiang, Liangxiao /D-1237-2012				Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Chichering D M, 1996, LEARNING DATA ARTIFI, P121; [邓维斌 DENG WeiBin], 2007, [计算机科学, Computer Science], V34, P204; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; FERREIRA JTA, 2001, WEIGHTED NAIVE BAYES; Frank E., 2003, P C UNC ART INT, P249; FRIEDMAN N, 1997, MACH LEARN, V1, P29; Grossman D., 2004, P 21 INT C MACH LEAR, P361; Hall M, 2007, KNOWL-BASED SYST, V20, P120, DOI 10.1016/j.knosys.2006.11.008; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Jiang LX, 2005, Progress in Intelligence Computation & Applications, P344; Jiang LX, 2008, INT J PATTERN RECOGN, V22, P1121, DOI 10.1142/S0218001408006703; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Kohavi R, 1997, ARTIF INTELL, V1, P273; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Langley P., 1994, P 10 C UNC ART INT, P339; Ling C.L., 2002, P 6 PAC AS C KDD, P123; Ling CX, 2003, P 18 INT C ART INT I, P329; Merz C., 1997, UCI REPOSITORY MACHI; Nadeau C., 1999, ADV NEURAL INFORMATI, P307; Pearl J., 1988, PROBABILISTIC REASON; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ratanamahatana C.A., 2002, P WORKSH DAT CLEAN P; SUN J, 2007, P 4 INT C FUZZ SYST, V1, P540; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Witten IH, 2005, DATA MINING PRACTICA; Xie Z., 2002, P 6 PAC AS C KDD, P104; Zhang H., 2004, P 4 IEEE INT C DAT M, P567; Zhang H., 2001, P 5 PAC AS C ADV KNO, P581; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	30	17	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	OCT	2009	21	10					1361	1371		10.1109/TKDE.2008.234		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	483VM	WOS:000268996800001	
J	del Coz, JJ; Diez, J; Bahamonde, A				Jose del Coz, Juan; Diez, Jorge; Bahamonde, Antonio			Learning Nondeterministic Classifiers	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						nondeterministic; multiclassification; reject option; multi-label classification; posterior probabilities	GENE-EXPRESSION SIGNATURES; NAIVE CREDAL CLASSIFIER; MULTICLASS CLASSIFICATION; MICROARRAY DATA; DATA SETS; PREDICTION; CANCER; REGRESSION; LEUKEMIA	Nondeterministic classifiers are defined as those allowed to predict more than one class for some entries from an input space. Given that the true class should be included in predictions and the number of classes predicted should be as small as possible, these kind of classifiers can be considered as Information Retrieval (IR) procedures. In this paper, we propose a family of IR loss functions to measure the performance of nondeterministic learners. After discussing such measures, we derive an algorithm for learning optimal nondeterministic hypotheses. Given an entry from the input space, the algorithm requires the posterior probabilities to compute the subset of classes with the lowest expected loss. From a general point of view, nondeterministic classifiers provide an improvement in the proportion of predictions that include the true class compared to their deterministic counterparts; the price to be paid for this increase is usually a tiny proportion of predictions with more than one class. The paper includes an extensive experimental study using three deterministic learners to estimate posterior probabilities: a multiclass Support Vector Machine (SVM), a Logistic Regression, and a Naive Bayes. The data sets considered comprise both UCI multi-class learning tasks and microarray expressions of different kinds of cancer. We successfully compare nondeterministic classifiers with other alternative approaches. Additionally, we shall see how the quality of posterior probabilities (measured by the Brier score) determines the goodness of nondeterministic predictions.	[Jose del Coz, Juan; Diez, Jorge; Bahamonde, Antonio] Univ Oviedo Gijon, Ctr Artificial Intelligence, Asturias, Spain	del Coz, JJ (reprint author), Univ Oviedo Gijon, Ctr Artificial Intelligence, Asturias, Spain.	JUANJO@AIC.UNIOVI.ES; JDIEZ@AIC.UNIOVI.ES; ANTONIO@AIC.UNIOVI.ES			MEC (Ministerio de Educacion y Ciencia, Spain) [TIN2005-08288]; MICINN (Ministerio de Ciencia e Innovacion, Spain) [TIN2008- 06247]	The research reported here is supported in part under grants TIN2005-08288 from the MEC (Ministerio de Educacion y Ciencia, Spain) and TIN2008- 06247 from the MICINN (Ministerio de Ciencia e Innovacion, Spain). We would also like to acknowledge all those people who generously shared the data sets and software used in this paper, and the anonymous reviewers, whose comments significantly improved it.	Alonso J, 2008, LECT NOTES ARTIF INT, V5211, P39, DOI 10.1007/978-3-540-87479-9_21; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Asuncion A., 2007, UCI MACHINE LEARNING; Bartlett PL, 2008, J MACH LEARN RES, V9, P1823; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Clare A, 2003, BIOINFORMATICS, V19, pii42; Corani G, 2008, J MACH LEARN RES, V9, P581; Corani G, 2008, J MACH LEARN RES, V9, P2695; Demsar J, 2006, J MACH LEARN RES, V7, P1; Kriegel HP, 2004, SIAM PROC S, P102; Lin CJ, 2008, J MACH LEARN RES, V9, P627; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Shafer G, 2008, J MACH LEARN RES, V9, P371; Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Su AI, 2001, CANCER RES, V61, P7388; Tamayo P, 2007, P NATL ACAD SCI USA, V104, P5959, DOI 10.1073/pnas.0701068104; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; Tibshirani R, 2007, J MACH LEARN RES, V8, P637; TSOUMAKAS G, 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101; Wu TF, 2004, J MACH LEARN RES, V5, P975; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Yeung KY, 2005, BIOINFORMATICS, V21, P2394, DOI 10.1093/bioinformatics/bti319; Yeung KY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-12-r83; Zaffalon M, 2002, J STAT PLAN INFER, V105, P5, DOI 10.1016/S0378-3758(01)00201-4	27	17	17	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	OCT	2009	10						2273	2293				21	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	527DH	WOS:000272346400004	
J	Isa, D; Kallimani, VP; Lee, LH				Isa, Dino; Kallimani, V. P.; Lee, Lam Hong			Using the self organizing map for clustering of text documents	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Bayesian; Self organizing maps; Clusters similarity		All increasing number of computational and statistical approaches have been used for text classification, including nearest-neighbor classification, naive Bayes classification, support vector machines, decision tree induction, rule induction, and artificial neural networks. Among these approaches, naive Bayes classifiers have been widely used because of its simplicity. Due to the simplicity of the Bayes formula, the naive Bayes classification algorithm requires a relatively small number of training data and shorter time in both the training and classification stages as compared to other classifiers. However, a major short coming of this technique is the fact that the classifier will pick the highest probability category as the one to which the document is annotated too. Doing this is tantamount to classifying using only one dimension of a multi-dimensional data set. The plain aim of this work is to utilize the strengths of the self organizing map (SOM) to overcome the inadvertent dimensionality reduction resulting from using only the Bayes formula to classify. Combining the hybrid system with new ranking techniques further improves the performance of the proposed document classification approach. This work describes the implementation of an enhanced hybrid classification approach which affords a better classification accuracy through the utilization of two familiar algorithms, the naive Bayes classification algorithm which is used to vectorize the document using a probability distribution and the self organizing map (SOM) clustering algorithm which is used as the multi-dimensional unsupervised classifier. (C) 2008 Elsevier Ltd. All rights reserved.	[Isa, Dino; Kallimani, V. P.; Lee, Lam Hong] Univ Nottingham, Fac Engn & Comp Sci, Semenyih 43500, Malaysia	Kallimani, VP (reprint author), Univ Nottingham, Fac Engn & Comp Sci, Malaysia Campus, Semenyih 43500, Malaysia.	Dino.Isa@nottingham.edu.my; VP.Kallimani@nottingham.edu.my; Kcx4lhl@nottingham.edu.my					Brucher H., 2002, CH3012 U BERN I INF; Chakrabarti S, 2003, VLDB J, V12, P170, DOI 10.1007/s00778-003-0098-9; CUNNINGHAM P, 2003, ICCBR 03 WORKSH LONG; Deboeck G., 1998, VISUAL EXPLORATIONS; Delany SJ, 2005, ARTIF INTELL REV, V24, P359, DOI 10.1007/s10462-005-9006-6; DELANY SJ, 2004, J KNOWLEDGE BASED SY, V18, P187; FLACH PA, 2002, PROBABILISTIC REASON; Han EH, 1999, TEXT CATEGORIZATION; HARTLEY M, 2006, DOMAIN KNOWLEDGE PRE; Haykin S., 1999, NEURAL NETWORKS COMP; ISA D, J COMPUTER IN PRESS; ISA D, 2007, CSECS 2007; Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings; KAMENS B, 2005, BAYESIAN FILTERING B; KIM SB, 2002, P 7 PAC RIM INT C AR, V2417; KONTKANEN P, 1997, P EXPERSYS 97 C SUND, P67; KRIEGEL HP, 2003, P ACM SIGMOD 2003 IN; MCCALLUM A, 2003, J MACHINE LEARNING R, V3, P1265; MICHALSKI RS, 1999, MACHINE LEARNING DAT; MIYAMOTO S, 2007, DATA CLUSTERING ALGO; Negnevitsky M., 2002, ARTIFICIAL INTELLIGE; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; OBRIEN C, 2002, P 1 INT S INF COMM T; Pal S.K., 2004, FDN SOFT CASE BASED; PETRUSHIN VA, 2005, P 11 ACM SIGKDD INT; Provost J, 1999, NAIVE BAYES VS RULE; Quinlan J.R., 1993, C4 5 PROGRAM MACHINE; Sahami M., 1998, AAAI 98 WORKSH LEARN; SU X, 2002, TEXT CATEGORIZATION; Vapnik V., 1995, NATURE STAT LEARNING; Vesanto J, 1999, SIMULATION NEWS EURO, V25, P54; WANG SH, 2001, INT J INTELLIGENT SY, V127; WEI K, 2003, NAIVE BAYES SPAM FIL; XIA Y, 2005, P INT C APPL NAT LAN	34	17	18	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	JUL	2009	36	5					9584	9591		10.1016/j.eswa.2008.07.082		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	427MG	WOS:000264782800094	
J	Manevitz, L; Yousef, M				Manevitz, Larry; Yousef, Malik			One-class document classification via Neural Networks	NEUROCOMPUTING			English	Article						classification; automated document retrieval; feed-forward neural networks; machine learning; one-class classification; autoencoder; bottleneck neural network		Automated document retrieval and classification is of central importance in many contexts; our main motivating goal is the efficient classification and retrieval of "interests" on the internet when only positive information is available. In this paper, we show how a simple feed-forward neural network can be trained to filter documents under these conditions, and that this method seems to be superior to modified methods (modified to use only positive examples), such as Rocchio, Nearest Neighbor, Naive-Bayes, Distance-based Probability and One-Class SVM algorithms. A novel experimental finding is that retrieval is enhanced substantially in this context by carrying out a certain kind of uniform transformation ("Hadamard") of the information prior to the training of the network. (c) 2006 Published by Elsevier B.V.	Univ Haifa, Dept Comp Sci, Haifa, Israel; Univ Oxford, Inst Math, Dept Expt Psychol, Oxford, England; Univ Penn, Wistar Inst, Philadelphia, PA USA	Manevitz, L (reprint author), Univ Haifa, Dept Comp Sci, Haifa, Israel.	manevitz@cs.haifa.ac.il; yousef@cs.haifa.ac.il					BALABANOVIC M, 1995, AAAI SPRING S SER IN; BOSTROM H, 1998, P 10 EUR C MACH LEAR, P226; DATTA P, 1997, THESIS U CALIFORNIA; DOMINGOS P, 1996, 13 INT C MACH LEARN; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; HUMMEL R, 1996, IEEE T SYST MAN CY A, V3, P378; Japkowicz N, 1995, INT JOINT CONF ARTIF, P518; Japkowicz N, 2001, MACH LEARN, V42, P97, DOI 10.1023/A:1007660820062; Japkowicz N, 2000, NEURAL COMPUT, V12, P531, DOI 10.1162/089976600300015691; JOACHIM T, 1998, P 10 EUR C MACH LEAR; Joachims Thorsten, 1996, PROBABILISTIC ANAL R; KAROV Y, 1998, ADV CLASSIFICATION R, V8, P59; LAGUS K, 1996, NEWSGROUP EXPLORATIO; Lang K., 1995, 12 INT C MACH LEARN; Lewis D. D., 1997, REUTERS 21578 TEXT C; Manevitz L., 2001, J MACHINE LEARNING R, V2, P139; Manevitz L. M., 2004, Web Intelligence and Agent Systems, V2; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Muggleton S., 1996, LECT NOTES ARTIF INT, V1314, P358; MUNRO P, 1988, ADV COGNITIVE SCI, V3; PAZZANI M, 1996, AAAI C; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; QUEK C, 1997, THESIS CARNEGIE MELL; Raskutti B., 2004, SIGKDD EXPLORATIONS, V6, P60, DOI DOI 10.1145/1007730.1007739; SALTON G, 1983, INTRO MODERN INFORMA; Scholkopf B., 1999, MSRTR9987; Schwenk H, 1998, NEURAL COMPUT, V10, P2175, DOI 10.1162/089976698300017025; Sheth B. D., 1994, THESIS MIT; Swingler K., 1996, APPL NEURAL NETWORKS; Van Rijsbergen C.J., 1979, INFORMATION RETRIEVA; WEINER E, 1995, 4 S DOC AN INF RETR, P317; Yang Y., 1997, P 14 INT C MACH LEAR, P412; YOUSEF M, 2002, THESIS U HAIFA; Zhang HH, 2005, IEEE T SYST MAN CY B, V35, P593, DOI 10.1109/TSMCB.2005.843980	35	17	19	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	MAR	2007	70	7-9			SI		1466	1481		10.1016/j.neucom.2006.05.013		16	Computer Science, Artificial Intelligence	Computer Science	155MN	WOS:000245581600032	
B	Bifet, A; Gavalda, R		Apte, C; Liu, B; Parthasarathy, S; Skillicorn, D		Bifet, Albert; Gavalda, Ricard			Learning from Time-Changing Data with Adaptive Windowing	PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING			English	Proceedings Paper	7th SIAM International Conference on Data Mining	APR 26-28, 2007	Minneapolis, MN	Amer Stat Assoc		Data Streams; Time-Changing Data; Concept and Distribution Drift; Naive Bayes		We present a new approach for dealing with distribution change and concept drift when learning from data sequences that may vary with time. We use sliding windows whose size, instead of being fixed a priori, is recomputed online according to the rate of change observed from the data in the window itself. This delivers the user or programmer from having to guess a time-scale for change. Contrary to many related works, we provide rigorous guarantees of performance, as bounds on the rates of false positives and false negatives. Using ideas from data stream algorithmics, we develop a time- and memory-efficient version of this algorithm, called ADWIN2. We show how to combine ADWIN2 with the Naive Bayes (NB) predictor, in two ways: one, using it to monitor the error rate of the current model and declare when revision is necessary and., two, putting it inside the NB predictor to maintain up-to-date estimations of conditional probabilities in the data. We test our approach using synthetic and real data streams and compare them to both fixed-size and variable-size window strategies with good results.	[Bifet, Albert; Gavalda, Ricard] Univ Politecn Cataluna, E-08028 Barcelona, Spain	Bifet, A (reprint author), Univ Politecn Cataluna, E-08028 Barcelona, Spain.	abifet@lsi.upc.edu; gavalda@lsi.upc.edu					BABCOCK B, 2002, P 21 ACM S PRINC DAT; BABCOCK B, 2002, P 1O ANN ACM SIAM S; Datar M., 2002, SIAM J COMPUT, V14, P27; Gama J., 2004, SBIA BRAZ S ART INT, P286; Harries M., 1999, SPLICE 2 COMP EVALUA; Kifer D., 2004, P 30 VLDB C TOR CAN; MUTHUKRISHNAN S, 2003, P 14 ANN ACM SIAM S	7	17	18	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			978-0-898716-30-6				2007							443	448				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Mathematics, Applied	Computer Science; Mathematics	BUG50	WOS:000289220200042	
J	Sakai, S; Kobayashi, K; Nakamura, I; Toyabe, S; Akazawa, K				Sakai, S.; Kobayashi, K.; Nakamura, J.; Toyabe, S.; Akazawa, K.			Accuracy in the diagnostic prediction of acute appendicitis based on the Bayesian network model	METHODS OF INFORMATION IN MEDICINE			English	Article; Proceedings Paper	Annual Meeting of the Japanese Congress of Medical Informatics	2006	Sapporo, JAPAN			artificial neural network; Bayesian network; diagnostic prediction; logistic regression analysis	QUANTITATIVE TRAIT; BELIEF-NETWORK; BREAST-CANCER; SCORE; METAANALYSIS; VALIDATION; PROGNOSIS; EXAMPLE	Objectives: The diagnosis of acute appendicitis is difficult, and a diagnostic error will often lead to either a perforation or the removal of a normal appendix. In this study, we constructed a Bayesian network model for the diagnosis of acute appendicitis and compared the diagnostic accuracy with other diagnostic models, such as the naive Bayes model, an artificial neural network model, and a logistic regression model. Methods: The data from 169 patients, who suffered from acute abdominal pain and who were suspected of having an acute appendicitis, were analyzed in this study. Nine variables were used for the evaluation of the accuracy of the four models for the diagnosis of an acute appendicitis. The naive Bayes model, the Bayesian network model, an artificial neural network model, and a logistic regression model were used in this study for the diagnosis of acute appendicitis. These four models were validated by using the ".632 + bootstrap method" for resampling. The levels of accuracy of the four models for diagnosis were compared by the error rates and by the areas under the receiver operating characteristic curves. Results: Through the course of illness, 50.9% (86 of 169) of the patients were diagnosed as having an acute appendicitis. The error rate was the lowest in the Bayesian network model, as compared with the other diagnostic models. The area under the receiver operating characteristic curve analysis also showed that the Bayesian network model provided the most reliable results. Conclusion: The Bayesian network model provided the most accurate results in comparison to other models for the diagnosis of acute appendicitis.	[Toyabe, S.; Akazawa, K.] Niigata Univ Med & Dent Hosp, Dept Med Informat, Niigata 9518520, Japan; [Sakai, S.; Kobayashi, K.] Niigata Univ, Grad Sch Med & Dent Sci, Niigata, Japan	Akazawa, K (reprint author), Niigata Univ Med & Dent Hosp, Dept Med Informat, Asahimachi Dori 1-754, Niigata 9518520, Japan.	akazawa@med.niigata-u.ac.jp					ALVARADO A, 1986, ANN EMERG MED, V15, P557, DOI 10.1016/S0196-0644(86)80993-3; Alvarez SM, 2006, J PEDIATR SURG, V41, P155, DOI 10.1016/j.jpedsurg.2005.10.019; Andersson REB, 2004, BRIT J SURG, V91, P28, DOI 10.1002/bjs.4464; ANGELOPOULOS N, 2001, P 17 ANN C UNC ART I, P16; ARNBJORNSSON E, 1985, ANN CHIR GYNAECOL FE, V74, P159; Aronsky D, 1998, Proc AMIA Symp, P632; BURNSIDE ES, 2000, RADIOLOGY, V240, P666; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Eldar S, 1997, AM J SURG, V173, P194, DOI 10.1016/S0002-9610(96)00011-6; ESKELINEN M, 1992, THEOR SURG, V7, P86; Friedman N., 2000, P 16 C UNC ART INT U, P201; Gevaert O, 2006, BIOINFORMATICS, V22, pE184, DOI 10.1093/bioinformatics/btl230; HANLEY JA, 1982, RADIOLOGY, V143, P29; HERSKOVITS EH, 1991, METHOD INFORM MED, V30, P81; Hua JP, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-274; Kharbanda AB, 2005, PEDIATRICS, V116, P709, DOI 10.1542/peds.2005-0094; Kline JA, 2005, ANN EMERG MED, V45, P282, DOI 10.1016/j.annemergmed.2004.08.036; Li L, 2007, STAT MED, V26, P3700, DOI 10.1002/sim.2837; Liu JF, 2006, SCI CHINA SER C, V49, P552, DOI 10.1007/s11427-006-2024-z; Ma JZ, 2007, GENET EPIDEMIOL, V31, P594, DOI 10.1002/gepi.20231; METZLER D, IN PRESS J MATH BIOL; Murphy K., 2001, COMPUTING SCI STAT, V33, P1786; Ohmann C, 1999, ARCH SURG-CHICAGO, V134, P993, DOI 10.1001/archsurg.134.9.993; Rodin AS, 2005, BIOINFORMATICS, V21, P3273, DOI 10.1093/bioinformatics/bti505; Sakellaropoulos GC, 1999, METHOD INFORM MED, V38, P37; Schurink CAM, 2005, LANCET INFECT DIS, V5, P305, DOI 10.1016/S1473-3099(05)70115-8; Toft N, 2007, PREV VET MED, V79, P244, DOI 10.1016/j.prevetmed.2007.01.003; Tzanakis NE, 2005, WORLD J SURG, V29, P1151, DOI 10.1007/s00268-005-7853-6; Wang XH, 1999, INT J MED INFORM, V54, P115, DOI 10.1016/S1386-5056(98)00174-9; Wehberg S, 2004, BIOMETRICAL J, V46, P35, DOI 10.1002/bimj.20041001; Yen AMF, 2006, METHOD INFORM MED, V45, P631	31	17	17	SCHATTAUER GMBH-VERLAG MEDIZIN NATURWISSENSCHAFTEN	STUTTGART	HOLDERLINSTRASSE 3, D-70174 STUTTGART, GERMANY	0026-1270			METHOD INFORM MED	Methods Inf. Med.		2007	46	6					723	726		10.3414/ME9066		4	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	245KW	WOS:000251934500017	
J	Keller, A; Ludwig, N; Comtesse, N; Hildebrandt, A; Meese, E; Lenhof, HP				Keller, Andreas; Ludwig, Nicole; Comtesse, Nicole; Hildebrandt, Andreas; Meese, Eckart; Lenhof, Hans-Peter			A minimally invasive multiple marker approach allows highly efficient detection of meningioma tumors	BMC BIOINFORMATICS			English	Article							OVARIAN-CANCER; CLASSIFICATION; ANTIGENS; SERUM	Background: The development of effective frameworks that permit an accurate diagnosis of tumors, especially in their early stages, remains a grand challenge in the field of bioinformatics. Our approach uses statistical learning techniques applied to multiple antigen tumor antigen markers utilizing the immune system as a very sensitive marker of molecular pathological processes. For validation purposes we choose the intracranial meningioma tumors as model system since they occur very frequently, are mostly benign, and are genetically stable. Results: A total of 183 blood samples from 93 meningioma patients (WHO stages I-III) and 90 healthy controls were screened for seroreactivity with a set of 57 meningioma-associated antigens. We tested several established statistical learning methods on the resulting reactivity patterns using 10-fold cross validation. The best performance was achieved by Naive Bayes Classifiers. With this classification method, our framework, called Minimally Invasive Multiple Marker (MIMM) approach, yielded a specificity of 96.2%, a sensitivity of 84.5%, and an accuracy of 90.3%, the respective area under the ROC curve was 0.957. Detailed analysis revealed that prediction performs particularly well on low-grade (WHO I) tumors, consistent with our goal of early stage tumor detection. For these tumors the best classification result with a specificity of 97.5%, a sensitivity of 91.3%, an accuracy of 95.6%, and an area under the ROC curve of 0.971 was achieved using a set of 12 antigen markers only. This antigen set was detected by a subset selection method based on Mutual Information. Remarkably, our study proves that the inclusion of non-specific antigens, detected not only in tumor but also in normal sera, increases the performance significantly, since non-specific antigens contribute additional diagnostic information. Conclusion: Our approach offers the possibility to screen members of risk groups as a matter of routine such that tumors hopefully can be diagnosed immediately after their genesis. The early detection will finally result in a higher cure- and lower morbidity-rate.	Univ Saarland, Ctr Bioinformat, D-66041 Homburg, Germany; Univ Saarland, Sch Med, Dept Human Genet, D-66421 Homburg, Germany	Lenhof, HP (reprint author), Univ Saarland, Ctr Bioinformat, Bldg 3-11, D-66041 Homburg, Germany.	ack@bioinf.uni-sb.de; lud.nic@arcor.de; hgncom@uniklinik-saarland.de; anhi@bioinf.uni-sb.de; hgemee@uniklinik-saarland.de; lenhof@bioinf.uni-sb.de	Hildebrandt, Andreas/B-5798-2008				Chatterjee M, 2006, CANCER RES, V66, P1181, DOI 10.1158/0008-5472.CAN-04-2962; Comtesse N, 2005, P NATL ACAD SCI USA, V102, P9601, DOI 10.1073/pnas.0500404102; Erkanli A, 2006, CANCER RES, V66, P1792, DOI 10.1158/0008-5472.CAN-05-0669; HASTIE T, 2001, AUG; Kleihues P, 2002, J NEUROPATH EXP NEUR, V61, P215; Koomen JM, 2005, CLIN CANCER RES, V11, P1110; LEE S, 2004, P NATL ACAD SCI USA, V100, P2651; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Scanlan MJ, 2004, CANC IMMUN, V4, P11; Schreiber H, 2002, SEMIN CANCER BIOL, V12, P25, DOI 10.1006/scbi.2001.0401; SHANNON C, 1984, BELL SYST TECH J, V27, P623; SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709; Sidransky D, 2002, NAT REV CANCER, V2, P210, DOI 10.1038/nrc755; SPINNEY L, 2006, AUG, V442, P736; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Vicini FA, 2005, J UROLOGY, V173, P1456, DOI 10.1097/01.ju.0000157323.55611.23; WANG X, 2005, NEW ENGL J MED, V335, P1224; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968	19	17	17	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	DEC 21	2006	7								539	10.1186/1471-2105-7-539		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	125HZ	WOS:000243434300001	
J	Langseth, H; Nielsen, TD				Langseth, H; Nielsen, TD			Classification using Hierarchical Naive Bayes models	MACHINE LEARNING			English	Article						classification; Naive Bayes models; hierarchical models		Classification problems have a long history in the machine learning literature. One of the simplest, and yet most consistently well-performing set of classifiers is the Naive Bayes models. However, an inherent problem with these classifiers is the assumption that all attributes used to describe an instance are conditionally independent given the class of that instance. When this assumption is violated (which is often the case in practice) it can reduce classification accuracy due to "information double-counting" and interaction omission. In this paper we focus on a relatively new set of models, termed Hierarchical Naive Bayes models. Hierarchical Naive Bayes models extend the modeling flexibility of Naive Bayes models by introducing latent variables to relax some of the independence statements in these models. We propose a simple algorithm for learning Hierarchical Naive Bayes models in the context of classification. Experimental results show that the learned models can significantly improve classification accuracy as compared to other frameworks.	Norwegian Univ Sci & Technol, Dept Math Sci, N-7491 Trondheim, Norway; Univ Aalborg, Dept Comp Sci, DK-9220 Aalborg O, Denmark	Langseth, H (reprint author), SINTEF Technol & Soc, N-7465 Trondheim, Norway.	helgel@math.ntnu.no; tdn@cs.auc.dk					Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Blake C. L., 1998, UCI REPOSITORY MACHI; Boutilier C., 1996, P 12 C UNC ART INT U, P115; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Elidan G., 2001, P 17 C UNC ART INT U, P144; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GREINER R, 1997, P 13 C UNC ART INT S, P198; Grossman D., 2004, P 21 INT C MACH LEAR, P361; Jaeger M., 2003, P 20 INT C MACH LEAR, P266; JENSEN F, 2001, BAYESIAN NETWORKS DE; KOCKA T, 2002, P 18 C UNC ART INT U, P267; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Langley P., 1994, P AAAI FALL S REL; LANGLEY P, 1993, LECT NOTES ART INTEL, V667, P153; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MADSEN AL, 1998, P 14 ANN C UNC ART I, P362; MARTIN JD, 1994, LRDCONR941 U PITTSB; Mitchell T.M., 1997, MACHINE LEARNING; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; NG AY, 2002, ADV NEURAL INFORMATI, V15, P841; Pazzani M. J., 1996, LEARNING DATA ARTIFI, P239; PAZZANI MJ, 2006, ISIS INFORMATION STA, P66; Pearl J., 1988, PROBABILISTIC REASON; Quinlan R., 1998, C5 0 INFORMAL TUTORI; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shafer G. R., 1990, ANN MATH ARTIFICIAL, V2, P327, DOI 10.1007/BF01531015; Spirtes P., 1993, CAUSATION PREDICTION; *SPSS INC, 2002, CLEM V6 5; Wettig H., 2003, P 18 INT JOINT C ART, P491; Whittaker J., 1990, GRAPHICAL MODELS APP; Zhang H, 2004, P 17 FLOR ART INT RE, P562; Zhang NL, 2004, J MACH LEARN RES, V5, P697; ZHANG NL, 2003, ARTIF INTELL, V30, P283	43	17	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	MAY	2006	63	2					135	159		10.1007/s10994-006-6136-2		25	Computer Science, Artificial Intelligence	Computer Science	041RE	WOS:000237472600002	
J	Xia, Y; Lu, LJ; Gerstein, M				Xia, Y; Lu, LJ; Gerstein, M			Integrated prediction of the helical membrane protein interactome in yeast	JOURNAL OF MOLECULAR BIOLOGY			English	Article						helical membrane protein; protein-protein interaction; integrated prediction; Naive Bayes; logistic regression	TRANSCRIPTIONAL REGULATORY NETWORKS; GENOME-WIDE ANALYSIS; SACCHAROMYCES-CEREVISIAE; GENETIC INTERACTIONS; BIOLOGICAL MEMBRANE; CELLULAR NETWORKS; EXPRESSION DATA; SCALE; IDENTIFICATION; ANNOTATION	At least a quarter of all genes in most genomes contain putative transmembrane (TM) helices, and helical membrane protein interactions are a major component of the overall cellular interactome. However, current experimental techniques for large-scale detection of protein-protein interactions are biased against membrane proteins. Here, we define protein-protein interaction broadly as co-complexation, and develop a weighted-voting procedure to predict interactions among yeast helical membrane proteins by optimally combining evidence based on diverse genome-wide information such as sequence, function, localization, abundance, regulation, and phenotype. We use logistic regression to simultaneously optimize the weights of all evidence sources for best discrimination based on a set of known helical membrane protein interactions. The resulting integrated classifier not only significantly outperforms classifiers based on any single genomic feature, but also does better than a benchmark Naive Bayes classifier (using a simplifying assumption of conditional independence among features). Finally, we apply the optimized classifier genome-wide, and construct a comprehensive map of predicted helical membrane protein interactome in yeast. This can serve as a guide for prioritizing further experimental validation efforts. (c) 2005 Elsevier Ltd. All rights resented.	Yale Univ, Dept Mol Biophys & Biochem, New Haven, CT 06520 USA; Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA	Gerstein, M (reprint author), Yale Univ, Dept Mol Biophys & Biochem, New Haven, CT 06520 USA.	mark.gerstein@yale.edu					Ashburner M, 2000, NAT GENET, V25, P25; Bork P, 2004, CURR OPIN STRUC BIOL, V14, P292, DOI 10.1016/j.sbi.2004.05.003; Bowers PM, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-5-r35; Breitkreutz BJ, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-3-r23; Cherry JM, 1998, NUCLEIC ACIDS RES, V26, P73, DOI 10.1093/nar/26.1.73; Drawid A, 2000, TRENDS GENET, V16, P426, DOI 10.1016/S0168-9525(00)02108-9; Drawid A, 2000, J MOL BIOL, V301, P1059, DOI 10.1006/jmbi.2000.3968; Eisenberg D, 2000, NATURE, V405, P823, DOI 10.1038/35015694; Enright AJ, 1999, NATURE, V402, P86; FIELDS S, 1989, NATURE, V340, P245, DOI 10.1038/340245a0; Gavin AC, 2002, NATURE, V415, P141, DOI 10.1038/415141a; Ge H, 2001, NAT GENET, V29, P482, DOI 10.1038/ng776; Ge H, 2003, TRENDS GENET, V19, P551, DOI 10.1016/j.tig.2003.08.009; Gerstein M, 1998, PROTEINS, V33, P518, DOI 10.1002/(SICI)1097-0134(19981201)33:4<518::AID-PROT5>3.0.CO;2-J; Greenbaum D, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-9-117; Han JDJ, 2005, NAT BIOTECHNOL, V23, P839, DOI 10.1038/nbt1116; Hartwell LH, 1999, NATURE, V402, pC47, DOI 10.1038/35011540; Ho Y, 2002, NATURE, V415, P180, DOI 10.1038/415180a; Horak CE, 2002, METHOD ENZYMOL, V350, P469; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2002, GENOME RES, V12, P37, DOI 10.1101/gr.205602; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Jeong H, 2001, NATURE, V411, P41, DOI 10.1038/35075138; Jones DT, 1998, FEBS LETT, V423, P281, DOI 10.1016/S0014-5793(98)00095-7; Kall L, 2004, J MOL BIOL, V338, P1027, DOI 10.1016/j.jmb.2004.03.016; Kelley R, 2005, NAT BIOTECHNOL, V23, P561, DOI 10.1038/nbt1096; Krogh A, 2001, J MOL BIOL, V305, P567, DOI 10.1006/jmbi.2000.4315; Kumar A, 2002, NATURE, V415, P123, DOI 10.1038/415123a; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Lehnert U, 2004, Q REV BIOPHYS, V37, P121, DOI 10.1017/S003358350400397X; Lin N, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-154; Lu L, 2003, GENOME RES, V13, P1146, DOI 10.1101/gr.1145203; Lu LJ, 2005, GENOME RES, V15, P945, DOI 10.1101/gr.3610305; Marcotte EM, 1999, NATURE, V402, P83; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Matthews LR, 2001, GENOME RES, V11, P2120, DOI 10.1101/gr.205301; McDermott J, 2005, BIOINFORMATICS, V21, P3217, DOI 10.1093/bioinformatics.bti514; Mewes HW, 2004, NUCLEIC ACIDS RES, V32, pD41, DOI 10.1093/nar/gkh092; Miller JP, 2005, P NATL ACAD SCI USA, V102, P12123, DOI 10.1073/pnas.0505482102; NG AY, 2002, ADV NEURAL INFORM PR, V14, P605; Rives AW, 2003, P NATL ACAD SCI USA, V100, P1128, DOI 10.1073/pnas.0237338100; Russ WP, 1999, P NATL ACAD SCI USA, V96, P863, DOI 10.1073/pnas.96.3.863; Schneider D, 2003, J BIOL CHEM, V278, P3105, DOI 10.1074/jbc.M206287200; Schwikowski B, 2000, NAT BIOTECHNOL, V18, P1257, DOI 10.1038/82360; Stagljar I, 2002, TRENDS BIOCHEM SCI, V27, P559, DOI 10.1016/S0968-0004(02)02197-7; Tamames J, 1997, J MOL EVOL, V44, P66, DOI 10.1007/PL00006122; Tong AHY, 2004, SCIENCE, V303, P808, DOI 10.1126/science.1091317; Troyanskaya OG, 2003, P NATL ACAD SCI USA, V100, P8348, DOI 10.1073/pnas.0832373100; Uetz P, 2000, NATURE, V403, P623; Valencia A, 2002, CURR OPIN STRUC BIOL, V12, P368, DOI 10.1016/S0959-440X(02)00333-0; von Mering C, 2002, NATURE, V417, P399; Walhout AJM, 2000, SCIENCE, V287, P116, DOI 10.1126/science.287.5450.116; Wallin E, 1998, PROTEIN SCI, V7, P1029; Wingender E, 2001, NUCLEIC ACIDS RES, V29, P281, DOI 10.1093/nar/29.1.281; Wong SL, 2004, P NATL ACAD SCI USA, V101, P15682, DOI 10.1073/pnas.0406614101; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Xia Y, 2004, ANNU REV BIOCHEM, V73, P1051, DOI 10.1146/annurev.biochem.73.011303.073950; Yu HY, 2003, TRENDS GENET, V19, P422, DOI 10.1016/S0168-9525(03)00175-6; Yu HY, 2004, NUCLEIC ACIDS RES, V32, P328, DOI 10.1093/nar/gkh164; Yu HY, 2004, GENOME RES, V14, P1107, DOI 10.1101/gr.1774904; Yu HY, 2004, TRENDS GENET, V20, P227, DOI 10.1016/j.tig.2004.04.008; Zhang LV, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-38; Zhu H, 2001, SCIENCE, V293, P2101, DOI 10.1126/science.1062191	64	17	21	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-2836			J MOL BIOL	J. Mol. Biol.	MAR 17	2006	357	1					339	349		10.1016/j.jmb.2005.12.067		11	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	019GP	WOS:000235823900027	
J	Ray, S; Craven, M				Ray, S; Craven, M			Learning statistical models for annotating proteins with function information using biomedical text	BMC BIOINFORMATICS			English	Article							GENE ONTOLOGY; DATABASE; RESOURCE; BIOLOGY	Background: The BioCreative text mining evaluation investigated the application of text mining methods to the task of automatically extracting information from text in biomedical research articles. We participated in Task 2 of the evaluation. For this task, we built a system to automatically annotate a given protein with codes from the Gene Ontology (GO) using the text of an article from the biomedical literature as evidence. Methods: Our system relies on simple statistical analyses of the full text article provided. We learn n-gram models for each GO code using statistical methods and use these models to hypothesize annotations. We also learn a set of Naive Bayes models that identify textual clues of possible connections between the given protein and a hypothesized annotation. These models are used to filter and rank the predictions of the n-gram models. Results: We report experiments evaluating the utility of various components of our system on a set of data held out during development, and experiments evaluating the utility of external data sources that we used to learn our models. Finally, we report our evaluation results from the BioCreative organizers. Conclusion: We observe that, on the test data, our system performs quite well relative to the other systems submitted to the evaluation. From other experiments on the held-out data, we observe that (i) the Naive Bayes models were effective in filtering and ranking the initially hypothesized annotations, and (ii) our learned models were significantly more accurate when external data sources were used during learning.	Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA; Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA	Ray, S (reprint author), Univ Wisconsin, Dept Comp Sci, 1210 W Dayton St, Madison, WI 53706 USA.	sray@cs.wisc.edu; craven@biostat.wisc.edu					Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Camon E, 2004, NUCLEIC ACIDS RES, V32, pD262, DOI 10.1093/nar/gkh021; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DOLINSKI K, 2003, SACCHAROMYCES GENOME; Harris TW, 2004, NUCLEIC ACIDS RES, V32, pD411, DOI 10.1093/nar/gkh066; Huala E, 2001, NUCLEIC ACIDS RES, V29, P102, DOI 10.1093/nar/29.1.102; Mitchell T.M., 1997, MACHINE LEARNING; *NAT LIB MED, 1999, UN MED LANG SYST; PORTER MF, 1980, PROGRAM, V14, P127; Gelbart W, 2003, NUCLEIC ACIDS RES, V31, P172, DOI 10.1093/nar/gkg094; Wain HM, 2002, GENOMICS, V79, P464, DOI 10.1006/geno.2002.6748	12	17	17	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAY 24	2005	6			1					S18	10.1186/1471-2105-6-S1-S18		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	022NB	WOS:000236061400018	
J	Ginter, F; Boberg, J; Jarvinen, J; Salakoski, T				Ginter, F; Boberg, J; Jarvinen, J; Salakoski, T			New techniques for disambiguation in natural language and their application to biological text	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						biological text; gene vs. protein name disambiguation; textual data mining; word sense disambiguation; context-sensitive spelling error correction	ALGORITHM	We study the problems of disambiguation in natural language, focusing on the problem of gene vs. protein name disambiguation in biological text and also considering the problem of context-sensitive spelling error correction. We introduce a new family of classifiers based on ordering and weighting the feature vectors obtained from word counts and word co-occurrence in the text, and inspect several concrete classifiers from this family. We obtain the most accurate prediction when weighting by positions of the words in the context. On the gene/protein name disambiguation problem, this classifier outperforms both the Naive Bayes and SNoW baseline classifiers. We also study the effect of the smoothing techniques with the Naive Bayes classifier, the collocation features, and the context length on the classification accuracy and show that correct setting of the context length is important and also problem-dependent.	Univ Turku, Dept Informat Technol, FIN-20520 Turku, Finland; Turku Ctr Comp Sci, FIN-20520 Turku, Finland	Ginter, F (reprint author), Univ Turku, Dept Informat Technol, Lemminkaisenkatu 14A, FIN-20520 Turku, Finland.	FILIP.GINTER@IT.UTU.FI; JORMA.BOBERG@IT.UTU.FI; JOUNI.JARVINEN@IT.UTU.FI; TAPIO.SALAKOSKI@IT.UTU.FI					Chen S.F., 1998, TR1098 HARV U CTR RE; Cohen WW, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P709; Dubou P. A., 2001, BIOINFORMATICS S1, V17, P97; GALE WA, 1992, COMPUT HUMANITIES, V26, P415, DOI 10.1007/BF00136984; Golding AR, 1999, MACH LEARN, V34, P107, DOI 10.1023/A:1007545901558; Kohavi R., 1997, P 9 EUR C MACH LEARN, P78; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; Manning C.D., 1999, FDN STAT NATURAL LAN; Ng H.T., 1997, P 2 C EMP METH NAT L, P208; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Rose Tony, 2002, P 3 INT C LANG RES E; Yager RR, 1997, ORDERED WEIGHTED AVERAGING OPERATORS, P41; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; Yarowsky David, 1994, P 32 ANN M ASS COMP, P88, DOI 10.3115/981732.981745	15	17	17	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2004	5						605	621				17	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026GP	WOS:000236327700002	
J	Bazell, D; Aha, DW				Bazell, D; Aha, DW			Ensembles of classifiers for morphological galaxy classification	ASTROPHYSICAL JOURNAL			English	Article						galaxies : fundamental parameters; methods : data analysis; methods : numerical	ARTIFICIAL NEURAL NETWORKS; DECISION TREES	We compare the use of three algorithms for performing automated morphological galaxy classification using a sample of 800 galaxies. Classifiers are created using a single training set as well as bootstrap replicates of the training set, producing an ensemble of classifiers. We use a Naive Bayes classifier, a neural network trained with backpropagation, and a decision-tree induction algorithm with pruning. Previous work in the field has emphasized backpropagation networks and decision trees. The Naive Bayes classifier is easy to understand and implement and often works remarkably well on real-world data. For each of these algorithms, we examine the classification accuracy of individual classifiers using 10-fold cross validation and of ensembles of classifiers trained using 25 bootstrap data sets and tested on the same cross-validation test sets. Our results show that (1) the neural network produced the best individual classifiers (lowest classification error) for the majority of cases, (2) the ensemble approach significantly reduced the classification error for the neural network and the decision-tree classifiers but not for the Naive Bayes classifier, (3) the ensemble approach worked better for decision trees (typical error reduction of 12%-23%) than for the neural network (typical error reduction of 7%-12%), and (4) the relative improvement when using ensembles decreases as the number of output classes increases. While more extensive comparisons are needed (e.g., a variety of data and classifiers), our work is the first demonstration that the ensemble approach can significantly increase the performance of certain automated classification methods when applied to the domain of morphological galaxy classification.	Eureka Sci Inc, Columbia, MD 21044 USA; USN, Ctr Appl Res Artificial Intelligence, Res Lab, Washington, DC 20375 USA	Bazell, D (reprint author), Eureka Sci Inc, 6509 Evensong Mews, Columbia, MD 21044 USA.						Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bazell D, 2000, MON NOT R ASTRON SOC, V316, P519, DOI 10.1046/j.1365-8711.2000.03525.x; Breiman L., 1994, 416 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Hertz J., 1991, INTRO THEORY NEURAL; MADDOX SJ, 1990, MON NOT R ASTRON SOC, V243, P692; Mitchell T.M., 1997, MACHINE LEARNING; NAIM A, 1995, MON NOT R ASTRON SOC, V275, P567; ODEWAHN SC, 1992, ASTRON J, V103, P318, DOI 10.1086/116063; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; Owens EA, 1996, MON NOT R ASTRON SOC, V281, P153; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Ricci F., 1998, P 10 EUR C MACH LEAR, P280; Ripley B., 1996, PATTERN RECOGNITION; Rumelhart D., 1986, PARALLEL DISTRIBUTED, V1; SALZBERG S, 1995, PUBL ASTRON SOC PAC, V107, P279, DOI 10.1086/133551; Sejnowski T. J., 1987, Complex Systems, V1; STORRIELOMBARDI MC, 1992, MNRAS, V259, P8; VONHIPPEL T, 1994, MON NOT R ASTRON SOC, V269, P97; Weir N, 1995, PUBL ASTRON SOC PAC, V107, P1243, DOI 10.1086/133683; Witten IH, 1999, DATA MINING	27	17	17	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X			ASTROPHYS J	Astrophys. J.	FEB 10	2001	548	1	1				219	223		10.1086/318696		5	Astronomy & Astrophysics	Astronomy & Astrophysics	401QN	WOS:000166939900018	
J	Kontkanen, P; Myllymaki, P; Silander, T; Tirri, H; Grunwald, P				Kontkanen, P; Myllymaki, P; Silander, T; Tirri, H; Grunwald, P			On predictive distributions and Bayesian networks	STATISTICS AND COMPUTING			English	Article						Bayesian networks; predictive inference; MDL; MML; Jeffreys' prior	PROBABILISTIC INFERENCE; STOCHASTIC COMPLEXITY; INFORMATION	In this paper we are interested in discrete prediction problems for a decision-theoretic setting, where the task is to compute the predictive distribution for a finite set of possible alternatives. This question is first addressed in a general Bayesian framework, where we consider a set of probability distributions defined by some parametric model class. Given a prior distribution on the model parameters and a set of sample data, one possible approach for determining a predictive distribution is to fix the parameters to the instantiation with the maximum a posteriori probability. A more accurate predictive distribution can be obtained by computing the evidence (marginal likelihood), i.e., the integral over all the individual parameter instantiations. As an alternative to these two approaches, we demonstrate how to use Rissanen's new definition of stochastic complexity for determining predictive distributions, and show how the evidence predictive distribution with Jeffrey's prior approaches the new stochastic complexity predictive distribution in the limit with increasing amount of sample data. To compare the alternative approaches in practice, each of the predictive distributions discussed is instantiated in the Bayesian network model family case. In particular, to determine Jeffrey's prior for this model family, we show how to compute the (expected) Fisher information matrix for a fixed but arbitrary Bayesian network structure. In the empirical part of the paper the predictive distributions are compared by using the simple tree-structured Naive Bayes model, which is used in the experiments for computational reasons. The experimentation with several public domain classification datasets suggest that the evidence approach produces the most accurate predictions in the log-score sense. The evidence-based methods are also quite robust in the sense that they predict surprisingly well even when only a small fraction of the full training set is used.	Univ Helsinki, Dept Comp Sci, Complex Syst Computat Grp, FIN-00014 Helsinki, Finland; Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA							BAXTER RA, 1994, 207 MON U DEP COMP S; Berger J.O., 1985, STAT DECISION THEORY; Bernardo J. M., 1994, BAYESIAN THEORY; Blake C. L., 1998, UCI REPOSITORY MACHI; CASTILLO E, 1997, MONOGRAPHS COMPUTER; CLARKE BS, 1994, J STAT PLAN INFER, V41, P37, DOI 10.1016/0378-3758(94)90153-8; CLARKE BS, 1990, IEEE T INFORM THEORY, V36, P453, DOI 10.1109/18.54897; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cover T. M., 1991, ELEMENTS INFORMATION; DeGroot M., 1970, OPTIMAL STAT DECISIO; DOM B, 1995, 9997 RJ IBM RES DIV; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; Geiger D., 1994, MSRTR9416; GRUNWALD P, 1998, THESIS; Grunwald P. D., 1998, P 14 INT C UNC ART I, P183; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Kass R., 1997, GEOMETRICAL FDN ASYM; Kontkanen P., 1997, P 6 INT WORKSH ART I, P311; KONTKANEN P, 1999, P UNC 99 7 INT WORKS, P231; Langley P., 1994, P 10 C UNC ART INT, P399; Michie D., 1994, MACHINE LEARNING NEU; Neapolitan R.E., 1990, PROBABILISTIC REASON; Pearl J., 1988, PROBABILISTIC REASON; Rissanen J., 1989, STOCHASTIC COMPLEXIT; RISSANEN J, 1987, J ROY STAT SOC B MET, V49, P252; RISSANEN J, 1987, J ROY STAT SOC B MET, V49, P223; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; SHACHTER RD, 1988, OPER RES, V36, P589, DOI 10.1287/opre.36.4.589; TAKEUCHI J, 1998, 1998 IEEE INT S INF; THIESSON B, 1995, R952020 AALB U I EL; Tirri H., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Wallace C., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); WALLACE C, 1996, 96254 MON U DEP COMP; WALLACE CS, 1968, COMPUT J, V11, P185; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240	37	17	17	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0960-3174			STAT COMPUT	Stat. Comput.	JAN	2000	10	1					39	54		10.1023/A:1008984400380		16	Computer Science, Theory & Methods; Statistics & Probability	Computer Science; Mathematics	273KN	WOS:000084706600005	
J	Dua, S; Acharya, UR; Chowriappa, P; Sree, SV				Dua, Sumeet; Acharya, U. Rajendra; Chowriappa, Pradeep; Sree, S. Vinitha			Wavelet-Based Energy Features for Glaucomatous Image Classification	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						Biomedical optical imaging; data mining; feature extraction; glaucoma; image texture; wavelet transforms	AUTOMATED DIAGNOSIS; DISEASE	Texture features within images are actively pursued for accurate and efficient glaucoma classification. Energy distribution over wavelet subbands is applied to find these important texture features. In this paper, we investigate the discriminatory potential of wavelet features obtained from the daubechies (db3), symlets (sym3), and biorthogonal (bio3.3, bio3.5, and bio3.7) wavelet filters. We propose a novel technique to extract energy signatures obtained using 2-D discrete wavelet transform, and subject these signatures to different feature ranking and feature selection strategies. We have gauged the effectiveness of the resultant ranked and selected subsets of features using a support vector machine, sequential minimal optimization, random forest, and naive Bayes classification strategies. We observed an accuracy of around 93% using tenfold cross validations to demonstrate the effectiveness of these methods.	[Dua, Sumeet; Chowriappa, Pradeep] Louisiana Tech Univ, Comp Sci Program, Ruston, LA 71272 USA; [Acharya, U. Rajendra] Ngee Ann Polytech, Dept Elect & Commun Engn, Singapore 599489, Singapore; [Sree, S. Vinitha] Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore 639798, Singapore	Dua, S (reprint author), Louisiana Tech Univ, Comp Sci Program, Ruston, LA 71272 USA.	sdua@coes.latech.edu; aru@np.edu.sg; pradeep@latech.edu; vinithasree@ntu.edu.sg					Acharya UR, 2011, IEEE T INF TECHNOL B, V15, P449, DOI 10.1109/TITB.2011.2119322; [Anonymous], 2010, GLAUCOMA GUIDE; Arivazhagan A., 2003, PATTERN RECOGN LETT, V24, P1513; Balasubramanian M, 2010, INVEST OPHTH VIS SCI, V51, P264, DOI 10.1167/iovs.08-2014; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown B, 2008, CLIN EXP OPTOM, V91, P504, DOI 10.1111/j.1444-0938.2008.00322.x; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Daubechies I., 1992, 10 LECT WAVELETS; Dua S., 2011, COMPUTATIONAL ANAL H; Duncan RO, 2007, INVEST OPHTH VIS SCI, V48, P733, DOI 10.1167/iovs.06-0773; Dunham M.H., 2002, DATA MINING INTRO AD; Essock EA, 2005, INVEST OPHTH VIS SCI, V46, P2838, DOI 10.1167/iovs.04-1156; Furcy D., 2005, P INT JOINT C ART IN, P125; George R, 2010, J GLAUCOMA, V19, P391, DOI 10.1097/IJG.0b013e3181c4ac5b; Goldberg D., 1989, GENETIC ALGORITHMS S; Gonzalez R. F., 2001, DIGITAL IMAGE PROCES; Phillips A., 1985, SIGKDD EXPLORATIONS, V31, P329, DOI DOI 10.1145/1656274.1656278; Huang K, 2008, IEEE T IMAGE PROCESS, V17, P1709, DOI 10.1109/TIP.2008.2001050; JOHN GH, 1995, P 11 C UNC ART INT, P338; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kira K., 1992, P 9 INT C MACH LEARN, P249; Liu H, 1996, P 13 INT C MACH LEAR, P319; Miquel-Jimenez J. M., 2010, MED ENG PHYS, V32, P617; Nayak J, 2009, J MED SYST, V33, P337, DOI 10.1007/s10916-008-9195-z; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Setiono R., 1995, P IEEE 7 INT C TOOLS, P338; Sung K. R., 2010, BR J OPHTHALMOL; Varma Rohit, 2008, Am J Manag Care, V14, pS15; Weiss S., 1978, COMPUT BIOL MED, V8, P24; WEISS SM, 1978, ARTIF INTELL, V11, P145, DOI 10.1016/0004-3702(78)90015-2	31	16	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771			IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	JAN	2012	16	1					80	87		10.1109/TITB.2011.2176540		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	892AX	WOS:000300260000010	
J	Gosangi, R; Gutierrez-Osuna, R				Gosangi, Rakesh; Gutierrez-Osuna, Ricardo			Active Temperature Programming for Metal-Oxide Chemoresistors	IEEE SENSORS JOURNAL			English	Article						Active sensing; hidden Markov models; metal-oxide (MOX) sensors; partially observable Markov decision processes (POMDP)	HOTPLATE GAS SENSORS; OBJECT RECOGNITION; MODULATION; LOCALIZATION; OPTIMIZATION; SEQUENCES; VISION; MODELS	Modulating the operating temperature of metal-oxide (MOX) chemical sensors gives rise to gas-specific signatures that provide a wealth of analytical information. In most cases, the operating temperature is modulated according to a standard waveform (e.g., ramp, sine wave). A few studies have approached the optimization of temperature profiles systematically, but these optimizations are performed offline and cannot adapt to changes in the environment. Here, we present an "active perception" strategy based on Partially Observable Markov Decision Processes (POMDP) that allows the temperature program to be optimized in real time, as the sensor reacts to its environment. We characterize the method on a ternary classification problem using a simulated sensor model subjected to additive Gaussian noise, and compare it against two "passive" approaches, a naive Bayes classifier and a nearest neighbor classifier. Finally, we validate the method in real time using a Taguchi sensor exposed to three volatile compounds. Our results show that the POMDP outperforms both passive approaches and provides a strategy to balance classification performance and sensing costs.	[Gosangi, Rakesh; Gutierrez-Osuna, Ricardo] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA	Gosangi, R (reprint author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.	rakesh@cse.tamu.edu; rgutier@cse.tamu.edu					Aloimonos J., 1988, INT J COMPUT VISION, V1, P333, DOI 10.1007/BF00133571; Arbel T, 2001, IMAGE VISION COMPUT, V19, P779, DOI 10.1016/S0262-8856(00)00103-7; Bajcsy R., 1988, Proceedings of the IEEE, V76, DOI 10.1109/5.5968; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; Bengio Y., 1995, ADV NEURAL INFORMATI, V7, P427; Ionescu R, 2003, SENSOR ACTUAT B-CHEM, V95, P203, DOI 10.1016/S0925-4005(03)00420-9; Clifford P.K., 1982, SENSOR ACTUATOR, V3, P255; de Croon GCHE, 2009, IMAGE VISION COMPUT, V27, P374, DOI 10.1016/j.imavis.2008.06.004; Denzler J, 2002, IEEE T PATTERN ANAL, V24, P145, DOI 10.1109/34.982896; Diamond D, 2008, CHEM REV, V108, P652, DOI 10.1021/cr0681187; Ding JH, 2001, SENSOR ACTUAT B-CHEM, V77, P597, DOI 10.1016/S0925-4005(01)00765-1; Fox D, 1998, ROBOT AUTON SYST, V25, P195, DOI 10.1016/S0921-8890(98)00049-9; Fukunaga K., 1990, INTRO STAT PATTERN R; Gibson J. J., 1979, ECOLOGICAL APPROACH; GOSANGI R, 2009, P 13 INT S OLF EL NO; Gutierrez-Osuna R, 2002, IEEE SENS J, V2, P189, DOI 10.1109/JSEN.2002.800688; Hierlemann A, 2008, CHEM REV, V108, P563, DOI 10.1021/cr068116m; Huang XJ, 2004, SENSOR ACTUAT B-CHEM, V99, P444, DOI 10.1016/j.snb.2003.12.013; Ji SH, 2007, PATTERN RECOGN, V40, P1474, DOI 10.1016/j.patcog.2006.11.008; John G., 1994, P 11 INT C MACH LEAR, P121; Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X; Kittler J., 1978, Pattern Recognition and Signal Processing; Kreucher C, 2005, SIGNAL PROCESS, V85, P607, DOI 10.1016/j.sigpro.2004.11.004; Kunt TA, 1998, SENSOR ACTUAT B-CHEM, V53, P24, DOI 10.1016/S0925-4005(98)00244-5; Lee AP, 1999, SENSOR ACTUAT B-CHEM, V60, P35, DOI 10.1016/S0925-4005(99)00241-5; Llobet E, 2001, SENSOR ACTUAT B-CHEM, V77, P275, DOI 10.1016/S0925-4005(01)00710-9; Mihaylova L., 2002, P 5 INT C NUM METH A, P316; Mitchell T.M., 1997, MACHINE LEARNING; Nakamoto T., 1995, Sensors and Actuators A (Physical), VA50, DOI 10.1016/0924-4247(96)80108-7; Nakata S, 2001, SENSOR ACTUAT B-CHEM, V76, P436, DOI 10.1016/S0925-4005(01)00652-9; NEFIAN AV, 2002, EURASIP J APPL SIG P, P1274; Ortega A, 2001, SENSOR ACTUAT B-CHEM, V78, P32, DOI 10.1016/S0925-4005(01)00788-2; Paletta L, 2000, ROBOT AUTON SYST, V31, P71, DOI 10.1016/S0921-8890(99)00079-2; PAPADIMITRIOU CH, 1987, MATH OPER RES, V12, P441, DOI 10.1287/moor.12.3.441; Priebe CE, 2004, IEEE T PATTERN ANAL, V26, P699, DOI 10.1109/TPAMI.2004.12; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; Sipe MA, 2002, IEEE T PATTERN ANAL, V24, P1634, DOI 10.1109/TPAMI.2002.1114854; Vergara A, 2005, SENSOR ACTUAT B-CHEM, V111, P271, DOI 10.1016/j.snb.2005.06.039; Vergara A, 2005, IEEE SENS J, V5, P1369, DOI 10.1109/JSEN.2005.855605; Waagen D, 2004, Proceedings of the 2004 Intelligent Sensors, Sensor Networks & Information Processing Conference, P295; WLODEK S, 1991, SENSOR ACTUAT B-CHEM, V3, P63, DOI 10.1016/0925-4005(91)85008-7; Zhang SP, 2009, SENSOR ACTUAT B-CHEM, V135, P552, DOI 10.1016/j.snb.2008.10.021; Zhou HJ, 2007, ROBOT AUTON SYST, V55, P292, DOI 10.1016/j.robot.2006.11.005	43	16	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1530-437X	1558-1748		IEEE SENS J	IEEE Sens. J.	JUN	2010	10	6					1075	1082		10.1109/JSEN.2010.2042165		8	Engineering, Electrical & Electronic; Instruments & Instrumentation; Physics, Applied	Engineering; Instruments & Instrumentation; Physics	580BK	WOS:000276421600007	
J	Maglogiannis, I; Loukis, E; Zafiropoulos, E; Stasis, A				Maglogiannis, Ilias; Loukis, Euripidis; Zafiropoulos, Elias; Stasis, Antonis			Support Vectors Machine-based identification of heart valve diseases using heart sounds	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Review						Biosignal processing; Heart sounds; Heart valve diseases; Automated diagnosis; Support Vector Machines	CORONARY-ARTERY DISEASE; MATCHING PURSUIT METHOD; CARDIAC AUSCULTATION; SPECTRAL-ANALYSIS; FREQUENCY-ANALYSIS; INTERVAL FEATURES; ECG MORPHOLOGY; DIAGNOSIS; SYSTEM; CLASSIFICATION	Taking into account that heart auscultation remains the dominant method for heart examination in the small health centers of the rural areas and generally in primary healthcare set-ups, the enhancement of this technique would aid significantly in the diagnosis of heart diseases. In this context, the present paper initially surveys the research that has been conducted concerning the exploitation of heart sound signals for automated and semi-automated detection of pathological heart conditions. Then it proposes an automated diagnosis system for the identification of heart valve diseases based on the Support Vector Machines (SVM) classification of heart sounds. This system performs a highly difficult diagnostic task (even for experienced physicians), much more difficult than the basic diagnosis of the existence or not of a heart valve disease (i.e. the classification of a heart sound as 'healthy' or 'having a heart valve disease'): it identifies the particular heart valve disease. The system was applied in a representative global dataset of 198 heart sound signals, which come both from healthy medical cases and from cases suffering from the four most usual heart valve diseases: aortic stenosis (AS), aortic regurgitation (AR), mitral stenosis (MS) and mitral regurgitation (MR). Initially the heart sounds were successfully categorized using a SVM classifier as normal or disease-related and then the corresponding murmurs in the unhealthy cases were classified as systolic or diastolic. For the heart sounds diagnosed as having systolic murmur we used a SVM classifier for performing a more detailed classification of them as having aortic stenosis or mitral regurgitation. Similarly for the heart sounds diagnosed as having diastolic murmur we used a SVM classifier for classifying them as having aortic regurgitation or mitral stenosis. Alternative classifiers have been applied to the same data for comparison (i.e. back-propagation neural networks, k-nearest-neighbour and naive Bayes classifiers), however their performance for the same diagnostic problems was lower than the SVM classifiers proposed in this work. (C) 2009 Elsevier Ireland Ltd. All rights reserved.	[Maglogiannis, Ilias] Univ Cent Greece, Dept Comp Sci & Biomed Informat, Lamia 35100, Greece; [Loukis, Euripidis; Zafiropoulos, Elias; Stasis, Antonis] Univ Aegean, Dept Informat & Commun Syst Engn, GR-83200 Karlovassi, Samos, Greece	Maglogiannis, I (reprint author), Univ Cent Greece, Dept Comp Sci & Biomed Informat, Papasiopoulou 2-4, Lamia 35100, Greece.	imaglo@ucg.gr					Ahlstrom C, 2006, ANN BIOMED ENG, V34, P1666, DOI 10.1007/s10439-006-9187-4; AKAY M, 1992, BIOL CYBERN, V67, P361, DOI 10.1007/BF02414891; AKAY YM, 1994, IEEE ENG MED BIOL, V13, P761, DOI 10.1109/51.334639; Anand RS, 2005, COMPUT ELECTR ENG, V31, P166, DOI 10.1016/j.compeleceng.2003.01.003; Arslan O, 2003, TURK J HEMATOL, V20, P7; BAHADIRLAR Y, 1994, P 16 ANN INT C IEEE, V2, P1278; Boser B., 1992, P 5 ANN WORKSH COMP, V21, P144, DOI DOI 10.1145/130385.130401; BRUSCO M, 2005, P 2005 IEEE ENG MED, V4, P3506; CABLE C, 1997, AUSCULTATION ASSISTA; Campadelli P, 2006, IEEE T MED IMAGING, V25, P1588, DOI 10.1109/TMI.2006.884198; CATHERS I, 1995, ARTIF INTELL MED, V7, P53, DOI 10.1016/0933-3657(94)00026-O; Charleston S, 1997, IEEE T BIO-MED ENG, V44, P1006, DOI 10.1109/10.634652; Chauhan S, 2008, COMPUT BIOL MED, V38, P221, DOI 10.1016/j.compbiomed.2007.10.006; Chen D, 1997, MED BIOL ENG COMPUT, V35, P311, DOI 10.1007/BF02534082; Chen DM, 1996, AM J CARDIOL, V78, P785, DOI 10.1016/S0002-9149(96)00422-5; Comak E, 2007, COMPUT BIOL MED, V37, P21, DOI 10.1016/j.compbiomed.2005.11.002; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CRILEY JM, 1995, PHYSL ORIGINS HEART; Criley SR, 2000, COMPUT CARDIOL, V27, P591; Debbal S. M., 2004, Journal of Medical Engineering & Technology, V28, P151, DOI 10.1080/0309190031000111362; de Chazal P, 2006, IEEE T BIO-MED ENG, V53, P2535, DOI 10.1109/TBME.2006.883802; de Chazal P, 2004, IEEE T BIO-MED ENG, V51, P1196, DOI 10.1109/TBME.2004.827359; DEGROFF C, 2005, ARTIF INTELL, V33, P251; DeGroff CG, 2001, CIRCULATION, V103, P2711; de Vos JP, 2007, IEEE T BIO-MED ENG, V54, P244, DOI 10.1109/TBME.2006.886660; DJEBBARI A, 2000, 7 IEEE INT C EL CIRC, P844; Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278; DURAND LG, 1993, MED BIOL ENG COMPUT, V31, P229, DOI 10.1007/BF02458041; ERGEN B, 2001, P 23 ANN INT C IEEE, V3, P2139; ERICSON B, 1997, HEART SOUNDS MURMURS; Fan Y, 2007, IEEE T MED IMAGING, V26, P93, DOI 10.1109/TMI.2006.886812; Flores-Tapia D, 2007, IEEE T BIO-MED ENG, V54, P234, DOI 10.1109/TBME.2006.886935; Fritzsche D, 2005, J HEART VALVE DIS, V14, P657; Garg AX, 2005, JAMA-J AM MED ASSOC, V293, P1223, DOI 10.1001/jama.293.10.1223; GLASS L, 1997, VIRTUAL STETHOSCOPE; Gupta CN, 2007, APPL SOFT COMPUT, V7, P286, DOI 10.1016/j.asoc.2005.06.006; Hadjileontiadis LJ, 1998, INT J MED INFORM, V52, P183, DOI 10.1016/S1386-5056(98)00137-3; HAGEN MD, 1995, PRIMARY CARE, V22, P213; HaghighiMood A, 1995, COMPUT CARDIOL, P501, DOI 10.1109/CIC.1995.482711; HAGHIGHIMOOD A, 1995, IEE C SIGN PROC CARD; Hayek C. Scott, 2003, Biomedical Instrumentation & Technology, V37, P263; Hebden JE, 1997, COMPUT CARDIOL, V24, P109; HEBDEN JE, 1996, PROC IEE C; Herold J, 2005, MED BIOL ENG COMPUT, V43, P451, DOI 10.1007/BF02344725; Higuchi K., 2006, Journal of Medical Engineering & Technology, V30, P61, DOI 10.1080/03091900500131110; Hsu Chih-Wei, 2002, IEEE T NEURAL NETWOR, V13; Hult P, 2004, MED BIOL ENG COMPUT, V42, P253, DOI 10.1007/BF02344639; JANDRE FC, 1997, P 19 INT C IEEE EMBS, V4, P1642, DOI 10.1109/IEMBS.1997.757032; JINGANG W, 2005, P ANN INT C IEEE ENG, V2, P2138; KARATZAS N, 1974, 12 RECORDED LESSONS; Kim SH, 1998, YONSEI MED J, V39, P302; KOCABASOGLU YE, 1998, HUMAN HEART SOUNDS; Lanning C, 2003, MED BIOL ENG COMPUT, V41, P416, DOI 10.1007/BF02348084; LEUNG TS, 2000, P 22 ANN INT C IEEE, V2, P988, DOI 10.1109/IEMBS.2000.897889; Leung T. S., 1998, Proceedings of the 20th Annual International Conference of the IEEE Engineering in Medicine and Biology Society. Vol.20 Biomedical Engineering Towards the Year 2000 and Beyond (Cat. No.98CH36286), DOI 10.1109/IEMBS.1998.747218; LEUNG TS, 1999, P 21 ANN INT C IEEE, P926; Liang H, 1997, COMPUT CARDIOL, V24, P105; LIANG H, 1997, P 19 ANN INT C IEEE, V4, P1630, DOI 10.1109/IEMBS.1997.757028; LITTMAN, 1999, 20 EXAMPLES CARDIAC; Lukkarinen S, 1997, COMPUT CARDIOL, V24, P117; Messer SR, 2001, MICROELECTR J, V32, P931, DOI 10.1016/S0026-2692(01)00095-7; Mitchell T.M., 1997, MACHINE LEARNING; Myint W. W., 2001, P 33 IEEE SE S SYST; Nakamitsu T, 1996, PROCEEDINGS OF THE 1996 FIFTEENTH SOUTHERN BIOMEDICAL ENGINEERING CONFERENCE, P365, DOI 10.1109/SBEC.1996.493227; NOPONEN AL, 2000, COMPUT CARDIOL, V25, P561; Nygaard H, 1993, J Heart Valve Dis, V2, P454; O'Rourke RA, 2000, CURR PROB CARDIOLOGY, V25, P786; Pavlopoulos S, 2004, BIOMEDICAL ENG O JUN, P1; POPOV B, 2004, P INT C IEEE ENG MED, V2, P921; POURAZAD M, 2005, P C IEEE ENG MED BIO, V3, P2736; Reed TR, 2004, SIMUL MODEL PRACT TH, V12, P129, DOI 10.1016/j.simpat.2003.11.005; REYNOLDS KJ, 1995, J ACOUST SOC AM, V98, P60, DOI 10.1121/1.413654; Roy Douglas, 2002, J Contin Educ Health Prof, V22, P152, DOI 10.1002/chp.1340220304; SAVA HP, 1995, P ENG MED BIOL SOC M, V1, P129, DOI 10.1109/IEMBS.1995.575034; STASIS A, 2003, THESIS NATL TU ATHEN; *STUD INT MED SOC, CLASS 2000 CARD HEAR; Sugiki Hiroshi, 2006, J Artif Organs, V9, P42, DOI 10.1007/s10047-005-0319-7; Tateishi O, 2001, J Cardiol, V38, P255; Tavel ME, 2006, CIRCULATION, V113, P1255, DOI 10.1161/CIRCULATIONAHA.105.591149; TINATI MA, 1996, P INT S SIGN PROC IT, V2, P815; TOVARCORONA B, 1998, COMPUT CARDIOL, V13, P601; Tovar-Corona B., 2001, Computers in Cardiology 2001. Vol.28 (Cat. No.01CH37287), DOI 10.1109/CIC.2001.977691; Turkoglu I, 2002, EXPERT SYST APPL, V23, P229, DOI 10.1016/S0957-4174(02)00042-8; Turkoglu I, 2003, COMPUT BIOL MED, V33, P319, DOI 10.1016/S0010-4825(03)00002-7; Uguz H, 2007, PATTERN RECOGN LETT, V28, P395, DOI 10.1016/j.patrec.2006.08.009; *VA MAR REG COLL V, VMRCVM CLASS 2002; Vapnik V., 1998, STAT LEARNING THEORY; Vogel-Claussen J, 2006, RADIOGRAPHICS, V26, P1769, DOI 10.1148/rg.266065035; Voss A, 2005, ANN BIOMED ENG, V33, P1167, DOI 10.1007/s10439-005-5347-x; Vukanovic-Criley JM, 2006, ARCH INTERN MED, V166, P610, DOI 10.1001/archinte.166.6.610; WANG P, 2005, P 19 ANN INT C IEEE, V5, P5519; Wang W, 2001, MED BIOL ENG COMPUT, V39, P644, DOI 10.1007/BF02345436; White PR, 1996, PROCEEDINGS OF THE IEEE-SP INTERNATIONAL SYMPOSIUM ON TIME-FREQUENCY AND TIME-SCALE ANALYSIS, P385, DOI 10.1109/TFSA.1996.550073; Witten Ian H., 2005, DATA MINING PRACTICA; WU CH, 1995, P IEEE INT C AC SPEE, V5, P3458; WU CH, 1997, J CHINESE I ELECT E, V4, P343; WU Y, 1995, P IEEE 17 ANN C ENG, P131; Xu J, 2002, HEART, V88, P76, DOI 10.1136/heart.88.1.76; Xu Shilin, 1994, Proceedings of the IEEE International Conference on Industrial Technology (Cat. No.94TH0659-3), DOI 10.1109/ICIT.1994.467056; XUESONG Y, 1998, P 20 ANN INT C IEEE, V3, P1546, DOI 10.1109/IEMBS.1998.747183; Zhang X, 1998, IEEE T BIO-MED ENG, V45, P962; 1998, FRONTIERS BIOSCIENCE	102	16	24	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607			COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	JUL	2009	95	1					47	61		10.1016/j.cmpb.2009.01.003		15	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	447JR	WOS:000266187900005	
J	Perez, A; Larranaga, P; Inza, I				Perez, Aritz; Larranaga, Pedro; Inza, Inaki			Bayesian classifiers based on kernel density estimation: Flexible classifiers	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						Bayesian network; Kernel density estimation; Supervised classification; Flexible naive Bayes	NETWORK CLASSIFIERS; CLASSIFICATION; EQUIVALENCE; VARIANCE; MIXTURES; BIAS	When learning Bayesian network based classifiers continuous variables are usually handled by discretization, or assumed that they follow a Gaussian distribution. This work introduces the kernel based Bayesian network paradigm for supervised classification. This paradigm is a Bayesian network which estimates the true density of the continuous variables using kernels. Besides, tree-augmented naive Bayes, k-dependence Bayesian classifier and complete graph classifier are adapted to the novel kernel based Bayesian network paradigm. Moreover, the strong consistency properties of the presented classifiers are proved and an estimator of the mutual information based on kernels is presented. The classifiers presented in this work can be seen as the natural extension of the flexible naive Bayes classifier proposed by John and Langley [G.H. John, P. Langley, Estimating continuous distributions in Bayesian classifiers, in: Proceedings of the 11th Conference on Uncertainty in Artificial Intelligence, 1995, pp. 338-345], breaking with its strong independence assumption. Flexible tree-augmented naive Bayes seems to have superior behavior for supervised classification among the flexible classifiers. Besides, flexible classifiers presented have obtained competitive errors compared with the state-of-the-art classifiers. (C) 2008 Elsevier Inc. All rights reserved.	[Perez, Aritz; Larranaga, Pedro; Inza, Inaki] Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, Madrid, Spain	Perez, A (reprint author), Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, Madrid, Spain.	aritz.perez@ehu.es; pedro.larranaga@ehu.es; inza@si.ehu.es	Larranaga, Pedro/F-9293-2013		Etortek, Saiotek and Research Groups [2007-2012 (IT-242-07)]; Basque Goverment [TIN2005-03824]; Consolider Ingenio [2010-CSD2007-00018]; Spanish Ministry of Education and Science; COMBIOMED	First, thanks to the helpful comments of the anonymous reviewers which have improved the quality of the paper. This work has been possible thanks to the Ph.D. grant Beca para la Formacion de Investigadores 2003-07 of the Basque Government. This work has been also supported by the Etortek, Saiotek and Research Groups 2007-2012 (IT-242-07) programs (Basque Goverment), TIN2005-03824 and Consolider Ingenio 2010-CSD2007-00018 projects (Spanish Ministry of Education and Science) and COMBIOMED network in computational biomedicine (Carlos III Health Institute).	ALADJEM M, 2002, LECT NOTES COMPUTER, V2396, P396; Aladjem M, 2005, IEEE T SIGNAL PROCES, V53, P4376, DOI 10.1109/TSP.2005.857007; Bilmes J.A., 1997, ICSITR97021 U BERK; Bishop C. M., 1999, LEARNING GRAPHICAL M, P371; Bishop CM, 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOTTCHER SG, 2004, THESIS AALBORG U; BOUCKAERT R, 2004, P 17 AUSTR C ART INT, P1089; Casella G, 1990, STAT INFERENCE; Castillo E., 1997, EXPERT SYSTEMS PROBA; Cheng J., 1999, P 15 C UNC ART INT U, P101; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cormen T., 2003, INTRO ALGORITHMS; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeGroot M., 1970, OPTIMAL STAT DECISIO; DELAIGLE A, 2002, COMPUTATIONAL STAT D, V39, P1; Demsar J, 2006, J MACH LEARN RES, V7, P1; DEVROYE L, 1983, ANN STAT, V11, P896, DOI 10.1214/aos/1176346255; Diamantidis NA, 2000, ARTIF INTELL, V116, P1, DOI 10.1016/S0004-3702(99)00094-6; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Duda R., 1973, PATTERN CLASSIFICATI; Duda R. O., 2000, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; FIGUEIREDO MAT, 1999, LECT NOTES COMPUTER, V1654, P732; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FUKUNAGA K, 1972, STAT PATTERN RECOGNI; Geiger D., 1994, LEARNING GAUSSIAN NE; German S., 1992, NEURAL COMPUT, V4, P1; Goldberg D., 1989, GENETIC ALGORITHMS S; GREINER R, 2005, MACH LEARN, V59, P97; GURWICZ Y, 2004, P 17 INT C PATT REC, V3, P700, DOI 52224783,12,1; Gurwicz Y, 2005, PATTERN RECOGN LETT, V26, P1761, DOI 10.1016/j.patrec.2004.12.008; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Jebara T., 2004, MACHINE LEARNING DIS; JOHN GH, 1995, P 11 C UNC ART INT, P338; Kohavi R, 1995, INT JOINT C ART INT, V14, P1137; Kohavi R., 1996, ICML, P275; KOHAVI R, 1997, IMPROVING SIMPLE BAY; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, THESIS STANFORD U; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1992, P 10 NAT C ART INT, P223; Larranaga P., 2002, ESTIMATION DISTRIBUT; Lauritzen S. L., 1996, GRAPHICAL MODELS; LAURITZEN SL, 1989, ANN STAT, V17; LAURITZEN SL, 1984, 848 AALB U I EL SYST; Lerner B, 2004, ARTIF INTELL MED, V30, P301, DOI 10.1016/j.artmed.2003.11.005; Lerner B, 2001, NEURAL COMPUT APPL, V10, P39, DOI 10.1007/s005210170016; McLachlan G., 2000, FINITE MIXTURE MODEL; Minsky M., 1961, T I RADIO ENG, V49, P8; MOON YI, 1995, PHYS REV E, V52, P2318, DOI 10.1103/PhysRevE.52.2318; MORAL S, 2002, 1 EUR WHORKSH PROB G, P156; Murphy P. M., 1995, UCI REPOSITORY MACHI; Neapolitan RE, 2003, LEARNING BAYESIAN NE; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PAZZANI M, 1997, LEARNING DATA ARTIFI, V5, P239; Pearl J., 1988, PROBABILISTIC REASON; Perez A, 2006, LECT NOTES ARTIF INT, V4265, P347; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; Raudys S., 1991, Informatica, V2; Romero V, 2006, INT J APPROX REASON, V42, P54, DOI 10.1016/j.ijar.2005.10.004; Roos T, 2005, MACH LEARN, V59, P267; Rosenblatt F., 1959, PRINCIPLES NEURODYNA; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; SANTAFE G, 2005, P 8 EUR C SYMB QUANT, P148; Scott D. W., 1992, MULTIVARIATE DENSITY; Scott DW, 2001, TECHNOMETRICS, V43, P323, DOI 10.1198/004017001316975916; Silverman B. W., 1986, DENSITY ESTIMATION S; Simonoff JS, 1996, SMOOTHING METHODS ST; Van der Putten P, 2004, MACH LEARN, V57, P177, DOI 10.1023/B:MACH.0000035476.95130.99; Wand MP, 1995, MONOGRAPHS STAT APPL; Witten IH, 2005, DATA MINING PRACTICA; YANG Y, 2003, 2003131 MON U SCH CO; Zhou A., 2003, P 8 INT C DAT SYST A, P285	82	16	21	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X			INT J APPROX REASON	Int. J. Approx. Reasoning	FEB	2009	50	2					341	362		10.1016/j.ijar.2008.08.008		22	Computer Science, Artificial Intelligence	Computer Science	421LD	WOS:000264359500014	
J	Krause, A; Guestrin, C				Krause, Andreas; Guestrin, Carlos			Optimal Value of Information in Graphical Models	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							COMPLEXITY	Many real-world decision making tasks require us to choose among several expensive observations. In a sensor network, for example, it is important to select the subset of sensors that is expected to provide the strongest reduction in uncertainty. In medical decision making tasks, one needs to select which tests to administer before deciding on the most effective treatment. It has been general practice to use heuristic-guided procedures for selecting observations. In this paper, we present the first efficient optimal algorithms for selecting observations for a class of probabilistic graphical models. For example, our algorithms allow to optimally label hidden variables in Hidden Markov Models (HMMs). We provide results for both selecting the optimal subset of observations, and for obtaining an optimal conditional observation plan. Furthermore we prove a surprising result: In most graphical models tasks, if one designs an efficient algorithm for chain graphs, such as HMMs, this procedure can be generalized to polytree graphical models. We prove that the optimizing value of information is NP(PP)-hard even for polytrees. It also follows from our results that just computing decision theoretic value of information objective functions, which are commonly used in practice, is a # P-complete problem even on Naive Bayes models (a simple special case of polytrees). In addition, we consider several extensions, such as using our algorithms for scheduling observation selection for multiple sensors. We demonstrate the effectiveness of our approach on several real-world datasets, including a prototype sensor network deployment for energy conservation in buildings.	[Krause, Andreas] CALTECH, Pasadena, CA 91125 USA; [Guestrin, Carlos] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Krause, A (reprint author), CALTECH, 1200 E Calif Blvd, Pasadena, CA 91125 USA.	KRAUSEA@CALTECH.EDU; GUESTRIN@CS.CMU.EDU					Abrams Z., 2004, IPSN; BALCAN N, 2006, ICML; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; BAYERZUBEK V, 2004, UAI; Bellman R., 1957, J MATH MECH, V6; BILGIC M, 2007, 22 C ART INT AAAI; Boyd S., 2004, CONVEX OPTIMIZATION; BOYEN X, 1998, UNCERTAINTY ARTIFICI; Chaloner K, 1995, STAT SCI, V10, P273, DOI 10.1214/ss/1177009939; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; *CONLL, 2003, C COMP NAT LANG LEAR; Cover T. M., 1991, ELEMENTS INFORM THEO; DASGUPTA S, 2005, NIPS; Deshpande A., 2004, VLDB; Deshpande A., 2008, LATIN; DITTMER SL, 1997, UNCERTAINTY ARTIFICI, P142; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Mitchison G., 1999, BIOL SEQUENCE ANAL P; GITTINS JC, 1979, BIOMETRIKA, V66, P561; GOLDBERG L, 2000, LMS J COMPUT MATH, V3, P117; Littman ML, 1998, J ARTIF INTELL RES, V9, P1; HECKERMAN D, 1993, IEEE T PATTERN ANAL, V15, P292, DOI 10.1109/34.204912; HOWARD R, 1966, IEEE T SYSTEMS SCI C, V2; HOWARD RA, 1984, READINGS PRINCIPLES, V2, P127; Ji SH, 2007, IEEE T SIGNAL PROCES, V55, P2720, DOI 10.1109/TSP.2007.893747; Kapoor A., 2007, INT JOINT C ART INT; Keeney R., 1976, DECISIONS MULTIPLE O; KO CW, 1995, OPER RES, V43, P684, DOI 10.1287/opre.43.4.684; KOLLAR T, 2008, AAAI; KOUSHANFARY F, 2006, INFOCOM; KRAUSE A, 2007, JMLR; KRAUSE A, 2006, P UNC ART INT UAI; KRAUSE A, 2005, P IJCAI; Krause A., 2008, J WATER RESOURCES PL, V136, P6; Lafferty J., 2001, ICML; Lerner U., 2001, UAI; LINDLEY DV, 1956, ANN MATH STAT, V27, P986, DOI 10.1214/aoms/1177728069; MOLINA L, 2002, ICDM; Mookerjee VS, 1997, IEEE T KNOWL DATA EN, V9, P675, DOI 10.1109/69.634747; MUNIE M, 2008, 23 C ART INT AAAI; Papadimitriou C., 1995, COMPUTATIONAL COMPLE; Park JD, 2004, J ARTIF INTELL RES, V21, P101; Pineau J, 2006, J ARTIF INTELL RES, V27, P335; QUINLAN JR, 1986, MACH LEARN, V1, P106; RADOVILSKY Y, 2006, IEEE INT C SYST MAN, V3, P2559; ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8; SCHEFFER T, 2001, ECML PKDD WORKSH INS; Sim R., 2005, IEEE INT C ROB AUT I; SINGH A, 2007, INT JOINT C ART INT, P2204; SINGHVI V, 2005, P 3 ACM C ENB NETW S; Slijepcevic S, 2001, ICC; SMALLWOO.RD, 1973, OPER RES, V21, P1071, DOI 10.1287/opre.21.5.1071; Stachniss C, 2005, ROBOTICS SCI SYSTEMS; TONG S, 2001, NIPS; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; VANDERGAAG L, 1993, AISB Q, V86, P23; Zhao F, 2002, IEEE SIGNAL PROC MAG, V19, P61	57	16	16	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757			J ARTIF INTELL RES	J. Artif. Intell. Res.		2009	35						557	591				35	Computer Science, Artificial Intelligence	Computer Science	476WL	WOS:000268477000002	
J	Isa, D; Lee, LH; Kallimani, VP; RajKumar, R				Isa, Dino; Lee, Lam Hong; Kallimani, V. P.; RajKumar, R.			Text document preprocessing with the Bayes formula for classification using the Support Vector Machine	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						document classification; Bayes formula; support vector machines		This work implements an enhanced hybrid classification method through the utilization of the naive Bayes approach and the Support Vector Machine (SVM). In this project, the Bayes formula was used to vectorize (as opposed to classify) a document according to a probability distribution reflecting the probable categories that the document may belong to. The Bayes formula gives a range of probabilities to which the document can be assigned according to a predetermined set of topics (categories) such as those found in the "20 Newsgroups" data set for instance. Using this probability distribution as the vectors to represent the document, the SVM can then be used to classify the documents on a multidimensional level. The effects of an inadvertent dimensionality reduction caused by classifying using only the highest probability using the naive Bayes classifier can be overcome using the SVM by employing all the probability values associated with every category for each document. This method can be used for any data set and shows a significant reduction in training time as compared to the Lsquare method and significant improvement in the classification accuracy when compared to pure naive Bayes systems and also the TF-IDF/SVM hybrids.	[Isa, Dino; Lee, Lam Hong; Kallimani, V. P.; RajKumar, R.] Univ Nottingham, Fac Engn & Comp Sci, Semenyih 43500, Selangor Darul, Malaysia	Isa, D (reprint author), Univ Nottingham, Fac Engn & Comp Sci, Malaysia Campus, Semenyih 43500, Selangor Darul, Malaysia.	dina.isa@nottingham.edu.my; kcx4lhl@nottingham.edu.my; vp.kallimani@nottingham.edu.my; rajprasad.rajkumar@nottingham.edu.my					ALMUBAID H, 2006, IEEE T KNOWLEDGE DAT, V18; BLOCK S, 2002, PROBABILITY SIMILARI; Brucher H, 2002, DOCUMENT CLASSIFICAT; Burges C.J.C., 1998, TUTORIAL SUPPORT VEC; Chakrabarti S, 2003, VLDB J, V12, P170, DOI 10.1007/s00778-003-0098-9; CUNNINGHAM P, 2003, P ICCBR WORKSH LONG; Delany SJ, 2005, ARTIF INTELL REV, V24, P359, DOI 10.1007/s10462-005-9006-6; DELANY SJ, 2004, J KNOWLEDGE BASED SY, V18, P187; FLACH PA, 2002, PROBABILISTIC REASON; Gunn S. R., 1998, SUPPORT VECTOR MACHI; GUTSCHOVEN B, MULTIMODAL IDENTITY; Han EH, 1999, TEXT CATEGORIZATION; HARTLEY M, 2006, DOMAIN KNOWLEDGE PRE; Haykin S., 1999, NEURAL NETWORKS COMP; Isa D., 2008, J COMPUTER INFORM SC, V1, P57; ISA D, 2007, P WSEAS C CIRC SYST; ISA D, 2007, EXPERT SYSTEMS UNPUB; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; KAMENS B, 2005, BAYESIAN FILTERING B; KECMAN V, 2004, 616 U AUCKL SCH ENG; KIM SB, 2002, P 7 PAC RIM INT C AR, V2417; LAW M, LECT CSE, V802; McCarthy Donna O, 2003, Biol Res Nurs, V5, P3, DOI 10.1177/1099800403005001001; Nigam K., 1999, P IJCAI 99 WORKSH MA, P61; OBRIEN C, 2002, P 1 INT S INF COMM T; Quinlan J.R., 1993, C4 5 PROGRAM MACHINE; Sahami M., 1998, P AAAI WORKSH LEARN; SOUCY P, 2005, P 19 INT JOINT C ART, P1130; SU X, 2002, TEXT CATEGORIZATION; Vapnik V., 1995, NATURE STAT LEARNING; XIA Y, 2005, P INT C APPL NAT LAN	31	16	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	SEP	2008	20	9					1264	1272		10.1109/TKDE.2008.76		9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	327XB	WOS:000257760700010	
J	Wu, XD; Zhu, XQ				Wu, Xindong; Zhu, Xingquan			Mining with noise knowledge: Error-aware data mining	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article						classification; data mining; naive Bayes (NB); noise handling; noise knowledge	IMPUTATION	Real-world data mining deals with noisy information sources where data collection inaccuracy, device limitations, data transmission and discretization errors, or man-made perturbations frequently result in imprecise or vague data. Two common practices are to adopt either data cleansing approaches to enhance the data consistency or simply take noisy data as quality sources and feed them into the data mining algorithms. Either way may substantially sacrifice the mining performance. In this paper, we consider an error-aware (EA) data mining design, which takes advantage of statistical error information (such as noise level and noise distribution) to improve data mining results. We assume that such noise knowledge is available in advance, and we propose a solution to incorporate it into the mining process. More specifically, we use noise knowledge to restore original data distributions, which are further used to rectify the model built from noise-corrupted data. We materialize this concept by the proposed EA naive Bayes classification algorithm. Experimental comparisons on real-world datasets will demonstrate the effectiveness of this design.	[Wu, Xindong] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China; [Wu, Xindong] Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA; [Zhu, Xingquan] Florida Atlantic Univ, Dept Comp Sci & Engn, Boca Raton, FL 33431 USA	Wu, XD (reprint author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China.	xwu@cs.uvm.edu; xqzhu@cse.fau.edu					Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BEAUMONT JF, 2000, P SURV RES METH SECT, P580; Berry M., 1999, MASTERING DATA MININ; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L., 1984, CLASSIFICATION REGRE; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Chapman AD, 2005, REPORT GLOBAL BIODIV; CHAPMAN P, 2000, CRISP DM 1 0 STEP BY; COPPOLA L, 2000, P DATACLEAN C, P30; *CSC SCI COMP LTD, 2005, DNA MICR DAT AN; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Du W., 2003, P 9 ACM SIGKDD INT C, P505; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1023/A:1022638503176; Fayyad UM, 1996, IEEE EXPERT, V11, P20; FELLEGI IP, 1976, J AM STAT ASSOC, V71, P17, DOI 10.2307/2285726; FERRARI L, 2006, BMC GENOMICS, V7, DOI DOI 10.1186/1471-2164-7-277; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; FUERNKRANZ J, 1998, J ARTIFICIAL INTELLI, V8, P129; Gamberger D, 1999, P 16 INT C MACH LEAR, P143; Garcke Jochen, 2001, P 7 ACM SIGKDD INT C, P87, DOI 10.1145/502512.502528; Guyon I., 1996, ADV KNOWLEDGE DISCOV, P181; Hernandez M. A., 1995, ACM SIGMOD RECORD, V24, P127, DOI 10.1145/568271.223807; Hu M., 1998, P SURV RES METH SECT, P308; Huang Z., 2005, P 2005 ACM SIGMOD C, P37, DOI 10.1145/1066157.1066163; John G. H., 1995, P 1 INT C KNOWL DISC, P174; KUBICA J, 2003, P ICDM C MELB FL; Lakshminarayan K, 1999, APPL INTELL, V11, P259, DOI 10.1023/A:1008334909089; LANGLEY P, 1992, P 10 NAT C ART INT; LUEBBERS D, 2003, P 29 VLDB BERL GERM; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; Quinlan J. R., 1986, MACHINE LEARNING; QUINLAN JR, 1983, P 2 INT MACH LEARN W; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rubin DB, 2004, MULTIPLE IMPUTATION; SARLE W, 1998, P 4 JOINT C INF SCI, P399; Shearer C., 2000, J DATA WAREHOUSING, V5, P13; TENG M, 1999, P 16 INT C MACH LEAR, P239; WANG RY, 1995, IEEE T KNOWL DATA EN, V7, P623, DOI 10.1109/69.404034; WU X, 2007, P 11 PAKDD NANJ CHIN; YANG Y, 2004, P 8 EUR C PKDD PIS I; ZHANG Y, 2007, P 7 IEEE ICDM OM NE; Zhu RB, 2005, ANTARCT SCI, V17, P11, DOI 10.1017/S0954102005002373; Zhu XQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P378; Zhu X, 2003, P 20 INT C MACH LEAR, P920; ZHU X, 2006, P IEEE INT C GRC ATL; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8	50	16	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4427			IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	JUL	2008	38	4					917	932		10.1109/TSMCA.2008.923034		16	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	317KX	WOS:000257020200014	
J	Zhang, Y; Ding, C; Li, T				Zhang, Yi; Ding, Chris; Li, Tao			Gene selection algorithm by combining reliefF and mRMR	BMC GENOMICS			English	Article								Background: Gene expression data usually contains a large number of genes, but a small number of samples. Feature selection for gene expression data aims at finding a set of genes that best discriminate biological samples of different types. In this paper, we present a two-stage selection algorithm by combining ReliefF and mRMR: In the first stage, ReliefF is applied to find a candidate gene set; In the second stage, mRMR method is applied to directly and explicitly reduce redundancy for selecting a compact yet effective gene subset from the candidate set. Results: We perform comprehensive experiments to compare the mRMR-ReliefF selection algorithm with ReliefF, mRMR and other feature selection methods using two classifiers as SVM and Naive Bayes, on seven different datasets. And we also provide all source codes and datasets for sharing with others. Conclusion: The experimental results show that the mRMR-ReliefF gene selection algorithm is very effective.	[Zhang, Yi; Li, Tao] Florida Int Univ, Sch Comp Sci, Miami, FL 33199 USA; [Ding, Chris] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA	Li, T (reprint author), Florida Int Univ, Sch Comp Sci, 11200 SW 8th St, Miami, FL 33199 USA.	yzhan004@cs.fiu.edu; CHQDing@uta.edu; taoli@cs.fiu.edu					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Chee M, 1996, SCIENCE, V274, P610, DOI 10.1126/science.274.5287.610; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; Ding C., 2003, IEEE COMP SOC BIOINF, P523; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; FODOR SPA, 1991, SCIENCE, V251, P767, DOI 10.1126/science.1990438; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; KOHAVI P, 1997, ARTIF INTELL, V97, P273; Langley P., 1994, AAAI FALL S REL, P140; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Marko R. S., 2003, MACHINE LEARNING J, V53, P23, DOI DOI 10.1023/A:1025667309714; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; SUN Y, 2006, P 23 INT C MACH LEAR, V29, P1035; Xing EP, 2001, P 18 INT C MACH LEAR, P601; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; ZHENG G, 2006, THESIS FLORIDA INT U; MLL GENE EXPRESSION; ARR GENE EXPRESSION; HBC GENE EXPRESSION; LYM GENE EXPRESSION; NC160 CANC MICROARAY; ALL GENE EXPRESSION	26	16	17	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics		2008	9			2					S27	10.1186/1471-2164-9-S2-S27		10	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	V92JQ	WOS:000206244200028	
J	Allocco, DJ; Song, Q; Gibbons, GH; Ramoni, MF; Kohane, IS				Allocco, Dominic J.; Song, Qing; Gibbons, Gary H.; Ramoni, Marco F.; Kohane, Isaac S.			Geography and genography: prediction of continental origin using randomly selected single nucleotide polymorphisms	BMC GENOMICS			English	Article							HUMAN-POPULATIONS; GENETIC-STRUCTURE; RACE; IDENTIFICATION; DIVERSITY; INFERENCE; ANCESTRY; PROJECT; DNA	Background: Recent studies have shown that when individuals are grouped on the basis of genetic similarity, group membership corresponds closely to continental origin. There has been considerable debate about the implications of these findings in the context of larger debates about race and the extent of genetic variation between groups. Some have argued that clustering according to continental origin demonstrates the existence of significant genetic differences between groups and that these differences may have important implications for differences in health and disease. Others argue that clustering according to continental origin requires the use of large amounts of genetic data or specifically chosen markers and is indicative only of very subtle genetic differences that are unlikely to have biomedical significance. Results: We used small numbers of randomly selected single nucleotide polymorphisms (SNPs) from the International HapMap Project to train naive Bayes classifiers for prediction of ancestral continent of origin. Predictive accuracy was tested on two independent data sets. Genetically similar groups should be difficult to distinguish, especially if only a small number of genetic markers are used. The genetic differences between continentally defined groups are sufficiently large that one can accurately predict ancestral continent of origin using only a minute, randomly selected fraction of the genetic variation present in the human genome. Genotype data from only 50 random SNPs was sufficient to predict ancestral continent of origin in our primary test data set with an average accuracy of 95%. Genetic variations informative about ancestry were common and widely distributed throughout the genome. Conclusion: Accurate characterization of ancestry is possible using small numbers of randomly selected SNPs. The results presented here show how investigators conducting genetic association studies can use small numbers of arbitrarily chosen SNPs to identify stratification in study subjects and avoid false positive genotype-phenotype associations. Our findings also demonstrate the extent of variation between continentally defined groups and argue strongly against the contention that genetic differences between groups are too small to have biomedical significance.	Harvard Univ, MIT, Div Hlth Sci & Technol, Childrens Hosp,Informat Program, Boston, MA 02115 USA; Beth Israel Deaconess Med Ctr, Div Cardiol, Boston, MA 02215 USA; Morehouse Sch Med, Cardiovasc Res Inst, Atlanta, GA USA; Harvard Univ, Partners Ctr Genet & Genom, Boston, MA 02115 USA	Allocco, DJ (reprint author), Harvard Univ, MIT, Div Hlth Sci & Technol, Childrens Hosp,Informat Program, Boston, MA 02115 USA.	alloccod@yahoo.com; qsong@msm.edu; ggibbons@msm.edu; marco_ramoni@harvard.edu; isaac_kohane@harvard.edu	Kohane, Isaac Kohane/K-3716-2012	Kohane, Isaac Kohane/0000-0003-2192-5160			Burchard EG, 2003, NEW ENGL J MED, V348, P1170, DOI 10.1056/NEJMsb025007; Calafell F, 2003, NAT GENET, V33, P435, DOI 10.1038/ng0403-435; Cavalli-Sforza LL, 2003, NAT GENET, V33, P266, DOI 10.1038/ng1113; Collins FS, 1998, SCIENCE, V282, P682, DOI 10.1126/science.282.5389.682; Cooper RS, 2003, NEW ENGL J MED, V348, P1166, DOI 10.1056/NEJMsb022863; Corander J, 2003, GENETICS, V163, P367; Dawson KJ, 2001, GENET RES, V78, P59; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Haga SB, 2003, SCIENCE, V301, P466, DOI 10.1126/science.1087004; Hinds DA, 2005, SCIENCE, V307, P1072, DOI 10.1126/science.1105436; Gibbs RA, 2003, NATURE, V426, P789, DOI 10.1038/nature02168; Jorde LB, 2004, NAT GENET, V36, pS28, DOI 10.1034/ng1435; Lao O, 2006, AM J HUM GENET, V78, P680, DOI 10.1086/501531; Lewontin RC, 1972, EVOLUTIONARY BIOL, V6, P381; MARON ME, 1961, J ACM, V8, P404, DOI 10.1145/321075.321084; Mountain JL, 1997, AM J HUM GENET, V61, P705, DOI 10.1086/515510; NEI M, 1974, AM J HUM GENET, V26, P421; Parra EJ, 1998, AM J HUM GENET, V63, P1839, DOI 10.1086/302148; Pritchard JK, 2000, GENETICS, V155, P945; Risch N, 2002, GENOME BIOL, V3, P1; Risch N, 2006, NEW ENGL J MED, V354, P408, DOI 10.1056/NEJMe058265; Rosenberg NA, 2003, AM J HUM GENET, V73, P1402, DOI 10.1086/380416; Rosenberg NA, 2002, SCIENCE, V298, P2381, DOI 10.1126/science.1078311; Salas A, 2004, AM J HUM GENET, V74, P454, DOI 10.1086/382194; Serre D, 2004, GENOME RES, V14, P1679, DOI 10.1101/gn2529604; Smigielski EM, 2000, NUCLEIC ACIDS RES, V28, P352, DOI 10.1093/nar/28.1.352; Tang H, 2005, AM J HUM GENET, V76, P268, DOI 10.1086/427888; Tishkoff SA, 2004, NAT GENET, V36, pS21, DOI 10.1038/ng1438; Wilson JF, 2001, NAT GENET, V29, P265, DOI 10.1038/ng761	29	16	16	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics	MAR 10	2007	8								68	10.1186/1471-2164-8-68		8	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	147TD	WOS:000245024500001	
J	Demichelis, F; Magni, P; Piergiorgi, P; Rubin, MA; Bellazzi, R				Demichelis, Francesca; Magni, Paolo; Piergiorgi, Paolo; Rubin, Mark A.; Bellazzi, Riccardo			A hierarchical Naive Bayes Model for handling sample heterogeneity in classification problems: an application to tissue microarrays	BMC BIOINFORMATICS			English	Article							GENE-EXPRESSION DATA; PROSTATE-CANCER; SELECTION; SPECIMENS; RACEMASE; DESIGN	Background: Uncertainty often affects molecular biology experiments and data for different reasons. Heterogeneity of gene or protein expression within the same tumor tissue is an example of biological uncertainty which should be taken into account when molecular markers are used in decision making. Tissue Microarray ( TMA) experiments allow for large scale profiling of tissue biopsies, investigating protein patterns characterizing specific disease states. TMA studies deal with multiple sampling of the same patient, and therefore with multiple measurements of same protein target, to account for possible biological heterogeneity. The aim of this paper is to provide and validate a classification model taking into consideration the uncertainty associated with measuring replicate samples. Results: We propose an extension of the well-known Naive Bayes classifier, which accounts for biological heterogeneity in a probabilistic framework, relying on Bayesian hierarchical models. The model, which can be efficiently learned from the training dataset, exploits a closed- form of classification equation, thus providing no additional computational cost with respect to the standard Naive Bayes classifier. We validated the approach on several simulated datasets comparing its performances with the Naive Bayes classifier. Moreover, we demonstrated that explicitly dealing with heterogeneity can improve classification accuracy on a TMA prostate cancer dataset. Conclusion: The proposed Hierarchical Na ve Bayes classifier can be conveniently applied in problems where within sample heterogeneity must be taken into account, such as TMA experiments and biological contexts where several measurements ( replicates) are available for the same biological sample. The performance of the new approach is better than the standard Naive Bayes model, in particular when the within sample heterogeneity is different in the different classes.	Brigham & Womens Hosp, Dept Pathol, Boston, MA 02115 USA; Univ Trent, Dept Informat & Commun Technol, Trento, Italy; IRST, ITC, SRA, Trento, Italy; Harvard Univ, Sch Med, Boston, MA USA; Univ Pavia, Dipartimento Informat & Sistemist, I-27100 Pavia, Italy; Harvard Univ, Dana Farber Canc Ctr, Boston, MA 02115 USA	Rubin, MA (reprint author), Brigham & Womens Hosp, Dept Pathol, 75 Francis St, Boston, MA 02115 USA.	fdemichelis@partners.org; paolo.magni@unipv.it; Ppiergiorgi@gmail.com; marubin@partners.org; riccardo.bellazzi@unipv.it					Bae K, 2004, BIOINFORMATICS, V20, P3423, DOI 10.1093/bioinformatics/bth419; BELLAZZI R, 2006, DIS TECHNICAL REPORT; Bhattacharyya C, 2004, J COMPUT BIOL, V11, P1073, DOI 10.1089/cmb.2004.11.1073; Bi J., 2004, SUPPORT VECTOR CLASS; Bismar TA, 2006, NEOPLASIA, V8, P59, DOI 10.1593/neo.05664; Browne TJ, 2004, HUM PATHOL, V35, P1462, DOI 10.1016/j.humpath.2004.09.009; BUDENDORF L, 2001, J PATHOL, V195, P72; Cho H, 2004, BIOINFORMATICS, V20, P2016, DOI 10.1093/bioinformatics/bth192; Ferrazzi Fulvia, 2005, Appl Bioinformatics, V4, P263, DOI 10.2165/00822942-200504040-00006; Gelman A., 2004, BAYESIAN DATA ANAL; Gilks W.R., 1996, MARKOV CHAIN MONTE C; Goldstein H, 2002, STAT MED, V21, P3291, DOI 10.1002/sim.1264; Hein AMK, 2005, BIOSTATISTICS, V6, P349, DOI 10.1093/biostatistics/kxi016; Helman P, 2004, J COMPUT BIOL, V11, P581, DOI 10.1089/1066527041887294; Ihaka R., 1996, J COMPUTATIONAL GRAP, P299, DOI DOI 10.2307/1390807; Ishibuchi H., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227388; Karklin Yan, 2005, Neural Comput, V17, P397, DOI 10.1162/0899766053011474; Kononen J, 1998, NAT MED, V4, P844, DOI 10.1038/nm0798-844; Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55; Langseth H, 2006, MACH LEARN, V63, P135, DOI 10.1007/s10994-006-6136-2; Lavrac N, 1998, AI COMMUN, V11, P191; Leyland AH, 2001, MULTILEVEL MODELLING; Liu Xueli, 2004, J Biopharm Stat, V14, P671, DOI 10.1081/BIP-200025657; Magni P, 2002, J PHARMACOKINET PHAR, V29, P445, DOI 10.1023/A:1022920403166; Michalski R. S., 2001, Machine learning and its applications. Advanced lectures; Mitchell T.M., 1997, MACHINE LEARNING; Mucci NR, 2000, HUM PATHOL, V31, P406, DOI 10.1053/hp.2000.7295; REDELMEIER DA, 1991, J CLIN EPIDEMIOL, V44, P1141, DOI 10.1016/0895-4356(91)90146-Z; Rhodes DR, 2002, CANCER RES, V62, P4427; Riva A, 1996, ARTIF INTELL MED, V8, P217, DOI 10.1016/0933-3657(95)00034-8; Rubin MA, 2005, CANCER EPIDEM BIOMAR, V14, P1424, DOI 10.1158/1055-9965.EPI-04-0801; Rubin MA, 2002, JAMA-J AM MED ASSOC, V287, P1662, DOI 10.1001/jama.287.13.1662; Shen RL, 2004, BMC GENOMICS, V5, DOI 10.1186/1171-2164-5-94; Shkedy Z, 2005, J BIOPHARM STAT, V15, P225, DOI 10.1081/BIP-200049825; Varambally S, 2002, NATURE, V419, P624, DOI 10.1038/nature01075; Witten I. H., 2000, DATA MINING; Xu JC, 2000, CANCER RES, V60, P1677; Yeung KY, 2005, BIOINFORMATICS, V21, P2394, DOI 10.1093/bioinformatics/bti319; Zhang DH, 2003, HUM PATHOL, V34, P362, DOI 10.1053/hupa.2003.60	39	16	17	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	NOV 24	2006	7								514	10.1186/1471-2105-7-514		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	118OF	WOS:000242950900001	
J	Perez, A; Larranaga, P; Inza, I				Perez, Aritz; Larranaga, Pedro; Inza, Inaki			Supervised classification with conditional Gaussian networks: Increasing the structure complexity from naive Bayes	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						conditional Gaussian network; Bayesian network; naive Bayes; tree augmented naive Bayes; k-dependence Bayesian classifiers; semi naive Bayes; filter; wrapper	FEATURE SUBSET-SELECTION; CLASSIFIERS; VARIANCE; BIAS; KNOWLEDGE; RELEVANCE	Most of the Bayesian network-based classifiers are usually only able to handle discrete variables. However, most real-world domains involve continuous variables. A common practice to deal with continuous variables is to discretize them, with a subsequent loss of information. This work shows how discrete classifier induction algorithms can be adapted to the conditional Gaussian network paradigm to deal with continuous variables without discretizing them. In addition, three novel classifier induction algorithms and two new propositions about mutual information are introduced. The classifier induction algorithms presented are ordered and grouped according to their structural complexity: naive Bayes, tree augmented naive Bayes, k-dependence Bayesian classifiers and semi naive Bayes. All the classifier induction algorithms are empirically evaluated using predictive accuracy, and they are compared to linear discriminant analysis, as a continuous classic statistical benchmark classifier. Besides, the accuracies for a set of state-of-the-art classifiers are included in order to justify the use of linear discriminant analysis as the benchmark algorithm. In order to understand the behavior of the conditional Gaussian network-based classifiers better, the results include bias-variance decomposition of the expected misclassification rate. The study suggests that semi naive Bayes structure based classifiers and, especially, the novel wrapper condensed semi naive Bayes backward, outperform the behavior of the rest of the presented classifiers. They also obtain quite competitive results compared to the state-of-the-art algorithms included. (c) 2006 Elsevier Inc. All rights reserved.	Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, San Sebastian 20080, Spain	Perez, A (reprint author), Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, POB 649, San Sebastian 20080, Spain.	aritz@si.ehu.es; ccplamup@si.ehu.es; inza@si.ehu.es	Larranaga, Pedro/F-9293-2013				ANDERSON FW, 1958, INTRO MULTIVARIATE S; BOTTCHER SG, 2004, THESIS ALLBORG U; Castillo E., 1997, EXPERT SYSTEMS PROBA; Cheng J., 1999, P 15 C UNC ART INT U, P101; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeGroot M., 1970, OPTIMAL STAT DECISIO; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Duda R., 1973, PATTERN CLASSIFICATI; Dudewicz E. J., 1988, MODERN MATH STAT; EGMONTPETERSON M, 2004, P JOINT IAPR WORKSH, P1034; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FRIEDMAN N, 1998, P 15 NAT C MACH LEAR; Geiger D., 1994, LEARNING GAUSSIAN NE; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; German S., 1992, NEURAL COMPUT, V4, P1; Giudici P, 1999, BIOMETRIKA, V86, P785, DOI 10.1093/biomet/86.4.785; Goldberg D., 1989, GENETIC ALGORITHMS S; Grossman D., 2004, P 21 INT C MACH LEAR; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall MA, 1997, P 4 INT C NEUR INF P, P855; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Jebara Tony, 2001, THESIS MIT; JOHN GH, 1995, P 11 C UNC ART INT, P338; Johnson R.A., 2002, APPL MULTIVARIATE ST; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Keogh E., 1999, P 7 INT WORKSH ART I, P225; KOHAVI R, 1996, INT C MACH LEARN; KOHAVI R, 1995, THESIS COMPUTER SCI; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; Larranaga P., 2002, ESTIMATION DISTRIBUT; Lauritzen S. L., 1996, GRAPHICAL MODELS; LAURITZEN SL, 1989, ANN STAT, V17; LAURITZEN SL, 1984, F848 AALB U I EL SYS; Liu H., 1998, FEATURE SELECTION KN; Minsky M., 1961, T I RADIO ENG, V49, P8; Murphy P. M., 1995, UCI REPOSITORY MACHI; Neapolitan RE, 2003, LEARNING BAYESIAN NE; PAZZANI M, 1997, LEARNING DATA ARTIFI, V5, P239; Pearl J., 1988, PROBABILISTIC REASON; Pernkopf F, 2005, PATTERN RECOGN, V38, P1, DOI 10.1016/j.patcog.2004.05.012; Pernkopf F., 2005, P 22 INT C MACH LEAR; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Raina R., 2003, ADV NEURAL INFORM PR, V16; Rosenblatt F., 1959, PRINCIPLES NEURODYNA; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; SNTAFE G, 2005, P 8 EUR C SYMB QUANT, P148; Van der Putten P, 2004, MACH LEARN, V57, P177, DOI 10.1023/B:MACH.0000035476.95130.99; Wang H, 1999, IEEE T PATTERN ANAL, V21, P271; WANG H, 1996, THESIS U ULSTER; Witten IH, 2005, DATA MINING PRACTICA; YANG Y, 2003, 2003131 MON U SCH CO; Yu L, 2004, J MACH LEARN RES, V5, P1205	64	16	17	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X			INT J APPROX REASON	Int. J. Approx. Reasoning	SEP	2006	43	1					1	25		10.1016/j.ijar.2006.01.002		25	Computer Science, Artificial Intelligence	Computer Science	079MR	WOS:000240181200001	
J	Rodgers, S; Glen, RC; Bender, A				Rodgers, S; Glen, RC; Bender, A			Characterizing bitterness: Identification of key structural features and development of a classification model	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	7th International Conference on Chemical Structures	JUN 05-09, 2005	Noordwijkerhout, NETHERLANDS	ASC, CINF, CSA Trust, CSJ, GDCh, KNCV			TASTE RECEPTORS; MOLECULAR SIMILARITY; TRANSDUCTION; PROTEASE	This work describes the first approach in the development of a comprehensive classification method for bitterness of small molecules. The data set comprises 649 bitter and 13 530 randomly selected molecules from the MDL Drug Data Repository (MDDR) which are analyzed by circular fingerprints (MOLPRINT 2D) and information-gain feature selection. The feature selection proposes substructural features which are statistically correlated to bitterness. Classification is performed on the selected features via a naive Bayes classifier. The substructural features upon which the classification is based are able to discriminate between bitter and random compounds, and thus we propose they are also functionally responsible for causing the bitter taste. Such substructures include various sugar moieties as well as highly branched carbon scaffolds. Cynaropicrine contains a number of the substructural features found to be statistically associated with bitterness and thus was correctly predicted to be bitter by our model. Alternatively, both promethazine and saccharin contain fewer of these substructural features, and thus the bitterness in these compounds was not identified. Two different classes of-bitter compounds were identified, namely those which are larger and contain mainly oxygen and carbon and often sugar moieties, and those which are rather smaller and contain additional nitrogen and/or sulfur fragments. The classifier is able to predict 72.1% of the bitter compounds. Feature selection reduces the number of false-positives while also increasing the number of false negatives to 69.5% of bitter compounds correctly predicted. Overall, the method presented here presents both one of the largest databases of bitter compounds presently available as well as a relatively reliable classification method.	Unilever Food & Hlth Res Inst, NL-3132 AT Vlaardingen, Netherlands; Univ Cambridge, Dept Chem, Unilever Ctr Mol Sci Informat, Cambridge CB2 1EW, England	Rodgers, S (reprint author), AZ R&D Charnwood, Bakewell Rd, Loughborough LE11 5RH, Leics, England.	Sarah.Rodgers@AstraZeneca.com	Bender, Andreas/C-6942-2009	Bender, Andreas/0000-0002-6683-7546			Adler E, 2000, CELL, V100, P693, DOI 10.1016/S0092-8674(00)80705-9; Behrens M, 2004, BIOCHEM BIOPH RES CO, V319, P479, DOI 10.1016/j.bbrc.2004.05.019; Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; BENDER A, 2005, THESIS U CAMBRIDGE; Bufe B, 2002, NAT GENET, V32, P397, DOI 10.1038/ng1014; Carpino S, 2002, J AGR FOOD CHEM, V50, P1143, DOI 10.1021/jf0112419; Chandrashekar J, 2000, CELL, V100, P703, DOI 10.1016/S0092-8674(00)80706-0; Chaudhari N, 2000, NAT NEUROSCI, V3, P113, DOI 10.1038/72053; CLARK M, 1989, J COMPUT CHEM, V10, P982, DOI 10.1002/jcc.540100804; *FSTA, 2003, FOOD SCI TECHN ABSTR; Glanz K, 1998, J AM DIET ASSOC, V98, P1118, DOI 10.1016/S0002-8223(98)00260-0; HECK GL, 1984, SCIENCE, V223, P403, DOI 10.1126/science.6691151; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; KINNAMON SC, 1988, P NATL ACAD SCI USA, V85, P7023, DOI 10.1073/pnas.85.18.7023; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; Kuhn C, 2004, J NEUROSCI, V24, P10260, DOI 10.1523/JNEUROSCI.1225-04.2004; MEYERHOFF W, 2005, IN PRESS BIOCH P; Ney K. H., 1979, ACS Symposium Series, V115, P149; Ninomiya K, 2002, FOOD REV INT, V18, P23, DOI 10.1081/FRI-120003415; Pronin AN, 2004, CHEM SENSES, V29, P583, DOI 10.1093/chemse/bjh064; Rodgers S, 2005, CHEM SENSES, V30, P547, DOI 10.1093/chemse/bji048; Schiffman SS, 1999, NUTRITION, V15, P767, DOI 10.1016/S0899-9007(99)00152-5; Spillane WJ, 2002, FOOD CHEM, V79, P15, DOI 10.1016/S0308-8146(02)00169-3; Wong GT, 1996, NATURE, V381, P796, DOI 10.1038/381796a0; ZHANG YS, 1992, P NATL ACAD SCI USA, V89, P2399, DOI 10.1073/pnas.89.6.2399	27	16	17	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAR-APR	2006	46	2					569	576		10.1021/ci0504418		8	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	028XT	WOS:000236522800015	
J	Borro, LC; Oliveira, SRM; Yamagishi, MEB; Mancini, AL; Jardine, JG; Mazoni, I; dos Santos, EH; Higa, RH; Kuser, PR; Neshich, G				Borro, Luiz C.; Oliveira, Stanley R. M.; Yamagishi, Michel E. B.; Mancini, Adaulto L.; Jardine, Jose G.; Mazoni, Ivan; dos Santos, Edgard H.; Higa, Roberto H.; Kuser, Paula R.; Neshich, Goran			Predicting enzyme class from protein structure using Bayesian classification	GENETICS AND MOLECULAR RESEARCH			English	Article						protein function prediction; protein structure; Naive Bayes; enzyme classification number; Bayesian classifier; data classification		Predicting enzyme class from protein structure parameters is a challenging problem in protein analysis. We developed a method to predict enzyme class that combines the strengths of statistical and data-mining methods. This method has a strong mathematical foundation and is simple to implement, achieving an accuracy of 45%. A comparison with the methods found in the literature designed to predict enzyme class showed that our method outperforms the existing methods.	[Borro, Luiz C.; Oliveira, Stanley R. M.; Yamagishi, Michel E. B.; Mancini, Adaulto L.; Jardine, Jose G.; Mazoni, Ivan; dos Santos, Edgard H.; Higa, Roberto H.; Kuser, Paula R.; Neshich, Goran] Embrapa Informat Technol, BR-13083886 Campinas, SP, Brazil	Yamagishi, MEB (reprint author), Embrapa Informat Technol, Andre Tosello 209,Caixa Postal 6041, BR-13083886 Campinas, SP, Brazil.	michel@cbi.cnptia.embrapa.br	Kuser-Falcao, Paula/A-5799-2010; Yamagishi, Michel/B-7902-2012; Neshich, Goran/C-3946-2013; Mazoni, Ivan/F-1040-2013; Borro, Luiz/H-6158-2013	Yamagishi, Michel/0000-0001-7109-3038; 			AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Chandonia JM, 2002, NUCLEIC ACIDS RES, V30, P260, DOI 10.1093/nar/30.1.260; Dobson PD, 2005, J MOL BIOL, V345, P187, DOI 10.1016/j.jmb.2004.10.024; Elkan C., 1997, BOOSTING NAIVE BAYES; Feller W., 1971, INTRO PROBABILITY TH; GOUTTE C, 1997, NEURAL COMPUT, V9, P1246; Han J., 2001, DATA MINING CONCEPTS; Higa RH, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-107; Langley P., 1994, SELECTION RELEVANT F; Neshich G, 2004, NUCLEIC ACIDS RES, V32, pW595, DOI 10.1093/nar/gkh480; Neshich G, 2003, NUCLEIC ACIDS RES, V31, P3386, DOI 10.1093/nar/gkg578; Neshich G, 2005, NUCLEIC ACIDS RES, V33, pW29, DOI 10.1093/nar/gki397; Shrager J, 2003, BIOINFORMATICS, V19, P1934, DOI 10.1093/bioinformatics/btg277; Witten IH, 2005, DATA MINING PRACTICA; Young F. W., 1987, MULTIDIMENSIONAL SCA; ZHANG H, 2004, P 15 EUR C MACH LEAR	20	16	17	FUNPEC-EDITORA	RIBEIRAO PRETO	RUA HUDSON 655, JARDIM CANADA, RIBEIRAO PRETO, SP, BRAZIL	1676-5680			GENET MOL RES	Genet. Mol. Res.		2006	5	1					193	202				10	Biochemistry & Molecular Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Genetics & Heredity	V44OJ	WOS:000203011700024	
S	Jin, X; Xu, AB; Bie, RF; Guo, P		Li, J; Yang, Q; Tan, AH		Jin, X; Xu, AB; Bie, RF; Guo, P			Machine learning techniques and Chi-square feature selection for cancer classification using SAGE gene expression profiles	DATA MINING FOR BIOMEDICAL APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1stWorkshop on Data Mining for Biomedical Applications	APR   09, 2006	Singapore, SINGAPORE	Nanyang Technol Univ, Sch Comp Engn, Inst Infocomm Res				Recently developed Serial Analysis of Gene Expression (SAGE) technology enables us to simultaneously quantify the expression levels of tens of thousands of genes in a population of cells. SAGE is better than Microarray in that SAGE can monitor both known and unknown genes while Microarray can only measure known genes. SAGE gene expression profiling based cancer classification is a better choice since cancers may be due to some unknown genes. Whereas a wide range of methods has been applied to traditional Microarray based cancer classification, relatively few studies have been done on SAGE based cancer classification. In our study we evaluate popular machine learning methods (SVM, Naive Bayes, Nearest Neighbor, C4.5 and RIPPER) for classifying cancers based on SAGE data. In order to deal with the high dimensional problem, we propose to use Chi-square for tag/gene selection. Both binary classification and multicategory classification are investigated. The experiments are based on two human SAGE datasets: brain and breast. The results show that SVM and Naive Bayes are the top-performing SAGE classifiers and that Chi-square based gene selection can improve the performance of all the five classifiers investigated.	Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China; Beijing Normal Univ, Image Proc & Pattern Recognit Lab, Beijing, Peoples R China	Jin, X (reprint author), Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.	xinjin796@126.com; anbangxu@mail.bnu.edu.cn; rfbie@bnu.edu.cn; pguo@bnu.edu.cn					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P1; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BUCKHAULTS P, 2003, CANCER RES, P4144; Cai L, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-7-r51; COHEN WW, 1995, P 12 INT C ML95; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; GOLUB TR, 1999, SCIENCE, V286; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; JOHN GH, 1995, P 11 C UNC ART INT, P338; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; LEZHANG, 2004, ACM T ASIAN LANGUAGE, V3, P243; NG RT, 2001, BIOKDD, P65; PORTER D, 2003, P NATL ACAD SCI USA, P10931; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Sander J, 2005, ACM T INFORM SYST, V23, P35, DOI 10.1145/1055709.1055712; Schneider K, 2003, P 10 C EUR CHAPT ASS, P307; STATNIKOV A, 2004, BIOINFORMATICS  0916; STATNIKOV A., 2004, BIOINFORMATICS; VELCULESCU VE, 1995, SCIENCE, V270, P484, DOI 10.1126/science.270.5235.484; Witten I.H., 2000, DATA MINING PRACTICA	21	16	16	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33104-2	LECT NOTES COMPUT SC			2006	3916						106	115				10	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Medical Laboratory Technology	Biochemistry & Molecular Biology; Computer Science; Medical Laboratory Technology	BEG77	WOS:000237241100011	
S	Delany, SJ; Cunningham, P; Doyle, D; Zamolotskikh, A		MunozAvila, H; Ricci, F		Delany, SJ; Cunningham, P; Doyle, D; Zamolotskikh, A			Generating estimates of classification confidence for a case-based spam filter	CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th International Conference on Case-Based Reasoning	AUG 23-26, 2005	Chicago, IL	Kaidara Software, Empolis, Naval Res Lab, PricewaterhouseCooper, AAAI			CBR	Producing estimates of classification confidence is surprisingly difficult. One might expect that classifiers that can produce numeric classification scores (e.g. kappa-Nearest Neighbour, Naive Bayes or Support Vector Machines) could readily produce confidence estimates based on thresholds. In fact, this proves not to be the case, probably because these are not probabilistic classifiers in the strict sense. The numeric scores coming from kappa-Nearest Neighbour, Naive Bayes and Support Vector Machine classifiers are not well correlated with classification confidence. In this paper we describe a case-based spam filtering application that would benefit significantly from an ability to attach confidence predictions to positive classifications (i.e. messages classified as spam). We show that 'obvious' confidence metrics for a case-based classifier are not effective. We propose an ensemble-like solution that aggregates a collection of confidence metrics and show that this offers an effective solution in this spam filtering domain.	Dublin Inst Technol, Dublin 8, Ireland; Univ Dublin Trinity Coll, Dublin 2, Ireland	Delany, SJ (reprint author), Dublin Inst Technol, Kevin St, Dublin 8, Ireland.	sarahjane.delany@comp.dit.ie; padraig.cunningham@cs.tcd.ie; donal.doyle@cs.tcd.ie; zamolota@cs.tcd.ie					ANDROUTSOPOULOS I, 2000, 200402 NCSR; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; Cheetham W., 2000, LNCS LNAI, V1898, P15; Cheetham W, 2004, LECT NOTES COMPUT SC, V3155, P106; Christianini N., 2000, INTRO SUPPORT VECTOR; DAVIS R, 1985, RULE BASED EXPERT SY, P507; DAVIS R, 1982, AI MAG, V3, P3; DELANY S, 2005, IN PRESS ARTIFICIAL; DELANY SJ, 2004, APPL INNOVATIONS INT, V12, P3; Delany SJ, 2004, LECT NOTES COMPUT SC, V3155, P128; Delany S.J., 2004, P 15 IR C ART INT CO, P9; Doyle D, 2004, LECT NOTES COMPUT SC, V3155, P157; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Fausett L., 1993, FUNDAMENTALS NEURAL; Hosmer DW, 2000, WILEY SERIES PROBABI; KOLCZ A, 2001, TEXTDM2001 IEEE ICDM, P123; LENAT D, 1983, BUILDING EXPERT SYST, P219; MASSIE S, 2004, LNCS; McLaren B, 2001, LECT NOTES ARTIF INT, V2080, P377; McSherry D, 2004, LECT NOTES COMPUT SC, V3155, P317; MICHELAKIS E, 2004, 1 C EM ANTISPAM CEAS; Mitchell T.M., 1997, MACHINE LEARNING; NUGENT C, 2005, IN PRESS ARTIFICIAL; Pantel P., 1998, P AAAI 98 WORKSH LEA, P95; Sahami M., 1998, P AAAI WORKSH LEARN, P55; SCHNEIDER K, 2003, 10 C EUR CHAPT ASS C, P307; Zhang L., 2004, ACM T ASIAN LANGUAGE, V3, P243, DOI 10.1145/1039621.1039625	27	16	16	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28174-6	LECT NOTES ARTIF INT			2005	3620						177	190				14	Computer Science, Artificial Intelligence	Computer Science	BDF64	WOS:000233274900016	
J	Gama, J				Gama, J			Iterative Bayes	THEORETICAL COMPUTER SCIENCE			English	Article; Proceedings Paper	3rd International Conference on Discovery Science	DEC, 2000	KYOTO, JAPAN			naive Bayes; iterative optimization; supervised machine learning		Naive Bayes is a well-known and studied algorithm both in statistics and machine learning. Bayesian learning algorithms represent each concept with a single probabilistic summary. In this paper we present an iterative approach to naive Bayes. The Iterative Bayes begins with the distribution tables built by the naive Bayes. Those tables are iteratively updated in order to improve the probability class distribution associated with each training example. In this paper we argue that Iterative Bayes minimizes a quadratic loss function instead of the 0-1 loss function that usually applies, to classification problems. Experimental evaluation of Iterative Bayes on 27 benchmark data sets shows consistent gains in accuracy. An interesting side effect of our algorithm is that it shows to be robust to attribute dependencies. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Porto, LIACC, FEP, P-4150 Oporto, Portugal	Gama, J (reprint author), Univ Porto, LIACC, FEP, Rua Campo Alegre 823, P-4150 Oporto, Portugal.	jgama@liacc.up.pt	Gama, Joao/A-2070-2008	Gama, Joao/0000-0003-3357-1195			Blake C., 1999, UCI REPOSITORY MACHI; BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1007/BF00994660; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J, 1995, P 12 INT C MACH LEAR; Duda R., 1973, PATTERN CLASSIFICATI; Elkan C., 1997, CS97557 U CAL; GAMA J, 2000, LECT NOTES ARTIFICIA, V1952; John G. H., 1994, P 11 INT C MACH LEAR; John G. H., 1997, THESIS STANFORD U; Kohavi R., 1996, P 13 INT C MACH LEAR; Kohavi R., 1996, P 2 INT C KNOWL DISC; KONONENKO I, 1991, LECT NOTES ARTIFICIA, V482; LANGLEY P, 1993, LECT NOTES ARTIFICIA, V667; LANGLEY P, 1999, P 16 INT C MACH LEAR; Liu H., 1998, FEATURE SELECTION KN; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T.M., 1997, MACHINE LEARNING; Nigam K., 2000, MACH LEARN, V39, P1; Pazzani M. J., 1996, Proceedings ofthe Conference, ISIS '96. Information, Statistics and Induction in Science; RIDGEWAY G, 1998, P 4 INT C KNOWL DISC; Ripley B., 1996, PATTERN RECOGNITION; Schapire R. E., 1997, P 14 INT C MACH LEAR; Webb G I, 1998, P 11 AUSTR JOINT C A, P285	23	16	17	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975			THEOR COMPUT SCI	Theor. Comput. Sci.	JAN 27	2003	292	2					417	430		10.1016/S0304-3975(02)00179-2		14	Computer Science, Theory & Methods	Computer Science	639XJ	WOS:000180655200006	
S	Ceci, M; Appice, A; Malerba, D		Lavrac, N; Gamberger, D; Todorovski, L; Blockeel, H		Ceci, M; Appice, A; Malerba, D			Mr-SBC: A multi-relational naive Bayes classifier	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2003, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th European Conferenc on Priciples and Practice of Knowledge Discovery in Databases	SEP 22-26, 2003	CAVTAT, CROATIA	Croatian Minist Sci & Technol, Slovenian Minist Educ, Sci & Sports, Knowledge Discovery Network Excellence				In this paper we propose an extension of the naive Bayes classification method to the multi-relational setting. In this setting, training data are stored in several tables related by foreign key constraints and each example is represented by a set of related tuples rather than a single row as in the classical data mining setting. This work is characterized by three aspects. First, an integrated approach in the computation of the posterior probabilities for each class that make use of first order classification rules. Second, the applicability to both discrete and continuous attributes by means a supervised discretization. Third, the consideration of knowledge on the data model embedded in the database schema during the generation of classification rules. The proposed method has been implemented in the new system Mr-SBC, which is tightly integrated with a relational DBMS. Testing has been performed on two datasets and four benchmark tasks. Results on predictive accuracy and efficiency are in favour of Mr-SBC for the most complex tasks.	Univ Bari, Dipartimento Informat, I-70126 Bari, Italy	Ceci, M (reprint author), Univ Bari, Dipartimento Informat, Via Orabona 4, I-70126 Bari, Italy.		Malerba, Donato/H-3850-2012				Blockeel H., 1998, THESIS KATHOLIEKE U; DERAEDT L, 1998, LECT NOTES ARTIFICIA, V1446; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Dzeroski S, 1999, LECT NOTES ARTIF INT, V1634, P80; FAYYAD UM, 1994, P 13 INT JOINT C ART, P1022; FLACH P, 1 ORDER BAYESIAN CLA; FLACH PA, 2000, MACHINE LEARNING; FLACH PA, 2000, P ECML2000 WORKSH DE, P33; FRIEDMAN N, 1999, P 6 INT JOINT C ART; GETOOR L, 2002, P KDD 2002 WORKSH MU, P36; Getoor L, 2001, P 1 WORKSH MULT DAT; Getoor L., 2001, THESIS STANFORD U; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KROGEL M, 2001, LECT NOTES ARTIFICIA, V2157; Lachiche N, 2003, LECT NOTES ARTIF INT, V2583, P133; LEIVA HA, 2002, MRDTL MULTIRELATIONA; Mitchell T.M., 1997, MACHINE LEARNING; MUGGLETON S, 1989, P 6 INT WORKSH MACH, P113; POMPE U, 1994, CISM LECT NOTES; Pompe Uros, 1995, P 5 INT WORKSH IND L, P417; SRINIVASAN A, 1999, PRGTR0899 OXF U COMP; Wrobel S, 2001, RELATIONAL DATA MINING, P74	23	16	18	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20085-1	LECT NOTES ARTIF INT			2003	2838						95	106				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BX96Y	WOS:000187062000011	
S	Flach, P; Lachiche, N		Dzeroski, S; Flach, P		Flach, P; Lachiche, N			1BC: A first-order Bayesian classifier	INDUCTIVE LOGIC PROGRAMMING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th International Workshop on Inductive Logic Programming (ILP-99)	JUN 24-27, 1999	BLED, SLOVENIA	ILPNet 2, Network Excellence Induct Log Programming, COMPULOG Net, European Network Excellence Computat Log, Jozef Stefan Inst, LPA Software Inc, Univ Bristol				In this paper we present IBC, a first-order Bayesian Classifier. Our approach is to view individuals as structured terms, and to distinguish between structural predicates referring to subterms (e.g. atoms from molecules), and properties applying to one or several of these subterms (e.g. a bond between two atoms). We describe an individual in terms of elementary features consisting of zero or more structural predicates and one property; these features are considered conditionally independent following the usual naive Bayes assumption. 1BC has been implemented in the context of the first-order descriptive learner Tertius, and we describe several experiments demonstrating the viability of our approach.	Univ Bristol, Bristol BS8 1TH, Avon, England	Flach, P (reprint author), Univ Bristol, Bristol BS8 1TH, Avon, England.						De Raedt L., 1998, LECT NOTES ARTIF INT, V1446, P1; Dehaspe L, 1997, LECT NOTES ARTIF INT, V1297, P125; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; DOLSAK B, 1994, GMD STUDIEN, V237, P305; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Flach P.A., 1998, LECT NOTES ARTIF INT, V1446, P185; FLACH PA, 1999, UNPUB 1 ORDER APPROA; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; Lavrac N., 1994, INDUCTIVE LOGIC PROG; MUGGLETON S, 1989, P 6 INT WORKSH MACH, P113; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; PIOLA R, 1997, P 14 INT C MACH LEAR, P46; Pompe Uros, 1995, P 5 INT WORKSH IND L, P417; RYMON R, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P539; SEBAG M, 1998, LECT NOTES ARTIF INT, V1446, P95; Srinivasan A., 1994, GMD STUDIEN, V237, P217; ZUCKER JD, 1998, LECT NOTES ARTIF INT, V1446, P235	17	16	16	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-66109-3	LECT NOTES ARTIF INT			1999	1634						92	103				12	Computer Science, Artificial Intelligence	Computer Science	BR08D	WOS:000165602200010	
J	Stow, CA; Carpenter, SR; Lathrop, RC				Stow, CA; Carpenter, SR; Lathrop, RC			A Bayesian observation error model to predict cyanobacterial biovolume from spring total phosphorus in Lake Mendota, Wisconsin	CANADIAN JOURNAL OF FISHERIES AND AQUATIC SCIENCES			English	Article							BLUE-GREEN-ALGAE; SIGMOID RELATIONSHIPS; RELATIVE BIOMASS; CHLOROPHYLL	We developed a logistic model for predicting summer blue-green biovolume from mean (log metric) spring total phosphorus concentration in Lake Mendota, Wisconsin. The model incorporates uncertainty in the sample estimates of the ''true'' mean total phosphorus values. We used Bayes Theorem to assess model parameters and predictive uncertainty from 19 years of data. When compared with a ''naive'' model that does not accommodate phosphorus uncertainty, the observation error model has a higher parameter variance, but lower prediction uncertainty. Lower prediction uncertainty occurs because some of the noise in the data is resolved as phosphorus uncertainty, thus reducing the variance of the model disturbance term. The observation error model results in less stringent phosphorus targets to meet acceptable blue-green levels than does the naive model because of this lower prediction uncertainty.	UNIV WISCONSIN,CTR LIMNOL,MADISON,WI 53706; WISCONSIN DEPT NAT RESOURCES,BUR RES,MONONA,WI 53716							Caroll R. J., 1995, MEASUREMENT ERROR NO; CHOWFRASER P, 1994, CAN J FISH AQUAT SCI, V51, P2052, DOI 10.1139/f94-208; DILLON PJ, 1974, LIMNOL OCEANOGR, V19, P767; Fuller W.A., 1987, MEASUREMENT ERROR MO; GEWEKE J, 1989, ECONOMETRICA, V57, P1317, DOI 10.2307/1913710; *IMSL, 1987, US MAN MATH LIB; Larson DW, 1996, AM SCI, V84, P7; Lathrop Richard C., 1992, P97; Lathrop R.C., 1992, FOOD WEB MANAGEMENT, P69; Ludwig Donald, 1993, SCIENCE, V260, P36; MCALLISTER MK, 1994, CAN J FISH AQUAT SCI, V51, P2673, DOI 10.1139/f94-267; MCCAULEY E, 1989, CAN J FISH AQUAT SCI, V46, P1171, DOI 10.1139/f89-152; National Research Council, 1992, REST AQ EC SCI TECHN; Piessens R, 1983, QUADPACK; PRAIRIE YT, 1995, CAN J FISH AQUAT SCI, V52, P788; RECKHOW KH, 1993, ECOL MODEL, V70, P35, DOI 10.1016/0304-3800(93)90071-Y; Reckhow K H, 1983, ENG APPROACHES LAKE; RECKHOW KH, 1987, WATER RESOUR B, V24, P723; Shapiro J., 1990, VERH INT VEREIN LIMN, V24, P38; SMITH VH, 1986, CAN J FISH AQUAT SCI, V43, P148, DOI 10.1139/f86-016; Soranno PA, 1996, ECOL APPL, V6, P865, DOI 10.2307/2269490; Stow CA, 1996, WATER RESOUR RES, V32, P165, DOI 10.1029/95WR03109; STOW CA, 1995, ECOL APPL, V5, P248, DOI 10.2307/1942067; TRIMBEE AM, 1987, CAN J FISH AQUAT SCI, V44, P1337, DOI 10.1139/f87-158; WALKER WW, 1985, LAKE RESERV MANAGE, V4, P57; WATSON S, 1992, CAN J FISH AQUAT SCI, V49, P2605, DOI 10.1139/f92-288; WOLPERT RL, 1991, CONT MATH, V115, P101; Zellner A., 1971, INTRO BAYESIAN INFER	28	16	17	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA ON K1A 0R6, CANADA	0706-652X			CAN J FISH AQUAT SCI	Can. J. Fish. Aquat. Sci.	FEB	1997	54	2					464	473		10.1139/cjfas-54-2-464		10	Fisheries; Marine & Freshwater Biology	Fisheries; Marine & Freshwater Biology	XB787	WOS:A1997XB78700022	
J	Calders, T; Verwer, S				Calders, Toon; Verwer, Sicco			Three naive Bayes approaches for discrimination-free classification	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 20-24, 2010	Barcelona, SPAIN			Discrimination-aware classification; Naive Bayes; Expectation maximization		In this paper, we investigate how to modify the naive Bayes classifier in order to perform classification that is restricted to be independent with respect to a given sensitive attribute. Such independency restrictions occur naturally when the decision process leading to the labels in the data-set was biased; e.g., due to gender or racial discrimination. This setting is motivated by many cases in which there exist laws that disallow a decision that is partly based on discrimination. Naive application of machine learning techniques would result in huge fines for companies. We present three approaches for making the naive Bayes classifier discrimination-free: (i) modifying the probability of the decision being positive, (ii) training one model for every sensitive attribute value and balancing them, and (iii) adding a latent variable to the Bayesian model that represents the unbiased label and optimizing the model parameters for likelihood using expectation maximization. We present experiments for the three approaches on both artificial and real-life data.	[Calders, Toon; Verwer, Sicco] Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands	Verwer, S (reprint author), Eindhoven Univ Technol, POB 513, NL-5600 MB Eindhoven, Netherlands.	s.verwer@tue.nl	Verwer, Sicco/D-1544-2012				CALDERS T, 2010, CONSTRUCTING DECISIO; CALDERS T, 2009, IEEE ICDM WORKSH DOM; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DUIVESTEIJN W, 2008, P ECML PKDD 08, P301; Elkan C., 2001, P 17 INT JOINT C ART, P973; KAMIRAN F, 2010, P BEN; KAMIRAN F, 2009, P IC409, pIC409; KOTLOWSKI W, 2007, P ECML PKDD 07; MARGINEANTU D, 1999, LEARNING DECISION TR; NIJSSEN S, 2007, P ACM SIGKDD; PEDRESCHI D, 2009, P SIAM DM; PEDRESCHI D, 2008, P ACM SIGKDD	12	15	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810			DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	SEP	2010	21	2			SI		277	292		10.1007/s10618-010-0190-x		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	634FI	WOS:000280564900005	
J	Maji, P				Maji, Pradipta			f-Information Measures for Efficient Selection of Discriminative Genes From Microarray Data	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						Classification; feature selection; gene selection; microarray analysis; mutual information	CANCER CLASSIFICATION; SUBSET-SELECTION	Among the great amount of genes presented in microarray gene expression data, only a small fraction is effective for performing a certain diagnostic test. In this regard, mutual information has been shown to be successful for selecting a set of relevant and nonredundant genes from microarray data. However, information theory offers many more measures such as the f-information measures that may be suitable for selection of genes from microarray gene expression data. This paper presents different f-information measures as the evaluation criteria for gene selection problem. To compute the gene-gene redundancy (respectively, gene-class relevance), these information measures calculate the divergence of the joint distribution of two genes' expression values (respectively, the expression values of a gene-and the class labels of samples) from the joint distribution when two genes (respectively, the gene and class label) are considered to be completely independent. The performance of different f-information measures is compared with that of the mutual information based on the predictive accuracy of naive Bayes classifier, K-nearest neighbor rule, and support vector machine. An important finding is that some f-information measures are shown to be effective for selecting relevant and nonredundant genes from microarray data. The effectiveness of different f-information measures, along with a comparison with mutual information, is demonstrated on breast cancer, leukemia, and colon cancer datasets. While some f-information measures provide 100% prediction accuracy for all three microarray datasets, mutual information attains this accuracy only for breast cancer dataset, and 98.6% and 93.6% for leukemia and colon cancer datasets, respectively.	Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India	Maji, P (reprint author), Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India.	pmaji@isical.ac.in					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Blanco R, 2004, INT J PATTERN RECOGN, V18, P1373, DOI 10.1142/S0218001404003800; Devijver P., 1982, PATTERN RECOGNITION; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523; Duda R.O., 1999, PATTERN CLASSIFICATI; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Heyer LJ, 1999, GENOME RES, V9, P1106, DOI 10.1101/gr.9.11.1106; JIANG C, 2004, IEEE T KNOWL DATA EN, V16, P1370; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Li JX, 2007, IEEE T INF TECHNOL B, V11, P398, DOI 10.1109/TITB.2006.892693; Liao JG, 2007, BIOINFORMATICS, V23, P1945, DOI 10.1093/bioinformatics/btm287; Liu JM, 2005, CALCIFIED TISSUE INT, V76, P1, DOI 10.1007/s00223-004-0007-2; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Pluim JPW, 2004, IEEE T MED IMAGING, V23, P1508, DOI 10.1109/TMI.2004.836872; Vajda I., 1989, THEORY STAT INFERENC; Vapnik V., 1995, NATURE STAT LEARNING; WEST M, 2001, P NATL ACAD SCI USA, V98	17	15	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9294	1558-2531		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	APR	2009	56	4					1063	1069		10.1109/TBME.2008.2004502		7	Engineering, Biomedical	Engineering	443UV	WOS:000265937200016	
J	Menahem, E; Shabtai, A; Rokach, L; Elovici, Y				Menahem, Eitan; Shabtai, Asaf; Rokach, Lior; Elovici, Yuval			Improving malware detection by applying multi-inducer ensemble	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							COMBINING CLASSIFIERS; CLASSIFICATION	Detection of malicious software (malware) using machine learning methods has been explored extensively to enable fast detection of new released malware. The performance of these classifiers depends on the induction algorithms being used. In order to benefit from multiple different classifiers, and exploit their strengths we suggest using an ensemble method that will combine the results of the individual classifiers into one final result to achieve overall higher detection accuracy. In this paper we evaluate several combining methods using five different base inducers (C4.5 Decision Tree, Naive Bayes, KNN, VFI and OneR) on five malware datasets. The main goal is to find the best combining method for the task of detecting malicious riles in terms of accuracy, AUC and Execution time. (C) 2008 Elsevier B.V. All rights reserved.	[Menahem, Eitan; Shabtai, Asaf; Rokach, Lior; Elovici, Yuval] Ben Gurion Univ Negev, Duetsche Telekom Labs, IL-84105 Beer Sheva, Israel	Rokach, L (reprint author), Ben Gurion Univ Negev, Duetsche Telekom Labs, IL-84105 Beer Sheva, Israel.	eitanme@bgu.ac.il; shabtaia@bgu.ac.il; liorrk@bgu.ac.il; elovici@bgu.ac.il	ELOVICI, YUVAL/F-1468-2012; Rokach, Lior/F-8247-2010		Deutsche Telecom AG	This research is supported by Deutsche Telecom AG.	ABOUASSALEH T, 2004, P ANN INT COMP SOFTW; Buntine W., 1990, THESIS U TECHNOLOGY; CAIA DM, 2007, COMPUTATIONAL STAT D, V51, P3156; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Demsar J, 2006, J MACH LEARN RES, V7, P1; DIKINSON J, 2005, NEW ANTIVIRUS FORMUL; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GUVENIR GD, 1997, P EUR C MACH LEARN, P85; HEIDARI M, 2004, MALICIOUS CODES DEPT; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JOHN GH, 1995, P 11 C UNC ART INT, P338; Kabiri P., 2005, INT J NETWORK SECURI, V1, P84; KELLY C, 2006, P INT SIAM WORKSH FE; KIBLER DA, 1991, MACH LEARN, P37; KIENZLE DM, 2003, ACM WORKSH RAP MALC; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kolter JZ, 2006, J MACH LEARN RES, V7, P2721; Kuncheva L.I., 2005, INFORM FUSION, V6, P3, DOI 10.1016/j.inffus.2004.04.009; MAHONEY MV, 2003, THESIS FLORIDA TECH; MENAHEM E, 2008, THESIS BENGURION U N; Mitchell T.M., 1997, MACHINE LEARNING; Moskovitch R, 2008, COMPUT STAT DATA AN, V52, P4544, DOI 10.1016/j.csda.2008.01.028; Mukkamala S, 2005, J NETW COMPUT APPL, V28, P167, DOI 10.1016/j.jnca.2004.01.003; Opitz DW, 1996, ADV NEUR IN, V8, P535; Quinlan Ross, 1993, C4 5 PROGRAM MACHINE; Schult M., 2001, P IEEE S SEC PRIV, P178; SEEWALD A, 2003, THESIS TU WIEN; Tumer K., 1996, CONNECT SCI, V8, P385; WANG K, 2004, P INT S REC ADV INTR, P1; WHITE S, 1999, ANATOMY COMMERCIAL G; WHITE SR, 1998, OPEN PROBLEMS COMPUT; Witten IH, 2005, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; ZHANG B, 2007, AUTONOMIC TRUSTED CO, P277	35	15	16	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	FEB 15	2009	53	4					1483	1494		10.1016/j.csda.2008.10.015		12	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	411CX	WOS:000263626700059	
J	Zadora, G				Zadora, Grzegorz			Classification of Glass Fragments Based on Elemental Composition and Refractive Index	JOURNAL OF FORENSIC SCIENCES			English	Article						forensic sciences; glass; Naive Bayes Classifiers; support vector machines; likelihood ratio; SEM-EDX; GRIM	SUPPORT VECTOR MACHINES; PATTERN-RECOGNITION; DISCRIMINATION; NETWORKS	The aim of this study was to assess the efficiency of likelihood ratio (LR)-based measures when they are applied to solving various classification problems for glass objects which are described by elemental composition, and refractive index (RI) values, and compare LR-based methods to other classification methods such as support vector machines (SVM) and naive Bayes classifiers (NBC). One hundred and fifty-three glass objects (23 building windows, 25 bulbs, 32 car windows, 57 containers, and 16 headlamps) were analyzed by scanning electron microscopy coupled with an energy dispersive X-ray spectrometer. Refractive indices for building and car windows were measured before (RI(b)), and after (RI(a)) an annealing process. The proposed scheme for glass fragment(s) classification demonstrates some efficiency, although the classification of car windows (c) and building windows (w) must be treated carefully. This is because of their very similar elemental content. However, a combination of elemental content and information on the change in RI during annealing (Delta RI = RI(a)-RI(b)) gave very promising results. A LR model for the classification of glass fragments into use-type categories for forensic purposes gives slightly higher misclassification rates than SVM and NBC. However, the observed differences between results obtained by all three approaches were very similar, especially when applied to the car window and building window classification problem. Therefore, the LR model can be recommended because of the ease of interpretation of LR-based measures of certainty.	Inst Forens Res, PL-31033 Krakow, Poland	Zadora, G (reprint author), Inst Forens Res, Westerplatte 9, PL-31033 Krakow, Poland.	gzadora@ies.krakow.pl					Aitken C. G. G., 2004, STAT EVALUATION EVID; Aitken CGG, 2007, J FORENSIC SCI, V52, P412, DOI 10.1111/j.1556-4029.2006.00358.x; Aitken CGG, 2006, COMPUT STAT DATA AN, V50, P2571, DOI 10.1016/j.csda.2005.04.005; Aitken C.G.G., 2004, APPL STAT, V53, p[109, 665]; Bishop CM, 2006, PATTERN RECOGNITION; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Caddy B., 2001, FORENSIC EXAMINATION; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Curran JM, 2000, FORENSIC INTERPRETAT; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HICKMAN DA, 1981, FORENSIC SCI INT, V17, P265, DOI 10.1016/0379-0738(81)90176-6; HICKMAN DA, 1987, FORENSIC SCI INT, V33, P23, DOI 10.1016/0379-0738(87)90137-X; Hicks T, 2003, FORENSIC SCI INT, V137, P107, DOI 10.1016/S0379-0738(03)00278-0; KOONS RD, 1988, J FORENSIC SCI, V33, P49; LOCKE J, 1985, FORENSIC SCI INT, V29, P237, DOI 10.1016/0379-0738(85)90117-3; Pawluk-Kolc M, 2008, FORENSIC SCI INT, V174, P222, DOI 10.1016/j.forsciint.2007.04.229; Pawluk-Kolc M, 2006, FORENSIC SCI INT, V160, P53, DOI 10.1016/j.forsciint.2005.08.016; *R FDN, R FDN STAT COMP VERS; SMOLA A, 1998, NCRR98030 COLT ROYAL; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Trejos T, 2005, TALANTA, V67, P388, DOI 10.1016/j.talanta.2005.01.042; Vapnik V., 1995, NATURE STAT LEARNING; WINSTANLEY R, 1985, FORENSIC SCI INT, V29, P1, DOI 10.1016/0379-0738(85)90028-3; ZADORA G, 2003, B INT STAT I, P364; Zadora G, 2007, J CHEMOMETR, V21, P174, DOI 10.1002/cem.1030; Zadora G, 2003, MATER CHEM PHYS, V81, P345, DOI 10.1016/S0254-0584(03)00018-X; ZADORA G, 2001, PROB FORENSIC SCI, V45, P36; ZADORA G, 2006, PROBL FORENSIC SCI, V45, P91	35	15	15	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0022-1198			J FORENSIC SCI	J. Forensic Sci.	JAN	2009	54	1					49	59		10.1111/j.1556-4029.2008.00905.x		11	Medicine, Legal	Legal Medicine	388WU	WOS:000262051600008	
J	Jing, YS; Pavlovic, V; Rehg, JM				Jing, Yushi; Pavlovic, Vladimir; Rehg, James M.			Boosted Bayesian network classifiers	MACHINE LEARNING			English	Article						Bayesian network classifiers; AdaBoost; ensemble models; structure learning	LOGISTIC-REGRESSION; PREDICTIONS; LIKELIHOOD; ALGORITHMS; TREES	The use of Bayesian networks for classification problems has received a significant amount of recent attention. Although computationally efficient, the standard maximum likelihood learning method tends to be suboptimal due to the mismatch between its optimization criteria (data likelihood) and the actual goal of classification (label prediction accuracy). Recent approaches to optimizing classification performance during parameter or structure learning show promise, but lack the favorable computational properties of maximum likelihood learning. In this paper we present boosted Bayesian network classifiers, a framework to combine discriminative data-weighting with generative training of intermediate models. We show that boosted Bayesian network classifiers encompass the basic generative models in isolation, but improve their classification performance when the model structure is suboptimal. We also demonstrate that structure learning is beneficial in the construction of boosted Bayesian network classifiers. On a large suite of benchmark data-sets, this approach outperforms generative graphical models such as naive Bayes and TAN in classification accuracy. Boosted Bayesian network classifiers have comparable or better performance in comparison to other discriminatively trained graphical models including ELR and BNC. Furthermore, boosted Bayesian networks require significantly less training time than the ELR and BNC algorithms.	[Jing, Yushi; Rehg, James M.] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA; [Pavlovic, Vladimir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Jing, YS (reprint author), Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.	yjing@cc.gatech.edu; vladimir@cs.rutgers.edu; rehg@cc.gatech.edu					Altun Y., 2003, P 20 INT C MACH LEAR, P3; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C. L., 1998, UCI REPOSITORY MACHI; CHELBA C, 2004, MSRTR200433 MICR; Chickering DM, 1997, MACH LEARN, V29, P181; CHOUDHURY T, 2002, P ICPR, V3, P789; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cutting D., 1992, P 3 C APPL NAT LANG, P133, DOI 10.3115/974499.974523; Demsar J, 2006, J MACH LEARN RES, V7, P1; DEVROYE L, 1996, PROBABILISTIC THEORY, P260; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; DRUCKER H, 1996, P 8 ADV NEUR INF PRO, P470; Duda R., 1973, PATTERN CLASSIFICATI; Elkan C., 1997, CS97557 U CAL DEP CO; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N., 2000, P 16 C UNC ART INT U, P201; Friedman N., 1999, P 16 INT JOINT C ART, P1300; Greiner R., 2002, P 18 NAT C ART INT, P167; Grossman D., 2004, P 21 INT C MACH LEAR, P361; HECKERMAN D, 1995, MSRT9506; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Jing Y., 2005, P 22 INT C MACH LEAR, P369, DOI 10.1145/1102351.1102398; Jojic V, 2004, BIOINFORMATICS, V20, P161, DOI 10.1093/bioinformatics/bth917; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Kohavi R., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Langley P., 1992, P 10 NAT C ART INT, P223; McCallum A., 2000, P 17 INT C MACH LEAR, P591; NADAS A, 1983, IEEE T ACOUST SPEECH, V31, P814, DOI 10.1109/TASSP.1983.1164173; Ng AY, 2002, ADV NEUR IN, V14, P841; Niculescu-mizil A., 2005, P 21 C UNC ART INT; PAVLOVIC V, 2000, 2000 IEEE COMP SOC C, V2, P34; Pavlovic V, 2002, BIOINFORMATICS, V18, P19, DOI 10.1093/bioinformatics/18.1.19; Pearl J., 1988, PROBABILISTIC REASON; Pernkopf F., 2005, P 22 INT C MACH LEAR, P657, DOI 10.1145/1102351.1102434; Rabiner L., 1993, FUNDAMENTALS SPEECH; REHG JM, 2003, IEEE T PATTERN ANAL, V25; RIDGEWAY G, 1998, P 4 INT C KNOWL DISC; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Schneiderman H, 2004, PROC CVPR IEEE, P639; Segal E., 2003, BIOINFORMATICS S1, V19, P273; Taskar B, 2004, P 21 INT C MACH LEAR, P102; Torralba A., 2004, P IEEE C COMP VIS PA, V2, DOI 10.1109/CVPR.2004.1315241; Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29	51	15	23	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	NOV	2008	73	2					155	184		10.1007/s10994-008-5065-7		30	Computer Science, Artificial Intelligence	Computer Science	353MF	WOS:000259571400003	
J	Stout, M; Bacardit, J; Hirst, JD; Krasnogor, N				Stout, Michael; Bacardit, Jaume; Hirst, Jonathan D.; Krasnogor, Natalio			Prediction of recursive convex hull class assignments for protein residues	BIOINFORMATICS			English	Article							SECONDARY STRUCTURE PREDICTION; MOLECULAR-FIELD ANALYSIS; THERMODYNAMIC DATABASE; SOLVENT ACCESSIBILITY; SEQUENCE ALIGNMENT; LIGAND-BINDING; AMINO-ACID; PROTHERM; SITES; DEPTH	Motivation: We introduce a new method for designating the location of residues in folded protein structures based on the recursive convex hull (RCH) of a point set of atomic coordinates. The RCH can be calculated with an efficient and parameterless algorithm. Results: We show that residue RCH class contains information complementary to widely studied measures such as solvent accessibility (SA), residue depth (RD) and to the distance of residues from the centroid of the chain, the residues exposure (Exp). RCH is more conserved for related structures across folds and correlates better with changes in thermal stability of mutants than the other measures. Further, we assess the predictability of these measures using three types of machine-learning technique: decision trees (C4.5), Naive Bayes and Learning Classifier Systems (LCS) showing that RCH is more easily predicted than the other measures. As an exemplar application of predicted RCH class (in combination with other measures), we show that RCH is potentially helpful in improving prediction of residue contact numbers (CN).	[Stout, Michael; Bacardit, Jaume; Krasnogor, Natalio] Automated Scheduling Optimizat & Planning Res Grp, Sch Comp Sci, Nottingham, England; [Bacardit, Jaume] Univ Nottingham, Sch Biosci, Nottingham NG7 2RD, England; [Hirst, Jonathan D.] Univ Nottingham, Sch Chem, Nottingham NG7 2RD, England	Krasnogor, N (reprint author), Automated Scheduling Optimizat & Planning Res Grp, Sch Comp Sci, Nottingham, England.		Hirst, Jonathan/G-7681-2011	Hirst, Jonathan/0000-0002-2726-0983			BACARDIT J, 2004, P 8 ANN C GEN EV COM, P247; BACARDIT J, 2004, THESIS RAMON LLULL U; BACARDIT J, 2007, GECCO 07, V1, P346; BADELCHAGNON A, 1994, J MOL GRAPHICS, V12, P162, DOI 10.1016/0263-7855(94)80082-0; Baldi P, 2002, IEEE INTELL SYST, V17, P28, DOI 10.1109/MIS.2002.999217; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Bava KA, 2004, NUCLEIC ACIDS RES, V32, pD120, DOI 10.1093/nar/gkh082; Ben-Shimon A, 2005, J MOL BIOL, V351, P309, DOI 10.1016/j.jmb.2005.06.047; CHAKRAVARTY S, 1999, STRUCTURE, V7, P724; Chen Brian Y, 2007, J Bioinform Comput Biol, V5, P353, DOI 10.1142/S021972000700276X; Coleman RG, 2006, J MOL BIOL, V362, P441, DOI 10.1016/j.jmb.2006.07.022; Cover T. M., 2006, WILEY SERIES TELECOM; Dor O, 2007, PROTEINS, V66, P838, DOI 10.1002/prot.21298; EIDHAMMER I, 2003, PROTEIN BIOINFORMATI; Gianese G, 2006, J COMPUT CHEM, V27, P621, DOI 10.1002/jcc.20370; Gromiha MM, 1999, NUCLEIC ACIDS RES, V27, P286, DOI 10.1093/nar/27.1.286; Hamelryck T, 2005, PROTEINS, V59, P38, DOI 10.1002/prot.20379; HOLLAND JH, 1975, ADAPTATION NATURAL A, P313; HOLM L, 1993, J MOL BIOL, V233, P123, DOI 10.1006/jmbi.1993.1489; Holmes JB, 2005, J MOL BIOL, V354, P706, DOI 10.1016/j.jmb.2005.09.081; JOHN GH, 1995, P 11 C UNC ART INT, P338; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; Kawabata T, 2007, PROTEINS, V68, P516, DOI 10.1002/prot.21283; Kinjo AR, 2005, PROTEINS, V58, P158, DOI 10.1002/prot.20300; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kumar MDS, 2006, NUCLEIC ACIDS RES, V34, pD204, DOI 10.1093/nar/gkj103; LEE B, 1971, J MOL BIOL, V55, P379, DOI 10.1016/0022-2836(71)90324-X; Lee M, 2006, J ORG CHEM, V71, P5082, DOI 10.1021/jo052659z; Liang J, 2001, BIOPHYS J, V81, P751; Lin TH, 1999, BBA-PROTEIN STRUCT M, V1429, P476, DOI 10.1016/S0167-4838(98)00261-1; Lin TH, 2001, COMPUT CHEM, V25, P489, DOI 10.1016/S0097-8485(00)00113-3; Liu S, 2007, PROTEINS, V68, P636, DOI 10.1002/prot.21459; MEIER R, 1995, ICIP 95, V3, P552; MILLER RG, 1981, SIMULTANEOUS STAT IN; Noguchi T, 2001, NUCLEIC ACIDS RES, V29, P219, DOI 10.1093/nar/29.1.219; Pintar A, 2003, BIOINFORMATICS, V19, P313, DOI 10.1093/bioinformatics/19.2.313; PREPARATA FP, 1977, COMMUN ACM, V20, P87, DOI 10.1145/359423.359430; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; ROST B, 1994, PROTEINS, V20, P216, DOI 10.1002/prot.340200303; SANDER C, 1991, PROTEINS, V9, P56, DOI 10.1002/prot.340090107; STOUT M, 2008, IN PRESS SOFT COMPUT; Van Walle I, 2005, BIOINFORMATICS, V21, P1267, DOI 10.1093/bioinformatics/bth493; Vlahovicek K, 2005, NUCLEIC ACIDS RES, V33, pW252, DOI 10.1093/nar/gki362; Wang Y, 2006, LECT NOTES COMPUT SC, V3959, P505; Witten IH, 2005, DATA MINING PRACTICA; Wood MJ, 2005, PROTEINS, V59, P476, DOI 10.1002/prot.20435	46	15	15	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	APR 1	2008	24	7					916	923		10.1093/bioinformatics/btn050		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	281BJ	WOS:000254470900005	
J	Brown, LD				Brown, Lawrence D.			IN-SEASON PREDICTION OF BATTING AVERAGES: A FIELD TEST OF EMPIRICAL BAYES AND BAYES METHODOLOGIES	ANNALS OF APPLIED STATISTICS			English	Article						Empirical Bayes; hierarchical Bayes; harmonic prior; variance stabilization; FDR; sports; hitting streaks; hot-hand	ESTIMATORS	Batting average is one of the principle performance measures for an individual baseball player. It is natural to statistically model this as a bionomial variable proportion, with a given (observed) number of qualifying attempts (called "at-bats"), an observed number of successes ("hits") distributed according to the binomial distribution, and with a true (but unknown) value of pi that represents the player's latent ability. This is a common data structure in many statistical applications; and so the methodological study here has implications for Such a range of applications. We look at batting records for each Major League player over the course of a single season (2005). The primary focus is on using only the batting records from an earlier part of the season (e.g., the first 3 months) in order to estimate the batter's latent ability pi, and consequently, also to predict their batting-average performance for the remainder of the season. Since we are using a season that has already concluded, we can then validate our estimation performance by comparing the estimated values to the actual values for the remainder of the season. The prediction methods to be investigated are motivated from empirical Bayes and hierarchical Bayes interpretations. A newly proposed nonparametric empirical Bayes procedure performs particularly well in the basic analysis of the full data set, though less well with analysis involving more homogeneous subsets of the data. In In those more homogeneous situations better performance is obtained from appropriate versions of more familiar methods. In all situations the poorest performing choice is the naive predictor which directly uses the current average to predict the future average. One feature of all the statistical methodologies here is the preliminary use of a new form of variance stabilizing transformation in order to transform the binomial data problem into a somewhat more familiar structure involving (approximately,) Normal random variables with known variances. This transformation technique is also used in the construction of a new empirical validation test of the binomial model assumption that is the conceptual basis for all our analyses.	Univ Penn, Dept Stat, Philadelphia, PA 19104 USA	Brown, LD (reprint author), Univ Penn, Dept Stat, Philadelphia, PA 19104 USA.	lbrown@wharton.upenn.edu					Albert J, 2008, J QUANTITATIVE ANAL, V4; Albert J., 2001, CURVE BALL BASEBALL; Albright S. C, 1993, J AM STAT ASSOC, V88, P1175, DOI 10.2307/2291254; ANSCOMBE FJ, 1948, BIOMETRIKA, V35, P246, DOI 10.2307/2332343; BARTLETT MS, 1947, BIOMETRICS, V3, P39, DOI 10.2307/3001536; Bartlett MS, 1936, J R STATIST SOC    S, V3, P68; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Berger J.O., 1985, STAT DECISION THEORY; BROWN KD, 2007, UNIFIED VIEW REGRESS; Brown L., 2002, SANKHYA SER A, V64, P611; BROWN LD, 1975, J AM STAT ASSOC, V70, P417, DOI 10.2307/2285833; BROWN LD, 1971, ANN MATH STAT, V42, P855, DOI 10.1214/aoms/1177693318; BROWN LD, 2006, ESTIMATORS GAUSSIAN; BROWN LD, 2007, LECT NOTES SHRINKAGE; BROWN LD, 2007, EMPIRICAL BAYE UNPUB; BROWN LD, 2008, IN SEASON PREDICTI S, DOI DOI 10.1214/07-AOAS138SUPP; BROWN LD, 2007, ROOT UNROOT ALGORITH; Efron B, 2003, ANN STAT, V31, P366, DOI 10.1214/aos/1051027871; EFRON B, 1975, J AM STAT ASSOC, V70, P311, DOI 10.2307/2285814; EFRON B, 1977, SCI AM, V236, P119; Frey J, 2007, AM STAT, V61, P105, DOI 10.1198/000313007X192437; GILOVICH T, 1985, COGNITIVE PSYCHOL, V17, P295, DOI 10.1016/0010-0285(85)90010-6; James W., 1961, P 4 BERK S PROB STAT, VI, P367; Lehmann E., 1998, THEORY POINT ESTIMAT; Lewis Michael, 2004, MONEYBALL ART WINNIN; Lindley D. V, 1962, J R STAT SOC B, V24, P285; MOSTELLER F, 1961, BIOMETRIKA, V48, P433, DOI 10.2307/2332765; Robbins H, 1956, P 3 BERK S MATH STAT, V1, P157; ROBBINS H, 1956, P 2 BERK S MATH STAT, P131; STEIN C., 1973, P PRAG S AS STAT CHA, VII, P345; STEIN CM, 1962, J ROY STAT SOC B, V24, P265; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; STERN H, 2005, STAT GUIDE UNKNOWN, P393; STRAWDER.WE, 1971, ANN MATH STAT, V42, P385, DOI 10.1214/aoms/1177693528; STRAWDERMAN WE, 1973, ANN MATH STAT, V44, P1189	35	15	15	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	MAR	2008	2	1					113	152		10.1214/07-AOAS138		40	Statistics & Probability	Mathematics	374QB	WOS:000261057700012	
J	Correa, M; Bielza, C; Ramirez, MD; Alique, JR				Correa, M.; Bielza, C.; Ramirez, M. de J.; Alique, J. R.			A Bayesian network model for surface roughness prediction in the machining process	INTERNATIONAL JOURNAL OF SYSTEMS SCIENCE			English	Article						Bayesian networks; supervised classification; probabilistic graphical models; surface roughness; high-speed milling	END-MILLING OPERATIONS; ADAPTIVE-CONTROL SYSTEM; NEURAL-NETWORKS; RECOGNITION	The literature reports many scientific works on the use of artificial intelligence techniques such as neural networks or fuzzy logic to predict surface roughness. This article aims at introducing Bayesian network-based classifiers to predict surface roughness (Ra) in high-speed machining. These models are appropriate as prediction techniques because the non-linearity of the machining process demands robust and reliable algorithms to deal with all the invisible trends present when a work piece is machining. The experimental test obtained from a high-speed milling contouring process analysed the indicator of goodness using the Naive Bayes and the Tree-Augmented Network algorithms. Up to 81.2% accuracy was achieved in the Ra classification results. Therefore, we envisage that Bayesian network-based classifiers may become a powerful and flexible tool in high-speed machining.	[Correa, M.; Alique, J. R.] CSIC, Dept Informat Ind, Inst Automat Ind, Madrid, Spain; [Bielza, C.] Univ Politecn Madrid, Dept Inteligencia Artificial, Madrid, Spain; [Ramirez, M. de J.] ITESM, Dept Mecatron & Automatiz, Monterrey, Mexico	Correa, M (reprint author), CSIC, Dept Informat Ind, Inst Automat Ind, Madrid, Spain.	macorrea@iai.csic.es	Bielza, Concha/F-9277-2013				[Anonymous], 13022002 ISO; Brezocnik M, 2003, MATER MANUF PROCESS, V18, P475, DOI 10.1081/AMP-120022023; Castillo E., 1997, EXPERT SYSTEMS PROBA; Chen JC, 2000, J INTELL MANUF, V11, P85, DOI 10.1023/A:1008908309585; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CORREA M, 2004, 25 C AUT, P8; CORREA M, 2003, THESIS U POLITECNICA; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O., 2001, PATTERN CLASSIFICATI; *ELV CONS, 2002, 1 EUR WORKSH PROB GR, P1; Feng CX, 2003, IIE TRANS, V35, P11, DOI 10.1080/07408170390116634; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Huang B, 2003, INT J ADV MANUF TECH, V21, P339; ISMAIL F, 1993, J ENG IND-T ASME, V115, P245; James M., 1985, CLASSIFICATION ALGOR; KIRBY D, 2004, J IND TECHNOLOGY, V20, P1; Kirby ED, 2006, EXPERT SYST APPL, V30, P592, DOI 10.1016/j.eswa.2005.07.005; Lou M.S., 1999, J IND TECHNOL, V15, P1; Lou SJ, 1999, INT J ADV MANUF TECH, V15, P200, DOI 10.1007/s001700050057; Lou SJ, 1997, COMPUT IND ENG, V33, P401, DOI 10.1016/S0360-8352(97)00122-8; MacQueen J., 1967, 5TH P BERK S MATH ST, V1, P281; Minsky M., 1961, T I RADIO ENG, V49, P8; MONTGOMERY DC, 1996, INTRO STAT QUALITY; Ripley B., 1996, PATTERN RECOGNITION; SAMSON SL, 2003, INT J ADV MANUF TECH, V22, P498; STONE M, 1974, J ROYAL STAT SOC B, V36, P211; Suresh PVS, 2002, INT J MACH TOOL MANU, V42, P675, DOI 10.1016/S0890-6955(02)00005-6; Tsai YH, 1999, INT J MACH TOOL MANU, V39, P583, DOI 10.1016/S0890-6955(98)00053-4; YANG JL, 2004, J IND TECHNOLOGY, V17, P1; Yang LD, 2006, INT J ADV MANUF TECH, V28, P236, DOI 10.1007/s00170-004-2361-7	31	15	15	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0020-7721			INT J SYST SCI	Int. J. Syst. Sci.		2008	39	12					1181	1192		10.1080/00207720802344683		12	Automation & Control Systems; Computer Science, Theory & Methods; Operations Research & Management Science	Automation & Control Systems; Computer Science; Operations Research & Management Science	396ZR	WOS:000262632000008	
S	Doucette, J; Heywood, MI		ONeill, M; Vanneschi, L; Gustafson, S; Alcazar, AIE; DeFalco, I; DellaCioppa, A; Tarantino, E		Doucette, John; Heywood, Malcolm I.			GP classification under imbalanced data sets: Active sub-sampling and AUC approximation	GENETIC PROGRAMMING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	11th European Conference on Genetic Programming	MAR 26-28, 2008	Naples, ITALY				COEVOLUTION	The problem of evolving binary classification models under increasingly unbalanced data sets is approached by proposing a strategy consisting of two components: Sub-sampling and 'robust' fitness function design. In particular, recent work in the wider machine learning literature has recognized that maintaining the original distribution of exemplars during training is often not appropriate for designing classifiers that are robust to degenerate classifier behavior. To this end we propose a 'Simple Active Learning Heuristic' (SALH) in which a subset of exemplars is sampled with uniform probability under a class balance enforcing rule for fitness evaluation. In addition, an efficient estimator for the Area Under the Curve (AUC) performance metric is assumed in the form of a modified Wilcoxon-Mann-Whitney (WMW) statistic. Performance is evaluated in terms of six representative UCI data sets and benchmarked against: canonical GP, SALH based GP, SALH and the modified WMW statistic, and deterministic classifiers (Naive Bayes and C4.5). The resulting SALH-WMW model is demonstrated to be both efficient and effective at providing solutions maximizing performance assessed in terms of AUC.	[Doucette, John; Heywood, Malcolm I.] Dalhousie Univ, Fac Comp Sci, Halifax, NS B3H 1W5, Canada	Doucette, J (reprint author), Dalhousie Univ, Fac Comp Sci, 6050 Univ Av, Halifax, NS B3H 1W5, Canada.						Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; CARTLIDGE J, 2002, IEEE C EV COMP, P1420; de Jong ED, 2007, EVOL COMPUT, V15, P61; de Jong ED, 2004, EVOL COMPUT, V12, P159; Eggermont J, 1999, LECT NOTES COMPUT SC, V1598, P193; FICICI SG, 2001, EUR C ART LIF, P316; Gathercole C, 1994, LECT NOTES COMPUT SC, V866, P312; Hand D., 1997, CONSTRUCTION ASSESSM; HILLIS WD, 1990, ARTIFICIAL LIFE 2, V10, P313; Koza J., 1992, GENETIC PROGRAMMING; Langdon WB, 2001, LECT NOTES COMPUT SC, V2038, P87; Lemczyk M, 2007, LECT NOTES COMPUT SC, V4445, P229; LICHODZIJEWSKI P, 2007, P GEN EV COMP C GECC, V1, P464; MCINTYRE AR, 2005, P C EV COMP CEC, V3, P2130; Newman DJ, 1998, UCI REPOSITORY MACHI; Noble J., 2001, P GEN EV COMP C GECC, P493; PATTERSON G, 2007, LNCS, V4830, P464; Song D, 2005, IEEE T EVOLUT COMPUT, V9, P225, DOI 10.1109/TEVC.2004.841683; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Yan L., 2003, P 20 INT C MACH LEAR, P848; ZOUNGKER D, 1998, LILGP GENETIC PROGRA	22	15	15	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-78670-2	LECT NOTES COMPUT SC			2008	4971						266	277				12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BHN52	WOS:000254506700023	
J	Wu, WH; Bui, AAT; Batalin, MA; Liu, D; Kaiser, WJ				Wu, Winston H.; Bui, Alex A. T.; Batalin, Maxim A.; Liu, Duo; Kaiser, William J.			Incremental diagnosis method for intelligent wearable sensor systems	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						ambulatory physiologic monitoring; gait assessment; incremental diagnosis; inference engine; naive Bayes classifier; utility function; wearable sensor system	LONG-TERM; GAIT; DEMENTIA; PRESSURE; CHILDREN	This paper presents an incremental diagnosis method (IDM) to detect a medical condition with the minimum wearable sensor usage by dynamically adjusting the sensor set based on the patient's state in his/her natural environment. The IDM, comprised of a naive Bayes classifier generated by supervised training with Gaussian clustering, is developed to classify patient motion in-context (due to a medical condition) and in real-time using a wearable sensor system. The IDM also incorporates a utility function, which is a simple form of expert knowledge and user preferences in sensor selection. Upon initial in-context detection, the utility function decides which sensor is to be activated next. High-resolution in-context detection with minimum sensor usage is possible because the necessary sensor can be activated or requested at the appropriate time. As a case study, the IDM is demonstrated in detecting different severity levels of a limp with minimum usage of high diagnostic resolution sensors.	Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Dept Bioengn, Los Angeles, CA USA; Univ Calif Los Angeles, Dept Radiol Sci, Los Angeles, CA 90024 USA	Wu, WH (reprint author), Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA.	winston@ee.ucla.edu; buia@mii.ucla.edu; maxim.batalin@ucla.edu; duoliu@ee.ucia.edu; kaiser@ee.ucla.edu					Abowd G., 2000, P 2000 C HUM FACT CO, P304; AMATO G, 2005, ERCIM NEWS, V60, P69; Anliker U, 2004, IEEE T INF TECHNOL B, V8, P415, DOI 10.1109/TITB.2004.837888; Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1; Benini L, 2000, IEEE T VLSI SYST, V8, P299, DOI 10.1109/92.845896; Berry C, 2001, EUR J HEART FAIL, V3, P283, DOI 10.1016/S1388-9842(01)00123-4; BRACHINGER HW, 2002, OPTIMIZATION OPERATI, P933; Budinger TE, 2003, ANNU REV BIOMED ENG, V5, P383, DOI 10.1146/annurev.bioeng.5.040202.121653; Bus SA, 2004, CLIN BIOMECH, V19, P629, DOI 10.1016/j.clinbiomech.2004.02.010; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; ELKAN C, 1997, DEP COMPUT SCI ENG U; Erkinjuntti T, 1997, Int Psychogeriatr, V9 Suppl 1, P51, DOI 10.1017/S1041610297004699; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hailey D, 2000, DISABIL REHABIL, V22, P275; HEALEY J, 2005, IEEE INT S; Heidenreich P, 2000, AM HEART J, V138, P633; Hellerstein J. L., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); HENNERICI MG, 1994, DEMENTIA, V5, P197, DOI 10.1159/000106723; HILDEN J, 1984, COMPUT BIOL MED, V14, P429, DOI 10.1016/0010-4825(84)90043-X; Huynh T., 2005, P JOINT C SMART OBJ, P159, DOI 10.1145/1107548.1107591; Kallio S., 2003, IEEE INT C SYST MAN, P2070; Kern N., 2003, P EUR S AMB INT, P220; KORHONEN I, 2003, IEEE ENG MED BIOL, V22, P6; Korpipaa P, 2003, PERS UBIQUIT COMPUT, V7, P113, DOI 10.1007/s00779-003-0237-8; Langley P., 1992, P 10 NAT C ART INT, P223; Mathie MJ, 2004, PHYSIOL MEAS, V25, pR1, DOI 10.1088/0967-3334/25/2/R01; Mitchell T.M., 1997, MACHINE LEARNING; Pappas IPI, 2004, IEEE SENS J, V4, P268, DOI 10.1109/JSEN.2004.823671; Pearl J., 1988, PROBABILISTIC REASON; Perry M, 2004, IEEE T INF TECHNOL B, V8, P258, DOI 10.1109/TITB.2004.835533; Rialle V, 2003, COMPUT METH PROG BIO, V72, P257, DOI 10.1016/S0169-2607(02)00161-X; Salarian A, 2004, IEEE T BIO-MED ENG, V51, P1434, DOI [10.1109/TBME.2004.827933, 10.1109/TMBE.2004.827933]; Schwartz MH, 2004, J PEDIATR ORTHOPED, V24, P45; SUN M, 1993, J BIOMECH, V26, P229, DOI 10.1016/0021-9290(93)90361-H; Tennenhouse D, 2000, COMMUN ACM, V43, P43, DOI 10.1145/332833.332837; Verghese J, 2002, NEW ENGL J MED, V347, P1761, DOI 10.1056/NEJMoa020441; Verghese J, 2003, NEUROLOGY, V61, P1667; Von Neumann J, 1947, THEORY GAMES EC BEHA; Yager RR, 2000, IEEE T SYST MAN CY B, V30, P60, DOI 10.1109/3477.826947; CROSSBOW X SCALE STA; ANALOG DEVICES ADX13	42	15	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771			IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	SEP	2007	11	5					553	562		10.1109/TITB.2007.897579		10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	208HH	WOS:000249309900007	
J	Wang, P; Morgan, AA; Zhang, Q; Sette, A; Peters, B				Wang, Peng; Morgan, Alexander A.; Zhang, Qing; Sette, Alessandro; Peters, Bjoern			Automating document classification for the Immune Epitope Database	BMC BIOINFORMATICS			English	Article							PROTEIN INTERACTIONS; TEXT CATEGORIZATION; RESOURCE; MACHINE; GENOME	Background: The Immune Epitope Database contains information on immune epitopes curated manually from the scientific literature. Like similar projects in other knowledge domains, significant effort is spent on identifying which articles are relevant for this purpose. Results: We here report our experience in automating this process using Naive Bayes classifiers trained on 20,910 abstracts classified by domain experts. Improvements on the basic classifier performance were made by a) utilizing information stored in PubMed beyond the abstract itself b) applying standard feature selection criteria and c) extracting domain specific feature patterns that e. g. identify peptides sequences. We have implemented the classifier into the curation process determining if abstracts are clearly relevant, clearly irrelevant, or if no certain classification can be made, in which case the abstracts are manually classified. Testing this classification scheme on an independent dataset, we achieve 95% sensitivity and specificity in the 51.1% of abstracts that were automatically classified. Conclusion: By implementing text classification, we have sped up the reference selection process without sacrificing sensitivity or specificity of the human expert classification. This study provides both practical recommendations for users of text classification tools, as well as a large dataset which can serve as a benchmark for tool developers.	La Jolla Inst Allerg & Immunol, La Jolla, CA 92037 USA; Stanford Univ, Sch Med, Stanford, CA 94305 USA	Peters, B (reprint author), La Jolla Inst Allerg & Immunol, 9420 Athena Circle, La Jolla, CA 92037 USA.	pwang@liai.org; alexmo@stanford.edu; qlehmann@liai.org; alex@liai.org; bpeters@liai.org					APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Bader GD, 2003, NUCLEIC ACIDS RES, V31, P248, DOI 10.1093/nar/gkg056; Chen D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-370; Dobrokhotov PB, 2003, BIOINFORMATICS, V19, pi91, DOI 10.1093/bioinformatics/btg1011; Donaldson I, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-11; Eppig JT, 2005, NUCLEIC ACIDS RES, V33, pD471, DOI 10.1093/nar/gki113; Han B, 2006, BIOINFORMATICS, V22, P2136, DOI 10.1093/bioinformatics/btl350; HANLEY JA, 1982, RADIOLOGY, V143, P29; HAYES P, 1990, P 6 IEEE CAIA, P321; HERSH W, 2006, TREC 2006 GENOMICS T; Hersh W, 2005, BRIEF BIOINFORM, V6, P344, DOI 10.1093/bib/6.4.344; JOACHIMS T, 1998, TEXT CATEGORIZATION, P137; Kanehisa M, 2004, NUCLEIC ACIDS RES, V32, pD277, DOI 10.1093/nar/gkh063; Kohavi R., 1995, STUDY CROSS VALIDATI, P1137; KROVETZ R, 1993, VIEWING MORPHOLOGY I, P191; Manning C.D., 1999, FDN STAT NATURAL LAN; McCallum A, 1998, AAAI 98 WORKSH LEARN; Miotto Olivo, 2005, Genome Inform, V16, P32; Mitchell T. M., 1997, MCGRAW HILL SERIES C; Nigam K., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Peters B, 2005, PLOS BIOL, V3, P379, DOI 10.1371/journal.pbio.0030091; Peters B, 2005, IMMUNOGENETICS, V57, P326, DOI 10.1007/s00251-005-0803-5; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; Sahami M., 1998, AAAI 98 WORKSH LEARN; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Suomela BP, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-75; Vita R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-341; Witten IH, 2005, DATA MINING PRACTICA; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303	31	15	18	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JUL 26	2007	8								269	10.1186/1471-2105-8-269		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	207TM	WOS:000249274000001	
J	Ceci, M; Malerba, D				Ceci, Michelangelo; Malerba, Donato			Classifying web documents in a hierarchy of categories: a comprehensive study	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						text categorization; hierarchical models; supervised learning; feature selection; performance evaluation; web content mining	TEXT CATEGORIZATION	Most of the research on text categorization has focused on classifying text documents into a set of categories with no structural relationships among them (flat classification). However, in many information repositories documents are organized in a hierarchy of categories to support a thematic search by browsing topics of interests. The consideration of the hierarchical relationship among categories opens several additional issues in the development of methods for automated document classification. Questions concern the representation of documents, the learning process, the classification process and the evaluation criteria of experimental results. They are systematically investigated in this paper, whose main contribution is a general hierarchical text categorization framework where the hierarchy of categories is involved in all phases of automated document classification, namely feature selection, learning and classification of a new document. An automated threshold determination method for classification scores is embedded in the proposed framework. It can be applied to any classifier that returns a degree of membership of a document to a category. In this work three learning methods are considered for the construction of document classifiers, namely centroid-based, naive Bayes and SVM. The proposed framework has been implemented in the system WebClassIII and has been tested on three datasets (Yahoo, DMOZ, RCV1) which present a variety of situations in terms of hierarchical structure. Experimental results are reported and several conclusions are drawn on the comparison of the flat vs. the hierarchical approach as well as on the comparison of different hierarchical classifiers. The paper concludes with a review of related work and a discussion of previous findings vs. our findings.	Univ Bari, Dipartimento Informat, I-70126 Bari, Italy	Ceci, M (reprint author), Univ Bari, Dipartimento Informat, I-70126 Bari, Italy.	ceci@di.uniba.it; malerba@di.uniba.it	Malerba, Donato/H-3850-2012				APTE C, 1994, INFORM SYST, V12, P233; Bennett P.N., 2000, CMUCS00155 SCH COMP; Blocked H., 2002, MULTIRELATIONAL DATA, P21; CECI M, 2003, P ECIR 03 25 EUR C I, P57; Chuang WT, 2000, LECT NOTES COMPUT SC, V1874, P409; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; D'Alessio S., 2000, P 6 INT C RECH INF A, P302; Debole F., 2003, P SAC 03 18 ACM S AP, P784; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Dumais Susan, 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593; ESPOSITO F, 2000, STUDIES CLASSIFICATI, V15, P139; EYHERAMENDY S, 2003, P 9 INT WORKSH ART I; GALAVOTTI L, 2000, ECDL 00, P59; Han E.-H., 2000, PRINCIPLES DATA MINI, P424; Haste H, 1997, PSYCHOLOGIST, V10, P507; Joachims T., 1997, ICML 97, P143; JOACHIMS T, 1998, SV MLIGHT IMPLEMENTA; Joachims Th., 1998, EUR C MACH LEARN ECM, P137; KIM S, 2002, LECT NOTES ARTIF INT, V2417, P95; Lertnattee V, 2004, INFORM SCIENCES, V158, P89, DOI 10.1016/j.ins.2003.07.007; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Lewis D.D., 1998, EUR C MACH LEARN, P4; MALERBA D, 2002, EDBT 02 P WORSH XMLD, P420; McCallum A., 1998, P 15 INT C MACH LEAR, P359; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; MILLER G, 1990, INT J LEXICOLOGY, V3, P278; MITCHELL T, 1998, CONDITIONS EQUIVALEN; Mitchell T.M., 1997, MACHINE LEARNING; Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0; Mladenic D., 1999, ICML 99 P 16 INT C M; MLADENIC D, 1998, THESIS U LJUBJANA SL; MLADENIC D, 1998, EUR C MACH LEARN, P95; NG HT, 1997, SIGIR FORUM, V31, P67; Platt J. C., 1998, ADV KERNEL METHODS S; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sahami M., 1997, P 14 INT C MACH LEAR, P170; SAHAMI M, 1996, 2 INT C KNOWL DISC D, P334; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Schapire R.E., 1998, SIGIR 98 P 21 ANN IN, P215; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SHEN Y, 2003, IMPROVING PERFORMANC; SONA D, 2004, P ECML PKDD 04 WORKS, P50; Sun A., 2001, ICDM 2001, P521; THEERAMUNKONG T, 2002, P 19 INT C COMP LING, P1; Tikk D, 2003, ISUMA 2003: FOURTH INTERNATIONAL SYMPOSIUM ON UNCERTAINTY MODELING AND ANALYSIS, P104; Vapnik V., 1995, NATURE STAT LEARNING; Vinokourov A, 2002, J INTELL INF SYST, V18, P153, DOI 10.1023/A:1013677411002; Weigend A. S., 1999, Information Retrieval, V1, DOI 10.1023/A:1009983522080; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42; Yang Y., 1997, ICML 97, P412; Yang Y, 1996, Proc AMIA Annu Fall Symp, P358; Zhang JN, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P888; Zheng Z., 2004, SIGKDD EXPLORATIONS, V6, P80	58	15	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902			J INTELL INF SYST	J. Intell. Inf. Syst.	FEB	2007	28	1					37	78		10.1007/s10844-006-0003-2		42	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	135XP	WOS:000244187500003	
J	Yang, Q; Ling, C; Chai, XY; Pan, R				Yang, Q; Ling, C; Chai, XY; Pan, R			Test-cost sensitive classification on data with missing values	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						cost-sensitive learning; decision trees; naive Bayes	KNOWLEDGE	In the area of cost-sensitive learning, inductive learning algorithms have been extended to handle different types of costs to better represent misclassification errors. Most of the previous works have only focused on how to deal with misclassification costs. In this paper, we address the equally important issue of how to handle the test costs associated with querying the missing values in a test case. When an attribute contains a missing value in a test case, it may or may not be worthwhile to take the extra effort in order to obtain a value for that attribute, or attributes, depending on how much benefit the new value will bring about in increasing the accuracy. In this paper, we consider how to integrate test-cost-sensitive learning with the handling of missing values in a unified framework that includes model building and a testing strategy. The testing strategies determine which attributes to perform the test on in order to minimize the sum of the classification costs and test costs. We show how to instantiate this framework in two popular machine learning algorithms: decision trees and naive Bayesian method. We empirically evaluate the test-cost-sensitive methods for handling missing values on several data sets.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada; Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Yang, Q (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.	qyang@cs.ust.hk; cling@csd.wuo.ca; chai@cs.purdue.edu; panrong@cs.ust.hk					Blake C. L., 1998, UCI REPOSITORY MACHI; CHAI X, 2004, P 2004 IEEE INT C DA; Cormen T., 2001, INTRO ALGORITHMS; Domingos P., 1999, KNOWLEDGE DISCOVERY, P155; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O., 2001, PATTERN CLASSIFICATI; Elkan C., 2001, P 17 INT JOINT C ART, P973; Fayyad UM, 1993, MULTIINTERVAL DISCRE, P1022; Greiner R, 2002, ARTIF INTELL, V139, P137, DOI 10.1016/S0004-3702(02)00209-6; Kai M., 1998, PRINCIPLES DATA MINI, P139; LING C, 2004, P 2004 INT C MACH LE; Mitchell T.M., 1997, MACHINE LEARNING; Norton S.W., 1989, P 11 INT JOINT C ART, P800; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; NUNEZ M, 1988, P 3 EUR WORK SESS LE, P139; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; TURNEY P, 2000, P WORKSH COST SENS L; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Zubek V.B., 2002, P 19 INT C MACH LEAR, P27	20	15	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2006	18	5					626	638				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	021MS	WOS:000235987900005	
J	Cerquides, J; De Mantaras, RL				Cerquides, J; De Mantaras, RL			TAN classifiers based on decomposable distributions	MACHINE LEARNING			English	Article						Bayesian networks; Bayesian network classifiers; naive Bayes; tree augmented naive Bayes; decomposable distributions; Bayesian model averaging	ALGORITHM; TREES	In this paper we present several Bayesian algorithms for learning Tree Augmented Naive Bayes (TAN) models. We extend the results in Meila & Jaakkola (2000a) to TANs by proving that accepting a prior decomposable distribution over TAN's, we can compute the exact Bayesian model averaging over TAN structures and parameters in polynomial time. Furthermore, we prove that the k-maximum a posteriori (MAP) TAN structures can also be computed in polynomial time. We use these results to correct minor errors in Meila & Jaakkola (2000a) and to construct several TAN based classifiers. We show that these classifiers provide consistently better predictions over Irvine datasets and artificially generated data than TAN based classifiers proposed in the literature.	Univ Barcelona, Dept Matemat Aplicada & Anal, E-08007 Barcelona, Spain; CSIC, Inst Invest & Intelligencia Artificial, Bellaterra 08190, Spain	Cerquides, J (reprint author), Univ Barcelona, Dept Matemat Aplicada & Anal, Gran Via 585, E-08007 Barcelona, Spain.	cerquide@maia.ub.es; mantaras@iiia.csic.es					CERQUIDES J, 1999, P INT C KNOWL DISC D, P292, DOI 10.1145/312129.312256; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; FAWCETT T, 2003, HPL20034 HP LAB PAL; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; IDE J, 2003, GENERATION RANDOM BA; KATOH N, 1981, SIAM J COMPUT, V10, P247, DOI 10.1137/0210017; KONTKANEN P, 1998, LECT NOTES ARTIF INT, V1398, P77; Langley P., 1992, P 10 NAT C ART INT, P223; MEILA M, 2000, CMURITR0015; Meila M., 2000, P 16 C UNC AI SAN FR, P380; Pettie S, 2002, J ACM, V49, P16, DOI 10.1145/505241.505243	14	15	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JUN	2005	59	3					323	354		10.1007/s10994-005-0470-7		32	Computer Science, Artificial Intelligence	Computer Science	933FG	WOS:000229613700006	
J	Zhang, H				Zhang, H			Exploring conditions for the optimality of Naive bayes	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article; Proceedings Paper	17th International Florida-Artificial-Intelligence-Research-Society Conference (FLAIRS)	MAY, 2004	Miami Beach, FL	Florida Artificial Intelligence Res Soc		Naive Bayes; optimality; classification		Naive Bayes is one of the most efficient and effective inductive learning algorithms for machine learning and data mining. Its competitive performance in classification is surprising, because the conditional independence assumption on which it is based is rarely true in real-world applications. An open question is: what is the true reason for the surprisingly good performance of Naive Bayes in classification? In this paper, we propose a novel explanation for the good classification performance of Naive Bayes. We show that, essentially, dependence distribution plays a crucial role. Here dependence distribution means how the local dependence of an attribute distributes in each class, evenly or unevenly, and how the local dependences of all attributes work together, consistently (supporting a certain classification) or inconsistently (canceling each other out). Specifically, we show that no matter how strong the dependences among attributes are, Naive Bayes can still be optimal if the dependences distribute evenly in classes, or if the dependences cancel each other out. We propose and prove a sufficient and necessary condition for the optimality of Naive Bayes. Further, we investigate the optimality of Naive Bayes under the Gaussian distribution. We present and prove a sufficient condition for the optimality of Naive Bayes, in which the dependences among attributes exist. This provides evidence that dependences may cancel each other out. Our theoretic analysis can be used in designing learning algorithms. In fact, a major class of learning algorithms for Bayesian networks are conditional independence-based (or Cl-based), which are essentially based on dependence. We design a dependence distribution-based algorithm by extending the ChowLiu algorithm, a widely used CI based algorithm. Our experiments show that the new algorithm outperforms the ChowLiu algorithm, which also provides empirical evidence to support our new explanation.	Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Zhang, H (reprint author), Univ New Brunswick, Fac Comp Sci, POB 4400, Fredericton, NB E3B 5A3, Canada.	hzhang@unb.ca					Bennett P. N., 2000, CMUCS00155; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER WS, 1995, ACM T INFORM SYST, V13, P100, DOI 10.1145/195705.195735; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Frank E, 2000, MACH LEARN, V41, P5, DOI 10.1023/A:1007670802811; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GARG A, 2001, P 12 EUR C MACH LEAR, P179; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P., 1992, P 10 NAT C ART INT, P223; Merz C., 1997, UCI REPOSITORY MACHI; MONTI F, 1999, P 15 C UNC ART INT, P447; PAZZANI MJ, 1996, LEARNING DATA ARTIFI; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Roth D, 1999, P INT JOINT C ART IN, P898; ZHANG H, 2001, P 18 INT C MACH LEAR, P617	19	15	16	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAR	2005	19	2					183	198		10.1142/S0218001405003983		16	Computer Science, Artificial Intelligence	Computer Science	916UG	WOS:000228411100005	
J	MacNab, YC; Farrell, PJ; Gustafson, P; Wen, SJ				MacNab, YC; Farrell, PJ; Gustafson, P; Wen, SJ			Estimation in Bayesian disease mapping	BIOMETRICS			English	Article						Bayesian disease mapping; conditional autoregressive model; empirical Bayes; hybrid Markov chain Monte Carlo; hyperprior Bayes; parametric bootstrap; penalized quasi-likelihood	EMPIRICAL BAYES; CONFIDENCE-INTERVALS; MODELS; RATES; BOOTSTRAP; INFERENCE; CHECKS	Recent work on Bayesian inference of disease mapping models discusses the advantages of the fully Bayesian (FB) approach over its empirical Bayes (EB) counterpart, suggesting that FB posterior standard deviations of small-area relative risks are more reflective of the uncertainty associated with the relative risk estimation than counterparts based on EB inference, since the latter fail to account for the variability in the estimation of the hyperparameters. In this article, an EB bootstrap methodology for relative risk inference with accurate parametric EB confidence intervals is developed, illustrated, and contrasted with the hyperprior Bayes. We elucidate the close connection between the EB bootstrap methodology and hyperprior Bayes, present a comparison between FB inference via hybrid Markov chain Monte Carlo and inference via penalized quasi-likelihood, and illustrate the ability of parametric bootstrap procedures to adjust for the undercoverage in the "naive" EB interval estimates. We discuss the important roles that FB and EB methods play in risk inference, map interpretation, and real-life applications. The work is motivated by a recent analysis of small-area infant mortality rates in the province of British Columbia in Canada.	Univ British Columbia, Dept Hlth Care & Epidemiol, Div Epidemiol & Biostat, Vancouver, BC V6T 1Z3, Canada; British Columbia Res Inst Childrens & Womens Hlth, Ctr Healthcare Innovat & Improvement, Vancouver, BC V6H 3V4, Canada; Carleton Univ, Sch Math & Stat, Ottawa, ON K1S 5B6, Canada; Univ British Columbia, Dept Stat, Vancouver, BC V6T 1Z2, Canada; Univ Texas, MD Anderson Canc Ctr, Dept Biostat, Houston, TX 77030 USA	MacNab, YC (reprint author), Univ British Columbia, Dept Hlth Care & Epidemiol, Div Epidemiol & Biostat, 2222 Hlth Sci Mall, Vancouver, BC V6T 1Z3, Canada.	ymacnab@cw.bc.ca					BERNARDINELLI L, 1992, STAT MED, V11, P983, DOI 10.1002/sim.4780110802; BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466; BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.2307/2290687; Carlin BP, 2000, BAYES EMPIRICAL BAYE; CARLIN BP, 1990, J AM STAT ASSOC, V85, P105, DOI 10.2307/2289531; CARLIN BP, 1991, J ROY STAT SOC B MET, V53, P189; Daniels MJ, 1999, CAN J STAT, V27, P567, DOI 10.2307/3316112; Dean CB, 2001, CAN J STAT, V29, P405, DOI 10.2307/3316037; Elliott P., 2000, SPATIAL EPIDEMIOLOGY; Farrell PJ, 1997, CAN J STAT, V25, P75, DOI 10.2307/3315358; Gelman Andrew, 1992, STAT SCI, V7, P457, DOI DOI 10.1214/SS/1177011136; GILKS WR, 1994, ADAPTIVE REJECTION M; GUSTAFSON P, 1996, TEST, V5, P300; Gustafson P, 1998, STAT COMPUT, V8, P357, DOI 10.1023/A:1008880707168; Gustafson P, 2004, STAT COMPUT, V14, P23, DOI 10.1023/B:STCO.0000009413.87656.ef; Gustafson P, 1997, BIOMETRICS, V53, P230, DOI 10.2307/2533110; LAIRD NM, 1987, J AM STAT ASSOC, V82, P739, DOI 10.2307/2288778; Lawson AB, 1999, DIS MAPPING RISK ASS; LEROUX A, 1999, STAT MODELS EPIDEMIO, P135; MacNab YC, 2003, BIOMETRICS, V59, P305, DOI 10.1111/1541-0420.00037; MacNab YC, 2000, STAT MED, V19, P2421, DOI 10.1002/1097-0258(20000915/30)19:17/18<2421::AID-SIM579>3.0.CO;2-C; MacNab YC, 2003, ACCIDENT ANAL PREV, V35, P91, DOI 10.1016/S0001-4575(01)00093-8; MACNAB YC, 1999, THESIS S FRASER U BU; MacNab YC, 2003, STAT MED, V22, P1761, DOI 10.1002/sim.1463; MACNAB YC, 2003, PEDIATR RES, V53, P491; MANTON KG, 1989, J AM STAT ASSOC, V84, P637, DOI 10.2307/2289644; Marshall EC, 2003, STAT MED, V22, P1649, DOI 10.1002/sim.1403; MARSHALL RJ, 1991, APPL STAT-J ROY ST C, V40, P283, DOI 10.2307/2347593; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Mollie A, 1999, DISEASE MAPPING AND RISK ASSESSMENT FOR PUBLIC HEALTH, P15; MORRIS CN, 1983, J AM STAT ASSOC, V78, P47, DOI 10.2307/2287098; MORRISON JR, 1987, J AM STAT ASSOC, V82, P752; NEAL RM, 1993, CRAGTR931 U TOR DEP; RUBIN DB, 1984, ANN STAT, V12, P1151, DOI 10.1214/aos/1176346785; Spiegelhalter DJ, 2002, J ROY STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353; Spiegelhalter DJ, 2003, BAYESIAN APPROACHES; Stern HS, 2000, STAT MED, V19, P2377, DOI 10.1002/1097-0258(20000915/30)19:17/18<2377::AID-SIM576>3.0.CO;2-1; STROHMAIER R, 1992, GEOGRAPHY DEATH MORT, P5	38	15	16	BLACKWELL PUBLISHING LTD	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DG, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	DEC	2004	60	4					865	873		10.1111/j.0006-341X.2004.00241.x		9	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	882LB	WOS:000225939300003	
B	Vaidya, J; Clifton, C		Berry, MW; Dayal, U; Kamath, C; Skillicorn, D		Vaidya, J; Clifton, C			Privacy preserving naive Bayes classifier for vertically partitioned data	Proceedings of the Fourth SIAM International Conference on Data Mining	SIAM PROCEEDINGS SERIES		English	Proceedings Paper	4th SIAM International Conference on Data Mining	APR 22-24, 2004	Lake Buena Vista, FL	Soc Ind & Appl Math		privacy; security; distributed classification		Privacy-Preserving Data Mining - developing models without seeing the data - is receiving growing attention. This paper assumes a privacy-preserving distributed data mining scenario: data sources collaborate to develop a global model, but must not disclose their data to others. Naive Bayes is often used as a baseline classifier, consistently providing reasonable classification performance. This paper brings privacy-preservation to Naive Bayes classification on vertically partitioned data.	Purdue Univ, W Lafayette, IN 47907 USA	Vaidya, J (reprint author), Purdue Univ, W Lafayette, IN 47907 USA.						Atallah MJ, 2001, P 17 ANN COMP SEC AP; FDA (Food and Drug Administration), 2001, FED REG, V66; Goldreich O., 1987, 19 STOC, P218, DOI DOI 10.1145/28395.28420; GOLDREICH O, 1998, SECURE MULTIPART SEP; IOANNIDIS I, 2002, 2002 INT C PAR PROC; Kantarcioglu Murat, 2004, IEEE T KNOWLEDGE DAT, V16; LIN X, IN PRESS KNOWLEDGE I; Lindell Y, 2002, J CRYPTOL, V15, P177, DOI 10.1007/s00145-001-0019-2; Mitchell T.M., 1997, MACHINE LEARNING; Naor M., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301312; VAIDYA J, 2003, 9 ACM SIGKDD INT C K; Vaidya J., 2002, 8 ACM SIGKDD INT C K, P639, DOI [10.1145/775047.775142, DOI 10.1145/775047.775142]	12	15	17	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			0-89871-568-7	SIAM PROC S			2004							522	526				5	Computer Science, Artificial Intelligence	Computer Science	BCR65	WOS:000230948400059	
J	Parks, DH; MacDonald, NJ; Beiko, RG				Parks, Donovan H.; MacDonald, Norman J.; Beiko, Robert G.			Classifying short genomic fragments from novel lineages using composition and homology	BMC BIOINFORMATICS			English	Article							NAIVE BAYESIAN CLASSIFIER; PHYLOGENETIC CLASSIFICATION; DNA FRAGMENTS; SEQUENCES; COMMUNITIES; METAGENOMICS; EVOLUTIONARY; ASSIGNMENT; READS; SEA	Background: The assignment of taxonomic attributions to DNA fragments recovered directly from the environment is a vital step in metagenomic data analysis. Assignments can be made using rank-specific classifiers, which assign reads to taxonomic labels from a predetermined level such as named species or strain, or rank-flexible classifiers, which choose an appropriate taxonomic rank for each sequence in a data set. The choice of rank typically depends on the optimal model for a given sequence and on the breadth of taxonomic groups seen in a set of close-to-optimal models. Homology-based (e.g., LCA) and composition-based (e. g., PhyloPythia, TACOA) rank-flexible classifiers have been proposed, but there is at present no hybrid approach that utilizes both homology and composition. Results: We first develop a hybrid, rank-specific classifier based on BLAST and Naive Bayes (NB) that has comparable accuracy and a faster running time than the current best approach, PhymmBL. By substituting LCA for BLAST or allowing the inclusion of suboptimal NB models, we obtain a rank-flexible classifier. This hybrid classifier outperforms established rank-flexible approaches on simulated metagenomic fragments of length 200 bp to 1000 bp and is able to assign taxonomic attributions to a subset of sequences with few misclassifications. We then demonstrate the performance of different classifiers on an enhanced biological phosphorous removal metagenome, illustrating the advantages of rank-flexible classifiers when representative genomes are absent from the set of reference genomes. Application to a glacier ice metagenome demonstrates that similar taxonomic profiles are obtained across a set of classifiers which are increasingly conservative in their classification. Conclusions: Our NB-based classification scheme is faster than the current best composition-based algorithm, Phymm, while providing equally accurate predictions. The rank-flexible variant of NB, which we term epsilon-NB, is complementary to LCA and can be combined with it to yield conservative prediction sets of very high confidence. The simple parameterization of LCA and epsilon-NB allows for tuning of the balance between more predictions and increased precision, allowing the user to account for the sensitivity of downstream analyses to misclassified or unclassified sequences.	[Parks, Donovan H.; MacDonald, Norman J.; Beiko, Robert G.] Dalhousie Univ, Fac Comp Sci, Halifax, NS, Canada	Beiko, RG (reprint author), Dalhousie Univ, Fac Comp Sci, 6050 Univ Ave, Halifax, NS, Canada.	beiko@cs.dal.ca			Killam Trusts; Natural Sciences and Engineering Research Council of Canada; Genome Atlantic; Canada Foundation for Innovation; Canada Research Chairs program; Government of Canada through Genome Canada; Ontario Genomics Institute [2009-OGI-ABC-1405]	DHP is supported by the Killam Trusts; NJM is supported by the Natural Sciences and Engineering Research Council of Canada; RGB acknowledges the support of Genome Atlantic, the Canada Foundation for Innovation, and the Canada Research Chairs program. The authors also acknowledge support from the Government of Canada through Genome Canada and the Ontario Genomics Institute (2009-OGI-ABC-1405).	ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; AMANN RI, 1995, MICROBIOL REV, V59, P143; Beja O, 2000, SCIENCE, V289, P1902, DOI 10.1126/science.289.5486.1902; Brady A, 2011, NAT METHODS, V8, P367, DOI 10.1038/nmeth0511-367; Brady A, 2009, NAT METHODS, V6, P673, DOI [10.1038/nmeth.1358, 10.1038/NMETH.1358]; Camacho C., 2009, BMC BIOINFORMATICS, V10, P421; Clemente JC, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-8; Deschavanne PJ, 1999, MOL BIOL EVOL, V16, P1391; Diaz NN, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-56; Gori F, 2011, BIOINFORMATICS, V27, P196, DOI 10.1093/bioinformatics/btq649; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Huson DH, 2007, GENOME RES, V17, P377, DOI 10.1101/gr.5969107; Karlin S, 1997, J BACTERIOL, V179, P3899; Krause L, 2008, NUCLEIC ACIDS RES, V36, P2230, DOI 10.1093/nar/gkn038; Martin HG, 2006, NAT BIOTECHNOL, V24, P1263, DOI 10.1038/nbt1247; McHardy AC, 2007, NAT METHODS, V4, P63, DOI 10.1038/NMETH976; Parks DH, 2010, BIOINFORMATICS, V26, P715, DOI 10.1093/bioinformatics/btq041; PATIL KR, 2001, NAT METHODS, V8, P191; Perry SC, 2010, GENOME BIOL EVOL, V2, P117, DOI 10.1093/gbe/evq004; Pruitt KD, 2009, NUCLEIC ACIDS RES, V37, pD32, DOI 10.1093/nar/gkn721; Qin JJ, 2010, NATURE, V464, P59, DOI 10.1038/nature08821; R Development Core Team, 2011, R LANG ENV STAT COMP; Richter DC, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003373; Rosen G, 2008, ADV BIOINFORMATICS, V2008; Sandberg R, 2001, GENOME RES, V11, P1404, DOI 10.1101/gr.186401; Schreiber F, 2010, BIOINFORMATICS, V26, P960, DOI 10.1093/bioinformatics/btq070; Simon C, 2009, APPL ENVIRON MICROB, V75, P7519, DOI 10.1128/AEM.00946-09; Tringe SG, 2005, SCIENCE, V308, P554, DOI 10.1126/science.1107851; Turnbaugh PJ, 2009, NATURE, V457, P480, DOI 10.1038/nature07540; Tyson GW, 2004, NATURE, V428, P37, DOI 10.1038/nature02340; Venter JC, 2004, SCIENCE, V304, P66, DOI 10.1126/science.1093857; Wang Q, 2007, APPL ENVIRON MICROB, V73, P5261, DOI 10.1128/AEM.00062-07; Wu DY, 2009, NATURE, V462, P1056, DOI 10.1038/nature08656; YU F, 2009, BIOINFORMATION, V4, P46	34	14	16	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	AUG 9	2011	12								328	10.1186/1471-2105-12-328		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	820HS	WOS:000294896900001	
J	Gasson, P; Miller, R; Stekel, DJ; Whinder, F; Zieminska, K				Gasson, Peter; Miller, Regis; Stekel, Dov J.; Whinder, Frances; Zieminska, Kasia			Wood identification of Dalbergia nigra (CITES Appendix I) using quantitative wood anatomy, principal components analysis and naive Bayes classification	ANNALS OF BOTANY			English	Article						Dalbergia nigra; Brazilian rosewood; CITES; wood anatomy; PCA; naive Bayes analysis		Dalbergia nigra is one of the most valuable timber species of its genus, having been traded for over 300 years. Due to over-exploitation it is facing extinction and trade has been banned under CITES Appendix I since 1992. Current methods, primarily comparative wood anatomy, are inadequate for conclusive species identification. This study aims to find a set of anatomical characters that distinguish the wood of D. nigra from other commercially important species of Dalbergia from Latin America. Qualitative and quantitative wood anatomy, principal components analysis and naive Bayes classification were conducted on 43 specimens of Dalbergia, eight D. nigra and 35 from six other Latin American species. Dalbergia cearensis and D. miscolobium can be distinguished from D. nigra on the basis of vessel frequency for the former, and ray frequency for the latter. Principal components analysis was unable to provide any further basis for separating the species. Naive Bayes classification using the four characters: minimum vessel diameter; frequency of solitary vessels; mean ray width; and frequency of axially fused rays, classified all eight D. nigra correctly with no false negatives, but there was a false positive rate of 36 center dot 36 %. Wood anatomy alone cannot distinguish D. nigra from all other commercially important Dalbergia species likely to be encountered by customs officials, but can be used to reduce the number of specimens that would need further study.	[Gasson, Peter; Whinder, Frances; Zieminska, Kasia] Royal Bot Gardens Kew, Jodrell Lab, Richmond TW9 3DS, Surrey, England; [Miller, Regis] Forest Prod Lab, Madison, WI 53726 USA; [Stekel, Dov J.] Univ Nottingham, Sch Biosci, Loughborough LE12 5RD, Leics, England	Gasson, P (reprint author), Royal Bot Gardens Kew, Jodrell Lab, Kew Rd, Richmond TW9 3DS, Surrey, England.	P.Gasson@kew.org					Angyalossy-Alfonso V, 2002, IAWA J, V23, P359; Carvalho Andre M. De, 1997, Brittonia, V49, P87; *CITES, 2009, UNEP WCMC SPEC DAT C; CITES, 2002, CITES ID GUID TROP W; DECARVALHO AMV, 1989, THESIS U READING UK; Durbin R., 1998, BIOL SEQUENCE ANAL; Esteban LG, 2009, IAWA J, V30, P87; Everitt BS, 2001, APPL MULTIVARIATE DA; FLYNN JH, 2001, GUIDE USEFUL WOODS W; Guzman JAS, 2008, IAWA J, V29, P311; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hellberg E, 2003, ECOSCIENCE, V10, P370; IAWA Committee, 1989, IAWA B, V10, P219; KHALID M, 2008, DESIGN INTELLIGENT W; Klitgaard BB, 2005, LEGUMES WORLD; Kribs D A, 1959, COMMERCIAL FOREIGN W; KUKACHKA BF, 1977, FPL0236 USDA FOR RES; MACLACHLAN IR, 2010, IAWA J IN PRESS; MILLER RB, 2006, FPLRP632 USDA FOR SE; MILLER RG, 1974, BIOMETRIKA, V61, P1; Moller M, 2007, BOT J LINN SOC, V155, P307, DOI 10.1111/j.1095-8339.2007.00697.x; PATEL J D, 1980, Phytomorphology, V30, P140; Record SJ, 1943, TIMBERS NEW WORLD; Richter HG, 1996, IAWA J, V17, P327; RICHTER HG, 2008, SOFTWARE PROGRAM CIT; VARTY N, 2009, IUCN 2008 IUCN RED L; WIEDENHOEFT AC, 2005, HDB WOOD CHEM WOOD C	27	14	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-7364			ANN BOT-LONDON	Ann. Bot.	JAN	2010	105	1					45	56		10.1093/aob/mcp270		12	Plant Sciences	Plant Sciences	534UW	WOS:000272923900017	
J	Agarwal, S; Yu, H				Agarwal, Shashank; Yu, Hong			Automatically classifying sentences in full-text biomedical articles into Introduction, Methods, Results and Discussion	BIOINFORMATICS			English	Article								Biomedical texts can be typically represented by four rhetorical categories: Introduction, Methods, Results and Discussion (IMRAD). Classifying sentences into these categories can benefit many other text-mining tasks. Although many studies have applied different approaches for automatically classifying sentences in MEDLINE abstracts into the IMRAD categories, few have explored the classification of sentences that appear in full-text biomedical articles. We first evaluated whether sentences in full-text biomedical articles could be reliably annotated into the IMRAD format and then explored different approaches for automatically classifying these sentences into the IMRAD categories. Our results show an overall annotation agreement of 82.14% with a Kappa score of 0.756. The best classification system is a multinomial naive Bayes classifier trained on manually annotated data that achieved 91.95% accuracy and an average F-score of 91.55%, which is significantly higher than baseline systems. A web version of this system is available online at-http://wood.ims.uwm.edu/full_text_classifier/.	[Agarwal, Shashank; Yu, Hong] Univ Wisconsin, Milwaukee, WI 53211 USA	Yu, H (reprint author), Univ Wisconsin, Milwaukee, WI 53211 USA.				National Institutes of Health [1r21rr024933-01a1, 5r01lm009836-02]; University of Wisconsin-Milwaukee's RGI	National Institutes of Health grants 1r21rr024933-01a1, 5r01lm009836-02 and the University of Wisconsin-Milwaukee's RGI in 2007-2008 ( to H. Y.).	Agarwal Sachin, 2009, 2009 Proceedings of 18th International Conference on Computer Communications and Networks - ICCCN 2009, DOI 10.1109/ICCCN.2009.5235383; McKnight Larry, 2003, AMIA Annu Symp Proc, P440; Day RA., 1998, WRITE PUBLISH SCI PA; Fleiss JL., 1981, STAT METHODS RATES P; FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161; Friedman C, 2001, Bioinformatics, V17 Suppl 1, pS74; GABBAY I, 2004, ACL WORKSH QUEST ANS, P16; Gospodnetic O., 2005, LUCENE ACTION; HERSH W, 2006, TREC GEN TRACK C NAT, P52; Klein D., 2003, ACCURATE UNLEXICALIZ, P423, DOI 10.3115/1075096.1075150; LIN J, 2006, GENERATIVE CONTENT M; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; MIHALCEA R, 2003, CURRENT ISSUES LINGU, P387; Mizuta Y, 2006, INT J MED INFORM, V75, P468, DOI 10.1016/j.ijmedinf.2005.06.013; Mullen T, 2005, ACM SIGKDD EXPLORATI, V7, P52, DOI 10.1145/1089815.1089823; SALANGERMEYER F, 1990, INTERFACE J APPL LIN, V4, P107; Shatkay H, 2008, BIOINFORMATICS, V24, P2086, DOI 10.1093/bioinformatics/btn381; Sollaci LB, 2004, J MED LIBR ASSOC, V92, P364; SWALES J, 1990, GENRE ANAL ENGLISH A; Wang YJ, 2003, AM J PHYSIOL-HEART C, V284, pH1008, DOI 10.1152/ajpheart.00600.2002; Wilbur WJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-356; Witten I. A., 2006, DATA MINING PRACTICA; YAMAMOTO Y, 2005, P 21 INT C DAT ENG W; Yeh AS, 2003, BIOINFORMATICS, V19, P331; Yu Hong, 2009, J Biomed Discov Collab, V4, P1, DOI 10.1186/1747-5333-4-1; Yu H, 2002, J AM MED INFORM ASSN, V9, P262, DOI 10.1197/jamia.M0913; Yu H, 2007, J BIOMED INFORM, V40, P236, DOI 10.1016/j.jbi.2007.03.002; YU H, 2003, P EMP METH NAT LANG	28	14	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	DEC 1	2009	25	23					3174	3180		10.1093/bioinformatics/btp548		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	523NL	WOS:000272080800019	
J	Kilicoglu, H; Demner-Fushman, D; Rindflesch, TC; Wilczynski, NL; Haynes, RB				Kilicoglu, Halil; Demner-Fushman, Dina; Rindflesch, Thomas C.; Wilczynski, Nancy L.; Haynes, R. Brian			Towards Automatic Recognition of Scientifically Rigorous Clinical Research Evidence	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							TEXT CATEGORIZATION; STACKED GENERALIZATION; BIOMEDICAL TEXT; SYSTEM	The growing numbers of topically relevant biomedical publications readily available due to advances in document retrieval methods pose a challenge to clinicians practicing evidence-based medicine. It is increasingly time consuming to acquire and critically appraise the available evidence. This problem could be addressed in part if methods were available to automatically recognize rigorous studies immediately applicable in a specific clinical situation. We approach the problem of recognizing studies containing useable clinical advice from retrieved topically relevant articles as a binary classification problem. The gold standard used in the development of PubMed clinical query filters forms the basis of our approach. We identify scientifically rigorous studies using supervised machine learning techniques (Naive Bayes, support vector machine (SVM), and boosting) trained on high-level semantic features. We combine these methods using an ensemble learning method (stacking). The performance of learning methods is evaluated using precision, recall and F, score, in addition to area under the receiver operating characteristic (ROC) curve (AUC). Using a training set of 10,000 manually annotated MEDLINE citations, and a test set of an additional 2,000 citations, we achieve 73.7% precision and 61.5% recall in identifying rigorous, clinically relevant studies, with stacking over five feature-classifier combinations and 82.5% precision and 84.3% recall in recognizing rigorous studies with treatment focus using stacking over word + metadata feature vector. Our results demonstrate that a high quality gold standard and advanced classification methods can help clinicians acquire best evidence from the medical literature.	[Kilicoglu, Halil] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada; [Kilicoglu, Halil; Demner-Fushman, Dina; Rindflesch, Thomas C.] Natl Lib Med, NIH, Bethesda, MD USA; [Wilczynski, Nancy L.; Haynes, R. Brian] McMaster Univ, Hlth Informat Res Unit, Hamilton, ON, Canada	Kilicoglu, H (reprint author), Concordia Univ, Dept Comp Sci & Software Engn, 1515 Ste Catherine W, Montreal, PQ H3G 1M8, Canada.	h_kilico@cse.concordia.ca			Intramural Research Program of the National Institutes of Health; National Library of Medicine	Supported in part by the Intramural Research Program of the National Institutes of Health, National Library of Medicine.	Aphinyanaphongs Y, 2005, J AM MED INFORM ASSN, V12, P207, DOI 10.1197/jamia.M1641; Aronson A, 2001, P AMIA S 2001, P17; Chapman WW, 2001, J BIOMED INFORM, V34, P4, DOI 10.1006/jbin.2001.1000; Demner-Fushman D, 2006, J AM MED INFORM ASSN, V13, P52, DOI 10.1197/jamia.M1911; Hersh W., 1994, P 17 ANN INT ACM SIG, P192; LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; McCray A T, 1994, Proc Annu Symp Comput Appl Med Care, P235; Mierswa I., 2006, P 12 ACM SIGKDD INT, P935, DOI DOI 10.1145/1150402.1150531; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; *PRINC U FIN HALL, 2008, MEDL DAT STOP WORDS; Rindflesch TC, 2003, J BIOMED INFORM, V36, P462, DOI 10.1016/j.jbi.2003.11.003; Ruiz M. E., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312700; Sackett DL, 1998, EVIDENCE BASED MED P; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Smith L, 2004, BIOINFORMATICS, V20, P2320, DOI 10.1093/bioinformatics/bth227; Ting KM, 1999, J ARTIF INTELL RES, V10, P271; WILCOX A, 2000, P WORKSH TEXT MIN KD; Wilczynski Nancy L, 2005, BMC Med Inform Decis Mak, V5, P20, DOI 10.1186/1472-6947-5-20; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; WONG SS, 2004, MEDINFO 1, V11, P311; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Yetisgen-Yildiz M, 2005, P AMIA S 2005, P849	24	14	14	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1067-5027			J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JAN-FEB	2009	16	1					25	31		10.1197/jamia.M2996		7	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	396UB	WOS:000262615600005	
J	Li, QR; Carvunis, AR; Yu, HY; Han, JDJ; Zhong, Q; Simonis, N; Tam, S; Hao, T; Klitgord, NJ; Dupuy, D; Mou, D; Wapinski, I; Regev, A; Hill, DE; Cusick, ME; Vidal, M				Li, Qian-Ru; Carvunis, Anne-Ruxandra; Yu, Haiyuan; Han, Jing-Dong J.; Zhong, Quan; Simonis, Nicolas; Tam, Stanley; Hao, Tong; Klitgord, Niels J.; Dupuy, Denis; Mou, Danny; Wapinski, Ilan; Regev, Aviv; Hill, David E.; Cusick, Michael E.; Vidal, Marc			Revisiting the Saccharomyces cerevisiae predicted ORFeome	GENOME RESEARCH			English	Article							PROTEIN-PROTEIN INTERACTIONS; SYSTEMATIC IDENTIFICATION; EVOLUTIONARY ANALYSIS; YEAST TRANSCRIPTOME; GENOME ANNOTATION; GLOBAL ANALYSIS; BUDDING YEAST; GENES; DROSOPHILA; COMPLEXES	Accurately defining the coding potential of an organism, i.e., all protein-encoding open reading frames (ORFs) or "ORFeome," is a prerequisite to fully understand its biology. ORFeome annotation involves iterative computational predictions from genome sequences combined with experimental verifications. Here we reexamine a set of Saccharomyces cerevisiae "orphan" ORFs recently removed from the original ORFeome annotation due to lack of conservation across evolutionarily related yeast species. We show that many orphan ORFs produce detectable transcripts and/or translated products in various functional genomics and proteomics experiments. By combining a naive Bayes model that predicts the likelihood of an ORF to encode a functional product with experimental verification of strand-specific transcripts, we argue that orphan ORFs should still remain candidates for functional ORFs. In support of this model, interstrain intraspecies genome sequence variation is lower across orphan ORFs than in intergenic regions, indicating that orphan ORFs endure functional constraints and resist deleterious mutations. We conclude that ORFs should be evaluated based on multiple levels of evidence and not be removed from ORFeome annotation solely based on low sequence conservation in other species. Rather, such ORFs might be important for micro-evolutionary divergence between species.	[Li, Qian-Ru; Carvunis, Anne-Ruxandra; Yu, Haiyuan; Han, Jing-Dong J.; Zhong, Quan; Simonis, Nicolas; Tam, Stanley; Hao, Tong; Klitgord, Niels J.; Dupuy, Denis; Mou, Danny; Hill, David E.; Cusick, Michael E.; Vidal, Marc] Dana Farber Canc Inst, CCSB, Boston, MA 02115 USA; [Li, Qian-Ru; Carvunis, Anne-Ruxandra; Yu, Haiyuan; Han, Jing-Dong J.; Zhong, Quan; Simonis, Nicolas; Tam, Stanley; Hao, Tong; Klitgord, Niels J.; Dupuy, Denis; Mou, Danny; Hill, David E.; Cusick, Michael E.; Vidal, Marc] Dana Farber Canc Inst, Dept Canc Biol, Boston, MA 02115 USA; [Li, Qian-Ru; Carvunis, Anne-Ruxandra; Yu, Haiyuan; Han, Jing-Dong J.; Zhong, Quan; Simonis, Nicolas; Tam, Stanley; Hao, Tong; Klitgord, Niels J.; Dupuy, Denis; Mou, Danny; Hill, David E.; Cusick, Michael E.; Vidal, Marc] Harvard Univ, Sch Med, Boston, MA 02115 USA; TIMC IMAG, Fac Med, CNRS UMR5525, F-38706 La Tronche, France; [Wapinski, Ilan; Regev, Aviv] MIT, Broad Inst, Cambridge, MA 02142 USA; [Wapinski, Ilan; Regev, Aviv] Harvard Univ, Cambridge, MA 02142 USA; [Wapinski, Ilan] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Regev, Aviv] MIT, Dept Biol, Cambridge, MA 02139 USA	Vidal, M (reprint author), Dana Farber Canc Inst, CCSB, Boston, MA 02115 USA.	marc_vidal@dfci.harvard.edu	Klitgord, Niels/B-5121-2009; Simonis, Nicolas/E-5124-2010; Hill, David/B-6617-2011				Alvaro D, 2007, PLOS GENET, V3, P2439, DOI 10.1371/journal.pgen.0030228; Birney E, 2007, NATURE, V447, P799, DOI 10.1038/nature05874; Brachat S, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r45; Clamp M, 2007, P NATL ACAD SCI USA, V104, P19428, DOI 10.1073/pnas.0709013104; Clark AG, 2007, NATURE, V450, P203, DOI 10.1038/nature06341; Cliften P, 2003, SCIENCE, V301, P71, DOI 10.1126/science.1084337; Craggs JK, 2001, J VIROL METHODS, V94, P111, DOI 10.1016/S0166-0934(01)00281-6; David L, 2006, P NATL ACAD SCI USA, V103, P5320, DOI 10.1073/pnas.0601091103; Domazet-Loso T, 2003, GENOME RES, V13, P2213, DOI 10.1101/gr.1311003; Fisk DG, 2006, YEAST, V23, P857, DOI 10.1002/yea.1400; Fleischer TC, 2006, GENE DEV, V20, P1294, DOI 10.1101/gad.1422006; GAVIN AC, 2002, NATURE, V415, P147; Gavin AC, 2006, NATURE, V440, P631, DOI 10.1038/nature04532; Ghaemmaghami S, 2003, NATURE, V425, P737, DOI 10.1038/nature02046; GOFFEAU A, 1996, SCIENCE, V274, P567; Hardison RC, 2003, PLOS BIOL, V1, P156, DOI 10.1371/journal.pbio.0000058; Hillier L, 1991, PCR Methods Appl, V1, P124; Ho Y, 2002, NATURE, V415, P180, DOI 10.1038/415180a; Holstege FCP, 1998, CELL, V95, P717, DOI 10.1016/S0092-8674(00)81641-4; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Kellis M, 2003, NATURE, V423, P241, DOI 10.1038/nature01644; Krogan NJ, 2006, NATURE, V440, P637, DOI 10.1038/nature04670; Kumar A, 2002, GENE DEV, V16, P707, DOI 10.1101/gad.970902; Liolios K, 2006, NUCLEIC ACIDS RES, V34, pD332, DOI 10.1093/nar/gkj145; Martinez MJ, 2004, MOL BIOL CELL, V15, P5295, DOI 10.1091/mbc.E04-11-0856; McClelland M, 2000, NUCLEIC ACIDS RES, V28, P4974, DOI 10.1093/nar/28.24.4974; Miller JP, 2005, P NATL ACAD SCI USA, V102, P12123, DOI 10.1073/pnas.0505482102; Miura F, 2006, P NATL ACAD SCI USA, V103, P17846, DOI 10.1073/pnas.0605645103; Pena-Castillo L, 2007, GENETICS, V176, P7, DOI 10.1534/genetics.107.074468; Samanta MP, 2003, P NATL ACAD SCI USA, V100, P12579, DOI 10.1073/pnas.2132527100; Schmid KJ, 2001, GENETICS, V159, P589; Snyder M, 2003, SCIENCE, V300, P258, DOI 10.1126/science.1084354; Stein LD, 2003, PLOS BIOL, V1, P166, DOI 10.1371/journal.pbio.0000045; Uetz P, 2000, NATURE, V403, P623; Velculescu VE, 1997, CELL, V88, P243, DOI 10.1016/S0092-8674(00)81845-0; Xia Y, 2006, J MOL BIOL, V357, P339, DOI 10.1016/j.jmb.2005.12.067; Yu HY, 2004, GENOME RES, V14, P1107, DOI 10.1101/gr.1774904	39	14	14	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1088-9051			GENOME RES	Genome Res.	AUG	2008	18	8					1294	1303		10.1101/gr.076661.108		10	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Genetics & Heredity	332XJ	WOS:000258116100010	
J	Vaidya, J; Kantarcioglu, M; Clifton, C				Vaidya, Jaideep; Kantarcioglu, Murat; Clifton, Chris			Privacy-preserving Naive Bayes classification	VLDB JOURNAL			English	Article						data mining; privacy; security; Naive Bayes; distributed computing		Privacy-preserving data mining-developing models without seeing the data - is receiving growing attention. This paper assumes a privacy-preserving distributed data mining scenario: data sources collaborate to develop a global model, but must not disclose their data to others. The problem of secure distributed classification is an important one. In many situations, data is split between multiple organizations. These organizations may want to utilize all of the data to create more accurate predictive models while revealing neither their training data/databases nor the instances to be classified. Naive Bayes is often used as a baseline classifier, consistently providing reasonable classification performance. This paper brings privacy-preservation to that baseline, presenting protocols to develop a Naive Bayes classifier on both vertically as well as horizontally partitioned data.	[Vaidya, Jaideep] Rutgers State Univ, Newark, NJ 07102 USA; [Kantarcioglu, Murat] Univ Texas Dallas, Dallas, TX 75230 USA; [Clifton, Chris] Purdue Univ, W Lafayette, IN 47907 USA	Vaidya, J (reprint author), Rutgers State Univ, Newark, NJ 07102 USA.	jsvaidya@rbs.rutgers.edu; muratk@utdallas.edu; clifton@cs.purdue.edu					Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; [Anonymous], 2002, FED REG, V67, P53181; Atallah MJ, 2001, P 17 ANN COMP SEC AP; Benaloh J. C., 1987, LNCS, V263, P251; BLUM M, 1984, ADV CRYPTOLOGY CRYPT; CHANG YC, 2001, LECT NOTES COMPUTER, V2248; CHOR B, 1993, INFORM PROCESS LETT, V45, P205, DOI 10.1016/0020-0190(93)90120-X; CRAMER R, 2000, PRIVACY PRESERVING D; DU W, 2002, IEEE INT C DAT MIN W, V14, P1; Du W.-L., 2001, NEW SEC PAR WORKSH C, P11; EVEN S, 1985, COMMUN ACM, V28, P637, DOI 10.1145/3812.3818; Evfimievski A., 2002, 8 ACM SIGKDD INT C K, P217; Goethals B, 2004, LECT NOTES COMPUT SC, V3506, P104; Goldreich O., 1987, 19 STOC, P218, DOI DOI 10.1145/28395.28420; Goldreich Oded, 2004, FDN CRYPTOGRAPHY, V2; HUANG Z, 2005, P 2005 ACM SIGMOD IN; IOANNIDIS I, 2002, 2002 INT C PAR PROC; Jagannathan G, 2005, P 11 ACM SIGKDD INT, P593, DOI 10.1145/1081870.1081942; Kantarcioglu M, 2004, IEEE T KNOWL DATA EN, V16, P1026, DOI 10.1109/TKDE.2004.45; Kantarcioglu M., 2002, ACM SIGMOD WORKSH RE, P24; KANTARCIOUGLU M, 2002, IEEE INT C DAT MIN W, V14, P37; Kargupta H, 2003, P 3 IEEE INT C DAT M; Lin XD, 2005, KNOWL INF SYST, V8, P68, DOI 10.1007/s10115-004-0148-7; Lindell Y, 2002, J CRYPTOL, V15, P177, DOI 10.1007/s00145-001-0019-2; Lindell Y, 2000, LECT NOTES COMPUT SC, V1880, P36; Mitchell T.M., 1997, MACHINE LEARNING; Naccache D., 1998, P 5 ACM C COMP COMM, P59, DOI 10.1145/288090.288106; NAOR M, 2001, P SODA 2001 SIAM S D; Naor M., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301312; Okamoto T, 1998, LECT NOTES COMPUT SC, V1403, P308; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; Rabin M.O., 1981, TR81 HARV U AIK COMP; Rizvi S. J., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases; VAIDYA J, 2005, 19 ANN IFIP WG 11 3; VAIDYA J, 2005, J COMPUT SECUR, V13; Vaidya J., 2003, 9 ACM SIGKDD INT C K, P206; Vaidya J., 2002, 8 ACM SIGKDD INT C K, P639, DOI [10.1145/775047.775142, DOI 10.1145/775047.775142]; VAIDYA J, 2004, 2004 SIAM INT C DAT, P522; Wright R., 2004, P 10 ACM SIGKDD INT; Yao A., 1986, P 27 IEEE S FDN COMP, P162, DOI DOI 10.1109/SFCS.1986.25	41	14	14	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1066-8888			VLDB J	VLDB J.	JUL	2008	17	4					879	898		10.1007/s00778-006-0041-y		20	Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	313UO	WOS:000256765700012	
J	Boulle, M				Boulle, Marc			Compression-based averaging of selective naive Bayes classifiers	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						naive Bayes; Bayesian; model selection; model averaging	CATEGORICAL ATTRIBUTES; DISCRETIZATION; VALUES	The naive Bayes classifier has proved to be very effective on many real data applications. Its performance usually benefits from an accurate estimation of univariate conditional probabilities and from variable selection. However, although variable selection is a desirable feature, it is prone to overfitting. In this paper, we introduce a Bayesian regularization technique to select the most probable subset of variables compliant with the naive Bayes assumption. We also study the limits of Bayesian model averaging in the case of the naive Bayes assumption and introduce a new weighting scheme based on the ability of the models to conditionally compress the class labels. The weighting scheme on the models reduces to a weighting scheme on the variables, and finally results in a naive Bayes classifier with "soft variable selection". Extensive experiments show that the compression-based averaged classifier outperforms the Bayesian model averaging scheme.	France Telecom R&D, F-22300 Lannion, France	Boulle, M (reprint author), France Telecom R&D, 2 Ave Pierre Marzin, F-22300 Lannion, France.	MARC.BOULLE@ORANGE-FTGROUP.COM					BLAKE CL, 1996, UCI RESP MACHINE LEA; Boulle M, 2005, LECT NOTES ARTIF INT, V3587, P228; BOULLE M, 2006, INT J C NEURAL NETWO, P2989; Boulle M, 2006, MACH LEARN, V65, P131, DOI 10.1007/s10994-006-8364-x; Boulle M, 2005, J MACH LEARN RES, V6, P1431; BOULLE M, 2006, FEATURE EXTRACTION F, P499; Breiman L., 1984, CLASSIFICATION REGRE; Dash D., 2002, P 19 INT C MACH LEAR, P91; DENG K, 2006, P ICML 2006 WORKSH R, P17; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; FAWCETT T, 2003, HPL20034 HP LAB; Guyon I, 2006, FEATURE EXTRACTION F; GUYON I, 2006, FEATURE EXTRACTION F, P237; GUYON I, 2006, INT JOINT C NEUR NET, P2958; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hoeting JA, 1999, STAT SCI, V14, P382; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Langley P., 1992, 10 NAT C ART INT, P223; Langley P., 1994, P 10 C UNC ART INT, P399; Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535; Mitchell T.M., 1997, MACHINE LEARNING; Pareto V., 1971, MANUALE EC POLITICA; Provost F., 1998, P 15 INT C MACH LEAR, P445; PROVOST F, 2001, WELL TRAINED PETS IM; RAFTERY AE, 2003, 433 U WASH DEP STAT; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; ROBERT CP, 1997, BAYESIAN CHOICE DECI; Shannon CE, 1948, MATH THEORY COMMUNIC; WRITTEN IH, 2000, DATA MINING; YANG Y, P PAC RIM KNOWL ACQ, P159	31	14	14	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2007	8						1659	1685				27	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	208XY	WOS:000249353700010	
S	Chang, KH; Chen, MY; Canny, J		Krumm, J; Abowd, GD; Seneviratne, A; Strang, T		Chang, Keng-hao; Chen, Mike Y.; Canny, John			Tracking free-weight exercises	UbiComp 2007: Ubiquitous Computing, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	9th International Conference on Ubiquitous Computing	SEP 16-19, 2007	Innsbruck, AUSTRIA	Intel Res, Saltlux, Siemens, Microsoft Res, TranIT, Nokia, KDubiq				Weight training, in addition to aerobic exercises, is an important component of a balanced exercise program. However, mechanisms for tracking free weight exercises have not yet been explored. In this paper, we study methods that automatically recognize what type of exercise you are doing and how many repetitions you have done so far. We incorporated a three-axis accelerometer into a workout glove to track hand movements and put another accelerometer on a user's waist to track body posture. To recognize types of exercises, we tried two methods: a Naive Bayes Classifier and Hidden Markov Models. To count repetitions developed and tested two algorithms: a peak counting algorithm and a method using the Viterbi algorithm with a Hidden Markov Model. Our experimental results showed overall recognition accuracy of around 90% over nine different exercises, and overall miscount rate of around 5%. We believe that the promising results will potentially contribute to the vision of a digital personal trainer, create a new experience for exercising, and enable physical and psychological well-being.	Univ Calif Berkeley, Div Comp Sci, Berkeley Inst Design, Berkeley, CA 94720 USA							ADES PA, 2001, NEW ENGL J MED, V111, P369; [Anonymous], 1979, PROGRAMS DIGITAL SIG; Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1; BENBASAT AY, 2000, THESIS MIT; BENBASAT AY, 2002, LNCS, V2298, P9; CANE J, 1999, COMPLETE IDIOTS GUID; De Vaul R, 2005, P 7 IEEE INT S WEAR, P4; DELAVIER F, 2005, STRENGTH TRAINING AN; DISHMAN E, 2004, IEEE COMPUT, V37, P34; FOMEY GD, 1973, P IEEE, V61, P268; HAMID R, 2006, P UAI 2005 ED SCOTL, P71, DOI 10.1145/1178782.1178794; HARTMAN B, 2007, P ACM CHI 2007 C HUM, P145, DOI 10.1145/1240624.1240646; HEALEY J, 2005, HPL2005134; Intille S. S., 2002, IEEE Pervasive Computing, V1, DOI 10.1109/MPRV.2002.1012340; LENENSHTEIN VI, 2001, J COMB THEORY A, V93, P310; Lester J., 2005, P 19 INT JOINT C ART, P766; Minnen D., 2006, INT S WEAR COMP ISWC, P11; MURPHY KP, 2001, 947201776 U CA BERK; Philipose M, 2004, IEEE PERVAS COMPUT, V3, P50, DOI 10.1109/MPRV.2004.7; Shephard RJ, 1999, CIRCULATION, V99, P963; Sothern MS, 1999, EUR J PEDIATR, V158, P271, DOI 10.1007/s004310051070; SUBRAMANYA A, 2006, P 22 ANN C UNC ART I; WARD JA, 2005, P 2005 JOINT C SMART, V121, P99; Westeyn T., 2003, P 5 INT C MULT INT, P85; Wyatt D., 2005, P 20 NAT C ART INT, P21	25	14	14	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74852-6	LECT NOTES COMPUT SC			2007	4717						19	37				19	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Social Sciences, Interdisciplinary	Computer Science; Social Sciences - Other Topics	BGQ83	WOS:000249815300002	
J	Seewald, AK				Seewald, Alexander K.			An evaluation of Naive Bayes variants in content-based learning for spam filtering	INTELLIGENT DATA ANALYSIS			English	Article						empirical study; spam filtering; machine learning; Naive Bayes		We describe an in-depth analysis of spam-filtering performance of a simple Naive Bayes learner and two extended variants. A set of seven mailboxes comprising about 65,000 mails from seven different users, as well as a representative snapshot of 25,000 mails which were received over 18 weeks by a single user, were used for evaluation. Our main motivation was to test whether two extended variants of Naive Bayes learning, SA-Train and CRM114, were superior to simple Naive Bayes learning, represented by SpamBayes. Surprisingly, we found that the performance of these systems was remarkably similar and that the extended systems have significant weaknesses which are not apparent for the simpler Naive Bayes learner. The simpler Naive Bayes learner, SpamBayes, also offers the most stable performance in that it deteriorates least over time. Overall, SpamBayes should be preferred over the more complex variants.	Seewald Solut, A-1180 Vienna, Austria	Seewald, AK (reprint author), Seewald Solut, A-1180 Vienna, Austria.	alex@seewald.at					Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; CORMACK G, 2004, STUDY SUPERVISED SPA; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Gauthronet S, 2001, UNSOLICITED COMMERCI; GOMEZ JM, 2000, COMBINING TEXT HEURI; GRAHAM P, 2003, PLAN SPAM; HOFFMAN P, 1998, IMCR008 UBE SOL; MEYER TM, 1998, P 1 C EM ANT CEAS MO; PALTT J, 1998, ADV KERNEL METHODS S; Sahami M., 1998, WS9805 AAAI; SAKKIS G, 2003, INFORM RETREIVAL J, V6; SAKKIS G, 2001, P EMNLP 01 6 C EMP M; SEEWALD AK, 2005, TR200504 AUSTR RES I; SEEWALD AK, 2004, TR200411 AUSTR RES I; SEEWALD AK, 2007, J ADV DATA ANAL CLAS, V3; SERGEANT M, 2003, 2003 MIT SPAM C CAMB; YERAZUNIS WS, 2004 MIT SPAM C MIT	17	14	14	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1088-467X			INTELL DATA ANAL	Intell. Data Anal.		2007	11	5					497	524				28	Computer Science, Artificial Intelligence	Computer Science	229AX	WOS:000250774800005	
J	Sorich, MJ; McKinnon, RA; Miners, JO; Smith, PA				Sorich, Michael J.; McKinnon, Ross A.; Miners, John O.; Smith, Paul A.			The importance of local chemical structure for chemical metabolism by human uridine 5 '-diphosphate - Glucuronosyltransferase	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							HUMAN UDP-GLUCURONOSYLTRANSFERASES; ELECTRONEGATIVITY EQUALIZATION METHOD; SUBSTITUTED BENZOIC-ACIDS; SUBSTRATE SELECTIVITY; IN-VITRO; DRUG GLUCURONIDATION; ISOFORM SELECTIVITY; PREDICTION; PHARMACOPHORE; SPECIFICITY	The uridine 5'-diphosphate-(UDP-) glucuronosyltransferase (UGT) family of enzymes catalyzes the conjugation of chemicals containing a suitable nucleophilic atom with glucuronic acid. Despite the importance of glucuronidation as an elimination and detoxification mechanism for drugs, environmental chemicals, and endogenous compounds, the structural features of substrates that confer isoform selectivity are poorly understood. The relationship between the local molecular structure of nucleophilic atoms of chemicals and the ability of UGT isoforms to glucuronidate the nucleophilic atoms was investigated here. The proximity of an aromatic ring to the nucleophilic atom was highly associated with a greater likelihood of glucuronidation by most UGT isoforms. Similarly, most UGT isoforms were found to have a statistically significant preference for oxygen over nitrogen as the nucleophilic atom. The converse was established only for UGT1A4. Naive Bayes models were trained to predict the site of glucuronidation for eight UGT isoforms on the basis of the partial charge and Fukui function of the nucleophilic atom and whether an aromatic ring was attached to the nucleophilic atom. On average, the cross-validated sensitivity and specificity of the models were approximately 75-80%. For all but UGT2B7, the area under the receiver operating characteristics curve of the model was greater than 0.8, indicating strong predictive ability. A chemical diversity analysis of the currently available data indicates bias toward chemicals containing phenolic groups, and it is likely that the availability of chemical data sets with greater diversity will facilitate further insights into the structural features of substrates that confer enzyme selectivity.	Univ S Australia, Sch Pharm & Med Sci, Sansom Inst, Adelaide, SA 5000, Australia; Flinders Univ S Australia, Dept Clin Pharmacol, Bedford Pk, SA 5042, Australia	Sorich, MJ (reprint author), Univ S Australia, Sch Pharm & Med Sci, Sansom Inst, Frome Rd, Adelaide, SA 5000, Australia.	michael.sorich@unisa.edu.au	McKinnon, Ross /B-9340-2009; Sorich, Michael/A-1210-2011	McKinnon, Ross /0000-0002-3725-793X; Sorich, Michael/0000-0003-1999-866X			Agresti A, 1992, STAT SCI, V7, P131, DOI DOI 10.1214/SS/1177011454; ARMSTRONG RN, 1987, CRIT REV BIOCHEM MOL, V22, P39, DOI 10.3109/10409238709082547; Aumont V, 2001, ARCH BIOCHEM BIOPHYS, V393, P281, DOI 10.1006/abbi.2001.2496; Barbier O, 2001, MOL PHARMACOL, V59, P636; BAUER DF, 1972, J AM STAT ASSOC, V67, P687, DOI 10.2307/2284469; BECK JR, 1986, ARCH PATHOL LAB MED, V110, P13; BONE R, 1991, METHOD ENZYMOL, V202, P643, DOI 10.1016/0076-6879(91)02030-D; Bultinck P, 2002, J PHYS CHEM A, V106, P7887, DOI 10.1021/jp0205463; BURCHELL B, 1995, LIFE SCI, V57, P1819, DOI 10.1016/0024-3205(95)02073-R; Cupid BC, 1996, XENOBIOTICA, V26, P157; Cupid BC, 1999, XENOBIOTICA, V29, P27, DOI 10.1080/004982599238795; de Hoon MJL, 2004, BIOINFORMATICS, V20, P1453, DOI 10.1093/bioinformatics/bth078; Demsar J, 2004, ORANGE EXPT MACHINE; Doerge DR, 2000, DRUG METAB DISPOS, V28, P298; Ethell BT, 2002, DRUG METAB DISPOS, V30, P734, DOI 10.1124/dmd.30.6.734; Geerlings P., 2002, INT J MOL SCI, V3, P276, DOI 10.3390/i3040276; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Jude AR, 2001, DRUG METAB DISPOS, V29, P652; Kemp DC, 2002, DRUG METAB DISPOS, V30, P694, DOI 10.1124/dmd.30.6.694; Langenaeker W., 1991, J MOL STRUC-THEOCHEM, V234, P329, DOI 10.1016/0166-1280(91)89021-R; LI Y, 1995, J AM CHEM SOC, V117, P7756, DOI 10.1021/ja00134a021; Miners JO, 2004, ANNU REV PHARMACOL, V44, P1, DOI 10.1146/annurev.pharmtox.44.101802.121546; MINERS JO, 1991, PHARMACOL THERAPEUT, V51, P347, DOI 10.1016/0163-7258(91)90065-T; R Development Core Team, 2005, R LAND ENV STAT COMP; Radominska-Pandya A, 1999, DRUG METAB REV, V31, P817, DOI 10.1081/DMR-100101944; Said M, 1996, QUANT STRUCT-ACT REL, V15, P382, DOI 10.1002/qsar.19960150503; Smith PA, 2003, J MED CHEM, V46, P1617, DOI 10.1021/jm020397c; Smith PA, 2003, CLIN EXP PHARMACOL P, V30, P836, DOI 10.1046/j.1440-1681.2003.03923.x; Smith PA, 2004, J MOL GRAPH MODEL, V22, P507, DOI 10.1016/j.jmgm.2004.03.011; Sorich MJ, 2002, PHARMACOGENETICS, V12, P635, DOI 10.1097/00008571-200211000-00008; Sorich MJ, 2004, J MED CHEM, V47, P5311, DOI 10.1021/jm0495529; Sorich MJ, 2004, MOL PHARMACOL, V65, P301, DOI 10.1124/mol.65.2.301; Sorich MJ, 2003, J CHEM INF COMP SCI, V43, P2019, DOI 10.1021/ci034108k; Stone AN, 2003, DRUG METAB DISPOS, V31, P1086, DOI 10.1124/dmd.31.9.1086; Uchaipichat V, 2004, DRUG METAB DISPOS, V32, P413, DOI 10.1124/dmd.32.4.413; Voigt JH, 2001, J CHEM INF COMP SCI, V41, P702, DOI 10.1021/ci000150t	37	14	15	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	NOV 27	2006	46	6					2692	2697		10.1021/ci600248e		6	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	109HF	WOS:000242298100047	
J	Ganguly, M; Brown, N; Schuffenhauer, A; Ertl, P; Gillet, VJ; Greenidge, PA				Ganguly, Milan; Brown, Nathan; Schuffenhauer, Ansgar; Ertl, Peter; Gillet, Valerie J.; Greenidge, Paulette A.			Introducing the consensus modeling concept in genetic algorithms: Application to interpretable discriminant analysis	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							MARKETED ORAL-DRUGS; SUBSTITUTED PIPERIDINES; BIOLOGICAL-ACTIVITY; RENIN INHIBITORS; SURFACE-AREA; PREDICTION; IDENTIFICATION; DISCOVERY; PROFILES	An evolutionary statistical learning method was applied to classify drugs according to their biological target and also to discriminate between a compilation of oral and nonoral drugs. The emphasis was placed not only on how well the models predict but also on their interpretability. In an enhancement to previous studies, the consistency of the model weights over several runs of the genetic algorithm was considered with the goal of producing comprehensible models. Via this approach, the descriptors and their ranges that contribute most to class discrimination were identified. Selecting a bin step size that enables the average descriptor properties of the class being trained to be captured improves the interpretability and discriminatory power of a model. The performance, consistency, and robustness of such models were further enhanced by using two novel approaches that reduce the variability between individual solutions: consensus and splice modeling. Finally, the ability of the genetic algorithm to discriminate between activity classes was compared with a similarity searching method, while naive Bayes classifiers and support vector machines were applied in discriminating the oral and nonoral drugs.	Novartis Inst BioMed Res, CH-4002 Basel, Switzerland; Univ Sheffield, Krebs Inst Biomol Res, Sheffield S10 2TN, S Yorkshire, England; Univ Sheffield, Dept Informat Studies, Sheffield S10 2TN, S Yorkshire, England	Brown, N (reprint author), Novartis Inst BioMed Res, CH-4002 Basel, Switzerland.	nathan.brown@novartis.com					AITCHISON J, 1976, BIOMETRIKA, V63, P413, DOI 10.1093/biomet/63.3.413; Ajay, 1998, J MED CHEM, V41, P3314, DOI 10.1021/jm970666c; AJAY, 1994, CHEMOMETR INTELL LAB, V24, P19, DOI 10.1016/0169-7439(94)00027-1; Beresford AP, 2004, CURR OPIN DRUG DISC, V7, P36; Bohm H.-J., 2004, DRUG DISCOV TODAY, V1, P217, DOI DOI 10.1016/J.DDTEC.2004.10.009; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; Clark DE, 1999, J PHARM SCI, V88, P815, DOI 10.1021/js980402t; Ertl P, 2003, SAR QSAR ENVIRON RES, V14, P321, DOI 10.1080/10629360310001673917; Ertl P, 2000, J MED CHEM, V43, P3714, DOI 10.1021/jm000942e; Gillet VJ, 1998, J CHEM INF COMP SCI, V38, P165, DOI 10.1021/ci970431+; Ginn CMR, 1997, J CHEM INF COMP SCI, V37, P23, DOI 10.1021/ci960466u; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Guller R, 1999, BIOORG MED CHEM LETT, V9, P1403, DOI 10.1016/S0960-894X(99)00196-1; Harper G, 2001, J CHEM INF COMP SCI, V41, P1295, DOI 10.1021/ci000397q; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Jenkins JL, 2004, J MED CHEM, V47, P6144, DOI 10.1021/jm049654z; Joachims T., 2001, LEARNING CLASSIFY TE; Kubinyi H., 2003, NAT REV DRUG DISCOV, V2, P151; Lajiness MS, 2004, CURR OPIN DRUG DISC, V7, P470; Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1; Oefner C, 1999, CHEM BIOL, V6, P127, DOI 10.1016/S1074-5521(99)89004-8; Pirard B, 2000, J CHEM INF COMP SCI, V40, P1431, DOI 10.1021/ci000386x; Vieira E, 1999, BIOORG MED CHEM LETT, V9, P1397, DOI 10.1016/S0960-894X(99)00195-X; Vieth M, 2004, J MED CHEM, V47, P224, DOI 10.1021/jm030267j; VLANDEWATERBEEM.H, 2003, NAT REV DRUG DISCOV, V2, P192; Wagener M, 2000, J CHEM INF COMP SCI, V40, P280, DOI 10.1021/ci990266t; Walters WP, 2002, ADV DRUG DELIVER REV, V54, P255, DOI 10.1016/S0169-409X(02)00003-0; Wenlock MC, 2003, J MED CHEM, V46, P1250, DOI 10.1021/jm021053p; Wilton D, 2003, J CHEM INF COMP SCI, V43, P469, DOI 10.1021/ci025586i	29	14	14	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	SEP 25	2006	46	5					2110	2124		10.1021/ci0505291		15	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	086VS	WOS:000240701700027	
J	Chen, X; Pereira, F; Lee, W; Strother, S; MitcheI, T				Chen, X; Pereira, F; Lee, W; Strother, S; MitcheI, T			Exploring predictive and reproducible Modeling with the single-subject FIAC dataset	HUMAN BRAIN MAPPING			English	Article; Proceedings Paper	Joint Statistical Meeting of the American-Statistical-Association	AUG 07-11, 2005	Minneapolis, MN	Amer Stat Assoc		classification; fMRI; linear discriminant analysis; predictive modeling; reproducible modeling	FUNCTIONAL NEUROIMAGING EXPERIMENTS; VENTRAL TEMPORAL CORTEX; FMRI DATA; PERFORMANCE METRICS; QUANTITATIVE-EVALUATION; PREPROCESSING CHOICES; MRI; REPRESENTATIONS; OBJECTS; FACES	Predictive modeling of functional magnetic resonance imaging (fMRI) has the potential to expand the amount of information extracted and to enhance our understanding of brain systems by predicting brain states, rather than emphasizing the standard spatial mapping. Based on the block datasets of Functional Imaging Analysis Contest (FIAC) Subject 3, we demonstrate the potential and pitfalls of predictive modeling in fMRI analysis by investigating the performance of five models (linear discriminant analysis, logistic regression, linear support vector machine, Gaussian naive Bayes, and a variant) as a function of preprocessing steps and feature selection methods. We found that: (1) independent of the model, temporal detrending and feature selection assisted in building a more accurate predictive model; (2) the linear support vector machine and logistic regression often performed better than either of the Gaussian naive Bayes models in terms of the optimal prediction accuracy; and (3) the optimal prediction accuracy obtained in a feature space using principal components was typically lower than that obtained in a voxel space, given the same model and same preprocessing. We show that due to the existence of artifacts from different sources, high prediction accuracy alone does not guarantee that a classifier is learning a pattern of brain activity that might be usefully visualized, although cross-validation methods do provide fairly unbiased estimates of true prediction accuracy. The trade-off between the prediction accuracy and the reproducibility of the spatial pattern should be carefully considered in predictive modeling of fMRI We suggest that unless the experimental goal is brain-state classification of new scans on well-defined spatial features, prediction alone should not be used as an optimization procedure in fMRI data analysis.	Rotman Res Inst, Baycrest Ctr, Toronto, ON M6A 2E1, Canada; Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; Carnegie Mellon Univ, Ctr Neural Basis Cognit, Pittsburgh, PA 15213 USA; Univ Toronto, Dept Med Biophys, Toronto, ON, Canada	Chen, X (reprint author), Rotman Res Inst, Baycrest Ctr, 3560 Bathurst St, Toronto, ON M6A 2E1, Canada.	xchen@rotman-baycrest.on.ca	Chen, Xu/J-4650-2013				Dehaene-Lambertz G, 2006, HUM BRAIN MAPP, V27, P360, DOI 10.1002/hbm.20250; Formisano E, 2002, NEUROCOMPUTING, V49, P241, DOI 10.1016/S0925-2312(02)00517-9; Gavrilescu M, 2002, NEUROIMAGE, V17, P532, DOI 10.1006/nimg.2002.1226; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Haynes JD, 2005, CURR BIOL, V15, P1301, DOI 10.1016/j.cub.2005.06.026; Holmes A, 1997, NEUROIMAGE, V5, pS480; Kjems U, 2002, NEUROIMAGE, V15, P772, DOI 10.1006/nimg.2001.1033; LaConte S, 2005, NEUROIMAGE, V26, P317, DOI 10.1016/j.neuroimage.2005.01.048; LaConte S, 2003, NEUROIMAGE, V18, P10, DOI 10.1006/nimg.2002.1300; Lange N, 1999, NEUROIMAGE, V10, P282, DOI 10.1006/nimg.1999.0472; Mitchell T.M., 1997, MACHINE LEARNING; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Mjolsness E, 2001, SCIENCE, V293, P2051, DOI 10.1126/science.293.5537.2051; Morch N, 1997, LECT NOTES COMPUT SC, V1230, P259; O'Toole AJ, 2005, J COGNITIVE NEUROSCI, V17, P580, DOI 10.1162/0898929053467550; Shaw ME, 2003, NEUROIMAGE, V19, P988, DOI 10.1016/S1053-8119(03)00116-2; Skudlarski P, 1999, NEUROIMAGE, V9, P311, DOI 10.1006/nimg.1999.0402; Strother S, 2004, NEUROIMAGE, V23, pS196, DOI 10.1016/j.neuroimage.2004.07.022; Strothert SC, 2002, NEUROIMAGE, V15, P747, DOI 10.1006/nimg.2001.1034; Strother SC, 1998, QUANTITATIVE FUNCTIONAL BRAIN IMAGING WITH POSITRON EMISSION TOMOGRAPHY, P241, DOI 10.1016/B978-012161340-2/50038-X; Tegeler C, 1999, HUM BRAIN MAPP, V7, P267, DOI 10.1002/(SICI)1097-0193(1999)7:4<267::AID-HBM5>3.0.CO;2-3; Vapnik V., 1995, NATURE STAT LEARNING; Xing EP, 2001, P 18 INT C MACH LEAR, P601	24	14	14	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1065-9471			HUM BRAIN MAPP	Hum. Brain Mapp.	MAY	2006	27	5					452	461		10.1002/hbm.20243		10	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	037KO	WOS:000237145800012	
J	Zhang, J; Kang, DK; Silvescu, A; Honavar, V				Zhang, J; Kang, DK; Silvescu, A; Honavar, V			Learning accurate and concise naive Bayes classifiers from attribute value taxonomies and data	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						attribute value taxonomies; AVT-based naive Bayes learner; partially specified data	DATABASES; IMPRECISE; KNOWLEDGE; COMMERCE	In many application domains, there is a need for learning algorithms that can effectively exploit attribute value taxonomies (AVT)-hierarchical groupings of attribute values-to learn compact, comprehensible and accurate classifiers from data-including data that are partially specified. This paper describes AVT-NBL, a natural generalization of the naive Bayes learner (NBL), for learning classifiers from AVT and data. Our experimental results show that AVT-NBL is able to generate classifiers that are substantially more compact and more accurate than those produced by NBL on a broad range of data sets with different percentages of partially specified values. We also show that AVT-NBL is more efficient in its use of training data: AVT-NBL produces classifiers that outperform those produced by NBL using substantially fewer training examples.	Iowa State Univ, Dept Comp Sci, Artificial Intelligence Res Lab, Computat Intelligence Learning & Discovery Progra, Ames, IA 50011 USA; Iowa State Univ, Bioinformat & Computat Biol Program, Ames, IA 50011 USA	Zhang, J (reprint author), Iowa State Univ, Dept Comp Sci, Artificial Intelligence Res Lab, Computat Intelligence Learning & Discovery Progra, Ames, IA 50011 USA.	jzhang@cs.iastate.edu					ALMUALLIM H, 1996, P 13 NAT C ART INT 8, V1, P703; ALMUALLIM H, 1995, P 12 INT C MACH LEAR, P12; Aronis J. M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Aronis J., 1996, P 2 INT C KNOWL DISC, P355; Ashburner M, 2000, NAT GENET, V25, P25; BERGADANO F, 1990, MACHINE LEARNING ART, V3, P474; BHATTACHARYA I, 2004, KDD WORKSH LINK AN G; Caragea D., 2004, INT J HYBRID INTELLI, V1, P80; CARAGEA D, 2004, P 3 INT C ONT DAT AP, P963; Chen ALP, 1996, IEEE T KNOWL DATA EN, V8, P273, DOI 10.1109/69.494166; Clare A., 2001, LECT NOTES COMPUTER, V2168, P42; Cohen WW, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P709; DeMichiel L. G., 1989, IEEE Transactions on Knowledge and Data Engineering, V1, DOI 10.1109/69.43423; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DESJARDINS M, 2000, LECT NOTES ARTIF INT, V1864, P260; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Han J., 1996, ADV KNOWLEDGE DISCOV, P399; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; Hendler J, 2001, SCI AM, V284, P35; HENDLER J, 1996, CSTR3672 U MAR I ADV; HENDLER J, UMIACSTR9656; KANG DK, 2004, P 4 IEEE INT C DAT M, P130; Kohavi R, 2001, DATA MIN KNOWL DISC, V5, P5, DOI 10.1023/A:1009840925866; KOHAVI R, 1997, IMPROVING SIMPLE BAY; Kohavi R, 2004, MACH LEARN, V57, P83, DOI 10.1023/B:MACH.0000035473.11134.83; Langley P., 1992, P 10 NAT C ART INT, P223; McCallum A., 1998, P 15 INT C MACH LEAR, P359; McClean S, 2001, IEEE T KNOWL DATA EN, V13, P902, DOI 10.1109/69.971186; Mitchell T.M., 1997, MACHINE LEARNING; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; PAZZANI M, 1992, MACH LEARN, V9, P54; Pazzani M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Pereira F., 1993, P 31 ANN M ASS COMP, P183, DOI 10.3115/981574.981598; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RISSANEN J, 1978, AUTOMATIC, V14, P37; Sahami M., 1997, P 14 INT C MACH LEAR, P170; Slonim N., 2000, ACM SIGIR, P208; TAYLOR MG, 1997, SIGMOD DAT MIN KNOWL; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; UNDERCOFFER J, 2004, KNOWLEDGE ENG REV SP; WALKER A, 1980, P VLDB, P47; YAMAZAKI T, 1995, P 12 INT C MACH LEAR, P575; Zhang J., 2002, LECT NOTES ARTIF INT, P316; Zhang J., 2003, P 20 INT C MACH LEAR, P880; ZHANG J, 2004, P 4 IEEE INT C DAT M, P289	47	14	16	SPRINGER LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL ROAD, GODALMING GU7 3DJ, SURREY, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	FEB	2006	9	2					157	179		10.1007/s10115-005-0211-z		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	020OG	WOS:000235918500002	
J	Boulle, M				Boulle, M			A Bayes optimal approach for partitioning the values of categorical attributes	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						data preparation; grouping; Bayesianism; model selection; classification; naive Bayes	DISCRETIZATION	In supervised machine learning, the partitioning of the values (also called grouping) of a categorical attribute aims at constructing a new synthetic attribute which keeps the information of the initial attribute and reduces the number of its values. In this paper, we propose a new grouping method MODL1 founded on a Bayesian approach. The method relies on a model space of grouping models and on a prior distribution defined on this model space. This results in an evaluation criterion of grouping, which is minimal for the most probable grouping given the data, i.e. the Bayes optimal grouping. We propose new super-linear optimization heuristics that yields near-optimal groupings. Extensive comparative experiments demonstrate that the MODL grouping method builds high quality groupings in terms of predictive quality, robustness and small number of groups.	France Telecom, R&D, F-22300 Lannion, France	Boulle, M (reprint author), France Telecom, R&D, 2 Ave Pierre Marzin, F-22300 Lannion, France.	MARC.BOULLE@FRANCETELECOM.COM					ASSERAF M, 2000, INT C HUM SYST LEARN; BERCKMAN NC, 1995, VALUE GROUPING BINAR; Bernardo J. M., 1994, BAYESIAN THEORY; Blake C. L., 1998, UCI REPOSITORY MACHI; BOULLE M, 2004, RNTI E 2, V2, P173; Boulle M, 2004, MANAG INFORMAT SYST, V10, P199; Boulle M, 2004, MACH LEARN, V55, P53, DOI 10.1023/B:MACH.0000019804.29836.05; Breiman L., 1984, CLASSIFICATION REGRE; CESTNIK B, 1987, PROGR MACHINE LEARNI; CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569; Dietterich T. G., 1998, NEURAL COMPUTATION, V10; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Fulton T., 1995, P 12 INT C MACH LEAR, P244; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hsu CN, 2003, MACH LEARN, V53, P235, DOI 10.1023/A:1026367023636; Kass G.V., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; KERBER R, 1991, P 10 INT C ART INT, P123; Kullback S., 1968, INFORM THEORY STAT; Langley P., 1992, P 10 NAT C ART INT, P223; LECHEVALLIER Y, 1990, 1247 INRIA; Pyle D., 1999, DATA PREPARATION DAT; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RITSCHARD G, 2003, REVUE NOUVELLES TECH, V1, P99; RITSCHARD G, 2001, MATH SCI HUM, V155, P81; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SPSS, 2001, ANSW TREE 3 0 US GUI; YANG Y, 2003, P 16 AUSTR JOINT C A; ZIGHED DA, 2000, GRAPHES INDUCTION, P327	30	14	14	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	SEP	2005	6						1431	1452				22	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	026HN	WOS:000236330100007	
J	Acid, S; De Campos, LM; Castellano, JG				Acid, S; De Campos, LM; Castellano, JG			Learning Bayesian network classifiers: Searching in a space of partially directed acyclic graphs	MACHINE LEARNING			English	Article						classification; Bayesian networks; learning algorithms; scoring functions; directed acyclic graphs; partially directed acyclic graphs	BELIEF NETWORKS	There is a commonly held opinion that the algorithms for learning unrestricted types of Bayesian networks, especially those based on the score+search paradigm, are not suitable for building competitive Bayesian network-based classifiers. Several specialized algorithms that carry out the search into different types of directed acyclic graph (DAG) topologies have since been developed, most of these being extensions (using augmenting arcs) or modifications of the Naive Bayes basic topology. In this paper, we present a new algorithm to induce classifiers based on Bayesian networks which obtains excellent results even when standard scoring functions are used. The method performs a simple local search in a space unlike unrestricted or augmented DAGs. Our search space consists of a type of partially directed acyclic graph (PDAG) which combines two concepts of DAG equivalence: classification equivalence and independence equivalence. The results of exhaustive experimentation indicate that the proposed method can compete with state-of-the-art algorithms for classification.	Univ Granada, Dept Ciencias Comp EIA, ETSI Informat, E-18071 Granada, Spain	Acid, S (reprint author), Univ Granada, Dept Ciencias Comp EIA, ETSI Informat, E-18071 Granada, Spain.	acid@decsai.ugr.es; lci@decsai.ugr.es; fjgc@decsai.ugr.es	de Campos, Luis/B-7436-2012; Garcia Castellano, Francisco Javier/D-9984-2012	de Campos, Luis/0000-0001-9125-1195; 			Acid S, 2001, INT J APPROX REASON, V27, P235, DOI 10.1016/S0888-613X(01)00041-X; Acid S, 2003, J ARTIF INTELL RES, V18, P445; Aliferis C.F., 2003, P 2003 AM MED INF AS, P21; Blake C. L., 1998, UCI REPOSITORY MACHI; CHEN G, 1999, IEEE CIRCUITS SYST S, V10, P1; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; CHICKERING DM, 1996, P 12 C UNC ART INT, P150; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; de Campos LM, 2000, INT J APPROX REASON, V24, P11, DOI 10.1016/S0888-613X(99)00042-0; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Elvira Consortium, 2002, P 1 EUR WORKSH PROB, P222; Ezawa K., 1996, P 13 INT C MACH LEAR, P139; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Frey L., 2003, P 3 IEEE INT C DAT M, P59; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GOOD IJ, 1965, ESTIMATIN PROBABILIT; Hand D.J., 1981, DISCRIMINATION CLASS; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; John G., 1994, P 11 INT C MACH LEAR, P121; Keogh E. J., 2002, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V11, DOI 10.1142/S0218213002001052; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Koller D., 1996, P 13 INT C MACH LEAR, P284; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; LUCAS P, 2002, P 1 EUR WORKSH PROB, P117; Pazzani M.J., 1995, LECT NOTES STAT, V112, P239; Pearl J, 1990, P 6 C UNC ART INT, P220; Pearl J., 1988, PROBABILISTIC REASON; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Sierra B, 1998, ARTIF INTELL MED, V14, P215, DOI 10.1016/S0933-3657(98)00024-4; Singh M., 1996, P 13 INT C MACH LEAR, P453; Spirtes P., 1993, LECT NOTES STAT, V81; Zhang NL, 2004, ARTIF INTELL MED, V30, P283, DOI 10.1016/j.artmed.2003.11.004	39	14	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JUN	2005	59	3					213	235				23	Computer Science, Artificial Intelligence	Computer Science	933FG	WOS:000229613700002	
J	Zorkadis, V; Karras, DA; Panayotou, M				Zorkadis, V; Karras, DA; Panayotou, M			Efficient information theoretic strategies for classifier combination, feature extraction and performance evaluation in improving false positives and false negatives for spam e-mail filtering	NEURAL NETWORKS			English	Article; Proceedings Paper	International Joint Conference on Neural Networks	JUL 31-AUG 04, 2005	Montreal, CANADA	IEEE Computat Intelligence Soc, Int Neural Networks Soc		privacy-enhancing technology; anti-spam filter; classifier combination; information theoretic feature extraction; classification equivocation; committee machines; Bayesian e-mail filter; boosting trees		Spam emails are considered as a serious privacy-related violation, besides being a costly, unsolicited communication. Various spam filtering techniques have been so far proposed, mainly based on Naive Bayesian algorithms. Other Machine Learning algorithms like Boosting trees, or Support Vector Machines (SVM) have already been used with success. However, the number of False Positives (FP) and False Negatives (FN) resulting through applying various spam e-mail filters still remains too high and the problem of spam e-mail categorization cannot be solved completely from a practical viewpoint. In this paper, we propose a novel approach for spam e-mail filtering based on efficient information theoretic techniques for integrating classifiers, for extracting improved features and for properly evaluating categorization accuracy in terms of FP and FN. The goal of the presented methodology is to empirically but explicitly minimize these FP and FN numbers by combining high-performance FP filters with high-performance FN filters emerging from a previous work of the authors [Zorkadis, V., Panayotou, M., & Karras, D. A. (2005). Improved spam e-mail filtering based on committee machines and information theoretic feature extraction. Proceedings of the International Joint Conference on Neural Networks, July 31-August 4, 2005, Montreal, Canada].(1) To this end, Random Committee-based filters along with ADTree-based ones are efficiently combined through information theory, respectively. The experiments conducted are of the most extensive ones so far in the literature, exploiting widely accepted benchmarking e-mail data sets and comparing the proposed methodology with the Naive Bayes spam filter as well as with the Boosting tree methodology, the classification via regression and other machine learning models. It is illustrated by means of novel information theoretic measures of FP & FN filtering performance that the proposed approach is very favorably compared to the other rival methods. Finally, it is found that the proposed information theoretic Boolean features present a remarkably high sparn categorization performance. (c) 2005 Elsevier Ltd. All rights reserved.	Data Protect Author & Hellen Open Univ, Athens, Greece; Chalkis Inst Technol, Dept Automat, Athens 16342, Greece; Hellen Open Univ, Chalkis Inst Technol, Athens 16342, Greece	Karras, DA (reprint author), Data Protect Author & Hellen Open Univ, Athens, Greece.	zorkadis@dpa.gr; dakarras@teihal.gr; dakarras@ieee.org					Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; CARRERAS X, 2001, P RANLP 01 4 INT C R; Cover T. M., 1991, ELEMENTS INFORMATION; DRUCKER H, 1999, IEEE T NEURAL NETWOR, P10; Elkan C., 1997, CS97557 U CAL DEP CO; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; Freund Y., 1999, P 16 INT C MACH LEAR, P124; KAPLAN S, 2003, WIRED MAGAZINE, P43; PORTER MF, 2003, ALGORITHM SUFFIX STR; Tresp V., 2001, HDB NEURAL NETWORK S; TRETYAKOV K, 2004, MACHINE LEARNING TEC, V3, P60; VAUGHANNICHOLS SJ, 2003, IEEE SPECTRUM MAGAZI, P40; ZORKADIS V, 2005, P INT JOINT C NEUR N	13	14	19	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	JUN-JUL	2005	18	5-6					799	807		10.1016/j.neunet.2005.06.045		9	Computer Science, Artificial Intelligence	Computer Science	967MY	WOS:000232096500040	
B	Florian, R; Yarowsky, D		Hajic, J; Matsumoto, Y		Florian, R; Yarowsky, D			Modeling consensus: Classifier combination for word sense disambiguation	PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING			English	Proceedings Paper	Conference on Empirical Methods in Natural Language Processing	JUL 06-07, 2002	Philadelphia, PA	Justsystem Corp, CLAIRVOYANCE Corp				This paper demonstrates the substantial empirical success of classifier combination for the word sense disambiguation task. It investigates more than 10 classifier combination methods, including second order classifier stacking, over 6 major structurally different base classifiers (enhanced Naive Bayes, cosine, Bayes Ratio, decision lists, transformation-based learning and maximum variance boosted mixture models). The paper also includes in-depth performance analysis sensitive to properties of the feature space and component classifiers. When evaluated on the standard SENSEVAL 1 and 2 data sets on 4 languages (English, Spanish, Basque, and Swedish), classifier combination performance exceeds the best published results on these data sets.	Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA			Yarowsky, David/A-3270-2010				BERGER A, 1996, CONVEXITY MAXIMUM LI; Brill E, 1995, COMPUT LINGUIST, V21, P543; Brill Eric, 1998, P COLING ACL 98, P191; CUCERZAN S, 2000, P ACL 2000, P270, DOI 10.3115/1075218.1075253; CUCERZAN S, P EMNLP 2002; DAELEMANS W, 1999, ILK9803 TILB U NETH; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Edmonds P., 2001, P 2 INT WORKSH EV WO, P1; FUHR N, 1989, ACM T INFORM SYST, V7, P183, DOI 10.1145/65943.65944; GALE WA, 1992, COMPUT HUMANITIES, V26, P415, DOI 10.1007/BF00136984; Henderson J., 1999, P 4 C EMP METH NAT L, P187; Kilgarriff A, 2000, COMPUT HUMANITIES, V34, P1, DOI 10.1023/A:1002619001915; Kilgarriff A, 2000, COMPUT HUMANITIES, V34, P15, DOI 10.1023/A:1002693207386; Manning C.D., 1999, FDN STAT NATURAL LAN; Ngai G, 2001, P 2 ANN M N AM CHAPT, P40; Pedersen T., 2000, P 1 ANN M N AM CHAPT, P63; PEDERSEN T, 1998, WORKSH NOT AAAI S SA; Perrone M.P., 1993, NEURAL NETWORKS SPEE, P126; Stevenson M, 2001, COMPUT LINGUIST, V27, P321, DOI 10.1162/089120101317066104; TJONG KSE, 2000, P COLING 2000, P857; TUMER K, 1995, TR950298 U TEX AUST; van Halteren H, 2001, COMPUT LINGUIST, V27, P199; VANHALTEREN H, 1998, P 36 ANN M ACL 17 IN, P491; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yarowsky D., 2000, P ACL 2000, P207, DOI 10.3115/1075218.1075245; YAROWSKY D, 2002, IN PRESS J NATURAL L; Yarowsky David, 1996, PROGR SPEECH SYNTHES, P159	27	14	14	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA							2002							25	32				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAO63	WOS:000223079900004	
J	Yuan, JS; Liu, ZC; Wu, Y				Yuan, Junsong; Liu, Zicheng; Wu, Ying			Discriminative Video Pattern Search for Efficient Action Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video pattern search; action detection; spatiotemporal branch-and-bound search	ACTION RECOGNITION	Actions are spatiotemporal patterns. Similar to the sliding window-based object detection, action detection finds the reoccurrences of such spatiotemporal patterns through pattern matching, by handling cluttered and dynamic backgrounds and other types of action variations. We address two critical issues in pattern matching-based action detection: 1) the intrapattern variations in actions, and 2) the computational efficiency in performing action pattern search in cluttered scenes. First, we propose a discriminative pattern matching criterion for action classification, called naive Bayes mutual information maximization (NBMIM). Each action is characterized by a collection of spatiotemporal invariant features and we match it with an action class by measuring the mutual information between them. Based on this matching criterion, action detection is to localize a subvolume in the volumetric video space that has the maximum mutual information toward a specific action class. A novel spatiotemporal branch-and-bound (STBB) search algorithm is designed to efficiently find the optimal solution. Our proposed action detection method does not rely on the results of human detection, tracking, or background subtraction. It can handle action variations such as performing speed and style variations as well as scale changes well. It is also insensitive to dynamic and cluttered backgrounds and even to partial occlusions. The cross-data set experiments on action detection, including KTH, CMU action data sets, and another new MSR action data set, demonstrate the effectiveness and efficiency of the proposed multiclass multiple-instance action detection method.	[Yuan, Junsong] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore; [Liu, Zicheng] Microsoft Res, Redmond, WA 98052 USA; [Wu, Ying] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA	Yuan, JS (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore, Singapore.	jsyuan@ntu.edu.sg; zliu@microsoft.com; yingwu@eecs.northwestern.edu	Wu, Ying/B-7283-2009; Yuan, Junsong/A-5171-2011		Nanyang Assistant Professorship; US National Science Foundation [IIS-0347877, IIS-0916607]; US Army Research Laboratory; US Army Research Office [ARO W911NF-08-1-0504]	This work was supported in part by the Nanyang Assistant Professorship to Dr. Junsong Yuan, US National Science Foundation grant IIS-0347877, IIS-0916607, and the US Army Research Laboratory and the US Army Research Office under grant ARO W911NF-08-1-0504. The authors thank Dr. Yan Ke, Dr. Cha Zhang, and Dr. Zhengyou Zhang for helpful discussions, and Liangliang Cao for the help on the experiments of the TRECVID data set.	Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Ali S., 2007, P IEEE C COMP VIS PA, P1; Bentley J., 1984, ACM COMMU, V27, P865; Blank M., 2005, P IEEE INT C COMP VI, V2, P1395, DOI 10.1109/ICCV.2005.28; Blaschko M., 2008, P EUR C COMP VIS, P2; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Boiman O., 2008, P IEEE C COMP VIS PA, P1; Cao L., 2010, P IEEE C COMP VIS PA; Datar M, 2004, P 20 ANN S COMP GEOM, P253, DOI 10.1145/997817.997857; DHILLON PS, 2008, COMBINING APPEARANCE; DIKMEN M, 2008, P VID EV WORKSH; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178); DUCHENNE O, 2009, P IEEE INT C COMP VI, P1491; EFROS AA, 2003, P IEEE INT C COMP VI, V2; Fathi A., 2008, P IEEE C COMP VIS PA, P1; HAN D, 2009, P IEEE INT C COMP VI, P1933; Hu Y., 2009, P IEEE INT C COMP VI, P128; Jia K., 2008, P IEEE C COMP VIS PA, P1; Jiang H., 2006, P IEEE C COMP VIS PA, P1646; [刘军 LIU Jun], 2008, [高分子通报, Polymer Bulletin], P1, DOI 10.1145/1509315.1509331; Ke Y., 2005, P IEEE INT C COMP VI, V1, P166; Ke Y., 2007, P IEEE INT C COMP VI, P1; Lampert C. H., 2008, P IEEE C COMP VIS PA, P1; LAMPERT CH, 2009, P 12 IEEE INT C COMP, P987; Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I., 2008, P IEEE C COMP VIS PA, P1; Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597; Lin Z., 2009, P IEEE INT C COMP VI, P444; Liu JG, 2009, PROC CVPR IEEE, P1996; Lv F., 2007, P IEEE C COMP VIS PA, P1; Natarajan P., 2008, P IEEE C COMP VIS PA, P1; NGUYEN N, 2005, P IEEE C COMP VIS PA, V2; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4; Perez P., 2007, P IEEE INT C COMP VI; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; REDDY KK, 2009, P IEEE INT C COMP VI, P1010; Rodriguez M. D., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587727; Schuldt C., 2004, P INT C PATT REC, V3, P32; Scovanner P., 2007, P ACM MULT; Shechtman E., 2005, P IEEE C COMP VIS PA, V1, P405; Sun J, 2009, PROC CVPR IEEE, P2004; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Vitaladevuni S.N., 2008, P C COMP VIS PATT RE, P1; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Weinland D., 2008, P IEEE C COMP VIS PA, P1; WEINLAND D, 2006, COMPUTER VISION IMAG, V104, P207; Wong S. F., 2007, P IEEE INT C COMP VI, P1; Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182; Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112; Yilmaz A., 2005, P IEEE C COMP VIS PA; YUAN J, 2009, P ACM MULT WORKSH EV; Yuan Jun-hui, 2010, Zhonghua Yixue Yichuanxue Zazhi, V27, P136, DOI 10.3760/cma.j.issn.1003-9406.2010.02.004; Yuan JS, 2009, PROC CVPR IEEE, P2434; Zhang Z., 2008, P EUR C COMP VIS, P817	56	13	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1728	1743		10.1109/TPAMI.2011.38		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	792JN	WOS:000292740000003	
J	Wee, LJK; Simarmata, D; Kam, YW; Ng, LFP; Tong, JC				Wee, Lawrence J. K.; Simarmata, Diane; Kam, Yiu-Wing; Ng, Lisa F. P.; Tong, Joo Chuan			SVM-based prediction of linear B-cell epitopes using Bayes Feature Extraction	BMC GENOMICS			English	Article; Proceedings Paper	9th International Conference on Bioinformatics (InCoB2010) - Computational Biology	SEP 26-28, 2010	Tokyo, JAPAN				PROTEINS; INFORMATION; PROGRAM	Backgound: The identification of B-cell epitopes on antigens has been a subject of intense research as the knowledge of these markers has great implications for the development of peptide-based diagnostics, therapeutics and vaccines. As experimental approaches are often laborious and time consuming, in silico methods for prediction of these immunogenic regions are critical. Such efforts, however, have been significantly hindered by high variability in the length and composition of the epitope sequences, making naive modeling methods difficult to apply. Results: We analyzed two benchmark datasets and found that linear B-cell epitopes possess distinctive residue conservation and position-specific residue propensities which could be exploited for epitope discrimination in silico. We developed a support vector machines (SVM) prediction model employing Bayes Feature Extraction to predict linear B-cell epitopes of diverse lengths (12- to 20-mers). The best SVM classifier achieved an accuracy of 74.50% and A(ROC) of 0.84 on an independent test set and was shown to outperform existing linear B-cell epitope prediction algorithms. In addition, we applied our model to a dataset of antigenic proteins with experimentally-verified epitopes and found it to be generally effective for discriminating the epitopes from non-epitopes. Conclusion: We developed a SVM prediction model utilizing Bayes Feature Extraction and showed that it was effective in discriminating epitopes from non-epitopes in benchmark datasets and annotated antigenic proteins. A web server for predicting linear B-cell epitopes was developed and is available, together with supplementary materials, at http://www.immunopred.org/bayesb/index.html.	[Wee, Lawrence J. K.; Tong, Joo Chuan] Inst Infocomm Res, Data Min Dept, Singapore 138632, Singapore; [Wee, Lawrence J. K.; Simarmata, Diane; Kam, Yiu-Wing; Ng, Lisa F. P.] Singapore Immunol Network, Singapore 138648, Singapore; [Ng, Lisa F. P.; Tong, Joo Chuan] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Biochem, Singapore 117597, Singapore	Tong, JC (reprint author), Inst Infocomm Res, Data Min Dept, 1 Fusionopolis Way,21-01 Connexis S Tower, Singapore 138632, Singapore.	victor@bic.nus.edu.sg					Alix AJP, 1999, VACCINE, V18, P311, DOI 10.1016/S0264-410X(99)00329-1; Blythe MJ, 2005, PROTEIN SCI, V14, P246, DOI 10.1110/ps.041059505; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.-C., LIBSVM LIB SUPPORT V; Chen J, 2007, AMINO ACIDS, V33, P423, DOI 10.1007/s00726-006-0485-9; EL-Manzalawy Y, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE, PROCEEDINGS, P289, DOI 10.1109/BIBM.2008.80; El-Manzalawy Y, 2008, J MOL RECOGNIT, V21, P243, DOI 10.1002/jmr.893; KORBER B, 2006, PLOS COMPUT BIOL, V2, pE71; Larsen Jens Erik Pontoppidan, 2006, Immunome Res, V2, P2, DOI 10.1186/1745-7580-2-2; Odorico M, 2003, J MOL RECOGNIT, V16, P20, DOI 10.1002/jmr.602; PELLEQUER JL, 1993, J MOL GRAPHICS, V11, P204, DOI 10.1016/0263-7855(93)80074-2; Rubinstein ND, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-287; Rubinstein ND, 2009, MOL IMMUNOL, V46, P840, DOI 10.1016/j.molimm.2008.09.009; Saha S, 2006, PROTEINS, V65, P40, DOI 10.1002/prot.21078; Saha S, 2005, BMC GENOMICS, V6, DOI 10.1186/1471-2164-6-79; Saha S, 2004, LECT NOTES COMPUT SC, V3239, P197; Shao JL, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004920; Shen JW, 2007, P NATL ACAD SCI USA, V104, P4337, DOI 10.1073/pnas.0607879104; Sollner J, 2006, J MOL RECOGNIT, V19, P200, DOI 10.1002/jmr.771; SONG J, BMC BIOINFORMATICS, V7, P124; Song JN, 2010, BIOINFORMATICS, V26, P752, DOI 10.1093/bioinformatics/btq043; Song JN, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-425; Sweredoski MJ, 2009, PROTEIN ENG DES SEL, V22, P113, DOI 10.1093/protein/gzn075; Bairoch A, 2008, NUCLEIC ACIDS RES, V36, pD190, DOI 10.1093/nar/gkm895	24	13	13	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics	DEC 2	2010	11			4					S21	10.1186/1471-2164-11-S4-S21		9	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	745WD	WOS:000289200700021	
J	Gkirtzou, K; Tsamardinos, I; Tsakalides, P; Poirazi, P				Gkirtzou, Katerina; Tsamardinos, Ioannis; Tsakalides, Panagiotis; Poirazi, Panayiota			MatureBayes: A Probabilistic Algorithm for Identifying the Mature miRNA within Novel Precursors	PLOS ONE			English	Article							MICRORNA PRECURSORS; NUCLEAR EXPORT; RNAS; IDENTIFICATION; PREDICTION; DIVISION; CANCER; GENES	Background: MicroRNAs (miRNAs) are small, single stranded RNAs with a key role in post-transcriptional regulation of thousands of genes across numerous species. While several computational methods are currently available for identifying miRNA genes, accurate prediction of the mature miRNA remains a challenge. Existing approaches fall short in predicting the location of mature miRNAs but also in finding the functional strand(s) of miRNA precursors. Methodology/Principal Findings: Here, we present a computational tool that incorporates a Naive Bayes classifier to identify mature miRNA candidates based on sequence and secondary structure information of their miRNA precursors. We take into account both positive (true mature miRNAs) and negative (same-size non-mature miRNA sequences) examples to optimize sensitivity as well as specificity. Our method can accurately predict the start position of experimentally verified mature miRNAs for both human and mouse, achieving a significantly larger (often double) performance accuracy compared with two existing methods. Moreover, the method exhibits a very high generalization performance on miRNAs from two other organisms. More importantly, our method provides direct evidence about the features of miRNA precursors which may determine the location of the mature miRNA. We find that the triplet of positions 7, 8 and 9 from the mature miRNA end towards the closest hairpin have the largest discriminatory power, are relatively conserved in terms of sequence composition (mostly contain a Uracil) and are located within or in very close proximity to the hairpin loop, suggesting the existence of a possible recognition site for Dicer and associated proteins. Conclusions: This work describes a novel algorithm for identifying the start position of mature miRNA(s) produced by miRNA precursors. Our tool has significantly better (often double) performance than two existing approaches and provides new insights about the potential use of specific sequence/structural information as recognition signals for Dicer processing. Web Tool available at: http://mirna.imbb.forth.gr/MatureBayes.html	[Gkirtzou, Katerina; Tsamardinos, Ioannis; Tsakalides, Panagiotis] Univ Crete, Dept Comp Sci, Iraklion, Greece; [Gkirtzou, Katerina; Tsamardinos, Ioannis; Tsakalides, Panagiotis] Fdn Res & Technol Hellas, Inst Comp Sci, Iraklion, Greece; [Poirazi, Panayiota] Fdn Res & Technol Hellas, Inst Mol Biol & Biotechnol, Iraklion, Greece	Gkirtzou, K (reprint author), Univ Crete, Dept Comp Sci, Iraklion, Greece.	poirazi@imbb.forth.gr			European Community [MTKD-CT-2005-029791]; European Commission [PIOF-GA-2008-219622]	This work was funded by the Marie Curie TOK-DEV ASPIRE grant [MTKD-CT-2005-029791] within the 6th European Community Framework Program (K.G., P.T.) and the Marie Curie Outgoing Fellowship [PIOF-GA-2008-219622] of the European Commission (P.P.). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Ambros V, 2003, RNA, V9, P277, DOI 10.1261/rna.2183803; Bartel DP, 2009, CELL, V136, P215, DOI 10.1016/j.cell.2009.01.002; BEREZIKOV E, 2006, NAT GENET S1, V38; Bernstein E, 2001, NATURE, V409, P363, DOI 10.1038/35053110; Cai XZ, 2004, RNA, V10, P1957, DOI 10.1261/rna.7135204; Chen JF, 2006, NAT GENET, V38, P228, DOI 10.1038/ng1725; Deshpande G, 2005, GENE DEV, V19, P1680, DOI 10.1101/gad.1316805; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Friedlander MR, 2008, NAT BIOTECHNOL, V26, P407, DOI 10.1038/nbt1394; GKIRTZOU K, 2008, 8 IEEE INT C BIOINFO, P1; HARRY Z, 2004, LECT NOTES COMPUTER, P501; Hatfield SD, 2005, NATURE, V435, P974, DOI 10.1038/nature03816; Helvik SA, 2007, BIOINFORMATICS, V23, P142, DOI 10.1093/bioinformatics/btl570; Iorio MV, 2005, CANCER RES, V65, P7065, DOI 10.1158/0008-5472.CAN-05-1783; JEFFREYS H, 1946, PROC R SOC LON SER-A, V186, P453, DOI 10.1098/rspa.1946.0056; Kapranov P, 2007, SCIENCE, V316, P1484, DOI 10.1126/science.1138341; Kim VN, 2004, TRENDS CELL BIOL, V14, P156, DOI 10.1016/j.tcb.2004.02.006; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kong Yong, 2005, GeoActa, V3, P62; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Landthaler M, 2004, CURR BIOL, V14, P2162, DOI 10.1016/j.cub.2004.11.001; LEE RC, 1993, CELL, V75, P843, DOI 10.1016/0092-8674(93)90529-Y; Lee Y, 2004, EMBO J, V23, P4051, DOI 10.1038/sj.emboj.7600385; Mitchell T.M., 1997, MACHINE LEARNING; Mourrain P, 2000, CELL, V101, P533, DOI 10.1016/S0092-8674(00)80863-6; Nam JW, 2005, NUCLEIC ACIDS RES, V33, P3570, DOI 10.1093/nar/gki668; Oulas A, 2009, IEEE T INF TECHNOL B, V13, P67, DOI 10.1109/TITB.2008.2007086; OULAS A, 2009, NUCLEIC ACIDS RES, V7, P3276; PBARTEL D, 2004, CELL, V116, P281; Rana TM, 2006, PLOS BIOL, V4; Ruby JG, 2007, NATURE, V448, P83, DOI 10.1038/nature05983; SHENG Y, 2007, PLOS ONE, V2; TAO M, 2007, THERMODYNAMIC STRUCT; Xu PZ, 2003, CURR BIOL, V13, P790, DOI 10.1016/S0960-9822(03)00250-1; Yi R, 2003, GENE DEV, V17, P3011, DOI 10.1101/gad.1158803; Yousef M, 2009, FEBS J, V276, P2150, DOI 10.1111/j.1742-4658.2009.06933.x; Yousef M, 2006, BIOINFORMATICS, V22, P1325, DOI 10.1093/bioinformatics/bt/094	37	13	13	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203			PLOS ONE	PLoS One	AUG 6	2010	5	8							e11843	10.1371/journal.pone.0011843		14	Multidisciplinary Sciences	Science & Technology - Other Topics	635WK	WOS:000280687900001	
J	Lam, HYK; Kim, PM; Mok, J; Tonikian, R; Sidhu, SS; Turk, BE; Snyder, M; Gerstein, MB				Lam, Hugo Y. K.; Kim, Philip M.; Mok, Janine; Tonikian, Raffi; Sidhu, Sachdev S.; Turk, Benjamin E.; Snyder, Michael; Gerstein, Mark B.			MOTIPS: Automated Motif Analysis for Predicting Targets of Modular Protein Domains	BMC BIOINFORMATICS			English	Article							SEQUENCE ALIGNMENT; WIDE PREDICTION; SPECIFICITY; NETWORKS; MATRICES; SERVER; YEAST	Background: Many protein interactions, especially those involved in signaling, involve short linear motifs consisting of 5-10 amino acid residues that interact with modular protein domains such as the SH3 binding domains and the kinase catalytic domains. One straightforward way of identifying these interactions is by scanning for matches to the motif against all the sequences in a target proteome. However, predicting domain targets by motif sequence alone without considering other genomic and structural information has been shown to be lacking in accuracy. Results: We developed an efficient search algorithm to scan the target proteome for potential domain targets and to increase the accuracy of each hit by integrating a variety of pre-computed features, such as conservation, surface propensity, and disorder. The integration is performed using naive Bayes and a training set of validated experiments. Conclusions: By integrating a variety of biologically relevant features to predict domain targets, we demonstrated a notably improved prediction of modular protein domain targets. Combined with emerging high-resolution data of domain specificities, we believe that our approach can assist in the reconstruction of many signaling pathways.	[Lam, Hugo Y. K.; Gerstein, Mark B.] Yale Univ, Program Computat Biol & Bioinformat, New Haven, CT 06520 USA; [Kim, Philip M.; Gerstein, Mark B.] Yale Univ, Dept Mol Biophys & Biochem, New Haven, CT 06520 USA; [Mok, Janine; Snyder, Michael] Yale Univ, Dept Mol Cellular & Dev Biol, New Haven, CT 06520 USA; [Tonikian, Raffi; Sidhu, Sachdev S.] Univ Toronto, Dept Mol Genet, Toronto, ON M5S 1A8, Canada; [Tonikian, Raffi; Sidhu, Sachdev S.] Univ Toronto, Banting & Best Dept Med Res, Toronto, ON M5G 1L6, Canada; [Turk, Benjamin E.] Yale Univ, Dept Pharmacol, New Haven, CT 06520 USA; [Gerstein, Mark B.] Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA	Lam, HYK (reprint author), Yale Univ, Program Computat Biol & Bioinformat, New Haven, CT 06520 USA.				NIH; AL Williams Professorship funds	We acknowledge support from the NIH and from the AL Williams Professorship funds. We would also like to thank Chong Shou for proofreading the manuscript and Kevin Yip for the discussion on the PCA.	Adamczak R, 2004, PROTEINS, V56, P753, DOI 10.1002/prot.20176; Beltrao P, 2005, PLOS COMPUT BIOL, V1, P202, DOI 10.1371/journal.pcbi.0010026; Eddy SR, 2004, NAT BIOTECHNOL, V22, P1035, DOI 10.1038/nbt0804-1035; Edgar RC, 2004, NUCLEIC ACIDS RES, V32, P1792, DOI 10.1093/nar/gkh340; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; HANKS SK, 1988, SCIENCE, V241, P42, DOI 10.1126/science.3291115; Henikoff JG, 1996, COMPUT APPL BIOSCI, V12, P135; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; Hutti JE, 2004, NAT METHODS, V1, P27, DOI 10.1038/NMETH708; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Jones DT, 2003, PROTEINS, V53, P573, DOI 10.1002/prot.10528; Landgraf C, 2004, PLOS BIOL, V2, P94, DOI 10.1371/journal.pbio.0020014; MCLACHLA.AD, 1972, J MOL BIOL, V64, P417, DOI 10.1016/0022-2836(72)90508-6; Mok J, 2010, SCI SIGNAL, V3, DOI 10.1126/scisignal.2000482; Obenauer JC, 2003, NUCLEIC ACIDS RES, V31, P3635, DOI 10.1093/nar/gkg584; PAWSON T, 1995, NATURE, V373, P573, DOI 10.1038/373573a0; Pawson T, 2003, SCIENCE, V300, P445, DOI 10.1126/science.1083653; Pei JM, 2001, BIOINFORMATICS, V17, P700, DOI 10.1093/bioinformatics/17.8.700; Puntervoll P, 2003, NUCLEIC ACIDS RES, V31, P3625, DOI 10.1093/nar/gkg545; Remm M, 2001, J MOL BIOL, V314, P1041, DOI 10.1006/jmbi.2001.5197; TONG AH, 2002, SCIENCE, V11, P321; Tonikian R, 2009, PLOS BIOL, V7, DOI 10.1371/journal.pbio.1000218; Tonikian R, 2007, NAT PROTOC, V2, P1368, DOI 10.1038/nprot.2007.151; Turhan B, 2009, DATA KNOWL ENG, V68, P278, DOI 10.1016/j.datak.2008.10.005; Ward JJ, 2004, BIOINFORMATICS, V20, P2138, DOI 10.1093/bioinformatics/bth195; Yaffe MB, 2001, NAT BIOTECHNOL, V19, P348, DOI 10.1038/86737; Zarrinpar A, 2003, NATURE, V426, P676, DOI 10.1038/nature02178; Zarrinpar A, 2003, SCI STKE; Zeng GS, 1999, J CELL BIOL, V144, P71, DOI 10.1083/jcb.144.1.71	29	13	13	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAY 11	2010	11								243	10.1186/1471-2105-11-243		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	623HD	WOS:000279728900007	
J	Turhan, B; Bener, A				Turhan, Burak; Bener, Ayse			Analysis of Naive Bayes' assumptions on software fault data: An empirical study	DATA & KNOWLEDGE ENGINEERING			English	Article						Naive Bayes; Software defect prediction; Empirical study	LEARN DEFECT PREDICTORS; STATIC CODE ATTRIBUTES	Software defect prediction is important for reducing test times by allocating testing resources effectively. In terms of predicting the defects in software, Naive Bayes outperforms a wide range of other methods. However, Naive Bayes assumes the 'independence' and 'equal importance' of attributes. In this work, we analyze these assumptions of Naive Bayes using public software defect data from NASA. Our analysis shows that independence assumption is not harmful for software defect data with PCA pre-processing. Our results also indicate that assigning weights to static code attributes may increase the prediction performance significantly, while removing the need for feature subset selection. (c) 2008 Elsevier B.V. All rights reserved.	[Turhan, Burak; Bener, Ayse] Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey	Turhan, B (reprint author), Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.	turhanb@boun.edu.tr; bener@boun.edu.tr	Turhan, Burak/G-7400-2011				Alpaydin E, 2004, INTRO MACHINE LEARNI; Auer M, 2006, IEEE T SOFTWARE ENG, V32, P83, DOI 10.1109/TSE.2006.1599418; BASILI V, 2002, P 24 INT C SOFTW ENG; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Frank E., 2003, P C UNC ART INT, P249; Hall M, 2007, KNOWL-BASED SYST, V20, P120, DOI 10.1016/j.knosys.2006.11.008; Halstead M.H., 1977, ELEMENTS SOFTWARE SC; HARROLD MJ, 2000, P C FUTURE SOFTWARE; Khoshgoftaar TM, 2003, EMPIR SOFTW ENG, V8, P255, DOI 10.1023/A:1024424811345; Lewis D., 1998, LECT NOTES COMPUTER, V1398, P4, DOI DOI 10.1007/BFB0026666; Lung J, 2008, PROC INT CONF SOFTW, P191, DOI 10.1145/1368088.1368115; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, DOI 10.1109/TSE.1976.233837; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P2, DOI 10.1109/TSE.2007.256941; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P637, DOI 10.1109/TSE.2007.70721; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; MUNSON J, 1990, J ELECT MAT, V19, P106; MUNSON JC, 1992, IEEE T SOFTWARE ENG, V18, P423, DOI 10.1109/32.135775; *NASA, 2007, WVU 4 5 FAC METR DAT; Oral A., 2007, P 22 INT S COMP INF, P1; Padberg F, 2004, IEEE T SOFTWARE ENG, V30, P17, DOI 10.1109/TSE.2004.1265733; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Song QB, 2006, IEEE T SOFTWARE ENG, V32, P69; TAHAT BV, 2001, P 25 ANN INT COMP SO, P489; TURBAN B, 2007, P 7 INT C QUAL SOFTW, P231; Turhan B., 2007, P 2 INT C SOFTW DAT, P244; Turhan B., 2008, P 20 INT C SOFTW ENG, P143; Zhang H., 2004, P 4 IEEE INT C DAT M, P567; Zhang HY, 2007, IEEE T SOFTWARE ENG, V33, P635, DOI 10.1109/TSE.2007.70706; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	29	13	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X			DATA KNOWL ENG	Data Knowl. Eng.	FEB	2009	68	2					278	290		10.1016/j.datak.2008.10.005		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	403HP	WOS:000263074000006	
J	Zhao, YL; Li, H; Hou, YY; Cha, L; Cao, Y; Wang, LG; Ying, XM; Li, WJ				Zhao, Yalin; Li, Hua; Hou, Yanyan; Cha, Lei; Cao, Yuan; Wang, Ligui; Ying, Xiaomin; Li, Wuju			Construction of two mathematical models for prediction of bacterial sRNA targets	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						prediction of sRNA targets; support vector machines; Naive Bayes method; feature forward selection; model	SMALL NONCODING RNAS; ESCHERICHIA-COLI; EXPRESSION; GENES; IDENTIFICATION; BINDING; CANCER; VECTOR; BLOOD	Accurate prediction of sRNA targets plays a key role in determining sRNA functions. Here we introduced two mathematical models, sRNATargetNB and sRNATargetSVM, for prediction of sRNA targets using Naive Bayes method and support vector machines (SVM), respectively. The training dataset was composed of 46 positive samples (real sRNA-targets interaction) and 86 negative samples (no interaction between sRNA and targets). The leave-one-out cross-validation (LOOCV) classification accuracy was 91.67% for sRNATargetNB, and 100.00% for sRNATargetSVM. To evaluate the performance of the models, an independent test dataset was used, which contained 22 positive samples and 1700 randomly generated negative samples. The results showed that the classification accuracy, sensitivity, and specificity were 93.03%, 40.90%, and 93.71% for sRNATargetNB and 80.55%, 72.73%, and 80.65% for sRNATargetSVM, respectively. Therefore, the presented models provide support for experimental identification of sRNA targets, The related software and supplementary materials can be downloaded from webpage http://www.biosun.org.cn/srnatarget/. (C) 2008 Elsevier Inc. All rights reserved.	[Zhao, Yalin; Li, Hua; Hou, Yanyan; Cha, Lei; Cao, Yuan; Wang, Ligui; Ying, Xiaomin; Li, Wuju] Beijing Inst Basic Med Sci, Ctr Computat Biol, Beijing 100850, Peoples R China	Ying, XM (reprint author), Beijing Inst Basic Med Sci, Ctr Computat Biol, Taiping Rd 27,Haidian Dist, Beijing 100850, Peoples R China.	yingxm@nic.bmi.ac.cn; liwj@nic.bmi.ac.cn					Altuvia S, 1998, EMBO J, V17, P6069, DOI 10.1093/emboj/17.20.6069; ARIANE ML, 2008, J MATH BIOL, V56, P15; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chen S, 2004, J BACTERIOL, V186, P6689, DOI 10.1128/JB.186.20.6689-6697.2004; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Delihas N, 2001, J MOL BIOL, V313, P1, DOI 10.1006/jmbi.2001.5029; Hofacker IL, 2003, NUCLEIC ACIDS RES, V31, P3429, DOI 10.1093/nar/gkg599; Kim SK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-411; Li Wuju, 2002, Bioinformatics (Oxford), V18, P325; Li WJ, 2005, BREAST CANCER RES, V7, DOI 10.1186/bcr1295; Mandin P, 2007, NUCLEIC ACIDS RES, V35, P962, DOI 10.1093/nar/gkl1096; Masse E, 2005, J BACTERIOL, V187, P6962, DOI 10.1128/JB.187.20.6962-6971.2005; Masse E, 2002, P NATL ACAD SCI USA, V99, P4620, DOI 10.1073/pnas.032066599; Tjaden B, 2006, NUCLEIC ACIDS RES, V34, P2791, DOI 10.1093/nar/gkl356; Tjaden B, 2008, J MATH BIOL, V56, P183, DOI 10.1007/s00285-007-0079-5; Vogel J, 2004, CURR BIOL, V14, P2271, DOI 10.1016/j.cub.2004.12.003; Vogel J, 2005, BIOL CHEM, V386, P1219, DOI 10.1515/BC.2005.140; Vogel J, 2007, CURR OPIN MICROBIOL, V10, P262, DOI 10.1016/j.mib.2007.06.001; Wu BL, 2007, BIOCHEM BIOPH RES CO, V354, P498, DOI 10.1016/j.bbrc.2007.01.002; Xiao T, 2005, MOL CELL PROTEOMICS, V4, P1480, DOI 10.1074/mcp.M500055-MCP200; Zhang Y, 2006, BIOCHEM BIOPH RES CO, V343, P950, DOI 10.1016/j.bbrc.2006.02.196	21	13	17	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	JUL 25	2008	372	2					346	350		10.1016/j.bbrc.2008.05.046		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	316HU	WOS:000256941000014	
J	Zhao, HM				Zhao, Huimin			Instance weighting versus threshold adjusting for cost-sensitive classification	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						classification; cost-sensitive learning; instance weighting; threshold adjusting; ROC curve	CASCADE GENERALIZATION; LEARNING ALGORITHMS; ROC CURVE; TREES; AREA	In real-world classification problems, different types of misclassification errors often have asymmetric costs, thus demanding cost-sensitive learning methods that attempt to minimize average misclassification cost rather than plain error rate. Instance weighting and post hoc threshold adjusting are two major approaches to cost-sensitive classifier learning. This paper compares the effects of these two approaches on several standard, off-the-shelf classification methods. The comparison indicates that the two approaches lead to similar results for some classification methods, such as Naive Bayes, logistic regression, and backpropagation neural network, but very different results for other methods, such as decision tree, decision table, and decision rule learners. The findings from this research have important implications on the selection of the cost-sensitive classifier learning approach as well as on the interpretation of a recently published finding about the relative performance of Naive Bayes and decision trees.	Univ Wisconsin, Sheldon B Lubar Sch Business, Milwaukee, WI 53201 USA	Zhao, HM (reprint author), Univ Wisconsin, Sheldon B Lubar Sch Business, POB 742, Milwaukee, WI 53201 USA.	hzhao@uwm.edu					Afifi A., 1996, COMPUTER AIDED MULTI; Blake C. L., 1998, UCI REPOSITORY MACHI; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Cohen W., 1995, P 12 INT C MACH LEAR, P115; De Falco I, 2005, KNOWL INF SYST, V7, P179, DOI 10.1007/s10115-003-0143-4; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5; Drummond C., 2000, P 17 INT C MACH LEAR, P239; Elkan C., 2001, P 17 INT JOINT C ART, P973; Fan W., 1999, P 16 INT C MACH LEAR, P97; Fawcett T., 2003, HPL20034 INT ENT TEC; Gama J., 2000, Intelligent Data Analysis, V4; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Hidalgo J.M.G, 2002, P 2002 ACM S APPL CO, P615; Hosmer Jr DW, 2000, APPL LOGISTIC REGRES; Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299; Japkowicz N., 2002, Intelligent Data Analysis, V6; Kim Y, 2004, KNOWL INF SYST, V6, P645, DOI 10.1007/s10115-003-0116-7; Kohavi R., 1995, P 8 EUR C MACH LEARN, P174; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y; LIN FY, 2000, P 17 INT C MACH LEAR, P84; Margineantu D., 2002, P 13 EUR C MACH LEAR, P270; Provost F., 1998, P 15 INT C MACH LEAR, P445; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sinha A.P., 2005, J MANAGEMENT INFORM, V21, P249; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659; Weiss S. M., 1991, COMPUTER SYSTEMS LEA; Witten IH, 2005, DATA MINING PRACTICA; Zadrozny B., 2003, P 3 IEEE INT C DAT M, P435; Zhang J, 2006, KNOWL INF SYST, V9, P157, DOI 10.1007/s10115-005-0211-z; Zhao H, 2005, IEEE T SYST MAN CY A, V35, P754, DOI 10.1109/TSMCA.2005.843392; Zhao HM, 2006, J DATABASE MANAGE, V17, P92, DOI 10.4018/jdm.2006070105; Zhao HM, 2004, IEEE T KNOWL DATA EN, V16, P727, DOI 10.1109/TKDE.2004.3	38	13	13	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	JUN	2008	15	3					321	334		10.1007/s10115-007-0079-1		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	307MY	WOS:000256324200003	
J	Linghu, B; Snitkin, ES; Holloway, DT; Gustafson, AM; Xia, Y; DeLisi, C				Linghu, Bolan; Snitkin, Evan S.; Holloway, Dustin T.; Gustafson, Adam M.; Xia, Yu; DeLisi, Charles			High-precision high-coverage functional inference from integrated data sources	BMC BIOINFORMATICS			English	Article							PROTEIN-INTERACTION NETWORKS; COMPARATIVE GENOME ANALYSIS; HETEROGENEOUS DATA SOURCES; GENE-FUNCTION PREDICTION; SACCHAROMYCES-CEREVISIAE; BIOLOGICAL DATA; YEAST; ANNOTATION; EXPRESSION; DISCOVERY	Background: Information obtained from diverse data sources can be combined in a principled manner using various machine learning methods to increase the reliability and range of knowledge about protein function. The result is a weighted functional linkage network (FLN) in which linked neighbors share at least one function with high probability. Precision is, however, low. Aiming to provide precise functional annotation for as many proteins as possible, we explore and propose a two-step framework for functional annotation ( 1) construction of a high-coverage and reliable FLN via machine learning techniques ( 2) development of a decision rule for the constructed FLN to optimize functional annotation. Results: We first apply this framework to Saccharomyces cerevisiae. In the first step, we demonstrate that four commonly used machine learning methods, Linear SVM, Linear Discriminant Analysis, NaIve Bayes, and Neural Network, all combine heterogeneous data to produce reliable and high-coverage FLNs, in which the linkage weight more accurately estimates functional coupling of linked proteins than use individual data sources alone. In the second step, empirical tuning of an adjustable decision rule on the constructed FLN reveals that basing annotation on maximum edge weight results in the most precise annotation at high coverages. In particular at low coverage all rules evaluated perform comparably. At coverage above approximately 50%, however, they diverge rapidly. At full coverage, the maximum weight decision rule still has a precision of approximately 70%, whereas for other methods, precision ranges from a high of slightly more than 30%, down to 3%. In addition, a scoring scheme to estimate the precisions of individual predictions is also provided. Finally, tests of the robustness of the framework indicate that our framework can be successfully applied to less studied organisms. Conclusion: We provide a general two-step function-annotation framework, and show that high coverage, high precision annotations can be achieved by constructing a high-coverage and reliable FLN via data integration followed by applying a maximum weight decision rule.	[Linghu, Bolan; Snitkin, Evan S.; Gustafson, Adam M.; Xia, Yu; DeLisi, Charles] Boston Univ, Bioinformat Grad Program, Boston, MA 02215 USA; [Linghu, Bolan; Snitkin, Evan S.; Holloway, Dustin T.; Gustafson, Adam M.; Xia, Yu; DeLisi, Charles] Boston Univ, Ctr Adv Genom Technol, Boston, MA 02215 USA	DeLisi, C (reprint author), Boston Univ, Bioinformat Grad Program, Boston, MA 02215 USA.	blinghu@bu.edu; esnitkin@bu.edu; dth128@bu.edu; gustafad@bu.edu; yuxia@bu.edu; delisi@bu.edu					Aravind L, 2000, GENOME RES, V10, P1074, DOI 10.1101/gr.10.8.1074; Ashburner M, 2000, NAT GENET, V25, P25; Asthana S, 2004, GENOME RES, V14, P1170, DOI 10.1101/gr.2203804; Balazsi G, 2005, P NATL ACAD SCI USA, V102, P7841, DOI 10.1073/pnas.0500365102; Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048; Ben-Hur Asa, 2005, BIOINFORMATICS S1, V21, pi38; Bork P, 1998, J MOL BIOL, V283, P707, DOI 10.1006/jmbi.1998.2144; Bowers PM, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-5-r35; Collins SR, 2007, MOL CELL PROTEOMICS, V6, P439, DOI 10.1074/mcp.M600381-MCP200; Deng MH, 2004, J COMPUT BIOL, V11, P463, DOI 10.1089/1066527041410346; Deng MH, 2004, BIOINFORMATICS, V20, P895, DOI 10.1093/bioinformatics/btg500; Deng Xutao, 2006, Journal of Bioinformatics and Computational Biology, V4, P217, DOI 10.1142/S0219720006001928; Dunn R, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-39; Enright AJ, 1999, NATURE, V402, P86; Flannick J, 2006, GENOME RES, V16, P1169, DOI 10.1101/gr.5235706; Franke L, 2006, AM J HUM GENET, V78, P1011, DOI 10.1086/504300; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Hibbs MA, 2007, BIOINFORMATICS, V23, P2692, DOI 10.1093/bioinformatics/btm403; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Huttenhower C, 2006, BIOINFORMATICS, V22, P2890, DOI 10.1093/informatics/btl492; Ito T, 2000, P NATL ACAD SCI USA, V97, P1143, DOI 10.1073/pnas.97.3.1143; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Jiang TJ, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-136; Kanehisa M, 2002, NOVART FDN SYMP, V247, P101; Kanehisa M, 2002, NOVART FDN SYMP, V247, P91; Kanehisa M, 2004, NUCLEIC ACIDS RES, V32, pD277, DOI 10.1093/nar/gkh063; Kanehisa M, 2002, NOVART FDN SYMP, V247, P244; Kanehisa M, 2002, NOVART FDN SYMP, V247, P119; Karaoz U, 2004, P NATL ACAD SCI USA, V101, P2888, DOI 10.1073/pnas.0307326101; Kiemer L, 2007, PROTEOMICS, V7, P932, DOI 10.1002/pmic.200600448; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; LETOVSKY S, 2003, BIOINFORMATICS S1, V19, P97; Li JX, 2006, BIOINFORMATICS, V22, P2037, DOI 10.1093/bioinformatics/btl345; MASSJOUNI N, 2006, NUCLEIC ACIDS RES, pW340; McDermott J, 2005, BIOINFORMATICS, V21, P3217, DOI 10.1093/bioinformatics.bti514; Altaf-Ul-Amin M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-207; Miller JP, 2005, P NATL ACAD SCI USA, V102, P12123, DOI 10.1073/pnas.0505482102; Myers CL, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-13-r114; Nabieva E, 2005, BIOINFORMATICS S1, V21, P302; Oliver S, 2000, NATURE, V403, P601, DOI 10.1038/35001165; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Pruitt KD, 2005, NUCLEIC ACIDS RES, V33, pD501, DOI 10.1093/nar/gki025; PRUITT KD, 2007, NUCLEIC ACIDS RES, pD61; Qi YJ, 2006, PROTEINS, V63, P490, DOI 10.1002/prot.20865; Reguly Teresa, 2006, J Biol, V5, P11, DOI 10.1186/jbiol36; Samanta MP, 2003, P NATL ACAD SCI USA, V100, P12579, DOI 10.1073/pnas.2132527100; Schwikowski B, 2000, NAT BIOTECHNOL, V18, P1257, DOI 10.1038/82360; Sharan R, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100129; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Troyanskaya OG, 2005, BRIEF BIOINFORM, V6, P34, DOI 10.1093/bib/6.1.34; Troyanskaya OG, 2003, P NATL ACAD SCI USA, V100, P8348, DOI 10.1073/pnas.0832373100; Vazquez A, 2003, NAT BIOTECHNOL, V21, P697, DOI 10.1038/nbt825; von Mering C, 2003, NUCLEIC ACIDS RES, V31, P258, DOI 10.1093/nar/gkg034; Wu HW, 2005, NUCLEIC ACIDS RES, V33, P2822, DOI 10.1093/nar/gki573; Wu J, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-80; Xiong JH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-268; Yao ZZ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S11	59	13	13	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	FEB 25	2008	9								119	10.1186/1471-2105-9-119		15	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	286VQ	WOS:000254874500001	
S	Moser, R; Pedrycz, W; Succi, G			IEEE	Moser, Raimund; Pedrycz, Witold; Succi, Giancarlo			A Comparative Analysis of the Efficiency of Change Metrics and Static Code Attributes for Defect Prediction	2008 30TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: (ICSE), VOLS 1 AND 2	INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING		English	Proceedings Paper	30th International Conference on Software Engineering	MAY 10-18, 2008	Leipzig, GERMANY	ACM SIGOFT, IEEE CSE, Univ Paderborn, Univ Leipzig, SIEMENS, Zuhlke, Adesso, Deutsch Telekom Lab, sd&m, Werum, Microsoft Res, IBM, i nemis, dSPACE		Defect prediction; software metrics; cost-sensitive classification	EMPIRICAL-ANALYSIS; SOFTWARE; MODELS; FAULTS	In this paper we present a comparative analysis of the predictive power of two different sets of metrics for defect prediction. We choose one set of product related and one set of process related software metrics and use them for classifying Java files of the Eclipse project as defective respective defect-free. Classification models are built using three common machine learners: logistic regression, Naive Bayes, and decision trees. To allow different costs for prediction errors we perform cost-sensitive classification, which proves to be very successful: >75% percentage of correctly classified files, a recall of >80%, and a false positive rate <30%. Results indicate that for the Eclipse data, process metrics are more efficient defect predictors than code metrics.	[Moser, Raimund; Succi, Giancarlo] Free Univ Bolzano Bozen, I-39100 Bolzano, Italy	Moser, R (reprint author), Free Univ Bolzano Bozen, Piazza Domenicani 3, I-39100 Bolzano, Italy.	Raimund.Moser@unibz.it; pedrycz@ee.ualberta.ca; Giancarlo.Succi@unibz.it					BASILI V, 1996, IEEE T SOFTWARE ENG, V22, P267; BELL RM, 2006, INT S SOFTW TEST AN; Duda R. O., 2002, PATTERN CLASSIFICATI; Fenton NE, 1999, IEEE T SOFTWARE ENG, V25, P675, DOI 10.1109/32.815326; Fenton NE, 2000, IEEE T SOFTWARE ENG, V26, P797, DOI 10.1109/32.879815; Gall H., 2003, Proceedings. Sixth International Workshop on Principles of Software Evolution; Graves TL, 2000, IEEE T SOFTWARE ENG, V26, P653, DOI 10.1109/32.859533; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hassan A., 2005, P 21 IEEE INT C SOFT; Hollander M, 1973, NONPARAMETRIC STAT M; KHOSHGOFTAAR TM, 2002, P 7 IEEE INT S HIGH; KHOSHGOFTAAR TM, 1992, IEEE T RELIAB, V41, P390, DOI 10.1109/24.159804; KNAB P, 2006, P INT WORKSH MIN SOF; Lanubile F, 1997, J SYST SOFTWARE, V38, P225, DOI 10.1016/S0164-1212(96)00153-7; MENZIES T, 2007, IEEE T SOFTWARE ENG, V32, P1; Moser R, 2007, P 19 INT C SOFTW ENG, P519; Nagappan N., 2005, P 27 INT C SOFTW ENG; Nagappan N., 2006, P 28 INT C SOFTW ENG; Ohlsson N, 1996, IEEE T SOFTWARE ENG, V22, P886, DOI 10.1109/32.553637; Ostrand TJ, 2005, IEEE T SOFTWARE ENG, V31, P340, DOI 10.1109/TSE.2005.49; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; RATZINGER J, 2007, P FUND APPR SOFTW EN, P12; SCHROTER A, 2006, SHORT PAPERS POSTERS, V2; SCHROTER A, 2006, P ACM IEEE 5 INT S E; Shull F., 2002, Proceedings Eighth IEEE Symposium on Software Metrics, DOI 10.1109/METRIC.2002.1011343; Subramanyam R, 2003, IEEE T SOFTWARE ENG, V29, P297, DOI 10.1109/TSE.2003.1191795; WEYUKER EJ, 2007, P 3 INT WORKSH PRED; Witten IH, 2005, DATA MINING PRACTICA; Zhou YM, 2006, IEEE T SOFTWARE ENG, V32, P771; Zimmermann T., 2004; Zimmermann T., 2007, P 3 INT WORKSH PRED	31	13	13	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0270-5257		978-1-4244-4486-1	PROC INT CONF SOFTW			2008							181	190		10.1145/1368088.1368114		10	Computer Science, Software Engineering	Computer Science	BKQ08	WOS:000268922500019	
J	Watson, P				Watson, Paul			Naive Bayes classification using 2D pharmacophore feature triplet vectors	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							BIOACTIVE REFERENCE STRUCTURES; AUTOMATED DOCKING; ACCURATE DOCKING; FLEXIBLE LIGANDS; LEARNING-METHODS; NEURAL-NETWORKS; MOLPRINT 2D; SIMILARITY; DATABASES; SHAPE	A naive Bayes classifier, employed in conjunction with 2D pharmacophore feature triplet vectors describing the molecules, is presented and validated. Molecules are described using a vector where each element in the vector contains the number of times a particular triplet of atom-based features separated by a set of topological distances occurs. Using the feature triplet vectors it is possible to generate naive Bayes classifiers that predict whether molecules are likely to be active against a given target (or family of targets). Two retrospective validation experiments were performed using a range of actives from WOMBAT, the Prous Integrity database, and the Arena screening library. The performance of the classifiers was evaluated using enrichment curves, enrichment factors, and the BEDROC metric. The classifiers were found to give significant enrichments for the various test sets.	[Watson, Paul] Arena Pharmaceut, San Diego, CA 92121 USA	Watson, P (reprint author), Arena Pharmaceut, 6166 Nancy Ridge Dr, San Diego, CA 92121 USA.	pwatson@arenapharm.com					Ballester PJ, 2007, J COMPUT CHEM, V28, P1711, DOI 10.1002/JCC.20681; Bazeley PS, 2006, J CHEM INF MODEL, V46, P2698, DOI 10.1021/ci600267k; Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Bender A, 2005, J BIOMOL SCREEN, V10, P658, DOI 10.1177/1087057105281048; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; Bender A, 2004, J MED CHEM, V47, P6569, DOI 10.1021/jm049611i; Bernazzani L, 2006, J CHEM INF MODEL, V46, P2030, DOI 10.1021/ci060104e; Bruno IJ, 1997, J COMPUT AID MOL DES, V11, P525, DOI 10.1023/A:1007934413448; Buontempo FV, 2005, J CHEM INF MODEL, V45, P904, DOI 10.1021/ci049652n; Byvatov E, 2004, J CHEM INF COMP SCI, V44, P993, DOI 10.1021/ci0342876; Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Ewing TJA, 2001, J COMPUT AID MOL DES, V15, P411, DOI 10.1023/A:1011115820450; Friesner RA, 2004, J MED CHEM, V47, P1739, DOI 10.1021/jm0306430; Goldman BB, 2006, ANN REP COMP CHEM, V2, P127, DOI 10.1016/S1574-1400(06)02008-1; GOOD AC, 1992, J COMPUT AID MOL DES, V6, P513, DOI 10.1007/BF00130401; Goodsell DS, 1996, J MOL RECOGNIT, V9, P1, DOI 10.1002/(SICI)1099-1352(199601)9:1<1::AID-JMR241>3.0.CO;2-6; Halgren TA, 2004, J MED CHEM, V47, P1750, DOI 10.1021/jm030644s; Hawkins PCD, 2007, J MED CHEM, V50, P74, DOI 10.1021/jm0603365; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; Jones G, 1997, J MOL BIOL, V267, P727, DOI 10.1006/jmbi.1996.0897; Li H, 2005, J CHEM INF MODEL, V45, P1376, DOI 10.1021/ci050135u; McGann MR, 2003, BIOPOLYMERS, V68, P76, DOI 10.1002/bip.10207; McGaughey GB, 2007, J CHEM INF MODEL, V47, P1504, DOI 10.1021/ci700052x; Morris GM, 1996, J COMPUT AID MOL DES, V10, P293, DOI 10.1007/BF00124499; Muller KR, 2005, J CHEM INF MODEL, V45, P249, DOI 10.1021/ci049737o; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Olah M., 2004, CHEMOINFORMATICS DRU, P223; Rarey M, 1996, J MOL BIOL, V261, P470, DOI 10.1006/jmbi.1996.0477; Rhodes N, 2003, J CHEM INF COMP SCI, V43, P443, DOI 10.1021/ci025605o; Rhodes N, 2006, J CHEM INF MODEL, V46, P615, DOI 10.1021/ci0503863; Rush TS, 2005, J MED CHEM, V48, P1489, DOI 10.1021/jm040163o; Schuffenhauer A, 2003, J CHEM INF COMP SCI, V43, P391, DOI 10.1021/ci025569t; Selzer P, 2006, J CHEM INF MODEL, V46, P2319, DOI 10.1021/ci0600657; Sun HM, 2005, J MED CHEM, V48, P4031, DOI 10.1021/jm050180t; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Taylor RD, 2002, J COMPUT AID MOL DES, V16, P151, DOI 10.1023/A:1020155510718; Truchon JF, 2007, J CHEM INF MODEL, V47, P488, DOI 10.1021/ci600426e; Vidal D, 2005, J CHEM INF MODEL, V45, P386, DOI 10.1021/ci0496797; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; WEININGER D, 1989, J CHEM INF COMP SCI, V29, P97, DOI 10.1021/ci00062a008; Willett P, 2006, DRUG DISCOV TODAY, V11, P1046, DOI 10.1016/j.drudis.2006.10.005; Willett P, 2005, J MED CHEM, V48, P4183, DOI 10.1021/jm0582165; Witten I.H., 2000, DATA MINING PRACTICA; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195	47	13	14	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	JAN	2008	48	1					166	178		10.1021/ci7003253		13	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	256FS	WOS:000252713700017	
J	Landwehr, N; Kersting, K; De Raedt, L				Landwehr, Niels; Kersting, Kristian; De Raedt, Luc			Integrating naive Bayes and FOIL	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						rule learning; naive Bayes; statistical relational learning; inductive logic programming		A novel relational learning approach that tightly integrates the naive Bayes learning scheme with the inductive logic programming rule-learner FOIL is presented. In contrast to previous combinations that have employed naive Bayes only for post-processing the rule sets, the presented approach employs the naive Bayes criterion to guide its search directly. The proposed technique is implemented in the NFOIL and TFOIL systems, which employ standard naive Bayes and tree augmented naive Bayes models respectively. We show that these integrated approaches to probabilistic model and rule learning outperform post-processing approaches. They also yield significantly more accurate models than simple rule learning and are competitive with more sophisticated ILP systems.	Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany; Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium	Landwehr, N (reprint author), Univ Freiburg, Dept Comp Sci, Georges Kohler Allee 79, D-79110 Freiburg, Germany.	LANDWEHR@INFORMATIK.UNI-FREIBURG.DE; KERSTING@INFORMATIK.UNI-FREIBURG.DE; LUC.DERAEDT@CS.KULEUVEN.BE					Blockeel H., 1997, LECT NOTES ARTIF INT, V1297, P77; Craven M, 2001, MACH LEARN, V43, P97, DOI 10.1023/A:1007676901476; DAVIS J, 2004, 3 WORKSH MULT DAT MI; Davis J, 2005, LECT NOTES ARTIF INT, V3720, P84; De Raedt L, 2004, LECT NOTES ARTIF INT, V3244, P19; Dehaspe L., 1997, LECT NOTES ARTIF INT, V1297, P109; DEHASPE L, 1998, P 4 INT C KNOWL DISC; DERAEDT L, 2003, ACM SIGKDD EXPLORATI, V5, P31, DOI 10.1145/959242.959247; DERAEDT L, 2004, P 9 INT C PRINC KNOW; Dzeroski S, 1998, APPL ARTIF INTELL, V12, P363, DOI 10.1080/088395198117686; Fang H, 2001, CHEM RES TOXICOL, V14, P280, DOI 10.1021/tx000208y; FAWCETT T, 1983, ROC GRAPHS NOTES PRA; Flach PA, 2004, MACH LEARN, V57, P233, DOI 10.1023/B:MACH.0000039778.69032.ab; Friedman N., 1996, P NATL C A1, V2, P1277; GETOOR L, 2007, IN PRESS STAT RELATI; Getoor L., 2001, RELATIONAL DATA MINI; Grossman D., 2004, P 21 INT C MACH LEAR, P361; KING RD, 1995, NEW GENERAT COMPUT, V13, P411; KROGEL MA, 2001, P 11 INT C IND LOG P, V2157; Landwehr N., 2005, P 20 NAT C ART INT A, P795; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Muggleton S., 1996, ADV INDUCTIVE LOGIC; Muggleton S., 1990, P 1 C ALG LEARN THEO, P368; MUGGLETON S, 1994, J LOGIC PROGRAM, V20, P629; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Neville J., 2003, P 3 IEEE INT C DAT M, P609; Perlich C, 2006, MACH LEARN, V62, P65, DOI 10.1007/s10994-006-6064-1; POMPE U, 1997, LECT NOTES COMPUTER, V1297, P235; Pompe Uros, 1995, P 5 INT WORKSH IND L, P417; POPESCUL A, 2003, P 3 IEEE INT C DAT M, P275; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; RPOVOST FJ, 1998, P 15 INT C MACH LEAN; Srinivasan A, 1996, ARTIF INTELL, V85, P277, DOI 10.1016/0004-3702(95)00122-0; SRINIVASAN A, 1999, LECT NOTES COMPUTER, V1634; Taskar B., 2001, P 17 INT JOINT C ART, P870; Witten I.H., 2000, DATA MINING PRACTICA	37	13	16	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAR	2007	8						481	507				27	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	175GV	WOS:000247002700004	
J	Airoldi, EM; Anderson, AG; Fienberg, SE; Skinner, KK				Airoldi, Edoardo M.; Anderson, Annelise G.; Fienberg, Stephen E.; Skinner, Kiron K.			Who Wrote Ronald Reagan's Radio Addresses?	BAYESIAN ANALYSIS			English	Article						Ronald Reagan; Radio Addresses; Authorship; Stylometry; Data Mining; Classification; Function Words; Semantic Analysis; Naive Bayes; Full Bayes; Poisson; Negative-Binomial; Modal Approximation; Mean Approximation		In his campaign for the U. S. presidency from 1975 to 1979, Ronald Reagan delivered over 1000 radio broadcasts. For over 600 of these we have direct evidence of Reagan's authorship. The aim of this study was to determine the authorship of 312 of the broadcasts for which no direct evidence is available. We addressed the prediction problem for speeches delivered in different epochs and we explored a wide range of off-the-shelf classification methods and fully Bayesian generative models. Eventually we produced separate sets of predictions using the most accurate classifiers, based on non-contextual words as well as on semantic features, for the 312 speeches of uncertain authorship. All the predictions agree on 135 of the "unknown" speeches, whereas the fully Bayesian models agree on an additional 154 of them. The magnitude of the posterior odds of authorship led us to conclude that Ronald Reagan drafted 167 speeches and was aided in the preparation of the remaining 145. Our inferences were not sensitive to "reasonable" variations in the sets of constants underlying the prior distributions, and the cross-validated accuracy of our best fully Bayesian model was above 90 percent in all cases. The agreement of multiple methods for predicting the authorship for the "unknown" speeches reinforced our confidence in the accuracy of our classifications.	[Airoldi, Edoardo M.; Fienberg, Stephen E.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; [Anderson, Annelise G.] Stanford Univ, Hoover Inst, Stanford, CA 94305 USA; [Fienberg, Stephen E.] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA; [Skinner, Kiron K.] Carnegie Mellon Univ, Dept Hist, Pittsburgh, PA 15213 USA; [Skinner, Kiron K.] Carnegie Mellon Univ, Dept Social & Decis Sci, Pittsburgh, PA 15213 USA	Airoldi, EM (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.		Airoldi, Edoardo/A-8575-2009				AIROLDI EM, 2006, LECT NOTES IN PRESS; AIROLDI EM, 2003, CMUSTAT03789; AIROLDI EM, 2005, P CLASS SOC N AM INT; Beeferman D., 1997, P 35 ANN M ASS COMP, P373; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Bishop YM, 1975, DISCRETE MULTIVARIAT; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 1984, CLASSIFICATION REGRE; Burrows J. F., 1992, Literary & Linguistic Computing, V7, DOI 10.1093/llc/7.2.91; Church K.W., 1995, P 18 ANN INT ACM SIG, P310, DOI 10.1145/215206.215376; COLLINS J, 2001, DOCU SCOPE JAVA APPL; DAWES R, 1976, 5 OR RES I; de Morgan Augustus, 1872, BUDGET PARADOXES; Efron B., 1998, INTRO BOOTSTRAP; Erosheva E, 2004, P NATL ACAD SCI USA, V101, P5220, DOI 10.1073/pnas.0307760101; Erosheva EA, 2005, STUD CLASS DATA ANAL, P11, DOI 10.1007/3-540-28084-7_2; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Hoel P., 1954, INTRO MATH STAT; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Johnson N. L., 1992, UNIVARIATE DISCRETE; Mendenhall T. C., 1887, SCIENCE, V9, P237; MILLER GA, 1954, ANNU REV PSYCHOL, P137; Mitchell T.M., 1997, MACHINE LEARNING; Mosteller F., 1964, INFERENCE DISPUTED A; Mosteller F., 1984, APPL BAYESIAN CLASSI; MOSTELLER F, 1968, HDB SOCIAL PSYCHOL, V1, P80; Ripley B., 1996, PATTERN RECOGNITION; SIMON HA, 1955, BIOMETRIKA, V42, P425; Skinner Kiron K., 2004, REAGANS PATH VICTORY; SKINNER KK, 2001, STORIES HIS OWN HAND; Skinner K.K., 2001, REAGAN HIS OWN HAND; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Wasserman L., 2004, ALL STAT; Welch BL, 1938, BIOMETRIKA, V29, P350, DOI 10.2307/2332010; YULE UG, 1944, STAT STUDY LIT VOCAB; Zhai C., 2001, P 24 ANN INT ACM SIG, P334, DOI DOI 10.1145/383952.384019; ZIPF G K, 1932, SELECTED STUDIES PRI	38	13	13	INT SOC BAYESIAN ANALYSIS	PITTSBURGH	CARNEGIE MELLON UNIV, DEPT STTISTICS, PITTSBURGH, PA 15213 USA	1931-6690			BAYESIAN ANAL	Bayesian Anal.		2006	1	2					289	319				31	Mathematics, Interdisciplinary Applications; Statistics & Probability	Mathematics	V10EI	WOS:000207446900006	
S	Livadas, C; Walsh, R; Lapsley, D; Strayer, WT		Elmallah, E; Christensen, K; Frank, M		Livadas, Carl; Walsh, Robert; Lapsley, David; Strayer, W. Timothy			Using machine learning techniques to identify botnet traffic	31st IEEE Conference on Local Computer Networks, Proceedings	PROCEEDINGS - CONFERENCE ON LOCAL COMPUTER NETWORKS		English	Proceedings Paper	31st Annual IEEE Conference on Local Computer Networks	NOV 14-16, 2006	Tampa, FL	Univ S Florida, Univ Bonn, Univ New S Wales, BBN Technologies, Nokia, IEEE Comp Soc				To date, techniques to counter cyber-attacks have predominantly been reactive; they focus on monitoring network traffic, detecting anomalies and cyber-attack traffic patterns, and, a posteriori, combating the cyber-attacks and mitigating their effects. Contrary to such approaches, we advocate proactively detecting and identifying botnets prior to their being used as part of a cyber-attack [12]. In this paper, we present our work on using machine learning-based classification techniques to identify the command and control (C2) traffic of IRC-based botnets - compromised hosts that are collectively commanded using Internet Relay Chat (IRC). We split this task into two stages: (I) distinguishing between IRC and non-IRC traffic, and (II) distinguishing between botnet and real IRC traffic. For Stage I, we compare the performance of J48, naive Bayes, and Bayesian network classifiers, identify the features that achieve good overall classification accuracy, and determine the classification sensitivity to the training set size. While sensitive to the training data and the attributes used to characterize communication flows, machine learning-based classifiers show promise in identifying IRC traffic. Using classification in Stage II is trickier, since accurately labeling IRC traffic as botnet and non-botnet is challenging. We are currently exploring labeling flows as suspicious and non-suspicious based on telltales of hosts being compromised.								DEWES C, 2003, IMC 03, P51; Duda R.O., 2001, PATTERN CLASSIFICATI; Henderson T., 2004, P 10 ANN INT C MOB C, P187, DOI 10.1145/1023720.1023739; Holz T, 2005, IEEE SECUR PRIV, V3, P76, DOI 10.1109/MSP.2005.58; Levy E., 2003, IEEE Security & Privacy, V1, DOI 10.1109/MSECP.2003.1219071; McCarty B., 2003, IEEE Security & Privacy, V1, DOI 10.1109/MSECP.2003.1219079; McCarty B., 2003, IEEE Security & Privacy, V1, DOI 10.1109/MSECP.2003.1236244; Moore A.W., 2005, SIGMETRICS 05, P50; Roughan M., 2004, IMC 04, P135; Sen S., 2004, WWW 04, P512; STRAYER WT, 2006, IN PRESS 31 IEEE C L; Witten IH, 2005, DATA MINING PRACTICA; 2004, KNOW YOUR ENEMY LEAR	13	13	13	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0742-1303		978-1-4244-0418-6	CONF LOCAL COMPUT NE			2006							967	974				8	Telecommunications	Telecommunications	BFQ41	WOS:000243785600140	
B	Zhao, WQ; Zhang, ZL		Tarumi, H; Li, Y; Yoshida, T		Zhao, WQ; Zhang, ZL			An email classification model based on rough set theory	Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005)			English	Proceedings Paper	3rd International Conference on Active Media Technology	MAY 19-21, 2005	Takamatsu, JAPAN	IEEE Syst, Man & Cybernet Soc, Informat Proc Soc Japan, Kagawa Univ			CATEGORIZATION	The communication via email is one of the most popular services of the Internet. Emails have brought us great convenience in our daily work and life. However, unsolicited messages or spam, flood our email boxes, which results in bandwidth, time and money wasting. To this end, this paper presents a rough set based model to classify emails into three categories - spam, no-spam and suspicious, rather than two classes (spam and nonspam) in most currently used approaches. By comparing with popular classification methods like Naive Bayes classification, the error ratio that a non-spam is discriminated to spam can be reduced using our proposed model.	N China Elect Power Univ, Sch Comp Sci & Technol, Baoding 071003, Peoples R China	Zhao, WQ (reprint author), N China Elect Power Univ, Sch Comp Sci & Technol, Baoding 071003, Peoples R China.						Clack C., 1997, Proceedings of the First International Conference on Autonomous Agents, DOI 10.1145/267658.267716; Cohen W., 1996, P AAAI SPRING S MACH; Cristianini N., 2000, INTRO SUPPORT VECTOR; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Jensen R., 2001, LNCS, V2198, P95; Lambert-Torres G., 1999, ROUGH FUZZY HYBRIDIZ, P263; Mitchell T.M., 1997, MACHINE LEARNING; OHM A, 1999, 1999133 NTNU; Pal S.K., 1999, ROUGH FUZZY HYBRIDIZ; PANTEL P, 1998, LEARN TEXT CAT PAP A; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; SAHAMI M, 1998, LEARN TEXT CAT PAP 1; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Skowron A, 1999, LECT NOTES ARTIF INT, V1704, P107; Spertus E., 1997, P INN APPL ART INT I, P1058; WITTEN I, 2000, DATA MINING PRACTICA, P235; WRBLEWSKI J, 1995, P 2 ANN JOINT C INF, P186; ZHANG L, 2003, P 20 INT C COMP PROC, P446; Zhang Lian-hua, 2004, J Zhejiang Univ Sci, V5, P1076, DOI 10.1631/jzus.2004.1076	20	13	13	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9035-0				2005							403	408				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BCR76	WOS:000230959600094	
S	Zhang, H; Su, J		Boulicaut, JF; Esposito, F; Giannoti, F; Pedreschi, D		Zhang, H; Su, J			Naive Bayesian classifiers for ranking	MACHINE LEARNING: ECML 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	15th European Conference on Machine Learning/8th European Conference on Principles and Practice of Knowledge Discovery in Databases	SEP 20-24, 2004	Pisa, ITALY	KDNet, Pascal Network, Kluwer & Mach Learning Journal, Springer, Municipal Pisa, Microsoft Res, COOP, Exeura, INSA-Lyon, ISTI-Cnr, Univ Pisa, Univ Bari, Reg Toscana			ROC CURVE; AREA	It is well-known that native Baves verforms surprisingly well in classification, but its probability estimation is poor. In many applications, however, a ranking based on class probabilities is desired. For example, a ranking of customers in terms of the likelihood that they buy one's products is useful in direct marketing. What is the general performance of naive Bayes in ranking? In this paper, we study it by both empirical experiments and theoretical analysis. Our experiments show that naive Bayes outperforms C4.4, the most state-of-the-art decision-tree algorithm for ranking. We study two example problems that have been used in analyzing the performance of naive Bayes in classification [3]. Surprisingly, naive Bayes performs perfectly on them in ranking, even though it does not in classification. Finally, we present and prove a sufficient condition for the optimality of naive Bayes in ranking.	Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Zhang, H (reprint author), Univ New Brunswick, Fac Comp Sci, POB 4400, Fredericton, NB E3B 5A3, Canada.	hzhang@unb.ca					Bennett P. N., 2000, CMUCS00155; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Ferri C., 2002, P 19 INT C MACH LEAR, P139; Franks MM, 2001, GERONTOLOGIST, V41, P5; FRIEDMAN N, 1997, MACH LEARN, V29, P103; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; KONONENKO I, 1990, CURRENT TRNEDS KNOWL; Lachiche N., 2003, P 20 INT C MACH LEAR, P416; Ling C.X., 2003, P 20 INT C MACH LEAR, P480; Ling CX, 2003, P 18 INT C ART INT I, P329; Merz C., 1997, UCI REPOSITORY MACHI; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; PROBOST F, 1997, P 3 INT C KNOWL DISC, P43; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Provost F., 1998, P 15 INT C MACH LEAR, P445; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Witten I.H., 2000, DATA MINING PRACTICA; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609	20	13	13	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23105-6	LECT NOTES COMPUT SC			2004	3201						501	512				12	Computer Science, Artificial Intelligence	Computer Science	BAX02	WOS:000223999500046	
J	Liu, JNK; Li, BNL; Dillon, TS				Liu, JNK; Li, BNL; Dillon, TS			An improved Naive Bayesian classifier technique coupled with a novel input solution method	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						data mining; genetic algorithm (GA); improved Naive Bayes classification (INCB); rainfall prediction	FUZZY	Data mining is the study of how to determine underlying patterns in the data to help make optimal decisions on computers when the database involved is voluminous, hard to characterize accurately, and constantly changing. It deploys techniques based on machine learning, alongside the conventional methods. More importantly, these techniques can generate decision or prediction models, based on the actual historical data. Therefore, they represent true evidence-based decision support. Rainfall prediction is a good problem to solve by these data mining techniques. This paper proposes an improved Naive Bayes classifier (INCB) technique and explores the use of genetic algorithms (GAs) for selection of a subset of input features in classification problems. It then carries out a comparison with several other techniques. It sets a comparison of the following algorithms, namely: 1) genetic algorithm with average classification or general classification (GA-AC, GA-C), 2) C4.5 with pruning, and 3) INBC with relative frequency or initial probability density (INBC-RF, INBC-IPD) on the real meteorological data in Hong Kong. Two simple schemes are proposed to construct a suitable data set for improving the performance. Scheme I uses all basic input parameters for rainfall prediction. Scheme II uses the optimal subset of input variables which are selected by a GA. The results show that among the methods we compared, INBC achieved about 90% accuracy rate on the rain/no-rain (Rain) classification problems. This method also attained reasonable performance on rainfall prediction with three-level depth (Depth3) and five-level depth (Depth5), which are around 65%-70%.	Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China	Liu, JNK (reprint author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.						Anderson JA, 1990, NEUROCOMPUTING; BUNTINE W, 1989, P 6 INT WORKSH MACH, P94; Cestnik B, 1990, P EUR C ART INT, P147; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P1; CHUNG CC, 1993, NEURAL COMPUT APPL, P215; Fung GSK, 1997, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I - III, P441, DOI 10.1109/FUZZY.1997.616408; Good I, 1965, ESTIMATION PROBABILI; Hunt E B, 1996, EXPT INDUCTION; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Langley P., 1992, P 10 NAT C ART INT, P223; LAWRENCE J, 1991, AI EXPERT        NOV, P34; Lee RST, 1999, INT J PATTERN RECOGN, V13, P1251, DOI 10.1142/S0218001499000719; LEE RST, 2000, STUDIES FUZZINESS SO, P31; LI B, 1998, INT J COMPUT INF SCI, V22, P351; LIU JNK, 1998, P ICONIP JNNS 98 KIT, P275; LIU JNK, 1996, P INT C NIP, V2, P787; Liu JNK, 1999, INT SER COMPUTAT INT, P121; *NEUR INC, 1995, NEUR PRED COMPL SOL; *NEUR INT BUS SOFT, 1994, NEUR US GUID; PAL S.K., 1996, GENETIC ALGORITHMS P; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; *ROHK, 1987, SURF OBS HONG KONG; *ROHK, 1984, SURF OBS HONG KONG; STEIN R, 1993, AI EXPERT        FEB, P42; STEIN R, 1993, AI EXPERT        MAR, P32; Tanaka Y., 1993, P WESCON SAN FRANC C, P446, DOI 10.1109/WESCON.1993.488475; TRIVEDI KS, 1982, PROBABILITY STAT REL, P469; TURKSEN IB, 1997, P IEEE INT C SMC ORL, P2975; WONG AKC, 1987, IEEE T PATTERN ANAL, V9, P796	29	13	14	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1094-6977			IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	MAY	2001	31	2					249	256		10.1109/5326.941848		8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	464GY	WOS:000170525900011	
J	Huber, MB; Nagarajan, MB; Leinsinger, G; Eibel, R; Ray, LA; Wismuller, A				Huber, Markus B.; Nagarajan, Mahesh B.; Leinsinger, Gerda; Eibel, Roger; Ray, Lawrence A.; Wismueller, Axel			Performance of topological texture features to classify fibrotic interstitial lung disease patterns	MEDICAL PHYSICS			English	Article						texture analysis; quantitative image analysis; lung high-resolution CT; supervised learning	HIGH-RESOLUTION CT; COMPUTER-AIDED DIAGNOSIS; AUTOMATED CLASSIFICATION; MINKOWSKI-FUNCTIONALS; MULTIDETECTOR CT; TRABECULAR BONE; PROXIMAL FEMUR; ARCHITECTURE; TOMOGRAPHY; TISSUE	Purpose: Topological texture features were compared in their ability to classify "honeycombing," a morphological pattern that is considered indicative for the presence of fibrotic interstitial lung disease in high-resolution computed tomography (HRCT) images. Methods: For 14 patients with known occurrence of honeycombing, a stack of 70 axial, lung kernel reconstructed images was acquired from HRCT chest exams. A set of 964 regions of interest of both healthy and pathological (356) lung tissue was identified by an experienced radiologist. Texture features were extracted using statistical features (Stat), six properties calculated from gray-level co-occurrence matrices (GLCMs), Minkowski dimensions (MDs), and three Minkowski functionals (MFs) (e.g., MF.Euler). A naive Bayes (NB) and k-nearest-neighbor (k-NN) classifier, a multilayer radial basis functions network (RBFN), and a support vector machine with a radial basis function (SVMrbf) kernel were optimized in a tenfold cross-validation for each texture vector, and the classification accuracy was calculated on independent test sets as a quantitative measure of automated tissue characterization. A Wilcoxon signed-rank test was used to compare two accuracy distributions and the significance thresholds were adjusted for multiple comparisons by the Bonferroni correction. Results: The best classification results were obtained by the MF features, which performed significantly better than all the standard Stat, GLCM, and MD features (p<0.001) for both classifiers. The highest accuracies were found for MF. Euler (93.6%, 94.9%, 94.2%, and 95.0% for NB, k-NN, RBFN, and SVMrbf, respectively). The best groups of standard texture features were a Stat and GLCM ("homogeneity") feature set (up to 91.8%). Conclusions: The results indicate that advanced topological texture features derived from MFs can provide superior classification performance in computer-assisted diagnosis of fibrotic interstitial lung disease patterns when compared to standard texture analysis methods. (C) 2011 American Association of Physicists in Medicine. [DOI: 10.1118/1.3566070]	[Huber, Markus B.; Nagarajan, Mahesh B.; Wismueller, Axel] Univ Rochester, Dept Imaging Sci, Rochester, NY 14627 USA; [Huber, Markus B.; Nagarajan, Mahesh B.; Wismueller, Axel] Univ Rochester, Dept Biomed Engn, Rochester, NY 14627 USA; [Leinsinger, Gerda; Wismueller, Axel] Univ Munich, Dept Radiol, D-80336 Munich, Germany; [Eibel, Roger] Helios Kliniken, Dept Radiol, D-19049 Schwerin, Germany; [Ray, Lawrence A.] Carestream Hlth Inc, Rochester, NY 14615 USA	Huber, MB (reprint author), Univ Rochester, Dept Imaging Sci, 601 Elmwood Ave, Rochester, NY 14627 USA.	mbh@bme.rochester.edu			Upstate New York Translational Research Network (UNYTRN) of the Clinical and Translational Science Institute (CTSI), University of Rochester [5-28527]; Center for Emerging and Innovative Sciences (CEIS), a NYSTAR-designated Center for Advanced Technology; Carestream Health, Inc., Rochester, NY	This research was funded, in part, by the Clinical and Translational Science Award No. 5-28527 within the Upstate New York Translational Research Network (UNYTRN) of the Clinical and Translational Science Institute (CTSI), University of Rochester, by the Center for Emerging and Innovative Sciences (CEIS), a NYSTAR-designated Center for Advanced Technology, and by Carestream Health, Inc., Rochester, NY. The authors thank Professor M. F. Reiser, FACR, FRCR, from the Department of Radiology, University of Munich, Germany, for his support.	ANYS H, 1995, IEEE T GEOSCI REMOTE, V33, P1170, DOI 10.1109/36.469481; Baum T, 2010, OSTEOPOROSIS INT, V21, P1553, DOI 10.1007/s00198-009-1090-z; Boehm H, 2006, P SOC PHOTO-OPT INS, V6144, pX1446, DOI 10.1117/12.650469; Boehm H, 2008, EUR RADIOL, V18, P2745, DOI 10.1007/s00330-008-1082-y; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Depeursinge A, 2010, J DIGIT IMAGING, V23, P18, DOI 10.1007/s10278-008-9158-4; Duda R. O., 2000, PATTERN CLASSIFICATI; Hadwiger H., 1957, VORLESUNGEN INHALT O; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Huber MB, 2009, MED PHYS, V36, P5089, DOI 10.1118/1.3215535; HUBER MB, 2010, MED IMAGING 2010 COM, V7624; Jiang C, 1999, MED BIOL ENG COMPUT, V37, P413, DOI 10.1007/BF02513322; Jiang CS, 1999, MED PHYS, V26, P872, DOI 10.1118/1.598604; King TE, 2005, AM J RESP CRIT CARE, V172, P268, DOI 10.1164/rccm.200503-483OE; Korfiatis P, 2008, MED PHYS, V35, P5290, DOI 10.1118/1.3003066; Korfiatis PD, 2010, IEEE T INF TECHNOL B, V14, P675, DOI 10.1109/TITB.2009.2036166; MARAGOS P, 1994, ADV ELECTRON EL PHYS, V88, P199; MECKE KR, 1991, J STAT PHYS, V64, P843, DOI 10.1007/BF01048319; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Michielsen K., 2001, Physics Reports, V347, DOI 10.1016/S0370-1573(00)00106-X; Raeth CW, 2006, P SOC PHOTO-OPT INS, V6144, pC1440, DOI 10.1117/12.653129; Sluimer I, 2006, IEEE T MED IMAGING, V25, P385, DOI 10.1109/TMI.2005.862753; Sluimer IC, 2003, MED PHYS, V30, P3081, DOI 10.1118/1.1624771; Sluimer IC, 2006, MED PHYS, V33, P2610, DOI 10.1118/1.2207131; Tourassi GD, 2001, MED PHYS, V28, P2394, DOI 10.1118/1.1418724; Uchiyama Y, 2003, MED PHYS, V30, P2440, DOI 10.1118/1.1597431; Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648; Webb WR, 2009, HIGH RESOLUTION CT L; WRIGHT SP, 1992, BIOMETRICS, V48, P1005, DOI 10.2307/2532694	30	12	12	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405			MED PHYS	Med. Phys.	APR	2011	38	4					2035	2044		10.1118/1.3566070		10	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	745GI	WOS:000289153500030	
J	Wang, G; Hao, JX; Ma, JA; Huang, LH				Wang, Gang; Hao, Jinxing; Ma, Jian; Huang, Lihua			A new approach to intrusion detection using Artificial Neural Networks and fuzzy clustering	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Intrusion detection systems; Artificial Neural Networks; Fuzzy clustering	IDS	Many researches have argued that Artificial Neural Networks (ANNs) can improve the performance of intrusion detection systems (IDS) when compared with traditional methods. However for ANN-based IDS, detection precision, especially for low-frequent attacks, and detection stability are still needed to be enhanced. In this paper, we propose a new approach, called FC-ANN, based on ANN and fuzzy clustering, to solve the problem and help IDS achieve higher detection rate, less false positive rate and stronger stability. The general procedure of FC-ANN is as follows: firstly fuzzy clustering technique is used to generate different training subsets. Subsequently, based on different training subsets, different ANN models are trained to formulate different base models. Finally, a meta-learner, fuzzy aggregation module, is employed to aggregate these results. Experimental results on the KDD CUP 1999 dataset show that our proposed new approach, FC-ANN, outperforms BPNN and other well-known methods such as decision tree, the naive Bayes in terms of detection precision and detection stability. (C) 2010 Elsevier Ltd. All rights reserved.	[Wang, Gang; Hao, Jinxing; Ma, Jian] City Univ Hong Kong, Dept Informat Syst, Kowloon, Hong Kong, Peoples R China; [Wang, Gang; Huang, Lihua] Fudan Univ, Sch Management, Shanghai 200433, Peoples R China; [Hao, Jinxing] Beihang Univ, Sch Econ & Management, Beijing 100083, Peoples R China	Wang, G (reprint author), City Univ Hong Kong, Dept Informat Syst, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.	wgedison@gmail.com	Hao, Jin-xing/E-9066-2010		Innovation and Technology Fund (ITF) of HK [GHP/006/07, InP/007/08]	The authors would like to thank the Editor-in-Chief and reviewers for their recommendation and comments. This work is partially supported by the grants from the Innovation and Technology Fund (ITF) of HK (GHP/006/07, InP/007/08).	Anderson J, 1995, INTRO NEURAL NETWORK; Anderson James P., 1980, COMPUTER SECURITY TH; Axelsson S., 2000, ACM Transactions on Information and Systems Security, V3, DOI 10.1145/357830.357849; BARBARA D, 2001, P 1 SIAM C DAT MIN C, P1; Beghdad R, 2008, COMPUT SECUR, V27, P168, DOI 10.1016/j.cose.2008.06.001; Bezdek JC, 1973, THESIS CORNELL U ITH; Chen YH, 2007, INT J INTELL SYST, V22, P337, DOI 10.1002/int.20203; Chiu S. L., 1994, J INTELL FUZZY SYST, V2, P267; Depren O, 2005, EXPERT SYST APPL, V29, P713, DOI 10.1016/j.eswa.2005.05.002; Dokas Paul, 2002, P NSF WORKSH NEXT GE, P21; Endorf C., 2004, INTRUSION DETECTION; GORDEEV M, 2000, INTRUSION DETECTION; Han SJ, 2006, IEEE T SYST MAN CY B, V36, P559, DOI 10.1109/TSMCB.2005.860136; Haykin S., 1999, NEURAL NETWORKS COMP; HOREIS T, 2003, INTRUSION DETECTION; Jirapummin C., 2002, P INT TECHN C CIRC S, P928; Joo D, 2003, EXPERT SYST APPL, V25, P69, DOI 10.1016/S0957-4174(03)00007-1; KEVIN LF, 1990, P 13 NAT COMP SEC C, P125; LINDQVIST U, 1999, IEEE S SEC PRIV, P146; Manikopoulos C, 2002, IEEE COMMUN MAG, V40, P76, DOI 10.1109/MCOM.2002.1039860; Mukkamala S, 2002, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2002.1007774; Mukkamala S.A., 2004, P 6 INT C ENT INF SY, P26; Patcha A, 2007, COMPUT NETW, V51, P3448, DOI 10.1016/j.comnet.2007.02.001; QIN M, 2004, P 13 USENIX SEC S, P456; Ryan J., 1998, ADV NEURAL INFORM PR, V10; Shyu M., 2003, P IEEE FDN NEW DIR D, P172; Silva LD, 2008, EXPERT SYST APPL, V34, P2326, DOI 10.1016/j.eswa.2007.03.011; TAN K, 1995, P IEEE INT C NEUR NE, V7, P476; TAYLOR C, 2001, P NEW SEC PAR WORKSH, P1; Witten IH, 2005, DATA MINING PRACTICA; Wu SY, 2009, EXPERT SYST APPL, V36, P5605, DOI 10.1016/j.eswa.2008.06.138; YAGER RR, 1994, IEEE T SYST MAN CYB, V24, P1279, DOI 10.1109/21.299710; 1999, KDD CUP 1999 DATASET	33	12	13	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	SEP	2010	37	9					6225	6232		10.1016/j.eswa.2010.02.102		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	606KT	WOS:000278424600012	
J	Wan, YW; Sabbagh, E; Raese, R; Qian, Y; Luo, DJ; Denvir, J; Vallyathan, V; Castranova, V; Guo, NL				Wan, Ying-Wooi; Sabbagh, Ebrahim; Raese, Rebecca; Qian, Yong; Luo, Dajie; Denvir, James; Vallyathan, Val; Castranova, Vincent; Guo, Nancy Lan			Hybrid Models Identified a 12-Gene Signature for Lung Cancer Prognosis and Chemoresponse Prediction	PLOS ONE			English	Article							GENE-EXPRESSION; BREAST-CANCER; CELL; ADENOCARCINOMA; SURVIVAL; PROFILES; SET	Background: Lung cancer remains the leading cause of cancer-related deaths worldwide. The recurrence rate ranges from 35-50% among early stage non-small cell lung cancer patients. To date, there is no fully-validated and clinically applied prognostic gene signature for personalized treatment. Methodology/Principal Findings: From genome-wide mRNA expression profiles generated on 256 lung adenocarcinoma patients, a 12-gene signature was identified using combinatorial gene selection methods, and a risk score algorithm was developed with Naive Bayes. The 12-gene model generates significant patient stratification in the training cohort HLM & UM (n = 256; log-rank P = 6.96e-7) and two independent validation sets, MSK (n = 104; log-rank P = 9.88e-4) and DFCI (n = 82; log-rank P = 2.57e-4), using Kaplan-Meier analyses. This gene signature also stratifies stage I and IB lung adenocarcinoma patients into two distinct survival groups (log-rank P<0.04). The 12-gene risk score is more significant (hazard ratio = 4.19, 95% CI: [2.08, 8.46]) than other commonly used clinical factors except tumor stage (III vs. I) in multivariate Cox analyses. The 12-gene model is more accurate than previously published lung cancer gene signatures on the same datasets. Furthermore, this signature accurately predicts chemoresistance/chemosensitivity to Cisplatin, Carboplatin, Paclitaxel, Etoposide, Erlotinib, and Gefitinib in NCl-60 cancer cell lines (P<0.017). The identified 12 genes exhibit curated interactions with major lung cancer signaling hallmarks in functional pathway analysis. The expression patterns of the signature genes have been confirmed in RT-PCR analyses of independent tumor samples. Conclusions/Significance: The results demonstrate the clinical utility of the identified gene signature in prognostic categorization. With this 12-gene risk score algorithm, early stage patients at high risk for tumor recurrence could be identified for adjuvant chemotherapy; whereas stage I and II patients at low risk could be spared the toxic side effects of chemotherapeutic drugs.	[Wan, Ying-Wooi; Sabbagh, Ebrahim; Raese, Rebecca; Luo, Dajie; Denvir, James; Guo, Nancy Lan] W Virginia Univ, Mary Babb Randolph Canc Ctr, Morgantown, WV 26506 USA; [Qian, Yong; Vallyathan, Val; Castranova, Vincent] NIOSH, Pathol & Physiol Res Branch, Hlth Effects Lab Div, Morgantown, WV USA	Wan, YW (reprint author), W Virginia Univ, Mary Babb Randolph Canc Ctr, Morgantown, WV 26506 USA.	lguo@hsc.wvu.edu			NIH/NLM [R01LM009500]; NCRR [P20RR16440]; NIH/NCRR [P2016477]	This study is supported by NIH/NLM R01LM009500 (PI: Guo) and NCRR P20RR16440 and Supplement (PD: Guo). The software license and training for IPA and Pathway Studio was supported by NIH/NCRR P2016477. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	American Cancer Society, 2005, CANC FACTS FIG 2005; Baker Stuart G, 2002, BMC Med Res Methodol, V2, P4, DOI 10.1186/1471-2288-2-4; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bild AH, 2006, NATURE, V439, P353, DOI 10.1038/nature04296; Borczuk AC, 2005, AM J RESP CRIT CARE, V172, P729, DOI 10.1164/rccm.200504-615OC; Boutros PC, 2009, P NATL ACAD SCI USA, V106, P2824, DOI 10.1073/pnas.0809444106; Chen HY, 2007, NEW ENGL J MED, V356, P11, DOI 10.1056/NEJMoa060096; Dalton WS, 2006, SCIENCE, V312, P1165, DOI 10.1126/science.1125948; Emir B, 1998, STAT MED, V17, P2563, DOI 10.1002/(SICI)1097-0258(19981130)17:22<2563::AID-SIM952>3.0.CO;2-O; Guo L, 2006, CLIN CANCER RES, V12, P3344, DOI 10.1158/1078-0432.CCR-05-2336; Guo NL, 2008, CLIN CANCER RES, V14, P8213, DOI 10.1158/1078-0432.CCR-08-0095; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hoffman PC, 2000, LANCET, V355, P479, DOI 10.1016/S0140-6736(00)82038-3; Hood L, 2004, SCIENCE, V306, P640, DOI 10.1126/science.1104635; Ikediobi ON, 2006, MOL CANCER THER, V5, P2606, DOI 10.1158/1535-7163.MCT-06-0433; Lau SK, 2007, J CLIN ONCOL, V25, P5562, DOI 10.1200/JCO.2007.12.0352; Livak KJ, 2001, METHOD METHODS, V25, P402; Lu Y, 2006, PLOS MED, V3, P2229, DOI 10.1371/journal.pmed.0030467; Ma Y, 2006, CLIN CANCER RES, V12, P4583, DOI 10.1158/1078-0432.CCR-06-0290; MA Y, 2009, INT J ONCOL, P107; MITCHELL TM, 1997, MACH LEARN, P413; NARUKE T, 1988, J THORAC CARDIOV SUR, V96, P440; Paik S, 2004, NEW ENGL J MED, V351, P2817, DOI 10.1056/NEJMoa041588; Pepe MS, 2004, AM J EPIDEMIOL, V159, P882, DOI 10.1093/aje/kwh101; Potti A, 2006, NEW ENGL J MED, V355, P570, DOI 10.1056/NEJMoa060467; Raponi M, 2006, CANCER RES, V66, P7466, DOI 10.1158/0008-5472.CAN-06-1191; Shankavaram UT, 2007, MOL CANCER THER, V6, P820, DOI 10.1158/1535-7163.MCT-06-0650; Shedden K, 2008, NAT MED, V14, P822, DOI 10.1038/nm.1790; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Subramanian J, 2010, J NATL CANCER I, V102, P464, DOI 10.1093/jnci/djq025; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Witten IH, 2005, DATA MINING PRACTICA; Wu ZJ, 2004, J AM STAT ASSOC, V99, P909, DOI 10.1198/016214504000000683	36	12	14	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203			PLOS ONE	PLoS One	AUG 17	2010	5	8							e12222	10.1371/journal.pone.0012222		15	Multidisciplinary Sciences	Science & Technology - Other Topics	639II	WOS:000280968100021	
J	Kotsiantis, S; Patriarcheas, K; Xenos, M				Kotsiantis, S.; Patriarcheas, K.; Xenos, M.			A combinational incremental ensemble of classifiers as a technique for predicting students' performance in distance education	KNOWLEDGE-BASED SYSTEMS			English	Article						Educational data mining; Online learning algorithms; Classifiers; Voting methods	BAYESIAN NETWORKS	The ability to predict a student's performance could be useful in a great number of different ways associated with university-level distance learning. Students' marks in a few written assignments can constitute the training set for a supervised machine learning algorithm. Along with the explosive increase of data and information, incremental learning ability has become more and more important for machine learning approaches. The online algorithms try to forget irrelevant information instead of synthesizing all available information (as opposed to classic batch learning algorithms) Nowadays, combining classifiers is proposed as a new direction for the improvement of the classification accuracy. However, most ensemble algorithms operate in batch mode. Therefore a better proposal is an online ensemble of classifiers that combines an incremental version of Naive Bayes, the 1-NN and the WINNOW algorithms using the voting methodology. Among other significant conclusions it was found that the proposed algorithm is the most appropriate to be used for the construction of a software support tool. (C) 2010 Elsevier B.V All rights reserved.	[Xenos, M.] Hellen Open Univ, Software Qual Lab, Sch Sci & Technol, Patras 26222, Greece	Xenos, M (reprint author), Hellen Open Univ, Software Qual Lab, Sch Sci & Technol, 12-15 Tsamadou Str, Patras 26222, Greece.		kotsiantis, sotiris/C-5640-2009	kotsiantis, sotiris/0000-0002-2247-3082			Aha D.W., 1997, LAZY LEARNING; AUER P, 1998, TRACKING BEST DISJUN, V32; AVOURIS N, 2005, WORKSH US AN LEARN S; BARRON A, 1999, TEACHERS GUIDE DISTA; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BURTON LJ, 2005, P 2005 HERDSA ANN C, P68; CASTRO F, 2007, APPL DATA MINING TEC; Cohen W., 1995, P 12 INT C MACH LEAR, P115; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fan W, 1999, P 5 ACM SIGKDD INT C, P362, DOI 10.1145/312129.312283; Fern A., 2000, P 17 INT C MACH LEAR, P279; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FREUND Y, 1999, LARGE MARGIN CLASSIF, V37; Garcia P, 2007, COMPUT EDUC, V49, P794, DOI 10.1016/j.compedu.2005.11.017; Guo QL, 2009, KNOWL-BASED SYST, V22, P439, DOI 10.1016/j.knosys.2009.06.001; Hamalainen W., 2006, P 8 INT C INT TUT SY, P525; KIDERA T, 2006, P INT JOINT C NEUR N, P3421; Kotsiantis SB, 2006, ARTIF INTELL REV, V26, P159, DOI 10.1007/S10462-007-9052-3; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; Lykourentzou I, 2009, COMPUT EDUC, V53, P950, DOI 10.1016/j.compedu.2009.05.010; Macek J., 2005, Proceedings. 18th IEEE Symposium on Computer-Based Medical Systems; Mazurowski MA, 2009, MED PHYS, V36, P2976, DOI 10.1118/1.3132304; Minaei-bidgoli B., 2003, P IEEE FRONT ED COL, P13; MOHAMMED HS, 2006, P IEEE INT C SYST MA, P4838; Muhlbaier MD, 2007, LECT NOTES COMPUT SC, V4472, P490; OZA NC, 2005, P IEEE INT C SYSTEMS, P2340; Patriarcheas K, 2009, COMPUT EDUC, V52, P438, DOI 10.1016/j.compedu.2008.09.013; Platt J., 1999, ADV NEURAL INFORM PR, V11; Polikar R, 2003, IEEE IJCNN, P2770; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; ROMERO C, 2008, P 1 INT C ED DAT MIN, P187; Romero C, 2008, COMPUT EDUC, V51, P368, DOI 10.1016/j.compedu.2007.05.016; Romero C, 2007, EXPERT SYST APPL, V33, P135, DOI 10.1016/j.eswa.2006.04.005; Saad D., 1998, ONLINE LEARNING NEUR; Salmeron JL, 2009, KNOWL-BASED SYST, V22, P275, DOI 10.1016/j.knosys.2009.01.002; Sannen D, 2009, PROCEEDINGS 2009 INTERNATIONAL CONFERENCE ON ADAPTIVE AND INTELLIGENT SYSTEMS, ICAIS 2009, P101, DOI 10.1109/ICAIS.2009.25; Simpson O., 2006, OPEN LEARNING J OPEN, V21, P125, DOI 10.1080/02680510600713110; STEVENSON K, 1996, OPEN LEARNING, V11, P22, DOI 10.1080/0268051960110103; Stevenson K., 1998, OPEN LEARNING, V13, P42, DOI [10.1080/0268051980130208, DOI 10.1080/0268051980130208]; SUPERBY JF, 2006, WORKSH ED DAT MIN, P37; SWERE E, 2006, P INT C INT ROB SYST, P645; TOOTH T, 2000, USE MULTIMEDIA DISTA; Ulas A, 2009, INFORM SCIENCES, V179, P1298, DOI 10.1016/j.ins.2008.12.024; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900; Witten IH, 2005, DATA MINING PRACTICA; Xenos M, 2004, COMPUT EDUC, V43, P345, DOI 10.1016/j.compedu.2003.09.005; Xenos M, 2002, COMPUT EDUC, V39, P361, DOI 10.1016/S0360-1315(02)00072-6; YUDELSON MV, 2006, AAAI WORKSH ED DAT M, P1	49	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	AUG	2010	23	6					529	535		10.1016/j.knosys.2010.03.010		7	Computer Science, Artificial Intelligence	Computer Science	633UO	WOS:000280532400005	
J	Fernandes, JA; Irigoien, X; Goikoetxea, N; Lozano, JA; Inza, I; Perez, A; Bode, A				Fernandes, Jose A.; Irigoien, Xabier; Goikoetxea, Nerea; Lozano, Jose A.; Inza, Inaki; Perez, Aritz; Bode, Antonio			Fish recruitment prediction, using robust supervised classification methods	ECOLOGICAL MODELLING			English	Article						Supervised classification; Ecological modelling; Fish recruitment; Discretization; Feature selection; Climate; Anchovy; Hake	ANCHOVY ENGRAULIS-ENCRASICOLUS; BAYESIAN NETWORKS; DISTRIBUTION ALGORITHMS; BISCAY ANCHOVY; CLIMATE-CHANGE; BAY; ENVIRONMENT; MODEL; SEA; DISCRETIZATION	Improving our ability to predict recruitment is a key element in fisheries management. However, the interactions between population dynamics and different environmental factors are complex and often non-linear, making it difficult to produce robust predictions. 'Machine-learning' techniques (in particular, supervised classification methods) have been proposed as useful tools, to overcome such difficulties. In this study, a methodology is proposed to build a robust classifier for fish recruitment prediction with sparse and noisy data. The methodology consists of 4 steps: (1) a semi-automated recruitment discretization method; (2) supervised discretization of predictors; (3) multivariate and non-redundant predictors selection: (4) learning a probabilistic classifier. in terms of fisheries management, the classifier estimated performance has important consequences and, to be useful, the manager needs to know the risk that is being taken when using this number. Probabilistic classifiers such as 'naive Bayes', have the advantage that, in addition to the predictions, estimate also the probability of each possible outcome. Anchovy (Engraulis encrasicolus) and hake (Merluccius merluccius) recruitments are used as application examples. 'Two-intervals' recruitment discretization accomplishes 70% accuracies and Brier scores of around 0.10, for both anchovy and hake recruitment. In comparison, 'three-intervals' recruitment discretization accomplishes 50% accuracies; and Brier scores of around 0.25 for anchovy and 0.30 for hake recruitment. These statistics are the result of validating not only the classifier, but also the previous steps, as a whole methodology. (C) 2009 Elsevier B.V. All rights reserved.	[Fernandes, Jose A.; Irigoien, Xabier; Goikoetxea, Nerea] AZTI Tecnalia, Div Marine Res, E-20110 Pasaia, Spain; [Fernandes, Jose A.; Lozano, Jose A.; Inza, Inaki; Perez, Aritz] Univ Basque Country, Dept Comp Sci & AI, ISG, E-20018 San Sebastian, Spain; [Bode, Antonio] Inst Espanol Oceanog, Ctr Oceanog A Coruna, E-15080 La Coruna, Spain	Fernandes, JA (reprint author), AZTI Tecnalia, Div Marine Res, Herrera Kaia Z-G, E-20110 Pasaia, Spain.	jfernandes@azti.es	Lozano, Jose/F-5120-2010		Fundacion Centros Tecnologicos Inaki Goenaga; Department of Agriculture, Fisheries and Food of the Basque Country Government; Basque Government [TIN2008-06815-C02-01]; Spanish Ministry of Education and Science [2010-CSD2007-00018]; COMBIOMED network in computational biomedicine (Carlos III Health Institute); EU [212085]	The research of Jose A. Fernandes and Nerea Goikoetxea is supported by a Doctoral Fellowship from the Fundacion Centros Tecnologicos Inaki Goenaga. This study has been supported by the following projects: Ecoanchoa (funded by the Department of Agriculture, Fisheries and Food of the Basque Country Government); the Saiotek and Research Groups 2007-2012 (IT-242-07) programs (Basque Government), TIN2008-06815-C02-01; Consolider Ingenio 2010-CSD2007-00018 projects (Spanish Ministry of Education and Science); COMBIOMED network in computational biomedicine (Carlos III Health Institute); the EU project UNCOVER; and the EU VII Framework project MEECE (MEECE No 212085). Angel Borja and Sonia Sanchez (AZTI-Tecnalia), as well as Professor Michael Collins (SOES, University of Southampton, UK and AZTI-Tecnalia, Spain), are acknowledged for their comments on the manuscript and help with the English language. This is contribution 472 from the Marine Research Division (AZTI-Tecnalia).	Alheit J, 1997, FISH OCEANOGR, V6, P130, DOI 10.1046/j.1365-2419.1997.00035.x; Allain G, 2001, FISH OCEANOGR, V10, P151, DOI 10.1046/j.1365-2419.2001.00164.x; Allain G, 2007, FISH OCEANOGR, V16, P506, DOI 10.1111/j.1365-2419.2007.00442.x; ALPAYDIN E, 2004, INTRO MACHINE LEARNI, P17; Alvarado M, 2004, EXPERT SYST APPL, V26, P1, DOI 10.1016/j.eswa.2003.08.001; Bailey KM, 2005, PROG OCEANOGR, V67, P24, DOI 10.1016/j.pocean.2005.06.001; Bakun A., 1996, PATTERNS OCEAN OCEAN, P323; BARNSTON AG, 1987, MON WEATHER REV, V115, P1083, DOI 10.1175/1520-0493(1987)115<1083:CSAPOL>2.0.CO;2; Bartolino V, 2008, FISH RES, V92, P277, DOI 10.1016/j.fishres.2008.01.007; BAUMGARTNER TR, 1992, CAL COOP OCEAN FISH, V33, P24; Bellier E, 2007, FISH OCEANOGR, V16, P1, DOI 10.1111/j.1365-2419.2006.00410.x; Benner TC, 1999, INT J CLIMATOL, V19, P391, DOI 10.1002/(SICI)1097-0088(19990330)19:4<391::AID-JOC365>3.0.CO;2-Z; Beverton R., 1957, FISHERY INVESTIGATIO, VXIX; Bishop CM, 2006, PATTERN RECOGNITION; Blanco R, 2003, INT J INTELL SYST, V18, P205, DOI 10.1002/int.10084; BODE A, 2006, P ICES CM THEM SESS; Borja A, 1998, FISH OCEANOGR, V7, P375, DOI 10.1046/j.1365-2419.1998.00064.x; Borja A, 2008, FISH OCEANOGR, V17, P477, DOI 10.1111/j.1365-2419.2008.00494.x; Borja A, 1996, SCI MAR, V60, P179; Bouckaert RR, 2004, P 8 PAC AS C KNOWL D, P3; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; Brunel T, 2007, FISH OCEANOGR, V16, P336, DOI 10.1111/j.1365-2419.2007.00435.x; CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164; Chen DG, 1999, CAN J FISH AQUAT SCI, V56, P2385, DOI 10.1139/cjfas-56-12-2385; Correa M, 2009, EXPERT SYST APPL, V36, P7270, DOI 10.1016/j.eswa.2008.09.024; Cushing D.H., 1982, CLIMATE FISHERIES; Demsar J, 2006, J MACH LEARN RES, V7, P1; De Oliveira JAA, 2005, FISH RES, V75, P2, DOI 10.1016/j.fishres.2005.05.005; Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DOUGHERTY J, 1995, SUPERVISED UNSUPERVI; Dreyfus-Leon M, 2007, ECOL MODEL, V203, P141, DOI 10.1016/j.ecolmodel.2005.09.016; Dreyfus-Leon M, 2008, ECOL INFORM, V3, P202, DOI 10.1016/j.ecoinf.2008.02.003; DUDA RO, 2001, PATTERN CLASSIFICATI, P487; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Fiksen O, 1998, FISH OCEANOGR, V7, P355, DOI 10.1046/j.1365-2419.1998.00068.x; Flores JL, 2007, INTELL DATA ANAL, V11, P525; Francis RICC, 2006, ICES J MAR SCI, V63, P594, DOI 10.1016/j.icesjms.2006.01.001; Frank E, 2000, MACH LEARN, V41, P5, DOI 10.1023/A:1007670802811; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Geurts P, 2000, LECT NOTES ARTIF INT, V1810, P162; Guyon I, 2008, CH CRC DATA MIN KNOW, P63; Hall M., 1998, THESIS WAIKATO U HAM; Hall MA, 2000, P 17 INT C MACH LEAR, P359; HURRELL JW, 2003, GEOPHYS MONOGR SERIE, V134; Ibaibarriaga L, 2007, FISH OCEANOGR, V16, P284, DOI 10.1111/j.1365-2419.2006.00430.x; *ICES, 2007, REP ICES GLOBEC WORK; *ICES, 2008, REP WORK GROUP ASS S, P613; Irigoien X, 2007, PROG OCEANOGR, V74, P132, DOI 10.1016/j.pocean.2007.04.011; Jin JS, 2009, P NATL ACAD SCI USA, V106, P8859, DOI 10.1073/pnas.0903931106; JOHN GH, 1995, P 11 C UNC ART INT, P338; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Langley P., 1992, P 10 NAT C ART INT, P223; Larranaga P, 2005, MACH LEARN, V59, P211, DOI 10.1007/s10994-005-0468-1; Larson SC, 1931, J EDUC PSYCHOL, V22, P45, DOI 10.1037/h0072400; LEAN J, 1995, GEOPHYS RES LETT, V22, P3195, DOI 10.1029/95GL03093; MacKenzie BR, 2008, CAN J FISH AQUAT SCI, V65, P1334, DOI 10.1139/F08-051; McFarlane GA, 2000, PROG OCEANOGR, V47, P147, DOI 10.1016/S0079-6611(00)00034-3; MEINERS CG, 2007, THESIS, P187; MOSTELLER F, 1968, HDB SOCIAL PSYCHOL, V2, P588; MYERS RA, 1995, CAN TECH REP FISH AQ, P2024; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Planque B, 2008, MAR ECOL PROG SER, V357, P213, DOI 10.3354/meps07274; Rayner NA, 2006, J CLIMATE, V19, P446, DOI 10.1175/JCLI3637.1; REID GC, 1991, J GEOPHYS RES-ATMOS, V96, P2835, DOI 10.1029/90JD02274; REID GC, 1987, NATURE, V329, P142, DOI 10.1038/329142a0; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; Revoredo K, 2004, LECT NOTES ARTIF INT, V3171, P317; RICKER W. E., 1954, JOUR FISH RES BD CANADA, V11, P559; RODRIGUEZ JD, 2009, EHUKZAAIK109 U BASQ; Ruiz J, 2009, FISH OCEANOGR, V18, P62, DOI 10.1111/j.1365-2419.2008.00497.x; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Schirripa MJ, 2006, FISH OCEANOGR, V15, P25, DOI 10.1111/j.1365-2419.2005.00352.x; Sebastiani P, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P193, DOI 10.1007/0-387-25465-X_10; Shannon CE, 1948, MATH THEORY COMMUNIC; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STONE M, 1974, J R STAT SOC B, V36, P111; TORGO L, 1997, LECT NOTES COMPUT SC, P266; Uusitalo L, 2007, ECOL MODEL, V203, P312, DOI 10.1016/j.ecolmodel.2006.11.033; VANDERGAAG LC, 2001, P 13 BELG NETH C ART, P109; Witten IH, 2005, DATA MINING PRACTICA; Yang Y, 2009, MACH LEARN, V74, P39, DOI 10.1007/s10994-008-5083-5; Yeung KY, 2005, BIOINFORMATICS, V21, P2394, DOI 10.1093/bioinformatics/bti319; ZHANG H, 2004, P 17 INT FLAIRS C; Zhou ZH, 2003, ARTIF INTELL, V143, P139, DOI 10.1016/S0004-3702(02)00357-0	87	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800			ECOL MODEL	Ecol. Model.	JAN 24	2010	221	2					338	352		10.1016/j.ecolmodel.2009.09.020		15	Ecology	Environmental Sciences & Ecology	544CF	WOS:000273628800021	
J	Holton, C				Holton, Carolyn			Identifying disgruntled employee systems fraud risk through text mining: A simple solution for a multi-billion dollar problem	DECISION SUPPORT SYSTEMS			English	Article						IS security; Occupational fraud; Text mining; Design science; Disgruntled employee; Organizational communication		Occupational fraud is a $652 billion problem to which disgruntled employees are a major contributor. Much security research addresses reducing fraud opportunity and increasing fraud detection, but detecting motivational factors like employee disgruntlement is less studied. The Sarbanes-Oxley Act requires that companies archive email, creating an untapped resource for deterring fraud. Herein, protocols to identify disgruntled communications are developed. Messages cluster well according to disgruntled content, giving confidence in the value of email for this task. A highly accurate naive Bayes model predicts whether messages contain disgruntled communications, providing extremely relevant information not otherwise likely to be revealed in a fraud audit. The model can be incorporated into fraud risk analysis systems to improve their ability to detect and deter fraud. (C) 2008 Elsevier B.V. All rights reserved.	Southeast Univ, Coll Business & Legal Studies, Lakeland, FL 33801 USA	Holton, C (reprint author), Southeast Univ, Coll Business & Legal Studies, 1000 Longfellow Blvd, Lakeland, FL 33801 USA.	cfholton@seuniversity.edu					*ACI, 2006, DAT AN SOFTW AN PRES; *AM I CERT PUBL AC, 2002, 99 SAS AM I CERT PUB; *AM I CERT PUBL AC, 2002, 99 AM I CERT PUBL AC; ARNESEN DW, 1998, BUSINESS HORIZONS, V41; BALOVICH D, 2007, SARBANES OXLEY DOCUM; BAPNA S, 2006, DECISION SCI, V37; BRADY T, 1993, MANAGEMENT REV, V82; BRILL E, 1994, 20 NAT C ART INT CAM; BUSH GW, 2002, WHITE HOUSE STATEMEN; CAVUSOGLU H, 2005, INFORM SYSTEMS RES, V16; CUTTING DR, 1992, P 15 ANN ACM SIGIR; DHILLON IS, 2001, MACHINE LEARNING, V42; DOMINGOS P, 1996, 13 INT C MACH LEARN; FERNANDEZMEDINA E, 2006, DECISION SUPPORT SYS, V42; GATTIKER UE, 1999, INFORM SYSTEMS RES, V10; GUPTA M, 2006, DECISION SUPPORT SYS, V41; Han J., 2000, ACM SIGMOD INT C MAN; HEPPLE M, 2000, 28 ANN M ASS COMP LI; Hevner A. R., 2004, MIS Q, V28; HOLLINGER R, 1983, SOCIAL FORCES, V62; HOLLINGER R, 1982, WORK OCCUPATIONS, V9; JACOBS DL, 1994, MANAGEMENT REV, V83; *KROLL INC, 2008, EC INT U OV KROLL GL; MAILVAGANAM H, 2004, TEXT MINING FRAUD DE; MARTENS D, 2008, DECISION SUPPORT SYS, V45; MONTANA JC, 2006, INFORM MANAGEMENT J, V40, P6; PEI J, 2000, ACM SIGMOD WORKSH RE; Porter M F, 1980, PROGRAM, V14; RAMOS M, 2003, J ACCOUNTANCY, V195; RHINEHART C, 2005, EMAIL MANAGEMENT SAR; RODRIGUES MES, 2004, 4 INT C REC ADV SOFT; SCHULTZ EE, 2002, COMPUTER SECURITY, V21; SCHWARTZ E, INFOWORLD, V26, P14; SCHWEDER RA, 1987, EMERGENCE MORALITY Y; Shaw GL, 2006, J HOMEL SECUR EMERG, V3; SIPONEN M, 2003, 7 PAC AS C INF SYST; STRAUB DW, 1998, MIS Q, V22; TOLSON B, 2006, EMAIL RETENTION POLI; TREMBLAY M, 2005, 11 AM C INF SYST OMA; VARON E, 2003, CIO MAGAZINE, V16; WELLS JT, 2001, J ACCOUNTANCY, V191; WESCHE TM, 2002, J HIGH TECHNOLOGY LA, V1; WILDING E, 2002, COMPUTER FRAUD SECUR; WILKS J, 2004, CONT ACCOUNTING RES, V21; WILLISON R, 2004, P 37 HAW INT C SYST; WORTHEN B, 2005, CIO MAGAZINE, V18; Yue WT, 2007, DECIS SUPPORT SYST, V44, P1, DOI 10.1016/j.dss.2006.08.009; PREVENTING CRIME VIO; 2006, REPORT NATION OCCUPA	49	12	13	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236			DECIS SUPPORT SYST	Decis. Support Syst.	MAR	2009	46	4					853	864		10.1016/j.dss.2008.11.013		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	426IK	WOS:000264701000010	
J	Huang, HL; Chin, HC; Haque, MM				Huang, Helai; Chin, Hoong Chor; Haque, Md. Mazharul			Empirical Evaluation of Alternative Approaches in Identifying Crash Hot Spots Naive Ranking, Empirical Bayes, and Full Bayes Methods	TRANSPORTATION RESEARCH RECORD			English	Article							MOTOR-VEHICLE CRASHES; POISSON-GAMMA; MODELS; ACCIDENT; IDENTIFICATION; PARAMETER; SAFETY; FIT	This study proposes a framework of a model-based hot spot identification method by applying full Bayes (1713) technique. In comparison with the state-of-the-art approach [i.e., empirical Bayes method (EB)], the advantage of the FB method is the capability to seamlessly integrate prior information and all available data into posterior distributions on which various ranking criteria could be based. With intersection crash data collected in Singapore, an empirical analysis was conducted to evaluate the following six approaches for hot spot identification: (a) naive ranking using raw crash data, (b) standard Ell ranking, (c) FB ranking using a Poisson-gamma model, (d) FB ranking using a Poisson-lognormal model, (e) FB ranking using a hierarchical Poisson model, and (f) FB ranking using a hierarchical Poisson (AR-1) model. The results show that (a) when using the expected crash rate-related decision parameters, all model-based approaches perform significantly better in safety ranking than does the naive ranking method, and (b) the FB approach using hierarchical models significantly outperforms the standard EB approach in correctly identifying hazardous sites.	[Huang, Helai] Univ Cent Florida, Dept Civil & Environm Engn, Orlando, FL 32816 USA; [Chin, Hoong Chor; Haque, Md. Mazharul] Natl Univ Singapore, Dept Civil Engn, Singapore 117576, Singapore	Huang, HL (reprint author), Univ Cent Florida, Dept Civil & Environm Engn, 301A Engn Bldg 2, Orlando, FL 32816 USA.	huanghelai@hotmail.com	Haque, Md. Mazharul/E-3155-2012				Brooks SP, 1998, J COMPUT GRAPH STAT, V7, P434, DOI 10.2307/1390675; Carlin BP, 2000, BAYES EMPIRICAL BAYE; Chapman R., 1973, ACCIDENT ANAL PREV, V5, P95, DOI 10.1016/0001-4575(73)90018-3; Cheng W, 2008, TRANSP RES RECORD, P76, DOI 10.3141/2083-09; Cheng W, 2005, ACCIDENT ANAL PREV, V37, P870, DOI 10.1016/j.aap.2005.04.015; Congdon P., 2003, APPL BAYESIAN MODELL; Deacon J. A., 1975, TRANSPORT RES REC, P16; Elvik R., 2007, 883 I TRANSP EC; GETMAN A, 2003, BAYESIAN DATA ANAL; Hauer E., 1984, TRANSPORT RES REC, V975, P36; Hauer E., 1997, OBSERVATIONAL STUDIE; Hauer E., 2002, TRANSPORT RES REC, V2182, P27, DOI 10.3141/1784-04; Hauer E., 1996, TRANSPORT RES REC, V1542, P54, DOI 10.3141/1542-09; Huang Helai, 2008, Accid Anal Prev, V40, P45, DOI 10.1016/j.aap.2007.04.002; HUANG H, 2008, 87 ANN M TRANSP RES; Lord D, 2008, SAFETY SCI, V46, P751, DOI 10.1016/j.ssci.2007.03.005; Lord D, 2007, ACCIDENT ANAL PREV, V39, P53, DOI 10.1016/j.aap.2006.06.004; Lord D, 2005, ACCIDENT ANAL PREV, V37, P35, DOI 10.1016/j.aap.2004.02.004; MacNab YC, 2003, ACCIDENT ANAL PREV, V35, P91, DOI 10.1016/S0001-4575(01)00093-8; MAHER MJ, 1988, ACCIDENT ANAL PREV, V20, P143, DOI 10.1016/0001-4575(88)90031-0; MIAOU SP, 1994, ACCIDENT ANAL PREV, V26, P471, DOI 10.1016/0001-4575(94)90038-8; Miaou SP, 2005, ACCIDENT ANAL PREV, V37, P699, DOI 10.1016/j.aap.2005.03.012; Miaou S.P., 2003, TRANSPORT RES REC, V1840, P31, DOI 10.3141/1840-04; SHANKAR V, 1995, ACCIDENT ANAL PREV, V27, P371, DOI 10.1016/0001-4575(94)00078-Z; Song JJ, 2006, J MULTIVARIATE ANAL, V97, P246, DOI 10.1016/j.jmva.2005.03.007; Spiegelhalter DJ, 2002, J ROY STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353; Spiegelhalter D.J., 2003, WINBUGS VERSION 1 4; STOKES RW, 1996, TRANSPORT RES REC, P44; TAMBURRI TN, 1970, HIGHWAY RES REC, V307, P28; Wang XS, 2006, ACCIDENT ANAL PREV, V38, P1137, DOI 10.1016/j.aap.2006.04.022	30	12	12	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0361-1981			TRANSP RES RECORD	Transp. Res. Record		2009		2103					32	41		10.3141/2103-05		10	Engineering, Civil; Transportation; Transportation Science & Technology	Engineering; Transportation	496JA	WOS:000269965800006	
J	Brodersen, KH; Penny, WD; Harrison, LM; Daunizeau, J; Ruff, CC; Duzel, E; Friston, KJ; Stephan, KE				Brodersen, Kay H.; Penny, Will D.; Harrison, Lee M.; Daunizeau, Jean; Ruff, Christian C.; Duzel, Emrah; Friston, Karl J.; Stephan, Klaas E.			Integrated Bayesian models of learning and decision making for saccadic eye movements	NEURAL NETWORKS			English	Article						Saccades; Decision making; Reaction time; Bayesian learning; Model comparison	REACTION-TIME; PERCEPTUAL DECISION; COUNTERMANDING SACCADES; VISUAL-DISCRIMINATION; SUPERIOR COLLICULUS; 2-CHOICE DECISIONS; NEURONAL-ACTIVITY; PROCESSING STAGES; SENSORY STIMULI; PARIETAL CORTEX	The neurophysiology of eye movements has been studied extensively, and several computational models have been proposed for decision-making processes that underlie the generation of eye movements towards a Visual stimulus in a Situation of uncertainty. One class of models, known as linear rise-to-threshold models, provides an economical, yet broadly applicable, explanation for the observed variability in the latency between the onset of a peripheral Visual target and the saccade towards it. So far, however, these models do not account for the dynamics of learning across a Sequence of stimuli, and they do not apply to situations in which Ssbjects are exposed to events with conditional probabilities. In this methodological paper, we extend the class of linear rise-to-threshold models to address these limitations. Specifically, we reformulate previous models in terms of a generative, hierarchical model. by combining two separate sub-models that account for the interplay between learning of target locations across trials and the decision-making process within trials. We derive a maximum-likelihood scheme for parameter estimation as well as model comparison on the basis of log likelihood ratios. The utility Of the integrated model is demonstrated by applying it to empirical saccade data acquired from three healthy subjects. Model comparison is used (i) to show that eye movements do not only reflect marginal but also conditional probabilities of target locations, and (ii) to reveal subject-specific learning profiles over trials. These individual learning profiles are Sufficiently distinct that test samples can be Successfully mapped onto the correct subject by a naive Bayes classifier. Altogether, our approach extends the class of linear rise-to-threshold models of saccadic decision making, overcomes some of their previous limitations, and enables statistical inference both about learning of target locations across trials and the decision-making process within trials. (C) 2008 Elsevier Ltd. All rights reserved.	[Brodersen, Kay H.; Penny, Will D.; Harrison, Lee M.; Daunizeau, Jean; Friston, Karl J.; Stephan, Klaas E.] UCL, Inst Neurol, Wellcome Trust Ctr Neuroimaging, London WC1N 3BG, England; [Brodersen, Kay H.] Univ Oxford, John Radcliffe Hosp, Ctr Funct Magnet Resonance Imaging Brain FMRIB, Oxford OX3 9DU, England; [Stephan, Klaas E.] Univ Zurich, Inst Empir Res Econ, Branco Weiss Lab, CH-8006 Zurich, Switzerland; [Ruff, Christian C.; Duzel, Emrah] UCL, Inst Cognit Neurosci, London WC1N 3AR, England	Brodersen, KH (reprint author), UCL, Inst Neurol, Wellcome Trust Ctr Neuroimaging, 12 Queen Sq, London WC1N 3BG, England.	kay.brodersen@gmx.net	Duzel, Emrah/A-1794-2010; Friston, Karl/D-9230-2011; Brodersen, Kay/B-6694-2013	Friston, Karl/0000-0001-7984-8909; Brodersen, Kay/0000-0002-7707-090X	Wellcome Trust [VS/06/UCLIA18]; German Academic Exchange Service [D/06/49008]; Stiftung Familie Klee	This research has been funded by the Wellcome Trust (VS/06/UCLIA18), the German Academic Exchange Service (DAAD, D/06/49008). and the Stiftung Familie Klee (Frankfurt/Main).	Anderson B, 2008, NEUROPSYCHOLOGIA, V46, P1566, DOI 10.1016/j.neuropsychologia.2007.12.006; Asrress KN, 2001, VISION RES, V41, P2645, DOI 10.1016/S0042-6989(01)00107-9; BASSO MA, 1997, NATURE, V389, P1966; Basso MA, 1998, J NEUROSCI, V18, P7519; Behrens TEJ, 2007, NAT NEUROSCI, V10, P1214, DOI 10.1038/nn1954; Carpenter RHS, 2004, CURR BIOL, V14, P1576, DOI 10.1016/j.cub.2004.08.068; Carpenter RHS, 2007, EXP BRAIN RES, V177, P176, DOI 10.1007/s00221-006-0666-5; CARPENTER RHS, 1995, NATURE, V377, P59, DOI 10.1038/377059a0; Carpenter RHS, 2001, NAT NEUROSCI, V4, P337, DOI 10.1038/85960; Corrado GS, 2005, J EXP ANAL BEHAV, V84, P581, DOI 10.1901/jeab.2005.23-05; FISCHER B, 1993, NEUROPSYCHOLOGIA, V31, P887, DOI 10.1016/0028-3932(93)90146-Q; Gitelman DR, 2002, BEHAV RES METH INS C, V34, P605, DOI 10.3758/BF03195488; Glimcher PW, 2003, ANNU REV NEUROSCI, V26, P133, DOI 10.1146/annurev.neuro.26.010302.081134; Glimcher PW, 2001, TRENDS NEUROSCI, V24, P654, DOI 10.1016/S0166-2236(00)01932-9; Gold JI, 2001, TRENDS COGN SCI, V5, P10, DOI 10.1016/S1364-6613(00)01567-9; Gold JI, 2002, NEURON, V36, P299, DOI 10.1016/S0896-6273(02)00971-6; Gold JI, 2000, NATURE, V404, P390, DOI 10.1038/35006062; GRICE GR, 1968, PSYCHOL REV, V75, P359, DOI 10.1037/h0026287; Hanes DP, 1996, SCIENCE, V274, P427, DOI 10.1126/science.274.5286.427; Hanes DP, 1999, VISION RES, V39, P2777, DOI 10.1016/S0042-6989(99)00011-5; HANES DP, 1995, EXP BRAIN RES, V103, P85; Hanes DP, 1998, J NEUROPHYSIOL, V79, P817; Harrison LM, 2006, NEURAL NETWORKS, V19, P535, DOI 10.1016/j.neunet.2005.11.002; HERRNSTEIN RJ, 1961, J EXP ANAL BEHAV, V4, P267, DOI 10.1901/jeab.1961.4-267; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JAZAYERI M, 2006, NATURE, V200, P6; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.2307/2291091; Kim JN, 1999, NAT NEUROSCI, V2, P176; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Kurata K, 2004, NEUROSCI RES, V48, P447, DOI 10.1016/j.neures.2004.01.003; Lau B, 2005, J EXP ANAL BEHAV, V84, P555, DOI 10.1901/jeab.2005.110-04; Leach JCD, 2001, VISION RES, V41, P3437, DOI 10.1016/S0042-6989(01)00059-1; LOON EMV, 2002, P BIOL SCI ROYAL SOC, V269, P1571, DOI 10.1098/rspb.2002.2062; Luce RD, 1963, HDB MATH PSYCHOL, V1, P103; Luce RD, 1986, RESPONSE TIMES THEIR; Ludwig CJH, 2005, J NEUROSCI, V25, P9907, DOI 10.1523/JNEURSCI.2197-05.2005; Ma WJ, 2006, NAT NEUROSCI, V9, P1432, DOI 10.1038/nn1790; Maddox WT, 2002, J EXP ANAL BEHAV, V78, P567, DOI 10.1901/jeab.2002.78-567; Madelain L, 2007, J NEUROPHYSIOL, V98, P2255, DOI 10.1152/jn.01286.2006; McDowell JE, 2002, BIOL PSYCHIAT, V51, P216, DOI 10.1016/S0006-3223(01)01204-5; McMillen T, 2006, J MATH PSYCHOL, V50, P30, DOI 10.1016/j.jmp.2005.10.003; MINKA TP, 2001, BAYESIAN INFERENCE E; Nakahara H, 2006, NEURAL NETWORKS, V19, P1027, DOI 10.1016/j.neunet.2006.07.001; NAZIR TA, 1991, PSYCHOL RES-PSYCH FO, V53, P281, DOI 10.1007/BF00920481; NEWSOME WT, 1988, J NEUROSCI, V8, P2201; NEWSOME WT, 1990, COLD SPRING HARB SYM, V55, P697; Newsome WT, 1997, J COMP PHYSIOL A, V181, P5, DOI 10.1007/s003590050087; NEWSOME WT, 1989, NATURE, V341, P52, DOI 10.1038/341052a0; Oswal A, 2007, J NEUROPHYSIOL, V97, P2722, DOI 10.1152/jn.01238.2006; Papoulis A., 1991, PROBABILITY RANDOM V; Penny WD, 2004, NEUROIMAGE, V22, P1157, DOI 10.1016/j.neuroimage.2004.03.026; Platt ML, 1999, NATURE, V400, P233, DOI 10.1038/22268; Platt ML, 2002, CURR OPIN NEUROBIOL, V12, P141, DOI 10.1016/S0959-4388(02)00302-1; Rao RPN, 2004, NEURAL COMPUT, V16, P1, DOI 10.1162/08997660460733976; Ratcliff R, 2003, J NEUROPHYSIOL, V90, P1392, DOI 10.1152/jn.01049.2002; RATCLIFF R, 1978, PSYCHOL REV, V85, P59, DOI 10.1037//0033-295X.85.2.59; Ratcliff R, 1998, PSYCHOL SCI, V9, P347, DOI 10.1111/1467-9280.00067; Ratcliff R, 1999, PSYCHOL REV, V106, P261, DOI 10.1037//0033-295X.106.2.261; Ratcliff R, 2004, PSYCHOL REV, V111, P333, DOI 10.1037/0033-295X.111.2.333; Reddi BAJ, 2000, NAT NEUROSCI, V3, P827; REDDI BAJ, 2001, CURR BIOL, V11, P603; Reddi BAJ, 2003, J NEUROPHYSIOL, V90, P3538, DOI 10.1152/jn.00689.2002; ROBINSON DA, 1973, KYBERNETIK, V14, P71, DOI 10.1007/BF00288906; Roitman JD, 2002, J NEUROSCI, V22, P9475; ROMAYA J, 2000, COGENT 2000 THIS EXP; SALZMAN CD, 1990, NATURE, V346, P174, DOI 10.1038/346174a0; Schall JD, 1999, ANNU REV NEUROSCI, V22, P241, DOI 10.1146/annurev.neuro.22.1.241; Schall JD, 2001, NAT REV NEUROSCI, V2, P33, DOI 10.1038/35049054; Schall JD, 2003, CURR OPIN NEUROBIOL, V13, P182, DOI 10.1016/S0959-4388(03)00039-4; Shadlen MN, 1996, J NEUROSCI, V16, P1486; Shadlen MN, 2001, J NEUROPHYSIOL, V86, P1916; Shadlen MN, 1996, P NATL ACAD SCI USA, V93, P628, DOI 10.1073/pnas.93.2.628; Shadlen MN, 2004, COGNITIVE NEUROSCIENCES III, THIRD EDITION, P1229; Sinha N, 2006, J NEUROPHYSIOL, V95, P3146, DOI 10.1152/jn.01184.2005; Smith AC, 2007, J NEUROPHYSIOL, V97, P2516, DOI 10.1152/jn.00946.2006; Smith J, 2004, J EARLY INTERVENTION, V27, P1, DOI 10.1177/105381510402700101; Stephan KE, 2006, BIOL PSYCHIAT, V59, P929, DOI 10.1016/j.biopsych.2005.10.005; Sternberg S, 1969, ACTA PSYCHOL, V30, P276, DOI 10.1016/0001-6918(69)90055-9; STERNBER.S, 1969, AM SCI, V57, P421; Strange BA, 2005, NEURAL NETWORKS, V18, P225, DOI 10.1016/j.neunet.2004.12.004; Thompson KG, 1996, J NEUROPHYSIOL, V76, P4040; Thompson KG, 1997, J NEUROPHYSIOL, V77, P1046; Usher M, 2001, PSYCHOL REV, V108, P550, DOI 10.1037//0033-295X.108.3.550; WALD A, 1945, ANN MATH STAT, V16, P117, DOI 10.1214/aoms/1177731118	84	12	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	NOV	2008	21	9					1247	1260		10.1016/j.neunet.2008.08.007		14	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	381QD	WOS:000261550100006	
J	Yu, B				Yu, Bei			An evaluation of text classification methods for literary study	LITERARY AND LINGUISTIC COMPUTING			English	Article								This article presents an empirical evaluation of text classification methods in literary domain. This study compared the performance of two popular algorithms, naive Bayes and support vector machines (SVMs) in two literary text classification tasks: the eroticism classification of Dickinson's poems and the sentimentalism classification of chapters in early American novels. The algorithms were also combined with three text pre-processing tools, namely stemming, stopword removal, and statistical feature selection, to study the impact of these tools on the classifiers' performance in the literary setting. Existing studies outside the literary domain indicated that SVMs are generally better than naive Bayes classifiers. However, in this study SVMs were not all winners. Both algorithms achieved high accuracy in sentimental chapter classification, but the naive Bayes classifier outperformed the SVM classifier in erotic poem classification. Self-feature selection helped both algorithms improve their performance in both tasks. However, the two algorithms selected relevant features in different frequency ranges, and therefore captured different characteristics of the target classes. The evaluation results in this study also suggest that arbitrary feature-reduction steps such as stemming and stopword removal should be taken very carefully. Some stopwords were highly discriminative features for Dickinson's erotic poem classification. In sentimental chapter classification, stemming undermined subsequent feature selection by aggressively conflating and neutralizing discriminative features.	[Yu, Bei] Univ Illinois, Grad Sch Lib & Informat Sci, Urbana, IL 61801 USA	Yu, B (reprint author), Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.	beiyu.work@gmail.com					Argamon S, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1121949.1121972; ARGAMON S, 2003, P IJCAI 03 WORKSH CO; Baeza-Yates R., 1999, MODERN INFORM RETRIE; Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290970; Biber Douglas, 1995, DIMENSIONS REGISTER; Biber Douglas, 1988, VARIATIONS SPEECH WR; BLAND JM, 1995, BRIT MED J, V310, P170; Brill E, 1995, COMPUT LINGUIST, V21, P543; COHEN W, 1995, ADV INDUCTIVE LOGIC; Craig H., 1999, Literary & Linguistic Computing, V14, DOI 10.1093/llc/14.1.103; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Heffernan JAW, 2004, MUSEUM WORDS POETICS; Holmes D. I., 1998, Literary & Linguistic Computing, V13, DOI 10.1093/llc/13.3.111; HOLMES DI, 1994, COMPUT HUMANITIES, V28, P87, DOI 10.1007/BF01830689; HORTON R, 2007, MINING 18 CENTURY MA; HORTON T, 2006, QUITE RIGHT DEAR INT; Joachims T., 1998, LNCS, V1398, P137; Juola P., 2005, Literary & Linguistic Computing, DOI 10.1093/llc/fqi024; Lewis D., 1998, LECT NOTES COMPUTER, V1398, P4, DOI DOI 10.1007/BFB0026666; Lewis David D., 1992, P 15 ANN INT ACM SIG, P37, DOI 10.1145/133160.133172; McCallum A, 1998, AAAI 98 WORKSH LEARN; Mitchell T.M., 1997, MACHINE LEARNING; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Mladenic D., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009034; Mosteller F., 1964, INFERENCE DISPUTED A; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Plaisant C., 2006, P 6 ACM IEEE CS JOIN, P141, DOI 10.1145/1141753.1141781; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; RAMSAY S, 2008, COMPANION DIGITAL LI, P477; RAMSAY S, 2004, FACE TEXT; Riloff E., 1995, P 18 ANN INT ACM SIG, P130, DOI 10.1145/215206.215349; Scott Sam, 1999, P 16 INT C MACH LEAR, P379; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Unsworth J., 2000, S HUM COMP FORM METH; Vapnik V., 1999, NATURE STAT LEARNING; Vapnik Vladimir, 1982, ESTIMATING DEPENDENC; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y., 1997, P 14 INT C MACH LEAR, P412; YU B, 2006, DISCOVERING POTENTIA	42	12	12	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0268-1145			LIT LINGUIST COMPUT	Lit. Linguist. Comput.	SEP	2008	23	3					327	343		10.1093/llc/fqn015		17	Linguistics; Language & Linguistics; Literature	Linguistics; Literature	V14LI	WOS:000207735500007	
J	Fujino, A; Ueda, N; Saito, K				Fujino, Akinori; Ueda, Naonori; Saito, Kazumi			Semisupervised learning for a hybrid generative/discriminative classifier based on the maximum entropy principle	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						generative model; maximum entropy principle; bias correction; unlabeled samples; text classification	TEXT CLASSIFICATION; UNLABELED DATA; EM	This paper presents a method for designing semisupervised classifiers trained on labeled and unlabeled samples. We focus on a probabilistic semisupervised classifier design for multiclass and single-labeled classification problems and propose a hybrid approach that takes advantage of generative and discriminative approaches. In our approach, we first consider a generative model trained by using labeled samples and introduce a bias correction model, where these models belong to the same model family but have different parameters. Then, we construct a hybrid classifier by combining these models based on the maximum entropy principle. To enable us to apply our hybrid approach to text classification problems, we employed naive Bayes models as the generative and bias correction models. Our experimental results for four text data sets confirmed that the generalization ability of our hybrid classifier was much improved by using a large number of unlabeled samples for training when there were too few labeled samples to obtain good performance. We also confirmed that our hybrid approach significantly outperformed the generative and discriminative approaches when the performance of the generative and discriminative approaches was comparable. Moreover, we examined the performance of our hybrid classifier when the labeled and unlabeled data distributions were different.	[Fujino, Akinori; Ueda, Naonori] NTT Corp, NTT Commun Sci Labs, Kyoto 6190237, Japan; [Saito, Kazumi] Univ Shizuoka, Sch Adm & Informat, Suruga Ku, Shizuoka 4228526, Japan	Fujino, A (reprint author), NTT Corp, NTT Commun Sci Labs, 2-4 Hikaridai,Seika Cho, Kyoto 6190237, Japan.	a.fujino@cslab.kecl.ntt.co.jp; ueda@cslab.kecl.ntt.co.jp; k-saito@u-shizuoka-ken.ac.jp					AMINI MR, 2002, P 15 EUR C ART INT, P390; Bekkerman R., 2001, P SIGIR 01 24 ACM IN, P146, DOI 10.1145/383952.383976; Berger AL, 1996, COMPUT LINGUIST, V22, P39; BLUM A, 1998, P 11 AM C COMP LEARN, V11; Chawla N, 2005, J ARTIF INTELL RES, V23, P331; Chen SF, 1999, GAUSSIAN PRIOR SMOOT; Cozman F.G., 2002, P 15 INT FLOR ART IN, P327; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Fujino A, 2007, INFORM PROCESS MANAG, V43, P379, DOI 10.1016/j.ipm.2006.07.013; FUJINO A, 2005, INFORM TECHNOLOGY LE, V4, P161; FUJINO A., 2005, P 20 NAT C ART INT, P764; Grandvalet Y, 2005, ADV NEURAL INFORM PR, V17, P529; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Inoue M, 2003, IEEE T PATTERN ANAL, V25, P1570, DOI 10.1109/TPAMI.2003.1251150; Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Manning C.D., 1999, FDN STAT NATURAL LAN; Miller DJ, 1997, ADV NEUR IN, V9, P571; Ng AY, 2002, ADV NEUR IN, V14, P841; Nigam K., 1999, P IJCAI 99 WORKSH MA, P61; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Raina R., 2004, ADV NEURAL INFORM PR, V16; Salton G., 1983, INTRO MODERN INFORM; Seeger M., 2001, LEARNING LABELED UNL; Szummer M, 2001, ADV NEUR IN, V13, P626; Tong S., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Zhu X.J., 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663	32	12	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					424	437		10.1109/TPAMI.2007.70710		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	250FT	WOS:000252286100005	
J	Hu, YC; Ansell, J				Hu, Yu-Chiang; Ansell, Jake			Measuring retail company performance using credit scoring techniques	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article						finance; credit scoring; retailing; multivariate statistics; artificial intelligence	DISCRIMINANT-ANALYSIS; FINANCIAL DISTRESS; EMPIRICAL-EVIDENCE; CLASSIFICATION MODELS; BANKRUPTCY PREDICTION; ACCOUNTING RATIOS; NEURAL-NETWORKS; FAILURE; CORPORATIONS; COMPETITION	This paper discusses models for evaluating credit risk in relation to the retailing industry. Hunt's [Hunt, S.D., 2000. A General Theory of Competition. Sage Publications Inc., California] Resource-Advantage Theory of Competition is used as a basis for variable selection, given the theory's relevancy to retail competition. The study focuses on the US retail market. Four standard credit scoring methodologies: Naive Bayes, Logistic Regression, Recursive Partitioning and Artificial Neural Network, are compared with Sequential Minimal Optimization (SMO), using a sample of 195 healthy companies and 51 distressed firms over five time periods from 1994 to 2002. The five methodologies performed well in predicting default particularly one year before financial distress. Prediction remained sound even five years before distress with accuracy rates above 78% and AUROC values above 0.79. No single methodology, however, had the best classification ability across different time scales and variable sets. External environmental influences exist, but these influences are weak. In terms of similarity with Moody's ranking, both SMO and logistic regression models are better than the neural network model, with SMO being slightly better than logistic regression. (c) 2006 Elsevier B.V. All rights reserved.	Univ Edinburgh, Management Sch & Econ, Edinburgh EH8 9JY, Midlothian, Scotland	Hu, YC (reprint author), Univ Edinburgh, Management Sch & Econ, William Robertson Bldg,50 George Square, Edinburgh EH8 9JY, Midlothian, Scotland.	Y.A.Hu@sms.ed.ac.uk; Jake.Ansell@ed.ac.uk					Altman E., 1977, J BANK FINANC, V1, P29, DOI 10.1016/0378-4266(77)90017-6; ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171; BLUM M, 1974, J ACCOUNTING RES, V12, P1, DOI 10.2307/2490525; BOWEN RM, 1982, FINANC MANAGE, V11, P10, DOI 10.2307/3665227; Carson JM, 1995, J RISK INSUR, V62, P764, DOI 10.2307/253595; CASEY C, 1985, J ACCOUNTING RES, V23, P384, DOI 10.2307/2490926; COATS PK, 1993, FINANC MANAGE, V22, P142, DOI 10.2307/3665934; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Dawson John, 2001, INT REV RETAIL DISTR, V10, P119, DOI 10.1080/095939600342325; DEAKIN EB, 1972, J ACCOUNTING RES, V10, P167, DOI 10.2307/2490225; DEAKIN EB, 1976, ACCOUNT REV, V51, P90; EISENBEIS RA, 1977, J FINANC, V32, P875, DOI 10.2307/2326320; FAN A, 2000, 2000 IEEE INNS ENNS; GENTRY JA, 1985, J ACCOUNTING RES, V23, P146, DOI 10.2307/2490911; GUPTA MC, 1972, J ACCOUNT RES, V10, P77, DOI 10.2307/2490219; HAMER MM, 1983, J ACCOUNTING PUBLIC, V2, P189; Hand D., 1997, CONSTRUCTION ASSESSM; HASTY R, 1997, RETAIL MANAGEMENT; Hosmer Jr DW, 2000, APPL LOGISTIC REGRES; Hunt SD, 1997, J MARKETING, V61, P74, DOI 10.2307/1252088; Hunt SD, 2001, J PUBLIC POLICY MARK, V20, P15, DOI 10.1509/jppm.20.1.15.17296; HUNT SD, 2000, GENERAL THEORY COMPE; FRYDMAN H, 1985, J FINANC, V40, P269, DOI 10.2307/2328060; Knott AM, 2005, STRATEGIC MANAGE J, V26, P617, DOI 10.1002/smj.470; LIBBY R, 1975, J ACCOUNTING RES, V13, P150, DOI 10.2307/2490653; MARAIS ML, 1984, J ACCOUNTING RES, V22, P87, DOI 10.2307/2490861; McCoy HD, 2001, GENET ENG NEWS, V21, P1; MENSAH YM, 1983, ACCOUNT REV, V58, P228; MENSAH YM, 1984, J ACCOUNTING RES, V22, P380, DOI 10.2307/2490719; *MOOD INV SERV INC, 1998, RAT METH IND COMP RA; Moore A.W., 2001, CROSS VALIDATION DET; OHLSON JA, 1980, J ACCOUNTING RES, V18, P109, DOI 10.2307/2490395; Platt H., 1990, J BUSINESS FINANCE A, V17, P31, DOI 10.1111/j.1468-5957.1990.tb00548.x; PLATT HD, 1999, ADV KERNEL METHODS S; Rose Peter S., 1982, J ACCOUNTING AUDITIN, V6, P20; *STAND POORS, 2003, STAND POORS 2003 COR; TAFFLER RJ, 1984, J BANK FINANC, V8, P199, DOI 10.1016/0378-4266(84)90004-9; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; THOMAS L, 2002, CREDIT SCORING ITS A; Trigueiros D., 1996, ACCOUNTING BUSINESS, V26, P347; WILLIAMS WH, 1971, J FINANC QUANT ANAL, V6, P1095, DOI 10.2307/2329608; Zhang GQ, 1999, EUR J OPER RES, V116, P16, DOI 10.1016/S0377-2217(98)00051-4	43	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217			EUR J OPER RES	Eur. J. Oper. Res.	DEC 16	2007	183	3					1595	1606		10.1016/j.ejor.2006.09.101		12	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	197XK	WOS:000248590100049	
J	Wang, B; Jones, GJF; Pan, WF				Wang, Bin; Jones, Gareth J. F.; Pan, Wenfeng			Using online linear classifiers to filter spam emails	PATTERN ANALYSIS AND APPLICATIONS			English	Article						online linear classifier; Perceptron; Winnow; anti-spam filtering	CATEGORIZATION; PERCEPTRON; ALGORITHM; WINNOW	The performance of two online linear classifiers-the Perceptron and Littlestone's Winnow-is explored for two anti-spam filtering benchmark corpora-PU1 and Ling-Spam. We study the performance for varying numbers of features, along with three different feature selection methods: information gain (IG), document frequency (DF) and odds ratio. The size of the training set and the number of training iterations are also investigated for both classifiers. The experimental results show that both the Perceptron and Winnow perform much better when using IG or DF than using odds ratio. It is further demonstrated that when using IG or DF, the classifiers are insensitive to the number of features and the number of training iterations, and not greatly sensitive to the size of training set. Winnow is shown to slightly outperform the Perceptron. It is also demonstrated that both of these online classifiers perform much better than a standard Naive Bayes method. The theoretical and implementation computational complexity of these two classifiers are very low, and they are very easily adaptively updated. They outperform most of the published results, while being significantly easier to train and adapt. The analysis and promising experimental results indicate that the Perceptron and Winnow are two very competitive classifiers for anti-spam filtering.	Chinese Acad Sci, Comp Technol Inst, Beijing, Peoples R China; Dublin City Univ, Sch Comp, Dublin 9, Ireland	Wang, B (reprint author), Chinese Acad Sci, Comp Technol Inst, Beijing, Peoples R China.	wangbin@ict.ac.cn; gareth.jones@computing.dcu.ie; panwenfeng@software.ict.ac.cn					ANDROUTSOPOULOS I, 2004, 20042 NCSR; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P1; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; Androutsopoulos I., 2000, P 23 ANN INT ACM SIG, P160, DOI 10.1145/345508.345569; Bel N, 2003, LECT NOTES COMPUT SC, V2769, P126; Carreras X., 2001, P 4 INT C REC ADV NA, P58; Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Dagan Ido, 1997, P 2 C EMP METH NAT L, P55; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; GROVE AJ, 1997, ANN WORKSH COMP LEAR, P171; Hidalgo J.M.G, 2002, P 2002 ACM S APPL CO, P615; HOFFMAN P, 1998, IMCR008 UBESOL; Kivinen J, 1997, ARTIF INTELL, V97, P325, DOI 10.1016/S0004-3702(97)00039-8; Lewis D.D., 1996, P 19 ANN INT ACM SIG, P298, DOI 10.1145/243199.243277; LIERE R, 1998, LEARNING TEXT CATEGO; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Ng HT, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P67, DOI 10.1145/258525.258537; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Sahami M., 1998, P AAAI WORKSH LEARN, P55; Schneider K, 2003, P 10 C EUR CHAPT ASS, P307; Schutze H., 1995, P 18 ANN INT ACM SIG, P229, DOI 10.1145/215206.215365; Vaughan-Nichols SJ, 2003, IEEE SPECTRUM, V40, P40, DOI 10.1109/MSPEC.2003.1222047; WHITWORTH B, 2004, IEEE COMPUT, V37, P37; Wiener E., 1995, P 4 ANN S DOC AN INF, P317; Xu HQ, 2002, PHYSIOL GENOMICS, V11, P11, DOI 10.1152/physiolgenomics.00060.2001; YANG L, 2002, P 12 CHIN COMP SOC C, P211; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Zhang T, 2001, ADV NEUR IN, V13, P703	29	12	13	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1433-7541			PATTERN ANAL APPL	Pattern Anal. Appl.	NOV	2006	9	4					339	351		10.1007/s10044-006-0045-7		13	Computer Science, Artificial Intelligence	Computer Science	097NS	WOS:000241455300004	
J	Needham, CJ; Bradford, JR; Bulpitt, AJ; Care, MA; Westhead, DR				Needham, Chris J.; Bradford, James R.; Bulpitt, Andrew J.; Care, Matthew A.; Westhead, David R.			Predicting the effect of missense mutations on protein function: analysis with Bayesian networks	BMC BIOINFORMATICS			English	Article							SINGLE NUCLEOTIDE POLYMORPHISMS; AMINO-ACID POLYMORPHISMS; BACTERIOPHAGE-T4 LYSOZYME; LAC REPRESSOR; SNPS; SUBSTITUTIONS; CONSEQUENCES; SEQUENCE; DISEASE	Background: A number of methods that use both protein structural and evolutionary information are available to predict the functional consequences of missense mutations. However, many of these methods break down if either one of the two types of data are missing. Furthermore, there is a lack of rigorous assessment of how important the different factors are to prediction. Results: Here we use Bayesian networks to predict whether or not a missense mutation will affect the function of the protein. Bayesian networks provide a concise representation for inferring models from data, and are known to generalise well to new data. More importantly, they can handle the noisy, incomplete and uncertain nature of biological data. Our Bayesian network achieved comparable performance with previous machine learning methods. The predictive performance of learned model structures was no better than a naive Bayes classifier. However, analysis of the posterior distribution of model structures allows biologically meaningful interpretation of relationships between the input variables. Conclusion: The ability of the Bayesian network to make predictions when only structural or evolutionary data was observed allowed us to conclude that structural information is a significantly better predictor of the functional consequences of a missense mutation than evolutionary information, for the dataset used. Analysis of the posterior distribution of model structures revealed that the top three strongest connections with the class node all involved structural nodes. With this in mind, we derived a simplified Bayesian network that used just these three structural descriptors, with comparable performance to that of an all node network.	Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England; Univ Leeds, Inst Mol & Cellular Biol, Leeds LS2 9JT, W Yorkshire, England	Needham, CJ (reprint author), Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.	chrisn@comp.leeds.ac.uk; J.R.Bradford@leeds.ac.uk; andyb@comp.leeds.ac.uk; M.A.Care98@leeds.ac.uk; D.R.Westhead@leeds.ac.uk					ALBER T, 1987, BIOCHEMISTRY-US, V26, P3754, DOI 10.1021/bi00387a002; Bao L, 2005, BIOINFORMATICS, V21, P2185, DOI 10.1093/bioinformatics/bti365; Beaumont MA, 2004, NAT REV GENET, V5, P251, DOI 10.1038/nrg1318; Cai ZH, 2004, HUM MUTAT, V24, P178, DOI 10.1002/humu.20063; Chasman D, 2001, J MOL BIOL, V307, P683, DOI 10.1006/jmbi.2001.4510; Fawcett T., 2003, ROC GRAPHS NOTES PRA; Ferrer-Costa C, 2002, J MOL BIOL, V315, P771, DOI 10.1006/jmbi.2001.5255; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Heckerman D, 1998, NATO ADV SCI I D-BEH, V89, P301; Herrgard S, 2003, PROTEINS, V53, P806, DOI 10.1002/prot.10458; Husmeier D., 2005, PROBABILISTIC MODELI; JENSEN F, 2001, BAYESIAN NETWORKS DE; Jordan M.I., 1998, LEARNING GRAPHICAL M; Krishnan VG, 2003, BIOINFORMATICS, V19, P2199, DOI 10.1093/bioinformatics/btg297; Leray P., 2004, BNT STRUCTURE LEARNI; MARKIEWICZ P, 1994, J MOL BIOL, V240, P421, DOI 10.1006/jmbi.1994.1458; MURPHY KP, 2001, COMPUTING SCI STAT, P331; Needham CJ, 2006, NAT BIOTECHNOL, V24, P51, DOI 10.1038/nbt0106-51; Ng PC, 2001, GENOME RES, V11, P863, DOI 10.1101/gr.176601; Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509; Pearl J, 2000, CAUSALITY MODELS REA; Ramensky V, 2002, NUCLEIC ACIDS RES, V30, P3894, DOI 10.1093/nar/gkf493; RENNELL D, 1991, J MOL BIOL, V222, P67, DOI 10.1016/0022-2836(91)90738-R; Saunders CT, 2002, J MOL BIOL, V322, P891, DOI 10.1016/S0022-2836(02)00813-6; Sherry ST, 2001, NUCLEIC ACIDS RES, V29, P308, DOI 10.1093/nar/29.1.308; Suckow J, 1996, J MOL BIOL, V261, P509, DOI 10.1006/jmbi.1996.0479; Sunyaev S, 2001, HUM MOL GENET, V10, P591, DOI 10.1093/hmg/10.6.591; Thorisson GA, 2003, NUCLEIC ACIDS RES, V31, P124, DOI 10.1093/nar/gkg052; Verzilli CJ, 2005, J ROY STAT SOC C-APP, V54, P191, DOI 10.1111/j.1467-9876.2005.00478.x; Wang Z, 2001, HUM MUTAT, V17, P263, DOI 10.1002/humu.22	30	12	12	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 6	2006	7								405	10.1186/1471-2105-7-405		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	090HO	WOS:000240941900001	
J	Han, B; Obradovic, Z; Hu, ZZ; Wu, CH; Vucetic, S				Han, Bo; Obradovic, Zoran; Hu, Zhang-Zhi; Wu, Cathy H.; Vucetic, Slobodan			Substring selection for biomedical document classification	BIOINFORMATICS			English	Article							PROTEIN INFORMATION; RESOURCE; TEXT; RETRIEVAL	Motivation: Attribute selection is a critical step in development of document classification systems. As a standard practice, words are stemmed and the most informative ones are used as attributes in classification. Owing to high complexity of biomedical terminology, general-purpose stemming algorithms are often conservative and could also remove informative stems. This can lead to accuracy reduction, especially when the number of labeled documents is small. To address this issue, we propose an algorithm that omits stemming and, instead, uses the most discriminative substrings as attributes. Results: The approach was tested on five annotated sets of abstracts from iProLINKthat report on the experimental evidence about five types of protein post-translational modifications. The experiments showed that Naive Bayes and support vector machine classifiers perform consistently better[with area under the ROC curve (AUC) accuracy in range 0.92-0.97] when usingthe proposed attribute selection than when using attributes obtained by the Porter stemmer algorithm (AUC in 0.86-0.93 range). The proposed approach is particularly useful when labeled clatasets are small. Contact: vucetic@ist.temple.edu Supplementary Information: The supplementary data are available from www.ist.tempie.edu/PIRsupplement.	Temple Univ, Ctr Informat Sci & Technol, Philadelphia, PA 19122 USA; Georgetown Univ, Med Ctr, Dept Biochem & Mol & Cellular Biol, Washington, DC 20007 USA	Vucetic, S (reprint author), Temple Univ, Ctr Informat Sci & Technol, Philadelphia, PA 19122 USA.	vucetic@ist.temple.edu	Crozier, Laura/A-4821-2010				Andrade MA, 1998, BIOINFORMATICS, V14, P600, DOI 10.1093/bioinformatics/14.7.600; Aphinyanaphongs Y, 2005, J AM MED INFORM ASSN, V12, P207, DOI 10.1197/jamia.M1641; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; CODY WJ, 1969, MATH COMPUT, V23, P631, DOI 10.2307/2004390; Dobrokhotov PB, 2003, BIOINFORMATICS, V19, pi91, DOI 10.1093/bioinformatics/btg1011; GHANEM MM, 2003, SIGKDD EXPLORATIONS, V4, P95; Hu ZZ, 2004, COMPUT BIOL CHEM, V28, P409, DOI 10.1016/j.compbiolchem.2004.09.010; Hu ZZ, 2005, BIOINFORMATICS, V21, P2759, DOI 10.1093/bioinformatics/bti390; Joachims T, 1999, ADV KERNEL METHODS S, P41; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Marcotte EM, 2001, BIOINFORMATICS, V17, P359, DOI 10.1093/bioinformatics/17.4.359; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; NENADIC G, 2003, P ACL 2003 WORKSH NA, P121; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; REGEV Y, 2003, SIGKDD EXPLORATIONS, V4, P90; Rice SB, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S22; SHI M, 2003, SIGKDD EXPLOR NEWSLE, V4, P93; Vapnik V., 1995, NATURE STAT LEARNING; WILBUR JW, 2000, P AMIA S, P918; Wu CH, 2006, NUCLEIC ACIDS RES, V34, pD187, DOI 10.1093/nar/gkj161; Wu CH, 2003, NUCLEIC ACIDS RES, V31, P345, DOI 10.1093/nar/gkg040; Yang Y., 1997, P 14 INT C MACH LEAR, P412	22	12	12	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	SEP 1	2006	22	17					2136	2142		10.1093/bioinformatics/btl350		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	083CI	WOS:000240433100012	
J	Kuncheva, LI				Kuncheva, LI			On the optimality of Naive Bayes with dependent binary features	PATTERN RECOGNITION LETTERS			English	Article						statistical pattern recognition; Naive Bayes classifier (NB); optimality of NB; dependent binary features		While Naive Bayes classifier (NB) is Bayes-optimal for independent features, we prove that it is also optimal for two equiprobable classes and two features with equal class-conditional covariances. Although strict optimality does not extend for three features, equal covariances are expected to be beneficial in higher-dimensional spaces. (c) 2005 Elsevier B.V. All rights reserved.	Univ Coll N Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales	Kuncheva, LI (reprint author), Univ Coll N Wales, Sch Informat, Dean St, Bangor LL57 1UT, Gwynedd, Wales.	L.I.Kuncheva@bangor.ac.uk					Devijver P., 1982, PATTERN RECOGNITION; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos P., 1996, P 13 INT C MACH LEAR; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; JAMAIN A, 2005, PATTERN RECOGNITION; Langley P, 1992, P 10 NAT C ART INT, P399; RISH I, 2001, RC21993 IBM TJ WATS; RISH I, 2001, P INT JOINT C ART IN; Sneath PH, 1973, NUMERICAL TAXONOMY; van der Heijden F., 2004, CLASSIFICATION PARAM; WEBB S, 1999, STAT PATTERN RECOGNI; Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019; Zhang H., 2004, P 17 INT FLAIRS C FL	13	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAY	2006	27	7					830	837		10.1016/j.patrec.2005.12.001		8	Computer Science, Artificial Intelligence	Computer Science	030JP	WOS:000236631000015	
J	Lee, M; Wang, WQ; Yu, H				Lee, M; Wang, WQ; Yu, H			Exploring supervised and unsupervised methods to detect topics in biomedical text	BMC BIOINFORMATICS			English	Article							GENES	Background: Topic detection is a task that automatically identifies topics (e.g., "biochemistry" and "protein structure") in scientific articles based on information content. Topic detection will benefit many other natural language processing tasks including information retrieval, text summarization and question answering; and is a necessary step towards the building of an information system that provides an efficient way for biologists to seek information from an ocean of literature. Results: We have explored the methods of Topic Spotting, a task of text categorization that applies the supervised machine-learning technique naive Bayes to assign automatically a document into one or more predefined topics; and Topic Clustering, which apply unsupervised hierarchical clustering algorithms to aggregate documents into clusters such that each cluster represents a topic. We have applied our methods to detect topics of more than fifteen thousand of articles that represent over sixteen thousand entries in the Online Mendelian Inheritance in Man (OMIM) database. We have explored bag of words as the features. Additionally, we have explored semantic features; namely, the Medical Subject Headings (MeSH) that are assigned to the MEDLINE records, and the Unified Medical Language System (UMLS) semantic types that correspond to the MeSH terms, in addition to bag of words, to facilitate the tasks of topic detection. Our results indicate that incorporating the MeSH terms and the UMLS semantic types as additional features enhances the performance of topic detection and the naive Bayes has the highest accuracy, 66.4%, for predicting the topic of an OMIM article as one of the total twenty-five topics. Conclusion: Our results indicate that the supervised topic spotting methods outperformed the unsupervised topic clustering; on the other hand, the unsupervised topic clustering methods have the advantages of being robust and applicable in real world settings.			ml1065@columbia.edu; wwq318@hotmail.com; hong.yu@dbmi.columbia.edu					Andrade MA, 1998, BIOINFORMATICS, V14, P600, DOI 10.1093/bioinformatics/14.7.600; CORPET F, 1988, NUCLEIC ACIDS RES, V16, P10881, DOI 10.1093/nar/16.22.10881; Ehrler F, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S23; Hamosh A, 2005, NUCLEIC ACIDS RES, V33, pD514; HATZIVASSILOGLO.V, 2000, INVESTIGATION LINGUI; HEARTST M, BIOTEXT PROJECT POWE; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; JOACHIMS T, 1998, TEXT CATEGORIZATION, P137; Wilbur W John, 2002, Pac Symp Biocomput, P386; *NIST, 1998, TOP DET TRACK PHAS 2; Raychaudhuri S, 2002, GENOME RES, V12, P203, DOI 10.1101/gr.199701; Rice SB, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S22; Smink LJ, 2005, NUCLEIC ACIDS RES, V33, pD544; Witten I. H., 1999, MANAGING GIGABYTES C; YU H, 2003, ANSWERING OPINION QU; Yu H, 1999, Proc AMIA Symp, P181	16	12	13	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAR 16	2006	7								140	10.1186/1471-2105-7-140		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	048YF	WOS:000237981800001	
J	Tang, YC; Xu, Y				Tang, YC; Xu, Y			Application of fuzzy Naive Bayes and a real-valued genetic algorithm in identification of fuzzy model	INFORMATION SCIENCES			English	Article						fuzzy model; fuzzy Naive Bayes; real-valued genetic algorithm; conditional probability; backing-truck; time series prediction	LOGIC CONTROLLER; KNOWLEDGE ACQUISITION; NEURAL-NETWORKS; CONTROL-SYSTEMS; RULES; SETS; PROBABILITIES	We present a method to identify a fuzzy model from data by using the fuzzy Naive Bayes and a real-valued genetic algorithm. The identification of a fuzzy model is comprised of the extraction of "if-then" rules that is followed by the estimation of their parameters. The involved parameters include those which determine the membership function of fuzzy sets and the certainty factors of fuzzy if-then rules. In our method, as long as the fuzzy partition in the input-output space is given, the certainty factor of each rule is computed with the fuzzy conditional probability of the consequent conditioned on the antecedent by using the fuzzy Naive Bayes, which is a generalization of Naive Bayes. The fuzzy model involves the rules characterized by the highest values of certainty factors. The certainty factor of each rule is the fuzzy conditional probability, and it reflects the inner relationship between the antecedent and the consequent. In order to improve the accuracy of the fuzzy model, the real-valued genetic algorithm is incorporated into our identification process. This process concerns the optimization of the membership functions occurring in the rules. We just involve the parameters of membership function of the fuzzy sets into the real-valued genetic algorithm, since the certainty factor of each rule can be computed automatically. The performance of the model is shown for the backing-truck problem and the prediction of Mackey-Glass time series. (C) 2004 Elsevier Inc. All rights reserved.	Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China; SW Jiaotong Univ, Dept Appl Math, Chengdu 610031, Sichuan, Peoples R China	Tang, YC (reprint author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.	yongchuan@263.net					BLANCO A, 1995, FUZZY SET SYST, V69, P29, DOI 10.1016/0165-0114(94)00250-B; Cheong F, 2000, IEEE T SYST MAN CY B, V30, P31, DOI 10.1109/3477.826945; DRAKOPOULOS JA, 1995, FUZZY SET SYST, V75, P1, DOI 10.1016/0165-0114(94)00341-4; DUBOIS D, 1991, FUZZY SET SYST, V42, P87, DOI 10.1016/0165-0114(91)90091-4; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Kasabov N, 1998, CONTROL CYBERN, V27, P593; Kleiter GD, 1996, ARTIF INTELL, V88, P143, DOI 10.1016/S0004-3702(96)00021-5; KLEITER GD, 1992, ARTIF INTELL, V54, P1, DOI 10.1016/0004-3702(92)90086-D; KONG SG, 1992, IEEE T NEURAL NETWOR, V3, P211, DOI 10.1109/72.125862; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; LEE CC, 1990, IEEE T SYST MAN CYB, V20, P419, DOI 10.1109/21.52552; LEE CC, 1990, IEEE T SYST MAN CYB, V20, P404, DOI 10.1109/21.52551; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Nguyen D. H., 1990, IEEE Control Systems Magazine, V10, DOI 10.1109/37.55119; Nguyen HT, 1997, FUZZY SET SYST, V90, P129, DOI 10.1016/S0165-0114(97)00078-X; Pal K, 1998, CONTROL CYBERN, V27, P521; Park GH, 1998, NEUROCOMPUTING, V18, P91, DOI 10.1016/S0925-2312(97)00071-4; Russo M, 2000, IEEE T EVOLUT COMPUT, V4, P259, DOI 10.1109/4235.873236; Su MC, 2000, FUZZY SET SYST, V112, P85, DOI 10.1016/S0165-0114(98)00180-8; SYLVIA FS, 1993, FUZZY SETS SYSTEMS, V60, P41; Viertl R., 1987, PROBABILITY BAYESIAN, P471; YAGER RR, 1993, IEEE T SYST MAN CYB, V23, P1198, DOI 10.1109/21.247902; YAGER RR, 1995, IEEE T SYST MAN CYB, V25, P1221, DOI 10.1109/21.398683; YAGER RR, 1993, FUZZY SET SYST, V55, P255, DOI 10.1016/0165-0114(93)90252-D; Yeung DS, 1997, FUZZY SET SYST, V88, P299, DOI 10.1016/S0165-0114(96)00052-8; ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4	26	12	13	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	FEB 1	2005	169	3-4					205	226		10.1016/j.ins.2004.05.004		22	Computer Science, Information Systems	Computer Science	894JO	WOS:000226787600002	
J	Huang, HJ; Hsu, CN				Huang, HJ; Hsu, CN			Bayesian classification for data from the same unknown class	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						classification; machine learning; naive Bayes classifier; speaker recognition		In this paper, we address the problem of how to classify a set of query vectors that belong to the same unknown class. Sets of data known to be sampled from the same class are naturally available in many application domains, such as speaker recognition. We refer to these sets as homologous sets. We show how to take advantage of homologous sets in classification to obtain improved accuracy over classifying each query vector individually. Our method, called homologous naive Bayes (HNB), is based on the naive Bayes classifier, a simple algorithm shown to be effective in many application domains. HNB uses a modified classification procedure that classifies multiple instances as a single unit. Compared with a voting method and several other variants of naive Bayes classification, HNB significantly outperforms these methods in a variety of test data sets, even when the number of query vectors in the homologous sets is small. We also report a successful application of HNB to speaker recognition. Experimental results show that HNB can achieve classification accuracy comparable to the Gaussian mixture model (GMM), the most widely used speaker recognition approach, while using less time for both training and classification.	Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 300, Taiwan; Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan	Huang, HJ (reprint author), Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 300, Taiwan.	chunnan@iis.sinica.edu.tw					Almond R.G., 1995, GRAPHICAL BELIEF MOD; Blake C. L., 1998, UCI REPOSITORY MACHI; CESTNIK B, 1991, LECT NOTES ARTIF INT, V482, P138; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DEVETH J, 1995, SPEECH COMMUN, V17, P81, DOI 10.1016/0167-6393(95)00015-G; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DOUGHERTY J, 1985, MACHINE LEARNING; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fukunaga K., INTRO STAT PATTERN R, P97; GISH H, 1996, IEEE SIGNAL PROCESSI, V11, P18; HSU CN, 2000, MACHINE LEARNING; JOHN GH, 1995, P 11 C UNC ART INT, P338; Lee C.-H., 1996, AUTOMATIC SPEECH SPE; Mitchell T.M., 1997, MACHINE LEARNING; PARSA I, 1997, KDD CUP 1997 PRESENT; PRZYBOCKI MA, 1998, WORKSH SPEAK REC ITS; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; ROSS A, 1998, 1ST COURSE PROBABILI; STONE M, 1974, J R STAT SOC B, V36, P111; Wilks S.S., 1962, MATH STAT	22	12	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2002	32	2					137	145				9	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	532DE	WOS:000174455700001	
S	Gama, J		Monard, MC; Sichman, JS		Gama, J			A linear-bayes classifier	ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	International Joint Conference of the 7th Ibero-American Conference on AI/15th Brazilian Symposium on AI	NOV 19-22, 2000	SAO PAULO, BRAZIL	FAPESP, CNPq, CAPES, CTEEP				Naive Bayes is a well known and studied algorithm both in statistics and machine learning. Although its limitations with respect to expressive power, this procedure has a surprisingly good performance in a wide variety of domains, including many where there are clear dependencies between attributes. In this paper we address its main perceived limitation - its inability to deal with attribute dependencies. We present Linear Bayes that uses, for the continuous attributes, a multivariate normal distribution to compute the require probabilities. In this way, the interdependencies between the continuous attributes are considered. On the empirical evaluation, we compare Linear Bayes against a naive-Bayes that discretize continuous attributes, a naive-Bayes that assumes a univariate Gaussian for continuous attributes, and a standard Linear discriminant function. We show that Linear Bayes is a plausible algorithm, that competes quite well against other well established techniques.	Univ Porto, FEP, LIACC, P-4150 Oporto, Portugal	Gama, J (reprint author), Univ Porto, FEP, LIACC, Rua Campo Alegre 823, P-4150 Oporto, Portugal.	jgama@ncc.up.pt	Gama, Joao/A-2070-2008	Gama, Joao/0000-0003-3357-1195			Blake C., 1999, UCI REPOSITORY MACHI; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, MACH LEARN P 12 INT; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN N, 1998, P 15 INT C ICML 98; GAMA J, 1999, LNAI, V1721; John G. H., 1997, THESIS STANFORD U; KITTLER J, 1998, PATTERN ANAL APPL, V1; Kohavi R., 1996, P 2 INT C KNOWL DISC; Kohavi R., 1997, ECML 97; KONONENKO I, 1991, LNAI, V482; LANGLEY P, 1993, LNAI, V667; LANGLEY P, 1999, MACH LEARN P 16 INT; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T.M., 1997, MACHINE LEARNING; Pazzani M. J., 1996, Proceedings ofthe Conference, ISIS '96. Information, Statistics and Induction in Science; Press W. H., 1992, NUMERICAL RECIPES C, V2; Webb G I, 1998, P 11 AUSTR JOINT C A, P285; ZHENG Z, 1998, LNAI, V1398	19	12	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-41276-X	LECT NOTES ARTIF INT			2000	1952						269	279				11	Computer Science, Artificial Intelligence	Computer Science	BU08W	WOS:000174952800028	
J	Farrell, PJ; MacGibbon, B; Tomberlin, TJ				Farrell, PJ; MacGibbon, B; Tomberlin, TJ			Empirical Bayes estimators of small area proportions in multistage designs	STATISTICA SINICA			English	Article						Bootstrap; complex survey design; labour force participation; logistic regression; random effects models	CONFIDENCE-INTERVALS; INFERENCE; MODELS	The importance of small area estimation as a facet of survey sampling cannot be over-emphasized, Of late, there has been an increasing demand for small area statistics in both the public and private sectors. It is widely recognized that direct survey estimates for small areas are likely to be unstable due to the small sample sizes in the areas. This makes it necessary to ''borrow strength'' from related areas to obtain more accurate estimates. In this study, an empirical Bayes methodology for the estimation of small area proportions is proposed, implemented, and evaluated. The basic idea consists of incorporating into a logistic regression model, random effects that are nested in such a way as to reflect the complex structure of a multistage sample design. This yields both point estimates and associated naive measures of accuracy. The latter do not incorporate the uncertainty that arises from estimating the prior distribution of the random effects. We adjust these naively-estimated measures of uncertainty using the bootstrap techniques developed by Laird and Louis (1987). The proposed estimation approach is applied to data from a United States Census to predict local labour force participation rates. Results are compared with those obtained using unbiased and synthetic estimation, as well as a domain-adjusted synthetic estimation approach which incorporates predictor variables at both the individual and local area levels.	ACADIA UNIV,DEPT MATH & STAT,WOLFVILLE,NS B0P 1X0,CANADA; UNIV QUEBEC,DEPT MATH & INFORMAT,MONTREAL,PQ H3C 3P8,CANADA; CONCORDIA UNIV,DEPT DECIS SCI & MIS,MONTREAL,PQ H3G 1M8,CANADA							CARLIN BP, 1990, J AM STAT ASSOC, V85, P105, DOI 10.2307/2289531; Cochran WG, 1997, SAMPLING TECHNIQUES; DATTA GS, 1991, ANN STAT, V19, P1748, DOI 10.1214/aos/1176348369; DEELY JJ, 1981, J AM STAT ASSOC, V76, P833, DOI 10.2307/2287578; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dempster A.P., 1980, P C CENS UND ARL VA, P88; FARRELL PJ, 1991, THESIS MCGILL U MONT; FARRELL PJ, 1994, CAN J STAT, V22, P365, DOI 10.2307/3315598; FAY RE, 1979, J AM STAT ASSOC, V74, P269; GHOSH M, 1994, STAT SCI, V9, P55, DOI 10.1214/ss/1177010647; GONZALEZ ME, 1978, J AM STAT ASSOC, V73, P7, DOI 10.2307/2286509; Gonzalez M.E, 1973, P SOC STAT SECT AM S, P33; Hansen M.H, 1978, P AM STAT ASS SURVEY, P82; LAIRD NM, 1978, BIOMETRIKA, V65, P581; LAIRD NM, 1987, J AM STAT ASSOC, V82, P739, DOI 10.2307/2288778; LEONARD KJ, 1988, THESIS CONCORDIA U M; MACGIBBON B., 1989, SURV METHODOL, V15, P237; Malec D., 1993, CASE STUDIES BAYESIA, P377; MORRIS CN, 1983, J AM STAT ASSOC, V78, P47, DOI 10.2307/2287098; ROBERTS G, 1987, BIOMETRIKA, V74, P1; ROYALL RM, 1970, BIOMETRIKA, V57, P377, DOI 10.2307/2334846; SCOTT A, 1969, J AM STAT ASSOC, V64, P830, DOI 10.2307/2283464; STROUD TWF, 1991, COMMUN STAT THEORY, V20, P13, DOI 10.1080/03610929108830480; TOMBERLIN TJ, 1988, J AM STAT ASSOC, V83, P309; *US BUR CENS, 1984, CENS POP; WONG GY, 1985, J AM STAT ASSOC, V80, P513, DOI 10.2307/2288464	26	12	12	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405			STAT SINICA	Stat. Sin.	OCT	1997	7	4					1065	1083				19	Statistics & Probability	Mathematics	YF243	WOS:A1997YF24300017	
J	Wei, W; Visweswaran, S; Cooper, GF				Wei, Wei; Visweswaran, Shyam; Cooper, Gregory F.			The application of naive Bayes model averaging to predict Alzheimer's disease from genome-wide data	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							SINGLE-NUCLEOTIDE POLYMORPHISMS; GENETIC ASSOCIATION; FEATURE-SELECTION; NETWORKS	Objective Predicting patient outcomes from genome-wide measurements holds significant promise for improving clinical care. The large number of measurements (eg, single nucleotide polymorphisms (SNPs)), however, makes this task computationally challenging. This paper evaluates the performance of an algorithm that predicts patient outcomes from genome-wide data by efficiently model averaging over an exponential number of naive Bayes (NB) models. Design This model-averaged naive Bayes (MANB) method was applied to predict late onset Alzheimer's disease in 1411 individuals who each had 312 318 SNP measurements available as genome-wide predictive features. Its performance was compared to that of a naive Bayes algorithm without feature selection (NB) and with feature selection (FSNB). Measurement Performance of each algorithm was measured in terms of area under the ROC curve (AUC), calibration, and run time. Results The training time of MANB (16.1 s) was fast like NB (15.6 s), while FSNB (1684.2 s) was considerably slower. Each of the three algorithms required less than 0.1 s to predict the outcome of a test case. MANB had an AUG of 0.72, which is significantly better than the AUG of 0.59 by NB (p<0.00001), but not significantly different from the AUG of 0.71 by FSNB. MANB was better calibrated than NB, and FSNB was even better in calibration. A limitation was that only one dataset and two comparison algorithms were included in this study. Conclusion MANB performed comparatively well in predicting a clinical outcome from a high-dimensional genome-wide dataset. These results provide support for including MANB in the methods used to predict outcomes from large, genome-wide datasets.	[Wei, Wei; Visweswaran, Shyam; Cooper, Gregory F.] Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15260 USA; [Visweswaran, Shyam; Cooper, Gregory F.] Univ Pittsburgh, Intelligent Syst Program, Pittsburgh, PA 15260 USA	Cooper, GF (reprint author), Univ Pittsburgh, Dept Biomed Informat, Suite M-183 Vale,200 Meyran Ave, Pittsburgh, PA 15260 USA.	gfc@pitt.edu			NLM [R01-LM010020, HHSN276201000030C]; NSF [IIS-0911032]	The research reported here was funded by NLM grants R01-LM010020 and HHSN276201000030C and NSF grant IIS-0911032.	Aliferis CF, 2010, J MACH LEARN RES, V11, P171; Avramopoulos D, 2009, GENOME MED, V1, DOI 10.1186/gm34; Bennet AM, 2010, J ALZHEIMERS DIS, V22, P129, DOI 10.3233/JAD-2010-100864; Bennett P.N., 2000, CMUCS00155 SCH COMP; Bertram L, 2007, NAT GENET, V39, P17, DOI 10.1038/ng1934; Bertram L, 2010, NEURON, V68, P270, DOI 10.1016/j.neuron.2010.10.013; BIRD TD, 2007, ALZHEIMER DIS OVERVI; Buntine W., 1991, P 7 C UNC ART INT, P52; COON KD, 2007, J CLIN PSYCHIAT, V68, P611; COOPER G, 2010, P FALL S AM MED INF, P127; Dash D., 2002, P 19 INT C MACH LEAR, P91; Dash D, 2004, J MACH LEARN RES, V5, P1177; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Fallin MD, 2010, NEUROGENETICS, V11, P335, DOI 10.1007/s10048-010-0234-9; Goedert M, 2006, SCIENCE, V314, P777, DOI 10.1126/science.1132814; Gorlov IP, 2008, AM J HUM GENET, V82, P100, DOI 10.1016/j.ajhg.2007.09.006; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Hoeting JA, 1999, STAT SCI, V14, P382; KOLLER D, 2009, BAYESIAN MODEL AVERA, P824; Kontkanen P., 1999, P 15 INT C UNC ART I, P334; Ku CS, 2010, J HUM GENET, V55, P195, DOI 10.1038/jhg.2010.19; Li H, 2008, ARCH NEUROL-CHICAGO, V65, P45, DOI 10.1001/archneurol.2007.3; Li QZ, 2010, HUM HERED, V69, P219, DOI 10.1159/000291927; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; Nyholt DR, 2009, EUR J HUM GENET, V17, P147, DOI 10.1038/ejhg.2008.198; RAFTERY A, 1995, BAYESIAN STAT, P323; Reiman EM, 2007, NEURON, V54, P713, DOI 10.1016/j.neuron.2007.05.022; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Schork NJ, 2009, CURR OPIN GENET DEV, V19, P212, DOI 10.1016/j.gde.2009.04.010; WARNER HR, 1961, JAMA-J AM MED ASSOC, V177, P177; Yeung KY, 2005, BIOINFORMATICS, V21, P2394, DOI 10.1093/bioinformatics/bti319; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609	33	11	11	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1067-5027			J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JUL	2011	18	4					370	375		10.1136/amiajnl-2011-000101		6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	783DM	WOS:000292061700007	
J	Melgar, MF; Collins, FS; Sethupathy, P				Melgar, Michael F.; Collins, Francis S.; Sethupathy, Praveen			Discovery of active enhancers through bidirectional expression of short transcripts	GENOME BIOLOGY			English	Article						Transcription; pausing; naive bayes classifier; gene regulation; histone modification; enhancers; chromatin marks; CTCF	RNA-POLYMERASE-II; EMBRYONIC STEM-CELLS; GENE-EXPRESSION; GENOME-WIDE; DROSOPHILA-MELANOGASTER; CHROMATIN STATE; GLOBAL ANALYSIS; HUMAN PROMOTERS; ORGANIZATION; RESOLUTION	Background Long-range regulatory elements, such as enhancers, exert substantial control over tissue-specific gene expression patterns. Genome-wide discovery of functional enhancers in different cell types is important for our understanding of genome function as well as human disease etiology. Results In this study, we developed an in silico approach to model the previously reported phenomenon of transcriptional pausing, accompanied by divergent transcription, at active promoters. We then used this model for large-scale prediction of non-promoter associated bidirectional expression of short transcripts. Our predictions were significantly enriched for DNase hypersensitive sites, histone H3 lysine 27 acetylation (H3K27ac), and other chromatin marks associated with active rather than poised or repressed enhancers. We also detected modest bidirectional expression at binding sites of the CCCTC-factor (CTCF) genome-wide, particularly those that overlap H3K27ac. Conclusions Our findings indicate that the signature of bidirectional expression of short transcripts, learned from promoter-proximal transcriptional pausing, can be used to predict active long-range regulatory elements genome-wide, likely due in part to specific association of RNA polymerase with enhancer regions.	[Melgar, Michael F.; Collins, Francis S.] NHGRI, Genome Technol Branch, NIH, Bethesda, MD 20892 USA; [Sethupathy, Praveen] Univ N Carolina, Dept Genet, Chapel Hill, NC 27599 USA; [Sethupathy, Praveen] Univ N Carolina, Carolina Ctr Genome Sci, Chapel Hill, NC 27599 USA; [Sethupathy, Praveen] Univ N Carolina, Lineberger Comprehens Canc Ctr, Chapel Hill, NC 27599 USA	Collins, FS (reprint author), NHGRI, Genome Technol Branch, NIH, 9000 Rockville Pike, Bethesda, MD 20892 USA.	melgamoose@gmail.com; Francis.Collins@nih.gov; praveen_sethupathy@med.unc.edu			NIH Division of Intramural Research/NHGRI [Z01-HG000024]; NIDDK/NIH [1K99DK091318-01]	The authors thank Rachel L. Goldfeder and Peter S. Chines for generating mouse genome (mm9) mapability data, as well as Michael L. Stitzel, Michael R. Erdos, and other members of the Collins laboratory for helpful discussions, insights, and suggestions for the manuscript. This study was supported by the NIH Division of Intramural Research/NHGRI project number Z01-HG000024 (F.S.C.), and by an NIDDK/NIH K99 grant 1K99DK091318-01 (P.S.).	Alexander RD, 2010, MOL CELL, V40, P582, DOI 10.1016/j.molcel.2010.11.005; [Anonymous], UCSC TABL BROWS; [Anonymous], HUMAN EPIGENOME ATLA; [Anonymous], IMR90 CTCF CHIP CHIP; Chen X, 2008, CELL, V133, P1106, DOI 10.1016/j.cell.2008.04.043; Chernukhin I, 2007, MOL CELL BIOL, V27, P1631, DOI 10.1128/MCB.01993-06; Churchman LS, 2011, NATURE, V469, P368, DOI 10.1038/nature09652; Core LJ, 2008, SCIENCE, V322, P1845, DOI 10.1126/science.1162228; Creyghton MP, 2010, P NATL ACAD SCI USA, V107, P21931, DOI 10.1073/pnas.1016071107; De Santa F, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000384; Ernst J, 2011, NATURE, V473, P43, DOI 10.1038/nature09906; Espinosa JM, 2010, MOL CELL, V40, P507, DOI 10.1016/j.molcel.2010.11.025; Gilchrist DA, 2010, CELL, V143, P540, DOI 10.1016/j.cell.2010.10.004; Hindorff LA, 2009, P NATL ACAD SCI USA, V106, P9362, DOI 10.1073/pnas.0903103106; Kim HD, 2009, SCIENCE, V325, P429, DOI 10.1126/science.1171347; Kim TH, 2005, NATURE, V436, P876, DOI 10.1038/nature03877; Kim TH, 2007, CELL, V128, P1231, DOI 10.1016/j.cell.2006.12.048; Kim TK, 2010, NATURE, V465, P182, DOI 10.1038/nature09033; Komili S, 2008, NAT REV GENET, V9, P38, DOI 10.1038/nrg2223; Levine M, 2011, CELL, V145, P502, DOI 10.1016/j.cell.2011.04.021; Li J, 2011, CURR OPIN GENET DEV, V21, P231, DOI 10.1016/j.gde.2011.01.010; Maniatis T, 2002, NATURE, V416, P499, DOI 10.1038/416499a; Mikkelsen TS, 2007, NATURE, V448, P553, DOI 10.1038/nature06008; Min IM, 2011, GENE DEV, V25, P742, DOI 10.1101/gad.2005511; Muse GW, 2007, NAT GENET, V39, P1507, DOI 10.1038/ng.2007.21; Nechaev S, 2010, SCIENCE, V327, P335, DOI 10.1126/science.1181421; Nica AC, 2010, PLOS GENET, V6, DOI 10.1371/journal.pgen.1000895; Nicolae DL, 2010, PLOS GENET, V6, DOI 10.1371/journal.pgen.1000888; Oesterreich FC, 2010, MOL CELL, V40, P571, DOI 10.1016/j.molcel.2010.11.004; Ohlsson R, 2010, BIOESSAYS, V32, P37, DOI 10.1002/bies.200900118; Ong CT, 2011, NAT REV GENET, V12, P283, DOI 10.1038/nrg2957; Palmer Adam C, 2011, Transcription, V2, P9, DOI 10.4161/trns.2.1.13511; Phillips JE, 2009, CELL, V137, P1194, DOI 10.1016/j.cell.2009.06.001; Preker P, 2008, SCIENCE, V322, P1851, DOI 10.1126/science.1164096; Rada-Iglesias A, 2011, NATURE, V470, P279, DOI 10.1038/nature09692; Roeder RG, 2005, FEBS LETT, V579, P909, DOI 10.1016/j.febslet.2004.12.007; ROUGVIE AE, 1988, CELL, V54, P795, DOI 10.1016/S0092-8674(88)91087-2; Schnetz MP, 2009, GENOME RES, V19, P590, DOI 10.1101/gr.086983.108; Schwartz S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016685; Seila AC, 2008, SCIENCE, V322, P1849, DOI 10.1126/science.1162253; Song L, 2010, COLD SPRING HARB PRO, V2010; Stitzel ML, 2010, CELL METAB, V12, P443, DOI 10.1016/j.cmet.2010.09.012; Wada Y, 2009, P NATL ACAD SCI USA, V106, P18357, DOI 10.1073/pnas.0902573106; Wang D, 2011, NATURE; Wyrick JJ, 2002, CURR OPIN GENET DEV, V12, P130, DOI 10.1016/S0959-437X(02)00277-0; Zeitlinger J, 2007, NAT GENET, V39, P1512, DOI 10.1038/ng.2007.26; Zentner GE, 2011, GENOME RES, V21, P1273, DOI 10.1101/gr.122382.111; Zhang Y, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-9-r137	48	11	11	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1474-7596			GENOME BIOL	Genome Biol.		2011	12	11							R113	10.1186/gb-2011-12-11-r113		35	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	904FB	WOS:000301178400004	
J	Katsikopoulos, KV; Schooler, LJ; Hertwig, R				Katsikopoulos, Konstantinos V.; Schooler, Lael J.; Hertwig, Ralph			The Robust Beauty of Ordinary Information	PSYCHOLOGICAL REVIEW			English	Article						inductive inference; heuristics; take-the-best; robustness; bootstrapping	FRUGAL HEURISTICS; DECISION-MAKING; LINEAR-MODELS; CHOICE; RATIONALITY; INFERENCE; VARIABLES; RULES	Heuristics embodying limited information search and noncompensatory processing of information can yield robust performance relative to computationally more complex models. One criticism raised against heuristics is the argument that complexity is hidden in the calculation of the cue order used to make predictions. We discuss ways to order cues that do not entail individual learning. Then we propose and test the thesis that when orders are learned individually, people's necessarily limited knowledge will curtail computational complexity while also achieving robustness. Using computer simulations, we compare the performance of the take-the-best heuristic with dichotomized or undichotomized cues to benchmarks such as the naive Bayes algorithm across 19 environments. Even with minute sizes of training sets, take-the-best using undichotomized cues excels. For 10 environments, we probe people's intuitions about the direction of the correlation between cues and criterion. On the basis of these intuitions, in most of the environments take-the-best achieves the level of performance that would be expected from learning cue orders from 50% of the objects in the environments. Thus, ordinary information about cues either gleaned from small training sets or intuited can support robust performance without requiring Herculean computations.	[Katsikopoulos, Konstantinos V.; Schooler, Lael J.] Max Planck Inst Human Dev, Ctr Adapt Behav & Cognit, D-14195 Berlin, Germany; [Katsikopoulos, Konstantinos V.] MIT, Dept Mech Engn, Cambridge, MA 02139 USA; [Katsikopoulos, Konstantinos V.] MIT, Engn Syst Div, Cambridge, MA 02139 USA; [Hertwig, Ralph] Univ Basel, Fac Psychol, Basel, Switzerland	Katsikopoulos, KV (reprint author), Max Planck Inst Human Dev, Ctr Adapt Behav & Cognit, Lentzeallee 94, D-14195 Berlin, Germany.	katsikop@mpib-berlin.mpg.de	X, Simon/F-4678-2011; Katsikopoulos, Konstantinos/B-6356-2012				Brandstatter E, 2006, PSYCHOL REV, V113, P409, DOI 10.1037/0033-295X.113.2.409; BRUNSWIK E, 1955, PSYCHOL REV, V62, P193, DOI 10.1037/h0047470; CHAPMAN LJ, 1969, J ABNORM PSYCHOL, V74, P271, DOI 10.1037/h0027592; Chater N, 2003, ORGAN BEHAV HUM DEC, V90, P63, DOI 10.1016/S0749-5978(02)00508-3; CONDORCET N., 1785, ESSAI APPL ANAL PROB; Czerlinski J., 1999, SIMPLE HEURISTICS MA, P97; DAWES RM, 1979, AM PSYCHOL, V34, P571, DOI 10.1037//0003-066X.34.7.571; DOUGHERTY MR, 2008, PSYCHOL REV, V115, P119; Garcia-Retamero R, 2007, Q J EXP PSYCHOL, V60, P1197, DOI 10.1080/17470210600937528; GARCIARETAMERO R, SOCIAL HEUR IN PRESS; GIGERENZER G, 1991, PSYCHOL REV, V98, P506, DOI 10.1037/0033-295X.98.4.506; Gigerenzer G, 2009, TOP COGN SCI, V1, P107, DOI 10.1111/j.1756-8765.2008.01006.x; Gigerenzer G., 1999, SIMPLE HEURISTICS MA; Gigerenzer G, 2008, PSYCHOL REV, V115, P230, DOI 10.1037/0033-295X.115.1.230; Goldstein DG, 2002, PSYCHOL REV, V109, P75, DOI 10.1037//0033-295X.109.1.75; Hastie R, 2005, PSYCHOL REV, V112, P494, DOI 10.1037/0033-295X.112.2.494; Hertwig R, 2008, J EXP PSYCHOL LEARN, V34, P1191, DOI 10.1037/a0013025; Hogarth RM, 2007, PSYCHOL REV, V114, P733, DOI 10.1037/0033-295X.114.3.733; Hogarth RM, 2005, J MATH PSYCHOL, V49, P115, DOI 10.1016/j.jmp.2005.01.001; Irwin JR, 2003, J MARKETING RES, V40, P366, DOI 10.1509/jmkr.40.3.366.19237; Juslin P, 2002, COGNITIVE SCI, V26, P563, DOI 10.1016/S0364-0213(02)00083-6; Katsikopoulos KV, 2006, J MATH PSYCHOL, V50, P488, DOI 10.1016/j.jmp.2006.06.001; Lee MD, 2004, PSYCHON B REV, V11, P343, DOI 10.3758/BF03196581; Newell BR, 2005, TRENDS COGN SCI, V9, P11, DOI 10.1016/j.tics.2004.11.005; Payne J.W., 1993, ADAPTIVE DECISION MA; Rakow T, 2004, THINK REASONING, V10, P1, DOI [10.1080/13546780342000016, 10.1080/134546780342000016]; Schooler LJ, 2005, PSYCHOL REV, V112, P610, DOI 10.1037/0033-295X.112.3.610; SIMON HA, 1956, PSYCHOL REV, V63, P129, DOI 10.1037/h0042769; TVERSKY A, 1972, PSYCHOL REV, V79, P281, DOI 10.1037/h0032955; Waldmann MR, 2006, CURR DIR PSYCHOL SCI, V15, P307, DOI 10.1111/j.1467-8721.2006.00458.x	30	11	12	AMER PSYCHOLOGICAL ASSOC	WASHINGTON	750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA	0033-295X			PSYCHOL REV	Psychol. Rev.	OCT	2010	117	4					1259	1266		10.1037/a0020418		8	Psychology; Psychology, Multidisciplinary	Psychology	673WC	WOS:000283693900010	
S	Behmo, R; Marcombes, P; Dalalyan, A; Prinet, V		Daniilidis, K; Maragos, P; Paragios, N		Behmo, Regis; Marcombes, Paul; Dalalyan, Arnak; Prinet, Veronique			Towards Optimal Naive Bayes Nearest Neighbor	COMPUTER VISION-ECCV 2010, PT IV	Lecture Notes in Computer Science		English	Proceedings Paper	11th European Conference on Computer Vision	SEP 05-11, 2010	Heraklion, GREECE	Inst Natl Rech Informat & Automat, Google, Microsoft Res, Technicolor, Adobe, DynaVox Mayer-Johnson, Eur Res Consortium Informat Math, Gen Elect, IBM, Johnson Controls, Point Grey, Univ Houston, Siemens			CLASSIFICATION	Naive Bayes Nearest Neighbor (NBNN) is a feature-based image classifier that achieves impressive degree of accuracy [1] by exploiting 'Image-to-Class' distances and by avoiding quantization of local image descriptors. It is based on the hypothesis that each local descriptor is drawn from a class-dependent probability measure. The density of the latter is estimated by the non-parametric kernel estimator, which is further simplified under the assumption that the normalization factor is class-independent. While leading to significant simplification, the assumption underlying the original NBNN is too restrictive and considerably degrades its generalization ability. The goal of this paper is to address this issue. As we relax the incriminated assumption we are faced with a parameter selection problem that we solve by hinge-loss minimization. We also show that our modified formulation naturally generalizes to optimal combinations of feature types. Experiments conducted on several datasets show that the gain over the original NBNN may attain up to 20 percentage points. We also take advantage of the linearity of optimal NBNN to perform classification by detection through efficient sub-window search [2], with yet another performance gain. As a result, our classifier outperforms - in terms of misclassification error - methods based on support vector machine and bags of quantized features on some datasets.	[Behmo, Regis; Marcombes, Paul; Prinet, Veronique] Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing 100864, Peoples R China	Behmo, R (reprint author), Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing 100864, Peoples R China.		Dalalyan, Arnak/G-7853-2011	Dalalyan, Arnak/0000-0003-4337-9500			Boiman O., 2008, CVPR; Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517; Bosch A., 2007, ICCV; BOSCH A, 2007, INT C IM VID RETR IC; Dong W., 2008, CIKM, P669; Fei-Fei L., 2006, T PAMI, V28, P594; Fei-fei L., 2005, CVPR; Harzallah H., 2009, INT C COMP VIS; Jegou H., 2010, IEEE T PATT IN PRESS; Jegou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2; Lampert C. H., 2008, CVPR; Lazebnik S., 2006, CVPR; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Ling H., 2007, ICCV; LOWE D, 2003, IJCV; Marszalek M., 2007, VIS REC CHALL WORKSH; Marszalek M., 2007, CVPR; Moosmann F., 2006, NEURAL INFORM PROCES; Muja M., 2009, VISAPP; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; OPELT A, 2004, PAMI, V28; STONE C, 1983, RECENT ADV STAT; VANDE S, 2010, T PAMI; Varma M., 2007, ICCV; YIANILOS P, 1993, SODA; Yuan JS, 2009, PROC CVPR IEEE, P2434; Zhang H., 2006, CVPR	27	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15560-4	LECT NOTES COMPUT SC			2010	6314		IV				171	184				14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BTD60	WOS:000286578100013	
J	Fan, LW; Poh, KL; Zhou, P				Fan, Liwei; Poh, Kim-Leng; Zhou, Peng			A sequential feature extraction approach for naive bayes classification of microarray data	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Microarray data; Naive Bayes; Feature extraction; Independent component analysis (ICA); Stepwise regression	INDEPENDENT COMPONENT ANALYSIS; ECG BEAT CLASSIFICATION; CANCER CLASSIFICATION; FEATURE-SELECTION; GENE SELECTION; PREDICTION; REGRESSION; NETWORK	Accurate classification of microarray data plays a vital role in cancer prediction and diagnosis. Previous Studies have demonstrated the usefulness of naive Bayes classifier in solving various classification problems. In microarray data analysis, however, the conditional independence assumption embedded in the classifier itself and the characteristics of microarray data, e.g. the extremely high dimensionality, may severely affect the classification performance of naive Bayes classifier. This paper presents a sequential feature extraction approach for naive Bayes classification of microarray data. The proposed approach consists of feature selection by stepwise regression and feature transformation by class-conditional independent component analysis. Experimental results on five microarray datasets demonstrate the effectiveness of the proposed approach in improving the performance of naive Bayes classifier in microarray data analysis. (C) 2009 Elsevier Ltd. All rights reserved.	[Fan, Liwei; Poh, Kim-Leng] Natl Univ Singapore, Dept Ind & Syst Engn, Singapore 119260, Singapore; [Zhou, Peng] Nanjing Univ Aeronaut & Astronaut, Coll Econ & Management, Nanjing 210016, Peoples R China	Fan, LW (reprint author), Natl Univ Singapore, Dept Ind & Syst Engn, 10 Kent Ridge Crescent, Singapore 119260, Singapore.	g0600308@nus.edu.sg	Zhou, Peng/A-6527-2012				Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054; Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004; FAN L, 2008, ENCY ARTIFICIAL INTE, V3, P879; Fan LW, 2007, LECT NOTES COMPUT SC, V4507, P16; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M, 2007, KNOWL-BASED SYST, V20, P120, DOI 10.1016/j.knosys.2006.11.008; Hsu CC, 2008, EXPERT SYST APPL, V35, P1080, DOI 10.1016/j.eswa.2007.08.031; Huang XH, 2003, BIOINFORMATICS, V19, P2072, DOI 10.1093/bioinformatics/btg283; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; Kelemen A, 2003, IEEE IJCNN, P1769; Kim KJ, 2004, NEUROCOMPUTING, V61, P361, DOI 10.1016/j.neucom.2003.11.008; LANGLEY P, 1992, P INT C ART INT; Lin KS, 2009, EXPERT SYST APPL, V36, P3327, DOI 10.1016/j.eswa.2008.01.068; Park HS, 2007, INT J COMPUT MATH, V84, P653, DOI 10.1080/00207160701294384; Sandberg R, 2001, GENOME RES, V11, P1404, DOI 10.1101/gr.186401; Vitria J, 2007, IEEE T SYST MAN CY C, V37, P32, DOI 10.1109/TSMCC.2006.876043; Wong TT, 2008, EXPERT SYST APPL, V34, P375, DOI 10.1016/j.eswa.2006.09.005; YU SN, 2008, EXPERT SYSTEMS APPL, V36, P2088; Yu SN, 2008, EXPERT SYST APPL, V34, P2841, DOI 10.1016/j.eswa.2007.05.006; Yu SN, 2007, EXPERT SYST APPL, V33, P824, DOI 10.1016/j.eswa.2006.07.002; Zheng CH, 2006, NEUROCOMPUTING, V69, P2407, DOI 10.1016/j.neucom.2006.02.006	29	11	11	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	AUG	2009	36	6					9919	9923		10.1016/j.eswa.2009.01.075		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	445YE	WOS:000266086600039	
J	Jiang, LX; Li, CQ; Cai, ZH				Jiang, Liangxiao; Li, Chaoqun; Cai, Zhihua			Learning decision tree for ranking	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						Ranking; Class probability estimation; Decision trees; Voting; Similarity-weighted voting; Naive Bayes		Decision tree is one of the most effective and widely used methods for classification. However, many real-world applications require instances to be ranked by the probability of class membership. The area under the receiver operating characteristics curve, simply AUC, has been recently used as a measure for ranking performance of learning algorithms. In this paper, we present two novel class probability estimation algorithms to improve the ranking performance of decision tree. Instead of estimating the probability of class membership using simple voting at the leaf where the test instance falls into, our algorithms use similarity-weighted voting and naive Bayes. We design empirical experiments to verify that our new algorithms significantly outperform the recent decision tree ranking algorithm C4.4 in terms of AUC.	[Jiang, Liangxiao; Cai, Zhihua] China Univ Geosci, Fac Comp Sci, Wuhan 430074, Peoples R China; [Li, Chaoqun] China Univ Geosci, Fac Math, Wuhan 430074, Peoples R China	Jiang, LX (reprint author), China Univ Geosci, Fac Comp Sci, Wuhan 430074, Peoples R China.	ljiang@cug.edu.cn	Jiang, Liangxiao /D-1237-2012		Research Foundation for Outstanding Young Teachers, China University of Geosciences (Wuhan) [CUGQNL0505]	We thank Yuanyuan Guo (a PhD student in Canada University of New Brunswick) and anonymous reviewers for their valuable comments and suggestions. The project is supported by the Research Foundation for Outstanding Young Teachers, China University of Geosciences (Wuhan) (No. CUGQNL0505).	Frank E., 2003, P C UNC ART INT, P249; Jian MY, 2005, PULM PHARMACOL THER, V18, P291, DOI 10.1016/j.pupt.2004.12.014; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Nadeau C., 1999, ADV NEURAL INFORMATI, P307; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Provost F., 1998, P 15 INT C MACH LEAR, P445; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rosset S, 2007, KNOWL INF SYST, V12, P331, DOI 10.1007/s10115-006-0037-3; Thabtah FA, 2006, KNOWL INF SYST, V9, P109, DOI 10.1007/s10115-005-0213-x; Witten Ian H., 2005, DATA MINING PRACTICA; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Zhang H, 2005, INT J PATTERN RECOGN, V19, P183, DOI 10.1142/S0218001405003983; Zhang H, 2006, PATTERN RECOGN LETT, V27, P892, DOI 10.1016/j.patrec.2005.10.013	13	11	11	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	JUL	2009	20	1					123	135		10.1007/s10115-008-0173-z		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	462PG	WOS:000267367500006	
J	Klon, AE				Klon, Anthony E.			Bayesian Modeling in Virtual High Throughput Screening	COMBINATORIAL CHEMISTRY & HIGH THROUGHPUT SCREENING			English	Article						Virtual screening; machine learning; naive bayes	PROTEIN-LIGAND DOCKING; INCREMENTAL CONSTRUCTION ALGORITHM; BIOACTIVE REFERENCE STRUCTURES; SIMILAR BIOLOGICAL-ACTIVITY; EMPIRICAL SCORING FUNCTION; MOLECULAR SIMILARITY; FLEXIBLE DOCKING; CHEMICAL DATABASES; ACCURATE DOCKING; HIV-1 PROTEASE	Naive Bayesian classifiers are a relatively recent addition to the arsenal of tools available to computational chemists. These classifiers fall into a class of algorithms referred to broadly as machine learning algorithms. Bayesian classifiers may be used in conjunction with classical modeling techniques to assist in the rapid virtual screening of large compound libraries in a systematic manner with a minimum of human intervention. This approach allows computational scientists to concentrate their efforts on their core strengths of model building. Bayesian classifiers have an added advantage of being able to handle a variety of numerical or binary data such as physicochemical properties or molecular fingerprints, making the addition of new parameters to existing models a relatively straightforward process. As a result, during a drug discovery project these classifiers can better evolve with the needs of the projects from general models in the lead finding stages to increasingly precise models in the lead optimization stages that are of particular interest to a specific medicinal chemistry team. Although other machine learning algorithms abound, Bayesian classifiers have been shown to compare favorably under most working conditions and have been shown to be tolerant of noisy experimental data.	[Klon, Anthony E.] Pharmacopeia Drug Discovery Inc, Dept Mol Modeling, Princeton, NJ 08543 USA	Klon, AE (reprint author), Locus Pharmaceut Inc, 4 Valley Sq,512 E Township Line Rd, Blue Bell, PA 19422 USA.	aklon@locuspharma.com					Bayes T., 1793, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSTL.1763.0053; Bender A, 2006, J CHEM INF MODEL, V46, P2445, DOI 10.1021/ci600197y; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Bender A, 2005, J BIOMOL SCREEN, V10, P658, DOI 10.1177/1087057105281048; Bender A, 2004, J CHEM INF COMP SCI, V44, P1708, DOI 10.1021/ci0498719; Bender A, 2004, J MED CHEM, V47, P6569, DOI 10.1021/jm049611i; Bissantz C, 2004, J CHEM INF COMP SCI, V44, P1162, DOI 10.1021/ci034181a; Bissantz C, 2000, J MED CHEM, V43, P4759, DOI 10.1021/jm001044l; BOHM HJ, 1994, J COMPUT AID MOL DES, V8, P243, DOI 10.1007/BF00126743; Bohm HJ, 1998, J COMPUT AID MOL DES, V12, P309, DOI 10.1023/A:1007999920146; Briem H, 1996, J MED CHEM, V39, P3401, DOI 10.1021/jm950800y; Bursulaya BD, 2003, J COMPUT AID MOL DES, V17, P755, DOI 10.1023/B:JCAM.0000017496.76572.6f; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Cavasotto CN, 2004, J MOL BIOL, V337, P209, DOI 10.1016/j.jmb.2004.01.003; Charifson PS, 1999, J MED CHEM, V42, P5100, DOI 10.1021/jm990352k; Chen B, 2007, J COMPUT AID MOL DES, V21, P53, DOI 10.1007/s10822-006-9096-5; Clark RD, 2002, J MOL GRAPH MODEL, V20, P281, DOI 10.1016/S1093-3263(01)00125-5; Cotesta S, 2005, PROTEINS, V60, P629, DOI 10.1002/prot.20473; DAVIES JW, 2006, CURR OPIN CHEM BIOL, V10, P1; Diller DJ, 2003, J MED CHEM, V46, P4638, DOI 10.1021/jm020503a; Eldridge MD, 1997, J COMPUT AID MOL DES, V11, P425, DOI 10.1023/A:1007996124545; Ewing TJA, 2001, J COMPUT AID MOL DES, V15, P411, DOI 10.1023/A:1011115820450; Fernandez-Recio J, 2003, PROTEINS, V52, P113, DOI 10.1002/prot.10383; Friesner RA, 2004, J MED CHEM, V47, P1739, DOI 10.1021/jm0306430; GEHLHAAR DK, 1995, CHEM BIOL, V2, P317, DOI 10.1016/1074-5521(95)90050-0; Glick M, 2003, MOL PHYS, V101, P1325, DOI 10.1080/0026897031000099862; Glick M, 2006, J CHEM INF MODEL, V46, P193, DOI 10.1021/ci050374h; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; GOODFORD PJ, 1985, J MED CHEM, V28, P849, DOI 10.1021/jm00145a002; Halgren TA, 2004, J MED CHEM, V47, P1750, DOI 10.1021/jm030644s; Hall L. H., 1991, REV COMPUTATIONAL CH, P367, DOI 10.1002/9780470125793.ch9; Hall L.H., 1999, MOL STRUCTURE DESCRI; Hert J, 2006, J CHEM INF MODEL, V46, P462, DOI 10.1021/ci050348j; Hert J, 2004, J CHEM INF COMP SCI, V44, P1177, DOI 10.1021/ci034231b; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; Hoffmann D, 1999, J MED CHEM, V42, P4422, DOI 10.1021/jm991090p; Irwin JJ, 2005, J CHEM INF MODEL, V45, P177, DOI 10.1021/ci049714+; Jacobsson M, 2003, J MED CHEM, V46, P5781, DOI 10.1021/jm030896t; Jain AN, 1996, J COMPUT AID MOL DES, V10, P427, DOI 10.1007/BF00124474; Jones G, 1997, J MOL BIOL, V267, P727, DOI 10.1006/jmbi.1996.0897; Klon AE, 2004, J MED CHEM, V47, P4356, DOI 10.1021/jm049970d; Klon AE, 2004, J CHEM INF COMP SCI, V44, P2216, DOI 10.1021/ci0497861; Klon AE, 2006, J CHEM INF MODEL, V46, P1945, DOI 10.1021/ci0601315; Klon AE, 2004, J MED CHEM, V47, P2743, DOI 10.1021/jm030363k; Klon AE, 2007, J CHEM INF MODEL, V47, P1354, DOI 10.1021/ci7000204; Kramer B, 1999, PROTEINS, V37, P228, DOI 10.1002/(SICI)1097-0134(19991101)37:2<228::AID-PROT8>3.0.CO;2-8; KUNTZ ID, 1982, J MOL BIOL, V161, P269, DOI 10.1016/0022-2836(82)90153-X; Labute P, 2002, COMB CHEM HIGH T SCR, V5, P135; LABUTE P, 1999, BIOC P 1999 PAC S, P444; Lajiness MS, 2004, J MED CHEM, V47, P4891, DOI 10.1021/jm049740z; Lemmen C, 1998, J MED CHEM, V41, P4502, DOI 10.1021/jm981037l; Lessel UF, 2000, J CHEM INF COMP SCI, V40, P246, DOI 10.1021/ci990439e; Martin YC, 2002, J MED CHEM, V45, P4350, DOI 10.1021/jm020155c; McMartin C, 1997, J COMPUT AID MOL DES, V11, P333, DOI 10.1023/A:1007907728892; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Muegge I, 1999, J MED CHEM, V42, P791, DOI 10.1021/jm980536j; Nidhi, 2006, J CHEM INF MODEL, V46, P1124, DOI 10.1021/ci060003g; Plewczynski D, 2006, J CHEM INF MODEL, V46, P1098, DOI 10.1021/ci050519k; Prathipati P, 2006, J CHEM INF MODEL, V46, P39, DOI 10.1021/ci050120w; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rarey M, 1996, J MOL BIOL, V261, P470, DOI 10.1006/jmbi.1996.0477; Rarey M, 1995, Proc Int Conf Intell Syst Mol Biol, V3, P300; Rarey M, 1996, J COMPUT AID MOL DES, V10, P41, DOI 10.1007/BF00124464; Rarey M, 1998, J COMPUT AID MOL DES, V12, P471, DOI 10.1023/A:1008068904628; Rarey M, 1997, J COMPUT AID MOL DES, V11, P369, DOI 10.1023/A:1007913026166; Rogers D, 2005, J BIOMOL SCREEN, V10, P682, DOI 10.1177/1087057105281365; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P854, DOI 10.1021/ci00020a020; Sanner MF, 1996, BIOPOLYMERS, V38, P305, DOI 10.1002/(SICI)1097-0282(199603)38:3<305::AID-BIP4>3.0.CO;2-Y; Schapira M, 2003, J MED CHEM, V46, P3045, DOI 10.1021/jm0300173; Schuffenhauer A, 2005, CURR TOP MED CHEM, V5, P751, DOI 10.2174/1568026054637700; Sheridan RP, 2001, J CHEM INF COMP SCI, V41, P1395, DOI 10.1021/ci0100144; Sun HM, 2004, J CHEM INF COMP SCI, V44, P1506, DOI 10.1021/ci049917y; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P1136, DOI 10.1021/ci025515j; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; TODESCHINI R, 2005, TALETE SRL; Truchon JF, 2007, J CHEM INF MODEL, V47, P488, DOI 10.1021/ci600426e; von Korff M, 2006, J CHEM INF MODEL, V46, P536, DOI 10.1021/ci050358k; Wang RX, 2001, J CHEM INF COMP SCI, V41, P1422, DOI 10.1021/ci010025x; Warren GL, 2006, J MED CHEM, V49, P5912, DOI 10.1021/jm050362n; Witten I.H., 2000, DATA MINING PRACTICA; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Xing L, 2002, J CHEM INF COMP SCI, V42, P796, DOI 10.1021/ci010315d; Yoon S, 2005, J COMPUT AID MOL DES, V19, P483, DOI 10.1007/s10822-005-9002-6	83	11	11	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1386-2073			COMB CHEM HIGH T SCR	Comb. Chem. High Throughput Screen	JUN	2009	12	5					469	483				15	Biochemical Research Methods; Chemistry, Applied; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	452FS	WOS:000266526200003	
J	Backus, BT				Backus, Benjamin T.			The Mixture of Bernoulli Experts: A theory to quantify reliance on cues in dichotomous perceptual decisions	JOURNAL OF VISION			English	Article						cue combination; cue recruitment; cue learning; bistability; ambiguous figure; perceptual dichotomy; appearance; sensory fusion; machine learning; Bayes; naive Bayes; Bayes rule	STEREOSCOPIC SLANT PERCEPTION; STRUCTURE-FROM-MOTION; PROBABILITY-DISTRIBUTIONS; TEXTURE; MODELS; COMBINATION; INTEGRATION; STEREOPSIS; VIEWPOINT; ILLUSIONS	The appearances of perceptually bistable stimuli can by definition be reported with confidence, so these stimuli may be useful to investigate how visual cues are learned and combined to construct visual appearance. However, interpreting experimental data (percent of trials seen one way or the other) requires a theoretically motivated measure of cue effectiveness. Here we describe a simple Bayesian theory for dichotomous perceptual decisions: the Mixture of Bernoulli Experts or MBE. In this theory, a cue's subjective reliability is the product of a weight and an estimate of the cue's ecological validity. The theory (1) justifies the use of probit analysis to measure the system's reliance on a cue and (2) enables hypothesis testing. To illustrate, we used apparent 3D rotation direction in perceptually ambiguous Necker cube movies to test whether the visual system relied on a newly recruited cue (position of the stimulus within the visual field) to the same extent when a long-trusted cue (binocular disparity) was present or not present in the display. For six trainees, reliance on the newly recruited cue was similar whether or not the long-trusted cue was present, suggesting that the visual system assumed the new cue to be conditionally independent.	[Backus, Benjamin T.] SUNY Coll Optometry, Dept Vis Sci, New York, NY 10010 USA	Backus, BT (reprint author), SUNY Optometry, 33 W 42nd St, New York, NY 10036 USA.	bbackus@sunyopt.edu					Attneave F, 1971, Sci Am, V225, P63; Backus BT, 2007, VISION RES, V47, P919, DOI 10.1016/j.visres.2006.12.008; Backus BT, 1999, PERCEPTION, V28, P217, DOI 10.1068/p2753; BARLOW H, 1990, VISION RES, V30, P1561, DOI 10.1016/0042-6989(90)90144-A; BELLINGHAM WP, 1985, ANIM LEARN BEHAV, V13, P152, DOI 10.3758/BF03199268; Bradley DC, 1998, NATURE, V392, P714; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; Brunswik E., 1956, PERCEPTION REPRESENT; Clark J. J., 1990, DATA FUSION SENSORY; Clemen RT, 1999, RISK ANAL, V19, P187, DOI 10.1023/A:1006917509560; COOMBS CC, 1970, MATH PSYCHOL ELEMENT, P165; Dietterich T.G., 2002, LECT NOTES COMPUTER, P15; Dodd JV, 2001, J NEUROSCI, V21, P4809; DOMINGOS P, 1996, 13 INT C MACH LEARN; DOSHER BA, 1986, VISION RES, V26, P973, DOI 10.1016/0042-6989(86)90154-9; Fechner G. T, 1860, ELEMENTE PSYCHOPHYSI; Feldman J, 2001, PERCEPT PSYCHOPHYS, V63, P1171, DOI 10.3758/BF03194532; Feldman J, 2006, COGNITION, V99, P131, DOI 10.1016/j.cognition.2004.12.008; Fine I, 2002, J VISION, V2, P190, DOI 10.1167/2.2.5; Finney DJ, 1971, PROBIT ANAL; Foster DP, 1999, GAME ECON BEHAV, V29, P7, DOI 10.1006/game.1999.0740; GADDUM JH, 1933, MED RES COUNCIL SPEC, V183; Gallistel C. R., 1990, ORG LEARNING; Geisler WS, 2002, NAT NEUROSCI, V5, P508, DOI 10.1038/nn0602-508; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; GEISLER WS, 1989, PSYCHOL REV, V96, P267, DOI 10.1037//0033-295X.96.2.267; Gelman A, 1995, BAYESIAN DATA ANAL; Good I. J., 1950, PROBABILITY WEIGHING; GREEN DM, 1966, SIGNAL DETECTION THE; Haijiang Qi, 2006, Proc Natl Acad Sci U S A, V103, P483, DOI 10.1073/pnas.0506728103; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hebb D. O., 1949, ORG BEHAV; HERRNSTEIN RJ, 2000, PAPERS PSYCHOL EC; Hillis JM, 2004, J VISION, V4, P967, DOI 10.1167/4.12.1; Ho YX, 2007, J VISION, V7, DOI 10.1167/7.1.1; Ho YX, 2008, PSYCHOL SCI, V19, P196, DOI 10.1111/j.1467-9280.2008.02067.x; Hochberg JE, 2004, CONT PSYCHOL APA REV, V49, P785; Hogervorst MA, 1998, P ROY SOC B-BIOL SCI, V265, P1587; HUMMEL RA, 1988, IEEE T PATTERN ANAL, V10, P235, DOI 10.1109/34.3885; JOHNSTON EB, 1993, VISION RES, V33, P813, DOI 10.1016/0042-6989(93)90200-G; Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005; Knill D. C., 1996, PERCEPTION BAYESIAN; Knill DC, 2003, VISION RES, V43, P831, DOI 10.1016/S0042-6989(03)00003-8; KOHAVI RI, 1996, 2 INT C KNOWL DIS DA; LANDY MS, 1995, VISION RES, V35, P389, DOI 10.1016/0042-6989(94)00176-M; Leopold DA, 1999, TRENDS COGN SCI, V3, P254, DOI 10.1016/S1364-6613(99)01332-7; Lewis D., 1998, 10 EUR C MACH LEARN; LINDLEY DV, 1979, J ROY STAT SOC A STA, V142, P146, DOI 10.2307/2345078; LONG GM, 1983, PERCEPT PSYCHOPHYS, V34, P29, DOI 10.3758/BF03205893; Mamassian P, 2001, VISION RES, V41, P2653, DOI 10.1016/S0042-6989(01)00147-X; Mamassian P, 1998, VISION RES, V38, P2817, DOI 10.1016/S0042-6989(97)00438-0; Michel M. M., 2007, J VISION, V7, P1, DOI DOI 10.1167/7.1.4; MORRIS PA, 1983, MANAGE SCI, V29, P24, DOI 10.1287/mnsc.29.1.24; Necker L. A., 1832, LONDON EDINBURGH PHI, V1, P329; Osherson D, 1997, ORGAN BEHAV HUM DEC, V69, P1, DOI 10.1006/obhd.1996.2668; Pelli DG, 1999, J OPT SOC AM A, V16, P647, DOI 10.1364/JOSAA.16.000647; Petrov AA, 2005, PSYCHOL REV, V112, P715, DOI 10.1037/0033-295X.112.4.715; SABES PN, 1996, ADV NEUR INF PROC SY; Savage L. G., 1972, FDN STAT; Shafer G., 1976, MATH THEORY EVIDENCE; SHAFER G, 1981, SYNTHESE, V48, P1, DOI 10.1007/BF01064627; Smith JE, 2004, MANAGE SCI, V50, P561, DOI 10.1287/mnsc.1040.0243; STEWART TR, 1994, J FORECASTING, V13, P579, DOI 10.1002/for.3980130703; SWANSON WH, 1992, PERCEPT PSYCHOPHYS, V51, P409, DOI 10.3758/BF03211637; van Ee R, 2003, J OPT SOC AM A, V20, P1398, DOI 10.1364/JOSAA.20.001398; Vermunt JK, 2003, COMPUT STAT DATA AN, V41, P531, DOI 10.1016/S0167-9473(02)00179-2; von Helmholtz H., 1910, TREATISE PHYSL OPTIC, V3; Vulkan N, 2000, J ECON SURV, V14, P101, DOI 10.1111/1467-6419.00106; Weiss Y, 2002, NAT NEUROSCI, V5, P598, DOI 10.1038/nn858; Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544; WINKLER RL, 1968, MANAGE SCI, V15, pB61; Woodbury CB, 1943, J COMP PSYCHOL, V35, P29, DOI 10.1037/h0054061; YOUNG MJ, 1993, VISION RES, V33, P2685, DOI 10.1016/0042-6989(93)90228-O; Zhang H., 2004, P 17 INT FLAIRS C FL; Zhu M., 2004, J STAT ED, V12, P1	75	11	11	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	1534-7362			J VISION	J. Vision		2009	9	1							6	10.1167/9.1.6		19	Ophthalmology	Ophthalmology	422SP	WOS:000264448300006	
S	Wu, JH; Pan, G; Zhang, DQ; Qi, GD; Li, SJ		Zhang, D; Portmann, M; Tan, AH; Indulska, J		Wu, Jiahui; Pan, Gang; Zhang, Daqing; Qi, Guande; Li, Shijian			Gesture Recognition with a 3-D Accelerometer	UBIQUITOUS INTELLIGENCE AND COMPUTING, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	6th International Conference on Ubiquitous Intelligence and Computing	JUL 07-09, 2009	Brisbane, AUSTRALIA	IEEE, IEEE Comp Soc TCSC, Australian Ctr Excellence Informat & Commun Technologies, NICTA				Gesture-based interaction, as a natural way for human-computer interaction, has a wide range of applications in ubiquitous computing environment. This paper presents an acceleration-based gesture recognition approach, called FDSVM (Frame-based Descriptor and multi-class SVM), which needs only a wearable 3-dimensional accelerometer. With FDSVM, firstly, the acceleration data of a gesture is collected and represented by a frame-based descriptor, to extract the discriminative information. Then a SVM-based multi-class gesture classifier is built for recognition in the nonlinear gesture feature space. Extensive experimental results on a data set with 3360 gesture samples of 12 gestures over weeks demonstrate that the proposed FDSVM approach significantly outperforms other four methods: DTW, Naive Bayes, C4.5 and HMM. In the user-dependent case, FDSVM achieves the recognition rate of 99.38% for the 4 direction gestures and 95.21% for all the 12 gestures. In the user-independent case, it obtains the recognition rate of 98.93% for 4 gestures and 89.29% for 12 gestures. Compared to other accelerometer-based gesture recognition approaches reported in literature FDSVM gives the best resulrs for both user-dependent and user-independent cases.	[Wu, Jiahui; Pan, Gang; Qi, Guande; Li, Shijian] Zhejiang Univ, Dept Comp Sci, Hangzhou 310027, Peoples R China	Wu, JH (reprint author), Zhejiang Univ, Dept Comp Sci, Hangzhou 310027, Peoples R China.	cat_nag@zju.edu.cn; gpan@zju.edu.cn; daqing.zhang@it-sudparis.eu; shijianli@zju.edu.cn	Qi, Guande/F-6726-2011; Pan, Gang/B-5978-2013	Pan, Gang/0000-0002-4049-6181			Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1; Cho S.-J., 2006, 10 INT WORKSH FRONT; CHRISTANINI J, 2000, INTRO SUPPORT VECTOR; Frigo Matteo, 2005, P IEEE, V93; Hofmann F.G., 1998, LNCS, V1371, P81; HOMMEL G, 1994, P WWDU 1994 4 INT SC, V2, P47; Joachims T., 1999, ADV KERNEL METHODS S; Kela J, 2006, PERS UBIQUIT COMPUT, V10, P285, DOI 10.1007/s00779-005-0033-8; LIU J, 2009, IEEE PERCOM 2009; Mantyjarvi J., 2004, P 3 INT C MOB UB MUL, P25, DOI 10.1145/1052380.1052385; Mantyla V. M., 2001, DISCRETE HIDDEN MARK; Mantyla V.-M., 2000, P IEEE INT C MULT EX, P281; Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Niezen G., 2008, INT WORKSH DEV ALT P; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; RAVI N., 2005, P 17 INN APPL ART IN, P11; SAWADA H, 2000, ELECTRON COMM JPN 3, P9; Schlomer T., 2008, INT C TANG EMB INT T, P11; Tsukada Koji, 2002, P APCHI 2002, V1, P388; WILSON DH, 2004, CMURITR0457	22	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-02829-8	LECT NOTES COMPUT SC			2009	5585						25	38				14	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	BLL34	WOS:000270444600003	
J	Xue, JH; Titterington, DM				Xue, Jing-Hao; Titterington, D. Michael			Comment on "On Discriminative vs. Generative Classifiers: A Comparison of Logistic Regression and Naive Bayes"	NEURAL PROCESSING LETTERS			English	Article						Asymptotic relative efficiency; Discriminative classifiers; Generative classifiers; Logistic regression; Normal-based discriminant analysis; Naive Bayes classifier		Comparison of generative and discriminative classifiers is an ever-lasting topic. As an important contribution to this topic, based on their theoretical and empirical comparisons between the naive Bayes classifier and linear logistic regression, Ng and Jordan (NIPS 841-848, 2001) claimed that there exist two distinct regimes of performance between the generative and discriminative classifiers with regard to the training-set size. In this paper, our empirical and simulation studies, as a complement of their work, however, suggest that the existence of the two distinct regimes may not be so reliable. In addition, for real world datasets, so far there is no theoretically correct, general criterion for choosing between the discriminative and the generative approaches to classification of an observation x into a class y; the choice depends on the relative confidence we have in the correctness of the specification of either p(y vertical bar x) or p(x, y) for the data. This can be to some extent a demonstration of why Efron (J Am Stat Assoc 70(352):892-898, 1975) and O'Neill (J Am Stat Assoc 75(369):154-160, 1980) prefer normal-based linear discriminant analysis (LDA) when no model mis-specification occurs but other empirical studies may prefer linear logistic regression instead. Furthermore, we suggest that pairing of either LDA assuming a common diagonal covariance matrix (LDA-A) or the naive Bayes classifier and linear logistic regression may not be perfect, and hence it may not be reliable for any claim that was derived from the comparison between LDA-A or the naive Bayes classifier and linear logistic regression to be generalised to all generative and discriminative classifiers.	[Xue, Jing-Hao] UCL, Dept Stat Sci, London WC1E 6BT, England; [Xue, Jing-Hao; Titterington, D. Michael] Univ Glasgow, Dept Stat, Glasgow G12 8QQ, Lanark, Scotland	Xue, JH (reprint author), UCL, Dept Stat Sci, Mortimer St, London WC1E 6BT, England.	jinghao@stats.ucl.ac.uk; mike@stats.gla.ac.uk					DAWID AP, 1976, BIOMETRICS, V32, P647, DOI 10.2307/2529753; EFRON B, 1975, J AM STAT ASSOC, V70, P892, DOI 10.2307/2285453; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Lim TS, 1996, COMPUT STAT DATA AN, V22, P287, DOI 10.1016/0167-9473(95)00054-2; Newman DJ, 1998, UCI REPOSITORY MACHI; Ng A. Y., 2001, NIPS, P841; ONEILL TJ, 1980, J AM STAT ASSOC, V75, P154, DOI 10.2307/2287404; Perlich C., 2003, J MACHINE LEARNING R, V4, P211; Ripley B., 1996, PATTERN RECOGNITION; Rubinstein Y., 1997, KDD, P49; SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918; Verboven S, 2005, CHEMOMETR INTELL LAB, V75, P127, DOI 10.1016/j.chemolab.2004.06.003	13	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621			NEURAL PROCESS LETT	Neural Process. Lett.	DEC	2008	28	3					169	187		10.1007/s11063-008-9088-7		19	Computer Science, Artificial Intelligence	Computer Science	371NW	WOS:000260839000003	
J	Sohn, S; Kim, W; Comeau, DC; Wilbur, WJ				Sohn, Sunghwan; Kim, Won; Comeau, Donald C.; Wilbur, W. John			Optimal training sets for Bayesian prediction of MeSH (R) assignment	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							CLASSIFIERS; TEXT	Objectives: The aim of this study was to improve naive Bayes prediction of Medical Subject Headings (MeSH) assignment to documents using optimal training sets found by an active learning inspired method. Design: The authors selected 20 MeSH terms whose occurrences cover a range of frequencies. For each MeSH term, they found an optimal training set, a subset of the whole training set. An optimal training set consists of all documents including a given MeSH term (C-1 class) and those documents not including a given MeSH term (C-1 class) that are closest to the C-1 class. These small sets were used to predict MeSH assignments in the MEDLINE (R) database. Measurements: Average precision was used to compare MeSH assignment using the naive Bayes learner trained on the whole training set, optimal sets, and random sets. The authors compared 95% lower confidence limits of average precisions of naive Bayes with upper bounds for average precisions of a K-nearest neighbor (KNN) classifier. Results: For all 20 MeSH assignments, the optimal training sets produced nearly 200% improvement over use of the whole training sets. In 17 of those MeSH assignments, naive Bayes using optimal training sets was statistically better than a KNN. In 15 of those, optimal training sets performed better than optimized feature selection. Overall naive Bayes averaged 14% better than a KNN for all 20 MeSH assignments. Using these optimal sets with another classifier, C-modified least squares (CMLS), produced an additional 6% improvement over naive Bayes. Conclusion: Using a smaller optimal training set greatly improved learning with naive Bayes. The performance is superior to a KNN. The small training set can be used with other sophisticated learning methods, such as CMLS, where using the whole training set would not be feasible.	[Sohn, Sunghwan; Kim, Won; Comeau, Donald C.; Wilbur, W. John] NIH, Natl Ctr Biotechnol Informat, Natl Lib Med, Bethesda, MD 20894 USA	Sohn, S (reprint author), NIH, Natl Ctr Biotechnol Informat, Natl Lib Med, Bldg 38A,6N611C,8600 Rockville Pike, Bethesda, MD 20894 USA.	sohn@ncbi.nlm.nih.gov					Aronson AR, 2004, ST HEAL T, V107, P268; Aronson A R, 2000, Proc AMIA Symp, P17; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BOLEY D, 2004, 4 SIAM INT C DAT MIN, P126; Bordes A, 2005, J MACH LEARN RES, V6, P1579; Burges C. J. C., 1999, TUTORIAL SUPPORT VEC; Cooper GF, 1998, J AM MED INFORM ASSN, V5, P62; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Fowler J, 1995, Proc Annu Symp Comput Appl Med Care, P893; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Japkowicz N., 2002, Intelligent Data Analysis, V6; Kim W, 2001, Proc AMIA Symp, P319; Kim Won, 2005, AMIA Annu Symp Proc, P395; Kouramajian V, 1995, Proc Annu Symp Comput Appl Med Care, P878; LEWIS DD, 1994, 17 ANN INT ACM SIGIR; Lewis D.D., 1994, 11 INT C MACH LEARN, P148; Lewis D.D., 1998, EUR C MACH LEARN, P4; MADSEN RE, 2005, 22 INT C MACH LEARN, P545; Maloof M, 2003, P ICML 2003 WORKSH L, P73; Manning C.D., 1999, FDN STAT NATURAL LAN; Mladenic D., 1999, 16 INT C MACH LEARN, P258; Nickerson A.S., 2001, P 8 INT WORKSH AI ST, P261; PAVLOV D, 2000, 15 INT C PATT REC BA, P2219; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; ROY N, 2001, 18 INT C MACH LEARN; Ruch P, 2006, BIOINFORMATICS, V22, P658, DOI 10.1093/bioinformatics/bti783; Salton Gerard, 1989, AUTOMATIC TEXT PROCE; Schapire R. E., 2002, MSRI WORKSH NONL EST; SCHOHN M, 2000, P 17 INT C MACH LEAR; SEUNG HS, 1992, 5TH P ANN ACM WORKSH, P287; Tong S., 2000, J MACHINE LEARNING R, V2, P45, DOI 10.1162/153244302760185243; Visa S., 2005, P 16 MIDW ART INT CO, P67; WILBUR WJ, 2000, AM MED INF 2000 ANN, P918; Witten I., 1999, MANAGING GIGABYTES; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	36	11	12	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	1067-5027			J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JUL-AUG	2008	15	4					546	553		10.1197/jamia.M2431		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	328JM	WOS:000257794700019	
J	Pino, LJ; Stashuk, DW; Boe, SG; Doherty, TJ				Pino, L. J.; Stashuk, D. W.; Boe, S. G.; Doherty, T. J.			Motor unit potential characterization using "pattern discovery"	MEDICAL ENGINEERING & PHYSICS			English	Article						clinical decision support system; electromyographic signal analysis; motor unit potential; neuromuscular disorder; pattern discovery; quantitative electromyography; QEMG	DECOMPOSITION; RELIABILITY; DIAGNOSIS; ELECTROMYOGRAPHY; CRITERIA; SIGNALS	Typically in clinical practice, electromyographers use qualitative auditory and visual analysis of electromyographic (EMG) signals to help infer if a neuromuscular disorder is present and if it is neuropathic or myopathic. Quantitative EMG methods exist that can more accurately measure feature values but require qualitative interpretation of a large number of statistics. Electrophysiological characterization of a neuromuscular system can be improved through the quantitative interpretation of EMG statistics. The aim of the present study was to compare the accuracy of pattern discovery (PD) characterization of motor unit potentials (MUPs) to other classifiers commonly used in the medical field. In addition, a demonstration of PD's transparency is provided. The transparency of PD characterization is a result of observing statistically significant events known as patterns. Using clinical MUP data from normal subjects and patients with known neuropathic disorders, PD achieved an error rate of 30.3% versus 29.8% for a Naive Bayes classifier, 30.1% for a Decision Tree and 29% for discriminant analysis. Similar results were found for simulated EMG data. PD characterization succeeded in interpreting the information extracted from MUPs and transforming it into knowledge that is consistent with the literature and that can be valuable for the capture and transparent expression of clinically useful knowledge. (c) 2007 IPEM. Published by Elsevier Ltd. All rights reserved.	[Pino, L. J.; Stashuk, D. W.] Univ Waterloo, Waterloo, ON N2L 3G1, Canada; [Boe, S. G.; Doherty, T. J.] London Hlth Sci Ctr, London, ON, Canada	Pino, LJ (reprint author), Univ Waterloo, Waterloo, ON N2L 3G1, Canada.	ljpino@uwaterloo.ca					Boe SG, 2004, MUSCLE NERVE, V29, P693, DOI 10.1002/mus.20031; Boe SG, 2006, CLIN NEUROPHYSIOL, V117, P596, DOI 10.1016/j.clinph.2005.10.021; Boe SG, 2005, MUSCLE NERVE, V31, P365, DOI 10.1002/mus.20266; Brooks BR, 2000, AMYOTROPH LATERAL SC, V1, P293, DOI 10.1080/146608200300079536; Buchthal F., 1957, INTRO ELECTROMYOGRAP; Bull C., 1993, Proceedings. Computers in Cardiology 1993 (Cat. No.93CH3384-5), DOI 10.1109/CIC.1993.378465; CHAN KM, 2002, NEUROMUSCULAR FUNCTI, P359; Duda R.O., 2001, PATTERN CLASSIFICATI; FENG C, 1994, MACHINE LEARNING NEU; HAMILTONWRIGHT A, 2003, MUSCLE NERVE, V28, pS126; Hamilton-Wright A, 2005, IEEE T BIO-MED ENG, V52, P171, DOI 10.1109/TBME.2004.840501; Kendall R, 2006, MUSCLE NERVE, V34, P238, DOI 10.1002/mus.20554; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; NANDEDKAR SD, 1988, ELECTROEN CLIN NEURO, V69, P561, DOI 10.1016/0013-4694(88)90168-X; PATTICHIS CS, 1995, IEEE T BIO-MED ENG, V42, P486, DOI 10.1109/10.376153; PFEIFFER G, 1995, ELECTROMYOGR MOTOR C, V97, P191, DOI 10.1016/0924-980X(95)00072-0; Pfeiffer G, 1999, MUSCLE NERVE, V22, P584, DOI 10.1002/(SICI)1097-4598(199905)22:5<584::AID-MUS6>3.0.CO;2-0; Podnar S, 2004, MUSCLE NERVE, V30, P596, DOI 10.1002/mus.20148; Sprogar Matej, 2002, J Med Syst, V26, P479, DOI 10.1023/A:1016413418549; Stalberg E, 1996, J CLIN NEUROPHYSIOL, V13, P401; Stålberg E, 2002, Electromyogr Clin Neurophysiol, V42, P433; Stashuk DW, 1999, MED ENG PHYS, V21, P389, DOI 10.1016/S1350-4533(99)00064-8; Stedman T.L., 2000, STEDMANS MED DICT; STEWART CR, 1989, MUSCLE NERVE, V12, P141; Strat T. M., 1989, International Journal of Approximate Reasoning, V3, DOI 10.1016/0888-613X(89)90020-0; Swash Michael, 2002, Muscle Nerve Suppl, V11, pS134; SZAFRON D, 2003, TR0309 U ALB; Trujillo-Ortiz A., 2004, RAFISHER2CDA CANONIC; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; WANG Y, 1997, THESIS U WATERLOO; Wickens C. D., 2000, ENG PSYCHOL HUMAN PE; Witten IH, 2005, DATA MINING PRACTICA; Wong AKC, 1997, IEEE T KNOWL DATA EN, V9, P877, DOI 10.1109/69.649314; WONG AKC, 1995, P 1995 IEEE INT C SY, V2, P1142; Wong M, 2003, BONE, V33, P1, DOI 10.1016/S8756-3282(03)00083-8	35	11	13	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1350-4533			MED ENG PHYS	Med. Eng. Phys.	JUN	2008	30	5					563	573		10.1016/j.medengphy.2007.06.005		11	Engineering, Biomedical	Engineering	320ZH	WOS:000257273300003	
J	Giansanti, D; Macellari, V; Maccioni, G				Giansanti, Daniele; Macellari, Velio; Maccioni, Giovanni			New neural network classifier of fall-risk based on the Mahalanobis distance and kinematic parameters assessed by a wearable device	PHYSIOLOGICAL MEASUREMENT			English	Article						patient-monitoring; accelerometer; gyroscopes; human movement analysis; accuracy; fall risk; fall prevention	DETECTION ALGORITHM; RATE GYROSCOPES; 3-D POSITION; SENSOR; ACCELEROMETERS; ORIENTATION	Fall prevention lacks easy, quantitative and wearable methods for the classification of fall-risk (FR). Efforts must be thus devoted to the choice of an ad hoc classifier both to reduce the size of the sample used to train the classifier and to improve performances. A new methodology that uses a neural network (NN) and a wearable device are hereby proposed for this purpose. The NN uses kinematic parameters assessed by a wearable device with accelerometers and rate gyroscopes during a posturography protocol. The training of the NN was based on the Mahalanobis distance and was carried out on two groups of 30 elderly subjects with varying fall-risk Tinetti scores. The validation was done on two groups of 100 subjects with different fall-risk Tinetti scores and showed that, both in terms of specificity and sensitivity, the NN performed better than other classifiers (naive Bayes, Bayes net, multilayer perceptron, support vector machines, statistical classifiers). In particular, (i) the proposed NN methodology improved the specificity and sensitivity by a mean of 3% when compared to the statistical classifier based on the Mahalanobis distance (SCMD) described in Giansanti (2006 Physiol. Meas. 27 1081-90); (ii) the assessed specificity was 97%, the assessed sensitivity was 98% and the area under receiver operator characteristics was 0.965.	[Giansanti, Daniele; Macellari, Velio; Maccioni, Giovanni] Ist Super Sanita, Dipartimento Tecnol & Salute, I-00161 Rome, Italy	Giansanti, D (reprint author), Ist Super Sanita, Dipartimento Tecnol & Salute, Viale Regina Elena 299, I-00161 Rome, Italy.	dgiansa@iss.it					Allen FR, 2006, PHYSIOL MEAS, V27, P935, DOI 10.1088/0967-3334/27/10/001; Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012; Bourke AK, 2008, MED ENG PHYS, V30, P84, DOI 10.1016/j.medengphy.2006.12.001; BRANNATH W, 2005, IEEE T BIOMED ENG, V44, P1165; COHEN A, 1986, COMPRESSION AUTOMATI, P53; DAGOSTINO RB, 1986, GOODNESS OF FIT TECH; Doughty K, 2000, J Telemed Telecare, V6 Suppl 1, pS150; Fry A G, 2002, J Matern Fetal Neonatal Med, V12, P247, DOI 10.1080/jmf.12.4.247.252; *GAL MOT CONTR, GAL MAN 2000; Giacinto G, 2001, PATTERN RECOGN LETT, V22, P25, DOI 10.1016/S0167-8655(00)00096-9; GIACINTO G, 2001, PATTERN RECOGN, V34, P179; Giansanti D, 2005, PHYSIOL MEAS, V26, P689, DOI 10.1088/0967-3334/26/5/010; Giansanti D, 2003, IEEE T BIO-MED ENG, V50, P476, DOI 10.1109/TBME.2003.809490; Giansanti D, 2005, IEEE T BIO-MED ENG, V52, P1271, DOI 10.1109/TBME.2005.847404; Giansanti D, 2006, PHYSIOL MEAS, V27, P1081, DOI 10.1088/0967-3334/27/11/003; Giansanti D, 2006, PHYSIOL MEAS, V27, P713, DOI 10.1088/0967-3334/27/8/006; HANLEY JA, 1982, RADIOLOGY, V143, P29; KANDEL ER, 2000, PRINCIPI NEUROSCIENZ; KUNCHEVA L, 2001, COMBINING PATTERN CL; MATHIE MJ, 2001, 23 ANN INT C MED BIO, P301; Mathie MJ, 2004, PHYSIOL MEAS, V25, pR1, DOI 10.1088/0967-3334/25/2/R01; *MATL, MATL US GUID 2003 VE; METZ CE, 1980, J MATH PSYCHOL, V22, P218, DOI 10.1016/0022-2496(80)90020-6; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; ROLI F, 2004, LECT NOTES COMPUTER, V3077; *STAT SOFTW, 2003, STAT SOFTW MAN; WILLIAMS G, 1998, 20 ANN INT C IEEE EN, P297; Witten IH, 2005, DATA MINING PRACTICA	28	11	11	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0967-3334			PHYSIOL MEAS	Physiol. Meas.	MAR	2008	29	3					N11	N19		10.1088/0967-3334/29/3/N01		9	Biophysics; Engineering, Biomedical; Physiology	Biophysics; Engineering; Physiology	271YD	WOS:000253823700012	
J	Hoare, Z				Hoare, Zoe			Landscapes of Naive Bayes classifiers	PATTERN ANALYSIS AND APPLICATIONS			English	Article						Naive Bayes; meta-analysis	CLASSIFICATION	The performance of the Naive Bayes classifier (NB) is of interest to many researchers. The desire to improve upon the apparent good performance of NB while maintaining its efficiency and simplicity is demonstrated by the variety of adaptations to NB in the literature. This study takes a look at 37 such adaptations. The idea is to give a qualitative overview of the adaptations rather than a quantitative analysis of their performance. Landscapes are produced using Sammon mapping, Principal Component Analysis (PCA) and Self-Organising feature Maps (SOM). Based on these, the methods are split into five main groups-tree structures, feature selection, space transformation, Bayesian networks and joint features. The landscapes can also be used for placing any new variant of NB to obtain its nearest neighbours as an aid for comparison studies.	[Hoare, Zoe] Univ Wales, Sch Informat, Bangor, Gwynedd, Wales	Hoare, Z (reprint author), Univ Wales, Sch Informat, Bangor, Gwynedd, Wales.	z.hoare@talk21.com					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; Bressan M, 2002, LECT NOTES ARTIF INT, V2527, P1; Cooper H., 1994, HDB RES SYNTHESIS; DENTON A, 2004, P SIAM INT C DAT MIN; DIAO L, 2002, LECTURE NOTES COMPUT, P115; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O., 2001, PATTERN CLASSIFICATI; FREIDMAN N, 1997, MACH LEARN, V29, P131; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Gama J, 2003, THEOR COMPUT SCI, V292, P417, DOI 10.1016/S0304-3975(02)00179-2; Huang HJ, 2002, IEEE T SYST MAN CY B, V32, P137, DOI 10.1109/3477.990870; HUNTER J, 1990, METHODS META ANAL; Jain AK, 2004, INT C PATT RECOG, P260, DOI 10.1109/ICPR.2004.1334073; JAMES N, 2001, IEEE T SYST MAN CYB, V31, P249; Keogh E., 1999, P 7 INT WORKSH ART I, P225; KLEINER A, 2000, P 3 IASTED INT C ART, P191; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; KOHONEN T, 1989, SELF ORGANIZATION AS; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1994, P 10 C UNC ART INT, P399; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; Lipsey M. W., 2001, PRACTICAL META ANAL; Ma SC, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1497; Manly BFJ, 1986, MULTIVARIATE STAT ME; MERETAKIS D, 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; NURNBERGER A, 1999, P 6 INT C NEUR INF P, P154; PAZZANI MJ, 1996, P INF STAT IND SCI; Pearl J., 1988, PROBABILISTIC REASON; Phillips P. J., 2002, Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition, DOI 10.1109/AFGR.2002.1004160; Ratanamahatana C.A., 2002, P WORKSH DAT CLEAN P; Ridgeway G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Robles V., 2003, Proceedings IEEE/WIC International Conference on Web Intelligence (WI 2003); ROSELL B, 2004, P 17 C CAN SOC COMP, P105; Sahami M., 1996, P 2 INT C KNOWL DISC, P334; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; Scheiner S. M., 1993, DESIGN ANAL ECOLOGIC; Schiffman S. S., 1981, INTRO MULTIDIMENSION; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137; Storr HP, 2002, P INTECH VJFUZZY, P172; TING KM, 1999, P 3 PAC AS C KNOWL D, P296; TSYMBAL A, 2003, SEARCH STRATEGIES EN; Tsymbal A, 2002, COMP MED SY, P225, DOI 10.1109/CBMS.2002.1011381; VILALTA R, 2003, P 14 EUR C MACH LEAR; Wang LM, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1383; WANG Z, 2002, P 2002 IEEE INT C DA, P490; Webb G I, 1998, P 11 AUSTR JOINT C A, P285; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Wolf FM, 1986, 59 SAG U; Zhang H, 2004, LECT NOTES COMPUT SC, V3201, P513; Zheng Z., 1998, P 10 EUR C MACH LEAR, P196; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719; ZHIPENG X, 2002, P ADV KNOWL DISC DAT	55	11	12	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541			PATTERN ANAL APPL	Pattern Anal. Appl.	JAN	2008	11	1					59	72		10.1007/s10044-007-0079-5		14	Computer Science, Artificial Intelligence	Computer Science	243WT	WOS:000251828700005	
J	Mahata, P; Mahata, K				Mahata, Pritha; Mahata, Kaushik			Selecting differentially expressed genes using minimum probability of classification error	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						microarray; gene selection; minimum probability of classification error; supervised classification; colon cancer; leukaemia; hereditary breast cancer	BREAST-CANCER; TUMOR; CARCINOMAS; PREDICTION; PROGNOSIS; SAMPLES; COLON	Discovery of differentially expressed genes between normal and diseased patients is a central research problem in bioinformatics. It is specially important to find few genetic markers which can be explored for diagnostic purposes. The performance of a set of markers is often measured by the associated classification accuracy. This motivates our ranking of genes depending on the minimum probability of classification errors (MPE) for each gene. In this work, we use Bayesian decision-making algorithm to compute MPE. A quantile-based probability density estimation technique is used for generating probability density functions of genes. The method is tested on three datasets: colon cancer, leukaemia, and hereditary breast cancer. The quality of the selected markers is evaluated by the classification accuracy obtained using support-vector-machine and a modified naive Bayes classifier. We obtain 96.77% accuracy in colon cancer and 97.06% accuracy in leukaemia, using only five genes in each case. Finally, using just three genes we get 100% accuracy in hereditary breast cancer. We also compare our results with those using the genes ranked by p-value and show that the genes ranked by MPE perform better or equal to those ranked by p-value. (C) 2007 Elsevier Inc. All rights reserved.	[Mahata, Pritha; Mahata, Kaushik] Univ Newcastle, Sch Elect Engn & Comp Sci, Callaghan, NSW 2308, Australia	Mahata, P (reprint author), Univ Newcastle, Sch Elect Engn & Comp Sci, Callaghan, NSW 2308, Australia.	Pritha.Mahata@newcastle.edu.au					Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Antonov AV, 2004, BIOINFORMATICS, V20, P644, DOI 10.1093/bioinformatics/btg462; Bo T., 2002, GENOME BIOL, P3; Cappello F, 2005, BMC CANCER, V5, DOI 10.1186/1471-2407-5-139; Cobleigh MA, 2005, CLIN CANCER RES, V11, P8623, DOI 10.1158/1078-0432.CCR-05-0735; D'Andrea MR, 2007, BREAST CANCER RES TR, V101, P279, DOI 10.1007/s10549-006-9300-2; DIAO Q, 2004, P 2004 IEEE COMP SYS, P574; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gibbons RD, 2005, J STAT PLAN INFER, V129, P19, DOI 10.1016/j.jspi.2004.06.037; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Groisman GM, 2006, HISTOPATHOLOGY, V48, P431, DOI 10.1111/j.1365-2559.2006.02357.x; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Helzlsouer KJ, 2006, EUR J CANCER, V42, P704, DOI 10.1016/j.ejca.2006.01.008; Kim S, 2002, J COMPUT BIOL, V9, P127, DOI 10.1089/10665270252833226; Kumaraguruparan R, 2006, RES VET SCI, V81, P218, DOI 10.1016/j.rvsc.2005.08.002; Lee KE, 2003, BIOINFORMATICS, V19, P90, DOI 10.1093/bioinformatics/19.1.90; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Madureira PA, 2006, J BIOL CHEM, V281, P25167, DOI 10.1074/jbc.M603906200; MAHATA P, 2006, 17 INT C GEN INF, P184; McLachlan GJ, 2006, BIOINFORMATICS, V22, P1608, DOI 10.1093/bioinformatics/btl148; PELCKMANS K, 1999, LSSVMLAB MATLABC TOO; Rennie J, 2003, P 20 INT C MACH LEAR, P616; SAKHINIA E, 2006, J CLIN PATHOL; Schwartz DR, 2002, CANCER RES, V62, P4722; Silverman B. W., 1986, DENSITY ESTIMATION S; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Sun Yi, 2004, Zhongguo Shi Yan Xue Ye Xue Za Zhi, V12, P450; van de Vijver M, 2002, NATURE, V415, P530, DOI DOI 10.1038/415530A; Vapnik V., 1995, NATURE STAT LEARNING; Vencio RZN, 2006, GENET MOL RES, V5, P138; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; WANG Z, 2006, P 2 INT S EV FUZZ SY; WERMUTH N, 1995, THEORY STAT; WESTON J, 2001, ADV NEURAL INFORM PR, P13; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Witten IH, 2005, DATA MINING PRACTICA; Xiong MM, 2000, BIOTECHNIQUES, V29, P1264; Yap YL, 2004, BMC CANCER, V4, DOI 10.1186/1471-2407-4-72; ZHOU X, 2003, NONLINEAR PROBIT GEN	40	11	12	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	DEC	2007	40	6					775	786		10.1016/j.jbi.2007.07.006		12	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	251FG	WOS:000252356500015	
J	Zadora, G				Zadora, Grzegorz			Glass analysis for forensic purposes - a comparison of classification methods	JOURNAL OF CHEMOMETRICS			English	Article; Proceedings Paper	International Chemometrics Research Meeting (ICRM 2006)	MAY 28-JUN 01, 2006	Veldhoven, NETHERLANDS			classification; Naive Bayes classifiers; support vector machines; forensic sciences; glass	SUPPORT VECTOR MACHINES; PATTERN-RECOGNITION; NETWORKS; DISCRIMINATION; FRAGMENTS	One of the purposes of the chemical analysis of glass fragments (pieces of glass of linear dimension ca. 0.5 mm) for forensic purposes is a classification of those fragments into use categories, for example windows, car headlights and containers. The object of this research was to check the efficiency of Naive Bayes Classifiers (NBCs) and Support Vector Machines (SVMs) to the application of the classification of glass objects when those objects may be described by the major and minor elemental concentrations obtained by Scanning Electron Microscopy coupled with an Energy Dispersive X-ray spectrometer which is routinely used in many forensic institutes. Copyright (C) 2007 John Wiley & Sons, Ltd.	Inst Forens Res, PL-31033 Krakow, Poland	Zadora, G (reprint author), Inst Forens Res, Westerplatte 9, PL-31033 Krakow, Poland.	gzadora@ies.krakow.pl					Aitken C. G. G., 2004, STAT EVALUATION EVID; AITKEN CGG, 2007, J FORENSIC SCI, V52, P31; Aitken CGG, 2006, COMPUT STAT DATA AN, V50, P2571, DOI 10.1016/j.csda.2005.04.005; Aitken C.G.G., 2004, APPL STAT, V53, p[109, 665]; AITKEN CGG, 1986, J FORENSIC SCI SOC, V26, P237, DOI 10.1016/S0015-7368(86)72490-0; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Caddy B., 2001, FORENSIC EXAMINATION; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini N., 2000, INTRO SUPPORT VECTOR; Curran JM, 2000, FORENSIC INTERPRETAT; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HICKMAN DA, 1981, FORENSIC SCI INT, V17, P265, DOI 10.1016/0379-0738(81)90176-6; HICKMAN DA, 1987, FORENSIC SCI INT, V33, P23, DOI 10.1016/0379-0738(87)90137-X; Hicks T, 2003, FORENSIC SCI INT, V137, P107, DOI 10.1016/S0379-0738(03)00278-0; KOONS RD, 1988, J FORENSIC SCI, V33, P49; Koons RD, 1999, J FORENSIC SCI, V44, P496; LOCKE J, 1984, FORENSIC SCI INT, V26, P147, DOI 10.1016/0379-0738(84)90071-9; ROYAL R, 1992, STAT EVIDENCE; Smola AJ, 1998, TUTORIAL SUPPORT VEC; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Trejos T, 2005, TALANTA, V67, P388, DOI 10.1016/j.talanta.2005.01.042; Vapnik V., 1995, NATURE STAT LEARNING; Zadora G, 2003, MATER CHEM PHYS, V81, P345, DOI 10.1016/S0254-0584(03)00018-X; ZADORA G, 2001, PROBLEMS FORENSIC SC, V47, P137; ZADORA G, 2001, PROB FORENSIC SCI, V45, P36; ZADORA G, 2003, B INT STAT I 54 SESS, V60, P364	32	11	11	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0886-9383			J CHEMOMETR	J. Chemometr.	MAY-JUN	2007	21	5-6					174	186		10.1002/cem.1030		13	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	219PX	WOS:000250098200002	
S	Rodriguez, JJ; Kuncheva, LI		Haindl, M; Kittler, J; Roli, F		Rodriguez, Juan J.; Kuncheva, Ludmila I.			Nai bayes ensembles with a random oracle	MULTIPLE CLASSIFIER SYSTEMS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	7th International Workshop on Multiple Classifier Systems	MAY 23-25, 2007	Prague, CZECH REPUBLIC	Int Assoc Pattern Recognit, EU IST FP6 BioSecure Network Excellence, EU IST FP6 MUSCLE Network Excellence, Univ Surrey, Ctr Vis, Speech & Signal Proc, Univ Cagliari, Dept Elect & Elect Engn, Acad Sci Czech Republic, Inst Informat Theory & Automat			OPTIMALITY; CLASSIFIER	Ensemble methods with Random Oracles have been proposed recently (Kuncheva and Rodriguez, 2007). A random-oracle classifier consists of a pair of classifiers and a fixed, randomly created oracle that selects between them. Ensembles of random-oracle decision trees were shown to fare better than standard ensembles. In that study, the oracle for a given tree was a random hyperplane at the root of the tree. The present work considers two random oracles types (linear and spherical) in ensembles of Naive Bayes Classifiers (NB). Our experiments show that ensembles based solely upon the spherical oracle (and no other ensemble heuristic) outrank Bagging, Wagging, Random Subspaces, AdaBoost.M1, MultiBoost and Decorate. Moreover, all these ensemble methods are better with any of the two random oracles than their standard versions without the oracles.	Univ Burgos, Dept Ingn Civil, Burgos, Spain	Rodriguez, JJ (reprint author), Univ Burgos, Dept Ingn Civil, Burgos, Spain.	jjrodriguez@ubu.es; 1.i.kuncheva@bangor.ac.uk	Rodriguez, Juan/B-1014-2008				Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C. L., 1998, UCI REPOSITORY MACHI; Bouckaert R., 2004, LECT NOTES AI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 1994, 421 U CAL DEP STAT; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Kuncheva LI, 2007, IEEE T KNOWL DATA EN, V19, P500, DOI [10.1109/TKDE.2007.1016, 10.1109/TDKE.2007.1016]; Kuncheva LI, 2006, PATTERN RECOGN LETT, V27, P830, DOI 10.1016/j.patrec.2005.12.001; Melville P., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.001; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Witten IH, 2005, DATA MINING PRACTICA	16	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-72481-0	LECT NOTES COMPUT SC			2007	4472						450	458				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BGG41	WOS:000246659200045	
S	Colas, F; Brazdil, P		Bramer, M		Colas, Fabrice; Brazdil, Pavel			Comparison of SVM and some older classification algorithms in text classification tasks	Artificial Intelligence in Theory and Practice	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	Conference on Artificial Intelligence in Theory and Practice held at the 19th World Computer Congress	AUG 21-24, 2006	Santiago, CHILE	IFIP TC 12				Document classification has already been widely studied. In fact, some studies compared feature selection techniques or feature space transformation whereas some others compared the performance of different algorithms. Recently, following the rising interest towards the Support Vector Machine, various studies showed that SVM outperforms other classification algorithms. So should we just not bother about other classification algorithms and opt always for SVM ? We have decided to investigate this issue and compared SVM to kNN and naive Bayes on binary classification tasks. An important issue is to compare optimized versions of these algorithms, which is what we have done. Our results show all the classifiers achieved comparable performance on most problems. One surprising result is that SVM was not a clear winner, despite quite good overall performance. If a suitable preprocessing is used with kNN, this algorithm continues to achieve very good results and scales up well with the number of documents, which is not the case for SVM. As for naive Bayes, it also achieved good performance.	Leiden Univ, LIACS, Leiden, Netherlands	Colas, F (reprint author), Leiden Univ, LIACS, Leiden, Netherlands.						Daelemans W., 2003, P 14 EUR C MACH LEAR, P84; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; FURNKRANZ J, 2002, P 13 EUR C MACH LEAR, P97; Joachims T., 1998, ADV KERNEL METHODS S; McCallum A, 1998, AAAI 98 WORKSH LEARN; MCCALLUM AK, 1997, BOW TOOLKIT STAT LAN; Mitchell T.M., 1997, MACHINE LEARNING; Platt J. C., 1998, 9814 MICR RES; Rogati M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; YANG Y, 2003, P 26 ACM INT C RES D; Yang Y., 1997, P 14 INT C MACH LEAR, P412; ZHANG T, 2001, INFORM RETRIEVAL, P5	14	11	11	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736		0-387-34654-6	INT FED INFO PROC			2006	217						169	178				10	Computer Science, Artificial Intelligence	Computer Science	BEZ59	WOS:000240380300018	
S	Jiang, LX; Zhang, H		Yang, Q; Webb, G		Jiang, Liangxiao; Zhang, Harry			Weightily averaged one-dependence estimators	PRICAI 2006: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2006)	AUG 07-11, 2006	Guilin, PEOPLES R CHINA			naive Bayes; Bayesian networks; AODE; WAODE; classification		NB(naive Bayes) is a probabilistic classification model, which is based on the attribute independence assumption. However, in many real-world data mining applications, this assumption is often violated. Responding to this fact, researchers have made a substantial amount of effort to improve NB's accuracy by weakening its attribute independence assumption. For a recent example, Webb et al.[1] propose a model called Averaged One-Dependence Estimators, simply AODE, which weakens the attribute independence assumption by averaging all models from a restricted class of one-dependence classifiers. Motivated by their work, we believe that assigning different weights to these one-dependence classifiers can result in significant improvement. Based on this belief, we present an improved algorithm called Weightily Averaged One-Dependence Estimators, simply WAODE. We experimentally tested our algorithm in Weka system[2], using the whole 36 UCI data sets[3] selected by Weka[2], and compared it to NB, SBC[4], TAN [5], NBTree[6], and AODE[1]. The experimental results show that WAODE significantly outperforms all the other algorithms used to compare.	China Univ Geosci, Fac Comp Sci, Wuhan 430074, Hubei, Peoples R China; Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Jiang, LX (reprint author), China Univ Geosci, Fac Comp Sci, Wuhan 430074, Hubei, Peoples R China.	ljiang@cug.edu.cn; hzhang@unb.ca	Jiang, Liangxiao /D-1237-2012				Chickering D. M., 1996, LEARNING DATA ARTIFI, VV, P121; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Langley P., 1994, P 10 C UNC ART INT, P339; Merz C., 1997, UCI REPOSITORY MACHI; Pearl J., 1988, PROBABILISTIC REASON; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; WITTEN IH, 2000, E DATA MINING PRACTI	8	11	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-36667-9	LECT NOTES ARTIF INT			2006	4099						970	974				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEY22	WOS:000240091500116	
J	Denis, F; Gilleron, R; Letouzey, F				Denis, F; Gilleron, R; Letouzey, F			Learning from positive and unlabeled examples	THEORETICAL COMPUTER SCIENCE			English	Article; Proceedings Paper	11th International Conference on Algorithmic Learning Theory (ALT 2000)	DEC 11-13, 2000	SYDNEY, AUSTRALIA	Univ New S Wales, Sch Comp Sci & Engn		PAC learning; statistical query model; semi-supervised learning; data mining		In many machine learning settings, labeled examples are difficult to collect while unlabeled data are abundant. Also, for some binary classification problems, positive examples which are elements of the target concept are available. Can these additional data be used to improve accuracy of supervised learning algorithms? We investigate in this paper the design of learning algorithms from positive and unlabeled data only. Many machine learning and data mining algorithms, such as decision tree induction algorithms and naive Bayes algorithms, use examples only to evaluate statistical queries (SQ-like algorithms). Kearns designed the statistical query learning model in order to describe these algorithms. Here, we design an algorithm scheme which transforms any SQ-Iike algorithm into an algorithm based on positive statistical queries (estimate for probabilities over the set of positive instances) and instance statistical queries (estimate for probabilities over the instance space). We prove that any class learnable in the statistical query learning model is learnable from positive statistical queries and instance statistical queries only if a lower bound on the weight of any target concept f can be estimated in polynomial time. Then, we design a decision tree induction algorithm POSC4.5, based on C4.5, that uses only positive and unlabeled examples and we give experimental results for this algorithm. In the case of imbalanced classes in the sense that one of the two classes (say the positive class) is heavily underrepresented compared to the other class, the learning problem remains open. This problem is challenging because it is encountered in many real-world applications. (c) 2005 Elsevier B.V. All rights reserved.	Univ Aix Marseille 1, Equipe BDAA, LIF, UMR 6166 CNRS, Marseille, France; Univ Lille 1, Equipe Grappa, LIFL, UPRESA 8022 CNRS, Lille, France; Univ Lille 3, Lille, France	Denis, F (reprint author), Univ Aix Marseille 1, Equipe BDAA, LIF, UMR 6166 CNRS, Marseille, France.	fdenis@cmi.univ-mrs.fr; gilleron@lifl.fr; letouzey@lifl.fr					Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116829; Blum A., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335355; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; BREIMAN L, 1984, CLASSIFICAL NOISE AP; DECOMITE F, 1999, P 10 INT C ALG LEARN, P219; DENIS F, 1998, P 9 INT C ALG LEARN, P112; Goldman S., 2000, P 17 INT C MACH LEAR, P327; HAUSSLER D, 1991, INFORM COMPUT, V95, P129, DOI 10.1016/0890-5401(91)90042-Z; JACKSON J, 2000, P 13 ANN C COMP LEAR, P7; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Kearns M., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167200; Merz C. J., 1998, UCI REPOSITORY MACHI; Mitchell TM, 1999, COMMUN ACM, V42, P30, DOI 10.1145/319382.319388; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354805; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Quinlan J., 1993, C4 5 PROGR MACHINE L; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972	17	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975			THEOR COMPUT SCI	Theor. Comput. Sci.	DEC 2	2005	348	1					70	83		10.1016/j.tcs.2005.09.007		14	Computer Science, Theory & Methods	Computer Science	989EN	WOS:000233655800006	
S	Dash, SK; Reddy, KS; Pujari, AK		Jajodia, S; Mazumdar, C		Dash, SK; Reddy, KS; Pujari, AK			Episode based masquerade detection	INFORMATION SYSTEMS SECURITY, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Information Systems Security (ICISS 2005)	DEC 19-21, 2005	Kolkata, INDIA	George Mason Univ, Ctr Secure Informat Syst, Jadavpur Univ, Ctr Distributed Comp, Birla Inst Technol, INDO US Sci & Technol Forum, USN, Off Naval Res Global	Jadavpur Univ		INTRUSION; COMMANDS	Masquerade detection is one of major concerns of system security research due to two main reasons. Such an attack cannot be detected at the time of access and any detection technique relies on user's signature and even a legitimate user is likely to deviate from its usual usage pattern. In the recent years, there have been several proposals to efficiently detect masquerader while keeping the false alarm rate as low as possible. One of the recent technique, Naive Bayes with truncated command line, has been very successful in maintaining low false alarm rate. This method depends on probability of individual commands. It is more appropriate to consider meaningful groups of commands rather than individual commands. In this paper we propose a method of masquerade detection by considering episodes, meaningful subsequences of commands. The main contributions of the present work are (i) an algorithm to determine episode from a long sequence of commands, and (ii) a technique to use these episodes to detect masquerade block of commands. Our experiments with standard datasets such as SEA dataset reveal that the episode based detection is a more useful masquerade detection technique.	Univ Hyderabad, AI Lab, Hyderabad 500046, Andhra Pradesh, India	Dash, SK (reprint author), Univ Hyderabad, AI Lab, Hyderabad 500046, Andhra Pradesh, India.	akpcs@uohyd.ernet.in					CHINCHANI R, 2004, 20 ANN COMP SEC APPL; Cohen P., 2002, Pattern Detection and Discovery. ESF Exploratory Workshop Proceedings (Lecture Notes in Artificial Intelligence Vol. 2447); Coull S., 2003, 19 ANN COMP SEC APPL; DAVISON BD, 1998, WS9807 AAAI; Greenberg S., 1988, 8833345 U CALG DEP C; KILLHOURHY KS, 2004, 869 CSTR U NEWC SCH; Kim HS, 2005, COMPUT SECUR, V24, P160, DOI 10.1016/j.cose.2004.08.007; Lane T., 1998, P 5 ACM C COMP COMM, P150, DOI 10.1145/288090.288122; Maxion R. A., 2002, Proceedings International Conference on Dependable Systems and Networks, DOI 10.1109/DSN.2002.1028903; Maxion R., 2003, INT C DEP SYST NETW; Maxion RA, 2004, IEEE T RELIAB, V53, P124, DOI 10.1109/TR.2004.824828; McCallum A, 1998, AAAI 98 WORKSH LEARN; Schonlau M, 2000, INFORM PROCESS LETT, V76, P33, DOI 10.1016/S0020-0190(00)00122-8; Schonlau M, 2001, STAT SCI, V16, P58; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WANG K, 2003, 3 ICDM WORKSH DAT MI	16	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30706-0	LECT NOTES COMPUT SC			2005	3803						251	262				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDQ26	WOS:000234880300019	
S	Davis, J; Burnside, E; Dutra, ID; Page, D; Costa, VS		Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Davis, J; Burnside, E; Dutra, ID; Page, D; Costa, VS			An integrated approach to learning Bayesian networks of rules	MACHINE LEARNING: ECML 2005, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD				Inductive Logic Programming (ILP) is a popular approach for learning rules for classification tasks. An important question is how to combine the individual rules to obtain a useful classifier. In some instances, converting each learned rule into a binary feature for a Bayes net learner improves the accuracy compared to the standard decision list approach [3,4,14]. This results in a two-step process, where rules are generated in the first phase, and the classifier is learned in the second phase. We propose an algorithm that interleaves the two steps, by incrementally building a Bayes net during rule learning. Each candidate rule is introduced into the network, and scored by whether it improves the performance of the classifier. We,call the algorithm SAYU for Score As You Use. We evaluate two structure learning algorithms Naive Bayes and Tree Augmented Naive Bayes. We test SAYU on four different datasets and see a significant improvement in two out of the four applications. Furthermore, the theories that SAYU learns tend to consist of far fewer rules than the theories in the two-step approach.	Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA; UFRJ, COPPE Sistemas, Ctr Tecnol, Rio De Janeiro, Brazil	Davis, J (reprint author), Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA.		Dutra, Ines/B-2881-2012; Santos Costa, Vitor/B-2859-2012; INESC-TEC, CRACS/F-7527-2012; FCUP, DCC/F-5042-2012				Alphonse E, 2000, FR ART INT, V54, P256; Davidson RJ, 2001, EMOTION, V1, P3, DOI 10.1037/1528-3542.1.1.3; DAVIS J, 2005, INT C INT AN VIENN V; DAVIS J, 2005, IJCAI05 ED SCOTL; DUTRA IC, 2002, EMPIRICAL EVALUATION, P48; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GOADRICH M, 2004, P 1J ILP PORT PORT; HOCHE S, 2001, ILP01, V2157, P51, DOI 10.1007/3-540-44797-0_5; KOK S, 2005, NAT C ART INT AAAI; LANDWEHR N, 2005, NAT C ART INT AAAI; Mewes HW, 2000, NUCLEIC ACIDS RES, V28, P37, DOI 10.1093/nar/28.1.37; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Neville Jennifer, 2003, KDD 03, P625; POMPE U, 1995, ILP95, P417; PRATI R, 2005, IJCAI05 ED SCOTL; Quinlan J.R., 1996, LECT NOTES COMPUTER, V1160, P143; RICHARDSON M, 2004, MARKOV LOGIC NETWORK; Srinivasan A., 2001, ALEPH MANUAL; Srinivasan A, 1997, LECT NOTES ARTIF INT, V1314, P89	19	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29243-8	LECT NOTES ARTIF INT			2005	3720						84	95				12	Computer Science, Artificial Intelligence	Computer Science	BDF41	WOS:000233235200013	
S	Schneider, KM		Gelbukh, A		Schneider, KM			Techniques for improving the performance of naive Bayes for text classification	COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th Annual Conference on Intelligent Text Processing and Computational Linguistics	FEB 13-19, 2005	Mexico City, MEXICO	Natl Polytech Inst, Nat Language & Text Proc Lab, Ctr Comp Res			WEB	Naive Bayes is often used in text classification applications and experiments because of its simplicity and effectiveness. However, its performance is often degraded because it does not model text well, and by inappropriate feature selection and the lack of reliable confidence scores. We address these problems and show that they can be solved by some simple corrections. We demonstrate that our simple modifications are able to improve the performance of Naive B ayes for text classification significantly.	Univ Passau, Dept Gen Linguist, D-94032 Passau, Germany	Schneider, KM (reprint author), Univ Passau, Dept Gen Linguist, Innstr 40, D-94032 Passau, Germany.	schneide@phil.uni-passau.de					Androutsopoulos I., 2000, P WORKSH MACH LEARN, P1; Apte C., 1994, P 17 ANN INT ACM SIG, P23; Bennett P.N., 2000, CMUCS00155 SCH COMP; Cohen WW, 1999, ACM T INFORM SYST, V17, P141, DOI 10.1145/306686.306688; Cover T. M., 1991, ELEMENTS INFORMATION; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Eyheramendy S., 2003, AI STAT 2003, P332; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GOMEZHIDALGO JM, 1997, ACL EACL 97 WORKSH A, P39; Joachims T., 1998, LNCS, V1398, P137; Katz S., 1996, NAT LANG ENG, V2, P15, DOI 10.1017/S1351324996001246; Kim S.-B., 2002, LECT NOTES ARTIF INT, V2417, P414; LANG K, 1995, P 12 INT C MACH LEAR, P331; MCCALLUM A, 1998, LEARNING TEXT CATEGO; Mitchell T.M., 1997, MACHINE LEARNING; MLADENIC D, 1998, P 17 EL COMP SCI C E; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Rennie J, 2003, P 20 INT C MACH LEAR, P616; Sahami M, 1998, LEARNING TEXT CATEGO, P55; Sahami M., 1997, P 14 INT C MACH LEAR, P170; TORKKOLA K, 2001, IEEE ICDM 2001 WORKS; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y., 1997, P 14 INT C MACH LEAR, P412	26	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-24523-5	LECT NOTES COMPUT SC			2005	3406						682	693				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCD56	WOS:000228725100076	
J	Viaene, S; Derrig, RA; Dedene, G				Viaene, S; Derrig, RA; Dedene, G			A case study of applying boosting naive Bayes to claim fraud diagnosis	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						data mining; pattern recognition; classifier design and evaluation; claim fraud detection; knowledge discovery; decision support	CLASSIFICATION; CLASSIFIERS	In this paper, we apply the weight of evidence reformulation of AdaBoosted naive Bayes scoring due to Ridgeway et al. [38] to the problem of diagnosing insurance claim fraud. The method effectively combines the advantages of boosting and the explanatory power of the weight of evidence scoring framework. We present the results of an experimental evaluation with an emphasis on discriminatory power, ranking ability, and calibration of probability estimates. The data to which we apply the method consists of closed personal injury protection (PIP) automobile insurance claims from accidents that occurred in Massachusetts during 1993 and were previously investigated for suspicion of fraud by domain experts. The data mimic the most commonly occurring data configuration-that is, claim records consisting of information pertaining to several binary fraud indicators. The findings of the study reveal the method to be a valuable contribution to the design of intelligible, accountable, and efficient fraud detection support.	Katholieke Univ Leuven, Dept Appl Econ Sci, B-3000 Louvain, Belgium; Vlerick Leuven Gent Management Sch, Louvain, Belgium; Automobile Insurers & Insurance Fraud Bur Massach, Boston, MA 02110 USA	Viaene, S (reprint author), Katholieke Univ Leuven, Dept Appl Econ Sci, Naamsestr 69, B-3000 Louvain, Belgium.	stijn.viaene@econ.kuleuven.ac.be; richard@aib.org; guido.dedene@econ.kuleuven.ac.be	Viaene, Stijn/C-2981-2009				Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BECKER B, 2001, INFORMATION VISUALIZ; Bennett P.N., 2000, CMUCS00155 SCH COMP; Berger JO, 1993, STAT DECISION THEORY; Bernardo J., 2001, BAYESIAN THEORY; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; *COM EUR ASS, 1997, EUR INS ANT GUID; *COM EUR ASS, 1996, EUR INS ANT GUID; COPAS JB, 1983, APPL STAT-J ROY ST C, V32, P25, DOI 10.2307/2348040; DERRIG RA, 2002, J RISK INSURANCE, V69; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R. O., 2000, PATTERN CLASSIFICATI; Elkan C., 1997, CS97557 U CAL DEP CO; Freund Y., 1995, P 2 EUR C COMP LEARN; Freund Y, 1996, P 13 INT C MACH LEAR; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Gelman A, 1995, BAYESIAN DATA ANAL; Good I, 1965, ESTIMATION PROBABILI; GOOD IJ, 1983, P 2 VAL INT M BAY ST; Hand D., 1997, CONSTRUCTION ASSESSM; Hand D J, 1992, Stat Methods Med Res, V1, P49, DOI 10.1177/096228029200100104; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; HANLEY JA, 1982, RADIOLOGY, V143, P29; Kearns M. J., 1994, INTRO COMPUTATIONAL; Kohavi R., 1997, P 9 EUR C MACH LEARN; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; OKANE JW, 1999, STAT ANAL CLIN VARIA; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; Pearl J., 1988, PROBABILISTIC REASON; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1998, P 15 INT C MACH LEAR; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RIDGEWAY G, 1998, P 4 INT C KNOWL DISC; Ridgeway G, 1999, P 7 INT WORKSH ART I; Shapire R., 1998, ANN STAT, V26, P1651; SPIEGELHALTER DJ, 1984, J ROY STAT SOC A STA, V147, P35, DOI 10.2307/2981737; SPIEGELHALTER DJ, 1986, STAT MED, V5, P421, DOI 10.1002/sim.4780050506; Suykens J., 2002, LEAST SQUARES SUPPOR, VI; SWETS JA, 1979, INVEST RADIOL, V14, P109, DOI 10.1097/00004424-197903000-00002; Swets JA, 1982, EVALUATION DIAGNOSTI; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918; Viaene S, 2002, J RISK INSUR, V69, P373, DOI 10.1111/1539-6975.00023; VIAENE S, 2002, THESIS KU LEUVEN; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Weisberg Herbert W., 1991, J INSURANCE REGULATI, V9, P497; WEISBERG HI, 1998, RISQUES, V35, P75; ZADROZNY B, 2001, P 7 ACM SIGKDD C KNO; ZHENG Z, 1999, P 16 INT C MACH LEAR; 2002, CANADIAN COALITION I; 2002, COALITION INSURANCE	52	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2004	16	5					612	620		10.1109/TKDE.2004.1277822		9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	814LG	WOS:000220975600007	
J	Zhang, NL; Nielsen, TD; Jensen, FV				Zhang, NL; Nielsen, TD; Jensen, FV			Latent variable discovery in classification models	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article; Proceedings Paper	Workshop on Bayesian Models in Medicine	JUL   01, 2001	Cascais, PORTUGAL			naive Bayes model; Bayesian networks; latent variables; learning; scientific discovery	BAYESIAN NETWORKS; LIKELIHOOD	The naive Bayes model makes the often unrealistic assumption that the feature variables are mutually independent given the class variable. We interpret a violation of this assumption as an indication of the presence of latent variables, and we show how latent variables can be detected. Latent variable discovery is interesting, especially for medical applications, because it can lead to a better understanding of application domains. It can also improve classification accuracy and boost user confidence in classification models. (C) 2004 Elsevier B.V. All rights reserved.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Univ Aalborg, Dept Comp Sci, Aalborg, Denmark	Zhang, NL (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	lzhang@cs.ust.hk; tdn@cs.auc.dk; fvj@cs.auc.dk					Blake C. L., 1998, UCI REPOSITORY MACHI; Chickering DM, 1997, MACH LEARN, V29, P181; CONNOLLY D, 1993, P 10 INT C MACH LEAR, P65; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; ELIDAN G, 2000, ADV NEURAL INFORMATI, V13, P479; Elidan G., 2001, P 17 C UNC ART INT U, P144; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N., 1997, P 14 INT C MACH LEAR, P125; Heckerman D., 1995, MSRTR9506; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Kwoh CK, 1996, ARTIF INTELL, V88, P1, DOI 10.1016/0004-3702(95)00119-0; MARTIN J, 1994, LRGCONR941 U PITTSB; PAZZANI M, 1995, P 5 INT WORKSH AI ST; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Thrun S. B., 1991, CMUCS91197	16	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	MAR	2004	30	3					283	299		10.1016/j.artmed.2003.11.004		17	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	810CC	WOS:000220681400005	
J	Shyu, ML; Haruechaiyasak, C; Chen, SC				Shyu, ML; Haruechaiyasak, C; Chen, SC			Category cluster discovery from distributed WWW directories	INFORMATION SCIENCES			English	Article						distributed information sources; information integration; cluster analysis; web mining; document classification	WEB	Due to the inherently distributed nature of many networks, including the Internet, information and knowledge are generated and organized independently by different groups of people. To discover and exploit all the knowledge from different sources, a method of knowledge integration is usually required. Considering the document category sets as information sources, we define a problem of information integration called category merging. The purpose of category merging is to automatically construct a unified category set which represents and exploits document information from several different sources. This merging process is based on the clustering concept where categories with similar characteristics are merged into the same cluster under certain distributed constraints. To evaluate the quality of the merged category set, we measure the precision and recall values under three classification methods, Naive Bayes, Vector Space Model, and K-Nearest Neighbor. In addition, we propose a performance measure called cluster entropy, which determines how well the categories from different sources are distributed over the resulting clusters. We perform the merging process by using the real data sets collected from three different Web directories. The results show that our merging process improves the classification performance over the non-merged approach and also provides a better representation for all categories from distributed directories. (C) 2003 Elsevier Inc. All rights reserved.	Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA; Florida Int Univ, Lab Sch Comp Sci, Distributed Multimedia Informat Syst, Miami, FL 33199 USA	Shyu, ML (reprint author), Univ Miami, Dept Elect & Comp Engn, POB 248294, Coral Gables, FL 33124 USA.						BRAZDIL P, 1990, CURRENT TRENDS ARTIF, P412; Broder A.Z., 1997, P 6 INT WORLD WID WE, P391; Chakrabarti S., 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; Cooley R, 1997, PROC INT C TOOLS ART, P558, DOI 10.1109/TAI.1997.632303; Halkidi M, 2002, SIGMOD RECORD, V31, P40; Haruechaiyasak C., 2002, International Journal of Computational Intelligence and Applications, V2, DOI 10.1142/S1469026802000609; Haruechaiyasak C, 2002, P INT COMP SOFTW APP, P487, DOI 10.1109/CMPSAC.2002.1045052; KAUFMAN L, 1990, FINDING GROU0S DATA; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; PINTO HS, 1999, P IJCAI WORKSH ONT P; Pirolli P., 1999, P 2 USENIX S INT TEC, P139; Rasmussen E., 1992, INFORMATION RETRIEVA, P419; Salton G., 1971, SMART RETRIEVAL SYST; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHYU ML, 2001, 7 INT C DISTR MULT S, P494; SHYU ML, 2001, IEEE INT C SYST MAN, P1717; Wang J., 1999, ACM COMPUTER COMM RE, V29, P36, DOI DOI 10.1145/505696.505701; Yang Y., 2001, P 24 ANN INT ACM SIG, P137, DOI 10.1145/383952.383975; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290956	24	11	11	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	OCT 15	2003	155	3-4					181	197		10.1016/S0020-0255(03)00169-5		17	Computer Science, Information Systems	Computer Science	729BR	WOS:000185751500002	
S	Zadrozny, B		Dietterich, TG; Becker, S; Ghahramani, Z		Zadrozny, B			Reducing multiclass to binary by coupling probability estimates	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 14, VOLS 1 AND 2	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	15th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 03-08, 2001	VANCOUVER, CANADA					This paper presents a method for obtaining class membership probability estimates for multiclass classification problems by coupling the probability estimates produced by binary classifiers. This is an extension for arbitrary code matrices of a method due to Hastie and Tibshirani for pairwise coupling of probability estimates. Experimental results with Boosted Naive Bayes show that our method produces calibrated class membership probability estimates, while having similar classification accuracy as loss-based decoding, a method for obtaining the most likely class that does not generate probability estimates.	Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA	Zadrozny, B (reprint author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.						Allwein EL, 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Blake C. L., 1998, UCI REPOSITORY MACHI; Bradley R., 1952, BIOMETRICS, p[1952, 324]; Crammer K., 2000, P 13 ANN C COMP LEAR, P35; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Elkan C., 1997, CS97557 U CAL; HASTIE T, 1998, ADV NEURAL INFORMATI, V10; Utschick W, 2001, NEURAL COMPUT, V13, P1065, DOI 10.1162/08997660151134334; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540	10	11	11	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-04208-8	ADV NEUR IN			2002	14						1041	1048				8	Computer Science, Artificial Intelligence	Computer Science	BV95T	WOS:000180520100130	
J	Pena, JM; Lozano, JA; Larranaga, P				Pena, JM; Lozano, JA; Larranaga, P			Learning Bayesian networks for clustering by means of constructive induction	PATTERN RECOGNITION LETTERS			English	Article						clustering; Bayesian networks; learning from incomplete data; constructive induction; EM algorithm; bound and collapse method; simulated annealing	LIKELIHOOD	The purpose of this paper is to present and evaluate a heuristic algorithm for learning Bayesian networks for clustering. Our approach is based upon improving the Naive-Bayes model by means of constructive induction. A key idea in this approach is to treat expected data as real data. This allows us to complete the database and to take advantage of factorable closed forms for the marginal likelihood. In order to get such an advantage, we search for parameter values using the EM algorithm or another alternative approach that we have developed: a hybridization of the Bound and Collapse method and the EM algorithm, which results in a method that exhibits a faster convergence rate and a more effective behaviour than the EM algorithm. Also, we consider the possibility of interleaving runnings of these two methods after each structural change. We evaluate our approach on synthetic and real-world databases. (C) 1999 Elsevier Science B.V. All rights reserved.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, E-20080 San Sebastian, Spain	Pena, JM (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, POB 649, E-20080 San Sebastian, Spain.		Lozano, Jose/F-5120-2010; Larranaga, Pedro/F-9293-2013				ARCISZEWSKI T, 1995, P 3 INT ROUND TABL C, P397; Cheeseman P, 1995, ADV KNOWLEDGE DISCOV, P153; Chickering DM, 1997, MACH LEARN, V29, P181; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda R., 1973, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N, 1998, P 14 C UNC ART INT, P129; Hartigan J. A., 1975, CLUSTERING ALGORITHM; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Kaufman L., 1990, FINDING GROUPS DATA; Keogh E., 1999, P 7 INT WORKSH ART I, P225; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; McLachlan G., 1997, EM ALGORITHM EXTENSI; Meila M., 1998, P 14 C UNC ART INT, P386; Merz C., 1997, UCI REPOSITORY MACHI; PAZZANI M, 1996, INFORMATION STAT IND; Pazzani M. J., 1996, LEARNING DATA ARTIFI, P239; PEOT M, 1996, P 12 C UNC ART INT; Ramoni M., 1997, P 13 C UNC ART INT; Ramoni M., 1998, INTELLIGENT DATA ANA, V2; Thiesson B., 1998, P 14 C UNC ART INT, P504	22	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	NOV	1999	20	11-13					1219	1230		10.1016/S0167-8655(99)00089-6		12	Computer Science, Artificial Intelligence	Computer Science	263YF	WOS:000084152300018	
S	Gama, J; Torgo, L; Soares, C		Coelho, H		Gama, J; Torgo, L; Soares, C			Dynamic discretization of continuous attributes	PROGRESS IN ARTIFICIAL INTELLIGENCE-IBERAMIA 98	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th Ibero-American Congress on Artificial Intelligence (IBERAMIA 98)	OCT 05-09, 1998	LISBON, PORTUGAL	Fundacao Calouste Gulbenkian, ESPRIT, IBM Portugal, Fundacao Ciencia Technol, Caixa Geral Depositos, Agencia Abreu, Compulog Net, Uniao Latina, Eival, British Council, RDP Radio Difusao Portugue, Camara Municipal Lisboa, Fundacao Liso America Desenvolvimento, Electricidade Portugal, Edicoes Colibri, Minolta, Edutorial Verbo, Esoterica		discretization; feature selection; continuous attributes		Discretization of continuous attributes is an important task for certain types of machine learning algorithms. Bayesian approaches, for instance, require assumptions about data distributions. Decision Trees on the other hand, require sorting operations to deal with continuous attributes, which largely increase learning times. This paper presents a new method of discretization, whose main characteristic is that it takes into account interdependencies between attributes. Detecting interdependencies can be seen as discovering redundant attributes. This means that our method performs attribute selection as a side effect of the discretization. Empirical evaluation on five benchmark datasets from UCI repository, using C4.5 and a naive Bayes, shows a consistent reduction of the features without loss of generalization accuracy.	Univ Porto, FEP, LIACC, P-4150 Porto, Portugal	Gama, J (reprint author), Univ Porto, FEP, LIACC, Rua Campo 823, P-4150 Porto, Portugal.		Gama, Joao/A-2070-2008; Soares, Carlos/J-5764-2012	Gama, Joao/0000-0003-3357-1195; Soares, Carlos/0000-0003-4549-8917			CATLETT J, 1991, MACH LEARN P 8 INT C; CATLETT J, 1991, LNAI, V482; DOMINGOS P, 1996, MACH LEARN P 13 INT; Dougherty J., 1995, MACH LEARN P 12 INT; FAYYAD UM, 1993, 13 INT JOINT C ART I; Holte R. C., 1993, MACHINE LEARNING, V11; KERBER R, 1992, P 10 NAT C ART INT A; KOHAVI R, 1996, P KDD 96; MORET B, 1990, ALGORITHMS P NP DESI, V1; RICHELDI M, 1995, LNAI, V912; ROBNIKSIKONJA M, 1995, P RK95; TORGO L, 1997, LNAI, V1224	12	11	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-64992-1	LECT NOTES ARTIF INT			1998	1484						160	169				10	Computer Science, Artificial Intelligence	Computer Science	BN72H	WOS:000082727600014	
J	Cheng, FX; Ikenaga, Y; Zhou, YD; Yu, Y; Li, WH; Shen, J; Du, Z; Chen, L; Xu, CY; Liu, GX; Lee, PW; Tang, Y				Cheng, Feixiong; Ikenaga, Yutaka; Zhou, Yadi; Yu, Yue; Li, Weihua; Shen, Jie; Du, Zheng; Chen, Lei; Xu, Congying; Liu, Guixia; Lee, Philip W.; Tang, Yun			In Silico Assessment of Chemical Biodegradability	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							READY BIODEGRADABILITY; NEAREST-NEIGHBOR; PREDICTION; CLASSIFICATION; MODELS; QSAR; APPLICABILITY; NONINHIBITORS; SUBSTRUCTURES; INHIBITORS	Biodegradation is the principal environmental dissipation process. Due to a lack of comprehensive experimental data, high study cost and time-consuming, in silico approaches for assessing the biodegradable profiles of chemicals are encouraged and is an active current research topic. Here we developed in silico methods to estimate chemical biodegradability in the environment. At first 1440 diverse compounds tested under the Japanese Ministry of International Trade and Industry (MITI) protocol were used. Four different methods, namely support vector machine, k-nearest neighbor, naive Bayes, and C4.5 decision tree, were used to build the combinatorial classification probability models of ready versus not ready biodegradability using physicochemical descriptors and fingerprints separately. The overall predictive accuracies of the best models were more than 80% for the external test set of 164 diverse compounds. Some privileged substructures were further identified for ready or not ready biodegradable chemicals by combining information gain and substructure fragment analysis. Moreover, 27 new predicted chemicals were selected for experimental assay through the Japanese MITI test protocols, which validated that all 27 compounds were predicted correctly. The predictive accuracies of our models outperform the commonly used software of the EPI Suite. Our study provided critical tools for early assessment of biodegradability of new organic chemicals in environmental hazard assessment.	[Cheng, Feixiong; Zhou, Yadi; Yu, Yue; Li, Weihua; Shen, Jie; Du, Zheng; Chen, Lei; Xu, Congying; Liu, Guixia; Lee, Philip W.; Tang, Yun] E China Univ Sci & Technol, Shanghai Key Lab New Drug Design, Sch Pharm, Shanghai 200237, Peoples R China; [Lee, Philip W.] Kyoto Univ, Grad Sch Agr, Sakyo Ku, Kyoto 6068502, Japan; [Ikenaga, Yutaka] Natl Inst Technol & Evaluat NITE, Safety Assessment Div, Chem Management Ctr, Shibuya Ku, Tokyo 1510066, Japan	Lee, PW (reprint author), E China Univ Sci & Technol, Shanghai Key Lab New Drug Design, Sch Pharm, 130 Meilong Rd, Shanghai 200237, Peoples R China.	philiplee2007@gmail.com; ytang234@ecust.edu.cn	Shen, Jie/H-5258-2011; Cheng, Feixiong/D-9922-2013; LI, Weihua/G-7190-2011	Cheng, Feixiong/0000-0002-1251-3116; 	Program for New Century Excellent Talents in University [NCET-08-0774]; National Natural Science Foundation of China [21072059]; 111 Project [B07023]; Shanghai Committee of Science and Technology [11DZ2260600]; Fundamental Research Funds for the Central Universities [WY1113007]	This work was supported by the Program for New Century Excellent Talents in University (Grant NCET-08-0774), the National Natural Science Foundation of China (Grant 21072059), the 111 Project (Grant B07023), the Shanghai Committee of Science and Technology (11DZ2260600), and the Fundamental Research Funds for the Central Universities (WY1113007).	Andreini C, 2011, J CHEM INF MODEL, V51, P730, DOI 10.1021/ci100392q; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Boethling RS, 2004, ENVIRON TOXICOL CHEM, V23, P911, DOI 10.1897/03-280; Breiman L., 1984, CLASSIFICATION REGRE; Chang C.-C., LIBSVM LIB SUPPORT V; Cheng FX, 2011, J CHEM INF MODEL, V51, P2482, DOI 10.1021/ci200317s; Cheng FX, 2011, CHEMOSPHERE, V82, P1636, DOI 10.1016/j.chemosphere.2010.11.043; Cheng FX, 2011, J CHEM INF MODEL, V51, P996, DOI 10.1021/ci200028n; Corinna Cortes, 1995, MACH LEARN, V20, P273; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cuissart B, 2002, J CHEM INF COMP SCI, V42, P1043, DOI 10.1021/ci020017w; DeLisle RK, 2004, J CHEM INF COMP SCI, V44, P862, DOI 10.1021/ci034188s; Ericson JF, 2010, ENVIRON SCI TECHNOL, V44, P375, DOI 10.1021/es902205r; EVANS BE, 1988, J MED CHEM, V31, P2235, DOI 10.1021/jm00120a002; Hao RX, 2009, CHEMOSPHERE, V75, P987, DOI 10.1016/j.chemosphere.2009.01.069; Hiromatsu K, 2000, CHEMOSPHERE, V41, P1749, DOI 10.1016/S0045-6535(00)00056-4; Horton DA, 2003, CHEM REV, V103, P893, DOI 10.1021/cr020033s; Hou BK, 2003, J CHEM INF COMP SCI, V43, P1051, DOI 10.1021/ci034018f; Howard PH, 2010, ENVIRON SCI TECHNOL, V44, P2277, DOI 10.1021/es903383a; Howard PH, 2011, ENVIRON SCI TECHNOL, V45, P6938, DOI 10.1021/es201196x; HOWARD PH, 1992, ENVIRON TOXICOL CHEM, V11, P593, DOI 10.1897/1552-8618(1992)11[593:PMFABD]2.0.CO;2; Jaworska JS, 2003, ENVIRON TOXICOL CHEM, V22, P1710, DOI 10.1897/01-302; Jensen BF, 2007, J MED CHEM, V50, P501, DOI 10.1021/jm060333; Judson R, 2008, TOXICOL APPL PHARM, V233, P7, DOI 10.1016/j.taap.2007.12.037; Klekota J, 2008, BIOINFORMATICS, V24, P2518, DOI 10.1093/bioinformatics/btn479; OECD 301, 1992, READ BIOD; Pavan M, 2008, QSAR COMB SCI, V27, P32, DOI 10.1002/qsar.200710117; Philipp B, 2007, ENVIRON SCI TECHNOL, V41, P1390, DOI 10.1021/es061505d; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Raymond JW, 2001, J HAZARD MATER, V84, P189, DOI 10.1016/S0304-3894(01)00207-2; Rodgers AD, 2010, CHEM RES TOXICOL, V23, P724, DOI 10.1021/tx900451r; Rorije E, 1999, CHEMOSPHERE, V38, P1409, DOI 10.1016/S0045-6535(98)00543-8; Rusyn I, 2010, ENVIRON HEALTH PERSP, V118, P1047, DOI 10.1289/ehp.1001925; Shen J., 2008, QSAR COMB SCI, V72, P635; Shen J, 2010, J CHEM INF MODEL, V50, P1034, DOI 10.1021/ci100104j; Sonquist J. A., 1964, DETECTION INTERACTIO, P296; Sushko I, 2010, J CHEM INF MODEL, V50, P2094, DOI 10.1021/ci100253r; Tetko IV, 2008, J CHEM INF MODEL, V48, P1733, DOI 10.1021/ci800151m; Tropsha A, 2007, CURR PHARM DESIGN, V13, P3494, DOI 10.2174/138161207782794257; Tunkel J, 2000, ENVIRON TOXICOL CHEM, V19, P2478, DOI 10.1897/1551-5028(2000)019<2478:PRBITJ>2.3.CO;2; Wang YL, 2009, NUCLEIC ACIDS RES, V37, pW623, DOI 10.1093/nar/gkp456; Watson P, 2008, J CHEM INF MODEL, V48, P166, DOI 10.1021/ci7003253; Weaver S, 2008, J MOL GRAPH MODEL, V26, P1315, DOI 10.1016/j.jmgm.2008.01.002; Yap CW, 2011, J COMPUT CHEM, V32, P1466, DOI 10.1002/jcc.21707; Zhu H, 2008, ENVIRON HEALTH PERSP, V116, P506, DOI 10.1289/ehp.10573	45	10	10	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAR	2012	52	3					655	669		10.1021/ci200622d		15	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	913NJ	WOS:000301884400003	
J	Aguiar-Pulido, V; Munteanu, CR; Seoane, JA; Fernandez-Blanco, E; Perez-Montoto, LG; Gonzalez-Diaz, H; Dorado, J				Aguiar-Pulido, Vanessa; Munteanu, Cristian R.; Seoane, Jose A.; Fernandez-Blanco, Enrique; Perez-Montoto, Lazaro G.; Gonzalez-Diaz, Humberto; Dorado, Julian			Naive Bayes QSDR classification based on spiral-graph Shannon entropies for protein biomarkers in human colon cancer	MOLECULAR BIOSYSTEMS			English	Article							AMINO-ACID-COMPOSITION; HIV-1 REVERSE-TRANSCRIPTASE; SUPPORT VECTOR MACHINE; STATE ENZYME-KINETICS; TOPOLOGICAL INDEXES; HUMAN BREAST; QSAR MODEL; NUMERICAL CHARACTERIZATION; SUBCELLULAR-LOCALIZATION; CONNECTIVITY INDEXES	Fast cancer diagnosis represents a real necessity in applied medicine due to the importance of this disease. Thus, theoretical models can help as prediction tools. Graph theory representation is one option because it permits us to numerically describe any real system such as the protein macromolecules by transforming real properties into molecular graph topological indices. This study proposes a new classification model for proteins linked with human colon cancer by using spiral graph topological indices of protein amino acid sequences. The best quantitative structure-disease relationship model is based on eleven Shannon entropy indices. It was obtained with the Naive Bayes method and shows excellent predictive ability (90.92%) for new proteins linked with this type of cancer. The statistical analysis confirms that this model allows diagnosing the absence of human colon cancer obtaining an area under receiver operating characteristic of 0.91. The methodology presented can be used for any type of sequential information such as any protein and nucleic acid sequence.	[Aguiar-Pulido, Vanessa; Munteanu, Cristian R.; Seoane, Jose A.; Fernandez-Blanco, Enrique; Dorado, Julian] Univ A Coruna, Dept Informat & Commun Technol, La Coruna 15071, Spain; [Perez-Montoto, Lazaro G.; Gonzalez-Diaz, Humberto] Univ Santiago de Compostela, Fac Pharm, Dept Microbiol & Parasitol, Santiago De Compostela 15782, Spain	Seoane, JA (reprint author), Univ A Coruna, Dept Informat & Commun Technol, Campus Elvina, La Coruna 15071, Spain.	jseoane@udc.es	Gonzalez-Diaz, Humberto/A-6785-2012; Munteanu, Cristian/G-1714-2011; Seoane, Jose A./I-4060-2012	Gonzalez-Diaz, Humberto/0000-0002-9392-2797; Seoane, Jose A./0000-0002-3856-9177	Xunta de Galicia; European Social Fund (ESF); Carlos III Health [RD07/0067/0005]; Economy and Industry Department of Xunta de Galicia [10SIN105004PR]	Cristian R. Munteanu and Gonzalez-Diaz H. acknowledge the funding support for a research position by the "Isidro Parga Pondal'' program from Xunta de Galicia and the European Social Fund (ESF). The work of Vanessa Aguiar-Pulido is supported by the "Plan I2C'' program, from Xunta de Galicia, and by the ESF. This work is supported by the following projects: RD07/0067/0005 funded by the Carlos III Health and 10SIN105004PR funded by Economy and Industry Department of Xunta de Galicia.	ALTHAUS IW, 1993, J BIOL CHEM, V268, P6119; ALTHAUS IW, 1993, BIOCHEMISTRY-US, V32, P6548, DOI 10.1021/bi00077a008; Althaus IW, 1996, BIOCHEM PHARMACOL, V51, P743, DOI 10.1016/0006-2952(95)02390-9; ALTHAUS IW, 1994, EXPERIENTIA, V50, P23, DOI 10.1007/BF01992044; Bender A, 2011, METHODS MOL BIOL, V672, P175, DOI 10.1007/978-1-60761-839-3_7; Bishop C.M., 1995, NEURAL NETWORKS PATT; Boursi B, 2007, CURR PHARM DESIGN, V13, P2274; Castillo-Garit JA, 2008, J COMPUT CHEM, V29, P2500, DOI 10.1002/jcc.20964; Chen C, 2009, PROTEIN PEPTIDE LETT, V16, P27; Chou KC, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009931; Chou K. C., 2011, NATURAL SCI, V3, P862, DOI DOI 10.4236/NS.2011.310111).NATURAL; Chou K.-C., 2009, NAT SCI, V1, P63, DOI DOI 10.4236/NS2009.12011; CHOU KC, 1990, BIOPHYS CHEM, V35, P1, DOI 10.1016/0301-4622(90)80056-D; CHOU KC, 1989, J BIOL CHEM, V264, P12074; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; CHOU KC, 1994, ANAL BIOCHEM, V221, P217, DOI 10.1006/abio.1994.1405; CHOU KC, 1981, J THEOR BIOL, V91, P637; Chou KC, 2012, MOL BIOSYST, V8, P629, DOI 10.1039/c1mb05420a; Chou KC, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018258; CHOU KC, 1980, BIOCHEM J, V187, P829; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1996, J PROTEIN CHEM, V15, P59, DOI 10.1007/BF01886811; Chou KC, 2010, CURR DRUG METAB, V11, P369; CHOU KC, 1992, AIDS RES HUM RETROV, V8, P1967, DOI 10.1089/aid.1992.8.1967; Chou KC, 2011, J THEOR BIOL, V273, P236, DOI 10.1016/j.jtbi.2010.12.024; Cruz-Monteagudo M, 2008, BIOORGAN MED CHEM, V16, P9684, DOI 10.1016/j.bmc.2008.10.004; Cruz-Monteagudo M, 2008, POLYMER, V49, P5575, DOI 10.1016/j.polymer.2008.09.070; Cruz-Monteagudo M, 2008, CHEM RES TOXICOL, V21, P619, DOI 10.1021/tx700296t; Demchuk E, 2011, TOXICOL APPL PHARM, V254, P192, DOI 10.1016/j.taap.2010.10.017; Devillers J., 1999, TOPOLOGICAL INDICES; Dobson PD, 2004, CURR MED CHEM, V11, P2135; Dobson PD, 2005, J MOL BIOL, V345, P187, DOI 10.1016/j.jmb.2004.10.024; Esmaeili M, 2010, J THEOR BIOL, V263, P203, DOI 10.1016/j.jtbi.2009.11.016; Estrada E, 2001, J CHEM INF COMP SCI, V41, P791, DOI 10.1021/ci000156i; Ferino G, 2008, BIOCHEM BIOPH RES CO, V372, P320, DOI 10.1016/j.bbrc.2008.05.071; Freedman AN, 2009, J CLIN ONCOL, V27, P686, DOI 10.1200/JCO.2008.17.4797; Freitas AA, 2011, BMC GENOMICS, V12, DOI 10.1186/1471-2164-12-27; Georgiou DN, 2009, J THEOR BIOL, V257, P17, DOI 10.1016/j.jtbi.2008.11.003; Glas AS, 2003, J CLIN EPIDEMIOL, V56, P1129, DOI 10.1016/S0895-4356(03)00177-X; Gonzalez-Diaz H., 2007, EL C SYNTH ORG CHEM, V11, P10; Gonzalez-Diaz H, 2011, J THEOR BIOL, V276, P229, DOI 10.1016/j.jtbi.2011.01.010; Gonzalez-Diaz H, 2011, MOL BIOSYST, V7, P1938, DOI 10.1039/c1mb05069a; Gonzalez-Diaz H, 2011, J PROTEOME RES, V10, P1698, DOI 10.1021/pr101009e; Guetlein M., 2009, P IEEE S COMP INT DA; Guyon, 2003, J MACH LEARN RES, V3, P1157; Phillips A., 1985, SIGKDD EXPLORATIONS, V31, P329, DOI DOI 10.1145/1656274.1656278; Hall M., 2008, P 21 FLOR ART INT RE; Hall MA, 1998, CORRELATION BASED FE; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Hou XB, 2011, PROTEIN PEPTIDE LETT, V18, P440; Iba W, 1992, ANAL BAYESIAN CLASSI; Ivanciuc O, 2000, J CHEM INF COMP SCI, V40, P631, DOI 10.1021/ci9900884; Jackson C, 2011, BIOINFORMATICS, V27, P1854, DOI 10.1093/bioinformatics/btr286; Jemal A, 2008, CA-CANCER J CLIN, V58, P71, DOI 10.3322/CA.2007.0010; Kohavi R., 1995, STUDY CROSS VALIDATI; KUZMIC P, 1992, ANAL BIOCHEM, V200, P68, DOI 10.1016/0003-2697(92)90278-F; LINNET K, 1988, CLIN CHEM, V34, P1379; Liu H., 1996, 13 INT C MACH LEARN; Marrero Ponce Yovani, 2004, Bioorganic & Medicinal Chemistry, V12, P5331, DOI 10.1016/j.bmc.2004.07.051; McLachlan GJ, 2004, ANAL MICROARRAY GENE; Mitra P, 2011, STRUCTURE, V19, P304, DOI 10.1016/j.str.2011.01.009; Mohabatkar H, 2011, J THEOR BIOL, V281, P18, DOI 10.1016/j.jtbi.2011.04.017; Mohabatkar H, 2010, PROTEIN PEPTIDE LETT, V17, P1207; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Morales AH, 2006, J MOL MODEL, V12, P769, DOI 10.1007/s00894-005-0088-5; Munteanu CR, 2009, J THEOR BIOL, V257, P303, DOI 10.1016/j.jtbi.2008.11.017; Munteanu CR, 2008, S2SNET SEQUENCE STAR; Munteanu CR, 2010, CURR PHARM DESIGN, V16, P2640; Ng AY, 2002, NEURAL INF PROCESS S, V2, P841, DOI 10.1.1.19.9829; Perez Montoto L. G., 2009, CULSPIN COMPUTE ULAM; PICARD RR, 1984, J AM STAT ASSOC, V79, P575, DOI 10.2307/2288403; Qi XQ, 2007, J THEOR BIOL, V249, P681, DOI 10.1016/j.jtbi.2007.08.025; Randic M, 2007, J MOL GRAPH MODEL, V26, P290, DOI 10.1016/j.jmgm.2006.12.006; Randic M, 2005, CHEM PHYS LETT, V407, P205, DOI 10.1016/j.cplett.2005.03.086; Randic M, 2003, J CHEM INF COMP SCI, V43, P532, DOI 10.1021/ci020051a; Randic M, 2001, J CHEM INF COMP SCI, V41, P1339, DOI 10.1021/ci0001684; Rappin Noel, 2006, WXPYTHON ACTION; Riera-Fernandez P, 2011, CURR BIOINFORM, V6, P94; Rodriguez-Soca Y, 2010, POLYMER, V51, P264, DOI 10.1016/j.polymer.2009.11.029; Roy K, 2011, COMB CHEM HIGH T SCR, V14, P450; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Schafmayer C, 2007, INT J CANCER, V121, P555, DOI 10.1002/ijc.22735; Sjoblom T, 2006, SCIENCE, V314, P268, DOI 10.1126/science.1133427; Tropsha A, 2010, MOL INFORM, V29, P476, DOI 10.1002/minf.201000061; Vapnik V., 1998, STAT LEARNING THEORY; Vilar S, 2009, J THEOR BIOL, V261, P449, DOI 10.1016/j.jtbi.2009.07.031; Vilar S, 2008, J COMPUT CHEM, V29, P2613, DOI 10.1002/jcc.21016; Wang J, 2011, PROTEIN PEPTIDE LETT, V18, P956; Wei H, 2009, MED CHEM, V5, P305; Wei W, 2011, J AM MED INFORM ASSN, V18, P370, DOI 10.1136/amiajnl-2011-000101; Wu ZC, 2010, J THEOR BIOL, V267, P29, DOI 10.1016/j.jtbi.2010.08.007; Wu ZC, 2011, MOL BIOSYST, V7, P3287, DOI 10.1039/c1mb05232b; Xiao XA, 2011, MOL BIOSYST, V7, P911, DOI 10.1039/c0mb00170h; Xing CH, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002110; Xu Y, 2011, J R SOC INTERFACE, V8, P555, DOI 10.1098/rsif.2010.0384; ZHANG CT, 1994, J MOL BIOL, V238, P1, DOI 10.1006/jmbi.1994.1263; Zhou GP, 2011, PROTEIN PEPTIDE LETT, V18, P966; Zhou GP, 2011, J THEOR BIOL, V284, P142, DOI 10.1016/j.jtbi.2011.06.006	99	10	10	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	1742-206X			MOL BIOSYST	Mol. Biosyst.		2012	8	6					1716	1722		10.1039/c2mb25039j		7	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	939AR	WOS:000303776200013	
J	Soria, D; Garibaldi, JM; Ambrogi, F; Biganzoli, EM; Ellis, IO				Soria, Daniele; Garibaldi, Jonathan M.; Ambrogi, Federico; Biganzoli, Elia M.; Ellis, Ian O.			A 'non-parametric' version of the naive Bayes classifier	KNOWLEDGE-BASED SYSTEMS			English	Article						Supervised learning; Naive Bayes; Logistic regression; Breast cancer; UCI data sets	GENE-EXPRESSION SIGNATURE; HUMAN BREAST-TUMORS; INCOMPLETE DATA; CANCER; SURVIVAL	Many algorithms have been proposed for the machine learning task of classification. One of the simplest methods, the naive Bayes classifier, has often been found to give good performance despite the fact that its underlying assumptions (of independence and a normal distribution of the variables) are perhaps violated. In previous work, we applied naive Bayes and other standard algorithms to a breast cancer database from Nottingham City Hospital in which the variables are highly non-normal and found that the algorithm performed well when predicting a class that had been derived from the same data. However, when we then applied naive Bayes to predict an alternative clinical variable, it performed much worse than other techniques. This motivated us to propose an alternative method, based on naive Bayes, which removes the requirement for the variables to be normally distributed, but retains the essential structure and other underlying assumptions of the method. we tested our novel algorithm on our breast cancer data and on three UCI datasets which also exhibited strong violations of normality. We found our algorithm outperformed naive Bayes in all four cases and outperformed multinomial logistic regression (MLR) in two cases. We conclude that our method offers a competitive alternative to MLR and naive Bayes when dealing with data sets in which non-normal distributions are observed. (C) 2011 Elsevier B.V. All rights reserved.	[Soria, Daniele; Garibaldi, Jonathan M.] Univ Nottingham, Sch Comp Sci, Nottingham NG8 1BB, England; [Ambrogi, Federico; Biganzoli, Elia M.] Univ Milan, Inst Med Stat & Biometry, I-20133 Milan, Italy; [Ellis, Ian O.] Univ Nottingham Hosp, Sch Mol Med Sci, Nottingham NG7 2UH, England; [Ellis, Ian O.] Univ Nottingham, Queens Med Ctr, Nottingham NG7 2UH, England	Soria, D (reprint author), Univ Nottingham, Sch Comp Sci, Jubilee Campus,Wollaton Rd, Nottingham NG8 1BB, England.	dqs@cs.nott.ac.uk; jmg@cs.nott.ac.uk; federico.ambrogi@unimi.it; elia.biganzoli@unimi.it; ian.ellis@nottingham.ac.uk			BIOPATTERN FP6 Network of Excellence [FP6-IST-508803]; BIOPTRAIN FP6 Marie-Curie EST Fellowship [FP6-007597]	This study was supported by the BIOPATTERN FP6 Network of Excellence (FP6-IST-508803) and the BIOPTRAIN FP6 Marie-Curie EST Fellowship (FP6-007597). Authors would also like to acknowledge the Turing Institute, Glasgow, Scotland for providing the vehicle Statlog dataset.	Abd El-Rehim DM, 2005, INT J CANCER, V116, P340, DOI 10.1002/ijc.21004; Asuncion A., 2007, UCI MACHINE LEARNING; Balamurugan Appavu Alias, 2011, Knowledge-Based Systems, V24, DOI 10.1016/j.knosys.2010.09.007; BOUCKAERT R, 2004, P 17 AUSTR C AI AI04; Chen JN, 2008, KNOWL-BASED SYST, V21, P530, DOI 10.1016/j.knosys.2008.03.013; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dougherty J., 1995, INT C MACH LEARN, P194; Evett I. W., 1987, KBS in Government. Proceedings of the Conference; GALEA MH, 1992, BREAST CANCER RES TR, V22, P207, DOI 10.1007/BF01840834; HABERMAN S, P 9 INT BIOM C, P104; Hall M, 2007, KNOWL-BASED SYST, V20, P120, DOI 10.1016/j.knosys.2006.11.008; Harrell FE, 1996, STAT MED, V15, P361, DOI 10.1002/(SICI)1097-0258(19960229)15:4<361::AID-SIM168>3.0.CO;2-4; Hsu CC, 2008, EXPERT SYST APPL, V35, P1080, DOI 10.1016/j.eswa.2007.08.031; John GH, 1995, P 11 C UNC ART INT; Lee CH, 2007, KNOWL-BASED SYST, V20, P220, DOI 10.1016/j.knosys.2006.05.014; Maindonald J, 2003, DATA ANAL GRAPHICS U; Mitchell T., 2005, GENERATIVE DISCRIMIN; Mitchell T.M., 1997, MACHINE LEARNING; Naderi A, 2007, ONCOGENE, V26, P1507, DOI 10.1038/sj.onc.1209920; Nahar J, 2007, J BIOL SYST, V15, P17, DOI 10.1142/S0218339007002076; NG AY, 2002, ADV NEURAL INFORM PR, P14; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pollack JR, 2002, P NATL ACAD SCI USA, V99, P12963, DOI 10.1073/pnas.162471999; Royston P, 1982, APPL STAT, V31, P176, DOI [DOI 10.2307/2347986, 10.2307/2347986]; Siebert J.P., 1987, TIRM87018; Soria D, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P619, DOI 10.1109/ICMLA.2008.97; Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van 't Veer LJ, 2003, BREAST CANCER RES, V5, P57, DOI 10.1186/bcr562; Venables W. N., 2002, MODERN APPL STAT S; Vuk M., 2006, METODOLOSKI ZVEZKI, V3, P89; Witten I.H., 2000, DATA MINING PRACTICA; XU L, 2005 IEEE MID SUMM W; Yager RR, 2006, INFORM SCIENCES, V176, P577, DOI 10.1016/j.ins.2004.12.006; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	35	10	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	AUG	2011	24	6					775	784		10.1016/j.knosys.2011.02.014		10	Computer Science, Artificial Intelligence	Computer Science	785JH	WOS:000292224800005	
J	Maji, P				Maji, Pradipta			Fuzzy-Rough Supervised Attribute Clustering Algorithm and Classification of Microarray Data	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						Attribute clustering; classification; gene selection; microarray analysis; rough sets	GENE-EXPRESSION DATA; PATTERNS; SETS	One of the major tasks with gene expression data is to find groups of coregulated genes whose collective expression is strongly associated with sample categories. In this regard, a new clustering algorithm, termed as fuzzy-rough supervised attribute clustering (FRSAC), is proposed to find such groups of genes. The proposed algorithm is based on the theory of fuzzy-rough sets, which directly incorporates the information of sample categories into the gene clustering process. A new quantitative measure is introduced based on fuzzy-rough sets that incorporates the information of sample categories to measure the similarity among genes. The proposed algorithm is based on measuring the similarity between genes using the new quantitative measure, whereby redundancy among the genes is removed. The clusters are refined incrementally based on sample categories. The effectiveness of the proposed FRSAC algorithm, along with a comparison with existing supervised and unsupervised gene selection and clustering algorithms, is demonstrated on six cancer and two arthritis data sets based on the class separability index and predictive accuracy of the naive Bayes' classifier, the K-nearest neighbor rule, and the support vector machine.	Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India	Maji, P (reprint author), Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India.	pmaji@isical.ac.in	jia, lp/H-5750-2011				Au WH, 2005, IEEE ACM T COMPUT BI, V2, P83; Boyle EI, 2004, BIOINFORMATICS, V20, P3710, DOI 10.1093/bioinformatics/bth456; Dembele D, 2003, BIOINFORMATICS, V19, P973, DOI 10.1093/bioinformatics/btg119; Dettling M, 2002, GENOME BIOL, V3; Devijver P., 1982, PATTERN RECOGNITION; Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004; DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107; Gasch AP, 2002, GENOME BIOL, V3; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T, 2001, GENOME BIOL, V2; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; Heyer LJ, 1999, GENOME RES, V9, P1106, DOI 10.1101/gr.9.11.1106; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370; Maji P, 2010, IEEE T KNOWL DATA EN, V22, P854, DOI 10.1109/TKDE.2009.124; Maji P, 2007, IEEE T SYST MAN CY B, V37, P1529, DOI 10.1109/TSMCB.2007.906578; Maji P, 2010, IEEE T SYST MAN CY B, V40, P741, DOI 10.1109/TSMCB.2009.2028433; McLachlan GJ, 2004, ANAL MICROARRAY GENE; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Pal SK, 1999, NEUROFUZZY PATTERN R; Pawlak Z., 1991, ROUGH SETS THEORETIC; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Vapnik V., 1995, NATURE STAT LEARNING; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	25	10	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419	1941-0492		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	FEB	2011	41	1					222	233		10.1109/TSMCB.2010.2050684		12	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	708TX	WOS:000286388300018	
J	Aguilera, PA; Fernandez, A; Reche, F; Rumi, R				Aguilera, P. A.; Fernandez, A.; Reche, F.; Rumi, R.			Hybrid Bayesian network classifiers: Application to species distribution models	ENVIRONMENTAL MODELLING & SOFTWARE			English	Article						Hybrid Bayesian networks; Classification; Mixtures of truncated exponentials; Conservation planning	FEATURE SUBSET-SELECTION; TRUNCATED EXPONENTIALS; CLIMATE-CHANGE; SPATIAL PREDICTION; PRESENCE-ABSENCE; HABITAT; MIXTURES; BIODIVERSITY; UNCERTAINTY; CONSERVATION	Bayesian networks are one of the most powerful tools in the design of expert systems located in an uncertainty framework. However, normally their application is determined by the discretization of the continuous variables. In this paper the naive Bayes (NB) and tree augmented naive Bayes (TAN) models are developed. They are based on Mixtures of Truncated Exponentials (MTE) designed to deal with discrete and continuous variables in the same network simultaneously without any restriction. The aim is to characterize the habitat of the spur-thighed tortoise (Testudo graeca graeca), using several continuous environmental variables, and one discrete (binary) variable representing the presence or absence of the tortoise. These models are compared with the full discrete models and the results show a better classification rate for the continuous one. Therefore, the application of continuous models instead of discrete ones avoids loss of statistical information due to the discretization. Moreover, the results of the TAN continuous model show a more spatially accurate distribution of the tortoise. The species is located in the Donana Natural Park, and in semiarid habitats. The proposed continuous models based on MTEs are valid for the study of species predictive distribution modelling. (C) 2010 Elsevier Ltd. All rights reserved.	[Fernandez, A.; Reche, F.; Rumi, R.] Univ Almeria, Dept Stat & Appl Math, Almeria 04120, Spain; [Aguilera, P. A.] Univ Almeria, Informat & Environm Res Grp, Dept Ecol, Almeria 04120, Spain	Fernandez, A (reprint author), Univ Almeria, Dept Stat & Appl Math, La Canada de San Urbano S-N, Almeria 04120, Spain.	aguilera@ual.es; afalvarez@ual.es; freche@ual.es; rrumi@ual.es			Spanish Ministry of Science and Innovation [TIN2007-67418-C03-02]; FEDER; Junta de Andalucia [P05-TIC-00276]	This work has been supported by the Spanish Ministry of Science and Innovation through project TIN2007-67418-C03-02, by FEDER funds, and by the Junta de Andalucia through project P05-TIC-00276.	AGUILERA P, 2007, P 1 C NAC BIOD; Anderson RP, 2002, OIKOS, V98, P3, DOI 10.1034/j.1600-0706.2002.t01-1-980116.x; Araujo MB, 2006, J BIOGEOGR, V33, P1712, DOI 10.1111/j.1365-2699.2006.01482.x; Araujo MB, 2004, GLOBAL CHANGE BIOL, V10, P1618, DOI 10.1111/j.1365-2486.2004.00828.x; Austin MP, 2002, ECOL MODEL, V157, P101, DOI 10.1016/S0304-3800(02)00205-3; Bell DA, 2000, MACH LEARN, V41, P175, DOI 10.1023/A:1007612503587; Ben-Bassat M., 1982, HDB STATISTICS, V1, P773, DOI 10.1016/S0169-7161(82)02038-0; Borsuk ME, 2004, ECOL MODEL, V173, P219, DOI 10.1016/j.ecolmodel.2003.08.020; Borsuk ME, 2006, ECOL MODEL, V192, P224, DOI 10.1016/j.ecolmodel.2005.07.006; Bromley J, 2005, ENVIRON MODELL SOFTW, V20, P231, DOI 10.1016/j.envsoft.2003.12.021; Brotons L, 2004, ECOGRAPHY, V27, P437, DOI 10.1111/j.0906-7590.2004.03764.x; Burgman MA, 2005, ECOLOGY, V86, P2007, DOI 10.1890/04-0906; Castillo E., 1997, EXPERT SYSTEMS PROBA; Cobb BR, 2007, STUD FUZZ SOFT COMP, V213, P81; Cobb BR, 2006, STAT COMPUT, V16, P293, DOI 10.1007/s11222-006-8175-8; Cowell R., 1999, STAT ENG INFORM SCI; Dedecker AP, 2004, ECOL MODEL, V174, P161, DOI 10.1016/j.ecolmodel.2004.01.003; Duda R.O., 2001, PATTERN CLASSIFICATI; Dzeroski S, 2003, ECOL MODEL, V170, P219, DOI 10.1016/S0304-3800(03)00229-1; Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x; Elvira Consortium, 2002, P 1 EUR WORKSH PROB, P222; Fernandez A, 2008, LECT NOTES COMPUT SC, V5290, P83, DOI 10.1007/978-3-540-88309-8_9; FERNANDEZ A, 2009, INT J UNCERTAIN FUZZ, V18, P69; Fernandez A, 2007, LECT NOTES COMPUT SC, V4723, P59; Ferrier S, 2002, SYST BIOL, V51, P331, DOI 10.1080/10635150252899806; FRIEDMAN, 1996, P 13 INT C MACH LEAR, P157; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Graham CH, 2004, EVOLUTION, V58, P1781, DOI 10.1554/03-274; Graham CH, 2004, TRENDS ECOL EVOL, V19, P497, DOI 10.1016/j.tree.2004.07.006; Guisan A, 1999, PLANT ECOL, V143, P107, DOI 10.1023/A:1009841519580; Guisan A, 2005, ECOL LETT, V8, P993, DOI 10.1111/j.1461-0248.2005.00792.x; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; Guisan A, 2006, CONSERV BIOL, V20, P501, DOI 10.1111/j.1523-1739.2006.00354.x; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; IUCN, 2009, RED LIST THREAT SPEC; Jensen FV, 2007, BAYESIAN NETWORKS DE; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kullback S, 1959, INFORM THEORY STAT; Langseth H, 2009, RELIAB ENG SYST SAFE, V94, P1499, DOI 10.1016/j.ress.2009.02.027; Lehmann A, 2003, ECOL MODEL, V160, P165, DOI 10.1016/S0304-3800(02)00354-X; Lehmann A, 2002, BIODIVERS CONSERV, V11, P2085, DOI 10.1023/A:1021354914494; Luoto M, 2005, GLOBAL ECOL BIOGEOGR, V14, P575, DOI 10.1111/j.1466-822x.2005.00186.x; Maggini R, 2006, J BIOGEOGR, V33, P1729, DOI 10.1111/j.1365-2699.2006.01465.x; Manel S, 2001, J APPL ECOL, V38, P921, DOI 10.1046/j.1365-2664.2001.00647.x; Midgley GF, 2003, BIOL CONSERV, V112, P87, DOI 10.1016/S0006-3207(02)00414-7; Miller J, 2002, ECOL MODEL, V157, P227, DOI 10.1016/S0304-3800(02)00196-5; Mladenic D, 2006, LECT NOTES COMPUT SC, V3940, P84; Moisen GG, 2002, ECOL MODEL, V157, P209, DOI 10.1016/S0304-3800(02)00197-7; Moral S, 2003, LECT NOTES ARTIF INT, V2711, P197; Moral S., 2001, LECT NOTES ARTIF INT, V2143, P135; Moral S, 2002, P 1 EUR WORKSH PROB, P156; Pearson RG, 2006, J BIOGEOGR, V33, P1704, DOI 10.1111/j.1365-2699.2006.01460.x; Peterson AT, 2003, Q REV BIOL, V78, P419, DOI 10.1086/378926; Peterson AT, 2002, NATURE, V416, P626, DOI 10.1038/416626a; Pleguezuelos JM, 2002, ATLAS LIBRO ROJO ANF; Pollino CA, 2007, ECOL MODEL, V201, P37, DOI 10.1016/j.ecolmodel.2006.07.032; Romero V, 2006, INT J APPROX REASON, V42, P54, DOI 10.1016/j.ijar.2005.10.004; RUMI R, 2005, P INT MED C MATH, P135; Rumi R, 2007, INT J APPROX REASON, V45, P191, DOI 10.1016/j.ijar.2006.06.007; Rumi R, 2006, TEST, V15, P397, DOI 10.1007/BF02607059; Segurado P, 2004, J BIOGEOGR, V31, P1555, DOI 10.1111/j.1365-2699.2004.01076.x; Smith CS, 2007, BIOL CONSERV, V139, P333, DOI 10.1016/j.biocon.2007.06.025; STONE M, 1974, J R STAT SOC B, V36, P111; Thuiller W, 2004, GLOBAL CHANGE BIOL, V10, P2020, DOI 10.1111/j.1365-2486.2004.00859.x; Uusitalo L, 2007, ECOL MODEL, V203, P312, DOI 10.1016/j.ecolmodel.2006.11.033; Wintle BA, 2005, AUSTRAL ECOL, V30, P719, DOI 10.1111/j.1442-9993.2005.01514.x; Zaffalon M, 2005, ENVIRON MODELL SOFTW, V20, P1003, DOI 10.1016/j.envsoft.2004.10.006	67	10	10	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1364-8152			ENVIRON MODELL SOFTW	Environ. Modell. Softw.	DEC	2010	25	12					1630	1639		10.1016/j.envsoft.2010.04.016		10	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Sciences	Computer Science; Engineering; Environmental Sciences & Ecology	660PI	WOS:000282655200013	
J	Boccard, J; Kalousis, A; Hilario, M; Lanteri, P; Hanafi, M; Mazerolles, G; Wolfender, JL; Carrupt, PA; Rudaz, S				Boccard, Julien; Kalousis, Alexandros; Hilario, Melanie; Lanteri, Pierre; Hanafi, Mohamed; Mazerolles, Gerard; Wolfender, Jean-Luc; Carrupt, Pierre-Alain; Rudaz, Serge			Standard machine learning algorithms applied to UPLC-TOF/MS metabolic fingerprinting for the discovery of wound biomarkers in Arabidopsis thaliana	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						Data mining; Machine learning; Mass spectrometry; Metabolomics; Arabidopsis thaliana; UPLC-MS	PLANT METABOLOMICS; MASS-SPECTROMETRY; SELECTION; EXTRACTS; MS	Metabolomics experiments involve the simultaneous detection of a high number of metabolites leading to large multivariate datasets and computer-based applications are required to extract relevant biological information. A high-throughput metabolic fingerprinting approach based on ultra performance liquid chromatography (UPLC) and high resolution time-of-flight (TOF) mass spectrometry (MS) was developed for the detection of wound biomarkers in the model plant Arabidopsis thaliana. High-dimensional data were generated and analysed with chemometric methods. Besides, machine learning classification algorithms constitute promising tools to decipher complex metabolic phenotypes but their application remains however scarcely reported in that research field. The present work proposes a comparative evaluation of a set of diverse machine learning schemes in the context of metabolomic data with respect to their ability to provide a deeper insight into the metabolite network involved in the wound response. Standalone classifiers, i.e. J48 (decision tree), kNN (instance-based learner), SMO (support vector machine), multilayer perceptron and RBF network (neural networks) and Naive Bayes (probabilistic method), or combinations of classification and feature selection algorithms, such as Information Gain, RELIEF-F. Correlation Feature-based Selection and SVM-based methods, are concurrently assessed and cross-validation resampling procedures are used to avoid overfitting. This study demonstrates that machine learning methods represent valuable tools for the analysis of UPLC-TOF/MS metabolomic data. In addition, remarkable performance was achieved, while the models' stability showed the robustness and the interpretability potential. The results allowed drawing attention to both temporal and spatial metabolic patterns in the context of stress signalling and highlighting relevant biomarkers not evidenced with standard data treatment. (C) 2010 Elsevier B.V. All rights reserved.	[Boccard, Julien; Wolfender, Jean-Luc; Carrupt, Pierre-Alain; Rudaz, Serge] Univ Lausanne, Sch Pharmaceut Sci, Univ Geneva, CH-1211 Geneva 4, Switzerland; [Kalousis, Alexandros; Hilario, Melanie] Univ Geneva, Dept Comp Sci, Artificial Intelligence Lab, CH-1211 Geneva, Switzerland; [Lanteri, Pierre] Univ Lyon 1, CNRS, Analyt Sci Lab, F-69622 Villeurbanne, France; [Hanafi, Mohamed] ONIRIS, Unite Rech Sensometrie & Chimiometrie, Nantes, France; [Mazerolles, Gerard] INRA, UMR SPO 1083, F-34060 Montpellier, France	Rudaz, S (reprint author), Univ Lausanne, Sch Pharmaceut Sci, Univ Geneva, 20 Bd Yvoy, CH-1211 Geneva 4, Switzerland.	serge.rudaz@unige.ch	Boccard, Julien/A-8870-2011; Carrupt, Pierre-Alain/C-4854-2008	Boccard, Julien/0000-0001-5913-9566; 	Swiss National Science Foundation [205320-107735]; European Commission through EU [FP7-231519]	The Swiss National Science Foundation is thanked for supporting this work (grant 205320-107735 to JLW and SR). We thank Elia Grata and Gaetan Glauser for the UPLC-MS metabolomic data and their helpful comments. The work reported in this paper was partially funded by the European Commission through EU project e-LICO (FP7-231519).	AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Boccard J, 2007, CHEMOMETR INTELL LAB, V86, P189, DOI 10.1016/j.chemolab.2006.06.004; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Farmer EE, 2003, CURR OPIN PLANT BIOL, V6, P372, DOI 10.1016/S1369-5266(03)00045-1; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Gallant S I, 1990, IEEE Trans Neural Netw, V1, P179, DOI 10.1109/72.80230; Glauser G, 2010, PHYTOCHEM ANALYSIS, V21, P95, DOI 10.1002/pca.1155; Grata E, 2007, J SEP SCI, V30, P2268, DOI 10.1002/jssc.200700143; Grata E, 2009, J CHROMATOGR A, V1216, P5660, DOI 10.1016/j.chroma.2009.05.069; Grata E, 2008, J CHROMATOGR B, V871, P261, DOI 10.1016/j.jchromb.2008.04.021; Hall MA, 2000, P 17 INT C MACH LEAR, P359; Hall RD, 2006, NEW PHYTOL, V169, P453, DOI 10.1111/j.1469-8137.2005.01632.x; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Kalousis A, 2007, KNOWL INF SYST, V12, P95, DOI 10.1007/s10115-006-0040-8; Kalousis A, 2004, PROC INT C TOOLS ART, P113; Keerthi SS, 2002, MACH LEARN, V46, P351, DOI 10.1023/A:1012431217818; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KULLBACK S, 1952, ANN MATH STAT, V23, P88, DOI 10.1214/aoms/1177729487; Mitchell T.M., 1997, MACHINE LEARNING; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Platt JR, 1998, IEEE AERO EL SYS MAG, V13, P26, DOI 10.1109/62.656331; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Sumner LW, 2003, PHYTOCHEMISTRY, V62, P817, DOI 10.1016/S0031-9422(02)00708-2; TRYGG J, 2006, BIOTECHNOL AGRIC FOR, V57, P117; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Weckwerth W, 2005, DRUG DISCOV TODAY, V10, P1551, DOI 10.1016/S1359-6446(05)03609-3	30	10	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	NOV 15	2010	104	1			SI		20	27		10.1016/j.chemolab.2010.03.003		8	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	685WH	WOS:000284658300004	
J	Schmah, T; Yourganov, G; Zemel, RS; Hinton, GE; Small, SL; Strother, SC				Schmah, Tanya; Yourganov, Grigori; Zemel, Richard S.; Hinton, Geoffrey E.; Small, Steven L.; Strother, Stephen C.			Comparing Classification Methods for Longitudinal fMRI Studies	NEURAL COMPUTATION			English	Article							SUPPORT VECTOR MACHINES; OBJECT RECOGNITION; NEUROIMAGING DATA; BRAIN IMAGES; PREDICTION; CLASSIFIERS; PIPELINES; SELECTION; PATTERNS; CORTEX	We compare 10 methods of classifying fMRI volumes by applying them to data from a longitudinal study of stroke recovery: adaptive Fisher's linear and quadratic discriminant; gaussian naive Bayes; support vector machines with linear, quadratic, and radial basis function (RBF) kernels; logistic regression; two novel methods based on pairs of restricted Boltzmann machines (RBM); and K-nearest neighbors. All methods were tested on three binary classification tasks, and their out-of-sample classification accuracies are compared. The relative performance of the methods varies considerably across subjects and classification tasks. The best overall performers were adaptive quadratic discriminant, support vector machines with RBF kernels, and generatively trained pairs of RBMs.	[Schmah, Tanya; Zemel, Richard S.; Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Strother, Stephen C.] Univ Toronto, Baycrest Ctr, Rotman Res Inst, Dept Med Biophys, Toronto, ON M6A 2E1, Canada; [Yourganov, Grigori; Strother, Stephen C.] Univ Toronto, Inst Med Sci, Toronto, ON M6A 2E1, Canada; [Small, Steven L.] Univ Chicago, Dept Neurol, Chicago, IL 60637 USA	Schmah, T (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.	schmah@cs.toronto.edu; gyourganov@rotman-baycrest.on.ca; zemel@cs.toronto.edu; hinton@cs.toronto.edu; small@uchicago.edu; sstrother@rotman-baycrest.on.ca			Brain Network Recovery Group through the James S. McDonnell Foundation [22002082]; National Institutes of Health [R01 DC7488]; Centre for Stroke Recovery of the Heart and Stroke Foundation of Ontario	We thank Natasa Kovacevic for coregistering and motion-correcting the fMRI data used in this study. This work was supported by the Brain Network Recovery Group through a grant from the James S. McDonnell Foundation (No. 22002082) and a grant from the National Institutes of Health (No. R01 DC7488). S. C. S. is partially supported by the Centre for Stroke Recovery of the Heart and Stroke Foundation of Ontario.	Carroll MK, 2009, NEUROIMAGE, V44, P112, DOI 10.1016/j.neuroimage.2008.08.020; Conover W. J., 1998, PRACTICAL NONPARAMET; De Martino F, 2008, NEUROIMAGE, V43, P44, DOI 10.1016/j.neuroimage.2008.06.037; Demsar J, 2006, J MACH LEARN RES, V7, P1; Friston K, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P1; Hansen LK, 2007, BRAIN LANG, V102, P186, DOI 10.1016/j.bandl.2006.12.004; Hanson SJ, 2004, NEUROIMAGE, V23, P156, DOI 10.1016/j.neuroimage.2004.05.020; Hanson SJ, 2008, NEURAL COMPUT, V20, P486, DOI 10.1162/neco.2007.09-06-340; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Haynes JD, 2005, NAT NEUROSCI, V8, P686, DOI 10.1038/nn1445; Hinton G. E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2007, SCHOLARPEDIA, V2, P1668; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Joachims T., 1999, ADV KERNEL METHODS S; Kjems U, 2001, ADV NEUR IN, V13, P549; Kjems U, 2002, NEUROIMAGE, V15, P772, DOI 10.1006/nimg.2001.1033; Kustra R, 2001, IEEE T MED IMAGING, V20, P376, DOI 10.1109/42.925291; LaConte S, 2005, NEUROIMAGE, V26, P317, DOI 10.1016/j.neuroimage.2005.01.048; Lamblin P., 2007, ADV NEURAL INFORM PR, V19, P153; LAROCHELLE H, 2008, ICML 08; Lukic AS, 2007, IEEE T MED IMAGING, V26, P1613, DOI 10.1109/TMI.2007.896934; Mardia K. V., 1979, MULTIVARIATE ANAL; McIntosh AR, 2004, NEUROIMAGE, V23, pS250, DOI 10.1016/j.neuroimage.2004.07.020; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Morch N, 1997, LECT NOTES COMPUT SC, V1230, P259; Ng AY, 2002, ADV NEUR IN, V14, P841; Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005; O'Toole AJ, 2007, J COGNITIVE NEUROSCI, V19, P1735, DOI 10.1162/jocn.2007.19.11.1735; Pereira F, 2009, NEUROIMAGE, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007; Pessoa L, 2006, CEREB CORTEX, V16, P366, DOI 10.1093/cercorbhi115; Press W. H., 1992, NUMERICAL RECIPES C; Schmah T., 2009, ADV NEURAL INFORM PR, V21, P1409; Small SL, 2002, BRAIN, V125, P1544, DOI 10.1093/brain/awf148; Strother S, 2004, NEUROIMAGE, V23, pS196, DOI 10.1016/j.neuroimage.2004.07.022; Strother SC, 2006, IEEE ENG MED BIOL, V25, P27, DOI 10.1109/MEMB.2006.1607667; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Woods RP, 1998, J COMPUT ASSIST TOMO, V22, P139, DOI 10.1097/00004728-199801000-00027; Yamashita O, 2008, NEUROIMAGE, V42, P1414, DOI 10.1016/j.neuroimage.2008.05.050; Zhang J, 2008, NEUROINFORMATICS, V6, P123, DOI 10.1007/s12021-008-9014-1	41	10	10	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	NOV	2010	22	11					2729	2762		10.1162/NECO_a_00024		34	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	662OR	WOS:000282820100001	
J	Towfic, F; Caragea, C; Gemperline, DC; Dobbs, D; Honavar, V				Towfic, Fadi; Caragea, Cornelia; Gemperline, David C.; Dobbs, Drena; Honavar, Vasant			Struct-NB: predicting protein-RNA binding sites using structural features	INTERNATIONAL JOURNAL OF DATA MINING AND BIOINFORMATICS			English	Article						protein-RNA interactions; propensity; structural features	STATISTICAL-ANALYSIS; RECOGNITION	We analyse sequence and structural features of protein-RNA interfaces using RB-147, a non-redundant dataset of protein-RNA complexes extracted from the PDB. We train classifiers using machine learning algorithms to predict protein-RNA interfaces from sequence and structure-derived features of proteins. Our experiments show that Struct-NB, a Naive Bayes classifier that exploits structural features, outperforms its counterparts that use only sequence features to predict protein-RNA binding residues.	[Dobbs, Drena] Iowa State Univ, Bioinformat & Computat Biol Grad Program, Dept Genet Dev & Cell Biol, Ames, IA 50011 USA; [Honavar, Vasant] Iowa State Univ, Bioinformat & Computat Biol Grad Program, Dept Comp Sci, Ames, IA 50011 USA; [Gemperline, David C.] Carthage Coll, Dept Chem, Dept Biol, Kenosha, WI 53140 USA	Towfic, F (reprint author), Iowa State Univ, Bioinformat & Computat Biol Grad Program, Dept Genet Dev & Cell Biol, Ames, IA 50011 USA.	ftowfic@cs.iastate.edu; cornelia@cs.iastate.edu; dcgemperline@gmail.com; ddobbs@iastate.edu; honavar@cs.iastate.edu			National Institutes of Health [GM066387]; Integrative Graduate Education and Research Training (IGERT); National Science Foundation [DGE 0504304, EEC 0608769]; Bloengineering and Bioinformatics Summer Institute (BBSI)	This research was supported in part by a grant from the National Institutes of Health (GM066387) to Vasant Honavar and Drena Dobbs, an Integrative Graduate Education and Research Training (IGERT) fellowship to Fadi Towfic, funded by the National Science Foundation grant (DGE 0504304) to Iowa State University, and a Bloengineering and Bioinformatics Summer Institute (BBSI) fellowship to David Gemperline, funded by a National Science Foundation award (EEC 0608769) to Iowa State University. This work has benefited from discussions with Dr. Robert Jernigan, Feihong WLI, Michael Terribilini and Yasser El-Manzalawy of Iowa State University.	Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bechara E, 2007, NUCLEIC ACIDS RES, V35, P299, DOI 10.1093/nar/gkl1021; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Caragea C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-438; Chen Y, 2005, FEBS J, V272, P2088, DOI 10.1111/j.1742-4658.2005.04650.x; CONNOLLY ML, 1993, J MOL GRAPHICS, V11, P139, DOI 10.1016/0263-7855(93)87010-3; CONNOLLY ML, 1986, J MOL GRAPHICS, V4, P3; Dietterich T.G., 2002, LECT NOTES COMPUTER, P15; Ellis JJ, 2007, PROTEINS, V66, P903, DOI 10.1002/prot.21211; Freed EO, 2006, RETROVIROLOGY, V3, DOI 10.1186/1742-4690-3-77; Jeong E, 2006, T COMPUT SYST BIOL, V4, P123; Jeong Euna, 2004, Genome Inform, V15, P105; Jones S, 2001, NUCLEIC ACIDS RES, V29, P943, DOI 10.1093/nar/29.4.943; Jurica MS, 2003, MOL CELL, V12, P5, DOI 10.1016/S1097-2765(03)00270-3; LEE B, 1971, J MOL BIOL, V55, P379, DOI 10.1016/0022-2836(71)90324-X; Lejeune D, 2005, PROTEINS, V61, P258, DOI 10.1002/prot.20607; LEWIS M, 1985, SCIENCE, V230, P1163, DOI 10.1126/science.4071040; Mitchell T.M., 1997, MACHINE LEARNING; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Moore MJ, 2005, SCIENCE, V309, P1514, DOI 10.1126/science.1111443; Noller HF, 2005, SCIENCE, V309, P1508, DOI 10.1126/science.1111771; Pintar A, 2002, BIOINFORMATICS, V18, P980, DOI 10.1093/bioinformatics/18.7.980; TERRIBILINI M, 2006, BIOINFORMATICS, V12, P1450; TERRIBILINI M, 2007, NUCLEIC ACIDS RES, V35, P1; TERRIBLINI M, 2006, PACIFIC S BIOCOMPUTI, V11, P415; TOWFIC F, 2007, P 2007 IEEE INT C BI, P60; Treger M, 2001, J MOL RECOGNIT, V14, P199, DOI 10.1002/jmr.534; WU F, 2007, P 2007 IEEE INT C BI, P35	28	10	10	INDERSCIENCE ENTERPRISES LTD	GENEVA	WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 896, CH-1215 GENEVA, SWITZERLAND	1748-5673			INT J DATA MIN BIOIN	Int. J. Data Min. Bioinform.		2010	4	1					21	43				23	Mathematical & Computational Biology	Mathematical & Computational Biology	559GI	WOS:000274810900002	
J	Huang, LC; Hsu, SY; Lin, E				Huang, Lung-Cheng; Hsu, Sen-Yen; Lin, Eugene			A comparison of classification methods for predicting Chronic Fatigue Syndrome based on genetic data	JOURNAL OF TRANSLATIONAL MEDICINE			English	Article							SINGLE NUCLEOTIDE POLYMORPHISMS; ENVIRONMENT INTERACTIONS; HAPLOTYPE ANALYSIS; DRUG EFFICACY; SELECTION; EXPRESSION; THERAPY	Background: In the studies of genomics, it is essential to select a small number of genes that are more significant than the others for the association studies of disease susceptibility. In this work, our goal was to compare computational tools with and without feature selection for predicting chronic fatigue syndrome (CFS) using genetic factors such as single nucleotide polymorphisms ( SNPs). Methods: We employed the dataset that was original to the previous study by the CDC Chronic Fatigue Syndrome Research Group. To uncover relationships between CFS and SNPs, we applied three classification algorithms including naive Bayes, the support vector machine algorithm, and the C4.5 decision tree algorithm. Furthermore, we utilized feature selection methods to identify a subset of influential SNPs. One was the hybrid feature selection approach combining the chi-squared and information-gain methods. The other was the wrapper-based feature selection method. Results: The naive Bayes model with the wrapper-based approach performed maximally among predictive models to infer the disease susceptibility dealing with the complex relationship between CFS and SNPs. Conclusion: We demonstrated that our approach is a promising method to assess the associations between CFS and SNPs.	[Lin, Eugene] Vita Genom Inc, Taipei, Taiwan; [Huang, Lung-Cheng] Natl Taiwan Univ Hosp, Dept Psychiat, Yun Lin Branch, Taipei, Taiwan; [Huang, Lung-Cheng] Kaohsiung Med Univ, Grad Inst Med, Kaohsiung, Taiwan; [Hsu, Sen-Yen] Chi Mei Med Ctr, Dept Psychiat, Tainan, Taiwan	Lin, E (reprint author), Vita Genom Inc, 7 Fl,6,Sec 1,Jung Shing Rd, Taipei, Taiwan.	psychidr@gmail.com; 779002@mail.chimei.org.tw; eugene.lin@vitagenomics.com					Afari N, 2003, AM J PSYCHIAT, V160, P221, DOI 10.1176/appi.ajp.160.2.221; Aliferis CF, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004922; BREIMAN L, 1995, CLASSIFICATION REGRE; BURGES CJC, 1998, DATA MIN KNOWL DISC, V2, P127; Chen K, 2007, BMC STRUCT BIOL, V7, DOI 10.1186/1472-6807-7-25; Chung YJ, 2007, BIOINFORMATICS, V23, P71, DOI 10.1093/bioinformatics/btl557; DOMINGOS P, 1997, MACH LEARN, V103, P137; Erdmann G, 2008, J NEUROENDOCRINOL, V20, P655, DOI 10.1111/j.1365-2826.2008.01717.x; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; FUKUDA K, 1994, ANN INTERN MED, V121, P953; Garcia A, 2004, AGING CELL, V3, P363, DOI 10.1111/j.1474-9728.2004.00130.x; Goertzel BN, 2006, PHARMACOGENOMICS, V7, P475, DOI 10.2217/14622416.7.3.475; Griffith James P, 2008, Prim Care Companion J Clin Psychiatry, V10, P120; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hewett R, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-S2-S21; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Lee KE, 2003, BIOINFORMATICS, V19, P90, DOI 10.1093/bioinformatics/19.1.90; Lin E, 2009, PHARMACOGENOMICS, V10, P35, DOI 10.2217/14622416.10.1.35; LIN E, 2008, COMPUT BIOL CHEM ADV, V1, P13; Lin E, 2007, PHARMACOGENOMICS, V8, P75, DOI 10.2217/14622416.8.1.75; Lin E, 2007, PHARMACOGENOMICS, V8, P1327, DOI 10.2217/14622416.8.10.1327; Lin E, 2008, MOL DIAGN THER, V12, P219; Lin E, 2006, MOL DIAGN THER, V10, P367; Lin E, 2006, PHARMACOGENOMICS, V7, P1017, DOI 10.2217/14622416.7.7.1017; Listgarten J, 2004, CLIN CANCER RES, V10, P2725, DOI 10.1158/1078-0432.CCR-1115-03; Quinlan J.R., 1993, PROGRAMS MACHINE LEA; Rajeevan MS, 2007, GENES BRAIN BEHAV, V6, P167, DOI 10.1111/j.1601-183X.2006.00244.x; Reeves WC, 2005, BMC MED, V3, DOI 10.1186/1741-7015-3-19; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Sanders P, 2008, WORLD J BIOL PSYCHIA, V9, P165, DOI 10.1080/15622970701310971; Smith AK, 2006, PHARMACOGENOMICS, V7, P387, DOI 10.2217/14622416.7.3.387; Smith AK, 2008, PSYCHONEUROENDOCRINO, V33, P188, DOI 10.1016/j.psyneuen.2007.11.001; Vapnik V., 1995, NATURE STAT LEARNING; Whorwood CB, 2002, DIABETES, V51, P1066, DOI 10.2337/diabetes.51.4.1066; Witten IH, 2005, DATA MINING PRACTICA; Zheng C, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-430	37	10	10	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1479-5876			J TRANSL MED	J. Transl. Med.	SEP 22	2009	7								81	10.1186/1479-5876-7-81		8	Medicine, Research & Experimental	Research & Experimental Medicine	516GQ	WOS:000271530600001	
J	Youn, E; Jeong, MK				Youn, Eunseog; Jeong, Myong K.			Class dependent feature scaling method using naive Bayes classifier for text datamining	PATTERN RECOGNITION LETTERS			English	Article						Classification; Feature selection; Naive Bayes classifier; Recursive feature elimination	SUPPORT VECTOR MACHINES; SELECTION; CANCER	The problem of feature selection is to find a subset of features for optimal classification. A critical part of feature selection is to rank features according to their importance for classification. The naive Bayes classifier has been extensively used in text categorization. We have developed a new feature scaling method, called class-dependent-feature-weighting (CDFW) using naive Bayes (NB) classifier. A new feature scaling method, CDFW-NB-RFE, combines CDFW and recursive feature elimination (RFE). Our experimental results showed that CDFW-NB-RFE outperformed other popular feature ranking schemes used on text clatasers. (c) 2008 Published by Elsevier B.V.	[Jeong, Myong K.] Rutgers State Univ, Dept Ind & Syst Engn, Piscataway, NJ 08854 USA; [Jeong, Myong K.] Rutgers State Univ, RUTCOR, Rutgers Ctr Operat Res, Piscataway, NJ 08854 USA; [Youn, Eunseog] Texas Tech Univ, Dept Comp Sci, Lubbock, TX 79409 USA	Jeong, MK (reprint author), Rutgers State Univ, Dept Ind & Syst Engn, Piscataway, NJ 08854 USA.	mjeong@rci.rutgers.edu			National Science Foundation [CMMI-0644830]	This work was supported by the National Science Foundation Grant no: CMMI-0644830. The authors thank anonymous reviewers for their constructive comments.	Bennett P.N., 2000, CMUCS00155 SCH COMP; Box G.E.P., 1978, STAT EXPT; BRANK J, 2002, WORKSH TEXT LEARN TE; BRANK J, 2002, MSRTR200263 MICR COR; Chakrabarti S, 1998, VLDB J, V7, P163, DOI 10.1007/s007780050061; CHAKRABARTI S, 2000, SIGKDD EXLORATIONS, V1; Chakrabarti S, 2003, VLDB J, V12, P170, DOI 10.1007/s00778-003-0098-9; Cheng BYM, 2005, PROTEINS, V58, P955, DOI 10.1002/prot.20373; Cover T. M., 1991, ELEMENTS INFORM THEO; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Han J., 2001, DATA MINING CONCEPTS; Joachims T., 1998, P 10 EUR C MACH LEAR; Joachims T, 2000, P 17 INT C MACH LEAR, P431; Joachims T., 1997, P 14 INT C MACH LEAR, P143; Koller D., 1996, P 13 INT C MACH LEAR, P284; LANG K, 1995, P 12 INT C MACH LEAR, P331; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Leslie Christina, 2002, Pac Symp Biocomput, P564; Liu H., 1998, FEATURE SELECTION KN; McCallum A., 1998, P AAAI 98 WORKSH LEA; Mitchel T., 1997, MACHINE LEARNING; Mladenic D., 1998, P 10 EUR C MACH LEAR, P95; Ng A. Y., 2001, NIPS, P841; NIGAM K, 1999, IJCAI 99 WORKSH INF; Rennie J., 2003, P 20 INT C MACH LEAR; RENNIE JDM, 2001, IMPROVING MULTICLASS; Rifkin R.M., 2002, THESIS MIT; Rish I., 2001, P IJCAI 01 WORKSH EM; Salton Gerard, 1989, AUTOMATIC TEXT PROCE; Sivia D.S., 1996, DATA ANAL BAYESIAN T; Tan P-N, 2005, INTRO DATA MINING; WEBB GI, 1998, P 11 AUSTR JOINT C A; Yang Y., 1997, P ICML 97 14 INT C M	39	10	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	APR 1	2009	30	5					477	485		10.1016/j.patrec.2008.11.013		9	Computer Science, Artificial Intelligence	Computer Science	423BO	WOS:000264471600002	
J	Yousef, M; Jung, S; Showe, LC; Showe, MK				Yousef, Malik; Jung, Segun; Showe, Louise C.; Showe, Michael K.			Learning from positive examples when the negative class is undetermined-microRNA gene identification	ALGORITHMS FOR MOLECULAR BIOLOGY			English	Article							PREDICTION; PRECURSORS; SEQUENCE; GENOMICS; ELEGANS; SUPPORT	Background: The application of machine learning to classification problems that depend only on positive examples is gaining attention in the computational biology community. We and others have described the use of two- class machine learning to identify novel miRNAs. These methods require the generation of an artificial negative class. However, designation of the negative class can be problematic and if it is not properly done can affect the performance of the classifier dramatically and/ or yield a biased estimate of performance. We present a study using one- class machine learning for microRNA ( miRNA) discovery and compare one- class to two- class approaches using naive Bayes and Support Vector Machines. These results are compared to published two- class miRNA prediction approaches. We also examine the ability of the one- class and two- class techniques to identify miRNAs in newly sequenced species. Results: Of all methods tested, we found that 2- class naive Bayes and Support Vector Machines gave the best accuracy using our selected features and optimally chosen negative examples. One class methods showed average accuracies of 70 - 80% versus 90% for the two 2- class methods on the same feature sets. However, some one- class methods outperform some recently published two- class approaches with different selected features. Using the EBV genome as and external validation of the method we found one- class machine learning to work as well as or better than a two- class approach in identifying true miRNAs as well as predicting new miRNAs. Conclusion: One and two class methods can both give useful classification accuracies when the negative class is well characterized. The advantage of one class methods is that it eliminates guessing at the optimal features for the negative class when they are not well defined. In these cases one-class methods can be superior to two- class methods when the features which are chosen as representative of that positive class are well defined. Availability: The OneClassmiRNA program is available at: [1].	[Yousef, Malik; Jung, Segun; Showe, Louise C.; Showe, Michael K.] Wistar Inst Anat & Biol, Syst Biol Div, Philadelphia, PA 19104 USA; [Jung, Segun] Drexel Univ, Sch Biomed Engn, Sci & Hlth Syst, Philadelphia, PA 19104 USA; [Yousef, Malik] Coll Sakhnin, Sakhnin, Israel; [Jung, Segun] NYU, Sch Med, Sackler Inst Grad Biomed Sci, New York, NY 10016 USA	Showe, MK (reprint author), Wistar Inst Anat & Biol, Syst Biol Div, Philadelphia, PA 19104 USA.	yousef@gal-soc.org; sj801@med.nyu.edu; lshowe@wistar.org; showe@wistar.org	Jung, Segun/C-9857-2009				Bartel DP, 2004, CELL, V116, P281, DOI 10.1016/S0092-8674(04)00045-5; BEREZIKOV E, 2006, NAT GENET; Cai XZ, 2006, PLOS PATHOG, V2, P236, DOI 10.1371/journal.ppat.0020023; Chang C.C., 2001, LIBSVM LIB SUPPORT V; CRAMMER K, 2004, P 21 INT C MACH LEAR; Grad Y, 2003, MOL CELL, V11, P1253, DOI 10.1016/S1097-2765(03)00153-9; Griffiths-Jones S, 2004, NUCLEIC ACIDS RES, V32, pD109, DOI 10.1093/nar/gkh023; Grundhoff A, 2006, RNA, V12, P733, DOI 10.1261/2326106; Gupta G., 2005, P 22 INT C MACH LEAR, P273, DOI 10.1145/1102351.1102386; Hertel J, 2006, BIOINFORMATICS, V22, pE197, DOI 10.1093/bioinformatics/btl257; Kim SK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-411; Koppel M., 2004, P 21 INT C MACH LEAR, P62; Kowalczyk A., 2002, SIGKDD EXPLORATIONS, V4, P99; Lai EC, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r42; Lim LP, 2003, GENE DEV, V17, P991, DOI 10.1101/gad.1074403; Lim LP, 2003, SCIENCE, V299, P1540, DOI 10.1126/science.1080372; Manevitz L., 2001, J MACHINE LEARNING R, V2, P139; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Nam JW, 2005, NUCLEIC ACIDS RES, V33, P3570, DOI 10.1093/nar/gki668; Pfeffer S, 2005, NAT METHODS, V2, P269, DOI 10.1038/NMETH746; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B., 1999, ADV KERNEL METHODS; Sewer A, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-267; Spinosa Eduardo J, 2005, Genet Mol Res, V4, P608; SUNGKYU K, 2005, IEEE S COMP INT BIOI, P46; TAX DMJ, 2001, ONE CLASS CLASSIFICA; TAX DMJ, 2005, DDTOOLS DAT DESCRIPT; Thirion B, 2004, MED IMAGE ANAL, V8, P403, DOI 10.1016/j.media.2004.09.001; Vapnik V., 1995, NATURE STAT LEARNING; WANG C, 2006, BIOINFORMATICS; Weber MJ, 2005, FEBS J, V272, P59, DOI 10.1111/j.1432-1033.2004.04389.x; Xue CH, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-310; Yousef M, 2006, BIOINFORMATICS, V22, P1325, DOI 10.1093/bioinformatics/bt/094; Zuker M, 2003, NUCLEIC ACIDS RES, V31, P3406, DOI 10.1093/nar/gkg595	34	10	11	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1748-7188			ALGORITHM MOL BIOL	Algorithms. Mol. Biol.	JAN 28	2008	3								2	10.1186/1748-7188-3-2		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	263GR	WOS:000253206100001	
J	Peterson, LE; Coleman, MA				Peterson, Leif E.; Coleman, Matthew A.			Machine learning-based receiver operating characteristic (ROC) curves for crisp and fuzzy classification of DNA microarrays in cancer research	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						receiver operator characteristic (ROC) curve; area under the curve (AUC); soft computing; fuzzy classification; gene expression; DNA microarrays	DIFFERENTIALLY EXPRESSED GENES; SAMPLE-SIZE; PARTICLE SWARM; BREAST-CANCER; PREDICTION; PATTERNS; TUMOR; POWER	Receiver operating characteristic (ROC) curves were generated to obtain classification area under the curve (AUC) as a function of feature standardization, fuzzification, and sample size from nine large sets of cancer-related DNA microarrays. Classifiers used included k-nearest neighbor (kNN), naive Bayes classifier (NBC), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), learning vector quantization (LVQ1), logistic regression (LOG), polytomous logistic regression (PLOG), artificial neural networks (ANN), particle swarm optimization (PSO), constricted particle swarm optimization (CPSO), kernel regression (RBF), radial basis function networks (RBFN), gradient descent support vector machines (SVMGD), and least squares support vector machines (SVMLS). For each data set, AUC was determined for a number of combinations of sample size, total sum[-log(p)] of feature t-tests, with and without feature standardization and with (fuzzy) and without (crisp) fuzzification of features. Altogether, a total of 2,123,530 classification runs were made. At the greatest level of sample size, ANN resulted in a fitted AUC of 90%, while PSO resulted in the lowest fitted AUC of 72.1%. AUC values derived from 4NN were the most dependent on sample size, while PSO was the least. ANN depended the most on total statistical significance of features used based on sum[-log(p)], whereas PSO was the least dependent. Standardization of features increased AUC by 8.1% for PSO and -0.2% for QDA, while fuzzification increased AUC by 9.4% for PSO and reduced AUC by 3.8% for QDA. AUC determination in planned microarray experiments without standardization and fuzzification of features will benefit the most if CPSO is used for lower levels of feature significance (i.e., sum[-log(p)] similar to 50) and ANN is used for greater levels of significance (i.e., sum[-log(p)] similar to 500). When only standardization of features is performed, studies are likely to benefit most by using CPSO for low levels of feature statistical significance and LVQ1 for greater levels of significance. Studies involving only fuzzification of features should employ LVQ1 because of the substantial gain in AUC observed and low expense of LVQ1. Lastly, PSO resulted in significantly greater levels of AUC (89.51% average) when feature standardization and fuzzification were performed. In consideration of the data sets used and factors influencing AUC which were investigated, if low-expense computation is desired then LVQ1 is recommended. However, if computational expense is of less concern, then PSO or CPSO is recommended. (c) 2007 Elsevier Inc. All rights reserved.	[Peterson, Leif E.] Baylor Coll Med, Houston, TX 77030 USA; [Coleman, Matthew A.] Lawrence Livermore Natl Lab, Livermore, CA 94550 USA	Peterson, LE (reprint author), Baylor Coll Med, Houston, TX 77030 USA.	peterson.leif@ieee.org; coleman16@llnl.gov					Abe S, 2005, SUPPORT VECTOR MACHI; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Armstrong S., 2001, NAT GENET, V30, P41; Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692; Cristianini N., 2000, INTRO SUPPORT VECTOR; de Falco I, 2006, LECT NOTES ARTIF INT, V3849, P164; Dubois D, 2000, FUNDAMENTALS FUZZY S; Fadda D, 1998, ASTRON ASTROPHYS SUP, V127, P335, DOI 10.1051/aas:1998355; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hosmer DW, 1989, APPL LOGISTIC REGRES; Hwang DH, 2002, BIOINFORMATICS, V18, P1184, DOI 10.1093/bioinformatics/18.9.1184; Jung SH, 2005, BIOSTATISTICS, V6, P157, DOI 10.1093/bostatistics/kxh026; Kennedy J., 1995, P IEEE INT C NEUR NE, DOI DOI 10.1109/ICNN.1995.488968; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Klir G. J., 1995, FUZZY SETS FUZZY LOG; Li SYS, 2005, STAT MED, V24, P2267, DOI 10.1002/sim.2119; Meissner M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-125; Mitra S., 2003, DATA MINING MULTIMED; Mukherjee S, 2003, J COMPUT BIOL, V10, P119, DOI 10.1089/106652703321825928; Page GP, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-84; Pal S.K., 2004, PATTERN RECOGNITION; Peterson LE, 2005, P 2005 IEEE S COMP I; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Rencher AC, 2002, METHODS MULTIVARIATE; Seo J, 2006, BIOINFORMATICS, V22, P808, DOI 10.1093/bioinformatics/btk052; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tibshirani R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-106; Tsai CA, 2005, BIOINFORMATICS, V21, P1502, DOI 10.1093/bioinformatics/bti162; Tsai Pi-Wen, 2005, Appl Bioinformatics, V4, P187, DOI 10.2165/00822942-200504030-00003; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang SJ, 2004, J COMPUT BIOL, V11, P714; Wei CM, 2004, BMC GENOMICS, V5, DOI 10.1186/1471-2164-5-87	34	10	11	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X			INT J APPROX REASON	Int. J. Approx. Reasoning	JAN	2008	47	1					17	36		10.1016/j.ijar.2007.03.006		20	Computer Science, Artificial Intelligence	Computer Science	245IF	WOS:000251927600003	
J	Fujino, A; Ueda, N; Saito, K				Fujino, Akinori; Ueda, Naonori; Saito, Kazumi			A hybrid generative/discriminative approach to text classification with additional information	INFORMATION PROCESSING & MANAGEMENT			English	Article; Proceedings Paper	Asia Information Retrieval Symposium (AIRS 2004)	OCT 18-20, 2004	Beijing, PEOPLES R CHINA	Microsoft Res Asia, Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, LexisNexis		multiclass and single-labeled text classification; multiple components; maximum entropy principle; Naive Bayes model	EM	This paper presents a classifier for text data samples consisting of main text and additional components, such as Web pages and technical papers. We focus on multiclass and single-labeled text classification problems and design the classifier based on a hybrid composed of probabilistic generative and discriminative approaches. Our formulation considers individual component generative models and constructs the classifier by combining these trained models based on the maximum entropy principle. We use naive Bayes models as the component generative models for the main text and additional components such as titles, links, and authors, so that we can apply our formulation to document and Web page classification problems. Our experimental results for four test collections confirmed that our hybrid approach effectively combined main text and additional components and thus improved classification performance. (c) 2006 Published by Elsevier Ltd.	NTT Corp, NTT Commun Sci Labs, Kyoto 6190237, Japan	Fujino, A (reprint author), NTT Corp, NTT Commun Sci Labs, 2-4 Hikaridai, Kyoto 6190237, Japan.	a.fujino@cslab.kecl.ntt.co.jp; ueda@cslab.kecl.ntt.co.jp; saito@csiab.kecl.ntt.co.jp					Berger AL, 1996, COMPUT LINGUIST, V22, P39; Beyerlein P., 1998, P IEEE INT C AC SPEE, P481, DOI 10.1109/ICASSP.1998.674472; BROCHU E, 2003, ADV NEURAL INFORM PR, V15, P1505; Chakrabarti S., 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; Chen SF, 1999, GAUSSIAN PRIOR SMOOT; Cohn D, 2001, ADV NEUR IN, V13, P430; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; GLOTIN H, 2001, P IEEE INT C AC SPEE, P165; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop; Lee J.H., 1995, P 18 ANN INT ACM SIG, P180, DOI 10.1145/215206.215358; LU Q, 2003, IJCAI WORKSH TEXT MI; Manning C.D., 1999, FDN STAT NATURAL LAN; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Och F. J., 2002, P 40 ANN M ASS COMP, P295; RAINA R, 2004, ADV NEURAL INFORMATI, V16; SALTON G, 1983, INTRO MODERN INFORMA; Sun A., 2002, P 4 INT WORKSH WEB I, P96	20	10	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573			INFORM PROCESS MANAG	Inf. Process. Manage.	MAR	2007	43	2					379	392		10.1016/j.ipm.2006.07.013		14	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	111AF	WOS:000242422100008	
S	Nguyen, TTT; Armitage, G		Elmallah, E; Christensen, K; Frank, M		Nguyen, Thuy T. T.; Armitage, Grenville			Training on multiple sub-flows to optimise the use of Machine Learning classifiers in real-world IP networks	31st IEEE Conference on Local Computer Networks, Proceedings	PROCEEDINGS - CONFERENCE ON LOCAL COMPUTER NETWORKS		English	Proceedings Paper	31st Annual IEEE Conference on Local Computer Networks	NOV 14-16, 2006	Tampa, FL	Univ S Florida, Univ Bonn, Univ New S Wales, BBN Technologies, Nokia, IEEE Comp Soc				Literature on the use of machine learning (ML) algorithms for classifying IP traffic has relied on full-flows or the first few packets of flows. In contrast, many real-world scenarios require a classification decision well before a flow has finished even if the flow's beginning is lost. This implies classification must be achieved using statistics derived from the most recent N packets taken at any arbitrary point in a flow's lifetime. We propose training the classifier on a combination of short sub-flows (extracted from full-flow examples of the target application's traffic). We demonstrate this optimisation using the Naive Bayes ML algorithm, and show that our approach results in excellent performance even when classification is initiated mid-way through a flow with windows as small as 25 packets long. We suggest future use of unsupervised ML algorithms to identify optimal subflows for training.	Swinburne Univ Technol, Ctr Adv Internet Architectures, Melbourne, Vic, Australia	Nguyen, TTT (reprint author), Swinburne Univ Technol, Ctr Adv Internet Architectures, Melbourne, Vic, Australia.						Armitage G., 2006, NETWORKING ONLINE GA; BAKER F, 2004, 3924 RFC INT ENG TAS; Bernaille L., 2006, ACM SIGCOMM COMPUTER, V36; BUSSIERE J, 2006, 060203A CAIA; DEMPSTER A, 1977, J ROYAL STAT SOC B, V30; JOHN GH, 1995, P 11 C UNC ART INT, P338; Karagiannis T., 2005, SIGCOMM 05; KARAGIANNIS T, 2004, P GLOBECOM 2004; McGregor A., 2004, PASS ACT MEAS WORKSH; Paxson V, 1999, COMPUT NETW, V31, P2435, DOI 10.1016/S1389-1286(99)00112-7; ROUGHAN M, 2004, ACM SIGCOMM IMC; SEN S, 2004, WWW 2004; STEWART L, 2005, IEEE TENCON 05; WILLIAMS N, 2006, 060410C CAIA; Witten I.H., 2000, DATA MINING PRACTICA; ZANDER S, 2006, PASS ACT MEAS WORKSH; Zander S., 2005, P IEEE 30 C LOC COMP; ZANDER S, 2005, ACM NETGAMES 2005; ZUEV D, 2005, ACM SIGMETRICS 2005	19	10	10	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0742-1303		978-1-4244-0418-6	CONF LOCAL COMPUT NE			2006							369	376				8	Telecommunications	Telecommunications	BFQ41	WOS:000243785600044	
S	Su, XY; Khoshgoftaar, TM			IEEE Comp Soc	Su, Xiaoyuan; Khoshgoftaar, Taghi M.			Collaborative filtering for multi-class data using belief nets algorithms	ICTAI-2006: Eighteenth International Conference on Tools with Artificial Intelligence, Proceedings	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	18th International Conference on Tools with Artificial Intelligence (ICTAI-2006)	NOV 13-15, 2006	Washington, DC	IEEE Comp Soc, Biol & Artificial Intelligence Soc, ITRI Wright State Univ, Virginia Tech CS Dept			PROBABILISTIC NETWORKS; CLASSIFIERS	As one of the most successful recommender systems, collaborative filtering (CF) algorithms can deal with high sparsity and high requirement of scalability amongst other challenges. Bayesian belief nets (BN's), one of the most frequently used classifiers, can be used for CF tasks. Previous works of applying BNs to CF tasks were mainly focused on binary-class data, and used simple or basic Bayesian classifiers [1][2]. In this work, we apply advanced BNs models to CF tasks instead of simple ones, and work on real-world multi-class CF data instead of synthetic binary-class data. Empirical results show that with their ability to deal with incomplete data, extended logistic regression on naive Bayes and tree augmented naive Bayes (NB-ELR and TAN-ELR) models [3] consistently perform better than the state-of-the-art Pearson correlation-based CF algorithm. In addition, the ELR-optimized BNs CF models are robust in terms of the ability to make predictions, while the robustness of the Pearson correlation-based CF algorithm degrades as the sparseness of the data increases.	Florida Atlantic Univ, Boca Raton, FL 33431 USA	Su, XY (reprint author), Florida Atlantic Univ, Boca Raton, FL 33431 USA.						Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Breese J, 1998, P 14 C UNC ART INT M; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Dempster A. P., 1977, J ROYAL STAT SOC B, V39; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209; Greiner R, 2005, MACH LEARN, V59, P297, DOI 10.1007/s10994-005-0469-0; Hagan MT, 1996, NEURAL NETWORK DESIG; Heckerman D, 2000, J MACHINE LEARNING R, V1, P49; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; McCullagh P., 1989, GEN LINEAR MODELS; MIYAHARA K, 2002, INFORMATION PROCESSI, V43; Miyahara K, 2000, 6 PAC RIM INT C ART, P679; Resnick P., 1994, P ACM C COMP SUPP CO, Vpp, P175, DOI DOI 10.1145/192844.192905; Ripley B., 1996, PATTERN RECOGNITION; Sarwar B., 2001, 10 INT WORLD WID WEB, P285	16	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		978-0-7695-2728-4	PROC INT C TOOLS ART			2006							497	504				8	Computer Science, Artificial Intelligence	Computer Science	BFW79	WOS:000245172700064	
J	Fragoudis, D; Meretakis, D; Likothanassis, S				Fragoudis, D; Meretakis, D; Likothanassis, S			Best terms: an efficient feature-selection algorithm for text categorization	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						feature selection; machine learning; text categorization		In this paper, we propose a new feature-selection algorithm for text classification, called best terms (BT). The complexity of BT is linear in respect to the number of the training-set documents and is independent from both the vocabulary size and the number of categories. We evaluate BT on two benchmark document collections, Reuters-21578 and 20-Newsgroups, using two classification algorithms, naive Bayes (NB) and support vector machines (SVM). Our experimental results, comparing BT with an extensive and representative list of feature-selection algorithms, show that (1) BT is faster than the existing feature-selection algorithms; (2) BT leads to a considerable increase in the classification accuracy of NB and SVM as measured by the F1 measure; (3) BT leads to a considerable improvement in the speed of NB and SVM; in most cases, the training time of SVM has dropped by an order of magnitude; (4) in most cases, the combination of BT with the simple, but very fast, NB algorithm leads to classification accuracy comparable with SVM while sometimes it is even more accurate.	Univ Patras, Comp Engn & Informat Dept, GR-26500 Patras, Greece; Griffith Univ, Novartis Pharma, Basel, Switzerland; Inst Comp Technol, Patras, Greece	Fragoudis, D (reprint author), Univ Patras, Comp Engn & Informat Dept, GR-26500 Patras, Greece.	dfragoud@ceid.upatras.gr					Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290970; Bekkerman R., 2001, P SIGIR 01 24 ACM IN, P146, DOI 10.1145/383952.383976; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Fuhr N., 1991, P RIAO 91, P606; Galavotti L, 2000, LECT NOTES COMPUT SC, V1923, P59; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; John G., 1994, P 11 INT C MACH LEAR, P121; LANG K, 1995, P 12 INT C MACH LEAR, P331; Lewis D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; Ng HT, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P67, DOI 10.1145/258525.258537; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1983, MACHINE LEARNING ART; Rogati M., 2002, P 11 INT C INF KNOWL; Ruiz M. E., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312700; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Van Rijsbergen C.J., 1979, INFORMATION RETRIEVA; Vapnik V., 1998, STAT LEARNING THEORY; Wiener E., 1995, P 4 ANN S DOC AN INF, P317; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y, 1997, 14 INT C MACH LEARN, P412; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	26	10	10	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	JUL	2005	8	1					16	33		10.1007/s10115-004-0177-2		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	938TE	WOS:000230025100002	
J	Butterworth, R; Simovici, DA; Santos, GS; Ohno-Machado, L				Butterworth, R; Simovici, DA; Santos, GS; Ohno-Machado, L			A greedy algorithm for supervised discretization	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						generalized entropy; metric; boundary points; naive Bayes classifiers	CLASSIFICATION	We present a greedy algorithm for supervised discretization using a metric defined on the space of partitions of a set of objects. This proposed technique is useful for preparing the data for classifiers that require nominal attributes. Experimental work on decision trees and naive Bayes classifiers confirm the efficacy of the proposed algorithm. (C) 2004 Elsevier Inc. All rights reserved.	Univ Massachusetts, Dept Comp Sci, Boston, MA 02125 USA; Harvard & MIT, Brigham & Womens Hosp, Div Hlth Sci & Technol, Decis Syst Grp, Boston, MA 02115 USA	Simovici, DA (reprint author), Univ Massachusetts, Dept Comp Sci, Boston, MA 02125 USA.	rickb@cs.umb.edu; dsim@cs.umb.edu; gsantos@mit.edu					Blake C. L., 1998, UCI REPOSITORY MACHI; Cerquides J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; DAROCZY Z, 1970, INFORM CONTROL, V16, P36, DOI 10.1016/S0019-9958(70)80040-7; DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379; DEVIJER PA, 1974, COMPUTER ORIENTED LE, P257; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; FAYYAD UM, 1991, THESIS U MICHIGAN; Havrda J., 1967, KYBERNETIKA, V3, P30; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; KONONENKO I, 1992, INFORMATICA, V16, P1; Ohno-Machado L, 2002, J INTELL FUZZY SYST, V12, P19; ROBNIK M, 1995, P ERK 95, P149; Simovici D., 2003, EXTRACTION GESTION C, P363; Simovici DA, 2002, IEEE T INFORM THEORY, V48, P2138, DOI 10.1109/TIT.2002.1013159; Witten I.H., 2000, DATA MINING PRACTICA; YANG Y, 2003, P PAKDD; Yang Y., 2001, P 12 EUR C MACH LEAR, P564	19	10	10	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	AUG	2004	37	4					285	292		10.1016/j.jbi.2004.07.006		8	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	863VZ	WOS:000224592800007	
S	Siefkes, C; Assis, F; Chhabra, S; Yerazunis, WS		Boulicaut, JF; Esposito, F; Giannotti, F; Pedreschi, D		Siefkes, C; Assis, F; Chhabra, S; Yerazunis, WS			Combining Winnow and orthogonal sparse bigrams for incremental spam filtering	KNOWLEDGE DISCOVERY IN DATABASES: PKDD 2004, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	15th European Conference on Machine Learning/8th European Conference on Principles and Practice of Knowledge Discovery in Databases	SEP 20-24, 2004	Pisa, ITALY	KDNet, Pascal Network, Kluwer & Mach Learning Journal, Springer, Municipal Pisa, Microsoft Res, COOP, Exeura, INSA-Lyon, ISTI-Cnr, Univ Pisa, Univ Bari, Reg Toscana		classification; text classification; spam filtering; email; incremental learning; online learning; feature generation; feature representation; Winnow; bigrams; orthogonal sparse bigrams		Spam filtering is a text categorization task that has attracted significant attention due to the increasingly huge amounts of junk email on the Internet. While current best-practice systems use Naive Bayes filtering and other probabilistic methods, we propose using a statistical, but non-probabilistic classifier based on the Winnow algorithm. The feature space considered by most current methods is either limited in expressivity or imposes a large computational cost. We introduce orthogonal sparse bigrams (OSB) as a feature combination technique that overcomes both these weaknesses. By combining Winnow and OSB with refined preprocessing and tokenization techniques we are able to reach an accuracy of 99.68% on a difficult test corpus, compared to 98.88% previously reported by the CRM114 classifier on the same test corpus.	Free Univ Berlin, Database & Informat Syst Grp, Berlin Brandenburg Grad Sch Distributed Informat, D-1000 Berlin, Germany; Empresa Brasileira Telecomunicac Embratel, Rio De Janeiro, Brazil; Univ Calif Riverside, Riverside, CA 92521 USA; Mitsubishi Elect Res Labs, Cambridge, MA USA	Siefkes, C (reprint author), Free Univ Berlin, Database & Informat Syst Grp, Berlin Brandenburg Grad Sch Distributed Informat, D-1000 Berlin, Germany.	christian@siefkes.net; fidelis@embratel.net.br; schhabra@cs.ucr.edu; wsy@merl.com					CARLSON AJ, 2004, SNOW USER MANUAL VER; Cohen WW, 1999, ACM T INFORM SYST, V17, P141, DOI 10.1145/306686.306688; DAGAN I, 1997, EMNLP 97; Graham P, 2003, MIT SPAM C; HIDALGO JMG, 2002, JADT 02 MADR ES; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; MUNOZ M, 1999, UIUCDCSR992087; SIEFKES C, 2002, THESIS TU BERLIN; YERAZUNIS WS, 2003, 2003 SPAM C CAMBR MA; ZHANG L, 2003, 20 INT C COMP PROC O; CRM114	11	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23108-0	LECT NOTES ARTIF INT			2004	3202						410	421				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAX57	WOS:000224109600038	
J	Pernkopf, F; O'Leary, P				Pernkopf, F; O'Leary, P			Floating search algorithm for structure learning of Bayesian network classifiers	PATTERN RECOGNITION LETTERS			English	Article						Bayesian network classifiers; feature selection; floating search method	FEATURE-SELECTION	This paper presents a floating search approach for learning the network structure of Bayesian network classifiers. A Bayesian network classifier is used which in combination with the search algorithm allows simultaneous feature selection and determination of the structure of the classifier. The introduced search algorithm enables conditional exclusions of previously added attributes and/or arcs from the network classifier. Hence, this algorithm is able to correct the network structure by removing attributes and/or arcs between the nodes if they become superfluous at a later stage of the search. Classification results of selective unrestricted Bayesian network classifiers are compared to naive Bayes classifiers and tree augmented naive Bayes classifiers. Experiments on different data sets show that selective unrestricted Bayesian network classifiers achieve a better classification accuracy estimate in two domains compared to tree augmented naive Bayes classifiers, whereby in the remaining domains the performance is similar. However, the achieved network structure of selective unrestricted Bayesian network classifiers is simpler. (C) 2003 Elsevier B.V. All rights reserved.	Graz Tech Univ, Inst Commun & Wave Propagat, A-8010 Graz, Austria; Univ Leobon, Inst Automat, A-8700 Leoben, Austria	Pernkopf, F (reprint author), Graz Tech Univ, Inst Commun & Wave Propagat, Inffeldgasse 16c II, A-8010 Graz, Austria.						Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Devijver P., 1982, PATTERN RECOGNITION; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; Heckerman D., 1995, MSRTR9506 MICR RES; Jain A., 1982, HDB STAT, V2; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jensen F. V., 1996, INTRO BAYESIAN NETWO; John G., 1994, P 11 INT C MACH LEAR, P121; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Kittler J., 1978, Pattern Recognition and Signal Processing; KOHAVI R, 1994, P AAAI FALL S REL, P122; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; Merz C., 1997, UCI REPOSITORY MACHI; MURPHY KP, 2001, BAYES NET TOOLBOX MA; Pearl J., 1988, PROBABILISTIC REASON; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; SINGH M, 1996, INT C MACH LEARN, P453; ZONGKER D, 1996, INT C PATT REC ICPR, P18	26	10	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	NOV	2003	24	15					2839	2848		10.1016/S0167-8655(03)00142-9		10	Computer Science, Artificial Intelligence	Computer Science	713LN	WOS:000184859600033	
S	Kotsiantis, SB; Pierrakeas, CJ; Pintelas, PE		Palade, V; Howlett, RJ; Jain, L		Kotsiantis, SB; Pierrakeas, CJ; Pintelas, PE			Preventing student dropout in distance learning using machine learning techniques	KNOWLEDGE-BASED INTELLIGNET INFORMATION AND ENGINEERING SYSTEMS, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th International Conference on Knowledge-Based Intelligent Information and Engineering Systems (KES 2003)	SEP 03-05, 2003	OXFORD, ENGLAND		UNIV OXFORD			Student dropout occurs quite often in universities providing distance education. The scope of this research is to study whether the usage of machine learning techniques can be useful in dealing with this problem. Subsequently, an attempt was made to identifying the most appropriate learning algorithm for the prediction of students' dropout. A number of experiments have taken place with data provided by the 'informatics' course of the Hellenic Open University and a quite interesting conclusion is that the Naive Bayes algorithm. can be successfully used. A prototype web based support tool, which can automatically recognize students with high probability of dropout, has been constructed by implementing this algorithm.	Univ Patras, Dept Math, Educ Software Dev Lab, GR-26110 Patras, Greece	Kotsiantis, SB (reprint author), Univ Patras, Dept Math, Educ Software Dev Lab, GR-26110 Patras, Greece.		kotsiantis, sotiris/C-5640-2009	kotsiantis, sotiris/0000-0002-2247-3082			Aha D.W., 1997, LAZY LEARNING; Burgess C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; CHYUNG Y, 1998, ANN C DIST TEACH LEA; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Long J., 1997, REGRESSION MODELS CA; Mitchell T.M., 1997, MACHINE LEARNING; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Park J, 1999, J HIGH ENERGY PHYS; PLATT J, 1999, ADV NEURAL INFORMATI, V11; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; SCHAFFER C, P 1994 INT C MACH LE, P153; SHIN N, 1999, DISTANCE ED INT J, V20; Witten I.H., 2000, DATA MINING PRACTICA; Xenos M, 2002, COMPUT EDUC, V39, P361, DOI 10.1016/S0360-1315(02)00072-6	16	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40804-5	LECT NOTES ARTIF INT			2003	2774						267	274				8	Computer Science, Artificial Intelligence	Computer Science	BX81U	WOS:000186518100037	
J	Frasconi, P; Soda, G; Vullo, A				Frasconi, P; Soda, G; Vullo, A			Hidden markov models for text categorization in multi-page documents	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						text categorization; multi-page documents; hidden Markov models; Naive Bayes; digital libraries	NETWORKS; EM	In the traditional setting, text categorization is formulated as a concept learning problem where each instance is a single isolated document. However, this perspective is not appropriate in the case of many digital libraries that offer as contents scanned and optically read books or magazines. In this paper, we propose a more general formulation of text categorization, allowing documents to be organized as sequences of pages. We introduce a novel hybrid system specifically designed for multi-page text documents. The architecture relies on hidden Markov models whose emissions are bag-of-words resulting from a multinomial word event model, as in the generative portion of the Naive Bayes classifier. The rationale behind our proposal is that taking into account contextual information provided by the whole page sequence can help disambiguation and improves single page classification accuracy. Our results on two datasets of scanned journals from the Making of America collection confirm the importance of using whole page sequences. The empirical evaluation indicates that the error rate (as obtained by running the Naive Bayes classifier on isolated pages) can be significantly reduced if contextual information is incorporated.	Univ Florence, Dept Comp Sci & Syst, I-50139 Florence, Italy	Frasconi, P (reprint author), Univ Florence, Dept Comp Sci & Syst, I-50139 Florence, Italy.		Frasconi, Paolo/G-2944-2010				Bengio Y., 1995, ADV NEURAL INFORMATI, V7, P427; BICKNESE DA, 1998, MEASURING ACCURACY O; Cavnar W.B., 1994, P 3 ANN S DOC AN INF, P161; Charniak E., 1993, STAT LANGUAGE LEARNI; COHEN WW, 1995, P 12 INT C MACH LEAR, P124; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Diligenti M., 2000, P 26 INT C VER LARG, P527; DILIGENTI M, 2001, LNCS, V2013, P147; Freitag D., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); HECKMAN J, 1997, CHICAGO POLICY REV, V1, P1; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Joachims T., 1999, P 16 INT C MACH LEAR, P200; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Junker M., 1998, International Journal on Document Analysis and Recognition, V1, DOI 10.1007/s100320050012; KALT T, 1996, TR9818 CIIR U MASS; Lewis D., 1994, P 17 ANN INT ACM SIG, P3; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; LUCKE H, 1995, SPEECH COMMUN, V16, P89, DOI 10.1016/0167-6393(94)00046-D; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; Mitchell T.M., 1997, MACHINE LEARNING; Ng HT, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P67, DOI 10.1145/258525.258537; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; PASSERINI A, 2001, LECT NOTES ARTIFICIA; Pearl J., 1988, PROBABILISTIC REASON; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Sahami M., 1997, P 14 INT C MACH LEAR, P170; SHAW EJ, 1997, D LIB MAGAZINE   JUL; Smyth P, 1997, NEURAL COMPUT, V9, P227, DOI 10.1162/neco.1997.9.2.227; Stolcke A., 1993, ADV NEURAL INFORMATI, V5, P11; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; Yang Y., 1997, P 14 INT C MACH LEAR, P412	31	10	14	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902			J INTELL INF SYST	J. Intell. Inf. Syst.	MAR-MAY	2002	18	2-3					195	217		10.1023/A:1013681528748		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	508XA	WOS:000173114000006	
S	Blei, DM; Ng, AY; Jordan, MI		Dietterich, TG; Becker, S; Ghahramani, Z		Blei, DM; Ng, AY; Jordan, MI			Latent Dirichlet allocation	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 14, VOLS 1 AND 2	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	15th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 03-08, 2001	VANCOUVER, CANADA					We propose a generative model for text and other collections of discrete data that generalizes or improves on several previous models including naive Bayes/unigram, mixture of unigrams [6], and Hofmann's aspect model, also known as probabilistic latent semantic indexing (pLSI) [3]. In the context of text modeling, our model posits that each document is generated as a mixture of topics, where the continuous-valued mixture proportions are distributed as a latent Dirichlet random variable. Inference and learning are carried out efficiently via variational algorithms. We present empirical results on applications of this model to problems in text modeling, collaborative filtering, and text classification.	Univ Calif Berkeley, Berkeley, CA 94720 USA	Blei, DM (reprint author), Univ Calif Berkeley, Berkeley, CA 94720 USA.						COHN D, 2001, ADV NEURAL INFORMATI, V13; GREEN PJ, 1998, MODELLING HETEROGENE; Hofmann T., 1999, P 22 ANN INT SIGIR C; JIANG TJ, 1992, J COMPUTATIONAL GRAP, V1, P231, DOI 10.2307/1390718; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; POPESCUL A, 2001, UNCERTAINTY ARTIFICI	7	10	10	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-04208-8	ADV NEUR IN			2002	14						601	608				8	Computer Science, Artificial Intelligence	Computer Science	BV95T	WOS:000180520100075	
S	Agrawal, R; Bayardo, R; Srikant, R		Zaniolo, C; Lockemann, PC; Scholl, MH; Grust, T		Agrawal, R; Bayardo, R; Srikant, R			Athena: Mining-based interactive management of text databases	ADVANCES IN DATABSE TECHNOLOGY-EDBT 2000, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Extending Database Technology	MAR 27-31, 2000	CONSTANCE, GERMANY	Software AG, Rentenanstalt/SwissLife, Credit Suisse, IBM Deutschland, Sun Microsyst, ORACLE, Dornier GmbH, Swiss Informat Soc (SI) DBTA, German Informat Sco, Univ Gesell Konstanz eV			AGENTS	We describe Athena: a system for creating, exploiting, and maintaining a hierarchy of textual documents through interactive mining-based operations. Requirements of any such system include speed and minimal end-user effort. Athena satisfies these requirements through linear-time classification and clustering engines which axe applied interactively to speed the development of accurate models. Naive Bayes classifiers are recognized to be among the best for classifying text. We show that our specialization of the Naive Bayes classifier is considerably more accurate (7 to 29% absolute increase in accuracy) than a standard implementation. Our enhancements include using Lidstone's law of succession instead of Laplace's law, under-weighting long documents, and over-weighting author and subject. We also present a new interactive clustering algorithm, C-Evolve, for topic discovery. C-Evolve first finds highly accurate cluster digests (partial clusters), gets user feedback to merge and correct these digests, and then uses the classification algorithm to complete the partitioning of the data. By allowing this interactivity in the clustering process, C-Evolve achieves considerably higher clustering accuracy (10 to 20% absolute increase in our experiments) than the popular K-Means and agglomerative clustering methods.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Agrawal, R (reprint author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.						AGRAWAL R, 1999, 10153 RJ IBM ALM RES; APTE C, 1994, ACM T INFORMATION SY; Chakrabarti S, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P446; COHEN W, 1996, P 1996 AAAI SPRING S; CUTTING DR, 1992, P 15 INT ACM SIGIR C; Good I, 1965, ESTIMATION PROBABILI; Hardy G.F., 1889, INSURANCE RECORD; Kohavi R., 1996, P 2 INT C KNOWL DISC; KOHAVI R, 1997, 9 EUR C MACH LEARN P; Kontkanen Petri, 1998, P 4 INT C KNOWL DISC; LANG K, 1995, P 12 INT C MACH LEAR, P331; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; Lidstone George James, 1920, T FACULTY ACTUARIES, V8, P182; MAES P, 1994, COMMUN ACM, V37, P31; McCallum A, 1998, AAAI 98 WORKSH LEARN; Mitchell T., 1997, MACH LEARN; Nigam K., 1998, INT C MACH LEARN; Payne TR, 1997, APPL ARTIF INTELL, V11, P1, DOI 10.1080/088395197118325; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; RASMUSSEN E, 1991, INFORMATION RETRIEVA, P419; Ristad E., 1995, CSTR49595 PRINC U; Sahami M., 1998, P 3 ACM INT C DIG LI, P200, DOI 10.1145/276675.276697; SAHAMI M, 1998, P AAAI 98 WORKHS LEA; SEGAL R, 1999, P 3 INT C AUT AG; Shafer J C, 1996, P 22 INT C VER LARG	25	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-67227-3	LECT NOTES COMPUT SC			2000	1777						365	379				15	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BS71H	WOS:000170923700025	
J	Hall, T; Beecham, S; Bowes, D; Gray, D; Counsell, S				Hall, Tracy; Beecham, Sarah; Bowes, David; Gray, David; Counsell, Steve			A Systematic Literature Review on Fault Prediction Performance in Software Engineering	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Review						Systematic literature review; software fault prediction	LEARN DEFECT PREDICTORS; STATIC CODE ATTRIBUTES; PARTICLE SWARM OPTIMIZATION; ORIENTED DESIGN METRICS; QUANTITATIVE-ANALYSIS; EMPIRICAL VALIDATION; PRONE CLASSES; MODELS; CLASSIFICATION; QUALITY	Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs, and improve the quality of software. Objective: We investigate how the context of models, the independent variables used, and the modeling techniques applied influence the performance of fault prediction models. Method: We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesize the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modeling techniques such as Naive Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology, and performance comprehensively.	[Hall, Tracy; Counsell, Steve] Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England; [Beecham, Sarah] Univ Limerick, Lero Irish Software Engn Res Ctr, Limerick, Ireland; [Bowes, David; Gray, David] Univ Hertfordshire, Sci & Technol Res Inst, Hatfield AL10 9AB, Herts, England	Hall, T (reprint author), Brunel Univ, Dept Informat Syst & Comp, Uxbridge UB8 3PH, Middx, England.	tracy.hall@brunel.ac.uk; sarah.beecham@lero.ie; d.h.bowes@herts.ac.uk; d.gray@herts.ac.uk; steve.counsell@brunel.ac.uk			United Kingdom's Engineering and Physical Science Research Council [EPSRC EP/E063039/1]; Science Foundation Ireland [3/CE2/I303_1]	The authors are grateful to the United Kingdom's Engineering and Physical Science Research Council who supported this research at Brunel University under grant EPSRC EP/E063039/1 and to Science Foundation Ireland grant 3/CE2/I303_1 who partially supported this work at Lero. They are also grateful to Dr. Sue Black and Dr. Paul Wernick who provided input to the early stages of the work reported in this paper and to Professor Martin Shepperd for his suggestions throughout the work. They are also grateful for the detailed and insightful comments from the reviewers that enabled them to significantly improve the quality of this paper.	Abreu R, 2009, IWPSE-EVOL 09: ERCIM WORKSHOP ON SOFTWARE EVOLUTION (EVOL) AND INTERNATIONAL WORKSHOP ON PRINCIPLES OF SOFTWARE EVOLUTION (IWPSE), P153; AFZAL W., 2008, P 3 INT C SOFTW ENG, P407; Afzal W, 2010, Proceedings 2010 17th Asia Pacific Software Engineering Conference (APSEC 2010). Software for Improving Quality of Life, DOI 10.1109/APSEC.2010.54; AFZAL W., 2008, P IEEE INT MULT C, P349; Amasaki S., 2003, P 14 INT S SOFTW REL, P215; Andersson C, 2007, IEEE T SOFTWARE ENG, V33, P273, DOI 10.1109/TSE.2007.1005; Arisholm E., 2006, P 2006 ACM IEEE INT, P8, DOI 10.1145/1159733.1159738; Arisholm E., 2007, P IEEE INT S SOFTW R, P215; Arisholm E, 2010, J SYST SOFTWARE, V83, P2, DOI 10.1016/j.jss.2009.06.055; Armour PG, 2004, COMMUN ACM, V47, P21, DOI 10.1145/971617.971635; Ayewah N, 2007, PASTE'07 PROCEEDINGS OF THE 2007 ACM SIGPLAN- SIGSOFT WORKSHOP ON PROGRAM ANALYSIS FOR SOFTWARE TOOLS & ENGINEERING, P1, DOI 10.1145/1251535.1251536; Batista G. E., 2004, ACM SIGKDD EXPLORATI, V6, P20, DOI DOI 10.1145/1007730.1007735; Bell RM, 2006, P ACM INT S SOFTW TE, P61, DOI 10.1145/1146238.1146246; Bellini P, 2005, IEEE INT C ENG COMP, P205; Bernstein A., 2007, P INT WORKSH PRINC S, P11, DOI DOI 10.1145/1294948.1294953; Bezerra M., 2007, P INT JOINT C NEUR N, P2869; Bibi S, 2006, I C COMP SYST APPLIC, P330, DOI 10.1109/AICCSA.2006.205110; Binkley D., 2007, P TEST AC IND C PRAC, P99; Binkley D, 2009, J SYST SOFTWARE, V82, P1793, DOI 10.1016/j.jss.2009.06.036; Bird C., 2009, P 20 INT S SOFTW REL, P109; Boetticher G., 2006, ADV MACHINE LEARNER, P52; Bowes D., 2011, 209 U HERTF; Bowes D., 2011, 510 U HERTF; Briand LC, 2002, IEEE T SOFTWARE ENG, V28, P706, DOI 10.1109/TSE.2002.1019484; Caglayan B, 2009, 2009 ICSE WORKSHOP ON EMERGING TRENDS IN FREE-LIBRE-OPEN SOURCE SOFTWARE RESEARCH AND DEVELOPMENT, P31, DOI 10.1109/FLOSS.2009.5071357; Calikli G., 2009, P 24 INT S COMP INF, P531; Catal C, 2009, EXPERT SYST APPL, V36, P7346, DOI 10.1016/j.eswa.2008.10.027; Catal C., 2007, P 2 INT C DEP COMP S, P238; Ceylan E, 2006, EUROMICRO CONF PROC, P240, DOI 10.1109/EUROMICRO.2006.56; Challagulla V. U. B., 2005, P 10 IEEE INT WORKSH, P263; Challagulla VUB, 2006, PROC INT C TOOLS ART, P39; Chawla N. V., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI DOI 10.1145/1007730.1007733; Cong J., 2010, 2010 2 INT C MULT IN, V1, P44; Cristianini N., 2006, INTRO SUPPORT VECTOR; Cruz C., 2009, P 3 INT S EMP SOFTW, P460; Cruz C., 2010, P ACM IEEE 32 INT C, P361; Cruzes DS, 2011, INFORM SOFTWARE TECH, V53, P440, DOI 10.1016/j.infsof.2011.01.004; Dallmeier V., 2007, P 22 IEEE ACM INT C, P433, DOI 10.1145/1321631.1321702; D'Ambros M, 2009, WORK CONF REVERSE EN, P135, DOI 10.1109/WCRE.2009.19; D'Ambros Marco, 2010, Proceedings of the 2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010), DOI 10.1109/MSR.2010.5463279; Davis J., 2006, P 23 INT C MACH LEAR, P233, DOI DOI 10.1145/1143844.1143874; de Carvalho AB, 2008, PROC INT C TOOLS ART, P387, DOI 10.1109/ICTAI.2008.76; de Carvalho AB, 2010, J SYST SOFTWARE, V83, P868, DOI 10.1016/j.jss.2009.12.023; Denaro G., 2000, Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium, DOI 10.1109/ICSE.2000.870474; Denaro G., 2002, Proceedings of the 24th International Conference on Software Engineering. ICSE 2002, DOI 10.1109/ICSE.2002.1007972; Denaro G., 2002, P INT C SOFTW ENG KN, P361; Dianqin Z., 2009, P INT C COMP INT SOF, P1; El Emam K, 2001, J SYST SOFTWARE, V56, P63, DOI 10.1016/S0164-1212(00)00086-8; Elish KO, 2008, J SYST SOFTWARE, V81, P649, DOI 10.1016/j.jss.2007.07.040; Fenton N., 2007, P 3 INT WORKSH PRED, P2; Fenton NE, 1999, IEEE T SOFTWARE ENG, V25, P675, DOI 10.1109/32.815326; Fenton NE, 2000, IEEE T SOFTWARE ENG, V26, P797, DOI 10.1109/32.879815; Fioravanti F, 2001, FIFTH EUROPEAN CONFERENCE ON SOFTWARE MAINTENANCE AND REENGINEERING, PROCEEDINGS, P121; Gao KH, 2007, IEEE T RELIAB, V56, P223, DOI 10.1109/TR.2007.896761; Gayatri N, 2009, Proceedings of the 2009 International Conference on Advances in Recent Technologies in Communication and Computing. ARTCom 2009, DOI 10.1109/ARTCom.2009.12; Gondra I, 2008, J SYST SOFTWARE, V81, P186, DOI 10.1016/j.jss.2007.05.035; Graves TL, 2000, IEEE T SOFTWARE ENG, V26, P653, DOI 10.1109/32.859533; Gray D., 2011, P EV ASS SOFTW ENG; Gray D., 2010, P INT JOINT C NEUR N, P1; Guo L., 2003, Proceedings 18th IEEE International Conference on Automated Software Engineering; Guo Lan, 2004, P 15 INT S SOFTW REL, P417, DOI DOI 10.1109/ISSRE.2004.35; Gyimothy T, 2005, IEEE T SOFTWARE ENG, V31, P897, DOI 10.1109/TSE.2005.112; Hall T, 2010, LECT NOTES COMPUT SC, V6156, P107, DOI 10.1007/978-3-642-13792-1_10; Hassan AE, 2009, PROC INT CONF SOFTW, P78, DOI 10.1109/ICSE.2009.5070510; Hassan AE, 2005, PROC IEEE INT CONF S, P263; He H., 2008, IEEE T KNOWL DATA EN, V21, P1263; Higo Y., 2008, P 2008 WORKSH DEF LA, P6, DOI 10.1145/1390817.1390820; Holschuh T, 2009, PROC INT CONF SOFTW, P172, DOI 10.1109/ICSE-COMPANION.2009.5070975; Hongyu Zhang, 2009, Proceedings of the 2009 IEEE International Conference on Software Maintenance (ICSM 2009), DOI 10.1109/ICSM.2009.5306304; Hovemeyer D., 2004, P 19 ACM C OBJ OR PR, P132; Hribar L., 2010, P 33 INT CONV MIPRO, P402; Hsu C.W., 2003, TECHNICAL REPORT; Huanjing W., 2010, P 9 INT C MACH LEARN, P135; Japkowicz N., 2002, Intelligent Data Analysis, V6; Jiang L, 2007, P 6 JOINT M EUR SOFT, P55, DOI 10.1145/1287624.1287634; Jiang Y., 2009, P 20 IEEE INT S SOFT, P99; Jiang Y., 2008, P 19 INT S SOFTW REL, P197; Jiang Y, 2008, EMPIR SOFTW ENG, V13, P561, DOI 10.1007/s10664-008-9079-3; Jiang Y, 2007, ISSRE 2007: 18TH IEEE INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, PROCEEDINGS, P237, DOI 10.1109/ISSRE.2007.24; Jones J. A., 2002, Proceedings of the 24th International Conference on Software Engineering. ICSE 2002, DOI 10.1109/ICSE.2002.1007991; Jones J, 2005, P 20 IEEE ACM INT C, P273, DOI 10.1145/1101908.1101949; Jorgensen M, 2007, IEEE T SOFTWARE ENG, V33, P33, DOI 10.1109/TSE.2007.256943; Joshi H., 2007, P 4 INT WORKSH MIN S, P33; Jun L., 2009, P 21 ANN I C CHIN CO, P2591; Kamei Y, 2007, P 1 INT S EMP SOFTW, P196; Kamei Y., 2010, P INT C SOFTW MAINT, P1; Kaminsky K, 2004, NAFIPS 2004: ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, VOLS 1AND 2, P10; Kanmani S., 2004, SIGSOFT SOFTWARE ENG, V29, P1; Kanmani S, 2007, INFORM SOFTWARE TECH, V49, P483, DOI 10.1016/j.infsof.2006.07.005; Kastro Y, 2008, SOFTWARE QUAL J, V16, P543, DOI 10.1007/s11219-008-9053-8; Kaur A, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P37, DOI 10.1109/ICACTE.2008.204; Kaur A, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P242, DOI 10.1109/ICMV.2009.54; Khoshgoftaar T. M., 2002, Empirical Software Engineering, V7, DOI 10.1023/A:1020511004267; Khoshgoftaar T. M., 2002, Proceedings Eighth IEEE Symposium on Software Metrics, DOI 10.1109/METRIC.2002.1011335; Khoshgoftaar T. M., 2001, Proceedings 12th International Symposium on Software Reliability Engineering, DOI 10.1109/ISSRE.2001.989459; Khoshgoftaar T. M., 2002, Proceedings 13th International Symposium on Software Reliability Engineering, DOI 10.1109/ISSRE.2002.1173256; Khoshgoftaar T. M., 2000, Proceedings 11th International Symposium on Software Reliability Engineering. ISSRE 2000, DOI 10.1109/ISSRE.2000.885877; Khoshgoftaar TM, 2002, PROC INT C TOOLS ART, P365, DOI 10.1109/TAI.2002.1180826; Khoshgoftaar TM, 2000, PROC INT C TOOLS ART, P54, DOI 10.1109/TAI.2000.889846; Khoshgoftaar T.M., 2010, P 22 IEEE INT C TOOL, V1, P137; Khoshgoftaar TM, 2005, EMPIR SOFTW ENG, V10, P183, DOI 10.1007/s10664-004-6191-x; Khoshgoftaar TM, 2002, EIGHTH IEEE SYMPOSIUM ON SOFTWARE METRICS, PROCEEDINGS, P203; Khoshgoftaar TM, 2004, EMPIR SOFTW ENG, V9, P229, DOI 10.1023/B:EMSE.0000027781.18360.9b; Kim S., 2006, P 14 ACM SIGSOFT INT, P35, DOI 10.1145/1181775.1181781; Kim S, 2006, IEEE INT CONF AUTOM, P81; Kim S, 2007, PROC INT CONF SOFTW, P489; Kitchenham B, 2010, J SYST SOFTWARE, V83, P37, DOI 10.1016/j.jss.2009.06.041; KITCHENHAM B. A., 2007, EBSE200701 KEEL U; Klas M., 2010, P 32 ACM IEEE INT C, P119; Klas M., 2008, P 19 INT S SOFTW REL, P17; KNAB P, 2006, P INT WORKSH MIN SOF, P119, DOI 10.1145/1137983.1138012; Koru AG, 2005, IEEE SOFTWARE, V22, P23, DOI 10.1109/MS.2005.149; Kutlubay O, 2007, EUROMICRO CONF PROC, P322; Lamkanfi Ahmed, 2010, Proceedings of the 2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010), DOI 10.1109/MSR.2010.5463284; Layman L, 2008, ESEM'08: PROCEEDINGS OF THE 2008 ACM-IEEE INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT, P206; Lessmann S, 2008, IEEE T SOFTWARE ENG, V34, P485, DOI 10.1109/TSE.2008.35; Li P., 2005, P IEEE SOFTW METR S, P10; Li P.L., 2004, SIGSOFT SOFTW ENG NO, V29, P263; Li P.L., 2006, P 28 INT C SOFTW ENG, P413, DOI 10.1145/1134285.1134343; Li Z., 2007, P IEEE INT C INF REU, P659; Liebchen G.A., 2008, PROMISE 08 P 4 INT W, P39, DOI 10.1145/1370788.1370799; Liu Wei, 2010, P 10 SIAM INT C DAT, P766; Ma Y., 2006, ADV MACHINE LEARNING, V1, P237; Madhavan J.T., 2007, P 2007 OOPSLA WORKSH, P36, DOI 10.1145/1328279.1328287; Mahaweerawat A., 2007, P 4 INT JOINT C COMP, P35; Mahaweerawat A., 2004, P INTECH C, P2; Mahaweerawat A., 2002, P INT C INT TECHN VI, P304; Marcus A, 2008, IEEE T SOFTWARE ENG, V34, P287, DOI 10.1109/TSE.2007.70768; Mende T., 2009, P 5 INT C PRED MOD S, P7; Mende T, 2009, EUR CON SFTWR MTNCE, P247, DOI 10.1109/CSMR.2009.55; Mende T, 2010, Proceedings of the 14th European Conference on Software Maintenance and Reengineering (CSMR 2010), DOI 10.1109/CSMR.2010.18; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P2, DOI 10.1109/TSE.2007.256941; Menzies T, 2010, AUTOMAT SOFTW ENG, V17, P375, DOI 10.1007/s10515-010-0069-5; Menzies T., 2008, P 4 INT WORKSH PRED, P47, DOI 10.1145/1370788.1370801; Menzies T., 2004, Proceedings. Eighth IEEE International Symposium on High Assurance Systems Engineering; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P637, DOI 10.1109/TSE.2007.70721; Mertik M., 2006, P INT C SOFTW ENG AD, P19; Mizuno O., 2007, P 6 JOINT M EUR SOFT, P405, DOI 10.1145/1287624.1287683; Mizuno Osamu, 2007, P 4 INT WORKSH MIN S, P4; Moser R, 2008, ICSE'08 PROCEEDINGS OF THE THIRTIETH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P181; Myrtveit I, 2005, IEEE T SOFTWARE ENG, V31, P380, DOI 10.1109/TSE.2005.58; Nagappan N., 2006, P 28 INT C SOFTW ENG, P452, DOI 10.1145/1134285.1134349; Nagappan N, 2005, PROC INT CONF SOFTW, P580, DOI 10.1145/1062455.1062558; Nagappan N, 2005, PROC INT CONF SOFTW, P284, DOI 10.1145/1062455.1062514; Nagappan Nachiappan, 2010, Proceedings of the 2010 IEEE 21st International Symposium on Software Reliability Engineering (ISSRE 2010), DOI 10.1109/ISSRE.2010.25; Nagwani NK, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P373, DOI 10.1109/IADCC.2010.5422923; Neufelder A. M., 2000, Proceedings 11th International Symposium on Software Reliability Engineering. ISSRE 2000, DOI 10.1109/ISSRE.2000.885868; Nikora A., 2004, P 28 INT COMP SOFTW, V1, P192; Nikora A. P., 2003, Proceedings. Ninth International Software Metrics Symposium, DOI 10.1109/METRIC.2003.1232479; Nugroho Ariadi, 2010, Proceedings of the 2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010), DOI 10.1109/MSR.2010.5463285; Olague HM, 2007, IEEE T SOFTWARE ENG, V33, P402, DOI 10.1109/TSE.2007.1015.; Oral A., 2007, P 22 INT S COMP INF, P1; Ostrand T., 2007, P 4 INT WORKSH SOFTW, P25; Ostrand T. J., 2010, P 6 INT C PRED MOD S, P1, DOI DOI 10.1145/1868328.1868357; Ostrand TJ, 2005, IEEE T SOFTWARE ENG, V31, P340, DOI 10.1109/TSE.2005.49; Ostrand TJ, 2005, P INT COMP SOFTW APP, P3; Ostrand T.J., 2004, ACM SIGSOFT SOFTW EN, V29, P86, DOI 10.1145/1013886.1007524; Ostrand T.J., 2005, P C DIV COMP, P48, DOI 10.1145/1095242.1095262; Ostrand TJ, 2007, P ACM SIGSOFT INT S, P219, DOI 10.1145/1273463.1273493; Padberg F, 2004, IEEE T SOFTWARE ENG, V30, P17, DOI 10.1109/TSE.2004.1265733; Pai GJ, 2007, IEEE T SOFTWARE ENG, V33, P675, DOI [10.1109/TSE.2007.70722., 10.1109/TSE.2007.70722]; Pandey A.K., 2010, P 2 INT C REL SAF HA, P136; Pelayo L, 2007, P ANN M N AM FUZZ IN, P69; Pendharkar PC, 2010, ENG APPL ARTIF INTEL, V23, P34, DOI 10.1016/j.engappai.2009.10.001; Peng Huang, 2009, Proceedings of the 2009 International Conference on Research Challenges in Computer Science (ICRCCS 2009), DOI 10.1109/ICRCCS.2009.19; Petersen K, 2009, P 3 INT S EMP SOFTW, P401; Pighin M., 2003, Proceedings 2003 International Symposium on Empirical Software Engineering. ISESE 2003; Pinzger M., 2008, P 16 ACM SIGSOFT INT, P2, DOI 10.1145/1453101.1453105; Pizzi NJ, 2002, IEEE IJCNN, P2405, DOI 10.1109/IJCNN.2002.1007518; Ramler R, 2009, 2009 35TH EUROMICRO CONFERENCE ON SOFTWARE ENGINEERING AND ADVANCED APPLICATIONS, PROCEEDINGS, P181, DOI 10.1109/SEAA.2009.65; Rana ZA, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 4, PROCEEDINGS, P3, DOI 10.1109/WCSE.2009.92; Ratzinger J, 2008, P INT WORK C MIN SOF, P35, DOI 10.1145/1370750.1370759; Reformat M., 2003, FUZZY BASED METAMODE; Rodriguez D., 2007, P 8 IEEE INT C INF R, P667; Rosenthal R, 2001, ANNU REV PSYCHOL, V52, P59, DOI 10.1146/annurev.psych.52.1.59; Sandhu P.S., 2010, P 2 INT C COMP AUT E, V4, P281; Sandhu P.S., 2010, P INT C EL INF ENG, V2, pV2; Schneidewind N., 2001, P 7 INT SOFTW METR S, P328; Schroter A, 2006, SIGSOFT SOFTW ENG NO, V31, P1; Schroter A., 2006, P 5 INT S EMP SOFTW, P18, DOI 10.1145/1159733.1159739; Schroter A., 2006, P 5 INT S EMP SOFTW, V2, P18; Seiffert C, 2009, IEEE T SYST MAN CY A, V39, P1283, DOI 10.1109/TSMCA.2009.2027131; Seliya N, 2005, P 9 IEEE INT S HIGH, P89; Seliya Naeem, 2010, Proceedings 2010 IEEE 12th International Symposium on High-Assurance Systems Engineering (HASE), DOI 10.1109/HASE.2010.29; Selvarani R, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING SYSTEMS, P766, DOI 10.1109/ICSPS.2009.163; Shatnawi R, 2008, J SYST SOFTWARE, V81, P1868, DOI 10.1016/j.jss.2007.12.794; Sherriff M., 2007, P C CTR ADV STUD COL, P276, DOI 10.1145/1321211.1321247; Sherriff M., 2005, SIGSOFT SOFTWARE ENG, V30, P1; Shin Y, 2009, 2009 6TH IEEE INTERNATIONAL WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES, P61, DOI 10.1109/MSR.2009.5069481; Shivaji S, 2009, IEEE INT CONF AUTOM, P600, DOI 10.1109/ASE.2009.76; Singh Pradeep, 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), DOI 10.1109/ACT.2009.212; Singh Y, 2008, LECT NOTES COMPUT SC, V5089, P204, DOI 10.1007/978-3-540-69566-0_18; Singh Y, 2010, SOFTWARE QUAL J, V18, P3, DOI 10.1007/s11219-009-9079-6; Song QB, 2011, IEEE T SOFTWARE ENG, V37, P356, DOI 10.1109/TSE.2010.90; Song QB, 2006, IEEE T SOFTWARE ENG, V32, P69; Stringfellow C, 2002, SOFTWARE QUAL J, V10, P299, DOI 10.1023/A:1022138004472; Succi G, 2003, J SYST SOFTWARE, V65, P1, DOI 10.1016/S0164-1212(02)00024-9; Suffian M.D.M., 2010, P INT S INF TECHN, V3, P1087; Thwin MMT, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P2312; Tomaszewski P, 2006, PROC IEEE INT CONF S, P487; Tosun A., 2009, P 2009 3 INT S EMP S, P477; Tosun A., 2009, P 5 INT C PRED MOD S, P11; Tosun A, 2010, INFORM SOFTWARE TECH, V52, P1242, DOI 10.1016/j.infsof.2010.06.006; Turhan B, 2009, EMPIR SOFTW ENG, V14, P540, DOI 10.1007/s10664-008-9103-7; Turhan B, 2010, LECT NOTES COMPUT SC, V6156, P116, DOI 10.1007/978-3-642-13792-1_11; Turhan B., 2007, P 7 INT C QUAL SOFTW, P231; Turhan B, 2008, PROCEEDINGS OF THE 34TH EUROMICRO CONFERENCE ON SOFTWARE ENGINEERING AND ADVANCED APPLICATIONS, P191, DOI 10.1109/SEAA.2008.52; Turhan B, 2009, EXPERT SYST APPL, V36, P9986, DOI 10.1016/j.eswa.2008.12.028; Vandecruys O, 2008, J SYST SOFTWARE, V81, P823, DOI 10.1016/j.jss.2007.07.034; Visa S., 2004, P IPMU C PER, P393; Vivanco R., 2010, P 23 CAN C EL COMP E, P1; Wahyudin D, 2008, PROCEEDINGS OF THE 34TH EUROMICRO CONFERENCE ON SOFTWARE ENGINEERING AND ADVANCED APPLICATIONS, P207, DOI 10.1109/SEAA.2008.36; Wang T., 2010, P IEEE VTC MAY, P1, DOI 10.1145/1921168.1921172; Wei Wei, 2010, Proceedings of the 2010 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA 2010), DOI 10.1109/CIMSA.2010.5611753; Weimin Y., 2008, P INT C INT COMP TEC, P747; Ostrand T. J., 2002, Software Engineering Notes, V27; Weyuker E. J., 2007, P INT WORKSH PRED MO, P8, DOI 10.1109/PROMISE.2007.14; Weyuker E. J., 2008, P 4 INT WORKSH PRED, P3, DOI 10.1145/1370788.1370792; Weyuker EJ, 2010, EMPIR SOFTW ENG, V15, P277, DOI 10.1007/s10664-009-9111-2; Weyuker EJ, 2008, EMPIR SOFTW ENG, V13, P539, DOI 10.1007/s10664-008-9082-8; Wohlin C, 2000, PROG COMPREHEN, P9, DOI 10.1109/WPC.2000.852475; Wong WE, 2000, SOFTWARE PRACT EXPER, V30, P1587, DOI 10.1002/1097-024X(20001125)30:14<1587::AID-SPE352>3.0.CO;2-1; Xu Z., 2000, P 5 IEEE INT S HIGH, P281; Yang B., 2007, P 3 INT C NAT COMP A, V1, P760; Yi Liu, 2010, IEEE Transactions on Software Engineering, V36, DOI 10.1109/TSE.2010.51; Youngki H., 2008, P IEEE ACIS 7 INT C, P469; Yu P., 2002, P 6 EUR C SOFTW MAIN, P99; Yuan X., 2000, Proceedings 3rd IEEE Symposium on Application-Specific Systems and Software Engineering Technology, DOI 10.1109/ASSET.2000.888052; Zhang Dongsong, 2007, P 3 INT WORKSH PRED, P10; Zhang HY, 2010, PROCEEDINGS OF THE ELEVENTH WEST LAKE INTERNATIONAL CONFERENCE ON SMALL & MEDIUM BUSINESS, P14; Zhang HY, 2007, IEEE T SOFTWARE ENG, V33, P635, DOI 10.1109/TSE.2007.70706; Zhong S., 2004, P 10 ISSAT INT C REL, P149; Zhou YM, 2010, J SYST SOFTWARE, V83, P660, DOI 10.1016/j.jss.2009.11.704; Zhou YM, 2006, IEEE T SOFTWARE ENG, V32, P771; Zimmermann T, 2007, ISSRE 2007: 18TH IEEE INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, PROCEEDINGS, P227, DOI 10.1109/ISSRE.2007.19; Zimmermann T., 2009, P 3 INT S EMP SOFTW, P435; Zimmermann T., 2007, P 3 INT WORKSH PRED, P9; Zimmermann T., 2009, P 7 JOINT M EUR SOFT, P91, DOI 10.1145/1595696.1595713; Zimmermann T, 2008, ICSE'08 PROCEEDINGS OF THE THIRTIETH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P531	239	9	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589			IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	NOV-DEC	2012	38	6					1276	1304		10.1109/TSE.2011.103		29	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	043PI	WOS:000311556100003	
J	Najy, WKA; Zeineldin, HH; Alaboudy, AHK; Woon, WL				Najy, Waleed K. A.; Zeineldin, H. H.; Alaboudy, Ali H. Kasem; Woon, Wei Lee			A Bayesian Passive Islanding Detection Method for Inverter-Based Distributed Generation Using ESPRIT	IEEE TRANSACTIONS ON POWER DELIVERY			English	Article						Estimation of signal parameters via rotational invariance techniques (ESPRIT); inverter-based distributed generation (DG); islanding detection; naive-Bayes classification; power systems	PERFORMANCE; RELAYS	In this paper, a new passive islanding detection method for grid-connected inverter-based distributed-generation (DG) systems is proposed. A statistical signal-processing algorithm known as estimation of signal parameters via rotational invariance techniques is used to extract new features from measurements of the voltage and frequency at the point of common coupling as islanding indicators. The new features are defined based on a damped-sinusoid model for power system voltage and frequency waveforms, and include modal initial amplitudes, oscillation frequencies, damping factors, and initial phases. A set of training cases generated on the IEEE 34-bus system was used to train a naive-Bayes classifier that discriminates islanding and nonislanding events. Cross-validation was used to evaluate the performance of the proposed islanding detection method. The results show that by using the new features extracted from ESPRIT, the classifier is capable of discriminating islanding and nonislanding events with an accuracy close to 100%.	[Najy, Waleed K. A.; Zeineldin, H. H.; Alaboudy, Ali H. Kasem; Woon, Wei Lee] Masdar Inst Sci & Technol, Abu Dhabi, U Arab Emirates	Najy, WKA (reprint author), Masdar Inst Sci & Technol, Abu Dhabi, U Arab Emirates.	wnajy@masdar.ac.ae; hzainaldin@masdar.ac.ae; aalaboudy@masdar.ac.ae; wwoon@masdar.ac.ae			Masdar Institute of Science and Technology	Manuscript received January 17, 2011; revised April 01, 2011; accepted June 03, 2011. Date of publication July 19, 2011; date of current version October 07, 2011. This work was supported by the Masdar Institute of Science and Technology. Paper no. TPWRD-00041-2011.	[Anonymous], 2009, 154722008 IEEE; [Anonymous], 2000, 9292000 IEEE; Bollen MHJ, 2005, IEEE T POWER DELIVER, V20, P2298, DOI 10.1109/TPWRD.2004.843386; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dong X., 2009, P C HIGH PERF COMP N, P1, DOI 10.1145/1654059.1654117; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; El-Arroudi K, 2007, IEEE T POWER SYST, V22, P1112, DOI 10.1109/TPWRS.2007.901089; El-Arroudi K, 2007, IEEE T POWER DELIVER, V22, P828, DOI 10.1109/TPWRD.2007.893592; Gu IYH, 2008, IEEE T POWER DELIVER, V23, P13, DOI 10.1109/TPWRD.2007.911130; Jang SI, 2004, IEEE T POWER DELIVER, V19, P745, DOI 10.1109/TPWRD.2003.822964; KARLSSON D, 1994, IEEE T POWER SYST, V9, P157, DOI 10.1109/59.317546; Kim S., 2009, P 31 INT C TEL EN IN, P1; Kim SK, 2010, IEEE T IND ELECTRON, V57, P494, DOI 10.1109/TIE.2009.2036028; Kundur P., 1994, POWER SYSTEM STABILI; Lidula N, 2009, P IEEE POW EN SOC GE, P1; Liu F, 2010, IET RENEW POWER GEN, V4, P36, DOI 10.1049/iet-rpg.2009.0019; Lopes LAC, 2006, IEEE T ENERGY CONVER, V21, P171, DOI 10.1109/TEC.2005.859981; O'Kane P., 1997, P 6 INT C DEV POW SY, P95; Pai F.S., 2001, IEEE POWER ENG REV, V21, P67, DOI 10.1109/MPER.2001.4311227; REDFERN MA, 1993, IEEE T POWER DELIVER, V8, P948, DOI 10.1109/61.252622; Ropp ME, 2000, IEEE T ENERGY CONVER, V15, P290, DOI 10.1109/60.875495; ROY R, 1989, IEEE T ACOUST SPEECH, V37, P984, DOI 10.1109/29.32276; Samantaray SR, 2010, IEEE T POWER DELIVER, V25, P1427, DOI 10.1109/TPWRD.2010.2042625; Vieira JCM, 2006, IEE P-GENER TRANSM D, V153, P399, DOI 10.1049/ip-gtd:20045205; Yang Y., 2001, P 12 EUR C MACH LEAR, P564; YIN J, 2005, P 36 POW EL SPEC C, P2482; Zeineldin HH, 2011, IEEE T IND ELECTRON, V58, P139, DOI 10.1109/TIE.2009.2033482; Zeineldin H., 2008, P 2008 IEEE POW EN S, P1; Zhu X., 2009, P IEEE EN CONV C EXP, P2733	29	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0885-8977			IEEE T POWER DELIVER	IEEE Trans. Power Deliv.	OCT	2011	26	4					2687	2696		10.1109/TPWRD.2011.2159403		10	Engineering, Electrical & Electronic	Engineering	874TU	WOS:000298981800068	
J	Ghosh, S; Dent, R; Harper, ME; Gorman, SA; Stuart, JS; McPherson, R				Ghosh, Sujoy; Dent, Robert; Harper, Mary-Ellen; Gorman, Shelby A.; Stuart, Joan S.; McPherson, Ruth			Gene expression profiling in whole blood identifies distinct biological pathways associated with obesity	BMC MEDICAL GENOMICS			English	Article							GENOME-WIDE ASSOCIATION; SET ENRICHMENT ANALYSIS; INSULIN-RESISTANCE; OXIDATIVE-PHOSPHORYLATION; SKELETAL-MUSCLE; ADULT OBESITY; FTO GENE; CANCER; CLASSIFICATION; INFLAMMATION	Background: Obesity is reaching epidemic proportions and represents a significant risk factor for cardiovascular disease, diabetes, and cancer. Methods: To explore the relationship between increased body mass and gene expression in blood, we conducted whole-genome expression profiling of whole blood from seventeen obese and seventeen well matched lean subjects. Gene expression data was analyzed at the individual gene and pathway level and a preliminary assessment of the predictive value of blood gene expression profiles in obesity was carried out. Results: Principal components analysis of whole-blood gene expression data from obese and lean subjects led to efficient separation of the two cohorts. Pathway analysis by gene-set enrichment demonstrated increased transcript levels for genes belonging to the "ribosome", "apoptosis" and "oxidative phosphorylation" pathways in the obese cohort, consistent with an altered metabolic state including increased protein synthesis, enhanced cell death from proinflammatory or lipotoxic stimuli, and increased energy demands. A subset of pathway-specific genes acted as efficient predictors of obese or lean class membership when used in Naive Bayes or logistic regression based classifiers. Conclusion: This study provides a comprehensive characterization of the whole blood transcriptome in obesity and demonstrates that the investigation of gene expression profiles from whole blood can inform and illustrate the biological processes related to regulation of body mass. Additionally, the ability of pathway-related gene expression to predict class membership suggests the feasibility of a similar approach for identifying clinically useful blood-based predictors of weight loss success following dietary or surgical interventions.	[Ghosh, Sujoy] N Carolina Cent Univ, Biomed Biotechnol Res Inst, Durham, NC USA; [Dent, Robert] Ottawa Hosp, Ottawa Hosp Weight Management Clin, Ottawa, ON, Canada; [Harper, Mary-Ellen] Univ Ottawa, Fac Med, Dept Biochem Microbiol & Immunol, Ottawa, ON, Canada; [Gorman, Shelby A.; Stuart, Joan S.] GlaxoSmithKline, Res Triangle Pk, NC USA; [McPherson, Ruth] Univ Ottawa, Inst Heart, Ottawa, ON, Canada	Ghosh, S (reprint author), N Carolina Cent Univ, Biomed Biotechnol Res Inst, Durham, NC USA.	sghosh@nccu.edu; rmcpherson@ottawaheart.ca	Harper, Mary-Ellen/C-3103-2009		GlaxoSmithKline; NIH [NHLBI-5R25HL059868-10, NIDDK-1R21DK088319-01]; Heart & Stroke Foundation of Ontario [NA-5413]	This work was conducted with a grant support from GlaxoSmithKline. Part of the study was supported by NIH grants NHLBI-5R25HL059868-10 and NIDDK-1R21DK088319-01 (Ghosh) and a grant from the Heart & Stroke Foundation of Ontario (NA-5413; McPherson, Dent and Harper).	Abeel T, BIOINFORMATICS, V26, P392; Amundson SA, 2004, CANCER RES, V64, P6368, DOI 10.1158/0008-5472.CAN-04-1883; Barouch LA, 2006, CIRC RES, V98, P119, DOI 10.1161/01.RES.0000199348.10580.1d; Batliwalla FM, 2005, MOL MED, V11, P21, DOI 10.2119/2006-00003.Gulko; Batliwalla FM, 2005, GENES IMMUN, V6, P388, DOI 10.1038/sj.gene.6364209; Breiman L, 2001, MACH LEARN, V455, P5; Charriere G, 2003, J BIOL CHEM, V278, P9850, DOI 10.1074/jbc.M210811200; Cover T. M., 1991, ELEMENTS INFORM THEO; Dandona P, 2004, TRENDS IMMUNOL, V25, P4, DOI 10.1016/j.it.2003.10.013; Del Rio A, 2008, J CHROMATOGR A, V1185, P49, DOI 10.1016/j.chroma.2008.01.034; DePrimo SE, 2003, BMC CANCER, V3, DOI 10.1186/1471-2407-3-3; Dhanasekaran SM, 2001, NATURE, V412, P822, DOI 10.1038/35090585; Forrest MS, 2005, ENVIRON HEALTH PERSP, V113, P801, DOI 10.1289/ehp.7635; Frayling TM, 2007, SCIENCE, V316, P889, DOI 10.1126/science.1141634; Glatt SJ, 2005, P NATL ACAD SCI USA, V102, P15533, DOI 10.1073/pnas.0507666102; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gould J, 2006, BIOINFORMATICS, V22, P1924, DOI 10.1093/bioinformatics/btl196; Harper ME, 2002, DIABETES, V51, P2459, DOI 10.2337/diabetes.51.8.2459; Hinney A, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001361; Hoppe S, 2009, P NATL ACAD SCI USA, V106, P17781, DOI 10.1073/pnas.0909873106; Indra Devi M, 2008, WEBOLOGY, V5; Irizarry RA, 2006, BIOINFORMATICS, V22, P789, DOI 10.1093/bioinformatics/btk046; KALOFOUTIS A, 1975, CLIN CHEM, V21, P1414; Kelley DE, 2002, DIABETES, V51, P2944, DOI 10.2337/diabetes.51.10.2944; Liu J, 2006, J MOL DIAGN, V8, P551, DOI 10.2353/jmoldx.2006.060021; Loos RJF, 2008, NAT GENET, V40, P768, DOI 10.1038/ng.140; Lupi R, 2002, DIABETES, V51, P1437, DOI 10.2337/diabetes.51.5.1437; Meyre D, 2009, NAT GENET, V41, P157, DOI 10.1038/ng.301; Miller GE, 2009, P NATL ACAD SCI USA, V106, P14716, DOI 10.1073/pnas.0902971106; Min J, BMC GENOMICS, V11, P96; Mootha VK, 2003, NAT GENET, V34, P267, DOI 10.1038/ng1180; Ogata H, 1999, NUCLEIC ACIDS RES, V27, P29, DOI 10.1093/nar/27.1.29; Pahl A, 2002, BLOOD, V100, P1094, DOI 10.1182/blood-2002-03-0813; Patti ME, 2003, P NATL ACAD SCI USA, V100, P8466, DOI 10.1073/pnas.1032913100; Pausova Z, 2001, HYPERTENSION, V38, P41; Raghavachari N, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006484; Rankinen T, 2006, OBESITY, V14, P529, DOI 10.1038/oby.2006.71; RAO GMM, 1984, EUR J APPL PHYSIOL O, V52, P272, DOI 10.1007/BF01015208; Schaefer CF, 2009, NUCLEIC ACIDS RES, V37, pD674, DOI 10.1093/nar/gkn653; Scherag A, 2006, PLOS GENET, V6; Scuteri A, 2007, PLOS GENET, V3, P1200, DOI 10.1371/journal.pgen.0030115; SNYDER LRG, 1982, RESP PHYSIOL, V48, P89, DOI 10.1016/0034-5687(82)90052-4; Solinas G, 2007, CELL METAB, V6, P386, DOI 10.1016/j.cmet.2007.09.011; Subramanian A, 2007, BIOINFORMATICS, V23, P3251, DOI 10.1093/bioinformatics/btm369; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Takamura T, 2008, OBESITY, V16, P2601, DOI 10.1038/oby.2008.419; Technote A, SIGN GEN DIFF BLOOD; Thorleifsson G, 2009, NAT GENET, V41, P18, DOI 10.1038/ng.274; Tsuang MT, 2005, AM J MED GENET B, V133B, P1, DOI 10.1002/ajmg.b.30161; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vernon SD, 2002, DIS MARKERS, V18, P193; Wallace DC, 2005, ANNU REV GENET, V39, P359, DOI 10.1146/annurev.genet.39.110304.095751; Wardle J, 2008, AM J CLIN NUTR, V87, P398; Whitney AR, 2003, P NATL ACAD SCI USA, V100, P1896, DOI 10.1073/pnas.252784499; Willer CJ, 2009, NAT GENET, V41, P25, DOI 10.1038/ng.287; Williams N, 2006, ACM SIGCOMM COMP COM, V36, P7; Wright C, 2008, CLIN CHEM, V54, P396, DOI 10.1373/clinchem.2007.093419; WYSOCKI M, 1991, ATHEROSCLEROSIS, V88, P21, DOI 10.1016/0021-9150(91)90253-Y; Xu HY, 2003, J CLIN INVEST, V112, P1821, DOI 10.1172/JCI200319451; Zhang HH, 2001, J CLIN ENDOCR METAB, V86, P2817, DOI 10.1210/jc.86.6.2817	60	9	9	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1755-8794			BMC MED GENOMICS	BMC Med. Genomics	DEC 1	2010	3								56	10.1186/1755-8794-3-56		13	Genetics & Heredity	Genetics & Heredity	702FB	WOS:000285878900001	
J	Matwin, S; Kouznetsov, A; Inkpen, D; Frunza, O; O'Blenis, P				Matwin, Stan; Kouznetsov, Alexandre; Inkpen, Diana; Frunza, Oana; O'Blenis, Peter			A new algorithm for reducing the workload of experts in performing systematic reviews	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article							TEXT CATEGORIZATION; MEDICINE; CLASSIFICATION	Objective To determine whether a factorized version of the complement naive Bayes (FCNB) classifier can reduce the time spent by experts reviewing journal articles for inclusion in systematic reviews of drug class efficacy for disease treatment. Design The proposed classifier was evaluated on a test collection built from 15 systematic drug class reviews used in previous work. The FCNB classifier was constructed to classify each article as containing high-quality, drug class-specific evidence or not. Weight engineering (WE) techniques were added to reduce underestimation for Medical Subject Headings (MeSH)-based and Publication Type (PubType)-based features. Cross-validation experiments were performed to evaluate the classifier's parameters and performance. Measurements Work saved over sampling (WSS) at no less than a 95% recall was used as the main measure of performance. Results The minimum workload reduction for a systematic review for one topic, achieved with a FCNB/WE classifier, was 8.5%; the maximum was 62.2% and the average over the 15 topics was 33.5%. This is 15.0% higher than the average workload reduction obtained using a voting perceptron-based automated citation classification system. Conclusion The FCNB/WE classifier is simple, easy to implement, and produces significantly better results in reducing the workload than previously achieved. The results support it being a useful algorithm for machine-learning- based automation of systematic reviews of drug class efficacy for disease treatment.	[Kouznetsov, Alexandre] Univ New Brunswick, Dept Comp Sci & Appl Stat, St John, NB E2L 4L5, Canada; [Matwin, Stan] Polish Acad Sci, Inst Comp Sci, PL-00901 Warsaw, Poland; [O'Blenis, Peter] Evidence Partners Corp, Ottawa, ON, Canada; [Matwin, Stan; Inkpen, Diana; Frunza, Oana] Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada	Kouznetsov, A (reprint author), Univ New Brunswick, Dept Comp Sci & Appl Stat, 100 Tucker Pk Rd, St John, NB E2L 4L5, Canada.	alexk@unb.ca			Precarn/Ontario Centres of Excellence Partnership; Natural Sciences and Engineering Research Council of Canada	This work was funded by the Precarn/Ontario Centres of Excellence Partnership, and by the Natural Sciences and Engineering Research Council of Canada.	ANDREW M, 1998, COMP EVENT MODELS NA; Aphinyanaphongs Y, 2005, J AM MED INFORM ASSN, V12, P207, DOI 10.1197/jamia.M1641; Bigby M, 1998, ARCH DERMATOL, V134, P1609, DOI 10.1001/archderm.134.12.1609; Blanco R, 2005, J BIOMED INFORM, V38, P376, DOI 10.1016/j.jbi.2005.05.004; COHEN AM, DRUG REV J CITATION; Cohen AM, 2009, J AM MED INFORM ASSN, V16, P690, DOI 10.1197/jamia.M3162; Cohen Aaron M, 2008, AMIA Annu Symp Proc, P121; Cohen AM, 2006, J AM MED INFORM ASSN, V13, P206, DOI 10.1197/jamia.M1929; CRAVEN MW, 1995, P IJCAI 95 WORKSH MA, P61; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; HAYNES RB, 1994, J AM MED INFORM ASSN, V1, P447; KOUZNETSOV A, 2009, CAN ART INT C; LEWIS DD, 1994, ACM T INFORM SYST, V12, P231; *NAT LIB MED, UN MED LANG SYST FAC; National Library of Medicine, MED SUBJ HEAD; Porter M., PORTER STEMMING ALGO; Rennie J, 2003, P 20 INT C MACH LEAR, P616; Sackett DL, 1996, BRIT MED J, V312, P71; SAHAMI M, 1998, AAAI ICML WORKSH MEN; Salton G., 1983, INTRO MODERN INFORM; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Seppi D., 2009, P INT C AFF COMP INT, P690; SU J, 2008, 25 INT C MACH LEARN, P1016; WILCZYNSKI NL, 2003, AMIA ANN S P, P728; Yang Y, 1997, 14 INT C MACH LEARN, P412	25	9	10	B M J PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1067-5027			J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JUL	2010	17	4					446	453		10.1136/jamia.2010.004325		8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	626YZ	WOS:000280005800015	
J	Wu, CC; Asgharzadeh, S; Triche, TJ; D'Argenio, DZ				Wu, Chia-Chin; Asgharzadeh, Shahab; Triche, Timothy J.; D'Argenio, David Z.			Prediction of human functional genetic networks from heterogeneous data using RVM-based ensemble learning	BIOINFORMATICS			English	Article							PROTEIN-PROTEIN INTERACTIONS; RELEVANCE VECTOR MACHINE; SACCHAROMYCES-CEREVISIAE; REGULATORY NETWORKS; DRUG DISCOVERY; MODELS; RECONSTRUCTION; CLASSIFIER; LINKAGES; BIOLOGY	Motivation: Three major problems confront the construction of a human genetic network from heterogeneous genomics data using kernel-based approaches: definition of a robust gold-standard negative set, large-scale learning and massive missing data values. Results: The proposed graph-based approach generates a robust GSN for the training process of genetic network construction. The RVM-based ensemble model that combines AdaBoost and reduced-feature yields improved performance on large-scale learning problems with massive missing values in comparison to Naive Bayes.	[Wu, Chia-Chin; D'Argenio, David Z.] Univ So Calif, Dept Biomed Engn, Los Angeles, CA 90089 USA; [Asgharzadeh, Shahab; Triche, Timothy J.] Childrens Hosp Los Angeles, Los Angeles, CA 90089 USA; [Asgharzadeh, Shahab; Triche, Timothy J.] Univ So Calif, Keck Sch Med, Los Angeles, CA 90089 USA	D'Argenio, DZ (reprint author), Univ So Calif, Dept Biomed Engn, Los Angeles, CA 90089 USA.	dargenio@bmsr.usc.edu			National Institute of Health [P41-EB001978]; US Department of Defense [W81XWH-07-1-0580]; National Institute of Health's Child Health Research Career Development [K12-CA60104]	National Institute of Health grant P41-EB001978, US Department of Defense grant W81XWH-07-1-0580, and National Institute of Health's Child Health Research Career Development Award Program K12-CA60104.	Ashburner M, 2000, NAT GENET, V25, P25; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Ben-Hur A, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S2; Ben-Hur Asa, 2005, BIOINFORMATICS S1, V21, pi38; Bowd C, 2005, INVEST OPHTH VIS SCI, V46, P1322, DOI 10.1167/iovs.04-1122; Bowers PM, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-5-r35; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dijkstra E.W., 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; Do T.N., 2007, P 6 INT C MACH LEARN, P7; Down TA, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-131; Ferretti V, 2007, NUCLEIC ACIDS RES, V35, pD122, DOI 10.1093/nar/gkl879; Franke L, 2006, AM J HUM GENET, V78, P1011, DOI 10.1086/504300; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GARY D, 2003, NUCLEIC ACIDS RES, V31, P248; Prasad TSK, 2009, NUCLEIC ACIDS RES, V37, pD767, DOI 10.1093/nar/gkn892; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Jansen R, 2004, CURR OPIN MICROBIOL, V7, P535, DOI 10.1016/j.mib.2004.08.012; Kondor RI, 2002, P 19 INT C MACH LEAR, P315; Krishnapuram B, 2004, J COMPUT BIOL, V11, P227, DOI 10.1089/1066527041410463; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; LI X, 2005, ENG APPL ARTIF INTEL, V21, P785; Linding R, 2008, NUCLEIC ACIDS RES, V36, pD695, DOI 10.1093/nar/gkm902; Loging W, 2007, NAT REV DRUG DISCOV, V6, P220, DOI 10.1038/nrd2265; Ng SK, 2003, NUCLEIC ACIDS RES, V31, P251, DOI 10.1093/nar/gkg079; Obayashi T, 2008, NUCLEIC ACIDS RES, V36, pD77, DOI 10.1093/nar/gkm840; OPITZ D, 1999, J ARTIFICIAL INTELLI, V11, P169; Papin JA, 2005, NAT REV MOL CELL BIO, V6, P99, DOI 10.1038/nrm1570; PAVLIDIS P, 2001, GENE FUNCTIONAL CLAS, P249; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Qi YJ, 2006, PROTEINS, V63, P490, DOI 10.1002/prot.20865; Qiu J, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000054; Rhodes DR, 2005, NAT BIOTECHNOL, V23, P951, DOI 10.1038/nbt1103; Rual JF, 2005, NATURE, V437, P1173, DOI 10.1038/nature04209; Saar-Tsechansky M, 2007, J MACH LEARN RES, V8, P1625; Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303; Stears RL, 2003, NAT MED, V9, P140, DOI 10.1038/nm0103-140; Stoughton RB, 2005, NAT REV DRUG DISCOV, V4, P345, DOI 10.1038/nrd1696; Tipping M. E., 2003, P 9 INT WORKSH ART I, P3; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Troyanskaya OG, 2003, P NATL ACAD SCI USA, V100, P8348, DOI 10.1073/pnas.0832373100; Van Holsbeke C, 2007, CLIN CANCER RES, V13, P4440, DOI 10.1158/1078-0432.CCR-06-2958; Vastrik I, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-3-r39; Yellaboina S, 2007, GENOME RES, V17, P527, DOI 10.1101/gr.5900607; Zhong WW, 2006, SCIENCE, V311, P1481, DOI 10.1126/science.1123287; ENTREZ GENE DATABASE	46	9	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	MAR 15	2010	26	6					807	813		10.1093/bioinformatics/btq044		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	564UO	WOS:000275243500014	
J	Gupta, KK; Nath, B; Kotagiri, R				Gupta, Kapil Kumar; Nath, Baikunth; Kotagiri, Ramamohanarao			Layered Approach Using Conditional Random Fields for Intrusion Detection	IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING			English	Article						Intrusion detection; Layered Approach; Conditional Random Fields; network security; decision trees; naive Bayes	MODELS	Intrusion detection faces a number of challenges; an intrusion detection system must reliably detect malicious activities in a network and must perform efficiently to cope with the large amount of network traffic. In this paper, we address these two issues of Accuracy and Efficiency using Conditional Random Fields and Layered Approach. We demonstrate that high attack detection accuracy can be achieved by using Conditional Random Fields and high efficiency by implementing the Layered Approach. Experimental results on the benchmark KDD '99 intrusion data set show that our proposed system based on Layered Conditional Random Fields outperforms other well-known methods such as the decision trees and the naive Bayes. The improvement in attack detection accuracy is very high, particularly, for the U2R attacks (34.8 percent improvement) and the R2L attacks (34.5 percent improvement). Statistical Tests also demonstrate higher confidence in detection accuracy for our method. Finally, we show that our system is robust and is able to handle noisy data without compromising performance.	[Gupta, Kapil Kumar] Univ Melbourne, Dept Comp Sci & Software Engn, Parkville, Vic 3010, Australia; Univ Melbourne, NICTA Victoria Res Lab, Parkville, Vic 3010, Australia	Gupta, KK (reprint author), Univ Melbourne, Dept Comp Sci & Software Engn, Parkville, Vic 3010, Australia.	kgupta@csse.unimelb.edu.au; bnath@csse.unimelb.edu.au; rao@csse.unimelb.edu.au					Abraham T., 2008, IDDM INTRUSION DETEC; Agrawal R., 1993, P 1993 ACM SIGMOD IN, V22, P207, DOI DOI 10.1145/170035.170072.ACCESSED; Amor N. B., 2004, P 2004 ACM S APPL CO, P420, DOI 10.1145/967900.967989; Anderson J.P., 2010, COMPUTER SECURITY TH; Bace R., 2001, INTRUSION DETECTION; Boughaci Dalila, 2006, P INT C DEP COMP SYS, P248; Bouzida Y, 2004, INT FED INFO PROC, V147, P241; Debar H., 1992, Proceedings. 1992 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.92CH3157-5), DOI 10.1109/RISP.1992.213257; Dietterich T.G., 2002, LECT NOTES COMPUTER, P15; Dokas Paul, 2002, P NSF WORKSH NEXT GE, P21; Du Y., 2004, P 5 WORLD C INT CONT, V5, P4348; Dzeroski S., 2002, P 19 INT C MACH LEAR, P123; ERTOZ L, 2003, P SPIE BATTLESPACE D, V3, P51; Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675; Gu Y., 2005, P 5 ACM SIGCOMM C IN, P345; gupta K., 2007, P 21 INT C ADV INF N, P203; GUPTA KK, 2006, INT J COMPUTER SCI N, V6, P151; Gupta KK, 2006, LECT NOTES COMPUT SC, V3975, P285; Ji CY, 1997, IEEE T NEURAL NETWOR, V8, P32; KIM DS, 2003, P INF NETW NETW TECH, P747; KLEIN D, 2002, P ACL C EMP METH NAT, V10, P9, DOI 10.3115/1118693.1118695; Kruegel C., 2003, Proceedings. 19th Annual Computer Security Applications Conference; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282; Lee W, 1998, PROCEEDINGS OF THE SEVENTH USENIX SECURITY SYMPOSIUM, P79; Lee W., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Lee W, 1999, P IEEE S SECUR PRIV, P120; McCallum A., 2000, P 17 INT C MACH LEAR, P591; McCallum A., 2003, P 19 C UNC ART INT U, P403; MCCALLUM AK, 2010, MALLET MACHINE LEARN; Portnoy L., 2001, P ACM WORKSH DAT MIN; Ratnaparkhi A., 1996, P C EMP METH NAT LAN, P133; Sabhnani M., 2003, Proceedings of the International Conference on Machine Learning; Models, Technologies and Applications. MLMTA'03; *SANS I, 2010, INTR DET FAQ; Shah H., 2003, P 12 IEEE INT C FUZZ, V2, P1274; SUTTON C., 2006, INTRO STAT RELATIONA; Tombini E., 2004, Proceedings. 20th Annual Computer Security Applications Conference; Wang W., 2004, P 2004 INT C MACH LE, V5, P2830; Warrender C, 1999, P IEEE S SECUR PRIV, P133, DOI 10.1109/SECPRI.1999.766910; Witten IH, 2005, DATA MINING PRACTICA; WU Y, 2003, P 19 ANN COMP SEC AP, P234; Zhang J, 2001, CHINESE J ASTRON AST, V1, P85; 2002, OVERVIEW ATTACK TREN; 2010, CRF YET ANOTHER CRF; 2010, PROBABILISTIC AGENT; 2010, AUTONOMOUS AGENTS IN; 2010, KDD CUP 1999 INTRUSI	46	9	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5971			IEEE T DEPEND SECURE	IEEE Trans. Dependable Secur. Comput.	JAN-MAR	2010	7	1					35	49		10.1109/TDSC.2008.20		15	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	551FY	WOS:000274193600005	
J	Mengle, SSR; Goharian, N				Mengle, Saket S. R.; Goharian, Nazli			Ambiguity Measure Feature-Selection Algorithm	JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article							TEXT CATEGORIZATION	With the increasing number of digital documents, the ability to automatically classify those documents both efficiently and accurately is becoming more critical and difficult. One of the major problems in text classification is the high dimensionality of feature space. We present the ambiguity measure (AM) feature-selection algorithm, which selects the most unambiguous features from the feature set. Unambiguous features are those features whose presence in a document indicate a strong degree of confidence that a document belongs to only one specific category. We apply AM feature selection on a naive Bayes text classifier. We favorably show the effectiveness of our approach in outperforming eight existing feature-selection methods, using five benchmark datasets with a statistical significance of at least 95% confidence. The support vector machine (SVM) text classifier is shown to perform consistently better than the naiive Bayes text classifier. The drawback, however, is the time complexity in training a model. We further explore the effect of using the AM feature-selection method on an SVM text classifier. Our results indicate that the training time for the SVM algorithm can be reduced by more than 50%, while still improving the accuracy of the text classifier. We favorably show the effectiveness of our approach by demonstrating that it statistically significantly (99% confidence) outperforms eight existing feature-selection methods using four standard benchmark datasets.	[Mengle, Saket S. R.; Goharian, Nazli] IIT, Informat Retrieval Lab, Chicago, IL 60616 USA	Mengle, SSR (reprint author), IIT, Informat Retrieval Lab, Chicago, IL 60616 USA.	saket@ir.iit.edu; nazli@ir.iit.edu					Breiman L., 1984, CLASSIFICATION REGRE; Chang C.C., 2001, LIBSVM LIB SUPPORT V; CHIH H, 2004, P 2004 IEEE WIC ACM, P599; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Debole F., 2003, P SAC 03 18 ACM S AP, P784; Forman G., 2008, P ACM C INF KNOWL MA, P263, DOI 10.1145/1458082.1458119; Forman G., 2004, P 21 INT C MACH LEAR, P38; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Galavotti L, 2000, LECT NOTES COMPUT SC, V1923, P59; Grossman D.a., 1998, INFORM RETRIEVAL ALG; Hersh W., 1994, P 17 ANN INT ACM SIG, P192; Joachims T., 1998, P ECML 98 10 EUR C M, V1398, P137; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Lavelli A, 2004, P 13 ACM INT C INF K, P615, DOI 10.1145/1031171.1031284; Lewis D. D., 1991, P SPEECH NAT LANG WO, P312, DOI 10.3115/112405.112471; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; MENGLE S, 2007, IEEE 5 INT C INT SEC, P308; MENGLE S, 2008, P 23 ACM ANN S APPL, P916, DOI 10.1145/1363686.1363896; Michie D., 1994, MACHINE LEARNING NEU; MLADENIC D, 1998, C AUT LEARN DISC CON; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Mladenic D., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009034; Novovicova J, 2005, IEEE IJCNN, P3272; Porter M.F., 1997, READINGS INFORM RETR, P313; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rennie J, 2003, P 20 INT C MACH LEAR, P616; Schwartz Ariel S, 2003, Pac Symp Biocomput, P451; Shang WQ, 2007, EXPERT SYST APPL, V33, P1, DOI 10.1016/j.eswa.2006.04.001; Urbain J., 2007, IEEE 7 S BIOINF BIOE, P1313; WU S, 2002, P ECML PKDD 02 WORKS, P156; Yan J., 2005, P 28 ANN INT ACM SIG, P122, DOI 10.1145/1076034.1076058; Yang Y. M., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; Yang Y, 2003, P 26 ANN INT ACM SIG, P96; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Yi Liu, 2005, Proceedings of the International Joint Conference on Neural Networks 2005 (IEEE Cat. No. 05CH37663C)	35	9	9	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1532-2882			J AM SOC INF SCI TEC	J. Am. Soc. Inf. Sci. Technol.	MAY	2009	60	5					1037	1050		10.1002/asi.21023		14	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	436NL	WOS:000265420700012	
J	Long, N; Gianola, D; Rosa, GJM; Weigel, KA; Avendano, S				Long, Nanye; Gianola, Daniel; Rosa, Guilherme J. M.; Weigel, Kent A.; Avendano, Santiago			Comparison of classification methods for detecting associations between SNPs and chick mortality	GENETICS SELECTION EVOLUTION			English	Article							GENOMIC-ASSISTED PREDICTION; GENE-EXPRESSION; NEURAL NETWORKS; SELECTING SNPS; BROILERS; MODEL	Multi-category classification methods were used to detect SNP-mortality associations in broilers. The objective was to select a subset of whole genome SNPs associated with chick mortality. This was done by categorizing mortality rates and using a filter-wrapper feature selection procedure in each of the classification methods evaluated. Different numbers of categories (2, 3, 4, 5 and 10) and three classification algorithms (naive Bayes classifiers, Bayesian networks and neural networks) were compared, using early and late chick mortality rates in low and high hygiene environments. Evaluation of SNPs selected by each classification method was done by predicted residual sum of squares and a significance test-related metric. A naive Bayes classifier, coupled with discretization into two or three categories generated the SNP subset with greatest predictive ability. Further, an alternative categorization scheme, which used only two extreme portions of the empirical distribution of mortality rates, was considered. This scheme selected SNPs with greater predictive ability than those chosen by the methods described previously. Use of extreme samples seems to enhance the ability of feature selection procedures to select influential SNPs in genetic association studies.	[Long, Nanye; Gianola, Daniel] Univ Wisconsin, Dept Anim Sci, Madison, WI 53706 USA; [Gianola, Daniel; Rosa, Guilherme J. M.; Weigel, Kent A.] Univ Wisconsin, Dept Dairy Sci, Madison, WI 53706 USA; [Avendano, Santiago] Aviagen Ltd, Newbridge EH28 8SZ, Midlothian, Scotland	Long, N (reprint author), Univ Wisconsin, Dept Anim Sci, Madison, WI 53706 USA.	nlong@wisc.edu; gianola@ansci.wisc.edu; grosa@wisc.edu; kweigel@wisc.edu; savendano@aviagen.com	Rosa, Guilherme/G-3862-2011		Wisconsin Agriculture Experiment Station;  [NRICGP/USDA2003-35205-12833];  [NSF DEB-0089742];  [NSF DMS044371]	Acknowledgements Support by the Wisconsin Agriculture Experiment Station, and by grants NRICGP/USDA2003-35205-12833, NSF DEB-0089742 and NSF DMS044371 is acknowledged. Prof. William G. Hill is thanked for suggesting the permutation test employed for generating the null distribution of PRESS values.	BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Blakey JD, 2007, THORAX, V62, P196, DOI 10.1136/thx.2006.070649; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Caruana R., 1994, INT C MACH LEARN, P28; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cordell HJ, 2002, AM J HUM GENET, V70, P124, DOI 10.1086/338007; Dekkers JCM, 2002, NAT REV GENET, V3, P22, DOI 10.1038/nrg701; Domingos P., 1996, INT C MACH LEARN, P105; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Gianola D, 2006, GENETICS, V173, P1761, DOI 10.1534/genetics.105.049510; Gianola D, 2008, GENETICS, V178, P2289, DOI 10.1534/genetics.107.084285; Gianola D, 2003, GENETICS, V163, P347; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Helman P, 2004, J COMPUT BIOL, V11, P581, DOI 10.1089/1066527041887294; Hoh J, 2000, ANN HUM GENET, V64, P413, DOI 10.1046/j.1469-1809.2000.6450413.x; JENSEN F, 2001, BAYESIAN NETWORKS DE; Kelemen A, 2003, IEEE IJCNN, P1769; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kohavi R, 1997, ARTIF INTELL, V1, P273; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Long N, 2007, J ANIM BREED GENET, V124, P377; Long N, 2008, J ANIM SCI, V86, P3358, DOI 10.2527/jas.2008-1021; LUNETTA K, 2004, BMC GENET, V5, P5; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Maier LM, 2006, J ALLERGY CLIN IMMUN, V117, P1306, DOI 10.1016/j.jaci.2005.12.1354; Meuwissen THE, 2001, GENETICS, V157, P1819; Mitchell T.M., 1997, MACHINE LEARNING; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Ruppert D, 2003, SEMIPARAMETRIC REGRE; Russell S. J., 2002, ARTIFICIAL INTELLIGE; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Sebastiani P, 2005, NAT GENET, V37, P435, DOI 10.1038/ng1533; Strobl C, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-307; Vapnik V., 2000, NATURE STAT LEARNING; Wang H, 2005, GENETICS, V170, P465, DOI 10.1534/genetics.104.039354; Warner B, 1996, AM STAT, V50, P284, DOI 10.2307/2684922; Witten IH, 2005, DATA MINING PRACTICA; Xu SZ, 2003, GENETICS, V163, P789	38	9	9	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	0999-193X			GENET SEL EVOL	Genet. Sel. Evol.	JAN 23	2009	41								18	10.1186/1297-9686-41-18		14	Agriculture, Dairy & Animal Science; Genetics & Heredity	Agriculture; Genetics & Heredity	438KP	WOS:000265554600001	
J	Armutlu, P; Ozdemir, ME; Uney-Yuksektepe, F; Kavakli, IH; Turkay, M				Armutlu, Pelin; Ozdemir, Muhittin E.; Uney-Yuksektepe, Fadime; Kavakli, I. Halil; Turkay, Metin			Classification of drug molecules considering their IC(50) values using mixed-integer linear programming based hyper-boxes method	BMC BIOINFORMATICS			English	Article							SELECTIVE CYCLOOXYGENASE-2 INHIBITORS; DIHYDROFOLATE-REDUCTASE; NEURAL-NETWORK; ACETYLCHOLINESTERASE INHIBITORS; PNEUMOCYSTIS-CARINII; DERIVATIVES; DESCRIPTOR; CHEMISTRY; PROTEINS; DESIGN	Background: A priori analysis of the activity of drugs on the target protein by computational approaches can be useful in narrowing down drug candidates for further experimental tests. Currently, there are a large number of computational methods that predict the activity of drugs on proteins. In this study, we approach the activity prediction problem as a classification problem and, we aim to improve the classification accuracy by introducing an algorithm that combines partial least squares regression with mixed-integer programming based hyper-boxes classification method, where drug molecules are classified as low active or high active regarding their binding activity (IC(50) values) on target proteins. We also aim to determine the most significant molecular descriptors for the drug molecules. Results: We first apply our approach by analyzing the activities of widely known inhibitor datasets including Acetylcholinesterase (ACHE), Benzodiazepine Receptor (BZR), Dihydrofolate Reductase (DHFR), Cyclooxygenase-2 (COX-2) with known IC(50) values. The results at this stage proved that our approach consistently gives better classification accuracies compared to 63 other reported classification methods such as SVM, Naive Bayes, where we were able to predict the experimentally determined IC50 values with a worst case accuracy of 96%. To further test applicability of this approach we first created dataset for Cytochrome P450 C17 inhibitors and then predicted their activities with 100% accuracy. Conclusion: Our results indicate that this approach can be utilized to predict the inhibitory effects of inhibitors based on their molecular descriptors. This approach will not only enhance drug discovery process, but also save time and resources committed.	[Armutlu, Pelin; Uney-Yuksektepe, Fadime; Turkay, Metin] Koc Univ, Dept Ind Engn, TR-34450 Istanbul, Turkey; [Ozdemir, Muhittin E.; Kavakli, I. Halil; Turkay, Metin] Koc Univ, Ctr Computat Biol & Bioinformat, TR-34450 Istanbul, Turkey; [Kavakli, I. Halil] Koc Univ, Dept Biol & Chem Engn, TR-34450 Istanbul, Turkey	Turkay, M (reprint author), Koc Univ, Dept Ind Engn, TR-34450 Istanbul, Turkey.	parmutlu@ku.edu.tr; muhozdemir@ku.edu.tr; funey@ku.edu.tr; hkavakli@ku.edu.tr; mturkay@ku.edu.tr	Turkay, Metin/F-9769-2011; Uney-Yuksektepe, Fadime/A-4293-2014	Turkay, Metin/0000-0003-4769-6714; Uney-Yuksektepe, Fadime/0000-0002-8068-5235	IBM SUR Award; Turkish National Academy of Science of Turkey	The computing hardware support from IBM SUR Award is gratefully acknowledged. IHK thanks for the support of Turkish National Academy of Science of Turkey for young investigator program (TUBA-GEBIP).	Aksyonova T.I., 2003, SAMS, V43, P1331, DOI 10.1080/02329290290024330; BROUGHTON MC, 1991, ANTIMICROB AGENTS CH, V35, P1348; Carter JS, 1999, BIOORG MED CHEM LETT, V9, P1167, DOI 10.1016/S0960-894X(99)00158-4; *CHEMAXON, 2005, MARV 4 1 7; CHENG J, 1999, COMPARING BAYESIAN N; Clement OO, 2003, J MED CHEM, V46, P2345, DOI 10.1021/jm020576u; COLLEGE MIS, 2003, MINITAB STAT SOFTWAR; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; Ferguson AM, 1997, J COMPUT AID MOL DES, V11, P143, DOI 10.1023/A:1008026308790; Gangjee A, 2001, BIOORGAN MED CHEM, V9, P2929, DOI 10.1016/S0968-0896(01)00223-1; Gangjee A, 1998, J MED CHEM, V41, P1409, DOI 10.1021/jm9705420; GARTHWAITE PH, 1994, J AM STAT ASSOC, V89, P122, DOI 10.2307/2291207; GOLENDER VE, 1993, 3D QSAR DRUG DESIGN, P137; Haefely W, 1985, ADV DRUG RES, V14, P165; Handratta VD, 2005, J MED CHEM, V48, P2972, DOI 10.1021/jm040202w; HUANG HC, 1995, BIOORG MED CHEM LETT, V5, P2377, DOI 10.1016/0960-894X(95)00414-O; Klebe G, 1999, J COMPUT AID MOL DES, V13, P1, DOI 10.1023/A:1008047919606; LANDWEHR N, 2003, 14 EUR C MACH LEARN; PINARDAN PJ, 1998, ADV KERNEL METHODS S; Plewczynski D, 2006, J CHEM INF MODEL, V46, P1098, DOI 10.1021/ci050519k; ROSOWSKY A, 1995, ANTIMICROB AGENTS CH, V39, P79; SUGIMOTO H, 1995, J MED CHEM, V38, P4821, DOI 10.1021/jm00024a009; SUGIMOTO H, 1990, J MED CHEM, V33, P1880, DOI 10.1021/jm00169a008; SUGIMOTO H, 1992, J MED CHEM, V35, P4542, DOI 10.1021/jm00102a005; Sutherland JJ, 2004, J MED CHEM, V47, P5541, DOI 10.1021/jm0497141; TAX D, 2002, 16 INT C PATT REC QU, V2, P124; Tetko IV, 2002, NEURAL PROCESS LETT, V16, P187, DOI 10.1023/A:1019903710291; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P717, DOI 10.1021/ci010379o; Tetko IV, 2005, DRUG DISCOV TODAY, V10, P1497, DOI 10.1016/S1359-6446(05)03584-1; Tetko IV, 2000, SAR QSAR ENVIRON RES, V11, P263, DOI 10.1080/10629360008033235; Todeschini R., 2000, HDB MOL DESCRIPTORS; Turner DB, 2000, EUR J MED CHEM, V35, P367, DOI 10.1016/S0223-5234(00)00141-0; Uney F, 2006, EUR J OPER RES, V173, P910, DOI 10.1016/j.ejor.2005.04.049; Whitley DC, 2000, J CHEM INF COMP SCI, V40, P1160, DOI 10.1021/ci000384c; Witten IH, 2005, DATA MINING PRACTICA; Yuksektepe FU, 2008, COMPUT CHEM ENG, V32, P78, DOI 10.1016/j.compchemeng.2007.07.002	37	9	10	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	OCT 3	2008	9								411	10.1186/1471-2105-9-411		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	366NO	WOS:000260489400002	
J	Hong, JH; Cho, SB				Hong, Jin-Hyuk; Cho, Sung-Bae			A probabilistic multi-class strategy of one-vs.-rest support vector machines for cancer classification	NEUROCOMPUTING			English	Article; Proceedings Paper	13th International Conference on Neural Informational Processing	OCT 03-06, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, K C Wong Educ Fdn		Support vector machines; Multi-class cancer classification; Naive Bayes classifiers; Fusion method	GENE-EXPRESSION DATA; MULTICATEGORY CLASSIFICATION; ALGORITHMS; PREDICTION; DIAGNOSIS; DISCOVERY; SELECTION; SURVIVAL	Support vector machines (SVMs), originally designed for binary classification, have been applied for multi-class classification with effective decomposition and reconstruction schemes. Decomposition schemes such as one-vs.-rest (OVR) and pair-wise partition a dataset into several subsets of two classes so as to produce multiple outputs that should be combined. Majority voting or winner-takes-all is a representative reconstruction scheme to combine those outputs, but it often causes some problems to consider tie-breaks and tune the weights of individual classifiers. in this paper, we propose a novel method in which SVMs are generated with the OVR scheme and probabilistically ordered by using the naive Bayes classifiers (NBs). This method is able to break ties that frequently occur when working with multi-class classification systems with OVR SVMs. More specifically, we use the Pearson correlation to select informative genes and reduce the dimensionality of gene expression profiles when constructing the NBs. The proposed method has been validated on several popular multi-class cancer datasets and produced higher accuracy than conventional methods. (C) 2008 Elsevier B.V. All rights reserved.	[Hong, Jin-Hyuk; Cho, Sung-Bae] Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea	Cho, SB (reprint author), Yonsei Univ, Dept Comp Sci, 134 Shinchon Dong, Seoul 120749, South Korea.	hjinh@sclab.yonsei.ac.kr; sbcho@cs.yonsei.ac.kr					Angulo C, 2003, NEUROCOMPUTING, V55, P57, DOI 10.1016/S0925-2312(03)00435-1; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Bredensteiner EJ, 1999, COMPUT OPTIM APPL, V12, P53, DOI 10.1023/A:1008663629662; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; Cho SB, 2002, P IEEE, V90, P1744, DOI 10.1109/JPROC.2002.804682; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; GESTEL T, 2002, NEURAL PROCESS LETT, V15, P45; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Inza I, 2001, ARTIF INTELL MED, V23, P187, DOI 10.1016/S0933-3657(01)00085-9; Koo JY, 2006, BIOINFORMATICS, V22, P950, DOI 10.1093/bioinformatics/btl029; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Liu JJ, 2005, BIOINFORMATICS, V21, P2691, DOI 10.1093/bioinformatics/bti419; Liu JNK, 2001, IEEE T SYST MAN CY C, V31, P249, DOI 10.1109/5326.941848; Nutt CL, 2003, CANCER RES, V63, P1602; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; POMEROY S, 2002, NATURE, V415, P437; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Sebald DJ, 2001, IEEE T SIGNAL PROCES, V49, P2865, DOI 10.1109/78.960434; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; Yeang C. H., 2001, BIOINFORMATICS, V17, P316	25	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	OCT	2008	71	16-18			SI		3275	3281		10.1016/j.neucom.2008.04.033		7	Computer Science, Artificial Intelligence	Computer Science	360OF	WOS:000260066100027	
J	Hsu, CC; Huang, YP; Chang, KW				Hsu, Chung-Chian; Huang, Yan-Ping; Chang, Keng-Wei			Extended Naive Bayes classifier for mixed data	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Naive Bayes classifier; classification; mixed data		Naive Bayes induction algorithm is very popular in classification field. Traditional method for dealing with numeric data is to discrete numeric attributes data into symbols. The difference of distinct discredited criteria has significant effect on performance. Moreover, several researches had recently employed the normal distribution to handle numeric data, but using only one value to estimate the population easily leads to the incorrect estimation. Therefore, the research for classification of mixed data using Naive Bayes classifiers is not very successful. In this paper, we propose a classification method, Extended Naive Bayes (ENB), which is capable for handling mixed data. The experimental results have demonstrated the efficiency of our algorithm in comparison with other classification algorithms ex. CART, DT and MLP's. (C) 2007 Elsevier Ltd. All rights reserved.	[Hsu, Chung-Chian; Huang, Yan-Ping; Chang, Keng-Wei] Natl Yunlin Univ Sci & Technol, Dept Informat Management, Douliu Yunlin 640, Taiwan; [Huang, Yan-Ping] Chin Min Inst Technol, Dept Informat Management, TouFen 351, Miao Li, Taiwan	Huang, YP (reprint author), Natl Yunlin Univ Sci & Technol, Dept Informat Management, 123,Sect 3,Univ Rd, Douliu Yunlin 640, Taiwan.	hsucc@mis.yuntech.edu.tw; sunny@chinmin.edu.tw; g9120817@yuntech.edu.tw					Breiman L., 1984, CLASSIFICATION REGRE; Duda R., 1973, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GREINER R, 1997, P 13 C UNC ART INT S, P198; Kontkanen P., 2001, P 17 C UNC ART INT S, P277; LANGLEY P, 1992, P INT C ART INT; MERZ CJ, 1996, UCI REPOSITORY ML DA; NG A, 2001, ADV NEURAL INFORMATI, V14, P605; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Simon H., 1999, NEURAL NETWORKS COMP; VOORHEES EM, 2000, 8 TEXT RETR C TREC 8	12	9	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	OCT	2008	35	3					1080	1083		10.1016/j.eswa.2007.08.031		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	331DU	WOS:000257993700049	
J	Zhang, M; Wong, P				Zhang, Mengjie; Wong, Phillip			Genetic programming for medical classification: a program simplification approach	GENETIC PROGRAMMING AND EVOLVABLE MACHINES			English	Article						genetic programming; program simplification; medical classification; algebraic equivalence hashing techniques	NEURAL NETWORKS	This paper describes a genetic programming (GP) approach to medical data classification problems. In this approach, the evolved genetic programs are simplified online during the evolutionary process using algebraic simplification rules, algebraic equivalence and prime techniques. The new simplification GP approach is examined and compared to the standard GP approach on two medical data classification problems. The results suggest that the new simplification GP approach can not only be more efficient with slightly better classification performance than the basic GP system on these problems, but also significantly reduce the sizes of evolved programs. Comparison with other methods including decision trees, naive Bayes, nearest neighbour, nearest centroid, and neural networks suggests that the new GP approach achieved superior results to almost all of these methods on these problems. The evolved genetic programs are also easier to interpret than the "hidden patterns" discovered by the other methods.	[Zhang, Mengjie; Wong, Phillip] Victoria Univ Wellington, Sch Math Stat & Comp Sci, Wellington, New Zealand	Zhang, M (reprint author), Victoria Univ Wellington, Sch Math Stat & Comp Sci, POB 600, Wellington, New Zealand.	mengjie@mcs.vuw.ac.nz; phillip@mcs.vuw.ac.nz					Abbass HA, 2002, ARTIF INTELL MED, V25, P265, DOI 10.1016/S0933-3657(02)00028-3; ASHLOCK W, 2005, SINGLE PARENT GENETI, V2, P1172; Banzhaf W., 1998, GENETIC PROGRAMMING; Blickle T., 1994, GENETIC ALGORITHMS F, P33; BOJARCZUK C, 1999, DISCOVERING COMPREHE, P953; Bojarczuk CC, 2004, ARTIF INTELL MED, V30, P27, DOI 10.1016/j.artmed.2003.06.001; BRAMEIER M, 1998, 4398 CI DORTM U; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; CHEROWITZO B, 2006, LECT NOTES; Ekart A, 2000, LECT NOTES COMPUT SC, V1829, P73; FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5; FRIEDBERG RM, 1958, IBM J RES DEV, V2, P2; GONNET GH, 1984, STOC 84, P334; GRAY H, 1997, GEN PROGR C, P291; Gustafson S., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030194.98244.e3; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOOPER D, 1996, IMPROVING ACCURACY R, P428; JACKSON D, 2005, FITNESS EVALUATION A, V3, P2530; Koza J., 1992, GENETIC PROGRAMMING; Koza John R., 1992, GENETIC PROGRAMMING; Langdon W. B., 2000, P GEN EV COMP C GECC, P451; LANGDON WB, 1997, FITNESS CAUSES BLOAT, P13; LANGDON WB, 1998, LNCS, V1391, P37; Lidl R., 1986, INTRO FINITE FIELDS; LOVEARD T, 2001, P C EV COMP, V2, P1070, DOI 10.1109/CEC.2001.934310; LUKE S, 2002, LEXICOGRAPHIC PARSIM, P829; MADDEN MG, 2002, CSLG0211003 CORR; MALLINSON H, 1999, COMPUTATIONAL INTEGR, V1; Mangasarian O. L., 1990, SIAM NEWS, V23; MARTIN WA, 1971, J ACM, V18, P549, DOI 10.1145/321662.321668; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Mitchell T.M., 1997, MACHINE LEARNING; Newman DJ, 1998, UCI REPOSITORY MACHI; NORDIN P, 1995, EXPLICITLY DEFINED I, P6; NORDIN P, 1995, COMPLEXITY COMPRESSI, P310; PARPINELLI RS, 2001, ANT COLONY BASED SYS, P791; PARROTT D, 2005, MULTIOBJECTIVE TECHN, V2, P1141; PENAREYES CA, 2001, APPL FUZZY COCO BREA; PISZCZ A, 2006, DYNAMICS EVOLUTIONAR, V1, P871; PODGORELEC V, 1999, MED DIAGNOSIS PREDIC, P394; Poli R., 1996, Genetic Programming. Proceedings of the First Annual Conference 1996; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RUMELHART D, 1986, LEARNING INTERNAL RE, V1; Smith JF, 2004, LECT NOTES COMPUT SC, V3177, P464; Smith MG, 2003, LECT NOTES COMPUT SC, V2610, P229; SOULE T, 1996, CODE GROWTH GENETIC, P215; Soule T, 1998, EVOL COMPUT, V6, P293, DOI 10.1162/evco.1998.6.4.293; Streeter MJ, 2003, LECT NOTES COMPUT SC, V2610, P443; TACKETT WAS, 1993, GENETIC PROGRAMMING, P303; TRAPPE W, 2006, INTRO CRYPTOGRAPY CO; Tsakonas A, 2004, ARTIF INTELL MED, V32, P195, DOI 10.1016/j.artmed.2004.02.007; WINKLER S, 2005, P FH SCI DAY 2005, P3; WINKLER SM, 2006, USING ENHANCED GENET; ZELL A, 1995, SNNS USER MANUAL VER; Zhang BT, 1995, EVOL COMPUT, V3, P17, DOI 10.1162/evco.1995.3.1.17; ZHANG M, 2003, EURASIP J SIGNAL PRO, P841; Zhang MJ, 1999, LECT NOTES ARTIF INT, V1747, P180; ZHANG M, LNCS, V3005, P379; Zhang MJ, 2005, LECT NOTES ARTIF INT, V3683, P988; ZHONG X, 2006, GROWTH SELF CANCELIN, V1, P223	60	9	9	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1389-2576			GENET PROGRAM EVOL M	Genet. Program. Evol. Mach.	SEP	2008	9	3					229	255		10.1007/s10710-008-9059-9		27	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	323IW	WOS:000257440800004	
J	Chiang, JH; Ho, SH				Chiang, Jung-Hsien; Ho, Shing-Hua			A combination of rough-based feature selection and RBF neural network for classification using gene expression data	IEEE TRANSACTIONS ON NANOBIOSCIENCE			English	Article						information gain (IG); microarray data; principle component analysis; radial basis function (RBF) neural network; rough-based feature selection	MICROARRAY DATA; K-MEANS; CANCER; PATTERNS; PREDICTION; MACHINES	This paper presents a novel rough-based feature selection method for gene expression data analysis. It can find the relevant features without requiring the number of clusters to be known a priori and identify the centers that approximate to the correct ones. In this paper, we attempt to introduce a prediction scheme that combines the rough-based feature selection method with radial basis function neural network. For further consider the effect of different feature selection methods and classifiers on this prediction process, we use the Naive Bayes and linear support vector machine as classifiers, and compare the performance with other feature selection methods, including information gain and principle component analysis. We demonstrate the performance by several published datasets and the results show that our proposed method can achieve high classification accuracy rate.	[Chiang, Jung-Hsien; Ho, Shing-Hua] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan	Chiang, JH (reprint author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.	jchiang@mail.ncku.edu.tw; hosh@cad.csie.ncku.edu.tw					Abido MA, 1997, IEEE T POWER SYST, V12, P1500, DOI 10.1109/59.627848; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ben-Dor A, 1999, P 3 ANN INT C COMP M, P33, DOI 10.1145/299432.299448; BLUM A, 1997, ARTIF INTELL, V1, P245; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; DING C, P RECOMB 2002, P127; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; do Prado HA, 2002, LECT NOTES ARTIF INT, V2475, P234; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; GIROSI F, 1994, NATO ASI F, V136, P166; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; GUH L, 2004, P 2 AS PAC BIOINF C, P161; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hartuv E, 1999, P 3 ANN INT C COMP M, P188, DOI 10.1145/299432.299483; Haykin S., 1999, NEURAL NETWORKS COMP; Haykin S., 1998, NEURAL NETWORKS COMP; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, P 13 INT C MACH LEAR, P284; Langley P., 1994, P AAAI FALL S REL, P140; Li F, 2005, BIOINFORMATICS, V21, P3741, DOI 10.1093/bioinformatics/bti618; LI J, 2003, BIOINFORMATICS, V19, P1061; Lingras P., 2004, Journal of Intelligent Systems, V13; Lingras P, 2004, J INTELL INF SYST, V23, P5, DOI 10.1023/B:JIIS.0000029668.88665.1a; Mitchell T.M., 1997, MACHINE LEARNING; Mitra S., 2003, DATA MINING MULTIMED; O'Neill M, 2003, GENET PROGR SER, V4, P1; Park JW, 2004, IEEE T NEURAL NETWOR, V15, P460, DOI 10.1109/TNN.2004.824260; Pawlak Z, 1982, INT J INFORMATION CO, V11, P145; Pawlak Z., 1992, ROUGH SETS THEORETIC; Peters G, 2006, PATTERN RECOGN, V39, P1481, DOI 10.1016/j.patcog.2006.02.002; Raychaudhuri S, 2000, PAC S BIOCOMPUT, V5, P452; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tang Y., 2005, P 5 IEEE S BIOINF BI, P290; Tavazoie S, 1999, NAT GENET, V22, P281; Vapnik V., 1995, NATURE STAT LEARNING; Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731; Voges KE, 2003, P AUSTR NZ MARK AC C, P1625; YAO YY, 1994, P 3 INT WORKSH ROUGH, P630; Zimmermann H. J., 2001, FUZZY SET THEORY ITS	45	9	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1536-1241			IEEE T NANOBIOSCI	IEEE Trans. Nanobiosci.	MAR	2008	7	1					91	99		10.1109/TNB.2008.2000142		9	Biochemical Research Methods; Nanoscience & Nanotechnology	Biochemistry & Molecular Biology; Science & Technology - Other Topics	272QB	WOS:000253873400011	
J	Calvo, B; Larranaga, P; Lozano, JA				Calvo, Boria; Larranaga, Pedro; Lozano, Jose A.			Learning Bayesian classifiers from positive and unlabeled examples	PATTERN RECOGNITION LETTERS			English	Article						positive unlabeled learning; Bayesian classifiers; naive Bayes; tree augmented naive Bayes; Bayesian approach	ALGORITHM	The positive unlabeled learning term refers to the binary classification problem in the absence of negative examples. When only positive and unlabeled instances are available, semi-supervised classification algorithms cannot be directly applied, and thus new algorithms are required. One of these positive unlabeled learning algorithms is the positive naive Bayes (PNB), which is an adaptation of the naive Bayes induction algorithm that does not require negative instances. In this work we propose two ways of enhancing this algorithm. On one hand, we have taken the concept behind PNB one step further, proposing a procedure to build more complex Bayesian classifiers in the absence of negative instances. We present a new algorithm (named positive tree augmented naive Bayes, PTAN) to obtain tree augmented naive Bayes models in the positive unlabeled domain. On the other hand, we propose a new Bayesian approach to deal with the a priori probability of the positive class that models the uncertainty over this parameter by means of a Beta distribution. This approach is applied to both PNB and PTAN, resulting in two new algorithms. The four algorithms are empirically compared in positive unlabeled learning problems based on real and synthetic databases. The results obtained in these comparisons suggest that, when the predicting variables are not conditionally independent given the class, the extension of PNB to more complex networks increases the classification performance. They also show that our Bayesian approach to the a priori probability of the positive class can improve the results obtained by PNB and PTAN. (c) 2007 Elsevier B.V. All rights reserved.	Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, Donostia San Sebastian 20018, Spain	Calvo, B (reprint author), Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, Paseo Manuel Lardizabal 1, Donostia San Sebastian 20018, Spain.	borja.calvo@ehu.es; pedro.larranaga@ehu.es; ja.lozano@ehu.es	Lozano, Jose/F-5120-2010; Calvo, Borja/D-8814-2012; Larranaga, Pedro/F-9293-2013				Bernardo J. M., 1994, BAYESIAN THEORY; Bishop CM, 2006, PATTERN RECOGNITION; Blake C. L., 1998, UCI REPOSITORY MACHI; Calvo B, 2007, COMPUT METH PROG BIO, V85, P229, DOI 10.1016/j.cmpb.2006.12.003; CASTELO R, 2004, BIOINFORMATICS, V4, P169; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DENIS F, 2002, 9 INT C INF PROC MAN, P1927; DENIS F, 2003, P ICML 2003 WORKSH C, P80; Duda R.O., 2001, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Li X., 2003, P 18 INT JOINT C ART, P587; Liu B., 2002, P 19 INT C MACH LEAR, P387; Liu B., 2003, Third IEEE International Conference on Data Mining; MINSKY M, 1961, P IRE, V49, P8, DOI 10.1109/JRPROC.1961.287775; Pearl J., 1988, PROBABILISTIC REASON; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Tax D., 2001, THESIS TU DELFT; Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583; Wang CL, 2006, BIOINFORMATICS, V22, P2590, DOI 10.1093/bioinformatics/btl441; Yu H., 2003, P 2003 ACM CIKM INT, P232	20	9	13	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC 1	2007	28	16					2375	2384		10.1016/j.patrec.2007.08.003		10	Computer Science, Artificial Intelligence	Computer Science	230TW	WOS:000250899800022	
S	Jiang, LX; Wang, DH; Cai, ZH; Yan, XS		Alhajj, R; Gao, H; Li, X; Li, JZ; Zaiane, OR		Jiang, Liangxiao; Wang, Dianhong; Cai, Zhihua; Yan, Xuesong			Survey of improving naive Bayes for classification	Advanced Data Mining and Applications, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	3rd International Conference on Advanced Data Mining and Applications	AUG 06-08, 2007	Harbin, PEOPLES R CHINA	Harbin Inst Technol		bayesian network classifiers; naive Bayes; feature selection; local learning; structure extension; data expansion; classification	CLASSIFIERS	The attribute conditional independence assumption of naive Bayes essentially ignores attribute dependencies and is often violated. On the other hand, although a Bayesian network can represent arbitrary attribute dependencies, learning an optimal Bayesian network classifier from data is intractable. Thus, learning improved naive Bayes has attracted much attention from researchers and presented many effective and efficient improved algorithms. In this paper, we review some of these improved algorithms and single out four main improved approaches: 1) Feature selection; 2) Structure extension; 3) Local learning; 4) Data expansion. We experimentally tested these approaches using the whole 36 UCI data sets selected by Weka, and compared them to naive Bayes. The experimental results show that all these approaches are effective. In the end, we discuss some main directions for future research on Bayesian network classifiers.	China Univ Geosci, Fac Comp Sci, Wuhan 430074, Hubei, Peoples R China	Jiang, LX (reprint author), China Univ Geosci, Fac Comp Sci, Wuhan 430074, Hubei, Peoples R China.		Jiang, Liangxiao /D-1237-2012				Chickering D. M., 1996, LEARNING DATA ARTIFI, VV, P121; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Frank E., 2003, P C UNC ART INT, P249; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Grossman D., 2004, P 21 INT C MACH LEAR, P361; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; JIANG L, 2005, P 17 IEEE INT C TOOL, P412; JIANG L, 2006, PRICAI 2006, V4099, P970; JIANG L, 2006, FSKD 2006, V4223, P365, DOI 10.1007/11881599_41; Jiang LX, 2005, Progress in Intelligence Computation & Applications, P344; Jiang L, 2006, ROM J INF SCI TECH, V9, P163; JIANG L, 2005, P 5 IEEE INT C DAT M, P202; JIANG L, 2006, CANADIAN AI 2006, V4013, P503; Jiang LX, 2005, LECT NOTES ARTIF INT, V3584, P186; Jiang LX, 2005, LECT NOTES COMPUT SC, V3501, P280; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Langley P., 1994, P 10 C UNC ART INT, P339; Langley P., 1992, P 10 NAT C ART INT, P223; LING CX, 2003, P INT JOINT C ART IN; Lowd D, 2005, P 22 INT C MACH LEAR, P529, DOI 10.1145/1102351.1102418; MERZ C, 1997, DEPT ICS U CALIFORNI; Nadeau C., 1999, ADV NEURAL INFORMATI, P307; Pearl J., 1988, PROBABILISTIC REASON; QUINLAN JR, 1993, PROGR MACH LEARN; Ratanamahatana C.A., 2002, P WORKSH DAT CLEAN P; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Witten IH, 2005, DATA MINING PRACTICA; XIE Z, 2002, PAKDD 2002, V2336, P104; Zhang H, 2004, LECT NOTES COMPUT SC, V3201, P501; ZHANG H, 2005, P 22 INT C MACH LEAR, P1025; Zhang H., 2005, P 20 NAT C ART INT, P919; ZHANG H, 2001, PAKDD 2001, V2035, P581; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	35	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-73870-1	LECT NOTES ARTIF INT			2007	4632						134	145				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BGS80	WOS:000250366700013	
S	Senaratne, R; Hardy, D; Vanderaa, B; Halgamuge, S		Liu, DR; Fei, SM; Hou, ZG; Zhang, HG; Sun, CY		Senaratne, Rajinda; Hardy, David; Vanderaa, Bill; Halgamuge, Saman			Driver fatigue detection by fusing multiple cues	ADVANCES IN NEURAL NETWORKS - ISNN 2007, PT 2, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	4th International Symposium on Neural Networks (ISNN 2007)	JUN 03-07, 2007	Nanjing, PEOPLES R CHINA	Natl Nat Sci Fdn China, KC Wong Educ Fdn, SE Univ China, Chinese Univ Hong Kong, Univ Illinois, Chicago			NEURAL-NETWORKS; VIGILANCE	A video-based driver fatigue detection system is presented. The system automatically locates the face in the first frame, and then tracks the eyes in subsequent frames. Four cues which characterises fatigue are used to determine the fatigue level. We used Support Vector Machines to estimate the percentage eye closure, which is the strongest cue. Improved results were achieved by using Support Vector Machines in comparison to Naive Bayes classifier. The performance was further improved by fusing all four cues using fuzzy rules.	Univ Melbourne, Dept Mech & Mfg Engn, Dynam Syst & Control Res Grp, Parkville, Vic 3052, Australia	Senaratne, R (reprint author), Univ Melbourne, Dept Mech & Mfg Engn, Dynam Syst & Control Res Grp, Parkville, Vic 3052, Australia.	senaratne@pgrad.unimelb.edu.au; d.hardy@ugrad.unimelb.edu.au; b.vanderaa@ugrad.unimelb.edu.au; saman@unimelb.edu.au	Halgamuge, Saman/A-8154-2008	Halgamuge, Saman/0000-0002-2536-4930			Baluja S, 2000, INT J PATTERN RECOGN, V14, P1097, DOI 10.1142/S0218001400000672; Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598; Chang C.C., 2001, LIBSVM LIB SUPPORT V; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Halgamuge SK, 1997, IEEE T SIGNAL PROCES, V45, P2766, DOI 10.1109/78.650103; Halgamuge SK, 1998, IEEE T FUZZY SYST, V6, P304, DOI 10.1109/91.669031; HALGAMUGE SK, 1995, INT J NEURAL SYST, V6, P185, DOI 10.1142/S0129065795000147; HALGAMUGE SK, 1995, INT J APPROX REASON, V12, P279, DOI 10.1016/0888-613X(94)00032-X; Ji Q, 2004, IEEE T VEH TECHNOL, V53, P1052, DOI 10.1109/TVT.2004.830974; Kennedy J., 1995, IEEE INT C NEUR NETW, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Lal SKL, 2002, PSYCHOPHYSIOLOGY, V39, P313, DOI 10.1017/S0048577201393095; POPIEUL JC, 2003, USING DRIVERS HEAD M, P616; Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI [10.1109/TEVC.2004.826071, 10.1109/tevc.2004.826071]; Roge J, 2001, ACCIDENT ANAL PREV, V33, P181, DOI 10.1016/S0001-4575(00)00029-4; Senaratne R, 2006, Proceedings of the Seventh International Conference on Automatic Face and Gesture Recognition - Proceedings of the Seventh International Conference, P120; SENARATNE R, 2006, J MULTIMEDIA, V1, P31; Shi Y., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.785511; Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342; STRINGA L, 1993, APPL ARTIF INTELL, V7, P365, DOI 10.1080/08839519308949995	19	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-72392-9	LECT NOTES COMPUT SC			2007	4492						801	809				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BGJ86	WOS:000247831300096	
J	Wu, QX; Bell, D; McGinnity, M				Wu, QX; Bell, D; McGinnity, M			Multiknowledge for decision making	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						classification; decision making; decision system; knowledge representation; multiknowledge; multiple reducts; rough set; uncertain rule	COMPUTATIONAL METHODS; ROUGH SETS; CLASSIFICATION	The representation of knowledge has an important effect on automated decision-making. In this paper, vector spaces are used to describe a condition space and a decision space, and knowledge is represented by a mapping from the condition space to the decision space. Many such mappings can be obtained from a training set. A set of mappings, which are created from multiple reducts in the training set, is defined as multiknowledge. In order to get a good reduct and find multiple reducts, the WADF (worst-attribute-drop-first) algorithm is developed through analysis of the properties of decision systems using rough set theory. An approach that combines multiknowledge and the naive Bayes classifier is applied to make decisions for unseen instances or for instances with missing attribute values. Benchmark data sets from the UCI Machine Learning Repository are used to test the algorithms. The experimental results are encouraging; the prediction accuracy for unseen instances by using the algorithms is higher than by using other approaches based on a single body of knowledge.	Univ Ulster, Sch Comp & Intelligent Syst, Magee BT48 7JL, Londonderry, North Ireland; Queens Univ Belfast, Sch Comp Sci, Belfast, Antrim, North Ireland	Wu, QX (reprint author), Univ Ulster, Sch Comp & Intelligent Syst, Magee BT48 7JL, Londonderry, North Ireland.	q.wu@ulster.ac.uk					BAO Y, 2003, INT J KNOWL BASED IN, V7, P54; Bao YG, 2002, LECT NOTES COMPUT SC, V2534, P340; Bell DA, 1998, J AM SOC INFORM SCI, V49, P403, DOI 10.1002/(SICI)1097-4571(19980415)49:5<403::AID-ASI3>3.3.CO;2-#; Bell DA, 2000, MACH LEARN, V41, P175, DOI 10.1023/A:1007612503587; Guan JW, 1998, ARTIF INTELL, V105, P77, DOI 10.1016/S0004-3702(98)00090-3; HONG ZQ, 1991, PATTERN RECOGN, V24, P317, DOI 10.1016/0031-3203(91)90074-F; HU X, 1997, ROUGH SET DATA MININ, P109; KOHAVI R, 1994, USEFUL FEATURE SUBSE; LIN TY, 1997, ROUGH SET DATA MININ; Mitchell M., 1997, MACHINE LEARNING; NGUYEN SH, 1997, P 7 INT FUZZ SYST AS, V2, P204; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pawlak Z., 1991, ROUGH SETS THEORETIC; Polkowski L., 1998, ROUGH SETS KNOWLEDGE, V1; Polkowski L., 1998, ROUGH SETS KNOWLEDGE, V2; Polkowski L., 2000, ROUGH SET METHODS AP; RISH I, 2001, IJCAI01 WORKSH EMP M; Skowron A., 1992, INTELLIGENT DECISION, P331; TANAKA H, 1998, ROUGH SETS KNOWLEDGE, V2, P295; WROBLEWSKI J, 1998, ROUGH SETS KNOWLEDGE, V2, P471; Wroblewski J., 1995, P 2 ANN JOINT C INF, P186; WU QX, 2001, P INT C COMP INT MOD, P543; YAO YY, 1997, ROUGH SETS DATA MINI, P25; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; Zupan B, 1998, IEEE INTELL SYST APP, V13, P38, DOI 10.1109/5254.671090	25	9	10	SPRINGER LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL ROAD, GODALMING GU7 3DJ, SURREY, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	FEB	2005	7	2					246	266		10.1007/s10115-004-0150-0		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	903FT	WOS:000227411800006	
J	Gama, J; Medas, P				Gama, J; Medas, P			Learning decision trees from dynamic data streams	JOURNAL OF UNIVERSAL COMPUTER SCIENCE			English	Article						data streams; incremental decision trees; concept drift		This paper presents a system for induction of forest of functional trees from data streams able to detect concept drift. The Ultra Fast Forest of Trees (UFFT) is an incremental algorithm, which works online, processing each example in constant time, and performing a single scan over the training examples. It uses analytical techniques to choose the splitting criteria, and the information gain to estimate the merit of each possible splitting-test. For multi-class problems the algorithm builds a binary tree for each possible pair of classes, leading to a forest of trees. Decision nodes and leaves contain naive-Bayes classifiers playing different roles during the induction process. Naive-Bayes in leaves are used to classify test examples. Naive-Bayes in inner nodes play two different roles. They can be used as multivariate splitting-tests if chosen by the splitting criteria, and used to detect changes in the class-distribution of the examples that traverse the node. When a change in the class-distribution is detected, all the sub-tree rooted at that node will be pruned. The use of naive-Bayes classifiers at leaves to classify test examples, the use of splitting-tests based on the outcome of naive-Bayes, and the use of naive-Bayes classifiers at decision nodes to detect changes in the distribution of the examples are directly obtained from the sufficient statistics required to compute the splitting criteria, without no additional computations. This aspect is a main advantage in the context of high-speed data streams. This methodology was tested with artificial and real-world data sets. The experimental results show a very good performance in comparison to a batch decision tree learner, and high capacity to detect drift in the distribution of the examples.	Univ Porto, FEP, LIACC, P-4050 Oporto, Portugal	Gama, J (reprint author), Univ Porto, FEP, LIACC, Rua Ceuta 118-6, P-4050 Oporto, Portugal.	jgama@liacc.up.pt; pmedas@liacc.up.pt	Gama, Joao/A-2070-2008	Gama, Joao/0000-0003-3357-1195			Blake C., 1999, UCI REPOSITORY MACHI; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347107; Duda R.O., 2001, PATTERN CLASSIFICATI; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Gama J, 2004, MACH LEARN, V55, P219, DOI 10.1023/B:MACH.0000027782.67192.13; GAMA J, 2003, 9 ACM SIGKDD INT C; HULTEN G, 2001, P 7 INT C KNOWL DISC; Hulten G., 2001, P WORKSH RES ISS DAT; Ihaka R., 1996, J COMPUTATIONAL GRAP, P299, DOI DOI 10.2307/1390807; KITTLER J, 1998, PATTERN ANAL APPL, V1; Klinkenberg R, 1998, LEARNING TEXT CATEGO, P33; Klinkenberg R, 2000, P 17 INT C MACH LEAR, P487; Klinkenberg R., 2004, Intelligent Data Analysis, V8; KUBAT M, 1995, P 8 EUR C MACH LEARN, P307; LOH WY, 1997, STAT SINICA, V7; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; Mitchell T.M., 1997, MACHINE LEARNING; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Street N., 2001, P 7 ACM SIGKDD INT C, P377; Vicente R, 1998, MACH LEARN, V32, P179, DOI 10.1023/A:1007428731714; WANG H, 2003, 9 ACM SIGKDD INT C; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900	22	9	10	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0948-695X			J UNIVERS COMPUT SCI	J. Univers. Comput. Sci.		2005	11	8					1353	1366				14	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	970ZR	WOS:000232351400002	
B	Jiang, LX; Zhang, HJ; Cai, ZH; Su, J		Lishan, K; Zhihua, C; Xuesong, Y		Jiang, LX; Zhang, HJ; Cai, ZH; Su, J			Evolutional naive Bayes	Progress in Intelligence Computation & Applications			English	Proceedings Paper	International Symposium on Intelligence Computation and Applications	APR 04-06, 2005	Wuhan, PEOPLES R CHINA	China Assoc Aerosp, Natl Nat Sci Fdn China, China Univ Geosci, China Univ Geosci Press		naive Bayes; Bayesian networks; classification; evolutional search; data mining; machine learning		Although Naive Bayes has conceptual and computational simplicity etc many advantages, it also has some limitations in itself, which include its unrealistic attribute independence assumption. Responding to this problem, many researchers have made a substantial amount of effort to improve Naive Bayes via selecting relevant attributes subsets in which attributes are conditionally independent. Interested in this approach, we present a novel algorithm called Evolutional Naive Bayes (simply ENB). Our algorithm, selects relevant attributes subsets by carrying an evolutional search through the whole space of attributes. Our motivation is to improve Naive Bayes ' accuracy in domains that include redundant attributes without degrading Naive Bayes ' accuracy in domains that don ' t. We experimentally tested our algorithm measured by accuracy, using the whole 36 UCI datasets recommended by Weka([1]), and compared it to Naive Bayes, SBC[2] and WRAP([3]). The experimental results shows that our algorithm outperforms Naive Bayes measured by classification accuracy significantly and retains the conceptual simplicity and direct theoretical foundation of Naive Bayes.	China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China	Jiang, LX (reprint author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.		Jiang, Liangxiao /D-1237-2012				BENNETT PN, 2000, 100155 CMUCS; Chickering D. M., 1996, ARTIF INTELL, VV, P121; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KOHAVI R, ARTIFICIAL INTELLIGE, V97, P1; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; LANGLEY P, 1994, ARTIF INTELL, P339; Merz C., 1997, UCI REPOSITORY MACHI; Nadeau C., 1999, ADV NEURAL INFORMATI, P307; Pearl J., 1998, PROBABILISTIC REASON; Ratanamahatana C.A., 2002, P WORKSH DAT CLEAN P; WITTEN JH, 2000, DATA MINING PRACTICA	11	9	10	CHINA UNIV GEOSCIENCES PRESS	WUHAN	388 LUMO ROAD, WUHAN, HUBEI 430074, PEOPLES R CHINA			7-5625-1983-8				2005							344	350				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCS66	WOS:000231083700055	
J	Madden, MG; Howley, T				Madden, MG; Howley, T			Transfer of experience between reinforcement learning environments with progressive difficulty	ARTIFICIAL INTELLIGENCE REVIEW			English	Article; Proceedings Paper	14th Artificial Intelligence and Cognitive Science Conference (AICS 2003)	SEP 17-19, 2003	Dublin, IRELAND		Trinity Coll Dublin	C4.5; experience transfer; Naive Bayes; PART; Progressive RL; Q-learning; reinforcement learning; rule learning		This paper describes an extension to reinforcement learning (RL), in which a standard RL algorithm is augmented with a mechanism for transferring experience gained in one problem to new but related problems. In this approach, named Progressive RL, an agent acquires experience of operating in a simple environment through experimentation, and then engages in a period of introspection, during which it rationalises the experience gained and formulates symbolic knowledge describing how to behave in that simple environment. When subsequently experimenting in a more complex but related environment, it is guided by this knowledge until it gains direct experience. A test domain with 15 maze environments, arranged in order of difficulty, is described. A range of experiments in this domain are presented, that demonstrate the benefit of Progressive RL relative to a basic RL approach in which each puzzle is solved from scratch. The experiments also analyse the knowledge formed during introspection, illustrate how domain knowledge may be incorporated, and show that Progressive Reinforcement Learning may be used to solve complex puzzles more quickly.	Natl Univ Ireland, Dept Informat Technol, Galway, Ireland	Madden, MG (reprint author), Natl Univ Ireland, Dept Informat Technol, Galway, Ireland.	michael.madden@nuigalway.ie	Madden, Michael/C-7113-2011				ABBOTT R, 1990, MAD MAZES INTRIGUING; ANDRE D, 2002, P 18 NAT C ART INT; BERNSTEIN DS, 1999, 9926 U MASS; Blockeel H, 1998, ARTIF INTELL, V101, P285, DOI 10.1016/S0004-3702(98)00034-4; BOWLING M, 1998, P AI AI 98 WORKSH NE; BOWLING M, 1999, P 16 INT JOINT C AI, P1340; BREISEMEISTER L, 1995, 2095 TU BERL; BREISEMEISTER L, 1996, P 1 EUR WORKSH COGN; CARROLL JL, 2001, P INT JOINT C NEUR N; Dietterich TG, 2000, J ARTIF INTELL RES, V13, P227; Dixon K.R., 2000, INCORPORATING PRIOR; Dreyfus H. L., 1986, MIND MACHINE POWER H; Dzeroski S, 2001, MACH LEARN, V43, P7, DOI 10.1023/A:1007694015589; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Langley P., 1992, P 10 NAT C ART INT, P223; Maclin R, 1996, MACH LEARN, V22, P251, DOI 10.1007/BF00114730; Michie D., 1990, Knowledge-Based Systems for Industrial Control, DOI 10.1049/PBCE044E_ch5; Ng A., 1999, P 16 INT C MACH LEAR; PERKINS TJ, 1999, 9934 U MASS; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Russell S., 2003, ARTIFICIAL INTELLIGE; SUC D, 2001, THESIS U LJUBLJANA S; Sun R., 1996, P 18 COGN SCI SOC C; Sun R, 1998, IEEE T NEURAL NETWOR, V9, P1217, DOI 10.1109/72.728364; Sun R, 2001, COGNITIVE SCI, V25, P203, DOI 10.1207/s15516709cog2502_2; Sutton R. S., 1998, REINFORCEMENT LEARNI; SUTTON RS, 2000, P ADV NEUR INF SYST; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; Thrun S., 1996, EXPLANATION BASED NE; THRUN S, 1995, P ADV NEUR INF SYST, P385; UTGOFF PE, 1998, P AAAI WORKSH METH A; Watkins C. J. C. H., 1989, THESIS CAMBRIDGE U; Whitehead S., 1991, 365 U ROCH; Witten I.H., 2000, DATA MINING PRACTICA	35	9	9	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821			ARTIF INTELL REV	Artif. Intell. Rev.	JUN	2004	21	3-4					375	398		10.1023/B:AIRE.0000036264.95672.64		24	Computer Science, Artificial Intelligence	Computer Science	841YL	WOS:000222968400011	
S	Bouckaert, RR		Webb, GI; Yu, X		Bouckaert, RR			Naive Bayes classifiers that perform well with continuous variables	AI 2004: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	17th Annual Australian Conference on Artificial Intelligence	DEC 04-06, 2004	Cairns, AUSTRALIA		Cent Queensland Univ			There are three main methods for handling continuous variables in naive Bayes classifiers, namely, the normal method (parametric approach), the kernel method (non parametric approach) and discretization. In this article, we perform a methodologically sound comparison of the three methods, which shows large mutual differences of each of the methods and no single method being universally better. This suggests that a method for selecting one of the three approaches to continuous variables could improve overall performance of the naive Bayes classifier. We present three methods that can be implemented efficiently v-fold cross validation for the normal, kernel and discretization method. Empirical evidence suggests that selection using 10 fold cross validation (especially when repeated 10 times) can largely and significantly improve over all performance of naive Bayes classifiers and consistently outperform any of the three popular methods for dealing with continuous variables on their own. This is remarkable, since selection among more classifiers does not consistently result in better accuracy.	Univ Waikato, Dept Comp Sci, Dunedin, New Zealand	Bouckaert, RR (reprint author), Univ Waikato, Dept Comp Sci, Dunedin, New Zealand.	remco@cs.waikato.ac.nz					Blake C. L., 1998, UCI REPOSITORY MACHI; BOUCKAERT RR, NAIVE BAYES CLASSIFI; BOUCKAERT RR, 2004, PAKDD; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, INT C MACH LEARN, P194; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; HSU CN, 2000, ICML, P399; John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995); NADEAU C, 2000, NIPS; Witten I.H., 2000, DATA MINING PRACTICA; YANG Y, 2003, P 16 AUSTR C AI AI 0, P440; YANG Y, 2003, 2003131 MON U; Yang Y., 2002, P PAC RIM KNOWL ACQ, P159	14	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-24059-4	LECT NOTES ARTIF INT			2004	3339						1089	1094				6	Computer Science, Artificial Intelligence	Computer Science	BBM32	WOS:000226133600106	
B	Han, H; Giles, L; Zha, H; Li, C; Tsioutsiouliklis, K		Chen, H; Christel, M; Lim, EP		Han, H; Giles, L; Zha, H; Li, C; Tsioutsiouliklis, K			Two supervised learning approaches for name disambiguation in author citations	JCDL 2004: PROCEEDINGS OF THE FOURTH ACM/IEEE JOINT CONFERENCE ON DIGITAL LIBRARIES: GLOBAL REACH AND DIVERSE IMPACT			English	Proceedings Paper	4th Joint Conference on Digital Libraries	JUN 07-11, 2004	Tucson, AZ	ACM SIGIR, ACM SIGWEB, IEEE, Tech Comm Digital Libraries		naive Bayes; name disambiguation; Support Vector Machine		Due to name abbreviations, identical names, name misspellings, and pseudonyms in publications or bibliographies (citations), an author may have multiple names and multiple authors may share the same name. Such name ambiguity affects the performance of document retrieval, web search, database integration, and may cause improper attribution to authors. This paper investigates two supervised teaming approaches to disambiguate authors in the citations'. One approach uses the naive Bayes probability model, a generative model; the other uses Support Vector Machines(SVMs) [39] and the vector space representation of citations, a discriminative model. Both approaches utilize three types of citation attributes: co-author names, the title of the paper, and the title of the journal or proceeding. We illustrate these two approaches on two types of data, one collected from the web, mainly publication lists from homepages, the other collected from the DBLP citation databases.	Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA							Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290970; Banerjee A., 2003, P 9 ACM SIGKDD INT C, P19; BANERJEE S, P 3 INT C INT TEXT P; Bar-Shalom Y., 1988, TRACKING DATA ASS; Bilenko M, 2003, IEEE INTELL SYST, V18, P16, DOI 10.1109/MIS.2003.1234765; BITTON D, 1983, ACM T DATABASE SYST, V8, P255, DOI 10.1145/319983.319987; BRANTING LK, 2002, J INFORMATION LAW TE, P1; Califf M. E., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Cohen W. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347141; Cristianini N., 2000, INTRO SUPPORT VECTOR; DAGAN I, 1994, M ASS COMP LING, P272; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Di Lauro T., 2001, D LIB MAGAZINE, V7; ESCUDERO G, 2000, P 14 EUR C ART INT E; FELLEGI IP, 1969, J AM STAT ASSOC, V64, P1183, DOI 10.2307/2286061; Giles C., 1998, P 3 ACM C DIG LIB, P89, DOI 10.1145/276675.276685; GILLMAN P, 1998, 91 BRIT LIB BOARD; Han H., 2003, P 3 ACM IEEE CS JOIN, P37; HAN H, 2003, P 2 INT SEM WEB C IS; Hernandez MA, 1998, DATA MIN KNOWL DISC, V2, P9, DOI 10.1023/A:1009761603038; Hofmann T., 1999, P UNC ART INT UAI 99; Joachims T., 2001, P 24 ANN INT ACM SIG, P128, DOI 10.1145/383952.383974; Krovetz R., 1993, P 16 ANN INT ACM SIG, P191, DOI 10.1145/160688.160718; LEE ML, 2000, 6 INT C KNOWL DISC D, P290; Lin D., 2002, P C COMP LING, P577; McCallum A., 2000, KNOWLEDGE DISCOVERY, P169; MONGE AE, 1997, RES ISSUES DATA MINI, P23; PASULA H, 2002, P NEUR INF PROC SYST; Pereira F. C. N., 1993, M ASS COMP LING, P183; Petinot Y., 2003, Proceedings 2003 Joint Conference on Digital Libraries; SEYMORE K, 1999, P AAAI 99 WORKSH MAC; SKOUNAKIS M, 2003, P 18 INT JOINT C ART; Takasu A., 2003, Proceedings 2003 Joint Conference on Digital Libraries; TAKEUCHI K, 2002, USE SUPPORT VECTOR M; Tejada S., 2002, P 8 ACM SIGKDD INT C, P350; TSURUOKA Y, 2003, P 7 C NAT LANG LEARN, P127; Vapnik V., 1995, NATURE STAT LEARNING; WARNER JW, 2001, P 1 ACM IEEE CS JOIN; Yao YY, 1995, INT J GEN SYST, V23, P343, DOI 10.1080/03081079508908047; Zha H., 2001, P 10 INT C INF KNOWL, P25; ZHANG X, 2001, RECURSIVE SAMPLE CLA	41	9	9	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			1-58113-832-6				2004							296	305				10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science	Computer Science; Information Science & Library Science	BAM92	WOS:000222881400052	
S	Novovicova, J; Malik, A; Pudil, P		Fred, A; Caelli, T; Duin, RPW; Campilho, A; DeRidder, D		Novovicova, J; Malik, A; Pudil, P			Feature selection using improved mutual information for text classification	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th International Workshop on Structural and Syntactic Pattern Recognition/5th International Conference on Statistical Techniques in Pattern Recognition	AUG 18-20, 2004	Lisbon, PORTUGAL	Inst Telecommun, Inst Super Tecn, Int Assoc Pattern Recognit, Fund Luso-Amer Desenvolvimento				A major characteristic of text document classification problem is extremely high dimensionality of text data. In this paper we present two algorithms for feature (word) selection for the purpose of text classification. We used sequential forward selection methods based on improved mutual information introduced by Battiti [1] and Kwak and Choi [6] for non-textual data. These feature evaluation functions take into consideration how features work together. The performance of these evaluation functions compared to the information gain which evaluate features individually is discussed. We present experimental results using naive Bayes classifier based on multinomial model on the Reuters data set. Finally, we analyze the experimental results from various perspectives, including F-1-measure, precision and recall. Preliminary experimental results indicate the effectiveness of the proposed feature selection algorithms in a text classification problem.	Acad Sci Czech Republ, Inst Informat Theory & Automat, Dept Pattern Recognit, CR-18208 Prague, Czech Republic; Univ Econ, Fac Management, Prague, Czech Republic; Czech Tech Univ, Fac Elect Engn, CR-16635 Prague, Czech Republic	Novovicova, J (reprint author), Acad Sci Czech Republ, Inst Informat Theory & Automat, Dept Pattern Recognit, CR-18208 Prague, Czech Republic.	novovic@utia.cas.cz; amalik@utia.cas.cz; pudil@utia.cas.cz	Pudil, Pavel/I-6071-2013				BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; KWAK N, 1999, INT JOINT C NEUR NET, P1313; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Yang Y, 2003, P 26 ANN INT ACM SIG, P96; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Yang Y., 1997, P 14 INT C MACH LEAR, P412	12	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22570-6	LECT NOTES COMPUT SC			2004	3138						1010	1017				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAS89	WOS:000223398900111	
S	Peng, FC; Schuurmans, D		Sebastiani, F		Peng, FC; Schuurmans, D			Combining naive Bayes and n-gram language models for text classification	ADVANCES IN INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	25th European Conference on Information Retrieval Research (ECIR 2003)	APR 14-16, 2003	PISA, ITALY	Elsevier, Assoc Italiana Informat Calcolo Automat, CEPIS, LIBERO, Microsoft Res, CRE, fast, Sharp, IBM, Data Port			CATEGORIZATION; TERMS	We augment the naive Bayes model with an n-gram. language model to address two shortcomings of naive Bayes text classifiers. The chain augmented naive Bayes classifiers we propose have two advantages over standard naive Bayes classifiers. First, a chain augmented naive Bayes model relaxes some of the independence assumptions of naive Bayes-allowing a local Markov chain dependence in the observed variables-while still permitting efficient inference and learning. Second, smoothing techniques from statistical language modeling can be used to recover better estimates than the Laplace smoothing techniques usually used in naive Bayes classification. Our experimental results on three real world data sets show that we achieve substantial improvements over standard naive Bayes classification, while also achieving state of the art performance that competes with the best known methods in these cases.	Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada	Peng, FC (reprint author), Univ Waterloo, Sch Comp Sci, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.						Bell T. C., 1990, TEXT COMPRESSION; CAVNER W, 1994, P SDAIR 94; Chen S. F., 1998, TR1098 HARV U; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; EYHERAMENDY S, 2003, IN PRESS ARTIFICAL I; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; HE J, 2000, P PRICAI 2000 INT WO, P24; Hiemstra D., 2001, THESIS U TWENTE; KEOGH E, 1999, ARTIFICIAL INTELLIGE; Kwok KL, 1999, J AM SOC INFORM SCI, V50, P709, DOI 10.1002/(SICI)1097-4571(1999)50:8<709::AID-ASI8>3.0.CO;2-V; LEWIS D, 1998, P ECML 98; Manning C.D., 1999, FDN STAT NATURAL LAN; McCallum A., 1998, P AAAI 98 WORKSH LEA; NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Ponte J. M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.291008; RENNIE J, 2001, AITR2001004; Rish I., 2001, P IJCAI 01 WORKSH EM; ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302; Scott Sam, 1999, P 16 INT C MACH LEAR, P379; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Stamatatos E, 2000, COMPUT LINGUIST, V26, P471, DOI 10.1162/089120100750105920; TEAHAN W, 2001, P WORKSH LMIR; TURPIN A, 2000, P SIGIR 1999, P309; Yang Y., 1999, INFORMATION RETRIEVA, V1, P67	26	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-01274-5	LECT NOTES COMPUT SC			2003	2633						335	350				16	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BX27M	WOS:000184816000024	
J	Stewart, B				Stewart, B			Predicting project delivery rates using the Naive-Bayes classifier	JOURNAL OF SOFTWARE MAINTENANCE AND EVOLUTION-RESEARCH AND PRACTICE			English	Article						software effort estimation; Bayesian networks; machine learning; model trees; neural networks	SOFTWARE	The importance of accurate estimation of software development effort is well recognized in software engineering. In recent years, machine learning approaches have been studied as possible alternatives to more traditional software cost estimation methods. The objective of this paper is to investigate the utility of the machine learning algorithm known as the Naive-Bayes classifier for estimating software project effort. We present empirical experiments with the Benchmark 6 data set from the International Software Benchmarking Standards Group to estimate project delivery rates and compare the performance of the Naive-Bayes approach to two other machine learning methods model trees and neural networks. A project delivery rate is defined as the number of effort hours per function point. The approach described is general and can be used to analyse not only software development data but also data on software maintenance and other types of software engineering. The paper demonstrates that the Naive-Bayes classifier has a potential to be used as an alternative machine learning tool for software development effort estimation. Copyright (C) 2002 John Wiley Sons, Ltd.	Univ Western Sydney, Sch Comp & Informat Technol, Penrith S DC, NSW 1797, Australia	Stewart, B (reprint author), Univ Western Sydney, Sch Comp & Informat Technol, Campbelltown Campus,Locked Bag 1797, Penrith S DC, NSW 1797, Australia.						ALBRECHT AJ, 1983, IEEE T SOFTWARE ENG, V9, P639, DOI 10.1109/TSE.1983.235271; Bishop C.M., 1995, NEURAL NETWORKS PATT; Boehm B. W., 1981, SOFTWARE ENG EC; Breiman L., 1984, CLASSIFICATION REGRE; BRIAND LC, 1992, IEEE T SOFTWARE ENG, V18, P931, DOI 10.1109/32.177363; Briand L. C., 1999, Proceedings of the 1999 International Conference on Software Engineering (IEEE Cat. No.99CB37002), DOI 10.1109/ICSE.1999.841022; Castillo E., 1997, EXPERT SYSTEMS PROBA; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowell R. G., 1999, PROBABILISTIC NETWOR; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Goldberg D., 1989, GENETIC ALGORITHMS S; JENSEN FV, INTRO BAYESIAN NETWO; JORGENSEN M, 1995, IEEE T SOFTWARE ENG, V21, P674, DOI 10.1109/32.403791; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MOTODA H, 1998, FEATURE EXTRACTION C; Neapolitan R.E., 1990, PROBABILISTIC REASON; Pearl J., 1988, PROBABILISTIC REASON; Pfleeger S.L., 1998, SOFTWARE ENG THEORY; PUTNAM LH, 1978, IEEE T SOFTWARE ENG, V4, P345, DOI 10.1109/TSE.1978.231521; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Shepperd M, 1997, IEEE T SOFTWARE ENG, V23, P736, DOI 10.1109/32.637387; Shin M, 2000, IEEE T SOFTWARE ENG, V26, P567; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Witten I.H., 2000, DATA MINING PRACTICA	26	9	10	JOHN WILEY & SONS LTD	W SUSSEX	BAFFINS LANE CHICHESTER, W SUSSEX PO19 1UD, ENGLAND	1532-060X			J SOFTW MAINT EVOL-R	J. Softw. Maint. Evol.-Res. Pract.	MAY-JUN	2002	14	3					161	179		10.1002/smr.250		19	Computer Science, Software Engineering	Computer Science	568UM	WOS:000176563100002	
J	Xie, ZP; Hsu, W; Liu, ZT; Lee, ML				Xie, ZP; Hsu, W; Liu, ZT; Lee, ML			Concept lattice based composite classifiers for high predictability	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE			English	Article; Proceedings Paper	International Workshop on Concept Lattice-Based Theory, Methods and Tools for KDD	JUL, 2001	STANFORD, CALIFORNIA		STANFORD UNIV	concept lattice; Naive Bayes; nearest neighbour algorithm; classification	RULES	Concept lattice model, the core structure in formal concept analysis, has been successfully applied in software engineering and knowledge discovery. This paper integrates the simple base classifier (Naive Bayes or Nearest Neighbour) into each node of the concept lattice to form a new composite classifier. Two new classification systems are developed, CLNB and CLNN, which employ efficient constraints to search for interesting patterns and voting strategy to classify a new object. CLNB integrates the Naive Bayes base classifier into concept nodes while CLNN incorporates the Nearest Neighbour base classifier into concept nodes. Experimental results indicate that these two composite classifiers greatly improve the accuracy of their corresponding base classifier. In addition, CLNB even outperforms three other state-of-the-art classification methods, NBTree, CBA and C4.5 Rules.	Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore; Shanghai Univ, Sch Comp, Shanghai 200072, Peoples R China							Aha D.W., 1997, LAZY LEARNING; BLANZIERI E, 1999, P 16 INT C MACH LEAR, P22; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GANTER B, 1999, P 2 INT C KNOWL DISC; GODIN R, 1994, THEOR COMPUT SCI, V133, P387, DOI 10.1016/0304-3975(94)90195-3; Liu B., 1998, P 4 INT C KNOWL DISC, P80; MEPHUNGUIFO E, 1994, PROC INT C TOOLS ART, P461, DOI 10.1109/TAI.1994.346456; Merz CJ, 1996, UCI REPOSITORY MACHI; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; NJIWOUA P, 1996, P BENELEARN 96 U LIM, P57; PASQUIER N, 1999, INFORMATION SYSTEMS, V19, P33; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SAHAMI M, 1995, P 8 EUR C MACH LEARN, P343; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Wille R., 1982, ORDERED SETS, P445; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	22	9	9	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK,, ABINGDON OX14 4RN, OXON, ENGLAND	0952-813X			J EXP THEOR ARTIF IN	J. Exp. Theor. Artif. Intell.	APR	2002	14	2					143	156		10.1080/09528130210164206		14	Computer Science, Artificial Intelligence	Computer Science	622VC	WOS:000179666900005	
J	Liu, B; Ma, YM; Wong, CK				Liu, Bing; Ma, Yiming; Wong, Ching Kian			Improving an Association Rule Based Classifier	LECTURE NOTES IN COMPUTER SCIENCE <D>			English	Article								Existing classification algorithms in machine learning mainly use heuristic search to find a subset of regularities in data for classification. In the past few years, extensive research was done in the database community on learning rules using exhaustive search under the name of association rule mining. Although the whole set of rules may not be used directly for accurate classification, effective classifiers have been built using the rules. This paper aims to improve such an exhaustive search based classification system CBA (Classification Based on Associations). The main strength of this system is that it is able to use the most accurate rules for classification. However, it also has weaknesses. This paper proposes two new techniques to deal with these weaknesses. This results in remarkably accurate classifiers. Experiments on a set of 34 benchmark datasets show that on average the new techniques reduce the error of CBA by 17% and is superior to CBA on 26 of the 34 datasets. They reduce the error of C4.5 by 19%, and improve performance on 29 datasets. Similar good results are also achieved against RIPPER, LB and a Naive-Bayes classifier.	[Liu, Bing; Ma, Yiming; Wong, Ching Kian] Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore	Liu, B (reprint author), Natl Univ Singapore, Sch Comp, 3 Sci Dr 2, Singapore 117543, Singapore.	liub@comp.nus.edu.sg; maym@comp.nus.edu.sg; wongck@comp.nus.edu.sg					Agrawal R., 1994, VLDB 94; CHAN PK, 1993, P 2 INT C INF KNOWL, P314; Cohen W.W., 1995, ICML 95; DONG G, 1999, DISCOVERY SCI; FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022; KOHAVI R, 1994, MLC MACHINE LEARNING, P740; Liu B., 1998, KDD 98; MERETKIS D, 1999, KDD 99; Merz CJ, 1996, UCI REPOSITORY MACHI; Quinlan J.R., 1992, C4 5 PROGRAM MACHINE; ZHENG Z, 1999, PAKDD 99	11	9	9	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0302-9743			LECT NOTES COMPUT<D>	Lect. Notes Comput. Sci.		2000	1910						504	509				6	Computer Science, Theory & Methods	Computer Science	V12XW	WOS:000207632900059	
J	Bruce, RF; Wiebe, JM				Bruce, RF; Wiebe, JM			Decomposable modeling in natural language processing	COMPUTATIONAL LINGUISTICS			English	Article								In this paper, we describe a framework for developing probabilistic classifiers in natural language processing. Our focus is on formulating models that capture the most important interdependencies among features, to avoid overfitting the data while also characterizing the data well. The class of probability models and the associated inference techniques described here were developed in mathematical statistics, and are widely used in artificial intelligence and applied statistics. Our goal is to make this model selection framework accessible to researchers in NLP, and provide pointers to available software and important references. In addition, toe describe how the quality of the three determinants of classifier performance (the features, the form of the model, and the parameter estimates) can be separately evaluated. We also demonstrate the classification performance of these models in a large-scale experiment involving the disambiguation of 34 words taken from the HECTOR word sense corpus (Hanks 1996). In 10-fold cross-validations, the model search procedure performs significantly better than naive Bayes on 6 of the words without being significantly worse on any of them.	Univ N Carolina, Dept Comp Sci, Asheville, NC 28804 USA; New Mexico State Univ, Dept Comp Sci, Las Cruces, NM 88003 USA	Bruce, RF (reprint author), Univ N Carolina, Dept Comp Sci, Asheville, NC 28804 USA.						AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; ATKINS S, 1993, PAPERS COMPUTATIONAL; BDSBERG JH, 1995, THESIS AALBORG U; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bishop YM, 1975, DISCRETE MULTIVARIAT; BOUTILIER C, 1996, P 12 C UNC ART INT U; Breiman L., 1984, CLASSIFICATION REGRE; Bruce R., 1996, P C EMP METH NAT LAN, P101; Bruce R.F., 1994, P 32 ANN M ASS COMP, P139, DOI 10.3115/981732.981752; BUNTINE W, 1995, 5 INT ART INT STAT W; BUNTINE W, 1996, IEEE T KNOWLEDGE DAT, V8; Cohen P., 1995, EMPIRICAL METHODS AR; DARROCH JN, 1980, ANN STAT, V8, P522, DOI 10.1214/aos/1176345006; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hanks Patrick, 1996, INT J CORPUS LINGUIS, V1, P75, DOI 10.1075/ijcl.1.1.06han; KAYALLP M, 1997, P COMP NAT LANG LEAR; Kilgarriff A., 1998, P 1 INT C LANG RES E, P581; Langley P., 1992, P 10 NAT C ART INT, P223; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LEACOCK C, 1993, P ARPA WORKSH HUM LA; Mood AM, 1974, INTRO THEORY STAT; Mooney R. J., 1996, P C EMP METH NAT LAN, P82; Pearl J., 1988, PROBABILISTIC REASON; PEDERSEN T, 1997, P 14 NAT C ART INT A; PEDERSEN T, 1997, P 5 C APPL NAT LANG; RATNAPARKHI A, 1997, P 2 C EMP METH NAT L; READ TRC, 1988, GOODNESS OF FIT STAT; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Whittaker J., 1990, GRAPHICAL MODELS APP; WIEBE J, 1997, P 2 INT C REC ADV NL	30	9	10	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	0891-2017			COMPUT LINGUIST	Comput. Linguist.	JUN	1999	25	2					195	207				13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Computer Science; Linguistics	210PN	WOS:000081114000002	
J	Mani, S; Shankle, WR; Dick, MB; Pazzani, MJ				Mani, S; Shankle, WR; Dick, MB; Pazzani, MJ			Two-stage machine learning model for guideline development	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						machine learning; clinical dementia rating scale; dementia staging; data mining	ALZHEIMERS-DISEASE; DEMENTIA; RELIABILITY; DIAGNOSIS; STATE; SCALE	We present a Two-Stage Machine Learning (ML) model as a data mining method to develop practice guidelines and apply it to the problem of dementia staging. Dementia staging in clinical settings is at present complex and highly subjective because of the ambiguities and the complicated nature of existing guidelines. Our model abstracts the two-stage process used by physicians to arrive at the global Clinical Dementia Rating Scale (CDRS) score. The model incorporates learning intermediate concepts (CDRS category scores) in the first stage that then become the feature space for the second stage (global CDRS score). The sample consisted of 678 patients evaluated in the Alzheimer's Disease Research Center at the University of California, Irvine. The demographic variables, functional and cognitive test results used by physicians for the task of dementia severity staging were used as input to the machine learning algorithms. Decision tree learners and rule inducers (C4.5, Cart, C4.5 rules) were selected for our study as they give expressive models, and Naive Bayes was used as a baseline algorithm for comparison purposes. We first learned the six CDRS category scores (memory, orientation, judgement and problem solving, personal care, home and hobbies, and community affairs). These learned CDRS category scores were then used to learn the global CDRS scores. The Two-Stage ML model classified as well as or better than the published inter-rater agreements for both the category and global CDRS scoring by dementia experts. Furthermore, for the most critical distinction, normal versus very mildly impaired, the Two-Stage ML model was 28.1 and 6.6% more accurate than published performances by domain experts. Our study of the CDRS examined one of the largest, most diverse samples in the literature, suggesting that our findings are robust. The Two-Stage ML model also identified a CDRS category, Judgment and Problem Solving, which has low classification accuracy similar to published reports. Since this CDRS category appears to be mainly responsible for misclassification of the global CDRS score when it occurs, further attribute and algorithm research on the Judgment and Problem Solving CDRS score could improve its accuracy as well as that of the global CDRS score. (C) 1999 Elsevier Science B.V. All rights reserved.	Univ Calif Irvine, Dept Informat & Comp Sci, Irvine, CA 92697 USA; Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92697 USA; Univ Calif Irvine, Dept Neurol, Irvine, CA 92697 USA	Mani, S (reprint author), Ctr Biomed Informat, Suite 8084,Forbes Tower,200 Sothrop St, Pittsburgh, PA 15213 USA.	mani@cbmi.upmc.edu					Abston KC, 1997, J AM MED INFORM ASSN, P168; *ALZH DIS COOP STU, 1994, ASS CLIN DEM RAT; Boone G., 1998, Proceedings of the Second International Conference on Autonomous Agents, DOI 10.1145/280765.280791; Brieman L., 1984, CLASSIFICATION REGRE; BUNTINE W, 1992, INTRO IND VERSION 2; BURKE WJ, 1988, ARCH NEUROL-CHICAGO, V45, P31; CHUI HC, 1992, NEUROLOGY, V42, P473; Clark CM, 1996, ALZ DIS ASSOC DIS, V10, P31, DOI 10.1097/00002093-199601010-00006; Cooper GF, 1997, ARTIF INTELL MED, V9, P107, DOI 10.1016/S0933-3657(96)00367-3; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6; GELB DJ, 1993, ALZ DIS ASSOC DIS, V7, P202, DOI 10.1097/00002093-199307040-00002; Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752; HUGHES CP, 1982, BRIT J PSYCHIAT, V140, P566, DOI 10.1192/bjp.140.6.566; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P74; Lubeck D P, 1994, Med Interface, V7, P130; Mani S, 1997, J AM MED INFORM ASSN, P875; MCCULLA MM, 1989, ARCH NEUROL-CHICAGO, V46, P1210; MCKHANN G, 1984, NEUROLOGY, V34, P939; MICHALSKI RS, 1993, MACHINE LEARNING MUL, P3; MICHIE D, 1995, LECT NOTES ARTIF INT, P17; Mittelman MS, 1996, JAMA-J AM MED ASSOC, V276, P1725, DOI 10.1001/jama.276.21.1725; Morris JC, 1997, NEUROLOGY, V48, P1508; Morris JC, 1995, TREATING ALZHEIMERS, P338; Ohmann C, 1995, LECT NOTES ARTIF INT, V934, P276; PAZZANI MJ, 1997, 3 INT C KNOWL DISC D, P235; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Shankle WR, 1997, LECT NOTES ARTIF INT, V1211, P73; SHANKLE WR, 1998, 9 WORLD C MED INF SE; Shapiro A.D., 1987, STRUCTURED INDUCTION; Shiffman RN, 1997, J AM MED INFORM ASSN, V4, P382; TURNEY P, 1995, MACH LEARN, V20, P23, DOI 10.1007/BF00993473; Wechsler D., 1955, MANUAL WECHSLER ADUL; WELSH KA, 1994, NEUROLOGY, V44, P609; Zupan B., 1997, P 14 INT C MACH LEAR, P421	36	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	MAY	1999	16	1					51	71		10.1016/S0933-3657(98)00064-5		21	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	184DR	WOS:000079595400004	
B	Frank, E; Paynter, GW; Witten, IH; Gutwin, C; Nevill-Manning, CG			IJCAII; IJCAII; IJCAII	Frank, E; Paynter, GW; Witten, IH; Gutwin, C; Nevill-Manning, CG			Domain-specific keyphrase extraction	IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2			English	Proceedings Paper	16th International Joint Conference on Artificial Intelligence (IJCAI 99)	JUL 31-AUG 06, 1999	STOCKHOLM, SWEDEN	Int Joint Conference Artificial Intelligence Inc, Scandinavian Al Soc				Keyphrases are an important means of document summarization, clustering, and topic search. Only a small minority of documents have author-assigned keyphrases, and manually assigning keyphrases to existing documents is very laborious. Therefore it is highly desirable to automate the keyphrase extraction process. This paper shows that a simple procedure for keyphrase extraction based on the naive Bayes learning scheme performs comparably to the state of the art. It goes on to explain how this procedure's performance can be boosted by automatically tailoring the extraction process to the particular document collection at hand. Results on a large collection of technical reports in computer science show that the quality of the extracted keyphrases improves significantly when domain-specific information is exploited.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Frank, E (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.		Frank, Eibe/A-1434-2008				Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dumais S., 1998, P 7 INT C INF KNOWL; LOVINS JB, 1968, MECH TRANSL, V11, P22; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; Turney P., 1999, ERB1057 I INF TECHN; Usama M.F., 1993, P 13 INT JOINT C ART, P1022	7	9	9	MORGAN KAUFMANN PUB INC	SAN FRANCISCO	340 PINE STR, 6TH FLR, SAN FRANCISCO, CA 94104-3205 USA			1-55860-613-0				1999							668	673				6	Computer Science, Artificial Intelligence	Computer Science	BR27X	WOS:000165996800095	
J	Farrell, PJ; MacGibbon, B; Tomberlin, TJ				Farrell, PJ; MacGibbon, B; Tomberlin, TJ			Bootstrap adjustments for empirical Bayes interval estimates of small-area proportions	CANADIAN JOURNAL OF STATISTICS-REVUE CANADIENNE DE STATISTIQUE			English	Article						logistic regression; random effects; step-function prior; coverage	CONFIDENCE-INTERVALS; MAXIMUM LIKELIHOOD; INCIDENCE RATES; LINEAR-MODELS; INFERENCE	Empirical Bayes approaches have often been applied to the problem of estimating small-area parameters. As a compromise between synthetic and direct survey estimators, an estimator based on an empirical Bayes procedure is not subject to the large bias that is sometimes associated with a synthetic estimator, nor is it as variable as a direct survey estimator. Although the point estimates perform very well, naive empirical Bayes confidence intervals tend to be too short to attain the desired coverage probability, since they fail to incorporate the uncertainty which results from having to estimate the prior distribution. Several alternative methodologies for interval estimation which correct for the deficiencies associated with the naive approach have been suggested. Laird and Louis (1987) proposed three types of bootstrap for correcting naive empirical Bayes confidence intervals. Calling the methodology of Laird and Louis (1987) an unconditional bias-corrected naive approach, Carlin and Gelfand (1991) suggested a modification to the Type In parametric bootstrap which corrects for bias in the naive intervals by conditioning on the data. Here we empirically evaluate the Type TI and Type III bootstrap proposed by Laird and Louis, as well as the modification suggested by Carlin and Gelfand (1991), with the objective of examining coverage properties of empirical Bayes confidence intervals for small-area proportions.	ACADIA UNIV, DEPT MATH & STAT, WOLFVILLE, NS B0P 1X0, CANADA; UNIV QUEBEC, DEPT MATH & INFORMAT, MONTREAL, PQ H3C 3P8, CANADA; CONCORDIA UNIV, DEPT DECIS SCI & MIS, MONTREAL, PQ H3G 1M8, CANADA							BETHLEHEM JG, 1990, J AM STAT ASSOC, V85, P38, DOI 10.2307/2289523; BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.2307/2290687; BUTLER SM, 1992, STAT MED, V11, P1981, DOI 10.1002/sim.4780111416; CARLIN BP, 1990, J AM STAT ASSOC, V85, P105, DOI 10.2307/2289531; CARLIN BP, 1991, J ROY STAT SOC B MET, V53, P189; Cox DR, 1975, PERSPECTIVES PROBABI, P47; Cressie N.A.C, 1992, SURV METHODOL, V18, P75; DATTA GS, 1991, ANN STAT, V19, P1748, DOI 10.1214/aos/1176348369; Datta G.S., 1992, SURV METHODOL, V18, P95; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dempster A.P., 1980, P C CENS UND ARL VA, P88; DERSIMONIAN R, 1987, J AM STAT ASSOC, V82, P755, DOI 10.2307/2288782; DEVINE OJ, 1994, STAT MED, V13, P1119, DOI 10.1002/sim.4780131104; DEVINE OJ, 1994, EPIDEMIOLOGY, V5, P622, DOI 10.1097/00001648-199411000-00010; FARRELL PJ, 1991, THESIS MCGILL U MONT; FARRELL PJ, 1994, CAN J STAT, V22, P365, DOI 10.2307/3315598; FAY RE, 1979, J AM STAT ASSOC, V74, P269; GHOSH M, 1991, P BUR CENS ANN RES C, P63; GHOSH M, 1994, STAT SCI, V9, P55, DOI 10.1214/ss/1177010647; LAIRD N, 1978, J AM STAT ASSOC, V73, P805, DOI 10.2307/2286284; LAIRD NM, 1978, BIOMETRIKA, V65, P581; LAIRD NM, 1987, J AM STAT ASSOC, V82, P739, DOI 10.2307/2288778; LEONARD KJ, 1988, THEIS CONCORDIA U; MACGIBBON B., 1989, SURV METHODOL, V15, P237; MORRIS CN, 1983, J AM STAT ASSOC, V78, P47, DOI 10.2307/2287098; RIPLEY BD, 1990, J COMPUT APPL MATH, V31, P165, DOI 10.1016/0377-0427(90)90347-3; ROYAL RM, 1970, BIOMETRIKA, V74, P1; TIERNEY L, 1986, J AM STAT ASSOC, V81, P82, DOI 10.2307/2287970; TOMBERLIN TJ, 1988, J AM STAT ASSOC, V83, P309, DOI 10.2307/2288845; *US BUR CENS, 1984, 1950 CENS POP; WONG GY, 1985, J AM STAT ASSOC, V80, P513, DOI 10.2307/2288464; ZEGER SL, 1991, J AM STAT ASSOC, V86, P79, DOI 10.2307/2289717	32	9	9	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0319-5724	1708-945X		CAN J STAT	Can. J. Stat.-Rev. Can. Stat.	MAR	1997	25	1					75	89		10.2307/3315358		15	Statistics & Probability	Mathematics	WU509	WOS:A1997WU50900009	
J	Shabbeer, A; Cowan, LS; Ozcaglar, C; Rastogi, N; Vandenberg, SL; Yener, B; Bennett, KP				Shabbeer, Amina; Cowan, Lauren S.; Ozcaglar, Cagri; Rastogi, Nalin; Vandenberg, Scott L.; Yener, Buelent; Bennett, Kristin P.			TB-Lineage: An online tool for classification and analysis of strains of Mycobacterium tuberculosis complex	INFECTION GENETICS AND EVOLUTION			English	Article						Tuberculosis; Classification; Spoligotype; MIRU-VNTR; Spoligoforest; Lineage	DISCRIMINATORY POWER; GLOBAL DISTRIBUTION; SPOLIGOTYPES; POLYMORPHISM; REPRODUCIBILITY; DATABASE	This paper formulates a set of rules to classify genotypes of the Mycobacterium tuberculosis complex (MTBC) into major lineages using spoligotypes and MIRU-VNTR results. The rules synthesize prior literature that characterizes lineages by spacer deletions and variations in the number of repeats seen at locus MIRU24 (alias VNTR2687). A tool that efficiently and accurately implements this rule base is now freely available at http://tbinsight.cs.rpi.edu/run_tb_lineage.html. When MIRU24 data is not available, the system utilizes predictions made by a Naive Bayes classifier based on spoligotype data. This website also provides a tool to generate spoligoforests in order to visualize the genetic diversity and relatedness of genotypes and their associated lineages. A detailed analysis of the application of these tools on a dataset collected by the CDC consisting of 3198 distinct spoligotypes and 5430 distinct MIRU-VNTR types from 37,066 clinical isolates is presented. The tools were also tested on four other independent datasets. The accuracy of automated classification using both spoligotypes and MIRU24 is >99%, and using spoligotypes alone is >95%. This online rule-based classification technique in conjunction with genotype visualization provides a practical tool that supports surveillance of TB transmission trends and molecular epidemiological studies. (C) 2012 Elsevier B.V. All rights reserved.	[Bennett, Kristin P.] Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12180 USA; [Shabbeer, Amina; Ozcaglar, Cagri; Yener, Buelent; Bennett, Kristin P.] Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA; [Cowan, Lauren S.] Ctr Dis Control & Prevent, Atlanta, GA 30333 USA; [Rastogi, Nalin] Inst Pasteur Guadeloupe, Abymes, Guadeloupe; [Vandenberg, Scott L.] Siena Coll, Dept Comp Sci, Loudonville, NY 12211 USA	Bennett, KP (reprint author), Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12180 USA.	shabba@cs.rpi.edu; los4@cdc.gov; ozcagc2@cs.rpi.edu; nrastogi@pasteur-guadeloupe.fr; vandenberg@siena.edu; yener@cs.rpi.edu; bennek@rpi.edu			NIH [R01LM009731]	This work was made possible by and with the assistance of Dr. Philip Supply of the Institute Pasteur de Lille. We thank Veronique Hill, David Couvin and Thierry Zozio at Institut Pasteur de la Guadeloupe and Minoo Aminian and Veronica Ahiati at Rensselaer Polytechnic Institute for their helpful suggestions and help with data analysis. This work was supported by NIH R01LM009731.	Allix-Beguec C, 2008, J CLIN MICROBIOL, V46, P2692, DOI 10.1128/JCM.00540-08; Allix-Beguec C, 2008, J CLIN MICROBIOL, V46, P1398, DOI 10.1128/JCM.02089-07; Aminian M, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S3-S4; Borile C, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-224; Brosch R, 2002, P NATL ACAD SCI USA, V99, P3684, DOI 10.1073/pnas.052548299; Brudey K., 2006, BMC MICROBIOL, V6; Comas I, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007815; Coscolla M., 2010, DRUG DISCOV TODAY DI, V7, pe47; de Jong BC, 2010, PLOS NEGLECT TROP D, V4, DOI 10.1371/journal.pntd.0000744; Ferdinand S, 2004, RES MICROBIOL, V155, P647, DOI 10.1016/j.resmic.2004.04.013; Filliol I, 2003, J CLIN MICROBIOL, V41, P1963, DOI 10.1128/JCM.41.5.1963.1970.2003; Filliol I, 2002, EMERG INFECT DIS, V8, P1347; Filliol I, 2006, J BACTERIOL, V188, P759, DOI 10.1128/JB.188.2.759-772.2006; Gagneux S, 2006, P NATL ACAD SCI USA, V103, P2869, DOI 10.1073/pnas.0511240103; Gagneux S, 2007, LANCET INFECT DIS, V7, P328, DOI 10.1016/S1473-3099(07)70108-1; Gansner ER, 2000, SOFTWARE PRACT EXPER, V30, P1203, DOI 10.1002/1097-024X(200009)30:11<1203::AID-SPE338>3.3.CO;2-E; Gutacker MM, 2006, J INFECT DIS, V193, P121, DOI 10.1086/498574; Hershberg R, 2008, PLOS BIOL, V6, P2658, DOI 10.1371/journal.pbio.0060311; Kamerbeek J, 1997, J CLIN MICROBIOL, V35, P907; Kato-Maeda M, 2011, INT J TUBERC LUNG D, V15, P131; Kremer K, 2005, J CLIN MICROBIOL, V43, P5628, DOI 10.1128/JCM.43.11.5628-5638.2005; Kremer K, 1999, J CLIN MICROBIOL, V37, P2607; Reyes J., 2011, INFECT GENET EVOL; Reyes JF, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-496; Sebban M, 2002, BIOINFORMATICS, V18, P235, DOI 10.1093/bioinformatics/18.2.235; Shabbeer A., 2011, INFECT GENET EVOL; Sola C, 2001, EMERG INFECT DIS, V7, P390; Sreevatsan S, 1997, P NATL ACAD SCI USA, V94, P9869, DOI 10.1073/pnas.94.18.9869; Streicher EM, 2007, J CLIN MICROBIOL, V45, P237, DOI 10.1128/JCM.01429-06; Supply P, 2000, MOL MICROBIOL, V36, P762, DOI 10.1046/j.1365-2958.2000.01905.x; Supply P, 2006, J CLIN MICROBIOL, V44, P4498, DOI 10.1128/JCM.01392-06; Vitol I, 2006, INFECT GENET EVOL, V6, P491, DOI 10.1016/j.meegid.2006.03.003; Warren RM, 2002, J CLIN MICROBIOL, V40, P4457, DOI 10.1128/JCM.40.12.4457-4465.2002	33	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1567-1348			INFECT GENET EVOL	Infect. Genet. Evol.	JUN	2012	12	4			SI		789	797		10.1016/j.meegid.2012.02.010		9	Infectious Diseases	Infectious Diseases	944QP	WOS:000304219200025	
J	Chen, B; Sheridan, RP; Hornak, V; Voigt, JH				Chen, Bin; Sheridan, Robert P.; Hornak, Viktor; Voigt, Johannes H.			Comparison of Random Forest and Pipeline Pilot Naive Bayes in Prospective QSAR Predictions	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							COMPOUND CLASSIFICATION; MOLECULAR DESCRIPTOR; COMPONENT ANALYSIS; NEURAL-NETWORKS; SIMILARITY; REGRESSION; MODELS; TOOL; SET; SELECTION	Random forest is currently considered one of the best QSAR methods available in terms of accuracy of prediction. However, it is computationally intensive. Naive Bayes is a simple, robust classification method. The Laplacian-modified Naive Bayes implementation is the preferred QSAR method in the widely used commercial chemoinformatics platform Pipeline Pilot. We made a comparison of the ability of Pipeline Pilot Naive Bayes (PLPNB) and random forest to make accurate predictions on 18 large, diverse in-house QSAR data sets. These include on-target and ADME-related activities. These data sets were set up as classification problems with either binary or multicategory activities. We used a time-split method of dividing training and test sets, as we feel this is a realistic way of simulating prospective prediction. PLPNB is computationally efficient. However, random forest predictions are at least as good and in many cases significantly better than those of PLPNB on our data sets. PLPNB performs better with ECFP4 and ECFP6 descriptors, which are native to Pipeline Pilot, and more poorly with other descriptors we tried.	[Sheridan, Robert P.; Hornak, Viktor; Voigt, Johannes H.] Merck Res Labs, Chem Modeling & Informat Dept, Rahway, NJ 07065 USA; [Chen, Bin] Indiana Univ, Sch Informat & Comp, Bloomington, IN 47405 USA	Sheridan, RP (reprint author), Merck Res Labs, Chem Modeling & Informat Dept, Rahway, NJ 07065 USA.	sheridan@merck.com					Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; Arif SM, 2009, J COMPUT AID MOL DES, V23, P655, DOI 10.1007/s10822-009-9285-0; Bender A, 2009, J CHEM INF MODEL, V49, P108, DOI 10.1021/ci800249s; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bruce CL, 2007, J CHEM INF MODEL, V47, P219, DOI [10.1021/ci600332j, 10.1021/ci600322j]; Burden FR, 1999, J MED CHEM, V42, P3183, DOI 10.1021/jm980697n; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Caruana R., 2006, P 23 INT C MACH LEAR; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Golbraikh A, 2002, J COMPUT AID MOL DES, V16, P357, DOI 10.1023/A:1020869118689; Heikamp K, 2011, J CHEM INF MODEL, V51, P1831, DOI 10.1021/ci200199u; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; Kaneko H, 2008, J CHEM INF MODEL, V48, P534, DOI 10.1021/ci700245f; Kearsley SK, 1996, J CHEM INF COMP SCI, V36, P118, DOI 10.1021/ci950274j; Klon AE, 2006, J CHEM INF MODEL, V46, P1945, DOI 10.1021/ci0601315; Leonard JT, 2006, QSAR COMB SCI, V25, P235, DOI 10.1002/qsar.200510161; Livingstone DJ, 2005, J MED CHEM, V48, P661, DOI 10.1021/jm049111p; Lombardo F, 2004, J MED CHEM, V47, P1242, DOI 10.1021/jm030408h; Michielan L, 2010, J CHEM INF MODEL, V50, P961, DOI 10.1021/ci100072z; Mosier PD, 2002, J CHEM INF COMP SCI, V42, P1460, DOI 10.1021/ci020039i; Nantasenamat C, 2010, EXPERT OPIN DRUG DIS, V5, P633, DOI 10.1517/17460441.2010.492827; Nidhi, 2006, J CHEM INF MODEL, V46, P1124, DOI 10.1021/ci060003g; NILAKANTAN R, 1987, J CHEM INF COMP SCI, V27, P82, DOI 10.1021/ci00054a008; Obrezanova O, 2010, J CHEM INF MODEL, V50, P1053, DOI 10.1021/ci900406x; Paolini GV, 2006, NAT BIOTECHNOL, V24, P805, DOI 10.1038/nbt1228; Prathipati P, 2008, J CHEM INF MODEL, V48, P2362, DOI 10.1021/ci800143n; Randic M, 2001, J CHEM INF COMP SCI, V41, P602, DOI 10.1021/ci000106d; Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t; Rogers D, 2005, J BIOMOL SCREEN, V10, P682, DOI 10.1177/1087057105281365; Sheridan RP, 2004, J CHEM INF COMP SCI, V44, P1912, DOI 10.1021/ci049782w; Sheridan RP, 2008, J CHEM INF MODEL, V48, P426, DOI 10.1021/ci700380x; Sprous DG, 2010, CURR TOP MED CHEM, V10, P619; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Vapnik V., 1998, STAT LEARNING THEORY; Vogt M, 2008, J CHEM INF MODEL, V48, P247, DOI 10.1021/ci700333t; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P109, DOI 10.1016/S0169-7439(01)00155-1; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Zhang H., FLAIRS 2004 C	40	8	8	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAR	2012	52	3					792	803		10.1021/ci200615h		12	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	913NJ	WOS:000301884400014	
J	Sullivan, JC; Mitchinson, B; Pearson, MJ; Evans, M; Lepora, NF; Fox, CW; Melhuish, C; Prescott, TJ				Sullivan, J. Charles; Mitchinson, Ben; Pearson, Martin J.; Evans, Mat; Lepora, Nathan F.; Fox, Charles W.; Melhuish, Chris; Prescott, Tony J.			Tactile Discrimination Using Active Whisker Sensors	IEEE SENSORS JOURNAL			English	Article						Bayesian methods; biomimetics; classification algorithms; robotics; sensor systems and applications; tactile sensors	ROUGHNESS DISCRIMINATION; RHYTHMIC WHISKING; RAT-VIBRISSAE; BEHAVIOR; CONTACT; SYSTEM; TOUCH; EXPLORATION; MOVEMENTS; ROBOT	We describe a novel, biomimetic tactile sensing system modeled on the facial whiskers (vibrissae) of animals such as rats and mice. The "BIOTACT Sensor" consists of a conical array of modular, actuated hair-like elements, each instrumented at the base to accurately detect deflections of the shaft by whisker-surface contacts. A notable characteristic of this array is that, like the biological sensory system it mimics, the whiskers are moved back-and-forth ("whisked") so as to make repeated, brief contacts with surfaces of interest. Furthermore, these movements are feedback-modulated in a manner intended to emulate some of the "active sensing" control strategies observed in whiskered animals. We show that accurate classification of surface texture using data obtained from whisking against three different surfaces is achievable using classifiers based on either naive Bayes or template methods. Notably, the performance of both these approaches to classify textures after training on as few as one or two surface contacts was improved when the whisking motion was controlled using a sensory feedback mechanism. We conclude that active vibrissal sensing could likewise be a useful sensory capacity for autonomous robots.	[Sullivan, J. Charles; Pearson, Martin J.; Melhuish, Chris] Univ W England, Bristol Robot Lab, Bristol BS16 1QD, Avon, England; [Mitchinson, Ben; Evans, Mat; Lepora, Nathan F.; Fox, Charles W.; Prescott, Tony J.] Univ Sheffield, Dept Psychol, Sheffield S10 2TP, S Yorkshire, England	Sullivan, JC (reprint author), Univ W England, Bristol Robot Lab, Bristol BS16 1QD, Avon, England.	charlie.sullivan@brl.ac.uk; b.mitchinson@sheffield.ac.uk; martin.pearson@brl.ac.uk; Mat.Evans@sheffield.ac.uk; n.lepora@sheffield.ac.uk; charles.fox@gmail.com; chris.melhuish@brl.ac.uk; t.j.prescott@sheffield.ac.uk	Prescott, Tony/A-7574-2008; Evans, Mathew/D-2912-2013	Prescott, Tony/0000-0003-4927-5390; Evans, Mathew/0000-0002-6873-0654	European Union [ICT-215910]	This work was supported by the European Union FP7 BIOTACT Project (ICT-215910). The associate editor coordinating the review of this paper and approving it for publication was Prof. Raul Martin-Palma.	Ahissar E, 2008, BIOL CYBERN, V98, P449, DOI 10.1007/s00422-008-0214-4; AHL AS, 1986, VET RES COMMUN, V10, P245, DOI 10.1007/BF02213989; Anderson S. E., 2010, IEEE T ROBOTICS, P1, DOI 10.3109/17477161003728477; Anjum F, 2006, P NATL ACAD SCI USA, V103, P16544, DOI 10.1073/pnas.0605573103; BAJCSY R, 1988, P IEEE, V76, P996; Berg RW, 2003, J NEUROPHYSIOL, V89, P104, DOI 10.1152/jn.00600.2002; Brecht M, 1997, BEHAV BRAIN RES, V84, P81, DOI 10.1016/S0166-4328(97)83328-1; CARVELL GE, 1990, J NEUROSCI, V10, P2638; DIAMOND M, 2008, PLOS BIOL, V6; EVANS M, 2010, P IEEE INT C ROB BIO, P720; EVANS M, 2010, LECT NOTES ARTIF INT, P178; Evans M. H., 2009, P AUT ROB SYST TAROS, P19; Flandrin P., 2003, APPL TIME FREQUENCY, P179; Fox C, 2009, AUTON ROBOT, V26, P223, DOI 10.1007/s10514-009-9109-z; Gao PH, 2001, J NEUROSCI, V21, P5374; Grant RA, 2009, J NEUROPHYSIOL, V101, P862, DOI 10.1152/jn.90783.2008; GUICROBLES E, 1992, BEHAV BRAIN RES, V48, P145, DOI 10.1016/S0166-4328(05)80150-0; GUICROBLES E, 1989, BEHAV BRAIN RES, V31, P285, DOI 10.1016/0166-4328(89)90011-9; Hartmann MJ, 2003, J NEUROSCI, V23, P6510; Hill DN, 2008, J NEUROSCI, V28, P3438, DOI 10.1523/JNEUROSCI.5008-07.2008; Hipp J, 2006, J NEUROPHYSIOL, V95, P1792, DOI 10.1152/jn.01104.2005; Kaneko M, 1998, IEEE T ROBOTIC AUTOM, V14, P278, DOI 10.1109/70.681246; Lamperski AG, 2005, IEEE INT CONF ROBOT, P3838; LEDERMAN SJ, 1993, ACTA PSYCHOL, V84, P29, DOI 10.1016/0001-6918(93)90070-8; LEPORA NF, 2010, P IEEE IJCNN APR 27, P1; LEPORA NF, 2010, P IEEE ROBIO 10, P131; Mitchinson B, 2010, ADV ENG INFORM, V24, P49, DOI 10.1016/j.aei.2009.08.002; MITCHINSON B, 2011, NEUROMORPHI IN PRESS; Mitchinson B, 2004, P ROY SOC B-BIOL SCI, V271, P2509, DOI 10.1098/rspb.2004.2882; Mitchinson B, 2007, P R SOC B, V274, P1035, DOI 10.1098/rspb.2006.0347; MITCHINSON B, 2006, P 9 INT C SIM AD BEH, V9, P77; Pearson MJ, 2007, ADAPT BEHAV, V15, P223, DOI 10.1177/1059712307082089; Pearson MJ, 2010, LECT NOTES ARTIF INT, V6226, P93, DOI 10.1007/978-3-642-15193-4_9; PRESCOTT T, 2011, VIBRISSAL BEHAV FUNC; Prescott TJ, 2009, IEEE ROBOT AUTOM MAG, V16, P42, DOI 10.1109/MRA.2009.933624; Towal RB, 2006, J NEUROSCI, V26, P8838, DOI 10.1523/JNEUROSCI.0581-06.2006; Towal RB, 2008, J NEUROPHYSIOL, V100, P740, DOI 10.1152/jn.01295.2007; Williams CM, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008806; Wolfe J, 2008, PLOS BIOL, V6, P1661, DOI 10.1371/journal.pbio.0060215	39	8	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1530-437X			IEEE SENS J	IEEE Sens. J.	FEB	2012	12	2					350	362		10.1109/JSEN.2011.2148114		13	Engineering, Electrical & Electronic; Instruments & Instrumentation; Physics, Applied	Engineering; Instruments & Instrumentation; Physics	858XW	WOS:000297837600011	
J	Freitas, AA; Vasieva, O; de Magalhaes, JP				Freitas, Alex A.; Vasieva, Olga; de Magalhaes, Joao Pedro			A data mining approach for classifying DNA repair genes into ageing-related or non-ageing-related	BMC GENOMICS			English	Article							DOUBLE-STRAND BREAKS; END JOINING NHEJ; CELLULAR SENESCENCE; DOWNS-SYNDROME; AUTOIMMUNITY; MECHANISMS; LONGEVITY; NETWORKS; PROTEINS; GENETICS	Background: The ageing of the worldwide population means there is a growing need for research on the biology of ageing. DNA damage is likely a key contributor to the ageing process and elucidating the role of different DNA repair systems in ageing is of great interest. In this paper we propose a data mining approach, based on classification methods (decision trees and Naive Bayes), for analysing data about human DNA repair genes. The goal is to build classification models that allow us to discriminate between ageing-related and non-ageing-related DNA repair genes, in order to better understand their different properties. Results: The main patterns discovered by the classification methods are as follows: (a) the number of protein-protein interactions was a predictor of DNA repair proteins being ageing-related; (b) the use of predictor attributes based on protein-protein interactions considerably increased predictive accuracy of attributes based on Gene Ontology (GO) annotations; (c) GO terms related to "response to stimulus" seem reasonably good predictors of ageing-relatedness for DNA repair genes; (d) interaction with the XRCC5 (Ku80) protein is a strong predictor of ageing-relatedness for DNA repair genes; and (e) DNA repair genes with a high expression in T lymphocytes are more likely to be ageing-related. Conclusions: The above patterns are broadly integrated in an analysis discussing relations between Ku, the non-homologous end joining DNA repair pathway, ageing and lymphocyte development. These patterns and their analysis support non-homologous end joining double strand break repair as central to the ageing-relatedness of DNA repair genes. Our work also showcases the use of protein interaction partners to improve accuracy in data mining methods and our approach could be applied to other ageing-related pathways.	[Freitas, Alex A.; de Magalhaes, Joao Pedro] Univ Liverpool, Inst Integrat Biol, Integrat Genom Ageing Grp, Liverpool L69 7ZB, Merseyside, England; [Freitas, Alex A.] Univ Kent, Sch Comp, Canterbury CT2 7NF, Kent, England; [Freitas, Alex A.] Univ Kent, Ctr BioMed Informat, Canterbury CT2 7NF, Kent, England; [Vasieva, Olga] Univ Liverpool, Inst Integrat Biol, Liverpool L69 7ZB, Merseyside, England	de Magalhaes, JP (reprint author), Univ Liverpool, Inst Integrat Biol, Integrat Genom Ageing Grp, Biosci Bldg,Crown St, Liverpool L69 7ZB, Merseyside, England.	jp@senescence.info	de Magalhaes, Joao Pedro/B-4741-2010; Freitas, Alex/H-1249-2011		BBSRC [BB/G024774/1, BB/H008497/1]; Ellison Medical Foundation; EC	We thank Dr. Fernando Otero for his help in the use of software for computing the set of all GO terms that are ancestors of a specific set of GO terms, in the procedure used for the creation of the GO term-based attributes. JPM thanks the BBSRC (BB/G024774/1 & BB/H008497/1), the Ellison Medical Foundation and a Marie Curie International Reintegration Grant within EC-FP7 for supporting work in his lab.	[Anonymous], 2005, NATURE, V437, P69, DOI 10.1038/nature04072; Ariyoshi K, 2007, J RADIAT RES, V48, P219, DOI 10.1269/jrr.07017; Arking R, 2006, BIOL AGING OBSERVATI; Beneke S, 2007, NUCLEIC ACIDS RES, V35, P7456, DOI 10.1093/nar/gkm735; Best BP, 2009, REJUV RES, V12, P199, DOI 10.1089/rej.2009.0847; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Budovsky A, 2007, MECH AGEING DEV, V128, P117, DOI 10.1016/j.mad.2006.11.018; Burma S, 2006, DNA REPAIR, V5, P1042, DOI 10.1016/j.dnarep.2006.05.026; Chautard E, 2010, BIOGERONTOLOGY, V11, P463, DOI 10.1007/s10522-010-9268-5; Cristianini N., 2000, INTRO SUPPORT VECTOR; de Magalhaes JP, 2004, FEBS LETT, V571, P243, DOI 10.1016/j.febslet.2004.07.006; de Magalhaes JP, 2009, AGING CELL, V8, P65, DOI 10.1111/j.1474-9726.2008.00442.x; de Magalhaes JP, 2005, AGEING RES REV, V4, P1, DOI 10.1016/j.arr.2004.05.003; Ferrarini L, 2005, BIOINFORMATICS, V21, P338, DOI 10.1093/bioinformatics/bti004; Freitas AA, 2010, IEEE ACM T COMPUT BI, V7, P172, DOI 10.1109/TCBB.2008.47; Friedberg E, 2006, DNA REPAIR MUTAGENES; Prasad TSK, 2009, NUCLEIC ACIDS RES, V37, pD767, DOI 10.1093/nar/gkn892; Harris MA, 2004, NUCLEIC ACIDS RES, V32, pD258, DOI 10.1093/nar/gkh036; Hasty P, 2004, AGING CELL, V3, P55, DOI 10.1111/j.1474-9728.2004.00082.x; Hasty P, 2003, SCIENCE, V299, P1355, DOI 10.1126/science.1079161; Hosaka N, 1996, P NATL ACAD SCI USA, V93, P8558, DOI 10.1073/pnas.93.16.8558; HRUZ T, 2008, BIOINFORMATICS; James SE, 2000, MECH AGEING DEV, V121, P139; Ju YJ, 2006, EXP MOL MED, V38, P686; Karlsson B, 1998, ARCH DIS CHILD, V79, P242; Kenyon CJ, 2010, NATURE, V464, P504, DOI 10.1038/nature08980; Kipling D, 2004, SCIENCE, V305, P1426, DOI 10.1126/science.1102587; MOMBAERTS P, 1992, CELL, V68, P869, DOI 10.1016/0092-8674(92)90030-G; Prelog M, 2006, AUTOIMMUN REV, V5, P136, DOI 10.1016/j.autrev.2005.09.008; Promislow DEL, 2004, P ROY SOC B-BIOL SCI, V271, P1225, DOI 10.1098/rspb.2004.2732; RABINOWE SL, 1989, J AUTOIMMUN, V2, P25, DOI 10.1016/0896-8411(89)90105-4; Rassool FV, 2003, CANCER LETT, V193, P1, DOI 10.1016/S0304-3835(02)00692-4; Seluanov A, 2007, DNA REPAIR, V6, P1740, DOI 10.1016/j.dnarep.2007.06.010; Szafron D, 2004, NUCLEIC ACIDS RES, V32, pW365, DOI 10.1093/nar/gkh485; TACUTU R, 2010, REJUV RES, V13, P30; VONDERVEN M, 2006, PLOS GENET, V2, P2013; Witten IH, 2005, DATA MINING PRACTICA; Wood RD, 2001, SCIENCE, V291, P1284, DOI 10.1126/science.1056154; Wood RD, 2005, MUTAT RES-FUND MOL M, V577, P275, DOI 10.1016/j.mrfmmm.2005.03.007	39	8	9	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics	JAN 12	2011	12								27	10.1186/1471-2164-12-27		11	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	713IB	WOS:000286729600001	
J	Suenderhauf, C; Hammann, F; Maunz, A; Helma, C; Huwyler, J				Suenderhauf, Claudia; Hammann, Felix; Maunz, Andreas; Helma, Christoph; Huwyler, Joerg			Combinatorial QSAR Modeling of Human Intestinal Absorption	MOLECULAR PHARMACEUTICS			English	Article						QSAR; intestinal drug absorption; molecular modeling; machine learning; decision tree induction; artificial neural network; support vector machines; naive Bayes; receiver operating characteristics	SUPPORT VECTOR MACHINE; HUMAN ORAL ABSORPTION; MOLECULAR-SURFACE PROPERTIES; DRUG ABSORPTION; P-GLYCOPROTEIN; IN-VIVO; COMPUTATIONAL PREDICTION; TOPOLOGICAL DESCRIPTORS; ADME EVALUATION; PERMEABILITY	Intestinal drug absorption in humans is a central topic in drug discovery. In this study, we use a broad selection of machine learning and statistical methods for the classification and numerical prediction of this key end point. Our data set is based on a selection of 458 small,druglike compounds with FDA approval. Using easily available tools, we calculated one- to three-dimensional physicochemical descriptors and used various methods of feature selection (best-first backward selection, correlation analysis, and decision tree analysis). We then used decision free induction (DTI), fragment-based lazy-learning (LAZAR), support vector machine classification, multilayer perceptrons, random forests, k-nearest neighbor and Naive Bayes analysis to model absorption ratios and binary classification (well-absorbed and poorly absorbed compounds). Best performance for classification was seen with DTI using the chi-squared analysis interaction detector (CHAID) algorithm, yielding corrected classification rate of 88% (Matthews correlation coefficient of 75%). In numeric predictions, the multilayer perceptron performed best, achieving a root mean squared error of 25.823 and a coefficient of determination of 0.6. In line with current understanding is the importance of descriptors such as lipophilic partition coefficients (log P) and hydrogen bonding. However, we are able to highlight the utility of gravitational indices and moments of inertia, reflecting the role of structural symmetry in oral absorption. Our models are based on a diverse data set of marketed drugs representing a broad chemical space. These models therefore contribute substantially to the molecular understanding of human intestinal drug absorption and qualify for a generalized use in drug discovery and lead optimization.	[Huwyler, Joerg] Univ Basel, Inst Pharmaceut Technol, Div Pharmaceut Technol, Dept Pharmaceut Sci, CH-4056 Basel, Switzerland; [Maunz, Andreas; Helma, Christoph] Univ Freiburg, Freiburger Zentrum Datenanal & Modellbildung, D-70104 Freiburg, Germany; [Helma, Christoph] In Silico Toxicol, CH-4054 Basel, Switzerland	Huwyler, J (reprint author), Univ Basel, Inst Pharmaceut Technol, Div Pharmaceut Technol, Dept Pharmaceut Sci, Klingelbergstr 50, CH-4056 Basel, Switzerland.	joerg.huwyler@unibas.ch	Hammann, Felix/E-8623-2011; Huwyler, Joerg/C-6573-2013; Hammann, Felix/H-8760-2013	Hammann, Felix/0000-0003-0658-9330; 	EU [Health-F5-2008-203787]; Swiss National Foundation [323530-119218]	Andreas Maunz and Christoph Helma are supported by the EU FP7 Project OpenTox 224 MOLECULAR PHARMACEUTICS (Contract Number Health-F5-2008-203787). Claudia Suenderhauf is supported by the Swiss National Foundation (Grant No. 323530-119218).	Aizerman M., 1964, AUTOMAT REM CONTR, V25, P821; Bai JPF, 2004, J CHEM INF COMP SCI, V44, P2061, DOI 10.1021/ci040023n; BAYES T, 1763, PHILOS T R SOC LONDO, V53, P13; Benet LZ, 2009, MOL PHARMACEUT, V6, P1631, DOI 10.1021/mp900253n; Brandsch M, 2008, J PHARM PHARMACOL, V60, P543, DOI 10.1211/jpp.60.5.0002; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 1984, CLASSIFICATION REGRE; Christians Uwe, 2005, Expert Opin Drug Metab Toxicol, V1, P641, DOI 10.1517/17425255.1.4.641; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Dahan A, 2009, MOL PHARMACEUT, V6, P19, DOI 10.1021/mp800088f; Deconinck E, 2005, J PHARMACEUT BIOMED, V39, P91, DOI 10.1016/j.jpba.2005.03.008; DOLLERY C, 1999, THERAPEUTIC DRUGS, pC349; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Ertl P, 2000, J MED CHEM, V43, P3714, DOI 10.1021/jm000942e; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fricker G, 1996, BRIT J PHARMACOL, V118, P1841; Grass GM, 2001, DRUG DISCOV TODAY, V6, pS54; Guerra A, 2010, EUR J MED CHEM, V45, P930, DOI 10.1016/j.ejmech.2009.11.034; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Hammann F, 2010, CLIN PHARMACOL THER, V88, P52, DOI 10.1038/clpt.2009.248; Hammann F, 2009, MOL PHARMACEUT, V6, P1920, DOI 10.1021/mp900217x; Hassinen T, 2001, J COMPUT CHEM, V22, P1229, DOI 10.1002/jcc.1080; Helma C, 2006, MOL DIVERS, V10, P147, DOI 10.1007/s11030-005-9001-5; Hou TJ, 2007, J CHEM INF MODEL, V47, P2408, DOI 10.1021/ci7002076; Hou TJ, 2009, COMB CHEM HIGH T SCR, V12, P497; Hou TJ, 2007, J CHEM INF MODEL, V47, P208, DOI 10.1021/ci600343x; Huwyler J, 2006, CURR DRUG METAB, V7, P119, DOI 10.2174/138920006775541534; Iyer M, 2007, MOL PHARM, V4, P218, DOI 10.1021/mp0600900; KARARLI TT, 1995, BIOPHARM DRUG DISPOS, V16, P351, DOI 10.1002/bdd.2510160502; Kerns EH, 2008, DRUG-LIKE PROPERTIES: CONCEPTS, STRUCTURE DESIGN AND METHODS, P1; Jones R, 2005, J CHEM INF MODEL, V45, P1337, DOI 10.1021/ci049653f; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; KUIJPERS MHM, 1986, J HYPERTENS, V4, pS41; Linnankoski J, 2006, J MED CHEM, V49, P3674, DOI 10.1021/jm051231p; Lipinski CA, 2001, ADV DRUG DELIVER REV, V46, P3, DOI 10.1016/S0169-409X(00)00129-0; Lipinski CA, 2000, J PHARMACOL TOXICOL, V44, P235, DOI 10.1016/S1056-8719(00)00107-6; Liu HX, 2005, J COMPUT AID MOL DES, V19, P33, DOI 10.1007/s10822-005-0095-8; Macheras P., 1995, BIOPHARMACEUTICS ORA; Manallack DT, 2003, J CHEM INF COMP SCI, V43, P674, DOI 10.1021/ci0202741; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Meredith D, 2006, J MEMBRANE BIOL, V213, P79, DOI 10.1007/s00232-006-0876-6; Metcalfe PD, 2010, CURR OPIN DRUG DISC, V13, P104; Niwa T, 2003, J CHEM INF COMP SCI, V43, P113, DOI 10.1021/ci020013r; Norinder U, 1997, PHARMACEUT RES, V14, P1786, DOI 10.1023/A:1012196216736; Obrezanova O, 2010, J CHEM INF MODEL, V50, P1053, DOI 10.1021/ci900406x; Palm K, 1996, J PHARM SCI, V85, P32, DOI 10.1021/js950285r; Palm K, 1997, PHARMACEUT RES, V14, P568, DOI 10.1023/A:1012188625088; Pearlman RS, 1999, J CHEM INF COMP SCI, V39, P28, DOI 10.1021/ci980137x; Reynolds DP, 2009, J PHARM SCI-US, V98, P4039, DOI 10.1002/jps.21730; Russel S., 2002, ARTIFICIAL INTELLIGE; Shen J, 2010, J CHEM INF MODEL, V50, P1034, DOI 10.1021/ci100104j; Sonquist J. A., 1964, DETECTION INTERACTIO, P296; Steinbeck C, 2003, J CHEM INF COMP SCI, V43, P493, DOI 10.1021/ci025584y; Votano JR, 2004, MOL DIVERS, V8, P379, DOI 10.1023/B:MODI.0000047512.82293.75; Wang Z, 2008, EUR J MED CHEM, V43, P2442, DOI 10.1016/j.ejmech.2008.05.017; Willett P, 2006, DRUG DISCOV TODAY, V11, P1046, DOI 10.1016/j.drudis.2006.10.005; Winiwarter S, 2003, J MOL GRAPH MODEL, V21, P273, DOI 10.1016/S1093-3263(02)00163-8; Winiwarter S, 1998, J MED CHEM, V41, P4939, DOI 10.1021/jm9810102; Yan AX, 2008, INT J MOL SCI, V9, P1961, DOI 10.3390/ijms9101961; YOUDEN WJ, 1950, CANCER, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3; Zhang H, 2004, P 17 FLOR ART INT RE, P562; Zhao YH, 2001, J PHARM SCI-US, V90, P749, DOI 10.1002/jps.1031; Zhao YH, 2002, PHARM RES-DORDR, V19, P1446, DOI 10.1023/A:1020444330011; Zimmermann C, 2005, DRUG METAB DISPOS, V33, P219, DOI 10.1124/dmd.104.001354	64	8	8	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1543-8384			MOL PHARMACEUT	Mol. Pharm.	JAN-FEB	2011	8	1					213	224		10.1021/mp100279d		12	Pharmacology & Pharmacy	Pharmacology & Pharmacy	715UZ	WOS:000286915000021	
J	Aubanel, V; Nguyen, N				Aubanel, Vincent; Nguyen, Noel			Automatic recognition of regional phonological variation in conversational interaction	SPEECH COMMUNICATION			English	Article						Conversational interaction; Regional phonological and phonetic variation; Automatic speech processing; French; Sociophonetics	SOCIAL DESIRABILITY; SPEECH RECOGNITION; PERCEPTION; LANGUAGE; DIALECT; FRENCH; CONVERGENCE; ACCENT; CORPUS; SCALE	One key aspect of face-to-face communication concerns the differences that may exist between speakers' native regional accents. This paper focuses on the characterization of regional phonological variation in a conversational setting. A new, interactive task was designed in which 12 pairs of participants engaged in a collaborative game leading them to produce a number of purpose-built names. In each game, the participants were native speakers of Southern French and Northern French, respectively. How the names were produced by each of the two participants was automatically determined from the recordings using ASR techniques and a pre-established set of possible regional variants along five phonological dimensions. A naive Bayes classifier was then applied to these phonetic forms, with a view to differentiating the speakers' native regional accents. The results showed that native regional accent was correctly recognized for 79% of the speakers. These results also revealed or confirmed the existence of accent-dependent differences in how segments are phonetically realized, such as the affrication of /d/ in /di/ sequences. Our data allow us to better characterize the phonological and phonetic patterns associated with regional varieties of French on a large scale and in a natural, interactional situation. (C) 2010 Elsevier B.V. All rights reserved.	[Aubanel, Vincent] CNRS, Lab Parole & Langage, F-13100 Aix En Provence, France; Aix Marseille Univ, F-13100 Aix En Provence, France	Aubanel, V (reprint author), CNRS, Lab Parole & Langage, 5 Ave Pasteur, F-13100 Aix En Provence, France.	vincent.aubanel@lpl-aix.fr; noel.nguyen@lpl-aix.fr			Region Provence-Alpes-Cote d'Azur;  [ANR-08-BLAN-0276-01]	This work was supported by a Ph.D. Scholarship awarded to the first author by the Region Provence-Alpes-Cote d'Azur, and by the project ANR-08-BLAN-0276-01. We are grateful to Stephane Rauzy for statistical advice and to the staff and students of the lycee Thiers, Marseille, for their kind participation. We also thank two anonymous reviewers for helpful comments.	Adda-Decker M, 2007, REV FR LING APPL, V12, P71; Adda-Decker M, 1999, SPEECH COMMUN, V29, P83, DOI 10.1016/S0167-6393(99)00032-1; Adda-Decker M., 2008, TRAITEMENT AUTOMATIQ, V49-3, P13; ANDERSON AH, 1991, LANG SPEECH, V34, P351; Bertrand R., 2008, TRAITEMENT AUTOMATIQ, V49, P105; Binisti N., 2003, CAHIERS FRANCAIS CON, V8, P107; Boula de Mareuil P., 2008, TRAITEMENT AUTOMATIQ, V49, P135; Bradlow A. R., 2007, J ACOUSTICAL SOC A 2, V121, P3072; Brunelliere A, 2009, COGNITION, V111, P390, DOI 10.1016/j.cognition.2009.02.013; CARTON FERNAND, 1983, ACCENTS FRANCAIS; Clopper CG, 2008, LANG SPEECH, V51, P175, DOI 10.1177/0023830908098539; Conrey B, 2005, BRAIN LANG, V95, P435, DOI 10.1016/j.bandl.2005.06.008; Coveney Aidan, 2001, SOUNDS CONT FRENCH A; CROWNE DP, 1960, J CONSULT PSYCHOL, V24, P349, DOI 10.1037/h0047358; Cutler A, 2005, SPEECH COMMUN, V47, P32, DOI 10.1016/j.specom.2005.02.001; Delvaux V, 2007, PHONETICA, V64, P145, DOI 10.1159/000107914; Dufour S., 2007, J ACOUST SOC AM, V121, P131; DURAND J, 1988, RECHERCHES LINGUISTI, V17, P29; Durand J., 2003, TRIBUNE INT LANGUES, V33, P3; Durand J., 2003, CORPUS VARIATION PHO, P11; Durand Jacques, 1990, GENERATIVE NONLINEAR; Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413; Eychenne J., 2006, THESIS U TOULOUSE LE; Fagyal-Le Mentec Z, 2006, FRENCH: A LINGUISTIC INTRODUCTION, P17, DOI 10.1017/CBO9780511791185.003; FAGYAL Z, 2002, P 24 JOURN ET PAR NA, P165; Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276; FONAGY I, 1989, REV ROMANE, V24, P225; Hansen Anita Berit, 2001, LINGUISTIQUE, V37, P33; Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014; Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013; LENNOX RD, 1984, J PERS SOC PSYCHOL, V46, P1349, DOI 10.1037/0022-3514.46.6.1349; Lyche Chantal, 2004, VARIATION FRANCOPHON, P217; MALECOT A, 1976, PHONETICA, V33, P45; MARLOWE D, 1961, J CONSULT PSYCHOL, V25, P100; MARTINET A, 1958, ROMANCE PHILOL, V11, P345; Martinet Andre, 1945, PRONONCIATION FRANCA; NATALE M, 1975, J PERS SOC PSYCHOL, V32, P790, DOI 10.1037/0022-3514.32.5.790; New B, 2004, BEHAV RES METH INS C, V36, P516, DOI 10.3758/BF03195598; Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720; Racine Isabelle, 2008, THESIS U GENEVE; Scharenborg O, 2007, SPEECH COMMUN, V49, P336, DOI 10.1016/j.specom.2007.01.009; SNYDER M, 1974, J PERS SOC PSYCHOL, V30, P526, DOI 10.1037/h0037039; Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001; TRIMAILLE C, 2008, AFLS C OXF 3 5 SEPT; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; VANRULLEN T, 2005, P TRAIT AUT LANG NAT; WOEHRLING C, 2009, THESIS U PARIS SUD	47	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393			SPEECH COMMUN	Speech Commun.	JUN	2010	52	6			SI		577	586		10.1016/j.specom.2010.02.008		10	Acoustics; Communication; Computer Science, Interdisciplinary Applications; Language & Linguistics	Acoustics; Communication; Computer Science; Linguistics	604MB	WOS:000278282000011	
J	McKeever, S; Ye, JA; Coyle, L; Bleakley, C; Dobson, S				McKeever, Susan; Ye, Juan; Coyle, Lorcan; Bleakley, Chris; Dobson, Simon			Activity recognition using temporal evidence theory	JOURNAL OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS			English	Article						Context reasoning; activity recognition; evidence theory; Dempster-Shafer theory; temporal; smart home dataset; time	ENVIRONMENTS; UNCERTAINTY; INFORMATION; MANAGEMENT; HOME	The ability to identify the behavior of people in a home is at the core of Smart Home functionality. Such environments are equipped with sensors that unobtrusively capture information about the occupants. Reasoning mechanisms transform the technical, frequently noisy data of sensors into meaningful interpretations of occupant activities. Time is a natural human way to reason about activities. Peoples' activities in the home often have an identifiable routine; activities take place at distinct times throughout the day and last for predicable lengths of time. However, the inclusion of temporal information is still limited in the domain of activity recognition. Evidence theory is gaining increasing interest in the field of activity recognition, and is suited to the incorporation of time related domain knowledge into the reasoning process. In this paper, an evidential reasoning framework that incorporates temporal knowledge is presented. We evaluate the effectiveness of the framework using a third party published smart home dataset. An improvement in activity recognition of 70% is achieved when time patterns and activity durations are included in activity recognition. We also compare our approach with Naive Bayes classifier and J48 Decision Tree, with temporal evidence theory achieving higher accuracies than both classifiers.	[McKeever, Susan; Bleakley, Chris] Univ Coll Dublin, Syst Res Grp, Sch Comp Sci & Informat, Dublin 4, Ireland; [Ye, Juan; Dobson, Simon] Univ St Andrews, Sch Comp Sci, St Andrews KY16 9AJ, Fife, Scotland	McKeever, S (reprint author), Univ Coll Dublin, Syst Res Grp, Sch Comp Sci & Informat, Dublin 4, Ireland.	susan.mckeever@ucd.ie			Irish Higher Education Authority [R10891]; Science Foundation Ireland [03/CE2/I303_1]	This work was supported in part by the Irish Higher Education Authority under Grant R10891 to the "Nembes: Networked Embedded Systems in Built Environments" project and by Science Foundation Ireland Grant 03/CE2/I303_1 to "Lero - the Irish Software Engineering Research Centre".	Allen J. E., 1994, Journal of Logic and Computation, V4, DOI 10.1093/logcom/4.5.531; Augusto JC, 2008, INT J COMPUT INT SYS, V1, P361; Choujaa D, 2009, LECT NOTES COMPUT SC, V5561, P19, DOI 10.1007/978-3-642-01721-6_2; Clarkson B., 2000, WEAR COMP IEEE INT S, V0, P69; Cook DJ, 2009, PERVASIVE MOB COMPUT, V5, P277, DOI 10.1016/j.pmcj.2009.04.001; Dey AK, 2009, J AMB INTEL SMART EN, V1, P57, DOI 10.3233/AIS-2009-0008; Guan DH, 2006, LECT NOTES ARTIF INT, V4114, P63; Hong X, 2009, STUD COMPUT INTELL, V189, P315; Hong X, 2009, PERVASIVE MOB COMPUT, V5, P236, DOI 10.1016/j.pmcj.2008.05.002; Intille SS, 2006, LECT NOTES COMPUT SC, V3968, P349; Jakkula VR, 2009, ADVANCED INTELLIGENT ENVIRONMENTS, P175, DOI 10.1007/978-0-387-76485-6_8; JAKKULA VR, 2007, USING TEMPORAL RELAT; Korpipaa P, 2003, IEEE PERVAS COMPUT, V2, P42, DOI 10.1109/MPRV.2003.1228526; Loke SW, 2004, KNOWL ENG REV, V19, P213, DOI [10.1017/S0269888905000263, 10.1017/s0269888905000263]; LOWRANCE JD, 1990, READINGS UNCERTAIN R, P611; McKeever S, 2009, LECT NOTES COMPUTER, V5786; McKeever S, 2009, LECT NOTES COMPUT SC, V5741, P149, DOI 10.1007/978-3-642-04471-7_12; Modayil J., 2008, UBICOMP 08, P40; Murphy CK, 2000, DECIS SUPPORT SYST, V29, P1, DOI 10.1016/S0167-9236(99)00084-6; Palmes P, 2010, PERVASIVE MOB COMPUT, V6, P43, DOI 10.1016/j.pmcj.2009.10.004; PARTRIDGE K, 2008, UBICOMP 08, P144; Ranganathan A, 2004, IEEE PERVAS COMPUT, V3, P62, DOI 10.1109/MPRV.2004.1316821; Sarkar AMJ, 2010, IETE TECH REV, V27, P107, DOI 10.4103/0256-4602.60164; Sentz K, 2002, SAND20020835 SAND NA; Shafer G., 1976, MATH THEORY EVIDENCE; Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158; VANKASTEREN E, 2008, P 10 INT C UB COMP S; Wang L, 2009, LECT NOTES COMPUT SC, V5859, P78; Witten IH, 2005, DATA MINING PRACTICA; Wu H, 2002, P IEEE INSTR MEAS TE; YE J, 2010, P PERV 2010 IN PRESS; Ye J., 2009, P 20 C ART INT COGN, P274; YE J, 2008, REV INTELLIGENCE ART, V22; YE J, 2008, THESIS U COLLEGE DUB; Zadeh L.A., 1986, AI MAG, V7, P85; Zhang DQ, 2010, FUTURE GENER COMP SY, V26, P207, DOI 10.1016/j.future.2009.08.005; Zheng VW, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P61	37	8	9	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1876-1364			J AMB INTEL SMART EN	J. Ambient Intell. Smart Environ.		2010	2	3					253	269		10.3233/AIS-2010-0071		17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	722SR	WOS:000287455400005	
J	Rabal, O; Link, W; Serelde, BG; Bischoff, JR; Oyarzabal, J				Rabal, Obdulia; Link, Wolfgang; Serelde, Beatriz G.; Bischoff, James R.; Oyarzabal, Julen			An integrated one-step system to extract, analyze and annotate all relevant information from image-based cell screening of chemical libraries	MOLECULAR BIOSYSTEMS			English	Article							DRUG DISCOVERY; INHIBITORS; CLASSIFICATION; IDENTIFICATION; SELECTION; PTEN	Here we report the development and validation of a complete solution to manage and analyze the data produced by image-based phenotypic screening campaigns of small-molecule libraries. In one step initial crude images are analyzed for multiple cytological features, statistical analysis is performed and molecules that produce the desired phenotypic pro. le are identified. A naive Bayes classifier, integrating chemical and phenotypic spaces, is built and utilized during the process to assess those images initially classified as "fuzzy''-an automated iterative feedback tuning. Simultaneously, all this information is directly annotated in a relational database containing the chemical data. This novel fully automated method was validated by conducting a re-analysis of results from a high-content screening campaign involving 33 992 molecules used to identify inhibitors of the PI3K/Akt signaling pathway. Ninety-two percent of confirmed hits identified by the conventional multistep analysis method were identified using this integrated one-step system as well as 40 new hits, 14.9% of the total, originally false negatives. Ninety-six percent of true negatives were properly recognized too. A web-based access to the database, with customizable data retrieval and visualization tools, facilitates the posterior analysis of annotated cytological features which allows identi. cation of additional phenotypic profiles; thus, further analysis of original crude images is not required.	[Rabal, Obdulia; Link, Wolfgang; Serelde, Beatriz G.; Bischoff, James R.; Oyarzabal, Julen] Spanish Natl Canc Res Ctr CNIO, Expt Therapeut Programme, Madrid 28029, Spain	Oyarzabal, J (reprint author), Spanish Natl Canc Res Ctr CNIO, Expt Therapeut Programme, Melchor Fernandez Almagro 3, Madrid 28029, Spain.	joyarzabal@cnio.es	Link, Wolfgang/F-4435-2012	Link, Wolfgang/0000-0002-3340-5165	Spanish Ministerio de Ciencia e Innovacion [BIO2006-02432]	We thank L. Bleicher, T. Moran and I. Mikic from Accelrys for their assistance and help with "image collection'' within Pipeline Pilot as well as for their stimulating discussions and suggestions, and M. Urbano-Cuadrado from Experimental Therapeutics Programme for his assistance and help in database annotation, and A. Fernandez from the Biomar Institute for providing a library of 168 compounds, and O. Rueda and R. Diaz for their assistance with statistical analyses. This work was supported by funding from the Spanish Ministerio de Ciencia e Innovacion (Project BIO2006-02432).	Abraham VC, 2008, J BIOMOL SCREEN, V13, P527, DOI 10.1177/1087057108318428; *ACC INC, PIP PIL V5 1; ADAMS ND, 2008, Patent No. 157191; Bender A, 2004, J CHEM INF COMP SCI, V44, P170, DOI 10.1021/ci034207y; Blake RA, 2007, METH MOL B, V356, P367; Carpenter AE, 2007, NAT CHEM BIOL, V3, P461, DOI 10.1038/nchembio.2007.15; Carpenter AE, 2007, NAT METHODS, V4, P120, DOI 10.1038/nmeth0207-120; Ciustea M, 2008, J MED CHEM, V51, P6563, DOI 10.1021/jm800366g; Di Cristofano A, 2000, CELL, V100, P387, DOI 10.1016/S0092-8674(00)80674-1; Eggert US, 2006, CURR OPIN CHEM BIOL, V10, P232, DOI 10.1016/j.cbpa.2006.04.010; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Giuliano KA, 2003, ASSAY DRUG DEV TECHN, V1, P565, DOI 10.1089/154065803322302826; Giuliano KA, 1997, J BIOMOL SCREEN, V2, P249, DOI 10.1177/108705719700200410; Glick M, 2004, J BIOMOL SCREEN, V9, P32, DOI 10.1177/1087057103260590; Hert J, 2004, ORG BIOMOL CHEM, V2, P3256, DOI 10.1039/b409865j; Jones TR, 2009, P NATL ACAD SCI USA, V106, P1826, DOI 10.1073/pnas.0808843106; Kau TR, 2003, CANCER CELL, V4, P463, DOI 10.1016/S1535-6108(03)00303-9; Lang P, 2006, NAT REV DRUG DISCOV, V5, P343, DOI 10.1038/nrd2008; Lee S, 2006, METHOD ENZYMOL, V414, P468, DOI 10.1016/S0076-6879(06)14025-2; Link W, 2009, J BIOL CHEM, V284, P28392, DOI 10.1074/jbc.M109.038984; Meyer F., 1979, THESIS ECOLE MINES; Mitchison TJ, 2005, CHEMBIOCHEM, V6, P33, DOI 10.1002/cbic.200400272; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; Rogers D, 2005, J BIOMOL SCREEN, V10, P682, DOI 10.1177/1087057105281365; Smith C, 2005, NAT METHODS, V2, P547, DOI 10.1038/nmeth0705-547; Tencza SB, 2004, J APPL TOXICOL, V24, P371, DOI 10.1002/jat.1025; Xia XY, 2004, J MED CHEM, V47, P4463, DOI 10.1021/jm0303195; Yang J, 2007, CHEM BIOL, V14, P371, DOI 10.1016/j.chembiol.2007.02.004; Zanella F, 2008, CHEMBIOCHEM, V9, P2229, DOI 10.1002/cbic.200800255; ZASK A, 2008, Patent No. 115974	30	8	8	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	1742-206X			MOL BIOSYST	Mol. Biosyst.		2010	6	4					711	720		10.1039/b919830j		10	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	570YP	WOS:000275715000012	
J	Tesfamariam, S; Liu, Z				Tesfamariam, Solomon; Liu, Zheng			Earthquake induced damage classification for reinforced concrete buildings	STRUCTURAL SAFETY			English	Article						Classification; Building vulnerability; Earthquake damage estimation	VULNERABILITY ASSESSMENT; RANDOM FORESTS; PREDICTION; SCENARIOS	Seismic risk assessment of reinforced concrete buildings needs consideration of seismic hazard, building vulnerability and consequence of failure. Different statistical methods are proposed to discern vulnerable buildings for retrofit prioritization. This paper utilized reported seismic induced damage data and illustrated eight different statistical damage classification techniques. naive Bayes, k-nearest-neighbor (kNN). Fisher's linear discriminant analysis (FLDA), partial least squares discriminant analysis (PLSDA), multilayer perceptron neural networks (MLP-NN), classification tree (CT), support vector machine (SVM), and random forest (RF). Six building performance modifiers were considered in this study for damage classification: number of stories above the ground level (N), soft story index (SSI), overhang ratio (OHR), minimum normalized lateral stiffness index (MNLSTFI), minimum normalized lateral strength index (MNLSI) and normalized redundancy score (NRS). The results demonstrate the feasibility and effectiveness of the selected statistical approaches to classify the damage of concrete buildings. (C) 2009 Elsevier Ltd. All rights reserved.	[Tesfamariam, Solomon] Univ British Columbia Okanagan, Sch Engn, Kelowna, BC V1V 1V7, Canada; [Liu, Zheng] Natl Res Council Canada, Inst Res Construct, Ottawa, ON K1A 0R6, Canada	Tesfamariam, S (reprint author), Univ British Columbia Okanagan, Sch Engn, 3333 Univ Way, Kelowna, BC V1V 1V7, Canada.	solomon.tesfamariam@ubc.ca; zhen-g.liu@ieee.org					ABDI H, 2003, ENCY MEASUREMENT STA, P740; ALALI A, 1998, 130 STANF U BLUM EAR; Applied Technology Council (ATC), 1985, ATC13; *ASCE, 1998, 310 ASCE FEMA; ATC, 2002, 154 ATC FEMA; BALAKRISHNAMA S, 1998, LINEAR DISCRIMINANT; Bertero RD, 1999, J STRUCT ENG-ASCE, V125, P81, DOI 10.1061/(ASCE)0733-9445(1999)125:1(81); BOISSONNADE AC, 1985, 67 JA BLUM EARTH ENG; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 2001, RANDOM FORESTS TECH; Dolce M, 2006, ENG STRUCT, V28, P357, DOI 10.1016/j.engstruct.2005.08.009; Duda R.O., 2001, PATTERN CLASSIFICATI; Earthquake Engineering Research Institute (EERI) Committee on Seismic Risk, 1989, EARTHQ SPECTRA, V5, P675, DOI DOI 10.1193/1.1585549; Ellingwood BR, 2001, RELIAB ENG SYST SAFE, V74, P251, DOI 10.1016/S0951-8320(01)00105-3; *FEMA, 1994, FEMA249; Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011; Gunn S. R., 1998, SUPPORT VECTOR MACHI; Hill T., 2006, STAT METHODS APPL CO; Kappos AJ, 1998, NAT HAZARDS, V17, P177, DOI 10.1023/A:1008083021022; Kuhn M, 2008, J STAT SOFTW, V28, P1; KUHN M, 2009, VARIABLE IMPORTANCE; KUHN M, 2009, PACKAGE CARET; LEWICKI P, 2005, STATISTICS METHODS A; Maindonald J, 2003, DATA ANAL GRAPHICS U; Marengo E, 2008, ANAL BIOANAL CHEM, V390, P1327, DOI 10.1007/s00216-008-1837-y; New Zealand Society for Earthquake Engineering (NZSEE), 2006, ASS IMPR STRUCT PERF; NRC, 1992, MAN SCREEN BUILD SEI; NRC, 1993, GUID SEISM EV EX BUI; Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1; *R PROJ, 2007, R PROJ STAT COMP; RISH I, 2001, P INT JOINT C ART IN, P1; *SERU, 2009, ADV EARTHQ ENG URB R; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; SVETNIK V, 2004, LECT NOTES COMPUTER, V3077; Tesfamariam S, 2008, EARTHQ SPECTRA, V24, P795, DOI 10.1193/1.2952767; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; Villaverde R, 2007, J STRUCT ENG-ASCE, V133, P57, DOI 10.1061/(ASCE)0733-9445(2007)133:1(57); Webb A. R., 2002, STAT PATTERN RECOGNI; Wen YK, 2003, UNCERTAINTY MODELING; Yucemen MS, 2004, STRUCT SAF, V26, P349, DOI 10.1016/j.strusafe.2003.09.002	40	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-4730			STRUCT SAF	Struct. Saf.		2010	32	2					154	164		10.1016/j.strusafe.2009.10.002		11	Engineering, Civil	Engineering	561LX	WOS:000274979900006	
J	Conway, M; Doan, S; Kawazoe, A; Collier, N				Conway, Mike; Doan, Son; Kawazoe, Ai; Collier, Nigel			Classifying disease outbreak reports using n-grams and semantic features	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						Text classification; Feature selection; Text mining; Information extraction; Disease tracking		Introduction: This paper explores the benefits of using n-grams and semantic features for the classification of disease outbreak reports, in the context of the BioCaster disease outbreak report text mining system. A novel feature of this work is the use of a general purpose semantic tagger - the USAS tagger - to generate features. Background: We outline the application context for this work (the BioCaster epidemiological text mining system), before going on to describe the experimental data used in our classification experiments (the 1000 document BioCaster corpus). Feature sets: Three broad groups of features are used in this work: Named Entity based features, n-gram features, and features derived from the USAS semantic tagger. Methodology: Three standard machine learning algorithms - Naive Bayes, the Support Vector Machine algorithm, and the C4.5 decision tree algorithm - were used for classifying experimental data (that is, the BioCaster corpus). Feature selection was performed using the chi(2) feature selection algorithm. Standard text classification performance metrics - Accuracy, Precision, Recall, Specificity and F-score - are reported. Results: A feature representation composed of unigrams, bigrams, trigrams and features derived from a semantic tagger, in conjunction with the Naive Bayes algorithm and feature selection yielded the highest classification accuracy (and F-score). This result was statistically significant compared to a baseline unigram representation and to previous work on the same task. However, it was feature selection rather than semantic tagging that contributed most to the improved performance. Conclusion: This study has shown that for the classification of disease outbreak reports, a combination of bag-of-words, n-grams and semantic features, in conjunction with feature selection, increases classification accuracy at a statistically significant level compared to previous work in this domain. (C) 2009 Elsevier Ireland Ltd. All rights reserved.	[Conway, Mike; Doan, Son; Kawazoe, Ai; Collier, Nigel] Res Org Informat & Syst, Natl Inst Informat, Chiyoda Ku, Tokyo 1018430, Japan	Conway, M (reprint author), Res Org Informat & Syst, Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.	mike@nii.ac.jp			Japanese Society for the Promotion of Science [P07722]; Research Organization of Information Systems	We would like to express thanks to Dr. Paul Rayson, Directer of UCREL (University Centre for Computer Corpus Research on Language) at Lancaster University for providing access to the USAS semantic tagger. This work was funded in part by grants from the Japanese Society for the Promotion of Science (grant no.: P07722) and the Research Organization of Information Systems.	BOUCKAERT R, 2004, CHAPTER EVALUATING R, P3; Collier N, 2008, BIOINFORMATICS, V24, P2940, DOI 10.1093/bioinformatics/btn534; CONWAY M, 2008, P 3 INT S SEM MIN BI, P29; DOAN S, 2007, P ACL 2007 WORKSH BI, P17, DOI 10.3115/1572392.1572396; Doan S, 2009, J BIOMED INFORM, V42, P773, DOI 10.1016/j.jbi.2008.12.009; DOAN S, 2008, P INT JOINT C NAT LA, P951; Feldman R., 2007, TEXT MINING HDB ADV; Fellbaum C., 1998, WORDNET ELECT LEXICA; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Heymann D L, 2001, Lancet Infect Dis, V1, P345, DOI 10.1016/S1473-3099(01)00148-7; KAWAZOE A, 2006, P INT WORKSH BIOM ON, P77; Lewis D. D., 1992, THESIS U MASSACHUSET; McArthur T., 1981, LONGMAN LEXICON CONT; Mitchell T.M., 1997, MACHINE LEARNING; MOSCHITTI A, 2004, P 26 EUR C INF RETR, P181; OAKES M, 2001, P 24 ANN INT ACM SIG, P440, DOI 10.1145/383952.384080; PIAO S, 2006, P COLING ACL 2006 WO, P2, DOI 10.3115/1613692.1613695; Rayson P., 2004, P WORKSH NAM ENT REC, P7; Rayson P., 2008, INT J CORPUS LINGUIS, V13, P519, DOI 10.1075/ijcl.13.4.06ray; Scott Sam, 1999, P 16 INT C MACH LEAR, P379; SHAROFF S, 2006, P 11 C EUR CHAPT ASS, P132; Witten IH, 2005, DATA MINING PRACTICA; Yang Y., 1997, P 14 INT C MACH LEAR, P412; Yu B, 2008, LIT LINGUIST COMPUT, V23, P327, DOI 10.1093/llc/fqn015	24	8	8	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056			INT J MED INFORM	Int. J. Med. Inform.	DEC	2009	78	12					E47	E58		10.1016/j.ijmedinf.2009.03.010		12	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	522YM	WOS:000272036200016	
J	Haouari, B; Ben Amor, N; Elouedi, Z; Mellouli, K				Haouari, Bakhta; Ben Amor, Nahla; Elouedi, Zied; Mellouli, Khaled			Naive possibilistic network classifiers	FUZZY SETS AND SYSTEMS			English	Article; Proceedings Paper	8th Conference of the International-Association-for-Fuzzy-Set-Management-and-Economy (SIGEF)	NOV 30-DEC 02, 2006	Hammamet, TUNISIA	Int Assoc Fuzzy Set Management & Econ		Possibility theory; Classification; Naive Bayes classifier; Possibilistic classifier; Aggregation operators	FEATURE SUBSET-SELECTION; INDEPENDENCE	Naive Bayesian network classifiers have proved their effectiveness to accomplish the classification task, even if they work under the strong assumption of independence of attributes in the context of the class node. However, as all of them are based on probability theory, they run into problems when they are faced with imperfection. This paper proposes a new approach of classification under the possibilistic framework with naive classifiers. To output the naive possibilistic network classifier, two procedures are studied namely the building phase, which deals with imperfect (imprecise/uncertain) dataset attributes and classes, and the classification phase, which is used to classify new instances that may be characterized by imperfect attributes. To improve the performance of our classifier, we propose two extensions namely selective naive possibilistic classifier and semi-naive possibilistic classifier. Experimental study has shown naive Bayes style possibilistic classifier, and is efficient in the imperfect case. (C) 2009 Elsevier B.V. All rights reserved.	[Haouari, Bakhta; Ben Amor, Nahla; Elouedi, Zied] Inst Super Gest Tunis, LARODEC, Le Bardo 2000, Tunisia; [Mellouli, Khaled] Inst Hautes Etud Commerciales Tunis, Tunis, Tunisia	Haouari, B (reprint author), Inst Super Gest Tunis, LARODEC, 41 Ave Liberte, Le Bardo 2000, Tunisia.	bakhtahaouari@yahoo.fr					Aha W., 1996, UCI REPOSITORY MACHI; Ben Amor N., 2003, Soft Computing, V8, DOI 10.1007/S00500-002-0255-X; BENAMOR N, 2004, P IEEE INT C FUZZ SY, V2, P653; Ben Amor N, 2002, INT J UNCERTAIN FUZZ, V10, P117; Bishop C., 1996, NEURAL NETWORKS PATT; Borgelt C., 1998, P 7 IEEE INT C FUZZ, P663; Borgelt C, 1999, P 7 EUR C INT TECHN, P556; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DUBOIS D, 2000, P 3 INT C INF FUS PA, P21; DUBOIS D, 1994, POSSIBILITY THEORY A; Dubois D., 1988, POSSIBILITY THEORY; Duda R., 1973, PATTERN CLASSIFICATI; ELOUEDI Z, 2006, LFA TOULOUSE, P61; Fonck P, 1997, INT J APPROX REASON, V16, P149, DOI 10.1016/S0888-613X(96)00095-3; FRIEH JM, 1997, ANN ORTHOP OUEST, V29, P161; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; GROSSMAN D, 2004, P MACH LEARN, P46; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; LI X, 2003, IEEE WORKSH AUT SPEE; Liu H., 1998, FEATURE SELECTION KN; PAZZANI M, 1997, LEARNING DATA ARTIFI, P239; PEARL J, 1988, PROBABILISTIC REASON, P221; Prade H., 1998, HDB DEFEASIBLE REASO, V1, P169; QUINLAN JR, 1986, MACH LEARN, V1, P106; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Shafer G., 1976, MATH THEORY EVIDENCE; Yager RR, 1997, INT J INTELL SYST, V12, P1; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5	34	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114			FUZZY SET SYST	Fuzzy Sets Syst.	NOV 16	2009	160	22					3224	3238		10.1016/j.fss.2009.01.009		15	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	504TU	WOS:000270641400004	
J	Stajduhar, I; Dalbelo-Basic, B; Bogunovic, N				Stajduhar, Ivan; Dalbelo-Basic, Bojana; Bogunovic, Nikola			Impact of censoring on learning Bayesian networks in survival modelling	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						Bayesian networks; Structure learning; Survival analysis; Censoring; Prognostic models in medicine; Medical decision support	BREAST-CANCER PATIENTS; NEURAL-NETWORK; STATISTICAL-DATA; PROGNOSIS; MANAGEMENT; REGRESSION; SEPARATION; LYMPHOMA; MEDICINE; SURGERY	Objective: Bayesian networks are commonly used for presenting uncertainty and covariate interactions in an easily interpretable way. Because of their efficient inference and ability to represent causal relationships, they are an excellent choice for medical decision support systems in diagnosis, treatment, and prognosis. Although good procedures for learning Bayesian networks from data have been defined, their performance in learning from censored survival data has not been widely studied. In this paper, we explore how to use these procedures to Learn about possible interactions between prognostic factors and their influence on the variate of interest. We study how censoring affects the probability of learning correct Bayesian network structures. Additionally, we analyse the potential usefulness of the learnt models for predicting the time-independent probability of an event of interest. Methods and materials: We analysed the influence of censoring with a simulation on synthetic data sampled from randomly generated Bayesian networks. We used two well-known methods for learning Bayesian networks from data: a constraint-based method and a score-based method. We compared the performance of each method under different levels of censoring to those of the naive Bayes classifier and the proportional hazards model. We did additional experiments on several datasets from real-world medical domains. The machine-learning methods treated censored cases in the data as event-free. Results: We report and compare results for several commonly used model evaluation metrics. On average, the proportional hazards method outperformed other methods in most censoring setups. As part of the simulation study, we also analysed structural similarities of the learnt networks. Heavy censoring, as opposed to no censoring, produces up to a 5% surplus and up to 10% missing total arcs. It also produces up to 50% missing arcs that should originally be connected to the variate of interest. Conclusion: Presented methods for learning Bayesian networks from data can be used to learn from censored survival data in the presence of light censoring (up to 20%) by treating censored cases as event-free. Given intermediate or heavy censoring, the learnt models become tuned to the majority class and would thus require a different approach. (C) 2009 Elsevier B.V. All rights reserved.	[Stajduhar, Ivan] Univ Rijeka, Fac Engn, Dept Automat Elect & Comp, Rijeka 51000, Croatia; [Dalbelo-Basic, Bojana; Bogunovic, Nikola] Univ Zagreb, Dept Elect Microelect Comp & Intelligent Syst, Fac Elect Engn & Comp, Zagreb 10000, Croatia	Stajduhar, I (reprint author), Univ Rijeka, Fac Engn, Dept Automat Elect & Comp, Vukovarska 58, Rijeka 51000, Croatia.	ivan.stajduhar@riteh.hr			Croatian Ministry of Science, Education and Sports [MZOS 069-0362214-1575, MZOS 036-1300646-1986, MZOS 098-0982560-2563]	This work was generously supported by the Croatian Ministry of Science, Education and Sports, project no. MZOS 069-0362214-1575, project no. MZOS 036-1300646-1986 and project no. MZOS 098-0982560-2563.	Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Andreassen S, 1999, ARTIF INTELL MED, V15, P121, DOI 10.1016/S0933-3657(98)00048-7; Asuncion A., UCI MACHINE LEARNING; Bender R, 2005, STAT MED, V24, P1713, DOI 10.1002/sim.2059; Blanco R, 2005, J BIOMED INFORM, V38, P376, DOI 10.1016/j.jbi.2005.05.004; Borgelt C., 2002, GRAPHICAL MODELS MET; Brieman L., 1984, CLASSIFICATION REGRE; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Chickering DM, 2002, J MACHINE LEARNING R, V11, P507; CLARKE J, 2008, STAT METHODOL, V5, P238, DOI 10.1016/j.stamet.2007.09.003; Contal C, 1999, COMPUT STAT DATA AN, V30, P253, DOI 10.1016/S0167-9473(98)00096-6; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; COX DR, 1972, J R STAT SOC B, V187, P220; Delen D, 2005, ARTIF INTELL MED, V34, P113, DOI 10.1016/j.artmed.2004.07.002; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O., 2001, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Fleming T. R., 1991, COUNTING PROCESSES S; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 1998, P 14 C UNC ART INT, P129; Glymour Clark, 2000, CAUSATION PREDICTION; Graf E, 1999, STAT MED, V18, P2529; HANLEY JA, 1982, RADIOLOGY, V143, P29; HARRELL FE, 1982, JAMA-J AM MED ASSOC, V247, P2543, DOI 10.1001/jama.247.18.2543; Hastie T. J., 2001, ELEMENTS STAT LEARNI; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Hoot Nathan, 2005, AMIA Annu Symp Proc, P345; Hothorn T, 2004, STAT MED, V23, P77, DOI 10.1002/sim.1593; Janzura M, 2006, INT J INTELL SYST, V21, P335, DOI 10.1002/int.20138; Jarman IH, 2008, ARTIF INTELL MED, V42, P165, DOI 10.1016/j.artmed.2007.11.005; Jerez-Aragones JM, 2003, ARTIF INTELL MED, V27, P45, DOI 10.1016/S0933-3657(02)00086-6; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; Kattan MW, 1998, COMPUT BIOMED RES, V31, P363, DOI 10.1006/cbmr.1998.1488; Klein JP, 2003, SURVIVAL ANAL TECHNI; Kleinbaum D., 2005, SURVIVAL ANAL SELF L; KOOPERBERG C, 1995, J AM STAT ASSOC, V90, P78, DOI 10.2307/2291132; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Lee ET, 2003, STAT METHODS SURVIVA; Lisboa PJG, 2003, ARTIF INTELL MED, V28, P1, DOI 10.1016/S0933-3657(03)00033-2; Lucas PJF, 2000, ARTIF INTELL MED, V19, P251, DOI 10.1016/S0933-3657(00)00048-8; Lucas PJF, 2004, ARTIF INTELL MED, V30, P201, DOI 10.1016/j.artmed.2003.11.001; Lucas PJF, 1998, METHOD INFORM MED, V37, P206; Lucas PJF, 1999, ARTIF INTELL MED, V15, P105, DOI 10.1016/S0933-3657(98)00047-5; MARSHALL A, 2000, LECT NOTES COMPUT SC, P516; Michie D., 1995, MACHINE LEARNING NEU; Pearl J, 2000, CAUSALITY MODELS REA; Pearl J., 1988, PROBABILISTIC REASON; Pellet JP, 2008, J MACH LEARN RES, V9, P1295; Pena-Reyes CA, 2000, ARTIF INTELL MED, V19, P1, DOI 10.1016/S0933-3657(99)00047-0; R Development Core Team, R LANG ENV STAT COMP; Ripley BD, 2001, CLINICAL APPLICATIONS OF ARTIFICIAL NEURAL NETWORKS, P237, DOI 10.1017/CBO9780511543494.011; Royston P, 2004, STAT MED, V23, P723, DOI 10.1002/sim.1621; Russell S. J., 2002, ARTIFICIAL INTELLIGE; SCHUMACHER M, 1994, J CLIN ONCOL, V12, P2086; Sierra B, 1998, ARTIF INTELL MED, V14, P215, DOI 10.1016/S0933-3657(98)00024-4; VERMA T, 1992, UNCERTAINTY ARTIFICI, V8, P323; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; Xie XC, 2008, J MACH LEARN RES, V9, P459; Zupan B, 2000, ARTIF INTELL MED, V20, P59, DOI 10.1016/S0933-3657(00)00053-1	59	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	NOV	2009	47	3					199	217		10.1016/j.artmed.2009.08.001		19	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	527XS	WOS:000272405100002	
J	Turhan, B; Kocak, G; Bener, A				Turhan, Burak; Kocak, Gozde; Bener, Ayse			Data mining source code for locating software bugs: A case study in telecommunication industry	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Software testing; Defect prediction; Software bugs; Case study	DEFECT-PREDICTION MODELS; FAULTS	In a large software system knowing which files are most likely to be fault-prone is Valuable information for project managers. They can use such information in prioritizing software testing and allocating resources accordingly. However, our experience shows that it is difficult to collect and analyze fine-grained test defects in a large and complex software system. On the other hand, previous research has shown that companies can safely use cross-company data with nearest neighbor sampling to predict their defects in case they are unable to collect local data, In this Study we analyzed 25 projects of a large telecommunication system. To predict defect proneness of modules we trained models on publicly available Nasa MDP data. In Our experiments we used static call graph based ranking (CGBR) as well as nearest neighbor sampling for constructing method level defect predictors. Our results suggest that, for the analyzed projects. at least 70% of the defects can be detected by inspecting only (i) 6% of the code using a Naive Bayes model, (ii) 3% of the code using CGBR framework. (C) 2008 Elsevier Ltd. All rights reserved.	[Turhan, Burak; Kocak, Gozde; Bener, Ayse] Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey	Turhan, B (reprint author), Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.	turhanb@boun.edu.tr	Turhan, Burak/G-7400-2011				ADAMS EN, 1984, IBM J RES DEV, V28, P2; BASILI VR, 1984, COMMUN ACM, V27, P42, DOI 10.1145/69605.2085; Bell RM, 2006, P ACM INT S SOFTW TE, P61, DOI 10.1145/1146238.1146246; Boetticher G, 2007, PROMISE REPOSITORY E; Fenton NE, 1999, IEEE T SOFTWARE ENG, V25, P675, DOI 10.1109/32.815326; Fenton NE, 2000, IEEE T SOFTWARE ENG, V26, P797, DOI 10.1109/32.879815; KOCAK G, 2008, EUROMICRO S IN PRESS; KOCAK G, 2008, ICSOFT IN PRESS; Koru AG, 2005, IEEE SOFTWARE, V22, P23, DOI 10.1109/MS.2005.149; Koru A.G., 2005, P PROMISE 2005 ST LO, P1; MALAIYA YK, 2000, ISSRE 2000, P62; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P2, DOI 10.1109/TSE.2007.256941; MENZIES T, 2007, CROSS VS WITHIN CO D; Nagappan N., 2006, EXPLAINING FAILURES; *NASA WVU IV V, NASA WVU IV V FAC ME; OSTRAND TJ, 2005, IEEE T SOFTWARE ENG, V31; OSTRAND TJ, 2004, P ACM INT S SOFTW TE; Ostrand T.J., 2002, P ACM INT S SOFTW TE, P55; OSTRAND TJ, 2007, P ACM INT S SOFTW TE; TURHAN B, 2008, DATA SAMPLING CROSS; TURHAN B, 2007, 7 INT C, P231, DOI 10.1109/QSIC.2007.4385500; Zhang HY, 2008, IEEE T SOFTWARE ENG, V34, P301, DOI 10.1109/TSE.2007.70771; ZIMMERMANN T, 2006, PREDICTING SUBSYSTEM	23	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	AUG	2009	36	6					9986	9990		10.1016/j.eswa.2008.12.028		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	445YE	WOS:000266086600047	
J	Appavu, S; Rajaram, R; Muthupandian, M; Athiappan, G; Kashmeera, KS				Appavu, S.; Rajaram, R.; Muthupandian, M.; Athiappan, G.; Kashmeera, K. S.			Data mining based intelligent analysis of threatening e-mail	KNOWLEDGE-BASED SYSTEMS			English	Article						Data mining; Classification; Threatening e-mail detection		This paper proposed a decision tree based classification method to detect e-mails that contain terrorism information. The proposed classification method is an incremental and user-feedback based extension of a decision tree induction algorithm named Ad Infinitum. We show that Ad Infinitum algorithm is a good choice for threatening e-mail detection as it runs fast on large and high dimensional databases, is easy to tune and is highly accurate, outperforming popular algorithms such as Decision Trees, Support Vector Machines and Naive Bayes. In particular, we are interested in detecting fraudulent and possibly criminal activities from such e-mails. (C) 2009 Elsevier B.V. All rights reserved.	[Appavu, S.; Rajaram, R.; Muthupandian, M.; Athiappan, G.; Kashmeera, K. S.] Thiagarajar Coll Engn, Madurai, Tamil Nadu, India	Appavu, S (reprint author), Thiagarajar Coll Engn, Madurai, Tamil Nadu, India.	sbit@tce.edu; rrajaram@tce.edu; muthupandi@tce.edu; athi@tce.edu; kashmeera@tce.edu					Appavu S, 2007, P IEEE INT C INT SEC, P316; APPAVU S, 2007, P EUR C DAT MIN PORT; LING SPAM PUI DATASE	3	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	JUL	2009	22	5					392	393		10.1016/j.knosys.2009.02.002		2	Computer Science, Artificial Intelligence	Computer Science	468KV	WOS:000267818000010	
S	Larson, M; Newman, E; Jones, GJF		Peters, C		Larson, Martha; Newman, Eamonn; Jones, Gareth J. F.			Overview of VideoCLEF 2008: Automatic Generation of Topic-Based Feeds for Dual Language Audio-Visual Content	EVALUATING SYSTEMS FOR MULTILINGUAL AND MULTIMODAL INFORMATION ACCESS	Lecture Notes in Computer Science		English	Proceedings Paper	9th Workshop of the Cross-Language Evaluation Forum (CLEF 2008)	SEP 17-19, 2008	Aarhus, DENMARK			Classification; Translation; Keyframe Extraction; Speech Recognition; Evaluation; Benchmark; Video		The VideoCLEF track, introduced in 2008, aims to develop and evaluate tasks related to analysis of and access to multilingual multimedia, content. In its first year, VideoCLEF piloted the Vid2RSS task, whose main subtask was the classification of dual language video (Dutch-language television content featuring English-speaking experts and studio guests). The task offered two additional discretionary subtasks: feed translation and automatic keyframe extraction. Task participants were supplied with Dutch archival metadata, Dutch speech transcripts, English speech transcripts and ten thematic category labels, which they were required to assign to the test set videos. The videos were grouped by class label into topic-based RSS-feeds, displaying title, description and keyframe for each video. Five groups participated in the 2008 VideoCLEF track. Participants, were required to collect their own training data; both Wikipedia, and general web content were used. Groups deployed various classifiers (SVM, Naive Bayes and k-NN) or treated the problem as an information retrieval task. Both the Dutch speech transcripts and the archival metadata performed well as sources of indexing features, but no group succeeded ill exploiting combinations of feature sources to significantly enhance performance. A small scale fluency/adequacy evaluation of the translation task output revealed the translation to be of sufficient quality to make it valuable to a non-Dutch speaking English speaker. For keyframe extraction, the strategy chosen was to select the keyframe from the shot with the most representative speech transcript content. The automatically selected shots were shown, with a, small user study, to be competitive with manually selected shots. Future years of VideoCLEF will aim to expand the corpus and the class label list, as well as to extend the track to additional tasks.	[Larson, Martha] Delft Univ Technol, EEMCS, NL-2628 CD Delft, Netherlands	Larson, M (reprint author), Delft Univ Technol, EEMCS, NL-2628 CD Delft, Netherlands.	m.a.larson@tudelft.nl; enewman@computing.dcu.ie; gjones@computing.dcu.ie					CALIC J, 2002, P INT C AC SPEECH SI; Huijbregts M, 2007, LECT NOTES COMPUT SC, V4816, P78; Jackson P., 2002, NATURAL LANGUAGE PRO; Larson M., 2008, P SIGIR 2008 WORKSH, P71; Paass G., 2002, LNCS LNAI, V2431, P373; Pecina P, 2008, LECT NOTES COMPUT SC, V5152, P674, DOI 10.1007/978-3-540-85760-0_86; Smeaton A.F., 2006, MIR 06, P321, DOI DOI 10.1145/1178677.1178722	7	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-04446-5	LECT NOTES COMPUT SC			2009	5706						906	917				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BMQ35	WOS:000273344500119	
J	Liu, QZ; Sung, AH; Qiao, MY; Chen, ZX; Yang, JY; Yang, MQ; Huang, XD; Deng, YP				Liu, Qingzhong; Sung, Andrew H.; Qiao, Mengyu; Chen, Zhongxue; Yang, Jack Y.; Yang, Mary Qu; Huang, Xudong; Deng, Youping			Comparison of feature selection and classification for MALDI-MS data	BMC GENOMICS			English	Article							IMPROVED PEAK DETECTION; SUPPORT VECTOR MACHINE; GENE SELECTION; MASS-SPECTRA; DIMENSIONALITY REDUCTION; WAVELET TRANSFORM; CANCER; SAMPLES; ALGORITHMS	Introduction: In the classification of Mass Spectrometry (MS) proteomics data, peak detection, feature selection, and learning classifiers are critical to classification accuracy. To better understand which methods are more accurate when classifying data, some publicly available peak detection algorithms for Matrix assisted Laser Desorption Ionization Mass Spectrometry (MALDI-MS) data were recently compared; however, the issue of different feature selection methods and different classification models as they relate to classification performance has not been addressed. With the application of intelligent computing, much progress has been made in the development of feature selection methods and learning classifiers for the analysis of high-throughput biological data. The main objective of this paper is to compare the methods of feature selection and different learning classifiers when applied to MALDI-MS data and to provide a subsequent reference for the analysis of MS proteomics data. Results: We compared a well-known method of feature selection, Support Vector Machine Recursive Feature Elimination (SVMRFE), and a recently developed method, Gradient based Leave-one-out Gene Selection (GLGS) that effectively performs microarray data analysis. We also compared several learning classifiers including K-Nearest Neighbor Classifier (KNNC), Naive Bayes Classifier (NBC), Nearest Mean Scaled Classifier (NMSC), uncorrelated normal based quadratic Bayes Classifier recorded as UDC, Support Vector Machines, and a distance metric learning for Large Margin Nearest Neighbor classifier (LMNN) based on Mahanalobis distance. To compare, we conducted a comprehensive experimental study using three types of MALDI-MS data. Conclusion: Regarding feature selection, SVMRFE outperformed GLGS in classification. As for the learning classifiers, when classification models derived from the best training were compared, SVMs performed the best with respect to the expected testing accuracy. However, the distance metric learning LMNN outperformed SVMs and other classifiers on evaluating the best testing. In such cases, the optimum classification model based on LMNN is worth investigating for future study.	[Liu, Qingzhong; Sung, Andrew H.; Qiao, Mengyu] New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA; [Liu, Qingzhong; Sung, Andrew H.] New Mexico Inst Min & Technol, Inst Complex Addit Syst Anal, Socorro, NM 87801 USA; [Chen, Zhongxue] Univ Texas Hlth Sci Ctr Houston, Ctr Clin & Translat Sci, Houston, TX 77030 USA; [Yang, Jack Y.] Harvard Univ, Cambridge, MA 02140 USA; [Yang, Mary Qu] NHGRI, NIH, US Dept HHS, Rockville, MD 20852 USA; [Huang, Xudong] Brigham & Womens Hosp, Dept Radiol, Ctr Adv Med Imaging, Boston, MA 02115 USA; [Huang, Xudong] Brigham & Womens Hosp, Div Nucl Med & Mol Imaging, Conjugate & Med Chem Lab, Boston, MA 02115 USA; [Huang, Xudong] Harvard Univ, Sch Med, Boston, MA 02115 USA; [Deng, Youping] SpecPro, Vicksburg, MS 39180 USA; [Deng, Youping] Univ So Mississippi, Dept Biol Sci, Hattiesburg, MS 39406 USA	Sung, AH (reprint author), New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA.	liu@cs.nmt.edu; sung@cs.nmt.edu; myuqiao@cs.nmt.edu; zhongxue.chen@uth.tmc.edu; Dr.Yang@JHU.edu; yangma@mail.NIH.GOV; xhuang3@partners.org; youping.deng@usm.edu	Chen, Zhongxue/K-1372-2013	Chen, Zhongxue/0000-0003-2537-7843	Mississippi Functional Genomics Network [2P20RR016476-04]	The authors wish to thank ICASA (Institute for Complex Additive Systems Analysis, a division of New Mexico Tech) for the support of this study. This work was also supported by the Mississippi Functional Genomics Network (DHHS/NIH/NCRR Grant# 2P20RR016476-04). Special thanks go to Ms. Kimberly Lawson of the Department of Radiology, Brigham and Women's Hospital and Harvard Medical School.	Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Chen S, 2007, COMPUT STAT DATA AN, V52, P211, DOI 10.1016/j.csda.2007.02.022; Chopra S., 2005, P COMPUTER VISION PA, V1, P539; Coombes K., 2007, FUNDAMENTALS DATA MI, P79, DOI 10.1007/978-0-387-47509-7_4; Coombes KR, 2005, PROTEOMICS, V5, P4107, DOI 10.1002/pmic.200401261; Domeniconi C., 2002, P NIPS; Du P, 2006, BIOINFORMATICS, V22, P2059, DOI 10.1093/bioinformatics/btl355; DUAN K, 2004, SVM RFE PEAK SELECTI, P191; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Goldberger J., 2005, P NIPS; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Heijden F., 2004, CLASSIFICATION PARAM; Hilario M, 2006, MASS SPECTROM REV, V25, P409, DOI 10.1002/mas.20072; Inza I, 2002, J INTELL FUZZY SYST, V12, P25; Li LP, 2004, BIOINFORMATICS, V20, P1638, DOI 10.1093/bioinformatics/bth098; LI X, 2005, BIOINFORMATICS COMPU, P91, DOI 10.1007/0-387-29362-0_6; LIU Q, 2007, THESIS DEP COMPUTER; Liu QZ, 2008, PATTERN RECOGN, V41, P56, DOI 10.1016/j.patcog.2007.06.005; Mantini D, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-101; PENG J, 2002, P INT C PATT REC; Petricoin EF, 2003, CLIN CHEM, V49, P533, DOI 10.1373/49.4.533; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Pusztai L, 2004, CANCER, V100, P1814, DOI 10.1002/cncr.20203; Ressom HW, 2007, BIOINFORMATICS, V23, P619, DOI 10.1093/bioinformatics/btl678; Rivals I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753724; Saul L. K., 2003, J MACHINE LEARNING R, V4, P119; Shin HJ, 2006, J BIOMED INFORM, V39, P227, DOI 10.1016/j.jbi.2005.04.002; Tang EK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-95; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Vapnik V., 1998, STAT LEARNING THEORY; Weinberger K., 2006, P NIPS, P1475; WILLIAMS B, 2005, P 43 ANN SE REG C MA; Xing E., 2003, P NIPS; Yang C, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-4; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Zhang K, 2005, PROC CVPR IEEE, P1001; ZHANG Z, 2003, P INT JOINT C ART IN	38	8	9	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics		2009	10								S3	10.1186/1471-2164-10-S1-S3		11	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	479BV	WOS:000268634900004	
J	Schierz, AC				Schierz, Amanda C.			Virtual screening of bioassay data	JOURNAL OF CHEMINFORMATICS			English	Article								Background: There are three main problems associated with the virtual screening of bioassay data. The first is access to freely-available curated data, the second is the number of false positives that occur in the physical primary screening process, and finally the data is highly-imbalanced with a low ratio of Active compounds to Inactive compounds. This paper first discusses these three problems and then a selection of Weka cost-sensitive classifiers (Naive Bayes, SVM, C4.5 and Random Forest) are applied to a variety of bioassay datasets. Results: Pharmaceutical bioassay data is not readily available to the academic community. The data held at PubChem is not curated and there is a lack of detailed cross-referencing between Primary and Confirmatory screening assays. With regard to the number of false positives that occur in the primary screening process, the analysis carried out has been shallow due to the lack of cross-referencing mentioned above. In six cases found, the average percentage of false positives from the High-Throughput Primary screen is quite high at 64%. For the cost-sensitive classification, Weka's implementations of the Support Vector Machine and C4.5 decision tree learner have performed relatively well. It was also found, that the setting of the Weka cost matrix is dependent on the base classifier used and not solely on the ratio of class imbalance. Conclusions: Understandably, pharmaceutical data is hard to obtain. However, it would be beneficial to both the pharmaceutical industry and to academics for curated primary screening and corresponding confirmatory data to be provided. Two benefits could be gained by employing virtual screening techniques to bioassay data. First, by reducing the search space of compounds to be screened and secondly, by analysing the false positives that occur in the primary screening process, the technology may be improved. The number of false positives arising from primary screening leads to the issue of whether this type of data should be used for virtual screening. Care when using Weka's cost-sensitive classifiers is needed - across the board misclassification costs based on class ratios should not be used when comparing differing classifiers for the same dataset.	Bournemouth Univ, Smart Technol Res Ctr, Poole BH12 5BB, Dorset, England	Schierz, AC (reprint author), Bournemouth Univ, Smart Technol Res Ctr, Poole House,Talbot Campus, Poole BH12 5BB, Dorset, England.	aschierz@bournemouth.ac.uk					[Anonymous], PUBCHEM HELP SOM I S; Bolton EE, 2010, ANN REP COMP CHEM, V4, P217, DOI 10.1016/S1574-1400(08)00012-1; Bradley D, 2008, NAT REV DRUG DISCOV, V7, P632, DOI 10.1038/nrd2649; Chen B, 2009, J MOL GRAPH IN PRESS; DiMasi JA, 2003, J HEALTH ECON, V22, P151, DOI 10.1016/S0167-6296(02)00126-1; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5; Ehrman TM, 2007, J CHEM INF MODEL, V47, P264, DOI 10.1021/ci600289v; Eitrich T, 2007, J CHEM INF MODEL, V47, P92, DOI 10.1021/ci60026l9; Elkan C., 2001, P 17 INT JOINT C ART, P973; Hollmen J, 2000, MANAG INFORMAT SYST, V2, P495; Leach A.R., 2003, INTRO CHEMOINFORMATI; Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1; Liu KJ, 2005, J CHEM INF MODEL, V45, P515, DOI 10.1021/ci049847v; Lo H.-Y., 2008, SIGKDD EXPLORATIONS, V10, P43; Seo YW, 2006, LECT NOTES COMPUT SC, V3975, P117; Sheng V.S., 2006, P 21 NAT C ART INT, P476; Wang Y, 2009, NUCLEIC ACIDS RES, pW623; Witten IH, 2005, DATA MINING PRACTICA	19	8	9	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1758-2946			J CHEMINFORMATICS	J. Cheminformatics		2009	1								21	10.1186/1758-2946-1-21		12	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	V21QM	WOS:000208222100021	
S	Gadi, MFA; Wang, XD; do Lago, AP		Bentley, PJ; Lee, D; Jung, S		Alonso Gadi, Manoel Fernando; Wang, Xidi; do Lago, Alair Pereira			Credit card fraud detection with Artificial Immune System	ARTIFICIAL IMMUNE SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	7th International Conference on Artificial Immune Systems	AUG 10-13, 2008	Phuket, THAILAND					We apply Artificial Immune Systems (AIS) [4] for credit card fraud detection and we compare it to other methods such as Neural Nets(NN) [8] and Bayesian Nets(BN) [2], Naive Bayes(NB) and Decision Trees(DT) [13]. Exhaustive search and Genetic Algorithm(GA) [7] are used to select, optimized parameters sets, which minimizes the fraud cost for a credit card database provided by a Brazilian card issuer. The specifics of the fraud database are taken into account, such as skewness of data and different, costs associated with false positives and negatives. Tests are done with holdout sample sets, and all executions are run using Weka [18], a publicly available software. Our results are consistent with the early result of Maes in [12] which concludes that BN is better than NN, and this occurred in all our evaluated tests. Although NN is widely used in the Market today, the evaluated implementation of NN is among the worse methods for our database. In spite of a poor behavior if used with the default parameters set, AIS has the best performance when parameters optimized by GA are used.	[Alonso Gadi, Manoel Fernando; do Lago, Alair Pereira] Univ Sao Paulo, Inst Matemat & Estatist, Dept Ciencia Computacao, BR-05508090 Sao Paulo, Brazil	Gadi, MFA (reprint author), Univ Sao Paulo, Inst Matemat & Estatist, Dept Ciencia Computacao, BR-05508090 Sao Paulo, Brazil.						BROWNLEE J, 2005, ARTIFICIAL IMMUNE RE; CHARNIAK E, 1991, AL MAGAZINE; DASGUPTA D, 1998, ARTFICIAL  IMMUNE SY; Decastro L. N., 2002, ARTIFICIAL IMMUNE SY; ELKAN G, 2001, IJCAI, P973; Fan W., 1999, P 16 INT C MACH LEAR, P97; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Kim JW, 1996, J PARALLEL DISTR COM, V32, P90, DOI 10.1006/jpdc.1996.0007; Klarreich E, 2002, NATURE, V415, P468, DOI 10.1038/415468a; MAES S, 2000, MACHINE LEARNING TEC; MAES S, 2002, P NF 2002 HAV CUB 16; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; PHUA C, 2005, ARTIFICIAL INT UNPUB; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; STOLFO S, 1997, WORK NOT AAAI WORKSH; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; WITTEN IH, 2008, SOFTWARE DOCUMENTATI; Witten IH, 2005, DATA MINING PRACTICA	19	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-85071-7	LECT NOTES COMPUT SC			2008	5132						119	131				13	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BID96	WOS:000258852800011	
J	Hu, XG; Li, PP; Wu, XD; Wu, GQ				Hu, Xue-Gang; Li, Pei-Pei; Wu, Xin-Dong; Wu, Gong-Qing			A semi-random multiple decision-tree algorithm for mining data streams	JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY			English	Article						data streams; Naive Bayes; random decision trees	INDUCTION	Mining with streaming data is a hot topic in data mining. When performing classification on data streams, traditional classification algorithms based on decision trees, such as ID3 and C4.5, have a relatively poor efficiency in both time and space due to the characteristics of streaming data. There are some advantages in time and space when using random decision trees. An incremental algorithm for mining data streams, SRMTDS (Semi-Random Multiple decision Trees for Data Streams), based on random decision trees is proposed in this paper. SRMTDS uses the inequality of Hoeffding bounds to choose the minimum number of split-examples, a heuristic method to compute the information gain for obtaining the split thresholds of numerical attributes, and a Naive Bayes classifier to estimate the class labels of tree leaves. Our extensive experimental study shows that SRMTDS has an improved performance in time, space, accuracy and the anti-noise capability in comparison with VFDTc, a state-of-the-art decision-tree algorithm for classifying data streams.	Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China; Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA	Hu, XG (reprint author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China.	jsjxhuxg@hfut.edu.cn; peipeili_hfut@163.com; xwu@cs.uvm.edu; wugongqing@gmail.com					Aggarwal C C, 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Blake C. L., 1998, UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang JH, 2003, P 9 ACM SIGKDD INT C, P487; Charikar M, 2003, P 35 ANN ACM S THEOR, P30, DOI DOI 10.1145/780542.780548; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347107; Fan W, 2003, P 3 IEEE INT C DAT M, P51, DOI DOI 10.1109/ICDM.2003.1250902; Gama J.a., 2003, P 9 ACM SIGKDD INT C, P523, DOI DOI 10.1145/956750.956813; GONG C, 2005, P ICDM 05 HOUST TX U, P585; Guha S., 2000, Proceedings 41st Annual Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2000.892124; Ho Tin Kam, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Kalles D, 1996, MACH LEARN, V24, P231, DOI 10.1007/BF00058613; LIU TF, 2005, P 9 PAC AS C KNOWL D, P605; Mao GJ, 2007, J INF SCI, V33, P251, DOI 10.1177/0165551506068179; MARON O, 1994, ADV NEURAL INFORM PR; OCLLAGHAN L, 2002, P ICDE 02 SAN JOS CA, P685; Ordonez C, 2003, P 8 ACM SIGMOD WORKS, P12; QIANG D, 2002, P ACM S APPL COMP SA, P413; Utgoff PE, 1997, MACH LEARN, V29, P5, DOI 10.1023/A:1007413323501; Xu Li-jun, 2006, Journal of Shanghai Jiaotong University, V40; XULI J, 2006, J SHANGHAI JIAOTONG, V40, P502; [周晓云 Zhou Xiaoyun], 2006, [计算机研究与发展, Journal of Computer Research and Development], V43, P834, DOI 10.1360/crad20060510	26	8	11	SCIENCE CHINA PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1000-9000			J COMPUT SCI TECHNOL	J. Comput. Sci. Technol.	SEP	2007	22	5					711	724		10.1007/s11390-007-9084-9		14	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Computer Science	218IN	WOS:000250009300007	
J	Nahar, J; Chen, YPP				Nahar, Jesmin; Chen, Yi-Ping Phoebe			Kernel-based naive Bayes classifier for breast cancer prediction	JOURNAL OF BIOLOGICAL SYSTEMS			English	Article						classification; breast cancer prediction; kernel-based naive Bayes classifier		The classification of breast cancer patients is of great importance in cancer diagnosis. Most classical cancer classification methods are clinical-based and have limited diagnostic ability. The recent advances in machine learning technique has made a great impact in cancer diagnosis. In this research, we develop a new algorithm: Kernel-Based Naive Bayes (KBNB) to classify breast cancer tumor based on memography data. The performance of the proposed algorithm is compared with that of classical navie bayes algorithm and kernel-based decision tree algorithm C4.5. The proposed algorithm is found to outperform in the both cases. We recommend the proposed algorithm could be, used as a tool to classify the breast patient for early cancer diagnosis.	Deakin Univ, Fac Sci & Technol, Sch Informat Technol & Engn, Geelong, Vic 3125, Australia; Univ Cent Queensland, Sch Informat Syst, Rockhampton, Qld 4702, Australia	Chen, YPP (reprint author), Deakin Univ, Fac Sci & Technol, Sch Informat Technol & Engn, 221 Burwood Highway, Geelong, Vic 3125, Australia.	phoebe@deakin.edu.au	Ali, A B M Shawkat /C-2354-2013	Ali, A B M Shawkat /0000-0002-9561-611X			CRISTIANINI N, 2002, AI MAGAZINE; DENTON A, 2004, P 2004 SIAM INT C DA; GAO C, 2004, ACM INT C MAN DAT SI; HENERY RJ, 1994, MACHINE LEARNING NEU, pCH7; Huang XH, 2003, BIOINFORMATICS, V19, P2072, DOI 10.1093/bioinformatics/btg283; KYUNGJOONG K, 2004, NEUROCOMPUTING, V61, P361; MEHRAN S, 1996, P 2 INT C KNOWL DISC, P335; NAHAR J, IN PRESS 9 INT C COM; Newman D. J., 1998, REPOSITORY MACHINE L; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; VAPNIK VN, 1999, IEEE T NEURAL NETW, V10; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; Yamauchi Y, 1999, LECT NOTES ARTIF INT, V1711, P334; Zhang J., 1992, P 9 INT MACH LEARN C, P470	15	8	8	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-3390			J BIOL SYST	J. Biol. Syst.	MAR	2007	15	1					17	25		10.1142/S0218339007002076		9	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	154UF	WOS:000245532600002	
S	Barreto, A; Zhai, J; Adjouadi, M		Lew, M; Sebe, N; Huang, TS; Bakker, EM		Barreto, Armando; Zhai, Jing; Adjouadi, Malek			Non-intrusive physiological monitoring for automated stress detection in human-computer interaction	HUMAN-COMPUTER INTERACTION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	IEEE International Workshop on Human - Computer Interaction	OCT   20, 2007	Rio de Janeiro, BRAZIL	IEEE, Leiden Inst Adv Comp Sci, Univ Amsterdam, Fac Sci, Univ Illinois Urbana Champaigen, Beckman Inst, BSIK, BRICKS, FOCUS, Netherlands Natl Sci Fdn		stress detection; affective computing; physiological sensing; biosignal processing; machine learning	INTERFERENCE	Affective Computing, one of the frontiers of Human-Computer Interaction studies, seeks to provide computers with the capability to react appropriately to a user's affective states. In order to achieve the required on-line assessment of those affective states, we propose to extract features from physiological signals from the user (Blood Volume Pulse, Galvanic Skin Response, Skin Temperature and Pupil Diameter), which can be processed by learning pattern recognition systems to classify the user's affective state. An initial implementation of our proposed system was set up to address the detection of "stress" states in a computer user. A computer-based "Paced Stroop Test" was designed to act as a stimulus to elicit emotional stress in the subject. Signal processing techniques were applied to the physiological signals monitored to extract features used by three learning algorithms: Naive Bayes, Decision Tree and Support Vector Machine to classify relaxed vs. stressed states.	[Barreto, Armando; Zhai, Jing; Adjouadi, Malek] Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33199 USA	Barreto, A (reprint author), Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33199 USA.						BARRETO A, 2003, WSEAS T CIRCUITS SYS, V3, P496; Beatty J., 2000, HDB PSYCHOPHYSIOLOGY, P142; Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197; Dishman RK, 2000, INT J PSYCHOPHYSIOL, V37, P121, DOI 10.1016/S0167-8760(00)00085-4; Grings W. W., 1978, EMOTIONS BODILY RESP; Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368; KROGSTAD AL, 1995, J AUTONOM NERV SYST, V53, P215, DOI 10.1016/0165-1838(94)00178-M; MARTINI F, 2001, FUNDAMENTALS ANATOMY, P78974; Partala T, 2003, INT J HUM-COMPUT ST, V59, P185, DOI 10.1016/S1071-5819(03)00017-X; Picard R. W., 1997, AFFECTIVE COMPUTING; Renaud P, 1997, INT J PSYCHOPHYSIOL, V27, P87, DOI 10.1016/S0167-8760(97)00049-4; Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/0096-3445.121.1.15; Witten IH, 2005, DATA MINING PRACTICA	13	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-75772-6	LECT NOTES COMPUT SC			2007	4796						29	38				10	Computer Science, Information Systems; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BHE72	WOS:000252490500004	
J	Flores, JL; Inza, I; Larranaga, P				Flores, J. L.; Inza, I.; Larranaga, P.			Wrapper discretization by means of estimation of distribution algorithms	INTELLIGENT DATA ANALYSIS			English	Article						discretization; classification; evolutionary computation; estimation of distribution algorithms	NAIVE-BAYES CLASSIFIERS; MULTIVARIATE DISCRETIZATION; CONTINUOUS ATTRIBUTES; INDUCTION; SELECTION; KHIOPS; MODELS	We present a supervised wrapper approach to discretization. In contrast to many classical approaches, the discretization process is multivariate: all variables are discretized simultaneously, and the proposed discretization is evaluated with the Naive-Bayes classifier. The search for the optimal discretization is carried out as an optimization process with the learning model estimated accuracy guiding it. The global optimization algorithm is based on estimation of distribution algorithms, a set of novel algorithms which are special kinds of evolutionary algorithms. In order to evaluate the behaviour of the algorithm, an analysis of different parameters is performed by means of analysis of variance (ANOVA). The evaluation was carried out using artificial datasets, and with UCI datasets. The results suggest that the proposed method provides an effective and robust technique for discretizating variables.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, San Sebastian 20080, Spain	Flores, JL (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, POB 649, San Sebastian 20080, Spain.	joseluis.flores@si.ehu.es; inza@si.ehu.es; ccplamup@si.ehu.es	Larranaga, Pedro/F-9293-2013				Bacardit J, 2003, LECT NOTES COMPUT SC, V2724, P1818; Bay S. D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347159; Blanco R, 2003, INT J INTELL SYST, V18, P205, DOI 10.1002/int.10084; Boulle M, 2005, LECT NOTES ARTIF INT, V3587, P228; Boulle M, 2003, LECT NOTES ARTIF INT, V2734, P50; Boulle M, 2004, MACH LEARN, V55, P53, DOI 10.1023/B:MACH.0000019804.29836.05; Boulle M, 2005, INTELL DATA ANAL, V9, P175; Butterworth R, 2004, J BIOMED INFORM, V37, P285, DOI 10.1016/j.jbi.2004.07.006; Castillo E., 1996, EXPERT SYSTEMS PROBA; CATLETT J, 1991, CHANGING CONTINUOUS, V482, P164; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; CHLEBUS BS, 1998, P 1 INT C ROUGH SETS, V1424, P545; CONSORTIUM E, 2002, ELVIRA ENV CREATING; DEBONCO R, 1996, ADV NEURAL INFORM PR, V9; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Duda R., 1973, PATTERN CLASSIFICATI; ETXEBERRIA R, 1999, GLOBAL OPTIMIZATION, V9, P332; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1023/A:1022638503176; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Ferrandiz S, 2005, LECT NOTES ARTIF INT, V3587, P600; Ferrandiz S, 2005, LECT NOTES ARTIF INT, V3587, P253; Gama J., 1998, LECT NOTES ARTIF INT, P160; Geurts P, 2000, LECT NOTES ARTIF INT, V1810, P162; Giraldez R, 2003, LECT NOTES COMPUT SC, V2723, P979; Gonzalez C, 2002, INT J APPROX REASON, V31, P313, DOI 10.1016/S0888-613X(02)00092-0; GRABCZEWSKI K, 2004, LECT NOTES COMPUTER, V3070, P574; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; HSU CN, 2002, MACH LEARNING J, V53; HUANG H, 2000, P 2000 INT COMP  S C; Inza I, 2001, ARTIF INTELL MED, V23, P187, DOI 10.1016/S0933-3657(01)00085-9; Kerber R., 1992, P 10 NAT C ART INT, P123; KNOTKANEN P, 1997, P EUR S INT TECHN, P265; Kohav R., 1996, P 13 INT C MACH LEAR, P275; Kohavi R., 1996, P 2 INT C KNOWL DISC, P114; KOZLOV AV, 1997, P 13 C UNC ART INT, P314; Kurgan LA, 2004, IEEE T KNOWL DATA EN, V16, P145, DOI 10.1109/TKDE.2004.1269594; Kwedlo W, 1999, LECT NOTES ARTIF INT, V1704, P392; Langley P., 1992, P 10 NAT C ART INT, P223; Larranaga P., 2002, ESTIMATION DISTRIBUT; Larranaga P., 2000, P 2000 GEN EV COMP C, P201; Larranaga P., 1999, KZZAIK499 U BASQ COU; Larranaga P., 2000, P 16 C UNC ART INT, P343; Liu L., 2004, Intelligent Data Analysis, V8; Minsky M., 1961, T I RADIO ENG, V49, P8; MUHLENBEIN H, 1996, NATURE LECT NOTES CO, V1141, P178; Muhlenbein H, 1999, EVOL COMPUT, V7, P353, DOI 10.1162/evco.1999.7.4.353; Muhlenbein H., 1998, EVOLUTIONARY COMPUTA, V5, P303; PAZZANI MJ, 1996, P 13 INT C MACH LEAR, V29, P105; PELIKAN M, 2000, LECT NOTES COMPUTER, V1, P212; Pelikan M., 2000, LECT NOTES COMPUTER, V1917, P385; Pelikan M, 2002, COMPUT OPTIM APPL, V21, P5, DOI 10.1023/A:1013500812258; PELIKAN M, 2000, LECT NOTES COMPUTER, P267; PFAHRINGER B, 1995, INT C MACH LEARN, P456; QUINLAN JR, 2004, LECT NOTES COMPUTER, V3171, P317; Revoredo K, 2004, LECT NOTES ARTIF INT, V3171, P317; Scheffe H, 1959, ANAL VARIANCE; Sebag M, 1998, LECT NOTES COMPUT SC, V1498, P418; Setiono R, 1995, P 7 IEEE INT C TOOLS, P388; SHACHTER RD, 1989, MANAGE SCI, V35, P527, DOI 10.1287/mnsc.35.5.527; Torgo L, 1997, LECT NOTES ARTIF INT, V1224, P266; VALDES J, 2003, P WORLD C EV COMP CA, P1957; VALDES JJ, 2003, EVOLUTION STRATEGIES; Wang MD, 2005, J STAT PLAN INFER, V131, P191, DOI 10.1016/j.jspi.2004.01.004; Witten IH, 2005, DATA MINING PRACTICA; Wu QX, 2006, LECT NOTES CONTR INF, V344, P778; Yang Y, 2003, DISCRETIZATION NAIVE; Yang Y, 2003, LECT NOTES ARTIF INT, V2903, P440; Zhang QF, 2004, IEEE T EVOLUT COMPUT, V8, P80, DOI 10.1109/TEVC.2003.819431; Zhang QF, 2004, IEEE T EVOLUT COMPUT, V8, P127, DOI 10.1109/TEVC.2003.820663; Zhigljavsky A.A., 1991, THEORY GLOBAL RANDOM	72	8	8	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1088-467X			INTELL DATA ANAL	Intell. Data Anal.		2007	11	5					525	545				21	Computer Science, Artificial Intelligence	Computer Science	229AX	WOS:000250774800006	
B	Kraetzer, C; Oermann, A; Dittmann, J; Lang, A			ACM	Kraetzer, Christian; Oermann, Andrea; Dittmann, Jana; Lang, Andreas			Digital Audio Forensics: A First Practical Evaluation on Microphone and Environment Classification	MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007			English	Proceedings Paper	9th ACM Multimedia and Security Workshop	SEP 20-21, 2007	Dallas, TX	ACM SIGMM		Digital Media Forensics; Multimedia Authentication		In this paper a first approach for digital media forensics is presented to determine the used microphones and the environments of recorded digital audio samples by using known audio steganalysis features. Our first evaluation is based on a limited exemplary test set of 10 different audio reference signals recorded as mono audio data by four microphones in 10 different rooms with 44.1 kHz sampling rate and 16 bit quantisation. Note that, of course, a generalisation of the results cannot be achieved. Motivated by the syntactical and semantical analysis of information and in particular by known audio steganalysis approaches, a first set of specific features are selected for classification to evaluate, whether this first feature set can support correct classifications. The idea was mainly driven by the existing steganalysis features and the question of applicability within a first and limited test set. In the tests presented in this paper, all inter-device analysis with different device characteristics is perforated while intra-device evaluations (identical microphone models of the same manufacturer) are not considered. For classification the data mining tool WEKA with K-means as a clustering and Naive Bayes as a classification technique are applied with the goal to evaluate their classification in regard to the classification accuracy on known audio steganalysis features. Our results show, that for our test set, the used classification techniques and selected steganalysis features, microphones call be better classified than environments. These first tests show promising results but of course are based on a limited test and training set as well a specific test set generation. Therefore additional and enhanced features with different test set generation strategies are necessary to generalise the findings.	[Kraetzer, Christian; Oermann, Andrea; Dittmann, Jana; Lang, Andreas] Univ Magdeburg, Dept Comp Sci, Res Grp Multimedia & Secur, D-39106 Magdeburg, Germany	Kraetzer, C (reprint author), Univ Magdeburg, Dept Comp Sci, Res Grp Multimedia & Secur, D-39106 Magdeburg, Germany.	kraetzer@iti.cs.uni-magdeburg.de; oermann@iti.cs.uni-magdeburg.de; dittmann@iti.cs.uni-magdeburg.de; alang@iti.cs.uni-magdeburg.de					Borgelt C, 2001, ADV SOFT COMP, P121; DITTMANN J, 2005, SECURITY STEGANOGRAP, V7, P607; Fridrich J., 2006, IEEE T INFORM SECURI, V1, P205; Hand DJ, 2001, PRINCIPLES DATA MINI; KHANNA N, 2006, P 6 DIG FOR RES WORK; KRAETZER C, 2006, SPIE C SECURITY STEG, V8; KRAETZER C, 2007, SPIE, V6505; LUKAS J, 2005, P SPIE INT C SECURIT, V7, P249; MacQueen J.B., 1967, P 5 BERK S MATH STAT, P281; Mikkilineni A. K., 2005, P IS TS NIP21 INT C, P223; Mikkilineni AK, 2005, P SOC PHOTO-OPT INS, V5681, P430, DOI 10.1117/12.593796; MOORE A, 2007, K MEANS HIERARCHICAL; Oermann A., 2005, P ACM MULT SEC WORKS, P57, DOI 10.1145/1073170.1073181; OERMANN A, 2007, P D A CH SEC 2007; OERMANN A, 2007, P SPIE ELECT IMAGING, V3; WATERS G, 1988, SOUND QUALITY ASSESS; Witten IH, 2005, DATA MINING PRACTICA	17	8	9	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-59593-857-2				2007							63	73				11	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	BKM78	WOS:000268585900007	
S	Lefebvre, C; Lim, WK; Basso, K; Favera, RD; Califano, A		Ideker, T; Bafna, V		Lefebvre, Celine; Lim, Wei Keat; Basso, Katia; Favera, Riccardo Dalla; Califano, Andrea			A context-specific network of protein-DNA and protein-protein interactions reveals new regulatory motifs in human B cells	SYSTEMS BIOLOGY AND COMPUTATIONAL PROTEOMICS	Lecture Notes in Computer Science		English	Proceedings Paper	RECOMB Satellite Conference on Systems Biology and Computational Proteomics	DEC 01-06, 2006	La Jolla, CA	Int Soc Computat Biol, Mol Syst Biol, Pfizer, UCSD Jacobs Sch Engn, Calif Inst Telecommun & Informat Technol		combinatorial regulation; evidence integration; human B cells; naive Bayes; network motifs	TRANSCRIPTION FACTOR; CELLULAR NETWORKS; GENE ONTOLOGY; DATABASE; BIOLOGY; TOOL	Recent genome wide studies in yeast have started to unravel the complex, combinatorial nature of transcriptional regulation in eukaryotic cells, including the concerted regulation of proteins involved in complex formation. In this work, we use a Bayesian evidence integration framework to assemble an integrated network, including both protein-DNA and protein-protein interactions, in a specific cellular context(human B cells). We then use it to study common interaction motifs between protein complexes and regulatory programs, using an enrichment analysis approach. Specifically, we compare the frequency of mixed interaction motifs in the real network against random networks of equivalent connectivity. These motifs include sets of target genes regulated by multiple interacting transcription factors, and gene sets encoding same complex proteins regulated by different transcription factors.	Columbia Univ, Ctr Computat Biol & Bioinformat, New York, NY 10032 USA	Califano, A (reprint author), Columbia Univ, Ctr Computat Biol & Bioinformat, 1130 St Nicholas Ave,9th Floor, New York, NY 10032 USA.	califano@c2b2.columbia.edu					Alterovitz G, 2007, NUCLEIC ACIDS RES, V35, pD322, DOI 10.1093/nar/gkl799; Ashburner M, 2000, NAT GENET, V25, P25; Bader GD, 2003, NUCLEIC ACIDS RES, V31, P248, DOI 10.1093/nar/gkg056; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Ge H, 2001, NAT GENET, V29, P482, DOI 10.1038/ng776; Hermjakob H, 2004, NUCLEIC ACIDS RES, V32, pD452, DOI 10.1093/nar/gkh052; Hua XX, 1999, P NATL ACAD SCI USA, V96, P13130, DOI 10.1073/pnas.96.23.13130; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Kumar A, 2002, GENE DEV, V16, P707, DOI 10.1101/gad.970902; Margolin AA, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S7; MATSYS V, 2003, NUCLEIC ACIDS RES, V31, P374; Mewes HW, 2006, NUCLEIC ACIDS RES, V34, pD169, DOI 10.1093/nar/gkj148; O'Brien KP, 2005, NUCLEIC ACIDS RES, V33, pD476, DOI 10.1093/nar/gki107; Peri S, 2003, GENOME RES, V13, P2363, DOI 10.1101/gr.1680803; Rhodes DR, 2005, NAT BIOTECHNOL, V23, P951, DOI 10.1038/nbt1103; Rual JF, 2005, NATURE, V437, P1173, DOI 10.1038/nature04209; Rzhetsky A, 2004, J BIOMED INFORM, V37, P43, DOI 10.1016/j.jbi.2003.10.001; Stelzl U, 2005, CELL, V122, P957, DOI 10.1016/j.cell.2005.08.029; Vazquez A, 2003, NAT BIOTECHNOL, V21, P697, DOI 10.1038/nbt825; Wang K, 2006, LECT NOTES COMPUT SC, V3909, P348; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Yeger-Lotem E, 2004, P NATL ACAD SCI USA, V101, P5934, DOI 10.1073/pnas.0306752101; Yu HY, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-7-r55; Zeller KI, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-10-r69	24	8	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-73059-0	LECT NOTES COMPUT SC			2007	4532						42	56				15	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Theory & Methods	Biochemistry & Molecular Biology; Computer Science	BGN93	WOS:000248903500004	
B	Ye, YF; Wang, DD; Li, T; Ye, DY		Berkhin, P; Caruana, R; Wu, X; Gaffney, S		Ye, Yanfang; Wang, Dingding; Li, Tao; Ye, Dongyi			IMDS: Intelligent Malware Detection System	KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING			English	Proceedings Paper	13th International Conference on Knowledge Discovery and Data Mining	AUG 12-15, 2007	San Jose, CA	ACM SIGKDD, ACM SIGMOD		Malware; PE file; Windows API sequence; OOA mining		The proliferation of malware has presented a serious threat to the security of computer systems. Traditional signature-based antivirus systems fail to detect polymorphic and new, previously unseen malicious executables. In this paper, resting on the analysis of Windows API execution sequences called by PE files, we develop the Intelligent Malware Detection System (IMDS) using Objective-Oriented Association (OOA) mining based classification. IMDS is an integrated system consisting of three major modules: PE parser, OOA rule generator, and rule based classifier. An OOA_Fast_FP-Growth algorithm is adapted to efficiently generate OOA rules for classification. A comprehensive experimental study on a large collection of PE files obtained from the anti-virus laboratory of King-Soft Corporation is performed to compare various malware detection approaches. Promising experimental results demonstrate that the accuracy and efficiency of our IMDS system outperform popular anti-virus software such as Norton AntiVirus and McAfee VirusScan, as well as previous data mining based detection systems which employed Naive Bayes, Support Vector Machine (SVM) and Decision Tree techniques.	[Ye, Yanfang] Xiamen Univ, Dept Comp Sci, Xiamen 361005, Peoples R China	Ye, YF (reprint author), Xiamen Univ, Dept Comp Sci, Xiamen 361005, Peoples R China.	yeyanfang@yahoo.com.cn; dwang003@cs.fiu.edu; taoli@cs.fiu.edu; yiedy@fzu.edu.cn					AGRAWAL R, 1994, P VLDB 94; CHENG H, 2007, ICDE 07; Christodorescu M., 2003, P 12 USENIX SEC S; [范明 Fan Ming], 2003, [计算机研究与发展, Journal of Computer Research and Development], V40, P1216; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; Han Jiawei, 2006, DATA MINING CONCEPTS; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Kephart J. O., 1994, P 4 VIR B INT C, P178; KOLTER J, 2004, P KDD 04; LIU B, 1998, P KDD 98; Peng Hanchuan, 2005, IEEE T PATTERN ANAL, V27; Rabek J., 2003, P 2003 ACM WORKSH RA, P76, DOI 10.1145/948187.948201; Schultz M., 2001, P IEEE INT C DAT MIN; Shen Y., 2002, P IEEE INT C DAT MIN; Sung A.H., 2004, P 20 ANN COMP SEC AP; Swets JA, 1982, EVALUATION DIAGNOSTI; Tan P-N, 2005, INTRO DATA MINING; WANG J, 2003, P IEEE INT C DAT MIN; Witten H., 2005, DATA MINING PRACTICA; XU J, 2004, P INT C HYBR INT SYS	20	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-59593-609-7				2007							1043	1047				5	Computer Science, Artificial Intelligence	Computer Science	BJK16	WOS:000266628300110	
J	Zhang, H; Su, J				Zhang, H; Su, J			Learning probabilistic decision trees for AUC	PATTERN RECOGNITION LETTERS			English	Article						decision trees; AUC; naive Bayes; ranking		Accurate ranking, measured by AUC (the area under the ROC curve), is crucial in many real-world applications. Most traditional learning algorithms, however, aim only at high classification accuracy. It has been observed that traditional decision trees produce good classification accuracy but poor probability estimates. Since the ranking generated by a decision tree is based on the class probabilities, a probability estimation tree (PET) with accurate probability estimates is desired in order to yield high AUC. Some researchers ascribe the poor probability estimates of decision trees to the decision tree learning algorithms. To our observation, however, the representation also plays an important role. In this paper, we propose to extend decision trees to represent a joint distribution and conditional independence, called conditional independence trees (CITrees), which is a more suitable model for yielding high AUC. We propose a novel AUC-based algorithm for learning CITrees, and our experiments show that the CITree algorithm outperforms the state-of-the-art decision tree learning algorithm C4.4 (a variant of C4.5), naive Bayes, and NBTree in AUC. Our work provides an effective model and algorithm for applications in which an accurate ranking is required. (c) 2005 Elsevier B.V. All rights reserved.	Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Zhang, H (reprint author), Univ New Brunswick, Fac Comp Sci, POB 4400, Fredericton, NB E3B 5A3, Canada.	hzhang@unb.ca					BUNTINE W, 1991, LEARNING CLASSIFICAT, P182; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Ferri C., 2003, P 14 EUR C MACH LEAR, P121; Ferri C., 2002, P 19 INT C MACH LEAR, P139; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; Ling C.X., 2003, P 20 INT C MACH LEAR, P480; Merz C., 1997, UCI REPOSITORY MACHI; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F., 1998, P 15 INT C MACH LEAR, P445; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; SYMTH P, 1996, P 12 INT C MACH LEAR, P506; Witten I.H., 2000, DATA MINING PRACTICA	17	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2006	27	8					892	899		10.1016/j.patrec.2005.10.013		8	Computer Science, Artificial Intelligence	Computer Science	041NL	WOS:000237462800005	
J	Randon, NJ; Lawry, J				Randon, NJ; Lawry, J			Classification and query evaluation using modelling with words	INFORMATION SCIENCES			English	Article; Proceedings Paper	9th International Conference on Information Processing and Management of Uncertainty in Knowledge Based Systems	JUL 01-05, 2002	ANNECY, FRANCE			random sets; label semantics; mass assignments; label prototypes; Semi-Naive Bayes		A random set based knowledge representation framework for learning linguistic models is presented. Within this framework a number of algorithms for learning prototypes are proposed, based on grouping certain sets of attributes and evaluating joint mass assignments on labels. These mass assignments can then be combined with a Semi-Naive Bayes classifier in order to determine classification probabilities. The potential of such linguistic classifiers is then illustrated by their application to a number of toy and benchmark problems. This framework also allows for the evaluation of linguistic queries as will be demonstrated on several well known data sets. (C) 2005 Elsevier Inc. All rights reserved.	Univ Bristol, AI Grp, Dept Engn Math, Bristol BS8 1TR, Avon, England	Randon, NJ (reprint author), Univ Bristol, AI Grp, Dept Engn Math, Bristol BS8 1TR, Avon, England.	nick.randon@bris.ac.uk; j.lawry@bris.ac.uk					Baldwin J F, 1995, FRIL FUZZY EVIDENTIA; BALDWIN JF, 1998, P IMPF98 PAR FRANC; Baldwin JF, 1999, INT J INTELL SYST, V14, P1041, DOI 10.1002/(SICI)1098-111X(199910)14:10<1041::AID-INT6>3.0.CO;2-9; DUBOIS D, 2001, FUZZ IEEE; Frie T-T, 1998, P 15 INT C MACH LEAR, P188; Goodman I.R., 1982, FUZZY SET POSSIBILIT, P327; Goodman IR, 1985, UNCERTAINTY MODELS K; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; KONONENKO I, 1991, SEMINAIVE BAYESIAN C, P206; LAWRY J, 2001, P NAFIPS; Lewis D., 1998, LECT NOTES COMPUTER, V1398, P4, DOI DOI 10.1007/BFB0026666; WOLPERT DH, 1995, SFITR9502010 SANT FE	12	8	8	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	FEB	2006	176	4			SI		438	464		10.1016/j.ins.2005.07.019		27	Computer Science, Information Systems	Computer Science	004NL	WOS:000234759400006	
J	Huang, DS; Huang, X				Huang, De-Shuang; Huang, Xin			Improved performance in protein secondary structure prediction by combining multiple predictions	PROTEIN AND PEPTIDE LETTERS			English	Article						protein secondary structure prediction; two-level network; reliability score; naive bayes; semi-probability profile; multiple sequence alignment	NEURAL-NETWORKS; PATTERN-RECOGNITION; POLYNOMIALS	In this paper(1) we present a novel framework for protein secondary structure prediction. In this prediction framework, firstly we propose a novel parameterized semi-probability profile, which combines single sequence with evolutionary information effectively. Secondly, different semi-probability profiles are respectively applied as network input to predict protein secondary structure. Then a comparison among these different predictions is discussed in this article. Finally, naive Bayes approaches are used to combine these predictions in order to obtain a better prediction performance than individual prediction. The experimental results show that our proposed framework can indeed improve the prediction accuracy.	CAS, Hefei Inst Intelligent Machines, Intelligent Comp Lab, Hefei, Anhui, Peoples R China	Huang, DS (reprint author), CAS, Hefei Inst Intelligent Machines, Intelligent Comp Lab, POB 1130, Hefei, Anhui, Peoples R China.	dshuang@iim.ac.cn					Baker D, 2001, SCIENCE, V294, P93, DOI 10.1126/science.1065659; Chandonia JM, 1999, PROTEINS, V35, P293; Cuff JA, 1999, PROTEINS, V34, P508, DOI 10.1002/(SICI)1097-0134(19990301)34:4<508::AID-PROT10>3.0.CO;2-4; Cuff JA, 1998, BIOINFORMATICS, V14, P892, DOI 10.1093/bioinformatics/14.10.892; Duda R., 1973, PATTERN CLASSIFICATI; Good I, 1965, ESTIMATION PROBABILI; Huang D.S., 1999, J INTELLIGENT SYSTEM, V9, P1; Huang DS, 2004, IEEE T NEURAL NETWOR, V15, P477, DOI 10.1109/TNN.2004.824424; Huang DS, 1997, INT J PATTERN RECOGN, V11, P873, DOI 10.1142/S0218001497000391; Huang DS, 1998, IEEE T SYST MAN CY B, V28, P477, DOI 10.1109/3477.678658; Huang DS, 2004, NEURAL COMPUT, V16, P1721, DOI 10.1162/089976604774201668; Huang X, 2005, PROTEIN PEPTIDE LETT, V12, P805, DOI 10.2174/0929866054864328; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; KNELLER DG, 1990, J MOL BIOL, V214, P171, DOI 10.1016/0022-2836(90)90154-E; Langley P., 1994, P 10 C UNC ART INT, P399; Lio P, 1998, BIOINFORMATICS, V14, P726, DOI 10.1093/bioinformatics/14.8.726; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Robles V, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P168; ROST B, 1993, P NATL ACAD SCI USA, V90, P7558, DOI 10.1073/pnas.90.16.7558; ROST B, 1994, PROTEINS, V19, P55, DOI 10.1002/prot.340190108; Zimmermann K, 1998, PROTEIN ENG, V11, P861, DOI 10.1093/protein/11.10.861	23	8	8	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	0929-8665			PROTEIN PEPTIDE LETT	Protein Pept. Lett.		2006	13	10					985	991		10.2174/092986606778777551		7	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	105CJ	WOS:000242006600006	
J	Langseth, H; Nielsen, TD				Langseth, H; Nielsen, TD			Latent classification models	MACHINE LEARNING			English	Article						classification; probabilistic graphical models; naive Bayes; correlation	NAIVE-BAYES; ALGORITHMS; INFERENCE	One of the simplest, and yet most consistently well-performing set of classifiers is the Naive Bayes models. These models rely on two assumptions: (i) All the attributes used to describe an instance are conditionally independent given the class of that instance, and (ii) all attributes follow a specific parametric family of distributions. In this paper we propose a new set of models for classification in continuous domains, termed latent classification models. The latent classification model can roughly be seen as combining the Naive Bayes model with a mixture of factor analyzers, thereby relaxing the assumptions of the Naive Bayes classifier. In the proposed model the continuous attributes are described by a mixture of multivariate Gaussians, where the conditional dependencies among the attributes are encoded using latent variables. We present algorithms for learning both the parameters and the structure of a latent classification model, and we demonstrate empirically that the accuracy of the proposed model is significantly higher than the accuracy of other probabilistic classifiers.	Norwegian Univ Sci & Technol, Dept Math Sci, N-7491 Trondheim, Norway; Univ Aalborg, Dept Comp Sci, DK-9220 Aalborg, Denmark	Langseth, H (reprint author), Norwegian Univ Sci & Technol, Dept Math Sci, N-7491 Trondheim, Norway.	helgel@math.ntnu.no; tdn@cs.auc.dk					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACHI; BOTTCHER SG, 2001, P 8 INT WORKSH ART I, P149; Bressan M, 2002, LECT NOTES ARTIF INT, V2527, P1; Burges C. J. C., 1998, DATA MIN KNOWL DISC, V2, P955; CAMPBELL NA, 1974, AUST J ZOOL, V22, P417, DOI 10.1071/ZO9740417; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Fokoue E, 2003, MACH LEARN, V50, P73, DOI 10.1023/A:1020297828025; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N, 1998, P 15 INT C MACH LEAR, P179; Friedman N, 1998, P 14 C UNC ART INT, P129; Gama J, 2000, LECT NOTES ARTIF INT, V1952, P269; Geiger D, 1994, MSRTR9410; Ghahramani Z, 1996, CRGTR961 U TOR DEP C; GREINER R, 1997, P 13 C UNC ART INT S, P198; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Hyvarinen A., 2001, INDEPENDENT COMPONEN; JOHN GH, 1995, P 11 C UNC ART INT, P338; KENDALL M., 1980, MULTIVARIATE ANAL; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; McLachlan G, 2004, DISCRIMINANT ANAL ST; MINKA TP, 2000, ADV NEURAL INFORMATI, V13, P598; Mitchell T.M., 1997, MACHINE LEARNING; MONTI S, 1999, LEARNING GRAPHICAL M, P521; MONTI S, 1999, P 15 C UNC ART INT S, P447; MURPHY KP, 1998, FITTING CONDITIONAL; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Ripley B., 1996, PATTERN RECOGNITION; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; RUBIN DB, 1982, PSYCHOMETRIKA, V47, P69, DOI 10.1007/BF02293851; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Vilalta R, 2003, LECT NOTES ARTIF INT, V2837, P444; Witten I.H., 2000, DATA MINING PRACTICA	40	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	JUN	2005	59	3					237	265				29	Computer Science, Artificial Intelligence	Computer Science	933FG	WOS:000229613700003	
S	Cao, MD; Gao, XY		Zhang, S; Jarvis, R		Cao, MD; Gao, XY			Combining contents and citations for scientific document classification	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol		MODELS	This paper introduces a classification system that exploits the content information as well as citation structure for scientific paper classification. The system first applies a content-based statistical classification method which is similar to general text classification. We investigate several classification methods including K-nearest neighbours, nearest centroid, naive Bayes and decision trees. Among those methods, the K-nearest neighbours is found to outperform others while the rest perform comparably. Using phrases in addition to words and a good feature selection strategy such as information gain can improve system accuracy and reduce training time in comparison with using words only. To combine citation links for classification, the system proposes an iterative method to update the labellings of classified instances using citation links. Our results show that, combining contents and citations significantly improves the system performance.	Victoria Univ Wellington, Sch Math Stat & Comp Sci, Wellington, New Zealand	Cao, MD (reprint author), Victoria Univ Wellington, Sch Math Stat & Comp Sci, POB 600, Wellington, New Zealand.	minhduc@mcs.vuw.ac.nz; xgao@mcs.vuw.ac.nz	Cao, Minh Duc/D-9356-2012	Cao, Minh Duc/0000-0003-4079-2383			BORKO H, 1963, J ACM, V10, P151, DOI 10.1145/321160.321165; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Chakrabarti S., 1998, SIGMOD 98, P307; COHEN WW, 1996, ADV INDUCTIVE LOGIC, P124; Craven M, 2001, MACH LEARN, V43, P97, DOI 10.1023/A:1007676901476; Getoor L, 2003, J MACH LEARN RES, V3, P679, DOI 10.1162/jmlr.2003.3.4-5.679; Han E.-H., 2000, PRINCIPLES DATA MINI, P424; Joachims T., 1998, P ECML 98 10 EUR C M, V1398, P137; JUNKER M, 1999, P 1 WORKSH LEARN LAN, P84; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Lewis D., 1998, P 10 EUR C MACH LEAR, V1398, P4; LEWIS D, 1992, P SIGIR 92 15 ACM IN, P289; McCallum A, 1998, AAAI 98 WORKSH LEARN; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; Mitchell T.M., 1997, MACHINE LEARNING; Nigam K, 1999, IJCAI 99 WORKSH MACH, P61; Porter M.F., 1997, ALGORITHM SUFFIX STR, P313; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Taskar B., 2001, P 17 INT JOINT C ART, P870; Wiener E., 1995, P 4 ANN S DOC AN INF, P317; WITTEN IH, 2000, PRACTICAL MACHINE LE; Yang Y., 1997, P 14 INT C MACH LEAR, P412	23	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						143	152				10	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100017	
J	Ko, Y; Seo, J				Ko, Y; Seo, J			Using the feature projection technique based on a normalized voting method for text classification	INFORMATION PROCESSING & MANAGEMENT			English	Article						text categorization; text classifier; feature projections; instance-based learning; k-NN	LEARNING ALGORITHMS; RETRIEVAL	This paper proposes a new approach for text categorization, based on a feature projection technique. In our approach, training data are represented as the projections of training documents on each feature. The voting for a classification is processed on the basis of individual feature projections. The final classification of test documents is determined by a majority voting from the individual classifications of each feature. Our empirical results show that the proposed approach, text categorization using feature projections (TCFP), outperforms k-NN, Rocchio, and Naive Bayes. Most of all, TCFP is a faster classifier, up to one hundred times faster than k-NN in the Newsgroups data set. It is also robust from noisy data. Since the TCFP algorithm is very simple, its implementation and training process can be done very easily. For these reasons, TCFP can be a useful classifier in text categorization tasks, which need fast execution speed, robustness, and high performance. (C) 2003 Elsevier Ltd. All rights reserved.	Sogang Univ, Dept Comp Sci, NLP Lab, Seoul 121742, South Korea	Ko, Y (reprint author), Sogang Univ, Dept Comp Sci, NLP Lab, Sinsu Dong 1, Seoul 121742, South Korea.	kyj@nlpzodiac.sogang.ac.kr; seojy@ccs.sogang.ac.kr					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Akkus A, 1996, P 13 INT C MACH LEAR, P12; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; Duda R.O., 2001, PATTERN CLASSIFICATI; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Keogh E., 1997, P 14 INT C MACH LEAR, P406; Ko Y., 2000, P 18 INT C COMP LING, P453; KO Y, IN PRESS INFORMATION; LEWIN G, 1996, ANNU REV NEUROSCI, V9, P289; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; NIGAM K, 2001, USING UNLABELED DATA; SALTON G, 1983, INTRO MODERN INFORMA; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H; Vapnic V, 1995, NATURE STAT LEARNING; WESTON V, 1999, P 7 EUR S ART NEUR N; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; YAN GY, 1994, P 17 INT ACM SIGIR C, P13; YAN GY, 1997, P 14 INT C MACH LEAR, P412; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Yang Y., 2002, J INTELLIGENT INFORM, V18; ZHANG J, 1992, P 9 INT C MACH LEARN	23	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573			INFORM PROCESS MANAG	Inf. Process. Manage.	MAR	2004	40	2					191	208		10.1016/S0306-4573(03)00029-3		18	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	778FD	WOS:000189228000001	
S	Castillo, G; Gama, J; Breda, AM		Brusilovsky, P; Corbett, A; DeRosis, F		Castillo, G; Gama, J; Breda, AM			Adaptive Bayes for a student modeling prediction task based on learning styles	USER MODELING 2003, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th International Conference on User Modeling	JUN 22-26, 2003	JOHNSTOWN, PENNSYLVANIA	Univ Pittsburgh, User Modeling Inc				We present Adaptive Bayes, an adaptive incremental version of Naive Bayes, to model a prediction task based on learning styles in the context of an Adaptive Hypermedia Educational System. Since the student's preferences can change over time, this task is related to a problem known as concept drift in the machine learning community. For this class of problems an adaptive predictive model, able to adapt quickly to the user's changes, is desirable. The results from conducted experiments show that Adaptive Bayes seems to be a fine and simple choice for this kind of prediction task in user modeling.	Univ Aveiro, Dept Math, R&D Unit Math & Applicat, P-3810 Aveiro, Portugal; Univ Porto, LIACC, P-4150 Oporto, Portugal	Castillo, G (reprint author), Univ Aveiro, Dept Math, R&D Unit Math & Applicat, P-3810 Aveiro, Portugal.		Gama, Joao/A-2070-2008	Gama, Joao/0000-0003-3357-1195			Felder R.M., INDEX LEARNING STYLE; GAMA J, 2002, ADV ARTIFICIAL INTEL, P776; Howard PA, 1999, ANN PHARMACOTHER, V33, P38, DOI 10.1345/aph.18097; Koychev I., 2000, P ECML2000 WORKSH MA; Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175	5	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40381-7	LECT NOTES ARTIF INT			2003	2702						328	332				5	Computer Science, Artificial Intelligence	Computer Science	BX29T	WOS:000184852200041	
S	Cohen, I; Sebe, N; Cozman, FG; Cirelo, MC; Huang, TS			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Cohen, I; Sebe, N; Cozman, FG; Cirelo, MC; Huang, TS			Learning Bayesian network classifiers for facial expression recognition using both labeled and unlabeled data	2003 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOL 1, PROCEEDINGS	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 18-20, 2003	MADISON, WI	IEEE Comp Soc, Tech Comm Pattern Anal & Machine Intelligence			EM	Understanding human emotions is one of the necessary skills for the computer to interact intelligently with human users. The most expressive way humans display emotions is through facial expressions. In this paper, we report on several advances we have made in building a system for classification of facial expressions from continuous video input. We use Bayesian network classifiers for classifying expressions from video. One of the motivating factor in using the Bayesian network classifiers is their ability to handle missing data, both during inference and training. In particular, we are interested in the problem of learning with both labeled and unlabeled data. We show that when using unlabeled data to learn classifiers, using correct modeling assumptions is critical for achieving improved classification performance. Motivated by this, we introduce a classification driven stochastic structure search algorithm for learning the structure of Bayesian network classifiers. We show that with moderate size labeled training sets and large amount of unlabeled data, our method can utilize unlabeled data to improve classification performance. We also provide results using the Naive Bayes (NB) and the Tree-Augmented Naive Bayes (TAN) classifiers, showing that the two can achieve good performance with labeled training sets, but perform poorly when unlabeled data are added to the training set.	Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	Cohen, I (reprint author), Univ Illinois, Beckman Inst, Urbana, IL 61801 USA.						BALUJA S, 1998, NIPS; Blake C. L., 1998, UCI REPOSITORY MACHI; CASTELLI V, 1994, THESIS STANFORD; Chen L. S., 2000, THESIS U ILLINOIS UR; COHEN I, 2003, IN PRESS CVIU SPECIA; COHEN I, 2002, ICME; COOPER G, 1992, MACH LEARN, V9, P308; COZMAN FG, 2002, FLAIRS; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Ekman P., 1978, FACIAL ACTION CODING; EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037//0033-2909.115.2.268; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; HAJEK B, 1988, MATH OPER RES, V13, P311, DOI 10.1287/moor.13.2.311; KANADE T, 2000, COMPREHENSIVE DATABA; MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615; MEILA M, 1999, THESIS MIT; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pearl J., 1988, PROBABILISTIC REASON; Seeger M., 2001, LEARNING LABELED UNL; TAO H, 1998, CVPR, P735; ZHANG T, 2000, ICML	23	8	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		0-7695-1900-8	PROC CVPR IEEE			2003							595	601				7	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BX05B	WOS:000184081300078	
S	Escudero, G; Marquez, L; Rigau, G		LaopezDeMantaras, R; Plaza, E		Escudero, G; Marquez, L; Rigau, G			Boosting applied to word sense disambiguation	MACHINE LEARNING: ECML 2000	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	11th European Conference on Machine Learning	MAY 31-JUN 02, 2000	BARCELONA, SPAIN	European Network Excellence Machine Learn, CSIC, Spanish Sci & Technol Council, Catalan Assoc Artifical Intell, Inst Invest Intell Artif				In this paper Schapire and Singer's AdaBoost.MH boosting algorithm is applied to the Word Sense Disambiguation (WSD) problem. Initial experiments on a set of 15 selected polysemous words show that the boosting approach surpasses Naive Bayes and Exemplar-based approaches, which represent state-of-the-art accuracy on supervised WSD. In order to make boosting practical for a real learning domain of thousands of words, several ways of accelerating the algorithm by reducing the feature space are studied. The best variant, which we call LazyBoosting, is tested on the largest sense-tagged corpus available containing 192,800 examples of the 191 most frequent and ambiguous English words. Again, boosting compares favourably to the other benchmark algorithms.	Univ Politecn Catalunya, TALP Res Ctr, LSI Dept, E-08034 Barcelona, Spain	Escudero, G (reprint author), Univ Politecn Catalunya, TALP Res Ctr, LSI Dept, Jordi Girona Salgado 1-3, E-08034 Barcelona, Spain.						ABNEY S, 1999, P JOINT SIGDAT C EMP; BAUER E, 1999, MACHINE LEARNING J; BREIMAN L, 1998, ANN STAT, P26; DEMANTARAS RL, 1991, MACH LEARN, P6; DIETTERICH TG, IN PRESS EXPT COMP 3; Duda R., 1973, PATTERN CLASSIFICATI; ENGELSON SP, 1996, LNAI, V1040; ESCUDERO G, 2000, LSI003R UPC; FREUND Y, 1997, J COMPUTER SYSTEM SC, P55; Freund Y, 1996, P 13 INT C MACH LEAR; FUJII A, 1998, COMPUTATIONAL LINGUI, P24; IDE N, 1998, COMPUTATIONAL LINGUI, P24; LEACOCK C, 1998, COMPUTATIONAL LINGUI, P24; MARQUEZ L, 1999, THESIS LSI DEP; MIHALCEA R, 1999, P 16 NAT C ART INT; MILLER GA, 1990, SPECIAL ISSUE INT J, P3; MOONEY RJ, 1996, P 1 C EMP METH NAT L; NG HT, 1997, P SIGLEX WORKSH TAGG; NG HT, 1996, P 34 ANN M ASS COMP; Ng H.T., 1999, P SIGLEX WORKSH STAN; NG HT, 1997, P 2 C EMP METH NAT L; PEDERSEN T, 1998, P 15 NAT C ART INT; Quinlan J.R., 1996, P 13 NAT C ART INT; SAMUEL K, 1998, P 11 INT FLOR AI RES; SCHAPIRE RE, IN PRESS BOOSTEXTER; SCHAPIRE RE, IN PRESS IMPROVED BO; TOWELL G, 1998, COMPUTATIONAL LINGUI, P24; YAROWSKY D, 1994, P 32 ANN M ASS COMP	28	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-67602-3	LECT NOTES ARTIF INT			2000	1810						129	141				13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BR57W	WOS:000166853300014	
J	Kim, J; Gleser, LJ				Kim, J; Gleser, LJ			SIMEX approaches to measurement error in ROC studies	COMMUNICATIONS IN STATISTICS-THEORY AND METHODS			English	Article						ROC curve; bias correction; regression calibration; Empirical Bayes; UMVUE; simulation and extrapolation	MODELS	This paper explores the estimation of the area under the ROC curve when test scores are subject to errors. The naive approach that ignores measurement errors generally yields inconsistent estimates, Finding the asymptotic bias of the naive estimator, Coffin and Sukhatme (1995, 1997) proposed bias-corrected estimators for parametric and nonparametric cases. However, the asymptotic distributions of these estimators have not been developed because of their complexity. We propose several alternative approaches, including the SIMEX procedure of Cook and Stefanski (1994). We also provide the asymptotic distributions of the SIMEX estimators for use in statistical inference. Small simulation studies illustrate that the SIMEX estimators perform reasonably well when compared to the bias-corrected estimators.	Univ Pittsburgh, Dept Stat, Pittsburgh, PA 15260 USA							BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; Carroll R. J., 1995, MEASUREMENT ERROR NO; Carroll RJ, 1996, J AM STAT ASSOC, V91, P242, DOI 10.2307/2291401; Coffin M, 1995, LIFETIME DATA MODELS, P71; Coffin M, 1997, BIOMETRICS, V53, P823, DOI 10.2307/2533545; COOK JR, 1994, J AM STAT ASSOC, V89, P1314, DOI 10.2307/2290994; Faraggi D, 2000, STAT MED, V19, P61, DOI 10.1002/(SICI)1097-0258(20000115)19:1<61::AID-SIM297>3.3.CO;2-1; RANDLES RH, 1979, INTRO THEORY NONPARM; SEN P. K., 1960, CALCUTTA STAT ASSOC, V10, P1	9	8	8	MARCEL DEKKER INC	NEW YORK	270 MADISON AVE, NEW YORK, NY 10016 USA	0361-0926			COMMUN STAT-THEOR M	Commun. Stat.-Theory Methods		2000	29	11					2473	2491		10.1080/03610920008832617		19	Statistics & Probability	Mathematics	370TL	WOS:000165138300008	
B	Ridgeway, G; Madigan, D; Richardson, T		Heckerman, D; Whittaker, J		Ridgeway, G; Madigan, D; Richardson, T			Boosting methodology for regression problems	ARTIFICIAL INTELLIGENCE AND STATISTICS 99, PROCEEDINGS			English	Proceedings Paper	7th International Workshop on Artificial Intelligence and Statistics (Uncertainty 99)	JAN 03-06, 1999	FT LAUDERDALE, FL	Soc Artificial Intelligence & Stat				Classification problems have dominated research on boosting to date. The application of boosting to regression problems, on the other hand, has received little investigation. In this paper we develop a new boosting method for regression problems. We cast the regression problem as a classification problem and apply an interpretable form of the boosted naive Bayes classifier. This induces a regression model that we show to be expressible as an additive model for which we derive estimators and discuss computational issues. We compare the performance of our boosted naive Bayes regression model with other interpretable multivariate regression procedures.	Univ Washington, Dept Stat, Seattle, WA 98195 USA	Ridgeway, G (reprint author), Univ Washington, Dept Stat, Box 354322, Seattle, WA 98195 USA.						BAUER E, 1998, MACH LEARN, V20, P1; BREIMAN L, 1997, 504 U CALIFORNIA BER; Breiman L, 1998, ANN STAT, V26, P801; Dollard J.D., 1979, PRODUCT INTEGRATION; Drucker H., 1997, P 14 INT C MACH LEAR, P107; DUAN N, 1991, ANN STAT, V19, P505, DOI 10.1214/aos/1176348109; ELKAN C, 1997, CS97557; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 1998, ADDITIVE LOGISTIC RE; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; FRIEDMAN JH, 1983, SIAM J SCI STAT COMP, V4, P291, DOI 10.1137/0904023; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Good I, 1965, ESTIMATION PROBABILI; Hastie TJ, 1990, GEN ADDITIVE MODELS; LOADER C, 1997, STAT COMPUTING GRAPH; PENROSE KW, 1985, MED SCI SPORT EXER, V17, P189, DOI 10.1249/00005768-198504000-00037; RIDGEWAY G, 1998, P 4 INT C KNOWL DISC; SPIEGELHALTER DJ, 1984, J ROY STAT SOC A STA, V147, P35, DOI 10.2307/2981737; ZHENG Z, 1998, C9817 TR DEAK U SCH	20	8	8	MORGAN KAUFMANN PUB INC	SAN FRANCISCO	340 PINE STR, 6TH FLR, SAN FRANCISCO, CA 94104-3205 USA			1-55860-589-4				1999							152	161				10	Computer Science, Artificial Intelligence; Statistics & Probability	Computer Science; Mathematics	BQ79Z	WOS:000089547000017	
J	Penny, WD; Frost, DP				Penny, WD; Frost, DP			Neural network modeling of the level of observation decision in an acute psychiatric ward	COMPUTERS AND BIOMEDICAL RESEARCH			English	Article								Patients in an acute psychiatric ward need to be observed with varying levels of closeness. We report a series of experiments in which neural networks were trained to model this ''level of observation'' decision. One hundred eighty-seven such clinical decisions were used to train and test the networks which were evaluated by a multitrial upsilon-fold cross-validation procedure. One neural network modeling approach was to break down the decision process into four subproblems, each of which was solved by a perceptron unit. This resulted in a hierarchical perceptron network having a structure that was equivalent to a sparsely connected two-layer perceptron. Neural network approaches were compared with nearest neighbor, linear regression, and naive Bayes classifiers. The hierarchical and sparse neural networks were the most accurate classifiers. This shows that the decision process is nonlinear, that neural nets can be more accurate than other statistical approaches, and that hierarchical decomposition is a useful methodology for neural network design. (C) 1997 Academic Press.	UCL, SCH MED, DEPT PSYCHIAT, LONDON W1N 8AA, ENGLAND	Penny, WD (reprint author), UNIV LONDON IMPERIAL COLL SCI TECHNOL & MED, DEPT ELECT ENGN, EXHIBIT RD, LONDON SW7 2BT, ENGLAND.						DAVIS GE, 1993, M D COMPUT, V10, P87; Duda R., 1973, PATTERN CLASSIFICATI; FAHLMANN SE, 1989, P 1988 CONNECTIONIST; FINOFF W, 1993, NEURAL NETWORKS, V6, P771; FLEISS J L, 1986, Journal of Psychiatric Research, V20, P195, DOI 10.1016/0022-3956(86)90003-8; FLETCHER JM, 1978, CORTEX, V14, P564; FROST D, 1994, COMMENT COMMUNITY IN; GOODMAN PH, 1995, NEVPROP NEURAL NETWO; Haykin S., 1994, NEURAL NETWORKS COMP; KLEINBAUM DG, 1988, APPLIED REGRESSION A; Lowe D, 1990, NETWORK-COMP NEURAL, V1, P299, DOI 10.1088/0954-898X/1/3/002; MAVROVOUNIOTIS ML, 1992, COMPUT CHEM ENG, V16, P347, DOI 10.1016/0098-1354(92)80053-C; MEHDI B, 1994, ANAL CELL PATHOL, V7, P171; Michie D., 1994, MACHINE LEARNING NEU; MODAI I, 1993, METHOD INFORM MED, V32, P396; MULSANT BH, 1988, P ANN S COMP APPL ME, P245; PENNY WD, 1996, IN PRESS MED DECISIO; PENNY WD, 1996, NEURAL NETWORKS THEI; Press W. H., 1992, NUMERICAL RECIPES C; *QUAL DEV UN, 1993, FACE PROJ FIN REP DE; Rumelhart D., 1986, PARALLEL DISTRIBUTED; SETHI IK, 1995, IEEE T SYST MAN CYB, V25, P1243, DOI 10.1109/21.398685; SETHI IK, 1990, P IEEE, V78, P1605, DOI 10.1109/5.58346; SHROUT PE, 1987, ARCH GEN PSYCHIAT, V44, P172; Siegel S, 1989, NONPARAMETRIC STAT B; SOMOZA E, 1993, MED DECIS MAKING, V13, P273, DOI 10.1177/0272989X9301300402; Spackman K A, 1992, Proc Annu Symp Comput Appl Med Care, P456; STONE M, 1974, J R STAT SOC B, V36, P111	28	8	8	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0010-4809			COMPUT BIOMED RES	Comput. Biomed. Res.	FEB	1997	30	1					1	17		10.1006/cbmr.1997.1432		17	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	XF644	WOS:A1997XF64400001	
J	Speier, W; Arnold, C; Lu, J; Taira, RK; Pouratian, N				Speier, William; Arnold, Corey; Lu, Jessica; Taira, Ricky K.; Pouratian, Nader			Natural language processing with dynamic classification improves P300 speller accuracy and bit rate	JOURNAL OF NEURAL ENGINEERING			English	Article							BRAIN-COMPUTER INTERFACE; BCI COMPETITION 2003; DATA SET IIB; COMMUNICATION	The P300 speller is an example of a brain-computer interface that can restore functionality to victims of neuromuscular disorders. Although the most common application of this system has been communicating language, the properties and constraints of the linguistic domain have not to date been exploited when decoding brain signals that pertain to language. We hypothesized that combining the standard stepwise linear discriminant analysis with a Naive Bayes classifier and a trigram language model would increase the speed and accuracy of typing with the P300 speller. With integration of natural language processing, we observed significant improvements in accuracy and 40-60% increases in bit rate for all six subjects in a pilot study. This study suggests that integrating information about the linguistic domain can significantly improve signal classification.	[Speier, William; Lu, Jessica; Pouratian, Nader] Univ Calif Los Angeles, Biomed Engn Interdept Program, Los Angeles, CA 90024 USA; [Speier, William; Arnold, Corey; Taira, Ricky K.] Univ Calif Los Angeles, Med Imaging Informat Grp, Los Angeles, CA USA; [Pouratian, Nader] Univ Calif Los Angeles, Dept Neurosurg, Los Angeles, CA USA; [Pouratian, Nader] Univ Calif Los Angeles, Neurosci Interdept Program, Los Angeles, CA USA	Speier, W (reprint author), Univ Calif Los Angeles, Biomed Engn Interdept Program, Los Angeles, CA 90024 USA.	Speier@mii.ucla.edu			National Library of Medicine [T15-LM007356]; UCLA	This work was supported by the National Library of Medicine Training Grant T15-LM007356. NP was supported by the UCLA Scholars in Translational Medicine Program.	Citi L, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/5/056006; Draper N.R., 1981, APPL REGRESSION ANAL; Duda R.O., 2001, PATTERN CLASSIFICATI; FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6; Francis W., 1979, BROWN CORPUS MANUAL; Jelinek Frederick, 1998, STAT METHODS SPEECH; Jin J, 2010, BIOMED TECH, V55, P203, DOI 10.1515/BMT.2010.029; Kaper M, 2004, IEEE T BIO-MED ENG, V51, P1073, DOI 10.1109/TBME.2004.826698; Krusienski DJ, 2006, J NEURAL ENG, V3, P299, DOI 10.1088/1741-2560/3/4/007; Lauer RT, 2000, IEEE T REHABIL ENG, V8, P205, DOI 10.1109/86.847817; Manning C.D., 1999, FDN STAT NATURAL LAN; MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095; McFarland DJ, 2011, CLIN NEUROPHYSIOL, V122, P731, DOI 10.1016/j.clinph.2010.10.029; Pfurtscheller G, 2000, NEUROSCI LETT, V292, P211, DOI 10.1016/S0304-3940(00)01471-3; PIERCE JOHN R., 1980, INTRO INFORM THEORY, P8; Ryan DB, 2011, INT J HUM-COMPUT INT, V27, P69, DOI 10.1080/10447318.2011.535754; Sellers EW, 2006, BIOL PSYCHOL, V73, P242, DOI 10.1016/j.biopsycho.2006.04.007; Serby H, 2005, IEEE T NEUR SYS REH, V13, P89, DOI 10.1109/TNSRE.2004.841878; Townsend G, 2010, CLIN NEUROPHYSIOL, V121, P1109, DOI 10.1016/j.clinph.2010.01.030; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3; WOLPAW JR, 1991, ELECTROEN CLIN NEURO, V78, P252, DOI 10.1016/0013-4694(91)90040-B; Xu N, 2004, IEEE T BIO-MED ENG, V51, P1067, DOI 10.1109/TBME.2004.826699	22	7	7	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	1741-2560			J NEURAL ENG	J. Neural Eng.	FEB	2012	9	1							016004	10.1088/1741-2560/9/1/016004		8	Engineering, Biomedical; Neurosciences	Engineering; Neurosciences & Neurology	897CJ	WOS:000300618700006	
J	Ballabio, C; Sterlacchini, S				Ballabio, Cristiano; Sterlacchini, Simone			Support Vector Machines for Landslide Susceptibility Mapping: The Staffora River Basin Case Study, Italy	MATHEMATICAL GEOSCIENCES			English	Article						Support Vector Machines; Landslide susceptibility mapping; Spatial prediction; Cross-validation	SPATIAL PREDICTION; SOIL PROPERTIES; GENE SELECTION; MODELS; HAZARD; CLASSIFICATION; INFORMATION; TOPOGRAPHY; REGRESSION; GIS	The aim of this study is the application of support vector machines (SVM) to landslide susceptibility mapping. SVM are a set of machine learning methods in which model capacity matches data complexity. The research is based on a conceptual framework targeted to apply and test all the procedural steps for landslide susceptibility modeling from model selection, to investigation of predictive variables, from empirical cross-validation of results, to analysis of predicted patterns. SVM were successfully applied and the final susceptibility map was interpreted via success and prediction rate curves and receiver operating characteristic (ROC) curves, to support the modeling results and assess the robustness of the model. SVM appeared to be very specific learners, able to discriminate between the informative input and random noise. About 78% of occurrences was identified within the 20% of the most susceptible study area for the cross-validation set. Then the final susceptibility map was compared with other maps, addressed by different statistical approaches, commonly used in susceptibility mapping, such as logistic regression, linear discriminant analysis, and naive Bayes classifier. The SVM procedure was found feasible and able to outperform other techniques in terms of accuracy and generalization capacity. The over-performance of SVM against the other techniques was around 18% for the cross-validation set, considering the 20% of the most susceptible area. Moreover, by analyzing receiver operating characteristic (ROC) curves, SVM appeared to be less prone to false positives than the other models. The study was applied in the Staffora river basin (Lombardy, Northern Italy), an area of about 275 km(2) characterized by a very high density of landslides, mainly superficial slope failures triggered by intense rainfall events.	[Ballabio, Cristiano] Univ Milano Bicocca, Environm & Land Sci Dept, I-20126 Milan, Italy; [Sterlacchini, Simone] Natl Res Council CNR IDPA, Inst Dynam Environm Proc, I-20126 Milan, Italy	Ballabio, C (reprint author), Univ Milano Bicocca, Environm & Land Sci Dept, I-20126 Milan, Italy.	cristiano.ballabio@unimib.it	Ballabio, Cristiano/A-6142-2014	Ballabio, Cristiano/0000-0001-7452-9271			Aizerman M., 1964, AUTOMAT REM CONTR, V25, P821; Aleotti P, 1999, B ENG ENV, V58, P21, DOI DOI 10.1007/S100640050066; Ayalew L, 2005, GEOMORPHOLOGY, V65, P15, DOI 10.1016/j.geomorph.2004.06.010; Ballabio C, 2009, GEODERMA, V151, P338, DOI 10.1016/j.geoderma.2009.04.022; Beatrizzotti G, 1969, GEOLOGICAL MAP ITALY; Bellman R.E., 1961, ADAPTIVE CONTROL PRO; Bonham-Carter G.F., 1994, GEOGRAPHIC INFORM SY; Boulesteix AL, 2007, BIOINFORMATICS, V23, P1702, DOI 10.1093/bioinformatics/btm162; Braga G, 1985, GEOLOGIA APPL IDROGE, V20, P621; Brenning A, 2005, NAT HAZARD EARTH SYS, V5, P853; CARG project, 1992, NEW IT 1 50 000 GEOL; Carrara A, 2003, EARTH SURF PROC LAND, V28, P1125, DOI 10.1002/esp.545; Carrara A, 2008, GEOMORPHOLOGY, V94, P353, DOI 10.1016/j.geomorph.2006.10.033; Carrara A, 1995, GEOGRAPHIC INFORM SY, P125; Chen PH, 2005, APPL STOCH MODEL BUS, V21, P111, DOI 10.1002/asmb.537; Cherkassky V, 2007, LEARNING DATA CONCEP, P439; Chung CJ, 2003, PHOTOGRAMM ENG REMOT, V65, P451; Chung CJF, 1999, PHOTOGRAMM ENG REM S, V65, P1389; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cruden D.M., 1996, TRANSPORTATION RES B, V247, P36; DUBAYAH R, 1995, INT J GEOGR INF SYST, V9, P405, DOI 10.1080/02693799508902046; DUSAF project, 2003, DEST US SUOL AGR FOR; Egan J, 1975, SIGNAL DETECTION THE; Evangelista PF, 2006, ADV SOFT COMP, V34, P425, DOI 10.1007/3-540-31662-0_33; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; FOX J, 1992, J AM STAT ASSOC, V87, P178, DOI 10.2307/2290467; Goodacre C, 1993, TECTONOPHYSICS, V217, P285; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Guzzetti F, 1999, GEOMORPHOLOGY, V31, P181, DOI 10.1016/S0169-555X(99)00078-1; Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007; Hastie T, 2001, ELEMENTS STAT LEARNI, P22; Hjerdt K, 2004, WATER RESOUR RES, V40, P6; Hsu C. W., 2007, PRACTICAL GUIDE SUPP; Kanevski M, 2009, MACHINE LEARNING SPA; Kanevsky M, 2000, SPATIAL DATA MAPPING; LeCun Y., 1990, ADV NEURAL INFORM PR, V2; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Marquardt D. W., 1970, TECHNOMETRICS, V12, P605; McKenzie NJ, 1999, GEODERMA, V89, P67, DOI 10.1016/S0016-7061(98)00137-2; Meisina C, 2006, ENG GEOL, V86, P240; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Nilsson NJ, 1965, FDN TRAINABLE PATTER; O'Brien RM, 2007, QUAL QUANT, V41, P673, DOI 10.1007/s11135-006-9018-6; Oommen T, 2011, MATH GEOSCI, V43, P99, DOI 10.1007/s11004-010-9311-8; Platt J.C., 1999, ADV LARGE MARGIN CLA; Poli S., 2007, NAT RESOUR RES, V16, P121, DOI DOI 10.1007/S11053-007-9043-8; Pozdnoukhov A, 2011, NAT HAZARD EARTH SYS, V11, P367, DOI 10.5194/nhess-11-367-2011; Samui P, 2010, MATH GEOSCI, V42, P433, DOI 10.1007/s11004-010-9268-7; Scholkopf B, 2001, P ADV NEUR INF PROC, P301; Smirnoff A, 2008, COMPUT GEOSCI-UK, V34, P127, DOI 10.1016/j.cageo.2006.12.008; Sterlacchini S, 2004, LANDSLIDES EVALUATIO, P109; Van Den Eeckhaut M., 2006, GEOMORPHOLOGY, V76, P392; Van Westen CJ, 2003, NAT HAZARDS, V30, P399, DOI 10.1023/B:NHAZ.0000007097.42735.9e; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V., 1995, NATURE STAT LEARNING; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Yokoyama R, 2002, PHOTOGRAMM ENG REM S, V68, P257; ZEVENBERGEN LW, 1987, EARTH SURF PROCESSES, V12, P47, DOI 10.1002/esp.3290120107; Zhou X, 2007, BIOINFORMATICS, V23, P1106, DOI 10.1093/bioinformatics/btm036	61	7	7	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1874-8961			MATH GEOSCI	Math Geosci.	JAN	2012	44	1					47	70		10.1007/s11004-011-9379-9		24	Geosciences, Multidisciplinary; Mathematics, Interdisciplinary Applications	Geology; Mathematics	876RA	WOS:000299124100003	
J	Bui, DT; Pradhan, B; Lofman, O; Revhaug, I				Dieu Tien Bui; Pradhan, Biswajeet; Lofman, Owe; Revhaug, Inge			Landslide Susceptibility Assessment in Vietnam Using Support Vector Machines, Decision Tree, and Naive Bayes Models	MATHEMATICAL PROBLEMS IN ENGINEERING			English	Article							ARTIFICIAL NEURAL-NETWORKS; SPATIAL PREDICTION MODELS; HOA BINH PROVINCE; LOGISTIC-REGRESSION; FUZZY-LOGIC; CONDITIONAL-PROBABILITY; SAMPLING STRATEGIES; FEATURE-SELECTION; HAZARD ASSESSMENT; CLASSIFIER	The objective of this study is to investigate and compare the results of three data mining approaches, the support vector machines (SVM), decision tree (DT), and Naive Bayes (NB) models for spatial prediction of landslide hazards in the Hoa Binh province (Vietnam). First, a landslide inventory map showing the locations of 118 landslides was constructed from various sources. The landslide inventory was then randomly partitioned into 70% for training the models and 30% for the model validation. Second, ten landslide conditioning factors were selected (i.e., slope angle, slope aspect, relief amplitude, lithology, soil type, land use, distance to roads, distance to rivers, distance to faults, and rainfall). Using these factors, landslide susceptibility indexes were calculated using SVM, DT, and NB models. Finally, landslide locations that were not used in the training phase were used to validate and compare the landslide susceptibility maps. The validation results show that the models derived using SVM have the highest prediction capability. The model derived using DT has the lowest prediction capability. Compared to the logistic regression model, the prediction capability of the SVM models is slightly better. The prediction capability of the DT and NB models is lower.	[Dieu Tien Bui; Lofman, Owe; Revhaug, Inge] Norwegian Univ Life Sci, Dept Math Sci & Technol, N-1432 As, Norway; [Dieu Tien Bui] Hanoi Univ Min & Geol, Fac Surveying & Mapping, Hanoi, Vietnam; [Pradhan, Biswajeet] Univ Putra Malaysia, Dept Civil Engn, Spatial & Numer Modelling Res Grp, Fac Engn, Serdang 43400, Malaysia	Bui, DT (reprint author), Norwegian Univ Life Sci, Dept Math Sci & Technol, POB 5003IMT, N-1432 As, Norway.	buitiendieu@gmail.com	Tien Bui, Dieu/K-2125-2012; Pradhan, Biswajeet/E-8226-2010	Pradhan, Biswajeet/0000-0001-9863-2054	Norwegian Quota scholarship program	This research was funded by the Norwegian Quota scholarship program. The data analysis and write-up were carried out as a part of the first author's Ph.D. studies at the Geomatics Section, Department of Mathematical Sciences and Technology, Norwegian University of Life Sciences, Norway.	Abe S, 2010, ADV PATTERN RECOGNIT, P1, DOI 10.1007/978-1-84996-098-4; Akgun A., 2011, COMPUT GEOSCI, V38, P23; Ali S, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P243, DOI 10.1109/IRI.2003.1251420; Arikan F, 2007, B ENG GEOL ENVIRON, V66, P415, DOI 10.1007/s10064-007-0087-0; Bai S. B., 2008, GEOPH RES ABSTR EGU, V10; Ballabio C, 2012, MATH GEOSCI, V44, P47, DOI 10.1007/s11004-011-9379-9; Breiman L., 1984, CLASSIFICATION REGRE; Brenning A, 2005, NAT HAZARD EARTH SYS, V5, P853; Bui D. Tien, COMPUTERS G IN PRESS; Bui DT, 2011, NAT HAZARDS, V59, P1413, DOI 10.1007/s11069-011-9844-2; Bui DT, 2012, CATENA, V96, P28, DOI 10.1016/j.catena.2012.04.001; Can T, 2005, GEOMORPHOLOGY, V72, P250, DOI 10.1016/j.geomorph.2005.05.011; Catani F, 2005, LANDSLIDES, V2, P329, DOI 10.1007/s10346-005-0021-0; Chacon J, 2006, B ENG GEOL ENVIRON, V65, P341, DOI 10.1007/s10064-006-0064-z; Chang Chih-Chung, 2011, ACM T INTELLIGENT SY; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Cherkassky V, 2007, LEARNING DATA CONCEP; Cho JH, 2011, SENSOR ACTUAT B-CHEM, V160, P542, DOI 10.1016/j.snb.2011.08.027; Chung CJF, 2003, NAT HAZARDS, V30, P451, DOI 10.1023/B:NHAZ.0000007172.62651.2b; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Damasevicius R., 2011, TOP, V18, P339; Damasevicius R, 2010, NEUROCOMPUTING, V73, P633, DOI 10.1016/j.neucom.2009.09.018; Debeljak M, 2011, MODELLING COMPLEX ECOLOGICAL DYNAMICS: AN INTRODUCTION INTO ECOLOGICAL MODELLING FOR STUDENTS, TEACHERS & SCIENTISTS, P197, DOI 10.1007/978-3-642-05029-9_14; Ercanoglu M, 2004, ENG GEOL, V75, P229, DOI 10.1016/j.enggeo.2004.06.001; Ercanoglu M, 2002, ENVIRON GEOL, V41, P720, DOI 10.1007/s00254-001-0454-2; Ermini L, 2005, GEOMORPHOLOGY, V66, P327, DOI 10.1016/j.geomorph.2004.09.025; Guzzetti F, 1999, GEOMORPHOLOGY, V31, P181, DOI 10.1016/S0169-555X(99)00078-1; Guzzetti F, 2006, GEOMORPHOLOGY, V81, P166, DOI 10.1016/j.geomorph.2006.04.007; Guzzetti F, 2005, GEOMORPHOLOGY, V72, P272, DOI 10.1016/j.geomorph.2005.06.002; Hoehler FK, 2000, J CLIN EPIDEMIOL, V53, P499, DOI 10.1016/S0895-4356(99)00174-2; Kazmierska J, 2008, RADIOTHER ONCOL, V86, P211, DOI 10.1016/j.radonc.2007.10.019; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Kheir RB, 2010, ENVIRON POLLUT, V158, P520, DOI 10.1016/j.envpol.2009.08.009; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lee S, 2007, ENVIRON GEOL, V52, P615, DOI 10.1007/s00254-006-0491-y; Lee S, 2005, ENVIRON GEOL, V48, P778, DOI 10.1007/s00254-005-0019-x; Lee S, 2003, EARTH SURF PROC LAND, V28, P1361, DOI 10.1002/esp.593; Lee S, 2007, LANDSLIDES, V4, P327, DOI 10.1007/s10346-007-0088-x; Lee S, 2004, ENG GEOL, V71, P289, DOI 10.1016/S0013-7952(03)00142-X; Lee S, 2007, INT J REMOTE SENS, V28, P4763, DOI 10.1080/01431160701264227; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Lin HT, 2003, STUDY SIGMOID KERNEL; Malamud BD, 2004, EARTH SURF PROC LAND, V29, P687, DOI [10.1002/esp.1064, 10.1002/esq.1064]; Marjanovic M, 2011, ENG GEOL, V123, P225, DOI 10.1016/j.enggeo.2011.09.006; Mattera D, 1999, ADVANCES IN KERNEL METHODS, P211; Michael J. A., 1997, DATA MINING TECHNIQU; Micheletti N., 2011, GEOPH RES ABSTR EGU, V13; Miner A. S., 2010, GEOLOGICALLY ACTIVE, P352; Mu TT, 2007, J FRANKLIN I, V344, P285, DOI 10.1016/j.jfranklin.2006.09.005; Murakami Y, 2010, BIOINFORMATICS, V26, P1841, DOI 10.1093/bioinformatics/btq302; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Myles AJ, 2004, J CHEMOMETR, V18, P275, DOI 10.1002/cem.873; Nefeslioglu HA, 2010, MATH PROBL ENG, DOI 10.1155/2010/901095; Nefeslioglu HA, 2008, ENG GEOL, V97, P171, DOI 10.1016/j.enggeo.2008.01.004; Oh HJ, 2011, COMPUT GEOSCI-UK, V37, P1264, DOI 10.1016/j.cageo.2010.10.012; Platt J., 2000, PROBABILISTIC OUTPUT; Poudyal CP, 2010, ENVIRON EARTH SCI, V61, P1049, DOI 10.1007/s12665-009-0426-5; Pradhan B, 2010, IEEE T GEOSCI REMOTE, V48, P4164, DOI 10.1109/TGRS.2010.2050328; Pradhan B, 2010, ADV SPACE RES, V45, P1244, DOI 10.1016/j.asr.2010.01.006; Pradhan B, 2011, ENVIRON EARTH SCI, V63, P329, DOI 10.1007/s12665-010-0705-1; Pradhan B, 2010, ENVIRON MODELL SOFTW, V25, P747, DOI 10.1016/j.envsoft.2009.10.016; Pradhan B, 2010, INT J COMPUT INT SYS, V3, P370; Pradhan B, 2011, ENVIRON ECOL STAT, V18, P471, DOI 10.1007/s10651-010-0147-7; Pradhan B, 2010, LANDSLIDES, V7, P13, DOI 10.1007/s10346-009-0183-2; Pradhan B, 2010, ENVIRON EARTH SCI, V60, P1037, DOI 10.1007/s12665-009-0245-8; Pradhan B, 2010, COMPUT ENVIRON URBAN, V34, P216, DOI 10.1016/j.compenvurbsys.2009.12.004; Pradhan B, 2010, ENVIRON ENG GEOSCI, V16, P107; Pradhan B, 2010, J INDIAN SOC REMOT, V38, P301, DOI 10.1007/s12524-010-0020-z; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ratanamahatana C, 2003, APPL ARTIF INTELL, V17, P475, DOI 10.1080/08839510390219327; Saito H, 2009, GEOMORPHOLOGY, V109, P108, DOI 10.1016/j.geomorph.2009.02.026; Samui P, 2008, ENVIRON GEOL, V56, P255, DOI 10.1007/s00254-007-1161-4; Sarkar S, 2008, J MT SCI-ENGL, V5, P52, DOI 10.1007/s11629-008-0052-9; Sassa K, 2008, LANDSLIDES DISASTER; Song ST, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017191; Soria D, 2011, KNOWL-BASED SYST, V24, P775, DOI 10.1016/j.knosys.2011.02.014; Tran VT, 2009, EXPERT SYST APPL, V36, P1840, DOI 10.1016/j.eswa.2007.12.010; Tso GKF, 2007, ENERGY, V32, P1761, DOI 10.1016/j.energy.2006.11.010; Tzu-Tsung Wong, 2012, Pattern Recognition, V45, DOI 10.1016/j.patcog.2011.12.014; Vahidnia MH, 2010, COMPUT GEOSCI-UK, V36, P1101, DOI 10.1016/j.cageo.2010.04.004; Van T.T., 2006, INVESTIGATION ASSESS; Vapnik V., 1998, STAT LEARNING THEORY; Vergari F, 2011, NAT HAZARD EARTH SYS, V11, P1475, DOI 10.5194/nhess-11-1475-2011; Wan SA, 2009, KNOWL-BASED SYST, V22, P580, DOI 10.1016/j.knosys.2009.07.008; Wang CM, 2009, EXPERT SYST APPL, V36, P5900, DOI 10.1016/j.eswa.2008.07.026; Wang HB, 2005, PROG PHYS GEOG, V29, P548, DOI [10.1191/0309133305pp462ra, 10.1191/0309133305pp463ra]; Witten IH, 2005, DATA MINING PRACTICA; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Xie Z., 2005, P 10 INT C DAT SYST, V3453, P983; Yao X, 2008, GEOMORPHOLOGY, V101, P572, DOI 10.1016/j.geomorph.2008.02.011; Yeon YK, 2010, ENG GEOL, V116, P274, DOI 10.1016/j.enggeo.2010.09.009; Yesilnacar E, 2005, ENG GEOL, V79, P251, DOI 10.1016/j.enggeo.2005.02.002; Yilmaz I, 2009, B ENG GEOL ENVIRON, V68, P297, DOI 10.1007/s10064-009-0185-2; Yilmaz I, 2010, ENVIRON EARTH SCI, V61, P821, DOI 10.1007/s12665-009-0394-9; Yilmaz I, 2010, ENVIRON EARTH SCI, V60, P505, DOI 10.1007/s12665-009-0191-5; Yilmaz I, 2009, COMPUT GEOSCI-UK, V35, P1125, DOI 10.1016/j.cageo.2008.08.007; Zhao YH, 2008, ADV SPACE RES, V41, P1955, DOI 10.1016/j.asr.2007.07.020; Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99; Zhuang L, 2006, LECT NOTES ARTIF INT, V4099, P434	102	7	7	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1024-123X			MATH PROBL ENG	Math. Probl. Eng.		2012									974638	10.1155/2012/974638		26	Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications	Engineering; Mathematics	991BK	WOS:000307675600001	
J	Liu, QZ; Sung, AH; Chen, ZX; Liu, JZ; Chen, L; Qiao, MY; Wang, ZH; Huang, XD; Deng, YP				Liu, Qingzhong; Sung, Andrew H.; Chen, Zhongxue; Liu, Jianzhong; Chen, Lei; Qiao, Mengyu; Wang, Zhaohui; Huang, Xudong; Deng, Youping			Gene selection and classification for cancer microarray data based on machine learning and similarity measures	BMC GENOMICS			English	Article							EXPRESSION DATA; CLASS PREDICTION; ALGORITHMS; REGRESSION; ARRAYS; TUMOR; MODEL; LASSO	Background: Microarray data have a high dimension of variables and a small sample size. In microarray data analyses, two important issues are how to choose genes, which provide reliable and good prediction for disease status, and how to determine the final gene set that is best for classification. Associations among genetic markers mean one can exploit information redundancy to potentially reduce classification cost in terms of time and money. Results: To deal with redundant information and improve classification, we propose a gene selection method, Recursive Feature Addition, which combines supervised learning and statistical similarity measures. To determine the final optimal gene set for prediction and classification, we propose an algorithm, Lagging Prediction Peephole Optimization. By using six benchmark microarray gene expression data sets, we compared Recursive Feature Addition with recently developed gene selection methods: Support Vector Machine Recursive Feature Elimination, Leave-One-Out Calculation Sequential Forward Selection and several others. Conclusions: On average, with the use of popular learning machines including Nearest Mean Scaled Classifier, Support Vector Machine, Naive Bayes Classifier and Random Forest, Recursive Feature Addition outperformed other methods. Our studies also showed that Lagging Prediction Peephole Optimization is superior to random strategy; Recursive Feature Addition with Lagging Prediction Peephole Optimization obtained better testing accuracies than the gene selection method varSelRF.	[Sung, Andrew H.] New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA; [Sung, Andrew H.] New Mexico Inst Min & Technol, Inst Complex Addit Syst Anal, Socorro, NM 87801 USA; [Wang, Zhaohui; Deng, Youping] Wuhan Univ Sci & Technol, Wuhan 430081, Hubei, Peoples R China; [Liu, Qingzhong; Chen, Lei] Sam Houston State Univ, Dept Comp Sci, Huntsville, TX 77341 USA; [Chen, Zhongxue] Univ Texas Hlth Sci Ctr Houston, Ctr Clin & Translat Sci, Biostat Epidemiol Res Design Core, Houston, TX 77030 USA; [Liu, Jianzhong] Chem21 Grp Inc, Lake Forest, IL 60045 USA; [Qiao, Mengyu] S Dakota Sch Mines & Technol, Dept Math & Comp Sci, Rapid City, SD 57701 USA; [Huang, Xudong] Brigham & Womens Hosp, Dept Radiol, Div Nucl Med & Mol Imaging, Conjugate & Med Chem Lab, Boston, MA 02115 USA; [Deng, Youping] Rush Univ, Ctr Canc, Chicago, IL 60612 USA; [Deng, Youping] Rush Univ, Med Ctr, Dept Internal Med, Chicago, IL 60612 USA	Sung, AH (reprint author), New Mexico Inst Min & Technol, Dept Comp Sci, Socorro, NM 87801 USA.	sung@cs.nmt.edu; Youping_Deng@rush.edu	Chen, Zhongxue/K-1372-2013	Chen, Zhongxue/0000-0003-2537-7843	Institute for Complex Additive Systems Analysis, a division of New Mexico Tech; Sam Houston State University	The authors are grateful to Matteo Masotti, E Ke Tang, and Xin Zhou for offering their codes of RfeRank, GLGS, LOOCSFS, SFS-LSbound, and SFFS-LSbound, to Ramon Diaz-Uriarte for the help with the use of varSelRF R package. Partial support for this study from the Institute for Complex Additive Systems Analysis, a division of New Mexico Tech, and from Sam Houston State University, is greatly acknowledged.	Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Bo T, 2002, GENOME BIOL, V3; Brazma A, 2006, NAT REV GENET, V7, P593, DOI 10.1038/nrg1922; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen ZX, 2007, BIOINFORMATICS, V23, P321, DOI 10.1093/bioinformatics/btl609; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hand DJ, 2005, J BIOMED BIOTECHNOL, P215, DOI 10.1155/JBB.2005.215; Heijden F., 2004, CLASSIFICATION PARAM; Inza I, 2002, J INTELL FUZZY SYST, V12, P25; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Liaw A, R NEWS, V2, P18; Liu QZ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0008250; Liu QZ, 2010, INFORM SCIENCES, V180, P1643, DOI 10.1016/j.ins.2010.01.001; Liu QZ, 2008, PATTERN RECOGN, V41, P56, DOI 10.1016/j.patcog.2007.06.005; Long A, J BIOL CHEM, V276, P19937; Monari G, 2000, NEUROCOMPUTING, V35, P195, DOI 10.1016/S0925-2312(00)00325-8; Newton MA, 2001, J COMPUT BIOL, V8, P37, DOI 10.1089/106652701300099074; Pavlidis P, 2001, GENOME BIOL, V2, DOI 10.1186/gb-2001-2-10-research0042; Pochet N, 2004, BIOINFORMATICS, V20, P3185, DOI 10.1093/bioinformatics/bth383; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Qin ZS, 2006, BIOINFORMATICS, V22, P1988, DOI 10.1093/bioinformatics/btl284; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Rivals I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753724; Segal E, 2005, NAT GENET, V37, pS38, DOI 10.1038/ng1561; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Singh D, 2002, CANCER CELL, V1, P227; Tan P, 2005, INTRO DATA MINING, P76; Tang EK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-95; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Torrente A, 2005, BIOINFORMATICS, V21, P3993, DOI 10.1093/bioinformatics/bti644; Van LJ, 2002, NATURE, V415, P530; Vapnik V., 1998, STAT LEARNING THEORY; Yu JS, 2005, BIOINFORMATICS, V21, pI487, DOI 10.1093/bioinformatics/bti1030; Zhou X, 2005, BIOINFORMATICS, V21, P1559, DOI 10.1093/bioinformatics/bti216	38	7	7	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics	DEC 23	2011	12			5					S1	10.1186/1471-2164-12-S5-S1		12	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	940WB	WOS:000303922700002	
J	Bista, RK; Brentnall, TA; Bronner, MP; Langmead, CJ; Brand, RE; Liu, Y				Bista, Rajan K.; Brentnall, Teresa A.; Bronner, Mary P.; Langmead, Christopher J.; Brand, Randall E.; Liu, Yang			Using Optical Markers of Nondysplastic Rectal Epithelial Cells to Identify Patients with Ulcerative Colitis-associated Neoplasia	INFLAMMATORY BOWEL DISEASES			English	Article						ulcerative colitis; field effect; spectroscopy; optical markers	INFLAMMATORY-BOWEL-DISEASE; COLORECTAL-CANCER; CHROMOSOMAL INSTABILITY; RAS MUTATIONS; RISK-FACTOR; SURVEILLANCE; SPECTROSCOPY; METHYLATION; DYSPLASIA; MUCOSA	Background: Current surveillance guidelines for patients with long-standing ulcerative colitis (UC) recommend repeated colonoscopy with random biopsies, which is time-consuming, discomforting, and expensive. A less invasive strategy is to identify neoplasia by analyzing biomarkers from the more accessible rectum to predict the need for a full colonoscopy. The goal of this pilot study was to evaluate whether optical markers of rectal mucosa derived from a novel optical technique, partial-wave spectroscopic microscopy (PWS), could identify UC patients with high-grade dysplasia (HGD) or cancer (CA) present anywhere in their colon. Methods: Banked frozen nondysplastic mucosal rectal biopsies were used from 28 UC patients (15 without dysplasia and 13 with concurrent HGD or CA). The specimen slides were made using a touch prep method and underwent PWS analysis. We divided the patients into two groups: 13 as a training set and an independent 15 as a validation set. Results: We identified six optical markers, ranked by measuring the information gain with respect to the outcome of cancer. The most effective markers were selected by maximizing the cross-validated training accuracy of a Naive Bayes classifier. The optimal classifier was applied to the validation data yielding 100% sensitivity and 75% specificity. Conclusions: Our results indicate that the PWS-derived optical markers can accurately predict UC patients with HGD/CA through assessment of rectal epithelial cells. By aiming for high sensitivity, our approach could potentially simplify the surveillance of UC patients and improve overall resource utilization by identifying patients with HGD/CA who should proceed with colonoscopy. (Inflamm Bowel Dis 2011; 17:2427-2435)	[Bista, Rajan K.; Brand, Randall E.; Liu, Yang] Univ Pittsburgh, Dept Med, Div Gastroenterol Hepatol & Nutr, Pittsburgh, PA 15232 USA; [Brentnall, Teresa A.] Univ Washington, Dept Med, Seattle, WA USA; [Bronner, Mary P.] Cleveland Clin, Dept Anat Med, Cleveland, OH 44106 USA; [Langmead, Christopher J.] Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA; [Langmead, Christopher J.] Carnegie Mellon Univ, Lane Ctr Computat Biol, Pittsburgh, PA 15213 USA; [Liu, Yang] Univ Pittsburgh, Dept Bioengn, Pittsburgh, PA USA	Liu, Y (reprint author), Univ Pittsburgh, Dept Med, Div Gastroenterol Hepatol & Nutr, 5117 Ctr Ave,HCCLB 2-32, Pittsburgh, PA 15232 USA.	liuy@pitt.edu			National Institute of Health/National Cancer Institute [R21CA138370, R21CA152935]; University of Pittsburgh Medical Center	Supported by National Institute of Health/National Cancer Institute (R21CA138370, R21CA152935) and University of Pittsburgh Medical Center	Andersen SN, 1999, GUT, V45, P686; Askling J, 2001, GASTROENTEROLOGY, V120, P1356, DOI 10.1053/gast.2001.24052; Boustany NN, 2010, ANNU REV BIOMED ENG, V12, P285, DOI 10.1146/annurev-bioeng-061008-124811; Brentnall TA, 2009, PROTEOM CLIN APPL, V3, P1326, DOI 10.1002/prca.200900061; Brentnall TA, 1996, CANCER RES, V56, P1237; Bronner MP, 2008, AM J PATHOL, V173, P1853, DOI 10.2353/ajpath.2008.080250; Chen R, 2003, AM J PATHOL, V162, P665, DOI 10.1016/S0002-9440(10)63860-6; Eaden JA, 2001, GUT, V48, P526, DOI 10.1136/gut.48.4.526; EKBOM A, 1990, NEW ENGL J MED, V323, P1228, DOI 10.1056/NEJM199011013231802; EKBOM A, 1992, GASTROENTEROLOGY, V103, P954; Fujii S, 2008, DIGESTION, V77, P2, DOI 10.1159/000111482; Hanauer SB, 2006, INFLAMM BOWEL DIS, V12, pS3, DOI 10.1097/01.MIB.0000195385.19268.68; Holzmann K, 2001, SCAND J GASTROENTERO, V36, P1320; Hsieh CJ, 1998, CANCER RES, V58, P3942; Issa JPJ, 2001, CANCER RES, V61, P3573; Kim MS, 2010, CANCER METAST REV, V29, P181, DOI 10.1007/s10555-010-9207-6; Lashner BA, 1999, AM J GASTROENTEROL, V94, P456; Liu Y, 2005, OPT LETT, V30, P2445, DOI 10.1364/OL.30.002445; O'Sullivan JN, 2002, NAT GENET, V32, P280, DOI 10.1038/ng989; Rabinovitch PS, 1999, CANCER RES, V59, P5148; RIDDELL RH, 1983, HUM PATHOL, V14, P931, DOI 10.1016/S0046-8177(83)80175-0; Roy HK, 2005, CANCER EPIDEM BIOMAR, V14, P1639, DOI 10.1158/1055-9965.EPI-04-0837; Rutter M, 2004, GASTROENTEROLOGY, V126, P451, DOI 10.1053/j.gastro.2003.11.010; Salk JJ, 2009, P NATL ACAD SCI USA, V106, P20871, DOI 10.1073/pnas.0909428106; Sato F, 2002, CANCER RES, V62, P1148; Shen LL, 2005, J NATL CANCER I, V97, P1330, DOI 10.1093/jnci/dji275; Subramanian H, 2009, CANCER RES, V69, P5357, DOI 10.1158/0008-5472.CAN-08-3895; Subramanian H, 2008, P NATL ACAD SCI USA, V105, P20124; Subramanian H, 2009, OPT LETT, V34, P518, DOI 10.1364/OL.34.000518; Watanabe T, 2007, CLIN CANCER RES, V13, P415, DOI 10.1158/1078-0432.CCR-06-0753	30	7	7	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1078-0998			INFLAMM BOWEL DIS	Inflamm. Bowel Dis.	DEC	2011	17	12					2427	2435		10.1002/ibd.21639		9	Gastroenterology & Hepatology	Gastroenterology & Hepatology	857QP	WOS:000297734000010	
J	Liew, CY; Lim, YC; Yap, CW				Liew, Chin Yee; Lim, Yen Ching; Yap, Chun Wei			Mixed learning algorithms and features ensemble in hepatotoxicity prediction	JOURNAL OF COMPUTER-AIDED MOLECULAR DESIGN			English	Article						Ensemble; Consensus; Meta-learner; Mixed variables; Mixed algorithm; Prediction; Drug-induced liver injuries; Hepatotoxicity; Drug discovery; Support vector machine; k-Nearest neighbor; Naive Bayes; QSTR	QUANTITATIVE STRUCTURE-ACTIVITY; INDUCED LIVER-INJURY; VALIDATED QSAR MODELS; SUPPORT VECTOR MACHINES; DRUG TOXICITY; IDIOSYNCRATIC HEPATOTOXICITY; CHEMICAL TOXICITY; ORGANIC-COMPOUNDS; TEST SETS; TOXICOLOGY	Drug-induced liver injury, although infrequent, is an important safety concern that can lead to fatality in patients and failure in drug developments. In this study, we have used an ensemble of mixed learning algorithms and mixed features for the development of a model to predict hepatic effects. This robust method is based on the premise that no single learning algorithm is optimum for all modelling problems. An ensemble model of 617 base classifiers was built from a diverse set of 1,087 compounds. The ensemble model was validated internally with five-fold cross-validation and 25 rounds of y-randomization. In the external validation of 120 compounds, the ensemble model had achieved an accuracy of 75.0%, sensitivity of 81.9% and specificity of 64.6%. The model was also able to identify 22 of 23 withdrawn drugs or drugs with black box warning against hepatotoxicity. Dronedarone which is associated with severe liver injuries, announced in a recent FDA drug safety communication, was predicted as hepatotoxic by the ensemble model. It was found that the ensemble model was capable of classifying positive compounds ( with hepatic effects) well, but less so on negatives compounds when they were structurally similar. The ensemble model built in this study is made available for public use.	[Liew, Chin Yee; Lim, Yen Ching; Yap, Chun Wei] Natl Univ Singapore, Dept Pharm, Pharmaceut Data Explorat Lab, Singapore 117548, Singapore	Yap, CW (reprint author), Natl Univ Singapore, Dept Pharm, Pharmaceut Data Explorat Lab, Singapore 117548, Singapore.	phayapc@nus.edu.sg	Yap, Chun Wei/B-2587-2010	Yap, Chun Wei/0000-0002-2004-3492	NUS [R-148-000-105-133]	This study was supported by the NUS start-up grant R-148-000-105-133.	Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; [Anonymous], ORANGE BOOK APPROVED; Arodz T, 2006, J CHEM INF MODEL, V46, P416, DOI 10.1021/ci050375+; Asikainen AH, 2004, SAR QSAR ENVIRON RES, V15, P19, DOI 10.1080/1062936032000169642; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Bjornsson E, 2006, CLIN PHARMACOL THER, V79, P521, DOI 10.1016/j.clpt.2006.02.012; Bolton EE, 2008, ANN REPORTS COMPUTAT, P217; Bostrom H, 2007, 10 INT C INF FUS, P1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brent R.P., 2002, ALGORITHMS MINIMIZAT; Budavari S, 1989, MERCK INDEX ENCY CHE; CambridgeSoft Desktop Software-ChemDraw (Windows/Mac), CHEMDRAW WIND MAC; CORINA: Generation of 3D coordinates, CORINA GENERATION 3D; Cruz-Monteagudo M, 2008, J COMPUT CHEM, V29, P533, DOI 10.1002/jcc.20812; Czerminski R, 2001, QUANT STRUCT-ACT REL, V20, P227, DOI 10.1002/1521-3838(200110)20:3<227::AID-QSAR227>3.0.CO;2-Y; Dahlgren MK, 2010, BIOORGAN MED CHEM, V18, P2686, DOI 10.1016/j.bmc.2010.02.022; Dearden JC, 2003, J COMPUT AID MOL DES, V17, P119, DOI 10.1023/A:1025361621494; Dearden JC, 2009, SAR QSAR ENVIRON RES, V20, P241, DOI 10.1080/10629360902949567; Dragos Horvath, 2009, J Chem Inf Model, V49, P1762, DOI 10.1021/ci9000579; Drug Safety and Availability, DRUG SAF AV FDA DRUG; Ebbels TMD, 2007, J PROTEOME RES, V6, P4407, DOI 10.1021/pr0703021; Fan W., 2003, ICDM, P51; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fourches D, 2010, CHEM RES TOXICOL, V23, P171, DOI 10.1021/tx900326k; Garbutt JC, 2010, CURR PHARM DESIGN, V16, P2091; Gini G, 2009, APPL ARTIF INTELL, V23, P261, DOI 10.1080/08839510802700847; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; Golbraikh A, 2003, J COMPUT AID MOL DES, V17, P241, DOI 10.1023/A:1025386326946; Gramatica P, 2007, J MOL GRAPH MODEL, V25, P755, DOI 10.1016/j.jmgm.2006.06.005; Gramatica P, 2004, J CHEM INF COMP SCI, V44, P1794, DOI 10.1021/ci049923u; Greene N, 1999, SAR QSAR ENVIRON RES, V10, P299, DOI 10.1080/10629369908039182; Greene N, 2010, CHEM RES TOXICOL, V23, P1215, DOI 10.1021/tx1000865; Greer ML, 2010, TOXICOLOGY, V268, P125, DOI 10.1016/j.tox.2009.08.007; Guengerich FP, 2007, CHEM RES TOXICOL, V20, P344, DOI 10.1021/tx600260a; Gunawan Basuki K, 2007, Clin Liver Dis, V11, P459, DOI 10.1016/j.cld.2007.06.001; Hong H, 2005, SAR QSAR ENVIRON RES, V16, P339, DOI 10.1080/10659360500203022; Huang RL, 2009, TOXICOL SCI, V112, P385, DOI 10.1093/toxsci/kfp231; Hultin-Rosenberg L, 2006, XENOBIOTICA, V36, P1122, DOI 10.1080/00498250600861801; Jaworska J, 2005, ATLA-ALTERN LAB ANIM, V33, P445; Kaplowitz N, 2003, DRUG INDUCED LIVER D; Katritzky AR, 2006, BIOORGAN MED CHEM, V14, P4888, DOI 10.1016/j.bmc.2006.03.012; Kuncheva LI, 2003, LECT NOTES COMPUT SC, V2652, P1126; Kuz'min VE, 2009, QSAR COMB SCI, V28, P664, DOI 10.1002/qsar.200860117; Lei BL, 2009, ANAL CHIM ACTA, V644, P17, DOI 10.1016/j.aca.2009.04.019; Li AP, 2002, CHEM-BIOL INTERACT, V142, P7, DOI 10.1016/S0009-2797(02)00051-0; Li JZ, 2008, J COMPUT CHEM, V29, P2636, DOI 10.1002/jcc.21002; Liew CY, 2010, J COMPUT AID MOL DES, V24, P131, DOI 10.1007/s10822-010-9321-0; Marchant CA, 2009, CHEM BIODIVERS, V6, P2107, DOI 10.1002/cbdv.200900133; Martinez SM, 2010, TOXICOL APPL PHARM, V249, P208, DOI 10.1016/j.taap.2010.09.012; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Matthews EJ, 2009, REGUL TOXICOL PHARM, V54, P23, DOI 10.1016/j.yrtph.2009.01.009; Meng Q, 2010, EXPERT OPIN DRUG MET, V6, P733, DOI 10.1517/17425251003674356; MetabolExpert, METABOLEXPERT; Micromedex<SUP>&REG;</SUP>Healthcare Series [Internet database], MICR HEALTHC SER INT; Mierswa I, 2006, KDD 06, P935, DOI DOI 10.1145/1150402.1150531; Muster WG, 2008, DRUG DISCOV TODAY, V13, P303, DOI 10.1016/j.drudis.2007.12.007; Nicholls A, 2008, J COMPUT AID MOL DES, V22, P239, DOI 10.1007/s10822-008-9170-2; Norinder U, 2006, MOL DIVERS, V10, P207, DOI 10.1007/s11030-006-9019-3; Oloff S, 2005, J MED CHEM, V48, P7322, DOI 10.1021/jm049116m; PaDEL-Descriptor, PADEL DESCRIPTOR; Pipeline Pilot Student Edition, PIPELINE PILOT STUDE; Reese M, 2011, CHEM-BIOL INTERACT, V192, P60, DOI 10.1016/j.cbi.2010.10.005; Richard AM, 2006, CHEM RES TOXICOL, V19, P1257, DOI 10.1021/tx060116u; Rodgers AD, 2010, CHEM RES TOXICOL, V23, P724, DOI 10.1021/tx900451r; Roy K, 2009, QSAR COMB SCI, V28, P406, DOI 10.1002/qsar.200810130; Rucker C, 2007, J CHEM INF MODEL, V47, P2345, DOI 10.1021/ci700157b; Sazonovas A, 2010, SAR QSAR ENVIRON RES, V21, P127, DOI 10.1080/10629360903568671; Schultz TW, 2003, J MOL STRUC-THEOCHEM, V622, P23, DOI 10.1016/S0166-1280(02)00615-2; Shen M, 2004, J MED CHEM, V47, P2356, DOI 10.1021/jm030584q; Subramanian K, 2008, EXPERT OPIN DRUG SAF, V7, P647, DOI 10.1517/14740330802501211 ; Sushko I, 2010, J CHEM INF MODEL, V50, P2094, DOI 10.1021/ci100253r; Sutherland JJ, 2003, J CHEM INF COMP SCI, V43, P1906, DOI 10.1021/ci034143r; Talete-Dragon, DRAG; Tan P-N, 2005, INTRO DATA MINING; Tropsha A, 2007, CURR PHARM DESIGN, V13, P3494, DOI 10.2174/138161207782794257; Tropsha A, 2010, MOL INFORM, V29, P476, DOI 10.1002/minf.201000061; Trotter MWB, 2001, MEAS CONTROL-UK, V34, P235; Validation of (Q) SAR Models, VALIDATION QSAR MODE; Vapnik V., 1995, NATURE STAT LEARNING; Veith GD, 2004, SAR QSAR ENVIRON RES, V15, P323, DOI 10.1080/10629360412331297380; Votano JR, 2004, MUTAGENESIS, V19, P365, DOI 10.1093/mutage/geh043; Walgren JL, 2005, CRIT REV TOXICOL, V35, P325, DOI 10.1080/10408440590935620; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Xu JHJ, 2008, TOXICOL SCI, V105, P97, DOI 10.1093/toxsci/kfn109; Xu JJ, 2004, CHEM-BIOL INTERACT, V150, P115, DOI 10.1016/j.cbi.2004.09.011; Yap CW, 2011, J COMPUT CHEM, V32, P1466, DOI 10.1002/jcc.21707; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Yen MH, 2006, ALCOHOL, V38, P117, DOI 10.1016/j.alcohol.2006.05.003; Yu L, 2004, P 10 ACM SIGKDD INT, P737, DOI 10.1145/1014052.1014149; Zhang LY, 2008, PHARM RES-DORDR, V25, P1902, DOI 10.1007/s11095-008-9609-0; Zhang SX, 2007, J COMPUT AID MOL DES, V21, P97, DOI 10.1007/s10822-007-9102-6; Zheng WF, 2000, J CHEM INF COMP SCI, V40, P185, DOI 10.1021/ci980033m; Zidek N, 2007, TOXICOL SCI, V99, P289, DOI 10.1093/toxsci/kfm131	93	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-654X			J COMPUT AID MOL DES	J. Comput.-Aided Mol. Des.	SEP	2011	25	9					855	871		10.1007/s10822-011-9468-3		17	Biochemistry & Molecular Biology; Biophysics; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Biophysics; Computer Science	849OD	WOS:000297134000006	
J	Saari, P; Eerola, T; Lartillot, O				Saari, Pasi; Eerola, Tuomas; Lartillot, Olivier			Generalizability and Simplicity as Criteria in Feature Selection: Application to Mood Classification in Music	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Cross-indexing; feature selection; music and emotion; musical features; overfitting; wrapper selection	AUDIO SIGNALS; RECOGNITION; EMOTION	Classification of musical audio signals according to expressed mood or emotion has evident applications to content-based music retrieval in large databases. Wrapper selection is a dimension reduction method that has been proposed for improving classification performance. However, the technique is prone to lead to overfitting of the training data, which decreases the generalizability of the obtained results. We claim that previous attempts to apply wrapper selection in the field of music information retrieval (MIR) have led to disputable conclusions about the used methods due to inadequate analysis frameworks, indicative of overfitting, and biased results. This paper presents a framework based on cross-indexing for obtaining realistic performance estimate of wrapper selection by taking into account the simplicity and generalizability of the classification models. The framework is applied on sets of film soundtrack excerpts that are consensually associated with particular basic emotions, comparing Naive Bayes, k-NN, and SVM classifiers using both forward selection (FS) and backward elimination (BE). K-NN with BE yields the most promising results-56.5% accuracy with only four features. The most useful feature subset for k-NN contains mode majorness and key clarity, combined with dynamical, rhythmical, and structural features.	[Saari, Pasi; Eerola, Tuomas; Lartillot, Olivier] Univ Jyvaskyla, Dept Mus, Finnish Ctr Excellence Interdisciplinary Mus Res, FI-40014 Jyvaskyla, Finland	Saari, P (reprint author), Univ Jyvaskyla, Dept Mus, Finnish Ctr Excellence Interdisciplinary Mus Res, FI-40014 Jyvaskyla, Finland.	pasi.saari@jyu.fi; tuomas.eerola@jyu.fi; olar-tillot@gmail.com	Eerola, Tuomas/I-6190-2013	Eerola, Tuomas/0000-0002-2896-929X	Finnish Centre of Excellence in Interdisciplinary Music Research	The work was supported by the Finnish Centre of Excellence in Interdisciplinary Music Research. This paper has supplementary downloadable material available at http://ieeexplore.ieee.org, provided by the authors. This includes the analyzed feature sets and MATLAB scripts that enable experimenting with the used methods and reproducing some of the reported results and visualizations. This material is 156 KB in size. The associate editor coordinating the review of this manuscript and approving it for publication was Mr. James Johnston.	Aucouturier JJ, 2007, J ACOUST SOC AM, V122, P881, DOI 10.1121/1.2750160; Aucouturier J.J., 2004, J NEGATIVE RESULTS S, V1, P1; Cormen T., 2001, INTRO ALGORITHMS; Dellacherie D, 2008, MUSIC PERCEPT, V25, P285, DOI 10.1525/MP.2008.25.4.285; Dumais Susan, 2000, P 23 ANN INT ACM SIG, P256, DOI 10.1145/345508.345593; EEROLA T, 2009, 7 TRIENN C EUR SOC C; Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821; FIEBRINK R, 2005, P INT C MUS INF RETR, P510; Fiebrink R., 2006, P 7 INT C MUS INF RE, P340; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Gosselin N, 2005, BRAIN, V128, P628, DOI 10.1093/brain/awh420; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 1998, ANN STAT, V26, P451; HU X., 2008, P 9 INT C MUS INF RE, P462; John G., 1994, P 11 INT C MACH LEAR, P121; JOHN GH, 1995, P 11 C UNC ART INT, P338; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kruskal J. B., 1978, MULTIDIMENSIONAL SCA; Lartillot O., 2007, P INT C MUS INF RETR, P127; Li T, 2003, P INT S MUS INF RETR, P239; Lindstrom E., 2001, MUSIC EMOTION THEORY, P223, DOI DOI 10.1525/MP.2004.21.4.561; Loughrey J, 2005, USING EARLY STOPPING; Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344; PLATT JC, 1999, ADV KERNEL METHODS S, V12, P185; REUNANEN J, 2007, P 20 INT JOINT C NEU, P2581; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; Reunanen J., 2004, P 4 INT WORKSH PATT, P176; Reunanen J, 2006, LECT NOTES COMPUT SC, V3940, P198; SILLA C, 2008, P 10 IEEE INT S MULT, P39; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; WIECZORKOWSKA A, 2005, P 15 INT S ISMIS 200, P456; Witten IH, 2005, DATA MINING PRACTICA; Yang Y., 2006, P 14 ANN ACM INT C M, P81, DOI 10.1145/1180639.1180665; Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513; YASLAN Y, 2006, P 18 INT C PATT REC, V2	35	7	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	AUG	2011	19	6					1802	1812		10.1109/TASL.2010.2101596		11	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	805BW	WOS:000293702300029	
J	Collin, A; Archambault, P; Long, B				Collin, Antoine; Archambault, Phillippe; Long, Bernard			Predicting Species Diversity of Benthic Communities within Turbid Nearshore Using Full-Waveform Bathymetric LiDAR and Machine Learners	PLOS ONE			English	Article							NEW-SOUTH-WALES; DISTRIBUTION MODELS; ECOLOGICAL THEORY; HABITAT; FISH; ASSEMBLAGES; PATTERNS; FORESTS; CONSERVATION; VEGETATION	Epi-macrobenthic species richness, abundance and composition are linked with type, assemblage and structural complexity of seabed habitat within coastal ecosystems. However, the evaluation of these habitats is highly hindered by limitations related to both waterborne surveys (slow acquisition, shallow water and low reactivity) and water clarity (turbid for most coastal areas). Substratum type/diversity and bathymetric features were elucidated using a supervised method applied to airborne bathymetric LiDAR waveforms over Saint-Simeon-Bonaventure's nearshore area (Gulf of Saint-Lawrence, Quebec, Canada). High-resolution underwater photographs were taken at three hundred stations across an 8-km(2) study area. Seven models based upon state-of-the-art machine learning techniques such as Naive Bayes, Regression Tree, Classification Tree, C 4.5, Random Forest, Support Vector Machine, and CN2 learners were tested for predicting eight epi-macrobenthic species diversity metrics as a function of the class number. The Random Forest outperformed other models with a three-discretized Simpson index applied to epi-macrobenthic communities, explaining 69% (Classification Accuracy) of its variability by mean bathymetry, time range and skewness derived from the LiDAR waveform. Corroborating marine ecological theory, areas with low Simpson epi-macrobenthic diversity responded to low water depths, high skewness and time range, whereas higher Simpson diversity relied upon deeper bottoms (correlated with stronger hydrodynamics) and low skewness and time range. The degree of species heterogeneity was therefore positively linked with the degree of the structural complexity of the benthic cover. This work underpins that fully exploited bathymetric LiDAR (not only bathymetrically derived by-products), coupled with proficient machine learner, is able to rapidly predict habitat characteristics at a spatial resolution relevant to epi-macrobenthos diversity, ranging from clear to turbid waters. This method might serve both to nurture marine ecological theory and to manage areas with high species heterogeneity where navigation is hazardous and water clarity opaque to passive optical sensors.	[Collin, Antoine; Long, Bernard] Univ Quebec, INRS, ETE, Dept Geosci, Quebec City, PQ, Canada; [Archambault, Phillippe] Univ Quebec, Inst Sci Mer, Rimouski, PQ G5L 3A1, Canada	Collin, A (reprint author), Univ Quebec, INRS, ETE, Dept Geosci, Quebec City, PQ, Canada.	antoinecollin1@gmail.com	Rogers, King/G-5482-2010; Collin, Antoine/L-1169-2013		network of excellence GEOIDE (Canada); Fisheries and Oceans Canada; US Naval Hydrographic Service; Optech Int.	This study was supported by the network of excellence GEOIDE (Canada), Fisheries and Oceans Canada, US Naval Hydrographic Service, and Optech Int. The funders had no role in study design, decision to publish, or preparation of the manuscript. Optech Int. was involved in data collection and analysis.	Adjeroud M, 1997, MAR ECOL PROG SER, V159, P105, DOI 10.3354/meps159105; Anselin L., 2003, GEODA 0 9 USERS GUID; Archambault P, 2001, MAR ECOL PROG SER, V222, P51, DOI 10.3354/meps222051; Austin M, 2007, ECOL MODEL, V200, P1, DOI 10.1016/j.ecolmodel.2006.07.005; Austin MP, 1996, AUST J ECOL, V21, P154, DOI 10.1111/j.1442-9993.1996.tb00596.x; Austin MP, 2002, ECOL MODEL, V157, P101, DOI 10.1016/S0304-3800(02)00205-3; AUSTIN MP, 1989, BIOL CONSERV, V50, P13, DOI 10.1016/0006-3207(89)90003-7; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; Brock JC, 2006, REMOTE SENS ENVIRON, V104, P31, DOI 10.1016/j.rse.2006.04.017; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Collin A., 2011, REMOTE SENS EN UNPUB; Collin A, 2010, REMOTE SENS ENVIRON, V114, P520, DOI 10.1016/j.rse.2009.10.011; Collin A, 2008, IEEE T GEOSCI REMOTE, V46, P2947, DOI 10.1109/TGRS.2008.920020; Demsar J, 2004, LECT NOTES ARTIF INT, V3202, P537; ELITH J, 2009, DO THEY DO THEY WHY; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Galparsoro I, 2009, ECOL MODEL, V220, P556, DOI 10.1016/j.ecolmodel.2008.11.003; Gray J.S., 1974, Oceanography mar Biol, V12, P223; GUENTHER GC, 2000, EARSEL DRESD; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; HARBORNE R, 2006, ECOLOGY, V87, P2871; Hewitt JE, 2005, ECOLOGY, V86, P1619, DOI 10.1890/04-1099; Hsu C.W., 2010, PRACTICAL GUIDE SUPP; IRISH JL, 2000, PIANC B, V103, P43; Kobler A, 2006, ECOL MODEL, V191, P83, DOI 10.1016/j.ecolmodel.2005.08.002; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; Leathwick JR, 1998, ECOGRAPHY, V21, P235, DOI 10.1111/j.1600-0587.1998.tb00561.x; LEVESQUE M, 2010, CAN TECH REP FISH AQ, V2893; Long B., 2006, ETUDE HYDRODYNAMIQUE; LONG BF, 2009, P 2 FUDOTERAM WORKSH; MALANSON GP, 1992, ECOL MODEL, V64, P261, DOI 10.1016/0304-3800(92)90026-B; MAXWELL DL, 2009, J SEA RES, V6, P258; McArthur R., 1967, THEORY ISLAND BIOGEO; MINCHIN PR, 1989, VEGETATIO, V83, P97, DOI 10.1007/BF00031683; Mitchell T.M., 1997, MACHINE LEARNING; Mumby PJ, 2001, OECOLOGIA, V128, P274, DOI 10.1007/s004420100643; Myers N, 2000, NATURE, V403, P853, DOI 10.1038/35002501; Petersen CGJ, 1913, REP DAN BIOL ANN REV, V16, P229; Pittman SJ, 2007, ECOL MODEL, V204, P9, DOI 10.1016/j.ecolmodel.2006.12.017; Pittman SJ, 2009, J COASTAL RES, V25, P27, DOI 10.2112/SI53-004.1; Purkis SJ, 2008, CORAL REEFS, V27, P167, DOI 10.1007/s00338-007-0306-y; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Research Systems, 2005, ENVI US GUID ENVI VE; Ridgeway G., 2006, GEN BOOSTED REGRESSI; Rigby RA, 2001, NEW TRENDS STAT MODE, P249; Rosenzweig M. L., 1995, SPECIES DIVERSITY SP; Rydgren K, 2003, J VEG SCI, V14, P869, DOI 10.1658/1100-9233(2003)014[0869:SRCAEG]2.0.CO;2; SAS Institute, 2009, JMP 8 US GUID; Thorson G., 1957, MEM GEOL SOC AMER, V67, P461; Turner MG, 2001, LANDSCAPE ECOLOGY TH; Ward TJ, 1999, ECOL APPL, V9, P691; Wedding LM, 2008, REMOTE SENS ENVIRON, V112, P4159, DOI 10.1016/j.rse.2008.01.025; Wei CL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0015323; Wood J. D., 1996, THESIS U LEICESTER L	55	7	7	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203			PLOS ONE	PLoS One	JUN 20	2011	6	6							e21265	10.1371/journal.pone.0021265		16	Multidisciplinary Sciences	Science & Technology - Other Topics	782BY	WOS:000291983800036	
J	Jamali, N; Sammut, C				Jamali, Nawid; Sammut, Claude			Majority Voting: Material Classification by Tactile Sensing Using Surface Texture	IEEE TRANSACTIONS ON ROBOTICS			English	Article						Frequency-domain analysis; machine learning; tactile sensing; texture classification	SENSOR; FINGERTIP; SYSTEM	In this paper, we present an application of machine learning to distinguish between different materials based on their surface texture. Such a system can be used for the estimation of surface friction during manipulation tasks; quality assurance in the textile, cosmetics, and harvesting industries; and other applications requiring tactile sensing. Several machine learning algorithms, such as naive Bayes, decision trees, and naive Bayes trees, have been trained to distinguish textures sensed by a biologically inspired artificial finger. The finger has randomly distributed strain gauges and polyvinylidene fluoride (PVDF) films embedded in silicone. Different textures induce different intensities of vibrations in the silicone. Consequently, textures can be distinguished by the presence of different frequencies in the signal. The data from the finger are preprocessed, and the Fourier coefficients of the sensor outputs are used to train classifiers. We show that the classifiers generalize well for unseen datasets with performance exceeding previously reported algorithms. Our classifiers can distinguish between different materials, such as carpet, flooring vinyls, tiles, sponge, wood, and polyvinyl- chloride (PVC) woven mesh with an accuracy of 95% +/- 4% on unseen test data.	[Jamali, Nawid; Sammut, Claude] Univ New S Wales, ARC Ctr Excellence Autonomous Syst, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia	Jamali, N (reprint author), Univ New S Wales, ARC Ctr Excellence Autonomous Syst, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.	nawidj@cse.unsw.edu.au; claude@cse.unsw.edu.au			Australian Research Council Centre of Excellence for Autonomous Systems; ARC/National Health and Medical Research Council	This work was supported by the Australian Research Council Centre of Excellence for Autonomous Systems and the ARC/National Health and Medical Research Council Thinking Systems project.	Anderson K. F., 1998, IEEE Instrumentation & Measurement Magazine, V1, DOI 10.1109/5289.658270; Bicchi A., 1996, Proceedings. 1996 IEEE International Conference on Robotics and Automation (Cat. No.96CH35857), DOI 10.1109/ROBOT.1996.503884; Birznieks I, 2001, J NEUROSCI, V21, P8222; Boissieu F., 2009, P ROB SYST SCI 5, P49; Charniya N. N., 2007, P INT JOINT C NEUR N, P2945; Edwards J., 2008, BIOINSPIR BIOMIM, V3, P035002; Engel J, 2005, SENSOR ACTUAT A-PHYS, V117, P50, DOI 10.1016/j.sna.2004.05.037; Fujimoto I, 2003, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P15, DOI 10.1109/MFI-2003.2003.1232571; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Hellard G., 2002, P AUSTR C ROB AUT AU, P100; Hosoda K., 2004, P EMB ART INT, P2325; Hosoda K, 2006, ROBOT AUTON SYST, V54, P104, DOI 10.1016/j.robot.2005.09.019; Jamali N., 2011, THESIS U NEW S WALES; Jamali N., 2009, AUSTR C ROB AUT SYDN; Jamali N., 2010, P IEEE INT C ROB AUT, P2336; Kerpa O., 2003, P 2003 IEEE RSJ INT, V1, P1; Kim J. K., 2004, P IEEE C CYB INT SYS, P1206; Kim SH, 2005, J MICROMECH MICROENG, V15, P912, DOI 10.1088/0960-1317/15/5/003; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; KOO SY, 2008, P 17 IEEE INT S ROB, P425; Mayol-Cuevas W. W., 1998, P IEEE INT C SYST MA, V5, P4246; Mazid A. M., 2008, P 10 INT C CONTR AUT, P1830; Naya F., 1999, P IEEE C SYST MAN CY, V2, P1030; O'Haver T, 2009, INTRO SIGNAL PROCESS; Ohka M, 2004, ROBOTICA, V22, P213, DOI 10.1017/S0263574703005538; Ohka M, 2005, JSME INT J C-MECH SY, V48, P278, DOI 10.1299/jsmec.48.278; Ohmura Y., 2006, Proceedings. 2006 Conference on International Robotics and Automation (IEEE Cat. No. 06CH37729D), DOI 10.1109/ROBOT.2006.1641896; Papakostas T., 2002, P IEEE SENS, V2, P1620, DOI 10.1109/ICSENS.2002.1037366; Petriu Emil M, 2009, Proceedings of the 2009 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2009), DOI 10.1109/HAVE.2009.5356117; Russell R.A., 1990, ROBOT TACTILE SENSIN; Shen Y., 2002, P 3 WORLD C INT CONT, P85; Stiehl W., 2006, P AAAI FALL S CAR MA; Sukhoy V., 2009, P HUM WORKSH TACT SE, P57; Tada Y., 2005, P IEEE RSJ INT C INT, P3323; Tada Y., 2004, P 8 C INT AUT SYST, P1005; Taddeucci D., 1997, P IEEE INT C ROB AUT, V4, P3100, DOI 10.1109/ROBOT.1997.606759; Takamuku S., 2008, P IEEE RSJ INT C INT, P3977; Takamuku S., 2007, P IEEE 6 INT C DEV L, P1; Tanaka Y, 2007, MICROSYST TECHNOL, V13, P1005, DOI 10.1007/s00542-006-0307-8; Torres-Jara E., 2006, MITCSAILTR2006014; Yahud S., 2009, P 31 ANN INT C IEEE, P2300	41	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1552-3098			IEEE T ROBOT	IEEE Trans. Robot.	JUN	2011	27	3			SI		508	521		10.1109/TRO.2011.2127110		14	Robotics	Robotics	774RU	WOS:000291404600012	
J	Dornaika, F; Lazkano, E; Sierra, B				Dornaika, F.; Lazkano, E.; Sierra, B.			Improving dynamic facial expression recognition with feature subset selection	PATTERN RECOGNITION LETTERS			English	Article						Dynamic facial expression recognition; Feature subset selection; Estimation of Distribution Algorithms; Machine learning approaches; Wrapper technique	IMAGE SEQUENCES; MACHINE; VIDEO; FACE	This paper addresses the dynamic recognition of basic facial expressions in videos using feature subset selection. Feature selection has been already used by some static classifiers where the facial expression is recognized from one single image. Past work on dynamic facial expression recognition has emphasized the issues of feature extraction and classification, however, less attention has been given to the critical issue of feature selection in the dynamic scenario. The main contributions of the paper are as follows. First, we show that dynamic facial expression recognition can be casted into a classical classification problem. Second, we combine a facial dynamics extractor algorithm with a feature selection scheme for generic classifiers. We show that the paradigm of feature subset selection with a wrapper technique can improve the dynamic recognition of facial expressions. We provide evaluations of performance on real video sequences using five standard machine learning approaches: Support Vector Machines, K Nearest Neighbor, Naive Bayes, Bayesian Networks, and Classification Trees. (C) 2010 Elsevier B.V. All rights reserved.	[Dornaika, F.; Lazkano, E.; Sierra, B.] Univ Basque Country, San Sebastian 20018, Spain; [Dornaika, F.] Basque Fdn Sci, IKERBASQUE, Bilbao 48011, Spain	Dornaika, F (reprint author), Univ Basque Country, Manuel Lardizabal 1, San Sebastian 20018, Spain.	fdornaika@hotmail.fr					AHA D, 1994, AAAI 94; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ahlberg J, 2002, THESIS LINKOPING U S; Ambadar Z, 2005, PSYCHOL SCI, V16, P403, DOI 10.1111/j.0956-7976.2005.01548.x; BARTLETT M, 2004, P IEEE INT C SMC HAG, V1, P592; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; BREAZEAL C, 1999, P WORKSH EMOT BAS AG; Cheon YJ, 2009, PATTERN RECOGN, V42, P1340, DOI 10.1016/j.patcog.2008.10.010; Dornaika F, 2007, SIGNAL PROCESS-IMAGE, V22, P769, DOI 10.1016/j.image.2007.06.006; DORNAIKA F, 2005, IEEE INT C IM PROC; Dornaika F, 2006, IEEE T CIRC SYST VID, V16, P1107, DOI 10.1109/TCSVT.2006.881200; EKMAN P, 1992, PHILOS T ROY SOC B, V335, P63, DOI 10.1098/rstb.1992.0008; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; HALL M, 1999, FLAIRS C; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; JOHN G, 1994, P 11 INT C; Kanade T, 2000, INT C AUT FAC GEST R, P46; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011; Liu H., 1998, FEATURE SELECTION KN; Liu HA, 1998, APPL INTELL, V9, P217, DOI 10.1023/A:1008363719778; Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4; Muhlenbein H., 1996, LECT NOTES COMPUTER, V1141, P178; Muller M., 2007, INFORM RETRIEVAL MUS; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Pantic M, 2005, ENCY MULTIMEDIA TECH, VI, P8; Pelikan M., 1999, 99018 ILLIGAL U ILL; Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Shan C., 2006, P BRIT MACH VIS C ED, VI, P297; Sierra B, 2009, DECIS SUPPORT SYST, V48, P180, DOI 10.1016/j.dss.2009.07.010; STONE M, 1974, J R STAT SOC B, V36, P111; SUNG J, 2006, P 18 INT C PATT REC, V1, P275; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Xiang T, 2008, PATTERN RECOGN, V41, P204, DOI 10.1016/j.patcog.2007.04.021; Yang P., 2008, COMPUTER VISION PATT; YEASIN M, 2005, IJCNN; Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699	39	7	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	APR 1	2011	32	5					740	748		10.1016/j.patrec.2010.12.010		9	Computer Science, Artificial Intelligence	Computer Science	734PJ	WOS:000288347400010	
J	El Akadi, A; Amine, A; El Ouardighi, A; Aboutajdine, D				El Akadi, Ali; Amine, Aouatif; El Ouardighi, Abdeljalil; Aboutajdine, Driss			A two-stage gene selection scheme utilizing MRMR filter and GA wrapper	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						Feature selection; Genetic algorithm; MRMR; Support Vector Machine; Naive Bayes classifier; LOOCV	SUPPORT VECTOR MACHINES; EXPRESSION DATA; CANCER CLASSIFICATION; ALGORITHMS; PATTERNS	Gene expression data usually contain a large number of genes, but a small number of samples. Feature selection for gene expression data aims at finding a set of genes that best discriminates biological samples of different types. In this paper, we propose a two-stage selection algorithm for genomic data by combining MRMR (Minimum Redundancy-Maximum Relevance) and GA (Genetic Algorithm). In the first stage, MRMR is used to filter noisy and redundant genes in high-dimensional microarray data. In the second stage, the GA uses the classifier accuracy as a fitness function to select the highly discriminating genes. The proposed method is tested for tumor classification on five open datasets: NCI, Lymphoma, Lung, Leukemia and Colon using Support Vector Machine (SVM) and Na < ve Bayes (NB) classifiers. The comparison of the MRMR-GA with MRMR filter and GA wrapper shows that our method is able to find the smallest gene subset that gives the most classification accuracy in leave-one-out cross-validation (LOOCV).	[El Akadi, Ali] Mohammed V Univ, Fac Sci, LRIT CNRS, LRIT Lab, Rabat, Morocco; [El Ouardighi, Abdeljalil] Univ Hassan I, Fac Econ Sci Settat, LM2CE, Settat, Morocco	El Akadi, A (reprint author), Mohammed V Univ, Fac Sci, LRIT CNRS, LRIT Lab, BP 1014, Rabat, Morocco.	elakadi@yahoo.com			Hassan II Academy of Science and Technology	This work is supported by the Hassan II Academy of Science and Technology. The authors would like to thank the anonymous referees for their very constructive comments and suggestions.	Ahmad A, 2005, PATTERN RECOGN LETT, V26, P43, DOI 10.1016/j.patrec.2004.08.015; Alba E, 2007, IEEE C EVOL COMPUTAT, P284, DOI 10.1109/CEC.2007.4424483; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; BENDOR K, 2000, J COMPUT BIOL, V7, P559; Bishop C.M., 1995, NEURAL NETWORKS PATT; BROWN M, 2000, P NATL ACAD SCI USA, P262; Caruana R., 1994, INT C MACH LEARN, P28; Chilingaryan A, 2002, MATH BIOSCI, V176, P59, DOI 10.1016/S0025-5564(01)00105-5; Christianini N., 2000, INTRO SUPPORT VECTOR; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523; DOAK J, 1992, 9218 CSE U CAL DAV C; Fujarewicz K., 2003, International Journal of Applied Mathematics and Computer Science, V13; FUREY T, 2000, BIOINFORMATICS, V16, P614; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Goldberg D., 1989, GENETIC ALGORITHMS S; Golub T, 1999, SCIENCE, V28, P531; GUERRASALCEDO C, 1998, P 3 ANN GEN PROGR C; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hamming R. W., 1980, CODING INFORM THEORY; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jaeger J, 2003, Pac Symp Biocomput, P53; JIN R, 2008, INT J KNOWL INFORM S, V19, P1; KIANMEHR K, 2009, INT J KNOWL INFORM S; KOHAVI J, 1998, MACH LEARN, P33; KOLLER D, 1996, P 13 INT C MACH LEAR, P87; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Mitchell T.M., 1997, MACHINE LEARNING; MODEL F, 2002, AUTOMATICA, V38, P787; MUKHERJEE S, 2003, CLASSIFYING MICROARR; Nguyen DV, 2002, BIOINFORMATICS, V18, P1216, DOI 10.1093/bioinformatics/18.9.1216; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; PENG H, 2003, P 36 S INT COMP BIOL; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Somol P, 2004, IEEE T PATTERN ANAL, V26, P900, DOI 10.1109/TPAMI.2004.28; SUN Z, 2002, IEEE WORKSH APPL COM, P165; Szabo A, 2002, MATH BIOSCI, V176, P71, DOI 10.1016/S0025-5564(01)00103-1; TORRES J, 2007, APPL GA BAYESIAN FIL; TURNEY P, 1997, EVOLUTIONARY COMPUTA, V4, P271; Vafaie H., 1994, P INT C FUZZ INT CON; Vapnik V., 1998, STAT LEARNING THEORY; Wong TT, 2008, EXPERT SYST APPL, V34, P375, DOI 10.1016/j.eswa.2006.09.005; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Xiong N, 2006, SOFT COMPUT, V10, P796, DOI 10.1007/s00500-005-0009-7; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091	51	7	7	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	MAR	2011	26	3					487	500		10.1007/s10115-010-0288-x		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	720AB	WOS:000287251500006	
J	Zhang, KX; Ouellette, BFF				Zhang, Kelvin Xi; Ouellette, B. F. Francis			CAERUS: Predicting CAncER oUtcomeS Using Relationship between Protein Structural Information, Protein Networks, Gene Expression Data, and Mutation Data	PLOS COMPUTATIONAL BIOLOGY			English	Article							NF-KAPPA-B; BREAST-CANCER; SIGNALING NETWORKS; SOMATIC MUTATION; SH2 DOMAINS; GENOME; KINASE; SIGNATURE; SURVIVAL; METASTASIS	Carcinogenesis is a complex process with multiple genetic and environmental factors contributing to the development of one or more tumors. Understanding the underlying mechanism of this process and identifying related markers to assess the outcome of this process would lead to more directed treatment and thus significantly reduce the mortality rate of cancers. Recently, molecular diagnostics and prognostics based on the identification of patterns within gene expression profiles in the context of protein interaction networks were reported. However, the predictive performances of these approaches were limited. In this study we propose a novel integrated approach, named CAERUS, for the identification of gene signatures to predict cancer outcomes based on the domain interaction network in human proteome. We first developed a model to score each protein by quantifying the domain connections to its interacting partners and the somatic mutations present in the domain. We then defined proteins as gene signatures if their scores were above a preset threshold. Next, for each gene signature, we quantified the correlation of the expression levels between this gene signature and its neighboring proteins. The results of the quantification in each patient were then used to predict cancer outcome by a modified naive Bayes classifier. In this study we achieved a favorable accuracy of 88.3%, sensitivity of 87.2%, and specificity of 88.9% on a set of well-documented gene expression profiles of 253 consecutive breast cancer patients with different outcomes. We also compiled a list of cancer-associated gene signatures and domains, which provided testable hypotheses for further experimental investigation. Our approach proved successful on different independent breast cancer data sets as well as an ovarian cancer data set. This study constitutes the first predictive method to classify cancer outcomes based on the relationship between the domain organization and protein network.	[Zhang, Kelvin Xi] Univ British Columbia, Grad Program Bioinformat, Vancouver, BC V5Z 1M9, Canada; [Zhang, Kelvin Xi; Ouellette, B. F. Francis] Ontario Inst Canc Res, Toronto, ON, Canada; [Zhang, Kelvin Xi] Univ Calif Los Angeles, David Geffen Sch Med, Dept Biol Chem, Los Angeles, CA 90095 USA; [Zhang, Kelvin Xi] Univ Calif Los Angeles, David Geffen Sch Med, Howard Hughes Med Inst, Los Angeles, CA 90095 USA	Zhang, KX (reprint author), Univ British Columbia, Grad Program Bioinformat, Vancouver, BC V5Z 1M9, Canada.	francis@oicr.on.ca			government of Ontario; CIHR/MSFHR; CIHR	This work was conducted with the support of the Ontario Institute for Cancer Research through funding provided by the government of Ontario to BFFO. KXZ was supported by the CIHR/MSFHR Strategic Training Program in Bioinformatics. KXZ was also supported by the CIHR Canada Graduate Scholarships Doctoral Award. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Berriz GF, 2009, BIOINFORMATICS, V25, P3043, DOI 10.1093/bioinformatics/btp498; Bikker JA, 2009, J MED CHEM, V52, P1493, DOI 10.1021/jm8010542; Bradford JR, 2006, J MOL BIOL, V362, P365, DOI 10.1016/j.jmb.2006.07.028; Chin K, 2006, CANCER CELL, V10, P529, DOI 10.1016/j.ccr.2006.10.009; Chuang HY, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100180; Hudson TJ, 2010, NATURE, V464, P993, DOI 10.1038/nature08987; Dutz JP, 2001, BLOOD, V97, P95, DOI 10.1182/blood.V97.1.95; Finn RD, 2005, BIOINFORMATICS, V21, P410, DOI 10.1093/bioinformatics/bti011; Forbes SA, 2008, CURR PROTOC HUM GENE; FRIEDMAN E, 1993, NAT GENET, V5, P242, DOI 10.1038/ng1193-242; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Gebauer G, 2008, BREAST CANCER RES, V10, DOI 10.1186/bcr2148; Greenman C, 2007, NATURE, V446, P153, DOI 10.1038/nature05610; Hanahan D, 2000, CELL, V100, P57, DOI 10.1016/S0092-8674(00)81683-9; HANKS SK, 1995, FASEB J, V9, P576; HANKS SK, 1991, METHOD ENZYMOL, V200, P38; Hortobagyi GN, 1998, NEW ENGL J MED, V339, P974; Jaluria P, 2007, MICROB CELL FACT, V6, DOI 10.1186/1475-2859-6-4; Kan ZY, 2010, NATURE, V466, P869, DOI 10.1038/nature09208; Kim PM, 2006, SCIENCE, V314, P1938, DOI 10.1126/science.1136174; Ledford H, 2010, NATURE, V464, P972, DOI 10.1038/464972a; Letunic I, 2009, NUCLEIC ACIDS RES, V37, pD229, DOI 10.1093/nar/gkn808; Lindstrom MS, 2007, MOL CELL BIOL, V27, P1056, DOI 10.1128/MCB.01307-06; Liu YC, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012890; Manning G, 2002, SCIENCE, V298, P1912, DOI 10.1126/science.1075762; MARENGERE LEM, 1994, J CELL SCI, P97; Matthews L, 2009, NUCLEIC ACIDS RES, V37, pD619, DOI 10.1093/nar/gkn863; Miller LD, 2005, P NATL ACAD SCI USA, V102, P13550, DOI 10.1073/pnas.0506230102; Naugler WE, 2008, CURR OPIN GENET DEV, V18, P19, DOI 10.1016/j.gde.2008.01.020; Nevins JR, 2007, NAT REV GENET, V8, P601, DOI 10.1038/nrg2137; Oh AS, 2008, MOL CELL BIOL, V28, P6580, DOI 10.1128/MCB.00118-08; Paez JG, 2004, SCIENCE, V304, P1497, DOI 10.1126/science.1099314; Pawson T, 2001, TRENDS CELL BIOL, V11, P504, DOI 10.1016/S0962-8924(01)02154-7; PAWSON T, 1995, NATURE, V373, P573, DOI 10.1038/373573a0; Pawson T, 2003, SCIENCE, V300, P445, DOI 10.1126/science.1083653; Pleasance E. D., 2009, NATURE, V463, P191, DOI 10. 1038/nature08658; Pleasance ED, 2009, NATURE, V463, P184, DOI [10.1038/nature08629, DOI 10.1038/NATURE08629]; Porter CJ, 2007, BMC STRUCT BIOL, V7, DOI 10.1186/1472-6807-7-58; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Razick S, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-405; RUSSELL RB, 1992, FEBS LETT, V304, P15, DOI 10.1016/0014-5793(92)80579-6; Sachs K, 2005, SCIENCE, V308, P523, DOI 10.1126/science.1105809; Schwartz MA, 2001, J CELL SCI, V114, P2553; Shedden K, 2008, NAT MED, V14, P822, DOI 10.1038/nm.1790; Shen HH, 2004, MOL CELL, V16, P363, DOI 10.1016/j.molcel.2004.10.021; Shupliakov O, 1997, SCIENCE, V276, P259, DOI 10.1126/science.276.5310.259; Sjoblom T, 2006, SCIENCE, V314, P268, DOI 10.1126/science.1133427; Stratton MR, 2009, NATURE, V458, P719, DOI 10.1038/nature07943; Taylor IW, 2009, NAT BIOTECHNOL, V27, P199, DOI 10.1038/nbt.1522; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1; Wang Z, 2009, NAT REV GENET, V10, P57, DOI 10.1038/nrg2484; Yoshihara K, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009615; Young MR, 2003, TRENDS MOL MED, V9, P36, DOI 10.1016/S1471-4914(02)00009-6	55	7	7	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1553-7358			PLOS COMPUT BIOL	PLoS Comput. Biol.	MAR	2011	7	3							e1001114	10.1371/journal.pcbi.1001114		11	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	743CU	WOS:000288995500021	
J	Monsen, KA; Banerjee, A; Das, P				Monsen, Karen A.; Banerjee, Arindam; Das, Puja			Discovering Client and Intervention Patterns in Home Visiting Data	WESTERN JOURNAL OF NURSING RESEARCH			English	Article						data mining; Omaha System; informatics; parenting/families; community; statistical analysis	MODELS	Family home visiting is a widely accepted strategy used with disadvantaged families to mitigate the effects of poverty. However, gaps persist in knowledge of effective intervention approaches for home visiting relative to specific client risks such as parenting and psychosocial problems. The purpose of this study was to inductively create clusters from electronic health records of 484 public health nursing clients, using client characteristics and intervention data. Four clinically relevant client clusters were generated using Mixed Membership Naive Bayes methods. Fourteen distinct intervention clusters were generated using KMETIS, a graph partitioning method. The content of the intervention clusters illustrates the complexity of public health nursing practice. This study leverages current nursing documentation technology capacity to advance nursing knowledge. Future research is needed to explore relationships between client and intervention clusters and their associations with client outcomes, with the end goals of improving home visiting practice and client outcomes.	[Monsen, Karen A.] Univ Minnesota, Sch Nursing, Minneapolis, MN 55455 USA; [Banerjee, Arindam; Das, Puja] Univ Minnesota, Sch Engn & Comp Sci, Minneapolis, MN 55455 USA	Monsen, KA (reprint author), Univ Minnesota, Sch Nursing, 5-160 Weaver Densford Hall, Minneapolis, MN 55455 USA.	mons0122@umn.edu			Midwest Nursing Research Society	The authors disclosed receipt of the following financial support for the research and/or authorship of this article: This work was supported by the Midwest Nursing Research Society New Investigator Seed Grant.	American Nurses Association, 2006, ANA REC TERM DAT EL; Banerjee A, 2007, IEEE DATA MINING, P421, DOI 10.1109/ICDM.2007.55; Barnard KE, 1998, ZERO 3, V18, P23; BENNETT C, 2007, COCHRANE DB SYST REV, V3, DOI 10.1002/14651858.CD003759.pub2; Berger AM, 2004, CIN-COMPUT INFORM NU, V22, P123, DOI 10.1097/00024665-200405000-00006; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Drummond JE, 2002, PUBLIC HEALTH NURS, V19, P21, DOI 10.1046/j.1525-1446.2002.19004.x; Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997; Martin KS, 2005, OMAHA SYSTEM KEY PRA; Martin KS, 1992, OMAHA SYSTEM APPL CO; Monsen Karen A, 2002, Outcomes Manag, V6, P62; Monsen KA, 2010, MATERN CHILD HLTH J, V14, P412, DOI 10.1007/s10995-009-0479-9; Monsen KA, 2006, CIN-COMPUT INFORM NU, V24, P152, DOI 10.1097/00024665-200605000-00012; MONSEN KA, 2006, THESIS U MINNESOTA M; Monsen KA, 2009, RES NURS HEALTH, V32, P647, DOI 10.1002/nur.20354; *NURS FAM PARTN, 2009, NURS FAM PARTN HELP; Olds David L, 2002, Prev Sci, V3, P153, DOI 10.1023/A:1019990432161; SCHAEFER K, 1991, LEVINES CONSERVATION; SHAN H, 2008, 09002 TR U MINN DEP; TIEDJE LB, 2005, MCN              NOV, P373; WANG H, 2009, SIAM INT C DAT MIN P, P209	21	7	7	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0193-9459			WESTERN J NURS RES	West. J. Nurs. Res.	DEC	2010	32	8					1031	1054		10.1177/0193945910370970		24	Nursing	Nursing	672LJ	WOS:000283584400004	
J	Lytle, DA; Martinez-Munoz, G; Zhang, W; Larios, N; Shapiro, L; Paasch, R; Moldenke, A; Mortensen, EN; Todorovic, S; Dietterich, TG				Lytle, David A.; Martinez-Munoz, Gonzalo; Zhang, Wei; Larios, Natalia; Shapiro, Linda; Paasch, Robert; Moldenke, Andrew; Mortensen, Eric N.; Todorovic, Sinisa; Dietterich, Thomas G.			Automated processing and identification of benthic invertebrate samples	JOURNAL OF THE NORTH AMERICAN BENTHOLOGICAL SOCIETY			English	Article						bioassessment; water quality; automated insect identification; bioindicators; Plecoptera	RECOGNITION; SYSTEM; SCALE	We present a visually based method for the taxonomic identification of benthic invertebrates that automates image capture, image processing, and specimen classification. The BugID system automatically positions and images specimens with minimal user input. Images are then processed with interest operators (machine-learning algorithms for locating informative visual regions) to identify informative pattern features, and this information is used to train a classifier algorithm. Naive Bayes modeling of stacked decision trees is used to determine whether a specimen is an unknown distractor (taxon not in the training data set) or one of the species in the training set. When tested on images from 9 larval stonefly taxa, BugID correctly identified 94.5% of images, even though small or damaged specimens were included in testing. When distractor taxa (10 common invertebrates not present in the training set) were included to make classification more challenging, overall accuracy decreased but generally was close to 90%. At the equal error rate (EER), 89.5% of stonefly images were correctly classified and the accuracy of nonrejected stoneflies increased to 96.4%, a result suggesting that many difficult-to-identify or poorly imaged stonefly specimens had been rejected prior to classification. BugID is the first system of its kind that allows users to select thresholds for rejection depending on the required use. Rejected images of distractor taxa or difficult specimens can be identified later by a taxonomic expert, and new taxa ultimately can be incorporated into the training set of known taxa. BugID has several advantages over other automated insect classification systems, including automated handling of specimens, the ability to isolate nontarget and novel species, and the ability to identify specimens across different stages of larval development.	[Lytle, David A.] Oregon State Univ, Dept Zool, Corvallis, OR 97331 USA; [Martinez-Munoz, Gonzalo; Zhang, Wei; Mortensen, Eric N.; Todorovic, Sinisa; Dietterich, Thomas G.] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA; [Larios, Natalia; Shapiro, Linda] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; [Shapiro, Linda] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA; [Paasch, Robert] Oregon State Univ, Dept Mech Engn, Corvallis, OR 97331 USA; [Moldenke, Andrew] Oregon State Univ, Dept Bot & Plant Pathol, Corvallis, OR 97331 USA	Lytle, DA (reprint author), Oregon State Univ, Dept Zool, Corvallis, OR 97331 USA.	lytleda@oregonstate.edu; martinez@eecs.oregonstate.edu; zhangwe@eecs.oregonstate.edu; nlarios@u.washington.edu; shapiro@cs.washington.edu; paasch@engr.orst.edu; moldenka@science.oregonstate.edu; enm@eecs.oregonstate.edu; sinisa@eecs.oregonstate.edu; tgd@oregonstate.edu	Martinez-Munoz, Gonzalo/K-7269-2012	Martinez-Munoz, Gonzalo/0000-0002-6125-6056	National Science Foundation [IIS-0326052, IIS-0705765, DEB-0445366]; Fulbright Program; Spanish Ministerio de Ciencia e Innovacion [TIN2007-66862-C02-02]	We thank Justin Miles, Frank Drake, Kate Boersma, Mike Bogan, Laura McMullen, and Asako Yamamuro for help with specimen collection and identification. Funding was provided by grants from the National Science Foundation (IIS-0326052, IIS-0705765, and DEB-0445366). GM-M acknowledges support from the Fulbright Program and the Spanish Ministerio de Ciencia e Innovacion, project TIN2007-66862-C02-02.	Bhanu Bir, 2008, American Entomologist, V54, P228; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Clark JY, 2007, SYST ASSOC SPEC VOL, V74, P207; Csurka G, 2004, WORKSH STAT LEARN CO, P1; Deng H, 2007, IEEE C COMP VIS PATT, P1; Do MT, 1999, B ENTOMOL RES, V89, P217; HAFELE R, 1998, STREAM MACR IN PRESS; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; LARIOS E, 2007, MACH VISION APPL, DOI DOI 10.1007/S00138-007-0086-Y; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MacLeod N, 2007, AUTOMATED TAXON IDEN; Martinez-Munoz G, 2009, PROC CVPR IEEE, P549; MIKOLAJCZYK K, 2002, EUR C COMP VIS, P128; Mortensen EN, 2007, SYST ASSOC SPEC VOL, V74, P189; Rodenacker K, 2006, MICROSC RES TECHNIQ, V69, P708, DOI 10.1002/jemt.20338; Sarpola MJ, 2008, T ASABE, V51, P2217; Savolainen V, 2005, PHILOS T ROY SOC B, V360, P1805, DOI 10.1098/rstb.2005.1730; WATSON AT, SYSTEMATICS BIODIVER, V1, P287	18	7	7	NORTH AMER BENTHOLOGICAL SOC	LAWRENCE	1041 NEW HAMSPHIRE STREET, LAWRENCE, KS 66044 USA	0887-3593			J N AM BENTHOL SOC	J. N. Am. Benthol. Soc.	SEP	2010	29	3					867	874		10.1899/09-080.1		8	Ecology; Marine & Freshwater Biology	Environmental Sciences & Ecology; Marine & Freshwater Biology	635XY	WOS:000280692400007	
J	Wong, JWH; Schwahn, AB; Downard, KM				Wong, Jason W. H.; Schwahn, Alexander B.; Downard, Kevin M.			FluTyper-an algorithm for automated typing and subtyping of the influenza virus from high resolution mass spectral data	BMC BIOINFORMATICS			English	Article							HEMAGGLUTINATION-INHIBITION; SPECTROMETRY; IDENTIFICATION; SURVEILLANCE; ANTIGENICITY; EVOLUTION	Background: High resolution mass spectrometry has been employed to rapidly and accurately type and subtype influenza viruses. The detection of signature peptides with unique theoretical masses enables the unequivocal assignment of the type and subtype of a given strain. This analysis has, to date, required the manual inspection of mass spectra of whole virus and antigen digests. Results: A computer algorithm, FluTyper, has been designed and implemented to achieve the automated analysis of MALDI mass spectra recorded for proteolytic digests of the whole influenza virus and antigens. FluTyper incorporates the use of established signature peptides and newly developed naive Bayes classifiers for four common influenza antigens, hemagglutinin, neuraminidase, nucleoprotein, and matrix protein 1, to type and subtype the influenza virus based on their detection within proteolytic peptide mass maps. Theoretical and experimental testing of the classifiers demonstrates their applicability at protein coverage rates normally achievable in mass mapping experiments. The application of FluTyper to whole virus and antigen digests of a range of different strains of the influenza virus is demonstrated. Conclusions: FluTyper algorithm facilitates the rapid and automated typing and subtyping of the influenza virus from mass spectral data. The newly developed naive Bayes classifiers increase the confidence of influenza virus subtyping, especially where signature peptides are not detected. FluTyper is expected to popularize the use of mass spectrometry to characterize influenza viruses.	[Wong, Jason W. H.] Univ New S Wales, Prince Wales Clin Sch, Fac Med, Sydney, NSW, Australia; [Wong, Jason W. H.] Univ New S Wales, Lowy Canc Res Ctr, Fac Med, Sydney, NSW, Australia; [Schwahn, Alexander B.; Downard, Kevin M.] Univ Sydney, Sch Mol Sci, Sydney, NSW 2006, Australia	Wong, JWH (reprint author), Univ New S Wales, Prince Wales Clin Sch, Fac Med, Sydney, NSW, Australia.	jason.wong@unsw.edu.au	Wong, Jason/A-9466-2008	Wong, Jason/0000-0003-2953-7728	Australian Research Council [LE0668439]; University of Sydney; ARC [DP0770619]	The FT-ICR mass spectrometer was purchased with funds provided by an Australian Research Council Discovery Linkage Infrastructure Equipment Facility (LIEF) Grant (LE0668439) and the University of Sydney. A. Schwahn was supported by an ARC Discovery Project Grant (DP0770619).	Bao YM, 2008, J VIROL, V82, P596, DOI 10.1128/JVI.02005-07; Bush RM, 1999, SCIENCE, V286, P1921, DOI 10.1126/science.286.5446.1921; Downard KM, 2007, ANALYST, V132, P611, DOI 10.1039/b701835e; Downard KM, 2009, MASS SPECTROM REV, V28, P35, DOI 10.1002/mas.20194; FLAHAULT A, 1994, EUR J EPIDEMIOL, V10, P471, DOI 10.1007/BF01719679; Garten RJ, 2009, SCIENCE, V325, P197, DOI 10.1126/science.1176225; Horn DM, 2000, J AM SOC MASS SPECTR, V11, P320, DOI 10.1016/S1044-0305(99)00157-9; INA Y, 1994, P NATL ACAD SCI USA, V91, P8388, DOI 10.1073/pnas.91.18.8388; Kiselar JG, 1999, BIOCHEMISTRY-US, V38, P14185, DOI 10.1021/bi991609j; Lapedes A, 2001, J THEOR BIOL, V212, P57, DOI 10.1006/jtbi.2001.2347; MAYNARD A, 2009, BRIT MED J, V19, P339; Morrissey B, 2006, PROTEOMICS, V6, P2034, DOI 10.1002/pmic.200500642; Morrissey B, 2007, J VIROL METHODS, V145, P106, DOI 10.1016/j.jviromet.2007.05.015; Pedersen Janice C., 2008, V436, P53, DOI 10.1007/978-1-59745-279-3_8; Peiris JSM, 2007, CLIN MICROBIOL REV, V20, P243, DOI 10.1128/CMR..00037-06; Perkins DN, 1999, ELECTROPHORESIS, V20, P3551, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3551::AID-ELPS3551>3.0.CO;2-2; Plotkin JB, 2002, P NATL ACAD SCI USA, V99, P6263, DOI 10.1073/pnas.082110799; Rompp A, 2005, EUR J MASS SPECTROM, V11, P443, DOI 10.1255/ejms.732; RVACHEV L, 1985, MATH BIOSCI, V73, P3; Schwahn AB, 2009, ANALYST, V134, P2253, DOI 10.1039/b912234f; SCHWAHN AB, 2010, EUR J MASS IN PRESS; Schwahn AB, 2010, J VIROL METHODS, V165, P178, DOI 10.1016/j.jviromet.2010.01.015; Schwahn AB, 2009, ANAL CHEM, V81, P3500, DOI 10.1021/ac900026f; Schwahn AB, 2009, J IMMUNOASS IMMUNOCH, V30, P245, DOI 10.1080/15321810903084350; SENKO MW, 1995, J AM SOC MASS SPECTR, V6, P229, DOI 10.1016/1044-0305(95)00017-8; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; White JM, 1997, STRUCTURAL BIOL VIRU, P80; *WHO, 2003, 211 WHO; WRIGHT KE, 1995, J CLIN MICROBIOL, V33, P1180	29	7	7	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAY 19	2010	11								266	10.1186/1471-2105-11-266		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	623HU	WOS:000279730700004	
J	Poh, N; Kittler, J; Bourlai, T				Poh, Norman; Kittler, Josef; Bourlai, Thirimachos			Quality-Based Score Normalization With Device Qualitative Information for Multimodal Biometric Fusion	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article						Multimodal biometrics; person authentication; quality-based fusion; score normalization	SENSOR INTEROPERABILITY	As biometric technology is rolled out on a larger scale, it will be a common scenario (known as cross-device matching) to have a template acquired by one biometric device used by another during testing. This requires a biometric system to work with different acquisition devices, an issue known as device interoperability. We further distinguish two subproblems, depending on whether the device identity is known or unknown. In the latter case, we show that the device information can be probabilistically inferred given quality measures (e.g., image resolution) derived from the raw biometric data. By keeping the template unchanged, cross-device matching can result in significant degradation in performance. We propose to minimize this degradation by using device-specific quality-dependent score normalization. In the context of fusion, after having normalized each device output independently, these outputs can be combined using the naive Bayes principal. We have compared and categorized several state-of-the-art quality-based score normalization procedures, depending on how the relationship between quality measures and score is modeled, as follows: 1) direct modeling; 2) modeling via the cluster index of quality measures; and 3) extending 2) to further include the device information (device-specific cluster index). Experimental results carried out on the Biosecure DS2 data set show that the last approach can reduce both false acceptance and false rejection rates simultaneously. Furthermore, the compounded effect of normalizing each system individually in multimodal fusion is a significant improvement in performance over the baseline fusion (without using any quality information) when the device information is given.	[Poh, Norman; Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Surrey GU2 7XH, England; [Bourlai, Thirimachos] W Virginia Univ, Biometr Ctr, Morgantown, WV 26506 USA	Poh, N (reprint author), Univ Surrey, Ctr Vis Speech & Signal Proc, Surrey GU2 7XH, England.	normanpoh@ieee.org; J.Kittler@surrey.ac.uk; ThBourlai@mail.wvu.edu			Swiss National Science Foundation [PA0022 121477]; European Union (EU) [IST-214324]	Manuscript received December 3, 2008. First published March 25, 2010; current version published April 14, 2010. This work was supported in part by the Swiss National Science Foundation under Advanced Researcher Fellowship PA0022 121477 and in part by the two following European Union (EU)-funded projects: Mobile Biometry (MOBIO) under Grant IST-214324 and the Biosecure Network of Excellence. This paper was recommended by Guest Editor K. W. Bowyer.	Alonso-Fernandez F, 2005, LECT NOTES COMPUT SC, V3781, P180; ALONSOFERNANDEZ F, 2008, P SPIE DEFENSE SECUR; Bigun J., 2003, Proceedings 12th International Conference on Image Analysis and Processing; Bishop C., 1999, NEURAL NETWORKS PATT; Bishop C. M., 2007, PATTERN RECOGNITION; Chen Y, 2005, LECT NOTES COMPUT SC, V3546, P160; Fatukasi O, 2007, LECT NOTES COMPUT SC, V4756, P881; Fierrez-Aguilar J, 2004, PROC SPIE, V5404, P544, DOI 10.1117/12.542800; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Jain A., 2008, HDB BIOMETRICS; Jensen F. V., 1996, INTRO BAYESIAN NETWO; KITTLER J, 2007, P SPIE DEFENSE SECUR, V6539; KRYSZCZUK K, 2006, P 13 EUR C SIGN PROC; KRYSZCZUK K, 2005, P 12 EUR C SIGN PROC; KRYSZCZUK K, 2007, LNCS, V4472, P1124; MALAYATH N, 2000, THESIS OREGON GRADUA; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Maurer D.E., 2007, PATTERN RECOGN, V41, P821; Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796; NANDAKUMAR K, 2006, P 18 INT C PATT REC, P473; ORTEGAGARCIA J, 2009, IEEE T PATTERN ANAL, VPP, P1; Poh N, 2009, IEEE T INF FOREN SEC, V4, P849, DOI 10.1109/TIFS.2009.2034885; Poh N., 2007, P IEEE C BIOM THEOR, P1; Poh N, 2007, LECT NOTES COMPUT SC, V4472, P344; Poh N., 2006, THESIS SWISS FEDERAL; Poh N, 2005, LECT NOTES COMPUT SC, V3546, P474; Ross A, 2004, LECT NOTES COMPUT SC, V3087, P134; Ross A, 2008, IEEE T KNOWL DATA EN, V20, P1097, DOI 10.1109/TKDE.2007.190696; Ross A. A., 2006, HDB MULTIBIOMETRICS; SCHEIDAT T, 2005, P IEEE INT C MULT EX, P1294; Vatsa M, 2009, IEEE T SYST MAN CY A, V39, P47, DOI 10.1109/TSMCA.2008.2007981	31	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4427			IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	MAY	2010	40	3					539	554		10.1109/TSMCA.2010.2041660		16	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	583NM	WOS:000276683900010	
J	Dong, LY; Zhang, HL; Ren, XS; Li, YL				Dong, Liyan; Zhang, Hailong; Ren, Xiangshi; Li, Yong-Li			CLASSIFIER LEARNING ALGORITHM BASED ON GENETIC ALGORITHMS	INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL			English	Article						Bayesian network classifier; Genetic algorithm; Algorithm likelihood; Classification	SYSTEMS	Combining the merits of the optimal search in Bayesian Theory and GA, this paper improves the TAN classifier, which maintains the classification accuracy rate of TAN and gives a restricted BAN classifier learning algorithm, namely GBAN. Learning the structure of the BAN classifier, a fitness function based on logarithm likelihood and the corresponding genetic operator are designed, and network structure code scheme is also designed, so that GBAN can constrict to global optimal structure. With the use of several data sets from the UCI Database, the comparisons of the classification results between GBAN and other algorithms such as TAN, BAN, GBN and Naive Bayes are given, respectively. And the results show that GBAN algorithm can get a better classification performance.	[Dong, Liyan; Zhang, Hailong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China; [Ren, Xiangshi] Kochi Univ Technol, Sch Informat, Kochi 7828502, Japan; [Li, Yong-Li] NE Normal Univ, Coll Comp, Changchun 130021, Peoples R China	Dong, LY (reprint author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.	dongliyan@gmail.com; ren.xiangshi@kochi-tech.ac.jp					Bouckaert RR, 2004, LECT NOTES ARTIF INT, V3339, P1089; Chang PC, 2008, INT J INNOV COMPUT I, V4, P2033; Cheng J., 1999, P 15 C UNC ART INT U, P101; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N., 1997, P 14 INT C MACH LEAR, P125; Hamzeh A, 2008, INT J INNOV COMPUT I, V4, P1797; Hsieh CH, 2009, INT J INNOV COMPUT I, V5, P387; Ji RR, 2007, INT J INNOV COMPUT I, V3, P1645; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; Liu D.Y., 2001, J COMPUTER RES DEV, V38, P916; Okuhara K, 2007, INT J INNOV COMPUT I, V3, P175; Pan TH, 2008, INT J INNOV COMPUT I, V4, P1383; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Su HS, 2007, INT J INNOV COMPUT I, V3, P977	14	7	7	ICIC INT	KUMAMOTO	TOKAI UNIV, 9-1-1, TOROKU, KUMAMOTO, 862-8652, JAPAN	1349-4198			INT J INNOV COMPUT I	Int. J. Innov. Comp. Inf. Control	APR	2010	6	4			SI		1973	1981				9	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	582ED	WOS:000276578000035	
S	Bifet, A; Holmes, G; Pfahringer, B; Frank, E		Zaki, MJ; Yu, JX; Ravindran, B; Pudi, V		Bifet, Albert; Holmes, Geoff; Pfahringer, Bernhard; Frank, Eibe			Fast Perceptron Decision Tree Learning from Evolving Data Streams	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PT II, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	14th Pacific-Asia Conference on Knowledge Discovery and Data Mining	JUN 21-24, 2010	Hyderabad, INDIA	IIIT Hyderbad, AFOSR, AOARD, ONRG			DRIFT DETECTION; MODEL TREES	Mining of data streams must balance three evaluation dimensions: accuracy, time and memory. Excellent accuracy on data streams has been obtained with Naive Bayes Hoeffding Trees-Hoeffding Trees with naive Hayes models at the leaf nodes-albeit with increased runtime compared to standard Hoeffding Trees. In this paper, we show that runtime can be reduced by replacing naive Bayes with perceptron classifiers, while maintaining highly competitive accuracy. We also show that accuracy can be increased even further by combining majority vote, naive Hayes, and perceptrons. We evaluate four perceptron-based learning strategies and compare them against appropriate baselines: simple perceptrons, Perceptron Hoeffding Trees, hybrid Naive Bayes Perceptron Trees, and bagged versions thereof. We implement a perceptron that uses the sigmoid activation function instead of the threshold activation function and optimizes the squared error, with one perceptron per class value. We test our methods by performing an evaluation study on synthetic and real-world datasets comprising up to ten million examples.	[Bifet, Albert; Holmes, Geoff; Pfahringer, Bernhard; Frank, Eibe] Univ Waikato, Hamilton, New Zealand	Bifet, A (reprint author), Univ Waikato, Hamilton, New Zealand.	abifet@cs.waikato.ac.nz; geoff@cs.waikato.ac.nz; bernhard@cs.waikato.ac.nz; eibe@cs.waikato.ac.nz	Frank, Eibe/A-1434-2008				Asuncion A., 2007, UCI MACHINE LEARNING; Bennett KP, 2000, MACH LEARN, V41, P295, DOI 10.1023/A:1007600130808; BIFET A, 2007, LEARNING TIME CHANGI; Bifet A, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P139; Breiman L., 1984, CLASSIFICATION REGRE; Domingos P., 2000, KNOWLEDGE DISCOVERY, P71; Frank E, 1998, MACH LEARN, V32, P63, DOI 10.1023/A:1007421302149; Gama J, 2004, LECT NOTES ARTIF INT, V3171, P286; GAMA J, 2009, COMBINING CLASSIFICA; Gama J., 2003, KDD 2003, P523; Harries M., 1999, SPLICE 2 COMP EVALUA; Holmes G, 2005, LECT NOTES ARTIF INT, V3721, P495; Holmes G., 2007, MOA MASSIVE ONLINE A; Hulten G., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Ikonomovska E, 2009, LECT NOTES ARTIF INT, V5808, P121; Ikonotnovska E, 2008, LECT NOTES COMPUT SC, V5255, P52, DOI 10.1007/978-3-540-88411-8_8; Landwehr N, 2005, MACH LEARN, V59, P161, DOI 10.1007/s10994-005-0466-3; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Oza N. C., 2001, ARTIF INTELL, P105; Oza N. C., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; SCHLIMMER JC, 1986, AAAI, P496; Street W. N., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Utgoff P. E., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence; Velte T., 2010, CLOUD COMPUTING PRAC; Zhou ZH, 2002, KNOWL-BASED SYST, V15, P515, DOI 10.1016/S0950-7051(02)00038-2	26	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-13671-9	LECT NOTES ARTIF INT			2010	6119		II				299	310				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BQR44	WOS:000281629400030	
J	Aseervatham, S; Bennani, Y				Aseervatham, Sujeevan; Bennani, Younes			Semi-structured document categorization with a semantic kernel	PATTERN RECOGNITION			English	Article						Mercer kernel; Support vector machine; Text categorization; Semantic similarity; Semi-structured data		Since a decade, text categorization has become an active field of research in the machine learning community. Most of the approaches are based on the term occurrence frequency. The performance of such surface-based methods can decrease when the texts are too complex, i.e., ambiguous. One alternative is to use the semantic-based approaches to process textual documents according to their meaning. Furthermore, research in text categorization has mainly focused on "flat texts" whereas many documents are now semi-structured and especially under the XML format. In this paper, we propose a semantic kernel for semi-structured biomedical documents. The semantic meanings of words are extracted using the unified medical language system (UMLS) framework. The kernel, with a SVM classifier, has been applied to a text categorization task on a medical corpus of free text documents. The results have shown that the semantic kernel outperforms the linear kernel and the naive Bayes classifier. Moreover, this kernel was ranked in the top 10 of the best algorithms among 44 classification methods at the 2007 Computational Medicine Center (CMC) Medical NLP International Challenge. (C) 2008 Elsevier Ltd. All rights reserved.	[Aseervatham, Sujeevan; Bennani, Younes] Univ Paris 13, LIPN, UMR 7030, CNRS, F-93430 Villetaneuse, France	Aseervatham, S (reprint author), Univ Paris 13, LIPN, UMR 7030, CNRS, 99 Av JB Clement, F-93430 Villetaneuse, France.	sujeevan@lipn.univ-paris13.fr; younes@lipn.univ-paris13.fr					Basili R., 2006, Informatica, V30; Berg C., 1984, HARMONIC ANAL SEMIGR; BLOEHDORN S, 2006, P IEEE ICDM, P808; Boser B., 1992, COMPUTATIONAL LEARNI, P144; Cristianini N, 2002, J INTELL INF SYST, V18, P127, DOI 10.1023/A:1013625426931; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DIVITA G, 2006, P AMIA FALL S, P201; Gliozzo A. M., 2005, P 9 C COMP NAT LANG, P56, DOI 10.3115/1706543.1706553; Haussler D., 1999, UCSCRL9910; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Joachims T., 2002, LEARNING CLASSIFY TE; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Joachims T., 1997, P 14 INT C MACH LEAR, P143; LEACOCK C, 1998, WORDNET ELECT LEXICA, V12, P265; Lin D., 1998, P 15 INT C MACH LEAR, P296; Pedersen T, 2007, J BIOMED INFORM, V40, P288, DOI 10.1016/j.jbi.2006.06.004; PESTIAN J, 2007, P 2007 ACL BIONLP AS; Resnik P., 1995, P 14 INT JOINT C ART, P448; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Sebastiani F, 2005, ADV MANAG INFORM, V2, P109; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; Shawe-Taylor J, 2004, KERNEL METHODS PATTE; SIOLAS G, 2000, P IJCNN 00 INT JOINT; Vapnik V., 1995, NATURE STAT LEARNING; Yang ZW, 2001, ALCOHOL, V24, P145, DOI 10.1016/S0741-8329(01)00145-8	25	7	8	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	SEP	2009	42	9					2067	2076		10.1016/j.patcog.2008.10.024		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	459GI	WOS:000267089000035	
J	Cuesta, I; Bielza, C; Larranaga, P; Cuenca-Estrella, M; Laguna, F; Rodriguez-Pardo, D; Almirante, B; Pahissa, A; Rodriguez-Tudela, JL				Cuesta, Isabel; Bielza, Concha; Larranaga, Pedro; Cuenca-Estrella, Manuel; Laguna, Fernando; Rodriguez-Pardo, Dolors; Almirante, Benito; Pahissa, Albert; Rodriguez-Tudela, Juan L.			Data Mining Validation of Fluconazole Breakpoints Established by the European Committee on Antimicrobial Susceptibility Testing	ANTIMICROBIAL AGENTS AND CHEMOTHERAPY			English	Article							CANDIDIASIS; EPIDEMIOLOGY	European Committee on Antimicrobial Susceptibility Testing (EUCAST) breakpoints classify Candida strains with a fluconazole MIC <= 2 mg/liter as susceptible, those with a fluconazole MIC of 4 mg/liter as representing intermediate susceptibility, and those with a fluconazole MIC > 4 mg/liter as resistant. Machine learning models are supported by complex statistical analyses assessing whether the results have statistical relevance. The aim of this work was to use supervised classification algorithms to analyze the clinical data used to produce EUCAST fluconazole breakpoints. Five supervised classifiers (J48, Correlation and Regression Trees [CART], OneR, Naive Bayes, and Simple Logistic) were used to analyze two cohorts of patients with oropharyngeal candidosis and candidemia. The target variable was the outcome of the infections, and the predictor variables consisted of values for the MIC or the proportion between the dose administered and the MIC of the isolate (dose/MIC). Statistical power was assessed by determining values for sensitivity and specificity, the false-positive rate, the area under the receiver operating characteristic (ROC) curve, and the Matthews correlation coefficient (MCC). CART obtained the best statistical power for a MIC > 4 mg/liter for detecting failures (sensitivity, 87%; false-positive rate, 8%; area under the ROC curve, 0.89; MCC index, 0.80). For dose/MIC determinations, the target was > 75, with a sensitivity of 91%, a false-positive rate of 10%, an area under the ROC curve of 0.90, and an MCC index of 0.80. Other classifiers gave similar breakpoints with lower statistical power. EUCAST fluconazole breakpoints have been validated by means of machine learning methods. These computer tools must be incorporated in the process for developing breakpoints to avoid researcher bias, thus enhancing the statistical power of the model.	[Cuesta, Isabel; Cuenca-Estrella, Manuel; Rodriguez-Tudela, Juan L.] Inst Salud Carlos III, Ctr Nacl Microbiol, Serv Micol, Majadahonda 28220, Spain; [Bielza, Concha; Larranaga, Pedro] Univ Politecn Madrid, Fac Informat, Dept Inteligencia Artificial, Madrid, Spain; [Laguna, Fernando] Hosp Carlos III, Med Interna Serv, Madrid, Spain; [Rodriguez-Pardo, Dolors; Almirante, Benito; Pahissa, Albert] Hosp Univ Valle Hebron, Serv Enfermedades Infecciosas, Barcelona, Spain	Rodriguez-Tudela, JL (reprint author), Inst Salud Carlos III, Ctr Nacl Microbiol, Serv Micol, Ctra Majadahonda Pozuelo Km 2, Majadahonda 28220, Spain.	jlrtudela@isciii.es	Ferrandos, Montserrat/H-7889-2012; Bielza, Concha/F-9277-2013; Larranaga, Pedro/F-9293-2013		Ministerio de Sanidad y Consumo, Instituto de Salud Carlos III; Spanish Network of Infection in Transplantation [RESITRA G03/075]; Spanish Network for the Research in Infectious Diseases [REIPI RD06/0008]	This work was supported in part by Ministerio de Sanidad y Consumo, Instituto de Salud Carlos III, Spanish Network of Infection in Transplantation (RESITRA G03/075), and by the Spanish Network for the Research in Infectious Diseases (REIPI RD06/0008).	Almirante B, 2005, J CLIN MICROBIOL, V43, P1829, DOI 10.1128/JCM.43.4.1829-1835.2005; Breiman L., 1984, CLASSIFICATION REGRE; Cestnik B., 1987, PROGR MACHINE LEARNI, P31; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Hosmer Jr DW, 2000, APPL LOGISTIC REGRES; Laguna F, 1997, CLIN INFECT DIS, V24, P124; Larranaga P, 2006, BRIEF BIOINFORM, V7, P86, DOI 10.1093/bib/bbk007; Pfaller MA, 2007, CLIN MICROBIOL REV, V20, P133, DOI 10.1128/CMR.00029-06; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rex JH, 2002, CLIN INFECT DIS, V35, P982, DOI 10.1086/342384; Rodriguez-Tudela JL, 2008, CLIN MICROBIOL INFEC, V14, P398, DOI 10.1111/j.1469-0691.2007.01935.x; Rodriguez-Tudela JL, 2007, ANTIMICROB AGENTS CH, V51, P3599, DOI 10.1128/AAC.00296-07; RODRIGUEZTUDELA JL, 2008, CLIN MICROBIOL INFEC, V14, P193, DOI DOI 10.1111/J.1469-0691.2007.01899.X; SANDERS CC, 1991, J ANTIMICROB CHEMOTH, V28, P621, DOI 10.1093/jac/28.5.621; Witten IH, 2005, DATA MINING PRACTICA	15	7	7	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0066-4804			ANTIMICROB AGENTS CH	Antimicrob. Agents Chemother.	JUL	2009	53	7					2949	2954		10.1128/AAC.00081-09		6	Microbiology; Pharmacology & Pharmacy	Microbiology; Pharmacology & Pharmacy	462LL	WOS:000267354000035	
J	Sakiyama, Y				Sakiyama, Yojiro			The use of machine learning and nonlinear statistical tools for ADME prediction	EXPERT OPINION ON DRUG METABOLISM & TOXICOLOGY			English	Review						ADME; ensemble; in silico; kernel; machine learning; nonlinear	SUPPORT VECTOR MACHINES; STRUCTURE-PROPERTY RELATIONSHIPS; RECURSIVE-PARTITIONING MODEL; HUMAN INTESTINAL-ABSORPTION; LIVER MICROSOMAL STABILITY; BRAIN-BARRIER PERMEATION; SELF-ORGANIZING MAPS; GENE-EXPRESSION DATA; IN-SILICO; AQUEOUS SOLUBILITY	Absorption, distribution, metabolism and excretion (ADME)-related failure of drug candidates is a major issue for the pharmaceutical industry today. Prediction of ADME by in silico tools has now become an inevitable paradigm to reduce cost and enhance efficiency in pharmaceutical research. Recently, machine learning as well as nonlinear statistical tools has been widely applied to predict routine ADME end points. To achieve accurate and reliable predictions, it would be a prerequisite to understand the concepts, mechanisms and limitations of these tools. Here, we have devised a small synthetic nonlinear data set to help understand the mechanism of machine learning by 2D-visualisation. We applied six new machine learning methods to four different data sets. The methods include Naive Bayes classifier, classification and regression tree, random forest, Gaussian process, support vector machine and k nearest neighbour. The results demonstrated that ensemble learning and kernel machine displayed greater accuracy of prediction than classical methods irrespective of the data set size. The importance of interaction with the engineering field is also addressed. The results described here provide insights into the mechanism of machine learning, which will enable appropriate usage in the future.	Sandwich Labs, Pfizer Global Res & Dev, Pharmacokinet Dynam Metab, Sandwich CT13 9NJ, Kent, England	Sakiyama, Y (reprint author), Sandwich Labs, Pfizer Global Res & Dev, Pharmacokinet Dynam Metab, Sandwich CT13 9NJ, Kent, England.	Yojiro.Sakiyama@pfizer.com					AKAIKE H, 1978, BIOMETRIKA, V65, P53, DOI 10.1093/biomet/65.1.53; [Anonymous], WEKA 3 DATA MINING S; Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; ATKSON CG, 1997, ARTIF INTELL REV, V11, P11; Balakin Konstantin V, 2005, Curr Drug Discov Technol, V2, P99, DOI 10.2174/1570163054064666; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; BARRETT SJ, 2005, ADV APPL MACHINE LEA; Bayes T., 1793, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSTL.1763.0053; Bellman R.E., 1961, ADAPTIVE CONTROL PRO; Bishop CM, 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; Boubacar HA, 2008, NEURAL NETWORKS, V21, P1287, DOI 10.1016/j.neunet.2008.03.016; BOX GBP, 2005, FRACTIONAL FACTORIAL; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Broomhead D. S., 1988, Complex Systems, V2; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Bruneau P, 2001, J CHEM INF COMP SCI, V41, P1605, DOI 10.1021/ci010363y; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burden FR, 2001, J CHEM INF COMP SCI, V41, P830, DOI 10.1021/ci000459c; Burden FR, 2000, J CHEM INF COMP SCI, V40, P1423, DOI 10.1021/ci000450a; Burton J, 2006, J MED CHEM, V49, P6231, DOI 10.1021/jm060267u; Cartmell J, 2005, J COMPUT AID MOL DES, V19, P821, DOI 10.1007/s10822-005-9029-8; CATUANA R, 2008, P 25 INT C MACH LEAR; Chohan KK, 2005, J MED CHEM, V48, P5154, DOI 10.1021/jm048959a; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, INTRO SUPPORT VECTOR; De Cerqueira Lima P., 2006, J CHEM INF MODEL, V46, P1245; Deconinck E, 2005, J PHARMACEUT BIOMED, V39, P91, DOI 10.1016/j.jpba.2005.03.008; Deconinck E, 2005, J PHARMACEUT BIOMED, V39, P1021, DOI 10.1016/j.jpba.2005.05.034; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; de Groot MJ, 2002, ADV DRUG DELIVER REV, V54, P367, DOI 10.1016/S0169-409X(02)00009-1; Delaney JS, 2004, J CHEM INF COMP SCI, V44, P1000, DOI 10.1021/ci034243x; Devillers J, 1998, J PHARM SCI-US, V87, P1086, DOI 10.1021/js980101j; DOGRA SK, 2008, CHOICE MODELS QSARWO; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Ekins S, 2006, J MED CHEM, V49, P5059, DOI 10.1021/jm060076r; Ekins Sean, 2005, Expert Opin Drug Metab Toxicol, V1, P303, DOI 10.1517/17425255.1.2.303; Embrechts MJ, 2007, DRUG METAB DISPOS, V35, P325, DOI 10.1124/dmd.106.013185; Fox T, 2006, CURR TOP MED CHEM, V6, P1579, DOI 10.2174/156802606778108915; FRIEDMAN J, 1988, MULTIVARIATE ADAPTIV; Frohlich H, 2006, QSAR COMB SCI, V25, P317, DOI 10.1002/qsar.200510135; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gamerman D, 1997, MARKOV CHAIN MONTE C; Ghose AK, 2008, J MED CHEM, V51, P5149, DOI 10.1021/jm800475y; Gleeson MP, 2006, J MED CHEM, V49, P1953, DOI 10.1021/jm0510070; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; GOOD IJ, 1964, ESTIMATION PROBABILI; GREEN DM, 1966, SIGNAL DETECTION THE, P45; GUPTA N, QSARWORLD STRAND LIF; Hansch C, 2004, DRUG METAB REV, V36, P105, DOI 10.1081/DMR-120028428; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Hebb D. O., 1949, ORG BEHAV; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; Holland J. H., 1975, ADAPTATION NATURAL A; Hopfield JJ, 1982, NATL ACAD SCI, V79, P2554, DOI DOI 10.1073/PNAS.79.8.2554; Hou TJ, 2007, J CHEM INF MODEL, V47, P2408, DOI 10.1021/ci7002076; Hou TJ, 2007, J CHEM INF MODEL, V47, P208, DOI 10.1021/ci600343x; Hsu Chih-Wei, PRACTICAL GUIDE SUPP; Hunt E.B, 1966, EXPT INDUCTION; Huuskonen J, 1997, J PHARM SCI, V86, P450, DOI 10.1021/js960358m; Jensen TS, 2002, EUR J PAIN-LONDON, V6, P3, DOI 10.1016/S1090-3801(02)90002-9; Jin B, 2007, INT J DATA MIN BIOIN, V1, P270, DOI 10.1504/IJDMB.2007.011613; Jordan M.I., 1999, LEARNING GRAPHICAL M; Jung E, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-245; Kaiser D, 2007, J MED CHEM, V50, P1698, DOI 10.1021/jm060604z; Karthikeyan M, 2005, J CHEM INF MODEL, V45, P581, DOI 10.1021/ci0500132; Keefer CE, 2006, CHEMOMETR INTELL LAB, V84, P40, DOI 10.1016/j.chemolab.2006.04.013; Klon AE, 2006, J CHEM INF MODEL, V46, P1945, DOI 10.1021/ci0601315; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; Kohonen T., 1984, SELF ORG ASS MEMORY; Kola I, 2004, NAT REV DRUG DISCOV, V3, P711, DOI 10.1038/nrd1470; Kononenko I, 2007, MACHINE LEARNING DAT; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Kuentz M, 2003, PHARM DEV TECHNOL, V8, P453, DOI 10.1081/PDT-120024698; Kurogi Y, 2001, CURR MED CHEM, V8, P1035; Lamanna C, 2008, J MED CHEM, V51, P2891, DOI 10.1021/jm701407x; Lee PH, 2007, J COMPUT AID MOL DES, V21, P665, DOI 10.1007/s10822-007-9124-0; Li GZ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S6-S7; Li H, 2005, J CHEM INF MODEL, V45, P1376, DOI 10.1021/ci050135u; Li H, 2007, J PHARM SCI-US, V96, P2838, DOI 10.1002/jps.20985; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Liu HX, 2005, J COMPUT AID MOL DES, V19, P499, DOI 10.1007/s10822-005-9003-5; Liu KH, 2008, COMPUT BIOL MED, V38, P601, DOI 10.1016/j.compbiomed.2008.02.007; Liu Q, 2008, J BIOMOL STRUCT DYN, V25, P685; Lombardo F, 2006, J MED CHEM, V49, P2262, DOI 10.1021/jm050200r; Ma WP, 2006, J CHROMATOGR A, V1113, P140, DOI 10.1016/j.chroma.2006.01.136; Ma Xiao Hua, 2008, Curr Drug Saf, V3, P100, DOI 10.2174/157488608784529224; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; MACKAY DJC, 1995, MAXIMUM ENTROPY BAYE, P211; Mente SR, 2005, J COMPUT AID MOL DES, V19, P465, DOI 10.1007/s10822-005-9001-7; Minka T. P., 2001, P 17 C UNC ART INT, P362; Mitchell T.M., 1997, MACHINE LEARNING; Banka H, 2008, CH CRC COMP SCI DATA, P277; MOSTELLER F, 1948, ANN MATH STAT, V19, P58, DOI 10.1214/aoms/1177730290; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Narasimhan B, 2006, CHEM PHARM BULL, V54, P1067, DOI 10.1248/cpb.54.1067; Narayanan R, 2005, BIOORGAN MED CHEM, V13, P3017, DOI 10.1016/j.bmc.2005.01.061; NEAL RM, 1997, 9702 U TOR DEP STAT, V45, P5; NEAL RM, 1996, BAYESIAN LEARNING NE; Netzeva TI, 2005, ATLA-ALTERN LAB ANIM, V33, P155; Neumann MH, 2000, STAT SINICA, V10, P399; Nilsson Nils J., 1965, LEARNING MACHINES; Nocedal J., 1999, NUMERICAL OPTIMIZATI; Obrezanova O, 2007, J CHEM INF MODEL, V47, P1847, DOI 10.1021/ci7000633; Obrezanova O, 2008, J COMPUT AID MOL DES, V22, P431, DOI 10.1007/s10822-008-9193-8; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; Osuna E., 1997, NEURAL NETWORKS SIGN, VVII, P276; Palmer DS, 2007, J CHEM INF MODEL, V47, P150, DOI 10.1021/ci060164k; Pedersen A G, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P226; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Polley MJ, 2005, AUST J CHEM, V58, P859, DOI 10.1071/CH05202; QUINLAIN JR, 1979, EXPERT SYSTEMS MICRO; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P854, DOI 10.1021/ci00020a020; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1; SAKIYAMA Y, 2008, P 2008 INT C MACH LE, V2, P784; Sakiyama Y, 2008, J MOL GRAPH MODEL, V26, P907, DOI 10.1016/j.jmgm.2007.06.005; Sato T, 2008, J MED CHEM, V51, P7705, DOI 10.1021/jm800504q; Schroeter T, 2007, MOL PHARMACEUT, V4, P524, DOI 10.1021/mp0700413; Schroeter TS, 2007, J COMPUT AID MOL DES, V21, P651, DOI 10.1007/s10822-007-9160-9; Schwaighofer A, 2008, J CHEM INF MODEL, V48, P785, DOI 10.1021/ci700142c; Schwaighofer A, 2007, J CHEM INF MODEL, V47, P407, DOI 10.1021/ci600205g; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SKINNER BT, 2007, C P IEEE ENG MED BIO, P3120; SONNENBURG S, J MACH LEARN, P2443; Sorich MJ, 2008, CURR DRUG METAB, V9, P60, DOI 10.2174/138920008783331167; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STOKES ME, 1995, CATEGORICAL DATA ANA, P98; STONE M, 1974, J R STAT SOC B, V36, P111; Susnow RG, 2003, J CHEM INF COMP SCI, V43, P1308, DOI 10.1021/ci030283p; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Team RDC, R LANG ENV STAT COMP; Tong WD, 2005, CURR COMPUT-AID DRUG, V1, P195, DOI 10.2174/1573409053585663; TOPLISS JG, 1979, J MED CHEM, V22, P1238, DOI 10.1021/jm00196a017; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4; Tropsha A, 2003, QSAR COMB SCI, V22, P69, DOI 10.1002/qsar.200390007; Trotter MWB, 2003, QSAR COMB SCI, V22, P533, DOI 10.1002/qsar.200310006; Vapnik V., 1995, NATURE STAT LEARNING; Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91; Votano JR, 2006, J MED CHEM, V49, P7169, DOI 10.1021/jm051245v; Wang YH, 2005, J COMPUT AID MOL DES, V19, P137, DOI 10.1007/s10822-005-3321-5; Wang YH, 2005, BIOORG MED CHEM LETT, V15, P4076, DOI 10.1016/j.bmcl.2005.06.015; Wang YH, 2005, J CHEM INF MODEL, V45, P750, DOI 10.1021/ci050041k; Whittaker J., 1990, GRAPHICAL MODELS APP; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; Winkler DA, 2004, DRUG FUTURE, V29, P1043, DOI 10.1358/dof.2004.029.10.863395; Wu C. F. J., 2000, EXPT PLANNING ANAL P; Yamashita F, 2006, J CHEM INF MODEL, V46, P1054, DOI 10.1021/ci0504770; Yamashita F, 2008, J CHEM INF MODEL, V48, P364, DOI 10.1021/ci700262y; Yap CW, 2007, MINI-REV MED CHEM, V7, P1097, DOI 10.2174/138955707782331696; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Yap CW, 2006, CURR TOP MED CHEM, V6, P1593, DOI 10.2174/156802606778108942; Yin YH, 1996, NUCLEIC ACIDS RES, V24, P1279, DOI 10.1093/nar/24.7.1279; Yoo PD, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-272; Zhang LY, 2008, PHARM RES-DORDR, V25, P1902, DOI 10.1007/s11095-008-9609-0; Zhang SX, 2006, J CHEM INF MODEL, V46, P1984, DOI 10.1021/ci060132x; Zhao CY, 2006, PHARM RES, V23, P41, DOI 10.1007/s11095-005-8716-4; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; 2008, INT C MACH LEARN MOD	165	7	7	INFORMA HEALTHCARE	LONDON	TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND	1742-5255	1744-7607		EXPERT OPIN DRUG MET	Expert Opin. Drug Metab. Toxicol.	FEB	2009	5	2					149	169		10.1517/17425250902753261		21	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	419QH	WOS:000264233800005	
J	Appavu, S; Rajaram, R				Appavu, Subramanian; Rajaram, Ramasamy			Knowledge-based system for text classification using ID6NB algorithm	KNOWLEDGE-BASED SYSTEMS			English	Article						Data mining; Dimensionality reduction; Classification; Decision tree; Majority voting; Naive Bayes		This paper presents a novel algorithm named ID6NB for extending decision tree induced by Quinlan's non-incremental ID3 algorithm. The presented approach is aimed at suggesting the solutions for few unhandled exceptions of the Decision tree induction algorithms such as (i) the situation in which the majority voting makes incorrect decision (generating two different types of rules for same data), and (ii) in case of dimensionality reduction by decision tree induction algorithms, the determination of appropriate attribute at a node where two or more attributes have equal highest information gain. Exception due to majority voting is handled with the help of Naive Bayes algorithm and also novel solutions are given for dimensionality reduction. As a result, the classification accuracy has drastically improved. An extensive experimental evaluation on a number of real and synthetic databases shows that ID6NB is a state-of-the-art classification algorithm that outperforms well than other methods of decision tree learning. (C) 2008 Elsevier B.V. All rights reserved,	[Appavu, Subramanian] Thiagarajar Coll Engn, Dept Informat Technol, Madurai, Tamil Nadu, India; [Rajaram, Ramasamy] Thiagarajar Coll Engn, Dept Comp Sci & Informat Technol, Madurai, Tamil Nadu, India	Appavu, S (reprint author), Thiagarajar Coll Engn, Dept Informat Technol, Madurai, Tamil Nadu, India.	sbit@tce.edu					Blake Catherine, UCI REPOSITORY MACHI; Cover T. M., 1991, ELEMENTS INFORM THEO; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; Han J., 2005, DATA MINING CONCEPTS; John G., 1994, P 11 INT C MACH LEAR, P121; JOYCE J, 2003, BAYES THEOREM STANDF; Liu H., 1998, FEATURE SELECTION KN; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P106; Schlimmer J., 1986, P 5 NAT C ART INT, V1, P502; Schlimmer J. C., 1986, Machine Learning, V1, DOI 10.1007/BF00116895; Schlimmer J. C., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Thrun S. B., 1991, CMUCS91197; Utgoff P.E., 1988, P 5 INT C MACH LEARN, P107; Utgoff PE, 1994, P 11 INT C MACH LEAR, P318; UTGOFF PE, 1989, P 6 INT WORKSH MACH; UTGOFF PE, 2004, J MACHINE LEARNI SPR, P5; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; *WEKA, WEKA OP SOURC COLL M; Witten I.H., 2000, DATA MINING PRACTICA	21	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	JAN	2009	22	1					1	7		10.1016/j.knosys.2008.04.006		7	Computer Science, Artificial Intelligence	Computer Science	392OF	WOS:000262311300001	
J	Morales, DA; Bengoetxea, E; Larranaga, P				Morales, Dinora A.; Bengoetxea, Endika; Larranaga, Pedro			Selection of human embryos for transfer by Bayesian classifiers	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						Bayesian classifiers; Supervised learning; Embryo image classification; In vitro fertilisations; Bayes methods	IN-VITRO FERTILIZATION; MOMENT INVARIANTS; CLASSIFICATION; RECOGNITION; QUALITY; SINGLE; OOCYTE; CHOICE; AREA; IVF	In this work we approach by Bayesian classifiers the selection of human embryos from images. This problem consists of choosing the embryos to be transferred in human-assisted reproduction treatments, which Bayesian classifiers address as a supervised classification problem. Different Bayesian classifiers capable of taking into account diverse dependencies between variables of this problem are tested in order to analyse their performance and validity for building a potential decision support system. The analysis by receiver operating characteristic (ROC) proves that the Bayesian classifiers presented in this paper are an appropriated and robust approach for this aim. From the Bayesian classifiers tested, the tree augmented naive Bayes, k-dependence Bayesian and naive Bayes classifiers showed to perform almost as well as the semi naive Bayes and selective naive Bayes classifiers. (C) 2008 Elsevier Ltd. All rights reserved.	[Morales, Dinora A.; Bengoetxea, Endika] Univ Basque Country, Intelligent Syst Grp, Donostia San Sebastian, Spain; [Larranaga, Pedro] Univ Politecn Madrid, Dept Inteligencia Artificial, Madrid, Spain	Morales, DA (reprint author), Univ Basque Country, Intelligent Syst Grp, Donostia San Sebastian, Spain.	dinora-morales@ehu.es	Larranaga, Pedro/F-9293-2013		Etortek, Saiotek and Research Group Funding programs [IT-242-07, TIN2008-06815-C02-01, TIN2008-06815-C02-02, 2010-CSD2007-00018]; COMBIOMED network in computational biomedicine	This work has been partially supported by the following grants: Etortek, Saiotek and Research Group Funding programs 2007-2012 (IT-242-07) (Basque Government), TIN2008-06815-C02-01, TIN2008-06815-C02-02 and Consolider Ingenio 2010-CSD2007-00018 projects (Spanish Ministry of Education and Science) and COMBIOMED network in computational biomedicine (Carlos III Health Institute).	ALBREGTSEN F, 2006, COMPUTER ANAL IMAGES, P496; BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; Blanco R, 2005, J BIOMED INFORM, V38, P376, DOI 10.1016/j.jbi.2005.05.004; Breiman L., 1984, CLASSIFICATION REGRE; DELLARAGIONE T, 2007, REPROD BIOL ENDOCRIN, V5; DOUGHERTY K, 1995, P 12 INT C MACH LEAR, P194; Duda R., 1973, PATTERN CLASSIFICATI; Duda R.O., 2001, PATTERN CLASSIFICATI; EGAN JP, 1975, SIGNAL DETECTION THE; Elvira Consortium, 2002, P 1 EUR WORKSH PROB, P222; ERENUS M, 1991, FERTIL STERIL, V56, P707; Fawcett T., ROC GRAPHS NOTES PRA; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GIORGETTI C, 1995, HUM REPROD, V10, P2427; HANLEY JA, 1982, RADIOLOGY, V143, P29; HILL GA, 1989, FERTIL STERIL, V52, P801; HU M, 1962, IRE T INFORM THEOR, V8, P179; Jurisica I, 1998, ARTIF INTELL MED, V12, P1, DOI 10.1016/S0933-3657(97)00037-7; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1994, P 10 C UNC ART INT, P399; Lasko TA, 2005, J BIOMED INFORM, V38, P404, DOI 10.1016/j.jbi.2005.02.008; MALOOF MA, 2003, WORKSH LEARN IMB SET, V2; Mangin JF, 2004, MED IMAGE ANAL, V8, P187, DOI 10.1016/j.media.2004.06.016; Manna C, 2004, REPROD BIOMED ONLINE, V8, P460; Mills Carla L., 1992, P187; Minsky M., 1961, T I RADIO ENG, V49, P8; Morales DA, 2008, COMPUT METH PROG BIO, V90, P104, DOI 10.1016/j.cmpb.2007.11.018; Patrizi G., 2004, International Transactions in Operational Research, V11, DOI 10.1111/j.1475-3995.2004.00464.x; PAZZANI M, 1997, LEARNING DATA ARTIFI, P239; Pearl J., 1988, PROBABILISTIC REASON; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Provost F., 1998, P 15 INT C MACH LEAR, P445; PUISSANT F, 1987, HUM REPROD, V2, P705; QUINLAN JR, 1986, MACH LEARN, V1, P106; Ruggeri A, 2002, COMPUT METH PROG BIO, V68, P25, DOI 10.1016/S0169-2607(01)00153-5; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Saith RR, 1998, HUM REPROD UPDATE, V4, P121, DOI 10.1093/humupd/4.2.121; Schulman A, 1993, FERTIL STERIL, V60, P123; Scott Lynette, 2003, Reprod Biomed Online, V6, P201; Spackman K., 1989, P 6 INT WORKSH MACH, P160; STONE M, 1974, J R STAT SOC B, V36, P111; TRIMARCHI JR, 2003, FERTIL STERIL, V80, P100, DOI 10.1016/S0015-0282(03)02065-X; Van Peperstraten AM, 2008, ACTA OBSTET GYN SCAN, V87, P226, DOI 10.1080/00016340701855670; Van Royen E, 1999, HUM REPROD, V14, P2345, DOI 10.1093/humrep/14.9.2345; VERBERG M, 2007, FERTIL STERIL, V89, P1159	47	7	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825			COMPUT BIOL MED	Comput. Biol. Med.	NOV-DEC	2008	38	11-12					1177	1186		10.1016/j.compbiomed.2008.09.002		10	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	386FU	WOS:000261868500006	
J	Guzella, TS; Mota-Santos, TA; Uchoa, JQ; Caminhas, W				Guzella, T. S.; Mota-Santos, T. A.; Uchoa, J. Q.; Caminhas, W. M.			Identification of SPAM messages using an approach inspired on the immune system	BIOSYSTEMS			English	Article						artificial immune system; SPAM identification; continuous learning; innate and adaptive immunity; regulatory T cells	REGULATORY T-CELLS; SELF-TOLERANCE; ANOMALY DETECTION; CLONAL SELECTION; INNATE IMMUNITY; ALGORITHM; FILTER; PRINCIPLE; MACHINES	In this paper, an immune-inspired model, named innate and adaptive artificial immune system (IA-AIS) is proposed and applied to the problem of identification of unsolicited bulk e-mail messages (SPAM). It integrates entities analogous to macrophages, B and T lymphocytes, modeling both the innate and the adaptive immune systems. An implementation of the algorithm was capable of identifying more than 99% of legitimate or SPAM messages in particular parameter configurations. It was compared to an optimized version of the naive Bayes classifier, which has been attained extremely high correct classification rates. It has been concluded that IA-AIS has a greater ability to identify SPAM messages, although the identification of legitimate messages is not as high as that of the implemented naive Bayes classifier. (c) 2008 Elsevier Ireland Ltd. All rights reserved.	[Guzella, T. S.; Caminhas, W. M.] Univ Fed Minas Gerais, Dept Elect Engn, BR-31270010 Belo Horizonte, MG, Brazil; [Mota-Santos, T. A.] Univ Fed Minas Gerais, Dept Biochem & Immunol, Belo Horizonte, MG, Brazil; [Uchoa, J. Q.] Univ Fed Lavras, Dept Comp Sci, BR-37200000 Lavras, MG, Brazil	Guzella, TS (reprint author), Univ Fed Minas Gerais, Dept Elect Engn, BR-31270010 Belo Horizonte, MG, Brazil.	tguzella@cpdee.ufmg.br; tomaz@icb.ufmg.br; joukim@ginux.ufla.br; caminhas@cpdee.ufmg.br	caminhas, walmir/F-4332-2010				Andren N, 2000, J STRATEGIC STUD, V23, P167; Ayara M, 2005, LECT NOTES COMPUT SC, V3627, P404; Bezerra GB, 2006, LECT NOTES COMPUT SC, V4163, P446; Burnet FM, 1959, CLONAL SELECTION THE; Carpinter J, 2006, COMPUT SECUR, V25, P566, DOI 10.1016/j.cose.2006.06.001; COHEN IR, 1992, IMMUNOL TODAY, V13, P441, DOI 10.1016/0167-5699(92)90071-E; Cohn M, 2005, SPRINGER SEMIN IMMUN, V27, P3, DOI 10.1007/s00281-005-0199-1; Coutinho A, 2005, INT J DEV BIOL, V49, P131, DOI 10.1387/ijdb.041965ac; Cutello V, 2007, IEEE T EVOLUT COMPUT, V11, P101, DOI 10.1109/TEVC.2006.880328; Dasgupta D, 2005, SOFT COMPUT, V9, P172, DOI 10.1007/s00500-003-0342-7; Decastro L. N., 2002, ARTIFICIAL IMMUNE SY; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; Delany SJ, 2005, KNOWL-BASED SYST, V18, P187, DOI 10.1016/j.knosys.2004.10.002; DORNBOS J, 2002, SPAM WHAT CAN YOU DO; Freitas AA, 2007, IEEE T EVOLUT COMPUT, V11, P521, DOI 10.1109/TEVC.2006.884042; Graham P., 2002, PLAN SPAM; Greensmith J, 2005, LECT NOTES COMPUT SC, V3627, P153; GUZELLA TS, 2005, P 7 BRAZ C NEUR NETW, V1; Janeway C., 2001, IMMUNE SYSTEM HLTH D; Ji Z, 2007, EVOL COMPUT, V15, P223, DOI 10.1162/evco.2007.15.2.223; KIM J, 2002, P C EV COMP, P1015; Lai CC, 2007, KNOWL-BASED SYST, V20, P249, DOI 10.1016/j.knosys.2006.05.016; Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635; Oda T, 2003, P C EV COMP CEC 2003, V1, P390; Oda T, 2003, LECT NOTES COMPUT SC, V2723, P231; SAHAMI M, 1998, WS9805; Sakaguchi S, 2004, ANNU REV IMMUNOL, V22, P531, DOI 10.1146/annurev.immunol.21.120601.141122; Salomon David, 2004, DATA COMPRESSION; Sarafijanovic S, 2005, IEEE T NEURAL NETWOR, V16, P1076, DOI 10.1109/TNN.2005.853419; Schwartz RH, 2005, NAT IMMUNOL, V6, P327, DOI 10.1038/ni1184; SECKER A, 2003, P IEEE CEC, V1, P131; Stepney Susan, 2005, INT J UNCONV COMPUT, V1, P315; Tedesco G, 2006, LECT NOTES COMPUT SC, V4163, P193; Twycross J, 2006, IEEE C EVOL COMPUTAT, P499, DOI 10.1109/CEC.2006.1688351; Twycross J, 2005, LECT NOTES COMPUT SC, V3627, P112; VARELA F, 1988, THEORETICAL IMMUNOLO, V2, P359; von Boehmer H, 2005, NAT IMMUNOL, V6, P338, DOI 10.1038/ni1180; Wang B, 2006, PATTERN ANAL APPL, V9, P339, DOI 10.1007/s10044-006-0045-7; Yue X, 2007, SOFT COMPUT, V11, P729, DOI 10.1007/s00500-006-0116-0	39	7	7	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0303-2647			BIOSYSTEMS	Biosystems	JUN	2008	92	3					215	225		10.1016/j.biosystems.2008.02.006		11	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	310YC	WOS:000256565900002	
B	Jiang, W; Li, YJ; Pang, XL			IEEE	Jiang, Wei; Li, Yi-Jun; Pang, Xiu-Li			An improved feature extraction approach based on rough sets for the medical diagnosis	PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7			English	Proceedings Paper	7th International Conference on Machine Learning and Cybernetics	JUL 12-15, 2008	Kunming, PEOPLES R CHINA	Hebei Univ, IEEE Syst, Man & Cybernet Soc, Yunnan Univ, Machine Learning & Cybernet Res Inst		medical diagnosis; rough sets; maximum entropy model; support vector machine; feature extraction		This paper presents a novel approach based on Rough Sets to extract the complicated features from the medical diagnosis corpus. Some symptoms or basic features in the medical diagnosis are usually correlated. In general, the combinations of several basic symptoms may represent the disease more precision. However, the overmuch feature can reduce the generalization ability, or even many unfit features as the noise can decrease the model's performance. This paper proposes to apply the rough set theory to mine the complicated features, even from noise or inconsistent corpus. Secondly, these complex features are added into the Maximum Entropy model or Support Vector Machine etc. as a new kind of features, consequently, the feature weights can be assigned according to the performance of the whole model. The experiments in the Liver-disorders repository show that our method can improve the Maximum Entropy model by the precision 3.51%, improve the Support Vector Machine model by the precision 3.05%, improve the Naive Bayes model by the precision 3.59%, and improve the Bayes and GoodTuring model by the precision 3.59%.	[Jiang, Wei; Li, Yi-Jun; Pang, Xiu-Li] Harbin Inst Technol, Informat Management Res Ctr, Harbin 150001, Peoples R China	Jiang, W (reprint author), Harbin Inst Technol, Informat Management Res Ctr, Harbin 150001, Peoples R China.						Carlin U, 1998, P 7 C INF PROC MAN U, P1528; CASTRO F, 1999, MED DECIS MAKING, V19, P178; GEORGEPETER K, 2001, IEEE T INF TECHNOL B, V5, P55; WakuliczDeja A, 1997, INT J MED INFORM, V46, P119, DOI 10.1016/S1386-5056(97)00061-0; Pawlak Z., 1991, SYSTEM THEORY KNOWLE, V9; Podgorelec V, 2001, J Med Syst, V25, P195, DOI 10.1023/A:1010733016906; POPLE HE, 1982, ARTIF INTELL, P119; Richards RJ, 1996, MED DECIS MAKING, V16, P367, DOI 10.1177/0272989X9601600407; Shortliffe E. H., 2000, MED INFORM COMPUTER; SLOWINSKI K, 1992, HDB APPL ADV ROUGH S, V11, P77; Wang XL, 2004, IEEE T SYST MAN CY B, V34, P834, DOI 10.1109/TSMCB.2003.817101; WEI J, 2006, J HARBIN I TECHNOLOG, V13, P94; WOOLERY LK, 1994, J AM MED INFORM ASSN, V1, P439	13	7	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2095-7				2008							385	390				6	Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BII01	WOS:000259604900069	
J	Zheng, HW; Zhang, YX				Zheng, Hongwen; Zhang, Yanxia			Feature selection for high-dimensional data in astronomy	ADVANCES IN SPACE RESEARCH			English	Article						method : data analysis; feature selection; astronomical catalogs; sky survey	COMPONENT ANALYSIS; CLASSIFICATION; SPECTRA	With an exponentially increasing amount of astronomical data, the complexity and dimension of astronomical data are likewise growing rapidly. Extracting information from such data becomes a critical and challenging problem. For example, some algorithms can only be employed in the low-dimensional spaces, so feature selection and feature extraction become important topics. Here we describe the difference between feature selection and feature extraction methods, and introduce the taxonomy of feature selection methods as well as the characteristics of each method. We present a case study comparing the performance and computational cost of different feature selection methods. For the filter method, ReliefF and fisher filter are adopted; for the wrapper method, improved CHAID, linear discriminant analysis (LDA), Naive Bayes (NB) and C4.5 are taken as learners. Applied on the sample, the result indicates that from the viewpoints of computational cost the filter method is superior to the wrapper method. Moreover, different learning algorithms combined with appropriate feature selection methods may arrive at better performance. (C) 2007 COSPAR. Published by Elsevier Ltd. All rights reserved.	[Zhang, Yanxia] CAS, Natl Astron Observ, Beijing 100012, Peoples R China; [Zheng, Hongwen] N China Elect Power Univ, Inst Math & Phys, Beijing 102206, Peoples R China	Zhang, YX (reprint author), CAS, Natl Astron Observ, 20A Datun Rd, Beijing 100012, Peoples R China.	zyx@lamost.org					ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; Dash M., 2002, Proceedings 2002 IEEE International Conference on Data Mining. ICDM 2002, DOI 10.1109/ICDM.2002.1183893; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Ferreras I, 2006, MON NOT R ASTRON SOC, V370, P828, DOI 10.1111/j.1365-2966.2006.10509.x; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; KIRA K, 1992, MACHINE LEARNING /, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Liu H., 1998, FEATURE SELECTION KN; Lu HL, 2006, ASTRON J, V131, P790, DOI 10.1086/498711; Miller A. J., 2002, SUBSET SELECTION REG; Mitchell T.M., 1997, MACHINE LEARNING; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAKOTOMALALA R, 1997, P AIDRI 97, P131; Fiorentin PR, 2007, ASTRON ASTROPHYS, V467, P1373, DOI 10.1051/0004-6361:20077334; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; SAPORTA G, 1990, PROBABILITY ANAL DAT; Zhang Y, 2004, ASTRON ASTROPHYS, V422, P1113, DOI 10.1051/0004-6361:20040141; Zhang YX, 2004, P SOC PHOTO-OPT INS, V5493, P483, DOI 10.1117/12.550982	18	7	7	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0273-1177			ADV SPACE RES	Adv. Space Res.		2008	41	12					1960	1964		10.1016/j.asr.2007.08.033		5	Astronomy & Astrophysics; Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences	Astronomy & Astrophysics; Geology; Meteorology & Atmospheric Sciences	313CW	WOS:000256719700003	
J	Hruschka, ER; Hruschka, ER; Ebecken, NFF				Hruschka, Estevam R., Jr.; Hruschka, Eduardo R.; Ebecken, Nelson F. F.			Bayesian networks for imputation in classification problems	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						missing values; Bayesian networks; data mining	EM ALGORITHM; MISSING DATA; CONVERGENCE PROPERTIES; FEATURE-SELECTION; INDUCTION; MIXTURES	Missing values are an important problem in data mining. In order to tackle this problem in classification tasks, we propose two imputation methods based on Bayesian networks. These methods are evaluated in the context of both prediction and classification tasks. We compare the obtained results with those achieved by classical imputation methods (Expectation-Maximization, Data Augmentation, Decision Trees, and Mean/Mode). Our simulations were performed by means of four datasets (Congressional Voting Records, Mushroom, Wisconsin Breast Cancer and Adult), which are benchmarks for data mining methods. Missing values were simulated in these datasets by means of the elimination of some known values. Thus, it is possible to assess the prediction capability of an imputation method, comparing the original values with the imputed ones. In addition, we propose a methodology to estimate the bias inserted by imputation methods in classification tasks. In this sense, we use four classifiers (One Rule, Naive Bayes, J4.8 Decision Tree and PART) to evaluate the employed imputation methods in classification scenarios. Computing times consumed to perform imputations are also reported. Simulation results in terms of prediction, classification, and computing times allow us performing several analyses, leading to interesting conclusions. Bayesian networks have shown to be competitive with classical imputation methods.	Univ Fed Sao Carlos, UFSCar, BR-13560 Sao Carlos, Brazil; Catholic Univ Santos Unisantos, Santos, Brazil; Univ Fed Rio de Janeiro, COPPE, BR-21945 Rio De Janeiro, Brazil	Hruschka, ER (reprint author), Univ Fed Sao Carlos, UFSCar, BR-13560 Sao Carlos, Brazil.	estevam@dc.ufscar.br; estevam@dc.ufscar.br	Hruschka Jr., Estevam/B-1073-2008; Hruschka, Eduardo/E-6593-2011				Anderson R. L., 1946, BIOMETRICS BULL, V2, P41, DOI 10.2307/3001999; Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI 10.1080/08839510390219309; Beinlich IA, 1989, P 2 EUR C ART INT ME, P247; BILMES JA, ICSITR97021 U BERK; Cano R, 2004, STUD FUZZ SOFT COMP, V146, P309; Cheng J., 1999, P 15 C UNC ART INT U, P101; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; DeGroot M., 1970, OPTIMAL STAT DECISIO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Di Zio M, 2004, J ROY STAT SOC A STA, V167, P309, DOI 10.1046/j.1467-985X.2003.00736.x; Druzdzel M. J., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); FRIEDMAN N, 1996, P 13 NAT C ART INT, P717; Friedman N, 1997, P 14 INT C MACH LEAR; Friedman N, 2000, P 4 ANN INT C COMP M, P127, DOI 10.1145/332306.332355; GELMAN A, 1995, BAYESIAN ANAL; GHAHRAMAMI Z, 1995, AI LAB MEMO, V1509; Gilks W., 1996, MARKOV CHAIN M CARLO; Gilks W.R., 1996, MARKOV CHAIN MONTE C, P89; Han J., 2001, DATA MINING CONCEPTS; Heckerman D., 1995, MSRTR9506 MICR CORP; HRUSCHKA ER, 2002, MISSING VALUES PREDI, V6; Hruschka ER, 2004, LECT NOTES ARTIF INT, V3060, P370; Hruschka Jr ER, 2003, P INT C COMP INT MOD; Hsu WH, 2004, INFORM SCIENCES, V163, P103, DOI 10.1016/j.ins.2003.03.019; Jordan M., 1996, NEURAL NETWORKS, V8, P1409; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kononenko I., 1984, EXPT AUTOMATIC LEARN; Lam W, 1994, COMPUT INTELL, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Little RJA, 1987, STAT ANAL MISSING DA; LOBO OO, 2000, J JAPANESE SOC ARTIF, V15, P499; Madsen AL, 2003, LECT NOTES ARTIF INT, V2711, P594; Merz C., 1997, UCI REPOSITORY MACHI; Mitchell T.M., 1997, MACHINE LEARNING; NIGAM K, 2001, USING UNLABELED DATA; Pearl J., 1988, PROBABILISTIC REASON; PREECE DA, 1971, TECHNOMETRICS, V13, P743, DOI 10.2307/1266951; Pyle D., 1999, DATA PREPARATION DAT; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; REDNER R, 1984, SIAM REV, V26, P152; RUBIN DB, 1977, J AM STAT ASSOC, V72, P538, DOI 10.2307/2286214; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; Rubin DB, 1987, MULTIPLE IMPUTATION; Schafer JL, 2002, PSYCHOL METHODS, V7, P147, DOI 10.1037//1082-989X.7.2.147; Schafer J.L., 2000, ANAL INCOMPLETE MULT; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SEBASTIANI P, 1997, BAYESIAN INFERENCE M; Spiegelhalter D. J., 1996, BAYESIAN STAT, V5, P407; Spiegelhalter D.J., 1999, WINBUGS BAYESIAN INF; SPIEGELHALTER DJ, 1990, NETWORKS, V20, P576; SPIRTES P, 1993, CAUSATION PREDICATIO; TANNER MA, 1987, J AM STAT ASSOC, V82, P528, DOI 10.2307/2289457; WHITE AP, 1987, RES DEV EXPERT SYSTE, V3, P35; Witten I.H., 2000, DATA MINING PRACTICA; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129	56	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902			J INTELL INF SYST	J. Intell. Inf. Syst.	DEC	2007	29	3					231	252		10.1007/s10844-006-0016-x		22	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	233MP	WOS:000251095300001	
J	Qiu, J; Hwang, JTG				Qiu, Jing; Hwang, J. T. Gene			Sharp simultaneous confidence intervals for the means of selected Populations with application to microarray data analysis	BIOMETRICS			English	Article						Bonferroni simultaneous confidence intervals; differential expression; empirical Bayes approach; inference after selection; random effect models	DIFFERENTIAL GENE-EXPRESSION; VARIANCE; MODELS	Simultaneous inference for a large number, N, of parameters is a challenge. In some situations, such as microarray experiments, researchers are only interested in making inference for the K parameters corresponding to the K most extreme estimates. Hence it seems important to construct simultaneous confidence intervals for these K parameters. The naive simultaneous confidence intervals for the K means (applied directly without taking into account the selection) have low coverage probabilities. We take an empirical Bayes approach (or an approach based on the random effect model) to construct simultaneous confidence intervals with good coverage probabilities. For N = 10,000 and K = 100, typical for microarray data, our confidence intervals could be 77% shorter than the naive K-dimensional simultaneous intervals.	Cornell Univ, Dept Math, Ithaca, NY 14853 USA; Cornell Univ, Dept Stat Sci, Ithaca, NY 14853 USA; Univ Missouri, Dept Stat, Columbia, MO 65211 USA	Hwang, JTG (reprint author), Cornell Univ, Dept Math, White Hall, Ithaca, NY 14853 USA.	qiujing@missouri.edu; hwang@math.cornell.edu					BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; CASELLA G, 1983, J AM STAT ASSOC, V78, P688, DOI 10.2307/2288139; Cohen A., 1982, STATISTICAL DECISION, V1, P243; Cui X, 2003, STAT APPL GENET MOL, V2, P1; Cui XG, 2005, BIOSTATISTICS, V6, P59, DOI 10.1093/biostatistics/kxh018; Efron B, 1993, INTRO BOOTSTRAP; He K., 1992, STAT DECISIONS, V10, P121; Hsu JC, 2006, J STAT PLAN INFER, V136, P2182, DOI 10.1016/j.jspi.2005.08.029; Hwang J. T., 1993, SANKHYA A, V55, P285; Kerr MK, 2000, J COMPUT BIOL, V7, P819, DOI 10.1089/10665270050514954; Kerr MK, 2003, J COMPUT BIOL, V10, P891, DOI 10.1089/106652703322756131; LAIRD NM, 1987, J AM STAT ASSOC, V82, P739, DOI 10.2307/2288778; MORRIS CN, 1983, J AM STAT ASSOC, V78, P47, DOI 10.2307/2287098; QIU J, 2005, SHARP SIMULTANEOUS I; QIU J, 2004, THESIS CORNELL U ITH; VENTER JH, 1988, S AFR J SCI, V84, P340; Venter J. H., 1991, J STAT COMPUT SIM, V38, P1, DOI 10.1080/00949659108811315; Wolfinger RD, 2001, J COMPUT BIOL, V8, P625, DOI 10.1089/106652701753307520; Wright GW, 2003, BIOINFORMATICS, V19, P2448, DOI 10.1093/bioinformatics/btg345; ZHANG M, 2005, GENETICS, V169, P2304	20	7	7	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	SEP	2007	63	3					767	776		10.1111/j.1541-0420.2007.00770.x		10	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	203AJ	WOS:000248947200018	
J	Marsolo, K; Twa, M; Bullimore, MA; Parthasarathy, S				Marsolo, Keith; Twa, Michael; Bullimore, Mark A.; Parthasarathy, Srinivasan			Spatial modeling and classification of corneal shape	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						corneal shape; decision trees; spatial modeling	ZERNIKE POLYNOMIALS; NEURAL-NETWORK; KERATOCONUS; TOPOGRAPHY; SURFACES	One of the most promising applications of data mining is in biomedical data used in patient diagnosis. Any method of data analysis intended to support the clinical decision-making process should meet several criteria: it should capture clinically relevant features, be computationally feasible, and provide easily interpretable results. In an initial study, we examined the feasibility of using Zernike polynomials to represent biomedical instrument data in conjunction with a decision tree classifier to distinguish between the diseased and non-diseased eyes. Here, we provide a comprehensive follow-up to that work, examining a second representation pseudo-Zernike polynomials, to determine whether they provide any increase in classification accuracy. We compare the fidelity of both methods using residual root-mean-square (rms) error and evaluate accuracy using several classifiers: neural networks, C4.5 decision trees, Voting Feature Intervals, and Naive Bayes. We also examine the effect of several meta-learning strategies: boosting, bagging, and Random Forests (RFs). We present results comparing accuracy as it relates to dataset and transformation resolution over a larger, more challenging, multi-class dataset. They show that classification accuracy is similar for both data transformations, but differs by classifier. We find that the Zernike polynomials provide better feature representation than the pseudo-Zernikes and that the decision trees yield the best balance of classification accuracy and interpretability.	Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; Ohio State Univ, Coll Optometry, Columbus, OH 43210 USA; Ohio State Univ, Dept Biomed Informat, Columbus, OH 43210 USA	Marsolo, K (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	marsolo.2@osu.edu; bullimore.1@osu.edu; srini@cse.ohio-state.edu	Twa, Michael/B-8755-2012	Twa, Michael/0000-0003-4544-5153			Bishop C.M., 1995, NEURAL NETWORKS PATT; Born M., 1980, PRINCIPLES OPTICS EL; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Demirz G., 1997, P 9 EUR C MACH LEARN, P85; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Hoekman DH, 2001, IEEE T GEOSCI REMOTE, V39, P584, DOI 10.1109/36.911116; ISKANDER DR, 2001, INVESTIGAT OPHTHALMO, V42, pS896; Iskander DR, 2002, IEEE T BIO-MED ENG, V49, P320, DOI 10.1109/10.991159; Iskander DR, 2001, IEEE T BIO-MED ENG, V48, P87, DOI 10.1109/10.900255; JOHN GH, 1995, P 11 C UNC ART INT, P338; KIELY PM, 1982, OPT ACTA, V29, P1027; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; MAEDA N, 1995, INVEST OPHTH VIS SCI, V36, P1327; MAEDA N, 1994, INVEST OPHTH VIS SCI, V35, P2749; Mandell RB, 1996, INT CONTACT LENS CLI, V23, P205, DOI 10.1016/S0892-8967(96)00103-4; Marsolo K., 2005, P 5 IEEE INT C DAT M, P298; MARSOLO K, 2005, P IEEE 5 S BIOINF BI, P49; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rabinowitz YS, 1999, J CATARACT REFR SURG, V25, P1327, DOI 10.1016/S0886-3350(99)00195-9; SCHWARTZ MD, 1995, JUSTICE Q, V12, P10; Smolek MK, 2001, J CATARACT REFR SURG, V27, P1926, DOI 10.1016/S0886-3350(01)01182-8; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; Thibos LN, 2000, OSA TRENDS OPT PHOTO, V35, P232; TWA MD, 2003, SIAM INT C DAT MIN S; WANG JY, 1980, APPL OPTICS, V19, P1510, DOI 10.1364/AO.19.001510; WILLIAMS G, 1984, LINEAR ALGEBRA APPL; Witten I.H., 2000, DATA MINING PRACTICA; ZEMIKE F, 1934, PHYSICA, V1, P689	30	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-7771			IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	MAR	2007	11	2					203	212		10.1109/TITB.2006.87959		10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	149PI	WOS:000245158600009	
B	Kolcz, A; Yih, WT		Berkhin, P; Caruana, R; Wu, X; Gaffney, S		Kolcz, Aleksander; Yih, Wen-tau			Raising the Baseline for High-Precision Text Classifiers	KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING			English	Proceedings Paper	13th International Conference on Knowledge Discovery and Data Mining	AUG 12-15, 2007	San Jose, CA	ACM SIGKDD, ACM SIGMOD		high precision text classification; Naive Bayes; low false positive rates; email spam detection		Many important application areas of text classifiers demand high precision and it is common to compare prospective solutions to the performance of Naive Bayes. This baseline is usually easy to improve upon, but in this work we demonstrate that appropriate document representation can make outperforming this classifier much more challenging. Most importantly, we provide a link between Naive Bayes and the logarithmic opinion pooling of the mixture-of-experts framework, which dictates a particular type of document length normalization. Motivated by document-specific feature selection we propose monotonic constraints on document term weighting, which is shown as an effective method of fine-tuning document representation. The discussion is supported by experiments using three large email corpora corresponding to the problem of spam detection, where high precision is of particular importance.	[Kolcz, Aleksander] Microsoft Live Labs, Redmond, WA USA	Kolcz, A (reprint author), Microsoft Live Labs, 1 Microsoft Way, Redmond, WA USA.	ark@microsoft.com; scottyih@microsoft.com					Bennett P. N., 2000, CMUCS00155; CHEN L, P AWIC 2005, P272; CORMACK G, 2007, VIRUS B; CORMACK GV, 2005, P TREC 2005 14 TEXT; CORMACK GV, 2006, P 3 C EM ANT CEAS 20; Debole F., 2003, P SAC 03 18 ACM S AP, P784; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; EDDA L, 2002, MACH LEARN, V46, P423; Elkan C., 2001, IJCAI, P973; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GARTNER T, 2001, P 18 INT C MACH LEAR; GENEST C, 1986, STAT SCI; GOODMAN J, 2001, P 40 ANN M ASS COMP, P9, DOI 10.3115/1073083.1073086; Graham P., 2002, PLAN SPAM; Hinton G, 1999, P 9 INT C ART NEUR N, P1; HONG S, 2002, P 2002 IEEE INT C DA, P621; Juan A., 2002, P 2 INT WORKSH PATT, P200; KIM SB, 2006, IEEE T KNOWLEDGE DAT, V18; KOLCZ A, 2005, P 11 ACM SIGKDD INT; KOLCZ A, 2001, P WORKSH TEXT MIN TE; Lee MD, 2003, COGNITIVE SCI, V27, P159, DOI 10.1016/S0364-0213(02)00117-9; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; McCallum A, 1998, AAAI 98 WORKSH LEARN; METSIS V, 2006, P 3 C EM ANT CEAS 20; Mladenic D., 2004, P 27 ANN INT ACM SIG; MLADENIC D, 1999, P ICML 1999; RAINA R, 2004, P NIPS 16; Rennie J., 2003, P 20 INT C MACH LEAR; ROBINSON G, 2003, LINUX J; SAUBAN M, 2003, P PKDD 03 CAVT DUBR, P411; SCHNEIDER KM, 2005, P 6 INT C INT TEXT P, P682; SOUCY P, 2005, P 19 INT JOINT C ART, P1130; WU H, 2002, P 8 ACM SIGKDD INT C; YIH WT, 2006, P 3 C EM ANT CEAS 20; Zheng Z., 1999, P 16 INT C MACH LEAR, P493	36	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-59593-609-7				2007							400	409				10	Computer Science, Artificial Intelligence	Computer Science	BJK16	WOS:000266628300041	
S	Sewell, C; Morris, D; Blevins, NH; Barbagli, F; Salisbury, K		Westwood, JD; Haluck, RS; Hoffman, HM; Mogel, GT; Phillips, R; Robb, RA; Vosburgh, KG		Sewell, Christopher; Morris, Dan; Blevins, Nikolas H.; Barbagli, Federico; Salisbury, Kenneth			Evaluating Drilling and Suctioning Technique in a Mastoidectomy Simulator	MEDICINE MEETS VIRTUAL REALITY 15	Studies in Health Technology and Informatics		English	Proceedings Paper	15th Conference on Medicine Meets Virtual Reality	FEB 06-09, 2007	Long Beach, CA			Surgical simulation; automatic performance evaluation; metrics; temporal bone; tutoring; mastoidectomy		This paper presents several new metrics related to bone removal and suctioning technique in the context of a mastoidectomy simulator. The expertise with which decisions as to which regions of bone to remove and which to leave intact is evaluated by building a Naive Bayes classifier using training data from known experts and novices. Since the bone voxel mesh is very large, and many voxels are always either removed or not removed regardless of expertise, the mutual information was calculated for each voxel and only the most informative voxels used for the classifier. Leave-out-one cross validation showed a high correlation of calculated expert probabilities with scores assigned by instructors. Additional metrics described in this paper include those for assessing smoothness of drill strokes, proper drill burr selection, sufficiency of suctioning, two-handed tool coordination, and application of appropriate force and velocity magnitudes as functions of distance from critical structures.	[Sewell, Christopher; Morris, Dan; Barbagli, Federico; Salisbury, Kenneth] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Sewell, C (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.						Cotin S, 2002, LECT NOTES COMPUT SC, V2488, P35; HUANG J, P MMVR 2005, P194; MORRIS D, 2006, IEEE T IN PRESS  NOV; ROSEN J, P MMVR 2001; Sahami M., 1998, AAAI WORKSH LEARN TE; Sewell C, 2006, ST HEAL T, V119, P497; SEWELL C, 2007, P MED MEETS IN PRESS; SEWELL C, 2005, MED MEETS VIRTUAL RE, P451	8	7	7	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0926-9630		978-1-58603-713-0	ST HEAL T			2007	125						427	432				6	Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	BLN86	WOS:000270613800096	
S	Wilhelm, J; Chiueh, TC		Kruegel, C; Lippmann, R; Clark, A		Wilhelm, Jeffrey; Chiueh, Tzi-Cker			A forced sampled execution approach to kernel rootkit identification	Recent Advances in Intrusion Detection, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	10th International Symposium on Recent Advances in Intrusion Detection	SEP 05-07, 2007	Gold Coast, AUSTRALIA	NW Security Inst, SAP, CERT, Software Engn Inst, Carnegie Mellon Univ		rootkit detection; X86 ISA emulation; dynamic malware analysis; Bayes classifier, and intrusion prevention		Kernel rootkits are considered one of the most dangerous forms of malware because they reside inside the kernel and can perform the most privileged operations on the compromised machine. Most existing kernel rootkit detection techniques attempt to detect the existence of kernel rootkits, but cannot do much about removing them, other than booting the victim machine from a clean operating system image and configuration. This paper describes the design, implementation and evaluation of a kernel rootkit identification system for the Windows platform called Limbo, which prevents kernel rootkits from entering the kernel by checking the legitimacy of every kernel driver before it is loaded into the operating system. Limbo determines whether a kernel driver is a kernel rootkit based on its binary contents and run-time behavior. To expose the execution behavior of a kernel driver under test, Limbo features a forced sampled execution approach to traverse the driver's control flow graph. Through a comprehensive characterization study of current kernel rootkits, we derive a set of run-time features that can best distinguish between legitimate and malicious kernel drivers. Applying a Naive Bayes classification algorithm on this chosen feature set, the first Limbo prototype is able to achieve 96.2% accuracy for a test set of 754 kernel drivers, 311 of which are kernel rootkits.								ATHOLZ N, 2006, ROOTKITS DUMMIES; *AV, AV ROOTK DET; BUTLER J, 2005, PHRACK, V63; BUTLER J, 2004, P BLACK HAT 2004 JUL; CHRISTODORESCU M, 2005, P IEEE S SEC PRIV OA; Cogswell B, 2006, ROOTKITREVEALER V1 7; *CORP FS, FSEC BLACKL ROOT; *CORP S, 2006, INT SEC THREAT REP; *CORP S, NORT ANT; FLAKE H, 2004, P BLACK HAT 2004 JUL; *FUZ, FU ROOTK; HOGLUND G, COMPANION WEBSITE RO; Hoglund G., 2005, ROOTKITS SUBVERTING; KARIM M, 2005, EUR RES J COMPUTER V; KIRDA E, 2006, P US SEC S; KRUEGEL C, 2004, LNCS, V3189; LIVINGSTONB, ICEWORD AUTHOR SPEAK; MICRO T, ROOTKITBUSTER; Moser A., 2007, P 2007 IEEE S SEC PR; PETRONI N, 2004, P US SEC S AUG; RESEARCH P, ROOTKIT CLEANER; Rutkowska J., RED PILL DETECT VMM; RUTKOWSKA J, 2004, P ITUNDERGROUND C 20; RUTKOWSKA J, 2005, THOUGHTS CROSS VIEW; Rutkowska J., 2005, SYSTEM VIRGINITY VER; SABIN T, COMPARING BINARIES G; *SOPH, SOPH  ANT ROOTK; STAMP M, 2006, J COMPUTER VIROLOGY, V2; Wang Y., 2005, P INT C DEP SYST NET; WANG YM, 2004, P US LARG INST SYST; *WIK, NAIV BAY CLASS	31	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74319-4	LECT NOTES COMPUT SC			2007	4637						219	235				17	Computer Science, Theory & Methods	Computer Science	BGS68	WOS:000250340500012	
J	Wang, LM; Li, XL; Cao, CH; Yuan, SM				Wang, Li-Min; Li, Xiao-n Li; Cao, Chun-Hong; Yuan, Sen-Miao			Combining decision tree and Naive Bayes for classification	KNOWLEDGE-BASED SYSTEMS			English	Article						self-adaptive NBTree; decision tree; Naive Bayes; Bayes measure; discretization		Decision tree is useful to obtain a proper set of rules from a large amount of instances. However, it has difficulty in obtaining the relationship between continuous-valued data points. We propose in this paper a novel algorithm, Self-adaptive NBTree, which induces a hybrid of decision tree and Naive Bayes. The Bayes measure, which is used to construct decision tree, can directly handle continuous attributes and automatically find the most appropriate boundaries for discretization and the number of intervals. The Naive Bayes node helps to solve overgeneralization and overspecialization problems which are often seen in decision tree. Experimental results on a variety of natural domains indicate that Self-adaptive NBTree has clear advantages with respect to the generalization ability. (c) 2006 Elsevier B.V. All rights reserved.	Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China; Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China; NE Univ, Dept Comp Sci, Shenyang 230012, Peoples R China	Wang, LM (reprint author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.	jeffreywlm@hotmail.com					Aha W., 1996, UCI REPOSITORY MACHI; AUER P, 1995, P 12 INT C MACH LEAR, P21; CARLERR J, 1991, P 5 EUR WORKSH SESS, P164; DOUGHERTY J, 1995, P 12 INT C MACH LEAR, P191; Duda R., 1973, PATTERN CLASSIFICATI; IBA W, 1992, P 10 C ART INT, P223; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202; McCallum A, 1998, P AAAI 98 WORKSH LEA, P41; Quinlan J. R., 1993, C45 PROGRAMS MACHINE; QUINLAN JR, 1996, ARTIF INTELL, V4, P77; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Silverman B. W., 1986, MONOGRAPHS STAT APPL; SMYTH P, 1995, P 12 INT C MACH LEAR, P506	13	7	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	NOV	2006	19	7					511	515		10.1016/j.knosys.2005.10.013		5	Computer Science, Artificial Intelligence	Computer Science	113ZQ	WOS:000242636900008	
J	Pampapathi, R; Mirkin, B; Levene, M				Pampapathi, Rajesh; Mirkin, Boris; Levene, Mark			A suffix tree approach to anti-spam email filtering	MACHINE LEARNING			English	Article						suffix tree; spam; e-mail filtering; scoring function; text categorization	CLASSIFICATION	We present an approach to email filtering based on the suffix tree data structure. A method for the scoring of emails using the suffix tree is developed and a number of scoring and score normalisation functions are tested. Our results show that the character level representation of emails and classes facilitated by the suffix tree can significantly improve classification accuracy when compared with the currently popular methods, such as naive Bayes. We believe the method can be extended to the classification of documents in other domains.	Univ London, Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HU, England	Pampapathi, R (reprint author), Univ London, Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HU, England.	rajesh@dcs.bbk.ac.uk; mirkin@dcs.bbk.ac.uk; mark@dcs.bbk.ac.uk					AAS K, 1999, TEXT CATEGORISATION; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; *AP, 2005, AP SPAM PROJ; Bejerano G, 2001, BIOINFORMATICS, V17, P23, DOI 10.1093/bioinformatics/17.1.23; DEFREITAS S, 2004, JISC TECHNOLOGY STAN, V401; Duda R., 1973, PATTERN CLASSIFICATI; Fawcett Tom, 2004, ROC GRAPHS NOTES PRA; Flach PA, 2004, MACH LEARN, V57, P233, DOI 10.1023/B:MACH.0000039778.69032.ab; Giegerich R, 1997, ALGORITHMICA, V19, P331, DOI 10.1007/PL00009177; GRAHAMCUMMINGS J, 2004, SPAMMERS COMPENDIUM; GUSFIELD D, 1997, ALGORITMS STRINGS TR; Kurtz S, 1999, SOFTWARE PRACT EXPER, V29, P1149, DOI 10.1002/(SICI)1097-024X(199911)29:13<1149::AID-SPE274>3.0.CO;2-O; Lewis David D., 1998, P 10 EUR C MACH LEAR, P4; Lewis FD, 1996, J PHOTOCH PHOTOBIO A, V96, P19, DOI 10.1016/1010-6030(95)04285-7; Li YH, 1998, COMPUT J, V41, P537, DOI 10.1093/comjnl/41.8.537; LLOYD A, 2000, SUFFIX TREES; LU B, 2003, BIOINFORMATICS, P113; Manning C.D., 1999, FDN STAT NATURAL LAN; McCallum A., 1998, COMP EVENT MODELS NA; MEYER T, 2004, P 1 C EM ANT CEAS MO; MICHELAKIS E, 2004, P 1 C EM ANT CEAS MO; Porter M.F., 1997, READINGS INFORM RETR, P313; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; Sahami M, 1998, LEARNING TEXT CATEGO; Schneider K, 2003, P 10 C EUR CHAPT ASS, P307; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SURKOV D, 2004, THESIS ROYAL HOLLOWA; UKKONEN E, 1992, ALGORITHMS SOFTWARE, V1, P484; *UNSP, 2004, SPAM NUMB STAT; Vapnik V., 1999, NATURE STAT LEARNING; Weiss S.M., 2005, TEXT MINING PREDICTI; WITTEL GL, 2004, P 1 C EM ANT CEAS MO; Zhang SG, 2003, NAT REV GENET, V4, P243, DOI 10.1038/nrg1054	33	7	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	OCT	2006	65	1					309	338		10.1007/s10994-006-9505-y		30	Computer Science, Artificial Intelligence	Computer Science	088FN	WOS:000240797500011	
J	Santafe, G; Lozano, JA; Larranaga, P				Santafe, Guzman; Lozano, Jose A.; Larranaga, Pedro			Bayesian model averaging of naive Bayes for clustering	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						Bayesian model averaging (MA); clustering; expectation-maximization (EM); naive Bayes	EM ALGORITHM; NETWORKS; CLASSIFICATION; DISTRIBUTIONS; PREDICTION; LIKELIHOOD; DISCOVERY; SELECTION	This paper considers a Bayesian model-averaging (MA) approach to learn an unsupervised naive Bayes classification model. By using the expectation model-averaging (EMA) algorithm, which is proposed in this paper, a unique naive Bayes model that approximates an MA over selective naive Bayes structures is obtained. This algorithm allows to obtain the parameters for the approximate MA clustering model in the same time complexity needed to learn the maximum-likelihood model with the expectation-maximization algorithm. On the other hand, the proposed method can also be regarded as an approach to an unsupervised feature subset selection due to the fact that the model obtained by the EMA algorithm incorporates information on how dependent every predictive variable is on the cluster variable.	Univ Basque Country, Comp Sci & Artificial Intelligent Dept, Intelligent Syst Grp, San Sebastian 20018, Spain	Santafe, G (reprint author), Univ Basque Country, Comp Sci & Artificial Intelligent Dept, Intelligent Syst Grp, San Sebastian 20018, Spain.	guzman@si.ehu.es; ja.lozano@ehu.es; pedro.larranaga@ehu.es	Lozano, Jose/F-5120-2010; Computing Service, IZO-SGI/F-3072-2010; Larranaga, Pedro/F-9293-2013; SGIKER, Cienciometria/A-5759-2012				BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Barash Y, 2002, J COMPUT BIOL, V9, P169, DOI 10.1089/10665270252935403; Bensmail H, 1997, STAT COMPUT, V7, P1, DOI 10.1023/A:1018510926151; Cerquides J, 2005, MACH LEARN, V59, P323, DOI 10.1007/s10994-005-0470-7; Cerquides J., 2003, P 16 INT FLAIRS C, P341; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; Chickering DM, 1997, MACH LEARN, V29, P181; COOPER KH, 1992, MUNIVIRO, V9, P4; Cover T. M., 1991, ELEMENTS INFORM THEO; DASH D, 2003, P 9 INT WORKSH ART I, P38; Dash D., 2002, P 19 INT C MACH LEAR, P91; Dash D, 2004, J MACH LEARN RES, V5, P1177; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Elidan G., 2001, P 17 C UNC ART INT U, P144; Elvira Consortium, 2002, P 1 EUR WORKSH PROB, P222; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 1998, P 14 C UNC ART INT, P129; Friedman N., 1997, P 14 INT C MACH LEAR, P125; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Heckerman D., 1995, MSRTR9506; Hoeting J. A., 1999, STAT SCI, V14, P4; IDE JS, 2004, P 16 EUR C ART INT, P323; JENSEN F, 2001, BAYESIAN NETWORKS DE; KARCIAUSKAS G, 2004, P 2 WORKSH PROB GRAP, P137; MacKay DJC, 1998, MACH LEARN, V33, P77, DOI 10.1023/A:1007558615313; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; McLachlan G., 1997, EM ALGORITHM EXTENSI; MEDVEDOVIC M, 2005, P 4 WORKSH DAT MIN B, P40; MILLER AB, 1985, J NUTR GROWTH CANCER, V2, P159; Neapolitan RE, 2003, LEARNING BAYESIAN NE; Pearl J., 1988, PROBABILISTIC REASON; Pena JM, 2000, PATTERN RECOGN LETT, V21, P779, DOI 10.1016/S0167-8655(00)00038-6; SHEREIDER YA, 1964, METHOD STAT TESTING; Sobol I.M., 1984, MONTE CARLO METHOD; THIESSON B, 1997, P 13 C UNC ART INT U, P453; Vogl C, 2005, BIOINFORMATICS, V21, P130, DOI 10.1093/bioinformatics/bti1122; Witten IH, 2005, DATA MINING PRACTICA; Yeung KY, 2005, BIOINFORMATICS, V21, P2394, DOI 10.1093/bioinformatics/bti319	41	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2006	36	5					1149	1161		10.1109/TSMCB.2006.874132		13	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	087QI	WOS:000240756700015	
S	Mendez, JR; Fdez-Riverola, F; Diaz, F; Iglesias, EL; Corchado, JM		Perner, P		Mendez, J. R.; Fdez-Riverola, F.; Diaz, F.; Iglesias, E. L.; Corchado, J. M.			A comparative performance study of feature selection methods for the anti-spam filtering domain	ADVANCES IN DATA MINING: APPLICATIONS IN MEDICINE, WEB MINING, MARKETING, IMAGE AND SIGNAL MINING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th Industrial Conference on Data Mining (ICDM 2006)	JUL 14-15, 2006	Leipzig, GERMANY				TEXT CATEGORIZATION	In this paper we analyse the strengths and weaknesses of the mainly used feature selection methods in text categorization when they are applied to the spam problem domain. Several experiments with different feature selection methods and content-based filtering techniques are carried out and discussed. Information Gain, chi(2)-text, Mutual Information and Document Frequency feature selection methods have been analysed in conjunction with Naive Bayes, boosting trees, Support Vector Machines and ECUE models in different scenarios. From the experiments carried out the underlying ideas behind feature selection methods are identified and applied for improving the feature selection process of SpamHunting, a novel anti-spam filtering software able to accurate classify suspicious e-mails.	Univ Vigo, Escuela Super Ingn Informat, Dept Informat, Edificio Politecn, Orense 32004, Spain; Univ Valladolid, Escuela Univ Informat, Dept Informat, Segovia 40005, Spain; Univ Salamanca, Dept Informat & Automat, E-37008 Salamanca, Spain	Mendez, JR (reprint author), Univ Vigo, Escuela Super Ingn Informat, Dept Informat, Edificio Politecn, Campus Univ As Lagoas S-N, Orense 32004, Spain.	moncho.mendez@uvigo.es; riverola@uvigo.es; fdiaz@infor.uva.es; eva@uvigo.es; corchado@usal.es	Corchado Rodriguez, Juan/D-3229-2013	Corchado Rodriguez, Juan/0000-0002-2829-1829			ANDROUTSOPOULOS I, 2004, 20042 NCSR; ANDROUTSOPOULOS I, 2000, WORKSH MACH LEARN TE, P1; Carreras X., 2001, P 4 INT C REC ADV NA, P58; Church K. W., 1989, P ACL, V27, P76; CORCHADO JM, 2003, P 5 INT C CAS BAS RE, P107; CORCHADO JM, 2004, P 7 EUR C CAS BAS RE, P533; DAELEMANS W, TIMBL TILBURG MEMORY; de Lange T, 2004, BMC GASTROENTEROL, V4, DOI 10.1186/1471-230X-4-9; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; DUMAIS S, 1998, P 7 INT C INF KNOWL, P229; FDEZRIVEROLA F, 2006, IN PRESS DECISION SU; FRAKES B, 2000, INFORM RETRIEVAL DAT; GAMA J, 2002, P 8 IB AM C AI IBERA, P765; GRAHAM P, 2003, P MIT SPAM C; HOVOLD J, 2005, P 2 C EMAIL ANT CEAS; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KOLCZ A, 2001, P ICDM WORKSH TEXT M; LENZ M, 1998, LECT NOTES ARTIF INT, V1400, P51; MENDEZ JR, 2005, IN PRESS RES COMPUTI; Mitchell T., 1996, MACHINE LEARNING; *NIST, 2004, REUT CORP; Oard DW, 1997, USER MODEL USER-ADAP, V7, P141, DOI 10.1023/A:1008287121180; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; SAHAMI M, 1998, WS9805 AAAI, P55; Sakkis G, 2003, INFORM RETRIEVAL, V6, P49, DOI 10.1023/A:1022948414856; Salton G., 1983, INTRO MODERN INFORM; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Scholz M., 2005, P 2 INT WORKSH KNOWL, P53; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Syed N., 1999, P 5 ACM SIGKDD INT C, P317, DOI 10.1145/312129.312267; Tsymbal A., PROBLEM CONCEPT DRIF; Vapnik V., 1999, NATURE STAT LEARNING; WITTEL GL, 2004, P 1 C EMAIL ANT CEAS; Yang Y., 1997, P 14 INT C MACH LEAR, P412	34	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-36036-0	LECT NOTES ARTIF INT			2006	4065						106	120				15	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEV61	WOS:000239623700009	
J	Zhang, Y; Chu, CH; Chen, YX; Zha, HY; Ji, X				Zhang, Y; Chu, CH; Chen, YX; Zha, HY; Ji, X			Splice site prediction using support vector machines with a Bayes kernel	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						splice site prediction; SVM; Support Vector Machines; Bayes classifier; machine learning; splice site prediction using support vector machines with Bayes kernel	GENOMIC DNA; PROTEIN; RECOGNITION; SEQUENCE	One of the most important tasks in correctly annotating genes in higher organisms is to accurately locate the DNA splice sites. Although relatively high accuracy has been achieved by existing methods, most of these prediction methods are computationally extensive. Due to the enormous amount of DNA sequences to be processed, the computational speed is an important issue to consider. In this paper, we present a new machine learning method for predicting DNA splice sites, which first applies a Bayes feature mapping (kernel) to project the data into a new feature space and then uses a linear Support Vector Machine (SVM) as a classifier to recognize the true splice sites. The computation time is linear to the number of sequences tested, while the performance is notably improved compared with the Naive Bayes classifier in terms of classification accuracy, precision, and recall. Our classification results are also comparable to the solution quality obtained by the SVMs with polynomial kernels, while the speed of our proposed method is significantly faster. This is a notable improvement in computational modeling considering the huge amount of DNA sequences to be processed. (c) 2005 Elsevier Ltd. All rights reserved.	Penn State Univ, Sch Informat Sci & Technol, University Pk, PA 16802 USA; Univ New Orleans, Dept Comp Sci, New Orleans, LA 70148 USA; Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA; NEC Labs Amer, Cupertino, CA 95014 USA	Chu, CH (reprint author), Penn State Univ, Sch Informat Sci & Technol, 301 KIST Bldg, University Pk, PA 16802 USA.	yzhang@ist.psu.edu; chu@ist.psu.edu; yixin@cs.uno.edu; zha@cse.psu.edu; xji@sv.nec-labs.com	CHU, Chao-Hsien/G-4220-2013				Acir N, 2004, EXPERT SYST APPL, V27, P451, DOI 10.1016/j.eswa.2004.05.007; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Brendel V, 1998, NUCLEIC ACIDS RES, V26, P4748, DOI 10.1093/nar/26.20.4748; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951; Burgess C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Cai CZ, 2003, NUCLEIC ACIDS RES, V31, P3692, DOI 10.1093/nar/gkg600; Cristianini N., 2000, INTRO SUPPORT VECTOR; Degroeve S, 2002, BIOINFORMATICS, V18, pS75; Hu HJ, 2004, IEEE T NANOBIOSCI, V3, P265, DOI 10.1109/TNB.2004.837906; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Joachims T., 1999, ADV KERNEL METHODS S; JONES D, 2000, COMPARING KERNELS US; Lim M. E., 2003, GENOME INFORMATICS, V14, P400; MACHE N, 2000, PARALLEL NEURAL NETW; Min JH, 2005, EXPERT SYST APPL, V28, P603, DOI 10.1016/j.eswa.2004.12.008; Ng A. Y., 2001, NIPS, P841; Noble W. S., 2004, KERNEL METHODS COMPU, P71; Patterson Donald J, 2002, Pac Symp Biocomput, P223, DOI 10.1109/HPCA.2002.995714; Pertea M, 2001, NUCLEIC ACIDS RES, V29, P1185, DOI 10.1093/nar/29.5.1185; Reese MG, 1997, J COMPUT BIOL, V4, P311, DOI 10.1089/cmb.1997.4.311; Scholkopf B., 1999, ADV KERNEL METHODS; Shin KS, 2005, EXPERT SYST APPL, V28, P127, DOI 10.1016/j.eswa.2004.08.009; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Sonnenburg S, 2002, LECT NOTES COMPUT SC, V2415, P329; STOCKWELL DRB, 1993, EXPERT SYST APPL, V6, P137, DOI 10.1016/0957-4174(93)90004-P; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V., 1995, NATURE STAT LEARNING; Wang HC, 2005, EXPERT SYST APPL, V28, P537, DOI 10.1016/j.eswa.2004.12.015; WEBER R, 2001, P INT C MATH ENG TEC; Witten I.H., 2000, DATA MINING PRACTICA; Zhang LR, 2003, NUCLEIC ACIDS RES, V31, P6214, DOI 10.1093/nar/gkg805; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	33	7	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	JAN	2006	30	1					73	81		10.1016/j.eswa.2005.09.052		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	991FT	WOS:000233798400010	
S	Zhao, WQ; Zhu, YL		Wang, G; Peters, JF; Skowron, YY; Yao, YY		Zhao, Wenqing; Zhu, Yongli			Classifying email using variable precision rough set approach	ROUGH SETS AND KNOWLEDGE TECHNOLOGY, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	1st International Conference on Rough Sets and Knowledge Technology (RSKT 2006)	JUL 24-26, 2006	Chongqing, PEOPLES R CHINA	Int Rough Set Soc, Rough Set & Soft Computat Soc, Chinese Assoc Artificial Intelligence, Natl Nat Sci Fdn China, Chongqing Univ Posts & Telecommun, Chongqing Inst Technol, Chongqing Jiaotong Univ, Chongqing Educ Commiss, Chongqing Sci & Technol Commiss, Chongqing Informat Ind Bur, Chongqing Assoc Sci & Tecjmp;		spam; classification; junk mail; rough set; information filtering		Emails have brought us great convenience in our daily work and life. However, Unsolicited messages or spam, flood our email boxes, viruses, worms, and denial-of service attacks that cripple computer networks may secret in spam. which result in bandwidth, time and money wasting. To this end, this paper presents a novel schema to do classification for emails by using Variable Precision Rough Set Approach. By comparing with popular classification methods like Naive Bayes classification, our anti-Spam filter model is effectiveness.	N China Elect Power Univ, Sch Comp Sci & Technol, Baoding 017003, Peoples R China	Zhao, WQ (reprint author), N China Elect Power Univ, Sch Comp Sci & Technol, Baoding 017003, Peoples R China.	wq-zhao@ncepu.edu.cn; zy12056@ncepu.edu.cn					Clack C., 1997, Proceedings of the First International Conference on Autonomous Agents, DOI 10.1145/267658.267716; Cohen W. W., 1996, P AAAI SPRING S MACH, P18; PANTEL P, 1998, LEARNING TEXT CATEGO, P95; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Sahami M, 1998, LEARNING TEXT CATEGO; Skowron A, 1999, LECT NOTES ARTIF INT, V1704, P107; Spertus E., 1997, P INN APPL ART INT I, P1058; WRBLEWSKI J, 1995, P 2 ANN JOINT C INF, P186; ZHANG L, 2003, P 20 INT C COMP PROC, P446; Ziarko W., 1993, Foundations of Computing and Decision Sciences, V18	10	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-36297-5	LECT NOTES ARTIF INT			2006	4062						766	771				6	Computer Science, Artificial Intelligence	Computer Science	BEV60	WOS:000239623500111	
J	Kabaila, P				Kabaila, P			On the coverage probability of confidence intervals in regression after variable selection	AUSTRALIAN & NEW ZEALAND JOURNAL OF STATISTICS			English	Article						adjusted R-2-statistic; AIC; backward elimination; 'best subset' regression; BIC; coverage probability; forward selection; Mallows' criterion	MODEL SELECTION; INFERENCE	This paper considers a linear regression model with regression parameter vector beta. The parameter of interest is theta = alpha(inverted perpendicular)beta where alpha is specified. When, as a first step, a data-based variable selection ( e. g. minimum Akaike information criterion) is used to select a model, it is common statistical practice to then carry out inference about., using the same data, based on the ( false) assumption that the selected model had been provided a priori. The paper considers a confidence interval for. with nominal coverage 1 - alpha constructed on this ( false) assumption, and calls this the naive 1 - alpha confidence interval. The minimum coverage probability of this confidence interval can be calculated for simple variable selection procedures involving only a single variable. However, the kinds of variable selection procedures used in practice are typically much more complicated. For the real-life data presented in this paper, there are 20 variables each of which is to be either included or not, leading to 220 different models. The coverage probability at any given value of the parameters provides an upper bound on the minimum coverage probability of the naive confidence interval. This paper derives a new Monte Carlo simulation estimator of the coverage probability, which uses conditioning for variance reduction. For these real-life data, the gain in efficiency of this Monte Carlo simulation due to conditioning ranged from 2 to 6. The paper also presents a simple one-dimensional search strategy for parameter values at which the coverage probability is relatively small. For these real-life data, this search leads to parameter values for which the coverage probability of the naive 0.95 confidence interval is 0.79 for variable selection using the Akaike information criterion and 0.70 for variable selection using Bayes information criterion, showing that these confidence intervals are completely inadequate.			P.Kabaila@latrobe.edu.au					BIONDINI R, 1977, J APPL METEOROL, V16, P585, DOI 10.1175/1520-0450(1977)016<0585:EPFNAS>2.0.CO;2; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; Graybill F., 1976, THEORY APPL LINEAR M; HURVICH CM, 1990, AM STAT, V44, P214, DOI 10.2307/2685338; KABAILA P, 1995, ECONOMET THEOR, V11, P537; Kabaila P, 1998, ECONOMET THEOR, V14, P463; Kabaila P, 2005, COMMUN STAT-THEOR M, V34, P291, DOI 10.1081/STA-200047462; KABAILA P, IN PRESS J AM STAT A; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Miller A. J., 2002, SUBSET SELECTION REG; POTSCHER BM, 1991, ECONOMET THEOR, V7, P163; The R Development Core Team, 2003, LANG ENV STAT COMP	12	7	7	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	1369-1473			AUST NZ J STAT	Aust. N. Z. J. Stat.	DEC	2005	47	4					549	562		10.1111/j.1467-842X.2005.00416.x		14	Statistics & Probability	Mathematics	987EW	WOS:000233502200013	
S	Cerquides, J; de Mantaras, RL		Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Cerquides, J; de Mantaras, RL			Robust Bayesian linear classifier ensembles	MACHINE LEARNING: ECML 2005, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD			LOGISTIC-REGRESSION; NETWORK CLASSIFIERS; NAIVE BAYES	Ensemble classifiers combine the classification results of several classifiers. Simple ensemble methods such as uniform averaging over a set of models usually provide an improvement over selecting the single best model. Usually probabilistic classifiers restrict the set of possible models that can be learnt in order to lower computational complexity costs. In these restricted spaces, where incorrect modeling assumptions are possibly made, uniform averaging sometimes performs even better than bayesian model averaging. Linear mixtures over sets of models provide an space that includes uniform averaging as a particular case. We develop two algorithms for learning maximum a posteriori weights for linear mixtures, based on expectation maximization and on constrained optimizition. We provide a nontrivial example of the utility of these two algorithms by applying them for one dependence estimators. We develop the conjugate distribution for one dependence estimators and empirically show that uniform averaging is clearly superior to Bayesian model averaging for this family of models, After that we empirically show that the maximum a posteriori linear mixture weights improve accuracy significantly over uniform aggregation.	Univ Barcelona, Dept Matemat Aplicada & Anal, Barcelona, Spain; CSIC, Spanish Council Sci Res, Artificial Intelligence Res Inst, IIIA, Madrid, Spain	Cerquides, J (reprint author), Univ Barcelona, Dept Matemat Aplicada & Anal, Barcelona, Spain.	cerquide@maia.ub.es; mantaras@iiia.csic.es					Bouchard G., 2004, IASC INT S COMP STAT, P721; Cerquides J, 2005, MACH LEARN, V59, P323, DOI 10.1007/s10994-005-0470-7; Clarke B., 2003, J MACHINE LEARNING R, P683; Dash D, 2004, J MACH LEARN RES, V5, P1177; DAWES RM, 1979, AM PSYCHOL, V34, P571, DOI 10.1037//0003-066X.34.7.571; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Domingos P., 2000, P 17 INT C MACH LEAR, P223; Fawcett T., 2003, HPL20034; FRIEDMAN J, 2004, WORKSH DAT MIN METH; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GENEST C, 1986, STAT SCI, V1, P114, DOI 10.1214/ss/1177013825; GENEST C, 1990, J FORECASTING, V9, P53, DOI 10.1002/for.3980090106; Ghahramani Z., 2003, BAYESIAN CLASSIFIER; GILL P, 1989, HDB OPERATIONS RES M; Greiner R, 2005, MACH LEARN, V59, P297, DOI 10.1007/s10994-005-0469-0; GROSSMAN D, 2004, ICML; GRUENWALD P, 2002, 7 VAL INT M BAY STAT; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Hoeting J.A., 1999, STAT SCI, V15, P193; Hoeting JA, 1999, STAT SCI, V14, P382; IDE J, 2003, GENERATION RANDOM BA; KEOGH EJ, 1999, UNCERTAINTY 99; McLachlan G., 1997, EM ALGORITHM EXTENSI; McLachlan G., 1988, MIXTURE MODELS; Meila M, 2001, J MACH LEARN RES, V1, P1, DOI 10.1162/153244301753344605; Meila-Predoviciu M, 1999, THESIS MIT; MINKA TP, 2002, BAYESIAN MODEL AVERA; Ng AY, 2002, ADV NEUR IN, V14, P841; PEDREGAL P, 2004, TEXTS APPL MATH, V46; Raina R., 2004, ADV NEURAL INFORM PR, V16; Roos T, 2005, MACH LEARN, V59, P267; Sahami M., 1996, 2 INT C KNOWL DISC D, P335; Thiesson B., 1998, P 14 C UNC ART INT, P504; THIESSON B, 1997, LEARNING MIXTURES BA; Ting KM, 1999, J ARTIF INTELL RES, V10, P271; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Witten I.H., 2000, DATA MINING PRACTICA; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	38	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29243-8	LECT NOTES ARTIF INT			2005	3720						72	83				12	Computer Science, Artificial Intelligence	Computer Science	BDF41	WOS:000233235200012	
S	Sordo, M; Zeng, Q		Oliveira, JL; Maojo, V; MartinSanchez, F; Pereira, AS		Sordo, M; Zeng, Q			On sample size and classification accuracy: A performance comparison	BIOLOGICAL AND MEDICAL DATA ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Symposium on Biological and Medical Data Analysis	NOV 10-11, 2005	Aveiro, PORTUGAL					We investigate the dependency between sample size and classification accuracy of three classification techniques: Naive Bayes, Support Vector Machines and Decision Trees over a set of similar to 8500 text excerpts extracted automatically from narrative reports from the Brigham & Women's Hospital, Boston, USA. Each excerpt refers to the smoking status of a patient as: current, past, never a smoker or, denies smoking. Our empirical results, consistent with [1], confirm that size of the training set and the classification rate are indeed correlated. Even though these algorithms perform reasonably well with small datasets, as the number of cases increases, both SMV and Decision Trees show a substantial improvement in performance, suggesting a more consistent learning process. Unlike the majority of evaluations, ours were carried out specifically in a medical domain where the limited amount of data is a common occurrence [13][14]. This study is part of the 12B2 project, Core 2(1).	Harvard Univ, Sch Med, Decis Syst Grp, Boston, MA 02115 USA	Sordo, M (reprint author), Harvard Univ, Sch Med, Decis Syst Grp, Boston, MA 02115 USA.	msordo@dsg.harvard.edu; qzeng@dsg.harvard.edu					Chapman W W, 1999, Proc AMIA Symp, P216; Cohen W.W., 1996, P 19 ANN INT ACM SIG, P307, DOI 10.1145/243199.243278; Dumais S., 1998, P 7 INT C INF KNOWL; GHANI R, 2001, WORKSH TEXT MIN 1 IE; GILLES G, SEMISUPERVISED LEARN; Joachims T., 1998, P 10 EUR C MACH LEAR; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; Manning C.D., 1999, FDN STAT NATURAL LAN; MCCALLUM A, 1998, AAAI 98 WORKSH LEARN, P1286; McCallum A, 1998, AAAI 98 WORKSH LEARN; MCKAY M, LAUR991357; Ng A., 2002, NIPS, V14; Raudys S. J., 1991, IEEE T PATTERN ANAL, V13; Vapnik V., 1995, NATURE STAT LEARNING; WIENER E, 1995, P 4 ANN S DOC AN INF; Wilcox A, 1999, Proc AMIA Symp, P455; Yang Y., 1994, P 17 ANN INT ACM SIG, P13	17	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29674-3	LECT NOTES COMPUT SC			2005	3745						193	201				9	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Medical Informatics	Biochemistry & Molecular Biology; Computer Science; Medical Informatics	BDM89	WOS:000234378000020	
S	Yang, Y; Korb, K; Ting, KM; Webb, GI		Zhang, S; Jarvis, R		Yang, Y; Korb, K; Ting, KM; Webb, GI			Ensemble selection for SuperParent-One-Dependence Estimators	AI 2005: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	18th Australian Joint Conference on Artificial Intelligence	DEC 05-09, 2005	Sydney, AUSTRALIA	AFOSR, Asian Off Aerosp Res & Dev	Univ Technol		MODEL	SuperParent-One-Dependence Estimators (SPODEs) loosen Naive-Bayes' attribute independence assumption by allowing each attribute to depend on a common single attribute (superparent) in addition to the class. An ensemble of SPODEs is able to achieve high classification accuracy with modest computational cost. This paper investigates how to select SPODEs for ensembling. Various popular model selection strategies are presented. Their learning efficacy and efficiency are theoretically analyzed and empirically verified. Accordingly, guidelines are investigated for choosing between selection criteria in differing contexts.	Monash Univ, Sch Comp Sci & Software Engn, Fac Informat Technol, Clayton, Vic 3800, Australia	Yang, Y (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Fac Informat Technol, Clayton, Vic 3800, Australia.	Ying.Yang@Infotech.Monash.edu.au; Kevin.Korb@Infotech.Monash.edu.au; Kaiming.Ting@Infotech.Monash.edu.au; Geoff.Webb@Infotech.Monash.edu.au	Webb, Geoffrey/A-1347-2008				AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BLAKE C, 2004, UCI REPOSITORY MACHI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Korb K. B., 2004, BAYESIAN ARTIFICIAL; Sahami M., 1996, P 2 INT C KNOWL DISC, P334; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SUZUKI J, 1996, P 13 INT C MACH LEAR, P463; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6	9	7	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30462-2	LECT NOTES ARTIF INT			2005	3809						102	112				11	Computer Science, Artificial Intelligence	Computer Science	BDW41	WOS:000235836100013	
B	Yang, ZQ; Zhong, S; Wright, RN		Kargupta, H; Srivastava, J; Kamath, C; Goodman, A		Yang, Zhiqiang; Zhong, Sheng; Wright, Rebecca N.			Privacy-Preserving Classification of Customer Data without Loss of Accuracy	PROCEEDINGS OF THE FIFTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING	SIAM Proceedings Series		English	Proceedings Paper	5th SIAM International Conference on Data Mining	APR 21-23, 2005	Newport Beach, CA	SIAM, Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Amer Stat Assoc				Privacy has become an increasingly important issue in data mining. In this paper, we consider a scenario in which a data miner surveys a large number of customers to learn classification rules on their data, while the sensitive attributes of these customers need to be protected. Solutions have been proposed to address this problem using randomization techniques. Such solutions exhibit a tradeoff of accuracy and privacy: the more each customer's private information is protected, the less accurate result the miner obtains; conversely, the more accurate the result, the less privacy for the customers. In this paper, we propose a simple cryptographic approach that is efficient even in a many-customer setting, provides strong privacy for each customer, and does not lose any accuracy as the cost of privacy. Our key technical contribution is a privacy-preserving method that allows a data miner to compute frequencies of values or tuples of values in the customers' data, without revealing the privacy-sensitive part of the data. Unlike general-purpose cryptographic protocols, this method requires no interaction between customers, and each customer only needs to send a single flow of communication to the data miner. However, we are still able to ensure that nothing about the sensitive data beyond the desired frequencies is revealed to the data miner. To illustrate the power of our approach, we use our frequency mining computation to obtain a privacy-preserving naive Bayes classifier learning algorithm. Initial experimental results demonstrate the practical efficiency of our solution. We also suggest some other applications of privacy-preserving frequency mining.	[Yang, Zhiqiang; Zhong, Sheng; Wright, Rebecca N.] Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA	Yang, ZQ (reprint author), Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA.						ADAM NR, 1989, COMPUT SURV, V21, P515; Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Agrawal R., 2000, SIGMOD C, P439; Ambainis A, 2004, LECT NOTES COMPUT SC, V2947, P425; Benaloh J., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195407; Ben-Or M., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/62212.62213; Blake C. L., 1998, UCI REPOSITORY MACHI; CRANOR L, 1999, COMM ACM, V42; Dinue I., 2003, P 22 ACM SIGACT SIGM, P202, DOI DOI 10.1145/773153.773173; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Du W., 2003, P 9 ACM SIGKDD INT C, P505; DWORK C, 2004, LECT NOTES COMPUTER, V3152; Evfimievski A., 2002, P 8 ACM SIGKDD INT C, P217; Evfimievski A. V., 2003, P 22 ACM SIGMOD SIGA, P211, DOI 10.1145/773153.773174; Goldreich O., 1987, P 19 ANN ACM S THEOR, P218, DOI 10.1145/28395.28420; Goldreich O., 2004, FDN CRYPTOGRAPHY BAS; GOLDWASSER S, 1984, J COMPUT SYST SCI, V28, P270, DOI 10.1016/0022-0000(84)90070-9; HIRT M, 2000, LECT NOTES COMPUTER, V1807; KANKANTARCIOGLU M, 2003, IEEE WORKSH PRIV PRE; KANTARCIOGLU M, 2002, IEEE ICDM WORKSH PRI, P37; Kantarcioglu M., 2002, ACM SIGMOD WORKSH RE, P24; KARGUPTA H, 2003, 3 IEEE INT C DAT MIN; Lindell Y, 2002, J CRYPTOL, V15, P177, DOI 10.1007/s00145-001-0019-2; Mitchell T.M., 1997, MACHINE LEARNING; Rizvi S.J., 2002, P 28 VLDB C; Schneier B., 1996, APPL CRYPTOGRAPHY; SUBRAMANIAM H, 2004, P VLDB WORKSH SEC DA, P55; Tsiounis Y., 1998, LNCS, V1431, P117; Vaidya J., 2002, P 8 ACM SIGKDD INT C, P639; Vaidya J., 2003, P 9 ACM SIGKDD INT C, P206; Vaidya J., 2004, 2004 SIAM INT C DAT; WARNER SL, 1965, J AM STAT ASSOC, V60, P63, DOI 10.2307/2283137; WESTIN A, 1999, WHAT NET USERS THINK; Wright R. N., 2004, P 10 ACM SIGKDD INT, P713, DOI 10.1145/1014052.1014145; Yao A. C., 1986, FOCS, P162	35	7	7	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			978-0-89871-593-4	SIAM PROC S			2005							92	102				11	Computer Science, Artificial Intelligence	Computer Science	BUJ08	WOS:000289491000009	
J	Kim, KJ; Cho, SB				Kim, KJ; Cho, SB			Fuzzy integration of structure adaptive SOMs for web content mining	FUZZY SETS AND SYSTEMS			English	Article						user profile; web content mining; structure adaptive self-organizing map; fuzzy integral; Syskill & Webert	MULTIPLE NEURAL NETWORKS; ROBUST CLASSIFICATION; CLASSIFIERS; SELECTION; MAP	Since exponentially growing web contains giga-bytes of web documents, users are faced with difficulty to find an appropriate web site. Using profile, information retrieval system can personalize browsing of the web by recommending suitable web sites. User's evaluation on web content cart be used to predict users' preference on web sites and construct profiles automatically. User profile represents different aspects of user's characteristics, thereby we need an ensemble of classifiers that estimate user's preference using web content labeled by user as "like" or "dislike." Fuzzy integral is a combination scheme that uses subjectively defined relevance of classifiers and structure adaptive self-organizing map (SASONI) is a variant of SOM that is useful to pattern recognition and visualization. In this paper, fuzzy integral-based ensemble of SASOMs trained independently is used to estimate user profile and tested on UCI Syskill & Webert data. Experimental results show that the proposed method can perform better than not only previous naive Bayes classifier but also majority voting of SASOMs. (C) 2004 Elsevier B.V. All rights reserved.	Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea	Cho, SB (reprint author), Yonsei Univ, Dept Comp Sci, 134 Shinchon Dong, Seoul 120749, South Korea.	sbcho@csai.yonsei.ac.kr					Bauer HU, 1997, IEEE T NEURAL NETWOR, V8, P218, DOI 10.1109/72.557659; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Chakrabarti S., 2002, MINING WEB ANAL HYPE; CHO SB, 1997, NEURAL COMPUT, V9, P1343; Cho SB, 1997, IEEE T NEURAL NETWOR, V8, P43; CHO SB, 1995, IEEE T NEURAL NETWOR, V6, P497; CHO SB, 1995, IEEE T SYST MAN CYB, V25, P380; Cooley R, 1997, PROC INT C TOOLS ART, P558, DOI 10.1109/TAI.1997.632303; Kim S, 2002, IIE TRANS, V34, P167, DOI 10.1023/A:1011995914535; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kosala R., 2000, SIGKDD EXPLORATIONS, V2, P1; Kumar AS, 1997, IEEE T GEOSCI REMOTE, V35, P787, DOI 10.1109/36.582004; Kumar R, 1999, COMPUT NETW, V31, P1481, DOI 10.1016/S1389-1286(99)00040-7; Kwon OW, 2003, INFORM PROCESS MANAG, V39, P25, DOI 10.1016/S0306-4573(02)00022-5; LESZCZYNSKI K, 1985, FUZZY SET SYST, V15, P147, DOI 10.1016/0165-0114(85)90043-0; Lewis D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; Li WS, 2002, J VISUAL LANG COMPUT, V13, P3, DOI 10.1006/jvlc.2001.0225; Madria S.K., 1999, P 1 INT C DAT WAR KN, P303; Mirhosseini AR, 1998, COMPUT VIS IMAGE UND, V71, P213, DOI 10.1006/cviu.1998.0710; Mitra S, 2002, IEEE T NEURAL NETWOR, V13, P3, DOI 10.1109/72.977258; Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0; Pal NR, 1999, FUZZY SET SYST, V103, P201, DOI 10.1016/S0165-0114(98)00222-X; Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pham T. D., 2002, Proceedings 2002 IEEE International Conference on Artificial Intelligence Systems (ICAIS 2002), DOI 10.1109/ICAIS.2002.1048051; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RIJSBERGEN CJ, 1981, IP M, V17, P77; SHO SB, 2000, INFORM SCI, V123, P103; Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12; Suganthan PN, 2001, PATTERN RECOGN, V34, P2173, DOI 10.1016/S0031-3203(00)00147-3; SUGATHAN PN, 1998, P 5 INT C CONTR AUT, P924; Sugeno M., 1977, FUZZY AUTOMATA DECIS, P89; Verikas A, 1999, PATTERN RECOGN LETT, V20, P429, DOI 10.1016/S0167-8655(99)00012-4; Vesanto J., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00013-X; Xiao YQ, 2001, DATA KNOWL ENG, V39, P191, DOI 10.1016/S0169-023X(01)00039-8; YAGER RR, 1993, IEEE T SYST MAN CYB, V23, P467, DOI 10.1109/21.229459	37	7	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114			FUZZY SET SYST	Fuzzy Sets Syst.	NOV 16	2004	148	1					43	60		10.1016/j.fss.2004.03.005		18	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	864BF	WOS:000224607100004	
J	Kim, HJ; Lee, SG				Kim, HJ; Lee, SG			An intelligent information system for organizing online text documents	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article						document categorization; document clustering; fuzzy relations; hierarchical agglomerative clustering; information systems; naive Bayes; topic hierarchy	CLUSTERING ALGORITHMS; RETRIEVAL	This paper describes an intelligent information system for effectively managing huge amounts of online text documents (such as Web documents) in a hierarchical manner. The organizational capabilities of this system are able to evolve semi-automatically with minimal human input. The system starts with an initial taxonomy in which documents are automatically categorized, and then evolves so as to provide a good indexing service as the document collection grows or its usage changes. To this end, we propose a series of algorithms that utilize text-mining technologies such as document clustering, document categorization, and hierarchy reorganization. In particular, clustering and categorization algorithms have been intensively studied in order to provide evolving facilities for hierarchical structures and categorization criteria. Through experiments using the Reuters-21578 document collection, we evaluate the performance of the proposed clustering and categorization methods by comparing them to those of well-known conventional methods.	Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 130743, South Korea; Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 130743, South Korea	Kim, HJ (reprint author), Seoul Natl Univ, Dept Elect & Comp Engn, 90 Jeonnongdong, Seoul 130743, South Korea.	khj@uos.ac.kr					Aggarwal C., 1999, P 5 ACM SIGKDD INT C, P352, DOI 10.1145/312129.312279; AGGRAWAL R, 2000, P 7 INT C EXT DAT TE, P365; Argamon-Engelson S, 1999, J ARTIF INTELL RES, V11, P335; Bensaid AM, 1996, PATTERN RECOGN, V29, P859, DOI 10.1016/0031-3203(95)00120-4; BURGIN R, 1995, J AM SOC INFORM SCI, V46, P562, DOI 10.1002/(SICI)1097-4571(199509)46:8<562::AID-ASI2>3.0.CO;2-B; Cover TM, 1991, ELEMENTS INFORMATION, P12; Cuba S., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; DEMIRIZ A, 2000, P ADV NEUR INF PROC, P368; El-Hamdouchi A, 1986, P ACM C RES DEV INF, P149, DOI 10.1145/253168.253200; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1007/BF00114265; Fox C., 1992, INFORMATION RETRIEVA, P102; FRIEDMAN JH, 1997, MACH LEARN, V28, P133; GROSSMAN DA, 1998, INFORMATION RETRIEVA, P11; HAN E, 1991, P 5 PAC AS C KNOWL D, P53; HARRIES M, 1995, P 8 AUSTR JOINT C AR, P91; *INKT, 2001, INKT DIR ENG; JOACHIMS T, 1997, LS8 U DORTM; Kaufman L., 1990, FINDING GROUPS DATA; KIM H, 2000, P 9 INT C INF KNOWL, P30, DOI 10.1145/354756.354777; Klinkenberg R, 2000, P 17 INT C MACH LEAR, P487; Klinkenberg R., 1998, P INT C MACH LEARN M, P33; KLIR GJ, 1995, FUZZY SETS FUZZY LOG, P119; LABZOUR T, 1998, P INT C FUZZ SYST, P1383; Lewis D., 1994, P 17 ANN INT ACM SIG, P3; Lewis D. D., 1997, REUTERS 21578 TEXT C; LEWIS K, 1992, CAREER DEV EXCEPTION, V15, P37; Lindenbaum M., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Mitchell T., 1997, MACH LEARN, P154; OGAWA Y, 1991, FUZZY SET SYST, V39, P163, DOI 10.1016/0165-0114(91)90210-H; ROSCHEISEN M, 1998, LECT NOTES COMPUTER, V1392, P213; Sahami M., 1998, P 3 ACM INT C DIG LI, P200, DOI 10.1145/276675.276697; Sanderson M., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312679; Schlimmer J. C., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Scott Sam, 1999, P 16 INT C MACH LEAR, P379; Seidl T, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P506; *SEM, 2001, SEM TAX; Talavera L, 1999, LECT NOTES COMPUT SC, V1642, P211; Tresch Markus, 1995, P 21 INT C VER LARG, P263; VAITHYANATHAN S, 1999, P 16 INT C MACH LEAR, P433; VOORHEES EM, 1986, INFORM PROCESS MANAG, V22, P465, DOI 10.1016/0306-4573(86)90097-X; *WEBB, 1999, W3C LIBWWW ROB; WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1; Yang Y., 1997, P 14 INT C MACH LEAR, P412	43	7	7	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	MAR	2004	6	2					125	149		10.1007/s10115-003-0103-z		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	885LT	WOS:000226158800001	
S	Farhangfar, A; Kurgan, L; Pedrycz, W		Priddy, KL		Farhangfar, A; Kurgan, L; Pedrycz, W			Experimental analysis of methods for imputation of missing values in databases	INTELLIGENT COMPUTING: THEORY AND APPLICATIONS II	Proceedings of SPIE		English	Proceedings Paper	Conference on Intelligent Computing - Theory and Applications II	APR 12-13, 2004	Orlando, FL	SPIE		incompleteness; missing values; imputation; preprocessing; machine learning		A very important issue faced by researchers and practitioners who use industrial and research databases is incompleteness of data, usually in terms of missing or erroneous values. While some of data analysis algorithms can work with incomplete data, a large portion of them require complete data. Therefore, different strategies, such as deletion of incomplete examples, and imputation (filling) of missing values through variety of statistical and machine learning (ML) procedures, are developed to preprocess the incomplete data. This study concentrates on performing experimental analysis of several algorithms for imputation of missing values, which range from simple statistical algorithms like mean and hot deck imputation to imputation algorithms that work based on application of inductive ML algorithms. Three major families of ML algorithms, such as probabilistic algorithms (e.g. Naive Bayes), decision tree algorithms (e.g. C4.5), and decision rule algorithms (e.g. CLIP4), are used to implement the ML based imputation algorithms. The analysis is carried out using a comprehensive range of databases, for which missing values were introduced randomly. The goal of this paper is to provide general guidelines on selection of suitable data imputation algorithms based on characteristics of the data. The guidelines are developed by performing a comprehensive experimental comparison of performance of different data imputation algorithms.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada	Farhangfar, A (reprint author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.	farhang@ece.ualberta.ca; lkurgan@ece.ualberta.ca; pedrycz@ee.ualberta.ca	Kurgan, Lukasz/B-5721-2009	Kurgan, Lukasz/0000-0002-7749-0314			Blake C. L., 1998, UCI REPOSITORY MACHI; BRAZDIL P, 1994, MACHINE LEARNING ECM; Cios K., 1998, DATA MINING METHODS; CIOS KJ, 2001, NEW LEARNING PARADIG, P276; CIOS KJ, 2004, IN PRESS INFORMATION; Dempster A.P., 1978, J ROY STAT SOC, V82, P528; DUDA RO, 1977, PATTERN CLASSIFICATI; KURGAN LA, 2004, IN PRESS NOVEL APPL; Lakshminarayan K, 1999, APPL INTELL, V11, P259, DOI 10.1023/A:1008334909089; Little RJA, 1987, STAT ANAL MISSING DA; Michie D., 1994, MACHINE LEARNING NEU; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rubin D, 1987, MULTIPLE IMPUTATIONS; SHANNON CE, 1948, AT&T TECH J, V27, P379; Vach W, 1994, CONTR STAT, P345	16	7	7	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5344-7	PROC SPIE			2004	5421						172	182		10.1117/12.542509		11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAI02	WOS:000222348000018	
S	Kelly, D; Tangney, B		Lester, JC; Vicari, RM; Paraguacu, F		Kelly, D; Tangney, B			Predicting learning characteristics in a multiple intelligence based tutoring system	INTELLIGENT TUTORING SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Intelligent Tutoring Systems	AUG 30-SEP 03, 2004	Maceio, BRAZIL	CNPq, CAPES, FAPEAL, FINEP, FAL, PETROBRAS, AAAI, AI Educ Soc				Research on learning has shown that students learn differently and that they process knowledge in various ways. EDUCE is an Intelligent Tutoring System for which a set of learning resources has been developed using the principles of Multiple Intelligences. It can dynamically identify user learning characteristics and adaptively provide a customised learning material tailored to the learner. This paper introduces the predictive engine used within EDUCE. It describes the input representation model and the learning mechanism employed. The input representation model consists of input features that describe how different resources were used and inferred from fine-grained information collected during student computer interactions. The predictive engine employs the Naive Bayes classifier and operates online using no prior information. Using data from a previous experimental study, a comparison was made between the performance of the predictive engine and the actual behaviour of a group of students using the learning material without any guidance from EDUCE. Results indicate correlation between student's behaviour and the predictions made by EDUCE. These results suggest that the concept of learning characteristics can be modelled using a learning scheme with appropriately chosen attributes.	Natl Univ Ireland Univ Coll Dublin, Dublin 4, Ireland; Univ Dublin Trinity Coll, Dublin 2, Ireland	Kelly, D (reprint author), Natl Univ Ireland Univ Coll Dublin, Dublin 4, Ireland.	dkelly@ncirl.ie; tangney@tcd.ie					BRUSILOVSKY P, 2001, ADAPATIVE HYPERMEDIA, V11; CARVER C, 1996, 1996 ED MEDIA C ED M; CASTILLO G, 2003, P US MOD C JOHNST PA; Duda R., 1973, PATTERN CLASSIFICATI; Gardner H., 1983, FRAMES MIND THEORY M; GILBERT JE, 1999, P WEBN 99 WORLD C WW; KELLY D, 2002, P 6 INT ITSS ITS2002; KELLY D, 2003, P 11 INT C ART INT E; KELLY D, 2003, P EDMED 03 WORLD C E; MILNE S, 1997, ADAPTING LEARNER ATT, V17; Rasmussen K, 1998, J MULTIMEDIA HYPERME, V7, P1998; RIDING R, 1997, COGNITIVE STYLES LEA; Riding R. J., 1991, COGNITIVE STYLES ANA; SPECHT M, 1998, ACE ADAPTIVE COURSE; STERN M, 2000, P 1 ADP HYP C AH2000	15	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22948-5	LECT NOTES COMPUT SC			2004	3220						678	688				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAV60	WOS:000223806300064	
S	Kibriya, AM; Frank, E; Pfahringer, B; Holmes, G		Webb, GI; Yu, X		Kibriya, AM; Frank, E; Pfahringer, B; Holmes, G			Multinomial naive Bayes for text categorization revisited	AI 2004: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	17th Annual Australian Conference on Artificial Intelligence	DEC 04-06, 2004	Cairns, AUSTRALIA		Cent Queensland Univ			This paper presents empirical results for several versions of the multinomial naive Bayes classifier on four text categorization problems, and a way of improving it using locally weighted learning. More specifically, it compares standard multinomial naive Bayes to the recently proposed transformed weight-normalized complement naive Bayes classifier (TWCNB) [1], and shows that some of the modifications included in TWCNB may not be necessary to achieve optimum performance on some datasets. However, it does show that TFIDF conversion and document length normalization are important. It also shows that support vector machines can, in fact, sometimes very significantly outperform both methods. Finally, it shows how the performance of multinomial naive Bayes can be improved using locally weighted learning. However, the overall conclusion of our paper is that support vector machines are still the method of choice if the aim is to maximize accuracy.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand	Kibriya, AM (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.	amk14@cs.waikato.ac.nz; eibe@cs.waikato.ac.nz; bernhard@cs.waikato.ac.nz; geoff@cs.waikato.ac.nz	Frank, Eibe/A-1434-2008				Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Eyheramendy S., 2003, 9 INT WORKSH ART INT, P3; FRANK E, 2003, P C UNC ART INT; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; MCCALLUM A, 1998, AM ASS ARTIFICAL INT; Platt J. C., 1998, ADV KERNEL METHODS S; Platt J.C., 1999, ADV LARGE MARGIN CLA; Rennie J, 2003, P 20 INT C MACH LEAR, P616; RENNIE J, 2004, COMMUNICATION; WITTEN I, 1999, PRACTICAL MACH LEARN; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	13	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-24059-4	LECT NOTES ARTIF INT			2004	3339						488	499				12	Computer Science, Artificial Intelligence	Computer Science	BBM32	WOS:000226133600043	
S	Kim, S; Park, S; Kim, M		Enser, P; Kompatsiaris, Y; OConnor, NE; Smeaton, AF; Smeulders, AWM		Kim, S; Park, S; Kim, M			Image classification into object/non-object classes	IMAGE AND VIDEO RETRIEVAL, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	3rd International Conference on Image and Video Retrieval (CIVR 2004)	JUL 21-23, 2004	Dublin, IRELAND	Dublin City Univ, Ctr Digital Video Proc, NDP, Sfi, DCU, IEE, ACM SIGIR, IPRCS, HEMA, BCS				We propose a method that automatically classifies the images into the object and non-object images. An object image is an image with object(s). An object in an image is defined as a set of regions located near the center of the image, which has significant color distribution compared with its surrounding (or background) region. We define three measures for the classification based on the characteristics of an object. The center significance is calculated from the difference in color distribution between the center area and its surrounding region. Second measure is the variance of significantly correlated colors in the image plane. Significantly correlated colors are first defined as the colors of two adjacent pixels that appear more frequently around center of an image rather than at the background of the image. The last one is the edge strength at the boundary of the region that is estimated as an object. To classify the images we combine each measure by training the neural network. A test with 900 images shows a classification accuracy of 84.2%. We also compare our result with the performance of several other classifiers, Naive Bayes, Decision Table, and Decision Tree.	Kumoh Natl Inst Technol, Sch Comp Engn, Gumi, South Korea; Pusan Natl Univ, Dept Comp Engn, Pusan, South Korea	Kim, S (reprint author), Kumoh Natl Inst Technol, Sch Comp Engn, Gumi, South Korea.	sykim@kumoh.ac.kr; sokkobi@pusan.ac.kr; mhkim@pusan.ac.kr					Breiman L., 1984, CLASSIFICATION REGRE; Good I, 1965, ESTIMATION PROBABILI; Huang J, 1997, PROC CVPR IEEE, P762; Kim S, 2003, LECT NOTES COMPUT SC, V2728, P39; KOHAVI R, 1995, LECT NOTES ARTIFICAL, V914; LIPPMANN RP, 1994, IEEE ASSP MAGAZINE, P4; Park SB, 2004, PATTERN RECOGN LETT, V25, P287, DOI 10.1016/j.patrec.2003.10.015; Serra Alvarez J. R., 1999, Pattern Recognition, V32; Szummer M., 1998, IEEE INT WORKSH CONT, P42; Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Witten I. H., 2000, DATA MINING	12	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22539-0	LECT NOTES COMPUT SC			2004	3115						393	400				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BAO68	WOS:000223080700043	
S	Butler, SM; Webb, GI; Lewis, RA		Gedeon, TD; Fung, LCC		Butler, SM; Webb, GI; Lewis, RA			A case study in feature invention for breast cancer diagnosis using X-ray scatter images	AI 2003: ADVANCES IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th Australian Conference on Artificial Intelligence	DEC 03-05, 2003	PERTH, AUSTRALIA	Natl Comm Artificial Intellignece & Expert Syst	UNIV WESTERN AUSTRALIA	knowledge discovery and data mining; applications	MAMMOGRAPHIC SENSITIVITY; WOMEN	X-ray mammography is the current clinical method for screening for breast cancer, and like any technique, has its limitations. Several groups have reported differences in the X-ray scattering patterns of normal and tumour tissue from the breast. This gives rise to the hope that X-ray scatter analysis techniques may lead to a more accurate and cost effective method of diagnosing beast cancer which lends itself to automation. This is a particularly challenging exercise due to the inherent complexity of the information content in X-ray scatter patterns from complex hetrogenous tissue samples. We use a simple naive Bayes classier as our classification system. High-level features are extracted from the low-level pixel data. This paper reports some preliminary results in the ongoing development of this classification method that can distinguish between the diffraction patterns of normal and cancerous tissue, with particular emphasis on the invention of features for classification.	Monash Univ, Sch Comp Sci & Software Engn, Clayton, Vic 3800, Australia; Monash Univ, Sch Phys & Mat Engn, Clayton, Vic 3800, Australia	Butler, SM (reprint author), Monash Univ, Sch Comp Sci & Software Engn, Bldg 26, Clayton, Vic 3800, Australia.		Webb, Geoffrey/A-1347-2008				Bjurstam N, 1997, CANCER, V80, P2091, DOI 10.1002/(SICI)1097-0142(19971201)80:11<2091::AID-CNCR8>3.0.CO;2-#; Coussens LM, 1996, CHEM BIOL, V3, P895, DOI 10.1016/S1074-5521(96)90178-7; Fernandez M, 2002, PHYS MED BIOL, V47, P577, DOI 10.1088/0031-9155/47/4/303; Kidane G, 1999, PHYS MED BIOL, V44, P1791, DOI 10.1088/0031-9155/44/7/316; Lewis RA, 2000, J SYNCHROTRON RADIAT, V7, P348, DOI 10.1107/S0909049500009973; Mushlin AI, 1998, AM J PREV MED, V14, P143, DOI 10.1016/S0749-3797(97)00019-6; NYSTROM L, 1993, LANCET, V341, P973, DOI 10.1016/0140-6736(93)91067-V; Rosenberg RD, 1998, RADIOLOGY, V209, P511; SIBBERING DM, 1995, BREAST, V4, P127, DOI 10.1016/0960-9776(95)90008-X; Witten I.H., 2000, DATA MINING PRACTICA; YANG Y, 2003, 2003131 MON U SCH CO	11	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20646-9	LECT NOTES ARTIF INT			2003	2903						677	685				9	Computer Science, Artificial Intelligence	Computer Science	BY08N	WOS:000187551700058	
S	Goncalves, T; Quaresma, P		Pires, FM; Abreu, S		Goncalves, T; Quaresma, P			A preliminary approach to the multilabel classification problem of Portuguese juridical documents	PROGRESS IN ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	11th Portuguese Conference on Artificial Intelligence	DEC 04-07, 2003	BEJA, PORTUGAL					Portuguese juridical documents from Supreme Courts and the Attorney General's Office are manually classified by juridical experts into a set of classes belonging to a taxonomy of concepts. In this paper, a preliminary approach to develop techniques to automatically classify these juridical documents, is proposed. As basic strategy, the integration of natural language processing techniques with machine learning ones is used. Support Vector Machines (SVM) are used as learning algorithm and the obtained results are presented and compared with other approaches, such as C4.5 and Naive Bayes.	Univ Evora, Dept Informat, P-7000 Evora, Portugal	Goncalves, T (reprint author), Univ Evora, Dept Informat, P-7000 Evora, Portugal.		Goncalves, Teresa/B-4308-2013	Goncalves, Teresa/0000-0002-1323-0249			CANOEDDA N, 2003, J MACHINE LEARNING R, V3, P1059; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cristianini Nello, 2000, SUPPORT VECTOR MACHI; Joachims T., 2002, LEARNING CLASSIFY TE; MCCALLUM A, 1998, LEARNING TEXT CATEGO; Quaresma P, 2003, LECT NOTES ARTIF INT, V2543, P51; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; SALTON G, 1983, INTRO MODERN INFORMA; Scholkopf B, 2002, LEARNING KERNELS; Vapnik V., 1995, NATURE STAT LEARNING; Vapnik VN, 1982, ESTIMATION DEPENDENC; Witten I.H., 1999, DATA MINING PRACTICA	12	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20589-6	LECT NOTES ARTIF INT			2003	2902						435	444				10	Computer Science, Artificial Intelligence	Computer Science	BY08M	WOS:000187551600042	
S	Lazkano, E; Sierra, B		Pires, FM; Abreu, S		Lazkano, E; Sierra, B			BAYES-NEAREST: A new hybrid classifier combining Bayesian network and distance based algorithms	PROGRESS IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	11th Portuguese Conference on Artificial Intelligence	DEC 04-07, 2003	BEJA, PORTUGAL				FEATURE SUBSET-SELECTION; INTENSIVE-CARE-UNIT; COMBINATION; KNOWLEDGE	This paper presents a new hybrid classifier that combines the probability based Bayesian Network paradigm with the Nearest Neighbor distance based algorithm. The Bayesian Network structure is obtained from the data by using the K2 structural learning algorithm. The Nearest Neighbor algorithm is used in combination with the Bayesian Network in the deduction phase. For those data bases in which some variables are continuous valued, automatic discretizations of the data are performed. We show the performance of the new proposed approach compared with the Bayesian Network paradigm and with the well known Naive Bayes classifier in some standard databases; the results obtained by the new algorithm are better or equal according to the Wilcoxon statistical test.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, E-20080 San Sebastian, Spain	Lazkano, E (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, POB 649, E-20080 San Sebastian, Spain.	ccpsiarb@si.ehu.es; ccplaore@si.ehu.es					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Castillo E., 1997, EXPERT SYSTEMS PROBA; CATLETT J, 1994, P EUR WORK SESS LEAR, P164; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cowell R. G., 1999, PROBABILISTIC NETWOR; DASARATHY BV, 1991, IEEE COMPUTER SOC PR; Dietterich TG, 1997, AI MAG, V18, P97; Dougherty J., 1995, INT C MACH LEARN, P194; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Henrion M., 1988, P 2 C UNC ART INT, P149; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; IRANI M, 1993, P 13 INT JOINT C ART, P1022; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Kohavi R., 1996, P 2 INT C KNOWL DISC; Lu Y, 1996, APPL INTELL, V6, P75, DOI 10.1007/BF00117809; Michie D., 1995, MACHINE LEARNING NEU; Mitchell T.M., 1997, MACHINE LEARNING; MURPHYS PM, 1994, UCI REPOSITORY MACHI; PEARL J, 1987, ARTIF INTELL, V32, P245, DOI 10.1016/0004-3702(87)90012-9; Pearl J., 1988, PROBABILISTIC REASON; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Sierra B, 1999, LECT NOTES ARTIF INT, V1620, P366; Sierra B., 2002, Knowledge-Based Intelligent Information Engineering Systems and Allied Technologies. KES 2002; Sierra B, 2001, ARTIF INTELL MED, V22, P233, DOI 10.1016/S0933-3657(00)00111-1; SIERRA B, 2000, LECT NOTES COMPUTER, P4; Sierra B, 2001, LECT NOTES ARTIF INT, V2101, P20; Sierra B, 1998, ARTIF INTELL MED, V14, P215, DOI 10.1016/S0933-3657(98)00024-4; STONE M, 1974, J R STAT SOC B, V36, P111; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	33	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20589-6	LECT NOTES ARTIF INT			2003	2902						171	183				13	Computer Science, Artificial Intelligence	Computer Science	BY08M	WOS:000187551600016	
J	Akaho, S				Akaho, S			Conditionally independent component analysis for supervised feature extraction	NEUROCOMPUTING			English	Article						independent component analysis; naive Bayes inference; supervised learning; graphical models	INFORMATION	The present paper extends the framework of independent component analysis (ICA) to supervised learning. The key idea is to find a conditionally independent representation of input variables for a target variable by linear transformation. The representation can be considered as independent components of observations from which explanatory parts for a target variable are removed, and it is directly useful for naive Bayes learning which has been reported to perform as well as more sophisticated methods for prediction. The learning algorithm is derived under a similar but different criterion to ICA. The algorithm attempts to maximize the independence among extracted features as well as the mutual information between extracted features and a target variable. (C) 2002 Elsevier Science B.V. All rights reserved.	AIST, Natl Inst Adv Ind Sci & Technol, Neurosci Res Inst, Math Neuroinformat Grp, Tsukuba, Ibaraki, Japan	Akaho, S (reprint author), AIST, Natl Inst Adv Ind Sci & Technol, Neurosci Res Inst, Math Neuroinformat Grp, Tsukuba, Ibaraki, Japan.						Akaho S., 1999, P 1999 INT JOINT C N, P927; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Anderson T., 1984, INTRO MULTIVARIATE S; BECKER S, 1996, MUTUAL INFORMATION M, V7; BECKER S, 1993, NEURAL COMPUT, V5, P267, DOI 10.1162/neco.1993.5.2.267; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Chambers JM, 1992, STAT MODELS; Cowell R. G., 1999, PROBABILISTIC NETWOR; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Frank E, 2000, MACH LEARN, V41, P5, DOI 10.1023/A:1007670802811; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; LEE TW, 1998, INDEPENDANT COMPONEN; Simonoff J.S., 1998, SMOOTHING METHODS ST; Slonim N, 2000, ADV NEUR IN, V12, P617; Yang HH, 1997, NEURAL COMPUT, V9, P1457, DOI 10.1162/neco.1997.9.7.1457	16	7	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	DEC	2002	49						139	150		10.1016/S0925-2312(02)00518-0		12	Computer Science, Artificial Intelligence	Computer Science	635CC	WOS:000180379300009	
J	Berikov, VB				Berikov, VB			An approach to the evaluation of the performance of a discrete classifier	PATTERN RECOGNITION LETTERS			English	Article						classifier analysis; naive Bayes; error rate estimation	STATISTICAL PATTERN-RECOGNITION; SAMPLE-SIZE; ERROR	The problem studied is the behavior of a discrete classifier on a finite learning sample. With naive Bayes approach, the value of misclassification probability is represented as a random function. for which the first two moments are analytically derived. For arbitrary distributions, this allows evaluating learning sample size sufficient for the classification with given admissible misclassification probability and confidence level. The comparison with statistical learning theory shows that the suggested approach frequently recommends significantly smaller learning sample size. (C) 2002 Elsevier Science B.V. All rights reserved.	Russian Acad Sci, Sobolev Inst Math, Siberian Branch, Novosibirsk, Russia	Berikov, VB (reprint author), Russian Acad Sci, Sobolev Inst Math, Siberian Branch, Novosibirsk, Russia.						Berikov VB, 1999, BIOINFORMATICS, V15, P553, DOI 10.1093/bioinformatics/15.7.553; CHANDRAS.B, 1971, IEEE T INFORM THEORY, V17, P452, DOI 10.1109/TIT.1971.1054665; Duda R., 1973, PATTERN CLASSIFICATI; DUIN RP, 1978, IEEE T INFORM THEORY, V24, P394, DOI 10.1109/TIT.1978.1055878; Glazko GB, 1998, J THEOR BIOL, V192, P475, DOI 10.1006/jtbi.1998.0668; GODWIN HJ, 1955, J AM STAT ASSOC, V50, P923, DOI 10.2307/2281177; GRISKEVICIUS D, 1979, STAT PROBLEMS CONTRO, V38, P95; Hand D., 1997, CONSTRUCTION ASSESSM; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain AK, 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Lbov G. S., 1992, International Journal of Imaging Systems and Technology, V4, DOI 10.1002/ima.1850040112; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; Raudys S, 1997, IEEE T PATTERN ANAL, V19, P667, DOI 10.1109/34.601254; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; STARTSEVA NG, 1997, PATTERN RECOGN, V8, P8; Vapnik VN, 1982, ESTIMATION DEPENDENC	17	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN	2002	23	1-3					227	233		10.1016/S0167-8655(01)00119-2		7	Computer Science, Artificial Intelligence	Computer Science	496LZ	WOS:000172398200022	
S	Liu, B; Ma, YM; Wong, CK		Grossman, RL; Kamath, C; Kegelmeyer, P; Kumar, V; Namburu, RR		Liu, B; Ma, YM; Wong, CK			Classification using association rules: Weaknesses and enhancements	DATA MINING FOR SCIENTIFIC AND ENGINEERING APPLICATIONS	MASSIVE COMPUTING		English	Proceedings Paper	Workshop on Mining Scientific Datasets	JUL, 2000	MINNEAPOLIS, MN	Army High Performance Comp Res Ctr		classification; association rules; combining multiple models		Existing classification and rule learning algorithms in machine learning mainly use heuristic/greedy search to find a subset of regularities (e.g., a decision tree or a set of rules) in data for classification. In the past few years, extensive research was done in the database community on learning rules using exhaustive search under the name of association rule mining. The objective there is to find all rules in data that satisfy the user-specified minimum support and minimum confidence. Although the whole set of rules may not be used directly for accurate classification, effective and efficient classifiers have been built using the rules. This paper aims to improve such an exhaustive search based classification system CBA (Classification Based on Associations). The main strength of this system is that it is able to use the most accurate rules for classification. However, it also has weaknesses. This paper proposes two new techniques to deal with these weaknesses. This results in remarkably accurate classifiers. Experiments on a set of 34 benchmark datasets show that on average the new techniques reduce the error of CBA by 17% and is superior to CBA on 26 of the 34 datasets. They reduce the error of the decision tree classifier C4.5 by 19%, and improve performance on 29 datasets. Similar good results are also achieved against the existing classification systems, RIPPER, LB and a Naive-Bayes classifier.	Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore	Liu, B (reprint author), Natl Univ Singapore, Sch Comp, 3 Sci Dr 2, Singapore 117543, Singapore.						AGRAWAL R, 1994, P VLDB 94; ALI K, 1996, MACH LEARN, V24, P3; Ali K., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; BAYARDO RJ, 1997, P KDD 97; CHAN PK, 1993, P 2 INT C INF KNOWL, P314; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; COHEN W, 1995, P ICML 95; COHEN W, 1999, P AAAI 99; DOMINGOS P, 1997, MACH LEARN, P29; DONG G, 1999, P DISC SCI 99; DOUGHERTY J, 1995, P ICML 95; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; FREUND Y, 1996, P ICML 96; FURNKRANZ J, 1994, ICML 94; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; KOHAVI R, 1996, P KDD 96; LITTLESTONE N, 1989, WEIGHTED MAJORITY AL; LIU B, 2000, P 4 EUR C PRINC PRAC; LIU B, 1998, P KDD 98; LIU B, 1999, P KDD 99; LU H, 2000, VLDB 2000; MERETKIS D, 1999, P KDD 99; Merz CJ, 1996, UCI REPOSITORY MACHI; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349; Murphy M A, 1994, J Clin Neurosci, V1, P257, DOI 10.1016/0967-5868(94)90066-3; Quinlan J.R., 1992, C4 5 PROGRAM MACHINE; QUINLAN JR, 1994, P ICML 94; RYMON R, 1996, P 2 C KNOWL DISC DAT, P331; WANG K, 2000, P KDD 2000; WEBB G, 1993, P AUSTR C ART INT; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; ZHENG Z, 1999, P PAC AS C KNOWL DIS	33	7	7	SPRINGER	DORDRECHT	PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1569-2698		1-4020-0033-2	MASSIVE COMP			2001	2						591	605				15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BT35B	WOS:000172716000030	
J	Miller, DJ; Yan, L				Miller, DJ; Yan, L			Approximate maximum entropy joint feature inference consistent with arbitrary lower-order probability constraints: Application to statistical classification	NEURAL COMPUTATION			English	Article							NETWORKS; DEPENDENCY; PRINCIPLE	We propose a new learning method for discrete space statistical classifiers. Similar to Chow and Liu (1968) and Cheeseman (1983), we cast classification/inference within the more general framework of estimating the joint probability mass function (p.m.f.) for the (feature vector, class label) pair. Cheeseman's proposal to build the maximum entropy (ME) joint p.m.f. consistent with general lower-order probability constraints is in principle powerful, allowing general dependencies between features. However, enormous learning complexity has severely limited the use of this approach. Alternative models such as Bayesian networks (BNs) require explicit determination of conditional independencies. These may be difficult to assess given limited data. Here we propose an approximate ME method, which, like previous methods, incorporates general constraints while retaining quite tractable learning. The new method restricts joint p.m.f. support during learning to a small subset of the full feature space. Classification gains are realized over dependence trees, tree-augmented naive Bayes networks, BNs trained by the Kutato algorithm, and multilayer perceptrons. Extensions to more general inference problems are indicated. We also propose a novel exact inference method when there are several missing features.	Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA	Miller, DJ (reprint author), Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA.						AHMAD S, 1993, P IEEE INT C NEUR NE, P1949; Berglund B, 1996, ENVIRON INT, V22, P1, DOI 10.1016/0160-4120(95)00098-4; Berman A., 1979, NONNEGATIVE MATRICES; BILBRO GL, 1992, NEURAL COMPUT, V4, P839, DOI 10.1162/neco.1992.4.6.839; BUHMANN J, 1993, IEEE T INFORM THEORY, V39, P1133, DOI 10.1109/18.243432; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Burg J. P., 1975, THESIS STANFORD U ST; CHEESEMAN P, 1988, P 5 INT C MACH LEARN; CHEESEMAN P, 1983, P 8 INT JOINT C AI, V1, P198; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; Cover T. M., 1991, ELEMENTS INFORMATION; EDWARDS D, 1985, BIOMETRIKA, V72, P339, DOI 10.1093/biomet/72.2.339; Frey B. J., 1998, GRAPHICAL MODELS MAC; Friedman N, 1998, P 15 INT C MACH LEAR, P179; Friedman N., 1996, P NATL C A1, V2, P1277; GEVARTER WB, 1986, 88224 NASA AM RES CT; Ghahramani Z., 1994, ADV NEURAL INFORMATI, V6, P120; Haykin S., 1999, NEURAL NETWORKS COMP; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; HERSKOVITS E, 1991, UNCERTAINTY ARTIFICI, V6, P117; Jaynes E.T., 1982, PAPERS PROBABILITY S; JIROUSEK R, 1995, COMPUT STAT DATA AN, V19, P177, DOI 10.1016/0167-9473(93)E0055-9; Kang HJ, 1997, PATTERN RECOGN LETT, V18, P515, DOI 10.1016/S0167-8655(97)00041-X; KU HH, 1969, IEEE T INFORM THEORY, V15, P444, DOI 10.1109/TIT.1969.1054336; LITTLE RJA, 1993, J AM STAT ASSOC, V88, P125, DOI 10.2307/2290705; Meila M, 1998, ADV NEUR IN, V10, P584; Miller D, 1996, IEEE T SIGNAL PROCES, V44, P3108, DOI 10.1109/78.553484; Miller DJ, 1999, IEEE T SIGNAL PROCES, V47, P2833, DOI 10.1109/78.790663; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Pearl J., 1988, PROBABILISTIC REASON; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ripley B., 1996, PATTERN RECOGNITION; ROSE K, 1992, IEEE T INFORM THEORY, V38, P1249, DOI 10.1109/18.144705; SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144; YAN L, 1999, UNPUB GEN STAT INFER; YAN L, 1999, P IEEE WORKSH NEUR N, P112; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	38	7	7	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	SEP	2000	12	9					2175	2207		10.1162/089976600300015105		33	Computer Science, Artificial Intelligence	Computer Science	352BG	WOS:000089194200009	
J	Yamashita, Y				Yamashita, Y			Supervised learning for the analysis of process operational data	COMPUTERS & CHEMICAL ENGINEERING			English	Article; Proceedings Paper	7th International Symposium on Process Systems Engineering	JUL 16-21, 2000	KEYSTONE, CO	CACHE Corp, AICHE, Comp & Syst Techno Div		machine learning; classification; operational knowledge; data mining	ATTRIBUTES	For the extraction of useful knowledge from recorded process operational data, several data mining algorithms are examined on a data set generated by a dynamic simulator of a debutanizer plant. Decision tree inducer can directly extract reasonable operational rules from the data-set with no previous knowledge. By integrating the feature-subset selection wrapper algorithm, Naive-Bayes classifier and nearest-neighbor classifier can also estimate the action of operation successfully. (C) 2000 Elsevier Science Ltd. All rights reserved.	Tohoku Univ, Dept Chem Engn, Sendai, Miyagi 9808579, Japan	Yamashita, Y (reprint author), Tohoku Univ, Dept Chem Engn, Sendai, Miyagi 9808579, Japan.	yyama@pse.che.tohoku.ac.jp	Yamashita, Yoshiyuki/G-2318-2010	Yamashita, Yoshiyuki/0000-0001-6583-1209			AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV, P1; *JAP SOC SCI, 2000, 21 JAP SOC SCI; Kohavi R., 1995, 1 INT C KNOWL DISC D, P192; LANGLEY P, 1999, 16 INT C MACH LEARN, P220; MICHALSKI RS, 1998, MACHINE LEARNING DAT, P71; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Wang X Z, 1999, DATA MINING KNOWLEDG	9	7	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0098-1354			COMPUT CHEM ENG	Comput. Chem. Eng.	JUL 15	2000	24	2-7					471	474		10.1016/S0098-1354(00)00497-X		4	Computer Science, Interdisciplinary Applications; Engineering, Chemical	Computer Science; Engineering	340QV	WOS:000088546800046	
J	Broos, PS; Getman, KV; Povich, MS; Feigelson, ED; Townsley, LK; Naylor, T; Kuhn, MA; King, RR; Busk, HA				Broos, Patrick S.; Getman, Konstantin V.; Povich, Matthew S.; Feigelson, Eric D.; Townsley, Leisa K.; Naylor, Tim; Kuhn, Michael A.; King, Robert R.; Busk, Heather A.			IDENTIFYING YOUNG STARS IN MASSIVE STAR-FORMING REGIONS FOR THE MYStIX PROJECT	ASTROPHYSICAL JOURNAL SUPPLEMENT SERIES			English	Article						infrared: stars; methods: data analysis; methods: statistical; open clusters and associations: general; stars: pre-main sequence; X-rays: general; X-rays: stars	ORION ULTRADEEP PROJECT; X-RAY SOURCES; CARINA COMPLEX PROJECT; STELLAR OBJECTS; INTERSTELLAR EXTINCTION; SPECTROSCOPIC ANALYSIS; FORMATION HISTORY; CHANDRA; POPULATION; NEBULA	The Massive Young star-forming Complex Study in Infrared and X-rays (MYStIX) project requires samples of young stars that are likely members of 20 nearby Galactic massive star-forming regions. Membership is inferred from statistical classification of X-ray sources, from detection of a robust infrared excess that is best explained by circumstellar dust in a disk or infalling envelope and from published spectral types that are unlikely to be found among field stars. We present the MYStIX membership lists here, and describe in detail the statistical classification of X-ray sources via a "Naive Bayes Classifier." These membership lists provide the empirical foundation for later MYStIX science studies.	[Broos, Patrick S.; Getman, Konstantin V.; Povich, Matthew S.; Feigelson, Eric D.; Townsley, Leisa K.; Kuhn, Michael A.; Busk, Heather A.] Penn State Univ, Dept Astron & Astrophys, University Pk, PA 16802 USA; [Povich, Matthew S.] Calif State Polytech Univ Pomona, Dept Phys & Astron, Pomona, CA 91768 USA; [Naylor, Tim; King, Robert R.] Univ Exeter, Sch Phys & Astron, Exeter EX4 4QL, Devon, England	Broos, PS (reprint author), Penn State Univ, Dept Astron & Astrophys, 525 Davey Lab, University Pk, PA 16802 USA.	patb@astro.psu.edu					Alexander DM, 2001, ASTRON J, V122, P2156, DOI 10.1086/323540; Aoyama H, 2001, PUBL ASTRON SOC JPN, V53, P1053; Benjamin RA, 2003, PUBL ASTRON SOC PAC, V115, P953, DOI 10.1086/376696; Bieging JH, 2011, ASTROPHYS J SUPPL S, V196, DOI 10.1088/0067-0049/196/2/18; Bik A, 2012, ASTROPHYS J, V744, DOI 10.1088/0004-637X/744/2/87; Broos PS, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/2; Broos PS, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/4; Broos P. S., 2012, ASTROPHYSICS SOURCE; Broos PS, 2010, ASTROPHYS J, V714, P1582, DOI 10.1088/0004-637X/714/2/1582; Broos PS, 2007, ASTROPHYS J SUPPL S, V169, P353, DOI 10.1086/512068; Casali M, 2007, ASTRON ASTROPHYS, V467, P777, DOI 10.1051/0004-6361:20066514; Chini R., 2008, HDB STAR FORMING REG, VII, P625; CHINI R, 1980, ASTRON ASTROPHYS, V91, P186; Congdon P, 2010, APPL BAYESIAN HIERAR; Costero R, 2008, REV MEX AST ASTR, V34, P102; Dobashi K., 2011, PASJ, V63, P1; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R.O., 2001, PATTERN CLASSIFICATI; Ellerbroek LE, 2012, ASTR SOC P, V464, P351; Feigelson ED, 2013, ASTROPHYS J SUPPL S, V209, DOI 10.1088/0067-0049/209/2/26; Flaherty KM, 2007, ASTROPHYS J, V663, P1069, DOI 10.1086/518411; Gagne M, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/5; Getman K., 2012, ASTROPHYSICS SOURCE, V1212; Getman KV, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/3; Getman KV, 2005, ASTROPHYS J SUPPL S, V160, P353, DOI 10.1086/432097; Getman KV, 2010, ASTROPHYS J, V708, P1760, DOI 10.1088/0004-637X/708/2/1760; Getman KV, 2012, MON NOT R ASTRON SOC, V426, P2917, DOI 10.1111/j.1365-2966.2012.21879.x; Getman KV, 2005, ASTROPHYS J SUPPL S, V160, P319, DOI 10.1086/432092; Gudel M, 2009, ASTRON ASTROPHYS REV, V17, P309, DOI 10.1007/s00159-009-0022-4; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.2307/1403452; Harvey P, 2007, ASTROPHYS J, V663, P1149, DOI 10.1086/518646; Hirsch L, 2012, ASTROPHYS J, V757, DOI 10.1088/0004-637X/757/2/113; Hoffmeister VH, 2008, ASTROPHYS J, V686, P310, DOI 10.1086/591070; Hong J, 2009, ASTROPHYS J, V706, P223, DOI 10.1088/0004-637X/706/1/223; King RR, 2013, ASTROPHYS J SUPPL S, V209, DOI 10.1088/0067-0049/209/2/28; Kraus S, 2007, ASTRON ASTROPHYS, V466, P649, DOI 10.1051/0004-6361:20066965; Kuhn MA, 2013, ASTROPHYS J SUPPL S, V209, DOI 10.1088/0067-0049/209/2/27; Kuhn MA, 2013, ASTROPHYS J SUPPL S, V209, DOI 10.1088/0067-0049/209/2/29; Kuhn MA, 2010, ASTROPHYS J, V725, P2485, DOI 10.1088/0004-637X/725/2/2485; Lawrence A, 2007, MON NOT R ASTRON SOC, V379, P1599, DOI 10.1111/j.1365-2966.2007.12040.x; Levenhagen RS, 2006, MON NOT R ASTRON SOC, V371, P252, DOI 10.1111/j.1365-2966.2006.10655.x; Lombardi M, 2001, ASTRON ASTROPHYS, V377, P1023, DOI 10.1051/0004-6361:20011099; Loredo T. J., 2012, LECT NOTES STAT, V209, P225; Loredo T. J., 2012, LECT NOTES STAT, V209, P303; Apellaniz JM, 2007, ASTROPHYS J, V660, P1480, DOI 10.1086/513098; Megeath ST, 2012, ASTRON J, V144, DOI 10.1088/0004-6256/144/6/192; Naylor T, 2013, ASTROPHYS J SUPPL S, V209, DOI 10.1088/0067-0049/209/2/30; Nieva MF, 2011, ASTRON ASTROPHYS, V532, DOI 10.1051/0004-6361/201116478; Ochsenbein F, 2000, ASTRON ASTROPHYS SUP, V143, P23, DOI 10.1051/aas:2000169; Paolillo M, 2004, ASTROPHYS J, V611, P93, DOI 10.1086/421967; Povich MS, 2013, ASTROPHYS J SUPPL S, V209, DOI 10.1088/0067-0049/209/2/31; Povich MS, 2009, ASTROPHYS J, V696, P1278, DOI 10.1088/0004-637X/696/2/1278; Povich MS, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/14; Preibisch T, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/10; Preibisch T, 2005, ASTROPHYS J SUPPL S, V160, P401, DOI 10.1086/432891; Renson P, 2009, ASTRON ASTROPHYS, V498, P961, DOI 10.1051/0004-6361/200810788; RIEKE GH, 1985, ASTROPHYS J, V288, P618, DOI 10.1086/162827; Robin AC, 2003, ASTRON ASTROPHYS, V409, P523, DOI 10.1051/0004-6361:20031117; Ryter CE, 1996, ASTROPHYS SPACE SCI, V236, P285, DOI 10.1007/BF00645150; Schneider N, 2011, ASTRON ASTROPHYS, V529, DOI 10.1051/0004-6361/200913884; SCHULZ A, 1981, ASTRON ASTROPHYS, V95, P94; Shemmer O, 2005, ASTROPHYS J, V630, P729, DOI 10.1086/432050; Shuping RY, 2012, ASTRON J, V144, DOI 10.1088/0004-6256/144/4/116; Simon JD, 2007, ASTROPHYS J, V669, P327, DOI 10.1086/521544; Simon-Diaz S, 2006, ASTRON ASTROPHYS, V448, P351, DOI 10.1051/0004-6361:20053066; Skiff B. A., 2009, YCAT, V1, P2023; Skrutskie MF, 2006, ASTRON J, V131, P1163, DOI 10.1086/498708; Sota A, 2011, ASTROPHYS J SUPPL S, V193, DOI 10.1088/0067-0049/193/2/24; Sug H., 2011, INT J MATH MODELS ME, V5, P797; Telleschi A, 2007, ASTRON ASTROPHYS, V468, P425, DOI 10.1051/0004-6361:20066565; Townsley LK, 2011, ASTROPHYS J SUPPL S, V194, DOI 10.1088/0067-0049/194/1/1; Waske B, 2009, LECT NOTES COMPUT SC, V5519, P375, DOI 10.1007/978-3-642-02326-2_38; Wenger M, 2000, ASTRON ASTROPHYS SUP, V143, P9, DOI 10.1051/aas:2000332; Wolk SJ, 2005, ASTROPHYS J SUPPL S, V160, P423, DOI 10.1086/432099	74	6	6	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0067-0049	1538-4365		ASTROPHYS J SUPPL S	Astrophys. J. Suppl. Ser.	DEC	2013	209	2								10.1088/0067-0049/209/2/32		25	Astronomy & Astrophysics	Astronomy & Astrophysics	266YG	WOS:000328059500014	
J	Liang, L; Juarez, S; Tran, VTN; Dunstan, S; Nakajima-Sasaki, R; Davies, DH; McSorley, S; Baker, S; Felgner, PL				Liang, Li; Juarez, Silvia; Tran Vu Thieu Nga; Dunstan, Sarah; Nakajima-Sasaki, Rie; Davies, D. Huw; McSorley, Stephen; Baker, Stephen; Felgner, Philip L.			Immune profiling with a Salmonella Typhi antigen microarray identifies new diagnostic biomarkers of human typhoid	SCIENTIFIC REPORTS			English	Article							PROTEIN MICROARRAY; FRANCISELLA-TULARENSIS; ANTIBODY-RESPONSES; PARATYPHOID FEVER; PREDICTION; DISCOVERY; SIGNATURE; CHILDREN; REVEALS; VIETNAM	Current serological diagnostic assays for typhoid fever are based on detecting antibodies against Salmonella LPS or flagellum, resulting in a high false-positive rate. Here we used a protein microarray containing 2,724 Salmonella enterica serovar Typhi antigens (>63% of proteome) and identified antibodies against 16 IgG antigens and 77 IgM antigens that were differentially reactive among acute typhoid patients and healthy controls. The IgG target antigens produced a sensitivity of 97% and specificity of 80%, whereas the IgM target antigens produced 97% and 91% sensitivity and specificity, respectively. Our analyses indicated certain features such as membrane association, secretion, and protein expression were significant enriching features of the reactive antigens. About 72% of the serodiagnostic antigens were within the top 25% of the ranked antigen list using a Naive bayes classifier. These data provide an important resource for improved diagnostics, therapeutics and vaccine development against an important human pathogen.	[Liang, Li; Juarez, Silvia; Nakajima-Sasaki, Rie; Davies, D. Huw; Felgner, Philip L.] Univ Calif Irvine, Dept Med, Div Infect Dis, Irvine, CA 92697 USA; [Tran Vu Thieu Nga; Dunstan, Sarah; Baker, Stephen] Univ Oxford, Ctr Trop Med, Clin Res Unit, Thanh Pho Ho Chi Minh, Vietnam; [McSorley, Stephen] Univ Calif Davis, Sch Vet Med, Dept Anat Physiol & Cell Biol, Ctr Comparat Med, Davis, CA 95616 USA	Liang, L (reprint author), Univ Calif Irvine, Dept Med, Div Infect Dis, Irvine, CA 92697 USA.	lliang3@uci.edu	liang, li/I-3972-2013		OAK foundation through Oxford University; Wellcome Trust of the United Kingdom;  [U01AI078213];  [R01AI073672]	We thank Renee Tsolis for providing Salmonella enterica ty2 genomic DNA. This work was supported by U01AI078213 (PLF) and a subcontract to DHD from R01AI073672 (SJMcS). SB is funded by the OAK foundation through Oxford University, SD and TVTN are funded by the Wellcome Trust of the United Kingdom.	Alexander N, 2011, TROPICAL MED INT HLT; Ansong C, 2008, J PROTEOME RES, V7, P546, DOI 10.1021/pr070434u; Baker S, 2011, OPEN BIOL, V1, DOI 10.1098/rsob.110008; Baker S, 2010, BMC INFECT DIS, V10, DOI 10.1186/1471-2334-10-45; Baldi P., 2002, DNA MICROARRAYS GENE; Baldi P., 2001, BIOINFORMATICS MACHI; Barbour AG, 2008, INFECT IMMUN, V76, P3374, DOI 10.1128/IAI.00048-08; BARCLAY GR, 1987, INFECT IMMUN, V55, P2706; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Charles RC, 2010, CLIN VACCINE IMMUNOL, V17, P1188, DOI 10.1128/CVI.00104-10; Connor BA, 2005, LANCET INFECT DIS, V5, P623, DOI 10.1016/S1473-3099(05)70239-5; Crompton PD, 2010, P NATL ACAD SCI USA, V107, P6958, DOI 10.1073/pnas.1001323107; Davies DH, 2007, PROTEOMICS, V7, P1678, DOI 10.1002/pmic.200600926; Dolecek C, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002188; Doran M, 2007, BIOINFORMATICS, V23, P487, DOI 10.1093/bioinformatics/btl626; Dunstan SJ, 2007, HUM GENET, V122, P51, DOI 10.1007/s00439-007-0372-9; Durbin B P, 2002, Bioinformatics, V18 Suppl 1, pS105; Dutta S, 2006, DIAGN MICR INFEC DIS, V56, P359, DOI 10.1016/j.diagmicrobio.2006.06.024; Eyles JE, 2007, PROTEOMICS, V7, P2172, DOI 10.1002/pmic.200600985; Felgner PL, 2009, P NATL ACAD SCI USA, V106, P13499, DOI 10.1073/pnas.0812080106; Gardy JL, 2005, BIOINFORMATICS, V21, P617, DOI 10.1093/bioinformatics/bti057; House D, 2008, J INFECT DEV COUNTR, V2, P308; House D, 2005, J CLIN MICROBIOL, V43, P4889, DOI 10.1128/JCM.43.9.4889-4890.2005; House D, 2001, J CLIN MICROBIOL, V39, P1002, DOI 10.1128/JCM.39.3.1002-1007.2001; Huber Wolfgang, 2002, Bioinformatics, V18 Suppl 1, pS96; Kalantari-Dehaghi M, 2012, J VIROL, V86, P4328, DOI 10.1128/JVI.05194-11; Kunnath-Velayudhan S, 2010, P NATL ACAD SCI USA, V107, P14703, DOI 10.1073/pnas.1009080107; Lee SJ, 2012, P NATL ACAD SCI USA, V109, P4998, DOI 10.1073/pnas.1111413109; Liang L, 2011, J PROTEOME RES, V10, P4813, DOI 10.1021/pr200619r; Liang L, 2011, MOL CELL PROTEOMICS, V10; Lim PL, 1998, J CLIN MICROBIOL, V36, P2271; Magnan CN, 2010, BIOINFORMATICS, V26, P2936, DOI 10.1093/bioinformatics/btq551; Moller S, 2001, BIOINFORMATICS, V17, P646, DOI 10.1093/bioinformatics/17.7.646; Ochiai RL, 2008, B WORLD HEALTH ORGAN, V86, P260, DOI 10.2471/BLT.06.039818; Ochiai RL, 2005, EMERG INFECT DIS, V11, P1764; Parry CM, 1999, J CLIN MICROBIOL, V37, P2882; Prakash P, 2007, J TROP PEDIATRICS, V53, P216, DOI 10.1093/tropej/fmm008; Pulickal AS, 2009, CLIN VACCINE IMMUNOL, V16, P1413, DOI 10.1128/CVI.00245-09; Sood S, 1999, EMERG INFECT DIS, V5, P483; Srinivasan A, 2004, CURR OPIN IMMUNOL, V16, P494, DOI 10.1016/j.coi.2004.05.001; Sundaresh S, 2007, BIOINFORMATICS, V23, pI508, DOI 10.1093/bioinformatics/btm207; Thompson LJ, 2009, P NATL ACAD SCI USA, V106, P22433, DOI 10.1073/pnas.0912386106; Witten IH, 2005, DATA MINING PRACTICA; Woods CW, 2006, T ROY SOC TROP MED H, V100, P1063, DOI 10.1016/j.trstmh.2005.12.011	45	6	6	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	2045-2322			SCI REP-UK	Sci Rep	JAN 9	2013	3								1043	10.1038/srep01043		10	Multidisciplinary Sciences	Science & Technology - Other Topics	067IP	WOS:000313287800003	
J	Sprouse, J; Almeida, D				Sprouse, Jon; Almeida, Diogo			Assessing the reliability of textbook data in syntax: Adger's Core Syntax	JOURNAL OF LINGUISTICS			English	Article							ACCEPTABILITY JUDGMENTS; MAGNITUDE ESTIMATION; GENERATIVE GRAMMAR; NULL HYPOTHESIS; LINGUISTIC ACCEPTABILITY; EMPIRICAL-EVIDENCE; WH-CONSTRAINTS; GRAMMATICALITY; INTUITIONS; CARROTS	There has been a consistent pattern of criticism of the reliability of acceptability judgment data in syntax for at least 50 years (e.g., Hill 1961), culminating in several high-profile criticisms within the past ten years (Edelman & Christiansen 2003, Ferreira 2005, Wasow & Arnold 2005, Gibson & Fedorenko 2010, in press). The fundamental claim of these critics is that traditional acceptability judgment collection methods, which tend to be relatively informal compared to methods from experimental psychology, lead to an intolerably high number of false positive results. In this paper we empirically assess this claim by formally testing all 469 (unique, US-English) data points from a popular syntax textbook (Adger 2003) using 440 naive participants, two judgment tasks (magnitude estimation and yes-no), and three different types of statistical analyses (standard frequentist tests, linear mixed effects models, and Bayes factor analyses). The results suggest that the maximum discrepancy between traditional methods and formal experimental methods is 2%. This suggests that even under the (likely unwarranted) assumption that the discrepant results are all false positives that have found their way into the syntactic literature due to the shortcomings of traditional methods, the minimum replication rate of these 469 data points is 98%. We discuss the implications of these results for questions about the reliability of syntactic data, as well as the practical consequences of these results for the methodological options available to syntacticians.	[Sprouse, Jon] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92697 USA; [Almeida, Diogo] Michigan State Univ, Dept Linguist & Languages, E Lansing, MI 48824 USA	Sprouse, J (reprint author), Univ Calif Irvine, Dept Cognit Sci, 3151 Social Sci Plaza A, Irvine, CA 92697 USA.	jsprouse@uci.edu; diogo@msu.edu					Adger David, 2003, CORE SYNTAX MINIMALI; Alexopoulou T, 2007, LANGUAGE, V83, P110, DOI 10.1353/lan.2007.0001; Almeida Diogo, 2012, CAMBRIDGE HDB BIOLIN; Almeida Diogo, 2011, POWER ACCEPTAB UNPUB; Alterman Richard, 2003, 25 ANN C COGN SCI SO, P652; Baayen R. H., 2007, ANAL LINGUISTIC DATA; Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005; Bader M, 2010, J LINGUIST, V46, P273, DOI 10.1017/S0022226709990260; Bard EG, 1996, LANGUAGE, V72, P32, DOI 10.2307/416793; Chomsky N., 1965, ASPECTS THEORY SYNTA; Chomsky N., 1986, BARRIERS; Chomsky N., 1955, LOGICAL STRUCTURE LI; COHEN J, 1962, J ABNORM PSYCHOL, V65, P145, DOI 10.1037/h0045186; Cohen J., 1988, STAT POWER ANAL BEHA; Cohen J., 2010, CURRENT DIRECTIONS P, V1, P98, DOI DOI 10.1111/1467-8721.EP10768783; Cowart Wayne, 1997, EXPT SYNTAX APPL OBJ; Culbertson J, 2009, BRIT J PHILOS SCI, V60, P721, DOI 10.1093/bjps/axp032; Culicover PW, 2010, TRENDS COGN SCI, V14, P234, DOI 10.1016/j.tics.2010.03.012; Dabrowska E, 2010, LINGUIST REV, V27, P1, DOI 10.1515/tlir.2010.001; Den Dikken M, 2007, THEOR LINGUIST, V33, P335, DOI 10.1515/TL.2007.022; Edelman S, 2003, TRENDS COGN SCI, V7, P60, DOI 10.1016/S1364-6613(02)00045-1; Fanselow G, 2007, THEOR LINGUIST, V33, P353, DOI 10.1515/TL.2007.023; Featherston S, 2005, LINGUA, V115, P1525, DOI 10.1016/j.lingua.2004.07.003; Featherston S, 2009, Z SPRACHWISS, V28, P127, DOI 10.1515/ZFSW.2009.014; Featherston S., 2008, WAS IST LINGUISTISCH, P69; Featherston S, 2007, THEOR LINGUIST, V33, P269, DOI 10.1515/TL.2007.020; Featherston S, 2005, LINGUISTICS, V43, P667, DOI 10.1515/ling.2005.43.4.667; Ferreira F, 2005, LINGUIST REV, V22, P365, DOI 10.1515/tlir.2005.22.2-4.365; Gallistel R., 2009, PSYCHOL REV, V116, P439; Gibson E, 2010, TRENDS COGN SCI, V14, P233, DOI 10.1016/j.tics.2010.03.005; Gibson E, 2013, LANG COGNITIVE PROC, V28, P88, DOI 10.1080/01690965.2010.515080; Gibson E., 2011, LANGUAGE LINGUISTICS, V5, P509; Gibson E., 1991, THESIS CARNEGIE MELL; Grewendorf G, 2007, THEOR LINGUIST, V33, P369, DOI 10.1515/TL.2007.024; Gross S, 2011, BRIT J PHILOS SCI, V62, P639, DOI 10.1093/bjps/axr009; Haider H, 2007, THEOR LINGUIST, V33, P381, DOI 10.1515/TL.2007.025; HILL AA, 1961, WORD, V17, P1; Hofmeister P, 2013, LANG COGNITIVE PROC, V28, P48, DOI 10.1080/01690965.2011.572401; Jeffreys H., 1961, THEORY PROBABILITY; KAYNE RS, 1983, LINGUIST INQ, V14, P223; Keller Frank, 2000, THESIS U EDINBURGH; Myers James, 2009, LANGUAGE LINGUISTICS, V3, P406; Newmeyer FJ, 2007, THEOR LINGUIST, V33, P395, DOI 10.1515/TL.2007.026; Nickerson RS, 2000, PSYCHOL METHODS, V5, P241, DOI 10.1037//1082-989X.5.2.241; Pesetsky David, 1987, LINGUISTIC REPRESENT, P98; Phillips C., 2009, JAPANESE KOREAN LING, V17; Phillips C, 2003, TRENDS COGN SCI, V7, P61, DOI 10.1016/S1364-6613(02)00046-3; Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225; Schutze Carson, 2011, LINGUISTIC INQ UNPUB; Schutze Carson T., 1996, EMPIRICAL BASE LINGU; Sorace A, 2005, LINGUA, V115, P1497, DOI 10.1016/j.lingua.2004.07.002; SPENCER NJ, 1973, J PSYCHOLINGUIST RES, V2, P83, DOI 10.1007/BF01067203; Sprouse J, 2011, SYNTAX-UK, V14, P179, DOI 10.1111/j.1467-9612.2011.00153.x; Sprouse J, 2008, LINGUIST INQ, V39, P686, DOI 10.1162/ling.2008.39.4.686; Sprouse J, 2011, BEHAV RES METHODS, V43, P155, DOI 10.3758/s13428-010-0039-7; Sprouse J, 2009, LINGUIST INQ, V40, P329, DOI 10.1162/ling.2009.40.2.329; Sprouse J, 2007, THESIS U MARYLAND; Sprouse J., 2007, BIOLINGUISTICS, V1, P118; Sprouse J, 2011, LANGUAGE, V87, P274; Sprouse Jon, RES METHODS LINGUIST; STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162; Wagers Matt, 2012, LANGUAGE, V88; Wasow T, 2005, LINGUA, V115, P1481, DOI 10.1016/j.lingua.2004.07.001; Weskott T, 2011, LANGUAGE, V87, P249; Wetzels R, 2009, PSYCHON B REV, V16, P752, DOI 10.3758/PBR.16.4.752	65	6	6	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0022-2267			J LINGUIST	J. Linguist.	NOV	2012	48	3					609	652		10.1017/S0022226712000011		44	Linguistics; Language & Linguistics	Linguistics	026IA	WOS:000310267200004	
J	Niaf, E; Rouviere, O; Mege-Lechevallier, F; Bratan, F; Lartizien, C				Niaf, Emilie; Rouviere, Olivier; Mege-Lechevallier, Florence; Bratan, Flavie; Lartizien, Carole			Computer-aided diagnosis of prostate cancer in the peripheral zone using multiparametric MRI	PHYSICS IN MEDICINE AND BIOLOGY			English	Article							CONTRAST-ENHANCED MRI; MULTISPECTRAL MRI; DCE-MRI; DIFFUSION; SEGMENTATION; LOCALIZATION; FEATURES; LESIONS	This study evaluated a computer-assisted diagnosis (CADx) system for determining a likelihood measure of prostate cancer presence in the peripheral zone (PZ) based on multiparametric magnetic resonance (MR) imaging, including T2-weighted, diffusion-weighted and dynamic contrast-enhanced MRI at 1.5 T. Based on a feature set derived from grey-level images, including first-order statistics, Haralick features, gradient features, semi-quantitative and quantitative (pharmacokinetic modelling) dynamic parameters, four kinds of classifiers were trained and compared : nonlinear support vector machine (SVM), linear discriminant analysis, k-nearest neighbours and naive Bayes classifiers. A set of feature selection methods based on t-test, mutual information and minimum-redundancy-maximum-relevancy criteria were also compared. The aim was to discriminate between the relevant features as well as to create an efficient classifier using these features. The diagnostic performances of these different CADx schemes were evaluated based on a receiver operating characteristic (ROC) curve analysis. The evaluation database consisted of 30 sets of multiparametric MR images acquired from radical prostatectomy patients. Using histologic sections as the gold standard, both cancer and nonmalignant (but suspicious) tissues were annotated in consensus on all MR images by two radiologists, a histopathologist and a researcher. Benign tissue regions of interest (ROIs) were also delineated in the remaining prostate PZ. This resulted in a series of 42 cancer ROIs, 49 benign but suspicious ROIs and 124 nonsuspicious benign ROIs. From the outputs of all evaluated feature selection methods on the test bench, a restrictive set of about 15 highly informative features coming from all MR sequences was discriminated, thus confirming the validity of the multiparametric approach. Quantitative evaluation of the diagnostic performance yielded a maximal area under the ROC curve (AUC) of 0.89 (0.81-0.94) for the discrimination of the malignant versus nonmalignant tissues and 0.82 (0.73-0.90) for the discrimination of the malignant versus suspicious tissues when combining the t-test feature selection approach with a SVM classifier. A preliminary comparison showed that the optimal CADx scheme mimicked, in terms of AUC, the human experts in differentiating malignant from suspicious tissues, thus demonstrating its potential for assisting cancer identification in the PZ.	[Niaf, Emilie; Rouviere, Olivier] INSERM, LabTau, U1032, F-69003 Lyon, France; [Niaf, Emilie; Lartizien, Carole] Univ Lyon, CREATIS, F-69003 Lyon, France; [Niaf, Emilie; Lartizien, Carole] CNRS, UMR5220, F-75700 Paris, France; [Niaf, Emilie; Lartizien, Carole] INSA Lyon, Lyon, France; [Niaf, Emilie; Lartizien, Carole] Univ Lyon 1, F-69622 Villeurbanne, France; [Rouviere, Olivier; Mege-Lechevallier, Florence; Bratan, Flavie] Hop Edouard Herriot, Dept Urinary & Vasc Radiol, Hosp Civils Lyon, F-69003 Lyon, France; [Rouviere, Olivier] Univ Lyon 1, Fac Med Lyon Est, F-69003 Lyon, France	Niaf, E (reprint author), INSERM, LabTau, U1032, F-69003 Lyon, France.	emilie.niaf@creatis.insa-lyon.fr					Artan Y, 2010, IEEE T IMAGE PROCESS, V19, P2444, DOI 10.1109/TIP.2010.2048612; Canu S, 2005, SVM KERNEL METHODS M; Chan I, 2003, MED PHYS, V30, P2390, DOI 10.1118/1.1593633; Cheikh Alexandre Ben, 2009, Eur Radiol, V19, P770, DOI 10.1007/s00330-008-1190-8; Dickinson L, 2011, EUR UROL, V59, P477, DOI 10.1016/j.eururo.2010.12.009; Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004; Girouin N, 2007, EUR RADIOL, V17, P1498, DOI 10.1007/s00330-006-0478-9; Haas GP, 2008, CAN J UROL, V15, P3866; Haider MA, 2007, AM J ROENTGENOL, V189, P323, DOI 10.2214/AJR.07.2211; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Kirkham APS, 2006, EUR UROL, V50, P1163, DOI 10.1016/j.eururo.2006.06.025; Kozlowski P, 2006, J MAGN RESON IMAGING, V24, P108, DOI 10.1002/jmri.20626; Langer DL, 2009, J MAGN RESON IMAGING, V30, P327, DOI 10.1002/jmri.21824; Lopes R, 2011, MED PHYS, V38, P83, DOI 10.1118/1.3521470; Madabhushi A, 2005, IEEE T MED IMAGING, V24, P1611, DOI 10.1109/TMI.2005.859208; Madabhushi A, 2006, LECT NOTES COMPUT SC, V4241, P25; Niemeijer M, 2011, IEEE T MED IMAGING, V30, P215, DOI 10.1109/TMI.2010.2072789; Ocak I, 2007, AM J ROENTGENOL, V189, pW192, DOI 10.2214/AJR.06.1329; Ozer S, 2010, MED PHYS, V37, P1873, DOI 10.1118/1.3359459; Platt J, 1999, ADV LARGE MARGIN CLA, P61; Puech P, 2009, INT J COMPUT ASS RAD, V4, P1, DOI 10.1007/s11548-008-0261-2; Rutter CM, 2000, ACAD RADIOL, V7, P413, DOI 10.1016/S1076-6332(00)80381-5; Vapnik V., 1998, STAT LEARNING THEORY; Viswanath S, 2009, SPIE MED IMAGING, V7260; Viswanath S, 2008, SPIE MED IMAGING, V6915; Viswanath S, 2008, LECT NOTES COMPUT SC, V5241, P662, DOI 10.1007/978-3-540-85988-8_79; Vos PC, 2010, PHYS MED BIOL, V55, P1719, DOI 10.1088/0031-9155/55/6/012; Vos PC, 2008, MED PHYS, V35, P888, DOI 10.1118/1.2836419; Wiart M, 2007, MAGN RESON MED, V58, P119, DOI 10.1002/mrm.21271	29	6	7	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0031-9155			PHYS MED BIOL	Phys. Med. Biol.	JUN 21	2012	57	12					3833	3851		10.1088/0031-9155/57/12/3833		19	Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Radiology, Nuclear Medicine & Medical Imaging	961RF	WOS:000305484700013	
J	Liu, Z; Zhang, QM; Lu, LY; Zhou, T				Liu, Zhen; Zhang, Qian-Ming; Lu, Linyuan; Zhou, Tao			Link prediction in complex networks: A local naive Bayes model	EPL			English	Article							SOCIAL NETWORKS; INTERACTOME	The common-neighbor-based method is simple yet effective to predict missing links, which assume that two nodes are more likely to be connected if they have more common neighbors. In the traditional method, each common neighbor of two nodes contributes equally to the connection likelihood. In this letter, we argue that different common neighbors may play different roles and thus contributes differently, and propose a local naive Bayes model. Extensive experiments were carried out on nine real networks. Compared with the traditional method, the present method can provide more accurate predictions. Copyright (C) EPLA, 2011	[Liu, Zhen; Zhang, Qian-Ming; Zhou, Tao] Univ Elect Sci & Technol China, Web Sci Ctr, Chengdu 610054, Peoples R China; [Lu, Linyuan] Univ Fribourg, Dept Phys, CH-1700 Fribourg, Switzerland	Liu, Z (reprint author), Univ Elect Sci & Technol China, Web Sci Ctr, Chengdu 610054, Peoples R China.	linyuan.lue@unifr.ch	Zhou, Tao/D-5849-2012		National Natural Science Foundation of China [11075031, 60903073, 60973069]; Swiss National Science Foundation [200020-132253]	We acknowledge CHONG-JING SUN for helpful assistance in manuscript preparation and DUANBING CHEN for valuable suggestions. This work is partially supported by the National Natural Science Foundation of China under Grant Nos. 11075031, 60903073 and 60973069. LL acknowledges the Swiss National Science Foundation under Grant No. 200020-132253.	Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1; Amaral LAN, 2008, P NATL ACAD SCI USA, V105, P6795, DOI 10.1073/pnas.0802459105; Baird D, 1998, ESTUAR COAST SHELF S, V47, P329, DOI 10.1006/ecss.1998.0360; Bernardo J., 2001, MEASUREMENT SCI TECH, V12, P221; Bilgic M., 2007, 7 IEEE INT C DAT MIN, P381, DOI 10.1109/ICDMW.2007.35; Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830; Colizza V, 2006, NAT PHYS, V2, P110, DOI 10.1038/nphys209; Feng X., 2011, ARXIV11034919; Gallagher B, 2008, P 14 ACM SIGKDD INT, P256, DOI 10.1145/1401890.1401925; Guimera R, 2009, P NATL ACAD SCI USA, V106, P22073, DOI 10.1073/pnas.0908366106; Guimera R, 2005, P NATL ACAD SCI USA, V102, P7794, DOI 10.1073/pnas.0407994102; Guimera R, 2007, NAT PHYS, V3, P63, DOI 10.1038/nphys489; HANLEY JA, 1982, RADIOLOGY, V143, P29; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Kossinets G, 2006, SOC NETWORKS, V28, P247, DOI 10.1016/j.socnet.2005.07.002; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; [刘宏鲲 LIU HongKun], 2011, [中国科学. 物理学, 力学, 天文学, Scientia Sinica Physica, Mechanica & Astronomica], V41, P816; Liu WP, 2010, EPL-EUROPHYS LETT, V89, DOI 10.1209/0295-5075/89/58007; Lu LY, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.046122; Lu LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027; Newman MEJ, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.208701; Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104; Popescul A., 2003, P WORKSH LEARN STAT, P81; Sarukkai RR, 2000, COMPUT NETW, V33, P377, DOI 10.1016/S1389-1286(00)00044-X; Stumpf MPH, 2008, P NATL ACAD SCI USA, V105, P6959, DOI 10.1073/pnas.0708078105; Ulanowicz R. E., 2000, TS19199; Ulanowicz R. E., 1998, 98123 CBL; von Mering C, 2002, NATURE, V417, P399; Wang C., 2007, 7 IEEE INT C DAT MIN, P1; Wang W.-Q., EVALUATING NET UNPUB; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; WHITE JG, 1986, PHILOS T ROY SOC B, V314, P1, DOI 10.1098/rstb.1986.0056; Xie YB, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.036106; Yu HY, 2008, SCIENCE, V322, P104, DOI 10.1126/science.1158684; Zhang QM, 2010, INT J MOD PHYS C, V21, P813, DOI 10.1142/S012918311001549X; Zhou T, 2009, EUR PHYS J B, V71, P623, DOI 10.1140/epjb/e2009-00335-8; Cui AX, 2011, ACTA PHYS SIN-CH ED, V60; ZHU J, 2002, LNCS, V2311, P55	38	6	7	EPL ASSOCIATION, EUROPEAN PHYSICAL SOCIETY	MULHOUSE	6 RUE DES FRERES LUMIERE, MULHOUSE, 68200, FRANCE	0295-5075			EPL-EUROPHYS LETT	EPL	NOV	2011	96	4							48007	10.1209/0295-5075/96/48007		6	Physics, Multidisciplinary	Physics	852CC	WOS:000297322500047	
J	Towey, DJ; Bain, PG; Nijran, KS				Towey, David J.; Bain, Peter G.; Nijran, Kuldip S.			Automatic classification of I-123-FP-CIT (DaTSCAN) SPECT images	NUCLEAR MEDICINE COMMUNICATIONS			English	Article						automatic classification; DaTSCAN; diagnostic accuracy; fluoropropyl-carbomethoxy-3 beta-4-iodophenyltropane; ioflupane; naive Bayes; principal component analysis; singular value decomposition	DOPAMINE TRANSPORTER SPECT; PARKINSONS-DISEASE; PRINCIPAL-COMPONENTS; STATISTICAL VARIABLES; COMPUTED-TOMOGRAPHY; ALZHEIMERS-DISEASE; QUANTIFICATION; RADIONUCLIDE; COMPLEX	Introduction We present a method of automatic classification of I-123-fluoropropyl-carbomethoxy-3 beta-4-iodophenyltropane (FP-CIT) images. This technique uses singular value decomposition (SVD) to reduce a training set of patient image data into vectors in feature space (D space). The automatic classification techniques use the distribution of the training data in D space to define classification boundaries. Subsequent patients can be mapped into D space, and their classification can be automatically given. Methods The technique has been tested using 116 patients for whom the diagnosis of either Parkinsonian syndrome or non-Parkinsonian syndrome has been confirmed from post I-123-FP-CIT imaging follow-up. The first three components were used to define D space. Two automatic classification tools were used, naive Bayes (NB) and group prototype. A leave-one-out cross-validation was performed to repeatedly train and test the automatic classification system. Four commercially available systems for the classification were tested using the same clinical database. Results The proposed technique combining SVD and NB correctly classified 110 of 116 patients (94.8%), with a sensitivity of 93.7% and specificity of 97.3%. The combination of SVD and an automatic classifier performed as well or better than the commercially available systems. Conclusion The combination of data reduction by SVD with automatic classifiers such as NB can provide good diagnostic accuracy and may be a useful adjunct to clinical reporting. Nucl Med Commun 32:699-707 (C) 2011 Wolters Kluwer Health vertical bar Lippincott Williams & Wilkins.	[Towey, David J.; Nijran, Kuldip S.] Imperial Coll Healthcare NHS Trust, Radiol Sci Unit, London W6 8RF, England; [Bain, Peter G.] Imperial Coll Healthcare NHS Trust, Dept Neurol, London W6 8RF, England	Towey, DJ (reprint author), Imperial Coll Healthcare NHS Trust, Radiol Sci Unit, 1st Floor N Wing,Fulham Palace Rd, London W6 8RF, England.	david.towey@imperial.nhs.uk					BARBER DC, 1980, PHYS MED BIOL, V25, P283, DOI 10.1088/0031-9155/25/2/008; BARBER DC, 1976, PHYS MED BIOL, V21, P792, DOI 10.1088/0031-9155/21/5/008; Booij J, 1997, J NEUROL NEUROSUR PS, V62, P133, DOI 10.1136/jnnp.62.2.133; Booij J, 1998, J NUCL MED, V39, P1879; Booij J, 1997, EUR J NUCL MED, V24, P68, DOI 10.1007/BF01728311; CHANG LT, 1978, IEEE T NUCL SCI, V25, P638, DOI 10.1109/TNS.1978.4329385; Colloby SJ, 2004, NEUROIMAGE, V23, P956, DOI 10.1016/j.neuroimage.2004.06.045; Friston K.J., 2006, STAT PARAMETRIC MAPP; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888; HOUSTON AS, 1994, J NUCL MED, V35, P239; Koch W, 2005, J NUCL MED, V46, P1109; Koch W, 2005, J NUCL MED, V46, P1804; Lopez M, 2009, ELECTRON LETT, V45, P389, DOI 10.1049/el.2009.0176; Lopez MM, 2009, NEUROSCI LETT, V464, P233, DOI 10.1016/j.neulet.2009.08.061; Lozza C, 2004, HUM BRAIN MAPP, V22, P236, DOI 10.1002/hbm.20033; Morton RJ, 2005, NUCL MED COMMUN, V26, P1139, DOI 10.1097/00006231-200512000-00015; NIJRAN KS, 1985, PHYS MED BIOL, V30, P1315, DOI 10.1088/0031-9155/30/12/005; NIJRAN KS, 1984, ANAL DYNAMIC RADIONU; Pearson K, 1901, PHILOS MAG, V2, P559; Pedro D., 1997, MACH LEARN, V29, P103; Pereira F, 2009, NEUROIMAGE, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007; Rasband W.S., 1997, IMAGE J; Rorden C, 2000, BEHAV NEUROL, V12, P191; Staff RT, 2009, NUCL MED COMMUN, V30, P194, DOI 10.1097/MNM.0b013e328314b863; Tossici-Bolt L, 2006, EUR J NUCL MED MOL I, V33, P1491, DOI 10.1007/s00259-006-0155-x; TOWEY DJ, 2009, EUR J NUCL MED MOL I, V36, pOP189; TOWEY DJ, 2008, ANN C EUR ASS NUCL M, V35, pS336; Winogrodzka A, 2001, J NEURAL TRANSM, V108, P1011, DOI 10.1007/s007020170019	29	6	6	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	0143-3636			NUCL MED COMMUN	Nucl. Med. Commun.	AUG	2011	32	8					699	707		10.1097/MNM.0b013e328347cd09		9	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	786NU	WOS:000292316000006	
J	Gershman, SJ; Blei, DM; Pereira, F; Norman, KA				Gershman, Samuel J.; Blei, David M.; Pereira, Francisco; Norman, Kenneth A.			A topographic latent source model for fMRI data	NEUROIMAGE			English	Article						fMRI; Bayesian; Spatial; MCMC; Multivariate; Naive Bayes	PATTERN-ANALYSIS; SPATIAL PRIORS; ACTIVATION; INFERENCE; IMAGES; MEMORY; STATES; ICA	We describe and evaluate a new statistical generative model of functional magnetic resonance imaging (fMRI) data. The model, topographic latent source analysis (TLSA), assumes that fMRI images are generated by a covariate-dependent superposition of latent sources. These sources are defined in terms of basis functions over space. The number of parameters in the model does not depend on the number of voxels, enabling a parsimonious description of activity patterns that avoids many of the pitfalls of traditional voxel-based approaches. We develop a multi-subject extension where latent sources at the subject-level are perturbations of a group-level template. We evaluate TLSA according to prediction, reconstruction and reproducibility. We show that it compares favorably to a Naive Bayes model while using fewer parameters. We also describe a hypothesis testing framework that can be used to identify significant latent sources. (C) 2011 Elsevier Inc. All rights reserved.	[Gershman, Samuel J.; Pereira, Francisco; Norman, Kenneth A.] Princeton Univ, Dept Psychol, Princeton, NJ 08540 USA; [Gershman, Samuel J.; Pereira, Francisco; Norman, Kenneth A.] Princeton Univ, Inst Neurosci, Princeton, NJ 08540 USA; [Blei, David M.] Princeton Univ, Dept Comp Sci, Princeton, NJ 08540 USA	Gershman, SJ (reprint author), Princeton Univ, Dept Psychol, Princeton, NJ 08540 USA.	sjgershm@princeton.edu; blei@cs.princeton.edu; fpereira@princeton.edu; knorman@princeton.edu			NSF/NIH [NSF IIS-1009542]; ONR [175-6343]; NSF [0745520]; AFOSR [09NL202]; Alfred P. Sloan foundation; Google; National Institute of Mental Health; National Science Foundation	We thank Per Sederberg, Matt Hoffmann, Richard Socher, Katherine Heller, Martin Lindquist and Michael Todd for helpful discussions. We are also grateful to Rob Mason and Marcel Just of the Center for Cognitive Brain Imaging at Carnegie-Mellon University for sharing the TB dataset. This research was supported by the NSF/NIH Collaborative Research in Computational Neuroscience Program, grant number NSF IIS-1009542. David M. Blei is supported by ONR 175-6343, NSF CAREER 0745520, AFOSR 09NL202, the Alfred P. Sloan foundation, and a grant from Google. Samuel J. Gershman was supported by a Quantitative Computational Neuroscience training grant from the National Institute of Mental Health as well as a National Science Foundation Graduate Research Fellowship.	BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bishop CM, 2006, PATTERN RECOGNITION; Bowman FD, 2008, NEUROIMAGE, V39, P146, DOI 10.1016/j.neuroimage.2007.08.012; CARDOSO J, 2002, SIGNAL PROCESS LETT, V4, P112; CHEN X, 2006, HUM BRAIN MAPP, V27; DUANE A, 1987, PHYS LETT B, V195, P216; Flandin G, 2007, NEUROIMAGE, V34, P1108, DOI 10.1016/j.neuroimage.2006.10.005; Frank E, 2000, MACH LEARN, V41, P5, DOI 10.1023/A:1007670802811; Friston KJ, 2003, NEUROIMAGE, V19, P1240, DOI 10.1016/S1053-8119(03)00144-7; Friston KJ, 1996, NEUROIMAGE, V4, P223, DOI 10.1006/nimg.1996.0074; Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Friston KJ, 2002, NEUROIMAGE, V16, P465, DOI 10.1006/nimg.2002.1090; Harrison LM, 2007, NEUROIMAGE, V38, P677, DOI 10.1016/j.neuroimage.2007.07.032; Hastie T. J., 2001, ELEMENTS STAT LEARNI; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Haynes JD, 2006, NAT REV NEUROSCI, V7, P523, DOI 10.1038/nrn1931; Hill Jennifer, 2007, DATA ANAL USING REGR; Hu DW, 2005, NEUROIMAGE, V25, P746, DOI 10.1016/j.neuroimage.2004.12.031; HYVARINEN A, 2002, NEURAL NETW IEEE T, V10, P626; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kiebel SJ, 2000, NEUROIMAGE, V11, P656, DOI 10.1006/nimg.1999.0542; Kim S, 2010, IEEE T MED IMAGING, V29, P1260, DOI 10.1109/TMI.2010.2044045; LaBar KS, 1999, NEUROIMAGE, V10, P695, DOI 10.1006/nimg.1999.0503; LaConte S, 2003, NEUROIMAGE, V18, P10, DOI 10.1006/nimg.2002.1300; Lindeberg T., 1994, J APPL STAT, V21, P225, DOI DOI 10.1080/757582976; Lindeberg T, 1999, HUM BRAIN MAPP, V7, P166, DOI 10.1002/(SICI)1097-0193(1999)7:3<166::AID-HBM3>3.0.CO;2-I; McDuff SGR, 2009, J NEUROSCI, V29, P508, DOI 10.1523/JNEUROSCI.3587-08.2009; McKeown MJ, 1998, HUM BRAIN MAPP, V6, P368, DOI 10.1002/(SICI)1097-0193(1998)6:5/6<368::AID-HBM7>3.0.CO;2-E; METROPOLIS N, 1949, J AM STAT ASSOC, V44, P335, DOI 10.2307/2280232; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058; Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005; O'Toole AJ, 2007, J COGNITIVE NEUROSCI, V19, P1735, DOI 10.1162/jocn.2007.19.11.1735; Penny WD, 2005, NEUROIMAGE, V24, P350, DOI 10.1016/j.neuroimage.2004.08.034; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Robert C. P., 2004, MONTE CARLO STAT MET; Svensen M, 2002, NEUROIMAGE, V16, P551, DOI 10.1006/nimg.2002.1122; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Wagenmakers EJ, 2006, PSYCHOL SCI, V17, P641, DOI 10.1111/j.1467-9280.2006.01757.x; Woolrich MW, 2004, IEEE T MED IMAGING, V23, P213, DOI 10.1109/TMI.2003.823065; Worsley KJ, 1996, HUM BRAIN MAPP, V4, P58, DOI 10.1002/(SICI)1097-0193(1996)4:1&lt;58::AID-HBM4&gt;3.0.CO;2-O; Xu L, 2009, BIOMETRICS, V65, P1041, DOI 10.1111/j.1541-0420.2008.01190.x	42	6	6	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119			NEUROIMAGE	Neuroimage	JUL 1	2011	57	1					89	100		10.1016/j.neuroimage.2011.04.042		12	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	777MC	WOS:000291624100012	
J	Flores, MJ; Gamez, JA; Martinez, AM; Puerta, JM				Flores, M. Julia; Gamez, Jose A.; Martinez, Ana M.; Puerta, Jose M.			Handling numeric attributes when comparing Bayesian network classifiers: does the discretization method matter?	APPLIED INTELLIGENCE			English	Article; Proceedings Paper	23rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligence Systems (IEA/AIE 2010)	2010	Cordoba, SPAIN	Univ Cordoba		Discretization; Bayesian classifiers; AODE; Naive Bayes		Within the framework of Bayesian networks (BNs), most classifiers assume that the variables involved are of a discrete nature, but this assumption rarely holds in real problems. Despite the loss of information discretization entails, it is a direct easy-to-use mechanism that can offer some benefits: sometimes discretization improves the run time for certain algorithms; it provides a reduction in the value set and then a reduction in the noise which might be present in the data; in other cases, there are some Bayesian methods that can only deal with discrete variables. Hence, even though there are many ways to deal with continuous variables other than discretization, it is still commonly used. This paper presents a study of the impact of using different discretization strategies on a set of representative BN classifiers, with a significant sample consisting of 26 datasets. For this comparison, we have chosen Naive Bayes (NB) together with several other semi-Naive Bayes classifiers: Tree-Augmented Naive Bayes (TAN), k-Dependence Bayesian (KDB), Aggregating One-Dependence Estimators (AODE) and Hybrid AODE (HAODE). Also, we have included an augmented Bayesian network created by using a hill climbing algorithm (BNHC). With this comparison we analyse to what extent the type of discretization method affects classifier performance in terms of accuracy and bias-variance discretization. Our main conclusion is that even if a discretization method produces different results for a particular dataset, it does not really have an effect when classifiers are being compared. That is, given a set of datasets, accuracy values might vary but the classifier ranking is generally maintained. This is a very useful outcome, assuming that the type of discretization applied is not decisive future experiments can be d times faster, d being the number of discretization methods considered.	[Flores, M. Julia; Gamez, Jose A.; Martinez, Ana M.; Puerta, Jose M.] Univ Castilla La Mancha, Comp Syst Dept, Intelligent Syst & Data Min SIMD, Albacete, Spain	Martinez, AM (reprint author), Univ Castilla La Mancha, Comp Syst Dept, Intelligent Syst & Data Min SIMD, I3A, Albacete, Spain.	julia.flores@uclm.es; jose.gamez@uclm.es; anamaria.martinez@uclm.es; jose.puerta@uclm.es					Asuncion A., 2007, UCI MACHINE LEARNING; Bouckaert R, 2005, BAYESIAN NETWORK CLA; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Casella G., 2001, STAT INFERENCE; Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Fayyad U.M., 1993, P 13 INT JOINT C ART, P1022; Fisher R. A., 1959, STAT METHODS SCI INF; Flores JL, 2007, INTELL DATA ANAL, V11, P525; Flores M. J., 2009, ACM INT C P SERIES, V382, P40; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Garcia S., 2009, J MACHINE LEARNING R, V9, P2677; HSU CN, 2000, ICML, P399; Hsu CN, 2003, MACH LEARN, V53, P235, DOI 10.1023/A:1026367023636; IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904; John G.H., 1995, ESTIMATING CONTINUOU, P338; Keogh E., 1999, P 7 INT WORKSH ART I, P225; Nemenyi P., 1963, THESIS; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Webb G. I., 2002, ESTIMATING BIAS VARI; Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6; Weiss N, 2002, INTRO STAT; Witten IH, 2005, DATA MINING PRACTICA; Yang Y, 2009, MACH LEARN, V74, P39, DOI 10.1007/s10994-008-5083-5; Zheng F., 2005, P 4 AUSTR DAT MIN C, P141; Zheng ZJ, 2000, MACH LEARN, V41, P53, DOI 10.1023/A:1007613203719	28	6	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X			APPL INTELL	Appl. Intell.	JUN	2011	34	3					372	385		10.1007/s10489-011-0286-z		14	Computer Science, Artificial Intelligence	Computer Science	759FY	WOS:000290227300005	
J	Zhang, ZQ; Ye, QA; Zhang, ZL; Li, YJ				Zhang, Ziqiong; Ye, Qiang; Zhang, Zili; Li, Yijun			Sentiment classification of Internet restaurant reviews written in Cantonese	EXPERT SYSTEMS WITH APPLICATIONS			English	Review						Sentiment classification; Online review; Cantonese; Restaurant; Machine learning	WORD-OF-MOUTH; TALK	Cantonese is an important dialect in some regions of Southern China. Local online users often represent their opinions and experiences on the web with written Cantonese. Although the information in those reviews is valuable to potential consumers and sellers, the huge amount of web reviews make it difficult to give an unbiased evaluation to a product and the Cantonese reviews are unintelligible for Mandarin Chinese speakers. In this paper, standard machine learning techniques naive Bayes and SVM are incorporated into the domain of online Cantonese-written restaurant reviews to automatically classify user reviews as positive or negative. The effects of feature presentations and feature sizes on classification performance are discussed. We find that accuracy is influenced by interaction between the classification models and the feature options. The naive Bayes classifier achieves as well as or better accuracy than SVM. Character-based bigrams are proved better features than unigrams and trigrams in capturing Cantonese sentiment orientation. (C) 2010 Elsevier Ltd. All rights reserved.	[Zhang, Ziqiong; Ye, Qiang; Zhang, Zili; Li, Yijun] Harbin Inst Technol, Dept Management Sci & Engn, Harbin 150001, Peoples R China	Zhang, ZQ (reprint author), Harbin Inst Technol, Dept Management Sci & Engn, Harbin 150001, Peoples R China.	xiaojia0459@yahoo.com.cn			National Science Foundation of China [70971033, 70890082];  [NCET-08-0172]	This study was partially funded by National Science Foundation of China (70971033, 70890082) and NCET-08-0172.	Bauer R. S., 2002, J CHINESE LINGUISTIC, V18; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cheung C, 2004, P 8 PAC AS C INF SYS, P2100; Das SR, 2007, MANAGE SCI, V53, P1375, DOI 10.1287/mnsc.1070.0704; Dave K., 2003, P 12 INT C WORLD WID, P519, DOI DOI 10.1145/775152.775226; Dellarocas C, 2003, MANAGE SCI, V49, P1407, DOI 10.1287/mnsc.49.10.1407.17308; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; FUJII A., 2006, P WORKSH SENT SUBJ T, P15, DOI 10.3115/1654641.1654644; Goldenberg J, 2001, MARKET LETT, V12, P211, DOI 10.1023/A:1011122126881; Gretzel U., 2008, INFORM COMMUNICATION, P35, DOI DOI 10.1007/978-3-211-77280-5; Hatzivassiloglou V., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640; Hearst M.A., 1992, TEXT BASED INTELLIGE; Horrigan J., 2008, ONLINE SHOPPING; Huettner A., 2000, ACL 2000 COMPANION V, P26; Joachims Thorsten, 1998, 10 EUR C MACH LEARN, P137; Ku L.-W, 2006, AAAI 2006 SPRING S C, P100; Liu B., 2005, P 14 INT WORLD WID W, P10; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Mitchell T.M., 1997, MACHINE LEARNING; Pan B., 2007, Journal of Travel Research, V46, P35, DOI 10.1177/0047287507302378; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Read J., 2005, P ACL STUD RES WORKS, P43, DOI 10.3115/1628960.1628969; Snow D., 2004, CANTONESE WRITTEN LA; [唐慧丰 TANG Huifeng], 2007, [中文信息学报, Journal of Chinese Information Processing], V21, P88; TONG RAN, 2001, WORKSH NOT SIGIR 200; Turney P., 2002, P 40 ANN M ASS COMP, P417, DOI DOI 10.3115/1073083.1073153; Yang Y., 1999, 22 ANN INT ACM SIGIR, P42; Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035; Yu B, 2008, LIT LINGUIST COMPUT, V23, P327, DOI 10.1093/llc/fqn015	29	6	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	JUN	2011	38	6					7674	7682		10.1016/j.eswa.2010.12.147		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	734OJ	WOS:000288343900142	
J	Shi, L; Ma, XM; Xi, L; Duan, QG; Zhao, JY				Shi, Lei; Ma, Xinming; Xi, Lei; Duan, Qiguo; Zhao, Jingying			Rough set and ensemble learning based semi-supervised algorithm for text classification	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Text classification; Rough set; Ensemble learning; Semi-supervised classification		Text classification has received more and more attention due to the enormous growth of digital content available on-line. This paper investigates the design of two-class text classifiers using positive and unlabeled data only. The specialty of this problem is that there is no labeled negative example for learning, which makes traditional text classification techniques inapplicable. In this paper, a novel semi-supervised classification algorithm based on tolerance rough set and ensemble learning is proposed. Tolerance rough set theory is used to approximate concepts existed in documents and extract an initial set of negative example. Then, SVM, Rocchio and Naive Bayes algorithms are used as base classifiers to construct an ensemble classifier, which runs iteratively and exploits margins between positive and negative data to progressively improve the approximation of negative data. Thus, the class boundary eventually converges to the true boundary of the positive class in the feature space. An experimental evaluation of different methods is carried out on two common text corpora, i.e., the Reuters-21578 collection and the WebKB collection. The experimental results indicate that the proposed method achieves significant performance improvement. (c) 2010 Elsevier Ltd. All rights reserved.	[Shi, Lei; Ma, Xinming; Xi, Lei] HeNan Agr Univ, Coll Informat & Management Sci, Zhengzhou 450002, Peoples R China; [Duan, Qiguo] Zhengzhou Commod Exchange, Zhengzhou 450008, Peoples R China; [Zhao, Jingying] Dalian Nationalities Univ, Dept Comp Sci & Engn, Dalian 116600, Peoples R China	Shi, L (reprint author), HeNan Agr Univ, Coll Informat & Management Sci, Zhengzhou 450002, Peoples R China.	sleicn@126.com			National Natural Science Foundation of China [60803096]; Fundamental Research Funds for the Central Universities; Dalian IT teachers project	The authors would like to thank the anonymous reviewers for their helpful comments and suggestions. This work was supported by the National Natural Science Foundation of China [Grant number 60803096], and the Fundamental Research Funds for the Central Universities, and Dalian IT teachers project.	COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENIS F, 1998, P 9 INT C ALG LEARN, P112; Dietterich T., 2000, LECT NOTES COMPUTER, P1; DUAN QG, 2007, 11 PAC AS C KNOWL DI, P481; JARVINEN J, 2000, ROUGH SETS CURRENT T, P182; Joachims T., 2001, P 24 ANN INT ACM SIG, P128, DOI 10.1145/383952.383974; Joachims T., 1997, P 14 INT C MACH LEAR, P143; KOWRON A, 1996, FUNDAMENTA INFORM, V27, P245; LETOUZEY F, 2000, P INT C ALG LEARN TH, P11; Lewis D.D., 1998, 10 EUR C MACH LEARN, P4; LIU B, 2002, P 19 INT C MACH LEAR, P8; Manevitz L., 2001, J MACHINE LEARNING R, V2, P139; Miao DQ, 2009, EXPERT SYST APPL, V36, P9168, DOI 10.1016/j.eswa.2008.12.026; NGO CL, 2004, PKDD 2004, P515; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Yang Y., 1999, 22 ANN INT ACM SIGIR, P42; YU H, 2004, IEEE T KNOWL DATA EN, V6, P70	19	6	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	MAY	2011	38	5					6300	6306		10.1016/j.eswa.2010.11.069		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	722GK	WOS:000287419900188	
J	Ozel, SA				Ozel, Selma Ayse			A Web page classification system based on a genetic algorithm using tagged-terms as features	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Web mining; Classification; Classifier learning; Genetic algorithms	TEXT CLASSIFICATION; DOCUMENT-RETRIEVAL; FEATURE-SELECTION	The incredible increase in the amount of information on the World Wide Web has caused the birth of topic specific crawling of the Web. During a focused crawling process, an automatic Web page classification mechanism is needed to determine whether the page being considered is on the topic or not. In this study, a genetic algorithm (GA) based automatic Web page classification system which uses both HTML tags and terms belong to each tag as classification features and learns optimal classifier from the positive and negative Web pages in the training dataset is developed. Our system classifies Web pages by simply computing similarity between the learned classifier and the new Web pages. In the existing GA-based classifiers, only HTML tags or terms are used as features, however in this study both of them are taken together and optimal weights for the features are learned by our GA. It was found that, using both HTML tags and terms in each tag as separate features improves accuracy of classification, and the number of documents in the training dataset affects the accuracy such that if the number of negative documents is larger than the number of positive documents in the training dataset, the classification accuracy of our system increases up to 95% and becomes higher than the well known Naive Bayes and k nearest neighbor classifiers. (C) 2010 Elsevier Ltd. All rights reserved.	Cukurova Univ, Dept Comp Engn, TR-01330 Adana, Turkey	Ozel, SA (reprint author), Cukurova Univ, Dept Comp Engn, TR-01330 Adana, Turkey.	saozel@cu.edu.tr			Cukurova University Academic Research Project Unit [MMF2008BAP6]	This work was supported by Cukurova University Academic Research Project Unit under the Grant No. MMF2008BAP6.	Altingovde IS, 2001, LECT NOTES COMPUT SC, V2113, P699; Baeza-Yates R., 1999, MODERN INFORM RETRIE; Bai RJ, 2007, LECT NOTES COMPUT SC, V4476, P256; Boughanem M., 1999, Information Retrieval, V1, DOI 10.1023/A:1009931404333; Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3; Chen CM, 2009, EXPERT SYST APPL, V36, P260, DOI 10.1016/j.eswa.2007.09.008; CHEN H, 1995, J MANAGEMENT INFORMA, V11, P7; Chen RC, 2006, EXPERT SYST APPL, V31, P427, DOI 10.1016/j.eswa.2005.09.079; Craven M, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P509; GORDON M, 1988, COMMUN ACM, V31, P1208, DOI 10.1145/63039.63044; Han Jiawei, 2006, DATA MINING CONCEPTS; Holland J.H., 1992, ADAPTATION NATURAL A; Kim S, 2003, APPL INTELL, V18, P243, DOI 10.1023/A:1023293820057; Liu H, 2003, LECT NOTES COMPUT SC, V2762, P173; Menczer F., 2004, ACM T INTERNET TECHN, V4, P378, DOI 10.1145/1031114.1031117; Michalewicz Z., 1996, GENETIC ALGORITHM DA; Ozalp SA, 2006, LECT NOTES COMPUT SC, V3743, P535, DOI 10.1007/11666806_61; Ozel SA, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P441; Pietramala A, 2008, LECT NOTES ARTIF INT, V5212, P188, DOI 10.1007/978-3-540-87481-2_13; PINKERTON B, 1994, 2 INT WWW C; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; DEBRA PME, 1994, COMPUT NETWORKS ISDN, V27, P183, DOI 10.1016/0169-7552(94)90132-5; QI D, 2004, IRI, P241; Qi XG, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459357; Ribeiro A, 2003, LECT NOTES ARTIF INT, V2663, P103; Robertson AM, 1996, J DOC, V52, P405, DOI 10.1108/eb026973; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Selamat A, 2004, INFORM SCIENCES, V158, P69, DOI 10.1016/j.ins.2003.03.003; Trotman A, 2005, INFORM PROCESS MANAG, V41, P243, DOI 10.1016/j.ipm.2003.10.003; Wakaki T., 2006, Web Intelligence and Agent Systems, V4	30	6	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	APR	2011	38	4					3407	3415		10.1016/j.eswa.2010.08.126		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	715RY	WOS:000286904600053	
J	Ravikumar, S; Ramachandran, KI; Sugumaran, V				Ravikumar, S.; Ramachandran, K. I.; Sugumaran, V.			Machine learning approach for automated visual inspection of machine components	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Feature extraction; Decision tree; Naive Bayes; Histogram features; Machine learning; Visual inspection	TOOL WEAR; VISION SYSTEM	Visual inspection on the surface of components is a main application of machine vision. Visual inspection finds its application in identifying defects such as scratches, cracks bubbles and measurement of cutting tool wear and welding quality. Machine learning approach to machine vision helps in automating the design process of machine vision systems. This approach involves image acquisition, preprocessing, feature extraction and classification. Study shows a library of features, and classifiers are available to classify the data. However, only the best combination of them can yield the highest classification accuracy. In this study, images with different known conditions were acquired, preprocessed, and histogram features were extracted. The classification accuracies of C4.5 classifier algorithm and Naive Bayes algorithm were compared, and results are reported. The study shows that C4.5 algorithm performs better. (C) 2010 Elsevier Ltd. All rights reserved.	[Ravikumar, S.; Ramachandran, K. I.] Amrita Vishwa Vidyapeetham, Dept Mech Engn, Coimbatore 641105, Tamil Nadu, India; [Sugumaran, V.] SRM Univ, Dept Mechatron Engn, Madras 603203, Tamil Nadu, India	Ravikumar, S (reprint author), Amrita Vishwa Vidyapeetham, Dept Mech Engn, Coimbatore 641105, Tamil Nadu, India.	er.ravikumars@gmail.com; ki_ram@ettimadai.amrita.edu; v_sugu@yahoo.com					ALHABAIBEH A, 2000, J MAT PROCESSING NOV, DOI DOI 10.1016/S0166-3615(96)00075-9; Bradley C, 2001, INT J ADV MANUF TECH, V17, P435, DOI 10.1007/s001700170161; Eberhardt M, 2008, COMPUT ELECTR ENG, V34, P111, DOI 10.1016/j.compeleceng.2007.10.006; Golnabi H, 2007, ROBOT CIM-INT MANUF, V23, P630, DOI 10.1016/j.rcim.2007.02.005; HAZEM R, 1996, COMPUT IND ENG, V13, P27; Jurkovic J, 2005, INT J MACH TOOL MANU, V45, P1023, DOI 10.1016/j.ijmachtools.2004.11.030; Kurada S, 1997, TRIBOL INT, V30, P295, DOI 10.1016/S0301-679X(96)00058-8; Lasher B., 1993, Wescon/93 Conference Record (Cat. No.93RC0500-9), DOI 10.1109/WESCON.1993.488418; MANICKAVASAGAN A, 2008, COMPUTERS ELECT AGR; Pfeifer T, 2000, MEASUREMENT, V28, P209, DOI 10.1016/S0263-2241(00)00014-2; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Rosati G, 2009, OPT LASER ENG, V47, P320, DOI 10.1016/j.optlaseng.2007.11.011; Shahabi HH, 2009, INT J ADV MANUF TECH, V43, P11, DOI 10.1007/s00170-008-1688-x; SU JC, 2006, J MAT PROCESSING AUG, DOI DOI 10.1016/J.JMATPROTEC.2006.07.0011515; UKTU H, 1998, J BREWING I, V104, P351; WANG W, 2005, COMPUTERS IND; Wang WH, 2006, INT J MACH TOOL MANU, V46, P199, DOI 10.1016/j.ijmachtools.2005.04.006; WINTER P, 1996, AGR I CAN ANN C SASK; Witten IH, 2005, DATA MINING PRACTICA; Zhang J, 1998, COMPUT ELECTRON AGR, V19, P155, DOI 10.1016/S0168-1699(97)00041-0	20	6	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	APR	2011	38	4					3260	3266		10.1016/j.eswa.2010.09.012		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	715RY	WOS:000286904600038	
J	Humpherys, SL; Moffitt, KC; Burns, MB; Burgoon, JK; Felix, WF				Humpherys, Sean L.; Moffitt, Kevin C.; Burns, Mary B.; Burgoon, Judee K.; Felix, William F.			Identification of fraudulent financial statements using linguistic credibility analysis	DECISION SUPPORT SYSTEMS			English	Article						Financial fraud; Deception; Text mining; Classification; Fraud risk; SAS 99		The strategic use of deceptive language in managerial financial fraud is investigated with linguistic cues extracted from 202 publicly available financial disclosures. Those crafting fraudulent disclosures use more activation language, words, imagery, pleasantness, group references, and less lexical diversity than non-fraudulent ones. Writers of fraudulent disclosures may write more to appear credible while communicating less in actual content. A parsimonious model with Naive Bayes and C4.5 achieved the highest classification accuracy. Results support the potential use of linguistic analyses by auditors to flag questionable financial disclosures and to assess fraud risk under Statement on Auditing Standards No. 99. (C) 2010 Elsevier B.V. All rights reserved.	[Humpherys, Sean L.; Moffitt, Kevin C.; Burns, Mary B.] Univ Arizona, Ctr Management Informat Syst, Eller Coll Management, Tucson, AZ 85721 USA; [Burgoon, Judee K.] Univ Arizona, Res Ctr Management Informat, Tucson, AZ 85721 USA; [Burgoon, Judee K.] Univ Arizona, Ctr Identificat Technol Res, Tucson, AZ 85721 USA	Humpherys, SL (reprint author), Univ Arizona, Ctr Management Informat Syst, Eller Coll Management, Tucson, AZ 85721 USA.	shumpherys@cmi.arizona.edu			PricewaterhouseCoopers' INQuiries Research Grant	We are pleased to acknowledge the generous support from PricewaterhouseCoopers' INQuiries Research Grant.	Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BACK B, 2001, INT J ACCOUNTING INF, V2; BELL TB, 2000, AUDITING J PRACTICE, V19; BENEISH M, 1997, J ACCOUNTING PUBLIC, V16; BLOOMFIELD RJ, 2002, ACCOUNTING HORIZONS, V16; BOND CF, 2006, PERSONALITY SOCIAL P, V10; BULLER DB, 1996, COMMUNICATION THEORY, V6; BURGOON JK, 2010, GROUP DECISION NEGOT, V19; BURGOON JK, 2006, J LANGUAGE SOCIAL PS, V25; CALDERON TG, 2002, INT J ACCOUNTING INF, V3; COLE C, 2005, J ACCOUNTING LIT, V24; CULLINAN CP, 2002, CRITICAL PERSPECTIVE, V13; Dechow P., 1996, CONTEMP ACCOUNT RES, V13, P1; DEPAULO BM, 2003, PSYCHOL B, V129; DRISCOLL LN, 1994, POLICE STUDIES INT R, V17; EKMAN P, 1969, PSYCHIATRY, V32; Elliot R.K., 1980, MANAGEMENT FRAUD DET; Fanning K., 1995, P 11 C ART INT APPL; FANNING K, 1998, INT J INTELLIGENT SY, V7; FRANK E, 2003, P C UNC ART INT; Fuller C, 2006, P 12 AM C INF SYST A; FULLER CM, 2008, P 41 HAW ITN C SYST; GAGANIS C, 2007, EXPERT SYSTEMS APPL, V32; Hancock JT, 2008, DISCOURSE PROCESS, V45, P1, DOI 10.1080/01638530701739181; *INT FED ACC, 2002, 240 INT FED ACC; JOHNSON M, 1981, PSYCHOL REV, V88; JONES K, 2005, MARR SCH BYU ACC S; JUNKER M, 1999, 5 INT C DOC AN REC I; KAMINSKI KA, 2004, MANAGERIAL AUDITING, V19; KIRKOS E, 2007, EXPERT SYSTEMS APPL, V32; KLOPTCHENKO A, 2004, INTELLIGENT SYSTEMS, V12; KOTSIANTIS S, 2006, INT J COMPUTATIONAL, V3; Kovalerchuk B., 2005, DATA MIN KNOWL DISC; *KPMG, 2003, KPMG FRAUD SURV 2003; LEE TA, 1999, CONT ACCOUNTING RES, V16; LI F, 2008, J ACCOUNTING EC, V45; LIN JW, 2003, MANAGERIAL AUDITING, V18; LOEBBECKE JK, 1989, AUDITING-J PRACT TH, V9, P1; MANN S, 2002, LAW HUMAN BEHAV, V26; MCCORNACK SA, 1992, COMMUNICATION MONOGR, V59; Minkin A., 2008, LINGUISTIC DECEPTION; NEWMAN ML, 2003, PERSONALITY SOCIAL P, V29; Qin T., 2005, P 38 HAW INT C SYST; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Schilit Howard, 2002, FINANCIAL SHENANIGAN; SPATHIS CT, 2002, MANAGERIAL AUDITING, V17; SUMMERS SL, 1998, ACCOUNTING REV, V73; TAVCAR LR, 1998, CPA J, V10; *US SEC EXCH COMM, 2006, FORM 10 K; *US SEC EXCH COMM, ACC AUD ENF REL; van Rijsbergen C. J., 1979, INFORM RETRIEVAL; VRIJ A, 2000, J NONVERBAL BEHAV, V24; VRIJ A, 2005, PSYCHOL PUBLIC POLIC, V11; WALLACE WA, 1995, AUDITING; Wells J. T., 1997, OCCUPATIONAL FRAUD A; ZHANG D, 2004, IEEE T SYSTEMS MAN C, V34; ZHOU L, 2004, J MANAGEMENT INFORM, V20; ZHOU L, 2003, INTELLIGENCE SECURIT; ZHOU L, 2004, GROUP DECISION NEGOT, V13; Zuckerman Miron, 1981, ADV EXPT SOCIAL PSYC; FRAUD	61	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236			DECIS SUPPORT SYST	Decis. Support Syst.	FEB	2011	50	3			SI		585	594		10.1016/j.dss.2010.08.009		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	714ZY	WOS:000286851400005	
