PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT	PM
J	Zhu, QM; Wang, YJ; Zhao, DY; Li, SY; Billings, SA				Zhu, Quanmin; Wang, Yongji; Zhao, Dongya; Li, Shaoyuan; Billings, Stephen A.			Review of rational (total) nonlinear dynamic system modelling, identification, and control	INTERNATIONAL JOURNAL OF SYSTEMS SCIENCE			English	Article						validation; identification; U-model and U-control; rational (total) nonlinear dynamic systems; nonlinear rational model set	LEAST-SQUARES ALGORITHM; NON-LINEAR SYSTEMS; PARAMETER-ESTIMATION; CORRELATION TESTS; NEURAL-NETWORKS; VALIDATION; REPRESENTATIONS	This paper is a summary of the research development in the rational (total) nonlinear dynamic modelling over the last two decades. Total nonlinear dynamic systems are defined as those where the model parameters and input (controller outputs) are subject to nonlinear to the output. Previously, this class of models has been known as rational models, which is amodel that can be considered to belong to the nonlinear autoregressive moving average with exogenous input (NARMAX) model subset and is an extension of the well-known polynomial NARMAX model. The justification for using the rational model is that it provides a very concise and parsimonious representation for highly complex nonlinear dynamic systems and has excellent interpolatory and extrapolatory properties. However, model identification and controller design are much more challenging compared to the polynomial models. This has been a new and fascinating research trend in the area of mathematical modelling, control, and applications, but still within a limited research community. This paper brings several representative algorithms together, developed by the authors and their colleagues, to form an easily referenced archive for promotion of the awareness, tutorial, applications, and even further research expansion.	[Zhu, Quanmin] Univ W England, Dept Engn Design & Math, Bristol BS16 1QY, Avon, England; [Wang, Yongji] Huazhong Univ Sci & Technol, Dept Control Sci & Engn, Sch Automat, Wuhan 430074, Peoples R China; [Zhao, Dongya] China Univ Petr, Coll Chem Engn, Qingdao, Peoples R China; [Li, Shaoyuan] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200030, Peoples R China; [Billings, Stephen A.] Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield, S Yorkshire, England	Zhu, QM (reprint author), Univ W England, Dept Engn Design & Math, Bristol BS16 1QY, Avon, England.	quan.zhu@uwe.ac.uk			National Nature Science Foundation of China [61004080, 61273188]; Shandong Provincial Natural Science Foundation, China [ZR2011FM003]; Fundamental Research Funds for the Central Universities of China; Development of Key Technologies Project of Qingdao Economic and Technological Development Zone [2011-2-52]; Taishan Scholar Construction Engineering Special funding	This work is partially supported by the National Nature Science Foundation of China [grant number 61004080], [grant number 61273188]; Shandong Provincial Natural Science Foundation, China [grant number ZR2011FM003]; the Fundamental Research Funds for the Central Universities of China; Development of Key Technologies Project of Qingdao Economic and Technological Development Zone [grant number 2011-2-52]; Taishan Scholar Construction Engineering Special funding.	Ali SSA, 2010, ELECTR ENG, V91, P405, DOI 10.1007/s00202-010-0149-3; BILLINGS SA, 1991, INT J CONTROL, V54, P529, DOI 10.1080/00207179108934174; BILLINGS SA, 1994, INT J CONTROL, V59, P1439, DOI 10.1080/00207179408923140; Billings SA, 1998, INT J SYST SCI, V29, P223, DOI 10.1080/00207729808929516; BILLINGS SA, 1994, INT J CONTROL, V60, P1107, DOI 10.1080/00207179408921513; BILLINGS SA, 1995, INT J CONTROL, V62, P749, DOI 10.1080/00207179508921566; BILLINGS SA, 1989, INT J SYST SCI, V20, P467, DOI 10.1080/00207728908910143; Billings S. A., 1983, IEE P D, V130, P190; Bowker A. H., 1972, ENG STAT; CHEN S, 1989, INT J CONTROL, V49, P1013; DIMITROV SD, 1991, COMPUT CHEM ENG, V15, P657, DOI 10.1016/0098-1354(91)87027-7; Du W. X., 2012, J SYSTEMS CONTROL EN, V226, P27; FORD I, 1989, TECHNOMETRICS, V31, P49, DOI 10.2307/1270364; Gerald C. F., 1978, APPL NUMERICAL ANAL; HABER R, 1990, AUTOMATICA, V26, P651, DOI 10.1016/0005-1098(90)90044-I; Haykin S., 1994, NEURAL NETWORKS; JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2; Kambhampati C, 2000, AUTOMATICA, V36, P485, DOI 10.1016/S0005-1098(99)00173-9; KAMENSKI DI, 1993, COMPUT CHEM ENG, V17, P643, DOI 10.1016/0098-1354(93)80052-O; Kramer A. H., 1989, ADV NEURAL INFORMATI, V1, P40; LEUNG H, 1993, NEURAL COMPUT, V5, P928, DOI 10.1162/neco.1993.5.6.928; Ljung L., 1999, SYSTEM IDENTIFICATIO; Muhammad S., 2005, J SYSTEMS CONTROL EN, V219, P449; PONTON JW, 1993, COMPUT CHEM ENG, V17, P1047, DOI 10.1016/0098-1354(93)80086-3; PROLL T, 1994, AICHE J, V40, P269, DOI 10.1002/aic.690400207; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sontag E. D., 1979, POLYNOMIAL RESPONSE, V13; SONTAG ED, 1979, IEEE T CIRCUITS SYST, V26, P342, DOI 10.1109/TCS.1979.1084646; Wang L. X., 1994, ADAPTIVE FUZZY SYSTE; Xu Feng-xia, 2013, Control and Decision, V28; Zhang LF, 2009, IEEE T NEURAL NETWOR, V20, P1, DOI 10.1109/TNN.2008.2003223; Zhang LF, 2007, INT J SYST SCI, V38, P47, DOI 10.1080/00207720601014552; ZHU QM, 1991, IEE PROC-D, V138, P33; Zhu Q. M., 1991, Journal of Systems Engineering, V1; Zhu Q. M., 1989, THESIS U WARWICK COV; Zhu QM, 2010, INT J SYST SCI, V41, P1043, DOI 10.1080/00207720903199598; ZHU QM, 1993, INT J CONTROL, V57, P309, DOI 10.1080/00207179308934390; Zhu QM, 2007, AUTOMATICA, V43, P1519, DOI 10.1016/j.automatica.2007.02.010; Zhu QM, 2003, APPL MATH MODEL, V27, P169, DOI 10.1016/S0307-904X(02)00097-5; Zhu QM, 2005, APPL MATH MODEL, V29, P673, DOI 10.1016/j.apm.2004.10.008	40	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0020-7721	1464-5319		INT J SYST SCI	Int. J. Syst. Sci.	SEP 10	2015	46	12					2122	2133		10.1080/00207721.2013.849774		12	Automation & Control Systems; Computer Science, Theory & Methods; Operations Research & Management Science	Automation & Control Systems; Computer Science; Operations Research & Management Science	CH0JK	WOS:000353705500003		
J	Cheng, G; Han, JW; Guo, L; Liu, ZB; Bu, SH; Ren, JC				Cheng, Gong; Han, Junwei; Guo, Lei; Liu, Zhenbao; Bu, Shuhui; Ren, Jinchang			Effective and Efficient Midlevel Visual Elements-Oriented Land-Use Classification Using VHR Remote Sensing Images	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						Autoencoder; land-use classification; midlevel visual elements; part detectors; remote sensing images	SCENE CLASSIFICATION; OBJECT DETECTION; FEATURES	Land-use classification using remote sensing images covers a wide range of applications. With more detailed spatial and textural information provided in very high resolution (VHR) remote sensing images, a greater range of objects and spatial patterns can be observed than ever before. This offers us a new opportunity for advancing the performance of land-use classification. In this paper, we first introduce an effective midlevel visual elements-oriented land-use classification method based on "partlets," which are a library of pretrained part detectors used for midlevel visual elements discovery. Taking advantage of midlevel visual elements rather than low-level image features, a partlets-based method represents images by computing their responses to a large number of part detectors. As the number of part detectors grows, a main obstacle to the broader application of this method is its computational cost. To address this problem, we next propose a novel framework to train coarse-to-fine shared intermediate representations, which are termed "sparselets," from a large number of pretrained part detectors. This is achieved by building a single-hidden-layer autoencoder and a single-hidden-layer neural network with an L0-norm sparsity constraint, respectively. Comprehensive evaluations on a publicly available 21-class VHR land-use data set and comparisons with state-of-the-art approaches demonstrate the effectiveness and superiority of this paper.	[Cheng, Gong; Han, Junwei; Guo, Lei] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China; [Liu, Zhenbao; Bu, Shuhui] Northwestern Polytech Univ, Sch Aeronaut, Xian 710072, Peoples R China; [Ren, Jinchang] Univ Strathclyde, Fac Engn, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland	Han, JW (reprint author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.	junweihan2010@gmail.com			National Science Foundation of China [61401357, 61473231, 61333017, 61202185]; China Postdoctoral Science Foundation [2014M552491]	This work was supported in part by the National Science Foundation of China under Grant 61401357, Grant 61473231, Grant 61333017, and Grant 61202185, and in part by the China Postdoctoral Science Foundation under Grant 2014M552491. (Corresponding author: Junwei Han.)	Bhagavathy S, 2006, IEEE T GEOSCI REMOTE, V44, P3706, DOI 10.1109/TGRS.2006.881741; Chen Y, 2013, IEEE T GEOSCI REMOTE, V51, P217, DOI 10.1109/TGRS.2012.2201730; Cheng G, 2013, INT J REMOTE SENS, V34, P45, DOI 10.1080/01431161.2012.705443; Cheng G, 2013, ISPRS J PHOTOGRAMM, V85, P32, DOI 10.1016/j.isprsjprs.2013.08.001; Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002; Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444; Dalal N, 2005, PROC CVPR IEEE, P886; Doersch C., 2013, P C ADV NEUR INF PRO, P494; Doersch C., 2012, ACM T GRAPHIC, V31, P101; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fernando B, 2014, INT J COMPUT VISION, V108, P186, DOI 10.1007/s11263-014-0700-1; Han JW, 2014, ISPRS J PHOTOGRAMM, V89, P37, DOI 10.1016/j.isprsjprs.2013.12.011; Han J., IEEE T CIRC IN PRESS; Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218; Huang X, 2009, IEEE GEOSCI REMOTE S, V6, P393, DOI 10.1109/LGRS.2009.2014398; Kim M, 2009, PHOTOGRAMM ENG REM S, V75, P819; Lazebnik S., 2006, P IEEE C COMP VIS PA, P2169; Li F.-F., 2005, P 2005 IEEE COMP SOC, P524; Li HT, 2010, INT J REMOTE SENS, V31, P1453, DOI 10.1080/01431160903475266; Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115; Longbotham N, 2012, IEEE T GEOSCI REMOTE, V50, P1155, DOI 10.1109/TGRS.2011.2165548; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2009, P 26 ANN INT C MACH, P689; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Moustakidis S, 2012, IEEE T GEOSCI REMOTE, V50, P149, DOI 10.1109/TGRS.2011.2159726; Munoz-Mari J, 2012, IEEE T GEOSCI REMOTE, V50, P3751, DOI 10.1109/TGRS.2012.2185504; Ng A., 2010, CS294A LECT NOTES SP; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.2307/2006193; Rosasco L, 2004, NEURAL COMPUT, V16, P1063, DOI 10.1162/089976604773135104; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418; Shao L, 2014, IEEE T NEUR NET LEAR, V25, P2303, DOI 10.1109/TNNLS.2014.2308519; Singh S., 2012, P EUR C COMP VIS, P73; Song H. O., 2012, P EUR C COMP VIS, P802; Tang J, 2014, COMPUT VIS IMAGE UND, V124, P91, DOI 10.1016/j.cviu.2014.02.007; Tuia D, 2014, IEEE T GEOSCI REMOTE, V52, P6062, DOI 10.1109/TGRS.2013.2294724; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Yang Y, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1465; Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829; Zhang DW, 2015, IEEE GEOSCI REMOTE S, V12, P701, DOI 10.1109/LGRS.2014.2358994; Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3241, DOI 10.1109/TIP.2014.2328894; Zheng XW, 2013, IEEE GEOSCI REMOTE S, V10, P652, DOI 10.1109/LGRS.2012.2216499; Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y	43	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892	1558-0644		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	AUG	2015	53	8					4238	4249		10.1109/TGRS.2015.2393857		12	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	CE3XQ	WOS:000351763800009		
J	Liu, MY; Li, SX; Shan, SG; Chen, XL				Liu, Mengyi; Li, Shaoxin; Shan, Shiguang; Chen, Xilin			AU-inspired Deep Networks for Facial Expression Feature Learning	NEUROCOMPUTING			English	Article						Facial expression recognition; AU-inspired Deep Networks (AUDN); Micro-Action-Pattern; Receptive field; Group-wise sub-network learning	CLASSIFICATION; RECOGNITION	Most existing technologies for facial expression recognition utilize off-the-shelf feature extraction methods for classification. In this paper, aiming at learning better features specific for expression representation, we propose to construct a deep architecture, AU-inspired Deep Networks (AUDN), inspired by the psychological theory that expressions can be decomposed into multiple facial Action Units (AUs). To fully exploit this inspiration but avoid detecting AUs, we propose to automatically learn: (1) informative local appearance variation; (2) optimal way to combining local variation and (3) high level representation for final expression recognition. Accordingly, the proposed AUDN is composed of three sequential modules. Firstly, we build a convolutional layer and a max-pooling layer to learn the Micro-Action-Pattern (MAP) representation, which can explicitly depict local appearance variations caused by facial expressions. Secondly, feature grouping is applied to simulate larger receptive fields by combining correlated MAPs adaptively, aiming to generate more abstract mid-level semantics. Finally, a multi-layer learning process is employed in each receptive field respectively to construct group-wise sub-networks for higher-level representations. Experiments on three expression databases CK+, MMI and SFEW demonstrate that, by simply applying linear classifiers on the learned features, our method can achieve state-of-the-art results on all the databases, which validates the effectiveness of AUDN in both lab-controlled and wild environments. (C) 2015 Elsevier B.V. All rights reserved.	[Liu, Mengyi; Li, Shaoxin; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China	Shan, SG (reprint author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	sgshan@ict.ac.cn			National Basic Research Program of China 973 Program [2015CB351802]; Natural Science Foundation of China [61222211, 61272319, 61390510]	This work is partially supported by National Basic Research Program of China 973 Program under Contract no. 2015CB351802, and Natural Science Foundation of China under Contract nos. 61222211, 61272319, and 61390510.	Bengio Y., 2007, ADV NEURAL INFORM PR, V19, P153; Coates A., 2011, ICML, V8, P10; Coates A., 2011, ADV NEURAL INFORM PR, V24, P2528; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Dhall A., 2011, ICCV WORKSH NOV, P2106; Ekman P, 1978, FACIAL ACTION CODING; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hu Y., 2008, IEEE C COMP VIS PATT, P1; Izard C. E., 1971, FACE EMOTION; Jia YQ, 2012, PROC CVPR IEEE, P3370; Kanade T., 2000, INT C AUT FAC GEST R, P46; LeCun Y., 2004, IEEE C COMP VIS PATT, V2, P11; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011; Liu M., 2012, AS C COMP VIS ACCV; Liu M., 2013, IEEE INT C AUT FAC G; Lucey P., 2010, IEEE COMP SOC C COMP, P94; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Rosenblatt F., 1961, TECHNICAL REPORT; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005; Sun X., 2008, IEEE C CYB INT SYST, P158; Tariq U., 2011, INT C AUT FAC GEST A, P872; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Valstar M., 2010, INT C LANG RES EV WO, P65; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yang P, 2010, PROC CVPR IEEE, P2638, DOI 10.1109/CVPR.2010.5539978; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhao XW, 2012, IMAGE VISION COMPUT, V30, P136, DOI 10.1016/j.imavis.2011.12.004; Zhong L, 2012, PROC CVPR IEEE, P2562	35	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	JUL 2	2015	159						126	136		10.1016/j.neucom.2015.02.011		11	Computer Science, Artificial Intelligence	Computer Science	CG2HD	WOS:000353094600015		
J	Burelli, P; Yannakakis, GN				Burelli, Paolo; Yannakakis, Georgios N.			Adapting virtual camera behaviour through player modelling	USER MODELING AND USER-ADAPTED INTERACTION			English	Article						Virtual camera control; Gaze interaction; Player modelling; Computer games		Research in virtual camera control has focused primarily on finding methods to allow designers to place cameras effectively and efficiently in dynamic and unpredictable environments, and to generate complex and dynamic plans for cinematography in virtual environments. In this article, we propose a novel approach to virtual camera control, which builds upon camera control and player modelling to provide the user with an adaptive point-of-view. To achieve this goal, we propose a methodology to model the player's preferences on virtual camera movements and we employ the resulting models to tailor the viewpoint movements to the player type and her game-play style. Ultimately, the methodology is applied to a 3D platform game and is evaluated through a controlled experiment; the results suggest that the resulting adaptive cinematographic experience is favoured by some player types and it can generate a positive impact on the game performance.	[Burelli, Paolo] Aalborg Univ, Dept Architecture Design & Media Technol, DK-2450 Copenhagen, Denmark; [Yannakakis, Georgios N.] Univ Malta, Inst Digital Games, Msida 2080, Malta	Burelli, P (reprint author), Aalborg Univ, Dept Architecture Design & Media Technol, AC Meyeraenge 15, DK-2450 Copenhagen, Denmark.	pabu@create.aau.dk; georgios.yannakakis@um.edu.mt					Arijon D., 1991, GRAMMAR FILM LANGUAG; Bares W.H., 1997, INT C US MOD, P215; Bares W.H., 1997, C INN APPL ART INT, P347; Bares W. H., 1998, IUI '98. 1998 International Conference on Intelligent User Interfaces; Bernhard M., 2010, ACM T APPL PERCEPT, V8; BLINN J, 1988, IEEE COMPUT GRAPH, V8, P76, DOI 10.1109/38.7751; Bourne O, 2008, CONSTRAINTS, V13, P180, DOI 10.1007/s10601-007-9026-8; Bungie Studios, 2001, HAL COMB EV; Burelli P, 2011, LECT NOTES COMPUT SC, V6815, P25, DOI 10.1007/978-3-642-22571-0_3; Burelli P., 2013, INT C FDN DIG GAM SO, P134; Burelli P., 2010, IEEE S COMP INT GAM, P403; Burelli P., 2012, THESIS IT U COPENHAG; CHRISTIANSON D.B., 1996, AAAI IAAI, V1, P148; Christie M, 2008, COMPUT GRAPH FORUM, V27, P2197, DOI 10.1111/j.1467-8659.2008.01181.x; Core Design, 1996, TOMB RAID; DIVGI DR, 1979, PSYCHOMETRIKA, V44, P169, DOI 10.1007/BF02293968; DRUCKER SM, 1994, GRAPH INTER, P190; El-Nasr M.S., 2006, ACM SIGCHI INT C ADV, V31, P22; He L.-W., 1996, ANN C SERIES, P217; Irwin D.E., 2004, INTERFACE LANGUAGE V, P105; Jhala A., 2005, AAAI, P307; Kamiya H., 2001, DEVIL MAY CRY CAPCOM; Kittler J., 1978, Pattern Recognition and Signal Processing; Land MF, 2009, VISUAL NEUROSCI, V26, P51, DOI 10.1017/S0952523808080899; Lino C., 2012, ACM SIGGRAPH EUR S C, P65; Mahlmann T., 2010, IEEE S COMP INT GAM, P178; Miyamoto S., 1996, MARIO, V64; Phillips C.B., 1992, ACM 13D, P71; Picardi A., 2011, INT C FDN DIG GAM, P107; Pinelle D, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1453; Pontriagin L.S., 1962, MATH THEORY OPTIMAL; Ranon R., 2014, IEEE T VIS COMPUT GR, V2626, P1; Riedmiller M., 1993, DIRECT ADAPTIVE METH; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sundstedt V, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P43; Togelius J., 2011, INT WORKSH PROC CONT, P6; Tomlinson B., 2000, INT C AUT AG BARC SP, P317; Ware C., 1990, ACM SIGGRAPH, V24, P175, DOI 10.1145/91394.91442; Wolf M.J.P., 2001, MEDIUM VIDEO GAME, P113; Yannakakis GN, 2011, LECT NOTES COMPUT SC, V6974, P437, DOI 10.1007/978-3-642-24600-5_47; Yannakakis GN, 2008, USER MODEL USER-ADAP, V18, P207, DOI 10.1007/s11257-007-9036-7; Yannakakis GN, 2010, USER MODEL USER-ADAP, V20, P313, DOI 10.1007/s11257-010-9078-0; Yarbus AL, 1967, EYE MOVEMENTS VISION, V1st	43	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-1868	1573-1391		USER MODEL USER-ADAP	User Model. User-Adapt. Interact.	JUN	2015	25	2					155	183		10.1007/s11257-015-9156-4		29	Computer Science, Cybernetics	Computer Science	CF8BA	WOS:000352779000002		
J	Adhikari, R				Adhikari, Ratnadip			A neural network based linear ensemble framework for time series forecasting	NEUROCOMPUTING			English	Article						Time series forecasting; Forecasting accuracy; Combining forecasts; Weights selection; Artificial neural networks	COMBINATION FORECASTS; PERFORMANCE; AVERAGES; MODEL	Combining time series forecasts from several models is a fruitful alternative to using only a single individual model. In the literature, it has been widely documented that a combined forecast improves the overall accuracy to a great extent and is often better than the forecast of each component model. The accuracy of a linear combination of forecasts primarily depends on the associated combining weights. Despite extensive research in this direction, finding out the most appropriate weights is still very challenging. This paper proposes a linear combination method for time series forecasting that determines the combining weights through a novel neural network structure. The designed neural network successively recognizes the weight patterns of the constituent models from their past forecasting records and then predicts the desired set of the combining weights. Empirical results from eight real-world time series show that our approach provides significantly better forecasting accuracies than the component models and other well recognized linear combination schemes. These findings are also verified through ranking methods and a non-parametric statistical test. (C) 2015 Elsevier B.V. All rights reserved.	LNM Inst Informat Technol, Dept Comp Sci & Engn, Jaipur 302031, Rajasthan, India	Adhikari, R (reprint author), LNM Inst Informat Technol, Dept Comp Sci & Engn, Jaipur 302031, Rajasthan, India.	adhikari.ratan@gmail.com			Council of Scientific and Industrial Research (CSIR), India	The author is very much thankful to the anonymous reviewers for their constructive suggestions which significantly facilitated the improvement of this paper. In addition, the author also expresses his profound gratitude to the Council of Scientific and Industrial Research (CSIR), India, for the obtained financial support that provided a great help in performing the present research work.	Adhikari R., 2012, ARTIF INTELL REV, P1; Adhikari R, 2012, J SCI IND RES INDIA, V71, P657; AKSU C, 1992, INT J FORECASTING, V8, P27, DOI 10.1016/0169-2070(92)90005-T; Andrawis RR, 2011, INT J FORECASTING, V27, P672, DOI 10.1016/j.ijforecast.2010.09.005; Anthony M., 1998, NEURAL COMPUT SURV, V1, P1; Armstrong J.S., 2001, PRINCIPLES FORECASTI, V30; BATES JM, 1969, OPER RES QUART, V20, P451, DOI 10.2307/3008764; Box GEP, 1970, TIME SERIES ANAL FOR; Box G.E.P., 1994, TIME SERIES ANAL FOR, V3rd; BUNN DW, 1975, OPER RES QUART, V26, P325, DOI 10.2307/3008467; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chapelle O., 2002, THESIS U PARIS FRANC; CLEMEN RT, 1989, INT J FORECASTING, V5, P559, DOI 10.1016/0169-2070(89)90012-5; De Gooijer JG, 2006, INT J FORECASTING, V22, P443, DOI 10.1016/j.ijforecast.2006.01.001; Delft Center for Systems and Control, 2013, MATLAB TOOLB ARMASA; de Menezes LM, 2000, EUR J OPER RES, V120, P190, DOI 10.1016/S0377-2217(98)00380-4; Demuth H., 2010, NEURAL NETWORK TOOLB; DICKEY DA, 1979, J AM STAT ASSOC, V74, P427, DOI 10.2307/2286348; Dickinson J., 1975, OPER RES Q, P205; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Farooq T., 2007, IEEE INT C SYST MAN, P373; Freitas PSA, 2006, EUR J OPER RES, V173, P801, DOI 10.1016/j.ejor.2005.06.057; FRENCH S, 1981, J OPER RES SOC, V32, P937; Gheyas IA, 2011, NEUROCOMPUTING, V74, P3855, DOI 10.1016/j.neucom.2011.08.005; Golub G. H., 2012, MATRIX COMPUTATIONS, V3; GRANGER CWJ, 1984, J FORECASTING, V3, P197, DOI 10.1002/for.3980030207; Hamzacebi C, 2008, INFORM SCIENCES, V178, P4550, DOI 10.1016/j.ins.2008.07.024; Hibon M, 2005, INT J FORECASTING, V21, P15, DOI 10.1016/j.ijforecast.2004.05.002; Hollander M., 2013, NONPARAMETRIC STAT M, V751; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HYNDMAN R.J, 2013, TIME SERIES DATA LIB; Jose VRR, 2008, INT J FORECASTING, V24, P163, DOI 10.1016/j.ijforecast.2007.06.001; Krogh A., 1995, ADV NEURAL INFORMATI, V25, P231; Kumar S., 2004, NEURAL NETWORKS CLAS; Kuncheva L. I., 2004, COMBINING PATTERN CL; Lemke C, 2010, NEUROCOMPUTING, V73, P2006, DOI 10.1016/j.neucom.2009.09.020; Lim C.P., 2005, INT J COMPUT INTELL, V3, P119; Makridakis S, 2000, INT J FORECASTING, V16, P451, DOI 10.1016/S0169-2070(00)00057-1; MAKRIDAKIS S, 1983, MANAGE SCI, V29, P987, DOI 10.1287/mnsc.29.9.987; Markham IS, 1998, COMPUT OPER RES, V25, P251, DOI 10.1016/S0305-0548(97)00074-9; Pollock DSG, 2003, COMPUT STAT DATA AN, V44, P37, DOI 10.1016/S0167-9473(03)00150-6; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Stock JH, 2004, J FORECASTING, V23, P405, DOI 10.1002/for.928; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Timmermann A, 2006, HBK ECON, V24, P135, DOI 10.1016/S1574-0706(05)01004-9; Vapnik V., 1995, NATURE STAT LEARNING; Zhang GP, 2007, INFORM SCIENCES, V177, P5329, DOI 10.1016/j.ins.2007.06.015; Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0; Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7; Zhao J, 2013, NEUROCOMPUTING, V118, P215, DOI 10.1016/j.neucom.2013.02.031; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	51	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	JUN 1	2015	157						231	242		10.1016/j.neucom.2015.01.012		12	Computer Science, Artificial Intelligence	Computer Science	CE4LH	WOS:000351801600022		
J	Vongsy, K; Eismann, MT; Mendenhall, MJ				Vongsy, Karmon; Eismann, Michael T.; Mendenhall, Michael J.			Extension of the Linear Chromodynamics Model for Spectral Change Detection in the Presence of Residual Spatial Misregistration	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						Change detection; generalized likelihood ratio test (GLRT); hyperspectral; misregistration	UNSUPERVISED CHANGE DETECTION; HYPERSPECTRAL CHANGE DETECTION; MULTISPECTRAL IMAGERY; MULTITEMPORAL IMAGES; MATCHED-FILTER; SIMPLEX-METHOD; TRANSFORM; SEARCH; IMPACT	A generalized likelihood ratio test (GLRT) statistic for spectral change detection based on the linear chromodynamics model is extended to accommodate unknown residual misregistration between imagery described by a prior probability density function for the spatial misregistration. Using a normal prior distribution leads to a fourth-order polynomial that can be numerically minimized over the unknown misregistration parameters. A more computationally efficient closed-form solution is developed based on a quadratic approximation and provides comparable results to the numerical minimization for the investigated test cases while running 30 times faster. The results applying the method to hyperspectral imagery indicate up to an order of magnitude reduction in false alarms at the same detection rate relative to baseline change detection methods for synthetically misregistered test data particularly in image regions containing edges and fine spatial features. Sensitivity to model parameters is assessed, and the method is compared with a previously published misregistration compensation approach yielding comparable results. Although the GLRT approach appears to exhibit comparable change detection performance, it offers the possibility of tailoring the algorithm to a priori knowledge of expected misregistration errors or to compensate structured misregistration as would occur due to parallax errors due to perspective variations (e.g., image parallax).	[Vongsy, Karmon; Eismann, Michael T.] US Air Force, Res Lab, Sensors Directorate, Wright Patterson AFB, OH 45433 USA; [Mendenhall, Michael J.] US Air Force, Inst Technol, Dept Elect Engn, Wright Patterson AFB, OH 45433 USA	Vongsy, K (reprint author), US Air Force, Res Lab, Sensors Directorate, Wright Patterson AFB, OH 45433 USA.	karmon.vongsy@us.af.mil; michael.eismann@us.af.mil; mendenmi@gmail.com			Sensors Directorate of the Air Force Research Laboratory, Wright-Patterson Air Force Base, Ohio	This work was supported by the Sensors Directorate of the Air Force Research Laboratory, Wright-Patterson Air Force Base, Ohio.	Bishop C. M., 2006, PATTERN RECOGNITION; Bovolo F, 2009, IEEE T GEOSCI REMOTE, V47, P2658, DOI 10.1109/TGRS.2009.2017014; Bovolo F, 2010, PATTERN RECOGN LETT, V31, P1148, DOI 10.1016/j.patrec.2009.07.002; Bovolo F., 2007, P IEEE 4 INT WORKSH, P1; Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169; Bruzzone L, 2003, IEEE T GEOSCI REMOTE, V41, P2455, DOI 10.1109/TGRS.2003.817268; Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009; Bruzzone L, 2000, INT J REMOTE SENS, V21, P3539, DOI 10.1080/014311600750037552; Carlotto M., 1996, P SOC PHOTO-OPT INS, P206; Carlotto MJ, 2000, OPT ENG, V39, P1223, DOI 10.1117/1.602496; Carlotto MJ, 2005, IEEE T GEOSCI REMOTE, V43, P374, DOI 10.1109/TGRS.2004.841481; Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059; Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095; Clifton C, 2003, APPL INTELL, V18, P215, DOI 10.1023/A:1021942526896; Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675; Cossu R, 2005, IEEE GEOSCI REMOTE S, V2, P352, DOI 10.1109/LGRS.2005.851541; Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566; Dalla Mura M., 2008, IEEE GEOSCI REMOTE S, V5, P433; D'Errico J., 2005, UNDERSTANDING FMINSE; Diehl M., 2013, SCRIPT NUMERICAL COU; Eismann M. T., 2012, HYPERSPECTRAL REMOTE; Eismann M. T., 2008, APPL OPTICS, V47, P27; Eismann MT, 2009, P IEEE, V97, P1031, DOI 10.1109/JPROC.2009.2013561; Eismann MT, 2008, IEEE T GEOSCI REMOTE, V46, P237, DOI 10.1109/TGRS.2007.907973; Fonseca LMG, 1996, PHOTOGRAMM ENG REM S, V62, P1049; Goshtasby A. A., 1999, SPECIAL ISSUE PATTER; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd; Haykin S., 1999, NEURAL NETWORKS COMP; Hazel GG, 2001, IEEE T GEOSCI REMOTE, V39, P553, DOI 10.1109/36.911113; Hemissi S, 2013, IEEE T GEOSCI REMOTE, V51, P199, DOI 10.1109/TGRS.2012.2200486; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Le Moigne J, 2002, IEEE T GEOSCI REMOTE, V40, P1849, DOI 10.1109/TGRS.2002.802501; Lu D., 2003, INT J REMOTE SENS, V25, P2365; Mayer R, 2003, IEEE T GEOSCI REMOTE, V41, P1136, DOI 10.1109/TGRS.2003.813553; Meola J., 2007, P SOC PHOTO-OPT INS; Meola J., 2011, THESIS OHIO STATE U; Meola J, 2011, IEEE T GEOSCI REMOTE, V49, P2647, DOI 10.1109/TGRS.2011.2109726; Meola J., 2008, P SOC PHOTO-OPT INS, V6966, P1; Mernyi E., 1996, ICARUS, V124, P280; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Nasrabadi NM, 2008, IEEE SIGNAL PROC LET, V15, P317, DOI 10.1109/LSP.2008.917805; NELDER JA, 1965, COMPUT J, V7, P308; Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962; Papoulis A., 1984, PROBABILITY RANDOM V, V2nd; Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698; REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107; Roy DP, 2000, IEEE T GEOSCI REMOTE, V38, P2017, DOI 10.1109/36.851783; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Scharf L. L., 1991, STAT SIGNAL PROCESSI; Schaum A., 1991, ANAL METHODS IMAGE R; Schaum A, 1997, P SOC PHOTO-OPT INS, V3071, P12, DOI 10.1117/12.280605; Schaum A., 2003, P 2003 IEEE AER C IE, V4, P41879; Schaum A, 2004, P SOC PHOTO-OPT INS, V5425, P77, DOI 10.1117/12.544026; SINGH A, 1989, INT J REMOTE SENS, V10, P989; Stein DWJ, 2002, IEEE SIGNAL PROC MAG, V19, P58, DOI 10.1109/79.974730; Stevenson B., 2005, CIVIL PATROL ARCHER; Theiler J, 2008, APPL OPTICS, V47, pF12, DOI 10.1364/AO.47.000F12; Theiler J, 2012, IEEE T GEOSCI REMOTE, V50, P3107, DOI 10.1109/TGRS.2011.2179942; TOWNSHEND JRG, 1992, IEEE T GEOSCI REMOTE, V30, P1054, DOI 10.1109/36.175340; Villeneuve PV, 1999, P SOC PHOTO-OPT INS, V3753, P278, DOI 10.1117/12.366290; Vongsy K., 2014, P SOC PHOTO-OPT INS, V9088; Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396	62	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892	1558-0644		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	JUN	2015	53	6					3005	3021		10.1109/TGRS.2014.2367471		17	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	CD4OV	WOS:000351063800003		
J	Zhao, YP; Wang, KK; Li, YB				Zhao, Yong-Ping; Wang, Kang-Kang; Li, Ye-Bo			Parsimonious regularized extreme learning machine based on orthogonal transformation	NEUROCOMPUTING			English	Article						Extreme learning machine; Sparseness; Tikhonov regularization; Orthogonal transformation; Condition number	FEEDFORWARD NETWORKS; NEURAL-NETWORKS; CLASSIFICATION; OPTIMIZATION; REGRESSION; IDENTIFICATION; APPROXIMATION; ALGORITHM; SELECTION; ELM	Recently, two parsimonious algorithms were proposed to sparsify extreme learning machine (ELM), i.e., constructive parsimonious ELM (CP-ELM) and destructive parsimonious ELM (DP-ELM). In this paper, the ideas behind CP-ELM and DP-ELM are extended to the regularized ELM (RELM), thus obtaining CP-RELM and DP-RELM. For CP-RELM(DP-RELM), there are two schemes to realize it, viz. CP-RELM-I and CP-RELM-II(DP-RELM-I and DP-RELM-II). Generally speaking, CP-RELM-II(DP-RELM-II) outperforms CP-RELM-I(DP-RELM-I) in terms of parsimoniousness. Under nearly the same generalization, compared with CP-ELM (DP-ELM), CP-RELM-II(DP-RELM-II) usually needs fewer hidden nodes. In addition, different from CP-ELM and DP-ELM, for CP-RELM and DP-RELM the number of candidate hidden nodes may be larger than the number of training samples, which assists the selection of much better hidden nodes for constructing more compact networks. Finally, eleven benchmark data sets divided into two groups are utilized to do experiments and the usefulness of the proposed algorithms is reported. (C) 2014 Elsevier B.V. All rights reserved.	[Zhao, Yong-Ping; Wang, Kang-Kang] Nanjing Univ Sci & Technol, Sch Mech Engn, Nanjing 210094, Jiangsu, Peoples R China; [Li, Ye-Bo] AVIC Aeroengine Control Res Inst, Wuxi 214063, Peoples R China	Zhao, YP (reprint author), Nanjing Univ Sci & Technol, Sch Mech Engn, Nanjing 210094, Jiangsu, Peoples R China.	y.p.zhao@163.com			National Natural Science Foundation of China [51006052]; NUST Outstanding Scholar Supporting Program	This research was partially supported by the National Natural Science Foundation of China under Grant no. 51006052, and the NUST Outstanding Scholar Supporting Program. Moreover, the authors wish to thank the anonymous reviewers for their constructive comments and great help in the writing process, which improve the manuscript significantly.	Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; BOBROW JE, 1993, IEEE T AUTOMAT CONTR, V38, P351, DOI 10.1109/9.250491; Bontempi G., 1998, P EUR C MACH LEARN, P292; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Deng WY, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P389, DOI 10.1109/CIDM.2009.4938676; Deng WY, 2010, NEURAL NETW WORLD, V20, P317; Duda R. O., 2000, PATTERN CLASSIFICATI, V2nd; Efron B, 2004, ANN STAT, V32, P407; Feng GR, 2009, IEEE T NEURAL NETWOR, V20, P1352, DOI 10.1109/TNN.2009.2024147; Feng GR, 2012, SOFT COMPUT, V16, P1485, DOI 10.1007/s00500-012-0823-7; Han M., 2009, P 2009 INT C ART INT, V1, P357; Hong X, 2009, IEEE T SYST MAN CY B, V39, P298, DOI 10.1109/TSMCB.2008.2005124; Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977; Huang GB, 2003, IEEE T NEURAL NETWOR, V14, P274, DOI 10.1109/TNN.2003.809401; Huang GB, 2004, IEEE IJCNN, P985; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.121.126; Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009; Huang GB, 2010, NEUROCOMPUTING, V74, P155, DOI 10.1016/j.neucom.2010.02.019; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Huang GB, 2008, NEUROCOMPUTING, V71, P3460, DOI 10.1016/j.neucom.2007.10.008; Huang GB, 1998, IEEE T NEURAL NETWOR, V9, P224, DOI 10.1109/72.655045; Huynh H.T., 2011, PATTERN RECOGNIT LET, P1930; Lan Y, 2009, NEUROCOMPUTING, V72, P3391, DOI 10.1016/j.neucom.2009.02.013; Lan Y, 2010, NEUROCOMPUTING, V73, P3191, DOI 10.1016/j.neucom.2010.05.022; Li XD, 2014, NEUROCOMPUTING, V128, P96, DOI 10.1016/j.neucom.2013.01.064; Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583; Liu Guohai, 2011, Journal of Southeast University (Natural Science Edition), V41, DOI 10.3969/j.issn.1001-0505.2011.S1.003; Liu Xue-yi, 2011, Journal of Shanghai Jiaotong University, V45; Liu XY, 2012, NEURAL NETWORKS, V33, P58, DOI 10.1016/j.neunet.2012.04.002; Mao WT, 2013, NEURAL COMPUT APPL, V22, P521, DOI 10.1007/s00521-011-0804-2; Miche Y, 2010, IEEE T NEURAL NETWOR, V21, P158, DOI 10.1109/TNN.2009.2036259; Miche Y, 2011, NEUROCOMPUTING, V74, P2413, DOI 10.1016/j.neucom.2010.12.042; Rong HJ, 2008, NEUROCOMPUTING, V72, P359, DOI 10.1016/j.neucom.2008.01.005; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Savitha R, 2012, INFORM SCIENCES, V187, P277, DOI 10.1016/j.ins.2011.11.003; Tikhonov A.N., 1977, SOLUTIONS ILL POSED; Vapnik V., 1995, NATURE STAT LEARNING; Wang N, 2014, IEEE T NEUR NET LEAR, V25, P1828, DOI 10.1109/TNNLS.2013.2296048; Wang N, 2014, NEUROCOMPUTING, V128, P59, DOI 10.1016/j.neucom.2013.01.062; [张弦 ZHANG Xian], 2011, [航空学报, Acta Aeronautica et Astronautica Sinica], V32, P1302; Zhang X.D., 2004, MATRIX ANAL APPL; Zhao JW, 2012, NEUROCOMPUTING, V87, P79, DOI 10.1016/j.neucom.2012.02.003; Zhao Y.-P., 2013, J SYST ENG ELECTRON, V25, P895; Zheng WB, 2013, NEURAL COMPUT APPL, V22, P447, DOI 10.1007/s00521-011-0808-y	44	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	MAY 25	2015	156						280	296		10.1016/j.neucom.2014.12.046		17	Computer Science, Artificial Intelligence	Computer Science	CE6WE	WOS:000351978100032		
J	Khanmirza, E; Khaji, N; Khanmirza, E				Khanmirza, Ebrahim; Khaji, Naser; Khanmirza, Esmaeel			Identification of linear and non-linear physical parameters of multistory shear buildings using artificial neural network	INVERSE PROBLEMS IN SCIENCE AND ENGINEERING			English	Article						artificial neural networks; forced vibration; Mass-damping-stiffness identification; inverse problems; linear and non-linear identification; shear building model	LEAST-SQUARE ESTIMATION; CRACK DETECTION; DAMAGE IDENTIFICATION; GENETIC ALGORITHM; BEAM ELEMENT; MODELS	In this research, a novel method has been proposed for simultaneous identification of physical parameters (i.e. mass, stiffness and damping matrices) as well as for separation of linear physical parameters from non-linear ones by use of artificial neural networks (ANNs) in non-linear multi-degree-of-freedom (DOF) systems. To design an appropriate ANN in this method, the vibration equation of the lumped mass system is re-arranged into a new form. The proposed ANN has two parts; namely linear and non-linear. The outputs of the non-linear part of the proposed ANN identify the non-linear properties of the system. Moreover, the number of the employed ANNs is equal to the number of DOFs considered for the non-linear system. Initially, the first ANN is trained and the corresponding parameters of the linear part are then identified. Afterwards, the second ANN is trained using the identified mass of the first DOF. This procedure of training and identifying the parameters of each DOF is repeated in this manner until all DOF parameters are identified; then the identification of the non-linear part begins by exciting the non-linear part of ANN. Finally, the linear stiffness values and non-linear patterns are obtained from the output results of the excitations. The proposed algorithm has been verified through some examples.	[Khanmirza, Ebrahim; Khaji, Naser] Tarbiat Modares Univ, Fac Civil & Environm Engn, Tehran, Iran; [Khanmirza, Esmaeel] Iran Univ Sci & Technol, Sch Mech Engn, Tehran, Iran	Khaji, N (reprint author), Tarbiat Modares Univ, Fac Civil & Environm Engn, Tehran, Iran.	nkhaji@modares.ac.ir					Alpaydin E., 2010, INTRO MACHINE LEARNI, V2nd; Bryson A. E., 1969, APPL OPTIMAL CONTROL; Ghanem R, 2006, STRUCT CONTROL HLTH, V13, P245, DOI 10.1002/stc.139; Haroon M, 2005, J SOUND VIB, V283, P1137, DOI 10.1016/j.jsv.2004.06.008; Huang CS, 2003, ASME J APPL MECH, V60, P123; Yang JN, 2006, INT J NONLINEAR MECH, V41, P124, DOI 10.1016/j.ijnonlinmec.2005.06.006; IBANEZ P, 1973, NUCL ENG DES, V25, P30, DOI 10.1016/0029-5493(73)90059-9; Ikhouane F., 2007, SYSTEMS HYSTERESIS A; Karimi I, 2011, ENG STRUCT, V32, P3583; Khaji N, 2009, INT J MECH SCI, V51, P667, DOI 10.1016/j.ijmecsci.2009.07.004; Khanmirza E, 2011, EXPERT SYST APPL, V38, P5320, DOI 10.1016/j.eswa.2010.10.026; Lin JW, 2004, EARTHQ ENG STRUCT D, V33, P419, DOI 10.1002/eqe.350; MASRI SF, 1993, J APPL MECH-T ASME, V60, P123, DOI 10.1115/1.2900734; Mehrjoo M, 2013, APPL SOFT COMPUT, V13, P867, DOI 10.1016/j.asoc.2012.09.014; Mehrjoo M, 2008, EXPERT SYST APPL, V35, P1122, DOI 10.1016/j.eswa.2007.08.008; Mehrjoo M, 2014, INVERSE PROBL SCI EN, V22, P359, DOI 10.1080/17415977.2013.788170; Platten MF, 2009, MECH SYST SIGNAL PR, V23, P8, DOI 10.1016/j.ymssp.2007.11.016; Rahrooh A, 2009, NONLINEAR ANAL-THEOR, V71, P1198; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Russell S. J., 2010, ARTIFICIAL INTELLIGE; Werbos P. J, 1974, THESIS HARVARD U CAM; Worden K, 2001, NONLINEARITY STRUCTU, DOI [10.1887/0750303565, DOI 10.1887/0750303565]; Xueqi C, 2009, J SOUND VIB, V320, P808, DOI 10.1016/j.jsv.2008.08.025; Yang JN, 2007, INT J NONLINEAR MECH, V42, P789, DOI 10.1016/j.ijnonlinmec.2007.03.004; Zhang J, 2008, ENG STRUCT, V30, P1417, DOI 10.1016/j.engstruct.2007.08.007	25	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1741-5977	1741-5985		INVERSE PROBL SCI EN	Inverse Probl. Sci. Eng.	MAY 19	2015	23	4					670	687		10.1080/17415977.2014.933829		18	Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications	Engineering; Mathematics	CA7LV	WOS:000349099700008		
J	Cao, QM; Guo, Q; Wang, YL; Wu, XH				Cao Qimin; Guo Qiao; Wang Yongliang; Wu Xianghua			Text clustering using VSM with feature clusters	NEURAL COMPUTING & APPLICATIONS			English	Article						Text clustering; Feature clusters; Distributed representation; FC-VSM; Non-contiguous phrases	MODEL	Representation of documents is the basis of clustering systems. In addition, non-contiguous phrases appear more and more frequent in the text in the Web 2.0 age, and these phrases can affect the result of text clustering. In order to improve the quality of text clustering, this paper proposed a feature cluster-based vector space model (FC-VSM) which used the text feature clusters co-occurrence matrix to represent document and proposed to identify non-contiguous phrases in the text preprocessing stage. Our method can reduce dimension of features compared with the traditional VSM-based model. It identified non-contiguous phrases, used distributed representation of features, and implements feature clusters. Despite their simplicity, our methods are surprisingly effective and can improve the accuracy of clustering significantly which is shown in experimental results.	[Cao Qimin; Guo Qiao; Wang Yongliang; Wu Xianghua] Beijing Inst Technol, Sch Automat, Beijing 100081, Peoples R China	Cao, QM (reprint author), Beijing Inst Technol, Sch Automat, Beijing 100081, Peoples R China.	caoqiminisbest@163.com					Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Collobert R., 2008, ICML, V307, P160, DOI DOI 10.1145/1390156.1390177; Doucet A, 2004, P 42 ANN M ASS COMP, P88, DOI 10.3115/1613186.1613198; Grabmeier J, 2002, DATA MIN KNOWL DISC, V6, P303, DOI 10.1023/A:1016308404627; Huang E.H., 2012, ANN M ASS COMP LING, V1, P873; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Lu Y, 2011, INFORM RETRIEVAL, V14, P178, DOI 10.1007/s10791-010-9141-9; Meyer CD, 2012, SIAM J MATRIX ANAL A, V33, P1214, DOI 10.1137/100804395; Mikolov T, 2012, THESIS BRNO U TECHNO; Mikolov T, 2013, EFFICIENT ESTIMATION; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mikolov T., 2013, ADV NEURAL INF PROCE, V26, P3111; Mnih A, 2008, ADV NEURAL INF PROCE, V21, P1081; Morin F, 2005, P INT WORKSH ART INT, P246; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Shi Z, 2002, KNOWLEDGE DISCOVERY; Simard M, 2005, P HUM LANG TECHN C C, P755, DOI DOI 10.3115/1220575.1220670; Socher R, 2011, P 28 INT C MACH LEAR, P129; Turian J, 2010, P 48 ANN M ASS COMP, P384	23	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0941-0643	1433-3058		NEURAL COMPUT APPL	Neural Comput. Appl.	MAY	2015	26	4					995	1003		10.1007/s00521-014-1792-9		9	Computer Science, Artificial Intelligence	Computer Science	CG5SX	WOS:000353356000021		
J	Huang, GB; Bai, Z; Lekamalage, L; Kasun, C; Vong, CM				Huang, Guang-Bin; Bai, Zuo; Lekamalage, Liyanaarachchi; Kasun, Chamara; Vong, Chi Man			Local Receptive Fields Based Extreme Learning Machine	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE			English	Article							TIME-SERIES PREDICTION; FUNCTIONAL-LINK NET; NEURAL-NETWORKS; BIG DATA; FUNCTION APPROXIMATION; CLASSIFICATION; RECOGNITION; REGRESSION; REPRESENTATIONS; OPTIMIZATION	Extreme learning machine (ELM), which was originally proposed for "generalized" single-hidden layer feedforward neural networks (SLFNs), provides efficient unified learning solutions for the applications of feature learning, clustering, regression and classification. Different from the common understanding and tenet that hidden neurons of neural networks need to be iteratively adjusted during training stage, ELM theories show that hidden neurons are important but need not be iteratively tuned. In fact, all the parameters of hidden nodes can be independent of training samples and randomly generated according to any continuous probability distribution. And the obtained ELM networks satisfy universal approximation and classification capability. The fully connected ELM architecture has been extensively studied. However, ELM with local connections has not attracted much research attention yet. This paper studies the general architecture of locally connected ELM, showing that: 1) ELM theories are naturally valid for local connections, thus introducing local receptive fields to the input layer; 2) each hidden node in ELM can be a combination of several hidden nodes (a subnetwork), which is also consistent with ELM theories. ELM theories may shed a light on the research of different local receptive fields including true biological receptive fields of which the exact shapes and formula may be unknown to human beings. As a specific example of such general architectures, random convolutional nodes and a pooling structure are implemented in this paper. Experimental results on the NORB dataset, a benchmark for object recognition, show that compared with conventional deep learning solutions, the proposed local receptive fields based ELM (ELM-LRF) reduces the error rate from 6.5% to 2.7% and increases the learning speed up to 200 times.	[Huang, Guang-Bin; Bai, Zuo; Lekamalage, Liyanaarachchi; Kasun, Chamara] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Vong, Chi Man] Univ Macau, Dept Comp & Informat Sci, Taipa, Peoples R China	Huang, GB (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.						Arnaldo I, 2015, IEEE COMPUT INTELL M, V10, P20, DOI 10.1109/MCI.2014.2369892; Bai Z, 2014, IEEE T CYBERNETICS, V44, P1858, DOI 10.1109/TCYB.2014.2298235; Barak O, 2013, J NEUROSCI, V33, P3844, DOI 10.1523/JNEUROSCI.2753-12.2013; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Butcher JB, 2013, NEURAL NETWORKS, V38, P76, DOI 10.1016/j.neunet.2012.11.011; Chen CLP, 1999, IEEE T SYST MAN CY B, V29, P62, DOI 10.1109/3477.740166; Chen CLP, 1998, NEUROCOMPUTING, V18, P11, DOI 10.1016/S0925-2312(97)00062-3; Chen CLP, 1996, IEEE T NEURAL NETWOR, V7, P1220, DOI 10.1109/72.536316; Coates A., 2011, P 14 INT C ART INT S, V15, P215; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cox D, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), DOI 10.1109/FG.2011.5771385; Frenay B., 2010, P 18 EUR S ART NEUR, P315; Hawkins J., 2007, INTELLIGENCE; Huang G, 2014, IEEE T CYBERNETICS, V44, P2405, DOI 10.1109/TCYB.2014.2307349; Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001; Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977; Huang GB, 2004, IEEE IJCNN, P985; Huang GB, 2006, IEEE T CIRCUITS-II, V53, P187, DOI 10.1109/TCSII.2005.857540; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.121.126; Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009; Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2; Huang GB, 2010, NEUROCOMPUTING, V74, P155, DOI 10.1016/j.neucom.2010.02.019; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Huang GB, 2008, NEUROCOMPUTING, V71, P3460, DOI 10.1016/j.neucom.2007.10.008; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215; IGELNIK B, 1995, IEEE T NEURAL NETWOR, V6, P1320, DOI 10.1109/72.471375; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kara P, 2003, J NEUROSCI, V23, P8547; Kasun LLC, 2013, IEEE INTELL SYST, V28, P31; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; Le Q., 2010, P ADV NEUR INF PROC, V23, P1279; LeCun Y, 2004, PROC CVPR IEEE, P97; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; LEE TH, 1993, J ECONOMETRICS, V56, P269, DOI 10.1016/0304-4076(93)90122-L; MARQUARD.DW, 1970, TECHNOMETRICS, V12, P591, DOI 10.2307/1267205; Minhas R, 2012, IEEE T CIRC SYST VID, V22, P1529, DOI 10.1109/TCSVT.2011.2177182; Nair V., 2009, P 23 ANN C NEUR INF, V22, P1339; Nizar AH, 2008, IEEE T POWER SYST, V23, P946, DOI 10.1109/TPWRS.2008.926431; Pal M, 2013, REMOTE SENS LETT, V4, P853, DOI 10.1080/2150704X.2013.805279; Pao Y., 1989, ADAPTIVE PATTERN REC; PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1; Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015; Poggio T., 2001, 2001011 AI MIT; RAHIMI A, 2008, P 46 ANN ALL C COMM, P555; Ranzato M., 2006, P NIPS, V19, P1137; Rao C. R., 1971, GEN INVERSE MATRICES, V7; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saxe A. M., 2011, P 28 INT C MACH LEAR, P1089; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Schmidt W.F., 1992, PATTERN RECOGNITIO B, VII, P1; Song YD, 2012, J NEUROSCI METH, V210, P132, DOI 10.1016/j.jneumeth.2012.07.003; Sosulski DL, 2011, NATURE, V472, P213, DOI 10.1038/nature09868; Steinwart I, 2011, J MACH LEARN RES, V12, P141; Stinchcombe MB, 1998, ECONOMET THEOR, V14, P295; White H., 1989, P INT JOINT C NEURAL, V2, P451; White H., 2006, HDB EC FORECASTING, P460; Widrow B, 2013, NEURAL NETWORKS, V37, P180, DOI 10.1016/j.neunet.2012.09.020; Yan Z, 2014, IEEE T NEUR NET LEAR, V25, P457, DOI 10.1109/TNNLS.2013.2275948; Yang YM, 2012, IEEE T NEUR NET LEAR, V23, P1498, DOI 10.1109/TNNLS.2012.2202289; You ZH, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-S8-S10; Zhai YT, 2014, IEEE COMPUT INTELL M, V9, P14, DOI 10.1109/MCI.2014.2326099; Zhang YW, 2011, CHEM ENG SCI, V66, P4702, DOI 10.1016/j.ces.2011.06.030; Zheng WB, 2013, NEURAL COMPUT APPL, V22, P447, DOI 10.1007/s00521-011-0808-y; Zhou Y., 2014, IEEE J SELE IN PRESS; Zhou ZH, 2014, IEEE COMPUT INTELL M, V9, P62, DOI 10.1109/MCI.2014.2350953	66	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-603X	1556-6048		IEEE COMPUT INTELL M	IEEE Comput. Intell. Mag.	MAY	2015	10	2					18	29		10.1109/MCI.2015.2405316		12	Computer Science, Artificial Intelligence	Computer Science	CF9RG	WOS:000352902900002		
J	Goncalves, FM; Ribeiro, RSD; Costa, RNT; Burte, JD				Goncalves, Fabrcio Mota; da Frota Ribeiro, Renato Silvio; Tavora Costa, Raimundo Nonato; Burte, Julien Daniel			A Management Analysis Tool for Emancipated and Public Irrigation Areas Using Neural Networks	WATER RESOURCES MANAGEMENT			English	Article						Multivariate discriminant analysis; Neural networks; Irrigation transfer management; Performance indicators; Evaluation model	SYSTEMS	The management transfer of irrigation districts from the public to the private sector became a broad strategy throughout the world. Although the extent to which the process is being implemented, there is little information available on the results of these transfer programs. In addition, there is no established procedure to analyze economic feasibility and general performance of the irrigation districts. In this context, the aim of this research was to develop a model to evaluate the performance of self-managed irrigated areas transferred from public sector to private irrigator associations. A list of performance indicators proposed by the Brazilian Federal Court of Accounts to monitor the public perimeters and pre-classification information from two public companies, San Francisco and Parnaiba Valleys Development Company (CODEVASF) and National Department of Works Against Droughts (DNOCS) were used in this research. A statistical multivariate model with discriminant analysis (MDA) was performed to identify the indicators importance in order to discriminate the current level of the irrigation areas. The data resulting from multivariate discriminant analysis was used to create an artificial neural network (ANN) that classifies the irrigated areas related to management. It was observed that the indicator Generated Revenue per Hectare (GRH) was the most important in the discriminating process regarding self-management. The neural network created from the values of the performance function resulted from multivariate discriminant analysis showed be capable of assessing the performance of Irrigated Perimeters over time and also be adequate as a tool for resource allocation and evaluation of self-managed irrigated areas.	[Goncalves, Fabrcio Mota] Univ Fed Ceara, Dept Agr Engn, BR-60455760 Fortaleza, Ceara, Brazil; [da Frota Ribeiro, Renato Silvio] Univ Fed Ceara, Geoproc Lab, Dept Agr Engn, BR-60455760 Fortaleza, Ceara, Brazil; [Tavora Costa, Raimundo Nonato] Univ Fed Ceara, Irrigat Lab, Dept Agr Engn, BR-60455760 Fortaleza, Ceara, Brazil; [Burte, Julien Daniel] CIRAD, UMR G EAU, F-34196 Montpellier 5, France	Ribeiro, RSD (reprint author), Univ Fed Ceara, Geoproc Lab, Dept Agr Engn, Campus Pici,Bloco 870, BR-60455760 Fortaleza, Ceara, Brazil.	fabriciomota21@yahoo.com.br; renato@ufc.br; rntcosta@secrel.com.br; julien.burte@cirad.fr			CAPES - Coordination for the Improvement of Higher Education	This research was partially supported by CAPES - Coordination for the Improvement of Higher Education.	Ali MK, 2014, WATER RESOUR MANAG, V28, P2751, DOI 10.1007/s11269-014-0634-y; Bialoskorski-Neto S, 2006, J ADM U SAO PAULO, V41, P59; Codevasf, 2011, PROGR ACT; Corrar LJ, 2007, MULTIVARIATE ANAL AD; Costa RNT, 2011, WATER RESOURCES ARID, P88; Dourado A, 2006, IRRIGATION PUBLIC PE; Gomez-Limon JA, 2009, J ENVIRON MANAGE, V90, P3345, DOI 10.1016/j.jenvman.2009.05.023; Hair J. F., 1998, MULTIVARIATE DATA AN; Kamara AB, 2002, PHYS CHEM EARTH, V27, P815, DOI 10.1016/S1474-7065(02)00070-0; Meinzen-Dick R, 2002, WORLD DEV, V30, P649, DOI 10.1016/S0305-750X(01)00130-9; OECD-Organization for Economic Co-Operation and Development, 2001, ENV IND AGR, V3; Ribeiro RSF, 1998, 982169 ASAE; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shah T, 2002, 60 IWMI, DOI [10.3910/2009.067, DOI 10.3910/2009.067]; Uysal OK, 2010, AGR WATER MANAGE, V97, P1017, DOI 10.1016/j.agwat.2010.02.007; Vermillion DL, 2001, COLLECTIVE ACTION PR, P182	16	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-4741	1573-1650		WATER RESOUR MANAG	Water Resour. Manag.	MAY	2015	29	7					2393	2406		10.1007/s11269-015-0948-4		14	Engineering, Civil; Water Resources	Engineering; Water Resources	CF8OZ	WOS:000352822700018		
J	Ling, ZH; Kang, SY; Zen, H; Senior, A; Schuster, M; Qian, XJ; Meng, H; Deng, L				Ling, Zhen-Hua; Kang, Shi-Yin; Zen, Heiga; Senior, Andrew; Schuster, Mike; Qian, Xiao-Jun; Meng, Helen; Deng, Li			Deep Learning for Acoustic Modeling in Parametric Speech Generation	IEEE SIGNAL PROCESSING MAGAZINE			English	Review							VOICE CONVERSION; NEURAL-NETWORKS; SYNTHESIS SYSTEM; BELIEF NETWORKS; HMM; REPRESENTATIONS; ENHANCEMENT; RECOGNITION; ALGORITHM; EXPERTS		[Ling, Zhen-Hua] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9YL, Midlothian, Scotland; [Ling, Zhen-Hua] Univ Sci & Technol China & iFLY TEK Co Ltd, Hefei, Peoples R China; [Ling, Zhen-Hua] Univ Sci & Technol China, Hefei, Peoples R China; [Ling, Zhen-Hua] Univ Washington, Seattle, WA 98195 USA; [Kang, Shi-Yin; Qian, Xiao-Jun; Meng, Helen] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China; [Zen, Heiga; Senior, Andrew] Google, Mountain View, CA USA; [Zen, Heiga; Senior, Andrew] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA; [Zen, Heiga] Toshiba Res Europe Ltd, Cambridge Res Lab, Cambridge, England; [Schuster, Mike] Adv Telecommun Res Labs, Kyoto, Japan; [Qian, Xiao-Jun] Microsoft Res Asia, Speech Grp, Beijing, Peoples R China; [Meng, Helen] Chinese Univ Hong Kong, Fac Engn, Hong Kong, Hong Kong, Peoples R China; [Deng, Li] Univ Waterloo, Waterloo, ON N2L 3G1, Canada; [Deng, Li] Microsoft Res, Deep Learning Technol Ctr, Redmond, WA USA; [Deng, Li] Univ Washington, Seattle, WA 98195 USA	Ling, ZH (reprint author), Univ Sci & Technol China, Hefei, Peoples R China.	zhling@ustc.edu.cn; sykang@se.cuhk.edu.hk; heigazen@google.com; andrewsenior@google.com; schuster@google.com; xjqian@se.cuhk.edu.hk; hmmeng@se.cuhk.edu.hk; deng@microsoft.com	Magazine, Signal Processing/E-9947-2015				Abe M., 1990, Journal of the Acoustical Society of Japan (E), V11; Bengio Y., 2007, P ADV NEUR INF PROC, P153; Chen L.-H., 2013, P INTERSPEECH, P3052; Chen LH, 2014, IEEE-ACM T AUDIO SPE, V22, P1859, DOI 10.1109/TASLP.2014.2353991; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L, 1997, SPEECH COMMUN, V22, P93, DOI 10.1016/S0167-6393(97)00018-6; Deng L., 2003, MATH FDN SPEECH LANG, P115; Deng L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1692; Deng L., 2003, SPEECH PROCESSING DY; Desai S, 2010, IEEE T AUDIO SPEECH, V18, P954, DOI 10.1109/TASL.2010.2047683; Erro D, 2010, IEEE T AUDIO SPEECH, V18, P922, DOI 10.1109/TASL.2009.2038663; Fernandez R, 2013, INT CONF ACOUST SPEE, P6885, DOI 10.1109/ICASSP.2013.6638996; Fukada T., 1992, P ICASSP 92, V1, P137; Helander E, 2012, IEEE T AUDIO SPEECH, V20, P806, DOI 10.1109/TASL.2011.2165944; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S., 2001, FIELD GUIDE DYNAMICA, P237, DOI DOI 10.1109/9780470544037.CH14; KANG SY, 2013, P ICASSP, P8012; Kang S.-Y., 2014, P INTERSPEECH; Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5; Koriyama T, 2014, IEEE J-STSP, V8, P173, DOI 10.1109/JSTSP.2013.2283461; Ling ZH, 2012, IEEE T AUDIO SPEECH, V20, P1492, DOI 10.1109/TASL.2011.2182511; Ling ZH, 2013, INT CONF ACOUST SPEE, P7825; Ling Z.-H., 2013, IEEE T AUDIO SPEECH, V21, P207; Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291; Ling Z.-H., 2006, P BLIZZ CHALL WORKSH; Lu H., 2013, P ISCA SSW8, P261; Lu X., 2013, P INT 13 AUG, P436; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mouchtaris A, 2007, IEEE T AUDIO SPEECH, V15, P1180, DOI 10.1109/TASL.2007.894511; Nakashika T., 2014, P IEEE INT C AC SPEE, P7939; Nakashika T., 2013, P INTERSPEECH, P369; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Nose T, 2007, IEICE T INF SYST, VE90D, P1406, DOI 10.1093/ietisy/e90-d.9.1406; Odell J., 1995, THESIS CAMBRIDGE U; Park KY, 2000, INT CONF ACOUST SPEE, P1843; Qian Y., 2014, P IEEE INT C AC SPEE, P3857; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saheer L, 2012, IEEE T AUDIO SPEECH, V20, P2134, DOI 10.1109/TASL.2012.2198058; Sainath TN, 2013, IEEE T AUDIO SPEECH, V21, P2267, DOI 10.1109/TASL.2013.2284378; Saito D, 2012, IEEE T AUDIO SPEECH, V20, P1784, DOI 10.1109/TASL.2012.2188628; Salakhutdinov R., 2009, THESIS U TORONTO; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472; Sun JP, 2002, J ACOUST SOC AM, V111, P1086, DOI 10.1121/1.1420380; Tachibana M, 2005, IEICE T INF SYST, VE88D, P2484, DOI 10.1093/ietisy/e88-d.11.2484; Taylor G., 2007, P C ADV NEUR INF PRO, P1345; Tiomkin T., 2010, IEEE T AUDIO SPEECH, V18, P1077; Toda T, 2012, IEEE T AUDIO SPEECH, V20, P2505, DOI 10.1109/TASL.2012.2205241; Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; Toda T, 2007, IEICE T INF SYST, VE90D, P816, DOI 10.1093/ietisy/e90-d.5.816; Tokuda K., 2002, P IEEE SPEECH SYNTH; TOKUDA K, 1995, INT CONF ACOUST SPEE, P660, DOI 10.1109/ICASSP.1995.479684; Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Uria B., 2011, P NIPS 2011 WORKSH D; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wu YJ, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P577; Wu YJ, 2006, INT CONF ACOUST SPEE, P89; Wu Z.-Z, 2013, P IEEE CHIN SUMM INT, P104; Xia B.-Y., 2013, P INTERSPEECH, P3444; Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240; Xu Y., P INT IN PRESS; Yamagishi J., 2005, IEICE T INF SYST, VE88-D, P503; Yamagishi J, 2007, IEICE T INF SYST, VE90D, P533, DOI 10.1093/ietisy/e90-d.2.533; Yamagishi J, 2009, IEEE T AUDIO SPEECH, V17, P1208, DOI 10.1109/TASL.2009.2016394; Yoshimura T., 2002, THESIS NAGOYA I TECH; Yoshimura T., 1998, P ICSLP, V2, P29; Yoshimura T., 1999, P EUR, P2347; Yu D., 2010, P NIPS WORKSH DEEP L; Yu K, 2011, SPEECH COMMUN, V53, P914, DOI 10.1016/j.specom.2011.03.003; Zen HG, 2007, IEICE T INF SYST, VE90D, P325, DOI 10.1093/ietisy/e90-d.1.325; Zen H., 2014, P IEEE INT C AC SPEE, P3872; Zen H, 2012, IEEE T AUDIO SPEECH, V20, P1713, DOI 10.1109/TASL.2012.2187195; Zen H., 2013, COMMUNICATION; Zen H, 2012, IEEE T AUDIO SPEECH, V20, P794, DOI 10.1109/TASL.2011.2165280; Zen H, 2007, IEICE T INF SYST, VE90D, P825, DOI 10.1093/ietisy/e90-d.5.825; Zen H, 2007, COMPUT SPEECH LANG, V21, P153, DOI 10.1016/j.csl.2006.01.002; Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004; Zen HG, 2013, INT CONF ACOUST SPEE, P7962; Zhang XL, 2013, IEEE T AUDIO SPEECH, V21, P697, DOI 10.1109/TASL.2012.2229986	86	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-5888	1558-0792		IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	MAY	2015	32	3					35	52		10.1109/MSP.2014.2359987		18	Engineering, Electrical & Electronic	Engineering	CF4DL	WOS:000352498800006		
J	Capano, V; Herrmann, HJ; de Arcangelis, L				Capano, Vittorio; Herrmann, Hans J.; de Arcangelis, Lucilla			Optimal percentage of inhibitory synapses in multi-task learning	Scientific Reports			English	Article							NEURONAL AVALANCHES; SYNAPTIC DEPRESSION; NETWORKS; POTENTIATION; VARIABILITY; HIPPOCAMPUS; CIRCUITS; DYNAMICS	Performing more tasks in parallel is a typical feature of complex brains. These are characterized by the coexistence of excitatory and inhibitory synapses, whose percentage in mammals is measured to have a typical value of 20-30%. Here we investigate parallel learning of more Boolean rules in neuronal networks. We find that multi-task learning results from the alternation of learning and forgetting of the individual rules. Interestingly, a fraction of 30% inhibitory synapses optimizes the overall performance, carving a complex backbone supporting information transmission with a minimal shortest path length. We show that 30% inhibitory synapses is the percentage maximizing the learning performance since it guarantees, at the same time, the network excitability necessary to express the response and the variability required to confine the employment of resources.	[Capano, Vittorio] Univ Naples Federico II, Dept Phys, Naples, Italy; [Herrmann, Hans J.] ETH, Inst Computat Phys Engn Mat, Zurich, Switzerland; [Herrmann, Hans J.] Univ Fed Ceara, Dept Fis, BR-60451970 Fortaleza, Ceara, Brazil; [de Arcangelis, Lucilla] Univ Naples 2, Dept Ind & Informat Engn, Aversa, CE, Italy; INFN Gr Coll Salerno, Aversa, CE, Italy	de Arcangelis, L (reprint author), Univ Naples 2, Dept Ind & Informat Engn, Aversa, CE, Italy.	lucilla.dearcangelis@unina2.it			European Research Council (ERC) [319968]	We thank the European Research Council (ERC) Advanced Grant 319968-FlowCCS for financial support.	Arieli A, 1996, SCIENCE, V273, P1868, DOI 10.1126/science.273.5283.1868; Bak P, 2001, PHYS REV E, V63, DOI 10.1103/PhysRevE.63.031912; Barto A. G., 1983, IEEE T SYST MAN CYB, V13, P835; Beggs JM, 2003, J NEUROSCI, V23, P11167; Bonifazi P, 2009, SCIENCE, V326, P1419, DOI 10.1126/science.1175509; Brunel N, 2000, J COMPUT NEUROSCI, V8, P183, DOI 10.1023/A:1008925309027; Changeux J. P, 1985, NEURONAL MAN BIOL MI; Coussens CM, 1997, J NEUROPHYSIOL, V78, P1; de Arcangelis L., 2014, J STAT MECH-THEORY E, V3; de Arcangelis L, 2012, FRONT PHYSIOL, V3, DOI 10.3389/fphys.2012.00062; de Arcangelis L, 2010, P NATL ACAD SCI USA, V107, P3977, DOI 10.1073/pnas.0912289107; de Arcangelis L, 2006, PHYS REV LETT, V96, DOI 10.1103/PhysRevLett.96.028107; Eguiluz VM, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.018102; Frey U, 1997, NATURE, V385, P533, DOI 10.1038/385533a0; Garrett DD, 2011, J NEUROSCI, V31, P4496, DOI 10.1523/JNEUROSCI.5641-10.2011; Garrett DD, 2010, J NEUROSCI, V30, P4914, DOI 10.1523/JNEUROSCI.5166-09.2010; Ghosh A, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000196; Gireesh ED, 2008, P NATL ACAD SCI USA, V105, P7576, DOI 10.1073/pnas.0800537105; Lombardi F, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.228703; McIntosh AR, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000106; Otmakhova NA, 1998, J NEUROSCI, V18, P1270; Pellegrini GL, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.016107; Petermann T, 2009, P NATL ACAD SCI USA, V106, P15921, DOI 10.1073/pnas.0904089106; Reyes-Harde M, 1999, P NATL ACAD SCI USA, V96, P4061, DOI 10.1073/pnas.96.7.4061; Roerig B, 2002, CEREB CORTEX, V12, P187, DOI 10.1093/cercor/12.2.187; Royer S, 2003, NATURE, V422, P518, DOI 10.1038/nature01530; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Young J. Z, 1964, MODEL BRAIN	28	0	0	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	2045-2322			SCI REP-UK	Sci Rep	APR 22	2015	5								9895	10.1038/srep09895		5	Multidisciplinary Sciences	Science & Technology - Other Topics	CG4UZ	WOS:000353284000001	25898781	
J	Schuld, M; Sinayskiy, I; Petruccione, F				Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco			An introduction to quantum machine learning	CONTEMPORARY PHYSICS			English	Article						quantum machine learning; quantum computing; artificial intelligence; machine learning	NEURAL-NETWORKS; INFORMATION	Machine learning algorithms learn a desired input-output relation from examples in order to interpret new inputs. This is important for tasks such as image and speech recognition or strategy optimisation, with growing applications in the IT industry. In the last couple of years, researchers investigated if quantum computing can help to improve classical machine learning algorithms. Ideas range from running computationally costly algorithms or their subroutines efficiently on a quantum computer to the translation of stochastic methods into the language of quantum theory. This contribution gives a systematic overview of the emerging field of quantum machine learning. It presents the approaches as well as technical details in an accessible way, and discusses the potential of a future theory of quantum learning.	[Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco] Univ KwaZulu Natal, Sch Chem & Phys, Quantum Res Grp, ZA-4001 Durban, South Africa; [Sinayskiy, Ilya; Petruccione, Francesco] Natl Inst Theoret Phys NITheP, Kwa Zulu, South Africa	Schuld, M (reprint author), Univ KwaZulu Natal, Sch Chem & Phys, Quantum Res Grp, ZA-4001 Durban, South Africa.	schuld@ukzn.ac.za			South African Research Chair Initiative of the Department of Science and Technology; National Research Foundation	This work was supported by the South African Research Chair Initiative of the Department of Science and Technology and the National Research Foundation.	Aimeur E, 2013, MACH LEARN, V90, P261, DOI 10.1007/s10994-012-5316-5; Aimeur E, 2006, LECT NOTES ARTIF INT, V4013, P431; Alpaydin E., 2004, INTRO MACHINE LEARNI; Barry J, 2014, PHYS REV A, V90, DOI 10.1103/PhysRevA.90.032311; Behrman E. C., 2013, IEEE S SER COMP INT; Bishop C. M., 2006, PATTERN RECOGNITION, V1; Bisio A, 2010, PHYS REV A, V81, DOI 10.1103/PhysRevA.81.032324; Brassard G., 2000, ARXIVQUANTPH0005055; Breuer H-P, 2002, THEORY OPEN QUANTUM; Briegel H. J., 2012, SCI REP, V2, P1; Buhrman H, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.167902; Clark L. A., 2015, ISCS 2014, V14, P143; Dayan P., 2001, THEORETICAL NEUROSCI, V31; Du JF, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.137902; Duda R. O., 2012, PATTERN CLASSIFICATI; Durr C., 1996, QUANTPH9607014 ARXIV; Eisert J, 1999, PHYS REV LETT, V83, P3077, DOI 10.1103/PhysRevLett.83.3077; Faber J., 2002, QUANTUM MODELS ARTIF; Gammelmark S., 2009, NEW J PHYS, V11; Gammelmark S, 2013, PHYS REV A, V87, DOI 10.1103/PhysRevA.87.032115; Georgescu IM, 2014, REV MOD PHYS, V86, DOI 10.1103/RevModPhys.86.153; Giovannetti V, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.160501; Gu M., 2010, NEW J PHYS, V12; Gupta S, 2001, J COMPUT SYST SCI, V63, P355, DOI 10.1006/jcss.2001.1769; HAMMING RW, 1950, AT&T TECH J, V29, P147; Harrow AW, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.150502; Hechenbichler K., 2004, 399 SFB LUDW MAX U; Hentschel A, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.063603; Hertz J. A., 1991, INTRO THEORY NEURAL, V1; Hilbert M, 2011, SCIENCE, V332, P60, DOI 10.1126/science.1200970; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Horn D, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.018702; Hunziker M, 2010, QUANTUM INF PROCESS, V9, P321, DOI 10.1007/s11128-009-0129-6; Landsburg S. E., 2011, WILEY ENCY OPERATION; Lloyd S., 2013, ARXIV13070411; Lu SF, 2014, QUANTUM INF PROCESS, V13, P757, DOI 10.1007/s11128-013-0687-5; Monras A., 2010, APPL MATH COMPUT SCI, V3, P93; Neigovzen R, 2009, PHYS REV A, V79, DOI 10.1103/PhysRevA.79.042321; Neven H., 2009, ARXIV09120779; Nielsen M. A., 2010, QUANTUM COMPUTATION; Panella M, 2011, INT J CIRC THEOR APP, V39, P61, DOI 10.1002/cta.619; Piotrowski EW, 2003, INT J THEOR PHYS, V42, P1089, DOI 10.1023/A:1025443111388; Plenio MB, 2001, CONTEMP PHYS, V42, P25, DOI 10.1080/00107510010018916; Pudenz KL, 2013, QUANTUM INF PROCESS, V12, P2027, DOI 10.1007/s11128-012-0506-4; Purushothaman G, 1997, IEEE T NEURAL NETWOR, V8, P679, DOI 10.1109/72.572106; Rabbiner L. R., 1989, P IEEE, V77, P257; Rebentrost P, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.130503; Rigatos GG, 2007, INTEGR COMPUT-AID E, V14, P225; Rogers S., 2012, 1 COURSE MACHINE LEA; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Russell S. J., 2010, ARTIFICIAL INTELLIGE, V3; Samuel A. L., 2000, IBM Journal of Research and Development, V44; Sasaki M, 2002, PHYS REV A, V66, DOI 10.1103/PhysRevA.66.022303; Sasaki M, 2001, PHYS REV A, V64, part. no., DOI 10.1103/PhysRevA.64.022317; Schuld M, 2014, QUANTUM INF PROCESS, V13, P2567, DOI 10.1007/s11128-014-0809-8; Schutzhold R, 2003, PHYS REV A, V67, DOI 10.1103/PhysRevA.67.062311; Sentis G., 2012, SCI REP, V2, P1; Silvada A. J., 2012, NEUROCOMPUTING, V75, P52; Toth G, 1996, SUPERLATTICE MICROST, V20, P473, DOI 10.1006/spmi.1996.0104; Trugenberger CA, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.067901; Trugenberger CA, 2002, QUANTUM INF PROCESS, V1, P471, DOI 10.1023/A:1024022632303; Ventura D, 2000, INFORM SCIENCES, V124, P273, DOI 10.1016/S0020-0255(99)00101-2; Wiebe N, 2014, PHYS REV A, V89, DOI 10.1103/PhysRevA.89.042314; Wiebe N., 2014, ARXIV14012142; Wiesner K, 2008, PHYSICA D, V237, P1173, DOI 10.1016/j.physd.2008.01.021	66	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0010-7514	1366-5812		CONTEMP PHYS	Contemp. Phys.	APR 3	2015	56	2					172	185		10.1080/00107514.2014.964942		14	Physics, Multidisciplinary	Physics	CH0OW	WOS:000353722300005		
J	Sinha, K; Das, P				Sinha, Keka; Das (Saha), Papita			Assessment of water quality index using cluster analysis and artificial neural network modeling: a case study of the Hooghly River basin, West Bengal, India	DESALINATION AND WATER TREATMENT			English	Article						River Hooghly; Water quality index; DELPHI process; Cluster analysis; CCME method; ANN model	MULTIVARIATE STATISTICAL TECHNIQUES; CLASSIFICATION SCHEME; GROUNDWATER; ADSORPTION; EVOLUTION; POLLUTION; EXAMPLE; SPAIN	River Hooghly, considered as an important tributary of the River Ganga, has been affected by indiscriminate discharging of polluted and untreated sewage sludge and industrial waste into the waterways. The assessment of water quality for natural river waters was done using a water quality index (WQI), developed by DELPHI and the Council of Ministers of the Environment methods. These two methods reflect the quality of the water measured with respect to its pollution level. Multivariate statistical techniques, such as cluster analysis, were applied to the data-set on water quality of the Hooghly River (India) which was generated during the years 2002-2008 controlling at eight different sites for five parameters. The relationships among the stations are highlighted by cluster analysis to characterize the WQI. The study represents a computer-simulated artificial neural network model for the evaluation of the relationship between the different parameters of water bodies collected at different stations along Hooghly River responsible for water quality measurement. Finally, both the water quality methods (CCME and DELPHI) were statistically compared by the coefficient of determination (R-2), root mean square error, and absolute average deviation based on the validation data-set.	[Sinha, Keka] Natl Inst Technol Durgapur, Dept Biotechnol, Durgapur 713209, WB, India; [Das (Saha), Papita] Jadavpur Univ, Dept Chem Engn, Kolkata, India	Das, P (reprint author), Jadavpur Univ, Dept Chem Engn, Kolkata, India.	papitasaha@gmail.com					Abbasi S., 1998, WATER QUALITY SAMPLI, P200; Adriano A.B., 2006, J ENVIRON MANAGE, V38, P910, DOI DOI 10.1007/S00267-004-0037-6; Alexande S. A., 1999, INDIAN J ENV PROT, V19, P842; Bennetts DA, 2006, J HYDROL, V323, P178, DOI 10.1016/j.jhydrol.2005.08.023; Boyacioglu H, 2007, WATER SA, V33, P101; BROWN R. M., 1970, WATER SEWAGE WORKS, V117, P339; Canadian Council of Ministers of the Environment (CCME), 2001, CANADIAN ENVIRONMENT; Coulston F., 1977, WATER QUALITY P INT, P51; Cude CG, 2001, J AM WATER RESOUR AS, V37, P125, DOI 10.1111/j.1752-1688.2001.tb05480.x; Einax J. W., 1997, CHEMOMETRICS ENV ANA, DOI [10.1002/352760216X, DOI 10.1002/352760216X]; FOVELL RG, 1993, J CLIMATE, V6, P2103, DOI 10.1175/1520-0442(1993)006<2103:CZOTCU>2.0.CO;2; Geyikci F, 2012, CHEM ENG J, V183, P53, DOI 10.1016/j.cej.2011.12.019; Helena B, 2000, WATER RES, V34, P807, DOI 10.1016/S0043-1354(99)00225-0; Hogan C. M., 2010, WATER POLLUTION ENCY; LANDWEHR JM, 1976, J WATER POLLUT CON F, V48, P954; Moghaddam M. G., 2011, Food and Nutrition Sciences, V2, P803, DOI 10.4236/fns.2011.28110; Ozdemir U, 2011, CHEM ENG J, V178, P183, DOI 10.1016/j.cej.2011.10.046; Pandey M., 2002, INT J ECOL ENV SCI, V28, P139; Parmar Kavita, 2010, International Journal of Environmental Sciences, V1; Pesce SF, 2000, WATER RES, V34, P2915, DOI 10.1016/S0043-1354(00)00036-1; Pulido-Leboeuf P, 2003, CR GEOSCI, V335, P1039, DOI 10.1016/j.crte.2003.08.004; Recknage F., 2011, ECOL MODEL, V146, P303; Reghunath R, 2002, WATER RES, V36, P2437, DOI 10.1016/S0043-1354(01)00490-0; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saha P., 2007, J I ENG, V88, P3; Sanchez E, 2007, ECOL INDIC, V7, P315, DOI 10.1016/j.ecolind.2006.02.005; Sargaonkar A, 2003, ENVIRON MONIT ASSESS, V89, P43, DOI 10.1023/A:1025886025137; Simeonov V, 2003, WATER RES, V37, P4119, DOI 10.1016/S0043-1354(03)00398-1; Simeonov V, 2004, CHEM ENG ECOLOGY, V11, P449; Simeonova P, 2003, CENT EUR J CHEM, V1, P121, DOI 10.2478/BF02479264; Singh R. K., 1996, INDIAN J ENV HLTH, V8, P21; Singh KP, 2004, WATER RES, V38, P3980, DOI 10.1016/j.watres.2004.06.011; Sinha K, 2012, IND CROP PROD, V37, P408, DOI 10.1016/j.indcrop.2011.12.032; Tokar A. S., 2011, J HYDROL ENG, V399, P232; Vega M, 1998, WATER RES, V32, P3581, DOI 10.1016/S0043-1354(98)00138-9; Walsk T. M., 1974, J ENV, V5, P93	36	0	0	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	1944-3994	1944-3986		DESALIN WATER TREAT	Desalin. Water Treat.	APR 3	2015	54	1					28	36		10.1080/19443994.2014.880379		9	Engineering, Chemical; Water Resources	Engineering; Water Resources	CC9IX	WOS:000350683800001		
J	Grigorian, B; Reinman, G				Grigorian, Beayna; Reinman, Glenn			Accelerating Divergent Applications on SIMD Architectures Using Neural Networks	ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION			English	Article						Design; Performance	MEMORY DIVERGENCE; GPU APPLICATIONS; CONTROL FLOW; APPROXIMATION; PROGRAMS; BRANCH	The purpose of this research is to find a neural-network-based solution to the well-known problem of branch divergence in Single Instruction Multiple Data (SIMD) architectures. Our approach differs from existing techniques that handle branch (or control-flow) divergence, which use costly hardware modifications, low-utilization masking techniques, or static prediction methods. As we examine divergent applications, we characterize the degree of data-dependent control flow seen in each and isolate the code regions (or "kernels") that cause the most performance degradation due to branch divergence. We then train neural networks (NNs) offline to approximate these kernels and inject the NN computations directly into the applications as substitutes for the kernels they approximate. This essentially translates control flow into nondivergent computation, trading off precision for performance. As our methodology manipulates application source code directly, it is inherently platform agnostic and can be adopted as a general means for accelerating divergent applications on data-parallel architectures. In this article, we present the Neuralizer, an automated software flow for kernel identification, NN training, and NN integration, as well as supplementary user-controlled optimization techniques. Evaluating our approach on a variety of divergent applications run on a Graphics Processing Unit (GPU), we on average achieve performance gains of 13.6x and energy savings of 14.8x with 96% accuracy.	[Grigorian, Beayna; Reinman, Glenn] Univ Calif Los Angeles, Los Angeles, CA 90095 USA	Grigorian, B (reprint author), Univ Calif Los Angeles, 4731G Boelter Hall, Los Angeles, CA 90095 USA.	bgrigori@cs.ucla.edu; reinman@cs.ucla.edu			NSF Expedition in Computing Award [CCF-0926127]; NSF Graduate Research Fellowship [DGE-0707424]; C-FAR (MARCO); C-FAR (DARPA)	This research is supported by the NSF Expedition in Computing Award # CCF-0926127, by the NSF Graduate Research Fellowship Grant # DGE-0707424, and by C-FAR (one of six centers of STARnet, an SRC program sponsored by MARCO and DARPA).	Baek W, 2010, ACM SIGPLAN NOTICES, V45, P198; Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128; Carbin M, 2013, ACM SIGPLAN NOTICES, V48, P33, DOI 10.1145/2509136.2509546; Chaudhuri Swarat, 2011, P 19 ACM SIGSOFT S 1, P102; Che S, 2008, J PARALLEL DISTR COM, V68, P1370, DOI 10.1016/j.jpdc.2008.05.014; Chen T., 2012, IEEE INT S WORKL CHA, P36; Cho HM, 2012, IEEE T COMPUT AID D, V31, P546, DOI 10.1109/TCAD.2011.2179038; Cong Jason, 2012, P 2012 ACM IEEE INT, P379; Diamos Gregory, 2011, P 44 ANN IEEE ACM IN, P477; Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48; Esmaeilzadeh H, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P301; Fung WWL, 2011, INT S HIGH PERF COMP, P25, DOI 10.1109/HPCA.2011.5749714; Fung WWL, 2007, INT SYMP MICROARCH, P407, DOI 10.1109/MICRO.2007.30; Gong Jason, 2012, P 49 ANN DES AUT C, P843; Grigorian B, 2014, NASA ESA CONF, P248, DOI 10.1109/AHS.2014.6880184; Gschwind Michael, 2006, P 3 C COMP FRONT, P1, DOI DOI 10.1145/1128022.1128023; Haykin Simon, 1998, NEURAL NETWORKS COMP; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Kapasi UJ, 2000, INT SYMP MICROARCH, P159; Kapasi Ujval J., 2004, THESIS STANFORD U; Lee Y, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P129; Lomont Chris, 2011, P 2 ANN ASCI C, P132; Meher PK, 2010, PROCEEDINGS OF THE 2010 18TH IEEE/IFIP INTERNATIONAL CONFERENCE ON VLSI AND SYSTEM-ON-CHIP, P91; Meng JY, 2010, CONF PROC INT SYMP C, P235; Narasiman Veynu, 2011, P 44 ANN IEEE ACM IN, P308; Nissen Steffen, 2003, IMPLEMENTATION FAST; Nvidia, 2014, CUDA MATH LIB; Nvidia, 2014, CUDA 5 5 PROD REL; Nvidia, 2013, GEFORCE GTX 480; Ortega J. M., 1970, ITERATIVE SOLUTION N; P3 International, 2014, KILL A WATT; Quinlan D., 2000, Parallel Processing Letters, V10, DOI 10.1142/S0129626400000214; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Samadi Mehrzad, 2014, P 19 INT C ARCH SUPP, P35; Samadi Mehrzad, 2013, P 46 ANN INT S MICR, P13; Sampson A, 2011, ACM SIGPLAN NOTICES, V46, P164, DOI 10.1145/1993316.1993518; Sanders Jason, 2010, CUDA EXAMPLE INTRO G; Sartori J, 2013, IEEE T MULTIMEDIA, V15, P279, DOI 10.1109/TMM.2012.2232647; Seiler Larry, 2008, ACM T GRAPHIC, V27, P18; Sidiroglou-Douskos Stelios, 2011, P 19 ACM SIGSOFT S 1, P124; Smith JE, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P260, DOI 10.1109/ISCA.2000.854396; Vaidya Aniruddha S., 2013, P 40 ANN INT S COMP, P368; Venkatesh Ganesh, 2011, P 44 ANN IEEE ACM IN, P163; Wald Ingo, 2011, P ACM SIGGRAPH S HIG, P51; Wu HC, 2012, INT J HIGH PERFORM C, V26, P170, DOI 10.1177/1094342011434814; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	46	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1544-3566	1544-3973		ACM T ARCHIT CODE OP	ACM Trans. Archit. Code Optim.	APR	2015	12	1							2	10.1145/2717311		23	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	CH0YW	WOS:000353749300002		
J	Wang, KJ; Adrian, AM; Chen, KH; Wang, KM				Wang, Kung-Jeng; Adrian, Angelia Melani; Chen, Kun-Huang; Wang, Kung-Min			A hybrid classifier combining Borderline-SMOTE with AIRS algorithm for estimating brain metastasis from lung cancer: A case study in Taiwan	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Article						Artificial immune recognition system; Brain metastasis; Imbalance dataset; Lung cancer; Borderline-synthetic minority over sampling technique	RESOURCE-ALLOCATION MECHANISM; IMMUNE RECOGNITION SYSTEM; BREAST	Classifying imbalanced data in medical informatics is challenging. Motivated by this issue, this study develops a classifier approach denoted as BSMAIRS. This approach combines borderline synthetic minority oversampling technique (BSM) and artificial immune recognition system (AIRS) as global optimization searcher with the nearest neighbor algorithm used as a local classifier. Eight electronic medical datasets collected from University of California, Irvine (UCI) machine learning repository were used to evaluate the effectiveness and to justify the performance of the proposed BSMAIRS. Comparisons with several well-known classifiers were conducted based on accuracy, sensitivity, specificity, and G-mean. Statistical results concluded that BSMAIRS can be used as an efficient method to handle imbalanced class problems. To further confirm its performance, BSMAIRS was applied to real imbalanced medical data of lung cancer metastasis to the brain that were collected from National Health Insurance Research Database, Taiwan. This application can function as a supplementary tool for doctors in the early diagnosis of brain metastasis from lung cancer. (C) 2015 Elsevier Ireland Ltd. All rights reserved.	[Wang, Kung-Jeng; Adrian, Angelia Melani; Chen, Kun-Huang] Natl Taiwan Univ Sci & Technol, Dept Ind Management, Taipei 106, Taiwan; [Adrian, Angelia Melani] De La Salle Univ, Dept Informat Engn, Manado 95231, Indonesia; [Wang, Kung-Min] Shin Kong Wu Ho Su Mem Hosp, Dept Surg, Taipei, Taiwan	Wang, KJ (reprint author), Natl Taiwan Univ Sci & Technol, Dept Ind Management, Taipei 106, Taiwan.	kjwang@mail.ntust.edu.tw; melaning21@yahoo.com; khchen@mail.ntust.edu.tw; albert.hua@msa.hinet.net			National Science Council Taiwan	The authors gratefully acknowledge the comments and suggestions of the editor and the anonymous referees. This work is partially supported by the National Science Council Taiwan. This study is based in part on electronic data from the National Health Insurance Research Database provided by the Bureau of National Health Insurance, Department of Health and managed by National Health Research Institutes, Taiwan. The interpretation and conclusions contained herein do not represent those of Bureau of National Health Insurance, Department of Health or National Health Research Institutes.	ABTA, 2012, MET BRAIN TUM; Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39; Alcala-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255; [Anonymous], 2015, TAIWAN CANC REGISTRY; Bache K., 2013, UCI MACHINE LEARNING; Bogges L., 2003, INTELLIGENT ENG SYST, P219; Brownlee J., 2005, TECHNICAL REPORT, P1; Caroli M., 2011, ISRN SURG, P1; Chandana Sandeep, 2009, Cancer Inform, V7, P57; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; Ferlay J, 2010, INT J CANCER, V127, P2893, DOI 10.1002/ijc.25516; GAO M, 2011, P INT JOINT C NEUR N, P1146; Hamaker J. S., 2004, Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753), DOI 10.1109/CEC.2004.1330980; Han H, 2005, LECT NOTES COMPUT SC, V3644, P878; Hariharan M., 2014, COMPUT METH PROG BIO, V113, P904; Hung YN, 2014, BRIT J PSYCHIAT, V205, P183, DOI 10.1192/bjp.bp.114.144741; James A.P., 2012, COMPUT J, P1; Juanjuan W., 2007, P INT C SIGN PROC; Kawabe T., 2004, PROGR NEUROL SURG, V75, P148; Lam C, 2014, COMPUT METH PROG BIO, V115, P103, DOI 10.1016/j.cmpb.2014.04.002; Li DC, 2010, COMPUT BIOL MED, V40, P509, DOI 10.1016/j.compbiomed.2010.03.005; Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853; Majid A, 2014, COMPUT METH PROG BIO, V113, P792, DOI 10.1016/j.cmpb.2014.01.001; National Health Insurance Research Database (NHIRD), 2014, NAT HLTH INS RES DAT; Polat K, 2007, EXPERT SYST APPL, V32, P172, DOI 10.1016/j.eswa.2005.11.024; Polat K, 2007, EXPERT SYST, V24, P252, DOI 10.1111/j.1468-0394.2007.00432.x; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Roth A., 2011, LUNG CANC; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saidi M., 2011, P INT C COMP SCI ITS; Shouman M., 2012, INT J INF ED TECH, V2, P220; Timmis J, 2000, BIOSYSTEMS, V55, P143, DOI 10.1016/S0303-2647(99)00092-1; Wang K.J., 2013, BMC MED INFORM DECIS, V13, P2; WANG KM, 2013, INT J COMPUT SCI ELE, V307, P1; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; Watkins A., 2007, 1 INT C ART IMM SYST, P173; Werbos P. J., 1974, THESIS HARVARD U; Zabel A, 2004, LUNG CANCER-J IASLC, V45, pS247, DOI 10.1016/j.lungcan.2004.07.000	40	0	0	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607	1872-7565		COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	APR	2015	119	2					63	76		10.1016/j.cmpb.2015.03.003		14	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	CF0FA	WOS:000352217000001	25823851	
J	Silversides, K; Melkumyan, A; Wyman, D; Hatherly, P				Silversides, Katherine; Melkumyan, Arman; Wyman, Derek; Hatherly, Peter			Automated recognition of stratigraphic marker shales from geophysical logs in iron ore deposits	COMPUTERS & GEOSCIENCES			English	Article						Mine modelling; Gaussian Processes; Machine learning	WESTERN-AUSTRALIA; HAMERSLEY PROVINCE; SEISMIC DATA; PREDICTION; IDENTIFICATION	The mining of stratiform ore deposits requires a means of determining the location of stratigraphic boundaries. A variety of geophysical logs may provide the required data but, in the case of banded iron formation hosted iron ore deposits in the Hamersley Ranges of Western Australia, only one geophysical log type (natural gamma) is collected for this purpose. The information from these logs is currently processed by slow manual interpretation. In this paper we present an alternative method of automatically identifying recurring stratigraphic markers in natural gamma logs from multiple drill holes. Our approach is demonstrated using natural gamma geophysical logs that contain features corresponding to the presence of stratigraphically important marker shales. The host stratigraphic sequence is highly consistent throughout the Hamersley and the marker shales can therefore be used to identify the stratigraphic location of the banded iron formation (BIF) or BIF hosted ore. The marker shales are identified using Gaussian Processes (GP) trained by either manual or active learning methods and the results are compared to the existing geological interpretation. The manual method involves the user selecting the signatures for improving the library, whereas the active learning method uses the measure of uncertainty provided by the GP to select specific examples for the user to consider for addition. The results demonstrate that both GP methods can identify a feature, but the active learning approach has several benefits over the manual method. These benefits include greater accuracy in the identified signatures, faster library building, and an objective approach for selecting signatures that includes the full range of signatures across a deposit in the library. When using the active learning method, it was found that the current manual interpretation could be replaced in 78.4% of the holes with an accuracy of 95.7%. (C) 2015 Elsevier Ltd. All rights reserved.	[Silversides, Katherine; Melkumyan, Arman; Hatherly, Peter] Univ Sydney, Australian Ctr Field Robot, Sydney, NSW 2006, Australia; [Wyman, Derek] Univ Sydney, Sch Geosci, Sydney, NSW 2006, Australia	Silversides, K (reprint author), Univ Sydney, Australian Ctr Field Robot, Rose St Bldg J04, Sydney, NSW 2006, Australia.	katherine.silversides@sydney.edu.au			Australian Centre for Field Robotics; Rio Tinto Centre for Mine Automation	This work has been supported by the Australian Centre for Field Robotics and the Rio Tinto Centre for Mine Automation.	Bezdek J., 1981, PATTERN RECOGNITION; Bishop C. M., 2006, PATTERN RECOGNITION; Borsaru M, 2006, APPL RADIAT ISOTOPES, V64, P272, DOI 10.1016/j.apradiso.2005.07.012; Chang HC, 2002, COMPUT GEOSCI-UK, V28, P223, DOI 10.1016/S0098-3004(01)00067-X; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; Davis J. C., 2002, STAT DATA ANAL GEOLO; Davis J.C, 1986, STAT DATA ANAL GEOLO, P646; Faraklioti M, 2004, MACH VISION APPL, V15, P216, DOI 10.1007/s00138-004-0151-8; Harmsworth R.A., 1990, GEOLOGY MINERAL DEPO, P617; Hoyes Jack, 2011, Leading Edge, V30, DOI 10.1190/1.3535431; Jeong C, 2013, ENERG SOURCE PART A, V35, P66, DOI 10.1080/15567030903515021; Jones H., 1973, P MOD EXPL METH REC, P53; Kohonen T., 1984, SELF ORG ASS MEMORY; Lascelles DF, 2000, AUST J EARTH SCI, V47, P799, DOI 10.1046/j.1440-0952.2000.00810.x; Lascelles DF, 2006, ECON GEOL, V101, P1359, DOI 10.2113/gsecongeo.101.7.1359; Li LL, 2012, IEEE GEOSCI REMOTE S, V9, P1066, DOI 10.1109/LGRS.2012.2190039; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rider M. H., 1996, GEOLOGICAL INTERPRET, V2nd; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SILVERSIDES KL, 2011, P IEEE INT C ROB AUT, P1577; Srivastava RM, 2005, MATH GEOL, V37, P513, DOI 10.1007/s11004-005-6670-7; Thorne W, 2008, REV ECON GEOL, V15, P197; Wang GC, 2012, COMPUT GEOSCI-UK, V49, P151, DOI 10.1016/j.cageo.2012.07.011	23	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0098-3004	1873-7803		COMPUT GEOSCI-UK	Comput. Geosci.	APR	2015	77						118	125		10.1016/j.cageo.2015.02.002		8	Computer Science, Interdisciplinary Applications; Geosciences, Multidisciplinary	Computer Science; Geology	CF7OA	WOS:000352745000012		
J	Salle, IL				Salle, Isabelle L.			Modeling expectations in agent-based models - An application to central bank's communication and monetary policy	ECONOMIC MODELLING			English	Article						Expectations; Agent-based modeling; Neural networks; Communication; Monetary policy	NEURAL-NETWORKS; HETEROGENEOUS EXPECTATIONS; RATIONAL-EXPECTATIONS; BOUNDED RATIONALITY; MACROECONOMIC MODEL; ALGORITHMS	Expectations play a major role in macroeconomic dynamics, especially regarding the conduct of monetary policy. Yet, modeling the interplay between communication, expectations and aggregate outcomes remains a challenging task, mainly because this requires deviation from the paradigm of rational expectations and perfect information. While agent-based macro models allow for such a deviation, their representation of expectations dynamics often remains simplistic. This paper introduces an expectation formation model which allows us to integrate a wide range of information disclosed by central banks. This expectation model is then integrated to the macroeconomic ABM developed in Salle et al. 2013 - [Economic Modelling, 2013, 34, 114-1281, and yields aggregate results strongly in line with empirical evidence. In particular, we find that i) opacity is always sub-optimal, giving rise to the so-called opacity bias, ii) communication loosens the trade-off between the two objectives of monetary policy, and iii) forward guidance acts as a partial substitute for policy actions, and softens the optimal policy responses. This expectation model appears therefore promising to develop macroeconomic agent-based models. (c) 2015 Elsevier B.V. All rights reserved.	[Salle, Isabelle L.] Amsterdam Sch Econ, CeNDEF, NL-1018 XE Amsterdam, Netherlands; [Salle, Isabelle L.] Tinbergen Inst, Amsterdam, Netherlands; [Salle, Isabelle L.] Univ Bordeaux, GREThA, Talence, France	Salle, IL (reprint author), Amsterdam Sch Econ, CeNDEF, Valckenierstr 65-67,Bldg J-K, NL-1018 XE Amsterdam, Netherlands.	I.L.Salle@uva.nl			EU FP7 RAstaNEWS project [320278]	I thank Paul De Grauwe, Cars Hommes, Marc-Alexandre Senegas, Thomas Vallee, Jouko Vilmunen and Murat Yildizoglu for their helpful comments and discussions at an earlier stage of this research. Financial support from the EU FP7 RAstaNEWS project (work package 2) under grant agreement No. 320278 (2013-2015) is greatly acknowledged.	Arifovic J, 2000, MACROECON DYN, V4, P373, DOI 10.1017/S1365100500016059; Arifovic J., 2014, 201406 GRETHA; Ashraf Q., 2012, NBER WORKING PAPERS, V18225; BENASSY JP, 1993, J ECON LIT, V31, P732; BOOKER LB, 1989, ARTIF INTELL, V40, P235, DOI 10.1016/0004-3702(89)90050-7; Brainard W, 1967, AM ECON REV, V57, P411; Branch WA, 2011, ECON THEOR, V47, P365, DOI 10.1007/s00199-010-0539-9; Brazier A, 2008, INT J CENT BANK, V4, P219; Bullard M., 2002, J MONETARY ECON, V49, P1105; Cho I.-K., 1997, LEARNING BE CREDIBLE; Cho I.-K, 1996, HDB COMPUTATIONAL EC, P441; Baeriswyl R, 2010, INT J CENT BANK, V6, P31; Cukierman A, 1986, FEDERAL RESERVE BANK, P5; De Grauwe P, 2011, ECON THEOR, V47, P423, DOI 10.1007/s00199-010-0543-0; Gatti DD, 2011, NEW ECON WINDOWS, P1, DOI 10.1007/978-88-470-1971-3; Demertzis M., 2009, BE J MACROECON, V99, P44; Dosi G, 2013, J ECON DYN CONTROL, V37, P1598, DOI 10.1016/j.jedc.2012.11.008; Dosi G, 2010, J ECON DYN CONTROL, V34, P1748, DOI 10.1016/j.jedc.2010.06.018; Eijffinger S. C., 2007, CEPR DISCUSSION PAPE; Eusepi S, 2010, AM ECON J-MACROECON, V2, P235, DOI 10.1257/mac.2.3.235; Evans G. W., 2001, LEARNING EXPECTATION; Geraats P., 2014, CESIFO WORKING PAPER, V4611; Geraats P., 2014, CESIFO WORKING PAPER, V4642; Geraats PM, 2009, INT FINANC, V12, P235, DOI 10.1111/j.1468-2362.2009.01239.x; Haber G, 2008, JAHRB NATL STAT, V228, P276; Heinemann M, 2000, J ECON DYN CONTROL, V24, P1007, DOI 10.1016/S0165-1889(99)00034-2; Herbrich R., 1999, ADV COMPUTATIONAL EC, V11, P169; Hildebrand P. M., 2006, FINANCIAL MARKETS PO, V20, P7, DOI 10.1007/s11408-006-0004-8; Hommes C, 2011, J ECON DYN CONTROL, V35, P1, DOI 10.1016/j.jedc.2010.10.003; Kahneman D, 2003, AM ECON REV, V93, P1449, DOI 10.1257/000282803322655392; KYDLAND FE, 1977, J POLIT ECON, V85, P473, DOI 10.1086/260580; Lamla MJ, 2011, APPL ECON, V43, P4289, DOI 10.1080/00036846.2010.491452; Lengnick M, 2013, J ECON BEHAV ORGAN, V86, P102, DOI 10.1016/j.jebo.2012.12.021; Marcet A., 1989, SUNSPOTS COMPLEXITY; Massaro D, 2013, J ECON DYN CONTROL, V37, P680, DOI 10.1016/j.jedc.2012.11.001; Masters T., 1993, PRACTICAL NEURAL NET; Mehrotra K., 1997, ELEMENTS ARTIFICIAL; Minegishi M., 2009, OECD EC DEP WORKING, V724; Oeffner M., 2008, THESIS BAYERISCHE JU; Orphanides A., 2005, INFLATION TARGETING; Orphanides A., 2007, MOMETARY POLICY INFL, VXI; Rotemberg J., 1998, NBER TECHNICAL WORKI, V0233; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salle I, 2013, ECON MODEL, V34, P114, DOI 10.1016/j.econmod.2013.01.031; Salle I., 2012, THESIS U BORDEAUX; Salle I., 2013, 2013 24 GRETHA; Salmon M., 1995, LEARNING RATIONALITY, P236; Sargent T., 1987, EC POLICY THEORY PRA; Seppecher P, 2012, MACROECON DYN, V16, P284, DOI 10.1017/S1365100511000447; Sgroi D, 2009, J ECON BEHAV ORGAN, V69, P27, DOI 10.1016/j.jebo.2008.09.008; Sgroi D, 2007, PHYSICA A, V375, P717, DOI 10.1016/j.physa.2006.10.026; Simon H., 1971, IFIP C, P261; Simon H.A., 1996, SCI ARTIFICIAL; Svensson Lars E.O., 2009, SVERIGES RIKSBANK EC, V2009, P5; TAYLOR JB, 1979, ECONOMETRICA, V47, P1267, DOI 10.2307/1911962; Tesfatsion L., HDB COMPUTATIONAL EC, V2; Walsh C., 2010, TRANSPARENCY O UNPUB; Walsh C., 2006, MONETARY POLICY INFL; Walsh Carl E., 2007, INT J CENT BANK, V3, P5; Walsh CE, 2008, FED RESERVE BANK ST, V90, P421; White H., 1992, ARTIFICAIAL NEURAL N; Williams J., 2010, FRBSF EC REV, P1; Woodford M, 2003, INTEREST AND PRICES: FOUNDATIONS OF A THEORY OF MONETARY POLICY, P1; Woodford M., 2005, P FEDERAL RESERVE BA, P399; Yildizoglu M., 2001, EUROPEAN J EC SOCIAL, V15, P51; Yildizoglu M, 2014, MACROECON DYN, V18, P727, DOI 10.1017/S1365100512000582	66	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0264-9993	1873-6122		ECON MODEL	Econ. Model.	APR	2015	46						130	141		10.1016/j.econmod.2014.12.040		12	Economics	Business & Economics	CE6UW	WOS:000351974700013		
J	Oliveira, GG; Pedrollo, OC; Castro, NMR				Oliveira, Guilherme G.; Pedrollo, Olavo C.; Castro, Nilza M. R.			Simplifying artificial neural network models of river basin behaviour by an automated procedure for input variable selection	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						Relative contribution index (RCI); Nested drainage basins; Hydrological simulation; Effect of scale	RAINFALL-RUNOFF MODELS; PREDICTION; IDENTIFICATION	The objective of the present work is to present a simplified and automated method for identifying and excluding unnecessary input variables, with a consequent reduction in dimensionality of ANN-based hydrological models. The proposed method is iterative and computationally efficient: it consists of perturbing the input variables, recording the change in model performance, establishing an index showing the contribution of each variable to the ANN (the relative contribution index, RCI) and excluding the least-influential variables that fall below a threshold. The method was used to simulate mean daily flow for a 20-year period 1989-2009 from four drainage basins nested at different scales ranging from 19.4 km(2) to 9426 km, in the Southern Brazil. The main result of this method of simplifying ANN-based hydrological models was to increase the Nash-Sutcliffe (NS) coefficient and to reduce RMSE in all the simulations undertaken. The potential of ANN models was therefore improved by eliminating unnecessary and/or redundant variables. Simulating the intermediate basin with area 5414 km(2) (Santo Angelo), for example, the initial performance (12 inputs; NS= 0.894) improved when a simpler and more parsimonious model was used (4 inputs; NS= 0.944). To validate the simplification procedure, a comparison was made between the proposed method (RCI) and the well-known methods of Overall Connection Weights (OCW) and Forward Stepwise Addition (FSA). For the comparison between RCI and OCW methods, in most cases, the ordering of selected variables was similar, confirming that the two procedures satisfactorily identify the more important variables, although the RCI is computationally more efficient giving a small advantage in the resulting model performance. In the FSA method, although the performance of the obtained models has also been satisfactory, the computational effort was much greater than with the other two methods because of the excessive number of the neural network training performed (117 training procedures in Combination 2, against only six for the RCI method, for example). (C) 2015 Elsevier Ltd. All rights reserved.	[Oliveira, Guilherme G.; Pedrollo, Olavo C.; Castro, Nilza M. R.] Univ Fed Rio Grande do Sul, Inst Hydraul Res, BR-91501970 Porto Alegre, RS, Brazil	Oliveira, GG (reprint author), Univ Fed Rio Grande do Sul, Inst Hydraul Res, Av Bento Goncalves 9500, BR-91501970 Porto Alegre, RS, Brazil.	g.g.oliveira10@gmail.com					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Bishop C. M., 1995, NEURAL NETWORKS PATT; Bowden GJ, 2005, J HYDROL, V301, P75, DOI 10.1016/j.jhydrol.2004.06.021; Campolo M, 1999, WATER RESOUR RES, V35, P3547, DOI 10.1029/1999WR900205; Castro NMD, 1999, HYDROL PROCESS, V13, P1621; Castro N.M.R., 2010, FINAL REPORT ACTIVIT; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dawson CW, 1998, HYDROLOG SCI J, V43, P47, DOI 10.1080/02626669809492102; DIMOPOULOS Y, 1995, NEURAL PROCESS LETT, V2, P1, DOI 10.1007/BF02309007; Dornelles F, 2013, RBRH REV BRASILEIRA, V18, P45; Garson GD, 1991, AI EXPERT, V6, P47; Gevrey M, 2003, ECOL MODEL, V160, P249, DOI 10.1016/S0304-3800(02)00257-0; GOH ATC, 1995, ARTIF INTELL ENG, V9, P143, DOI 10.1016/0954-1810(94)00011-S; Guha R, 2005, J CHEM INF MODEL, V45, P1109, DOI 10.1021/ci050110v; Guo L, 2010, J NEUROSCI METH, V191, P101, DOI 10.1016/j.jneumeth.2010.05.020; HSU KL, 1995, WATER RESOUR RES, V31, P2517, DOI 10.1029/95WR01955; Imrie CE, 2000, J HYDROL, V233, P138, DOI 10.1016/S0022-1694(00)00228-6; Jain A, 2004, HYDROL PROCESS, V18, P571, DOI 10.1002/hyp.5502; Jain A, 2007, APPL SOFT COMPUT, V7, P585, DOI 10.1016/j.asoc.2006.03.002; Jayawardena A.W, 1997, IAHS PUBLICATION INT, P239; Khashei M, 2011, APPL SOFT COMPUT, V11, P2664, DOI 10.1016/j.asoc.2010.10.015; Lek S, 1996, ECOL MODEL, V90, P39, DOI 10.1016/0304-3800(95)00142-5; Lek S, 1995, MAR FRESHWATER RES, V46, P1229, DOI 10.1071/MF9951229; Li G, 2010, APPL ENERG, V87, P2313, DOI 10.1016/j.apenergy.2009.12.013; Lu JQ, 2011, IEEE T NEURAL NETWOR, V22, P329, DOI 10.1109/TNN.2010.2101081; Maier H. R., 1997, Microcomputers in Civil Engineering, V12; Maier HR, 1998, ECOL MODEL, V105, P257, DOI 10.1016/S0304-3800(97)00161-0; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; Maier HR, 1996, WATER RESOUR RES, V32, P1013, DOI 10.1029/96WR03529; Mak B, 1998, IEEE T SYST MAN CY C, V28, P561, DOI 10.1109/5326.725342; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Olden JD, 2004, ECOL MODEL, V178, P389, DOI 10.1016/j.ecolmodel.2004.03.013; Olden JD, 2002, ECOL MODEL, V154, P135, DOI 10.1016/S0304-3800(02)00064-9; Ozturk C, 2011, IEEE C EVOL COMPUTAT, P84; Piotrowski AP, 2011, J HYDROL, V407, P12, DOI 10.1016/j.jhydrol.2011.06.019; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sajikumar N, 1999, J HYDROL, V216, P32, DOI 10.1016/S0022-1694(98)00273-X; Scardi M, 1999, ECOL MODEL, V120, P213, DOI 10.1016/S0304-3800(99)00103-9; Shamseldin AY, 1997, J HYDROL, V199, P272, DOI 10.1016/S0022-1694(96)03330-6; Silva V.S.V., 2011, THESIS FEDERAL U RIO; Slowik A, 2011, IEEE T IND ELECTRON, V58, P3160, DOI 10.1109/TIE.2010.2062474; Sudheer KP, 2002, HYDROL PROCESS, V16, P1325, DOI 10.1002/hyp.554; Talebizadeh M, 2011, EXPERT SYST APPL, V38, P4126, DOI 10.1016/j.eswa.2010.09.075; Tiwari MK, 2010, J HYDROL, V382, P20, DOI 10.1016/j.jhydrol.2009.12.013; Tucci C.E.M., 1980, P OXF S APR 1980 IAS, P445; Valenca Ludermir T.B., 2007, 17 S BRAS REC HIDR S; Widrow B., 1960, 4 WESCON, P96	47	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976	1873-6769		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	APR	2015	40						47	61		10.1016/j.engappai.2015.01.001		15	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	CE7TV	WOS:000352045600006		
J	Zhou, P; Jiang, H; Dai, LR; Hu, Y; Liu, QF				Zhou, Pan; Jiang, Hui; Dai, Li-Rong; Hu, Yu; Liu, Qing-Feng			State-Clustering Based Multiple Deep Neural Networks Modeling Approach for Speech Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Cross entropy training; data partition; deep neural networks (DNN); model parallelism; multiple DNNs (mDNN); parallel training; sequence training; speech recognition; state clustering	SYSTEMS	The hybrid deep neural network (DNN) and hidden Markov model (HMM) has recently achieved dramatic performance gains in automatic speech recognition (ASR). The DNN-based acoustic model is very powerful but its learning process is extremely time-consuming. In this paper, we propose a novel DNN-based acoustic modeling framework for speech recognition, where the posterior probabilities of HMM states are computed from multiple DNNs (mDNN), instead of a single large DNN, for the purpose of parallel training towards faster turnaround. In the proposed mDNN method all tied HMM states are first grouped into several disjoint clusters based on data-driven methods. Next, several hierarchically structured DNNs are trained separately in parallel for these clusters using multiple computing units (e.g. GPUs). In decoding, the posterior probabilities of HMM states can be calculated by combining outputs from multiple DNNs. In this work, we have shown that the training procedure of the mDNN under popular criteria, including both frame-level cross-entropy and sequence-level discriminative training, can be parallelized efficiently to yield significant speedup. The training speedup is mainly attributed to the fact that multiple DNNs are parallelized over multiple GPUs and each DNN is smaller in size and trained by only a subset of training data. We have evaluated the proposed mDNN method on a 64-hour Mandarin transcription task and the 320-hour Switchboard task. Compared to the conventional DNN, a 4-cluster mDNN model with similar size can yield comparable recognition performance in Switchboard (only about 2% performance degradation) with a greater than 7 times speed improvement in CE training and a 2.9 times improvement in sequence training, when 4 GPUs are used.	[Zhou, Pan; Dai, Li-Rong; Hu, Yu; Liu, Qing-Feng] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China; [Jiang, Hui] York Univ, Lassonde Sch Engn, Dept Elect Engn & Comp Sci, Toronto, ON M3J 1P3, Canada	Zhou, P (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China.	pan2005@mail.ustc.edu.cn; hj@cse.yorku.ca; lrdai@ustc.edu.cn; yuhu@iflytek.com; qfliu@iflytek.com			National Nature Science Foundation of China [61273264]; National 973 program of China [2012CB326405]	This work was supported in part by the National Nature Science Foundation of China under Grant 61273264 and in part by the National 973 program of China under Grant 2012CB326405. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Mei-Yuh Hwang.	Abdel-Hamid O., 2012, P IEEE INT C AC SPEE; Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736; Bourlard H., 1992, P IEEE INT C AC SPEE; Bourlard H. A., 1993, CONNECTIONIST SPEECH; Chen X., 2012, P INTERSPEECH; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; FRANCO H, 1994, COMPUT SPEECH LANG, V8, P211, DOI 10.1006/csla.1994.1010; Gibson M., 2006, P INTERSPEECH; Grezl F., 2007, P IEEE INT C AC SPEE, P4729; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2012, P INTERSPEECH; Jiang H, 2010, COMPUT SPEECH LANG, V24, P589, DOI 10.1016/j.csl.2009.08.002; Kingsbury B., 2012, P INTERSPEECH; Kontar S., 2006, P 12 INT C SOFT COMP; Le H.-S., 2013, IEEE T AUDIO SPEECH, V21, P197; Le Q., 2012, P ICML; Li X., 2006, P INT C SPOK LANG PR; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed A.-R., 2012, P IEEE INT C AC SPEE; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301; Park J., 2009, P INTERSPEECH; Povey D., 2004, DISCRIMINATIVE TRAIN, V79; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sainath T. N., 2013, P IEEE INT C AC SPEE; Seide F., 2011, P IEEE WORKSH AUT SP; Seide F., 2014, P INTERSPEECH; Seide F., 2011, P INTERSPEECH, P437; Su H., 2013, P IEEE INT C AC SPEE; Valtchev V, 1997, SPEECH COMMUN, V22, P303, DOI 10.1016/S0167-6393(97)00029-0; Vesely K., 2010, P INTERSPEECH; Xue J., 2013, P INTERSPEECH; Xue SF, 2014, IEEE-ACM T AUDIO SPE, V22, P1713, DOI 10.1109/TASLP.2014.2346313; Yu D., 2010, P NIPS WORKSH DEEP L; Yu D., 2012, P IEEE INT C AC SPEE; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Zhang S., 2014, P IEEE INT C AC SPEE; Zhang S., 2013, P IEEE INT C AC SPEE; Zhou P., 2014, P IEEE INT C AC SPEE; Zhou P., 2013, P IEEE INT C AC SPEE	43	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	APR	2015	23	4					631	642		10.1109/TASLP.2015.2392944		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CE4ZY	WOS:000351840600003		
J	Zhang, NM				Zhang, Naimin			A Study on the Optimal Double Parameters for Steepest Descent with Momentum	NEURAL COMPUTATION			English	Letter							FEEDFORWARD NEURAL-NETWORKS; QUADRATIC-FUNCTIONS; LEARNING RATE; BACKPROPAGATION ALGORITHM; GRADIENT-METHOD; CONVERGENCE; TERM	This letter presents the stability analysis for two steepest descent algorithms with momentum for quadratic functions. The corresponding local optimal parameters in Torii and Hagan (2002) and Zhang (2013) are extended to the global optimal parameters, that is, both the optimal learning rates and the optimal momentum factors are obtained simultaneously which make for the fastest convergence.	Wenzhou Univ, Sch Math & Informat Sci, Wenzhou 325035, Peoples R China	Zhang, NM (reprint author), Wenzhou Univ, Sch Math & Informat Sci, Wenzhou 325035, Peoples R China.	nmzhang@wzu.edu.cn					Attoh-Okine NO, 1999, ADV ENG SOFTW, V30, P291, DOI 10.1016/S0965-9978(98)00071-4; Bhaya A, 2004, NEURAL NETWORKS, V17, P65, DOI 10.1016/S0893-6080(03)00170-9; Chao Z, 2014, J COMPUT APPL MATH, V266, P52, DOI 10.1016/j.cam.2014.01.023; Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2; Cristianini N., 2000, INTRO SUPPORT VECTOR; Fung G, 2003, NEUROCOMPUTING, V55, P39, DOI 10.1016/S0925-2312(03)00379-5; PHANSALKAR VV, 1994, IEEE T NEURAL NETWOR, V5, P505, DOI 10.1109/72.286925; Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shao HM, 2011, NEUROCOMPUTING, V74, P749, DOI 10.1016/j.neucom.2010.10.008; Shao HM, 2012, NEUROCOMPUTING, V77, P243, DOI 10.1016/j.neucom.2011.09.003; Shao HM, 2011, NEUROCOMPUTING, V74, P765, DOI 10.1016/j.neucom.2010.10.005; Torii M, 2002, IEEE T NEURAL NETWOR, V13, P752, DOI 10.1109/TNN.2002.1000143; Wang J, 2011, IEEE T NEURAL NETWOR, V22, P1297, DOI 10.1109/TNN.2011.2159992; Xu DP, 2012, NEUROCOMPUTING, V93, P133, DOI 10.1016/j.neucom.2012.03.013; YOUNG D., 1971, ITERATIVE SOLUTIONS; Yu XH, 1997, NEURAL NETWORKS, V10, P517, DOI 10.1016/S0893-6080(96)00102-5; YU XH, 1995, IEEE T NEURAL NETWOR, V6, P669; Zhang NM, 2013, NEURAL COMPUT, V25, P1277, DOI 10.1162/NECO_a_00436; Zhang NM, 2006, IEEE T NEURAL NETWOR, V17, P522, DOI 10.1109/TNN.2005.863460	21	0	0	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	0899-7667	1530-888X		NEURAL COMPUT	Neural Comput.	APR	2015	27	4					982	1004		10.1162/NECO_a_00710		23	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	CE1WO	WOS:000351603800007	25602771	
J	Fuster, JM; Bressler, SL				Fuster, Joaquin M.; Bressler, Steven L.			Past Makes Future: Role of pFC in Prediction	JOURNAL OF COGNITIVE NEUROSCIENCE			English	Review							MEDIAL PREFRONTAL CORTEX; VERBAL WORKING-MEMORY; POSTERIOR PARIETAL CORTEX; HUMAN FRONTAL-LOBE; COGNITIVE CONTROL; DECISION-MAKING; VISUAL-CORTEX; ANTERIOR CINGULATE; CORTICOCORTICAL CONNECTIONS; FUNCTIONAL NEUROANATOMY	The pFC enables the essential human capacities for predicting future events and preadapting to them. These capacities rest on both the structure and dynamics of the human pFC. Structurally, pFC, together with posterior association cortex, is at the highest hierarchical level of cortical organization, harboring neural networks that represent complex goal-directed actions. Dynamically, pFC is at the highest level of the perception-action cycle, the circular processing loop through the cortex that interfaces the organism with the environment in the pursuit of goals. In its predictive and preadaptive roles, pFC supports cognitive functions that are critical for the temporal organization of future behavior, including planning, attentional set, working memory, decision-making, and error monitoring. These functions have a common future perspective and are dynamically intertwined in goal-directed action. They all utilize the same neural infrastructure: a vast array of widely distributed, overlapping, and interactive cortical networks of personal memory and semantic knowledge, named cognits, which are formed by synaptic reinforcement in learning and memory acquisition. From this cortex-wide reservoir of memory and knowledge, pFC generates purposeful, goal-directed actions that are preadapted to predicted future events.	[Fuster, Joaquin M.] Univ Calif Los Angeles, Los Angeles, CA USA; [Bressler, Steven L.] Florida Atlantic Univ, Boca Raton, FL 33431 USA	Bressler, SL (reprint author), Florida Atlantic Univ, Ctr Complex Syst & Brain Sci, 777 Glades Rd, Boca Raton, FL 33431 USA.	joaquinf@ucla.edu; bressler@fau.edu					Adams RA, 2013, BRAIN STRUCT FUNCT, V218, P611, DOI 10.1007/s00429-012-0475-5; Addis DR, 2007, NEUROPSYCHOLOGIA, V45, P1363, DOI 10.1016/j.neuropsychologia.2006.10.016; Alexander WH, 2011, NAT NEUROSCI, V14, P1338, DOI 10.1038/nn.2921; Amiri A, 2014, NEURAL COMPUT, V26, P377, DOI 10.1162/NECO_a_00546; ANDERSEN RA, 1990, J NEUROSCI, V10, P1176; Asaad WF, 2011, J NEUROSCI, V31, P17772, DOI 10.1523/JNEUROSCI.3793-11.2011; Averbeck BB, 2009, J NEUROPHYSIOL, V102, P1911, DOI 10.1152/jn.00519.2009; Azuar C, 2014, NEUROIMAGE, V84, P1053, DOI 10.1016/j.neuroimage.2013.09.031; Baddeley A. D., 1993, ATTENTION SELECTION, P152; BADDELEY AD, 1983, PHILOS T ROY SOC B, V302, P311, DOI 10.1098/rstb.1983.0057; Badre D, 2009, NAT NEUROSCI, V12, P515, DOI 10.1038/nn.2277; Badre D, 2008, TRENDS COGN SCI, V12, P193, DOI 10.1016/j.tics.2008.02.004; Baldauf D, 2014, SCIENCE, V344, P424, DOI 10.1126/science.1247003; Bari A, 2013, PROG NEUROBIOL, V108, P44, DOI 10.1016/j.pneurobio.2013.06.005; Bissonette GB, 2013, BEHAV BRAIN RES, V250, P91, DOI 10.1016/j.bbr.2013.04.037; Bollinger J, 2010, J NEUROSCI, V30, P14399, DOI 10.1523/JNEUROSCI.1547-10.2010; Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009; Braitenberg V., 1978, Theoretical approaches to complex systems; Bressler SL, 2011, NEUROIMAGE, V58, P323, DOI 10.1016/j.neuroimage.2010.02.059; Bressler SL, 2008, J NEUROSCI, V28, P10056, DOI 10.1523/JNEUROSCI.1776-08.2008; BUCHSBAUM MS, 1982, ARCH GEN PSYCHIAT, V39, P251; Bunge Silvia A., 2004, Cognitive Affective & Behavioral Neuroscience, V4, P564, DOI 10.3758/CABN.4.4.564; Buschman TJ, 2012, NEURON, V76, P838, DOI 10.1016/j.neuron.2012.09.029; Cabeza R, 2000, J COGNITIVE NEUROSCI, V12, P1, DOI 10.1162/08989290051137585; Casey BJ, 1998, NEUROIMAGE, V8, P249, DOI 10.1006/nimg.1998.0360; CAVADA C, 1989, J COMP NEUROL, V287, P422, DOI 10.1002/cne.902870403; CAVADA C, 1989, J COMP NEUROL, V287, P393, DOI 10.1002/cne.902870402; Chadick JZ, 2011, NAT NEUROSCI, V14, P830, DOI 10.1038/nn.2823; Chafee MV, 2000, J NEUROPHYSIOL, V83, P1550; Charron S, 2010, SCIENCE, V328, P360, DOI 10.1126/science.1183614; Cheng H, 2012, NEUROIMAGE, V61, P1153, DOI 10.1016/j.neuroimage.2012.03.036; Choroschko W. K., 1923, Z GESAMTE NEUROL PSY, V18, P291; Clark A, 2013, BEHAV BRAIN SCI, V36, P233, DOI [10.1017/S0140525X12000477, 10.1017/S0140525X12002440]; Compte A, 2000, CEREB CORTEX, V10, P910, DOI 10.1093/cercor/10.9.910; Coutlee CG, 2012, BRAIN RES, V1428, P3, DOI 10.1016/j.brainres.2011.05.053; Crottaz-Herbette S, 2004, NEUROIMAGE, V21, P340, DOI 10.1016/j.neuroimage.2003.09.019; D'Esposito M., 2000, EXP BRAIN RES, V133, P3; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; Diekhof EK, 2012, NEUROPSYCHOLOGIA, V50, P1252, DOI 10.1016/j.neuropsychologia.2012.02.007; Dreher JC, 2013, PROG BRAIN RES, V202, P289, DOI 10.1016/B978-0-444-62604-2.00016-2; Duncan J, 2000, TRENDS NEUROSCI, V23, P475, DOI 10.1016/S0166-2236(00)01633-7; Durstewitz D, 2009, NEURAL NETWORKS, V22, P1189, DOI 10.1016/j.neunet.2009.07.016; Durstewitz D, 2010, NEURON, V66, P438, DOI 10.1016/j.neuron.2010.03.029; Eiselt AK, 2013, J NEUROSCI, V33, P7526, DOI 10.1523/JNEUROSCI.5827-12.2013; Elman J. L., 1996, RETHINKING INNATENES; Feuchtwanger E., 1923, MONOGR GESAMTGEB NEU, V38, P4; Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005; Friston KJ, 2003, NEURAL NETWORKS, V16, P1325, DOI 10.1016/j.neunet.2003.06.005; FUNAHASHI S, 1989, J NEUROPHYSIOL, V61, P331; Fuster J, 1995, MEMORY CEREBRAL CORT; Fuster JM, 2008, PREFRONTAL CORTEX, 4TH EDITION, P1; Fuster JM, 2009, J COGNITIVE NEUROSCI, V21, P2047, DOI 10.1162/jocn.2009.21280; Fuster JM, 2000, NATURE, V405, P347, DOI 10.1038/35012613; FUSTER JM, 1985, BRAIN RES, V330, P299, DOI 10.1016/0006-8993(85)90689-4; Fuster JM, 2004, TRENDS COGN SCI, V8, P143, DOI 10.1016/j.tics.2004.02.004; FUSTER JM, 1982, J NEUROSCI, V2, P361; FUSTER JM, 1973, J NEUROPHYSIOL, V36, P61; Fuster JM, 2012, TRENDS COGN SCI, V16, P207, DOI 10.1016/j.tics.2012.03.005; Gerlach KD, 2014, SOC COGN AFFECT NEUR, V9, P1942, DOI 10.1093/scan/nsu001; Gerlach KD, 2011, NEUROIMAGE, V55, P1816, DOI 10.1016/j.neuroimage.2011.01.030; Goldstein JM, 2005, NEUROPSYCHOLOGY, V19, P509, DOI 10.1037/0894-4105.19.4.509; Goldstein K., 1942, AFTEREFFECTS BRAIN I; Gomez CM, 2011, NEUROSCI BIOBEHAV R, V35, P452, DOI 10.1016/j.neubiorev.2010.05.005; GRAFMAN J, 1986, BRAIN, V109, P1127, DOI 10.1093/brain/109.6.1127; Harrison LM, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00037; Hebb D., 1949, ORG BEHAV; Hellyer PJ, 2014, J NEUROSCI, V34, P451, DOI 10.1523/JNEUROSCI.1853-13.2014; Hikosaka K, 2000, CEREB CORTEX, V10, P263, DOI 10.1093/cercor/10.3.263; Honey GD, 2002, NEUROIMAGE, V17, P573, DOI 10.1006/nimg.2002.1193; Jackson J. H., 1882, MED PRESS CIRC, Vii, P411; Jerde TA, 2013, J PHYSIOL-PARIS, V107, P510, DOI 10.1016/j.jphysparis.2013.04.002; JONES E G, 1970, Brain Behavior and Evolution, V93, P793, DOI 10.1093/brain/93.4.793; Kable JW, 2007, NAT NEUROSCI, V10, P1625, DOI 10.1038/nn2007; Katsuki Fumi, 2012, Front Integr Neurosci, V6, P17, DOI 10.3389/fnint.2012.00017; Kennerley SW, 2011, NAT NEUROSCI, V14, P1581, DOI 10.1038/nn.2961; Kleist K, 1934, GEHIRNPATHOLOGIE; Klingberg T, 2006, NEUROPSYCHOLOGIA, V44, P2171, DOI 10.1016/j.neuropsychologia.2005.11.019; Koechlin E, 2003, SCIENCE, V302, P1181, DOI 10.1126/science.1088545; Koechlin E, 2007, SCIENCE, V318, P594, DOI 10.1126/science.1142995; Kuhnt D, 2013, J NEUROSURG SCI, V57, P1; Leaver AM, 2009, J NEUROSCI, V29, P2477, DOI 10.1523/JNEUROSCI.4921-08.2009; Lemaire JJ, 2013, BRAIN TOPOGR, V26, P428, DOI 10.1007/s10548-012-0257-7; Levy DJ, 2012, CURR OPIN NEUROBIOL, V22, P1027, DOI 10.1016/j.conb.2012.06.001; Liang LN, 2010, COGN NEURODYNAMICS, V4, P359, DOI 10.1007/s11571-010-9129-6; Linden DEJ, 2012, J NEUROPHYSIOL, V107, P628, DOI 10.1152/jn.00105.2011; Lowe MJ, 2000, NEUROIMAGE, V12, P582, DOI 10.1006/nimg.2000.0654; Luria A. R., 1966, HIGHER CORTICAL FUNC; Luria AR, 1970, TRAUMATIC APHASIA; Magno E, 2006, J NEUROSCI, V26, P4769, DOI 10.1523/JNEUROSCI.0369-06.2006; Mante V, 2013, NATURE, V503, P78, DOI 10.1038/nature12742; Marcus G. F., 2001, ALGEBRAIC MIND INTEG; Martino J, 2013, BRAIN STRUCT FUNCT, V218, P105, DOI 10.1007/s00429-012-0386-5; Mecklinger A, 2000, HUM BRAIN MAPP, V11, P146; Mesulam MM, 1998, BRAIN, V121, P1013, DOI 10.1093/brain/121.6.1013; Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167; Modirrousta M, 2008, J NEUROSCI, V28, P14000, DOI 10.1523/JNEUROSCI.4450-08.2008; Montojo CA, 2008, NEURON, V59, P173, DOI 10.1016/j.neuron.2008.05.012; Morris R, 2005, CURR ISS THINK REASO, P1; Nee DE, 2013, CEREB CORTEX, V23, P264, DOI 10.1093/cercor/bhs007; NIKI H, 1974, BRAIN RES, V70, P346, DOI 10.1016/0006-8993(74)90324-2; Niv Y, 2008, TRENDS COGN SCI, V12, P265, DOI 10.1016/j.tics.2008.03.006; Okuda J, 2003, NEUROIMAGE, V19, P1369, DOI 10.1016/S1053-8119(03)00179-4; Pandya D. N., 1985, ARCHITECTURE CONNECT, V4, P3; Pollmann S, 2000, EXP BRAIN RES, V133, P12, DOI 10.1007/s002210000396; Potts GF, 2011, PSYCHOPHYSIOLOGY, V48, P218, DOI 10.1111/j.1469-8986.2010.01049.x; QUINTANA J, 1989, BRAIN RES, V503, P100, DOI 10.1016/0006-8993(89)91709-5; Quintana J, 1999, CEREB CORTEX, V9, P213, DOI 10.1093/cercor/9.3.213; Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676; Rajah MN, 2005, BRAIN, V128, P1964, DOI 10.1093/brain/awh608; Reverberi C, 2012, J NEUROSCI, V32, P17420, DOI 10.1523/JNEUROSCI.2344-12.2012; Rigotti M, 2013, NATURE, V497, P585, DOI 10.1038/nature12160; Rolls ET, 2008, PROG NEUROBIOL, V86, P216, DOI 10.1016/j.pneurobio.2008.09.001; ROSENKILDE CE, 1981, BRAIN RES, V209, P375, DOI 10.1016/0006-8993(81)90160-8; Rowe JB, 2005, CEREB CORTEX, V15, P85, DOI 10.1093/cercor/bhh111; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Rushworth MFS, 2008, NAT NEUROSCI, V11, P389, DOI 10.1038/nn2066; Rutledge RB, 2010, J NEUROSCI, V30, P13525, DOI 10.1523/JNEUROSCI.1747-10.2010; Sadaghiani S., 2014, CEREB CORTEX, DOI [10.1093/cercor/bhu072, DOI 10.1093/CERCOR/BHU072]; Salazar RF, 2012, SCIENCE, V338, P1097, DOI 10.1126/science.1224000; Schacter DL, 2012, NEURON, V76, P677, DOI 10.1016/j.neuron.2012.11.001; Scheidt RA, 2010, EXP BRAIN RES, V204, P239, DOI 10.1007/s00221-010-2308-1; Schoenbaum G., 2011, NEUROBIOLOGY SENSATI, P329; Schultz W, 2006, ANNU REV PSYCHOL, V57, P87, DOI 10.1146/annurev.psych.56.091103.070229; Schultz W, 1997, SCIENCE, V275, P1593, DOI 10.1126/science.275.5306.1593; Sescousse G, 2013, BRAIN, V136, P2527, DOI 10.1093/brain/awt126; Shackman AJ, 2011, NAT REV NEUROSCI, V12, P154, DOI 10.1038/nrn2994; Shipp S, 2013, TRENDS NEUROSCI, V36, P706, DOI 10.1016/j.tins.2013.09.004; Sigala N, 2008, P NATL ACAD SCI USA, V105, P11969, DOI 10.1073/pnas.0802569105; Silver MA, 2009, TRENDS COGN SCI, V13, P488, DOI 10.1016/j.tics.2009.08.005; Spreng RN, 2010, NEUROIMAGE, V53, P303, DOI 10.1016/j.neuroimage.2010.06.016; Sreenivasan KK, 2014, TRENDS COGN SCI, V18, P82, DOI 10.1016/j.tics.2013.12.001; Stokes MG, 2013, NEURON, V78, P364, DOI 10.1016/j.neuron.2013.01.039; Sylvester CM, 2009, J NEUROSCI, V29, P10671, DOI 10.1523/JNEUROSCI.1141-09.2009; Tang HJ, 2010, NEURAL COMPUT, V22, P1899, DOI 10.1162/neco.2010.07-09-1050; Uexkull J. V., 1926, THEORETICAL BIOL; VANESSEN DC, 1983, TRENDS NEUROSCI, V6, P370, DOI 10.1016/0166-2236(83)90167-4; Verduzco-Flores S., 2009, PLOS ONE, V4, pe6499; Wager TD, 2003, COGN AFFECT BEHAV NE, V3, P255, DOI 10.3758/CABN.3.4.255; Wang M, 2013, NEURON, V77, P736, DOI 10.1016/j.neuron.2012.12.032; Wang XJ, 2002, NEURON, V36, P955, DOI 10.1016/S0896-6273(02)01092-9; Wunderlich K, 2012, NAT NEUROSCI, V15, P786, DOI 10.1038/nn.3068; Yee LTS, 2010, J NEUROPHYSIOL, V103, P557, DOI 10.1152/jn.91299.2008	142	0	0	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	0898-929X	1530-8898		J COGNITIVE NEUROSCI	J. Cogn. Neurosci.	APR	2015	27	4					639	654		10.1162/jocn_a_00746		16	Neurosciences; Psychology, Experimental	Neurosciences & Neurology; Psychology	CC7YO	WOS:000350585000001	25321486	
J	Barradas, AO; Barros, AKD; Labidi, S; Viegas, IMA; Marques, DB; Romariz, ARS; de Sousa, RM; Marques, ALB; Marques, EP				Barradas Filho, Alex Oliveira; Duailibe Barros, Allan Kardec; Labidi, Sofiane; Amorim Viegas, Isabelle Moraes; Marques, Delano Brandes; Romariz, Alexandre R. S.; de Sousa, Raquel M.; Marques, Aldalea Lopes B.; Marques, Edmar Pereira			Application of artificial neural networks to predict viscosity, iodine value and induction period of biodiesel focused on the study of oxidative stability	FUEL			English	Article						Artificial neural networks; Quality parameters of biodiesel; Oxidative stability; Viscosity; Iodine value; Induction period	FATTY-ACID-COMPOSITION; KINEMATIC VISCOSITY; CETANE NUMBER; QUALITY PARAMETERS; FLOW PROPERTIES; FUEL PROPERTIES; OILS; MIXTURES; DENSITY; BLENDS	In the search for alternative fuels that can gradually replace petroleum derivatives, biodiesel is highlighted as a substitute for diesel and it is defined as a biofuel obtained from transesterification of triglycerides. Despite of several advantages over mineral diesel, an elementary disadvantage of biodiesel is its low oxidative stability, which is strongly influenced by the unsaturation degree of its fatty acid methyl esters (FAMEs) and by the conditions to which biodiesel is exposed during storage, transporting and handling. The present work focuses on the optimization and application of artificial neural networks (ANNs) on prediction of viscosity, iodine value and induction period of biodiesel, properties that directly reflect its level of degradation, to evaluate the oxidative stability. The input variables were the percentages of the 13 most common FAMEs in biodiesels and the transesterification does not change the fatty esters profile of the raw material. In this case the ANN method allows predicting viscosity, iodine value and induction period, either before transesterification, after synthesis of biodiesel or during the storage. Therefore, this method can be useful as a tool to evaluate the potential of raw materials to produce a biodiesel with good oxidative stability and to reach improvements concerning official methods. The optimization process of the ANN occurred in three steps: test of algorithms for adjusting weights, test of stopping condition and test of activation functions, and the physicochemical properties were treated independently. For the set of test samples, which simulates real samples, the application of the optimized ANNs provided results with root mean squared errors (RMSE) of 0.55 mm(2)/s, 3.49 g/100 g and 0.89 h for viscosity, iodine value and induction period, respectively, what ensures the feasibility of the proposed method. A comparison between the proposed method and linear methods from literature, both based on the biodiesel composition indicates that our ANN model is much more adequate to the problem addressed. (C) 2014 Elsevier Ltd. All rights reserved.	[Barradas Filho, Alex Oliveira; Duailibe Barros, Allan Kardec; Labidi, Sofiane; de Sousa, Raquel M.] Univ Fed Maranhao, Dept Elect Engn, Sao Luis, MA, Brazil; [Amorim Viegas, Isabelle Moraes; Marques, Aldalea Lopes B.; Marques, Edmar Pereira] Univ Fed Maranhao, Dept Chem Technol, LAPQAP NEPE, Sao Luis, MA, Brazil; [Marques, Delano Brandes; Romariz, Alexandre R. S.] Univ Brasilia, Dept Elect Engn, BR-70910900 Brasilia, DF, Brazil	Barradas, AO (reprint author), Av Portugueses 1966, BR-65080805 Sao Luis, MA, Brazil.	barradas.alex@gmail.com; aldalea.ufma@hotmail.com			ANP (PRH ANP) [39]; FINEP (RECOL 05/NANOPET project); CNPq; FAPEMA	The authors would like to thank to ANP (PRH ANP Number 39), FINEP (RECOL 05/NANOPET project), CNPq, and FAPEMA for the financial support and fellowships received. We also thank to the Program of PostGraduate in Electrical Engineering of UFMA (PPGEE/UFMA) and to LAPQAP/NEPE/UFMA.	Balabin RM, 2011, FUEL, V90, P2007, DOI 10.1016/j.fuel.2010.11.038; Balat M, 2011, ENERG CONVERS MANAGE, V52, P1479, DOI 10.1016/j.enconman.2010.10.011; Candeia RA, 2008, THESIS U FEDERAL PAR; Cay Y, 2013, ENERGY, V50, P177, DOI 10.1016/j.energy.2012.10.052; Cheenkachorn K., 2006, AS J ENERGY ENV, V7, P299; Dantas MB, 2011, FUEL, V90, P773, DOI 10.1016/j.fuel.2010.09.014; Dantas MB, 2010, THESIS U FEDERAL PAR; Dermibas A, 2009, APPL ENERG, V86, P108; Duarte SH, 2014, BIORESOURCE TECHNOL, V161, P416, DOI 10.1016/j.biortech.2014.03.096; Focke WW, 2012, FUEL, V94, P227, DOI 10.1016/j.fuel.2011.11.061; Freire LMS, 2012, FUEL, V95, P126, DOI 10.1016/j.fuel.2011.11.014; Gopinath A, 2009, RENEW ENERG, V34, P1806, DOI 10.1016/j.renene.2008.11.023; Hoekman SK, 2012, RENEW SUST ENERG REV, V16, P143, DOI 10.1016/j.rser.2011.07.143; Hong IK, 2014, J IND ENG CHEM, V20, P2348, DOI 10.1016/j.jiec.2013.10.011; Kivevele TT, 2011, ENERG FUEL, V25, P2341, DOI 10.1021/ef200243e; Knothe G, 2005, FUEL, V84, P1059, DOI 10.1016/j.fuel.2005.01.016; Knothe G, 2007, FUEL PROCESS TECHNOL, V88, P669, DOI 10.1016/j.fuproc.2007.01.005; Knothe G, 2011, FUEL, V90, P3217, DOI 10.1016/j.fuel.2011.06.016; Knothe G, 2002, J AM OIL CHEM SOC, V79, P847, DOI 10.1007/s11746-002-0569-4; Kumar J., 2010, J SCI ENG TECHNOL, V6, P98; Lobo IP, 2009, QUIM NOVA, V32, P1596, DOI 10.1590/S0100-40422009000600044; Marques DB, 2014, INT J COMP SCI APPL, V3, P97; Martin C, 2010, BIOMASS BIOENERG, V34, P533, DOI 10.1016/j.biombioe.2009.12.019; Meng XZ, 2014, FUEL, V121, P133, DOI 10.1016/j.fuel.2013.12.029; Moser BR, 2011, RENEW ENERG, V36, P1221, DOI 10.1016/j.renene.2010.10.009; Nadai DV, 2013, FUEL, V105, P325, DOI 10.1016/j.fuel.2012.06.018; Nogueira CA, 2010, J CHEM ENG DATA, V55, P5305, DOI 10.1021/je1003862; Padhi SK, 2010, PREPARATION CHARACTE; Park JY, 2008, BIORESOURCE TECHNOL, V99, P1196, DOI 10.1016/j.biortech.2007.02.017; Piloto-Rodriguez R, 2013, ENERG CONVERS MANAGE, V65, P255, DOI 10.1016/j.enconman.2012.07.023; Ramirez-Verduzco LF, 2011, FUEL, V90, P1751, DOI 10.1016/j.fuel.2010.12.032; Ramirez-Verduzco LF, 2012, FUEL, V91, P102, DOI 10.1016/j.fuel.2011.06.070; Ramos MJ, 2009, BIORESOURCE TECHNOL, V100, P261, DOI 10.1016/j.biortech.2008.06.039; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saldana DA, 2012, ENERG FUEL, V26, P2416, DOI 10.1021/ef3001339; Sanford SD, FEEDSTOCK BIODIESEL; SANTOS J. R. J., 2008, THESIS U FEDERAL PAR; Sarin A, 2009, ENERGY, V34, P1271, DOI 10.1016/j.energy.2009.05.018; Sarin A, 2010, ENERGY, V35, P3449, DOI 10.1016/j.energy.2010.04.039; Sarin R, 2007, FUEL, V86, P1365, DOI 10.1016/j.fuel.2006.11.040; Viegas IMA, 2012, CADERNOS PESQUISA, V20, P26; Viegas IMA, 2014, CADERNOS PESQUISA, V21; [王利兵 Wang Libing], 2012, [燃料化学学报, Journal of Fuel Chemistry and Technology], V40, P397; Yaakob Z, 2014, RENEW SUST ENERG REV, V35, P136, DOI 10.1016/j.rser.2014.03.055	44	0	0	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0016-2361	1873-7153		FUEL	Fuel	APR 1	2015	145						127	135		10.1016/j.fuel.2014.12.016		9	Energy & Fuels; Engineering, Chemical	Energy & Fuels; Engineering	CA7HQ	WOS:000349088800014		
J	Zhang, F; Du, B; Zhang, LP				Zhang, Fan; Du, Bo; Zhang, Liangpei			Saliency-Guided Unsupervised Feature Learning for Scene Classification	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						Autoencoder; saliency detection; scene classification; unsupervised feature learning	LATENT DIRICHLET ALLOCATION; IMAGE CLASSIFICATION; NEURAL-NETWORKS; STRATEGIES	Due to the rapid technological development of various different satellite sensors, a huge volume of high-resolution image data sets can now be acquired. How to efficiently represent and recognize the scenes from such high-resolution image data has become a critical task. In this paper, we propose an unsupervised feature learning framework for scene classification. By using the saliency detection algorithm, we extract a representative set of patches from the salient regions in the image data set. These unlabeled data patches are exploited by an unsupervised feature learning method to learn a set of feature extractors which are robust and efficient and do not need elaborately designed descriptors such as the scale-invariant-feature-transform-based algorithm. We show that the statistics generated from the learned feature extractors can characterize a complex scene very well and can produce excellent classification accuracy. In order to reduce overfitting in the feature learning step, we further employ a recently developed regularization method called "dropout," which has proved to be very effective in image classification. In the experiments, the proposed method was applied to two challenging high-resolution data sets: the UC Merced data set containing 21 different aerial scene categories with a submeter resolution and the Sydney data set containing seven land-use categories with a 60-cm spatial resolution. The proposed method obtained results that were equal to or even better than the previous best results with the UC Merced data set, and it also obtained the highest accuracy with the Sydney data set, demonstrating that the proposed unsupervised-feature-learning-based scene classification method provides more accurate classification results than the other latent-Dirichlet-allocation-based methods and the sparse coding method.	[Zhang, Fan; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China; [Du, Bo] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China	Zhang, F (reprint author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.	rszhang@whu.edu.cn; remoteking@whu.edu.cn; zlp62@public.wh.hb.cn			National Basic Research Program of China (973 Program) [2011CB707105, 2012CB719905]; National Natural Science Foundation of China [41431175, 61471274]	This work was supported in part by the National Basic Research Program of China (973 Program) under Grants 2011CB707105 and 2012CB719905 and in part by the National Natural Science Foundation of China under Grants 41431175 and 61471274.	Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Chang CC, 2011, ACM T INTEL SYST TEC, V2, P27, DOI DOI 10.1145/1961189.1961199; Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444; Ciresan D. C., 2012, ARXIV1202745; Coates A., 2011, P 14 INT C AI STAT, P215; Csurka G., 2004, P WORKSH STAT LEARN, V1, P1; Du B, 2014, PATTERN RECOGN, V47, P344, DOI 10.1016/j.patcog.2013.07.005; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Hinton G. E., 2012, ARXIV12070580; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Krizhevsky A., 2012, P ADV NEUR INF PROC, V25, P1106; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Lee H., 2008, P ADV NEUR INF PROC, V20, P873; Lienou M, 2010, IEEE GEOSCI REMOTE S, V7, P28, DOI 10.1109/LGRS.2009.2023536; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Marc'Aurelio R., 2007, P ADV NEUR INF PROC, V20, P1185; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155; Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277; Simard P., 2003, P 7 INT C DOC AN REC, V2, P958, DOI DOI 10.1109/1CDAR.2003.1227801; Singh S., 2012, P EUR C COMP VIS, P73; Sivic J., 2003, P 9 IEEE C COMP VIS, V2, P1470, DOI [DOI 10.1109/ICCV.2003.1238663, DOI 10.1109/ICCV.2003.1238663]]; Tao DP, 2013, IEEE T CYBERNETICS, V43, P1406, DOI 10.1109/TCYB.2013.2264285; Vaduva C, 2013, IEEE T GEOSCI REMOTE, V51, P2770, DOI 10.1109/TGRS.2012.2219314; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Yang Y, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1465; Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829; Zhang LF, 2012, IEEE T GEOSCI REMOTE, V50, P879, DOI 10.1109/TGRS.2011.2162339	38	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892	1558-0644		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	APR	2015	53	4					2175	2184		10.1109/TGRS.2014.2357078		10	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	AR9NQ	WOS:000343902300041		
J	Spiliopoulos, L				Spiliopoulos, Leonidas			Transfer of conflict and cooperation from experienced games to new games: a connectionist model of learning	FRONTIERS IN NEUROSCIENCE			English	Article						transfer of learning; game theory; cooperation and conflict; connectionist modeling; neural networks and behavior; agent-based modeling	NORMAL-FORM GAMES; STAG HUNT GAMES; NEURAL-NETWORKS; COORDINATION GAMES; MULTIPLE GAMES; BEHAVIORAL SPILLOVERS; BOUNDED RATIONALITY; RISK DOMINANCE; STARTING SMALL; EQUILIBRIUM	The question of whether, and if so how, learning can be transfered from previously experienced games to novel games has recently attracted the attention of the experimental game theory literature. Existing research presumes that learning operates over actions, beliefs or decision rules. This study instead uses a connectionist approach that learns a direct mapping from game payoffs to a probability distribution over own actions. Learning is operationalized as a backpropagation rule that adjusts the weights of feedforward neural networks in the direction of increasing the probability of an agent playing a myopic best response to the last game played. One advantage of this approach is that it expands the scope of the model to any possible n x n normal-form game allowing for a comprehensive model of transfer of learning. Agents are exposed to games drawn from one of seven classes of games with significantly different strategic characteristics and then forced to play games from previously unseen classes. I find significant transfer of learning, i.e., behavior that is path-dependent, or conditional on the previously seen games. Cooperation is more pronounced in new games when agents are previously exposed to games where the incentive to cooperate is stronger than the incentive to compete, i.e., when individual incentives are aligned. Prior exposure to Prisoner's dilemma, zero-sum and discoordination games led to a significant decrease in realized payoffs for all the game classes under investigation. A distinction is made between superficial and deep transfer of learning both the former is driven by superficial payoff similarities between games, the latter by differences in the incentive structures or strategic implications of the games. I examine whether agents learn to play the Nash equilibria of games, how they select amongst multiple equilibria, and whether they transfer Nash equilibrium behavior to unseen games. Sufficient exposure to a strategically heterogeneous set of games is found to be a necessary condition for deep learning (and transfer) across game classes. Paradoxically, superficial transfer of learning is shown to lead to better outcomes than deep transfer for a wide range of game classes. The simulation results corroborate important experimental findings with human subjects, and make several novel predictions that can be tested experimentally.	Max Planck Inst Human Dev, Ctr Adapt Rat, D-14195 Berlin, Germany	Spiliopoulos, L (reprint author), Max Planck Inst Human Dev, Ctr Adapt Rat, Lentzeallee 94, D-14195 Berlin, Germany.	spiliopoulos@mpib-berlin.mpg.de			Alexander von Humboldt foundation (Fellowship for Experienced Researchers)	I would like to thank two anonymous referees and the editor for constructive suggestions to the paper, Andreas Ortmann and Wouter van den Bos for helpful discussions. I gratefully acknowledge financial support from the Alexander von Humboldt foundation (Fellowship for Experienced Researchers).	Ahn TK, 2001, PUBLIC CHOICE, V106, P137, DOI 10.1023/A:1005219123532; Battalio R, 2001, ECONOMETRICA, V69, P749, DOI 10.1111/1468-0262.00212; Bednar J, 2012, GAME ECON BEHAV, V74, P12, DOI 10.1016/j.geb.2011.06.009; Bednar J, 2007, RATION SOC, V19, P65, DOI 10.1177/1043463107075108; Bruns B., 2015, CHANGING GAMES ATLAS; Cabrales A, 2000, INT J IND ORGAN, V18, P137, DOI 10.1016/S0167-7187(99)00037-5; Cason TN, 2012, EUR ECON REV, V56, P233, DOI 10.1016/j.euroecorev.2011.09.001; Cason TN, 2013, ECON INQ, V51, P1715, DOI 10.1111/j.1465-7295.2012.00486.x; Chen SH, 2012, J ECON DYN CONTROL, V36, P1, DOI 10.1016/j.jedc.2011.09.003; Cheung YW, 1997, GAME ECON BEHAV, V19, P46, DOI 10.1006/game.1997.0544; Cooper D. J., 2007, ECON THEOR, V34, P415, DOI 10.1007/s00199-006-0192-5; Cooper DJ, 2003, AM ECON REV, V93, P202, DOI 10.1257/000282803321947056; Devetag G, 2005, ECON LETT, V89, P227, DOI 10.1016/j.econlet.2005.05.038; Duffy J, 2009, GAME ECON BEHAV, V66, P785, DOI 10.1016/j.geb.2008.07.003; Egelman DM, 1998, J COGNITIVE NEUROSCI, V10, P623, DOI 10.1162/089892998563022; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Elman JL, 2005, TRENDS COGN SCI, V9, P111, DOI 10.1016/j.tics.2005.01.005; Frankenhuis WE, 2012, DEV PSYCHOL, V48, P628, DOI 10.1037/a0025629; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; Glimcher PW, 2011, P NATL ACAD SCI USA, V108, P15647, DOI 10.1073/pnas.1014269108; Grimm V, 2012, J ECON THEORY, V147, P2220, DOI 10.1016/j.jet.2012.05.011; Harsanyi J. C., 1988, GEN THEORY EQUILIBRI; Haruvy E, 2004, J ECON BEHAV ORGAN, V53, P319, DOI 10.1016/j.jebo.2002.10.001; Haruvy E, 2012, GAME ECON BEHAV, V74, P208, DOI 10.1016/j.geb.2011.06.001; Hinton G. E., 1989, PARALLEL DISTRIBUTED, P49; Izquierdo L. R., 2012, ENCY SCI LEARNING, P1782; Jehiel P, 2005, J ECON THEORY, V123, P81, DOI 10.1016/j.jet.2003.12.003; Juvina I., 2014, J APPL RES IN PRESS, P1; Juvina I, 2013, ORGAN BEHAV HUM DEC, V120, P206, DOI 10.1016/j.obhdp.2012.09.004; KETTNER R, 1993, J COGNITIVE NEUROSCI, V5, P14, DOI 10.1162/jocn.1993.5.1.14; KILGOUR DM, 1988, THEOR DECIS, V24, P99, DOI 10.1007/BF00132457; Knez M, 2000, ORGAN BEHAV HUM DEC, V82, P194, DOI 10.1006/obhd.2000.2882; LEHKY SR, 1988, NATURE, V333, P452, DOI 10.1038/333452a0; Marchiori D, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00139; Marchiori D, 2008, SCIENCE, V319, P1111, DOI 10.1126/science.1151185; Mareschal D, 2007, IEEE T EVOLUT COMPUT, V11, P137, DOI 10.1109/TEVC.2006.890232; Marr D, 1982, VISION COMPUTATIONAL; Mazzoni P, 1991, CEREB CORTEX, V1, P293, DOI 10.1093/cercor/1.4.293; MCCLELLAND JL, 1994, INTERNATIONAL PERSPECTIVES ON PSYCHOLOGICAL SCIENCE, VOL 1: LEADING THEMES, P57; Mengel F, 2014, ECON LETT, V125, P381, DOI 10.1016/j.econlet.2014.10.015; Minsky M., 1969, PERCEPTRONS INTRO CO; Munakata Y, 2003, DEVELOPMENTAL SCI, V6, P413, DOI 10.1111/1467-7687.00296; Nagel R, 1995, AM ECON REV, V85, P1313; Nudelman E., 2004, P 3 INT JOINT C AUT, P880; Ockenfels A, 2005, GAME ECON BEHAV, V51, P155, DOI 10.1016/j.geb.2004.04.002; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pratt L., 1996, Connection Science, V8, DOI 10.1080/095400996116866; Rankin FW, 2000, GAME ECON BEHAV, V32, P315, DOI 10.1006/game.1999.0711; Rapoport A., 1976, THE 2 X 2 GAME; Rick S, 2010, GAME ECON BEHAV, V68, P716, DOI 10.1016/j.geb.2009.10.004; Rieskamp J, 2003, J EXP PSYCHOL LEARN, V29, P1066, DOI 10.1037/0278-7393.29.6.1066; Robinson T, 2000, TECHNICAL REPORT; Rohde DLT, 1999, COGNITION, V72, P67, DOI 10.1016/S0010-0277(99)00031-1; ROTH AE, 1995, GAME ECON BEHAV, V8, P164, DOI 10.1016/S0899-8256(05)80020-X; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; RUMELHART DE, 1993, ATTENTION PERFORM, V14, P3; Samuelson L, 2001, J ECON THEORY, V97, P320, DOI 10.1006/jeth.2000.2754; Schlesinger M, 2001, DEV REV, V21, P121, DOI 10.1006/drev.2000.0520; Schmidt D, 2003, GAME ECON BEHAV, V42, P281, DOI 10.1016/S0899-8256(02)00552-3; Schultz W, 1998, J NEUROPHYSIOL, V80, P1; Selten R, 2005, EXP ECON, V8, P5, DOI 10.1007/s10683-005-1407-5; Selten R, 1998, EUR ECON REV, V42, P413, DOI 10.1016/S0014-2921(97)00148-7; Sgroi D, 2009, J ECON BEHAV ORGAN, V69, P27, DOI 10.1016/j.jebo.2008.09.008; Sgroi D, 2007, PHYSICA A, V375, P717, DOI 10.1016/j.physa.2006.10.026; Simon H. A., 1986, J BUS, V59, P209; Simon H. A., 1976, 25 YEARS EC THEORY, P65; Spiliopoulos L, 2012, PHYSICA A, V391, P5557, DOI 10.1016/j.physa.2012.06.017; SPILIOPOULOS L, 2011, AGENT BASED APPROACH, V8, P61; Spiliopoulos L., 2008, THESIS U SYDNEY; Spiliopoulos L, 2011, ADAPT BEHAV, V19, P383, DOI 10.1177/1059712311417636; Steiner J, 2008, THEOR ECON, V3, P431; Straub P. G., 1996, Q REV EC FINANCE, V35, P339, DOI 10.1016/1062-9769(95)90048-9; Tesfatsion L, 2002, ARTIF LIFE, V8, P55, DOI 10.1162/106454602753694765; Tesfatsion Leigh, 2006, HDB COMPUTATIONAL EC, V2; Thorndike EL, 1901, PSYCHOL REV, V8, P247; Thrun S., 2012, LEARNING LEARN; van Ooyen A., 2003, ARTIFICIAL NEURAL NE, P442; ZIPSER D, 1988, NATURE, V331, P679, DOI 10.1038/331679a0; Zizzo DJ, 2003, CAMBRIDGE J ECON, V27, P867, DOI 10.1093/cje/27.6.867	79	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-453X			FRONT NEUROSCI-SWITZ	Front. Neurosci.	MAR 31	2015	9								102	10.3389/fnins.2015.00102		18	Neurosciences	Neurosciences & Neurology	CG0RG	WOS:000352974000002	25873855	
J	Ehret, A; Hochstuhl, D; Gianola, D; Thaller, G				Ehret, Anita; Hochstuhl, David; Gianola, Daniel; Thaller, Georg			Application of neural networks with back-propagation to genome-enabled prediction of complex traits in Holstein-Friesian and German Fleckvieh cattle	GENETICS SELECTION EVOLUTION			English	Article							DENSE MOLECULAR MARKERS; QUANTITATIVE TRAITS; ASSISTED PREDICTION; REGRESSION-MODELS; GENETIC VALUE; IMPUTATION	Background: Recently, artificial neural networks (ANN) have been proposed as promising machines for marker-based genomic predictions of complex traits in animal and plant breeding. ANN are universal approximators of complex functions, that can capture cryptic relationships between SNPs (single nucleotide polymorphisms) and phenotypic values without the need of explicitly defining a genetic model. This concept is attractive for high-dimensional and noisy data, especially when the genetic architecture of the trait is unknown. However, the properties of ANN for the prediction of future outcomes of genomic selection using real data are not well characterized and, due to high computational costs, using whole-genome marker sets is difficult. We examined different non-linear network architectures, as well as several genomic covariate structures as network inputs in order to assess their ability to predict milk traits in three dairy cattle data sets using large-scale SNP data. For training, a regularized back propagation algorithm was used. The average correlation between the observed and predicted phenotypes in a 20 times 5-fold cross-validation was used to assess predictive ability. A linear network model served as benchmark. Results: Predictive abilities of different ANN models varied markedly, whereas differences between data sets were small. Dimension reduction methods enhanced prediction performance in all data sets, while at the same time computational cost decreased. For the Holstein-Friesian bull data set, an ANN with 10 neurons in the hidden layer achieved a predictive correlation of r = 0.47 for milk yield when the entire marker matrix was used. Predictive ability increased when the genomic relationship matrix (r = 0.64) was used as input and was best (r = 0.67) when principal component scores of the marker genotypes were used. Similar results were found for the other traits in all data sets. Conclusion: Artificial neural networks are powerful machines for non-linear genome-enabled predictions in animal breeding. However, to produce stable and high-quality outputs, variable selection methods are highly recommended, when the number of markers vastly exceeds sample size.	[Ehret, Anita; Thaller, Georg] Univ Kiel, Inst Anim Breeding & Husb, D-24098 Kiel, Germany; [Hochstuhl, David] Univ Kiel, Inst Theoret Phys & Astrophys, D-24098 Kiel, Germany; [Gianola, Daniel] Univ Wisconsin, Dept Anim Sci, Madison, WI 53706 USA; [Gianola, Daniel] Univ Wisconsin, Dept Dairy Sci, Madison, WI 53706 USA; [Gianola, Daniel] Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA	Ehret, A (reprint author), Univ Kiel, Inst Anim Breeding & Husb, Olshausenstr 40, D-24098 Kiel, Germany.	aehret@tierzucht.uni-kiel.de			German Federal Ministry of Education and Research (BMBF) within the AgroClustEr "Synbreed - Synergistic plant and animal breeding"	This research was supported by the German Federal Ministry of Education and Research (BMBF) within the AgroClustEr "Synbreed - Synergistic plant and animal breeding". The authors thank Claas Heuer (Institute of Animal Breeding and Husbandry, Christian-Albrechts-University, Olshausenstr. 40, 24098 Kiel, Germany) for the comments and suggestions to the manuscript.	Bishop C. M., 2006, PATTERN RECOGNITION, V1; Core Team R., 2014, R LANG ENV STAT COMP; de los Campos G, 2013, GENETICS, V193, P327, DOI 10.1534/genetics.112.143313; de los Campos G, 2009, GENETICS, V182, P375, DOI 10.1534/genetics.109.101501; Gianola D, 2006, GENETICS, V173, P1761, DOI 10.1534/genetics.105.049510; Gianola D, 2008, GENETICS, V178, P2289, DOI 10.1534/genetics.107.084285; Gianola D, 2011, BMC GENET, V12, DOI 10.1186/1471-2156-12-87; Gonzalez-Recio O, 2008, GENETICS, V178, P2305, DOI 10.1534/genetics.107.084293; Gurney K, 1997, INTRO NEURAL NETWORK, V1; Hanrahan G, 2011, ARTIFICIAL NEURAL NE; Hastie T, 2009, MATH INTELL, V27, P83; Howie B, 2012, NAT GENET, V44, P955, DOI 10.1038/ng.2354; Kohavi R, 1995, INT JOINT C ART INT, V14, P1137; KOLMOGOROV AN, 1957, DOKL AKAD NAUK SSSR+, V114, P953; Kriesel D, 2007, BRIEF INTRO NEURAL N; KURKOVA V, 1992, NEURAL NETWORKS, V5, P501, DOI 10.1016/0893-6080(92)90012-8; MacKay D. J., 2003, INFORM THEORY INFERE; MANDEL J, 1982, AM STAT, V36, P15, DOI 10.2307/2684086; Meuwissen THE, 2001, GENETICS, V157, P1819; Okut H, 2011, GENET RES, V93, P189, DOI 10.1017/S0016672310000662; Okut H, 2013, GENET SEL EVOL, V45, DOI 10.1186/1297-9686-45-34; Pausch H, 2013, GENET SEL EVOL, V45, DOI 10.1186/1297-9686-45-3; Pereira B, 2009, DATA MINING USING NE; Perez-Rodriguez P, 2013, J ANIM SCI, V91, P3522, DOI 10.2527/jas.2012-6162; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Tusell L, 2013, ANIMAL, V7, P1739, DOI 10.1017/S1751731113001389; VanRaden PM, 2008, J DAIRY SCI, V91, P4414, DOI 10.3168/jds.2007-0980; Wellmann R, 2011, GENET RES, V93, P139, DOI 10.1017/S0016672310000649; Werbos PJ, 1994, ROOTS BACKPROPAGATIO; Whittaker JC, 2000, GENET RES, V75, P249, DOI 10.1017/S0016672399004462	30	0	0	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	0999-193X	1297-9686		GENET SEL EVOL	Genet. Sel. Evol.	MAR 31	2015	47								22	10.1186/s12711-015-0097-5		9	Agriculture, Dairy & Animal Science; Genetics & Heredity	Agriculture; Genetics & Heredity	CE7CO	WOS:000351994800001	25886037	
J	Kuriscak, E; Marsalek, P; Stroffek, J; Toth, PG				Kuriscak, Eduard; Marsalek, Petr; Stroffek, Julius; Toth, Peter G.			Biological context of Hebb learning in artificial neural networks, a review	NEUROCOMPUTING			English	Article						Artificial neural networks; Biological neural networks; Hebb learning; Hebb rule; Hebb synapse; Synaptic plasticity	TIMING-DEPENDENT PLASTICITY; ASSOCIATIVE MEMORY; SOUND LOCALIZATION; PYRAMIDAL NEURONS; DENDRITIC SPINES; PATTERN STORAGE; MODEL; RULE; HIPPOCAMPAL; FREQUENCIES	In 1949 Donald Olding Hebb formulated a hypothesis describing how neurons excite each other and how the efficiency of this excitation subsequently changes with time. In this paper we present a review of this idea. We evaluate its influences on the development of artificial neural networks and the way we describe biological neural networks. We explain how Hebb's hypothesis fits into the research both of that time and of present. We highlight how it has gone on to inspire many researchers working on artificial neural networks. The underlying biological principles that corroborate this hypothesis, that were discovered much later, are also discussed in addition to recent results in the field and further possible directions of synaptic learning research. (C) 2014 Elsevier B.V. All rights reserved.	[Kuriscak, Eduard] Charles Univ Prague, Inst Physiol, Med Fac 1, CZ-12800 Prague 2, Czech Republic; [Marsalek, Petr; Stroffek, Julius; Toth, Peter G.] Charles Univ Prague, Inst Pathol Physiol, Med Fac 1, CZ-12853 Prague 2, Czech Republic; [Marsalek, Petr] Czech Tech Univ, CZ-16636 Prague 6, Czech Republic	Kuriscak, E (reprint author), Charles Univ Prague, Inst Physiol, Med Fac 1, Albertov 5, CZ-12800 Prague 2, Czech Republic.	Eduard.kuriscak@lfl.cuni.cz			Charles University in Prague [260 033, 205024]	This work was supported by graduate students research program SW 2014 no. 260 033 to P.M., J.S. and P.G.T. and PRVOUK program no. 205024 to P.M. both programs at Charles University in Prague. Thanks to Elisa Brann, Libor Husnik, Jiri Kofranek and Martin Vokurka.	Adrian ED, 1926, J PHYSIOL-LONDON, V61, P151; Amit DJ, 1989, MODELING BRAIN FUNCT; Ariens Kappers C.U., 1936, COMP ANATOMY NERVOUS; BARTO AG, 1985, IEEE T SYST MAN CYB, V15, P360; Benuskova L, 2007, J COMPUT NEUROSCI, V22, P129, DOI 10.1007/s10827-006-0002-x; Bibitchkov D, 2002, NEUROCOMPUTING, V44, P329, DOI 10.1016/S0925-2312(02)00363-6; Bibitchkov D, 2002, NETWORK-COMP NEURAL, V13, P115, DOI 10.1088/0954-898X/13/1/304; BIENENSTOCK EL, 1982, J NEUROSCI, V2, P32; Brown RE, 2003, NAT REV NEUROSCI, V4, P1013, DOI 10.1038/nrn1257; Brown T.H., 1990, SYNAPTIC ORG BRAIN, P346; Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639; CARR CE, 1988, P NATL ACAD SCI USA, V85, P8311, DOI 10.1073/pnas.85.21.8311; Cooper L.N., 2010, FRONT SYNAPTIC NEURO, V2, P00014; Cushing S, 2005, J NEUROPHYSIOL, V94, P3465, DOI 10.1152/jn.00439.2005; Dan Y, 2004, NEURON, V44, P23, DOI 10.1016/j.neuron.2004.09.007; Eccles J.C., 1957, NOTES REC R SOC LOND, P216; Eriksson JL, 2006, BEHAV PROCESS, V73, P348, DOI 10.1016/j.beproc.2006.08.005; Gerstner W, 1996, NATURE, V383, P76, DOI 10.1038/383076a0; Gerstner W, 2002, BIOL CYBERN, V87, P404, DOI 10.1007/s00422-002-0353-y; Gerstner W., 2002, NEURON MODELS SINGLE; GOLOMB D, 1990, PHYS REV A, V41, P1843, DOI 10.1103/PhysRevA.41.1843; Graham B, 1999, NEURAL COMPUT, V11, P117, DOI 10.1162/089976699300016845; Hebb D., 1949, ORG BEHAV; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Hopfield J.J., 2007, SCHOLARPEDIA, V2, P1977; Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577; James W., 1907, PRAGMATISM NEW NAME; JEFFRESS LA, 1948, J COMP PHYSIOL PSYCH, V41, P35, DOI 10.1037/h0061495; Kandel E., 2007, SEARCH MEMORY EMERGE; KELSO SR, 1986, P NATL ACAD SCI USA, V83, P5326, DOI 10.1073/pnas.83.14.5326; Klein R. M., 2011, SCHOLARPEDIA, V6, P3719; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohout U., 1990, PERSPECTIVE INTELLIG; Kuriscák E, 2004, Prague Med Rep, V105, P369; Kuriscak E., 2012, COMPUT MATH METHOD M, V2012, P1; Laufberger V., 1947, VZRUCHOVA THEORIE IM; Marr D, 1982, VISION COMPUTATIONAL; Marsalek P, 2004, NEUROCOMPUTING, V58, P999, DOI 10.1016/j.neucom.2004.01.158; Marsalek P, 1998, BIOSYSTEMS, V48, P147, DOI 10.1016/S0303-2647(98)00060-4; Marsalek P, 2001, NEUROCOMPUTING, V38, P1443, DOI 10.1016/S0925-2312(01)00524-0; Marsalek PR, 1997, P NATL ACAD SCI USA, V94, P735, DOI 10.1073/pnas.94.2.735; MAZZONI P, 1991, P NATL ACAD SCI USA, V88, P4433, DOI 10.1073/pnas.88.10.4433; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Mlcek M, 2001, PHYSIOL RES, V50, P425; Morimoto T, 1998, NEUROSCIENCE, V82, P969; Movellan J.R., 1990, P 1990 CONN MOD SUMM, P10; ODELL TJ, 1991, P NATL ACAD SCI USA, V88, P11285, DOI 10.1073/pnas.88.24.11285; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Pavlov IP, 1927, CONDITIONED REFLEXES; PRIBRAM KH, 1969, SCI AM, V220, P73; Rolls ET, 1998, NEURAL NETWORKS BRAI; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sala C, 2014, PHYSIOL REV, V94, P141, DOI 10.1152/physrev.00012.2013; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Santamaria F, 2011, EUR J NEUROSCI, V34, P561, DOI 10.1111/j.1460-9568.2011.07785.x; Sejnowski TJ, 1999, NEURON, V24, P773, DOI 10.1016/S0896-6273(00)81025-9; SHANNON CE, 1949, AT&T TECH J, V28, P656; SHERRINGTON D, 1975, PHYS REV LETT, V35, P1792, DOI 10.1103/PhysRevLett.35.1792; Sjostrom J., 2010, SCHOLARPEDIA, V5, P1362, DOI [10.4249/scholarpedia.l362, DOI 10.4249/SCHOLARPEDIA.1362]; Song S., 2004, COMPUTATIONAL NEUROS, P324; Stroffek J, 2012, NEUROCOMPUTING, V77, P108, DOI 10.1016/j.neucom.2011.08.021; Stroffek J, 2010, IEEE VEH TECHNOL MAG, V5, P56, DOI 10.1109/MVT.2010.939109; Stroffek J, 2007, BIOSYSTEMS, V89, P257, DOI 10.1016/j.biosystems.2006.04.023; Torres JJ, 2007, NEUROCOMPUTING, V70, P2022, DOI 10.1016/j.neucom.2006.10.099; Tsodyks MV, 1997, P NATL ACAD SCI USA, V94, P719, DOI 10.1073/pnas.94.2.719; Turing A. M, 1936, P LOND MATH SOC, V42, P230, DOI DOI 10.1112/PLMS/S2-42.1.230; VONDERHEYDT R, 1984, SCIENCE, V224, P1260, DOI 10.1126/science.6539501; Widrow B., 1960, IRE Wescon Convention Record, V4; Wiener N., 1961, CYBERNETICS CONTROL; WILLSHAW DJ, 1969, NATURE, V222, P960, DOI 10.1038/222960a0; Wilson H.R., 1999, SPIKES DECISIONS ACT, P223; ZADOR A, 1990, P NATL ACAD SCI USA, V87, P6718, DOI 10.1073/pnas.87.17.6718	75	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	MAR 25	2015	152						27	35		10.1016/j.neucom.2014.11.022		9	Computer Science, Artificial Intelligence	Computer Science	CB4BG	WOS:000349572600004		
J	Hanif, A; Protopapas, P				Hanif, A.; Protopapas, P.			Recursive Bayesian estimation of regularized and irregular quasar light curves	MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY			English	Article						methods: data analysis; Magellanic Clouds; quasars: general	ACTIVE GALACTIC NUCLEI; DAMPED RANDOM-WALK; OPTICAL VARIABILITY; MACHO PROJECT; CLASSIFICATION; FLUCTUATIONS; METHODOLOGY; MODELS	We investigate the efficacy of recursive Bayesian estimation of regularized and irregular astrophysical time series using particle filters to understand latent dynamics. We begin by regularizing a MACHO (massive compact halo object) quasar light curve using linear interpolation techniques. This is subsequently modelled using a variety of autoregressive and autoregressive-integrated moving average models. We find that we can learn regularized astrophysical time series using particle filters. Motivated by this result, we proceed by working on raw, irregular light curves. Accurately modelling the underlying dynamics as a continuous autoregressive stochastic process, calibrated using an MCMC we find that the scale variable, t, is in fact first-order stable across 55 MACHO quasar light curves and thus not correlated with the black hole mass. We show that particle filters can be used to learn regularized and irregular astrophysical light curves. These results can be used to inform classification systems of stellar type and further study variability characteristics of quasars.	[Hanif, A.; Protopapas, P.] Harvard Univ, Inst Appl Computat Sci, Cambridge, MA 02138 USA; [Hanif, A.] UCL, Dept Comp Sci, Intelligent Syst Grp, London WC1E 6BT, England; [Protopapas, P.] Harvard Smithsonian Ctr Astrophys, Cambridge, MA 02138 USA	Hanif, A (reprint author), Harvard Univ, Inst Appl Computat Sci, Cambridge, MA 02138 USA.	ayub.hanif@ucl.ac.uk			UCL Graduate School	This work is supported by the UCL Graduate School under the Research Projects Fund.	Alcock C, 2000, ASTROPHYS J, V542, P281, DOI 10.1086/309512; Anderson B., 1979, PRENTICE HALL INFORM, P1; Aretxaga I, 1997, MON NOT R ASTRON SOC, V286, P271; Bauwens L., 1999, BAYESIAN INFERENCE D; Bloom JS, 2012, CH CRC DATA MIN KNOW, P89; Boroson TA, 2002, ASTROPHYS J, V565, P78, DOI 10.1086/324486; Box G., 1976, HOLDEN DAY SERIES TI, V1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BROCKWELL P.J., 2002, INTRO TIME SERIES FO, V2nd; Carpenter J, 1999, IEE P-RADAR SON NAV, V146, P2, DOI 10.1049/ip-rsn:19990255; Chen Z., 2003, TECHNICAL REPORT; Fernandes RC, 2000, ASTROPHYS J, V544, P123; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Debosscher J, 2007, ASTRON ASTROPHYS, V475, P1159, DOI 10.1051/0004-6361:20077638; Doucet A., 2001, SEQUENTIAL MONTE CAR; Doucet A., 2008, TUTORIAL PARTICLE FI; Duda R., 1973, PATERN CLASSIFICATIO; Freitas J., 2000, NEURAL COMPUT, V12, P955, DOI 10.1162/089976600300015664; Geha M, 2003, ASTRON J, V125, P1, DOI 10.1086/344947; GEWEKE J, 1989, ECONOMETRICA, V57, P1317, DOI 10.2307/1913710; GORDON NJ, 1993, IEE PROC-F, V140, P107; Hamilton J., 1994, TIME SERIES ANAL; Hanif A., 2012, EVOLUTIONARY COMPUTA, P1; Hawkins MRS, 2004, ASTRON ASTROPHYS, V424, P519, DOI 10.1051/0004-6361:20041127; Hodapp KW, 2004, ASTRON NACHR, V325, P636, DOI 10.1002/asna.200410300; Ivezic Z., 2008, SERB ASTRON J, V176; Kawaguchi T, 1998, ASTROPHYS J, V504, P671, DOI 10.1086/306105; Kazanas D., 2012, ASTRON REV, V7, P92; Kelly BC, 2011, ASTROPHYS J, V730, DOI 10.1088/0004-637X/730/1/52; Kelly BC, 2009, ASTROPHYS J, V698, P895, DOI 10.1088/0004-637X/698/1/895; Kim D.-W., 2012, APJ, P747; Kim D.-W., 2011, APJ, P735; Kitagawa G., 1996, J COMPUTATIONAL GRAP, V5, P1, DOI DOI 10.2307/1390750; Kozlowski S, 2010, ASTROPHYS J, V708, P927, DOI 10.1088/0004-637X/708/2/927; Larson S., 2003, BAAS, V35, P982; Law NM, 2009, PUBL ASTRON SOC PAC, V121, P1395; Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847; MacLeod CL, 2010, ASTROPHYS J, V721, P1014, DOI 10.1088/0004-637X/721/2/1014; Maskell S, 2004, STATE SPACE UNOBSERV, P40, DOI 10.1017/CBO9780511617010.004; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Mushotzky RF, 2011, ASTROPHYS J LETT, V743, DOI 10.1088/2041-8205/743/1/L12; Nenkova M, 2002, ASTROPHYS J, V570, pL9, DOI 10.1086/340857; Nikolaev N., 2007, WILMOTT MAGAZINE JUL, P72; Peterson BM, 2004, ASTROPHYS J, V613, P682, DOI 10.1086/423269; Pichara K., 2012, MNRAS, V427, P401; PRESS WH, 1992, ASTROPHYS J, V385, P404, DOI 10.1086/170951; Quinlan J. R., 1993, PROGRAMS MACHINE LEA, V1; Richards J. W., 2011, APJ, P733; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Rybicki G. B., 1994, APJ, V432, pL79; RYBICKI GB, 1992, ASTROPHYS J, V398, P169, DOI 10.1086/171845; Sorenson H, 1980, PARAMETER ESTIMATION; Sterken C., 1996, LIGHT CURVES VARIABL, P1; Wachman G, 2009, LECT NOTES ARTIF INT, V5782, P489; Wang YY, 2010, LECT NOTES ARTIF INT, V6323, P418; Zu Y, 2013, ASTROPHYS J, V765, DOI 10.1088/0004-637X/765/2/106	57	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0035-8711	1365-2966		MON NOT R ASTRON SOC	Mon. Not. Roy. Astron. Soc.	MAR 21	2015	448	1					390	402		10.1093/mnras/stv004		13	Astronomy & Astrophysics	Astronomy & Astrophysics	CC3TS	WOS:000350273500026		
J	Schuld, M; Sinayskiy, I; Petruccione, F				Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco			Simulating a perceptron on a quantum computer	PHYSICS LETTERS A			English	Article						Quantum neural network; Quantum machine learning; Quantum computing; Linear classification	NEURAL-NETWORKS; MODEL	Perceptrons are the basic computational unit of artificial neural networks, as they model the activation mechanism of an output neuron due to incoming signals from its neighbours. As linear classifiers, they play an important role in the foundations of machine learning. In the context of the emerging field of quantum machine learning, several attempts have been made to develop a corresponding unit using quantum information theory. Based on the quantum phase estimation algorithm, this paper introduces a quantum perceptron model imitating the step-activation function of a classical perceptron. This scheme requires resources in O(n) (where n is the size of the input) and promises efficient applications for more complex structures such as trainable quantum neural networks. (C) 2014 Elsevier B.V. All rights reserved.	[Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco] Univ KwaZulu Natal Durban, Sch Chem & Phys, Quantum Res Grp, ZA-4001 Kwa Zulu, South Africa; [Sinayskiy, Ilya; Petruccione, Francesco] Natl Inst Theoret Phys NITheP, ZA-4001 Kwa Zulu, South Africa	Schuld, M (reprint author), Univ KwaZulu Natal Durban, Sch Chem & Phys, Quantum Res Grp, ZA-4001 Kwa Zulu, South Africa.	schuld@ukzn.ac.za			South African Research Chair Initiative of the Department of Science and Technology, Republic of South Africa; National Research Foundation	This work is based upon research supported by the South African Research Chair Initiative of the Department of Science and Technology, Republic of South Africa, and National Research Foundation.	Altaisky M., ARXIVQUANTPH0107012; BARENCO A, 1995, PHYS REV A, V52, P3457, DOI 10.1103/PhysRevA.52.3457; Behrman EC, 2000, INFORM SCIENCES, V128, P257, DOI 10.1016/S0020-0255(00)00056-6; Dorit Aharonov J.K., 2001, P 33 STOC, P50; Fei L., 2003, P IEEE INT C NEUR NE, V1, P539; Grover L. K., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237866; Gupta S, 2001, J COMPUT SYST SCI, V63, P355, DOI 10.1006/jcss.2001.1769; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kouda N, 2005, NEURAL COMPUT APPL, V14, P114, DOI 10.1007/S00521-004-0446-8; LEWENSTEIN M, 1994, J MOD OPTIC, V41, P2491, DOI 10.1080/09500349414552331; Minsky M., 1969, PERCEPTRONS INTRO CO; Nielsen M. A., 2010, QUANTUM COMPUTATION; Plenio MB, 2001, CONTEMP PHYS, V42, P25, DOI 10.1080/00107510010018916; Purushothaman G, 1997, IEEE T NEURAL NETWOR, V8, P679, DOI 10.1109/72.572106; Quoc Le V., 2013, 2013 IEEE INT C AC S, P8595; Ricks B., 2003, ADV NEURAL INFORM PR, V16, P1; Rojas R., 1996, NEURAL NETS SYSTEMAT; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sagheer A., ARXIV13124149; Schuld M, 2014, QUANTUM INF PROCESS, V13, P2567, DOI 10.1007/s11128-014-0809-8; Siomau M, 2014, QUANTUM INF PROCESS, V13, P1211, DOI 10.1007/s11128-013-0723-5; Watrous J., 2014, LECT NOT WINT 2006; Zhou RG, 2007, INT J THEOR PHYS, V46, P3209, DOI 10.1007/s10773-007-9437-8	24	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0375-9601	1873-2429		PHYS LETT A	Phys. Lett. A	MAR 20	2015	379	7					660	663		10.1016/j.physleta.2014.11.061		4	Physics, Multidisciplinary	Physics	CB8KD	WOS:000349877600009		
J	Xu, JG; Li, H; Zhou, SL				Xu, Jungang; Li, Hui; Zhou, Shilong			An Overview of Deep Generative Models	IETE TECHNICAL REVIEW			English	Article						Deep belief networks; Restricted boltzmann machine; Deep autoencoder; Deep generative model; Deep boltzmann machine	RESTRICTED BOLTZMANN MACHINES; NEURAL-NETWORKS; CONTRASTIVE DIVERGENCE; BELIEF NETWORKS; VISUAL-CORTEX; RECOGNITION	As an important category of deep models, deep generative model has attracted more and more attention with the proposal of Deep Belief Networks (DBNs) and the fast greedy training algorithm based on restricted Boltzmann machines (RBMs). In the past few years, many different deep generative models are proposed and used in the area of Artificial Intelligence. In this paper, three important deep generative models including DBNs, deep autoencoder, and deep Boltzmann machine are reviewed. In addition, some successful applications of deep generative models in image processing, speech recognition and information retrieval are also introduced and analysed.	[Xu, Jungang; Li, Hui; Zhou, Shilong] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China	Xu, JG (reprint author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China.	xujg@ucas.ac.cn; lihui211@mails.ucas.ac.cn; zhoushilong12@mails.ucas.ac.cn			National Natural Science Foundation of China [61372171]; National Key Technology R&D Program of China [2012BAH23B03]	This work was supported by the National Natural Science Foundation of China [grant number 61372171]; the National Key Technology R&D Program of China [grant number 2012BAH23B03].	Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y., 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Cho K. H., 2010, P 2010 INT JOINT C N, P1; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; DeMers D., 1992, ADV NEURAL INFORMATI, V5, P580; Deng L., 2013, DEEP LEARNING SIGNAL; Earl DJ, 2005, PHYS CHEM CHEM PHYS, V7, P3910, DOI 10.1039/b509983h; Fang W, 2012, IETE TECH REV, V29, P380, DOI 10.4103/0256-4602.103168; Freund Y, 1991, ADV NEURAL INFORM PR, V4, P912; HECHTNIELSEN R, 1995, SCIENCE, V269, P1860, DOI 10.1126/science.269.5232.1860; Hinton G, 2011, TOP COGN SCI, V3, P74, DOI 10.1111/j.1756-8765.2010.01109.x; Hinton G. E., 1995, SCIENCE, V268, P1558; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Iba Y, 2001, INT J MOD PHYS C, V12, P623, DOI 10.1142/S0129183101001912; Jordan M. I., 1998, LEARNING GRAPHICAL M; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Luo J., 2012, INT J APPL MATH STAT, V28, P59; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Neal RM, 1996, STAT COMPUT, V6, P353, DOI 10.1007/BF00143556; Plaut D. C., 1987, Computer Speech and Language, V2, DOI 10.1016/0885-2308(87)90026-X; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov R., 2012, ADV NEURAL INFORM PR, V25, P1; Salakhutdinov R., 2009, THESIS U TORONTO TOR; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2222; Tanveer A., 2013, IETE TECHNICAL REV, V30, P47; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; Welling M., 2004, ADV NEURAL INFORM PR, V17, P1481; Werbos P. J., 1974, REGRESSION NEW TOOLS; Xu JG, 2014, NEUROCOMPUTING, V139, P328, DOI 10.1016/j.neucom.2014.02.024	46	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0256-4602	0974-5971		IETE TECH REV	IETE Tech. Rev.	MAR 4	2015	32	2					131	139		10.1080/02564602.2014.987328		9	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	CE5AS	WOS:000351842700007		
J	Ferre-Aracil, J; Cardona, SC; Navarro-Laboulais, J				Ferre-Aracil, J.; Cardona, S. C.; Navarro-Laboulais, J.			Ozonation Kinetics of Acid Red 27 Azo Dye: A Novel Methodology Based on Artificial Neural Networks for the Determination of Dynamic Kinetic Constants in Bubble Column Reactors	CHEMICAL ENGINEERING COMMUNICATIONS			English	Article						Ozonation; Bubble column reactor; Artificial neural network; Kinetic rate constant estimation	MASS-TRANSFER PARAMETERS; IDENTIFIABILITY ANALYSIS; OZONE OXIDATION; GAS HOLDUP; FILM MODEL; IDENTIFICATION; SYSTEMS; WATER; EFFLUENTS; OBSERVERS	A procedure for the determination of initial parameter values for quadratically convergent optimization methods is proposed using artificial neural networks coupled with a non-stationary gas-liquid reaction model. The evaluation of the regression and the mean squared error coefficients of the neural network during its training process allow the parameter sensitivity analysis of the gas-liquid model. This analysis examines how many and which parameters of the model will be available depending on the observable information of the mathematical model. Numerical simulations show the relevance of the initial values and the non-linearity of the objective function. The methodology has been applied to the study of the reaction of the azo-dye Acid Red 27 with ozone in acid media. The rate constant is in the order of (1.6 +/- 0.1) 10(3)M(-1)s(-1) under the experimental conditions.	[Ferre-Aracil, J.; Cardona, S. C.; Navarro-Laboulais, J.] Univ Politecn Valencia, ISIRYM, Dept Chem & Nucl Engn, Alcoy 03801, Alicante, Spain	Navarro-Laboulais, J (reprint author), Univ Politecn Valencia, ISIRYM, Dept Chem & Nucl Engn, Alcoy 03801, Alicante, Spain.	jnavarla@iqn.upv.es			Universitat Politecnica de Valencia [UPV-PAID-FPI-2010-04]	J. Ferre-Aracil acknowledges the support of the doctoral fellowship from the Universitat Politecnica de Valencia (UPV-PAID-FPI-2010-04).	[Anonymous], 2010, MATLAB V7 11; Baawain MS, 2007, OZONE-SCI ENG, V29, P343, DOI 10.1080/01919510701549236; Bas D, 2007, J FOOD ENG, V79, P1152, DOI 10.1016/j.jfoodeng.2006.04.004; Bas D, 2007, J FOOD ENG, V79, P622, DOI 10.1016/j.jfoodeng.2006.02.021; Bin AK, 2006, OZONE-SCI ENG, V28, P67, DOI 10.1080/01919510600558635; Cardona SC, 2010, CAN J CHEM ENG, V88, P491, DOI 10.1002/cjce.20327; Catorceno LLC, 2010, SEP SCI TECHNOL, V45, P1521, DOI 10.1080/01496395.2010.487453; Chairez I, 2007, IND ENG CHEM RES, V46, P5855, DOI 10.1021/ie0705103; Chairez I, 2010, CATAL TODAY, V151, P159, DOI 10.1016/j.cattod.2010.02.057; Constantinides A., 1999, NUMERICAL METHODS CH; Dachipally P, 2011, J ENVIRON SCI HEAL A, V46, P887, DOI 10.1080/10934529.2011.580201; Dote Y, 2001, P IEEE, V89, P1243, DOI 10.1109/5.949483; Dua V, 2011, COMPUT CHEM ENG, V35, P545, DOI 10.1016/j.compchemeng.2010.06.005; Englezos P., 2001, APPL PARAMEER ESTIMA; Ferre-Aracil J, 2013, OZONE-SCI ENG, V35, P423, DOI 10.1080/01919512.2013.815104; Galvan IM, 1996, COMPUT CHEM ENG, V20, P1451, DOI 10.1016/0098-1354(95)00231-6; Gokcen F, 2005, CHEM ENG J, V114, P99, DOI 10.1016/j.cej.2005.09.006; Gomes AC, 2010, J HAZARD MATER, V178, P57, DOI 10.1016/j.jhazmat.2010.01.043; Gupta P, 2000, FLOW MEAS INSTRUM, V11, P123, DOI 10.1016/S0955-5986(99)00025-4; Heck SL, 2001, ENVIRON ENG SCI, V18, P205, DOI 10.1089/109287501750281095; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Kantarci N, 2005, PROCESS BIOCHEM, V40, P2263, DOI 10.1016/j.procbio.2004.10.004; Kumar KV, 2009, CHEM ENG J, V148, P20, DOI 10.1016/j.cej.2008.07.026; Lemoine R, 2008, FUEL PROCESS TECHNOL, V89, P322, DOI 10.1016/j.fuproc.2007.11.016; Lopez-Lopez A, 2007, CHEMOSPHERE, V66, P2120, DOI 10.1016/j.chemosphere.2006.09.025; Molga EJ, 2000, CHEM ENG PROCESS, V39, P323, DOI 10.1016/S0255-2701(99)00093-8; Navarro-Laboulais J, 2006, AICHE J, V52, P2851, DOI 10.1002/aic.10901; Navarro-Laboulais J, 2008, COMPUT CHEM ENG, V32, P2382, DOI 10.1016/j.compchemeng.2007.12.004; Poznyak A, 2006, AUTOMAT REM CONTR+, V67, P887, DOI 10.1134/S0005117906060051; Poznyak A., 2004, INT J DIFFERENTIAL E, V12, P195; Poznyak T, 2005, WATER RES, V39, P2611, DOI 10.1016/j.watres.2005.04.061; Poznyak T, 2007, J HAZARD MATER, V146, P661, DOI 10.1016/j.jhazmat.2007.04.103; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saraceno A, 2010, COMPUT CHEM ENG, V34, P1590, DOI 10.1016/j.compchemeng.2009.11.010; Sevimli MF, 2002, J CHEM TECHNOL BIOT, V77, P842, DOI 10.1002/jctb.644; Shaikh A, 2003, CHEM ENG PROCESS, V42, P599, DOI 10.1016/S0255-2701(02)00209-X; Sumathi S, 2010, COMPUTATIONAL INTELLIGENCE PARADIGMS: THEORY AND APPLICATIONS USING MATLAB, P1, DOI 10.1201/9781439809037; Supardan MD, 2004, J CHEM ENG JPN, V37, P927, DOI 10.1252/jcej.37.927; Tizaoui C, 2011, CHEM ENG J, V173, P463, DOI 10.1016/j.cej.2011.08.014; Wong SY, 2010, CRYST GROWTH DES, V10, P2620, DOI 10.1021/cg100122y; Zwillinger D., 1998, HDB DIFFERENTIAL EQU	41	0	0	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0098-6445	1563-5201		CHEM ENG COMMUN	Chem. Eng. Commun.	MAR 4	2015	202	3					279	293		10.1080/00986445.2013.841146		15	Engineering, Chemical	Engineering	AS4HO	WOS:000344234900002		
J	Rombouts, JO; Bohte, SM; Roelfsema, PR				Rombouts, Jaldert O.; Bohte, Sander M.; Roelfsema, Pieter R.			How Attention Can Create Synaptic Tags for the Learning of Working Memories in Sequential Tasks	PLOS COMPUTATIONAL BIOLOGY			English	Article							PREFRONTAL CORTEX; DECISION-MAKING; BASAL GANGLIA; ORBITOFRONTAL CORTEX; COMPUTATIONAL MODEL; CIRCUIT MECHANISM; ACTION SELECTION; PARIETAL CORTEX; NEURAL-NETWORKS; NUCLEUS BASALIS	Intelligence is our ability to learn appropriate responses to new stimuli and situations. Neurons in association cortex are thought to be essential for this ability. During learning these neurons become tuned to relevant features and start to represent them with persistent activity during memory delays. This learning process is not well understood. Here we develop a biologically plausible learning scheme that explains how trial-and-error learning induces neuronal selectivity and working memory representations for task-relevant information. We propose that the response selection stage sends attentional feedback signals to earlier processing levels, forming synaptic tags at those connections responsible for the stimulus-response mapping. Globally released neuromodulators then interact with tagged synapses to determine their plasticity. The resulting learning rule endows neural networks with the capacity to create new working memory representations of task relevant information as persistent activity. It is remarkably generic: it explains how association neurons learn to store task-relevant information for linear as well as non-linear stimulus-response mappings, how they become tuned to category boundaries or analog variables, depending on the task demands, and how they learn to integrate probabilistic evidence for perceptual decisions.	[Rombouts, Jaldert O.; Bohte, Sander M.] Ctr Wiskunde & Informat, Dept Life Sci, Amsterdam, Netherlands; [Roelfsema, Pieter R.] Netherlands Inst Neurosci, Dept Vis & Cognit, Amsterdam, Netherlands; [Roelfsema, Pieter R.] Vrije Univ Amsterdam, Ctr Neurogen & Cognit Res, Dept Integrat Neurophysiol, Amsterdam, Netherlands; [Roelfsema, Pieter R.] Univ Amsterdam, Acad Med Ctr, Dept Psychiat, NL-1105 AZ Amsterdam, Netherlands	Rombouts, JO (reprint author), Ctr Wiskunde & Informat, Dept Life Sci, Amsterdam, Netherlands.	p.roelfsema@nin.knaw.nl			European Union [269921, PITN-GA-2011-290011, 339490]; NWO [433-09-208, 612.066.826]	The work was supported by grants of the European Union (project 269921 "BrainScaleS"; PITN-GA-2011-290011 "ABC"; ERC Grant Agreement n. 339490) and a NWO grants (VICI and Brain, Cognition grant n. 433-09-208 and EW grant n. 612.066.826). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	AHISSAR M, 1993, P NATL ACAD SCI USA, V90, P5718, DOI 10.1073/pnas.90.12.5718; Baird L, 1995, ICML, V95, P30; Barak O, 2013, PROG NEUROBIOL, V103, P214, DOI 10.1016/j.pneurobio.2013.02.002; Boyan J.A., 1995, ADV NEURAL INFORM PR, V7, P369; Cassenaer S, 2012, NATURE, V482, P47, DOI 10.1038/nature10776; Dayan P, 2002, NEURON, V36, P285, DOI 10.1016/S0896-6273(02)00963-7; Deco G, 2010, P NATL ACAD SCI USA, V107, P7545, DOI 10.1073/pnas.1002333107; De Pasquale R, 2011, J NEUROSCI, V31, P16494, DOI 10.1523/JNEUROSCI.3664-11.2011; Deubel H, 1996, VISION RES, V36, P1827, DOI 10.1016/0042-6989(95)00294-4; Duncan J, 2010, TRENDS COGN SCI, V14, P172, DOI 10.1016/j.tics.2010.01.004; Easton A, 2002, CEREB CORTEX, V12, P729, DOI 10.1093/cercor/12.7.729; Egorov AV, 2002, NATURE, V420, P173, DOI 10.1038/nature01171; Engel TA, 2011, J NEUROSCI, V31, P6982, DOI 10.1523/JNEUROSCI.6150-10.2011; Fransen E, 2006, NEURON, V49, P735, DOI 10.1016/j.neuron.2006.01.036; Freedman DJ, 2001, SCIENCE, V291, P312, DOI 10.1126/science.291.5502.312; Freedman DJ, 2006, NATURE, V443, P85, DOI 10.1038/nature05078; Fremaux N, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003024; Frey U, 1997, NATURE, V385, P533, DOI 10.1038/385533a0; Friedrich J, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002092; FUNAHASHI S, 1989, J NEUROPHYSIOL, V61, P331; Fusi S, 2005, NEURON, V45, P599, DOI 10.1016/j.neuron.2005.02.001; GNADT JW, 1988, EXP BRAIN RES, V70, P216; Gold JI, 2007, ANNU REV NEUROSCI, V30, P535, DOI 10.1146/annurev.neuro.29.051605.113038; Gottlieb J, 1999, NAT NEUROSCI, V2, P906, DOI 10.1038/13209; Gurney K, 2001, BIOL CYBERN, V84, P401, DOI 10.1007/PL00007984; Hernandez A, 1997, J NEUROSCI, V17, P6391; Hikosaka O, 2006, J NEUROPHYSIOL, V95, P567, DOI 10.1152/jn.00458.2005; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hoerzer GM, 2014, CEREB CORTEX, V24, P677, DOI 10.1093/cercor/bhs348; Houk JC, 1995, MODELS INFORM PROCES, P1, DOI [10.1007/s00422-011-0439-5, DOI 10.1007/S00422-011-0439-5]; Humphries MD, 2006, J NEUROSCI, V26, P12921, DOI 10.1523/JNEUROSCI.3486-06.2006; Izhikevich EM, 2007, CEREB CORTEX, V17, P2443, DOI 10.1093/cercor/bhl152; Jiang YH, 2001, Q J EXP PSYCHOL-A, V54, P1105, DOI 10.1080/02724980042000516; Kilgard MP, 1998, SCIENCE, V279, P1714, DOI 10.1126/science.279.5357.1714; Koulakov AA, 2002, NAT NEUROSCI, V5, P775, DOI 10.1038/nn893; Krueger KA, 2009, COGNITION, V110, P380, DOI 10.1016/j.cognition.2008.11.014; Liu ZX, 2014, NEURON, V81, P1360, DOI 10.1016/j.neuron.2014.02.010; Lo CC, 2006, NAT NEUROSCI, V9, P956, DOI 10.1038/nn1722; Luk CH, 2009, J NEUROSCI, V29, P7526, DOI 10.1523/JNEUROSCI.0386-09.2009; Machens CK, 2005, SCIENCE, V307, P1121, DOI 10.1126/science.1104171; Mao TY, 2011, NEURON, V72, P111, DOI 10.1016/j.neuron.2011.07.029; Matsumoto K, 2003, SCIENCE, V301, P229, DOI 10.1126/science.1084204; Miller P, 2006, P NATL ACAD SCI USA, V103, P201, DOI 10.1073/pnas.0508072103; Moncada D, 2011, P NATL ACAD SCI USA, V108, P12931, DOI 10.1073/pnas.1104495108; Montague PR, 2004, NATURE, V431, P760, DOI 10.1038/nature03015; Moore T, 2003, NATURE, V421, P370, DOI 10.1038/nature01341; Morris G, 2006, NAT NEUROSCI, V9, P1057, DOI 10.1038/nn1743; Nassi JJ, 2009, NAT REV NEUROSCI, V10, P360, DOI 10.1038/nrn2619; O'Reilly RC, 2012, OXFORD HDB COGNITIVE; O'Reilly R.C., 2000, COMPUTATIONAL EXPLOR; O'Reilly RC, 2006, NEURAL COMPUT, V18, P283, DOI 10.1162/089976606775093909; Padoa-Schioppa C, 2006, NATURE, V441, P223, DOI 10.1038/nature04676; Parisien C, 2008, NEURAL COMPUT, V20, P1473, DOI 10.1162/neco.2008.07-06-295; Peck CJ, 2014, J NEUROSCI, V34, P13757, DOI 10.1523/JNEUROSCI.2106-14.2014; Potjans W, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1001133; RICHARDSON RT, 1986, BRAIN RES, V399, P364, DOI 10.1016/0006-8993(86)91529-5; Rigotti M, 2013, NATURE, V497, P585, DOI 10.1038/nature12160; Roelfsema PR, 2010, TRENDS COGN SCI, V14, P64, DOI 10.1016/j.tics.2009.11.005; Roelfsema PR, 2005, NEURAL COMPUT, V17, P2176, DOI 10.1162/0899766054615699; Rombouts J.O., 2012, ADV NEURAL INFORM PR, V25, P1880; Romo R, 2003, NAT REV NEUROSCI, V4, P203, DOI 10.1038/nrn1058; Romo R, 2003, NEURON, V38, P649, DOI 10.1016/S0896-6273(03)00287-3; Romo R, 1999, NATURE, V399, P470, DOI 10.1038/20939; Romo R, 2004, NEURON, V41, P165, DOI 10.1016/S0896-6273(03)00817-1; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Rummery GA, 1994, ON LINE Q LEARNING U; Sajikumar S, 2011, P NATL ACAD SCI USA, V108, P2551, DOI 10.1073/pnas.1016849108; Samejima K, 2005, SCIENCE, V310, P1337, DOI 10.1126/science.1115270; Schoups A, 2001, NATURE, V412, P549, DOI 10.1038/35087601; Schultz W, 2007, ANNU REV NEUROSCI, V30, P259, DOI 10.1146/annurev.neuro.28.061604.135722; Schultz W, 2002, NEURON, V36, P241, DOI 10.1016/S0896-6273(02)00967-4; Self MW, 2012, P NATL ACAD SCI USA, V109, P11031, DOI 10.1073/pnas.1119527109; Seung HS, 2003, NEURON, V40, P1063, DOI 10.1016/S0896-6273(03)00761-X; Sherman SM, 1998, P NATL ACAD SCI USA, V95, P7121, DOI 10.1073/pnas.95.12.7121; Soltani A, 2009, NAT NEUROSCI, V13, P112, DOI [10.1038/nn.2450, DOI 10.1038/NN.2450]; Sommer MA, 2001, J NEUROPHYSIOL, V85, P1673; Stewart TC, 2012, FRONT NEUROSCI, V6; Suri RE, 1998, EXP BRAIN RES, V121, P350, DOI 10.1007/s002210050467; Sutton R. S., 1998, REINFORCEMENT LEARNI; Todd MT, 2009, NEURAL INFORM PROCES, V21, P1689; Urbanczik R, 2009, NAT NEUROSCI, V12, P250, DOI 10.1038/nn.2264; Usher M, 2001, PSYCHOL REV, V108, P550, DOI 10.1037//0033-295X.108.3.550; Wallis JD, 2007, ANNU REV NEUROSCI, V30, P31, DOI 10.1146/annurev.neuro.30.051606.094334; Wiering M, 1997, ADAPT BEHAV, V6, P219, DOI 10.1177/105971239700600202; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Yagishita S, 2014, SCIENCE, V345, P1616, DOI 10.1126/science.1255514; Yang T, 2007, NATURE, V447, P1075, DOI 10.1038/nature05852; Zipser D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.179	88	0	0	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1553-734X	1553-7358		PLOS COMPUT BIOL	PLoS Comput. Biol.	MAR	2015	11	3							e1004060	10.1371/journal.pcbi.1004060		34	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	CE9XB	WOS:000352195700007	25742003	
J	Soh, H; Demiris, Y				Soh, Harold; Demiris, Yiannis			Spatio-Temporal Learning With the Online Finite and Infinite Echo-State Gaussian Processes	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			English	Article						Gaussian processes (GPs); machine learning; recurrent neural networks (RNNs); time-series analysis	RECURRENT; REGRESSION; ALGORITHM; NETWORKS; MODEL	Successful biological systems adapt to change. In this paper, we are principally concerned with adaptive systems that operate in environments where data arrives sequentially and is multivariate in nature, for example, sensory streams in robotic systems. We contribute two reservoir inspired methods: 1) the online echostate Gaussian process (OESGP) and 2) its infinite variant, the online infinite echostate Gaussian process (OIESGP) Both algorithms are iterative fixed-budget methods that learn from noisy time series. In particular, the OESGP combines the echo-state network with Bayesian online learning for Gaussian processes. Extending this to infinite reservoirs yields the OIESGP, which uses a novel recursive kernel with automatic relevance determination that enables spatial and temporal feature weighting. When fused with stochastic natural gradient descent, the kernel hyperparameters are iteratively adapted to better model the target system. Furthermore, insights into the underlying system can be gleamed from inspection of the resulting hyperparameters. Experiments on noisy benchmark problems (one-step prediction and system identification) demonstrate that our methods yield high accuracies relative to state-of-the-art methods, and standard kernels with sliding windows, particularly on problems with irrelevant dimensions. In addition, we describe two case studies in robotic learning-by-demonstration involving the Nao humanoid robot and the Assistive Robot Transport for Youngsters (ARTY) smart wheelchair.	[Soh, Harold; Demiris, Yiannis] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, Intelligent Syst & Networks Grp, Personal Robot Lab, London SW7 2BT, England	Soh, H (reprint author), Singapore MIT Alliance Res & Technol, Singapore 138602, Singapore.	haroldsoh@smart.mit.edu; y.demiris@imperial.ac.uk			EU FP7 Project ALIZ-E [248116]	This work was supported by the EU FP7 Project ALIZ-E under Grant 248116.	Amari S, 2000, NEURAL COMPUT, V12, P1399, DOI 10.1162/089976600300015420; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024; Atiya AF, 2000, IEEE T NEURAL NETWOR, V11, P697, DOI 10.1109/72.846741; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, DOI 10.1007/978-3-642-35289-8_25; Candela J., 2005, J MACH LEARN RES, V6, P1939; CASDAGLI M, 1991, PHYSICA D, V51, P52, DOI 10.1016/0167-2789(91)90222-U; Chatzis SP, 2011, IEEE T NEURAL NETWOR, V22, P1435, DOI 10.1109/TNN.2011.2162109; Csato L, 2002, NEURAL COMPUT, V14, P641, DOI 10.1162/089976602317250933; Csato L., 2002, THESIS ASTON U BIRMI; Demiris Y, 2006, ROBOT AUTON SYST, V54, P361, DOI 10.1016/j.robot.2006.02.003; Deng ZD, 2007, IEEE T NEURAL NETWOR, V18, P1364, DOI 10.1169/TNN.2007.894082; Engel Y, 2004, IEEE T SIGNAL PROCES, V52, P2275, DOI 10.1109/TSP.2004.830985; GEISSER S, 1979, J AM STAT ASSOC, V74, P153, DOI 10.2307/2286745; Girard A., 2004, THESIS U GLASGOW GLA; Hermans M., 2011, NEURAL COMPUT, V24, P104; Jaeger H, 2003, ADV NEURAL INFORM PR, V15, P593; Jaeger H., 2001, 148 GMD GERM NAT RES, P148; Kalman R. E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552; Kantz H., 2003, NONLINEAR TIME SERIE, V7; Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991; Korkinof D, 2013, IEEE INT C INT ROBOT, P3222, DOI 10.1109/IROS.2013.6696814; Kountouriotis P., 2005, P INT C COMP TOOL NO, V2, P1574; Liu WF, 2008, IEEE T SIGNAL PROCES, V56, P543, DOI 10.1109/TSP.2007.907881; Lukosevicius M., 2009, COMPUTER SCI REV, V3, P127, DOI DOI 10.1016/J.COSREV.2009.03.005; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Marchal-Crespo L, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-40; Neal RM, 1996, BAYESIAN LEARNING NE; Opper M., 1998, ON LINE LEARNING NEU, P363; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rodan A, 2011, IEEE T NEURAL NETWOR, V22, P131, DOI 10.1109/TNN.2010.2089641; Roux N. L., 2007, ADV NEURAL INFORM PR, V20, P849; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schafer AM, 2006, LECT NOTES COMPUT SC, V4131, P632; Seeger M., 2003, P 9 INT WORKSH ART I, V9, P2003; Snelson E., 2006, ADV NEURAL INFORM PR, V18, P1257; Soh H., 2012, P INT JOINT C NEUR N, P1; Soh H, 2012, IEEE INT C INT ROBOT, P4489, DOI 10.1109/IROS.2012.6385992; Soh H., 2012, P IROS WORKSH PROGR; Stark J, 2003, J NONLINEAR SCI, V13, P519, DOI 10.1007/s00332-003-0534-4; Strauss T, 2012, NEURAL COMPUT, V24, P3246, DOI 10.1162/NECO_a_00374; Takens F., 1981, DYNAMICAL SYSTEMS TU, V898, P366, DOI DOI 10.1007/BFB0091924; Van Vaerenbergh S, 2012, IEEE T NEUR NET LEAR, V23, P1313, DOI 10.1109/TNNLS.2012.2200500; Verstraeten D., 2010, RESERVOIR COMPUTING; Vijayakumar S, 2005, NEURAL COMPUT, V17, P2602, DOI 10.1162/089976605774320557; Vivarelli F, 1999, ADV NEUR IN, V11, P613; Wen E., 2011, TIME SERIES DATA; WERBOS PJ, 1988, NEURAL NETWORKS, V1, P339, DOI 10.1016/0893-6080(88)90007-X; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270	50	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2162-237X	2162-2388		IEEE T NEUR NET LEAR	IEEE Trans. Neural Netw. Learn. Syst.	MAR	2015	26	3					522	536		10.1109/TNNLS.2014.2316291		15	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	CE4XT	WOS:000351834400009	25720008	
J	D'Andrea, E; Pagnotta, S; Grifoni, E; Legnaioli, S; Lorenzetti, G; Palleschi, V; Lazzerini, B				D'Andrea, Eleonora; Pagnotta, Stefano; Grifoni, Emanuela; Legnaioli, Stefano; Lorenzetti, Giulia; Palleschi, Vincenzo; Lazzerini, Beatrice			A hybrid calibration-free/artificial neural networks approach to the quantitative analysis of LIBS spectra	APPLIED PHYSICS B-LASERS AND OPTICS			English	Article							INDUCED BREAKDOWN SPECTROSCOPY	A 'hybrid' method is proposed for the quantitative analysis of materials by LIBS, combining the precision of the calibration-free LIBS (CF-LIBS) algorithm with the quickness of artificial neural networks. The method allows the precise determination of the samples' composition even in the presence of relatively large laser fluctuations and matrix effects. To show the strength and robustness of this approach, a number of synthetic LIBS spectra of Cu-Ni binary alloys with different composition were computer-simulated, in correspondence of different plasma temperatures, electron number densities and ablated mass. The CFLIBS/ANN approach here proposed demonstrated to be capable, after appropriate training, of 'learning' the basic physical relations between the experimentally measured line intensities and the plasma parameters. Because of that the composition of the sample can be correctly determined, as in CF-LIBS measurements, but in a much shorter time.	[D'Andrea, Eleonora; Lazzerini, Beatrice] Univ Pisa, Dept Informat Engn, I-56122 Pisa, Italy; [Pagnotta, Stefano; Grifoni, Emanuela; Legnaioli, Stefano; Lorenzetti, Giulia; Palleschi, Vincenzo] CNR, Res Area, Inst Chem Organometall Cpds, I-56122 Pisa, Italy	Palleschi, V (reprint author), CNR, Res Area, Inst Chem Organometall Cpds, Via G Moruzzi 1, I-56122 Pisa, Italy.	vincenzo.palleschi@cnr.it					Andrade JM, 2010, SPECTROCHIM ACTA B, V65, P658, DOI 10.1016/j.sab.2010.04.008; Borges FO, 2014, APPL PHYS B-LASERS O, V117, P437, DOI 10.1007/s00340-014-5852-8; Boueri M, 2011, APPL SPECTROSC, V65, P307, DOI 10.1366/10-06079; Bredice F, 2007, SPECTROCHIM ACTA B, V62, P1237, DOI 10.1016/j.sab.2007.10.014; Caceres JO, 2013, APPL SPECTROSC, V67, P1064, DOI 10.1366/12-06916; Cavalcanti GH, 2013, SPECTROCHIM ACTA B, V87, P51, DOI 10.1016/j.sab.2013.05.016; Ciucci A, 1999, APPL SPECTROSC, V53, P960, DOI 10.1366/0003702991947612; Cremers D.A., 2013, LIBS ANAL FIGURES ME; Cristoforetti G, 2010, SPECTROCHIM ACTA B, V65, P86, DOI 10.1016/j.sab.2009.11.005; D'Andrea E, 2014, SPECTROCHIM ACTA B, V99, P52, DOI 10.1016/j.sab.2014.06.012; Danzer K, 1998, PURE APPL CHEM, V70, P993, DOI 10.1351/pac199870040993; El Haddad J, 2014, SPECTROCHIM ACTA B, V97, P57, DOI 10.1016/j.sab.2014.04.014; Haykin S., 1999, NEURAL NETWORKS COMP; Kuncheva L. I., 2004, COMBINING PATTERN CL; Mikut R, 2011, WIRES DATA MIN KNOWL, V1, P431, DOI 10.1002/widm.24; Russo RE, 2006, LASER-INDUCED BREAKDOWN SPECTROSCOPY (LIBS): FUNDAMENTALS AND APPLICATIONS, pXV; Palleschi V, 2011, J ANAL ATOM SPECTROM, V26, P2300, DOI 10.1039/c1ja10197h; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Tognoni E, 2010, SPECTROCHIM ACTA B, V65, P1, DOI 10.1016/j.sab.2009.11.006; Vitkova G, 2012, SPECTROCHIM ACTA B, V73, P1, DOI 10.1016/j.sab.2012.05.010; Winefordner JD, 2004, J ANAL ATOM SPECTROM, V19, P1061, DOI 10.1039/b400355c	21	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0946-2171	1432-0649		APPL PHYS B-LASERS O	Appl. Phys. B-Lasers Opt.	MAR	2015	118	3					353	360		10.1007/s00340-014-5990-z		8	Optics; Physics, Applied	Optics; Physics	CC4UO	WOS:000350349600003		
J	Hu, WP; Qian, Y; Soong, FK; Wang, Y				Hu, Wenping; Qian, Yao; Soong, Frank K.; Wang, Yong			Improved mispronunciation detection with deep neural network trained acoustic models and transfer learning based logistic regression classifiers	SPEECH COMMUNICATION			English	Article						Computer-aided language learning; Mispronunciation detection; Deep neural network; Logistic regression; Transfer learning	SPEECH RECOGNITION; KNOWLEDGE; ERROR	Mispronunciation detection is an important part in a Computer-Aided Language Learning (CALL) system. By automatically pointing out where mispronunciations occur in an utterance, a language learner can receive informative and to-the-point feedbacks. In this paper, we improve mispronunciation detection performance with a Deep Neural Network (DNN) trained acoustic model and transfer learning based Logistic Regression (LR) classifiers. The acoustic model trained by the conventional GMM-HMM based approach is refined by the DNN training with enhanced discrimination. The corresponding Goodness Of Pronunciation (GOP) scores are revised to evaluate pronunciation quality of non-native language learners robustly. A Neural Network (NN) based, Logistic Regression (LR) classifier, where a general neural network with shared hidden layers for extracting useful speech features is pre-trained firstly with pooled, training data in the sense of transfer learning, and then phone-dependent, 2-class logistic regression classifiers are trained as phone specific output layer nodes, is proposed to mispronunciation detection. The new LR classifier streamlines training multiple individual classifiers separately by learning the common feature representation via the shared hidden layer. Experimental results on an isolated English word corpus recorded by non-native (L2) English learners show that the proposed GOP measure can improve the performance of GOP based mispronunciation detection approach, i.e., 7.4% of the precision and recall rate are both improved, compared with the conventional GOP estimated from GMM-HMM. The NN-based LR classifier improves the equal precision recall rate by 25% over the best GOP based approach. It also outperforms the state-of-art Support Vector Machine (SVM) based classifier by 2.2% of equal precision recall rate improvement. Our approaches also achieve similar results on a continuous read, L2 Mandarin language learning corpus. (C) 2014 Elsevier B.V. All rights reserved.	[Hu, Wenping; Wang, Yong] Univ Sci & Technol China, Hefei 230026, Peoples R China; [Hu, Wenping; Qian, Yao; Soong, Frank K.] Microsoft Res Asia, Beijing 100080, Peoples R China	Qian, Y (reprint author), Microsoft Res Asia, Beijing 100080, Peoples R China.	hwping@mail.ustc.edu.cn; yaoqian@microsoft.com; frankkps@microsoft.com; yongwang@ustc.edu.cn					Bahl L., 1986, P INT C AC SPEECH SI, V11, P49, DOI DOI 10.1109/ICASSP.1986.1169179>; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bishop C. M., 2006, PATTERN RECOGNITION; Chen N.F., 2013, P INTERSPEECH 2013 I, P2370; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Franco H., 1999, P EUR, V2, P851; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G. E., 2012, IMPROVING NEURAL NET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hirabayashi K, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P598; Hu W., 2014, P ICASSP 2014 IEEE, P3230; Hu W., 2013, P INTERSPEECH 2013 I, P1886; Hu W., 2014, P ISCSLP 2014 IEEE, P245; Huang JT, 2013, INT CONF ACOUST SPEE, P7304; Ito A., 2005, P EUROSPEECH, P173; Jiang H, 2005, SPEECH COMMUN, V45, P455, DOI 10.1016/j.specrom.2004.12.004; Jie J., 2009, P ICASSP 2009 IEEE, P4833; Joachims T., 1998, 24 LS8 U DORTM; Juang B.H., 1997, IEEE T SPEECH AUDIO, V5, P266; Kim Y, 1997, P EUR, V97, P645; Pitrelli J.F., 1995, PHONEBOOK NYNEX ISOL; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Qian X., 2012, P INTERSPEECH 2012 I; Qian XJ, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P757; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Seide F., 2011, P ASRU, P24; Soong F.K., 2004, P SWIM 2004; Strik H, 2009, SPEECH COMMUN, V51, P845, DOI 10.1016/j.specom.2009.05.007; Tokuda K, 2002, IEICE T INF SYST, VE85D, P455; Truong K, 2004, THESIS UTRECHT U NET; van Doremalen J, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P580, DOI 10.1109/ASRU.2009.5373335; Vanhoucke V, 2013, INT CONF ACOUST SPEE, P7582, DOI 10.1109/ICASSP.2013.6639137; Vapnik V., 1995, NATURE STAT LEARNING; Wang YB, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5049; Wei S, 2009, SPEECH COMMUN, V51, P896, DOI 10.1016/j.specom.2009.03.004; Witt SM, 2000, SPEECH COMMUN, V30, P95, DOI 10.1016/S0167-6393(99)00044-8; Witt S.M., 2012, P INT S AUT DET ERR, P1; Xu S, 2009, INT CONF ACOUST SPEE, P4841; Xue J., 2013, P INTERSPEECH, P2365; Yan K., 2011, IJITCS, V3, P17; Yoon SY, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P614; Zhang F, 2008, INT CONF ACOUST SPEE, P5077	42	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393	1872-7182		SPEECH COMMUN	Speech Commun.	MAR	2015	67						154	166		10.1016/j.specom.2014.12.008		13	Acoustics; Communication; Computer Science, Interdisciplinary Applications; Language & Linguistics	Acoustics; Communication; Computer Science; Linguistics	CC1HD	WOS:000350090900013		
J	Masikos, M; Demestichas, K; Adamopoulou, E; TheologouNational, M				Masikos, Michail; Demestichas, Konstantinos; Adamopoulou, Evgenia; TheologouNational, Michael			Energy-efficient routing based on vehicular consumption predictions of a mesoscopic learning model	APPLIED SOFT COMPUTING			English	Article						Energy-efficient routing; Mesoscopic learning model; FEV; Contex-aware routing; Consumption factor analysis	FUEL CONSUMPTION; NEURAL-NETWORK; EMISSIONS; SYSTEM; ALGORITHM; CHOICE; PATHS; TIME	This paper proposes an alternative approach for determining the most energy efficient route towards a destination. An innovative mesoscopic vehicular consumption model that is based on machine learning functionality is introduced and its application in a case study involving Fully Electric Vehicles (FEVs) is examined. The integration of this model in a routing engine especially designed for FEVs is also analyzed and a software architecture for implementing the proposed routing methodology is defined. In order to verify the robustness and the energy efficiency of this methodology, a system prototype has been developed and a series of field tests have been performed. The results of these tests are reported and significant conclusions are derived regarding the generated energy efficient routes. (C) 2014 Elsevier B.V. All rights reserved.	[Masikos, Michail; Demestichas, Konstantinos; Adamopoulou, Evgenia; TheologouNational, Michael] Natl Tech Univ Athens, Athens, Greece	Masikos, M (reprint author), Natl Tech Univ Athens, Heroon Polytechneiou 9, Athens, Greece.	mmasik@telecom.ntua.gr			EU Seventh Framework Programme [FP7 314151]	This work is performed under the FP7 314151 project EMERALD, which has received research funding from the EU Seventh Framework Programme. This paper reflects only the authors views, and the Community is not liable for any use that may be made of the information contained therein.	ADLINK, 2013, ADLINK MXE 5302 DEV; Ahn K., 2007, C INT TRANSP SYST C; Ahn KG, 2008, TRANSPORT RES D-TR E, V13, P151, DOI 10.1016/j.trd.2008.01.005; Alam MS, 2014, TRANSPORT POLICY, V35, P42, DOI 10.1016/j.tranpol.2014.05.016; Bandeira J., 2012, J INTELL TRANSP SYST, V17, P3; Bandeira J., 2012, TRANSP RES BOARD 91; Bellman R., 1958, Q APPL MATH, V16, P87; Ben Dhaou I, 2011, IEEE INT VEH SYM, P37, DOI 10.1109/IVS.2011.5940399; Boriboonsomsin K, 2012, IEEE T INTELL TRANSP, V13, P1694, DOI 10.1109/TITS.2012.2204051; Carrese S, 2013, PROCD SOC BEHV, V87, P211, DOI 10.1016/j.sbspro.2013.10.605; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; DTREG, 2013, DTREG SOFTW PRED MOD; Ericsson E, 2006, TRANSPORT RES C-EMER, V14, P369, DOI 10.1016/j.trc.2006.10.001; Fletcher R., 1987, PRACTICAL METHODS OP; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; Ford L. R., 1956, TECHNICAL REPORT; Frey HC, 2008, ENVIRON SCI TECHNOL, V42, P2483, DOI 10.1021/es702493v; HART P, 1968, IEEE T SYST SCI CYB, V2, P100, DOI DOI 10.1109/TSSC.1968.300136; Haykin Simon, 1998, NEURAL NETWORKS COMP; JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993; Kamal MAS, 2011, IEEE T INTELL TRANSP, V12, P783, DOI 10.1109/TITS.2011.2112648; Kang J., 2011, 2011 11 INT C ITS TE, P207; Kono T, 2008, 15 WORLD C INT TRANS; Kraschl-Hirschmann K., 2012, IEEE INT VEH S, P258, DOI DOI 10.1109/IVS.2012.6232127; Ma XL, 2012, ENVIRON MODEL ASSESS, V17, P375, DOI 10.1007/s10666-011-9296-9; Mensing F, 2014, TRANSPORT RES C-EMER, V38, P110, DOI 10.1016/j.trc.2013.10.013; Minett C. F., 2011, 2011 IEEE Forum on Integrated and Sustainable Transportation Systems (FISTS 2011), DOI 10.1109/FISTS.2011.5973621; Mitchell T. M, 1997, MACHINE LEARNING; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Nie Y, 2013, TRANSPORT RES B-METH, V55, P154, DOI 10.1016/j.trb.2013.06.004; Nouveliere L., 2012, 2012 9th IEEE International Conference on Networking, Sensing and Control (ICNSC), DOI 10.1109/ICNSC.2012.6204942; Pachernegg S., 1969, SAE TECHNICAL PAPER; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Vapnik V., 1995, NATURE STAT LEARNING; Vector, 2013, VECT BOX VN1610 DEV; WARSHALL S, 1962, J ACM, V9, P11, DOI 10.1145/321105.321107; Wu JD, 2011, EXPERT SYST APPL, V38, P4967, DOI 10.1016/j.eswa.2010.09.155; Wu JD, 2012, EXPERT SYST APPL, V39, P1883, DOI 10.1016/j.eswa.2011.07.139; Yao EJ, 2013, J INTELL TRANSPORT S, V17, P42, DOI 10.1080/15472450.2013.747822	39	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946	1872-9681		APPL SOFT COMPUT	Appl. Soft. Comput.	MAR	2015	28						114	124		10.1016/j.asoc.2014.11.054		11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	AZ8GF	WOS:000348452500012		
J	Lahmiri, S; Boukadoum, M				Lahmiri, S.; Boukadoum, M.			An Ensemble System Based on Hybrid EGARCH-ANN with Different Distributional Assumptions to Predict S&P 500 Intraday Volatility	FLUCTUATION AND NOISE LETTERS			English	Article						Stock market; volatility; EGARCH; neural networks; ensemble; forecasting	NEURAL-NETWORK; GARCH MODELS; STOCK INDEX; RETURN; FORECASTS	Accurate forecasting of stock market volatility is an important issue in portfolio risk management. In this paper, an ensemble system for stock market volatility is presented. It is composed of three different models that hybridize the exponential generalized autoregressive conditional heteroscedasticity (GARCH) process and the artificial neural network trained with the backpropagation algorithm (BPNN) to forecast stock market volatility under normal, t-Student, and generalized error distribution (GED) assumption separately. The goal is to design an ensemble system where each single hybrid model is capable to capture normality, excess skewness, or excess kurtosis in the data to achieve complementarity. The performance of each EGARCH-BPNN and the ensemble system is evaluated by the closeness of the volatility forecasts to realized volatility. Based on mean absolute error and mean of squared errors, the experimental results show that proposed ensemble model used to capture normality, skewness, and kurtosis in data is more accurate than the individual EGARCH-BPNN models in forecasting the S&P 500 intra-day volatility based on one and five-minute time horizons data.	[Lahmiri, S.] ESCA Sch Management, Casablanca, Morocco; [Boukadoum, M.] Univ Quebec, Dept Comp Sci, Montreal, PQ H3C 3P8, Canada	Lahmiri, S (reprint author), ESCA Sch Management, Casablanca, Morocco.	slahmiri@esca.ma; boukadoum.mounir@uqam.ca					Amilon H, 2003, J FORECASTING, V22, P317, DOI 10.1002/for.867; Anders U, 1998, J FORECASTING, V17, P369, DOI 10.1002/(SICI)1099-131X(1998090)17:5/6<369::AID-FOR702>3.0.CO;2-S; Andersen T., 1998, J FINANC, V6, P457; Andersen TG, 1998, INT ECON REV, V39, P885, DOI 10.2307/2527343; Andersen TG, 2001, J FINANC ECON, V61, P43, DOI 10.1016/S0304-405X(01)00055-1; Awartani BMA, 2005, INT J FORECASTING, V21, P167, DOI [10.1016/j.ijforecast.2004.08.003, 10.1016/j.ijforecast.204.08.003]; Bildirici M, 2009, EXPERT SYST APPL, V36, P7355, DOI 10.1016/j.eswa.2008.09.051; BOLLERSLEV T, 1987, REV ECON STAT, V69, P542, DOI 10.2307/1925546; Box G.E.P., 1994, TIME SERIES ANAL FOR, V3rd; CHAN K, 1991, REV FINANC STUD, V4, P657, DOI 10.1093/rfs/4.4.657; Chong CW, 1999, J FORECASTING, V18, P333, DOI 10.1002/(SICI)1099-131X(199909)18:5<333::AID-FOR742>3.0.CO;2-K; ENGLE RF, 1982, ECONOMETRICA, V50, P987, DOI 10.2307/1912773; Evans T., 2007, APPL FINANCIAL EC, V17, P1421, DOI 10.1080/09603100601007149; Hajizadeh E, 2012, EXPERT SYST APPL, V39, P431, DOI 10.1016/j.eswa.2011.07.033; Haykin S., 2008, NEURAL NETWORKS LEAR, V3rd; Hyup R. Tae, 2007, EXPERT SYST APPL, V33, P916; Kristjanpoller W, 2014, EXPERT SYST APPL, V41, P2437, DOI 10.1016/j.eswa.2013.09.043; Lee YH, 2010, EXPERT SYST APPL, V37, P4737, DOI 10.1016/j.eswa.2009.11.044; Liu HC, 2010, EXPERT SYST APPL, V37, P4928, DOI 10.1016/j.eswa.2009.12.022; Lopez JA, 2001, J FORECASTING, V20, P87, DOI 10.1002/1099-131X(200103)20:2<87::AID-FOR782>3.0.CO;2-7; Loudon GF, 2000, J APPL ECONOM, V15, P117, DOI 10.1002/(SICI)1099-1255(200003/04)15:2<117::AID-JAE550>3.0.CO;2-4; Marcucci J., 2005, STUDIES NONLINEAR DY, V9, P1; NELSON DB, 1991, ECONOMETRICA, V59, P347, DOI 10.2307/2938260; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0	25	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-4775	1793-6780		FLUCT NOISE LETT	Fluct. Noise Lett.	MAR	2015	14	1							1550001	10.1142/S0219477515500017		10	Mathematics, Interdisciplinary Applications; Physics, Applied	Mathematics; Physics	AX4NE	WOS:000346908300001		
J	Maithani, S				Maithani, Sandeep			Neural networks-based simulation of land cover scenarios in Doon valley, India	GEOCARTO INTERNATIONAL			English	Article						land cover; artificial neural networks; simulation	CELLULAR-AUTOMATA; URBAN-DEVELOPMENT; MODEL; CLASSIFICATION; SUITABILITY; CALIBRATION; HIMALAYAS; ACCURACY; ZONATION; REGION	Land cover transformation is one of the foremost aspects of human-induced environmental change, having an extensive history dating back to antiquity. The present study aims to simulate the process of land cover change based on different policy-based scenarios so as to provide a basis for sustainable development in Doon valley, India. For this purpose, an artificial neural network-based spatial predictive model was developed for the Doon valley. The predictive model generated future land cover patterns under three policy scenarios, i.e. baseline scenario, compact growth scenario and hierarchical growth scenario (HGS). The simulated land cover patterns mirror where land cover patterns are headed in the valley by year 2021. The result suggests that unabated continuation of the present pattern of land cover transformation will result in a regional imbalance. However, this skewed development can be corrected by altering the current growth trend as revealed in the compact growth and HGSs.	Indian Inst Remote Sensing, Urban & Reg Studies Dept, Dehra Dun, Uttar Pradesh, India	Maithani, S (reprint author), Indian Inst Remote Sensing, Urban & Reg Studies Dept, Dehra Dun, Uttar Pradesh, India.	maithani@iirs.gov.in					Alberti M, 1999, ENVIRON PLANN B, V26, P605, DOI 10.1068/b260605; Almeida C. M. de, 2003, COMPUTERS ENV URBAN, V27, P481; Anderson J. R, 1976, 964 USGS; Arora MK, 2004, INT J REMOTE SENS, V25, P559, DOI 10.1080/0143116031000156819; Arora MK, 1998, ASIAN PACIFIC REMOTE, V10, P11; Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700; Barredo JI, 2003, LANDSCAPE URBAN PLAN, V64, P145, DOI 10.1016/S0169-2046(02)00218-9; Barredo JI, 2004, ENVIRON PLANN B, V31, P65, DOI 10.1068/b29103; Batty M, 2000, GEOCOMPUTATION, P95; Batty M., 2001, INT J APPL EARTH OBS, V3, P252, DOI 10.1016/S0303-2434(01)85032-7; Cabral P, 2006, P 1 WORKSH EARSEL SP, P119; CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B; Congalton RG, 1999, ASSESSING ACCURACY R, P160; Couclelis H., 2002, GEOGRAPHIC INFORM SY, P36; Dietzel C., 2007, Transactions in GIS, V11, P29, DOI 10.1111/j.1467-9671.2007.01031.x; Foody GM, 1997, INT J REMOTE SENS, V18, P799, DOI 10.1080/014311697218764; Gregorio D, 2005, UN LAND COVER CLASSI; Hansen HS, 2010, LANDSCAPE URBAN PLAN, V98, P141, DOI 10.1016/j.landurbplan.2010.08.018; Haykin S., 1999, NEURAL NETWORKS COMP; Hecht-Nielson R, 1987, P IEEE 1 ANN INT C N, V3, P11; Hush D.R., 1989, P IEEE INT C SYST EN, P277; Jacob N., 2006, INT J GEOINF, V2, P31; Kanellopoulos I, 1997, INT J REMOTE SENS, V18, P711, DOI 10.1080/014311697218719; Kanungo DP, 2006, ENG GEOL, V85, P347, DOI 10.1016/j.enggeo.2006.03.004; Kavzoglu T, 2003, INT J REMOTE SENS, V24, P4097; Kumar S., 2004, NEURAL NETWORKS CLAS; Li X, 2001, ENVIRON PLANN A, V33, P1445, DOI 10.1068/a33210; Li X, 2002, INT J GEOGR INF SCI, V16, P323, DOI 10.1080/13658810210137004; Li X, 2006, INT J GEOGR INF SCI, V20, P1109, DOI 10.1080/13658810600816870; Lipschutz S, 1981, THEORY PROBLEMS PROB, P126; Maithani S, 2009, J INDIAN SOC REMOT, V37, P363; Maithani S, 2010, GEOCARTO INT, V25, P663, DOI 10.1080/10106049.2010.524313; Mather P., 1999, COMPUTER PROCESSING; Overmars KP, 2007, LAND USE POLICY, V24, P584, DOI 10.1016/j.landusepol.2005.09.008; Pijanowski B. C., 2002, Computers, Environment and Urban Systems, V26, DOI 10.1016/S0198-9715(01)00015-1; Pijanowski BC, 2002, LAKES RESERVOIRS RES, V7, P189; Pijanowski BC, 2005, INT J GEOGR INF SCI, V19, P197, DOI 10.1080/13658810410001713416; Ramachandran R., 1991, URBANIZATION URBAN S; Reginster I, 2006, ENVIRON PLANN B, V33, P619, DOI 10.1068/b31079; Ripley BD, 1993, NETWORKS CHAOS STAT, P40, DOI 10.1007/978-1-4899-3099-6; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shortridge A, 2007, COMPUT ENVIRON URBAN, V31, P362, DOI 10.1016/j.compenvurbsys.2006.07.001; Silva E. A., 2002, Computers, Environment and Urban Systems, V26, DOI 10.1016/S0198-9715(01)00014-X; Sivanandam S. N., 2006, INTRO NEURAL NETWORK; Soares-Filho BS, 2009, MODELING ENV DYNAMIC; Thapa RB, 2011, COMPUT ENVIRON URBAN, V35, P25, DOI 10.1016/j.compenvurbsys.2010.07.005; Thapa RB, 2010, APPL GEOGR, V30, P70, DOI 10.1016/j.apgeog.2009.10.002; Thapa R.B., 2012, LANDSCAPE URBAN PLAN, V105, P141; Verburg PH, 2006, APPL GEOGR, V26, P153, DOI 10.1016/j.apgeog.2005.11.005; WANG F, 1994, ENVIRON PLANN A, V26, P265, DOI 10.1068/a260265; Wolff SB, 2004, ECOL RES, V19, P119, DOI [10.1111/ere.2004.19.issue-1, DOI 10.1111/ERE.2004.19.ISSUE-1]; Wu FL, 2002, INT J GEOGR INF SCI, V16, P795, DOI 10.1080/13658810210157769	52	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1010-6049	1752-0762		GEOCARTO INT	Geocarto Int.	FEB 7	2015	30	2					163	185		10.1080/10106049.2014.927535		23	Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology	AW9MJ	WOS:000346581300005		
J	Yang, J; Mei, XS; Zhao, L; Ma, C; Shi, H; Feng, B				Yang, Jun; Mei, Xuesong; Zhao, Liang; Ma, Chi; Shi, Hu; Feng, Bin			Thermal error compensation on a computer numerical control machine tool considering thermal tilt angles and cutting tool length	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART B-JOURNAL OF ENGINEERING MANUFACTURE			English	Article						Machine tool compensation; five-point method; thermal tilt angle; cutting tool length; thermal error modelling	SPINDLE; MODEL; SYSTEM	The present error compensation technology of computer numerical control machine tools ignores radial thermal tilt angle errors of the spindle, while the thermal-induced offset is closely related to the tilt angle and the handle length. To solve this problem, three models of spindle thermal errors are proposed for the thermal yaw, pitch angles and elongation, and error compensation is performed based on the thermal tilt angles and cutting tool length. A five-point method was applied to measure the spindle thermal drifts at different speeds by eddy current sensors, which could effectively analyse the changes in the position-pose of the errors. Fuzzy clustering and correlation analysis were applied to group and optimise the temperature variables and select the variables sensitive to thermal errors in order to depress the multicollinearity of the temperature variables and improve the stability of the model. Finally, the thermal offset compensation was conducted in three directions. The results indicate that back propagation has a better capability for nonlinear fitting, but its generalisation is far less than that of time series. While the structure of multiple linear regression analysis is simple, its prediction accuracy is not satisfied. Time series adequately reflects the dynamic behaviours of the thermal error, and the prediction accuracy can reach 94%, with excellent robustness under different cutting conditions. The thermal error compensation equation that includes thermal tilt angles and cutting tool length is suitable for actual conditions and can accurately describe the space-pose of the thermal deformation and improve the machining accuracy.	[Yang, Jun; Mei, Xuesong; Zhao, Liang; Ma, Chi; Shi, Hu; Feng, Bin] Xi An Jiao Tong Univ, State Key Lab Mfg Syst Engn, Xian 710049, Peoples R China	Yang, J (reprint author), Xi An Jiao Tong Univ, State Key Lab Mfg Syst Engn, Xian 710049, Peoples R China.	softyj@163.com			National High-Tech R&D Program of China (863 Program) [2012AA040701]	This research was supported by the National High-Tech R&D Program of China (863 Program) under Grant Number 2012AA040701.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; [Anonymous], 23032007 ISO, P20; Box GEP, 2011, TIME SERIES ANAL FOR; Bryan J., 1990, CIRP ANN-MANUF TECHN, V39, P645, DOI 10.1016/S0007-8506(07)63001-7; Donmez MA, 2007, CIRP ANN-MANUF TECHN, V56, P521, DOI 10.1016/j.cirp.2007.05.124; Frohlich T, 2003, STABILITY PT100 THIN, P325; Fu YQ, 2014, ADV MATER RES-SWITZ, V889-890, P1003, DOI 10.4028/www.scientific.net/AMR.889-890.1003; Galimberti G, 2014, COMPUT STAT DATA AN, V71, P138, DOI 10.1016/j.csda.2013.01.017; Creighton E, 2010, INT J MACH TOOL MANU, V50, P386, DOI 10.1016/j.ijmachtools.2009.11.002; Hong C., 2012, INT J AUTOMATION TEC, V6-2, P196; Jenq SC, 2003, INT J MACH TOOL MANU, V43, P1163; Jerance N, 2013, SENSORS-BASEL, V13, P5205, DOI 10.3390/s130405205; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; Lee JH, 2002, INT J MACH TOOL MANU, V42, P147, DOI 10.1016/S0890-6955(01)00110-9; Li Y, 2012, IEEE INT C MECH AUT, P2319; Miao EM, 2011, INT SOC OPT ENG 4 IN, V7997; Miao EM, 2013, INT J ADV MANUF TECH, V69, P2593, DOI 10.1007/s00170-013-5229-x; Min X, 2011, P I MECH ENG C-J MEC, V225, P186, DOI 10.1177/09544062JMES2148; Mou J, 1997, J MANUF SCI E-T ASME, V119, P247, DOI 10.1115/1.2831101; Ouafi AE, 2013, ADV MAT RES ENV MAT, V664, P907; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; Vissiere A, 2012, MEAS SCI TECHNOL, V23, DOI 10.1088/0957-0233/23/9/094015; Vyroubal J, 2012, PRECIS ENG, V36, P121, DOI 10.1016/j.precisioneng.2011.07.013; Wang H, 2011, 2011 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD), P716; Wang W, 2013, ADV MAT RES, V820, P147; Yang S, 1996, INT J MACH TOOL MANU, V36, P527, DOI 10.1016/0890-6955(95)00040-2; Zhang Y, 2013, P I MECH ENG C-J MEC, V227, P246, DOI 10.1177/0954406212447521; Zhang Y, 2013, P I MECH ENG C-J MEC, V227, P1102, DOI 10.1177/0954406212456475; Zhao HT, 2007, INT J MACH TOOL MANU, V47, P1003, DOI 10.1016/j.ijmachtools.2006.06.018	30	0	0	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0954-4054	2041-2975		P I MECH ENG B-J ENG	Proc. Inst. Mech. Eng. Part B-J. Eng. Manuf.	FEB	2015	229			1			78	97		10.1177/0954405414556499		20	Engineering, Manufacturing; Engineering, Mechanical	Engineering	CF5EO	WOS:000352579400006		
J	Jajac, N; Marovic, I; Hanak, T				Jajac, Niksa; Marovic, Ivan; Hanak, Tomas			Decision support for management of urban transport projects	GRADEVINAR			English	Article						strategic planning; project management; support to decision-making; multicriteria methods; neural networks	SYSTEM	The planning phase within the urban-transport project management is a complex process from both the management and techno-economic aspects. The focus of this research is on decision-making processes related to the planning phase during management of urbanroad infrastructure projects. The proposed concept is based on multicriteria methods and Artificial Neural Networks. The decision-support concept presented in this paper is tested on the road infrastructure of the city of Split, and it shows how urban road infrastructure planning can be improved.	[Jajac, Niksa] Univ Split, Fac Civil Engn Architecture & Geodesy, Split, Croatia; [Marovic, Ivan] Univ Rijeka, Fac Civil Engn, Rijeka, Croatia; [Hanak, Tomas] Brno Univ Technol, Fac Civil Engn, CS-61090 Brno, Czech Republic	Jajac, N (reprint author), Univ Split, Fac Civil Engn Architecture & Geodesy, Split, Croatia.	niksa.jajac@gradst.hr; ivan.marovic@gradri.uniri.hr; hanak.t@fce.vutbr.cz					Aghdaie MH, 2012, BALT J ROAD BRIDGE E, V7, P145, DOI 10.3846/bjrbe.2012.20; [Anonymous], 2011, POP STAN KUC STAN 20; BIELLI M, 1992, EUR J OPER RES, V61, P106, DOI 10.1016/0377-2217(92)90272-B; Coutinho-Rodrigues J., 2011, DECISION SUPPORT SYS, V51, P720; Deluka-Tibljas A, 2013, GRADEVINAR, V65, P619; Frooman J, 1999, ACAD MANAGE REV, V24, P191; Guisseppi A., 2002, INFORM SCI, V144, P75; Hanak T., 2014, INT J ENG MODELLING, V27, P61; Hwang C. L., 1981, MULTIPLE ATTRIBUTE D; Jajac Niksa, 2009, Organization, Technology and Management in Construction: An International Journal, V1; Jajac N., 2010, THESIS EKONOMSKI FAK; Jajac N., P 8 INT C ORG TECHN; Leclerc G., 2001, WORLD MULT SYST CYB, VXVIII, P143; Marovic I., 2013, THESIS GRADEVINSKI F; Mitchell RK, 1997, ACAD MANAGE REV, V22, P853, DOI 10.2307/259247; Parker D.B, 1985, TR47 MIT CTR COMP RE; Parker D.B, 1987, P IEEE INT C NEUR NE, P593; Pomerol J., 1996, J DECISION SYSTEMS, V5, P249; Quintero A, 2005, EUR J OPER RES, V162, P654, DOI 10.1016/j.ejor.2003.10.019; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saaty T.L., 1982, DECISION MAKING LEAD; Sayers T. M., 2003, TRANSPORT POLICY, V10, P95, DOI 10.1016/S0967-070X(02)00049-5; Shelton J, 2010, TRANSP RES RECORD, P51, DOI 10.3141/2174-08; Sprague R. H., 1982, BUILDING EFFECTIVE D; Turban E., 1995, DECISION SUPPORT SYS; Turban E., 1993, DECISION SUPPORT EXP; Vajjhala SP, 2010, J MAPS, P488, DOI 10.4113/jom.2010.1086; Werbos P. J., 1974, THESIS HARVARD U; Yedla S, 2003, TRANSPORT RES A-POL, V37, P717, DOI 10.1016/S0965-8564(03)00027-2	29	0	0	CROATIAN SOC CIVIL ENGINEERS-HSGI	ZAGREB	BERISLAVICEVA 6, ZAGREB, 00000, CROATIA	0350-2465	1333-9095		GRADEVINAR	Gradev.	FEB	2015	67	2					131	141				11	Engineering, Civil	Engineering	CE1JO	WOS:000351568100003		
J	Gazzaz, NM; Yusoff, MK; Ramli, MF; Juahir, H; Aris, AZ				Gazzaz, Nabeel M.; Yusoff, Mohd Kamil; Ramli, Mohammad Firuz; Juahir, Hafizan; Aris, Ahmad Zaharin			Artificial Neural Network Modeling of the Water Quality Index Using Land Use Areas as Predictors	WATER ENVIRONMENT RESEARCH			English	Article						artificial neural network; function approximation; three-layer perceptron; land use areas; water quality index; weighted arithmetic mean; unweighted harmonic square mean	RESOURCES APPLICATIONS; CLASSIFICATION SCHEME; INPUT DETERMINATION; CROSS-VALIDATION; RIVER; SELECTION; COVER; URBAN; ALGORITHMS; ECOSYSTEMS	This paper describes the design of an artificial neural network (ANN) model to predict the water quality index (WQI) using land use areas as predictors. Ten-year records of land use statistics and water quality data for Kinta River (Malaysia) were employed in the modeling process. The most accurate WQI predictions were obtained with the network architecture 7-23-1; the back propagation training algorithm; and a learning rate of 0.02. The WQI forecasts of this model had significant (p < 0.01), positive, very high correlation (rho(S) = 0.882) with the measured WQI values. Sensitivity analysis revealed that the relative importance of the land use classes to WQI predictions followed the order: mining > rubber > forest > logging > urban areas > agriculture > oil palm. These findings show that the ANNs are highly reliable means of relating water quality to land use, thus integrating land use development with river water quality management.	[Gazzaz, Nabeel M.; Yusoff, Mohd Kamil; Ramli, Mohammad Firuz] Univ Putra Malaysia, Dept Environm Sci, Fac Environm Studies, Serdang 43400, Selangur Darul, Malaysia; [Juahir, Hafizan; Aris, Ahmad Zaharin] Univ Putra Malaysia, Ctr Excellence Environm Forens, Fac Environm Studies, Upm Serdang 43400, Selangur Darul, Malaysia	Gazzaz, NM (reprint author), Univ Putra Malaysia, Dept Environm Sci, Fac Environm Studies, Serdang 43400, Selangur Darul, Malaysia.	NabeelMGazzaz@Yahoo.com					Abrahao R, 2007, WATER SA, V33, P459; Abrahart RJ, 2000, HYDROL PROCESS, V14, P2157, DOI 10.1002/1099-1085(20000815/30)14:11/12<2157::AID-HYP57>3.0.CO;2-S; Akintola K. G., 2011, INT J RES REV APPL S, V9, P468; Amiri BJ, 2009, POL J ENVIRON STUD, V18, P151; Bowden G. J., 2003, J HYDROINFORM, V5, P245; Bowden GJ, 2005, J HYDROL, V301, P93, DOI 10.1016/j.jhydrol.2004.06.020; Bowden GJ, 2005, J HYDROL, V301, P75, DOI 10.1016/j.jhydrol.2004.06.021; Boyacioglu H, 2007, WATER SA, V33, P101; Bruzzone L, 2004, PATTERN RECOGN LETT, V25, P1491, DOI 10.1016/j.patrec.2004.06.002; Corsini G, 2003, INT J REMOTE SENS, V24, P3917, DOI 10.1080/0143116031000103781; Coulter CB, 2004, J AM WATER RESOUR AS, V40, P1593, DOI 10.1111/j.1752-1688.2004.tb01608.x; Cude CG, 2001, J AM WATER RESOUR AS, V37, P125, DOI 10.1111/j.1752-1688.2001.tb05480.x; Cude CG, 2005, J AM WATER RESOUR AS, V41, P47, DOI 10.1111/j.1752-1688.2005.tb03716.x; Dawson CW, 2001, PROG PHYS GEOG, V25, P80, DOI 10.1191/030913301674775671; Department of Environment (DoE), 2005, MAL ENV QUAL REP 200; DOJLIDO J, 1994, ENVIRON MONIT ASSESS, V33, P33, DOI 10.1007/BF00546659; EISENSTEIN E, 1993, EUROPHYS LETT, V21, P501, DOI 10.1209/0295-5075/21/4/020; Fahlman S. E., 1988, EMPIRICAL STUDY LEAR; Fernandez N., 2004, BISTUA REV FACULTAD, V2, P19; Fischer M. M., 2006, T GIS, V10, P521, DOI 10.1111/j.1467-9671.2006.01010.x; Fisher DS, 2000, FOREST ECOL MANAG, V128, P39, DOI 10.1016/S0378-1127(99)00270-4; FLAVELLE P, 1992, ADV WATER RESOUR, V15, P5, DOI 10.1016/0309-1708(92)90028-Z; Gazzaz NM, 2012, MAR POLLUT BULL, V64, P688, DOI 10.1016/j.marpolbul.2012.01.032; Gazzaz NM, 2012, MAR POLLUT BULL, V64, P2409, DOI 10.1016/j.marpolbul.2012.08.005; Ghani A.A., 2007, INT J RIVER BASIN MA, V5, P329; Govindaraju RS, 2000, J HYDROL ENG, V5, P115; Ha HJ, 2003, WATER RES, V37, P4222, DOI 10.1016/S0043-1354(03)00344-0; Hanh P. T. M., 2011, J ENV ENG, V137, P273; HILL T, 1994, INT J FORECASTING, V10, P5, DOI 10.1016/0169-2070(94)90045-0; HUNSAKER CT, 1995, BIOSCIENCE, V45, P193, DOI 10.2307/1312558; Johnson LB, 1997, FRESHWATER BIOL, V37, P193, DOI 10.1046/j.1365-2427.1997.d01-539.x; Kaurish FW, 2007, J AM WATER RESOUR AS, V43, P533, DOI 10.1111/j.1752-1688.2007.00042.x; Khalil B, 2011, J HYDROL, V405, P277, DOI 10.1016/j.jhydrol.2011.05.024; Khuan L. Y., 2002, P 2002 STUD C RES DE, P157; Kovalishyn VV, 1998, J CHEM INF COMP SCI, V38, P651, DOI 10.1021/ci980325n; Leahy P, 2008, J HYDROL, V355, P192, DOI 10.1016/j.jhydrol.2008.03.017; Lek S, 1999, WATER RES, V33, P3469, DOI 10.1016/S0043-1354(99)00061-5; Liao KP, 2005, COMPUT OPER RES, V32, P2151, DOI 10.1016/j.cor.2004.02.006; Liou SM, 2004, ENVIRON MONIT ASSESS, V96, P35, DOI 10.1023/B:EMAS.0000031715.83752.a1; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154; May DB, 2009, ENVIRON MODELL SOFTW, V24, P296, DOI 10.1016/j.envsoft.2008.07.004; Norhayati M. T., 1997, J ENSEARCH, V10, P27; Olszewski T., 2008, Journal of Research and Applications in Agricultural Engineering, V53, P26; Ozesmi SL, 2006, ECOL MODEL, V195, P83; Palani S, 2008, MAR POLLUT BULL, V56, P1586, DOI 10.1016/j.marpolbul.2008.05.021; Pastor-Barcenasa O, 2005, ECOL MODEL, V182, P149, DOI 10.1016/j.ecolmodel.2004.07.015; Pesce SF, 2000, WATER RES, V34, P2915, DOI 10.1016/S0043-1354(00)00036-1; Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0; Qi M, 2001, EUR J OPER RES, V132, P666, DOI 10.1016/S0377-2217(00)00171-5; Riad S, 2004, MATH COMPUT MODEL, V40, P839, DOI 10.1016/j.mcm.2004.10.012; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sanchez E, 2007, ECOL INDIC, V7, P315, DOI 10.1016/j.ecolind.2006.02.005; Sargaonkar A, 2003, ENVIRON MONIT ASSESS, V89, P43, DOI 10.1023/A:1025886025137; Schindler DW, 1997, HYDROL PROCESS, V11, P1043, DOI 10.1002/(SICI)1099-1085(19970630)11:8<1043::AID-HYP517>3.0.CO;2-5; Schindler DW, 2001, CAN J FISH AQUAT SCI, V58, P18, DOI 10.1139/cjfas-58-1-18; Seitz NE, 2011, ENVIRON IMPACT ASSES, V31, P172, DOI 10.1016/j.eiar.2010.08.001; Serpico SB, 1996, PATTERN RECOGN LETT, V17, P1331, DOI 10.1016/S0167-8655(96)00090-6; Shaker R, 2010, J ENVIRON PROT ECOL, V11, P337; Shamseldin AY, 2002, HYDROL EARTH SYST SC, V6, P671; Singh KP, 2009, ECOL MODEL, V220, P888, DOI 10.1016/j.ecolmodel.2009.01.004; Song T, 2009, J ENVIRON MANAGE, V90, P1534, DOI 10.1016/j.jenvman.2008.11.008; Teschl R, 2006, NAT HAZARD EARTH SYS, V6, P629; Tiron G, 2010, ROM REP PHYS, V62, P405; Tong STY, 2002, J ENVIRON MANAGE, V66, P377, DOI 10.1006/jema.2002.0593; TOURBIER JT, 1994, J SOIL WATER CONSERV, V49, P14; TURNEY P, 1994, J EXP THEOR ARTIF IN, V6, P361, DOI 10.1080/09528139408953794; Twomey JM, 1998, IEEE T SYST MAN CY C, V28, P417, DOI 10.1109/5326.704579; Wilamowski B. M., 2003, P IEEE INT C IND TEC; Wu CL, 2011, J HYDROL, V399, P394, DOI 10.1016/j.jhydrol.2011.01.017; Yu XH, 2002, IEEE T NEURAL NETWOR, V13, P251, DOI 10.1109/72.977323; Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7	72	0	0	WATER ENVIRONMENT FEDERATION	ALEXANDRIA	601 WYTHE ST, ALEXANDRIA, VA 22314-1994 USA	1061-4303	1554-7531		WATER ENVIRON RES	Water Environ. Res.	FEB	2015	87	2					99	112		10.2175/106143014X14062131179276		14	Engineering, Environmental; Environmental Sciences; Limnology; Water Resources	Engineering; Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	CD1YH	WOS:000350870100001	25790513	
J	Ma, JS; Sheridan, RP; Liaw, A; Dahl, GE; Svetnik, V				Ma, Junshui; Sheridan, Robert P.; Liaw, Andy; Dahl, George E.; Svetnik, Vladimir			Deep Neural Nets as a Method for Quantitative Structure-Activity Relationships	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							COMPOUND CLASSIFICATION; RANDOM FOREST; NETWORKS; CLASSIFIERS; TOOL	Neural networks were widely used for quantitative structure-activity relationships (QSAR) in the 1990s. Because of various practical issues (e.g., slow on large problems, difficult to train, prone to overfitting, etc.), they were superseded by more robust methods like support vector machine (SVM) and random forest (RF), which arose in the early 2000s. The last 10 years has witnessed a revival of neural networks in the machine learning community thanks to new methods for preventing overfitting, more efficient training algorithms, and advancements in computer hardware. In particular, deep neural nets (DNNs), i.e. neural nets with more than one hidden layer, have found great successes in many applications, such as computer vision and natural language processing. Here we show that DNNs can routinely make better prospective predictions than RF on a set of large diverse QSAR data sets that are taken from Mercks drug discovery effort. The number of adjustable parameters needed for DNNs is fairly large, but our results show that it is not necessary to optimize them for individual data sets, and a single set of recommended parameters can achieve better performance than RF for most of the data sets we studied. The usefulness of the parameters is demonstrated on additional data sets not used in the calibration. Although training DNNs is still computationally intensive, using graphical processing units (GPUs) can make this issue manageable.	[Ma, Junshui; Liaw, Andy; Svetnik, Vladimir] Merck Res Labs, Biometr Res Dept, Rahway, NJ 07065 USA; [Sheridan, Robert P.] Merck Res Labs, Dept Struct Chem, Rahway, NJ 07065 USA; [Dahl, George E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S, Canada	Ma, JS (reprint author), Merck Res Labs, Biometr Res Dept, Rahway, NJ 07065 USA.	junshui_ma@merck.com					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bruce CL, 2007, J CHEM INF MODEL, V47, P219, DOI [10.1021/ci600332j, 10.1021/ci600322j]; Burden FR, 2001, J CHEM INF COMP SCI, V41, P830, DOI 10.1021/ci000459c; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Chen B, 2012, J CHEM INF MODEL, V52, P792, DOI 10.1021/ci200615h; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dahl G.E., 2014, MULTITASK NEURAL NET; Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kearsley SK, 1996, J CHEM INF COMP SCI, V36, P118, DOI 10.1021/ci950274j; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Mnih V., 2009, TR2009004 UTML; Nair V., 2010, P 27 INT C MACH LEAR, P807; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sheridan RP, 2013, J CHEM INF MODEL, V53, P783, DOI 10.1021/ci400084k; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tieleman T., 2010, TR2010002 UTML; Wager S., 2013, ADV NEURAL INFORM PR, P351	21	0	0	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	FEB	2015	55	2					263	274		10.1021/ci5000747n		12	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	CB9HR	WOS:000349943100007	25635324	
J	Deng, CW; Huang, GB; Xu, J; Tang, JX				Deng ChenWei; Huang GuangBin; Xu Jia; Tang JieXiong			Extreme learning machines: new trends and applications	SCIENCE CHINA-INFORMATION SCIENCES			English	Review						extreme learning machine; fast learning; high-speed and real-time signal processing; large-scale computing; big-data; feature representation	IMAGE QUALITY ASSESSMENT; NONNEGATIVE MATRIX FACTORIZATION; FEEDFORWARD NETWORKS; NEURAL-NETWORKS; ALGORITHM; APPROXIMATION; CLASSIFICATION; REGRESSION; FEATURES	Extreme learning machine (ELM), as a new learning framework, draws increasing attractions in the areas of large-scale computing, high-speed signal processing, artificial intelligence, and so on. ELM aims to break the barriers between the conventional artificial learning techniques and biological learning mechanism and represents a suite of machine learning techniques in which hidden neurons need not to be tuned. ELM theories and algorithms argue that "random hidden neurons" capture the essence of some brain learning mechanisms as well as the intuitive sense that the efficiency of brain learning need not rely on computing power of neurons. Thus, compared with traditional neural networks and support vector machine, ELM offers significant advantages such as fast learning speed, ease of implementation, and minimal human intervention. Due to its remarkable generalization performance and implementation efficiency, ELM has been applied in various applications. In this paper, we first provide an overview of newly derived ELM theories and approaches. On the other hand, with the ongoing development of multilayer feature representation, some new trends on ELM-based hierarchical learning are discussed. Moreover, we also present several interesting ELM applications to showcase the practical advances on this subject.	[Deng ChenWei; Xu Jia; Tang JieXiong] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China; [Huang GuangBin] Nanyang Technol Univ, Sch Elect Engn, Singapore 639798, Singapore	Huang, GB (reprint author), Nanyang Technol Univ, Sch Elect Engn, Singapore 639798, Singapore.	egbhuang@ntu.edu.sg			National Natural Science Foundation of China [61301090]	This work was supported by National Natural Science Foundation of China (Grant No. 61301090).	An L, 2012, IEEE IMAGE PROC, P2209; Anderson Jr W.N., 1985, LINEAR MULTILINEAR A, V18, P141, DOI 10.1080/03081088508817681; Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bi F, 2010, ADV NEURAL NETWORK R, P729; Bouzerdoum A, 2004, Proceedings of the Fourth IEEE International Symposium on Signal Processing and Information Technology, P330, DOI 10.1109/ISSPIT.2004.1433751; Buffalo EA, 2010, P NATL ACAD SCI USA, V107, P361, DOI 10.1073/pnas.0907658106; Carrai P, 2002, P IEEE INT S CIRC SY; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Decherchi S, 2013, NEUROCOMPUTING, V102, P78, DOI 10.1016/j.neucom.2011.12.050; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hassoun M H, 1995, FUNDAMENTALS ARTIFIC, P35; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOERL AE, 1970, TECHNOMETRICS, V12, P55; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Huang G, 2014, IEEE T SY B IN PRESS; Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977; Huang GB, 2004, IEEE IJCNN, P985; Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009; Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Huang GB, 2008, NEUROCOMPUTING, V71, P3460, DOI 10.1016/j.neucom.2007.10.008; Kasun LLC, 2013, IEEE INTELL SYST, V28, P31; Lee DD, 2001, ADV NEUR IN, V13, P556; Lee DD, 1999, NATURE, V401, P788; Li K, 2005, IEEE T AUTOMAT CONTR, V50, P1211, DOI 10.1109/TAC.2005.852557; Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382; Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583; Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935; Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343; Minhas R, 2010, NEUROCOMPUTING, V73, P1906, DOI 10.1016/j.neucom.2010.01.020; MOTTER BC, 1993, J NEUROPHYSIOL, V70, P909; Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391; Narwaria M, 2012, PATTERN RECOGN, V45, P299, DOI 10.1016/j.patcog.2011.06.023; Rong HJ, 2009, IEEE T SYST MAN CY B, V39, P1067, DOI 10.1109/TSMCB.2008.2010506; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Suresh S, 2009, APPL SOFT COMPUT, V9, P541, DOI 10.1016/j.asoc.2008.07.005; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; TANABE K, 1971, NUMER MATH, V17, P203, DOI 10.1007/BF01436376; Tang J, 2014, P IEEE INT IN PRESS; Tang J, 2014, IEEE T NEUR IN PRESS; Tang J, 2014, IEEE T GEOS IN PRESS; van Gestel T, 2002, LEAST SQUARES SUPPOR; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Wang S, 2013, P IEEE CHIN SUMM INT, P255; Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; White H, 1992, ARTIFICIAL NEURAL NE, P30; Wilamowski BM, 2010, IEEE T NEURAL NETWOR, V21, P1793, DOI 10.1109/TNN.2010.2073482; Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048; Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864; Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730; Zhu CR, 2010, IEEE T GEOSCI REMOTE, V48, P3446, DOI 10.1109/TGRS.2010.2046330; Zhu JY, 2012, IEEE T IMAGE PROCESS, V21, P919, DOI 10.1109/TIP.2011.2169971	60	0	0	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1674-733X	1869-1919		SCI CHINA INFORM SCI	Sci. China-Inf. Sci.	FEB	2015	58	2							020301	10.1007/s11432-014-5269-3		16	Computer Science, Information Systems	Computer Science	CC7FV	WOS:000350534000001		
J	Jin, L; Zhu, JS; Huang, Y; Zhao, HS; Lin, KP; Jin, J				Jin, Long; Zhu, Jieshun; Huang, Ying; Zhao, Hua-sheng; Lin, Kai-ping; Jin, Jian			A nonlinear statistical ensemble model for short-range rainfall prediction	THEORETICAL AND APPLIED CLIMATOLOGY			English	Article							NEURAL-NETWORK APPROACH; REGIONAL-SCALE; PRECIPITATION; SYSTEM; FORECAST; PATTERNS	Following the practice of the numerical weather ensemble prediction, a nonlinear statistical ensemble prediction model has been developed based on a neural network technique with a Particle Swarm Optimization (PSO) algorithm. The model is validated by short-range climate forecasts of monthly mean rainfall at 37 stations in Guangxi, China during the first rainy season (April, May, and June). Independent prediction results show that the Particle Swarm Optimization Neural Network ensemble prediction model is clearly better than the traditional linear statistical method, such as the multiple regression method and the stepwise regression method. It is also suggested that by applying multiple ensemble members with each member objectively determined by the PSO algorithm, the generalization capacity of the ensemble prediction model is enhanced, demonstrating a vast range of possibilities for operational short-range climate prediction.	[Jin, Long] Guangxi Climate Ctr, Nanning, Peoples R China; [Zhu, Jieshun] Ctr Ocean Land Atmosphere Studies, Calverton, MD USA; [Huang, Ying; Zhao, Hua-sheng; Lin, Kai-ping] Guangxi Res Inst Meteorol Disasters Mitigat, Nanning, Peoples R China; [Jin, Jian] E China Normal Univ, Dept Comp Sci & Technol, Shanghai 200062, Peoples R China	Jin, L (reprint author), Guangxi Climate Ctr, Nanning, Peoples R China.	jinlong01@163.com			National Natural Science Foundation of China [41065002, 61203301]; Major Program of Natural Science Foundation of Guangxi [2011GXNSFE018006]	This work was supported by the National Natural Science Foundation of China (Grant 41065002 and 61203301) and the Major Program of Natural Science Foundation of Guangxi (Grant 2011GXNSFE018006).	Cannon AJ, 2002, J HYDROL, V259, P136, DOI 10.1016/S0022-1694(01)00581-9; Chadwick R, 2012, J HYDROMETEOROL, V13, P913, DOI 10.1175/JHM-D-11-081.1; Cui C, 2010, ARTIF LIFE ROBOTICS, V15, P58; de Oliveira MMF, 2009, J APPL METEOROL CLIM, V48, P143, DOI 10.1175/2008JAMC1907.1; Gerhard V, 2003, AIAA J, V41, P1583; GRAY BM, 1981, J CLIMATOL, V1, P273; Hsieh WW, 2001, J CLIMATE, V14, P2528, DOI 10.1175/1520-0442(2001)014<2528:NCCAOT>2.0.CO;2; Jin L, 2008, MON WEATHER REV, V136, P4541, DOI 10.1175/2008MWR2269.1; Khan MS, 2010, J HYDROMETEOROL, V11, P482, DOI 10.1175/2009JHM1160.1; Kim G, 2001, J HYDROL, V246, P45, DOI 10.1016/S0022-1694(01)00353-5; Lund IA, 1971, J APPL METEOROL, V10, P892, DOI DOI 10.1175/1520-0450(1971)010<0892:AAOSAS>2.0.CO;2; Mu Y, 2010, INT J ADV MANUF TECH, V50, P517, DOI 10.1007/s00170-010-2556-z; Muhlbauer A, 2009, J APPL METEOROL CLIM, V48, P1961, DOI 10.1175/2009JAMC1851.1; Nohara D, 2004, J METEOROL SOC JPN, V82, P167, DOI 10.2151/jmsj.82.167; Palmer TN, 2004, B AM METEOROL SOC, V85, P853, DOI 10.1175/BAMS-85-6-853; Pasini A, 2010, WATER-SUI, V2, P321, DOI 10.3390/w2030321; Pasini A, 2012, J CLIMATE, V25, P2123, DOI 10.1175/JCLI-D-11-00551.1; Poli Riccardo, 2007, Swarm Intelligence, V1, DOI 10.1007/s11721-007-0002-0; Ramirez-Beltran ND, 2007, MON WEATHER REV, V135, P877, DOI 10.1175/MWR3290.1; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saha S, 2006, J CLIMATE, V19, P3483, DOI 10.1175/JCLI3812.1; Santos-Garcia G, 2004, ARTIF INTELL MED, V30, P61, DOI 10.1016/S0933-3657(03)00059-9; Scherrer SC, 2004, WEATHER FORECAST, V19, P552, DOI 10.1175/1520-0434(2004)019<0552:AOTSRU>2.0.CO;2; Silverman D, 2000, J APPL METEOROL, V39, P57, DOI 10.1175/1520-0450(2000)039<0057:ANNALR>2.0.CO;2; Stensrud DJ, 2000, MON WEATHER REV, V128, P2077, DOI 10.1175/1520-0493(2000)128<2077:UICAMP>2.0.CO;2; Tangang FT, 1997, CLIM DYNAM, V13, P135, DOI 10.1007/s003820050156; Wei CC, 2012, J HYDROMETEOROL, V13, P722, DOI 10.1175/JHM-D-11-03.1; Zhong X-K, 2012, ADV INTELL SOFT COMP, V112, P267; Zhou XQ, 2006, ADV ATMOS SCI, V23, P342, DOI 10.1007/s00376-006-0342-5; Zhu JS, 2012, GEOPHYS RES LETT, V39, DOI 10.1029/2012GL051503; Zhu JS, 2013, CLIM DYNAM, V41, P1941, DOI 10.1007/s00382-013-1785-x; Zhu JS, 2013, J CLIMATE, V26, P5689, DOI 10.1175/JCLI-D-13-00190.1; Zuo ZY, 2013, CLIM DYNAM, V40, P3071, DOI 10.1007/s00382-013-1772-2	33	0	0	SPRINGER WIEN	WIEN	SACHSENPLATZ 4-6, PO BOX 89, A-1201 WIEN, AUSTRIA	0177-798X	1434-4483		THEOR APPL CLIMATOL	Theor. Appl. Climatol.	FEB	2015	119	3-4					791	807		10.1007/s00704-014-1161-8		17	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	CA6KC	WOS:000349020900028		
J	Feng, GR; Lan, Y; Zhang, XP; Qian, ZX				Feng, Guorui; Lan, Yuan; Zhang, Xinpeng; Qian, Zhenxing			Dynamic Adjustment of Hidden Node Parameters for Extreme Learning Machine	IEEE TRANSACTIONS ON CYBERNETICS			English	Article						Adjustment of hidden node parameters; error minimized approximation; extreme learning machine; least squares method	NEURAL-NETWORKS; FEEDFORWARD NETWORKS; REGRESSION; CLASSIFICATION; ALGORITHM	Extreme learning machine (ELM), proposed by Huang et al., was developed for generalized single hidden layer feedforward networks with a wide variety of hidden nodes. ELMs have been proved very fast and effective especially for solving function approximation problems with a predetermined network structure. However, it may contain insignificant hidden nodes. In this paper, we propose dynamic adjustment ELM (DA-ELM) that can further tune the input parameters of insignificant hidden nodes in order to reduce the residual error. It is proved in this paper that the energy error can be effectively reduced by applying recursive expectation-minimization theorem. In DA-ELM, the input parameters of insignificant hidden node are updated in the decreasing direction of the energy error in each step. The detailed theoretical foundation of DA-ELM is presented in this paper. Experimental results show that the proposed DA-ELM is more efficient than the state-of-art algorithms such as Bayesian ELM, optimally-pruned ELM, two-stage ELM, Levenberg-Marquardt, sensitivity-based linear learning method as well as the preliminary ELM.	[Feng, Guorui; Zhang, Xinpeng; Qian, Zhenxing] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China; [Lan, Yuan] Taiyuan Univ Technol, Res Inst Mechatron Engn, Taiyuan 030024, Peoples R China	Feng, GR (reprint author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.	fgr2082@aliyun.com; layulibiyi@gmail.com; xzhang@shu.edu.cn; zxqian@shu.edu.cn			National Natural Science Foundation of China [61373151]; Natural Science Foundation of Shanghai [13ZR1415000]; Qualified Personnel Foundation of Taiyuan University of Technology [tyutrc-201307b]; Taiyuan University of Technology Group Fund [1205-04020102]; Innovation Program of Shanghai Municipal Education Commission [14YZ019]; Shanghai Rising-Star Program [14QA1401900]	This work was supported in part by the National Natural Science Foundation of China under Grant 61373151, in part by the Natural Science Foundation of Shanghai under Grant 13ZR1415000, in part by the Qualified Personnel Foundation of Taiyuan University of Technology under Grant tyutrc-201307b, in part by the Taiyuan University of Technology Group Fund under Grant 1205-04020102, in part by the Innovation Program of Shanghai Municipal Education Commission under Grant 14YZ019, and in part by Shanghai Rising-Star Program under Grant 14QA1401900. This paper was recommended by Associate Editor X. You.	Blake C., 1998, UCI REPOSITORY MACHI; Castillo E, 2006, J MACH LEARN RES, V7, P1159; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Efron B, 2004, ANN STAT, V32, P407; Feng GR, 2009, IEEE T NEURAL NETWOR, V20, P1352, DOI 10.1109/TNN.2009.2024147; Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Han M., 2012, P IEEE VTC FALL QUEB, P1; Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.121.126; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Jaeger H., 2002, 159 GMD GERM NAT RES; Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63; Lan Y, 2010, NEUROCOMPUTING, V73, P3028, DOI 10.1016/j.neucom.2010.07.012; Li K, 2005, IEEE T AUTOMAT CONTR, V50, P1211, DOI 10.1109/TAC.2005.852557; Lu YW, 1997, NEURAL COMPUT, V9, P461; Miche Y, 2010, IEEE T NEURAL NETWOR, V21, P158, DOI 10.1109/TNN.2009.2036259; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; Rao C., 1971, GEN INVERSE MATRICES; Rong HJ, 2008, NEUROCOMPUTING, V72, P359, DOI 10.1016/j.neucom.2008.01.005; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Scarselli F, 1998, NEURAL NETWORKS, V11, P15, DOI 10.1016/S0893-6080(97)00097-X; Simila T, 2005, LECT NOTES COMPUT SC, V3697, P97; Soria-Olivas E, 2011, IEEE T NEURAL NETWOR, V22, P505, DOI 10.1109/TNN.2010.2103956; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Zhang R, 2013, IEEE T CYBERNETICS, V43, P2054, DOI 10.1109/TCYB.2013.2239987; Zhang R, 2012, IEEE T NEUR NET LEAR, V23, P365, DOI 10.1109/TNNLS.2011.2178124	28	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2168-2267	2168-2275		IEEE T CYBERNETICS	IEEE T. Cybern.	FEB	2015	45	2					279	288		10.1109/TCYB.2014.2325594		10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	AZ2OA	WOS:000348071500011	24919208	
J	Torija, AJ; Ruiz, DP				Torija, Antonio J.; Ruiz, Diego P.			A general procedure to generate models for urban environmental noise pollution using feature selection and machine learning methods	SCIENCE OF THE TOTAL ENVIRONMENT			English	Article						Feature selection; Multiple linear regression; Multilayer perceptron; Sequential minimal optimisation; Gaussian processes for regression; Environmental-noise prediction	GAUSSIAN PROCESS REGRESSION; SUPPORT VECTOR REGRESSION; TRAFFIC-NOISE; SOUND ENVIRONMENTS; PREDICTION METHOD; NEURAL-NETWORKS; SVM REGRESSION; AIR-POLLUTION; ROAD; ALGORITHMS	The prediction of environmental noise in urban environments requires the solution of a complex and non-linear problem, since there are complex relationships among the multitude of variables involved in the characterization and modelling of environmental-noise and environmental-noise magnitudes. Moreover, the inclusion of the great spatial heterogeneity characteristic of urban environments seems to be essential in order to achieve an accurate environmental-noise prediction in cities. This problem is addressed in this paper, where a procedure based on feature-selection techniques and machine-learning regression methods is proposed and applied to this environmental problem. Three machine-learning regression methods, which are considered very robust in solving nonlinear problems, are used to estimate the energy-equivalent sound-pressure level descriptor (L-Aeq). These three methods are: (i) multilayer perceptron (MLP), (ii) sequential minimal optimisation (SMO), and (iii) Gaussian processes for regression (GPR). In addition, because of the high number of input variables involved in environmental-noise modelling and estimation in urban environments, which make L-Aeq prediction models quite complex and costly in terms of time and resources for application to real situations, three different techniques are used to approach feature selection or data reduction. The feature-selection techniques used are: (i) correlation-based feature-subset selection (CFS), (ii) wrapper for feature-subset selection (WFS), and the data reduction technique is principal-component analysis (PCA). The subsequent analysis leads to a proposal of different schemes, depending on the needs regarding data collection and accuracy. The use of WFS as the feature-selection technique with the implementation of SMO or GPR as regression algorithm provides the best L-Aeq estimation (R-2 = 0.94 and mean absolute error (MAE) = 1.14-1.16 dB(A)). (C) 2014 Elsevier B.V. All rights reserved.	[Torija, Antonio J.] Univ Malaga, Higher Tech Sch Telecommun Engn, Dept Elect Technol, E-29071 Malaga, Spain; [Ruiz, Diego P.] Univ Granada, Dept Appl Phys, E-18071 Granada, Spain	Torija, AJ (reprint author), Univ Malaga, Higher Tech Sch Telecommun Engn, Dept Elect Technol, Campus Teatinos, E-29071 Malaga, Spain.	ajtorija@ugr.es			University of Malaga [246550]; European Commission [246550]; Co-funding of Regional, National and International Programmes (COFUND); Ministerio de Economia y Competitividad [TEC2012-38883-C02-02, COFUND2013-40259]	This work was funded by the University of Malaga and the European Commission under the Agreement Grant no. 246550 of the seventh Framework Programme for R & D of the EU, granted within the People Programme, "Co-funding of Regional, National and International Programmes" (COFUND), and Ministerio de Economia y Competitividad (COFUND2013-40259). Moreover, this work is also supported by the "Ministerio de Economia y Competitividad" of Spain under project TEC2012-38883-C02-02.	Agirre-Basurko E, 2006, ENVIRON MODELL SOFTW, V21, P430, DOI 10.1016/j.envsoft.2004.07.008; Belojevic G, 1997, ENVIRON INT, V23, P221, DOI 10.1016/S0160-4120(97)00008-1; Belojevic G, 2008, ENVIRON INT, V34, P226, DOI 10.1016/j.envint.2007.08.003; Calvo B, 2009, PATTERN RECOGN LETT, V30, P1027, DOI 10.1016/j.patrec.2009.04.015; Chandra P., 2003, NEURAL PROCESS LETT, V18, P205, DOI 10.1023/B:NEPL.0000011137.04221.96; Chuang CC, 2011, APPL SOFT COMPUT, V11, P64, DOI 10.1016/j.asoc.2009.10.017; De Jong K., 1988, Machine Learning, V3, DOI 10.1023/A:1022606120092; de Souza LCL, 2011, COMPUT ENVIRON URBAN, V35, P421, DOI 10.1016/j.compenvurbsys.2011.06.001; Flake GW, 2002, MACH LEARN, V46, P271, DOI 10.1023/A:1012474916001; Garg N, 2014, ENVIRON IMPACT ASSES, V46, P68, DOI 10.1016/j.eiar.2014.02.001; Givargis S, 2010, J ENVIRON MANAGE, V91, P2529, DOI 10.1016/j.jenvman.2010.07.011; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Gundogdu O, 2005, APPL ACOUST, V66, P799, DOI 10.1016/j.apacoust.2004.11.003; Hall M. A., 1997, P 4 INT C NEUR INF P, P855; Hall Mark, 2009, SIGKDD EXPLORATIONS, P11; Haykin S., 1999, NEURAL NETWORKS COMP; HOFMAN WF, 1995, J SOUND VIB, V179, P577, DOI 10.1006/jsvi.1995.0038; Ibarra-Berastegi G, 2008, ENVIRON MODELL SOFTW, V23, P622, DOI 10.1016/j.envsoft.2007.09.003; Jolliffe T, 1986, ACM COMPUT SURV, P1; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kurra S, 1999, J SOUND VIB, V220, P251, DOI 10.1006/jsvi.1998.1928; Nega T, 2012, COMPUT ENVIRON URBAN, V36, P245, DOI 10.1016/j.compenvurbsys.2011.09.001; Pamanikabud P, 2003, ENVIRON MODELL SOFTW, V18, P959, DOI 10.1016/S1364-8152(03)00097-5; Pasolli L, 2010, IEEE GEOSCI REMOTE S, V7, P464, DOI 10.1109/LGRS.2009.2039191; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Scholkopf B., 2002, LEARNING KERNELS SUP; Shaw EAG, 1996, NOISE CONTROL ENG, V44, P109, DOI 10.3397/1.2828392; Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Steele C, 2001, APPL ACOUST, V62, P271, DOI 10.1016/S0003-682X(00)00030-X; Tang UW, 2007, ENVIRON MODELL SOFTW, V22, P1750, DOI 10.1016/j.envsoft.2007.02.003; Thissen U, 2004, CHEMOMETR INTELL LAB, V73, P169, DOI 10.1016/j.chemolab.2004.01.002; Tiwari R, 2010, INT J COMPUT APPL, V4, P28; Torija AJ, 2011, APPL ACOUST, V72, P89, DOI 10.1016/j.apacoust.2010.09.011; Torija AJ, 2012, SCI TOTAL ENVIRON, V435, P270, DOI 10.1016/j.scitotenv.2012.07.014; Torija AJ, 2012, BUILD ENVIRON, V52, P45, DOI 10.1016/j.buildenv.2011.12.024; Torija AJ, 2010, BUILD ENVIRON, V45, P1477, DOI 10.1016/j.buildenv.2009.12.011; Torija AJ, 2014, SCI TOTAL ENVIRON, V482, P440, DOI 10.1016/j.scitotenv.2013.07.108; Uguz H, 2011, KNOWL-BASED SYST, V24, P1024, DOI 10.1016/j.knosys.2011.04.014; Ustun B, 2006, CHEMOMETR INTELL LAB, V81, P29, DOI 10.1016/j.chemolab.2005.09.003; Vafaie H, 1994, P 3 INT FUZZ SYST IN; Valle S, 1999, IND ENG CHEM RES, V38, P4389, DOI 10.1021/ie990110i; Vapnik V, 1995, NATURAL STAT LEARNIN; Vapnik V. N., 1998, STAT LEARNING THEORY; Venkatesan P, 2006, CURR SCI INDIA, V91, P1195; Verrelst J, 2012, REMOTE SENS ENVIRON, V118, P127, DOI 10.1016/j.rse.2011.11.002; Vlachokostas C, 2012, ENVIRON INT, V39, P8, DOI 10.1016/j.envint.2011.09.007; Wu Q, 2012, EXPERT SYST APPL, V39, P4769, DOI 10.1016/j.eswa.2011.09.159; Xinjun Peng, 2010, Neural Networks, V23, DOI 10.1016/j.neunet.2009.07.002; Yilmaz I, 2011, EXPERT SYST APPL, V38, P5958, DOI 10.1016/j.eswa.2010.11.027; Zhao JQ, 2012, APPL ACOUST, V73, P276	53	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0048-9697	1879-1026		SCI TOTAL ENVIRON	Sci. Total Environ.	FEB 1	2015	505						680	693		10.1016/j.scitotenv.2014.08.060		14	Environmental Sciences	Environmental Sciences & Ecology	AY6CJ	WOS:000347654900069	25461071	
J	Mattar, MA; Alazba, AA; El-Abedin, TKZ				Mattar, M. A.; Alazba, A. A.; El-Abedin, T. K. Zin			Forecasting furrow irrigation infiltration using artificial neural networks	AGRICULTURAL WATER MANAGEMENT			English	Article						Artificial neural networks; Infiltrated water volume; Furrow irrigation	PARTIAL MUTUAL INFORMATION; SURFACE IRRIGATION; ADVANCE DATA; MODEL; WATER; PARAMETERS; EQUATIONS; VARIABILITY; SELECTION; SYSTEMS	An artificial neural network (ANN) was developed for estimating the infiltrated water volume (Z) under furrow irrigation. A feed-forward neural network using back-propagation training algorithm was developed for the prediction. Four variables were used as input parameters; inflow rate (Q(o)), furrow length (L), waterfront advance time at the end of the furrow (T-L) and infiltration opportunity time (T-o). The Z was the one node in the output layer. The data used to develop the ANN model were taken from published experiments. The ANN model predicted Z over a wide range of the input variables with statistical analysis indicating that it can successfully predict Z with a high degree of accuracy. Performance evaluation criteria indicated that the ANN model was better than the two-point method using a volume balance model. Using testing and validation data sets to compare the ANN model with the two-point method shows that the two-point method had a mean coefficient of determination (R-2) value that was about 3.6% less accurate than that from the ANN model. Also, the mean root mean square error (RMSE) value of 0.0135 m(3) m(-1) for the two-point method was almost double that of mean values for the ANN model. The relative errors of computed Z values for the ANN model were mostly around +/- 10%. Therefore, the ANN model is applicable to other soils and to different furrow irrigation hydraulics. (C) 2014 Elsevier B.V. All rights reserved.	[Mattar, M. A.; El-Abedin, T. K. Zin] King Saud Univ, Coll Food & Agr Sci, Dept Agr Engn, Riyadh 11451, Saudi Arabia; [Alazba, A. A.] King Saud Univ, Agr Engn Dept & supervisor, Alamoudi Water Chair, Riyadh 11451, Saudi Arabia; [Mattar, M. A.] Agr Engn Res Inst AEnRI, Agr Res Ctr, Giza, Egypt; [El-Abedin, T. K. Zin] Univ Alexandria, Coll Agr, Dept Agr Engn, Alexandria, Egypt	Mattar, MA (reprint author), King Saud Univ, Coll Food & Agr Sci, Dept Agr Engn, POB 2460, Riyadh 11451, Saudi Arabia.	mmattar@ksu.edu.sa			Deanship of Scientific Research, King Saud University; Agriculture Research Center, College of Food and Agriculture Sciences	With sincere respect and gratitude we would like to express deep thanks to Deanship of Scientific Research, King Saud University and Agriculture Research Center, College of Food and Agriculture Sciences for the financial support, sponsoring and encouragement.	Alazba AA, 2012, J IRRIG DRAIN E-ASCE, V138, P166, DOI 10.1061/(ASCE)IR.1943-4774.0000387; Al-Janobi A. A., 2010, Australian Journal of Basic and Applied Sciences, V4, P3869; Alvarez JAR, 2003, AGR WATER MANAGE, V60, P227, DOI 10.1016/S0378-3774(02)00163-4; Basheer L. A., 2000, J MICROBIOLOGICAL ME, V43, P3, DOI DOI 10.1016/S0167-7012(00)00201-3; Blair A.W., 1983, ASAE WINT M; BLAIR AW, 1988, J IRRIG DRAIN E-ASCE, V114, P18; Burt C.M., 1982, 822537 ASAE; Christiansen J.E., 1966, T ASAE, V9, P671; Ebrahimian H, 2010, IRRIGATION SCI, V28, P479, DOI 10.1007/s00271-010-0209-5; ELLIOTT RL, 1982, T ASAE, V25, P396; ELLIOTT RL, 1983, T ASAE, V26, P1726; ELSHAFEI YZ, 1980, Z KULTURTECH FLURBER, V21, P8; Esfandiari M, 1997, AGR WATER MANAGE, V34, P169, DOI 10.1016/S0378-3774(97)00007-3; Esfandiari M., 2001, J AGR ENG RES, V79, P229; FAO-UNESCO, 1988, FAO UNESCO WORLD SOI, V60, P142; Fernando TMKG, 2009, J HYDROL, V367, P165, DOI 10.1016/j.jhydrol.2008.10.019; Givi J, 2004, AGR WATER MANAGE, V70, P83, DOI 10.1016/j.agwat.2004.06.009; Hanson B.R., 1990, P 3 NAT IRR S ASAE, P228; Holzapfel EA, 2004, AGR WATER MANAGE, V68, P19, DOI 10.1016/j.agwat.2004.03.002; Kalogirou SA, 2001, RENEW SUST ENERG REV, V5, P373, DOI 10.1016/S1364-0321(01)00006-5; Kenward T.C., 2004, P WRPMD 99 PREP 21 C, V102, P245; Kiefer F.W., 1965, SPECIAL PUBLICATION; Kim J.H., 2004, P WRPMD 99 PREP 21 C, V102, P236; Kurt H, 2007, J ENERGY INST, V80, P46, DOI 10.1179/174602207X171570; LAL R, 1972, T ASAE, V15, P69; Landeras G, 2008, AGR WATER MANAGE, V95, P553, DOI 10.1016/j.agwat.2007.12.011; Landeras G, 2009, J IRRIG DRAIN E-ASCE, V135, P323, DOI 10.1061/(ASCE)IR.1943-4774.0000008; Legates DR, 1999, WATER RESOUR RES, V35, P233, DOI 10.1029/1998WR900018; Lewis M.R., 1938, AGR ENG, V19, P267; Mateos L, 2005, AGR WATER MANAGE, V76, P62, DOI 10.1016/j.agwat.2005.01.013; May RJ, 2008, ENVIRON MODELL SOFTW, V23, P1312, DOI 10.1016/j.envsoft.2008.03.007; Nestorl S.Y., 2006, J SCI HYDROLOGIQUES, V51, P3; Norum D.E., 1970, J IRRIG DRAIN DIV AS, V96, P111; Oyonarte NA, 2003, T ASAE, V46, P85; Playan E, 2004, J IRRIG DRAIN E-ASCE, V130, P106, DOI 10.1061/(ASCE)0733-9437(2004)130:2(106); Pulido-Calvo I, 2007, BIOSYST ENG, V97, P283, DOI 10.1016/j.biosystemseng.2007.03.003; Pulido-Calvo I, 2009, BIOSYST ENG, V102, P202, DOI 10.1016/j.biosystemseng.2008.09.032; Ravi V., 1998, EPA600R87128A US ENV, VI, P26; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sablani SS, 1997, FOOD RES INT, V30, P105, DOI 10.1016/S0963-9969(97)00029-X; SCALOPPI EJ, 1995, J IRRIG DRAIN E-ASCE, V121, P57, DOI 10.1061/(ASCE)0733-9437(1995)121:1(57); Sepaskhah AR, 2007, BIOSYST ENG, V98, P248, DOI 10.1016/j.biosystemseng.2007.03.024; Serralheiro R.P., 1988, THESIS U EVORA EVORA; Shaalan K., 1999, Egyptian Computer Journal, V27; STRELKOFF T, 1977, J IRR DRAIN DIV-ASCE, V103, P325; Strelkoff TS, 2009, J IRRIG DRAIN E-ASCE, V135, P537, DOI 10.1061/(ASCE)IR.1943-4774.0000088; Swingler K., 2001, APPL NEURAL NETWORKS; Valiantzas JD, 2001, AGR WATER MANAGE, V52, P17, DOI 10.1016/S0378-3774(01)00128-7; Walker W. R., 1987, SURFACE IRRIGATION T; Walker WR, 2006, AGR WATER MANAGE, V85, P157, DOI 10.1016/j.agwat.2006.04.002; Walker W.R., 1989, 45 FAO IRR DRAIN, P137; Wanakule N., 2005, P IMP GLOB CLIM CHAN, V173, P89; Wu L.-P., 1971, T ASAE, V14, P295; Yang IH, 2003, ENERG CONVERS MANAGE, V44, P2791, DOI 10.1016/S0196-8904(03)00044-X; Zanetti SS, 2007, J IRRIG DRAIN E-ASCE, V133, P83, DOI 10.1061/(ASCE)0733-9437(2007)133:2(83)	55	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3774	1873-2283		AGR WATER MANAGE	Agric. Water Manage.	JAN 31	2015	148						63	71		10.1016/j.agwat.2014.09.015		9	Agronomy; Water Resources	Agriculture; Water Resources	AW8XA	WOS:000346541500008		
J	He, S; Chen, HH; Zhu, ZX; Ward, DG; Cooper, HJ; Viant, MR; Heath, JK; Yao, X				He, Shan; Chen, Huanhuan; Zhu, Zexuan; Ward, Douglas G.; Cooper, Helen J.; Viant, Mark R.; Heath, John K.; Yao, Xin			Robust twin boosting for feature selection from high-dimensional omics data with label noise	INFORMATION SCIENCES			English	Article						Feature selection; Boosting; Ensemble learning	GENE-EXPRESSION DATA; SUPPORT VECTOR MACHINES; MASS-SPECTROMETRY DATA; MUTUAL INFORMATION; TUMOR CLASSIFICATION; SPARSE APPROXIMATION; LOGISTIC-REGRESSION; COLORECTAL-CANCER; DATA PERTURBATION; BIOMARKER	Omics data such as microarray transcriptomic and mass spectrometry proteomic data are typically characterized by high dimensionality and relatively small sample sizes. In order to discover biomarkers for diagnosis and prognosis from omics data, feature selection has become an indispensable step to find a parsimonious set of informative features. However, many previous studies report considerable label noise in omics data, which will lead to unreliable inferences to select uninformative features. Yet, to the best of our knowledge, very few feature selection methods are proposed to address this problem. This paper proposes a novel ensemble feature selection algorithm, robust twin boosting feature selection (RTBFS), which is robust to label noise in omics data. The algorithm has been validated on an omics feature selection test bed and seven real-world heterogeneous omics datasets, of which some are known to have label noise. Compared with several state-of-the-art ensemble feature selection methods, RTBFS can select more informative features despite label noise and obtain better classification results. RTBFS is a general feature selection method and can be applied to other data with label noise. MATLAB implementation of RTBFS and sample datasets are available at: http://www.cs.bham.ac.uk/similar to szh/TReBFSMatlab.zip. (C) 2014 Elsevier Inc. All rights reserved.	[He, Shan; Chen, Huanhuan; Yao, Xin] Univ Birmingham, Sch Comp Sci, CERCIA, Birmingham B15 2TT, W Midlands, England; [Zhu, Zexuan] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China; [Ward, Douglas G.] Univ Birmingham, Sch Canc Sci, Birmingham B15 2TT, W Midlands, England; [Cooper, Helen J.; Viant, Mark R.; Heath, John K.] Univ Birmingham, Sch Biosci, Birmingham B15 2TT, W Midlands, England	Zhu, ZX (reprint author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.	s.he@cs.bham.ac.uk; h.chen@cs.bham.ac.uk; zhuzx@szu.edu.cn; d.g.ward@bham.ac.uk; h.j.cooper@bham.ac.uk; m.viant@bham.ac.uk; j.k.heath@bham.ac.uk; x.yao@cs.bham.ac.uk			Leverhulme Trust [ECF/2007/0433]; Royal Society International Exchanges NSFC [IE111069]; National Natural Science Foundation of China [61471246, 61205092]; NSFC-RS joint project [61211130120]; Guangdong Foundation of Outstanding Young Teachers in Higher Education Institutions [Yq2013141]; Shenzhen Scientific Research and Development Funding Program [JCYJ20130329115450637, KQC201108300045A, ZYC201105170243A]; Guangdong Natural Science Foundation [S2012010009545]	This work is supported by the Leverhulme Trust Early Career Fellowship (ECF/2007/0433), the Royal Society International Exchanges 2011 NSFC cost share scheme (IE111069), National Natural Science Foundation of China (61471246 and 61205092), the NSFC-RS joint project (61211130120), the Guangdong Foundation of Outstanding Young Teachers in Higher Education Institutions (Yq2013141), the Shenzhen Scientific Research and Development Funding Program (JCYJ20130329115450637, KQC201108300045A, and ZYC201105170243A), and the Guangdong Natural Science Foundation (S2012010009545).	Abeel T, 2009, J MACH LEARN RES, V10, P931; Abeel T, 2010, BIOINFORMATICS, V26, P392, DOI 10.1093/bioinformatics/btp630; ABELLAN J, 2009, SYMBOLIC QUANTITATIV, V5590, P446, DOI 10.1007/978-3-642-02906-6_39; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Avezzu A, 2008, CANCER LETT, V268, P308, DOI 10.1016/j.canlet.2008.04.004; Bootkrajang J, 2013, BIOINFORMATICS, V29, P870, DOI 10.1093/bioinformatics/btt078; Bulmann P., 2010, STAT COMPUT, V20, P119; Choudhary A, 2006, BIOINFORMATICS, V22, P837, DOI 10.1093/bioinformatics/btl008; COPAS JB, 1988, J ROY STAT SOC B MET, V50, P225; COPAS JB, 1983, J R STAT SOC B, V45, P311; Derrac J, 2012, IEEE T SYST MAN CY B, V42, P1383, DOI 10.1109/TSMCB.2012.2191953; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Diao R, 2012, IEEE T SYST MAN CY B, V42, P1509, DOI 10.1109/TSMCB.2012.2193613; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Donoho DL, 1993, P S APPL MATH, V47, P173; Fan NJ, 2012, CAN J GASTROENTEROL, V26, P41; Fischer H, 2001, CARCINOGENESIS, V22, P875, DOI 10.1093/carcin/22.6.875; Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894; Frenay B, 2014, COMPUT STAT DATA AN, V71, P832, DOI 10.1016/j.csda.2013.05.001; Frenay B, 2013, NEUROCOMPUTING, V112, P64, DOI 10.1016/j.neucom.2012.12.051; Freund Yoav, 1995, P 2 EUR C COMP LEARN, P23; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Gan JQ, 2014, INT J MACH LEARN CYB, V5, P413, DOI 10.1007/s13042-012-0139-z; Ge GT, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-275; Gerlach R, 2007, STAT MODEL, V7, P255, DOI 10.1177/1471082X0700700303; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2003, ELEMENTS STAT LEARNI; He S, 2009, PROTEOMICS, V9, P4176, DOI 10.1002/pmic.200800502; Hingorani S.R., 2004, CANC CELL, V5; Huber P.J., 1981, ROBUST STAT; Jiyan H., 2011, INT J PHYS SCI, V6, P5897; Kanamori T, 2007, NEURAL COMPUT, V19, P2183, DOI 10.1162/neco.2007.19.8.2183; Karmaker A., 2006, INT J HYBRID INTELL, V3, P169; Kuschner KW, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-177; Leung YY, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046700; Li AH, 2001, CLIN CANCER RES, V7, P3298; Li JY, 2002, BIOINFORMATICS, V18, P1406, DOI 10.1093/bioinformatics/18.10.1406; Liu JL, 2011, EXPERT SYST APPL, V38, P2253, DOI 10.1016/j.eswa.2010.08.013; Long PM, 2010, MACH LEARN, V78, P287, DOI 10.1007/s10994-009-5165-z; Ma YL, 2009, MOL CELL PROTEOMICS, V8, P1878, DOI 10.1074/mcp.M800541-MCP200; Malossini A, 2006, BIOINFORMATICS, V22, P2114, DOI 10.1093/bioinformatics/btl346; Masnadi-Shirazi H., 2009, ADV NEURAL INFORM PR, V21, P1049; Netzer M, 2009, BIOINFORMATICS, V25, P941, DOI 10.1093/bioinformatics/btp093; Niemela O, 2001, FREE RADICAL BIO MED, V31, P1533, DOI 10.1016/S0891-5849(01)00744-4; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Rantalainen M, 2011, J PROTEOME RES, V10, P5562, DOI 10.1021/pr200507b; Ressom HW, 2007, BIOINFORMATICS, V23, P619, DOI 10.1093/bioinformatics/btl678; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Semmes OJ, 2005, LEUKEMIA, V19, P1229, DOI 10.1038/sj.leu.2403781; Shanab A.A., 2012, P 25 INT FLOR ART IN, P92; Sharma A, 2012, INT J MACH LEARN CYB, V3, P269, DOI 10.1007/s13042-011-0061-9; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; STONE BG, 1993, LIPIDS, V28, P705, DOI 10.1007/BF02535990; Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; Telgarsky M., 2013, J MACH LEARN RES, V28; Van Marck V, 2011, INT J CANCER, V128, P1031, DOI 10.1002/ijc.25427; Vapnik V., 1995, NATURE STAT LEARNING; Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0; Wei P, 2014, INT J MACH LEARN CYB, V5, P339, DOI 10.1007/s13042-013-0164-6; Wei XL, 2010, P NATL ACAD SCI USA, V107, P6737, DOI 10.1073/pnas.0910140107; Wen W, 2010, SOFT COMPUT, V14, P1241, DOI 10.1007/s00500-009-0535-9; Wheway V., 2001, ADV ARTIFICIAL INTEL, P123; Yang JB, 2012, IEEE T SYST MAN CY B, V42, P1550, DOI 10.1109/TSMCB.2012.2195000; Yu L, 2004, J MACH LEARN RES, V5, P1205; Zhang C, 2009, BIOINFORMATICS, V25, P2708, DOI 10.1093/bioinformatics/btp478; Zhang WS, 2006, BIOINFORMATICS, V22, P317, DOI 10.1093/bioinformatics/bti738; Zhu ZX, 2010, IEEE COMPUT INTELL M, V5, P41, DOI 10.1109/MCI.2010.936311; Zhu ZX, 2007, IEEE T SYST MAN CY B, V37, P70, DOI 10.1109/TSMCB.2006.883267; Zhu ZX, 2007, PATTERN RECOGN, V40, P3236, DOI 10.1016/j.patcog.2007.02.007	74	0	0	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255	1872-6291		INFORM SCIENCES	Inf. Sci.	JAN 10	2015	291						1	18		10.1016/j.ins.2014.08.048		18	Computer Science, Information Systems	Computer Science	AS3WP	WOS:000344206300001		
J	Rashidi, S; Ahmadpour, A; Jahanshahi, N; Mahboub, MJD; Rashidi, H				Rashidi, Sajjad; Ahmadpour, Ali; Jahanshahi, Neda; Mahboub, Mohammad Jaber Darabi; Rashidi, Hamed			Application of Artificial Intelligent Modeling for Predicting Activated Carbons Properties Used for Methane Storage	SEPARATION SCIENCE AND TECHNOLOGY			English	Article						Artificial Intelligence; methane storage; activated carbon; ANFIS	CHEMICAL ACTIVATION; NEURAL-NETWORKS; PHENOLIC RESIN; ADSORPTION; BIOMASS; NAOH; CO2	Performance characterization and optimization of activated carbons are extensively studied using artificial intelligence modeling. In this study, the effect of several parameters on the preparation of activated carbon by chemical activation is investigated. Various preliminary parameters have been considered. The study has resulted in finding four parameters, which are of higher importance compared to the others. These parameters include chemical agent type, chemical agent to precursor ratio, activation temperature, and activation time. In our previous study, 36 activated carbon (AC) samples were prepared using the aforementioned parameters at various levels. In the present investigation, these experimental results have been used for the modeling. As a novel approach, an adaptive neuro-fuzzy inference system (ANFIS) is also applied to the experimental data presented in this study. ANFIS is established by combining artificial neural network (ANN) with fuzzy inference system. After determining the model parameters, some additional data points are used to validate the models. Finally, the outcomes are compared with the experimental results. The normalized mean square error (NMSE) has been obtained as 0.00327, which is very satisfactory for the model validation. These attempts to simulate the preparation stage of activated carbons would provide a simple and flexible route with various AC preparations. Such an effort is essential to develop the adsorbed natural gas (ANG) technology.	[Rashidi, Sajjad; Ahmadpour, Ali; Jahanshahi, Neda; Mahboub, Mohammad Jaber Darabi; Rashidi, Hamed] Ferdowsi Univ Mashhad, Dept Chem Engn, Mashhad, Iran	Ahmadpour, A (reprint author), Ferdowsi Univ Mashhad, Dept Chem Engn, Mashhad, Iran.	ahmadpour@um.ac.ir			Iranian Nano Technology Initiative	Financial support was prepared by Iranian Nano Technology Initiative and authors are thankful for their support.	Ahmadpour A, 1997, CARBON, V35, P1723, DOI 10.1016/S0008-6223(97)00127-9; Balabin RM, 2011, FUEL, V90, P2007, DOI 10.1016/j.fuel.2010.11.038; Cazorla-Amoros D, 1998, LANGMUIR, V14, P4589, DOI 10.1021/la980198p; CazorlaAmoros D, 1996, LANGMUIR, V12, P2820, DOI 10.1021/la960022s; Cladera A, 2004, ENG STRUCT, V26, P917, DOI 10.1016/j.engstruct.2004.02.010; Devillers J, 1996, STRENGTHS WEAKNESSES; Hashemipour H., 2009, INT J CHEM REACT ENG, V7, P563; Haykin S., 1999, NEURAL NETWORKS COMP; Jang S, 1997, NEUROFUZZY SOFT COMP; Jang S. R., 1993, IEEE T SYST MAN CYB, V23, P665; Jin Z., 2002, IECON 02 IND EL SOC, V221, P229; KUMAMOTO S, 1994, T MRS JAP, V18, P647; Lillo-Rodenas MA, 2004, CARBON, V42, P1371, DOI 10.1016/j.carbon.2004.01.008; Lillo-Rodenas MA, 2001, CARBON, V39, P751, DOI 10.1016/S0008-6223(00)00186-X; Lillo-Rodenas MA, 2003, CARBON, V41, P267, DOI 10.1016/S0008-6223(02)00279-8; Lozano-Castello D, 2002, FUEL, V81, P1777, DOI 10.1016/S0016-2361(02)00124-2; Lozano-Castello D, 2002, CARBON, V40, P989, DOI 10.1016/S0008-6223(01)00235-4; Namvar-Asl M, 2008, ENERG CONVERS MANAGE, V49, P2478, DOI 10.1016/j.enconman.2008.01.036; Namvar-Asl M, 2008, ENERG CONVERS MANAGE, V49, P2471, DOI 10.1016/j.enconman.2008.01.039; Qi Y, 2011, FUEL, V90, P1567, DOI 10.1016/j.fuel.2011.01.015; QUINN DF, 1992, CARBON, V30, P1097, DOI 10.1016/0008-6223(92)90141-I; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schalkoff RJ., 1997, ARTIFICIAL NEURAL NE; Shahsavand A, 2005, COMPUT CHEM ENG, V29, P2134, DOI 10.1016/j.compchemeng.2005.07.002; SIMITZIS J, 1995, J APPL POLYM SCI, V58, P541, DOI 10.1002/app.1995.070580308; SIMITZIS J, 1994, J APPL POLYM SCI, V54, P2091, DOI 10.1002/app.1994.070541311; Sugeno M., 1985, IND APPL FUZZY CONTR; Ubeyli ED, 2009, COMPUT METH PROG BIO, V93, P313, DOI 10.1016/j.cmpb.2008.10.012; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	29	0	0	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0149-6395	1520-5754		SEP SCI TECHNOL	Sep. Sci. Technol.	JAN 2	2015	50	1					110	120		10.1080/01496395.2014.948001		11	Chemistry, Multidisciplinary; Engineering, Chemical	Chemistry; Engineering	AX6RI	WOS:000347048600013		
