PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT	PM
S	Pham, DS; Venkatesh, S			IEEE	Pham, Duc-Son; Venkatesh, Svetha			Robust learning of discriminative projection for multicategory classification on the Stiefel manifold	2008 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-12	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 23-28, 2008	Anchorage, AK	IEEE Comp Soc			FACE-RECOGNITION ALGORITHMS; DIMENSIONALITY REDUCTION; ILLUMINATION; FRAMEWORK; DATABASE; POSE	Learning a robust projection with a small number of training samples is still a challenging problem in face recognition, especially when the unseen faces have extreme variation in pose, illumination, and facial expression. To address this problem, we propose a framework formulated under statistical learning theory that facilitates robust learning of a discriminative projection. Dimensionality reduction using the projection matrix is combined with a linear classifier in the regularized framework of lasso regression. The projection matrix in conjunction with the classifier parameters are then found by solving an optimization problem over the Stiefel manifold. The experimental results on standard face databases suggest that the proposed method outperforms some recent regularized techniques when the number of training samples is small.	[Pham, Duc-Son; Venkatesh, Svetha] Curtin Univ Technol, Dept Comp, Perth, WA 6845, Australia	Pham, DS (reprint author), Curtin Univ Technol, Dept Comp, GPO Box U1987, Perth, WA 6845, Australia.						An S., 2007, P CVPR; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cai D, 2007, P CVPR; Cai D., CODES DATASETS SUBSP; CAI D, 2006, IEEE T IMAGE PROCESS, V5, P3608; Candes E., L1 MAGIC RECOVERY SP; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Cover T. M., 2006, ELEMENTS INFORM THEO; Donoho DL, 2005, J MATH IMAGING VIS, V23, P5, DOI 10.1007/s10851-005-4965-4; Hastie T., 2001, ELEMENTS STAT LEARNI; He X., 2003, P NIPS; KIM SJ, IEEE J SELE IN PRESS; LAZEBNIK F, REGULAR SIMPLEX R N; Lin D., 2006, P CVPR; Manton J. H., 2002, IEEE T SIGNAL PROCES, V50, P4311; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Scholkopf B., 2002, LEARNING KERNELS; *SPARS, SEEK SPARS SOL LIN S; Srivastava M. S., 2002, METHODS MULTIVARIATE; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Vapnik V., 1998, STAT LEARNING THEORY	29	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-2242-5	PROC CVPR IEEE			2008							510	516				7	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BII46	WOS:000259736800067		
S	Yang, JC; Wright, J; Huang, T; Ma, Y			IEEE	Yang, Jianchao; Wright, John; Huang, Thomas; Ma, Yi			Image super-resolution as sparse representation of raw image patches	2008 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-12	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 23-28, 2008	Anchorage, AK	IEEE Comp Soc				This paper addresses the problem of generating a super-resolution (SR) image from a single low-resolution input image. We approach this problem from the perspective of compressed sensing. The low-resolution image is viewed as downsampled version of a high-resolution image, whose patches are assumed to have a sparse representation with respect to an over-complete dictionary of prototype signal-atoms. The principle of compressed sensing ensures that under mild conditions, the sparse representation can be correctly recovered from the downsampled signal. We will demonstrate the effectiveness of sparsity as a prior for regularizing the otherwise ill-posed super-resolution problem. We further show that a small set of randomly chosen raw patches from training images of similar statistical nature to the input image generally serve as a good dictionary, in the sense that the computed representation is sparse and the recovered high-resolution image is competitive or even superior in quality to images produced by other SR methods.	[Yang, Jianchao; Huang, Thomas] Univ Illinois, Beckman Inst, ECE Dept, Urbana, IL 61801 USA	Yang, JC (reprint author), Univ Illinois, Beckman Inst, ECE Dept, Urbana, IL 61801 USA.	jyang29@uiuc.edu; jnwright@uiuc.edu; huang@uiuc.edu; yima@uiuc.edu					Aharon M., 2006, IEEE T SIGNAL PROCES, V54; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Candes E., 2006, P INT C MATH; Capel D. P., 2001, THESIS U OXFORD; CHANG H., 2004, CVPR; DAI S, 2007, P ICCV; Donoho D. L., 2004, MOST LARGE UNDERDETE; Donoho D. L., 2005, COMPRESSED SENSING; Donoho D. L., 2006, COMM PURE APPL MATH, V59; ELAD M, 2006, IEEE TIP, V15; Freeman W. T., 2000, IJCV; Freeman William T., 2002, IEEE COMPUTER GRAPHI, V22; Hardie R.C., 1997, IEEE TIP; Irani M., 1993, JVCI; Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5; MAIRAL J, 2008, SIAM MULTISCALE MODE; Nowak E., 2006, P ECCV; PICKUP LC, 2003, P NIPS; RAUHUT H, 2007, COMPRESSED SENSING R; SUN J, 2003, P CVPR; TIPPING ME, 2003, P NIPS; WANG Q, 2005, P ICCV	26	0	1	6	10	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-2242-5	PROC CVPR IEEE			2008							2378	2385				8	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BII46	WOS:000259736802012		
B	Barron, AR; Huang, C; Li, JQ; Luo, X			IEEE	Barron, Andrew R.; Huang, Cong; Li, Jonathan Q.; Luo, Xi			MDL, penalized likelihood, and statistical risk	2008 IEEE INFORMATION THEORY WORKSHOP			English	Proceedings Paper	IEEE Information Theory Workshop	MAY 05-08, 2008	Porto, PORTUGAL	IEEE			COMPLEXITY DENSITY-ESTIMATION; MINIMUM CONTRAST ESTIMATORS; GENERALIZED LINEAR-MODELS; NEURAL NETWORKS; STOCHASTIC COMPLEXITY; GREEDY APPROXIMATION; MATHEMATICAL-THEORY; DESCRIPTION LENGTH; ENTROPY RISK; INFORMATION	We determine, for both countable and uncountable collections of functions, information-theoretic conditions on a penalty pen(f) such that the optimizer f of the penalized log likelihood criterion log 1/likelihood(f)+pen(f) has risk not more than the index of resolvability corresponding to the accuracy of the optimizer of the expected value of the criterion. If F is the linear span of a dictionary of functions, traditional description-length penalties are based on the number of non-zero terms (the l(0) norm of the coefficients). We specialize our general conclusions to show the l(1) norm of the coefficients times a suitable multiplier lambda is also an information-theoretically valid penalty.	[Barron, Andrew R.; Huang, Cong; Luo, Xi] Yale Univ, Dept Stat, New Haven, CT 06520 USA	Barron, AR (reprint author), Yale Univ, Dept Stat, New Haven, CT 06520 USA.						Kolaczyk ED, 2004, ANN STAT, V32, P500; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Modha DS, 1996, IEEE T INFORM THEORY, V42, P2133, DOI 10.1109/18.556602; Xie Q, 1997, IEEE T INFORM THEORY, V43, P646, DOI 10.1109/18.556120; Birge L, 1998, BERNOULLI, V4, P329, DOI 10.2307/3318720; CHERNOFF H, 1952, ANN MATH STAT, V23, P493, DOI 10.1214/aoms/1177729330; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Efron B, 2004, ANN STAT, V32, P407; Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776; Koltchinskii V, 2005, ANN STAT, V33, P1455, DOI 10.1214/009053605000000228; Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Banerjee Onureena, 2007, J MACHINE LEARNING R; BARRON A., 2008, FESTSCHRIFT JORMA RI; Barron A., 1990, NONPARAMETRIC FUNCTI, P561; Barron A., 1994, MACH LEARN, V14, P113; Barron A, 1998, ANN STAT, V26, P1800; Barron A, 1999, PROBAB THEORY REL, V113, P301, DOI 10.1007/s004400050210; Barron A. R., 1985, THESIS STANFORD U; BARRON A. R., 1998, BAYESIAN STAT, P27; Li JQ, 2000, ADV NEUR IN, V12, P279; BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; BARRON AR, 1991, COMPUTATIONAL LEARNI, P243; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Barron AR, 2008, ANN STAT, V36, P64, DOI 10.1214/009053607000000631; BARRON AR, 1998, 7 U ILL STAT DEPT; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; BIRGE L, 1993, PROBAB THEORY REL, V97, P113, DOI 10.1007/BF01199316; Bunea F, 2007, ANN STAT, V35, P1674, DOI 10.1214/009053606000001587; Bunea F, 2006, P 19 ANN C LEARN THE, P379; Bunea F., 2007, P 20 ANN C LEARN THE, P530; CHEANG GHL, 1998, THESIS YALE U; CHEANG GHL, 2001, P 9 ESANN, P371; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; CHEN SS, 1994, P AS C; CLARKE BS, 1994, J STAT PLAN INFER, V41, P37, DOI 10.1016/0378-3758(94)90153-8; CLARKE BS, 1990, IEEE T INFORM THEORY, V36, P453, DOI 10.1109/18.54897; Cover T. M., 2006, ELEMENTS INFORM THEO; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; Cramer H., 1946, MATH METHODS STAT; de Montricher G.F., 1975, ANN STAT, V3, P1329, DOI 10.1214/aos/1176343288; Friedman J., 2007, BIOSTATISTICS; GOOD IJ, 1971, BIOMETRIKA, V58, P255, DOI 10.2307/2334515; Grunwald P. D., 2007, MINIMUM DESCRIPTION; HAUSSLER D, 1993, COMPUTATIONAL LEARNING & COGNITION, P74; Haussler D, 1997, ANN STAT, V25, P2451; Huang C., 2008, ANN STAT UNPUB; JONES LK, 1992, ANN STAT, V20, P608, DOI 10.1214/aos/1176348546; Juditsky A, 2000, ANN STAT, V28, P681; Koh KM, 2007, J MACH LEARN RES, V8, P1519; Kolaczyk ED, 2005, BIOMETRIKA, V92, P119, DOI 10.1093/biomet/92.1.119; Lee WS, 1996, IEEE T INFORM THEORY, V42, P2118; Li J., 1999, THESIS YALE U; Makovoz Y, 1996, J APPROX THEORY, V85, P98, DOI 10.1006/jath.1996.0031; MEIER L, 2008, J ROYAL STAT SOC B, V70; Modha DS, 1996, NEURAL COMPUT, V8, P1107, DOI 10.1162/neco.1996.8.5.1107; Nemirovskii A. S., 1985, Problems of Information Transmission, V21; PARK MY, J ROYAL STAT SOC B, V69, P659; Rakhlin A., 2005, ESAIM-PROBAB STAT, V9, P220, DOI 10.1051/ps:2005011; Renyi A., 1961, P 4 BERK S MATH STAT, P547; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; SHANNON CE, 1948, AT&T TECH J, V27, P623; SHANNON CE, 1948, AT&T TECH J, V27, P379; Shen XT, 1998, STAT SINICA, V8, P337; SILVERMAN BW, 1982, ANN STAT, V10, P795, DOI 10.1214/aos/1176345872; TAKEUCHI J, 1997, 1998 INT S INF THEOR; TAKEUCHI J, 2007, IEEE T INFO IN PRESS; Takeuchi J., 1997, P SITA 97, P665; TAKEUCHI J, P 1998 INT S INF THE; van de Geer SA, 2008, ANN STAT, V36, P614, DOI 10.1214/009053607000000929; Wahba G., 1990, SPLINE MODELS OBSERV; WILLETT R, 2005, MULTISCALE POISSON I; Xie Q, 2000, IEEE T INFORM THEORY, V46, P431; Yang Y., 1998, IEEE T INFORM THEORY, V44, P117; Yang YH, 1999, ANN STAT, V27, P1564; ZHANG H, 2005, J AM STAT ASSOC, V99, P659; Zhang T., 2007, SOME SHARP PER UNPUB; Zhang T, 2006, ANN STAT, V34, P2180, DOI 10.1214/009053606000000704; Zhang T, 2003, IEEE T INFORM THEORY, V49, P682, DOI 10.1109/TIT.2002.808136	82	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2269-2				2008							247	257		10.1109/ITW.2008.4578660		11	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BIG31	WOS:000259299000054		
S	Wisell, D; Jalden, J; Handel, P			IEEE	Wisell, David; Jalden, Joakim; Handel, Peter			Behavioral Power Amplifier Modeling Using the LASSO	2008 IEEE INSTRUMENTATION AND MEASUREMENT TECHNOLOGY CONFERENCE, VOLS 1-5	IEEE INSTRUMENTATION & MEASUREMENT TECHNOLOGY CONFERENCE, PROCEEDINGS		English	Proceedings Paper	25th IEEE Instrumentation and Measurement Technology Conference	MAY 12-15, 2008	Victoria, CANADA	IEEE Instrumentat & Measurement Soc		Behavioral modeling; LASSO; measurement system; power amplifier; regularization		In this paper we use regularization; in the form of the LASSO, as identification procedure in order to find the parameters of the parallel Hammerstein model for behavioral power amplifier modeling. It is shown that the LASSO chooses a subset of the parameters of the parallel Hammerstein model in a systematic way and thereby reduces the number of model parameters while maintaining the performance. The values of the parameters are also smaller than when the ordinary least-squares algorithm is used for the parameter extraction since the LASSO imposes a limit on the L1-norm of the parameters Thus, the problem with larger and sometimes very large, parameters that is often encountered in behavioral power amplifier modeling is avoided Experimental results from measurements on a power amplifier intended for the 3G WCDMA system is provided to support the theory.	[Wisell, David] Ericcson AB, SE-16480 Stockholm, Sweden	Wisell, D (reprint author), Ericcson AB, SE-16480 Stockholm, Sweden.	david.wisell@ericsson.com		Jalden, Joakim/0000-0001-6630-243X; Handel, Peter/0000-0002-2718-0262			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; *ETSI, 25141 EGPP TS ETSI; HEUTMAKER MS, 1996, ARFTG CLEARW FL US, V48; ISAKSSON M, 2006, IEEE MTT S SAN FRANS; Isaksson M, 2006, IEEE T MICROW THEORY, V54, P348, DOI 10.1109/TMTT.2005.860500; Isaksson M, 2007, INT J RF MICROW C E, V17, P542, DOI 10.1002/mmce.20253; Jalden J., 2002, THESIS ROYAL I TECHN; LANDIN P, 2008, IEEE MTT S IN PRESS; Ljung L, 1999, SYSTEM IDENTIFICATIO; Pedro JC, 2005, IEEE T MICROW THEORY, V53, P1150, DOI 10.1109/TMTT.2005.845723; Schetzen M., 1989, VOLTERRA WIENER THEO	11	4	4	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1091-5281		978-1-4244-1540-3	IEEE IMTC P			2008							1864	1867		10.1109/IMTC.2008.4547349		4	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	BIP18	WOS:000261512101101		
S	Solo, V			IEEE	Solo, Victor			A modified clean algorithm does l(1)-denoising	2008 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING, VOLS 1-12	International Conference on Acoustics Speech and Signal Processing (ICASSP)		English	Proceedings Paper	33rd IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 30-APR 04, 2008	Las Vegas, NV			l(1) denoising; sparse; CLEAN; estimation	LINEAR INVERSE PROBLEMS; REGRESSION; SELECTION; LASSO	The CLEAN algorithm is one of the best known signal processing algorithms in (radio-)astronomy. It is essentially a deconvolution procedure and is used e.g. to reconstruct a sparse (star) brightness distribution from noisy ('dirty' - hence 'cleaning') observed data. In this paper we make a connection for the first time between CLEAN and l(1)-denoising. We show CLEAN does a crude version of l(1)-denoising and develop a modified algorithm with much improved behaviour.	Univ New S Wales, Sch Elect Engn & Telecommun, Sydney, NSW 2052, Australia	Solo, V (reprint author), Univ New S Wales, Sch Elect Engn & Telecommun, Sydney, NSW 2052, Australia.						ALLINEY S, 1994, IEEE T SIGNAL PROCES, V42, P618, DOI 10.1109/78.277854; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Efron B, 2004, ANN STAT, V32, P407; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172; DONOHO DL, 1992, J ROY STAT SOC B MET, V54, P41; Forsythe G.E., 1960, FINITE DIFFERENCE ME; Hansen P., 1998, RANK DEFICIENT DISCR; Hogbom J. A., 1974, Astronomy and Astrophysics Supplement Series, V15; Ostrowski A., 1973, SOLUTION EQUATIONS E; SCHWARZ UJ, 1978, ASTRON ASTROPHYS, V65, P345; Southwell R V, 1935, P ROY SOC LOND A MAT, V151, P56, DOI 10.1098/rspa.1935.0134; STEWART GW, 1974, INTRO MATRIX COMPUTA; Temple G, 1939, PROC R SOC LON SER-A, V169, P476, DOI 10.1098/rspa.1939.0012; WELSH RE, 1980, REGRESSION DIAGNOSTI	19	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-1483-3	INT CONF ACOUST SPEE			2008							3665	3668		10.1109/ICASSP.2008.4518447		4	Acoustics; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Biomedical; Engineering, Electrical & Electronic; Mathematical & Computational Biology; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging; Telecommunications	Acoustics; Computer Science; Engineering; Mathematical & Computational Biology; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging; Telecommunications	BHY47	WOS:000257456702239		
S	Parvaresh, F; Hassibi, B			IEEE	Parvaresh, Farzad; Hassibi, Babak			Explicit measurements with almost optimal thresholds for compressed sensing	2008 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING, VOLS 1-12	International Conference on Acoustics Speech and Signal Processing (ICASSP)		English	Proceedings Paper	33rd IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 30-APR 04, 2008	Las Vegas, NV			convex optimization; sparse signals; Reed-Solomon codes; decoding algorithms; compressed sensing	REED-SOLOMON-CODES; RECONSTRUCTION	We consider the deterministic construction of a measurement matrix and a recovery method for signals that are block sparse. A signal that has dimension N = nd, which consists of n blocks of size d, is called (s, d)-block sparse if only s blocks out of n are nonzero. We construct an explicit linear mapping Phi that maps the (s, d)-block sparse signal to a measurement vector of dimension M, where s . d < N (1 - (1 -M/N) (d/d+1)) - o(1). We show that if the (s, d)-N block sparse signal is chosen uniformly at random then the signal can almost surely be reconstructed from the measurement vector in O(N-3) computations.	[Parvaresh, Farzad] CALTECH, Ctr Math Informat, Pasadena, CA 91125 USA	Parvaresh, F (reprint author), CALTECH, Ctr Math Informat, 1200 E Calif, Pasadena, CA 91125 USA.						AKCAKAYA M, ARXIVCS0703045; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes E, 2006, IEEE T INFORM THEORY; COPPERSMITH D., 2003, P 35 ACM S THEOR COM, P136; DONOHO DL, 2005, DISC COMPUT GEOMETRY; Guruswami V., 1999, IEEE T INFORM THEORY, V45, P1755; Maravic I, 2005, IEEE T SIGNAL PROCES, V53, P2788, DOI 10.1109/TSP.2005.850321; PARVARESH F, COMPRESSED SEN UNPUB; Roth RM, 2000, IEEE T INFORM THEORY, V46, P246, DOI 10.1109/18.817522; Sudan M, 1997, J COMPLEXITY, V13, P180, DOI 10.1006/jcom.1997.0439; TANNER J, 2006, P C INF SCI SYS MARC; Tao T., 2007, OPEN QUESTION DETERM	13	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-1483-3	INT CONF ACOUST SPEE			2008							3853	3856		10.1109/ICASSP.2008.4518494		4	Acoustics; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Biomedical; Engineering, Electrical & Electronic; Mathematical & Computational Biology; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging; Telecommunications	Acoustics; Computer Science; Engineering; Mathematical & Computational Biology; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging; Telecommunications	BHY47	WOS:000257456702286		
S	Mosci, S; Barla, A; Verri, A; Rosasco, L		Chen, Y; He, J; Reddy, CK; Yang, J; Yoo, I; Zhang, X; Gao, J; Huang, Y; Song, M; Yang, J; Wu, Z		Mosci, Sofia; Barla, Annalisa; Verri, Alessandro; Rosasco, Lorenzo			Finding structured gene signatures	2008 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE WORKSHOPS, PROCEEDINGS	IEEE International Conference on Bioinformatics and Biomedicine Workshop-BIBMW		English	Proceedings Paper	IEEE International Conference on Bioinformatics and Biomedicine	NOV 03-05, 2008	Philadelphia, PA	IEEE			EXPRESSION DATA; CANCER	In the context of gene signature identification from microarray data, a main problem is devising statistical and visual tools to interpret and understand the biological meaning of the selected genes. Most available statistical tools for gene signature extraction typically provide unstructured list of genes and lack the capability of handling correlation among genes. Recently an algorithm for feature selection, namely elastic net, was proposed allowing to deal with correlated genes in a transparent way. In this work we exploit the form of the output given by elastic net, as used in [3], to obtain a structured gene signature where genes are disposed in block of intra-correlated genes and the blocks are ranked according to a measure of the block discrminative power After recalling how elastic net can be used to define nested lists of increasingly intra-correlated genes, we propose an ad hoc agglomerative clustering technique able to refine such a nested output by explicitly identifying modules of correlated genes. We take advantage of such a structure to visualize the correlation patterns underlying the data. The proposed procedure is validated on both synthetic data and applied to real gene expression datasets.	[Mosci, Sofia] Univ Genoa, DIFI DISI, I-16146 Genoa, Italy	Mosci, S (reprint author), Univ Genoa, DIFI DISI, Via Dodecaneso 35, I-16146 Genoa, Italy.	mosci@disi.unige.it; barla@disi.unige.it; verri@disi.unige.it; lrosasco@mit.edu	Barla, Annalisa/K-6417-2015; 	Barla, Annalisa/0000-0002-3436-035X; rosasco, lorenzo/0000-0003-3098-383X			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hastie T, 2007, ELECTRON J STAT, V1, P1, DOI 10.1214/07-EJS004; Gordon GJ, 2002, CANCER RES, V62, P4963; BARLA A, 2008, P ESANN EUR S ART NE; DE MOL C., 2008, ELASTIC NET REGULARI; DEMOL C, 2007, REGULARIZED METHOD S; DESTRERO A, 2008, COMPUTATIONAL MANAGE; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hilsenbeck SG, 1999, J NATL CANCER I, V91, P453, DOI 10.1093/jnci/91.5.453; Li Y, 2002, BIOINFORMATICS, V18, P1332, DOI 10.1093/bioinformatics/18.10.1332; RAYCHAUDHURI S, 2000, PRINCIPAL COMPONENTS; SINGH D, 2002, CANC CELL, V1; ZOU H, 2005, J ROYAL STAT SOC B, V67	14	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2163-6966		978-1-4244-2890-8	IEEE INT C BIO BIO W			2008							158	165		10.1109/BIBMW.2008.4686230		8	Engineering, Biomedical	Engineering	BIQ62	WOS:000262067000030		
S	He, F; Brown, M; Yeung, LF			IEEE	He, Fei; Brown, Martin; Yeung, Lam Fat			On the Complexity - Sensitivity Trade-off for the NF-kappa B Pathway Modeling	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			GENE-EXPRESSION; OSCILLATIONS; SELECTION; DYNAMICS; MODULE	An important aspect of systems biology research is the so-called "reverse engineering" of cellular metabolic dynamics from measured input-output data. This allows researchers to estimate and validate both the pathway's structure as well as the kinetic constants. In this paper, a regularization based method which performs model structure selection is developed and applied to the problem of analyzing how existing pathway knowledge can be used as a prior investigate the model change complexity/sensitivity trade-off. Specifically, a 1-norm prior on parameter deviations from an existing model of the I kappa B-NF-kappa B pathway is combined with new experimental data and an analysis is performed to determine which are the most relevant components to alter.	[He, Fei; Brown, Martin] Univ Manchester, Sch Elect & Elect Engn, Manchester M60 1QD, Lancs, England	He, F (reprint author), Univ Manchester, Sch Elect & Elect Engn, Manchester M60 1QD, Lancs, England.	fei.he@postgrad.manchester.ac.uk; martin.brown@manchester.ac.uk; eelyeung@cityu.edu.hk					Hoffmann A, 2002, SCIENCE, V298, P1241, DOI 10.1126/science.1071914; Kearns JD, 2006, J CELL BIOL, V173, P659, DOI 10.1083/jcb.200510155; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Rao CV, 2002, NATURE, V420, P231, DOI 10.1038/nature01258; Lipniacki T, 2004, J THEOR BIOL, V228, P195, DOI 10.1016/j.jtbi.2004.01.001; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; JIN Y, AM CONTR C 2007 NEW; KRUSE K, 2006, SYSTEMS MODELLING CE; Nelson DE, 2004, SCIENCE, V306, P704, DOI 10.1126/science.1099962; Saltelli A., 2000, SENSITIVITY ANAL; SZALLASI Z, 2006, SYSTEMS MODELLING CE; Voit EO, 2000, COMPUTATIONAL ANAL B; Wilkinson SJ, 2008, MOL BIOSYST, V4, P74, DOI 10.1039/b707506e; Yue H, 2006, MOL BIOSYST, V2, P640, DOI 10.1039/b609442b	14	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1820-6	IEEE IJCNN			2008							3933	3940		10.1109/IJCNN.2008.4634363		8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827202123		
S	Cecchi, GA; Garg, R; Rao, AR			IEEE	Cecchi, Guillermo A.; Garg, Rahul; Rao, A. Ravishankar			Inferring brain dynamics using Granger causality on fMRI data	2008 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: FROM NANO TO MACRO, VOLS 1-4	IEEE International Symposium on Biomedical Imaging		English	Proceedings Paper	5th IEEE International Symposium on Biomedical Imaging	MAY 14-17, 2008	Paris, FRANCE	IEEE		magnetic resonance imaging; image interpretation; functional imaging	CONNECTIVITY; REGRESSION	Here we present a scalable method to compute the structure of causal links over large scale dynamical systems that achieves high efficiency in discovering actual functional connections. The method is based on the Granger causality analysis of multivariate linear models, solved by means of a sparse regression approach, and can deal with autoregressive models of more than 10,000 variables.	[Cecchi, Guillermo A.; Garg, Rahul; Rao, A. Ravishankar] IBM Corp, Thomas J Watson Res Ctr, Computat Biol Ctr, Yorktown Hts, NY 10598 USA	Cecchi, GA (reprint author), IBM Corp, Thomas J Watson Res Ctr, Computat Biol Ctr, Box 218, Yorktown Hts, NY 10598 USA.						Arieli A, 1996, SCIENCE, V273, P1868, DOI 10.1126/science.273.5283.1868; Baccala LA, 2001, BIOL CYBERN, V84, P463, DOI 10.1007/PL00007990; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Rodriguez E, 1999, NATURE, V397, P430; Friston KJ, 2000, P NATL ACAD SCI USA, V97, P7591, DOI 10.1073/pnas.97.13.7591; Efron B, 2004, ANN STAT, V32, P407; Cecchi GA, 2007, BMC CELL BIOL, V8, DOI 10.1186/1471-2121-8-S1-S5; Eguiluz VM, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.018102; Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Valdes-Sosa PA, 2005, PHILOS T ROY SOC B, V360, P969, DOI 10.1098/rstb.2005.1654; Weisberg S., 1980, APPL LINEAR REGRESSI	11	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1945-7928		978-1-4244-2002-5	I S BIOMED IMAGING			2008							604	607		10.1109/ISBI.2008.4541068		4	Engineering, Biomedical; Engineering, Electrical & Electronic; Nanoscience & Nanotechnology; Imaging Science & Photographic Technology	Engineering; Science & Technology - Other Topics; Imaging Science & Photographic Technology	BIB70	WOS:000258259800152		
B	Omidiran, D; Wainwright, MJ			IEEE	Omidiran, Dapo; Wainwright, Martin J.			High-dimensional subset recovery in noise: Sparse measurements and statistical efficiency	2008 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY PROCEEDINGS, VOLS 1-6			English	Proceedings Paper	IEEE International Symposium on Information Theory	JUL 06-11, 2008	Toronto, CANADA	IEEE, RIM, Ontario Cent Excellence, IBM Res, Microsoft Res			LARGE UNDERDETERMINED SYSTEMS; EQUATIONS	We consider the problem of estimating the support of a vector beta* epsilon R(P) based on observations contaminated by noise. A significant body of work has studied behavior of l(1)-relaxations when applied to measurement matrices drawn from standard dense ensembles (e.g., Gaussian, Bernoulli). In this paper, we analyze sparsifted measurement ensembles, and consider the trade-off between measurement sparsity, as measured by the fraction gamma of non-zero entries, and the statistical efficiency, as measured by the minimal number of observations n required for exact support recovery with probability converging to one. Our main result is to prove that it is possible to let gamma -> 0 at some rate, yielding measurement matrices with a vanishing fraction of non-zeros per row while retaining the same statistical efficiency (sample size n) as dense ensembles. A variety of simulation results confirm the sharpness of our theoretical predictions.	[Omidiran, Dapo; Wainwright, Martin J.] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Omidiran, D (reprint author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	dapo@eecs.berkeley.edu; wainwrig@eecs.berkeley.edu					Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Feldman J, 2007, IEEE T INFORM THEORY, V53, P82, DOI 10.1109/TIT.2006.887523; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; COMMODE G, 2005, ALGORITHMIC THEORY C; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Gilbert AC, 2006, P ALL C COMM CONTR C; MEINSHAUSEN N, 2006, ANN STAT IN PRESS; OMIDIRAN D, 2008, INT S INF THEOR JUL; RAVIKUMAR P, 2008, NIPS C DEC 2006; SARVOTHAM S, 2006, INT S INF THEOR SEAT; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Vershynin R., 2000, ACTA MATH U COMENIAN, V69, P137; WAINWRIGHT MJ, 2006, 709 UC DEP STAT; WANG W, 2008, INT S INF THEOR JUL; Xu W., 2007, IEEE INF THEOR WORKS, P414	18	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2256-2				2008							2192	2196		10.1109/ISIT.2008.4595379		5	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BIK25	WOS:000260364401162		
S	Li, Y; Tsin, Y; Genc, Y; Kanade, T			IEEE	Li, Yan; Tsin, Yanghai; Genc, Yakup; Kanade, Takeo			Flexible Edge Arrangement Templates for object detection	2008 IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION	IEEE Workshop on Applications of Computer Vision		English	Proceedings Paper	IEEE Workshop on Applications of Computer Vision	JAN 07-09, 2008	Copper Mt, CO				REGRESSION	We present a novel feature representation for categorical object detection. Unlike previous approaches that have concentrated on generic interest-point detectors, we construct object-specific features directly from the training images. Our feature is represented by a collection of Flexible Edge Arrangement Templates (FEATs). We propose a two-stage semi-supervised learning approach to feature selection. A subset of frequent templates are first selected from a large template pool. In the second stage, we formulate feature selection as a regression problem and use LASSO method to find the most discriminative templates from the pre-selected ones. FEATs adaptively capture the image structure and naturally accommodate local shape variations. We show that this feature can be complemented by the traditional holistic patch method, thus achieving both efficiency and accuracy. We evaluate our method on three well-known car datasets, showing performance competitive with existing methods.	[Li, Yan; Kanade, Takeo] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Li, Y (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.						AMIT Y, 1997, 459 U CHIC DEP STAT; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478; Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Efron B, 2004, ANN STAT, V32, P407; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Bay H., 2006, ECCV; Canny J, 1986, PAMI, V8, P679, DOI DOI 10.1109/TPAMI.1986.4767851; Csurka G., 2004, ECCV WORKSH STAT LEA; Dalal N., 2005, CVPR; Fei- Fei L., 2005, CVPR; Fei-Fei L., 2004, CVPR WORKSH GEN MOD; Fergus R., 2003, CVPR; Ferrari V., 2006, ECCV; GOODMAN J, 2004, ACL; Grauman K., 2005, CVPR; Grimson E, 1981, IMAGES SURFACES COMP; Hastie T., 2001, ELEMENTS STAT LEARNI; Lazebnik S., 2006, CVPR; LEIBE B, 2004, STAT LEARN COMP VIS; Lepetit V., 2005, CVPR; Mikolajczyk K., 2005, IJCV, V65; Opelt A., 2006, ECCV; SHOTTON J, 2004, ICML; Shotton J., 2005, ICCV	26	0	0	0	18	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-5790		978-1-4244-1913-5	IEEE WORK APP COMP			2008							67	74		10.1109/CHICC.2008.4605286		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BIE39	WOS:000258906400011		
S	Gasso, G; Rakotomamonjy, A; Canu, S			IEEE	Gasso, Gilles; Rakotomamonjy, Alain; Canu, Stephane			SOLVING NON-CONVEX LASSO TYPE PROBLEMS WITH DC PROGRAMMING	2008 IEEE WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING	IEEE Workshop on Machine Learning for Signal Processing		English	Proceedings Paper	IEEE Workshop on Machine Learning for Signal Processing	OCT 16-19, 2008	Cancun, MEXICO	IEEE Signal Processing Soc, IEEE		variable selection; non-convex penalization; DC programming; coordinatewise optimization	LOGISTIC-REGRESSION; VARIABLE SELECTION; ORACLE PROPERTIES; OPTIMIZATION; ALGORITHM	The paper proposes a novel algorithm for addressing variable selection (or sparsity recovering) problem using non-convex penalties. A generic framework based on a DC programming is presented and yields to an iterative weighted lasso-type problem. We have then showed that many existing approaches for solving such a non-convex problem are particular cases of our algorithm. We also provide some empirical evidence that our algorithm outperforms existing ones.	[Gasso, Gilles; Rakotomamonjy, Alain; Canu, Stephane] Univ Rouen, INSA, LITIS EA 4108, F-76081 St Etienne, France	Gasso, G (reprint author), Univ Rouen, INSA, LITIS EA 4108, Ave Univ, F-76081 St Etienne, France.	gilles.gasso@insa-rouen.fr; alain.rakotomamonjy@univ-rouen.fr; stephane.canu@insa-rouen.fr					Tao PD, 1998, SIAM J OPTIMIZ, V8, P476, DOI 10.1137/S1052623494274313; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Tibshirani R., 1996, J ROY STAT SOC, V46, P431; VISHWANATHAN SVN, 2003, ICML; ZHANG T., 2007, SOME SHARP PERFORMAN; ZOU H, ANN STAT IN PRESS	14	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1551-2541		978-1-4244-2375-0	MACHINE LEARN SIGN P			2008							450	455		10.1109/MLSP.2008.4685522		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BJK47	WOS:000266687900077		
B	Aeron, S; Zhao, M; Saligrania, V			IEEE	Aeron, Shitchin; Zhao, Manqi; Saligrania, Venkatesh			ALGORITHMS AND BOUNDS FOR SENSING CAPACITY AND COMPRESSED SENSING WITH APPLICATIONS TO LEARNING GRAPHICAL MODELS	2008 INFORMATION THEORY AND APPLICATIONS WORKSHOP			English	Proceedings Paper	IEEE Information Theory and Applications Workshop	JAN, 2008	San Diego, CA	IEEE		Sensing capacity; SNR level; Compressed Sensing; LASSO; LP; Learning Graphical Models	SIGNAL RECONSTRUCTION	We consider the problem of recovering sparse phenomena from projections of noisy data, a topic of interest in compressed sensing. We describe the problem in terms of sensing capacity, which we define as the supremum of the ratio of the number of signal dimensions that can be identified per projection. This notion quantifies minimum number of observations required to estimate a signal as a function of sensing channel, SNR, sensed environment(sparsity) as well as desired distortion up to which the sensed phenomena must be reconstructed. We first present bounds for two different sensing channels: (A) i.i.d. Gaussian observations (B) Correlated observations. We then extend the results derived for the correlated case to the problem of learning sparse graphical models. We then present convex programming methods for the different distortions for the correlated case. We then comment on the differences between the achievable bounds and the performance of convex programming methods.	[Aeron, Shitchin; Zhao, Manqi; Saligrania, Venkatesh] Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA	Aeron, S (reprint author), Boston Univ, Dept Elect & Comp Engn, 8 St Marys St, Boston, MA 02215 USA.		Aeron, Shuchin/F-9745-2013				Aeron S., 2007, IEEE INF THEOR WORKS; AERON S, 2007, IEEE STAT SIGN PROC; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Haupt J, 2006, IEEE T INFORM THEORY, V52, P4036, DOI 10.1109/TIT.2006.880031; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; BARANIUK R, CONSTRUCTIV IN PRESS; BASSO K, 2005, NATURE GENETICS; Candes E. J., COMM PURE APPL MATH, V59, P1207; CANDES EJ, 2004, NEAR OPTIMAL SIGNAL; DUARTE MF, 2006, INT C AC SPEECH SIGN; FAN J, 2001, J AM STAT ASSOC, V96, P1138; Tropp JA, 2005, IEEE T INFORM THEORY, V51, P1568, DOI 10.1109/TIT.2005.844057; TROPP JA, 2006, IEEE T INFORM THEORY, V51, P1030; Wainwright M.J., 2006, ALL C COMM CONTR COM	16	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2670-6				2008							345	351				7	Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BIM85	WOS:000260931800055		
B	Schniter, P; Potter, LC; Ziniel, J			IEEE	Schniter, Philip; Potter, Lee C.; Ziniel, Justin			Fast Bayesian Matching Pursuit	2008 INFORMATION THEORY AND APPLICATIONS WORKSHOP			English	Proceedings Paper	IEEE Information Theory and Applications Workshop	JAN, 2008	San Diego, CA	IEEE			SIGNAL RECOVERY; BASIS SELECTION; REGRESSION; VECTOR	A low-complexity recursive procedure is presented for minimum mean squared error (MMSE) estimation in linear regression models. A Gaussian mixture is chosen as the prior on the unknown parameter vector. The algorithm returns both an approximate MMSE estimate of the parameter vector and a set of high posterior probability mixing parameters. Emphasis is given to the case of a sparse parameter vector. Numerical simulations demonstrate estimation performance and illustrate the distinctions between MMSE estimation and MAP model selection. The set of high probability mixing parameters not only provides MAP basis selection, but also yields relative probabilities that reveal potential ambiguity in the sparse model.	[Schniter, Philip; Potter, Lee C.; Ziniel, Justin] Ohio State Univ, Dept ECE, Columbus, OH 43210 USA	Schniter, P (reprint author), Ohio State Univ, Dept ECE, Columbus, OH 43210 USA.	schniter@ece.osu.edu; potter@ece.osu.edu; ziniel.I@osu.edu	Schniter, Philip/A-7336-2012; Potter, Lee/F-8668-2014				Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016; Larsson EG, 2007, IEEE T SIGNAL PROCES, V55, P451, DOI 10.1109/TSP.2006.887109; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251; Cetin M, 2001, IEEE T IMAGE PROCESS, V10, P623, DOI 10.1109/83.913596; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Bouman C, 1993, IEEE Trans Image Process, V2, P296, DOI 10.1109/83.236536; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Delaney AH, 1996, IEEE T IMAGE PROCESS, V5, P740, DOI 10.1109/83.495957; Donoho D. L., 2006, 200602 STANF U DEP S; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hogbom J. A., 1974, Astronomy and Astrophysics Supplement Series, V15; JI S, 2007, P 24 INT C MACH LEAR; Kuppusamy P, 2004, ANTIOXID REDOX SIGN, V6, P583, DOI 10.1089/152308604773934332; LEE H, 1987, IEEE INT C AC SPEECH, P1569; LEVY S, 1981, GEOPHYSICS, V46, P1235, DOI 10.1190/1.1441261; Pati Y. C., 1993, P 27 ANN AS C SIGN S; Poor H. V., 1994, INTRO SIGNAL DETECTI	23	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2670-6				2008							368	375				8	Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BIM85	WOS:000260931800058		
J	Anagnostopoulos, C; Adams, N		AlDabass, D; Orsoni, A; Brentnall, A; Abraham, A; Zobel, R		Anagnostopoulos, Christoforos; Adams, Niall			Simulating dynamic covariance structures for testing the adaptive behavior of variable selection algorithms	2008 UKSIM TENTH INTERNATIONAL CONFERENCE ON COMPUTER MODELING AND SIMULATION			English	Proceedings Paper	UKSim 10th International Conference on Computer Modelling and Simulation (EUROSIM/UKSim)	APR 01-03, 2008	Cambridge, ENGLAND	IEEE, IEEE Comp Soc, UK Simulat Soc (UKSim), European Federat Simulat Soc (EUROSIM), European Council Modelling & Simulat (ECMS), Kingston Univ, Imperial Coll Sci, Technol & Med, Norwegian Univ Sci & Technol, Nottingham Trent Univ, Univ Technol Malaysia (UTM)	Emmanuel Coll		REGRESSION	Variable selection for regression is a classical statistical problem, motivated by concerns that too large a number of covariates may bring about overfitting and unnecessarily high measurement costs. Novel difficulties arise in streaming contexts, where the correlation structure of the process may be drifting, in which case it must be constantly tracked so that selections may be revised accordingly. A particularly interesting phenomenon is that non-selected covariates become missing variables, inducing bias on subsequent decisions. This raises an intricate exploration-exploitation tradeoff, whose dependence on the covariance tracking algorithm and the choice of variable selection scheme is too complex to be dealt with analytically. We hence capitalise on the strength of simulations to explore this problem, taking the opportunity to tackle the difficult task of simulating dynamic correlation structures.	[Anagnostopoulos, Christoforos; Adams, Niall] Univ London Imperial Coll Sci Technol & Med, Maths Dept, London W7 2AZ, England	Anagnostopoulos, C (reprint author), Univ London Imperial Coll Sci Technol & Med, Maths Dept, London W7 2AZ, England.						Anagnostopoulos C., 2008, P ACM S APP IN PRESS, V2; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; BREIMAN L, 1992, J AM STAT ASSOC, V87, P738, DOI 10.2307/2290212; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; Efron B, 2004, ANN STAT, V32, P407; Chiu T., 1996, J AM STAT ASS, V91; Deshpande A., 2004, P 30 VLDB C; Gunter L, 2007, P 11 C ART INT MED; Hellerstein J, 2000, IEEE DATA ENG B, V23, P7; Platanioti K., 2005, ESTIMATION METHODS U; Sjostrand K., 2005, MATLAB IMPLEMENTATIO; Sutton R. S., 1992, REINFORCEMENT LEARNI; Vermorel J., 2005, P 16 EUR C MACH LEAR, P437; Yi B.-K., 2000, ONLINE DATA MINING C, P13	15	0	0	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3114-4				2008							52	57		10.1109/UKSIM.2008.92		6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BAN67	WOS:000304857300010		
S	Mukherjee, S; Fradkin, D; Roth, M			IEEE Computer Society	Mukherjee, Saikat; Fradkin, Dmitriy; Roth, Michael			Classifying Spend Descriptions with off-the-shelf Learning Components	20TH IEEE INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, VOL 1, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	20th IEEE International Conference on Tools with Artificial Intelligence	NOV 03-05, 2008	Dayton, OH	IEEE Comp Soc, Biol & Artificial Intelligence Soc, Wright State Univ, Univ Patras, Virginia Tech			REGRESSION	Analyzing spend transactions is essential to organizations for understanding their global procurement. Central to this analysis is the automated classification of these transactions to hierarchical commodity coding systems. Spend classification is challenging due not only to the complexities of the commodity coding systems but also because of the sparseness and quality of each individual transaction text description and the volume of such transactions in an organization. In this paper, we demonstrate the application of off-the-shelf machine learning tools to address the challenges in spend classification. We hove built a system using off-the-shelf SVM, Logistic Regression, and language processing toolkits and describe the effectiveness of these different learning techniques for spend classification.	[Mukherjee, Saikat; Fradkin, Dmitriy; Roth, Michael] Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA	Mukherjee, S (reprint author), Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA.	saikat.mukherjee@siemens.com; dmitrity.fradkin@siemens.com; michael.roth.ext@siemens.com					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wu TF, 2004, J MACH LEARN RES, V5, P975; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Balakrishnan S, 2008, J MACH LEARN RES, V9, P313; BRILL E, 2000, P ANN M ASS COMP LIN; Cai Lijuan, 2004, ACM C INF KNOWL MAN; Cauwenberghs G., 2000, ADV NEURAL INFORM PR; Chang C., 2001, LIBSVM LIB SUPPORT V; Clarkson P., 1997, P ESCA EUR; Crammer K., 2000, COMPUTATIONAL LEARNI, P35; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; DUMAIS S, 2000, ACM C INF RETR SIGIR; Friedman J., 1996, ANOTHER APPROACH POL; Gusfield D., 1997, ALGORITHMS STRINGS T; Hsu Chih-Wei, 2002, IEEE T NEURAL NETWOR, V13; Joachims T, 1998, EUR C MACH LEARN; KOLAK O, 2005, P HUM LANG TECHN C C; Koller D., 1997, P 14 INT C MACH LEAR, P170; Kukich K., 1992, ACM COMPUTING SURVEY, V24; Laskov P, 2006, J MACH LEARN RES, V7, P1909; LEWIS DD, 1992, TEXT-BASED INTELLIGENT SYSTEMS : CURRENT RESEARCH AND PRACTICE IN INFORMATION EXTRACTION AND RETRIEVAL, P179; MADIGAN D, 2005, P JOINT ANN M CLASS; Marzal A., 1993, IEEE T PATTERN ANAL, V15; Miller G., 1990, INT J LEXICOGRAPHY, V3; ROUSU J, 2005, P INT C MACH LEARN; Salton G., 1983, INTRO MODERN INFORM; SINGH M, 2005, INT C INF KNOWL MAN; Vapnik Vladimir, 1998, NATURE STAT LEARNING; Weston J., 1998, CSDTR9804 U LOND DEP; ZADROZNY B, 2002, P ACM SIGKDD 02	31	0	0	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		978-0-7695-3440-4	PROC INT C TOOLS ART			2008							53	60		10.1109/ICTAI.2008.95		8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BIR42	WOS:000262214700007		
S	Fradkin, D			IEEE Computer Society	Fradkin, Dmitriy			Clustering Inside Classes Improves Performance of Linear Classifiers	20TH IEEE INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, VOL 2, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	20th IEEE International Conference on Tools with Artificial Intelligence	NOV 03-05, 2008	Dayton, OH	IEEE Comp Soc, Biol & Artificial Intelligence Soc, Wright State Univ, Univ Patras, Virginia Tech				This work systematically examines a Clustering Inside Classes (CIC) approach to classification. In CIC, each class is partitioned into subclasses based on cluster analysis. We find that CIC, by extracting local structure and producing compact subclasses, can improve performance of linear classifiers such as SVM and logistic regression. It is compared against a global classifier on four benchmark datasets. We empirically analyze effects of the training set size and the number of clusters per class on the results of the CIC approach. We also examine use of an automated method for selecting the number of clusters for each class.	Siemens Corp Res, Princeton, NJ 08540 USA	Fradkin, D (reprint author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.	dmitriy.fradkin@siemens.com					MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; FORGY EW, 1965, BIOMETRICS, V21, P768; Blake C.L., 1998, UCI REPOSITORY MACHI; Chang C., 2001, LIBSVM LIB SUPPORT V; FARLEY C, 2002, J AM STAT ASSOC, V97, P611; FRADKIN D, 2006, THESIS STATE U NEW J; JAPKOWICZ N, 2002, P IASTED INT C ART I, P321; JUNJIE PW, 2007, P KDD 2007, P814; Lloyd S. P., 1957, IEEE T INFORMATION T, VIT-28, P128; MADIGAN D, 2005, P JOINT ANN M CLASS; Pelleg D., 2000, P 17 INT C MACH LEAR, P727; Vapnik Vladimir, 1998, NATURE STAT LEARNING; VILALTA R, 2003, P EUR C MACH LEARN, P444	15	0	0	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		978-0-7695-3440-4	PROC INT C TOOLS ART			2008							439	442		10.1109/ICTAI.2008.29		4	Computer Science, Artificial Intelligence	Computer Science	BIR43	WOS:000262215500059		
S	Lyzell, C; Roll, J; Ljung, L			IEEE	Lyzell, Christian; Roll, Jacob; Ljung, Lennart			The Use of Nonnegative Garrote for Order Selection of ARX Models	47TH IEEE CONFERENCE ON DECISION AND CONTROL, 2008 (CDC 2008)	IEEE Conference on Decision and Control		English	Proceedings Paper	47th IEEE Conference on Decision and Control	DEC 09-11, 2008	Cancun, MEXICO	IEEE, Soc Ind & Appl Math (SIAM), Inst Operat Res & Management Sci (INFORMS), Japanese Soc Instrument & Control Engn (SICE), European Union Control Assoc (EUCA), Taylor & Francis Grp, StatoilHydro	IEEE Control Syst Soc (CSS)		REGRESSION	Order selection of linear regression models has been thoroughly researched in the statistical community for some time. Different shrinkage methods have been proposed, such as the Ridge and Lasso regression methods. Especially the Lasso regression has won fame because of its ability to set less important parameters exactly to zero. However, these methods do not take dynamical systems into account, where the regressors are ordered via the time lag. To this end, a modified variant of the nonnegative garrote method will be analyzed.	[Lyzell, Christian; Roll, Jacob; Ljung, Lennart] Linkoping Univ, Div Automat Control, SE-58183 Linkoping, Sweden	Lyzell, C (reprint author), Linkoping Univ, Div Automat Control, SE-58183 Linkoping, Sweden.	lyzell@isy.liu.se; roll@isy.liu.se; ljung@isy.liu.se	Ljung, Lennart/B-3822-2014	Ljung, Lennart/0000-0003-4881-8955			BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; ASTROM KJ, 1971, AUTOMATICA, V7, P123; Ljung L, 1999, SYSTEM IDENTIFICATIO; Niu SS, 1996, IEEE T SIGNAL PROCES, V44, P2847, DOI 10.1109/78.542442; Roll J., 2007, AUTOMATICA IN PRESS; Tondel P, 2003, 42ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, PROCEEDINGS, P3173; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Zhoe K., 1995, ROBUST OPTIMAL CONTR	10	3	3	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0191-2216		978-1-4244-3124-3	IEEE DECIS CONTR P			2008							1974	1979				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BBL77	WOS:000307311602017		
S	Bobin, J; Starck, JL; Moudden, Y; Fadili, MJ		Hawkes, PW		Bobin, Jerome; Starck, Jean-Luc; Moudden, Yassir; Fadili, Mohamed Jalal			Blind Source Separation: The Sparsity Revolution	ADVANCES IN IMAGING AND ELECTRON PHYSICS, VOL 152	Advances in Imaging and Electron Physics		English	Review; Book Chapter							INDEPENDENT COMPONENT ANALYSIS; LINEAR INVERSE PROBLEMS; MORPHOLOGICAL DIVERSITY; ATOMIC DECOMPOSITION; MATCHING PURSUITS; REPRESENTATION; DICTIONARIES; ALGORITHM; BASES; STATISTICS		[Bobin, Jerome; Starck, Jean-Luc; Moudden, Yassir] Univ Paris Diderot, CEA Saclay, Lab AIM, CEA DSM,CNRS,IRFU SEDI SAP,Serv Astrophys, F-91191 Gif Sur Yvette, France; [Fadili, Mohamed Jalal] ENSICAEN, Image Proc Grp, GREYC CNRS UMR 6072, F-14050 Caen, France	Bobin, J (reprint author), Univ Paris Diderot, CEA Saclay, Lab AIM, CEA DSM,CNRS,IRFU SEDI SAP,Serv Astrophys, F-91191 Gif Sur Yvette, France.		Starck, Jean-Luc/D-9467-2011; Bobin, Jerome/P-3729-2014	Bobin, Jerome/0000-0003-1457-7890			AKAIKE H, 1970, ANN I STAT MATH, V22; Amari S, 1999, IEEE T SIGNAL PROCES, V47, P936, DOI 10.1109/78.752592; AMARI S, IEEE T SIGNAL PROCES, V45; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Bobin J, 2007, IEEE T IMAGE PROCESS, V16, P2662, DOI 10.1109/TIP.2007.906256; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI 10.1109/TIP.2002.1014998; Li YQ, 2006, IEEE T SIGNAL PROCES, V54, P423, DOI 10.1109/TSP.2005.861743; Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031; Candes EJ, 1999, PHILOS T R SOC A, V357, P2495; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Efron B, 2004, ANN STAT, V32, P407; Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307; Starck JL, 2004, ADV IMAG ELECT PHYS, V132, P287, DOI 10.1016/S1076-5670(04)32006-9; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410; Fornasier M, 2008, SIAM J NUMER ANAL, V46, P577, DOI 10.1137/0606668909; Cardoso JF, 1999, NEURAL COMPUT, V11, P157, DOI 10.1162/089976699300016863; Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; BALAN R, 2006, LNCS, V4666, P333; Barlow H, 1961, SENS COMMUN, P217; BENNETT C, 2008, ASTROPHYS J SUPPL, V148; Bobin J, 2007, IEEE T IMAGE PROCESS, V16, P2675, DOI 10.1109/TIP.2007.907073; Bobin J, 2006, IEEE SIGNAL PROC LET, V13, P409, DOI 10.1109/LSP.2006.873141; BOBIN J, J MATH IMAG IN PRESS; BOBIN J, GMCALAB; BOBIN J, 2007, P SPIE C WAV SPIE; BOBIN J, 2006, ICASSP 06, V5, P833; Bouchet FR, 1999, NEW ASTRON, V4, P443, DOI 10.1016/S1384-1076(99)00027-5; Bronstein AM, 2005, INT J IMAG SYST TECH, V15, P84, DOI 10.1002/ima.20042; BRUCKSTEIN A, 2008, SIAM REV IN PRESS; Candes E. J., 2007, SIAM MULTISCALE MODE, V5, P861, DOI DOI 10.1137/05064182X; Candes E.J., 1999, CURVELETS; Cardoso J., 2003, J MACHINE LEARNING R, V4, P1177, DOI 10.1162/jmlr.2003.4.7-8.1177; CARDOSO JF, 2001, P ICA SAN DIEG CA; Cardoso JF, 1997, IEEE SIGNAL PROC LET, V4, P112, DOI 10.1109/97.566704; CHEN J, 2005, ICASSP 05; Cichocki A., 2002, ADAPTIVE BLIND SIGNA; COMBETTES FL, 2005, SIAM J MULTISCALE MO, V4, P1168; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; *CURV, CURV 2 1 MATLAB 7 X; DARMOIS G, 1953, REV I INT STAT, P2; Davies M, 2004, IEEE SIGNAL PROC LET, V11, P470, DOI 10.1109/LSP.2004.826508; DEMANET L, 2006, WAVE ATOMS IN PRESS; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Donoho D. L., IEEE T INFORM UNPUB; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; DONOHO DL, C MATH CHALL 21 CENT; Donoho DL, 1998, IEEE T INFORM THEORY, V44, P2435, DOI 10.1109/18.720544; Donoho D. L., 1993, Applied and Computational Harmonic Analysis, V1, DOI 10.1006/acha.1993.1008; Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005; Elad M, 2006, IEEE T INFORM THEORY, V52, P5559, DOI 10.1109/TIT.2006.885522; FADILI MJ, 2005, COMPUT J IN PRESS; Feuer A, 2003, IEEE T INFORM THEORY, V49, P1579, DOI 10.1109/TIT.2003.811926; Field DJ, 1999, PHILOS T R SOC A, V357, P2527, DOI 10.1098/rsta.1999.0446; FUCHS JJ, 2006, ICASSP 06, V3, P337; Fuchs JJ, 2004, IEEE T INFORM THEORY, V50, P1341, DOI 10.1109/TIT.2004.828141; Georgiev P, 2005, IEEE T NEURAL NETWOR, V16, P992, DOI 10.1109/TNN.2005.849840; Gribonval R., 2006, ADV COMPUT MATH, V28, P23; Gribonval R, 2006, IEEE T INFORM THEORY, V52, P255, DOI 10.1109/TIT.2005.860474; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Ichir MM, 2006, IEEE T IMAGE PROCESS, V15, P1887, DOI 10.1109/TIP.2006.877068; Jourjine A, 2000, IEEE INT C AC SPEECH, V5, P2985; Jungman G, 1996, PHYS REV D, V54, P1332, DOI 10.1103/PhysRevD.54.1332; Koldovsky Z, 2006, INT CONF ACOUST SPEE, P873; Koldovsky Z, 2006, IEEE T NEURAL NETWOR, V17, P1265, DOI 10.1109/TNN.2006.875991; LEE TW, 1998, UNIFYING INFORM THEO; Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753; Li YQ, 2006, IEEE T INFORM THEORY, V52, P3139, DOI 10.1109/TIT.2006.876348; MAIRAL J, 2006, SPARSE REPRESE UNPUB; Malioutov D. M., 2005, IEEE INT C AC SPEECH, VV, P733; Mallat S., 1998, WAVELET TOUR SIGNAL; MEYER Y, COMMUNICATION; MOUDDEN Y, 2005, EURASIP J APPL SIG P, V15, P2437; NADAL JP, 1994, NETWORK, V4, P295; Olshausen B., 1998, VISION RES, V37, P3311; PEARLMUTTER B, 1997, ADV NEURAL INFORM P, V9; PEYRE G, 2007, SSVM 2007; PEYRE G, 2007, SSVM 07; Pham DT, 1992, P EUSIPCO, P771; Plumbley MD, 2006, LECT NOTES COMPUT SC, V3889, P206; SAITO N, 2003, STUDIES COMPUTATIONA, V109, P225; Sallee P., 2002, ADV NEURAL INFORM PR, V15, P1327; Sardy S, 2000, J COMPUT GRAPH STAT, V9, P361, DOI 10.2307/1390659; Starck J. L., 2002, IEEE T IMAGE PROCESS, V11, P131; Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206; Starck JL, 2007, IEEE T IMAGE PROCESS, V16, P297, DOI 10.1109/TIP.2006.887733; SUNYAEV R, 1980, ANN REV ASTRON ASTRO, V18; TROPP J, SIGNAL RECOVERY PART; Vetterli M, 2001, IEEE SIGNAL PROC MAG, V18, P59, DOI 10.1109/79.952805; Vincent E., 2007, P INT C IND COMP AN, P430; Zibulevsky M., 2003, P 4 INT S IND COMP A, P897; Zibulevsky M, 2001, NEURAL COMPUT, V13, P863, DOI 10.1162/089976601300014385; 2005, WAVELAB 850 MATLAB 7	105	23	25	1	10	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA	1076-5670		978-0-12-374219-3	ADV IMAG ELECT PHYS	Adv. Imag. Electron Phys.		2008	152						221	302		10.1016/S1076-5670(08)00605-8		82	Physics, Applied	Physics	BIJ87	WOS:000260166100005		
S	Gao, JB; Antolovich, M; Kwan, PW		Wobcke, W; Zhang, M		Gao, Junbin; Antolovich, Michael; Kwan, Paul W.			L1 LASSO Modeling and Its Bayesian Inference	AI 2008: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	21st Australian Joint Conference on Artificial Intelligence	DEC 01-05, 2008	Auckland, NEW ZEALAND		Auckland Univ Technol		REGRESSION; IDENTIFICATION	A new iterative procedure for solving regression problems with the so-called LASSO penalty [1] is proposed by using generative Bayesian modeling and inference. The algorithm produces the anticipated parsimonious or sparse regression models that generalize well on unseen data. The proposed algorithm is quite robust and there is no need to specify any model hyperparameters. A comparison with state-of-the-art methods for constructing sparse regression models such as the relevance vector machine (RVM) and the local regularization assisted orthogonal least squares regression (LROLS) is given.	[Gao, Junbin; Antolovich, Michael] Charles Sturt Univ, Sch Comp Sci & Accounting, Bathurst, NSW 2795, Australia	Gao, JB (reprint author), Charles Sturt Univ, Sch Comp Sci & Accounting, Bathurst, NSW 2795, Australia.	jbgao@csu.edu.au; mantolovich@csu.edu.au; kwan@turing.une.edu.au					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Efron B, 2004, ANN STAT, V32, P407; CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472; BILLINGS SA, 1989, MECH SYST SIGNAL PR, V3, P123, DOI 10.1016/0888-3270(89)90012-5; CAO J, 2008, NEURAL COMPUT, V20, P555; Chen S, 2006, NEUROCOMPUTING, V69, P559, DOI 10.1016/j.neucom.2004.12.011; Drezet PML, 1998, P UKACC INT C CONTR, P688; Gao JB, 2002, LECT NOTES ARTIF INT, V2557, P395; Gao JB, 2007, LECT NOTES COMPUT SC, V4830, P26; GESTEL T, 2003, P 13 IFAC S SYST ID, P27; Hesterberg T., 2008, STAT SURVEYS, V2, P61, DOI DOI 10.1214/08-SS035; KRUIF B, 2002, P 41 IEEE C DEC CONT, P10; PONTIL M, 1998, 1651 MIT AI LAB; Scholkopf B., 2002, LEARNING KERNELS; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; VALYON J, 2003, P 13 IFAC S SYST ID; Vapnik V., 1998, STAT LEARNING THEORY	20	1	1	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-89377-6	LECT NOTES ARTIF INT			2008	5360						318	324				7	Computer Science, Artificial Intelligence	Computer Science	BIW26	WOS:000263294500031		
S	Potter, LC; Schniter, P; Ziniel, J		Zelnio, EG; Garber, FD		Potter, Lee C.; Schniter, Philip; Ziniel, Justin			Sparse reconstruction for RADAR	ALGORITHMS FOR SYNTHETIC APERTURE RADAR IMAGERY XV	Proceedings of SPIE		English	Proceedings Paper	Conference on Algorithms for Synthetic Aperture Radar Imagery XV	MAR 17-18, 2008	Orlando, FL	SPIE		sparse reconstruction; radar imaging; Gaussian mixture models	SIGNAL RECOVERY; BASIS SELECTION; REGRESSION; PURSUIT; DECONVOLUTION; VECTOR	Imaging is not itself a system goal, but is rather a means to support inference tasks. For data processing with linearized signal models, we seek to report all high-probability interpretations of the data and to report confidence labels in the form of posterior probabilities. A low-complexity recursive procedure is presented for Bayesian estimation in linear regression models. A Gaussian mixture is chosen as the prior on the unknown parameter vector. The algorithm returns both a set of high posterior probability mixing parameters and an approximate minimum mean squared error (MMSE) estimate of the parameter vector. Emphasis is given to the case of a sparse parameter vector. Numerical simulations demonstrate estimation performance and illustrate the distinctions between MMSE estimation and maximum a posteriori probability (MAP) model selection. The proposed treesearch algorithm provides exact ratios of posterior probabilities for a set of high probability solutions to the sparse reconstruction problem. These relative probabilities serve to reveal potential ambiguity among multiple candidate solutions that are ambiguous due to low signal-to-noise ratio and/or significant correlation among columns in the super-resolving regressor matrix.	[Potter, Lee C.; Schniter, Philip; Ziniel, Justin] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA	Potter, LC (reprint author), Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.	potter.36@osu.edu	Schniter, Philip/A-7336-2012; Potter, Lee/F-8668-2014				Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016; Larsson EG, 2007, IEEE T SIGNAL PROCES, V55, P451, DOI 10.1109/TSP.2006.887109; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251; Cetin M, 2001, IEEE T IMAGE PROCESS, V10, P623, DOI 10.1109/83.913596; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Bouman C, 1993, IEEE Trans Image Process, V2, P296, DOI 10.1109/83.236536; Casteel CH, 2007, P SOC PHOTO-OPT INS, V6568, pD5680, DOI 10.1117/12.731457; CHARTRAND, ICASSP 2008 IN PRESS; COTTER SF, 2001, IEEE INT C AC SPEECH, V6, P3933; Delaney AH, 1996, IEEE T IMAGE PROCESS, V5, P740, DOI 10.1109/83.495957; DEVORE R, 2007, IMA SEM JUN; Donoho D. L., 2006, 200602 STANF U DEP S; Gerry MJ, 1999, IEEE T ANTENN PROPAG, V47, P1179, DOI 10.1109/8.785750; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hogbom J. A., 1974, Astronomy and Astrophysics Supplement Series, V15; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; JACKSON JA, IEEE T AERO IN PRESS; JI S, 2007, P 24 INT C MACH LEAR; KELLER JB, 1962, J OPT SOC AM, V52, P116, DOI 10.1364/JOSA.52.000116; Kuppusamy P, 2004, ANTIOXID REDOX SIGN, V6, P583, DOI 10.1089/152308604773934332; Lawson C.L., 1961, THESIS UCLA; LEE H, 1987, IEEE INT C AC SPEECH, P1569; LEVY S, 1981, GEOPHYSICS, V46, P1235, DOI 10.1190/1.1441261; LO YT, 1964, IEEE T ANTENN PROPAG, VAP12, P257, DOI 10.1109/TAP.1964.1138220; Marseille GJ, 1996, J MAGN RESON SER B, V111, P70, DOI 10.1006/jmrb.1996.0061; Pati Y. C., 1993, P 27 ANN AS C SIGN S; Sharma S., 2007, THESIS OHIO STATE U; Tao T., 2007, OPEN QUESTION DETERM; TAYLOR HL, 1979, GEOPHYSICS, V44, P39, DOI 10.1190/1.1440921; WAINWRIGHT MJ, 2006, 709 DEP STAT	37	2	2	3	4	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-7161-1	PROC SPIE			2008	6970								697003	10.1117/12.786286		15	Optics; Physics, Applied	Optics; Physics	BHZ65	WOS:000257705200001		
B	Anagnostopoulos, C; Adams, NM; Hand, DJ			ACM	Anagnostopoulos, Christoforos; Adams, Niall M.; Hand, David J.			Deciding what to observe next: adaptive variable selection for regression in multivariate data streams	APPLIED COMPUTING 2008, VOLS 1-3			English	Proceedings Paper	23rd Annual ACM Symposium on Applied Computing	MAR 16-20, 2008	Fortaleza, BRAZIL	ACM SIGAC, Univ Fortaleza, Federal Univ Ceara		variable selection; Lasso; EM algorithm; sensor networks; exploration-exploitation	LASSO; MODEL	Variable selection can be valuable in the analysis of streaming data with costly measurements, as in intensive care monitoring or battery-powered sensor networks. In the presence of drift, selections must be constantly revised, calling for adaptive variable selection schemes. An important and novel problem arises front the fact that non-selected variables become missing variables, which induces bias upon subsequent decisions. Here, we consider adaptive variable selection in the context of linear regression, using only a fraction of the available regressors per timepoint. We suggest a scheme that fits a multivariate Gaussian over a sliding window using the EM algorithm and selects which variables to observe next using the Lasso algorithm. We experiment with simulated and real data to demonstrate that very high prediction accuracy may be retained using as little as 10% of the data.	[Anagnostopoulos, Christoforos; Hand, David J.] Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, London SW7 2PG, England	Anagnostopoulos, C (reprint author), Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, 53 Princes Gate, London SW7 2PG, England.	christoforos.anagnostopoulos06@imperial.ac.uk; n.adams@imperial.ac.uk; d.j.hand@imperial.ac.uk	Anagnostopoulos, Christoforos/A-8018-2010; Adams, Niall/D-2472-2010				Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Sato M, 2001, NEURAL COMPUT, V13, P1649, DOI 10.1162/089976601750265045; Efron B, 2004, ANN STAT, V32, P407; Dellaportas P, 2002, STAT COMPUT, V12, P27, DOI 10.1023/A:1013164120801; Brown PJ, 1999, BIOMETRIKA, V86, P635; Deshpande A., 2004, P 30 VLDB C; Deshpande A., 2005, P 2 BIENN C INN DAT, P317; GEORGE E, 2000, J AM STAT ASS, V95; Han S, 2007, REAL-TIME SYST, V35, P33, DOI 10.1007/s11241-006-9000-3; Hellerstein J, 2000, IEEE DATA ENG B, V23, P7; Little RJA, 2002, WILEY SERIES PROBABI; Sjostrand K., 2005, MATLAB IMPLEMENTATIO; Sutton R. S., 1998, INTRO REINFORCEMENT; THOMPSON ML, 1978, INT STAT REV, V46, P1, DOI 10.2307/1402505; VERMOREL J, P 16 EUR C MACH LEAR, P437; Wang H., 2006, P 12 ACM SIGKDD INT, P736, DOI 10.1145/1150402.1150496; ZHANG P, 1992, BIOMETRIKA, V79, P741, DOI 10.1093/biomet/79.4.741	19	1	1	2	4	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA							2008							961	965				5	Computer Science, Interdisciplinary Applications	Computer Science	BKK67	WOS:000268392201022		
S	Signoretto, M; Pelckmans, K; Suykens, JAK		Kurkova, V; Neruda, R; Koutnik, J		Signoretto, Marco; Pelckmans, Kristiaan; Suykens, Johan A. K.			Quadratically Constrained Quadratic Programming for Subspace Selection in Kernel Regression Estimation	ARTIFICIAL NEURAL NETWORKS - ICANN 2008, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	18th International Conference on Artificial Neural Networks (ICANN 2008)	SEP 03-06, 2008	Prague, CZECH REPUBLIC				MODELS	In this contribution we consider the problem of regression estimation. We elaborate on a framework based on functional analysis giving rise to structured models in the context of reproducing kernel Hilbert spaces. In this setting the task of input selection is converted into the task of selecting functional components depending on one (or more) inputs. In turn the process of learning with embedded selection of such components can be formalized as a convex-concave problem. This results in a practical algorithm that can be implemented as a quadratically constrained quadratic programming (QCQP) optimization problem. We further investigate the mechanism of selection for the class of linear functions, establishing a relationship with LASSO.	[Signoretto, Marco; Pelckmans, Kristiaan; Suykens, Johan A. K.] Katholieke Univ Leuven, ESAT SCD, B-3001 Louvain, Belgium	Signoretto, M (reprint author), Katholieke Univ Leuven, ESAT SCD, Kasteelpk Arenberg 10, B-3001 Louvain, Belgium.	Marco.Signoretto@esat.kuleuven.be; Kristiaan.Pelckmans@esat.kuleuven.be; Johan.Suykens@esat.kuleuven.be	Pelckmans, Kristiaan/A-3118-2013; Suykens, Johan/C-9781-2014				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI DOI 10.2307/1990404; Berlinet A., 2004, REPRODUCING K HILBER; Chen S.S., 1995, THESIS STANFORD U; CHEN ZH, 1993, J ROY STAT SOC B MET, V55, P473; Cucker F, 2007, C MO AP C M, P1, DOI 10.1017/CBO9780511618796; DONOHO D, 2003, BIOMETRIKA, V81, P425; Grant M., 2006, CVX MATLAB SOFTWARE; GU C, 2002, SERIES STAT; Huang JZ, 1998, J MULTIVARIATE ANAL, V67, P49, DOI 10.1006/jmva.1998.1753; Light W. A., 1985, LECT NOTES MATH, V1169; Lin M, 2000, TISSUE ANTIGENS, V55, P1, DOI 10.1034/j.1399-0039.2000.550101.x; Miller A, 2002, SUBSET SELECTION REG, V2nd; Nemirovski A., 2001, LECT MODERN CONVEX O; PELCKMANS K, 2005, SUPPORT VECTOR MACHI, P77; TAKEMURA A, 1983, J AM STAT ASSOC, V78, P894, DOI 10.2307/2288201; Tsang IWH, 2006, IEEE T NEURAL NETWOR, V17, P48, DOI 10.1109/TNN.2005.860848; VALNIK V, 1998, STAT LEARNING THEORY; Wahba G., 1990, CBMS NSF REGIONAL C, V59	20	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-87535-2	LECT NOTES COMPUT SC			2008	5163						175	184				10	Computer Science, Theory & Methods	Computer Science	BIH68	WOS:000259566200019		
J	Wasserman, L				Wasserman, Larry			Objections to Bayesian statistics Comment on Article by Gelman	BAYESIAN ANALYSIS			English	Editorial Material									[Wasserman, Larry] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA; [Wasserman, Larry] Carnegie Mellon Univ, Machine Learning Dept, Pittsburgh, PA 15213 USA	Wasserman, L (reprint author), Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846	2	1	1	0	1	INT SOC BAYESIAN ANALYSIS	PITTSBURGH	CARNEGIE MELLON UNIV, DEPT STTISTICS, PITTSBURGH, PA 15213 USA	1931-6690			BAYESIAN ANAL	Bayesian Anal.		2008	3	3					463	465		10.1214/08-BA318D		3	Mathematics, Interdisciplinary Applications; Statistics & Probability	Mathematics	V10HL	WOS:000207455000006		
J	Gelman, A				Gelman, Andrew			Objections to Bayesian statistics Rejoinder	BAYESIAN ANALYSIS			English	Editorial Material						Comparisons to other methods; Foundations		In the main article I presented a series of objections to Bayesian inference, written in the voice of a hypothetic a l anti-Bayesian statistician. Here I respond to these objections along with some other comments made by four discussants.	[Gelman, Andrew] Columbia Univ, Dept Stat, New York, NY 10027 USA; [Gelman, Andrew] Columbia Univ, Dept Polit Sci, New York, NY 10027 USA	Gelman, A (reprint author), Columbia Univ, Dept Stat, New York, NY 10027 USA.						ALPERT NM, 1991, J CEREBR BLOOD F MET, V11, pA26; ZEGER SL, 1988, BIOMETRICS, V44, P1049, DOI 10.2307/2531734; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; EFRON B, 1973, J AM STAT ASSOC, V68, P117, DOI 10.2307/2284155; Agresti A, 1998, AM STAT, V52, P119, DOI 10.2307/2685469; Carlin BP, 2008, BAYESIAN METHODS DAT; CASELLA A, 2008, 14103 NAT BUR EC RES; CHIPMAN HE, 2005, BAYESIAN ADDITIVE RE; Efron B, 1993, INTRO BOOTSTRAP; Gelman A, 1995, SOCIOL METHODOL, V25, P165, DOI 10.2307/271064; Gelman A, 2003, J BUS ECON STAT, V21, P213, DOI 10.1198/073500103288618909; Gelman A., 2003, BAYESIAN DATA ANAL; GELMAN AA, 2008, ANN APPL ST IN PRESS; GREENLAND S, 2008, HIERARCHICAL MODELS; HECKMAN JJ, 2007, SOCIOL METHODOL, P135; HENRION M, 1986, AM J PHYS, V54, P791, DOI 10.1119/1.14447; Kuhn T, 1962, STRUCTURE SCI REVOLU; Lu H, 2003, J OFF STAT, V19, P133; Morgenstern O., 1947, THEORY GAMES EC BEHA; Popper Karl, 1959, LOGIC SCI DISCOVERY; Ripley B. D., 1981, SPATIAL STAT; Vehtari A, 2002, NEURAL COMPUT, V14, P2439, DOI 10.1162/08997660260293292; YOUDEN WJ, 1962, EXPT MEASUREMENT	23	5	5	2	5	INT SOC BAYESIAN ANALYSIS	PITTSBURGH	CARNEGIE MELLON UNIV, DEPT STTISTICS, PITTSBURGH, PA 15213 USA	1931-6690			BAYESIAN ANAL	Bayesian Anal.		2008	3	3					467	477		10.1214/08-BA318REJ		11	Mathematics, Interdisciplinary Applications; Statistics & Probability	Mathematics	V10HL	WOS:000207455000007		
S	Ince, NF; Goksu, F; Tewfik, AH		Fred, A; Filipe, J; Gamboa, H		Ince, Nuri F.; Goksu, Fikri; Tewfik, Ahmed H.			ECoG Based Brain Computer Interface with Subset Selection	BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES	COMMUNICATIONS IN COMPUTER AND INFORMATION SCIENCE		English	Proceedings Paper	International Joint Conference on Biomedical Engineering Systems and Technologies	JAN 28-31, 2008	Funchal, PORTUGAL			Electrocorticogram; Brain Computer Interface; Time Frequency; Undecimated Wavelet Packet Transform	SINGLE-TRIAL EEG; MOTOR IMAGERY; CLASSIFICATION	We describe an adaptive approach for the classification of multichannel neural recordings for a brain computer interface. A dual-tree undecimated wavelet packet transform generates a structured redundant feature dictionary with different time-frequency resolutions computed on multichannel neural recordings. Rather than evaluating the individual discrimination performance of each electrode or candidate feature, the proposed approach implements a wrapper strategy combined with pruning to select a subset of features from the structured dictionary by evaluating the classification performance of their combination. The pruning stage and wrapper combination enables the algorithm to select a subset of the most informative features coming from different cortical areas and/or time frequency locations with faster speeds, while guaranteeing high generalization capability and lower error rates. We show experimental classification results on the ECoG data set of BCI competition 2005. The proposed approach achieved a classification accuracy of 93% by using only three features. This is a. marked improvement over other reported approaches that use all electrodes or require manual selection of sensor subsets and feature indices and at best achieve slightly lower classification accuracies.	[Ince, Nuri F.; Goksu, Fikri; Tewfik, Ahmed H.] Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA	Ince, NF (reprint author), Univ Minnesota, Dept Elect & Comp Engn, 200 Union St SE, Minneapolis, MN 55455 USA.	firat@umn.edu; goks0002@umn.edu; tewfik@umn.edu					Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P164, DOI 10.1109/TRE.2000.847807; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Duda RO, 2006, PATTERN CLASSIFICATI; Hinterberger T., 2005, ADV NEURAL INFORM PR, V17, P737; Ince NF, 2006, J NEURAL ENG, V3, P235, DOI 10.1088/1741-2560/3/3/006; INCE NF, 2007, COMP BIOL MED; Leuthardt Eric C, 2004, J Neural Eng, V1, P63, DOI 10.1088/1741-2560/1/2/001; PREZENGER M, 1999, IEEE T REHABIL ENG, V7, P413; SAITO N, 2002, PATTERN RECOGN, V35, P1842; Schlogl A, 1997, BIOMED TECH, V42, P162, DOI 10.1515/bmte.1997.42.6.162; Vetterli M, 2001, IEEE SIGNAL PROC MAG, V18, P59, DOI 10.1109/79.952805; Wang T, 2004, CLIN NEUROPHYSIOL, V115, P2744, DOI 10.1016/j.clinph.2004.06.022	16	3	3	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929		978-3-540-92218-6	COMM COM INF SC			2008	25						357	374				18	Engineering, Biomedical	Engineering	BIV03	WOS:000262981100027		
B	Pecot, T; Kervrann, C; Bouthemy, P		Encarnacao, P; Veloso, A		Pecot, Thierry; Kervrann, Charles; Bouthemy, Patrick			Network Tomography-based tracking for intracellular traffic analysis in fluorescence microscopy imaging	BIOSIGNALS 2008: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, VOL 1			English	Proceedings Paper	1st International Conference on Bio-Inspired Systems and Signal Processing	JAN 28-31, 2008	Funchal, PORTUGAL	Inst Syst & Technol Informat, Control & Commun, Univ Madeira, IEEE Engn Med & Biol Soc, Special Interest Grp Artificial Intelligence, Assoc Adv Artificial Intelligence		object tracking; fluorescence microscopy; network tomography; Voronoi diagram; trafficking; membrane transport		Determination of the sub-cellular localization and dynamics of any proteins is an important step towards the understanding of multi-molecular complexes in a cellular context. Green Fluorescent Protein (GFP)-tagging and time-lapse fluorescence microscopy allows to acquire multidimensional data on rapid cellular activities, and then make possible the analysis of proteins of interest. Consequently, novel techniques of image analysis are needed to quantify dynamics of biological processes observed in such image sequences. In biological trafficking analysis, the previous tracking methods do not manage when many small and poorly distinguishable objects interact. Nevertheless, an another way of tracking that usually consists in determining the full trajectories of all the objects, can be more relevant. General information about the traffic like the regions of origin and destination of the moving objects represent interesting features for analysis. In this paper, we propose to estimate the paths (regions of origin and destination) used by the objects of interest, and the proportions of moving objects for each path. This can be accomplished by exploiting the recent advances in Network Tomography (NT) commonly used in network communications. This idea is demonstrated on real image sequences for the Rab6 protein, a GTPase involved in the regulation of intracellular membrane trafficking.	[Pecot, Thierry; Kervrann, Charles; Bouthemy, Patrick] IRISA INRIA, F-35042 Rennes, France	Pecot, T (reprint author), IRISA INRIA, Campus Univ Beaulieu, F-35042 Rennes, France.	thpecot@irisa.fr; ckervran@irisa.fr; bouthemy@irisa.fr					ANDERSON CM, 1992, J CELL SCI, V101, P415; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Sbalzarini IF, 2005, J STRUCT BIOL, V151, P182, DOI 10.1016/j.jsb.2005.06.002; BECHAR I, 2006, P MICCAI WORKSH MICR; BOULANGER J, 2006, P ICIP 2006 ATL; BOYD JE, 1999, P 7 IEEE INT C COMP, V1, P163; CANDES E, 2007, ANN STAT IN PRESS; Medina A., 2002, SIGCOMM 02 P C APPL, P161; PECOT T, 2007, P IEEE ISBI 2007 ARL, P268; RACINE V, 2006, P IEEE ISBI 2006; Santini S, 2000, 5 IEEE WORKSH APPL C, P140; SIBARITA J, 2006, P IEEE ISBI 2006; SMAL I, 2007, P IEEE INT S BIOM IM, P1048, DOI DOI 10.1109/ISBI.2007.357035; Thomann D, 2003, J MICROSC-OXFORD, V211, P230; Vardi Y, 1996, J AM STAT ASSOC, V91, P365, DOI 10.2307/2291416	16	0	0	0	2	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL			978-989-8111-18-0				2008							154	161				8	Engineering, Biomedical; Mathematical & Computational Biology; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Mathematical & Computational Biology; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	BHW15	WOS:000256959600024		
J	Tibshirani, R; Wang, P				Tibshirani, Robert; Wang, Pei			Spatial smoothing and hot spot detection for CGH data using the fused lasso	BIOSTATISTICS			English	Article						DNA copy number; Signal detection	FALSE DISCOVERY RATES; ARRAY-CGH; TUMORS	We apply the "fused lasso" regression method of Tibshirani and others (2004) to the problem of "hotspot detection", in particular, detection of regions of gain or loss in comparative genomic hybridization (CGH) data. The fused lasso criterion leads to a convex optimization problem, and we provide a fast algorithm for its solution. Estimates of false-discovery rate are also provided. Our studies show that the new method generally outperforms competing methods for calling gains and losses in CGH data.	[Tibshirani, Robert] Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA; [Tibshirani, Robert] Stanford Univ, Dept Biostat, Stanford, CA 94305 USA; [Wang, Pei] Fred Hutchinson Canc Res Ctr, Seattle, WA 98109 USA	Tibshirani, R (reprint author), Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA.	tibs@stat.stanford.edu					Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Lai WR, 2005, BIOINFORMATICS, V21, P3763, DOI 10.1093/bioinformatics/bti611; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Efron B, 2002, GENET EPIDEMIOL, V23, P70, DOI 10.1002/gepi.01124; Diskin SJ, 2006, GENOME RES, V16, P1149, DOI 10.1101/gr.5076506; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Olshen AB, 2004, BIOSTATISTICS, V5, P557, DOI 10.1093/biostatistics/kxh008; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Pollack JR, 2002, P NATL ACAD SCI USA, V99, P12963, DOI 10.1073/pnas.162471999; Becker R. A., 1988, NEW S LANGUAGE; Bredel M, 2005, CANCER RES, V65, P4088, DOI 10.1158/0008-5472.CAN-04-4229; CHU G, 2003, SIGNIFICANCE ANAL MI; Fridlyand J, 2004, J MULTIVARIATE ANAL, V90, P132, DOI 10.1016/j.jmva.2004.02.008; GILL P, 1999, USERS GUIDE SQOPT 5; LIPSON D, 2005, J COMPUT BIOL, V13, P215; Myers CL, 2004, BIOINFORMATICS, V20, P3533, DOI 10.1093/bioinformatics/bth440; Picard F, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-27; Ruppert D., 2003, SEMIPARAMETRIC REGRE; Wang P, 2005, BIOSTATISTICS, V6, P45, DOI 10.1093/biostatistics/kxh017	19	100	104	3	8	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1465-4644			BIOSTATISTICS	Biostatistics	JAN	2008	9	1					18	29		10.1093/biostatistics/kxm013		12	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	241TT	WOS:000251679400002	17513312	
J	Koukouvinos, C; Mylona, K				Koukouvinos, C.; Mylona, K.			A method for analyzing supersaturated designs with a block orthogonal structure	COMMUNICATIONS IN STATISTICS-SIMULATION AND COMPUTATION			English	Article						data analysis; penalized least squares; supersaturated design	VARIABLE-SELECTION; CONSTRUCTION; STRATEGY; LASSO	Supersaturated designs is a large class of factorial designs which can be used for screening out the important factors from a large set of potentially active variables. The huge advantage of these designs is that they reduce the experimental cost drastically, but their critical disadvantage is the confounding involved in the statistical analysis. In this article, we propose a method for analyzing data using a specific type of supersaturated designs. This method heavily uses the special block orthogonal structure of the supersaturated designs given by Tang and Wu (1997). Also, we compare our method with several known statistical analysis methods by using some of the existing supersaturated designs. The comparison is performed by some simulating experiments and the Type I and Type II error rates are calculated. The results are presented in tables and the discussion to follow.	[Koukouvinos, C.; Mylona, K.] Natl Tech Univ Athens, Dept Math, GR-15773 Athens, Greece	Koukouvinos, C (reprint author), Natl Tech Univ Athens, Dept Math, Zografou Campus, GR-15773 Athens, Greece.			MYLONA, KALLIOPI/0000-0002-1460-0715			Abraham B, 1999, TECHNOMETRICS, V41, P135, DOI 10.2307/1270729; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; BOX GEP, 1986, TECHNOMETRICS, V28, P11, DOI 10.2307/1269599; CRAVEN P, 1979, NUMER MATH, V31, P377; Beattie SD, 2002, TECHNOMETRICS, V44, P55, DOI 10.1198/004017002753398326; Chipman H, 1997, TECHNOMETRICS, V39, P372, DOI 10.2307/1271501; Fan J., 1997, J ITALIAN STAT ASS, V6, P131; HAMADA M, 1992, J QUAL TECHNOL, V24, P130; Holcomb DR, 2003, J QUAL TECHNOL, V35, P13; Koukouvinos C., 2006, Journal of Discrete Mathematical Sciences & Cryptography, V9; Li R., 2003, J DATA SCI, V1, P249; Li RZ, 2002, STAT PROBABIL LETT, V59, P135, DOI 10.1016/S0167-7152(02)00140-2; LIN DKJ, 1995, TECHNOMETRICS, V37, P213, DOI 10.2307/1269622; LIN DKJ, 1993, TECHNOMETRICS, V35, P28, DOI 10.2307/1269286; Liu MQ, 2000, J STAT PLAN INFER, V91, P139, DOI 10.1016/S0378-3758(00)00136-1; Lu X, 2004, J QUAL TECHNOL, V36, P392; Lu XA, 2000, J STAT PLAN INFER, V86, P229, DOI 10.1016/S0378-3758(99)00169-X; Nguyen NK, 1996, TECHNOMETRICS, V38, P69, DOI 10.2307/1268904; Satterthwaite F. E., 1959, TECHNOMETRICS, V1, P111, DOI 10.2307/1266466; Tang BX, 1997, CAN J STAT, V25, P191, DOI 10.2307/3315731; WANG PC, 1995, TECHNOMETRICS, V37, P358, DOI 10.2307/1269944; Westfall PH, 1998, STAT SINICA, V8, P101	25	6	6	0	0	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0361-0918			COMMUN STAT-SIMUL C	Commun. Stat.-Simul. Comput.		2008	37	2					290	300		10.1080/03610910701790376		11	Statistics & Probability	Mathematics	308JT	WOS:000256386400004		
J	Ruhlicke, R; Gervini, D				Ruehlicke, Robin; Gervini, Daniel			Logistic discrimination with total variation regularization	COMMUNICATIONS IN STATISTICS-SIMULATION AND COMPUTATION			English	Article						classification; discrimination; machine learning; speech recognition	NONCONCAVE PENALIZED LIKELIHOOD; REGRESSION; SELECTION	This article introduces a regularized logistic discrimination method that is especially suited for discretized stochastic processes (such as periodograms, spectrograms, EEG curves, etc.). The proposed method penalizes the total variation of the discriminant directions, giving smaller misclassification errors than alternative methods, and smoother and more easily interpretable discriminant directions. The properties of the new method are studied by simulation and by a real-data example involving classification of phonemes.	[Gervini, Daniel] Univ Wisconsin, Dept Math Sci, Milwaukee, WI 53201 USA; [Ruehlicke, Robin] Univ Ulm, Fac Math & Econ, Ulm, Germany	Gervini, D (reprint author), Univ Wisconsin, Dept Math Sci, POB 413, Milwaukee, WI 53201 USA.	gervini@uwm.edu	Gervini, Daniel/E-6904-2014	Gervini, Daniel/0000-0003-2655-0337			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Hastie T., 2001, ELEMENTS STAT LEARNI; Johnson R. A., 2002, APPL MULTIVARIATE ST; KRZANOWSKI WJ, 1977, TECHNOMETRICS, V19, P191, DOI 10.2307/1268629; NOCEDAL J., 1999, NUMERICAL OPTIMIZATI; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	8	1	1	0	1	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0361-0918			COMMUN STAT-SIMUL C	Commun. Stat.-Simul. Comput.		2008	37	9					1825	1838		10.1080/03610910802178398		14	Statistics & Probability	Mathematics	355FG	WOS:000259694200010		
B	Gatu, C; Sysi-Aho, M; Oresic, M		Brito, P		Gatu, Cristian; Sysi-Aho, Marko; Oresic, Matej			A regression subset-selection strategy for fat-structure data	COMPSTAT 2008: PROCEEDINGS IN COMPUTATIONAL STATISTICS			English	Proceedings Paper	18th Symposium on Computational Statistics (COMSTAT 2008)	AUG 24-29, 2008	Oporto, PORTUGAL	Univ Porto, Fac Econ, PSE, FCT, FEUP, Banco Porutgal, PORTO, SPM, Caixa Geral Depositos, SPE, CLAD, ifcs		regression tree; branch-and-bound; model selection; fat-structure data	LINEAR-REGRESSION; QR DECOMPOSITION; MODELS; ALGORITHMS; VARIABLES	A strategy is proposed for finding the most significant linear regression submodel for fat-structure data, that is when the number of variables n exceeds the number of available observations m. The method consists of two stages. First, a heuristic is employed to preselect a number of variables n(S) such that n(S) <= m. The second stage performs an exhaustive search on the reduced list of variables. It employs a regression tree structure that generates all possible subset models. Non-optimal subtrees are pruned using a branch-and-bound device. Cross validation experiments on a real biomedical dataset are presented and analyzed.	[Gatu, Cristian; Sysi-Aho, Marko; Oresic, Matej] VTT Tech Res Ctr Finland, FI-02044 Espoo, Vtt, Finland			Gatu, Cristian/C-4814-2011				BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; Katajamaa M, 2006, BIOINFORMATICS, V22, P634, DOI 10.1093/bioinformatics/btk039; Efron B, 2004, ANN STAT, V32, P407; CLARKE MRB, 1981, APPL STATIST, V30, P198, DOI 10.2307/2346398; EDWARDS D, 1987, J AM STAT ASSOC, V82, P205, DOI 10.2307/2289155; GATU C, 2005, COMPUT MANAGE SCI, V4, P253; GATU C, 2008, J EC DYNAMI IN PRESS; Gatu C, 2006, J COMPUT GRAPH STAT, V15, P139, DOI 10.1198/106186006X100290; Gatu C, 2006, J ECON DYN CONTROL, V30, P721, DOI 10.1016/j.jedc.2005.03.006; Gatu C, 2007, COMPUT STAT DATA AN, V52, P799, DOI 10.1016/j.csda.2007.02.018; Gatu C, 2003, PARALLEL COMPUT, V29, P505, DOI 10.1016/S0167-8191(03)00019-X; Hastie T., 2001, SPRINGER SERIES STAT; HOCKING RR, 1976, BIOMETRICS, V32, P1, DOI 10.2307/2529336; HOCKING RR, 1983, TECHNOMETRICS, V25, P219, DOI 10.2307/1268603; Hofmann M, 2007, COMPUT STAT DATA AN, V52, P16, DOI 10.1016/j.csda.2007.03.017; Hui Z., 2005, J ROYAL STAT SOC B, V67, P301; LAMOTTE LR, 1970, TECHNOMETRICS, V12, P83, DOI 10.2307/1267353; Miller A, 2002, SUBSET SELECTION REG, V2nd; MILLER AJ, 1984, J ROY STAT SOC A STA, V147, P389, DOI 10.2307/2981576; Oresic M, 2006, EXPERT REV MOL DIAGN, V6, P575, DOI 10.1586/14737159.6.4.575; R Development Core Team, 2005, R LANG ENV STAT COMP; Searle SR., 1971, LINEAR MODELS; SEBER GAF, 1977, LINEAR REGRESSION AN; Sen A. K., 1990, REGRESSION ANAL THEO; SMITH DM, 1989, COMPUT STAT DATA AN, V7, P217, DOI 10.1016/0167-9473(89)90023-6; YETUKURI L, 2007, BMC SYST BIOL, V1, pC12	29	0	0	1	2	PHYSICA-VERLAG GMBH & CO	HEIDELBERG	TIERGARTENSTR 17, D-69121 HEIDELBERG, GERMANY			978-3-7908-2083-6				2008							349	358		10.1007/978-3-7908-2084-3_29		10	Economics; Statistics & Probability	Business & Economics; Mathematics	BIG48	WOS:000259327700029		
B	Galimberti, G; Montanari, A; Viroli, C		Brito, P		Galimberti, Giuliano; Montanari, Angela; Viroli, Cinzia			Latent classes of objects and variable selection	COMPSTAT 2008: PROCEEDINGS IN COMPUTATIONAL STATISTICS			English	Proceedings Paper	18th Symposium on Computational Statistics (COMSTAT 2008)	AUG 24-29, 2008	Oporto, PORTUGAL	Univ Porto, Fac Econ, PSE, FCT, FEUP, Banco Porutgal, PORTO, SPM, Caixa Geral Depositos, SPE, CLAD, ifcs		factor analysis; LASSO; finite Gaussian mixtures	MODEL	In this paper we present a model based clustering approach which contextually performs dimension reduction and variable selection. In particular we assume that the data have been generated by a linear factor model with latent variables modeled as gaussian mixtures (thus obtaining dimension reduction) and. we shrink the factor loadings, resorting to a penalized likelihood method, with an L1 penalty (thus realizing automatic variable selection). We derive an EM algorithm to obtain the penalized model estimates and a modified BIC criterion to select the penalization parameter. We evaluate the performance of the proposed method on simulated data.	[Galimberti, Giuliano; Montanari, Angela; Viroli, Cinzia] Univ Bologna, Dept Stat, I-40126 Bologna, Italy			Galimberti, Giuliano/J-5353-2012; Viroli, Cinzia/F-5786-2014; 	Galimberti, Giuliano/0000-0002-9161-9671; Viroli, Cinzia/0000-0002-3278-5266; Montanari, Angela/0000-0002-8369-1761			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; McLachlan GJ, 2003, COMPUT STAT DATA AN, V41, P379, DOI 10.1016/S0167-9473(02)00183-4; Fraley C, 1999, J CLASSIF, V16, P297, DOI 10.1007/s003579900058; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Khalili A, 2007, J AM STAT ASSOC, V102, P1025, DOI 10.1198/016214507000000590; Dempster N.M., 1977, J ROYAL STAT SOC B, V39, P1; Fraley C., 2002, 415 U WASH DEP STAT; Fraley C, 2003, J CLASSIF, V20, P263, DOI 10.1007/s00357-003-0015-3; Hoff PD, 2005, BIOMETRICS, V61, P1027, DOI 10.1111/j.1541-0420.2005.00381.x; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Liu J. S., 2003, BAYESIAN STAT, V7, P249; Pan W, 2007, J MACH LEARN RES, V8, P1145; Peel D, 2000, FINITE MIXTURE MODEL	16	1	1	0	1	PHYSICA-VERLAG GMBH & CO	HEIDELBERG	TIERGARTENSTR 17, D-69121 HEIDELBERG, GERMANY			978-3-7908-2083-6				2008							373	383		10.1007/978-3-7908-2084-3_31		11	Economics; Statistics & Probability	Business & Economics; Mathematics	BIG48	WOS:000259327700031		
S	Makadia, A; Pavlovic, V; Kumar, S		Forsyth, D; Torr, P; Zisserman, A		Makadia, Ameesh; Pavlovic, Vladimir; Kumar, Sanjiv			A New Baseline for Image Annotation	COMPUTER VISION - ECCV 2008, PT III, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	10th European Conference on Computer Vision (ECCV 2008)	OCT 12-18, 2008	Marseille, FRANCE	INRIA, Ville Marseille, Reg Province Alpes-Cote Azur, Deutsch Telekom Lab, Microsoft Res, Orange, INRIA, Microsoft Res, EADS, TOSHIBA, Springer				Automatically assigning keywords to images is of great interest as it allows one to index, retrieve, and understand large collections of image data. Many techniques have been proposed for image annotation in the last decade that give reasonable performance on standard datasets. However, most of these works fail to compare their methods with simple baseline techniques to justify the need for complex models and subsequent training. In this work, we introduce a new baseline technique for image annotation that treats annotation as a retrieval problem. The proposed technique utilizes low-level image features and a simple combination of basic distances to find nearest neighbors of a given image. The keywords are then assigned using a greedy label transfer mechanism. The proposed baseline outperforms the current state-of-the-art methods on two standard and one large Web dataset. We believe that such a baseline measure will provide a strong platform to compare and better understand future annotation techniques.	[Makadia, Ameesh; Kumar, Sanjiv] Google Res, New York, NY USA	Makadia, A (reprint author), Google Res, New York, NY USA.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Barnard K, 2005, ARTIF INTELL, V167, P13, DOI 10.1016/j.artint.2005.04.009; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460; Carneiro G., 2007, IEEE T PATTERN ANAL, V29; Datta R., 2008, ACM COMPUTING SURVEY; Duygulu P., 2002, ECCV, P97; Feng S., 2004, IEEE C COMP VIS PATT; FROME A, 2007, P IEEE INT C COMP VI; GAO Y, 2006, 8 ACM INT WORKSH MUL, P79; HARE JS, 2006, MULTIMEDIA CONTENT A; Jeon J, 2003, ACM SIGIR, P119, DOI DOI 10.1145/860435.860459; Jin R., 2004, ACM MULT C, P892; Lavrenko V., 2004, ADV NEURAL INFORM PR, V16; Li J., 2003, IEEE T PATTERN ANAL, V25; METZLER D, 2005, IMAGE VIDEO RETRIEVA, P42; Monay F., 2003, ACM MULTIMEDIA, P275; MORI Y, 1999, 1 INT WORKSH MULT IN; von Ahn L., 2004, ACM CHI; WANG L, 2004, ACM INT WORKSH MULT; YANG C, 2006, P IEEE INT C COMP VI; YAVLINSKY A, 2005, LNCS, V3568	21	48	48	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88689-1	LECT NOTES COMPUT SC			2008	5304		3				316	329				14	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIM02	WOS:000260659800024		
S	Anagnostopoulos, C; Tasoulis, D; Hand, DJ; Adams, NM		Ghallab, M; Spyropoulos, CD; Fakotakis, N; Avouris, N		Anagnostopoulos, Christoforos; Tasoulis, Dimitris; Hand, David J.; Adams, Niall M.			Online optimization for variable selection in data streams	ECAI 2008, PROCEEDINGS	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	18th European Conference on Artificial Intelligence	JUL 21-25, 2008	Patras, GREECE	European Comm Artificial Intelligence, Hellen Artificial Intelligence Soc	Univ Patras		LASSO; REGRESSION	Variable selection for regression is a classical statistical problem, motivated by concerns that too many covariates invite overfitting. Existing approaches notably include a class of convex optimisation techniques, such as the Lasso algorithm. Such techniques are invariably reliant on assumptions that are unrealistic in streaming contexts, namely that the data is available off-line and the correlation structure is static. In this paper, we relax both these constraints, proposing for the first time an online implementation of the Lasso algorithm with exponential forgetting. We also optimise the model dimension and the speed of forgetting in an online manner, resulting in a fully automatic scheme. In simulations our scheme improves on recursive least squares in dynamic environments, while also featuring model discovery and changepoint detection capabilities.	[Anagnostopoulos, Christoforos; Tasoulis, Dimitris; Hand, David J.] Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, London SW7 2PG, England	Anagnostopoulos, C (reprint author), Univ London Imperial Coll Sci Technol & Med, Inst Math Sci, London SW7 2PG, England.	cda@imperial.ac.uk					Akaike H., 1973, INT S INF THEOR, P267, DOI DOI 10.2307/2334537; ANAGNOSTOPOULOS C, 2008, P 10 INT C COMP MOD; ANAGNOSTOPOULOS C, 2008, P ACM S APPL COMP, V2; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; Efron B, 2004, ANN STAT, V32, P407; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Breiman L, 1996, ANN STAT, V24, P2350; CAMPI M, 1994, J MATH SYSTEMS, V4, P13; Dong Guozhu, 2003, P 2003 ACM SIGMOD WO; Draper N.R., 1966, APPL LINEAR REGRESSI; Golub G., 1996, MATRIX COMPUTATIONS; Haykin S., 1996, ADAPTIVE FILTER THEO; Miller A, 2002, SUBSET SELECTION REG, V2nd; Yi B.-K., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839383; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	17	4	4	2	4	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		978-1-58603-891-5	FR ART INT			2008	178						132	136		10.3233/978-1-58603-891-5-132		5	Computer Science, Artificial Intelligence	Computer Science	BMY54	WOS:000273903100025		
J	Lounici, K				Lounici, Karim			Sup-norm convergence rate and sign concentration property of Lasso and Dantzig estimators	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Linear model; Lasso; Dantzig; Sparsity; Model selection; Sign consistency	SELECTION; REGRESSION	We derive the l(infinity) convergence rate simultaneously for Lasso and Dantzig estimators in a high-dimensional linear regression model under a mutual coherence assumption on the Gram matrix of the design and two different assumptions on the noise: Gaussian noise and general noise with finite variance. Then we prove that simultaneously the thresholded Lasso and Dantzig estimators with a proper choice of the threshold enjoy a sign concentration property provided that the non-zero components of the target vector are not too small.	[Lounici, Karim] Univ Paris 07, Lab Probabilites & Modeles Aleatoires, UMR CNRS 7599, F-75251 Paris 05, France; [Lounici, Karim] CREST, Stat Lab, F-92240 Malakoff, France	Lounici, K (reprint author), CREST, Stat Lab, 3 Ave Pierre Larousse, F-92240 Malakoff, France.	lounici@math.jussieu.fr					Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; BICKEL PJ, 2007, ANN STAT; Bunea F, 2007, ANN STAT, V35, P1674, DOI 10.1214/009053606000001587; BUNEA F, 2007, IMS LECT NOTES MONOG; Bunea F, 2007, ELECTRON J STAT, V1, P169, DOI 10.1214/07-EJS008; CANDES E, 2007, ANN STAT IN PRESS; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; EFRON B, 2004, ANN STAT, V32, P402; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; KOLTCHINSKII V, 2006, SPARSITY PENAL UNPUB; KOLTCHINSKII V, 2007, DANTZIG SELECT UNPUB; MEINSHAUSEN N, 2006, ANN STATI IN PRESS; Nemirovski A., 2000, LECT NOTES MATH, V1738, P85; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; VANDERGEER SA, 2007, ANN STAT IN PRESS; VANDERGEER SA, 2007, SEM STAT ETH ZUR; Wainwright M., 2006, 709 UC BERK DEP STAT; ZHANG CH, 2007, ANN STAT IN PRESS	23	43	43	0	0	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2008	2						90	102		10.1214/08-EJS177		13	Statistics & Probability	Mathematics	V16FB	WOS:000207854400004		
J	Wu, SH; Zou, H; Yuan, M				Wu, Seongho; Zou, Hui; Yuan, Ming			Structured variable selection in support vector machines	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Classification; Heredity; Nonparametric estimation; Support vector machine; Variable selection		When applying the support vector machine (SVM) to high-dimensional classification problems, we often impose a sparse structure in the SVM to eliminate the influences of the irrelevant predictors. The lasso and other variable selection techniques have been successfully used in the SVM to perform automatic variable selection. In some problems, there is a natural hierarchical structure among the variables. Thus, in order to have an interpretable SVM classifier, it is important to respect the heredity principle when enforcing the sparsity in the SVM. Many variable selection methods, however, do not respect the heredity principle. In this paper we enforce both sparsity and the heredity principle in the SVM by using the so-called structured variable selection (SVS) framework originally proposed in [20]. We minimize the empirical hinge loss under a set of linear inequality constraints and a lasso-type penalty. The solution always obeys the desired heredity principle and enjoys sparsity. The new SVM classifier can be efficiently fitted, because the optimization problem is a linear program. Another contribution of this work is to present a nonparametric extension of the SVS framework, and we propose nonparametric heredity SVMs. Simulated and real data are used to illustrate the merits of the proposed method.	[Wu, Seongho; Zou, Hui] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA; [Yuan, Ming] Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA	Zou, H (reprint author), Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA.	swu@stat.umn.edu; hzou@stat.umn.edu; myuan@isye.gatech.edu			National Science Foundation [DMS 0706733]	Zou's research is supported by National Science Foundation grant DMS 0706733.	BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Hastie T, 2004, BIOSTATISTICS, V5, P329, DOI 10.1093/biostatistics/kxh010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Efron B, 2004, ANN STAT, V32, P407; Bradley Paul S., 1998, ICML 98; Chipman H, 1996, CAN J STAT, V24, P17, DOI 10.2307/3315687; Chipman H, 1997, TECHNOMETRICS, V39, P372, DOI 10.2307/1271501; CHOI N, 2006, VARIABLE SELECTION S; de Boor C., 1978, APPL MATH SCI, V27; Green PJ, 1994, MONOGRAPHS STAT APPL, V58; HAMADA M, 1992, J QUAL TECHNOL, V24, P130; Hamada M, 2000, WILEY SERIES PROBABI; Hastie T., 2001, SPRINGER SERIES STAT; Hastie T. J., 1990, MONOGRAPHS STAT APPL, V43; Vapnik V.N., 1996, NATURE STAT LEARNING; Venables WN, 1994, STAT COMPUTING; Wahba G., 1990, CBMS NSF REGIONAL C, V59; YUAN M, 2007, STRUCTURED VARIABLE; Yuan M, 2005, J AM STAT ASSOC, V100, P1215, DOI 10.1198/016214505000000367; Zhao P, 2006, GROUPED HIERARCHICAL; ZHU J, 2004, ADV NEURAL NFORMATIO, V16; ZOU H, 2005, STAT SINICA IN PRESS	24	4	4	0	2	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2008	2						103	117		10.1214/07-EJS125		15	Statistics & Probability	Mathematics	V16FB	WOS:000207854400005		
J	Xie, BH; Pan, W; Shen, XT				Xie, Benhuai; Pan, Wei; Shen, Xiaotong			Penalized model-based clustering with cluster-specific diagonal covariance matrices and grouped variables	ELECTRONIC JOURNAL OF STATISTICS			English	Article						BIC; EM algorithm; High-dimension but low-sample size; L(1) penalization; Microarray gene expression; Mixture model; Penalized likelihood		Clustering analysis is one of the most widely used statistical tools in many emerging areas such as microarray data analysis. For microarray and other high-dimensional data, the presence of many noise variables may mask underlying clustering structures. Hence removing noise variables via variable selection is necessary. For simultaneous variable selection and parameter estimation, existing penalized likelihood approaches in model-based clustering analysis all assume a common diagonal covariance matrix across clusters, which however may not hold in practice. To analyze high-dimensional data, particularly those with relatively low sample sizes, this article introduces a novel approach that shrinks the variances together with means, in a more general situation with cluster-specific (diagonal) covariance matrices. Furthermore, selection of grouped variables via inclusion or exclusion of a group of variables altogether is permitted by a specific form of penalty, which facilitates incorporating subject-matter knowledge, such as gene functions in clustering microarray samples for disease subtype discovery. For implementation, EM algorithms are derived for parameter estimation, in which the Si-steps clearly demonstrate the effects of shrinkage and thresholding. Numerical examples, including an application to acute leukemia subtype discovery with microarray gene expression data, are provided to demonstrate the utility and advantage of the proposed method.	[Xie, Benhuai; Pan, Wei] Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA; [Shen, Xiaotong] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	Pan, W (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA.	benhuaix@biostat.umn.edu; weip@biostat.umn.edu; xshen@stat.umn.edu			NIH [GM081535, HL65462]; UM AHC; NSF [IIS-0328802, DMS-0604394]	We thank the editor loran extremely timely and helpful review. This research was partially supported by NIH grant GM081535; in addition, BX and WP by NIH grant HL65462 and a UM AHC Faculty Research Development grant, and XS by NSF grants IIS-0328802 and DMS-0604394.	Alaiya AA, 2002, INT J CANCER, V98, P895, DOI 10.1002/ijc.10288; Lin XH, 1999, J ROY STAT SOC B, V61, P381, DOI 10.1111/1467-9868.00183; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Tian L, 2005, P NATL ACAD SCI USA, V102, P13544, DOI 10.1073/pnas.0506577102; Newton MA, 2007, ANN APPL STAT, V1, P85, DOI 10.1214/07-AOAS104; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; McLachlan GJ, 2003, COMPUT STAT DATA AN, V41, P379, DOI 10.1016/S0167-9473(02)00183-4; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Efron B, 2007, ANN APPL STAT, V1, P107, DOI 10.1214/07-AOAS101; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Antonov AV, 2004, BIOINFORMATICS, V20, P644, DOI 10.1093/bioinformatics/btg462; Baker SG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-407; Bardi E, 2004, PEDIATR NEPHROL, V19, P1145, DOI 10.1007/s00467-004-1548-3; Fraley C, 2006, 504 U WASH DEP STAT; Friedman J.H., 2004, J ROYAL STAT SOC B, V66, P1; Ghosh D, 2002, BIOINFORMATICS, V18, P275, DOI 10.1093/bioinformatics/18.2.275; GNANADESIKAN R, 1995, J CLASSIF, V12, P113, DOI 10.1007/BF01202271; GU C, 2005, ANN STAT, V33, P377; Hoff PD, 2006, BAYESIAN ANAL, V1, P321; HOFF PD, 2004, J R STAT SOC B, V66, P845; Huang DS, 2006, BIOINFORMATICS, V22, P1259, DOI 10.1093/bioinformatics/btl065; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; Huang Xiaohong, 2002, Funct Integr Genomics, V2, P126, DOI 10.1007/s10142-002-0066-2; HUBERT L, 1985, J CLASSIF, V2, P1993; Kaufman L, 1990, FINDING GROUPS DATA; Kim S, 2006, BIOMETRIKA, V93, P877, DOI 10.1093/biomet/93.4.877; Koo JY, 2006, BIOINFORMATICS, V22, P950, DOI 10.1093/bioinformatics/btl029; Li HZ, 2001, GENOME BIOL, V2; Liao JG, 2007, BIOINFORMATICS, V23, P1945, DOI 10.1093/bioinformatics/btm287; Liu J. S., 2003, BAYESIAN STAT, V7, P249; Ma P, 2006, NUCLEIC ACIDS RES, V34, P1261, DOI 10.1093/nar/gkl013; Mangasarian O. L., 2004, P SIAM INT C DAT MIN, P23; McLachlan G, 2002, FINITE MIXTURE MODEL; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; Pan W, 2006, BIOINFORMATICS, V22, P795, DOI 10.1093/bioinformatics/btl011; Pan W, 2006, J ROY STAT SOC C-APP, V55, P301; Pan W, 2006, BIOINFORMATICS, V22, P2388, DOI 10.1093/bioinformatics/btl393; Pan W, 2007, J MACH LEARN RES, V8, P1145; RAETERY AE, 2006, J AM STAT ASSOC, V101, P168; Tadesse MG, 2005, J AM STAT ASSOC, V100, P602, DOI 10.1198/0162145040000001565; Thalamuthu A, 2006, BIOINFORMATICS, V22, P2405, DOI 10.1093/bioinformatics/btl406; TYCKO B, 1991, J EXP MED, V174, P867, DOI 10.1084/jem.174.4.867; WANG S, 2008, BIOMETRICS IN PRESS; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; WRIGHT DD, 1994, MOL CELL BIOL, V14, P2429; XIE B, 2008, BIOMETRICS IN PRESS; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977; Zhao P, 2006, GROUPED HIERARCHICAL; ZOU H, 2004, ANN STAT IN PRESS	59	17	18	1	4	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2008	2						168	212		10.1214/08-EJS194		45	Statistics & Probability	Mathematics	V16FB	WOS:000207854400009		
J	Fokianos, K				Fokianos, Konstantinos			Comparing two samples by penalized logistic regression	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Empirical likelihood; biased sampling; penalty; semiparametric; shrinkage; mean square error; power	SELECTION BIAS MODELS; EMPIRICAL DISTRIBUTIONS; NONORTHOGONAL PROBLEMS; RIDGE REGRESSION; LIKELIHOOD; LASSO; REGULARIZATION	Inference based on the penalized density ratio model is proposed and studied. The model under consideration is specified by assuming that the log-likelihood function of two unknown densities is of some parametric form. The model has been extended to cover multiple samples problems while its theoretical properties have been investigated using large sample theory. A main application of the density ratio model is testing whether two, or more, distributions are equal. We extend these results by arguing that the penalized maximum empirical likelihood estimator has less mean square error than that of the ordinary maximum likelihood estimator, especially for small samples. In fact, penalization resolves any existence problems of estimators and a modified Wald type test statistic can be employed for testing equality of the two distributions. A limited simulation study supports further the theory.	Univ Cyprus, Dept Math & Stat, Nicosia, Cyprus	Fokianos, K (reprint author), Univ Cyprus, Dept Math & Stat, Nicosia, Cyprus.	fokianos@ucy.ac.cy					Albert A, 1984, BIOMETRIKA, V71, P10; ANDERSON JA, 1972, BIOMETRIKA, V59, P19, DOI 10.2307/2334611; ANDERSON JA, 1979, BIOMETRIKA, V66, P17, DOI 10.1093/biomet/66.1.17; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Hastie T, 2004, BIOSTATISTICS, V5, P329, DOI 10.1093/biostatistics/kxh010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; VARDI Y, 1982, ANN STAT, V10, P616, DOI 10.1214/aos/1176345802; Breslow NE, 1980, STATISTICAL METHODS, V1, P346; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; Cox D. R., 1989, ANAL BINARY DATA; FAREWELL VT, 1979, BIOMETRIKA, V66, P27, DOI 10.1093/biomet/66.1.27; Fokianos K, 2001, TECHNOMETRICS, V43, P56, DOI 10.1198/00401700152404327; Fokianos K, 2006, ANN I STAT MATH, V58, P475, DOI 10.1007/s10463-005-0022-8; Gilbert PB, 2000, ANN STAT, V28, P151, DOI 10.1214/aos/1016120368; Gilbert PB, 1999, BIOMETRIKA, V86, P27, DOI 10.1093/biomet/86.1.27; GILL RD, 1988, ANN STAT, V16, P1069, DOI 10.1214/aos/1176350948; HOERL AE, 1970, TECHNOMETRICS, V12, P69, DOI 10.2307/1267352; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; McCullagh P., 1989, GEN LINEAR MODELS; Murphy SA, 2000, J AM STAT ASSOC, V95, P449, DOI 10.2307/2669386; Owen A. B., 2001, EMPIRICAL LIKLEIHOOD; PRENTICE RL, 1979, BIOMETRIKA, V66, P403, DOI 10.1093/biomet/66.3.403; Qin J, 1998, BIOMETRIKA, V85, P619, DOI 10.1093/biomet/85.3.619; Qin J, 1997, BIOMETRIKA, V84, P609, DOI 10.1093/biomet/84.3.609; Santner T. J., 1989, STAT ANAL DISCRETE D; VARDI Y, 1985, ANN STAT, V13, P178, DOI 10.1214/aos/1176346585; Zhang B, 2000, SCAND J STAT, V27, P263, DOI 10.1111/1467-9469.00188	31	3	3	1	2	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2008	2						564	580		10.1214/07-EJS078		17	Statistics & Probability	Mathematics	V16FB	WOS:000207854400023		
J	Nardi, Y; Rinaldo, A				Nardi, Yuval; Rinaldo, Alessandro			On the asymptotic properties of the group lasso estimator for linear models	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Least Squares; Sparsity; Group-Lasso; Model Selection; Oracle Inequalities; Persistence	NONCONCAVE PENALIZED LIKELIHOOD; VARIABLE SELECTION; ORACLE INEQUALITIES; REGRESSION; PARAMETERS; NUMBER	We establish estimation and model selection consistency, prediction and estimation bounds and persistence for the group-lasso estimator and model selector proposed by Yean and Lin (2006) for least squares problems when the covariates have a not grouping structure. We consider the case of a fixed-dimensional parameter space with increasing sample size and the double asymptotic scenario where the model complexity changes with the sample size.	[Nardi, Yuval; Rinaldo, Alessandro] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA	Nardi, Y (reprint author), Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA.	yuval@stat.cmu.edu; arinaldo@stat.cmu.edu			NSF [EIA-0131884, DMS-0631589]; Pennsylvania Department of Health;  [DAAD19-02-1-3-0389]	Supported in part by NSF grant EIA-0131884 and Army contract DAAD19-02-1-3-0389.Supported in part by NSF grant DMS-0631589 and a grant from the Pennsylvania Department of Health through the Commonwealth Universal Research Enhancement Program.	Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Meier L, 2008, J R STAT SOC B, V70, P53; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Bach F., 2007, J MACHINE L IN PRESS; BICKEL PJ, 2007, ANN STAT UNPUB; Bunea F, 2007, ANN STAT, V35, P1674, DOI 10.1214/009053606000001587; Bunea F, 2007, ELECTRON J STAT, V1, P169, DOI 10.1214/07-EJS008; Cavalier L, 2002, ANN STAT, V30, P843; Dahinden C., 2006, 132 SWISS FED I TECH; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; GEYER CJ, 1994, ANN STAT, V22, P1993, DOI 10.1214/aos/1176325768; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; Greenshtein H., 2006, ANN STAT, V34, P2367; KIM Y, 2006, STAT SINICA, V16; Koltchinskii V., 2005, SPARSITY PENAL UNPUB; LEDOUX M., 1991, PROBABILITY BANACH S; Lounici K, 2008, ELECTRON J STAT, V2, P90, DOI 10.1214/08-EJS177; Massart P, 2007, LECT NOTES MATH, V1896, P1, DOI 10.1007/978-3-540-48503-2; Meinshausen N., 2006, ANN STAT IN PRESS; Nardi N., 2007, LOG LINER GROU UNPUB; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; PORTNOY S, 1988, ANN STAT, V16, P356, DOI 10.1214/aos/1176350710; Ravikumar P., 2007, SPARSE ADDITIV UNPUB; Rinaldo, 2006, COMPUTING MAXIMUM LI; van de Geer S.A., 2007, LECT EMPIRICAL PROCE; van der Vaart A. W., 1998, WEAK CONVERGENCE EMP; Wainwright M. J., 2007, INFORM THEORETIC LIM; Wainwright M.J., 2006, 708 UC BERK DEP STAT; Zhang H., 2007, ANN STAT IN PRESS; Zhang T., 2007, SOME SHARP PER UNPUB; Zhao P., 2008, GROUPED HIERAR UNPUB; Zhou N., 2007, GROUP VARIABLE UNPUB; Zhou S., 2007, COMPRESSED REG UNPUB	42	34	35	0	0	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2008	2						605	633		10.1214/08-EJS200		29	Statistics & Probability	Mathematics	V16FB	WOS:000207854400025		
J	Lecue, G				Lecue, Guillaume			Classification with minimax fast rates for classes of Bayes rules with sparse representation	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Classification; Sparsity; Decision dyadic trees; Minimax rates; Aggregation		We consider the classification problem on the cube [0,1](d) when the Bayes rule is known to belong to some new functions classes. These classes are made of prediction rules satisfying some conditions regarding their coefficients when developed over the (overcomplete) basis of indicator functions of dyadic cubes of [0, 1](d). The main concern of the paper is on the thorough analysis of the approximation term, which is in general bypassed in the classification literature. An adaptive classifier is designed to achieve the minimax rate of convergence (up to a logarithmic factor) over these functions classes. Lower bounds on the convergence rate over these classes are established when the underlying marginal of the design is comparable to the Lebesgue measure. Connections with some existing models for classification (RKHS and "boundary fragements") are established.	Univ Paris 06, CNRS, UMR 7599, Lab Probabil & Modeles Aleatoires, F-75252 Paris, France	Lecue, G (reprint author), Univ Paris 06, CNRS, UMR 7599, Lab Probabil & Modeles Aleatoires, 4 Pl Jussieu,Boite Courrier 188, F-75252 Paris, France.	lecue@ccr.jussieu.fr					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tsybakov AB, 2004, ANN STAT, V32, P135; Murthy SK, 1998, DATA MIN KNOWL DISC, V2, P345, DOI 10.1023/A:1009744630224; Antos A, 1999, IEEE T PATTERN ANAL, V21, P643, DOI 10.1109/34.777375; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI DOI 10.2307/1990404; ASSOUAD P, 1983, CR ACAD SCI I-MATH, V296, P1021; Blanchard G, 2007, MACH LEARN, V66, P209, DOI 10.1007/s10994-007-0717-6; BOUCHERON S., 2005, ESAIM-PROBAB STAT, V9, P323, DOI 10.1051/ps:2005018; Breiman L., 1984, CLASSIFICATION REGRE; Devroye L, 1996, PROBABILISTIC THEORY; Korostelev A. P., 1993, LECT NOTES STAT, V82; LECUE G, 2006, P 19 ANN C LEARN THE, V32, P364; Lecue G, 2007, BERNOULLI, V13, P1000, DOI 10.3150/07-BEJ6044; Lugosi G, 2004, ANN STAT, V32, P30; Mammen E, 1999, ANN STAT, V27, P1808; Massart P., 2006, ANN STAT, V34; Meyer Y., 1990, ONDELETTES OPERATEUR; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Scott C, 2006, IEEE T INFORM THEORY, V52, P1335, DOI 10.1109/TIT.2006.871056; Steinwart I., 2006, P 19 ANN C LEARN THE, V32, P79; Steinwart I., 2006, ANN STAT, V35; Thomas J. A., 1991, ELEMENTS INFORM THEO; Tsybakov AB, 2005, ANN STAT, V33, P1203, DOI 10.1214/009053604000001066; Vayatis N, 2003, J MACHINE LEARNING R, V4, P861; Yang YH, 1999, IEEE T INFORM THEORY, V45, P2285; Yang YH, 1999, IEEE T INFORM THEORY, V45, P2271	26	2	2	0	0	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2008	2						741	773		10.1214/07-EJS015		33	Statistics & Probability	Mathematics	V16FI	WOS:000207855100003		
J	Alquier, P				Alquier, Pierre			LASSO, Iterative Feature Selection and the Correlation Selector: Oracle inequalities and numerical performances	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Regression estimation; statistical learning; confidence regions; shrinkage and thresholding methods; LASSO	REGRESSION	We propose a general family of algorithms for regression estimation with quadratic loss, on the basis of geometrical considerations. These algorithms are able to select relevant functions into a large dictionary. We prove that a lot of methods that have already been studied for this task (LASSO, Dantzig selector, Iterative Feature Selection, among others) belong to our family, and exhibit another particular member of this family that we call Correlation Selector in this paper. Using general properties of our family of algorithm we prove oracle inequalities for IFS, for the LASSO and for the Correlation Selector, and compare numerical performances of these estimators on a toy example.	[Alquier, Pierre] Univ Paris 07, Lab Probabil & Modeles Aleatoires, F-75252 Paris 05, France; [Alquier, Pierre] CREST LS, F-92240 Malakoff, France	Alquier, P (reprint author), Univ Paris 07, Lab Probabil & Modeles Aleatoires, 175 Rue Chevaleret, F-75252 Paris 05, France.	alquier@ensae.fr					Alquier P., 2008, ESAIM-PROBAB STAT, V12, P438, DOI 10.1051/ps:2007050; Alquier P, 2008, ANN I H POINCARE-PR, V44, P47, DOI 10.1214/07-AIHP106; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Efron B, 2004, ANN STAT, V32, P407; Bakin S, 1999, THESIS AUSTR NATL U; Barron AR, 2008, ANN STAT, V36, P64, DOI 10.1214/009053607000000631; BICKEL P, ANN STAT IN PRESS; Bunea F., 2007, P 20 ANN C LEARN THE, P530; BUNEA F, 2008, 08084051 ARXIV; Bunea F, 2007, ELECTRON J STAT, V1, P169, DOI 10.1214/07-EJS008; Candes E., 2007, ANN STAT, V35; Catoni O., 2003, PAC BAYESIAN APPROAC; CHESNEAU C, 2007, SOME THEORETIC UNPUB; Cohen A, 2000, HDB NUMERICAL ANAL, V7; FRANK L, 1993, TECHNOMETRICS, V16, P499; Huang C., 2008, RISK PENALIZED LEAST; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Panchenko D, 2003, ANN PROBAB, V31, P2068, DOI 10.1214/aop/1068646378; R Development Core Team, 2004, R LANG ENV STAT COMP; Vapnik Vladimir, 1998, NATURE STAT LEARNING	21	2	2	0	1	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2008	2						1129	1152		10.1214/08-EJS288		24	Statistics & Probability	Mathematics	V16FI	WOS:000207855100019		
B	Nguyen, V; Steece, B; Boehm, B			ACM	Nguyen, Vu; Steece, Bert; Boehm, Barry			A Constrained Regression Technique for COCOMO Calibration	ESEM'08: PROCEEDINGS OF THE 2008 ACM-IEEE INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT			English	Proceedings Paper	ACM/IEEE International Symposium on Empirical Software Engineering and Measurement	OCT 09-10, 2008-2009	Kaiserslautern, GERMANY	ACM SIGSOFT, IEEE CS, Siemens AG, Robert Bosch GmbH		Software cost estimation; COCOMO; calibration; linear regression with constraints; optimization; linear programming; quadratic programming	COST ESTIMATION; SOFTWARE; MODELS	Building cost estimation models is often considered a search problem in which the solver should return an optimal solution satisfying an objective function. This solution also needs to meet certain constraints. For example, a solution for the estimates coefficients of COCOMO models must be non-negative. In this research, we introduce a constrained regression technique that uses objective functions and constraints to estimate the coefficients of the COCOMO models. To access the performance of the proposed technique, we run a cross-validation procedure and compare the prediction accuracy from different approaches such as least squares, stepwise, Lasso, and Ridge regression. Our result suggests that the regression model that minimizes the sum of relative errors and imposes non-negative coefficients is a favorable technique for calibrating the COCOMO model parameters.	[Nguyen, Vu; Boehm, Barry] Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA	Nguyen, V (reprint author), Univ So Calif, Dept Comp Sci, 941 W 37th Pl,SAL 332, Los Angeles, CA 90089 USA.	nguyenvu@usc.edu; berts@usc.edu; boehm@usc.edu					Jorgensen M, 2007, IEEE T SOFTWARE ENG, V33, P33, DOI 10.1109/TSE.2007.256943; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Efron B, 2004, ANN STAT, V32, P407; Boehm B., 2000, ANN SOFTWARE ENG; Boehm Barry W., 2000, SOFTWARE COST ESTIMA; Boehm B.W., 1981, SOFTWARE ENG EC; BOEHM BW, 2005, USCCSE2005513; Burgess CJ, 2001, INFORM SOFTWARE TECH, V43, P863; Chen ZH, 2005, IEEE SOFTWARE, V22, P38, DOI 10.1109/MS.2005.151; Chulani S, 1999, IEEE T SOFTWARE ENG, V25, P573, DOI 10.1109/32.799958; Conte S, 1986, SOFTWARE ENG METRICS; Dolado JJ, 2001, INFORM SOFTWARE TECH, V43, P61, DOI 10.1016/S0950-5849(00)00137-3; Ferens D. V., 1998, J PARAMETRICS, V18, P55; Gray A, 1997, INFORM SOFTWARE TECH, V39, P425, DOI 10.1016/S0950-5849(96)00006-7; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; KEMERER CF, 1987, COMMUN ACM, V30, P416, DOI 10.1145/22899.22906; Kitchenham B. A., 2001, IEE Proceedings-Software, V148, DOI 10.1049/ip-sen:20010506; Kohavi R, 1997, ARTIF INTELL, V1, P273; Lokan C., 2005, P 11 IEEE INT SOFTW, V34; MENZIES T, 2006, IEEE T SOFTWARE ENG; Miller A, 2002, SUBSET SELECTION REG, V2nd; NARULA SC, 1977, TECHNOMETRICS, V19; Pickard L., 1999, Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403), DOI 10.1109/METRIC.1999.809734; SHEPPERD M, 2001, P 7 IEEE INT SOFTW M, P987; Shepperd M, 1997, IEEE T SOFTWARE ENG, V23, P736, DOI 10.1109/32.637387; Weisberg S., 2005, APPL LINEAR REGRESSI	26	6	6	0	1	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-59593-971-5				2008							213	222				10	Computer Science, Software Engineering	Computer Science	BJJ30	WOS:000266371500024		
S	Assimes, TL; Olshen, AB; Narasimhan, B; Olshen, RA		Rao, DC; Gu, CC		Assimes, Themistocles L.; Olshen, Adam B.; Narasimhan, Balasubramanian; Olshen, Richard A.			Associations Among Multiple Markers and Complex Disease: Models, Algorithms, and Applications	GENETIC DISSECTION OF COMPLEX TRAITS, 2ND EDITION	Advances in Genetics		English	Review; Book Chapter							GENOME-WIDE ASSOCIATION; PRESSURE PROGRAM FBPP; GAMETIC DISEQUILIBRIUM; LINKAGE DISEQUILIBRIUM; BLOOD-PRESSURE; RISK LOCI; HAPLOTYPES; HYPERTENSION; GENE; REGRESSION	This chapter is a report on collaborations among its authors and others over many years. It devolves from our goal of understanding genes, their main and epistatic effects combined with interactions involving demographic and environmental features also, as together they predict genetically complex diseases. Thus, our goal is "association." Particular phenotypes of interest to us are hypertension, insulin resistance, angina, and myocardial infarction. Prediction of complex disease is notoriously difficult, though it would be made easier were we given strand-specific information on genotype. Unfortunately, with current technology, genotypic information comes to us "unphased." While obviously we have strand-specific information when genotype is homozygous, we do not have such information when genotype is heterozygous. To summarize, the ultimate goals of approaches we provide is to predict phenotype, typically untoward or not, within a specific window of time. Our approach is neither through linkage nor from finding haplotype frequencies per se. (C) 2008, Elsevier Inc.	[Assimes, Themistocles L.] Stanford Univ, Dept Med, Div Cardiovasc Med, Stanford, CA 94305 USA; [Olshen, Adam B.] Mem Sloan Kettering Canc Ctr, Dept Epidemiol & Biostat, New York, NY 10021 USA; [Narasimhan, Balasubramanian; Olshen, Richard A.] Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA; [Narasimhan, Balasubramanian; Olshen, Richard A.] Stanford Univ, Dept Stat, Stanford, CA 94305 USA; [Olshen, Richard A.] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Assimes, TL (reprint author), Stanford Univ, Dept Med, Div Cardiovasc Med, Stanford, CA 94305 USA.						Agresti A., 1992, STAT SCI, V7, P131, DOI DOI 10.1214/SS/1177011454; HOCHBERG Y, 1988, BIOMETRIKA, V75, P800, DOI 10.1093/biomet/75.4.800; Rioux JD, 2007, NAT GENET, V39, P596, DOI 10.1038/ng2032; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Helgadottir A, 2007, SCIENCE, V316, P1491, DOI 10.1126/science.1142842; Duerr RH, 2006, SCIENCE, V314, P1461, DOI 10.1126/science.1135245; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; BLACKWELL D, 1953, ANN MATH STAT, V24, P265, DOI 10.1214/aoms/1177729032; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Barrett JC, 2005, BIOINFORMATICS, V21, P263, DOI 10.1093/bioinformatics/bth457; Schaid DJ, 2002, AM J HUM GENET, V70, P425, DOI 10.1086/338688; Zeggini E, 2007, SCIENCE, V316, P1336, DOI 10.1126/science.1142364; Benjamini Y, 2001, ANN STAT, V29, P1165; HEDRICK PW, 1987, GENETICS, V117, P331; Frayling TM, 2007, SCIENCE, V316, P889, DOI 10.1126/science.1141634; Sladek R, 2007, NATURE, V445, P881, DOI 10.1038/nature05616; Chanock SJ, 2007, NATURE, V447, P655, DOI 10.1038/447655a; Carlson CS, 2004, AM J HUM GENET, V74, P106, DOI 10.1086/381000; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Scott LJ, 2007, SCIENCE, V316, P1341, DOI 10.1126/science.1142382; McPherson R, 2007, SCIENCE, V316, P1488, DOI 10.1126/science.1142447; Bloch DA, 2002, J COMPUT GRAPH STAT, V11, P263, DOI 10.1198/106186002760180509; Breiman L., 1984, CLASSIFICATION REGRE; Clark AG, 2004, GENET EPIDEMIOL, V27, P321, DOI 10.1002/gepi.20025; Crawford DC, 2005, ANNU REV MED, V56, P303, DOI 10.1146/annurev.med.56.082103.104540; Saxena R, 2007, SCIENCE, V316, P1331, DOI 10.1126/science.1142358; EAGLESON GK, 1969, AUST J STAT, V11, P29; EVERITT BS, 2001, CLUSTER CLUSTER ANAL; Boerwinkle E, 2002, HYPERTENSION, V39, P3; Hastie T., 2001, ELEMENTS STAT LEARNI; Huang J, 2004, P NATL ACAD SCI USA, V101, P10529, DOI 10.1073/pnas.0403794101; LANCASTER HO, 1963, ANN MATH STAT, V34, P532, DOI 10.1214/aoms/1177704165; LEWONTIN RC, 1988, GENETICS, V120, P849; Mohlke KL, 2001, GENOME RES, V11, P1221, DOI 10.1101/gr.173201; PARK MY, 2006, REGULARIZATION UNPUB; PHELPS RR, 2001, BERLIN HEIDELBERGLEC, V1757; Risch NJ, 2000, NATURE, V405, P847, DOI 10.1038/35015718; Schaid DJ, 2004, GENET EPIDEMIOL, V27, P348, DOI 10.1002/gepi.20037; *SEATTL SNPS, 2007, NHLBI PROGR GEN APPL; Steinthorsdottir V, 2007, NAT GENET, V39, P770, DOI 10.1038/ng2043; Burton PR, 2007, NATURE, V447, P661, DOI 10.1038/nature05911; Vapnik V.N., 1999, NATURE STAT LEARNING; Wu XD, 2006, AM J HYPERTENS, V19, P122, DOI 10.1016/j.amjhyper.2005.07.010	44	2	2	1	3	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA	0065-2660		978-0-12-373883-7	ADV GENET	Adv. Genet.		2008	60						437	464		10.1016/S0065-2660(07)00416-6		28	Genetics & Heredity	Genetics & Heredity	BQB52	WOS:000280575900018	18358329	
S	Dhillon, PS; Foster, D; Ungar, LH	Giannotti, F	Gunopulos, D; Turini, F; Zaniolo, C; Ramakrishnan, N; Wu, XD		Dhillon, Paramveer S.; Foster, Dean; Ungar, Lyle H.	Giannotti, F		Efficient Feature Selection in the Presence of Multiple Feature Classes	ICDM 2008: EIGHTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS	IEEE International Conference on Data Mining		English	Proceedings Paper	8th IEEE International Conference on Data Mining	DEC 15-19, 2008	Pisa, ITALY	IEEE, Yahoo Res, WIND, Microsoft, Ask com, IBM, Natl Sci Fdn, coop, BASE, Univ Pisa, Brite, Comune Pisa, Prov Pisa, Prov Lucca, Inst Sci & Tecnol Informazione, Consiglio Nazl Ric, GeoPKDD, Camera Commercia Pisa			REGRESSION; LASSO	We present an information theoretic approach to feature selection when the data possesses feature classes. Feature classes are pervasive in real data. For example, in gene expression data, the genes which serve as features may be divided into classes based on their membership in gene families or pathways. When doing word sense disambiguation or named entity extraction, features fall into classes including adjacent words, their parts of speech, and the topic and venue of the document the word is in. When predictive features occur predominantly in a small number of feature classes, our information theoretic approach significantly improves feature selection. Experiments on real and synthetic data demonstrate substantial improvement in predictive accuracy over the standard L(0) penalty-based stepwise and streamwise feature selection methods as well as over Lasso and Elastic Nets, all of which are oblivious to the existence of feature classes.	[Dhillon, Paramveer S.; Ungar, Lyle H.] Univ Penn, CIS, Philadelphia, PA 19104 USA	Dhillon, PS (reprint author), Univ Penn, CIS, Philadelphia, PA 19104 USA.	pasing@gseas.upenn.edu; foster@wharton.upenn.edu; ungar@cis.upenn.edu					Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Efron B, 2007, ANN APPL STAT, V1, P107, DOI 10.1214/07-AOAS101; Mootha VK, 2003, NAT GENET, V34, P267, DOI 10.1038/ng1180; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; CHEN J, 2005, IJCNLP, P933; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; Rissanen J, 1999, COMPUT J, V42, P260, DOI 10.1093/comjnl/42.4.260; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Zhou J, 2006, J MACH LEARN RES, V7, P1861	12	1	1	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		978-0-7695-3502-9	IEEE DATA MINING			2008							779	784		10.1109/ICDM.2008.56		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BJA60	WOS:000264173600084		
S	Goetschalckx, R; Driessens, K; Sanner, S	Giannotti, F	Gunopulos, D; Turini, F; Zaniolo, C; Ramakrishnan, N; Wu, XD		Goetschalckx, Robby; Driessens, Kurt; Sanner, Scott	Giannotti, F		Cost-sensitive Parsimonious Linear Regression	ICDM 2008: EIGHTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS	IEEE International Conference on Data Mining		English	Proceedings Paper	8th IEEE International Conference on Data Mining	DEC 15-19, 2008	Pisa, ITALY	IEEE, Yahoo Res, WIND, Microsoft, Ask com, IBM, Natl Sci Fdn, coop, BASE, Univ Pisa, Brite, Comune Pisa, Prov Pisa, Prov Lucca, Inst Sci & Tecnol Informazione, Consiglio Nazl Ric, GeoPKDD, Camera Commercia Pisa				We examine linear regression problems where somefeatures may only be observable at a cost (e.g., in medical domains where features may correspond to diagnostic tests that take time and costs money). This can be important in the context of data mining, in order to obtain the best predictions from the data on a limited cost budget. We define a parsimonious linear regression objective criterion that jointly minimizes prediction error and feature cost. We modify least angle regression algorithms commonly used for sparse linear regression to produce the ParLiR algorithm, which not only provides an efficient and parsimonious solution as we demonstrate empirically, but it also provides formal guarantees that we prove theoretically	[Goetschalckx, Robby; Driessens, Kurt] Katholieke Univ Leuven, Louvain, Belgium	Goetschalckx, R (reprint author), Katholieke Univ Leuven, Louvain, Belgium.	Robby.Goetschalckx@cs.kuleuven.de; Kurt.Driessens@cs.kuleuven.be; Scott.Sanner@nicta.com.au					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Efron B, 2004, ANN STAT, V32, P407; Brown PJ, 1999, BIOMETRIKA, V86, P635; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Elkan C., 2001, IJCAI, P973; TORGO L, 2007, PRINCIPLES KNOWLEDGE, P597; Turney P., 2000, WORKSH COST SENS LEA; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; *U WAIK DEP COMP S, 2004, WEKA 3 DAT MIN SOFTW	9	1	1	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		978-0-7695-3502-9	IEEE DATA MINING			2008							809	814		10.1109/ICDM.2008.76		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BJA60	WOS:000264173600089		
S	Patra, S; Shanker, K; Kundu, D	Giannotti, F	Gunopulos, D; Turini, F; Zaniolo, C; Ramakrishnan, N; Wu, XD		Patra, Sabyasachi; Shanker, Kripa; Kundu, Debasis	Giannotti, F		Sparse Maximum Margin Logistic Regression for Credit Scoring	ICDM 2008: EIGHTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS	IEEE International Conference on Data Mining		English	Proceedings Paper	8th IEEE International Conference on Data Mining	DEC 15-19, 2008	Pisa, ITALY	IEEE, Yahoo Res, WIND, Microsoft, Ask com, IBM, Natl Sci Fdn, coop, BASE, Univ Pisa, Brite, Comune Pisa, Prov Pisa, Prov Lucca, Inst Sci & Tecnol Informazione, Consiglio Nazl Ric, GeoPKDD, Camera Commercia Pisa			CLASSIFICATION METHODS; SELECTION; PATH	The objective of credit scoring model is to categorize the applicants as either accepted or rejected debtors prior to granting credit. A modified logistic loss function is proposed which can approximate hinge loss and therefore the resulting model, maximum margin logistic regression (MMLR), has the classification capability of support vector machine (SVM) with low computational cost. Finally, to classify credit applicants, an efficient algorithm is also described for MMLR based on e.-boosting which can provide sparse estimation of coefficients for better stability and interpretability.	[Patra, Sabyasachi; Shanker, Kripa] Indian Inst Technol, Dept Ind & Mgt Engn, Kanpur 208016, Uttar Pradesh, India	Patra, S (reprint author), Indian Inst Technol, Dept Ind & Mgt Engn, Kanpur 208016, Uttar Pradesh, India.	sspatra@iitk.ac.in; ks@iitk.ac.in; kundu@iitk.ac.in					Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Hand DJ, 1997, J R STAT SOC A STAT, V160, P523; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; CHEN CH, 1996, COMPUTATIONAL OPTIMI, V8, P97; KIM J, 2005, GRADIENT LASSO ALGOR; Park CY, 2008, COMPUT STAT DATA AN, V52, P3709, DOI 10.1016/j.csda.2007.12.011; RENNIE J, MAXIMUM MARGIN UNPUB; Rosset S, 2004, J MACH LEARN RES, V5, P941; Wood SN, 2006, GEN ADDITIVE MODELS; Zhang J., 2003, P 20 INT C MACH LEAR; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	13	0	1	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		978-0-7695-3502-9	IEEE DATA MINING			2008							977	982		10.1109/ICDM.2008.84		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BJA60	WOS:000264173600117		
B	Nechva, KN; Berzinsh, G; Nechval, NA; Purgailis, M; Zolova, N		Kopytov, E; Pranevicius, H; Zavadskas, E; Yatskiv, I		Nechva, Konstanthi N.; Berzinsh, Gundars; Nechval, Nicholas A.; Purgailis, Maris; Zolova, Natalie			Information criterion for variable selection in econometric models and its applications	INTERNATIONAL CONFERENCE MODELLING OF BUSINESS, INDUSTRIAL AND TRANSPORT SYSTEMS			English	Proceedings Paper	International Conference on Modelling of Business, Industrial and Transport Systems	MAY 07-10, 2008	Riga, LATVIA	Transport &Telecommun Inst, Kaunas Univ Technol, Vilnius Gediminas Tech Unv, Latvian Operat Res Soc, Telemat & Logist Inst, Latvian Transport Dev & Educ Assoc, LitORS, Assoc European Operat Res Soc, Latvian Simulat Soc, Acad Pk Latvia		regression model; variable selection; criterion	CROSS-VALIDATION; LINEAR-REGRESSION; INFLATION CRITERION; MULTIPLE-REGRESSION; PREDICTION; SHRINKAGE; CHOICE	The analysis of regression data usually involves a comparison of several competing or candidate variables. Because the true variables are seldom known a priori, there is need for objective data-driven methods to aid in the selection of "good" variables. The problem of determining the "best" subset of variables has long been of interest to applied statisticians and, primary because of the current availability of high-speed computations, this problem has received considerable attention in the recent statistical literature. Often referred to as the problem of subset selection, it arises when one wants to model the relationship between a variable of interest and a subset of potential explanatory variables or predictors, but there is uncertainty about which subset to use. Several papers have dealt with various aspects of the problem but it appears that the typical regression user has not benefited appreciably. One reason for the lack of resolution of the problem is the fact that it is has not been well defined. Indeed, it is apparent that there is not a single problem, but rather several problems for which different answers might be appropriate. The intent of this paper is not to give specific answers but merely to present a new variable selection criterion, The variables, which optimise the criterion, are chosen to be the best variables. We find that the new criterion performs consistently well across a wide variety of variable selection problems. Practical utility of this criterion is demonstrated by numerical examples.	[Nechva, Konstanthi N.] Transport & Telecommun Inst, Dept Math Methods & Modelling, LV-1019 Riga, Latvia							Akaike H., 1973, P 2 INT S INF THEOR, P267; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; STONE M, 1977, J R STAT SOC B, V39, P44; SHIBATA R, 1981, BIOMETRIKA, V68, P45; HURVICH CM, 1989, BIOMETRIKA, V76, P297, DOI 10.1093/biomet/76.2.297; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; BRIEMAN L, 1992, J AM STAT ASSOC, V87, P738; BRIEMAN L, 1995, TECHNOMETRICS, V37, P373; Clyde M., 1999, BAYESIAN INFERENCE W, P309; Clyde M, 2000, J ROY STAT SOC B, V62, P681, DOI 10.1111/1467-9868.00257; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; DONOHO DL, 1995, J ROYAL STAT SOC B, V57, P1200; Draper N, 1981, APPL REGRESSION ANAL; Efroymson M. A., 1960, MATH METHODS DIGITAL, P191; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; Garthwaite PH, 1996, CHEMOMETR INTELL LAB, V35, P1, DOI 10.1016/S0169-7439(96)00035-4; George E. I., 2006, ENCY STAT SCI UPDATE, V3, P39; Gilmour SG, 1996, STATISTICIAN, V45, P49, DOI 10.2307/2348411; GONG G, 1986, J AM STAT ASSOC, V81, P108, DOI 10.2307/2287975; HAUGHTON DMA, 1988, ANN STAT, V16, P342, DOI 10.1214/aos/1176350709; HOCKING RR, 1976, BIOMETRICS, V32, P1, DOI 10.2307/2529336; Hudson DJ, 1964, STATISTICS; Hurvich CM, 1998, BIOMETRIKA, V85, P701, DOI 10.1093/biomet/85.3.701; JOHNSTONE IM, 1998, EMPIRICAL BAYES APPR; Miller A. J., 1990, SUBSET SELECTION REG; Montgomery D.C., 1992, INTRO LINEAR REGRESS; MORAN PAP, 1953, AUST J ZOOL, V1, P163, DOI 10.1071/ZO9530163; Myers R, 1992, CLASSICAL MODERN REG; NARULA SC, 1977, TECHNOMETRICS, V19, P185, DOI 10.2307/1268628; NECHVAL KN, 2008, P 7 ANN HAW INT C ST, P111; NECHVAL N, 2008, CYBERNETICS IN PRESS, V1; RAO CR, 1989, BIOMETRIKA, V76, P369, DOI 10.2307/2336671; Shao J, 1997, STAT SINICA, V7, P221; STONE M, 1979, J ROY STAT SOC B MET, V41, P276; THOMPSON ML, 1978, INT STAT REV, V46, P1, DOI 10.2307/1402505; Tibshirani R, 1999, J ROY STAT SOC B, V61, P529, DOI 10.1111/1467-9868.00191; Tong H., 1990, NONLINEAR TIME SERIE; WEI CZ, 1992, ANN STAT, V29, P1; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609; ZHANG P, 1993, ANN STAT, V21, P299, DOI 10.1214/aos/1176349027; ZHANG P, 1992, BIOMETRIKA, V79, P741, DOI 10.1093/biomet/79.4.741; Zheng XD, 1997, STAT SINICA, V7, P311	48	0	0	1	2	TRANSPORT & TELECOMMUNICATION INST	RIGA	LOMONOSOVA IELA 1, RIGA, LV-1019, LATVIA			978-9984-818-04-7				2008							24	32				9	Business; Computer Science, Information Systems; Information Science & Library Science; Transportation Science & Technology	Business & Economics; Computer Science; Information Science & Library Science; Transportation	BIE23	WOS:000258885800004		
J	Jin, R; Si, L; Chan, C				Jin, Rong; Si, Luo; Chan, Christina			A Bayesian framework for knowledge driven regression model in micro-array data analysis	INTERNATIONAL JOURNAL OF DATA MINING AND BIOINFORMATICS			English	Article						Bayesian analysis; knowledge driven data regression; data regression; graph Laplacian; gene expression analysis; data mining; bioinformatics		This paper addresses the sparse data problem in the linear regression model, namely the number of variables is significantly larger than the number of the data points for regression. We assume that in addition to the measured data points, the prior knowledge about the input variables may be provided in the form of pair wise similarity. We presented a full Bayesian framework to effectively exploit the similarity information of the input variables for linear regression. Empirical studies with gene expression data show that the regression errors can be reduced significantly by incorporating the similarity information derived from gene ontology.	[Jin, Rong] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Si, Luo] Purdue Univ, Dept Comp Sci, W Lafayette, IN USA; [Chan, Christina] Michigan State Univ, Dept Chem Engn & Mat Sci, E Lansing, MI 48824 USA	Jin, R (reprint author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	rongjin@cse.msu.edu; lsi@cs.purdue.edu; krischan@egr.msu.edu			NSF [IIS0610784]; NIH [R01 GM079688-01]; Michigan Universities Commercialisation Initiative (MUCI) Challenge Fund	This research was partially supported by NSF grant (IIS0610784), NIH grant (R01 GM079688-01) and Michigan Universities Commercialisation Initiative (MUCI) Challenge Fund. Any opinions, findings, conclusions, or recommendations expressed in this paper are the authors, and do not necessarily reflect those of the sponsors.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Bishop C. M., 1995, NEURAL NETWORKS PATT; BUTTCHER SL, 2005, P 13 TEXT RETR C GAI; Casella G., 2001, STAT INFERENCE; Chung F. R. K., 1997, SPECTRAL GRAPH THEOR; Common P., 1994, SIGNAL PROCESS, V36, P287; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Gelman A., 2004, BAYESIAN DATA ANAL; HERSH W, 2004, P 13 TEXT RETR C GAI; HERSH W, 2003, P 12 TEXT RETR C GAI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; HSKULDSSON A, 1988, J CHEMOMETR, V2, P211; HUANG J, 2005, P 13 TEXT RETR C GAI; Jensen LJ, 2003, BIOINFORMATICS, V19, P635, DOI 10.1093/bioinformatics/btg036; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Li Z, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-21; Lu XH, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-122; ROBERTSON SE, 1999, P 8 TEXT RETR C TREC; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SEKI K, 2005, APPL TEXT CATEGORIZA, P138; Shatkay H, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P317; Speer N, 2004, PROCEEDINGS OF THE 2004 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P252; Tanabe L, 1999, BIOTECHNIQUES, V27, P1210; Townsend RP, 2002, MOL SIE S T, V3, P1; Wiener E, 1995, P 4 ANN S DOC AN INF, P317	26	2	2	0	2	INDERSCIENCE ENTERPRISES LTD	GENEVA	WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND	1748-5673	1748-5681		INT J DATA MIN BIOIN	Int. J. Data Min. Bioinform.		2008	2	3					250	267		10.1504/IJDMB.2008.020525		18	Mathematical & Computational Biology	Mathematical & Computational Biology	370IA	WOS:000260754700004	19024497	
J	Hong, X; Mitchell, RJ; Chen, S; Harris, CJ; Li, K; Irwin, GW				Hong, X.; Mitchell, R. J.; Chen, S.; Harris, C. J.; Li, K.; Irwin, G. W.			Model selection approaches for non-linear system identification: a review	INTERNATIONAL JOURNAL OF SYSTEMS SCIENCE			English	Review						adaptive learning; cross validation; model selection; model generalisation; system identification; control engineering	ORTHOGONAL LEAST-SQUARES; SUPPORT VECTOR MACHINES; BASIS FUNCTION NETWORKS; OPTIMALITY EXPERIMENTAL-DESIGN; ARTIFICIAL NEURAL-NETWORK; ADAPTIVE-CONTROL; VARIABLE SELECTION; MUTUAL INFORMATION; SUBSPACE IDENTIFICATION; LEARNING ALGORITHMS	The identification of non-linear systems using only observed finite datasets has become a mature research area over the last two decades. A class of linear-in-the-parameter models with universal approximation capabilities have been intensively studied and widely used due to the availability of many linear-learning algorithms and their inherent convergence conditions. This article presents a systematic overview of basic research on model selection approaches for linear-in-the-parameter models. One of the fundamental problems in non-linear system identification is to find the minimal model with the best model generalisation performance from observational data only. The important concepts in achieving good model generalisation used in various non-linear system-identification algorithms are first reviewed, including Bayesian parameter regularisation and models selective criteria based on the cross validation and experimental design. A significant advance in machine learning has been the development of the support vector machine as a means for identifying kernel models based on the structural risk minimisation principle. The developments on the convex optimisation-based model construction algorithms including the support vector regression algorithms are outlined. Input selection algorithms and on-line system identification algorithms are also included in this review. Finally, some industrial applications of non-linear models are discussed.	[Hong, X.; Mitchell, R. J.] Univ Reading, Sch Syst Engn, Reading, Berks, England; [Chen, S.; Harris, C. J.] Univ Southampton, Sch Elect & Comp Sci, Southampton, Hants, England; [Li, K.; Irwin, G. W.] Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast, Antrim, North Ireland	Hong, X (reprint author), Univ Reading, Sch Syst Engn, Reading, Berks, England.	x.hong@reading.ac.uk	Irwin, George/D-1087-2009; Chen, Sheng/F-7835-2011				Adeney KM, 2000, NEURAL NETWORKS, V13, P787, DOI 10.1016/S0893-6080(00)00049-6; Aguirre LA, 2005, IEE P-CONTR THEOR AP, V152, P349, DOI 10.1049/ip-cta:20045152; Aguirre LA, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026701; Aguirre LA, 2000, IEEE T CIRCUITS-I, V47, P1081, DOI 10.1109/81.855463; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Altinkok N, 2006, J COMPOS MATER, V40, P779, DOI 10.1177/0021998305055547; Engel Y, 2004, IEEE T SIGNAL PROCES, V52, P2275, DOI 10.1109/TSP.2004.830985; Leung H, 2001, IEEE T NEURAL NETWOR, V12, P1163, DOI 10.1109/72.950144; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; NISHII R, 1984, ANN STAT, V12, P758, DOI 10.1214/aos/1176346522; Knight K, 2000, ANN STAT, V28, P1356; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Peng H, 2004, CONTROL ENG PRACT, V12, P191, DOI 10.1016/S0967-0661(03)00050-9; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Li K, 2006, AUTOMATICA, V42, P1189, DOI 10.1016/j.automatica.2006.03.004; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Vanderbei RJ, 1999, OPTIM METHOD SOFTW, V11-2, P451, DOI 10.1080/10556789908805759; Pelckmans K, 2005, NEUROCOMPUTING, V64, P137, DOI 10.1016/j.neucom.2004.11.029; Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500; CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472; SANNER RM, 1992, IEEE T NEURAL NETWOR, V3, P837, DOI 10.1109/72.165588; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI DOI 10.2307/1990404; Astrom K., 1989, ADAPTIVE CONTROL; ASTROM KJ, 1971, AUTOMATICA, V7, P123; Atkinson AC, 1992, OPTIMUM EXPT DESIGNS; Bai EW, 2004, AUTOMATICA, V40, P671, DOI 10.1016/j.automatica.2003.11.007; Bai EW, 1998, AUTOMATICA, V34, P333, DOI 10.1016/S0005-1098(97)00198-2; BARDFORD JR, 2005, BIOINFORMATICS, V21, P1487; BARRON AR, 1984, SELFORGANIZING METHO; BARTLETT PL, 2003, LECT NOTES U CALIFOR; Basso M, 2005, IEEE T CONTR SYST T, V13, P599, DOI 10.1109/TCST.2004.843129; Billings SA, 2005, INT J SYST SCI, V36, P137, DOI 10.1080/00207720512331338120; BILLINGS SA, 1989, MECH SYST SIGNAL PR, V3, P123, DOI 10.1016/0888-3270(89)90012-5; BILLINGS SA, 1987, INT J CONTROL, V46, P215, DOI 10.1080/00207178708933894; BOHLIN T, 1971, AUTOMATICA, V7, P199, DOI 10.1016/0005-1098(71)90063-X; Bohlin T., 2006, PRACTICAL GREY BOX P; Bossley K.M., 1997, THESIS U SOUTHAMPTON; Bowden GJ, 2005, J HYDROL, V301, P75, DOI 10.1016/j.jhydrol.2004.06.021; BOX GEP, 1976, TIME SERIES ANAL FOR; Broomhead D. S., 1988, Complex Systems, V2; Brown M., 1994, NEUROFUZZY ADAPTIVE; Brown M, 1997, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL SAS USERS GROUP INTERNATIONAL CONFERENCE, P13; Brown MD, 2002, T I MEAS CONTROL, V24, P215, DOI 10.1191/0142331202tm057oa; Burges C.J.C., 1996, P 13 INT C MACH LEAR, P71; Chambers J., 2001, RECURRENT NEURAL NET; CHEN HG, 1991, COMPUT IND ENG, V20, P77, DOI 10.1016/0360-8352(91)90042-5; Chen S, 2003, IEEE T AUTOMAT CONTR, V48, P1029, DOI 10.1109/TAC.2003.812790; Chen S, 1999, IEEE T NEURAL NETWOR, V10, P1239, DOI 10.1109/72.788663; CHEN S, 2007, 2007 INT JOINT C NEU; Chen S, 2003, IEE P-CONTR THEOR AP, V150, P139, DOI 10.1049/ip-cta:20030253; Chen S., 2002, P 6 INT C SIGN PROC, P1229; CHEN S, 2005, P 2005 INT C INT COM, P777; Chen S, 2004, IEEE T SYST MAN CY B, V34, P898, DOI 10.1109/TSMCB.2003.817107; Chen S, 2005, IEEE T CONTR SYST T, V13, P401, DOI 10.1109/TCST.2004.841652; Chiras N, 2001, IEEE T INSTRUM MEAS, V50, P893, DOI 10.1109/19.948295; Clarkson T., 1999, P ERUDIT WORKSH APPL; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; CONNALLY P, 2007, NEUROCOMPUT IN PRESS, DOI DOI 10.1016/J.NEUCOM.2007.06.005; CONNALLY P, 2005, P 16 IFAC WORLD C PR; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Daubechies I., 1992, 10 LECT WAVELETS; Debnath L., 1998, INTRO HILBERT SPACES; Downs T., 2001, J MACHINE LEARNING R, V2, P293; DREZET PML, 1998, P UKACC INT C CONTR, V1, P688; Dybowski R, 2001, CLIN APPL ARTIFICIAL; ESPINOZA M, 2005, P JOINT 44 IEEE C DE, P5716, DOI 10.1109/CDC.2005.1583074; Espinoza M, 2005, IEEE T AUTOMAT CONTR, V50, P1602, DOI 10.1109/TAC.2005.856656; Eykhoff P., 1974, SYSTEM IDENTIFICATIO; Fabri SG, 2001, FUNCTIONAL ADAPTIVE; Faller WE, 1996, PROG AEROSP SCI, V32, P433, DOI 10.1016/0376-0421(95)00011-9; FLOOD I, 1998, HDB INTELLIGENT CONT; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Gamero LG, 2001, EXP PHYSIOL, V86, P519, DOI 10.1113/eph8602172; Gao JB, 2001, NEURAL COMPUT, V13, P1975, DOI 10.1162/089976601750399263; Gao Y, 2003, IEEE T FUZZY SYST, V11, P462, DOI 10.1109/TFUZZ.2003.814833; Garson G. D., 1991, Social Science Computer Review, V9, DOI 10.1177/089443939100900304; Ge S.S., 2001, STABLE ADAPTIVE NEUR; Gevers M., 2005, EUROPEAN J CONTROL, V11, P1; GIROSI F, 1990, BIOL CYBERN, V63, P169, DOI 10.1007/BF00195855; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Glass JW, 1999, INT J CONTROL, V72, P289, DOI 10.1080/002071799221109; Goethals I, 2005, AUTOMATICA, V41, P1263, DOI 10.1016/j.automatica.2005.02.002; Goethals I, 2003, IEEE T AUTOMAT CONTR, V48, P1843, DOI [10.1109/TAC.2003.817940, 10.1109/TAC.203.817940]; Goodwin G. C., 1984, ADAPTIVE FILTERING P; Govindhasamy JJ, 2005, CONTROL ENG PRACT, V13, P1243, DOI [10.1016/j.conengprac.2004.11.006, 10.1016/j.congengprac.2004.11.006]; GRAY GJ, 1996, LATE BREAKING PAPERS, P32; GREBLICKI W, 1989, INT J SYST SCI, V20, P2355, DOI 10.1080/00207728908910318; Green P, 1994, NONPARAMETRIC REGRES; Harris CJ, 2002, ADAPTIVE MODELLING E; Harrison RF, 2005, ANN EMERG MED, V46, P431, DOI 10.1016/j.annemergmed.2004.09.012; Hastie T., 2002, ELEMENTS STAT LEARNI; Hastie TJ, 1996, GEN ADDITIVE MODELS; Hoegaerts L, 2005, NEUROCOMPUTING, V63, P293, DOI 10.1016/j.neucom.2004.04.013; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hong W., 2006, INT J MANAGEMENT, V23, P375; Hong X, 2003, INT J SYST SCI, V34, P733, DOI 10.1080/00207720310001640223; Hong X, 2005, IEEE T SYST MAN CY B, V35, P155, DOI 10.1109/TSMCB.2004.839910; Hong X., 2004, INT J HYBRID INTELL, V1, P90; Hong X, 2007, INT J SYST SCI, V38, P101, DOI 10.1080/00207720601051463; Hong X, 2001, IEE P-CONTR THEOR AP, V148, P530, DOI 10.1049/ip-cta:20010704; Hong X, 2001, IEEE T FUZZY SYST, V9, P88; Hong X, 2003, IEE P-CONTR THEOR AP, V150, P245, DOI 10.1049/ip-cta:20030311; Huang G B, 2004, P INT JOINT C NEUR N, V2, P985; Huang GB, 2004, IEEE T SYST MAN CY B, V34, P2284, DOI 10.1109/TSMCB.2004.834428; Huang SN, 2006, IEEE T NEURAL NETWOR, V17, P243, DOI 10.1109/TNN.2005.857948; Huber P. J., 1981, ROBUST STAT; IPLIKCI S, 2006, INT J ROBUST NONLIN, V16, P834; Irwin G.W., 1995, NEURAL NETWORK APPL; James W., 1961, P 4 BERK S MATH STAT, V1, P311; Juditsky A, 1995, AUTOMATICA, V31, P1725, DOI 10.1016/0005-1098(95)00119-1; Jurado F, 2005, FUEL CELLS, V5, P105, DOI 10.1002/fuce.200400056; Jurado F, 2005, ENERG CONVERS MANAGE, V46, P385, DOI 10.1016/j.enconman.2004.03.012; KADIRKAMANATHAN V, 1993, NEURAL COMPUT, V5, P954, DOI 10.1162/neco.1993.5.6.954; Kalkkuhl J, 1999, IEEE T NEURAL NETWOR, V10, P885, DOI 10.1109/72.774241; Kanevski M, 2004, ENVIRON MODELL SOFTW, V19, P845, DOI 10.1016/j.envsoft.2003.03.004; Karayiannis NB, 2006, IEEE T BIO-MED ENG, V53, P633, DOI 10.1109/TBME.2006.870249; KAVLI T, 1993, INT J CONTROL, V58, P947, DOI 10.1080/00207179308923037; Khan MS, 2006, J HYDROL ENG, V11, P199, DOI 10.1061/(ASCE)1084-0699(2006)11:3(199); KORENBERG MJ, 1988, ANN BIOMED ENG, V16, P123, DOI 10.1007/BF02367385; Lee KL, 2002, INT J SYST SCI, V33, P811, DOI 10.1080/0020772021000017317; LEONTARITIS IJ, 1985, INT J CONTROL, V41, P303, DOI 10.1080/0020718508961129; Leva A, 2002, SMART MATER STRUCT, V11, P79, DOI 10.1088/0964-1726/11/1/309; Lewis FL, 1998, INT J CONTROL, V70, P337, DOI 10.1080/002071798222262; Li K, 2005, IEEE T AUTOMAT CONTR, V50, P1211, DOI 10.1109/TAC.2005.852557; Li K, 2004, CONTROL ENG PRACT, V12, P707, DOI 10.1016/S0967-0661(03)00171-0; Li K, 2006, INT J PATTERN RECOGN, V20, P143, DOI 10.1142/S0218001406004570; LI K, 2005, P 16 IFAC WORLD C PR; Lin BS, 2007, IEEE T NEURAL NETWOR, V18, P823, DOI 10.1109/TNN.2007.891185; Liu G.P., 2001, NONLINEAR IDENTIFICA; Liu GPP, 1999, IEEE T SYST MAN CY C, V29, P34, DOI 10.1109/5326.740668; Ljung L., 1987, SYSTEM IDENTIFICATIO; LJUNG L, 2005, IEEE T AUTOMAT CONTR, V50, P1477; LJUNG L, 1983, THEORY PRACTICE RECE; LORITO F, 1999, CONTROL ENG PRACT, V6, P1331; Luh GC, 2004, P I MECH ENG I-J SYS, V218, P353, DOI 10.1243/0959651041568524; LUO W, 1996, IEEE INT C SYST MAN, V1, P107; MA Q, 2000, ACM SIGKDD INT C KNO, P305; Mackay D., 1991, THESIS CALTECH US; MACKAY DJC, 1997, LECT NOTES NIPS 1997; Mao KZ, 2000, INT J CONTROL, V73, P132, DOI 10.1080/002071700219830; Mao KZ, 1999, INT J SYST SCI, V30, P455, DOI 10.1080/002077299292209; Mao KZ, 1999, MECH SYST SIGNAL PR, V13, P351, DOI 10.1006/mssp.1998.0180; Markovsky I, 2005, AUTOMATICA, V41, P755, DOI 10.1016/j.automatica.2004.10.007; Marose R. A., 1990, AI Expert, V5; MARQUARD.DW, 1970, TECHNOMETRICS, V12, P591, DOI 10.2307/1267205; MCGINNITY S, 1996, INT J SYST SCI, V28, P643; Miller A. J., 1990, SUBSET SELECTION REG; Minoux M., 1986, MATH PROGRAMMING THE; Mitra S, 2006, IEEE T SYST MAN CY C, V36, P616, DOI 10.1109/TSMCC.2006.879384; Moody J., 1994, STAT NEURAL NETWORKS; Murray-Smith R, 1994, THESIS U STRATHCLYDE; Murray-Smith R., 1997, MULTIPLE MODEL APPRO; Myers R. H., 1995, RESPONSE SURFACE MET; Neal R. M., 1996, BAYESIAN LEARNING NE; Nunnari G, 2004, ENVIRON MODELL SOFTW, V19, P887, DOI 10.1016/j.envsoft.2003.10.003; Orr M.J.L., 1995, NEURAL COMPUT, V7, P954; PARK DC, 1991, IEEE T NEURAL NETWOR, V2, P334, DOI 10.1109/72.97910; Parlitz U, 2004, CHAOS, V14, P420, DOI 10.1063/1.1737818; Peng JX, 2006, IEEE T NEURAL NETWOR, V17, P1439, DOI 10.1109/TNN.2006.880860; Platt J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.213; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; PLUTOWSKI M, 1993, IEEE T NEURAL NETWOR, V4, P305, DOI 10.1109/72.207618; POWELL MJD, 1985, ALGORITHMS APPROXIMA, P143; Priestley M., 1981, SPECTRAL ANAL TIME S; Raghavan H, 2005, J PROCESS CONTR, V15, P451, DOI 10.1016/j.jprocont.2004.06.011; Rao GP, 2006, IEE P-CONTR THEOR AP, V153, P185, DOI [10.1049/ip-cta:20045250, 10.1049/ic-cta:20045250]; Ribeiro B, 2005, IEEE T SYST MAN CY C, V35, P401, DOI 10.1109/TSMCC.2004.843228; Rojas CR, 2007, AUTOMATICA, V43, P993, DOI 10.1016/j.automatica.2006.12.013; Ruano A., 2005, INTELLIGENT CONTROL; SARGANTANIS IG, 2004, AICHE J, V45, P2034; Sindelar R, 2004, IEEE T FUZZY SYST, V12, P688, DOI 10.1109/TFUZZ.2004.834810; Sjoberg J, 1995, AUTOMATICA, V31, P1691, DOI 10.1016/0005-1098(95)00120-8; Smola A. J., 1998, NCTR98030 ROYAL HOLL; SMOLA AJ, 1998, THESIS INFORM TU BER; Soderstrom T, 2005, AUTOMATICA, V41, P357, DOI 10.1016/j.automatica.2004.11.004; Soderstrom T., 1989, SYSTEM IDENTIFICATIO; SODERSTROM T, 1990, AUTOMATICA, V26, P125, DOI 10.1016/0005-1098(90)90164-D; Soderstrom T., 2006, P 14 IFAC S SYST ID; Soumelidis MI, 2006, P I MECH ENG I-J SYS, V220, P595, DOI 10.1243/09596518JSCE185; Stewart P, 2003, INT J SYST SCI, V34, P837, DOI 10.1080/00207720310001640287; Stone M., 1974, J R STAT SOC B, V36, P117; Sugiyama M, 2001, NEURAL NETWORKS, V14, P67, DOI 10.1016/S0893-6080(00)00079-4; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Tothill RW, 2005, CANCER RES, V65, P4031, DOI 10.1158/0008-5472.CAN-04-3617; TOWNSEND S, 2001, BOOK SERIES IEE, V61; Tsang KM, 2005, IEE P-ELECT POW APPL, V152, P627, DOI 10.1049/ip-epa:20045058; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Vemuri AT, 1998, IEEE T ROBOTIC AUTOM, V14, P342, DOI 10.1109/70.681254; Wahba G., 1990, SPLINE MODELS OBSERV; Wang L., 1992, IEEE T NEURAL NETWOR, V43, P807; Wilson DJH, 1999, IEEE T NEURAL NETWOR, V10, P1424, DOI 10.1109/72.809087; XIA X, 2007, 2007 INT JOINT C NEU; Xie N, 2005, IEEE T NEURAL NETWOR, V16, P709, DOI 10.1109/TNN.2005.845145; Yingwei L., 1998, IEEE T NEURAL NETWOR, V9, P308; Young P. C., 1984, RECURSIVE ESTIMATION; Zhang LF, 2007, INT J SYST SCI, V38, P47, DOI 10.1080/00207720601014552; Zhang Q., 1993, IEEE T NEURAL NETWOR, V8, P1997; Zheng GL, 1999, INT J CONTROL, V72, P1592, DOI 10.1080/002071799220065; Zheng GL, 1996, NEURAL NETWORKS, V9, P1619, DOI 10.1016/0893-6080(95)00139-5; Zheng GL, 2002, INT J SYST SCI, V33, P331, DOI 10.1080/00207720110121105; Zhong ZD, 2006, J POWER SOURCES, V160, P293, DOI 10.1016/j.jpowsour.2006.01.040	213	61	63	8	48	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0020-7721	1464-5319		INT J SYST SCI	Int. J. Syst. Sci.		2008	39	10					925	946		10.1080/00207720802083018		22	Automation & Control Systems; Computer Science, Theory & Methods; Operations Research & Management Science	Automation & Control Systems; Computer Science; Operations Research & Management Science	339QG	WOS:000258591500001		
J	Martinez-Montes, E; Vega-Hernandez, M; Sanchez-Bornot, JM; Valdes-Sosa, PA				Martinez-Montes, Eduardo; Vega-Hernandez, Mayrim; Sanchez-Bornot, Jose M.; Valdes-Sosa, Pedro A.			Identifying Complex Brain Networks Using Penalized Regression Methods	JOURNAL OF BIOLOGICAL PHYSICS			English	Article						Information Entropy; PARAFAC; EEG inverse problem; Multiple penalized least squares model; Complex brain networks	VARIABLE SELECTION; CORTEX	The recorded electrical activity of complex brain networks through the EEG reflects their intrinsic spatial, temporal and spectral properties. In this work we study the application of new penalized regression methods to i) the spatial characterization of the brain networks associated with the identification of faces and ii) the PARAFAC analysis of resting-state EEG. The use of appropriate constraints through non-convex penalties allowed three types of inverse solutions (Loreta, Lasso Fusion and ENet L) to spatially localize networks in agreement with previous studies with PORI. Furthermore, we propose a new penalty based in the Information Entropy for the constrained PARAFAC analysis of resting EEG that allowed the identification in time, frequency and space of those brain networks with minimum spectral entropy. This study is an initial attempt to explicitly include complexity descriptors as a constraint in multilinear EEG analysis.	[Martinez-Montes, Eduardo; Vega-Hernandez, Mayrim; Sanchez-Bornot, Jose M.; Valdes-Sosa, Pedro A.] Cuban Neurosci Ctr, Neurostat Dept, Havana, Cuba	Martinez-Montes, E (reprint author), Cuban Neurosci Ctr, Neurostat Dept, Ave 25,Esq 158,15202 Cubanacan,POB 6414, Havana, Cuba.	eduardo@cneuro.edu.cu					Miwakeichi F, 2004, NEUROIMAGE, V22, P1035, DOI 10.1016/j.neuroimage.2004.03.039; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Kanwisher N, 1997, J NEUROSCI, V17, P4302; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Bro R., 1998, THESIS U AMSTERDAM D; Durka PJ, 2001, IEEE ENG MED BIOL, V20, P47, DOI 10.1109/51.956819; Freiwald WA, 1999, J NEUROSCI METH, V94, P105, DOI 10.1016/S0165-0270(99)00129-6; Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Harrison L, 2003, NEUROIMAGE, V19, P1477, DOI 10.1016/S1053-8119(03)00160-5; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Kiebel SJ, 2005, HUM BRAIN MAPP, V26, P170, DOI 10.1002/hbm.20153; Land S. R., 1996, VARIABLE FUSION NEW; Mardia KV, 1979, MULTIVARIATE ANAL; Martinez-Montes E, 2004, NEUROIMAGE, V22, P1023, DOI 10.1016/j.neuroimage.2004.03.038; MARTINEZMONTES E, 2007, NEUROIMAGE, V36; Pascual-Marqui R. D., 1999, INT J BIOELECTROMAGN, V1, P75, DOI DOI 10.1186/1743-0003-5-25; Makeig S, 2002, SCIENCE, V295, P690, DOI 10.1126/science.1066168; Shannon E. C., 1948, BELL SYST TECH J, V27, P623; Valdes-Sosa PA, 2006, HDB TIME SERIES ANAL, P461, DOI 10.1002/9783527609970.ch18; VEGAHERNANDEZ M, 2006, NEUROIMAGE, V27	22	4	4	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0092-0606			J BIOL PHYS	J. Biol. Phys.		2008	34	3-4					315	323		10.1007/s10867-008-9077-0		9	Biophysics	Biophysics	399UI	WOS:000262824400006	19669480	
J	Lee, YJ; Chang, CC; Chao, CH				Lee, Yuh-Jye; Chang, Chien-Chung; Chao, Chia-Huang			Incremental forward feature selection with application to microarray gene expression data	JOURNAL OF BIOPHARMACEUTICAL STATISTICS			English	Article						1-norm support vector machine; filter model; incremental forward feature selection; weight score; wrapper model	SUPPORT VECTOR MACHINE; CLASSIFICATION; CANCER; LASSO	In this study, the authors propose a new feature selection scheme, the incremental forward feature selection, which is inspired by incremental reduced support vector machines. In their method, a new feature is added into the current selected feature subset if it will bring in the most extra information. This information is measured by using the distance between the new feature vector and the column space spanned by current feature subset. The incremental forward feature selection scheme can exclude highly linear correlated features that provide redundant information and might degrade the efficiency of learning algorithms. The method is compared with the weight score approach and the 1-norm support vector machine on two well-known microarray gene expression data sets, the acute leukemia and colon cancer data sets. These two data sets have a very few observations but huge number of genes. The linear smooth support vector machine was applied to the feature subsets selected by these three schemes respectively and obtained a slightly better classification results in the 1-norm support vector machine and incremental forward feature selection. Finally, the authors claim that the rest of genes still contain some useful information. The previous selected features are iteratively removed from the data sets and the feature selection and classification steps are repeated for four rounds. The results show that there are many distinct feature subsets that can provide enough information for classification tasks in these two microarray gene expression data sets.	[Lee, Yuh-Jye; Chang, Chien-Chung; Chao, Chia-Huang] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Lee, YJ (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.	yuh-jye@mail.ntust.edu.tw					ALON U, 1999, CELL BIOL, V96, P6745; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lee YJ, 2001, COMPUT OPTIM APPL, V20, P5, DOI 10.1023/A:1011215321374; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Bishop C. M., 1995, NEURAL NETWORKS PATT; Cristianini N., 2000, INTRO SUPPORT VECTOR; Duda R. O., 1973, PATTERN CLASSIFICATI; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; GUYON I, 2002, MACHINE LEARN, V46, P191; Joachims T., 2002, LEARNING CLASSIFY TE; John G., 1998, FEATURE SELECTION KN, P33; Langley P., 1994, P 10 C UNC ART INT, P399; Lee YJ, 2003, COMPUT OPTIM APPL, V25, P151, DOI 10.1023/A:1022953004360; MUKHERJEE S, 1998, 1677182 CBCL MIT AI; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Slonim D.K., 2000, P 4 ANN INT C COMP M, P263, DOI 10.1145/332306.332564; Vapnik V.N., 1995, NATURE STAT LEARNING; Weston J, 2001, ADV NEUR IN, V13, P668; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; Yu Lei, 2003, P 20 INT C MACH LEAR, P856; Zhu J., 2004, ADV NEURAL INFORM PR, V16	25	5	5	0	1	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	1054-3406			J BIOPHARM STAT	J. Biopharm. Stat.		2008	18	5					827	840		10.1080/10543400802277868		14	Pharmacology & Pharmacy; Statistics & Probability	Pharmacology & Pharmacy; Mathematics	346UC	WOS:000259093800003	18781519	
J	Leeb, H; Potscher, BM				Leeb, Hannes; Poetscher, Benedikt M.			Sparse estimators and the oracle property, or the return of Hodges' estimator	JOURNAL OF ECONOMETRICS			English	Article						oracle property; sparsity; penalized maximum likelihood; penalized least squares; Hodges' estimator; SCAD; lasso; bridge estimator; hard-thresholding; maximal risk; maximal absolute bias; nonuniform limits	NONCONCAVE PENALIZED LIKELIHOOD; MODEL SELECTION; VARIABLE SELECTION; COVARIATE SELECTION; REGRESSION; INFERENCE; LASSO; SHRINKAGE; NUMBER; RISK	We point out some pitfalls related to the concept of an oracle property as used in Fan and Li [2001. Variable selection via nonconcave penalized likelihood and its oracle properties. Journal of the American Statistical Association 96, 1348-1360; 2002. Variable selection for Cox's proportional hazards model and frailty model. Annals of Statistics 30, 74-99; 2004. New estimation and model selection procedures for semiparametric modeling in longitudinal data analysis. Journal of the American Statistical Association 99, 710-723] which are reminiscent of the well-known pitfalls related to Hodges' estimator. The oracle property is often a consequence of sparsity of an estimator. We show that any estimator satisfying a sparsity property has maximal risk that converges to the supremum of the loss function; in particular, the maximal risk diverges to infinity whenever the loss function is unbounded. For ease of presentation the result is set in the framework of a linear regression model, but generalizes far beyond that setting. In a Monte Carlo study we also assess the extent of the problem in finite samples for the smoothly clipped absolute deviation (SCAD) estimator introduced in Fan and Li [2001. Variable selection via nonconcave penalized likelihood and its oracle properties. Journal of the American Statistical Association 96, 1348-1360]. We find that this estimator can perform rather poorly in finite samples and that its worst-case performance relative to maximum likelihood deteriorates with increasing sample size when the estimator is tuned to sparsity. (C) 2007 Elsevier B.V. All rights reserved.	[Poetscher, Benedikt M.] Univ Vienna, Dept Stat, A-1010 Vienna, Austria; [Leeb, Hannes] Yale Univ, Dept Stat, New Haven, CT 06520 USA	Potscher, BM (reprint author), Univ Vienna, Dept Stat, A-1010 Vienna, Austria.	benedikt.poetscher@univie.ac.at	Leeb, Hannes/C-9026-2014	Leeb, Hannes/0000-0002-5770-5955			Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Bunea F, 2004, ANN STAT, V32, P898, DOI 10.1214/009053604000000247; Bunea F, 2005, J MULTIVARIATE ANAL, V92, P186, DOI 10.1016/j.jmva.2003.09.006; Cai JW, 2005, BIOMETRIKA, V92, P303, DOI 10.1093/biomet/92.2.303; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2002, ANN STAT, V30, P74; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; HAJEK J, 1971, FDN STAT INFERENCE, P142; Hajek J, 1967, THEORY RANK TESTS; Hosoya Y., 1984, TIME SERIES ANAL THE, V5, P39; Judge G., 1978, STAT IMPLICATIONS PR; KABAILA P, 1995, ECONOMET THEOR, V11, P537; Kabaila P, 2002, ECONOMET THEOR, V18, P913, DOI 10.1017/S0266466602184052; KOUL HL, 1984, STAT DECISIONS S, V1, P17; Leeb H, 2006, ECONOMET THEOR, V22, P69, DOI 10.1017/S0266466606060038; Leeb H, 2005, ECONOMET THEOR, V21, P21, DOI 10.1017/S0266466605050036; Lehmann E. L., 1998, THEORY POINT ESTIMAT; POTSCHER BM, 1991, ECONOMET THEOR, V7, P163; SHIBATA R, 1986, ANN I STAT MATH, V38, P459, DOI 10.1007/BF02482533; Shibata R, 1986, J APPL PROBAB A, V23, P127, DOI DOI 10.2307/3214348; VONROSEN D, 1988, SCAND J STAT, V15, P97; Yang YH, 2005, BIOMETRIKA, V92, P937, DOI 10.1093/biomet/92.4.937	27	42	43	1	8	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0304-4076			J ECONOMETRICS	J. Econom.	JAN	2008	142	1					201	211		10.1016/j.jeconom.2007.05.017		11	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	245BX	WOS:000251910600008		
J	Johnson, BA; Peng, L				Johnson, Brent A.; Peng, Limin			Rank-based variable selection	JOURNAL OF NONPARAMETRIC STATISTICS			English	Article						lasso; oracle property; penalised least-squares; robust linear model	CENSORED-DATA; ORACLE PROPERTIES; LINEAR-MODELS; REGRESSION; PARAMETER; SHRINKAGE; LASSO; TESTS	This note considers variable selection in the robust linear model via R-estimates. The proposed rank-based approach is a generalisation of the penalised least-squares estimators where we replace the least-squares loss function with Jaeckel's (1972) dispersion function. Our rank-based method is robust to outliers in the errors and has roots in traditional non-parametric statistics for simple location-shift problems. We establish the theoretical properties of our estimators which ensure desirable asymptotic behaviour of setting coefficient estimates to zero for unimportant variables and consistently estimating coefficients for important variables. Numerical studies indicate that the rank-based methods perform well for both light- and heavy-tailed error distributions.	[Johnson, Brent A.; Peng, Limin] Emory Univ, Dept Biostat, Atlanta, GA 30322 USA	Johnson, BA (reprint author), Emory Univ, Dept Biostat, Atlanta, GA 30322 USA.	bajohn3@emory.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; JAECKEL LA, 1972, ANN MATH STAT, V43, P1449, DOI 10.1214/aoms/1177692377; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Chang WH, 1999, J AM STAT ASSOC, V94, P205, DOI 10.2307/2669695; Hajek J., 1999, THEORY RANK TESTS; Heiler S., 1988, STATISTICS, V19, P173, DOI 10.1080/02331888808802084; HETTMANSPERGER TP, 1977, TECHNOMETRICS, V19, P275, DOI 10.2307/1267697; Huber P. J., 1981, ROBUST STAT; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Johnson BA, 2008, J ROY STAT SOC B, V70, P351, DOI 10.1111/j.1467-9868.2008.00639.x; JURECKOV.J, 1969, ANN MATH STAT, V40, P1889, DOI 10.1214/aoms/1177697273; JURECKOVA J, 1971, ANN MATH STAT, V42, P109; KOUL HL, 1987, SCAND J STAT, V14, P131; MCKEAN JW, 1978, BIOMETRIKA, V65, P571; PRENTICE RL, 1978, BIOMETRIKA, V65, P167, DOI 10.1093/biomet/65.1.167; TSIATIS AA, 1990, ANN STAT, V18, P354, DOI 10.1214/aos/1176347504	21	9	9	0	3	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1048-5252			J NONPARAMETR STAT	J. Nonparametr. Stat.		2008	20	3					241	252		10.1080/10485250801998950		12	Statistics & Probability	Mathematics	317YX	WOS:000257057500004		
J	Curtice, J; Firth, D				Curtice, John; Firth, David			Exit polling in a cold climate: the BBC-ITV experience in Britain in 2005	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES A-STATISTICS IN SOCIETY			English	Article						exit poll; forecasting; general election; postal voting; probability calibration; steed swing; swingometer; ternary diagram	ELECTORAL SYSTEM; REGRESSION; SHRINKAGE; ELECTION	Conducting an exit poll to forecast the outcome of a national election in terms of both votes and seats is particularly difficult in Britain. No official information is available on how individual polling stations voted in the past, use of single-member plurality means that there is no consistent relationship between votes and seats, electors can choose to vote by post and most of those who vote in person do so late in the day. In addition, around one in every six intended exit poll respondents refuses to participate. Methods that were developed to overcome these problems, and their use in the successful 2005 British Broadcasting Corporation-Independent Television exit poll, are described and evaluated. The methodology included a panel design to allow the estimation of electoral change at local level, coherent multiple-regression modelling of multiparty electoral change to capture systematic patterns of variation, probabilistic prediction of constituency winners to account for uncertainty in projected constituency level shares, collection of information about the voting intentions of postal voters before polling day and access to interviewer guesses on the voting behaviour of refusals. The coverage and accuracy of the exit poll data are critically examined, the effect of key aspects of the statistical modelling of the data is assessed and some general lessons are drawn for the design and analysis of electoral exit polls.	[Firth, David] Univ Warwick, Dept Stat, Coventry CV4 7AL, W Midlands, England; [Curtice, John] Univ Strathclyde, Glasgow, Lanark, Scotland	Firth, D (reprint author), Univ Warwick, Dept Stat, Coventry CV4 7AL, W Midlands, England.	d.firth@warwick.ac.uk	Firth, David/A-8207-2011				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; COPAS JB, 1983, J R STAT SOC B, V45, P311; Blau A, 2004, ELECT STUD, V23, P431, DOI 10.1016/s0261-3794(03)00030-1; BROWN P, 1975, J ROY STAT SOC A STA, V138, P463, DOI 10.2307/2345211; BROWN P, 1984, STATISTICIAN, V33, P217, DOI 10.2307/2987852; Butler D. E., 1951, BRIT GEN ELECTION 19; CURTICE J, 1986, ELECT STUD, V5, P209, DOI 10.1016/0261-3794(86)90012-0; Curtice J, 2005, PARLIAMENT AFF, V58, P776, DOI 10.1093/pai/gsi066; CURTICE J, 1997, BRIT GEN ELECTION 19; CURTICE J, 2005, BRIT GEN ELECTION 20; CURTICE J, 2006, C PLUR MULT ROUND EL; CURTICE J, 1982, BRIT J POLIT SCI, V12, P249; CURTICE J, 2005, TRANSLATING POLL RES; Dawid A. P., 1986, ENCY STATISTICAL SCI, V7, P210; *EL COMM, 2002, POST VOT PROX VOT SP; *EL COMM, 2005, EL 2005 TURN HOW MAN; Gudgin G., 1979, SEATS VOTES SPATIAL; Kendall MG, 1950, BRIT J SOCIOL, V1, P183, DOI 10.2307/588113; MILLER W. L., 1977, ELECTORAL DYNAMICS B; PAYNE CD, 2003, EURAMERICA, V33, P193; R Development Core Team, 2007, R LANG ENV STAT COMP; Rossiter D. J., 2001, VOTES SEATS OPERATIO; Steed M., 2001, BRIT GEN ELECTION 20; STEED M, 1965, BRIT GEN ELECTION 19; Taagepera R., 1989, SEATS VOTES EFFECTS; Tarr GA, 2005, 2004 EUR PARL EL UK; Thrasher M., 2004, MEDIA GUIDE NEW SCOT; TUFTE ER, 1973, AM POLIT SCI REV, V67, P540, DOI 10.2307/1958782; Tukey J. W., 1977, DATA ANAL REGRESSION; UPTON GJG, 1994, J ROY STAT SOC A STA, V157, P231, DOI 10.2307/2983360	30	7	7	2	2	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0964-1998			J R STAT SOC A STAT	J. R. Stat. Soc. Ser. A-Stat. Soc.		2008	171		3				509	533		10.1111/j.1467-985X.2007.00536.x		25	Social Sciences, Mathematical Methods; Statistics & Probability	Mathematical Methods In Social Sciences; Mathematics	300OY	WOS:000255836300001		
J	Meier, L; van de Geer, SA; Buhlmann, P				Meier, Lukas; van de Geer, Sara A.; Buhlmann, Peter			The group lasso for logistic regression	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						categorical data; co-ordinate descent algorithm; DNA splice site; group variable selection; high dimensional generalized linear model; penalized likelihood	VARIABLE SELECTION; REGULARIZATION; ALGORITHM; MODEL	The group lasso is an extension of the lasso to do variable selection on (predefined) groups of variables in linear regression models. The estimates have the attractive property of being invariant under groupwise orthogonal reparameterizations. We extend the group lasso to logistic regression models and present an efficient algorithm, that is especially suitable for high dimensional problems, which can also be applied to generalized linear models to solve the corresponding convex optimization problem. The group lasso estimator for logistic regression is shown to be statistically consistent even if the number of predictors is much larger than sample size but with sparse true underlying structure. We further use a two-stage procedure which aims for sparser models than the group lasso, leading to improved prediction performance for some cases. Moreover, owing to the two-stage nature, the estimates can be constructed to be hierarchical. The methods are used on simulated and real data sets about splice site detection in DNA sequences.	[Meier, Lukas; van de Geer, Sara A.; Buhlmann, Peter] ETH, CH-8092 Zurich, Switzerland	Meier, L (reprint author), ETH, Leonhardstr 27, CH-8092 Zurich, Switzerland.	meier@stat.math.ethz.ch	Buhlmann, Peter/A-2107-2013				Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Burge C, 1997, J MOL BIOL, V268, P78, DOI 10.1006/jmbi.1997.0951; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Efron B, 2004, ANN STAT, V32, P407; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Bakin S, 1999, THESIS AUSTR NATL U; BALAKRISHNAN S, 2006, ALGORITHMS SPARSE LI; Bertsekas D. P., 2003, NONLINEAR PROGRAMMIN; Burge C., 1998, COMPUTATIONAL METHOD, P129; Cai TT, 2001, J AM STAT ASSOC, V96, P960; Kim Y, 2006, STAT SINICA, V16, P375; KING G, 2001, POLITICAL ANAL, V0009; LOKHORST J, 1999, HONORS PROJECT; PARK MY, 2006, REGULARIZATION ALGOR; Rosset S, 2005, ADV NEURAL INFORM PR, V1153, P1153; Roth V, 2004, IEEE T NEURAL NETWOR, V15, P16, DOI 10.1109/TNN.2003.809398; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Tarigan B, 2006, BERNOULLI, V12, P1045, DOI 10.3150/bj/1165269150; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; TSENG P, 2007, IN PRESS MATH PROGRA; van de Geer SA, 2003, RECENT ADVANCES AND TRENDS IN NONPARAMETRIC STATISTICS, P235, DOI 10.1016/B978-044451378-6/50016-8; VANDEGEER S, 2007, IN PRESS ANN STAT; Yeo G.W., 2004, J COMPUTNL BIOL, V11, P475; ZHAO P, 2007, IN PRESS J MATH LEAR	30	266	272	6	48	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1369-7412			J R STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2008	70		1				53	71				19	Statistics & Probability	Mathematics	248AA	WOS:000252122500004		
J	Johnson, BA				Johnson, Brent A.			Variable selection in semiparametric linear regression with censored data	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						false selection rate; hard thresholding; non-smooth estimating function; rank regression; soft thresholding; survival analysis	PREDICTION ERROR PROPERTY; RANK-TESTS; LASSO ESTIMATOR; LARGE-SAMPLE; MODEL; PARAMETERS	We describe two procedures for selecting variables in the semiparametric linear regression model for censored data. One procedure penalizes a vector of estimating equations and simultaneously estimates regression coefficients and selects submodels. A second procedure controls systematically the proportion of unimportant variables through forward selection and the addition of pseudorandom variables. We explore both rank-based statistics and Buckley-James statistics in the setting proposed and evaluate the performance of all methods through extensive simulation studies and one real data set.	Emory Univ, Rollins Sch Publ Hlth, Dept Biostat, Atlanta, GA 30322 USA	Johnson, BA (reprint author), Emory Univ, Rollins Sch Publ Hlth, Dept Biostat, 1518 Clifton Rd, Atlanta, GA 30322 USA.	bajohn3@emory.edu					Akaike H., 1973, P 2 INT S INF THEOR, P267; McKean JW, 2004, STAT SCI, V19, P562, DOI 10.1214/088342304000000549; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; LAI TL, 1991, ANN STAT, V19, P531, DOI 10.1214/aos/1176348110; Strawderman RL, 2005, BIOMETRIKA, V92, P647, DOI 10.1093/biomet/92.3.647; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Efron B, 2004, ANN STAT, V32, P407; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; BUCKLEY J, 1979, BIOMETRIKA, V66, P429; BOOS DD, 1992, AM STAT, V46, P327, DOI 10.2307/2685328; DICKSON ER, 1989, HEPATOLOGY, V10, P1, DOI 10.1002/hep.1840100102; Fan JQ, 2002, ANN STAT, V30, P74; FYGENSON M, 1994, ANN STAT, V22, P732, DOI 10.1214/aos/1176325493; Huang FC, 2003, AUST NZ J STAT, V45, P217, DOI 10.1111/1467-842X.00277; Huang YJ, 2002, J AM STAT ASSOC, V97, P318, DOI 10.1198/016214502753479446; LAI TL, 1991, ANN STAT, V19, P1370, DOI 10.1214/aos/1176348253; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; PRENTICE RL, 1978, BIOMETRIKA, V65, P167, DOI 10.1093/biomet/65.1.167; RITOV Y, 1990, ANN STAT, V18, P303, DOI 10.1214/aos/1176347502; Rosset S, 2004, AUST NZ J STAT, V46, P505, DOI 10.1111/j.1467-842X.2004.00347.x; ROTNITZKY A, 1990, BIOMETRIKA, V77, P485, DOI 10.1093/biomet/77.3.485; STUTE W, 1993, J MULTIVARIATE ANAL, V45, P89, DOI 10.1006/jmva.1993.1028; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Tibshirani R, 1999, J ROY STAT SOC B, V61, P529, DOI 10.1111/1467-9868.00191; TSIATIS AA, 1990, ANN STAT, V18, P354, DOI 10.1214/aos/1176347504; WEI LJ, 1990, BIOMETRIKA, V77, P845, DOI 10.1093/biomet/77.4.845; Wu YJ, 2007, J AM STAT ASSOC, V102, P235, DOI 10.1198/016214506000000843; YING ZL, 1993, ANN STAT, V21, P76, DOI 10.1214/aos/1176349016	31	24	26	1	3	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2008	70		2				351	370		10.1111/j.1467-9868.2008.00639.x		20	Statistics & Probability	Mathematics	259TP	WOS:000252964100004		
J	Jin, JS				Jin, Jiashun			Proportion of non-zero normal means: universal oracle equivalences and uniformly consistent estimators	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Fourier transform; oracle; phase function; uniform consistency	FALSE DISCOVERY RATE; NULL HYPOTHESES; SHRINKAGE; NUMBER; RATES	Since James and Stein's seminal work, the problem of estimating n normal means has received plenty of enthusiasm in the statistics community. Recently, driven by the fast expansion of the field of large-scale multiple testing, there has been a resurgence of research interest in the n normal means problem. The new interest, however, is more or less concentrated on testing n normal means: to determine simultaneously which means are 0 and which are not. In this setting, the proportion of the non-zero means plays a key role. Motivated by examples in genomics and astronomy, we are particularly interested in estimating the proportion of non-zero means, i.e. given n independent normal random variables with individual means X-j similar to N(mu(j),1), j=1,...,n, to estimate the proportion epsilon(n)=(1/n) #{j:mu(j) /= 0}. We propose a general approach to construct the universal oracle equivalence of the proportion. The construction is based on the underlying characteristic function. The oracle equivalence reduces the problem of estimating the proportion to the problem of estimating the oracle, which is relatively easier to handle. In fact, the oracle equivalence naturally yields a family of estimators for the proportion, which are consistent under mild conditions, uniformly across a wide class of parameters. The approach compares favourably with recent works by Meinshausen and Rice, and Genovese and Wasserman. In particular, the consistency is proved for an unprecedentedly broad class of situations; the class is almost the largest that can be hoped for without further constraints on the model. We also discuss various extensions of the approach, report results on simulation experiments and make connections between the approach and several recent procedures in large-scale multiple testing, including the false discovery rate approach and the local false discovery rate approach.	[Jin, Jiashun] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA; [Jin, Jiashun] Purdue Univ, W Lafayette, IN 47907 USA	Jin, JS (reprint author), Carnegie Mellon Univ, Dept Stat, Baker Hall, Pittsburgh, PA 15213 USA.	jiashun@stat.cmu.edu					Storey JD, 2007, J ROY STAT SOC B, V69, P347, DOI 10.1111/j.1467-9868.2007.005592.x; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lonnstedt I, 2002, STAT SINICA, V12, P31; Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; Benjamini Y, 2001, ANN STAT, V29, P1165; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Efron B, 2001, J AM STAT ASSOC, V96, P1151, DOI 10.1198/016214501753382129; SCHWEDER T, 1982, BIOMETRIKA, V69, P493; Benjamin Y., 2005, BIOMETRIKA, V93, P491; CAI T, 2007, IN PRESS ANN STAT; Donoho D, 2006, ANN STAT, V34, P2980, DOI 10.1214/009053606000000920; Donoho D, 2004, ANN STAT, V32, P962, DOI 10.1214/009053604000000265; Efron B, 2004, J AM STAT ASSOC, V99, P96, DOI 10.1198/016214504000000089; FAN JQ, 1991, ANN STAT, V19, P1257, DOI 10.1214/aos/1176348248; Ferreira JA, 2006, ANN STAT, V34, P1827, DOI 10.1214/009053606000000425; Genovese C, 2004, ANN STAT, V32, P1035, DOI 10.1214/009053604000000283; INGSTER Y. I., 1999, MATH METHODS STAT, V7, P401; INGSTER Y. I., 1997, MATH METHODS STAT, V6, P47; JIN J, 2007, PROPORTION NONZERO N; JIN J, 2007, UNPUB ESTIMATING PRO; Jin J, 2007, J AM STAT ASSOC, V102, P496; KENDALL DG, 1974, PHIL T R SOC LOND A, V276, P195; Mallat S., 1998, WAVELET TOUR SIGNAL; Meinshausen N, 2005, BIOMETRIKA, V92, P893, DOI 10.1093/biomet/92.4.893; Meinshausen N, 2006, ANN STAT, V34, P373, DOI 10.1214/009053605000000741; Shorack G.R., 1986, EMPIRICAL PROCESSES; Smyth G. K., 2004, STAT APPL GENET MOL, V3, DOI [10.2202/1544-6115.1027, DOI 10.2202/1544-6115.1027]; Stein C., 1961, P 4 BERK S MATH STAT, V1, P361; Swanepoel JWH, 1999, ANN STAT, V27, P24, DOI 10.1214/aos/1018031099; TANG W, 2007, IMS MONOGR SER, V54, P151; TANG W, 2006, BAYES EMPIRICAL BAYE; Wasserman L, 2006, ALL NONPARAMETRIC ST; Yang IV, 2002, GENOME BIOL, V3; ZHANG CH, 1990, ANN STAT, V18, P806, DOI 10.1214/aos/1176347627	36	7	7	1	2	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2008	70		3				461	493		10.1111/j.1467-9868.2007.00645.x		33	Statistics & Probability	Mathematics	287YX	WOS:000254954500001		
S	Singh, AP; Gordon, GJ		Daelemans, W; Goethals, B; Morik, K		Singh, Ajit P.; Gordon, Geoffrey J.			A Unified View of Matrix Factorization Models	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PART II, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	European Conference on Principles of Data Mining and Knowledge Discovery	SEP 15-19, 2008	Antwerp, BELGIUM	Univ Antwerp, Computat Linguist Flanders, Google, hp, VADIS, COGNOS, European Off Aerosp, SPSS, textkernel, Data Mining & Knowledge Discovery, IBM, Machine Learning				We present a unified view of matrix factorization that frames the differences among popular methods, such as NMF, Weighted SVD, E-PCA, MMMF, pLSI, pLSI-pHITS, Bregman co-clustering, and many others, in terms of a small number of modeling choices. Many of these approaches can be viewed as minimizing a generalized Bregman divergence, and we show that (i) a straightforward alternating projection algorithm can be applied to almost any model in our unified view; (ii) the Hessian for each projection has special structure that makes a Newton projection feasible, even when there are equality constraints on the factors, which allows for matrix co-clustering; and (iii) alternating projections can be generalized to simultaneously factor a set of matrices that share dimensions. These observations immediately yield new optimization algorithms for the above factorization methods, and suggest novel generalizations of these methods such as incorporating row and column biases, and adding or relaxing clustering constraints.	[Singh, Ajit P.; Gordon, Geoffrey J.] Carnegie Mellon Univ, Machine Learning Dept, Pittsburgh, PA 15213 USA	Singh, AP (reprint author), Carnegie Mellon Univ, Machine Learning Dept, Pittsburgh, PA 15213 USA.						Aldous D., 1985, ECOLE ETE PROBABILIT, P1; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50; KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643; ALDOUS DJ, 1981, J MULTIVARIATE ANAL, V11, P581, DOI 10.1016/0047-259X(81)90099-3; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; GABRIEL KR, 1979, TECHNOMETRICS, V21, P489, DOI 10.2307/1268288; Azoury KS, 2001, MACH LEARN, V43, P211, DOI 10.1023/A:1010896012157; Banerjee A., 2007, SDM; Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI 10.1016/0041-5553(67)90040-7; Buntine W, 2006, LECT NOTES COMPUT SC, V3940, P1; Cohn D., 2000, NIPS; Collins M., 2001, NIPS; Ding C, 2005, LECT NOTES ARTIF INT, V3720, P530; DING CHQ, 2006, AAAI; FORSTER J, 2000, COLT 00, P90; Golub G.H., 1996, MATRIX COMPUTIONS; Gordon G., 1999, THESIS CARNEGIE MELL; GORDON GJ, 2002, NIPS; Hartigan J., 1975, CLUSTERING ALGORITHM; *INT MOV DAT INC, 2007, IMDB ALT INT; Ke Q., 2005, CVPR, P739; Lee D. D., 2001, NIPS; Long B., 2006, ICML, P585; Long B., 2006, KDD, P317; Long B., 2007, ICML, P569; Long B, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P470; *NETFL, 2007, NETFL PRIZ DAT; NOCEDAL J., 1999, NUMERICAL OPTIMIZATI; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Pereira F., 2006, ICML, P689; RENNIE J, 2007, THESIS MIT; Rennie J.D.M., 2005, ICML, P713; RISH I, 2008, ICML; SCHEIN AI, 2003, AISTATS; Schmidt M, 2007, LECT NOTES ARTIF INT, V4701, P286; Singh A.P., 2008, KDD; Srebro N., 2004, NIPS; Srebro N., 2003, ICML; Vandenberghe L., 2004, CONVEX OPTIMIZATION; WELLING M, 2008, SDM; Welling M., 2005, NIPS; Yu K., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Yu S., 2006, KDD, P464; Zenios S., 1997, PARALLEL OPTIMIZATIO; Zhu S., 2007, SIGIR, P487	47	19	19	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-87480-5	LECT NOTES ARTIF INT			2008	5212		II				358	373				16	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	BIJ50	WOS:000260075900024		
S	Darkner, S; Sabuncu, MR; Golland, P; Paulsen, RR; Larsen, R		Metaxas, D; Axel, L; Fichtinger, G; Szekely, G		Darkner, Sune; Sabuncu, Mert R.; Golland, Polina; Paulsen, Rasmus R.; Larsen, Rasmus			Analysis of Surfaces Using Constrained Regression Models	MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2008, PT I, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	11th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI2008)	SEP 06-10, 2008	New York, NY	Rutgers Univ, New York Univ, Robarts Res Inst, NE Digital Inc, Medtron Inc, Siemens Corp Res, Philips, GE			RIDGE-REGRESSION; SELECTION; LASSO; EAR	We present a study of the relationship between the changes in the shape of the human ear due to jaw movement and acoustical feedback (AF) in hearing aids. In particular, we analyze the deformation field of the outer ear associated with the movement of the mandible (jaw bone) to understand its effect on AF and identify local regions that play a significant role. Our data contains ear impressions of 42 hearing aid users, in two different positions: open and closed mouth, and survey data including information about experienced discomfort due to AF. We use weighted Support vector machines (WSVM) to investigate the separation between the presence and lack of AF and achieve classification accuracy of 80% based on the deformation field. To robustly localize the regions of the deformation field that, significantly contribute to AF we employ logistic regression penalized with elastic net (EN). By visualizing the selected variables on the mean surface, we provide clinical interpretations of the results.	[Darkner, Sune; Larsen, Rasmus] Tech Univ Denmark, Dept Informat & Math Modelling, Lyngby, Denmark	Darkner, S (reprint author), Tech Univ Denmark, Dept Informat & Math Modelling, Lyngby, Denmark.	sda@imm.dtu.dk					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Malthouse EC, 1999, J INTERACT MARK, V13, P10, DOI 10.1002/(SICI)1520-6653(199923)13:4<10::AID-DIR2>3.0.CO;2-3; BOGER B, 1992, 5 ANN WORKSH COMP LE, P144; COOTES T, 2004, P BRIT MACH VIS C, V1, P447; DAKNER S, 2008, SPIE MED IMAGING; Darkner S, 2007, LECT NOTES COMPUT SC, V4792, P801; GOLLAND P, 2001, NIPS, P745; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; LIU S, 2005, NEW WEIGHTED SUPPORT, V7, P4351; OLIVEIRA RJ, 1992, EAR HEARING, V13, P464, DOI 10.1097/00003446-199212000-00013; PAULSEN RR, 2002, LNCS, V2489; SJOESTRAND K, 2008, SPIE MED IMAGING; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1035; ZOLLEIL, 2005, ICCV; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	17	0	0	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-85987-1	LECT NOTES COMPUT SC			2008	5241						842	849				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIO76	WOS:000261373700100		
S	Hagiwara, K		Ishikawa, M; Doya, K; Miyamoto, H; Yamakawa, T		Hagiwara, Katsuyuki			Orthogonal shrinkage methods for nonparametric regression under Gaussian noise	NEURAL INFORMATION PROCESSING, PART I	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	14th International Conference on Neural Information Processing (ICONIP 2007)	NOV 13-16, 2007	Kitakyushu, JAPAN	RIKEN Brain Sci Inst, Adv Telecommun Res Inst Int, Japan SOc Fuzzy Theory & Intelligent Informat, IEEE CIS Japan Chap, Fuzzy Log Syst Inst			MACHINES	In this article, for regression problems, we proposed shrinkage methods in training a machine in terms of a regularized cost function. The machine considered in this article is represented by a linear combination of fixed basis functions, in which the number of basis functions, or equivalently, the number of adjustable weights is identical to the number of training data. This setting can be viewed as a nonparametric regression method in statistics. In the regularized cost function employed in this article, the error function is defined by the sum of squared errors and the regularization term is defined by the quadratic form of the weight vector. By assuming i.i.d. Gaussian noise, we proposed three thresholding methods for the orthogonal components which are obtained by eigendecomposition of the Gram matrix of the vectors of basis function outputs. The final weight values are obtained by a linear transformation of the thresholded orthogonal components and are shrinkage estimators. The proposed methods are quite simple and automatic, in which the regularization parameter is enough to be fixed for a small constant value. Simple numerical experiments showed that, by comparing the leave-one-out cross validation method, the computational costs of the proposed methods are strictly low and the generalization capabilities of the trained machines are comparable when the number of data is relatively large.	Mie Univ, Fac Educ, Tsu, Mie 5148507, Japan	Hagiwara, K (reprint author), Mie Univ, Fac Educ, 1577 Kurima Machiya Cho, Tsu, Mie 5148507, Japan.						Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; CRAVEN P, 1979, NUMER MATH, V31, P377; CARTER CK, 1992, J ROY STAT SOC B MET, V54, P773; Chen S, 2006, NEUROCOMPUTING, V69, P559, DOI 10.1016/j.neucom.2004.12.011; Cristianini N., 2000, INTRO SUPPORT VECTOR; Rifkin R., 2002, THESIS MIT; Williams CKI, 2001, ADV NEUR IN, V13, P682	9	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-69154-9	LECT NOTES COMPUT SC			2008	4984		I				537	546				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHX61	WOS:000257246100056		
B	Wang, Y; Xia, Y		Zhang, XS; Chen, L; Wu, LY; Wang, Y		Wang, Yong; Xia, Yu			Condition specific subnetwork identification using an optimization model	OPTIMIZATION AND SYSTEMS BIOLOGY, PROCEEDINGS	Lecture Notes in Operations Research		English	Proceedings Paper	2nd International Symposium on Optimization and Systems Biology	OCT 31-NOV 03, 2008	Lijiang, PEOPLES R CHINA	Chinese Acad Sci, Shangha Univ, Univ Tokyo, Natl Nat Sci Fdn China		Condition specific subnetwork; Optimization model and algorithm; Diabetes	NETWORKS; MODULES; GRAPHS	Subnetworks can reveal the complex patterns of the whole-genome network by extracting the interactions that depend on temporal, spatial, or condition specific context. In this paper we present an optimization framework to identify condition specific subnetworks. This framework allows us to identify the most coherent subnetwork by integrating the information from both nodes and edges. in the graph. Importantly we design an algorithm to solve the optimization problem efficiently. It is very fast and can extract subnetworks from large-scale network with about 10000 nodes. As a pilot study we apply our method to identify type 2 diabetes related subnetworks in the human protein-protein interaction network.	[Wang, Yong; Xia, Yu] Boston Univ, Bioinformat Program, Dept Chem, Boston, MA 02215 USA	Wang, Y (reprint author), Boston Univ, Bioinformat Program, Dept Chem, Boston, MA 02215 USA.		Wang, Yong/J-9193-2012				Alon U., 2007, INTRO SYSTEMS BIOL D; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Stark C, 2006, NUCLEIC ACIDS RES, V34, pD535, DOI 10.1093/nar/gkj109; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; AUFFRAY C, 2007, MOL SYSTEMS BIOL, V3; Chuang HY, 2007, MOL SYSTEMS BIOL, V3; Ding C, 2006, INT J DATA MIN BIOIN, V1, P162, DOI 10.1504/IJDMB.2006.010854; Eisenberg D, 2000, NATURE, V405, P823, DOI 10.1038/35015694; Li Z, 2007, BIOINFORMATICS, V23, P1631, DOI 10.1093/bioinformatics/btm156; Liu M, 2007, PLOS GENET, V3, P958, DOI 10.1371/journal.pgen.0030096; MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6; Pereira-Leal JB, 2004, PROTEINS, V54, P49, DOI 10.1002/prot.10505'; Tiffin N, 2006, NUCLEIC ACIDS RES, V34, P3067, DOI 10.1093/nar/gkl381; YE Y, 1992, PRINCETON SERIES COM, P19; Zhang SH, 2007, PROTEOMICS, V7, P2856, DOI 10.1002/pmic.200700095; Zhao XM, 2008, NUCLEIC ACIDS RES, V36, DOI 10.1093/nar/gkn145	17	10	10	2	2	WORLD PUBLISHING CORPORATION	BEIJING	137 CHAONEI DAJIE, BEIJING 100010, PEOPLES R CHINA			978-7-5062-9289-4	LECT NOTES OPER RES			2008	9						333	340				8	Mathematical & Computational Biology; Operations Research & Management Science; Mathematics, Applied	Mathematical & Computational Biology; Operations Research & Management Science; Mathematics	BJA64	WOS:000264181700042		
J	Kunapuli, G; Bennett, KP; Hu, J; Pang, JS				Kunapuli, G.; Bennett, K. P.; Hu, Jing; Pang, Jong-Shi			Classification model selection via bilevel programming	OPTIMIZATION METHODS & SOFTWARE			English	Article; Proceedings Paper	Workshop on Mathematical Programming in Data Mining and Machine Learning	JUN 01-04, 2005	Hamilton, CANADA		McMaster Univ	support vector classification; cross-validation; bilevel programming; model selection; feature selection	SUPPORT VECTOR MACHINES; COMPLEMENTARITY CONSTRAINTS; MATHEMATICAL PROGRAMS; REGULARIZATION; CONVERGENCE; ALGORITHM	Support vector machines and related classification models require the solution of convex optimization problems that have one or more regularization hyper-parameters. Typically, the hyper-parameters are selected to minimize the cross-validated estimates of the out-of-sample classification error of the model. This cross-validation optimization problem can be formulated as a bilevel program in which the outer-level objective minimizes the average number of misclassified points across the cross-validation folds, subject to inner-level constraints such that the classification functions for each fold are (exactly or nearly) optimal for the selected hyper-parameters. Feature selection is included in the bilevel program in the form of bound constraints in the weights. The resulting bilevel problem is converted to a mathematical program with linear equilibrium constraints, which is solved using state-of-the-art optimization methods. This approach is significantly more versatile than commonly used grid search procedures, enabling, in particular, the use of models with many hyper-parameters. Numerical results demonstrate the practicality of this approach for model selection in machine learning.	[Kunapuli, G.; Bennett, K. P.; Hu, Jing] Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12180 USA; [Pang, Jong-Shi] Univ Illinois, Dept Ind & Enterprise Syst Engn, Urbana, IL 61801 USA	Kunapuli, G (reprint author), Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12180 USA.	kunapg@rpi.edu	Kunapuli, Gautam/E-9804-2013	Kunapuli, Gautam/0000-0002-9297-2071			ANITESCU M, 2002, ANLMCSP12420405; Anitescu M, 2005, SIAM J OPTIMIZ, V15, P1203, DOI 10.1137/S1052623402401221; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Jiang HY, 2000, SIAM J OPTIMIZ, V10, P779, DOI 10.1137/S1052623497332329; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Fletcher R, 2004, OPTIM METHOD SOFTW, V19, P15, DOI 10.1080/10556780410001654241; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; BENNETT K, 2006, P INT JOINT C NEUR N, P1922; Dempe S, 2003, OPTIMIZATION, V52, P333, DOI 10.1080/0233193031000149894; Dempe S., 2002, FDN BILEVEL PROGRAMM; Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X; FACCHINEI F, 2003, FINITE DIMENSIONAL V, P10; Ferris MC, 2004, MATH PROGRAM, V101, P185, DOI 10.1007/s10107-004-0541-8; Fletcher R, 2002, SIAM J OPTIMIZ, V13, P44, DOI 10.1137/S105262340038081X; FLETCHER R, USER MANAUAL FILTERS; Fletcher R, 2002, MATH PROGRAM, V91, P239, DOI 10.1007/s101070100244; FLETCHER R, 2006, SIAM J OPTIMIZ, V1, P259; Fukushima M, 2002, SIAM J OPTIMIZ, V12, P724, DOI 10.1137/S1052623499363232; Fukushima M, 1999, LECT NOTES ECON MATH, V477, P99; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; JOACIMS T, P 12 ACM SIGKDD INT, P217; Luo Z.-Q., 1996, MATH PROGRAMS EQUILI; MANGASARIAN OL, 1994, J GLOBAL OPTIM, V5, P309, DOI 10.1007/BF01096681; Scheel H, 2000, MATH OPER RES, V25, P1, DOI 10.1287/moor.25.1.1.15213; Scheinberg K, 2006, J MACH LEARN RES, V7, P2237; Scholtes S, 1999, SIAM J CONTROL OPTIM, V37, P617, DOI 10.1137/S0363012996306121; Scholtes S, 2001, SIAM J OPTIMIZ, V11, P918, DOI 10.1137/S1052623499361233; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Vapnik V., 2000, NATURE STAT LEARNING; WANG G, 2006, P 23 INT C MACH LEAR, V148, P993; Zhu J., 2003, ADV NEURAL INFORM PR, V16	36	9	9	0	4	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1055-6788			OPTIM METHOD SOFTW	Optim. Method Softw.		2008	23	4					475	489		10.1080/10556780802102586		15	Computer Science, Software Engineering; Operations Research & Management Science; Mathematics, Applied	Computer Science; Operations Research & Management Science; Mathematics	324UO	WOS:000257545100002		
B	Coons, KE; Robatmili, B; Taylor, ME; Maher, BA; Burger, D; McKinley, KS			ACM	Coons, Katherine E.; Robatmili, Behnam; Taylor, Matthew E.; Maher, Betrand A.; Burger, Doug; McKinley, Kathryn S.			Feature Selection and Policy Optimization for Distributed Instruction Placement Using Reinforcement Learning	PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES			English	Proceedings Paper	17th International Conference on Parallel Architectures and Compilation Techniques	OCT 25-29, 2008	Toronto, CANADA	ACM SIGARCH, IEEE CS TCCA, IFIP, IEEE CS TCCP		Instruction Scheduling; Machine Learning; Genetic Algorithms; Neural Networks; Compiler Heuristics	NEURAL-NETWORKS	Communication overheads are one of the fundamental challenges in a multiprocessor system. As the number of processors on a chip increases, communication overheads and the distribution of computation and data become increasingly important performance factors. Explicit Dataflow Graph Execution (EDGE) processors, in which instructions communicate with one another directly on a distributed substrate, give the compiler control over communication overheads at a fine granularity. Prior work shows that compilers can effectively reduce fine-grained communication overheads in EDGE architectures using a spatial instruction placement algorithm with a heuristic-based cost function. While this algorithm is effective, the cost function must be painstakingly tuned. Heuristics tuned to perform well across a variety of applications leave users with little ability to tune performance-critical applications, yet we find that the best placement heuristics vary significantly with the application. First, we suggest a systematic feature selection method that reduces the feature set size based on the extent to which features affect performance. To automatically discover placement heuristics, we then use these features as input to a reinforcement learning technique, called Neuro-Evolution of Augmenting Topologies (NEAT), that uses a genetic algorithm to evolve neural networks. We show that NEAT outperforms simulated annealing, the most commonly used optimization technique for instruction placement. We use NEAT to learn general heuristics that are as effective as hand-tuned heuristics, but we find that improving over highly hand-tuned general heuristics is difficult. We then suggest a hierarchical approach to machine learning that classifies segments of code with similar characteristics and learns heuristics for these classes. This approach performs closer to the specialized heuristics. Together, these results suggest that learning compiler heuristics may benefit from both improved feature selection and classification.	[Coons, Katherine E.; Robatmili, Behnam; Taylor, Matthew E.; Maher, Betrand A.; Burger, Doug; McKinley, Kathryn S.] Univ Texas Austin, Austin, TX 78712 USA	Coons, KE (reprint author), Univ Texas Austin, Austin, TX 78712 USA.	coonske@cs.utexas.edu; beroy@cs.utexas.edu; mtaylor@cs.utexas.edu; bmaher@cs.utexas.edu; dburger@cs.utexas.edu; mckinley@cs.utexas.edu					Agakov F., 2006, INT S COD GEN OPT CG, P295, DOI 10.1109/CGO.2006.37; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115; CAVAZOS J, 2006, INT C COMP CONSTR VI, P124; Cavazos J., 2005, ACM IEEE C SUP WASH, P14, DOI 10.1109/SC.2005.14; CAVAZOS J, 2006, ACM INT C COMP ARCH, P24; CAVAZOS J, 2004, ACM C PROGR LANG DES, P183; COONS KE, 2006, ASPLOS 12, P129; COOPER K, 1999, ACM SIGPLAN WORKSH L, P1; Dasgupta D., 1992, INT WORKSH COMB GEN, P87; DUBACH C, 2007, ACM INT C COMP FRONT, P131; KISUKI T, 1999, 2 INT S HIGH PERF CO, P121; Kisuki T, 2000, COMPILERS PARALLEL C, P35; LEATHER H, 2008, 2 WORKSH ST IN PRESS; Maher BA, 2006, INT SYMP MICROARCH, P65; Mahlke S. A., 1992, INT S MICR; MERCALDI M, 2006, S PAR ARCH APPL CAMB, P158; MERCALDI M, 2006, ASPLOS XII P 12 INT, P141; Monsifrot A., 2002, P 10 INT C ART INT M, P41; Moss E., 1997, P NEUR INF PROC S, P929; PAULIN PG, 1987, ACM IEEE C DES AUT M, P195; Sankaralingam K, 2006, INT SYMP MICROARCH, P480; SMITH A, 2006, INT S COD GEN OPT MA; Stephenson M., 2005, International Symposium on Code Generation and Optimization, DOI 10.1109/CGO.2005.29; STEPHENSON M, 2003, ACM SIGPLAN C PROGR, P77; Taylor M., 2006, P GEN EV COMP C, P1321, DOI 10.1145/1143997.1144202; WATERMAN T, 2006, THESIS RICE U; Whiteson S, 2005, GECCO 2005: Genetic and Evolutionary Computation Conference, Vols 1 and 2, P1225; Witten I., 2005, DATA MINING PRACTICA; Yao X, 1999, P IEEE, V87, P1423	31	3	3	0	5	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-282-5				2008							32	42		10.1145/1454115.1454122		11	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	BJR85	WOS:000267053400004		
S	Morup, M; Madsen, KH; Hansen, LK			IEEE	Morup, Morten; Madsen, Kristoffer Hougaard; Hansen, Lars Kai			Approximate L(0) constrained non-negative matrix and tensor factorization	PROCEEDINGS OF 2008 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-10	IEEE International Symposium on Circuits and Systems		English	Proceedings Paper	IEEE International Symposium on Circuits and Systems	MAY 18-21, 2008	Seattle, WA	IEEE			REGRESSION; SELECTION	Non-negative matrix factorization (NMF), i.e. V approximate to WH where both V, W and H are non-negative has become a widely used blind source separation technique due to its part based representation. The NMF decomposition is not in general unique and a part based representation not guaranteed. However, imposing sparseness both improves the uniqueness of the decomposition and favors part based representation. Sparseness in the form of attaining as many zero elements in the solution as possible is appealing from a conceptional point of view and corresponds to minimizing reconstruction error with an L(0) norm constraint. In general, solving for a given L(0) norm is an NP hard problem thus convex relaxation to regularization by the L(1) norm is often considered, i.e., minimizing (1/2 parallel to V-WH parallel to(2)(F)+gimel parallel to H parallel to(1)). An open problem is to control the degree of sparsity A imposed. We here demonstrate that a full regularization path for the L(1) norm regularized least squares NMF for fixed W can be calculated at the cost of an ordinary least squares solution based on a modification of the Least Angle Regression and Selection (LARS) algorithm forming a non-negativity constrained LARS (NLARS). With the full regularization path, the L(1) regularization strength gimel that best approximates a given L(0) can be directly accessed and in effect used to control the sparsity of H. The MATLAB code for the NLARS algorithm is available for download.	[Morup, Morten; Madsen, Kristoffer Hougaard; Hansen, Lars Kai] Tech Univ Denmark, DK-2800 Lyngby KGS, Denmark	Morup, M (reprint author), Tech Univ Denmark, DK-2800 Lyngby KGS, Denmark.	mm@imm.dtu.dk; khm@imm.dtu.dk; lkh@imm.dtu.dk	Hansen, Lars/E-3174-2013				Bro R, 1997, J CHEMOMETR, V11, P393, DOI 10.1002/(SICI)1099-128X(199709/10)11:5<393::AID-CEM483>3.0.CO;2-L; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Lee DD, 1999, NATURE, V401, P788; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Efron B, 2004, ANN STAT, V32, P407; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; Welling M, 2001, PATTERN RECOGN LETT, V22, P1255, DOI 10.1016/S0167-8655(01)00070-8; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Donoho D., 2003, DOES NONNEGATIVE MAT; Eggert J., 2004, NEURAL NETWORKS, V4, P2529; Harshman R.A., 1970, UCLA WORKING PAPERS, V16, P1; Hoyer PO, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P557, DOI 10.1109/NNSP.2002.1030067; Lee DD, 2000, NIPS, P556; *MIT CTR BIOL COMP, 1 MIT CTR BIOL COMP; MORUP M, NLARS ALGORITHM; MORUP M, ALGORITHMS SPA UNPUB; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; SHAOBING SC, 1994, 28 AS C SIGN SYST CO; SMARAGDIS P, 2003, NONNEGATIVE MATRIX F, P177	22	8	8	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0271-4302		978-1-4244-2078-0	IEEE INT SYMP CIRC S			2008							1328	1331				4	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied; Telecommunications	Computer Science; Engineering; Physics; Telecommunications	BID36	WOS:000258532101063		
B	Deng, HS; Ma, YZ; Shao, WZ		Xia, GP; Deng, XQ		Deng, Haisong; Ma, Yizhong; Shao, Wenze			SPARSE VARIABLE SELECTION VIA ITERATIVELY REWEIGHTED LEAST SQUARES	PROCEEDINGS OF THE 38TH INTERNATIONAL CONFERENCE ON COMPUTERS AND INDUSTRIAL ENGINEERING, VOLS 1-3			English	Proceedings Paper	38th International Conference on Computers and Industrial Engineering	OCT 31-NOV 02, 2008	Beijing, PEOPLES R CHINA		Beihang Univ	Variable selection; Sparseness; Computer experiments; Reweighted least squares; Regularization	COMPUTER EXPERIMENTS; REGRESSION	Recently, there has been growing interest in computer experiments which are extremely important in modern industry, science, and engineering. A feature of computer experiments is that the number of input variables can be quite large, so screening active-effective factors is very important. One of the goals in computer experiments is to choose a parsimonious model by variable selection that is viewed as a kind of regularization. In this paper, a novel algorithm is proposed originated from signal processing. Different from the existed methods, we present a reweighted L-2 norm to approximate the L-p(0 < p < 1) minimization problems with good sparseness for variable selection. The algorithm consists of solving a sequence of weighted L-2 minimization problems where the weights used for the next iteration are computed from the value of the current solution. This novel regularization strategy which has no necessity to choose the proper regularization parameter is found to greatly improve the ability of variable selection. We illustrate our algorithm by a famous example and make comparison with previous works. Experimental results demonstrate that the new algorithm not only behaves better than many other methods, bust also has low computational cost.	[Deng, Haisong; Ma, Yizhong; Shao, Wenze] Nanjing Univ Sci & Technol, Dept Management Sci & Engn, Nanjing, Peoples R China	Deng, HS (reprint author), Nanjing Univ Sci & Technol, Dept Management Sci & Engn, Nanjing, Peoples R China.	denghaisong1003@yahoo.com.cn; yzma-2004@163.com; shaowenze1010@yahoo.com.cn					An J, 2001, J COMPLEXITY, V17, P588, DOI 10.1006/jcom.2001.0588; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; [Anonymous], 1996, HANDB STAT, DOI 10.1016/S0169-7161(96)13011-X; SACKS J, 1989, TECHNOMETRICS, V31, P41, DOI 10.2307/1270363; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; BOX GEP, 1986, TECHNOMETRICS, V28, P11, DOI 10.2307/1269599; Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251; Efron B, 2004, ANN STAT, V32, P407; CRAVEN P, 1979, NUMER MATH, V31, P377; Breiman L, 1996, ANN STAT, V24, P2350; CHARTRAND R, 2008, ITERATIVE REW UNPUB; Donoho DL, 2004, MOST LARGE UND UNPUB; FANG KT, 2000, CASE STUDIES C UNPUB; FANG KT, 2001, HDB STAT; Fang KT, 2006, CH CRC COMP SCI DATA, P3; Li R., 2002, INT J RELIAB QUAL SA, V9, P367, DOI 10.1142/S0218539302000901; Miller A, 2002, SUBSET SELECTION REG, V2nd; MORRIS MD, 1993, TECHNOMETRICS, V35, P243, DOI 10.2307/1269517; Rao C. R., 1973, LINEAR STAT INFERENC; Sacks J., 1989, STAT SCI, V4, P409, DOI DOI 10.1214/SS/1177012413; WORLEY B, 1987, DETERMINISTIC UNCERT	23	0	0	0	8	PUBLISHING HOUSE ELECTRONICS INDUSTRY	BEIJING	PO BOX 173 WANSHOU ROAD, BEIJING 100036, PEOPLES R CHINA			978-7-121-07437-0				2008							467	472				6	Computer Science, Information Systems; Engineering, Industrial	Computer Science; Engineering	BIR61	WOS:000262289600065		
B	Wang, LM; You, JH; Zhou, Y		Ai, C; Wu, D		Wang, Liming; You, Jinhong; Zhou, Yong			Selection of risk factors for regression analysis with missing data	PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON FINANCIAL ENGINEERING AND RISK MANAGEMENT 2008			English	Proceedings Paper	International Symposium on Financial Engineering and Risk Management	JUN 08-10, 2008	Shanghai, PEOPLES R CHINA	Shanghai Univ Finance & Econ, Bendheim Ctr Finance, Princton Univ, CME UIC Int Ctr Futures & Derivat, Univ Illinois Chicago, Ctr Stat Res, Chinese Acad Sci, RiskChina Res Ctr, Univ Toronto		risk factors; estimated likelihood; nonconcave panelization; oracle property; asymptotic normality	MODELS; VALIDATION; ERROR	We propose a penalized estimated likelihood method for variable selection in the regression model with some risk factors being missing or mismeasured. Under some general regularity conditions, we show the consistency and asymptotic normality of-the penalized likelihood estimator. We further propose that, for certain penalty functions with proper choices of regularization parameters, a sophisticated selection approach of tuning parameter is given by local quadratic approximation. Some simulation study results show that the proposed method performs well under reasonable finite sample results. We illustrate the proposed method by analyzing a data set from the Collaborative Perinatal Project (CPP).	[Wang, Liming] Shanghai Univ Finance & Econ, Dept Stat, Shanghai, Peoples R China							Akaike H., 1973, P 2 INT S INF THEOR, P267; BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; ROBINS JM, 1994, J AM STAT ASSOC, V89, P846, DOI 10.2307/2290910; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; CAI J, 2003, MODEL SELECTIO UNPUB; CARROLL RJ, 1991, J ROY STAT SOC B MET, V53, P573; Chen HY, 2004, J AM STAT ASSOC, V99, P1176, DOI 10.1198/016214504000001727; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2002, ANN STAT, V30, P74; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; Hall P, 2004, J AM STAT ASSOC, V99, P1015, DOI 10.1098/01621450400000548; Hall P, 2005, ANN STAT, V33, P1404, DOI 10.1214/009053604000001282; Li R, 2001, J AM STAT ASSOC, V95, P1348; Liang H, 2004, J AM STAT ASSOC, V99, P357, DOI 10.1198/016214504000000421; Little Roderick, 1987, STAT ANAL MISSING DA; LONGNECKER MP, 2002, AM J EPIDEMIOL, V155, P311; PEPE MS, 1991, J AM STAT ASSOC, V86, P108, DOI 10.2307/2289720; ROBIN DB, 1976, BIOMERIKA, V6, P581; SCHILL W, 1993, BIOMETRIKA, V80, P339, DOI 10.1093/biomet/80.2.339; Sepanski J. H., 1995, J NONPARAMETR STAT, V4, P365, DOI 10.1080/10485259508832627; WITTES J, 1989, STAT MED, V8, P415, DOI 10.1002/sim.4780080405; Wu L, 2004, CAN J STAT, V32, P27, DOI 10.2307/3315997; Wu L, 2004, J AM STAT ASSOC, V99, P700, DOI 10.1198/0162145040000001006; Zhou H, 1995, BIOMETRIKA, V85, P139; Zhou H, 2000, J ROY STAT SOC B, V62, P657, DOI 10.1111/1467-9868.00255; Zhou HB, 2002, BIOMETRICS, V58, P352, DOI 10.1111/j.0006-341X.2002.00352.x	29	0	0	0	3	UNIVERSE ACADEMIC PRESS TORONTO	TORONTO	1 SPADINA CRESCENT,  ROOM 205, TORONTO, ONTARIO M5S 3G3, CANADA			978-0-9783484-6-5				2008							29	33				5	Business, Finance; Economics; Management; Mathematics, Applied	Business & Economics; Mathematics	BIF42	WOS:000259115100005		
S	Shi, Y; Simon, I; Mitchell, T; Bar-Joseph, Z		Vingron, M; Wong, L		Shi, Yanxin; Simon, Itamar; Mitchell, Tom; Bar-Joseph, Ziv			A combined expression-interact ion model for inferring the temporal activity of transcription factors	RESEARCH IN COMPUTATIONAL MOLECULAR BIOLOGY, PROCEEDINGS	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	12th Annual International Conference on Research Computational Molecular Biology	MAR 30-APR 02, 2008	Singapore, SINGAPORE	Natl Univ Singapore, NUS Bioinformat Programme, Lilly, IBM, ISCB, World Sci, Taylor & Francis			SACCHAROMYCES-CEREVISIAE; GENE-EXPRESSION; PROTEIN-KINASE; NETWORK; CYCLE; PHOSPHORYLATION; YEAST; PATHWAYS; SEQUENCE; STRESS	Methods suggested for reconstructing regulatory networks can be divided into two sets based on how the activity level of transcription factors (TFs) is inferred. The first group of methods relies on the expression levels of TFs assuming that the activity of a TF is highly correlated with its mRNA abundance. The second treats the activity level as unobserved and infers it from the expression of the genes the TF regulates. While both types of methods were successfully applied, each suffers from drawbacks that limit their accuracy. For the first set, the assumption that mRNA levels are correlated with activity is violated for many TFs due to post-transcriptional modifications. For the second, the expression level of a TF which might be informative is completely ignored. Here we present the Post-Transcriptional Modification Model (PTMM) that unlike previous methods utilizes both sources of data concurrently. Our method uses a switching model to determine whether a TF is transcriptionally or post-transcriptionally regulated. This model is combined with a factorial HMM to fully reconstruct the interactions in a dynamic regulatory network. Using simulated and real data we show that PTMM outperforms the other two approaches discussed above. Using real data we also show that PTMM can recover meaningful TF activity levels and identify post-transcriptionally modified TFs, many of which are supported by other sources.	[Shi, Yanxin; Mitchell, Tom; Bar-Joseph, Ziv] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Bar-Joseph, Z (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.			Bar-Joseph, Ziv/0000-0003-3430-6051			Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Arbeitman MN, 2002, SCIENCE, V297, P2270, DOI 10.1126/science.1072152; MacIsaac KD, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-113; Nau GJ, 2002, P NATL ACAD SCI USA, V99, P1503, DOI 10.1073/pnas.022649799; Zou M, 2005, BIOINFORMATICS, V21, P71, DOI 10.1093/bioinformatics/bth463; Ideker T, 2001, SCIENCE, V292, P929, DOI 10.1126/science.292.5518.929; Gorner W, 1998, GENE DEV, V12, P586, DOI 10.1101/gad.12.4.586; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Theuns J, 2000, HUM MOL GENET, V9, P2383, DOI 10.1093/hmg/9.16.2383; Garreau H, 2000, MICROBIOL-UK, V146, P2113; Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023; Hu ZZ, 2007, NAT GENET, V39, P683, DOI 10.1038/ng2012; Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; Harbison CT, 2004, NATURE, V431, P99, DOI 10.1038/nature02800; Bose S, 2005, GENETICS, V169, P1215; D'haeseleer P, 2000, BIOINFORMATICS, V16, P707, DOI 10.1093/bioinformatics/16.8.707; Ernst J, 2007, NATURE EMBO MOL SYST, V3, P74; KANNAN, 2007, LNCS, V4453, P325; MITCHELL T, 2006, P ICML; MOLL T, 1991, CELL, V66, P743, DOI 10.1016/0092-8674(91)90118-I; Murphy K., 2002, THESIS U CALIFORNIA; NACHMAN I, 2004, BIOINFORMATICS, V20, P1248; Panda S, 2002, CELL, V109, P307, DOI 10.1016/S0092-8674(02)00722-5; Pearl J, 1998, PROBABILISTIC REASON; Pic-Taylor A, 2004, MOL CELL BIOL, V24, P10036, DOI 10.1128/MCB.24.22.10036-10046.2004; Sabatti C, 2006, BIOINFORMATICS, V22, P739, DOI 10.1093/bioinformatics/btk017; Shi Y., 2007, BIOINFORMATICS, V23, P459; Tanay A, 2001, Bioinformatics, V17 Suppl 1, pS270; TSANG JSH, 1990, NUCLEIC ACIDS RES, V18, P7331, DOI 10.1093/nar/18.24.7331; Wang LF, 2007, BIOINFORMATICS, V23, P1486, DOI 10.1093/bioinformatics/btm125; Washburn MP, 2003, P NATL ACAD SCI USA, V100, P3107, DOI 10.1073/pnas.0634629100; Workman CT, 2006, SCIENCE, V312, P1054, DOI 10.1126/science.1122088; XING E, 2003, P UAI	35	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-78838-6	LECT N BIOINFORMAT			2008	4955						82	97				16	Biochemical Research Methods; Biochemistry & Molecular Biology; Computer Science, Information Systems; Mathematical & Computational Biology; Mathematics, Applied	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology; Mathematics	BHM89	WOS:000254391500006		
B	Liu, ZQ		Wani, MA; Chen, X; Casasent, D; Kurgan, L; Hu, T; Hafeez, K		Liu, Zhenqiu			Detecting Disease Associated Genes and Gene-Gene Interactions with Penalized AUC Maximization	SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS			English	Proceedings Paper	7th International Conference on Machine Learning and Applications	DEC 11-13, 2008	San Diego, CA	IEEE SMC, Calif State Univ Bakersfield, Assoc Machine Learning & Applicat			LASSO	In an association study, empirical evidences support the commonality of gene-gene interactions. Although genetic factors play an important role in many human diseases, multiple genes or genes and environmental factors may ultimately influence individual risk for these disease. However, such interactions are difficult to detect. In this paper we propose a penalized area under ROC curve (AUC) maximization (LpAUC) to detect gene-gene interactions. The proposed approach is demonstrated by a simulation study and real data analysis. Analyses of both real data and simulated data show the effectiveness of our approach.	Univ Maryland, Greenebaum Canc Ctr, Div Biostat, Baltimore, MD 21201 USA	Liu, ZQ (reprint author), Univ Maryland, Greenebaum Canc Ctr, Div Biostat, 22 S Greene St, Baltimore, MD 21201 USA.	zliu@umm.edu					Malioutov D, 2005, IEEE T SIGNAL PROCES, V53, P3010, DOI 10.1109/TSP.2005.850882; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Ritchie MD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-28; CALDERS T, 2007, 11 EUR C PRINC PRACT, P42; Chen SH, 2008, GENET EPIDEMIOL, V32, P152, DOI 10.1002/gepi.20272; Chen X, 2007, P NATL ACAD SCI USA, V104, P19199, DOI 10.1073/pnas.0709868104; CLAYTON D, 2004, GENET EPIDEMIOL, V27; COOK N, 2004, STAT MED, V23; CORDELL HJ, 2002, AM J HUM GENET, V70; HALL P, 2003, ANN STAT, V31; Hsieh FS, 1996, ANN STAT, V24, P25; LIU Z, 2007, J STAT APPL GENETICS, V6; LIU Z, 2008, IEEE ACM T COMP 0128; Mailund T, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105/7/454; METZ CE, 1998, STAT MED, V17; Musani SK, 2007, HUM HERED, V63, P67, DOI 10.1159/000099179; PARK MY, 2006, PENALIZED LOGISTIC R; QIN G, 2006, BIOMETRICS, V62; TIBSHIRANI R, 1998, STAT MED; TIPPING ME, 2001, J MACHINE LEARNING R, V1; VERZILLI CJ, 2006, J HUM GENET, V79; WAN S, 2007, STAT MED, V26; WANG WYS, 2005, NAT REV, V6; ZOU KH, 2000, J APPL STAT, V27	26	0	0	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3495-4				2008							599	603		10.1109/ICMLA.2008.145		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BIV71	WOS:000263205800089		
J	Yin, WT; Osher, S; Goldfarb, D; Darbon, J				Yin, Wotao; Osher, Stanley; Goldfarb, Donald; Darbon, Jerome			Bregman Iterative Algorithms for l(1)-Minimization with Applications to Compressed Sensing	SIAM JOURNAL ON IMAGING SCIENCES			English	Article						l(1)-minimization; basis pursuit; compressed sensing; iterative regularization; Bregman distances		We propose simple and extremely efficient methods for solving the basis pursuit problem min{parallel to u parallel to(1) : Au = f, u is an element of R(n)}, which is used in compressed sensing. Our methods are based on Bregman iterative regularization, and they give a very accurate solution after solving only a very small number of instances of the unconstrained problem min(u is an element of Rn) mu parallel to u parallel to(1)+ 1/2 parallel to Au-f(k)parallel to(2)(2) for given matrix A and vector f(k). We show analytically that this iterative approach yields exact solutions in a finite number of steps and present numerical results that demonstrate that as few as two to six iterations are sufficient in most cases. Our approach is especially useful for many compressed sensing applications where matrix-vector operations involving A and A(inverted perpendicular) can be computed by fast transforms. Utilizing a fast fixed-point continuation solver that is based solely on such operations for solving the above unconstrained subproblem, we were able to quickly solve huge instances of compressed sensing problems on a standard PC.	[Yin, Wotao] Rice Univ, Dept Computat & Appl Math, Houston, TX 77005 USA; [Osher, Stanley; Darbon, Jerome] Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA; [Goldfarb, Donald] Columbia Univ, Dept Ind Engn & Operat Res, New York, NY 10027 USA	Yin, WT (reprint author), Rice Univ, Dept Computat & Appl Math, Houston, TX 77005 USA.	wotao.yin@rice.edu; sjo@math.ucla.edu; goldfarb@columbia.edu; jerome@math.ucla.edu			Dean of Engineering at Rice University; ONR [N000140710810, N00014-03-0514]; NSF [DMS 06-06712]; DOE [GE-FG01-92ER-25126]	This author's research was supported by an internal faculty research grant from the Dean of Engineering at Rice University.The research of these authors was supported by ONR grant N000140710810.This author's research was supported in part by NSF grant DMS 06-06712, ONR grant N00014-03-0514, and DOE grant GE-FG01-92ER-25126.	ADEYEMI T, 2005, 2005 IEEE SP 13 WORK, P865; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; DeVore RA, 2007, J COMPLEXITY, V23, P918, DOI 10.1016/j.jco.2007.04.002; Candes E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Elad M, 2007, APPL COMPUT HARMON A, V23, P346, DOI 10.1016/j.acha.2007.02.002; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; PANG JS, 1987, MATH OPER RES, V12, P474, DOI 10.1287/moor.12.3.474; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Rudelson M, 2005, INT MATH RES NOTICES, P4019; Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319; Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195; Candes EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; LUO ZQ, 1992, SIAM J CONTROL OPTIM, V30, P408, DOI 10.1137/0330025; Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI 10.1016/j.sigpro.2005.05.029; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; Combettes PL, 2008, SIAM J OPTIMIZ, V18, P1351, DOI 10.1137/060669498; BACHMAYR M, 2007, THESIS J KEPLER U LI; Bajwa W., 2006, P 5 INT C INF PROC S, P134, DOI DOI 10.1145/1127777.1127801; Baron D., 2005, DISTRIBUTED COMPRESS; Bect J., 2004, LECT NOTES COMPUTER, V3024, P1; Bioucas-Dias JM, 2006, IEEE T IMAGE PROCESS, V15, P937, DOI 10.1109/TIP.2005.863972; Bioucas-Dias JM, 2007, P IEEE INT C IM PROC; BLUMENSATH T, J FOURIER A IN PRESS; Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI 10.1016/0041-5553(67)90040-7; Burger M, 2006, COMMUN MATH SCI, V4, P179; Burger M, 2005, LECT NOTES COMPUT SC, V3752, P25; CHAMBOLLE A, 2005, 7641 UMR CNRS EC POL; CHARTRAND R, P ICASSP 08 UNPUB; CHARTRAND R, 2007, P 32 INT C AC SPEECH, P889; Chen T, 2005, LECT NOTES COMPUT SC, V3765, P114; Darbon J, 2006, J MATH IMAGING VIS, V26, P261, DOI 10.1007/s10851-006-8803-0; Darbon J., 2007, FAST DISCRETE OPTIMI; DAUBECHIES I, 2007, ACCELERATED PROJECTE; De Mol C., 2002, CONT MATH, V313, P85; DEVORE RA, 1992, ACTA NUMER, P54; DONG B, 2007, FAST LINEARIZED BREG; Donoho D. L., IEEE T INFORM UNPUB; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9452, DOI 10.1073/pnas.0502258102; Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005; ELAD M, 2007, P SPIE WAVELET 12; Elad M, 2006, IEEE T INFORM THEORY, V52, P5559, DOI 10.1109/TIT.2006.885522; FADILI MJ, 2006, P ASTR DAT AN ADA 06; Feuer A, 2003, IEEE T INFORM THEORY, V49, P1579, DOI 10.1109/TIT.2003.811926; FIGUEIREDO M, IEEE J SELE IN PRESS; Figueiredo M., 2005, P IEEE INT C IM PROC; Figueiredo MAT, 2007, IEEE T IMAGE PROCESS, V16, P2980, DOI 10.1109/TIP.2007.909318; FORNASIER M, 2006, RECOVERY ALGORITHMS; Gan L, 2007, P INT C DIG SIGN PRO; Gao HY, 1997, STAT SINICA, V7, P855; GOLDFARB D, 2007, TR0709 CAAM RIC U; GRIBONVAL R, 2007, ATOMS ALL CHANNELS U; Hale E., 2007, TR0707 CAAM RIC U, VTR07-07; Hale E., 2007, FPC FIXED POINT CONT; HALE E, IEEE T INFORM UNPUB; HALE ET, SIAM J OPTIM UNPUB; He L., 2006, 0635 UCLA CAM; Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, DOI 10.1007/BF00927673; Jung H, 2007, PHYS MED BIOL, V52, P3201, DOI 10.1088/0031-9155/52/11/018; KIM SJ, 2007, METHOD LARGE SCALE R; Kirolos S., 2006, P IEEE DALL CIRC SYS; KOH K, 2007, L1 LS SIMPLE MATLAB; Laska J., 2006, P IEEE DALL CIRC SYS; Laska J., 2007, P IEEE INT S CIRC SY; LUSTIG M, 2007, APPL COMPRESSED SENS; LUSTIG M, 2006, P 14 ANN M INT SOC M; Nesterov Y., 2007, 200776 CORE; NOWAK R, 2001, P 35 AS C SIGN SYST; Powell M., 1972, OPTIMIZATION, P283; Rabbat M., 2006, P INT C INF PROC SEN; RAGHEB T, 2007, P MIDW S CIRC SYST M; REEVES TH, 2002, P 2002 INT C IM PROC, V3, P24; Rockafellar R. T., 1973, MATH PROGRAM, V5, P354, DOI 10.1007/BF01580138; Selesnick I., 2004, P 2004 INT C IM PROC, V3, P1819; SHEIKH M, 2007, 0706 TREE RIC U RIC; TAKHAR D, 2006, P COMP IM 4 SPIE S E; Tropp J., 2006, P IEEE INT C AC SPEE; Van den Berg E., 2007, SPGL1 SOLVER SPARSE; VANDENBERG E, 2007, TR200716 UBC COMP SC; Wakin M., 2006, P PICT COD S PCS BEI; Wakin M. B., 2006, P IEEE INT C IM PROC; Wang W., 2007, P INT C INF PROC SEN; WANG Y, 2007, FAST FIXED POINT ALG; Xu JJ, 2007, IEEE T IMAGE PROCESS, V16, P534, DOI 10.1109/TIP.2006.888335; Ye JC, 2007, IEEE SIGNAL PROC LET, V14, P750, DOI 10.1109/LSP.2007.898342; Yin W, 2007, MULTISCALE MODEL SIM, V6, P190, DOI 10.1137/060663027; Yin WT, 2007, J VIS COMMUN IMAGE R, V18, P240, DOI 10.1016/j.jvcir.2007.01.004; Yin WT, 2005, BIOINFORMATICS, V21, P2410, DOI 10.1093/bioinformatics/bti341; Zhang Y., 2006, TR0615 CAAM RIC U; Zhang Y., 2005, TR0509 CAAM RIC U; Ziemer W.P., 1989, GRAD TEXTS MATH	101	435	480	0	42	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	1936-4954			SIAM J IMAGING SCI	SIAM J. Imaging Sci.		2008	1	1					143	168		10.1137/070703983		26	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Mathematics, Applied; Imaging Science & Photographic Technology	Computer Science; Mathematics; Imaging Science & Photographic Technology	V11YQ	WOS:000207567300006		
J	D'Aspremont, A; Banerjee, O; El Ghaoui, L				D'Aspremont, Alexandre; Banerjee, Onureena; El Ghaoui, Laurent			First-order methods for sparse covariance selection	SIAM JOURNAL ON MATRIX ANALYSIS AND APPLICATIONS			English	Article						covariance selection; semidefinite programming; coordinate descent	GRAPHICAL MODELS; MINIMIZATION	Given a sample covariance matrix, we solve a maximum likelihood problem penalized by the number of nonzero coefficients in the inverse covariance matrix. Our objective is to find a sparse representation of the sample data and to highlight conditional independence relationships between the sample variables. We first formulate a convex relaxation of this combinatorial problem, we then detail two efficient first-order algorithms with low memory requirements to solve large-scale, dense problem instances.	[D'Aspremont, Alexandre] Princeton Univ, ORFE Dept, Princeton, NJ 08544 USA; [Banerjee, Onureena; El Ghaoui, Laurent] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA	D'Aspremont, A (reprint author), Princeton Univ, ORFE Dept, Princeton, NJ 08544 USA.	aspremon@princeton.edu; onureena@eecs.berkeley.edu; elghaoui@eecs.berkeley.edu					AKAIKE J, 1973, 2 INT S INF THEOR AK, P267; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Bilmes JA, 2000, INT CONF ACOUST SPEE, P1009; BILMES JA, 1999, THESIS UC BERKELEY B; DAHL J, 2005, MAXIMUM LIKELIHOOD E; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; Dobra A., 2004, BAYESIAN COVARIANCE; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9446, DOI 10.1073/pnas.0502269102; Fazel M., 2001, P AM CONTR C, V6, P4734, DOI 10.1109/ACC.2001.945730; HUANG JZ, 2007, BIOMETRIKA, V93, P85; Jones B, 2005, STAT SCI, V20, P388, DOI 10.1214/088342305000000304; Lemarechal C, 1997, SIAM J OPTIMIZ, V7, P367; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; Nesterov Y., 1983, SOV MATH DOKL, V27, P372; NESTEROV Y, 2003, INTROD LECT CONVEX O; Vandenberghe L., 2004, CONVEX OPTIMIZATION	19	75	76	2	7	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	0895-4798			SIAM J MATRIX ANAL A	SIAM J. Matrix Anal. Appl.		2008	30	1					56	66		10.1137/060670985		11	Mathematics, Applied	Mathematics	295UV	WOS:000255500300004		
J	Kim, H; Park, H				Kim, Hyunsoo; Park, Haesun			NONNEGATIVE MATRIX FACTORIZATION BASED ON ALTERNATING NONNEGATIVITY CONSTRAINED LEAST SQUARES AND ACTIVE SET METHOD	SIAM JOURNAL ON MATRIX ANALYSIS AND APPLICATIONS			English	Article						nonnegative matrix factorization; lower rank approximation; two-block coordinate descent method; Karush-Kuhn-Tucker (KKT) conditions; nonnegativity constrained least squares; active set method	CANCER CLASS DISCOVERY; GENE-EXPRESSION; PREDICTION; ALGORITHMS; PARTS	Nonnegative matrix factorization (NMF) determines a lower rank approximation of a matrix A is an element of R(mxn) approximate to WH where an integer k << min(m, n) is given and nonnegativity is imposed on all components of the factors W is an element of R(mxk) and H is an element of R(kxn). NMF has attracted much attention for over a decade and has been successfully applied to numerous data analysis problems. In applications where the components of the data are necessarily nonnegative, such as chemical concentrations in experimental results or pixels in digital images, NMF provides a more relevant interpretation of the results since it gives nonsubtractive combinations of nonnegative basis vectors. In this paper, we introduce an algorithm for NMF based on alternating nonnegativity constrained least squares (NMF/ANLS) and the active set-based fast algorithm for nonnegativity constrained least squares with multiple right-hand side vectors, and we discuss its convergence properties and a rigorous convergence criterion based on the Karush-Kuhn-Tucker (KKT) conditions. In addition, we also describe algorithms for sparse NMFs and regularized NMF. We show how we impose a sparsity constraint on one of the factors by L(1)-norm minimization and discuss its convergence properties. Our algorithms are compared to other commonly used NMF algorithms in the literature on several test data sets in terms of their convergence behavior.	[Kim, Hyunsoo; Park, Haesun] Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Kim, H (reprint author), Georgia Inst Technol, Coll Comp, 266 Ferst Dr, Atlanta, GA 30332 USA.	hskim@cc.gatech.edu; hpark@cc.gatech.edu					Li SZ, 2001, PROC CVPR IEEE, P207; Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60; Bro R, 1997, J CHEMOMETR, V11, P393, DOI 10.1002/(SICI)1099-128X(199709/10)11:5<393::AID-CEM483>3.0.CO;2-L; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006; Lee DD, 1999, NATURE, V401, P788; Lee DD, 2001, ADV NEUR IN, V13, P556; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Pauca VP, 2006, LINEAR ALGEBRA APPL, V416, P29, DOI 10.1016/j.laa.2005.06.025; Gao Y, 2005, BIOINFORMATICS, V21, P3970, DOI 10.1093/bioinformatics/bti653; Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134; Grippo L, 2000, OPER RES LETT, V26, P127, DOI 10.1016/S0167-6377(99)00074-7; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Kim DM, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P343; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Bertsekas D., 1999, NONLINEAR PROGRAMMIN; Chu M., 2004, OPTIMALITY COMPUTATI; Ding Chris, 2006, P 12 ACM SIGKDD INT, P126, DOI 10.1145/1150402.1150420; Dueck D, 2005, BIOINFORMATICS S1, V21, P144, DOI DOI 10.1093/BIOINFORMATICS/BTL1041; Golub G., 1996, MATRIX COMPUTATIONS; Gonzales E. F., 2005, ACCELERATING LEE SEU; Hoyers PO., 2002, P IEEE WORKSH NEUR N, P557, DOI DOI 10.1109/NNSP.2002.1030067; Kim H, 2007, LECT N BIOINFORMAT, V4463, P477; KIM H, 2006, P IASTED INT C COMP, P95; Kim PM, 2003, GENOME RES, V13, P1706, DOI 10.1101/gr.903503; Lawson C. L., 1974, SOLVING LEAST SQUARE; Lin C. J., 2005, ISSTECH95013 NAT TAI; LIU W, 2003, EXISTING NEW ALGORIT; *MATHWORKS, 1992, MATLAB US GUID; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Park H., 2006, P WORKSH TEXT MIN 6; Pauca VP, 2004, SIAM PROC S, P452; PIPER J, 2004, P AM TECHN C; SRA S, 2006, 0627 U TEX; Van Benthem MH, 2004, J CHEMOMETR, V18, P441, DOI 10.1002/cem.889; ZDUNEK R, 2006, P 8 INT C ART INT SO, P870	37	93	100	4	12	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	0895-4798			SIAM J MATRIX ANAL A	SIAM J. Matrix Anal. Appl.		2008	30	2					713	730		10.1137/07069239X		18	Mathematics, Applied	Mathematics	358ZI	WOS:000259955600016		
J	Hale, ET; Yin, WT; Zhang, Y				Hale, Elaine T.; Yin, Wotao; Zhang, Yin			FIXED-POINT CONTINUATION FOR l(1)-MINIMIZATION: METHODOLOGY AND CONVERGENCE	SIAM JOURNAL ON OPTIMIZATION			English	Article						l(1) regularization; fixed-point algorithm; q-linear convergence; continuation; compressed sensing	ROBUST UNCERTAINTY PRINCIPLES; THRESHOLDING ALGORITHM; MONOTONE-OPERATORS; SPLITTING METHOD; RECONSTRUCTION; SHRINKAGE; SUM; DECONVOLUTION; MINIMIZATION; EIGENVALUES	We present a framework for solving the large-scale l(1)-regularized convex minimization problem: min parallel to x parallel to(1) + mu f(x). Our approach is based on two powerful algorithmic ideas: operator-splitting and continuation. Operator-splitting results in a fixed-point algorithm for any given scalar mu; continuation refers to approximately following the path traced by the optimal value of x as mu increases. In this paper, we study the structure of optimal solution sets, prove finite convergence for important quantities, and establish q-linear convergence rates for the fixed-point algorithm applied to problems with f(x) convex, but not necessarily strictly convex. The continuation framework, motivated by our convergence results, is demonstrated to facilitate the construction of practical algorithms.	[Hale, Elaine T.; Yin, Wotao; Zhang, Yin] Rice Univ, Dept Computat & Appl Math, Houston, TX 77005 USA	Hale, ET (reprint author), Rice Univ, Dept Computat & Appl Math, 6100 Main St,MS 134, Houston, TX 77005 USA.	ehale@rice.edu; wotao.yin@rice.edu; yzhang@rice.edu					Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; PANG JS, 1987, MATH OPER RES, V12, P474, DOI 10.1287/moor.12.3.474; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Rudelson M, 2005, INT MATH RES NOTICES, P4019; Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319; Candes EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; LUO ZQ, 1992, SIAM J CONTROL OPTIM, V30, P408, DOI 10.1137/0330025; Efron B, 2004, ANN STAT, V32, P407; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; Combettes PL, 2008, SIAM J OPTIMIZ, V18, P1351, DOI 10.1137/060669498; Baron D., 2005, DISTRIBUTED COMPRESS; Bect J., 2004, LECT NOTES COMPUTER, V3024, P1; BIOUCASDIAS J, 2007, IEEE INT C IM PROC C; Chen H.G., 1997, SIAM J OPTIMIZ, V7, P421; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; COMBETTES PL, 2005, SIAM J MULTISCALE MO, V4, P1168; DAUBECHIES I, 2007, ARXIV07064297; De Mol C., 2002, CONT MATH, V313, P85; DONOHO D, 2006, FAST SOLUTIONS L1 NO; Donoho D. L., 2006, 200602 STANF U DEP S; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9452, DOI 10.1073/pnas.0502258102; ECKSTEIN J., 1989, THESIS MIT CAMBRIDGE; EDELMAN A, 1988, SIAM J MATRIX ANAL A, V9, P543, DOI 10.1137/0609045; ELAD M, 2007, WIDE ANGLE VIEW ITER; Elad M, 2006, IEEE T INFORM THEORY, V52, P5559, DOI 10.1109/TIT.2006.885522; Elad M., 2006, J APPL COMPUT HARMON, V23, P346; FIGUEIREDO MA, 2007, GRADIENT PROJECTION; Gabay D., 1983, AUGMENTED LAGRANGIAN; Glowinski R., 1989, AUGMENTED LAGRANGIAN; HALE E, 2008, TR0824 RIC U; Haubruge S, 1998, J OPTIMIZ THEORY APP, V97, P645, DOI 10.1023/A:1022646327085; JONSSON D, 1982, J MULTIVARIATE ANAL, V12, P1, DOI 10.1016/0047-259X(82)90080-X; Kirolos S., 2006, P IEEE DALL CIRC SYS; Laska J., 2006, P IEEE DALL CIRC SYS; Laska J., 2007, P IEEE INT S CIRC SY; LEVY S, 1981, GEOPHYSICS, V46, P1235, DOI 10.1190/1.1441261; Malioutov D., 2005, P IEEE INT C AC SPEE, V5, P733, DOI 10.1109/ICASSP.2005.1416408; Mercier B., 1980, INEQUATIONS VARIATIO; Miller A, 2002, SUBSET SELECTION REG, V2nd; Nesterov Y., 2007, 200776 CORE; Noor MA, 2000, J MATH ANAL APPL, V246, P174, DOI 10.1006/jmaa.2000.6776; PASSTY GB, 1979, J MATH ANAL APPL, V72, P383, DOI 10.1016/0022-247X(79)90234-8; Rachford H., 1956, T AM MATH SOC, V82, P421, DOI DOI 10.1090/S0002-9947-1956-0084194-4; PEACEMAN DW, 1955, J SOC IND APPL MATH, V3, P28, DOI 10.1137/0103003; Rockafellar R.T., 1970, CONVEX ANAL; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; Takhar D., 2006, P COMP IM 4 SPIE EL; TAYLOR HL, 1979, GEOPHYSICS, V44, P39, DOI 10.1190/1.1440921; Tropp J., 2006, P IEEE INT C AC SPEE; TROPP JA, 2006, IEEE T INFORM THEORY, V51, P1030; TSAIG Y, 2005, SIGNAL PROCESS, V86, P533; Tseng P, 2000, SIAM J CONTROL OPTIM, V38, P431, DOI 10.1137/S0363012998338806; Turlach B. A., 2005, P AM STAT ASS STAT C, P2572; VANDENBERG E, 2007, PURSUIT ROOT; Wakin M., 2006, P PICT COD S PCS BEI; Wakin M. B., 2006, P INT C IM PROC ICIP; Zhang Y., 2006, TR0615 CAAM RIC U	67	233	253	0	9	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	1052-6234			SIAM J OPTIMIZ	SIAM J. Optim.		2008	19	3					1107	1130		10.1137/070698920		24	Mathematics, Applied	Mathematics	403TC	WOS:000263103900006		
J	van den Berg, E; Friedlander, MP				van den Berg, Ewout; Friedlander, Michael P.			PROBING THE PARETO FRONTIER FOR BASIS PURSUIT SOLUTIONS	SIAM JOURNAL ON SCIENTIFIC COMPUTING			English	Article						basis pursuit; convex program; duality; root-finding; Newton's method; projected gradient; one-norm regularization; sparse solutions	PROJECTED GRADIENT METHODS; SIGNAL RECOVERY; LEAST-SQUARES; CONVEX-SETS; RECONSTRUCTION; REGRESSION; SHRINKAGE; SELECTION; NOISE; LASSO	The basis pursuit problem seeks a minimum one-norm solution of an underdetermined least-squares problem. Basis pursuit denoise (BPDN) fits the least-squares problem only approximately, and a single parameter determines a curve that traces the optimal trade-off between the least-squares fit and the one-norm of the solution. We prove that this curve is convex and continuously differentiable over all points of interest, and show that it gives an explicit relationship to two other optimization problems closely related to BPDN. We describe a root-finding algorithm for finding arbitrary points on this curve; the algorithm is suitable for problems that are large scale and for those that are in the complex domain. At each iteration, a spectral gradient-projection method approximately minimizes a least-squares problem with an explicit one-norm constraint. Only matrix-vector operations are required. The primal-dual solution of this problem gives function and derivative information needed for the root-finding method. Numerical experiments on a comprehensive set of test problems demonstrate that the method scales well to large problems.	[van den Berg, Ewout; Friedlander, Michael P.] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada	van den Berg, E (reprint author), Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.	ewout@cs.ubc.ca; mpf@cs.ubc.ca			NSERC [334810-05]	This work was supported by NSERC Collaborative Research and Development Grant 334810-05.	Birgin EG, 2000, SIAM J OPTIMIZ, V10, P1196, DOI 10.1137/S1052623497330963; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728; Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Das I, 1997, STRUCT OPTIMIZATION, V14, P63, DOI 10.1007/BF01197559; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Dai YH, 2005, NUMER MATH, V100, P21, DOI 10.1007/s00211-004-0569-y; Efron B, 2004, ANN STAT, V32, P407; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; DEMBO RS, 1982, SIAM J NUMER ANAL, V19, P400, DOI 10.1137/0719025; BARZILAI J, 1988, IMA J NUMER ANAL, V8, P141, DOI 10.1093/imanum/8.1.141; Bertsekas D., 2003, CONVEX ANAL OPTIMIZA; Bertsekas D., 1999, NONLINEAR PROGRAMMIN; Birgin EG, 2003, IMA J NUMER ANAL, V23, P539, DOI 10.1093/imanum/23.4.539; Bjorck A., 1996, NUMERICAL METHODS LE; Candes E., L1 MAGIC; Chen S, 2001, RAPID COMMUN MASS SP, V15, P159, DOI 10.1002/1097-0231(20010130)15:2<159::AID-RCM210>3.0.CO;2-W; DAI Y, 2006, IMA J NUMER ANAL, V7, P604; DAUBECHIES I, 2007, J FOURIER A IN PRESS; Dax A, 1992, SIAM J OPTIMIZ, V2, P602, DOI 10.1137/0802029; Donoho D.L., FAST SOLUTION L1 NOR; FIGUEIREDO M, 2007, SELECTED TOPICS SIGN, P586; Friedlander MP, 2007, ANN STAT, V35, P2385, DOI 10.1214/00905360700000479; Hansen P., 1998, RANK DEFICIENT DISCR; HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086; Hennenfent G, 2008, GEOPHYSICS, V73, pV19, DOI 10.1190/1.2841038; HENNENFENT G, 2005, P SEG INT EXP 75 ANN; HERRMANN F, SLIMPY PYTHON INTERF; ILOG CPLEX, MATH PROGR SYST; LEYFFER S, 2005, ANLMCSP12900905 MATH; *MATHWORKS, 1992, MATLAB US GUID; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Rockafellar R.T., 1970, CONVEX ANAL; SAUNDERS MA, MATLAB SOFTWARE CONV; Sturm J. F., 1998, MATLAB TOOLBOX OPTIM; Tikhonov AN, 1977, SOLUTIONS ILL POSED; VANDENBERG E, ACM T MATH IN PRESS; Vandenberghe L., 2004, CONVEX OPTIMIZATION; MATH PROGRAMMING SYS	48	389	390	4	28	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	1064-8275			SIAM J SCI COMPUT	SIAM J. Sci. Comput.		2008	31	2					890	912		10.1137/080714488		23	Mathematics, Applied	Mathematics	421JD	WOS:000264354300005		
J	Zou, H; Yuan, M				Zou, Hui; Yuan, Ming			The F-infinity-norm support vector machine	STATISTICA SINICA			English	Article						F-infinity penalty; factor selection; feature selection; linear programming; L-infinity penalty; support vector machine	SELECTION; CLASSIFICATION; REGRESSION	In this paper we propose a new support vector machine (SVM), the F-infinity-norm SVM, to perform automatic factor selection in classification. The F.-norm SVM methodology is motivated by the feature selection problem in cases where the input features are generated by factors, and the model is best interpreted in terms of significant factors. This type of problem arises naturally when a set of dummy variables is used to represent a categorical factor and/or a set of basis functions of a continuous variable is included in the predictor set. In problems without such obvious group information, we propose to first create groups among features by clustering, and then apply the F-infinity-norm SVM. We show that the F-infinity-norm SVM is equivalent to a linear programming problem and can be efficiently solved using standard techniques. Analysis on simulated and real data shows that the F-infinity-norm SVM enjoys competitive performance when compared with the I-norm and 2-norm SVMs.	[Zou, Hui] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA; [Yuan, Ming] Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA	Zou, H (reprint author), Univ Minnesota, Sch Stat, 313 Ford Hall,224 Church St SE, Minneapolis, MN 55455 USA.	hzou@stat.umn.edu; myuan@isye.gatech.edu					Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Friedman J, 2004, ANN STAT, V32, P102; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; Bradley P., 1998, INT C MACH LEARN MOR; Canu S, 2003, ADV NEURAL INFORM PR, V15; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODELS; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; NEWTON DJ, 1998, UCI REPOSITORY MACHI; ROSSET S, 2003, ADV NEURAL INFORM PR, V16; SCHOLKOPF B, 2002, LEARNING KERLNELS SU; Song M., 2002, J CHEM INFORM COMPUT; TURLACH B, 2004, SIMULTANEOUS VARIABL; Vapnik V.N., 1995, NATURE STAT LEARNING; Wahba G, 2000, ADV NEUR IN, P297; Weston J, 2001, ADV NEURAL INFORM PR, V13; Zhang HP, 2003, J AM STAT ASSOC, V98, P369, DOI 10.1198/016214503000152; Zhu J., 2004, ADV NEURAL INFORM PR, V16	21	29	30	0	3	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405			STAT SINICA	Stat. Sin.	JAN	2008	18	1					379	398				20	Statistics & Probability	Mathematics	261RW	WOS:000253098700032		
J	Le Cao, KA; Rossouw, D; Robert-Granie, C; Besse, P				Le Cao, Kim-Anh; Rossouw, Debra; Robert-Granie, Christele; Besse, Philippe			A Sparse PLS for Variable Selection when Integrating Omics Data	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						joint analysis; two-block data set; multivariate regression; dimension reduction	LEAST-SQUARES REGRESSION; CO-INERTIA ANALYSIS; GENE EXPRESSIONS; SHRINKAGE; TRANSCRIPT; METABOLITE	Recent biotechnology advances allow for multiple types of omics data, such as transcriptomic, proteomic or metabolomic data sets to be integrated. The problem of feature selection has been addressed several times in the context of classification, but needs to be handled in a specific manner when integrating data. In this study, we focus on the integration of two-block data that are measured on the same samples. Our goal is to combine integration and simultaneous variable selection of the two data sets in a one-step procedure using a Partial Least Squares regression (PLS) variant to facilitate the biologists' interpretation. A novel computational methodology called "sparse PLS" is introduced for a predictive analysis to deal with these newly arisen problems. The sparsity of our approach is achieved with a Lasso penalization of the PLS loading vectors when computing the Singular Value Decomposition. Sparse PLS is shown to be effective and biologically meaningful. Comparisons with classical PLS are performed on a simulated data set and on real data sets. On one data set, a thorough biological interpretation of the obtained results is provided. We show that sparse PLS provides a valuable variable selection tool for highly dimensional data sets.	[Rossouw, Debra] Univ Stellenbosch, ZA-7600 Stellenbosch, South Africa; [Le Cao, Kim-Anh] Univ Toulouse, Toulouse, France	Le Cao, KA (reprint author), Univ Toulouse, Toulouse, France.	k.lecao@imb.uq.edu.au; debra@sun.ac.za; christele.robert-granie@toulouse.inra.fr; philippe.besse@math.univ-toulouse.fr	Rohlf, F/A-8710-2008; Le Cao, Kim-Anh/B-6637-2013	Le Cao, Kim-Anh/0000-0003-3923-1116			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Shen HP, 2008, J MULTIVARIATE ANAL, V99, P1015, DOI 10.1016/j.jmva.2007.06.007; Heinloth AN, 2004, TOXICOL SCI, V80, P193, DOI 10.1093/toxsci/kfh145; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Mevik BH, 2007, J STAT SOFTW, V18, P1; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Dickinson JR, 2003, J BIOL CHEM, V278, P8028, DOI 10.1074/jbc.M211914200; BELY M, 1990, AM J ENOL VITICULT, V41, P319; Boulesteix A.L., 2004, STAT APPL GENET MOL, V3, P1075; Boulesteix AL, 2005, THEOR BIOL MED MODEL, V2, DOI 10.1186/1742-4682-2-23; Burnham AJ, 1996, J CHEMOMETR, V10, P31, DOI 10.1002/(SICI)1099-128X(199601)10:1<31::AID-CEM398>3.0.CO;2-1; Bushel P, 2007, BMC SYSTEMS BIOL, P1; Bylesjo M, 2007, PLANT J, V52, P1181, DOI 10.1111/j.1365-313X.2007.03293.x; CADIMA J, 1995, J APPL STAT, V22, P203, DOI 10.1080/757584614; CHUN H, 2007, SPARSE PARTIAL LEAST; Culhane AC, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-59; Datta S, 2001, GENE EXPRESSION, V9, P249; DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X; DEJONG S, 1994, J CHEMOMETR, V8, P169, DOI 10.1002/cem.1180080208; DOLEDEC S, 1994, FRESHWATER BIOL, V31, P277, DOI 10.1111/j.1365-2427.1994.tb01741.x; Dray S, 2003, T GIS, V7, P411, DOI 10.1111/1467-9671.00153; Gibon Y, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-8-r76; Gidskehaug L, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-346; Hoskuldsson A, 1988, J CHEMOMETR, V2, P211, DOI DOI 10.1002/CEM.1180020306; Kramer N, 2007, COMPUTATION STAT, V22, P249, DOI 10.1007/s00180-007-0038-z; LECAO, 2007, STAT APPL GENET MOL, V6; LORBER A, 1987, J CHEMOMETR, V1, P13; Mewes HW, 2000, NUCLEIC ACIDS RES, V28, P37, DOI 10.1093/nar/28.1.37; NYKANEN L, 1977, J I BREWING, V83, P30; PIHUR V, 2008, BIOINFORMATICS; Ribereau-Gayon P, 2000, HDB ENOLOGY; Tenenhaus M., 1998, REGRESSION PLS THEOR; Thioulouse J, 1997, STAT COMPUT, V7, P75, DOI 10.1023/A:1018513530268; Trendafilov NT, 2006, COMPUT STAT DATA AN, V50, P242, DOI 10.1016/j.csda.2004.07.017; Trygg J, 2003, J CHEMOMETR, V17, P53, DOI 10.1002/cem.775; UMETRI AB, 1996, SIMCA P WINDOWS GRAP; Waaijenborg S, 2008, STAT APPL GENET MOL, V7; Wegelin J., 2000, 371 U WASH DEP STAT; Weng S, 2003, NUCLEIC ACIDS RES, V31, P216, DOI 10.1093/nar/gkg054; Wold H., 1966, MULTIVARIATE ANAL; Wold S., 2004, PLS METHOD PARTIAL L	43	48	49	4	32	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-6302			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2008	7	1							35			32	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	378OW	WOS:000261334800001		
J	Strimenopoulou, F; Brown, PJ				Strimenopoulou, Foteini; Brown, Philip J.			Empirical Bayes logistic regression	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article							VARIABLE SELECTION; REGULARIZATION; CLASSIFICATION; MODELS	We construct a diagnostic predictor for patient disease status based on a single data set of mass spectra of serum samples together with the binary case-control response. The model is logistic regression with Bernoulli log-likelihood augmented either by quadratic ridge or absolute L1 penalties. For ridge penalization using the singular value decomposition we reduce the number of variables for maximization to the rank of the design matrix. With log-likelihood loss, 10-fold cross-validatory choice is employed to specify the penalization hyperparameter. Predictive ability is judged on a set-aside subset of the data.	[Strimenopoulou, Foteini; Brown, Philip J.] Univ Kent, Canterbury CT2 7NZ, Kent, England	Strimenopoulou, F (reprint author), Univ Kent, Canterbury CT2 7NZ, Kent, England.	fs54@kent.ac.uk; Philip.J.Brown@kent.ac.uk					Hastie T, 2004, BIOSTATISTICS, V5, P329, DOI 10.1093/biostatistics/kxh010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Holmes CC, 2006, BAYESIAN ANAL, V1, P145; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Brown P. J., 1993, MEASUREMENT REGRESSI; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; DAWID AP, 1976, BIOMETRICS, V32, P647, DOI 10.2307/2529753; EFRON B, 1975, J AM STAT ASSOC, V70, P892, DOI 10.2307/2285453; FEARN T, 1999, REV R ACAD CIENC EXA, V93, P337; Harrell Jr. FE, 2007, DESIGN PACKAGE R VER; Morris JS, 2006, BAYESIAN INFERENCE FOR GENE EXPRESSION AND PROTEOMICS, P269; MORRIS JS, 2008, BIOMETRICS; PARK MY, 2007, GLMPATH PACKAGE R VE; R Development Core Team, 2007, R LANG ENV STAT COMP; Sha N, 2003, COMP FUNCT GENOM, V4, P171, DOI 10.1002/cfg.264; Sha NJ, 2004, BIOMETRICS, V60, P812, DOI 10.1111/j.0006-341X.2004.00233.x; Vannucci M, 2005, CHEMOMETR INTELL LAB, V77, P139, DOI 10.1016/j.chemolab.2004.10.009	18	5	5	0	1	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2008	7	2							9			16	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	282LA	WOS:000254568100006		
J	Waaijenborg, S; Hamer, PCVDW; Zwinderman, AH				Waaijenborg, Sandra; Hamer, Philip C. Verselewel De Witt; Zwinderman, Aeilko H.			Quantifying the association between gene expressions and DNA-Markers by penalized canonical correlation analysis	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						canonical correlation analysis; co-regulated networks; elastic net	SELECTION	Multiple changes at the DNA level are at the basis of complex diseases. Identifying the genetic networks that are influenced by these changes might help in understanding the development of these diseases. Canonical correlation analysis is used to associate gene expressions with DNA-markers and thus reveals sets of co-expressed and co-regulated genes and their associating DNA-markers. However, when the number of variables gets high, e.g. in the case of microarray studies, interpretation of these results can be difficult. By adapting the elastic net to canonical correlation analysis the number of variables reduces, and interpretation becomes easier, moreover, due to the grouping effect of the elastic net co-regulated and co-expressed genes cluster. Additionally, our adaptation works well in situations where the number of variables exceeds by far the number of subjects.	[Waaijenborg, Sandra; Hamer, Philip C. Verselewel De Witt; Zwinderman, Aeilko H.] Univ Amsterdam, Acad Med Ctr, NL-1105 AZ Amsterdam, Netherlands	Waaijenborg, S (reprint author), Univ Amsterdam, Acad Med Ctr, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.	s.waaijenborg@amc.uva.nl; p.c.dewitthamer@amc.uva.nl; a.h.zwinderman@amc.uva.nl					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zhao XJ, 2004, CANCER RES, V64, P3060, DOI 10.1158/0008-5472.CAN-03-3308; Bredel M, 2005, CANCER RES, V65, P8679, DOI 10.1158/0008-5472; Bredel M, 2005, CANCER RES, V65, P4088, DOI 10.1158/0008-5472.CAN-04-4229; Hoerl A.E, 1962, CHEM ENG PROGR, V58, P54; HUANG SY, 2006, UNPUB KERNEL CANONIC; Johnson R. A., 2002, APPL MULTIVARIATE ST; Vinod H. D., 1976, J ECONOMETRICS, V4, P147, DOI 10.1016/0304-4076(76)90010-5; Wegelin J. A., 2000, SURVEY PARTIAL LEAST; WOLD H, 1975, PATH MODELS LATENT V, P307; Yamanishi Y, 2003, BIOINFORMATICS, V19, pi323, DOI 10.1093/bioinformatics/btg1045; Yin D, 2005, NEUROL RES, V27, P27, DOI 10.1179/016164105X18151; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	15	41	41	0	4	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2008	7	1							3			29	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	258HG	WOS:000252858400003		
J	Zeng, LM; Wu, J; Xie, J				Zeng, Lingmin; Wu, Jing; Xie, Jun			Statistical Methods in Integrative Analysis for Gene Regulatory Modules	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						gene regulation; regression analysis; sequence analysis	MICROARRAY DATA; YEAST; DNA; GENOME; REGRESSION; DISCOVERY; MOTIF; MODEL	We propose a suite of statistical methods for inferring a cis-regulatory module, which is a combination of several transcription factors binding in the promoter regions to regulate gene expression. The approach is an integrative analysis that combines information from multiple types of biological data, including genomic DNA sequences, genome-wide location analysis (ChIP-chip experiments), and gene expression microarray. More specifically, we use a hidden Markov model to first predict a cluster of transcription factor binding sites in DNA sequences. The predictions are refined by regression analysis on gene expression microarray data and/or ChIP-chip binding experiments. In regression analysis, we particularly apply factor analysis, whose statistical model characterizes the modular structure of cis-regulation. When groups of coexpressed genes are available, we further apply canonical correlation analysis to infer relationships between a group of genes and their common set of transcription factors. Our approach is validated on the well-studied yeast cell cycle gene regulation. It is then used to study condition-specific regulators for a set of Ste12 target genes. The multiple data sources provide information of transcriptional regulation from different aspects. Therefore, the integrative analysis offers a fine prediction on transcriptional regulatory code and infers potential regulatory networks.	[Zeng, Lingmin; Wu, Jing; Xie, Jun] Purdue Univ, W Lafayette, IN 47907 USA	Xie, J (reprint author), Purdue Univ, W Lafayette, IN 47907 USA.	lzeng@stat.purdue.edu; jingwu@stat.purdue.edu; junxie@stat.purdue.edu			National Science Foundation [DMS-604776]	This work is supported by National Science Foundation Grant DMS-604776.	Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Ren B, 2000, SCIENCE, V290, P2306, DOI 10.1126/science.290.5500.2306; Gasch AP, 2000, MOL BIOL CELL, V11, P4241; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Chu S, 1998, SCIENCE, V282, P699, DOI 10.1126/science.282.5389.699; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; Tanay A, 2004, P NATL ACAD SCI USA, V101, P2981, DOI 10.1073/pnas.0308661100; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Efron B, 2004, ANN STAT, V32, P407; Harbison CT, 2004, NATURE, V431, P99, DOI 10.1038/nature02800; Bailey TL, 2003, BIOINFORMATICS S2, V19, pii16; BARJOSEPH Z, 2003, NAT BIOTECHNOL, DOI DOI 10.1038/NBT890; Crowley EM, 1997, J MOL BIOL, V268, P8, DOI 10.1006/jmbi.1997.0965; DiIorio F.C., 1991, SAS APPL PROGRAMMING; Frith MC, 2001, BIOINFORMATICS, V17, P878, DOI 10.1093/bioinformatics/17.10.878; Jennrich RI, 1995, INTRO COMPUTATIONAL; Lemmens K, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-5-r37; ODOM DT, 2006, MOL SYSTEMS BIOL, DOI UNSP 4100059-E1-4100059-E5; Rajewsky N, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-30; Simon I, 2001, CELL, V106, P697, DOI 10.1016/S0092-8674(01)00494-9; SINHA S, 2003, BIOINFORMATICS S1, V19, P292; Wingender E, 2000, NUCLEIC ACIDS RES, V28, P316, DOI 10.1093/nar/28.1.316; Wu J, 2008, J COMPUT BIOL, V15, P279, DOI 10.1089/cmb.2008.0024; Xie J, 2003, STRUCT EQU MODELING, V10, P566, DOI 10.1207/S15328007SEM1004_5; Yamanishi Y, 2003, BIOINFORMATICS, V19, pi323, DOI 10.1093/bioinformatics/btg1045	27	1	1	0	1	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2008	7	1							28			23	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	367MB	WOS:000260555000002		
J	Zucknick, M; Richardson, S; Stronach, EA				Zucknick, Manuela; Richardson, Sylvia; Stronach, Euan A.			Comparing the characteristics of gene expression profiles derived by univariate and multivariate classification methods	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						microarrays; molecular signature; classification; multivariate analysis; penalised likelihood	MICROARRAY DATA; BREAST-CANCER; CLASS PREDICTION; OVARIAN-CANCER; SELECTION; REGRESSION; SIGNATURES; DISCOVERY; BEHAVIOR	One application of gene expression arrays is to derive molecular profiles, i.e., sets of genes, which discriminate well between two classes of samples, for example between tumour types. Users are confronted with a multitude of classification methods of varying complexity that can be applied to this task. To help decide which method to use in a given situation, we compare important characteristics of a range of classification methods, including simple univariate filtering, penalised likelihood methods and the random forest. Classification accuracy is an important characteristic, but the biological interpretability of molecular profiles is also important. This implies both parsimony and stability, in the sense that profiles should not vary much when there are slight changes in the training data. We perform a random resampling study to compare these characteristics between the methods and across a range of profile sizes. We measure stability by adopting the Jaccard index to assess the similarity of resampled molecular profiles. We carry out a case study on five well-established cancer microarray data sets, for two of which we have the benefit of being able to validate the results in an independent data set. The study shows that those methods which produce parsimonious profiles generally result in better prediction accuracy than methods which don't include variable selection. For very small profile sizes, the sparse penalised likelihood methods tend to result in more stable profiles than univariate filtering while maintaining similar predictive performance.	[Zucknick, Manuela] German Canc Res Ctr, Heidelberg, Germany; [Richardson, Sylvia; Stronach, Euan A.] Univ London Imperial Coll Sci Technol & Med, London SW7 2AZ, England	Zucknick, M (reprint author), German Canc Res Ctr, Heidelberg, Germany.	manuela.zucknick03@imperial.ac.uk; sylvia.richardson@imperial.ac.uk; e.stronach@imperial.ac.uk	Richardson, Sylvia/G-4691-2015	Richardson, Sylvia/0000-0003-1998-492X			Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Simon R, 2003, J NATL CANCER I, V95, P14; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Roepman P, 2006, CANCER RES, V66, P2361, DOI 10.1158/0008-5472.CAN-05-3960; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Ein-Dor L, 2005, BIOINFORMATICS, V21, P171, DOI 10.1093/bioinformatics/bth469; Blangiardo M, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-4-r54; BOVELSTAD HM, 2007, BIOINFORMATICS, V23, P2088; Davis CA, 2006, BIOINFORMATICS, V22, P2356, DOI 10.1093/bioinformatics/btl400; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; DUPUY A, 2007, JNCI-J NATL CANCER I, V99; HAZEL JE, 1970, GEOL SOC AM BULL, V81, P3237, DOI 10.1130/0016-7606(1970)81[3237:BCACIB]2.0.CO;2; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Jaccard P., 1901, B SOC VAUD SCI NAT, V37, P547; JANSON S, 1981, OECOLOGIA, V49, P371, DOI 10.1007/BF00347601; Lai C, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-235; Lu KH, 2004, CLIN CANCER RES, V10, P3291, DOI 10.1158/1078-0432.CCR-03-0409; Ma SG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-253; OCHIAI AKIRA, 1957, BULL JAPANESE SOC SCI FISH, V22, P526; R Development Core Team, 2006, R LANG ENV STAT COMP; Schwartz DR, 2002, CANCER RES, V62, P4722; Sepkoski Jr E., 1974, MATH GEOL, V6, P135; Simon R, 2006, J NATL CANCER I, V98, P1169, DOI 10.1093/jnci/djj364; SIMPSON GG, 1960, AM J SCI, V258, P300; Sokal R., 1973, NUMERICAL TAXONOMY P; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; VALK PJ, 2004, NEW ENGL J MED, V350, P617; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a	37	21	21	1	4	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-6302	1544-6115		STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2008	7	1							7	10.2202/1544-6115.1307		34	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	282KY	WOS:000254567900004		
J	Shi, WL; Wahba, G; Wright, S; Lee, K; Klein, R; Klein, B				Shi, Weiliang; Wahba, Grace; Wright, Stephen; Lee, Kristine; Klein, Ronald; Klein, Barbara			LASSO-Patternsearch algorithm with application to ophthalmology and genomic data	STATISTICS AND ITS INTERFACE			English	Article							GENERALIZED CROSS-VALIDATION; BEAVER DAM EYE; SMOOTHING SPLINE ANOVA; VARIABLE SELECTION; BERNOULLI OBSERVATIONS; LOGISTIC-REGRESSION; ADULT-POPULATION; BASIS PURSUIT; MODEL; DECOMPOSITION	The LASSO-Patternsearch algorithm is proposed to efficiently identify patterns of multiple dichotomous risk factors for outcomes of interest in demographic and genomic studies. The patterns considered are those that arise naturally from the log linear expansion of the multivariate Bernoulli density. The method is designed for the case where there is a possibly very large number of candidate patterns but it is believed that only a relatively small number are important. A LASSO is used to greatly reduce the number of candidate patterns, using a novel computational algorithm that can handle an extremely large number of unknowns simultaneously. The patterns surviving the LASSO are further pruned in the framework of (parametric) generalized linear models. A novel tuning procedure based on the GACV for Bernoulli outcomes, modified to act as a model selector, is used at both steps. We applied the method to myopia data from the population-based Beaver Dam Eye Study, exposing physiologically interesting interacting risk factors. We then applied the the method to data from a generative model of Rheumatoid Arthritis based on Problem 3 from the Genetic Analysis Workshop 15, successfully demonstrating its potential to efficiently recover higher order patterns from attribute vectors of length typical of genomic studies.	[Shi, Weiliang; Wahba, Grace] Univ Wisconsin, Dept Stat, Dept Comp Sci, Madison, WI 53706 USA; [Wahba, Grace] Univ Wisconsin, Dept Biostat & Med Informat, Madison, WI 53706 USA; [Lee, Kristine; Klein, Ronald; Klein, Barbara] Univ Wisconsin, Dept Ophthalmol & Visual Sci, Madison, WI 53706 USA	Shi, WL (reprint author), Univ Wisconsin, Dept Stat, Dept Comp Sci, 1300 Univ Ave, Madison, WI 53706 USA.	shiw@stat.wisc.edu; wahba@stat.wisc.edu; swright@cs.wisc.edu; klee@epi.ophth.wisc.edu; kleinr@epi.ophth.wisc.edu; kleinb@epi.ophth.wisc.edu			NIH [EY09946, EY06594, EY015286]; NSF [DMS-0505636, DMS-0604572, SCI-0330538, DMS0427689, CCF-0430504, CTS-0456694, CNS-0540147]; ONR [N0014-06-0095]; DOE [DE-FG02-04ER25627]; Research to Prevent Blindness	Research supported in part by NIH Grant EY09946, NSF Grants DMS-0505636, DMS-0604572 and ONR Grant N0014-06-0095.Corresponding Author. Research supported in part by NIH Grant EY09946, NSF Grants DMS-0505636, DMS-0604572 and ONR Grant N0014-06-0095.Research supported in part by NSF Grants SCI-0330538, DMS0427689, CCF-0430504, CTS-0456694, CNS-0540147 and DOE Grant DE-FG02-04ER25627.Research supported in part by NIH grants EY06594 and EY015286.Research support in part by NIH grants EY06594, EY015286 andResearch to Prevent Blindness Senior Investigator Awards.	Park MY, 2008, BIOSTATISTICS, V9, P30, DOI 10.1093/biostatistics/kxm010; Knight K, 2000, ANN STAT, V28, P1356; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; KLEIN R, 1991, OPHTHALMOLOGY, V98, P1310; Lee KE, 2002, INVEST OPHTH VIS SCI, V43, P2566; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; WAHBA G, 1975, COMMUN STAT, V4, P1; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Efron B, 2004, ANN STAT, V32, P407; LI KC, 1986, ANN STAT, V14, P1101, DOI 10.1214/aos/1176350052; CRAVEN P, 1979, NUMER MATH, V31, P377; Breiman L., 1984, CLASSIFICATION REGRE; Chan KY, 2004, J COMPUT GRAPH STAT, V13, P826, DOI 10.1198/106186004X13064; CORDELL H, 2007, BMC P S1, V1, P1; Galan P, 2005, EUR J CLIN NUTR, V59, P1181, DOI 10.1038/sj.ejcn.1602230; Gao FY, 2001, J AM STAT ASSOC, V96, P127, DOI 10.1198/016214501750332749; Gunn SR, 2002, MACH LEARN, V48, P137, DOI 10.1023/A:1013903804720; HAUGHTON DMA, 1988, ANN STAT, V16, P342, DOI 10.1214/aos/1176350709; HUDSON ME, 1978, ANN STAT, V6, P473; Lee KE, 1999, INVEST OPHTH VIS SCI, V40, P1645; Lee Y, 2006, BIOMETRIKA, V93, P555, DOI 10.1093/biomet/93.3.555; Leng CL, 2006, STAT SINICA, V16, P1273; Lin X., 1998, 1003 U WISC DEP STAT; Lin XW, 2000, ANN STAT, V28, P1570; MILLER M, 2007, BMC P S1, V1, P1; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; SCHWARTZ D, 2007, BMC P S1, V1, P1; Seet B, 2001, BRIT J OPHTHALMOL, V85, P521, DOI 10.1136/bjo.85.5.521; Shi W., 2006, 1131 U WISC DEP STAT; SHI W, 2007, BMC P S1, V1, P1; Thomson W, 2007, NAT GENET, V39, P1431, DOI 10.1038/ng.2007.32; Wahba G, 2002, P NATL ACAD SCI USA, V99, P16524, DOI 10.1073/pnas.242574899; Whittaker J, 1990, GRAPHICAL MODELS APP; Wong WH, 2006, FRONTIERS IN STATISTICS: DEDICATED TO PETER JOHN BICKEL IN HONOR OF HIS 65TH BIRTHDAY, P491, DOI 10.1142/9781860948886_0022; Xiang D, 1996, STAT SINICA, V6, P675; Zhang HH, 2004, J AM STAT ASSOC, V99, P659, DOI 10.1198/016214504000000593; Zhang HH, 2006, STAT SINICA, V16, P1021	40	13	13	0	2	INT PRESS BOSTON, INC	SOMERVILLE	PO BOX 43502, SOMERVILLE, MA 02143 USA	1938-7989			STAT INTERFACE	Stat. Interface		2008	1	1					137	153				17	Mathematical & Computational Biology; Mathematics, Interdisciplinary Applications	Mathematical & Computational Biology; Mathematics	V13GG	WOS:000207654700013		
S	Das, A; Kempe, D			ACM	Das, Abhimanyu; Kempe, David			Algorithms for Subset Selection in Linear Regression	STOC'08: PROCEEDINGS OF THE 2008 ACM INTERNATIONAL SYMPOSIUM ON THEORY OF COMPUTING	Annual ACM Symposium on Theory of Computing		English	Proceedings Paper	14th Annual ACM International Symposium on Theory of Computing	MAY 17-20, 2008	Victoria, CANADA	ACM SIGACT		Algorithms; Theory	POLYNOMIAL-TIME; VARIABLES; NOISE; APPROXIMATION; RECOVERY	We study the problem of selecting a subset of k random variables to observe that will yield the best linear prediction of another variable of interest, given the pairwise correlations between the observation variables and the predictor variable. Under approximation preserving reductions, this problem is also equivalent to the "sparse approximation" problem of approximating signals concisely. We propose and analyze exact and approximation algorithms for several special cases of practical interest. We give an FPTAS when the covariance matrix has constant bandwidth, and exact algorithms when the associated covariance graph, consisting of edges for pairs of variables with nor)zero correlation, forms a tree or has a large (known) independent set. Furthermore, we give all exact algorithm when the variables can be embedded into a line such that the covariance decreases exponentially in the distance, and a constant-factor approximation when the variables have no "conditional suppressor variables". Much of our reasoning is based on perturbation results for the R-2 multiple correlation measure, frequently used as a measure for "goodness-of-fit statistics". It lies at the core of our FPTAS, and also allows us to extend exact algorithms to approximation algorithms when the matrix "nearly" falls into one of the above classes. We also use perturbation analysis to prove approximation guarantees For the widely used "Forward Regression" heuristic when the observation variables are nearly independent.	[Das, Abhimanyu; Kempe, David] Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA	Das, A (reprint author), Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.	abhimand@usc.edu; dkempe@usc.edu					Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971; Anstreicher KM, 2001, DISCRETE APPL MATH, V108, P211, DOI 10.1016/S0166-218X(00)00217-1; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; CORNUEJOLS G, 1977, MANAGE SCI, V23, P789, DOI 10.1287/mnsc.23.8.789; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; ANSTREICHER K, 1995, OPER RES, V43, P684; COCHRAN WG, 1970, J AM STAT ASSOC, V65, P22, DOI 10.2307/2283572; Cohen JP, 2003, APPL MULTIPLE REGRES; Couvreur C, 2000, SIAM J MATRIX ANAL A, V21, P797, DOI 10.1137/S0895479898332928; Davis G, 1997, J CONSTR APPROX, V13, P57; Deshpande A., 2004, P INT C VER LARG DAT; DIEKHOFF G, 2002, STAT SOCIAL BEHAV SC; DONOHO D, 2005, COMMUNICATIONS PURE, V59, P1207; FLACK VF, 1987, AM STAT, V41, P84, DOI 10.2307/2684336; GILBERT A, 2003, P ACM SIAM S DISCR A; Guestrin C., 2005, INT C MACH LEARN ICM; Horn RA, 1999, MATRIX ANAL; Hwang FK, 1999, SIAM J OPTIMIZ, V10, P70, DOI 10.1137/S1052623497344002; Johnson R. A., 2002, APPL MULTIVARIATE ST; LIASKOVITIS P, 2007, P 3 INT C DISTR COMP; Miller A, 2002, SUBSET SELECTION REG, V2nd; Muthukrishnan S., 2005, FDN TRENDS THEORETIC, V1; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Onn S, 2001, MATH OPER RES, V26, P583, DOI 10.1287/moor.26.3.583.10587; PESARAN MH, 1994, ECONOMETRICA, V62, P705, DOI 10.2307/2951666; SAXE JB, 1980, SIAM J ALGEBRA DISCR, V1, P363, DOI 10.1137/0601042; Stewart G.W., 1990, MATRIX PERTURBATION; TEMLYAKOV V, 2002, FOUND COMPUT MATH, V3, P33; Temlyakov VN, 1999, J APPROX THEORY, V98, P117, DOI 10.1006/jath.1998.3265; TROPP J, 2003, P IEEE ICIP; Tropp J. A., 2004, THESIS U TEXAS AUSTI; Vandenberghe L., 2004, CONVEX OPTIMIZATION; VELICER WF, 1978, EDUC PSYCHOL MEAS, V38, P953, DOI 10.1177/001316447803800415; WAINWRIGHT M, 2006, P ALL C COMM; Walker DA, 2003, J COLL STUDENT DEV, V44, P127, DOI 10.1353/csd.2003.0010	39	17	17	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA	0737-8017		978-1-60558-047-0	ACM S THEORY COMPUT			2008							45	54				10	Computer Science, Theory & Methods	Computer Science	BJK15	WOS:000266622800006		
S	Jang, J; Ye, JC		Conchello, JA; Cogswell, CJ; Wilson, T; Brown, TG		Jang, Jaeduck; Ye, Jong Chul			Multi-view optical tomography using L1 data fidelity and sparsity constraint - art. no. 68610G	THREE-DIMENSIONAL AND MULTIDIMENSIONAL MICROSCOPY: IMAGE ACQUISITION AND PROCESSING XV	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Three-Dimensional and Multidimensional Microscopy - Image Acquisition and Processing XV	JAN 21-24, 2008	San Jose, CA	SPIE		PCD; OSBP; tilted tomography; off-centered aperture	COMPUTED-TOMOGRAPHY; MICROSCOPY; OPTIMIZATION; COORDINATE; SHRINKAGE	This paper describes a novel reconstruction algorithm for microscopy axial tomography, which reconstructs a 3-D volume using multiple tilted views through an off-centered aperture and numerical processing. The main contribution of this paper is a derivation of novel optimization criterion and algorithm for a cost function with L, fidelity term and sparsity constraint. A parallel coordinate descent (PCD) algorithm has been derived as an efficient optimization methods, which corresponds to iterative application of projection and nonlinear back-projection using median. Numerical simulation results using synthetic and real microscopy data show that accurate reconstruction can be obtained rapidly, and interference artifacts from high contrast objects in a volume can be removed efficiently. Our algorithm is quite general, and can be used for many other tomosynthesis applications with limited number of views.	[Jang, Jaeduck; Ye, Jong Chul] Korea Adv Inst Sci & Technol, Dept Bio & Brain Engn, Taejon 305701, South Korea	Jang, J (reprint author), Korea Adv Inst Sci & Technol, Dept Bio & Brain Engn, 373-1 Guseong Dong, Taejon 305701, South Korea.						Elad M, 2007, APPL COMPUT HARMON A, V23, P346, DOI 10.1016/j.acha.2007.02.002; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Conchello JA, 2005, NAT METHODS, V2, P920, DOI 10.1038/NMETH815; Born, 1965, PRINCIPLES OPTICS; Bouman CA, 1996, IEEE T IMAGE PROCESS, V5, P480, DOI 10.1109/83.491321; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Claus BEH, 2002, P SOC PHOTO-OPT INS, V4684, P814, DOI 10.1117/12.467229; Donoho D., 2006, IEEE T INFORM THEORY, V52; Elad M, 2006, IEEE T INFORM THEORY, V52, P5559, DOI 10.1109/TIT.2006.885522; Fauver M., 2004, Proceedings of the SPIE - The International Society for Optical Engineering, V5324, DOI 10.1117/12.530914; GIBSON SF, 1991, J OPT SOC AM A, V8, P1601; GONDROM S, 2002, J NONDESTR TEST ULTR, V7; GRANAI L, 2005, P SIGN PROC AD SPARS, P135; Hsieh J, 2000, MED PHYS, V27, P23, DOI 10.1118/1.598853; KAWATA S, 1987, J OPT SOC AM A, V4, P292, DOI 10.1364/JOSAA.4.000292; KIKUCHI S, 1994, OPT COMMUN, V107, P432, DOI 10.1016/0030-4018(94)90361-1; Kikuchi S, 1996, OPT COMMUN, V123, P725, DOI 10.1016/0030-4018(95)00478-5; Man B. D., 2004, PHYS MED BIOL, V49, P2463, DOI DOI 10.1088/0031-9155/49/11/024; Sharpe J, 2002, SCIENCE, V296, P541, DOI 10.1126/science.1068206	20	0	0	1	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-7036-2	P SOC PHOTO-OPT INS			2008	6861						G8610	G8610		10.1117/12.762412		8	Microscopy	Microscopy	BHU02	WOS:000256378900012		
B	Qiao, ZH; Zhou, L; Huang, JHZ		Ao, SI; Gelman, L; Hukins, DWL; Hunter, A; Korsunsky, AM		Qiao, Zhihua; Zhou, Lan; Huang, Jianhua Z.			Effective linear discriminant analysis for high dimensional, low sample size data	WORLD CONGRESS ON ENGINEERING 2008, VOLS I-II	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	World Congress on Engineering 2008	JUL 02-04, 2008	London, ENGLAND	Int Assoc Engineers	Imperial Coll London	classification; linear discriminant analysis; variable selection; regularization; sparse LDA		In the so-called high dimensional, low sample size (HDLSS) settings, LDA possesses the "data piling" property, that is, it maps all points from the same class in the training data to a common point, and so when viewed along the LDA projection directions, the data are piled up. Data piling indicates overfitting and usually results in poor out-of-sample classification. In this paper,a novel approach to overcome the data piling problem is introduced. It incorporates variable selection into LDA. The underlying assumption is that, among the large number of variables there are many irrelevant or redundant variables for the purpose of classification. By using only important or significant variables we essentially deal with a lower dimensional problem. Experiments on both synthetic and real data sets show that the proposed method is effective in overcoming the data piling and overfitting problem of LDA while improving the out-of-sample classification performance.	[Qiao, Zhihua] MIT, Sloan Sch Management, Cambridge, MA 02142 USA	Qiao, ZH (reprint author), MIT, Sloan Sch Management, 50 Mem Dr,E52-456, Cambridge, MA 02142 USA.	zqiao@MIT.EDU; lzhou@stat.tamu.edu; jianhua@stat.tamu.edu					ALON U, 1999, P NATL ACAD SCI USA, V96, P503; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Gower J.C., 2004, PROCRUSTES PROBLEMS; Marron JS, 2007, J AM STAT ASSOC, V480, P1267; Qiao Z., 2006, THESIS U PENNSYLVANI; ZOU H, 2006, J COMPUTATIONAL STAT, V15, P157	6	1	1	0	3	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA			978-988-98671-9-5	LECT NOTES ENG COMP			2008							1070	1075				6	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Multidisciplinary; Engineering, Electrical & Electronic; Mathematics, Applied	Computer Science; Engineering; Mathematics	BIH83	WOS:000259580600201		
J	Lafferty, J; Wasserman, L				Lafferty, John; Wasserman, Larry			Rodeo: Sparse, greedy nonparametric regression	ANNALS OF STATISTICS			English	Article						nonparametric regression; sparsity; local linear smoothing; bandwidth estimation; variable selection; minimax rates of convergence	NONCONCAVE PENALIZED LIKELIHOOD; VARIABLE SELECTION; APPROXIMATION; ADAPTATION; SPLINES; LASSO	We present a greedy method for simultaneously performing local bandwidth selection and variable selection in nonparametric regression. The method starts with a local linear estimator with large bandwidths, and incrementally decreases the bandwidth of variables for which the gradient of the estimator with respect to bandwidth is large. The method-called rodeo (regularization of derivative expectation operator)-conducts a sequence of hypothesis tests to threshold derivatives, and is easy to implement. Under certain assumptions on the regression function and sampling density, it is shown that the rodeo applied to local linear smoothing avoids the curse of dimensionality, achieving near optimal minimax rates of convergence in the number of relevant variables, as if these variables were isolated in advance.	[Lafferty, John] Carnegie Mellon Univ, Dept Machine Learning, Dept Comp Sci, Pittsburgh, PA 15213 USA; [Wasserman, Larry] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA	Lafferty, J (reprint author), Carnegie Mellon Univ, Dept Machine Learning, Dept Comp Sci, Pittsburgh, PA 15213 USA.	lafferty@cs.cmu.edu; larry@stat.cmu.edu					Kerkyacharian G, 2001, PROBAB THEORY REL, V121, P137, DOI 10.1007/PL00008800; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FAN JQ, 1992, J AM STAT ASSOC, V87, P998, DOI 10.2307/2290637; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Lepski OV, 1997, ANN STAT, V25, P929; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Efron B, 2004, ANN STAT, V32, P407; RICE J, 1984, ANN STAT, V12, P1215, DOI 10.1214/aos/1176346788; Breiman L., 1984, CLASSIFICATION REGRE; Buhlmann P, 2006, J MACH LEARN RES, V7, P1001; DONOHO D, 2004, COMMUN PUR APPL MATH, V59, P797; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; George EI, 1997, STAT SINICA, V7, P339; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Gyorfi L, 2002, DISTRIBUTION FREE TH; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 1993, STAT SCI, V8, P120, DOI 10.1214/ss/1177011002; HRISTACHE M, 2001, ANN STAT, V29, P1237; Lawrence N., 2003, ADV NEURAL INFORMATI, V15, P625; Li LX, 2005, J ROY STAT SOC B, V67, P285, DOI 10.1111/j.1467-9868.2005.00502.x; RUPPERT D, 1994, ANN STAT, V22, P1346, DOI 10.1214/aos/1176325632; Ruppert D, 1997, J AM STAT ASSOC, V92, P1049, DOI 10.2307/2965570; Samarov A, 2005, J AM STAT ASSOC, V100, P429, DOI 10.1198/016214504000001529; Smola AJ, 2001, ADV NEUR IN, V13, P619; Stone CJ, 1997, ANN STAT, V25, P1371; TROPP JA, 2006, IEEE T INFORM THEORY, V51, P1030; TURLACH B, 2004, ANN STAT, V32, P464; ZHANG H, 2005, J AM STAT ASSOC, V99, P659	31	25	25	1	2	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	FEB	2008	36	1					28	63		10.1214/009053607000000811		36	Statistics & Probability	Mathematics	265VO	WOS:000253390000002		
J	Li, R; Liang, H				Li, Runze; Liang, Hua			Variable selection in semiparametric regression modeling	ANNALS OF STATISTICS			English	Article						local linear regression; nonconcave penalized likelihood; SCAD; varying coefficient models	VARYING-COEFFICIENT MODELS; EFFICIENT ESTIMATION; LIKELIHOOD; INFERENCES	In this paper, we are concerned with how to select significant variables in semiparametric modeling. Variable selection for semiparametric regression models consists of two components: model selection for nonparametric components and selection of significant variables for the parametric portion. Thus, semiparametric variable selection is much more challenging than parametric variable selection (e.g., linear and generalized linear models) because traditional variable selection procedures including stepwise regression and the best subset selection now require separate model selection for the nonparametric components for each submodel. This leads to a very heavy computational burden. In this paper, we propose a class of variable selection procedures for semiparametric regression models using nonconcave penalized likelihood. We establish the rate of convergence of the resulting estimate. With proper choices of penalty functions and regularization parameters, we show the asymptotic normality of the resulting estimate and further demonstrate that the proposed procedures perform as well as an oracle procedure. A semiparametric generalized likelihood ratio test is proposed to select significant variables in the nonparametric component. We investigate the asymptotic behavior of the proposed test and demonstrate that its limiting null distribution follows a chi-square distribution which is independent of the nuisance parameters. Extensive Monte Carlo simulation studies are conducted to examine the finite sample performance of the proposed variable selection procedures.	[Li, Runze] Penn State Univ, Dept Stat, University Pk, PA 16802 USA; [Li, Runze] Penn State Univ, Method Ctr, University Pk, PA 16802 USA; [Liang, Hua] Univ Rochester, Dept Biostat & Computat Biol, Rochester, NY 14642 USA	Li, R (reprint author), Penn State Univ, Dept Stat, University Pk, PA 16802 USA.	rli@stat.psu.edu; hliang@bst.rochester.edu	Li, Runze/C-5444-2013	Li, Runze/0000-0002-0154-2202			AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Fan JQ, 2005, BERNOULLI, V11, P1031, DOI 10.3150/bj/1137421639; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Carroll RJ, 1997, J AM STAT ASSOC, V92, P477, DOI 10.1080/01621459.1997.10474001; HASTIE T, 1993, J ROY STAT SOC B MET, V55, P757; CRAVEN P, 1979, NUMER MATH, V31, P377; Breiman L, 1996, ANN STAT, V24, P2350; Cai ZW, 2000, J AM STAT ASSOC, V95, P888, DOI 10.2307/2669472; Fan JQ, 2001, ANN STAT, V29, P153, DOI 10.1214/aos/996986505; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; Hardle W, 2000, PARTIALLY LINEAR MOD; HUNSBERGER S, 1994, J AM STAT ASSOC, V89, P1354, DOI 10.2307/2290997; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; LI R, 2005, VARIABLE SELECTION S; MACK YP, 1982, Z WAHRSCHEINLICHKEIT, V61, P405, DOI 10.1007/BF00539840; POLLARD D, 1991, ECONOMET THEOR, V7, P186; Ruppert D, 1995, J AM STAT ASSOC, V90, P1257, DOI 10.2307/2291516; Ruppert D., 2003, SEMIPARAMETRIC REGRE; SEVERINI TA, 1994, J AM STAT ASSOC, V89, P501, DOI 10.2307/2290852; Xia YC, 2004, BIOMETRIKA, V91, P661, DOI 10.1093/biomet/91.3.661; Yatchew A., 2003, SEMIPARAMETRIC REGRE; Zhang WY, 2002, J MULTIVARIATE ANAL, V82, P166, DOI 10.1006/jmva.2001.2012	27	125	137	3	13	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	FEB	2008	36	1					261	286		10.1214/009053607000000604		26	Statistics & Probability	Mathematics	265VO	WOS:000253390000010		
J	Radchenko, P				Radchenko, Peter			Mixed-rates asymptotics	ANNALS OF STATISTICS			English	Article						nonstandard asymptotics; rates of convergence; limiting distribution; empirical processes; M-estimators; singular quadratic approximation; Lasso; k-means; Shorth; partial splines	THEOREM; LASSO	A general method is presented for deriving the limiting behavior of estimators that are defined as the values of parameters optimizing an empirical criterion function. The asymptotic behavior of such estimators is typically deduced from uniform limit theorems for rescaled and reparametrized criterion functions. The new method can handle cases where the standard approach does not yield the complete limiting behavior of the estimator. The asymptotic analysis depends on a decomposition of criterion functions into sums of components with different rescalings. The method is explained by examples from Lasso-type estimation, k-means clustering, Shorth estimation and partial linear models.	Univ So Calif, Los Angeles, CA 90089 USA	Radchenko, P (reprint author), Univ So Calif, 3670 Trousdale Pkwy,Bridge Hall 401-M, Los Angeles, CA 90089 USA.	radchenk@usc.edu	Radchenko, Peter/E-2601-2015				Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; KIM JY, 1990, ANN STAT, V18, P191, DOI 10.1214/aos/1176347498; Andrews DWK, 1999, ECONOMETRICA, V67, P1341, DOI 10.1111/1468-0262.00082; Dudley R. M., 1999, UNIFORM CENTRAL LIMI; DUDLEY RM, 1985, LECT NOTES MATH, V1153, P141; GRUBEL R, 1988, ANN STAT, V16, P619, DOI 10.1214/aos/1176350823; Kosorok MR, 2006, INTRO EMPIRICAL PROC; POLLARD D, 1982, ANN PROBAB, V10, P919, DOI 10.1214/aop/1176993713; Pollard D., 1990, EMPIRICAL PROCESSES; POLLARD D, 1981, ANN STAT, V9, P135, DOI 10.1214/aos/1176345339; Pollard D, 2006, J MULTIVARIATE ANAL, V97, P548, DOI 10.1016/j.jmva.2005.04.002; RADCHENKO P, 2005, 2005 P AM STAT ASS; RADCHENKO P, 2006, MIXED RATES ASYMPTOT; RADCHENKO P, 2004, THESIS YALE U; Rotnitzky A, 2000, BERNOULLI, V6, P243, DOI 10.2307/3318576; Shorack G.R., 1986, EMPIRICAL PROCESSES; van de Geer S., 1999, EMPIRICAL PROCESSES; Van der Vaart A., 1996, WEAK CONVERGENCE EMP; van der Vaart A. W., 1998, ASYMPTOTIC STAT	21	5	5	0	0	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	FEB	2008	36	1					287	309		10.1214/009053607000000668		23	Statistics & Probability	Mathematics	265VO	WOS:000253390000011		
J	Lind, I; Ljung, L				Lind, Ingela; Ljung, Lennart			Regressor and structure selection in NARX models using a structured ANOVA approach	AUTOMATICA			English	Article						nonlinear system identification; structure identification; analysis of variance	IDENTIFICATION; SYSTEMS; ALGORITHM	Regressor selection can be viewed as the first step in the system identification process. The benefits of finding good regressors before estimating complex models are especially clear for nonlinear systems, where the class of possible models is huge. In this article, a structured way of using the tool analysis of variance (ANOVA) is presented and used for NARX model (nonlinear autoregressive model with exogenous input) identification with many candidate regressors. (C) 2007 Elsevier Ltd. All rights reserved.	[Lind, Ingela; Ljung, Lennart] Linkoping Univ, Dept Elect Engn, Div Automat Control, SE-58337 Linkoping, Sweden	Lind, I (reprint author), Linkoping Univ, Dept Elect Engn, Div Automat Control, SE-58337 Linkoping, Sweden.	ingela.lind@saab.se; ljung@isy.liu.se	Ljung, Lennart/B-3822-2014	Ljung, Lennart/0000-0003-4881-8955			AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; AUTIN M, 1992, IEEE INT S CIRC SYST, V1, P296; BARNETT W, 1978, OULTLIERS STAT DATA; CHEN R, 1995, BIOMETRIKA, V82, P369; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gunn SR, 2002, MACH LEARN, V48, P137, DOI 10.1023/A:1013903804720; HABER R, 1990, AUTOMATICA, V26, P651, DOI 10.1016/0005-1098(90)90044-I; KORENBERG M, 1988, INT J CONTROL, V48, P193, DOI 10.1080/00207178808906169; Lind I, 2005, AUTOMATICA, V41, P693, DOI 10.1016/j.automatica.2004.11.017; LIND I, 2006, THESIS LINKOPINS U L; LIND I, 2000, P IFAC S SYSID 2000, P367; Ljung L., 2004, P 6 IFAC S NONL CONT, P543; MANNALE R, 2006, LITHISYR2730 LINK U; MILLER RG, 1997, ANOVA; Montgomery DC, 1991, DESIGN ANAL EXPT; *NOLCOS, 2004, P 6 IFAC S NONL CONT; Pintelon R., 2001, SYSTEM IDENTIFICATIO; Piroddi L, 2003, INT J CONTROL, V76, P1767, DOI 10.1080/00207170310001635419; Rhodes C, 1998, AICHE J, V44, P151, DOI 10.1002/aic.690440116; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; ROLL J, 2006, 45 IEEE C DEC CONTR, P4907; SPINELLI W, 2006, P AM CONTR C MINN MN, P2387	26	27	27	1	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0005-1098			AUTOMATICA	Automatica	FEB	2008	44	2					383	395		10.1016/j.automatica.2007.06.010		13	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	264BO	WOS:000253260400007		
J	Wang, L; Zhu, J; Zou, H				Wang, Li; Zhu, Ji; Zou, Hui			Hybrid huberized support vector machines for microarray classification and gene selection	BIOINFORMATICS			English	Article							REGRESSION; CANCER; TUMOR	Motivation: The standard L-2-norm support vector machine (SVM) is a widely used tool for microarray classification. Previous studies have demonstrated its superior performance in terms of classification accuracy. However, a major limitation of the SVM is that it cannot automatically select relevant genes for the classification. The L-1-norm SVM is a variant of the standard L-2-norm SVM, that constrains the L-1-norm of the fitted coefficients. Due to the singularity of the L-1-norm, the L-1-norm SVM has the property of automatically selecting relevant genes. On the other hand, the L-1-norm SVM has two drawbacks: (1) the number of selected genes is upper bounded by the size of the training data; (2) when there are several highly correlated genes, the L-1-norm SVM tends to pick only a few of them, and remove the rest. Results: We propose a hybrid huberized support vector machine (HHSVM). The HHSVM combines the huberized hinge loss function and the elastic-net penalty. By doing so, the HHSVM performs automatic gene selection in a way similar to the L-1-norm SVM. In addition, the HHSVM encourages highly correlated genes to be selected (or removed) together. We also develop an efficient algorithm to compute the entire solution path of the HHSVM. Numerical results indicate that the HHSVM tends to provide better variable selection results than the L-1-norm SVM, especially when variables are highly correlated.	[Zhu, Ji] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA; [Wang, Li] Univ Michigan, Ross Sch Business, Ann Arbor, MI 48109 USA; [Zou, Hui] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	Zhu, J (reprint author), Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Potti A, 2006, NEW ENGL J MED, V355, P570, DOI 10.1056/NEJMoa060467; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Bradley P., 1998, P 15 INT C MACH LEAR; EVGENIOU T, 1999, ADV LARGE MARGIN CLA; MUKHERJEE S, 2000, SUPPORT VECTOR MACHI; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Vapnik V.N., 1995, NATURE STAT LEARNING; ZHU J, 2004, P NEURAL INFORM PROC	15	50	62	1	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	FEB 1	2008	24	3					412	419		10.1093/bioinformatics/btm579		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	258XM	WOS:000252903700015	18175770	
J	Balakrishnan, S; Madigan, D				Balakrishnan, Suhrid; Madigan, David			Algorithms for sparse linear classifiers in the massive data setting	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						Laplace approximation; expectation propagation; LASSO	TEXT CATEGORIZATION; LOGISTIC-REGRESSION; SELECTION; LASSO	Classifiers favoring sparse solutions, such as support vector machines, relevance vector machines, LASSO-regression based classifiers, etc., provide competitive methods for classification problems in high dimensions. However, current algorithms for training sparse classifiers typically scale quite unfavorably with respect to the number of training examples. This paper proposes online and multipass algorithms for training sparse linear classifiers for high dimensional data. These algorithms have computational complexity and memory requirements that make learning on massive data sets feasible. The central idea that makes this possible is a straightforward quadratic approximation to the likelihood function.	[Balakrishnan, Suhrid] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA; [Madigan, David] Columbia Univ, Dept Stat, New York, NY 10027 USA	Balakrishnan, S (reprint author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.	SUHRID@CS.RUTGERS.EDU; MADIGAN@STAT.COLUMBIA.EDU					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Bernardo J. M., 1994, BAYESIAN THEORY; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; ESKIN E, 2003, NEURAL INFORM PROCES, V16; Figueiredo M. A. T., 2001, P IEEE INT C COMP VI, V1, P35; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; Koh KM, 2007, J MACH LEARN RES, V8, P1519; KOMAREK P, 1927, TR0527 CARN MELL U R; Krishnapuram B., 2005, IEEE T PATTERN ANAL; Lewis D., 2004, OXFORD STUDIES METAP, V1, P3; Minka T. P., 2001, P 17 C UNC ART INT, P362; Minka T.P., 2001, THESIS MIT; Opper M., 1998, ON LINE LEARNING NEU, P363; Qi Y., 2004, P 21 INT C MACH LEAR; Rockafellar R.T., 1970, CONVEX ANAL; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217; Zhang T, 2002, MACH LEARN, V46, P91, DOI 10.1023/A:1012498226479	27	13	14	0	2	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2008	9						313	337				25	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312AP	WOS:000256641800012		
J	Gao, JB				Gao, Junbin			Robust L1 principal component analysis and its Bayesian variational inference	NEURAL COMPUTATION			English	Article							ANALYZERS; MIXTURES; MODELS	We introduce a robust probabilistic L1-PCA model in which the conventional gaussian distribution for the noise in the observed data was replaced by the Laplacian distribution (or L1 distribution). Due to the heavy tail characteristics of the L1 distribution, the proposed model is supposed to be more robust against data outliers. In this letter, we demonstrate how a variational approximation scheme enables effective inference of key parameters in the probabilistic L1-PCA model. As the L1 density can be expanded as a superposition of infinite number of gaussian densities, we express the L1-PCA model as a marginalized model over the superpositions. By doing so, a tractable Bayesian inference can be achieved based on the variational expectation-maximization-type algorithm.	Charles Sturt Univ, Sch Comp Sci, Bathurst, NSW 2795, Australia	Gao, JB (reprint author), Charles Sturt Univ, Sch Comp Sci, Bathurst, NSW 2795, Australia.	jbgao@csu.edu.au	Gao, Junbin/C-6566-2008				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Baccini A, 1996, ST CLASS DAT ANAL, P359; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; ARCHAMBEAU C, 2005, THESIS U CATHOLIQUE; Archambeau C., 2006, P 23 INT C MACH LEAR; BLACK MJ, 1996, P ECCV, V1; DELATORRE F, 2001, INT C COMPUTER VISIO, V52, P362; Ding C., 2006, P 23 INT C MACH LEAR; Gao JB, 2002, LECT NOTES ARTIF INT, V2557, P395; Ghahramani Z, 2000, ADV NEUR IN, V12, P449; GUO Y, 2006, TWIN MEASURE EMBEDDI; IRANI M, 1999, P INT C COMP VIS WAS; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; KE Q, 2001, P CVPR; Ke Q., 2005, P CVPR, P739, DOI 10.1109/CVPR.2005.309; KHAN Z, 2004, GITGVU0411 GEORG I T; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Ng A. Y., 2004, P INT C MACH LEARN; Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081; PONTIL M, 1998, 1651 MIT A1 LAB; RIDDER DD, 2003, BMVC 2003, P319; RUYMGAART FH, 1981, J MULTIVARIATE ANAL, V11, P485, DOI 10.1016/0047-259X(81)90091-9; Tipping M, 1999, J ROYAL STAT SOC B, V61, P611; Tipping ME, 2005, NEUROCOMPUTING, V69, P123, DOI 10.1016/j.neucom.2005.02.016; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Verbeek J, 2006, IEEE T PATTERN ANAL, V28, P1236, DOI 10.1109/TPAMI.2006.166; VERBEEK JJ, 2004, ADV NEURAL INFORM PR, V16; Zou H., 2004, SPARSE PRINCIPAL COM	31	31	32	2	5	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	FEB	2008	20	2					555	572		10.1162/neco.2007.11-06-397		18	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	249RU	WOS:000252248200011	18045015	
J	Wu, TT; Lange, K				Wu, Tong Tong; Lange, Kenneth			COORDINATE DESCENT ALGORITHMS FOR LASSO PENALIZED REGRESSION	ANNALS OF APPLIED STATISTICS			English	Article						Model selection; Edgeworth's algorithm; cyclic; greedy; consistency; convergence	MODEL SELECTION; APPROXIMATION; CONSISTENCY; EXPRESSION	Imposition of a lasso penalty shrinks parameter estimates toward zero and performs continuous model selection. Lasso penalized regression is capable of handling linear regression problems where the number of predictors far exceeds the number of cases. This paper tests two exceptionally fast algorithms for estimating regression coefficients with a lasso penalty. The previously known l(2) algorithm is based on cyclic coordinate descent. Our new C, algorithm is based oil greedy coordinate descent and Edgeworth's algorithm for ordinary l(1) regression. Each algorithm relies on a tuning constant that can be chosen by cross-validation. In some regression problems it is natural to group parameters and penalize parameters group by group rather than separately. If the group penalty is proportional to the Euclidean norin of the parameters of the group, then it is possible to majorize the norm and reduce parameter estimation to l(2) regression with a lasso penalty. Thus, the existing algorithm can be extended to novel settings. Each of the algorithms discussed is tested via either simulated or real data or both. The Appendix proves that a greedy form of the l(2) algorithm converges to the minimum value of the objective function.	[Wu, Tong Tong] Univ Maryland, Dept Epidemiol & Biostat, College Pk, MD 20707 USA; [Lange, Kenneth] Univ Calif Los Angeles, Dept Biomath Human Genet & Stat, Los Angeles, CA 90095 USA	Wu, TT (reprint author), Univ Maryland, Dept Epidemiol & Biostat, College Pk, MD 20707 USA.	ttwu@umd.edu; klange@ucla.edu			NIH [GM53275, MH59490]	Supported in part by NIH Grants GM53275 and MH59490.	Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Huang BL, 2002, DIABETES, V51, P276; [Anonymous], 2001, J OPTIMIZ THEORY APP, DOI DOI 10.1023/A:1017501703105; MERLE G, 1974, COMPUTING, V12, P315, DOI 10.1007/BF02253335; Portnoy S, 1997, STAT SCI, V12, P279; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836; Armstrong R. D., 1978, Applied Statistics, V27, DOI 10.2307/2347181; BARRODALE I, 1980, ACM T MATH SOFTWARE, V6, P231, DOI 10.1145/355887.355896; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; Edgeworth F., 1888, PHILOS MAG, V25, P184; ENGEWORTH FY, 1887, HERMATHENA, V6, P279; GHAZALPOUR A, 2005, NAT GENET, V37, P1224; Ghazalpour A, 2006, PLOS GENET, V2, P1182, DOI 10.1371/1journal.pgen.0020130; HASTIE T, 2007, LARS PACKAGE; Lange K., 2004, OPTIMIZATION; Li Y., 2004, EURASIP J APPL SIG P, V12, P1762; Mehrabian M, 2005, NAT GENET, V37, P1224, DOI 10.1038/ng1619; OBERHOFER W, 1982, ANN STAT, V10, P316, DOI 10.1214/aos/1176345716; PARK M. Y., 2006, 200615 STANF U DEP S; PARK MP, 2006, 200614 STANF U DEP S; Rudin W., 1987, REAL COMPLEX ANAL; Ruszczynski A., 2006, NONLINEAR OPTIMIZATI; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; SCHLOSSM.EJ, 1973, J AM STAT ASSOC, V68, P857, DOI 10.2307/2284512; Sugden MC, 2003, OBES RES, V11, P167, DOI 10.1038/oby.2003.26; TAYLOR HL, 1979, GEOPHYSICS, V44, P39, DOI 10.1190/1.1440921; Wang L., 2006, P 6 INT C DAT MIN IC, P690, DOI 10.1109/ICDM.2006.134; Wang S, 2006, PLOS GENET, V2, P148, DOI 10.1371/journal.pgen.0020015; WU TT, 2008, CORDINATE DESCENT S, DOI DOI 10.1214/07-AOAS174SUPP; Zhao P, 2006, GROUPED HIERARCHICAL	38	179	181	2	13	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	MAR	2008	2	1					224	244		10.1214/07-AOAS147		21	Statistics & Probability	Mathematics	374QB	WOS:000261057700016		
J	Levina, E; Rothman, A; Zhu, J				Levina, Elizaveta; Rothman, Adam; Zhu, Ji			SPARSE ESTIMATION OF LARGE COVARIANCE MATRICES VIA A NESTED LASSO PENALTY	ANNALS OF APPLIED STATISTICS			English	Article						Covariance matrix; high dimension low sample size; large p small n; Lasso; sparsity; Cholesky decomposition	LONGITUDINAL DATA; NONPARAMETRIC-ESTIMATION; PROSTATE-CANCER; SELECTION; LIKELIHOOD; REGRESSION; MODELS; BAYES; MEN	The paper proposes a new covariance estimator for large covariance matrices when the variables have if natural ordering. Using the Cholesky decomposition of the inverse, we impose if handed structure on the Cholesky factor, and select the bandwidth adaptively for each row of the Cholesky factor, using a novel penalty we call nested Lasso. This structure has more flexibility than regular banding, but, unlike regular Lasso applied to the entries of the Cholesky factor, results in a sparse estimator for the inverse of the covariance matrix. matrix. An iterative algorithm for solving the optimization problem is developed. The estimator is compared to a number of other covariance estimators and is shown to de best, both in simulations and on a real data example. Simulations show that the margin by which the estimator outperforms its competitors tends to increase with dimension.	[Levina, Elizaveta; Rothman, Adam; Zhu, Ji] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA	Levina, E (reprint author), Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA.	elevina@umich.edu; ajrothma@umich.edu; jizhu@umich.edu			NSF [DMS-05-05424, DMS-05-05432, DMS-07-05532]; NSA [MSPF-04Y-120]	Supported in part by NSF Grant DMS-05-05424 and NSA Grant MSPF-04Y-120.Supported in part by NSF Grants DMS-05-05432 and DMS-07-05532.	Adam BL, 2002, CANCER RES, V62, P3609; Anderson T., 1958, INTRO MULTIVARIATE S; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Wong F, 2003, BIOMETRIKA, V90, P809, DOI 10.1093/biomet/90.4.809; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Ledoit O, 2004, J MULTIVARIATE ANAL, V88, P365, DOI 10.1016/S0047-259X(03)00096-4; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Pourahmadi M, 1999, BIOMETRIKA, V86, P677, DOI 10.1093/biomet/86.3.677; Johnstone IM, 2001, ANN STAT, V29, P295, DOI 10.1214/aos/1009210544; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Banerjee O., 2006, P ICML; BICKEL PJ, 2007, ANN STAT IN PRESS; DEY DK, 1985, ANN STAT, V13, P1581, DOI 10.1214/aos/1176349756; Diggle PJ, 1998, BIOMETRICS, V54, P401, DOI 10.2307/3109751; Djavan B, 1999, UROLOGY, V54, P517, DOI 10.1016/S0090-4295(99)00153-3; FAN J, 2008, J ECONOMETR IN PRESS; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Furrer R, 2007, J MULTIVARIATE ANAL, V98, P227, DOI 10.1016/j.jmva.2006.08.003; HAFF LR, 1980, ANN STAT, V8, P586, DOI 10.1214/aos/1176345010; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; JOHNSTONE IM, 2007, J AM STAT A IN PRESS; Mardia KV, 1979, MULTIVARIATE ANAL; Pannek J, 1998, Semin Urol Oncol, V16, P100; Smith M, 2002, J AM STAT ASSOC, V97, P1141, DOI 10.1198/016214502388618942; Stamey TA, 2002, J UROLOGY, V167, P103, DOI 10.1016/S0022-5347(05)65392-X; Wu WB, 2003, BIOMETRIKA, V90, P831, DOI 10.1093/biomet/90.4.831; Zhao P., 2006, 703 UC BERK DEP STAT, VDepartment of Statistics	34	55	55	1	7	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	MAR	2008	2	1					245	263		10.1214/07-AOAS139		19	Statistics & Probability	Mathematics	374QB	WOS:000261057700017		
J	Herrmann, FJ; Moghaddam, P; Stolk, CC				Herrmann, Felix J.; Moghaddam, Peyman; Stolk, Christiaan C.			Sparsity- and continuity-promoting seismic image recovery with curvelet frames	APPLIED AND COMPUTATIONAL HARMONIC ANALYSIS			English	Article							GENERALIZED RADON-TRANSFORM; ANISOTROPIC ELASTIC MEDIA; LINEAR INVERSE PROBLEMS; LEAST-SQUARES; MICROLOCAL ANALYSIS; DEPTH-MIGRATION; AMPLITUDE; REPRESENTATIONS; DECOMPOSITION; ALGORITHM	A nonlinear singularity-preserving solution to seismic image recovery with sparseness and continuity constraints is proposed. We observe that curvelets, as a directional frame expansion, lead to sparsity of seismic images and exhibit invariance under the normal operator of the linearized imaging problem. Based on this observation we derive a method for stable recovery of the migration amplitudes from noisy data. The method corrects the amplitudes during a post-processing step after migration, such that the main additional cost is one application of the normal operator, i.e., a modeling followed by a migration. Asymptotically this normal operator corresponds to a pseudodifferential operator, for which a convenient diagonal approximation in the curvelet domain is derived, including a bound for its error and a method for the estimation of the diagonal from a compound operator consisting of discrete implementations for the scattering operator and its adjoint the migration operator. The solution is formulated as a nonlinear optimization problem where sparsity in the curvelet domain as well as continuity along the imaged reflectors are jointly promoted. To enhance sparsity, the l(1)-norm on the curvelet coefficients is minimized, while continuity is promoted by minimizing an anisotropic diffusion norm on the image. The performance of the recovery scheme is evaluated with a reverse-time 'wave-equation' migration code on synthetic datasets, including the complex SEG/EAGE AA' salt model. (c) 2007 Elsevier Inc. All rights reserved.	[Herrmann, Felix J.; Moghaddam, Peyman] Univ British Columbia, Seism Lab Imaging & Modeling, Dept Earth & Ocean Sci, Vancouver, BC V6T 1Z4, Canada; [Stolk, Christiaan C.] Univ Twente, Dept Appl Math, Enschede, Netherlands	Herrmann, FJ (reprint author), Univ British Columbia, Seism Lab Imaging & Modeling, Dept Earth & Ocean Sci, 6339 Stores Rd, Vancouver, BC V6T 1Z4, Canada.	flierrmann@eos.ubc.ca					AMINZADEH F, 1997, SEG EAGE 3 D MODELLI, V1; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Stolk CC, 2000, WAVE MOTION, V32, P267, DOI 10.1016/S0165-2125(00)00043-3; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Nemeth T, 1999, GEOPHYSICS, V64, P208, DOI 10.1190/1.1444517; Candes E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Candes EJ, 2005, APPL COMPUT HARMON A, V19, P198, DOI 10.1016/j.acha.2005.02.004; Chavent G, 1999, GEOPHYSICS, V64, P508, DOI 10.1190/1.1444557; Plessix RE, 2004, GEOPHYS J INT, V157, P975, DOI 10.1111/j.1365-246X.2004.02282.x; Guitton A, 2004, GEOPHYSICS, V69, P1017, DOI 10.1190/1.1778244; Kuhl H, 2003, GEOPHYSICS, V68, P262, DOI 10.1190/1.1543212; Hennenfent G, 2006, COMPUT SCI ENG, V8, P16, DOI 10.1109/MCSE.2006.49; Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI 10.1016/j.sigpro.2005.05.029; Candes EJ, 2005, APPL COMPUT HARMON A, V19, P162, DOI 10.1016/j.acha.2005.02.003; Hu JX, 2001, GEOPHYSICS, V66, P939, DOI 10.1190/1.1444984; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; BEYLKIN G, 1984, COMMUN PUR APPL MATH, V37, P579, DOI 10.1002/cpa.3160370503; Bleistein N, 2001, MATH MULTIDIMENSIONA; Brandsberg-Dahl S, 2003, GEOPHYSICS, V68, P232, DOI 10.1190/1.1543210; Candes EJ, 2002, ANN STAT, V30, P784; Candes E.J., 2000, CURVES SURFACES; Candes EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116; Candes EJ, 2002, SIGNAL PROCESS, V82, P1519, DOI 10.1016/S0165-1684(02)00300-6; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; CLAERBOUT J, 1994, SPECTRAL PRECONDITIO; deHoop MV, 1997, INVERSE PROBL, V13, P669, DOI 10.1088/0266-5611/13/3/009; de Hoop MV, 2000, INVERSE PROBL, V16, P519, DOI 10.1088/0266-5611/16/3/301; DONOHO DL, 1995, APPL COMPUT HARMON A, V2, P101, DOI 10.1006/acha.1995.1008; Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005; Fehmers GC, 2003, GEOPHYSICS, V68, P1286, DOI 10.1190/1.1598121; FIGUEIREDO MAT, 2003, IEEE T IMAGE PROCESS; Herrmann FJ, 2007, GEOPHYS J INT, V170, P781, DOI 10.1111/J.1365-246X.2007.03360.X; Herrmann FJ, 2003, P SOC PHOTO-OPT INS, V5207, P240, DOI 10.1117/12.505275; Lee NY, 2001, IEEE T IMAGE PROCESS, V10, P79, DOI 10.1109/83.892445; OBRIEN M, 1997, LEADING EDGE, V15, P17; PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989; Rickett JE, 2003, GEOPHYSICS, V68, P1371, DOI 10.1190/1.1598130; Scherzer O, 2003, ADV IMAG ELECT PHYS, V128, P445, DOI 10.1016/S1076-5670(03)80067-8; STARK JL, 2004, ADV IMAG ELECT PHYS, V132; Stolk CC, 2003, INVERSE PROBL, V19, P73, DOI 10.1088/0266-5611/19/1/305; SYMES WW, IN PRESS GEOPHYSICS; Symes W.W., 1991, GEOPHYSICS, V56, P2061; Symes WW, 2007, GEOPHYSICS, V72, pSM213, DOI 10.1190/1.2742686; ten Kroode APE, 1998, WAVE MOTION, V28, P149, DOI 10.1016/S0165-2125(98)00004-3; Ying L., 2005, P SOC PHOTO-OPT INS, V5914, DOI 10.1117/12.616205	49	34	36	1	5	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1063-5203			APPL COMPUT HARMON A	Appl. Comput. Harmon. Anal.	MAR	2008	24	2					150	173		10.1016/j.acha.2007.06.007		24	Mathematics, Applied; Physics, Mathematical	Mathematics; Physics	279JL	WOS:000254351400003		
J	Bondell, HD; Reich, BJ				Bondell, Howard D.; Reich, Brian J.			Simultaneous regression shrinkage, variable selection, and supervised clustering of predictors with OSCAR	BIOMETRICS			English	Article						correlation; penalization; predictive group; regression; shrinkage; supervised clustering; variable selection	LASSO	Variable selection can be challenging, particularly in situations with a large number of predictors with possibly high correlations, such as gene expression data. In this article, a new method called the OSCAR (octagonal shrinkage and clustering algorithm for regression) is proposed to simultaneously select variables while grouping them into predictive clusters. In addition to improving prediction accuracy and interpretation, these resulting groups can then be investigated further to discover what contributes to the group having a similar behavior. The technique is based on penalized least squares with a geometrically intuitive penalty function that shrinks some coefficients to exactly zero. Additionally, this penalty yields exact equality of some coefficients, encouraging correlated predictors that have a similar effect on the response to form predictive clusters represented by a single coefficient. The proposed procedure is shown to compare favorably to the existing shrinkage and variable selection techniques in terms of both prediction error and model complexity, while yielding the additional grouping information.	[Bondell, Howard D.; Reich, Brian J.] N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA	Bondell, HD (reprint author), N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA.	bondell@stat.ncsu.edu					MARSHALL AW, 1967, J AM STAT ASSOC, V62, P30, DOI 10.2307/2282907; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; Dettling M, 2004, J MULTIVARIATE ANAL, V90, P106, DOI 10.1016/j.jmva.2004.02.012; GILL PE, 2005, 051 NA U CAL DEP MAT; HASTIE T, 2002, GENOME BIOL, V2; Jornsten R, 2003, BIOINFORMATICS, V19, P1100, DOI 10.1093/bioinformatics/btg039; Park MY, 2007, BIOSTATISTICS, V8, P212, DOI 10.1093/biostatistics/kxl002; ROSSET S, 2007, IN PRESS ANN STAT, V35; ZOU H, 2006, 646 U MINN SCH STAT; ZOU H, 2004, DEGREES FREEDOM LASS	14	66	68	2	8	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	MAR	2008	64	1					115	123		10.1111/j.1541-0420.2007.00843.x		9	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	269EL	WOS:000253632200013	17608783	
J	Li, LX; Yin, XR				Li, Lexin; Yin, Xiangrong			Sliced inverse regression with regularizations	BIOMETRICS			English	Article						regularized least squares; sliced inverse regression; sufficient dimension reduction	DIMENSION REDUCTION METHODS; GENE-EXPRESSION DATA; CLASS PREDICTION; SELECTION; LASSO; CLASSIFICATION; VISUALIZATION; DISCOVERY; SHRINKAGE; SURVIVAL	In high-dimensional data analysis, sliced inverse regression (SIR) has proven to be an effective dimension reduction tool and has enjoyed wide applications. The usual SIR, however, cannot work with problems where the number of predictors, p, exceeds the sample size, n, and can suffer when there is high collinearity among the predictors. In addition, the reduced dimensional space consists of linear combinations of all the original predictors and no variable selection is achieved. In this article, we propose a regularized SIR approach based on the least-squares formulation of SIR. The L-2 regularization is introduced, and an alternating least-squares algorithm is developed, to enable SIR to work with n < p and highly correlated predictors. The L, regularization is further introduced to achieve simultaneous reduction estimation and predictor selection. Both simulations and the analysis of a microarray expression data set demonstrate the usefulness of the proposed method.	[Li, Lexin] N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA; [Yin, Xiangrong] Univ Georgia, Dept Stat, Athens, GA 30602 USA	Li, LX (reprint author), N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA.	li@stat.ncsu.edu; xryin@stat.uga.edu					Akaike H., 1973, 2 INT S INF THEOR, P267; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Bura E, 2001, J AM STAT ASSOC, V96, P996, DOI 10.1198/016214501753208979; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; [Anonymous], 2004, ANN STAT, V32, P1061; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; SCHOTT JR, 1994, J AM STAT ASSOC, V89, P141, DOI 10.2307/2291210; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Bura E, 2003, BIOINFORMATICS, V19, P1252, DOI 10.1093/bioinformatics/btg150; Chiaromonte F, 2002, MATH BIOSCI, V176, P123, DOI 10.1016/S0025-5564(01)00106-7; COOK R. D., 1998, REGRESSION GRAPHICS; Cook RD, 2001, AUST NZ J STAT, V43, P147, DOI 10.1111/1467-842X.00164; COOK RD, 1994, J AM STAT ASSOC, V89, P592, DOI 10.2307/2290862; COOK RD, 1991, J AM STAT ASSOC, V86, P328, DOI 10.2307/2290564; Cook RD, 1996, J AM STAT ASSOC, V91, P983, DOI 10.2307/2291717; EATON ML, 1986, J MULTIVARIATE ANAL, V20, P272, DOI 10.1016/0047-259X(86)90083-7; HALL P, 1993, ANN STAT, V21, P867, DOI 10.1214/aos/1176349155; JAFFE ES, 1999, LYMPHOMAS, P77; LI KC, 1992, J AM STAT ASSOC, V87, P1025, DOI 10.2307/2290640; Li KC, 1999, ANN STAT, V27, P1; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Li LX, 2004, BIOINFORMATICS, V20, P3406, DOI 10.1093/bioinformatics/bth415; Li LX, 2004, COMPUT STAT DATA AN, V47, P175, DOI 10.1016/j.csda.2003.10.017; Ni LQ, 2005, BIOMETRIKA, V92, P242, DOI 10.1093/biomet/92.1.242; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Shi PD, 2002, J ROY STAT SOC B, V64, P237, DOI 10.1111/1467-9868.00335; Ye ZS, 2003, J AM STAT ASSOC, V98, P968, DOI 10.1198/016214503000000927; Zhong WX, 2005, BIOINFORMATICS, V21, P4169, DOI 10.1093/bioinformatics/bti680; Zhu LX, 2006, J AM STAT ASSOC, V101, P630, DOI 10.1198/016214505000001285; ZOU H, 2004, DEGREES FREEDOM LASS	34	33	33	4	7	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	MAR	2008	64	1					124	131		10.1111/j.1541-0420.2007.00836.x		8	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	269EL	WOS:000253632200014	17651455	
J	Wang, S; Nan, B; Zhu, J; Beer, DG				Wang, Sijian; Nan, Bin; Zhu, Ji; Beer, David G.			Doubly penalized Buckley-James method for survival data with high-dimensional covariates	BIOMETRICS			English	Article						accelerated failure time model; Buckley-James method; censored survival data; elastic net; high-dimensional covariate; lung cancer; microarray analysis; variable selection	RIGHT-CENSORED DATA; LARGE SAMPLE THEORY; FAILURE TIME MODEL; REGRESSION-ANALYSIS; LINEAR-REGRESSION; LUNG ADENOCARCINOMA; VARIABLE SELECTION; LEAST-SQUARES; RANK-TESTS; COX MODEL	Recent interest in cancer research focuses on predicting patients' survival by investigating gene expression profiles based on microarray analysis. We propose a doubly penalized Buckley-James method for the serniparametric accelerated failure time model to relate high-dimensional genomic data to censored survival outcomes, which uses the elastic-net penalty that is a mixture of L-1- and L-2-norm penalties. Similar to the elastic-net method for a linear regression model with uncensored data, the proposed method performs automatic gene selection and parameter estimation, where highly correlated genes are able to be selected (or removed) together. The two-dimensional tuning parameter is determined by generalized crossvalidation. The proposed method is evaluated by simulations and applied to the Michigan squamous cell lung carcinoma study.	[Wang, Sijian; Nan, Bin] Univ Michigan, Dept Biostat, Ann Arbor, MI 48109 USA; [Zhu, Ji] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA; [Beer, David G.] Univ Michigan, Dept Surg, Ann Arbor, MI 48109 USA; [Beer, David G.] Univ Michigan, Dept Radiat Oncol, Ann Arbor, MI 48109 USA	Wang, S (reprint author), Univ Michigan, Dept Biostat, Ann Arbor, MI 48109 USA.	bnan@umich.edu					Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Raponi M, 2006, CANCER RES, V66, P7466, DOI 10.1158/0008-5472.CAN-06-1191; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Efron B, 2004, ANN STAT, V32, P407; BUCKLEY J, 1979, BIOMETRIKA, V66, P429; COX DR, 1972, J R STAT SOC B, V34, P187; De Langhe SP, 2006, DEV BIOL, V299, P52, DOI 10.1016/j.ydbio.2006.07.001; Fang K, 1994, NUMBER THEORETIC MET; Gharib Tarek G, 2004, Clin Lung Cancer, V5, P307, DOI 10.3816/CLC.2004.n.011; Gharib TG, 2002, NEOPLASIA, V4, P440, DOI 10.1038/sj.neo.7900257; HELLER G, 1990, BIOMETRIKA, V77, P515, DOI 10.1093/biomet/77.3.515; Huang J, 2002, BIOMETRICS, V58, P781, DOI 10.1111/j.0006-341X.2002.00781.x; Huang J, 2006, BIOMETRICS, V62, P813, DOI 10.1111/j.1541-0420.2006.00562.x; Huang J, 2005, BIOMETRICS, V61, P17, DOI 10.1111/j.0006-341X.2005.040304.x; KOUL H, 1981, ANN STAT, V9, P1276, DOI 10.1214/aos/1176345644; LAI TL, 1991, ANN STAT, V19, P1370, DOI 10.1214/aos/1176348253; Li H., 2003, PAC S BIOC, P65; LI H, 2004, BIOINFORMATICS, V28, P208; Li LX, 2004, BIOINFORMATICS, V20, P3406, DOI 10.1093/bioinformatics/bth415; Little R., 2002, STAT ANAL MISSING DA; Ma S, 2006, BIOMETRICS, V62, P202, DOI 10.1111/j.1541-0420.2005.00405.x; MILLER RG, 1976, BIOMETRIKA, V63, P449, DOI 10.1093/biomet/63.3.449; Nan B, 2005, BIOMETRICS, V61, P576, DOI 10.1111/j.1541-0420.2005.030905.x; OSULLIVAN F, 1988, SIAM J SCI STAT COMP, V9, P531, DOI 10.1137/0909035; PARK MY, 2006, REGULARIZATIONPATH A; Prentice R. L., 2002, STAT ANAL FAILURE TI; RITOV Y, 1990, ANN STAT, V18, P303, DOI 10.1214/aos/1176347502; Rosset S, 2004, J MACH LEARN RES, V5, P941; SCHNEIDER H, 1986, BIOMETRIKA, V73, P741; SUSARLA V, 1980, ANN STAT, V8, P1002, DOI 10.1214/aos/1176345138; SUSARLA V, 1984, BIOMETRIKA, V71, P624; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; TSIATIS AA, 1990, ANN STAT, V18, P354, DOI 10.1214/aos/1176347504; WEI LJ, 1992, STAT MED, V11, P1871, DOI 10.1002/sim.4780111409; WEI LJ, 1990, BIOMETRIKA, V77, P845, DOI 10.1093/biomet/77.4.845; YING ZL, 1993, ANN STAT, V21, P76, DOI 10.1214/aos/1176349016; Yu MG, 2006, LIFETIME DATA ANAL, V12, P345, DOI 10.1007/s10985-006-9014-0; ZOU H, 2005, DEGREES FREEDOM LASS	40	18	18	1	1	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	MAR	2008	64	1					132	140		10.1111/j.1541-0420.2007.00877.x		9	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	269EL	WOS:000253632200015	17680828	
J	Zou, H				Zou, Hui			A note on path-based variable selection in the penalized proportional hazards model	BIOMETRIKA			English	Article						adaptive path; lasso; oracle property; penalized partial likelihood; smoothly-clipped-absolute deviation penalty; variable selection	ORACLE PROPERTIES; LASSO; REGRESSION; ASYMPTOTICS; LIKELIHOOD	We propose an efficient and adaptive shrinkage method for variable selection in the Cox model. The method constructs a piecewise-linear regularization path connecting the maximum partial likelihood estimator and the origin. Then a model is selected along the path. We show that the constructed path is adaptive in the sense that, with a proper choice of regularization parameter, the fitted model works as well as if the true underlying submodel were given in advance. A modified algorithm of the least-angle-regression type efficiently computes the entire regularization path of the new estimator. Furthermore, we show that, with a proper choice of shrinkage parameter, the method is consistent in variable selection and efficient in estimation. Simulation shows that the new method tends to outperform the lasso and the smoothly-clipped-absolute-deviation estimators with moderate samples. We apply the methodology to data concerning nursing homes.	Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	Zou, H (reprint author), Univ Minnesota, Sch Stat, 224 Church St SE, Minneapolis, MN 55455 USA.	hzou@stat.umn.edu					ANDERSEN PK, 1982, ANN STAT, V10, P1100, DOI 10.1214/aos/1176345976; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; COX DR, 1975, BIOMETRIKA, V62, P269, DOI 10.1093/biomet/62.2.269; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Cai JW, 2005, BIOMETRIKA, V92, P303, DOI 10.1093/biomet/92.2.303; COX DR, 1972, J R STAT SOC B, V34, P187; Fan JQ, 2002, ANN STAT, V30, P74; GEYER CJ, 1994, ANN STAT, V22, P1993, DOI 10.1214/aos/1176325768; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Morris C.N., 1994, WILEY S PRO, P231; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Zhu J., 2004, ADV NEURAL INFORM PR, V16; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	18	23	24	0	5	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0006-3444			BIOMETRIKA	Biometrika	MAR	2008	95	1					241	247		10.1093/biomet/asm083		7	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	270UU	WOS:000253746500017		
J	Hilario, M; Kalousis, A				Hilario, Melanie; Kalousis, Alexandros			Approaches to dimensionality reduction in proteomic biomarker studies	BRIEFINGS IN BIOINFORMATICS			English	Article						proteomics; mass spectra; biomarkers; dimensionality reduction; feature transformation; feature selection	MASS-SPECTROMETRY DATA; LASER DESORPTION/IONIZATION-TIME; SPECTRAL SERUM PROFILES; FEATURE-SELECTION; GENE-EXPRESSION; OVARIAN-CANCER; PROSTATE-CANCER; DISEASE CLASSIFICATION; SAMPLE CLASSIFICATION; LOGISTIC-REGRESSION	Mass-spectra based proteomic profiles have received widespread attention as potential tools for biomarker discovery and early disease diagnosis. A major data-analytical problem involved is the extremely high dimensionality (i.e. number of features or variables) of proteomic data, in particular when the sample size is small. This article reviews dimensionality reduction methods that have been used in proteomic biomarker studies. It then focuses on the problem of selecting the most appropriate method for a specific task or dataset, and proposes method combination as a potential alternative to single-method selection. Finally, it points out the potential of novel dimension reduction techniques, in particular those that incorporate domain knowledge through the use of informative priors or causal inference.	[Hilario, Melanie] Univ Geneva, Artificial Intelligence Lab, CH-1211 Geneva 4, Switzerland	Hilario, M (reprint author), Univ Geneva, Dept Comp Sci, Battelle Bat 7,Route Drize, CH-1227 Carouge, Switzerland.	Melanie.Hilario@cui.unige.ch					Achlioptas D, 2001, P ACM S PRINC DAT SY, P274, DOI DOI 10.1109/TIT.2006.885507; Adam BL, 2002, CANCER RES, V62, P3609; Aliferis C F, 2003, AMIA Annu Symp Proc, P21; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Li LP, 2004, BIOINFORMATICS, V20, P1638, DOI 10.1093/bioinformatics/bth098; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Dorigo M, 1999, ARTIF LIFE, V5, P137, DOI 10.1162/106454699568728; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Geurts P, 2005, BIOINFORMATICS, V21, P3138, DOI 10.1093/bioinformatics/bti494; Zhang XG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-1-197; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Kalousis A, 2007, KNOWL INF SYST, V12, P95, DOI 10.1007/s10115-006-0040-8; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Banez LL, 2003, J UROLOGY, V170, P442, DOI 10.1097/01.ju.0000069431.95404.56; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Baggerly KA, 2003, PROTEOMICS, V3, P1667, DOI 10.1002/pmic.200300522; BERTONI A, 2007, BMC BIOINFORMATIC S3, V8, P7; Bhanot G, 2006, PROTEOMICS, V6, P592, DOI 10.1002/pmic.200500192; Bhattacharyya C, 2003, SIGNAL PROCESS, V83, P729, DOI 10.1016/S0165-1684(02)00474-7; Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI 10.1145/502512.502546; Bishop C., 2006, PATTERN RECOGNITION; BOULESTEIX AL, 2006, BRIEF BIOINFORM, V8, P32, DOI 10.1093/bib/bbl016; Breiman L., 1984, CLASSIFICATION REGRE; CHAN D, 2007, COMPUTATIONAL METHOD, P377; Dai JJ, 2006, STAT APPL GENET MOL, V5; Dietterich T. G., 2000, MULTIPLE CLASSIFIER; DOMENICONI C, 2002, ADV NEURAL INFORM PR; Duda RO, 2000, PATTERN CLASSIFICATI, P117; Dutkowski J., 2007, BMC BIOINFORM S5, V8, P5; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman N., 2000, P 4 ANN INT C COMP M, P127, DOI 10.1145/332306.332355; GOLDBERGER A, 2005, ADV NEURAL INFORM PR; GUYON I, 2003, P BISCFLINT CIBI 200; GUYON I, 2006, FEATURE EXTRACTION F, P1; Guyon I., 2007, COMPUTATIONAL METHOD, P63; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hastie T., 2001, ELEMENTS STAT LEARNI; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hilario M, 2003, PROTEOMICS, V3, P1716, DOI 10.1002/pmic.200300523; Hillel A., 2003, P 20 INT C MACH LEAR, P11; HOLLAND JH, 1992, ADAPTATION NATURAL A; JOHNSON WB, 1982, P C MODERN ANAL PROB, P189; Jong K, 2004, PROCEEDINGS OF THE 2004 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P41; KENNEDY J, 1995, P IEEE INT C NEUR NE, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kira K, 1992, P 10 NAT C ART INT, P129; Kohonen T., 1995, SELF ORG MAPS; Kozak KR, 2003, P NATL ACAD SCI USA, V100, P12343, DOI 10.1073/pnas.2033602100; KRZANOWSKI WJ, 1995, APPL STAT-J ROY ST C, V44, P101, DOI 10.2307/2986198; Lee KR, 2003, PROTEOMICS, V3, P1680, DOI 10.1002/pmic.200300515; Levner I, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-68; Li LH, 2004, ARTIF INTELL MED, V32, P71, DOI 10.1016/j.artmed.2004.03.006; Lilien RH, 2003, J COMPUT BIOL, V10, P925, DOI 10.1089/106652703322756159; Liu Huiqing, 2002, Genome Inform, V13, P51; Liu ZQ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1248; Ng A. Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435; Oh Jung Hun, 2005, Genome Inform, V16, P195; Papadopoulos MC, 2004, LANCET, V363, P1358, DOI 10.1016/S0140-6736(04)16046-7; Pratapa P., 2006, PAC S BIOCOMPT, V11, P279; Purohit PV, 2003, PROTEOMICS, V3, P1699, DOI 10.1002/pmic.200300518; Qu YS, 2002, CLIN CHEM, V48, P1835; Qu YS, 2003, BIOMETRICS, V59, P143, DOI 10.1111/1541-0420.00017; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; RESSOM H, 2005, P 2005 C GEN EV COMP, P431, DOI 10.1145/1068009.1068078; Ressom HW, 2005, BIOINFORMATICS, V21, P4039, DOI 10.1093/bioinformatics/bti670; Ressom HW, 2007, BIOINFORMATICS, V23, P619, DOI 10.1093/bioinformatics/btl678; REUNANEN J, 2006, FEATURE EXTRACTION F; Rogers MA, 2003, CANCER RES, V63, P6971; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Sima C, 2006, BIOINFORMATICS, V22, P2430, DOI 10.1093/bioinformatics/btl407; Simon R, 2003, SIGKDD EXPLORATIONS, V5, P31; Soltys SG, 2004, CLIN CANCER RES, V10, P4806, DOI 10.1158/1078-0432.CCR-03-0469; Somol P, 1999, PATTERN RECOGN LETT, V20, P1157, DOI 10.1016/S0167-8655(99)00083-5; Somorjai RL, 2003, BIOINFORMATICS, V19, P1484, DOI 10.1093/bioinformatics/btg182; Sorace JM, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-24; Sun Y., 2006, P 23 INT C MACH LEAR, P913, DOI 10.1145/1143844.1143959; Thomas J. A., 1991, ELEMENTS INFORM THEO; Tsamardinos I., 2003, P 16 INT FLOR ART IN, P376; TUKEY JW, 1993, CONTROL CLIN TRIALS, V14, P266, DOI 10.1016/0197-2456(93)90225-3; Tuv E, 2006, FEATURE EXTRACTION F, P187; Wagner M, 2003, PROTEOMICS, V3, P1692, DOI 10.1002/pmic.200300519; Weinberger K., 2006, ADV NEURAL INFORM PR; Won Y, 2003, PROTEOMICS, V3, P2310, DOI 10.1002/pmic.200300590; Wu BL, 2003, BIOINFORMATICS, V19, P1636, DOI 10.1093/bioinformatics/btg210; Xing E., 2001, P 18 INT C MACH LEAR, P601; Xing E, 2003, ADV NEURAL INFORM PR, P505; Yanagisawa K, 2003, LANCET, V362, P433, DOI 10.1016/S0140-6736(03)14068-8; Yasui Y, 2003, BIOSTATISTICS, V4, P449, DOI 10.1093/biostatistics/4.3.449; Yu JS, 2005, BIOINFORMATICS, V21, P2200, DOI 10.1093/bioinformatics/bti370; Zhu J., 2004, ADV NEURAL INFORM PR, P16; ZOU H, 2007, COMPUTATIONAL METHOD, P393	97	43	45	0	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463			BRIEF BIOINFORM	Brief. Bioinform.	MAR	2008	9	2					102	118		10.1093/bib/bbn005		17	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	284CI	WOS:000254682400002	18310106	
J	You, JH; Xu, QF; Zhou, B				You, Jinhong; Xu, Qinfeng; Zhou, Bin			Statistical inference for partially linear regression models with measurement errors	CHINESE ANNALS OF MATHEMATICS SERIES B			English	Article						partially linear model; measurement error; bandwidth selection; goodness-of-fit test; oracle property	NONCONCAVE PENALIZED LIKELIHOOD; IN-VARIABLES MODELS; SEMIPARAMETRIC REGRESSION; CONVERGENCE-RATES; SELECTION; ESTIMATORS	In this paper, the authors investigate three aspects of statistical inference for the partially linear regression models where some covariates are measured with errors. Firstly, a bandwidth selection procedure is proposed, which is a combination of the difference-based technique and GCV method. Secondly, a goodness-of-fit test procedure is proposed, which is an extension of the generalized likelihood technique. Thirdly, a variable selection procedure for the parametric part is provided based on the nonconcave penalization and corrected profile least squares. Same as "Variable selection via nonconcave penalized likelihood and its oracle properties" (J. Amer. Statist. Assoc., 96, 2001, 1348 - 1360), it is shown that the resulting estimator has an oracle property with a proper choice of regularization parameters and penalty function. Simulation studies are conducted to illustrate the finite sample performances of the proposed procedures.	[You, Jinhong] Univ N Carolina, Dept Biostat, Chapel Hill, NC 27599 USA; [Zhou, Bin] E China Normal Univ, Dept Stat, Shanghai 200062, Peoples R China	Xu, QF (reprint author), Fudan Univ, Sch Math Sci, Shanghai 200433, Peoples R China.	qfxu@fudan.edu.cn					ENGLE RF, 1986, J AM STAT ASSOC, V81, P310, DOI 10.2307/2289218; BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Hamilton SA, 1997, J MULTIVARIATE ANAL, V60, P1, DOI 10.1006/jmva.1996.1642; Bickel PJ, 2001, STAT SINICA, V11, P863; Cai JW, 2005, BIOMETRIKA, V92, P303, DOI 10.1093/biomet/92.2.303; Carroll R, 1995, MEASUREMENT ERROR NO; CHEN H, 1988, ANN STAT, V16, P136, DOI 10.1214/aos/1176350695; CHEN H, 1991, J STAT PLAN INFER, V27, P187, DOI 10.1016/0378-3758(91)90015-7; CHEN H, 1994, ANN STAT, V22, P211, DOI 10.1214/aos/1176325366; Cheng CL, 2004, J AM STAT ASSOC, V99, P805, DOI 10.1198/016214504000001141; Cui HJ, 1998, J MULTIVARIATE ANAL, V64, P1; DONALD SG, 1994, J MULTIVARIATE ANAL, V50, P30, DOI 10.1006/jmva.1994.1032; EUBANK RL, 1990, J MULTIVARIATE ANAL, V32, P70, DOI 10.1016/0047-259X(90)90072-P; Fan JQ, 2001, ANN STAT, V29, P153, DOI 10.1214/aos/996986505; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2002, ANN STAT, V30, P74; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; Hardle W., 1990, APPL NONPARAMETRIC R; Hardle W, 2000, PARTIALLY LINEAR MOD; HWANG JT, 1986, J AM STAT ASSOC, V81, P680, DOI 10.2307/2288996; Iturria SJ, 1999, J ROY STAT SOC B, V61, P547, DOI 10.1111/1467-9868.00192; Liang H, 2000, J STAT PLAN INFER, V86, P51, DOI 10.1016/S0378-3758(99)00093-2; Liang H, 1999, ANN STAT, V27, P1519; RICE J, 1986, STAT PROBABIL LETT, V4, P203, DOI 10.1016/0167-7152(86)90067-2; ROBINSON PM, 1988, ECONOMETRICA, V56, P931, DOI 10.2307/1912705; SHI PD, 1995, STATISTICS, V26, P27, DOI 10.1080/02331889508802465; SPECKMAN P, 1988, J ROY STAT SOC B MET, V50, P413; Xu QF, 2007, COMMUN STAT-THEOR M, V36, P375, DOI 10.1080/03610920600974765; Zhu LX, 2003, SCAND J STAT, V30, P429, DOI 10.1111/1467-9469.00340	34	4	4	20	33	SHANGHAI SCIENTIFIC TECHNOLOGY LITERATURE PUBLISHING HOUSE	SHANGHAI	SHANGHAI, PEOPLES R CHINA	0252-9599	1860-6261		CHINESE ANN MATH B	Chin. Ann. Math. Ser. B	MAR	2008	29	2					207	222		10.1007/s11401-006-0210-8		16	Mathematics	Mathematics	274SS	WOS:000254021900009		
J	Candes, EJ; Wakin, MB				Candes, Emmanuel J.; Wakin, Michael B.			An introduction to compressive sampling	IEEE SIGNAL PROCESSING MAGAZINE			English	Article							SIGNAL RECOVERY; UNCERTAINTY PRINCIPLES; PURSUIT		[Candes, Emmanuel J.] CALTECH, Pasadena, CA 91125 USA	Candes, EJ (reprint author), CALTECH, Pasadena, CA 91125 USA.	emmanuel@acm.caltech.edu; wakin@umich.edu	Wakin, Michael/G-1582-2012; Magazine, Signal Processing/E-9947-2015				Candes E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vetterli M, 2002, IEEE T SIGNAL PROCES, V50, P1417, DOI 10.1109/TSP.2002.1003065; Haupt J, 2006, IEEE T INFORM THEORY, V52, P4036, DOI 10.1109/TIT.2006.880031; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; BARANIUK RG, UNPUB SIMPLE PROOF R; Baron D., 2005, DISTRIBUTED COMPRESS; Blahut R.E., 2003, ALGEBRAIC CODES DATA; CANDES E, UNPUB STAT ESTIMATIO; Candes E. J., 2007, LECT COMPRESSIVE SAM; Candes E.J., 2007, ENHANCING SPARSITY R; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; Cohen A., 2006, COMPRESSED SENSING B; Coifman R, 2001, APPL COMPUT HARMON A, V10, P27, DOI 10.1006/acha.2000.0313; DONOHO DL, 1989, SIAM J APPL MATH, V49, P906, DOI 10.1137/0149053; FENG P, 1996, P IEEE INT C AC SPEE, V2, P1689; GILBERT A, 2005, P WAVELETS 11 SPIE O; Lustig M, 2006, P 14 ANN M ISMRM SEA; Marcellin M. W., 2001, JPEG 2000 IMAGE COMP; MENDELSON S, 2006, UNIFORM UNCERTAINTY; RUDELSON M, UNPUB SPARSE RECONST; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; Takhar D., 2006, P COMP IM 4 SPIE EL	30	1946	2215	52	228	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-5888			IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	MAR	2008	25	2					21	30		10.1109/MSP.2007.914731		10	Engineering, Electrical & Electronic	Engineering	281BL	WOS:000254471100005		
J	Li, YJ; Zhu, J				Li, Youjuan; Zhu, Ji			L-1-norm quantile regression	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						effective dimension; LASSO; linear programming; L-1-norm penalty; variable selection	MODEL SELECTION; SURVIVAL; LASSO; ERROR	Classical regression methods have focused mainly on estimating conditional mean functions. In recent years, however, quantile regression has emerged as a comprehensive approach to the statistical analysis of response models. In this article we consider the L-1-norm (LASSO) regularized quantile regression (L-1-norm QR), which uses the sum of the absolute values of the coefficients as the penalty. The L-1-norm penalty has the advantage of simultaneously controlling the variance of the fitted coefficients and performing automatic variable selection. We propose an efficient algorithm that computes the entire solution path of the L-1-norm QR. Furthermore, we derive an estimate for the effective dimension of the L-1-norm QR model, which allows convenient selection of the regularization parameter.	[Li, Youjuan; Zhu, Ji] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA	Li, YJ (reprint author), Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA.	jizhu@umich.edu					Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Koenker R, 2001, J AM STAT ASSOC, V96, P458, DOI 10.1198/016214501753168172; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Redfern CH, 2000, P NATL ACAD SCI USA, V97, P4826, DOI 10.1073/pnas.97.9.4826; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Friedman J, 2004, ANN STAT, V32, P102; Efron B, 2004, ANN STAT, V32, P407; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; COLE TJ, 1992, STAT MED, V11, P1305, DOI 10.1002/sim.4780111005; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; Heagerty PJ, 1999, J ROY STAT SOC C-APP, V48, P533, DOI 10.1111/1467-9876.00170; HENDRICKS W, 1992, J AM STAT ASSOC, V87, P58, DOI 10.2307/2290452; Koenker R, 2001, J ECON PERSPECT, V15, P143, DOI 10.1257/jep.15.4.143; KOENKER R, 1994, BIOMETRIKA, V81, P673; Leng CL, 2006, STAT SINICA, V16, P1273; Li YJ, 2007, J AM STAT ASSOC, V102, P255, DOI 10.1198/016214506000000979; Meyer M, 2000, ANN STAT, V28, P1083; Nychka D, 1995, J AM STAT ASSOC, V90, P1171, DOI 10.2307/2291509; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; Yang S, 1999, J AM STAT ASSOC, V94, P137, DOI 10.2307/2669689; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609; YUAN M, 2006, COMPUTATIONAL STAT D, V5, P813	26	51	52	3	8	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	MAR	2008	17	1					163	185		10.1198/106186008X289155		23	Statistics & Probability	Mathematics	275FG	WOS:000254056700009		
J	Elliott, G; Timmermann, A				Elliott, Graham; Timmermann, Allan			Economic forecasting	JOURNAL OF ECONOMIC LITERATURE			English	Review							MACROECONOMIC TIME-SERIES; BAYESIAN VECTOR AUTOREGRESSIONS; EXCHANGE-RATE; PREDICTIVE ABILITY; ASYMMETRIC LOSS; LINEAR-MODELS; REGRESSION MODELS; ERROR-CORRECTION; NEURAL-NETWORKS; BUSINESS-CYCLE	Forecasts guide decisions in all areas of economics and finance and their value can only be understood in relation to, and in the context Of such decisions. We discuss the central role of the loss function in helping determine the forecaster's objectives. Decision theory provides a framework for both the construction and evaluation of forecasts. This framework allows an understanding of the challenges that arise from the explosion in the sheer volume of predictor variables under consideration and the forecaster's ability to entertain an endless array of forecasting models and time-varying specifications, none of which may coincide with the "true" model. We show this along with reviewing methods for comparing the forecasting performance of pairs Of models or evaluating the ability of the best of many models to beat a benchmark specification.	[Elliott, Graham] Univ Calif San Diego, San Diego, CA 92103 USA	Elliott, G (reprint author), Univ Calif San Diego, San Diego, CA 92103 USA.						Amato JD, 2001, J MONETARY ECON, V48, P3, DOI 10.1016/S0304-3932(01)00070-8; Andersen TG, 2006, HBK ECON, V24, P777, DOI 10.1016/S1574-0706(05)01015-3; Ang A, 2002, J BUS ECON STAT, V20, P163, DOI 10.1198/073500102317351930; KADIYALA KR, 1993, J FORECASTING, V12, P365; Terasvirta T, 2006, HBK ECON, V24, P413, DOI 10.1016/S1574-0706(05)01008-6; BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Clark TE, 2001, J ECONOMETRICS, V105, P85, DOI 10.1016/S0304-4076(01)00071-9; Batchelor R, 1998, ECON LETT, V61, P49, DOI 10.1016/S0165-1765(98)00157-8; DIEBOLD FX, 1991, J AM STAT ASSOC, V86, P603, DOI 10.2307/2290388; Garcia R, 1996, REV ECON STAT, V78, P111, DOI 10.2307/2109851; HAMILTON JD, 1989, ECONOMETRICA, V57, P357, DOI 10.2307/1912559; KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; ZELLNER A, 1986, J AM STAT ASSOC, V81, P446, DOI 10.2307/2289234; KEANE MP, 1990, AM ECON REV, V80, P714; Giacomini R, 2006, ECONOMETRICA, V74, P1545, DOI 10.1111/j.1468-0262.2006.00718.x; Romer CD, 2000, AM ECON REV, V90, P429, DOI 10.1257/aer.90.3.429; Schorfheide F, 2005, J ECONOMETRICS, V128, P99, DOI 10.1016/j.jeconom.2004.08.009; Marcellino M, 2006, J ECONOMETRICS, V135, P499, DOI 10.1016/j.jeconom.2005.07.020; LEITCH G, 1991, AM ECON REV, V81, P580; Stock JH, 1996, J BUS ECON STAT, V14, P11, DOI 10.2307/1392096; Raftery AE, 1997, J AM STAT ASSOC, V92, P179, DOI 10.2307/2291462; Tay AS, 2000, J FORECASTING, V19, P235, DOI 10.1002/1099-131X(200007)19:4<235::AID-FOR772>3.3.CO;2-C; DAVIES A, 1995, J ECONOMETRICS, V68, P205, DOI 10.1016/0304-4076(94)01649-K; Hansen PR, 2005, J BUS ECON STAT, V23, P365, DOI 10.1198/07350010500000063; Diebold FX, 1998, INT ECON REV, V39, P863, DOI 10.2307/2527342; SIMS CA, 1980, ECONOMETRICA, V48, P1, DOI 10.2307/1912017; Stock JH, 2002, J BUS ECON STAT, V20, P147, DOI 10.1198/073500102317351921; Ottaviani M, 2006, J FINANC ECON, V81, P441, DOI 10.1016/j.jfineco.2005.08.002; Inoue A, 2006, J ECONOMETRICS, V130, P273, DOI 10.1016/j.jeconom.2005.03.003; CHONG YY, 1986, REV ECON STUD, V53, P671, DOI 10.2307/2297611; Christoffersen PF, 1997, ECONOMET THEOR, V13, P808; Corradi V, 2002, J ECONOMETRICS, V110, P353, DOI 10.1016/S0304-4076(02)00099-4; Bai JS, 1998, ECONOMETRICA, V66, P47, DOI 10.2307/2998540; DIEBOLD FX, 1995, J BUS ECON STAT, V13, P253, DOI 10.2307/1392185; ENGLE RF, 1987, ECONOMETRICA, V55, P251, DOI 10.2307/1913236; Sullivan R, 1999, J FINANC, V54, P1647, DOI 10.1111/0022-1082.00163; West KD, 1996, ECONOMETRICA, V64, P1067, DOI 10.2307/2171956; Kilian L, 1999, J APPL ECONOM, V14, P491, DOI 10.1002/(SICI)1099-1255(199909/10)14:5<491::AID-JAE527>3.0.CO;2-D; Patton AJ, 2007, J AM STAT ASSOC, V102, P1172, DOI 10.1198/016214506000001176; Chauvet M, 1998, INT ECON REV, V39, P969, DOI 10.2307/2527348; West KD, 1998, INT ECON REV, V39, P817, DOI 10.2307/2527340; Svensson LEO, 1997, EUR ECON REV, V41, P1111, DOI 10.1016/S0014-2921(96)00055-4; White H, 2000, ECONOMETRICA, V68, P1097, DOI 10.1111/1468-0262.00152; Elliott G, 2005, REV ECON STUD, V72, P1107, DOI 10.1111/0034-6527.00363; Makridakis S, 2000, INT J FORECASTING, V16, P451, DOI 10.1016/S0169-2070(00)00057-1; BATES JM, 1969, OPER RES QUART, V20, P451, DOI 10.2307/3008764; ZELLNER A, 1989, J ECONOMETRICS, V40, P183, DOI 10.1016/0304-4076(89)90036-5; Kadiyala KR, 1997, J APPL ECONOM, V12, P99; Forni M, 2000, REV ECON STAT, V82, P540, DOI 10.1162/003465300559037; Artis M., 2001, ECONOMET J, V4, pS20; Bai J, 1997, REV ECON STAT, V79, P551, DOI 10.1162/003465397557132; BATCHELOR R, 1991, J MONEY CREDIT BANK, V23, P692, DOI 10.2307/1992704; Box G. E. P., 1970, TIME SERIES ANAL FOR; Brayton F., 1996, FINANCE EC DISCUSSIO, V96-42; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BROWN BW, 1981, ECONOMETRICA, V49, P491, DOI 10.2307/1913322; CAMPBELL B, 1995, REV ECON STAT, V77, P17, DOI 10.2307/2109989; CAPISTRAN CC, 2006, 200614 BANC MEX; Christoffersen P, 2004, J FINANC ECON, V72, P291, DOI 10.1016/j.jfineco.2003.02.001; Christoffersen PF, 2006, MANAGE SCI, V52, P1273, DOI 10.1287/mnsc.1060.0520; CLARK TE, 2007, RWP0706 FED RES BANK; CLARK TE, 2004, 0403 RWP FED RES BAN; CLEMEN RT, 1989, INT J FORECASTING, V5, P559, DOI 10.1016/0169-2070(89)90012-5; Clements M., 1998, FORECASTING EC TIME; Clements MP, 2006, HBK ECON, V24, P605, DOI 10.1016/S1574-0706(05)01012-8; Clements M.P., 2002, ECONOMET J, V5, P319, DOI 10.1111/1368-423X.00086; Corradi V, 2006, HBK ECON, V24, P197, DOI 10.1016/S1574-0706(05)01005-0; Corradi V, 2006, J ECONOMETRICS, V135, P187, DOI 10.1016/j.jeconom.2005.07.026; CORRADI V, 2007, INT ECON REV, V48, P97; Croushore D, 2003, REV ECON STAT, V85, P605, DOI 10.1162/003465303322369759; Croushore D, 2006, HBK ECON, V24, P961, DOI 10.1016/S1574-0706(05)01017-7; Del Negro M, 2007, J BUS ECON STAT, V25, P123, DOI 10.1198/073500107000000016; Diebold FX, 1996, REV ECON STAT, V78, P67, DOI 10.2307/2109848; Diebold FX, 2000, J BUS ECON STAT, V18, P265, DOI 10.2307/1392260; Doan TA, 1984, ECONOMET REV, V3, P1, DOI DOI 10.1080/07474938408800053; Ehrbeck T, 1996, Q J ECON, V111, P21, DOI 10.2307/2946656; Elliott G, 2004, J ECONOMETRICS, V122, P47, DOI 10.1016/j.jeconom.2003.10.019; ELLIOTT G, 2006, UNPUB BIASES MACROEC; Elliott G, 2006, REV ECON STUD, V73, P907, DOI 10.1111/j.1467-937X.2006.00402.x; Elliott G, 2005, INT ECON REV, V46, P1081, DOI 10.1111/j.1468-2354.2005.00361.x; ELLIOTT G, 2005, UNPUB FORECASTING PR; ELLIOTT G, 2006, UNPUB PREDICTING BIN; FIGLEWSKI S, 1981, REV ECON STAT, V63, P1, DOI 10.2307/1924211; FORNI M, 2002, 3432 CEPR; Franses PH, 2005, INT J FORECASTING, V21, P87, DOI 10.1016/j.ijforecast.2004.05.005; GALLANT AR, 1981, J ECONOMETRICS, V15, P211, DOI 10.1016/0304-4076(81)90115-9; GEWCKE J, 2006, HDB EC FORECASTING, P3; Geweke J, 2005, WILEY SER PROBAB ST, P1, DOI 10.1002/0471744735; GRANGER CWJ, 1969, OPER RES QUART, V20, P199, DOI 10.2307/3008559; Granger C. W. J., 1999, SPAN ECON REV, V1, P161; Granger C.W., 1986, FORECASTING EC TIME, V2nd; Granger CWJ, 2006, HBK ECON, V24, P81, DOI 10.1016/S1574-0706(05)01002-5; GRANGER CWJ, 1966, ECONOMETRICA, V34, P150, DOI 10.2307/1909859; Granger CWJ, 2000, J FORECASTING, V19, P537, DOI 10.1002/1099-131X(200012)19:7<537::AID-FOR769>3.3.CO;2-7; GUIDOLIN M, IN PRESS J ECONOMETR; Guidolin M, 2006, J APPL ECONOM, V21, P1, DOI 10.1002/jae.824; Hong H, 2003, J FINANC, V58, P313, DOI 10.1111/1540-6261.00526; Harrison J., 1997, BAYESIAN FORECASTING; HARVEY A, 1993, J AM STAT ASSOC, V88, P1228, DOI 10.2307/2291261; Harvey A, 2006, HBK ECON, V24, P327, DOI 10.1016/S1574-0706(05)01007-4; Harvey DI, 1998, J BUS ECON STAT, V16, P254, DOI 10.2307/1392581; Hendry DF, 2004, ELECT STUD, V23, P525, DOI 10.1016/j.electstud.2004.05.002; Hyndman RJ, 2008, SPRINGER SER STAT, P3; INOUE A, IN PRESS J AM STAT A; ITO T, 1990, AM ECON REV, V80, P434; Jagannathan R, 2003, J FINANC, V58, P1651, DOI 10.1111/1540-6261.00580; KILIAN L, 2006, UNPUB CENTRAL BANKER; Kilian Lutz, 2004, ECONOMET REV, V23, P371, DOI DOI 10.1081/ETC-200040785; Kim Chang-Jin, 1999, STATE SPACE MODELS R; KOOP GM, IN PRESS REV EC STUD; Learner EE, 1978, SPECIFICATION SEARCH; Ledoit 0., 2003, J EMPIR FINANC, V10, P603, DOI DOI 10.1016/S0927-5398(03)00007-0; Lim T, 2001, J FINANC, V56, P369, DOI 10.1111/0022-1082.00329; LITTERMAN RB, 1986, J BUS ECON STAT, V4, P25, DOI 10.2307/1391384; Litterman R. B., 1980, BAYESIAN PROCEDURE F; Lopez RH, 2001, GRANUL MATTER, V3, P69, DOI 10.1007/PL00010888; LUDVIGSON SC, 2005, UNPUB MACRO FACTORS; Ludvigson SC, 2007, J FINANC ECON, V83, P171, DOI 10.1016/j.jfineco.2005.12.002; Mamaysky H., 2007, REV FINANC, V11, P359, DOI 10.1093/rof/rfm018; Marcellino M, 2004, OXFORD B ECON STAT, V66, P91, DOI 10.1111/j.1468-0084.2004.00071.x; MEESE RA, 1983, J INT ECON, V14, P3, DOI 10.1016/0022-1996(83)90017-X; Miller A, 2002, SUBSET SELECTION REG, V2nd; Mincer J., 1969, EC FORECASTS EXPECTA, P14; MISHKIN FS, 1981, AM ECON REV, V71, P295; NELSON CR, 1982, J MONETARY ECON, V10, P139, DOI 10.1016/0304-3932(82)90012-5; PAGAN A, 2003, BANK ENGLAND Q B, V43, P60; PALM FC, 1992, J FORECASTING, V11, P687, DOI 10.1002/for.3980110806; PATTON AJ, 1977, J ECONOMETRICS, V140, P884; Paye B., 2006, J EMPIR FINANC, V13, P274, DOI DOI 10.1016/J.JEMPFIN.2005.11.001; Perez-Quiros G, 2000, J FINANC, V55, P1229, DOI 10.1111/0022-1082.00246; Pesaran H, 2005, ECONOMET THEOR, V21, P212, DOI 10.1017/S0266466605050139; PESARAN M, 1965, J ECONOMETRICS, V129, P183; Pesaran MH, 2006, HBK ECON, V24, P715, DOI 10.1016/S1574-0706(05)01014-1; Pesaran MH, 2006, REV ECON STUD, V73, P1057; Pesaran MH, 2007, J ECONOMETRICS, V137, P134, DOI 10.1016/j.jeconom.2006.03.010; Pesaran MH, 2002, COMPANION EC FORECAS, P241; NEWEY WK, 1987, ECONOMETRICA, V55, P819, DOI 10.2307/1911031; Psaradakis Z, 2005, J FORECASTING, V24, P119, DOI 10.1002/for.946; Racine J, 2001, J BUS ECON STAT, V19, P380, DOI 10.1198/073500101681019927; Rapach D. E., 2006, J FINANCIAL ECONOMET, V4, P238, DOI DOI 10.1093/JJFINEC/NBJ008; Robertson J.C., 1999, FEDERAL RESERVE BANK, V84, P4; ROSSI B, 2006, 0601 DUK U DEP EC; Rossi B, 2006, MACROECON DYN, V10, P20, DOI 10.1017/S136510050505008X; Sarno L, 2002, IMF STAFF PAPERS, V49, P65; SATCHELL S, 1995, J FORECASTING, V14, P477, DOI 10.1002/for.3980140602; SCHARFSTEIN DS, 1990, AM ECON REV, V80, P465; Siliverstovs B, 2004, J FORECASTING, V23, P315, DOI 10.1002/for.925; Simss C., 2002, BROOKINGS PAPERS EC, V2, P1; SKOURAS S, 2001, 0111064 SANT FE I; Stein C., 1961, P 4 BERK S MATH STAT, V1, P361; Stock J. H., 1999, COINTEGRATION CAUSAL, P1; Stock JH, 1999, J MONETARY ECON, V44, P293, DOI 10.1016/S0304-3932(99)00027-6; STOCK JH, 2005, UNPUB EMPIRICAL COMP; STOCK JH, 1998, J AM STAT ASSOC, V93, P441; SWANSON NR, 1995, J BUS ECON STAT, V13, P265, DOI 10.2307/1392186; Terasvirta T, 2005, INT J FORECASTING, V21, P755, DOI 10.1016/j.ijforecast.2005.04.010; Timmermann A, 2007, IMF STAFF PAPERS, V54, P1, DOI 10.1057/palgrave.imfsp.9450007; Timmermann A, 2006, HBK ECON, V24, P135, DOI 10.1016/S1574-0706(05)01004-9; TRUEMAN B, 1994, REV FINANC STUD, V7, P97, DOI 10.1093/rfs/7.1.97; van Dijk D., 2003, ECONOMET J, V6, P79, DOI 10.1111/1368-423X.00103; Varian H. R., 1974, STUDIES BAYESIAN ECO, P195; Waggoner DF, 1999, REV ECON STAT, V81, P639, DOI 10.1162/003465399558508; Weiss AA, 1996, J APPL ECONOM, V11, P539, DOI 10.1002/(SICI)1099-1255(199609)11:5<539::AID-JAE412>3.3.CO;2-9; WEST KD, 1993, J INT ECON, V35, P23, DOI 10.1016/0022-1996(93)90003-G; White H., 2001, ASYMPTOTIC THEORY EC; Whitemans CH, 1996, FORECASTING PREDICTI, P149; ZARNOWITZ V, 1985, J BUS ECON STAT, V3, P293, DOI 10.2307/1391715	168	61	64	1	20	AMER ECONOMIC ASSOC	NASHVILLE	2014 BROADWAY, STE 305, NASHVILLE, TN 37203 USA	0022-0515	2328-8175		J ECON LIT	J. Econ. Lit.	MAR	2008	46	1					3	56		10.1257/jel.46.1.3		54	Economics	Business & Economics	282SF	WOS:000254586800002		
J	Xie, XC; Geng, Z				Xie, Xianchao; Geng, Zhi			A recursive method for structural learning of directed acyclic graphs	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						Bayesian network; conditional independence; decomposition; directed acyclic graph; structural learning	BAYESIAN NETWORKS; PROBABILISTIC NETWORKS; SELECTION; ALGORITHM; LASSO; DECOMPOSITION; SEARCH; MODELS	In this paper, we propose a recursive method for structural learning of directed acyclic graphs (DAGs), in which a problem of structural learning for a large DAG is first decomposed into two problems of structural learning for two small vertex subsets, each of which is then decomposed recursively into two problems of smaller subsets until none subset can be decomposed further. In our approach, search for separators of a pair of variables in a large DAG is localized to small subsets, and thus the approach can improve the efficiency of searches and the power of statistical tests for structural learning. We show how the recent advances in the learning of undirected graphical models can be employed to facilitate the decomposition. Simulations are given to demonstrate the performance of the proposed method.	[Xie, Xianchao; Geng, Zhi] Peking Univ, LMAM, Sch Math Sci, Beijing 100871, Peoples R China	Xie, XC (reprint author), Peking Univ, LMAM, Sch Math Sci, Beijing 100871, Peoples R China.	XXIE@FAS.HARVARD.EDU; ZGENG@MATH.PKU.EDU.CN					ALIFERIS CF, 2003, 2003 INT C MATH ENG; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Kalisch M, 2007, J MACH LEARN RES, V8, P613; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Abramson B, 1996, INT J FORECASTING, V12, P57, DOI 10.1016/0169-2070(95)00664-8; Richardson T, 2002, ANN STAT, V30, P962; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Chickering DM, 2004, J MACH LEARN RES, V5, P1287; ARNBORG S, 1987, SIAM J ALGEBRA DISCR, V8, P277, DOI 10.1137/0608024; Becker A, 2001, ARTIF INTELL, V125, P3, DOI 10.1016/S0004-3702(00)00075-8; Beinlich I, 1989, P 2 EUR C ART INT ME, P247; Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; Castelo R, 2006, J MACH LEARN RES, V7, P2621; Cowell R. G., 1999, PROBABILISTIC NETWOR; Engelhardt B.E., 2006, P 23 INT C MACH LEAR, P297, DOI 10.1145/1143844.1143882; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N., 1999, P 15 C UNC ART INT U, P206; Geng Z, 2005, J MULTIVARIATE ANAL, V96, P282, DOI 10.1016/j.jmva.2004.10.012; HECKERMAN D, 1998, TUTORIAL LEARNING BA, P301; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Jensen F. V., 1994, P 10 C UNC ART INT, P360; Koller D., 1996, P 13 INT C MACH LEAR, P284; Lauritzen S. L., 1996, GRAPHICAL MODELS; Margaritis D., 1999, P NEUR INF PROC SYST, P505; Meek C., 1995, P 11 C UNC ART INT, P403; Murphy K, 2001, COMPUTER SCI STAT, V33, P331; NARASIMHAN M, 2005, ADV NEURAL INFORM PR, V17, P961; Pearl J., 2000, CAUSALITY; Rose D. J., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205021; SCHMIDT M, 2007, P ASS ADV ART INT AA, P1278; Spirtes P., 2000, CAUSATION PREDICTION; Spirtes P., 1991, Social Science Computer Review, V9, DOI 10.1177/089443939100900106; TARJAN RE, 1984, SIAM J COMPUT, V13, P566, DOI 10.1137/0213035; TSAMARDINOS I, 2003, P 16 INT FLAIRS C, P592; Verma T., 1990, P 6 ANN C UNC ART IN, P255; Wainwright M., 2006, P 12 ADV NEUR INF PR, P1465; Whittaker J, 1990, GRAPHICAL MODELS APP; WILKS SS, 1938, ANN MATH STAT, V20, P595; Wille A, 2006, STAT APPL GENET MOL, V5; Xie XC, 2006, ARTIF INTELL, V170, P422, DOI 10.1016/j.artint.2005.12.004	47	22	23	3	10	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAR	2008	9						459	483				25	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312AR	WOS:000256642000004		
J	Banerjee, O; El Ghaoui, L; d'Aspremont, A				Banerjee, Onureena; El Ghaoui, Laurent; d'Aspremont, Alexandre			Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						model selection; maximum likelihood estimation; convex optimization; Gaussian graphical model; binary data	MINIMIZATION; GRAPHS; LASSO	We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse. Our approach is to solve a maximum likelihood problem with an added l(1)-norm penalty term. The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes. We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case. Our first algorithm uses block coordinate descent, and can be interpreted as recursive l(1)-norm penalized regression. Our second algorithm, based on Nesterov's first order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods. Using a log determinant relaxation of the log partition function (Wainwright and Jordan, 2006), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case. We test our algorithms on synthetic data, as well as on gene expression and senate voting records data.	[Banerjee, Onureena; El Ghaoui, Laurent] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; [d'Aspremont, Alexandre] Princeton Univ, ORFE Dept, Princeton, NJ 08544 USA	Banerjee, O (reprint author), Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA.	ONUREENA@EECS.BERKELEY.EDU; ELGHAOUI@EECS.BERKELEY.EDU; ASPREMON@PRINCETON.EDU					Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Bickel PJ, 2008, ANN STAT, V36, P199, DOI 10.1214/009053607000000758; Ashburner M, 2000, NAT GENET, V25, P25; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Bertsekas D. P., 1998, NONLINEAR PROGRAMMIN; DAHL J, 2007, OPTIMIZATIO IN PRESS; d'Aspremont A., 2004, ADV NEURAL INFORM PR, V17; Dobra A., 2004, BAYESIAN COVARIANCE; Friedman J., 2007, BIOSTATISTICS; Lauritzen S. L., 1996, GRAPHICAL MODELS; LI H, 2005, GRADIENT DIRECTED RE; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; Natsoulis G, 2005, GENOME RES, V15, P724, DOI 10.1101/gr.2807605; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; SPEED TP, 1986, ANN STAT, V14, P138, DOI 10.1214/aos/1176349846; Tibshirani R, 1996, J ROYAL STAT SOC B, V58; WAINWRIGHT M, 2006, IEEE T SIGNAL PROCES; WAINWRIGHT M, 2006, P ADV NEUR INF PROC	20	220	223	4	18	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAR	2008	9						485	516				32	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312AR	WOS:000256642000005		
J	Joseph, VR; Hung, Y; Sudjianto, A				Joseph, V. Roshan; Hung, Ying; Sudjianto, Agus			Blind kriging: a new method for developing metamodels	JOURNAL OF MECHANICAL DESIGN			English	Article						computer experiments; design optimization; cross validation; finite element models; kriging; metamodels; variable selection	COMPUTER EXPERIMENTS; DESIGNED EXPERIMENTS; VARIABLE-SELECTION; UNCERTAINTY; REGRESSION; MODELS; PREDICTION; SIMULATION	Kriging is a useful method for developing metamodels for product design optimization. The most popular kriging method, known as ordinary kriging, uses a constant mean in, the model. In this article, a modified kriging method is proposed, which has an unknown mean model. Therefore, it is called blind kriging. The unknown mean model is identified from experimental data using a Bayesian variable selection technique. Many examples are presented, which show remarkable improvement in prediction using blind kriging over ordinary kriging. Moreover, a blind kriging predictor is easier to interpret and seems to be more robust against mis-specification in the correlation parameters.	[Joseph, V. Roshan; Hung, Ying] Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA; [Sudjianto, Agus] Bank Amer, Charlotte, NC 28255 USA	Joseph, VR (reprint author), Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA.	roshan@isye.gatech.edu					BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yang RJ, 2005, J MECH DESIGN, V127, P1014, DOI 10.1115/1.1906264; SACKS J, 1989, TECHNOMETRICS, V31, P41, DOI 10.2307/1270363; Martin JD, 2005, AIAA J, V43, P853, DOI 10.2514/1.8650; WELCH WJ, 1992, TECHNOMETRICS, V34, P15, DOI 10.2307/1269548; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Efron B, 2004, ANN STAT, V32, P407; Jin R, 2001, STRUCT MULTIDISCIP O, V23, P1; Apley DW, 2006, J MECH DESIGN, V128, P945, DOI 10.1115/1.2204974; Cappelleri DJ, 2002, J MECH DESIGN, V124, P354, DOI 10.1115/1.1446866; Chen W, 2005, J MECH DESIGN, V127, P875, DOI 10.1115/1.1904642; Chipman H, 1997, TECHNOMETRICS, V39, P372, DOI 10.2307/1271501; CURRIN C, 1991, J AM STAT ASSOC, V86, P953, DOI 10.2307/2290511; Fang KT, 2006, CH CRC COMP SCI DATA, P3; HAMADA M, 1992, J QUAL TECHNOL, V24, P130; Hoffman R. M., 2003, 2003010148 SAE; Jeff Wu CF, 2000, EXPT PLANNING ANAL P; Joseph VR, 2006, TECHNOMETRICS, V48, P458, DOI 10.1198/004017006000000011; Joseph VR, 2007, TECHNOMETRICS, V49, P1, DOI 10.1198/004017006000000372; Joseph VR, 2006, TECHNOMETRICS, V48, P219, DOI 10.1198/004017005000000652; Li RZ, 2005, TECHNOMETRICS, V47, P111, DOI 10.1198/004017004000000671; Martin JD, 2006, J MECH DESIGN, V128, P959, DOI 10.1115/1.2204975; Miller A, 2002, SUBSET SELECTION REG, V2nd; MORRIS MD, 1993, TECHNOMETRICS, V35, P243, DOI 10.2307/1269517; Pacheco JE, 2003, J MECH DESIGN, V125, P664, DOI 10.1115/1.1631580; Qian ZG, 2006, J MECH DESIGN, V128, P668, DOI 10.1115/1.2179459; Sacks J., 1989, STAT SCI, V4, P409, DOI DOI 10.1214/SS/1177012413; Santner TJ, 2003, DESIGN ANAL COMPUTER; Sasena MJ, 2005, J MECH DESIGN, V127, P1006, DOI 10.1115/1.1906247; WACKERNAGEL H, 2002, MULTIVARIATIVE GEOST	31	26	28	7	17	ASME	NEW YORK	TWO PARK AVE, NEW YORK, NY 10016-5990 USA	1050-0472			J MECH DESIGN	J. Mech. Des.	MAR	2008	130	3							031102	10.1115/1.2829873		8	Engineering, Mechanical	Engineering	276MA	WOS:000254144900003		
J	Kokshenev, I; Braga, AP				Kokshenev, Illya; Braga, Antonio Padua			A multi-objective approach to RBF network learning	NEUROCOMPUTING			English	Article; Proceedings Paper	15th European Symposium on Artificial Neural Networks	APR, 2007	Brugge, BELGIUM			multi-objective learning; generalization; regularization; complexity; radial basis functions	NEURAL-NETWORKS; ALGORITHMS	The problem of inductive supervised learning is discussed in this paper within the context of multi-objective (MOBJ) optimization. The smoothness-based apparent (effective) complexity measure for RBF networks is considered. For the specific case of RBF network, bounds on the complexity measure are formally described. As the synthetic and real-world data experiments show, the proposed MOBJ learning method is capable of efficient generalization control along with network size reduction. (c) 2008 Elsevier B.V. All rights reserved.	[Kokshenev, Illya; Braga, Antonio Padua] Univ Fed Minas Gerais, Dept Engn Eletron, BR-30161970 Belo Horizonte, MG, Brazil	Kokshenev, I (reprint author), Univ Fed Minas Gerais, Dept Engn Eletron, Av Antonio Carlos,6-627 Campus UFMG Pampulha, BR-30161970 Belo Horizonte, MG, Brazil.	illya.kokshenev@gmail.com; apbraga@cpdee.ufmg.br	Braga, Antonio/A-2912-2008	Braga, Antonio/0000-0002-9007-0920			Adams Robert A., 2003, SOBOLEV SPACES; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; Asuncion A., 2007, UCI MACHINE LEARNING; Bartlett PL, 1997, ADV NEUR IN, V9, P134; Braga AP, 2006, STUD COMP INTELL, V16, P151; COSTA MA, 2006, INT JOINT C NEIR VAN, P6344; Costa MA, 2003, NEUROCOMPUTING, V51, P467, DOI 10.1016/S0925-2312(02)00697-5; EFRON B, 2002, LEAST ANGLE REGRESSI; JIN Y, 2006, MULTI OBJECTIVE MACH, V16; JIN Y, 2004, CEC2004 C, V1, P1; LIU G, 2003, MULTIOBJECTIVE OPTIR; MacQueen J. B., 1967, P 5 BERK S MATH STAT, P281; PRECHELT L, 1994, 2194; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; Teixeira RD, 2000, NEUROCOMPUTING, V35, P189, DOI 10.1016/S0925-2312(00)00327-1; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1035; TIKLIONOV AN, 1977, SOLUTIONS 3 POSED PR; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V., 1974, THEORY PATTERN RECOG	21	16	16	2	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	MAR	2008	71	7-9					1203	1209		10.1016/j.neucom.2007.11.021		7	Computer Science, Artificial Intelligence	Computer Science	292AQ	WOS:000255239200009		
J	Binder, H; Tutz, G				Binder, Harald; Tutz, Gerhard			A comparison of methods for the fitting of generalized additive models	STATISTICS AND COMPUTING			English	Article						generalized additive models; selection of smoothness; variable selection; boosting; mixed model approach	SMOOTHING PARAMETER-ESTIMATION; REGRESSION; SELECTION; SPLINES; LIKELIHOOD	There are several procedures for fitting generalized additive models, i.e. regression models for an exponential family response where the influence of each single covariates is assumed to have unknown, potentially non-linear shape. Simulated data are used to compare a smoothing parameter optimization approach for selection of smoothness and of covariates, a stepwise approach, a mixed model approach, and a procedure based on boosting techniques. In particular it is investigated how the performance of procedures is linked to amount of information, type of response, total number of covariates, number of influential covariates, and extent of non-linearity. Measures for comparison are prediction performance, identification of influential covariates, and smoothness of fitted functions. One result is that the mixed model approach returns sparse fits with frequently over-smoothed functions, while the functions are less smooth for the boosting approach and variable selection is less strict. The other approaches are in between with respect to these measures. The boosting procedure is seen to perform very well when little information is available and/or when a large number of covariates is to be investigated. It is somewhat surprising that in scenarios with low information the fitting of a linear model, even with stepwise variable selection, has not much advantage over the fitting of an additive model when the true underlying structure is linear. In cases with more information the prediction performance of all procedures is very similar. So, in difficult data situations the boosting approach can be recommended, in others the procedures can be chosen conditional on the aim of the analysis.	[Binder, Harald] Univ Freiburg Klinikum, Inst Med Biometrie & Med Informat, D-79104 Freiburg, Germany; [Tutz, Gerhard] Univ Munich, Inst Stat, Munich, Germany	Binder, H (reprint author), Univ Freiburg Klinikum, Inst Med Biometrie & Med Informat, Stefan Meier Str 26, D-79104 Freiburg, Germany.	binderh@fdm.uni-freiburg.de	Binder, Harald/C-7413-2009	Binder, Harald/0000-0002-5666-8662			Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Ruppert D, 2002, J COMPUT GRAPH STAT, V11, P735, DOI 10.1198/106186002853; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Wood SN, 2004, J AM STAT ASSOC, V99, P673, DOI 10.1198/016214504000000980; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Friedman J, 2004, ANN STAT, V32, P102; BINDER H, 2006, FITTING GEN ADDITIVE; Chambers JM, 1992, STAT MODELS; FREIDMAN JH, 2001, ANN STAT, V29, P1189; FREIDMAN JH, 1981, J AM STAT ASSOC, V76, P817; Green P, 1994, NONPARAMETRIC REGRES; Hurvich CM, 1998, J ROY STAT SOC B, V60, P271, DOI 10.1111/1467-9868.00125; Kim YJ, 2004, J ROY STAT SOC B, V66, P337, DOI 10.1046/j.1369-7412.2003.05316.x; Lee TCM, 2003, COMPUT STAT DATA AN, V42, P139, DOI 10.1016/S0167-9473(02)00159-7; Lindstrom MJ, 1999, J COMPUT GRAPH STAT, V8, P333, DOI 10.2307/1390640; Linton OB, 1996, BIOMETRIKA, V83, P529, DOI 10.1093/biomet/83.3.529; Marx BD, 1998, COMPUT STAT DATA AN, V28, P193, DOI 10.1016/S0167-9473(98)00033-4; MCCULLAGH P, 2006, GEN LINEAR MODELS; *R DEV COR TEAM, 2006, LANG ENV STAT COMP F; Ruppert D., 2003, SEMIPARAMETRIC REGRE; Speed TP, 1991, STAT SCI, V6, P42, DOI 10.1214/ss/1177011930; Tibshirani R., 1986, STAT SCI, V3, P295; Tutz G, 2006, BIOMETRICS, V62, P961, DOI 10.1111/j.1541-0420.2006.00578.x; Wand MP, 2000, COMPUTATION STAT, V15, P443, DOI 10.1007/s001800000047; Wang YD, 1998, J ROY STAT SOC B, V60, P159, DOI 10.1111/1467-9868.00115; Wood SN, 2000, J ROY STAT SOC B, V62, P413, DOI 10.1111/1467-9868.00240; Wood SN, 2006, GEN ADDITIVE MODELS	29	10	10	2	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0960-3174			STAT COMPUT	Stat. Comput.	MAR	2008	18	1					87	99		10.1007/s11222-007-9040-0		13	Computer Science, Theory & Methods; Statistics & Probability	Computer Science; Mathematics	240XA	WOS:000251620300008		
J	Iasonos, A; Schrag, D; Raj, GV; Panageas, KS				Iasonos, Alexia; Schrag, Deborah; Raj, Ganesh V.; Panageas, Katherine S.			How to build and interpret a nomogram for cancer prognosis	JOURNAL OF CLINICAL ONCOLOGY			English	Article; Proceedings Paper	43rd Annual Meeting of the American-Society-of-Clinical-Oncology	JUN 01-05, 2007	Chicago, IL	Amer Soc Clin Oncol			PROSTATE-CANCER; BLADDER-CANCER; SURVIVAL; VALIDATION; RISK; RECURRENCE; PREDICTION; DISCRIMINATION; REGRESSION; SELECTION	Nomograms are widely used for cancer prognosis, primarily because of their ability to reduce statistical predictive models into a single numerical estimate of the probability of an event, such as death or recurrence, that is tailored to the profile of an individual patient. User-friendly graphical interfaces for generating these estimates facilitate the use of nomograms during clinical encounters to inform clinical decision making. However, the statistical underpinnings of these models require careful scrutiny, and the degree of uncertainty surrounding the point estimates requires attention. This guide provides a nonstatistical audience with a methodological approach for building, interpreting, and using nomograms to estimate cancer prognosis or other health outcomes.	Mem Sloan Kettering Canc Ctr, Dept Epidemiol & Biostat, New York, NY 10021 USA; Univ Texas Dallas, SW Med Ctr, Dept Urol, Dallas, TX USA	Iasonos, A (reprint author), Mem Sloan Kettering Canc Ctr, Dept Epidemiol & Biostat, 307 E 63rd St,3rd Floor, New York, NY 10021 USA.	iasonosa@mskcc.org					Alran S, 2007, ANN SURG ONCOL, V14, P2195, DOI 10.1245/s10434-006-9331-2; Pencina MJ, 2004, STAT MED, V23, P2109, DOI 10.1002/sim.1802; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Freedman AN, 2005, J NATL CANCER I, V97, P715; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Kattan MW, 2006, J UROLOGY, V175, P2103, DOI 10.1016/S0022-5347(06)00313-2; Karakiewicz PI, 2007, J CLIN ONCOL, V25, P1316, DOI 10.1200/JCO.2006.06.1218; Ohori M, 2004, J UROLOGY, V171, P1844, DOI 10.1097/01.ju.0000121693.05077.3d; Barker L, 2001, STAT MED, V20, P1431, DOI 10.1002/sim.680; Bochner BH, 2006, J CLIN ONCOL, V24, P3967, DOI 10.1200/JCO.2005.05.3884; Cowen ME, 2006, J UROLOGY, V175, P99, DOI 10.1016/S0022-5347(05)00018-2; Diblasio CJ, 2003, UROLOGY, V62, P9, DOI 10.1016/j.urology.2003.09.029; Eastham James A, 2002, Semin Urol Oncol, V20, P108, DOI 10.1053/suro.2002.32936; Efron B, INTRO BOOTSTRAP; Ferrone CR, 2005, J CLIN ONCOL, V23, P7529, DOI 10.1200/JCO.2005.01.8101; Harrell FE, 2001, REGRESSION MODELING; Kattan MW, 2003, CURR OPIN UROL, V13, P111, DOI 10.1097/01.mou.0000058631.64616.54; Mariani L, 2005, CANCER, V103, P402, DOI 10.1002/cncr.20778; Neter J, 1990, APPL LINEAR STAT MOD, V3rd; Raj GV, 2007, J UROLOGY, V177, P53, DOI 10.1016/j.juro.2006.08.067; Roach M, 2006, J UROLOGY, V176, pS16, DOI 10.1016/j.juro.2006.06.081; Sorbellini M, 2006, J UROLOGY, V176, P472, DOI 10.1016/j.juro.2006.03.090; Stephenson AJ, 2005, J CLIN ONCOL, V23, P7005, DOI 10.1200/JCO.2005.01.867; Sternberg CN, 2006, J CLIN ONCOL, V24, P3819, DOI 10.1200/JCO.2006.07.1290; Steyerberg EW, 2007, J UROLOGY, V177, P107, DOI 10.1016/j.juro.2006.08.068; Van Steen K, 2002, STAT MED, V21, P3865, DOI 10.1002/sim.1358; Wang L, 2006, RADIOLOGY, V238, P597, DOI 10.1148/radiol.2382041905; White RR, 2006, ANN SURG ONCOL, V13, P1485, DOI 10.1245/s10434-006-9104-y; Wierda WG, 2007, BLOOD, V109, P4679, DOI 10.1182/blood-2005-12-051458; Wong SL, 2005, ANN SURG ONCOL, V12, P282, DOI 10.1245/ASO.2005.05.016	30	131	132	5	17	AMER SOC CLINICAL ONCOLOGY	ALEXANDRIA	330 JOHN CARLYLE ST, STE 300, ALEXANDRIA, VA 22314 USA	0732-183X			J CLIN ONCOL	J. Clin. Oncol.	MAR 10	2008	26	8					1364	1370		10.1200/JCO.2007.12.9791		7	Oncology	Oncology	276XZ	WOS:000254178300028	18323559	
J	Bastien, P				Bastien, Philippe			Deviance residuals based PLS regression for censored data in high dimensional setting	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article; Proceedings Paper	9th Annual Chemometrics Congress	NOV 30-DEC 01, 2006	Paris, FRANCE	CNRS, Soc Francaise Stat, Federat Francaise Sci Chim, Soc Chim Ind	Ecole Natl Superaleure Chim Paris	PLS; LARS; Lasso; Cox; deviance residuals; kernel; regularization	PARTIAL LEAST-SQUARES; GENE-EXPRESSION DATA; B-CELL LYMPHOMA; KERNEL ALGORITHM; SELECTION; SURVIVAL; LASSO	The PLS Cox regression has been proposed in the framework of PLS generalized linear regression as an alternative to the Cox model when dealing with highly correlated covariates. However, in high dimensional settings the algorithm becomes computer-intensive and a more efficient algorithm must be used. In this article we propose an alternative both faster and easier to carry out by the direct use of standard procedures which are available in most statistical softwares. Recently, Segal suggested a solution to the Cox-Lasso algorithm when dealing with high dimensional data. Following Segal, we propose a Deviance Residuals based PLS regression (PLSDR) as an alternative to the PLS-Cox model in high dimensional settings. The PLSDR algorithm only needs to carry out null deviance residuals using a simple intercept Cox model and use these as outcome in a standard PLS regression. This algorithm which can be extended to kernels to deal with non-linearity can also be viewed as a variable selection method in a threshold penalized formulation. An application carried out on gene expression from patients with diffuse large B-cell lymphoma shows the practical interest of using deviance residuals as outcomes in PLS regression when dealing with very many descriptors and censored data. (C) 2007 Elsevier B.V. All rights reserved.	LOreal Rech Aulnay, F-92583 Clichy, France	Bastien, P (reprint author), LOreal Rech Aulnay, 90 Rue Gen Roguet, F-92583 Clichy, France.	pbastien@rd.loreal.com					Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; RANNAR S, 1994, J CHEMOMETR, V8, P111, DOI 10.1002/cem.1180080204; Efron B, 2004, ANN STAT, V32, P407; LINDGREN F, 1993, J CHEMOMETR, V7, P45, DOI 10.1002/cem.1180070104; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Barros AS, 2004, CHEMOMETR INTELL LAB, V73, P245, DOI 10.1016/j.chemolab.2004.03.007; Bastien P, 2004, P COMPSTAT 04, P655; BASTIEN P, 2001, CISIA CERESTA, P131; Bastien P, 2005, COMPUT STAT DATA AN, V48, P17, DOI 10.1016/j.csda.2004.02.005; BENNETT E, 2003, NATO SCI SERIES, V3, P227; Collett D., 1994, MODELLING SURVIVAL D; COX DR, 1972, J R STAT SOC B, V34, P187; DEJONG S, 1994, J CHEMOMETR, V8, P169, DOI 10.1002/cem.1180080208; Friedman JH, 2004, GRADIENT DIRECTED RE; GARTHWAITE PH, 1994, J AM STAT ASSOC, V89, P122, DOI 10.2307/2291207; Hastie TJ, 1990, GEN ADDITIVE MODELS; HEAGERTY P, 2003, WORKING PAPER SERIES, V219; Li H., 2003, PAC S BIOC, P65; Rosipal R., 2001, J MACHINE LEARNING R, V2, P97; Segal MR, 2006, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; Tenenhaus A, 2007, COMPUT STAT DATA AN, V51, P4083, DOI 10.1016/j.csda.2007.01.004; Tenenhaus M., 1998, REGRESSION PLS; TENENHAUS M, 1999, FES, P721; THEMEAU TM, 1990, BIOMETRIKA, V77, P147; Therneau TM, 2000, MODELING SURVIVAL DA; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; VINZI VE, 2001, CISIA CERESTA, P117; Wold H., 1966, MULTIVARIATE ANAL, P391; WOLD S, 1982, LECT NOTES MATH, P286	30	1	1	2	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	MAR 15	2008	91	1					78	86		10.1016/j.chemolab.2007.09.009		9	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	286BD	WOS:000254819400010		
J	Tian, GL; Tang, ML; Fang, HB; Tan, M				Tian, Guo-Liang; Tang, Man-Lai; Fang, Hong-Bin; Tan, Ming			Efficient methods for estimating constrained parameters with applications to regularized (lasso) logistic regression	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							MAXIMUM-LIKELIHOOD-ESTIMATION; EM ALGORITHM; ECM ALGORITHM; OPTIMIZATION	Fitting logistic regression models is challenging when their parameters are restricted. In this article, we first develop a quadratic lower-bound QLB) algorithm for optimization with box or linear inequality constraints and derive the fastest QLB algorithm corresponding to the smallest global majorization matrix. The proposed QLB algorithm is particularly suited to problems to which the EM-type algorithms are not applicable (e.g., logistic, multinomial logistic, and Cox's proportional hazards models) while it retains the same EM ascent property and thus assures the monotonic convergence. Secondly, we generalize the QLB algorithm to penalized problems in which the penalty functions may not be totall, differentiable. The proposed method thus provides an alternative algorithm for estimation in lasso logistic regression, where the convergence of the existing lasso algorithm is not generally ensured. Finally, by relaxing the ascent requirement, convergence speed can be further accelerated. We introduce a pseudo-Newton method that retains the simplicity of the QLB algorithm and the fast convergence of the Newton method. Theoretical justification and numerical examples show that the pseudo-Newton method is up to 71 (in terms of CPU time) or 107 (in terms of number of iterations) times faster than the fastest QLB algorithm and thus makes bootstrap variance estimation feasible. Simulations and comparisons are performed and three real examples (Down syndrome data, kyphosis data, and colon microarray data) are analyzed to illustrate the proposed methods. (c) 2007 Elsevier B.V. All rights reserved.	[Tian, Guo-Liang; Fang, Hong-Bin; Tan, Ming] Univ Maryland, Greenebaum Canc Ctr, Div Biostat, Baltimore, MD 21201 USA; [Tang, Man-Lai] Hong Kong Baptist Univ, Dept Math, Kowloon, Hong Kong, Peoples R China	Tian, GL (reprint author), Univ Maryland, Greenebaum Canc Ctr, Div Biostat, 10 S Pine St,MSTF Suite 261, Baltimore, MD 21201 USA.	gtian2@umm.edu	Tang, Man /B-4326-2009; Tian, Guoliang/D-3128-2009; HKBU, Mathematics/B-5086-2009; 	Tang, Man Lai/0000-0001-6460-8136			Agresti A., 2002, CATEGORICAL DATA ANA; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; MENG XL, 1991, J AM STAT ASSOC, V86, P899, DOI 10.2307/2290503; Efron B, 2004, ANN STAT, V32, P407; Meng XL, 1997, J ROY STAT SOC B MET, V59, P511, DOI 10.1111/1467-9868.00082; CRAVEN P, 1979, NUMER MATH, V31, P377; BARLOW RE, 1972, J AM STAT ASSOC, V67, P140, DOI 10.2307/2284712; BOHNING D, 1992, ANN I STAT MATH, V44, P197, DOI 10.1007/BF00048682; BOHNING D, 1988, ANN I STAT MATH, V40, P641, DOI 10.1007/BF00049423; Collett D, 1991, MODELING BINARY DATA; DYKSTRA RL, 1983, J AM STAT ASSOC, V78, P837, DOI 10.2307/2288193; Efron B, 1993, INTRO BOOTSTRAP; FESSLER JA, 1993, IEEE T NUCL SCI, V40, P1055, DOI 10.1109/23.256712; GEYER CJ, 1991, J AM STAT ASSOC, V86, P717, DOI 10.2307/2290403; Gilks WR, 1996, MARKOV CHAIN MONTE C, P75; GREEN PJ, 1990, J ROY STAT SOC B MET, V52, P443; Hastie TJ, 1990, GEN ADDITIVE MODELS; HOOK EB, 1978, TERATOLOGY, V17, P223, DOI 10.1002/tera.1420170303; KHURI AI, 1976, COMMUN STAT B, V5, P82; Kim Y, 2006, COMPUT STAT DATA AN, V51, P1643, DOI 10.1016/j.csda.2006.06.007; Liu CH, 2000, J AM STAT ASSOC, V95, P109, DOI 10.2307/2669531; Mehta CR, 2000, J AM STAT ASSOC, V95, P99, DOI 10.2307/2669530; MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.2307/2337198; MENG XL, 1994, ANN STAT, V22, P326, DOI 10.1214/aos/1176325371; Meyer MC, 1999, J STAT PLAN INFER, V81, P13, DOI 10.1016/S0378-3758(99)00025-7; Oakes D., 1984, ANAL SURVIVAL DATA; Robertson T, 1988, ORDER RESTRICTED STA; SCHMOYER RL, 1984, J AM STAT ASSOC, V79, P448, DOI 10.2307/2288289; Silvapulle M. J., 2005, CONSTRAINED STAT INF; TAN M, 2003, DEV MODERN STAT RELA, P53; Tan M, 2007, STAT SINICA, V17, P945	35	7	7	1	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAR 15	2008	52	7					3528	3542		10.1016/j.csda.2007.11.007		15	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	290TU	WOS:000255145900018		
J	Hsu, NJ; Hung, HL; Chang, YM				Hsu, Nan-Jung; Hung, Hung-Lin; Chang, Ya-Mei			Subset selection for vector autoregressive processes using Lasso	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							TIME-SERIES MODELS; ORACLE PROPERTIES; MULTIVARIATE; REGRESSION; SHRINKAGE	A subset selection method is proposed for vector autoregressive (VAR) processes using the Lasso [Tibshirani, R. (1996). Regression shrinkage and selection via the Lasso. Journal of the Royal Statistical Society, Series B 58, 267-288] technique. Simply speaking, Lasso is a shrinkage method in a regression setup which selects the model and estimates the parameters simultaneously. Compared to the conventional information-based methods such as AIC and BIC, the Lasso approach avoids computationally intensive and exhaustive search. On the other hand, compared to the existing subset selection methods with parameter constraints such as the top-down and bottom-up strategies, the Lasso method is computationally efficient and its result is robust to the order of series included in the autoregressive model. We derive the asymptotic theorem for the Lasso estimator under VAR processes. Simulation results demonstrate that the Lasso method performs better than several conventional subset selection methods for small samples in terms of prediction mean squared errors and estimation errors under various settings. The methodology is applied to modeling U.S. macroeconomic data for illustration. (c) 2007 Elsevier B.V. All rights reserved.	[Hsu, Nan-Jung; Hung, Hung-Lin; Chang, Ya-Mei] Natl Tsing Hua Univ, Inst Stat, Hsinchu, Taiwan	Hsu, NJ (reprint author), Natl Tsing Hua Univ, Inst Stat, Hsinchu, Taiwan.	njhsu@stat.nthu.edu.tw	Chang, Ya-Mei/E-6763-2010				AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Anderson T. W., 1971, STAT ANAL TIME SERIE; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Krolzig HM, 2001, J ECON DYN CONTROL, V25, P831, DOI 10.1016/S0165-1889(00)00058-0; TIAO GC, 1981, J AM STAT ASSOC, V76, P802, DOI 10.2307/2287575; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Bruggemann R., 2001, ECONOMETRIC STUDIES, P107; BRUGGEMANN R, 2004, LECT NOTES EC MATH S; Chen CH, 1996, J MULTIVARIATE ANAL, V57, P175, DOI 10.1006/jmva.1996.0028; Fuller W. A, 1996, INTRO STAT TIME SERI; HOSKING JRM, 1980, J AM STAT ASSOC, V75, P602, DOI 10.2307/2287656; HOSKING JRM, 1981, J ROY STAT SOC B MET, V43, P219; HSIAO C, 1979, J AM STAT ASSOC, V74, P553, DOI 10.2307/2286972; Li H, 1998, J AM STAT ASSOC, V93, P770, DOI 10.2307/2670127; LI WK, 1981, J ROY STAT SOC B MET, V43, P231; Lutkepohl H., 1991, INTRO MULTIPLE TIME; NIU XF, 1995, J AM STAT ASSOC, V90, P969, DOI 10.2307/2291333; Penm J, 1982, J TIME SER ANAL, V3, P43, DOI 10.1111/j.1467-9892.1982.tb00329.x; PENM JHW, 1984, J ECONOMETRICS, V24, P311, DOI 10.1016/0304-4076(84)90056-3; PENM JHW, 1992, J BUS ECON STAT, V10, P213, DOI 10.2307/1391679; Tsay R. S., 2002, ANAL FINANCIAL TIME; Wang HS, 2007, J ROY STAT SOC B, V69, P63	26	23	24	2	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAR 15	2008	52	7					3645	3657		10.1016/j.csda.2007.12.004		13	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	290TU	WOS:000255145900025		
J	Nott, DJ				Nott, David J.			Predictive performance of Dirichlet process shrinkage methods in linear regression	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							NONPARAMETRIC PROBLEMS; VARIABLE SELECTION; BAYESIAN MODEL; PRIORS; MIXTURES; LASSO	An obvious Bayesian nonparametric generalization of ridge regression assumes that coefficients are exchangeable, from a prior distribution of unknown form, which is given a Dirichlet process prior with a normal base measure. The purpose of this paper is to explore predictive performance of this generalization, which does not seem to have received any detailed attention, despite related applications of the Dirichlet process for shrinkage estimation in multivariate normal means, analysis of randomized block experiments and nonparametric extensions of random effects models in longitudinal data analysis. We consider issues of prior specification and computation, as well as applications in penalized spline smoothing. With a normal base measure in the Dirichlet process and letting the precision parameter approach infinity the procedure is equivalent to ridge regression, whereas for finite values of the precision parameter the discreteness of the Dirichlet process means that some predictors can be estimated as having the same coefficient. Estimating the precision parameter from the data gives a flexible method for shrinkage estimation of mean parameters which can work well when ridge regression does, but also adapts well to sparse situations. We compare our approach with ridge regression, the lasso and the recently proposed elastic net in simulation studies and also consider applications to penalized spline smoothing. (C) 2007 Elsevier B.V. All rights reserved.	Natl Univ Singapore, Dept Stats & Appl Probabail, Singapore 117546, Singapore	Nott, DJ (reprint author), Natl Univ Singapore, Dept Stats & Appl Probabail, Singapore 117546, Singapore.	standj@nus.edu.sg					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Raftery AE, 1997, J AM STAT ASSOC, V92, P179, DOI 10.2307/2291462; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Kohn R, 2001, STAT COMPUT, V11, P313, DOI 10.1023/A:1011916902934; BLACKWEL.D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Breiman L, 1996, ANN STAT, V24, P2350; Bush CA, 1996, BIOMETRIKA, V83, P275, DOI 10.1093/biomet/83.2.275; ESCOBAR MD, 1994, J AM STAT ASSOC, V89, P268, DOI 10.2307/2291223; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; GILKS WR, 1998, M CHAIN MONTE CARLO; Kleinman KP, 1998, BIOMETRICS, V54, P921, DOI 10.2307/2533846; Leslie DS, 2007, STAT COMPUT, V17, P131, DOI 10.1007/s11222-006-9013-8; LO AY, 1984, ANN STAT, V12, P351, DOI 10.1214/aos/1176346412; MacEachern SN, 1998, J COMPUT GRAPH STAT, V7, P223, DOI 10.2307/1390815; MACEACHERN SN, 1994, COMMUN STAT SIMULAT, V23, P727, DOI 10.1080/03610919408813196; Miller A. J., 1990, SUBSET SELECTION REG; Muller P, 1997, J AM STAT ASSOC, V92, P1279, DOI 10.2307/2965398; Park MY, 2007, BIOSTATISTICS, V8, P212, DOI 10.1093/biostatistics/kxl002; Ruppert D., 2003, SEMIPARAMETRIC REGRE; Smith M, 1996, J ECONOMETRICS, V75, P317, DOI 10.1016/0304-4076(95)01763-1	27	3	3	2	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAR 15	2008	52	7					3658	3669		10.1016/j.csda.2007.12.005		12	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	290TU	WOS:000255145900026		
J	Huang, J; Horowitz, JL; Ma, SG				Huang, Jian; Horowitz, Joel L.; Ma, Shuangge			Asymptotic properties of bridge estimators in sparse high-dimensional regression models	ANNALS OF STATISTICS			English	Article						penalized regression; high-dimensional data; variable selection; asymptotic normality; oracle property	NONCONCAVE PENALIZED LIKELIHOOD; 2-WAY SEMILINEAR MODEL; MICROARRAY DATA; VARIABLE SELECTION; LASSO; CONSISTENCY; PARAMETERS; NORMALIZATION; BEHAVIOR; P2/N	We Study the asymptotic properties of bridge estimators in sparse, high-dimensional, linear regression models when the number of covariates may increase to infinity with the sample size. We are particularly interested in the use of bridge estimators to distinguish between covariates whose coefficients are zero and covariates whose coefficients are nonzero. We show that under appropriate conditions, bridge estimators correctly select covariates with nonzero coefficients with probability converging to one and that the estimators of nonzero coefficients have the same asymptotic distribution that they would have if the zero coefficients were known in advance. Thus, bridge estimators have an oracle property in the sense of Fan and Li [J. Amer. Statist. Assoc. 96 (2001) 1348-1360] and Fan and Peng [Ann. Statist. 32 (2004) 928-961]. In general, the oracle property holds only if the number of covariates is smaller than the sample size. However, under a partial orthogonality condition in which the covariates of the zero coefficients are uncorrelated or weakly correlated with the covariates of nonzero coefficients, we show that marginal bridge estimators can correctly distinguish between covariates with nonzero and zero coefficients with probability converging to one even when the number of covariates is greater than the sample size.	[Huang, Jian] Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA; [Horowitz, Joel L.] Northwestern Univ, Dept Econ, Evanston, IL 60208 USA; [Ma, Shuangge] Yale Univ, Dept Epidemiol & Publ Hlth, Div Biostat, New Haven, CT 06520 USA	Huang, J (reprint author), Univ Iowa, Dept Stat & Actuarial Sci, 241 SH, Iowa City, IA 52242 USA.	jian@stat.uiowa.edu; joel-horowitz@northwestern.edu; shuangge.ma@yale.edu					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; HOERL AE, 1970, TECHNOMETRICS, V12, P55; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; van der Laan M J, 2001, Biostatistics, V2, P445, DOI 10.1093/biostatistics/2.4.445; BULHMAN P, 2006, ANN STAT, V34, P559; Fan J., 1997, J ITALIAN STAT ASS, V6, P131; FAN J, 2006, SURE INDEPENDENCE SC; Fan J., 2006, INT C MATH, VIII, P595; Fan JQ, 2005, J AM STAT ASSOC, V100, P781, DOI 10.1198/016214504000001781; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Huang J, 2005, J AM STAT ASSOC, V100, P814, DOI 10.1198/016214504000002032; Huang J, 2005, STAT SINICA, V15, P597; Huber P. J., 1981, ROBUST STAT; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Kosorok MR, 2007, ANN STAT, V35, P1456, DOI 10.1214/009053606000001433; PORTNOY S, 1984, ANN STAT, V12, P1298, DOI 10.1214/aos/1176346793; PORTNOY S, 1985, ANN STAT, V13, P1403, DOI 10.1214/aos/1176349744; Van der Vaart A., 1996, WEAK CONVERGENCE EMP	24	128	130	5	10	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	APR	2008	36	2					587	613		10.1214/009053607000000875		27	Statistics & Probability	Mathematics	281MW	WOS:000254502700004		
J	van de Geer, SA				van de Geer, Sara A.			High-dimensional generalized linear models and the lasso	ANNALS OF STATISTICS			English	Article						lasso; oracle inequality; sparsity	LARGE UNDERDETERMINED SYSTEMS; EMPIRICAL PROCESSES; SELECTION; AGGREGATION; CLASSIFIERS; EQUATIONS	We consider high-dimensional generalized linear models with Lipschitz loss functions, and prove a nonasymptotic oracle inequality for the empirical risk minimizer with Lasso penalty. The penalty is based on the coefficients in the linear predictor, after normalization with the empirical norm. The examples include logistic regression, density estimation and classification with hinge loss. Least squares regression is also discussed.	ETH, Seminar Stat, CH-8092 Zurich, Switzerland	van de Geer, SA (reprint author), ETH, Seminar Stat, LEO D11, CH-8092 Zurich, Switzerland.	geer@stat.math.ethz.ch					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Tsybakov AB, 2004, ANN STAT, V32, P135; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Bousquet O, 2002, CR MATH, V334, P495, DOI 10.1016/S1631-073X(02)02292-6; Bunea F, 2006, LECT NOTES ARTIF INT, V4005, P379, DOI 10.1007/11776420_29; BUNEA F, 2007, COLT, V4539, P530; Bunea F, 2007, ELECTRON J STAT, V1, P169, DOI 10.1214/07-EJS008; DAHINDEN C, 2008, IN PRESS BMC BIOINFO; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Greenshtein E, 2006, ANN STAT, V34, P2367, DOI 10.1214/009053606000000768; Hastie T., 2001, ELEMENTS STAT LEARNI; LEDOUX M., 1991, PROBABILITY BANACH S; Ledoux M., 1996, ESAIM PROBAB STAT, V1, P63; Loubes J.-M., 2002, STAT NEERL, V56, P453; Massart P., 2000, ANN FAC SCI TOULOUSE, V9, P245; Massart P, 2000, ANN PROBAB, V28, P863, DOI 10.1214/aop/1019160263; MEIER L, 2008, IN PRESS J ROY STA B; MEINSHAUSEN N, 2007, 720 DEP STAT; Rockafeller R.T., 1970, CONVEX ANAL; Tarigan B, 2006, BERNOULLI, V12, P1045, DOI 10.3150/bj/1165269150; van de Geer S, 2000, EMPIRICAL PROCESSES; van de Geer SA, 2003, RECENT ADVANCES AND TRENDS IN NONPARAMETRIC STATISTICS, P235, DOI 10.1016/B978-044451378-6/50016-8; ZHANG CH, 2006, 2006003 RUTG U DEP S	27	119	119	2	14	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	APR	2008	36	2					614	645		10.1214/009053607000000929		32	Statistics & Probability	Mathematics	281MW	WOS:000254502700005		
J	Wagadarikar, A; John, R; Willett, R; Brady, D				Wagadarikar, Ashwin; John, Renu; Willett, Rebecca; Brady, David			Single disperser design for coded aperture snapshot spectral imaging	APPLIED OPTICS			English	Article							SPECTROMETER; RECONSTRUCTION; SPECTROSCOPY	We present a single disperser spectral imager that exploits recent theoretical work in the area of compressed sensing to achieve snapshot spectral imaging. An experimental prototype is used to capture the spatiospectral information of a scene that consists of two balls illuminated by different light sources. An iterative algorithm is used to reconstruct the data cube. The average spectral resolution is 3.6 nm per spectral channel. The accuracy of the instrument is demonstrated by comparison of the spectra acquired with the proposed system with the spectra acquired by a nonimaging reference spectrometer. (C) 2008 Optical Society of America.	[Wagadarikar, Ashwin; John, Renu; Willett, Rebecca; Brady, David] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Brady, D (reprint author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	dbrady@duke.edu	John, Renu/B-4488-2009				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wagadarikar AA, 2007, APPL OPTICS, V46, P4932, DOI 10.1364/AO.46.004932; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Dai YH, 2005, NUMER MATH, V100, P21, DOI 10.1007/s00211-004-0569-y; Smith WL, 2001, P SOC PHOTO-OPT INS, V4151, P94, DOI 10.1117/12.416996; BENNETT CL, 1993, P SOC PHOTO-OPT INS, V1937, P191, DOI 10.1117/12.157065; BRADY DJ, 2006, P SPIE, V6246; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Descour MR, 1997, OPT LETT, V22, P1271, DOI 10.1364/OL.22.001271; Gehm ME, 2006, APPL OPTICS, V45, P2965, DOI 10.1364/AO.45.002965; Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9; Hanley QS, 2000, J MICROSC-OXFORD, V197, P5; Harwit M., 1979, HADAMARD TRANSFORM O; Herrala E., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2248, DOI 10.1117/12.194344; Johnson WR, 2006, APPL OPTICS, V45, P1898, DOI 10.1364/AO.45.001898; Lerner JM, 2006, CYTOM PART A, V69A, P712, DOI 10.1002/cyto.a.20242; Lin R. P., 2003, REUVEN RAMATY HIGH E; Mooney JM, 1997, J OPT SOC AM A, V14, P2951, DOI 10.1364/JOSAA.14.002951; MORRIS HR, 1994, APPL SPECTROSC, V48, P857, DOI 10.1366/0003702944029820; Pham TH, 2000, APPL OPTICS, V39, P6487, DOI 10.1364/AO.39.006487; Schroeder D., 1987, ASTRONOMICAL OPTICS; Stellman CM, 2001, P SOC PHOTO-OPT INS, V4379, P339, DOI 10.1117/12.445382	24	126	141	5	13	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	1559-128X	2155-3165		APPL OPTICS	Appl. Optics	APR 1	2008	47	10					B44	B51		10.1364/AO.47.000B44		8	Optics	Optics	293OU	WOS:000255345400006	18382550	
J	Foster, SD; Verbyla, AP; Pitchford, WS				Foster, Scott D.; Verbyla, Arunas P.; Pitchford, Wayne S.			A random model approach for the LASSO	COMPUTATIONAL STATISTICS			English	Article						random model; marginal likelihood; adjusted scores	REGRESSION	The least absolute selection and shrinkage operator (LASSO) is a method of estimation for linear models similar to ridge regression. It shrinks the effect estimates, potentially shrinking some to be identically zero. The amount of shrinkage is governed by a single parameter. Using a random model formulation of the LASSO, this parameter can be specified as the ratio of dispersion parameters. These parameters are estimated using an approximation to the marginal likelihood of the observed data. The observed score equations from the approximation are biased and hence are adjusted by subtracting an empirical estimate of the expected value. After estimation, the model effects can be tested (via simulation) as the distribution of the observed data given that all model effects are zero is known. Two related simulation studies are presented that show that dispersion parameter estimation results in effect estimates that are competitive with other estimation methods (including other LASSO methods).	[Foster, Scott D.; Verbyla, Arunas P.; Pitchford, Wayne S.] Univ Adelaide, Sch Agr Food & Wine, Cooperat Res Ctr Cattle & Beef Qual, Glen Osmond, SA 5064, Australia	Foster, SD (reprint author), CSIRO Math & Informat Sci, GPO Box 1538, Hobart, Tas 7001, Australia.	scott.foster@csiro.au	Verbyla, Arunas/A-5032-2009; foster, scott/E-9311-2010; 	Pitchford, Wayne/0000-0002-5213-3978			Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Efron B, 2004, ANN STAT, V32, P407; Gassmann HI, 2002, J COMPUT GRAPH STAT, V11, P920, DOI 10.1198/106186002385; Harville DA, 1997, MATRIX ALGEBRA STAT; JENNRICH RI, 1976, TECHNOMETRICS, V18, P11, DOI 10.2307/1267911; Kotz S, 2000, WILEY SERIES PROBABI; Mardia KV, 1979, MULTIVARIATE ANAL; MCCULLAGH P, 1990, J ROY STAT SOC B MET, V52, P325; Miller A., 2002, MONOGRAPHS STAT APPL, V95; Osborne M R, 1985, WILEY SERIES PROBABI; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Ripley B. D., 1994, MODERN APPL STAT S P; Robinson G. K., 1991, STAT SCI, V6, P15, DOI DOI 10.1214/SS/1177011926; STAMEY TA, 1989, J UROLOGY, V141, P1076	16	5	6	1	2	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0943-4062			COMPUTATION STAT	Comput. Stat.	APR	2008	23	2					217	233		10.1007/s00180-007-0033-4		17	Statistics & Probability	Mathematics	287ZT	WOS:000254956700004		
J	Knight, K				Knight, Keith			Shrinkage estimation for nearly singular designs	ECONOMETRIC THEORY			English	Article							REGRESSION; LIKELIHOOD; LASSO; ASYMPTOTICS; INFERENCE; SELECTION	Shrinkage estimation procedures such as ridge regression and the lasso have been proposed for stabilizing estimation in linear models when high collinearity exists in the design. In this paper, we consider asymptotic properties of shrinkage estimators in the case of "nearly singular" designs.	Univ Toronto, Dept Stat, Toronto, ON M5S 3G3, Canada	Knight, K (reprint author), Univ Toronto, Dept Stat, 100 St George St, Toronto, ON M5S 3G3, Canada.	keith@utstat.toronto.edu					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; HOERL AE, 1970, TECHNOMETRICS, V12, P55; Stock JH, 2002, J BUS ECON STAT, V20, P518, DOI 10.1198/073500102288618658; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; BARNABANI M, 2002, 200213 U FLOR DEP ST; CANER M, 2004, NEARLY SINGULAR DESI; CANER M, 2006, LASSO TYPE GMM ESTIM; Chernozhukov V, 2005, ANN STAT, V33, P806, DOI 10.1214/009053604000001165; Chernozhukov V, 2004, ECONOMETRICA, V72, P1445, DOI 10.1111/j.1468-0262.2004.00540.x; GABAIX X, 2006, LOG RANK 1 2 SIMPLE; GEYER CJ, 1996, ASYMPTOTICS CONVEX S; GEYER CJ, 1994, ANN STAT, V22, P1993, DOI 10.1214/aos/1176325768; KNIGHT K, 1999, UNPUB EPICONVERGENCE; Leeb H, 2006, ECONOMET THEOR, V22, P69, DOI 10.1017/S0266466606060038; Lorber A., 1987, J CHEMOMETR, V1, P19, DOI 10.1002/cem.1180010105; Pflug GC, 1995, MATH OPER RES, V20, P769, DOI 10.1287/moor.20.4.769; PHILLIPS PCB, 2001, 1310 YAL U COWL FDN; RADCHENKO P, 2004, UNPUB REWEIGHTING LA; Rotnitzky A, 2000, BERNOULLI, V6, P243, DOI 10.2307/3318576; SRIVASTA.MS, 1971, ANN MATH STAT, V42, P1403, DOI 10.1214/aoms/1177693251; STONE M, 1990, J ROY STAT SOC B MET, V52, P237; Van der Vaart A., 1996, WEAK CONVERGENCE EMP; Wold H., 1985, ENCY STATISTICAL SCI, V6, P581	26	7	7	0	4	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0266-4666			ECONOMET THEOR	Economet. Theory	APR	2008	24	2					323	337		10.1017/S0266466608080146		15	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Statistics & Probability	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	268IU	WOS:000253574300002		
J	Pan, Y; Billings, SA				Pan, Y.; Billings, S. A.			The identification of complex spatiotemporal patterns using Coupled Map Lattice models	INTERNATIONAL JOURNAL OF BIFURCATION AND CHAOS			English	Article						spatiotemporal patterns; CML; identification	STIRRED TANK REACTOR; ILL-POSED PROBLEMS; TIME-SERIES; AUTOCATALYTIC REACTIONS; CHEMICAL-SYSTEMS; TURING PATTERNS; DYNAMICS; INTERMITTENCY; OSCILLATIONS; VALIDATION	Many complex and interesting spatiotemporal patterns have been observed in a wide range of scientific areas. In this paper, two kinds of spatiotemporal patterns including spot replication and Turing systems are investigated and new identification methods are proposed to obtain Coupled Map Lattice (CML) models for this class of systems. Initially, a new correlation analysis method is introduced to determine an appropriate temporal and spatial data sampling procedure for the identification of spatiotemporal systems. A new combined Orthogonal Forward Regression and Bayesian Learning algorithm with Laplace priors is introduced to identify sparse and robust CML models for complex spatiotemporal patterns. The final identified CML models are validated using correlation-based model validation tests for spatiotemporal systems. Numerical results illustrate the identification procedure and demonstrate the validity of the identified models.	[Pan, Y.; Billings, S. A.] Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S1 3JD, S Yorkshire, England	Pan, Y (reprint author), Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield S1 3JD, S Yorkshire, England.						ABARBANEL HDI, 1990, PHYS REV A, V41, P1782, DOI 10.1103/PhysRevA.41.1782; LEE KJ, 1994, NATURE, V369, P215, DOI 10.1038/369215a0; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; ZAIKIN AN, 1970, NATURE, V225, P535, DOI 10.1038/225535b0; LENGYEL I, 1991, SCIENCE, V251, P650, DOI 10.1126/science.251.4994.650; CASTETS V, 1990, PHYS REV LETT, V64, P2953, DOI 10.1103/PhysRevLett.64.2953; LEE KJ, 1993, SCIENCE, V261, P192, DOI 10.1126/science.261.5118.192; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Barrio RA, 1999, B MATH BIOL, V61, P483, DOI 10.1006/bulm.1998.0093; BASCOMPTE J, 1995, TRENDS ECOL EVOL, V10, P361, DOI 10.1016/S0169-5347(00)89134-X; BILLINGS SA, 1991, INT J CONTROL, V54, P157, DOI 10.1080/00207179108934155; BILLINGS SA, 1989, INT J CONTROL, V49, P2157, DOI 10.1080/00207178908559767; Billings SA, 1995, INT J BIFURCAT CHAOS, V5, P1541, DOI 10.1142/S0218127495001174; Coca D, 2002, AUTOMATICA, V38, P1851, DOI 10.1016/S0005-1098(02)00099-7; Coca D, 2001, PHYS LETT A, V287, P65, DOI 10.1016/S0375-9601(01)00136-0; DEKEPPER P, 1991, PHYSICA D, V49, P161, DOI 10.1016/0167-2789(91)90204-M; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Frommer A, 1999, SIAM J SCI COMPUT, V20, P1831, DOI 10.1137/S1064827596313310; Gradisek J, 2000, PHYS REV E, V62, P3146, DOI 10.1103/PhysRevE.62.3146; GRAY P, 1985, J PHYS CHEM-US, V89, P22, DOI 10.1021/j100247a009; GRAY P, 1983, CHEM ENG SCI, V38, P29, DOI 10.1016/0009-2509(83)80132-8; GRAY P, 1984, CHEM ENG SCI, V39, P1087, DOI 10.1016/0009-2509(84)87017-7; Guo LZ, 2004, DYNAM SYST, V19, P265, DOI 10.1080/14689360410001730773; HANSEN PC, 1992, SIAM REV, V34, P561, DOI 10.1137/1034115; KANEKO K, 1989, PHYSICA D, V34, P1, DOI 10.1016/0167-2789(89)90227-3; KANEKO K, 1986, PHYSICA D, V18, P475, DOI 10.1016/0167-2789(86)90219-8; KANEKO K, 1985, PROG THEOR PHYS, V74, P1033, DOI 10.1143/PTP.74.1033; KAPRAL R, 1995, PHYSICA D, V86, P149, DOI 10.1016/0167-2789(95)00096-M; KAREIVA P, 1995, NATURE, V373, P299, DOI 10.1038/373299a0; Kilmer ME, 2001, SIAM J MATRIX ANAL A, V22, P1204, DOI 10.1137/S0895479899345960; Lesmes F, 2003, PHYS REV LETT, V91, DOI 10.1103/PhysRevLett.91.238301; MACKAY D, 1992, NEURAL COMPUT, V4, P417; Maini PK, 1997, J CHEM SOC FARADAY T, V93, P3601, DOI 10.1039/a702602a; Mandelj S, 2001, INT J BIFURCAT CHAOS, V11, P2731, DOI 10.1142/S0218127401003802; Marcos-Nikolaus P, 2002, INT J BIFURCAT CHAOS, V12, P369, DOI 10.1142/S0218127402004371; Maron JL, 1997, SCIENCE, V278, P1619, DOI 10.1126/science.278.5343.1619; Muratov CB, 2000, J PHYS A-MATH GEN, V33, P8893, DOI 10.1088/0305-4470/33/48/321; Murray J.D., 1989, MATH BIOL; Nishiura Y, 1999, PHYSICA D, V130, P73, DOI 10.1016/S0167-2789(99)00010-X; OSTAVIK S, 1998, PHYS LETT A, V247, P145; OUYANG Q, 1991, NATURE, V352, P610, DOI 10.1038/352610a0; PAINTER KJ, 2000, MATH MODELS BIOL PAT, V121, P59; Pan Y, 2007, INT J BIFURCAT CHAOS, V17, P4323, DOI 10.1142/S0218127407019986; Parlitz U, 2000, PHYS REV LETT, V84, P1890, DOI 10.1103/PhysRevLett.84.1890; PEARSON JE, 1993, SCIENCE, V261, P189, DOI 10.1126/science.261.5118.189; ROSENSTEIN MT, 1994, PHYSICA D, V73, P82, DOI 10.1016/0167-2789(94)90226-7; ROVINSKY A, 1992, PHYS REV A, V46, P6315, DOI 10.1103/PhysRevA.46.6315; VIGIL RD, 1992, PHYSICA A, V188, P17, DOI 10.1016/0378-4371(92)90248-O	49	3	4	1	2	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-1274			INT J BIFURCAT CHAOS	Int. J. Bifurcation Chaos	APR	2008	18	4					997	1013		10.1142/S021812740802080X		17	Mathematics, Interdisciplinary Applications; Multidisciplinary Sciences	Mathematics; Science & Technology - Other Topics	321GI	WOS:000257292300006		
J	Barrios, EB; Sarte, GMF				Barrios, Erniel B.; Sarte, Genelyn Ma. F.			Monitoring sustainable agriculture in Southeast Asia	INTERNATIONAL JOURNAL OF SUSTAINABLE DEVELOPMENT AND WORLD ECOLOGY			English	Article						sustainable agriculture; monitoring; principal component analysis; sparse principal component analysis; Southeast Asia	LASSO	Monitoring agricultural sustainability requires careful summarising of indicators collected over time into indices representing facets of sustainability. When the number of variables exceeds the number of observations, interpretation of components from ordinary principal component analysis is usually difficult because of minimal or absence of sparsity among the loadings. This is also true for time series indicators that exhibit non-stationarity. A framework for the assessment of agricultural sustainability in a regional context is proposed. Sparse principal component analysis is used in constructing indices of agricultural sustainability that are then used to characterise the state of agricultural development and the dynamics of agricultural growth in Southeast Asia.	[Barrios, Erniel B.; Sarte, Genelyn Ma. F.] Univ Philippines, Sch Stat Bldg, Quezon City 1101, Philippines	Barrios, EB (reprint author), Univ Philippines, Sch Stat Bldg, Magsaysay Ave, Quezon City 1101, Philippines.	erniel.barrios@up.edu.ph					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; BROWN BJ, 1987, ENVIRON MANAGE, V11, P713, DOI 10.1007/BF01867238; Chipman HA, 2005, J APPL STAT, V32, P969, DOI 10.1080/02664760500168648; DEVRIES FWT, 1995, 2020 VISION BRIEF, P18; Gervini D, 2004, AM STAT, V58, P72, DOI 10.1198/0003130042863; Jolliffe IT, 2002, PRINCIPAL COMPONENT, V2nd, P1; Rousson V, 2004, J ROY STAT SOC C-APP, V53, P539, DOI 10.1111/j.1467-9876.2004.05359.x; Setboonsarng S., 2006, 49 ADB I; Trendafilov NT, 2006, COMPUT STAT DATA AN, V50, P242, DOI 10.1016/j.csda.2004.07.017; *UN FAO, 2004, FOASTAT; VINES SK, 2000, APPL STAT, V49, P441; Zhou H., 2006, J COMPUTATIONAL GRAP, V15, P265; Zhou H, 2005, J ROYAL STAT SOC B, V67, P301	15	1	1	0	3	SAPIENS PUBL	DUMFRIESSHIRE	DUNCOW, KIRKMAHOE, DUMFRIESSHIRE, DG1 1TA, ENGLAND	1350-4509			INT J SUST DEV WORLD	Int. J. Sustain. Dev. World Ecol.	APR	2008	15	2					95	102		10.1080/13504500809469774		8	Ecology	Environmental Sciences & Ecology	295WZ	WOS:000255506200003		
J	Jensen, DR; Ramirez, DE				Jensen, Donald R.; Ramirez, Donald E.			Anomalies in the foundations of ridge regression	INTERNATIONAL STATISTICAL REVIEW			English	Article						constrained optimization; incomplete use of LaGrange's method; non-singular distributions; alternative foundations	LINEAR-REGRESSION; SELECTION; VARIABLES	Errors persist in ridge regression, its foundations, and its usage, as set forth in Hoerl & Kennard (1970) and elsewhere. Ridge estimators need not be minimizing, nor a prospective ridge parameter be admissible. Conventional estimators are not LaGrange's solutions constrained to fixed lengths, as claimed, since such solutions are singular. Of a massive literature on estimation, prediction, cross-validation, choice of ridge parameter, and related issues, little emanates from constrained optimization to include inequality constraints. The problem traces to a misapplication of LaGrange's Principle, unrecognized singularities, and misplaced links between constraints and ridge parameters. Alternative principles, based on condition numbers, are seen to validate both conventional ridge and surrogate ridge regression to be defined. Numerical studies illustrate that ridge regression as practiced often exhibits pathologies it is intended to redress.	[Jensen, Donald R.; Ramirez, Donald E.] Univ Virginia, Dept Math, Charlottesville, VA 22904 USA	Jensen, DR (reprint author), Univ Virginia, Dept Math, Charlottesville, VA 22904 USA.	djensen@vt.edu; der@virginia.edu	Ramirez, Donald/E-9422-2011	Ramirez, Donald/0000-0002-2419-4538			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; HOERL AE, 1970, TECHNOMETRICS, V12, P55; ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; BALAKRISHNAN AV, 1963, J CONTROL, V1, P109, DOI 10.1137/0301008; BEATON AE, 1976, J AM STAT ASSOC, V71, P158, DOI 10.2307/2285761; Belsley D., 1980, REGRESSION DIAGNOSTI; BERK KN, 1977, J AM STAT ASSOC, V72, P863, DOI 10.2307/2286476; DAVIES RB, 1975, BIOMETRIKA, V62, P383, DOI 10.2307/2335377; DEMPSTER AP, 1977, J AM STAT ASSOC, V72, P77, DOI 10.2307/2286909; DRAPER NR, 1963, TECHNOMETRICS, V5, P469, DOI 10.2307/1266023; HOCKING RR, 1976, BIOMETRICS, V32, P1, DOI 10.2307/2529336; HOERL AE, 1975, COMMUN STAT, V4, P105, DOI 10.1080/03610917508548342; Levenberg K., 1944, Quarterly of Applied Mathematics, V2; MARQUARDT DW, 1975, AM STAT, V29, P3, DOI 10.2307/2683673; MARQUARD.DW, 1970, TECHNOMETRICS, V12, P591, DOI 10.2307/1267205; Marshall A.W., 1979, INEQUALITIES THEORY; Myers R, 1990, CLASSICAL MODERN REG; Myoken H., 1977, Metrika, V24, DOI 10.1007/BF01893398; Riley J. D., 1955, MATH COMPUT, P96, DOI 10.2307/2002065; Stoer J., 1970, CONVEXITY OPTIMIZATI; VANNOSTRAND C, 1980, J AM STAT ASSOC, V75, P92; Zhang R, 2005, COMMUN STAT-THEOR M, V34, P1487, DOI 10.1081/STA-200063266	24	8	8	1	2	INT STATISTICAL INST	VOORBURG	428 PRINSES BEATRIXLAAN, 2270 AZ VOORBURG, NETHERLANDS	0306-7734			INT STAT REV	Int. Stat. Rev.	APR	2008	76	1					89	105		10.1111/j.1751-5823.2007.00041.x		17	Statistics & Probability	Mathematics	288QG	WOS:000255000300005		
J	Seeger, MW				Seeger, Matthias W.			Bayesian inference and optimal design for the sparse linear model	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						sparse linear model; Laplace prior; expectation propagation; approximate inference; optimal design; Bayesian statistics; gene network recovery; image coding; compressive sensing	APPROXIMATE INFERENCE; VECTOR MACHINE; GENE NETWORKS; CLASSIFICATION; LIKELIHOOD; ALGORITHMS; FRAMEWORK; SELECTION; STRATEGY	The linear model with sparsity-favouring prior on the coefficients has important applications in many different domains. In machine learning, most methods to date search for maximum a posteriori sparse solutions and neglect to represent posterior uncertainties. In this paper, we address problems of Bayesian optimal design (or experiment planning), for which accurate estimates of uncertainty are essential. To this end, we employ expectation propagation approximate inference for the linear model with Laplace prior, giving new insight into numerical stability properties and proposing a robust algorithm. We also show how to estimate model hyperparameters by empirical Bayesian maximisation of the marginal likelihood, and propose ideas in order to scale up the method to very large underdetermined problems. We demonstrate the versatility of our framework on the application of gene regulatory network identification from micro-array expression data, where both the Laplace prior and the active experimental design approach are shown to result in significant improvements. We also address the problem of sparse coding of natural images, and show how our framework can be used for compressive sensing tasks. Part of this work appeared in Seeger et al. (2007b). The gene network identification application appears in Steinke et al. (2007).	Max Planck Inst Biol Cybernet, Tubingen, Germany	Seeger, MW (reprint author), Max Planck Inst Biol Cybernet, Spemannstr 38, Tubingen, Germany.	seeger@tuebingen.mpg.de					MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hojen-Sorensen PADFR, 2002, NEURAL COMPUT, V14, P889, DOI 10.1162/089976602317319009; Chaloner K, 1995, STAT SCI, V10, P273, DOI 10.1214/ss/1177009939; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Rogers S, 2005, BIOINFORMATICS, V21, P3131, DOI 10.1093/bioinformatics/bti487; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Chib S, 1995, J AM STAT ASSOC, V90, P1313, DOI 10.2307/2291521; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Gardner TS, 2000, NATURE, V403, P339; Kuss M, 2005, J MACH LEARN RES, V6, P1679; Attias H, 2000, ADV NEUR IN, V12, P209; Berkes P., 2008, ADV NEURAL INFORM PR, V20; BISHOP C, 2003, WORKSH ART INT STAT, V9, P244; Bogachev V., 1998, MATH SURVEYS MONOGRA; Bottou L., 1998, ON LINE LEARNING NEU; Boyd S., 2002, CONVEX OPTIMIZATION; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Chhikara R. S., 1989, INVERSE GAUSSIAN DIS; DERISI J, 1997, SCIENCE, V282, P699; Dongarra J.J., 1979, LINPACK USERS GUIDE; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Faul AC, 2002, ADV NEUR IN, V14, P383; Fedorov V. V., 1972, THEORY OPTIMAL EXPT; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1050; GERWINN S, 2008, ADV NEURAL INFORM PR, V20; Ghahramani Z, 2001, ADV NEUR IN, V13, P507; Gilks W. R., 1996, MARKOV CHAIN MONTE C; GILKS WR, 1992, APPL STAT-J ROY ST C, V41, P337, DOI 10.2307/2347565; Girolami M, 2001, NEURAL COMPUT, V13, P2517, DOI 10.1162/089976601753196003; Gneiting T, 1997, J STAT COMPUT SIM, V59, P375, DOI 10.1080/00949659708811867; Hastie T, 2004, J MACH LEARN RES, V5, P1391; HENDERSON HV, 1981, SIAM REV, V23, P53, DOI 10.1137/1023004; Horn R. A., 1985, MATRIX ANAL; Ishwaran H, 2005, J AM STAT ASSOC, V100, P764, DOI 10.1198/016214505000000051; JAAKKOLA T, 1997, THESIS MASSACHUSETTS; JI S, 2007, INT C MACH LEARN OMN, V24; Jordan M.I., 1997, LEARNING GRAPHICAL M; Kholodenko BN, 2002, P NATL ACAD SCI USA, V99, P12841, DOI 10.1073/pnas.192442699; Kushner HJ, 2000, IEEE T AUTOMAT CONTR, V45, P580, DOI 10.1109/9.847749; Lawrence N., 2003, ADV NEURAL INFORM PR, V15, P609; LEWI J, 2007, ADV NEURAL INFORM PR, V19; Lewicki MS, 1999, J OPT SOC AM A, V16, P1587, DOI 10.1364/JOSAA.16.001587; Lovasz L., 2003, MSRTR200305; MACKAY D, 1991, NEURAL COMPUT, V4, P589; MINKA T, 2001, THESIS MASSACHUSETTS; Minka T., 2001, UNCERTAINTY ARTIFICI, V17; MINKA T, 2004, TECHNICAL REPORT MIC; Neal R. M., 1993, CRGTR931 U TOR; Neal R.M., 1996, LECT NOTES STAT, V118; O'Hagan A., 1994, KENDALLS ADV THEOR B, V1st, p2B; Opper M, 2005, J MACH LEARN RES, V6, P2177; Opper M, 2000, NEURAL COMPUT, V12, P2655, DOI 10.1162/089976600300014881; PALMER A, 2006, ADV NEURAL INFORM PR, V18; Paninski L., 2005, ADV NEURAL INFORM PR, V17; Park T., 2005, BAYESIAN LASSO; PEETERS R, 2004, P 16 INT S MATH THEO; PRATT JW, 1981, J AM STAT ASSOC, V76, P103, DOI 10.2307/2287052; QI Y, 2004, INT C MACH LEARN MOR, V21; Rabiner L., 2003, FUNDAMENTALS SPEECH, V2nd; Saad Y, 1996, ITERATIVE METHODS SP; SEEGER M, 2007, EUR C MACH LEARN SPR, V18; SEEGER M, 2008, COMPRESSED IN PRESS; SEEGER M, 2007, WORKSH ART INT STAT, V11; SEEGER M, 2004, LOW RANK UPDATES CHO; Seeger M. W., 2005, EXPECTATION PROPAGAT; Seeger Matthias, 2003, THESIS U EDINBURGH; SEUNG HS, 1992, C COMP LEARN THEOR M, V5, P287; Spiegelhalter D. L., 1995, BUGS BAYESIAN INFERE; STEINKE F, 2007, BMC SYSTEMS BIOL, V1; Tegner J, 2003, P NATL ACAD SCI USA, V100, P5944, DOI 10.1073/pnas.0933416100; Wainwright M., 2006, 709 UC BERK DEP STAT; Wainwright M. J., 2003, 649 UC BERK DEP STAT; WIPF D, 2007, P ICASSP 2007; Wipf D., 2004, ADV NEURAL INFORM PR, V16; ZOETER O, 2005, WORKSH ART INT STAT, V10	77	68	71	0	13	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	APR	2008	9						759	813				55	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	312AS	WOS:000256642100008		
J	Kiiveri, HT				Kiiveri, Harri T.			A general approach to simultaneous model fitting and variable elimination in response models for biological data with many more variables than observations	BMC BIOINFORMATICS			English	Article							CLASSIFICATION; SELECTION; REGRESSION; ALGORITHM	Background: With the advent of high throughput biotechnology data acquisition platforms such as micro arrays, SNP chips and mass spectrometers, data sets with many more variables than observations are now routinely being collected. Finding relationships between response variables of interest and variables in such data sets is an important problem akin to finding needles in a haystack. Whilst methods for a number of response types have been developed a general approach has been lacking. Results: The major contribution of this paper is to present a unified methodology which allows many common (statistical) response models to be fitted to such data sets. The class of models includes virtually any model with a linear predictor in it, for example (but not limited to), multiclass logistic regression (classification), generalised linear models (regression) and survival models. A fast algorithm for finding sparse well fitting models is presented. The ideas are illustrated on real data sets with numbers of variables ranging from thousands to millions. R code implementing the ideas is available for download. Conclusion: The method described in this paper enables existing work on response models when there are less variables than observations to be leveraged to the situation when there are many more variables than observations. It is a powerful approach to finding parsimonious models for such datasets. The method is capable of handling problems with millions of variables and a large variety of response types within the one framework. The method compares favourably to existing methods such as support vector machines and random forests, but has the advantage of not requiring separate variable selection steps. It is also works for data types which these methods were not designed to handle. The method usually produces very sparse models which make biological interpretation simpler and more focused.	CSIRO Math & Informat Sci, Leeuwin Ctr, Wembly, WA 6014, Australia	Kiiveri, HT (reprint author), CSIRO Math & Informat Sci, Leeuwin Ctr, 65 Brockway Rd, Wembly, WA 6014, Australia.	harri.kiiveri@csiro.au	Kiiveri, Harri/E-5309-2010				ABRAMOWITZ M, 1972, HDB MATH FUNCTIONS F, V14; Spira A, 2004, P NATL ACAD SCI USA, V101, P10143, DOI 10.1073/pnas.0401422101; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; Dave SS, 2004, NEW ENGL J MED, V351, P2159, DOI 10.1056/NEJMoa041869; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Tomlins SA, 2007, NAT GENET, V39, P41, DOI 10.1038/ng1935; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; COX DR, 1984, MONOGRAPHS STAT APPL, V8; FIGUEIREDO M, 2003, NONLINEAR ESTIMATION, V171, P474; FIGUEIREDO M, 2002, ADV NEURAL INFORM PR, V14; GRIFFIN JE, ALTERNATIVE PRIOR DI, P34; Hinds DA, 2005, SCIENCE, V307, P1072, DOI 10.1126/science.1105436; KLIVERI HT, 2003, SCI STAT FESTSCHRIFT, V41, P474; KOTZ S, 1985, ENCY STAT SCI, V5, P665; MCCULLAGH P, 1989, MONOGRAPHS STAT APPL, V19; Park MY, 2007, BIOSTATISTICS, V8, P212, DOI 10.1093/biostatistics/kxl002; Platt J, 1999, ADV KERNEL METHODS S; Ross ME, 2003, BLOOD, V102, P2951, DOI 10.1182/blood-2003-01-0338; SCHEOLKOPF B, 1999, ADV KERNEL METHODS S, V7; TEAM RDC, 2005, R LANGUAGE ENV STAT; Watson GN, 1966, TREATISE THEORY BESS, pvi; ZHANG S, 1996, COMPUTATION SPECIAL, V36; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217; Zhu JX, 2008, J STAT PLAN INFER, V138, P374, DOI 10.1016/j.jspi.2007.06.003	28	14	14	2	4	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	APR 15	2008	9								195	10.1186/1471-2105-9-195		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	303JK	WOS:000256036600001	18410693	
J	Burd, RS; Ouyang, M; Madigan, D				Burd, Randall S.; Ouyang, Ming; Madigan, David			Bayesian logistic injury severity score: A method for predicting mortality using international classification of disease-9 codes	ACADEMIC EMERGENCY MEDICINE			English	Article; Proceedings Paper	20th Annual Meeting of the Eastern-Association-for-the-Surgery-of-Trauma	JAN 16-20, 2007	Ft Myers, FL	Eastern Assoc Surg Trauma		International Classification of Diseases; trauma severity indices; predictive value of tests; survival rate	SURVIVAL RISK RATIOS; BODY REGION; TRAUMA; REGRESSION; SELECTION; SYSTEM; SIMULATION; TRIPLETS; ACCURACY; EVENTS	Objectives: Owing to the large number of injury International Classification of Disease-9 revision (ICD-9) codes, it is not feasible to use standard regression methods to estimate the independent risk of death for each injury code. Bayesian logistic regression is a method that can select among a large numbers of predictors without loss of model performance. The purpose of this study was to develop a model for predicting in-hospital trauma deaths based on this method and to compare its performance with the ICD-9-based Injury Severity Score (ICISS). Methods: The authors used Bayesian logistic regression to train and test models for predicting mortality based on injury ICD-9 codes (2,210 codes) and injury codes with two-way interactions (243,037 codes and interactions) using data from the National Trauma Data Bank (NTDB). They evaluated discrimination using area under the receiver operating curve (AUC) and calibration with the Hosmer-Lemeshow (HL) h-statistic. The authors compared performance of these models with one developed using ICISS. Results: The discrimination of a model developed using individual ICD-9 codes was similar to that of a model developed using individual codes and their interactions (AUC = 0.888 vs. 0.892). Inclusion of injury interactions, however, improved model calibration (HL h-statistic = 2,737 vs. 1,347). A model based on ICISS had similar discrimination (AUC = .855) but showed worse calibration (HL h-statistic = 45,237) than those based on regression. Conclusions: A model that incorporates injury interactions had better predictive performance than one based only on individual injuries. A regression approach to predicting injury mortality based on injury ICD-9 codes yields models with better predictive performance than ICISS.	[Burd, Randall S.] Univ Med & Dent New Jersey, Robert Wood Johnson Med Sch, Dept Surg, New Brunswick, NJ 08903 USA; [Ouyang, Ming] Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY USA; [Madigan, David] Columbia Univ, Dept Stat, New York, NY USA	Burd, RS (reprint author), Univ Med & Dent New Jersey, Robert Wood Johnson Med Sch, Dept Surg, New Brunswick, NJ 08903 USA.	burdrs@umdnj.edu					Kilgo PD, 2003, J TRAUMA, V55, P599, DOI 10.1097/01.TA.0000085723.47738.BD; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vittinghoff E, 2007, AM J EPIDEMIOL, V165, P710, DOI 10.1093/aje/kwk052; BOYD CR, 1987, J TRAUMA, V27, P370; Osler T, 1996, J TRAUMA, V41, P380, DOI 10.1097/00005373-199609000-00002; Osler T, 1997, J TRAUMA, V43, P922, DOI 10.1097/00005373-199712000-00009; Durham R, 2006, ANN SURG, V243, P775, DOI 10.1097/01.sla.0000219644.52926.f1; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Aharonson-Daniel L, 2006, J TRAUMA, V61, P711, DOI 10.1097/01.ta.0000235294.32326.e6; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Barell V, 2002, INJ PREV, V8, P91, DOI 10.1136/ip.8.2.91; Burd RS, 2007, J TRAUMA, V62, P1004, DOI 10.1097/01.ta.0000221555.01704.c9; Burd RS, 2006, J TRAUMA, V60, P792, DOI 10.1097/01.ta.0000214589.02515.dd; Chawda MN, 2004, INJURY, V35, P347, DOI 10.1016/S0020-1383(03)00140-2; *HCUP NIS, 2003, AG HEALTHC RES QUAL; Healey C, 2003, J TRAUMA, V54, P671, DOI 10.1097/01.TA.0000058130.30490.5D; Hermans PG, 2006, VET REC, V158, P615; IZRAEL D, 2002, P 27 ANN SAS US GROU; Kilgo PD, 2004, J TRAUMA, V57, P479, DOI 10.1097/01.TA.0000141024.96440.7C; Kilgo PD, 2006, J TRAUMA, V60, P1002, DOI 10.1097/01.ta.0000215827.54546.01; Koh KM, 2007, J MACH LEARN RES, V8, P1519; Lefering R, 2002, EUR J TRAUMA, V28, P52, DOI 10.1007/s00068-002-0170-y; Markogiannakis H, 2006, ACTA CHIR BELG, V106, P566; Meredith JW, 2003, J TRAUMA, V55, P933, DOI 10.1097/01.TA.0000085646.71451.5F; Moore L, 2006, J TRAUMA, V60, P802, DOI 10.1097/01.ta.0000200838.55420.ad; Mullins RJ, 2006, J TRAUMA, V60, P691, DOI 10.1097/01.ta.0000210454.92078.89; Peduzzi P, 1996, J CLIN EPIDEMIOL, V49, P1373, DOI 10.1016/S0895-4356(96)00236-3; Clarke JR, 2005, J TRAUMA, V59, P563, DOI 10.1097/01.ta.0000177786.86575.c1; Russell R, 2004, J TRAUMA, V56, P1321, DOI 10.1097/01.TA.0000062763.21379.D9; Setakis E, 2006, GENOME RES, V16, P290, DOI 10.1101/gr.4346306; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Wynn A, 2001, J TRAUMA, V51, P464, DOI 10.1097/00005373-200109000-00007; Zhu BP, 1996, CRIT CARE MED, V24, P57, DOI 10.1097/00003246-199601000-00011	34	9	9	1	5	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	1069-6563			ACAD EMERG MED	Acad. Emerg. Med.	MAY	2008	15	5					466	475		10.1111/j.1553-2712.2008.00105.x		10	Emergency Medicine	Emergency Medicine	292SA	WOS:000255285200010	18439203	
J	Li, CY; Li, HZ				Li, Caiyan; Li, Hongzhe			Network-constrained regularization and variable selection for analysis of genomic data	BIOINFORMATICS			English	Article							GLIOBLASTOMA CELL-LINES; ORACLE PROPERTIES; PROTEIN-KINASE; REGRESSION; LASSO; MODEL	Motivation: Graphs or networks are common ways of depicting information. In biology in particular, many different biological processes are represented by graphs, such as regulatory networks or metabolic pathways. This kind of a priori information gathered over many years of biomedical research is a useful supplement to the standard numerical genomic data such as microarray gene-expression data. How to incorporate information encoded by the known biological networks or graphs into analysis of numerical data raises interesting statistical challenges. In this article, we introduce a network-constrained regularization procedure for linear regression analysis in order to incorporate the information from these graphs into an analysis of the numerical data, where the network is represented as a graph and its corresponding Laplacian matrix. We define a network-constrained penalty function that penalizes the L-1-norm of the coefficients but encourages smoothness of the coefficients on the network. Results: Simulation studies indicated that the method is quite effective in identifying genes and subnetworks that are related to disease and has higher sensitivity than the commonly used procedures that do not use the pathway structure information. Application to one glioblastoma microarray gene-expression dataset identified several subnetworks on several of the Kyoto Encyclopedia of Genes and Genomes (KEGG) transcriptional pathways that are related to survival from glioblastoma, many of which were supported by published literatures. Conclusions: The proposed network-constrained regularization procedure efficiently utilizes the known pathway structures in identifying the relevant genes and the subnetworks that might be related to phenotype in a general regression framework. As more biological networks are identified and documented in databases, the proposed method should find more applications in identifying the subnetworks that are related to diseases and other biological processes. Contact: hongzhe@mail.med.upenn.edu.	[Li, Caiyan; Li, Hongzhe] Univ Penn, Sch Med, Dept Biostat & Epidemiol, Philadelphia, PA 19104 USA	Li, HZ (reprint author), Univ Penn, Sch Med, Dept Biostat & Epidemiol, Philadelphia, PA 19104 USA.						Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Leach DR, 1996, SCIENCE, V271, P1734, DOI 10.1126/science.271.5256.1734; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Accili D, 2004, CELL, V117, P421, DOI 10.1016/S0092-8674(04)00452-0; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Li J, 1997, SCIENCE, V275, P1943, DOI 10.1126/science.275.5308.1943; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; Chung F. R., 1997, SPECTRAL GRAPH THEOR, V92; Horvath S, 2006, P NATL ACAD SCI USA, V103, P17402, DOI 10.1073/pnas.0608396103; LI C, 2007, 23 U PENN; Mawrin C, 2003, INT J ONCOL, V23, P641; Pelloski CE, 2006, CLIN CANCER RES, V12, P3935, DOI 10.1158/1078-0432.CCR-05-2202; Perego C, 2002, J CELL SCI, V115, P3331; Rahnenfuhrer J, 2004, STAT APPL GENET MOL, V3, P16, DOI [10.2202/1544-6115.1055, DOI 10.2202/1544-6115.1055]; Swisshelm K, 2005, ADV DRUG DELIVER REV, V57, P919, DOI 10.1016/j.addr.2005.01.006; Uht RM, 2007, ONCOGENE, V26, P2885, DOI 10.1038/sj.onc.1210090; Wei P, 2008, BIOINFORMATICS, V24, P404, DOI 10.1093/bioinformatics/btm612; Wei Z, 2008, ANN APPL STAT, V2, P408, DOI 10.1214/07-AOAS145; Wei Z, 2007, BIOINFORMATICS, V23, P1537, DOI 10.1093/bioinformatics/btm129; WU TT, 2007, IN PRESS ANN APPL ST	25	131	131	0	7	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	MAY 1	2008	24	9					1175	1182		10.1093/bioinformatics/btn081		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	293DB	WOS:000255313900008	18310618	
J	Frank, LE; Heiser, WJ				Frank, Laurence E.; Heiser, Willem J.			Feature selection in feature network models: Finding predictive subsets of features with the Positive Lasso	BRITISH JOURNAL OF MATHEMATICAL & STATISTICAL PSYCHOLOGY			English	Article							DISTINCTIVE FEATURES; SIMILARITY TREES; GRAY CODES; REGRESSION; COMMON	A set of features is the basis for the network representation of proximity data achieved by feature network models (FNMs). Features are binary variables that characterize the objects in an experiment, with some measure of proximity as response variable. Sometimes features are provided by theory and play an important role in the construction of the experimental conditions. In some research settings, the features are not known a priori. This paper shows how to generate features in this situation and how to select an adequate subset of features that takes into account a good compromise between model fit and model complexity, using a new version of least angle regression that restricts coefficients to be non-negative, called the Positive Lasso. It will be shown that features can be generated efficiently with Gray codes that are naturally linked to the FNMs. The model selection strategy makes use of the fact that FNM can be considered as univariate multiple regression model. A simulation study shows that the proposed strategy leads to satisfactory results if the number of objects is less than or equal to 22. If the number of objects is larger than 22, the number of features selected by our method exceeds the true number of features in some conditions.	[Frank, Laurence E.] Univ Utrecht, Dept Methodol & Stat, Fac Social & Behav Sci, NL-3508 TC Utrecht, Netherlands; [Heiser, Willem J.] Leiden Univ, Dept Psychol, NL-2300 RA Leiden, Netherlands	Frank, LE (reprint author), Univ Utrecht, Dept Methodol & Stat, Fac Social & Behav Sci, POB 80140, NL-3508 TC Utrecht, Netherlands.	LE.Frank@uv.nl					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/0033-295X.84.4.327; Efron B, 2004, ANN STAT, V32, P407; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526; ARABIE P, 1980, PSYCHOMETRIKA, V45, P211, DOI 10.1007/BF02294077; CARROLL JD, 1995, J CLASSIF, V12, P283; Corter J. E., 1996, TREE MODELS SIMILARI; CORTER JE, 1986, PSYCHOMETRIKA, V51, P429, DOI 10.1007/BF02294065; Draper N. R., 1998, APPL REGRESSION ANAL; Flament C., 1963, APPL GRAPH THEORY GR; FRANK LE, 2004, INT M PSYCH SOC PAC; Frank LE, 2007, BRIT J MATH STAT PSY, V60, P1, DOI 10.1348/000711005X64240; Friedman JH, 2004, GRADIENT DIRECTED RE; GARDNER M, 1972, SCI AM, V227, P106; GATI I, 1984, COGNITIVE PSYCHOL, V16, P341, DOI 10.1016/0010-0285(84)90013-6; GILBERT EN, 1958, AT&T TECH J, V37, P815; GOODMAN N, 1977, STRUCTURE APPEARENCE; GOODMAN N, 1951, STRUCTURE APPEARENCE; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2001, ELEMENTS STAT LEARNI; HEISER WJ, 1998, DATA SCI CLASSIFICAT, P52; KEREN G, 1981, PERCEPT PSYCHOPHYS, V29, P234, DOI 10.3758/BF03207290; MALLOWS CL, 1995, TECHNOMETRICS, V37, P362, DOI 10.2307/1269729; Navarro DJ, 2004, PSYCHON B REV, V11, P961, DOI 10.3758/BF03196728; Nijenhuis A, 1978, COMBINATORIAL ALGORI; RESTLE E, 1961, PSYCHOL JUDGMENT CHO; RESTLE F, 1959, PSYCHOMETRIKA, V24, P207, DOI 10.1007/BF02289843; SATTATH S, 1977, PSYCHOMETRIKA, V42, P319, DOI 10.1007/BF02293654; Savage C, 1997, SIAM REV, V39, P605, DOI 10.1137/S0036144595295272; Shepard R., 1972, HUMAN COMMUNICATION, P67; SHEPARD RN, 1979, PSYCHOL REV, V86, P87, DOI 10.1037/0033-295X.86.2.87; Yang YH, 2005, BIOMETRIKA, V92, P937, DOI 10.1093/biomet/92.4.937; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	34	3	3	0	0	BRITISH PSYCHOLOGICAL SOC	LEICESTER	ST ANDREWS HOUSE, 48 PRINCESS RD EAST, LEICESTER LE1 7DR, LEICS, ENGLAND	0007-1102			BRIT J MATH STAT PSY	Br. J. Math. Stat. Psychol.	MAY	2008	61		1				1	27		10.1348/000711006X119365		27	Mathematics, Interdisciplinary Applications; Psychology, Mathematical; Psychology, Experimental; Statistics & Probability	Mathematics; Psychology	310JN	WOS:000256524900001	18482473	
J	Zhang, ZG; Zhang, SL; Wong, MY; Wareham, NJ; Sha, QY				Zhang, Zhaogong; Zhang, Shuanglin; Wong, Man-Yu; Wareham, Nicholas J.; Sha, Qiuying			An ensemble learning approach jointly modeling main and interaction effects in genetic association studies	GENETIC EPIDEMIOLOGY			English	Article						epistasis; association study; complex disease; Type 2 diabetes	MULTIFACTOR-DIMENSIONALITY REDUCTION; TIGHTLY LINKED MARKERS; RANDOM FORESTS; BREAST-CANCER; EPISTASIS; DISEASE; SUSCEPTIBILITY; LINKAGE; TESTS; LOCI	Complex diseases are presumed to be the results of interactions of several genes and environmental factors, with each gene only having a small effect on the disease. Thus, the methods that can account for gene-gene interactions to search for a set of marker loci in different genes or across genome and to analyze these loci jointly are critical. In this article, we propose an ensemble learning approach (ELA) to detect a set of loci whose main and interaction effects jointly have a significant association with the trait. In the ELA, we first search for "base learners" and then combine the effects of the base learners by a linear model. Each base learner represents a main effect or an interaction effect. The result of the ELA is easy to interpret. When the ELA is applied to analyze a data set, we can get a final model, an overall P-value of the association test between the set of loci involved in the final model and the trait, and an importance measure for each base learner and each marker involved in the final model. The final model is a linear combination of some base learners. We know which base learner represents a main effect and which one represents an interaction effect. The importance measure of each base learner or marker can tell us the relative importance of the base learner or marker in the final model. We used intensive simulation studies as well as a real data set to evaluate the performance of the ELA. Our simulation studies demonstrated that the ELA is more powerful than the single-marker test in all the simulation scenarios. The ELA also outperformed the other three existing multi-locus methods in almost all cases. In an application to a large-scale case-control study for Type 2 diabetes, the ELA identified 11 single nucleotide polymorphisms that have a significant multi-locus effect (P-value = 0.01), while none of the single nucleotide polymorphisms showed significant marginal effects and none of the two-locus combinations showed significant two-locus interaction effects.	[Zhang, Zhaogong; Zhang, Shuanglin; Sha, Qiuying] Michigan Technol Univ, Dept Math Sci, Houghton, MI 49931 USA; [Zhang, Zhaogong; Zhang, Shuanglin] Heilongjiang Univ, Harbin, Peoples R China; [Wong, Man-Yu] Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Hong Kong, Peoples R China; [Wareham, Nicholas J.] Univ Cambridge, Inst Publ Hlth, Dept Publ Hlth & Primary Care, Cambridge, England	Sha, QY (reprint author), Michigan Technol Univ, Dept Math Sci, 1400 Townsend Dr, Houghton, MI 49931 USA.	qsha@mtu.edu					Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; Zhao HY, 2000, AM J HUM GENET, V67, P936, DOI 10.1086/303073; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Moore JH, 2005, BIOESSAYS, V27, P637, DOI 10.1002/bias.20236; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Devlin B, 1999, BIOMETRICS, V55, P997, DOI 10.1111/j.0006-341X.1999.00997.x; Schaid DJ, 2002, AM J HUM GENET, V70, P425, DOI 10.1086/338688; Fallin D, 2001, GENOME RES, V11, P143, DOI 10.1101/gr.148401; Chapman JM, 2003, HUM HERED, V56, P18, DOI 10.1159/000073729; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Carrasquillo MM, 2002, NAT GENET, V32, P237, DOI 10.1038/ng998; Ritchie MD, 2003, GENET EPIDEMIOL, V24, P150, DOI 10.1002/gepi.10218; Millstein J, 2006, AM J HUM GENET, V78, P15, DOI 10.1086/498850; Xiong MM, 2002, AM J HUM GENET, V70, P1257, DOI 10.1086/340392; Cordell HJ, 2002, HUM MOL GENET, V11, P2463, DOI 10.1093/hmg/11.20.2463; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Hoh J, 2003, NAT REV GENET, V4, P701, DOI 10.1038/nrg1155; Hoh J, 2001, GENOME RES, V11, P2115, DOI 10.1101/gr.204001; Efron B, 2004, ANN STAT, V32, P407; Nelson MR, 2001, GENOME RES, V11, P458, DOI 10.1101/gr.172901; Wallace C, 2006, AM J HUM GENET, V78, P498, DOI 10.1086/500562; Dudbridge Frank, 2006, Human Genomics, V2, P310; Aston CE, 2005, HUM GENET, V116, P208, DOI 10.1007/s00439-004-1206-7; Barlassina C, 2002, J AM SOC NEPHROL, V13, pS155, DOI 10.1097/01.ASN.0000032524.13069.88; Barroso I, 2003, PLOS BIOL, V1, P41, DOI 10.1371/journal.pbio.0000020; Becker T, 2005, GENET EPIDEMIOL, V29, P313, DOI 10.1002/gepi.20096; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Bureau A, 2005, GENET EPIDEMIOL, V28, P171, DOI 10.1002/gepi.20041; Cook Nancy R., 2004, Statistics in Medicine, V23, P1439, DOI 10.1002/sim.1749; Cordell HJ, 2001, GENETICS, V158, P357; Cox NJ, 1999, NAT GENET, V21, P213, DOI 10.1038/6002; Culverhouse R, 2004, GENET EPIDEMIOL, V27, P141, DOI 10.1002/gepi.20006; Culverhouse R, 2002, AM J HUM GENET, V70, P461, DOI 10.1086/338759; De Miglio MR, 2004, INT J CANCER, V111, P9, DOI 10.1002/ijc.20225; Devlin B, 2003, GENET EPIDEMIOL, V25, P36, DOI 10.1002/gepi.10237; Dong CH, 2005, EUR J HUM GENET, V13, P102, DOI 10.1038/sj.ejhg.5201292; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman J., 2005, PREDICTIVE LEARNING; Hastie T., 2001, ELEMENTS STAT LEARNI; Lunetta KL, 2004, BMC GENET, V5, DOI 10.1186/1471-2156-5-32; Moore JH, 2004, EXPERT REV MOL DIAGN, V4, P795, DOI 10.1586/14737159.4.6.795; Moore JH, 2002, ANN MED, V34, P88, DOI 10.1080/07853890252953473; Nicolae DL, 2002, NAT GENET, V30, P3, DOI 10.1038/ng0102-3; Olson JM, 2002, AM J HUM GENET, V71, P154, DOI 10.1086/341034; Potter DM, 2006, GENET EPIDEMIOL, V30, P438, DOI 10.1002/gepi.20155; RAO CR, 1962, J ROY STAT SOC B, V24, P152; Risch N, 1999, AM J HUM GENET, V65, P493, DOI 10.1086/302497; Risch NJ, 2000, NATURE, V405, P847, DOI 10.1038/35015718; Roldan V, 2005, HAEMATOLOGICA, V90, P421; Schymick JC, 2007, LANCET NEUROL, V6, P322, DOI 10.1016/S1474-4422(07)70037-6; Sha QY, 2006, ANN HUM GENET, V70, P677, DOI 10.1111/j.1469-1809.2006.00262.x; Souverein OW, 2006, ANN HUM GENET, V70, P372, DOI 10.1111/j.1469-1809.2005.00236.x; Templeton AR, 2000, EPISTASIS EVOLUTIONA; Tiwari HK, 1998, THEOR POPUL BIOL, V54, P161, DOI 10.1006/tpbi.1997.1373; Wichern D. W., 1998, APPL MULTIVARIATE ST; WILSON SR, 2001, ANN HUM GENET, V62, P565; Yanchina ED, 2004, B EXP BIOL MED+, V137, P64, DOI 10.1023/B:BEBM.0000024389.16247.0a; Yang P, 2004, CARCINOGENESIS, V25, P1935, DOI 10.1093/carcin/bgh203; Zhang SL, 2003, AM J HUM GENET, V73, P566, DOI 10.1086/378205	60	8	8	1	5	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0741-0395			GENET EPIDEMIOL	Genet. Epidemiol.	MAY	2008	32	4					285	300		10.1002/gepi.20304		16	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	295JP	WOS:000255471100001	18205210	
J	Hennenfent, G; Herrmann, FJ				Hennenfent, Gilles; Herrmann, Felix J.			Simply denoise: Wavefield reconstruction via jittered undersampling	GEOPHYSICS			English	Article							ROBUST UNCERTAINTY PRINCIPLES; SEISMIC DATA; FOURIER-TRANSFORM; INTERPOLATION; ALGORITHM; EQUATION	We present a new, discrete undersampling scheme designed to favor wavefield reconstruction by sparsity-promoting inversion with transform elements localized in the Fourier domain. The work is motivated by empirical observations in the seismic community, corroborated by results from compressive sampling, that indicate favorable (wavefield) reconstructions from random rather than regular undersampling. Indeed, random undersampling renders coherent aliases into harmless incoherent random noise, effectively turning the interpolation problem into a much simpler denoising problem. A practical requirement of wavefield reconstruction with localized sparsifying transforms is the control on the maximum gap size. Unfortunately, random undersampling does not provide such a control. Thus, we introduce a sampling scheme, termed jittered undersampling, that shares the benefits of random sampling and controls the maximum gap size. The contribution of jittered sub-Nyquist sampling is key in formulating a versatile wavefield sparsity-promoting recovery scheme that follows the principles of compressive sampling. After the behavior of the jittered-undersampling scheme in the Fourier domain is analyzed, its performance is studied for curvelet recovery by sparsity-promoting inversion (CRSI). The findings on synthetic and real seismic data indicate an improvement of several decibels over recovery from regularly undersampled data for the same amount of data collected.	[Hennenfent, Gilles; Herrmann, Felix J.] Univ British Columbia, Dept Earth & Ocean Sci, Vancouver, BC V5Z 1M9, Canada	Hennenfent, G (reprint author), Univ British Columbia, Dept Earth & Ocean Sci, Vancouver, BC V5Z 1M9, Canada.	ghennenfent@eos.ubc.ca; fherrmann@eos.ubc.ca					Sacchi MD, 1998, IEEE T SIGNAL PROCES, V46, P31, DOI 10.1109/78.651165; Xu S, 2005, GEOPHYSICS, V70, pV87, DOI 10.1190/1.1993713; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Abma R, 2006, GEOPHYSICS, V71, pE91, DOI 10.1190/1.2356088; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X; Zwartjes PM, 2007, GEOPHYSICS, V72, pV21, DOI 10.1190/1.2399442; Candes EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Trad D, 2003, GEOPHYSICS, V68, P386, DOI 10.1190/1.1543224; Hennenfent G, 2006, COMPUT SCI ENG, V8, P16, DOI 10.1109/MCSE.2006.49; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Bednar J. B., 1996, LEADING EDGE, V15, P763, DOI [10.1190/1.1437365, DOI 10.1190/1.1437365]; BIONDI B, 1998, GEOPHYSICS, V63, P1177; Candes E.J., 2005, COMMUNICATIONS PURE, V99, P1207; Canning A, 1996, GEOPHYSICS, V61, P1103, DOI 10.1190/1.1444031; CLAERBOU.JF, 1971, GEOPHYSICS, V36, P467, DOI 10.1190/1.1440185; DIPPE M, 1992, PROGR COMPUTER GRAPH, V1, P1; DONOHO DL, 2006, TR20062 STANF STAT D; FIGUEIREDO MA, 2007, GRADIENT PROJECTION; Frigo M., 1998, ICASSP C P, V3, P1381; GERSZTENKORN A, 1986, GEOPHYSICS, V51, P357, DOI 10.1190/1.1442095; Hennenfent G., 2005, 75 ANN INT M SEG, P2162; HERRMANN FJ, 2008, GEOPHYS J INT; Herrmann FJ, 2008, GEOPHYSICS, V73, pA1, DOI 10.1190/1.2799517; LENEMAN OAZ, 1966, INFORM CONTROL, V9, P347, DOI 10.1016/S0019-9958(66)80002-5; SPITZ S, 1991, GEOPHYSICS, V67, P890; Stolt RH, 2002, GEOPHYSICS, V67, P890, DOI 10.1190/1.1484532; Sun YH, 1997, GEOPHYSICS, V62, P918, DOI 10.1190/1.1444199; TRAD DO, 1999, 6 INT C BRAZ GEOPH S; TRAD DO, 2005, CSEG NAT CONV, P309; van den Berg E., 2007, TR200716 U BRIT COL; Verdu S., 1998, MULTIUSER DETECTION; VERSCHUUR DJ, 1992, GEOPHYSICS, V57, P1166, DOI 10.1190/1.1443330; Wang JF, 2007, GEOPHYSICS, V72, pS11, DOI 10.1190/1.2387139; Zhou C., 1995, 65 ANN INT M SEG, P1145	38	58	55	3	7	SOC EXPLORATION GEOPHYSICISTS	TULSA	8801 S YALE ST, TULSA, OK 74137 USA	0016-8033			GEOPHYSICS	Geophysics	MAY-JUN	2008	73	3					V19	V28		10.1190/1.2841038		10	Geochemistry & Geophysics	Geochemistry & Geophysics	313PE	WOS:000256751700031		
J	Yardibi, T; Li, J; Stoica, P; Cattafesta, LN				Yardibi, Tarik; Li, Jian; Stoica, Petre; Cattafesta, Louis N., III			Sparsity constrained deconvolution approaches for acoustic source mapping	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA			English	Article							ARRAYS; REPRESENTATIONS; SELECTION; NOISE	Using microphone arrays for estimating source locations and strengths has become common practice in aeroacoustic applications.' The classical delay-and-sum approach suffers from low resolution and high sidelobes and the resulting beamforming maps are difficult to interpret. The deconvolution approach for the mapping of acoustic sources (DAMAS) deconvolution algorithm recovers the actual source levels from the contaminated delay-and-sum results by defining an inverse problem that can be represented as a linear system of equations. In this paper, the deconvolution problem is carried onto the sparse signal representation area and a sparsity constrained deconvolution approach (SC-DAMAS) is presented for solving the DAMAS inverse problem. A sparsity preserving covariance matrix fitting approach (CMF) is also presented to overcome the drawbacks of the DAMAS inverse problem. The proposed algorithms are convex optimization problems. Our simulations show that CMF and SC-DAMAS outperform DAMAS and as the noise in the measurements increases, CMF works better than both DAMAS and SC-DAMAS. It is observed that the proposed algorithms converge faster than DAMAS. A modification to SC-DAMAS is also provided which makes it significantly faster than DAMAS and CMF. For the correlated source case, the CMF-C algorithm is proposed and compared with DAMAS-C. Improvements in performance are obtained similar to the uncorrelated case. (c) 2008 Acoustical Society of America.	[Yardibi, Tarik; Li, Jian] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA; [Stoica, Petre] Uppsala Univ, Dept Informat Technol, SE-75105 Uppsala, Sweden; [Cattafesta, Louis N., III] Univ Florida, Dept Mech & Aerosp Engn, Gainesville, FL 32611 USA	Li, J (reprint author), Univ Florida, Dept Elect & Comp Engn, POB 116130, Gainesville, FL 32611 USA.	li@dsp.ufl.edu	Cattafesta, Louis/A-9545-2015	Cattafesta, Louis/0000-0002-5767-3383			Malioutov D, 2005, IEEE T SIGNAL PROCES, V53, P3010, DOI 10.1109/TSP.2005.850882; Brooks TF, 2006, J SOUND VIB, V294, P856, DOI 10.1016/j.jsv.2005.12.046; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Li J, 2003, IEEE T SIGNAL PROCES, V51, P1702, DOI 10.1109/TSP.2003.812831; Wipf DP, 2007, IEEE T SIGNAL PROCES, V55, P3704, DOI 10.1109/TSP.2007.894265; Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172; BOYD S, 2004, CONVEX OOPTIMIZATION; Brooks T. F., 2006, 12 AIAA CEAS AER C C; BROOKS TF, 1999, 5 AIAA CEAS AER C EX; Brooks TF, 2005, 11 AIAA CEAS AER C M; BROOKS TF, 1987, J SOUND VIB, V112, P192, DOI 10.1016/S0022-460X(87)80105-0; Brooks T.F., 2004, 10 AIAA CEAS AER C M; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Dougherty R.P., 2005, 11 AIAA CEAS AER C M; Dougherty RP, 2002, AEROACOUSTIC MEASURE, P63; EHRENFRIED K, 2006, 12 AIAA CEAS AER C C; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Fuchs JJ, 2001, IEEE T SIGNAL PROCES, V49, P702, DOI 10.1109/78.912914; Fuchs JJ, 2005, IEEE T INFORM THEORY, V51, P3601, DOI 10.1109/TIT.2005.855614; Fuchs JJ, 2004, IEEE T INFORM THEORY, V50, P1341, DOI 10.1109/TIT.2004.828141; Fuchs JJ, 1996, INT CONF ACOUST SPEE, P3161, DOI 10.1109/ICASSP.1996.550547; Humphreys W.M., 1998, 4 AIAA CEAS AER C RE; Li J, 2007, IEEE T SIGNAL PROCES, V55, P5643, DOI 10.1109/TSP.2007.899343; Li J, 1996, IEEE T SIGNAL PROCES, V44, P281; Lofberg J., 2004 IEEE INT S COMP, P284; MEADOWS KR, 1997, 3 AIAA CEAS AER C AT; RAVETTA PA, 2006, 12 AIAA CEAS AER C C; Stoica P., 2005, SPECTRAL ANAL SIGNAL; TROPP JA, 2006, IEEE T INFORM THEORY, V51, P1030; Van Trees H. L., 2002, OPTIMUM ARRAY PROCES; Wang YW, 2004, J ACOUST SOC AM, V115, P757, DOI 10.1121/1.1639906	34	34	35	7	13	ACOUSTICAL SOC AMER AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0001-4966			J ACOUST SOC AM	J. Acoust. Soc. Am.	MAY	2008	123	5	1				2631	2642		10.1121/1.2896754		12	Acoustics; Audiology & Speech-Language Pathology	Acoustics; Audiology & Speech-Language Pathology	301FE	WOS:000255881000022	18529183	
J	Davison, AC				Davison, A. C.			Some challenges for statistics	STATISTICAL METHODS AND APPLICATIONS			English	Article; Proceedings Paper	Workshop on New Challenges and Developments in Statistics	SEP   22, 2006	Venice, ITALY			Bayesian inference; composite likelihood; likelihood asymptotics; metabolite profiling; mixture model; sparsity; statistical education; stochastic model; wavelet regression	APPROXIMATE CONDITIONAL INFERENCE; LIKELIHOOD; REGRESSION; ASYMPTOTICS; SHRINKAGE; SELECTION; MODELS	The paper gives a highly personal sketch of some current trends in statistical inference. After an account of the challenges that new forms of data bring, there is a brief overview of some topics in stochastic modelling. The paper then turns to sparsity, illustrated using Bayesian wavelet analysis based on a mixture model and metabolite profiling. Modern likelihood methods including higher order approximation and composite likelihood inference are then discussed, followed by some thoughts on statistical education.	Ecole Polytech Fed Lausanne, Sch Basic Sci, Inst Math, STAT IMA FSB EPFL, CH-1015 Lausanne, Switzerland	Davison, AC (reprint author), Ecole Polytech Fed Lausanne, Sch Basic Sci, Inst Math, STAT IMA FSB EPFL, Stn 8, CH-1015 Lausanne, Switzerland.	anthony.davison@epfl.ch					Abramovich F, 1998, J ROY STAT SOC B, V60, P725, DOI 10.1111/1467-9868.00151; Ancey C, 2008, J FLUID MECH, V595, P83, DOI 10.1017/S0022112007008774; Fisher RA, 1925, P CAMB PHILOS SOC, V22, P700; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Johnstone IM, 2005, ANN STAT, V33, P1700, DOI 10.1214/009053605000000345; Lonnstedt I, 2002, STAT SINICA, V12, P31; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; AZZALINI A, 1983, BIOMETRIKA, V70, P381; Barndorff-Nielsen OE, 2003, J R STAT SOC B, V65, P775, DOI 10.1111/1467-9868.00415; BARNDORFFNIELSE.OE, 1994, INFERENCE ASYMPTOTIC; BARNDORFFNIELSE.OE, 2001, LEVY PROCESSES THEOR; BELLIO R, 1999, STAT APPL, V11, P251; Bellio R, 2003, J COMPUT GRAPH STAT, V12, P682, DOI 10.1198/1061860032003; Bellio R, 2001, STAT COMPUT, V11, P17, DOI 10.1023/A:1026501714434; BELLIO R, 1999, THESIS U PADOVA; Bhowmick D, 2006, BIOSTATISTICS, V7, P630, DOI 10.1093/biostatistics/kxj032; Bickel P, 1993, EFFICIENT ADAPTIVE E; Bohm T, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.061307; BRAZZALE AR, 2000, THESIS SWISS FEDERAL; BRAZZALE AR, 2007, CASE STUDIES SMALL S; Brazzale AR, 1999, J COMPUT GRAPH STAT, V8, P653, DOI 10.2307/1390882; BUHLMANN P, 2006, BOOSTING ALGORITHMS; Castillo JD, 2006, BERNOULLI, P491, DOI [10.3150/bj/1151525132, DOI 10.3150/BJ/1151525132]; Chellappa R., 1993, MARKOV RANDOM FIELDS; Clifford P., 1990, DISORDER PHYS SYSTEM, P19; COX DR, 2004, BIOMETRIKA, V91, P211; COX DR, 1988, P ROY SOC LOND A MAT, V415, P317, DOI 10.1098/rspa.1988.0016; Davison A. C., 2003, STAT MODELS; EFRON B, 2003, STOCHASTIC MUSINGS P, P31; Fisher RA, 1934, P R SOC LOND A-CONTA, V144, P0285, DOI 10.1098/rspa.1934.0050; FISHER RA, 1922, PHILOS T R SOC A, V222, P309, DOI DOI 10.1098/RSTA.1922.0009; Gu C., 2002, SMOOTHING SPLINE ANO; HALL P, 2005, PAPERS HONOUR SIR D, P137; Hastie T., 2001, ELEMENTS STAT LEARNI; Heard NA, 2006, J AM STAT ASSOC, V101, P18, DOI 10.1198/016214505000000187; ISHAM V, 1981, INT STAT REV, V49, P21, DOI 10.2307/1403035; ISHAM VS, 2005, PAPERS HONOUR SIR D, P27; Kou SC, 2005, J ROY STAT SOC C-APP, V54, P469, DOI 10.1111/j.1467-9876.2005.00509.x; LAU JW, 2008, IN PRESS J COMPUTATI; Lindsay B., 1988, CONT MATH, V80, P220; McCulloch CE, 2001, GEN LINEAR MIXED MOD; Messerli G, 2007, PLANT PHYSIOL, V143, P1484, DOI 10.1104/pp.106.090795; Murphy SA, 2000, J AM STAT ASSOC, V95, P449, DOI 10.2307/2669386; Owen A. B., 2001, EMPIRICAL LIKELIHOOD; Pace L., 1997, PRINCIPLES STAT INFE; Panaretos VM, 2006, ADV APPL PROBAB, V38, P320, DOI 10.1239/aap/1151337074; Panaretos VM, 2007, J MATH BIOL, V54, P645, DOI 10.1007/s00285-006-0062-6; Pearce ND, 2006, AM STAT, V60, P233, DOI 10.1198/000313006X124541; PORPORATO A, 2005, PAPERS HONOUR SIR D, P55; Reid N, 2003, ANN STAT, V31, P1695, DOI 10.1214/aos/1074290325; ROTNITZKY A, 2005, PAPERS HONOUR SIR D, P115; Sartori N, 2003, BIOMETRIKA, V90, P533, DOI 10.1093/biomet/90.3.533; Severini T.A., 2000, LIKELIHOOD METHODS S; VARIN C, 2008, IN PRESS STATISTICS; Wahba G., 1990, CBMS NSF REGIONAL C	59	1	1	0	1	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1618-2510			STAT METHOD APPL	Stat. Method. Appl.	MAY	2008	17	2					167	181		10.1007/s10260-007-0079-z		15	Statistics & Probability	Mathematics	290AO	WOS:000255095200003		
J	Meinshausen, N				Meinshausen, Nicolai			A note on the Lasso for Gaussian graphical model selection	STATISTICS & PROBABILITY LETTERS			English	Article							REGRESSION	Inspired by the success of the Lasso for regression analysis, it seems attractive to estimate the graph of a multivariate normal distribution by l(1)-norm penalized likelihood maximization. We examine some properties of the estimator and show that care has to be taken with interpretation of results as the estimator is not consistent for Some graphs. (c) 2007 Elsevier B.V. All rights reserved.	Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Meinshausen, N (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.	nicolai@stat.berkeley.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Edwards D., 2000, INTRO GRAPHICAL MODE; Lauritzen S. L., 1996, GRAPHICAL MODELS	9	11	11	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-7152			STAT PROBABIL LETT	Stat. Probab. Lett.	MAY	2008	78	7					880	884		10.1016/j.spl.2007.09.014		5	Statistics & Probability	Mathematics	306LF	WOS:000256249000006		
J	Wang, Q; Yin, XR				Wang, Qin; Yin, Xiangrong			A nonlinear multi-dimensional variable selection method for high dimensional data: Sparse MAVE	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							SLICED INVERSE REGRESSION; PRINCIPAL HESSIAN DIRECTIONS; MODEL SELECTION; REDUCTION; LASSO; SHRINKAGE	Traditional variable selection methods are model based and may suffer from possible model misspecification. On the other hand, sufficient dimension reduction provides us with a way to find sufficient dimensions without a parametric model. However, the drawback is that each reduced variable is a linear combination of all the original variables, which may be difficult to interpret. In this paper, focusing on the sufficient dimensions in the regression mean function, we combine the ideas of sufficient dimension reduction and variable selection to propose a shrinkage estimation method, sparse MAVE. The sparse MAVE can exhaustively estimate dimensions in the mean function, while selecting informative covariates simultaneously without assuming any particular model or particular distribution on the predictor variables. Furthermore, we propose a modified BIC criterion for effectively estimating the dimension of the mean function. The efficacy of sparse MAVE is verified through simulation studies and via analysis of a real data set. (c) 2008 Elsevier B.V. All rights reserved.	[Wang, Qin; Yin, Xiangrong] Univ Georgia, Dept Stat, Athens, GA 30602 USA	Yin, XR (reprint author), Univ Georgia, Dept Stat, 204 Stat Bldg, Athens, GA 30602 USA.	xryin@stat.uga.edu					Akaike H., 1973, 2 INT S INF THEOR, P267; BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Breiman L, 1996, ANN STAT, V24, P2350; COOK R. D., 1998, REGRESSION GRAPHICS; COOK RD, 1998, J AM STAT ASSOC, V93, P84, DOI 10.2307/2669605; COOK RD, 1991, J AM STAT ASSOC, V86, P328, DOI 10.2307/2290564; Cook RD, 2002, ANN STAT, V30, P455, DOI 10.1214/aos/1021379861; Cox DR, 1974, J R STAT SOC C-APPL, V23, P51; Friedman J. H., 1994, STAT NEURAL NETWORKS; Fung WK, 2002, STAT SINICA, V12, P1093; Henderson PW, 1998, J MARKETING, V62, P14, DOI 10.2307/1252158; LI KC, 1992, J AM STAT ASSOC, V87, P1025, DOI 10.2307/2290640; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Li LX, 2005, J ROY STAT SOC B, V67, P285, DOI 10.1111/j.1467-9868.2005.00502.x; Li LX, 2006, TECHNOMETRICS, V48, P503, DOI 10.1198/004017006000000129; Li LX, 2007, BIOMETRIKA, V94, P603, DOI 10.1093/biomet/asm044; Miller A, 2002, SUBSET SELECTION REG, V2nd; Naik PA, 2005, J AM STAT ASSOC, V100, P204, DOI 10.1198/016214504000000773; Ni LQ, 2005, BIOMETRIKA, V92, P242, DOI 10.1093/biomet/92.1.242; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; RUPPERT D, 1994, ANN STAT, V22, P1346, DOI 10.1214/aos/1176325632; Shi PD, 2002, J ROY STAT SOC B, V64, P237, DOI 10.1111/1467-9868.00335; Silverman B. M., 1986, DENSITY ESTIMATION S; Xia YC, 2002, J ROY STAT SOC B, V64, P363, DOI 10.1111/1467-9868.03411; Ye ZS, 2003, J AM STAT ASSOC, V98, P968, DOI 10.1198/016214503000000927; Yin XR, 2004, J COMPUT GRAPH STAT, V13, P554, DOI 10.1198/106186004X2462; ZHOU J, 2008, ANN STAT IN PRESS; Zhu LX, 2006, J AM STAT ASSOC, V101, P630, DOI 10.1198/016214505000001285; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	35	17	18	4	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473	1872-7352		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAY 15	2008	52	9					4512	4520		10.1016/j.csda.2008.03.003		9	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	317IS	WOS:000257014000025		
J	Zhang, M; Zhang, DB; Wells, MT				Zhang, Min; Zhang, Dabao; Wells, Martin T.			Variable selection for large p small n regression models with incomplete data: Mapping QTL with epistases	BMC BIOINFORMATICS			English	Article							QUANTITATIVE TRAIT LOCI; MORPHOLOGICAL SHAPE DIFFERENCE; GENETIC ARCHITECTURE; EXPERIMENTAL CROSSES; ESTIMATORS; PARAMETERS; SHRINKAGE	Background: Identifying quantitative trait loci (QTL) for both additive and epistatic effects raises the statistical issue of selecting variables from a large number of candidates using a small number of observations. Missing trait and/or marker values prevent one from directly applying the classical model selection criteria such as Akaike's information criterion (AIC) and Bayesian information criterion (BIC). Results: We propose a two-step Bayesian variable selection method which deals with the sparse parameter space and the small sample size issues. The regression coefficient priors are flexible enough to incorporate the characteristic of "large p small n" data. Specifically, sparseness and possible asymmetry of the significant coefficients are dealt with by developing a Gibbs sampling algorithm to stochastically search through low-dimensional subspaces for significant variables. The superior performance of the approach is demonstrated via simulation study. We also applied it to real QTL mapping datasets. Conclusion: The two-step procedure coupled with Bayesian classification offers flexibility in modeling "large p small n" data, especially for the sparse and asymmetric parameter space. This approach can be extended to other settings characterized by high dimension and low sample size.	[Zhang, Min; Zhang, Dabao] Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA; [Wells, Martin T.] Cornell Univ, Dept Biol Stat & Computat Biol, Ithaca, NY 14853 USA	Zhang, DB (reprint author), Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA.	minzhang@stat.purdue.edu; zhangdb@stat.purdue.edu; mtw1@cornell.edu					HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zeng ZB, 1999, GENET RES, V74, P279, DOI 10.1017/S0016672399004255; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Sanjuan R, 2005, GENETICS, V170, P1001, DOI 10.1534/genetics.105.040741; TANKSLEY SD, 1993, ANNU REV GENET, V27, P205, DOI 10.1146/annurev.ge.27.120193.001225; LANDER ES, 1989, GENETICS, V121, P185; Kao CH, 1999, GENETICS, V152, P1203; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Alvarez-Castro JM, 2007, GENETICS, V176, P1151, DOI 10.1534/genetics.106.067348; Ball RD, 2001, GENETICS, V159, P1351; Bateson W, 1909, MENDELS PRINCIPLES H; Bogdan M, 2005, HEREDITY, V95, P476, DOI 10.1038/sj.hdy.6800747; Bogdan M, 2004, GENETICS, V167, P989, DOI 10.1534/genetics.103.021683; BOGDAN M, BIOMETRICS IN PRESS; Broman KW, 2002, J R STAT SOC B, V64, P641, DOI 10.1111/1467-9868.00354; CARLBORG D, 2004, NATURE REV GENETICS, V5, P618; Cui YH, 2005, BIOINFORMATICS, V21, P2447, DOI 10.1093/bioinformatics/bti342; Doerge RW, 1997, STAT SCI, V12, P195; Eshed Y, 1996, GENETICS, V143, P1807; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fourdrinier D, 1998, ANN STAT, V26, P660; GAFFNEY P, 2001, THESIS U WISCONSIN M; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; HASTIE H, 1999, THESIS STANFORD U ST; Ishwaran H, 2005, ANN STAT, V33, P730, DOI 10.1214/009053604000001147; Jeffreys H., 1961, THEORY PROBABILITY; JEFFREYS H, 1935, P CAMBRIDGE PHILOS S, V31, P201; Kao CH, 2002, GENETICS, V160, P1243; Kao CH, 1997, BIOMETRICS, V53, P653, DOI 10.2307/2533965; Leamy LJ, 2002, EVOLUTION, V56, P642, DOI 10.1111/j.0014-3820.2002.tb01373.x; Little R., 2002, STAT ANAL MISSING DA; Liu J, 1996, GENETICS, V142, P1129; MITCHELL TJ, 1988, J AM STAT ASSOC, V83, P1023, DOI 10.2307/2290129; PORTNOY S, 1984, ANN STAT, V12, P1298, DOI 10.1214/aos/1176346793; Shi Weiliang, 2007, BMC Proc, V1 Suppl 1, pS60; Wagner A, 2000, NAT GENET, V24, P355, DOI 10.1038/74174; Wang H, 2005, GENETICS, V170, P465, DOI 10.1534/genetics.104.039354; Williams SM, 2000, HYPERTENSION, V36, P2; Xu SZ, 2007, GENETICS, V175, P1955, DOI 10.1534/genetics.106.066571; Yandell BS, 2007, BIOINFORMATICS, V23, P641, DOI 10.1093/bioinformatics/btm011; Yi NJ, 2002, GENET RES, V79, P185, DOI 10.1017/S0016672301005511; Yi NJ, 2007, GENETICS, V176, P1865, DOI 10.1534/genetics.107.071365; Yi NJ, 2007, GENETICS, V176, P1855, DOI 10.1534/genetics.107.071142; Yi NJ, 2005, GENETICS, V170, P1333, DOI 10.1534/genetics.104.040386; Zak M, 2007, GENETICS, V176, P1845, DOI 10.1534/genetics.106.068031; Zeng ZB, 2000, GENETICS, V154, P299; Zeng ZB, 2005, GENETICS, V169, P1711, DOI 10.1534/genetics.104.035857; ZHANG M, 2008, GENERALIZED SHRINKAG; Zhang M, 2005, GENETICS, V169, P2305, DOI 10.1534/genetics.104.034181	50	9	9	0	2	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAY 29	2008	9								251	10.1186/1471-2105-9-251		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	319IZ	WOS:000257158600001	18510743	
J	Lee, AB; Nadler, B; Wasserman, L				Lee, Ann B.; Nadler, Boaz; Wasserman, Larry			TREELETS - AN ADAPTIVE MULTI-SCALE BASIS FOR SPARSE UNORDERED DATA	ANNALS OF APPLIED STATISTICS			English	Article						Feature selection; dimensionality reduction; multi-resolution analysis; local best basis. sparsity; principal component analysis; hierarchical clusetering; small smaple sizes	NET ANALYTE SIGNAL; MULTIVARIATE CALIBRATION; PRINCIPAL COMPONENTS; VARIABLE SELECTION; DENSITY-ESTIMATION; WAVELET TRANSFORM; GENE-EXPRESSION; PREDICTION; CLASSIFICATION; CANCER	In many modern applications, including analysis of gene expression and texts documents, the data are noisy, high-dimensional, and unordered-with no particular meaning to the given order of the variables. Yet, successful learning is often possible due to sparsity: the fact that the data are typically redundant with underlying structures that can be represented by only a few features. In this paper we present treelets-a novel construction of multi-scale bases that extends wavelets to nonsmooth signals. The method is fully adaptive, as it returns a hierarchical tree and an orthonormal basis which both reflect the internal structure of the data. Treelets are especially well-suited as dimensionality reduction and feature selection tool prior to regression and classification, in situations where sample sizes are small and the data are sparse with unknown groupings of correlated or collinear variables. The method is also simple to implement and analyze theoretically. Here we describe a variety of situations where treelets perform better than principal component analysis, as well as some common variable selection and cluster averaging schemes. We illustrate treelets on a blocked covariance model and on several data sets (hyperspectral image data, DNA microarray data, and internet advertisements) with highly complex dependencies between variables.	[Lee, Ann B.; Wasserman, Larry] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA; [Nadler, Boaz] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Lee, AB (reprint author), Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA.	annlee@stat.cmu.edu; boaz.nadler@weizmann.ac.il; larry@stat.cmu.edu	Nadler, Boaz/C-7217-2008		NSF [CCF-0625879, DMS-0707059]; Hana and Julius Rosen fund; William Z. and Eda Bess Novick Young Scientist fund	Supported in part by NSF Grants CCF-0625879 and DMS-0707059.Supported by the Hana and Julius Rosen fund and by the William Z. and Eda Bess Novick Young Scientist fund.	AHN J, 2008, BIOMETRIKA IN PRESS; Angeletti C, 2005, LAB INVEST, V85, P1555, DOI 10.1038/labinvest.3700357; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Kalisch M, 2007, J MACH LEARN RES, V8, P613; Lorber A, 1997, ANAL CHEM, V69, P1620, DOI 10.1021/ac960862b; Bickel PJ, 2008, ANN STAT, V36, P199, DOI 10.1214/009053607000000758; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hall P, 2005, J ROY STAT SOC B, V67, P427, DOI 10.1111/j.1467-9868.2005.00510.x; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Johnstone IM, 2001, ANN STAT, V29, P295, DOI 10.1214/aos/1009210544; ASIMOV D, 1985, SIAM J SCI STAT COMP, V6, P128, DOI 10.1137/0906011; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; BERAN R, 1985, ANN STAT, V13, P95, DOI 10.1214/aos/1176346579; BUCKHEIT JB, 1995, P SOC PHOTO-OPT INS, V2569, P540, DOI 10.1117/12.217608; Coifman RR, 1996, PROCEEDINGS OF THE IEEE-SP INTERNATIONAL SYMPOSIUM ON TIME-FREQUENCY AND TIME-SCALE ANALYSIS, P129, DOI 10.1109/TFSA.1996.546703; Coifman R.R., 1992, IEEE T INFORM THEORY, V32, P712; Dettling M, 2004, J MULTIVARIATE ANAL, V90, P106, DOI 10.1016/j.jmva.2004.02.012; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Golub G., 1996, MATRIX COMPUTATIONS; Gruber M. H. J., 1998, IMPROVING EFFICIENCY; Hastie T, 2001, GENOME BIOL, V2; Hastie T., 2001, ELEMENTS STAT LEARNI; JOHNSTONE I, 2008, J AM STAT A IN PRESS; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Kushmerick N., 1999, Proceedings of the Third International Conference on Autonomous Agents, DOI 10.1145/301136.301186; Lee SW, 2007, IET COMPUT VIS, V1, P17, DOI 10.1049/iet-cvi:20045243; LEVINA E, 2007, SPARSE ESTIMAT UNPUB; Mallat S., 1998, WAVELET TOUR SIGNAL; Murtagh F, 2004, J CLASSIF, V21, P167, DOI 10.1007/s00357-004-0015-z; Murtagh F, 2007, J CLASSIF, V24, P3, DOI 10.1007/s00357-007-0007-9; Murtagh F, 2000, COMPUT J, V43, P107, DOI 10.1093/comjnl/43.2.107; Nadler B, 2005, J CHEMOMETR, V19, P107, DOI 10.1002/cem.915; NADLER B, 2007, FINITE SAMPLE UNPUB; Nadler B, 2005, J CHEMOMETR, V19, P45, DOI 10.1002/cem.906; Ogden R. T., 1997, ESSENTIAL WAVELETS S; SAITO N, 1995, LOCAL ORTHONORMAL BA, P1529; Saito N, 2002, PATTERN RECOGN, V35, P2841, DOI 10.1016/S0031-3203(02)00019-5; TIBSHIRANI R, 1999, CLUSTERING METHODS A; WHITTAKER J, 2001, GRAPHICAL MODELS MUL; ZHAO Z, 2007, P 20 INT JOINT C AI; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	53	24	24	0	4	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	JUN	2008	2	2					435	471		10.1214/07-AOAS137		37	Statistics & Probability	Mathematics	374QC	WOS:000261057800001		
J	Zou, H; Yuan, M				Zou, Hui; Yuan, Ming			Composite quantile regression and the oracle model selection theory	ANNALS OF STATISTICS			English	Article						asymptotic efficiency; linear program; model selection; oracle properties; universal lower bound	LASSO	Coefficient estimation and variable selection in multiple linear regression is routinely done in the (penalized) least squares (LS) framework. The concept of model selection oracle introduced by Fan and Li [J. Amer. Statist. Assoc. 96 (2001) 1348-1360] characterizes the optimal behavior of a model selection procedure. However, the least-squares oracle theory breaks down if the error variance is infinite. In the current paper we propose a new regression method called composite quantile regression (CQR). We show that the oracle model selection theory using the CQR oracle works beautifully even when the error variance is infinite. We develop a new oracular procedure to achieve the optimal properties of the CQR oracle. When the error variance is finite, CQR still enjoys great advantages in terms of estimation efficiency. We show that the relative efficiency of CQR compared to the least squares is greater than 70% regardless the error distribution. Moreover, CQR could be much more efficient and sometimes arbitrarily more efficient than the least squares. The same conclusions hold when comparing a CQR-oracular estimator with a LS-oracular estimator.	[Zou, Hui] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA; [Yuan, Ming] Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA	Zou, H (reprint author), Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA.	hzou@stat.umn.edu; myuan@isye.gatech.edu					BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Koenker R, 2001, J AM STAT ASSOC, V96, P458, DOI 10.1198/016214501753168172; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Fan J., 2006, P INT C MATH, P595; Feller W., 1968, INTRO PROBABILITY TH, VI; Knight K, 1998, ANN STAT, V26, P755; Koenker R, 2001, J ECON PERSPECT, V15, P143, DOI 10.1257/jep.15.4.143; Koenker R, 2005, QUANTILE REGRESSION; ZOU H, 2007, COMPOSITE QUANTILE R	11	80	89	2	8	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	JUN	2008	36	3					1108	1126		10.1214/07-AOS507		19	Statistics & Probability	Mathematics	310BR	WOS:000256504400004		
J	Hofmann, T; Scholkopf, B; Smola, AJ				Hofmann, Thomas; Schoelkopf, Bernhard; Smola, Alexander J.			Kernel methods in machine learning	ANNALS OF STATISTICS			English	Review						machine learning; reproducing kernels; support vector machines; graphical models	SUPPORT VECTOR MACHINES; INDEPENDENT COMPONENT ANALYSIS; LOG-LINEAR MODELS; PROJECTION PURSUIT; PATTERN-RECOGNITION; CANONICAL-ANALYSIS; METRIC-SPACES; REGRESSION; REGULARIZATION; APPROXIMATION	We review machine learning methods employing positive definite kernels. These methods formulate learning and estimation problems in a reproducing kernel Hilbert space (RKHS) of functions defined on the data domain, expanded in terms of a kernel. Working in linear spaces of function has the benefit of facilitating the construction and analysis of learning algorithms while at the same time allowing large classes of functions. The latter include nonlinear functions as well as functions defined on nonvectorial data. We cover a wide range of methods, ranging from binary classifiers to sophisticated methods for estimation with structured data.	[Hofmann, Thomas] Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany; [Schoelkopf, Bernhard] Max Planck Inst Biol Cybernet, Tubingen, Germany; [Smola, Alexander J.] Natl ICT Australia, Stat Machine Learning Program, Canberra, ACT, Australia	Hofmann, T (reprint author), Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.	hofmann@int.tu-darmstadt.de; bs@tuebingen.mpg.de; Alex.Smola@nicta.com.au	Scholkopf, Bernhard/A-7570-2013				Aizerman M.A., 1964, AUTOMAT REM CONTR, V25, P821; Allwein E. L., 2000, P 17 INT C MACH LEAR, P9; Alon N., 1993, Proceedings. 34th Annual Symposium on Foundations of Computer Science (Cat. No.93CH3368-8), DOI 10.1109/SFCS.1993.366858; ALTUN Y, 2004, P INT C MACH LEARN, P25; Altun Y., 2003, P 20 INT C MACH LEAR, P3; ALTUN Y, 2004, UNCERTAINTY ARTIFICI, P2; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Schoenberg IJ, 1938, ANN MATH, V39, P811, DOI 10.2307/1968466; Smola AJ, 2003, LECT NOTES ARTIF INT, V2777, P144, DOI 10.1007/978-3-540-45167-9_12; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Taskar B, 2004, ADV NEUR IN, V16, P25; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Bochner S, 1933, MATH ANN, V108, P378, DOI 10.1007/BF01452844; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; FIEDLER M, 1973, CZECH MATH J, V23, P298; Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI DOI 10.2307/1990404; Bach FR, 2002, J MACHINE LEARNING R, V3, P1; Bakir G. H., 2007, PREDICTING STRUCTURE; BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2; Barndorff-Nielsen O., 1978, INFORM EXPONENTIAL F; Bartlett P. L., 2002, J MACHINE LEARNING R, V3, P463; Basilico J., 2004, P 21 INT C MACH LEAR, P65; Baum L.E., 1972, INEQUALITIES, V3, P1; Ben-David S, 2003, J COMPUT SYST SCI, V66, P496, DOI 10.1016/S0022-0000(03)00038-2; Bennett KP, 2000, P 17 INT C MACH LEAR, P65; Bennett KP, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Berg C, 1984, HARMONIC ANAL SEMIGR; Bertsimas D., 1997, INTRO LINEAR PROGRAM; Bloomfield P., 1983, LEAST ABSOLUTE DEVIA; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Bousquet O., 2005, ESAIM-PROBAB STAT, V9, P323; Chapelle O., 2005, ADV NEURAL INFORM PR, V17, P257; Chen AY, 2005, IEEE T SIGNAL PROCES, V53, P3625, DOI 10.1109/TSP.2005.855098; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; COLLEDGE B, 2000, INT CONSTRUCTION LAW, V17, P175; Cook D., 1993, J COMPUTATIONAL GRAP, V2, P225, DOI 10.2307/1390644; Cortes C., 2005, ICML, P153; Crammer K., 2001, J MACHINE LEARNING R, V2, P265; CRAMMER K, 2005, P ANN C COMP LEARN T, P48; Cristianini N, 2002, ADV NEUR IN, V14, P367; Cristianini N., 2000, INTRO SUPPORT VECTOR; Culotta A., 2005, UMCS2005028; DAS S, 1994, LINEAR ALGEBRA APPL, V210, P29, DOI 10.1016/0024-3795(94)90464-2; Dauxois J, 1998, ANN STAT, V26, P1254; Dawid A. P., 1992, Statistics and Computing, V2, DOI 10.1007/BF01890546; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Dekel O, 2004, ADV NEUR IN, V16, P497; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Collins M, 2002, ADV NEUR IN, V14, P625; EINMAHL JHJ, 1992, ANN STAT, V20, P1062, DOI 10.1214/aos/1176348670; Elisseeff A, 2002, ADV NEUR IN, V14, P681; FITZGERALD CH, 1995, LINEAR ALGEBRA APPL, V221, P83, DOI 10.1016/0024-3795(93)00232-O; Fletcher R., 1989, PRACTICAL METHODS OP; Fortet R, 1953, ANN SCI ECOLE NORM S, V70, P266; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Gartner T., 2003, SIGKDD EXPLORATIONS, V5, P49, DOI DOI 10.1145/959242.959248; Green P. J., 1985, LECTURE NOTES STATIS, V32, P44; Gretton A, 2005, P INT C ALG LEARN TH, P63; Gretton A., 2005, P 10 INT WORKSH ART, P112; Ham J., 2004, P 21 INT C MACH LEAR, P369; Hammersley J., 1971, MARKOV FIELDS UNPUB; Haussler D., 1999, UCSCCRL9910 COMP SCI; Hein M, 2005, J COMPUT SYST SCI, V71, P333, DOI 10.1016/j.jcss.2004.10.013; Herbrich R., 2002, LEARNING KERNEL CLAS; Herbrich R, 2000, ADV NEUR IN, P115; HILBERT D, 1904, NACHR AKAD WISS GO P, V2, P49; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hofmann T., 2006, 156 MAX PLANCK I BIO; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Huber P. J., 1981, ROBUST STAT; Hyvarinen A., 2001, INDEPENDENT COMPONEN; JAAKKOLA TS, 1999, P 7 INT WORKSH A1 ST; Jebara T, 2003, LECT NOTES ARTIF INT, V2777, P57, DOI 10.1007/978-3-540-45167-9_6; Jensen F.V., 1990, COMPUTATIONAL STATIS, V4, P269; Joachims T., 2002, LEARNING CLASSIFY TE; Joachims T., 2005, P 22 INT C MACH LEAR, P377, DOI 10.1145/1102351.1102399; JONES MC, 1987, J ROY STAT SOC A STA, V150, P1, DOI 10.2307/2981662; JORDAN MI, 2003, 638 U CAL; KARUSH W, 1939, THESIS U CHIC DEP MA; Kashima H., 2003, P 20 INT C MACH LEAR, P321; KETTENRI.JR, 1971, BIOMETRIKA, V58, P433, DOI 10.2307/2334380; Kim KI, 2005, IEEE T PATTERN ANAL, V27, P1351; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Koltchinskii V, 2001, IEEE T INFORM THEORY, V47, P1902, DOI 10.1109/18.930926; Kondor I., 2002, P 19 INT C MACH LEAR, P315; Kuhn H., 1951, P 2 BERK S MATH STAT, P481; LAFFERTY J, 2004, P INT C MACH LEARN, V21, P64; Lafferty J.D., 2001, P INT C MACH LEARN, V18, P282; Lee TW, 2000, COMPUT MATH APPL, V39, P1, DOI 10.1016/S0898-1221(00)00101-2; Leslie Christina, 2002, Pac Symp Biocomput, P564; Loeve M, 1978, PROBABILITY THEORY, V2; MAGERMAN DM, 1996, SPRINGER VERLAG LECT, V1147, P1; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; MCCALLUM A, 2005, C IMC AO UAI, V388; Mendelson S., 2003, LECT NOTES COMPUT SC, P1; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; Minsky M., 1969, PERCEPTRONS INTRO CO; Morozov V.A., 1984, METHODS SOLVING INCO; Murray M. K., 1993, DIFFERENTIAL GEOMETR; Nelder JA, 1983, GEN LINEAR MODELS; Oliver N, 2000, ADV NEUR IN, P51; OSULLIVAN F, 1986, J AM STAT ASSOC, V81, P96, DOI 10.2307/2287973; Parzen E., 1970, P 12 BIENN SEM CAN M, P1; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; POGGIO T, 1975, BIOL CYBERN, V19, P201, DOI 10.1007/BF00334440; Press WH, 1994, NUMERICAL RECIPES C, V2nd; RASMUSSEN CE, 2006, GAUSSIAN PROCESSESFO; Ratsch G, 2007, PLOS COMPUT BIOL, V3, P313, DOI 10.1371/journal.pcbi.0030020; RENYI A., 1959, ACTA MATH ACAD SCI H, V10, P441, DOI DOI 10.1007/BF02024507; Rockafellar R.T., 1970, CONVEX ANAL; Scholkopf B., 1997, SUPPORT VECTOR LEARN; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B., 2004, KERNEL METHODS COMPU; Sha F., 2003, P HLT NAACL, p213 ; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; SMOLA AJ, 2000, ADV LARGE MATGIN CLA; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Smola AJ, 1998, ALGORITHMICA, V22, P211, DOI 10.1007/PL00013831; Steinwart I, 2002, J MACH LEARN RES, V2, P67; Steinwart I, 2002, J COMPLEXITY, V18, P768, DOI 10.1006/jcom.2002.0642; Stewart J, 1976, ROCKY MOUNTAIN MATH, V6, P409; Stitson MO, 1999, ADVANCES IN KERNEL METHODS, P285; TASKAR B, 2004, EMPIRICAL METHODS NA, V1; Tax DM J, 1999, P EUR S ART NEUR NET, P251; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1035; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Van Rijsbergen C., 1979, INFORM RETRIEVAL; Vapnik V.N., 1963, Avtomatika i Telemekhanika, V24; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V, 1997, ADV NEUR IN, V9, P281; Vapnik V., 1991, PATTERN RECOGN, V1, P283; Vapnik V.N., 1995, NATURE STAT LEARNING; Vapnik VN, 1982, ESTIMATION DEPENDENC; Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0; VISHWANATHAN SVN, 2004, KERNEL METHODS COMPU, P3; WAHBA G., 1990, SPLINE MODELSFOR OBS; Wahba G, 1995, ANN STAT, V23, P1865; Wainwright M., 2003, 649 U CAL DEP STAT; Watkins C, 2000, ADV NEUR IN, P39; Wendland H., 2005, SCATTERED DATA APPRO; WESTON J, 2003, ADV NEURAL INFORM PR, V15, P873; Whittaker J, 1990, GRAPHICAL MODELS APP; Yang HH, 1997, NEURAL COMPUT, V9, P1457, DOI 10.1162/neco.1997.9.7.1457; Zettlemoyer L. S., 2005, UAI, P658	157	170	180	6	51	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	JUN	2008	36	3					1171	1220		10.1214/009053607000000677		50	Statistics & Probability	Mathematics	310BR	WOS:000256504400007		
J	Chan, ZSH; Havukkala, I; Jain, V; Hu, YJ; Kasabov, N				Chan, Zeke S. H.; Havukkala, Ilkka; Jain, Vishal; Hu, Yingjie; Kasabov, Nikola			Soft computing methods to predict gene regulatory networks: An integrative approach on time-series gene expression data	APPLIED SOFT COMPUTING			English	Article; Proceedings Paper	BISC International Special Event on Forging the Frontiers (BISCSE'05)	NOV 03-06, 2005	Berkeley, CA		Univ Calif Berkeley	gene regulatory network; reverse-engineering; LARS; automatic model building; time series microarray data; yeast; schizosaccharomyces pombe	FISSION YEAST; SCHIZOSACCHAROMYCES-POMBE; CELL-CYCLE; RIBONUCLEOTIDE REDUCTASE; SACCHAROMYCES-CEREVISIAE; REGRESSION; MICROARRAY; IDENTIFICATION; SELECTION	To unravel the controlling mechanisms of gene regulation, in this paper we present the application of sophisticated soft computing methods applied on an important problem from Bioinformatics-inferring gene regulatory networks (GRN) from time series gene expression microarray data. The main questions addressed in this paper are: (a) what knowledge can be derived from different models? (b) Would an integrated approach be more suitable to reveal about the controls of gene regulation? To reduce the number of genes in addition to apply the appropriate clustering methods, here we have also considered the valuable inputs from the biological experiments. To infer the GRN we have applied: three computational intelligence methods-Least Angle Regression (LARS), Expectation Maximization (EM) with Kalman Filter (KF), and an Evolving Fuzzy Neural Network (EFuNN). The methods are applied on time series microarray data of Schizosaccharomyces pombe yeast cell-cycle genes. Each method reveals some new aspects of the problem and it is agreed that to infer the GRN and to understand the processes behind gene regulation it is more suitable to adopt such integrative approach as ours through which some new knowledge is discovered, such as: using LARS we hypothesize-first, an exoglucanase gene exg1 is now implicated to be tied with MCB cluster regulation and second, a mannosidase with histone linked mannoses. A new quantitative prediction is that the time delay of the interaction between two genes seems to be approximately 30 min, or 0.17 cell cycles. Using the method of EM with KF, 25 cell cycle-regulated key genes were successfully clustered into three functionally co-regulated groups. We have also identified two genes namely Cdc22 and Suc22 that indeed interact with each other and are the potential candidates as a control in Ribonucleotide reductase (RNR) activity. Based on the EFuNN results and integrating knowledge from EM-KF method, we hypothesize that interaction between Suc22, Cdc22 and Mrc1 may be mediated by two other genes namely Cds1 and Spd1. The methods discussed and applied here can be used to analyze any kind of short time series of many interacting variables for inferring the regulatory network. Researchers should take such integrative computational intelligence approach seriously to understand the complex phenomenon of gene regulation and thus to simulate the development of the cell. (C) 2007 Elsevier B.V. All rights reserved.	[Chan, Zeke S. H.; Havukkala, Ilkka; Jain, Vishal; Hu, Yingjie; Kasabov, Nikola] Knowledge Engn & Discovery Res Inst, Auckland, New Zealand	Kasabov, N (reprint author), Knowledge Engn & Discovery Res Inst, 581 AUT Technol Pk,Great S Rd, Auckland, New Zealand.	nkasabov@aut.ac.nz		havukkala, ilkka/0000-0002-3934-7306			Rustici G, 2004, NAT GENET, V36, P809, DOI 10.1038/ng1377; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Guldener U, 2005, NUCLEIC ACIDS RES, V33, pD364, DOI 10.1093/nar/gki053; Yeung MKS, 2002, P NATL ACAD SCI USA, V99, P6163, DOI 10.1073/pnas.092576199; Marguerat S, 2006, YEAST, V23, P261, DOI 10.1002/yea.1351; Liu C, 2003, GENE DEV, V17, P1130, DOI 10.1101/gad.1090803; Chen DR, 2003, MOL BIOL CELL, V14, P214, DOI 10.1091/mbc.E02-08-0499; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Wood V, 2002, NATURE, V415, P871, DOI 10.1038/nature724; Peng X, 2005, MOL BIOL CELL, V16, P1026, DOI 10.1091/mbc.E04-04-0299; Efron B, 2004, ANN STAT, V32, P407; Wang P, 2005, GENOME BIOL, V6, DOI 10.1186/gb-2005-6-7-226; Arevalo-Rodriguez M, 2005, EUKARYOT CELL, V4, P17, DOI 10.1128/EC.4.1.17-29.2005; BALAKRISHNAN S, IN PRESS J MACH LEAR; Bar-Joseph Z, 2004, BIOINFORMATICS, V20, P2493, DOI 10.1093/bioinformatics/bth283; Berriz GF, 2003, BIOINFORMATICS, V19, P2502, DOI 10.1093/bioinformatics/btg363; Chan Zeke S. H., 2005, Journal of Bioinformatics and Computational Biology, V3, P1227, DOI 10.1142/S0219720005001478; Clare Amanda, 2002, In Silico Biology, V2, P511; Davidson EH, 2003, P NATL ACAD SCI USA, V100, P1475, DOI 10.1073/pnas.0437746100; GILKS WR, 2005, BIOINFORMATICS S2, V21; GUSTAFSSON M, 2005, COMP BIOL BIOINFORM, V2, P254; Hakansson P, 2006, J BIOL CHEM, V281, P1778; Han JDJ, 2004, NATURE, V430, P88, DOI 10.1038/nature02555; Han KS, 2004, NUCLEIC ACIDS RES, V32, pW89, DOI 10.1093/nar/gkh462; Hastie T., 2001, ELEMENTS STAT LEARNI; Huang X., 2005, BMC BIOINFORMATICS, V6, P1; Joseph JD, 1999, FUNGAL GENET BIOL, V27, P55, DOI 10.1006/fgbi.1999.1131; KASABOV N, 2002, P ICONIP 2002 INT C; Kasabov N., 2002, EVOLVING CONNECTIONI; Kasabov N, 2001, IEEE T SYST MAN CY B, V31, P902, DOI 10.1109/3477.969494; Li Fan, 2004, Genome Inform, V15, P131; Martin-Cuadrado AB, 2003, J CELL SCI, V116, P1689, DOI 10.1242/jcs.00377; Murphy K, 1999, MODELLING GENE EXPRE; Nagl SB, 2002, CURR DRUG TARGETS, V3, P387, DOI 10.2174/1389450023347452; Pe'er D, 2001, BIOINFORMATICS S1, V17, P215; Pemberton TJ, 2005, YEAST, V22, P927, DOI 10.1002/yea.1288; PENKETT CJ, TOGY WEB BASED INTEG; Simon I, 2001, CELL, V106, P697, DOI 10.1016/S0092-8674(01)00494-9; SOMEREN EPV, 2003, SIGNAL PROCESS, V83, P763; TIKKA J, 2004, P WORKSH TEMP DAT MI; WOOD V, 2006, TOPICS CURRENT GENET, P233; Wille A, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-11-r92	45	6	6	0	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946			APPL SOFT COMPUT	Appl. Soft. Comput.	JUN	2008	8	3					1189	1199		10.1016/j.asoc.2007.02.023		11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	273TH	WOS:000253954100004		
J	Wang, SJ; Zhu, J				Wang, Sijian; Zhu, Ji			Variable selection for model-based high-dimensional clustering and its application to microarray data	BIOMETRICS			English	Article						EM algorithm; high-dimension low sample size; microarray; model-based clustering; regularization; variable selection	MAXIMUM-LIKELIHOOD; ORACLE PROPERTIES; ADAPTIVE LASSO; CLASSIFICATION; PREDICTION; ALGORITHM	Variable selection in high-dimensional clustering analysis is an important yet challenging problem. In this article, we propose two methods that simultaneously separate data points into similar clusters and select informative variables that contribute to the clustering. Our methods are in the framework of penalized model-based clustering. Unlike the classical L-1-norm penalization, the penalty terms that we propose make use of the fact that parameters belonging to one variable should be treated as a natural "group." Numerical results indicate that the two new methods tend to remove noninformative variables more effectively and provide better clustering results than the L-1-norm approach.	[Wang, Sijian] Univ Michigan, Dept Biostat, Ann Arbor, MI 48109 USA; [Zhu, Ji] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA	Wang, SJ (reprint author), Univ Michigan, Dept Biostat, Ann Arbor, MI 48109 USA.	jizhu@umich.edu					BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Shen XT, 2002, J AM STAT ASSOC, V97, P210, DOI 10.1198/016214502753479356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Friedman JH, 2004, J ROY STAT SOC B, V66, P815, DOI 10.1111/j.1467-9868.2004.02059.x; Hoff PD, 2006, BAYESIAN ANAL, V1, P321; Liu J. S., 2003, BAYESIAN STAT, V7, P249; MARRON J, 2002, DISTANCE WEIGHTED DI; McLachlan G, 2002, FINITE MIXTURE MODEL; MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.2307/2337198; PAN W, 2006, J MACHINE LEARNING R, V8, P1145; Raftery AE, 2006, J AM STAT ASSOC, V101, P168, DOI 10.1198/016214506000000113; RAFTERY AE, 2003, BAYESIAN STAT, V7, P266; Tadesse MG, 2005, J AM STAT ASSOC, V100, P602, DOI 10.1198/0162145040000001565; ZHANG H, 2006, I STAT MIMEO SERIES, V2596; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037; ZHAO P, 2006, 703 U CAL DEP STAT; ZOU H, 2006, F NORM SUPPORT VECTO	27	29	30	1	7	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	JUN	2008	64	2					440	448		10.1111/j.1541-0420.2007.00922.x		9	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	302HN	WOS:000255959500014	17970821	
J	Tsygankova, IG				Tsygankova, Irina G.			Variable selection in QSAR models for drug design	CURRENT COMPUTER-AIDED DRUG DESIGN			English	Review						variable subset selection; stepwise regression; stochastic search; partial least squares; QSAR prediction	STRUCTURE-PROPERTY RELATIONSHIP; JUVENILE-HORMONE MIMETICS; ARTIFICIAL NEURAL NETWORKS; ANT COLONY OPTIMIZATION; PARTIAL LEAST-SQUARES; K-NEAREST-NEIGHBOR; GENETIC ALGORITHMS; BENZODIAZEPINE/GABA(A) RECEPTORS; REGRESSION-ANALYSIS; OBJECTIVE FUNCTION	QSAR modeling, a powerful method for the computer-aided drug design, demands appropriate choice of molecular structure description. At present thousands descriptors of molecular structure are suggested in QSAR and QSPR approaches. The selection of a subset of the most relevant molecular descriptors, used as variables, is important step in model development. In this short review recently reported algorithms for variable subset selection procedure are considered. The scoring functions and some other useful guidelines are discussed.	RAS, Inst Theoret & Expt Biophys, Pushchino 142290, Moscow Region, Russia	Tsygankova, IG (reprint author), RAS, Inst Theoret & Expt Biophys, Pushchino 142290, Moscow Region, Russia.	tsygan@iteb.ru					Abraham B, 1999, TECHNOMETRICS, V41, P135, DOI 10.2307/1270729; Agrafiotis DK, 2002, J MED CHEM, V45, P1098, DOI 10.1021/jm0104668; Baumann K, 2002, J CHEMOMETR, V16, P339, DOI 10.1002/cem.730; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tropsha A, 2003, QSAR COMB SCI, V22, P69, DOI 10.1002/qsar.200390007; Baumann K, 2003, TRAC-TREND ANAL CHEM, V22, P395, DOI 10.1016/S0165-9936(03)00607-1; Dorigo M, 1999, ARTIF LIFE, V5, P137, DOI 10.1162/106454699568728; BARONI M, 1993, QUANT STRUCT-ACT REL, V12, P9, DOI 10.1002/qsar.19930120103; Zupan J, 1997, CHEMOMETR INTELL LAB, V38, P1, DOI 10.1016/S0169-7439(97)00030-0; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P854, DOI 10.1021/ci00020a020; Eriksson L, 2003, ENVIRON HEALTH PERSP, V111, P1361, DOI 10.1289/ehp.5758; CVIJOVIC D, 1995, SCIENCE, V267, P664, DOI 10.1126/science.267.5198.664; Efron B, 2004, ANN STAT, V32, P407; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; Benigni R, 2000, CHEM REV, V100, P3697, DOI 10.1021/cr9901079; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Zheng WF, 2000, J CHEM INF COMP SCI, V40, P185, DOI 10.1021/ci980033m; ASHTON WT, 1993, J MED CHEM, V36, P591, DOI 10.1021/jm00057a009; Back T, 1993, EVOL COMPUT, V1, P1, DOI 10.1162/evco.1993.1.1.1; Basak SC, 2006, J CHEM INF MODEL, V46, P65, DOI 10.1021/ci050215y; Basak SC, 2007, SAR QSAR ENVIRON RES, V18, P45, DOI 10.1080/10629360601033671; Baumann K, 2005, QSAR COMB SCI, V24, P1033, DOI 10.1002/qsar.200530134; Belsey D. A., 1980, REGRESSION DIAGNOSTI, P104; Bridges AJ, 1996, J MED CHEM, V39, P267, DOI 10.1021/jm9503613; Buyukbingol E, 2007, BIOORGAN MED CHEM, V15, P4265, DOI 10.1016/j.bmc.2007.03.065; CAMILLERI P, 1993, J COMPUT AID MOL DES, V7, P61, DOI 10.1007/BF00141575; Cho SJ, 2002, J CHEM INF COMP SCI, V42, P927, DOI 10.1021/ci010247v; DEJONG K, 1990, MACH LEARN, V5, P351, DOI 10.1023/A:1022625623050; Draper N, 1981, APPL REGRESSION ANAL; Du YP, 2002, J CHEM INF COMP SCI, V42, P993, DOI 10.1021/ci020283+; Dutta D, 2007, J CHEM INF MODEL, V47, P989, DOI 10.1021/ci600563w; Eberhart R. C., 1995, P 6 INT S MICR HUM S, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/MHS.1995.494215, 10.1109/MHS.1995.494215#blank]; Fang H, 2001, CHEM RES TOXICOL, V14, P280, DOI 10.1021/tx000208y; FORREST S, 1993, SCIENCE, V261, P872, DOI 10.1126/science.8346439; Ghafourian T, 2005, SAR QSAR ENVIRON RES, V16, P171, DOI 10.1080/10629360412331319808; GOLDBRAIKH A, 2002, J MOL GRAPH MODEL, V20, P269; Gordeeva E.V., 1990, TETRAHEDRON COMPUT M, V3, P389, DOI 10.1016/0898-5529(90)90066-H; Hasegawa K, 1999, J CHEM INF COMP SCI, V39, P112, DOI 10.1021/ci980088o; HAYASHI T, 1990, J AGR FOOD CHEM, V38, P1965, DOI 10.1021/jf00100a019; HAYASHI T, 1991, J AGR FOOD CHEM, V39, P2029, DOI 10.1021/jf00011a031; HIRST JD, 1994, J COMPUT AID MOL DES, V8, P405, DOI 10.1007/BF00125375; Hoffmann R, 1996, B SOC CHIM FR, V133, P117; Itskowitz P, 2005, J CHEM INF MODEL, V45, P777, DOI 10.1021/ci049628+; Izrailev S, 2002, SAR QSAR ENVIRON RES, V13, P417, DOI 10.1080/10629360290014296; Katritzky A. R., 1994, CODESSA 2 0 COMPREHE; Khanna IK, 1997, J MED CHEM, V40, P1634, DOI 10.1021/jm9700225; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KUBINYI H, 1994, QUANT STRUCT-ACT REL, V13, P285, DOI 10.1002/qsar.19940130306; KUBINYI H, 1994, QUANT STRUCT-ACT REL, V13, P393, DOI 10.1002/qsar.19940130403; Kubinyi H, 1996, J CHEMOMETR, V10, P119; Kurup A, 2001, CHEM REV, V101, P2727, DOI 10.1021/cr000025g; LEARDI R, 1992, J CHEMOMETR, V6, P267, DOI 10.1002/cem.1180060506; Lin WQ, 2005, J CHEM INF MODEL, V45, P486, DOI 10.1021/ci049890i; Liu SP, 1997, ENVIRON SCI TECHNOL, V31, P3358, DOI 10.1021/es960695x; Liu SS, 2003, J CHEM INF COMP SCI, V43, P964, DOI 10.1021/ci020377j; MADDALENA DJ, 1995, J MED CHEM, V38, P715, DOI 10.1021/jm00004a017; MALPASS J, 1995, METHODS PRINCIPLES M; Marini F, 2005, J CHEM INF MODEL, V45, P1507, DOI 10.1021/ci0501645; MCFARLAND JW, 1994, QUANT STRUCT-ACT REL, V13, P11, DOI 10.1002/qsar.19940130104; Milne GWA, 1997, J CHEM INF COMP SCI, V37, P639, DOI 10.1021/ci960165k; Nicolotti O, 2002, J MED CHEM, V45, P5069, DOI 10.1021/jm020919o; NIWA A, 1989, J AGR FOOD CHEM, V37, P462, DOI 10.1021/jf00086a042; NIWA A, 1989, J AGR FOOD CHEM, V37, P467; NIWA A, 1989, J AGR FOOD CHEM, V37, P378; NIWA A, 1990, J AGR FOOD CHEM, V38, P514, DOI 10.1021/jf00092a040; Norinder U, 1997, J PEPT RES, V49, P155; NORINDER U, 1993, J COMPUT AID MOL DES, V7, P671, DOI 10.1007/BF00125325; NOVIC M, 1995, J CHEM INF COMP SCI, V35, P454, DOI 10.1021/ci00025a013; Ojelund H, 2001, J CHEMOMETR, V15, P497; Pompe M, 2004, J CHEM INF COMP SCI, V44, P399, DOI 10.1021/ci0304268; Rodriguez-Vazquez K, 1998, ELECTRON LETT, V34, P930, DOI 10.1049/el:19980632; Salt DW, 2004, J COMPUT AID MOL DES, V18, P495, DOI 10.1007/s10822-004-5203-7; SELWOOD DL, 1990, J MED CHEM, V33, P136, DOI 10.1021/jm00163a023; Shen M, 2002, J MED CHEM, V45, P2811, DOI 10.1021/jm010488u; Shen Q, 2003, ANAL BIOANAL CHEM, V375, P248, DOI 10.1007/s00216-002-1668-1; Shen Q, 2005, J CHEM INF MODEL, V45, P1024, DOI 10.1021/ci049610z; Shi WM, 2007, EUR J MED CHEM, V42, P81, DOI 10.1016/j.ejmech.2006.08.001; SKVORTSOVA MI, 1993, J CHEM INF COMP SCI, V33, P630, DOI 10.1021/ci00014a017; Smith JS, 2000, TOXICOL SCI, V55, P215, DOI 10.1093/toxsci/55.1.215; Smith PA, 2003, J MED CHEM, V46, P1617, DOI 10.1021/jm020397c; So SS, 1996, J MED CHEM, V39, P5246, DOI 10.1021/jm960536o; So SS, 1996, J MED CHEM, V39, P1521, DOI 10.1021/jm9507035; STONE M, 1990, J ROY STAT SOC B MET, V52, P237; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; Szantai-Kis C, 2006, CURR MED CHEM, V13, P277, DOI 10.2174/092986706775476098; TODESCHINI R, 1997, DRAGON TALETE SRL MI; Todeschini R., 2000, METHODS PRINCIPLES M; Todeschini R, 2004, ANAL CHIM ACTA, V515, P199, DOI 10.1016/j.aca.2003.12.010; TOPLISS JG, 1979, J MED CHEM, V22, P1238, DOI 10.1021/jm00196a017; TOPLISS JG, 1972, J MED CHEM, V15, P1066, DOI 10.1021/jm00280a017; Tsygankova IG, 2006, RUSS J GEN CHEM+, V76, P1618, DOI 10.1134/S1070363206100203; Ursu O, 2006, CROAT CHEM ACTA, V79, P483; VARNEK A, 2007, J CHEM INF MODEL, V47, P1123; Waller CL, 2004, J CHEM INF COMP SCI, V44, P758, DOI 10.1021/ci0342526; Waller CL, 1999, J CHEM INF COMP SCI, V39, P345, DOI 10.1021/ci980405r; WHILEY DC, 2000, J CHEM INF COMP SCI, V40, P1160; WIKEL JH, 1993, BIOORG MED CHEM LETT, V3, P645, DOI 10.1016/S0960-894X(01)81246-4; Wold H., 1966, MULTIVARIATE ANAL; Yasri A, 2001, J CHEM INF COMP SCI, V41, P1218, DOI 10.1021/ci010291a; Zefirov NS, 2001, J CHEM INF COMP SCI, V41, P1022, DOI 10.1021/ci0001637; Zupan J, 1999, ANAL CHIM ACTA, V388, P243, DOI 10.1016/S0003-2670(99)00079-3	101	12	12	4	10	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4099			CURR COMPUT-AID DRUG	Curr. Comput.-Aided Drug Des.	JUN	2008	4	2					132	142		10.2174/157340908784533238		11	Chemistry, Medicinal; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Computer Science	310ZS	WOS:000256570200005		
J	Yi, NJ; Xu, SH				Yi, Nengjun; Xu, Shizhong			Bayesian LASSO for quantitative trait loci mapping	GENETICS			English	Article							EXPERIMENTAL CROSSES; VARIABLE SELECTION; GENETIC VALUE; ENTIRE GENOME; REGRESSION; MARKERS; SHRINKAGE; PREDICTION; BARLEY; MODEL	The mapping of quantitative trait loci (QTL) is to identify molecular markers or genomic loci that influence the variation of complex traits. The problem is complicated by the facts that QTL data usually contain a large number of markers across the entire genome and most of them have little or no effect on the phenotype. In this article, we propose several Bayesian hierarchical models for mapping multiple QTL that simultaneously fit and estimate all possible genetic effects associated with all markers. The proposed models use prior distributions for the genetic effects that are scale mixtures of normal distributions with mean zero and variances distributed to give each effect a high probability of being near zero. We consider two types of priors for the variances, exponential and scaled inverse-chi(2) distributions, which result in a Bayesian version of the popular least absolute shrinkage and selection operator (LASSO) model and the well-known Student's I model, respectively. Unlike most applications where fixed values are preset for hyperparameters in the priors, we treat all hyperparameters as unknowns and estimate them along with other parameters. Markov chain Monte Carlo (MCMC) algorithms are developed to simulate the parameters from the posteriors. The methods are illustrated using well-known barley data.	[Yi, Nengjun] Univ Alabama Birmingham, Dept Biostat, Sect Stat Genet, Birmingham, AL 35294 USA; [Xu, Shizhong] Univ Calif Riverside, Dept Bot & Plant Sci, Riverside, CA 92521 USA	Yi, NJ (reprint author), Univ Alabama Birmingham, Dept Biostat, Sect Stat Genet, Birmingham, AL 35294 USA.	nyi@ms.soph.uab.edu					ANDREWS DF, 1974, J ROY STAT SOC B MET, V36, P99; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; LANDER ES, 1989, GENETICS, V121, P185; Kao CH, 1999, GENETICS, V152, P1203; Efron B, 2004, ANN STAT, V32, P407; Meuwissen THE, 2001, GENETICS, V157, P1819; Sturtz S, 2005, J STAT SOFTW, V12, P1; BAO K, 2004, BIOINFORMATICS, V20, P3423; Chhikara R. S., 1989, INVERSE GAUSSIAN DIS; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Foster SD, 2007, J AGR BIOL ENVIR ST, V12, P300, DOI 10.1198/108571107X200396; Gelman A, 2006, BAYESIAN ANAL, V1, P515; Gelman A, 2005, ANN STAT, V33, P1, DOI 10.1214/009053604000001048; Gelman A., 2003, BAYESIAN DATA ANAL; Gianola D, 2003, GENETICS, V163, P347; GRIFFIN JE, 2006, ALTERNATIVE PRIOR DI; HALEY CS, 1992, HEREDITY, V69, P315; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hoti F, 2006, HEREDITY, V97, P4, DOI 10.1038/sj.hdy.6800817; Huang H, 2007, GENETICS, V176, P2529, DOI 10.1534/genetics.106.064980; Jiang CJ, 1997, GENETICA, V101, P47, DOI 10.1023/A:1018394410659; PARK T, 2007, BAYESIAN LASSO; R Development Core Team, 2006, R LANG ENV STAT COMP; Sillanpaa MJ, 1998, GENETICS, V148, P1373; Sorensen D., 2002, LIKELIHOOD BAYESIAN; Spiegelhalter D., 2002, BUGS BAYESIAN INFERE; Tinker NA, 1996, CROP SCI, V36, P1053; Varona L., 2005, GENET RES, V88, P143; Wang H, 2005, GENETICS, V170, P465, DOI 10.1534/genetics.104.039354; Xu SZ, 2007, GENETICS, V175, P1955, DOI 10.1534/genetics.106.066571; Xu SZ, 2007, BIOMETRICS, V63, P513, DOI 10.1111/j.1541-0420.2006.00711.x; Xu SZ, 2003, GENETICS, V163, P789; Yandell BS, 2007, BIOINFORMATICS, V23, P641, DOI 10.1093/bioinformatics/btm011; Yang RQ, 2007, GENETICS, V176, P1169, DOI 10.1534/genetics.106.064279; Yi N, 2008, HEREDITY, V100, P240, DOI 10.1038/sj.hdy.6801074; Yi NJ, 2004, GENETICS, V167, P967, DOI 10.1534/genetics.104.026286; Yi NJ, 2005, GENETICS, V170, P1333, DOI 10.1534/genetics.104.040386; Yi NJ, 2003, GENETICS, V164, P1129; Yuan M, 2005, J AM STAT ASSOC, V100, P1215, DOI 10.1198/016214505000000367; Zhang M, 2005, GENETICS, V169, P2305, DOI 10.1534/genetics.104.034181; Zhang YM, 2005, HEREDITY, V95, P96, DOI 10.1038/sj.hdy.6800702	41	115	117	2	13	GENETICS SOC AM	BETHESDA	9650 ROCKVILLE AVE, BETHESDA, MD 20814 USA	1943-2631			GENETICS	Genetics	JUN	2008	179	2					1045	1055		10.1534/genetics.107.085589		11	Genetics & Heredity	Genetics & Heredity	315PV	WOS:000256892800029	18505874	
J	Parvaresh, F; Vikalo, H; Misra, S; Hassibi, B				Parvaresh, Farzad; Vikalo, Haris; Misra, Sidhant; Hassibi, Babak			Recovering Sparse Signals Using Sparse Measurement Matrices in Compressed DNA Microarrays	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING			English	Article						Compressive sampling; DNA microarrays; sparse measurements	GENE-EXPRESSION PATTERNS; ROBUST UNCERTAINTY PRINCIPLES; RANDOM PROJECTIONS; EXPANDER GRAPHS; HUMAN CANCER; RECONSTRUCTION; IDENTIFICATION; TECHNOLOGY; ARRAYS	Microarrays (DNA, protein, etc.) are massively parallel affinity-based biosensors capable of detecting and quantifying a large number of different genomic particles simultaneously. Among them, DNA microarrays comprising tens of thousands of probe spots are currently being employed to test multitude of targets in a single experiment. In conventional microarrays, each spot contains a large number of copies of a single probe designed to capture a single target, and, hence, collects only a single data point. This is a wasteful use of the sensing resources in comparative DNA microarray experiments, where a test sample is measured relative to a reference sample. Typically, only a fraction of the total number of genes represented by the two samples is differentially expressed, and, thus, a vast number of probe spots may not provide any useful information. To this end, we propose an alternative design, the so-called compressed microarrays, wherein each spot contains copies of several different probes and the total number of spots is potentially much smaller than the number of targets being tested. Fewer spots directly translates to significantly lower costs due to cheaper array manufacturing, simpler image acquisition and processing, and smaller amount of genomic material needed for experiments. To recover signals from compressed microarray measurements, we leverage ideas from compressive sampling. For sparse measurement matrices, we propose an algorithm that has significantly lower computational complexity than the widely used linear-programming-based methods, and can also recover signals with less sparsity.	[Parvaresh, Farzad] CALTECH, Ctr Math Informat, Pasadena, CA 91125 USA; [Vikalo, Haris] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78701 USA; [Misra, Sidhant] Indian Inst Technol, Kanpur 208016, Uttar Pradesh, India; [Hassibi, Babak] CALTECH, Dept Elect Engn, Pasadena, CA 91125 USA	Parvaresh, F (reprint author), CALTECH, Ctr Math Informat, Pasadena, CA 91125 USA.	farzad@caltech.edu; hvikalo@ece.utexas; hassibi@caltech.edu			California Institute of Technology; David and Lucille Packard Foundation; Millard and Muriel Jacobs Genetics and Genomics Laboratory	This work was supported in part by a Grubstake Award from California Institute of Technology, in part by grant from the David and Lucille Packard Foundation, and in part by the Millard and Muriel Jacobs Genetics and Genomics Laboratory at Caltech. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Ahmed Tewfik.	Afshari CA, 1999, CANCER RES, V59, P4759; Hoory S, 2006, B AM MATH SOC, V43, P439, DOI 10.1090/S0273-0979-06-01126-8; Kononen J, 1998, NAT MED, V4, P844, DOI 10.1038/nm0798-844; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Schena M, 1998, TRENDS BIOTECHNOL, V16, P301, DOI 10.1016/S0167-7799(98)01219-0; DeRisi J, 1996, NAT GENET, V14, P457; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Marx J, 2000, SCIENCE, V289, P1670, DOI 10.1126/science.289.5485.1670; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Shalon D, 1996, GENOME RES, V6, P639, DOI 10.1101/gr.6.7.639; Haupt J, 2006, IEEE T INFORM THEORY, V52, P4036, DOI 10.1109/TIT.2006.880031; Candes EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Schena M, 1996, P NATL ACAD SCI USA, V93, P10614, DOI 10.1073/pnas.93.20.10614; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Marton MJ, 1998, NAT MED, V4, P1293, DOI 10.1038/3282; Blanchard AP, 1996, NAT BIOTECHNOL, V14, P1649, DOI 10.1038/nbt1296-1649; Blanchard AP, 1996, BIOSENS BIOELECTRON, V11, P687, DOI 10.1016/0956-5663(96)83302-1; Candes E., 2004, P SPIE C, V5914; Candes E. J., 2006, INT C MATH MADR SPAI; Capalbo M., 2002, P 34 ANN ACM S THEOR, P659; Chen S., 1995, THESIS STANFORD U ST; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; CORMODE G, 2005, 200525 DIMACS TR; Cormode G., 2005, 200540 DIMACS TR; Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028; GILBERT A, 2006, P SPIE INTELLIGENT I; Khan J, 1999, ELECTROPHORESIS, V20, P223, DOI 10.1002/(SICI)1522-2683(19990201)20:2<223::AID-ELPS223>3.0.CO;2-A; LIPSON D, 2007, THESIS TECHNION ISRA; MARGULIS GA, 1973, PROBL INF TRANSM, V9, P84; Margulis G. A., 1988, Problems of Information Transmission, V24; Mueller U. R., 2005, MICROARRAY TECHNOLOG; PELEG D, 1989, COMBINATORICA, V9, P289, DOI 10.1007/BF02125897; PIQUEREGI R, 2007, P IEEE INT C AC SPEE, P353; SARVOTHAM S, 2006, IEEE S INF THEOR SEA; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Schena M., 2003, MICROARRAY ANAL; Sheikh M. A., 2007, P IEEE WORKSH STAT S, P215; SHMULEVICH I, 2003, NUCL ACID RES, V31; Shoemaker DD, 2001, NATURE, V409, P922, DOI 10.1038/35057141; Sipser M, 1996, IEEE T INFORM THEORY, V42, P1710, DOI 10.1109/18.556667; TROPP J, IEEE T INF IN PRESS; Tu Y, 2002, P NATL ACAD SCI USA, V99, P14031, DOI 10.1073/pnas.222164199; VIKALO H, 2006, IEEE INT C AC SPEECH; Vikalo H, 2006, IEEE T SIGNAL PROCES, V54, P2444, DOI 10.1109/TSP.2006.873716; Wainwright M., 2006, SHARP THRESHOLDS HIG; Xu W., 2007, P IEEE INF THEOR WOR; ZHANG W, 2002, COMPUTATIONAL STAT A	51	48	50	4	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1932-4553			IEEE J-STSP	IEEE J. Sel. Top. Signal Process.	JUN	2008	2	3					275	285		10.1109/JSTSP.2008.924384		11	Engineering, Electrical & Electronic	Engineering	437NW	WOS:000265495200003		
J	Ji, SH; Xue, Y; Carin, L				Ji, Shihao; Xue, Ya; Carin, Lawrence			Bayesian compressive sensing	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						adaptive compressive sensing; Bayesian model selection; compressive sensing (CS); experimental design; relevance vector machine (RVM); sparse Bayesian learning	VARIABLE SELECTION; INFORMATION; REGRESSION; EFFICIENT	The data of interest are assumed to be represented as N-dimensional real vectors, and these vectors are compressible in some linear basis B, implying that the signal can be reconstructed accurately using only a small number M << N of basis-function coefficients associated with B. Compressive sensing is a framework whereby one does not measure one of the aforementioned N-dimensional signals directly, but rather a set of related measurements, with the new measurements a linear combination of the original underlying N-dimensional signal. The number of required compressive-sensing measurements is typically much smaller than N, offering the potential to simplify the sensing system. Let f denote the unknown underlying N-dimensional signal, and g a vector of compressive-sensing measurements, then one may approximate f accurately by utilizing knowledge of the (under-determined) linear relationship between f and g, in addition to knowledge of the fact that f is compressible in B. In this paper we employ a Bayesian formalism for estimating the underlying signal f based on compressive-sensing measurements g. The proposed framework has the following properties: i) in addition to estimating the underlying signal f, "error bars" are also estimated, these giving a measure of confidence in the inverted signal; ii) using knowledge of the error bars, a principled means is provided for determining when a sufficient number of compressive-sensing measurements have been performed; iii) this setting lends itself naturally to a framework whereby the compressive sensing measurements are optimized adaptively and hence not determined randomly; and iv) the framework accounts for additive noise in the compressive-sensing measurements and provides an estimate of the noise variance. In this paper we present the underlying theory, an associated algorithm, example results, and provide comparisons to other compressive-sensing inversion algorithms in the literature.	[Ji, Shihao; Xue, Ya; Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Ji, SH (reprint author), Integrian Inc, Durham, NC 27703 USA.	shji@ee.duke.edu; yx10@ee.duke.edu; lcarin@ee.duke.edu					Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Haupt J, 2006, IEEE T INFORM THEORY, V52, P4036, DOI 10.1109/TIT.2006.880031; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150; Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI 10.1016/j.sigpro.2005.05.029; Efron B, 2004, ANN STAT, V32, P407; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; Bernardo J. M., 1994, BAYESIAN THEORY; Bishop C., 2000, P 16 C UNC ART INT, P46; CANDES EJ, IN PRESS ANN STAT; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Daubechies I., 1992, 10 LECT WAVELETS; Donoho D. L., 2006, SPARSE SOLUTION UNDE; Faul AC, 2002, ADV NEUR IN, V14, P383; Fedorov V. V., 1972, THEORY OPTIMAL EXPT; FIGUEIREDO M, 2002, ADV NEURAL INFORM PR, V14; Gelman A., 2003, BAYESIAN DATA ANAL; George EI, 2000, BIOMETRIKA, V87, P731, DOI 10.1093/biomet/87.4.731; George EI, 1997, STAT SINICA, V7, P339; Gilks W. R., 1996, MARKOV CHAIN MONTE C; Ji SH, 2006, IEEE T PATTERN ANAL, V28, P522; Mallat S., 1998, WAVELET TOUR SIGNAL; Papoulis A, 2002, PROBABILITY RANDOM V; Robert C. P., 2001, BAYESIAN CHOICE DECI; Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834; Tipping M. E., 2003, P 9 INT WORKSH ART I; Wipf D., 2005, ADV NEURAL INFORM PR, V17; Wipf D., 2004, ADV NEURAL INFORM PR, V16; WIPF D. P., 2006, ADV NEURAL INFORM PR	34	469	535	14	75	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-587X			IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	JUN	2008	56	6					2346	2356		10.1109/TSP.2007.914345		11	Engineering, Electrical & Electronic	Engineering	305BW	WOS:000256153800016		
J	Bach, FR				Bach, Francis R.			Consistency of trace norm minimization	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						convex optimization; singular value decomposition; trace norm; consistency	LASSO; REGRESSION; ASYMPTOTICS; SELECTION	Regularization by the sum of singular values, also referred to as the trace norm, is a popular technique for estimating low rank rectangular matrices. In this paper, we extend some of the consistency results of the Lasso to provide necessary and sufficient conditions for rank consistency of trace norm minimization with the square loss. We also provide an adaptive version that is rank consistent even when the necessary condition for the non adaptive version is not fulfilled.	Ecole Normale Super, CNRS INRIA UMR 8548, INRIA WILLOW Project Team, Lab Informat, F-75230 Paris, France	Bach, FR (reprint author), Ecole Normale Super, CNRS INRIA UMR 8548, INRIA WILLOW Project Team, Lab Informat, 45 Rue Ulm, F-75230 Paris, France.	francis.bach@mines.org					Abernethy J., 2006, N2406MM EC MIN PAR; ABERNETHY J, 2008, HAL00250231; Amit Y., 2007, P INT C MACH LEARN; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Bach FR, 2008, J MACH LEARN RES, V9, P1179; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; ARGYRIOU T, 2007, ADV NEURAL INFORM PR, V19; BACH FR, 2004, ADV NEURAL INFORM PR, V17; Bonnans J. F., 2003, NUMERICAL OPTIMIZATI; Borwein J. M., 2000, CMS BOOKS MATH, V3; Boyd S., 2003, CONVEX OPTIMIZATION; Fazel M., 2001, P AM CONTR C, V6, P4734, DOI 10.1109/ACC.2001.945730; GEYER CJ, 1996, ASYMPTOTICS CONVEX S; GEYER CJ, 1994, ANN STAT, V22, P1993, DOI 10.1214/aos/1176325768; Golub G., 1996, MATRIX COMPUTATIONS; HALL P, 1980, MARTINGALE LIMIT THE; Kato T., 1966, PERTURBATION THEORY; Lewis AS, 2001, SIAM J MATRIX ANAL A, V23, P368, DOI 10.1137/S089547980036838X; Lu Z., 2008, CONVEX OPTIMIZATION; Magnus J. R., 1998, MATRIX DIFFERENTIAL; MEINSHAUSEN N, 2006, 720 UC DPT STAT; Recht B., 2007, ARXIV07064138V1; Rennie J., 2005, P INT C MACH LEARN; Rudin W., 1987, REAL COMPLEX ANAL; Shao J., 2003, MATH STAT; Srebro N, 2005, ADV NEURAL INFORM PR, V17; Stewart G.W., 1990, MATRIX PERTURBATION; van der Vaart A. W., 1998, ASYMPTOTIC STAT; Yuan M, 2007, J ROY STAT SOC B, V69, P329, DOI 10.1111/j.1467-9868.2007.00591.x	34	36	36	1	4	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2008	9						1019	1048				30	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	340LE	WOS:000258646300003		
J	Bach, FR				Bach, Francis R.			Consistency of the group Lasso and multiple kernel learning	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						sparsity; regularization; consistency; convex optimization; covariance operators	MODEL SELECTION; REGRESSION	We consider the least-square regression problem with regularization by a block l(1)-norm, that is, a sum of Euclidean norms over spaces of dimensions larger than one. This problem, referred to as the group Lasso, extends the usual regularization by the l(1)-norm where all spaces have dimension one, where it is commonly referred to as the Lasso. In this paper, we study the asymptotic group selection consistency of the group Lasso. We derive necessary and sufficient conditions for the consistency of group Lasso under practical assumptions, such as model misspecification. When the linear predictors and Euclidean norms are replaced by functions and reproducing kernel Hilbert norms, the problem is usually referred to as multiple kernel learning and is commonly used for learning from heterogeneous data sources and for non linear variable selection. Using tools from functional analysis, and in particular covariance operators, we extend the consistency results to this infinite dimensional case and also propose an adaptive scheme to obtain a consistent model estimate, even when the necessary condition required for the non adaptive scheme is not satisfied.	Ecole Normale Super, CNRS ENS INRIA UMR 8548, Lab Informat, F-75230 Paris, France	Bach, FR (reprint author), Ecole Normale Super, CNRS ENS INRIA UMR 8548, Lab Informat, 45 Rue Ulm, F-75230 Paris, France.	francis.bach@mines.org					Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; McAuley J, 2005, IEEE T SPEECH AUDI P, V13, P956, DOI 10.1109/TSA.2005.851952; Fukumizu K, 2004, J MACH LEARN RES, V5, P73; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; Gretton A, 2005, J MACH LEARN RES, V6, P2075; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Cucker F, 2002, B AM MATH SOC, V39, P1; Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294; Wu Q, 2007, J COMPLEXITY, V23, P108, DOI 10.1016/j.jco.2006.06.007; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; Bach F., 2008, P INT C MACH LEARN I; Bach FR, 2008, J MACH LEARN RES, V9, P1019; BACH FR, 2004, ADV NEURAL INFORM PR, V17; BACH FR, 2004, P INT C MACH LEARN I; BAKER CR, 1973, T AM MATH SOC, V186, P273, DOI 10.2307/1996566; Berlinet A., 2003, REPRODUCING K HILBER; BOUSQUET O, 2003, ADV NEURAL INFORM PR, V17; Boyd S., 2003, CONVEX OPTIMIZATION; Bremaud P., 1999, MARKOV CHAINS GIBBS; BREZIS H, 1980, ANAL FONCTIONELLE; Caponnetto A., 2005, 248AI CBCL MIT, P2005; Durrett R., 2004, PROBABILITY THEORY E; FUKUMIZU K, 2007, J MACHINE LEARNING R, V8; HARCHAOUI Z, 2007, P C COMP VIS PATT RE; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODELS; Juditsky A, 2000, ANN STAT, V28, P681; MEIER L, 2006, 131 ETH; MEINSHAUSEN N, 2006, 720 UC DEP STAT; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; RAKOTOMAMONJY A, 2007, P INT C MACH LEARN I; Ravikumar P., 2008, ADV NEURAL INFORM PR, V22; RENYI A., 1959, ACTA MATH ACAD SCI H, V10, P441, DOI DOI 10.1007/BF02024507; Scholkopf B., 2001, LEARNING KERNELS; Steinwart I., 2001, J MACHINE LEARNING R, V2, P67, DOI 10.1162/153244302760185252; Tikhonov A. N., 1997, SOLUTIONS ILL POSED; van der Vaart A. W., 1998, ASYMPTOTIC STAT; VARMA M, 2007, P IEEE INT C COMP VI; Wahba G., 1990, SPLINE MODELS OBSERV; WAINWRIGHT MJ, 2006, 709 UC DEP STAT; ZHOU D, 2007, P INT C MACH LEARN I; Zhu H., 1998, NEURAL NETWORKS MACH	48	150	157	2	11	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2008	9						1179	1225				47	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	340LE	WOS:000258646300008		
J	Kesari, S; Kim, RS; Markos, V; Drappatz, J; Wen, PY; Pruitt, AA				Kesari, Santosh; Kim, Ryung S.; Markos, Vassilios; Drappatz, Jan; Wen, Patrick Y.; Pruitt, Amy A.			Prognostic factors in adult brainstem gliomas: a multicenter, retrospective analysis of 101 cases	JOURNAL OF NEURO-ONCOLOGY			English	Article						brainstem glioma; natural history; chemotherapy; radiation; surgery; prognostic factors	CHILDRENS CANCER GROUP; TUMORS; MANAGEMENT; ASTROCYTOMA; CHILDHOOD; DIAGNOSIS; SELECTION; THERAPY; LASSO	Background Adult brainstem gliomas (BSG) are uncommon and poorly understood with respect to prognostic factors. We retrospectively evaluated the clinical, radiographic, histologic, and treatment features from 101 adults with presumed or biopsy proven BSG to determine prognostic factors. Patients and Methods We reviewed the records of patients diagnosed from 1987-2005. We used Cox proportional hazard models to determine prognostic factors. Results These 50 male and 51 female patients ranged in age from 18 to 79 years at diagnosis (median 36 years) with follow-ups from I to 261 months (median 47 months). The overall survival for all patients at 5 and 10 years was 58% and 41%, respectively, with a median survival of 85 months (range 1-228). Out of 24 candidate prognosis factors, we selected seven covariates for proportional hazards model by Lasso procedure: age of diagnosis, ethnicity, need for corticosteroids, tumor grade, dysphagia, tumor location, and karnofsky performance status (KPS). Univariate analysis showed that these seven factors are significantly associated with survival. Multivariate analysis showed that four covariates significantly increased hazard for survival: ethnicity, tumor location, age of diagnosis, and tumor grade. Conclusions In this study, we identified four prognostic factors that were significantly associated with survival in adults with BSGs. Overall, these patients have a better prognosis than children with BSGs reported in the literature. These results call for larger prospective studies to fully assess the importance of these factors in the clinical setting and to help stratify patients in future clinical studies.	[Kesari, Santosh; Markos, Vassilios; Drappatz, Jan; Wen, Patrick Y.] Dana Farber Brigham & Womens Canc Ctr, Ctr Neurooncol, Boston, MA 02115 USA; [Kesari, Santosh; Drappatz, Jan; Wen, Patrick Y.] Brigham & Womens Hosp, Dept Neurol, Div Canc Neurol, Boston, MA 02115 USA; [Kesari, Santosh; Drappatz, Jan; Wen, Patrick Y.] Harvard Univ, Sch Med, Boston, MA 02115 USA; [Kim, Ryung S.] Worcester Polytech Inst, Dept Math Sci, Worcester, MA 01602 USA; [Markos, Vassilios] Univ Gen Hosp, Dept Med Oncol, Iraklion, Greece; [Pruitt, Amy A.] Univ Penn, Med Ctr, Dept Neurol, Hosp Univ Penn, Philadelphia, PA 19104 USA	Kesari, S (reprint author), Dana Farber Brigham & Womens Canc Ctr, Ctr Neurooncol, SW430,44 Binney St, Boston, MA 02115 USA.	skesari@partners.org	Kesari, Santosh/E-8461-2013				ALBRIGHT AL, 1986, J NEUROSURG, V65, P751, DOI 10.3171/jns.1986.65.6.0751; ALBRIGHT AL, 1993, NEUROSURGERY, V33, P1026; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Jallo GI, 2004, CHILD NERV SYST, V20, P143, DOI 10.1007/s00381-003-0870-6; Donaldson SS, 2006, J CLIN ONCOL, V24, P1266, DOI 10.1200/JCO.2005.04.6599; Mauffrey C, 2006, J CLIN NEUROSCI, V13, P431, DOI 10.1016/j.jocn.2005.05.015; Abbott R, 1996, PEDIATR NEUROSURG, V25, P41, DOI 10.1159/000121095; BARKOVICH A J, 1990, Pediatric Neurosurgery, V16, P73, DOI 10.1159/000120511; BERGER MS, 1983, NEUROSURGERY, V12, P298; COHEN ME, 1986, NEUROLOGY, V36, P602; Farmer JP, 2001, PEDIATR NEUROSURG, V34, P206, DOI 10.1159/000056021; Fincher C, 2004, ETHNIC DIS, V14, P360; Grambsch P M, 1995, Cancer Treat Res, V75, P95; GRIGSBY PW, 1989, CANCER, V63, P2124, DOI 10.1002/1097-0142(19890601)63:11<2124::AID-CNCR2820631109>3.0.CO;2-9; Guillamo JS, 2001, BRAIN, V124, P2528, DOI 10.1093/brain/124.12.2528; GUINEY MJ, 1993, INT J RADIAT ONCOL, V25, P235; Hastie T, 2003, ELEMENTS STAT LEARNI; HOFFMAN HJ, 1980, NEUROSURGERY, V7, P243; Kansal Somil, 1999, Indian Journal of Cancer, V36, P99; Kaplan AM, 1996, PEDIATR NEUROSURG, V24, P185, DOI 10.1159/000121036; Khwaja FW, 2007, J PROTEOME RES, V6, P559, DOI 10.1021/pr060240z; Landolfi JC, 1998, NEUROLOGY, V51, P1136; LAWS ER, 1984, J NEUROSURG, V61, P665, DOI 10.3171/jns.1984.61.4.0665; LEE BCP, 1985, AM J NEURORADIOL, V6, P159; LINSTADT DE, 1991, INT J RADIAT ONCOL, V20, P757; LITTMAN P, 1980, CANCER, V45, P2787, DOI 10.1002/1097-0142(19800601)45:11<2787::AID-CNCR2820451113>3.0.CO;2-V; MAHALEY MS, 1989, J NEUROSURG, V71, P826, DOI 10.3171/jns.1989.71.6.0826; MANTRAVADI RVP, 1982, CANCER, V49, P1294, DOI 10.1002/1097-0142(19820315)49:6<1294::AID-CNCR2820490636>3.0.CO;2-V; PACKER RJ, 1985, NEUROLOGY, V35, P397; PANITCH HS, 1970, AM J DIS CHILD, V119, P465; PARK M, 2006, LI REGULARIZATION PA; POLLACK IF, 1993, J NEUROSURG, V78, P859, DOI 10.3171/jns.1993.78.6.0859; Selvapandian S, 1999, ACTA NEUROCHIR, V141, P721, DOI 10.1007/s007010050367; SHRIEVE DC, 1992, INT J RADIAT ONCOL, V24, P599; STECK J, 1995, SURG NEUROL, V43, P563, DOI 10.1016/0090-3019(95)00156-5; Takasato Yoshio, 1993, Neurologia Medico-Chirurgica, V33, P625, DOI 10.2176/nmc.33.625; Team RDC, 2006, R LANG ENV STAT COMP; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; TOKURIKI Y, 1986, ACTA NEUROCHIR, V79, P67, DOI 10.1007/BF01407447; Venables WN, 2002, MODERN APPL STAT S; Zimmerman RA, 1996, PEDIATR NEUROSURG, V25, P45, DOI 10.1159/000121096	41	29	33	1	1	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0167-594X			J NEURO-ONCOL	J. Neuro-Oncol.	JUN	2008	88	2					175	183		10.1007/s11060-008-9545-1		9	Oncology; Clinical Neurology	Oncology; Neurosciences & Neurology	307IS	WOS:000256313200007	18365144	
J	Inoue, A; Kilian, L				Inoue, Atsushi; Kilian, Lutz			How useful is bagging in forecasting economic time series? A case study of US consumer price inflation	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						Bayesian model averaging; bootstrap aggregation; factor model; forecast combination; forecasting model selection; pre testing; shrinkage estimation	CONSISTENT COVARIANCE-MATRIX; STOCK RETURN PREDICTABILITY; DYNAMIC-FACTOR MODEL; HETEROSKEDASTICITY-CONSISTENT; EURO AREA; SELECTION; REGRESSION; AUTOREGRESSIONS; UNCERTAINTY; PREDICTORS	This article focuses on the widely studied question of whether the inclusion of indicators of real economic activity lowers the prediction mean squared error of forecasting models of U.S. consumer price inflation. We propose three variants of the bagging algorithm specifically designed for this type of forecasting problem and evaluate their empirical performance. Although bagging predictors in our application are clearly more accurate than equally weighted forecasts, median forecasts, ARM forecasts, AFTER forecasts, or Bayesian forecast averages based on one extra predictor at a time, they are generally about as accurate as the Bayesian shrinkage predictor, the ridge regression predictor, the iterated LASSO predictor, or the Bayesian model average predictor based on random subsets of extra predictors. Our results show that bagging can achieve large reductions in prediction mean-squared errors even in such challenging applications as inflation forecasting; however, bagging is not the only method capable of achieving such gains.	[Inoue, Atsushi] Univ British Columbia, Dept Econ, Vancouver, BC V6T 1Z1, Canada; [Inoue, Atsushi] N Carolina State Univ, Dept Agr & Resource Econ, Raleigh, NC 27695 USA; [Kilian, Lutz] Univ Michigan, Dept Econ, Ann Arbor, MI 48109 USA	Inoue, A (reprint author), Univ British Columbia, Dept Econ, Vancouver, BC V6T 1Z1, Canada.	ainoue@interchange.ubc.ca; lkilian@umich.edu					Yang YH, 2003, STAT SINICA, V13, P783; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; NEWEY WK, 1987, ECONOMETRICA, V55, P703, DOI 10.2307/1913610; Forni M, 2003, J MONETARY ECON, V50, P1243, DOI 10.1016/S0304-3932(03)00079-5; WHITE H, 1980, ECONOMETRICA, V48, P817, DOI 10.2307/1912934; Stock JH, 2002, J AM STAT ASSOC, V97, P1167, DOI 10.1198/016214502388618960; Raftery AE, 1997, J AM STAT ASSOC, V92, P179, DOI 10.2307/2291462; Goncalves S, 2004, J ECONOMETRICS, V123, P89, DOI 10.1016/j.jeconom.2003.10.030; Stock JH, 2002, J BUS ECON STAT, V20, P147, DOI 10.1198/073500102317351921; Inoue A, 2006, J ECONOMETRICS, V130, P273, DOI 10.1016/j.jeconom.2005.03.003; Stock JH, 2003, J ECON LIT, V41, P788, DOI 10.1257/002205103322436197; Bernanke BS, 2003, J MONETARY ECON, V50, P525, DOI 10.1016/S0304-3932(03)00024-2; Yang YH, 2004, ECONOMET THEOR, V20, P176, DOI 10.1017/S0266466604201086; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Forni M, 2005, J AM STAT ASSOC, V100, P830, DOI 10.1198/016214504000002050; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; BATES JM, 1969, OPER RES QUART, V20, P451, DOI 10.2307/3008764; Forni M, 2000, REV ECON STAT, V82, P540, DOI 10.1162/003465300559037; Avramov D, 2002, J FINANC ECON, V64, P423, DOI 10.1016/S0304-405X(02)00131-9; Breiman L., 1996, MACH LEARN, V36, P105; Buhlmann P, 2002, ANN STAT, V30, P927; CECCHETTI S, 2000, FEDERAL RESERVE BANK, V6, P1; Cremers KJM, 2002, REV FINANC STUD, V15, P1223, DOI 10.1093/rfs/15.4.1223; EDELSTEIN P, 2006, COMMODITY PRIC UNPUB; Goncalves S, 2004, J ECONOMETRICS, V119, P199, DOI 10.1016/S0304-4076(03)00204-5; Hall P, 1996, ECONOMETRICA, V64, P891, DOI 10.2307/2171849; Inoue A, 2006, J ECONOMETRICS, V133, P531, DOI 10.1016/j.jeconom.2005.06.004; Koop G., 2004, ECONOMET J, V7, P550, DOI DOI 10.1111/J.1368-423X.2004.00143.X; Lee TH, 2006, J ECONOMETRICS, V135, P465, DOI 10.1016/j.jeconom.2005.07.017; LITTERMAN RB, 1986, J BUS ECON STAT, V4, P25, DOI 10.2307/1391384; Lutkepohl H., 1993, INTRO MULTIPLE TIME; Marcellino M, 2003, EUR ECON REV, V47, P1, DOI 10.1016/S0014-2921(02)00206-4; MIN CK, 1993, J ECONOMETRICS, V56, P89, DOI 10.1016/0304-4076(93)90102-B; Romano J., 1999, SUBSAMPLING; Stock JH, 1999, J MONETARY ECON, V44, P293, DOI 10.1016/S0304-3932(99)00027-6; STOCK JH, 2006, SHRINKAGE METH UNPUB; West KD, 1997, J ECONOMETRICS, V76, P171, DOI 10.1016/0304-4076(95)01788-7; WRIGHT JH, 2003, INT FINANCE DISCUSSI, V780; WRIGHT JH, 2003, INT FINANCE DISCUSSI, V779; Yang YH, 2001, J AM STAT ASSOC, V96, P574, DOI 10.1198/016214501753168262	40	27	27	6	11	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	JUN	2008	103	482					511	522		10.1198/016214507000000473		12	Statistics & Probability	Mathematics	329VA	WOS:000257897500010		
J	Johnson, BA; Lin, DY; Zeng, DL				Johnson, Brent A.; Lin, D. Y.; Zeng, Donglin			Penalized estimating functions and variable selection in semiparametric regression models	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						accelerated failure time model; Buckley-James estimator; censoring; least absolute shrinkage and selection operator; least squares; linear regression; missing data; smoothly clipped absolute deviation	LONGITUDINAL DATA-ANALYSIS; RIGHT-CENSORED DATA; LINEAR RANK-TESTS; ORACLE PROPERTIES; LARGE-SAMPLE; LASSO	We propose a general strategy for variable selection in semiparametric regression models by penalizing appropriate estimating functions. Important applications include semiparametric linear regression with censored responses and semiparametric regression with missing predictors. Unlike the existing penalized maximum likelihood estimators, the proposed penalized estimating functions may not pertain to the derivatives of any objective functions and may be discrete in the regression coefficients. We establish a general asymptotic theory for penalized estimating functions and present suitable numerical algorithms to implement the proposed estimators. In addition, we develop a resampling technique to estimate the variances of the estimated regression coefficients when the asymptotic variances cannot be evaluated directly. Simulation studies demonstrate that the proposed methods perform well in variable selection and variance estimation. We illustrate our methods using data from the Paul Coverdell Stroke Registry.	[Johnson, Brent A.] Emory Univ, Dept Biostat, Atlanta, GA 30322 USA; [Lin, D. Y.; Zeng, Donglin] Univ N Carolina, Dept Biostat, Chapel Hill, NC 27599 USA	Johnson, BA (reprint author), Emory Univ, Dept Biostat, Atlanta, GA 30322 USA.	bajohn3@emory.edu; lin@bios.unc.edu; dzeng@bios.unc.edu					ROBINS JM, 1994, J AM STAT ASSOC, V89, P846, DOI 10.2307/2290910; LIN JS, 1992, J AM STAT ASSOC, V87, P1091, DOI 10.2307/2290646; LIANG KY, 1986, BIOMETRIKA, V73, P13, DOI 10.1093/biomet/73.1.13; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; LAI TL, 1991, ANN STAT, V19, P531, DOI 10.1214/aos/1176348110; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; BUCKLEY J, 1979, BIOMETRIKA, V66, P429; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Cai JW, 2005, BIOMETRIKA, V92, P303, DOI 10.1093/biomet/92.2.303; COX DR, 1972, J R STAT SOC B, V34, P187; Fan JQ, 2002, ANN STAT, V30, P74; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; Fu W. J., 2003, BIOMETRICS, V35, P109; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Johnson BA, 2008, J ROY STAT SOC B, V70, P351, DOI 10.1111/j.1467-9868.2008.00639.x; LAI TL, 1991, ANN STAT, V19, P1370, DOI 10.1214/aos/1176348253; Lin DY, 2001, J AM STAT ASSOC, V96, P103, DOI 10.1198/016214501750333018; Prentice R. L., 2002, STAT ANAL FAILURE TI; PRENTICE RL, 1978, BIOMETRIKA, V65, P167, DOI 10.1093/biomet/65.1.167; Arora S, 2005, STROKE, V36, P1232, DOI 10.1161/01.STR.0000165902.18021.5b; RITOV Y, 1990, ANN STAT, V18, P303, DOI 10.1214/aos/1176347502; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; TSIATIS A. A., 2006, SEMIPARAMETRIC THEOR; TSIATIS AA, 1990, ANN STAT, V18, P354, DOI 10.1214/aos/1176347504; Van der Vaart A., 1996, WEAK CONVERGENCE EMP; WAHBA G, 1985, ANN STAT, V13, P1378, DOI 10.1214/aos/1176349743; WEI LJ, 1990, BIOMETRIKA, V77, P845, DOI 10.1093/biomet/77.4.845; YING ZL, 1993, ANN STAT, V21, P76, DOI 10.1214/aos/1176349016	32	44	45	2	10	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	JUN	2008	103	482					672	680		10.1198/016214508000000184		9	Statistics & Probability	Mathematics	329VA	WOS:000257897500024		
J	Park, T; Casella, G				Park, Trevor; Casella, George			The Bayesian Lasso	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						empirical Bayes; Gibbs sampler; hierarchical model; inverse Gaussian; linear regression; penalized regression; scale mixture of normals	LEAST ANGLE REGRESSION; VARIABLE SELECTION; SCALE MIXTURES; NORMAL-DISTRIBUTIONS; MODELS	The Lasso estimate for linear regression parameters can be interpreted as a Bayesian posterior mode estimate when the regression parameters have independent Laplace (i.e., double-exponential) priors. Gibbs sampling from this posterior is possible using an expanded hierarchy with conjugate normal priors for the regression parameters and independent exponential priors on their variances. A connection with the inverse-Gaussian distribution provides tractable full conditional distributions. The Bayesian Lasso provides interval estimates (Bayesian credible intervals) that can guide variable selection. Moreover, the structure of the hierarchical model provides both Bayesian and likelihood methods for selecting the Lasso parameter. Slight modifications lead to Bayesian versions of other Lasso-related estimation methods, including bridge regression and a robust variant.	[Park, Trevor; Casella, George] Univ Florida, Dept Stat, Gainesville, FL 32611 USA	Park, T (reprint author), Univ Florida, Dept Stat, Gainesville, FL 32611 USA.	tpark@stat.ufl.edu; casella@stat.ufl.edu					ANDREWS DF, 1974, J ROY STAT SOC B MET, V36, P99; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Efron B, 2004, ANN STAT, V32, P407; ATKINSON AC, 1982, SIAM J SCI STAT COMP, V3, P502, DOI 10.1137/0903033; Bae K, 2004, BIOINFORMATICS, V20, P3423, DOI 10.1093/bioinformatics/bth419; Casella G, 2001, Biostatistics, V2, P485, DOI 10.1093/biostatistics/2.4.485; Chhikara R. S., 1989, INVERSE GAUSSIAN DIS; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Gneiting T, 1997, J STAT COMPUT SIM, V59, P375, DOI 10.1080/00949659708811867; Hastie T., 2001, ELEMENTS STAT LEARNI; JORGENSEN B, 1987, J ROY STAT SOC B MET, V49, P127; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Rosset S, 2004, ANN STAT, V32, P469; WEST M, 1984, J ROY STAT SOC B MET, V46, P431; WEST M, 1987, BIOMETRIKA, V74, P646, DOI 10.1093/biomet/74.3.646; Yuan M, 2005, J AM STAT ASSOC, V100, P1215, DOI 10.1198/016214505000000367	21	397	401	8	31	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	JUN	2008	103	482					681	686		10.1198/016214508000000337		6	Statistics & Probability	Mathematics	329VA	WOS:000257897500025		
J	Nielsen, AB; Hansen, LK				Nielsen, Andreas Brinch; Hansen, Lars Kai			Structure learning by pruning in independent component analysis	NEUROCOMPUTING			English	Article						independent component analysis; pruning; structure; sparsity	BLIND SEPARATION; NEURAL NETWORKS	We discuss pruning as a means of structure learning in independent component analysis (ICA). Learning the structure is attractive in both signal processing and in analysis of abstract data, where it can assist model interpretation, generalizability and reduce computation. We derive the relevant saliency expressions and compare with magnitude based pruning and Bayesian sparsification. We show in simulations that pruning is able to identify underlying structures without prior knowledge on the dimensionality of the model. We find, that for ICA, magnitude based pruning is as efficient as saliency based methods and Bayesian methods, for both small and large samples. The Bayesian information criterion (BIC) seems to outperform both AIC and test sets as tools for determining the optimal dimensionality. (C) 2008 Elsevier B.V. All rights reserved.	[Nielsen, Andreas Brinch; Hansen, Lars Kai] Tech Univ Denmark, DK-2800 Lyngby, Denmark	Nielsen, AB (reprint author), Tech Univ Denmark, DK-2800 Lyngby, Denmark.	abn@imm.dtu.dk; lkh@imm.dtu.dk					AKAIKE H, 1993, BREAKTHROUGHS STAT, V1, P610; Tenenbaum JB, 2000, ADV NEUR IN, V12, P59; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hojen-Sorensen PADFR, 2002, NEURAL COMPUT, V14, P889, DOI 10.1162/089976602317319009; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Bishop CM, 1996, NEURAL NETWORKS PATT; Bronstein AM, 2005, INT J IMAG SYST TECH, V15, P84, DOI 10.1002/ima.20042; Cardoso JF, 1997, IEEE SIGNAL PROC LET, V4, P112, DOI 10.1109/97.566704; Gorodkin J, 1997, Int J Neural Syst, V8, P489, DOI 10.1142/S0129065797000471; Gorodkin J, 1993, Int J Neural Syst, V4, P159, DOI 10.1142/S0129065793000146; Goutte C, 1997, NEURAL NETWORKS, V10, P1053, DOI 10.1016/S0893-6080(97)00027-0; GOUTTE C, 1996, NEURAL NETWORKS SIGN, V6, P52; HANSEN LK, 2001, IEEE INT C AC SPEECH, V5, P3197; Hansen L.K., 1994, NEURAL COMPUT, V6, P1222; Hassibi B., 1993, ADV NEURAL INFORMATI, V5, P164; HE Z, 2006, INDEPENDENT COMPONEN, P164; Hoyer PO, 2006, LECT NOTES COMPUT SC, V3889, P115; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Kaashoek JF, 2002, J FORECASTING, V21, P559, DOI 10.1002/for.835; Le Cun Y., 1990, ADV NEURAL INFORMATI, V2, P598; NIELSEN HB, 2006, MATLAB TOOLBOX OPTIM; Park HM, 2006, LECT NOTES COMPUT SC, V3889, P658; PEDERSEN MS, 2005, IEEE INT C AC SPEECH, V5, P297; Pedersen MW, 1996, ADV NEUR IN, V8, P521; RAGG T, 1997, INT C ART NEUR NETW; ROSCA JP, 2006, LECT NOTES COMPUTER, V3889; Shimizu S., 2005, P 21 ANN C UNC ART I, P525; Thodberg H. H., 1991, International Journal of Neural Systems, V1, DOI 10.1142/S0129065791000352; Thodberg HH, 1996, IEEE T NEURAL NETWOR, V7, P56, DOI 10.1109/72.478392	32	7	7	0	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	JUN	2008	71	10-12					2281	2290		10.1016/j.neucom.2007.09.016		10	Computer Science, Artificial Intelligence	Computer Science	322ZH	WOS:000257413300046		
J	Tian, GL; Ng, KW; Tan, M				Tian, Guo-Liang; Ng, Kai Wang; Tan, Ming			EM-type algorithms for computing restricted MLEs in multivariate normal distributions and multivariate t-distributions	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							MAXIMUM-LIKELIHOOD-ESTIMATION; LINEAR INVERSE PROBLEMS; DUAL BASES ALGORITHM; ORDER RESTRICTIONS; CONSTRAINED PARAMETER; ISOTONIC REGRESSION; ECM ALGORITHM; RECONSTRUCTION; MODELS; CONVERGENCE	Constrained parameter problems arise in a variety of statistical applications but they have been most resistant to solution. This paper proposes methodology for estimating restricted parameters in multivariate normal distributions with known or unknown covariance matrix. The proposed method thus provides a solution to an open problem to find penalized estimation for linear inverse problem with positivity restrictions [Vardi, Y., Lee, D. 1993. From image deblurring to optimal investments: Maximum likelihood solutions for positive linear inverse problems (with discussion). journal of the Royal Statistical Society, Series B 55,569-6121. By first considering the simplest bound constraints and then generalizing them to linear inequality constraints, we propose a unified EM-type algorithm for estimating constrained parameters via data augmentation. The key idea is to introduce a sequence of latent variables such that the complete-data model belongs to the exponential family, hence, resulting in a simple E-step and an explicit M-step. Furthermore, we extend restricted multivariate normal distribution to multivariate t-distribution with constrained parameters to obtain robust estimation. With the proposed algorithms, standard errors can be calculated by bootstrapping. The proposed method is appealing for its simplicity and ease of implementation and its applicability to a wide class of parameter restrictions. Three real data sets are analyzed to illustrate different aspects of the proposed methods. Finally, the proposed algorithm is applied to linear inverse problems with possible negativity restrictions and is evaluated numerically. (C) 2008 Elsevier B.V. All rights reserved.	[Tian, Guo-Liang; Tan, Ming] Univ Maryland, Greenebaum Canc Ctr, Div Biostat, Baltimore, MD 21201 USA; [Ng, Kai Wang] Univ Hong Kong, Dept Stat & Actuarial Sci, Hong Kong, Hong Kong, Peoples R China	Tian, GL (reprint author), Univ Maryland, Greenebaum Canc Ctr, Div Biostat, MSTF Suite 261,10 S Pine St, Baltimore, MD 21201 USA.	gtian2@umm.edu	Tian, Guoliang/D-3128-2009; Ng, Kai Wang/D-3114-2009				Agresti A., 1984, ANAL ORDINAL CATEGOR; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; RUBIN DB, 1982, PSYCHOMETRIKA, V47, P69, DOI 10.1007/BF02293851; LANGE KL, 1989, J AM STAT ASSOC, V84, P881, DOI 10.2307/2290063; Meng XL, 1997, J ROY STAT SOC B MET, V59, P511, DOI 10.1111/1467-9868.00082; ARCHER GEB, 1995, STAT SINICA, V5, P77; BARLOW R. E., 1972, STAT INFERENCE ORDER; BARLOW RE, 1972, J AM STAT ASSOC, V67, P140, DOI 10.2307/2284712; Broffitt J. D., 1984, SCAND ACTUAR J, V4, P231; Broffitt J.D., 1988, T SOC ACTUARIES, V40, P115; CALVIN JA, 1991, ANN STAT, V19, P850, DOI 10.1214/aos/1176348124; CARLIN BP, 1992, APPL STAT-J ROY ST C, V41, P389, DOI 10.2307/2347570; CHEN M, 2000, M CARLO METHODS BAYE; Chen MingHui, 1996, Journal of Agricultural, Biological, and Environmental Statistics, V1, P467, DOI 10.2307/1400440; CHIU HY, 1986, J AM STAT ASSOC, V81, P667, DOI 10.2307/2288994; Cox D. R., 1989, ANAL BINARY DATA; DAUBEWITHERSPOON ME, 1986, IEEE T MED IMAGING, V5, P61, DOI 10.1109/TMI.1986.4307748; Dempster A. P., 1980, MULTIVARIATE ANAL, P35; DYKSTRA RL, 1983, J AM STAT ASSOC, V78, P837, DOI 10.2307/2288193; DYKSTRA RL, 1982, ANN STAT, V10, P708, DOI 10.1214/aos/1176345866; FRASER DAS, 1989, SCAND J STAT, V16, P65; Gasparini M, 2000, BIOMETRICS, V56, P609, DOI 10.1111/j.0006-341X.2000.00609.x; GELFAND AE, 1992, J AM STAT ASSOC, V87, P523, DOI 10.2307/2290286; Gelman A, 1996, STAT SINICA, V6, P215; GEYER CJ, 1991, J AM STAT ASSOC, V86, P717, DOI 10.2307/2290403; Hajivassiliou VA, 1998, ECONOMETRICA, V66, P863, DOI 10.2307/2999576; HWANG JTG, 1994, ANN STAT, V22, P67, DOI 10.1214/aos/1176325358; KENT JT, 1993, J ROYAL STAT SOC B, V55, P599; Little R., 2002, STAT ANAL MISSING DA; LITTLE RJA, 1988, APPL STAT-J ROY ST C, V37, P23, DOI 10.2307/2347491; Liu CH, 2000, J AM STAT ASSOC, V95, P109, DOI 10.2307/2669531; LIU CH, 1995, STAT SINICA, V5, P19; Liu CH, 1997, J MULTIVARIATE ANAL, V63, P296, DOI 10.1006/jmva.1997.1703; LIU CH, 1994, BIOMETRIKA, V81, P633; Louis T. A., 1982, J R STAT SOC B, V44, P98; Luther H. A., 1969, APPL NUMERICAL METHO; MAJUMDER PP, 1998, ENCY BIOSTATISTICS, P73; MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.2307/2337198; Meyer MC, 1999, J STAT PLAN INFER, V81, P13, DOI 10.1016/S0378-3758(99)00025-7; Nettleton D, 1999, CAN J STAT, V27, P639, DOI 10.2307/3316118; PAWITAN Y, 1993, J ROYAL STAT SOC B, V55, P606; Pinheiro JC, 2001, J COMPUT GRAPH STAT, V10, P249, DOI 10.1198/10618600152628059; RAMGOPAL P, 1993, BIOMETRIKA, V80, P489, DOI 10.1093/biomet/80.3.489; Robertson T, 1988, ORDER RESTRICTED STA; Rubin D. B., 1983, ENCY STATISTICAL SCI, V4, P272; SCHMOYER RL, 1984, J AM STAT ASSOC, V79, P448, DOI 10.2307/2288289; SCHOENFELD DA, 1986, J AM STAT ASSOC, V81, P186, DOI 10.2307/2287988; SHAKED M, 1990, ANN I STAT MATH, V42, P1, DOI 10.1007/BF00050775; Shi NZ, 2005, J MULTIVARIATE ANAL, V92, P53, DOI 10.1016/S0047-259X(03)00134-9; Silvapulle M. J., 2004, CONSTRAINED STAT INF; TAN M, 2003, DEV MODERN STAT RELA, P53; Tan Ming, 2005, Statistics in Medicine, V24, P109, DOI 10.1002/sim.1775; TITTERINGTON DM, 1985, ASTRON ASTROPHYS, V144, P381; VANDYK DA, 1995, STAT SINICA, V5, P55; VARDI Y, 1993, J ROY STAT SOC B MET, V55, P569	58	3	3	1	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JUN 15	2008	52	10					4768	4778		10.1016/j.csda.2008.03.022		11	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	322LR	WOS:000257377100020		
J	Rapaport, F; Barillot, E; Vert, JP				Rapaport, Franck; Barillot, Emmanuel; Vert, Jean-Philippe			Classification of arrayCGH data using fused SVM	BIOINFORMATICS			English	Article; Proceedings Paper	16th ISMB Conference on Intelligent Systems for Molecular Biology	JUL 19-23, 2008	Toronto, CANADA	ISMB			COMPARATIVE GENOMIC HYBRIDIZATION; COPY NUMBER; LOGISTIC-REGRESSION; GENE-EXPRESSION; UVEAL MELANOMA; BLADDER-CANCER; MINIMAL REGION; NEUROBLASTOMA; SELECTION; LASSO	Motivation: Array-based comparative genomic hybridization (arrayCGH) has recently become a popular tool to identify DNA copy number variations along the genome. These profiles are starting to be used as markers to improve prognosis or diagnosis of cancer, which implies that methods for automated supervised classification of arrayCGH data are needed. Like gene expression profiles, arrayCGH profiles are characterized by a large number of variables usually measured on a limited number of samples. However, arrayCGH profiles have a particular structure of correlations between variables, due to the spatial organization of bacterial artificial chromosomes along the genome. This suggests that classical classification methods, often based on the selection of a small number of discriminative features, may not be the most accurate methods and may not produce easily interpretable prediction rules. Results: We propose a new method for supervised classification of arrayCGH data. The method is a variant of support vector machine that incorporates the biological specificities of DNA copy number variations along the genome as prior knowledge. The resulting classifier is a sparse linear classifier based on a limited number of regions automatically selected on the chromosomes, leading to easy interpretation and identification of discriminative regions of the genome. We test this method on three classification problems for bladder and uveal cancer, involving both diagnosis and prognosis. We demonstrate that the introduction of the new prior on the classifier leads not only to more accurate predictions, but also to the identification of known and new regions of interest in the genome.	[Rapaport, Franck; Barillot, Emmanuel; Vert, Jean-Philippe] Inst Curie, Ctr Rech, F-75248 Paris, France; [Rapaport, Franck; Barillot, Emmanuel; Vert, Jean-Philippe] INSERM, U900, F-75248 Paris, France; [Rapaport, Franck; Barillot, Emmanuel; Vert, Jean-Philippe] Ecole Mines, Ctr Computat Biol, F-77305 Fontainebleau, France	Rapaport, F (reprint author), Inst Curie, Ctr Rech, F-75248 Paris, France.	franck.rapaport@curie.fr					Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Blaveri E, 2005, CLIN CANCER RES, V11, P7012, DOI 10.1158/1078-0432.CCR-05-0177; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Hanahan D, 2000, CELL, V100, P57, DOI 10.1016/S0092-8674(00)81683-9; Pinkel D, 1998, NAT GENET, V20, P207, DOI 10.1038/2524; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Yao J, 2006, CANCER RES, V66, P4065, DOI 10.1158/0008-5472.CAN-05-4083; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Boser B. E., 1992, COMPUTATIONAL LEARNI, P144; Bown N, 2001, MED PEDIATR ONCOL, V36, P14, DOI 10.1002/1096-911X(20010101)36:1<14::AID-MPO1005>3.0.CO;2-G; CHIN SF, 2006, ONCOGENE, V26, P1959; Corson TW, 2005, ONCOGENE, V24, P4741, DOI 10.1038/sj.onc.1208641; Gershon D, 2005, NATURE, V437, P1195, DOI 10.1038/4371195a; IDBAIH A, 2007, INT J CANC; Jones C, 2004, CLIN CANCER RES, V10, P5988, DOI 10.1158/1078-0432.CCR-03-0731; Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55; Land S. R., 1996, VARIABLE FUSION NEW; Lastowska M, 1997, GENE CHROMOSOME CANC, V18, P162; O'Hagan RC, 2003, CANCER RES, V63, P5352; Parrella P, 2003, CANCER RES, V63, P8507; Shing DC, 2003, CANCER RES, V63, P4568; SPEICHER MR, 1994, CANCER RES, V54, P3817; Stransky N, 2006, NAT GENET, V38, P1386, DOI 10.1038/ng1923; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; TIBSHIRANI R, 2007, BIOSTATISTICS; TROLET J, 2008, CANC RES UNPUB; Tschentscher F, 2001, CANCER RES, V61, P3439; van Beers EH, 2006, BREAST CANCER RES, V8, DOI 10.1186/bcr1510; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Van Roy N, 2002, GENE CHROMOSOME CANC, V35, P113, DOI 10.1002/gcc.10034; Vapnik V., 1998, STAT LEARNING THEORY; WALDMAN FM, 1991, CANCER RES, V51, P3807; Zhu J., 2004, ADV NEURAL INFORM PR, V16	37	14	14	1	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JUL 1	2008	24	13					I375	I382		10.1093/bioinformatics/btn188		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	319NE	WOS:000257169700065	18586737	
J	Hennenfent, G; van den Berg, E; Friedlander, MP; Herrmann, FJ				Hennenfent, Gilles; van den Berg, Ewout; Friedlander, Michael P.; Herrmann, Felix J.			New insights into one-norm solvers from the Pareto curve	GEOPHYSICS			English	Article							ALGORITHM	Geophysical inverse problems typically involve a trade-off between data misfit and some prior model. Pareto curves trace the optimal trade-off between these two competing aims. These curves are used commonly in problems with two-norm priors in which they are plotted on a log-log scale and are known as L-curves. For other priors, such as the sparsity-promoting one-norm prior, Pareto curves remain relatively unexplored. We show how these curves lead to new insights into one-norm regularization. First, we confirm theoretical properties of smoothness and convexity of these curves from a stylized and a geophysical example. Second, we exploit these crucial properties to approximate the Pareto curve for a large-scale problem. Third, we show how Pareto curves provide an objective criterion to gauge how different one-norm solvers advance toward the solution.	[Hennenfent, Gilles; Herrmann, Felix J.] Univ British Columbia, Dept Earth & Ocean Sci, Seism Lab Imaging & Modeling, Vancouver, BC V5Z 1M9, Canada; [van den Berg, Ewout; Friedlander, Michael P.] Univ British Columbia, Dept Comp Sci, Comp Sci Lab, Vancouver, BC V5Z 1M9, Canada	Hennenfent, G (reprint author), Univ British Columbia, Dept Earth & Ocean Sci, Seism Lab Imaging & Modeling, Vancouver, BC V5Z 1M9, Canada.	ghennenfent@eos.ubc.ca; ewout78@cs.ubc.ca; mpf@cs.ubc.ca; fherrmann@eos.ubc.ca					PHILLIPS DL, 1962, J ACM, V9, P84, DOI 10.1145/321105.321114; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; OLDENBURG DW, 1983, GEOPHYSICS, V48, P1318, DOI 10.1190/1.1441413; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; DAUBECHIES IM, 2007, ARXIV E PRINTS, V706; DONOHO DL, 2006, TR20062 STANF STAT D; GERSZTENKORN A, 1986, GEOPHYSICS, V51, P357, DOI 10.1190/1.1442095; Hennefent G., 2008, GEOPHYSICS, V73, P19; HERRMANN FJ, 2008, GEOPHYS J INT, V173, P1233; Lawson C. L., 1974, SOLVING LEAST SQUARE; Parker R., 1994, GEOPHYS INVERSE THEO; Rauhut H, 2007, APPL COMPUT HARMON A, V22, P16, DOI 10.1016/j.acha.2006.05.002; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1035; VANDENBERG E, 2008, TR200801 UBC COMP SC	18	17	18	0	0	SOC EXPLORATION GEOPHYSICISTS	TULSA	8801 S YALE ST, TULSA, OK 74137 USA	0016-8033			GEOPHYSICS	Geophysics	JUL-AUG	2008	73	4					A23	A26		10.1190/1.2944169		4	Geochemistry & Geophysics	Geochemistry & Geophysics	329HW	WOS:000257859000001		
J	Wei, P; Pan, W				Wei, Peng; Pan, Wei			Incorporating gene functions into regression analysis of DNA-protein binding data and gene expression data to construct transcriptional networks	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						LASSO; microarray; shrinkage estimator; stratified analysis; transcription factor	YEAST-CELL-CYCLE; SACCHAROMYCES-CEREVISIAE; REGULATORY NETWORKS; IDENTIFICATION; INFORMATION; MODEL; CATEGORIES; SELECTION; CHROMATIN; ONTOLOGY	Useful information on transcriptional networks has been extracted by regression analyses of gene expression data and DNA-protein binding data. However, a potential limitation of these approaches is their assumption on the common and constant activity level of a transcription factor (TF) on all of the genes in any given experimental condition, for example, any TF is assumed to be either an activator or a repressor, but not both, whereas it is known that some TFs can be dual regulators. Rather than assuming a common linear regression model for all of the genes, we propose using separate regression models for various gene groups; the genes can be grouped based on their functions or some clustering results. Furthermore, to take advantage of the hierarchical structure of many existing gene function annotation systems such as Gene Ontology (GO), we propose a shrinkage method that borrows information from relevant gene groups. Applications to a yeast data set and simulations lend support to our proposed methods. In particular, we find that the shrinkage method consistently works well under various scenarios. We recommend the use of the shrinkage method as a useful alternative to the existing methods.	[Wei, Peng; Pan, Wei] Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA	Wei, P (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, A460 Mayo Bldg MMC 303, Minneapolis, MN 55455 USA.	pengw@biostat.umn.edu; weip@biostat.umn.edu	Wei, Peng/E-4173-2012	Wei, Peng/0000-0003-1873-3301			Al-Shahrour F, 2005, BIOINFORMATICS, V21, P2988, DOI 10.1093/bioinformatics/bti457; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Zeeberg BR, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-4-r28; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Tian L, 2005, P NATL ACAD SCI USA, V102, P13544, DOI 10.1073/pnas.0506577102; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; Khatri P, 2005, BIOINFORMATICS, V21, P3587, DOI 10.1093/bioinformatics/bti565; Ashburner M, 2000, NAT GENET, V25, P25; Mootha VK, 2003, NAT GENET, V34, P267, DOI 10.1038/ng1180; Perez-Rueda E, 2000, NUCLEIC ACIDS RES, V28, P1838, DOI 10.1093/nar/28.8.1838; Handl J, 2005, BIOINFORMATICS, V21, P3201, DOI 10.1093/bioinformatics/bti517; Efron B, 2004, ANN STAT, V32, P407; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Barry WT, 2005, BIOINFORMATICS, V21, P1943, DOI 10.1093/bioinformatics/bti260; Ben-Shaul Y, 2005, BIOINFORMATICS, V21, P1129, DOI 10.1093/bioinformatics/bti149; Brune I, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-21; Bussemaker HJ, 2001, NAT GENET, V27, P167, DOI 10.1038/84792; Cheng Jill, 2004, J Biopharm Stat, V14, P687, DOI 10.1081/BIP-200025659; Cui Y, 2004, OMICS, V8, P106, DOI 10.1089/1536231041388320; de Lichtenberg U, 2005, SCIENCE, V307, P724, DOI 10.1126/science.1105103; DOOLIN MT, 2001, MOL MICROBIOL, V40, P22; FANG Z, 2005, J BIOMEDICAL INFORM; Gao F, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-31; Hastie T., 2001, ELEMENTS STAT LEARNI; Huang DS, 2006, BIOINFORMATICS, V22, P1259, DOI 10.1093/bioinformatics/btl065; HUGHES TR, 2000, CELL, V126, P102; Iyer VR, 2001, NATURE, V409, P533, DOI 10.1038/35054095; Kaufman L., 1990, FITTING GROUPS DATA; Keles S, 2002, BIOINFORMATICS, V18, P1167, DOI 10.1093/bioinformatics/18.9.1167; Louis T. A., 2000, BAYES EMPIRICAL BAYE; Mewes HW, 2002, NUCLEIC ACIDS RES, V30, P31, DOI 10.1093/nar/30.1.31; Middendorf Manuel, 2004, Bioinformatics, V20 Suppl 1, pi232, DOI 10.1093/bioinformatics/bth923; Mishra RK, 2001, MOL CELL BIOL, V21, P1311, DOI 10.1128/MCB.21.4.1311-1318.2001; Okada M, 1998, MOL CELL BIOL, V18, P2455; Pan W, 2006, BIOINFORMATICS, V22, P795, DOI 10.1093/bioinformatics/btl011; PAN W, 2005, STAT APPL GENETIC MO, V4; Phuong TM, 2004, BIOINFORMATICS, V20, P750, DOI 10.1093/bioinformatics/btg480; REN B, 2000, SCIENCE, V290; Ruan JH, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-114; Simon I, 2001, CELL, V106, P697, DOI 10.1016/S0092-8674(01)00494-9; Sun N, 2006, P NATL ACAD SCI USA, V103, P7988, DOI 10.1073/pnas.0600164103; Van der Laan MJ, 2003, J STAT COMPUT SIM, V73, P575, DOI 10.1080/0094965031000136012; Xu XL, 2002, HUM MOL GENET, V11, P1977, DOI 10.1093/hmg/11.17.1977; ZHAO H, 2003, SCI STAT FESTSCHRIFT, P259, DOI 10.1214/lnms/1215091147; Zhong Sheng, 2004, Appl Bioinformatics, V3, P261, DOI 10.2165/00822942-200403040-00009; Zhou YY, 2005, BIOINFORMATICS, V21, P1237, DOI 10.1093/bioinformatics/bti111	47	4	4	0	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963			IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JUL-SEP	2008	5	3					401	415		10.1109/TCBB.2007.1062		15	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	330ZP	WOS:000257981800008	18670043	
J	d'Aspremont, A; Bach, F; El Ghaoui, L				d'Aspremont, Alexandre; Bach, Francis; El Ghaoui, Laurent			Optimal solutions for sparse principal component analysis	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						PCA; subset selection; sparse eigenvalues; sparse recovery; lasso	SELECTION; LASSO; APPROXIMATIONS; ROTATION	Given a sample covariance matrix, we examine the problem of maximizing the variance explained by a linear combination of the input variables while constraining the number of nonzero coefficients in this combination. This is known as sparse principal component analysis and has a wide array of applications in machine learning and engineering. We formulate a new semidefinite relaxation to this problem and derive a greedy algorithm that computes a full set of good solutions for all target numbers of non zero coefficients, with total complexity O(n(3)), where n is the number of variables. We then use the same relaxation to derive sufficient conditions for global optimality of a solution, which can be tested in O ( n3) per pattern. We discuss applications in subset selection and sparse recovery and show on artificial examples and biological data that our algorithm does provide globally optimal solutions in many cases.	[d'Aspremont, Alexandre] Princeton Univ, ORFE, Princeton, NJ 08544 USA; [Bach, Francis] INRIA WILLOW Project Team, CNRS ENS, Ecole Normale Super, Lab Informat,UMR 8548, F-75230 Paris, France; [El Ghaoui, Laurent] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA	d'Aspremont, A (reprint author), Princeton Univ, ORFE, Princeton, NJ 08544 USA.	ASPREMON@PRINCETON.EDU; FRANCIS.BACH@MINES.ORG; ELGHAOUI@EECS.BERKELEY.EDU					Alon A., 1999, CELL BIOL, V96, P6745; KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Ben-Tal A, 2002, SIAM J OPTIMIZ, V12, P811, DOI 10.1137/S1052623400374756; CADIMA J, 1995, J APPL STAT, V22, P203, DOI 10.1080/757584614; Couvreur C, 2000, SIAM J MATRIX ANAL A, V21, P797, DOI 10.1137/S0895479898332928; d'Aspremont A., 2007, P 24 INT C MACH LEAR; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9446, DOI 10.1073/pnas.0502269102; Horn R. A., 1985, MATRIX ANAL; JOLLIFFE IT, 1995, J APPL STAT, V22, P29, DOI 10.1080/757584395; Kato T., 1966, PERTURBATION THEORY; MEINSHAUSEN N, 2006, LASSO TYPE RECOVERY; MOGHADDAM B., 2006, ADV NEURAL INFORM PR, V18; MOGHADDAM B, 2007, COMP VIS 2007 ICCV 2; Moghaddam B., 2006, P ICML; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Neuhaus JO, 1954, BRIT J STATIST PSYCH, V7, P81; Rudin W., 1987, REAL COMPLEX ANAL; Sriperumbudur B. K., 2007, P 24 INT C MACH LEAR, P831, DOI 10.1145/1273496.1273601; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Zhang ZY, 2002, SIAM J MATRIX ANAL A, V23, P706, DOI 10.1137/S0895479899359631; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	29	52	52	1	10	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUL	2008	9						1269	1294				26	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	340LJ	WOS:000258646800001		
J	Shen, HP; Huang, JHZ				Shen, Haipeng; Huang, Jianhua Z.			Sparse principal component analysis via regularized low rank matrix approximation	JOURNAL OF MULTIVARIATE ANALYSIS			English	Article						dimension reduction; high-dimension-low-sample-size; regularization; singular value decomposition; thresholding	VARIABLE SELECTION; SHRINKAGE; CHOICE; LASSO	Principal component analysis (PCA) is a widely used tool for data analysis and dimension reduction in applications throughout science and engineering. However, the principal components (PCs) can sometimes be difficult to interpret, because they are linear combinations of all the original variables. To facilitate interpretation, sparse PCA produces modified PCs with sparse loadings, i.e. loadings with very few non-zero elements. In this paper, we propose a new sparse PCA method, namely sparse PCA via regularized SVD (sPCA-rSVD). We use the connection of PCA with singular value decomposition (SVD) of the data matrix and extract the PCs through solving a low rank matrix approximation problem. Regularization penalties are introduced to the corresponding minimization problem to promote sparsity in PC loadings. An efficient iterative algorithm is proposed for computation. Two tuning parameter selection methods are discussed. Some theoretical results are established to justify the use of sPCA-rSVD when only the data covariance matrix is available. In addition, we give a modified definition of variance explained by the sparse PCs. The sPCA-rSVD provides a uniform treatment of both classical multivariate data and high-dimension-low-sample-size (HDLSS) data. Further understanding of sPCA-rSVD and some existing alternatives is gained through simulation studies and real data examples, which suggests that sPCA-rSVD provides competitive results. (C) 2007 Elsevier Inc. All rights reserved.	[Shen, Haipeng] Univ N Carolina, Dept Stat & Operat Res, Chapel Hill, NC 27599 USA; [Huang, Jianhua Z.] Texas A&M Univ, Dept Stat, College Stn, TX 77843 USA	Shen, HP (reprint author), Univ N Carolina, Dept Stat & Operat Res, Chapel Hill, NC 27599 USA.	haipeng@email.unc.edu; jianhua@stat.tamu.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; GABRIEL KR, 1979, TECHNOMETRICS, V21, P489, DOI 10.2307/1268288; Benito M, 2004, BIOINFORMATICS, V20, P105, DOI 10.1093/bioinformatics/btg385; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; CADIMA J, 1995, J APPL STAT, V22, P203, DOI 10.1080/757584614; Hastie T, 2000, GENOME BIOL, V1, P1, DOI DOI 10.1186/GB-2000-1-2-RESEARCH0003; Jeffers JNR, 1967, APPLIED STATISTICS, V16, P225, DOI 10.2307/2985919; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Jolliffe IT, 2000, J COMPUT GRAPH STAT, V9, P689, DOI 10.2307/1391088; JOLLIFFE IT, 1995, J APPL STAT, V22, P29, DOI 10.1080/757584395; LIU Y, 2007, J COMPUT GR IN PRESS; MARRON JS, 2005, J AM STAT A IN PRESS; VINES SK, 2000, APPL STAT, V49, P441; West M., 2003, BAYESIAN STAT, P723; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	20	114	118	6	31	ELSEVIER INC	SAN DIEGO	525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA	0047-259X			J MULTIVARIATE ANAL	J. Multivar. Anal.	JUL	2008	99	6					1015	1034		10.1016/j.jmva.2007.06.007		20	Statistics & Probability	Mathematics	314IZ	WOS:000256804400001		
J	Joseph, VR; Delaney, JD				Joseph, V. Roshan; Delaney, James Dillon			Analysis of optimization experiments	JOURNAL OF QUALITY TECHNOLOGY			English	Article						empirical Bayes method; practical significance level; shrinkage estimation; variable selection	RESPONSE-SURFACE OPTIMIZATION; DESIGNED EXPERIMENTS; BAYESIAN-APPROACH; REGRESSION; VARIABLES; SELECTION	The typical practice for analyzing industrial experiments is to identify statistically significant effects with a 5% level of significance and then to optimize the model containing only those effects. In this article, we illustrate the danger in utilizing this approach. We propose methodology using the practical significance level, which is a quantity that a practitioner can easily specify. We also propose utilizing empirical Bayes estimation, which gives shrinkage estimates of the effects. Interestingly, the mechanics of statistical testing can be viewed as an approximation to empirical Bayes estimation, but with a significance level in the range of 15-40%. We also establish the connections that our approach has with a less known but intriguing technique proposed by Taguchi, known as the beta coefficient method. A real example and simulations are used to demonstrate the advantages of the proposed methodology.	[Joseph, V. Roshan] Georgia Inst Technol, H Milton Stewart Sch Ind & Syst Engn, Atlanta, GA 30332 USA; [Delaney, James Dillon] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA	Joseph, VR (reprint author), Georgia Inst Technol, H Milton Stewart Sch Ind & Syst Engn, Atlanta, GA 30332 USA.	roshan@isye.gatech.edu; jdelaney@stat.cmu.edu					BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Efron B, 2004, ANN STAT, V32, P407; Berger J. O., 1985, STAT DECISION THEORY; Box G. E. P., 2005, STAT EXPT; BOX GEP, 1993, J QUAL TECHNOL, V25, P94; Chipman H, 1997, TECHNOMETRICS, V39, P372, DOI 10.2307/1271501; Daniel C., 1959, TECHNOMETRICS, V1, P311, DOI DOI 10.1080/00401706.1959.10489866; DELANEY JD, 2006, THESIS GEORGIA I TEC; GRUBER TH, 1998, IMPROVING EFFICIENCY; Hamada M, 1998, STAT SINICA, V8, P1; HAMADA M, 1992, J QUAL TECHNOL, V24, P130; HELLSTRAND C, 1989, PHILOS T R SOC A, V327, P529, DOI 10.1098/rsta.1989.0008; Jeff Wu CF, 2000, EXPT PLANNING ANAL P; Joseph VR, 2007, TECHNOMETRICS, V49, P1, DOI 10.1198/004017006000000372; Joseph VR, 2004, J QUAL TECHNOL, V36, P129; Joseph VR, 2006, TECHNOMETRICS, V48, P219, DOI 10.1198/004017005000000652; KENNEDY WJ, 1971, ANN MATH STAT, V42, P1273, DOI 10.1214/aoms/1177693240; Lehmann E. L., 1998, THEORY POINT ESTIMAT; LENTH RV, 1989, TECHNOMETRICS, V31, P469, DOI 10.2307/1269997; Louis T. A., 2000, BAYES EMPIRICAL BAYE; Meyer RD, 1996, TECHNOMETRICS, V38, P303, DOI 10.2307/1271297; Miro-Quesada G, 2004, J APPL STAT, V31, P251, DOI 10.1080/0266476042000184019; Montgomery D. C., 2002, RESPONSE SURFACE MET; Montgomery D.C., 2004, DESIGN ANAL EXPT; Peterson JJ, 2004, J QUAL TECHNOL, V36, P139; Rajagopal R, 2005, TECHNOMETRICS, V47, P152, DOI 10.1198/004017005000000120; Taguchi Genichi, 1987, SYSTEM EXPT DESIGN, V1; Taguchi Genichi, 1987, SYSTEM EXPT DESIGN, V2	29	3	3	0	1	AMER SOC QUALITY CONTROL-ASQC	MILWAUKEE	600 N PLANKINTON AVE, MILWAUKEE, WI 53203 USA	0022-4065			J QUAL TECHNOL	J. Qual. Technol.	JUL	2008	40	3					282	298				17	Engineering, Industrial; Operations Research & Management Science; Statistics & Probability	Engineering; Operations Research & Management Science; Mathematics	322BZ	WOS:000257351500004		
J	Reich, BJ; Hodges, JS				Reich, Brian J.; Hodges, James S.			Identitication of the variance components in the general two-variance linear model	JOURNAL OF STATISTICAL PLANNING AND INFERENCE			English	Article						conditional autoregressive prior; hierarchical models; identification; mixed linear model; variance components		Bayesian analyses frequently employ two-stage hierarchical models involving two-variance parameters: one controlling measurement error and the other controlling the degree of smoothing implied by the model's higher level. These analyses can be hampered by poorly identified variances which may lead to difficulty in computing and in choosing reference priors for these parameters. In this paper, we introduce the class of two-variance hierarchical linear models and characterize the aspects of these models that lead to well-identified or poorly identified variances. These ideas are illustrated with a spatial analysis of a periodontal data set and examined in some generality for specific two-variance models including the conditionally autoregressive (CAR) and one-way random effect models. We also connect this theory with other constrained regression methods and suggest a diagnostic that can be used to search for missing spatially varying fixed effects in the CAR model. (c) 2007 Elsevier B.V. All rights reserved.	[Reich, Brian J.] N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA; [Hodges, James S.] Univ Minnesota, Div Biostat, Sch Publ Hlth, Minneapolis, MN 55414 USA	Reich, BJ (reprint author), N Carolina State Univ, Dept Stat, 2501 Founders Dr,Box 8203, Raleigh, NC 27695 USA.	reich@stat.ncsu.edu					LINDLEY DV, 1972, J ROY STAT SOC B, V34, P1; Fulton W, 2000, B AM MATH SOC, V37, P209, DOI 10.1090/S0273-0979-00-00865-X; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466; Browne W., 2001, STAT MODEL, V1, P103, DOI DOI 10.1191/147108201128113; Gelman A, 2005, BAYESIAN ANAL, V1, P1; Hodges JS, 2003, BIOMETRICS, V59, P317, DOI 10.1111/1541-0420.00038; Hodges JS, 2001, BIOMETRIKA, V88, P367, DOI 10.1093/biomet/88.2.367; LAIRD NM, 1982, BIOMETRICS, V38, P963, DOI 10.2307/2529876; McCaffrey DF, 2004, J EDUC BEHAV STAT, V29, P67, DOI 10.3102/10769986029001067; Reich BJ, 2007, J AM STAT ASSOC, V102, P44, DOI 10.1198/016214606000000753; ROBERTS T, 1999, EXAMINING MEAN STRUC; SHIEVITZ P, 1997, THESIS U MINNESOTA M; Spiegelhalter DJ, 2002, J ROY STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353	14	3	3	2	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3758			J STAT PLAN INFER	J. Stat. Plan. Infer.	JUL 1	2008	138	6					1592	1604		10.1016/j.jspi.2007.05.046		13	Statistics & Probability	Mathematics	285ZH	WOS:000254814200006		
J	Hoggart, CJ; Whittaker, JC; De Iorio, M; Balding, DJ				Hoggart, Clive J.; Whittaker, John C.; De Iorio, Maria; Balding, David J.			Simultaneous Analysis of All SNPs in Genome-Wide and Re-Sequencing Association Studies	PLOS GENETICS			English	Article							BAYESIAN VARIABLE SELECTION; GENETIC RISK; PREDICTION; REGRESSION; DISEASE; REGIONS; LASSO	Testing one SNP at a time does not fully realise the potential of genome-wide association studies to identify multiple causal variants, which is a plausible scenario for many complex diseases. We show that simultaneous analysis of the entire set of SNPs from a genome-wide study to identify the subset that best predicts disease outcome is now feasible, thanks to developments in stochastic search methods. We used a Bayesian-inspired penalised maximum likelihood approach in which every SNP can be considered for additive, dominant, and recessive contributions to disease risk. Posterior mode estimates were obtained for regression coefficients that were each assigned a prior with a sharp mode at zero. A non-zero coefficient estimate was interpreted as corresponding to a significant SNP. We investigated two prior distributions and show that the normal-exponential-gamma prior leads to improved SNP selection in comparison with single-SNP tests. We also derived an explicit approximation for type-I error that avoids the need to use permutation procedures. As well as genome-wide analyses, our method is well-suited to fine mapping with very dense SNP sets obtained from re- sequencing and/or imputation. It can accommodate quantitative as well as case-control phenotypes, covariate adjustment, and can be extended to search for interactions. Here, we demonstrate the power and empirical type-I error of our approach using simulated case-control data sets of up to 500 K SNPs, a real genome-wide data set of 300 K SNPs, and a sequence-based dataset, each of which can be analysed in a few hours on a desktop workstation.	[Hoggart, Clive J.; De Iorio, Maria; Balding, David J.] Univ London Imperial Coll Sci Technol & Med, Dept Epidemiol & Publ Hlth, London, England; [Whittaker, John C.] London Sch Hyg & Trop Med, Noncommunicable Dis Epidemiol Unit, London WC1, England	Hoggart, CJ (reprint author), Univ London Imperial Coll Sci Technol & Med, Dept Epidemiol & Publ Hlth, London, England.	c.hoggart@ic.ac.uk	Balding, David/G-9898-2011; Peng, Bo/A-6920-2009; Whittaker, John/B-8609-2012	Balding, David/0000-0002-1480-6115; Peng, Bo/0000-0001-8225-2284; Whittaker, John/0000-0002-3529-2379	UK Medical Research Council; UK Department of Trade and Industry	Clive Hoggart was funded by the UK Medical Research Council. This work has been carried out within the BARGEN project, under the LINK scheme operated by the UK Department of Trade and Industry.	Lunn DJ, 2006, GENET EPIDEMIOL, V30, P231, DOI 10.1002/gepi.20140; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Sasieni PD, 1997, BIOMETRICS, V53, P1253, DOI 10.2307/2533494; Holmes CC, 2006, BAYESIAN ANAL, V1, P145; Brown PJ, 2002, J R STAT SOC B, V64, P519, DOI 10.1111/1467-9868.00348; Sladek R, 2007, NATURE, V445, P881, DOI 10.1038/nature05616; Morrison AC, 2007, AM J EPIDEMIOL, V166, P28, DOI 10.1093/aje/kwm060; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Schaffner SF, 2005, GENOME RES, V15, P1576, DOI 10.1101/gr.3709305; Meuwissen THE, 2001, GENETICS, V157, P1819; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; BAZARAA M. S., 1979, NONLINEAR PROGRAMMIN; Breiman L, 1996, ANN STAT, V24, P2350; George EI, 1997, STAT SINICA, V7, P339; Gorlov IP, 2008, AM J HUM GENET, V82, P100, DOI 10.1016/j.ajhg.2007.09.006; Gradshteyn I.S., 1980, TABLES INTEGRALS SER; GRIFFIN JE, 2007, BAYESIAN ADAPTIVE LA; Hoggart CJ, 2007, GENETICS, V177, P1725, DOI 10.1534/genetics.106.069088; Li Y, 2006, AM J HUM GENET S, VS79, P2290; MITCHELL TJ, 1988, J AM STAT ASSOC, V83, P1023, DOI 10.2307/2290129; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Patterson N, 2006, PLOS GENET, V2, P190; Servin B, 2007, PLOS GENET, V3, P1296, DOI 10.1371/journal.pgen.0030114; Burton PR, 2007, NATURE, V447, P661, DOI 10.1038/nature05911; WEST M, 2003, BAYESIAN STAT, V7, P733; Wray NR, 2007, GENOME RES, V17, P1520, DOI 10.1101/gr.6665407; Zhang SJ, 1996, COMPUTATION SPECIAL	27	132	134	2	17	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-7390			PLOS GENET	PLoS Genet.	JUL	2008	4	7							e1000130	10.1371/journal.pgen.1000130		8	Genetics & Heredity	Genetics & Heredity	365ML	WOS:000260410600004	18654633	
J	He, XS; Holmes, TH; Sasaki, S; Jaimes, MC; Kemble, GW; Dekker, CL; Arvin, AM; Greenberg, HB				He, Xiao-Song; Holmes, Tyson H.; Sasaki, Sanae; Jaimes, Maria C.; Kemble, George W.; Dekker, Cornelia L.; Arvin, Ann M.; Greenberg, Harry B.			Baseline Levels of Influenza-Specific CD4 Memory T-Cells Affect T-Cell Responses to Influenza Vaccines	PLOS ONE			English	Article								Background: Factors affecting immune responses to influenza vaccines have not been studied systematically. We hypothesized that T-cell and antibody responses to the vaccines are functions of pre-existing host immunity against influenza antigens. Methodology/Principal Findings: During the 2004 and 2005 influenza seasons, we have collected data on cellular and humoral immune reactivity to influenza virus in blood samples collected before and after immunization with inactivated or live attenuated influenza vaccines in healthy children and adults. We first used cross-validated lasso regression on the 2004 dataset to identify a group of candidate baseline correlates with T-cell and antibody responses to vaccines, defined as fold-increase in influenza-specific T-cells and serum HAI titer after vaccination. The following baseline parameters were examined: percentages of influenza-reactive IFN-gamma(+) cells in T and NK cell subsets, percentages of influenza-specific memory B-cells, HAI titer, age, and type of vaccine. The candidate baseline correlates were then tested with the independent 2005 dataset. Baseline percentage of influenza-specific IFN-gamma(+) CD4 T-cells was identified as a significant correlate of CD4 and CD8 T- cell responses, with lower baseline levels associated with larger T- cell responses. Baseline HAI titer and vaccine type were identified as significant correlates for HAI response, with lower baseline levels and the inactivated vaccine associated with larger HAI responses. Previously we reported that baseline levels of CD56(dim) NK reactivity against influenza virus inversely correlated with the immediate T- cell response to vaccination, and that NK reactivity induced by influenza virus depended on IL-2 produced by influenza-specific memory T- cells. Taken together these results suggest a novel mechanism for the homeostasis of virus-specific T- cells, which involves interaction between memory helper T-cells, CD56(dim) NK and DC. Significance: These results demonstrate that assessment of baseline biomarkers may predict immunologic outcome of influenza vaccination and may reveal some of the mechanisms responsible for variable immune responses following vaccination and natural infection.	[He, Xiao-Song; Sasaki, Sanae; Jaimes, Maria C.; Greenberg, Harry B.] Stanford Univ, Dept Med, Sch Med, Stanford, CA 94305 USA; [He, Xiao-Song; Sasaki, Sanae; Jaimes, Maria C.; Greenberg, Harry B.] VA Palo Alto Hlth Care Syst, Palo Alto, CA USA; [Holmes, Tyson H.] Stanford Univ, Sch Med, Dept Hlth Res & Policy Biostat, Stanford, CA USA; [Kemble, George W.; Arvin, Ann M.] MedImmune Vaccines, Mountain View, CA USA; [Dekker, Cornelia L.; Arvin, Ann M.] Stanford Univ, Sch Med, Dept Pediat, Stanford, CA USA; [Greenberg, Harry B.] Stanford Univ, Sch Med, Dept Microbiol & Immunol, Stanford, CA USA	He, XS (reprint author), Stanford Univ, Dept Med, Sch Med, Stanford, CA 94305 USA.	xiaosong@Stanford.edu			(National Center for Research Resources), National Institutes of Health [U19 AI057229, M01 RR-00070]	U19 AI057229 and M01 RR-00070 (National Center for Research Resources), National Institutes of Health. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Anfossi N, 2006, IMMUNITY, V25, P331, DOI 10.1016/j.immuni.2006.06.013; He XS, 2004, J CLIN INVEST, V114, P1812, DOI 10.1172/JCI200422797; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Moretta A, 2002, NAT REV IMMUNOL, V2, P957, DOI 10.1038/nri956; He XS, 2006, J VIROL, V80, P11756, DOI 10.1128/JVI.01460-06; Liu BX, 2004, J GEN VIROL, V85, P423, DOI 10.1099/vir.0.19596-0; Nichol KL, 1999, JAMA-J AM MED ASSOC, V282, P137, DOI 10.1001/jama.282.2.137; Belshe RB, 2007, NEW ENGL J MED, V356, P685, DOI 10.1056/NEJMoa065368; McDonald NJ, 2007, J GEN VIROL, V88, P3209, DOI 10.1099/vir.0.83184-0; Hurwitz ES, 2000, JAMA-J AM MED ASSOC, V284, P1677, DOI 10.1001/jama.284.13.1677; SCHAPIRO JM, 1990, J MED VIROL, V30, P196, DOI 10.1002/jmv.1890300310; Medzhitov R, 1997, CURR OPIN IMMUNOL, V9, P4, DOI 10.1016/S0952-7915(97)80152-5; Doherty PC, 1997, IMMUNOL REV, V159, P105, DOI 10.1111/j.1600-065X.1997.tb01010.x; Piccioli D, 2002, J EXP MED, V195, P335, DOI 10.1084/jem.20010934; Seder RA, 2008, NAT REV IMMUNOL, V8, P247, DOI 10.1038/nri2274; Sasaki S, 2007, J VIROL, V81, P215, DOI 10.1128/JVI.01957-06; LANZAVECCHIA A, 1985, NATURE, V314, P537, DOI 10.1038/314537a0; Banchereau J, 2000, ANNU REV IMMUNOL, V18, P767, DOI 10.1146/annurev.immunol.18.1.767; Ohmit SE, 2006, NEW ENGL J MED, V355, P2513, DOI 10.1056/NEJMoa061850; Ferlazzo G, 2002, J EXP MED, V195, P343, DOI 10.1084/jem.20011149; Belshe RB, 2004, CLIN INFECT DIS, V39, P920, DOI 10.1086/423001; BELSHE RB, 2004, VACCINES; Belshe RB, 2001, PHILOS T ROY SOC B, V356, P1947, DOI 10.1098/rstb.2001.0982; Beyer WEP, 2004, VIRUS RES, V103, P125, DOI 10.1016/j.virusres.2004.02.024; Bot A, 1996, J VIROL, V70, P5668; Couch R B, 2003, Dev Biol (Basel), V115, P25; ENNIS FA, 1981, LANCET, V2, P891; Gerosa F, 2005, J IMMUNOL, V174, P727; Graham MB, 1997, J EXP MED, V186, P2063, DOI 10.1084/jem.186.12.2063; GRUBER WC, 1990, AM J DIS CHILD, V144, P595; Gruber WC, 1996, J INFECT DIS, V173, P1313; Harrell FE, 2001, REGRESSION MODELING; Hastie T., 2001, ELEMENTS STAT LEARNI; HE XS, 2008, J INFECT DIS; He XS, 2003, J INFECT DIS, V187, P1075, DOI 10.1086/368218; Holm S, 1979, SCAND J STAT, V43, P223; Kilbourne ED, 1999, VACCINES, P531; Kutza J, 1996, CLIN DIAGN LAB IMMUN, V3, P105; Lamb R. A., 2001, FIELDS VIROLOGY, P1533; Lee MS, 2004, PEDIATR INFECT DIS J, V23, P852, DOI 10.1097/01.inf.0000137566.87691.3b; MCMICHAEL AJ, 1983, NEW ENGL J MED, V309, P13, DOI 10.1056/NEJM198307073090103; MILLIKEN G, 1998, ANAL MESSY DATA DESI; Mysliwska J, 2004, EXP GERONTOL, V39, P1447, DOI 10.1016/j.exger.2004.08.005; NAGLER A, 1989, J IMMUNOL, V143, P3183; NETER J, 1996, APPL LINEAR STAT MOD, P724; Perez OD, 2006, IMMUNOL REV, V210, P208, DOI 10.1111/j.0105-2896.2006.00364.x; Plotkin JB, 2002, P NATL ACAD SCI USA, V99, P6263, DOI 10.1073/pnas.082110799; Soen Y, 2003, PLOS BIOL, V1, P429, DOI 10.1371/journal.pbio.0000065; Villarino AV, 2007, J EXP MED, V204, P65, DOI 10.1084/jem.20061198; YAP KL, 1978, NATURE, V273, P238, DOI 10.1038/273238a0; Zar J. H., 1999, BIOSTATISTICAL ANAL; Zeman AM, 2007, PEDIATR INFECT DIS J, V26, P107, DOI 10.1097/01.inf.0000253251.03785.9b; Zitvogel L, 2002, J EXP MED, V195, pf9, DOI 10.1084/jem.20012040	53	17	17	0	0	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203			PLOS ONE	PLoS One	JUL 2	2008	3	7							e2574	10.1371/journal.pone.0002574		7	Multidisciplinary Sciences	Science & Technology - Other Topics	406IM	WOS:000263288200039	18596908	
J	Farkas, O; Zenkevich, IG; Stout, F; Kalivas, JH; Heberger, K				Farkas, Orsolya; Zenkevich, Igor G.; Stout, Forrest; Kalivas, John H.; Heberger, Karoly			Prediction of retention indices for identification of fatty acid methyl esters	JOURNAL OF CHROMATOGRAPHY A			English	Article						prediction of retention index; fatty acid methyl-esters; QSRR; variable selection; MLR; PLS; pair-correlation method; Lasso method; forward selection	GAS-CHROMATOGRAPHIC RETENTION; IONIZATION MASS-SPECTROMETRY; EQUIVALENT CHAIN LENGTHS; PAIR-CORRELATION METHOD; RIDGE-REGRESSION; MULTIVARIATE CALIBRATION; POSED PROBLEMS; L-CURVE; SELECTION; RESOLUTION	Quantitative structure-retention relationships have been developed to predict retention indices of fatty acid methyl esters on standard non-polar polydimethylsiloxane stationary phases. Branched, saturated and unsaturated compounds were included. All retention indices have been evaluated by statistical processing of experimentally measured and literature data in accordance with the concept of interlaboratory data randomization. Multiple linear regression (MLR) has been carried out to find relationships between selected properties and retention indices. Models have been built in two different ways (i) the same degrees of freedom for all models have been fixed and the variable selection ability has been compared; (ii) variable selection methods have been used in their best performance. The five selection methods were: pair-wise correlation, forward selection, partial least squares projection of latent structures, modified best subset selection and the Lasso method. The stability and the validity of models have been tested by internal and external validation. The error of predicted retention indices is close to the error of interlaboratory reproducibility of retention indices. The most relevant variables in description of retention indices were molecular mass, number of double bonds and number of rotatable bonds complemented with topological descriptors. Predictive models have been built for 130 fatty acid methyl esters for identification purposes. Moreover, prediction of unknown retention indices for 37 fatty acid methyl esters has also been carried out. (C) 2008 Elsevier B.V. All rights reserved.	[Farkas, Orsolya; Heberger, Karoly] Hungarian Acad Sci, Chem Res Ctr, H-1525 Budapest, Hungary; [Zenkevich, Igor G.] Chem Res Inst, St Petersburg 198504, Russia; [Stout, Forrest; Kalivas, John H.] Idaho State Univ, Dept Chem, Pocatello, ID 83209 USA	Heberger, K (reprint author), Hungarian Acad Sci, Chem Res Ctr, POB 17, H-1525 Budapest, Hungary.	heberger@chemres.hu	Heberger, Karoly/A-4195-2011	Heberger, Karoly/0000-0003-0965-939X			ACKMAN RG, 1973, J CHROMATOGR, V86, P73, DOI 10.1016/S0021-9673(01)81236-X; ACKMAN R G, 1974, Chromatographia, V7, P107, DOI 10.1007/BF02269820; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tropsha A, 2003, QSAR COMB SCI, V22, P69, DOI 10.1002/qsar.200390007; BARVE JA, 1972, CHEM PHYS LIPIDS, V8, P117, DOI 10.1016/0009-3084(72)90023-0; CHRISTIE WW, 1989, GAS CHROMATOGRAPHY L, P161; Dobson G, 2002, EUR J LIPID SCI TECH, V104, P36, DOI 10.1002/1438-9312(200201)104:1<36::AID-EJLT111136>3.0.CO;2-W; Draper N. R., 1981, APPL REGRESSION ANAL, P307; DRAPER NR, 1981, APPL REGRESSION ANAL, P412; Farkas O, 2005, J CHEM INF MODEL, V45, P339, DOI 10.1021/ci049827t; Farkas O, 2004, CHEMOMETR INTELL LAB, V72, P173, DOI 10.1016/j.chemolab.2004.01.012; Forrester JB, 2004, J CHEMOMETR, V18, P372, DOI 10.1002/cem.883; GILLAN FT, 1983, J CHROMATOGR SCI, V21, P293; GOLOVNYA RV, 1977, CHROMATOGRAPHIA, V10, P545, DOI 10.1007/BF02262915; GOLOVNYA RV, 1976, J CHROMATOGR, V121, P118, DOI 10.1016/S0021-9673(00)82312-2; HANAI T, 1989, HRC-J HIGH RES CHROM, V12, P327; HANSEN PC, 1992, SIAM REV, V34, P561, DOI 10.1137/1034115; HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086; HASTIE T, 2001, ELEMENTS STAT LEARNI, P57; Heberger K, 2002, J CHEMOMETR, V16, P436, DOI 10.1002/cem.748; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Jimenez JJ, 2003, J CHROMATOGR A, V1007, P101, DOI 10.1016/S0021-9673(03)00962-2; Kalivas JH, 2001, APPL SPECTROSC, V55, P1645, DOI 10.1366/0003702011953955; Kalivas JH, 2005, J CHEMOMETR, V19, P64, DOI 10.1002/cem.905; Kittiratanapiboon K, 1998, J CHROMATOGR SCI, V36, P361; Li BY, 2003, CHROMATOGRAPHIA, V57, P235, DOI 10.1007/BF02491722; Martens H, 2003, ANAL CHEM, V75, P394, DOI 10.1021/ac020194w; *MATHWORKS, 2003, MATL 7 0 MATL OPT TO; Miller A.J., 1990, SUBSET SELECTION REG, P43; MILLER AJ, 1990, SUBSET SELECTION REG, P12; Mjos SA, 2004, EUR J LIPID SCI TECH, V106, P550, DOI 10.1002/ejit.200401013; Mjos SA, 2006, J CHROMATOGR A, V1122, P249, DOI 10.1016/j.chroma.2006.04.067; Mjos SA, 2006, J CHROMATOGR A, V1110, P171, DOI 10.1016/j.chroma.2006.01.092; *NIST, 2005, 69 NIST MS DAT CTR; Rajko R, 2001, CHEMOMETR INTELL LAB, V57, P1, DOI 10.1016/S0169-7439(01)00101-0; Seipel HA, 2004, J CHEMOMETR, V18, P306, DOI 10.1002/cem.874; SPITELLER M, 1979, J CHROMATOGR, V164, P253, DOI 10.1016/S0378-4347(00)81232-3; *STATSOFT, 2002, STAT 6 SOFTW PACK; STERN DJ, 1985, J AGR FOOD CHEM, V33, P180, DOI 10.1021/jf00062a005; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1035; Todeschini R., 2000, HDB MOL DESCRIPTORS; Todeschini R, 2002, DRAGON SOFTWARE VERS; Ubik K., 1974, COLLECT CZECH CHEM C, V40, P2826; van de Waterbeemd H., 1995, CHEMOMETRIC METHODS; VINE J, 1980, J CHROMATOGR, V196, P415, DOI 10.1016/S0021-9673(00)84744-5; Zenkevich I.G., 1984, ZH ANAL KHIM, V39, P1297; ZENKEVICH IG, 1988, J CHROMATOGR, V439, P185, DOI 10.1016/S0021-9673(01)83833-4	47	19	21	1	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0021-9673	1873-3778		J CHROMATOGR A	J. Chromatogr. A	JUL 11	2008	1198						188	195		10.1016/j.chroma.2008.05.019		8	Biochemical Research Methods; Chemistry, Analytical	Biochemistry & Molecular Biology; Chemistry	324UT	WOS:000257545600026	18533170	
J	Ayers, KL; Lange, K				Ayers, Kristin L.; Lange, Kenneth			Penalized estimation of haplotype frequencies	BIOINFORMATICS			English	Article							LINKAGE DISEQUILIBRIUM; GENOTYPE DATA; POPULATION; RECONSTRUCTION; ALGORITHMS; INFERENCE; MODEL	Motivation: Low haplotype diversity and linkage disequilibrium are the rule in short genomic segments. This fact suggests that parsimony should be enforced in estimation of haplotype frequencies. The current article introduces a diversity penalty that automatically discards potential haplotypes with low explanatory power. The standard EM algorithm for haplotype frequency estimation can accommodate the penalty if one passes over to a more general minorizemaximize (MM) scheme for estimation. Results: Our new MM algorithm converges in fewer iterations, eliminates marginal haplotypes from further consideration and reduces the computational complexity of each iteration. Estimation by the MM algorithm also improves haplotyping and genotype imputation compared to naive application of the EM algorithm. Thus, the MM algorithm is a useful substitute for the EM algorithm. Compared to the most sophisticated current methods of haplotyping and genotype imputation, the MM algorithm is slightly less accurate but at least an order of magnitude faster.	[Ayers, Kristin L.; Lange, Kenneth] Univ Calif Los Angeles, Dept Biomath, Los Angeles, CA 90095 USA; [Lange, Kenneth] Univ Calif Los Angeles, Dept Human Genet, Los Angeles, CA 90095 USA; [Lange, Kenneth] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Ayers, KL (reprint author), Univ Calif Los Angeles, Dept Biomath, Los Angeles, CA 90095 USA.	kayers@ucla.edu					Akey J, 2001, EUR J HUM GENET, V9, P291, DOI 10.1038/sj.ejhg.5200619; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Stephens M, 2005, AM J HUM GENET, V76, P449, DOI 10.1086/428594; EXCOFFIER L, 1995, MOL BIOL EVOL, V12, P921; Stephens M, 2001, AM J HUM GENET, V68, P978, DOI 10.1086/319501; Marchini J, 2006, AM J HUM GENET, V78, P437, DOI 10.1086/500808; Scheet P, 2006, AM J HUM GENET, V78, P629, DOI 10.1086/502802; Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836; Ayers KL, 2007, GENET EPIDEMIOL, V31, P672, DOI 10.1002/gepi.20232; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; DELEEUW J, 1977, GEOMETRIC REPRESENTA; Groenen P. J. F., 1993, MAJORIZATION APPROAC; Halperin E, 2004, BIOINFORMATICS, V20, P1842, DOI 10.1093/bioinformatics/bth149; HAWLEY ME, 1995, J HERED, V86, P409; Lange K, 2002, MATH STAT METHODS GE; LANGE K, 1987, AM J HUM GENET, V40, P250; Lange K., 2001, AM J HUM GENET S, V69, pA1886; Lange K., 2004, OPTIMIZATION; LONG JC, 1995, AM J HUM GENET, V56, P225; Qin ZHS, 2002, AM J HUM GENET, V71, P1242, DOI 10.1086/344207; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; TAYLOR HL, 1979, GEOPHYSICS, V44, P39, DOI 10.1190/1.1440921	23	12	12	1	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JUL 15	2008	24	14					1596	1602		10.1093/bioinformatics/btn236		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	325GC	WOS:000257576000006	18487240	
J	Zou, H; Li, RZ				Zou, Hui; Li, Runze			One-step sparse estimates in nonconcave penalized likelihood models	ANNALS OF STATISTICS			English	Article						AIC; BIC; LASSO; one-step estimator; oracle properties; SCAD	SURROGATE OBJECTIVE FUNCTIONS; FAILURE TIME DATA; VARIABLE SELECTION; REGRESSION; LASSO; REGULARIZATION; ASYMPTOTICS	Fan and Li propose a family of variable selection methods via penalized likelihood using concave penalty functions. The nonconcave penalized likelihood estimators enjoy the oracle properties, but maximizing the penalized likelihood function is computationally challenging, because the objective function is nondifferentiable and nonconcave. In this article, we propose a new unified algorithm based on the local linear approximation (LLA) for maximizing the penalized likelihood for a broad class of concave penalty functions. Convergence and other theoretical properties of the LLA algorithm are established. A distinguished feature of the LLA algorithm is that at each LLA step, the LLA estimator can naturally adopt a sparse representation. Thus, we suggest using the one-step LLA estimator from the LLA algorithm as the final estimates. Statistically, we show that if the regularization parameter is appropriately chosen, the one-step LLA estimates enjoy the oracle properties with good initial estimators. Computationally, the one-step LLA estimation methods dramatically reduce the computational cost in maximizing the nonconcave penalized likelihood. We conduct some Monte Carlo simulation to assess the finite sample performance of the one-step sparse estimation methods. The results are very encouraging.	[Zou, Hui] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA; [Li, Runze] Penn State Univ, Dept Stat, University Pk, PA 16802 USA; [Li, Runze] Penn State Univ, Methodol Ctr, University Pk, PA 16802 USA	Zou, H (reprint author), Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA.	hzou@stat.umn.edu; rli@stat.psu.edu	Li, Runze/C-5444-2013	Li, Runze/0000-0002-0154-2202			Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; BICKEL PJ, 1975, J AM STAT ASSOC, V70, P428, DOI 10.2307/2285834; BLACK A, 1987, VISUAL RECONSTRUCTIO; Breiman L, 1996, ANN STAT, V24, P2350; Cai JW, 2007, ANN STAT, V35, P324, DOI 10.1214/009053606000001145; Cai JW, 2005, BIOMETRIKA, V92, P303, DOI 10.1093/biomet/92.2.303; Cai ZW, 2000, J AM STAT ASSOC, V95, P888, DOI 10.2307/2669472; Fan J., 2006, P INT C MATH, P595; Fan JQ, 2006, ANN STAT, V34, P290, DOI 10.1214/009053605000000796; Fan JQ, 1999, J ROY STAT SOC B, V61, P927, DOI 10.1111/1467-9868.00211; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2002, ANN STAT, V30, P74; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; GEYER CJ, 1994, ANN STAT, V22, P1993, DOI 10.1214/aos/1176325768; HEISER W, 1995, CONVERGENT COMPUTATI; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; LANGE K, 1995, J ROY STAT SOC B MET, V57, P425; Lehmann E. L., 1998, THEORY POINT ESTIMAT; Leng CL, 2006, STAT SINICA, V16, P1273; Li R, 2008, ANN STAT, V36, P261, DOI 10.1214/009053607000000604; MIKE W, 1984, J R STAT SOC B, V46, P431; Miller A, 2002, SUBSET SELECTION REG, V2nd; ROBINSON PM, 1988, ECONOMETRICA, V56, P531, DOI 10.2307/1911699; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Wu YN, 2000, J COMPUT GRAPH STAT, V9, P32, DOI 10.2307/1390608; Yuan M, 2005, J AM STAT ASSOC, V100, P1215, DOI 10.1198/016214505000000367	36	279	290	2	10	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	AUG	2008	36	4					1509	1533		10.1214/009053607000000802		25	Statistics & Probability	Mathematics	334TB	WOS:000258243000001		
J	Zou, H; Li, RZ				Zou, Hui; Li, Runze			Rejoinder: One-step sparse estimates in nonconcave penalized likelihood models	ANNALS OF STATISTICS			English	Editorial Material							LEAST ANGLE REGRESSION; VARIABLE SELECTION; ORACLE PROPERTIES; LASSO; CONSISTENCY		[Zou, Hui] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA; [Li, Runze] Penn State Univ, Dept Stat, University Pk, PA 16802 USA	Zou, H (reprint author), Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA.	hzou@stat.umn.edu; rli@stat.psu.edu	Li, Runze/C-5444-2013	Li, Runze/0000-0002-0154-2202			Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhang T, 2005, ANN STAT, V33, P1538, DOI 10.1214/009053605000000255; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Barbieri MM, 2004, ANN STAT, V32, P870, DOI 10.1214/009053604000000238; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Fan J., 2006, P INT C MATH, P595; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; Hastie T., 2001, ELEMENTS STAT LEARNI; Li R, 2008, ANN STAT, V36, P261, DOI 10.1214/009053607000000604; Madigan D, 2004, ANN STAT, V32, P465	16	1	1	1	2	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	AUG	2008	36	4					1561	1566		10.1214/07-AOS0316REJ		6	Statistics & Probability	Mathematics	334TB	WOS:000258243000005		
J	Zhang, CH; Huang, J				Zhang, Cun-Hui; Huang, Jian			The sparsity and bias of the lasso selection in high-dimensional linear regression	ANNALS OF STATISTICS			English	Article; Proceedings Paper	Workshop on Qualitative Assumptions and Regularization for High-Dimensional Data	2006	Oberwolfach, GERMANY			penalized regression; high-dimensional data; variable selection; bias; rate consistency; spectral analysis; random matrices	STATISTICAL ESTIMATION; VARIABLE SELECTION; DANTZIG SELECTOR; MODEL SELECTION; RANDOM MATRICES; LARGER; RISK	Meinshausen and Buhlmann [Ann. Statist. 34 (2006) 1436-1462] showed that, for neighborhood selection in Gaussian graphical models, under a neighborhood stability condition, the LASSO is consistent, even when the number of variables is of greater order than the sample size. Zhao and Yu [(2006) J. Machine Learning Research 7 2541-2567] formalized the neighborhood stability condition in the context of linear regression as a strong irrepresentable condition. That paper showed that under this condition, the LASSO selects exactly the set of nonzero regression coefficients, provided that these coefficients are bounded away from zero at a certain rate. In this paper, the regression coefficients outside an ideal model are assumed to be small, but not necessarily zero. Under a sparse Riesz condition on the correlation of design variables, we prove that the LASSO selects a model of the correct order of dimensionality, controls the bias of the selected model at a level determined by the contributions of small regression coefficients and threshold bias, and selects all coefficients of greater order than the bias of the selected model. Moreover, as a consequence of this rate consistency of the LASSO in model selection, it is proved that the sum of error squares for the mean response and the l(alpha)-loss for the regression coefficients converge at the best possible rates under the given conditions. An interesting aspect of our results is that the logarithm of the number of variables can be of the same order as the sample size for certain random dependent designs.	[Zhang, Cun-Hui] Rutgers State Univ, Dept Stat, Hill Ctr, Piscataway, NJ 08854 USA; [Huang, Jian] Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA	Zhang, CH (reprint author), Rutgers State Univ, Dept Stat, Hill Ctr, Piscataway, NJ 08854 USA.	czhang@stat.rutgers.edu; jian@stat.uiowa.edu					Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Bai ZD, 1999, STAT SINICA, V9, P611; Band Johnson W, 2001, HDB GEOMETRY BANACH, V1, P317, DOI 10.1016/S1874-5849(01)80010-3; BUNEA F, 2006, M979 FLOR STAT U DEP; DONOHO DL, 1994, PROBAB THEORY REL, V99, P277, DOI 10.1007/BF01199026; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Eaton M., 1983, MULTIVARIATE STAT VE; Efron B, 2007, ANN STAT, V35, P2358, DOI 10.1214/009053607000000433; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; GEMAN S, 1980, ANN PROBAB, V8, P252, DOI 10.1214/aop/1176994775; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; HUANG J, 2007, STAT SINICA IN PRESS; Leng CL, 2006, STAT SINICA, V16, P1273; MEINSHAUSEN N, 2006, LASSO TYPE RECOVERY; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; SILVERSTEIN JW, 1985, ANN PROBAB, V13, P1364, DOI 10.1214/aop/1176992819; VAN DE GEER S., 2007, ANN STAT, V36, P614; Wainwright M., 2006, SHARP THRESHOLDS HIG; ZHANG CH, 2006, 2006003 RUTG U DEP S	26	196	199	4	17	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	AUG	2008	36	4					1567	1594		10.1214/07-AOS520		28	Statistics & Probability	Mathematics	334TB	WOS:000258243000006		
J	Paul, D; Bair, E; Hastie, T; Tibshirani, R				Paul, Debashis; Bair, Eric; Hastie, Trevor; Tibshirani, Robert			"Preconditioning" for feature selection and regression in high-dimensional problems'	ANNALS OF STATISTICS			English	Article						model selection; prediction error; lasso	GENE-EXPRESSION; MODEL SELECTION; LASSO; SURVIVAL	We consider regression problems where the number of predictors greatly exceeds the number of observations. We propose a method for variable selection that first estimates the regression function, yielding a "preconditioned" response variable. The primary method used for this initial regression is supervised principal components. Then we apply a standard procedure such as forward stepwise selection or the LASSO to the preconditioned response variable. In a number of simulated and real data examples, this two-step procedure outperforms forward stepwise selection or the usual LASSO (applied directly to the raw outcome). We also show that under a certain Gaussian latent variable model, application of the LASSO to the preconditioned response variable is consistent as the number of predictors and observations increases. Moreover, when the observational noise is rather large, the suggested procedure can give a more accurate estimate than LASSO. We illustrate our method on some real problems, including survival analysis with microarray data.	[Paul, Debashis] Univ Calif Davis, Dept Stat, Davis, CA 95616 USA; [Bair, Eric] Stanford Univ, Dept Stat, Stanford, CA 94305 USA; [Hastie, Trevor; Tibshirani, Robert] Stanford Univ, Dept Stat & Hlth, Stanford, CA 94305 USA; [Hastie, Trevor; Tibshirani, Robert] Stanford Univ, Dept Res & Policy, Stanford, CA 94305 USA	Paul, D (reprint author), Univ Calif Davis, Dept Stat, Davis, CA 95616 USA.	debashis@wald.ucdavis.edu; ebair@stat.stanford.edu; hastie@stat.stanford.edu; tibs@stat.stanford.edu		Bair, Eric/0000-0001-8733-7869			Shen XT, 2002, J AM STAT ASSOC, V97, P210, DOI 10.1198/016214502753479356; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Efron B, 2004, ANN STAT, V32, P407; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Donoho D. L., 2004, MOST LARGE UNDERDETE; FAN J, 2005, J AM STAT ASSOC, V96, P1348; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; MEINSHAUSEN M, 2005, 129 ETH; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; PARK MY, 2006, REGULARIZATION UNPUB; PAUL D., 2005, THESIS STANFORD U; Prentice RL, 1980, STAT ANAL FAILURE TI; Zhao HJ, 2006, PLOS MED, V3, P115, DOI 10.1371/journal.pmed.0030013; ZOU H, 2005, J AM STAT ASSOC, V101, P1418	20	22	23	0	9	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	AUG	2008	36	4					1595	1618		10.1214/009053607000000578		24	Statistics & Probability	Mathematics	334TB	WOS:000258243000007		
J	Zhou, JH; He, XM				Zhou, Jianhui; He, Xuming			Dimension reduction based on constrained canonical correlation and variable filtering	ANNALS OF STATISTICS			English	Article						canonical correlation; dimension reduction; L-1-norm constraint	SLICED INVERSE REGRESSION; NONCONCAVE PENALIZED LIKELIHOOD; SELECTION; SHRINKAGE	The "curse of dimensionality" has remained a challenge for high-dimensional data analysis in statistics'. The sliced inverse regression (SIR) and canonical correlation (CANCOR) methods aim to reduce the dimensionality of data by replacing the explanatory variables with a small number of composite directions without losing much information. However, the estimated composite directions generally involve all of the variables, making their interpretation difficult. To simplify the direction estimates, Ni, Cook and Tsai [Biometrika 92 (2005) 242-247] proposed the shrinkage sliced inverse regression (SSIR) based on SIR. In this paper, we propose the constrained canonical correlation (C-3) method based on CANCOR, followed by a simple variable filtering method. As a result, each composite direction consists of a subset of the variables for interpretability as well as predictive power. The proposed method aims to identify simple structures without sacrificing the desirable properties of the unconstrained CANCOR estimates. The simulation studies demonstrate the performance advantage of the proposed C-3 method over the SSIR method. We also use the proposed method in two examples for illustration.	[Zhou, Jianhui] Univ Virginia, Dept Stat, Charlottesville, VA 22904 USA; [He, Xuming] Univ Illinois, Dept Stat, Champaign, IL 61820 USA	Zhou, JH (reprint author), Univ Virginia, Dept Stat, Charlottesville, VA 22904 USA.	jz9p@virginia.edu; x-he@uiuc.edu					Li B, 2005, ANN STAT, V33, P1580, DOI 10.1214/009053605000000192; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Chen CH, 1998, STAT SINICA, V8, P289; COOK R. D, 1994, 1994 P SECT PHYS ENG, P18; COOK RD, 1991, J AM STAT ASSOC, V86, P328, DOI 10.2307/2290564; Cook RD, 2000, J AM STAT ASSOC, V95, P781, DOI 10.2307/2669462; Cook RD, 2004, ANN STAT, V32, P1062, DOI 10.1214/009053604000000292; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fung WK, 2002, STAT SINICA, V12, P1093; LI KC, 1992, J AM STAT ASSOC, V87, P1025, DOI 10.2307/2290640; LI KC, 1989, ANN STAT, V17, P1009, DOI 10.1214/aos/1176347254; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Li K.-C., 2000, HIGH DIMENSIONAL DAT; Li LX, 2007, BIOMETRIKA, V94, P603, DOI 10.1093/biomet/asm044; MUIRHEAD RJ, 1980, BIOMETRIKA, V67, P31; Naik PA, 2001, BIOMETRIKA, V88, P821, DOI 10.1093/biomet/88.3.821; Ni LQ, 2005, BIOMETRIKA, V92, P242, DOI 10.1093/biomet/92.1.242; Shi PD, 2002, J ROY STAT SOC B, V64, P237, DOI 10.1111/1467-9868.00335; Xia YC, 2002, J ROY STAT SOC B, V64, P363, DOI 10.1111/1467-9868.03411; ZHOU J, 2008, ROBUST DIMENSION RED	21	25	25	1	1	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	AUG	2008	36	4					1649	1668		10.1214/07-AOS529		20	Statistics & Probability	Mathematics	334TB	WOS:000258243000009		
J	Sardy, S				Sardy, Sylvain			On the practice of rescaling covariates	INTERNATIONAL STATISTICAL REVIEW			English	Article						lasso; Markov random field; principal component regression; l(n) prior; ridge regression; wavelets	RIDGE-REGRESSION METHODS; WAVELET SHRINKAGE; DISTRIBUTIONS; CRITIQUE; MODELS; LASSO	Whether doing parametric or nonparametric regression with shrinkage, thresholding, penalized likelihood, Bayesian posterior estimators (e.g., ridge regression, lasso, principal component regression, waveshrink or Markov random field), it is common practice to rescale covariates by dividing by their respective standard errors rho. The stated goal of this operation is to provide unitless covariates to compare like with like, especially when penalized likelihood or prior distributions are used. We contend that this vision is too simplistic. Instead, we propose to take into account a more essential component of the structure of the regression matrix by rescaling the covariates based on the diagonal elements of the covariance matrix Sigma of the maximum-likelihood estimator. We illustrate the differences between the standard rho- and proposed Sigma-rescalings with various estimators and data sets.	Univ Geneva, Sect Math, CH-1211 Geneva, Switzerland	Sardy, S (reprint author), Univ Geneva, Sect Math, 2-4 Rue Lievre, CH-1211 Geneva, Switzerland.	Sylvain.Sardy@math.unige.ch					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; Efron B, 2004, ANN STAT, V32, P407; Kolaczyk ED, 1999, J AM STAT ASSOC, V94, P920, DOI 10.2307/2670007; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; FRIEDMAN JH, 1989, TECHNOMETRICS, V31, P3, DOI 10.2307/1270359; Besag J, 1986, J ROYAL STAT SOC B, V48, P192; Besbeas P, 2004, INT STAT REV, V72, P209; BUEHLMANN P, 2007, STAT SCI, V22, P516; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Fryzlewicz P, 2004, J COMPUT GRAPH STAT, V13, P621, DOI 10.1198/106186004X2697; Garcia AL, 2005, OBES RES, V13, P626, DOI 10.1038/oby.2005.67; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Jensen DR, 2008, INT STAT REV, V76, P89, DOI 10.1111/j.1751-5823.2007.00041.x; MARQUARDT DW, 1980, J AM STAT ASSOC, V75, P87, DOI 10.2307/2287388; MARQUARDT DW, 1975, AM STAT, V29, P3, DOI 10.2307/2683673; MEEGAN CA, 1992, NATURE, V355, P143, DOI 10.1038/355143a0; Sardy S, 2004, J COMPUT GRAPH STAT, V13, P399, DOI 10.1198/1061860043399; Sardy S, 2004, J AM STAT ASSOC, V99, P191, DOI 10.1198/016214504000000188; SMITH G, 1980, J AM STAT ASSOC, V75, P74, DOI 10.2307/2287386; Vapnik V.N., 1995, NATURE STAT LEARNING; Wahba G., 1990, SERIES APPL MATH, V59; Wold H., 1966, MULTIVARIATE ANAL, P391	29	4	4	1	1	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0306-7734	1751-5823		INT STAT REV	Int. Stat. Rev.	AUG	2008	76	2					285	297		10.1111/j.1751-5823.2008.00050.x		13	Statistics & Probability	Mathematics	331BV	WOS:000257988600009		
J	Kietzmann, TC; Lange, S; Riedmiller, M				Kietzmann, Tim C.; Lange, Sascha; Riedmiller, Martin			Incremental GRLVQ: Learning relevant features for 3D object recognition	NEUROCOMPUTING			English	Article						object recognition; relevance learning; feature selection; incremental learning vector quantization; adaptive metric	CLASSIFICATION; INTERPOLATION; RETRIEVAL; SELECTION; NETWORK; FACES	We present a new variant of generalized relevance learning vector quantization (GRLVQ) in a computer vision scenario. A version with incrementally added prototypes is used for the non-trivial case of high-dimensional object recognition. Training is based upon a generic set of standard visual features, the learned input weights are used for iterative feature pruning. Thus, prototypes and input space are altered simultaneously, leading to very sparse and task-specific representations. The effectiveness of the approach and the combination of the incremental variant together with pruning was tested on the COIL100 database, It exhibits excellent performance with regard to codebook size, feature selection and recognition accuracy. (C) 2007 Elsevier B.V. All rights reserved.	[Kietzmann, Tim C.; Lange, Sascha; Riedmiller, Martin] Univ Osnabruck, Inst Cognit Sci, Inst Comp Sci, D-49069 Osnabruck, Germany	Kietzmann, TC (reprint author), Univ Osnabruck, Inst Cognit Sci, Inst Comp Sci, D-49069 Osnabruck, Germany.	tkietzma@uos.de; salange@uos.de; martin.riedmiller@uos.de					ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; Hammer B, 2005, NEURAL PROCESS LETT, V21, P21, DOI 10.1007/s11063-004-3255-2; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; HU M, 1962, IRE T INFORM THEOR, V8, P179; Bishop C. M., 1995, NEURAL NETWORKS PATT; BOJER T, 2003, EUR S ART NEUR NETW, P433; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HAMMER B, 2002, INT C ART NEUR NETW; Hammer B, 2001, ADVANCES IN SELF-ORGANISING MAPS, P173; HAMMER B, 2005, BIOINFORMATIC USING, P25; Heidemann G., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.905265; John G., 1994, P 11 INT C MACH LEAR, P121; Jolliffe I., 1986, PRINCIPLE COMPONENT; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Kira K, 1992, P 10 NAT C ART INT, P129; KIRSTEIN S, 2005, 27 PATT REC S DAGM, P301; Koller D., 1996, INT C MACH LEARN; Kononenko I., 1994, EUR C MACH LEARN, P171; Korn F., 1996, FAST NEAREST NEIGHBO; KRZANOWSKI WJ, 1987, APPL STAT-J ROY ST C, V36, P22, DOI 10.2307/2347842; Le Cun Y., 1990, ADV NEURAL INFORMATI, V2, P598; Lehmann TM, 2005, COMPUT MED IMAG GRAP, V29, P143, DOI 10.1016/j.compmedimag.2004.09.010; McCabe G. P., 1984, TECHNOMETRICS, V26, P127; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Neal R. M., 1996, BAYESIAN LEARNING NE; Nene S. A., 1996, CUCS00696; OBDRZLEK S, 2002, BMVC, P113; Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770; PERRETT DI, 1987, TRENDS NEUROSCI, V10, P358, DOI 10.1016/0166-2236(87)90071-3; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; QI YA, 2004, ACM INT C P SERIES; Roobaert D., 1999, NEURAL NETWORKS SIGN, VIX, P77; Sato A.S., 1995, ADV NEURAL INFORMATI, V7, P423; SCHNEIDER G, 2004, 3 WORKSH SELFORGANIZ, P104; Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3; SIMS K, 1993, P 8 SCIA THROMS NORW; Strickert M, 2001, LECT NOTES COMPUT SC, V2130, P677; TARR MJ, 1995, J EXP PSYCHOL HUMAN, V21, P1494, DOI 10.1037/0096-1523.21.6.1494; Toussaint G, 2005, INT J COMPUT GEOM AP, V15, P101, DOI 10.1142/S0218195905001622; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0; WU P, 2001, P ACM MULT 01 ACM MU, P89; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	51	16	16	0	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	AUG	2008	71	13-15					2868	2879		10.1016/j.neucom.2007.08.018		12	Computer Science, Artificial Intelligence	Computer Science	347DP	WOS:000259121100047		
J	Sharon, E; Lubliner, S; Segal, E				Sharon, Eilon; Lubliner, Shai; Segal, Eran			A Feature-Based Approach to Modeling Protein-DNA Interactions	PLOS COMPUTATIONAL BIOLOGY			English	Article							FACTOR-BINDING-SITES; EMBRYONIC STEM-CELLS; HUMAN GENOME; TRANSCRIPTION FACTORS; REGULATORY MOTIFS; CHROMATIN IMMUNOPRECIPITATION; SACCHAROMYCES-CEREVISIAE; SYSTEMATIC DISCOVERY; GENE-EXPRESSION; ZINC FINGERS	Transcription factor (TF) binding to its DNA target site is a fundamental regulatory interaction. The most common model used to represent TF binding specificities is a position specific scoring matrix (PSSM), which assumes independence between binding positions. However, in many cases, this simplifying assumption does not hold. Here, we present feature motif models (FMMs), a novel probabilistic method for modeling TF-DNA interactions, based on log-linear models. Our approach uses sequence features to represent TF binding specificities, where each feature may span multiple positions. We develop the mathematical formulation of our model and devise an algorithm for learning its structural features from binding site data. We also developed a discriminative motif finder, which discovers de novo FMMs that are enriched in target sets of sequences compared to background sets. We evaluate our approach on synthetic data and on the widely used TF chromatin immunoprecipitation (ChIP) dataset of Harbison et al. We then apply our algorithm to high-throughput TF ChIP data from mouse and human, reveal sequence features that are present in the binding specificities of mouse and human TFs, and show that FMMs explain TF binding significantly better than PSSMs. Our FMM learning and motif finder software are available at http://genie.weizmann.ac.il/.	[Sharon, Eilon; Lubliner, Shai; Segal, Eran] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel; [Segal, Eran] Weizmann Inst Sci, Dept Mol Cell Biol, IL-76100 Rehovot, Israel	Sharon, E (reprint author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.	eran.segal@weizmann.ac.il			Israel Science Foundation [645/06]; ENFIN; European Commission [LSHG-CT-2005-518254]	This research was supported by the Israel Science Foundation (Grant No. 645/06), and by ENFIN, a Network of Excellence funded by the European Commission within its FP6 Programme, Contract No. LSHG-CT-2005-518254.	Berger MF, 2006, NAT BIOTECHNOL, V24, P1429, DOI 10.1038/nbt1246; Ren B, 2000, SCIENCE, V290, P2306, DOI 10.1126/science.290.5500.2306; Boyer LA, 2005, CELL, V122, P947, DOI 10.1016/j.cell.2005.08.020; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Kellis M, 2003, NATURE, V423, P241, DOI 10.1038/nature01644; Xie XH, 2005, NATURE, V434, P338, DOI 10.1038/nature03441; Elkon R, 2003, GENOME RES, V13, P773, DOI 10.1101/gr.947203; Lee TI, 2006, CELL, V125, P301, DOI 10.1016/j.cell.2006.02.043; MacIsaac KD, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-113; Johnson DS, 2007, SCIENCE, V316, P1497, DOI 10.1126/science.1141319; Odom DT, 2004, SCIENCE, V303, P1378, DOI 10.1126/science.1089769; Wei CL, 2006, CELL, V124, P207, DOI 10.1016/j.cell.2005.10.043; Reid JL, 2000, MOL CELL, V6, P1297, DOI 10.1016/S1097-2765(00)00128-3; Yedidia JS, 2001, ADV NEUR IN, V13, P689; Zeller KI, 2006, P NATL ACAD SCI USA, V103, P17834, DOI 10.1073/pnas.0604129103; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Sandelin A, 2004, NUCLEIC ACIDS RES, V32, pD91, DOI 10.1093/nar/gkh012; Loh YH, 2006, NAT GENET, V38, P431, DOI 10.1038/ng1760; Bulyk ML, 2006, CURR OPIN BIOTECH, V17, P422, DOI 10.1016/j.copbio.2006.06.015; Cliften P, 2003, SCIENCE, V301, P71, DOI 10.1126/science.1084337; Robertson G, 2007, NAT METHODS, V4, P651, DOI 10.1038/NMETH1068; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Tavazoie S, 1999, NAT GENET, V22, P281; Harbison CT, 2004, NATURE, V431, P99, DOI 10.1038/nature02800; ASHBURNER M, 2000, GENE ONTOLOGY CONSOR, V25, P25, DOI DOI 10.1038/75556; Barash Y, 2002, J COMPUT BIOL, V9, P169, DOI 10.1089/10665270252935403; Barash Y., 2003, P 7 ANN INT C COMP M, P28, DOI 10.1145/640075.640079; Ben-Gal I, 2005, BIOINFORMATICS, V21, P2657, DOI 10.1093/bioinformatics/bti410; Bhinge AA, 2007, GENOME RES, V17, P910, DOI 10.1101/gr.5574907; Birney E, 2007, NATURE, V447, P799, DOI 10.1038/nature05874; Brazma A, 1998, GENOME RES, V8, P1202; Bulyk ML, 1999, NAT BIOTECHNOL, V17, P573; Bulyk ML, 2001, P NATL ACAD SCI USA, V98, P7158, DOI 10.1073/pnas.111163698; Bussemaker HJ, 2001, NAT GENET, V27, P167, DOI 10.1038/84792; Eden E, 2007, PLOS COMPUT BIOL, V3, P508, DOI 10.1371/journal.pcbi.0030039; Ellrott K, 2002, BIOINFORMATICS, V18, pS100; Elnitski L, 2006, GENOME RES, V16, P1455, DOI 10.1101/gr.4140006; Gold L, 1997, P NATL ACAD SCI USA, V94, P59, DOI 10.1073/pnas.94.1.59; Grandori C, 1997, TRENDS BIOCHEM SCI, V22, P177, DOI 10.1016/S0968-0004(97)01025-6; Heinemeyer T, 1999, NUCLEIC ACIDS RES, V27, P318, DOI 10.1093/nar/27.1.318; Hong PY, 2005, BIOINFORMATICS, V21, P2636, DOI 10.1093/bioinformatics/bti402; Horak CE, 2002, P NATL ACAD SCI USA, V99, P2924, DOI 10.1073/pnas.052706999; Iyer VR, 2001, NATURE, V409, P533, DOI 10.1038/35054095; Kim TH, 2007, CELL, V128, P1231, DOI 10.1016/j.cell.2006.12.048; Lee S.-I., 2007, ADV NEURAL INFORM PR, V19, P817; Liu X, 2001, Pac Symp Biocomput, P127; Look DC, 1995, J BIOL CHEM, V270, P30264; Maerkl SJ, 2007, SCIENCE, V315, P233, DOI 10.1126/science.1131007; Minka TP, 2001, UNCERTAINTY ARTIFICI, P362; Narlikar L, 2007, PLOS COMPUT BIOL, V3, P2199, DOI 10.1371/journal.pcbi.0030215; Ng A. Y., 2004, P 21 INT C MACH LEAR; OLIPHANT AR, 1989, MOL CELL BIOL, V9, P2944; PEARL J., 1988, PROBABILISTIC REASON; Perkins S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753698; Pietra S. D., 1997, IEEE T PATTERN ANAL, V19, P380; Pilpel Y, 2001, NAT GENET, V29, P153, DOI 10.1038/ng724; Pudimat R, 2005, BIOINFORMATICS, V21, P3082, DOI 10.1093/bioinformatics/bti477; Qi Y, 2006, NAT BIOTECHNOL, V24, P963, DOI 10.1038/nbt1233; Ren B, 2002, GENE DEV, V16, P245, DOI 10.1101/gad.949802; Renda M, 2007, J BIOL CHEM, V282, P33336, DOI 10.1074/jbc.M706213200; Roth FP, 1998, NAT BIOTECHNOL, V16, P939, DOI 10.1038/nbt1098-939; Segal E., 2003, BIOINFORMATICS S1, V19, P273; Simon I, 2001, CELL, V106, P697, DOI 10.1016/S0092-8674(01)00494-9; Sinha S, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P344; SOLOMON DLC, 1993, NUCLEIC ACIDS RES, V21, P5372, DOI 10.1093/nar/21.23.5372; Tomovic A, 2007, BIOINFORMATICS, V23, P933, DOI 10.1093/bioinformatics/btm055; Weinmann AS, 2002, GENE DEV, V16, P235, DOI 10.1101/gad.943102; Xie XH, 2007, P NATL ACAD SCI USA, V104, P7145, DOI 10.1073/pnas.0701811104; Xing Eric P, 2004, J Bioinform Comput Biol, V2, P127, DOI 10.1142/S0219720004000508; Zhao XY, 2005, J COMPUT BIOL, V12, P894, DOI 10.1089/cmb.2005.12.894; Zhou Q, 2004, BIOINFORMATICS, V20, P909, DOI 10.1093/bioinformatics/bth006	72	36	37	1	3	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-734X			PLOS COMPUT BIOL	PLoS Comput. Biol.	AUG	2008	4	8							e1000154	10.1371/journal.pcbi.1000154		17	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	360EX	WOS:000260041300019	18725950	
J	Pers, TH; Martin, FP; Verdich, C; Holst, C; Johansen, JV; Astrup, A; Polak, J; Martinez, JA; Rezzi, S; Blaak, EE; Saris, WHM; Kochhar, S; Macdonald, IA; Sorensen, TIA; Ramadan, Z				Pers, T. H.; Martin, F. P.; Verdich, C.; Holst, C.; Johansen, J. V.; Astrup, A.; Polak, J.; Martinez, J. A.; Rezzi, S.; Blaak, E. E.; Saris, W. H. M.; Kochhar, S.; Macdonald, I. A.; Sorensen, T. I. A.; Ramadan, Z.			Prediction of fat oxidation capacity using H-1-NMR and LC-MS lipid metabolomic data combined with phenotypic data	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						fat oxidation capacity; genetic algorithm; metabolomics; obesity; orthogonal signal correction; partial least squares	MAGNETIC-RESONANCE-SPECTROSCOPY; FORMERLY OBESE WOMEN; MASS-SPECTROMETRY; CROSS-VALIDATION; SYSTEMS BIOLOGY; H-1; METABONOMICS; SAMPLES; HUMANS; URINE	There is evidence from clinical trials that a low capacity to oxidize dietary fats may predispose human individuals to weight gain, obesity, and weight regain following weight loss. These observations have led to a need to identify plasma markers of fat oxidation capacity in order to avoid time consuming direct measurements by indirect calorimetry. The aim of this study was to investigate whether prediction of fat oxidation capacity in an obese population is possible, using H-1-NMR and LC-MS-based metabolic profiling of blood plasma samples collected before and after a high fat test meal from 100 obese women, who represented the extremes of fat oxidizing capacity. Subject characteristics (baseline anthropometrics, body composition and dietary records) and clinical data (blood values and derived measures for insulin resistance) were recorded into a phenotypic dataset. Filtering by orthogonal signal correction, variable reduction by spectra segmentation, Mann-Whitney U tests and genetic algorithms were applied to spectral data together with partial least squares regression models for prediction. Our findings suggested that only a small fraction of subject variation contained in metabolic profiles is related to fat oxidation capacity and variable reduction methods improved fat oxidation capacity predictability. The LC-MS dataset led to higher specificity (fasting: 86%; postprandial: 73%) and sensitivity (fasting: 75%; postprandial: 75%) than classification using the H-1-NMR dataset (specificity: fasting: 50%; postprandial: 60%; sensitivity: fasting: 67%; postprandial: 62%). Inclusion of phenotypic variables increased specificity and sensitivity values in both fasting and postprandial time points. However, the moderate specificity and sensitivity values indicated that fat oxidation capacity may only be reflected in subtle differences in the metabolic profiles analyzed. In future studies, metabolomics data may be supplemented with gene variation and gene expression data to caption the properties of fat oxidation capacity more precisely. (C) 2008 Elsevier B.V. All rights reserved.	[Pers, T. H.; Verdich, C.; Holst, C.; Sorensen, T. I. A.] Univ Copenhagen Hosp, Inst Prevent Med, DK-2100 Copenhagen, Denmark; [Pers, T. H.; Johansen, J. V.; Rezzi, S.] Univ Copenhagen, Dept Mol Biol, Bioinformat Ctr, DK-2200 Copenhagen, Denmark; [Martin, F. P.; Rezzi, S.; Kochhar, S.; Ramadan, Z.] Nestle Res Ctr, BioAnalyt Sci Dept, CH-1000 Lausanne 26, Switzerland; [Astrup, A.] Univ Copenhagen, Fac Life Sci, Dept Human Nutr, DK-1168 Copenhagen, Denmark; [Polak, J.] Charles Univ Prague, Fac Med 3, Dept Sports Med, Prague, Czech Republic; [Martinez, J. A.] Univ Navarra, Dept Physiol & Nutr, E-31080 Pamplona, Spain; [Blaak, E. E.; Saris, W. H. M.] Maastricht Univ, Nutr & Toxicol Res Inst NUTRIM, Dept Human Biol, Maastricht, Netherlands; [Macdonald, I. A.] Univ Nottingham, Sch Med, Queens Med Ctr, Sch Biomed Sci, Nottingham NG7 2RD, England	Ramadan, Z (reprint author), Nestle Purina PetCare Res, 1 Checkerboard Sq, St Louis, MO 63164 USA.	ziad.ramadan@rdmo.nestle.com	Polak, Jan/J-3404-2014; 	Martin, Francois-Pierre/0000-0003-1373-5367; Martinez Hernandez, J Alfredo/0000-0001-5218-6941			Nicholson JK, 2003, NAT REV DRUG DISCOV, V2, P668, DOI 10.1038/nrd1157; Schneider T, 2001, J CLIMATE, V14, P853, DOI 10.1175/1520-0442(2001)014<0853:AOICDE>2.0.CO;2; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Nicholson JK, 2005, NAT REV MICROBIOL, V3, P431, DOI 10.1038/nrmicro1152; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Fiehn O, 2000, NAT BIOTECHNOL, V18, P1157, DOI 10.1038/81137; Haslam DW, 2005, LANCET, V366, P1197, DOI 10.1016/S0140-6736(05)67483-1; MEIBOOM S, 1958, REV SCI INSTRUM, V29, P688, DOI 10.1063/1.1716296; Nicholson JK, 1999, XENOBIOTICA, V29, P1181; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; HORTON TJ, 1995, AM J CLIN NUTR, V62, P19; Dumas ME, 2006, P NATL ACAD SCI USA, V103, P12511, DOI 10.1073/pnas.0601056103; SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709; NICHOLSON JK, 1989, PROG NUCL MAG RES SP, V21, P449, DOI 10.1016/0079-6565(89)80008-1; Bro R, 1996, J CHEMOMETR, V10, P47, DOI 10.1002/(SICI)1099-128X(199601)10:1<47::AID-CEM400>3.3.CO;2-3; Turnbaugh PJ, 2006, NATURE, V444, P1027, DOI 10.1038/nature05414; Rezzi S, 2007, J PROTEOME RES, V6, P513, DOI 10.1021/pr060522z; ASTRUP A, 1994, AM J PHYSIOL, V266, pE592; Bijlsma S, 2006, ANAL CHEM, V78, P567, DOI 10.1021/ac051495j; Blaak EE, 2006, J CLIN ENDOCR METAB, V91, P1462, DOI 10.1210/jc.2005-1598; Breiman L., 2001, MACH LEARN, V45; Dear GJ, 1998, RAPID COMMUN MASS SP, V12, P2023, DOI 10.1002/(SICI)1097-0231(19981230)12:24<2023::AID-RCM431>3.0.CO;2-6; GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288; Griffin JL, 2006, PHARMACOGENOMICS, V7, P1095, DOI 10.2217/14622416.7.7.1095; HOLLAND JH, 1992, ADAPTATION NAUTURAL; Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Kanduc K.R, 2003, CHEMOM INTELL LAB SY, V65, P221; Katajamaa M, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-179; Kemsley EK, 2007, BRIT J NUTR, V98, P1, DOI 10.1017/S0007114507685365; Krogh A, 2008, NAT BIOTECHNOL, V26, P195, DOI 10.1038/nbt1386; Lafaye A, 2003, RAPID COMMUN MASS SP, V17, P2541, DOI 10.1002/rcm.1243; Lenz EM, 2003, J PHARMACEUT BIOMED, V33, P1103, DOI 10.1016/S0731-7085(03)00410-2; Lenz EM, 2004, J PHARMACEUT BIOMED, V36, P841, DOI 10.1016/j.jpba.2004.08.002; Lenz EM, 2004, ANALYST, V129, P535, DOI 10.1039/b400159c; Marchesi JR, 2007, J PROTEOME RES, V6, P546, DOI 10.1021/pr060470d; Martens H., 1989, MULTIVARIATE CALIBRA; Martin FPJ, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100153; Martin FPJ, 2006, J PROTEOME RES, V5, P2185, DOI 10.1021/pr060157b; Massart DL, 1998, HDB CHEMOMETRICS Q A; McGovern AC, 2002, BIOTECHNOL BIOENG, V78, P527; Moka D, 1998, J PHARMACEUT BIOMED, V17, P125, DOI 10.1016/S0731-7085(97)00176-3; NICHOLSON JK, 1995, ANAL CHEM, V67, P793, DOI 10.1021/ac00101a004; Petersen M, 2006, INT J OBESITY, V30, P552, DOI 10.1038/sj.ijo.0803186; Qu Hai-bin, 2005, J Zhejiang Univ Sci B, V6, P838, DOI 10.1631/jzus.2005.B0838; RABEN A, 1994, AM J PHYSIOL-ENDOC M, V267, pE549; Ranneries C, 1998, AM J PHYSIOL-ENDOC M, V274, pE155; Solanky KS, 2005, J NUTR BIOCHEM, V16, P236, DOI 10.1016/j.jnutbio.2004.12.005; THOMAS CD, 1992, AM J CLIN NUTR, V55, P934; Vandeginste BMG, 1998, HDB CHEMOMETRICS Q B; Wang YL, 2005, J AGR FOOD CHEM, V53, P191, DOI 10.1021/jf0403282; ZURLO F, 1990, AM J PHYSIOL, V259, pE650	51	2	2	2	14	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439	1873-3239		CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	AUG 15	2008	93	1					34	42		10.1016/j.chemolab.2008.03.008		9	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	328VD	WOS:000257825400005		
J	Wang, HS; Leng, CL				Wang, Hansheng; Leng, Chenlei			A note on adaptive group lasso	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							REGRESSION SHRINKAGE; VARIABLE SELECTION; ORACLE PROPERTIES; MODEL SELECTION	Group lasso is a natural extension of lasso and selects variables in a grouped manner. However, group lasso suffers from estimation inefficiency and selection inconsistency, To remedy these problems, we propose the adaptive group lasso method. We show theoretically that the new method is able to identify the true model consistently, and the resulting estimator can be as efficient as oracle. Numerical studies confirmed our theoretical findings. (c) 2008 Elsevier B.V. All rights reserved.	[Wang, Hansheng] Peking Univ, Guanghua Sch Management, Beijing 100871, Peoples R China; Natl Univ Singapore, Singapore 117548, Singapore	Wang, HS (reprint author), Peking Univ, Guanghua Sch Management, Beijing 100871, Peoples R China.	hansheng@gsm.pku.edu.cn					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Wang HS, 2007, J BUS ECON STAT, V25, P347, DOI 10.1198/073500106000000251; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Wang H, 2007, BIOMETRIKA, V94, P553, DOI 10.1093/biomet/asm053; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Leng CL, 2006, STAT SINICA, V16, P1273; Wang HS, 2007, J ROY STAT SOC B, V69, P63; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037	13	44	46	6	19	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	AUG 15	2008	52	12					5277	5286		10.1016/j.csda.2008.05.006		10	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	346NR	WOS:000259075900020		
J	Zou, H; Yuan, M				Zou, Hui; Yuan, Ming			Regularized simultaneous model selection in multiple quantiles regression	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							SMOOTHING SPLINES; VARIABLE SELECTION	Simultaneously estimating multiple conditional quantiles is often regarded as a more appropriate regression tool than the usual conditional mean regression for exploring the stochastic relationship between the response and covariates. When multiple quantile regressions are considered, it is of great importance to share strength among them. In this paper, we propose a novel regularization method that explores the similarity among multiple quantile regressions by selecting a common subset of covariates to model multiple conditional quantiles simultaneously. The penalty we employ is a matrix norm that encourages sparsity in a column-wise fashion. We demonstrate the effectiveness of the proposed method using both simulations and an application of gene expression data analysis. (c) 2008 Elsevier B.V. All rights reserved.	[Zou, Hui] Univ Minnesota, Minneapolis, MN 55455 USA; [Yuan, Ming] Georgia Inst Technol, Atlanta, GA 30332 USA	Zou, H (reprint author), Univ Minnesota, Minneapolis, MN 55455 USA.	hzou@stat.umn.edu; myuan@isye.gatech.edu			NSF [DMS-0706733]	We thank Professor Mark Segal for kindly providing us the cardiomypathy data. The authors sincerely thank an AE and two referees for their helpful comments that substantially improved an earlier version of this paper. This work is supported by NSF grant DMS-0706733.	Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; He XM, 1998, J ROY STAT SOC B, V60, P537, DOI 10.1111/1467-9868.00138; Li YJ, 2008, J COMPUT GRAPH STAT, V17, P163, DOI 10.1198/106186008X289155; Koenker R, 2001, J AM STAT ASSOC, V96, P458, DOI 10.1198/016214501753168172; Redfern CH, 2000, P NATL ACAD SCI USA, V97, P4826, DOI 10.1073/pnas.97.9.4826; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Turlach BA, 2005, TECHNOMETRICS, V47, P349, DOI 10.1198/004017005000000139; Breiman L, 1997, J ROY STAT SOC B MET, V59, P3, DOI 10.1111/1467-9868.00054; FAN J, 2008, J ROYAL S B IN PRESS; Hastie T., 2001, ELEMENTS STAT LEARNI; Koenker R, 2001, J ECON PERSPECT, V15, P143, DOI 10.1257/jep.15.4.143; Koenker R., 2005, ECONOMETRIC SOC MONO; KOENKER R, 1994, BIOMETRIKA, V81, P673; Koenker R, 2004, J MULTIVARIATE ANAL, V91, P74, DOI 10.1016/j.jmva.2004.05.006; Li YJ, 2007, J AM STAT ASSOC, V102, P255, DOI 10.1198/016214506000000979; Meyer M, 2000, ANN STAT, V28, P1083; Yuan M, 2006, COMPUT STAT DATA AN, V50, P813, DOI 10.1016/j.csda.2004.10.008; Zhang HH, 2008, ELECTRON J STAT, V2, P149, DOI 10.1214/08-EJS122; Zou H, 2008, STAT SINICA, V18, P379	22	22	22	2	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	AUG 15	2008	52	12					5296	5304		10.1016/j.csda.2008.05.013		9	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	346NR	WOS:000259075900022		
J	Binder, H; Sauerbrei, W				Binder, Harald; Sauerbrei, Willi			Increasing the usefulness of additive spline models by knot removal	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							ADAPTIVE REGRESSION SPLINES; POLYNOMIAL SPLINES; SELECTION; PENALTIES; EXPOSURE; CURVES; LASSO	Modern techniques for fitting generalized additive models mostly rely on basis expansions of covariates using a large number of basis functions and penalized estimation of parameters. For example, a mixed model approach is used to fit: a model for children's lung function that allows for non-linear influence of several covariates available in a substantial data set. While the resulting model is expected to have good prediction performance, its handling beyond simple visual presentation is problematic. It is shown how the number basis functions of the underlying B-spline representation can be reduced by knot removal techniques without refitting, while preserving the shape of the fitted functions. The condition for exact knot removal is extended towards approximate knot removal by incorporating the covariance matrix of the initial parameter estimates, resulting in considerable simplification of the model. Covariance matrices for the transformed parameter estimates are provided. It is demonstrated that enforcing the knot removal condition during estimation leads to the difference penalties employed in the P-spline approach for estimation of B-spline coefficients, and therefore provides a further justification for this type of penalty. A final transform to a truncated power basis provides a simple equation for the model. This increases transportability, while retaining properties of the initial fit such as good prediction performance. (c) 2008 Elsevier B.V. All rights reserved.	[Binder, Harald; Sauerbrei, Willi] Univ Freiburg Klinikum, Inst Med Biometrie & Med Informat, D-79104 Freiberg, Germany	Binder, H (reprint author), Univ Freiburg Klinikum, Inst Med Biometrie & Med Informat, Stefan Meier Str 26, D-79104 Freiberg, Germany.	binderh@imbi.uni-freiburg.de	Binder, Harald/C-7413-2009	Binder, Harald/0000-0002-5666-8662	Deutsche Forschungsgemeinschaft [SA 580/4-1]	We gratefully acknowledge support from Deutsche Forschungsgemeinschaft (SA 580/4-1). We also thank Gabi Ihorst for providing the ozone study data.	ROYSTON P, 1994, APPL STAT-J ROY ST C, V43, P429, DOI 10.2307/2986270; Molinari N, 2001, STAT MED, V20, P237, DOI 10.1002/1097-0258(20010130)20:2<237::AID-SIM654>3.0.CO;2-I; Ruppert D, 2002, J COMPUT GRAPH STAT, V11, P735, DOI 10.1198/106186002853; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wood SN, 2004, J AM STAT ASSOC, V99, P673, DOI 10.1198/016214504000000980; Sauerbrei W, 1999, J ROY STAT SOC A STA, V162, P71, DOI 10.1111/1467-985X.00122; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; FRIEDMAN JH, 1989, TECHNOMETRICS, V31, P3, DOI 10.2307/1270359; Binder H, 2008, STAT COMPUT, V18, P87, DOI 10.1007/s11222-007-9040-0; BOEHM W, 1980, COMPUT AIDED DESIGN, V12, P199, DOI 10.1016/0010-4485(80)90154-2; BREIMAN L, 1993, COMPUT STAT DATA AN, V15, P13, DOI 10.1016/0167-9473(93)90217-H; de Boor C., 2001, PRACTICAL GUIDE SPLI; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; EILERS PHC, 2004, SPLINES KNOTS UNPUB; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gervini D, 2006, J ROY STAT SOC B, V68, P671, DOI 10.1111/j.1467-9868.2006.00561.x; Govindarajulu US, 2007, STAT MED, V26, P3735, DOI 10.1002/sim.2848; Green P, 1994, NONPARAMETRIC REGRES; Hastie TJ, 1990, GEN ADDITIVE MODELS; Ihorst G, 2004, EUR RESPIR J, V23, P292, DOI 10.1183/09031936.04.00021704; Kooperberg C, 1997, J AM STAT ASSOC, V92, P117, DOI 10.2307/2291455; Mao WX, 2003, J ROY STAT SOC B, V65, P901, DOI 10.1046/j.1369-7412.2003.00422.x; Marx BD, 1998, COMPUT STAT DATA AN, V28, P193, DOI 10.1016/S0167-9473(98)00033-4; Miyata S, 2003, J COMPUT GRAPH STAT, V12, P197, DOI 10.1198/1061860031284; Molinari N, 2004, COMPUT STAT DATA AN, V45, P159, DOI 10.1016/S0167-9473(02)00343-2; Osborne MR, 1998, COMP SCI STAT, V30, P44; Ruppert D., 2003, SEMIPARAMETRIC REGRE; Speed TP, 1991, STAT SCI, V6, P42, DOI 10.1214/ss/1177011930; Stone CJ, 1997, ANN STAT, V25, P1371; TILLER W, 1992, COMPUT AIDED DESIGN, V24, P445, DOI 10.1016/0010-4485(92)90012-Y; Welham SJ, 2007, AUST NZ J STAT, V49, P1, DOI 10.1111/j.1467-842X.2006.00454.x; Wood SN, 2006, GEN ADDITIVE MODELS; WYATT JC, 1995, BRIT MED J, V311, P1539; Zhou SG, 2001, J AM STAT ASSOC, V96, P247, DOI 10.1198/016214501750332820	34	1	1	2	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	AUG 15	2008	52	12					5305	5318		10.1016/j.csda.2008.05.009		14	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	346NR	WOS:000259075900023		
J	Haufe, S; Nikulin, VV; Ziehe, A; Muller, KR; Nolte, G				Haufe, Stefan; Nikulin, Vadim V.; Ziehe, Andreas; Mueller, Klaus-Robert; Nolte, Guido			Combining sparsity and rotational invariance in EEG/MEG source reconstruction	NEUROIMAGE			English	Article						EEG/MEG; inverse problem; source localization; second-order cone programming; l(1)-norm regularization; sparsity; vector fields; rotational invariance	ELECTROMAGNETIC TOMOGRAPHY; SIGNAL RECONSTRUCTION; SOURCE LOCALIZATION; NERVE-STIMULATION; MAGNETIC-FIELDS; INVERSE PROBLEM; MEG; BRAIN; EEG; REGRESSION	We introduce Focal Vector Field Reconstruction (FVR), a novel technique for the inverse imaging of vector fields. The method was designed to simultaneously achieve two goals: a) invariance with respect to the orientation of the coordinate system, and b) a preference for sparsity of the solutions and their spatial derivatives. This was achieved by defining the regulating penalty function, which renders the solutions unique, as a global l(1)-norm of local l(2)-norms. We show that the method can be successfully used for solving life EEG inverse problem. In the joint localization of 2-3 simulated dipoles, FVR always reliably recovers the true sources. The competing methods have limitations in distinguishing close sources because their estimates are either too smooth (LORETA, Minimum l(1)-norm) or too scattered (Minimum l(2)-norm). In both noiseless and noisy simulations, FVR has the smallest localization error according to the Earth Mover's Distance (EMD), which is introduced here as a meaningful measure to compare arbitrary source distributions. We also apply the method to the simultaneous localization of left and right somatosensory N20 generators front real EEG recordings. Compared to its peers FVR was the only method that delivered correct location of the source in the somatosensory area of each hemisphere in accordance with neurophysiological prior knowledge. (C) 2008 Elsevier Inc. All rights reserved.	[Haufe, Stefan; Ziehe, Andreas; Mueller, Klaus-Robert] TU Berlin, Machine Learning Grp, Dept Comp Sci, D-10587 Berlin, Germany; [Haufe, Stefan; Ziehe, Andreas; Mueller, Klaus-Robert; Nolte, Guido] Fraunhofer Inst FIRST, Intelligent Data Anal Grp, D-12489 Berlin, Germany; [Nikulin, Vadim V.] Charite Univ Med Berlin, Neurophys Grp, Dept Neurol, D-12203 Berlin, Germany; [Nikulin, Vadim V.; Mueller, Klaus-Robert] Bernstein Ctr Computat Neurosci, Berlin, Germany	Haufe, S (reprint author), TU Berlin, Machine Learning Grp, Dept Comp Sci, Franklinstr 28-29, D-10587 Berlin, Germany.	haufe@cs.tu-berlin.de	Muller, Klaus/C-3196-2013; Nikulin, Vadim/A-6050-2014	Nikulin, Vadim/0000-0001-6082-3859	Bundesministerium fur Bildung und Forschung [16SV2234, 01GQ0415]; Deutsche Forschungsgemeinschaft [MU 987/3-1]; IST Programme of the European Community [IST-2002-506778]	This Work was supported in part by the Bundesministerium fur Bildung und Forschung (16SV2234, 01GQ0415), the Deutsche Forschungsgemeinschaft (MU 987/3-1) and the IST Programme of the European Community, under the PASCAL Network of Excellence (IST-2002-506778). We thank Friederike Hohlefeld and Monika Weber for help in preparing the experiment, and Ryota Tomioka for fruitful discussions.	Malioutov D, 2005, IEEE T SIGNAL PROCES, V53, P3010, DOI 10.1109/TSP.2005.850882; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; PASCUALMARQUI RD, 1994, INT J PSYCHOPHYSIOL, V18, P49, DOI 10.1016/0167-8760(84)90014-X; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Huang MX, 2006, NEUROIMAGE, V31, P1025, DOI 10.1016/j.neuroimage.2006.01.029; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Baillet S, 2001, IEEE SIGNAL PROC MAG, V18, P14, DOI 10.1109/79.962275; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172; Baillet S, 1997, IEEE T BIO-MED ENG, V44, P374, DOI 10.1109/10.568913; Bennett KP, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; DALE AM, 1993, J COGNITIVE NEUROSCI, V5, P162, DOI 10.1162/jocn.1993.5.2.162; GORODNITSKY IF, 1995, ELECTROEN CLIN NEURO, V95, P231, DOI 10.1016/0013-4694(95)00107-A; GRAEPEL T, 1999, P 9 INT C ART NEUR N, P304; Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032; Huttunen J, 2006, NEUROIMAGE, V32, P1024, DOI 10.1016/j.neuroimage.2006.04.196; JEFFS B, 1987, IEEE T BIO-MED ENG, V34, P713, DOI 10.1109/TBME.1987.325996; Kincses WE, 2003, HUM BRAIN MAPP, V18, P100, DOI 10.1002/hbm.10079; Kohler T., 1996, 18 ANN INT C IEEE EN, P812; Komssi S, 2004, CLIN NEUROPHYSIOL, V115, P534, DOI 10.1016/j.clinph.2003.10.034; MATSUURA K, 1995, IEEE T BIO-MED ENG, V42, P608, DOI 10.1109/10.387200; Mauguiere F, 1997, EVOKED POTENTIAL, V104, P281, DOI 10.1016/S0013-4694(97)00006-0; Mosher JC, 1999, IEEE T SIGNAL PROCES, V47, P332, DOI 10.1109/78.740118; Nakata K, 2006, PARALLEL COMPUT, V32, P24, DOI 10.1016/j.parco.2005.07.002; Nolte G, 2005, PHYS MED BIOL, V50, P3807, DOI 10.1088/0031-9155/50/16/010; Nunez P. L., 2005, ELECT FIELDS BRAIN N; Polonsky A, 2004, LECT NOTES COMPUT SC, V3195, P1001; SCHERG M, 1986, ELECTROEN CLIN NEURO, V65, P344, DOI 10.1016/0168-5597(86)90014-6; SCHMIDT RO, 1986, IEEE T ANTENN PROPAG, V34, P276, DOI 10.1109/TAP.1986.1143830; Uutela K, 1999, NEUROIMAGE, V10, P173, DOI 10.1006/nimg.1999.0454; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Veen B. V., 1988, IEEE ASSP MAG    APR, V5, P4	39	35	35	0	4	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119			NEUROIMAGE	Neuroimage	AUG 15	2008	42	2					726	738		10.1016/j.neuroimage.2008.04.246		13	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	341DU	WOS:000258695200028	18583157	
J	Liang, YL; Kelemen, A				Liang, Yulan; Kelemen, Arpad			Bayesian models and meta analysis for multiple tissue gene expression data following corticosteroid administration	BMC BIOINFORMATICS			English	Article							FALSE DISCOVERY RATE; MIXTURE MODEL; MICROARRAY DATA; METAANALYSIS; FRAMEWORK; SELECTION; PROFILES; PROMISE; CANCER	Background: This paper addresses key biological problems and statistical issues in the analysis of large gene expression data sets that describe systemic temporal response cascades to therapeutic doses in multiple tissues such as liver, skeletal muscle, and kidney from the same animals. Affymetrix time course gene expression data U34A are obtained from three different tissues including kidney, liver and muscle. Our goal is not only to find the concordance of gene in different tissues, identify the common differentially expressed genes over time and also examine the reproducibility of the findings by integrating the results through meta analysis from multiple tissues in order to gain a significant increase in the power of detecting differentially expressed genes over time and to find the differential differences of three tissues responding to the drug. Results and conclusion: Bayesian categorical model for estimating the proportion of the 'call' are used for pre-screening genes. Hierarchical Bayesian Mixture Model is further developed for the identifications of differentially expressed genes across time and dynamic clusters. Deviance information criterion is applied to determine the number of components for model comparisons and selections. Bayesian mixture model produces the gene-specific posterior probability of differential/non-differential expression and the 95% credible interval, which is the basis for our further Bayesian meta-inference. Meta-analysis is performed in order to identify commonly expressed genes from multiple tissues that may serve as ideal targets for novel treatment strategies and to integrate the results across separate studies. We have found the common expressed genes in the three tissues. However, the up/down/no regulations of these common genes are different at different time points. Moreover, the most differentially expressed genes were found in the liver, then in kidney, and then in muscle.	[Liang, Yulan] Univ Maryland, Dept Org Syst & Adult Hlth, Baltimore, MD 21201 USA; [Kelemen, Arpad] SUNY Buffalo, Jacobs Neurol Inst, Buffalo Neuroimaging Anal Ctr, Dept Neurol, Buffalo, NY 14203 USA	Liang, YL (reprint author), Univ Maryland, Dept Org Syst & Adult Hlth, 655 W Lombard St, Baltimore, MD 21201 USA.	ylian001@umaryland.edu; akelemen@buffalo.edu			National Institute of General Medical Sciences [NIH: 1P20GM067650-01A1]; NSF [DMS-0604639]	The authors would like to thank Dr. Richard Almon for providing the data. This work was supported in part by the National Institute of General Medical Sciences Grant (NIH: 1P20GM067650-01A1) and by NSF grant DMS-0604639.	Agresti A., 2005, STAT METHODS APPL, V14, P297, DOI DOI 10.1007/S10260-005-0121-Y; Agresti A., 2002, CATEGORICAL DATA ANA; Almon RR, 2003, PHARMACOGENOMICS, V4, P791, DOI 10.1517/phgs.4.6.791.22816; Egger M, 1997, BRIT MED J, V315, P1371; Medvedovic M, 2002, BIOINFORMATICS, V18, P1194, DOI 10.1093/bioinformatics/18.9.1194; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Rhodes DR, 2004, P NATL ACAD SCI USA, V101, P9309, DOI 10.1073/pnas.0401994101; Lunn DJ, 2000, STAT COMPUT, V10, P325, DOI 10.1023/A:1008929526011; Do KA, 2005, J ROY STAT SOC C-APP, V54, P627, DOI 10.1111/j.1467-9876.2005.05593.x; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Efron B, 2001, J AM STAT ASSOC, V96, P1151, DOI 10.1198/016214501753382129; Wang L, 2006, STAT SINICA, V16, P589; Bailar JC, 1997, NEW ENGL J MED, V337, P559, DOI 10.1056/NEJM199708213370810; Broet P, 2004, BIOINFORMATICS, V20, P2562, DOI 10.1093/bioinformatics/bth285; Congdon P., 2002, BAYESIAN STAT MODELI; Conlon EM, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-80; DUMOUCHEL WH, 1983, J AM STAT ASSOC, V78, P293, DOI 10.2307/2288631; Ghosh Debashis, 2003, Functional & Integrative Genomics, V3, P180; GHOSH D, 2004, BIOINFORMATICS; Jin JY, 2003, J PHARMACOL EXP THER, V307, P93, DOI 10.1124/jpet.103.053256; Kauermann G, 2004, BIOMETRICS, V60, P376, DOI 10.1111/j.0006-341X.2004.00182.x; Kim S, 2006, BIOMETRIKA, V93, P877, DOI 10.1093/biomet/93.4.877; Liang Yulan, 2005, Int J Bioinform Res Appl, V1, P399, DOI 10.1504/IJBRA.2005.008443; Liang Yulan, 2006, Functional & Integrative Genomics, V6, P1, DOI 10.1007/s10142-005-0006-z; LIANG Y, 2005, BIOINFORMATICS, V20, P3009; LIANG Y, 2007, BIOMETR J, V49, P1; LIANG Y, 2004, STAT APPL GENET MOL, V3; Liang Y., 2008, STAT SURVEYS, V2, P43; Liao JG, 2004, BIOINFORMATICS, V20, P2694, DOI 10.1093/bioinformatics/bth310; Luan Y, 2004, BIOINFORMATICS, V20, P332, DOI 10.1093/bioinformatics/btg413; Luan YH, 2003, BIOINFORMATICS, V19, P474, DOI 10.1093/bioinformatics/btg014; Ma P, 2006, NUCLEIC ACIDS RES, V34, P1261, DOI 10.1093/nar/gkl013; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; Nimgaonkar A, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-27; Pan Wei, 2003, Functional & Integrative Genomics, V3, P117; Smith TC, 1995, STAT MED, V14, P2685, DOI 10.1002/sim.4780142408; Spiegelhalter DJ, 2002, J ROY STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353; Sun WG, 2007, J AM STAT ASSOC, V102, P901, DOI 10.1198/016214507000000545; Teschendorff AE, 2005, BIOINFORMATICS, V21, P3025, DOI 10.1093/bioinformatics/bti466; Pan Wei, 2008, Pac Symp Biocomput, P465	40	4	4	0	2	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	AUG 28	2008	9								354	10.1186/1471-2105-9-354		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	372DY	WOS:000260883200001	18755028	
J	Renard, BY; Kirchner, M; Steen, H; Steen, JAJ; Hamprecht, FA				Renard, Bernhard Y.; Kirchner, Marc; Steen, Hanno; Steen, Judith A. J.; Hamprecht, Fred A.			NITPICK: peak identification for mass spectrometry data	BMC BIOINFORMATICS			English	Article							ISOTOPIC DISTRIBUTIONS; PROTEIN IDENTIFICATION; CHARGE STATES; SPECTRA; DECONVOLUTION; ALGORITHM; PEPTIDE; PROTEOMICS; SELECTION; REGRESSION	Background: The reliable extraction of features from mass spectra is a fundamental step in the automated analysis of proteomic mass spectrometry (MS) experiments. Results: This contribution proposes a sparse template regression approach to peak picking called NITPICK. NITPICK is a Non-greedy, Iterative Template-based peak PICKer that deconvolves complex overlapping isotope distributions in multicomponent mass spectra. NITPICK is based on fractional averagine, a novel extension to Senko's well-known averagine model, and on a modified version of sparse, non-negative least angle regression, for which a suitable, statistically motivated early stopping criterion has been derived. The strength of NITPICK is the deconvolution of overlapping mixture mass spectra. Conclusion: Extensive comparative evaluation has been carried out and results are provided for simulated and real-world data sets. NITPICK outperforms pepex, to date the only alternate, publicly available, non-greedy feature extraction routine. NITPICK is available as software package for the R programming language and can be downloaded from http://hci.iwr.uni-heidelberg.de/mip/proteomics/.	[Renard, Bernhard Y.; Kirchner, Marc; Hamprecht, Fred A.] Univ Heidelberg, Interdisciplinary Ctr Sci Comp, Heidelberg, Germany; [Renard, Bernhard Y.; Kirchner, Marc; Hamprecht, Fred A.] Childrens Hosp, Dept Pathol, Boston, MA 02115 USA; [Steen, Hanno] Harvard Univ, Sch Med, Dept Pathol, Boston, MA 02115 USA; [Steen, Judith A. J.] Harvard Univ, Sch Med, Dept Neurobiol, Boston, MA 02115 USA; [Steen, Judith A. J.] Childrens Hosp, Dept Neurol, Boston, MA 02115 USA	Hamprecht, FA (reprint author), Univ Heidelberg, Interdisciplinary Ctr Sci Comp, Heidelberg, Germany.	bernhard.renard@iwr.uni-heidelberg.de; marc.kirchner@iwr.uni-heidelberg.de; hanno.steen@childrens.harvard.edu; judith.steen@childrens.harvard.edu; fred.hamprecht@iwr.uni-heidelberg.de			Hans L. Merkle foundation; Karl Steinbuch Scholarship; dm/Filiadata GmbH; Robert Bosch GmbH; Children's Hospital Trust; DFG [HA4364/2-1]	The authors would like to thank Yin Yin Lin (Dept. of Pathology, Children's Hospital, Boston, MA, USA) for LC/MS data acquisition, Lyle Burton (AB/MDS Sciex, Concord, Canada) for MarkerView 1.2 evaluation versions, Ullrich Kothe, Linus Gorlitz, Bjorn Menze, Michael Kelm (Interdisciplinary Center for Scientific Computing (IWR), University of Heidelberg, Germany), and Flavio Monigatti (Dept. of Pathology, Children's Hospital, Boston, MA, USA) for comments, suggestions, and fruitful discussions. We gratefully acknowledge financial support by the Hans L. Merkle foundation (M. K.), the Karl Steinbuch Scholarship (B. Y. R.), dm/Filiadata GmbH (B. Y. R.), Robert Bosch GmbH (F. A. H.), the Children's Hospital Trust (J. A. J. S. and H. S.), and the DFG under grant no. HA4364/2-1 (B. Y. R., F. A. H).	SENKO MW, 1995, J AM SOC MASS SPECTR, V6, P229, DOI 10.1016/1044-0305(95)00017-8; Jensen ON, 2006, NAT REV MOL CELL BIO, V7, P391, DOI 10.1038/nrm1939; Listgarten J, 2005, MOL CELL PROTEOMICS, V4, P419, DOI 10.1074/mcp.R500005-MCP200; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Horn DM, 2000, J AM SOC MASS SPECTR, V11, P320, DOI 10.1016/S1044-0305(99)00157-9; SENKO MW, 1995, J AM SOC MASS SPECTR, V6, P52, DOI 10.1016/1044-0305(94)00091-D; Wehofsky M, 2001, EUR J MASS SPECTROM, V7, P39, DOI 10.1255/ejms.387; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P45, DOI 10.1093/nar/28.1.45; Wang WX, 2003, ANAL CHEM, V75, P4818, DOI 10.1021/ac026468x; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Efron B, 2004, ANN STAT, V32, P407; Chen L, 2006, ANAL CHEM, V78, P5006, DOI 10.1021/ac060099d; Beretta L, 2007, NAT METHODS, V4, P785, DOI 10.1038/nmeth1007-785; Breen EJ, 2000, ELECTROPHORESIS, V21, P2243, DOI 10.1002/1522-2683(20000601)21:11<2243::AID-ELPS2243>3.0.CO;2-K; Casella G., 2001, STAT INFERENCE; Claydon MA, 1996, NAT BIOTECHNOL, V14, P1584, DOI 10.1038/nbt1196-1584; Du PC, 2006, ANAL CHEM, V78, P3385, DOI 10.1021/ac052212q; Fernandez-De-Cossio J, 2004, RAPID COMMUN MASS SP, V18, P2465, DOI [10.1002/rcm.1647, 10.1002/rsm.1647]; Gras R, 1999, ELECTROPHORESIS, V20, P3535, DOI 10.1002/(SICI)1522-2683(19991201)20:18<3535::AID-ELPS3535>3.3.CO;2-A; Hastie T., 2001, ELEMENTS STAT LEARNI; Kaur P, 2006, J AM SOC MASS SPECTR, V17, P459, DOI 10.1016/j.jasms.2005.11.024; Kaur P, 2004, ANAL CHEM, V76, P2756, DOI 10.1021/ac035334w; Kearsley AJ, 2005, APPL MATH LETT, V18, P1412, DOI 10.1016/j.aml.2005.02.033; Lawson C. L., 1974, SOLVING LEAST SQUARE; MANN M, 1995, 43 C MASS SPECTR ALL; MASON CJ, 2006, MOL CELLULAR PROTEOM, V6, P305, DOI 10.1074/mcp.M600148-MCP200; Pineda FJ, 2003, ANAL CHEM, V75, P3817, DOI 10.1021/ac034069b; ROCKWOOD AL, 1995, ANAL CHEM, V67, P2699, DOI 10.1021/ac00111a031; Rockwood AL, 2003, J AM SOC MASS SPECTR, V14, P311, DOI 10.1016/S1044-0305(03)00062-X; Rockwood AL, 2006, J AM SOC MASS SPECTR, V17, P415, DOI 10.1016/j.jasms.2005.12.001; Rockwood AL, 1996, ANAL CHEM, V68, P2027, DOI 10.1021/ac951158i; Roussis SG, 2003, ANAL CHEM, V75, P1470, DOI 10.1021/ac020516w; Samuelsson J, 2004, BIOINFORMATICS, V20, P3628, DOI 10.1093/bioinformatics/bth460; Schwartz SA, 2004, CLIN CANCER RES, V10, P981, DOI 10.1158/1078-0432.CCR-0927-3; SENKO M, 1997, ISOPRO 3 0; Szymura JA, 2003, J MASS SPECTROM, V38, P817, DOI 10.1002/jms.499; Tabb DL, 2006, J AM SOC MASS SPECTR, V17, P903, DOI 10.1016/j.jasms.2006.02.003; Wallace WE, 2004, ANAL CHEM, V76, P2446, DOI 10.1021/ac0354701; Wehofsky M, 2002, J MASS SPECTROM, V37, P223, DOI 10.1002/jms.278; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609; YERGEY JA, 1983, INT J MASS SPECTROM, V52, P337, DOI 10.1016/0020-7381(83)85053-0; Yu WC, 2006, COMPUT BIOL CHEM, V30, P27, DOI 10.1016/j.compbiolchem.2005.10.006; Zhang X, 2005, J AM SOC MASS SPECTR, V16, P1181, DOI 10.1016/j.jasms.2005.03.016; Zhang ZQ, 1998, J AM SOC MASS SPECTR, V9, P225, DOI 10.1016/S1044-0305(97)00284-5; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	46	34	34	0	4	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	AUG 28	2008	9								355	10.1186/1471-2105-9-355		18	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	427EY	WOS:000264763800001	18755032	
J	Yu, ZX; Wa, LW; Hildebrandt, MAT; Schaid, DJ				Yu, Zhaoxia; Wa, Liewel; Hildebrandt, Michelle A. T.; Schaid, Daniel J.			Testing, whether genetic variation explains correlation of quantitative measures of gene expression, and application to genetic network analysis	STATISTICS IN MEDICINE			English	Article						Fisher's z-transformation; Taylor expansion; model selection; pathway; association; multiple regression; optimal linear composites	VARIABLE SELECTION; GRAPHICAL MODELS; COVARIANCE; POLYMORPHISMS; SHRINKAGE; GENOMICS; LASSO	Genetic networks for gene expression data are often built by graphical models, which in turn are built from pair-wise correlations of gene expression levels. A key feature of building graphical models is the evaluation of conditional independence of two traits, given other traits. When conditional independence can be assumed, the traits that are conditioned on are considered to 'explain' the correlation of a pair of traits, allowing efficient building, and interpretation of a network. Overlaying genetic polymorphisms, such as single nucleotide polymorphisms (SNPs), on quantitative measures of gene expression provides a much richer set of data to build a genetic network, because it is possible to evaluate whether sets of SNPs 'explain' the correlation of gene expression levels. However, there is strong evidence that gene expression levels are controlled by multiple interacting genes, suggesting that it Will be difficult to reduce the partial correlation completely to zero. ignoring the fact that some sets of SNPs can explain at least part of the correlation between gene expression levels, if not all. might result in missing important clues on the genetic control of gene expression. To enrich the assessment of the causes of correlation between gene expression levels, we develop methods to evaluate whether a set of covariates (e.g. SNPs. or even a set of quantitative expression transcripts) explains at least some of the correlation of gene expression levels. These methods can be used to assist the interpretation Of regulation of gene expression and the construction of gene regulatory networks. Copyright (c) 2008 John Wiley & Sons, Ltd.	[Yu, Zhaoxia; Schaid, Daniel J.] Mayo Clin, Biostat Sect, Coll Med, Dept Hlth Sci Res,Div Biostat, Rochester, MN 55905 USA; [Wa, Liewel; Hildebrandt, Michelle A. T.] Mayo Clin, Div Clin Pharmacol, Coll Med, Dept Mol Pharmacol & Expt Therapeut, Rochester, MN 55905 USA; [Yu, Zhaoxia] Univ Calif Irvine, Dept Stat, Irvine, CA USA	Schaid, DJ (reprint author), Mayo Clin, Biostat Sect, Coll Med, Dept Hlth Sci Res,Div Biostat, Harwick 775,200 1st St SW, Rochester, MN 55905 USA.	scgaid@mayo.edu			U.S. Public Health Service, National Institutes of Health [GM065450]; Pharmacogenetic Research Network [U01, GM61388]; PhRMA Foundation Center of Excellence in Clinical Pharmacology Award	This work was supported by the U.S. Public Health Service, National Institutes of Health, contract grant number GM065450, the Pharmacogenetic Research Network, U01, GM61388, and PhRMA Foundation Center of Excellence in Clinical Pharmacology Award. We thank Mr Paul Doran and Affymetrix for the support of this study. We Would also like to thank the referee for his/her valuable comments.	AKUTSU S, 1998, P 9 ANN ACM SIAM S D; Anderson TW, 1984, INTRO MULTIVARIATE S; OLKIN I, 1995, PSYCHOL BULL, V118, P155, DOI 10.1037//0033-2909.118.1.155; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Stuart JM, 2003, SCIENCE, V302, P249, DOI 10.1126/science.1087447; STEIGER JH, 1984, PSYCHOMETRIKA, V49, P11, DOI 10.1007/BF02294202; Nyholt DR, 2004, AM J HUM GENET, V74, P765, DOI 10.1086/383251; Butte AJ, 2000, P NATL ACAD SCI USA, V97, P12182, DOI 10.1073/pnas.220392197; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; MENG XL, 1992, PSYCHOL BULL, V111, P172, DOI 10.1037/0033-2909.111.1.172; Schafer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175; JORESKOG KG, 1978, PSYCHOMETRIKA, V43, P443, DOI 10.1007/BF02293808; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Brem RB, 2005, NATURE, V436, P701, DOI 10.1038/nature03865; Chen T., 1999, P 3 ANN INT C COMP M, P94, DOI 10.1145/299432.299462; Cheverud JM, 2001, HEREDITY, V87, P52, DOI 10.1046/j.1365-2540.2001.00901.x; Cox D.R., 1996, MULTIVARIATE DEPENDE; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; DWYER PS, 1967, J AM STAT ASSOC, V62, P607, DOI 10.2307/2283988; Edwards D, 1995, INTRO GRAPHICAL MODE; Gibson G, 2005, TRENDS GENET, V21, P616, DOI 10.1016/j.tig.2005.08.010; Heckerman D, 1999, LEARNING GRAPHICAL M; Hittner JB, 2003, J GEN PSYCHOL, V130, P149; Jones B, 2005, BIOMETRIKA, V92, P779, DOI 10.1093/biomet/92.4.779; Kadie C., 2000, J MACHINE LEARNING R, V1, P49; Kishino H, 2000, Genome Inform Ser Workshop Genome Inform, V11, P83; Kulp DC, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-125; Li RH, 2006, PLOS GENET, V2, P1046, DOI 10.1371/journal.pgen0020114; LORD FM, 1975, AM STAT, V29, P56, DOI 10.2307/2683686; OLKIN I, 1976, ESSAYS PROBABILITY S; Pearson K, 1898, PHILOS T R SOC A, V191, P229, DOI 10.1098/rsta.1898.0007; Rao C. R., 1973, LINEAR STAT INFERENC; Whittaker J, 1990, GRAPHICAL MODELS APP; Zhu J, 2004, CYTOGENET GENOME RES, V105, P363, DOI 10.1159/000078209	37	1	1	1	2	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0277-6715			STAT MED	Stat. Med.	AUG 30	2008	27	19					3847	3867		10.1002/sim.3274		21	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Medicine, Research & Experimental; Statistics & Probability	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Research & Experimental Medicine; Mathematics	340DJ	WOS:000258626000011	18444230	
J	Frieman, JH; Popescu, BE				Frieman, Jerome H.; Popescu, Bogdan E.			PREDICTIVE LEARNING VIA RULE ENSEMBLES	ANNALS OF APPLIED STATISTICS			English	Article						Regression; classification; learning ensembles; rules; interaction effects; variable importance; machine learning; data mining	REGRESSION; SHRINKAGE	General regression and classification models are constructed as linear combinations of simple rules derived from the data. Each rule consists of a conjunction of a small number of simple statements concerning the values of individual input variables. These rule ensembles are shown to produce predictive accuracy comparable to the best methods. However, their principle advantage lies in interpretation. Because of its simple form, each rule is easy to understand, as it its influence on individual predictions, selected subsets of predictions, or globally over the entire space of joint input variable values. Similarly, the degree of relevance of the respective input variables can be assessed globally, locally in different regions of the input space, or at individual prediction points. Techniques are presented for automatically identifying those variables that are involved in interactions with other variables, the strength and degree of those interactions, as well as the indentities of the other variables with which they interact. Graphical representations are used to visualize both main and interaction effects.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Frieman, JH (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.	jhf@stanford.edu; bogdan@stat.stanford.edu			Department of Energy [DE-AC02-76SF00515]; NSF [DMS-97-64431]	Supported in part by the Department of Energy under contract DE-AC02-76SF00515 and NSF Grant DMS-97-64431.Supported in part by NSF Grant DMS-97-64431.	Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COHEN W, 1989, MACH LEARN P 12 INT, P115; COHFN W, 1999, P 16 NAT C ART INT A, P335; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; Efron B, 1993, INTRO BOOTSTRAP; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J. H., 2003, IMPORTANCE SAMPLED L; Friedman JH, 2004, GRADIENT DIRECTED RE; Friedman JH, 2007, J STAT PLAN INFER, V137, P669, DOI 10.1016/j.jspi.2006.06.002; HARRISON D, 1978, J ENVIRON ECON MANAG, V8, P276; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODELS; Ho T.K., 1996, P 13 INT C PATT REC, P880; HOOKER G, 2004, BLACK BOX DIAGNOSTIC; Huber P. J., 1964, ANN MATH STAT, V53, P73; JIANG T, 2001, QUASIREGRESSION VISU; Kleinberg EM, 1996, ANN STAT, V24, P2319; Kleinberg EM, 2000, IEEE T PATTERN ANAL, V22, P473, DOI 10.1109/34.857004; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Mitchell T., 1997, MACHINE LEARNING; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; OWEN AB, 2001, STAT SINICA, V13, P1; PFAHRINGER B, 2004, P 15 EUR C MACH LEAR; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; ROOSEN C, 1995, THESIS STANFORD U; Rosset S., 2000, SIGKDD EXPLORATIONS, V1, P85; RUCKERT U, 2006, P 23 INT C MACH LEAR; WEISS SM, 2000, P 17 INT C MACH LEAR, P1135	33	70	71	0	10	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	SEP	2008	2	3					916	954		10.1214/07-AOAS148		39	Statistics & Probability	Mathematics	374QD	WOS:000261057900006		
J	Witten, DM; Tibshirani, R				Witten, Daniela M.; Tibshirani, Robert			TESTING SIGNIFICANCE OF FEATURES BY LASSOED PRINCIPAL COMPONENTS	ANNALS OF APPLIED STATISTICS			English	Article						Microarray; gene expression; multiple testing; feature selection	GENE-EXPRESSION; MICROARRAY DATA; PREDICT SURVIVAL; CONSENSUS; TUMOR	We consider the problem of testing the significance of features in high-dimensional settings. In particular, we test for differentially-expressed genes in a microarray experiment. We wish to identify genes that are associated with some type of outcome, such as survival time or cancer type. We propose a new procedure, called Lassoed Principal Components (LPC), that builds upon existing methods and can provide a sizable improvement. For instance, in the case of two-class data, a standard (albeit simple) approach might be to compute a two-sample t-statistic for each gene. The LPC method involves projecting these conventional gene scores onto the eigenvectors of the gene expression data covariance matrix and then applying an L-1 penalty in order to de-noise the resulting projecting. We present a theoretical framework under which LPC is the logical choice for identifying significant genes, and we show that LPC can provide a marked reduction in false discovery rates over the conventional methods on both real and stimulated data. Moreover, this flexible procedure can be applied to a variety of types of data and can be used to improve many existing methods for the identification of significant features.	[Witten, Daniela M.] Stanford Univ, Dept Stat, Stanford, CA 94305 USA; [Tibshirani, Robert] Stanford Univ, Dept Hlth Res & Policy & Stat, Stanford, CA 94305 USA	Witten, DM (reprint author), Stanford Univ, Dept Stat, 390 Serra Mall, Stanford, CA 94305 USA.	dwitten@stanford.edu; tibs@stat.stanford.edu			National Defense Science and Enoineering Graduate Fellowship; NSF [DMS-99-71405]; National Institutes of Health [N01-11V-28183]	Supported by a National Defense Science and Enoineering Graduate Fellowship.Supported in part by NSF Grant DMS-99-71405 and the National Institutes of Health Contract N01-11V-28183.	Price AL, 2006, NAT GENET, V38, P904, DOI 10.1038/ng1847; Sjoblom T, 2006, SCIENCE, V314, P268, DOI 10.1126/science.1133427; Cui XG, 2005, BIOSTATISTICS, V6, P59, DOI 10.1093/biostatistics/kxh018; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Lonnstedt I, 2002, STAT SINICA, V12, P31; Allison DB, 2006, NAT REV GENET, V7, P55, DOI 10.1038/nrg1749; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Leek JT, 2007, PLOS GENET, V3, P1724, DOI 10.1371/journal.pgen.0030161; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; CARVALHO C, 2008, J AM STAT A IN PRESS; Cut X, 2003, GENOME BIOL, V4, P210; Getz Gad, 2007, Science, V317, P1500; Shen RL, 2006, BIOINFORMATICS, V22, P2635, DOI 10.1093/bioinformatics/btl442; Smyth GK, 2004, STAT APPL GENET MOL, V3; Storey JD, 2007, BIOSTATISTICS, V8, P414, DOI 10.1093/biostatistics/kxl019; West M., 2003, BAYESIAN STAT, P723; WITTEN DM, 2008, TESTING SIGNIFICAN S, DOI DOI 10.1214/08-AOAS182SUPP; Zhao HJ, 2006, PLOS MED, V3, P115, DOI 10.1371/journal.pmed.0030013	23	5	5	1	6	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	SEP	2008	2	3					986	1012		10.1214/08-AOAS182		27	Statistics & Probability	Mathematics	374QD	WOS:000261057900009		
J	Fornasier, M; Rauhut, H				Fornasier, Massimo; Rauhut, Holger			Iterative thresholding algorithms	APPLIED AND COMPUTATIONAL HARMONIC ANALYSIS			English	Article						linear inverse problems; joint sparsity; thresholded Landweber iterations; frames; variational calculus on sequence spaces; Gamma-convergence	LINEAR INVERSE PROBLEMS; WAVELET SHRINKAGE; SPARSITY CONSTRAINTS; IMAGE-RESTORATION; NOISE REMOVAL; REGRESSION; REGULARIZATION; DECOMPOSITION; SELECTION; RECOVERY	This article provides a variational formulation for hard and firm thresholding. A related functional can be used to regularize inverse problems by sparsity constraints. We show that a damped hard or firm thresholded Landweber iteration converges to its minimizer. This provides an alternative to an algorithm recently studied by the authors. We prove stability of minimizers with respect to the parameters of the functional by means of Gamma-convergence. All investigations are done in the general setting of vector-valued (multi-channel) data. (c) 2007 Elsevier Inc. All rights reserved.	[Rauhut, Holger] Univ Vienna, Dept Math, Numer Harmon Anal Grp, A-1090 Vienna, Austria; [Fornasier, Massimo] Princeton Univ, Program Appl & Computat Math, Princeton, NJ 08544 USA	Rauhut, H (reprint author), Univ Vienna, Dept Math, Numer Harmon Anal Grp, Nordbergstr 15, A-1090 Vienna, Austria.	mfornasi@math.princeton.edu; holger.rauhut@univie.ac.at					Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319; Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258; Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; ANTHOINE S, 2005, THESIS PRINCETON U; Baron D., 2005, DISTRIBUTED COMPRESS; Blumensath T., 2007, P IEEE INT C AC SPEE; Christensen O., 2003, INTRO FRAMES RIESZ B; Dal Maso G., 1993, INTRO GAMMA CONVERGE; Daubechies I, 2007, INVERSE PROBL IMAG, V1, P29; Daubechies I, 2005, APPL COMPUT HARMON A, V19, P1, DOI 10.1016/j.acha.2004.12.004; DONOHO DL, 1992, SIAM J MATH ANAL, V23, P1309, DOI 10.1137/0523074; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; DONOHO DL, 1995, APPL COMPUT HARMON A, V2, P101, DOI 10.1006/acha.1995.1008; Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005; Engl H. W., 1996, REGULARIZATION INVER, V375; FORNASIER M, 2007, J COMPUT AP IN PRESS; FORNASIER M, 2007, SIAM J NUME IN PRESS; Gao HY, 1997, STAT SINICA, V7, P855; Loris I, 2007, GEOPHYS J INT, V170, P359, DOI 10.1111/j.1365-246X.2007.03409.x; MEIER L, 2007, J ROY STA B IN PRESS; Ramlau R, 2005, INVERSE PROBL, V21, P1571, DOI 10.1088/0266-5611/21/5/005; Ramlau R, 2006, NUMER MATH, V104, P177, DOI 10.1007/s00211-006-0016-3; Rauhut H, 2007, APPL COMPUT HARMON A, V22, P16, DOI 10.1016/j.acha.2006.05.002; Starck JL, 2003, SIGNAL PROCESS, V83, P2279, DOI 10.1016/S0165-1684(03)00150-6; Starck JL, 2003, ASTRON ASTROPHYS, V398, P785, DOI 10.1051/0004-6361:20021571; Teschke G, 2007, APPL COMPUT HARMON A, V22, P43, DOI 10.1016/j.acha.2006.05.003; Xu JJ, 2007, IEEE T IMAGE PROCESS, V16, P534, DOI 10.1109/TIP.2006.888335	38	47	58	2	7	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1063-5203			APPL COMPUT HARMON A	Appl. Comput. Harmon. Anal.	SEP	2008	25	2					187	208		10.1016/j.acha.2007.10.005		22	Mathematics, Applied; Physics, Mathematical	Mathematics; Physics	339WA	WOS:000258606800004		
J	Xie, BH; Pan, W; Shen, XT				Xie, Benhuai; Pan, Wei; Shen, Xiaotong			Variable selection in penalized model-based clustering via regularization on grouped parameters	BIOMETRICS			English	Article						BIC; diagonal covariance; EM algorithm; high-dimension but low-sample size; microarray gene expression; mixture model; penalized likelihood	GENE-EXPRESSION DATA; MIXTURE MODEL; EM ALGORITHM; CLASSIFICATION; REGRESSION; PREDICTION; LASSO	Penalized model-based clustering has been proposed for high-dimensional but small sample-sized data, such as arising from genomic studies; in particular, it can be used for variable selection. A new regularization scheme is proposed to group together multiple parameters of the same variable across clusters, which is shown both analytically and numerically to be more effective than the conventional L-1 penalty for variable selection. In addition, we develop a strategy to combine this grouping scheme with grouping structured variables. Simulation studies and applications to microarray gene expression data for cancer subtype discovery demonstrate the advantage of the new proposal over several existing approaches.	[Xie, Benhuai; Pan, Wei] Univ Minnesota, Div Biostat, Sch Publ Hlth, Minneapolis, MN 55455 USA; [Shen, Xiaotong] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	Xie, BH (reprint author), Univ Minnesota, Div Biostat, Sch Publ Hlth, Minneapolis, MN 55455 USA.	weip@biostat.umn.edu					Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Efron B, 2004, ANN STAT, V32, P407; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; CHOI NH, 2006, 453 U MICH DEP STAT; Friedman J.H., 2004, J ROYAL STAT SOC B, V66, P1; Ghosh D, 2002, BIOINFORMATICS, V18, P275, DOI 10.1093/bioinformatics/18.2.275; H Li, 2001, GENOME BIOL, V2; Hastie T., 2001, ELEMENTS STAT LEARNI; Hoff PD, 2006, BAYESIAN ANAL, V1, P321; Hoff PD, 2005, BIOMETRICS, V61, P1027, DOI 10.1111/j.1541-0420.2005.00381.x; Kim S, 2006, BIOMETRIKA, V93, P877, DOI 10.1093/biomet/93.4.877; Liu J. S., 2003, BAYESIAN STAT, V7, P249; Mangasarian O. L., 2004, P SIAM INT C DAT MIN, P23; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; Pan W, 2006, BIOINFORMATICS, V22, P2388, DOI 10.1093/bioinformatics/btl393; Pan W, 2007, J MACH LEARN RES, V8, P1145; Raftery AE, 2006, J AM STAT ASSOC, V101, P168, DOI 10.1198/016214506000000113; Tadesse MG, 2005, J AM STAT ASSOC, V100, P602, DOI 10.1198/0162145040000001565; WANG S, 2006, 449 U MICH DEP STAT; Wang SJ, 2007, BIOINFORMATICS, V23, P972, DOI 10.1093/bioinformatics/btm046; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; XIE B, 2007, PENALIZED MODEL BASE; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977; Zhao P, 2006, GROUPED HIERARCHICAL; ZHOU N, 2007, 464 U MICH DEP STAT; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	34	11	12	2	6	BLACKWELL PUBLISHING	OXFORD	9600 GARSINGTON RD, OXFORD OX4 2DQ, OXON, ENGLAND	0006-341X			BIOMETRICS	Biometrics	SEP	2008	64	3					921	930		10.1111/j.1541-0420.2007.00955.x		10	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	337YE	WOS:000258470600029	18162109	
J	Chen, JH; Chen, ZH				Chen, Jiahua; Chen, Zehua			Extended Bayesian information criteria for model selection with large model spaces	BIOMETRIKA			English	Article						Bayesian paradigm; consistency; genome-wide association study; tournament approach; variable selection	QUANTITATIVE TRAIT LOCI; GENERALIZED CROSS-VALIDATION; VARIABLE SELECTION; LASSO; REGRESSION; LIKELIHOOD; CHOICE	The ordinary Bayesian information criterion is too liberal for model selection when the model space is large. In this paper, we re-examine the Bayesian paradigm for model selection and propose an extended family of Bayesian information criteria, which take into account both the number of unknown parameters and the complexity of the model space. Their consistency is established, in particular allowing the number of covariates to increase to infinity with the sample size. Their performance in various situations is evaluated by simulation studies. It is demonstrated that the extended Bayesian information criteria incur a small loss in the positive selection rate but tightly control the false discovery rate, a desirable property in many applications. The extended Bayesian information criteria are extremely useful for variable selection in problems with a moderate sample size but with a huge number of covariates, especially in genome-wide association studies, which are now an active area in genetics research.	[Chen, Jiahua] Univ British Columbia, Dept Stat, Vancouver, BC V6T 1Z2, Canada; [Chen, Zehua] Natl Univ Singapore, Dept Stat & Appl Probabil, Singapore 117546, Singapore	Chen, JH (reprint author), Univ British Columbia, Dept Stat, Vancouver, BC V6T 1Z2, Canada.	jhchen@stat.ubc.ca; stachenz@nus.edu.sg	Chen, Jiahua/C-5040-2008	Chen, Jiahua/0000-0001-8064-4444			Akaike H., 1973, 2 INT S INF THEOR, P267; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Marchini J, 2005, NAT GENET, V37, P413, DOI 10.1038/ng1537; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Wilks SS, 1938, ANN MATH STAT, V9, P60, DOI 10.1214/aoms/1177732360; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; CRAVEN P, 1979, NUMER MATH, V31, P377; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Berger J. O., 2001, LECT NOTES MONOGRAPH, V38, P135; Bogdan M, 2004, GENETICS, V167, P989, DOI 10.1534/genetics.103.021683; Broman KW, 2002, J R STAT SOC B, V64, P641, DOI 10.1111/1467-9868.00354; Clyde MA, 2007, ASTR SOC P, V371, P224; Csorgo M., 1997, LIMIT THEOREMS CHANG; LI KC, 1987, ANN STAT, V15, P958, DOI 10.1214/aos/1176350486; RAO CR, 1989, BIOMETRIKA, V76, P369, DOI 10.2307/2336671; Shao J, 1997, STAT SINICA, V7, P221; Siegmund D, 2004, BIOMETRIKA, V91, P785, DOI 10.1093/biomet/91.4.785; STONE M, 1974, J R STAT SOC B, V36, P111; YAO YC, 1988, STAT PROBABIL LETT, V6, P181, DOI 10.1016/0167-7152(88)90118-6; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520	22	135	135	3	12	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0006-3444			BIOMETRIKA	Biometrika	SEP	2008	95	3					759	771		10.1093/biomet/asn034		13	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	343NO	WOS:000258861000017		
J	Ma, S; Huang, J				Ma, Shuangge; Huang, Jian			Penalized feature selection and classification in bioinformatics	BRIEFINGS IN BIOINFORMATICS			English	Article						bioinformatics application; feature selection; penalization	SUPPORT VECTOR MACHINES; GENE-EXPRESSION DATA; PROTEIN SUBCELLULAR-LOCALIZATION; SPARSE LOGISTIC-REGRESSION; MICROARRAY DATA; DISEASE CLASSIFICATION; SAMPLE CLASSIFICATION; DIMENSION REDUCTION; VARIABLE SELECTION; MASS-SPECTROMETRY	In bioinformatics studies, supervised classification with high-dimensional input variables is frequently encountered. Examples routinely arise in genomic, epigenetic and proteomic studies. Feature selection can be employed along with classifier construction to avoid over-fitting, to generate more reliable classifier and to provide more insights into the underlying causal relationships. In this article, we provide a review of several recently developed penalized feature selection and classification techniqueswhich belong to the family of embedded feature selection methodsfor bioinformatics studies with high-dimensional input. Classification objective functions, penalty functions and computational algorithms are discussed. Our goal is to make interested researchers aware of these feature selection and classification methods that are applicable to high-dimensional bioinformatics data.	[Ma, Shuangge] Yale Univ, Dept Epidemiol & Publ Hlth, New Haven, CT 06520 USA; [Huang, Jian] Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA; [Huang, Jian] Univ Iowa, Dept Biostat, Iowa City, IA 52242 USA	Ma, S (reprint author), 60 College ST,LEPH 209, New Haven, CT 06510 USA.	shuangge.ma@yale.edu	Sincan, Murat /A-3794-2010				AN JL, 2003, P 2 INT C MACH LEARN; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Yu CS, 2006, PROTEINS, V64, P643, DOI 10.1002/prot.21018; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zhang HH, 2006, BIOINFORMATICS, V22, P88, DOI 10.1093/bioinformatics/bti736; Huang J, 2008, ANN STAT, V36, P587, DOI 10.1214/009053607000000875; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Tibshirani R, 2004, BIOINFORMATICS, V20, P3034, DOI 10.1093/bioinformatics/bth357; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; BOULESTEIX AL, 2005, THESIS LMU MUNCHEN; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dai JJ, 2006, STAT APPL GENET MOL, V5; Diamandis EP, 2005, CLIN CANCER RES, V11, P963; FRIEDMAN JH, 2006, HERDING LAMBDAS FAST; Ghosh D, 2005, J BIOMED BIOTECHNOL, P147, DOI 10.1155/JBB.2005.147; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HUANG J, 2007, STAT SIN IN PRESS; Kim Y, 2004, P 21 INT C MACH LEAR; Leng CL, 2006, STAT SINICA, V16, P1273; Lesk A. M, 2002, INTRO BIOINFORMATICS, V1st; Liu ZQ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1248; Ma SG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-537; MA S, 2007, BMC BIOINFORMATICS, V8, P198; Ma SG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-253; Ma SG, 2005, BIOINFORMATICS, V21, P4356, DOI 10.1093/bioinformatics/bti724; McCullagh P., 1989, GEN LINEAR MODELS; Mossman D, 1999, MED DECIS MAKING, V19, P78, DOI 10.1177/0272989X9901900110; Noble W, 2004, KERNEL METHODS COMPU, P71; Pan W, 2006, BIOINFORMATICS, V22, P2388, DOI 10.1093/bioinformatics/btl393; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pepe MS, 2003, STAT EVALUATION MED; PIYATHILAKE C, 2002, AM SOC NUTR SCI, V132, pS2340; Rey Sébastien, 2005, BMC Genomics, V6, P162, DOI 10.1186/1471-2164-6-162; ROTH V, 2002, IAITR20028 U BONN DE; SAEYS Y, 2007, BIOINFORMATICS, V19, P2507; Shen L, 2005, IEEE ACM T COMPUT BI, V2, P166; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang H., 2006, PACIFIC S BIOCOMPUTI, V11, P303; Wang LF, 2007, BIOINFORMATICS, V23, P1486, DOI 10.1093/bioinformatics/btm125; WEI P, 2006, IEEE T COMPUT BIOL B, V99, P1; Weston J, 2004, ADV NEUR IN, V16, P595; WONG S, 2004, PRACTICAL BIOINFORMA; YANG H, 2004, P IEEE INT C SYST MA, P3444; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430; Zukiel R, 2004, MOL CANCER RES, V2, P196	63	50	51	6	13	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463			BRIEF BIOINFORM	Brief. Bioinform.	SEP	2008	9	5					392	403		10.1093/bib/bbn027		12	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	337YK	WOS:000258471200005	18562478	
J	Raz, DJ; Ray, MR; Kim, J; He, B; Taron, M; Skrzypski, M; Segal, M; Gandara, DR; Rosell, R; Jablons, DM				Raz, Dan J.; Ray, M. Roshni; Kim, Jaey; He, Biao; Taron, Miquel; Skrzypski, Marcin; Segal, Mark; Gandara, David R.; Rosell, Rafael; Jablons, David M.			A multigene assay is prognostic of survival in patients with early-stage lung adenocarcinoma	CLINICAL CANCER RESEARCH			English	Article							GENE-EXPRESSION DATA; SQUAMOUS-CELL; CANCER; REGRESSION; CARCINOMAS; PROFILES; MODELS	Purpose: Clinical staging does not adequately risk stratify patients with early stage non-small cell lung cancer. We sought to generate a real-time PCR (RT-PCR) -based prognostic model in patients with early stage lung adenocarcinoma, the dominant histology of lung cancer in the United States. Experimental Design: We studied gene expression of 61 candidate genes in 107 patients with completely surgically resected lung adenocarcinoma using RT-PCR. We used crossvalidation methods to select and validate a prognostic model based on the expression of a limited number of genes. A risk score was generated based on model coefficients, and survival of patients with high- and low-risk scores were analyzed. Results: We generated a four-gene model based on expression of WNT3a, ERBB3, LCK, and RND3. Risk score predicted mortality better than clinical stage or tumor size (adjusted hazard ratio, 6.7; 95% confidence interval, 1.6-28.9; P = 0.001). Among 70 patients with stage I disease, 5-year overall survival was 87% among patients with low-risk scores, and 38% among patients with high-risk scores (P = 0.0002). Among all patients, 5-year overall survival was 62% and 41%, respectively (P 0,0054). Disease-free survival was also significantly different among low- and high-risk score patients. Conclusions: This multigene assay predicts overall and disease-free survival significantly better than clinical stage and tumor size in patients with early stage lung adenocarcinorna and performs especially well in patients with stage I disease. Prospective clinical trials are needed to determine whether high-risk patients with stage I disease benefit from adjuvant chemotherapy.	[Raz, Dan J.; Ray, M. Roshni; Kim, Jaey; He, Biao; Jablons, David M.] Univ Calif San Francisco, Thorac Oncol Program, Dept Surg, San Francisco, CA 94131 USA; [Segal, Mark] Univ Calif San Francisco, Dept Epidemiol & Biostat, San Francisco, CA 94131 USA; [Taron, Miquel; Rosell, Rafael] Hosp Badalona Germans Trias & Pujol, Catalan Inst Oncol, Barcelona, Spain; [Skrzypski, Marcin] Med Univ Gdansk, Gdansk, Poland; [Gandara, David R.] Univ Calif Davis, Ctr Canc, Div Hematol Oncol, Sacramento, CA 95817 USA	Raz, DJ (reprint author), Univ Calif San Francisco, Thorac Oncol Program, Dept Surg, 513 Parnassus Ave S-321, San Francisco, CA 94131 USA.	Dan.raz@ucsf.edu		Ricchetti, Roshni/0000-0002-1969-1046			Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Raponi M, 2006, CANCER RES, V66, P7466, DOI 10.1158/0008-5472.CAN-06-1191; Le Chevalier T, 2004, NEW ENGL J MED, V350, P351; Bektic J, 2005, PROSTATE, V64, P332, DOI 10.1002/pros.20243; Mazieres J, 2005, CANCER LETT, V222, P1, DOI 10.1016/j.canlet.2004.08.040; Dominioni L, 2000, CANCER, V89, P2334, DOI 10.1002/1097-0142(20001201)89:11+<2334::AID-CNCR4>3.0.CO;2-I; Chen HY, 2007, NEW ENGL J MED, V356, P11, DOI 10.1056/NEJMoa060096; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Efron B, 2004, ANN STAT, V32, P407; Jemal A, 2006, CA-CANCER J CLIN, V56, P106; Winton T, 2005, NEW ENGL J MED, V352, P2589, DOI 10.1056/NEJMoa043623; Potti A, 2006, NEW ENGL J MED, V355, P570, DOI 10.1056/NEJMoa060467; Harrell FE, 1996, STAT MED, V15, P361, DOI 10.1002/(SICI)1097-0258(19960229)15:4<361::AID-SIM168>3.0.CO;2-4; Brundage MD, 2002, CHEST, V122, P1037, DOI 10.1378/chest.122.3.1037; HARPOLE DH, 1995, CANCER, V76, P787, DOI 10.1002/1097-0142(19950901)76:5<787::AID-CNCR2820760512>3.0.CO;2-Q; Hastie T., 2001, ELEMENTS STAT LEARNI; Inngjerdingen M, 2002, BLOOD, V99, P4318, DOI 10.1182/blood.V99.12.4318; Lau SK, 2007, J CLIN ONCOL, V25, P5562, DOI 10.1200/JCO.2007.12.0352; McDoniels-Silvers AL, 2002, NEOPLASIA, V4, P141, DOI 10.1038/sj.neo.7900217; Miura K, 2002, CANCER RES, V62, P3244; Muller-Tidow C, 2005, CANCER RES, V65, P1778, DOI 10.1158/0008-5472.CAN-04-3388; Raz DJ, 2007, J THORAC ONCOL, V2, P125; Schneider PM, 2000, BRIT J CANCER, V83, P473, DOI 10.1054/bjoc.2000.1287; Segal MR, 2006, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; TEAM RRC, 2006, R LANGUAGE ENV STAT; Thunnissen FBJM, 2006, HISTOPATHOLOGY, V48, P779, DOI 10.1111/j.1365-2559.2006.02386.x; Wang YL, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-59; Wigle DA, 2002, CANCER RES, V62, P3005	32	45	45	1	4	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	SEP 1	2008	14	17					5565	5570		10.1158/1078-0432.CCR-08-0544		6	Oncology	Oncology	347UG	WOS:000259166000030	18765549	
J	Zelinski, AC; Wald, LL; Setsompop, K; Goyal, VK; Adalsteinsson, E				Zelinski, Adam C.; Wald, Lawrence L.; Setsompop, Kawin; Goyal, Vivek K.; Adalsteinsson, Elfar			Sparsity-enforced slice-selective MRI RF excitation pulse design	IEEE TRANSACTIONS ON MEDICAL IMAGING			English	Article						B(1) inhomogeneity mitigation; high field strength; magnetic resonance imaging (MRI) radio-frequency (RF) pulse sequence design; parallel transmission; sparse approximation; three-dimensional (3-D) RF excitation	PARALLEL EXCITATION; SIGNAL RECONSTRUCTION; TRANSMIT SENSE; BIRDCAGE COIL; 3 TESLA; ALGORITHMS; EQUATIONS; RESONANCE; SYSTEMS; APPROXIMATION	We introduce a novel algorithm for the design of fast slice-selective spatially-tailored magnetic resonance imaging (MRI) excitation pulses. This method, based on sparse approximation theory, uses a second-order cone optimization to place and modulate a small number of slice-selective sinc-like radio-frequency (RF) pulse segments ("spokes") in excitation k-space, enforcing sparsity on the number of spokes allowed while simultaneously encouraging those that remain to be placed and modulated in a way that best forms a user-defined in-plane target magnetization. Pulses are designed to mitigate B(1) inhomogeneity in a water phantom at 7 T and to produce highly-structured excitations in an oil phantom on an eight-channel parallel excitation system at 3 T. In each experiment, pulses generated by the sparsity-enforced method outperform those created via conventional Fourier-based techniques, e.g., when attempting to produce a uniform magnetization in the presence of severe B., inhomogeneity, a 5.7-ms 15-spoke pulse generated by the sparsity-enforced method produces an excitation with 1.28 times lower root mean square error than conventionally-designed 15-spoke pulses. To achieve this same level of uniformity, the conventional methods need to use 29-spoke pulses that are 7.8 ms long.	[Zelinski, Adam C.; Setsompop, Kawin; Goyal, Vivek K.; Adalsteinsson, Elfar] MIT, Dept Elect Engn & Comp Sci, Elect Res Lab, Cambridge, MA 02139 USA; [Wald, Lawrence L.] Harvard Univ, Sch Med, Dept Radiol, Boston, MA 02115 USA; [Wald, Lawrence L.] Harvard Univ, Sch Med, HST, Boston, MA 02115 USA; [Adalsteinsson, Elfar] Harvard MIT, Div Hlth Sci & Technol, Cambridge, MA 02139 USA	Zelinski, AC (reprint author), MIT, Dept Elect Engn & Comp Sci, Elect Res Lab, Cambridge, MA 02139 USA.	zelinski@MIT.edu	Adalsteinsson, Elfar/F-2477-2010; Wald, Lawrence/D-4151-2009; Setsompop, Kawin/P-1464-2014	Setsompop, Kawin/0000-0003-0455-7634	National Institutes of Health [1P41RR14075, 1R01EB000790, 1R01EB006847, 1R01EB007942]; National Science Foundation [CCF-643836]; United States Department of Defense National Defense Science and Engineering Graduate [F49620-02-C-0041]; MIND Institute; A. A. Martinos Center for Biomedical Imaging; R. J. Shillman Career Development Award	This work was supported in part by the National Institutes of Health under Grant 1P41RR14075, Grant 1R01EB000790, Grant 1R01EB006847, and 1R01EB007942, in part by the National Science Foundation under Grant CCF-643836, in part by the United States Department of Defense National Defense Science and Engineering Graduate Fellowship F49620-02-C-0041, in part the MIND Institute, in part the A. A. Martinos Center for Biomedical Imaging, and in part by the R. J. Shillman Career Development Award.	Alagappan V, 2006, P 14 ANN M ISMRM SEA, P12; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Barberi EA, 2000, MAGNET RESON MED, V43, P284, DOI 10.1002/(SICI)1522-2594(200002)43:2<284::AID-MRM16>3.0.CO;2-C; Malioutov D, 2005, IEEE T SIGNAL PROCES, V53, P3010, DOI 10.1109/TSP.2005.850882; Sodickson DK, 1997, MAGNET RESON MED, V38, P591, DOI 10.1002/mrm.1910380414; TIKHONOV AN, 1963, DOKL AKAD NAUK SSSR+, V151, P501; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Zhu YD, 2004, MAGNET RESON MED, V51, P775, DOI 10.1002/mrm.20011; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Pruessmann KP, 1999, MAGNET RESON MED, V42, P952, DOI 10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S; ERNST RR, 1966, REV SCI INSTRUM, V37, P93, DOI 10.1063/1.1719961; Collins CM, 1998, MAGNET RESON MED, V40, P847, DOI 10.1002/mrm.1910400610; Grissom W, 2006, MAGN RESON MED, V56, P620, DOI 10.1002/mrm.20978; Yip CY, 2005, MAGNET RESON MED, V54, P908, DOI 10.1002/mrm.20631; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031; PAULY J, 1989, J MAGN RESON, V81, P43, DOI 10.1016/0022-2364(89)90265-5; Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475; Ibrahim TS, 2001, PHYS MED BIOL, V46, P609, DOI 10.1088/0031-9155/46/2/324; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Zelinski AC, 2007, CONCEPT MAGN RESON B, V31B, P176, DOI 10.1002/cmr.b.20093; Bernstein MA, 2004, HDB MRI PULSE SEQUEN; Bomsdorf H, 1988, NMR Biomed, V1, P151, DOI 10.1002/nbm.1940010308; BOTTOMLEY PA, 1978, PHYS MED BIOL, V23, P630, DOI 10.1088/0031-9155/23/4/006; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Collins CM, 2005, J MAGN RESON IMAGING, V21, P192, DOI 10.1002/jmri.20245; Davis G., 1994, THESIS NEW YORK U; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; DONOVAN BJ, 1994, BUMBLEBEE QUEST, V1, P3; DUMOULIN CL, 1986, RADIOLOGY, V161, P717; Elad M., 2006, P IEEE COMP SOC C CO, V2, P1924; GLOVER G, 1998, P 6 ANN M ISMRM SYDN, P298; Graesslin I, 2006, P 14 ANN M ISMRM SEA, P129; Hansen P. C., 1994, Numerical Algorithms, V6, DOI 10.1007/BF02149761; HU XP, 1994, MAGNET RESON MED, V31, P691, DOI 10.1002/mrm.1910310618; JIN J, 1997, MAGN RESON MED, V21, P192; JOHNSTONE IM, 1994, ANN STAT, V22, P271, DOI 10.1214/aos/1176325368; Katscher U, 2004, IEEE T MED IMAGING, V23, P520, DOI 10.1109/TMI.2004.824151; KATSCHER U, 2006, P INT SOC MAGN RES M, P600; Katscher U, 2003, MAGNET RESON MED, V49, P144, DOI 10.1002/mrm.10353; KERR AB, 2006, P INT SOC MAGN RES M, P14; KIM SJ, 2007, METHOD LARGE SCALE R; Luenberger D. G., 1969, OPTIMIZATION VECTOR; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Nemirovski A., 2001, LECT MODERN CONVEX O; Oppenheim A. V., 1989, DISCRETE TIME SIGNAL; PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989; Powell M, 1978, LECT NOTES MATH, V630, P144, DOI DOI 10.1007/BFB0067703; Saekho S, 2006, MAGN RESON MED, V55, P719, DOI 10.1002/mrm.20840; SAUNDERS M. A., PDCO PRIMAL DUAL INT; SETSOMPOP K, 2007, P INT SOC MAGN RES M, P356; Setsompop K, 2006, MAGN RESON MED, V56, P1163, DOI 10.1002/mrm.21042; SOUZA SP, 1989, P 11 ANN INT C ENG M, V2, P514; Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762; TROPP J, 1992, P 11 ANN M SMRM BERL, P4009; Tropp J. A., 2004, THESIS U TEXAS AUSTI; Ullmann P, 2005, MAGNET RESON MED, V54, P994, DOI 10.1002/mrm.20646; ULLMANN P, 2007, P INT SOC MAGN RES M, P672; Ulloa J, 2005, P 13 ANN M ISMRM MIA, P21; Van De Moortele PF, 2005, MAGNET RESON MED, V54, P1503, DOI 10.1002/mrm.20708; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Vaughan JT, 2001, MAGNET RESON MED, V46, P24, DOI 10.1002/mrm.1156; Wang JH, 2005, MAGNET RESON MED, V53, P408, DOI 10.1002/mrm.20354; YIP CP, 2005, P 13 ANN M ISMRM MIA, P2350; Yip CY, 2007, MAGN RESON MED, V58, P598, DOI 10.1002/mrm.21262; Yip CY, 2006, MAGN RESON MED, V56, P1050, DOI 10.1002/mrm.21048; ZELINSKI AC, 2007, P INT SOC MAGN RES M, P1691; ZHU Y, 2005, P 13 ANN M ISMRM MIA, P14	69	25	26	2	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0278-0062			IEEE T MED IMAGING	IEEE Trans. Med. Imaging	SEP	2008	27	9					1213	1229		10.1109/TMI.2008.920605		17	Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	344TF	WOS:000258949500004	18779063	
J	Brownlees, CT; Gallo, GM				Brownlees, Christian T.; Gallo, Giampiero M.			On variable selection for volatility forecasting: The role of focused selection criteria	JOURNAL OF FINANCIAL ECONOMETRICS			English	Article						focused information criteria; forecasting; model selection; realized volatility; value at risk	STOCK-RETURN VOLATILITY; MODEL SELECTION; STOCHASTIC VOLATILITY; INFORMATION CRITERION; MICROSTRUCTURE NOISE; RISK-MANAGEMENT; TRADING VOLUME; HIGH-FREQUENCY; VARIANCE; COMBINATION	This paper is concerned with the issues of modeling and projecting the dynamics of volatility when a group of potentially useful predetermined variables is available. We predict realized volatility and value at risk (VaR) with a nested set of multiplicative error models for realized volatility. We make use of recently proposed focused model selection/combination strategies as well as the classic AIC/BIC. Focused strategies consist of choosing the model that minimizes the estimated MSE of a given function of the parameters of interest to the forecaster. Results show that VaR forecasts can significantly be improved upon using focused prediction strategies.	[Gallo, Giampiero M.] Univ Florence, Dipartimento Stat G Parenti, I-50134 Florence, Italy	Gallo, GM (reprint author), Univ Florence, Dipartimento Stat G Parenti, Viale GB Morgagni 59, I-50134 Florence, Italy.	gallog@ds.unifi.it	Brownlees, Christian/D-9811-2014	Brownlees, Christian/0000-0003-4276-1468			Ait-Sahalia Y, 2005, REV FINANC STUD, V18, P351, DOI 10.1093/rfs/hhi016; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Akaike H, 1973, 2 INT S INF THEOR BU; Alizadeh S, 2002, J FINANC, V57, P1047, DOI 10.1111/1540-6261.00454; Andersen T., 2003, ECONOMETRICA, V71, P529; Andersen T., 2006, REALIZED VOLATILITY; Andersen TG, 2001, J FINANC ECON, V61, P43, DOI 10.1016/S0304-405X(01)00055-1; Andersen TG, 2001, J AM STAT ASSOC, V96, P42, DOI 10.1198/016214501750332965; Andersen TG, 2005, ECONOMETRICA, V73, P279, DOI 10.1111/j.1468-0262.2005.00572.x; Andersen TG, 1996, J FINANC, V51, P169, DOI 10.2307/2329306; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hoeting JA, 1999, STAT SCI, V14, P382; Andersen TG, 1998, INT ECON REV, V39, P885, DOI 10.2307/2527343; Andersen TG, 2007, REV ECON STAT, V89, P701, DOI 10.1162/rest.89.4.701; Claeskens G, 2003, J AM STAT ASSOC, V98, P900, DOI 10.1198/016214503000000819; Engle R, 2002, J APPL ECONOM, V17, P425, DOI 10.1002/jae.683; Hansen BE, 2007, ECONOMETRICA, V75, P1175, DOI 10.1111/j.1468-0262.2007.00785.x; Engle RF, 2006, J ECONOMETRICS, V131, P3, DOI 10.1016/j.jeconom.2005.01.018; Forsberg L, 2007, J FINANC ECONOMET, V5, P31, DOI 10.1093/jjfinec/nbl010; Hjort NL, 2003, J AM STAT ASSOC, V98, P879, DOI 10.1198/016214503000000828; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Ghysels E, 2006, J ECONOMETRICS, V131, P59, DOI 10.1016/j.jeconom.2005.01.004; Buckland ST, 1997, BIOMETRICS, V53, P603, DOI 10.2307/2533961; BATES JM, 1969, OPER RES QUART, V20, P451, DOI 10.2307/3008764; Christoffersen PF, 1998, INT ECON REV, V39, P841, DOI 10.2307/2527341; BANDI FM, 2007, REALIZED VOLATILITY; Bandi FM, 2006, J FINANC ECON, V79, P655, DOI 10.1016/j.jfineco.2005.01.005; Barndorff-Nielsen OE, 2002, J APPL ECONOM, V17, P457, DOI 10.1002/jae.691; Barndorff-Nielsen O., 2002, J ROY STAT SOC, V63, P253; Barndorff-Nielsen O. E., 2006, J FINANCIAL ECONOMET, V4, P1; Barndorff-Nielsen O. E., 2004, J FINANCIAL ECONOMET, V2, P1, DOI DOI 10.1093/JJFINEC/NBH001; BLACK F., 1976, P AM STAT ASS BUS EC, P177; BOLLERSLEV T, 1986, J ECONOMETRICS, V31, P304; Breiman L, 1996, ANN STAT, V24, P2350; Brooks C, 2003, J FORECASTING, V22, P1, DOI 10.1002/for.841; BROWNLEES CT, 2008, 200803 WP U FIR DIP; BROWNLEES CT, 2007, 200702 WP U FIR DIP; Brownlees CT, 2006, COMPUT STAT DATA AN, V51, P2232, DOI 10.1016/j.csda.2006.09.030; Burnham K. P., 2002, MODEL SELECTION MULT; Christoffersen PF, 2000, REV ECON STAT, V82, P12, DOI 10.1162/003465300558597; Claeskens G, 2006, BIOMETRICS, V62, P972, DOI 10.1111/j.1541-0420.2006.00567.x; Corsi F., 2003, SIMPLE LONG MEMORY M; ENGLE RF, 1982, ECONOMETRICA, V50, P987, DOI 10.2307/1912773; GALLO G, 2007, 200701 WP U FIR DIP; Gallo G.M., 2001, AUST ECON PAP, V40, P567, DOI 10.1111/1467-8454.00142; Giacomini R, 2005, J BUS ECON STAT, V23, P416, DOI 10.1198/07350010500000018; Giot P., 2004, J EMPIR FINANC, V11, P379, DOI 10.1016/j.jempfin.2003.04.003; HANSEN BE, 2007, LEAST SQUARES FORECA; HANSEN BE, 2007, JACKKNIFE MODEL AVER; Hansen P. R., 2005, 200507 FED RES BANK; Hansen PR, 2005, J APPL ECONOM, V20, P873, DOI 10.1002/jae.800; Jones CM, 1998, J FINANC ECON, V47, P315, DOI 10.1016/S0304-405X(97)00047-0; Komunjer I, 2005, J ECONOMETRICS, V128, P137, DOI 10.1016/j.jeconom.2004.08.010; Koopman S. J., 2005, J EMPIR FINANC, V12, P445, DOI DOI 10.1016/J.JEMPFIN.2004.04.009; Kupiec P.H., 1995, J DERIV, V3, P73, DOI DOI 10.3905/JOD.1995.407942; LAMOUREUX CG, 1994, J BUS ECON STAT, V12, P253, DOI 10.2307/1391488; LAMOUREUX CG, 1990, J FINANC, V45, P221, DOI 10.2307/2328817; Leeb H, 2005, ECONOMET THEOR, V21, P21, DOI 10.1017/S0266466605050036; Lopez J.A., 1999, FEDERAL RESERVE BANK, V2, P3; Pacini B., 2000, EUROPEAN J FINANCE, V6, P163; PARKINSON M, 1980, J BUS, V53, P61, DOI 10.1086/296071; Pong SY, 2004, J BANK FINANC, V28, P2541, DOI 10.1016/j.jbankfin.2003.10.015; Poon SH, 2005, FINANC ANAL J, V61, P45, DOI 10.2469/faj.v61.n1.2683; Sarma M, 2003, J FORECASTING, V22, P337, DOI 10.1002/for.868; STOCK JH, 2006, EMPIRICAL COMP METHO; TAUCHEN GE, 1983, ECONOMETRICA, V51, P485, DOI 10.2307/1912002; Timmermann A, 2006, HBK ECON, V24, P135, DOI 10.1016/S1574-0706(05)01004-9	67	7	7	1	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1479-8409			J FINANC ECONOMET	J. Financ. Econom.	FAL	2008	6	4					513	539		10.1093/jjfinec/nbn012		27	Business, Finance; Economics	Business & Economics	356HX	WOS:000259770400004		
J	Radchenko, P; James, GM				Radchenko, Peter; James, Gareth M.			Variable Inclusion and Shrinkage Algorithms	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						Dantzig selector; Generalized linear model; Lasso; Variable selection	REGRESSION; LASSO; SELECTION	The Lasso is a popular and computationally efficient procedure for automatically performing both variable selection and coefficient shrinkage on linear regression models. Oner limitation of the Lasso is that the same tuning parameter is used for both variable selection and shrinkage. As a result, it typically ends up selecting a model with too many variables to prevent overshrinkage of the regression coefficients. we suggest an improved class of methods called variable inclusion and shrinkage algorithms (VISA). Our approach is capable of selecting sparse models while avoiding overshrinkage problems and uses a path algorithm, and so also is computationally efficient. We show through extensive simulations that VISA significantly outperforms the Lasso and also provides improvements over more recent procedures, such as the Dantzig selector, relaxed Lasso, and adaptive Lasso. In addition, we provide theoretical justification for VISA in terms of nonasymptotic bounds on the estimation error that suggest it should exhibit good performance even for large numbers of predictors. Finally, we extend the VISA methodolog, path algorithm, and the theoretical bounds to the generalized linear models framework.	[Radchenko, Peter; James, Gareth M.] Univ So Calif, Marshall Sch Business, Los Angeles, CA 90089 USA	Radchenko, P (reprint author), Univ So Calif, Marshall Sch Business, Los Angeles, CA 90089 USA.	peter.radchenko@marshall.usc.edu; gareth@marshall.usc.edu	Radchenko, Peter/E-2601-2015		National Science Foundation [DMS-0705312]	This work was supported in part by National Science Foundation grant DMS-0705312.	Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; BENNETT G, 1962, J AM STAT ASSOC, V57, P33, DOI 10.2307/2282438; FANG J, 2001, J AM STAT ASSOC, V96, P1348; JAMES GM, 2008, J ROYAL S B IN PRESS; JAMES GM, 2008, GEN DANTZIG SELECTOR; McCullagh P., 1989, GEN LINEAR MODELS; van de Geer S., 1999, EMPIRICAL PROCESSES; Zhao P, 2006, GROUPED HIERARCHICAL	16	25	25	0	2	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	SEP	2008	103	483					1304	1315		10.1198/016214508000000481		12	Statistics & Probability	Mathematics	362JJ	WOS:000260193700039		
J	Eklund, M; Spjuth, O; Wikberg, JES				Eklund, Martin; Spjuth, Ola; Wikberg, Jarl E. S.			The (CC2)-C-1: A framework for simultaneous model selection and assessment	BMC BIOINFORMATICS			English	Article							COMPETITIVE WORKFLOW; VARIABLE SELECTION; CROSS-VALIDATION; CANCER; QSAR; MICROARRAYS; PREDICTION; REGRESSION; QSPR	Background: There has been recent concern regarding the inability of predictive modeling approaches to generalize to new data. Some of the problems can be attributed to improper methods for model selection and assessment. Here, we have addressed this issue by introducing a novel and general framework, the (CC2)-C-1, for simultaneous model selection and assessment. The framework relies on a partitioning of the data in order to separate model choice from model assessment in terms of used data. Since the number of conceivable models in general is vast, it was also of interest to investigate the employment of two automatic search methods, a genetic algorithm and a brute-force method, for model choice. As a demonstration, the (CC2)-C-1 was applied to simulated and real-world datasets. A penalized linear model was assumed to reasonably approximate the true relation between the dependent and independent variables, thus reducing the model choice problem to a matter of variable selection and choice of penalizing parameter. We also studied the impact of assuming prior knowledge about the number of relevant variables on model choice and generalization error estimates. The results obtained with the (CC2)-C-1 were compared to those obtained by employing repeated K-fold cross-validation for choosing and assessing a model. Results: The (CC2)-C-1 framework performed well at finding the true model in terms of choosing the correct variable subset and producing reasonable choices for the penalizing parameter, even in situations when the independent variables were highly correlated and when the number of observations was less than the number of variables. The (CC2)-C-1 framework was also found to give accurate estimates of the generalization error. Prior information about the number of important independent variables improved the variable subset choice but reduced the accuracy of generalization error estimates. Using the genetic algorithm worsened the model choice but not the generalization error estimates, compared to using the brute-force method. The results obtained with repeated K-fold cross-validation were similar to those produced by the (CC2)-C-1 in terms of model choice, however a lower accuracy of the generalization error estimates was observed. Conclusion: The (CC2)-C-1 framework was demonstrated to work well for finding the true model within a penalized linear model class and accurately assess its generalization error, even for datasets with many highly correlated independent variables, a low observation-to-variable ratio, and model assumption deviations. A complete separation of the model choice and the model assessment in terms of data used for each task improves the estimates of the generalization error.	[Eklund, Martin; Spjuth, Ola; Wikberg, Jarl E. S.] Uppsala Univ, Dept Pharmaceut Pharmacol, BMC, SE-75124 Uppsala, Sweden	Eklund, M (reprint author), Uppsala Univ, Dept Pharmaceut Pharmacol, BMC, Box 591, SE-75124 Uppsala, Sweden.	martin.eklund@farmbio.uu.se; ola.spjuth@farmbio.uu.se; jarl.wikberg@farmbio.uu.se		Spjuth, Ola/0000-0002-8083-2864	Swedish VR [04X-05975]	Supported by the Swedish VR (04X-05975). We extend out gratitude to three anonymous reviewers who helped to improve this paper.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; KASS RE, 1995, J AM STAT ASSOC, V90, P928, DOI 10.2307/2291327; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; Cartmell J, 2007, CURR OPIN DRUG DISC, V10, P347; Cartmell J, 2005, J COMPUT AID MOL DES, V19, P821, DOI 10.1007/s10822-005-9029-8; Cho SJ, 2002, J CHEM INF COMP SCI, V42, P927, DOI 10.1021/ci010247v; Efron B, 1993, INTRO BOOTSTRAP; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; Freyhult E., 2005, BMC BIOINFORMATICS, V6, P1; Goldberg D. E., 1989, GENETIC ALGORITHMS S, P372; HANSCH C, 1969, ACCOUNTS CHEM RES, V2, P232, DOI 10.1021/ar50020a002; Hastie T, 2001, SPRINGER SERIES STAT, P533; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hvidsten TR, 2005, GENOME RES, V15, P856, DOI 10.1101/gr.3760605; *JAV, SOURC JAV DEV; *JGAP, JAV GEN ALG PACK; Johnson SR, 2008, J CHEM INF MODEL, V48, P25, DOI 10.1021/ci700332k; KONTIJEVSKIS A, 2007, PLOS COMPUTATIONAL B, V3; KUBINYI H, 1994, QUANT STRUCT-ACT REL, V13, P393, DOI 10.1002/qsar.19940130403; Kuha J, 2004, SOCIOL METHOD RES, V33, P188, DOI 10.1177/0049124103262065; Nicolotti O, 2006, J CHEM INF MODEL, V46, P264, DOI 10.1021/ci0502931; Ntzani EE, 2003, LANCET, V362, P1439, DOI 10.1016/S0140-6736(03)14686-7; Obrezanova O, 2008, J COMPUT AID MOL DES, V22, P431, DOI 10.1007/s10822-008-9193-8; SELWOOD DL, 1990, J MED CHEM, V33, P136, DOI 10.1021/jm00163a023; Shao J, 1997, STAT SINICA, V7, P221; Shimodaira H, 2004, ANN STAT, V32, P2616, DOI 10.1214/009053604000000823; SKURICHINA M, 2001, STABILIZING WEAK CLA; Spjuth O, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-59; STONE M, 1974, J R STAT SOC B, V36, P111; TODESCHINI R, 2004, ANAL CHIM ACTA, V515, P99; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; WASSERMAN L, 1999, MATH PSYCH S BLOOM I; Wikberg J.E., 2004, CHEMOGENOMICS DRUG D, P289, DOI 10.1002/3527603948.ch10; SELWOOD DATASET	40	10	10	0	1	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 2	2008	9								360	10.1186/1471-2105-9-360		13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	355XN	WOS:000259742800001	18761753	
J	Belitz, C; Lang, S				Belitz, Christiane; Lang, Stefan			Simultaneous selection of variables and smoothing parameters in structured additive regression models	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							BAYESIAN P-SPLINES; NONPARAMETRIC REGRESSION; PENALTIES; SHAPE	In recent years, considerable research has been devoted to developing complex regression models that can deal simultaneously with nonlinear covariate effects and time trends, unitor cluster specific heterogeneity, spatial heterogeneity and complex interactions between covariates of different types. Much less effort, however, has been devoted to model and variable selection. The paper develops a methodology for the simultaneous selection of variables and the degree of smoothness in regression models with a structured additive predictor. These models are quite general, containing additive (mixed) models, geoadditive models and varying coefficient models as special cases. This approach allows one to decide whether a particular covariate enters the model linearly or nonlinearly or is removed from the model. Moreover, it is possible to decide whether a spatial or cluster specific effect should be incorporated into the model to cope with spatial or cluster specific heterogeneity. Particular emphasis is also placed on selecting complex interactions between covariates and effects of different types. A new penalty for two-dimensional smoothing is proposed, that allows for ANOVA-type decompositions into main effects and an interaction effect without explicitly specifying the main effects. The penalty is an additive combination of other penalties. Fast algorithms and software are developed that allow one to even handle situations with many covariate effects and observations. The algorithms are related to backfitting and Markov chain Monte Carlo techniques, which divide the problem in a divide and conquer strategy into smaller pieces. Confidence intervals taking model uncertainty into account are based on the bootstrap in combination with MCMC techniques. (c) 2008 Elsevier B.V. All rights reserved.	[Lang, Stefan] Univ Innsbruck, Dept Stat, A-6020 Innsbruck, Austria; [Belitz, Christiane] Univ Munich, Dept Stat, D-80539 Munich, Germany	Lang, S (reprint author), Univ Innsbruck, Dept Stat, Univ Str 15, A-6020 Innsbruck, Austria.	christiane.belitz@stat.uni-muenchen.de; stefan.lang@uibk.ac.at	Lang, Stefan/E-7500-2010	Lang, Stefan/0000-0003-0739-3858			Rigby RA, 2005, J ROY STAT SOC C-APP, V54, P507, DOI 10.1111/j.1467-9876.2005.00510.x; Fahrmeir L, 2004, STAT SINICA, V14, P731; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Brezger A, 2006, COMPUT STAT DATA AN, V50, P967, DOI 10.1016/j.csda.2004.10.011; Fahrmeir L, 2001, J ROY STAT SOC C-APP, V50, P201, DOI 10.1111/1467-9876.00229; Shively TS, 1999, J AM STAT ASSOC, V94, P777, DOI 10.2307/2669990; Lang S, 2004, J COMPUT GRAPH STAT, V13, P183, DOI 10.1198/1061860043010; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; Efron B, 2004, ANN STAT, V32, P407; Bollaerts K, 2006, BRIT J MATH STAT PSY, V59, P451, DOI 10.1348/000711005X84293; HASTIE T, 1993, J ROY STAT SOC B MET, V55, P757; POLITIS DN, 1994, J AM STAT ASSOC, V89, P1303, DOI 10.2307/2290993; BELITZ C, 2007, THESIS; BRENT RP, 2003, ALGORITHMS MINIMIZAT; BREZGER A, 2005, BAYESX MANUALS; Brezger A, 2005, J STAT SOFTW, V14, P1; Buhlmann P, 2006, ANN STAT, V34, P559, DOI 10.1214/009053606000000092; Casella G, 2006, J AM STAT ASSOC, V101, P157, DOI 10.1198/016214505000000646; CHAMBERS JM, 1991, STAT MODELS S CHAPMA; CHEN ZH, 1993, J ROY STAT SOC B MET, V55, P473; de Boor C., 2001, PRACTICAL GUIDE SPLI; Diggle P., 2002, ANAL LONGITUDINAL DA; Eilers PHC, 2002, J COMPUT GRAPH STAT, V11, P758, DOI 10.1198/106186002844; Eilers PHC, 2003, CHEMOMETR INTELL LAB, V66, P159, DOI 10.1016/S0169-7439(03)00029-7; Fahrmeir L, 2007, REGRESSION MODELLE M; Fahrmeir L., 2001, MULTIVARIATE STAT MO, V2nd; Fotheringham AS., 2002, GEOGRAPHICALLY WEIGH; Gamerman D, 2003, COMPUT STAT DATA AN, V42, P513, DOI 10.1016/S0167-9473(02)00211-6; George A., 1981, COMPUTER SOLUTION LA; Gu C., 2002, SMOOTHING SPLINE ANO; Hastie T, 2003, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODELS; Hurvich CM, 1998, J ROY STAT SOC B, V60, P271, DOI 10.1111/1467-9868.00125; Jullion A, 2007, COMPUT STAT DATA AN, V51, P2542, DOI 10.1016/j.csda.2006.09.027; Kamman E. E., 2003, APPL STAT, V52, P1; Kandala NB, 2001, RES OFFICIAL STAT, V1, P81; Kauermann G, 2004, J COMPUT GRAPH STAT, V13, P66, DOI 10.1198/1061860043056; KAUERMANN G, 2006, KBI0609 KATH U LEUV; Lin JF, 1999, J POLYM RES-TAIWAN, V6, P1, DOI 10.1007/s10965-006-0065-4; Marx BD, 1998, COMPUT STAT DATA AN, V28, P193, DOI 10.1016/S0167-9473(98)00033-4; Miller A, 2002, SUBSET SELECTION REG, V2nd; Ruppert D., 2003, SEMIPARAMETRIC REGRE; Skrondal A., 2004, GEN LATENT VARIABLE; STASINOPOULOS M, 2005, INSTRUCTIONS USE GAM; Stone CJ, 1997, ANN STAT, V25, P1371; Tutz G, 2007, COMPUT STAT DATA AN, V51, P6044, DOI 10.1016/j.csda.2006.11.041; Verbeke G., 2000, LINEAR MIXED MODELS; WOOD S, 2004, CONFIDENCE INTERVALS; Wood SN, 2000, J ROY STAT SOC B, V62, P413, DOI 10.1111/1467-9868.00240; WOOD SN, 2006, R MANUAL MGCV PACKAG; Wood SN, 2003, J ROY STAT SOC B, V65, P95, DOI 10.1111/1467-9868.00374; Wood SN, 2006, GEN ADDITIVE MODELS; Wood SN, 2006, AUST NZ J STAT, V48, P445, DOI 10.1111/j.1467-842X.2006.00450.x; Yau P, 2003, J COMPUT GRAPH STAT, V12, P23, DOI 10.1198/1061860031301	54	25	25	1	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	SEP 15	2008	53	1					61	81		10.1016/j.csda.2008.05.032		21	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	355LM	WOS:000259710400005		
J	Zheng, SR				Zheng, Shurong			Selection of components and degrees of smoothing via lasso in high dimensional nonparametric additive models	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							PARAMETER-ESTIMATION; REGRESSION; SHRINKAGE	This paper proposes a procedure for selecting components and degrees of smoothing in high dimensional nonparametric additive models. In the procedure, different components have different penalties, and all the smoothing parameters in one component have the same penalties. The idea is similar to, but in fact different from, Wang et al.'s [Wang, H., Li, G.D., Tsai, C.L., 2007. Regression coefficient and autoregressive order shrinkage and selection via the lasso. journal of the Royal Statistical Society, Series B 69, 63-781 modified lasso, which requires different penalties for different parameters. The procedure obtains the sequence of components according to the importance of these components by Efron et al.'s [Efron, B., Hastie, T., Johnstone, I, Tibshirani, R., 2004. Least angle regression. Annals of Statistics 32, 407-489] LARS. CV or BIC selector can be used to select the tuning parameters in the procedure, where some asymptotic properties are proved. Some simulation results and two examples are used to illustrate the procedure. (c) 2008 Elsevier B.V. All rights reserved.	[Zheng, Shurong] NE Normal Univ, KLAS, Changchun, Jilin Province, Peoples R China; [Zheng, Shurong] NE Normal Univ, Sch Math & Stat, Changchun, Jilin Province, Peoples R China	Zheng, SR (reprint author), NE Normal Univ, KLAS, 5268 Renmin St, Changchun, Jilin Province, Peoples R China.	zhengsr@nenu.edu.cn			NSFC [10501005, 10701021, NENU-STC07001]	The author thanks the referees and the associate editor for their valuable comments and suggestions. The research is supported by NSFC grants 10501005, 10701021 and NENU-STC07001.	Aneiros-Perez G, 2004, ENVIRONMETRICS, V15, P675, DOI 10.1002/env.659; Knight K, 2000, ANN STAT, V28, P1356; Ruppert D, 2002, J COMPUT GRAPH STAT, V11, P735, DOI 10.1198/106186002853; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wood SN, 2004, J AM STAT ASSOC, V99, P673, DOI 10.1198/016214504000000980; Efron B, 2004, ANN STAT, V32, P407; FRIEDMAN JH, 1989, TECHNOMETRICS, V31, P3, DOI 10.2307/1270359; Ferraty F, 2003, COMPUT STAT DATA AN, V44, P161, DOI 10.1016/S0167-9473(03)00032-X; Ferraty F, 2006, NONPARAMETRIC FUNCTI; Ferraty F, 2002, COMPUTATION STAT, V17, P545, DOI 10.1007/s001800200126; GEYER CJ, 1996, ASYMPTOTICS CONVEX S; GU C, 1991, SIAM J SCI STAT COMP, V12, P383, DOI 10.1137/0912021; Hastie TJ, 1990, GEN ADDITIVE MODELS; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; Shao J, 1997, STAT SINICA, V7, P221; Tutz G, 2006, BIOMETRICS, V62, P961, DOI 10.1111/j.1541-0420.2006.00578.x; Wang HS, 2007, J AM STAT ASSOC, V102, P1039, DOI 10.1198/016214507000000509; Wang HS, 2007, J ROY STAT SOC B, V69, P63; Wood SN, 2000, J ROY STAT SOC B, V62, P413, DOI 10.1111/1467-9868.00240	19	2	2	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	SEP 15	2008	53	1					164	175		10.1016/j.csda.2008.06.022		12	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	355LM	WOS:000259710400013		
J	Read, D				Read, Dwight			AN INTERACTION MODEL FOR RESOURCE IMPLEMENT COMPLEXITY BASED ON RISK AND NUMBER OF ANNUAL MOVES	AMERICAN ANTIQUITY			English	Article							GREAT-BASIN; SETTLEMENT SYSTEMS; STRATEGIES; DEMOGRAPHY; MOBILITY; BOTSWANA; INTENSIFICATION; COMPETITION; EVOLUTION; CRITIQUE	Different hypotheses identifying factors affecting the complexity of implements used to obtain food resources by hunter-gatherer groups are assessed with regression analysis. A regression model based on interaction between growing season as a proxy measure for risk and number of yearly moves fits data on the complexity of implements for 20 hunter-gatherer groups. The interaction model leads to a division of hunter-gatherer groups into two subgroups that correspond to collector vs. forager strategies for procuring resources. Implications of the interaction model for the evolution of complex implements are discussed.	Univ Calif Los Angeles, Dept Anthropol, Los Angeles, CA 90095 USA	Read, D (reprint author), Univ Calif Los Angeles, Dept Anthropol, Los Angeles, CA 90095 USA.	dread@anthro.ucla.edu	Read, Dwight/I-2280-2014	Read, Dwight/0000-0003-3125-0769			BINFORD LR, 1980, AM ANTIQUITY, V45, P4, DOI 10.2307/279653; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; CASHDAN EA, 1985, MAN, V20, P454, DOI 10.2307/2802441; Henrich J, 2004, AM ANTIQUITY, V69, P197, DOI 10.2307/4128416; ROHDE K, 1992, OIKOS, V65, P514, DOI 10.2307/3545569; Shennan S, 2001, CAMB ARCHAEOL J, V11, P5; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Helgason A, 2006, AM J PHYS ANTHROPOL, V130, P123, DOI 10.1002/ajpa.20313; Balikci Asen, 1970, NETSILIK ESKIMO; Bamforth D., 1997, ARCHAEOLOGICAL PAPER, V7, P109, DOI 10.1525/ap3a.1997.7.1.109; BAMFORTH DB, 1986, AM ANTIQUITY, V51, P38, DOI 10.2307/280392; BARNARD A, 1979, SOCIAL ECOLOGICAL SY, P131; Bettinger RL, 2006, J ARCHAEOL SCI, V33, P538, DOI 10.1016/j.jas.2005.09.009; BETTINGER RL, 1978, J ANTHROPOL RES, V34, P27; BETTINGER RL, 1982, AM ANTIQUITY, V47, P485, DOI 10.2307/280231; BETTINGER RL, 2001, HUNTER GATHERERS ARC; Binford L.R., 1983, PURSUIT DECODING ARC; BINFORD LR, 1990, J ANTHROPOL RES, V46, P119; Binford LR, 2001, CONSTRUCTING FRAMES; BLECK DF, 1928, NARON BUSHMAN TRIBE; Bleed P., 1996, LITHIC TECHNOLOGY, V21, P95; BLEED P, 1991, AM ANTIQUITY, V56, P19, DOI 10.2307/280969; BONNICHSEN R, 1977, NAT MUSEUM MAN MERCU, V60; Bousman C.B., 1993, LITHIC TECHNOLOGY, V18, P59; Bousman CB, 2005, J ANTHROPOL ARCHAEOL, V24, P193, DOI 10.1016/j.jaa.2005.05.001; Butzer K., 1988, GEOARCHAEOLOGY, V3, P193, DOI 10.1002/gea.3340030303; Caran SC, 1998, PLAINS ANTHROPOL, V43, P111; CASHDAN E, 1986, AFRICA, V56, P299, DOI 10.2307/1160686; CASHDAN EA, 1987, MAN, V22, P121; Churchill SE, 1993, ARCHAEOLOGICAL PAPER, V4, P11, DOI [10.1525/ap3a.1993.4.1.11, DOI 10.1525/AP3A.1993.4.1.11]; CIA L, 2007, ARCHAEOL ANTHROP SCI, P198; Collard M., 2005, CANADIAN J ARCHAEOLO, V29, P1; Crown Patricia L, 2002, CHILDREN PREHISTORIC, P108; DAMAS D, 1969, ANN REPORT NATL MUSE, V230, P40; Ebert J., 1979, ETHNOARCHAEOLOGY IMP, P59; Eerkens JW, 2004, AM ANTIQUITY, V69, P653, DOI 10.2307/4128442; EFRON B, 2003, LEAST ANGLE REGRESSI; Goody EN, 1989, APPRENTICESHIP THEOR, P233; GUENTHER M, 1986, NIHARO BUSHMEN BOTSW; Hastie T., 2001, ELEMENTS STAT LEARNI; HAYDEN B, 1988, LITHIC TECHNOLOGY, V17, P12; Henrich J, 2006, AM ANTIQUITY, V71, P771; HISCOCK P, 1994, J WORLD PREHIST, V8, P267, DOI 10.1007/BF02221051; HITCHCOCK RK, 1982, THESIS U NEW MEXICO; HITCHCOCK RK, 1989, ANTHROPOS, V84, P47; Ingold T., 1988, HUNTERS GATHERERS HI, P161; JENNESS D, 1946, MAT CULTURE C ESKIMO, V16; JENNESS D, 1922, LIFE C ESKIMOS REPOR, V12; Jochim M. A., 1981, STRATEGIES SURVIVAL; Kelly R, 1995, FORAGING SPECTRUM; KELLY RL, 1983, J ANTHROPOL RES, V39, P277; KUHN SL, 2000, HUNTER GATHERERS INT, P99; MARQUARDT WH, 1984, DEP ANTHR MISCELLANE, V22; Marquardt William, 1986, SE ARCHAEOLOGY, V5, P63; Mathiassen T, 1930, AM ANTHROPOL, V32, P591, DOI 10.1525/aa.1930.32.4.02a00020; McKinney M. L., 2007, ENV SCI SYSTEMS SOLU, V4; Miller A, 2002, SUBSET SELECTION REG, V2nd; Myers A., 1989, TIME ENERGY STONE TO, P78; Nelson M. C., 1996, EVOLVING COMPLEXITY, P107; OSBORN AJ, 1999, FOLSOM LITHIC TECHNO, P188; OSGOOD C, 1933, AM ANTHROPOL, V35, P695, DOI 10.1525/aa.1933.35.4.02a00070; Oswalt W. H., 1973, HABITAT TECHNOLOGY E; Oswalt WH, 1976, ANTHR ANAL FOOD GETT; Park RW, 1997, AM ANTIQUITY, V62, P273, DOI 10.2307/282510; Peck JR, 1997, GENETICS, V145, P1171; READ D, 1987, QUANTITATIVE RES ARC, P151; Read D, 2005, CYBERNET SYST, V36, P773, DOI 10.1080/01969720500306253; READ D, 2007, ARCHAEOLOGICAL CLASS; Read D, 2006, AM ANTIQUITY, V71, P164; Read DW, 2003, CURR ANTHROPOL, V44, P59, DOI 10.1086/344616; ROWLEYCONWY P, 2008, BAD YEAR EC CULTURAL, P40; SHOTT M, 1986, J ANTHROPOL RES, V42, P15; Spencer Robert F, 1959, BUREAU AM ETHNOLOGY, V171; Steward J. H., 1938, BUREAU AM ETHNOLOGY, V120; STEWARD JH, 1933, U CALIFORNIA PUBLI 3, V33; THALBITZER W, 1941, MEDDELELSER GRONLAND, V40, P565; TORRENCE R, 1983, BAD YEAR EC CULTURAL, P11; Torrence R, 2001, BIOSOCIAL S, V13, P73; Torrence R., 1989, TIME ENERGY STONE TO, P57; VIERRA BJ, 1995, SUBSISTENCE STONE TO; Widmer R.J., 1988, EVOLUTION CALUSA NON; Wiessner P, 1977, THESIS U MICHIGAN; Wiessner P., 1982, POLITICS HIST BAND S, P61	83	15	16	2	5	SOC AMER ARCHAEOLOGY	WASHINGTON	900 SECOND ST., NE  STE 12, WASHINGTON, DC 20002-3557 USA	0002-7316			AM ANTIQUITY	Am. Antiq.	OCT	2008	73	4					599	625				27	Anthropology; Archaeology	Anthropology; Archaeology	369PW	WOS:000260707400002		
J	Valavanis, VD; Pierce, GJ; Zuur, AF; Palialexis, A; Saveliev, A; Katara, I; Wang, JJ				Valavanis, Vasilis D.; Pierce, Graham J.; Zuur, Alain F.; Palialexis, Andreas; Saveliev, Anatoly; Katara, Isidora; Wang, Jianjun			Modelling of essential fish habitat based on remote sensing, spatial analysis and GIS	HYDROBIOLOGIA			English	Review						marine species; statistical modelling; fisheries; environment; ecology	ADAPTIVE REGRESSION SPLINES; RESOURCE SELECTION FUNCTIONS; GENERALIZED ADDITIVE-MODELS; ARTIFICIAL NEURAL-NETWORKS; SPECIES DISTRIBUTIONS; CLIMATE-CHANGE; NEW-ZEALAND; CEPHALOPOD FISHERIES; QUANTILE REGRESSION; EMPIRICAL-MODELS	We review the variety of existing modelling approaches applied to species habitat mapping and we discuss issues arising from the availability and nature of sampled biological data and corresponding ecological and environmental habitat descriptors, as well as the different spatial analysis approaches that are selected according to specific hypotheses. We focus on marine species habitat mapping, presenting an overview of work on modelling fish habitat carried out through a European Communities Policy-Support Action, EnviEFH 'Environmental Approach to Essential Fish Habitat (EFH) Designation' (2005-2008). The selection of the appropriate habitat model is dataset-specific and the resulting EFH maps are often similar in spite of using different models. Derived EFH maps are based on either environmental ranges (used as minimum and maximum environmental habitat descriptors) or probability of occurrence values. We apply model outputs to regions larger than sampled areas making use of the capacity of satellite data to cover wide areas.	[Valavanis, Vasilis D.; Palialexis, Andreas] Hellen Ctr Marine Res, Inst Marine Biol Resources, Marine GIS Lab, Thalassocosmos 71003, Heraklion Crete, Greece; [Pierce, Graham J.] Inst Espanol Oceanog, Ctr Oceanog Vigo, Vigo 36200, Spain; [Zuur, Alain F.] Highland Stat Ltd, Newburgh AB41 6FN, Scotland; [Saveliev, Anatoly] Kazan VI Lenin State Univ, Fac Geog & Ecol, Kazan 420008, Russia; [Pierce, Graham J.; Katara, Isidora; Wang, Jianjun] Univ Aberdeen, Sch Biol Sci Zool, Aberdeen AB24 2TX, Scotland	Valavanis, VD (reprint author), Hellen Ctr Marine Res, Inst Marine Biol Resources, Marine GIS Lab, Thalassocosmos 71003, Heraklion Crete, Greece.	vasilis@her.hcmr.gr	Valavanis, Vasilis/G-8869-2011; 	Pierce, Graham/0000-0002-4744-4501			AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Stockwell D, 1999, INT J GEOGR INF SCI, V13, P143, DOI 10.1080/136588199241391; Olden JD, 2002, FRESHWATER BIOL, V47, P1976, DOI 10.1046/j.1365-2427.2002.00945.x; Ullman DS, 2000, J ATMOS OCEAN TECH, V17, P1667, DOI 10.1175/1520-0426(2000)017<1667:EOFDMF>2.0.CO;2; Cade BS, 1999, ECOLOGY, V80, P311; Guisan A, 2000, ECOL MODEL, V135, P147, DOI 10.1016/S0304-3800(00)00354-9; LEGENDRE P, 1993, ECOLOGY, V74, P1659, DOI 10.2307/1939924; Araujo MB, 2005, GLOBAL ECOL BIOGEOGR, V14, P529, DOI 10.1111/j.1466-822x.2005.00182.x; Olivier F, 2005, ECOL MODEL, V189, P105, DOI 10.1016/j.ecolmodel.2005.04.009; Nishida T, 2004, FISH RES, V70, P265, DOI 10.1016/j.fishres.2004.08.008; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; CARPENTER G, 1993, BIODIVERS CONSERV, V2, P667, DOI 10.1007/BF00051966; Cade BS, 2003, FRONT ECOL ENVIRON, V1, P412, DOI 10.2307/3868138; Francis MP, 2005, ESTUAR COAST SHELF S, V64, P419, DOI 10.1016/j.ecss.2005.03.007; Friedman JH, 2003, STAT MED, V22, P1365, DOI 10.1002/sim.1501; Keitt TH, 2002, ECOGRAPHY, V25, P616, DOI 10.1034/j.1600-0587.2002.250509.x; Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644; Leathwick JR, 2006, MAR ECOL PROG SER, V321, P267, DOI 10.3354/meps321267; Loehle C, 1996, ECOL MODEL, V90, P1, DOI 10.1016/0304-3800(96)83709-4; Perry AL, 2005, SCIENCE, V308, P1912, DOI 10.1126/science.1111322; Boyce MS, 2002, ECOL MODEL, V157, P281, DOI 10.1016/S0304-3800(02)00200-4; Jaberg C, 2001, J APPL ECOL, V38, P1169, DOI 10.1046/j.0021-8901.2001.00668.x; Dormann CF, 2007, ECOGRAPHY, V30, P609, DOI 10.1111/j.2007.0906-7590.05171.x; Austin M, 2007, ECOL MODEL, V200, P1, DOI 10.1016/j.ecolmodel.2006.07.005; Guisan A, 2002, ECOL MODEL, V157, P89, DOI 10.1016/S0304-3800(02)00204-1; Segurado P, 2004, J BIOGEOGR, V31, P1555, DOI 10.1111/j.1365-2699.2004.01076.x; Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7; Heikkinen RK, 2006, PROG PHYS GEOG, V30, P751, DOI 10.1177/0309133306071957; Brotons L, 2004, ECOGRAPHY, V27, P437, DOI 10.1111/j.0906-7590.2004.03764.x; Eastwood PD, 2001, MAR ECOL PROG SER, V224, P251, DOI 10.3354/meps224251; Moisen GG, 2002, ECOL MODEL, V157, P209, DOI 10.1016/S0304-3800(02)00197-7; Wagner HH, 2005, ECOLOGY, V86, P1975, DOI 10.1890/04-0914; Laurel BJ, 2007, MAR ECOL PROG SER, V338, P183, DOI 10.3354/meps338183; EFRON B, 1991, SCIENCE, V253, P390, DOI 10.1126/science.253.5018.390; Phillips SJ, 2006, ECOL MODEL, V190, P231, DOI 10.1016/j.ecolmodel.2005.03.026; Johnson JB, 2004, TRENDS ECOL EVOL, V19, P101, DOI 10.1016/j.tree.2003.10.013; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Hiddink JG, 2005, ECOGRAPHY, V28, P264, DOI 10.1111/j.0906-7590.2005.04063.x; Munoz J, 2004, J VEG SCI, V15, P285, DOI 10.1658/1100-9233(2004)015[0285:COSMCU]2.0.CO;2; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Hirzel AH, 2001, ECOL MODEL, V145, P111, DOI 10.1016/S0304-3800(01)00396-9; Elith J, 2006, ECOGRAPHY, V29, P129, DOI 10.1111/j.2006.0906-7590.04596.x; Zaniewski AE, 2002, ECOL MODEL, V157, P261, DOI 10.1016/S0304-3800(02)00199-0; Leathwick JR, 2006, ECOL MODEL, V199, P188, DOI 10.1016/j.ecolmodel.2006.05.022; Austin M. P., 1991, NATURE CONSERVATION, P31; AUSTIN MP, 1989, BIOL CONSERV, V50, P13, DOI 10.1016/0006-3207(89)90003-7; Behrouz A. N., 2006, RIVER RES APPL, V22, P503; BISHOP CM, 1997, NEURAL NETWORKS PATT, P484; BLACKBURN TM, 1992, OIKOS, V65, P107, DOI 10.2307/3544892; Bourg NA, 2005, ECOLOGY, V86, P2793, DOI 10.1890/04-1666; Brosse S, 1999, ECOL MODEL, V120, P299, DOI 10.1016/S0304-3800(99)00110-6; BUCKLAND ST, 1993, J APPL ECOL, V30, P478, DOI 10.2307/2404188; Busby J., 1991, NATURE CONSERVATION, P64; Cade BS, 2005, ECOLOGY, V86, P786, DOI 10.1890/04-0785; Capen D.E., 1986, P171; CLARK SJ, 2005, ECOL LETT, V8, P2; DECOURSEY DG, 1992, WEED TECHNOL, V6, P709; Dettki H, 2003, AMBIO, V32, P549, DOI 10.1639/0044-7447(2003)032[0549:MHSFMI]2.0.CO;2; Elith J, 2002, PREDICTING SPECIES OCCURRENCES: ISSUES OF ACCURACY AND SCALE, P303; *ESRI, 1994, ARC MACR LANG ENV SY, P3; Ferguson MC, 2006, ECOL MODEL, V193, P645, DOI 10.1016/j.ecolmodel.2005.10.034; Ferrier S, 1997, EVALUATION EFFECTIVE; Fotheringham AS., 2002, GEOGRAPHICALLY WEIGH; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; GIANNOULAKI MA, 2006, SPATIAL MODELLING EU, P11; Harrell Jr Frank E., 2001, REGRESSION MODELLING; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODELS; Hirzel A, 2002, ECOL MODEL, V157, P331, DOI 10.1016/S0304-3800(02)00203-X; Hirzel AH, 2003, ENVIRON MANAGE, V32, P614, DOI 10.1007/s00267-003-0040-3; Huisman J, 2002, ECOL RES, V17, P175, DOI 10.1046/j.1440-1703.2002.00477.x; KAISER MS, 1994, J AM STAT ASSOC, V89, P410, DOI 10.2307/2290841; KOHONEN T, 1996, SELF ORGANIZING MAPS, P428; Korzukhin MD, 1996, CAN J FOREST RES, V26, P879, DOI 10.1139/x26-096; Kuhn T., 1996, STRUCTURE SCI REVOLU; Lakatos I., 1970, CRITICISM GROWTH KNO, P91; Lawler JJ, 2004, LANDSCAPE ECOL, V19, P515, DOI 10.1023/B:LAND.0000036151.28327.01; Leathwick JR, 2005, FRESHWATER BIOL, V50, P2034, DOI 10.1111/j.1365-2427.2005.01448.x; Legendre P., 1998, NUMERICAL ECOLOGY; Lehmann A, 2002, ECOL MODEL, V157, P189, DOI 10.1016/S0304-3800(02)00195-3; LEVINS R, 1966, AM SCI, V54, P421; LI J, ECOLOGICAL IN PRESS; LUTCHMAN I, 2003, ACHIEVING SUSTAINABL, P31; MacLeod CD, 2008, HYDROBIOLOGIA, V612, P21, DOI 10.1007/s10750-008-9491-0; Maggini R, 2006, J BIOGEOGR, V33, P1729, DOI 10.1111/j.1365-2699.2006.01465.x; MALLER RA, 1990, J CONSEIL, V46, P140; Manel S, 1999, J APPL ECOL, V36, P734, DOI 10.1046/j.1365-2664.1999.00440.x; Maravelias CD, 2007, FISH OCEANOGR, V16, P294, DOI 10.1111/j.1365-2419.2006.00421.x; McCullagh P., 1989, GEN LINEAR MODELS; Morrell LJ, 2008, BEHAV ECOL, V19, P193, DOI 10.1093/beheco/arm122; Pickett S. T. A., 1994, ECOLOGICAL UNDERSTAN; Pierce GJ, 2002, B MAR SCI, V71, P35; Pierce GJ, 2001, INT J GEOGR INF SCI, V15, P763, DOI 10.1080/13658810110074500; PIERCE GJ, 2008, HYDROBIOLOGIA; Pollock JF, 2006, CONSERV BIOL, V20, P882, DOI 10.1111/j.1523-1739-2006.00342.x; Popper Karl R., 1963, GROWTH SCI KNOWLEDGE; PRENTICE IC, 1986, FOREST DYNAMICS RES, P32; Redfern JV, 2006, MAR ECOL PROG SER, V310, P271, DOI 10.3354/meps310271; Ripley B. D., 1996, PATTERN RECOGN, P416; Rubio G, 2003, AM J BOT, V90, P143, DOI 10.3732/ajb.90.1.143; Rushton SP, 2004, J APPL ECOL, V41, P193, DOI 10.1111/j.0021-8901.2004.00903.x; Shipley B, 1999, OIKOS, V86, P374, DOI 10.2307/3546455; STOCKWELL DRB, 1992, THESIS AUSTR NATL U; Thomson JD, 1996, ECOLOGY, V77, P1698, DOI 10.2307/2265776; Valavanis VD, 2002, B MAR SCI, V71, P867; Valavanis VD, 2004, ECOL MODEL, V178, P417, DOI 10.1016/j.ecolmodel.2004.02.015; Valavanis VD, 2005, INT J GEOGR INF SCI, V19, P1131, DOI 10.1080/13658810500391206; Wood SN, 2006, GEN ADDITIVE MODELS; Wright S, 1921, J AGR RES, V20, P557; Zuur A. F., 2007, SPRINGER SERIES STAT	110	51	52	9	55	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0018-8158			HYDROBIOLOGIA	Hydrobiologia	OCT	2008	612						5	20		10.1007/s10750-008-9493-y		16	Marine & Freshwater Biology	Marine & Freshwater Biology	333LK	WOS:000258153800002		
J	Jensen, AC; Berge, A; Solberg, AS				Jensen, Are C.; Berge, Asbjorn; Solberg, Anne Schistad			Regression Approaches to Small Sample Inverse Covariance Matrix Estimation for Hyperspectral Image Classification	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article; Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 23-27, 2007	Barcelona, SPAIN	IEEE		Cholesky decomposition; covariance parameterization; hyperspectral image classification; pattern classification; precision matrix; regularization; sparse regression	MAXIMUM-LIKELIHOOD CLASSIFICATION; DISCRIMINANT-ANALYSIS; LONGITUDINAL DATA; SELECTION; MODELS	A key component in most parametric classifiers is the estimation of an inverse covariance matrix. In hyperspectral images, the number of bands can be in the hundreds, leading to covariance matrices having tens of thousands of elements. Lately, the use of linear regression in estimating the inverse covariance matrix has been introduced in the time-series literature. This paper adopts and expands these ideas to ill-posed hyperspectral image classification problems. The results indicate that at least some of the approaches can give a lower classification error than traditional methods such as the linear discriminant analysis and the regularized discriminant analysis. Furthermore, the results show that, contrary to earlier beliefs, estimating long-range dependencies between bands appears necessary to build an effective hyperspectral. classifier and that the high correlations between neighboring bands seem to allow differing sparsity configurations of the inverse covariance matrix to obtain similar classification results.	[Jensen, Are C.; Solberg, Anne Schistad] Univ Oslo, Dept Informat, Digital Signal Proc & Image Anal Grp, N-0316 Oslo, Norway; [Berge, Asbjorn] SINTEF ICT, N-0373 Oslo, Norway	Jensen, AC (reprint author), Univ Oslo, Dept Informat, Digital Signal Proc & Image Anal Grp, N-0316 Oslo, Norway.	arej@ifi.uio.no					HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481; Pourahmadi M, 1999, BIOMETRIKA, V86, P677, DOI 10.1093/biomet/86.3.677; Berger AN, 2007, J SMALL BUS MANAGE, V45, P5, DOI 10.1111/j.1540-627X.2007.00195.x; BICKEL PJ, 2007, ANN STAT, V36, P199; Bruzzone L, 2001, IEEE T GEOSCI REMOTE, V39, P456, DOI 10.1109/36.905255; Chang C., 2001, LIBSVM LIB SUPPORT V; Chi MM, 2007, IEEE T GEOSCI REMOTE, V45, P1870, DOI 10.1109/TGRS.2007.894550; Duda R.O., 2000, PATTERN CLASSIFICATI; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GAMBA P, 2004, P IGARSS, P69; Hastie T., 2001, ELEMENTS STAT LEARNI; Hoffsis GF, 1996, COMP CONT EDUC PRACT, V18, P7; Huang JHZ, 2007, J COMPUT GRAPH STAT, V16, P189, DOI 10.1198/106186007X181452; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; JIA XP, 1994, IEEE T GEOSCI REMOTE, V32, P274; Krzanowski WJ, 1999, J APPL STAT, V26, P59, DOI 10.1080/02664769922656; LEVINA E, 2006, 459 UMICH DEP STAT; Roger RE, 1996, INT J REMOTE SENS, V17, P589; Schulerud H, 2004, COMPUT METH PROG BIO, V73, P91, DOI 10.1016/S0169-2607(03)00018-X; Solberg AHS, 1999, IEEE T GEOSCI REMOTE, V37, P1234, DOI 10.1109/36.763280; Whittaker J, 1990, GRAPHICAL MODELS APP	26	9	9	1	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	OCT	2008	46	10	1				2814	2822		10.1109/TGRS.2008.2001169		9	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	359PJ	WOS:000260000300006		
J	Zdunek, R; Cichocki, A				Zdunek, Rafal; Cichocki, Andrzej			Improved M-FOCUSS algorithm with overlapping blocks for locally smooth sparse signals	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						FOCal Underdetermined System Solver (FOCUSS); generalized cross-validation (GCV); smooth signals; sparse solutions; underdetermined systems	BLIND SOURCE SEPARATION; DICTIONARY LEARNING ALGORITHMS; MORPHOLOGICAL DIVERSITY; APPROXIMATE SOLUTIONS; IMAGE-RESTORATION; BASIS SELECTION; REPRESENTATION; RECONSTRUCTION; MINIMIZATION; SYSTEMS	The FOCal Underdetermined System Solver (FOCUSS) algorithm has already found many applications in signal processing and data analysis, whereas the regularized M-FOCUSS algorithm has been recently proposed by Cotter et al. for finding sparse solutions to an underdetermined system of linear equations with multiple measurement vectors. In this paper, we propose three modifications to the M-FOCUSS algorithm to make it more efficient for sparse and locally smooth solutions. First, motivated by the simultaneously autoregressive (SAR) model, we incorporate an additional weighting (smoothing) matrix into the Tikhonov regularization term. Next, the entire set of measurement vectors is divided into blocks, and the solution is updated sequentially, based on the overlapping of data blocks. The last modification is based on an alternating minimization technique to provide data-driven (simultaneous) estimation of the regularization parameter with the generalized cross-validation (GCV) approach. Finally, the simulation results demonstrating the benefits of the proposed modifications support the analysis.	[Zdunek, Rafal; Cichocki, Andrzej] RIKEN, Brain Res Inst, Lab Adv Brain Signal Proc, Wako, Saitama 3510198, Japan; [Zdunek, Rafal] Wroclaw Univ Technol, Inst Telecommun Teleinformat & Acoust, PL-50370 Wroclaw, Poland; [Cichocki, Andrzej] Polish Acad Sci PAN, IBS, PL-01447 Warsaw, Poland; [Cichocki, Andrzej] Warsaw Univ Technol, PL-00661 Warsaw, Poland	Zdunek, R (reprint author), RIKEN, Brain Res Inst, Lab Adv Brain Signal Proc, 2-1 Hirosawa, Wako, Saitama 3510198, Japan.	rafal.zdunek@pwr.wroc.pl; cia@brain.riken.jp	Zdunek, Rafal/A-3959-2008; Cichocki, Andrzej/A-1545-2015; 	Zdunek, Rafal/0000-0003-3323-6717			ALLINEY S, 1994, IEEE T SIGNAL PROCES, V42, P618, DOI 10.1109/78.277854; ALLINEY S, 1992, IEEE T SIGNAL PROCES, V40, P1548, DOI 10.1109/78.139258; Amari S., 2003, ADAPTIVE BLIND SIGNA; Bobin J, 2007, IEEE T IMAGE PROCESS, V16, P2662, DOI 10.1109/TIP.2007.906256; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Rao BD, 2003, IEEE T SIGNAL PROCES, V51, P760, DOI 10.1109/TSP.2002.808076; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Li YQ, 2006, IEEE T SIGNAL PROCES, V54, P423, DOI 10.1109/TSP.2005.861743; Duttweiler DL, 2000, IEEE T SPEECH AUDI P, V8, P508, DOI 10.1109/89.861368; WAHBA G, 1977, SIAM J NUMER ANAL, V14, P651, DOI 10.1137/0714044; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Engan K, 2007, DIGIT SIGNAL PROCESS, V17, P32, DOI 10.1016/j.dsp.2006.02.002; Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016; Xu P, 2007, IEEE T BIO-MED ENG, V54, P400, DOI 10.1109/TBME.2006.886640; Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031; Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Efron B, 2004, ANN STAT, V32, P407; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Chen J, 2006, IEEE T SIGNAL PROCES, V54, P4634, DOI 10.1109/TSP.2006.881263; Besag J., 1989, J APPL STAT, V16, P395, DOI 10.1080/02664768900000049; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BJORCK A, 1996, NUMERICAL METHODS LE; BOBIN J, 2007, P SPIE, V6701; Bobin J, 2006, IEEE SIGNAL PROC LET, V13, P409, DOI 10.1109/LSP.2006.873141; Bobin J, 2007, LECT NOTES COMPUT SC, V4666, P349; Chen P., 2006, P INT C POWERCON CHO, P1; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Cichocki A, 2005, P SOC PHOTO-OPT INS, V5818, P11, DOI 10.1117/12.606876; Cotter RJ, 2005, J MASS SPECTROM SOC, V53, P7; Davies M., 2003, P INT IEEE WASPAA NE, P107; Davies ME, 2006, SIGNAL PROCESS, V86, P457, DOI 10.1016/j.sigpro.2005.05.024; Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430; DEVORE RA, 1996, ADV COMPUT MATH, V12, P213; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; DONOHO DL, 1989, SIAM J APPL MATH, V49, P906, DOI 10.1137/0149053; DONOHO DL, 1992, SIAM J APPL MATH, V52, P571; DONOHO DL, 1992, SIAM J MATH ANAL, V23, P1309, DOI 10.1137/0523074; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Fadili JM, 2005, IEEE T SIGNAL PROCES, V53, P3436, DOI 10.1109/TSP.2005.853207; Forsythe G. E., 1976, COMPUTER METHODS MAT; Galatsanos NP, 2000, IEEE T IMAGE PROCESS, V9, P1784, DOI 10.1109/83.869189; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; GORODNITSKY IF, 1993, P IEEE INT C AC SPEE, V3, P1331; GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985; GRIBONVAL R, 2002, P IEEE INT C AC SPEE, V3, P3057; HAN J, 1993, P 26 ANN INT C IEEE, V1, P122; Hansen P., 1998, RANK DEFICIENT DISCR; Hansen P. C., 1994, Numerical Algorithms, V6, DOI 10.1007/BF02149761; Herrity K. K., 2006, P IEEE INT C AC SPEE, V3, P624; Huggins PS, 2007, IEEE T SIGNAL PROCES, V55, P3760, DOI 10.1109/TSP.2007.894287; Im CH, 2007, IEEE T MAGN, V43, P1709, DOI 10.1109/TMAG.2006.892282; Jeffs B. D., 1998, P ICASSP, P1885, DOI 10.1109/ICASSP.1998.681832; Jeffs BD, 1993, IEEE T IMAGE PROCESS, V2, P202, DOI 10.1109/83.217223; Karlovitz L. A., 1970, J APPROXIMATION THEO, V37, P123, DOI 10.1016/0021-9045(70)90019-5; Kreutz-Delgado K, 2000, P SOC PHOTO-OPT INS, V4119, P459, DOI 10.1117/12.408634; Lesage S., 2005, P IEEE INT C AC SPEE, V5, P293, DOI 10.1109/ICASSP.2005.1416298; Li Y., 2003, P 4 INT S IND COMP A, P89; Li YQ, 2004, NEURAL COMPUT, V16, P1193, DOI 10.1162/089976604773717586; Liu HS, 2005, IEEE T BIO-MED ENG, V52, P1681, DOI 10.1109/TBME.2005.855720; Lopez JM, 2002, THEOR COMP FLUID DYN, V16, P3, DOI 10.1007/s00162-002-0062-0; Molina R, 1999, IEEE T IMAGE PROCESS, V8, P231, DOI 10.1109/83.743857; Moran JE, 2005, BRAIN TOPOGR, V18, P1, DOI 10.1007/s10548-005-7896-x; MURRAY JF, 2001, 35 AS C SIGN SYST CO, V1, P347; Murray JF, 2006, J VLSI SIG PROC SYST, V45, P97, DOI 10.1007/s11265-006-9774-5; Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Pati Y. C., 1993, P 27 AS C SIGN SYST, V1, P40, DOI DOI 10.1109/ACSSC.1993.342465; Phillips JW, 1997, IEEE T MED IMAGING, V16, P338, DOI 10.1109/42.585768; Rao B. D., 1997, P 31 AS C SIGN SYST, V1, P955; RAO BD, 1996, P 30 AS C SIGN SYST, V2, P1218; RAO BD, 2004, P IEEE INT C AC SPEE, V2, P369; Ripley B. D., 1981, SPATIAL STAT; RYEN T, 2001, P 2 INT S IM SIGN PR, P541; SAMENI R, 2007, EURASIP J A IN PRESS; SIMILA T, 2007, P IEEE INT C AC SPEE, V2, P553; SKRETTING K, 2002, THESIS NORWEGIAN U S; Skretting K, 2006, SIGNAL PROCESS, V86, P117, DOI 10.1016/j.sigpro.2005.04.013; Takigawa I, 2004, IEEE T SIGNAL PROCES, V52, P582, DOI 10.1109/TSP.2003.822284; WHITTLE P, 1954, BIOMETRIKA, V41, P434; Wipf D. P., 2005, ADV NEURAL INFORM PR; Zhang GM, 2006, ULTRASONICS, V45, P82, DOI 10.1016/j.ultras.2006.07.005; Zibulevsky M, 2001, NEURAL COMPUT, V13, P863, DOI 10.1162/089976601300014385	85	13	15	3	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-587X			IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	OCT	2008	56	10	1				4752	4761		10.1109/TSP.2008.928160		10	Engineering, Electrical & Electronic	Engineering	351EM	WOS:000259407300018		
J	Bai, J; Ng, S				Bai, Jushan; Ng, Serena			Forecasting economic time series using targeted predictors	JOURNAL OF ECONOMETRICS			English	Article; Proceedings Paper	Conference held in honor of Charles R Nelson	MAR 31-APR 01, 2006	Atlanta, GA	Fed Reserve Bank Atlanta		Diffusion index; Factor models; LASSO; LARS; Hard thresholding	VARIABLE SELECTION; PRINCIPAL COMPONENTS; REGRESSIONS; INFLATION; SHRINKAGE; LASSO	This paper studies two refinements to the method of factor forecasting. First, we consider the method of quadratic principal components that allows the link function between the predictors and the factors to be non-linear. Second, the factors used in the forecasting equation are estimated in a way to take into account that the goal is to forecast a specific series. This is accomplished by applying the method of principal components to 'targeted predictors' selected using hard and soft thresholding rules. Our three main findings can be summarized as follows. First, we find improvements at all forecast horizons over the current diffusion index forecasts by estimating the factors using fewer but informative predictors. Allowing for non-linearity often leads to additional gains. Second, forecasting the volatile one month ahead inflation warrants a high degree of targeting to screen out the noisy predictors. A handful of variables, notably relating to housing starts and interest rates, are found to have systematic predictive power for inflation at all horizons. Third, the targeted predictors selected by both soft and hard thresholding changes with the forecast horizon and the sample period. Holding the set of predictors fixed as is the current practice of factor forecasting is unnecessarily restrictive. (c) 2008 Elsevier B.V. All rights reserved.	[Ng, Serena] Columbia Univ, Dept Econ, New York, NY 10027 USA; [Bai, Jushan] Tsinghua Univ, Sch Econ & Management, Beijing 100084, Peoples R China; [Bai, Jushan] NYU, Dept Econ, New York, NY 10012 USA	Ng, S (reprint author), Columbia Univ, Dept Econ, 420 W 118 St, New York, NY 10027 USA.	jushan.Bai@nyu.edu; serena.ng@columbia.edu					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Stock JH, 2002, J AM STAT ASSOC, V97, P1167, DOI 10.1198/016214502388618960; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; HOLM S, 1979, SCAND J STAT, V6, P65; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Forni M, 2005, J AM STAT ASSOC, V100, P830, DOI 10.1198/016214504000002050; Boivin J, 2006, J ECONOMETRICS, V132, P169, DOI 10.1016/j.jeconom.2005.01.027; Efron B, 2004, ANN STAT, V32, P407; Inoue A, 2008, J AM STAT ASSOC, V103, P511, DOI 10.1198/016214507000000473; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Bai J, 2006, ECONOMETRICA, V74, P1133, DOI 10.1111/j.1468-0262.2006.00696.x; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; Beveridge S., 1981, J MONETARY EC; Boivin J., 2005, INT J CENT BANK, V1, P117; FORNI M, 2001, DO FINANCIAL V UNPUB; Ludvigson SC, 2007, J FINANC ECON, V83, P171, DOI 10.1016/j.jfineco.2005.12.002; MOL C, 2006, FORECASTING US UNPUB; NELSON CR, 1982, J MONETARY ECON, V10, P139, DOI 10.1016/0304-3932(82)90012-5; Stock J., 2006, HDB FORECASTING; Stock JH, 1999, J MONETARY ECON, V44, P293, DOI 10.1016/S0304-3932(99)00027-6; Stock J.H., 2004, EMPIRICAL COMP UNPUB	23	43	43	2	8	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0304-4076			J ECONOMETRICS	J. Econom.	OCT	2008	146	2					304	317		10.1016/j.jeconom.2008.08.010		14	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	373QW	WOS:000260988100010		
J	De Mol, C; Giannone, D; Reichlin, L				De Mol, Christine; Giannone, Domenico; Reichlin, Lucrezia			Forecasting using a large number of predictors: Is Bayesian shrinkage a valid alternative to principal components?	JOURNAL OF ECONOMETRICS			English	Article; Proceedings Paper	Conference held in honor of Charles R Nelson	MAR 31-APR 01, 2006	Atlanta, GA	Fed Reserve Bank Atlanta		Bayesian shrinkage; Bayesian VAR; Ridge regression; Lasso regression; Principal components; Large cross-sections	DYNAMIC-FACTOR MODEL; REGRESSION	This paper considers Bayesian regression with normal and double-exponential priors as forecasting methods based on large panels of time series. We show that, empirically, these forecasts are highly correlated with principal component forecasts and that they perform equally well for a wide range of prior choices. Moreover, we study conditions for consistency of the forecast based on Bayesian regression as the cross-section and the sample size become large. This analysis serves as a guide to establish a criterion for setting the amount of shrinkage in a large cross-section. (c) 2008 Elsevier B.V. All rights reserved.	[Giannone, Domenico] European Cent Bank, Directorate Gen Res, D-60311 Frankfurt, Germany; [De Mol, Christine; Giannone, Domenico] Univ Libre Bruxelles, ECARES, Brussels, Belgium	Giannone, D (reprint author), European Cent Bank, Directorate Gen Res, Kaiserstr 29, D-60311 Frankfurt, Germany.	Domenico.Giannone@ecb.int	Reichlin, Lucrezia/J-9024-2015; 	Giannone, Domenico/0000-0003-3850-2586			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Giacomini R, 2006, ECONOMETRICA, V74, P1545, DOI 10.1111/j.1468-0262.2006.00718.x; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Bai JS, 2002, ECONOMETRICA, V70, P191, DOI 10.1111/1468-0262.00273; Stock JH, 2002, J BUS ECON STAT, V20, P147, DOI 10.1198/073500102317351921; Forni M, 2005, J AM STAT ASSOC, V100, P830, DOI 10.1198/016214504000002050; Giannone D, 2008, J MONETARY ECON, V55, P665, DOI 10.1016/j.jmoneco.2008.05.010; Efron B, 2004, ANN STAT, V32, P407; Fernandez C, 2001, J ECONOMETRICS, V100, P381, DOI 10.1016/S0304-4076(00)00076-2; Bai J, 2003, ECONOMETRICA, V71, P135, DOI 10.1111/1468-0262.00392; Forni M, 2000, REV ECON STAT, V82, P540, DOI 10.1162/003465300559037; Bai J, 2006, ECONOMETRICA, V74, P1133, DOI 10.1111/j.1468-0262.2006.00696.x; Bai J, 2008, J ECONOMETRICS, V146, P304, DOI 10.1016/j.jeconom.2008.08.010; BANBURA M, 2007, J APPL ECON IN PRESS; CHAMBERLAIN G, 1983, ECONOMETRICA, V51, P1305, DOI 10.2307/1912276; D'Agostino A, 2007, 6564 CTR EC POL RES; D'Agostino A, 2006, WORKING PAPER SERIES, V605; Daubechies I., 2004, COMMUN PURE APPL MAT, V57, P1416; DEMOL C, 2002, INVERSE PROBL IMAG, P85; Doan TA, 1984, ECONOMET REV, V3, P1, DOI DOI 10.1080/07474938408800053; Forni M, 2004, J ECONOMETRICS, V119, P231, DOI 10.1016/S0304-4076(03)00196-9; FORNI M, 2007, WORKING PAP IN PRESS, V712; FU WJ, 1998, J COMPUTATIONAL GRAP, V7, P497; Giannone D., 2004, NBER MACROECON ANN, P161; Hastie T., 2001, ELEMENTS STAT LEARNI; KOOP G, 2003, STAFF REPORTS FEDERA, V163; LITTERMAN RB, 1986, J BUS ECON STAT, V4, P25, DOI 10.2307/1391384; ONATSKI A, 2006, ASYMPTOTIC DIS UNPUB; Stock J, 2005, EMPIRICAL COMP METHO; Stock J., 2006, HDB EC FORECASTING, V1, P515, DOI 10.1016/S1574-0706(05)01010-4; Stock J. H., 2002, J AM STAT ASSOC, V97, P147; Stock J. H., 2005, NBER WORKING PAPERS, V11467; WRIGHT JH, 2003, INT FINANCE DISCUSSI, V780	33	65	67	0	7	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0304-4076			J ECONOMETRICS	J. Econom.	OCT	2008	146	2					318	328		10.1016/j.jeconom.2008.08.011		11	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	373QW	WOS:000260988100011		
J	Jais, JP; Haioun, C; Molina, TJ; Rickman, DS; de Reynies, A; Berger, F; Gisselbrecht, C; Briere, J; Reyes, F; Gaulard, P; Feugier, P; Labouyrie, E; Tilly, H; Bastard, C; Coiffier, B; Salles, G; Leroy, K				Jais, J-P; Haioun, C.; Molina, T. J.; Rickman, D. S.; de Reynies, A.; Berger, F.; Gisselbrecht, C.; Briere, J.; Reyes, F.; Gaulard, P.; Feugier, P.; Labouyrie, E.; Tilly, H.; Bastard, C.; Coiffier, B.; Salles, G.; Leroy, K.		Grp Etude Lymphomes Adulte	The expression of 16 genes related to the cell of origin and immune response predicts survival in elderly patients with diffuse large B-cell lymphoma treated with CHOP and rituximab	LEUKEMIA			English	Article						diffuse B-cell lymphoma; rituximab; gene expression; prognosis	GERMINAL CENTER; R-CHOP; TRANSCRIPTION FACTOR; PROTEIN EXPRESSION; TISSUE MICROARRAY; PROGNOSTIC IMPACT; CHEMOTHERAPY; DLBCL; LPP; CLASSIFICATION	Gene expression profiles have been associated with clinical outcome in patients with diffuse large B-cell lymphoma (DLBCL) treated with anthracycline-containing chemotherapy. Using Affymetrix HU133A microarrays, we analyzed the lymphoma transcriptional profile of 30 patients treated with CHOP (cyclophosphamide, doxorubicin, vincristine, prednisone) and 23 patients treated with rituximab (R)-CHOP in the Groupe d'Etude des Lymphomes de l'Adulte clinical centers. We used this data set to select transcripts showing an association with progression-free survival in all patients or showing a differential effect in the two treatment groups. We performed real-time quantitative reverse transcription-PCR in the 23 R-CHOP samples of the screening set and an additional 44 R-CHOP samples set to evaluate the prognostic significance of these transcripts. In these 67 patients, the level of expression of 16 genes and the cell-of-origin classification were significantly associated with overall survival, independently of the International Prognostic Index. A multivariate model comprising four genes of the cell-of-origin signature (LMO2, MME, LPP and FOXP1) and two genes related to immune response, identified for their differential effects in R-CHOP patients (APOBEC3G and RAB33A), demonstrated a high predictive efficiency in this set of patients, suggesting that both features affect outcome in DLBCL patients receiving immunochemotherapy.	[Leroy, K.] Univ Paris 12, Hop Henri Mondor, AP HP, Dept Pathol,INSERM,Unite 841,IMRB,Equipe 9, F-94000 Creteil, France; [Reyes, F.; Gaulard, P.; Leroy, K.] Univ Paris 12, Serv Hematol, F-94000 Creteil, France; [Jais, J-P] Hop Necker Enfants Malad, AP HP, Serv Biostat, Paris, France; [Jais, J-P; Molina, T. J.] Univ Paris 05, Fac Med, Paris, France; [Molina, T. J.] Hop Hotel Dieu, AP HP, Dept Pathol, F-75181 Paris, France; [Rickman, D. S.; de Reynies, A.] Ligue Natl Contre Canc, Programme CIT, Paris, France; [Berger, F.; Coiffier, B.; Salles, G.] Univ Lyon 1, Hosp Civils Lyon, Serv Hematol, CNRS,UMR 5239, Pierre Benite, France; [Berger, F.; Coiffier, B.; Salles, G.] Univ Lyon 1, Hosp Civils Lyon, Serv Anatomopathol, CNRS,UMR 5239, Pierre Benite, France; [Gisselbrecht, C.; Briere, J.] Univ Paris 07, Hop St Louis, AP HP, Serv Hematol, Paris, France; [Gisselbrecht, C.; Briere, J.] Univ Paris 07, Hop St Louis, AP HP, Dept Pathol, Paris, France; [Feugier, P.; Labouyrie, E.] Hop Brabois, Serv Hematol, Vandoeuvre Les Nancy, France; [Feugier, P.; Labouyrie, E.] Hop Brabois, Dept Pathol, Vandoeuvre Les Nancy, France; [Tilly, H.; Bastard, C.] Ctr Henri Becquerel, Serv Hematol & Oncol Mol, F-76038 Rouen, France	Leroy, K (reprint author), Univ Paris 12, Hop Henri Mondor, AP HP, Dept Pathol,INSERM,Unite 841,IMRB,Equipe 9, 51 Ave Marechal Lattre Tassigny, F-94000 Creteil, France.	karen.leroy@hmn.aphp.fr	JAIS, Jean-Philippe/B-2993-2009; Leroy, Karen/E-9235-2011; Jones, Jeffrey/E-9827-2013	JAIS, Jean-Philippe/0000-0002-0708-8776; 	Ligue Nationale Contre le Cancer; Programme Hospitalier de Recherche Clinique [AOM 03060]; Roche	We are grateful to Fabien Petel (Ligue Nationale Contre le Cancer) for the management of the Affymetrix and annotation databases and submission of the same to the Array Express. We thank E Jacquet, H Levaique, E Garrido (CNRS, Gif sur Yvette, France) and E Come for the realization of the TLDA experiments; A Allain and N Nio for their help in clinical data management. We are indebted to the pathologists and clinicians of the GELA who contributed pathological specimen and clinical data. This study was supported by grants of the Ligue Nationale Contre le Cancer (programme Carte d'Identite des Tumeurs), the Programme Hospitalier de Recherche Clinique (AOM 03060) and an unrestricted grant from Roche.	Lossos IS, 2004, NEW ENGL J MED, V350, P1828, DOI 10.1056/NEJMoa032520; Cartron G, 2004, BLOOD, V104, P2635, DOI 10.1182/blood-2004-03-1110; Barrans SL, 2004, BLOOD, V104, P2933, DOI 10.1182/blood-2004-03-1209; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Gallois-Montbrun S, 2007, J VIROL, V81, P2165, DOI 10.1128/JVI.02287-06; Coiffier B, 2005, J CLIN ONCOL, V23, P6387, DOI 10.1200/JCO.2005.05.015; Feugier P, 2005, J CLIN ONCOL, V23, P4117, DOI 10.1200/JCO.2005.09.131; Coiffier B, 2002, NEW ENGL J MED, V346, P235, DOI 10.1056/NEJMoa011795; Monti S, 2005, BLOOD, V105, P1851, DOI 10.1182/blood-2004.07.2947; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Harris NL, 1999, J CLIN ONCOL, V17, P3835; Smith MR, 2003, ONCOGENE, V22, P7359, DOI 10.1038/sj.onc.1206939; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Skol AD, 2006, NAT GENET, V38, P209, DOI 10.1038/ng1706; Natkunam Y, 2008, J CLIN ONCOL, V26, P447, DOI 10.1200/JCO.2007.13.0690; Jacobsen M, 2005, J INFECT DIS, V192, P1211, DOI 10.1086/444428; van Imhoff GW, 2006, J CLIN ONCOL, V24, P4135, DOI 10.1200/JCO.2006-05.5897; Hans CP, 2004, BLOOD, V103, P275, DOI 10.1182/blood-2003-05-1545; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Stopak KS, 2007, J BIOL CHEM, V282, P3539, DOI 10.1074/jbc.M610138200; SHIPP MA, 1993, NEW ENGL J MED, V329, P987; Harrell FE, 1996, STAT MED, V15, P361, DOI 10.1002/(SICI)1097-0258(19960229)15:4<361::AID-SIM168>3.0.CO;2-4; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Banham AH, 2005, CLIN CANCER RES, V11, P1065; Chang CC, 2004, AM J SURG PATHOL, V28, P464, DOI 10.1097/00000478-200404000-00005; Cheng E, 2006, J INVEST DERMATOL, V126, P2257, DOI 10.1038/sj.jid.5700386; Daheron L, 2001, GENE CHROMOSOME CANC, V31, P382, DOI 10.1002/gcc.1157; de Jong D, 2007, J CLIN ONCOL, V25, P805, DOI 10.1200/JCO.2006.09.4490; Fabiani B, 2004, VIRCHOWS ARCH, V445, P545, DOI 10.1007/s00428-004-1129-7; Friedberg Jonathan W, 2005, Hematology Am Soc Hematol Educ Program, P329; GENTLEMAN R, 2007, R LANGUAGE ENV STAT, P1; Gentleman RC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-10-r80; Guo BQ, 2006, MOL CELL BIOL, V26, P4529, DOI 10.1128/MCB.01667-05; Kalbfleisch J.D., 2002, STAT ANAL FAILURE TI, P95; Lossos IS, 2005, J CLIN ONCOL, V23, P6351, DOI 10.1200/JCO.2005.05.012; Mounier N, 2003, BLOOD, V101, P4279, DOI 10.1182/blood-2002-11-3442; Nyman H, 2007, BLOOD, V109, P4930, DOI 10.1182/blood-2006-09-047068; Petit MMR, 1996, GENOMICS, V36, P118, DOI 10.1006/geno.1996.0432; Schwindt H, 2006, J NEUROPATH EXP NEUR, V65, P776; Segal MR, 2006, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; Takaori-Kondo A, 2006, INT J HEMATOL, V83, P213, DOI 10.1532/IJH97.06006; Winter JN, 2006, BLOOD, V107, P4207, DOI 10.1182/blood-2005-10-4222; Wright G, 2003, P NATL ACAD SCI USA, V100, P9991, DOI 10.1073/pnas.1732008100; Zehetmayer S, 2005, BIOINFORMATICS, V21, P3771, DOI 10.1093/bioinformatics/bti604	45	44	44	2	6	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	0887-6924			LEUKEMIA	Leukemia	OCT	2008	22	10					1917	1924		10.1038/leu.2008.188		8	Oncology; Hematology	Oncology; Hematology	359SA	WOS:000260007200013	18615101	
J	Tin, JA; D'Souza, A; Yamamoto, K; Yoshioka, T; Hoffman, D; Kakei, S; Sergio, L; Kalaska, J; Kawato, M; Strick, P; Schaal, S				Tin, Jo-Anne; D'Souza, Aaron; Yamamoto, Kenji; Yoshioka, Toshinori; Hoffman, Donna; Kakei, Shinji; Sergio, Lauren; Kalaska, John; Kawato, Mitsuo; Strick, Peter; Schaal, Stefan			Variational Bayesian least squarest: An application to brain-machine interface data	NEURAL NETWORKS			English	Article						High-dimensional regression; Variational Bayesian methods; Linear models; Dimensionality reduction; Feature selection; Brain-machine interfaces; EMG prediction; Statistical learning	PRIMARY MOTOR CORTEX; DIRECT CORTICAL CONTROL; MUSCLE-ACTIVITY; EM ALGORITHM; REGRESSION; SELECTION; NEURONS; DEVICES; MODEL; TASK	An increasing number of projects in neuroscience require statistical analysis of high-dimensional data, as, for instance, in the prediction of behavior from neural firing or in the operation of artificial devices from brain recordings in brain-machine interfaces. Although prevalent, classical linear analysis techniques are often numerically fragile in high dimensions due to irrelevant, redundant, and noisy information. We developed a robust Bayesian linear regression algorithm that automatically detects relevant features and excludes irrelevant ones, all in a computationally efficient manner. In comparison with standard linear methods, the new Bayesian method regularizes against overfitting, is computationally efficient (unlike previously proposed variational linear regression methods, is suitable for data sets with large numbers of samples and a very high number of input dimensions) and is easy to use, thus demonstrating its potential as a drop-in replacement for other linear regression techniques. We evaluate our technique on synthetic data sets and on several neurophysiological data sets. For these neurophysiological data sets we address the question of whether EMG data collected from arm movements of monkeys can be faithfully reconstructed from neural activity in motor cortices. Results demonstrate the success of our newly developed method, in comparison with other approaches in the literature, and, from the neurophysiological point of view, confirms recent findings on the organization of the motor cortex. Finally, an incremental, real-time version of our algorithm demonstrates the suitability of our approach for real-time interfaces between brains and machines. (C) 2008 Elsevier Ltd. All rights reserved.	[Tin, Jo-Anne; Schaal, Stefan] Univ So Calif, Los Angeles, CA 90089 USA; [D'Souza, Aaron] Google Inc, Mountain View, CA 94043 USA; [Yamamoto, Kenji] Natl Inst Radiol Sci, Chiba 2638555, Japan; [Yoshioka, Toshinori; Kawato, Mitsuo; Schaal, Stefan] ATR Computat Neurosci Labs, Kyoto 6190288, Japan; [Hoffman, Donna; Strick, Peter] Univ Pittsburgh, Pittsburgh, PA 15261 USA; [Kakei, Shinji] Tokyo Metropolitan Inst Neurosci, Tokyo 1838526, Japan; [Sergio, Lauren] York Univ, N York, ON M3J 1P3, Canada; [Kalaska, John] Univ Montreal, Montreal, PQ H3C 3J7, Canada	Tin, JA (reprint author), Univ So Calif, Hedco Neurosci Bldg,3641 Watt Way, Los Angeles, CA 90089 USA.	joanneti@usc.edu					Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444; Nicolelis MAL, 2001, NATURE, V409, P403, DOI 10.1038/35053191; Kakei S, 1999, SCIENCE, V285, P2136, DOI 10.1126/science.285.5436.2136; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; Lebedev MA, 2006, TRENDS NEUROSCI, V29, P536, DOI 10.1016/j.tins.2006.07.004; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Musallam S, 2004, SCIENCE, V305, P258, DOI 10.1126/science.1097938; McKiernan BJ, 1998, J NEUROPHYSIOL, V80, P1961; Haynes JD, 2005, NAT NEUROSCI, V8, P686, DOI 10.1038/nn1445; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; Hochberg LR, 2006, NATURE, V442, P164, DOI 10.1038/nature04970; Sato M, 2001, NEURAL COMPUT, V13, P1649, DOI 10.1162/089976601750265045; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Wolpaw JR, 2004, P NATL ACAD SCI USA, V101, P17849, DOI 10.1073/pnas.0403504101; Chapin JK, 1999, NAT NEUROSCI, V2, P664, DOI 10.1038/10223; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; STRASSEN V, 1969, NUMER MATH, V13, P354, DOI 10.1007/BF02165411; ATTIAS H, 2000, ADV NEURAL INFORM PR, V13; Bennett KMB, 1996, J NEUROPHYSIOL, V75, P1826; Bishop C., 2006, PATTERN RECOGNITION; D'Souza A., 2004, P 21 INT C MACH LEAR; DERKSEN S, 1992, BRIT J MATH STAT PSY, V45, P265; Draper N, 1981, APPL REGRESSION ANAL; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Gelman A., 2000, BAYESIAN DATA ANAL; Ghahramani Z., 2000, ADV MEAN FIELD METHO; Hastie T. J., 1990, MONOGRAPHS STAT APPL, V43; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Jaakkola T., 2000, ADV MEAN FIELD METHO; Jordan M., 1999, LEARNING GRAPHICAL M; Kakei S, 2001, NAT NEUROSCI, V4, P1020, DOI 10.1038/nn726; Ljung L., 1983, THEORY PRACTICE RECU; Morrow MM, 2003, J NEUROPHYSIOL, V89, P2279, DOI 10.1152/jn.00632.2002; Neal R. M., 1994, THESIS U TORONTO; Nicolelis MAL, 2006, SCI AM, V295, P70, DOI 10.1038/scientificamerican1206-70; Sato M, 2000, NEURAL COMPUT, V12, P407, DOI 10.1162/089976600300015853; SCHAAL S, 1998, ADV NEURAL INFORM PR; Sergio LE, 1998, J NEUROPHYSIOL, V80, P1577; TING J, 2005, P ADV NEURAL INFORM, V18; Todorov E, 2000, NAT NEUROSCI, V3, P391, DOI 10.1038/73964; Townsend BR, 2006, J NEUROPHYSIOL, V96, P2578, DOI 10.1152/jn.01086.2005; Wessberg J, 2004, J COGNITIVE NEUROSCI, V16, P1022, DOI 10.1162/0898929041502652; Wold H., 1975, PERSPECTIVES PROBABI	44	1	1	0	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	OCT	2008	21	8			SI		1112	1131		10.1016/j.neunet.2008.06.012		20	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	374FJ	WOS:000261028300009		
J	Ganesh, G; Burdet, E; Haruno, M; Kawato, M				Ganesh, G.; Burdet, E.; Haruno, M.; Kawato, M.			Sparse linear regression for reconstructing muscle activity from human cortical fMRI	NEUROIMAGE			English	Article							PRIMARY MOTOR CORTEX; TRANSCRANIAL MAGNETIC STIMULATION; DIFFERENT ARM ORIENTATIONS; DORSAL PREMOTOR CORTEX; SIMILAR HAND PATHS; REACHING MOVEMENTS; UNSTABLE DYNAMICS; INDIVIDUAL CELLS; SURFACE EMG; FEEDBACK	In humans, it is generally not possible to use invasive techniques in order to identify brain activity corresponding to activity of individual muscles. Further, it is believed that the spatial resolution of non-invasive brain imaging modalities is not Sufficient to isolate neural activity related to individual muscles. However, this study shows that it is possible to reconstruct muscle activity from functional magnetic resonance imaging (fMRI). We simultaneously recorded surface electromyography (EMG) from two antagonist muscles and motor cortices activity using fMRI, during an isometric task requiring both reciprocal activation and co-activation of the wrist muscles. Bayesian sparse regression was used to identify the parameters of a linear mapping from the fMRI activity in areas 4 (M1) and 6 (pre-motor, SMA) to EMG, and to reconstruct muscle activity in an independent test data set. The mapping obtained by the Sparse regression algorithm showed significantly better generalization than those obtained from algorithms commonly used in decoding, i.e., support vector machine and least square regression. The two voxel sets Corresponding to the activity of the antagonist muscles were intermingled but disjoint. They were distributed over a wide area of pre-motor cortex and M1 and not limited to regions generally associated with wrist control. These results show that brain activity measured by fMRI in humans can be used to predict individual muscle activity through Bayesian linear models, and that our algorithm provides a novel and non-invasive tool to investigate the brain mechanisms involved in motor control and learning in humans. (C) 2008 Elsevier Inc. All rights reserved.	[Ganesh, G.; Haruno, M.; Kawato, M.] ATR Int, Dept Computat Neurobiol, Computat Neurosci Labs, Seika, Kyoto 6190288, Japan; [Ganesh, G.; Burdet, E.] Univ London Imperial Coll Sci Technol & Med, Dept Bioengn, London SW7 2AZ, England	Ganesh, G (reprint author), ATR Int, Dept Computat Neurobiol, Computat Neurosci Labs, 2-2-2 Hikaridai, Seika, Kyoto 6190288, Japan.	gganesh@atr.jp			Human Frontier Science Program (HFSP)	We thank Satoshi Tada, Ichiro Fujimoto and Yasuhiro Shimada for their valuable help in the preparation of experiments and collection of imaging data. This study was funded by the Human Frontier Science Program (HFSP).	Scott SH, 1997, J NEUROPHYSIOL, V77, P826; Kakei S, 1999, SCIENCE, V285, P2136, DOI 10.1126/science.285.5436.2136; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Franklin DW, 2003, J NEUROPHYSIOL, V90, P3270, DOI 10.1152/jn.01112.2002; Picard N, 2001, CURR OPIN NEUROBIOL, V11, P663, DOI 10.1016/S0959-4388(01)00266-5; Pesaran B, 2006, NEURON, V51, P125, DOI 10.1016/j.neuron.2006.05.025; Burdet E, 2001, NATURE, V414, P446, DOI 10.1038/35106566; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Nudo RJ, 1996, SCIENCE, V272, P1791, DOI 10.1126/science.272.5269.1791; Rathelot JA, 2006, P NATL ACAD SCI USA, V103, P8257, DOI 10.1073/pnas.0602933103; Crammond DJ, 2000, J NEUROPHYSIOL, V84, P986; WASSERMANN EM, 1992, ELECTROEN CLIN NEURO, V85, P1, DOI 10.1016/0168-5597(92)90094-R; Hallett M, 2007, NEURON, V55, P187, DOI 10.1016/j.neuron.2007.06.026; Birn RM, 2004, NEUROIMAGE, V23, P1046, DOI 10.1016/j.neuroimage.2004.07.039; Burdet E, 2004, Conf Proc IEEE Eng Med Biol Soc, V6, P4491; Bursztyn LLCD, 2006, CURR BIOL, V16, P2440, DOI 10.1016/j.cub.2006.10.051; Cisek P, 2003, J NEUROPHYSIOL, V89, P922, DOI 10.1152/jn.00607.2002; Dai TH, 2001, EXP BRAIN RES, V140, P290, DOI 10.1007/s002210100815; d'Avella A, 2006, J NEUROSCI, V26, P7791, DOI 10.1523/JNEUROSCI.0830-06.2006; Diedrichsen J, 2005, J NEUROSCI, V25, P9919, DOI 10.1523/JNEUROSCI.1874-05.2005; Ehrsson HH, 2000, J NEUROPHYSIOL, V83, P528; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Ganesh G, 2007, J NEUROPHYSIOL, V97, P912, DOI 10.1152/jn.00679.2006; Gao JB, 2003, NEUROCOMPUTING, V50, P391, DOI 10.1016/S0925-2312(02)00573-8; Gassert R, 2006, IEEE-ASME T MECH, V11, P216, DOI 10.1109/TMECH.2006.871897; Haruno M, 2005, J NEUROPHYSIOL, V94, P4244, DOI 10.1152/jn.00404.2005; HARUNO M, 2007, NEUR CONTR MOV NCM 2; Hoffman DS, 1999, J NEUROPHYSIOL, V81, P319; HOGAN N, 1984, J NEUROSCI, V4, P2745; Imamizu H, 2004, J NEUROSCI, V24, P1173, DOI 10.1523/JNEUROSCI.4011-03.2004; Jackson A, 2007, J NEUROPHYSIOL, V97, P360, DOI 10.1152/jn.00710.2006; Koike Y, 2006, NEUROSCI RES, V55, P146, DOI 10.1016/j.neures.2006.02.012; KURATA K, 1988, EXP BRAIN RES, V69, P327; Milner TE, 2007, NEUROIMAGE, V36, P388, DOI 10.1016/j.neuroimage.2007.01.057; Morrow MM, 2003, J NEUROPHYSIOL, V89, P2279, DOI 10.1152/jn.00632.2002; Ojakangas CL, 2006, J CLIN NEUROPHYSIOL, V23, P577, DOI 10.1097/01.wnp.0000233323.87127.14; Pope P, 2005, NEUROIMAGE, V27, P909, DOI 10.1016/j.neuroimage.2005.05.010; SANES JN, 1995, SCIENCE, V268, P1696; Schaal Stefan, 2004, Nat Neurosci, V7, P1136, DOI 10.1038/nn1322; Scott SH, 1997, J NEUROPHYSIOL, V78, P2413; Sylvestre PA, 2006, J NEUROSCI, V26, P4922, DOI 10.1523/JNEUROSCI.4099-05.2006; Talairach J, 1988, COPLANAR STEREOTAXIC; TING J, 2005, NIPS C; Townsend BR, 2006, J NEUROPHYSIOL, V96, P2578, DOI 10.1152/jn.01086.2005; van Duinen H, 2005, NEUROIMAGE, V27, P240, DOI 10.1016/j.neuroimage.2005.04.003; van Elswijk G, 2008, CORTEX, V44, P609, DOI 10.1016/j.cortex.2007.07.003	46	19	19	0	6	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119			NEUROIMAGE	Neuroimage	OCT 1	2008	42	4					1463	1472		10.1016/j.neuroimage.2008.06.018		10	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	351CB	WOS:000259401000018	18634889	
J	Martinez-Montes, E; Sanchez-Bornot, JM; Valdes-Sosa, PA				Martinez-Montes, Eduardo; Sanchez-Bornot, Jose M.; Valdes-Sosa, Pedro A.			PENALIZED PARAFAC ANALYSIS OF SPONTANEOUS EEG RECORDINGS	STATISTICA SINICA			English	Article						Dimensionality reduction; EEG; PARAFAC; penalized regression	PARALLEL FACTOR-ANALYSIS; VARIABLE SELECTION; COMPONENT ANALYSIS; WAY ARRAYS; UNIQUENESS; MODEL; DECOMPOSITION; CONSTRAINTS; SMOOTHNESS; ALGORITHMS	The multidimensional nature of neuroscience data has made the use of multi-way statistical analysis suitable in this field. Parallel Factor Analysis (PARAFAC) is a, multidimensional generalization of PCA with the advantage of offering unique solutions. However, imposing physiologically acceptable constraints would improve the interpretation of this type of analysis. In this work we propose a new algorithm called Alternating Penalized Least Squares to estimate PARAFAC solutions using different kinds of soft penalization. The algorithm relies oil the recent generalization of modified Newton-Raphson techniques to estimate a multiple penalized least squares model. Applied to semi-synthetic and real spontaneous EEG time-varying spectra, we show that a wide range of sparse and smooth solutions can be found separately, as well as with these two properties combined. Smoothness is usually desired in spectra, and different sparse scenarios are observed in the temporal evolution of physiological intermittent phenomena. The degree of constraints can be tuned through the weighting parameters, whose optimal - values can be chosen by means of the cross-validation and Corcondia measures.	[Martinez-Montes, Eduardo; Sanchez-Bornot, Jose M.; Valdes-Sosa, Pedro A.] Cuban Neurosci Ctr, Neurostat Dept, Havana, Cuba	Martinez-Montes, E (reprint author), Cuban Neurosci Ctr, Neurostat Dept, Havana, Cuba.	eduardo@cneuro.edu.cu; bornot@cneuro.edu.cu; peter@cneuro.edu.cu					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; KRUSKAL JB, 1977, LINEAR ALGEBRA APPL, V18, P95, DOI 10.1016/0024-3795(77)90069-6; Miwakeichi F, 2004, NEUROIMAGE, V22, P1035, DOI 10.1016/j.neuroimage.2004.03.039; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436; Tomasi G, 2006, COMPUT STAT DATA AN, V50, P1700, DOI 10.1016/j.csda.2004.11.013; Morup M, 2006, NEUROIMAGE, V29, P938, DOI 10.1016/j.neuroimage.2005.08.005; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Beckmann CF, 2005, NEUROIMAGE, V25, P294, DOI 10.1016/j.neuroimage.2004.10.043; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Andersson CA, 2000, CHEMOMETR INTELL LAB, V52, P1, DOI 10.1016/S0169-7439(00)00071-X; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Sidiropoulos ND, 2000, J CHEMOMETR, V14, P229, DOI 10.1002/1099-128X(200005/06)14:3<229::AID-CEM587>3.3.CO;2-E; ANSLEY CF, 1994, J AUST MATH SOC A, V57, P316; Bro R., 1998, THESIS U AMSTERDAM D; CARROLL JD, 1980, PSYCHOMETRIKA, V45, P3; Fan J., 1997, J ITALIAN STAT ASS, V6, P131; Harshman R.A., 1970, UCLA WORKING PAPERS, V16, P1; Hastie TJ, 1990, GEN ADDITIVE MODELS; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Land S. R., 1996, VARIABLE FUSION NEW; Martinez-Montes E, 2004, NEUROIMAGE, V22, P1023, DOI 10.1016/j.neuroimage.2004.03.038; MORUP M, 2005, THESIS TU DENMARK; Sanchez-Bornot JM, 2008, STAT SINICA, V18, P1501; Stegeman A, 2007, LINEAR ALGEBRA APPL, V420, P540, DOI 10.1016/j.laa.2006.08.010; Timmerman ME, 2002, COMPUT STAT DATA AN, V40, P447, DOI 10.1016/S0167-9473(02)00059-2; VALDESSOSA PA, 2006, HDB TIME SERIES ANAL, pCH18	29	2	2	2	3	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405			STAT SINICA	Stat. Sin.	OCT	2008	18	4					1449	1464				16	Statistics & Probability	Mathematics	374TR	WOS:000261067100014		
J	Sanchez-Bornot, JM; Martinez-Montes, E; Lage-Castellanos, A; Vega-Hernandez, M; Valdes-Sosa, PA				Sanchez-Bornot, Jose M.; Martinez-Montes, Eduardo; Lage-Castellanos, Agustin; Vega-Hernandez, Mayrim; Valdes-Sosa, Pedro A.			UNCOVERING SPARSE BRAIN EFFECTIVE CONNECTIVITY: A VOXEL-BASED APPROACH USING PENALIZED REGRESSION	STATISTICA SINICA			English	Article						Brain connectivity; FDR; feature selection; fMRI	FUNCTIONAL CONNECTIVITY; VARIABLE SELECTION; FMRI; LIKELIHOOD; WORKSHOP; LASSO; MRI	The processing of massive data generated by bioinformatic and neuroscience studies is a current challenge to statisticians since they require the development of computationally efficient and stable algorithms that can deal with many more variables than observations. In neuroscience, a clear example of this situation is the estimation of brain physiological interactions through the analysis of fMRI time series. The widespread use of the General Linear Model in the resolution of these problems has now been enhanced by the addition of prior assumptions, such as the sparseness and/or the spatiotemporal smoothness of a desirable solution (Valdes-Sosa (2004)). In this context, the use of Local Quadratic Approximation (LQA) (Fan and Li (2001)) and the Minorization-Maximization (MM) Hunter and Li (2005)) algorithms are practical ways for estimating the sparse models. Recently, we have extended these techniques to allow the combination of these attractive properties (Valdes-Sosa et al. (2006)). Here, we further formalize the methods and introduce a feature selection algorithm for feasible implementation. The methodology is then applied to the estimation of voxel-based brain effective connectivity using simulated and neuroimaging data.	[Sanchez-Bornot, Jose M.; Martinez-Montes, Eduardo; Lage-Castellanos, Agustin; Vega-Hernandez, Mayrim; Valdes-Sosa, Pedro A.] Cuban Neurosci Ctr, Neurostat Dept, Havana, Cuba	Sanchez-Bornot, JM (reprint author), Cuban Neurosci Ctr, Neurostat Dept, Havana, Cuba.	bornot@cneuro.edu.cu; eduardo@cneuro.edu.cu; agustin@cneuro.edu.cu; mayrim@cneuro.edu.cu; peter@cneuro.edu.cu					Buchel C, 1997, CEREB CORTEX, V7, P768, DOI 10.1093/cercor/7.8.768; Le Bihan D, 2003, NAT REV NEUROSCI, V4, P469, DOI 10.1038/nrn1119; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436; Iturria-Medina Y, 2007, NEUROIMAGE, V36, P645, DOI 10.1016/j.neuroimage.2007.02.012; Salvador R, 2005, PHILOS T R SOC B, V360, P937, DOI 10.1098/rstb.2005.1645; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Friston KJ, 2003, NEUROIMAGE, V19, P1273, DOI 10.1016/S1053-8119(03)00202-7; Goldman RI, 2002, NEUROREPORT, V13, P2487, DOI 10.1097/00001756-200212200-00022; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Logothetis NK, 2001, NATURE, V412, P150, DOI 10.1038/35084005; Bullmore ET, 2004, NEUROINFORMATICS, V2, P123, DOI 10.1385/NI:2:2:123; Eichler M, 2005, PHILOS T ROY SOC B, V360, P953, DOI 10.1098/rstb.2005.1641; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Friston Karl J., 1994, Human Brain Mapping, V2, P56, DOI 10.1002/hbm.460020107; Friston K. J., 2006, STAT PARAMETRIC MAPP; Harrison L, 2003, NEUROIMAGE, V19, P1477, DOI 10.1016/S1053-8119(03)00160-5; Heeger DJ, 2002, NAT REV NEUROSCI, V3, P142, DOI 10.1038/nrn730; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Jirsa V. K., 2007, HDB BRAIN CONNECTIVI; Kotter R, 2001, PHILOS T ROY SOC B, V356, P1111, DOI 10.1098/rstb.2001.0902; Lee L, 2003, NEUROIMAGE, V19, P457, DOI 10.1016/S1053-8119(03)00062-4; LI RZ, 2006, NONCONVEX PENA UNPUB; Martinez-Montes E, 2004, NEUROIMAGE, V22, P1023, DOI 10.1016/j.neuroimage.2004.03.038; OGAWA S, 2007, FUNCTIONAL MAGNETIC; PENNY W, 2007, FUNCTIONAL IMAGING; Perkins S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753698; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; Sporns O, 2005, PLOS COMPUT BIOL, V1, P245, DOI 10.1371/journal.pcbi.0010042; Stephan KE, 2001, PHILOS T ROY SOC B, V356, P1159; Valdes-Sosa PA, 2005, PHILOS T ROY SOC B, V360, P969, DOI 10.1098/rstb.2005.1654; Valdes-Sosa PA, 2004, NEUROINFORMATICS, V2, P239, DOI 10.1385/NI:2:2:239; VALDESSOSA PA, 2006, HDB TIME SERIES ANAL, pCH18	35	9	9	1	2	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405			STAT SINICA	Stat. Sin.	OCT	2008	18	4					1501	1518				18	Statistics & Probability	Mathematics	374TR	WOS:000261067100017		
J	Vega-Hernandez, M; Martinez-Montes, E; Sanchez-Bornot, JM; Lage-Castellanos, A; Valdes-Sosa, PA				Vega-Hernandez, Mayrim; Martinez-Montes, Eduardo; Sanchez-Bornot, Jos M.; Lage-Castellanos, Agustin; Valdes-Sosa, Pedro A.			PENALIZED LEAST SQUARES METHODS FOR SOLVING THE EEG INVERSE PROBLEM	STATISTICA SINICA			English	Article						EEG; inverse problem; least squares; penalized regression	RESOLUTION ELECTROMAGNETIC TOMOGRAPHY; GENERALIZED CROSS-VALIDATION; VARIABLE SELECTION; MM ALGORITHMS; BRAIN; REGRESSION; FIELDS; MODEL; LASSO	Most of the known solutions (linear and nonlinear) of the ill-posed EEG Inverse Problem can be interpreted as the estimated coefficients in a penalized regression framework. In this work we present a general formulation of this problem as a Multiple Penalized Least Squares model, which encompasses many of the previously known methods as particular cases (e.g., Minimum Norm, LORETA). New types of inverse solutions arise since recent advances in the field of penalized regression have made it possible to deal with non-convex penalty functions, which provide sparse solutions (Fan and Li (2001)). Moreover, a generalization of this approach allows the use of any combination of penalties based on l1 or l2-norms, leading to solutions with combined properties such as smoothness and sparsity. Synthetic data is used to explore the benefits of non-convex penalty functions (e.g., LASSO, SCAD and LASSO Fusion) and mixtures (e.g., Elastic Net and LASSO Fused) by comparing them with known solutions in terms of localization error, blurring and visibility. Real data is used to show that a mixture model (Elastic Net) allows for tuning the spatial resolution of the solution to range from very concentrated to very blurred sources.	[Vega-Hernandez, Mayrim; Martinez-Montes, Eduardo; Sanchez-Bornot, Jos M.; Lage-Castellanos, Agustin; Valdes-Sosa, Pedro A.] Cuban Neurosci Ctr, Neurostat Dept, Havana, Cuba	Vega-Hernandez, M (reprint author), Cuban Neurosci Ctr, Neurostat Dept, Havana, Cuba.	mayrim@cneuro.edu.cu; eduardo@cneuro.edu.cu; bornot@cneuro.edu.cu; agustin@cneuro.edu.cu; peter@cneuro.edu.cu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; PASCUALMARQUI RD, 1994, INT J PSYCHOPHYSIOL, V18, P49, DOI 10.1016/0167-8760(84)90014-X; Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436; HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476; Trujillo-Barreto NJ, 2004, NEUROIMAGE, V21, P1300, DOI 10.1016/j.neuroimage.2003.11.008; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; CRAVEN P, 1979, NUMER MATH, V31, P377; Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836; Bosch-Bayard J, 2001, CLIN ELECTROENCEPHAL, V32, P47; Carbonell F, 2004, NEUROIMAGE, V22, P268, DOI 10.1016/j.neuroimage.2004.01.020; Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009; DEPERALTA RG, 1998, IEEE ENG MED BIOL, V4, P2143; Evans AC, 1993, P IEEE NUCL SCI S ME, V95, P1813; Fuchs M, 1995, STUD APPL ELECTROMAG, V7, P320; Fuchs M, 1999, J CLIN NEUROPHYSIOL, V16, P267, DOI 10.1097/00004691-199905000-00006; Hadamard J., 1923, LECT CAUCHY PROBLEM; HANSEN PC, 1992, SIAM REV, V34, P561, DOI 10.1137/1034115; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Kiiveri HT, 2003, INST MATH S, V40, P127; Land S. R., 1996, VARIABLE FUSION NEW; Martinez A., 2001, HUM BRAIN MAPP, V15, P95, DOI DOI 10.1002/HBM.10010; Nagarajan SS, 2006, NEUROIMAGE, V33, P878, DOI 10.1016/j.neuroimage.2006.07.023; Pascual-Marqui R. D., 1999, INT J BIOELECTROMAGN, V1, P75, DOI DOI 10.1186/1743-0003-5-25; Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P91; Riera JJ, 1998, IEEE T BIO-MED ENG, V45, P746, DOI 10.1109/10.678609; SCHERG M, 1986, ELECTROEN CLIN NEURO, V65, P344, DOI 10.1016/0168-5597(86)90014-6; SCHOLZ B, 1994, IEEE T BIO-MED ENG, V41, P735, DOI 10.1109/10.310089; Makeig S, 2002, SCIENCE, V295, P690, DOI 10.1126/science.1066168; Valdes-Sosa P., 2000, P 10 INT C BIOM, V2, P373; VALDESSOSA PA, 2006, HDB TIME SERIES ANAL, pCH18; VIDAKOVIC B, 1998, PRACTICAL NONPARAMET, V133, P133; Yamashita O, 2004, HUM BRAIN MAPP, V21, P221, DOI 10.1002/hbm.20000	36	15	15	0	3	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405			STAT SINICA	Stat. Sin.	OCT	2008	18	4					1535	1551				17	Statistics & Probability	Mathematics	374TR	WOS:000261067100019		
J	Huang, J; Ma, SG; Zhang, CH				Huang, Jian; Ma, Shuangge; Zhang, Cun-Hui			ADAPTIVE LASSO FOR SPARSE HIGH-DIMENSIONAL REGRESSION MODELS	STATISTICA SINICA			English	Article						Asymptotic normality; high-dimensional data; penalized regression; variable selection; oracle property; zero-consistency	NONCONCAVE PENALIZED LIKELIHOOD; VARIABLE SELECTION; ORACLE PROPERTIES; NORMALIZATION; ESTIMATORS; BIAS	We study the asymptotic properties of the adaptive Lasso estimators in sparse, high-dimensional, linear regression models when the number of covariates may increase with the sample size. We consider variable selection using the adaptive Lasso, where the L, norms in the penalty are re-weighted by data-dependent weights. We show that, if a reasonable initial estimator is available, under appropriate conditions, the adaptive Lasso correctly selects covariates with nonzero coefficients with probability converging to one, and that the estimators of nonzero coefficients have the same asymptotic distribution they would have if the zero coefficients were known in advance. Thus, the adaptive Lasso has an oracle property in the sense of Fan and Li (2001) and Fan and Peng (2004). In addition, under a partial orthogonality condition in which the covariates with zero coefficients are weakly correlated with the covariates with nonzero coefficients, marginal regression can be used to obtain the initial estimator. With this initial estimator, the adaptive Lasso has the oracle property even when the number of covariates is much larger than the sample size.	[Huang, Jian] Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA; [Ma, Shuangge] Yale Univ, Div Biostat, Dept Epidemiol & Publ Hlth, New Haven, CT 06520 USA; [Zhang, Cun-Hui] Rutgers State Univ, Dept Stat, Piscataway, NJ 08854 USA	Huang, J (reprint author), Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA.	jian@stat.uiowa.edu; shuangge.ma@yale.edu; cunhui@stat.rutgers.edu					Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Huang J, 2008, ANN STAT, V36, P587, DOI 10.1214/009053607000000875; Scheetz TE, 2006, P NATL ACAD SCI USA, V103, P14429, DOI 10.1073/pnas.0602562103; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; CANDES EJ, 2005, ANN STAT IN PRESS; Chiang AP, 2006, P NATL ACAD SCI USA, V103, P6287, DOI 10.1073/pnas.0600158103; Fan J., 1997, J ITALIAN STAT ASS, V6, P131; FAN J, 2006, SURE INDEPENDENCE SC; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Leng CL, 2006, STAT SINICA, V16, P1273; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520	23	98	102	2	12	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405	1996-8507		STAT SINICA	Stat. Sin.	OCT	2008	18	4					1603	1618				16	Statistics & Probability	Mathematics	374TR	WOS:000261067100023		
J	Liu, ZQ; Gartenhaus, RB; Tan, M; Jiang, F; Jiao, XL				Liu, Zhenqiu; Gartenhaus, Ronald B.; Tan, Ming; Jiang, Feng; Jiao, Xiaoli			Gene and pathway identification with L(p) penalized Bayesian logistic regression	BMC BIOINFORMATICS			English	Article							EXPRESSION DATA; SELECTION; CLASSIFICATION; LASSO; REGULARIZATION	Background: Identifying genes and pathways associated with diseases such as cancer has been a subject of considerable research in recent years in the area of bioinformatics and computational biology. It has been demonstrated that the magnitude of differential expression does not necessarily indicate biological significance. Even a very small change in the expression of particular gene may have dramatic physiological consequences if the protein encoded by this gene plays a catalytic role in a specific cell function. Moreover, highly correlated genes may function together on the same pathway biologically. Finally, in sparse logistic regression with L(p) ( p < 1) penalty, the degree of the sparsity obtained is determined by the value of the regularization parameter. Usually this parameter must be carefully tuned through cross-validation, which is time consuming. Results: In this paper, we proposed a simple Bayesian approach to integrate the regularization parameter out analytically using a new prior. Therefore, there is no longer a need for parameter selection, as it is eliminated entirely from the model. The proposed algorithm (BLpLog) is typically two or three orders of magnitude faster than the original algorithm and free from bias in performance estimation. We also define a novel similarity measure and develop an integrated algorithm to hunt the regulatory genes with low expression changes but having high correlation with the selected genes. Pathways of those correlated genes were identified with DAVID http://david.abcc.ncifcrf.gov/. Conclusion: Experimental results with gene expression data demonstrate that the proposed methods can be utilized to identify important genes and pathways that are related to cancer and build a parsimonious model for future patient predictions.	[Liu, Zhenqiu; Tan, Ming; Jiao, Xiaoli] Univ Maryland, Greenebaum Canc Ctr, Div Biostat, Baltimore, MD 21201 USA; [Gartenhaus, Ronald B.] Univ Maryland, Sch Med, Dept Med, Baltimore, MD 21201 USA; [Gartenhaus, Ronald B.] Univ Maryland, Sch Med, Greenebaum Canc Ctr, Baltimore, MD 21201 USA; [Jiang, Feng] Univ Maryland, Sch Med, Dept Pathol, Baltimore, MD 21201 USA	Liu, ZQ (reprint author), Univ Maryland, Greenebaum Canc Ctr, Div Biostat, 22 S Greene St, Baltimore, MD 21201 USA.	zliu@umm.edu; rgartenhaus@som.umaryland.edu; mtan@umm.edu; fjiang@som.umaryland.edu; jiao@umbc.edu			National Institute of Health [IR03CA128102-02]	We thank the Associate Editor and the two anonymous referees for their constructive comments which helped improve the manuscript. ZL was partially supported by grant IR03CA128102-02 from the National Institute of Health.	Knight K, 2000, ANN STAT, V28, P1356; WILLIAMS PM, 1995, NEURAL COMPUT, V7, P117, DOI 10.1162/neco.1995.7.1.117; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhang HH, 2006, BIOINFORMATICS, V22, P88, DOI 10.1093/bioinformatics/bti736; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Nutt CL, 2003, CANCER RES, V63, P1602; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Efron B, 2004, ANN STAT, V32, P407; Bo T., 2002, GENOME BIOL, V3; Cawley GC, 2006, BIOINFORMATICS, V22, P2348, DOI 10.1093/bioinformatics/btl386; Chow ML, 2001, PHYSIOL GENOMICS, V5, P99; Klebanov L, 2006, STAT APPL GENET MOL, V5; Li Y, 2002, BIOINFORMATICS, V18, P1332, DOI 10.1093/bioinformatics/18.10.1332; Liu ZQ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1248; lizuka N., 2003, LANCET, V361, P923; MacKay DJC, 1999, NEURAL COMPUT, V11, P1035, DOI 10.1162/089976699300016331; Rapaport F, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-35; Rivals I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753724; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; SUBRAMANIAN A, 2005, PNAS, V101, P9309; van'tsVeer L. J., 2002, NATURE, V415, P484; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	22	3	3	3	6	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	OCT 3	2008	9								412	10.1186/1471-2105-9-412		19	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	360TO	WOS:000260080900001	18834526	
J	Wu, TT; Sun, W; Yuan, SS; Chen, CH; Li, KC				Wu, Tongtong; Sun, Wei; Yuan, Shinsheng; Chen, Chun-Houh; Li, Ker-Chau			A method for analyzing censored survival phenotype with gene expression data	BMC BIOINFORMATICS			English	Article							SLICED INVERSE REGRESSION; DIMENSION REDUCTION; MOLECULAR PORTRAITS; MICROARRAY DATA; BREAST-TUMORS; CANCER; CELL; DISCOVERY; SELECTION; RECEPTOR	Background: Survival time is an important clinical trait for many disease studies. Previous works have shown certain relationship between patients' gene expression profiles and survival time. However, due to the censoring effects of survival time and the high dimensionality of gene expression data, effective and unbiased selection of a gene expression signature to predict survival probabilities requires further study. Method: We propose a method for an integrated study of survival time and gene expression. This method can be summarized as a two-step procedure: in the first step, a moderate number of genes are pre-selected using correlation or liquid association ( LA). Imputation and transformation methods are employed for the correlation/LA calculation. In the second step, the dimension of the predictors is further reduced using the modified sliced inverse regression for censored data (censorSIR). Results: The new method is tested via both simulated and real data. For the real data application, we employed a set of 295 breast cancer patients and found a linear combination of 22 gene expression profiles that are significantly correlated with patients' survival rate. Conclusion: By an appropriate combination of feature selection and dimension reduction, we find a method of identifying gene expression signatures which is effective for survival prediction.	[Yuan, Shinsheng; Chen, Chun-Houh; Li, Ker-Chau] Acad Sinica, Inst Stat Sci, Taipei 115, Taiwan; [Wu, Tongtong] Univ Maryland, Dept Epidemiol & Biostat, College Pk, MD 20742 USA; [Sun, Wei] Univ N Carolina, Carolina Ctr Genome Sci, Dept Biostat, Chapel Hill, NC 27599 USA; [Li, Ker-Chau] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Li, KC (reprint author), Acad Sinica, Inst Stat Sci, Taipei 115, Taiwan.	ttwu@umd.edu; wsun@bios.unc.edu; syuan@stat.sinica.edu.tw; cchen@stat.sinica.edu.tw; kcli@stat.ucla.edu			NSF [DMS0201005, DMS0406091, DMS-0707160]; MIB; Institute of Statistical Science; Academia Sinica; NIEHS [5 P42 ES05948-15, 5 P30 ES10126-07];  [NSC95-3114-P-002-005-Y];  [NSC97-2627-P-001-003]	Authors would like to thank Dr. Charles Perou and Mr. Cheng Fan for helpful discussions. Research conducted by Li is supported in part by NSF grants DMS0201005, DMS0406091, and DMS-0707160. Li and Yuan were also supported in part by MIB, Institute of Statistical Science, Academia Sinica and grant NSC95-3114-P-002-005-Y and NSC97-2627-P-001-003. Research conducted by Sun is supported in part by NIEHS grant 5 P42 ES05948-15 and 5 P30 ES10126-07.	Andersen P., 1993, STAT MODELS BASED CO; ANDERSEN PK, 1982, ANN STAT, V10, P1100, DOI 10.1214/aos/1176345976; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Sha NJ, 2006, BIOINFORMATICS, V22, P2262, DOI 10.1093/bioinformatics/btl362; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Li KC, 2002, P NATL ACAD SCI USA, V99, P16875, DOI 10.1073/pnas.252466999; Chen HY, 2007, NEW ENGL J MED, V356, P11, DOI 10.1056/NEJMoa060096; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; BRESLOW N, 1974, BIOMETRICS, V30, P89, DOI 10.2307/2529620; CHANG HY, 2005, P NATL ACAD SCI USA, V102, P3783; EFRON B, 1977, J AM STAT ASSOC, V72, P557, DOI 10.2307/2286217; Fan C, 2006, NEW ENGL J MED, V355, P560, DOI 10.1056/NEJMoa052933; Hu ZY, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-96; Jiang ZF, 2003, J BIOL CHEM, V278, P10952, DOI 10.1074/jbc.M212112200; Katoh M, 2003, INT J ONCOL, V22, P1369; Klein J., 2003, SURVIVAL ANAL TECHNI; LI H, 2004, BIOINFORMATICS, V21, P3001; Li KC, 1999, ANN STAT, V27, P1; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Li KC, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-10-r205; Li LX, 2004, BIOINFORMATICS, V20, P3406, DOI 10.1093/bioinformatics/bth415; Li LX, 2007, BIOMETRIKA, V94, P603, DOI 10.1093/biomet/asm044; Ma SG, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-192; Nguyen DV, 2002, BIOINFORMATICS, V18, P1625, DOI 10.1093/bioinformatics/18.12.1625; Oakes D., 1984, ANAL SURVIVAL DATA; Prentice RL, 1980, STAT ANAL FAILURE TI; SHEN Q, 2007, ONCOGENE, V27, P366; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; Taniuchi K, 2005, CANCER RES, V65, P105; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vijver MJ, 2002, NEW ENGL J MED, V347, P1999; Zhong WX, 2005, BIOINFORMATICS, V21, P4169, DOI 10.1093/bioinformatics/bti680	33	5	5	0	1	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	OCT 6	2008	9								417	10.1186/1471-2105-9-417		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	372EB	WOS:000260883500001	18837994	
J	Marcia, RF; Kim, C; Eldeniz, C; Kim, J; Brady, DJ; Willett, RM				Marcia, Roummel F.; Kim, Changsoon; Eldeniz, Cihat; Kim, Jungsang; Brady, David J.; Willett, Rebecca M.			Superimposed video disambiguation for increased field of view	OPTICS EXPRESS			English	Article							SOURCE SEPARATION; BLIND SEPARATION; IMAGES; SPARSE	Many infrared optical systems in wide-ranging applications such as surveillance and security frequently require large fields of view (FOVs). Often this necessitates a focal plane array (FPA) with a large number of pixels, which, in general, is very expensive. In a previous paper, we proposed a method for increasing the FOV without increasing the pixel resolution of the FPA by superimposing multiple sub-images within a static scene and disambiguating the observed data to reconstruct the original scene. This technique, in effect, allows each sub-image of the scene to share a single FPA, thereby increasing the FOV without compromising resolution. In this paper, we demonstrate the increase of FOVs in a realistic setting by physically generating a superimposed video from a single scene using an optical system employing a beamsplitter and a movable mirror. Without prior knowledge of the contents of the scene, we are able to disambiguate the two sub-images, successfully capturing both large-scale features and fine details in each sub-image. We improve upon our previous reconstruction approach by allowing each sub-image to have slowly changing components, carefully exploiting correlations between sequential video frames to achieve small mean errors and to reduce run times. We show the effectiveness of this improved approach by reconstructing the constituent images of a surveillance camera video. (c) 2008 Optical Society of America	[Marcia, Roummel F.; Kim, Changsoon; Eldeniz, Cihat; Kim, Jungsang; Brady, David J.; Willett, Rebecca M.] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Marcia, RF (reprint author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	roummel.marcia@duke.edu	Willett, Rebecca/G-6930-2012		DARPA [HR0011-04-C-0111, HR0011-06-C-0109]; ONR [N00014-061-0610]	The authors would like to thank Les Todd, assistant director of Duke Photography, for allowing the use of the "Duke Earth Day" photograph in our physical experiments. The authors were partially supported by DARPA Contract No. HR0011-04-C-0111, ONR Grant No. N00014-061-0610, and DARPA Contract No. HR0011-06-C-0109.	Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wong HSP, 1998, IEEE T ELECTRON DEV, V45, P889, DOI 10.1109/16.662797; Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21; Be'ery E, 2008, IEEE T IMAGE PROCESS, V17, P340, DOI 10.1109/TIP.2007.915548; Bobin J, 2006, IEEE SIGNAL PROC LET, V13, P409, DOI 10.1109/LSP.2006.873141; Bronstein AM, 2005, INT J IMAG SYST TECH, V15, P84, DOI 10.1002/ima.20042; CANDES E, 2006, IEEE T INFO IN PRESS; DONOHO DL, 2006, FAST SOLUTION L 1 NO; FIGUEIREDO MAT, IEEE J SELE IN PRESS; GILLETT JC, 1995, OPT ENG, V34, P3130, DOI 10.1117/12.213590; Gunapala SD, 2005, SEMICOND SCI TECH, V20, P473, DOI 10.1088/0268-1242/20/5/026; Hagiwara Y, 1996, IEEE T ELECTRON DEV, V43, P2122, DOI 10.1109/16.544383; Hardie RC, 1998, OPT ENG, V37, P247, DOI 10.1117/1.601623; Hicks RA, 2007, OPT LETT, V32, P1066, DOI 10.1364/OL.32.001066; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; KRISHNA S, 2005, APPL PHYS LETT, V86, P193; KRISHNA S, 2005, APPL PHYS LETT, V86, P501; Marcia R. F., 2008, P 16 EUR SIGN PROC C; MARCIA RF, P IEEE INT IN PRESS; O'Grady PD, 2005, INT J IMAG SYST TECH, V15, P18, DOI 10.1002/ima.20035; Szeliski R., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), DOI 10.1109/ACV.1994.341287; 2004, 6 IEEE INT WORKSH PE	24	9	9	1	2	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	1094-4087			OPT EXPRESS	Opt. Express	OCT 13	2008	16	21					16352	16363		10.1364/OE.16.016352		12	Optics	Optics	371XB	WOS:000260864900008	18852741	
J	Tsiatis, AA; Davidian, M; Zhang, M; Lu, XM				Tsiatis, Anastasios A.; Davidian, Marie; Zhang, Min; Lu, Xiaomin			Covariate adjustment for two-sample treatment comparisons in randomized clinical trials: A principled yet flexible approach	STATISTICS IN MEDICINE			English	Article; Proceedings Paper	Workshop on Statistical Methods in HIV/AIDS and its Practical Applications	OCT   10, 2006	Bethesda, MD	NIAID		baseline variables; clinical trials; covariate adjustment; efficiency; semiparametric theory; variable selection	SUBGROUP ANALYSIS; INTRODUCTORY NOTE; PRETEST-POSTTEST; SELECTION; DIFFERENCE; MODEL	There is considerable debate regarding whether and how covariate-adjusted analyses should be used in the comparison of treatments in randomized clinical trials. Substantial baseline covariate information is routinely collected in such trials, and one goal of adjustment is to exploit covariates associated with outcome to increase precision of estimation of the treatment effect. However, concerns are routinely raised over the potential for bias when the covariates used are selected post hoc and the potential for adjustment based on a model of the relationship between outcome, covariates, and treatment to invite a 'fishing expedition' for that leading to the most dramatic effect estimate. By appealing to the theory of semiparametrics, we are led naturally to a characterization of all treatment effect estimators and to principled, practically feasible methods for covariate adjustment that yield the desired gains in efficiency and that allow covariate relationships to be identified and exploited while circumventing the usual concerns. The methods and strategies for their implementation in practice are presented. Simulation studies and an application to data from an HIV clinical trial demonstrate the performance of the techniques relative to the existing methods. Copyright (C) 2007 John Wiley & Sons, Ltd.	[Tsiatis, Anastasios A.; Davidian, Marie; Zhang, Min] N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA; [Lu, Xiaomin] Univ Florida, Dept Epidemiol & Biostat, Gainesville, FL 32611 USA	Davidian, M (reprint author), N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA.	davidian@stat.ncsu.edu					Altman DG, 2005, ENCY BIOSTATISTICS, P1273; ROBINS JM, 1994, J AM STAT ASSOC, V89, P846, DOI 10.2307/2290910; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Pocock SJ, 2002, STAT MED, V21, P2917, DOI 10.1002/sim.1296; Assmann SF, 2000, LANCET, V355, P1064, DOI 10.1016/S0140-6736(00)02039-0; Hammer SM, 1996, NEW ENGL J MED, V335, P1081, DOI 10.1056/NEJM199610103351501; Brookhart MA, 2006, COMPUT STAT DATA AN, V50, P475, DOI 10.1016/j.csda.2004.08.013; Carroll R.J., 2006, MEASUREMENT ERROR NO; CASSEL CM, 1976, BIOMETRIKA, V63, P615, DOI 10.1093/biomet/63.3.615; Cochran W.G., 1977, SAMPLING TECHNIQUES; Davidian M, 2005, STAT SCI, V20, P261, DOI 10.1214/088342305000000151; Grouin JM, 2004, STAT MED, V23, P697, DOI 10.1002/sim.1646; Harrell FE, 2001, REGRESSION MODELING; Hastie TJ, 1990, GEN ADDITIVE MODELS; Hauck WW, 1998, CONTROL CLIN TRIALS, V19, P249, DOI 10.1016/S0197-2456(97)00147-5; Koch GG, 1998, STAT MED, V17, P1863, DOI 10.1002/(SICI)1097-0258(19980815/30)17:15/16<1863::AID-SIM989>3.3.CO;2-D; Korsholm L, 2003, CONTROL CLIN TRIALS, V24, p62S; Leon S, 2003, BIOMETRICS, V59, P1048; Lesaffre E, 2003, STAT MED, V22, P3586; Lesaffre E, 2002, CONTROL CLIN TRIALS, V23, P127, DOI 10.1016/S0197-2456(01)00201-X; Lewis JA, 1999, STAT MED, V18, P1903, DOI 10.1002/(SICI)1097-0258(19990815)18:15<1903::AID-SIM188>3.0.CO;2-F; Raab GM, 2000, CONTROL CLIN TRIALS, V21, P330, DOI 10.1016/S0197-2456(00)00061-1; ROBINS JM, 2000, ASA P BAYES STAT SCI, P6; Sarndal C, 1992, MODEL ASSISTED SURVE; Senn S, 2000, J ROY STAT SOC D-STA, V49, P135, DOI 10.1111/1467-9884.00227; SENN SJ, 1989, STAT MED, V8, P467, DOI 10.1002/sim.4780080410; Shen XT, 2004, J AM STAT ASSOC, V99, P751, DOI 10.1198/016214504000001097; Stefanski LA, 2002, AM STAT, V56, P29, DOI 10.1198/000313002753631330; TSIATIS A. A., 2006, SEMIPARAMETRIC THEOR; WU T, 2007, J AM STAT ASSOC, V102, P235; Yang L, 2001, AM STAT, V55, P314, DOI 10.1198/000313001753272466	32	55	55	3	6	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0277-6715			STAT MED	Stat. Med.	OCT 15	2008	27	23			SI		4658	4677		10.1002/sim.3113		20	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Medicine, Research & Experimental; Statistics & Probability	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Research & Experimental Medicine; Mathematics	353FB	WOS:000259550400006	17960577	
J	Slawski, M; Daumer, M; Boulesteix, AL				Slawski, M.; Daumer, M.; Boulesteix, A-L			CMA - a comprehensive Bioconductor package for supervised classification with high dimensional data	BMC BIOINFORMATICS			English	Article							GENE-EXPRESSION; CROSS-VALIDATION; MICROARRAY CLASSIFICATION; DISCRIMINANT-ANALYSIS; SHRUNKEN CENTROIDS; VARIABLE SELECTION; CLASS PREDICTION; ERROR ESTIMATION; MODEL SELECTION; NEURAL NETWORKS	Background: For the last eight years, microarray-based classification has been a major topic in statistics, bioinformatics and biomedicine research. Traditional methods often yield unsatisfactory results or may even be inapplicable in the so-called "p >> n" setting where the number of predictors p by far exceeds the number of observations n, hence the term "ill-posed-problem". Careful model selection and evaluation satisfying accepted good-practice standards is a very complex task for statisticians without experience in this area or for scientists with limited statistical background. The multiplicity of available methods for class prediction based on high-dimensional data is an additional practical challenge for inexperienced researchers. Results: In this article, we introduce a new Bioconductor package called CMA (standing for "Classification for MicroArrays") for automatically performing variable selection, parameter tuning, classifier construction, and unbiased evaluation of the constructed classifiers using a large number of usual methods. Without much time and effort, users are provided with an overview of the unbiased accuracy of most top-performing classifiers. Furthermore, the standardized evaluation framework underlying CMA can also be beneficial in statistical research for comparison purposes, for instance if a new classifier has to be compared to existing approaches. Conclusion: CMA is a user-friendly comprehensive package for classifier construction and evaluation implementing most usual approaches. It is freely available from the Bioconductor website at http://bioconductor.org/packages/2.3/bioc/html/CMA.html.	[Slawski, M.; Daumer, M.; Boulesteix, A-L] Sylvia Lawry Ctr Multiple Sclerosis Res, D-81677 Munich, Germany; [Boulesteix, A-L] Univ Munich, Dept Stat, D-80539 Munich, Germany	Boulesteix, AL (reprint author), Sylvia Lawry Ctr Multiple Sclerosis Res, Hohenlindenerstr 1, D-81677 Munich, Germany.	martin.slawski@campus.lmu.de; daumer@slcmsr.org; boulesteix@stat.uni-muenchen.de	Boulesteix, Anne-Laure/A-3948-2010		Porticus Foundation	We thank the four referees for their very constructive comments which helped us to improve this manuscript. This work was partially supported by the Porticus Foundation in the context of the International School for Technical Medicine and Clinical Bioinformatics.	Boulesteix AL, 2007, BRIEF BIOINFORM, V8, P32, DOI 10.1093/bib/bb1016; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hastie T, 2004, BIOSTATISTICS, V5, P329, DOI 10.1093/biostatistics/kxh010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Bovelstad HM, 2007, BIOINFORMATICS, V23, P2080, DOI 10.1093/bioinformatics/btm305; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Berrar D, 2006, BIOINFORMATICS, V22, P1245, DOI 10.1093/bioinformatics/btl066; Binder H, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-14; Boulesteix AL, 2007, BIOINFORMATICS, V23, P1702, DOI 10.1093/bioinformatics/btm162; Boulesteix A.-L., 2004, STAT APPL GENET MOL, V3, P33, DOI DOI 10.2202/1544-6115.1075; Boulesteix AL, 2008, BIOINFORMATICS, V24, P1698, DOI 10.1093/bioinformatics/btn262; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Chambers J. M., 1998, PROGRAMMING DATA; Daumer M, 2008, BMC MED RES METHODOL, V8, DOI 10.1186/1471-2288-8-18; Davis CA, 2006, BIOINFORMATICS, V22, P2356, DOI 10.1093/bioinformatics/btl400; Diaz-Uriarte R, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-30; Dudoit S., 2005, BIOINFORMATICS COMPU; Dupuy A, 2007, J NATL CANCER I, V99, P147, DOI 10.1093/jnci/dik018; Efron B, 1993, INTRO BOOTSTRAP; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Gentleman RC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-10-r80; Golub G. H., 1983, MATRIX COMPUTATIONS; Hastie T., 2001, ELEMENTS STAT LEARNI; HASTIE T, 2008, IMPUTATION MICROARRA; Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Ioannidis JPA, 2005, LANCET, V365, P454, DOI 10.1016/S0140-6736(05)17878-7; MAR J, 2007, MLINTERFACES UNIFORM; McLachlan G., 1992, DISCRIMINANT ANAL ST; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Ripley B. D., 1996, PATTERN RECOGNITION; Ruschhaupt M., 2004, STAT APPL GENET MOL, V3; RUSCHHAUPT M, 2007, MCRESTIMATE MISCLASS; Scholkopf B., 2002, LEARNING KERNELS; Schumacher M, 2007, BIOINFORMATICS, V23, P1768, DOI 10.1093/bioinformatics/btm232; SLAWSKI M, 2008, BIOCONDUCTOR; Smyth G. K., 2004, STAT APPL GENET MOL, V3, DOI [10.2202/1544-6115.1027, DOI 10.2202/1544-6115.1027]; VANWIERINGEN W, 2008, COMPUTATION IN PRESS; Wood SN, 2006, GEN ADDITIVE MODELS; Young-Park M, 2007, J ROYAL STAT SOC B, V69, P659; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	60	40	40	1	11	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	OCT 16	2008	9								439	10.1186/1471-2105-9-439		17	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	415YE	WOS:000263971600001	18925941	
J	Roll, J				Roll, Jacob			Piecewise linear solution paths with application to direct weight optimization	AUTOMATICA			English	Article						Parametric programming; Piecewise quadratic programming; Function approximation; Nonlinear system identification; Nonparametric identification	REGRESSION; SELECTION	Recently, pathfollowing algorithms for parametric optimization problems with piecewise linear solution paths have been developed within the field of regularized regression. This paper presents a generalization of these algorithms to a wider class of problems. It is shown that the approach can be applied to the nonparametric system identification method, Direct Weight Optimization (DWO), and be used to enhance the computational efficiency of this method. The most important design parameter in the DWO method is a parameter (lambda) controlling the bias-variance trade-off, and the use of parametric optimization with piecewise linear solution paths means that the DWO estimates can be efficiently computed for all values of lambda simultaneously. This allows for designing computationally attractive adaptive bandwidth selection algorithms. One such algorithm for DWO is proposed and demonstrated in two examples. 0 2008 Elsevier Ltd. All rights reserved.	Linkoping Univ, Div Automat Control, SE-58183 Linkoping, Sweden	Roll, J (reprint author), Linkoping Univ, Div Automat Control, SE-58183 Linkoping, Sweden.	jacob.roll@autoliv.com					Akaike H., 1973, 2 INT S INF THEOR, P267; Bontempi G, 1999, INT J CONTROL, V72, P643, DOI 10.1080/002071799220830; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bemporad A, 2002, AUTOMATICA, V38, P3, DOI 10.1016/S0005-1098(01)00174-1; Efron B, 2004, ANN STAT, V32, P407; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Atkeson CG, 1997, ARTIF INTELL REV, V11, P75, DOI 10.1023/A:1006511328852; Borrelli F., 2003, LECT NOTES CONTROL I, V290; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; GUDDAT J., 1990, PARAMETRIC OPTIMIZAT; Hardle W, 1990, ECONOMETRIC SOC MONO, V19; Juditsky A., 2004, 6th IFAC Symposium on Nonlinear Control Systems (NOLCOS 2004); MAYNE DQ, 2007, EUR CONTR C, P2762; NAZIN A, 2006, 14 IFAC S SYST ID; Pistikopoulos E., 2007, MULTIPARAMETRIC PROG, V1; Rockafellar R.T., 1970, CONVEX ANAL; ROLL J, 2005, 16 IFAC WORLD C AUT; ROLL J, 2007, LITHISYR2816 LINK U; Roll J., 2003, THESIS LINKOPING U L; Roll J, 2005, AUTOMATICA, V41, P475, DOI 10.1016/j.automatica.2004.11.010; Rosset S, 2004, ANN STAT, V32, P469; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Stenman A, 1999, THESIS LINKOPING U L; Tondel P, 2003, AUTOMATICA, V39, P489, DOI 10.1016/S0005-1098(02)00250-9; Vandenberghe L., 2004, CONVEX OPTIMIZATION	27	8	9	1	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0005-1098			AUTOMATICA	Automatica	NOV	2008	44	11					2745	2753		10.1016/j.automatica.2008.03.020		9	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	378UP	WOS:000261350000006		
J	Cosgrove, EJ; Zhou, Y; Gardner, TS; Kolaczyk, ED				Cosgrove, Elissa J.; Zhou, Yingchun; Gardner, Timothy S.; Kolaczyk, Eric D.			Predicting gene targets of perturbations via network-based filtering of mRNA expression compendia	BIOINFORMATICS			English	Article							ESCHERICHIA-COLI; VARIABLE SELECTION; METABOLIC NETWORKS; BIOLOGY APPROACH; PROFILES; LASSO; ALGORITHM; CLASSIFICATION; IDENTIFICATION; ORGANIZATION	Motivation: DNA microarrays are routinely applied to study diseased or drug-treated cell populations. A critical challenge is distinguishing the genes directly affected by these perturbations from the hundreds of genes that are indirectly affected. Here, we developed a sparse simultaneous equation model (SSEM) of mRNA expression data and applied Lasso regression to estimate the model parameters, thus constructing a network model of gene interaction effects. This inferred network model was then used to filter data from a given experimental condition of interest and predict the genes directly targeted by that perturbation. Results: Our proposed SSEM-Lasso method demonstrated substantial improvement in sensitivity compared with other tested methods for predicting the targets of perturbations in both simulated datasets and microarray compendia. In simulated data, for two different network types, and over a wide range of signal-to-noise ratios, our algorithm demonstrated a 167% increase in sensitivity on average for the top 100 ranked genes, compared with the next best method. Our method also performed well in identifying targets of genetic perturbations in microarray compendia, with up to a 24% improvement in sensitivity on average for the top 100 ranked genes. The overall performance of our network-filtering method shows promise for identifying the direct targets of genetic dysregulation in cancer and disease from expression profiles.	[Zhou, Yingchun; Kolaczyk, Eric D.] Boston Univ, Dept Math & Stat, Boston, MA 02215 USA; [Cosgrove, Elissa J.; Gardner, Timothy S.] Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA	Kolaczyk, ED (reprint author), Boston Univ, Dept Math & Stat, Boston, MA 02215 USA.				National Science Foundation (NSF)/National Institutes of Health (NIH) [1R01GM078987-01]	National Science Foundation (NSF)/National Institutes of Health (NIH) Mathematical Biology Program (1R01GM078987-01).	Ravasz E, 2002, SCIENCE, V297, P1551, DOI 10.1126/science.1073374; Kohanski MA, 2007, CELL, V130, P797, DOI 10.1016/j.cell.2007.06.049; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Mnaimneh S, 2004, CELL, V118, P31, DOI 10.1016/j.cell.2004.06.013; Jeong H, 2001, NATURE, V411, P41, DOI 10.1038/35075138; Jeong H, 2000, NATURE, V407, P651; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Courcelle J, 2001, GENETICS, V158, P41; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Barrett T, 2007, NUCLEIC ACIDS RES, V35, pD760, DOI 10.1093/nar/gkl887; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Marton MJ, 1998, NAT MED, V4, P1293, DOI 10.1038/3282; Bonneau R, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-5-r36; di Bernardo D, 2005, NAT BIOTECHNOL, V23, P377, DOI 10.1038/nbt1075; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; Dwyer DJ, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100135; Ergun A, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100125; Faith JJ, 2007, PLOS BIOL, V5, P54, DOI 10.1371/journal.pbio.0050008; FAITH JJ, 2007, NUCLEIC ACIDS RES, DOI DOI 10.1093/NAR/GKM815; Hastie T., 2001, ELEMENTS STAT LEARNI; Irizarry RA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng015; Leng CL, 2006, STAT SINICA, V16, P1273; Liao JC, 2003, P NATL ACAD SCI USA, V100, P15522, DOI 10.1073/pnas.2136632100; Ma SG, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-60; Miklos GLG, 2004, NAT BIOTECHNOL, V22, P615, DOI 10.1038/nbt965; Natsoulis G, 2005, GENOME RES, V15, P724, DOI 10.1101/gr.2807605; Newman MEJ, 2003, HANDBOOK OF GRAPHS AND NETWORKS: FROM THE GENOME TO THE INTERNET, P35; Parkinson H, 2007, NUCLEIC ACIDS RES, V35, pD747, DOI 10.1093/nar/gkl995; Tibshirani R, 2007, BIOSTATISTICS, V8, P2, DOI 10.1093/biostatistics/kx1005; Xing HM, 2006, NAT PROTOC, V1, P2551, DOI 10.1038/nprot.2006.300	34	12	12	2	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	NOV 1	2008	24	21					2482	2490		10.1093/bioinformatics/btn476		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	365BP	WOS:000260381200010	18779235	
J	Binder, H; Schumacher, M				Binder, Harald; Schumacher, Martin			Comment on 'network-constrained regularization and variable selection for analysis of genomic data'	BIOINFORMATICS			English	Letter							SURVIVAL MODELS; PREDICTION		[Binder, Harald] Univ Freiburg, Freiburg Ctr Data Anal & Modeling, D-79104 Freiburg, Germany; [Binder, Harald; Schumacher, Martin] Univ Freiburg, Inst Med Biometry & Med Informat, D-79104 Freiburg, Germany	Binder, H (reprint author), Univ Freiburg, Freiburg Ctr Data Anal & Modeling, Stefan Meier Str 26, D-79104 Freiburg, Germany.		Binder, Harald/C-7413-2009	Binder, Harald/0000-0002-5666-8662			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Gerds TA, 2006, BIOMETRICAL J, V48, P1029, DOI 10.1002/bimj.200610301; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; Binder H, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-14; Binder H, 2008, STAT APPL GENET MOL, V7; Gerds TA, 2007, BIOMETRICS, V63, P1283, DOI 10.1111/j.1541-0420.2007.00832.x; Horvath S, 2006, P NATL ACAD SCI USA, V103, P17402, DOI 10.1073/pnas.0608396103; Li CY, 2008, BIOINFORMATICS, V24, P1175, DOI 10.1093/bioinformatics/btn081; Schumacher M, 2007, BIOINFORMATICS, V23, P1768, DOI 10.1093/bioinformatics/btm232	12	5	5	0	7	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	NOV 1	2008	24	21					2566	2568		10.1093/bioinformatics/btn412		3	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	365BP	WOS:000260381200030	18682424	
J	Wang, J; Tao, Q				Wang, Jue; Tao, Qing			Machine Learning: The State of the Art	IEEE INTELLIGENT SYSTEMS			English	Article							SUPPORT VECTOR MACHINES; NONLINEAR DIMENSIONALITY REDUCTION; RISK MINIMIZATION; CLASSIFICATION; REGRESSION; RULE; LEARNABILITY; SELECTION		[Wang, Jue; Tao, Qing] Chinese Acad Sci, Inst Automat, Beijing 100864, Peoples R China	Wang, J (reprint author), Chinese Acad Sci, Inst Automat, Beijing 100864, Peoples R China.	jue.wang@mail.ia.ac.cn; qing.tao@mail.ia.ac.cn			Chinese National Basic Research Program [2004CB318103]; Natural Science Foundation of China [60835002]	The Chinese National Basic Research Program (2004CB318103) and Natural Science Foundation of China grant 60835002 supported this research.	Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Tao Q, 2005, IEEE T NEURAL NETWOR, V16, P1561, DOI 10.1109/tnn.2005.857955; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; Efron B, 2004, ANN STAT, V32, P407; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Duda R. O., 1973, PATTERN CLASSIFICATI; Hastie T., 2006, STAT SCI, V21, P352, DOI 10.1214/088342306000000466; Herbrich R., 1999, P 9 INT C ART NEUR N, P97; Hunt Earl B, 1966, EXPT INDUCTION; Lavrae N., 2001, RELATIONAL DATA MINI; Liang HL, 2007, COMPUT J, V50, P421, DOI 10.1093/comjnl/bxm012; MINSKY M, 1988, PERCEPTRON; Motoda H., 1998, FEATURE SELECTION KN; NOSOFSKY RM, 1994, PSYCHOL REV, V101, P53, DOI 10.1037/0033-295X.101.1.53; Pawlak Z., 1991, ROUGH SETS THEORETIC; Quinlan JR, 1986, MACH LEARN, V1, P106; ROSENBLATT F, 1957, 854601 CORN U AER LA; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED; SAMUEL AL, 1967, IBM J RES DEV, V11, P601; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Scharloo M, 1999, J RHEUMATOL, V26, P1686; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; SHEPARD RN, 1961, PSYCHOL MONOGR, V75, P1; Simon H. A., 1983, MACHINE LEARNING ART, P25; SOLOMONOFF R, 1959, P INT C INF PROC PAR, P285; STEINWART I, 2002, WHICH DATA DEPENDENT; Tao Q, 2008, IEEE T NEURAL NETWOR, V19, P189, DOI 10.1109/TNN.2007.908267; Tao Q, 2005, PATTERN RECOGN, V38, P1071, DOI 10.1016/j.patcog.2004.10.010; Tao Q, 2007, PATTERN RECOGN, V40, P2633, DOI 10.1016/j.patcog.2007.01.022; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V.N., 1995, NATURE STAT LEARNING; Von Neumann J., 1932, MATH FDN QUANTUM MEC; Wang J, 2003, AI COMMUN, V16, P17; Xing E.P., 2003, ADV NEURAL INFORMATI, V15, P505; YAO YY, 2005, IEEE INTELL SYST APP, P52; Zhang T, 2004, ANN STAT, V32, P56; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2	47	0	4	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1541-1672			IEEE INTELL SYST	IEEE Intell. Syst.	NOV-DEC	2008	23	6					49	55				7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	398XI	WOS:000262764400010		
J	Donoho, DL; Tsaig, Y				Donoho, David L.; Tsaig, Yaakov			Fast Solution of l(1)-Norm Minimization Problems When the Solution May Be Sparse	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						basis pursuit; l(1) minimization; HOMOTOPY methods; Least Angle Regression (LARS); LASSO; orthogonal matching pursuit; polytope faces pursuit; sparse representations; underdetermined systems of linear equations	LARGE UNDERDETERMINED SYSTEMS; UNCERTAINTY PRINCIPLES; SIGNAL RECOVERY; REPRESENTATIONS; DECOMPOSITION; REGRESSION; SELECTION; EQUATIONS; LASSO; BASES	The minimum l(1)-norm solution to an underdetermined system of linear equations y = Ax is often, remarkably, also the sparsest solution to that system. This sparsity-seeking property is of interest in signal processing and information transmission. However, general-purpose optimizers are much too slow for l(1) minimization in many large-scale applications. In this paper, the Homotopy method, originally proposed by Os-borne et al. and Efron et al., is applied to the underdetermined l(1)-minimization problem min parallel to x parallel to(1) subject to y = Ax. Homotopy is shown to run much more rapidly than general-purpose LP solvers when sufficient sparsity is present. Indeed, the method often has the following k-step solution property: if the underlying solution has only k nonzeros, the Homotopy method reaches that solution in only k iterative steps. This k-step solution property is demonstrated for several ensembles of matrices, including incoherent matrices, uniform spherical matrices, and partial orthogonal matrices. These results imply that Homotopy may be used to rapidly decode error-correcting codes in a stylized communication system with a computational budget constraint. The approach also sheds light on the evident parallelism in results on l(1) minimization and Orthogonal Matching Pursuit (OMP), and aids in explaining the inherent relations between HOMOTOPY, Least Angle Regression (LARS), OMP, and polytope faces pursuit.	[Donoho, David L.] Stanford Univ, Dept Stat, Stanford, CA 94305 USA; [Tsaig, Yaakov] Stanford Univ, Inst Computat & Math Engn, Stanford, CA 94035 USA	Donoho, DL (reprint author), Stanford Univ, Dept Stat, Stanford, CA 94305 USA.				NIH; ONR-MURI; NSF [DMS 00-77261, DMS 01-40698 (FRG), DMS 05-05303]	This work was supported in part by grants front NIH, ONR-MURI, and NSF DMS 00-77261. DMS 01-40698 (FRG) and DMS 05-05303.	Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI 10.1016/j.sigpro.2005.05.029; Efron B, 2004, ANN STAT, V32, P407; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Starck JL, 2004, ADV IMAG ELECT PHYS, V132, P287, DOI 10.1016/S1076-5670(04)32006-9; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Berkelaar M., LP SOLVE MIXED INTEG; Bertsekas D., 2003, CONVEX ANAL OPTIMIZA; BRIGGS WL, 1995, DFT OWNERS MANUAL DI; Buckheit J. B., 1995, WAVELETS STAT, P55; CANDES EJ, 2005, PRACTICAL SIGN UNPUB; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; CHOI SC, BEAMLAB WEB SITE; Davis BH, 1997, HDB HETEROGENEOUS CA, P13; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Donoho D. L., 2006, SPARSE SOLUTIO UNPUB; Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028; Donoho D.L., 2005, NEIGHBORLY POLYTOPES; DONOHO DL, 1992, SIAM J APPL MATH, V52, P577, DOI 10.1137/0152031; Donoho DL, 2006, DISCRETE COMPUT GEOM, V35, P617, DOI 10.1007/s00454-005-1220-0; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; DONOHO DL, 2008, J AM MATH S IN PRESS; DRORI I, 2006, P IEEE INT C AC SPEE; EFRON B, LARS SOFTARE WEB SIT; ELAD M, APPL COMP H IN PRESS; Fuchs JJ, 2004, IEEE T INFORM THEORY, V50, P1341, DOI 10.1109/TIT.2004.828141; Garnaev A.Y., 1984, SOV MATH DOKL, V30, P200; Gilbert A. C., 2002, P 34 ACM S THEOR COM, P152; Golub G., 1996, MATRIX COMPUTATIONS; Gribonval R., 2003, IEEE T INFORM THEORY, V49, P1320; GRIBONVAL R, 2006, HIGHLY SPAR IN PRESS; Harwit M., 1979, HADAMARD TRANSFORM O; Hastie T., 2001, ELEMENTS STAT LEARNI; Kashin B.S., 1977, IZV AN SSSR M, V41, P334; LUSTIG M, 2004, P 13 INT SOC MAGN RE; LUSTIG M, 2006, P 9 ANN M SOC CARD M; Malioutov D., 2005, P IEEE INT C AC SPEE, V5, P733, DOI 10.1109/ICASSP.2005.1416408; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; PLUMBLEY M, 2006, P INT C IND COMP AN, P206; Plumbley M. D., 2005, P C SIGN PROC AD SPA, P206; Rudelson M., 2005, GEOMETRIC APPROACH E; SAUNDERS M. A., PDCO PRIMAL DUAL INT; Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206; STROMTEJSEN P, 2003, P HLTH BUILD 2003 SI, V3, P257; TROPP JA, 2006, IEEE T INFORM THEORY, V51, P1030; TROPP JA, 2005, SIGNAL RECOVER UNPUB	55	178	194	7	25	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	NOV	2008	54	11					4789	4812		10.1109/TIT.2008.929958		24	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	365RV	WOS:000260426400001		
J	Fan, JQ; Lv, JC				Fan, Jianqing; Lv, Jinchi			Sure independence screening for ultrahigh dimensional feature space	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Adaptive lasso; Dantzig selector; Dimensionality reduction; Lasso; Oracle estimator; Smoothly clipped absolute deviation; Sure independence screening; Sure screening; Variable selection	NONCONCAVE PENALIZED LIKELIHOOD; VARIABLE SELECTION; SMALLEST EIGENVALUE; ORACLE PROPERTIES; GENE-EXPRESSION; MODEL SELECTION; RANDOM MATRICES; LASSO; REGRESSION; CANCER	Variable selection plays an important role in high dimensional statistical modelling which nowadays appears in many areas and is key to various scientific discoveries. For problems of large scale or dimensionality p, accuracy of estimation and computational cost are two top concerns. Recently, Candes and Tao have proposed the Dantzig selector using L(1)-regularization and showed that it achieves the ideal risk up to a logarithmic factor log(p). Their innovative procedure and remarkable result are challenged when the dimensionality is ultrahigh as the factor log(p) can be large and their uniform uncertainty principle can fail. Motivated by these concerns, we introduce the concept of sure screening and propose a sure screening method that is based on correlation learning, called sure independence screening, to reduce dimensionality from high to a moderate scale that is below the sample size. In a fairly general asymptotic framework, correlation learning is shown to have the sure screening property for even exponentially growing dimensionality. As a methodological extension, iterative sure independence screening is also proposed to enhance its finite sample performance. With dimension reduced accurately from high to below sample size, variable selection can be improved on both speed and accuracy, and can then be accomplished by a well-developed method such as smoothly clipped absolute deviation, the Dantzig selector, lasso or adaptive lasso. The connections between these penalized least squares methods are also elucidated.	[Fan, Jianqing] Princeton Univ, Dept Operat Res & Financial Engn, Princeton, NJ 08544 USA; [Lv, Jinchi] Univ So Calif, Los Angeles, CA USA	Fan, JQ (reprint author), Princeton Univ, Dept Operat Res & Financial Engn, Princeton, NJ 08544 USA.	jqfan@princeton.edu	Lv, Jinchi/D-2295-2012				BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Knight K, 2000, ANN STAT, V28, P1356; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Fan JQ, 2006, CLIN CANCER RES, V12, P4469, DOI 10.1158/1078-0432.CCR-06-1033; Bickel PJ, 2008, ANN STAT, V36, P199, DOI 10.1214/009053607000000758; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Huang J, 2008, ANN STAT, V36, P587, DOI 10.1214/009053607000000875; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; BAI ZD, 1993, ANN PROBAB, V21, P1275, DOI 10.1214/aop/1176989118; Meier L, 2008, J R STAT SOC B, V70, P53; Hall P, 2005, J ROY STAT SOC B, V67, P427, DOI 10.1111/j.1467-9868.2005.00510.x; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Johnstone IM, 2001, ANN STAT, V29, P295, DOI 10.1214/aos/1009210544; Bai ZD, 1999, STAT SINICA, V9, P611; Baron D., 2005, DISTRIBUTED CO UNPUB; Barron AR, 2008, ANN STAT, V36, P64, DOI 10.1214/009053607000000631; BICKEL PJ, 2008, ANN STAT IN PRESS, V36; Breiman L, 1996, ANN STAT, V24, P2350; Chikuse Y., 2003, LECT NOTES STAT; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Donoho D. L, 2000, AM MATH SOC C MATH C; Eaton M. L., 1989, GROUP INVARIANCE APP; FAN J, 2008, AM STAT IN PRESS; Fan J., 1997, J ITALIAN STAT ASS, V6, P131; Fan J., 2006, P INT C MATH, P595; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2002, ANN STAT, V30, P74; GEMAN S, 1980, ANN PROBAB, V8, P252, DOI 10.1214/aop/1176994775; George EI, 1997, STAT SINICA, V7, P339; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; Greenshtein E, 2006, ANN STAT, V34, P2367, DOI 10.1214/009053606000000768; Grenander U., 1984, TOEPLITZ FORMS THEIR; GRIBONVAL R, 2007, P INT C AC SPEECH SI; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; LAM C, 2007, SPARSISTENCY R UNPUB; Ledoux M, 2001, CONCENTRATION MEASUR; LEDOUX M, 2005, DEVIATION INEQ UNPUB; Meinshausen N, 2007, ANN STAT, V35, P2373, DOI 10.1214/009053607000000460; MEINSHAUSEN N, 2007, COMPUTNL STAT DATA A, V52, P393; MEINSHAUSEN N, 2007, ANN STAT, V35, P2384; MEINSHAUSEN N, 2006, ANN STAT, V34, P61462; Nikolova M, 2000, SIAM J APPL MATH, V61, P633, DOI 10.1137/S0036139997327794; PAUL D, 2008, ANN STAT IN PRESS; Ravikumar P., 2007, SPARSE ADDITIV UNPUB; SILVERSTEIN JW, 1985, ANN PROBAB, V13, P1364, DOI 10.1214/aop/1176992819; Van der Vaart A., 1996, WEAK CONVERGENCE EMP; Zhang C. H., 2007, 2007003 RUTG U DEP S; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520; ZHANG CH, 2008, ANN STAT, V36, P1594; ZOU H, 2008, ANN STAT IN PRESS; ZOU H, 2006, J AM STAT ASSOC, V101, P1429	65	335	341	11	28	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.	NOV	2008	70						849	883		10.1111/j.1467-9868.2008.00674.x		35	Statistics & Probability	Mathematics	400EM	WOS:000262850800001		
J	Bickel, P; Buhlmann, P; Yao, QW; Samworth, R; Hall, P; Titterington, DM; Xue, JH; Anagnostopoulos, C; Tasoullis, DK; Zhang, WY; Xia, YC; Johnstone, IM; Richardson, S; Bottolo, L; Kent, JT; Adragni, K; Cook, RD; Gather, U; Guddat, C; Greenshtein, E; James, GM; Radchenko, P; Leng, CL; Wang, HS; Levina, E; Zhu, J; Li, RZ; Liu, YF; Longford, NT; Luo, WQ; Baxter, PD; Taylor, CC; Marron, JS; Morris, JS; Robert, CP; Yu, KM; Zhang, CH; Zhang, HH; Zhou, HH; Lin, XH; Zou, H				Bickel, Peter; Buehlmann, Peter; Yao, Qiwei; Samworth, Richard; Hall, Peter; Titterington, D. M.; Xue, Jing-Hao; Anagnostopoulos, C.; Tasoullis, D. K.; Zhang, Wenyang; Xia, Yingcun; Johnstone, Iain M.; Richardson, Sylvia; Bottolo, Leonardo; Kent, John T.; Adragni, Kofi; Cook, R. Dennis; Gather, Ursula; Guddat, Charlotte; Greenshtein, Eitan; James, Gareth M.; Radchenko, Peter; Leng, Chenlei; Wang, Hansheng; Levina, Elizaveta; Zhu, Ji; Li, Runze; Liu, Yufeng; Longford, N. T.; Luo, Weiqi; Baxter, Paul D.; Taylor, Charles C.; Marron, J. S.; Morris, Jeffrey S.; Robert, Christian P.; Yu, Keming; Zhang, Cun-Hui; Zhang, Hao Helen; Zhou, Harrison H.; Lin, Xihong; Zou, Hui			Sure independence screening for ultrahigh dimensional feature space Discussion	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Editorial Material							NONCONCAVE PENALIZED LIKELIHOOD; SUPPORT VECTOR MACHINES; VARIABLE SELECTION; MODEL SELECTION; GEOMETRIC REPRESENTATION; INVERSE REGRESSION; ORACLE PROPERTIES; ADAPTIVE LASSO; LINEAR-MODELS; CLASSIFICATION		[Bickel, Peter] Univ Calif Berkeley, Berkeley, CA 94720 USA; [Buehlmann, Peter] ETH, Zurich, Switzerland; [Yao, Qiwei] Univ London London Sch Econ & Polit Sci, London WC2A 2AE, England; [Samworth, Richard] Univ Cambridge, Cambridge CB2 1TN, England; [Hall, Peter] Univ Melbourne, Melbourne, Vic 3010, Australia; [Titterington, D. M.; Xue, Jing-Hao] Univ Glasgow, Glasgow G12 8QQ, Lanark, Scotland; [Anagnostopoulos, C.; Tasoullis, D. K.; Richardson, Sylvia; Bottolo, Leonardo] Univ London Imperial Coll Sci Technol & Med, London SW7 2AZ, England; [Zhang, Wenyang] Univ Bath, Bath BA2 7AY, Avon, England; [Xia, Yingcun; Leng, Chenlei] Natl Univ Singapore, Singapore, Singapore; [Johnstone, Iain M.] Stanford Univ, Stanford, CA 94305 USA; [Kent, John T.; Luo, Weiqi; Baxter, Paul D.; Taylor, Charles C.] Univ Leeds, Leeds LS2 9JT, W Yorkshire, England; [Adragni, Kofi; Cook, R. Dennis; Zou, Hui] Univ Minnesota, Minneapolis, MN USA; [Gather, Ursula; Guddat, Charlotte] Dortmund Univ Technol, Dortmund, Germany; [Greenshtein, Eitan] Duke Univ, Durham, NC 27706 USA; [James, Gareth M.; Radchenko, Peter] Univ So Calif, Los Angeles, CA USA; [Wang, Hansheng] Peking Univ, Beijing 100871, Peoples R China; [Levina, Elizaveta; Zhu, Ji] Univ Michigan, Ann Arbor, MI 48109 USA; [Li, Runze] Penn State Univ, University Pk, PA 16802 USA; [Liu, Yufeng; Marron, J. S.] Univ N Carolina, Chapel Hill, NC USA; [Longford, N. T.] SNTL, Reading, Berks, England; [Longford, N. T.] Univ Pompeu Fabra, Barcelona, Spain; [Morris, Jeffrey S.] Univ Texas MD Anderson Canc Ctr, Houston, TX 77030 USA; [Robert, Christian P.] Univ Paris 09, Malakoff, France; [Robert, Christian P.] Ctr Rech Econ & Stat, Malakoff, France; [Yu, Keming] Brunel Univ, Uxbridge UB8 3PH, Middx, England; [Zhang, Cun-Hui] Rutgers State Univ, Piscataway, NJ USA; [Zhang, Hao Helen] N Carolina State Univ, Raleigh, NC 27695 USA; [Zhou, Harrison H.] Yale Univ, New Haven, CT USA; [Lin, Xihong] Harvard Univ, Cambridge, MA 02138 USA	Bickel, P (reprint author), Univ Calif Berkeley, Berkeley, CA 94720 USA.		Anagnostopoulos, Christoforos/A-8018-2010; Yu, Kin Man/J-1399-2012; Buhlmann, Peter/A-2107-2013; Radchenko, Peter/E-2601-2015	Yu, Kin Man/0000-0003-1350-9642; 			Ahn J, 2007, BIOMETRIKA, V94, P760, DOI 10.1093/biomet/asm050; AN HZ, 2008, ADJUSTED IN IN PRESS; ANAGNOSTOPOULOS C, 2008, P 18 EUR C IN PRESS; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zou H, 2008, ANN STAT, V36, P1108, DOI 10.1214/07-AOS507; Kalisch M, 2007, J MACH LEARN RES, V8, P613; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Wang H, 2007, BIOMETRIKA, V94, P553, DOI 10.1093/biomet/asm053; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Wu YC, 2007, J AM STAT ASSOC, V102, P974, DOI 10.1198/016214507000000617; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Hall P, 2005, J ROY STAT SOC B, V67, P427, DOI 10.1111/j.1467-9868.2005.00510.x; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Westad F, 2000, J NEAR INFRARED SPEC, V8, P117; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Hans C, 2007, J AM STAT ASSOC, V102, P507, DOI 10.1198/016214507000000121; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Bauer P., 1988, STATISTICS, V19, P39, DOI 10.1080/02331888808802068; BICKEL P, 2007, ANN STAT, V35, P2313; BICKEL PJ, 2008, ANN STAT IN PRESS, V36; BOTTOLO L, 2008, EVOLUTIONARY STOCHAS; Breiman L, 1996, ANN STAT, V24, P2350; Buhlmann P, 2006, ANN STAT, V34, P559, DOI 10.1214/009053606000000092; BUHLMANN P, 2008, VARIABLE SELECTION H; Buhlmann P, 2008, ANN STAT, V36, P1534, DOI 10.1214/07-AOS0316A; BUNCA F, 2006, J STAT PLAN INFER, V136, P4349; Cook RD, 2007, STAT SCI, V22, P1, DOI 10.1214/088342306000000682; DONOHO DL, 1994, PROBAB THEORY REL, V99, P277, DOI 10.1007/BF01199026; DZIAK J, 2004, THESIS PENNSYLVANIA; FAN J, 2008, ULTRADIMENS IN PRESS; FAN J, 2008, ANN STAT IN PRESS; Fan J, 2007, P 4 INT C CHIN MATH, VII, P735; Fan JQ, 2001, ANN STAT, V29, P153, DOI 10.1214/aos/996986505; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2007, TEST, V16, P409, DOI 10.1007/s11749-007-0080-8; Fang K, 1990, SYMMETRIC MULTIVARIA; GATHER U, 2002, STATISTICS, V13, P271; Gather U, 2001, TRENDS MATH, P147; GNANADES.R, 1972, BIOMETRICS, V28, P81, DOI 10.2307/2528963; GREENSHTEIN E, 2008, APPL NONPAR IN PRESS; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HALL P, 2008, TILTING MET IN PRESS; HALL P, 2008, USING GEN C IN PRESS; HANS C, 2007, B INT SOC BAVES ANAL, V24, P8; HUANG J, 2006, STAT SIN IN PRESS; JOHNSTONE IM, 2008, ANN STAT IN PRESS; JOHNSTONE IM, 2008, APPROXIMATE NULL DIS; KAI B, 2008, 0886 PENNS STAT U ME; Leng CL, 2006, STAT SINICA, V16, P1273; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Li LX, 2007, BIOMETRIKA, V94, P603, DOI 10.1093/biomet/asm044; Li LX, 2007, BIOMETRIKA, V94, P615, DOI 10.1093/biomet/asm043; LI R, 2008, DISCUSSION SURE INDE; Liang F, 2008, J AM STAT ASSOC, V103, P410, DOI 10.1198/016214507000001337; MEINSHAUSEN N, 2008, ANN STAT IN PRESS, V36; POTSCHER BM, 1983, ANN STAT, V11, P872, DOI 10.1214/aos/1176346253; QIAO X, 2008, BIOMETRICS IN PRESS; Shao J, 1997, STAT SINICA, V7, P221; Spirtes P., 2000, CAUSATION PREDICTION; Tasoulis DK, 2006, COMPUT BIOL MED, V36, P1126, DOI 10.1016/j.compbiomed.2005.09.003; van de Geer SA, 2008, ANN STAT, V36, P614, DOI 10.1214/009053607000000929; Vapnik V., 1998, STAT LEARNING THEORY; WACHTER KW, 1980, ANN STAT, V8, P937, DOI 10.1214/aos/1176345134; Wainwright M. J., 2007, INFORM THEORETIC LIM; WANG H, 2008, SHRINKAGE TUNING PAR; Wang H., 2007, J AM STAT ASSOC, V101, P1418; Wang HS, 2007, J ROY STAT SOC B, V69, P63; Wang LF, 2007, J AM STAT ASSOC, V102, P583, DOI 10.1198/016214506000001383; Zhang C. H., 2007, 2007003 RUTG U DEP S; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520; ZHANG CH, 2007, 2007008 RUTG U DEP S; Zhang CH, 2008, ANN STAT, V36, P1553, DOI 10.1214/07-AOS0316C; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037; ZHANG Y, 2008, 0887 PENNS STAT U ME; ZHANG Y, 2006, THESIS PENNSYLVANIA; ZOU H, 2008, ANN STAT IN PRESS	84	4	4	5	17	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.	NOV	2008	70						883	911				29	Statistics & Probability	Mathematics	400EM	WOS:000262850800002		
J	Hojsgaard, S; Lauritzen, SL				Hojsgaard, Soren; Lauritzen, Steffen L.			Graphical Gaussian models with edge and vertex symmetries	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Conditional independence; Covariance selection; Invariance; Iterative partial maximization; Patterned covariance matrices; Permutation symmetry; Transformation models	INVARIANT NORMAL-MODELS; STATISTICAL-ANALYSIS; SPATIAL INTERACTION; LIKELIHOOD; SELECTION; LASSO	We introduce new types of graphical Gaussian models by placing symmetry restrictions on the concentration or correlation matrix. The models can be represented by coloured graphs, where parameters that are associated with edges or vertices of the same colour are restricted to being identical. We study the properties of such models and derive the necessary algorithms for calculating maximum likelihood estimates. We identify conditions for restrictions on the concentration and correlation matrices being equivalent. This is for example the case when symmetries are generated by permutation of variable labels. For such models a particularly simple maximization of the likelihood function is available.	[Lauritzen, Steffen L.] Univ Oxford, Dept Stat, Oxford OX1 3TG, England; [Hojsgaard, Soren] Aarhus Univ, DK-8000 Aarhus C, Denmark	Lauritzen, SL (reprint author), Univ Oxford, Dept Stat, 1 S Parks Rd, Oxford OX1 3TG, England.	steffen@stats.ox.ac.uk	Lauritzen, Steffen/L-9314-2014	Lauritzen, Steffen/0000-0001-7176-6212	Directorate for Food, Fisheries and Agro Business, Denmark; Lattec I/S; Danish Cattle Association; Danish Institute of Agricultural Sciences; Danish Natural Science Research Council	This work has been supported by a grant that was financed by the Directorate for Food, Fisheries and Agro Business, Denmark, Lattec I/S, the Danish Cattle Association, the Danish Institute of Agricultural Sciences and the Danish Natural Science Research Council. The authors have benefited from conversations with Mathias Drton, Ingram Olkin and Michael Perlman, and Chris Holmes kindly made the breast cancer data available to us.	Agresti A, 1990, CATEGORICAL DATA ANA; Anderson RL, 1942, ANN MATH STAT, V13, P1, DOI 10.1214/aoms/1177731638; ANDERSSON SA, 1983, ANN STAT, V11, P392, DOI 10.1214/aos/1176346149; ANDERSON TW, 1973, ANN STAT, V1, P135, DOI 10.1214/aos/1193342389; Anderson T.W., 1970, ESSAYS PROBABILITY S, P1; Andersson S, 1998, ANN STAT, V26, P525; ANDERSSON S, 1975, ANN STAT, V3, P132, DOI 10.1214/aos/1176343004; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Miller LD, 2005, P NATL ACAD SCI USA, V102, P13550, DOI 10.1073/pnas.0506230102; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; BARNDORFFNIELSEN O, 1982, P ROY SOC LOND A MAT, V379, P41, DOI 10.1098/rspa.1982.0004; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG JE, 1975, BIOMETRIKA, V62, P555; Bollobas B., 1998, MODERN GRAPH THEORY; BUHL SL, 1993, SCAND J STAT, V20, P263; Cox D.R., 1996, MULTIVARIATE DEPENDE; COX DR, 1993, STAT SCI, V8, P204, DOI 10.1214/ss/1177010887; Drton M, 2004, BIOMETRIKA, V91, P383, DOI 10.1093/biomet/91.2.383; DRTON M, 2003, P 20 C UNC ART INT, P130; Drton M, 2006, SCAND J STAT, V33, P247, DOI 10.1111/j.1467-9469.2006.00482.x; Edwards D., 2000, INTRO GRAPHICAL MODE; Frets G.P., 1921, GENETICA, V41, P193, DOI 10.1007/BF01844048; HOJSGAARD S, 2005, P 10 INT WRKSHP ART, P159; HOJSGAARD S, 2007, J STAT SOFTWR, V23; Horn R. A., 1985, MATRIX ANAL; Hylleberg B., 1993, THESIS AALBORG U AAL; JENSEN ST, 1991, BIOMETRIKA, V78, P867; JENSEN ST, 2004, ANN STAT, V31, P219; Kauermann G, 1996, SCAND J STAT, V23, P105; Krishnaiah P. R., 1969, MULTIVARIATE ANALYSI, V2, P55; Lauritzen S. L., 1996, GRAPHICAL MODELS; LEIPNIK RB, 1947, ANN MATH STAT, V18, P80, DOI 10.1214/aoms/1177730494; Madsen J, 2000, ANN STAT, V28, P1150, DOI 10.1214/aos/1015956711; Mardia KV, 1979, MULTIVARIATE ANAL; OLKIN I, 1969, ANN MATH STAT, V40, P1358, DOI 10.1214/aoms/1177697508; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Schur I, 1911, J REINE ANGEW MATH, V140, P1; SPEED TP, 1986, ANN STAT, V14, P138, DOI 10.1214/aos/1176349846; Spielberger C., 1983, ADV PERSONALITY ASSE, V2, P159; Spielberger C. D., 1970, MANUAL STATE TRAIT; VOTAW DF, 1948, ANN MATH STAT, V19, P447, DOI 10.1214/aoms/1177730145; Whittaker J, 1990, GRAPHICAL MODELS APP; Whittle P., 1954, BIOMETRIKA, V41, P439; WILKS SS, 1946, ANN MATH STAT, V17, P257, DOI 10.1214/aoms/1177730940; WOLFE DA, 1976, BIOMETRIKA, V63, P214, DOI 10.1093/biomet/63.1.214	46	13	13	1	4	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.	NOV	2008	70						1005	1027		10.1111/j.1467-9868.2008.00666.x		23	Statistics & Probability	Mathematics	400EM	WOS:000262850800007		
J	Cook, RD; Forzani, L				Cook, R. Dennis; Forzani, Liliana			Principal Fitted Components for Dimension Reduction in Regression	STATISTICAL SCIENCE			English	Article						Central subspace; dimension reduction; inverse regression; principal components	INVERSE REGRESSION; PREDICTION	We provide a remedy for two concerns that have dogged the use of principal components in regression: (i) principal components are computed from the predictors alone and do not make apparent use of the response, and (ii) principal components are not invariant or equivariant under full rank linear transformation of the predictors. The development begins with principal fitted components [Cook, R. D. (2007). Fisher lecture: Dimension reduction in regression (with discussion). Statist. Sci. 22 1-26] and uses normal models for the inverse regression of the predictors on the response to gain reductive information for the forward regression of interest. This approach includes methodology for testing hypotheses about the number of components and about conditional independencies among the predictors.	[Cook, R. Dennis] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA; [Forzani, Liliana] Consejo Nacl Invest Cient & Tecn, Inst Matemat Aplicada Litoral, RA-3000 Buenos Aires, Santa Fe, Argentina	Cook, RD (reprint author), Univ Minnesota, Sch Stat, 313 Ford Hall,224 Church St SE, Minneapolis, MN 55455 USA.	dennis@stat.umn.edu; liliana.forzani@gmail.com			NSF [DMS-07-04098]	The authors thank Prof. Eaton for his helpful discussions. Research for this article was supported in part by NSF Grant DMS-07-04098.	Anderson T. W., 1971, INTRO MULTIVARIATE S; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; Bura E, 2001, J ROY STAT SOC B, V63, P393, DOI 10.1111/1467-9868.00292; Bura E, 2003, BIOINFORMATICS, V19, P1252, DOI 10.1093/bioinformatics/btg150; Burnham K. P., 2002, MODEL SELECTION MULT; Chikuse Y., 2003, STAT SPECIAL MANIFOL; Cook R. D., 1994, P SECT PHYS ENG SCI, P18; COOK R. D., 1998, REGRESSION GRAPHICS; Cook RD, 2006, BIOMETRIKA, V93, P65, DOI 10.1093/biomet/93.1.65; COOK RD, 2007, BIOMETRIKA, V94, P569, DOI DOI 10.1093/BIIMET/ASM038; Cook RD, 2007, STAT SCI, V22, P1, DOI 10.1214/088342306000000682; COOK RD, 2009, J AM STAT A IN PRESS; COX DR, 1968, J R STAT SOC SER A-G, V131, P265, DOI 10.2307/2343523; Eaton M, 1983, MULTIVARIATE STAT; FEARN T, 1983, J R STAT SOC C-APPL, V32, P73; FRANKLIN NL, 1956, T I CHEM ENG-LOND, V34, P280; HELLAND IS, 1990, SCAND J STAT, V17, P97; HELLAND IS, 1994, J AM STAT ASSOC, V89, P583, DOI 10.2307/2290861; Krishnaiah P. R., 1969, MULTIVARIATE ANALYSI, V2, P55; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Li LX, 2004, BIOINFORMATICS, V20, P3406, DOI 10.1093/bioinformatics/bth415; MEINSHAUSFN N, 2006, RELAXO RELAXED LASSO; Muirhead R., 1982, ASPECTS MULTIVARIATE; ROGERS GS, 1977, COMMUN STAT A-THEOR, V6, P121, DOI 10.1080/03610927708827477	25	27	27	1	7	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0883-4237			STAT SCI	Stat. Sci.	NOV	2008	23	4					485	501		10.1214/08-STS275		17	Statistics & Probability	Mathematics	459DC	WOS:000267079300003		
J	Napoletani, D; Sauer, T; Struppa, DC; Petricoin, E; Liotta, L				Napoletani, D.; Sauer, T.; Struppa, D. C.; Petricoin, E.; Liotta, L.			Augmented sparse reconstruction of protein signaling networks	JOURNAL OF THEORETICAL BIOLOGY			English	Article						Sparse representations; Protein interaction models; Biochemical pathways	LARGE UNDERDETERMINED SYSTEMS; ENGINEERING GENE NETWORKS; BAYESIAN NETWORKS; EXPRESSION DATA; REGRESSION; DECOMPOSITION; MECHANISMS; EQUATIONS; THERAPY; MODEL	The problem of reconstructing and identifying intracellular protein signaling and biochemical networks is of critical importance in biology. We propose a mathematical approach called augmented sparse reconstruction for the identification of links among nodes of ordinary differential equation (ODE) networks, given a small set of observed trajectories with various initial conditions. As a test case, the method is applied to the epidermal growth factor receptor (EGFR) driven signaling cascade, a well-studied and clinically important signaling network. Our method builds a system of representation from a collection of trajectory integrals, selectively attenuating blocks of terms in the representation. The system of representation is then augmented with random vectors, and l(1) minimization is used to find sparse representations for the dynamical interactions of each node. After showing the performance of our method on a model of the EGFR protein network, we sketch briefly the potential future therapeutic applications of this approach. (C) 2008 Elsevier Ltd. All rights reserved.	[Napoletani, D.; Sauer, T.] George Mason Univ, Dept Math Sci, Fairfax, VA 22030 USA; [Napoletani, D.; Petricoin, E.; Liotta, L.] George Mason Univ, Ctr Appl Prote & Mol Med, Manassas, VA 20110 USA; [Struppa, D. C.] Chapman Univ, Dept Math & Comp Sci, Orange, CA 92866 USA	Napoletani, D (reprint author), George Mason Univ, Dept Math Sci, 4400 Univ Dr MS 3F2, Fairfax, VA 22030 USA.	dnapolet@gmu.edu	Sauer, Timothy/H-8272-2012	Sauer, Timothy/0000-0002-8501-8722			Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Yeung MKS, 2002, P NATL ACAD SCI USA, V99, P6163, DOI 10.1073/pnas.092576199; Lacouture ME, 2006, NAT REV CANCER, V6, P803, DOI 10.1038/nrc1970; Petricoin EF, 2007, CANCER RES, V67, P3431, DOI 10.1158/0008-5472.CAN-06-1344; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Albert R, 2005, J CELL SCI, V118, P4947, DOI 10.1242/jcs.02714; Rogers S, 2005, BIOINFORMATICS, V21, P3131, DOI 10.1093/bioinformatics/bti487; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Araujo RP, 2005, BIOSYSTEMS, V80, P57, DOI 10.1016/j.biosystems.2004.10.002; Araujo RP, 2007, NAT REV DRUG DISCOV, V6, P871, DOI 10.1038/nrd2381; Araujo RP, 2004, DRUG DISCOV TODAY TH, V1, P425, DOI 10.1016/j.ddstr.2004.11.004; CANDES E, 2005, P 46 ANN IEEE S FDN, P295; CANDES E, 2004, IEEE T INFORM THEORY, V52, P5406; Chou I.C., 2006, THEOR BIOL MED MODEL, V3; Debashis P., 2008, ANN STAT, V36, P1595; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Hastie T., 2001, ELEMENTS STAT LEARNI; HU P, 2006, NAT REV CANCER, V7, P23; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Judd K, 2004, PHYSICA D, V196, P224, DOI 10.1016/j.physd.2004.03.020; Kaufman L., 2005, FINDING GROUPS DATA; Liotta LA, 2001, JAMA-J AM MED ASSOC, V286, P2211, DOI 10.1001/jama.286.18.2211; Lustig I. J., 1994, ORSA Journal on Computing, V6; Mallat S., 1998, WAVELET TOUR SIGNAL; Nachman I, 2004, BIOINFORMATICS, V20, P248, DOI 10.1093/bioinformatics/bth941; Napoletani D, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.026103; Santos SDM, 2007, NAT CELL BIOL, V9, P324, DOI 10.1038/ncb1543; Sheehan KM, 2008, ONCOGENE, V27, P323, DOI 10.1038/sj.onc.1210647; Tegner J, 2003, P NATL ACAD SCI USA, V100, P5944, DOI 10.1073/pnas.0933416100; Voit EO, 2000, COMPUTATIONAL ANAL B; Voss HU, 2004, INT J BIFURCAT CHAOS, V14, P1905, DOI 10.1142/S0218127404010345; Wulfkuhle JD, 2008, J PROTEOME RES, V7, P1508, DOI 10.1021/pr7008127; ZAK DE, 2002, P 3 INT C SYST BIOL, P236; Zhang Y, 1998, OPTIM METHOD SOFTW, V10, P1, DOI 10.1080/10556789808805699	38	7	7	0	5	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193			J THEOR BIOL	J. Theor. Biol.	NOV 7	2008	255	1					40	52		10.1016/j.jtbi.2008.07.026		13	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	364TF	WOS:000260357500005	18706918	
J	Kramer, N; Boulesteix, AL; Tutz, G				Kraemer, Nicole; Boulesteix, Anne-Laure; Tutz, Gerhard			Penalized Partial Least Squares with applications to B-spline transformations and functional data	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						NIR spectroscopy; Additive model; Dimensionality reduction; Nonlinear regression; Conjugate gradient; Krylov spaces	SMOOTHING PARAMETER-ESTIMATION; DIMENSIONAL GENOMIC DATA; MULTIVARIATE CALIBRATION; REGRESSION; PLS; SELECTION; ALGORITHMS; PRINCIPAL; PENALTIES; CURVES	We propose a novel framework that combines penalization techniques with Partial Least Squares (PLS). We focus on two important applications. (1) We combine PLS with a roughness penalty to estimate high-imensional regression problems with functional predictors and scalar response. (2) Starting with an additive model, we expand each variable in terms of a generous number of B-spline basis functions. To prevent overfitting, we estimate the model by applying a penalized version of PLS. We gain additional model flexibility by incorporating a sparsity penalty. Both applications can be formulated in terms of a unified algorithm called Penalized Partial Least Squares, which can be computed virtually as fast as PLS using the kernel trick. Furthermore, we prove a close connection of penalized PLS to preconditioned linear systems. In experiments. we show the benefits of our method to noisy functional data and to sparse nonlinear regression models. (C) 2008 Elsevier B.V. All rights reserved.	[Kraemer, Nicole] TU Berlin, Dept Elect Engn & Comp Sci, D-10587 Berlin, Germany; [Boulesteix, Anne-Laure] Sylvia Lawry Ctr MS Res, Munich, Germany; [Boulesteix, Anne-Laure] Tech Univ Munich, Dept Med Stat & Epidemiol, Munich, Germany; [Tutz, Gerhard] Univ Munich, Dept Stat, D-80539 Munich, Germany	Kramer, N (reprint author), TU Berlin, Dept Elect Engn & Comp Sci, Franklinstr 28-29, D-10587 Berlin, Germany.	nkraemer@cs.tu-berlin.de	Boulesteix, Anne-Laure/A-3948-2010		Deutsche Forschurgsgemeirschaft [SFB 386]; European Community, under the PASCAL Network of Excellence, [IST-2002-506778]	This research was supported by the Deutsche Forschurgsgemeirschaft (SFB 386, "Statistical Analysis of Discrete Structures"), and by the IST Programme of the European Community, under the PASCAL Network of Excellence, dIST-2002-506778.	Boulesteix AL, 2007, BRIEF BIOINFORM, V8, P32, DOI 10.1093/bib/bb1016; Spiegelman CH, 1998, ANAL CHEM, V70, P35, DOI 10.1021/ac9705733; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Wood SN, 2004, J AM STAT ASSOC, V99, P673, DOI 10.1198/016214504000000980; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; Silverman BW, 1996, ANN STAT, V24, P1; RANNAR S, 1994, J CHEMOMETR, V8, P111, DOI 10.1002/cem.1180080204; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Boulesteix AL, 2008, TEST, V17, P31, DOI 10.1007/s11749-008-0103-0; Brown PJ, 2001, J AM STAT ASSOC, V96, P398, DOI 10.1198/016214501753168118; Cardot H, 2003, STAT SINICA, V13, P571; Chapelle O., 2006, SEMISUPERVISED LEARN; de Boor C., 1978, PRACTICAL GUIDE SPLI; DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X; Durand JF, 1997, J AM STAT ASSOC, V92, P1546, DOI 10.2307/2965425; Durand JF, 2001, CHEMOMETR INTELL LAB, V58, P235, DOI 10.1016/S0169-7439(01)00162-9; Goutis C, 1996, J AM STAT ASSOC, V91, P627, DOI 10.2307/2291658; Hastie TJ, 1990, GEN ADDITIVE MODELS; Ide T, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P515; Kondylis A, 2008, COMPUT STAT DATA AN, V52, P2588, DOI 10.1016/j.csda.2007.09.014; Kramer N, 2006, THESIS TU BERLIN; Kramer N., 2007, P 24 INT C MACH LEAR, P441, DOI 10.1145/1273496.1273552; KRAMER N, 2008, PPLS PENALIZED PARTI; Lanczos C, 1950, J RES NBS, V45, P225; MANNE R, 1987, CHEMOMETR INTELL LAB, V2, P187, DOI 10.1016/0169-7439(87)80096-5; Marske D., 1967, THESIS U WISCONSIN M; Martens H., 1989, MULTIVARIATE CALIBRA; Marx BD, 1999, TECHNOMETRICS, V41, P1, DOI 10.2307/1270990; MOMMA M, 2006, CONSTRUCTING ORTHOGO; Nadler B, 2005, J CHEMOMETR, V19, P107, DOI 10.1002/cem.915; OSBORNE BG, 1984, J SCI FOOD AGR, V35, P99, DOI 10.1002/jsfa.2740350116; Phatak A, 2002, J CHEMOMETR, V16, P361, DOI 10.1002/cem.728; R Development Core Team, 2008, R LANG ENV STAT COMP; Ramsay J. O., 2005, FUNCTIONAL DATA ANAL; Reiss PT, 2007, J AM STAT ASSOC, V102, P984, DOI 10.1198/016214507000000527; Rosipal R., 2003, P 20 INT C MACH LEAR, P640; Rosipal R., 2001, J MACHINE LEARNING R, V2, P97; Rosipals R, 2006, LECT NOTES COMPUTER, P34, DOI [10.1007/11752790_2, DOI 10.1007/11752790_2]; Saeys W, 2008, J CHEMOMETR, V22, P335, DOI 10.1002/cem.1129; SAIGO H, 2008, 14 INT C KN IN PRESS; WALD S, 1984, J SCI STAT COMPUTATI, V5, P735; Wold H., 1975, QUANTITATIVE SOCIOLO, P307; Wood SN, 2000, J ROY STAT SOC B, V62, P413, DOI 10.1111/1467-9868.00240	45	27	27	1	13	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	NOV 15	2008	94	1					60	69		10.1016/j.chemolab.2008.06.009		10	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	408OD	WOS:000263443400007		
J	Tutt, A; Wang, A; Rowland, C; Gillett, C; Lau, K; Chew, K; Dai, HY; Kwok, S; Ryder, K; Shu, H; Springall, R; Cane, P; McCallie, B; Kam-Morgan, L; Anderson, S; Buerger, H; Gray, J; Bennington, J; Esserman, L; Hastie, T; Broder, S; Sninsky, J; Brandt, B; Waldman, F				Tutt, Andrew; Wang, Alice; Rowland, Charles; Gillett, Cheryl; Lau, Kit; Chew, Karen; Dai, Hongyue; Kwok, Shirley; Ryder, Kenneth; Shu, Henry; Springall, Robert; Cane, Paul; McCallie, Blair; Kam-Morgan, Lauren; Anderson, Steve; Buerger, Horst; Gray, Joe; Bennington, James; Esserman, Laura; Hastie, Trevor; Broder, Samuel; Sninsky, John; Brandt, Burkhard; Waldman, Fred			Risk estimation of distant metastasis in node-negative, estrogen receptor-positive breast cancer patients using an RT-PCR based prognostic expression signature	BMC CANCER			English	Article							GENE-EXPRESSION; SURVIVAL; PROLIFERATION; TAMOXIFEN; THERAPY; MARKERS; CHEMOTHERAPY; VALIDATION; RECURRENCE; WOMEN	Background: Given the large number of genes purported to be prognostic for breast cancer, it would be optimal if the genes identified are not confounded by the continuously changing systemic therapies. The aim of this study was to discover and validate a breast cancer prognostic expression signature for distant metastasis in untreated, early stage, lymph node-negative (N-) estrogen receptor-positive (ER+) patients with extensive follow-up times. Methods: 197 genes previously associated with metastasis and ER status were profiled from 142 untreated breast cancer subjects. A "metastasis score" (MS) representing fourteen differentially expressed genes was developed and evaluated for its association with distant-metastasis-free survival (DMFS). Categorical risk classification was established from the continuous MS and further evaluated on an independent set of 279 untreated subjects. A third set of 45 subjects was tested to determine the prognostic performance of the MS in tamoxifen-treated women. Results: A 14-gene signature was found to be significantly associated (p < 0.05) with distant metastasis in a training set and subsequently in an independent validation set. In the validation set, the hazard ratios (HR) of the high risk compared to low risk groups were 4.02 (95% CI 1.91-8.44) for the endpoint of DMFS and 1.97 (95% CI 1.28 to 3.04) for overall survival after adjustment for age, tumor size and grade. The low and high MS risk groups had 10-year estimates (95% CI) of 96% (90-99%) and 72% (64-78%) respectively, for DMFS and 91% (84-95%) and 68% (61-75%), respectively for overall survival. Performance characteristics of the signature in the two sets were similar. Ki-67 labeling index (LI) was predictive for recurrent disease in the training set, but lost significance after adjustment for the expression signature. In a study of tamoxifen-treated patients, the HR for DMFS in high compared to low risk groups was 3.61 (95% CI 0.86-15.14). Conclusion: The 14-gene signature is significantly associated with risk of distant metastasis. The signature has a predominance of proliferation genes which have prognostic significance above that of Ki-67 LI and may aid in prioritizing future mechanistic studies and therapeutic interventions.	[Tutt, Andrew] Kings Coll London, Breakthrough Breast Canc Res Unit, London WC2R 2LS, England; [Tutt, Andrew; Ryder, Kenneth] Guys Hosp, London SE1 9RT, England; [Wang, Alice; Rowland, Charles; Lau, Kit; McCallie, Blair; Sninsky, John] Celera LLC, Alameda, CA USA; [Gillett, Cheryl] Guys & St Thomas Hosp, Breast Res Tissue & Data Bank, London SE1 9RT, England; [Chew, Karen; Waldman, Fred] Univ Calif San Francisco, Ctr Comprehens Canc, San Francisco, CA 94143 USA; [Dai, Hongyue] Rosetta Inpharmat, Seattle, WA USA; [Cane, Paul] St Thomas Hosp, Dept Cellular Pathol, London, England; [Kam-Morgan, Lauren; Anderson, Steve] Lab Corp Amer, Triangle Park, NC USA; [Buerger, Horst; Brandt, Burkhard] Univ Hamburg, Univ Med Ctr, Inst Tumor Biol, Hamburg, Germany; [Gray, Joe] Univ Calif Berkeley, Lawrence Berkeley Lab, Div Life Sci, Berkeley, CA 94720 USA; [Bennington, James; Waldman, Fred] Calif Pacific Med Ctr, Dept Pathol, San Francisco, CA USA; [Esserman, Laura] Univ Calif San Francisco, Carol Franc Buck Breast Canc, San Francisco, CA 94143 USA; [Hastie, Trevor] Stanford Univ, Dept Stat, Stanford, CA 94305 USA; [Hastie, Trevor] Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA	Tutt, A (reprint author), Kings Coll London, Breakthrough Breast Canc Res Unit, London WC2R 2LS, England.	andrew.tutt@icr.ac.uk; alice.wang@celera.com; Charles.Rowland@celera.com; cheryl.gillett@kcl.ac.uk; kitfunlau@hotmail.com; acanthurus@aol.com; hongyue_dai@merck.com; Shirley.Kwok@celera.com; kenneth.ryder@cancer.org.uk; henshu@aol.com; robert.springall@kcl.ac.uk; paul.cane@gstt.nhs.uk; blairrip@yahoo.com; kaml@labcorp.com; Steve.Anderson@viromed.com; burgerh@uni-muenster.de; jgray@cc.ucsf.edu; jlbenn@pacbell.net; laura.esserman@ucsfmedctr.org; hastie@stanford.edu; Samuel.Broder@celera.com; John.Sninsky@celera.com; bu.brandt@uke.uni-hamburg.de; waldman@cc.ucsf.edu		Brandt, Burkhard/0000-0003-3681-3049	UC Discovery	We recognize the outstanding support and contributions of C. Santini, C. Sigua, and J. Chan under the overall excellent guidance of S-Y. Chang who provided technical and HT Biomarker infrastructure support for the study. C. Christopherson, S. Tom and W. Kim provided valuable technical support in RNA preparation with thoughtful supervision by S. Kwok. We thank the UCSF Cancer Center Breast Oncology Program Tissue Core. We appreciate early study discussions and analysis by H. Li (University of Pennsylvania). Discussions of unpublished results with A. Sachs and Y. He at Rosetta Inpharmatics assisted markedly. We thank J. Devlin, J. Catanese and T. White for careful review of the manuscript. Most importantly, we are deeply indebted to the patients who made this study possible; breast cancer advocacy, in general, and UCSF's Breast Cancer Advocacy Core, specifically for facilitating focused translational breast cancer research. Supports for carrying out this study were provided by a UC Discovery grant and Celera. The studies described in this paper evolved as part of a collaboration through the Early Detection Research Network (EDRN), an initiative of the National Cancer Institute (NCI).	AKRITAS MG, 1994, ANN STAT, V22, P1299, DOI 10.1214/aos/1176325630; Pai SI, 2006, GENE THER, V13, P464, DOI 10.1038/sj.gt.3302694; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Foekens JA, 2006, J CLIN ONCOL, V24, P1665, DOI 10.1200/JCO.2005.03.9115; Esteva FJ, 2005, CLIN CANCER RES, V11, P3315, DOI 10.1158/1078-0432.CCR-04-1707; Chang HY, 2005, P NATL ACAD SCI USA, V102, P3738, DOI 10.1073/pnas.0409462102; Ma XJ, 2006, J CLIN ONCOL, V24, P4611, DOI 10.1200/JCO.2006.06.6944; Akinc A, 2008, NAT BIOTECHNOL, V26, P561, DOI 10.1038/nbt1402; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vincent-Salomon A, 2004, EUR J CANCER, V40, P1502, DOI 10.1016/j.ejca.2004.03.014; Desmedt C, 2007, CLIN CANCER RES, V13, P3207, DOI 10.1158/1078-0432.CCR-06-2765; Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1; Paik S, 2006, J CLIN ONCOL, V24, P3726, DOI 10.1200/JCO.2005.04.7985; Livak KJ, 2001, METHODS, V25, P402, DOI 10.1006/meth.2001.1262; Colozza M, 2005, ANN ONCOL, V16, P1723, DOI 10.1093/annonc/mdi352; Devi GR, 2006, CANCER GENE THER, V13, P819, DOI 10.1038/sj.cgt.7700931; Buyse M, 2006, J NATL CANCER I, V98, P1183, DOI 10.1093/jnci/djj329; Whitfield ML, 2006, NAT REV CANCER, V6, P99, DOI 10.1038/nrc1802; Paik S, 2004, NEW ENGL J MED, V351, P2817, DOI 10.1056/NEJMoa041588; Rogge L, 2000, NAT GENET, V25, P96, DOI 10.1038/75671; Jansen MPHM, 2007, J CLIN ONCOL, V25, P662, DOI 10.1200/JCO.2006.07.3676; Potemski P, 2006, PATHOL RES PRACT, V202, P491, DOI 10.1016/j.prp.2006.02.005; Miller LD, 2005, P NATL ACAD SCI USA, V102, P13550, DOI 10.1073/pnas.0506230102; Carey LA, 2006, JAMA-J AM MED ASSOC, V295, P2492, DOI 10.1001/jama.295.21.2492; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; de Azambuja E, 2007, BRIT J CANCER, V96, P1504, DOI 10.1038/sj.bjc.6603756; Heagerty PJ, 2000, BIOMETRICS, V56, P337, DOI 10.1111/j.0006-341X.2000.00337.x; Flanagan MB, 2008, MODERN PATHOL, V21, P1255, DOI 10.1038/modpathol.2008.54; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; Burcombe R, 2006, BREAST CANCER RES, V8, DOI 10.1186/bcr1508; Collett D., 1994, MODELING SURVIVAL DA; COX DR, 1972, J R STAT SOC B, V34, P187; Dai HY, 2005, CANCER RES, V65, P4059, DOI 10.1158/0008-5472.CAN-04-3953; Dowsett M, 2007, J NATL CANCER I, V99, P167, DOI 10.1093/jnci/djk020; Eden P, 2004, EUR J CANCER, V40, P1837, DOI 10.1016/j.ejca.2004.02.025; Efron B, 1993, INTRO BOOTSTRAP; ELSTON CW, 1991, HISTOPATHOLOGY, V19, P403, DOI 10.1111/j.1365-2559.1991.tb00229.x; Fan C, 2006, NEW ENGL J MED, V355, P560, DOI 10.1056/NEJMoa052933; Goetz MP, 2006, CLIN CANCER RES, V12, P2080, DOI 10.1158/1078-0432.CCR-05-1263; Harrell FE, 2001, REGRESSION MODELING; HASTIE TJ, 2005, SOFTWARE ONLINE; Hayes DF, 2005, BREAST, V14, P493, DOI 10.1016/j.breast.2005.08.023; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; Miller WR, 2003, EUR J CANCER, V39, P462, DOI 10.1016/S0959-8049(02)00600-7; *R DEV COR TEAM R, 2007, R LANG ENV STAT COMP; *SAS I INC, 2001, SAS SOFTW VERS 9 1; Tan PH, 2005, MODERN PATHOL, V18, P374, DOI 10.1038/modpathol.3800254; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; RILKE F, 1982, TUMORI, V68, P181	51	23	24	0	0	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2407			BMC CANCER	BMC Cancer	NOV 21	2008	8								339	10.1186/1471-2407-8-339		15	Oncology	Oncology	397ZE	WOS:000262700100001	19025599	
J	Mulliken, GH; Musallam, S; Andersen, RA				Mulliken, Grant H.; Musallam, Sam; Andersen, Richard A.			Decoding Trajectories from Posterior Parietal Cortex Ensembles	JOURNAL OF NEUROSCIENCE			English	Article						brain-machine interface; trajectory decoding; neural prosthetics; sensorimotor control; posterior parietal cortex; neurophysiology	BRAIN-COMPUTER INTERFACE; GOAL-DIRECTED MOVEMENTS; CONTROL SIGNALS; CORTICAL-NEURONS; MOTOR CONTROL; MODELS; TRANSFORMATIONS; RECORDINGS; PREDICTION; REGRESSION	High-level cognitive signals in the posterior parietal cortex (PPC) have previously been used to decode the intended endpoint of a reach, providing the first evidence that PPC can be used for direct control of a neural prosthesis (Musallam et al., 2004). Here we expand on this work by showing that PPC neural activity can be harnessed to estimate not only the endpoint but also to continuously control the trajectory of an end effector. Specifically, we trained two monkeys to use a joystick to guide a cursor on a computer screen to peripheral target locations while maintaining central ocular fixation. We found that we could accurately reconstruct the trajectory of the cursor using a relatively small ensemble of simultaneously recorded PPC neurons. Using a goal-based Kalman filter that incorporates target information into the state-space, we showed that the decoded estimate of cursor position could be significantly improved. Finally, we tested whether we could decode trajectories during closed-loop brain control sessions, in which the real-time position of the cursor was determined solely by a monkey's neural activity in PPC. The monkey learned to perform brain control trajectories at 80% success rate (for 8 targets) after just 4-5 sessions. This improvement in behavioral performance was accompanied by a corresponding enhancement in neural tuning properties (i.e., increased tuning depth and coverage of encoding parameter space) as well as an increase in off-line decoding performance of the PPC ensemble.	[Musallam, Sam; Andersen, Richard A.] CALTECH, Div Biol, Pasadena, CA 91125 USA	Mulliken, GH (reprint author), MIT, McGovern Inst Brain Res, Bldg 46,Room 6165,77 Massachusetts Ave, Cambridge, MA 02139 USA.	grantm@mit.edu	Musallam, Sam/E-8064-2011		National Eye Institute; James G. Boswell Foundation; Defense Advanced Research Projects Agency; National Institutes of Health	This work was supported by the National Eye Institute, the James G. Boswell Foundation, the Defense Advanced Research Projects Agency, and a National Institutes of Health training grant fellowship to G. H. M. We thank J. Burdick, E. Hwang, and M. Hauschild for comments on this manuscript, K. Pejsa and N. Sammons for animal care, and V. Shcherbatyuk and T. Yao for technical and administrative assistance.	Andersen RA, 2002, ANNU REV NEUROSCI, V25, P189, DOI 10.1146/annurev.neuro.25.112701.142922; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; Musallam S, 2004, SCIENCE, V305, P258, DOI 10.1126/science.1097938; Suner S, 2005, IEEE T NEUR SYS REH, V13, P524, DOI 10.1109/TNSRE.2005.857687; WOLPERT DM, 1995, SCIENCE, V269, P1880, DOI 10.1126/science.7569931; Snyder LH, 1997, NATURE, V386, P167, DOI 10.1038/386167a0; Serruya MD, 2002, NATURE, V416, P141, DOI 10.1038/416141a; Paninski L, 2004, J NEUROPHYSIOL, V91, P515, DOI 10.1152/jn.00587.2002; Hochberg LR, 2006, NATURE, V442, P164, DOI 10.1038/nature04970; Wolpaw JR, 2004, P NATL ACAD SCI USA, V101, P17849, DOI 10.1073/pnas.0403504101; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Averbeck BB, 2005, J NEUROPHYSIOL, V93, P508, DOI 10.1152/jn.00357.2004; Wessberg J, 2000, NATURE, V408, P361; Mulliken GH, 2008, P NATL ACAD SCI USA, V105, P8170, DOI 10.1073/pnas.0802602105; Efron B, 2004, ANN STAT, V32, P407; Ringach DL, 1997, NATURE, V387, P281, DOI 10.1038/387281a0; FLANDERS M, 1989, J NEUROSCI, V9, P447; ASHE J, 1994, CEREB CORTEX, V4, P590, DOI 10.1093/cercor/4.6.590; Batista AP, 1999, SCIENCE, V285, P257, DOI 10.1126/science.285.5425.257; BRANCHAUD EA, 2006, IEEE RAS EMBS INT C; Buneo CA, 2002, NATURE, V416, P632, DOI 10.1038/416632a; Carmena Jose M, 2003, PLoS Biol, V1, pE42; Cham JG, 2005, J NEUROPHYSIOL, V93, P570, DOI 10.1152/jn.00369.2004; Gail A, 2006, J NEUROSCI, V26, P9376, DOI 10.1523/JNEUROSCI.1570-06.2006; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1; Kalman R. E., 1960, T ASME D, V82, P35, DOI DOI 10.1115/1.3662552; Kennedy PR, 2000, IEEE T REHABIL ENG, V8, P198, DOI 10.1109/86.847815; Nenadic Z, 2005, IEEE T BIO-MED ENG, V52, P74, DOI 10.1109/TBME.2004.839800; Patil P. G., 2004, NEUROSURGERY, V55, P35; Patil PG, 2004, NEUROSURGERY, V55, P27, DOI 10.1227/01.NEU.0000126872.23715.E5; Petersen N, 1998, J PHYSIOL-LONDON, V512, P267, DOI 10.1111/j.1469-7793.1998.267bf.x; Pistohl T, 2008, J NEUROSCI METH, V167, P105, DOI 10.1016/j.jneumeth.2007.10.001; Quiroga RQ, 2006, J NEUROSCI, V26, P3615, DOI 10.1523/JNEUROSCI.3468-05.2006; Santhanam G, 2006, NATURE, V442, P195, DOI 10.1038/nature04968; Scherberger H, 2005, NEURON, V46, P347, DOI 10.1016/j.neuron.2005.03.004; Shenoy KV, 2003, NEUROREPORT, V14, P591, DOI 10.1097/01.wnr.0000063250.41814.39; Srinivasan L, 2006, NEURAL COMPUT, V18, P2465, DOI 10.1162/neco.2006.18.10.2465; Welch G, 2006, 95041 U N CAR; Wu W., 2003, ADV NEURAL INFORMATI, V15, P133; Yu BM, 2007, J NEUROPHYSIOL, V97, P3763, DOI 10.1152/jn.00482.2006	45	101	101	1	6	SOC NEUROSCIENCE	WASHINGTON	11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA	0270-6474			J NEUROSCI	J. Neurosci.	NOV 26	2008	28	48					12913	12926		10.1523/JNEUROSCI.1463-08.2008		14	Neurosciences	Neurosciences & Neurology	376OA	WOS:000261191700033	19036985	
J	Cannamela, C; Garnier, J; Iooss, B				Cannamela, Claire; Garnier, Josselin; Iooss, Bertrand			CONTROLLED STRATIFICATION FOR QUANTILE ESTIMATION	ANNALS OF APPLIED STATISTICS			English	Article						Quantile estimation; Monte Carlo methods; variance reduction; computer experiments	OUTPUTS	In this paper we propose and discuss variance reduction techniques for the estimation of quantiles of the output of a complex model with random input parameters. These techniques are based on the use of a reduced model, such as a metamodel or a response surface. The reduced model can be used as a control variate; or a rejection method can be implemented to sample the realizations of the input parameters in prescribed relevant strata; or the reduced model can be used to determine a good biased distribution of the input parameters for the implementation of an importance sampling strategy. The different strategies are analyzed and the asymptotic variances are computed, which shows the benefit of an adaptive controlled stratification method. This method is finally applied to a real example (computation of the peak cladding temperature during a large-break loss of coolant accident in a nuclear reactor).	[Cannamela, Claire] DEN DEC SESC LSC, CEA Cadarache, F-13108 St Paul Les Durance, France; [Cannamela, Claire] SUPELEC, Dept Signaux & Syst Elect, F-91192 Gif Sur Yvette, France; [Garnier, Josselin] Univ Paris 07, Lab Probabil & Modeles Aleatoires, F-75251 Paris 05, France; [Garnier, Josselin] Univ Paris 07, Lab Jacques Louis Lions, F-75251 Paris 05, France; [Iooss, Bertrand] DEN DER SESI LCFR, CEA Cadarache, F-13108 St Paul Les Durance, France	Cannamela, C (reprint author), DEN DEC SESC LSC, CEA Cadarache, F-13108 St Paul Les Durance, France.	claire.cannamela@supelec.fr; garnier@math.jussieu.fr; bertrand.iooss@cea.fr					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; HESTERBERG T, 1995, TECHNOMETRICS, V37, P185, DOI 10.2307/1269620; Volkova E, 2008, STOCH ENV RES RISK A, V22, P17, DOI 10.1007/s00477-006-0093-y; Jones DR, 1998, J GLOBAL OPTIM, V13, P455, DOI 10.1023/A:1008306431147; Avramidis AN, 1998, OPER RES, V46, P574, DOI 10.1287/opre.46.4.574; David H. A., 1981, ORDER STAT; DAVIDSON R, 1992, J ECONOMETRICS, V54, P203, DOI 10.1016/0304-4076(92)90106-2; DIELMAN T, 1994, COMMUN STAT SIMULAT, V23, P355, DOI 10.1080/03610919408813175; Fang KT, 2006, CH CRC COMP SCI DATA, P3; Fishman GS, 1996, MONTE CARLO CONCEPTS; GLASSERMAN P, 1998, P 1999 WINT SIM C, P351; Glynn P. W., 1996, MATH METHODS STOCHAS, P180; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODELS; Hesterberg TC, 1998, MANAGE SCI, V44, P1295, DOI 10.1287/mnsc.44.9.1295; HESTERBERG TC, 1993, P STAT COMPUTING SEC, P40; HSU JC, 1987, P 1987 WINT SIM C, P434, DOI 10.1145/318371.318631; Law A. M., 1991, SIMULATION MODELING; LIN DKJ, 1993, TECHNOMETRICS, V35, P28, DOI 10.2307/1269286; Marrel A, 2008, COMPUT STAT DATA AN, V52, P4731, DOI 10.1016/j.csda.2008.03.026; NELSON BL, 1990, OPER RES, V38, P974, DOI 10.1287/opre.38.6.974; Nutt WT, 2004, RELIAB ENG SYST SAFE, V83, P57, DOI [10.1016/j.ress2003.08.008, 10.1016/j.ress.2003.08.608]; Oakley J, 2004, J ROY STAT SOC C-APP, V53, P83, DOI 10.1046/j.0035-9254.2003.05044.x; Oh M.-S., 1992, J STAT COMPUT SIM, V41, P143, DOI 10.1080/00949659208810398; Petruzzi A, 2004, P INT M BEST EST MET, V1, P225; RANJAN P, 2008, TECHNOMETRI IN PRESS; Rao C. R., 1973, LINEAR STAT INFERENC; Rubinstein RY, 1981, SIMULATION MONTE CAR; Rutherford B, 2006, RELIAB ENG SYST SAFE, V91, P1322, DOI 10.1016/j.ress.2005.11.050; Sacks J., 1989, STAT SCI, V4, P409, DOI DOI 10.1214/SS/1177012413; SCHONLAU M, 2005, SCREENING METHODS EX, P308; VAZQUEZ E, 2008, J STAT PLAN IN PRESS	32	8	8	1	3	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	DEC	2008	2	4					1554	1580		10.1214/08-AOAS186		27	Statistics & Probability	Mathematics	398KN	WOS:000262731100020		
J	Schwender, H; Ickstadt, K; Rahnenfuhrer, J				Schwender, Holger; Ickstadt, Katja; Rahnenfuehrer, Joerg			Classification with High-Dimensional Genetic Data: Assigning Patients and Genetic Features to Known Classes	BIOMETRICAL JOURNAL			English	Review						Bioinformatics; Discrimination; Gene expression; Genetics; Microarray; SNP; Supervised learning	SUPPORT VECTOR MACHINES; PENALIZED LOGISTIC-REGRESSION; EXPRESSION DATA; MICROARRAY DATA; LOGIC REGRESSION; DISCRIMINANT-ANALYSIS; TUMOR CLASSIFICATION; SELECTION BIAS; RANDOM FORESTS; GENOMIC DATA	A major task in the statistical analysis of genetic data such as gene expressions and single nucleotide polymorphisms (SNPs) is to predict whether a patient has a certain disease, or from which of several known subtypes of a disease it patient suffers. A large number of discrimination methods have been proposed in the literature and have been applied to genetic data to tackle this task. In this paper, we give an overview on the most popular of these procedures in the analysis of genetic data. Moreover, we describe how these methods for supervised classification can be combined with variable selection approaches to reduce the number of genetic features from several thousands to as few as possible to form a concise classification rule. Finally, we show how the resulting statistical models can be validated.	[Schwender, Holger; Ickstadt, Katja; Rahnenfuehrer, Joerg] Tech Univ Dortmund, Fak Stat, D-44227 Dortmund, Germany	Rahnenfuhrer, J (reprint author), Tech Univ Dortmund, Fak Stat, Vogelpothsweg 87, D-44227 Dortmund, Germany.	rahnenfuehrer@statistik.tu-dortmund.de			Deutsche Forschungsgemeinschaft [SFB 475]	Katja Ickstadt and Holger Schwender gratefully acknowledge the financial support of the Deutsche Forschungsgemeinschaft (SFB 475, "Reduction of Complexity in Multivariate Data Structures"),	Tan Aik Choon, 2003, Appl Bioinformatics, V2, pS75; Alvarez S, 2005, CLIN CANCER RES, V11, P1146; Boulesteix AL, 2007, BRIEF BIOINFORM, V8, P32, DOI 10.1093/bib/bb1016; Buhlmann P, 2007, STAT SCI, V22, P477, DOI 10.1214/07-STS242; Park MY, 2008, BIOSTATISTICS, V9, P30, DOI 10.1093/biostatistics/kxm010; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Dudoit S, 2003, STAT SCI, V18, P71, DOI 10.1214/ss/1056397487; Breiman L, 1998, ANN STAT, V26, P801; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Dudoit S, 2003, BIOINFORMATICS, V19, P1090, DOI 10.1093/bioinformatics/btg038; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Simon R, 2003, J NATL CANCER I, V95, P14; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Ruczinski I, 2003, J COMPUT GRAPH STAT, V12, P475, DOI 10.1198/1061860032238; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Bo T, 2002, GENOME BIOL, V3; Boulesteix A.-L., 2004, STAT APPL GENET MOL, V3, P33, DOI DOI 10.2202/1544-6115.1075; Boulesteix AL, 2008, BIOINFORMATICS, V24, P1698, DOI 10.1093/bioinformatics/btn262; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Buhlmann P, 2002, ANN STAT, V30, P927; Bureau A, 2005, GENET EPIDEMIOL, V28, P171, DOI 10.1002/gepi.20041; Cho JH, 2004, FEBS LETT, V571, P93, DOI 10.1016/j.febslet.2004.05.087; Culverhouse R, 2002, AM J HUM GENET, V70, P461, DOI 10.1086/338759; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004; Dudoit S, 2008, SPRINGER SER STAT, P1; Eilers P. H. C., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4266, DOI 10.1117/12.427987; Fix E., 1951, DISCRIMINATORY ANAL; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; Gunther EC, 2003, P NATL ACAD SCI USA, V100, P9608, DOI 10.1073/pnas.1632587100; GUYON I, 2006, FEATURE EXTRA CTION; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Jaeger J, 2003, PAC S BIOC, V8, P53; Jaeger J, 2005, STAT APPL GENET MO B, V4; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kooperberg C, 2001, GENET EPIDEMIOL, V21, P626; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; LEISCH F, 1999, 51 VIENN U EC BUS AD; Liu ZQ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1248; LOTTAZ C, 2007, BIOINFORMATICS GENOM, V2, P1023; Lunetta KL, 2004, BMC GENET, V5, DOI 10.1186/1471-2156-5-32; Man Michael Z, 2004, J Biopharm Stat, V14, P1065, DOI 10.1081/BIP-200035491; Markowetz F, 2005, METHOD INFORM MED, V44, P438; Nunkesser R, 2007, BIOINFORMATICS, V23, P3280, DOI 10.1093/bioinformatics/btm522; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; R Development Core Team, 2008, R LANG ENV STAT COMP; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753706; Roth V, 2004, IEEE T NEURAL NETWOR, V15, P16, DOI 10.1109/TNN.2003.809398; Ruczinski I, 2004, J MULTIVARIATE ANAL, V90, P178, DOI 10.1016/j.jmva.2004.02.010; Ruschhaupt M., 2004, STAT APPL GENET MOL, V3; Schoelkopf B., 2001, LEARNING KERNELS; Schwarz Daniel F, 2007, BMC Proc, V1 Suppl 1, pS59; Schwender H, 2008, BIOSTATISTICS, V9, P187, DOI 10.1093/biostatistics/kxm024; Schwender H, 2004, TOXICOL LETT, V151, P291, DOI 10.1016/j.toxlet.2004.02.021; SCHWENDER H, 2006, CHANCE, V19, P3; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25; Theilhaber J, 2002, GENOME RES, V12, P165, DOI 10.1101/gr.182601; Vapnik V., 2000, NATURE STAT LEARNING; Witte JS, 2001, GENET EPIDEMIOL, V21, P600; Yao ZZ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S11; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046; Ziegler A, 2008, BIOMETRICAL J, V50, P8, DOI 10.1002/bimj.200710398	77	12	13	1	7	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0323-3847	1521-4036		BIOMETRICAL J	Biom. J.	DEC	2008	50	6					911	926		10.1002/bimj.200810475		16	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	386ES	WOS:000261865700002	19067340	
J	Liu, ZQ; Tan, M				Liu, Zhenqiu; Tan, Ming			ROC-Based Utility Function Maximization for Feature Selection and Classification with Applications to High-Dimensional Protease Data	BIOMETRICS			English	Article						Classification; LASSO; ROC; Sensitivity; Specificity; Utility maximization	SUBSTRATE-SPECIFICITY; CURVES; VIRUS; LASSO	In medical diagnosis, the diseased and nondiseased classes are usually unbalanced and one class may be more important than the other depending on the diagnosis purpose. Most standard classification methods, however, are designed to maximize the overall accuracy and cannot incorporate different costs to different classes explicitly. In this article, we propose a novel nonparametric method to directly maximize the weighted specificity and sensitivity of the receiver operating characteristic curve. Combining advances in machine learning, optimization theory, and statistics, the proposed method has excellent generalization property and assigns different error costs to different classes explicitly. We present experiments that compare the proposed algorithms with support vector machines and regularized logistic regression using data from a study on HIV-1 protease as well as six public available datasets. Our main conclusion is that the performance of proposed algorithm is significantly better in most cases than the other classifiers tested. Software package in MATLAB is available upon request.	[Liu, Zhenqiu; Tan, Ming] Univ Maryland, Greenebaum Canc Ctr, Div Biostat, Baltimore, MD 21201 USA	Liu, ZQ (reprint author), Univ Maryland, Greenebaum Canc Ctr, Div Biostat, 22 S Greene St, Baltimore, MD 21201 USA.	zliu@umm.edu			National Institute of Health [1R03CA128102-01]	We thank the editor, associate editor, and referees for their constructive comments and references. This research was partially supported by grant 1R03CA128102-01 from the National Institute of Health.	YOUDEN WJ, 1950, CANCER, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Beck ZQ, 2000, VIROLOGY, V274, P391, DOI 10.1006/viro.2000.0420; Beck ZQ, 2001, J VIROL, V75, P9458, DOI 10.1128/JVI.75.19.9458-9469.2001; Breiman L., 1984, CLASSIFICATION REGRE; BROYDEN CG, 1967, MATH COMPUT, V21, P368, DOI 10.2307/2003239; CORTES C, 2003, ADV NEURAL INFORM PR, V15; Hastie T., 2001, ELEMENTS STAT LEARNI; Lasko TA, 2005, J BIOMED INFORM, V38, P404, DOI 10.1016/j.jbi.2005.02.008; Le CT, 2006, STAT METHODS MED RES, V15, P571, DOI 10.1177/0962280206070637; Ma SG, 2005, BIOINFORMATICS, V21, P4356, DOI 10.1093/bioinformatics/bti724; MCDIARMID C, 1989, LOND MATH S, V141, P148; PEPE MS, 2006, BIOSTATISTICS, V8, P474, DOI 10.1093/biostatistics/kxl038; Pepe MS, 2005, STAT MED, V24, P3687, DOI 10.1002/sim.2431; Rakotomamonjy A., 2004, P EUR C ART INT WORK; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Tozser J, 2000, EUR J BIOCHEM, V267, P6287, DOI 10.1046/j.1432-1327.2000.01714.x; Vapnik V.N., 1995, NATURE STAT LEARNING; Zhang H, 1999, RECURSIVE PARTITIONI; Zhang HP, 2001, P NATL ACAD SCI USA, V98, P6730, DOI 10.1073/pnas.111153698; Zhou XH, 2005, BIOMETRICS, V61, P600, DOI 10.1111/j.1541-0420.2005.00324.x	23	5	5	1	2	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0006-341X			BIOMETRICS	Biometrics	DEC	2008	64	4					1155	1161		10.1111/j.1541-0420.2008.01015.x		7	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	374OV	WOS:000261054500017	18363775	
J	Leng, CL				Leng, Chenlei			Sparse optimal scoring for multiclass cancer diagnosis and biomarker detection using microarray data	COMPUTATIONAL BIOLOGY AND CHEMISTRY			English	Article						Microarray data analysis; Biomarker detection; Multiclass classification	GENE-EXPRESSION DATA; SUPPORT VECTOR MACHINES; CLASSIFICATION; PREDICTION; SELECTION; REGRESSION; SIGNATURES; TUMORS	Gene expression data sets hold the promise to provide cancer diagnosis on the molecular level. However, using all the gene profiles for diagnosis may be suboptimal. Detection of the molecular signatures not only reduces the number of genes needed for discrimination purposes, but may elucidate the roles they play in the biological processes. Therefore, a central part of diagnosis is to detect a small set of tumor biomarkers which can be used for accurate multiclass cancer classification. This task calls for effective multiclass classifiers with built-in biomarker selection mechanism. We propose the sparse optimal scoring (SOS) method for multiclass cancer characterization. SOS is a simple prototype classifier based on linear discriminant analysis, in which predictive biomarkers can be automatically determined together with accurate classification. Thus, SOS differentiates itself from many other commonly used classifiers, where gene preselection must be applied before classification. We obtain satisfactory performance while applying SOS to several public data sets. (C) 2007 Elsevier Ltd. All rights reserved.	Natl Univ Singapore, Dept Stat & Appl Probabil, Singapore 117546, Singapore	Leng, CL (reprint author), Natl Univ Singapore, Dept Stat & Appl Probabil, Singapore 117546, Singapore.	stalc@nus.edu.sg			NUS [R-155-050-053-133]	Leng's research is partially supported by NUS research grant R-155-050-053-133. The author is grateful to Hui Yu for helpful discussions.	Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Nguyen DV, 2002, BIOINFORMATICS, V18, P1216, DOI 10.1093/bioinformatics/18.9.1216; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Davis CA, 2006, BIOINFORMATICS, V22, P2356, DOI 10.1093/bioinformatics/btl400; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Ghosh D, 2003, BIOMETRICS, V59, P992, DOI 10.1111/j.0006-341X.2003.00114.x; GHOSH D, 2005, J BIOMEDICAL BIOTECH, V2, P147, DOI DOI 10.1155/JBB.2005.147; Koo JY, 2006, BIOINFORMATICS, V22, P950, DOI 10.1093/bioinformatics/btl029; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Liu FQ, 2005, CHINESE J INORG CHEM, V21, P1697; Mardia KV, 1979, MULTIVARIATE ANAL; MUNAGALA K, 2004, BMC BIOINFORMATICS, V5, DOI DOI 10.1186/1471-2105-5-21; SCHWARTZ F, 1994, HUM GENET, V94, P658; Tibshirani R, 2007, J MACH LEARN RES, V8, P637	25	10	10	2	7	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1476-9271			COMPUT BIOL CHEM	Comput. Biol. Chem.	DEC	2008	32	6					417	425		10.1016/j.compbiolchem.2008.07.015		9	Biology; Computer Science, Interdisciplinary Applications	Life Sciences & Biomedicine - Other Topics; Computer Science	377NI	WOS:000261257500005	18722815	
J	Zhou, SM; Gan, JQ				Zhou, Shang-Ming; Gan, John Q.			Low-level interpretability and high-level interpretability: a unified view of data-driven interpretable fuzzy system modelling	FUZZY SETS AND SYSTEMS			English	Review						Data-driven fuzzy systems; Interpretable; Fuzzy models; Interpretability; Transparency; Criteria; Parsimony; Distinguishability; Low-level interpretability; High-level interpretability	ORTHOGONAL LEAST-SQUARES; RULE-BASED SYSTEMS; BASIS FUNCTION NETWORKS; INFERENCE SYSTEMS; DECISION TREES; CLASSIFICATION RULES; DISTINGUISHABILITY QUANTIFICATION; CLUSTERING ALGORITHMS; COMPLEXITY REDUCTION; INFORMATION CRITERIA	This paper aims at providing an in-depth overview of designing interpretable fuzzy inference models from data within a unified framework. The objective of complex system modelling is to develop reliable and understandable models for human being to get insights into complex real-world systems whose first-principle models are unknown. Because system behaviour can be described naturally as a series of linguistic rules, data-driven fuzzy modelling becomes an attractive and widely used paradigm for this purpose. However, fuzzy models constructed from data by adaptive learning algorithms usually suffer from the loss of model interpretability. Model accuracy and interpretability are two conflicting objectives, so interpretation preservation during adaptation in data-driven fuzzy system modelling is a challenging task, which has received much attention in fuzzy system modelling community. In order to clearly discriminate the different roles of fuzzy sets, input variables, and other components in achieving an interpretable fuzzy model, a taxonomy of fuzzy model interpretability is first proposed in terms of low-level interpretability and high-level interpretability in this paper. The low-level interpretability of fuzzy models refers to fuzzy model interpretability achieved by optimizing the membership functions in terms of semantic criteria on fuzzy set level, while the high-level interpretability refers to fuzzy model interpretability obtained by dealing with the coverage, completeness, and consistency of the rules in terms of the criteria on fuzzy rule level. Some criteria for low-level interpretability and high-level interpretability are identified, respectively. Different data-driven fuzzy modelling techniques in the literature focusing on the interpretability issues are reviewed and discussed from the perspective of low-level interpretability and high-level interpretability. Furthermore, some open problems about interpretable fuzzy models are identified and some potential new research directions on fuzzy model interpretability are also suggested. Crown Copyright (C) 2008 Published by Elsevier B.V. All rights reserved.	[Zhou, Shang-Ming] De Montfort Univ, Sch Comp, Ctr Computat Intelligence, Leicester LE1 9BH, Leics, England; [Gan, John Q.] Univ Essex, Dept Comp & Elect Syst, Colchester CO4 3SQ, Essex, England	Zhou, SM (reprint author), De Montfort Univ, Sch Comp, Ctr Computat Intelligence, Leicester LE1 9BH, Leics, England.	smzhou@ieee.org	Zhou, Shang-Ming/A-8443-2008				Abonyi J, 2000, INT J SYST SCI, V31, P657, DOI 10.1080/002077200290966; Alcala R, 2007, INT J UNCERTAIN FUZZ, V15, P539, DOI 10.1142/S0218488507004868; Alcala R, 2007, INT J APPROX REASON, V44, P45, DOI 10.1016/j.ijar.2006.02.007; Alcala R, 2006, SOFT COMPUT, V10, P717, DOI 10.1007/s00500-005-0002-1; Alcala R, 2001, J INTELL FUZZY SYST, V11, P99; AMARAL TG, 2006, P IEEE INT C FUZZ SY, P8502; ANDERSON HC, 1998, THESIS U QUEENSLAND; BEZDEK JC, 1985, IEEE T SYST MAN CYB, V15, P637; Pena-Reyes CA, 1999, ARTIF INTELL MED, V17, P131, DOI 10.1016/S0933-3657(99)00019-6; Roubos JA, 2003, INFORM SCIENCES, V150, P77, DOI 10.1016/S0020-0255(02)00369-9; Mendel JM, 2006, IEEE T FUZZY SYST, V14, P808, DOI 10.1109/TFUZZ.2006.879986; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; MAMDANI EH, 1974, P I ELECTR ENG, V121, P1585; Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; MAMDANI EH, 1977, IEEE T COMPUT, V26, P1182; DUBOIS D, 1978, INT J SYST SCI, V9, P613, DOI 10.1080/00207727808941724; Pedrycz W, 1998, IEEE T FUZZY SYST, V6, P411, DOI 10.1109/91.705509; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Pedrycz W, 1996, IEEE T SYST MAN CY B, V26, P627, DOI 10.1109/3477.517038; Mikut R, 2005, FUZZY SET SYST, V150, P179, DOI 10.1016/j.fss.2004.06.006; DELUCA A, 1972, INFORM CONTROL, V20, P301, DOI 10.1016/S0019-9958(72)90199-4; AKAIKE H, 1969, ANN I STAT MATH, V21, P243, DOI 10.1007/BF02532251; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; Zhou SM, 2007, IEEE T FUZZY SYST, V15, P398, DOI 10.1109/TFUZZ.2006.882464; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; YAGER RR, 1994, IEEE T SYST MAN CYB, V24, P1279, DOI 10.1109/21.299710; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI DOI 10.2307/1990404; BABUSKA R, 2000, P ESIT 2000 AACH GER, P445; Babuska R., 1998, FUZZY MODELLING CONT; Back T., 1994, Parallel Problem Solving from Nature - PPSN III. International Conference on Evolutionary Computation. The Third Conference on Parallel Problem Solving from Nature. Proceedings; Berthold M. R., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00004-9; BEZDEK JC, 1995, NEURAL NETWORKS, V8, P729, DOI 10.1016/0893-6080(95)00024-T; Bezdek J.C., 1981, PATTERN RECOGNITION; BHANSALI RJ, 1977, BIOMETRIKA, V64, P547, DOI 10.1093/biomet/64.3.547; Bikdash M, 1999, IEEE T FUZZY SYST, V7, P686, DOI 10.1109/91.811237; BODENHOFER U, 2000, P 6 INT C SOFT COMP, P334; BODENHOFER U, 2003, INTERPRETABILITY ISS, V128; Bossley K.M., 1997, THESIS U SOUTHAMPTON; Brown M., 1994, NEUROFUZZY ADAPTIVE; Camastra F, 2005, IEEE T PATTERN ANAL, V27, P801, DOI 10.1109/TPAMI.2005.88; Casillas J., 2003, ACCURACY IMPROVEMENT; Casillas J, 2005, IEEE T FUZZY SYST, V13, P13, DOI 10.1109/TFUZZ.2004.839670; Casillas J., 2003, INTERPRETABILITY ISS; Castellano G., 2002, Archives of Control Sciences, V12(48); CASTELLANO G, 2002, COGNITIVE SYSTEMS RE, V3, P125, DOI DOI 10.1016/S1389-0417(01)00055-9; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Chen S.S., 1995, THESIS STANFORD U; Chen YX, 2003, IEEE T FUZZY SYST, V11, P716, DOI 10.1109/TFUZZ.2003.819843; Cherkassky V. S., 1998, LEARNING DATA CONCEP; CHIU S, 1994, P NAFIPS C SAN ANT T, P436; Chiu S., 1994, J INTELL FUZZY SYST, V2, P267; Cococcioni M, 2007, SOFT COMPUT, V11, P1013, DOI 10.1007/s00500-007-0150-6; Cordon O, 2003, IEEE T FUZZY SYST, V11, P866, DOI 10.1109/TFUZZ.2003.819820; Dempster A, 1977, J ROYAL STAT SOC B, V39, P38, DOI DOI 10.2307/2984875; DENG JL, 1982, SYST CONTROL LETT, V1, P288; de Oliveira JV, 1999, IEEE T SYST MAN CY A, V29, P128, DOI 10.1109/3468.736369; DEOLIVEIRA JV, 1995, IEEE T FUZZY SYST, V3, P404; Destercke S, 2007, FUZZY SET SYST, V158, P2078, DOI 10.1016/j.fss.2007.04.026; Dubois D., 1980, FUZZY SETS SYSTEMS T; Dubois D, 1997, IEEE T FUZZY SYST, V5, P398, DOI 10.1109/91.618276; Dunn J. C., 1973, Journal of Cybernetics, V3; ENGL HW, 1999, REGULARIZATION INVER; Espinosa J, 2000, IEEE T FUZZY SYST, V8, P591; Farin G, 1994, CURVES SURFACES COMP; Fiordaliso A, 2001, FUZZY SET SYST, V118, P307, DOI 10.1016/S0165-0114(99)00109-8; FRIDEDMAN JH, 1991, ANN STAT, V19, P79; Fritzke B., 1997, P APPL SOFT COMP SPI, P86; FURUBASHI T, 2002, LECT NOTES COMPUTER, V2275, P12; Furuhashi T., 2001, P 10 IEEE INT C FUZZ, P284; Gan Q, 1999, IEEE T SYST MAN CY B, V29, P559, DOI 10.1109/3477.775275; Gan Q, 2001, IEEE T NEURAL NETWOR, V12, P43, DOI 10.1109/72.896795; Gegov A, 2007, STUD FUZZ SOFT COMP, V211, P1, DOI 10.1007/978-3-540-38885-2; GEWEKE J, 1981, INT ECON REV, V22, P55, DOI 10.2307/2526135; Golub G. H., 1976, TR456 U MAR DEP COMP; GOTTWALD S, 1995, P 3 EUR C INT TECH S, P682; Guillaume S, 2004, IEEE T FUZZY SYST, V12, P324, DOI 10.1109/TFUZZ.2004.825979; Guillaume S, 2001, IEEE T FUZZY SYST, V9, P426, DOI 10.1109/91.928739; Gunn SR, 2002, MACH LEARN, V48, P137, DOI 10.1023/A:1013903804720; Gustafson D. E., 1979, P IEEE CDC, V2, P761; HANNAN EJ, 1979, J ROY STAT SOC B MET, V41, P190; HANNAN EJ, 1980, ANN STAT, V8, P1071, DOI 10.1214/aos/1176345144; HARDEL W, 1990, APPL NONPARAMETRIC R; Harris CJ, 2002, ADAPTIVE MODELLING E; Hastie T, 1996, CLASSIFICATION PAIRW; Hastie TJ, 1990, GEN ADDITIVE MODELS; Hefny HA, 2007, INFORM SCIENCES, V177, P4832, DOI 10.1016/j.ins.2007.02.027; Hoeppner F, 1997, IEEE T FUZZY SYST, V5, P599, DOI 10.1109/91.649912; Hong X, 2000, IEEE T NEURAL NETWOR, V11, P889, DOI 10.1109/72.857770; Hoppner F., 2000, P 4 INT C KNOWL BAS, P162; Ichihashi H, 1996, FUZZY SET SYST, V81, P157, DOI 10.1016/0165-0114(95)00247-2; Ishibuchi H, 2007, INT J APPROX REASON, V44, P4, DOI 10.1016/j.ijar.2006.01.004; Ishibuchi H, 2001, INFORM SCIENCES, V136, P109, DOI 10.1016/S0020-0255(01)00144-X; JAKEL J, 1999, P 7 EUR C INT TECHN, P279; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Jang J-SR, 1997, NEUROFUZZY SOFT COMP; Janikow CZ, 1998, IEEE T SYST MAN CY B, V28, P1, DOI 10.1109/3477.658573; JEROME C, 2002, P INF PROC MAN UNC I, P225; JIMENEZ F, 2002, P IEEE INT C SYST MA, P253; Jin YC, 2000, IEEE T FUZZY SYST, V8, P212, DOI 10.1109/91.842154; Jin YC, 1999, IEEE T SYST MAN CY B, V29, P829, DOI 10.1109/3477.809036; Johansen TA, 2000, IEEE T FUZZY SYST, V8, P297, DOI 10.1109/91.855918; Johansen TA, 2003, IEEE T FUZZY SYST, V11, P847, DOI 10.1109/TFUZZ.2003.819824; John RI, 2005, IEEE T SYST MAN CY B, V35, P1340, DOI 10.1109/TSMCB.2005.855588; JORGENSEN SB, 1995, INT J ADAPT CONTROL, V9, P547, DOI 10.1002/acs.4480090607; KANDOLA JS, 2001, THESIS U SOUTHAMPTON; KANJILAL PP, 1995, IEEE T NEURAL NETWOR, V6, P1061, DOI 10.1109/72.410351; Karayiannis NB, 1997, IEEE T NEURAL NETWOR, V8, P1492, DOI 10.1109/72.641471; KAVLI T, 1993, INT J CONTROL, V58, P947, DOI 10.1080/00207179308923037; Kim E, 1998, IEEE T FUZZY SYST, V6, P596; Kim SW, 2005, IEEE T PATTERN ANAL, V27, P136; KLOSE A, 1999, P NEUR NETW APPL NN, P47; KLOSE A, 1998, P 6 EUR C INT TECHN, P629; Klose A., 1999, P 7 EUR C INT TECHN, P6; Kohonen T, 1989, SELF ORG ASS MEMORY; Kullback S., 1959, INFORM THEORY STAT; Kumar M, 2006, IEEE T FUZZY SYST, V14, P314, DOI 10.1109/TFUZZ.2005.861614; Laha A, 2001, IEEE T SYST MAN CY B, V31, P881, DOI 10.1109/3477.969492; Lindskog P., 1997, FUZZY MODEL IDENTIFI, P3; Lotfi A, 1996, INT J APPROX REASON, V15, P379, DOI 10.1016/S0888-613X(96)00070-9; MAMDANI EH, 1976, INT J MAN MACH STUD, V8, P669, DOI 10.1016/S0020-7373(76)80028-4; Mastorocostas PA, 2001, FUZZY SET SYST, V118, P215, DOI 10.1016/S0165-0114(98)00344-3; Mencar C, 2007, INFORM SCIENCES, V177, P130, DOI 10.1016/j.ins.2006.04.008; MENCAR C, 2004, P 5 INT C REC ADV SO, P354; Mouzouris G. C., 1996, Proceedings of the Fifth IEEE International Conference on Fuzzy Systems. FUZZ-IEEE '96 (Cat. No.96CH35998), DOI 10.1109/FUZZY.1996.551757; Mouzouris GC, 1997, J INTELL FUZZY SYST, V5, P367; Nauck D, 1999, ARTIF INTELL MED, V16, P149, DOI 10.1016/S0933-3657(98)00070-0; Nauck D, 1997, FUZZY SET SYST, V89, P277, DOI 10.1016/S0165-0114(97)00009-2; Nauck D., 1998, P IEEE INT C FUZZ SY, P1106; Nauck DD, 2003, IEEE INT CONF FUZZY, P196; NELLES O, 1999, THESIS DARMSTADT U D; Nelles O, 1996, IEEE DECIS CONTR P, P470, DOI 10.1109/CDC.1996.574356; Nelles O., 2000, International Journal of Applied Mathematics and Computer Science, V10; OMOHUNDRO SM, 1990, TR90001 INT COMP SCI; Paiva RP, 2004, FUZZY SET SYST, V147, P17, DOI 10.1016/j.fss.2003.11.012; Pal NR, 1999, FUZZY SET SYST, V103, P201, DOI 10.1016/S0165-0114(98)00222-X; Pal NR, 2001, IEEE T SYST MAN CY B, V31, P745, DOI 10.1109/3477.956036; PENAREYES CA, 2003, ACCURACY IMPROVEMENT, V129; Pena-Reyes CA, 2001, IEEE T FUZZY SYST, V9, P727, DOI 10.1109/91.963759; Plate T, 1999, BEHAVIOURMETRIKA SPE, V26, P29, DOI 10.2333/bhmk.26.29; Quinlan R., 1986, MACH LEARN, V1, P81; Riid A., 2001, P 10 INT S SYST MOD, P165; Riid A., 2000, P IFAC S ART INT REA, P229; RIID A, 2002, THESIS TALLINN TU ES; JANG JSR, 1993, IEEE T NEURAL NETWOR, V4, P156, DOI 10.1109/72.182710; Rojas I, 2000, IEEE T FUZZY SYST, V8, P23, DOI 10.1109/91.824763; Roubos H, 2001, IEEE T FUZZY SYST, V9, P516, DOI 10.1109/91.940965; Roubos JA, 2003, IEEE T FUZZY SYST, V11, P861, DOI 10.1109/TFUZZ.2003.819822; Ruiz A, 2001, IEEE T NEURAL NETWOR, V12, P16, DOI 10.1109/72.896793; Scholkopf B., 1998, P 8 INT C ART NEUR N, P147; Schwefel H.P., 1995, EVOLUTION OPTIMUM SE; Setnes M., 2000, P 9 IEEE INT C FUZZ, P700; Setnes M, 1998, IEEE T SYST MAN CY B, V28, P376, DOI 10.1109/3477.678632; Setnes M, 2001, IEEE T SYST MAN CY C, V31, P199, DOI 10.1109/5326.941843; Setnes M, 1998, IEEE T SYST MAN CY C, V28, P165, DOI 10.1109/5326.661100; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Shen Q, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P168; Silipo R, 2000, IEEE T SYST MAN CY B, V30, P821, DOI 10.1109/3477.891144; Stitson MO, 1999, ADVANCES IN KERNEL METHODS, P285; Stone CJ, 1997, ANN STAT, V25, P1371; Sugeno M., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390281; SUGENO M, 1988, FUZZY SET SYST, V28, P15, DOI 10.1016/0165-0114(88)90113-3; SUZUKI T, 2003, STUDIES FUZZINESS SO, V128; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; TANIGUCHI M, 1980, ANN I STAT MATH, V32, P401, DOI 10.1007/BF02480345; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1035; Tou J. T., 1974, PATTERN RECOGNITION; Van Broekhoven E, 2007, INT J APPROX REASON, V44, P65, DOI 10.1016/j.ijar.2006.03.003; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Wahba G., 1990, SPLINE MODELS OBSERV; Wahba G, 1995, ANN STAT, V23, P1865; Wang H, 2005, IEEE T SYST MAN CYB, V29, P143; WANG L, 1994, IEEE T SIGNAL PROCES, V42, P1388; WANG L, 1995, IEEE T FUZZY SYST, V3, P454; WANG LX, 1992, IEEE T NEURAL NETWOR, V3, P807, DOI 10.1109/72.159070; Wang XZ, 2001, IEEE T SYST MAN CY B, V31, P215, DOI 10.1109/3477.915344; Wang HL, 2005, FUZZY SET SYST, V149, P149, DOI 10.1016/j.fss.2004.07.013; Weston J., 1998, CSDTR9804 U LOND DEP; WYATT J, 1995, LANCET, V346, P1175, DOI 10.1016/S0140-6736(95)92893-6; YAGER RR, 1993, IEEE T SYST MAN CYB, V23, P1198, DOI 10.1109/21.247902; Yen J, 1998, IEEE T FUZZY SYST, V6, P530, DOI 10.1109/91.728447; Yen J, 1998, IEEE T FUZZY SYST, V6, P362, DOI 10.1109/91.705503; Zadeh L. A., 1996, INT J MULTIPLE VALUE, V1, P1; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; Zadeh LA, 1971, ASPECTS NETWORK SYST, P469; Zhang HH, 2004, J AM STAT ASSOC, V99, P659, DOI 10.1198/016214504000000593; ZHOU SM, 2004, INT J COMPUT INTELL, V4, P355, DOI 10.1142/S1469026804001379; Zhou SM, 2006, FUZZY SET SYST, V157, P1057, DOI 10.1016/j.fss.2005.08.004; Zwick R., 1987, International Journal of Approximate Reasoning, V1, DOI 10.1016/0888-613X(87)90015-6	197	92	95	7	21	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114	1872-6801		FUZZY SET SYST	Fuzzy Sets Syst.	DEC 1	2008	159	23					3091	3131		10.1016/j.fss.2008.05.016		41	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	369SA	WOS:000260713000001		
J	Grosenick, L; Greer, S; Knutson, B				Grosenick, Logan; Greer, Stephanie; Knutson, Brian			Interpretable Classifiers for fMRI Improve Prediction of Purchases	IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING			English	Article						Accumbens; classification; discriminant; elastic net; frontal; functional magnetic resonance imaging (fMRI); human; insula; lasso; penalized discriminant analysis (PDA); prediction; purchasing; single-trial; sparse; spatiotemporal; support vector machine (SVM)	HUMAN VISUAL-CORTEX; DISCRIMINANT-ANALYSIS; VARIABLE SELECTION; BRAIN ACTIVITY; NEURAL BASIS; REGRESSION; REGULARIZATION; PATTERNS; MACHINE; IMAGES	Despite growing interest in applying machine learning to neuroimaging analyses, few studies have gone beyond classifying sensory input to directly predicting behavioral output. With spatial resolution on the order of millimeters and temporal resolution on the order of seconds, functional magnetic resonance imaging (fMRI) is a promising technology for such applications. However, fMRI data's low signal-to-noise ratio, high dimensionality, and extensive spatiotemporal correlations present formidable analytic challenges. Here, we apply different machine-learning algorithms to previously acquired data to examine the ability of fMRI activation in three regions-the nucleus accumbens (NAcc), medial prefrontal cortex (MPFC), and insula-to predict purchasing. Our goal was to improve spatiotemporal interpretability as well as classification accuracy. To this end, sparse penalized discriminant analysis (SPDA) enabled automatic selection of correlated variables, yielding interpretable models that generalized well to new data. Relative to logistic regression, linear discriminant analysis, and linear support vector machines, SPDA not only increased interpretability but also improved classification accuracy. SPDA promises to allow more precise inferences about when specific brain regions contribute to purchasing decisions. More broadly, this approach provides a general framework for using neuroimaging data to build interpretable models, including those that predict choice.	[Grosenick, Logan] Stanford Univ, Neurosci Inst Stanford, Stanford, CA 94305 USA; [Greer, Stephanie; Knutson, Brian] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA	Grosenick, L (reprint author), Stanford Univ, Neurosci Inst Stanford, Stanford, CA 94305 USA.			Knutson, Brian/0000-0002-7669-426X	FINRA Investor Education Grant; National Institute of Aging [R21 030778]	The work of B. Knutson was supported in part by a FINRA Investor Education Grant and in part by the National Institute of Aging under Grant R21 030778.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444; Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Knutson B, 2007, NEURON, V53, P147, DOI 10.1016/j.neuron.2006.11.010; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Logothetis NK, 2002, PHILOS T ROY SOC B, V357, P1003, DOI 10.1098/rstb.2002.1114; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Knutson B, 2005, J NEUROSCI, V25, P4806, DOI 10.1523/JNEUROSCI.0642-05.2005; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Knutson B, 2003, NEUROIMAGE, V18, P263, DOI 10.1016/S1053-8119(02)00057-5; Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713; Kuhnen CM, 2005, NEURON, V47, P763, DOI 10.1016/j.neuron.2005.08.008; Efron B, 2004, ANN STAT, V32, P407; Cox DD, 2003, NEUROIMAGE, V19, P261, DOI 10.1016/S1053-8119(03)00049-1; Davatzikos C, 2005, NEUROIMAGE, V28, P663, DOI 10.1016/j.neuroimage.2005.08.009; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; O'Toole AJ, 2005, J COGNITIVE NEUROSCI, V17, P580, DOI 10.1162/0898929053467550; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; CARLSON TA, 2003, J COGN NAUROSCI, V15, P701; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Glover G. H., 2001, MAGN RESON MED, V46, P512; Hampton AN, 2007, P NATL ACAD SCI USA, V104, P1377, DOI 10.1073/pnas.0606297104; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Haynes JD, 2005, CURR BIOL, V15, P1301, DOI 10.1016/j.cub.2005.06.026; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Huettel S, 2004, FUNCTIONAL MAGNETIC; Kim H, 2007, P NATL ACAD SCI USA, V104, P18253, DOI 10.1073/pnas.0703101104; Mallows C., 1973, TECHNOMETRICS, V42, P87; Mourão-Miranda Janaina, 2007, Neuroimage, V36, P88, DOI 10.1016/j.neuroimage.2007.02.020; PANKESEPP J, 1998, AFFECTIVE NEUROSCIEN; Polyn SM, 2005, SCIENCE, V310, P1963, DOI 10.1126/science.1117645; RDC Team, 2008, R LANG ENV STAT COMP; Vapnik VN, 1995, NATURE STAT LEARNING; Wang XJ, 2003, P SOC PHOTO-OPT INS, V4895, P1, DOI 10.1117/12.466531; ZHAO P, 2006, MODEL SELECTION CONS	42	37	38	0	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1534-4320	1558-0210		IEEE T NEUR SYS REH	IEEE Trans. Neural Syst. Rehabil. Eng.	DEC	2008	16	6					539	548		10.1109/TNSRE.2008.926701		10	Engineering, Biomedical; Rehabilitation	Engineering; Rehabilitation	395XO	WOS:000262557000004	19144586	
J	Ulfarsson, MO; Solo, V				Ulfarsson, Magnus O.; Solo, Victor			Sparse Variable PCA Using Geodesic Steepest Descent	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						Geodesic; geometric; l(1); LASSO; principal component analysis (PCA); regularization; sparse	PRINCIPAL COMPONENT ANALYSIS; ALGORITHMS; CONSTRAINTS; SELECTION; MODEL; ADAPTATION; REGRESSION; SHRINKAGE; MANIFOLD; LASSO	Principal component analysis (PCA) is a dimensionality reduction technique used in most fields of science and engineering. It aims to find linear combinations of the input variables that maximize variance. A problem with PCA is that it typically assigns nonzero loadings to all the variables, which in high dimensional problems can require a very large number of coefficients. But in many applications, the aim is to obtain a massive reduction in the number of coefficients. There are two very different types of sparse PCA problems: sparse loadings PCA (slPCA) which zeros out loadings (while generally keeping all of the variables) and sparse variable PCA which zeros out whole variables (typically leaving less than half of them). In this paper, we propose a new svPCA, which we call sparse variable noisy PCA (svnPCA). It is based on a statistical model, and this gives access to a range of modeling and inferential tools. Estimation is based on optimizing a novel penalized log-likelihood able to zero out whole variables rather than just some loadings. The estimation algorithm is based on the geodesic steepest descent algorithm. Finally, we develop a novel form of Bayesian information criterion (BIC) for tuning parameter selection. The svnPCA algorithm is applied to both simulated data and real functional magnetic resonance imaging (fMRI) data.	[Ulfarsson, Magnus O.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48104 USA; [Solo, Victor] Univ New S Wales, Sch Elect Engn, Sydney, NSW 2052, Australia	Ulfarsson, MO (reprint author), Univ Iceland, Dept Elect Engn, IS-111 Reykjavik, Iceland.	mou@hi.is; v.solo@unsw.edu.au					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; ALLINEY S, 1994, IEEE T SIGNAL PROCES, V42, P618, DOI 10.1109/78.277854; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; ANDERSON TW, 1963, ANN MATH STAT, V34, P122, DOI 10.1214/aoms/1177704248; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; SCHNEEWEISS H, 1995, J MULTIVARIATE ANAL, V55, P105, DOI 10.1006/jmva.1995.1069; Schneeweiss H, 1997, MULTIVAR BEHAV RES, V32, P375, DOI 10.1207/s15327906mbr3204_4; Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504; Turlach BA, 2005, TECHNOMETRICS, V47, P349, DOI 10.1198/004017005000000139; MEYER RR, 1976, J COMPUT SYST SCI, V12, P108, DOI 10.1016/S0022-0000(76)80021-9; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Bertsekas D., 1999, NONLINEAR PROGRAMMIN; CICHOCKI A, 2003, IEICE T FUND ELECTR, V86, P1; DASPREMONT A, 2006, SIAM REV IN PRESS; Douglas SC, 2000, IEEE T SIGNAL PROCES, V48, P1843, DOI 10.1109/78.845952; Elden L, 1999, NUMER MATH, V82, P599, DOI 10.1007/s002110050432; Fiori S, 2001, NEURAL COMPUT, V13, P1625, DOI 10.1162/089976601750265036; Golub G H, 1996, MATRIX COMPUTATION; Jackson J. E., 1991, USERS GUIDE PRINCIPA; JOHNSTONE II, 2004, PRINCIPAL COMPONENT; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; LANGE K, 1995, J ROY STAT SOC B MET, V57, P425; LAWLEY D, 1953, P UPPS S PSYCH FACT, P35; Loader C., 1999, LOCAL REGRESSION LIK; LUENBERGER D. G., 1973, INTRO LINEAR NONLINE; LUENBERG.DG, 1972, MANAGE SCI, V18, P620, DOI 10.1287/mnsc.18.11.620; Manton JH, 2002, IEEE T SIGNAL PROCES, V50, P635, DOI 10.1109/78.984753; MOLER C, 1978, SIAM REV, V20, P4; NISHIMORI Y, 1999, P INT JOINT C NEUR N, V2, P933; Ostrowski A. M., 1973, SOLUTIONS EQUATIONS; Preisendorfer R. W., 1988, PRINCIPAL COMPONENT; Robinson G. K., 1991, STAT SCI, V6, P15, DOI DOI 10.1214/SS/1177011926; SOLO V, 2002, ROTATED FUNCTIONAL P; Solo V., 1999, P IEEE INT C AC SPEE, V3, P1653; STEVENSON RL, 1994, IEEE T SYST MAN CYB, V24, P455, DOI 10.1109/21.278994; THEOBALD CM, 1975, BIOMETRIKA, V62, P461, DOI 10.1093/biomet/62.2.461; Ulfarsson MO, 2007, I S BIOMED IMAGING, P460, DOI 10.1109/ISBI.2007.356888; ZANGWILL W. I., 1969, NONLINEAR PROGRAMMIN; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	46	12	13	0	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-587X			IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	DEC	2008	56	12					5823	5832		10.1109/TSP.2008.2006587		10	Engineering, Electrical & Electronic	Engineering	378HD	WOS:000261310900008		
J	Scott, JG; Carvalho, CM				Scott, James G.; Carvalho, Carlos M.			Feature-Inclusion Stochastic Search for Gaussian Graphical Models	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						Bayesian model selection; Covariance selection; Hyper-inverse Wishart distribution; Lasso; Metropolis algorithm	BAYES VARIABLE SELECTION; COVARIANCE-SELECTION; COMPUTATION; REGRESSION; LASSO	We describe a serial algorithm called feature-inclusion stochastic search, or FINCS, that uses online estimates of edge-inclusion probabilities to guide Bayesian model determination in Gaussian graphical models. FINCS is compared to MCMC, to Metropolis-based search methods, and to the popular lassos it is found to be superior along a variety of dimensions. leading to better sets of discovered models, greater speed and stability, and reasonable estimates of edge-inclusion probabilities. We illustrate FINCS on an example involving mutual-fund data, where we compare the model-averaged predictive performance of models discovered with FINCS to those discovered by competing methods.	[Scott, James G.] Duke Univ, Dept Stat Sci, Durham, NC 27708 USA; [Carvalho, Carlos M.] Univ Chicago, Grad Sch Business, Chicago, IL 60637 USA	Scott, JG (reprint author), Duke Univ, Dept Stat Sci, Durham, NC 27708 USA.	james@stat.duke.edu; carlos.carvalho@chicagogsb.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wong F, 2003, BIOMETRIKA, V90, P809, DOI 10.1093/biomet/90.4.809; Carvalho CM, 2007, BAYESIAN ANAL, V2, P69; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Scott JG, 2006, J STAT PLAN INFER, V136, P2144, DOI 10.1016/j.jspi.2005.08.031; Hans C, 2007, J AM STAT ASSOC, V102, P507, DOI 10.1198/016214507000000121; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Barbieri MM, 2004, ANN STAT, V32, P870, DOI 10.1214/009053604000000238; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Berger JO, 2005, STAT NEERL, V59, P3, DOI 10.1111/j.1467-9574.2005.00275.x; Berry A, 2004, ALGORITHMICA, V39, P287, DOI 10.1007/s00453-004-1084-3; Berry A, 2006, DISCRETE MATH, V306, P318, DOI 10.1016/j.disc.2005.12.002; Carvalho CM, 2007, BIOMETRIKA, V94, P647, DOI 10.1093/biomet/asm056; CARVALHO CM, 2007, OBJECTIVE BAYESIAN M; Cui W, 2008, J STAT PLAN INFER, V138, P888, DOI 10.1016/j.jspi.2007.02.011; DAWID AP, 1993, ANN STAT, V21, P1272, DOI 10.1214/aos/1176349260; DESHPANDE A, 2001, UNCERTAINTY ARTIFICI; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; FRYDENBERG M, 1989, BIOMETRIKA, V76, P539, DOI 10.1093/biomet/76.3.539; George EI, 2000, BIOMETRIKA, V87, P731, DOI 10.1093/biomet/87.4.731; Giudici P, 1999, BIOMETRIKA, V86, P785, DOI 10.1093/biomet/86.4.785; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Jones B, 2005, STAT SCI, V20, P388, DOI 10.1214/088342305000000304; LIANG F, 2007, J AM STAT ASSOC, V103, P410; OHAGAN A, 1995, J ROY STAT SOC B MET, V57, P99; SCOTT JG, 2008, BAYES EMPIRICAL BAYE; WOODARD DB, 2007, THESIS DUKE U; Zellner A, 1986, BAYESIAN INFERENCE D, P233; Zellner A., 1980, BAYESIAN STAT, P585	30	26	26	0	2	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	DEC	2008	17	4					790	808		10.1198/106186008X382683		19	Statistics & Probability	Mathematics	497MN	WOS:000270063700002		
J	Yuan, M				Yuan, Ming			Efficient Computation of l(1) Regularized Estimates in Gaussian Graphical Models	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						GraphGarrote; GraphLasso; Solution path	VARIABLE SELECTION; REGRESSION; LASSO	In this article, I propose an efficient algorithm to compute l(1) regularized maximum likelihood estimates in the Gaussian graphical model. These estimators, recently proposed in an earlier article by Yuan and Lin, conduct parameter estimation and model selection simultaneously and have been shown to enjoy nice properties in both large and finite samples. TO compute the estimates, however, can be very challenging in practice because of the high dimensionality and positive definiteness constraint oil the covariance matrix. Taking advantage of the recent advance in semidefinite programming, Yuan and Lin suggested a sophisticated interior-point algorithm to solve the optimization problem. Although a polynomial time algorithm, the optimization technique is known not to be scalable for high-dimensional problems. Alternatively, this article shows that the estimates can be computed by iteratively solving a sequence of l(1) regularized quadratic programs. By effectively exploiting the sparsity of the graphical structure, I propose a new algorithm that can be applied to problems of larger scale. When combined with a path-following strategy, the new algorithm can be used to efficiently approximate the entire solution path of the C, regularized maximum likelihood estimates, which also facilitates the choice of tuning parameter. I demonstrate the efficacy and usefulness of the proposed algorithm on a few simulations and real datasets.	Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA	Yuan, M (reprint author), Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA.	myuan@isye.gatech.edu			NSF [DMS-0624841]	This research was supported in part by NSF grant DMS-0624841.	Drton M, 2004, BIOMETRIKA, V91, P591, DOI 10.1093/biomet/91.3.591; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Li HZ, 2006, BIOSTATISTICS, V7, P302, DOI 10.1093/biostatistics/kxj008; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Boyd S., 2003, CONVEX OPTIMIZATION; Dempster A., 1972, BIOMETRIKA, V32, P95; Edwards D., 2000, INTRO GRAPHICAL MODE; Lauritzen S. L., 1996, GRAPHICAL MODELS; Mardia KV, 1979, MULTIVARIATE ANAL; Nelsen R. B., 1998, INTRO COPULAS; Whittaker J, 1990, GRAPHICAL MODELS APP; Wu S. P., 1996, SOFTWARE DETERMINANT; Wille A, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-11-r92	19	9	9	0	2	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	DEC	2008	17	4					809	826		10.1198/106186008X382692		18	Statistics & Probability	Mathematics	497MN	WOS:000270063700003		
J	Kim, J; Kim, Y; Kim, Y				Kim, Jinseog; Kim, Yuwon; Kim, Yongdai			A Gradient-Based Optimization Algorithm for LASSO	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						Gradient descent; LASSO; Multiclass logistic model; Variable selection	VARIABLE SELECTION; GREEDY APPROXIMATION; REGRESSION; CLASSIFICATION; PREDICTION; LIKELIHOOD; SHRINKAGE; PURSUIT; BOUNDS; PATH	LASSO is a useful method for achieving both shrinkage and variable selection simultaneously. The main idea of LASSO is to use the L-1 constraint in the regularization step which has been applied to various models such as wavelets, kernel machines, smoothing splines, and multiclass logistic models. We call such models with the L-1 constraint generalized LASSO models. In this article, we propose a new algorithm called the gradient LASSO algorithm for generalized LASSO. The gradient LASSO algorithm is computationally more stable than QP-based algorithms because it does not require matrix inversions, and thus it can be more easily applied to high-dimensional data. Simulation results show that the proposed algorithm is fast enough for practical purposes and provides reliable results. To illustrate its computing power with high-dimensional data, we analyze multiclass microarray data using the proposed algorithm.	[Kim, Jinseog] Dongguk Univ, Dept Stat & Informat Sci, Gyeongju 780714, South Korea; [Kim, Yuwon] NHN Corp, Datamining Lab, Gyeonggi Do 463844, South Korea; [Kim, Yongdai] Seoul Natl Univ, Dept Stat, Seoul 151742, South Korea	Kim, J (reprint author), Dongguk Univ, Dept Stat & Informat Sci, Gyeongju 780714, South Korea.	jinseog.kim@gmail.com; yuwon.kim@nhncorp.com; ydkim0903@gmail.com		Kim, Jinseog/0000-0003-3172-3212	Korean Foundation [KRF-2005-070-C00021, KRF-2005-214-C00187]; Korean Government (MOEHRD)	We thank the Associate Editor and the referees whose helpful comments led to significant improvements in this paper. This research was supported in part by the Korean Foundation grant KRF-2005-070-C00021 and KRF-2005-214-C00187 funded by the Korean Government (MOEHRD).	Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; Bakin S, 1999, THESIS AUSTR NATL U; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Grandvalet Y, 1999, ADV NEUR IN, V11, P445; GUNN SR, 2002, MACH LEARN, V48, P115; JONES LK, 1992, ANN STAT, V20, P608, DOI 10.1214/aos/1176348546; Kim Y, 2006, STAT SINICA, V16, P375; Kim Y., 2004, P 21 INT C MACH LEAR, P473; LOKHORST J, 2006, LASSO 2 S PLUS LIB S; MA S, 2005, LASSO METHOD ADDITIV; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Perkins S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753698; Rosset S, 2004, J MACH LEARN RES, V5, P941; Rosset S, 2005, ADV NEURAL INFORM PR, V1153, P1153; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Roth V, 2004, IEEE T NEURAL NETWOR, V15, P16, DOI 10.1109/TNN.2003.809398; Yuan ZH, 2006, SCI CHINA SER B, V49, P67, DOI 10.1007/s11426-004-0106-y; Zhang HH, 2004, J AM STAT ASSOC, V99, P659, DOI 10.1198/016214504000000593; Zhang T, 2003, IEEE T INFORM THEORY, V49, P682, DOI 10.1109/TIT.2002.808136; ZHAO P, 2004, 678 UC BERK DEP STAT	31	12	12	1	2	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	DEC	2008	17	4					994	1009		10.1198/106186008X386210		16	Statistics & Probability	Mathematics	497MN	WOS:000270063700013		
J	Candes, EJ; Wakin, MB; Boyd, SP				Candes, Emmanuel J.; Wakin, Michael B.; Boyd, Stephen P.			Enhancing Sparsity by Reweighted l(1) Minimization	JOURNAL OF FOURIER ANALYSIS AND APPLICATIONS			English	Article; Proceedings Paper	4th IEEE International Symposium on Biomedical Imaging	APR 12-15, 2007	Arlington, VA	IEEE		l(1)-Minimization; Iterative reweighting; Underdetermined systems of linear equations; Compressive sensing; Dantzig selector; Sparsity; FOCUSS	SIGNAL RECOVERY; UNCERTAINTY PRINCIPLES; ATOMIC DECOMPOSITION; PROGRAMMING METHODS; IMAGE-RESTORATION; RECONSTRUCTION; ALGORITHMS; DECONVOLUTION; OPTIMIZATION; NOISE	It is now well understood that (1) it is possible to reconstruct sparse signals exactly from what appear to be highly incomplete sets of linear measurements and (2) that this can be done by constrained l(1) minimization. In this paper, we study a novel method for sparse signal recovery that in many situations outperforms l(1) minimization in the sense that substantially fewer measurements are needed for exact recovery. The algorithm consists of solving a sequence of weighted l(1)-minimization problems where the weights used for the next iteration are computed from the value of the current solution. We present a series of experiments demonstrating the remarkable performance and broad applicability of this algorithm in the areas of sparse signal recovery, statistical estimation, error correction and image processing. Interestingly, superior gains are also achieved when our method is applied to recover signals with assumed near-sparsity in overcomplete representations-not by reweighting the l(1) norm of the coefficient sequence as is common, but by reweighting the l(1) norm of the transformed object. An immediate consequence is the possibility of highly efficient data acquisition protocols by improving on a technique known as Compressive Sensing.	[Wakin, Michael B.] Colorado Sch Mines, Golden, CO 80401 USA; [Candes, Emmanuel J.] CALTECH, Pasadena, CA 91125 USA; [Boyd, Stephen P.] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Wakin, MB (reprint author), Colorado Sch Mines, Golden, CO 80401 USA.	emmanuel@acm.caltech.edu; mwakin@mines.edu; boyd@stanford.edu	Wakin, Michael/G-1582-2012				Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983; Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Delaney AH, 1998, IEEE T IMAGE PROCESS, V7, P204, DOI 10.1109/83.660997; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031; Elad M, 2007, INVERSE PROBL, V23, P947, DOI 10.1088/0266-5611/23/3/007; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300; Donoho DL, 2009, J AM MATH SOC, V22, P1; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Zou H, 2008, ANN STAT, V36, P1509, DOI 10.1214/009053607000000802; Lobo MS, 2007, ANN OPER RES, V152, P341, DOI 10.1007/s10479-006-0145-1; Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410; Bajwa W., 2006, P 5 INT C INF PROC S, P134, DOI DOI 10.1145/1127777.1127801; Baron D., 2005, DISTRIBUTED COMPRESS; Boyd S., 2007, LECT NOTES EE364B CO; Candes E. J., 2006, HIGHLY ROBUST ERROR; Chartrand R., 2008, P IEEE INT C AC SPEE, P3869; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; Dahleh MA, 1995, CONTROL UNCERTAIN SY; Donoho D. L., 2006, IEEE T INF THEORY, V52; DONOHO DL, 1989, SIAM J APPL MATH, V49, P906, DOI 10.1137/0149053; Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028; DONOHO DL, 1992, SIAM J APPL MATH, V52, P577, DOI 10.1137/0152031; Fazel M., 2002, THESIS STANFORD U; Fazel M., 2003, P AM CONTR C JUN; Figueiredo MAT, 2007, IEEE T IMAGE PROCESS, V16, P2980, DOI 10.1109/TIP.2007.909318; FIGUEIREDO MAT, 2005, P IEEE INT C IM PROC, V2; Ghosh A, 2006, IEEE DECIS CONTR P, P6605, DOI 10.1109/CDC.2006.377282; Goldfarb D, 2005, SIAM J SCI COMPUT, V27, P622, DOI 10.1137/040608982; HARIKUMAR G, 1996, P INT C AC SPEECH SI; Hassibi A, 1999, J GUID CONTROL DYNAM, V22, P862, DOI 10.2514/2.4464; HEALY DL, 2005, ANALOG TO INFORMATIO; Huber P. J., 1981, ROBUST STAT; KIM SJ, 2008, SIAM REV IN PRESS; Lange K., 2004, SPRINGER TEXTS STAT; LOBO M, 2006, ANN OPER RES, V152, P341; Lustig M., 2007, SPARSE MRI APPL COMP; Saab R., 2008, 33 INT C AC SPEECH S; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; SCHLOSSM.EJ, 1973, J AM STAT ASSOC, V68, P857, DOI 10.2307/2284512; Starck J. L., 2004, ADV IMAG ELECT PHYS, V132, P288; Sun J, 2006, SIAM REV, V48, P681, DOI 10.1137/S0036144504443821; Takhar D., 2006, P COMP IM 4 SPIE EL; TAYLOR HL, 1979, GEOPHYSICS, V44, P39, DOI 10.1190/1.1440921; VANDENBERGHE L., 1997, P 1997 IEEE ACM INT, P252; VANDENBERGHE L, 1998, IEEE T COMPUT AID D, V2, P110; Vandenberghe L., 2004, CONVEX OPTIMIZATION; WIPF DP, 2008, P NEUR INF PROC SYST, V20; WIPF DP, 2008, COMMUNICATION    JAN; YARLAGADDA R, 1985, IEEE T ACOUST SPEECH, V33, P174, DOI 10.1109/TASSP.1985.1164508	62	755	805	18	82	BIRKHAUSER BOSTON INC	CAMBRIDGE	675 MASSACHUSETTS AVE, CAMBRIDGE, MA 02139 USA	1069-5869			J FOURIER ANAL APPL	J. Fourier Anal. Appl.	DEC	2008	14	5-6					877	905		10.1007/s00041-008-9045-x		29	Mathematics, Applied	Mathematics	379QM	WOS:000261411300013		
J	Braunstein, A; Pagnani, A; Weigt, M; Zecchina, R				Braunstein, A.; Pagnani, A.; Weigt, M.; Zecchina, R.			Inference algorithms for gene networks: a statistical mechanics analysis	JOURNAL OF STATISTICAL MECHANICS-THEORY AND EXPERIMENT			English	Article						cavity and replica method; regulatory networks (theory); message-passing algorithms; genomic and proteomic networks	REGULATORY NETWORKS; EXPRESSION; SELECTION; MODELS; MOTIFS; LASSO	The inference of gene regulatory networks from high throughput gene expression data is one of the major challenges in systems biology. This paper aims at analysing and comparing two different algorithmic approaches. The first approach uses pairwise correlations between regulated and regulating genes; the second one uses message-passing techniques for inferring activating and inhibiting regulatory interactions. The performance of these two algorithms can be analysed theoretically on well-defined test sets, using tools from the statistical physics of disordered systems like the replica method. We find that the second algorithm outperforms the first one since it takes into account collective effects of multiple regulators.	[Braunstein, A.; Pagnani, A.; Weigt, M.] Inst Sci Interchange, I-10133 Turin, Italy; [Braunstein, A.; Zecchina, R.] Politecn Torino, I-10129 Turin, Italy	Braunstein, A (reprint author), Inst Sci Interchange, Viale S Severo 65, I-10133 Turin, Italy.	alfredo.braunstein@polito.it; pagnani@isi.it; weigt@isi.it; riccardo.zecchina@polito.it	Braunstein, Alfredo/E-6924-2012; Braunstein, Alfredo/D-6049-2011; Pagnani, Andrea/J-2363-2015	Braunstein, Alfredo/0000-0002-4562-3610; Pagnani, Andrea/0000-0002-6509-0807			Alberts B., 2003, ESSENTIAL CELL BIOL; Shen-Orr SS, 2002, NAT GENET, V31, P64, DOI 10.1038/ng881; Albert R, 2003, J THEOR BIOL, V223, P1, DOI 10.1016/S0022-5193(03)00035-3; Hartemink AJ, 2005, NAT BIOTECHNOL, V23, P554, DOI 10.1038/nbt0505-554; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Margolin AA, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S7; GARDNER E, 1987, EUROPHYS LETT, V4, P481, DOI 10.1209/0295-5075/4/4/016; Guelzim N, 2002, NAT GENET, V31, P60, DOI 10.1038/ng873; Shmulevich I, 2002, P IEEE, V90, P1778, DOI 10.1109/JPROC.2002.804686; Davidson EH, 2002, SCIENCE, V295, P1669, DOI 10.1126/science.1069883; Butte AJ, 2000, P NATL ACAD SCI USA, V97, P12182, DOI 10.1073/pnas.220392197; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; BAILLETBECHET M, 2008, PREPRINT; Banerjee O, 2006, ACM INT C P SER, V148, P89; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Bolouri H, 2002, DEV BIOL, V246, P2, DOI 10.1006/dbio.2002.0617; Braunstein A, 2006, PHYS REV LETT, V96, DOI 10.1103/PhysRevLett.96.030201; Braunstein A, 2008, Journal of Physics: Conference Series, V95, DOI 10.1088/1742-6596/95/1/012016; Buchler NE, 2003, P NATL ACAD SCI USA, V100, P5136, DOI 10.1073/pnas.0930314100; BUTTE AJ, 1999, FALL S AM MED INF AS; GARDNER E, 1988, J PHYS A-MATH GEN, V21, P257, DOI 10.1088/0305-4470/21/1/030; Hashimoto RF, 2004, BIOINFORMATICS, V20, P1241, DOI 10.1093/bioinformatics/bth074; Hertz J., 1991, INTRO THEORY NEURAL; JING Y, 2004, BIOINFORMATICS, V20, P3594; Kabashima Y, 2003, J PHYS A-MATH GEN, V36, P11111, DOI 10.1088/0305-4470/36/43/030; Kabashima Yoshiyuki, 2008, Journal of Physics: Conference Series, V95, DOI 10.1088/1742-6596/95/1/012001; Lee S.-I., 2007, ADV NEURAL INFORM PR; MURPHY K, 1999, TECHNICAL REPORT U C; RAVIKUMAR P, 2008, TECHNICAL REPORT DEP; SCHMIDT M, 2007, P 22 AAAI C ART INT; TRIA F, 2008, UNPUB; Uda S, 2005, J PHYS SOC JPN, V74, P2233, DOI [10.1143/JPSJ.74.2233, 10.1143/JPSJ.743.2233]; Van den Broeck C., 2001, STAT MECH LEARNING	35	14	14	0	3	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1742-5468			J STAT MECH-THEORY E	J. Stat. Mech.-Theory Exp.	DEC	2008									P12001	10.1088/1742-5468/2008/12/P12001		29	Mechanics; Physics, Mathematical	Mechanics; Physics	392ZF	WOS:000262340000001		
J	Wang, LF; Li, HZ; Huang, JHZ				Wang, Lifeng; Li, Hongzhe; Huang, Jianhua Z.			Variable Selection in Nonparametric Varying-Coefficient Models for Analysis of Repeated Measurements	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						Functional response; Longitudinal data; Nonparametric function estimation; Oracle property; Regularized estimation	LONGITUDINAL DATA-ANALYSIS; NONCONCAVE PENALIZED LIKELIHOOD; BASIS FUNCTION APPROXIMATIONS; LARGE COVARIANCE MATRICES; GENE-EXPRESSION DATA; TRANSCRIPTION FACTORS; COMPONENT SELECTION; ORACLE PROPERTIES; SPLINE ESTIMATION; LINEAR-MODELS	Nonparametric varying-coefficient models are commonly used for analyzing data measured repeatedly over time, including longitudinal and functional response data. Although many procedures have been developed for estimating varying coefficients. the problem of variable selection for such models has rot been addressed to date. la this article we present a regularized estimation procedure for variable selection that combines basis function approximations and the smoothly clipped absolute deviation penalty. The proposed I)procedure Sill)simultaneously selects significant variables with time-varying, effects and estimates the nonzero smooth coefficient functions. Under suitable conditions. we establish the theoretical properties of our procedure, including consistency in variable selection and the oracle property in estimation. Here the oracle property means that the asymptotic distribution of an estimated coefficient function is the same as that when it is known a priori which variables are in the model. The method is illustrated with simulations and tow real data examples, one for identifying risk factors in the study of AIDS and one using microarray time-course gene expression data to identify the transcription factors related to the yeast cell-cycle process.	[Li, Hongzhe] Univ Penn, Sch Med, Dept Biostat & Epidemiol, Philadelphia, PA 19104 USA; [Huang, Jianhua Z.] Texas A&M Univ, Dept Stat, College Stn, TX 77843 USA		lifwang@mail.med.upenn.edu; hongzhe@mail.med.upenn.edu; jianhua@stat.tamu.edu	Wang, Lifeng/E-7746-2010				LIANG KY, 1986, BIOMETRIKA, V73, P13, DOI 10.1093/biomet/73.1.13; Banerjee N, 2003, NUCLEIC ACIDS RES, V31, P7024, DOI 10.1093/nar/gkg894; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Huang JHZ, 2002, BIOMETRIKA, V89, P111, DOI 10.1093/biomet/89.1.111; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; Huang J, 2008, ANN STAT, V36, P587, DOI 10.1214/009053607000000875; Fan JQ, 2000, J ROY STAT SOC B, V62, P303, DOI 10.1111/1467-9868.00233; Hoover DR, 1998, BIOMETRIKA, V85, P809, DOI 10.1093/biomet/85.4.809; Lin Y, 2006, ANN STAT, V34, P2272, DOI 10.1214/009053606000000722; Tsai HK, 2005, P NATL ACAD SCI USA, V102, P13532, DOI 10.1073/pnas.0505874102; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; HASTIE T, 1993, J ROY STAT SOC B MET, V55, P757; Bickel PJ, 2006, TEST-SPAIN, V15, P271, DOI 10.1007/BF02607055; Chen G, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-r4; Chiang CT, 2001, J AM STAT ASSOC, V96, P605, DOI 10.1198/016214501753168280; Diggle P. J., 1994, ANAL LONGITUDINAL DA; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; Huang Hsiu-Wen, 2007, Taiwanese Journal of Agricultural Chemistry and Food Science, V45, P1; Huang JHZ, 2004, STAT SINICA, V14, P763; Huang JHZ, 2007, J COMPUT GRAPH STAT, V16, P189, DOI 10.1198/106186007X181452; Huang JHZ, 2003, ANN STAT, V31, P1600, DOI 10.1214/aos/1065705120; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; KASLOW RA, 1987, AM J EPIDEMIOL, V126, P310; Leng C., 2007, J NONPARAMETR STAT, V18, P417; Lin XH, 2000, J AM STAT ASSOC, V95, P520, DOI 10.2307/2669396; Luan YH, 2003, BIOINFORMATICS, V19, P474, DOI 10.1093/bioinformatics/btg014; PETROV V, 1975, SUMS INDEPENDENCE RA; Qu A, 2006, BIOMETRICS, V62, P379, DOI 10.1111/j.1541-0420.2005.00490.x; Rice JA, 2004, STAT SINICA, V14, P631; Rice JA, 2001, BIOMETRICS, V57, P253, DOI 10.1111/j.0006-341X.2001.00253.x; RICE JA, 1991, J ROY STAT SOC B MET, V53, P233; Schumaker L., 1981, SPLINE FUNCTIONS BAS; Simon I, 2001, CELL, V106, P697, DOI 10.1016/S0092-8674(01)00494-9; Spellman P. T., 1998, MOL BIOL CELL, V9; Stone C. J., 1982, ANN STAT, V10, P1348; Wang LF, 2007, BIOINFORMATICS, V23, P1486, DOI 10.1093/bioinformatics/btm125; Wu CO, 2000, STAT SINICA, V10, P433; Wu WB, 2003, BIOMETRIKA, V90, P831, DOI 10.1093/biomet/90.4.831; ZEGER SL, 1994, BIOMETRICS, V50, P689, DOI 10.2307/2532783; Zhang HH, 2006, STAT SINICA, V16, P659; Zhang HH, 2006, STAT SINICA, V16, P1021	47	89	94	3	12	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	DEC	2008	103	484					1556	1569		10.1198/016214508000000788		14	Statistics & Probability	Mathematics	402JB	WOS:000263008900023		
J	Doksum, K; Tang, S; Tsui, KW				Doksum, Kjell; Tang, Shijie; Tsui, Kam-Wah			Nonparametric Variable Selection: The EARTH Algorithm	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						Adaptive bandwidth selection; Co-plots; Efficacy; GUIDE; Importance scores; Local polynomial regression; MARS; Prediction; Random forest	GOODNESS-OF-FIT; REGRESSION TREES; TESTS; MODEL	We consider regression experiments involving a response variable Y and a large number of predictor variables X(1),...,X(d), many of which may be irrelevant for the prediction of Y and thus must be removed before Y can be predicted from the X's. We consider two procedures that select variables by using importance scores that measure the strength of the relationship between predictor variables and a response and keep those variables whose importance scores exceed a threshold. In the first of these procedures, scores are obtained by randomly drawn subregions (tubes) of the predictor space that constrain all but one predictor and in each subregion computing a signal-to-noise ratio (efficacy) based on a nonparametric univariate regression of Y on the unconstrained variable. The subregions are adapted to boost weak variables iteratively by searching (hunting) for the subregions in which the efficacy is maximized. The efficacy can be viewed as an approximation to a one-to-one function of the probability of identifying features. By using importance scores based on averages of maximized efficacies. We develop a variable selection algorithm called EARTH (efficacy adaptive regression tube hunting) based on examining the conditional expectation of the response given all but one of the predictor variables for a collection of randomly, adaptively, and iteratively selected regions. The second importance score method (RFVS) is based on using random forest importance values to select variable. Computer simulations show that EARTH and RFVS are successful variable selection methods compared with other procedures in nonparametric situations with a large number of irrelevant predictor variables, and that when each is combined with the model selection and prediction procedure MARS, the tree-based prediction procedure GUIDE, and the random forest method, the combinations lead to improved prediction accuracy for certain models with many irrelevant variables. We give conditions under which a version of the EARTH algorithm selects the correct model with probability lending to 1 as the sample size n tends to infinity even if d -> infinity as n -> infinity. We include the analysis of a real data set in which we show how a training set can be used to find a threshold for the EARTH importance scores.	[Doksum, Kjell; Tsui, Kam-Wah] Univ Wisconsin, Dept Stat, Madison, WI 53706 USA; [Tang, Shijie] Bristol Myers Squibb Co, Wallingford, CT 06492 USA	Doksum, K (reprint author), Univ Wisconsin, Dept Stat, Madison, WI 53706 USA.	doksum@stat.wisc.edu; shijie.tang@bms.com; kwtsui@star.wisc.edu			National Science Foundation [DMS-0505651, DMS-0604931]	This work was Supported in part by National Science Foundation grants DMS-0505651 and DMS-0604931. The authors are grateful to the reviewers for helpful comments and suggestions and particularly, the associate editor, who suggested including the random Forest variable selection procedure based on random forest importance scores. They also thank Herman Chernoff. Yingying Fan. Shaw-Hwa Lo, and Wei-Yin Loh for helpful comments.	AKAIKE H, 1970, ANN I STAT MATH, V22, P202; Ait-Sahalia Y, 2001, J ECONOMETRICS, V105, P363, DOI 10.1016/S0304-4076(01)00091-4; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Loh WY, 2002, STAT SINICA, V12, P361; Efron B, 2004, ANN STAT, V32, P407; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Bickel PJ, 2006, ANN STAT, V34, P721, DOI 10.1214/009053606000000137; BICKEL PJ, 1965, ANN MATH STAT, V36, P160, DOI 10.1214/aoms/1177700280; Breiman L, 2003, SETTING USING UNDERS; Breiman L., 1984, CLASSIFICATION REGRE; Chan KY, 2004, J COMPUT GRAPH STAT, V13, P826, DOI 10.1198/106186004X13064; Cleveland W. S., 1993, VISUALIZING DATA; Doksum K, 1995, ANN STAT, V23, P1443, DOI 10.1214/aos/1176324307; Doksum KA, 2006, FRONTIERS IN STATISTICS: DEDICATED TO PETER JOHN BICKEL IN HONOR OF HIS 65TH BIRTHDAY, P113, DOI 10.1142/9781860948886_0006; Fan JQ, 2001, ANN STAT, V29, P153, DOI 10.1214/aos/996986505; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Hall P, 2000, ANN STAT, V28, P20; Hall Peter, 1992, BOOTSTRAP EDGEWORTH; Hastie T., 2001, ELEMENTS STAT LEARNI; Ishwaran H, 2007, ELECTRON J STAT, V1, P519, DOI 10.1214/07-EJS039; Lehmann E., 1999, ELEMENTS LARGE SAMPL, V1st; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; MEINSHAUSEN N, 2009, ANN STAT IN PRESS; Pitman EJ, 1948, LECT NOTES NONPARAME; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; Zhang HH, 2004, J AM STAT ASSOC, V99, P659, DOI 10.1198/016214504000000593	28	4	4	2	9	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	DEC	2008	103	484					1609	1620		10.1198/016214508000000878		12	Statistics & Probability	Mathematics	402JB	WOS:000263008900027		
J	Kim, Y; Choi, H; Oh, HS				Kim, Yongdai; Choi, Hosik; Oh, Hee-Seok			Smoothly Clipped Absolute Deviation on High Dimensions	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						High dimension; Oracle property; Regression; Regularization; Smoothly clipped absolutely deviation penalty	NONCONCAVE PENALIZED LIKELIHOOD; VARIABLE SELECTION; ORACLE PROPERTIES; MODEL SELECTION; LASSO; REGULARIZATION; PERSISTENCE	The smoothly clipped absolute deviation (SCAD) estimator, proposed by Fan and Li, has many desirable properties, including continuity, sparsity, and unbiasedness. The SCAD estimator also has the (asymptotically) oracle property when the dimension of covariates is fixed or diverges more slowly than the sample size. In this article we study the SCAD estimator in high-dimensional settings where the dimension of covariates can be much larger than the sample size. First, we develop and efficient optimization algorithm that is fast and always converges to a local minimum. Second, we prove that the SCAD estimator still has the oracle property on high-dimensional problems. We perform numerical studies to compare the SCAD estimator with the LASSO and SIS-SCAD estimators in terms of prediction accuracy and variable selectivity when the true model is sparse. Through the simulation, we show that the variance estimator of Fan and Li still works well for some limited high-dimensional cases where the true nonzero coefficients are not too small and the sample size is moderately large. We apply the proposed algorithm to analyze a high-dimensional microarray data set.	[Kim, Yongdai; Oh, Hee-Seok] Seoul Natl Univ, Dept Stat, Seoul, South Korea; [Choi, Hosik] Hoseo Univ, Dept Informat Stat, Asan, Chungnam, South Korea	Kim, Y (reprint author), Seoul Natl Univ, Dept Stat, Seoul, South Korea.	ydkim0903@gmail.com; choi.hosik@gmail.com; heeseok@stats.snu.ac.kr			Korean Government [KRF-2005-070-C00021, KRF-2008-314-C00046]	This work was supported by the Korea Research Foundation grants funded by the Korean Government (KRF-2005-070-C00021) and (KRF-2008-314-C00046).	Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; An LTH, 1997, J GLOBAL OPTIM, V11, P253; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Scheetz TE, 2006, P NATL ACAD SCI USA, V103, P14429, DOI 10.1073/pnas.0602562103; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Fan JQ, 2008, J ROY STAT SOC B, V70, P849, DOI 10.1111/j.1467-9868.2008.00674.x; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Bertsekas D., 1999, NONLINEAR PROGRAMMIN; Breiman L, 1996, ANN STAT, V24, P2350; Collins P, 2000, NAT REV NEUROSCI, V1, P7, DOI 10.1038/35036178; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Friedman JH, 2004, GRADIENT DIRECTED RE; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; Greenshtein E, 2006, ANN STAT, V34, P2367, DOI 10.1214/009053606000000768; HUANG J, 2006, 374 U IOW DEP STAT A; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Shen XT, 2003, J AM STAT ASSOC, V98, P724, DOI 10.1198/016214503000000639; VANDEGEER SA, 2006, SEM STAT ETH ZUR; Wang LF, 2007, J AM STAT ASSOC, V102, P583, DOI 10.1198/016214506000001383	25	58	59	2	6	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	DEC	2008	103	484					1665	1673		10.1198/016214508000001066		9	Statistics & Probability	Mathematics	402JB	WOS:000263008900033		
J	Chow, SC; Tse, SK; Lin, M				Chow, Shein-Chung; Tse, Siu-Keung; Lin, Min			Statistical Methods in Translational Medicine	JOURNAL OF THE FORMOSAN MEDICAL ASSOCIATION			English	Article						bench-to-bedside; biomarker development; lost in translation; one-way translation; two-way translation	CROSS-VALIDATION; CLINICAL-TRIALS; SELECTION	This study focuses on strategies and statistical considerations for assessment of translation in language (e.g. translation of case report forms in multinational clinical trials), information (e.g. translation of basic discoveries to the clinic) and technology (e.g. translation of Chinese diagnostic techniques to well-established clinical study endpoints) in pharmaceutical/clinical research and development. However, most of our efforts will be directed to statistical considerations for translation in information. Translational medicine has been defined as bench-to-bedside research, where a basic laboratory discovery becomes applicable to the diagnosis, treatment or prevention of a specific disease, and is brought forth by either a physician-scientist who works at the interface between the research laboratory and patient care, or by a team of basic and clinical science investigators. Statistics plays an important role in translational medicine to ensure that the translational process is accurate and reliable with certain statistical assurance. Statistical inference for the applicability of an animal model to a human model is also discussed. Strategies for selection of clinical study endpoints (e.g. absolute changes, relative changes, or responder-defined, based on either absolute or relative change) are reviewed. [J Formos Med Assoc 2008;107(12 Suppl):S61-S73]	[Chow, Shein-Chung; Lin, Min] Duke Univ, Sch Med, Dept Biostat & Bioinformat, Durham, NC 27705 USA; [Tse, Siu-Keung] City Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China; [Chow, Shein-Chung] Natl Cheng Kung Univ, Tainan 70101, Taiwan	Chow, SC (reprint author), Duke Univ, Sch Med, Dept Biostat & Bioinformat, 2400 Pratt St,Room 0311 Terrace Level, Durham, NC 27705 USA.	sheinchung.chow@duke.edu					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; SHIBATA R, 1981, BIOMETRIKA, V68, P45; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Rutgeerts P, 2005, NEW ENGL J MED, V353, P2462, DOI 10.1056/NEJMoa050516; Chang M., 2007, ADAPTIVE DESIGN THEO; CHEN JJ, 2003, ENCY BIOPHARMACEUTIC, P599; Chow S. C., 2006, ADAPTIVE DESIGN METH; Chow Shein-Chung, 2002, J Biopharm Stat, V12, P385, DOI 10.1081/BIP-120014567; Chow SC, 2005, J BIOPHARM STAT, V15, P575, DOI 10.1081/BIP-200062277; CHOW SC, 2007, CURR ADV EV RES DEV; Chow SC, 2006, STAT MED, V25, P1101, DOI 10.1002/sim.2208; GUNST GF, 1980, REGRESSION ANAL ITS; Hsiao Chin-Fu, 2003, J Biopharm Stat, V13, P793, DOI 10.1081/BIP-120024210; Hsiao CF, 2007, J BIOPHARM STAT, V17, P109, DOI 10.1080/10543400601001501; Hsiao CF, 2005, J BIOPHARM STAT, V15, P75, DOI 10.1081/BIP-200040836; Hung HMJ, 2003, STAT MED, V22, P213, DOI 10.1002/sim.1315; HUNG HMJ, 2003 S STAT METH EV; Li Li, 2004, J Biopharm Stat, V14, P723, DOI 10.1081/BIP-200025679; Liu B, 2002, CELL RES, V12, P401, DOI 10.1038/sj.cr.7290142; Mankoff S. P., 2004, J TRANSL MED, V2, P14, DOI DOI 10.1186/1479-5876-2-14; PIZZO PA, 2006, DEANS NEWSLETTER; Shao J, 2007, J MULTIVARIATE ANAL, V98, P1529, DOI 10.1016/j.jmva.2004.12.004; Shao J, 2002, STAT MED, V21, P1727, DOI 10.1002/sim.1177; Shih WJ, 2001, CONTROL CLIN TRIALS, V22, P357, DOI 10.1016/S0197-2456(01)00138-6; TSE SK, 2007, CURR ADV EV RES DEV; 1997, FED REG, V83, P31790	29	2	3	0	4	ELSEVIER SINGAPORE PTE LTD	SINGAPORE	3 KILLINEY ROAD 08-01, WINSLAND HOUSE 1, SINGAPORE, 239519, SINGAPORE	0929-6646			J FORMOS MED ASSOC	J. Formos. Med. Assoc.	DEC	2008	107	12					S61	S73				13	Medicine, General & Internal	General & Internal Medicine	394EE	WOS:000262427700010		
J	Naik, P; Wedel, M; Bacon, L; Bodapati, A; Bradlow, E; Kamakura, W; Kreulen, J; Lenk, P; Madigan, DM; Montgomery, A				Naik, Prasad; Wedel, Michel; Bacon, Lynd; Bodapati, Anand; Bradlow, Eric; Kamakura, Wagner; Kreulen, Jeffrey; Lenk, Peter; Madigan, David M.; Montgomery, Alan			Challenges and opportunities in high-dimensional choice data analyses	MARKETING LETTERS			English	Article						Challenges; Opportunities; High-dimensional choice data analyses; Modern businesses; Four-way VAST matrix arrays	SLICED INVERSE REGRESSION; RECOMMENDATION SYSTEMS; POLYNOMIAL-EXPANSIONS; BINOMIAL-DISTRIBUTION; BAYESIAN-INFERENCE; REDUCTION; SIMULATION; SELECTION; MODEL	Modern businesses routinely capture data on millions of observations across subjects, brand SKUs, time periods, predictor variables, and store locations, thereby generating massive high-dimensional datasets. For example, Netflix has choice data on billions of movies selected, user ratings, and geodemographic characteristics. Similar datasets emerge in retailing with potential use of RFIDs, online auctions (e.g., eBay), social networking sites (e.g., mySpace), product reviews (e.g., ePinion), customer relationship marketing, internet commerce, and mobile marketing. We envision massive databases as four-way VAST matrix arrays of Variables x Alternatives x Subject x Time where at least one dimension is very large. Predictive choice modeling of such massive databases poses novel computational and modeling issues, and the negligence of academic research to address them will result in a disconnect from the marketing practice and an impoverishment of marketing theory. To address these issues, we discuss and identify the challenges and opportunities for both practicing and academic marketers. Thus, we offer an impetus for advancing research in this nascent area and fostering collaboration across scientific disciplines to improve the practice of marketing in information-rich environment.	[Wedel, Michel] Univ Maryland, College Pk, MD 20742 USA; [Naik, Prasad] Univ Calif Davis, Davis, CA 95616 USA; [Bacon, Lynd] Polimetrix Inc, Palo Alto, CA USA; [Bodapati, Anand] Univ Calif Los Angeles, Los Angeles, CA USA; [Bradlow, Eric] Univ Penn, Philadelphia, PA 19104 USA; [Kamakura, Wagner] Duke Univ, Durham, NC USA; [Kreulen, Jeffrey] IBM Almaden Res Ctr, San Jose, CA USA; [Lenk, Peter] Univ Michigan, Ann Arbor, MI 48109 USA; [Madigan, David M.] Columbia Univ, New York, NY USA; [Montgomery, Alan] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Wedel, M (reprint author), Univ Maryland, College Pk, MD 20742 USA.	mwedel@rhsmith.umd.edu					Montgomery AL, 2004, MARKET SCI, V23, P579, DOI 10.1287/mksc.1040.0073; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Ying YP, 2006, J MARKETING RES, V43, P355, DOI 10.1509/jmkr.43.3.355; Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; DuMouchel W, 1999, AM STAT, V53, P177, DOI 10.2307/2686093; Ansari A, 2000, J MARKETING RES, V37, P363, DOI 10.1509/jmkr.37.3.363.18779; BACON L, 2006, INTERACTIVE INNOVATI; BAKER S, 2007, BUSINESS WEEK   1213; Balakrishnan S, 2006, BAYESIAN ANAL, V1, P345; BALAKRISHNAN S, 2007, LAPS LASSO PARTITION; Balasubramanian S, 1998, STAT NEERL, V52, P303, DOI 10.1111/1467-9574.00086; BENZECRI JP, 2005, CORRES ANAL DATA COD; Bodapati AV, 2008, J MARKETING RES, V45, P77, DOI 10.1509/jmkr.45.1.77; Bradlow ET, 2002, J COMPUT GRAPH STAT, V11, P189, DOI 10.1198/106186002317375677; Breese J.S., 1998, EMPIRICAL ANAL PREDI; Brockwell AE, 2005, J COMPUT GRAPH STAT, V14, P436, DOI 10.1198/106186005X47453; Brockwell AE, 2006, J COMPUT GRAPH STAT, V15, P246, DOI 10.1198/106186006X100579; Brown S, 1996, IEEE DES TEST COMPUT, V13, P42, DOI 10.1109/54.500200; BRYNJOLFSON E, 2007, GREAT EQUALIZER EMPI; Bucklin Randolph E., 2007, ESTIMATING DYNAMIC E; CHUNG T, 2007, MARKETING S IN PRESS; COOK RD, 1991, J AM STAT ASSOC, V86, P328, DOI 10.2307/2290564; DING M, 2007, BARTER MARKETS; DU R, 2007, EFFICIENT IS YOUR CA; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; Everson PJ, 2002, J COMPUT GRAPH STAT, V11, P202, DOI 10.1198/106186002317375686; FOUTZ NZ, 2007, FORECASTING NEW PROD; Handcock MS, 2007, J ROY STAT SOC A STA, V170, P301, DOI 10.1111/j.1467-985X.2007.00471.x; Hauben Manfred, 2005, Expert Opin Drug Saf, V4, P929, DOI 10.1517/14740338.4.5.929; HUANG Z, 2006, SAMPLING BAYESIAN CO; Jordan MI, 1998, NATO ADV SCI I D-BEH, V89, P105; Kamakura WA, 2007, J RETAILING, V83, P159, DOI 10.1016/j.jretai.2006.02.006; KREULEN J, 2005, INTERACTIVE METHODS, P495; KREULEN J, 2003, J MANAGEMENT INFORM, V19, P191; KREULEN J, 2002, IBM SYST J, V41, P2002; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Li LX, 2007, BIOMETRIKA, V94, P615, DOI 10.1093/biomet/asm043; Miller C, 2006, FRONT ECOL ENVIRON, V4, P173; Montgomery AL, 1997, MARKET SCI, V16, P315, DOI 10.1287/mksc.16.4.315; Naik PA, 2005, J AM STAT ASSOC, V100, P204, DOI 10.1198/016214504000000773; NAIK PA, 2008, J BUSINESS IN PRESS; Naik PA, 2004, COMPUT STAT DATA AN, V47, P775, DOI 10.1016/j.csda.2003.11.023; Naik PA, 2000, J MARKETING RES, V37, P88, DOI 10.1509/jmkr.37.1.88.18715; PRELEC D, 2001, READINGS PACKET INFO; RIDGEWAY G, 2002, J KNOWLEDGE DISCOVER, V7, P301; Rossi PE, 1996, MARKET SCI, V15, P321, DOI 10.1287/mksc.15.4.321; Silverman B.W., 1986, DENSITY ESTIMATION; Simonoff J. S., 1996, SMOOTHING METHODS ST; Spangler S., 2007, MINING TALK UNLOCKIN; Toubia O, 2006, MARKET SCI, V25, P411, DOI 10.1287/mksc.1050.0166; TRUSOV M, 2007, DETERMINING INFLUENT; Wainwright M. J., 2003, 649 UC BERK DEP STAT; Wasserman S., 1994, SOCIAL NETWORK ANAL; Wedel M, 2004, J MARKETING RES, V41, P448, DOI 10.1509/jmkr.41.4.448.47017; Wedel M, 2001, PSYCHOMETRIKA, V66, P515, DOI 10.1007/BF02296193; Wedel M., 2000, MARKET SEGMENTATION	58	6	6	0	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0923-0645			MARKET LETT	Mark. Lett.	DEC	2008	19	3-4					201	213		10.1007/s11002-008-9036-3		13	Business	Business & Economics	363EJ	WOS:000260250300002		
J	Ma, L; Wahab, A; Ng, GS; Erdogan, S				Ma, L.; Wahab, A.; Ng, G. S.; Erdogan, S.			An experimental study of the extended NRBF regression model and its enhancement for classification problem	NEUROCOMPUTING			English	Article						Radial basis function; Expectation maximization; Gaussian mixture model; Regression; Classification	BASIS FUNCTION NETWORKS; NETS; RECOGNITION; SYSTEM	As an extension of the traditional normalized radial basis function (NRBF) model, the extended normalized RBF (ENRBF) model was proposed by Xu [RBF nets, mixture experts, and Bayesian Ying-Yang learning, Neurocomputing 19 (1998) 223-257]. In this paper, we perform a supplementary study on ENRBF with several properly designed experiments and some further theoretical discussions. It is shown that ENRBF is able to efficiently improve the learning accuracies under some circumstances. Moreover, since the ENRBF model is initially proposed for the regression and function approximation problems, a further step is taken in this work to modify the ENRBF model to deal with the classification problems. Both the original ENRBF model and the new proposed ENRBF classifier (ENRBFC) can be viewed as the special cases of the mixture-of-experts (ME) model that is discussed in Xu et al. [An alternative model for mixtures of experts, in: Advances in Neural Information Processing Systems, MIT Press, Cambridge, MA, 1995]. Experimental results show the potentials of ENRBFC compared to some other related classifiers. (c) 2008 Elsevier B.V. All rights reserved.	[Ma, L.; Wahab, A.; Ng, G. S.; Erdogan, S.] Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore	Ng, GS (reprint author), Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Blk N4,2A-36,Nanyang Ave, Singapore 639798, Singapore.	gsng@ieee.org					Albrecht S, 2000, NEURAL NETWORKS, V13, P1075, DOI 10.1016/S0893-6080(00)00060-5; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Bishop C., 2006, PATTERN RECOGNITION; Bishop C., 1997, NEURAL NETWORKS PATT; Bugmann G, 1998, NEUROCOMPUTING, V20, P97, DOI 10.1016/S0925-2312(98)00027-7; Cherkassky V. S., 1998, LEARNING DATA CONCEP; Hastie T., 2001, ELEMENTS STAT LEARNI; Kwok HF, 2003, ARTIF INTELL MED, V29, P185, DOI 10.1016/S0933-3657(02)00074-X; Looney CG, 2002, NEUROCOMPUTING, V48, P489, DOI 10.1016/S0925-2312(01)00613-0; Marcondes J, 2003, PACKAG TECHNOL SCI, V16, P69, DOI 10.1002/pts.614; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Nabney Ian, 2002, NETLAB ALGORITHMS PA; Ng GS, 1998, ARTIF INTELL ENG, V12, P189; Ng GS, 1998, PATTERN RECOGN LETT, V19, P227, DOI 10.1016/S0167-8655(98)00005-1; Ng GS, 1998, INT J PATTERN RECOGN, V12, P645, DOI 10.1142/S0218001498000373; NG GS, 1995, PATTERN RECOGN LETT, V16, P1111, DOI 10.1016/0167-8655(95)00064-N; Powell M. J. D., 1987, ALGORITHMS APPROXIMA, P143; JANG JSR, 1993, IEEE T NEURAL NETWOR, V4, P156, DOI 10.1109/72.182710; Staiano A, 2006, NEUROCOMPUTING, V69, P1570, DOI 10.1016/j.neucom.2005.06.014; Wahab A, 2005, NEUROCOMPUTING, V68, P13, DOI 10.1016/j.neucom.2005.02.004; Wang CS, 1998, MED ENG PHYS, V20, P534, DOI 10.1016/S1350-4533(98)00048-4; Wang D, 2004, NEURAL PROCESS LETT, V20, P39, DOI 10.1023/B:NEPL.0000039425.58002.36; XU L, 1994, NEURAL NETWORKS, V7, P609, DOI 10.1016/0893-6080(94)90040-X; Xu L, 1998, NEUROCOMPUTING, V19, P223, DOI 10.1016/S0925-2312(97)00091-X; XU L, 1995, ALTERNATIVE MODEL MI; ONLINE TIME SERIES D; WISCONSIN DIAGNOSTIC	27	4	4	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	DEC	2008	72	1-3					458	470		10.1016/j.neucom.2007.12.011		13	Computer Science, Artificial Intelligence	Computer Science	382ZK	WOS:000261643700051		
J	Takane, Y; Jung, S				Takane, Yoshio; Jung, Sunho			Regularized Partial and/or Constrained Redundancy Analysis	PSYCHOMETRIKA			English	Article						reduced rank approximations; covariates; linear constraints; least squares estimation; ridge least squares estimation; generalized singular value decomposition (GSVD); G-fold cross validation; bootstrap method	CANONICAL CORRELATION-ANALYSIS; WORK-FAMILY CONFLICT; LINEAR-REGRESSION	Methods of incorporating a ridge type of regularization into partial redundancy analysis (PRA), constrained redundancy analysis (CRA), and partial and constrained redundancy analysis (PCRA) were discussed. The usefulness of ridge estimation in reducing mean square error (MSE) has been recognized in multiple regression analysis for some time, especially when predictor variables are nearly collinear, and the ordinary least squares estimator is poorly determined. The ridge estimation method was extended to PRA, CRA, and PCRA, where the reduced rank ridge estimates of regression coefficients were obtained by minimizing the ridge least squares criterion. It was shown that in all cases they could be obtained in closed form for a fixed value of ridge parameter. An optimal value of the ridge parameter is found by G-fold cross validation. Illustrative examples were given to demonstrate the usefulness of the method in practical data analysis situations.	[Takane, Yoshio] McGill Univ, Dept Psychol, Montreal, PQ H3A 1B1, Canada	Takane, Y (reprint author), McGill Univ, Dept Psychol, 1205 Dr Penfield Ave, Montreal, PQ H3A 1B1, Canada.	takane@psych.mcgill.ca			Natural Sciences and Engineering Research Council of Canada [10630]	We thank Jim Ramsay for his insightful comments on an earlier draft of this paper. The work reported in this paper is supported by Grants 10630 from the Natural Sciences and Engineering Research Council of Canada to the first author.	ANDERSON TW, 1951, ANN MATH STAT, V22, P327, DOI 10.1214/aoms/1177729580; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Anderson SE, 2002, J MANAGE, V28, P787, DOI 10.1016/S0149-2063(02)00190-3; Breiman L, 1997, J ROY STAT SOC B MET, V59, P3, DOI 10.1111/1467-9868.00054; CHINCHILLI VM, 1985, COMMUN STAT-THEOR M, V14, P3075, DOI 10.1080/03610928508829096; DAMBRA L, 1989, MULTIWAY DATA ANAL; DUXBURY L, 1994, J FAM ISSUES, V15, P449, DOI 10.1177/019251394015003006; Efron B, 1993, INTRO BOOTSTRAP; Gross J., 2003, LINEAR REGRESSION; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; LAMBERT ZV, 1988, PSYCHOL BULL, V104, P282, DOI 10.1037//0033-2909.104.2.282; Legendre P., 1998, NUMERICAL ECOLOGY; Reinsel G., 1998, MULTIVARIATE REDUCED; Sparrow P. R., 1996, HUMAN RESOURCE MANAG, V6, P75, DOI 10.1111/j.1748-8583.1996.tb00419.x; Takane Y, 2007, COMPUT STAT DATA AN, V52, P394, DOI 10.1016/j.csda.2007.02.014; Takane Y, 2002, MULTIVAR BEHAV RES, V37, P163, DOI 10.1207/S15327906MBR3702_01; TAKANE Y, 1991, PSYCHOMETRIKA, V56, P97, DOI 10.1007/BF02294589; Takane Y, 2008, LINEAR ALGEBRA APPL, V428, P1778, DOI 10.1016/j.laa.2007.10.017; Takane Yoshio, 2006, MULTIPLE CORRES ANAL, P259; ten Berge JMF, 1993, LEAST SQUARES OPTIMI; Ter Braak CJF, 1998, CANOCO REFERENCE MAN; VANDENWOLLENBERG AL, 1977, PSYCHOMETRIKA, V42, P207; VELU RP, 1991, APPL STAT-J ROY ST C, V40, P159, DOI 10.2307/2347914; Yuan M, 2007, J ROY STAT SOC B, V69, P329, DOI 10.1111/j.1467-9868.2007.00591.x	24	2	2	2	2	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0033-3123	1860-0980		PSYCHOMETRIKA	Psychometrika	DEC	2008	73	4					671	690		10.1007/s11336-008-9067-y		20	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Psychology, Mathematical	Mathematics; Mathematical Methods In Social Sciences; Psychology	387NP	WOS:000261959200008		
J	Camarda, CG; Eilers, PHC; Gampe, J				Camarda, Carlo G.; Eilers, Paul H. C.; Gampe, Jufta			Modelling general patterns of digit preference	STATISTICAL MODELLING			English	Article						composite link model; digit preference; L(1) penalty; penalized likelihood; smoothing	BLOOD-PRESSURE-MEASUREMENTS; AGE; ERROR; WEIGHT	In many applications data can be interpreted as indirect observations of a latent distribution. A typical example is the phenomenon known as digit preference, i.e. the tendency to round outcomes to pleasing digits. The composite link model (CLM) is a useful framework to uncover such latent distributions. Moreover, when applied to data showing digit preferences, this approach allows estimation of the proportions of counts that were transferred to neighbouring digits. As the estimating equations generally are singular or severely ill-conditioned, we impose smoothness assumptions on the latent distribution and penalize the likelihood function. To estimate the misreported proportions, we use a weighted least-squares regression with an added L(1) penalty. The optimal smoothing parameters are found by minimizing the Akaike's information Criterion (AIC). The approach is verified by a simulation study and several applications are presented.	[Camarda, Carlo G.; Gampe, Jufta] Max Planck Inst Demog Res, D-18057 Rostock, Germany; [Eilers, Paul H. C.] Univ Utrecht, Fac Social & Behav Sci, NL-3508 TC Utrecht, Netherlands; [Eilers, Paul H. C.] Leiden Univ, Data Theory Grp, NL-2300 RA Leiden, Netherlands	Camarda, CG (reprint author), Max Planck Inst Demog Res, Konrad Zuse Str 1, D-18057 Rostock, Germany.	camarda@demogr.mpg.de					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; COALE AJ, 1991, DEMOGRAPHY, V28, P293, DOI 10.2307/2061281; BENNETT S, 1994, J CLIN EPIDEMIOL, V47, P293, DOI 10.1016/0895-4356(94)90010-8; BHAT PNM, 1990, DEMOGRAPHY, V27, P149, DOI 10.2307/2061559; CANNER PL, 1991, AM J EPIDEMIOL, V134, P379; Crawford SL, 2002, AM J EPIDEMIOL, V156, P676, DOI 10.1093/aje/kwf059; DASGUPTA P, 1975, DEMOGRAPHY, V12, P303, DOI 10.2307/2060767; Edouard L, 1997, PUBLIC HEALTH, V111, P77; Eilers PHC, 2007, STAT MODEL, V7, P239, DOI 10.1177/1471082X0700700302; Eilers RHC, 2004, INT J TUBERC LUNG D, V8, P232; HEITJAN DF, 1990, J AM STAT ASSOC, V85, P304, DOI 10.2307/2289765; HESSEL PA, 1986, INT J EPIDEMIOL, V15, P122, DOI 10.1093/ije/15.1.122; *I NAC EST, 1941, AN DEM AN 1940; McCullagh P, 1989, MONOGRAPHS STAT APPL, V37; Myers R., 1940, T ACTUARIAL SOC AM, V41, P395; *NHANES, 1976, NAT HLTH NUTR EX SUR; PICKERING RM, 1992, STAT MED, V11, P1225, DOI 10.1002/sim.4780110908; R Development Core Team, 2007, R LANG ENV STAT COMP; RIDOUT MS, 1991, BIOMETRICS, V47, P1423, DOI 10.2307/2532396; ROWLAND ML, 1990, AM J CLIN NUTR, V52, P1125; SCHLOSSM.EJ, 1973, J AM STAT ASSOC, V68, P857, DOI 10.2307/2284512; Siegel JS, 2004, METHODS MAT DEMOGRAP, V2nd; Thompson R., 1981, Applied Statistics, V30, DOI 10.2307/2346381; WEN SW, 1993, J CLIN EPIDEMIOL, V46, P1187, DOI 10.1016/0895-4356(93)90118-K	26	7	7	1	4	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1471-082X			STAT MODEL	Stat. Model.	DEC	2008	8	4					385	401		10.1177/1471082X0800800404		17	Statistics & Probability	Mathematics	428DT	WOS:000264828900004		
J	Srivastava, S; Zhang, LX; Jin, R; Chan, C				Srivastava, Shireesh; Zhang, Linxia; Jin, Rong; Chan, Christina			A Novel Method Incorporating Gene Ontology Information for Unsupervised Clustering and Feature Selection	PLOS ONE			English	Article								Background: Among the primary goals of microarray analysis is the identification of genes that could distinguish between different phenotypes (feature selection). Previous studies indicate that incorporating prior information of the genes' function could help identify physiologically relevant features. However, current methods that incorporate prior functional information do not provide a relative estimate of the effect of different genes on the biological processes of interest. Results: Here, we present a method that integrates gene ontology (GO) information and expression data using Bayesian regression mixture models to perform unsupervised clustering of the samples and identify physiologically relevant discriminating features. As a model application, the method was applied to identify the genes that play a role in the cytotoxic responses of human hepatoblastoma cell line (HepG2) to saturated fatty acid (SFA) and tumor necrosis factor (TNF)-alpha, as compared to the non-toxic response to the unsaturated FFAs (UFA) and TNF-alpha. Incorporation of prior knowledge led to a better discrimination of the toxic phenotypes from the others. The model identified roles of lysosomal ATPases and adenylate cyclase (AC9) in the toxicity of palmitate. To validate the role of AC in palmitate-treated cells, we measured the intracellular levels of cyclic AMP (cAMP). The cAMP levels were found to be significantly reduced by palmitate treatment and not by the other FFAs, in accordance with the model selection of AC9. Conclusions: A framework is presented that incorporates prior ontology information, which helped to (a) perform unsupervised clustering of the phenotypes, and (b) identify the genes relevant to each cluster of phenotypes. We demonstrate the proposed framework by applying it to identify physiologically-relevant feature genes that conferred differential toxicity to saturated vs. unsaturated FFAs. The framework can be applied to other problems to efficiently integrate ontology information and expression data in order to identify feature genes.	[Srivastava, Shireesh; Zhang, Linxia; Chan, Christina] Michigan State Univ, Dept Chem Engn & Mat Sci, E Lansing, MI 48824 USA; [Jin, Rong; Chan, Christina] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Chan, Christina] Michigan State Univ, Dept Biochem & Mol Biol, E Lansing, MI 48824 USA	Srivastava, S (reprint author), NIAAA, Lab Metab Control, Rockville, MD 20852 USA.	krischan@egr.msu.edu			National Science Foundation [BES 0425821, IIS-0643494]; National Institute of Health [1R01GM079688-01, 1R21CA126136-01]; Environmental Protection Agency [RD83184701]; MSU Foundation; Center for Systems Biology	This research was supported by the National Science Foundation (BES 0425821 and IIS-0643494), the National Institute of Health (1R01GM079688-01 and 1R21CA126136-01), the Environmental Protection Agency (RD83184701), and the MSU Foundation and the Center for Systems Biology. The funders had no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Tan YX, 2004, COMPUT BIOL CHEM, V28, P235, DOI 10.1016/j.compbiolchem.2004.05.002; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Troyanskaya OG, 2002, BIOINFORMATICS, V18, P1454, DOI 10.1093/bioinformatics/18.11.1454; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; [Anonymous], 2008, ADV NEURAL INFORM PR; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Le Phillip P, 2004, In Silico Biol, V4, P335; Beisvag V, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-470; Chan C, 2003, BIOTECHNOL PROGR, V19, P580, DOI 10.1021/bp025660h; Chen T, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S2-S20; Cho JH, 2004, FEBS LETT, V571, P93, DOI 10.1016/j.febslet.2004.05.087; Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004; Distelhorst CW, 2003, BIOCHEM SOC T, V31, P958; Draghici S, 2003, NUCLEIC ACIDS RES, V31, P3775, DOI 10.1093/nar/gkg624; Feldstein AE, 2006, AM J PHYSIOL-GASTR L, V290, pG1339, DOI 10.1152/ajpgi.00509.2005; Guo L, 2006, MOL DIVERS, V10, P349, DOI 10.1007/s11030-006-9038-0; Hirota N, 2006, LIFE SCI, V79, P1312, DOI 10.1016/j.lfs.2006.03.048; Hwang D, 2003, ORAL ONCOL, V39, P259, DOI 10.1016/S1368-8375(02)00108-2; LI T, 2007, P 24 ANN INT C MACH; Liu JJ, 2005, BIOINFORMATICS, V21, P2691, DOI 10.1093/bioinformatics/bti419; MORRISON JL, BMC BIOINFORMATICS, V6, P233; Pan W, 2005, STAT APPL GENET MO B, V4; Robbins MJ, 2002, MOL BRAIN RES, V106, P136, DOI 10.1016/S0169-328X(02)00420-5; Roth V, 2004, IEEE T NEURAL NETWOR, V15, P16, DOI 10.1109/TNN.2003.809398; Saukkonen T, 2006, DIABETES, V55, P2365, DOI 10.2337/db05-1646; Soldatenkov VA, 1998, CELL DEATH DIFFER, V5, P307, DOI 10.1038/sj.cdd.4400345; Wang ZY, 2006, BIOINFORMATICS, V22, P755, DOI 10.1093/bioinformatics/btk036; Ye Jieping, 2008, ADV NEURAL INFORM PR, V20, P1649	29	5	5	1	3	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1932-6203			PLOS ONE	PLoS One	DEC 4	2008	3	12							e3860	10.1371/journal.pone.0003860		8	Multidisciplinary Sciences	Science & Technology - Other Topics	436YO	WOS:000265452200010	19052637	
J	Loris, I				Loris, Ignace			L1 Packv2: A Mathematica package for minimizing an l(1)-penalized functional	COMPUTER PHYSICS COMMUNICATIONS			English	Article						Inverse problem; Sparsity; 1-norm; Minimization; Compressed sensing	INVERSE PROBLEMS; REGRESSION; ALGORITHM; SELECTION	L1 Packv2 is a Mathematica package that contains a number of algorithms that call be used for the minimization of all l(1)-penalized least squares functional. The algorithms call handle a mix of penalized and unpenalized variables. Several instructive examples are given. Also, all implementation that yields all exact Output whenever exact data are given is provided. Program summary Catalogue identifier: AEBP_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEBP_v1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 6018 No. of bytes in distributed program, including test data, etc.: 101297 Distribution format: tar.gz Programming language: Mathemtica Computer: Any Computer running Mathematica Operating system: Any OS running Mathematica Classification: : 4.9 Nature of problem: Minimization of L1-penalized least squares functionals Solution method: Several algorithms are provided (iterative and non-iterative) Restrictions: Real matrices and vectors only Unusual features: Also handles exact arithmetic and unpenalized variables Running time: Seconds to Minutes (c) 2008 Elsevier B.V. All rights reserved.	Vrije Univ Brussels, Dept Math, B-1050 Brussels, Belgium	Loris, I (reprint author), Vrije Univ Brussels, Dept Math, Pl Laan 2, B-1050 Brussels, Belgium.	igloris@vub.ac.be			 [VUB-GOA 62]	Most of the work presented in this article was done while the author was a 'Francqui Foundation intercommunity postdoctoral researcher' at the Universite Libre de Bruxelles. Part of this work was done as a post-doctoral research fellow for the F.W.O-Vlaanderen (Belgium) at the Vrije Universiteit Brussel. Financial help was also provided by VUB-GOA 62 grant. Stimulating discussions with 1. Daubechies and C. De Mol are gratefully acknowledged. The author thanks the referees for their suggestions which greatly helped improve the manuscript.	Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Efron B, 2004, ANN STAT, V32, P407; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Chaux C, 2007, INVERSE PROBL, V23, P1495, DOI 10.1088/0266-5611/23/4/008; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; Bertero M., 1998, INTRO INVERSE PROBLE; BERTERO M, 1989, ADV ELECTRON EL PHYS, V75, P1; BRODIE J, SPARSE STABLE MARKOW; CANDES E, 2005, E1 MAGIC RECOVERY SP; DAUBECHIES I, J FOURIER A IN PRESS; DEFRISE M, 1987, INVERSE PROBLEMS INT, P261; Donoho D. L., 2007, SPARSELAB; Engl H. W., 1996, MATH ITS APPL, V375; KOH K, 2007, METHOD LARGE SCALE I; Loris I, 2007, GEOPHYS J INT, V170, P359, DOI 10.1111/j.1365-246X.2007.03409.x; LORIS I, J PHYS C SER UNPUB; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; Sjostrand K., 2005, MATLAB IMPLEMENTATIO; Wolfram Research Inc., 2005, MATH VERS 5 2	24	6	6	0	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0010-4655			COMPUT PHYS COMMUN	Comput. Phys. Commun.	DEC 15	2008	179	12					895	902		10.1016/j.cpc.2008.07.010		8	Computer Science, Interdisciplinary Applications; Physics, Mathematical	Computer Science; Physics	380TV	WOS:000261489000006		
B	Fathi, B; Behjat, L; Rakai, LM			ACM	Fathi, Bahareh; Behjat, Laleh; Rakai, Logan M.			A Pre-Placement Net Length Estimation Technique for Mixed-Size Circuits	11TH INTERNATIONAL WORKSHOP ON SYSTEM-LEVEL INTERCONNECT PREDICTION (SLIP 09)			English	Proceedings Paper	11th International Workshop on System-Level Interconnect Prediction (SLIP 09)	JUL 26, 2009	San Francisco, CA	ACM		Wire Length Estimation; Placement; Hypergraph Clustering; Physical Design	LOGIC	An accurate model for pre-placement wire length estimation can be a useful tool during the physical design of integrated circuits. In this paper, an a priori wire length estimation technique for mixed-size circuits is proposed. The proposed technique is capable of predicting the wire lengths for individual nets, and uses both relevant factors used in previous research as well as new factors that can affect the net lengths in mixed-size designs. The proposed model's main characteristics include reporting individual net lengths, suitability for mixed-size designs, and the power to predict preplacement net lengths before and after clustering. The net lengths estimated by this model are shown to be an average of 10% more correlated to after placement lengths compared to the most elaborated model of literature. The model can be used for a priori individual net length estimation and predicting the possible effects of clustering on lengths of individual nets during the placement stage.	[Fathi, Bahareh; Behjat, Laleh; Rakai, Logan M.] Univ Calgary, Calgary, AB, Canada	Fathi, B (reprint author), Univ Calgary, Calgary, AB, Canada.	bfathi@ucalgary.ca; laleh@ucalgary.ca; lmrakai@ucalgary.ca					Adya S, 2004, P INT C COMP AID DES, P550; Alpert C., 2005, P ISPD, P200, DOI 10.1145/1055137.1055179; Alpert CJ, 1998, IEEE T COMPUT AID D, V17, P655, DOI 10.1109/43.712098; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Bodapati S, 2001, IEEE T VLSI SYST, V9, P943, DOI 10.1109/92.974908; Caldwell A. E., 2000, Proceedings ASP-DAC 2000. Asia and South Pacific Design Automation Conference 2000 with EDA TechnoFair 2000. (Cat. No.00EX389), DOI 10.1109/ASPDAC.2000.835182; Caldwell AE, 1999, IEEE T COMPUT AID D, V18, P1265, DOI 10.1109/43.784119; Caldwell AE, 2000, P ACM IEEE DES AUT C, P477, DOI 10.1145/337292.337549; Chan T. R., 2006, Proceedings of ISPD'06. 2006 International Symposium on Physical Design, DOI 10.1145/1123008.1123055; Christie P, 2000, IEEE T VLSI SYST, V8, P639, DOI 10.1109/92.902258; Cong J, 2004, IEEE T COMPUT AID D, V23, P346, DOI [10.1109/TCAD.2004.823353, 10.1109/TCAD.20034.823353]; Donath W. E., 1979, IEEE Transactions on Circuits and Systems, VCAS-26, DOI 10.1109/TCS.1979.1084635; DONATH WE, 1981, IBM J RES DEV, V25, P152; FEUER M, 1982, IEEE T COMPUTERS C, V31; Hamada T, 1996, IEEE T COMPUT AID D, V15, P912, DOI 10.1109/43.511571; Hamada T., 1992, Proceedings. 29th ACM/IEEE Design Automation Conference (Cat. No.92CH3144-3), DOI 10.1109/DAC.1992.227861; Heineken HT, 1996, PROCEEDINGS OF THE IEEE 1996 CUSTOM INTEGRATED CIRCUITS CONFERENCE, P167, DOI 10.1109/CICC.1996.510535; HU B, 2003, P DES AUT C, P800; HU B, 2003, P ISPD, P67; Kahng A., 2005, P ACM IEEE INT C COM, P173; KAHNG AB, 1992, IEEE T COMPUT AID D, V11, P893, DOI 10.1109/43.144853; Karypis G, 1999, IEEE T VLSI SYST, V7, P69, DOI 10.1109/92.748202; LANDMAN BS, 1971, IEEE T COMPUT, VC 20, P1469, DOI 10.1109/T-C.1971.223159; LI J, 2006, P ISPD, V26, P200; LIU Q, 2004, P DES AUT C, P582, DOI 10.1145/996566.996726; Liu Q., 2003, P SLIP, P99; Nam G. - J., 2005, P ISPD, P216, DOI 10.1145/1055137.1055182; Nam G.-J., 2006, P ISPD, P167, DOI 10.1145/1123008.1123042; Pedram M, 1989, P IEEE INT C COMP AI, P390; TAGHAVI T, 2005, INT S PHYS DES, P245; Taghavi T, 2007, PROCEEDINGS OF SLIP '07: 2007 INTERNATIONAL WORKSHOP ON SYSTEM LEVEL INTERCONNECT PREDICTION, P15, DOI 10.1145/1231956.1231961; VISWANATHAN N, 2007, P ASPDAC; Yan T, 2007, ASIA S PACIF DES AUT, P268; YAN T, 2006, P DAC ICCAD, P172, DOI 10.1145/1233501.1233536	34	1	1	0	2	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-576-5				2009							45	52				8	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	BRB30	WOS:000282306200007		
J	Tarnopolskaya, T; Tabak, J; de Hoog, FR		Anderssen, RS; Braddock, RD; Newham, LTH		Tarnopolskaya, T.; Tabak, J.; de Hoog, F. R.			L-curve for hedging instrument selection in CVaR-minimizing portfolio hedging	18TH WORLD IMACS CONGRESS AND MODSIM09 INTERNATIONAL CONGRESS ON MODELLING AND SIMULATION: INTERFACING MODELLING AND SIMULATION WITH MATHEMATICAL AND COMPUTATIONAL SCIENCES			English	Proceedings Paper	Combined IMACS World Congress/Modelling and Simulation Society-of-Australia-and-New-Zealand (MSSANZ)/18th Biennial Conference on Modelling and Simulation	JUL 13-17, 2009	Cairns, AUSTRALIA	IMACS, MSSANZ, CSIRO, Australian Math Sci Inst, Griffith Univ, eWater Cooperat Res Ctr, Dept Sustainabil & Environm, HEMA Consulting, Hellenic European Res Comp Math & Applicat, Int Council Ind Appl Math, Int Soc Grid Generat, Int Soc Photogrammetry & Remote Sensing, Japan Soc Simulat Technol, Pacific Rim Math Assoc, Rutgers, State Univ New Jersey		Conditional value-at-risk (CVaR); optimal hedging; proportional transaction costs; one-period portfolio selection; L-curve; generalized L1-norm penalty	POSED PROBLEMS; RISK	Derivative contracts are popular instruments of risk management in financial and commodity markets. An optimal selection of a small subset from the large set of available hedging derivative instruments is an important practical problem. In this paper, the L-curve phase-plot strategy of regularization is generalized to this situation to provide a quick exploratory tool for optimal selection of hedging instruments. In this paper, the optimal hedging problem is formulated as a one-period static portfolio selection model. The conditional value-at-risk (CVaR) of the portfolio loss distribution is adopted as a measure of hedging risk. CVaR is rapidly gaining popularity as a risk measure in portfolio analysis due to its coherence property. It is is closely related to VaR (Value-at-Risk), which is a current international industry benchmark in risk analysis. CVaR, however, is free of some limitations of VaR, which lacks sub-additivity and convexity and therefore contradicts the diversification principle and poses difficulties for optimization. We consider a problem of reducing the risk of a target portfolio, consisting of derivative instruments on the underlying asset, by purchasing or selling the underlying asset and the derivative instruments on the same underlying asset. Such problem is typically ill-posed. The objective function considered in this paper is the CVaR of portfolio loss distribution with a generalized L1-norm penalty on portfolio decision vector in the form of proportional transaction costs. The advantage of such formulation is twofold: (1) it provides a required regularization of the problem; (2) the L1-norm penalty is known for causing some of the vector components to become exactly zero when the regularization parameter increases, thus performing automatic subset selection. In this paper, we introduce a phase plot (or a parametric function) that relates the generalized L1-norm of the portfolio decision vector and the CVaR of the portfolio loss distribution, with the regularization parameter as an independent parameter of the function. We call such phase plot an "L-Curve" by analogy with Tikhonov regularization, due to its distinctive L-shape. The L-curve is calculated in this paper by formulating the problem as a Linear Programming problem and using CPLEX as the LP-solver. Numerical simulations reveal that the phase-plot of generalized L1-norm versus CVaR indeed possesses a pronounced L-shape and exhibits two distinctive regions: (1) a region of a rapid decrease in generalized L1-norm of the portfolio decision vector with increase in CVaR, and (2) a region of a slow decrease in the generalized L1-norm with increase in CVaR. The regularization parameter that corresponds to the transition between the two regions (or the "corner" of the L-curve) is a candidate for an optimal trade-off between minimization of the CVaR and the transaction costs (generalized L1-norm of portfolio decision vector). It is shown in this paper that in case of hedging a portfolio of derivatives with CVaR as a hedging risk measure, the L-curve can be interpreted as the trade-off curve between the deterministic and stochastic components of portfolio risk. The properties of the regularized solution have been established via numerical simulations. Amongst these properties is the existence of a threshold value of the regularization parameter below which the solution is unbounded.	[Tarnopolskaya, T.] CSIRO Math & Informat Sci, N Ryde, NSW, Australia	Tarnopolskaya, T (reprint author), CSIRO Math & Informat Sci, N Ryde, NSW, Australia.	tanya.tarnopolskaya@csiro.au	Tarnopolskaya, Tanya/C-1907-2009; CSIRO, CMIS/D-8200-2011; de Hoog, Frank/A-4555-2009				Alexander S, 2006, J BANK FINANC, V30, P583, DOI 10.1016/j.jbankfin.2005.04.012; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Artzner P, 1999, MATH FINANC, V9, P203, DOI 10.1111/1467-9965.00068; HANSEN PC, 1992, SIAM REV, V34, P561, DOI 10.1137/1034115; HANSEN PC, 1993, SIAM J SCI COMPUT, V14, P1487, DOI 10.1137/0914086; Rockafellar R, 2000, J RISK, V2, P21; Rockafellar RT, 2002, J BANK FINANC, V26, P1443, DOI 10.1016/S0378-4266(02)00271-6	7	1	1	0	2	UNIV WESTERN AUSTRALIA	NEDLANDS	NEDLANDS, WA, AUSTRALIA			978-0-9758400-7-8				2009							1559	1565				7	Computer Science, Interdisciplinary Applications; Operations Research & Management Science; Mathematics, Applied; Mathematics, Interdisciplinary Applications	Computer Science; Operations Research & Management Science; Mathematics	BUQ27	WOS:000290045001090		
B	Fadili, MJ; Starck, JL			IEEE	Fadili, M. J.; Starck, J. -L.			MONOTONE OPERATOR SPLITTING FOR OPTIMIZATION PROBLEMS IN SPARSE RECOVERY	2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6			English	Proceedings Paper	16th IEEE International Conference on Image Processing	NOV 07-10, 2009	Cairo, EGYPT	IEEE		Convex analysis; Non-smooth optimization; Monotone operator splitting; Sparse recovery	SIGNAL RECOVERY; ALGORITHM	This work focuses on several optimization problems involved in recovery of sparse solutions of linear inverse problems. Such problems appear in many fields including image and signal processing, and have attracted even more interest since the emergence of the compressed sensing (CS) theory. In this paper, we formalize many of these optimization problems within a unified framework of convex optimization theory, and invoke tools from convex analysis and maximal monotone operator splitting. We characterize all these optimization problems, and to solve them, we propose fast iterative convergent algorithms using forward-backward and/or Peaceman/Douglas-Rachford splitting iterations. With non-differentiable sparsity-promoting penalties, the proposed algorithms are essentially based on iterative shrinkage. This makes them very competitive for large-scale problems. We also report some experiments on image reconstruction in CS to demonstrate the applicability of the proposed framework.	[Fadili, M. J.] Univ Caen, GREYC CNRS ENSICAEN, F-14050 Caen, France	Fadili, MJ (reprint author), Univ Caen, GREYC CNRS ENSICAEN, F-14050 Caen, France.						Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes E, 2007, ANN STAT, V35, P2392, DOI 10.1214/009053607000000532; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Combettes PL, 2007, IEEE J-STSP, V1, P564, DOI 10.1109/JSTSP.2007.910264; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Combettes PL, 2004, OPTIMIZATION, V53, P475, DOI 10.1080/02331930412331327157; COMBETTES PL, 2005, SIAM J MULTISCALE MO, V4, P1168; DONOHO DL, 2006, IEEE T INFORM UNPUB; Fadili M., 2007, COMPUT J, V52, P64; MOREAU JJ, 1962, CR HEBD ACAD SCI, V255, P2897; Nesterov Y., 2007, CORE DISCUSSION PAPE; Rockafellar T., 1970, CONVEX ANAL; VANDENBERG E, 2008, TR200801 U BRIT COL	18	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5653-6				2009							1461	1464		10.1109/ICIP.2009.5414555		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BQA01	WOS:000280464300362		
B	Li, Y; Zhou, Y; Xu, L; Yang, XC; Yang, J			IEEE	Li, Yin; Zhou, Yue; Xu, Lei; Yang, Xiaochao; Yang, Jie			INCREMENTAL SPARSE SALIENCY DETECTION	2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6			English	Proceedings Paper	16th IEEE International Conference on Image Processing	NOV 07-10, 2009	Cairo, EGYPT	IEEE		Saliency Detection; Incremental Coding length; Sparse Coding		By the guidance of attention, human visual system is able to locate objects of interest in complex scene. We propose a new visual saliency detection model for both image and video. Inspired by biological vision, saliency is defined locally. Lossy compression is adopted, where the saliency of a location is measured by the Incremental Coding Length(ICL). The ICL is computed by presenting the center patch as the sparsest linear representation of its surroundings. The final saliency map is generated by accumulating the coding length. The model is tested on both images and videos. The results indicate a reliable and robust saliency of our method.	[Li, Yin; Zhou, Yue; Xu, Lei; Yang, Xiaochao; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China	Li, Y (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.		Zheng, Zhenzhu/F-1081-2011				Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Bruce N., 2006, ADV NEURAL INFORM PR, V18, P155; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Hou X., 2007, CVPR, P1; Itti L, 2005, CVPR 05, V1, P631; RENSINK RA, 2000, SEEING SENSING SCRUT; WIESE TN, 1965, J NEROPHYSIOL, V28, P229; WRIGHT J, 2008, ADV NEURAL INFORM PR, V20, P1633	12	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5653-6				2009							3093	3096				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BQA01	WOS:000280464301221		
B	Xi, YT; Ramadge, PJ			IEEE	Xi, Yongxin Taylor; Ramadge, Peter J.			USING SPARSE REGRESSION TO LEARN EFFECTIVE PROJECTIONS FOR FACE RECOGNITION	2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6			English	Proceedings Paper	16th IEEE International Conference on Image Processing	NOV 07-10, 2009	Cairo, EGYPT	IEEE		Face recognition; Feature extraction; Image recognition; Pattern classification; Object detection	DISCRIMINANT-ANALYSIS; EIGENFACES; ALGORITHMS	We explore sparse regression for effective feature selection and classification in face identity and expression recognition. We argue that sparse regression in pixel space is inappropriate. We propose instead a method which combines the virtues of sparse regression with projection methods such as PCA and FDA. The method can learn a sparse set of discriminative projections and increase recognition accuracy beyond that achievable by FDA. We demonstrate this by performance comparisons on three face data sets.	[Xi, Yongxin Taylor; Ramadge, Peter J.] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA	Xi, YT (reprint author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.						An S., 2007, CVPR 07, P1; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014; Efron B, 2004, ANN STAT, V32, P407; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Clemmensen LH, 2007, LECT NOTES COMPUT SC, V4522, P61; Hastie T., 2001, ELEMENTS STAT LEARNI; KIM S, 2006, ADV NEURAL INFORM PR, P659; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Shakhnarovich G., 2004, HDB FACE RECOGNITION, P141; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71	15	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5653-6				2009							3333	3336		10.1109/ICIP.2009.5413913		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BQA01	WOS:000280464301281		
B	Angelosante, D; Giannakis, GB; Grossi, E			IEEE	Angelosante, D.; Giannakis, G. B.; Grossi, E.			COMPRESSED SENSING OF TIME-VARYING SIGNALS	2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2			English	Proceedings Paper	16th International Conference on Digital Signal Processing	JUL 05-07, 2009	Santorini, GREECE			Compressed Sensing; Lasso; Group Lasso; Fused Lasso; Smoothing; Tracking	MULTIPLE-MEASUREMENT VECTORS; ORACLE PROPERTIES; MODEL SELECTION; LASSO; REGRESSION; RECOVERY	Compressed sensing (CS) lowers the number of measurements required for reconstruction and estimation of signals that are sparse when expanded over a proper basis. Traditional CS approaches deal with time-invariant sparse signals, meaning that, during the measurement process, the signal of interest does not exhibit variations. However, many signals encountered in practice are varying with time as the observation window increases (e.g., video imaging, where the signal is sparse and varies between different frames). The present paper develops CS algorithms for time-varying signals, based on the least-absolute shrinkage and selection operator (Lasso) that has been popular for sparse regression problems. The Lasso here is tailored for smoothing time-varying signals, which are modeled as vector valued discrete time series. Two algorithms are proposed: the Group-Fused Lasso, when the unknown signal support is time-invariant but signal samples are allowed to vary with time; and the Dynamic Lasso, for the general class of signals with time-varying amplitudes and support. Performance of these algorithms is compared with a sparsity-unaware Kalman smoother, a support-aware Kalman smoother, and the standard Lasso which does not account for time variations. The numerical results amply demonstrate the practical merits of the novel CS algorithms.	[Angelosante, D.; Giannakis, G. B.] Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA	Angelosante, D (reprint author), Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA.						AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Angelosante D., 2009, P IEEE INT C AC SPEE; Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172; Chen J, 2006, IEEE T SIGNAL PROCES, V54, P4634, DOI 10.1109/TSP.2006.881263; Bar-Shalom Y., 1993, ESTIMATION TRACKING; Candes E., ANN STAT IN PRESS; Chen Y, 1998, NONCON OPTIM ITS APP, V20, P1; LOFBERG J, 2006, P AM CONTR C MINN MN; Phillips JW, 1997, IEEE T MED IMAGING, V16, P338, DOI 10.1109/42.585768; TROOP J, 2006, SIGNAL PROCESS, V86, P589; Vandenberghe L., 2004, CONVEX OPTIMIZATION; VASWANI N, 2008, P IEEE INT C IM P SA	25	0	0	0	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3297-4				2009							816	823				8	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BOF71	WOS:000276494500139		
B	Schizas, ID; Giannakis, GB; Sidiropoulos, ND			IEEE	Schizas, Ioannis D.; Giannakis, Georgios B.; Sidiropoulos, Nicholas D.			Exploiting Covariance-domain Sparsity for Dimensionality Reduction	2009 3RD IEEE INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP)			English	Proceedings Paper	3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	DEC 13-16, 2009	Aruba, NETHERLANDS	IEEE, IEEE Signal Proc Soc			LASSO	Novel schemes are developed for linear dimensionality reduction of data vectors whose covariance matrix exhibits sparsity. Two types of sparsity are considered: i) sparsity in the eigenspace of the covariance matrix; or, ii) sparsity in the factors that the covariance matrix is decomposed. Different from existing alternatives, the novel dimensionality-reducing and reconstruction matrices are designed to fully exploit covariance-domain sparsity. They are obtained by solving properly formulated optimization problems using simple coordinate descent iterations. Numerical tests corroborate that the novel algorithms achieve improved reconstruction quality relative to related approaches that do not fully exploit covariance-domain sparsity.	[Schizas, Ioannis D.; Giannakis, Georgios B.] Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA	Schizas, ID (reprint author), Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA.	schiz001@umn.edu; georgios@umn.edu; nikos@telecom.tuc.gr					d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; Bertsekas D. P., 2003, NONLINEAR PROGRAMMIN; Brillinger D. R., 1981, TIME SERIES DATA ANA; Ulfarsson MO, 2008, IEEE T SIGNAL PROCES, V56, P5823, DOI 10.1109/TSP.2008.2006587; Zhou H., 2006, J COMPUTATIONAL GRAP, V15, P265	9	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5180-7				2009							117	120				4	Engineering, Electrical & Electronic	Engineering	BYI50	WOS:000298924200030		
B	Kekatos, V; Angelosante, D; Giannakis, GB			IEEE	Kekatos, Vassilis; Angelosante, Daniele; Giannakis, Georgios B.			Sparsity-Aware Estimation of Nonlinear Volterra Kernels	2009 3RD IEEE INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP)			English	Proceedings Paper	3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	DEC 13-16, 2009	Aruba, NETHERLANDS	IEEE, IEEE Signal Proc Soc			LASSO	The Volterra series expansion has well-documented merits for modeling smooth nonlinear systems. Given that nature itself is parsimonious and models with minimal degrees of freedom are attractive from a system identification viewpoint, estimating sparse Volterra models is of paramount importance. Based on input-output data, existing estimators of Volterra kernels are sparsity agnostic because they rely on standard (possibly recursive) least-squares approaches. Instead, the present contribution develops batch and recursive algorithms for estimating sparse Volterra kernels using the least-absolute shrinkage and selection operator (Lasso) along with its recent weighted and online variants. Analysis and simulations demonstrate that weighted (recursive) Lasso has the potential to obviate the "curse of dimensionality," especially in the under-determined case where input-output data are less than the number of unknowns dictated by the order of the expansion and the memory of the kernels.	[Kekatos, Vassilis; Angelosante, Daniele; Giannakis, Georgios B.] Univ Minnesota, ECE Dept, Minneapolis, MN 55455 USA	Kekatos, V (reprint author), Univ Minnesota, ECE Dept, Minneapolis, MN 55455 USA.	kekatos@umn.edu; angel129@umn.edu; georgios@umn.edu					Angelosante D., 2009, P IEEE INT C AC SPEE; Angelosante D., 2009, WORKSH STAT SIGN PRO; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Benedetto S., 1983, IEEE Journal on Selected Areas in Communications, VSAC-1, DOI 10.1109/JSAC.1983.1145885; Mathews V. J., 2000, POLYNOMIAL SIGNAL PR; NOWAK RD, 1995, IEEE T SIGNAL PROCES, V43, P705, DOI 10.1109/78.370624; NOWAK RD, 1994, IEEE T SIGNAL PROCES, V42, P2124, DOI 10.1109/78.301847; PALM G, 1977, SIAM J APPL MATH, V33, P195, DOI 10.1137/0133012	9	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5180-7				2009							129	132				4	Engineering, Electrical & Electronic	Engineering	BYI50	WOS:000298924200033		
J	Zhou, MY; Paisley, J; Carin, L			IEEE	Zhou, Mingyuan; Paisley, John; Carin, Lawrence			Nonparametric Learning of Dictionaries for Sparse Representation of Sensor Signals	2009 3RD IEEE INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP)			English	Proceedings Paper	3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	DEC 13-16, 2009	Aruba, NETHERLANDS	IEEE, IEEE Signal Proc Soc				Nonparametric Bayesian techniques are considered for learning dictionaries for sparse data representations, with applications in sparse rendering of sensor data. The beta process is employed as a prior for learning the dictionary, and this non parametric method naturally infers an appropriate dictionary size. The proposed method can learn a sparse dictionary, and may also be used to denoise a signal under test. The noise variance need not be known, and can be non-stationary. The dictionary coefficients for a given sensor signal may be employed within a classifier. Several example results are presented, using both Gibbs and variational Bayesian inference, with comparisons to other state-of-the-art approaches.	[Zhou, Mingyuan; Paisley, John; Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Zhou, MY (reprint author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	lcarin@ee.duke.edu					Aharon M., 2006, IEEE T SIGNAL PROCES, V54; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; [Anonymous], 2009, IEEE T PATTERN ANAL; Beal M. J., 2003, THESIS U COLL LONDON; Cristianini N., 2000, INTRO SUPPORT VECTOR; DUARTECARVAJALI.J, 2008, IMA PREPRINT SERIES, V2211; Elad M., 2006, IEEE T IMAGE PROCESS, V15; Ji Sh., 2008, IEEE T SIGNAL PROCES, V56; Knowles D.A., 2007, 7 INT C IND COMP AN; Mairal J., 2008, P NEUR INF PROC SYST; MAIRAL J, 2009, P INT C MACH LEARN; Mairal J., 2008, IEEE T IMAGE PROCESS, V17; Olshausen B. A., 1997, VISION RES, V37; Paisley J., 2009, P INT C MACH LEARN; Rai P., 2008, ADV NEURAL INFORM PR; Raina R, 2007, P INT C MACH LEARN; Ranzato M., 2006, P NEURAL INFORM PROC; Thibaux R., 2007, INT C ART INT STAT; Tipping M. E., 2001, J MACHINE LEARNING R, V1	19	0	0	0	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5180-7				2009							237	240				4	Engineering, Electrical & Electronic	Engineering	BYI50	WOS:000298924200060		
B	Kim, SJ; Dall'Anese, E; Giannakis, GB			IEEE	Kim, Seung-Jun; Dall'Anese, Emiliano; Giannakis, Georgios B.			Spectrum Sensing for Cognitive Radios Using Kriged Kalman Filtering	2009 3RD IEEE INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP)			English	Proceedings Paper	3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	DEC 13-16, 2009	Aruba, NETHERLANDS	IEEE, IEEE Signal Proc Soc				A cooperative spectrum sensing algorithm for cognitive radios (CRs) is developed using the novel notion of channel gain maps. These maps capture the spatio-temporal variation of the RF propagation in the geographical area where the CR network is operated. They are tracked via Kriged Kalman filtering (KKF), a tool with well-appreciated merits in geo-statistics. This in turn enables the activity of an unknown number of primary users to be tracked using a sparse regression technique based on a weighted least-squares criterion regularized by the l(1) norm of the regression coefficient vector. Simulations demonstrate considerable performance advantage of the proposed scheme over a crude path loss-based sensing algorithm.	[Kim, Seung-Jun; Giannakis, Georgios B.] Univ Minnesota, Dept Electr & Comp Engr, Minneapolis, MN 55455 USA	Kim, SJ (reprint author), Univ Minnesota, Dept Electr & Comp Engr, Minneapolis, MN 55455 USA.	seungjun@umn.edu; edallane@dei.unipd.it; georgios@umn.edu					Agrawal P., 2008, ARXIV08042708; Angelosante D., 2009, P IEEE WORKSH STAT S; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Bazerque J.-A., 2009, IEEE T SIG P     JUL; Bazerque J.-A., 2008, P 42 AS C SIGN SYST; Cabric D., 2006, P MIL COMM C MILCOM, P1; Cortes J., 2009, IEEE T AUTOMATIC JAN; Mardia KV, 1998, TEST, V7, P217, DOI 10.1007/BF02565111; Rappaport T.S., 1996, WIRELESS COMMUNICATI; Ripley B. D., 1981, SPATIAL STAT; Suetin P K, 1999, ORTHOGONAL POLYNOMIA; Wikle CK, 1999, BIOMETRIKA, V86, P815, DOI 10.1093/biomet/86.4.815	13	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5180-7				2009							392	395				4	Engineering, Electrical & Electronic	Engineering	BYI50	WOS:000298924200099		
B	Schizas, ID; Giannakis, GB; Sidiropoulos, ND			IEEE	Schizas, Ioannis D.; Giannakis, Georgios B.; Sidiropoulos, Nicholas D.			Exploiting Covariance-domain Sparsity for Dimensionality Reduction	2009 3RD IEEE INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP 2009)			English	Proceedings Paper	3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	DEC 13-16, 2009	Aruba, NETHERLANDS	IEEE, IEEE Signal Proc Soc			LASSO	Novel schemes are developed for linear dimensionality reduction of data vectors whose covariance matrix exhibits sparsity. Two types of sparsity are considered: i) sparsity in the eigenspace of the covariance matrix; or, ii) sparsity in the factors that the covariance matrix is decomposed. Different from existing alternatives, the novel dimensionality-reducing and reconstruction matrices are designed to fully exploit covariance-domain sparsity. They are obtained by solving properly formulated optimization problems using simple coordinate descent iterations. Numerical tests corroborate that the novel algorithms achieve improved reconstruction quality relative to related approaches that do not fully exploit covariance-domain sparsity.	[Schizas, Ioannis D.; Giannakis, Georgios B.] Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA	Schizas, ID (reprint author), Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA.	schiz001@umn.edu; georgios@umn.edu; nikos@telecom.tuc.gr					d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; Bertsekas D. P., 2003, NONLINEAR PROGRAMMIN; Brillinger D. R., 1981, TIME SERIES DATA ANA; ULFARSSON MO, 2008, IEEE T SIGNAL PROCES, P5823; Zhou H., 2006, J COMPUTATIONAL GRAP, V15, P265	9	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5179-1				2009							117	120				4	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BUK97	WOS:000289697600030		
B	Kekatos, V; Angelosante, D; Giannakis, GB			IEEE	Kekatos, Vassilis; Angelosante, Daniele; Giannakis, Georgios B.			Sparsity-Aware Estimation of Nonlinear Volterra Kernels	2009 3RD IEEE INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP 2009)			English	Proceedings Paper	3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	DEC 13-16, 2009	Aruba, NETHERLANDS	IEEE, IEEE Signal Proc Soc			LASSO	The Volterra series expansion has well-documented merits for modeling smooth nonlinear systems. Given that nature itself is parsimonious and models with minimal degrees of freedom are attractive from a system identification viewpoint, estimating sparse Volterra models is of paramount importance. Based on input-output data, existing estimators of Volterra kernels are sparsity agnostic because they rely on standard (possibly recursive) least-squares approaches. Instead, the present contribution develops batch and recursive algorithms for estimating sparse Volterra kernels using the least-absolute shrinkage and selection operator (Lasso) along with its recent weighted and online variants. Analysis and simulations demonstrate that weighted (recursive) Lasso has the potential to obviate the "curse of dimensionality," especially in the under-determined case where input-output data are less than the number of unknowns dictated by the order of the expansion and the memory of the kernels.	[Kekatos, Vassilis; Angelosante, Daniele; Giannakis, Georgios B.] Univ Minnesota, ECE Dept, Minneapolis, MN 55455 USA	Kekatos, V (reprint author), Univ Minnesota, ECE Dept, Minneapolis, MN 55455 USA.	kekatos@umn.edu; angel129@umn.edu; georgios@umn.edu					Angelosante D., 2009, P IEEE INT C AC SPEE; Angelosante D., 2009, WORKSH STAT SIGN PRO; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Benedetto S., 1983, IEEE Journal on Selected Areas in Communications, VSAC-1, DOI 10.1109/JSAC.1983.1145885; Mathews V. J., 2000, POLYNOMIAL SIGNAL PR; NOWAK RD, 1995, IEEE T SIGNAL PROCES, V43, P705, DOI 10.1109/78.370624; NOWAK RD, 1994, IEEE T SIGNAL PROCES, V42, P2124, DOI 10.1109/78.301847; PALM G, 1977, SIAM J APPL MATH, V33, P195, DOI 10.1137/0133012	9	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5179-1				2009							129	132				4	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BUK97	WOS:000289697600033		
B	Zhou, MY; Paisley, J; Carin, L			IEEE	Zhou, Mingyuan; Paisley, John; Carin, Lawrence			Nonparametric Learning of Dictionaries for Sparse Representation of Sensor Signals	2009 3RD IEEE INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP 2009)			English	Proceedings Paper	3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	DEC 13-16, 2009	Aruba, NETHERLANDS	IEEE, IEEE Signal Proc Soc				Nonparametric Bayesian techniques are considered for learning dictionaries for sparse data representations, with applications in sparse rendering of sensor data. The beta process is employed as a prior for learning the dictionary, and this nonparametric method naturally infers an appropriate dictionary size. The proposed method can learn a sparse dictionary, and may also be used to denoise a signal under test. The noise variance need not be known, and can be non-stationary. The dictionary coefficients for a given sensor signal may be employed within a classifier. Several example results are presented, using both Gibbs and variational Bayesian inference, with comparisons to other state-of-the-art approaches.	[Zhou, Mingyuan; Paisley, John; Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Zhou, MY (reprint author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	lcarin@ee.duke.edu					AHARON M, 2006, K SVD ALGORITHM DESI, P54; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Beal M. J., 2003, THESIS U COLL LONDON; DUARTECARVAJALI.JM, 2008, LEARNING SENSE SPARS; ELAD M, 2006, IMAGE DENOISING VIA, P15; JI S, 2008, BAYESIAN COMPRESSIVE, P56; MAIRAL J, 2008, SPARSE REPRESENTATIO, P17; OLSHAUSEN BA, 1997, SPARSE CODING OVERCO, P37; TIPPING M, 2001, SPARSE BAYESIAN LEAR, P1; Wright John, 2009, ROBUST FACE RECOGNIT	10	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5179-1				2009							237	240				4	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BUK97	WOS:000289697600060		
B	Kim, SJ; Dall'Anese, E; Giannakis, GB			IEEE	Kim, Seung-Jun; Dall'Anese, Emiliano; Giannakis, Georgios B.			Spectrum Sensing for Cognitive Radios Using Kriged Kalman Filtering	2009 3RD IEEE INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP 2009)			English	Proceedings Paper	3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)	DEC 13-16, 2009	Aruba, NETHERLANDS	IEEE, IEEE Signal Proc Soc				A cooperative spectrum sensing algorithm for cognitive radios (CRs) is developed using the novel notion of channel gain maps. These maps capture the spatio-temporal variation of the RF propagation in the geographical area where the CR network is operated. They are tracked via Kriged Kalman filtering (KKF), a tool with well-appreciated merits in geo-statistics. This in turn enables the activity of an unknown number of primary users to be tracked using a sparse regression technique based on a weighted least-squares criterion regularized by the Pi norm of the regression coefficient vector. Simulations demonstrate considerable performance advantage of the proposed scheme over a crude path loss-based sensing algorithm.	[Kim, Seung-Jun; Giannakis, Georgios B.] Univ Minnesota, Dept Electr & Comp Engr, Minneapolis, MN 55455 USA	Kim, SJ (reprint author), Univ Minnesota, Dept Electr & Comp Engr, Minneapolis, MN 55455 USA.	seungjun@umn.edu; edallane@dei.unipd.it; georgios@umn.edu					Agrawal P., 2008, ARXIV08042708; Angelosante D., 2009, P IEEE WORKSH STAT S; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; BAZERQUE JA, 2009, IEEE T SIG PROC  JUL; Bazerque J.-A., 2008, P 42 AS C SIGN SYST; Cabric D., 2006, P MIL COMM C MILCOM, P1; Cortes J., 2009, IEEE T AUTOMATIC JAN; Mardia KV, 1998, TEST, V7, P217, DOI 10.1007/BF02565111; Rappaport T.S., 1996, WIRELESS COMMUNICATI; Ripley B. D., 1981, SPATIAL STAT; Suetin P K, 1999, ORTHOGONAL POLYNOMIA; Wikle CK, 1999, BIOMETRIKA, V86, P815, DOI 10.1093/biomet/86.4.815	13	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5179-1				2009							392	395				4	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BUK97	WOS:000289697600099		
B	Chen, XH; Gottardo, R			IEEE	Chen, Xiaohui; Gottardo, Raphael			An MM-based Optimization Algorithm for Sparse Linear Modeling on Microarray Data Analysis	2009 3RD INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICAL ENGINEERING, VOLS 1-11			English	Proceedings Paper	3rd International Conference on Bioinformatics and Biomedical Engineering	JUN 11-16, 2009	Beijing, PEOPLES R CHINA	IEEE Engineering Med & Biol Soc, Gordon Life Sci Inst, Fudan Univ, Beijing Univ Posts & Telecommunicat, Beijing Inst Technol, Wuhan Univ, Journal Biomed Sci & Engn			VARIABLE SELECTION; REGRESSION; LASSO	Sparsity is crucial for high-dimensional statistical modeling. On one hand, dimensionality reduction can reduce the variability of estimation and thus provide reliable predictive power. On the other hand, the selected sub-model can discover and emphasize the underlying dependencies, which is useful for objective interpretation. Many variable selection methods have been proposed in literatures. For a prominent example, Least Absolute Shrinkage and Selection Operator (lasso) in linear regression context has been extensively explored. This paper discusses a class of scaled mixture of Gaussian models from both a penalized likelihood and a Bayesian regression point of view. We propose an Majorize-Minimize (MM) algorithm to find the Maximum A Posteriori (MAP) estimator, where the EM algorithm can be stuck at local optimum for some members in this class. Simulation studies show the outperformance of proposed algorithm in nonstochastic design variable selection scenario. The proposed algorithm is applied to a real large-scale E. coli data set with known bona fide interactions for constructing sparse gene regulatory networks. We show that our regression networks with a properly chosen prior can perform comparably to state-of-the-art regulatory network construction algorithms.	[Chen, Xiaohui] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada	Chen, XH (reprint author), Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada.	xiaohuic@ece.ubc.ca; raph@stat.ubc.ca					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Efron B, 2004, ANN STAT, V32, P407; CARON F, 2008, INT C MACH IN PRESS; CHEN X, 2008, SIGNAL PROCESS UNPUB; Faith JJ, 2007, PLOS BIOL, V5, P54, DOI 10.1371/journal.pbio.0050008; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Griffin J., 2005, ALTERNATIVE PRIOR DI; Griffin J. E., 2007, BAYESIAN ADAPTIVE LA; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Salgado H, 2006, NUCLEIC ACIDS RES, V34, pD394, DOI 10.1093/nar/gkj156; Shalgi R, 2007, PLOS COMPUT BIOL, V3, P1291, DOI 10.1371/journal.pcbi.0030131	16	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2901-1				2009							48	51				4	Engineering, Biomedical; Engineering, Electrical & Electronic	Engineering	BTB33	WOS:000286342800011		
B	Asif, MS; Romberg, J			IEEE	Asif, M. Salman; Romberg, Justin			Dynamic Updating for Sparse Time Varying Signals	2009 43RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1 AND 2			English	Proceedings Paper	43rd Annual Conference on Information Sciences and Systems	MAR 18-20, 2009	Baltimore, MD	Johns Hopkins Univ, Dept Elect & Comp Engn, IEEE Informat Theory Soc			DANTZIG SELECTOR; RECONSTRUCTION; REGRESSION; LASSO	Many signal processing applications revolve around finding a sparse solution to a (often underdetermined) system of linear equations. Recent results in compressive sensing (CS) have shown that when the signal we are trying to acquire is sparse and the measurements are incoherent, the signal can be reconstructed reliably from an incomplete set of measurements. However, the signal recovery is an involved process, usually requiring the solution of an l(1) minimization program. In this paper we discuss the problem of estimating a time-varying sparse signal from a series of linear measurements. We propose an efficient way to dynamically update the solution to two types of l(1) problems when the underlying signal changes. The proposed dynamic update scheme is based on homotopy continuation, which systematically breaks down the solution update into a small number of linear steps. The computational cost for each step is just a few matrix-vector multiplications.	[Asif, M. Salman; Romberg, Justin] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	Asif, MS (reprint author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.	sasif@ece.gatech.edu; jrom@ece.gatech.edu					Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Efron B, 2004, ANN STAT, V32, P407; Asif M., 2008, THESIS GEORGIA I TEC; Bertsekas D., 1999, NONLINEAR PROGRAMMIN; Buckheit J., WAVELAB 850 SOFTWARE; Candes E., 2006, P INT C MATH, V3, P1433; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Cotter SF, 2002, IEEE T COMMUN, V50, P374, DOI 10.1109/26.990897; Fuchs JJ, 2004, IEEE T INFORM THEORY, V50, P1341, DOI 10.1109/TIT.2004.828141; Golub G., 1996, MATRIX COMPUTATIONS; James GM, 2009, J ROY STAT SOC B, V71, P127, DOI 10.1111/j.1467-9868.2008.00668.x; Malioutov D. M., 2005, IEEE INT C AC SPEECH, VV, P733; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Wen Z., FPC AS MATLAB SOLVER	20	6	6	1	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2733-8				2009							3	8		10.1109/CISS.2009.5054679		6	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BLT78	WOS:000270992700002		
B	Carrillo, RE; Barner, KE			IEEE	Carrillo, Rafael E.; Barner, Kenneth E.			Iteratively Re-weighted Least Squares for Sparse Signal Reconstruction from Noisy Measurements	2009 43RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1 AND 2			English	Proceedings Paper	43rd Annual Conference on Information Sciences and Systems	MAR 18-20, 2009	Baltimore, MD	Johns Hopkins Univ, Dept Elect & Comp Engn, IEEE Informat Theory Soc		Compressed sensing; sampling methods; signal reconstruction; underdetermined systems of linear equations; reweighted least squares	RECOVERY; NORM	Finding sparse solutions of under-determined systems of linear equations is a problem of significance importance in signal processing and statistics. In this paper we study an iterative reweighted least squares (IRLS) approach to find sparse solutions of underdetermined system of equations based on smooth approximation of the L(0) norm and the method is extended to find sparse solutions from noisy measurements. Analysis of the proposed methods show that weaker conditions on the sensing matrices are required. Simulation results demonstrate that the proposed method requires fewer samples than existing methods, while maintaining a reconstruction error of the same order and demanding less computational complexity.	[Carrillo, Rafael E.; Barner, Kenneth E.] Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19716 USA	Carrillo, RE (reprint author), Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19716 USA.	carrillo@ee.udel.edu; barner@ee.udel.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Haupt J, 2006, IEEE T INFORM THEORY, V52, P4036, DOI 10.1109/TIT.2006.880031; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; CANDES EJ, 2008, ENHACING SPARSITY RE; Candess EJ, 2008, COMPTE RENDUS ACAD 1, P589; CHARTRAND R, 2008, RESTRICTED ISOMETRY; DAUBECHIES I, 2008, ITERATIVELY REWEIGHT; Needell D., 2008, COSAMP ITERATIVE SIG; SAAB R, 2008, SPARSE RECOVERY NONC	14	5	5	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2733-8				2009							448	453		10.1109/CISS.2009.5054762		6	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BLT78	WOS:000270992700085		
B	Raskutti, G; Wainwright, MJ; Yu, B			IEEE	Raskutti, Garvesh; Wainwright, Martin J.; Yu, Bin			Minimax rates of convergence for high-dimensional regression under l(q)-ball sparsity	2009 47TH ANNUAL ALLERTON CONFERENCE ON COMMUNICATION, CONTROL, AND COMPUTING, VOLS 1 AND 2			English	Proceedings Paper	47th Annual Allerton Conference on Communication, Control, and Computing	SEP 30-OCT 02, 2009	Monticello, IL				ASYMPTOTIC EQUIVALENCE; WHITE-NOISE; LASSO; SELECTION; RECOVERY; REPRESENTATIONS	Consider the standard linear regression model y = X beta* + w, where y is an element of R-n is an observation vector, X is an element of R-nxd is a measurement matrix, beta* is an element of R-d is the unknown regression vector, and w similar to N(0, sigma I-2) is additive Gaussian noise. This paper determines sharp minimax rates of convergence for estimation of beta* in l(2) norm, assuming that beta* belongs to a weak l(q)-ball B-q (R-q) for some q is an element of [0, 1]. We show that under suitable regularity conditions on the design matrix X, the minimax error in squared l(2)-norm scales as R-q(logd/n)(1-q/2). In addition, we provide lower bounds on rates of convergence for general l(p) norm (for all p is an element of [1, + infinity], p not equal q). Our proofs of the lower bounds are information-theoretic in nature, based on Fano's inequality and results on the metric entropy of the balls B-q (R-q). Matching upper bounds are derived by direct analysis of the solution to an optimization algorithm over We prove that the conditions on X required by optimal algorithms are satisfied with high probability by broad classes of non-i.i.d. Gaussian random matrices, for which RIP or other sparse eigenvalue conditions are violated. For q = 0, l(1)-based methods (Lasso and Dantzig selector) achieve the minimax optimal rates in l(2) error, but require stronger regularity conditions on the design than the non-convex optimization algorithm used to determine the minimax upper bounds.	[Raskutti, Garvesh; Wainwright, Martin J.; Yu, Bin] Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Raskutti, G (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.						AKCAKAYA M, 2007, ARXIVCSIT07110366 HA; AMINI AA, 2009, ANN STAT IN PRESS; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Baik J, 2006, J MULTIVARIATE ANAL, V97, P1382, DOI 10.1016/j.jmva.2005.08.003; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; BAI ZD, 1988, ANN PROBAB, V16, P863, DOI 10.1214/aop/1176991792; Band Johnson W, 2001, HDB GEOMETRY BANACH, V1, P317, DOI 10.1016/S1874-5849(01)80010-3; BICKEL P, 2008, ANN STAT IN PRESS; Brown LD, 1996, ANN STAT, V24, P2384; Chen Y, 1998, NONCON OPTIM ITS APP, V20, P1; DONOHO DL, 1994, PROBAB THEORY REL, V99, P277, DOI 10.1007/BF01199026; FLETCHER AK, 2008, ARXIVCSIT08041839 UC; GORDON Y, 1985, ISRAEL J MATH, V50, P265, DOI 10.1007/BF02759761; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; GUEDON O, 2000, GEOMETRIC ASPECTS FU, P95; Has'minskii R.Z., 1978, THEOR PROBAB APPL, V23, P794; Kuhn T, 2001, J APPROX THEORY, V110, P120, DOI 10.1006/jath.2000.3554; Ledoux M., 2001, MATH SURVEYS MONOGRA; Matousek J., 2002, LECT DISCRETE GEOMET; Meinshausen N, 2009, ANN STAT, V37, P246, DOI 10.1214/07-AOS582; Nussbaum M, 1996, ANN STAT, V24, P2399; Pinsker M. S., 1980, Problems of Information Transmission, V16; Pollard D., 1984, CONVERGENCE STOCHAST; REEVES G, 2007, THESIS UC BERKELEY; Thomas J. A., 1991, ELEMENTS INFORM THEO; WAINWRIGHT MJ, 2007, INT S INF THEOR JUN; WAINWRIGHT MJ, IEEE T INFO IN PRESS; Wainwright MJ, 2009, IEEE T INFORM THEORY, V55, P2183, DOI 10.1109/TIT.2009.2016018; WANG W, ISIT 2008 TOR CAN; Yang YH, 1999, ANN STAT, V27, P1564; Yu B., 1996, RES PAPERS PROBABILI, P423; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520	36	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5870-7				2009							251	257		10.1109/ALLERTON.2009.5394804		7	Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BPQ13	WOS:000279627100035		
B	Lage-Castellanos, A; Pagnani, A; Weigt, M			IEEE	Lage-Castellanos, Alejandro; Pagnani, Andrea; Weigt, Martin			The importance of dilution in the inference of biological networks	2009 47TH ANNUAL ALLERTON CONFERENCE ON COMMUNICATION, CONTROL, AND COMPUTING, VOLS 1 AND 2			English	Proceedings Paper	47th Annual Allerton Conference on Communication, Control and Computing	SEP 30-OCT 02, 2009	Monticello, IL				NEURAL-NETWORKS; ALGORITHM; TRANSCRIPTION; ROBUSTNESS	One of the crucial tasks in many inference problems is the extraction of an underlying sparse graphical model from a given number of high-dimensional measurements. In machine learning, this is frequently achieved using, as a penalty term, the L(p) norm of the model parameters, with p <= 1 for efficient dilution. Here we propose a statistical-mechanics analysis of the problem in the setting of perceptron memorization and generalization. Using a replica approach, we are able to evaluate the relative performance of naive dilution (obtained by learning without dilution, following by applying a threshold to the model parameters), L(1) dilution (which is frequently used in convex optimization) and L(0) dilution (which is optimal but computationally hard to implement). Whereas both L(p) diluted approaches clearly outperform the naive approach, we find a small region where L(0) works almost perfectly and strongly outperforms the simpler to implement L(1) dilution. In the second part we propose an efficient message-passing strategy in the simpler case of discrete classification vectors, where the norm L(0) norm coincides with the L(1). Some examples are discussed.	[Lage-Castellanos, Alejandro] Univ Havana, Fac Phys, Havana, Cuba	Lage-Castellanos, A (reprint author), Univ Havana, Fac Phys, CP 10400, Havana, Cuba.	lage@fisica.uh.cu; pagnani@isi.it; weigt@isi.it	Pagnani, Andrea/J-2363-2015	Pagnani, Andrea/0000-0002-6509-0807			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Orlando DA, 2008, NATURE, V453, P944, DOI 10.1038/nature06955; GARDNER E, 1987, EUROPHYS LETT, V4, P481, DOI 10.1209/0295-5075/4/4/016; Li FT, 2004, P NATL ACAD SCI USA, V101, P4781, DOI 10.1073/pnas.0305937101; BANERJEE O, 2006, ACM INT C P SERIES, V148, P12; Bishop CM, 1996, NEURAL NETWORKS PATT; BOUTEN M, 1990, J PHYS A-MATH GEN, V23, P4643, DOI 10.1088/0305-4470/23/20/025; BRAUNSTEIN A, 2005, PHYS REV LETT, V96; Braunstein A, 2008, Journal of Physics: Conference Series, V95, DOI 10.1088/1742-6596/95/1/012016; Braunstein A, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/12/P12001; GARCES R, 1992, J PHYS A-MATH GEN, V25, pL1335; GARDNER E, 1988, J PHYS A-MATH GEN, V21, P257, DOI 10.1088/0305-4470/21/1/030; Guyon I., 2006, FEATURE EXTRACTION F; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; GYORGYI G, 1990, PHYS REV LETT, V64, P2957, DOI 10.1103/PhysRevLett.64.2957; Hassibi B., 1993, ADV NEURAL INFORMATI, V5, P164; Kabashima Y, 2003, J PHYS A-MATH GEN, V36, P11111, DOI 10.1088/0305-4470/36/43/030; KOMODA A, 1991, J PHYS A-MATH GEN, V24, pL743, DOI 10.1088/0305-4470/24/13/008; Kovacs LAS, 2008, CELL CYCLE, V7, P2626, DOI 10.4161/cc.7.17.6515; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; KUHLMANN P, 1992, J PHYS A-MATH GEN, V25, pL593, DOI 10.1088/0305-4470/25/9/014; KUHLMANN P, 1994, J PHYS A-MATH GEN, V27, P3759, DOI 10.1088/0305-4470/27/11/026; Lau KY, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.051907; LeCun Y., 1990, ADV NEURAL INFORM PR, V2; Lee S., 2006, ADV NEURAL INFORM PR; MacKay D, 2002, INFORM THEORY INFERE; Malzahn D, 2000, PHYS REV E, V61, P6261, DOI 10.1103/PhysRevE.61.6261; Meinshausen N., 2006, ANN STAT, V34; Mezard M., 1987, SPIN GLASS THEORY; Pagnani A, 2009, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2009/05/P05001; RAVIKUMAR P, 2006, ADV NEURAL INFORM PR, V19, P1465; SCHMIDT M, 2007, P 22 AAAI C ART INT; SEUNG HS, 1992, PHYS REV A, V45, P6056, DOI 10.1103/PhysRevA.45.6056; Uda S, 2005, J PHYS SOC JPN, V74, P2233, DOI [10.1143/JPSJ.74.2233, 10.1143/JPSJ.743.2233]; WONG KYM, 1991, EUROPHYS LETT, V16, P525, DOI 10.1209/0295-5075/16/6/003; YEDIDIA J, 2001, ADV NEURAL INFORM PR, V13, P772	36	0	0	0	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5870-7				2009							531	538		10.1109/ALLERTON.2009.5394907		8	Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BPQ13	WOS:000279627100072		
S	Aho, T; Zenko, B; Dzeroski, S		Wang, W; Kargupta, H; Ranka, S; Yu, PS; Wu, XD		Aho, Timo; Zenko, Bernard; Dzeroski, Saso			Rule Ensembles for Multi-Target Regression	2009 9TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING	IEEE International Conference on Data Mining		English	Proceedings Paper	9th IEEE International Conference on Data Mining	DEC 06-09, 2009	Miami Beach, FL	Knime, Mitre, CRC Press		Multi-Target Prediction; Rule Learning; Regression	MODEL	Methods for learning decision rules are being successfully applied to many problem domains, especially where understanding and interpretation of the learned model is necessary. In many real life problems, we would like to predict multiple related (nominal or numeric) target attributes simultaneously. Methods for learning rules that predict multiple targets at once already exist, but are unfortunately based on the covering algorithm, which is not very well suited for regression problems. A better solution for regression problems may be a rule ensemble approach that transcribes an ensemble of decision trees into a large collection of rules. An optimization procedure is then used for selecting the best (and much smaller) subset of these rules, and to determine their weights. Using the rule ensembles approach we have developed a new system for learning rule ensembles for multi-target regression problems. The newly developed method was extensively evaluated and the results show that the accuracy of multi-target regression rule ensembles is better than the accuracy of multi-target regression trees, but somewhat worse than the accuracy of multi-target random forests. The rules are significantly more concise than random forests, and it is also possible to create very small rule sets that are still comparable in accuracy to single regression trees.	[Aho, Timo] Tampere Univ Technol, Dept Software Syst, FI-33101 Tampere, Finland	Aho, T (reprint author), Tampere Univ Technol, Dept Software Syst, Korkeakoulunkatu 1, FI-33101 Tampere, Finland.	timo.aho@tut.fi; bernard.zenko@ijs.si; saso.dzeroski@ijs.si					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Karalic A, 1997, MACH LEARN, V26, P147, DOI 10.1023/A:1007365207130; Demsar J, 2006, J MACH LEARN RES, V7, P1; Blockeel H, 1998, 15 INT C MACH LEARN, P55; Blockeel H, 1998, THESIS KATHOLIEKE U; Blockeel H., 2002, J MACHINE LEARNING R, V3, P621, DOI DOI 10.1162/JMLR.2003.3.4-5.621; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Dembczynski Krzysztof, 2008, P 25 INT C MACH LEAR, P224, DOI 10.1145/1390156.1390185; Demsar D, 2006, ECOL MODEL, V191, P131, DOI 10.1016/j.ecolmodel.2005.08.017; Demsar D., 2005, 90 ESA ANN M EC SOC, P152; Dzeroski S, 2000, APPL INTELL, V13, P7, DOI 10.1023/A:1008323212047; Dzeroski Saso, 2006, P 20 INT C INF ENV P, P125; Dzeroski Saso, 2002, P WORKSH ACT MIN ICD, P9; Dzeroski Saso, 2005, P 2 INT C COEX GM NO, P207; Flach P., 2003, INTELL DATA ANAL, P229, DOI 10.1007/978-3-540-48625-1_7; Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148; Friedman JH, 2004, GRADIENT DIRECTED RE; Kampichler C, 2000, SOIL BIOL BIOCHEM, V32, P197, DOI 10.1016/S0038-0717(99)00147-9; Kocev D, 2009, ECOL MODEL, V220, P1159, DOI 10.1016/j.ecolmodel.2009.01.037; KOCEV D, 2007, LNCS, P624; Michalski R.S., 1969, P 5 INT S INF PROC A, P125; Stojanova D., 2009, THESIS J STEFAN INT; Suzuki Einoshin, 2001, LECT NOTES ARTIF INT, P436; ZENKO B, 2008, LNCS, P454; Zenko Bernard, 2007, THESIS U LJUBLJANA L	27	3	3	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-4786		978-1-4244-5242-2	IEEE DATA MINING			2009							21	30		10.1109/ICDM.2009.16		10	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTL37	WOS:000287216600003		
S	Chen, X; Pan, WK; Kwok, JT; Carbonell, JG		Wang, W; Kargupta, H; Ranka, S; Yu, PS; Wu, XD		Chen, Xi; Pan, Weike; Kwok, James T.; Carbonell, Jaime G.			Accelerated Gradient Method for Multi-Task Sparse Learning Problem	2009 9TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING	IEEE International Conference on Data Mining		English	Proceedings Paper	9th IEEE International Conference on Data Mining	DEC 06-09, 2009	Miami Beach, FL	Knime, Mitre, CRC Press		multi-task learning; L-1-infinity regularization; optimal method; gradient descend	SHRINKAGE	Many real world learning problems can be recast as multi-task learning problems which utilize correlations among different tasks to obtain better generalization performance than learning each task individually. The feature selection problem in multi-task setting has many applications in fields of computer vision, text classification and bio-informatics. Generally, it can be realized by solving a L-1-infinity regularized optimization problem. And the solution automatically yields the joint sparsity among different tasks. However, due to the nonsmooth nature of the L-1-infinity norm, there lacks an efficient training algorithm for solving such problem with general convex loss functions. In this paper, we propose an accelerated gradient method based on an "optimal" first order black-box method named after Nesterov and provide the convergence rate for smooth convex loss functions. For nonsmooth convex loss functions, such as hinge loss, our method still has fast convergence rate empirically. Moreover, by exploiting the structure of the L-1-infinity ball, we solve the black-box oracle in Nesterov's method by a simple sorting scheme. Our method is suitable for large-scale multi-task learning problem since it only utilizes the first order information and is very easy to implement. Experimental results show that our method significantly outperforms the most state-of-the-art methods in both convergence speed and learning accuracy.	[Chen, Xi; Carbonell, Jaime G.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Chen, X (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.	xichen@cs.cmu.edu; weikep@cse.ust.hk; jamesk@cse.ust.hk; jgc@cs.cmu.edu					Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bertsekas D., 1999, NONLINEAR PROGRAMMIN; Duchi J., 2008, P INT C MACH LEARN; DUCHI J, 2008, ONLINE BATCH LEARNIN; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI 10.1145/1014052.1014067; Ji S., 2009, P INT C MACH LEARN; LAN G, 2008, EFFICIENT METHODS ST; LIU H, 2009, P INT C MACH LEARN; LIU J, 2009, P C UNC ART INT; Nesterov Y., 2007, 200776 CORE; Nesterov Y., 2003, INTRO LECT CONVEX OP; Obozinski G., 2006, MULTITASK FEATURE SE; OBOZINSKI G, 2008, ADV NEURAL INFORM PR; OSBORNE M, 1999, J COMPUTATIONAL GRAP, V9, P319; QUATTONI A, 2009, P INT C MACH LEARN; Rockafellar R. T., 1998, VARIATIONAL ANAL; THRUM S, 1998, LEARNING LEARN; Tseng P., 2008, SIAM J OPTIMIZ UNPUB; Turlach B., 2005, TECHNOMETRICS, V27, P349; ZHANG J, THESIS CARNEGIE MELL; Zinkevich M., 2003, P INT C MACH LEARN	26	23	25	0	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-4786		978-1-4244-5242-2	IEEE DATA MINING			2009							746	751		10.1109/ICDM.2009.128		6	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTL37	WOS:000287216600081		
S	Kujala, J; Aho, T; Elomaa, T		Wang, W; Kargupta, H; Ranka, S; Yu, PS; Wu, XD		Kujala, Jussi; Aho, Timo; Elomaa, Tapio			A Walk from 2-Norm SVM to 1-Norm SVM	2009 9TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING	IEEE International Conference on Data Mining		English	Proceedings Paper	9th IEEE International Conference on Data Mining	DEC 06-09, 2009	Miami Beach, FL	Knime, Mitre, CRC Press			SHRINKAGE	This paper studies how useful the standard 2-norm regularized SVM is in approximating the 1-norm SVM problem. To this end, we examine a general method that is based on iteratively re-weighting the features and solving a 2-norm optimization problem. The convergence rate of this method is unknown. Previous work indicates that it might require an excessive number of iterations. We study how well we can do with just a small number of iterations. In theory the convergence rate is fast, except for coordinates of the current solution that are close to zero. Our empirical experiments confirm this. In many problems with irrelevant features, already one iteration is often enough to produce accuracy as good as or better than that of the 1-norm SVM. Hence, it seems that in these problems we do not need to converge to the 1-norm SVM solution near zero values. The benefit of this approach is that we can build something similar to the 1-norm regularized solver based on any 2-norm regularized solver. This is quick to implement and the solution inherits the good qualities of the solver such as scalability and stability.	[Kujala, Jussi; Aho, Timo; Elomaa, Tapio] Tampere Univ Technol, Dept Software Syst, FI-33101 Tampere, Finland	Kujala, J (reprint author), Tampere Univ Technol, Dept Software Syst, POB 553, FI-33101 Tampere, Finland.	jussi.kujala@tut.fi; timo.aho@tut.fi; tapio.elomaa@tut.fi	Elomaa, Tapio/G-4233-2014				BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Mangasarian OL, 2006, J MACH LEARN RES, V7, P1517; Argyriou A., 2007, ADV NEURAL INFORM PR, V19, P41; Bottou L., 2008, ADV NEURAL INFORM PR, V20, P161; Franc V., 2008, P 25 INT C MACH LEAR, P320, DOI 10.1145/1390156.1390197; Friedman JH, 2004, GRADIENT DIRECTED RE; Grandvalet Y, 1999, ADV NEUR IN, V11, P445; Grandvalet Y., 1998, PERSPECTIVES NEURAL, V1, P201; Hsieh C.J., 2008, P 25 INT C MACH LEAR, P408, DOI [10.1145/1390156.1390208, DOI 10.1145/1390156.1390208]; Hsu C.-W., 2003, PRACTICAL GUIDE SUPP; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Joachims Thorsten, 2006, P 12 ACM SIGKDD INT, P217, DOI DOI 10.1145/1150402.1150429; Ng A. Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435; Schmidt M., 2007, P 18 EUR C MACH LEAR, P286; Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807, DOI DOI 10.1145/1273496.1273598; Zhu J., 2004, ADV NEURAL INFORM PR, V16	17	3	3	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-4786		978-1-4244-5242-2	IEEE DATA MINING			2009							836	841		10.1109/ICDM.2009.100		6	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTL37	WOS:000287216600096		
S	Lin, DY; Foster, DP		Wang, W; Kargupta, H; Ranka, S; Yu, PS; Wu, XD		Lin, Dongyu; Foster, Dean P.			VIF Regression: A Fast Regression Algorithm For Large Data	2009 9TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING	IEEE International Conference on Data Mining		English	Proceedings Paper	9th IEEE International Conference on Data Mining	DEC 06-09, 2009	Miami Beach, FL	Knime, Mitre, CRC Press		variable selection; stepwise regression; variance inflation factor; false discovery rate	SELECTION	We propose a fast regression algorithm that can substantially reduce the computational complexity of searching, yet retain good accuracy. It also guarantees to discover correlated features that are collectively predictive, and avoid model over-fitting. Its capability of controlling mFDR (marginal False Discovery Rate) statistically enables the one-pass. search of the fast algorithm and guarantees the accuracy of the sparse model chosen by the algorithm without cross validation. Numerical results show that our algorithm is much faster than any other algorithm and is competitively as accurate as the best but slower algorithms.	[Lin, Dongyu; Foster, Dean P.] Univ Penn, Wharton Sch, Dept Stat, Philadelphia, PA 19104 USA	Lin, DY (reprint author), Univ Penn, Wharton Sch, Dept Stat, Philadelphia, PA 19104 USA.	dongyu@wharton.upenn.edu; dean@foster.net					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Efron B., 2004, ANN STAT, V32; FOSTER DP, 2008, J R STAT SOC B, V70; Friedman J. H., 2008, FAST SPARSE REGRESSI; ZHANG T, 2009, ADV NEURAL INFORM PR, V21; Zhou J, 2006, J MACH LEARN RES, V7, P1861	7	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-4786		978-1-4244-5242-2	IEEE DATA MINING			2009							848	853		10.1109/ICDM.2009.146		6	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTL37	WOS:000287216600098		
S	Liu, B; Chen, S; Qian, MJ; Zhang, CS		Wang, W; Kargupta, H; Ranka, S; Yu, PS; Wu, XD		Liu, Bin; Chen, Shuo; Qian, Mingjie; Zhang, Changshui			Sparse Norm-Regularized Reconstructive Coefficients Learning	2009 9TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING	IEEE International Conference on Data Mining		English	Proceedings Paper	9th IEEE International Conference on Data Mining	DEC 06-09, 2009	Miami Beach, FL	Knime, Mitre, CRC Press		support vector machine; l(1)-norm; sparse	REGRESSION	Inspired by the fact that the final decision rule is mainly affected by a small subset of the training samples, i.e., Support Vector Machine(SVM) shows that the decision function relies on the few samples that are on or over the margin. We propose a new framework that explicitly strengthen this intuitive fact by adding an l(1)-norm regularizer. We give different formulations for our framework in different scenarios, and the experiments show that our framework can not only lead to high sparse solutions but also better performance than traditional methods.	[Liu, Bin; Chen, Shuo; Qian, Mingjie; Zhang, Changshui] Tsinghua Univ, Dept Automat, Tsinghua Natl Lab Informat Sci & Technol TNList, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China	Liu, B (reprint author), Tsinghua Univ, Dept Automat, Tsinghua Natl Lab Informat Sci & Technol TNList, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.	liubin07@mails.tsinghua.edu.cn; chenshuo071@mails.tsinghua.edu.cn; qian.mingjie@gmail.com; zcs@mail.tsinghua.edu.cn					Alavi Y, 1991, GRAPH THEORY COMBINA, V2, P871; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Rosipal R, 2002, J MACH LEARN RES, V2, P97, DOI 10.1162/15324430260185556; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Belkin M., 2005, P 10 INT WORKSH ART; Bennett KP, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Blake C.L., 1998, UCI REPOSITORY MACHI; Boser B. E., 1992, COMPUTATIONAL LEARNI, P144; Chan A. B., 2007, P 24 INT C MACH LEAR, P145, DOI 10.1145/1273496.1273515; Chang C., 2001, LIBSVM LIB SUPPORT V; Cvetkovic D. M., 1980, SPECTRA GRAPHS THEOR; Grant M., CVX MATLAB SOFTWARE; Hirsch M.W., 1977, INVARIANT MANIFOLDS; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; MOSEK A, MOSEK OPTIMIZATION T; Nene S.A., CUCS00696; Scholkopf B, 2001, ADV NEUR IN, V13, P301; Sonnenburg S., 2006, ADV NEURAL INFORM PR, V18, P1273; Vapnik V., 2000, NATURE STAT LEARNING; Vapnik V, 1997, ADV NEUR IN, V9, P281; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751	22	0	0	1	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-4786		978-1-4244-5242-2	IEEE DATA MINING			2009							854	859		10.1109/ICDM.2009.106		6	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTL37	WOS:000287216600099		
S	Sharon, Y; Wright, J; Ma, Y			IEEE	Sharon, Yoav; Wright, John; Ma, Yi			Minimum Sum of Distances Estimator: Robustness and Stability	2009 AMERICAN CONTROL CONFERENCE, VOLS 1-9	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2009	JUN 10-12, 2009	St Louis, MO					We consider the problem of estimating a state x from noisy and corrupted linear measurements y = Ax + z + e, where z is a dense vector of small-magnitude noise and e is a relatively sparse vector whose entries can be arbitrarily large. We study the behavior of the l(1) estimator (x) over cap = arg min(x) parallel to y - Ax parallel to(1), and analyze its breakdown point with respect to the number of corrupted measurements parallel to e parallel to(0). We show that the breakdown point is independent of the noise. We introduce a novel algorithm for computing the breakdown point for any given A, and provide a simple bound on the estimation error when the number of corrupted measurements is less than the breakdown point. As a motivational example we apply our algorithm to design a robust state estimator for an autonomous vehicle, and show how it can significantly improve performance over the Kalman filter.	[Sharon, Yoav; Wright, John; Ma, Yi] Univ Illinois, Dept Elect & Comp Engn, Coordinated Sci Lab, Urbana, IL 61801 USA	Sharon, Y (reprint author), Univ Illinois, Dept Elect & Comp Engn, Coordinated Sci Lab, Urbana, IL 61801 USA.	ysharon@illinois.edu; jnwright@illinois.edu; yima@illinois.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Candes E. J., 2006, HIGHLY ROBUST ERROR; Donoho D., 2006, IEEE T INFO THEORY; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; DONOHO DL, 2008, J AM MATH S IN PRESS; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; LOPUHAA HP, 1991, ANN STAT, V19, P229, DOI 10.1214/aos/1176347978; MEINSHAUSEN N, 2008, ANN STAT IN PRESS; Needell D., 2008, COSAMP ITERATIVE SIG	10	2	2	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619		978-1-4244-4523-3	P AMER CONTR CONF			2009							524	530		10.1109/ACC.2009.5160571		7	Automation & Control Systems	Automation & Control Systems	BLF29	WOS:000270044900086		
S	Gorinevsky, D; Boyd, S; Poll, S			IEEE	Gorinevsky, Dimitry; Boyd, Stephen; Poll, Scott			Estimation of Faults in DC Electrical Power System	2009 AMERICAN CONTROL CONFERENCE, VOLS 1-9	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2009	JUN 10-12, 2009	St Louis, MO				HARMONIC STATE ESTIMATION; IDENTIFICATION	This paper demonstrates a novel optimization-based approach to estimating fault states in a DC power system. The model includes faults changing the circuit topology along with sensor faults. Our approach can be considered as a relaxation of the mixed estimation problem. We develop a linear model of the circuit and pose a convex problem for estimating the faults and other hidden states. A sparse fault vector solution is computed by using l(1) regularization. The solution is computed reliably and efficiently, and gives accurate diagnostics on the faults. We demonstrate a real-time implementation of the approach for an instrumented electrical power system testbed at NASA. Accurate estimates of multiple faults are computed in milliseconds on a PC. The approach performs well despite unmodeled transients and other modeling uncertainties present in the system.	[Gorinevsky, Dimitry] Mitek Analyt LLC, Palo Alto, CA 94306 USA	Gorinevsky, D (reprint author), Mitek Analyt LLC, Palo Alto, CA 94306 USA.	dimitry@mitekan.com; boyd@stanford.edu; scott.poll@nasa.gov					Abur A., 2004, POWER SYSTEM STATE E; Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zymnis A, 2009, SIGNAL PROCESS, V89, P989, DOI 10.1016/j.sigpro.2008.11.014; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; BARAN ME, 1999, WILEY ENCY ELECT ELE; BOSE A, 1987, P IEEE, V75, P1607, DOI 10.1109/PROC.1987.13930; Clements KA, 1998, IEEE T POWER SYST, V13, P347, DOI 10.1109/59.667350; DAIGLE M, T I MEASURE IN PRESS; Davidson EM, 2003, IEEE T POWER SYST, V18, P680, DOI 10.1109/TPWRS.2003.810981; Gonzalez AJ, 1996, IEEE T SYST MAN CY A, V26, P470, DOI 10.1109/3468.508825; IRVING MR, 1978, P I ELECTR ENG, V125, P879; KELLER K, 2006, IEEE AER C MARCH BIG; Korres GN, 2002, IEEE T POWER SYST, V17, P818, DOI 10.1109/TPWRS.2002.800943; KOTIUGA WW, 1982, IEEE T POWER AP SYST, V101, P844, DOI 10.1109/TPAS.1982.317150; Li Liu, 2007, IEEE Transactions on Vehicular Technology, V56, DOI 10.1109/TVT.2007.897219; Liao HW, 2007, IEEE T POWER SYST, V22, P15, DOI 10.1109/TPWRS.2006.887957; MELIOPOULOS APS, 1994, IEEE T POWER DELIVER, V9, P1701, DOI 10.1109/61.311191; MENGSHOEL OJ, 2008, 20 INN APPL ART INT; Monticelli A., 1999, STATE ESTIMATION ELE; *MOSEK APS, 2007, MOSEK OPT TOOLS VERS; MUZI F, 2007, IEEE POW ENG SOC GEN; Pillage L., 1998, ELECT CIRCUIT SYSTEM; POLL S, 2007, 18 INT WORKSH PRINC, P178; Qin S.J., 1997, AICHE S SER, V93, P232; SINGH H, 1995, IEEE T POWER SYST, V10, P1159, DOI 10.1109/59.466541; Spyker R., 2005, EL INS C EL MAN EXP, P146; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Zymnis A, 2008, IEEE DECIS CONTR P, P3219	30	14	14	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619		978-1-4244-4523-3	P AMER CONTR CONF			2009							4334	4339		10.1109/ACC.2009.5160301		6	Automation & Control Systems	Automation & Control Systems	BLF29	WOS:000270044902059		
S	Li, JT; Jia, YM; Du, JP; Yu, FS			IEEE	Li, Juntao; Jia, Yingmin; Du, Junping; Yu, Fashan			A New Support Vector Machine for Microarray Classification and Adaptive Gene Selection	2009 AMERICAN CONTROL CONFERENCE, VOLS 1-9	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2009	JUN 10-12, 2009	St Louis, MO			Gene selection; grouping effect; microarray classification; solution path; support vector machine (SVM)	REGRESSION; REGULARIZATION; ALGORITHM; CANCER	This paper presents a new support vector machine for simultaneous gene selection and microarray classification. By introducing the adaptive elastic net penalty which is a convex combination of weighted 1-norm penalty and weighted 2-norm penalty, the proposed support vector machine can encourage an adaptive grouping effect and reduce the shrinkage bias for the large coefficients. According to a reasonable correlation between the two regularization parameters, the optimal coefficient paths are shown to be piecewise linear and the corresponding solving algorithm is developed. Experiments are performed on leukaemia data that verify the research results.	[Li, Juntao; Jia, Yingmin] Beihang Univ BUAA, Res Div 7, Beijing 100191, Peoples R China	Li, JT (reprint author), Beihang Univ BUAA, Res Div 7, Beijing 100191, Peoples R China.	juntaolimail@yahoo.com.cn					Park MY, 2008, BIOSTATISTICS, V9, P30, DOI 10.1093/biostatistics/kxm010; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhu J, 2004, ADV NEUR IN, V16, P49; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; Wang L, 2008, BIOINFORMATICS, V24, P412, DOI 10.1093/bioinformatics/btm579; Wang L, 2006, STAT SINICA, V16, P589; Bradley P., 1998, P 15 INT C MACH LEAR; Dong JX, 2005, IEEE T PATTERN ANAL, V27, P603; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Jiao LC, 2007, IEEE T NEURAL NETWOR, V18, P685, DOI 10.1109/TNN.2006.889500; MA S, 2007, BIOINFORMATICS, V8; MUKHERJEE S, 2000, SUPPORT VECTOR MACHI; Park MY, 2007, BIOSTATISTICS, V8, P212, DOI 10.1093/biostatistics/kxl002; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Vapnik V.N., 1995, NATURE STAT LEARNING; ZHU J, 2004, BIOSTATISTICS, V46, P505; Zou H., 2007, 11 INT C ART INT STA	25	3	3	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619		978-1-4244-4523-3	P AMER CONTR CONF			2009							5410	5415		10.1109/ACC.2009.5160235		6	Automation & Control Systems	Automation & Control Systems	BLF29	WOS:000270044902237		
S	Madar, A; Greenfield, A; Ostrer, H; Vanden-Eijnden, E; Bonneau, R			IEEE	Madar, Aviv; Greenfield, Alex; Ostrer, Harry; Vanden-Eijnden, Eric; Bonneau, Richard			The Inferelator 2.0: a scalable framework for reconstruction of dynamic regulatory network models.	2009 ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-20	IEEE Engineering in Medicine and Biology Society Conference Proceedings		English	Proceedings Paper	Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society	SEP 03-06, 2009	Minneapolis, MN	IEEE Engn Med & Biol Soc				Current methods for reconstructing biological networks often learn either the topology of large networks or the kinetic parameters of smaller networks with a well-characterized topology. We have recently described a network reconstruction algorithm, the Inferelator 1.0, that given a set of genome-wide measurements as input, simultaneously learns both topology and kinetic-parameters. Specifically, it learns a system of ordinary differential equations (ODEs) that describe the rate of change in transcription of each gene or gene-cluster, as a function of environmental and transcription factors. In order to scale to large networks, in Inferelator 1.0 we have approximated the system of ODEs to be uncoupled, and have solved each ODE using a one-step finite difference approximation. Naturally, these approximations become crude as the simulated time-interval increases. Here we present, implement, and test a new Markov-Chain-Monte-Carlo (MCMC) dynamical modeling method, Inferelator 2.0, that works in tandem with Inferelator 1.0 and is designed to relax these approximations. We show results for the prokaryote Halobacterium that demonstrate a marked improvement in our predictive performance in modeling the regulatory dynamics of the system over longer time-scales.	[Madar, Aviv; Vanden-Eijnden, Eric; Bonneau, Richard] NYU, Courant Inst Math Sci, New York, NY 10003 USA	Madar, A (reprint author), NYU, Courant Inst Math Sci, 251 Mercer St, New York, NY 10003 USA.	bonneau@nyu.edu					Wikle CK, 2007, PHYSICA D, V230, P1, DOI 10.1016/j.physd.2006.09.017; Bonneau R, 2007, CELL, V131, P1354, DOI 10.1016/j.cell.2007.10.053; Bonneau R, 2008, NAT CHEM BIOL, V4, P658, DOI 10.1038/nchembio.122; Bonneau R, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-5-r36; Efron B., 2003, ANN STAT; Farmer CL, 2007, Algorithms for Approximation, Proceedings, P147, DOI 10.1007/978-3-540-46551-5_12; Gardiner C W, 1985, HDB STOCHASTIC METHO; Hastie T., 2001, ELEMENTS STAT LEARNI; JAMES SC, 2003, INTRO STOCHASTIC SEA; Liu J.S., 2001, SPRINGER SERIES STAT; Reiss DJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-280; Tibshirani R., 1996, J ROYAL STAT SOC B	12	3	3	0	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1557-170X		978-1-4244-3295-0	IEEE ENG MED BIO			2009							5448	5451		10.1109/IEMBS.2009.5334018		4	Engineering, Biomedical	Engineering	BQB05	WOS:000280543604089		
B	Li, JM; Qian, YT		Shi, H; Zhang, YC; Bottema, MJ; Lovell, BC; Maeder, AJ		Li, Jiming; Qian, Yuntao			Regularized Multinomial Regression Method for Hyperspectral Data Classification via Pathwise Coordinate Optimization	2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009)			English	Proceedings Paper	11th Conference on Digital Image Computing: Techniques and Applications	DEC 01-03, 2009	Melbourne, AUSTRALIA			hyperspectral; classification; feature selection; pathwise coordinate descent	SUPPORT VECTOR MACHINES; REMOTE-SENSING IMAGES; BAND SELECTION; LASSO	Hyperspectral imagery generally contains enormous amounts of data due to hundreds of spectral bands. As recent researchers have discovered, many of the bands are highly correlated and may provide redundant information for the classification related problems. Therefore, feature selection is very important in hyperspectral image processing problem. "Pathwise Coordinate Descent" algorithm is the "one-at-a-time" coordinate-wise descent algorithm for a class of convex optimization problems. When applied on the L1-regularized regression (lasso) problem, the algorithm can handle large problems and can also efficiently obtain sparse features in a comparatively very low timing cost. Through computing the solutions for a decreasing sequence of regularization parameters, the algorithm also combines model selection procedure into itself. In this paper, we utilize the multinomial logistic regression with lasso, elastic-net convex penalties on hyperspectral image classification. Pathwise Coordinate Descent is used for estimation these models. Experimental results demonstrate that, in the context of the hyperspectral data classification problem, models obtained by Pathwise Coordinate Descent algorithm do effectively achieve a sparse feature subsets and very good classification results with very low computational costs.	[Li, Jiming; Qian, Yuntao] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China	Li, JM (reprint author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.	ljming@zju.edu.cn; ytqian@zju.edu.cn					Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; [Anonymous], AVIRIS NW INDIANAS I; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; ARCHIBALD GFR, 2007, IEEE GEOSCI REMOTE S, V4, P674; Archibald R, 2007, IEEE GEOSCI REMOTE S, V4, P674, DOI 10.1109/LGRS.2007.905116; Bazi Y, 2006, IEEE T GEOSCI REMOTE, V44, P3374, DOI 10.1109/TGRS.2006.880628; Chang C.-I., 2003, HYPERSPECTRAL IMAGIN; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; Chi MM, 2007, IEEE T GEOSCI REMOTE, V45, P1870, DOI 10.1109/TGRS.2007.894550; Friedman J., 2008, REGULARIZATION PATHS; Jimenez-Rodriguez LO, 2007, IEEE T GEOSCI REMOTE, V45, P469, DOI 10.1109/TGRS.2006.885412; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951; Neher R, 2005, IEEE T GEOSCI REMOTE, V43, P1363, DOI 10.1109/TGRS.2005.846865; SERPICO BS, 2001, IEEE T GEOSCI REMOTE, V39, P1360; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3	18	1	1	2	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5297-2				2009							540	545		10.1109/DICTA.2009.89		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BUV70	WOS:000290469200078		
B	Patel, R; Liu, J; Chen, KW; Reiman, EM; Alexander, G; Ye, JP			IEEE	Patel, Rinkal; Liu, Jun; Chen, Kewei; Reiman, Eric; Alexander, Gene; Ye, Jieping			Sparse Inverse Covariance Analysis of Human Brain for Alzheimer's Disease Study	2009 ICME INTERNATIONAL CONFERENCE ON COMPLEX MEDICAL ENGINEERING			English	Proceedings Paper	ICME International Conference on Complex Medical Engineering	APR 09-11, 2009	Tempe, AZ	ICME			SELECTION	Analysis of functional neuroimaging data in the studies of human brain has become very critical in understanding neuro-degenerative diseases such as Alzheimer's disease (AD). The most common approach in AD neuroimaging studies has been of univariate nature, where individual brain regions/voxels are analyzed separately. In many cases these techniques prove to be effective. However, they could not shed light on inter brain region connectivity associated with the brain function or disease of interest. Indeed, human brain is a very complex organ anatomically and the functional interactions between its regions are even more. As a result, there is a need to understand this interdependency or inter-connection of brain regions. There are several existing techniques to address this issue. They include principal component analysis (PCA), PCA based scaled subprofile modeling (SSM), Bayesian network approach and independent component analysis (ICA). In this study, we propose a machine learning technique called "Sparse Inverse Covariance Analysis" to learn the brain region interactivity, with minimal computational cost and appropriate degree of sparsity. Under Gaussian assumption, each element of the inverse covariance matrix represents conditional dependence between the constituent pair. of variables, given all other variables. By introducing sparsity constraint, unnecessary/noisy functional dependencies are eliminated by setting the constituent element to zero, resulting into conditional independence between the variable pairs. Using functional FDG-PET data acquired from 49 AD and 67 normal subjects from the Alzheimer's disease neuroimaging initiative (ADNI) project, we evaluate this technique in terms of distinct brain region connectivity pattern in patients with AD compared to that in normal control subjects. It was found that the patients with AD had disconnections that are not present in the normal controls. This different connectivity pattern is potentially usable for clinical diagnosis and for establishing sensitive markers for the disease progression and treatment evaluation.	[Patel, Rinkal; Liu, Jun] Arizona State Univ, Dept Comp Sci, Tempe, AZ 85287 USA	Chen, KW (reprint author), Univ Arizona, Dept Radiol, Banner Alzheimers Inst, Tucson, AZ 85721 USA.	rinkal@asu.edu; j.liu@asu.edu; kchen@math.la.asu.edu; Eric.Reiman@bannerhealth.com; Gene.Alexander@asu.edu; jieping.ye@asu.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Banerjee O, 2008, J MACH LEARN RES, V9, P485; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Dempster A. P., 1972, BIOMETRICS, V28; FRIEDMAN J, SPARSE INVERSE COVAR; Jolliffe IT, 2002, SPRINGER SERIES STAT, VXXIX; Jordan M., 1999, LEARNING GRAPHICAL M; MOLCHAN S, 2005, BUSINESS BRIEFING US, P30; NIDA, NIH PUBL, V10-5771; NIH, 2003, NIH PUBL, V03-5387; SMITH JF, NETWORK ANAL SINGLE	11	0	0	0	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3315-5				2009							5	9				5	Engineering, Biomedical; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	BMF84	WOS:000272211300002		
S	Mairal, J; Bach, F; Ponce, J; Sapiro, G; Zisserman, A			IEEE	Mairal, Julien; Bach, Francis; Ponce, Jean; Sapiro, Guillermo; Zisserman, Andrew			Non-local Sparse Models for Image Restoration	2009 IEEE 12TH INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)	IEEE International Conference on Computer Vision		English	Proceedings Paper	12th IEEE International Conference on Computer Vision	SEP 29-OCT 02, 2009	Kyoto, JAPAN	IEEE, IEEE Comp Soc			REGRESSION; SELECTION; DICTIONARIES; SHRINKAGE; DOMAIN	We propose in this paper to unify two different approaches to image restoration: On the one hand, learning a basis set (dictionary) adapted to sparse signal descriptions has proven to be very effective in image reconstruction and classification tasks. On the other hand, explicitly exploiting the self-similarities of natural images has led to the successful non-local means approach to image restoration. We propose simultaneous sparse coding as a framework for combining these two approaches in a natural manner. This is achieved by jointly decomposing groups of similar signals on subsets of the learned dictionary. Experimental results in image denoising and demosaicking tasks with synthetic and real noise show that the proposed method outperforms the state of the art, making it possible to effectively restore raw images from digital cameras at a reasonable speed and memory cost.								Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI [10.1109/TIP.2002.801121, 10.1109/TIP/2002.801121]; Zhang L, 2005, IEEE T IMAGE PROCESS, V14, P2167, DOI 10.1109/TIP.2005.857260; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Turlach BA, 2005, TECHNOMETRICS, V47, P349, DOI 10.1198/004017005000000139; Efron B, 2004, ANN STAT, V32, P407; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Awate S., 2006, IEEE T PAMI, P364; Bertalmio M., 2000, P COMP GRAPH INT TEC; Buades A., 2005, P IEEE CVPR; Buades A., 2007, 200715 CMLA; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Efros A. A., 1999, P ICCV; Li Y., 2008, P ECCV; Mairal J., 2009, ONLINE DICT LEARNING; Mallat S., 1999, WAVELET TOUR SIGNAL; Paliy D., 2007, INT J IMAG SYS TECH, V17; Puetter RC, 2005, ANNU REV ASTRON ASTR, V43, P139, DOI 10.1146/annurev.astro.43.112904.104850; Roth S., 2005, P IEEE CVPR; Rudin L., 1994, P ICIP; Szlam A., 2007, JMLR; Weisberg S., 1980, APPL LINEAR REGRESSI	32	218	226	3	25	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-5499		978-1-4244-4419-9	IEEE I CONF COMP VIS			2009							2272	2279		10.1109/ICCV.2009.5459452		8	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BWU77	WOS:000294955300293		
B	Harrington, PL; Rao, A; Hero, AO			IEEE	Harrington, Patrick L., Jr.; Rao, Arvind; Hero, Alfred O., III			CLASSIFICATION OF MULTIPLE TIME-SERIES VIA BOOSTING	2009 IEEE 13TH DIGITAL SIGNAL PROCESSING WORKSHOP & 5TH IEEE PROCESSING EDUCATION WORKSHOP, VOLS 1 AND 2, PROCEEDINGS			English	Proceedings Paper	13th IEEE Digital Signal Processing Workshop/5th IEEE Signal Processing Education Workshop	JAN 04-07, 2009	Marco Isl, FL	IEEE, IEEE Signal Proc Soc		Boosting; Time-Series; Additive Models	REGRESSION	Much of modem machine learning and statistics research consists of extracting information from high-dimensional patterns. Often times, the large number of features that comprise this high-dimensional pattern are themselves vector valued, corresponding to sampled values in a time-series. Here, we present a classification methodology to accommodate multiple time-series using boosting. This method constructs an additive model by adaptively selecting basis functions consisting of a discriminating feature's full time-series. We present the necessary modifications to Fisher Linear Discriminant Analysis and Least-Squares, as base learners, to accommodate the weighted data in the proposed boosting procedure. We conclude by presenting the performance of our proposed method against a synthetic stochastic differential equation data set and a real world data set involving prediction of cancer patient susceptibility for a particular chemoradiotherapy.	[Harrington, Patrick L., Jr.; Hero, Alfred O., III] Univ Michigan, Bioinformat Grad Program, Ann Arbor, MI 48109 USA	Harrington, PL (reprint author), Univ Michigan, Bioinformat Grad Program, Ann Arbor, MI 48109 USA.	plhjr@umich.edu; ukarvind@andrew.cmu.edu; hero@umich.edu					Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHAN AB, 2007, ICML 07, P145; Daemen Anneleen, 2008, Pac Symp Biocomput, P166; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODELS; Hero A. O., 2007, FDN APPL SENSOR MANA; Moghaddam B., 2006, P ICML; SCHAPIRE RE, 1999, ALGORITHMIC LEARNING, V1720, P13, DOI 10.1007/3-540-46769-6_2; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V.N., 1995, NATURE STAT LEARNING	15	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3676-7				2009							410	415		10.1109/DSP.2009.4785958		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BKB98	WOS:000267715800074		
B	Li, X		Tang, TA; Zeng, XY; Chen, Y; Yu, HH		Li, Xin			Large-Scale Analog/RE Performance Modeling by Statistical Regression	2009 IEEE 8TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS			English	Proceedings Paper	IEEE 8th International Conference on ASIC	OCT 20-23, 2009	Changsha, PEOPLES R CHINA	IEEE Beijing Sect, Fudan Univ, IEEE China Council, Natl Univ Def Tech, IEEE CAS, IEEE SSCS, Chinese Inst Elect		Process Variation; Performance Modeling		In this paper, we introduce several large-scale modeling techniques to analyze the high-dimensional, strongly-nonlinear performance variability observed in nanoscale manufacturing technologies. Our goal is to solve a large number of (e.g., 10(4)similar to 10(6)) model coefficients from a small set of (e.g., 10(2)similar to 10(3)) sampling points without over-fitting. This is facilitated by exploiting the underlying sparsity of model coefficients. Our circuit example designed in a commercial 65nm process demonstrates that the proposed techniques achieve 25x speedup compared with the traditional response surface modeling(1).	Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Li, X (reprint author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.	xinli@ece.cmu.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Hastie T, 2003, ELEMENTS STAT LEARNI; Li X, 2004, ICCAD-2004: INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, IEEE/ACM DIGEST OF TECHNICAL PAPERS, P2; Li X., 2008, IEEE DAC, P38; LI X, 2009, IEEE DAC; Li X, 2005, IEEE IC CAD, P721; Mitev A, 2007, IEEE IC CAD, P632; Seber G., 1984, WILEY SERIES; Semiconductor Industry Association, 2007, INT TECHN ROADM SEM; SINGHEE A, 2007, IEEE DAC, P256; Vandenberghe L., 2004, CONVEX OPTIMIZATION	12	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3868-6				2009							646	649		10.1109/ASICON.2009.5351329		4	Engineering, Electrical & Electronic	Engineering	BNZ26	WOS:000275924100159		
S	Li, YQ; Yu, ZL; Namburi, P; Guan, CT			IEEE	Li, Yuanqing; Yu, Zhuliang; Namburi, Praneeth; Guan, Cuntai			VOXEL SELECTION IN FMRI DATA ANALYSIS: A SPARSE REPRESENTATION METHOD	2009 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1- 8, PROCEEDINGS	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	APR 19-24, 2009	Taipei, TAIWAN	IEEE, IEEE Signal Proc Soc		Functional magnetic resonance imaging (fMRI); voxel selection; sparse representation; statistical parametric mapping (SPM); prediction		This paper proposes an iterative sparse representation-based algorithm for voxel selection in functional magnetic resonance imaging (fMRI) data. The output of the algorithm is a sparse weight vector, of which the magnitude of each entry represents the significance of its corresponding voxel with respect to mental tasks or stimulus. To demonstrate the validity of our algorithm and illustrate its application, we apply this algorithm to the Pittsburgh Brain Activity Interpretation Competition (PBAlC) 2007 fMRI data set for selecting the voxels which are the most relevant to the tasks of the subjects. Compared with three baseline methods, general linear model (GLM)-based statistical parametric mapping (SPM), correlation method and mutual information method, our method shows satisfactory performance for voxel selection.	[Li, Yuanqing; Yu, Zhuliang] S China Univ Technol, Sch Automat, Guangzhou 510640, Guangdong, Peoples R China	Li, YQ (reprint author), S China Univ Technol, Sch Automat, Guangzhou 510640, Guangdong, Peoples R China.	auyqli@scut.edu.cn					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Cox DD, 2003, NEUROIMAGE, V19, P261, DOI 10.1016/S1053-8119(03)00049-1; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; Kidron E, 2007, IEEE T SIGNAL PROCES, V55, P1390, DOI 10.1109/TSP.2006.888095; LI Y, 2004, NEURAL COMPUTATION, V16; MEYER F, 2007, P 21 ANN C NEUR INF; SCHNEIDER W, PITTSBURGH BRAIN ACT	10	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-2353-8	INT CONF ACOUST SPEE			2009							413	416				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BKQ01	WOS:000268919200104		
S	Shen, B; Hu, W; Zhang, YM; Zhang, YJ			IEEE	Shen, Bin; Hu, Wei; Zhang, Yimin; Zhang, Yu-Jin			IMAGE INPAINTING VIA SPARSE REPRESENTATION	2009 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1- 8, PROCEEDINGS	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	APR 19-24, 2009	Taipei, TAIWAN	IEEE, IEEE Signal Proc Soc		Image inpainting; texture synthesis; sparse representation; Lasso; L1 norm minimization		This paper proposes a novel patch-wise image inpainting algorithm using the image signal sparse representation over a redundant dictionary, which merits in both capabilities to deal with large holes and to preserve image details while taking less risk. Different from all existing works, we consider the problem of image inpainting from the view point of sequential incomplete signal recovery under the assumption that the every image patch admits a sparse representation over a redundant dictionary. To ensure the visually plausibility and consistency constraints between the filled hole and the surroundings, we propose to construct a redundant signal dictionary by directly sampling from the intact source region of current image. Then we sequentially compute the sparse representation for each incomplete patch at the boundary of the hole and recover it until the whole hole is filled. Experimental results show that this approach can efficiently fill in the hole with visually plausible information, and take less risk to introduce unwanted objects or artifacts.	[Shen, Bin; Zhang, Yu-Jin] Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Shen, B (reprint author), Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	chenbin03@mails.tsinghua.edu.cn; wei.hu@intel.com; yimin.zhang@intel.com; zhang-yj@mail.tsinghua.edu.cn					Aharon M., 2005, P SPARS, P9; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; BERTALMIO M, SIGGRAPH 2000; CHEN Q, 2007, LNCS, V477, P242; CHEN Y, ICIP 2006; CRIMINISI A, CVPR 2003; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; EFROS AA, ICCV 1999; EFROS AA, SIGGRAPH 2001; GROSSAUER H, ECCV 2004; GUO C, ICCV 2003; Huang J. Z., CVPR 2008; JIA J, CVPR 2003; MASNOU S, ICIP 1998; SUN J, SIGGRAPH 2005; WRIGHT J, IEEE T PATT IN PRESS	19	25	29	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-2353-8	INT CONF ACOUST SPEE			2009							697	700				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BKQ01	WOS:000268919200175		
S	Tian, Z; Leus, G; Lottici, V			IEEE	Tian, Zhi; Leus, Geert; Lottici, Vincenzo			DETECTION OF SPARSE SIGNALS UNDER FINITE-ALPHABET CONSTRAINTS	2009 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1- 8, PROCEEDINGS	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	APR 19-24, 2009	Taipei, TAIWAN	IEEE, IEEE Signal Proc Soc		compressed sensing; sparsity; finite alphabet; sphere decoding (SD)		In this paper, we solve the problem of detecting the entries of a sparse finite-alphabet signal from a limited amount of data, for instance obtained by compressive sampling. While existing methods either rely on the sparsity property, the finite-alphabet property, or none of those properties to solve the under-determined system of linear equations, we capitalize on both the sparsity and the finite-alphabet features of the signal. The problem is first formulated in a Bayesian framework to incorporate the prior knowledge of sparsity, which is then shown to be solvable using sphere decoding (SD) or semidefinite relaxation (SDR) for efficient Boolean programming. A few toy simulations show how our method can outperform existing works.	[Tian, Zhi] Michigan Technol Univ, Dept Elect & Comp Engn, Houghton, MI 49931 USA	Tian, Z (reprint author), Michigan Technol Univ, Dept Elect & Comp Engn, Houghton, MI 49931 USA.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Cui T, 2005, IEEE COMMUN LETT, V9, P423, DOI [10.1109/LCOMM.2005.1431159, 10.1109/LCOMM.2005.05021]; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; BAZERQUE JA, 2008, P AS C PAC GROV CA O; Duarte M, 2006, P IEEE ICASSP, P305; Ma WK, 2002, IEEE T SIGNAL PROCES, V50, P912; Scaglione A, 1999, IEEE T SIGNAL PROCES, V47, P1988, DOI 10.1109/78.771047; WIPF DP, 2002, IEEE T SIGNAL PROCES, V50, P912	9	8	8	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-2353-8	INT CONF ACOUST SPEE			2009							2349	2352				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BKQ01	WOS:000268919201127		
S	Chen, YL; Gu, YT; Hero, AO			IEEE	Chen, Yilun; Gu, Yuantao; Hero, Alfred O., III			SPARSE LMS FOR SYSTEM IDENTIFICATION	2009 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1- 8, PROCEEDINGS	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	APR 19-24, 2009	Taipei, TAIWAN	IEEE, IEEE Signal Proc Soc		LMS; compressive sensing; sparse models; zero-attracting; 11 norm relaxation		We propose a new approach to adaptive system identification when the system model is sparse. The approach applies l(1) relaxation, common in compressive sensing, to improve the performance of LMS-type adaptive methods. This results in two new algorithms, the zero-attracting LMS (ZA-LMS) and the reweighted zero-attracting LMS (RZA-LMS). The ZA-LMS is derived via combining a l(1) norm penalty on the coefficients into the quadratic LMS cost function, which generates a zero attractor in the LMS iteration. The zero attractor promotes sparsity in taps during the filtering process, and therefore accelerates convergence when identifying sparse systems. We prove that the ZA-LMS can achieve lower mean square error than the standard LMS. To further improve the filtering performance, the RZA-LMS is developed using a reweighted zero attractor. The performance of the RZA-LMS is superior to that of the ZA-LMS numerically. Experiments demonstrate the advantages of the proposed filters in both convergence rate and steady-state behavior under sparsity assumptions on the true coefficient vector. The RZA-LMS is also shown to be robust when the number of non-zero taps increases.	[Chen, Yilun; Hero, Alfred O., III] Univ Michigan, Dept EECS, Ann Arbor, MI 48109 USA	Chen, YL (reprint author), Univ Michigan, Dept EECS, Ann Arbor, MI 48109 USA.	yilun@umich.edu; gyt@tsinghua.edu.cn; hero@umich.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Duttweiler DL, 2000, IEEE T SPEECH AUDI P, V8, P508, DOI 10.1109/89.861368; Baraniuk R., 2007, IEEE SIGNAL PROCESSI, V25, P21; CANDES E, J FOURIER A IN PRESS; Candes E. J., 2006, INT C MATH, V3, P1433; Etter D. M., 1985, P ICASSP, P1169; Gay S. L., 1998, P 32 AS C SIGN SYST, V1, P394; Godavarti M, 2005, IEEE T SIGNAL PROCES, V53, P2382, DOI 10.1109/TSP.2005.849167; Homer J, 1998, IEEE T SIGNAL PROCES, V46, P2651, DOI 10.1109/78.720368; Kawamura S., 1986, P ICASSP, V11, P2979; Li Y., 2006, P ICASSP, V3, P109; Widrow B, 1985, ADAPTIVE SIGNAL PROC	12	108	112	1	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-2353-8	INT CONF ACOUST SPEE			2009							3125	3128				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BKQ01	WOS:000268919201321		
S	Angelosante, D; Giannakis, GB			IEEE	Angelosante, Daniele; Giannakis, Georgios B.			RLS-WEIGHTED LASSO FOR ADAPTIVE ESTIMATION OF SPARSE SIGNALS	2009 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1- 8, PROCEEDINGS	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	APR 19-24, 2009	Taipei, TAIWAN	IEEE, IEEE Signal Proc Soc		Lasso; Variable Selection; Sparsity; Tracking	NONCONCAVE PENALIZED LIKELIHOOD; ORACLE PROPERTIES; SELECTION	The batch least-absolute shrinkage and selection operator (Lasso) has well-documented merits for estimating sparse signals of interest emerging in various applications, where observations adhere to parsimonious linear regression models. To cope with linearly growing complexity and memory requirements that batch Lasso estimators face when processing observations sequentially, the present paper develops a recursive Lasso algorithm that can also track slowly-varying sparse signals of interest. Performance analysis reveals that recursive Lasso can either estimate consistently the sparse signal's support or its nonzero entries, but not both. This motivates the development of a weighted version of the recursive Lasso scheme with weights obtained from the recursive least-squares (RLS) algorithm. The resultant RLS-weighted Lasso algorithm provably estimates sparse signals consistently. Simulated tests compare competing alternatives and corroborate the performance of the novel algorithms in estimating time-invariant and tracking slow-varying signals under sparsity constraints.	[Angelosante, Daniele] Univ Cassino, I-03043 Cassino, Italy	Angelosante, D (reprint author), Univ Cassino, Via Di Biasio 43, I-03043 Cassino, Italy.						ANGELOSANTE D, 2008, IEEE T SIGNAL UNPUB; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Zou H, 2008, ANN STAT, V36, P1509, DOI 10.1214/009053607000000802; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; BAZERQUE JA, 2008, P 42 AS C PAC GROV C; Bertsekas D. P., 2003, NONLINEAR PROGRAMMIN; Kay S., 1993, FUNDAMENTALS STAT SI; MALIOUTOV DM, 2008, P ICASSP LAS VEG NV	12	17	18	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-2353-8	INT CONF ACOUST SPEE			2009							3245	3248		10.1109/ICASSP.2009.4960316		4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BKQ01	WOS:000268919201351		
S	Wang, CH; Yan, SC; Zhang, HJ			IEEE	Wang, Changhu; Yan, Shuicheng; Zhang, Hong-Jiang			LARGE SCALE NATURAL IMAGE CLASSIFICATION BY SPARSITY EXPLORATION	2009 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOLS 1- 8, PROCEEDINGS	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	APR 19-24, 2009	Taipei, TAIWAN	IEEE, IEEE Signal Proc Soc		Image classification; sparsity; l(1)-nearest-neighbor; k-nearest-neighbor; WordNet	SELECTION; LASSO	We consider in this paper the problem of large scale natural image classification. As the explosion and popularity of images in the Internet, there are increasing attentions to utilize millions of or even billions of these images for helping image related research. Beyond the opportunities brought by unlimited data, a great challenge is how to design more effective classification methods under these large scale scenarios. Most of existing attempts are based on k-nearest-neighbor method. However, in spite of the optimistic performance in some tasks, this strategy still suffers from that, one single fixed global parameter k is not robust for different object classes from different semantic levels. In this paper, we propose an alternative method, called l(1)-nearest-neighbor, based on a sparse representation computed by l(1)-minimization. We first treat a testing sample as a sparse linear combination of all training samples, and then consider the related samples as the nearest neighbors of the testing sample. Finally, we classify the testing sample based on the majority of these neighbors' classes. We conduct extensive experiments on a 1.6 million natural image database on different semantic levels defined based on WordNet, which demonstrate that the proposed l(1)-nearest-neighbor algorithm outperforms k-nearest-neighbor in two aspects: 1) the robustness of parameter selection for different semantic levels, and 2) the discriminative capability for large scale image classification task.	[Wang, Changhu] Univ Sci & Technol China, MOE MS Key Lab MCC, Hefei, Peoples R China	Wang, CH (reprint author), Univ Sci & Technol China, MOE MS Key Lab MCC, Hefei, Peoples R China.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; BELONGIE S, 2000, SHAPE CONTEXT NEW DE, P831; Berg A. C., 2005, CVPR, V1, P26, DOI DOI 10.1109/CVPR.2005.320; Candes E, 2006, IEEE T INFORM THEORY; Fellbaum C., 1998, WORDNET ELECT LEXICA; Field D., 1994, NEURAL COMPUTATION; JING F, 2006, IGROUP WEB IMAGE SEA; Olshausen B. A., 1997, VISION RES; SHAKHNAROVICH G, 2003, FAST POSE ESTIMATION; Torralba A., 2007, TINY IMAGES; WANG C, 2008, LEARNING REDUCE SEMA; WANG C, 2006, SCALABLE SEARCH BASE; Wright J., 2008, IEEE T PAMI; YEH T, 2004, SEARCHING WEB MOBILE	16	4	4	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-2353-8	INT CONF ACOUST SPEE			2009							3709	3712		10.1109/ICASSP.2009.4960432		4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BKQ01	WOS:000268919202002		
S	Feng, YJ; Yu, GQ; Wang, TL; Shih, IM; Wang, Y			IEEE	Feng, Yuanjian; Yu, Guoqiang; Wang, Tian-Li; Shih, Ie-Ming; Wang, Yue			Analyzing DNA Copy Number Changes Using Fused Margin Regression	2009 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE	IEEE International Conference on Bioinformatics and Biomedicine-BIBM		English	Proceedings Paper	IEEE International Conference on Bioinformatics and Biomedicine (BIBMW 2009)	NOV 01-04, 2009	Washington, DC	IEEE, IEEE Comp Soc, Natl Sci Fdn			ARRAY CGH DATA; CANCER; TUMORS; LASSO	DNA copy number change is an important form of structural variations in human genomes. Detecting copy number changes using DNA array data is a challenging task due to high density genomic loci, low signal to noise ratios, and normal tissue contamination. We propose fused margin regression (FMR) method that combines a variable fusion rule and robust epsilon-insensitive loss criterion to approximate piecewise constant segments of the underlying copy number profile. We tested FMR on both simulation and real CGH and SNP array datasets, and observed competitively improved performance as compared to several widely-adopted existing methods.	[Feng, Yuanjian; Yu, Guoqiang; Wang, Yue] Virginia Polytech Inst & State Univ, Dept Elect & Comp Engn, Arlington, VA USA	Feng, YJ (reprint author), Virginia Polytech Inst & State Univ, Dept Elect & Comp Engn, Arlington, VA USA.						Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Lai WR, 2005, BIOINFORMATICS, V21, P3763, DOI 10.1093/bioinformatics/bti611; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2008, BIOSTATISTICS, V9, P18, DOI 10.1093/biostatistics/kxm013; Venkatraman ES, 2007, BIOINFORMATICS, V23, P657, DOI 10.1093/bioinformatics/btl646; Hupe P, 2004, BIOINFORMATICS, V20, P3413, DOI 10.1093/bioinformatics/bth418; Kuo KT, 2009, CANCER RES, V69, P4036, DOI 10.1158/0008-5472.CAN-08-3913; Ben-Yaacov E, 2008, BIOINFORMATICS, V24, P139, DOI DOI 10.1093/BIOINFORMATICS/BTN272; Bredel M, 2005, CANCER RES, V65, P4088, DOI 10.1158/0008-5472.CAN-04-4229; Carter NP, 2007, NAT GENET, V39, pS16, DOI 10.1038/ng2028; Eilers PHC, 2005, BIOINFORMATICS, V21, P1146, DOI 10.1093/bioinformatics/bti148; Huang T, 2005, BIOINFORMATICS, V21, P3811, DOI 10.1093/bioinformatics/bti646; Land S. R., 1996, VARIABLE FUSION NEW; Li YJ, 2007, BIOINFORMATICS, V23, P2470, DOI 10.1093/bioinformatics/btm364; Marioni JC, 2006, BIOINFORMATICS, V22, P1144, DOI 10.1093/bioinformatics/btl089; Nakao K, 2004, CARCINOGENESIS, V25, P1345, DOI 10.1093/carcin/bgh134; Peel D, 2000, FINITE MIXTURE MODEL	17	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2156-1125		978-0-7695-3885-3	IEEE INT C BIOINFORM			2009							388	391		10.1109/BIBM.2009.57		4	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Engineering	BNY71	WOS:000275900200071		
S	Gueguen, L; Sayrac, B; Depierre, D			IEEE	Gueguen, Lionel; Sayrac, Berna; Depierre, David			Spectrogram Reconstruction from Random Sampling: Application to the GSM Band Sensing	2009 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-8	IEEE International Conference on Communications		English	Proceedings Paper	IEEE International Conference on Communications (ICC 2009)	JUN 14-18, 2009	Dresden, GERMANY	IEEE				In the context of cognitive radios, we present a method to sense wideband radio spectra from randomly distributed samples with an average sampling rate smaller than the Nyquist sampling rate. The method finds its roots in the compressed sensing paradigm. The Gabor time-frequency is employed as a sparsifying transform to represent the radio signals generated in the framework of TDMA/FDMA based radio access technologies. Indeed, many white spaces are observable in these wideband spectrograms. In addition, noisy measurements are modeled through the Basis Pursuit De Noise formulation, which enables to reconstruct the time-frequency representation with some errors or information losses. The method is experimented on measured baseband radio signals sampled at 51.2MHZ and acquired in the GSM 900 downlink band. Finally, results about the effects of the algorithm parameters and about the algorithm complexity are provided and discussed.	[Gueguen, Lionel; Sayrac, Berna] Orange Labs, F-92130 Issy Les Moulineaux, France	Gueguen, L (reprint author), Orange Labs, 38-40 Rue Gen Leclerc, F-92130 Issy Les Moulineaux, France.	lionel.gueguen@orange-ftgroup.com; berna.sayrac@orange-ftgroup.com; david.depierre@fr.thalesgroup.com					Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571; AUSLANDER L, 1991, IEEE T SIGNAL PROCES, V39, P825, DOI 10.1109/78.80904; Birgin EG, 2003, IMA J NUMER ANAL, V23, P539, DOI 10.1093/imanum/23.4.539; Ganesan G., 2005, IEEE INT S NEW FRONT, P137; Janssen AJEM, 2002, J FOURIER ANAL APPL, V8, P1, DOI 10.1007/s00041-002-0001-x; Kim K., 2007, IEEE INT S NEW FRONT, P212; Laska J., 2006, P IEEE DALL CIRC SYS, P119; Mallat S., 1999, WAVELET TOUR SIGNAL; Mitola J., 2000, THESIS ROYAL I TECHN; PFANDER GE, 2007, SPARSITY TIME FREQUE; Tian Zhi, 2007, IEEE INT C AC SPEECH, V4; Tuttlebee W., 2002, SOFTWARE DEFINED RAD; VANDENBERG E, 2008, TR200801 U BRIT COL	17	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-3607		978-1-4244-3434-3	IEEE ICC			2009							2802	2806				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BQG15	WOS:000280922201142		
B	Yukihiro, H; Yasunori, E; Sadaaki, M			IEEE	Yukihiro, Hamasuna; Yasunori, Endo; Sadaaki, Miyamoto			On L(1)-Norm based Tolerant Fuzzy c-Means Clustering	2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3			English	Proceedings Paper	18th IEEE International Conference on Fuzzy Systems	AUG 20-24, 2009	Jeju Isl, SOUTH KOREA	IEEE				In this paper, we will propose two types of L(1)-norm based tolerant fuzzy c-means clustering (TFCM) from the viewpoint of handling data more flexibly. One is based on the constraint for tolerance vector and the other is based on the regularization term. First, the concept of clusterwise tolerance is introduced into optimization problems. In these methods, a tolerance vector attributes not only to each data but also each cluster. First, the concept of clusterwise tolerance is introduced into optimization problems. Second, optimal solutions for these optimization problems are derived. Third, new clustering algorithms are constructed based on the explicit optimal solutions. Finally, effectiveness of proposed algorithms is verified through numerical examples.	[Yukihiro, Hamasuna] Univ Tsukuba, Grad Sch Syst & Informat Engn, Tsukuba, Ibaraki 3058573, Japan	Yukihiro, H (reprint author), Univ Tsukuba, Grad Sch Syst & Informat Engn, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.	yhama@soft.risk.tsukuba.ac.jp; endo@risk.tsukuba.ac.jp; miyamoto@risk.tsukuba.ac.jp					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hathaway RJ, 2001, IEEE T SYST MAN CY B, V31, P735, DOI 10.1109/3477.956035; Bezdek J.C., 1981, PATTERN RECOGNITION; Endo Y., 2005, P INT S NONL THEOR I, P345; HAMASUNA Y, INT FUZZY S IN PRESS; Hamasuna Y., 2008, J JAPAN SOC FUZZY TH, V20, P388, DOI 10.3156/jsoft.20.388; HAMASUNA Y, J ADV COMPU IN PRESS; Hasegawa Y, 2007, LECT NOTES ARTIF INT, V4617, P237; JAJUGA K, 1991, FUZZY SET SYST, V39, P43, DOI 10.1016/0165-0114(91)90064-W; Kazama J, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P137; Miyamoto S., 1997, P 7 INT FUZZ SYST AS, VII, P86; Miyamoto S., 1995, Control and Cybernetics, V24; Miyamoto S, 2008, STUD FUZZ SOFT COMP, V229, P1; Murata R., 2006, J ADV COMPUTATIONAL, V10, P673; Takata O., 2000, J JAPAN SOC FUZZY TH, V12, P686; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Tsuda K., 2006, P 23 INT C MACH LEAR, P953, DOI 10.1145/1143844.1143964; WILLIAMS TF, 1995, AGING-CLIN EXP RES, V7, P1	18	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3596-8				2009							1125	1130		10.1109/FUZZY.2009.5277417		6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BND85	WOS:000274242600195		
B	Hamasuna, Y; Endo, Y; Miyamoto, S		Lin, TY; Hu, XH; Xia, JL; Hong, TP; Shi, ZZ; Han, JC; Tsumoto, S; Shen, ZJ		Hamasuna Yukihiro; Endo Yasunori; Miyamoto Sadaaki			Comparison of Tolerant Fuzzy c-Means Clustering with L(2)- and L(1)-Regularization	2009 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING ( GRC 2009)			English	Proceedings Paper	IEEE International Conference on Granular Computing	AUG 17-19, 2009	Nanchang, PEOPLES R CHINA			fuzzy c-means clustering; clusterwise tolerance; tolerant fuzzy c-means clustering; L(2)-regularization term; L(1)-regularization term		In this paper, we will propose two types of tolerant fuzzy c-means clustering with regularization terms. One is L(2)-regularization term and the other is L(1)-regularization one for tolerance vector. Introducing a concept of clusterwise tolerance, we have proposed tolerant fuzzy c-means clustering from the viewpoint of handling data more flexibly. In tolerant fuzzy c-means clustering, a constraint for tolerance vector which restricts the upper bound of tolerance vector is used. In this paper, regularization terms for tolerance vector are used instead of the constraint. First, the concept of clusterwise tolerance is introduced. Second, optimization problems for tolerant fuzzy c-means clustering with regularization term are formulated. Third, optimal solutions of these optimization problems are derived. Fourth, new clustering algorithms are constructed based on the explicit optimal solutions. Finally, effectiveness of proposed algorithms is verified through numerical examples.	[Hamasuna Yukihiro] Univ Tsukuba, Grad Sch Sys & Info Eng, Tsukuba, Ibaraki 3058573, Japan	Hamasuna, Y (reprint author), Univ Tsukuba, Grad Sch Sys & Info Eng, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.	yhama@soft.risk.tsukuba.ac.jp; endo@risk.tsukuba.ac.jp; miyamoto@risk.tsukuba.ac.jp					WILLIAMS PM, 1995, NEURAL COMPUT, V7, P117, DOI 10.1162/neco.1995.7.1.117; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hathaway RJ, 2001, IEEE T SYST MAN CY B, V31, P735, DOI 10.1109/3477.956035; Bezdek J.C., 1981, PATTERN RECOGNITION; Endo Y., 2005, P INT S NONL THEOR I, P345; HAMASUNA Y, 2009, INT FUZZY S IN PRESS; Hamasuna Y., 2008, J JAPAN SOC FUZZY TH, V20, P388, DOI 10.3156/jsoft.20.388; HAMASUNA Y, 2009 INT C IN PRESS; HAMASUNA Y, J ADV COMPU IN PRESS; Hasegawa Y, 2007, LECT NOTES ARTIF INT, V4617, P237; JAJUGA K, 1991, FUZZY SET SYST, V39, P43, DOI 10.1016/0165-0114(91)90064-W; Kazama J, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P137; Miyamoto S., 1997, P 7 INT FUZZ SYST AS, VII, P86; Miyamoto S., 1995, Control and Cybernetics, V24; Murata R., 2006, J ADV COMPUTATIONAL, V10, P673; Takata O., 2000, J JAPAN SOC FUZZY TH, V12, P686; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Tsuda K., 2006, P 23 INT C MACH LEAR, P953, DOI 10.1145/1143844.1143964	18	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4831-9				2009							197	202		10.1109/GRC.2009.5255128		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTR12	WOS:000287830500045		
S	Zhou, TY; Tao, DC			IEEE	Zhou, Tianyi; Tao, Dacheng			Manifold Elastic Net for Sparse Learning	2009 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC 2009), VOLS 1-9	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 11-14, 2009	San Antonio, TX	IEEE		Least Angle Regression (LARS); Elastic Net; Manifold Learning; Manifold Elastic Net (MEN)	NONLINEAR DIMENSIONALITY REDUCTION; SELECTION	In this paper, we present the manifold elastic net (MEN) for sparse variable selection. MEN combines merits of the manifold regularization and the elastic net regularization, so it considers both the nonlinear manifold structure of a dataset and the sparse property of the redundant data representation. Face based gender recognition has received much attention in the psychophysical and video surveillance literatures. Most of existing works apply the appearance based information for data representation. A face image with size 40 by 40 could be seen as a point in a linear space with 1600 dimensions. For gender recognition, we have two classes (male and female) in total, so it is essential to find a small number of variables for representation to generalize duly. MEN can duly find the intrinsic structure of a dataset for separating males from the females. Sufficient experimental results on FERET and UMIST datasets suggest that MEN is more effective in selecting discriminative variables for face based gender recognition compared to principal component analysis, sparse principal component analysis, and discriminative locality alignment.	[Zhou, Tianyi; Tao, Dacheng] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Zhou, TY (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	ZHOU0144@ntu.edu.sg; dctao@ntu.edu.sg					Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Brunelli R., 1992, P DARPA IM UND WORKS, P311; Efron B., 2004, ANN STAT, V32, P68; Fisher RA, 1936, ANN EUGENIC, V7, P179; GOLOMB B, 1991, NIPS, V3; Jain A., 2004, Proceedings. Sixth IEEE International Conference on Automatic Face and Gesture Recognition; ZHANG T, IEEE T KNOW IN PRESS; ZHANG T, 2008, ECCV, V1, P725; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	16	0	0	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4244-2793-2	IEEE SYS MAN CYBERN			2009							3699	3704		10.1109/ICSMC.2009.5346879		6	Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BPP02	WOS:000279574602034		
B	Oka, A; Lampe, L			IEEE	Oka, Anand; Lampe, Lutz			A Compressed Sensing Receiver for Bursty Communication with UWB Impulse Radio	2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009)			English	Proceedings Paper	9th IEEE International Conference on Ultra-Wideband	SEP 09-11, 2009	Vancouver, CANADA	IEEE Microwave Theory & Tech Soc, IEEE Vancouver Sect, IEEE Seattle Sect				We propose a novel receiver for Ultra-Wideband Impulse-Radio communication in bursty applications like Wireless Sensor Networks. It is based on the principle of Compressed Sensing, and exploits the sparsity of the transmitted signal to achieve reliable demodulation. Instead of a full-fledged high-rate A/D, a modest number of projections of the received signal are acquired using analog correlators, and a joint decoding of the time of arrival and the data bits is performed from these under. sampled measurements via an efficient quadratic program. The receiver does not use wideband analog delay lines, and is robust to large timing uncertainty, hence the transmitter need not waste power on explicit training headers for timing synchronization. Moreover, the receiver can operate in a regime of heavy inter-symbol interference (ISI), and allows a very high baud rate (close to the Nyquist rate). Its performance is shown to remain close to the maximum likelihood receiver under every scenario of under-sampling, timing uncertainty, ISI, and delay spread.	[Oka, Anand; Lampe, Lutz] Univ British Columbia, Dept Elect & Comp Eng, Vancouver, BC V5Z 1M9, Canada	Oka, A (reprint author), Univ British Columbia, Dept Elect & Comp Eng, Vancouver, BC V5Z 1M9, Canada.	anando@ece.ubc.ca; lampe@ece.ubc.ca					Paredes JL, 2007, IEEE J-STSP, V1, P383, DOI 10.1109/JSTSP.2007.906657; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Roy S, 2004, P IEEE, V92, P295, DOI 10.1109/JPROC.2003.821910; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Arslan H., 2006, ULTRAWIDEBAND WIRELE; CHAO YL, 2003, P IEEE GLOBECOM, V2, P759; Chao YL, 2005, IEEE T VEH TECHNOL, V54, P1556, DOI 10.1109/TVT.2005.855700; D'Amico AA, 2007, IEEE T WIREL COMMUN, V6, P2652, DOI 10.1109/TWC.2007.05974; Horn R. A., 2005, MATRIX ANAL; IEEE, 2007, 802154A2007 IEEE; Kusuma J., 2003, P IEEE INT C COMM AN, P3540; Molisch AF, 2006, IEEE T ANTENN PROPAG, V54, P3151, DOI 10.1109/TAP.2006.883983; OKA A, COMPRESSED SENSING R; Pausini M, 2006, IEEE J SEL AREA COMM, V24, P815, DOI 10.1109/JSAC.2005.863845; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Wang Z., 2007, IEEE SPAWC, P1; Wang Z., 2007, IEEE INT C UWB SEPT, P393; Wang ZM, 2008, HANN BEITR NACHRICHT, V2, P157, DOI 10.1109/ICUWB.2008.4653375; Win MZ, 1998, IEEE COMMUN LETT, V2, P36, DOI 10.1109/4234.660796	21	2	2	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2930-1				2009							279	284		10.1109/ICUWB.2009.5288845		6	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BTM11	WOS:000287267300055		
B	Grosenick, L; Anderson, T; Smith, SJ			IEEE	Grosenick, Logan; Anderson, Todd; Smith, Stephen J.			ELASTIC SOURCE SELECTION FOR IN VIVO IMAGING OF NEURONAL ENSEMBLES	2009 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: FROM NANO TO MACRO, VOLS 1 AND 2			English	Proceedings Paper	IEEE Internaional Symposium on Biomedical Imaging - From Nano to Macro	JUN 28-JUL 01, 2009	Boston, MA	IEEE		Neuroimaging; Calcium Imaging; ICA; Sparse Regression; In Vivo	REGRESSION	Advances in microscopy and biochemistry now allow investigators to image the calcium dynamics of hundreds to thousands of neurons in awake behaving animals. However, as speed and resolution of such techniques rapidly increase, so do the dimension and complexity of the data collected. ICA has been widely employed to reveal independent non-Gaussian sources underlying large data sets consisting of mixed sources. We apply a recently developed sparse regression method, the Elastic Net (ENET), to the columns of the mixing matrix of a Independent Component Analysis (ICA) procedure. This regression method automatically selects only those columns of the mixing matrix relevant to a dependent variable of interest. Further, because ICA is a linear operator, we can easily project the "relevance filtered" data back into the native data space for interpretation. We demonstrate the utility of this method on 3D calcium imaging data collected from the optic tectum of an awake behaving larval zebrafish watching a prey-like stimulus.	[Grosenick, Logan; Smith, Stephen J.] Stanford Univ, Neurosci Program, Stanford, CA 94305 USA	Grosenick, L (reprint author), Stanford Univ, Neurosci Program, Stanford, CA 94305 USA.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; Hyvarinen A., 2001, INDEPENDENT COMPONEN; LEVOY M, 2006, SIGGRAPH 06 ACM SIGG, P924; Niell CM, 2005, NEURON, V45, P941, DOI 10.1016/j.neuron.2005.01.047; Ramdya P, 2008, NAT NEUROSCI, V11, P1083, DOI 10.1038/nn.2166; Sumbre G, 2008, NATURE, V456, P102, DOI 10.1038/nature07351	9	7	7	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3931-7				2009							1263	1266		10.1109/ISBI.2009.5193292		4	Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Radiology, Nuclear Medicine & Medical Imaging	BLO57	WOS:000270678400323		
B	Sun, JZ; Goyal, VK			IEEE	Sun, John Z.; Goyal, Vivek K.			Optimal Quantization of Random Measurements in Compressed Sensing	2009 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1- 4			English	Proceedings Paper	IEEE International Symposium on Information Theory (ISIT 2009)	JUN 28-JUL 03, 2009	Seoul, SOUTH KOREA	IEEE				Quantization is an important but often ignored consideration in discussions about compressed sensing. This paper studies the design of quantizers for random measurements of sparse signals that are optimal with respect to mean-squared error of the lasso reconstruction. We utilize recent results in high-resolution functional scalar quantization and homotopy continuation to approximate the optimal quantizer. Experimental results compare this quantizer to other practical designs and show a noticeable improvement in the operational distortion-rate performance.	[Sun, John Z.; Goyal, Vivek K.] MIT, Elect Res Lab, Cambridge, MA 02139 USA	Sun, JZ (reprint author), MIT, Elect Res Lab, Cambridge, MA 02139 USA.	johnsun@mit.edu; vgoyal@mit.edu					Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Boufounos P T, 2008, P 42 ANN C INF SCI S, P16; Candes E., 2006, P IEEE DAT COMPR C S, P33; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Dai W., 2009, arXiv:0901.0749v2 [cs.IT]; Goyal VK, 2008, IEEE SIGNAL PROC MAG, V25, P48, DOI 10.1109/MSP.2007.915001; JACQUES L, 2009, ARXIV09022367V2MATHO; MALIOUTOV DM, 2006, P IEEE AC SPEECH SIG, P733; MISRA V, 2008, ARXIV08113617V1CSIT; PAI RJ, 2006, NONADAPTIVE LOUSY EN; Wainwright M., 2006, 709 UC BERK DEP STAT	17	18	18	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4312-3				2009							6	10		10.1109/ISIT.2009.5205695		5	Engineering, Electrical & Electronic	Engineering	BPW21	WOS:000280141400002		
B	Zhu, H; Giannakis, GB			IEEE	Zhu, Hao; Giannakis, Georgios B.			Sparsity-Embracing Multiuser Detection for CDMA Systems with Low Activity Factor	2009 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1- 4			English	Proceedings Paper	IEEE International Symposium on Information Theory (ISIT 2009)	JUN 28-JUL 03, 2009	Seoul, SOUTH KOREA	IEEE		Sparsity; Multiuser Detection; Compressive Sampling; Lasso; Sphere Decoding		The number of active users in code-division multiple access (CDMA) systems is often much lower than the spreading gain. The present paper exploits fruitfully this a priori information to improve performance of multiuser detectors. A low-activity factor manifests itself in a sparse symbol vector with entries drawn from a finite alphabet that is augmented by the zero symbol to capture user inactivity. The non-equiprobable symbols of the augmented alphabet motivate a sparsity-exploiting maximum a posteriori probability (S-MAP) criterion, which is shown to yield a cost comprising the l(2) least-squares error penalized by the p-th norm of the wanted symbol vector (p = 0, 1. 2). Related optimization problems appear in variable selection (shrinkage) schemes developed for linear regression, as well as in the emerging field of compressive sampling (CS). The contribution of this work to CDMA systems is a gamut of sparsity-embracing multiuser detectors trading off performance for complexity requirements. From the vantage point of CS and the least-absolute shrinkage selection operator (Lasso) spectrum of applications, the contribution amounts to sparsity-exploiting algorithms when the entries of the wanted signal vector adhere to finite-alphabet constraints.	[Zhu, Hao; Giannakis, Georgios B.] Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA	Zhu, H (reprint author), Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA.	zhuh@umn.edu; georgios@umn.edu					Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Giannakis G., 2007, SPACE TIME CODING BR; Verdu S., 1998, MULTIUSER DETECTION; Viterbo E, 1999, IEEE T INFORM THEORY, V45, P1639, DOI 10.1109/18.771234; ZHU H, 2008, IEEE T SIGNAL UNPUB	10	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4312-3				2009							164	168				5	Engineering, Electrical & Electronic	Engineering	BPW21	WOS:000280141400034		
B	Fletcher, AK; Rangan, S; Goyal, VK			IEEE	Fletcher, Alyson K.; Rangan, Sundeep; Goyal, Vivek K.			A Sparsity Detection Framework for On-Off Random Access Channels	2009 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1- 4			English	Proceedings Paper	IEEE International Symposium on Information Theory (ISIT 2009)	JUN 28-JUL 03, 2009	Seoul, SOUTH KOREA	IEEE			SIGNAL RECOVERY	This paper considers a simple on-off random multiple access channel (MAC), where n, users communicate simultaneously to a single receiver. Each user is assigned a single codeword which it transmits with some probability lambda over m degrees of freedom. The receiver must detect which users transmitted. We show that detection for this random MAC is mathematically equivalent to a standard sparsity detection problem. Using new results in sparse estimation we are able to estimate the capacity of these channels and compare the achieved performance of various detection algorithms. The analysis provides insight into the roles of power control and multi-user detection.	[Fletcher, Alyson K.] Univ Calif Berkeley, Berkeley, CA 94720 USA	Fletcher, AK (reprint author), Univ Calif Berkeley, Berkeley, CA 94720 USA.	alyson@eecs.berkeley.edu; srangan@qualcomm.com; vgoyal@mit.edu					Ahlswede R., 1971, P 2 INT S INF THEOR, P23; AKCAKAYA M, 2007, ARXIV07110366V1; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DAVIS G, 1994, OPT ENG, V33, P2183, DOI 10.1117/12.173207; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Duarte MF, 2005, 2005 39th Asilomar Conference on Signals, Systems and Computers, Vols 1 and 2, P1537; FLETCHER A, 2008, ARXIV08041839V1; FLETCHER AK, 2009, ARXIV09031022V1; Jin Y., 2008, P IEEE INT S INF TH, P2444; LUPAS R, 1990, IEEE T COMMUN, V38, P496, DOI 10.1109/26.52661; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Needell D., 2008, ARXIV08032392V2; Pati Y. C., 1993, AS C SIG SYS COMP, P40; QIU L, 2001, P IEEE VEH TECH C OC, P1701; Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190; Reeves G., 2008, UCBEECS20083; Thomas J. A., 1991, ELEMENTS INFORM THEO; Verdu S., 1998, MULTIUSER DETECTION; VERDU S, 1986, IEEE T INFORM THEORY, V32, P85, DOI 10.1109/TIT.1986.1057121; Wainwright M. J., 2006, ARXIVMATHST0605740V1; WAINWRIGHT MJ, 2007, 725 U CAL BERK DEP S; Wipf D., 2006, P NEUR INF PROC SYST	27	5	5	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4312-3				2009							169	173		10.1109/ISIT.2009.5205769		5	Engineering, Electrical & Electronic	Engineering	BPW21	WOS:000280141400035		
B	Willett, RM; Raginsky, M			IEEE	Willett, Rebecca M.; Raginsky, Maxim			Performance Bounds on Compressed Sensing with Poisson Noise	2009 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1- 4			English	Proceedings Paper	IEEE International Symposium on Information Theory (ISIT 2009)	JUN 28-JUL 03, 2009	Seoul, SOUTH KOREA	IEEE			RANDOM PROJECTIONS; SIGNAL RECOVERY; RECONSTRUCTION	This paper describes performance bounds for compressed sensing in the presence of Poisson noise when the underlying signal, a vector of Poisson intensities, is sparse or compressible (admits a sparse approximation). The signal-independent and bounded noise models used in the literature to analyze the performance of compressed sensing do not accurately model the effects of Poisson noise. However, Poisson noise is an appropriate noise model for a variety of applications, including low-light imaging, where sensing hardware is large or expensive, and limiting the number of measurements collected is important. In this paper, we describe how a feasible positivity-preserving sensing matrix can be constructed, and then analyze the performance of a compressed sensing reconstruction approach for Poisson data that minimizes an objective function consisting of a negative Poisson log likelihood term and a penalty term which could be used as a measure of signal sparsity.	[Willett, Rebecca M.; Raginsky, Maxim] Duke Univ, Durham, NC 27708 USA	Willett, RM (reprint author), Duke Univ, Durham, NC 27708 USA.	willett@duke.edu; m.raginsky@duke.edu	Willett, Rebecca/G-6930-2012				Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Kolaczyk ED, 2004, ANN STAT, V32, P500; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Haupt J, 2006, IEEE T INFORM THEORY, V52, P4036, DOI 10.1109/TIT.2006.880031; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; CSISZAR I, 1991, ANN STAT, V19, P2032, DOI 10.1214/aos/1176348385; Gehm ME, 2007, OPT EXPRESS, V15, P14013, DOI 10.1364/OE.15.014013; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Dai W, 2009, IEEE T INFORM THEORY, V55, P2215, DOI 10.1109/TIT.2009.2016024; KHAJEHNEJAD MA, 2009, SPARSE RECOVER UNPUB; LI Q, 2000, ADV NEURAL INFORM PR, V12; Mendelson S, 2007, GEOM FUNCT ANAL, V17, P1248, DOI 10.1007/s00039-007-0618-7; SNYDER DL, 1993, J OPT SOC AM A, V10, P1014, DOI 10.1364/JOSAA.10.001014; Zenios S., 1997, PARALLEL OPTIMIZATIO	16	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4312-3				2009							174	178		10.1109/ISIT.2009.5205258		5	Engineering, Electrical & Electronic	Engineering	BPW21	WOS:000280141400036		
B	Majumdar, A; Ward, RK			IEEE	Majumdar, A.; Ward, R. K.			FAST GROUP SPARSE CLASSIFICATION	2009 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING, VOLS 1 AND 2			English	Proceedings Paper	IEEE Pacific Rim Conference on Communications, Computers and Signal Processing	AUG 23-26, 2009	Victoria, CANADA	IEEE		Classification; Group Sparsity; Random Projections	REGRESSION; SELECTION; PURSUITS	A recent work [1] proposed a novel Group Sparse Classifier (GSC) that was based on the assumption that the training samples of a particular class approximately form a linear basis for any test sample belonging to that class. The Group Sparse Classifier requires solving an NP hard group-sparsity promoting optimization problem. Thus a convex relaxation of the optimization problem was proposed. The convex optimization problem however, needs to be solved by quadratic programming and hence requires a large amount of computational time. To overcome this, we propose novel greedy (sub-optimal) algorithms for directly solving the NP hard minimization problem. We call the classifiers based on these greedy group sparsity promoting algorithms as Fast Group Sparse Classifiers (FGSC).	[Majumdar, A.; Ward, R. K.] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V5Z 1M9, Canada	Majumdar, A (reprint author), Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V5Z 1M9, Canada.						Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Blumensath T, 2008, IEEE T SIGNAL PROCES, V56, P2370, DOI 10.1109/TSP.2007.916124; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Donoho D. L., SPARSE SOLUTION UNDE; ELDAR YC, 2008, IEEE T INF THE UNPUB; ELDAR YC, ICASSP09 IN PRESS; FORNASIER M, 2007, ITERATIVE THRESHOLDI; MAJUMDAR A, ICASSP09 IN PRESS; NEEDELL D, 2007, UNIFORM UNCERT UNPUB; PATI YC, 1993, AS C SIG SYS COMP NO; van den Berg E., 2008, TR200809 U BRIT COL; WU CJ, 2006, ICASSP06, V4; Yang Y., IEEE T PAMI IN PRESS	16	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4560-8				2009							11	16		10.1109/PACRIM.2009.5291404		6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BPR97	WOS:000279748100003		
B	Uhlich, S; Loesch, B; Yang, B			IEEE	Uhlich, Stefan; Loesch, Benedikt; Yang, Bin			POLYNOMIAL LMMSE ESTIMATION: A CASE STUDY	2009 IEEE/SP 15TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2			English	Proceedings Paper	15th IEEE/SP Workshop on Statistical Signal Processing	AUG 31-SEP 03, 2009	Cardiff, WALES	IEEE, SP		Linear MMSE estimation; Frequency estimation; Variable selection	PARAMETER-ESTIMATION; FEATURE-SELECTION; SINGLE-TONE; SYSTEMS; BRANCH	This paper investigates the potential of the polynomial LMMSE estimation for nonlinear/nongaussian estimation problems. This is done by a case study: the estimation of the frequency of a sinusoidal signal with unknown amplitude and phase. We give analytical formulas to calculate the second order moments which are needed for the polynomial LMMSE estimation and we study the performance for varying orders of observations. Variable selection is used to identify the most relevant observations. It turns out that only a small number (less than one percent) of all available variables gives nearly the same mean squared error.	[Uhlich, Stefan; Loesch, Benedikt; Yang, Bin] Univ Stuttgart, Chair Syst Theory & Signal Proc, D-7000 Stuttgart, Germany	Uhlich, S (reprint author), Univ Stuttgart, Chair Syst Theory & Signal Proc, D-7000 Stuttgart, Germany.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; RIFE DC, 1974, IEEE T INFORM THEORY, V20, P591, DOI 10.1109/TIT.1974.1055282; BALAKRISHNAN AV, 1960, IRE T INFORM THEOR, V6, P490, DOI 10.1109/TIT.1960.1057589; BONDON P, 1994, IEEE T INFORM THEORY, V40, P960, DOI 10.1109/18.335913; Fung HW, 2004, SIGNAL PROCESS, V84, P601, DOI 10.1016/j.sigpro.2003.12.005; Jacobsen E, 2007, IEEE SIGNAL PROC MAG, V24, P123, DOI 10.1109/MSP.2007.361611; Kay S. M., 1993, FUNDAMENTALS STAT SI, V1; KENEFIC R, 1987, IEEE J OCEANIC ENG, V12; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; PICINBONO B, 1988, IEEE T INFORM THEORY, V34, P304, DOI 10.1109/18.2638; Pudil P., 1994, PATTERN RECOGN, V2, P279, DOI 10.1109/ICPR.1994.576920; PUDIL P, 1999, COMPUT INTELL, P159; Scharf L. L., 1990, STAT SIGNAL PROCESSI; Somol P, 2004, IEEE T PATTERN ANAL, V26, P900, DOI 10.1109/TPAMI.2004.28; THERRIEN C, 1996, IEEE DIG SIGN PROC W, P382	17	1	1	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2709-3				2009							65	68		10.1109/SSP.2009.5278637		4	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BNM76	WOS:000274988800017		
B	Angelosante, D; Bazerque, JA; Giannakis, GB			IEEE	Angelosante, Daniele; Bazerque, Juan Andres; Giannakis, Georgios B.			ONLINE COORDINATE DESCENT FOR ADAPTIVE ESTIMATION OF SPARSE SIGNALS	2009 IEEE/SP 15TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2			English	Proceedings Paper	15th IEEE/SP Workshop on Statistical Signal Processing	AUG 31-SEP 03, 2009	Cardiff, WALES	IEEE, SP		Lasso; Basis Pursuit; Compressive Sensing; Coordinate Descent; Recursive Least-Squares	REGRESSION; LASSO	Two low-complexity sparsity-aware recursive schemes are developed for real-time adaptive signal processing. Both rely on a novel online coordinate descent algorithm which minimizes a time-weighted least-squares cost penalized with the scaled l(1) norm of the unknown parameters. In addition to computational savings offered when processing time-invariant sparse parameter vectors, both schemes can be used for tracking slowly varying sparse signals. Analysis and preliminary simulations confirm that when the true signal is sparse the proposed estimators converge to a time-weighted least-absolute shrinkage and selection operator, and both outperform sparsity-agnostic recursive least-squares alternatives.	[Angelosante, Daniele; Bazerque, Juan Andres; Giannakis, Georgios B.] Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA	Angelosante, D (reprint author), Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA.						ANGELOSANTE D, 2009, P IEEE INT C AC SP S; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Wu TT, 2008, ANN APPL STAT, V2, P224, DOI 10.1214/07-AOAS147; Gu Y., 2009, P IEEE INT C AC SP S; SANGHAVI S, 2008, P IEEE INT C AC SP S; Sayed AH., 2003, FUNDAMENTALS ADAPTIV; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; WHITE GP, 2008, IEEE T SIGNAL PROCES, V56, P3150	10	2	2	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2709-3				2009							369	372		10.1109/SSP.2009.5278561		4	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BNM76	WOS:000274988800093		
B	Roos, T; Yu, B			IEEE	Roos, Teemu; Yu, Bin			Estimating sparse models from multivariate discrete data via transformed Lasso	2009 INFORMATION THEORY AND APPLICATIONS WORKSHOP			English	Proceedings Paper	IEEE Information Theory and Applications Workshop	FEB 08-13, 2009	La Jolla, CA				REGRESSION; SELECTION	The type of l(1) norm regularization used in Lasso and related methods typically yields sparse parameter estimates where most of the estimates are equal to zero. We study a class of estimators obtained by applying a linear transformation on the parameter vector before evaluating the l(1) norm. The resulting "transformed Lasso" yields estimates that are "smooth" in a way that depends on the applied transformation. The optimization problem is convex and can be solved efficiently using existing tools. We present two examples: the Haar transform which corresponds to variable length Markov chain (context-tree) models, and the Walsh-Hadamard transform which corresponds to linear combinations of XOR (parity) functions of binary input features.	[Roos, Teemu] Univ Helsinki, HIIT, FIN-00014 Helsinki, Finland	Roos, T (reprint author), Univ Helsinki, HIIT, FIN-00014 Helsinki, Finland.	teemu.roos@hiit.fi; binyu@stat.berkeley.edu					Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; WILLEMS FMJ, 1995, IEEE T INFORM THEORY, V41, P653, DOI 10.1109/18.382012; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Meier L, 2008, J R STAT SOC B, V70, P53; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; Beer T., 1981, AM J PHYS, V49; Buhlmann P. L., 1998, ANN STAT, V27, P480; Hesterberg T., 2008, STAT SURVEYS, V2, P61, DOI DOI 10.1214/08-SS035; Karpovsky M., 1976, FINITE ORTHOGONAL SE; Mallat S., 1998, WAVELET TOUR SIGNAL; McLachlan G., 1992, DISCRIMINANT ANAL ST; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; WEINBERGER MJ, 1995, IEEE T INFORM THEORY, V41, P643, DOI 10.1109/18.382011; ZHAO P, ANN STAT IN PRESS; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	19	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3990-4				2009							287	291				5	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BMC75	WOS:000271861000044		
B	Hang, XY		Zhang, J; Li, GZ; Yang, JY		Hang, Xiyi			Multiclass Gene Selection on Microarray Data using l(1)-norm Least Square Regression	2009 INTERNATIONAL JOINT CONFERENCE ON BIOINFORMATICS, SYSTEMS BIOLOGY AND INTELLIGENT COMPUTING, PROCEEDINGS			English	Proceedings Paper	International Joint Conference on Bioinformatics, Systems Biology and Intelligent Computing	AUG 03-05, 2009	Shanghai, PEOPLES R CHINA	IEEE Computer Soc, Conf Publish Serv		gene selection; l1-norm; regression; microarray	EXPRESSION; CLASSIFICATION; PREDICTION	A new univariate filter method for multiclass gene selection is proposed based on l1-norm least square regression. The numerical experiment shows that the method is, at least, comparable to two popular methods: ANOVA and BSS/WSS.	Calif State Univ Northridge, Dept Elect & Comp Engn, Northridge, CA 91330 USA	Hang, XY (reprint author), Calif State Univ Northridge, Dept Elect & Comp Engn, Northridge, CA 91330 USA.	xhang@csun.edu					Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Nutt CL, 2003, CANCER RES, V63, P1602; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; CANDES E, 2006, 2 MAGIC COLLECTION M; Chang C., 2001, LIBSVM LIB SUPPORT V; FRIEDLANDER M, 2008, SPGLI SOLVER LARGE S; Gibbons J.D., 2003, NONPARAMETRIC STAT I; HANG X, 2009, WORLD C COMP SCI INF; *MOSEK, 2002, MOSEK OPT TOOLS VERS; SAUNDERS M, 2002, PDC  PRIMAL DUAL INT; SAYES Y, 2007, BIOINFORMATICS, V19, P2507; VANDENBERG E, 2008 U BRIT COL DEP	17	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3739-9				2009							52	55		10.1109/IJCBS.2009.76		4	Computer Science, Artificial Intelligence; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BRI88	WOS:000282797800009		
B	Parsa, S; Vahidi-Asl, M; Naree, SA; Minaei-Bidgoli, B			IEEE	Parsa, Saeed; Vahidi-Asl, Mojtaba; Naree, Somaye Arabi; Minaei-Bidgoli, Behrouz			Statistical Software Debugging: From Bug Predictors to the Main Causes of Failure	2009 SECOND INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT 2009)			English	Proceedings Paper	2nd International Conference on the Applications of Digital Information and Web Technologies	AUG 04-06, 2009	London, ENGLAND	ICADIWT, London Metropolitan Business School, IEEE UKRI Section				Detecting latent errors is a key challenging issue in the software testing process. Latent errors could be best detected by bug predictors. A bug predictor manifests the effect of a bug on the program execution state. The aim has been to find the smallest reasonable subset of the bug predictors, manifesting all possible bugs within a program. In this paper, a new algorithm for finding the smallest subset of bug predictors is presented. The algorithm, firstly, applies a LASSO method to detect program predicates which have relatively higher effect on the termination status of the program. Then, a ridge regression method is applied to select a subset of the detected predicates as independent representatives of all the program predicates. Program control and data dependency graphs can be best applied to find the causes of bugs represented by the selected bug predictors. Our proposed approach has been evaluated on two well-known test suites. The experimental results demonstrate the effectiveness and accuracy of the proposed approach	[Parsa, Saeed; Vahidi-Asl, Mojtaba; Naree, Somaye Arabi; Minaei-Bidgoli, Behrouz] Iran Univ Sci & Technol, Fac Comp Engn, Tehran, Iran	Parsa, S (reprint author), Iran Univ Sci & Technol, Fac Comp Engn, Tehran, Iran.	parsa@iust.ac.ir; mojtaba_vahidi@comp.iust.ac.ir; atarabi@comp.iust.ac.ir; minaeibi@cse.msu.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Arumuga Nainar P., 2007, INT S SOFTW TEST AN, P5; Chatterjee S., 2006, WILEY SERIES PROBABI, VFourth; COLLOFELLO JS, 1989, J SYST SOFTWARE, V9, P191, DOI 10.1016/0164-1212(89)90039-3; *EXIF, EXIF SOFTW; Fei L., 2006, P FUND APPR SOFTW EN, P308; *GRAMMATECH INC, 2007, COD PATH INSP; Hastie T., 2001, ELEMENTS STAT LEARNI; Jiang L., 2007, 22 IEEE ACM INT C AU, P184; Kaner C., 2004, P 10 INT SOFTW METR; Liblit B., 2005, INT C PROGR LANG DES, P15; Liblit Ben, 2003, P ACM SIGPLAN 2003 C, P141; Liblit Benjamin, 2004, THESIS U CALIFORNIA; Liu C., 2005, 10 EUR SOFTW ENG C 1, P286; *RHYTHMB, MUS MAN APPL GNOME; SAS Institute Inc, 1988, SAS STAT US GUID; Zeller A, 2006, WHY PROGRAMS FAIL GU; Zheng A. X., 2006, ICML 06, P1105; LARS SOFTWARE R SPLU; SOFTWARE MEASUREMNET	20	3	3	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4456-4				2009							802	807		10.1109/ICADIWT.2009.5273934		6	Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BTX32	WOS:000288359000135		
B	Alahi, A; Boursier, Y; Jacques, L; Vandergheynst, P			IEEE	Alahi, Alexandre; Boursier, Yannick; Jacques, Laurent; Vandergheynst, Pierre			Sport Players Detection and Tracking With a Mixed Network of Planar and Omnidirectional Cameras	2009 THIRD ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS			English	Proceedings Paper	3rd ACM/IEEE International Conference on Distributed Smart Cameras	AUG 30-SEP 02, 2009	Como, ITALY	ACM, IEEE		Inverse problem; Sparsity; Sport player; Detection; Tracking		A generic approach is presented to detect and track people with a network of fixed and omnidirectional cameras given severely degraded foreground silhouettes. The problem is formulated as a sparsity constrained inverse problem. A dictionary made of atoms representing the silhouettes of a person at a given location is used within the problem formulation. A re-weighted scheme is considered to better approximate the sparsity prior. Although the framework is generic to any scene, the focus of this paper is to evaluate the performance of the proposed approach on a basketball game. The main challenges come from the players' behavior, their similar appearance, and the mutual occlusions present in the views. In addition, the extracted foreground silhouettes are severely degraded due to the polished floor reflecting the players, and the strong shadow present in the scene. We present qualitative and quantitative results with the APIDIS dataset as part of the ICDSC sport challenge.(1)	[Alahi, Alexandre; Boursier, Yannick; Vandergheynst, Pierre] Ecole Polytech Fed Lausanne, Inst Elect Engn, CH-1015 Lausanne, Switzerland	Alahi, A (reprint author), Ecole Polytech Fed Lausanne, Inst Elect Engn, CH-1015 Lausanne, Switzerland.						ALAHI A, 2009, 16 INT C DIG SIGN PR; Antonini G, 2006, TRANSPORT RES B-METH, V40, P667, DOI 10.1016/j.trb.2005.09.006; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; Lu WL, 2009, IMAGE VISION COMPUT, V27, P189, DOI 10.1016/j.imavis.2008.02.008; Avidan S., 2007, PAMI, V29, P261; Cai YZ, 2006, LECT NOTES COMPUT SC, V3954, P107; Candes E.J., 2007, ENHANCING SPARSITY R; Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z; Combettes PL, 2004, OPTIMIZATION, V53, P475, DOI 10.1080/02331930412331327157; FADILI MJ, 2009, SIAM J IMAGING UNPUB; FLEURET F, 2009, IEEE T PATTERN ANAL; Khan S. M., 2006, ECCV; MAUTHNER T, 2007, PERFORM EVALUATION, P81; Mueller K., 2003, ICME, V2, P657; NEEDHAM CJ, 2001, TRACKING MULTIPLE SP; Orwell J., 1999, INT C IM AN PROC VEN, P1104; Porikli F, 2006, J REAL-TIME IMAGE PR, V1, P33, DOI 10.1007/s11554-006-0011-z; Reddy CC, 2008, IEEE T DIELECT EL IN, V15, P221, DOI 10.1109/T-DEI.2008.4446754; SEO Y, 1997, LECT NOTES COMPUTER, P196; Stauffer C., 1999, P IEEE C COMP VIS PA, V2, P246	22	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4619-3				2009							7	14				8	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Optics	Automation & Control Systems; Computer Science; Engineering; Optics	BOC56	WOS:000276178900002		
B	Yang, AY; Maji, S; Christoudias, CM; Darrell, T; Malik, J; Sastry, SS			IEEE	Yang, Allen Y.; Maji, Subhransu; Christoudias, C. Mario; Darrell, Trevor; Malik, Jitendra; Sastry, S. Shankar			Multiple-View Object Recognition in Band-Limited Distributed Camera Networks	2009 THIRD ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS			English	Proceedings Paper	3rd ACM/IEEE International Conference on Distributed Smart Cameras	AUG 30-SEP 02, 2009	Como, ITALY	ACM, IEEE		Distributed object recognition; compressive sensing; random projection; joint sparsity; smart camera networks	RANDOM PROJECTIONS; FEATURES	In this paper, we study the classical problem of object recognition in low-power, low-bandwidth distributed camera networks. The ability to perform robust object recognition is crucial for applications such as visual surveillance to track and identify objects of interest, and compensate visual nuisances such as occlusion and pose variation between multiple camera views. We propose an effective framework to perform distributed object recognition using a network of smart cameras and a computer as the base station. Due to the limited bandwidth between the cameras and the computer, the method utilizes the available computational power on the smart sensors to locally extract and compress SIFT-type image features to represent individual camera views. In particular, we show that between a network of cameras, high-dimensional SIFT histograms share a joint sparse pattern corresponding to a set of common features in 3-D. Such joint sparse patterns can be explicitly exploited to accurately encode the distributed signal via random projection, which is unsupervised and independent to the sensor modality. On the base station, we study multiple decoding schemes to simultaneously recover the multiple-view object features based on the distributed compressive sensing theory. The system has been implemented on the Berkeley CITRIC smart camera platform. The efficacy of the algorithm is validated through extensive simulation and experiments.	[Yang, Allen Y.; Maji, Subhransu; Christoudias, C. Mario; Darrell, Trevor; Malik, Jitendra; Sastry, S. Shankar] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA	Yang, AY (reprint author), Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA.	yang@eecs.berkeley.edu; smaji@eecs.berkeley.edu; cmch@eecs.berkeley.edu; trevor@eecs.berkeley.edu; malik@eecs.berkeley.edu; sastry@eecs.berkeley.edu					Agarwal S., 2002, ECCV; AILON N, 2006, STOC; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; BARANIUK R, 2007, CONSTRUCTIV IN PRESS; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; CHEN D, 2009, DAT COMPR C; Chen P., 2008, P INT C DISTR SMART; Cheng ZL, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/57034; Christoudias C. M., 2008, CVPR; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9452, DOI 10.1073/pnas.0502258102; Donoho D.L., 2005, NEIGHBORLY POLYTOPES; Duarte MF, 2005, 2005 39th Asilomar Conference on Signals, Systems and Computers, Vols 1 and 2, P1537; ELDAR Y, 2008, ARXIV08074581; Ferrari V., 2004, CVPR; LEE JL, 2008, MITCSAILTR2008017; LEIBE B, 2005, CVPR, V1, P878, DOI DOI 10.1109/CVPR.2005.272; Li P, 2007, J MACH LEARN RES, V8, P2497; Liu C., 2008, ECCV; Lowe D. G., 1999, ICCV; Maji S., 2008, CVPR; Nene S. A., 1996, CUCS00696; Nister D., 2006, CVPR; PLUMBLEY M, 2006, P INT C IND COMP AN, P206; Quattoni A., 2008, CVPR; RAO B, 1996, 30 AS C SIGN SYST CO; Thomas A., 2006, CVPR; Vempala S. S., 2004, RANDOM PROJECTION ME; Yang A.Y., 2009, INT C INF FUS; YEO C, 2008, ICIP	34	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4619-3				2009							36	43				8	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Optics	Automation & Control Systems; Computer Science; Engineering; Optics	BOC56	WOS:000276178900006		
B	Guo, D; Qu, XB; Xiao, MB; Yao, Y		Wang, CX; Ouyang, S		Guo Di; Qu Xiaobo; Xiao Mingbo; Yao Yan			Comparative analysis on transform and reconstruction of compressed sensing in sensor networks	2009 WRI INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND MOBILE COMPUTING: CMC 2009, VOL I			English	Proceedings Paper	WRI International Conference on Communications and Mobile Computing	JAN 06-08, 2009	Kunming, PEOPLES R CHINA	World Res Inst, IEEE Comp Soc			PURSUIT	Compressed sensing (CS) is an emerging field based on the revelation that a small collection of linear projections of a sparse signal contains enough information for reconstruction. It holds valuable implications for wireless sensor networks because power and bandwidth arc, limited resources. In this paper, applying the theory of compressed sensing to the practical sensor network data recovery problem, we compare the performance of different CS reconstruction algorithms combined with wavelet and discrete cosine transform (DCT) basis. We demonstrate empirically that DCT is good for sinusoid oscillatory data while wavelet is good for data with point-like singularities. Furthermore, comparison on reconstruction algorithms shows basis pursuit (BP) is best in term of PSNR performance and computing time. In addition, benefit of CS for noisy channel of sensor network is tested and how to achieve good performance in noisy channel is discussed.	[Guo Di; Qu Xiaobo; Xiao Mingbo; Yao Yan] Xiamen Univ, Dept Commun Engn, Xiamen 361005, Peoples R China	Guo, D (reprint author), Xiamen Univ, Dept Commun Engn, Xiamen 361005, Peoples R China.	guodi@xmu.edu.cn; quxiaobo@xmu.edu.cn; mingbo@xmu.edu.cn; yaoy@tsinghua.edu.cn		Qu, Xiaobo/0000-0002-8675-5820			Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Haupt J, 2008, IEEE SIGNAL PROC MAG, V25, P92, DOI 10.1109/MSP.2007.914732; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Bajwa W., P 5 INT C INF PROC S, P134; BRETT H, ROBUSTNESS COMPRESSE; Donoho D. L., 2007, SPARSELAB; Duarte M. R., 2006, The Fifth International Conference on Information Processing in Sensor Networks (IEEE Cat. No. 06EX1353); WAINWRIGHT MJ, SHARP THRESHOLDS HIG	11	3	3	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3501-2				2009							441	445		10.1109/CMC.2009.19		5	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BJG24	WOS:000265599800092		
S	Hauff, C; Azzopardi, L; Hienstra, D		Boughanem, M; Berrut, C; Mothe, J; SouleDupuy, C		Hauff, Claudi; Azzopardi, Leif; Hienstra, Djoerd			The Combination and Evaluation of Query Performance Prediction Methods	ADVANCES IN INFORMATION RETRIEVAL, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	31st European Conference on Information Research	APR 06-09, 2009	Toulouse, FRANCE	Google, Mateixware Informat Serv, Microsoft Res, Yahoo, Exalead, GDR 13, Univ Paul Sabatier, ARIA, Inforsid & Reg, Midi Pyrennees			REGRESSION; SELECTION	In this paper, we examine a number of newly applied methods for combining pre-retrieval query performance predictors in order to obtain a better prediction of the query's performance. However, in order to adequately and appropriately compare such techniques, we critically examine the current evaluation methodology and show how using linear Correlation coefficients (i) do not provide an intuitive measure indicative of a method's quality, (ii) can provide a misleading indication of performance, and (iii) overstate the performance of combined methods. To address this, we extend the current evaluation methodology to include cross validation, report a more intuitive and descriptive statistic, and apply statistical testing to determine significant differences. During the course of a comprehensive empirical study over several TREC collections, we evaluate nineteen pre-retrieval predictors and three combination methods.	[Hauff, Claudi; Hienstra, Djoerd] Univ Twente, Enschede, Netherlands	Hauff, C (reprint author), Univ Twente, Enschede, Netherlands.	c.hauff@utwente.nl; leif@dcs.gla.ac.uk; d.hiemstra@utwente.nl					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; [Anonymous], 1998, WORDNET ELECT LEXICA; Efron B, 2004, ANN STAT, V32, P407; MENG XL, 1992, PSYCHOL BULL, V111, P172, DOI 10.1037/0033-2909.111.1.172; BACH FR, 2008, JCML; Banerjee S, 2003, IJCAI, P805; Cronen-Townsend S, 2002, SIGIR 02, P299; He B, 2004, LECT NOTES COMPUT SC, V3246, P43; He JY, 2008, LECT NOTES COMPUT SC, V4956, P689; Krovetz R., 1993, SIGIR Forum; MACDONALD C, 2005, SIGIR 2005 QUER PRED; MOTHE J, 2005, SIGIR 2005 QUER PRED; Scholer F, 2004, J AM SOC INF SCI TEC, V55, P637, DOI 10.1002/asi.20011; VINAY V, 2006, SIGIR 2006, P398; VOORHEES E, 2003, P 12 TEXT RETR C; Zhai C., 2001, SIGIR 2001, P334; Zhao Y, 2008, LECT NOTES COMPUT SC, V4956, P52; Zhou Y., 2007, SIGIR 07, P543; 1955, RANK CORRELATION MET	21	7	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-00957-0	LECT NOTES COMPUT SC			2009	5478						301	312				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BJG81	WOS:000265680800025		
S	Cai, YP; Sun, YJ; Li, J; Goodison, S		Theeramunkong, T; Kijsirikul, B; Cercone, N; Ho, TB		Cai, Yunpeng; Sun, Yijun; Li, Jian; Goodison, Steve			Online Feature Selection Algorithm with Bayesian l(1) Regularization	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	13th Pacific-Asia Conference on Knowledge and Data Mining	APR 27-30, 2009	Bangkok, THAILAND	Sirindhorn Int Inst Technol, Thammasat Univ, Chulalonkorn Univ, Asian Inst Technol, Natl Elect & Comp Technol Ctr, Thailand Convent & Exhibit Bureau, AF Off Sci Res, Asian Off Aerosp Res & Dev			REGRESSION	We propose a novel online-learning based feature selection algorithm for supervised learning in the presence of a huge amount of irrelevant features. The key idea of the algorithm is to decompose a nonlinear problem into a set of locally linear ones through local learning, and then estimate the relevance of features globally in a large margin framework with l(1) regularization. Unlike batch learning, the regularization parameter in online learning has to be tuned on-the-fly with the increasing of training data. We address this issue within the Bayesian learning paradigm, and provide an analytic solution for automatic estimation of the regularization parameter via variational methods. Numerical experiments on a variety of benchmark data sets are presented that demonstrate the effectiveness of the newly proposed feature selection algorithm.	[Cai, Yunpeng; Li, Jian] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32610 USA	Cai, YP (reprint author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32610 USA.						MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Jiang W, 2006, IEEE T IMAGE PROCESS, V15, P702, DOI 10.1109/TIP.2005.863105; Bishop C., 2006, PATTERN RECOGNITION; Cawley GC, 2005, NEUROCOMPUTING, V64, P119, DOI 10.1016/j.neucom.2004.11.021; Gilad-Bachrach R, 2004, P 21 INT C MACH LEAR, P43; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kress R., 1998, NUMERICAL ANAL; Lafferty J, 2006, STAT SINICA, V16, P307; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; Ng A. Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435; Pudil P, 1998, IEEE INTELL SYST APP, V13, P66, DOI 10.1109/5254.671094; Spall J. C., 2003, INTRO STOCHASTIC SEA; Sun Y., 2008, P 8 SIAM INT C DAT M, P530; Sun YJ, 2007, BIOINFORMATICS, V23, P30, DOI 10.1093/bioinformatics/btl543; Sun YJ, 2007, IEEE T PATTERN ANAL, V29, P1035, DOI 10.1109/TPAMI.2007.1093; Vapnik V., 1998, STAT LEARNING THEORY	21	3	3	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-01306-5	LECT NOTES ARTIF INT			2009	5476						401	413				13	Computer Science, Artificial Intelligence	Computer Science	BKN07	WOS:000268632000034		
S	Gao, JB; Zhang, J		Theeramunkong, T; Kijsirikul, B; Cercone, N; Ho, TB		Gao, Junbin; Zhang, Jun			Sparse Kernel Learning and the Relevance Units Machine	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	13th Pacific-Asia Conference on Knowledge and Data Mining	APR 27-30, 2009	Bangkok, THAILAND	Sirindhorn Int Inst Technol, Thammasat Univ, Chulalongkorn Univ, Asian Inst Technol, Natl Elect & Comp Technol Ctr, Thailand Convent & Exhibit Bureau, AF Off Sci Res, Asian Off Aerosp Res & Dev			PRINCIPAL COMPONENT ANALYSIS; REGRESSION; MODELS; LASSO	The relevance vector machine(RVM) is a state-of-the-art constructing sparse regression kernel model [1,2,3,4]. It not, only gene;rates a much sparser model but; provides better generalization performance than the standard support vector machine (SVM). In RVM and SVM, relevance vectors (RVs) and support vectors (SVs) are both selected from the input vector set. This play limit model flexibility. In this paper we propose a. new sparse kernel model called Relevance Units Machine (RUM). RUM follows the idea of RVM under the Bayesian framework lint releases the constraint that RVs have to be selected from the input vectors. RUM treats relevance units as part of the parameters of the model. As a result; a RUM maintains all the advantages of RVM and offers superior sparsity. The new algorithm is demonstrated to possess considerable computational advantages over well-known the state-of-the-art algorithms.	[Gao, Junbin; Zhang, Jun] Charles Sturt Univ, Sch Accounting & Comp Sci, Bathurst, NSW 2795, Australia	Gao, JB (reprint author), Charles Sturt Univ, Sch Accounting & Comp Sci, Bathurst, NSW 2795, Australia.	jbgao@csu.edu.au; jzhang@csu.edu.au	Zhang, Jun/B-3596-2012				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Gao JB, 2008, NEURAL COMPUT, V20, P555, DOI 10.1162/neco.2007.11-06-397; BILLINGS SA, 1989, MECH SYST SIGNAL PR, V3, P123, DOI 10.1016/0888-3270(89)90012-5; Bishop CM, 2000, UNCERTAINTY ARTIFICI, P46; Burges C.J.C., 1996, P 13 INT C MACH LEAR, P71; Chen S, 2006, NEUROCOMPUTING, V69, P559, DOI 10.1016/j.neucom.2004.12.011; Drezet PML, 1998, P UKACC INT C CONTR, P688; GAO J, 2008, 21 AUSTR JOINT C ART; GESTEL T, 2003, P 13 IFAC S SYST ID, P27; KRUIF B, 2002, P 41 IEEE C DEC CONT, P10; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Poggio T, 1998, NEURAL COMPUT, V10, P1445, DOI 10.1162/089976698300017250; Roth V, 2004, IEEE T NEURAL NETWOR, V15, P16, DOI 10.1109/TNN.2003.809398; Scholkopf B., 2002, LEARNING KERNELS; Snelson E., 2006, ADV NEURAL INFORM PR, V18, P1257; Suykens J., 2002, LEAST SQUARE SUPPORT; Tipping M. E., 2001, MACH LEARNING, V1, P211; Tipping M. E., 2003, P 9 INT WORKSH ART I; Tipping ME, 2000, ADV NEURAL INFORM PR, V12; VALYON J, 2003, P 13 IFAC S SYST IDE; Vapnik V., 1998, STAT LEARNING THEORY; Wang G., 2007, INT C ART INT STAT, P580; Wu MR, 2006, J MACH LEARN RES, V7, P603	23	1	1	0	24	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-01306-5	LECT NOTES ARTIF INT			2009	5476						612	619				8	Computer Science, Artificial Intelligence	Computer Science	BKN07	WOS:000268632000057		
B	Kang, C; Ghosal, S		SenGupta, A		Kang, Changku; Ghosal, Subhashis			Clusterwise Regression Using Dirichlet Mixtures	ADVANCES IN MULTIVARIATE STATISTICAL METHODS	Statistical Science and Interdisciplinary Research		English	Proceedings Paper	International Conference on Multivariate Statistical Methods	DEC 28-29, 2006	Calcutta, INDIA				LINEAR-REGRESSION; DENSITY	The article describes a method of estimating nonparametric regression function through Bayesian clustering. The basic working assumption in the underlying method is that the population is a union of several hidden subpopulations in each of which a different linear regression is in force and the overall nonlinear regression function arises as a result of superposition of these linear regression functions. A Bayesian clustering technique based on Dirichlet mixture process is used to identify clusters which correspond to samples from these hidden subpopulations. The clusters are formed automatically within a Markov chain Monte-Carlo scheme arising from a Dirichlet mixture process prior for the density of the regressor variable. The number of components in the mixing distribution is thus treated as unknown allowing considerable flexibility in modeling. Within each cluster, we estimate model parameters by the standard least square method or some of its variations. Automatic model averaging takes care of the uncertainty in classifying a new observation to the obtained clusters. As opposed to most commonly used nonparametric regression estimates which break up the sample locally, our method splits the sample into a number of subgroups not depending on the dimension of the regressor variable. Thus our method avoids the curse of dimensionality problem. Through extensive simulations, we compare the performance of our proposed method with that of commonly used nonparametric regression techniques. We conclude that when the model assumption holds and the subpopulation are not highly overlapping, our method has smaller estimation error particularly if the dimension is relatively large.	[Kang, Changku] Bank Korea, Econ Stat Dept, Seoul, South Korea	Kang, C (reprint author), Bank Korea, Econ Stat Dept, 110,3 Ga, Seoul, South Korea.	koncap@gmail.com; sghosal@stat.ncsu.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; DESARBO WS, 1988, J CLASSIF, V5, P249, DOI 10.1007/BF01897167; DONOHO DL, 1988, ANN STAT, V16, P1390, DOI 10.1214/aos/1176351045; Efromovich S, 1999, NONPARAMETRIC CURVE; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P557; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Geweke J, 2007, J ECONOMETRICS, V138, P252, DOI 10.1016/j.jeconom.2006.05.022; Ghosal S, 1999, ANN STAT, V27, P143; Hastie TJ, 1990, GEN ADDITIVE MODELS; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; HUBERT L, 1985, J COMPUT GRAPH STAT, V7, P233; MacEachern SN, 1998, J COMPUT GRAPH STAT, V7, P223, DOI 10.2307/1390815; Muller P, 1996, BIOMETRIKA, V83, P67, DOI 10.1093/biomet/83.1.67; SPATH H, 1979, COMPUTING, V22, P367, DOI 10.1007/BF02265317; Van Aelst S, 2006, COMPUT STAT DATA AN, V50, P1287, DOI 10.1016/j.csda.2004.11.011; WAHBA G, 1978, J ROY STAT SOC B MET, V40, P364	20	2	2	1	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			978-981-283-823-0	STAT SCI INTERDISC R			2009	4						305	325				21	Statistics & Probability	Mathematics	BMY67	WOS:000273936100018		
S	Wang, JF; Lee, KH; Leung, KS		Yu, W; He, H; Zhang, N		Wang, JinFeng; Lee, KinHong; Leung, KwongSak			L1-norm Regularization Based Nonlinear Integrals	ADVANCES IN NEURAL NETWORKS - ISNN 2009, PT 1, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	6th International Symposium on Neural Networks	MAY 26-29, 2009	Wuhan, PEOPLES R CHINA	Huazhong Univ Sci & Technol, Chinese Univ Hong Kong, Natl Nat Sci Fdn, IEEE Wuhan Sect, IEEE Computat Intel Soc, Int Neural Network Soc		Nonlinear Integral; L1-Norm Regularization; Classification; LASSO	FUZZY MEASURES; CLASSIFICATION; SELECTION	Since Nonlinear Integrals, such as the Choquet Integral and Sugeno Integrals, were proposed, how to get the FUZZY Measure and confirm the unique solution became the hard problems. Some researchers can obtain the optimal solution for Fuzzy Measure using soft computing tools. When the Nonlinear Integrals can be transformed to a linear equation with regards to Fuzzy Measure by Prof. Wang, we call apply the L1-norm regularization method to solve the linear equation system for one dataset and find a Solution with the fewest nonzero values. The solution with the fewest nonzero can show the degree of contribution of some features or their combinations for decision. The experimental results show that the L1-norm regularization is helpful to the classifier based oil Nonlinear Integrals. It can not only reduce the complexity of Nonlinear Integral but also keep the good performance of the model based on Nonlinear Integral. Meanwhile, we can dig out and understand the affection and meaning of the Fuzzy Measure better.	[Wang, JinFeng; Lee, KinHong; Leung, KwongSak] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Wang, JF (reprint author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Grabisch M, 2000, FUZZY MEASURES INTEG; GRABISCH M, 1994, FUZZY SET SYST, V65, P255, DOI 10.1016/0165-0114(94)90023-X; Grabisch M, 1996, PATTERN RECOGN LETT, V17, P567, DOI 10.1016/0167-8655(96)00020-7; Hastie T., 2001, ELEMENTS STAT LEARNI; Keller J.M., 1992, 1 IEEE INT C FUZZ SY, P661, DOI 10.1109/FUZZY.1992.258738; Leung KS, 2002, IEEE T SYST MAN CY B, V32, P630, DOI 10.1109/TSMCB.2002.1033182; Merz C. J., 1996, UCI REPOSITORY MACHI; Mikenina L, 1999, FUZZY SET SYST, V107, P197, DOI 10.1016/S0165-0114(98)00429-1; MUROFUSHI T, 1994, FUZZY SET SYST, V64, P73, DOI 10.1016/0165-0114(94)90008-6; SHIRISH KS, 2003, BIOINFORMATICS, V19, P2246; Sugeno M., 1974, THESIS TOKYO I TECHN; Wang W, 1998, J INTELL FUZZY SYST, V6, P171; Wang Z., 2003, P 12 IEEE INT C FUZZ, P819; Wang ZY, 1999, FUZZY SET SYST, V102, P463, DOI 10.1016/S0165-0114(98)00220-6; Xu KB, 2003, IEEE T FUZZY SYST, V11, P187, DOI 10.1109/TFUZZ.2003.809891	16	0	0	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-01506-9	LECT NOTES COMPUT SC			2009	5551						201	208				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BKB59	WOS:000267695000024		
S	Parsa, S; Vahidi-Asl, M; Arabi, S; Minaei-Bidgoli, B		Slezak, D; Kim, TH; Kiumi, A; Jiang, T; Verner, J; Abrahao, S		Parsa, Saeed; Vahidi-Asl, Mojtaba; Arabi, Somaye; Minaei-Bidgoli, Behrouz			Software Fault Localization Using Elastic Net: A New Statistical Approach	ADVANCES IN SOFTWARE ENGINEERING, PROCEEDINGS	Communications in Computer and Information Science		English	Proceedings Paper	International Conference on Advanced Software Engineering and Its Applications held at the Future Generation Information Technology Conference	DEC 10-12, 2009	Jeju Isl, SOUTH KOREA			Software Testing; Statistical debugging; Elastic Net; Program Slicing; Bug Predictors		Fault localization is an important task in software testing process. The aim is to find latent semantic faults which do not violate program syntactic rules. Statistical debugging techniques are amongst best methods for identifying faults in the program source code. However, they have some drawbacks. They require a large number of executions to identify faults. Furthermore, they do not consider the simultaneous effect of predicates on program termination status. To resolve the problems, in this paper a new approach based on elastic net has been proposed. The proposed approach finds the smallest effective subset of program predicates known as bug predictors. Detecting most effective bug predictors considering fewer amounts of executions as much as possible is highly desirable. The elastic net is advantageous when the number of executions is much smaller than the number of predicates. After selecting bug predictors, the main causes of faults are detected by using existing program slicing technique. The experimental results on two well-known test suites reveal the effectiveness and accuracy of the proposed approach.	[Parsa, Saeed; Vahidi-Asl, Mojtaba; Arabi, Somaye; Minaei-Bidgoli, Behrouz] Iran Univ Sci & Technol, Dept Comp Engn, Tehran, Iran	Parsa, S (reprint author), Iran Univ Sci & Technol, Dept Comp Engn, Tehran, Iran.	parsa@iust.ac.ir; mojtaba_vahidi@comp.iust.ac.ir; atarabi@comp.iust.ac.ir; minaeibi@cse.msu.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Arumuga Nainar P., 2007, ISSTA, P5; Chatterjee S, 2006, REGRESSION ANAL EXAM; DELMOL C, 2008, ELASTIC NET REGULARI; Fei L, 2006, LECT NOTES COMPUT SC, V3922, P308; Hastie T., 2001, ELEMENTS STAT LEARNI; Liblit B., 2005, INT C PROGR LANG DES, P15; Liblit Ben, 2003, P ACM SIGPLAN 2003 C, P141; Liblit Benjamin, 2004, THESIS U CALIFORNIA; Liu C., 2005, 10 EUR SOFTW ENG C 1, P286; Zeller A, 2006, WHY PROGRAMS FAIL GU	11	1	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929		978-3-642-10618-7	COMM COM INF SC			2009	59						127	134				8	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BMY92	WOS:000273955300016		
J	Kagie, M; van der Loos, M; van Wezel, M				Kagie, Martijn; van der Loos, Matthijs; van Wezel, Michiel			Including item characteristics in the probabilistic latent semantic analysis model for collaborative filtering	AI COMMUNICATIONS			English	Article						Recommender systems; probabilistic latent semantic analysis; hybrid recommender systems	RECOMMENDER SYSTEMS; MAXIMUM-LIKELIHOOD; REGRESSION; ALGORITHM; FRAMEWORK	We propose a new hybrid recommender system that combines some advantages of collaborative and content-based recommender systems. While it uses ratings data of all users, as do collaborative recommender systems, it is also able to recommend new items and provide an explanation of its recommendations, as do content-based systems. Our approach is based on the idea that there are communities of users that find the same characteristics important to like or dislike a product. This model is an extension of the probabilistic latent semantic model for collaborative filtering with ideas based on clusterwise linear regression. On a movie data set, we show that the model, at the cost of a very small loss in overall performance, is able to recommend new items and give an explanation of its recommendations to its users.	[Kagie, Martijn; van der Loos, Matthijs; van Wezel, Michiel] Erasmus Univ, Erasmus Sch Econ, NL-3000 DR Rotterdam, Netherlands	Kagie, M (reprint author), Erasmus Univ, Erasmus Sch Econ, POB 1738, NL-3000 DR Rotterdam, Netherlands.	kagie@ese.eur.nl; mvanderloos@ese.eur.nl; mvanwezel@ese.eur.nl	Sucunuta, Manuel/G-7550-2015	Sucunuta, Manuel/0000-0002-9334-8625			Aikake H, 1974, IEEE T AUTOMAT CONTR, V19, P716, DOI 10.1109/TAC.1974.1100705; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; RAMASWAMY V, 1993, MARKET SCI, V12, P103, DOI 10.1287/mksc.12.1.103; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781; Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774; Desarbo WS, 2005, STRATEGIC MANAGE J, V26, P47, DOI 10.1002/smj.431; Zhou YH, 2008, LECT NOTES COMPUT SC, V5034, P337; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Ansari A, 2000, J MARKETING RES, V37, P363, DOI 10.1509/jmkr.37.3.363.18779; Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Bishop C., 2006, PATTERN RECOGNITION; Breese J., 1998, P 14 C UNC ART INT, P43; Camargo SJ, 2007, J CLIMATE, V20, P3635, DOI 10.1175/JCLI4188.1; Claypool M., 1999, P ACM SIGIR WORKSH R; CONDLIFF MK, 1999, P ACM SIGIR WORKSH R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESARBO WS, 1988, J CLASSIF, V5, P249, DOI 10.1007/BF01897167; DeSarbo W.S., 1992, MARKET LETT, V3, P273, DOI 10.1007/BF00994135; Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209; Good N., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Herlocker JL, 2000, P 2000 ACM C COMP SU, P241, DOI DOI 10.1145/358916.358995; Herlocker J. L., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312682; HOFMANN T, 1999, P 15 C UNC ART INT U, P289; KOREN Y, 2009, IEEE COMPUT, V42, P30; KRIEGLER M, 2006, EUR J AGEING, V2, P13; Larcker DF, 2004, J ACCOUNTING RES, V42, P625, DOI 10.1111/j.1475-679X.2004.t01-1-00143.x; McCullagh P., 1989, MONOGRAPHS STAT APPL, V37; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; Melville P., 2002, P 18 NAT C ART INT, P187; Pazzani M., 2007, LNCS, V4321, P325, DOI DOI 10.1007/978-3-540-72079-9_10; Pennings JME, 2004, J BANK FINANC, V28, P951, DOI 10.1016/S0378-4266(03)00046-3; Popescul A., 2001, P 17 C UNC ART INT U, P437; Prasad B., 2003, J ELECT COMMERCE RES, V4, P65; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Resnick P., 1994, P ACM C COMP SUPP CO, P175, DOI DOI 10.1145/192844.192905; Sarwar B, 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/564376.564421; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Sinha R, 2002, C HUM FACT COMP SYST, P830; SOBOROFF I, 1999, P IJCAI WORKSH MACH; Takacs Gabor, 2008, P 2008 ACM C REC SYS, P267, DOI 10.1145/1454008.1454049; Tintare N., 2007, P 23 INT C DAT ENG W, P801; Tran T., 2000, P KNOWL BAS EL MARK; Vriens M, 1996, J MARKETING RES, V33, P73, DOI 10.2307/3152014; WEDEL M, 1995, J CLASSIF, V12, P21, DOI 10.1007/BF01202266	57	1	2	1	7	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126			AI COMMUN	AI Commun.		2009	22	4					249	265		10.3233/AIC-2009-0467		17	Computer Science, Artificial Intelligence	Computer Science	535HR	WOS:000272958500004		
J	O'Hara, RB; Sillanpaa, MJ				O'Hara, R. B.; Sillanpaa, M. J.			A Review of Bayesian Variable Selection Methods: What, How and Which	BAYESIAN ANALYSIS			English	Review						Variable Selection; MCMC; BUGS	QUANTITATIVE TRAIT LOCI; MONTE-CARLO METHODS; QUALITATIVE TRAITS; MODEL SELECTION; ENTIRE GENOME; ASSOCIATION; LASSO; INFORMATION; PREDICTION; FRAMEWORK	The selection of variables in regression problems has occupied the minds of many statisticians. Several Bayesian variable selection methods have been developed, and we concentrate on the following methods: Kuo & Mallick, Gibbs Variable Selection (GVS), Stochastic Search Variable Selection (SSVS), adaptive shrinkage with Jeffreys' prior or a Laplacian prior, and reversible jump MCMC. We review these methods, in the context of their different properties. We then implement the methods in BUGS, using both real and simulated data as examples, and investigate how the different methods perform in practice. Our results suggest that SSVS, reversible jump MCMC and adaptive shrinkage methods can all work well, but the choice of which method is better will depend on the priors that are used, and also on how they are implemented.	[O'Hara, R. B.; Sillanpaa, M. J.] Univ Helsinki, Dept Math & Stat, FIN-00014 Helsinki, Finland	O'Hara, RB (reprint author), Univ Helsinki, Dept Math & Stat, FIN-00014 Helsinki, Finland.	bob.ohara@helsinki.fi	O'Hara, Robert/A-7499-2008	O'Hara, Robert/0000-0001-9737-3724	Academy of Finland [202324, 205371]	We would like to thank Nengjun Yi and Roderick D.Ball for their comments on the manuscript. This work was supported by research grants (202324 and 205371) from the Academy of Finland.	Lunn DJ, 2006, GENET EPIDEMIOL, V30, P231, DOI 10.1002/gepi.20140; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; CARLIN BP, 1995, J ROY STAT SOC B MET, V57, P473; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; Meuwissen THE, 2001, GENETICS, V157, P1819; Sturtz S, 2005, J STAT SOFTW, V12, P1; Godsill SJ, 2001, J COMPUT GRAPH STAT, V10, P230, DOI 10.1198/10618600152627924; Tipping ME, 2004, LECT NOTES ARTIF INT, V3176, P41; Ball RD, 2001, GENETICS, V159, P1351; Broman KW, 2002, J R STAT SOC B, V64, P641, DOI 10.1111/1467-9868.00354; Brown PJ, 1998, J R STAT SOC B, V60, P627, DOI 10.1111/1467-9868.00144; Burnham K. P., 2002, MODEL SELECTION MULT; DELLAPORTAS P., 2000, GEN LINEAR MODELS BA, P273; DELLAPORTAS P, 1997, BAYESIAN MODEL VARIA; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Gelman A, 2006, BAYESIAN ANAL, V1, P515; George E. I., 1993, J AM STAT ASSOC, V85, P398; George EI, 1997, STAT SINICA, V7, P339; Geweke J., 1996, BAYESIAN STAT, V5, P609; Geyer CJ, 1992, STAT SCI, V7, P473, DOI DOI 10.1214/SS/1177011137); Goring HHH, 2001, AM J HUM GENET, V69, P1357, DOI 10.1086/324471; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; HOPERT JP, 1996, J AM STAT ASSOC, V91, P1461; Hoti F, 2006, HEREDITY, V97, P4, DOI 10.1038/sj.hdy.6800817; Iswaran H., 2005, ANN STAT, V33, P730; Kilpikari R, 2003, GENET EPIDEMIOL, V25, P122, DOI 10.1002/gepi.10257; KNAPP SJ, 1990, THEOR APPL GENET, V79, P583, DOI 10.1007/BF00226869; Kuo L., 1998, SANKHYA B, V60, P65; LANDE R, 1990, GENETICS, V124, P743; McDonald AS, 2008, IET RENEW POWER GEN, V2, P3, DOI 10.1049/iet-rpg:20070071; Meuwissen THE, 2004, GENET SEL EVOL, V36, P261, DOI 10.1051/gse:2004001; Miller A, 2002, SUBSET SELECTION REG, V2nd; Plummer M., 2008, CODA OUTPUT ANAL DIA; Robert CP, 2004, MONTE CARLO STAT MET; Sen S, 2001, GENETICS, V159, P371; Sillanpaa MJ, 2002, TRENDS GENET, V18, P301, DOI 10.1016/S0168-9525(02)02688-4; Sillanpaa MJ, 1998, GENETICS, V148, P1373; Sillanpaa MJ, 2005, GENETICS, V169, P427, DOI 10.1534/genetics.104.032680; Sillanpaa MJ, 2004, GENETICS, V167, P1037, DOI 10.1534/genetics.103.025320; Sillanpaa MJ, 2006, GENETICS, V174, P1597, DOI 10.1523/genetics.106.061275; Smith M, 2002, J AM STAT ASSOC, V97, P1141, DOI 10.1198/016214502388618942; Spiegelhalter DJ, 2002, J ROY STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353; ter Braak CJF, 2005, GENETICS, V170, P1435, DOI 10.1534/genetics.105.040469; Thomas A., 2006, R NEWS, V6, P12; Tinker NA, 1996, CROP SCI, V36, P1053; Uimari P, 1997, GENETICS, V146, P735; Xu SZ, 2003, GENETICS, V163, P789; Yi NJ, 2004, GENETICS, V167, P967, DOI 10.1534/genetics.104.026286; Yi NJ, 2008, GENETICS, V179, P1045, DOI 10.1534/genetics.107.085589; Yi NJ, 2003, GENETICS, V164, P1129; Zhang YM, 2005, HEREDITY, V95, P96, DOI 10.1038/sj.hdy.6800702	52	130	130	6	41	INT SOC BAYESIAN ANALYSIS	PITTSBURGH	CARNEGIE MELLON UNIV, DEPT STTISTICS, PITTSBURGH, PA 15213 USA	1931-6690	1936-0975		BAYESIAN ANAL	Bayesian Anal.		2009	4	1					85	117		10.1214/09-BA403		33	Mathematics, Interdisciplinary Applications; Statistics & Probability	Mathematics	542HI	WOS:000273483200007		
J	Fraley, C				Fraley, Chris			A Stochastic Partitioning Method to Associate High-dimensional Responses and Covariates Comment on Article by Monni and Tadesse	BAYESIAN ANALYSIS			English	Editorial Material							CLUSTERWISE LINEAR-REGRESSION; BAYESIAN VARIABLE SELECTION; MIXTURES-OF-EXPERTS; MODELS; IDENTIFIABILITY; LASSO; PANEL		[Fraley, Chris] Univ Washington, Dept Stat, Seattle, WA 98195 USA; [Fraley, Chris] Insilicos LLC, Seattle, WA USA	Fraley, C (reprint author), Univ Washington, Dept Stat, Seattle, WA 98195 USA.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Turlach BA, 2005, TECHNOMETRICS, V47, P349, DOI 10.1198/004017005000000139; Efron B, 2004, ANN STAT, V32, P407; O'Hara RB, 2009, BAYESIAN ANAL, V4, P85, DOI 10.1214/09-BA403; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Khalili A, 2007, J AM STAT ASSOC, V102, P1025, DOI 10.1198/016214507000000590; BANERJEE S, 1993, PATTERN RECOGN, V26, P963, DOI 10.1016/0031-3203(93)90061-Z; Breiman L, 1997, J ROY STAT SOC B MET, V59, P3, DOI 10.1111/1467-9868.00054; Brown PJ, 1998, J R STAT SOC B, V60, P627, DOI 10.1111/1467-9868.00144; Brusco MJ, 2003, J MARKETING RES, V40, P225, DOI 10.1509/jmkr.40.2.225.19227; BRYANT P, 1978, BIOMETRIKA, V65, P273, DOI 10.1093/biomet/65.2.273; Bussey KJ, 2006, MOL CANCER THER, V5, P853, DOI 10.1158/1535-7163.MCT-05-0155; DESARBO WS, 1988, J CLASSIF, V5, P249, DOI 10.1007/BF01897167; FRIEDMAN J, 2009, REGULARIZATION UNPUB; George EI, 1997, STAT SINICA, V7, P339; GEYER CJ, 1991, COMPUTING SCIENCE AND STATISTICS, P156; Gupta M, 2007, J AM STAT ASSOC, V102, P867, DOI 10.1198/016214507000000068; Hennig C, 2000, J CLASSIF, V17, P273, DOI 10.1007/s003570000022; Jiang W, 1999, NEURAL NETWORKS, V12, P1253, DOI 10.1016/S0893-6080(99)00066-0; Jiang WX, 1999, ANN STAT, V27, P987; Lenk PJ, 2000, PSYCHOMETRIKA, V65, P93, DOI 10.1007/BF02294188; McLachlan G. J., 1988, MIXTURE MODELS INFER; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Peel D, 2000, FINITE MIXTURE MODEL; Shankavaram UT, 2007, MOL CANCER THER, V6, P820, DOI 10.1158/1535-7163.MCT-06-0650; SPATH H, 1979, COMPUTING, V22, P367, DOI 10.1007/BF02265317; WEDEL M, 1991, J MARKETING RES, V28, P384; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977	30	0	0	1	1	INT SOC BAYESIAN ANALYSIS	PITTSBURGH	CARNEGIE MELLON UNIV, DEPT STTISTICS, PITTSBURGH, PA 15213 USA	1931-6690			BAYESIAN ANAL	Bayesian Anal.		2009	4	3					439	448		10.1214/09-BA416B		10	Mathematics, Interdisciplinary Applications; Statistics & Probability	Mathematics	542HL	WOS:000273483500003		
S	Zheng, SF; Liu, WX		Chen, J; Chen, X; Ely, J; HakkaniTr, D; He, J; Hsu, HH		Zheng, Songfeng; Liu, Weixiang			Lasso based Gene Selection for Linear Classifiers	BIBMW: 2009 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE WORKSHOP	IEEE International Conference on Bioinformatics and Biomedicine Workshop-BIBMW		English	Proceedings Paper	IEEE International Conference on Bioinformatics and Biomedicine (BIBMW 2009)	NOV 01-04, 2009	Washington, DC	IEEE, IEEE Comp Soc, Natl Sci Fdn		Lasso; variable selection; linear classifier; leave-one-out; cross validation	SUPPORT VECTOR MACHINES; LEAST ANGLE REGRESSION; EXPRESSION DATA; TUMOR CLASSIFICATION; CANCER; PREDICTION; PROFILES; STRATEGY	Selecting a subset of genes with strong discriminative power is a very important step in classification problems based on gene expression data. Lasso is known to have automatic variable selection ability in linear regression analysis. This paper uses Lasso to select most informative genes to represent the class label as a linear function of the gene expression data. The selected genes are further used to fit linear classifiers for tumor classification. The proposed approach (gene selection and linear classification) was applied to 5 publicly available cancer datasets. Compared to other methods in literature, the proposed method achieves similar or higher classification accuracy with fewer genes.	[Zheng, Songfeng] Missouri State Univ, Dept Math, Springfield, MO 65897 USA	Zheng, SF (reprint author), Missouri State Univ, Dept Math, Springfield, MO 65897 USA.	SongfengZheng@MissouriState.edu; wxliu@szu.edu.cn					Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Yang K, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-228; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Efron B, 2004, ANN STAT, V32, P407; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tang YC, 2007, IEEE ACM T COMPUT BI, V4, P365, DOI 10.1109/TCBB.2007.1028; Potti A, 2006, NEW ENGL J MED, V355, P570, DOI 10.1056/NEJMoa060467; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Antoniadis A, 2003, BIOINFORMATICS, V19, P563, DOI 10.1093/bioinformatics/btg062; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867; Duda R., PATTERN CLASSIFICATI; Fung G, 2001, P KDD 2001 KNOWL DIS, P77, DOI DOI 10.1145/502512.502527; Ghosh Debashis, 2002, Pac Symp Biocomput, P18; GOLUB T, SCIENCE, V286, P531; LI F, 2005, P ADV NEUR INF PROC; Madigan D, 2004, ANN STAT, V32, P465; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Welsh JB, 2001, P NATL ACAD SCI USA, V98, P1176, DOI 10.1073/pnas.98.3.1176; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; Xiong MM, 2001, GENOME RES, V11, P1878; Xiong MM, 2000, BIOTECHNIQUES, V29, P1264; ZHU J, 2003, P C NEUR INF PROC SY	34	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2163-6966		978-1-4244-5120-3	IEEE INT C BIO BIO W			2009							200	205				6	Engineering, Biomedical; Medical Informatics	Engineering; Medical Informatics	BNF35	WOS:000274329200032		
S	Van Belle, V; Pelckmans, K; Suykens, JAK; Van Huffel, S		Cabestany, J; Prieto, A; Sandoval, F; Corchado, JM		Van Belle, V.; Pelckmans, K.; Suykens, J. A. K.; Van Huffel, S.			Feature Selection in Survival Least Squares Support Vector Machines with Maximal Variation Constraints	BIO-INSPIRED SYSTEMS: COMPUTATIONAL AND AMBIENT INTELLIGENCE, PT 1	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Work-Conference on Artificial Neural Networks (IWANN 2009)	JUN 10-12, 2009	Salamanca, SPAIN			failure time data; feature selection; LS-SVM	CLASSIFIERS	This work proposes the use of maximal variation analysis for feature selection within least squares support vector machines for survival analysis. Instead of selecting a subset of variables with forward or backward feature selection procedures, we modify the loss function in such a way that the maximal variation for each covariate is minimized, resulting in models which have sparse dependence on the features. Experiments on artificial data illustrate the ability of the maximal variation method to recover relevant variables from the given ones. A real life study concentrates on a breast cancer dataset containing clinical variables. The results indicate a better performance for the proposed method compared to Cox regression with an L(1) regularization scheme.	[Van Belle, V.; Pelckmans, K.; Suykens, J. A. K.; Van Huffel, S.] Katholieke Univ Leuven, ESAT SCD, B-3001 Louvain, Belgium	Van Belle, V (reprint author), Katholieke Univ Leuven, ESAT SCD, Kasteelpk Arenberg 10, B-3001 Louvain, Belgium.	vanya.vanbelle@esat.kuleuven.be; kristiaan.pelckmans@esat.kuleuven.be; johan.suykens@esat.kuleuven.be; sabine.vanhuffel@esat.kuleuven.be	Pelckmans, Kristiaan/A-3118-2013; Suykens, Johan/C-9781-2014				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; BOVELSTAD HMM, BIOINFORMATICS, V23, P2080; Cox DR, 1972, J R STAT SOC B, V34, P197; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HARRELL FE, 1988, J NATL CANC I, V80; Kohavi R, 1997, ARTIF INTELL, V1, P273; Ojeda F, 2008, NEURAL NETWORKS, V21, P437, DOI 10.1016/j.neunet.2007.12.053; Pelckmans K, 2005, LECT NOTES COMPUT SC, V3697, P643; PELCKMANS K, 2005, COMPONENTWISE LEAST, P77; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753706; SCHUMACHER M, 1994, J CLIN ONCOLOGY, V12; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; VANBELLE V, 2008, P 16 EUR S ART NEUR, P89; VANBELLE V, 2008, ADDITIVE SURVIVAL LE; VANBELLE V, 2007, P 3 INT C COMP INT M	16	1	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-02477-1	LECT NOTES COMPUT SC			2009	5517						65	72				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BLF80	WOS:000270081200009		
J	Fitch, AM; Jones, MB				Fitch, A. Marie; Jones, M. Beatrix			Shortest path analysis using partial correlations for classifying gene functions from gene expression data	BIOINFORMATICS			English	Article							SELECTION; LASSO; DISCOVERY; NETWORK	Motivation: Gaussian graphical models (GGMs) are a popular tool for representing gene association structures. We propose using estimated partial correlations from these models to attach lengths to the edges of the GGM, where the length of an edge is inversely related to the partial correlation between the gene pair. Graphical lasso is used to fit the GGMs and obtain partial correlations. The shortest paths between pairs of genes are found. Where terminal genes have the same biological function intermediate genes on the path are classified as having the same function. We validate the method using genes of known function using the Rosetta Compendium of yeast (Saccharomyces Cerevisiae) gene expression profiles. We also compare our results with those obtained using a graph constructed using correlations. Results: Using a partial correlation graph, we are able to classify approximately twice as many genes to the same level of accuracy as when using a correlation graph. More importantly when both methods are tuned to classify a similar number of genes, the partial correlation approach can increase the accuracy of the classifications.	[Fitch, A. Marie; Jones, M. Beatrix] Massey Univ, Inst Informat & Math Sci, Auckland, New Zealand	Fitch, AM (reprint author), Massey Univ, Inst Informat & Math Sci, Auckland, New Zealand.						Aburatani S, 2003, SIGNAL PROCESS, V83, P777, DOI 10.1016/S0165-1684(02)00476-0; Zhou XH, 2002, P NATL ACAD SCI USA, V99, P12783, DOI 10.1073/pnas.192159399; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; de la Fuente A, 2004, BIOINFORMATICS, V20, P3565, DOI 10.1093/bioinformatics/bth445; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Banerjee O, 2008, J MACH LEARN RES, V9, P485; Schafer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; Dobra A., 2004, BAYESIAN COVARIANCE; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; MATUSNO T, 2006, IEICE T INF SYST, V89, P1563; MEINHAUSEN N, 2006, LASSOTYPE RECOVERY S; SHIMAMURA T, 2007, JAP SOC BIOINFORM, P142; Toh H, 2002, BIOINFORMATICS, V18, P287, DOI 10.1093/bioinformatics/18.2.287; Wille A, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-11-r92	18	6	6	1	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JAN 1	2009	25	1					42	47		10.1093/bioinformatics/btn574		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	388BX	WOS:000261996400007	18984597	
J	Gao, CL; Dang, X; Chen, YX; Wilkins, D				Gao, Cuilan; Dang, Xin; Chen, Yixin; Wilkins, Dawn			Graph ranking for exploratory gene data analysis	BMC BIOINFORMATICS			English	Article; Proceedings Paper	6th Annual Conference of the MidSouth-Computational-Biology-and-Bioinformatics-Society	FEB 20-21, 2009	Starkville, MS	MidSouth Computat Biol & Bioinformat Soc	Mississippi State Univ		SUPPORT VECTOR MACHINES; MICROARRAY DATA; EXPRESSION DATA; VARIABLE SELECTION; CLASSIFICATION; ONTOLOGY; SEARCH; CANCER; SETS	Background: Microarray technology has made it possible to simultaneously monitor the expression levels of thousands of genes in a single experiment. However, the large number of genes greatly increases the challenges of analyzing, comprehending and interpreting the resulting mass of data. Selecting a subset of important genes is inevitable to address the challenge. Gene selection has been investigated extensively over the last decade. Most selection procedures, however, are not sufficient for accurate inference of underlying biology, because biological significance does not necessarily have to be statistically significant. Additional biological knowledge needs to be integrated into the gene selection procedure. Results: We propose a general framework for gene ranking. We construct a bipartite graph from the Gene Ontology (GO) and gene expression data. The graph describes the relationship between genes and their associated molecular functions. Under a species condition, edge weights of the graph are assigned to be gene expression level. Such a graph provides a mathematical means to represent both species-independent and species-dependent biological information. We also develop a new ranking algorithm to analyze the weighted graph via a kernelized spatial depth (KSD) approach. Consequently, the importance of gene and molecular function can be simultaneously ranked by a real-valued measure, KSD, which incorporates the global and local structure of the graph. Over-expressed and under-regulated genes also can be separately ranked. Conclusion: The gene-function bigraph integrates molecular function annotations into gene expression data. The relevance of genes is described in the graph (through a common function). The proposed method provides an exploratory framework for gene data analysis.	[Gao, Cuilan; Dang, Xin] Univ Mississippi, Dept Math, University, MS 38677 USA; [Chen, Yixin; Wilkins, Dawn] Univ Mississippi, Dept Comp & Informat Sci, University, MS 38677 USA	Dang, X (reprint author), Univ Mississippi, Dept Math, University, MS 38677 USA.	cgao@olemiss.edu; xdang@olemiss.edu; ychen@cs.olemiss.edu; dwilkins@cs.olemiss.edu					AGARWAL A, 2007, LEARNING RANDOM WALK; Daigle BJ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-214; Ando Rie Kubota, 2006, P NEUR INF PROC SYST, P25; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Khatri P, 2005, BIOINFORMATICS, V21, P3587, DOI 10.1093/bioinformatics/bti565; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Caba E, 2005, MUTAT RES-FUND MOL M, V575, P34, DOI 10.1016/j.mrfmmm.2005.02.005; Alexa A, 2006, BIOINFORMATICS, V22, P1600, DOI 10.1093/bioinformatics/btl140; Wang L, 2008, BIOINFORMATICS, V24, P412, DOI 10.1093/bioinformatics/btm579; Falcon S, 2007, BIOINFORMATICS, V23, P257, DOI 10.1093/bioinformatics/btl567; Lee KE, 2003, BIOINFORMATICS, V19, P90, DOI 10.1093/bioinformatics/19.1.90; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Newton MA, 2001, J COMPUT BIOL, V8, P37, DOI 10.1089/106652701300099074; Chen YX, 2009, IEEE T PATTERN ANAL, V31, P288, DOI 10.1109/TPAMI.2008.72; Chung F R K, 1997, CBMS REGIONAL C SERI, V92; Dang X, 2009, J NONPARAMETR STAT, V21, P49, DOI 10.1080/10485250802447981; Dhillon I.S., 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Ding YY, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S2-S12; Ding YY, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S7-S8; Dudoit S., 2005, BIOINFORMATICS COMPU; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; GROSSMANN S, 2006, P 10 ANN INT C RES C, P85; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Ho ND, 2005, APPL MATH LETT, V18, P917, DOI 10.1016/j.aml.2004.07.034; Kerr MK, 2000, J COMPUT BIOL, V7, P819, DOI 10.1089/10665270050514954; Konder R., 2002, P 19 INT C MACH LEAR, P315; Lee M-LT, 2004, ANAL MICROARRAY GENE; Ma XT, 2007, BIOINFORMATICS, V23, P215, DOI 10.1093/bioinformatics/btl569; Martin D, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-12-r101; Morrison JL, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-233; Mukherjee Sach, 2004, Proc IEEE Comput Syst Bioinform Conf, P131; Pepe MS, 2003, BIOMETRICS, V59, P133, DOI 10.1111/1541-0420.00016; Serfling R, 2002, STAT DATA ANAL BASED, P25; SMOLA AJ, 2005, LEARNING THEORM KERN; SRIVASTAVA S, 2008, PLOS ONE, V3; Tanay Amos, 2002, Bioinformatics, V18 Suppl 1, pS136; Trajkovski I, 2008, J BIOMED INFORM, V41, P588, DOI 10.1016/j.jbi.2007.12.001; Uriarte R.D., 2006, BMC BIOINFORMATICS, V7, P3; ZADEH SFM, 2006, P 8 INT C SIGN PROC, V4, P16; Zha H., 2001, P 10 INT C INF KNOWL, P25; Zhang B, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-16	46	6	6	0	1	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics		2009	10			11					S19	10.1186/1471-2105-10-S11-S19		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	509YY	WOS:000271056400019	19811684	
S	Gustafsson, M; Hornquist, M; Lundstrom, J; Bjorkegren, J; Tegner, J		Stolovitzky, G; Kahlem, P; Califano, A		Gustafsson, Mika; Hornquist, Michael; Lundstrom, Jesper; Bjorkegren, Johan; Tegner, Jesper			Reverse Engineering of Gene Networks with LASSO and Nonlinear Basis Functions	CHALLENGES OF SYSTEMS BIOLOGY: COMMUNITY EFFORTS TO HARNESS BIOLOGICAL COMPLEXITY	Annals of the New York Academy of Sciences		English	Article; Proceedings Paper	ENFIN-DREAM Conference on the Assessment of Computational Methods in Systems BiologyDREAM2 Conference	APR 28-29, 2008DEC 03-04, 2007	Madrid, SPAINNew York, NY		New York Acad Sci	reverse engineering; network inference; nonlinear; DREAM conference; LARS; LASSO	HUMAN B-CELLS; COMPLEX NETWORKS; INFERENCE; VALIDATION; REGRESSION; SELECTION; BIOLOGY	The quest to determine cause from effect is often referred to as reverse engineering in the context of cellular networks. Here we propose and evaluate an algorithm for reverse engineering a gene regulatory network from time-series kind steady-state data. Our algorithmic pipeline, which is rather standard in its parts but not in its integrative composition, combines ordinary differential equations, parameter estimations by least angle regression, and cross-validation procedures for determining the in-degrees and selection of nonlinear transfer functions. The result of the algorithm is a complete directed net-work, in which each edge has been assigned a score front it bootstrap procedure. To evaluate the performance, we submitted the outcome of the algorithm to the reverse engineering assessment competition DREAM2, where we used the data corresponding to the InSillico1 and InSilico2 networks as input. Our algorithm outperformed all other algorithms when inferring one of the directed gene-to-gene networks.	[Gustafsson, Mika; Hornquist, Michael] Linkoping Univ, Dept Sci & Technol, S-60171 Norrkoping, Sweden; [Lundstrom, Jesper; Bjorkegren, Johan; Tegner, Jesper] Karolinska Univ Sjukhuset, Ctr Mol Med, Dept Med, Stockholm, Sweden; [Tegner, Jesper] Linkoping Univ, Dept Phys, S-58183 Linkoping, Sweden	Hornquist, M (reprint author), Linkoping Univ, Dept Sci & Technol ITN, S-60171 Norrkoping, Sweden.	micho@itn.lin.se			Centre for Industrial Information Technology at Linkoping Institute of Technology, Sweden	We acknowledge Pedro Mendes and Gustavo Stolovitzky for letting us use Figures 2 and 3 (PM) and 4 and 5 (GS), respectively. We also acknowledge financial support from the Centre for Industrial Information Technology at Linkoping Institute of Technology, Sweden (MG and MH) and from the PhD school in medical bioinformatics (FMB) (JL).	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hoops S, 2006, BIOINFORMATICS, V22, P3067, DOI 10.1093/bioinformatics/btl485; Bansal M, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100120; Efron B, 2004, ANN STAT, V32, P407; Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; BERGHEN FV, 2005, LARS LIB LEAST UNPUB; D'haeseleer P, 1999, PAC S BIOC, V4, P41; *DREAM, 2007, DIAL REV ENG ASS MET; Gustafsson M, 2006, PHYSICA A, V367, P559, DOI 10.1016/j.physa.2005.12.017; Gustafsson M, 2005, IEEE ACM T COMPUT BI, V2, P254, DOI 10.1109/TCBB.2005.35; GUSTAFSSON M, 2008, COMPUTATIONAL METHOD; Hartwell LH, 1999, NATURE, V402, pC47, DOI 10.1038/35011540; Karlsson F, 2007, PHYSICA A, V384, P747, DOI 10.1016/j.physa.2007.05.050; KAUFFMAN SA, 1969, J THEOR BIOL, V22, P437, DOI 10.1016/0022-5193(69)90015-0; Margolin AA, 2007, ANN NY ACAD SCI, V1115, P51, DOI 10.1196/annals.1407.019; Nilsson R, 2007, J MACH LEARN RES, V8, P589; Rice JJ, 2005, BIOINFORMATICS, V21, P765, DOI 10.1093/bioinformatics/bti064; Stolovitzky G, 2007, ANN NY ACAD SCI, V1115, P1, DOI 10.1196/annals.1407.021; Tegner J, 2007, TRENDS GENET, V23, P34, DOI 10.1016/j.tig.2006.11.003; Werner M, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-40	22	11	12	1	5	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN STREET, MALDEN 02148, MA USA	0077-8923		978-1-57331-751-1	ANN NY ACAD SCI	Ann.NY Acad.Sci.		2009	1158						265	275		10.1111/j.1749-6632.2008.03764.x		11	Biotechnology & Applied Microbiology; Mathematical & Computational Biology; Multidisciplinary Sciences	Biotechnology & Applied Microbiology; Mathematical & Computational Biology; Science & Technology - Other Topics	BJG41	WOS:000265650800022	19348648	
J	Bierman, S; Steel, S				Bierman, Surette; Steel, Sarel			Variable Selection for Support Vector Machines	COMMUNICATIONS IN STATISTICS-SIMULATION AND COMPUTATION			English	Article						Kernel model dimension; Kernel target alignment; Recursive feature elimination; Variable selection for SVMs	SUBSET-SELECTION; KERNEL; REGRESSION	Consider using values of variables X(1), X(2), ... , X(p) to classify entities into one of two classes. Kernel-based procedures such as support vector machines (SVMs) are well suited for this task. In general, the classification accuracy of SVMs can be substantially improved if instead of all p candidate variables, a smaller subset of (say m) variables is used. A new two-step approach to variable selection for SVMs is therefore proposed: best variable subsets of size k = 1, 2, ... , p are first identified, and then a new data-dependent criterion is used to determine a value for m. The new approach is evaluated in a Monte Carlo simulation study, and on a sample of data sets.	[Bierman, Surette; Steel, Sarel] Univ Stellenbosch, Dept Stat & Actuarial Sci, ZA-7602 Matieland, South Africa	Bierman, S (reprint author), Univ Stellenbosch, Dept Stat & Actuarial Sci, Private Bag 11, ZA-7602 Matieland, South Africa.	surette@sun.ac.za					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Louw N, 2006, COMPUT STAT DATA AN, V51, P2043, DOI 10.1016/j.csda.2005.12.018; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Asuncion A., 2007, UCI MACHINE LEARNING; Claeskens G, 2008, J MACH LEARN RES, V9, P541; Couvreur C, 2000, SIAM J MATRIX ANAL A, V21, P797, DOI 10.1137/S0895479898332928; Elissedff A., 2002, ADV NEURAL INFORM PR, V14; Gestel T. V., 2004, MACH LEARN, V54, P5; GRANDVALET Y, 2002, ADAPTIVE SCALING FEA; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; KEERTHI SS, 2005, ACM INT C PROC SER, V119, P417; Kohavi R, 1997, ARTIF INTELL, V1, P273; Liu Huiqing, 2002, Genome Inform, V13, P51; Niijima S, 2006, PATTERN RECOGN LETT, V27, P1884, DOI 10.1016/j.patrec.2006.04.017; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753706; Scholkopf B., 2002, LEARNING KERNELS SUP; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Stoppiglia H., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753733; Wang WJ, 2003, NEUROCOMPUTING, V55, P643, DOI 10.1016/S0925-2312(02)00632-X; Weston J, 2001, ADV NEUR IN, V13, P668; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; Zhang HH, 2006, STAT SINICA, V16, P659	24	7	7	0	2	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0361-0918			COMMUN STAT-SIMUL C	Commun. Stat.-Simul. Comput.		2009	38	8					1640	1658		10.1080/03610910903072391		19	Statistics & Probability	Mathematics	508EV	WOS:000270912500007		
J	Lin, D; Shkedy, Z; Burzykowski, T; Talloen, W; Bijnens, L				Lin, Dan; Shkedy, Ziv; Burzykowski, Tomasz; Talloen, Willem; Bijnens, Luc			A Comparison of Procedures for Controlling the False Discovery Rate in the Presence of Small Variance Genes: A Simulation Study	COMMUNICATIONS IN STATISTICS-SIMULATION AND COMPUTATION			English	Article						Control of the FDR; Fudge factor; Power; SAM	EXPRESSION DATA; MIXTURE MODEL; MICROARRAYS	The Significance Analysis of Microarrays (SAM; Tusher et al., 2001) method is widely used in analyzing gene expression data while controlling the FDR by using resampling-based procedure in the microarray setting. One of the main components of the SAM procedure is the adjustment of the test statistic. The introduction of the fudge factor to the test statistic aims at deflating the large value of test statistics due to the small standard error of gene-expression. Lin et al. (2008) pointed out that the fudge factor does not effectively improve the power and the control of the FDR as compared to the SAM procedure without the fudge factor in the presence of small variance genes. Motivated by the simulation results presented in Lin et al. (2008), in this article, we extend our study to compare several methods for choosing the fudge factor in the modified t-type test statistics and use simulation studies to investigate the power and the control of the FDR of the considered methods.	[Lin, Dan] Hasselt Univ, B-3590 Diepenbeek, Belgium; [Talloen, Willem; Bijnens, Luc] J&JPRD, Beerse, Belgium	Lin, D (reprint author), Hasselt Univ, Univ Campus,Bldg D, B-3590 Diepenbeek, Belgium.	dan.lin@uhasselt.be			Belgian Government (Belgian Science Policy) [P5/24]	Financial support from the IAP research network nr P5/24 of the Belgian Government (Belgian Science Policy) is gratefully acknowledged.	Efron B, 2002, GENET EPIDEMIOL, V23, P70, DOI 10.1002/gepi.01124; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Efron B, 2001, J AM STAT ASSOC, V96, P1151, DOI 10.1198/016214501753382129; Broberg P, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-6-r41; Chu GB, 2001, SAM SIGNIFICANCE ANA; Delmar P, 2005, J R STAT SOC C-APPL, V54, P31, DOI 10.1111/j.1467-9876.2005.00468.x; Ge Y, 2003, 633 U CAL DEP STAT; GENOVESE C, 2001, OPERATING CHARACTERI; Lin D, 2008, BIOMETRICAL J, V50, P801, DOI 10.1002/bimj.200710467; LOVELL DR, 1996, ENG APPL NEURAL NETW, P487; Manda SOM, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-124; PARMIGRANI G, 2003, ANAL GENE EXPRESSION; STOREY JD, 2001, DIRECT APPROACH FALS; TibShirani R., 1996, J ROYAL STAT SOC B, V58; Wu TD, 2001, J PATHOL, V195, P53, DOI 10.1002/1096-9896(200109)195:1<53::AID-PATH891>3.0.CO;2-H	16	0	0	1	1	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0361-0918			COMMUN STAT-SIMUL C	Commun. Stat.-Simul. Comput.		2009	38	10					2111	2122		10.1080/03610910903249510		12	Statistics & Probability	Mathematics	508EX	WOS:000270912700006		
S	Lansel, S; Parmar, M; Wandell, BA		Bouman, CA; Miller, EL; Pollak, I		Lansel, Steven; Parmar, Manu; Wandell, Brian A.			Dictionaries for sparse representation and recovery of reflectances	COMPUTATIONAL IMAGING VII	Proceedings of SPIE-The International Society for Optical Engineering		English	Proceedings Paper	Conference on Computational Imaging VII	JAN 19-20, 2009	San Jose, CA	IS&T - Soc Imaging Sci & Technol, SPIE		Reflectance estimation; sparse recovery; dictionary learning	SPECTRA; IMAGES	The surface reflectance function of many common materials varies slowly over the visible wavelength range. For this reason, linear models with a small number of bases (5-8) are frequently used for representation and estimation of these functions. In other signal representation and recovery applications, it has been recently demonstrated that dictionary based sparse representations can outperform linear model approaches. In this paper, we describe methods for building dictionaries for sparse estimation of reflectance functions. We describe a method for building dictionaries that account for the measurement system; in estimation applications these dictionaries outperform the ones designed for sparse representation without accounting for the measurement system. Sparse recovery methods typically outperform traditional linear methods by 20-40% (in terms of RMSE).	[Lansel, Steven; Parmar, Manu] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Lansel, S (reprint author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.						AHARON M, 2005, P SPARSE 05 NOV; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; DiCarlo JM, 2003, J OPT SOC AM A, V20, P1261, DOI 10.1364/JOSAA.20.001261; Engan K, 2000, SIGNAL PROCESS, V80, P2121, DOI 10.1016/S0165-1684(00)00072-4; Engan K., 1999, NORSIG-99. Norwegian Signal Processing Symposium; Engan K., 1999, AC SPEECH SIGN PROC, V5, P2443; Gorodnitsky I.F., 1997, SIGNAL PROCESSING IE, V45, P600; Hale E. T., 2007, TR0707 RIC U; Heikkinen V, 2008, J OPT SOC AM A, V25, P2444, DOI 10.1364/JOSAA.25.002444; Lehtonen J, 2006, J OPT SOC AM A, V23, P2983, DOI 10.1364/JOSAA.23.002983; Marcellin M. W., 2000, DAT COMPR C, P523; MARIMONT DH, 1992, J OPT SOC AM A, V9, P1905, DOI 10.1364/JOSAA.9.001905; MURRAY J, 2001, SIGN SYST COMP 2001, V1, P347; Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; PARMAR M, 2008, IM PROC 2008 ICIP 20, V15, P473; PARMAR M, 2008, DIGITAL PHOTOGRAPHY, V6817; RAO B, 1997, SIGN SYST COMP 1997, V1, P955; Shimano N, 2006, IEEE T IMAGE PROCESS, V15, P1848, DOI 10.1109/TIP.2006.877069; Trussell HJ, 1996, IEEE T IMAGE PROCESS, V5, P677, DOI 10.1109/83.491346; Tzeng DY, 2005, COLOR RES APPL, V30, P84, DOI 10.1002/col.20086; WANDELL BA, 1987, IEEE T PATTERN ANAL, V9, P2; YAGHOOBI M, 2008, EUR SIGN PROC C AUG	33	2	2	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-7496-4	P SOC PHOTO-OPT INS			2009	7246								72460D	10.1117/12.813769		11	Microscopy; Optics; Radiology, Nuclear Medicine & Medical Imaging	Microscopy; Optics; Radiology, Nuclear Medicine & Medical Imaging	BVG09	WOS:000291439400007		
S	Wu, DJ; Bi, JB; Boyer, K			IEEE	Wu, Dijia; Bi, Jinbo; Boyer, Kim			A Min-Max Framework of Cascaded Classifier with Multiple Instance Learning for Computer Aided Diagnosis	CVPR: 2009 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-4	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE-Computer-Society Conference on Computer Vision and Pattern Recognition Workshops	JUN 20-25, 2009	Miami Beach, FL	IEEE Comp Soc				The computer aided diagnosis (CAD) problems of detecting potentially diseased structures from medical images are typically distinguished by the following challenging characteristics: extremely unbalanced data between negative and positive classes; stringent real-time requirement of on execution; multiple positive candidates generated for the same malignant structure that are highly correlated and spatially close to each other. To address all these problems, we propose a novel learning formulation to combine cascade classification and multiple instance learning (MIL) in a unified min-max framework, leading to a joint optimization problem which can be converted to a tractable quadratically constrained quadratic program and efficiently solved by block-coordinate optimization algorithms. We apply the proposed approach to the CAD problems of detecting pulmonary embolism and colon cancer from computed tomography images. Experimental results show that our approach significantly reduces the computational cost while yielding comparable detection accuracy to the current state-of-the-art MIL or cascaded classifiers. Although not specifically designed for balanced MIL problems, the proposed method achieves superior performance on balanced MIL benchmark data such as MUSK and image data sets.	[Wu, Dijia; Boyer, Kim] Rensselaer Polytech Inst, Troy, NY 12180 USA	Wu, DJ (reprint author), Rensselaer Polytech Inst, Troy, NY 12180 USA.	wud5@rpi.edu; jinbo.bi@siemens.com					Andrews S., 2002, ADV NEURAL INFORM PR, V15; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; BI J, 2007, P IEEE C COMP VIS PA; Bourdev L., 2005, P IEEE C COMP VIS PA, V2, P236; Dundar M., 2007, P IEEE C COMP VIS PA; Fung G., 2007, ADV NEURAL INFORM PR, V19, P425; JEMAL D, 2004, CANC STAT; LIANG J, 2008, P PULM IM AN ANN C M; Maron O., 1998, ADV NEURAL INFORM PR, V10; Raykar V. C., 2008, P 25 INT C MACH LEAR, P808, DOI 10.1145/1390156.1390258; Schneiderman H., 2004, P CVPR, V2, P29, DOI 10.1109/CVPR.2004.1315141; Settles B., 2008, ADV NEURAL INFORM PR, V20, P1289; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; Viola P., 2006, ADV NEURAL INFORM PR, VXVIII, P1417; Xiao R., 2003, 9 IEEE INT C COMP VI, V1, P709; Zhang Q., 2002, ADV NEURAL INFORM PR, V14	18	4	5	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-3992-8	PROC CVPR IEEE			2009							1359	1366				8	Computer Science, Artificial Intelligence	Computer Science	BPK14	WOS:000279038000174		
S	Elhamifar, E; Vidal, R			IEEE	Elhamifar, Ehsan; Vidal, Rene			Sparse Subspace Clustering	CVPR: 2009 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-4	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE-Computer-Society Conference on Computer Vision and Pattern Recognition Workshops	JUN 20-25, 2009	Miami Beach, FL	IEEE Comp Soc			SEGMENTATION; COMPRESSION; IMAGES	We propose a method based on sparse representation (SR) to cluster data drawn from multiple low-dimensional linear or affine subspaces embedded in a high-dimensional space. Our method is based on the fact that each point in a union of subspaces has a SR with respect to a dictionary formed by all other data points. In general, finding such a SR is NP hard. Our key contribution is to show that, under mild assumptions, the SR can be obtained 'exactly' by using l(1) optimization. The segmentation of the data is obtained by applying spectral clustering to a similarity matrix built from this SR. Our method can handle noise, outliers as well as missing data. We apply our subspace clustering algorithm to the problem of segmenting multiple motions in video. Experiments on 167 video sequences show that our approach significantly outperforms state-of-the-art methods.	[Elhamifar, Ehsan; Vidal, Rene] Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA	Elhamifar, E (reprint author), Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA.						Candes EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Donoho DL, 2009, J AM MATH SOC, V22, P1; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Baraniuk R., 2008, CONSTRUCTIVE APPROXI; CHEN G, 2008, INT J COMPUTER VISIO; COSTEIRA J, 1998, INT J COMPUT VISION, V29; ELDAR YC, 2008, ROBUST RECOVERY SIGN; Fan ZM, 2006, IEEE T PATTERN ANAL, V28, P91; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GRUBER A, 2004, IEEE C COMP VIS PATT, V1, P707; HO J, 2003, IEEE C COMP VIS PATT, V1, P11; Hong W, 2006, IEEE T IMAGE PROCESS, V15, P3655, DOI 10.1109/TIP.2006.882016; Kanatani K., 2001, IEEE INT C COMP VIS, p[II, 586]; Ma Y., 2008, SIAM REV; MARIAL J, 2008, CVPR; MARIAL J, 2008, TIP, V17, P53; Rao S., 2008, IEEE C COMP VIS PATT; Sugaya Y., 2004, WORKSH STAT METH VID; Vidal R., 2005, IEEE T PATTERN ANAL, V27, P1; Vidal R, 2008, INT J COMPUT VISION, V79, P85, DOI 10.1007/s11263-007-0099-z; Wright J., 2009, IEEE T PATTERN ANAL, V31; Yan J., 2006, EUR C COMP VIS, P94; Zelnik-Manor L., 2003, IEEE C COMP VIS PATT, V2, P287	30	1	1	2	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-3992-8	PROC CVPR IEEE			2009							2782	2789				8	Computer Science, Artificial Intelligence	Computer Science	BPK14	WOS:000279038001165		
S	Kanso, MA; Rabbat, MG		Krishnamachari, B; Suri, S; Heinzelman, W; Mitra, U		Kanso, Mohammad A.; Rabbat, Michael G.			Compressed RF Tomography for Wireless Sensor Networks: Centralized and Decentralized Approaches	DISTRIBUTED COMPUTING IN SENSOR SYSTEMS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	5th IEEE International Conference on Distributed Computing in Sensor Systems	JUN 08-10, 2009	Marina del Rey, CA	IEEE Comp Soc, TCCP, IEEE Comp Soc, TCDP, ACM SIGARCH, ACM SIGBED, European Assoc Theoret Comp Sci, IFIP WG 10 3			SIGNAL RECOVERY; RECONSTRUCTION; REGRESSION	Radio Frequency (RF) tomography refers to the process of inferring information about an environment by capturing and analyzing RF signals transmitted between nodes in a wireless sensor network. In the case where few available measurements are available, the inference techniques applied in previous work may not be feasible. Under certain assumptions, compressed sensing techniques can accurately infer environment characteristics even from a small set of measurements. This paper introduces Compressed RF Tomography, an approach that combines RF tomography and compressed sensing for monitoring in a wireless sensor network. We also present decentralized techniques which allow monitoring and data analysis to be performed cooperatively by the nodes. The simplicity of our approach makes it attractive for sensor networks. Experiments with simulated and real data demonstrate the capabilities of the approach in both centralized and decentralized scenarios.	[Kanso, Mohammad A.; Rabbat, Michael G.] McGill Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada	Kanso, MA (reprint author), McGill Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.	mohammad.kanso@mail.mcgill.ca; michael.rabbat@mcgill.ca	Rabbat, Michael/G-4582-2012				Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Haupt J, 2008, IEEE SIGNAL PROC MAG, V25, P92, DOI 10.1109/MSP.2007.914732; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Efron B, 2004, ANN STAT, V32, P407; Duarte MF, 2005, 2005 39th Asilomar Conference on Signals, Systems and Computers, Vols 1 and 2, P1537; GUIBIN LG, 1967, USSR OCMPUTATIONAL M, V7; JOHANSSON B, 2008, THESIS ROY I TECH; KIBARDIN VM, 1980, AUTOMAT REM CONTR, V40, P109; Nedic A., 2000, STOCHASTIC OPTIMIZAT; PATWARI N, 2008, EFFECTS CORRELATED S, P82; PATWARI N, 2008, P IEEE INT C AC SPE, P3873; Rabbat M., 2004, Third International Symposium on Information Processing in Sensor Networks (IEEE Cat. No.04EX890); Wilson J., 2008, RADIO TOMOGRAPHIC IM	19	17	17	1	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-02084-1	LECT NOTES COMPUT SC			2009	5516						173	186				14	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Remote Sensing	Computer Science; Remote Sensing	BKD54	WOS:000267823300013		
J	Rottenkolber, M				Rottenkolber, M.			The Suitability of Elastic Nets for Signal Detection in Spontaneous Report Databases	DRUG SAFETY			English	Meeting Abstract	9th ISoP Annual Meeting on From Pharmacovigilance to Risk Management	OCT 06-09, 2009	Reims, FRANCE	Int Soc Pharmacovigilance			SELECTION		[Rottenkolber, M.] Univ Munich, Inst Med Informat Biometry & Epidemiol, Munich, Germany							Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; GOEMAN J, 2009, PENALIZED PACKAGE VE; Hoerl A., 1988, ENCY STAT SCI, V8, P129; Schneeweiss S, 2002, EUR J CLIN PHARMACOL, V58, P285, DOI 10.1007/s00228-002-0467-0	5	0	0	0	1	ADIS INT LTD	AUCKLAND	41 CENTORIAN DR, PRIVATE BAG 65901, MAIRANGI BAY, AUCKLAND 1311, NEW ZEALAND	0114-5916			DRUG SAFETY	Drug Saf.		2009	32	10				262	985	986				2	Public, Environmental & Occupational Health; Pharmacology & Pharmacy; Toxicology	Public, Environmental & Occupational Health; Pharmacology & Pharmacy; Toxicology	504GD	WOS:000270603200268		
B	Zhang, J; Shakya, SS		Wani, MA; Kantardzic, M; Palade, V; Kurgan, L; Qi, Y		Zhang, Jian; Shakya, Shobhit S.			Knowledge Transfer for Feature Generation in Document Classification	EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS			English	Proceedings Paper	8th International Conference on Machine Learning and Applications	DEC 13-15, 2009	Miami Beach, FL	IEEE SMCS, Cal State Univ, Assoc Machine Learning & Appl, Univ Louisville		Feature generation; Knowledge transfer; Classification; Correlation		One important problem in machine learning is how to extract knowledge from prior experience, then transfer and apply this knowledge in new learning tasks. To address this problem, transfer learning leverages information from (supervised) learning on related tasks to facilitate the current learning task. Self-taught learning uses information extracted from (unsupervised) learning on related data. In this paper, we propose a new method for knowledge extraction, transfer and application in classification. We consider document classification where we mine correlation relationships among the words from a set of documents and compile a collection of correlation relationships as prior knowledge. This knowledge is then applied to generate new features for classifying documents in classes/types different from the ones which we obtain the correlation relationships from. Our experiment results show that the correlation-based knowledge transfer helps to reduce classification errors.	[Zhang, Jian; Shakya, Shobhit S.] Louisiana State Univ, Dept Comp Sci, Baton Rouge, LA 70803 USA	Zhang, J (reprint author), Louisiana State Univ, Dept Comp Sci, Baton Rouge, LA 70803 USA.	zhang@csc.lsu.edu; sshaky2@tigers.lsu.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Cohen E, 2001, IEEE T KNOWL DATA EN, V13, P64, DOI 10.1109/69.908981; Egozi O, 2008, P 23 AAAI C ART INT, P1132; GABRILOVICH E, 2005, P 19 INT JOINT C ART, P1048; Gelman A., 1995, BAYESIAN DATA ANAL; Goodman J, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P305; INDYK, 1998, ACM S THEOR COMP STO; KOH K, 2007, AAAI, P565; Lang K., 1995, P 12 INT C MACH LEAR, P331; McCallum A.K., 1996, BOW TOOLKIT STAT LAN; Ng A.Y., 2004, ACM INT C MACH LEARN, P78; RAINA R, 2007, MACH LEARN P 24 INT, P759; Raina R., 2006, P 23 INT C MACH LEAR, P713, DOI 10.1145/1143844.1143934; Thrun S., 1995, NIPS, P640; Zhang J., 2006, P 15 ACM INT C INF K, P152, DOI 10.1145/1183614.1183640	18	2	2	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3926-3				2009							255	260		10.1109/ICMLA.2009.90		6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BVC15	WOS:000291011600037		
J	Ambroise, C; Chiquet, J; Matias, C				Ambroise, Christophe; Chiquet, Julien; Matias, Catherine			Inferring sparse Gaussian graphical models with latent structure	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Gaussian graphical model; Mixture model; penalization; l(1)-penalization; Model selection; Variational inference; EM algorithm	STOCHASTIC BLOCKSTRUCTURES; MIXTURE MODEL; SELECTION; LASSO; REGRESSION; PREDICTION; LIKELIHOOD; SHRINKAGE; INFERENCE	Our concern is selecting the concentration matrix's nonzero coefficients for a sparse Gaussian graphical model in a high-dimensional setting. This corresponds to estimating the graph of conditional dependencies between the variables. We describe a novel framework taking into account a latent structure on the concentration matrix. This latent structure is used to drive a penalty matrix and thus to recover a graphical model with a constrained topology. Our method uses an l(1) penalized likelihood criterion. Inference of the graph of conditional dependencies between the variates and of the hidden variables is performed simultaneously in an iterative EM-like algorithm named SIMoNe (Statistical Inference for Modular Networks). Performances are illustrated on synthetic as well as real data, the latter concerning breast cancer. For gene regulation networks, our method can provide a useful insight both on the mutual influence existing between genes, and on the modules existing in the network.	[Ambroise, Christophe; Chiquet, Julien; Matias, Catherine] Univ Evry, Lab Stat & Genome, CNRS, UMR 8071,INRA 1152, F-91000 Evry, France	Ambroise, C (reprint author), Univ Evry, Lab Stat & Genome, CNRS, UMR 8071,INRA 1152, 523 Pl Terrasses Agora, F-91000 Evry, France.	christophe.ambroise@genopole.cnrs.fr; julien.chiquet@genopole.cnrs.fr; catherine.matias@genopole.cnrs.fr					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Drton M, 2008, J STAT PLAN INFER, V138, P1179, DOI 10.1016/j.jspi.2007.05.035; Ihmels J, 2002, NAT GENET, V31, P370, DOI 10.1038/ng941; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Snijders TAB, 1997, J CLASSIF, V14, P75, DOI 10.1007/s003579900004; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Banerjee O, 2008, J MACH LEARN RES, V9, P485; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Wu TT, 2008, ANN APPL STAT, V2, P224, DOI 10.1214/07-AOAS147; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Castelo R, 2006, J MACH LEARN RES, V7, P2621; Chiquet J, 2009, BIOINFORMATICS, V25, P417, DOI 10.1093/bioinformatics/btn637; Daudin JJ, 2008, STAT COMPUT, V18, P173, DOI 10.1007/s11222-007-9046-7; Dempster A, 1977, J ROYAL STAT SOC B, V39, P38, DOI DOI 10.2307/2984875; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Drton M, 2007, STAT SCI, V22, P430, DOI 10.1214/088342307000000113; FRANK O, 1982, J AM STAT ASSOC, V77, P835, DOI 10.2307/2287315; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; Hess KR, 2006, J CLIN ONCOL, V24, P4236, DOI 10.1200/JCO.2006.05.6861; JAAKKOLA T, 2001, NEURAL INFORM PROCES; Jones B, 2005, STAT SCI, V20, P388, DOI 10.1214/088342305000000304; Lauritzen Steffen L., 1996, OXFORD STAT SCI SERI, V17; MARIADASSOU M, 2007, 10 STAT SYST BIOL; Natowicz R., 2008, BMC BIOINFORMATICS, V9; Ng A., 2002, NIPS, V14; Nowicki K, 2001, J AM STAT ASSOC, V96, P1077, DOI 10.1198/016214501753208735; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Schafer J., 2005, STAT APPL GENETICS M, V4; Tallberg C, 2005, J MATH SOCIOL, V29, P1, DOI 10.1080/00222500590889703; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; Wille A., 2006, STAT APPL GENET MOL, V5. 1; Zanghi H, 2008, PATTERN RECOGN, V41, P3592, DOI 10.1016/j.patcog.2008.06.019	38	8	8	0	1	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2009	3						205	238		10.1214/08-EJS314		34	Statistics & Probability	Mathematics	V16FJ	WOS:000207855200009		
J	She, YY				She, Yiyuan			Thresholding-based iterative selection procedures for model selection and shrinkage	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Sparsity; nonconvex penalties; thresholding; model selection & shrinkage; lasso; ridge; SCAD	VARIABLE SELECTION; ORACLE INEQUALITIES; WAVELET SHRINKAGE; LASSO; REGRESSION; RECOVERY; SPARSITY; REGULARIZATION; OPTIMIZATION; ALGORITHMS	This paper discusses a class of thresholding-based iterative selection procedures (TISP) for model selection and shrinkage. People have long before noticed the weakness of the convex l(1)-constraint (or the soft-thresholding) in wavelets and have designed many different forms of nonconvex penalties to increase model sparsity and accuracy. But for a nonorthogonal regression matrix, there is great difficulty in both investigating the performance in theory and solving the problem in computation. TISP Provides a simple and efficient way to tackle this so that we successfully borrow the rich results in the orthogonal design to solve the nonconvex penalized regression for a general design matrix. Our starting point is, however, thresholding rules rather than penalty functions. Indeed, there is a universal connection between them. But a drawback of the latter is its non-unique form, and our approach greatly facilitates the computation and the analysis. In fact, we are able to build the convergence theorem and explore theoretical properties of the selection and estimation via TISP nonasymptotically. More importantly, a novel Hybrid-TISP is proposed based on hard-thresholding and ridge-thresholding. It provides a fusion between the l(0)-penalty and the l(2)-penalty, and adaptively achieves the right balance between shrinkage and selection in statistical modeling. In practice, Hybrid-TISP shows superior performance in test-error and is parsimonious.	Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA	She, YY (reprint author), Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA.	yshe@stat.fsu.edu					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; BROWDER FE, 1967, J MATH ANAL APPL, V20, P197, DOI 10.1016/0022-247X(67)90085-6; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zhang HH, 2006, BIOINFORMATICS, V22, P88, DOI 10.1093/bioinformatics/bti736; SIDAK Z, 1967, J AM STAT ASSOC, V62, P626, DOI 10.2307/2283989; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Candes EJ, 2006, ACT NUMERIC, V15, P257, DOI 10.1017/S0962492906230010; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Wu TT, 2008, ANN APPL STAT, V2, P224, DOI 10.1214/07-AOAS147; Antoniadis A., 2007, STAT SURVEYS, V1, P16, DOI DOI 10.1214/07-SS014; Antoniadis A, 1997, ITALIAN J STAT, V6, P97; Bunea F, 2007, ELECTRON J STAT, V1, P169, DOI 10.1214/07-EJS008; Cai JW, 2007, ANN STAT, V35, P324, DOI 10.1214/009053606000001145; CANDES E, 2005, ANN STAT, V35, P2392; Fan J, 1997, ITALIAN J STAT, V6, P97; Gannaz I., 2006, ROBUST ESTIMATION WA; GAO HY, 1998, J COMPUT GRAPH STAT, V7, P469, DOI DOI 10.2307/1390677; Hunter DR, 2000, J COMPUT GRAPH STAT, V9, P52, DOI 10.2307/1390612; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; MEINSHAUSEN N, 2009, ANN STAT, V720, P246; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; SHE Y., 2008, THRESHOLDING BASED I; She Y, 2008, THESIS STANFORD U; SHIMIZU K., 1997, NONDIFFERENTIBLE 2 L; Wang LF, 2007, BIOINFORMATICS, V23, P1486, DOI 10.1093/bioinformatics/btm125; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520; ZOU H, 2008, ANN STAT, P1509; Zou H., 2006, JASA, V101, P476	40	22	22	0	0	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2009	3						384	415		10.1214/08-EJS348		32	Statistics & Probability	Mathematics	V16FJ	WOS:000207855200017		
J	Johnson, BA				Johnson, Brent A.			On lasso for censored data	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Accelerated failure time model; Buckley-James estimator; least angle regression; survival analysis; synthetic data	LARGE-SAMPLE THEORY; LINEAR RANK-TESTS; VARIABLE SELECTION; LEAST-SQUARES; REGRESSION-ANALYSIS; MODEL; ASYMPTOTICS	In this paper, we propose a new lasso-type estimator for censored data after one-step imputatation. While several penalized likelihood estimators have been proposed for censored data variable selection through hazards regression, many such estimators require parametric or proportional hazards assumptions. The proposed estimator, on the other hand, is based on the linear model and least-squares principles. Iterative penalized Buckley-James estimators are also popular in this setting but have been shown to be unstable and unreliable. Unlike path-based learning based on least-squares approximation, our method requires no covariance assumption and the method is valid for even modest sample sizes. Our calibration estimator is the minimizer of a convex loss function using synthetic data and yields reproducible coefficient estimates and coefficient paths. The numerical algorithms are fast reliable, and readily available because they build on existing software for complete, uncensored data. We examine the large and small sample properties of our estimator and illustrate the method through simulation studies and application to two real data sets.	Emory Univ, Dept Biostat, Rollins Sch Publ Hlth, Atlanta, GA 30322 USA	Johnson, BA (reprint author), Emory Univ, Dept Biostat, Rollins Sch Publ Hlth, 1518 Clifton Rd NE, Atlanta, GA 30322 USA.	bajohn3@emory.edu			National Institutes of Allergies and infections Diseases [R03 AI068484]; Emory's Center for AIDS Research [P30 AI050409]	The research of the author was supported, in part, by a grant from the National Institutes of Allergies and infections Diseases (R03 AI068484) and Emory's Center for AIDS Research (P30 AI050409).	Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Wang N, 1998, BIOMETRIKA, V85, P935, DOI 10.1093/biomet/85.4.935; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Johnson BA, 2008, J NONPARAMETR STAT, V20, P241, DOI 10.1080/10485250801998950; Zeng D, 2007, J AM STAT ASSOC, V102, P1387, DOI 10.1198/016214507000001085; Efron B, 2004, ANN STAT, V32, P407; BUCKLEY J, 1979, BIOMETRIKA, V66, P429; COX DR, 1972, J R STAT SOC B, V34, P187; Datta S, 2007, BIOMETRICS, V63, P259, DOI 10.1111/j.1541-0420.2006.00660.x; DICKSON ER, 1989, HEPATOLOGY, V10, P1, DOI 10.1002/hep.1840100102; Efron B., 2005, LOCAL FALSE DISCOVER; Fleming T. R., 1991, COUNTING PROCESSES S; Fu W. J., 2003, BIOMETRICS, V35, P109; Gehan E. A., 1965, BIOMETRIKA, V90, P341; GEYER CJ, 1994, ANN STAT, V22, P1993, DOI 10.1214/aos/1176325768; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; HUANG J., 2009, BIOMETRICS IN PRESS; Huang JL, 2006, ACTA CRYSTALLOGR E, V62, pM611, DOI 10.1107/S1600536806006283; Jin ZZ, 2006, BIOMETRIKA, V93, P147, DOI 10.1093/biomet/93.1.147; Johnson BA, 2008, J ROY STAT SOC B, V70, P351, DOI 10.1111/j.1467-9868.2008.00639.x; JOHNSON B.A., 2008, ESTIMATION L1 REGULA; JOHNSON B.A., 2009, RANK BASED ESTIMATIO; Johnson BA, 2008, J AM STAT ASSOC, V103, P672, DOI 10.1198/016214508000000184; KOUL H, 1981, ANN STAT, V9, P1276, DOI 10.1214/aos/1176345644; LAI TL, 1991, ANN STAT, V19, P1370, DOI 10.1214/aos/1176348253; MANTEL NATHAN, 1966, CANCERCHEMOTHERAP REP, V50, P163; MILLER R, 1982, BIOMETRIKA, V69, P521; Oakes D., 1984, ANAL SURVIVAL DATA; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Prentice R. L., 2002, STAT ANAL FAILURE TI; PRENTICE RL, 1978, BIOMETRIKA, V65, P167, DOI 10.1093/biomet/65.1.167; REID N, 1994, STAT SCI, V9, P439, DOI 10.1214/ss/1177010394; RITOV Y, 1990, ANN STAT, V18, P303, DOI 10.1214/aos/1176347502; RUBIN D., 2007, INT J BIOSTATISTICS, V3; SCHMID M., 2008, 0182008 U MUN DEP ST; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; TSIATIS A. A., 2006, SEMIPARAMETRIC THEOR; TSIATIS AA, 1990, ANN STAT, V18, P354, DOI 10.1214/aos/1176347504; VAN DER LAAN M. J., 2003, UNIFIED METHODS CENS; WANG H., 2007, J BUSINESS EC STAT, V11, P1; Wang HS, 2007, J AM STAT ASSOC, V102, P1039, DOI 10.1198/016214507000000509; Wang SX, 2008, ACTA CRYSTALLOGR E, V64, pM78, DOI 10.1107/S1600536807062186; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037; ZOU H., 2006, BIOMETRIKA, V101, P1418	46	12	12	4	7	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2009	3						485	506		10.1214/08-EJS322		22	Statistics & Probability	Mathematics	V16FJ	WOS:000207855200021		
J	Mang, DB; Lin, YZ; Zhang, M				Mang, Dabao; Lin, Yanzhu; Zhang, Min			Penalized orthogonal-components regression for large p small n data	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Empirical Bayes thresholding; Latent-variable model; p >> n data; POCRE; Sparse predictors; Supervised dimension reduction	PARTIAL LEAST-SQUARES; MODEL SELECTION; LASSO; SHRINKAGE	Here we propose a penalized orthogonal-components regression (POCRE) for large p small n data. Orthogonal components are sequentially constructed to maximize, upon standardization, their correlation to the response residuals. A new penalization framework, implemented via empirical Bayes thresholding, is presented to effectively identify sparse predictors of each component. POCRE is computationally efficient owing to its sequential construction of leading sparse principal components. In addition, such construction offers other properties such as grouping highly correlated predictors and allowing for collinear or nearly collinear predictors. With multivariate responses, POCRE can construct common components and thus build up latent-variable models for large p small n data.	[Mang, Dabao; Lin, Yanzhu; Zhang, Min] Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA	Zhang, M (reprint author), Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA.	zhangdb@stat.purdue.edu; lin43@stat.purdue.edu; minzhang@stat.purdue.edu			NSF [IIS-0844945]; Oncological Science Center of Purdue University	The authors thank Jayanta K. Ghosh for his helpful comments. The authors also thank the associate editor and two referees for constructive suggestions that led to substantial improvement of the article. This research was partially supported by NSF CAREER award IIS-0844945 and the CCE project at the Oncological Science Center of Purdue University.	Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Shen HP, 2008, J MULTIVARIATE ANAL, V99, P1015, DOI 10.1016/j.jmva.2007.06.007; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; Breiman L, 1996, ANN STAT, V24, P2350; Cao K.A., 2008, STAT APPL GENET MOL, V7, P35; CHUN H, 2007, SPARSE PARTIAL LEAST; Cook RD, 2007, STAT SCI, V22, P1, DOI 10.1214/088342306000000682; Efron B, 2004, J AM STAT ASSOC, V99, P96, DOI 10.1198/016214504000000089; GARTHWAITE PH, 1994, J AM STAT ASSOC, V89, P122, DOI 10.2307/2291207; Hastie T, 2000, GENOME BIOL, V1, P1, DOI DOI 10.1186/GB-2000-1-2-RESEARCH0003; Johnstone IM, 2004, ANN STAT, V32, P1594, DOI 10.1214/009053604000000030; JOHNSTONE M, 2005, J STAT SOFTW, V12, P1; Kramer R., 1998, CHEMOMETRIC TECHNIQU; Lan H, 2006, PLOS GENET, V2, P51, DOI 10.1371/journal.pgen.0020006; Stein C., 1961, P 4 BERK S MATH STAT, V1, P361; STEWART GW, 1974, INTRO MATRIX COMPUTA; Wold H., 1975, PERSPECTIVES PROBABI; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	24	6	7	1	5	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2009	3						781	796		10.1214/09-EJS354		16	Statistics & Probability	Mathematics	V16FJ	WOS:000207855200031		
J	Ruppert, D; Wand, MP; Carroll, RJ				Ruppert, David; Wand, M. P.; Carroll, Raymond J.			Semiparametric regression during 2003-2007	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Asymptotics; boosting; BUGS; functional data analysis; generalized linear mixed models; graphical models; hierarchical bayesian models; kernel machines; longitudinal data analysis; mixed models; Monte Carlo methods; penalized splines; spatial statistics	GENERALIZED ADDITIVE-MODELS; LIKELIHOOD RATIO TESTS; LINEAR MIXED MODELS; PENALIZED SPLINE REGRESSION; VARYING-COEFFICIENT MODELS; BAYESIAN P-SPLINES; GEOADDITIVE HAZARD REGRESSION; SEQUENTIAL MONTE-CARLO; SINGLE-INDEX MODELS; SPACE-TIME DATA	Semiparametric regression is a fusion between parametric regression and nonparametric regression that integrates low-rank penalized splines, mixed model and hierarchical Bayesian methodology thus allowing more streamlined handling of longitudinal and spatial correlation. We review progress in the field over the five-year period between 2003 and 2007. We find semiparametric regression to be a vibrant field with substantial involvement and activity, continual enhancement and widespread application.	[Ruppert, David] Cornell Univ, Sch Operat Res & Informat Engn, Ithaca, NY 14853 USA; [Wand, M. P.] Univ Wollongong, Sch Math & Appl Stat, Ctr Stat & Survey Methodol, Wollongong, NSW 2522, Australia; [Carroll, Raymond J.] Texas A&M Univ, Dept Stat, College Stn, TX 77843 USA	Ruppert, D (reprint author), Cornell Univ, Sch Operat Res & Informat Engn, 1170 Comstock Hall, Ithaca, NY 14853 USA.	dr24@cornell.edu; mwand@uow.edu.au; carroll@stat.tamu.edu	Ruppert, David/B-1301-2013	Ruppert, David/0000-0002-6713-2257	National Cancer Institute [CA57030, CA104620]; National Science Foundation [DMS-0805975]; Australian Research Council [DP0877055]; King Abdullah University of Science and Technology [KUS-CI-016-04]	Supported by grants from the National Cancer Institute (CA57030) and the National Science Foundation (DMS-0805975).Supported by a grant from the Australian Research Council (DP0877055).Supported by grants from the National Cancer Institute (CA57030, CA104620), and also in part by award number KUS-CI-016-04 made by the King Abdullah University of Science and Technology.	Adebayo SB, 2005, STAT MED, V24, P709, DOI 10.1002/sim.1842; Lin XH, 1999, J ROY STAT SOC B, V61, P381, DOI 10.1111/1467-9868.00183; STRAM DO, 1994, BIOMETRICS, V50, P1171, DOI 10.2307/2533455; Buhlmann P, 2007, STAT SCI, V22, P477, DOI 10.1214/07-STS242; Currie ID, 2004, STAT MODEL, V4, P279, DOI 10.1191/1471082X04st080oa; SELF SG, 1987, J AM STAT ASSOC, V82, P605, DOI 10.2307/2289471; DiMatteo I, 2001, BIOMETRIKA, V88, P1055, DOI 10.1093/biomet/88.4.1055; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Fahrmeir L, 2004, STAT SINICA, V14, P731; Ruppert D, 2002, J COMPUT GRAPH STAT, V11, P735, DOI 10.1198/106186002853; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; FAN JQ, 1992, J AM STAT ASSOC, V87, P998, DOI 10.2307/2290637; Brezger A, 2006, COMPUT STAT DATA AN, V50, P967, DOI 10.1016/j.csda.2004.10.011; Breiman L, 1998, ANN STAT, V26, P801; Wood SN, 2004, J AM STAT ASSOC, V99, P673, DOI 10.1198/016214504000000980; Durban M, 2005, STAT MED, V24, P1153, DOI 10.1002/sim.1991; Marjoram P, 2003, P NATL ACAD SCI USA, V100, P15324, DOI 10.1073/pnas.0306899100; Nott D, 2006, COMPUTATION STAT, V21, P603, DOI 10.1007/s00180-006-0017-9; Beran R, 1998, ANN STAT, V26, P1826; Kauermann G, 2006, COMPUT STAT DATA AN, V51, P1944, DOI 10.1016/j.csda.2005.12.009; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; Lunn DJ, 2000, STAT COMPUT, V10, P325, DOI 10.1023/A:1008929526011; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Haario H, 2005, COMPUTATION STAT, V20, P265, DOI 10.1007/BF02789703; Dominici F, 2004, J AM STAT ASSOC, V99, P938, DOI 10.1198/016214504000000656; Denison DGT, 1998, J ROY STAT SOC B, V60, P333, DOI 10.1111/1467-9868.00128; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; Canfield RL, 2003, NEW ENGL J MED, V348, P1517, DOI 10.1056/NEJMoa022848; Lang S, 2004, J COMPUT GRAPH STAT, V13, P183, DOI 10.1198/1061860043010; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Moguerza JM, 2006, STAT SCI, V21, P322, DOI 10.1214/088342306000000493; Eilers PHC, 1996, STAT SCI, V11, P89, DOI 10.1214/ss/1038425655; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Verbyla AP, 1999, J ROY STAT SOC C-APP, V48, P269, DOI 10.1111/1467-9876.00154; Genovese CR, 2004, STAT SCI, V19, P308, DOI 10.1214/088342304000000161; Bollaerts K, 2006, BRIT J MATH STAT PSY, V59, P451, DOI 10.1348/000711005X84293; HAMPEL FR, 1974, J AM STAT ASSOC, V69, P383, DOI 10.2307/2285666; Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026; Beaumont MA, 2002, GENETICS, V162, P2025; Skaug HJ, 2006, COMPUT STAT DATA AN, V51, P699, DOI 10.1016/j.csda.2006.03.005; Paciorek CJ, 2006, ENVIRONMETRICS, V17, P483, DOI 10.1002/env.785; Loeb V, 1997, NATURE, V387, P897, DOI 10.1038/43174; ANSLEY CF, 1993, BIOMETRIKA, V80, P75, DOI 10.1093/biomet/80.1.75; Antoniadis A, 2007, COMPUT STAT DATA AN, V51, P4793, DOI 10.1016/j.csda.2006.09.038; Apanasovich TV, 2008, BIOMETRICS, V64, P490, DOI 10.1111/j.1541-0420.2007.00892.x; Augustin NH, 2007, J R STAT SOC C-APPL, V56, P29, DOI 10.1111/j.1467-9876.2007.00563.x; Avalos M, 2007, COMPUT STAT DATA AN, V51, P2851, DOI 10.1016/j.csda.2006.10.007; Bachrach LK, 1999, J CLIN ENDOCR METAB, V84, P4702, DOI 10.1210/jc.84.12.4702; Baladandayuthapani V, 2005, J COMPUT GRAPH STAT, V14, P378, DOI 10.1198/106186005X47345; Baladandayuthapani V, 2008, BIOMETRICS, V64, P64, DOI 10.1111/j.1541-0420.2007-00846.x; BALL R, 2009, IMESPLINES 1 0 1 R P; Banerjee T, 2006, COMPUT STAT DATA AN, V51, P1147, DOI 10.1016/j.csda.2005.11.013; Berry SM, 2002, J AM STAT ASSOC, V97, P160, DOI 10.1198/016214502753479301; Binder H, 2008, STAT COMPUT, V18, P87, DOI 10.1007/s11222-007-9040-0; Bollaerts K, 2006, STAT MODEL, V6, P189, DOI 10.1191/1471082X06st118oa; Branscum AJ, 2007, AUST NZ J STAT, V49, P287, DOI 10.1111/j.1467-842X.2007.00481.x; Breidt FJ, 2005, BIOMETRIKA, V92, P831, DOI 10.1093/biomet/92.4.831; Breidt F. J., 2009, HDB STAT, V29; Breidt FJ, 2007, J AM STAT ASSOC, V102, P803, DOI 10.1198/016214506000001167; Breidt FJ, 2000, ANN STAT, V28, P1026; Brezger A, 2005, J STAT SOFTW, V14, P1; Brezger A, 2007, J ROY STAT SOC C-APP, V56, P327, DOI 10.1111/j.1467-9876.2007.00580.x; BROWN D, 2007, BIOMETR J, V49, P411; Brown LD, 1996, ANN STAT, V24, P2384; Brown LD, 2002, ANN STAT, V30, P688; Cadarso-Suarez C, 2006, STAT MED, V25, P603, DOI 10.1002/sim.2356; Cai T, 2002, J COMPUT GRAPH STAT, V11, P784, DOI 10.1198/106186002862; Cai TX, 2003, BIOMETRICS, V59, P570, DOI 10.1111/1541-0420.00067; Cantet RJC, 2005, J ANIM SCI, V83, P2482; Cardot H, 2003, STAT SINICA, V13, P571; Carroll RJ, 2004, STAT SINICA, V14, P649; Carroll R.J., 2006, MEASUREMENT ERROR NO; Carroll R.J., 2008, J ROYAL STAT SOC B, V69, P859; Carroll RJ, 2004, J AM STAT ASSOC, V99, P736, DOI 10.1198/016214504000001088; Chavez-Demoulin V, 2005, J ROY STAT SOC C-APP, V54, P207, DOI 10.1111/j.1467-9876.2005.00479.x; Chen KN, 2005, BIOMETRIKA, V92, P59, DOI 10.1093/biomet/92.1.59; Chen QX, 2006, BIOMETRICS, V62, P177, DOI 10.1111/j.1541-0420.2005.00438.x; Choudhary PK, 2007, COMPUT STAT DATA AN, V51, P6229, DOI 10.1016/j.csda.2007.01.006; Choudhary PK, 2006, BIOMETRICS, V62, P288, DOI 10.1111/j.1541-0420.2005.00422.x; CHRISTENSEN OF, 2008, GEORG1M 0 8 R PACKAG; Claeskens G, 2004, J ROY STAT SOC B, V66, P909, DOI 10.1111/j.1467-9868.2004.05421.x; COLE TJ, 1992, STAT MED, V11, P1305, DOI 10.1002/sim.4780111005; Congdon P, 2006, COMPUT STAT DATA AN, V50, P422, DOI 10.1016/j.csda.2004.08.008; Cook R.D., 1982, RESIDUALS INFLUENCE; Coull BA, 2004, STAT SINICA, V14, P695; Cowell R. G., 1999, PROBABILISTIC NETWOR; Crainiceanu C, 2005, BIOMETRIKA, V92, P91, DOI 10.1093/biomet/92.1.91; Crainiceanu CM, 2007, J COMPUT GRAPH STAT, V16, P265, DOI 10.1198/106186007x208768; Crainiceanu C. M., 2005, J STAT SOFTW, V14, P1; Crainiceanu CM, 2004, J ROY STAT SOC B, V66, P165, DOI 10.1111/j.1467-9868.2004.00438.x; Crainiceanu CM, 2004, J MULTIVARIATE ANAL, V91, P35, DOI 10.1016/j.jmva.2004.04.008; Crainiceanu CM, 2008, J AM STAT ASSOC, V103, P21, DOI 10.1198/016214507000001409; Crainiceanu CM, 2004, STAT SINICA, V14, P713; Cristianini N., 2000, INTRO SUPPORT VECTOR; Currie I., 2002, STAT MODEL, V2, P333; Currie ID, 2006, J ROY STAT SOC B, V68, P259, DOI 10.1111/j.1467-9868.2006.00543.x; Dean CB, 2007, ENVIRONMETRICS, V18, P713, DOI 10.1002/env.870; Del Moral P, 2006, J ROY STAT SOC B, V68, P411, DOI 10.1111/j.1467-9868.2006.00553.x; DEMITRIADOU E, 2008, E1071 1 5 R PACKAGE; Demmel J. W., 1997, APPL NUMERICAL LINEA; Diggle P., 2002, ANAL LONGITUDINAL DA; DONNELLY CA, 1995, J AM STAT ASSOC, V90, P984, DOI 10.2307/2291334; Draper N. R., 1998, APPL REGRESSION ANAL; Durban M, 2003, COMPUTATION STAT, V18, P251; EFRON B, 1986, DOUBLE EXPONENTIAL F, V81, P709; Eilers PHC, 2006, COMPUT STAT DATA AN, V50, P61, DOI 10.1016/j.csda.2004.07.008; Eilers PHC, 2007, STAT MED, V26, P3358, DOI 10.1002/sim.2817; Eilers PHC, 2003, CHEMOMETR INTELL LAB, V66, P159, DOI 10.1016/S0169-7439(03)00029-7; EILERS PHC, 2008, STAT MED; Eilerss PHC, 2005, J CHEMOMETR, V19, P317, DOI 10.1002/cem.935; ELLIOTT MR, 2007, BIOSTATISTICS, V8, P758; Eubank RL, 1999, NONPARAMETRIC REGRES; Fahrmeir L, 2006, APPL STOCH MODEL BUS, V22, P351, DOI 10.1002/asmb.631; Fahrmeir L, 2007, PSYCHOMETRIKA, V72, P327, DOI 10.1007/s11336-007-9010-7; Fan J., 2003, NONLINEAR TIME SERIE; Fan J, 1995, LOCAL POLYNOMIAL MOD; FAN Y, 2006, BAYESIAN STAT, V8; Figueiras A, 2005, J EPIDEMIOL COMMUN H, V59, P881, DOI 10.1136/jech.2004.026740; Fitzmaurice G, 2009, CH CRC HANDB MOD STA, P1; French JL, 2004, BIOSTATISTICS, V5, P177, DOI 10.1093/biostatistics/5.2.177; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Ganguli B, 2006, STAT MED, V25, P2469, DOI 10.1002/sim.2378; Ganguli B, 2005, AUST NZ J STAT, V47, P193, DOI 10.1111/j.1467-842X.2005.00383.x; Ganguli B, 2004, J COMPUT GRAPH STAT, V13, P954, DOI 10.1198/106186004X12515; Gelman A, 2006, BAYESIAN ANAL, V1, P515; Geraci M, 2006, STAT MODEL, V6, P321, DOI 10.1177/1471082006071849; Ghidey W, 2004, BIOMETRICS, V60, P945, DOI 10.1111/j.0006-341X.2004.00250.x; Ghosh D, 2007, BIOSTATISTICS, V8, P402, DOI 10.1093/biostatistics/kxl018; Gianola D, 2006, GENETICS, V173, P1761, DOI 10.1534/genetics.105.049510; Gimenez O, 2006, BIOMETRICS, V62, P691, DOI 10.1111/j.1541-0420.2005.00514.x; Gluhovsky I, 2007, TECHNOMETRICS, V49, P129, DOI 10.1198/004017006000000426; Green P, 1994, NONPARAMETRIC REGRES; GREEN PJ, 1985, BIOMETRIKA, V72, P523; GREVEN S, 2008, J COMPUTATIONAL GRAP, V17, P8700; Gryparis A, 2007, J ROY STAT SOC C-APP, V56, P183, DOI 10.1111/j.1467-9876.2007.00573.x; Gurrin LC, 2005, STAT MED, V24, P3361, DOI 10.1002/sim.2193; Hall P, 2005, BIOMETRIKA, V92, P105, DOI 10.1093/biomet/92.1.105; HAREZLAK J, 2006, COMPUTATIONAL STAT D, V51, P4911; Harezlak J, 2007, STAT MED, V26, P1383, DOI 10.1002/sim.2623; Harezlak J, 2005, BIOMETRICS, V61, P1037, DOI 10.1111/j.1541-0420.2005.00376.x; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T., 2006, STAT SCI, V21, P352, DOI 10.1214/088342306000000466; HASTIE T, 2006, GAM 0 98 R PACKAGE; Hastie TJ, 1990, GEN ADDITIVE MODELS; Heim S, 2007, COMPUT STAT DATA AN, V51, P6212, DOI 10.1016/j.csda.2007.01.005; Hennerfeind A, 2006, J AM STAT ASSOC, V101, P1065, DOI 10.1198/016214506000000348; Hens N, 2006, STAT MED, V25, P2502, DOI 10.1002/sim.2559; Hickernell FJ, 2005, STAT SCI, V20, P1, DOI 10.1214/088342304000000468; Houseman EA, 2006, J AM STAT ASSOC, V101, P1365, DOI 10.1198/016214506000000627; Hu ZH, 2004, BIOMETRIKA, V91, P251, DOI 10.1093/biomet/91.2.251; Izenman A. J., 1975, Journal of Multivariate Analysis, V5, DOI 10.1016/0047-259X(75)90042-1; Jank W, 2007, J ROY STAT SOC C-APP, V56, P1, DOI 10.1111/j.1467-9876.2007.00562.x; Jullion A, 2007, COMPUT STAT DATA AN, V51, P2542, DOI 10.1016/j.csda.2006.09.027; Kammann EE, 2003, J ROY STAT SOC C-APP, V52, P1, DOI 10.1111/1467-9876.00385; KARATZOGLOU A, 2007, KERNLAB 0 9 R PACKAG; Kauermann G, 2009, J R STAT SOC B, V71, P487, DOI 10.1111/j.1467-9868.2008.00691.x; Kauermann G, 2005, J STAT PLAN INFER, V127, P53, DOI 10.1016/j.jspi.2003.09.023; Kim I, 2003, BIOMETRICS, V59, P1158, DOI 10.1111/j.0006-341X.2003.00133.x; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Kneib T, 2006, BIOMETRICS, V62, P109, DOI 10.1111/j.1541-0420.2005.00392.x; Kneib T, 2007, SCAND J STAT, V34, P207, DOI 10.1111/j.1467-9469.2006.00524.x; Kneib T, 2006, COMPUT STAT DATA AN, V51, P777, DOI 10.1016/j.csda.2006.06.019; KOENKER R, 2008, QUANTILE REGRESSION; KOOPERBERG C, 2007, POLSPLINE 1 0 R PACK; Krivobokova T, 2008, J COMPUT GRAPH STAT, V17, P1, DOI 10.1198/106186008X287328; Krivobokova T, 2007, J AM STAT ASSOC, V102, P1328, DOI 10.1198/016214507000000978; KRIVOBOVA T, 2007, ADAPTFIT 0 2 R PACKA; Kuo FY, 2008, METHODOL COMPUT APPL, V10, P239, DOI 10.1007/s11009-007-9045-3; Lambert P, 2005, STAT MED, V24, P3977, DOI 10.1002/sim.2396; LANG S, 2003, COMPUTATION STAT, V18, P163; Lee TCM, 2007, COMPUTATION STAT, V22, P159, DOI 10.1007/s00180-007-0031-6; Leitenstorfer F, 2007, COMPUT STAT DATA AN, V51, P4605, DOI 10.1016/j.csda.2006.08.008; Leitenstorfer F, 2007, BIOSTATISTICS, V8, P654, DOI 10.1093/biostatistics/kxl036; LI Y, 2007, ANN STAT, V35, P1068; Li YX, 2008, BIOMETRIKA, V95, P415, DOI 10.1093/biomet/asn010; Liang H, 2003, BIOSTATISTICS, V4, P297, DOI 10.1093/biostatistics/4.2.297; LIGGES U, 2007, BRUGS 0 4 R PACKAGE; Lin J, 2006, BIOMETRICS, V62, P803, DOI 10.1111/j.1541-0420.2005.00521.x; Lin X., 2006, J ROYAL STAT SOC B, V68, P68; Lin XH, 2000, J AM STAT ASSOC, V95, P520, DOI 10.2307/2669396; Lin XH, 2004, BIOMETRIKA, V91, P177, DOI 10.1093/biomet/91.1.177; Lin XH, 1997, BIOMETRIKA, V84, P309, DOI 10.1093/biomet/84.2.309; Lin XH, 2001, J AM STAT ASSOC, V96, P1045, DOI 10.1198/016214501753208708; LINTON OB, 2003, P 2 SEATTL S BIOST A, P23; Little R., 2003, J OFF STAT, V19, P99; Liu A, 2004, J STAT COMPUT SIM, V74, P581, DOI 10.1080/00949650310001623416; Liu DS, 2007, ACTA CRYSTALLOGR E, V63, pM385, DOI 10.1107/S1600536806046538; Luo Z, 1997, J AM STAT ASSOC, V92, P107, DOI 10.2307/2291454; Ma YY, 2006, J AM STAT ASSOC, V101, P1465, DOI 10.1198/016214506000000519; MacNab YC, 2007, ENVIRONMETRICS, V18, P727, DOI 10.1002/env.876; MacNab YC, 2007, STAT MED, V26, P4455, DOI 10.1002/sim.2868; Malfait N, 2003, CAN J STAT, V31, P115, DOI 10.2307/3316063; Mallick B, 2002, BIOMETRICS, V58, P13, DOI 10.1111/j.0006-341X.2002.00013.x; Mallick BK, 2005, J R STAT SOC B, V67, P219, DOI 10.1111/j.1467-9868.2005.00498.x; Marron JS, 2005, COMPUTATION STAT, V20, P481, DOI 10.1007/BF02741310; Marx BD, 2005, TECHNOMETRICS, V47, P13, DOI [10.1198/004017004000000626, 10.1098/004017004000000626]; Marx BD, 1999, TECHNOMETRICS, V41, P1, DOI 10.2307/1270990; Marx BD, 2002, J CHEMOMETR, V16, P129, DOI 10.1002/cem.701; McCulloch C., 2008, GEN LINEAR MIXED MOD; MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.2307/2337198; Morris JS, 2006, J ROY STAT SOC B, V68, P179, DOI 10.1111/j.1467-9868.2006.00539.x; MORRIS JS, 2007, BIOMETRICS, V64, P479; Morris JS, 2003, J AM STAT ASSOC, V98, P573, DOI 10.1198/016214503000000422; Morris JS, 2006, J AM STAT ASSOC, V101, P1352, DOI 10.1198/016214506000000465; Namata H, 2007, J APPL STAT, V34, P923, DOI 10.1080/02664760701590525; Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461; Ngo L, 2004, J STAT SOFTW, V9, P1; NUSSBAUM M, 1985, ANN STAT, V13, P984, DOI 10.1214/aos/1176349651; NYCHKA D, 2007, FIELDS 4 1 R PACKAGE; O'Sullivan F., 1986, STAT SCI, V4, P505; OConnell MA, 1997, J COMPUT GRAPH STAT, V6, P224, DOI 10.2307/1390932; OGDEN RT, 1996, ESSENTIAL WAVELETS S; Opsomer JD, 2008, J ROY STAT SOC B, V70, P265; Opsomer JD, 2007, J AM STAT ASSOC, V102, P400, DOI 10.1198/016214506000001491; ORMEROD JT, 2008, COMPUTATIONAL STAT; Paciorek C., 2007, J STAT SOFTWARE, V19; PACIOREK CJ, 2007, SPECTRALGP 1 1 R PAC; Paciorek CJ, 2007, COMPUT STAT DATA AN, V51, P3631, DOI 10.1016/j.csda.2006.11.008; Parker R.L., 1985, J ROYAL STAT SOC B, V47, P40; Pearce ND, 2006, AM STAT, V60, P233, DOI 10.1198/000313006X124541; Peng RD, 2006, J ROY STAT SOC A STA, V169, P179, DOI 10.1111/j.1467-985X.2006.00410.x; Piepho HP, 2007, AM STAT, V61, P224, DOI 10.1198/000313007X220426; PINHEIRO J, 2008, N1ME 3 1 R PACKAGE; Qin L, 2006, BIOSTATISTICS, V7, P225, DOI 10.1093/biostatistics/kxj003; Qu A, 2006, BIOMETRICS, V62, P379, DOI 10.1111/j.1541-0420.2005.00490.x; R Development Core Team, 2008, R LANG ENV STAT COMP; Ramsay J. O., 2002, APPL FUNCTIONAL DATA; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; RAO J. N. K., 2003, SMALL AREA ESTIMATIO; Rasmussen C. E., 2006, GAUSSIAN PROCESS MAC; Reiss PT, 2007, J AM STAT ASSOC, V102, P984, DOI 10.1198/016214507000000527; RIBEIRO PJ, 2008, GEOR 1 6 R PACKAGE; RICE J, 1986, STAT PROBABIL LETT, V4, P203, DOI 10.1016/0167-7152(86)90067-2; Robert CP, 2004, STAT SCI, V19, P1, DOI 10.1214/088342304000000062; Roca-Pardinas J, 2006, STAT MED, V25, P2483, DOI 10.1002/sim.2415; Ruppert D, 2007, BIOMETRICS, V63, P483, DOI 10.1111/j.1541-0420.2006.00704.x; Ruppert D., 2003, SEMIPARAMETRIC REGRE; Sain SR, 2006, J AGR BIOL ENVIR ST, V11, P462, DOI 10.1198/108571106X154957; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SCHEIPL F, 2007, RLRSIM 1 0 R PACKAGE; Sergeant JC, 2006, BIOSTATISTICS, V7, P213, DOI 10.1093/biostatistics/kxj002; SILVERMAN BW, 1984, ANN STAT, V12, P898, DOI 10.1214/aos/1176346710; Sisson SA, 2007, P NATL ACAD SCI USA, V104, P1760, DOI 10.1073/pnas.0607208104; Skrondal A., 2004, GEN LATENT VARIABLE; Smith ADAC, 2008, STAT MED, V27, P435, DOI 10.1002/sim.2925; Smith M, 1996, J ECONOMETRICS, V75, P317, DOI 10.1016/0304-4076(95)01763-1; SPECKMAN P, 1988, J ROY STAT SOC B MET, V50, P413; Speed TP, 1991, STAT SCI, V6, P42, DOI 10.1214/ss/1177011930; Staudenmayer J, 2008, J AM STAT ASSOC, V103, P726, DOI 10.1198/016214508000000328; Stein M. L., 1999, INTERPOLATION SPATIA; Stone CJ, 1997, ANN STAT, V25, P1371; Sturtz S., 2005, J STAT SOFTWARE, V12; STURTZ S, 2007, R2WINBUGS 2 1 R PACK; Takeuchi I, 2006, J MACH LEARN RES, V7, P1231; Tarantola A., 2005, INVERSE PROBLEM THEO; Thomas A., 2006, R NEWS, V6, P12; THOMPSON R, 1985, J ROYAL STAT SOC B, V47, P43; Tukey J. W., 1977, EXPLORATORY DATA ANA; Tutz G, 2007, STAT MED, V26, P2872, DOI 10.1002/sim.2738; Tutz G, 2007, J COMPUT GRAPH STAT, V16, P165, DOI 10.1198/106186007X180949; Tutz G, 2004, COMPUT STAT DATA AN, V46, P777, DOI 10.1016/j.csda.2003.10.001; Tutz G, 2004, J STAT COMPUT SIM, V74, P183, DOI 10.1080/0094965031000118959; Tutz G, 2006, BIOMETRICS, V62, P961, DOI 10.1111/j.1541-0420.2006.00578.x; Tutz G, 2003, BIOMETRICS, V59, P263, DOI 10.1111/1541-0420.00033; Tutz G, 2004, STAT MED, V23, P2445, DOI 10.1002/sim.1824; Vandenhende F, 2007, STAT MED, V26, P4876, DOI 10.1002/sim.2960; VENABLES W, 2009, MASS 7 3 3 R PACKAGE; VERBYLA AP, 1994, 17 INT BIOM C HAM AU, P177; Wager C, 2007, AUST NZ J STAT, V49, P173, DOI 10.1111/j.1467-842X.2007.00473.x; Wager CG, 2004, J ROY STAT SOC B, V66, P429, DOI 10.1046/j.1369-7412.2003.05285.x; WAHBA G, 1978, J ROY STAT SOC B MET, V40, P364; Wahba G., 1990, SPLINE MODELS OBSERV; WAHBA G, 2006, STAT SCI, V21, P347, DOI 10.1214/088342306000000457; WAND MP, 2007, SEMIPAR 1 0 R PACKAG; Wand MP, 2003, COMPUTATION STAT, V18, P223; Wand MP, 2008, AUST NZ J STAT, V50, P179, DOI 10.1111/j.1467-842X.2008.00507.x; Wand MP, 2009, AUST NZ J STAT, V51, P9, DOI 10.1111/j.1467-842X.2009.00538.x; Wang HN, 2007, BIOMETRICS, V63, P209, DOI 10.1111/j.1541-0420.2006.00674.x; Wang N, 2005, J AM STAT ASSOC, V100, P147, DOI 10.1198/016214504000000629; Wang NY, 2003, BIOMETRIKA, V90, P43, DOI 10.1093/biomet/90.1.43; Wang YD, 1998, J ROY STAT SOC B, V60, P159, DOI 10.1111/1467-9868.00115; Welham SJ, 2006, BIOMETRICS, V62, P392, DOI 10.1111/j.1541-0420.2005.00500.x; WELHAM SJ, 2008, HDB MODERN STAT METH; Welham SJ, 2007, AUST NZ J STAT, V49, P1, DOI 10.1111/j.1467-842X.2006.00454.x; Welsh AH, 2002, J AM STAT ASSOC, V97, P482, DOI 10.1198/016214502760047014; Wikle C. K., 2002, SPATIAL CLUSTER MODE, P199; WOOD SN, 2008, MGCV 1 3 R PACKAGE; Wood SN, 2006, BIOMETRICS, V62, P1025, DOI 10.1111/j.1541-0420.2006.00574.x; Wood SN, 2003, J ROY STAT SOC B, V65, P95, DOI 10.1111/1467-9868.00374; Wood SN, 2006, GEN ADDITIVE MODELS; Wood SN, 2006, AUST NZ J STAT, V48, P445, DOI 10.1111/j.1467-842X.2006.00450.x; Yao F, 2006, J ROY STAT SOC B, V68, P3, DOI 10.1111/j.1467-9868.2005.00530.x; Yee TW, 1996, J ROY STAT SOC B MET, V58, P481; Yee T. W., 2007, EXTREMES, V10, P1, DOI [10.1007/s10687-007-0032-4, DOI 10.1007/S10687-007-0032-4]; Yee TW, 2004, STAT MED, V23, P2295, DOI 10.1002/sim.1822; Yee TW, 2003, STAT MODEL, V3, P15, DOI 10.1191/1471082X03st045oa; YEE TW, 2008, VGAM  0 7 R PACKAGE; Yu Y, 2002, J AM STAT ASSOC, V97, P1042, DOI 10.1198/016214502388618861; Yu Y, 2004, STAT SINICA, V14, P449; Yuan Y, 2007, BIOMETRICS, V63, P1172, DOI 10.1111/j.1541-0420.2007.00816.x; ZEGER SL, 1994, BIOMETRICS, V50, P689, DOI 10.2307/2532783; Zhang DM, 2007, ACTA CRYSTALLOGR E, V63, pO81, DOI 10.1107/S1600536806051294; Zhang DW, 2003, BIOSTATISTICS, V4, P57, DOI 10.1093/biostatistics/4.1.57; Zhang DW, 2004, BIOMETRICS, V60, P8, DOI 10.1111/j.0006-341X.2004.00165.x; Zhang J, 2006, NONPARAMETRIC REGRES; Zhao Y, 2006, STAT SCI, V21, P35, DOI 10.1214/088342306000000015; Zhengs H, 2004, SURV METHODOL, V30, P209; Zhou L, 2008, BIOMETRIKA, V95, P601, DOI 10.1093/biomet/asn035; Zhou S, 1998, ANN STAT, V26, P1760	312	36	36	9	25	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2009	3						1193	1256		10.1214/09-EJS525		64	Statistics & Probability	Mathematics	V16FK	WOS:000207855300017		
J	Meinshausen, N				Meinshausen, Nicolai			Forest Garrote	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Nonnegative Garrote; Random Forests; sparsity; tree ensembles	VARIABLE SELECTION; MODEL SELECTION; REGRESSION; LASSO	Variable selection for high-dimensional linear models has received a lot of attention lately, mostly in the context of l(1)-regularization. Part of the attraction is the variable selection effect: parsimonious models are obtained, which are very suitable for interpretation. In terms of predictive power, however, these regularized linear models are often slightly inferior to machine learning procedures like tree ensembles. Tree ensembles, on the other hand, lack usually a formal way of variable selection and are difficult to visualize. A Garrote-style convex penalty for trees ensembles, in particular Random Forests, is proposed. The penalty selects functional groups of nodes in the trees. These could be as simple as monotone functions of individual predictor variables. This yields a parsimonious function fit, which lends itself easily to visualization and interpretation. The predictive power is maintained at least at the same level as the original tree ensemble. A key feature of the method is that, once a tree ensemble is fitted, no further tuning parameter needs to be selected. The empirical performance is demonstrated on a wide array of datasets.	Univ Oxford, Dept Stat, Oxford OX1 3TG, England	Meinshausen, N (reprint author), Univ Oxford, Dept Stat, 1 S Parks Rd, Oxford OX1 3TG, England.	meinshausen@stats.ox.ac.uk					BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Meier L, 2008, J R STAT SOC B, V70, P53; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Asuncion A., 2007, UCI MACHINE LEARNING; Breiman L., 1984, CLASSIFICATION REGRE; CONLON F, 2003, P NATL ACAD SCI USA, V100, P3339; Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Hastie T., 2001, ELEMENTS STAT LEARNI; Leng CL, 2006, STAT SINICA, V16, P1273; LYKOU A, 2009, COMPUTATION IN PRESS; NASH W, 1994, POPULATION BIOL ABAL; Strobl C, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-307; Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25; Zhao P, 2009, ANN STAT, V37, P3468, DOI 10.1214/07-AOS584	23	3	3	0	0	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2009	3						1288	1304		10.1214/09-EJS434		17	Statistics & Probability	Mathematics	V16FK	WOS:000207855300019		
J	Zhou, H; Pan, W; Shen, XT				Zhou, Hui; Pan, Wei; Shen, Xiaotong			Penalized model-based clustering with unconstrained covariance matrices	ELECTRONIC JOURNAL OF STATISTICS			English	Article						Covariance estimation; EM algorithm; Gaussian graphical models; high-dimension but low-sample size; L(1) penalization; normal mixtures; penalized likelihood; semi-supervised learning		Clustering is one of the most useful tools for high-dimensional analysis, e.g., for microarray data. It becomes challenging in presence of a large number of noise variables, which may mask underlying clustering structures. Therefore, noise removal through variable selection is necessary. One effective way is regularization for simultaneous parameter estimation and variable selection in model-based clustering. However, existing methods focus on regularizing the mean parameters representing centers of clusters, ignoring dependencies among variables within clusters, leading to incorrect orientations or shapes of the resulting clusters. In this article, we propose a regularized Gaussian mixture model with general covariance matrices, taking various dependencies into account. At the same time, this approach shrinks the means and covariance matrices, achieving better clustering and variable selection. To overcome one technical challenge in estimating possibly large covariance matrices, we derive an E-M algorithm to utilize the graphical lasso (Friedman et al. 2007) for parameter estimation. Numerical examples, including applications to microarray gene expression data, demonstrate the utility of the proposed method.	[Zhou, Hui; Pan, Wei] Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA; [Shen, Xiaotong] Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	Pan, W (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA.	zhoux292@umn.edu; weip@biostat.umn.edu; xshen@stat.umn.edu			NIH [RO1-GM081535, RO1-HL65462]; NSF [DMS-0604394, DMS-0906616]	This research was partially supported by NIH grant RO1-GM081535; in addition, HZ and WP by NIH grant RO1-HL65462, and XS by NSF grants DMS-0604394 and DMS-0906616.	Alaiya AA, 2002, INT J CANCER, V98, P895, DOI 10.1002/ijc.10288; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Chi JT, 2003, P NATL ACAD SCI USA, V100, P10623, DOI 10.1073/pnas.1434429100; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Fan JQ, 2009, ANN APPL STAT, V3, P521, DOI 10.1214/08-AOAS215; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Tavazoie S, 1999, NAT GENET, V22, P281; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Antonov AV, 2004, BIOINFORMATICS, V20, P644, DOI 10.1093/bioinformatics/btg462; Baker SG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-407; Bardi E, 2004, PEDIATR NEPHROL, V19, P1145, DOI 10.1007/s00467-004-1548-3; Carvalho CM, 2009, BIOMETRIKA, V96, P497, DOI 10.1093/biomet/asp017; FRIEDMAN J, 2007, BIOSTATISTICS, P1; GUO FJ, 2009, BIOMETRICS IN PRESS; Hoff PD, 2006, BAYESIAN ANAL, V1, P321; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; Jiang Aixiang, 2007, J Bioinform Comput Biol, V5, P875, DOI 10.1142/S0219720007002989; Jones B, 2005, STAT SCI, V20, P388, DOI 10.1214/088342305000000304; Kim S, 2006, BIOMETRIKA, V93, P877, DOI 10.1093/biomet/93.4.877; Lau JW, 2007, J COMPUT GRAPH STAT, V16, P526, DOI 10.1198/106186007X238855; LEVINA L, 2008, ANN APPL STAT, V2, P245; Liang F, 2007, STAT SCI, V22, P189, DOI 10.1214/088342307000000032; Liao JG, 2007, BIOINFORMATICS, V23, P1945, DOI 10.1093/bioinformatics/btm287; Liu J. S., 2003, BAYESIAN STAT, V7, P249; MCLACHLAN GJ, 1987, APPL STAT-J ROY ST C, V36, P318, DOI 10.2307/2347790; McLachlan G, 2002, FINITE MIXTURE MODEL; McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413; Muller P, 1996, BIOMETRIKA, V83, P67, DOI 10.1093/biomet/83.1.67; Pan W, 2006, BIOINFORMATICS, V22, P795, DOI 10.1093/bioinformatics/btl011; Pan W, 2006, BIOINFORMATICS, V22, P2388, DOI 10.1093/bioinformatics/btl393; Pan W, 2007, J MACH LEARN RES, V8, P1145; Raftery AE, 2006, J AM STAT ASSOC, V101, P168, DOI 10.1198/016214506000000113; Rothman AJ, 2009, J AM STAT ASSOC, V104, P177, DOI 10.1198/jasa.2009.0101; Scott J., 2009, J COMPUT GRAPH STAT, V17, P790; Tadesse MG, 2005, J AM STAT ASSOC, V100, P602, DOI 10.1198/0162145040000001565; TEH YW, 2004, SHARING CLUSTERS REL; Thalamuthu A, 2006, BIOINFORMATICS, V22, P2405, DOI 10.1093/bioinformatics/btl406; Tseng GC, 2007, BIOINFORMATICS, V23, P2247, DOI 10.1093/bioinformatics/btm320; Tseng P., 2001, J OPT THEORY APPL, V109, P474; TSENG P, 1988, 1840 LIDSP MIT LAB I; Wang SX, 2008, ACTA CRYSTALLOGR E, V64, pM78, DOI 10.1107/S1600536807062186; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; Wasserman L, 2000, J ROY STAT SOC B, V62, P159, DOI 10.1111/1467-9868.00226; Xie B, 2008, ACTA CRYSTALLOGR E, V64, pM622, DOI 10.1107/S1600536808008398; XIE B, 2009, BIOINFORMAT IN PRESS; Xie BH, 2008, ELECTRON J STAT, V2, P168, DOI 10.1214/08-EJS194	53	6	7	4	8	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1935-7524			ELECTRON J STAT	Electron. J. Stat.		2009	3						1473	1496		10.1214/09-EJS487		24	Statistics & Probability	Mathematics	V16FK	WOS:000207855300026		
J	Oresic, M				Oresic, Matej			Bioinformatics and computational approaches applicable to lipidomics	EUROPEAN JOURNAL OF LIPID SCIENCE AND TECHNOLOGY			English	Review						Bioinformatics; Lipidomics; Metabolomics; Pathway analysis; Systems biology	PARTIAL LEAST-SQUARES; MASS-SPECTROMETRY; MULTIPLE PRECURSOR; SPHINGOLIPID METABOLISM; QUANTITATIVE-ANALYSIS; METABOLOMICS DATA; PROFILE DATA; DATABASE; LIPIDS; INFORMATION	Lipidomics owes its emergence to technologies developed over the past decade that empowered us with the ability to detect and quantify hundreds of intact lipid molecular species in parallel. One of the biggest current challenges of lipidomics is the elucidation of important pathobiological phenomena from the integration of large amounts of new data becoming available. In this respect, development of lipidomics as a field bears many similarities to the emergence and progress of genomics. Initial excitement over the ability to measure the expression of large numbers of genes in parallel was soon overshadowed by concerns over die ability to reliably analyze and interpret the expression data. This led to active research in the area of bioinformatics, which led to improved statistical methods as well as to new approaches for the analysis of transcriptome data in the pathway context. This review covers recent bioinformatics developments of relevance to analysis and interpretation of analytical lipidomics data, with the focus primarily on practical aspects of lipid bioinformatics.	VTT Tech Res Ctr, Espoo 02044, Finland	Oresic, M (reprint author), VTT Tech Res Ctr, POB 1000, Espoo 02044, Finland.	matej.oresic@vtt.fi					Adiels M, 2005, J LIPID RES, V46, P58, DOI 10.1194/jlr.M400108-JLR200; Alvarez-Vasquez F, 2005, NATURE, V433, P425, DOI 10.1038/nature03232; Alvarez-Vasquez F, 2004, J THEOR BIOL, V226, P265, DOI 10.1016/j.jtbi.2003.08.010; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Boulesteix AL, 2007, BRIEF BIOINFORM, V8, P32, DOI 10.1093/bib/bb1016; Wingender E, 2008, BRIEF BIOINFORM, V9, P326, DOI 10.1093/bib/bbn016; Han XL, 2005, MASS SPECTROM REV, V24, P367, DOI 10.1002/mas.20023; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Westerhuis JA, 2008, METABOLOMICS, V4, P81, DOI 10.1007/s11306-007-0099-6; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Taguchi R, 2005, J CHROMATOGR B, V823, P26, DOI 10.1016/j.jchromb.2005.06.005; Kanehisa M, 2008, NUCLEIC ACIDS RES, V36, pD480, DOI 10.1093/nar/gkm882; Wang YL, 2007, J PROTEOME RES, V6, P1846, DOI 10.1021/pr060685n; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Ogiso H, 2008, ANAL BIOCHEM, V375, P124, DOI 10.1016/j.ab.2007.12.027; Wheeler DL, 2007, NUCLEIC ACIDS RES, V35, pD5, DOI 10.1093/nar/gkl1031; Pears MR, 2005, J BIOL CHEM, V280, P42508, DOI 10.1074/jbc.M507380200; Watson AD, 2006, J LIPID RES, V47, P2101, DOI 10.1194/jlr.R600022-JLR200; Ejsing CS, 2006, ANAL CHEM, V78, P6202, DOI 10.1021/ac060545x; Fahy E, 2005, J LIPID RES, V46, P839, DOI 10.1194/jlr.E400004-JLR200; Fahy E, 2007, NUCLEIC ACIDS RES, V35, pW606, DOI 10.1093/nar/gkm324; Watkins SM, 2002, J LIPID RES, V43, P1809, DOI 10.1194/jlrM200169-JLR200; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Katajamaa M, 2006, BIOINFORMATICS, V22, P634, DOI 10.1093/bioinformatics/btk039; Wenk MR, 2005, NAT REV DRUG DISCOV, V4, P594, DOI 10.1038/nrd1776; Watanabe K, 2000, TRENDS GLYCOSCI GLYC, V12, P175; Kind T, 2007, ANAL BIOCHEM, V363, P185, DOI 10.1016/j.ab.2007.01.028; Nordstrom A, 2006, ANAL CHEM, V78, P3289, DOI 10.1021/ac060245f; Sud M, 2007, NUCLEIC ACIDS RES, V35, pD527, DOI 10.1093/nar/gkl838; Broadhurst DI, 2006, METABOLOMICS, V2, P171, DOI 10.1007/s11306-006-0037-z; CAFFREY M, 1992, CHEM PHYS LIPIDS, V61, P1, DOI 10.1016/0009-3084(92)90002-7; Clish CB, 2004, OMICS, V8, P3, DOI 10.1089/153623104773547453; Damian D, 2007, METABOLOMICS, V3, P69, DOI 10.1007/s11306-006-0045-z; Ekroos K, 2002, ANAL CHEM, V74, P941, DOI 10.1021/ac015655c; EVERITT BS, 2001, CLUSTER AANALYSIS; Fahy E, 2007, METHOD ENZYMOL, V432, P247, DOI 10.1016/S0076-6879(07)32011-9; Forrester JS, 2004, MOL PHARMACOL, V65, P813, DOI 10.1124/mol.65.4.813; Friedman J.H., 2004, J ROYAL STAT SOC B, V66, P1; Guan XL, 2006, FASEB J, V20, P1152, DOI 10.1096/fj.05-5362com; Haimi P, 2006, ANAL CHEM, V78, P8324, DOI 10.1021/ac061390w; Hastie T., 2001, ELEMENTS STAT LEARNI; Hermansson M, 2005, ANAL CHEM, V77, P2166, DOI 10.1021/ac048489s; Jackson J. E., 1991, USERS GUIDE PRINCIPA; Jansen JJ, 2004, BIOINFORMATICS, V20, P2438, DOI 10.1093/bioinformatics/bth268; Katajamaa M, 2007, J CHROMATOGR A, V1158, P318, DOI 10.1016/j.chroma.2007.04.021; Katajamaa M, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-179; Kekkonen RA, 2008, WORLD J GASTROENTERO, V14, P3188, DOI 10.3748/wjg.14.3188; Laaksonen R, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000097; Lagarde M, 2003, BBA-MOL CELL BIOL L, V1634, P61, DOI 10.1016/j.bbalip.2003.11.002; Mao JC, 1996, IEEE T NEURAL NETWOR, V7, P16; Medina-Gomez G, 2007, PLOS GENET, V3, DOI 10.1371/journal.pgen.0030064; Niemela PS, 2007, PLOS COMPUT BIOL, V3, P304, DOI 10.1371/journal.pcbi.0030034; Nikkila J, 2008, MOL SYST BIOL, V4, pe197; OKUDA S, 2008, NUCLEIC ACIDS RES; Parsons L., 2004, SIGKDD EXPLORATIONS, V6, P90, DOI DOI 10.1145/1007730.1007731; Schwab U, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002630; Schwudke D, 2006, ANAL CHEM, V78, P585, DOI 10.1021/ac051605m; Serhan CN, 2006, AAPS J, V8, pE284; Serhan CN, 2007, METHOD ENZYMOL, V432, P275, DOI 10.1016/S0076-6879(07)32012-0; Smilde AK, 2005, BIOINFORMATICS, V21, P3043, DOI 10.1093/bioinformatics/bti476; Sysi-Aho M, 2007, BMC BIOINFORMATICS, V8, pe93; Sysi-Aho M, 2007, BIOINFORMATICS, V23, P519; 't Hart BA, 2003, J NEUROL SCI, V212, P21, DOI 10.1016/S0022-510X(03)00080-7; Yetukuri L, 2007, BMC SYST BIOL, V1, pE12; Yetukuri L, 2008, MOL BIOSYST, V4, P121, DOI 10.1039/b715468b	68	14	14	2	10	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1438-7697			EUR J LIPID SCI TECH	Eur. J. Lipid Sci. Technol.	JAN	2009	111	1					99	106		10.1002/ejlt.200800144		8	Food Science & Technology; Nutrition & Dietetics	Food Science & Technology; Nutrition & Dietetics	406VU	WOS:000263323800009		
B	Qu, LM		Guo, MY; Tang, FL; Shen, Y		Qu, Leming			Wavelet Image Restoration and Regularization Parameters Selection	FCST 2009: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY			English	Proceedings Paper	4th International Conference on Frontier of Computer Science and Technology	DEC 17-19, 2009	Shanghai, PEOPLES R CHINA	IEEE Comp Soc, TCSC, Shanghai Jiao Tong Univ, SCS		Wavelet; image restoration; Lasso; AIC	ADAPTIVE MODEL SELECTION; LINEAR INVERSE PROBLEMS; THRESHOLDING ALGORITHM; CROSS-VALIDATION; SHRINKAGE; RECONSTRUCTION; DECONVOLUTION; SIGNALS; LASSO	For the restoration of an image based on its noisy distorted observations, we propose wavelet domain restoration by scale-dependent l(1) penalized regularization method (WaveRSL1). The data adaptive choice of the regularization parameters is based on the Akaike Information Criterion (AIC) and the degrees of freedom (df) is estimated by the number of nonzero elements in the solution. Experiments on some commonly used testing images illustrate that the proposed method possesses good empirical properties.	Boise State Univ, Dept Math, Boise, ID 83725 USA	Qu, LM (reprint author), Boise State Univ, Dept Math, Boise, ID 83725 USA.	lqu@boisestate.edu					Akaike H., 1973, P 2 INT S INF THEOR, P267; Shen XT, 2002, J AM STAT ASSOC, V97, P210, DOI 10.1198/016214502753479356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; ARCHER G, 1995, IEEE T IMAGE PROCESS, V4, P989, DOI 10.1109/83.392339; Atkinson I, 2006, IEEE T IMAGE PROCESS, V15, P992, DOI 10.1109/TIP.2005.863024; Bertero M., 1998, INTRO INVERSE PROBLE; CHAN RH, 2008, SIAM J IMAGING SCI, V1; Chan TF, 2005, IMAGE PROCESSING AND ANALYSIS, P1, DOI 10.1137/1.9780898717877; Chang SG, 2006, IEEE T IMAGE PROCESS, V15, P1471, DOI 10.1109/TIP.2006.871162; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; DUP F, 2009, IEEE T IMAGE PROCESS, V18, P310; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; Johnstone IM, 2004, J ROY STAT SOC B, V66, P547, DOI 10.1111/j.1467-9868.2004.02056.x; Justen L, 2009, APPL COMPUT HARMON A, V26, P43, DOI 10.1016/j.acha.2008.02.002; Luisier F, 2008, IEEE T IMAGE PROCESS, V17, P482, DOI 10.1109/TIP.2008.919370; Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1; Moigne J. L., 2002, IEEE T GEOSCI REMOTE, V40, P1849; Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592; Qu LM, 2009, IEEE SIGNAL PROC LET, V16, P73, DOI 10.1109/LSP.2008.2008939; ROUTH PS, 2007, SEG, V26, P1795, DOI 10.1190/1.2792840; Shen XT, 2004, TECHNOMETRICS, V46, P306, DOI 10.1198/004017004000000338; STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632; Vidakovic B, 1999, STAT MODELING WAVELE; Yang YH, 2005, BIOMETRIKA, V92, P937, DOI 10.1093/biomet/92.4.937; Ye JM, 1998, J AM STAT ASSOC, V93, P120, DOI 10.2307/2669609; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	34	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3932-4				2009							241	247		10.1109/FCST.2009.18		7	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BOJ39	WOS:000276838500035		
S	Myers, LJ; Downs, JH		Schmorrow, DD; Estabrooke, IV; Grootjen, M		Myers, Lance J.; Downs, J. Hunter			Parsimonious Identification of Physiological Indices for Monitoring Cognitive Fatigue	FOUNDATIONS OF AUGMENTED COGNITION, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th International Conference on Foundation of Augmented Cognition	JUL 19-24, 2009	San Diego, CA			cognitive fatigue; heart rate variability; feature selection; wearable sensors	HEART-RATE-VARIABILITY; REGRESSION	The objective of this study was to identify a parsimonious set of physiological measures that could be used to best predict cognitive fatigue levels. A 37 hour sleep deprivation study was conducted to induce reduced levels of alertness and cognitive impairment as measured by a psychomotor vigilance test. Non-invasive, wearable and ambulatory sensors were used to acquire cardio-respiratory and motion data during the sleep deprivation. Subsequently 23 potential predictors were derived from the raw sensor data. The least absolute shrinkage and selection operator, along with a cross validation strategy was used to create a sparse model and identify a minimum predictor subset that provided the best prediction accuracy. Final predictor selection was found to vary with task and context. Depending on context selected predictors indicated elevated levels of sympathetic nervous system activity, increased restlessness during engaging tasks and increased cardio-respiratory synchronization with increasing cognitive fatigue.	[Myers, Lance J.; Downs, J. Hunter] Archinoetics LLC, Honolulu, HI 96813 USA	Myers, LJ (reprint author), Archinoetics LLC, 700 Bishop St,Suite E, Honolulu, HI 96813 USA.						Kripke DF, 2002, ARCH GEN PSYCHIAT, V59, P131, DOI 10.1001/archpsyc.59.2.131; GROSSMAN P, 1993, PSYCHOPHYSIOLOGY, V30, P486, DOI 10.1111/j.1469-8986.1993.tb02072.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Acharya UR, 2006, MED BIOL ENG COMPUT, V44, P1031, DOI 10.1007/s11517-006-0119-0; Efron B, 2004, ANN STAT, V32, P407; Dinges DF, 1997, SLEEP, V20, P267; Arnedt JT, 2000, J SLEEP RES, V9, P233; Camm AJ, 1996, CIRCULATION, V93, P1043; CARSKADON MA, 1991, SLEEP SLEEPINESS PER; Gundel A, 2007, SOMNOLOGIE SCHLAFFOR, V11, P148, DOI 10.1007/s11818-007-0312-x; KLEITMAN N, 1963, SLEEP WAKEFULNESS, P114; Lotric MB, 2000, PHYSICA A, V283, P451, DOI 10.1016/S0378-4371(00)00204-1; National Sleep Foundation, 2005, 2005 SLEEP AM POLL; Wilhelm FH, 2001, BIOL PSYCHIAT, V49, P596, DOI 10.1016/S0006-3223(00)01000-3; Zhang C, 2009, EXPERT SYST APPL, V36, P4664, DOI 10.1016/j.eswa.2008.06.022	15	0	0	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-02811-3	LECT NOTES ARTIF INT			2009	5638						495	503				9	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	BKH40	WOS:000268101300058		
B	Ling, Q; Tian, Z			IEEE	Ling, Qing; Tian, Zhi			A Decentralized Gauss-Seidel Approach for In-Network Sparse Signal Recovery	FUSION: 2009 12TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOLS 1-4			English	Proceedings Paper	12th International Conference on Information Fusion	JUL 06-09, 2009	Seattle, WA	ISIF, IEEE, ONR, ARL, AF Res Lab, Northrop Grumman, CUBRC, Boeing, Georgia Tech Res Inst		Wireless sensor networks; sparse signal recovery; in-network signal processing; decentralized Gauss-Seidel approach		This paper addresses the problem of monitoring and discovering abnormalities in sensing fields with large-scale wireless sensor networks. By exploiting the sparsity of abnormalities, the signal recovery problem is expressed as an l-l regularized least squares formulation with nonnegative constraints. Furthermore, a decentralized Gauss-Seidel approach is proposed for in-network signal processing. Comparing with its centralized counterpart, the decentralized algorithm improves the robustness and scalability of a large-scale network. Parameter settings of the l-l regularized least squares formulation are studied via theoretical analysis and extensive simulations. An illustrative example of structural health monitoring demonstrates the effectiveness of the proposed decentralized sparse signal recovery algorithm in practical applications.	[Ling, Qing; Tian, Zhi] Michigan Technol Univ, Dept ECE, Houghton, MI 49931 USA	Ling, Q (reprint author), Michigan Technol Univ, Dept ECE, Houghton, MI 49931 USA.	qling@mtu.edu; ztian@mtu.edu					Boyd S, 2006, IEEE T INFORM THEORY, V52, P2508, DOI 10.1109/TIT.2006.874516; Lynch JP, 2007, PHILOS T R SOC A, V365, P345, DOI 10.1098/rsta.2006.1932; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; LENT A, 1980, SIAM J CONTROL OPTIM, V18, P444, DOI 10.1137/0318033; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Barzerque J., 2008, P AS C SIGN SYST COM; Bertsekas D., 1999, NUMERICAL OPTIMIZATI; Bertsekas D. P., 1997, PARALLEL DISTRIBUTED; Cevher V., 2008, P EUR SIGN PROC C; Doebling S.W., 1998, SHOCK VIBRATION DIGE, V30, P91, DOI DOI 10.1177/058310249803000201; FARRAR C, 1999, P INT WORKSH STRUCT; LING Q, IEEE SENSOR IN PRESS; Pacific Earthquake Engineering Research Center, 1999, OPENSEES OP SYST EAR; SCHIZAS I, IEEE T SIGN IN PRESS; Schizas ID, 2008, IEEE T SIGNAL PROCES, V56, P350, DOI 10.1109/TSP.2007.906734; SOHN H, 2001, SMART MATER STRUCT, V10, P445; SUNDARESAN A, 2007, P INT C INF FUS	20	1	1	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-9824-4380-4				2009							380	387				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BMT89	WOS:000273560000050		
J	Fridley, BL				Fridley, Brooke L.			Bayesian Variable and Model Selection Methods for Genetic Association Studies	GENETIC EPIDEMIOLOGY			English	Article						Bayesian model averaging; Bayesian variable selection; candidate gene; Markov chain Monte Carlo; reversible jump MCMC; stochastic search variable selection	COMPLEMENT FACTOR-H; GENOME-WIDE ASSOCIATION; QUANTITATIVE TRAIT LOCI; MACULAR DEGENERATION; APOLIPOPROTEIN-E; HAPLOTYPE RECONSTRUCTION; GENOTYPE DATA; RISK; SUSCEPTIBILITY; POLYMORPHISM	Variable selection is growing in importance with the advent of high throughput genotyping methods requiring analysis of hundreds to thousands of single nucleotide polymorphisms (SNPs) and the increased interest in using these genetic studies to better understand common, complex diseases. Up to now, the standard approach has been to analyze the genotypes for each SNP individually to look for an association with a disease. Alternatively, combinations of SNPs or haplotypes are analyzed for association. Another added complication in studying complex diseases or phenotypes is that genetic risk for the disease is often due to multiple SNPs in various locations on the chromosome with small individual effects that may have a collectively large effect on the phenotype. Hence, multi-locus SNP models, as opposed to single SNP models, may better capture the true underlying genotypic-phenotypic relationship. Thus, innovative methods for determining which SNPs to include in the model are needed. The goal of this article is to describe several methods currently available for variable and model selection using Bayesian approaches and to illustrate their application for genetic association studies using both real and simulated candidate gene data for a complex disease. In particular, Bayesian model averaging (BMA), stochastic search variable selection (SSVS), and Bayesian variable selection (BVS) using a reversible jump Markov chain Monte Carlo (MCMC) for candidate gene association studies are illustrated using a Study of age-related macular degeneration (AMD) and simulated data. Genet. Epidemiol. 33:27-37, 2009. (C) 2008 Wiley-Liss, Inc.	Mayo Clin, Div Biostat, Coll Med, Dept Hlth Sci Res, Rochester, MN 55905 USA	Fridley, BL (reprint author), Mayo Clin, Div Biostat, Coll Med, Dept Hlth Sci Res, Harwick 766,200 1st St SW, Rochester, MN 55905 USA.	fridley.brooke@mayo.edu	Fridley, Brooke/D-8315-2015	Fridley, Brooke/0000-0001-7739-7956			Akaike H., 1973, 2 INT S INF THEOR, P267; Efron B, 2005, J AM STAT ASSOC, V100, P1, DOI 10.1198/016214505000000033; Lunn DJ, 2006, GENET EPIDEMIOL, V30, P231, DOI 10.1002/gepi.20140; ALBERT JH, 1993, J AM STAT ASSOC, V88, P669, DOI 10.2307/2290350; Price AL, 2006, NAT GENET, V38, P904, DOI 10.1038/ng1847; CARLIN BP, 1995, J ROY STAT SOC B MET, V57, P473; GELFAND AE, 1990, J AM STAT ASSOC, V85, P398, DOI 10.2307/2289776; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Hoeting JA, 1999, STAT SCI, V14, P382; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; Little RJ, 2006, AM STAT, V60, P213, DOI 10.1198/000313006X117837; Pritchard JK, 2000, GENETICS, V155, P945; Gold B, 2006, NAT GENET, V38, P458, DOI 10.1038/ng1750; Klein RJ, 2005, SCIENCE, V308, P385, DOI 10.1126/science.1109557; Raftery AE, 1997, J AM STAT ASSOC, V92, P179, DOI 10.2307/2291462; Beaumont MA, 2004, NAT REV GENET, V5, P251, DOI 10.1038/nrg1318; Thomas DC, 2005, AM J HUM GENET, V77, P337, DOI 10.1086/432962; Friedman DS, 2004, ARCH OPHTHALMOL-CHIC, V122, P564; Stephens M, 2003, AM J HUM GENET, V73, P1162, DOI 10.1086/379378; Rivera A, 2005, HUM MOL GENET, V14, P3227, DOI 10.1093/hmg/ddi353; Heil F, 2004, SCIENCE, V303, P1526, DOI 10.1126/science.1093620; Haines JL, 2005, SCIENCE, V308, P419, DOI 10.1126/science.1110359; Wang WYS, 2005, NAT REV GENET, V6, P109, DOI 10.1038/nrg1522; Carlson CS, 2004, AM J HUM GENET, V74, P106, DOI 10.1086/381000; Marchini J, 2007, NAT GENET, V39, P906, DOI 10.1038/ng2088; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Edwards AO, 2005, SCIENCE, V308, P421, DOI 10.1126/science.1110189; Alexopoulou L, 2001, NATURE, V413, P732, DOI 10.1038/35099560; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; Stephens M, 2001, AM J HUM GENET, V68, P978, DOI 10.1086/319501; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Lee KE, 2003, BIOINFORMATICS, V19, P90, DOI 10.1093/bioinformatics/19.1.90; Jakobsdottir J, 2005, AM J HUM GENET, V77, P389, DOI 10.1086/444437; Yates JRW, 2007, NEW ENGL J MED, V357, P553, DOI 10.1056/NEJMoa072618; Dellaportas P, 2002, STAT COMPUT, V12, P27, DOI 10.1023/A:1013164120801; Ball RD, 2001, GENETICS, V159, P1351; Bayes T., 1763, PHILOS T ROY SOC LON, V1763, P330; Berger JO, 2000, J AM STAT ASSOC, V95, P1269, DOI 10.2307/2669768; Blangero J, 2005, HUM BIOL, V77, P541, DOI 10.1353/hub.2006.0003; Brooks SP, 2003, J R STAT SOC B, V65, P3, DOI 10.1111/1467-9868.03711; Brown PJ, 1998, J R STAT SOC B, V60, P627, DOI 10.1111/1467-9868.00144; Chipman H, 1996, CAN J STAT, V24, P17, DOI 10.2307/3315687; Christensen R, 2005, AM STAT, V59, P121, DOI 10.1198/000313005X20871; Diebold SS, 2004, SCIENCE, V303, P1529, DOI 10.1126/science.1093616; EFRON B, 1986, AM STAT, V40, P1, DOI 10.2307/2683105; Gelman A., 1995, BAYESIAN DATA ANAL; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; George EI, 1997, STAT SINICA, V7, P339; Gilks W. R., 1996, MARKOV CHAIN MONTE C; Goverdhan SV, 2005, INVEST OPHTH VIS SCI, V46, P1726, DOI 10.1167/iovs.04-0928; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Hastie T., 2001, ELEMENTS STAT LEARNI; *INT HAPMAP CONOS, 2007, 2 GEN HUM HAPL MAP 3; Altshuler D, 2005, NATURE, V437, P1299, DOI 10.1038/nature04226; Kim KW, 2004, NEUROSCI LETT, V366, P182, DOI 10.1016/j.neulet.2004.05.041; Klaver CCW, 1998, AM J HUM GENET, V63, P200, DOI 10.1086/301901; Kohl J, 2006, IMMUNOL RES, V34, P157, DOI 10.1385/IR:34:2:157; LUNN DJ, 2005, MULTIVARIATE PROBIT; MEDZHITOV R, 1997, NATURE, V388, P397; Miller A. J., 1990, SUBSET SELECTION REG; Neter J., 1996, APPL LINEAR STAT MOD; Nothnagel M, 2002, AM J HUM GENET S, V71, pA2363; Parker LC, 2007, CLIN EXP IMMUNOL, V147, P199; Poltorak A, 1998, SCIENCE, V282, P2085, DOI 10.1126/science.282.5396.2085; Raftery AE, 1996, BIOMETRIKA, V83, P251, DOI 10.1093/biomet/83.2.251; Raftery A.E., 2005, R NEWS, V5, P2; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; Schafer JL, 1997, ANAL INCOMPLETE MULT; Seddon JM, 2006, HUM HERED, V61, P157, DOI 10.1159/000094141; Sha NJ, 2004, BIOMETRICS, V60, P812, DOI 10.1111/j.0006-341X.2004.00233.x; Souied EH, 1998, AM J OPHTHALMOL, V125, P353, DOI 10.1016/S0002-9394(99)80146-9; Spiegelhalter D, 2003, WINBUGS USER MANUAL; Swartz MD, 2006, BIOMETRICS, V62, P495, DOI 10.1111/j.1541-0420.2005.00451.x; Viallefont V, 2001, STAT MED, V20, P3215, DOI 10.1002/sim.976.abs; Volinsky CT, 1997, APPL STAT-J ROY ST C, V46, P433; Wakefield J, 1996, J AM STAT ASSOC, V91, P917, DOI 10.2307/2291710; Yi NJ, 2004, GENETICS, V167, P967, DOI 10.1534/genetics.104.026286; Yi NJ, 2003, GENETICS, V164, P1129; Zareparsi S, 2005, HUM MOL GENET, V14, P1449, DOI 10.1093/hmg/ddi154	81	17	17	1	4	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0741-0395			GENET EPIDEMIOL	Genet. Epidemiol.	JAN	2009	33	1					27	37		10.1002/gepi.20353		11	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	391PJ	WOS:000262244900004	18618760	
J	Ghosh, S				Ghosh, Saurabh			Genome-Wide Association Analyses of Quantitative Traits: The GAW16 Experience	GENETIC EPIDEMIOLOGY			English	Article; Proceedings Paper	17th Annual Meeting of the International-Genetic-Epidemiology-Society	SEP 14-16, 2008	St Louis, MO	Int Genet Epidemiol Soc		linkage disequilibrium mapping; model-free genetic analyses; rheumatoid arthritis; cardiovascular disorder	RHEUMATOID-ARTHRITIS; LINKAGE DISEQUILIBRIUM; BLOOD-PRESSURE; LOCI; STRATIFICATION; REGRESSION; SELECTION	The group that formed on the theme of genome-wide association analyses of quantitative traits (Group 2) in the Genetic Analysis Workshop 16 comprised eight sets of investigators. Three data sets Were available: one on autoantibodies related to rheumatoid arthritis provided by the North American Rheumatoid Arthritis Consortium; the second on anthropometric, lipid, and biochemical measures provided by the Framingham Heart Study (FHS); and the third a simulated data set modeled after FHS. The different investigators in the group addressed a large set of statistical challenges and applied a wide spectrum of association methods in analyzing quantitative traits at the genome-wide level. While some previously reported genes were validated, some novel chromosomal regions provided significant evidence of association in multiple contributions in the group. In this report, we discuss the different strategies explored by the different investigators with the common goal of improving the power to detect association. Genet. Epideiniol. 33 (Suppl. 1):S13-S18, 2009. (C) 2009 Wiley-Liss, Inc.	Indian Stat Inst, Human Genet Unit, Kolkata 700108, India	Ghosh, S (reprint author), Indian Stat Inst, Human Genet Unit, 203 BT Rd, Kolkata 700108, India.	saurabh@isical.ac.in					Price AL, 2006, NAT GENET, V38, P904, DOI 10.1038/ng1847; Begovich AB, 2004, AM J HUM GENET, V75, P330, DOI 10.1086/422827; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Almasy L, 1998, AM J HUM GENET, V62, P1198, DOI 10.1086/301844; Kastbom A, 2004, ANN RHEUM DIS, V63, P1085, DOI 10.1136/ard.2003.016808; Aulchenko YS, 2007, GENETICS, V177, P577, DOI 10.1534/genetics.107.075614; Cui JSS, 2003, HYPERTENSION, V41, P207, DOI 10.1161/01.HYP.0000044938.94150.E3; Marchini J, 2007, NAT GENET, V39, P906, DOI 10.1038/ng2088; Tobin MD, 2005, STAT MED, V24, P2911, DOI 10.1002/sim.2165; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Wallace C, 2006, AM J HUM GENET, V78, P498, DOI 10.1086/500562; Clayton D, 2007, HUM HERED, V64, P45, DOI 10.1159/000101422; Criswell LA, 2007, ARTHRITIS RHEUM, V56, P58, DOI 10.1002/art.22325; del Val del Amo N, 2006, CLIN EXP RHEUMATOL, V24, P281; Ghosh S, 2007, HUM HERED, V64, P82, DOI 10.1159/000101426; Ghosh Saurabh, 2009, BMC Proc, V3 Suppl 7, pS18; Gonzalez-Ortiz M, 1999, DIABETES NUTR METAB, V12, P32; Hinrichs AL, 2009, GENET EPIDEMIOL, V33, pS88, DOI 10.1002/gepi.20478; Huang BE, 2007, AM J HUM GENET, V80, P567, DOI 10.1086/512727; Julvez J, 2007, INT J EPIDEMIOL, V36, P825, DOI 10.1093/ije/dym107; Kent Jack W Jr, 2009, BMC Proc, V3 Suppl 7, pS19; Kerlan-Candon S, 2001, CLIN EXP IMMUNOL, V124, P142, DOI 10.1046/j.1365-2249.2001.01498.x; Kraja Aldi T, 2009, BMC Proc, V3 Suppl 7, pS4; Lin Yanzhu, 2009, BMC Proc, V3 Suppl 7, pS20; Ma S, 2007, BIOMETRICS, V63, P751, DOI 10.1111/j.1541-0420.2006.00731.x; Majumder PP, 2005, J CLIN INVEST, V115, P1419, DOI 10.1172/JCI24757; Purcell S, 2007, AM J HUM GENET, V81, P559, DOI 10.1086/519795; Rabinowitz D, 2000, HUM HERED, V504, P227; Srivastava Sudeep, 2009, BMC Proc, V3 Suppl 7, pS21; Rantapaa-Dahlqvist S, 2003, ARTHRITIS RHEUM, V48, P2741, DOI 10.1002/art.11223; Sun Xiangqing, 2009, BMC Proc, V3 Suppl 7, pS22; Burton PR, 2007, NATURE, V447, P661, DOI 10.1038/nature05911; Vimaleswaran KS, 2005, DIABETIC MED, V22, P1516, DOI 10.1111/j.1464-5491.2005.01709.x; Waldron ERB, 2006, GENET EPIDEMIOL, V30, P170, DOI 10.1002/gepi.20134; Xing Chao, 2009, BMC Proc, V3 Suppl 7, pS23; ZHANG D, 2008, ELECT J STAT, V3, P781; Zhu XF, 2008, AM J HUM GENET, V82, P352, DOI 10.1016/j.ajhg.2007.10.009	37	0	1	1	2	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0741-0395	1098-2272		GENET EPIDEMIOL	Genet. Epidemiol.		2009	33			1			S13	S18		10.1002/gepi.20466		6	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	529TL	WOS:000272540700003	19924711	
J	Neuman, RJ; Sung, YJ				Neuman, Rosalind J.; Sung, Yun Ju			Multistage Analysis Strategies for Genome-Wide Association Studies: Summary of Group 3 Contributions to Genetic Analysis Workshop 16	GENETIC EPIDEMIOLOGY			English	Article; Proceedings Paper	16th Genetic Analysis Workshop/17th Annual Meeting of the International-Genetic-Epidemiology-Society	SEP 17-20, 2008	St Louis, MO	Int Genet Epidemiol Soc		imputation; elastic net; two-locus models; LASSO; sliding window	SELECTION; DESIGNS; TRAITS	This contribution summarizes the work done by six independent teams of investigators to identify the genetic and non-genetic variants that work together or independently to predispose to disease. The theme addressed in these studies is multistage strategies in the context of genome-wide association studies (GWAS). The work performed comes from Group 3 of the Genetic Analysis Workshop 16 held in St. Louis, Missouri in September 2008. These six studies represent a diversity of multistage methods of which five are applied to the North American Rheumatoid Arthritis Consortium rheumatoid arthritis case-control data, and one method is applied to the low-density lipoprotein phenotype in the Framingham Heart Study simulated data. In the first stage of analyses, the majority of studies used a variety of screening techniques to reduce the noise of single-nucleotide polymorphisms purportedly not involved in the phenotype of interest. Three studies analyzed the data using penalized regression models, either LASSO or the elastic net. The main result was a reconfirmation of the involvement of variants in the HLA region on chromosome 6 with rheumatoid arthritis. The hope is that the intense computational methods highlighted in this group of papers will become useful tools in future GWAS. Genet. Epidemiol. 33 (Suppl. 1):S19-S23, 2009. (C) 2009 Wiley-Liss, Inc.	[Neuman, Rosalind J.; Sung, Yun Ju] Washington Univ, Sch Med, Dept Psychiat, St Louis, MO 63108 USA; [Neuman, Rosalind J.] Washington Univ, Sch Med, Dept Genet, St Louis, MO 63108 USA; [Sung, Yun Ju] Washington Univ, Sch Med, Div Biostat, St Louis, MO 63108 USA	Neuman, RJ (reprint author), Washington Univ, Sch Med, Dept Psychiat, 660 S Euclid, St Louis, MO 63108 USA.	rneuman@wustl.edu					Agresti A., 2002, CATEGORICAL DATA ANA; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Devlin B, 1999, BIOMETRICS, V55, P997, DOI 10.1111/j.0006-341X.1999.00997.x; Hindorff LA, 2009, P NATL ACAD SCI USA, V106, P9362, DOI 10.1073/pnas.0903103106; Browning SR, 2007, AM J HUM GENET, V81, P1084, DOI 10.1086/521987; Skol AD, 2006, NAT GENET, V38, P209, DOI 10.1038/ng1706; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Chen WM, 2007, AM J HUM GENET, V81, P913, DOI 10.1086/521580; Childers Douglas K, 2009, BMC Proc, V3 Suppl 7, pS24; Cho Seoae, 2009, BMC Proc, V3 Suppl 7, pS25; Goldstein DB, 2009, NEW ENGL J MED, V360, P1696, DOI 10.1056/NEJMp0806284; Hinrichs AL, 2009, GENET EPIDEMIOL, V33, pS88, DOI 10.1002/gepi.20478; Kraft P, 2009, NAT REV GENET, V10, P264, DOI 10.1038/nrg2516; Marchini J, 2008, AM J HUM GENET, V83, P535, DOI 10.1016/j.ajhg.2008.09.007; Nicolae DL, 2006, GENET EPIDEMIOL, V30, P718, DOI 10.1002/gepi.20182; Niu Adan, 2009, BMC Proc, V3 Suppl 7, pS26; Satagopan JM, 2004, BIOMETRICS, V60, P589, DOI 10.1111/j.0006-341X.2004.00207.x; Servin B, 2007, PLOS GENET, V3, P1296, DOI 10.1371/journal.pgen.0030114; Sung Yun Ju, 2009, BMC Proc, V3 Suppl 7, pS27; Thomas D, 2004, GENET EPIDEMIOL, V27, P401, DOI 10.1002/gepi.20047; Wang Xuexia, 2009, BMC Proc, V3 Suppl 7, pS28; Wang XX, 2009, GENET EPIDEMIOL, V33, P164, DOI 10.1002/gepi.20369; Wu Zheyang, 2009, BMC Proc, V3 Suppl 7, pS29	23	0	0	0	0	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0741-0395			GENET EPIDEMIOL	Genet. Epidemiol.		2009	33						S19	S23		10.1002/gepi.20467		5	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	529TL	WOS:000272540700004	19924712	
J	Szymczak, S; Biernacka, JM; Cordell, HJ; Gonzalez-Recio, O; Konig, IR; Zhang, HP; Sun, YV				Szymczak, Silke; Biernacka, Joanna M.; Cordell, Heather J.; Gonzalez-Recio, Oscar; Koenig, Inke R.; Zhang, Heping; Sun, Yan V.			Machine Learning in Genome-Wide Association Studies	GENETIC EPIDEMIOLOGY			English	Article; Proceedings Paper	16th Genetic Analysis Workshop/17th Annual Meeting of the International-Genetic-Epidemiology-Society	SEP 17-20, 2008	St Louis, MO	Int Genet Epidemiol Soc		Genetic Analysis Workshop; data mining; penalized regression; random forests; network analysis	LOGISTIC-REGRESSION; RIDGE-REGRESSION; SELECTION; LASSO; DISEASE; TRAITS; MODEL	Recently, genome-wide association studies have substantially expanded our knowledge about genetic variants that influence the susceptibility to complex diseases. Although standard statistical tests for each single-nucleotide polymorphism (SNP) separately are able to capture main genetic effects, different approaches are necessary to identify SNPs that influence disease risk jointly or in complex interactions. Experimental and simulated genome-wide SNP data provided by the Genetic Analysis Workshop 16 afforded an opportunity to analyze the applicability and benefit of several machine learning methods. Penalized regression, ensemble methods, and network analyses resulted in several new findings while known and simulated genetic risk variants were also identified. In conclusion, machine learning approaches are promising complements to standard single-and multi-SNP analysis methods for understanding the overall genetic architecture of complex human diseases. However, because they are not optimized for genome-wide SNP data, improved implementations and new variable selection procedures are required. Genet. Epidemiol. 33 (Suppl. 1):S51-S57, 2009. (C) 2009 Wiley-Liss, Inc.	[Szymczak, Silke; Koenig, Inke R.] Med Univ Lubeck, Inst Med Biometrie & Stat, D-23562 Lubeck, Germany; [Biernacka, Joanna M.] Mayo Clin, Dept Hlth Sci Res, Rochester, MN USA; [Cordell, Heather J.] Univ Newcastle, Inst Human Genet, Int Ctr Life, Newcastle Upon Tyne, Tyne & Wear, England; [Zhang, Heping] Yale Univ, Dept Epidemiol & Publ Hlth, Sch Med, New Haven, CT 06520 USA; [Gonzalez-Recio, Oscar] Univ Wisconsin, Dept Dairy Sci, Madison, WI 53706 USA; [Sun, Yan V.] Univ Michigan, Sch Publ Hlth, Dept Epidemiol, Ann Arbor, MI 48109 USA	Szymczak, S (reprint author), Med Univ Lubeck, Inst Med Biometrie & Stat, Maria Goeppert Str 1, D-23562 Lubeck, Germany.	silke.szymczak@imbs.uni-luebeck.de	Sun, Yan/A-7461-2008; Konig, Inke/A-4544-2009; Szymczak, Silke/C-6625-2013; 	Gonzalez-Recio, Oscar/0000-0002-9106-4063			Amos Christopher I, 2009, BMC Proc, V3 Suppl 7, pS2; Amos Christopher I, 2007, BMC Proc, V1 Suppl 1, pS3; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436; Frazer KA, 2009, NAT REV GENET, V10, P241, DOI 10.1038/nrg2554; Meier L, 2008, J R STAT SOC B, V70, P53; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Marchini J, 2007, NAT GENET, V39, P906, DOI 10.1038/ng2088; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Samani NJ, 2007, NEW ENGL J MED, V357, P443, DOI 10.1056/NEMJoa072366; Arshadi Niloofar, 2009, BMC Proc, V3 Suppl 7, pS60; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; BREIMAN L, 2009, RANDOM FORESTS CLASS; Croiseau Pascal, 2009, BMC Proc, V3 Suppl 7, pS61; Cupples L Adrienne, 2009, BMC Proc, V3 Suppl 7, pS3; D'Angelo Gina M, 2009, BMC Proc, V3 Suppl 7, pS62; Dasarathy B. V., 1991, NEAREST NEIGHBOR PAT; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Easton DF, 2008, HUM MOL GENET, V17, pR109, DOI 10.1093/hmg/ddn287; Garcia-Magarinos M, 2009, ANN HUM GENET, V73, P360, DOI 10.1111/j.1469-1809.2009.00511.x; González-Recio Oscar, 2009, BMC Proc, V3 Suppl 7, pS63; Hastie T., 2001, ELEMENTS STAT LEARNI; Heckerman David, 1999, LEARNING GRAPHICAL M, P301; Kim Yoonhee, 2009, BMC Proc, V3 Suppl 7, pS64; Kraja Aldi T, 2009, BMC Proc, V3 Suppl 7, pS4; Lettre G, 2008, HUM MOL GENET, V17, pR116, DOI 10.1093/hmg/ddn246; Malo N, 2008, AM J HUM GENET, V82, P375, DOI 10.1016/j.ajhg.2007.10.012; Mohlke KL, 2008, HUM MOL GENET, V17, pR102, DOI 10.1093/hmg/ddn275; PEARL J., 1988, PROBABILISTIC REASON; Plenge RM, 2007, NEW ENGL J MED, V357, P1199, DOI 10.1056/NEJMoa073491; Ripley B. D., 1996, PATTERN RECOGNITION; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Schwarz Daniel F, 2007, BMC Proc, V1 Suppl 1, pS59; Schwarz Daniel F, 2009, BMC Proc, V3 Suppl 7, pS65; Sebastiani P, 2005, NAT GENET, V37, P435, DOI 10.1038/ng1533; Stassen Hans H, 2009, BMC Proc, V3 Suppl 7, pS66; STROBL C, 2008, 17 U MUN DEP STAT; Sun Yan V, 2009, BMC Proc, V3 Suppl 7, pS67; Sun YV, 2008, GENET EPIDEMIOL, V32, P350, DOI 10.1002/gepi.20309; Sun Yan V, 2007, BMC Proc, V1 Suppl 1, pS62; Tang Rui, 2009, BMC Proc, V3 Suppl 7, pS68; Tomita Y, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-120; Vapnik V.N., 1996, NATURE STAT LEARNING; Wan X, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-13; Wang Minghui, 2009, BMC Proc, V3 Suppl 7, pS69; Wu TT, 2009, BIOINFORMATICS, V25, P714, DOI 10.1093/bioinformatics/btp041; Yang Wei Will, 2009, BMC Proc, V3 Suppl 7, pS70; Ziegler A, 2007, GENET EPIDEMIOL, V31, pS51, DOI 10.1002/gepi.20280	54	29	31	5	9	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0741-0395			GENET EPIDEMIOL	Genet. Epidemiol.		2009	33						S51	S57		10.1002/gepi.20473		7	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	529TL	WOS:000272540700010	19924717	
J	Carrera, J; Rodrigo, G; Jaramillo, A; Elena, SF				Carrera, Javier; Rodrigo, Guillermo; Jaramillo, Alfonso; Elena, Santiago F.			Reverse-engineering the Arabidopsis thaliana transcriptional network under changing environmental conditions	GENOME BIOLOGY			English	Article							REGULATORY NETWORKS; EXPRESSION PATTERNS; ESCHERICHIA-COLI; SCALE-FREE; DATA SETS; ORGANIZATION; BIOLOGY; MODEL; PROFILES; MOTIF	Background: Understanding the molecular mechanisms plants have evolved to adapt their biological activities to a constantly changing environment is an intriguing question and one that requires a systems biology approach. Here we present a network analysis of genome-wide expression data combined with reverse-engineering network modeling to dissect the transcriptional control of Arabidopsis thaliana. The regulatory network is inferred by using an assembly of microarray data containing steady-state RNA expression levels from several growth conditions, developmental stages, biotic and abiotic stresses, and a variety of mutant genotypes. Results: We show that the A. thaliana regulatory network has the characteristic properties of hierarchical networks. We successfully applied our quantitative network model to predict the full transcriptome of the plant for a set of microarray experiments not included in the training dataset. We also used our model to analyze the robustness in expression levels conferred by network motifs such as the coherent feed-forward loop. In addition, the meta-analysis presented here has allowed us to identify regulatory and robust genetic structures. Conclusions: These data suggest that A. thaliana has evolved high connectivity in terms of transcriptional regulation among cellular functions involved in response and adaptation to changing environments, while gene networks constitutively expressed or less related to stress response are characterized by a lower connectivity. Taken together, these findings suggest conserved regulatory strategies that have been selected during the evolutionary history of this eukaryote.	[Carrera, Javier; Rodrigo, Guillermo; Elena, Santiago F.] Consejo Super Invest Cient UPV, Inst Biol Mol & Celular Plantas, Valencia 46022, Spain; [Carrera, Javier] Univ Politecn Valencia, ITACA, Valencia 46022, Spain; [Jaramillo, Alfonso] Ecole Polytech, CNRS UMR7654, Biochim Lab, F-91128 Palaiseau, France; [Jaramillo, Alfonso] Genopole Univ Evry Val Essonne, CNRS UPS3201, Epigenom Project, F-91034 Evry, France; [Elena, Santiago F.] Santa Fe Inst, Santa Fe, NM 87501 USA	Elena, SF (reprint author), Consejo Super Invest Cient UPV, Inst Biol Mol & Celular Plantas, Ingn Fausto Elio S-N, Valencia 46022, Spain.	sfelena@ibmcp.upv.es	Elena, Santiago/A-4191-2011; Jaramillo, Alfonso/G-4257-2013	Elena, Santiago/0000-0001-8249-5593; Jaramillo, Alfonso/0000-0002-6313-9689	Spanish Ministerio de Ciencia e Innovacion [BFU2006-14819-C02-01/BMC, TIN2006-12860]; European Regional Development Fund (ERDF); MIT-France; HPC-Europa program [RII3-CT-2003-506079]; Generalitat Valenciana; EMBO Short-term fellowship [ASTF-343.00-2007]; Santa Fe Institute.;  [FP6-NESTs 043340];  [043338];  [FP7-KBBE-212894];  [91-A3405-ATIGE]	We thank J Forment for help with computer resources and MA Blazquez for critical reading of the manuscript and useful suggestions. This work was supported by grants BFU2006-14819-C02-01/BMC and TIN2006-12860 from the Spanish Ministerio de Ciencia e Innovacion to SFE and AJ, respectively; FP6-NESTs 043340 (BioModularH2) and 043338 (Emergence), FP7-KBBE-212894 (Tarpol), the Structural Funds of the European Regional Development Fund (ERDF), the 91-A3405-ATIGE Genopole/UEVE and the MIT-France grants to AJ. JC, GR and AJ acknowledge the HPC-Europa program (RII3-CT-2003-506079). GR was supported by a graduate fellowship from the Generalitat Valenciana and an EMBO Short-term fellowship (reference ASTF-343.00-2007). SFE also acknowledges support from the Santa Fe Institute.	Kim SK, 2001, SCIENCE, V293, P2087, DOI 10.1126/science.1061603; Ravasz E, 2002, SCIENCE, V297, P1551, DOI 10.1126/science.1073374; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Oltvai ZN, 2002, SCIENCE, V298, P763, DOI 10.1126/science.1078563; Yu J, 2004, BIOINFORMATICS, V20, P3594, DOI 10.1093/bioinformatics/bth448; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Mangan S, 2003, J MOL BIOL, V334, P197, DOI 10.1016/j.jmb.2003.09.049; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Lee HK, 2004, GENOME RES, V14, P1085, DOI 10.1101/gr.1910904; Hucka M, 2003, BIOINFORMATICS, V19, P524, DOI 10.1093/bioinformatics/btg015; Ihmels J, 2002, NAT GENET, V31, P370, DOI 10.1038/ng941; Ma SS, 2007, GENOME RES, V17, P1614, DOI 10.1101/gr.6911207; Bonneau R, 2007, CELL, V131, P1354, DOI 10.1016/j.cell.2007.10.053; Albert R, 2005, J CELL SCI, V118, P4947, DOI 10.1242/jcs.02714; Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Dekel E, 2005, NATURE, V436, P588, DOI 10.1038/nature03842; Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47; Alon U, 2007, NAT REV GENET, V8, P450, DOI 10.1038/nrg2102; Mangan S, 2003, P NATL ACAD SCI USA, V100, P11980, DOI 10.1073/pnas.2133841100; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; Bar-Joseph Z, 2004, BIOINFORMATICS, V20, P2493, DOI 10.1093/bioinformatics/bth283; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Bonneau R, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-5-r36; Butte A. J., 2000, PAC S BIOCOMPUT, V5, P418; Carrera J, 2009, NUCLEIC ACIDS RES, V37, DOI 10.1093/nar/gkp022; D'haeseleer P, 2000, BIOINFORMATICS, V16, P707, DOI 10.1093/bioinformatics/16.8.707; di Bernardo D, 2005, NAT BIOTECHNOL, V23, P377, DOI 10.1038/nbt1075; Faith JJ, 2007, PLOS BIOL, V5, P54, DOI 10.1371/journal.pbio.0050008; Fujita A, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-39; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Gutierrez-Rios RM, 2003, GENOME RES, V13, P2435, DOI 10.1101/gr.1387003; Hayot F, 2005, J THEOR BIOL, V234, P133, DOI 10.1016/j.jtbi.2004.11.010; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Kashtan N, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.031909; Khanin R, 2006, J COMPUT BIOL, V13, P810, DOI 10.1089/cmb.2006.13.810; Ma SS, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-4-r49; Margolin LG, 2006, J TURBUL, V7, P1, DOI 10.1080/14685240500331595; Mentzen WI, 2008, BMC PLANT BIOL, V8, DOI 10.1186/1471-2229-8-99; Meyer Patrick E, 2007, EURASIP J Bioinform Syst Biol, P79879, DOI 10.1155/2007/79879; Ravasz E, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.026112; Sanjuan R, 2006, P NATL ACAD SCI USA, V103, P14402, DOI 10.1073/pnas.0604543103; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Steinke F, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-51; Wernicke S, 2006, BIOINFORMATICS, V22, P1152, DOI 10.1093/bioinformatics/btl038; TAIR; ATHI GENOME ARRAY; ATREGNET; NASCARRAYS; ATGENEXPRESS	52	29	31	0	6	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1474-760X			GENOME BIOL	Genome Biol.		2009	10	9							R96	10.1186/gb-2009-10-9-r96		15	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	514VX	WOS:000271425300014	19754933	
S	Antonevich, AB		Kielanowski, P; Ali, ST; Odzijewicz, A; Schlichenmaier, M; Voronov, T		Antonevich, A. B.			On Extensions of the Legendre Transform	GEOMETRIC METHODS IN PHYSICS	AIP Conference Proceedings		English	Proceedings Paper	28th Workshop on Geometric Methods in Physics	JUN 28-JUL 04, 2009	Bialowieza, POLAND	Univ Bialystok		Legendre transform; convex functional; semicontinuous functional; efficiency domain		We consider a convex functional on Banach space, such that the efficiency domain of the Legendre-dual functional belong to some cone in the dual space. We show how naturally define some extension of the initial functional on a set, which is larger that the initial space.	Univ Bialystok Akad 2, Inst Math, PL-15267 Bialystok, Poland	Antonevich, AB (reprint author), Univ Bialystok Akad 2, Inst Math, PL-15267 Bialystok, Poland.						ANTONEVICH A, 2008, ARXIV08093216V1MATHD; Antonevich A. B., 1994, FUNCTIONAL DIFFERENT; Ekeland I, 1999, CONVEX ANAL VARIATIO, V28; Katok A., 1998, INTRO MODERN THEORY; LATUSHKIN YD, 1988, FUNCT ANAL APPL+, V22, P330; Maslov V. P., 1992, IDEMPOTENT ANAL	6	2	2	1	2	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X		978-0-7354-0728-2	AIP CONF PROC			2009	1191						1	6		10.1063/1.3275593		6	Physics, Mathematical	Physics	BOB95	WOS:000276139200001		
J	Sillanpaa, MJ				Sillanpaa, Mikko J.			Detecting Interactions in Association Studies by Using Simple Allele Recoding	HUMAN HEREDITY			English	Article						Allele recoding; Interaction models; Association mapping	QUANTITATIVE TRAIT LOCI; GENE-ENVIRONMENT INTERACTIONS; MULTILOCUS ASSOCIATION; QUALITATIVE TRAITS; BAYESIAN-ANALYSIS; REGRESSION; EPISTASIS; POPULATION; QTL; SUSCEPTIBILITY	This paper aims to describe the benefits of using data recoding methods for the analysis of genetic interactions. By changing the representation of the input data it is possible to model non-additive genetic effects in association analysis software, which has been primarily designed to analyse only additive genetic effects. Similar treatment can be applied also for general-purpose statistical search algorithms available in general statistical packages. Data recoding is illustrated for several interaction models using hypothetical examples and by presenting gene-gene interaction analysis in a real cystic fibrosis dataset using the BAMA software. Copyright (C) 2008 S. Karger AG, Basel	Univ Helsinki, Dept Math & Stat, FIN-00014 Helsinki, Finland	Sillanpaa, MJ (reprint author), Univ Helsinki, Dept Math & Stat, POB 68, FIN-00014 Helsinki, Finland.	mjs@rni.helsinki.fi			Academy of Finland [202324]	I am grateful to Petri Koistinen for discussions and to three anonymous referees for their constructive comments on the manuscript. This work was supported by reseach grant (no. 202324) from the Academy of Finland.	Albrechtsen A, 2007, GENETICS, V176, P1197, DOI 10.1534/genetics.107.071696; Ritchie MD, 2001, AM J HUM GENET, V69, P138, DOI 10.1086/321276; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Sasieni PD, 1997, BIOMETRICS, V53, P1253, DOI 10.2307/2533494; Moore JH, 2003, HUM HERED, V56, P73, DOI 10.1159/000073735; Zhang Y, 2007, NAT GENET, V39, P1167, DOI 10.1038/ng2110; Efron B, 2004, ANN STAT, V32, P407; Moore JH, 2006, J THEOR BIOL, V241, P252, DOI 10.1016/j.jtbi.2005.11.036; Ayodo G, 2007, AM J HUM GENET, V81, P234, DOI 10.1086/519221; Ball RD, 2007, GENETICS, V177, P2399, DOI 10.1534/genetics.106.069955; Basu A, 2005, GENOME RES, V15, P67, DOI 10.1101/gr.2358005; Bogdan M, 2004, GENETICS, V167, P989, DOI 10.1534/genetics.103.021683; Charmet G, 1998, MOL BREEDING, V4, P67, DOI 10.1023/A:1009697522267; Cordell HJ, 2004, GENET EPIDEMIOL, V26, P167, DOI 10.1002/gepi.10307; Culverhouse R, 2002, AM J HUM GENET, V70, P461, DOI 10.1086/338759; Frankel WN, 1996, NAT GENET, V14, P371, DOI 10.1038/ng1296-371; Hoti F, 2006, HEREDITY, V97, P4, DOI 10.1038/sj.hdy.6800817; Jansen RC, 2003, NAT REV GENET, V4, P145, DOI 10.1038/nrg996; KEREM BS, 1989, SCIENCE, V245, P1073, DOI 10.1126/science.2570460; Kilpikari R, 2003, GENET EPIDEMIOL, V25, P122, DOI 10.1002/gepi.10257; Molitor J, 2003, GENET EPIDEMIOL, V25, P95, DOI 10.1002/gepi.10251; Narita A, 2004, GENET SEL EVOL, V36, P415, DOI 10.1051/gse:2004009; Purcell S, 2007, AM J HUM GENET, V81, P559, DOI 10.1086/519795; Roeder K, 2006, AM J HUM GENET, V78, P243, DOI 10.1086/500026; Setakis E, 2006, GENOME RES, V16, P290, DOI 10.1101/gr.4346306; Sillanpaa MJ, 2004, ANN HUM GENET, V68, P646, DOI 10.1046/j.1529-8817.2004.00122.x; Sillanpaa MJ, 2007, GENETICS, V177, P2361, DOI 10.1534/genetics.107.081299; Sillanpaa MJ, 2005, GENETICS, V169, P427, DOI 10.1534/genetics.104.032680; Sillanpaa MJ, 2004, GENETICS, V167, P1037, DOI 10.1534/genetics.103.025320; Sillanpaa MJ, 2006, GENETICS, V174, P1597, DOI 10.1523/genetics.106.061275; Strauch K, 2004, HUM HERED, V58, P55, DOI 10.1159/000081457; Tanck MWT, 2006, GENET EPIDEMIOL, V30, P645, DOI 10.1002/gepi.20176; Burton PR, 2007, NATURE, V447, P661, DOI 10.1038/nature05911; VORMFELDE SV, 2007, NAT REV GENET C 1201; Xu SZ, 2007, BIOMETRICS, V63, P513, DOI 10.1111/j.1541-0420.2006.00711.x; Zhang YM, 2005, HEREDITY, V95, P96, DOI 10.1038/sj.hdy.6800702	37	3	3	1	3	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	0001-5652			HUM HERED	Hum. Hered.		2009	67	1					69	75		10.1159/000164401		7	Genetics & Heredity	Genetics & Heredity	372HF	WOS:000260892000008	18931512	
B	Zhang, ZH; Pei, CX; Chen, N; Yi, YH			IEEE	Zhang, Zhenghao; Pei, Changxing; Chen, Nan; Yi, Yunhui			Robust Reconstruction under Unknown SNR Signal for Analog-to-Information Conversion	ICIEA: 2009 4TH IEEE CONFERENCE ON INDUSTRIAL ELECTRONICS AND APPLICATIONS, VOLS 1-6			English	Proceedings Paper	4th IEEE Conference on Industrial Electronics and Applications	MAY 25-27, 2009	Xian, PEOPLES R CHINA	IEEE, Ind Elect Chapter Singapore, NW Polytech Univ, IEEE Xian Sect, IEEE Control Syst Soc, IEEE Ind Elect Soc, Natl Nat Sci Fdn China, Inst Engn & Technol, Shaanxi Key Lab Informat Acquist & Proc		compressed sensing; unkown SNR; analog-to-information converter; signal reconstruction		A robust method to reconstruct the spectrum information for the analog-to-information converter (AIC) is developed. Current reconstruction algorithms require the prior knowledge or the estimation of noise level to set algorithmic parameters and stopping conditions. The proposed method requires no knowledge of noises or the acquired signal-to-noise ratio (SNR). We present a joined convex optimization model (JCO). Sampling at half of the Nyquist rate, the information of the origin signal can be rebuilt under the SNR as low as -10dB.	[Zhang, Zhenghao; Pei, Changxing; Chen, Nan; Yi, Yunhui] Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Peoples R China	Zhang, ZH (reprint author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Peoples R China.	chancejack@gmail.com					Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Kirolos S., 2006, P IEEE DALL CIRC SYS; Laska JN, 2007, IEEE INT SYMP CIRC S, P1959, DOI 10.1109/ISCAS.2007.378360	6	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2799-4				2009							571	574				4	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BMO85	WOS:000273183200111		
S	Aswani, A; Bickel, P; Tomlin, C			IEEE	Aswani, Anil; Bickel, Peter; Tomlin, Claire			Statistics for Sparse, High-Dimensional, and Nonparametric System Identification	ICRA: 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-7	IEEE International Conference on Robotics and Automation-ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation	MAY 12-17, 2009	Kobe, JAPAN	IEEE			REGRESSION; LASSO; SELECTION	Local linearization techniques are an important class of nonparametric system identification. Identifying local linearizations in practice involves solving a linear regression problem that is ill-posed. The problem can be ill-posed either if the dynamics of the system lie on a manifold of lower dimension than the ambient space or if there are not enough measurements of all the modes of the dynamics of the system. We describe a set of linear regression estimators that can handle data lying on a lower-dimension manifold. These estimators differ from previous estimators, because these estimators are able to improve estimator performance by exploiting the sparsity of the system the existence of direct interconnections between only some of the states and can work in the "large p, small n" setting in which the number of states is comparable to the number of data points. We describe our system identification procedure, which consists of a presmoothing step and a regression step, and then we apply this procedure to data taken from a quadrotor helicopter. We use this data set to compare our procedure with existing procedures.	[Aswani, Anil; Tomlin, Claire] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Aswani, A (reprint author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	aaswani@eecs.berkeley.edu; bickel@stat.berkeley.edu; tomlin@eecs.berkeley.edu					Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; MASSY WF, 1965, J AM STAT ASSOC, V60, P234, DOI 10.2307/2283149; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; ASWANI A, 2009, EXTERIOR DERIV UNPUB; Atkeson CG, 1997, ARTIF INTELL REV, V11, P75, DOI 10.1023/A:1006511328852; BICKEL P, 2007, IMS LECT NOTES MONOG, V54; BICKEL P, 2008, ANN STAT IN PRESS; BICKEL PJ, 2006, MATH STAT; Callier F. M., 1991, LINEAR SYSTEM THEORY; El Karoui N, 2007, ANN PROBAB, V35, P663, DOI 10.1214/009117906000000917; Hoerl A. E., 1970, TECHNOMETRICS, V8, P27; Hoffmann G., 2007, P AIAA GUID NAV CONT; Hoffmann G. M., 2008, P AIAA GUID NAV CONT; Hunt KJ, 1997, INT J CONTROL, V66, P619, DOI 10.1080/002071797224487; Johnstone I. M., 2004, SPARSE PRINCIPAL COM; KOO JY, 1993, ANN STAT, V21, P590, DOI 10.1214/aos/1176349138; Lee J. M., 2003, INTRO SMOOTH MANIFOL; Ljung L, 1999, SYSTEM IDENTIFICATIO; Marcenko V. A., 1967, MATH USSR SB, V1, P507; Meinshausen N., 2006, ANN STAT IN PRESS; Phillips WF, 2001, J AIRCRAFT, V38, P718, DOI 10.2514/2.2824; Proakis J. G., 1995, DIGITAL SIGNAL PROCE, V3rd; RUPPERT D, 1994, ANN STAT, V22, P1346, DOI 10.1214/aos/1176325632; Sastry S., 1999, NONLINEAR SYSTEMS; Schneeweiss H., 1976, Metrika, V23; TING J, 2008, P IEEE INT C ROB AUT; Van Huffel S., 1991, TOTAL LEAST SQUARES; Varaiya P., 1986, STOCHASTIC SYSTEMS E; Vijayakumar S, 2005, NEURAL COMPUT, V17, P2602, DOI 10.1162/089976605774320557; Wold H., 1975, PERSPECTIVES PROBABI	34	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729		978-1-4244-2788-8	IEEE INT CONF ROBOT			2009							4091	4096				6	Automation & Control Systems; Robotics	Automation & Control Systems; Robotics	BOB06	WOS:000276080402041		
J	Qu, LM; Routh, PS; Anno, PD				Qu, Leming; Routh, Partha S.; Anno, Phil D.			Wavelet Reconstruction of Nonuniformly Sampled Signals	IEEE SIGNAL PROCESSING LETTERS			English	Article						AIC; LARS; Lasso; wavelet	REGRESSION; SHRINKAGE; SELECTION; SPARSE; LASSO	For the reconstruction of a nonuniformly sampled signal based on its noisy observations, we propose a level dependent 11 penalized wavelet reconstruction method. The LARS/Lasso algorithm is applied to solve the Lasso problem. The data adaptive choice of the regularization parameters is based on the AIC and the degrees of freedom is estimated by the number of nonzero elements in the Lasso solution. Simulation results conducted on some commonly used I D test signals illustrate that the proposed method possesses good empirical properties.	[Qu, Leming] Boise State Univ, Dept Math, Boise, ID 83725 USA; [Routh, Partha S.; Anno, Phil D.] Conoco Phillips, Seism Technol Dev, Houston, TX 77252 USA	Qu, LM (reprint author), Boise State Univ, Dept Math, Boise, ID 83725 USA.	lqu@boisestate.edu; Partha.S.Routh@Cono-coPhillips.com; phil.d.anno@conocophillips.com					Amato U, 2006, STAT COMPUT, V16, P37, DOI 10.1007/s11222-006-5283-4; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Efron B, 2004, ANN STAT, V32, P407; CHOI H, 1999, P IEEE INT C AC SPEE, P1645; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Fu WJ, 2005, J STAT PLAN INFER, V131, P333, DOI 10.1016/j.jspi.2004.03.001; Hennenfent G, 2008, GEOPHYSICS, V73, pA23, DOI 10.1190/1.2944169; Mallat S., 1998, WAVELET TOUR SIGNAL; Vidakovic B, 1999, STAT MODELING WAVELE; Yang YH, 2005, BIOMETRIKA, V92, P937, DOI 10.1093/biomet/92.4.937; Zhang HH, 2004, J AM STAT ASSOC, V99, P659, DOI 10.1198/016214504000000593; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	15	2	2	1	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1070-9908			IEEE SIGNAL PROC LET	IEEE Signal Process. Lett.	JAN-MAR	2009	16	1-3					73	76		10.1109/LSP.2008.2008939		4	Engineering, Electrical & Electronic	Engineering	444JT	WOS:000265977900018		
J	Destrero, A; De Mol, C; Odone, F; Verri, A				Destrero, Augusto; De Mol, Christine; Odone, Francesca; Verri, Alessandro			A Sparsity-Enforcing Method for Learning Face Features	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article						Face features; feature selection; regularization methods; sparsity-enforcing penalty	OBJECT DETECTION; SELECTION; IMAGES; MODEL	In this paper, we propose a new trainable system for selecting face features from over-complete dictionaries of image measurements. The starting point is an iterative thresholding algorithm which provides sparse solutions to linear systems of equations. Although the proposed methodology is quite general and could be applied to various image classification tasks, we focus here on the case study of face and eves detection. For our initial representation, we adopt rectangular features in order to allow straightforward comparisons with existing techniques. For computational efficiency and memory saving requirements, instead of implementing the full optimization scheme on tenths of thousands of features, we propose a three-stage architecture which consists of finding first intermediate solutions to smaller size optimization problems, then merging the obtained results, and next applying further selection procedures. The devised system requires the solution of a number of independent problems, and, hence, the necessary computations could be implemented in parallel. Experimental results obtained on both benchmark and newly acquired face and eyes images indicate that our method is a serious competitor to other feature selection schemes recently popularized in computer vision for dealing with problems of real-time object detection. A major advantage of the proposed system is that it performs well even with relatively small training sets.	[Destrero, Augusto; Odone, Francesca; Verri, Alessandro] Univ Genoa, Dept Comp & Informat Sci DISI, I-16146 Genoa, Italy; [De Mol, Christine] Univ Libre Bruxelles, Dept Math, B-1050 Brussels, Belgium; [De Mol, Christine] Univ Libre Bruxelles, ECARES, B-1050 Brussels, Belgium	Destrero, A (reprint author), Univ Genoa, Dept Comp & Informat Sci DISI, I-16146 Genoa, Italy.	destrero@disi.unige.it; demol@ulb.ac.be; odone@disi.unige.it; verri@disi.unige.it			FIRB [RBINO4PARL]; DISI; ARC [02/07-281, GOA62]	Manuscript received June 28, 2007 revised August 12, 2008. First published November 18, 2008; Current version published December 12, 2008. This work was supported in part by the FIRB Project LEAP (RBINO4PARL). C. De Mol was Supported in part by DISI during a sabbatical semester in Genoa and in part by Grants ARC 02/07-281 and GOA62 (VUB). The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Gaudenz Danuser.	Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; BURT PJ, 1988, P IEEE, V76, P1006, DOI 10.1109/5.5971; Chen Y, 1998, NONCON OPTIM ITS APP, V20, P1; Daubechies I., 2004, COMMUN PURE APPL MAT, V57, P1416; Destrero A, 2007, LECT NOTES COMPUT SC, V4844, P881; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; FOWLER J, 2005, IEEE SIGNAL PROCESS, V12, P639; FRANCESCHI E, 2005, IEEE INT C IM PROC; Freund Y., 1995, P 2 EUR C COMP LEARN, P23; FRIEDMAN J, 1998, ADDITIVE LOGISTICS R; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HEISELE B, 2001, CVPR; Heisele B., 2001, IEEE CVPR; Lehmann E. L., 1975, NONPARAMETRICS STAT; Li S., 2004, IEEE T PATTERN ANAL, V26; Mann S., 1991, P VIS INT, P205; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Osuna E., 1997, CVPR; RAJPOOT N, 2001, IEEE INT C IM PROC; RESEFIELD A, 1977, IEEE T SYST MAN CYB, V7, P104; ROTH D, 2000, NEUR INF PROCESS, V12; SCHNEIDERMAN H, 2000, INT C COMP VIS; SMERALDI F, 2002, P 16 ICPR QUEB QC, V3, P379; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; TSOTSOS JK, 1995, ARTIF INTELL J, V78; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; WANG Q, 2006, INT J INTELL TECHNOL, V1; WESTON J, 2003, J MACH LEARN RES, V3; ZHANG D, 2004, ICPR; Zhu J., 2004, ADV NEURAL INFORM PR, V16	38	16	16	0	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1057-7149			IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	JAN	2009	18	1					188	201		10.1109/TIP.2008.2007610		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	391GN	WOS:000262221900016	19095529	
J	Ji, SH; Dunson, D; Carin, L				Ji, Shihao; Dunson, David; Carin, Lawrence			Multitask Compressive Sensing	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						Compressive sensing (CS); hierarchical Bayesian modeling; multitask learning; relevance vector machine (RVM); simultaneous sparse approximation	SIMULTANEOUS SPARSE APPROXIMATION; MULTIPLE TASKS; INFORMATION; REGRESSION; ALGORITHMS; EFFICIENT; SELECTION; MODELS	Compressive sensing (CS) is a framework whereby one performs N nonadaptive measurements to constitute a vector upsilon is an element of R(N), with upsilon used to recover an approximation (u) over cap is an element of R(M) to a desired signal u is an element of R(M), with N << M; this is performed under the assumption that a is sparse in the basis represented by the matrix Psi is an element of R(MxM). It has been demonstrated that with appropriate design of the compressive measurements used to define upsilon, the decompressive mapping upsilon -> (u) over cap may be performed with error parallel to u - (u) over cap parallel to(2)(2) having asymptotic properties analogous to those of the best adaptive transform-coding algorithm applied in the basis T. The mapping upsilon -> (u) over cap constitutes an inverse problem, often solved using l(1) regularization or related techniques. In most previous research, if L > 1 sets of compressive measurements {upsilon(i)}(i)=1, L are performed, each of the associated {(u) over cap (i)}(i)=1, L are recovered one at a time, independently. In many applications the L "tasks" defined by the mappings upsilon(i) -> (u) over cap (i) are not statistically independent, and it may be possible to improve the performance of the inversion if statistical interrelationships are exploited. In this paper, we address this problem within a multitask learning setting, wherein the mapping v; - u; for each task corresponds to inferring the parameters (here, wavelet coefficients) associated with the desired signal u;, and a shared prior is placed across all of the L tasks. Under this hierarchical Bayesian modeling, data from all L tasks contribute toward inferring a posterior on the hyperparameters, and once the shared prior is thereby inferred, the data from each of the L individual tasks is then employed to estimate the task-dependent wavelet coefficients. An empirical Bayesian procedure for the estimation of hyperparameters is considered; two fast inference algorithms extending the relevance vector machine (RVM) are developed. Example results on several data sets demonstrate the effectiveness and robustness of the proposed algorithms.	[Ji, Shihao; Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; [Dunson, David] Duke Univ, Inst Stat & Decis Sci, Durham, NC 27708 USA	Ji, SH (reprint author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	shji@ece.duke.edu; dunson@stat.duke.edu; lcarin@ece.duke.edu			Office of Naval Research; Defense Advanced Research Project Agency (DARPA)	This work was supported in part by the Office of Naval Research and by the Defense Advanced Research Project Agency (DARPA) under the Mathematical Time Reversal program.	MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150; Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016; Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; Tropp JA, 2006, SIGNAL PROCESS, V86, P589, DOI 10.1016/j.sigpro.2005.05.031; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI 10.1016/j.sigpro.2005.05.029; Efron B, 2004, ANN STAT, V32, P407; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Wipf DP, 2007, IEEE T SIGNAL PROCES, V55, P3704, DOI 10.1109/TSP.2007.894265; Baron D., 2005, DISTRIBUTED COMPRESS; Baxter J, 1995, COLT; BAXTER J, 2000, J ARTIF INTELL RES; Bishop C., 2000, P 16 C UNC ART INT, P46; Burr D, 2005, J AM STAT ASSOC, V100, P242, DOI 10.1198/016214504000001024; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Cotter RJ, 2005, J MASS SPECTROM SOC, V53, P7; Daubechies I., 1992, 10 LECT WAVELETS; Dominici F, 1997, J AGR BIOL ENVIR ST, V2, P294; Donoho D. L., 2006, SPARSE SOLUTION UNDE; Dunson DB, 2007, STAT SINICA, V17, P481; Escoda OD, 2006, IEEE T SIGNAL PROCES, V54, P3468, DOI 10.1109/TSP.2006.879306; FAUL AC, 2002, P ADV NEUR INF PROC, V14, P383; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; FIGUEIREDO M, 2002, ADV NEURAL INF PROCE; FIGUEIREDO MA, 2007, GRADIENT PROJECTION; Hoff PD, 2003, 421 U WASH STAT DEP; Ji Sh., 2008, IEEE T SIGNAL PROCES, V56; Lawrence Neil D., 2004, P 21 INT C MACH LEAR; Leviatan D., 2003, SIMULTANEOUS APPROXI; Louis T. A., 2000, BAYES EMPIRICAL BAYE; Mallat S., 1998, WAVELET TOUR SIGNAL; Mallick BK, 1997, BIOMETRIKA, V84, P697, DOI 10.1093/biomet/84.3.697; Muller P, 2004, J ROY STAT SOC B, V66, P735, DOI 10.1111/j.1467-9868.2004.05564.x; Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834; SVENSEN M, 2004, NEUROCOMPUTING, V64, P235; TIPPING ME, 2003, 9 INT WORKSH AISTATS; Tropp J. A., 2007, IEEE T INF THEORY; Tropp Joel A, 2005, P  IEEE ICASSP PHIL, V5, P721, DOI 10.1109/ICASSP.2005.1416405; WIPF DP, 2008, P ADV NEUR INF PROC, V20; WIPF DP, 2006, P ADV NEUR INF PROC, V18; Yu K., 2005, P 22 INT C MACH LEAR; YU S, 2007, P 24 INT C MACH LEAR; ZHANG J, 2005, P ADV NEUR INF PROC, V18	50	125	134	8	31	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-587X			IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	JAN	2009	57	1					92	106		10.1109/TSP.2008.2005866		15	Engineering, Electrical & Electronic	Engineering	395XT	WOS:000262557500009		
S	Bailly, K; Milgram, M			IEEE	Bailly, Kevin; Milgram, Maurice			BISAR: Boosted Input Selection Algorithm for Regression	IJCNN: 2009 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1- 6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 14-19, 2009	Atlanta, GA	Int Neural Network Soc, IEEE Computat Intelligence Soc				We present in this paper a new regression method adapted to problems dealing with a huge set of potential features like in pattern recognition. This method combines a boosted forward feature selection algorithm and a Generalized Regression Neural Network. The feature selection uses a new criterion, the Fuzzy Functional Criterion, to evaluate the relevance of each feature. It is well suited to measure to what extent a random variable y can be viewed as a function of another random variable x. We explain how this measure is more appropriate than the classical mutual information. At each step, features are evaluated using weights on examples computed from the error produced by the neural network at the previous step. This boosting strategy helps our system to focus on hard examples during the feature selection process. The application is head pose estimation, a challenging problem in pattern recognition. Test are carried out on the commonly used Pointing 04 database and compared with state-of-the-art results.	[Bailly, Kevin; Milgram, Maurice] Univ Paris 06, UPMC, CNRS, UMR 7222,ISIR, F-75005 Paris, France	Bailly, K (reprint author), Univ Paris 06, UPMC, CNRS, UMR 7222,ISIR, F-75005 Paris, France.	kevin.bailly@isir.fr; maurice.milgram@upmc.fr					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; CHAPADOS N, 2001, P IJCNN 01 INT JOINT, V2, P1233; GOURIER N, 2007, LNCS MULTIMODAL TECH, P270; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Kohavi R, 1997, ARTIF INTELL, V1, P273; MURPHYCHUTORIAN E, 2008, IEEE T PATTERN ANAL, V99; REDPATH DB, 2005, ICAPR, P305; Schapire R., 2003, NONLINEAR ESTIMATION; Shrestha DL, 2006, NEURAL COMPUT, V18, P1678, DOI 10.1162/neco.2006.18.7.1678; Viola Paul, 2002, INT J COMPUTER VISIO; VOIT M, 2007, LNCS MULTIMODAL TECH, P291; WASSERMAN PD, 1993, ADV METH NEURAL COMP; Wu H., 2008, COMPUTER VISION PATT, P1; Xu X., 2006, INT C COMP SCI, P670	14	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-3549-4	IEEE IJCNN			2009							2287	2293				7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BQB78	WOS:000280591601076		
S	Zhang, K; Peng, H; Chan, LW; Hyvarinen, A		Adali, T; Jutten, C; Romano, JMT; Barros, AK		Zhang, Kim; Peng, Heng; Chan, Laiwan; Hyvarinen, Aapo			ICA with Sparse Connections: Revisited	INDEPENDENT COMPONENT ANALYSIS AND SIGNAL SEPARATION, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	8th International Conference on Independent Component Analysis and Signal Separation	MAR 15-18, 2009	Paraty, BRAZIL	CNPq, CAPES, FAPERJ, Univ Campinas, Fed Univ Maranhao, Fed Univ Rio de Janeiro, Fed Univ Ceara, Fed Univ Minas Gerais, Brazilian Telecommun Soc			INDEPENDENT COMPONENT ANALYSIS; SELECTION; MODEL; LIKELIHOOD; LASSO	When applying independent component analysis (ICA), sometimes we expect the connections between the observed mixtures and the recovered independent components (or the original sources) to be sparse, to make the interpretation easier or to reduce the random effect in the results. In this paper we propose two methods to tackle this problem. One is based oil adaptive Lasso, which exploits the L(1) penalty with data-adaptive weights. We show the relationship between this method and the classic information criteria such as BIC and ATC. The other is based oil optimal brain surgeon, and we show how its stepping criterion is related to the information criteria. This method produces the solution path of the transformation matrix, with different number of zero entries. These methods involve low computational loads. Moreover, in each method, the parameter controlling the sparsity level of the transformation matrix has clear interpretations. By setting such parameters to certain values, the results of the proposed methods are consistent with those produced by classic information criteria.	[Zhang, Kim; Hyvarinen, Aapo] Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland	Zhang, K (reprint author), Univ Helsinki, Dept Comp Sci, FIN-00014 Helsinki, Finland.						Akaike H., 1973, P 2 INT S INF THEOR, P267; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Shimizu S, 2006, J MACH LEARN RES, V7, P2003; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; HASSIBI B, 1993, NIPS, V5, P164; Hyvarinen A, 2002, NEUROCOMPUTING, V49, P151, DOI 10.1016/S0925-2312(02)00512-X; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Pham DT, 1997, IEEE T SIGNAL PROCES, V45, P1712; Silva F. M., 1990, Neural Networks. EURASIP Workshop 1990 Proceedings; Zhang K, 2006, LECT NOTES COMPUT SC, V4224, P530; Zhang K, 2008, J MACH LEARN RES, V9, P2455; ZOU H, 2006, J AM STAT ASSOC, V101, P1417	14	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-00598-5	LECT NOTES COMPUT SC			2009	5441						195	202				8	Computer Science, Theory & Methods	Computer Science	BJE21	WOS:000265092800025		
S	Ng, B; Abugharbieh, R; McKeown, MJ		Prince, JL; Pham, DL; Myers, KJ		Ng, Bernard; Abugharbieh, Rafeef; McKeown, Martin J.			Discovering Sparse Functional Brain Networks Using Group Replicator Dynamics (GRD)	INFORMATION PROCESSING IN MEDICAL IMAGING, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	21st International Conference on Information Processing in Medical Imaging	JUL 05-10, 2009	Williamsburg, VA	Natl Inst Biomed Imaging & Biengn, Natl Canc Inst, Natl Inst Neurol Disorders & Stroke, Natl Inst Aging, Johns Hopkin Univ	Coll William & Mary	fMRI; functional connectivity; group analysis; replicator dynamics	INDEPENDENT COMPONENT ANALYSIS; WORKING-MEMORY NETWORK; TEMPORAL-LOBE EPILEPSY; FMRI TIME-SERIES; MULTIPLE-SCLEROSIS; MOTOR CORTEX; IMAGING DATA; CONNECTIVITY; MRI; CONSEQUENCES	Functional magnetic resonance imaging (fMRI) has become increasingly used for studying functional integration of the brain. However, the large inter-subject variability in functional connectivity renders detection of representative group networks very difficult. In this paper, we propose a new iterative method that we refer to as "group replicator dynamics," for detecting sparse functional networks that are common across subjects within a group. The proposed method uses replicator dynamics, which we show to be equivalent to non-negative sparse PCA, and incorporates group information for identifying common networks across subjects with subject-specific weightings of the identified brain regions reflecting individual differences. Finding a separate network for each subject, as opposed to employing, traditional averaging approaches, permits statistical testing of group significance. We validated Our method on synthetic data, and applying it to real fMRI data detected task-specific group networks that conform well with prior neuroscience knowledge.	[Ng, Bernard; Abugharbieh, Rafeef] Univ British Columbia, Dept Elect Engn, Biomed Signal & Image Comp Lab, Vancouver, BC, Canada	Ng, B (reprint author), Univ British Columbia, Dept Elect Engn, Biomed Signal & Image Comp Lab, Vancouver, BC, Canada.	bernardn@ece.ubc.ca; rafeef@ece.ubc.ca; mmckeown@interchange.ubc.ca					Addis DR, 2007, BRAIN, V130, P2327, DOI 10.1093/brain/awm166; Greicius MD, 2003, P NATL ACAD SCI USA, V100, P253, DOI 10.1073/pnas.0135058100; Bassett DS, 2006, NEUROSCIENTIST, V12, P512, DOI 10.1177/1073858406293182; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Uylings HBM, 2005, ANAT EMBRYOL, V210, P423, DOI 10.1007/s00429-005-0042-4; He BJ, 2007, CURR OPIN NEUROL, V20, P655; McKeown MJ, 1998, HUM BRAIN MAPP, V6, P160, DOI 10.1002/(SICI)1097-0193(1998)6:3<160::AID-HBM5>3.0.CO;2-1; SCHUSTER P, 1983, J THEOR BIOL, V100, P533, DOI 10.1016/0022-5193(83)90445-9; van de Ven VG, 2004, HUM BRAIN MAPP, V22, P165, DOI 10.1002/hbm.20022; Cordes D, 2002, MAGN RESON IMAGING, V20, P305, DOI 10.1016/S0730-725X(02)00503-9; Goutte C, 1999, NEUROIMAGE, V9, P298, DOI 10.1006/nimg.1998.0391; Marrelec G, 2006, NEUROIMAGE, V32, P228, DOI 10.1016/j.neuroimage.2005.12.057; Calhoun VD, 2001, HUM BRAIN MAPP, V14, P140, DOI 10.1002/hbm.1048; BISWAL B, 1995, MAGNET RESON MED, V34, P537, DOI 10.1002/mrm.1910340409; Cader S, 2006, BRAIN, V129, P527, DOI 10.1093/brain/awh670; Schmithorst VJ, 2004, J MAGN RESON IMAGING, V19, P365, DOI 10.1002/jmri.20009; Bokde ALW, 2001, NEURON, V30, P609, DOI 10.1016/S0896-6273(01)00288-4; Cates J, 2007, LECT NOTES COMPUT SC, V4584, P333; DASPREMONT A, 2007, 24 INT C MACH LEARN, V227, P177; Duong MVA, 2005, J CEREBR BLOOD F MET, V25, P1245, DOI 10.1038/j.jcbfm.9600122; Duong MVA, 2005, NEUROIMAGE, V24, P533, DOI 10.1016/j.neuroimage.2004.08.038; FRISTON KJ, 1993, J CEREBR BLOOD F MET, V13, P5; Friston K. J., 1993, Human Brain Mapping, V1, P69, DOI 10.1002/hbm.460010108; Goncalves MS, 2001, NEUROIMAGE, V14, P1353, DOI 10.1006/nimg.2001.0954; Haslinger B, 2001, BRAIN, V124, P558, DOI 10.1093/brain/124.3.558; Liao R, 2005, IEEE T MED IMAGING, V24, P29, DOI 10.1109/TMI.2004.837791; Lohmann G, 2002, IEEE T MED IMAGING, V21, P485, DOI 10.1109/TMI.2002.1009384; Neumann J, 2005, HUM BRAIN MAPP, V25, P165, DOI 10.1002/hbm.20133; Neumann J, 2006, NEUROIMAGE, V32, P208, DOI 10.1016/j.neuroimage.2006.02.039; NG B, 2008, 5 IEEE INT S BIOM IM, P275; NG B, 2009, SPIE C MED IM ORL FL; OGUZ I, 2008, 5 IEEE INT S BIOM IM, P1637; Samanez-Larkin GR, 2008, SOC COGN AFFECT NEUR, V3, P290, DOI 10.1093/scan/nsn029; Schlosser RGM, 2006, NEUROSCIENCE, V139, P91, DOI 10.1016/j.neuroscience.2005.06.037; Sigg C.D., 2008, 25 INT C MACH LEARN; Talairach J, 1988, COPLANAR STEREOTAXIC; van den Heuvel M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002001; Verstynen T, 2005, J NEUROPHYSIOL, V93, P1209, DOI 10.1152/jn.00720.2004; Waites AB, 2006, ANN NEUROL, V59, P335, DOI 10.1002/ana.20733; Wilke M, 2002, HUM BRAIN MAPP, V17, P48, DOI 10.1002/hbm.10053; Zass R., 2006, ADV NEURAL INFORM PR, P1561; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	42	2	2	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-02497-9	LECT NOTES COMPUT SC			2009	5636						76	87				12	Computer Science, Information Systems; Computer Science, Theory & Methods; Medical Informatics	Computer Science; Medical Informatics	BLR60	WOS:000270886300007		
J	Kukreja, SL				Kukreja, Sunil L.			Application of a least absolute shrinkage and selection operator to aeroelastic flight test data	INTERNATIONAL JOURNAL OF CONTROL			English	Article						aeroelasticity; non-linear system identification; parametric models; mathematical modelling; model selection; NARMAX; LASSO	NONLINEAR TIME-SERIES; OUTPUT PARAMETRIC MODELS; NON-LINEAR SYSTEMS; NONPARAMETRIC IDENTIFICATION; EMBEDDING DIMENSION; ORDER DETERMINATION; STOCHASTIC-SYSTEMS; SQUARES ALGORITHM; BOOTSTRAP METHOD; NARMAX MODELS	Identification of non-linear systems involves estimating unknown parameters and model (regressor) selection, selection of a subset of candidate terms that best describes the observed output. Model selection is an important step in black-box modelling of any observed process. This procedure is concerned with selecting a subset of parameters to give a parsimonious description of the system which may afford greater insight into the functionality of the system or a simpler controller design. In this study, a least absolute shrinkage and selection operator (LASSO) technique is investigated for computing efficient model descriptions of non-linear aeroelastic systems. The LASSO minimises the residual sum of squares by the addition of an 1 penalty term on the parameter vector of the traditional 2 minimisation problem. Its use for model selection is a natural extension of this constrained minimisation approach to pseudolinear regression problems which produces some model parameters that are exactly zero and, therefore, yields a parsimonious system description. Applicability of this technique for model structure computation for the F/A-18 Active Aeroelastic Wing using flight test data is shown for several flight conditions (Mach numbers) by identifying a parsimonious system description with a high percent fit for cross-validated data.	NASA, Dryden Flight Res Ctr, Edwards AFB, CA 93523 USA	Kukreja, SL (reprint author), NASA, Dryden Flight Res Ctr, MailStop TRL 47, Edwards AFB, CA 93523 USA.	sunil.l.kukreja@nasa.gov					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; PI H, 1994, NEURAL COMPUT, V6, P509, DOI 10.1162/neco.1994.6.3.509; KENNEL MB, 1992, PHYS REV A, V45, P3403, DOI 10.1103/PhysRevA.45.3403; SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328; Young P, 1996, J APPL STAT, V23, P165; AUESTAD B, 1990, BIOMETRIKA, V77, P669, DOI 10.1093/biomet/77.4.669; AUTIN M, 1992, IEEE INT S CIRC SYST, V1, P296; Baldelli DH, 2004, 45 AIAA ASME ASCE AH; BILLINGS SA, 1988, INT J SYST SCI, V19, P1559, DOI 10.1080/00207728808964057; CHEN R, 1995, BIOMETRIKA, V82, P369; CHENG B, 1992, J ROY STAT SOC B MET, V54, P427; Dowell E, 2003, J AIRCRAFT, V40, P857, DOI 10.2514/2.6876; Efron B, 1993, INTRO BOOTSTRAP; Gawronski W., 1996, BALANCED CONTROL FLE; GUPTA NK, 1977, J GUIDANCE DYNAMICS, V1, P197; HABER R, 1990, AUTOMATICA, V26, P651, DOI 10.1016/0005-1098(90)90044-I; HE XD, 1993, PROCEEDINGS OF THE 1993 AMERICAN CONTROL CONFERENCE, VOLS 1-3, P2520; KLEIN V, 1981, AIAA 1981 1866 AM I; Klein V., 1981, TP1916 NASA; KLEIN V, 1983, J AIRCRAFT, V20, P469, DOI 10.2514/3.44895; KORENBERG M, 1988, INT J CONTROL, V48, P193, DOI 10.1080/00207178808906169; KRISHNASWAMI V, 1995, PROCEEDINGS OF THE 1995 AMERICAN CONTROL CONFERENCE, VOLS 1-6, P2113; Kukreja S. L., 2006, P 14 IFAC S SYST ID, P814; Kukreja SL, 2005, INT J CONTROL, V78, P937, DOI 10.1080/00207170500199627; Kukreja SL, 2007, J GUID CONTROL DYNAM, V30, P557, DOI 10.2514/1.20835; Kukreja SL, 2004, INT J CONTROL, V77, P132, DOI 10.1080/00207170310001646264; Lee BHK, 1999, PROG AEROSP SCI, V35, P205, DOI 10.1016/S0376-0421(98)00015-3; LEONTARITIS IJ, 1985, INT J CONTROL, V41, P303, DOI 10.1080/0020718508961129; LEONTARITIS IJ, 1985, INT J CONTROL, V41, P329, DOI 10.1080/0020718508961130; Lind I, 2005, AUTOMATICA, V41, P693, DOI 10.1016/j.automatica.2004.11.017; MESZAROS C, 1998, 9888 HUNG AC SCI; Nielsen HA, 2001, COMPUT STAT DATA AN, V37, P13, DOI 10.1016/S0167-9473(00)00061-X; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; PEARSON RK, 1995, J PROCESS CONTR, V5, P197, DOI 10.1016/0959-1524(95)00014-H; Pendleton EW, 2000, J AIRCRAFT, V37, P554, DOI 10.2514/2.2654; PONCET A, 1994, IEEE INT S CIRC SYST, V5, P221; Pottmann M, 1998, AICHE J, V44, P131, DOI 10.1002/aic.690440114; Rhodes C, 1998, AICHE J, V44, P151, DOI 10.1002/aic.690440116; SMITH R, 1995, IEEE AUTOMATIC CONTR, V40, P10631; TJOSTHEIM D, 1994, J AM STAT ASSOC, V89, P1398, DOI 10.2307/2291002; TJOSTHEIM D, 1994, J AM STAT ASSOC, V89, P1410, DOI 10.2307/2291003; Tschernig R, 2000, J TIME SER ANAL, V21, P457, DOI 10.1111/1467-9892.00193; Vandenberghe L., 2004, CONVEX OPTIMIZATION; VIEU P, 1995, STATISTICS, V26, P307, DOI 10.1080/02331889508802499; YAO QW, 1994, STAT SINICA, V4, P51; Young P, 2000, COMPUT ELECTRON AGR, V26, P239, DOI 10.1016/S0168-1699(00)00078-8; Young P, 2001, INT J CONTROL, V74, P1767, DOI 10.1080/00207170110089789; Young P, 2000, NONLINEAR AND NONSTATIONARY SIGNAL PROCESSING, P74; Young PC, 2001, INT J CONTROL, V74, P1837, DOI 10.1080/00207170110089824; Zheng GL, 1996, NEURAL NETWORKS, V9, P1619, DOI 10.1016/0893-6080(95)00139-5	51	3	3	1	4	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0020-7179			INT J CONTROL	Int. J. Control		2009	82	12					2284	2292	PII 913707281	10.1080/00207170903032847		9	Automation & Control Systems	Automation & Control Systems	515YE	WOS:000271508000011		
J	Liu, ZQ; Jiang, F				Liu, Zhenqiu; Jiang, Feng			Gene identification and survival prediction with L-p Cox regression and novel similarity measure	INTERNATIONAL JOURNAL OF DATA MINING AND BIOINFORMATICS			English	Article						survival prediction; gene selection; L-p penalty	MICROARRAY DATA; MODEL; SELECTION; LASSO	In this paper, Cox's proportional hazards model with L-p penalty method is developed for simultaneous gene selection and survival prediction. L-p penalty shrinks coefficients and produces some coefficients that are exactly zero, and therefore can be used to identify survival related downstream genes. We also define a novel similarity measure to hunt the regulatory genes that their gene expression changes may be low but they are highly correlated with the selected genes. Experimental results with gene expression data demonstrate that the proposed procedures can be used for identifying important gene clusters that are related to time to death due to cancer and for building parsimonious model for predicting the survival of future patients.	[Liu, Zhenqiu; Jiang, Feng] Univ Maryland, Greenebaum Canc Ctr, Baltimore, MD 21201 USA	Liu, ZQ (reprint author), Univ Maryland, Greenebaum Canc Ctr, 22 S Greene St, Baltimore, MD 21201 USA.	zliu@umm.edu; fjiang@som.umaryland.edu					Knight K, 2000, ANN STAT, V28, P1356; Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Dave SS, 2004, NEW ENGL J MED, V351, P2159, DOI 10.1056/NEJMoa041869; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Heagerty PJ, 2005, BIOMETRICS, V61, P92, DOI 10.1111/j.0006-341X.2005.030814.x; Cheng S, 1998, CHINA RICE, V1, P3; Cox D. R., 1972, J R STAT SOC B, V34; Donoho D. L., 2003, P NATL ACAD SCI USA, V100; Inza I, 2002, J INTELL FUZZY SYST, V12, P25; Klebanov L, 2006, STAT APPL GENET MOL, V5; LIU Z, 2007, J STAT APPL GENETICS, V6; Ma SG, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-192; Monari G, 2000, NEUROCOMPUTING, V35, P195, DOI 10.1016/S0925-2312(00)00325-8; Rapaport F, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-35; Rivals I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753724; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Wolberg WH, 1999, CLIN CANCER RES, V5, P3542	19	5	5	0	3	INDERSCIENCE ENTERPRISES LTD	GENEVA	WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 896, CH-1215 GENEVA, SWITZERLAND	1748-5673			INT J DATA MIN BIOIN	Int. J. Data Min. Bioinform.		2009	3	4			SI		398	408				11	Mathematical & Computational Biology	Mathematical & Computational Biology	532CR	WOS:000272722100004	20052904	
S	Seeger, MW		Inoue, M; Ishii, S; Kabashima, Y; Okada, M		Seeger, Matthias W.			Sparse linear models: Variational approximate inference and Bayesian experimental design	INTERNATIONAL WORKSHOP ON STATISTICAL-MECHANICAL INFORMATICS 2009 (IW-SMI 2009)	Journal of Physics Conference Series		English	Proceedings Paper	International Workshop on Statistical-Mechanical Informatics	SEP 13, 2009	Kyoto, JAPAN				IMAGES	A wide range of problems such as signal reconstruction, denoising, source separation, feature selection, and graphical model search are addressed today by posterior maximization for linear models with sparsity-favouring prior distributions The Bayesian posterior contains useful information far beyond its mode, which can be used to drive methods for sampling optimization (active learning), feature relevance ranking, or hyperparameter estimation, if only this representation of uncertainty can be approximated in a tractable manner. In this paper, we review recent results for variational sparse inference, and show that they share underlying computational primitives. We discuss how sampling optimization can be implemented as sequential Bayesian experimental design. While there has been tremendous recent activity to develop sparse estimation, little attendance has been given to sparse approximate inference In this paper, we argue that many problems in practice, such as compressive sensing for real-world image reconstruction, are served much better by proper uncertainty approximations than by ever more aggressive sparse estimation algorithms. Moreover, since some variational inference methods have been given strong convex optimization characterizations recently, theoretical analysis may become possible, promising new insights Into nonlinear experimental design	Univ Saarland, D-66123 Saarbrucken, Germany	Seeger, MW (reprint author), Univ Saarland, Campus E1-4, D-66123 Saarbrucken, Germany.						Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chaloner K, 1995, STAT SCI, V10, P273, DOI 10.1214/ss/1177009939; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Simoncelli EP, 1999, P SOC PHOTO-OPT INS, V3813, P188, DOI 10.1117/12.366779; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Bekas C, 2008, SIAM J MATRIX ANAL A, V30, P397, DOI 10.1137/060675435; Berger J. O., 1985, STAT DECISION THEORY; BOGACHEV V, 1998, GAUSSIAN MEASURES MA; Boyd S., 2002, CONVEX OPTIMIZATION; CHANG H, 2009, 09014275V1CSITARXIV; Fedorov V. V., 1972, THEORY OPTIMAL EXPT; GARROWAY AN, 1974, J PHYS C SOLID STATE, V7, pL457, DOI 10.1088/0022-3719/7/24/006; Girolami M, 2001, NEURAL COMPUT, V13, P2517, DOI 10.1162/089976601753196003; GOLUB G, 1996, MATH SURVEYS MONOGRA; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; JI S, 2007, INT C MACH LEARN, V24; Kushner HJ, 2000, IEEE T AUTOMAT CONTR, V45, P580, DOI 10.1109/9.847749; LAUTERBUR PC, 1973, NATURE, V242, P190, DOI 10.1038/242190a0; MACKAY D, 1991, NEURAL COMPUT, V4, P589; Malioutov DM, 2008, IEEE T SIGNAL PROCES, V56, P4621, DOI 10.1109/TSP.2008.927482; Malioutov DM, 2006, J MACH LEARN RES, V7, P2031; Minka T., 2001, UNCERTAINTY ARTIFICI, V17; MINKA T, 2004, POWER EP TECH REP MI; NICKISCH H, 2009, INT C MACH LEARN, V26, P761; Opper M, 2005, J MACH LEARN RES, V6, P2177; Opper M, 2000, NEURAL COMPUT, V12, P2655, DOI 10.1162/089976600300014881; Palmer J. A., 2006, ADV NEURAL INFORM PR, V18; PARK T, 2005, BAYESIAN LASSO TECH; Schneider MK, 2001, SIAM J SCI COMPUT, V22, P1840, DOI 10.1137/S1064827599357292; SEEGER M, 2009, ADV NEURAL INFORM PR, V21, P1441; SEEGER M, 2008, 175 MPI BIOL CYB; SEEGER M, 2008, INT C MACH LEARN, V25; Seeger MW, 2008, J MACH LEARN RES, V9, P759; Thomas J. A., 1991, ELEMENTS INFORM THEO; Wainwright Martin J, 2008, Foundations and Trends in Machine Learning, V1, DOI 10.1561/2200000001; WEAVER JB, 1991, MAGNET RESON MED, V21, P288, DOI 10.1002/mrm.1910210213; Wipf D., 2004, ADV NEURAL INFORM PR, V16; Wipf D. P., 2008, ADV NEURAL INFORM PR, V20	40	3	3	1	3	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1742-6588			J PHYS CONF SER			2009	197								012001	10.1088/1742-6596/197/1/012001		13	Engineering, Biomedical; Physics, Applied	Engineering; Physics	BPY38	WOS:000280342700001		
B	Black, M; Tepperman, J; Lee, S; Narayanan, S			ISCA-INST SPEECH COMMUN ASSOC	Black, Matthew; Tepperman, Joseph; Lee, Sungbok; Narayanan, Shrikanth			Predicting Children's Reading Ability using Evaluator-Informed Features	INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5			English	Proceedings Paper	10th INTERSPEECH 2009 Conference	SEP 06-10, 2009	Brighton, ENGLAND	Int Speech Commun Assoc		children's speech; reading assessment; feature selection; pronunciation verification; disfluency detection	REGRESSION	Automatic reading assessment software has the difficult task of trying to model human-based observations, which have both objective and subjective components. In this paper, we mimic the grading patterns of a "ground-truth" (average) evaluator in order to produce models that agree with many people's judgments. We examine one particular reading task, where children read a list of words aloud, and evaluators rate the children's overall reading ability on a scale from one to seven. We first extract various features correlated with the specific cues that evaluators said they used. We then compare various supervised learning methods that mapped the most relevant features to the ground-truth evaluator scores. Our final system predicted these scores with 0.91 correlation, higher than the average inter-evaluator agreement.	[Black, Matthew; Tepperman, Joseph; Lee, Sungbok; Narayanan, Shrikanth] Univ So Calif, Signal Anal & Interpretat Lab, Los Angeles, CA 90089 USA	Black, M (reprint author), Univ So Calif, Signal Anal & Interpretat Lab, Los Angeles, CA 90089 USA.	matthepb@usc.edu; tepperma@usc.edu; sungbokl@usc.edu; shri@sipi.usc.edu	Narayanan, Shrikanth/D-5676-2012				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Cincarek T, 2009, COMPUT SPEECH LANG, V23, P65, DOI 10.1016/j.csl.2008.03.001; BLACK M, 2007, P INT ANTW BELG; BLACK M, 2008, P INT BRISB AUSTR; CUCCHIARINI C, 2000, P NEW SOUNDS; Efron B, ANN STAT, V32, P407; HAGEN A, 2005, P L TC POZN POL; KAZEMZADEH A, 2005, P EUR LISB PORT; TEPPERMAN J, 2007, P INT ANTW BELG; You H., 2005, P EUR LISB PORT; SPARSELAB 2 0 MATLAB	11	0	0	0	3	ISCA-INST SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-61567-692-7				2009							1859	1862				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BOJ53	WOS:000276842801006		
B	Zhang, ZG; Chan, SC; Zhou, Y; Hu, Y			IEEE	Zhang, Z. G.; Chan, S. C.; Zhou, Y.; Hu, Y.			Robust Linear Estimation using M-estimation and Weighted L1 Regularization: Model Selection and Recursive Implementation	ISCAS: 2009 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-5			English	Proceedings Paper	IEEE International Symposium on Circuits and Systems (ISCAS 2009)	MAY 24-27, 2009	Taipei, TAIWAN	IEEE			ORACLE PROPERTIES; LASSO; REGRESSION; SHRINKAGE; RECOVERY; NOISE	This paper studies an M-estimation-based method for linear estimation with weighted L1 regularization and its recursive implementation. Motivated by the sensitivity of conventional least-squares-based L1-regularized linear estimation (Lasso) in impulsive noise environment, an M-estimator-based Lasso (M-Lasso) method is introduced to restrain the outliers and an iterative re-weighted least-squares (IRLS) algorithm is proposed to solve this M-estimation problem. Moreover, instead of using the matrix inversion formula, QR decomposition (QRD) is employed in the M-Lasso for recursive implementation with a lower arithmetic complexity. Simulation results show that the M-estimation-based Lasso performs considerably better than the traditional LS-based Lasso in suppressing the impulsive noise, and its recursive QRD algorithm has a good performance in online processing.	[Zhang, Z. G.; Hu, Y.] Univ Hong Kong, Dept Orthopaed & Traumatol, Hong Kong, Hong Kong, Peoples R China	Zhang, ZG (reprint author), Univ Hong Kong, Dept Orthopaed & Traumatol, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.	zgzhang@eee.hku.hk; scchan@eee.hku.hk; yizhou@eee.hku.hk; yhud@hku.hk					Knight K, 2000, ANN STAT, V28, P1356; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Chan SC, 2004, IEEE T SIGNAL PROCES, V52, P975, DOI 10.1109/TSP.2004.823496; CHAN SC, 2005, P IEEE INT S CIRC SY, V5, P4333; Huber P. J., 1981, ROBUST STAT; Leng CL, 2006, STAT SINICA, V16, P1273; Roth V, 2004, IEEE T NEURAL NETWOR, V15, P16, DOI 10.1109/TNN.2003.809398; Schmidt M., 2007, P 18 EUR C MACH LEAR; Wang HS, 2007, J ROY STAT SOC B, V69, P63; Zhang ZG, 2008, J SIGNAL PROCESS SYS, V52, P263, DOI 10.1007/s11265-007-0156-4	18	4	5	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3827-3				2009							1193	1196				4	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BNZ33	WOS:000275929800306		
J	Usai, MG; Goddard, ME; Hayes, BJ				Usai, Mario Graziano; Goddard, Mike E.; Hayes, Ben J.			Using LASSO to estimate marker effects for Genomic Selection	ITALIAN JOURNAL OF ANIMAL SCIENCE			English	Article; Proceedings Paper	18th Congress of the Scientific-Association-of-Animal-Production (ASPA)	JUN 09-12, 2009	Palermo, ITALY	Sci Assoc Anim Product		Genomic-selection; SNP; LASSO; LARS	REGRESSION	Here we suggest a least absolute shrinkage and selection operator (LASSO) approach to estimate the marker effects for genomic selection using the least angle regression (LABS) algorithm, modified to include a cross validation step to define the best subset of markers to involve in the model. The LASSO-LABS was tested on simulated data which consisted of 5,865 individuals and 6,000 SNPs. The last generations of this dataset were the selection candidates. Using only animals from generations prior to the candidates, three approaches to splitting the population into training and validation sets for cross-validation were evaluated. Furthermore, different sizes of the validation sample were tested. Moreover, BLUP and Bayesian methods were carried out for comparison. The most reliable cross-validation method was the random splitting of overall population with a validation sample size of 50% of the reference population. The accuracy of the GEBVs (correlation with true breeding values) in the candidate population obtained by LASSO-LARS was 0.89 with 156 explanatory SNPs. This value was higher then those obtained by using BLUP and Bayesian methods, which were 0.75 and 0.84 respectively. It was concluded that LASSO-LARS approach is a good alternative way to estimate markers effects for genomic selection.	[Usai, Mario Graziano] AGRIS Sardegna, Settore Genet & Biotecnol DIRPA, I-07040 Olmedo, SS, Italy; [Goddard, Mike E.] Univ Melbourne, Fac Land & Food Resources, Melbourne, Vic 3010, Australia	Usai, MG (reprint author), AGRIS Sardegna, Settore Genet & Biotecnol DIRPA, I-07040 Olmedo, SS, Italy.	graziano.usai@gmail.com					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Efron B, 2004, ANN STAT, V32, P407; Meuwissen THE, 2001, GENETICS, V157, P1819; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; LUND MS, 2009, BMC P IN PRESS	5	0	0	1	4	PAGEPRESS PUBL	PAVIA	MEDITGROUP, VIA G BELLI, 4, PAVIA, 27100, ITALY	1594-4077			ITAL J ANIM SCI	Ital. J. Anim. Sci.		2009	8			2			168	170				3	Agriculture, Dairy & Animal Science; Agriculture, Multidisciplinary; Veterinary Sciences	Agriculture; Veterinary Sciences	590FZ	WOS:000277211600051		
B	Roos, T; Yu, B			IEEE	Roos, Teemu; Yu, Bin			Sparse Markov Source Estimation via Transformed Lasso	ITW: 2009 IEEE INFORMATION THEORY WORKSHOP ON NETWORKING AND INFORMATION THEORY			English	Proceedings Paper	IEEE Information Theory Workshop on Networking and Information Theory	JUN 10-12, 2009	Volos, GREECE	IEEE			REGRESSION; SELECTION; MODELS	We establish a connection between Lasso-type l(1) regularization and learning variable length Markov chains (VLMCs). This is achieved by a parameterization of discrete-valued finite-memory Markov sources in which setting a parameter value equal to zero is equivalent to eliminating a node in the corresponding context tree model. The parameterization involves a Haar wavelet transformation on a set of indicator functions, the output of which is mapped to symbol probabilities via logistic regression. The optimization problem is convex and can be solved efficiently using existing tools. We present preliminary results, comparing the method to an earlier algorithm for learning VLMCs in terms of model selection and prediction performance. We also discuss other transformations which lead to a flexible family of sparse representations of Markov sources.	[Roos, Teemu] Univ Helsinki, Helsinki Inst Informat Technol HIIT, FIN-00014 Helsinki, Finland	Roos, T (reprint author), Univ Helsinki, Helsinki Inst Informat Technol HIIT, FIN-00014 Helsinki, Finland.	teemu.roos@hiit.fi; binyu@stat.berkeley.edu					Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; WILLEMS FMJ, 1995, IEEE T INFORM THEORY, V41, P653, DOI 10.1109/18.382012; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Meier L, 2008, J R STAT SOC B, V70, P53; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; Beer T., 1981, AM J PHYS, V49; Buhlmann P. L., 1998, ANN STAT, V27, P480; Hesterberg T., 2008, STAT SURVEYS, V2, P61, DOI DOI 10.1214/08-SS035; Hsu NJ, 2008, COMPUT STAT DATA AN, V52, P3645, DOI 10.1016/j.csda.2007.12.004; Mallat S., 1998, WAVELET TOUR SIGNAL; McLachlan G., 1992, DISCRIMINANT ANAL ST; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; WEINBERGER MJ, 1995, IEEE T INFORM THEORY, V41, P643, DOI 10.1109/18.382011; Zhao XY, 2005, J COMPUT BIOL, V12, P894, DOI 10.1089/cmb.2005.12.894; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	19	1	1	0	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4535-6				2009							241	245				5	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BMZ11	WOS:000273966100051		
J	Hang, XY; Wu, FX				Hang, Xiyi; Wu, Fang-Xiang			Sparse Representation for Classification of Tumors Using Gene Expression Data	JOURNAL OF BIOMEDICINE AND BIOTECHNOLOGY			English	Article							MOLECULAR CLASSIFICATION; CANCER-DIAGNOSIS; PREDICTION; MICROARRAYS; CARCINOMAS; SIGNATURES; SELECTION	Personalized drug design requires the classification of cancer patients as accurate as possible. With advances in genome sequencing and microarray technology, a large amount of gene expression data has been and will continuously be produced from various cancerous patients. Such cancer-alerted gene expression data allows us to classify tumors at the genomewide level. However, cancer-alerted gene expression datasets typically have much more number of genes (features) than that of samples (patients), which imposes a challenge for classification of tumors. In this paper, a new method is proposed for cancer diagnosis using gene expression data by casting the classification problem as finding sparse representations of test samples with respect to training samples. The sparse representation is computed by the l(1)-regularized least square method. To investigate its performance, the proposed method is applied to six tumor gene expression datasets and compared with various support vector machine (SVM) methods. The experimental results have shown that the performance of the proposed method is comparable with or better than those of SVMs. In addition, the proposed method is more efficient than SVMs as it has no need of model selection. Copyright (C) 2009 X. Hang and F.-X. Wu.	[Hang, Xiyi] Calif State Univ Northridge, Dept Elect & Comp Engn, Northridge, CA 91330 USA; [Wu, Fang-Xiang] Univ Saskatchewan, Dept Mech Engn, Saskatoon, SK S7N 5A9, Canada; [Wu, Fang-Xiang] Univ Saskatchewan, Div Biomed Engn, Saskatoon, SK S7N 5A9, Canada	Wu, FX (reprint author), Calif State Univ Northridge, Dept Elect & Comp Engn, Northridge, CA 91330 USA.	faw341@mail.usask.ca			Natural Science and Engineering Research Council of Canada (NSERC)	The second author would like to thank Natural Science and Engineering Research Council of Canada (NSERC) for supporting this research. Both authors thank the editor and reviewers for their kind comments and suggestions.	Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Nutt CL, 2003, CANCER RES, V63, P1602; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Platt JC, 2000, ADV NEUR IN, V12, P547; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Bertucci F, 2004, ONCOGENE, V23, P1377, DOI 10.1038/sj.onc.1207262; CANDES E, 2006, L 1 MAGIC COLLECTION; Chen DC, 2005, J BIOMED BIOTECHNOL, P132, DOI 10.1155/JBB.2005.132; Crammer K., 2000, P 13 ANN C COMP LEAR, P35; Dyrskjot L, 2003, NAT GENET, V33, P90, DOI 10.1038/ng1061; Gibbons J.D., 2003, NONPARAMETRIC STAT I; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Rifkin R, 2003, SIAM REV, V45, P706, DOI 10.1137/S0036144502411986; Sawiris GP, 2002, CANCER RES, V62, P2923; Segal NH, 2003, J CLIN ONCOL, V21, P1775, DOI 10.1200/JCO.2003.10.108; Su AI, 2001, CANCER RES, V61, P7388; van 't Veer LJ, 2003, BREAST CANCER RES, V5, P57, DOI 10.1186/bcr562; Weston J., 1999, P 7 EUR S ART NEUR N, P219	33	15	15	0	2	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-7243			J BIOMED BIOTECHNOL	J. Biomed. Biotechnol.		2009									403689	10.1155/2009/403689		6	Biotechnology & Applied Microbiology; Medicine, Research & Experimental	Biotechnology & Applied Microbiology; Research & Experimental Medicine	428TJ	WOS:000264872700001		
J	Liu, ZQ; Tan, M; Jiang, F				Liu, Zhenqiu; Tan, Ming; Jiang, Feng			Regularized F-Measure Maximization for Feature Selection and Classification	JOURNAL OF BIOMEDICINE AND BIOTECHNOLOGY			English	Article							LASSO	Receiver Operating Characteristic (ROC) analysis is a common tool for assessing the performance of various classifications. It gained much popularity in medical and other fields including biological markers and, diagnostic test. This is particularly due to the fact that in real-world problems misclassification costs are not known, and thus, ROC curve and related utility functions such as F-measure can be more meaningful performance measures. F-measure combines recall and precision into a global measure. In this paper, we propose a novel method through regularized F-measure maximization. The proposed method assigns different costs to positive and negative samples and does simultaneous feature selection and prediction with L(1) penalty. This method is useful especially when data set is highly unbalanced, or the labels for negative (positive) samples are missing. Our experiments with the benchmark, methylation, and high dimensional microarray data show that the performance of proposed algorithm is better or equivalent compared with the other popular classifiers in limited experiments. Copyright (c) 2009 Zhenqiu Liu et al.	[Liu, Zhenqiu; Tan, Ming] Univ Maryland, Greenebaum Canc Ctr, Div Biostat, Baltimore, MD 21201 USA; [Jiang, Feng] Univ Maryland, Dept Pathol, Baltimore, MD 21201 USA	Liu, ZQ (reprint author), Univ Maryland, Greenebaum Canc Ctr, Div Biostat, 22 S Greene St, Baltimore, MD 21201 USA.	zliu@umm.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; Wang L, 2006, STAT SINICA, V16, P589; BROYDEN CG, 1967, MATH COMPUT, V21, P368, DOI 10.2307/2003239; Cortes C, 2003, ADV NEURAL INFORM PR, V16, P313; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Jansche M, 2005, P C HUM LANG TECHN E, P692, DOI 10.3115/1220575.1220662; KUN D, 2006, P 3 WORKSH ROC AN MA, P17; Lasko TA, 2005, J BIOMED INFORM, V38, P404, DOI 10.1016/j.jbi.2005.02.008; Musicant DR, 2003, P 16 INT FLOR ART IN, P356; Pepe MS, 2007, BIOSTATISTICS, V8, P474, DOI 10.1093/biostatistics/kxl038; Pepe MS, 2005, STAT MED, V24, P3687, DOI 10.1002/sim.2431; Pepe MS, 2003, STAT EVALUATION MED; Rakotomamonjy A., 2004, P EUR C ART INT WORK; Siegmund KD, 2004, BIOINFORMATICS, V20, P1896, DOI 10.1093/bioinformatics/bth176; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Vapnik V.N., 1995, NATURE STAT LEARNING; Virmani AK, 2002, CANCER EPIDEM BIOMAR, V11, P291	19	3	3	0	23	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-7243			J BIOMED BIOTECHNOL	J. Biomed. Biotechnol.		2009									617946	10.1155/2009/617946		8	Biotechnology & Applied Microbiology; Medicine, Research & Experimental	Biotechnology & Applied Microbiology; Research & Experimental Medicine	449FY	WOS:000266317400001		
J	Southworth, H; O'Connell, M				Southworth, H.; O'Connell, M.			DATA MINING AND STATISTICALLY GUIDED CLINICAL REVIEW OF ADVERSE EVENT DATA IN CLINICAL TRIALS	JOURNAL OF BIOPHARMACEUTICAL STATISTICS			English	Article						Adverse events; Boosting; Clinical trials; Data mining; Drug safety; Hierarchical models; Penalized likelihood; Random forests	LOGRANK TEST; REGRESSION; PROPORTIONS; LIKELIHOOD; SURVIVAL	Some approaches to the analysis of adverse event data arising from clinical trials are presented. These include (a) an inside-out data mining method where the adverse events are used as explanatory variables, classifying the treatment allocation, (b) a support method where we fit separate regression models to each adverse event with and without a treatment effect, and (c) a three-level hierarchical Bayesian mixture model for analysis of adverse event counts. The problem of understanding treatment-emergence of the adverse events is formulated as one of data mining rather than hypothesis testing. Our approaches provide an ordering of the adverse events by the strength of evidence of a treatment effect, rather than p values for prespecified hypotheses. The three methods produce intuitive graphical summaries showing the treatment effect on adverse event incidence. These graphs can be readily linked to relevant supportive information such as reports summarizing predicted risks for (demographic) subpopulations of interest and patient-level data such as laboratory information, concomitant medications, and medical history. This results in a statistically guided and thorough review of drug safety in the clinical trial.		Southworth, H (reprint author), Parklands,Alderley Pk, Macclesfield SK10 4TG, Cheshire, England.	Harry.Southworth@astrazeneca.com					Berry SM, 2004, BIOMETRICS, V60, P418, DOI 10.1111/j.0006-341X.2004.00186.x; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Heinze G, 2002, STAT MED, V21, P2409, DOI 10.1002/sim.1047; Efron B, 2004, ANN STAT, V32, P407; Carroll KJ, 2007, PHARM STAT, V6, P99, DOI 10.1002/pst.251; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chen C., 2004, USING RANDOM FOREST; Committee for Proprietary Medicinal Products, 2002, POINTS CONS MULT ISS; Council for International Organizations of Medical Sciences, 2005, MAN SAF INF CLIN TRI; Cox DR, 2006, PRINCIPLES OF STATISTICAL INFERENCE, P1, DOI 10.2277/ 0521685672; CUZICK J, 1982, BIOMETRICS, V38, P1033, DOI 10.2307/2529884; Edwards A. W. F., 1992, LIKELIHOOD; Fidler F, 2004, J SOCIO-ECON, V33, P615, DOI DOI 10.1016/J.S0CEC.2004.09.035; FIRTH D, 1993, BIOMETRIKA, V80, P27, DOI 10.1093/biomet/80.1.27; Fisher R. A., 1973, STAT METHODS SCI INF; GAIL MH, 1985, CONTROL CLIN TRIALS, V6, P112, DOI 10.1016/0197-2456(85)90116-3; Hand D., 2001, PRINCIPLES DATA MINI; Hastie T., 2001, ELEMENTS STAT LEARNI; Heinze G, 2001, BIOMETRICS, V57, P114, DOI 10.1111/j.0006-341X.2001.00114.x; International Conference on Harmonization, 1998, STAT PRINC CLIN TRIA; Jeffreys Harold, 1939, THEORY PROBABILITY; KASS RE, 1995, J AM STAT ASSOC, V90, P188; KRANTZ DH, 1999, J AM STAT ASSOC, V44, P1373; Lee Y, 2006, GEN LINEAR MODELS RA; Lindsey J. K, 1996, PARAMETRIC STAT INFE; Longford NT, 1999, STAT MED, V18, P2311, DOI 10.1002/(SICI)1097-0258(19990915/30)18:17/18<2311::AID-SIM257>3.0.CO;2-T; Nelder JA, 1999, STATISTICIAN, V48, P257; Nester MR, 1996, APPL STAT-J ROY ST C, V45, P401, DOI 10.2307/2986064; OBRIEN PC, 1988, J AM STAT ASSOC, V83, P52, DOI 10.2307/2288918; Ripley B. D., 1996, PATTERN RECOGNITION; Royall R., 1997, STAT EVIDENCE LIKELI	33	4	4	1	4	TAYLOR & FRANCIS INC	PHILADELPHIA	520 CHESTNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	1054-3406	1520-5711		J BIOPHARM STAT	J. Biopharm. Stat.		2009	19	5					803	817		10.1080/10543400903105232		15	Pharmacology & Pharmacy; Statistics & Probability	Pharmacology & Pharmacy; Mathematics	544AJ	WOS:000273623200005	20183445	
J	Moore, KL; van der Laan, MJ				Moore, K. L.; van der Laan, M. J.			INCREASING POWER IN RANDOMIZED TRIALS WITH RIGHT CENSORED OUTCOMES THROUGH COVARIATE ADJUSTMENT	JOURNAL OF BIOPHARMACEUTICAL STATISTICS			English	Article						Clinical trials; Covariate adjustment; Logrank test; Targeted maximum likelihood estimation	CLINICAL-TRIALS; EFFICIENCY; LOGRANK	Targeted maximum likelihood methodology is applied to provide a test that makes use of the covariate data that are commonly collected in randomized trials, and does not require assumptions beyond those of the logrank test when censoring is uninformative. Under informative censoring, the logrank test is biased, whereas the test provided in this article is consistent under consistent estimation of the censoring mechanism or the conditional hazard for survival. Two approaches based on this methodology are provided: (1) a substitution-based approach that targets treatment and time-specific survival from which the logrank parameter is estimated, and (2) directly targeting the logrank parameter.	[Moore, K. L.; van der Laan, M. J.] Univ Calif Berkeley, Div Biostat, Berkeley, CA 94720 USA	Moore, KL (reprint author), Univ Calif Berkeley, Div Biostat, 101 Haviland Hall, Berkeley, CA 94720 USA.	klmoore@stat.berkeley.edu					Akazawa K, 1997, STAT MED, V16, P583, DOI 10.1002/(SICI)1097-0258(19970315)16:5<583::AID-SIM433>3.0.CO;2-Z; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Pocock SJ, 2002, STAT MED, V21, P2917, DOI 10.1002/sim.1296; Cox DR, 1972, J R STAT SOC B, V187, P220; Hastie TJ, 1990, GEN ADDITIVE MODELS; Hernandez AV, 2006, ANN EPIDEMIOL, V16, P41, DOI 10.1016/j.annepidem.2005.09.007; Jiang HH, 2008, STAT MED, V27, P5850, DOI 10.1002/sim.3406; Koch GG, 1998, STAT MED, V17, P1863, DOI 10.1002/(SICI)1097-0258(19980815/30)17:15/16<1863::AID-SIM989>3.3.CO;2-D; Lu XM, 2008, BIOMETRIKA, V95, P679, DOI 10.1093/biomet/asn003; Moore Kelly L., 2009, V31, P455; Moore KL, 2009, STAT MED, V28, P39, DOI 10.1002/sim.3445; Ripley B. D., 1996, PATTERN RECOGNITION; Robins J. M., 1992, AIDS EPIDEMIOLOGY ME, P297; Sinisi S.E., 2004, STAT APPL GENET MOL, V3, P1, DOI DOI 10.2202/1544-; Tangen C M, 1999, J Biopharm Stat, V9, P307, DOI 10.1081/BIP-100101179; Tsiatis AA, 2008, STAT MED, V27, P4658, DOI 10.1002/sim.3113; VAN DER LAAN M. J., 2003, UNIFIED METHODS CENS; van der Laan MJ, 2006, INT J BIOSTAT, V2, DOI DOI 10.2202/1557-4679.1043; vander Laan M. J., 2008, 232 U CAL DIV BIOST; VANDERLAAN M, 2009, 246 U CAL DIV BIOST; VANDERLAAN MJ, 2007, 222 U CAL DIV BIOST; Wood Angela M, 2004, Clin Trials, V1, P368, DOI 10.1191/1740774504cn032oa; Zhang M, 2008, BIOMETRICS, V64, P707, DOI 10.1111/j.1541-0420.2007.00976.x	24	5	5	0	1	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	1054-3406			J BIOPHARM STAT	J. Biopharm. Stat.		2009	19	6					1099	1131		10.1080/10543400903243017		33	Pharmacology & Pharmacy; Statistics & Probability	Pharmacology & Pharmacy; Mathematics	544DW	WOS:000273633700012	20183467	
J	Liu, ZQ; Gartenhaus, RB; Chen, XW; Howell, CD; Tan, M				Liu, Zhenqiu; Gartenhaus, Ronald B.; Chen, Xue-Wen; Howell, Charles D.; Tan, Ming			Survival Prediction and Gene Identification with Penalized Global AUC Maximization	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						biology; cancer genomics; combinatorial optimization; DNA arrays; functional genomics; gene clusters; gene expression; HMM; statistics	EXPRESSION DATA; COX REGRESSION; CELL LYMPHOMA; MODEL; SELECTION; LASSO	Identifying genes (biomarkers) and predicting the clinical outcomes with censored survival times are important for cancer prognosis and pathogenesis. In this article, we propose a novel method with L(1) penalized global AUC summary maximization (L(1)GAUCS). The L(1)GAUCS method is developed for simultaneous gene (feature) selection and survival prediction. L(1) penalty shrinks coefficients and produces some coefficients that are exactly zero, and therefore selects a small subset of genes (features). It is a well-known fact that many genes are highly correlated in gene expression data and the highly correlated genes may function together. We, therefore, define a correlation measure to identify those genes such that their expression level may be low but they are highly correlated with the downstream highly expressed genes selected with L(1)GAUCS. Partial pathways associated with the correlated genes are identified with DAVID (http://david.abcc.ncifcrf.gov/). Experimental results with chemotherapy and gene expression data demonstrate that the proposed procedures can be used for identifying important genes and pathways that are related to time to death due to cancer and for building a parsimonious model for predicting the survival of future patients. Software is available upon request from the first author.	[Liu, Zhenqiu; Tan, Ming] Univ Maryland, Div Biostat, Greenebaum Canc Ctr, Baltimore, MD 21201 USA; [Gartenhaus, Ronald B.; Howell, Charles D.] Univ Maryland, Dept Med, Sch Med, Baltimore, MD 21201 USA; [Gartenhaus, Ronald B.; Howell, Charles D.] Univ Maryland, Greenebaum Canc Ctr, Sch Med, Baltimore, MD 21201 USA; [Chen, Xue-Wen] Univ Kansas, Dept Elect Engn & Comp Sci, Bioinformat & Computat Life Sci Lab, Lawrence, KS 66045 USA	Liu, ZQ (reprint author), Univ Maryland, Div Biostat, Greenebaum Canc Ctr, 685 W Baltimore St,Suite 261, Baltimore, MD 21201 USA.	zliu@umm.edu					Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Rosenwald A, 2003, CANCER CELL, V3, P185, DOI 10.1016/S1535-6108(03)00028-X; Heagerty PJ, 2005, BIOMETRICS, V61, P92, DOI 10.1111/j.0006-341X.2005.030814.x; Hiriart-Urruty J.-B., 2001, FUNDAMENTALS CONVEX; LIU Z, 2007, P 6 INT C MACH LEARN, P624; Ma SG, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-192; Moller GMO, 2007, FEBS LETT, V581, P1329, DOI 10.1016/j.febslet.2007.02.048; Pepe MS, 2005, STAT MED, V24, P3687, DOI 10.1002/sim.2431; Pepe MS, 2003, STAT EVALUATION MED; Segal MR, 2006, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; van Houwelingen HC, 2006, STAT MED, V25, P3201, DOI 10.1002/sim.2353; Wolberg WH, 1999, CLIN CANCER RES, V5, P3542	15	3	3	0	0	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277			J COMPUT BIOL	J. Comput. Biol.		2009	16	12					1661	1670		10.1089/cmb.2008.0188		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	545CG	WOS:000273709400003	19772397	
J	Lin, ZY; Xiang, YB; Zhang, CY				Lin, Zhengyan; Xiang, Yanbiao; Zhang, Caiya			Adaptive Lasso in high-dimensional settings	JOURNAL OF NONPARAMETRIC STATISTICS			English	Article						adaptive Lasso; oracle property; high-dimensional setting	NONCONCAVE PENALIZED LIKELIHOOD; VARIABLE SELECTION; REGRESSION-MODELS; ORACLE PROPERTIES; ESTIMATORS	Huang et al. [J. Huang, S. Ma, and C.-H. Zhang, Adaptive Lasso for sparse high-dimensional regression models, Statist. Sinica 18 (2008), pp. 1603-1618] have studied the asymptotic properties of the adaptive Lasso estimators in sparse, high-dimensional, linear regression models when the number of covariates may increase with the sample size. They proved that the adaptive Lasso has an oracle property in the sense of Fan and Li [J. Fan and R. Li, Variable selection via nonconcave penalized likelihood and its oracle properties, J. Am. Statist. Assoc. 96 (2001), pp. 1348-1360] and Fan and Peng [J. Fan and H. Peng, Nonconcave penalized likelihood with a diverging number of parameters, Ann. Statist. 32 (2004), pp. 928-961] under appropriate conditions. Particularly, they assumed that the errors of the linear regression model have Gaussian tails. In this paper, we relax this condition and assume that the errors have the finite 2kth moment for an integer k > 0. With this assumption, we prove that the adaptive Lasso also has the oracle property under some appropriate conditions. Simulations are carried out to provide understanding of our result.	[Lin, Zhengyan; Xiang, Yanbiao; Zhang, Caiya] Zhejiang Univ, Dept Math, Hangzhou 310027, Peoples R China	Zhang, CY (reprint author), Zhejiang Univ, Dept Math, Hangzhou 310027, Peoples R China.	ccynyb@zju.edu.cn			National Natural Science Foundation of China [10871177]; Specialised Research Fund for the Doctor Program of Higher Education [20060335032]	We wish to thank the referees for their careful reading of the article and for their helpful comments. Research supported by National Natural Science Foundation of China (10871177) and Specialised Research Fund for the Doctor Program of Higher Education (20060335032).	Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Huang J, 2008, ANN STAT, V36, P587, DOI 10.1214/009053607000000875; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; FAN J, 2007, SURE INDEPENDENCE SC; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Huang J, 2008, STAT SINICA, V18, P1603; ZHANG CH, 2006, 2006003 RUTG U DEP S	12	0	0	1	8	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1048-5252			J NONPARAMETR STAT	J. Nonparametr. Stat.		2009	21	6					683	696		10.1080/10485250902984875		14	Statistics & Probability	Mathematics	479NC	WOS:000268665300002		
J	Zhu, ZY; Liu, YF				Zhu, Zhengyuan; Liu, Yufeng			Estimating spatial covariance using penalised likelihood with weighted L-1 penalty	JOURNAL OF NONPARAMETRIC STATISTICS			English	Article						Cholesky decomposition; Gaussian Markov random fields; LASSO; maximum likelihood; nonstationarity	AUTOREGRESSIVE MODELS; VARIABLE SELECTION; ORACLE PROPERTIES; ADAPTIVE LASSO; REGRESSION; MATRICES; GRAPHS	In spatial statistics, the estimation of covariance matrices is of great importance because of its role in spatial prediction and design. In this paper, we propose a penalised likelihood approach with weighted L-1 regularisation to estimate the covariance matrix for spatial Gaussian Markov random field models with unspecified neighbourhood structures. A new algorithm for ordering spatial points is proposed such that the corresponding precision matrix can be estimated more effectively. Furthermore, we develop an efficient algorithm to minimise the penalised likelihood via a novel usage of the regularised solution path algorithm, which does not require the use of iterative algorithms. By exploiting the sparsity structure in the precision matrix, we show that the LASSO type of approach gives improved covariance estimators measured by several criteria. Asymptotic properties of our proposed estimator are derived. Both our simulated examples and an application to the rainfall data set show that the proposed method performs competitively.	[Liu, Yufeng] Univ N Carolina, Carolina Ctr Genome Sci, Dept Stat & Operat Res, Chapel Hill, NC 27599 USA; [Zhu, Zhengyuan] Iowa State Univ, Dept Stat, Ames, IA 50011 USA	Liu, YF (reprint author), Univ N Carolina, Carolina Ctr Genome Sci, Dept Stat & Operat Res, Chapel Hill, NC 27599 USA.	yfliu@email.unc.edu			NSF DMS [0605434, 0606577]; National High Technology Research and Development Program of China [2008AA127201]; CAREER [0747575]	The authors would like to thank the editor, the AE, and three reviewers for their constructive comments and suggestions. Zhu's research is partially supported by NSF DMS grant 0605434 and the National High Technology Research and Development Program of China ( No. 2008AA127201) Liu's research is partially supported by NSF DMS grant 0606577 and CAREER grant 0747575.	Knight K, 2000, ANN STAT, V28, P1356; Smirnov O, 2001, COMPUT STAT DATA AN, V35, P301, DOI 10.1016/S0167-9473(00)00018-9; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Rothman AJ, 2008, ELECTRON J STAT, V2, P494, DOI 10.1214/08-EJS176; ORD K, 1975, J AM STAT ASSOC, V70, P120, DOI 10.2307/2285387; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Banerjee O, 2008, J MACH LEARN RES, V9, P485; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Pourahmadi M, 1999, BIOMETRIKA, V86, P677, DOI 10.1093/biomet/86.3.677; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Banerjee S., 2004, HIERARCHICAL MODELIN; Brewer MJ, 2007, ENVIRONMETRICS, V18, P841, DOI 10.1002/env.844; CHINN PZ, 1982, J GRAPH THEOR, V6, P223, DOI 10.1002/jgt.3190060302; Cressie N., 1993, STAT SPATIAL DATA; Cuthill E, 1969, P 24 NAT C ACM, P157, DOI DOI 10.1145/800195.805928; Duff IS, 1989, DIRECT METHODS SPARS; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; George A., 1981, COMPUTER SOLUTION LA; GROISMAN P, 2000, DATA DOCUMENTATION T; Hastie T., 2001, ELEMENTS STAT LEARNI; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; Lee LF, 2004, ECONOMETRICA, V72, P1899, DOI 10.1111/j.1468-0262.2004.00558.x; Levina E, 2008, ANN APPL STAT, V2, P245, DOI 10.1214/07-AOAS139; Lu H, 2007, ENVIRON ECOL STAT, V14, P433, DOI 10.1007/s10651-007-0029-9; Nott DJ, 2002, BIOMETRIKA, V89, P819, DOI 10.1093/biomet/89.4.819; PAPADIMITRIOU CH, 1976, COMPUTING, V16, P263, DOI 10.1007/BF02280884; Ripley B. D., 1981, SPATIAL STAT; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Rue H, 2002, SCAND J STAT, V29, P31, DOI 10.1111/1467-9469.00058; GREEN PJ, 1978, COMPUT J, V21, P168; WHITTLE P, 1954, BIOMETRIKA, V41, P434; YANNAKAKIS M, 1981, SIAM J ALGEBRA DISCR, V2, P77, DOI 10.1137/0602010; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037	35	7	7	2	2	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1048-5252			J NONPARAMETR STAT	J. Nonparametr. Stat.		2009	21	7					925	942		10.1080/10485250903023632		18	Statistics & Probability	Mathematics	515MG	WOS:000271475100013		
J	Ko, YH; Jun, CH				Ko, Young-Hyun; Jun, Chi-Hyuck			Use of reference distributions when dealing with unknown regression errors	JOURNAL OF STATISTICAL COMPUTATION AND SIMULATION			English	Article						EM algorithm; maximum likelihood; Newton method; robust regression	PARAMETER; LIKELIHOOD; SELECTION	A problem of estimating regression coefficients is considered when the distribution of error terms is unknown but symmetric. We propose the use of reference distributions having various kurtosis values. It is assumed that the true error distribution is one of the reference distributions, but the indicator variable for the true distribution is missing. The generalized expectation-maximization algorithm combined with a line search is developed for estimating regression coefficients. Simulation experiments are carried out to compare the performance of the proposed approach with some existing robust regression methods including least absolute deviation, Lp, Huber M regression and an approximation using normal mixtures under various error distributions. As the error distribution is far from a normal distribution, the proposed method is observed to show better performance than other methods.	[Jun, Chi-Hyuck] POSTECH, Dept Ind & Management Engn, Pohang, South Korea; [Ko, Young-Hyun] Samsung Card Co Ltd, Mkt Decis Sci Team, Seoul, South Korea	Jun, CH (reprint author), POSTECH, Dept Ind & Management Engn, Pohang, South Korea.	chjun@postech.ac.kr	Lee, Jung-Hye/F-6974-2013		MOST (KOSEF)	This work was supported by MOST (KOSEF) through the National Core Research Center for Systems Bio-Dynamics at POSTECH.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Bartolucci F, 2005, COMPUT STAT DATA AN, V48, P821, DOI 10.1016/j.csda.2004.04.005; Birkes D, 1993, ALTERNATIVE METHODS; Brownlee K A, 1965, STAT THEORY METHODOL; Cade BS, 1996, BIOMETRICS, V52, P886, DOI 10.2307/2533050; CELEUX G, 1995, PATTERN RECOGN, V28, P781, DOI 10.1016/0031-3203(94)00125-6; DIELMAN TE, 1986, J FORECASTING, V5, P189, DOI 10.1002/for.3980050305; Huber P. J., 1981, ROBUST STAT; Jamshidian M, 2001, J STAT COMPUT SIM, V71, P11, DOI 10.1080/00949650108812131; Li YY, 1993, SIAM J OPTIMIZ, V3, P609, DOI 10.1137/0803030; Mc Lachlan G.J., 1997, EM ALGORITHM EXTENSI; Mineo AM, 2005, J STAT SOFTW, V12, P1; Smola A., 1998, NCTR98030 U LOND ROY	18	0	0	0	1	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0094-9655			J STAT COMPUT SIM	J. Stat. Comput. Simul.		2009	79	10					1195	1204	PII 907422222	10.1080/00949650802176475		10	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	498QA	WOS:000270155800002		
J	Berk, R; Sherman, L; Barnes, G; Kurtz, E; Ahlman, L				Berk, Richard; Sherman, Lawrence; Barnes, Geoffrey; Kurtz, Ellen; Ahlman, Lindsay			Forecasting murder within a population of probationers and parolees: a high stakes application of statistical learning	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES A-STATISTICS IN SOCIETY			English	Article						Forecasting; Homicide; Parole; Probation; 'Random forests'; Statistical learning	PREDICTION INSTRUMENT; VALIDITY; EFFICIENCY	Forecasts of future dangerousness are often used to inform the sentencing decisions of convicted offenders. For individuals who are sentenced to probation or paroled to community supervision, such forecasts affect the conditions under which they are to be supervised. The statistical criterion for these forecasts is commonly called recidivism, which is defined as a charge or conviction for any new offence, no matter how minor. Only rarely do such forecasts make distinctions on the basis of the seriousness of offences. Yet seriousness may be central to public concerns, and judges are increasingly required by law and sentencing guidelines to make assessments of seriousness. At the very least, information about seriousness is essential for allocating scarce resources for community supervision of convicted offenders. The paper focuses only on murderous conduct by individuals on probation or parole. Using data on a population of over 60000 cases from Philadelphia's Adult Probation and Parole Department, we forecast whether each offender will be charged with a homicide or attempted homicide within 2 years of beginning community supervision. We use a statistical learning approach that makes no assumptions about how predictors are related to the outcome. We also build in the costs of false negative and false positive charges and use half of the data to build the forecasting model, and the other half of the data to evaluate the quality of the forecasts. Forecasts that are based on this approach offer the possibility of concentrating rehabilitation, treatment and surveillance resources on a small subset of convicted offenders who may be in greatest need, and who pose the greatest risk to society.	[Berk, Richard] Univ Penn, Dept Criminol, Philadelphia, PA 19104 USA; [Sherman, Lawrence] Univ Cambridge, Cambridge CB2 1TN, England; [Kurtz, Ellen; Ahlman, Lindsay] First Judicial Dist Penn, Philadelphia, PA USA	Berk, R (reprint author), Univ Penn, Dept Criminol, 483 McNeil Bldg,3718 Locust Walk, Philadelphia, PA 19104 USA.	berk@sas.upenn.edu			University of Pennsylvania; National Science Foundation [SES-0437169]	Richard Berk's work on this paper was funded by seed money from the University of Pennsylvania, and a grant from the National Science Foundation: SES-0437169, 'Ensemble methods for data analysis in the behavioral, social and economic sciences'. Geoffrey Barnes's work and Lawrence Sherman's work were funded by the Jerry Lee Foundation. All of this support is gratefully acknowledged. Special thanks go to the Joint Editor and several reviewers for their very helpful suggestions.	Allen R, 2007, JUSTICE REINVESTMENT; Anderson DC, 1995, CRIME POLITICS HYSTE; Anderson Elijah, 1999, CODE STREET; Lin Y, 2006, J AM STAT ASSOC, V101, P578, DOI 10.1198/016214505000001230; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Berk RA, 2006, SOCIOL METHOD RES, V34, P263, DOI 10.1177/0049124105283119; Sampson RJ, 1997, SCIENCE, V277, P918, DOI 10.1126/science.277.5328.918; Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2; Gottfredson SD, 2006, CRIME DELINQUENCY, V52, P178, DOI 10.1177/0011128705281748; AYRES I, 2007, SUPERCRUNCHERS ANYTH; Berk RA, 2008, SPRINGER SER STAT, P1, DOI 10.1007/978-0-387-77501-2_1; Berk RA, 2005, EVALUATION REV, V29, P358, DOI 10.1177/0193841X05275333; BERK RA, 2008, ANN REV LAW SOCIAL S; Berk RA, 2006, J QUANT CRIMINOL, V22, P131, DOI 10.1007/s-10940-006-9005-z; Blumstein A., 1986, CRIMINAL CAREERS CAR; Borden HG, 1928, J AM INST CRIM LAW C, V19, P328, DOI 10.2307/1134622; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; *BUR JUST STAT, 2006, NAT CRIM VICT SURV C; Burgess E. W., 1928, WORKINGS INDETERMINA, P205; DOERNER WG, 1988, CRIMINOLOGY, V26, P171, DOI 10.1111/j.1745-9125.1988.tb00837.x; Farrington D. P., 1985, PREDICTION CRIMINOLO; FARRINGTON DP, 1987, PREDICTION CLASSIFIC; FIELDING A, 1977, STATISTICIAN, V26, P17, DOI 10.2307/2988216; Goodman LA, 1953, AM J SOCIOL, V58, P510, DOI 10.1086/221204; Goodman LA, 1953, AM J SOCIOL, V58, P503, DOI 10.1086/221203; Goodman LA, 1952, AM SOCIOL REV, V17, P609, DOI 10.2307/2088228; Gottfredson Don M, 1987, PREDICTION CLASSIFIC; GOTTFREDSON SD, 1987, PREDICTION CLASSIFIC; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T., 2008, ELEMENTS STAT LEARNI; Lennert-Cody CE, 2007, J ROY STAT SOC A STA, V170, P671, DOI 10.1111/j.1467-985X.2006.00460.x; MALTZ MD, 1984, RECIDVISM; Meehl P. E., 1954, CLIN VERSUS STAT PRE; Ohlin LE, 1952, AM SOCIOL REV, V17, P268, DOI 10.2307/2088072; Ohlin LE, 1949, AM J SOCIOL, V54, P441, DOI 10.1086/220398; Ostrom BJ, 2002, OFFENDER RISK ASSESS; Reiss AJ, 1951, AM J SOCIOL, V56, P552; ROSSI PH, 1974, AM SOCIOL REV, V39, P224, DOI 10.2307/2094234; Schmidt P., 1988, PREDICTING RECIDIVIS; Sherman L. W., 2007, J EXPT CRIMINOLOGY, V3, P299, DOI 10.1007/s11292-007-9044-y; SHERMAN LW, 2007, CRIMINOL PUBL POLY, V6, P843; Skogan W. G., 2004, FAIRNESS EFFECTIVENE; Strobl C., 2007, BMC BIOINFORMATICS, V8, P1; *VIRG CRIM SENT CO, 2007, 2007 ANN REP VIRG CR; Zhang H, 1999, RECURSIVE PARTITIONI	47	26	26	2	11	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0964-1998	1467-985X		J R STAT SOC A STAT	J. R. Stat. Soc. Ser. A-Stat. Soc.		2009	172		1				191	211		10.1111/j.1467-985X.2008.00556.x		21	Social Sciences, Mathematical Methods; Statistics & Probability	Mathematical Methods In Social Sciences; Mathematics	387OX	WOS:000261962600011		
J	James, GM; Radchenko, P; Lv, JC				James, Gareth M.; Radchenko, Peter; Lv, Jinchi			DASSO: connections between the Dantzig selector and lasso	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Dantzig selector; DASSO; Lasso; Least angle regression	ROBUST UNCERTAINTY PRINCIPLES; STATISTICAL ESTIMATION; VARIABLE SELECTION; ORACLE PROPERTIES; MODEL SELECTION; REGRESSION; LARGER; REPRESENTATIONS; EQUATIONS; RECOVERY	We propose a new algorithm, DASSO, for fitting the entire coefficient path of the Dantzig selector with a similar computational cost to the least angle regression algorithm that is used to compute the lasso. DASSO efficiently constructs a piecewise linear path through a sequential simplex-like algorithm, which is remarkably similar to the least angle regression algorithm. Comparison of the two algorithms sheds new light on the question of how the lasso and Dantzig selector are related. In addition, we provide theoretical conditions on the design matrix X under which the lasso and Dantzig selector coefficient estimates will be identical for certain tuning parameters. As a consequence, in many instances, we can extend the powerful non-asymptotic bounds that have been developed for the Dantzig selector to the lasso. Finally, through empirical studies of simulated and real world data sets we show that in practice, when the bounds hold for the Dantzig selector, they almost always also hold for the lasso.	[James, Gareth M.] Univ So Calif, Informat & Operat Management Dept, Los Angeles, CA 90089 USA	James, GM (reprint author), Univ So Calif, Informat & Operat Management Dept, 401R Bridge Hall, Los Angeles, CA 90089 USA.	gareth@marshall.usc.edu	Lv, Jinchi/D-2295-2012; Radchenko, Peter/E-2601-2015		National Science Foundation [DMS-0705312, DMS-0806030]	We thank the Associate Editor and referees for many helpful suggestions that improved the paper. The IQ data set was kindly supplied by Dr Adrian Raine. This work was partially supported by National Science Foundation grant DMS-0705312. Lv's research was partially supported by National Science Foundation grant DMS-0806030 and the 2008 Zumberge Individual Award from the James H. Zumberge Faculty Research and Innovation Fund at the University of Southern California.	BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Shen XT, 2002, J AM STAT ASSOC, V97, P210, DOI 10.1198/016214502753479356; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Candes E, 2007, ANN STAT, V35, P2392, DOI 10.1214/009053607000000532; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; BARANIUK R, 2008, CONSTRUCT A IN PRESS; Bazaraa MS, 1990, LINEAR PROGRAMMING N; BICKEL P, 2008, ANN STAT IN PRESS; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9446, DOI 10.1073/pnas.0502269102; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Efron B, 2007, ANN STAT, V35, P2358, DOI 10.1214/009053607000000433; JAMES GM, 2008, GEN DANTZIG SELECTOR; Plumbley MD, 2007, IEEE T INFORM THEORY, V53, P3188, DOI 10.1109/TIT.2007.903129; Rocha G, 2007, ANN STAT, V35, P2372; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; ZHANG CH, 2007, MODEL SELECTIO UNPUB	28	52	57	1	5	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2009	71						127	142		10.1111/j.1467-9868.2008.00668.x		16	Statistics & Probability	Mathematics	391LS	WOS:000262235400007		
J	Witten, DM; Tibshirani, R				Witten, Daniela M.; Tibshirani, Robert			Covariance-regularized regression and classification for high dimensional problems	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Classification; Covariance regularization; n < p; Regression; Variable selection	B-CELL LYMPHOMA; MAXIMUM-LIKELIHOOD-ESTIMATION; GENE-EXPRESSION; DISCRIMINANT-ANALYSIS; SHRUNKEN CENTROIDS; VARIABLE SELECTION; MODEL SELECTION; MICROARRAYS; LASSO; PREDICTION	We propose covariance-regularized regression, a family of methods for prediction in high dimensional settings that uses a shrunken estimate of the inverse covariance matrix of the features to achieve superior prediction. An estimate of the inverse covariance matrix is obtained by maximizing the log-likelihood of the data, under a multivariate normal model, subject to a penalty; it is then used to estimate coefficients for the regression of the response onto the features. We show that ridge regression, the lasso and the elastic net are special cases of covariance-regularized regression, and we demonstrate that certain previously unexplored forms of covariance-regularized regression can outperform existing methods in a range of situations. The covariance-regularized regression framework is extended to generalized linear models and linear discriminant analysis, and is used to analyse gene expression data sets with multiple class and survival outcomes.	[Witten, Daniela M.] Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Witten, DM (reprint author), Stanford Univ, Dept Stat, 390 Serra Mall, Stanford, CA 94305 USA.	dwitten@stanford.edu			National Defense Science and Engineering Graduate Fellowship; National Science Foundation [DMS-9971405]; National Institutes of Health [N01-HV-28183]	We thank the Joint Editor and two reviewers for helpful comments. We thank Trevor Hastie for showing us the solution to the penalized log-likelihood with an L<INF>2</INF>-penalty. We thank both Trevor Hastie and Jerome Friedman for valuable discussions and for providing the code for the L<INF>2</INF>-penalized multiclass logistic regression and the elastic net. Daniela Witten was supported by a National Defense Science and Engineering Graduate Fellowship. Robert Tibshirani was partially supported by National Science Foundation grant DMS-9971405 and National Institutes of Health contract N01-HV-28183.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Rothman AJ, 2008, ELECTRON J STAT, V2, P494, DOI 10.1214/08-EJS176; Monti S, 2005, BLOOD, V105, P1851, DOI 10.1182/blood-2004.07.2947; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Banerjee O, 2008, J MACH LEARN RES, V9, P485; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; BICKEL P, 2008, ANN STAT IN PRESS; DEY DK, 1985, ANN STAT, V13, P1581, DOI 10.1214/aos/1176349756; FRIEDMAN J, 2008, REGULARIZAT IN PRESS; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; GREEN PJ, 1984, J ROY STAT SOC B MET, V46, P149; HAFF LR, 1979, ANN STAT, V7, P1264, DOI 10.1214/aos/1176344845; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hummel M, 2006, NEW ENGL J MED, V354, P2419, DOI 10.1056/NEJMoa055351; Liang F, 2007, STAT SCI, V22, P189, DOI 10.1214/088342307000000032; Mardia KV, 1979, MULTIVARIATE ANAL; McLachlan G., 1992, DISCRIMINANT ANAL ST; ONEILL TJ, 1978, J AM STAT ASSOC, V73, P821, DOI 10.2307/2286287; Prentice RL, 1980, STAT ANAL FAILURE TI; Stein C., 1961, P 4 BERK S MATH STAT, V1, P361; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	35	54	54	2	21	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1369-7412	1467-9868		J R STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2009	71		3				615	636		10.1111/j.1467-9868.2009.00699.x		22	Statistics & Probability	Mathematics	453HT	WOS:000266602200003		
J	Audrino, F; Buhlmann, P				Audrino, Francesco; Buehlmann, Peter			Splines for financial volatility	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Boosting; B-splines; Conditional variance; Financial time series; Generalized auto-regressive conditional heteroscedasticity model; Volatility	AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTICITY; ADAPTIVE ESTIMATION; MODEL SELECTION; ARCH MODELS; GARCH(1,1); ESTIMATORS; REGRESSION; BOUNDS; LASSO	We propose a flexible generalized auto-regressive conditional heteroscedasticity type of model for the prediction of volatility in financial time series. The approach relies on the idea of using multivariate B-splines of lagged observations and volatilities. Estimation of such a B-spline basis expansion is constructed within the likelihood framework for non-Gaussian observations. As the dimension of the B-spline basis is large, i.e. many parameters, we use regularized and sparse model fitting with a boosting algorithm. Our method is computationally attractive and feasible for large dimensions. We demonstrate its strong predictive potential for financial volatility on simulated and real data, and also in comparison with other approaches, and we present some supporting asymptotic arguments.	[Audrino, Francesco] Univ St Gallen, Fachbereich Math & Stat, CH-9000 St Gallen, Switzerland	Audrino, F (reprint author), Univ St Gallen, Fachbereich Math & Stat, Bodanstr 6, CH-9000 St Gallen, Switzerland.	francesco.audrino@unisg.ch	Buhlmann, Peter/A-2107-2013				Andersen T. G., 2005, HDB FINANCIAL ECONOM; ANDREWS DWK, 1994, INT STAT REV, V62, P119, DOI 10.2307/1403549; ANGO NP, 2004, ECONOMET THEOR, V20, P995; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Hardle W, 1997, J ECONOMETRICS, V81, P223, DOI 10.1016/S0304-4076(97)00044-4; Laurent B, 2000, ANN STAT, V28, P1302; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Carrasco M, 2002, ECONOMET THEOR, V18, P17, DOI 10.1017/S0266466602181023; Zhang L, 2005, J AM STAT ASSOC, V100, P1394, DOI 10.1198/016214505000000169; Birge L, 1998, BERNOULLI, V4, P329, DOI 10.2307/3318720; DIEBOLD FX, 1995, J BUS ECON STAT, V13, P253, DOI 10.2307/1392185; Efron B, 2004, ANN STAT, V32, P407; Audrino F, 2001, J R STAT SOC B, V63, P727, DOI 10.1111/1467-9868.00309; Audrino F, 2005, J TIME SER ANAL, V26, P251, DOI 10.1111/j.1467-9892.2005.00400.x; Audrino F., 2003, J COMPUT FINANC, V6, P65; Baillie RT, 1996, J ECONOMETRICS, V74, P3, DOI 10.1016/S0304-4076(95)01749-6; Barron A, 1999, PROBAB THEORY REL, V113, P301, DOI 10.1007/s004400050210; Berkowitz J, 2002, J FINANC, V57, P1093, DOI 10.1111/1540-6261.00455; Bickel PJ, 2006, J MACH LEARN RES, V7, P705; Birge L., 1997, FESTSCHRIFT LUCIEN C, P55, DOI 10.1007/978-1-4612-1880-7_4; BOLLERSLEV T, 1986, J ECONOMETRICS, V31, P307, DOI 10.1016/0304-4076(86)90063-1; Buhlmann P, 2006, ANN STAT, V34, P559, DOI 10.1214/009053606000000092; Buhlmann P, 2002, COMPUT STAT DATA AN, V40, P665, DOI 10.1016/S0167-9473(02)00080-4; Comte F, 2002, STOCH PROC APPL, V97, P111, DOI 10.1016/S0304-4149(01)00128-4; CURCI G, 2003, 44 NAT CTR COMP RES; de Boor C., 2001, PRACTICAL GUIDE SPLI; de Jong RM, 1998, J ECONOMETRICS, V86, P243, DOI 10.1016/S0304-4076(97)00116-4; Engle R, 2002, J BUS ECON STAT, V20, P339, DOI 10.1198/073500102288618487; Engle Robert F., 2005, SPLINE GARCH MODEL U; Francq C, 2006, ECONOMET THEOR, V22, P815, DOI 10.1017/S0266466606060373; GOURIEROUX C, 1992, J ECONOMETRICS, V52, P159, DOI 10.1016/0304-4076(92)90069-4; Hafner CM, 1998, J STAT PLAN INFER, V68, P247, DOI 10.1016/S0378-3758(97)00144-4; Hansen PR, 2005, J APPL ECONOM, V20, P873, DOI 10.1002/jae.800; Hansen PR, 2003, OXFORD B ECON STAT, V65, P839, DOI 10.1046/j.0305-9049.2003.00086.x; Hansen PR, 2006, J ECONOMETRICS, V131, P97, DOI 10.1016/j.jeconom.2005.10.005; Lin Y, 2000, ANN STAT, V28, P734, DOI 10.1214/aos/1015951996; PATTON A, 2006, VOLATILITY FORECAST; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Yang L., 1999, J TIME SER ANAL, V20, P579, DOI DOI 10.1111/1467-9892.00159; Zhao P, 2007, J MACH LEARN RES, V8, P2701	40	5	5	2	4	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2009	71						655	670		10.1111/j.1467-9868.2009.00696.x		16	Statistics & Probability	Mathematics	453HT	WOS:000266602200005		
J	Wang, HS; Li, B; Leng, CL				Wang, Hansheng; Li, Bo; Leng, Chenlei			Shrinkage tuning parameter selection with a diverging number of parameters	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Bayesian information criterion; Diverging number of parameters; Lasso; Smoothly clipped absolute deviation	NONCONCAVE PENALIZED LIKELIHOOD; LINEAR-MODEL SELECTION; ORACLE PROPERTIES; ADAPTIVE LASSO; BRIDGE	Contemporary statistical research frequently deals with problems involving a diverging number of parameters. For those problems, various shrinkage methods (e.g. the lasso and smoothly clipped absolute deviation) are found to be particularly useful for variable selection. Nevertheless, the desirable performances of those shrinkage methods heavily hinge on an appropriate selection of the tuning parameters. With a fixed predictor dimension, Wang and co-worker have demonstrated that the tuning parameters selected by a Bayesian information criterion type criterion can identify the true model consistently. In this work, similar results are further extended to the situation with a diverging number of parameters for both unpenalized and penalized estimators. Consequently, our theoretical results further enlarge not only the scope of applicabilityation criterion type criteria but also that of those shrinkage estimation methods.	[Wang, Hansheng] Peking Univ, Guanghua Sch Management, Beijing 100871, Peoples R China; [Li, Bo] Tsinghua Univ, Beijing 100084, Peoples R China; [Leng, Chenlei] Natl Univ Singapore, Singapore 117548, Singapore	Wang, HS (reprint author), Peking Univ, Guanghua Sch Management, Beijing 100871, Peoples R China.	hansheng@gsm.pku.edu.cn			National Natural Science Foundation of China [10771006, 10801086, 70621061, 70831003]; National University of Singapore; National University of Singapore Risk Management Institute	The authors are very grateful to the Joint Editor, the Associate Editor and two referees for their careful reading and insightful comments, which led to a substantially improved manuscript. Hansheng Wang is supported in part by National Natural Science Foundation of China grant 10771006. Bo Li is supported in part by National Natural Science Foundation of China grants 10801086, 70621061 and 70831003. Chenlei Leng is supported by National University of Singapore academic research grants and a grant from the National University of Singapore Risk Management Institute.	Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Huang J, 2008, ANN STAT, V36, P587, DOI 10.1214/009053607000000875; Wang H, 2007, BIOMETRIKA, V94, P553, DOI 10.1093/biomet/asm053; Zou H, 2008, ANN STAT, V36, P1509, DOI 10.1214/009053607000000802; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; BAI Z. D., 2006, SPECTRAL ANAL LARGE; Fan J., 2006, P INT C MATH, P595; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; HUANG J, 2007, 374 U IOW DEP STAT A; Shao J, 1997, STAT SINICA, V7, P221; Shi PD, 2002, J ROY STAT SOC B, V64, P237, DOI 10.1111/1467-9868.00335; Wang H., 2007, J AM STAT ASSOC, V101, P1418; Wang HS, 2007, J ROY STAT SOC B, V69, P63; XIE H, 2008, ANN STAT IN PRESS; Yang YH, 2005, BIOMETRIKA, V92, P937, DOI 10.1093/biomet/92.4.937; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037; Zhao M, 2006, STAT PROBABIL LETT, V76, P520, DOI 10.1016/j.spl.2005.08.020	20	72	75	2	14	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1369-7412			J R STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2009	71		3				671	683		10.1111/j.1467-9868.2008.00693.x		13	Statistics & Probability	Mathematics	453HT	WOS:000266602200006		
J	Hall, P; Titterington, DM; Xue, JH				Hall, Peter; Titterington, D. M.; Xue, Jing-Hao			Tilting methods for assessing the influence of components in a classifier	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Biased bootstrap; Bootstrap; Centroid-based classifier; Cross-validation; Distance- based classifiers; Empirical likelihood; Genomic data; High dimensional data; Lasso; Variable selection	DIFFERENTIAL GENE-EXPRESSION; CONSTRAINED BALANCE RANDOMIZATION; MICROARRAY DATA; CONFIDENCE-REGIONS; CLINICAL-TRIALS; T-TEST; LIKELIHOOD; CENTROIDS; MODELS; CANCER	Many contemporary classifiers are constructed to provide good performance for very high dimensional data. However, an issue that is at least as important as good classification is determining which of the many potential variables provide key information for good decisions. Responding to this issue can help us to determine which aspects of the datagenerating mechanism (e.g. which genes in a genomic study) are of greatest importance in terms of distinguishing between populations. We introduce tilting methods for addressing this problem. We apply weights to the components of data vectors, rather than to the data vectors themselves (as is commonly the case in related work). In addition we tilt in a way that is governed by L(2)-distance between weight vectors, rather than by the more commonly used Kullback-Leibler distance. It is shown that this approach, together with the added constraint that the weights should be non-negative, produces an algorithm which eliminates vector components that have little influence on the classification decision. In particular, use of the L(2)-distance in this problem produces properties that are reminiscent of those that arise when L(1)-penalties are employed to eliminate explanatory variables in very high dimensional prediction problems, e.g. those involving the lasso. We introduce techniques that can be implemented very rapidly, and we show how to use bootstrap methods to assess the accuracy of our variable ranking and variable elimination procedures.	[Xue, Jing-Hao] UCL, Dept Stat Sci, London WC1E 6BT, England; [Hall, Peter; Xue, Jing-Hao] Univ Melbourne, Melbourne, Vic 3010, Australia; [Hall, Peter; Titterington, D. M.; Xue, Jing-Hao] Univ Glasgow, Glasgow G12 8QQ, Lanark, Scotland	Xue, JH (reprint author), UCL, Dept Stat Sci, Mortimer St, London WC1E 6BT, England.	jinghao@stats.ucl.ac.uk			Carnegie Centenary Professorship; Hutchison Whampoa-Engineering and Physical Sciences Research Council Dorothy Hodgkin Postgraduate Award	This work was partly supported by the award of a Carnegie Centenary Professorship to PH and a Hutchison Whampoa-Engineering and Physical Sciences Research Council Dorothy Hodgkin Postgraduate Award to J-HX. The work benefited from the participation of DMT and J-HX in the research programme on 'Statistical theory and methods for complex, high-dimensional data' at the Isaac Newton Institute for Mathematical Sciences in Cambridge. The authors are very grateful for the extensive and helpful comments from the referees.	Fan JQ, 2008, ANN STAT, V36, P2605, DOI 10.1214/07-AOS504; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Cui XG, 2005, BIOSTATISTICS, V6, P59, DOI 10.1093/biostatistics/kxh018; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Wright GW, 2003, BIOINFORMATICS, V19, P2448, DOI 10.1093/bioinformatics/btg345; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Lonnstedt I, 2002, STAT SINICA, V12, P31; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Dabney AR, 2005, BIOINFORMATICS, V21, P4148, DOI 10.1093/bioinformatics/bti681; Iizuka N, 2003, LANCET, V361, P923, DOI 10.1016/S0140-6736(03)12775-4; Ideker T, 2000, J COMPUT BIOL, V7, P805, DOI 10.1089/10665270050514945; Baldi P, 2001, BIOINFORMATICS, V17, P509, DOI 10.1093/bioinformatics/17.6.509; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Fan JQ, 2008, J ROY STAT SOC B, V70, P849, DOI 10.1111/j.1467-9868.2008.00674.x; OWEN A, 1990, ANN STAT, V18, P90, DOI 10.1214/aos/1176347494; Wipf DP, 2007, IEEE T SIGNAL PROCES, V55, P3704, DOI 10.1109/TSP.2007.894265; Efron B, 2001, J AM STAT ASSOC, V96, P1151, DOI 10.1198/016214501753382129; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Newton MA, 2001, J COMPUT BIOL, V8, P37, DOI 10.1089/106652701300099074; Gordon GJ, 2002, CANCER RES, V62, P4963; BICKEL P, 2009, ANN STAT IN PRESS; Bishop C., 2006, PATTERN RECOGNITION; Buhlmann P, 2006, ANN STAT, V34, P559, DOI 10.1214/009053606000000092; CAWLEY GC, 2007, ADV NEUR INFORM PROC, P19; Chan NH, 2007, J ECONOMETRICS, V137, P556, DOI 10.1016/j.jeconom.2005.08.008; Critchley F, 2004, BIOMETRIKA, V91, P125, DOI 10.1093/biomet/91.1.125; Critchley F, 2001, J ROY STAT SOC B, V63, P307, DOI 10.1111/1467-9868.00287; CUI X, 2003, GENOME BIOL, V4, pR210; DABNEY AR, 2005, 267 U WASH DEP BIOST; DABNEY AR, 2007, PLOS ONE, V2; Efron B., 1982, JACKKNIFE BOOTSTRAP; Fox RJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-126; Ghosh AK, 2004, STAT SINICA, V14, P457; Hall P, 1999, J ROY STAT SOC B, V61, P661, DOI 10.1111/1467-9868.00199; Hall P, 2003, J ROY STAT SOC B, V65, P425, DOI 10.1111/1467-9868.00394; HALL P, 2009, MEDIAN BASED C UNPUB; HALL P, 2009, J COMPUTNL IN PRESS; Hazelton ML, 2007, COMPUT STAT DATA AN, V51, P3057, DOI 10.1016/j.csda.2006.02.002; KLOTZ JH, 1978, BIOMETRICS, V34, P283, DOI 10.2307/2530018; Lee SMS, 2003, BIOMETRIKA, V90, P393, DOI 10.1093/biomet/90.2.393; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Neal R. M., 1996, BAYESIAN LEARNING NE; Opgen-rhein R, 2007, STAT APPL GENET MOL, V6; OWEN AB, 1988, BIOMETRIKA, V75, P237, DOI 10.2307/2336172; Peng L, 2006, ANN STAT, V34, P1964, DOI 10.1214/009053606000000416; READ TRC, 1988, GOODNESS OF FIT STAT; Rubin H., 1965, SANKHYA A, V27, P325; Seeger MW, 2008, J MACH LEARN RES, V9, P759; Smyth G. K., 2004, STAT APPL GENET MOL, V3, DOI [10.2202/1544-6115.1027, DOI 10.2202/1544-6115.1027]; TITTERINGTON DM, 1983, BIOMETRICS, V39, P1083, DOI 10.2307/2531342; VANDERVAART AW, 2006, DECSNS, V24, P351; Wang SJ, 2007, BIOINFORMATICS, V23, P972, DOI 10.1093/bioinformatics/btm046; Wu BL, 2005, BIOINFORMATICS, V21, P1565, DOI 10.1093/bioinformatics/bti217	59	13	13	3	5	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2009	71						783	803				21	Statistics & Probability	Mathematics	480EA	WOS:000268713700002		
J	Ravikumar, P; Lafferty, J; Liu, H; Wasserman, L				Ravikumar, Pradeep; Lafferty, John; Liu, Han; Wasserman, Larry			Sparse additive models	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Additive models; Lasso; Non-parametric regression; Sparsity	NONPARAMETRIC REGRESSION; VARIABLE SELECTION; ORACLE PROPERTIES; LASSO	We present a new class of methods for high dimensional non-parametric regression and classification called sparse additive models. Our methods combine ideas from sparse linear modelling and additive non-parametric regression. We derive an algorithm for fitting the models that is practical and effective even when the number of covariates is larger than the sample size. Sparse additive models are essentially a functional version of the grouped lasso of Yuan and Lin. They are also closely related to the COSSO model of Lin and Zhang but decouple smoothing and sparsity, enabling the use of arbitrary non-parametric smoothers. We give an analysis of the theoretical properties of sparse additive models and present empirical results on synthetic and real data, showing that they can be effective in fitting sparse non-parametric models in high dimensional data.	[Wasserman, Larry] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA; [Ravikumar, Pradeep] Univ Calif Berkeley, Berkeley, CA 94720 USA	Wasserman, L (reprint author), Carnegie Mellon Univ, Dept Stat, 232 Baker Hall, Pittsburgh, PA 15213 USA.	larry@stat.cmu.edu			National Science Foundation [CCF-0625879]; Siebel scholarship	This research was supported in part by National Science Foundation grant CCF-0625879 and a Siebel scholarship to PR.	Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Lin Y, 2006, ANN STAT, V34, P2272, DOI 10.1214/009053606000000722; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; BUJA A, 1989, ANN STAT, V17, P453, DOI 10.1214/aos/1176347115; Bunea F, 2007, ELECTRON J STAT, V1, P169, DOI 10.1214/07-EJS008; DAUBECHIES I, 2007, ARXIV07064297 PRINC; Fan JQ, 2005, J AM STAT ASSOC, V100, P890, DOI 10.1198/016214504000001439; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; Hastie T. J., 1999, GEN ADDITIVE MODELS; Juditsky A, 2000, ANN STAT, V28, P681; KOLTCHINSKII V., 2008, P 21 A C LEARN THEOR, P229; LEDOUX M., 1991, PROBABILITY BANACH S; MEIER L, 2008, HIGH DIMENSIONAL ADD; MEINSHAUSEN N, 2006, 720 U CAL DEP STAT; Ravikumar P., 2008, ADV NEURAL INFORM PR, V20, P1201; van der Vaart A. W., 1998, ASYMPTOTIC STAT; Wainwright M. J., 2006, 709 U CAL DEP STAT; Wainwright M. J., 2007, ADV NEURAL INFORM PR, V19, P1465; WASSERMAN L, 2007, ARXIV07041139 CARN M; YUAN M, 2007, P ART INT STAT	27	69	69	5	11	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2009	71						1009	1030				22	Statistics & Probability	Mathematics	507DU	WOS:000270832200006		
J	Mineault, PJ; Barthelme, S; Pack, CC				Mineault, Patrick J.; Barthelme, Simon; Pack, Christopher C.			Improved classification images with sparse priors in a smooth basis	JOURNAL OF VISION			English	Article						classification image; detection/discrimination; linear template; generalized linear model; sparse prior	GENERALIZED LINEAR-MODELS; REVERSE-CORRELATION; RECEPTIVE-FIELDS; BAYESIAN-INFERENCE; NATURAL IMAGES; SELECTION; NONLINEARITIES; FEATURES; DESIGN; CHOICE	Classification images provide compelling insight into the strategies used by observers in psychophysical tasks. However, because of the high-dimensional nature of classification images and the limited quantity of trials that can practically be performed, classification images are often too noisy to be useful unless denoising strategies are adopted. Here we propose a method of estimating classification images by the use of sparse priors in smooth bases and generalized linear models (GLMs). Sparse priors in a smooth basis are used to impose assumptions about the simplicity of observers' internal templates, and they naturally generalize commonly used methods such as smoothing and thresholding. The use of GLMs in this context provides a number of advantages over classic estimation techniques, including the possibility of using stimuli with non-Gaussian statistics, such as natural textures. Using simulations, we show that our method recovers classification images that are typically less noisy and more accurate for a smaller number of trials than previously published techniques. Finally, we have verified the efficiency and accuracy of our approach with psychophysical data from a human observer.	[Mineault, Patrick J.; Pack, Christopher C.] McGill Univ, Montreal Neurol Inst, Montreal, PQ, Canada; [Barthelme, Simon] Univ Paris 05, Lab Psychol Percept, Paris, France	Mineault, PJ (reprint author), 3801 Univ St 896, Montreal, PQ H3A 2B4, Canada.	patrick.mineault@mail.mcgill.ca			CIHR [MOP-79352]; Le ministre du Developpement economique, de l'Innovation et de l'Exportation du Quebec	We would like to thank two anonymous reviewers for their insightful comments. Simon Barthelme wishes to thank Pascal Mamassian for his support. This work was supported by grants from the CIHR (MOP-79352) and Le ministre du Developpement economique, de l'Innovation et de l'Exportation du Quebec.	Abbey CK, 2002, J VISION, V2, P66, DOI 10.1167/2.1.5; Abbey C. K., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4324, DOI 10.1117/12.431179; Abbey CK, 2002, PROC SPIE, V4686, P25, DOI 10.1117/12.462683; Ahrens MB, 2008, J NEUROSCI, V28, P1929, DOI 10.1523/JNEUROSCI.3377-07.2008; Ahrens MB, 2008, NETWORK-COMP NEURAL, V19, P35, DOI 10.1080/09548980701813936; Ahumada Jr A., 1996, PERCEPTION, V26, P18; David SV, 2007, NETWORK-COMP NEURAL, V18, P191, DOI 10.1080/09548980701609235; Buhlmann P, 2007, STAT SCI, V22, P477, DOI 10.1214/07-STS242; Neri P, 2006, VISION RES, V46, P2465, DOI 10.1016/j.visres.2006.02.002; Ahumada AJ, 2002, J VISION, V2, P121, DOI 10.1167/2.1.8; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303; GEISSER S, 1979, J AM STAT ASSOC, V74, P153, DOI 10.2307/2286745; Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194; Sekuler AB, 2004, CURR BIOL, V14, P391, DOI 10.1016/j.cub.2004.02.028; Pillow JW, 2008, NATURE, V454, P995, DOI 10.1038/nature07140; Tadin D, 2006, J NEUROSCI, V26, P2614, DOI 10.1523/JNEUROSCI.4253-05.2006; GEISSER S, 1975, J AM STAT ASSOC, V70, P320, DOI 10.2307/2285815; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; AHUMADA A, 1971, J ACOUST SOC AM, V49, P1751, DOI 10.1121/1.1912577; Bishop C., 2006, PATTERN RECOGNITION; BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851; Chauvin A, 2005, J VISION, V5, P659, DOI 10.1167/5.9.1; GELFAND AE, 1994, J ROY STAT SOC B MET, V56, P501; Gelman A., 2003, BAYESIAN DATA ANAL; Gold JM, 2000, CURR BIOL, V10, P663, DOI 10.1016/S0960-9822(00)00523-6; Hale E. T., 2007, TR0707 RIC U; Hastie T., 2007, STAT SCI, V22, P513, DOI DOI 10.1214/07-STS242A; Jeffreys H., 1961, THEORY PROBABILITY; KNOBLAUCH K, 2008, J VISION, V8, pA344, DOI DOI 10.1167/8.6.344; Knoblauch K, 2008, J VISION, V8, DOI 10.1167/8.16.10; Lee TW, 2002, VISION RES, V42, P2095, DOI 10.1016/S0042-6989(02)00122-0; Levi DM, 2002, J VISION, V2, P46, DOI 10.1167/2.1.4; Mangini MC, 2004, COGNITIVE SCI, V28, P209, DOI 10.1016/j.cogsci.2003.11.004; MINEAULT PJ, 2008, J VISION, V8, pA271, DOI DOI 10.1167/8.6.271; Murray RF, 2002, J VISION, V2, P79, DOI 10.1167/2.1.6; Neri P, 1999, NATURE, V401, P695, DOI 10.1038/44409; Neri P., 2008, J VISION, V8, P1, DOI DOI 10.1167/8.1.22; Olman C, 2004, COGNITIVE SCI, V28, P227, DOI [10.1016/j.cogsci.2003.09.004, 10.1016/j.cogsci.2004.09.004]; Paninski L, 2005, NEURAL COMPUT, V17, P1480, DOI 10.1162/0899766053723032; Rajashekar U, 2006, J VISION, V6, P379, DOI 10.1167/6.4.7; Ross MG, 2009, J VISION, V9, DOI 10.1167/9.3.23; Rosset S, 2004, J MACH LEARN RES, V5, P941; Rust NC, 2006, NAT NEUROSCI, V9, P1421, DOI 10.1038/nn1786; Sahani M, 2003, ADV NEURAL INFORM PR, V15, P317; Seeger M, 2007, LECT NOTES ARTIF INT, V4701, P298; Seeger MW, 2008, J MACH LEARN RES, V9, P759; Simoncelli E. P., 2004, COGNITIVE NEUROSCIEN, V3, P327; SIMONCELLI EP, 1995, P 1995 INT C IM PROC, V3; Solomon JA, 2002, J VISION, V2, P105, DOI 10.1167/2.1.7; Thomas JP, 2005, J OPT SOC AM A, V22, P2257, DOI 10.1364/JOSAA.22.002257; Tjan BS, 2006, J VISION, V6, P387, DOI 10.1167/6.4.8; Victor JD, 2005, NAT NEUROSCI, V8, P1651, DOI 10.1038/nn1607; VUONG QH, 1989, ECONOMETRICA, V57, P307, DOI 10.2307/1912557; WIPF D, 2008, ADV NEURAL INFORM PR, P1625; Wood SN, 2006, GEN ADDITIVE MODELS; Worsley KJ, 1996, HUM BRAIN MAPP, V4, P74, DOI 10.1002/(SICI)1097-0193(1996)4:1&lt;74::AID-HBM5&gt;3.0.CO;2-M; Wu MCK, 2006, ANNU REV NEUROSCI, V29, P477, DOI 10.1146/annurev.neuro.29.051605.113024; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	64	11	11	2	3	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	1534-7362			J VISION	J. Vision		2009	9	10							17	10.1167/9.10.17		24	Ophthalmology	Ophthalmology	539TB	WOS:000273279800017		
J	Roether, CL; Omlor, L; Christensen, A; Giese, MA				Roether, Claire L.; Omlor, Lars; Christensen, Andrea; Giese, Martin A.			Critical features for the perception of emotion from gait	JOURNAL OF VISION			English	Review						emotion; locomotion; biological motion; emotional body expression; sparse feature learning; unsupervised learning	INDEPENDENT COMPONENT ANALYSIS; BIOLOGICAL MOTION; FACIAL EXPRESSIONS; LIGHT DISPLAYS; BODY MOVEMENTS; POINT-LIGHT; CLASSIFICATION IMAGES; RECOGNITION ACCURACY; MATRIX FACTORIZATION; PRINCIPAL COMPONENT	Human observers readily recognize emotions expressed in body movement. Their perceptual judgments are based on simple movement features, such as overall speed, but also on more intricate posture and dynamic cues. The systematic analysis of such features is complicated due to the difficulty of considering the large number of potentially relevant kinematic and dynamic parameters. To identify emotion-specific features we motion-captured the neutral and emotionally expressive (anger, happiness, sadness, fear) gaits of 25 individuals. Body posture was characterized by average flexion angles, and a low-dimensional parameterization of the spatio-temporal structure of joint trajectories was obtained by approximation with a nonlinear mixture model. Applying sparse regression, we extracted critical emotion-specific posture and movement features, which typically depended only on a small number of joints. The features we extracted from the motor behavior closely resembled features that were critical for the perception of emotion from gait, determined by a statistical analysis of classification and rating judgments of 21 observers presented with avatars animated with the recorded movements. The perceptual relevance of these features was further supported by another experiment showing that artificial walkers containing only the critical features induced high-level after-effects matching those induced by adaptation with natural emotional walkers.	[Roether, Claire L.; Omlor, Lars; Christensen, Andrea; Giese, Martin A.] Univ Tubingen, Hertie Inst Clin Brain Res, Sect Computat Sensomotor, D-72070 Tubingen, Germany; [Roether, Claire L.; Omlor, Lars; Christensen, Andrea; Giese, Martin A.] Univ Tubingen, Ctr Integrat Neurosci, D-72070 Tubingen, Germany; [Christensen, Andrea] Univ Tubingen, Hertie Inst Clin Brain Res, Sect Neuropsychol, D-72070 Tubingen, Germany	Giese, MA (reprint author), Univ Tubingen, Hertie Inst Clin Brain Res, Sect Computat Sensomotor, Frondsbergstr 23, D-72070 Tubingen, Germany.	martin.giese@uni-tuebingen.de			Volkswagenstiftung; DFG [SFB 550]; Forschergruppe Perceptual Graphics, HFSP; EC; Hermann and Lilly Schilling Foundation; University Clinic Tubingen	We thank W. Ilg for assistance in the motion-capture lab, J. Scharm for help with data collection, and T. Flash, T. Hendler, A. Berthoz and M. Pavlova for interesting discussions. We are grateful to two anonymous reviewers for constructive comments on the manuscript. The work was supported by the Volkswagenstiftung, DFG SFB 550 and the Forschergruppe Perceptual Graphics, HFSP, and the EC FP6 project COBOL. Additional support was provided by the Hermann and Lilly Schilling Foundation and the fortune program of the University Clinic Tubingen.	O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; WALLBOTT HG, 1986, J PERS SOC PSYCHOL, V51, P690, DOI 10.1037//0022-3514.51.4.690; EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Ellison JW, 1997, J EXP PSYCHOL HUMAN, V23, P213, DOI 10.1037/0096-1523.23.1.213; Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a; SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570; Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W; Hojen-Sorensen PADFR, 2002, NEURAL COMPUT, V14, P889, DOI 10.1162/089976602317319009; Webster MA, 2004, NATURE, V428, P557, DOI 10.1038/nature02420; Dittrich WH, 1996, PERCEPTION, V25, P727, DOI 10.1068/p250727; Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2; Schmidt KL, 2001, YEARB PHYS ANTHROPOL, V44, P3, DOI 10.1002/ajpa.20001; EKMAN P, 1967, PERCEPT MOTOR SKILL, V24, P711; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Schyns PG, 2007, CURR BIOL, V17, P1580, DOI 10.1016/j.cub.2007.08.048; Lee DD, 1999, NATURE, V401, P788; OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4; de Gelder B, 2006, NAT REV NEUROSCI, V7, P242, DOI 10.1038/nrn1872; Atkinson AP, 2007, COGNITION, V104, P59, DOI 10.1016/j.cognition.2006.05.005; Kleinsmith A, 2006, INTERACT COMPUT, V18, P1371, DOI 10.1016/j.intcom.2006.04.003; Calder AJ, 2001, VISION RES, V41, P1179, DOI 10.1016/S0042-6989(01)00002-5; FRIJDA NH, 1988, AM PSYCHOL, V43, P349, DOI 10.1037//0003-066X.43.5.349; Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0; Santello M, 2002, J NEUROSCI, V22, P1426; Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9; Ivanenko YP, 2005, J NEUROSCI, V25, P7238, DOI 10.1523/JNEUROSCI.1327-05.2005; Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096; Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be; Ivanenko YP, 2004, J PHYSIOL-LONDON, V556, P267, DOI 10.1113/jphysiol.2003.057174; ARONOFF J, 1992, J PERS SOC PSYCHOL, V62, P1050, DOI 10.1037/0022-3514.62.6.1050; Bartlett E.S., 1972, PATTERNS EMOTIONS NE; BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037//0022-3514.37.11.2049; BASSILI JN, 1978, J EXP PSYCHOL HUMAN, V4, P373, DOI 10.1037//0096-1523.4.3.373; BERTENTHAL BI, 1994, PSYCHOL SCI, V5, P221, DOI 10.1111/j.1467-9280.1994.tb00504.x; Bortz J., 1993, STAT SOZIALWISSENSCH; Brescoll VL, 2008, PSYCHOL SCI, V19, P268, DOI 10.1111/j.1467-9280.2008.02079.x; BULL N, 1951, ATTITUDE THEORY EMOT, V81; Cacioppo J. T., 2000, HDB EMOTIONS, P173; Carey S., 1994, VIS COGN, V1, P253, DOI 10.1080/13506289408402302; CHAN YT, 1978, IEEE T ACOUST SPEECH, V26, P217, DOI 10.1109/TASSP.1978.1163078; Cichocki A., 2002, ADAPTIVE BLIND SIGNA; d'Avella A, 2005, P NATL ACAD SCI USA, V102, P3076, DOI 10.1073/pnas.0500199102; DAVIS BL, 1993, J ELECTROMYOGR KINES, V3, P51, DOI 10.1016/1050-6411(93)90023-P; DEMEIJER M, 1989, J NONVERBAL BEHAV, V13, P247; DEMEIJER M, 1991, EUR J SOC PSYCHOL, V21, P249, DOI 10.1002/ejsp.2420210307; DITTRICH WH, 1993, PERCEPTION, V22, P15, DOI 10.1068/p220015; Donker SF, 2002, EXP BRAIN RES, V146, P26, DOI 10.1007/s00221-002-1145-2; Donker SF, 2001, J MOTOR BEHAV, V33, P86; Eckstein MP, 2002, J VISION, V2, pI, DOI 10.1167/2.1.i; EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550; EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86; Ekman P., 1978, FACIAL ACTION CODING; EKMAN P, 1965, J PERS SOC PSYCHOL, V2, P726, DOI 10.1037/h0022736; Elfenbein HA, 2007, J NONVERBAL BEHAV, V31, P205, DOI 10.1007/s10919-007-0033-7; ETCOFF NL, 1992, COGNITION, V44, P227, DOI 10.1016/0010-0277(92)90002-Y; FRIDLUND AJ, 1991, J PERS SOC PSYCHOL, V60, P229, DOI 10.1037/0022-3514.60.2.229; FRIDLUND AJ, 1992, J NONVERBAL BEHAV, V16, P191, DOI 10.1007/BF00988034; Friesen W. V., 1969, SEMIOTICA, V1, P49; GELLHORN E, 1964, PSYCHOL REV, V71, P457, DOI 10.1037/h0039834; Giese MA, 2002, VISION RES, V42, P1847, DOI 10.1016/S0042-6989(02)00093-7; Giese MA, 2000, INT J COMPUT VISION, V38, P59, DOI 10.1023/A:1008118801668; Giese MA, 2008, J VISION, V8, DOI 10.1167/8.9.13; Golubitsky M, 1999, NATURE, V401, P693, DOI 10.1038/44416; Grezes J, 2007, NEUROIMAGE, V35, P959, DOI 10.1016/j.neuroimage.2006.11.030; Hancock P J, 1996, Mem Cognit, V24, P21; Henley N., 1985, POWER DOMINANCE NONV; Izard C.E., 1977, HUMAN EMOTIONS; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Jordan H, 2006, NAT NEUROSCI, V9, P738, DOI 10.1038/nn1710; Kamachi M, 2001, PERCEPTION, V30, P875, DOI 10.1068/p3131; Kirtley C., 2006, CLIN GAIT ANAL; Knill D. C., 2008, PERCEPTION BAYESIAN; Leopold DA, 2001, NAT NEUROSCI, V4, P89, DOI 10.1038/82947; LU H, 2006, J VISION, V6, P12, DOI DOI 10.1167/6.4.12; Lu HJ, 2006, J VISION, V6, P475, DOI 10.1167/6.4.12; Maloney L. T, 2002, J VISION, V2, P6, DOI [10.1167/ 2.6.6., DOI 10.1167/2.6.6]; Maloney Laurence T, 2002, J Vis, V2, P493, DOI 10.1167/2.6.6; MATHER G, 1992, P ROY SOC B-BIOL SCI, V249, P149, DOI 10.1098/rspb.1992.0097; Meinshausen N, 2007, ANN STAT, V35, P2373, DOI 10.1214/009053607000000460; Merkle LA, 1998, J NEUROSCI METH, V82, P207, DOI 10.1016/S0165-0270(98)00054-5; MEZGER J, 2005, ACM SIGGRAPH S APPL; Montepare J, 1999, J NONVERBAL BEHAV, V23, P133, DOI 10.1023/A:1021435526134; MONTEPARE JM, 1987, J NONVERBAL BEHAV, V11, P33, DOI 10.1007/BF00999605; MUKOVSKIY A, 2008, 13 INT FALL WORKSH V; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Oja E., 2003, 4 INT S IND COMP AN; OLREE KS, 1995, BIOL CYBERN, V73, P409, DOI 10.1007/BF00201475; Omlor L., 2007, NEUROCOMPUTING, V70, P1938, DOI DOI 10.1016/J.NEUC0M.2006.10.100; Omlor L., 2007, ADV NEURAL INFORM PR, V19, P1049; OSGOOD CE, 1966, SCAND J PSYCHOL, V7, P1, DOI 10.1111/j.1467-9450.1966.tb01334.x; PADGETT C, 1995, 2 JOINT S NEUR COMP; Pavlova M, 2005, PERCEPTION, V34, P1107, DOI 10.1068/p5400; Pinto J, 1999, ACTA PSYCHOL, V102, P293, DOI 10.1016/S0001-6918(99)00028-1; Pollick FE, 2002, VISION RES, V42, P2345, DOI 10.1016/S0042-6989(02)00196-7; Roether CL, 2008, CURR BIOL, V18, pR329, DOI 10.1016/j.cub.2008.02.044; ROETHER CL, DYNAMICS VI IN PRESS; Santello M, 1997, SOMATOSENS MOT RES, V14, P203; Sawada M, 2003, PERCEPT MOTOR SKILL, V97, P697; Scherer K. R., 2003, HDB AFFECTIVE SCI, P433; SCHOUWSTRA SJ, 1995, PERCEPT MOTOR SKILL, V81, P673; SOGON S, 1989, PSYCHOL REP, V65, P35; Spiegel John, 1974, MESSAGES BODY; TANAKA JW, 1993, Q J EXP PSYCHOL-A, V46, P225; Thurman SM, 2008, J VISION, V8, DOI 10.1167/8.3.28; THURMAN SM, 2008, J VISION, V8, P1, DOI DOI 10.1167/8.3.28; Tresch MC, 2006, J NEUROPHYSIOL, V95, P2199, DOI 10.1152/jn.00222.2005; Troje N. F., 2006, J VISION, V6, P7, DOI 10.1167/6.8.7; Troje NF, 2006, J VISION, V6, P850, DOI 10.1167/6.8.7; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Unuma M., 1995, P SIGGRAPH 95, P91, DOI 10.1145/218380.218419; Valentin D, 1997, J MATH PSYCHOL, V41, P398, DOI 10.1006/jmps.1997.1186; VANGENEUGDEN J, 2008, CEREBRAL CORTEX; WALK RD, 1984, B PSYCHONOMIC SOC, V22, P437; Westermann R, 1996, EUR J SOC PSYCHOL, V26, P557, DOI 10.1002/(SICI)1099-0992(199607)26:4<557::AID-EJSP769>3.0.CO;2-4; WUNDT W, 2004, GRUNDRISS PSYCHOL; Xu H, 2008, J NEUROSCI, V28, P3374, DOI 10.1523/JNEUROSCI.0182-08.2008; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; ZUCKERMAN M, 1975, J PERS SOC PSYCHOL, V32, P1068, DOI 10.1037//0022-3514.32.6.1068	122	39	39	10	23	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	1534-7362			J VISION	J. Vision		2009	9	6							15	10.1167/9.6.15		32	Ophthalmology	Ophthalmology	526EM	WOS:000272270500015		
B	Ji, SW; Yuan, L; Li, YX; Zhou, ZH; Kumar, S; Ye, JP			ACM	Ji, Shuiwang; Yuan, Lei; Li, Ying-Xin; Zhou, Zhi-Hua; Kumar, Sudhir; Ye, Jieping			Drosophila Gene Expression Pattern Annotation Using Sparse Features and Term-Term Interactions	KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING			English	Proceedings Paper	15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining	JUN 28-JUL 01, 2009	Paris, FRANCE	ACM SIGKDD, ACM SIGMOD		gene expression pattern; image annotation; bag-of-words; sparse learning; regularization	GLOBAL ANALYSIS; LASSO	The Drosophila gene expression pattern images document the spatial and temporal dynamics of gene expression and they are valuable tools for explicating the gene functions, interaction, and networks during Drosophila embryogenesis. To provide text-based pattern searching, the images in the Berkeley Drosophila Genome Project (BDGP) study are annotated with ontology terms manually by human curators. We present a systematic approach for automating this task, because the number of images needing text descriptions is now rapidly increasing. We consider both improved feature representation and novel learning formulation to boost the annotation performance. For feature representation, we adapt the bag-of-words scheme commonly used in visual recognition problems so that the image group information in the BDGP study is retained. Moreover, images from multiple views can e integrated naturally in this representation. To reduce the quantization error caused by the bag-of-words representation, we propose an improved feature representation scheme based on the sparse learning technique. In the design of learning formulation, we propose a local regularization framework that can incorporate the correlations among terms explicitly. We further show that the resulting optimization problem admits an analytical solution. Experimental results show that the representation based on sparse learning outperforms the bag-of-words representation significantly. Results also show that incorporation of the term-term correlations improves the annotation performance consistently.	[Ji, Shuiwang; Yuan, Lei; Kumar, Sudhir; Ye, Jieping] Arizona State Univ, Biodesign Inst, Ctr Evolutionary Funct Genom, Tempe, AZ 85287 USA	Ji, SW (reprint author), Arizona State Univ, Biodesign Inst, Ctr Evolutionary Funct Genom, Tempe, AZ 85287 USA.		Kumar, Sudhir/F-1411-2011				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Lecuyer E, 2007, CELL, V131, P174, DOI 10.1016/j.cell.2007.08.003; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI 10.1145/1014052.1014067; Fowlkes CC, 2008, CELL, V133, P364, DOI 10.1016/j.cell.2008.01.053; Gurunathan R., 2004, BMC BIOINFORMATICS, V5, P13; Ji SW, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-119; Ji SW, 2008, BIOINFORMATICS, V24, P1881, DOI 10.1093/bioinformatics/btn347; KIM S, 2008, CMUML08113; Kumar S, 2002, GENETICS, V162, P2037; KUMAR S, 2009, KNOWLEDGEBASE UNPUB; Li Y., 2009, P 21 INT JOINT C ART; Mairal J., 2008, ADV NEURAL INFORM PR, V21, P1; Nowk E., 2006, P EUR C COMP VIS, P490; Philbin J., 2008, P IEEE C COMP VIS PA; Sivic J, 2008, P IEEE, V96, P548, DOI 10.1109/JPROC.2008.916343; Tomancak P., 2002, GENOME BIOL, V3; Tomancak P, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-7-r145; Ye J., 2008, ACM T KNOWL DISCOV D, V2, P1, DOI 10.1145/1342320.1342324; Ye J., 2006, P COMP SYST BIOINF C, P293	27	3	3	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-495-9				2009							407	415				9	Computer Science, Artificial Intelligence	Computer Science	BLS23	WOS:000270922000040		
B	Lozano, AC; Abe, N; Liu, Y; Rosset, S			ACM	Lozano, Aurelie C.; Abe, Naoki; Liu, Yan; Rosset, Saharon			Grouped Graphical Granger Modeling Methods for Temporal Causal Modeling	KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING			English	Proceedings Paper	15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining	JUN 28-JUL 01, 2009	Paris, FRANCE	ACM SIGKDD, ACM SIGMOD		Temporal Causal modeling; Boosting; Variable Group Selection; Granger Causality; Graphical Modeling	REGRESSION; SELECTION; LASSO	We develop and evaluate an approach to causal modeling based on time series data, collectively referred to as "grouped graphical Granger modeling methods." Graphical Granger modeling uses graphical modeling techniques on time series data and invokes the notion of "Granger causality" to make assertions on causality among a potentially large number of time series variables through inference on time-lagged effects. The present paper proposes a novel enhancement to the graphical Granger methodology by developing and applying families of regression methods that are sensitive to group information among variables, to leverage the group structure present in the lagged temporal variables according to the time series they belong to. Additionally, we propose a new family of algorithms we call group boosting, as an improved component of grouped graphical Granger modeling over the existing regression methods with grouped variable selection in the literature (e.g group Lasso). The introduction of group boosting methods is primarily motivated by the need to deal with non-linearity in the data. We perform empirical evaluation to confirm the advantage of the grouped graphical Granger methods over the standard (non-grouped) methods, as well as that specific to the methods based on group boosting. This advantage is also demonstrated for the real world application of gene regulatory network discovery from time-course microarray data.	[Lozano, Aurelie C.; Abe, Naoki; Liu, Yan] IBM Corp, Thomas J Watson Res Ctr, Dept Math Sci, Yorktown Hts, NY 10598 USA	Lozano, AC (reprint author), IBM Corp, Thomas J Watson Res Ctr, Dept Math Sci, Yorktown Hts, NY 10598 USA.						Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Arnold A., 2007, P 13 ACM SIGKDD INT; BACH F, 2008, J MACHINE L IN PRESS; Buhlmann P, 2006, ANN STAT, V34, P559, DOI 10.1214/009053606000000092; Buhlmann P, 2006, J MACH LEARN RES, V7, P1001; BUHLMANN P, 2007, TWIN BOOSTING IMPROV; Dahlhaus R., 2003, HIGHLY STRUCTURED ST; Eichler M, 2007, J ECONOMETRICS, V137, P334, DOI 10.1016/j.jeconom.2005.06.032; Enders Walter, 2003, APPL ECONOMETRIC TIM, V2nd; GRANGER CWJ, 1980, J ECON DYN CONTROL, V2, P329, DOI 10.1016/0165-1889(80)90069-X; Hastie T., 2001, ELEMENTS STAT LEARNI; Hurvich CM, 1998, J ROY STAT SOC B, V60, P271, DOI 10.1111/1467-9868.00125; LOZANO A, 2009, P ISMB 2009; MUKHOPADHYAY ND, 2007, BIOINFORMATICS, V23; SAMBO F, 2008, CNET ALGORITHM REVER; Spirtes P., 2000, CAUSATION PREDICTION; ZHAO P, 2006, ANN STAT IN PRESS; Zhou N., 2007, GROUP VARIABLE UNPUB	22	2	2	0	6	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-495-9				2009							577	585				9	Computer Science, Artificial Intelligence	Computer Science	BLS23	WOS:000270922000057		
B	Lozano, A; Li, H; Niculescu-Mizil, A; Liu, Y; Perlich, C; Hosking, J; Abe, N			ACM	Lozano, A.; Li, H.; Niculescu-Mizil, A.; Liu, Y.; Perlich, C.; Hosking, J.; Abe, N.			Spatial-temporal Causal Modeling for Climate Change Attribution	KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING			English	Proceedings Paper	15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining	JUN 28-JUL 01, 2009	Paris, FRANCE	ACM SIGKDD, ACM SIGMOD		Climate modeling; Climate change attribution; Spatio-temporal modeling; Causal modeling Granger causality	SELECTION; REGRESSION	Attribution of climate change to causal factors has been based predominantly on simulations using physical climate models, which have inherent limitations in describing such a complex and chaotic system. We propose an alternative, data centric, approach that relies on actual measurements of climate observations and human and natural forcing factors. Specifically, we develop a novel method to infer causality from spatial-temporal data, as well as a procedure to incorporate extreme value modeling into our method in order to address the attribution of extreme climate events, such as heat-waves. Our experimental results on a real world dataset indicate that changes in temperature are not solely accounted for by solar radiance, but attributed more significantly to CO2 and other greenhouse gases. Combined with extreme value modeling, we also show that there has been a significant increase in the intensity of extreme temperatures, and that such changes in extreme temperature are also attributable to greenhouse gases. These preliminary results suggest that our approach can offer a useful alternative to the simulation-based approach to climate modeling and attribution, and provide valuable insights from a fresh perspective.	[Lozano, A.; Li, H.; Niculescu-Mizil, A.; Liu, Y.; Perlich, C.; Hosking, J.; Abe, N.] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Lozano, A (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	aclozano@us.ibm.com; liho@us.ibm.com; anicule@us.ibm.com; liuya@us.ibm.com; perlich@us.ibm.com; hosking@us.ibm.com; nabe@us.ibm.com					Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Banerjee S., 2004, HIERARCHICAL MODELIN; BARNETT TP, 2001, SCIENCE, V292; Beirlant J., 2004, STAT EXTREMES THEORY; CARTER CK, 1994, BIOMETRIKA, V81, P541; CHRISTIDIS N, 2005, GEOPHYS RES LETT, V32, P2005; Climate Change, 2007, CLIMATE CHANGE 2007; Coles S. G., 2001, INTRO STAT MODELING; GILLETT NP, 2003, NATURE, V422; GRANGER CWJ, 1980, J ECON DYN CONTROL, V2, P329, DOI 10.1016/0165-1889(80)90069-X; KAROLY DJ, 2003, SCIENCE, V302; LUO L, 1998, J CLIMATE, V11; Matern B., 1960, SPATIAL VARIATION; New M, 1999, J CLIMATE, V12, P829, DOI 10.1175/1520-0442(1999)012<0829:RTCSTC>2.0.CO;2; STOTT PA, 2004, NATURE, V432	17	3	3	0	1	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-495-9				2009							587	595				9	Computer Science, Artificial Intelligence	Computer Science	BLS23	WOS:000270922000058		
B	Liu, Y; Kalagnanam, JR; Johnsen, O			ACM	Liu, Yan; Kalagnanam, Jayant R.; Johnsen, Oivind			Learning Dynamic Temporal Graphs for Oil-production Equipment Monitoring System	KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING			English	Proceedings Paper	15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining	JUN 28-JUL 01, 2009	Paris, FRANCE	ACM SIGKDD, ACM SIGMOD		Graphical models; time series data; structure learning	VARIABLE SELECTION; REGRESSION; MODELS; LASSO	Learning temporal graph structures from time series data reveals important dependency relationships between current observations and histories. Most previous work focuses on learning and predicting with "static" temporal graphs only. However, in many applications such as mechanical systems and biology systems, the temporal dependencies might change over time. In this paper, we develop a dynamic temporal graphical models based on hidden Markov model regression and lasso-type algorithms. Our method is able to integrate two usually separate tasks, i.e. inferring underlying states and learning temporal graphs, in one unified model. The output temporal graphs provide better understanding about complex systems, i.e. how their dependency graphs evolve over time, and achieve more accurate predictions. We examine our model on two synthetic datasets as well as a real application dataset for monitoring oil-production equipment to capture different stages of the system, and achieve promising results.	[Liu, Yan; Kalagnanam, Jayant R.] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Liu, Y (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	liuya@us.ibm.com; jayant@us.ibm.com; oivindj@no.ibm.com					Aha D. W., 1995, P 5 INT WORKSH ART I, P1; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; ARNOLD A, 2007, P INT C KNOWL DISC D; Brillinger D. R., 1996, REV ECONOMETRICA, V16, P1; CHENG H, 2008, P INT C KNOWL DISC D, P133, DOI 10.1145/1401890.1401911; CHICKERING D, 1996, LEARNING DATA A STAT, V5; Eaton D., 2007, UAI; Friedman J. H., 2008, REGULARIZED PATHS GE; FUJINAGA K, 2001, P ICASSP, P513; GOLDENBERG A, 2004, P INT C MACH LEARN I; Guo F., 2007, ICML 07, P321; Jordan M. I., 1998, LEARNING GRAPHICAL M; Lee S., 2006, AAAI; Lee S.-I., 2007, ADV NEURAL INFORM PR, V19, P817; LOZANO A, 2009, P INT C INT SYST MOL; LOZANO A, 2009, P INT C KNOWL DISC D; NOTO K, 1924, P 24 ANN C UNC ART I; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAVIKUMAR P, 2007, THESIS CARNEGIE MELL; WAINWRIGHT M, 2007, ADV NEURAL INFORM PR, P1465	24	2	2	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-495-9				2009							1225	1233				9	Computer Science, Artificial Intelligence	Computer Science	BLS23	WOS:000270922000122		
B	Sun, L; Patel, R; Liu, J; Chen, KW; Wu, T; Li, J; Reiman, E; Ye, JP			ACM	Sun, Liang; Patel, Rinkal; Liu, Jun; Chen, Kewei; Wu, Teresa; Li, Jing; Reiman, Eric; Ye, Jieping			Mining Brain Region Connectivity for Alzheimer's Disease Study via Sparse Inverse Covariance Estimation	KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING			English	Proceedings Paper	15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining	JUN 28-JUL 01, 2009	Paris, FRANCE	ACM SIGKDD, ACM SIGMOD		Brain network; Alzheimer's disease; neuroimaging; FDG-PET; sparse inverse covariance estimation	GENETIC NETWORKS; SELECTION; LIKELIHOOD; GRAPHS; MODEL	Effective diagnosis of Alzheimer's disease (AD), the most common type of dementia in elderly patients, is of primary importance in biomedical research. Recent studies have demonstrated that AD is closely related to the structure change of the brain network, i.e., the connectivity among different brain regions. The connectivity patterns will pro-vide useful imaging-based biomarkers to distinguish Normal Controls (NC), patients with Mild Cognitive Impairment (MCI), and patients with AD. In this paper, we investigate the sparse inverse covariance estimation technique for identifying the connectivity among different brain regions. In particular, a novel algorithm based on the block coordinate descent approach is proposed for the direct estimation of the inverse covariance matrix. One appealing feature of the proposed algorithm is that it allows the user feedback (e.g., prior domain knowledge) to be incorporated into the estimation process, while the connectivity patterns can be discovered automatically. We apply the proposed algorithm to a collection of FDG-PET images from 232 NC, MCI, and AD subjects. Our experimental results demonstrate that the proposed algorithm is promising in revealing the brain region connectivity differences among these groups.	[Sun, Liang; Liu, Jun; Ye, Jieping] Arizona State Univ, Biodesign Inst, Ctr Evolutionary Funct Genom, Tempe, AZ 85287 USA	Sun, L (reprint author), Arizona State Univ, Biodesign Inst, Ctr Evolutionary Funct Genom, Tempe, AZ 85287 USA.			Chen, kewei/0000-0001-8497-3069			Alexander G. E., 2003, DEMENTIAS DIAGNOSIS; Wakana S, 2004, RADIOLOGY, V230, P77, DOI 10.1148/radiol.2301021640; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; MCKHANN G, 1984, NEUROLOGY, V34, P939; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978; Li HZ, 2006, BIOSTATISTICS, V7, P302, DOI 10.1093/biostatistics/kxj008; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Delbeuck X, 2003, NEUROPSYCHOL REV, V13, P79, DOI 10.1023/A:1023832305702; Banerjee O, 2008, J MACH LEARN RES, V9, P485; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Banerjee O., 2006, ICML 06, P89; Berge A, 2007, IEEE T GEOSCI REMOTE, V45, P1399, DOI 10.1109/TGRS.2007.892598; Bilmes JA, 2000, INT CONF ACOUST SPEE, P1009; Dahl J, 2008, OPTIM METHOD SOFTW, V23, P501, DOI 10.1080/10556780802102693; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Folstein MF, 1975, J PSYCHIATR RES, V12, P198; Friedman J., 2007, BIOSTATISTICS, V8, P1; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; HESTON L, 1983, VANISHING MIND PRACT; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; Lauritzen S. L., 1996, GRAPHICAL MODELS; MOLCHAN S, 2005, BUSINESS BRIEFING US, P30; Nemirovski A, 2004, SIAM J OPTIMIZ, V15, P229, DOI 10.1137/S1052623403425629; Stam CJ, 2007, CEREB CORTEX, V17, P92, DOI 10.1093/cercor/bhj127; Supekar K, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000100; Tegner J, 2003, P NATL ACAD SCI USA, V100, P5944, DOI 10.1073/pnas.0933416100; Tseng P., 2001, J OPT THEORY APPL, V109, P474; Ye J., 2008, KDD, P1025	30	7	7	1	2	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-495-9				2009							1335	1343				9	Computer Science, Artificial Intelligence	Computer Science	BLS23	WOS:000270922000133		
J	Gimona, A; Messager, P; Occhi, M				Gimona, Alessandro; Messager, Pernette; Occhi, Martino			CORINE-based landscape indices weakly correlate with plant species richness in a northern European landscape transect	LANDSCAPE ECOLOGY			English	Article						Distribution atlas; Indicators; MARS; Land cover; Flora	PATTERN INDEXES; AGRICULTURAL LANDSCAPES; ECOLOGICAL PROCESSES; THEMATIC RESOLUTION; CHANGING SCALE; REGIONAL-SCALE; METRICS; REGRESSION; DIVERSITY; FOREST	We present the results of one of the few available tests of how CORINE (CLC2000) is likely to perform as a basis for the calculation of landscape indices, for environmental monitoring over large areas. This paper investigates to what extent landscape structural indices based on this widely used European land cover database can be used to predict plant species richness in a 2,000 km(2) transect in the northeast of Scotland. We investigate both statistical and map resolution issues by comparing the performance of CORINE-based common landscape indices with the same indices derived from a much more detailed geographic data set. In our case study, only shape-related indices show correlation with species richness, but effect size, important for monitoring, is small. The results highlight the area-specific and map specific nature of the performance of landscape indices for protecting plant diversity.	[Occhi, Martino] Univ Milan, Dipartimento Prod Vegetale, I-20133 Milan, Italy; [Gimona, Alessandro; Messager, Pernette] Macaulay Inst, Aberdeen AB15 8QH, Scotland	Gimona, A (reprint author), Macaulay Inst, Aberdeen AB15 8QH, Scotland.	a.gimona@macaulay.ac.uk	wrbka, thomas/A-5699-2010				AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; ALTMAN DG, 1989, STAT MED, V8, P771, DOI 10.1002/sim.4780080702; Buyantuyev A, 2007, LANDSCAPE ECOL, V22, P7, DOI 10.1007/s10980-006-9010-5; Grossman YL, 1996, REMOTE SENS ENVIRON, V56, P182, DOI 10.1016/0034-4257(95)00235-9; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hawkins BA, 2003, ECOLOGY, V84, P3105, DOI 10.1890/03-8006; Gustafson EJ, 1998, ECOSYSTEMS, V1, P143, DOI 10.1007/s100219900011; Chown SL, 2003, ECOL APPL, V13, P1233, DOI 10.1890/02-5105; Li HB, 2004, LANDSCAPE ECOL, V19, P389, DOI 10.1023/B:LAND.0000030441.15628.d6; Schmit C, 2006, ENVIRON SCI POLICY, V9, P174, DOI 10.1016/j.envsci.2005.11.006; Thomas CD, 2004, NATURE, V427, P145, DOI 10.1038/nature02121; DUNNING JB, 1992, OIKOS, V65, P169, DOI 10.2307/3544901; Gimona A, 2007, LANDSCAPE ECOL, V22, P1255, DOI 10.1007/s10980-007-9105-7; Haslem A, 2008, AGR ECOSYST ENVIRON, V125, P191, DOI 10.1016/j.agee.2008.01.001; Gaston KJ, 2003, P ROY SOC B-BIOL SCI, V270, P1293, DOI 10.1098/rspb.2002.2303; Rahbek C, 2001, P NATL ACAD SCI USA, V98, P4534, DOI 10.1073/pnas.071034898; Moser D, 2005, J BIOGEOGR, V32, P1117, DOI 10.1111/j.1365-2699.2005.01265.x; Munoz J, 2004, J VEG SCI, V15, P285, DOI 10.1658/1100-9233(2004)015[0285:COSMCU]2.0.CO;2; CRAVEN P, 1979, NUMER MATH, V31, P377; Wagner HH, 2000, LANDSCAPE ECOL, V15, P219, DOI 10.1023/A:1008114117913; Bailey D, 2007, ECOL INDIC, V7, P692, DOI 10.1016/j.ecolind.2006.08.001; Baldwin DJB, 2004, LANDSCAPE ECOL, V19, P255, DOI 10.1023/B:LAND.0000030442.96122.ef; Bastian O, 2006, LANDSCAPE ECOL, V21, P359, DOI 10.1007/s10980-005-5224-1; Bastian O, 2000, LANDSCAPE URBAN PLAN, V50, P145, DOI 10.1016/S0169-2046(00)00086-4; Bera P, 2006, T ASABE, V49, P297; Bunce RGH, 2008, LANDSCAPE ECOL, V23, P11, DOI 10.1007/s10980-007-9173-8; *CDB, CONV BIOL DIV; *COMM EUR COMM, 2006, HALT LOSS BIOD 2006; *COMM EUR COMM, 1998, COM9842 COMM EUR COM; Corry RC, 2005, LANDSCAPE URBAN PLAN, V72, P265, DOI 10.1016/j.landurbplan.2004.04.003; *COUNC EUR, 1994, LANDS DIV STRAT; Council of Europe, 2000, EUR LANDS CONV; Dale VH, 2000, ECOL APPL, V10, P639; De Clercq EM, 2006, INT J APPL EARTH OBS, V8, P113, DOI 10.1016/j.jag.2005.07.002; Deutschewitz K, 2003, GLOBAL ECOL BIOGEOGR, V12, P299, DOI 10.1046/j.1466-822X.2003.00025.x; Donohue RJ, 2007, HYDROL EARTH SYST SC, V11, P983; DRAMSTAD WE, 2002, J ENVIRON MANAGE, V63, P1; *EEA, 2006, THEM ACC CORINE LAND; EEA, 2002, CORINE LAND COV UPD; Evans KL, 2005, FUNCT ECOL, V19, P899, DOI 10.1111/j.1365-2435.2005.01046.x; Fjellstad WJ, 1999, LANDSCAPE URBAN PLAN, V45, P177, DOI 10.1016/S0169-2046(99)00055-9; Forman RTT, 1986, LANDSCAPE ECOLOGY; Groom G, 2006, LANDSCAPE ECOL, V21, P391, DOI 10.1007/s10980-004-4212-1; Gustafson EJ, 2007, LANDSCAPE ECOL, V22, P141, DOI 10.1007/s10980-006-9017-y; HANSKI I, 1991, BIOL J LINN SOC, V42, P17, DOI 10.1111/j.1095-8312.1991.tb00549.x; Hastie T., 2001, ELEMENTS STAT LEARNI; Hernandez-Stefanoni JL, 2006, BIODIVERS CONSERV, V15, P1441, DOI 10.1007/s10531-005-0598-6; Herzog F, 2001, ENVIRON MANAGE, V27, P91, DOI 10.1007/s002670010136; Hietala-Koivu R, 1999, LANDSCAPE URBAN PLAN, V46, P103, DOI 10.1016/S0169-2046(99)00051-1; *HMSO, 1995, BIOD UK ACT PLAN; *IRENA, 2004, IRENA EXP M LANDS BI; Kim KH, 2007, LAND USE POLICY, V24, P264, DOI 10.1016/j.landusepol.2005.12.001; Kivinen S., 2005, Journal of Biogeography, V33, P862; Kivinen S, 2006, J BIOGEOGR, V33, P862, DOI 10.1111/j.1365-2699.2006.01433.x; Leathwick JR, 2005, FRESHWATER BIOL, V50, P2034, DOI 10.1111/j.1365-2427.2005.01448.x; LEVINS R, 1969, Bulletin of the Entomological Society of America, V15, P237; Luoto M, 2000, PLANT ECOL, V149, P157, DOI 10.1023/A:1026531400356; MacArthur R. H., 1967, THEORY ISLAND BIOGEO; Mander U, 1999, LANDSCAPE URBAN PLAN, V46, P169, DOI 10.1016/S0169-2046(99)00042-0; Mangel M., 1997, ECOLOGICAL DETECTIVE; McGarigal K., 1995, PNW351 USDA FOR SERV; Mortelliti A, 2007, ACTA THERIOL, V52, P75, DOI 10.1007/BF03194202; Moser D, 2002, LANDSCAPE ECOL, V17, P657, DOI 10.1023/A:1021513729205; Oja T, 2005, ECOL INDIC, V5, P314, DOI 10.1016/j.ecolind.2005.03.008; Preston CD, 2002, NEW ATLAS BRIT IRISH; RIITTERS KH, 1995, LANDSCAPE ECOL, V10, P23, DOI 10.1007/BF00158551; Rosenzweig M. L., 1995, SPECIES DIVERSITY SP; Rosenzweig ML, 2001, P NATL ACAD SCI USA, V98, P5404, DOI 10.1073/pnas.101092798; Saura S, 2001, PHOTOGRAMM ENG REM S, V67, P1027; Tischendorf L, 2001, LANDSCAPE ECOL, V16, P235, DOI 10.1023/A:1011112719782; Tress B, 2003, LANDSCAPE URBAN PLAN, V64, P161, DOI 10.1016/S0169-2046(02)00219-0; Uuemaa E, 2005, ECOL INDIC, V5, P350, DOI 10.1016/j.ecolind.2005.03.009; van der Horst D, 2005, BIOL CONSERV, V123, P421, DOI 10.1016/j.biocon.2004.11.020; Walters S, 2007, LANDSCAPE ECOL, V22, P867, DOI 10.1007/s10980-006-9065-3; Wascher DM, 2005, EUROPEAN LANDSCAPE C; Wu JG, 2002, LANDSCAPE ECOL, V17, P761, DOI 10.1023/A:1022995922992; Wu JG, 2004, LANDSCAPE ECOL, V19, P125, DOI 10.1023/B:LAND.0000021711.40074.ae; Zechmeister HG, 2001, BIODIVERS CONSERV, V10, P1609, DOI 10.1023/A:1012008828522; Zhang Y, 2005, CAN J REMOTE SENS, V31, P153	79	10	11	4	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0921-2973			LANDSCAPE ECOL	Landsc. Ecol.	JAN	2009	24	1					53	64		10.1007/s10980-008-9279-7		12	Ecology; Geography, Physical; Geosciences, Multidisciplinary	Environmental Sciences & Ecology; Physical Geography; Geology	395EI	WOS:000262506000005		
S	Zien, A; Kramer, N; Sonnenburg, S; Ratsch, G		Buntine, W; Grobelnik, M; Mladenic, D; ShaweTaylor, J		Zien, Alexander; Kraemer, Nicole; Sonnenburg, Soeren; Raetsch, Gunnar			The Feature Importance Ranking Measure	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia			VARIABLE IMPORTANCE; CLASSIFICATION; SHRINKAGE; MACHINE; MATRIX	Most accurate predictions are typically obtained by learning machines with complex feature spaces (as e.g. induced by kernels). Unfortunately, such decision rules are hardly accessible to humans and cannot easily be used to gain insights about the application domain. Therefore, one often resorts to linear models in combination with variable selection, thereby sacrificing some predictive power for presumptive interpretability. Here, we introduce the Feature Importance Ranking Measure (FIRM), which by retrospective analysis of arbitrary learning machines allows to achieve both excellent predictive performance and superior interpretation. In contrast to standard raw feature weighting, FIRM takes the underlying correlation structure of the features into account. Thereby, it is able to discover the most relevant features, even if their appearance in the training data is entirely prevented by noise. The desirable properties of FIRM are investigated analytically and illustrated in simulations.	[Zien, Alexander] Fraunhofer FIRST IDA, D-12489 Berlin, Germany	Zien, A (reprint author), Fraunhofer FIRST IDA, Kekulestr 7, D-12489 Berlin, Germany.						Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Schafer J, 2005, STAT APPL GENET MO B, V4, DOI 10.2202/1544-6115.1175; Bennett KP, 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; CORTES C, 2008, OUTC NIPS 2008 WORKS; Graf ABA, 2006, NEURAL COMPUT, V18, P143, DOI 10.1162/089976606774841611; Ratsch G, 2005, BIOINFORMATICS S1, V21, P369; Scholkopf B., 2002, LEARNING KERNELS; Sonnenburg S, 2005, LECT NOTES COMPUT SC, V3500, P389; Strobl C, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-307; Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25; Ustün B, 2007, Anal Chim Acta, V595, P299, DOI 10.1016/j.aca.2007.03.023; VANDERLAAN M, 2006, INT J BIOSTAT, V2, P1008; ZIEN A, 2008, P 16 INT C INT SYST; ZIEN A, 2007, ELECT PUBL, V2	17	6	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-04173-0	LECT NOTES ARTIF INT			2009	5782						694	709				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BMF17	WOS:000272076400045		
J	Schmid, VJ; Whitcher, B; Padhani, AR; Taylor, NJ; Yang, GZ				Schmid, Volker J.; Whitcher, Brandon; Padhani, Anwar R.; Taylor, N. Jane; Yang, Guang-Zhong			A Bayesian Hierarchical Model for the Analysis of a Longitudinal Dynamic Contrast-Enhanced MRI Oncology Study	MAGNETIC RESONANCE IN MEDICINE			English	Article						breast cancer; clinical trial; drug development; mixed-effects model; treatment response	BRAIN-BARRIER PERMEABILITY; IMAGING DATA; FMRI; INFERENCE; PERFUSION; KINETICS; EXCHANGE; CANCER	Imaging in clinical oncology trials provides a wealth of Information that contributes to the drug development process, especially In early phase studies. This article focuses on kinetic modeling in DCE-MRI, Inspired by mixed-effects models that are frequently used in the analysis of clinical trials. Instead of summarizing each scanning session as a single kinetic parameter-such as median K-trans across all voxels in the tumor ROI-we propose to analyze all voxel time courses from all scans and across all subjects simultaneously in a single model. The kinetic parameters from the usual nonlinear regression model are decomposed into unique components associated with factors from the longitudinal study; e.g., treatment, patient, and voxel effects. A Bayesian hierarchical model provides the framework to construct a data model, a parameter model, as well as prior distributions. The posterior distribution of the kinetic parameters Is estimated using Markov chain Monte Carlo (MCMC) methods. Hypothesis testing at the study level for an overall treatment effect is straightforward and the patient- and voxel-level parameters capture random effects that provide additional information at various levels of resolution to allow a thorough evaluation of the clinical trial. The proposed method is validated with a breast cancer study, where the subjects were Imaged before and after two cycles of chemotherapy, demonstrating the clinical potential of this method to longitudinal oncology studies. Magn Reson Mad 61:163-174, 2009. (C) 2009 Wiley-Liss, Inc.	[Whitcher, Brandon] Univ London Imperial Coll Sci Technol & Med, GlaxoSmithKline, Clin Imaging Ctr, Hammersmith Hosp, London W12 0NN, England; [Schmid, Volker J.; Yang, Guang-Zhong] Univ London Imperial Coll Sci Technol & Med, Inst Biomed Engn, London SW7 2AZ, England; [Padhani, Anwar R.; Taylor, N. Jane] Mt Vernon Hosp, Paul Strickland Scanner Ctr, Northwood HA6 2RN, Middx, England	Whitcher, B (reprint author), Univ London Imperial Coll Sci Technol & Med, GlaxoSmithKline, Clin Imaging Ctr, Hammersmith Hosp, Cane Rd, London W12 0NN, England.	brandon.j.whitcher@gsk.com	Schmid, Volker/F-3251-2010	Schmid, Volker/0000-0003-2195-8130	GlaxoSmith Kline; UK Engineering and Physical Sciences Research Council (EPSRC) [GR/T06735/01]	Grant sponsor: GlaxoSmith Kline; Grant sponsor: UK Engineering and Physical Sciences Research Council (EPSRC); Grant number: GR/T06735/01	Ah-See MLW, 2004, J CLIN ONCOL, V22, p22S; LIU JS, 1994, BIOMETRIKA, V81, P27; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tofts PS, 1999, J MAGN RESON IMAGING, V10, P223, DOI 10.1002/(SICI)1522-2586(199909)10:3<223::AID-JMRI2>3.0.CO;2-S; Fahrmeir L, 2001, J ROY STAT SOC C-APP, V50, P201, DOI 10.1111/1467-9876.00229; d'Arcy JA, 2006, RADIOGRAPHICS, V26, P621, DOI 10.1148/rg.262045187; Behrens TEJ, 2003, MAGNET RESON MED, V50, P1077, DOI 10.1002/mrm.10609; Beckmann CF, 2003, NEUROIMAGE, V20, P1052, DOI 10.1016/S1053-8119(03)00435-X; Friston KJ, 2002, NEUROIMAGE, V16, P465, DOI 10.1006/nimg.2002.1090; St Lawrence KS, 1998, J CEREBR BLOOD F MET, V18, P1365; Leach MO, 2005, BRIT J CANCER, V92, P1599, DOI 10.1038/sj.bjc.6602550; Beresford MJ, 2006, J MAGN RESON IMAGING, V24, P1316, DOI 10.1002/jmri.20768; Buckleys DL, 2005, DYNAMIC CONTRAST ENH, P69; Clayton D., 1996, MARKOV CHAIN MONTE C, P275; Collins DJ, 2004, IEEE ENG MED BIOL, V23, P65, DOI 10.1109/MEMB.2004.1360410; Fahrmeir L., 2001, MULTIVARIATE STAT MO, V2nd; Friston KJ, 2005, NEUROIMAGE, V24, P244, DOI 10.1016/j.neuroimage.2004.08.055; FritzHansen T, 1996, MAGNET RESON MED, V36, P225, DOI 10.1002/mrm.1910360209; Gelman A., 2003, BAYESIAN DATA ANAL; Genovese CR, 2000, J AM STAT ASSOC, V95, P691, DOI 10.2307/2669445; Gilks W. R., 1996, MARKOV CHAIN MONTE C; Hastie TJ, 1990, GEN ADDITIVE MODELS; HROWN, 1999, APPL MIXED MODELS ME; Johnson N. L., 1994, CONTINUOUS UNIVARIAT, V1; Johnson N. L., 1995, CONTINUOUS UNIVARIAT, V2; Kety SS., 1960, METHOD MED RES, P223; LARSSON HBW, 1992, MAGNET RESON MED, V24, P174, DOI 10.1002/mrm.1910240119; Padhani AR, 2003, J MAGN RESON IMAGING, V17, P427, DOI 10.1002/jmri.10257; Parker GJM, 1998, RADIOGRAPHICS, V18, P497; Parker GJM, 1997, JMRI-J MAGN RESON IM, V7, P564, DOI 10.1002/jmri.1880070318; Pinheiro J. C., 2000, MIXED EFFECTS MODELS; Port RE, 1999, JMRI-J MAGN RESON IM, V10, P233; Roche A, 2007, NEUROIMAGE, V38, P501, DOI 10.1016/j.neuroimage.2007.06.043; Rue H, 2001, J ROY STAT SOC B, V63, P325, DOI 10.1111/1467-9868.00288; Schmid VJ, 2005, LECT NOTES COMPUT SC, V3750, P886; Schmid VJ, 2006, IEEE T MED IMAGING, V25, P1627, DOI 10.1109/TMI.2006.884210; Silverman B.W., 1986, DENSITY ESTIMATION; TOFTS PS, 1991, MAGNET RESON MED, V17, P357, DOI 10.1002/mrm.1910170208; WEINMANN HJ, 1984, PHYSIOL CHEM PHYS, V16, P167; Wikle CK, 2003, INT STAT REV, V71, P181	40	17	17	2	3	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0740-3194	1522-2594		MAGN RESON MED	Magn. Reson. Med.	JAN	2009	61	1					163	174		10.1002/mrm.21807		12	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	386WT	WOS:000261914000020	19097226	
S	Fornasier, M		Hancock, ER; Martin, RR; Sabin, MA		Fornasier, M.			Compressive Algorithms-Adaptive Solutions of PDEs and Variational Problems	MATHEMATICS OF SURFACES XIII	Lecture Notes in Computer Science		English	Proceedings Paper	13th IMA Conference on the Mathematics of Surfaces	SEP 07-09, 2009	York, ENGLAND	Inst Math & Applicat	Univ York		LINEAR INVERSE PROBLEMS; ELLIPTIC OPERATOR-EQUATIONS; BOUNDARY-VALUE-PROBLEMS; TOTAL VARIATION MINIMIZATION; SADDLE-POINT PROBLEMS; FINITE-ELEMENT-METHOD; SIGNAL RECOVERY; SPARSITY CONSTRAINTS; WAVELET METHODS; CONVERGENCE-RATES	This paper is concerned with an overview of the main concepts and a few significant applications of a class of adaptive iterative algorithms which allow for dimensionality reductions when used to solve large scale problems. We call this class of numerical methods Compressive Algorithms. The introduction of this paper presents an historical excursus on the developments of the main ideas behind compressive algorithms and stresses the common features of diverse applications. The first part of the paper is addressed to the optimal performances of such algorithms when compared with known benchmarks in the numerical solution of elliptic partial differential equations. In the second part we address the solution of inverse problems both with sparsity and compressibility constraints. We stress how compressive algorithms can stein from variational principles. We illustrate the main results and applications by a few significant numerical examples. We conclude by pointing out future developments.			massimo.fornasier@oeaw.ac.at					ALEXEEV B, 2009, COMPLEXITY FREE DISC; Ambrosio L., 2000, OXFORD MATH MONOGRAP, Vxviii; Cohen A, 2002, FOUND COMPUT MATH, V2, P203, DOI 10.1007/s102080010027; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Cohen A, 2001, MATH COMPUT, V70, P27; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319; DUFFIN RJ, 1952, T AM MATH SOC, V72, P341, DOI 10.2307/1990760; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Daudet L, 2002, SIGNAL PROCESS, V82, P1595, DOI 10.1016/S0165-1684(02)00304-3; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412; Cohen A, 2003, SIAM J NUMER ANAL, V41, P1785, DOI 10.1137/S0036142902412269; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Fornasier M, 2008, SIAM J NUMER ANAL, V46, P577, DOI 10.1137/0606668909; CHAMBOLLE A, 1995, SIAM J APPL MATH, V55, P827, DOI 10.1137/S0036139993257132; AUBERT G, 2002, PARTIAL DIFFERENTIAL; Binev P, 2004, NUMER MATH, V97, P219, DOI 10.1007/s00211-003-0492-7; Blake A., 1987, VISUAL RECONSTRUCTIO; Bourdin B, 2000, NUMER MATH, V85, P609, DOI 10.1007/s002110000099; Candes E. J., 2006, INT C MATH, V3, P1433; Candes EJ, ENHANCING SPARSITY R; CHAMBOLLE A, 1999, M2AN MATH MODEL NUME, V33, P651; Chen S, 1998, SIAM J SCI COMPUT, V1, P33; Christensen O., 2003, INTRO FRAMES RIESZ B; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; Cohen A, 2004, SIAM J NUMER ANAL, V42, P1479, DOI 10.1137/S0036142902411793; Dahlke S, 2002, SIAM J NUMER ANAL, V40, P1230, DOI 10.1137/S003614290139233X; Dahlke S, 2007, IMA J NUMER ANAL, V27, P717, DOI 10.1093/imanum/drl035; Dahlke S, 1997, APPL NUMER MATH, V23, P21, DOI 10.1016/S0168-9274(96)00060-8; Dahlke S, 2000, ESAIM-MATH MODEL NUM, V34, P1003, DOI 10.1051/m2an:2000113; Dahlke S, 1997, COMMUN PART DIFF EQ, V22, P1, DOI 10.1080/03605309708821252; Dahlke S, 1999, APPL MATH LETT, V12, P31, DOI 10.1016/S0893-9659(99)00075-0; DAHLKE S, 2009, NUMERICAL M IN PRESS; Dahlke S, 2007, ADV COMPUT MATH, V27, P27, DOI 10.1007/s10444-005-7501-6; Dahlke S., 1997, MULTISCALE WAVELET M, P237; Dahmen W, 1999, MATH COMPUT, V68, P1533, DOI 10.1090/S0025-5718-99-01092-3; Dahmen W, 1999, SIAM J MATH ANAL, V31, P184, DOI 10.1137/S0036141098333451; Dahmen W., 1998, RESULTS MATH, V34, P255; Dal Maso G, 1993, INTRO TAU CONVERGENC; Daubechies I, 2008, J FOURIER ANAL APPL, V14, P764, DOI 10.1007/s00041-008-9039-8; Daubechies I., 1992, 10 LECT WAVELETS; Daubechies I, 2007, INVERSE PROBL IMAG, V1, P29; Daubechies I, 2005, APPL COMPUT HARMON A, V19, P1, DOI 10.1016/j.acha.2004.12.004; DAUBECHIES I, ARXIV08070575; DAUBECHIES I, 2009, COMMUN PURE IN PRESS; DeVore R. A., 1998, Acta Numerica, V7, DOI 10.1017/S0962492900002816; DONOHO DL, 1989, SIAM J APPL MATH, V49, P906, DOI 10.1137/0149053; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9446, DOI 10.1073/pnas.0502269102; Donoho D.L., 1992, SIAM J APPL MATH, V52, P557; DONOHO DL, 1992, SIAM J MATH ANAL, V23, P1309, DOI 10.1137/0523074; DONOHO DL, 2006, COUNTING FACES RANDO; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; Donoho DL, 2006, DISCRETE COMPUT GEOM, V35, P617, DOI 10.1007/s00454-005-1220-0; DONOHO DL, 1995, APPL COMPUT HARMON A, V2, P101, DOI 10.1006/acha.1995.1008; Engl H. W., 1996, MATH APPL, V375; FORNASIER M, 2009, SIAM J NUME IN PRESS; FORNASIER M, 2009, ADV COMPUT IN PRESS; Fornasier M, 2004, J MATH ANAL APPL, V289, P180, DOI 10.1016/j.jmaa.2003.09.041; FORNASIER M, 2009, P SAMPTA 2009 MARS; FORNASIER M, 2009, ARXIV09012605; Fornasier M, 2007, INVERSE PROBL, V23, P2505, DOI 10.1088/0266-5611/23/6/014; Fornasier M, 2008, APPL COMPUT HARMON A, V25, P187, DOI 10.1016/j.acha.2007.10.005; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; GILBERT AC, 2006, ONE SKETCH ALL FAST; Gribonval R, 2007, APPL COMPUT HARMON A, V22, P335, DOI 10.1016/j.acha.2006.09.003; GROCHERNIG K, 2000, FDN TIME FREQUENCY A; Kim S.-J., 2007, IEEE J SELECTED TOPI; Loris I, 2009, INVERSE PROBL, V25, DOI 10.1088/0266-5611/25/3/035008; Loris I, 2007, GEOPHYS J INT, V170, P359, DOI 10.1111/j.1365-246X.2007.03409.x; Mallat S., 1999, WAVELET TOUR SIGNAL; Morin P., 2002, SIAM REV, V44, P631, DOI 10.1137/S0036144502409093; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Oswald P., 1997, FRAMES SPACE SPLITTI; Oswald P., 1997, MULTILEVEL FRAMES RI; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; Starck JL, 2003, SIGNAL PROCESS, V83, P2279, DOI 10.1016/S0165-1684(03)00150-6; Starck JL, 2003, ASTRON ASTROPHYS, V398, P785, DOI 10.1051/0004-6361:20021571; Stevenson R, 2007, FOUND COMPUT MATH, V7, P245, DOI 10.1007/s10208-005-0183-0; Stevenson R, 2009, MATH COMPUT, V78, P619; Stevenson R, 2008, IMA J NUMER ANAL, V28, P354, DOI 10.1093/imanum/drm025; Stevenson R, 2005, SIAM J NUMER ANAL, V42, P2188, DOI 10.1137/S0036142903425082; Stevenson R, 2003, SIAM J NUMER ANAL, V41, P1074, DOI 10.1137/S0036142902407988; TADMOR E, 2009, NUMERICAL METHODS NO; TAYLOR HL, 1979, GEOPHYSICS, V44, P39, DOI 10.1190/1.1440921; Vese L, 2001, APPL MATH OPT, V44, P131, DOI 10.1007/s00245-001-0017-7; WEISS P, 2009, SIAM J SCI IN PRESS; Zou J, 2006, J COMPUT PHYS, V211, P572, DOI 10.1016/j.jcp.2005.06.005	100	0	0	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-03595-1	LECT NOTES COMPUT SC			2009	5654						143	169				27	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BLC70	WOS:000269928400009		
J	Carrera, J; Rodrigo, G; Jaramillo, A				Carrera, Javier; Rodrigo, Guillermo; Jaramillo, Alfonso			Towards the automated engineering of a synthetic genome	MOLECULAR BIOSYSTEMS			English	Review							GENE REGULATORY NETWORKS; SCALE METABOLIC RECONSTRUCTION; ESCHERICHIA-COLI; IN-SILICO; COMPUTATIONAL DESIGN; BIOCHEMICAL NETWORKS; EXPRESSION PROFILES; TRANSCRIPTIONAL REGULATION; KNOCKOUT SIMULATION; OBJECTIVE FUNCTIONS	The development of the technology to synthesize new genomes and to introduce them into hosts with inactivated wild-type chromosome opens the door to new horizons in synthetic biology. Here it is of outmost importance to harness the ability of using computational design to predict and optimize a synthetic genome before attempting its synthesis. The methodology to computationally design a genome is based on an optimization that computationally mimics genome evolution. The biggest bottleneck lies on the use of an appropriatetness function. This fitness function, usually cell growth, relies on the ability to quantitatively model the biochemical networks of the cell at the genome scale using parameters inferred from high-throughput data. Computational methods integrating such models in a common multilayer design platform can be used to automatically engineer synthetic genomes under physiological specifications. We describe the current state-of-the-art on automated methods for engineering or re-engineering synthetic genomes. We restrict ourselves to global models of metabolism, transcription and DNA structure. Although we are still far from the de novo computational genome design, it is important to collect all relevant work towards this goal. Finally, we discuss future perspectives about the practicability of an automated methodology for such computational design of synthetic genomes.	[Carrera, Javier; Rodrigo, Guillermo; Jaramillo, Alfonso] Genopole Univ Evry Val Essonne, CNRS, UPS 3201, Synth Bio Grp,Epigenom Project, F-91034 Evry, France; [Carrera, Javier; Rodrigo, Guillermo] Univ Politecn Valencia, CSIC, Inst Biol Mol & Celular Plantas, Valencia 46022, Spain; [Carrera, Javier] Univ Politecn Valencia, Inst ITACA, Valencia 46022, Spain; [Jaramillo, Alfonso] Ecole Polytech, CNRS, UMR 7654, Biochim Lab, F-91128 Palaiseau, France	Jaramillo, A (reprint author), Genopole Univ Evry Val Essonne, CNRS, UPS 3201, Synth Bio Grp,Epigenom Project, F-91034 Evry, France.	Alfonso.Jaramillo@polytechnique.fr	Jaramillo, Alfonso/G-4257-2013	Jaramillo, Alfonso/0000-0002-6313-9689	Spanish Ministry of Education and Science [TIN-2006-12860]; Structural Funds of the European Regional Development Fund (ERDF); HPC-Europa programme (RII3-CT2003-506079); TIGE Genopole/UEVE; EU [FP6-NEST-043340]; EMERGENCE [FP6-NEST-043338]; TARPOL [FP7-KBBE-212894]; Generalitat Valenciana [BFPI-2007-160]; EMBO [ASTF-343-2007]	This work was supported by the fellowship from the Spanish Ministry of Education and Science (TIN-2006-12860), the Structural Funds of the European Regional Development Fund (ERDF), the HPC-Europa programme (RII3-CT2003-506079), the ATIGE Genopole/UEVE grant, and the EU grants BioModularH2 (FP6-NEST-043340), EMERGENCE (FP6-NEST-043338) and TARPOL (FP7-KBBE-212894). G. R. acknowledges a graduate fellowship from the Generalitat Valenciana (BFPI-2007-160) and an EMBO short-term fellowship (ASTF-343-2007). We are very thankful to Joan Herisson for insightful comments and for providing Fig. 5.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Faith JJ, 2008, NUCLEIC ACIDS RES, V36, pD866, DOI 10.1093/nar/gkm815; Margolin AA, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S7; Covert MW, 2008, BIOINFORMATICS, V24, P2044, DOI 10.1093/bioinformatics/btn352; Yu J, 2004, BIOINFORMATICS, V20, P3594, DOI 10.1093/bioinformatics/bth448; Francois P, 2004, P NATL ACAD SCI USA, V101, P580, DOI 10.1073/pnas.0304532101; Kuchner O, 1997, TRENDS BIOTECHNOL, V15, P523, DOI 10.1016/S0167-7799(97)01138-4; Stelling J, 2002, NATURE, V420, P190, DOI 10.1038/nature01166; Yeung MKS, 2002, P NATL ACAD SCI USA, V99, P6163, DOI 10.1073/pnas.092576199; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Schomburg I, 2002, NUCLEIC ACIDS RES, V30, P47, DOI 10.1093/nar/30.1.47; Martin VJJ, 2003, NAT BIOTECHNOL, V21, P796, DOI 10.1038/nbt833; Hatzimanikatis V, 2005, BIOINFORMATICS, V21, P1603, DOI 10.1093/bioinformatics/bti213; Kolesov G, 2007, P NATL ACAD SCI USA, V104, P13948, DOI 10.1073/pnas.0700672104; Burgard AP, 2004, GENOME RES, V14, P301, DOI 10.1101/gr.1926504; Lee SJ, 2005, APPL ENVIRON MICROB, V71, P7880, DOI 10.1128/AEM.71.12.7880-7887.2005; Segre D, 2002, P NATL ACAD SCI USA, V99, P15112, DOI 10.1073/pnas.232349399; Covert MW, 2003, J THEOR BIOL, V221, P309, DOI 10.1006/jtbi.2003.3071; Edwards JS, 2001, NAT BIOTECHNOL, V19, P125, DOI 10.1038/84379; Rothlisberger D, 2008, NATURE, V453, P190, DOI 10.1038/nature06879; Bonneau R, 2007, CELL, V131, P1354, DOI 10.1016/j.cell.2007.10.053; Pfleger BF, 2006, NAT BIOTECHNOL, V24, P1027, DOI 10.1038/nbt1226; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Bansal M, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100120; Gibson DG, 2008, SCIENCE, V319, P1215, DOI 10.1126/science.1151721; De Jong H, 2002, J COMPUT BIOL, V9, P67, DOI 10.1089/10665270252833208; Eppstein D, 1998, SIAM J COMPUT, V28, P652, DOI 10.1137/S0097539795290477; Oh YK, 2007, J BIOL CHEM, V282, P28791, DOI 10.1074/jbc.M703759200; Barrett T, 2007, NUCLEIC ACIDS RES, V35, pD760, DOI 10.1093/nar/gkl887; Bansal M, 2006, BIOINFORMATICS, V22, P815, DOI 10.1093/bioinformatics/btl003; Efron B, 2004, ANN STAT, V32, P407; Burgard AP, 2003, BIOTECHNOL BIOENG, V84, P647, DOI 10.1002/bit.10803; Alper H, 2005, NAT BIOTECHNOL, V23, P612, DOI 10.1038/nbt1083; Sauer U, 2006, MOL SYST BIOL, V2, DOI 10.1038/msb4100109; Thieffry D, 1998, BIOESSAYS, V20, P433, DOI 10.1002/(SICI)1521-1878(199805)20:5<433::AID-BIES10>3.0.CO;2-2; Tavazoie S, 1999, NAT GENET, V22, P281; Sprinzak D, 2005, NATURE, V438, P443, DOI 10.1038/nature04335; Forster J, 2003, GENOME RES, V13, P244, DOI 10.1101/gr.234503; SCHAAFF I, 1989, YEAST, V5, P285, DOI 10.1002/yea.320050408; Edwards JS, 2000, P NATL ACAD SCI USA, V97, P5528, DOI 10.1073/pnas.97.10.5528; Arita M, 2004, P NATL ACAD SCI USA, V101, P1543, DOI 10.1073/pnas.0306458101; BAILEY JE, 1991, SCIENCE, V252, P1668, DOI 10.1126/science.2047876; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Bennett MR, 2008, NATURE, V454, P1119, DOI 10.1038/nature07211; Bindewald E, 2008, J MOL GRAPH MODEL, V27, P299, DOI 10.1016/j.jmgm.2008.05.004; Blight KJ, 2000, SCIENCE, V290, P1972, DOI 10.1126/science.290.5498.1972; Blum T, 2008, BIOINFORMATICS, V24, P2108, DOI 10.1093/bioinformatics/btn360; Bonneau R, 2008, NAT CHEM BIOL, V4, P658, DOI 10.1038/nchembio.122; Bonneau R, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-5-r36; Burgard AP, 2003, BIOTECHNOL BIOENG, V82, P670, DOI 10.1002/bit.10617; Butte A J, 2000, Pac Symp Biocomput, P418; Carlson Robert, 2003, Biosecur Bioterror, V1, P203, DOI 10.1089/153871303769201851; Carrera J, 2009, NUCLEIC ACIDS RES, V37, DOI 10.1093/nar/gkp022; Cello J, 2002, SCIENCE, V297, P1016, DOI 10.1126/science.1072266; Covert MW, 2004, NATURE, V429, P92, DOI 10.1038/nature02456; Covert MW, 2001, TRENDS BIOCHEM SCI, V26, P179, DOI 10.1016/S0968-0004(00)01754-0; Croes D, 2005, NUCLEIC ACIDS RES, V33, pW326, DOI 10.1093/nar/gki437; Dasika MS, 2006, BIOPHYS J, V91, P382, DOI 10.1529/biophysj.105.069724; Dasika MS, 2008, BMC SYST BIOL, V2, DOI 10.1186/1752-0509-2-24; di Bernardo D, 2005, NAT BIOTECHNOL, V23, P377, DOI 10.1038/nbt1075; Emmerling M, 2002, J BACTERIOL, V184, P152, DOI 10.1128/JB.184.1.152-164.2002; Endy D, 2008, SCIENCE, V319, P1196, DOI 10.1126/science.1155749; Faith JJ, 2007, PLOS BIOL, V5, P54, DOI 10.1371/journal.pbio.0050008; Feist AM, 2009, NAT REV MICROBIOL, V7, P129, DOI 10.1038/nrmicro1949; Feist AM, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100155; Forster AC, 2006, MOL SYST BIOL, V2, DOI 10.1038/msb4100090; FU P, 2009, J CHEM TECHNOL BIOT, V84, P789; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Gollub J, 2003, NUCLEIC ACIDS RES, V31, P94, DOI 10.1093/nar/gkg078; Handorf T, 2007, NUCLEIC ACIDS RES, V35, pW613, DOI 10.1093/nar/gkm287; Haro MA, 2001, J BIOTECHNOL, V85, P103, DOI 10.1016/S0168-1656(00)00367-9; HERISSON J, 2007, CELL MOL BIOL, V52, P24; HLAVACEK WS, 2006, SCI STKE, V344, pR6; Hou BK, 2003, J CHEM INF COMP SCI, V43, P1051, DOI 10.1021/ci034018f; Hyland C, 2006, NUCLEIC ACIDS RES, V34, pW725, DOI 10.1093/nar/gkl196; Isalan M, 2008, NATURE, V452, P840, DOI 10.1038/nature06847; Jiang L, 2008, SCIENCE, V319, P1387, DOI 10.1126/science.1152692; Karp PD, 2007, NUCLEIC ACIDS RES, V35, P7577, DOI 10.1093/nar/gkm740; Karp PD, 2005, NUCLEIC ACIDS RES, V33, P6083, DOI 10.1093/nar/gki892; Kodumal SJ, 2004, P NATL ACAD SCI USA, V101, P15573, DOI 10.1073/pnas.0406911101; Lartigue C, 2007, SCIENCE, V317, P632, DOI 10.1126/science.1144622; Leduc M, 2006, BIOPROC BIOSYST ENG, V28, P295, DOI 10.1007/s00449-005-0034-z; Li CH, 2004, CHEM ENG SCI, V59, P5051, DOI 10.1016/j.ces.2004.09.021; Marchisio MA, 2008, BIOINFORMATICS, V24, P1903, DOI 10.1093/bioinformatics/btn330; Martinez-Antonio A, 2006, TRENDS MICROBIOL, V14, P22, DOI 10.1016/j.tim.2005.11.002; Mason J, 2004, CHAOS, V14, P707, DOI 10.1063/1.1786683; Mehta P, 2008, MOL SYST BIOL, V4, DOI 10.1038/msb.2008.58; Lee JM, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000086; Murty K.G, 1983, LINEAR PROGRAMMING; Gombert AK, 2000, CURR OPIN BIOTECH, V11, P180, DOI 10.1016/S0958-1669(00)00079-3; Nogales J, 2008, BMC SYST BIOL, V2, DOI 10.1186/1752-0509-2-79; Noirel J, 2008, BIOINFORMATICS, V24, P2792, DOI 10.1093/bioinformatics/btn499; Paladugu SR, 2006, IEE P SYST BIOL, V153, P223, DOI 10.1049/ip-syb:20050096; Palsson B, 2002, NAT BIOTECHNOL, V20, P649, DOI 10.1038/nbt0702-649; Papin JA, 2002, GENOME RES, V12, P1889, DOI 10.1101/gr.327702; Park JH, 2007, P NATL ACAD SCI USA, V104, P7797, DOI 10.1073/pnas.0702609104; Pazos F, 2005, NUCLEIC ACIDS RES, V33, pD588, DOI 10.1093/nar/gki068; Pharkya P, 2004, GENOME RES, V14, P2367, DOI 10.1101/gr.2872004; Puchalka J, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000210; Reiss DJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-280; Richardson SM, 2006, GENOME RES, V16, P550, DOI 10.1101/gr.4431306; Rodrigo G, 2007, BIOINFORMATICS, V23, P1857, DOI 10.1093/bioinformatics/btm237; Rodrigo G, 2008, BIOINFORMATICS, V24, P2554, DOI 10.1093/bioinformatics/btn471; Salgado H, 2006, NUCLEIC ACIDS RES, V34, pD394, DOI 10.1093/nar/gkj156; Schilling CH, 1999, BIOTECHNOL PROGR, V15, P296, DOI 10.1021/bp990048k; Schuetz R, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100162; Schuster S, 1999, TRENDS BIOTECHNOL, V17, P53, DOI 10.1016/S0167-7799(98)01290-6; Shlomi T, 2005, P NATL ACAD SCI USA, V102, P7695, DOI 10.1073/pnas.0406346102; SHLONI T, 2007, MOL SYST BIOL, V3, P10; SMITH HO, 2003, P NATL ACAD SCI U S, V100; Steinke F, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-51; Stephanopoulos Gregory, 1994, Current Opinion in Biotechnology, V5, P196, DOI 10.1016/S0958-1669(05)80036-9; Sterner R, 2008, CHEM BIOL, V15, P421, DOI 10.1016/j.chembiol.2008.04.007; Suarez M, 2009, J R SOC INTERFACE, V6, DOI 10.1098/rsif.2008.0508.focus; Suarez M, 2008, J COMPUT CHEM, V29, P2704, DOI 10.1002/jcc.20981; Suthers PF, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000285; Tagkopoulos I, 2008, SCIENCE, V320, P1313, DOI 10.1126/science.1154456; Takahashi K, 2003, BIOINFORMATICS, V19, P1727, DOI 10.1093/bioinformatics/btg221; Tegner J, 2003, P NATL ACAD SCI USA, V100, P5944, DOI 10.1073/pnas.0933416100; Tomita M, 1999, BIOINFORMATICS, V15, P72, DOI 10.1093/bioinformatics/15.1.72; VARMA A, 1994, BIO-TECHNOL, V12, P994, DOI 10.1038/nbt1094-994; Wall ME, 2004, NAT REV GENET, V5, P34, DOI 10.1038/nrg1244	122	13	14	0	6	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	1742-206X			MOL BIOSYST	Mol. Biosyst.		2009	5	7					733	743		10.1039/b904400k		11	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	463NR	WOS:000267439400007	19562112	
J	Ioannidis, A; Nicolaou, C; Chatzipanagiotou, S				Ioannidis, Anastassios; Nicolaou, Chrysoula; Chatzipanagiotou, Stylianos			Correlation Between Flagellin A (flaA) Genotypes and Antimicrobial Susceptibility Patterns of Campylobacter jejuni Strains Isolated from Children with Gastroenteritis in Athens, Greece	MOLECULAR DIAGNOSIS & THERAPY			English	Article							FIELD GEL-ELECTROPHORESIS; ANTIBIOTIC-RESISTANCE; POULTRY; SPP.; FECES	Background and Objective: Campylobacter jejuni is one of the most common enteric pathogens worldwide. The bacterium is transmitted to humans via contaminated food and water. In the majority of cases the disease is self-limiting, but treatment is indicated in immunocompromised patents, in severe cases with septicemia, and in children. The subtyping of clinical, animal, and food C. jejuni isolates is very important for epidemiological studies. In the present Study, 192 Campylobacter jejuni isolates characterized by pulsed-field gel electrophoresis (PFGE) of SmaI digested genomic DNA were further examined with respect to their antimicrobial resistance and their flagellin A (flaA) genotypes in order to disclose any correlation between a certain flaA type and a specific antimicrobial susceptibility pattern. Methods: C. jejuni clinical isolates were collected from infected children up to 14 years of age from five general hospitals in the area of Attica, Greece, during the period 2004-7. C. jejuni strain isolation and identification from stool samples were performed by conventional bacteriological methods. Sinal restriction fragments were prepared as described previously for the PFGE analysis. Antimicrobial susceptibility was tested and interpreted by determination of the minimal inhibitory concentration (MIC) by use of the agar dilution method as described by the Clinical Laboratory Standards Institute. flaA typing was performed by PCR amplification of the corresponding gene, and the product was digested with DdeI and visualized by agarose gel electrophoresis. Data were analyzed using the software Gene Profiler 1-D Gel Analysis and Data Basing for Windows (R). Results: A statistically significant correlation between certain flaA genotypes (flaA 17 Greece [GR], flaA 19 GR and flaA 39 GR) and resistance to some antimicrobial agents (ampicillin, amoxicillin/clavulinic acid [co-amoxiclav], erythromycin, nalidixic acid, and ciprofloxacin) was detected in C. jejuni strains isolated from infected children. Conclusions: Further investigations on a molecular basis are warranted in order to clarify whether certain C. jejuni flaA types are associated with specific antimicrobial resistance attributes.	[Ioannidis, Anastassios; Nicolaou, Chrysoula; Chatzipanagiotou, Stylianos] Univ Athens, Dept Clin Microbiol, Aeginit Hosp, Athens Med Sch, Athens, Greece	Chatzipanagiotou, S (reprint author), Aeginit Hosp, Athens Med Sch, Dept Biopathol & Clin Microbiol, Vass Sophias Av 72-74, Athens 11528, Greece.	schatzi@med.uoa.gr			European Social; National Resources	The project was co-funded by the European Social Fund and National Resources (EPEAEK II, PYTHAGORAS II). The authors have no conflicts of interest that are directly relevant to the content of this study.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wassenaar TM, 2000, APPL ENVIRON MICROB, V66, P1; Cardinale E, 2006, J APPL MICROBIOL, V100, P209, DOI 10.1111/j.1365-2672.2005.02763.x; Chatzipanagiotou S, 2002, J ANTIMICROB CHEMOTH, V49, P803, DOI 10.1093/jac/dkf002; CLSI, 2009, M07A8 CLSI, V29; Corcoran D, 2006, LETT APPL MICROBIOL, V43, P560, DOI 10.1111/j.1472-765X.2006.01987.x; DOYLE MP, 1991, COLONIZATION CONTROL, P121; Gu WM, 2009, APPL ENVIRON MICROB, V75, P474, DOI 10.1128/AEM.02012-08; Guarino A, 2008, J PEDIATR GASTR NUTR, V46, pS81, DOI 10.1097/MPG.0b013e31816f7b16; Harrington CS, 1997, J CLIN MICROBIOL, V35, P2386; Ioannidis A, 2006, EUR J EPIDEMIOL, V21, P823, DOI 10.1007/s10654-006-9073-2; Ioannidis A, 2006, MOL DIAGN THER, V10, P391; Nachamkin I, 1996, J CLIN MICROBIOL, V34, P277; Peters TM, 2009, METHODS MOL BIOL, V551, P59, DOI 10.1007/978-1-60327-999-4_6; REINA J, 1995, J ANTIMICROB CHEMOTH, V35, P351, DOI 10.1093/jac/35.2.351; REINA J, 1994, ANTIMICROB AGENTS CH, V38, P2917; Rudi K, 2004, APPL ENVIRON MICROB, V70, P790, DOI 10.1128/AEM.70.2.790-797.2004; Stern NJ, 2002, AVIAN DIS, V46, P401, DOI 10.1637/0005-2086(2002)046[0401:EODWCO]2.0.CO;2; Ternhag A, 2007, CLIN INFECT DIS, V44, P696, DOI 10.1086/509924; Wittwer M, 2005, APPL ENVIRON MICROB, V71, P2840, DOI 10.1128/AEM.71.6.2840-2847.2005; Yang JR, 2008, BMC INFECT DIS, V8, DOI 10.1186/1471-2334-8-151	21	2	2	2	2	ADIS INT LTD	AUCKLAND	41 CENTORIAN DR, PRIVATE BAG 65901, MAIRANGI BAY, AUCKLAND 1311, NEW ZEALAND	1177-1062			MOL DIAGN THER	Mol. Diagn. Ther.		2009	13	6					389	395				7	Genetics & Heredity; Pharmacology & Pharmacy	Genetics & Heredity; Pharmacology & Pharmacy	537IB	WOS:000273105400006	19925037	
J	Gao, JB; Kwan, PW; Guo, Y				Gao, Junbin; Kwan, Paul W.; Guo, Yi			Robust multivariate L1 principal component analysis and dimensionality reduction	NEUROCOMPUTING			English	Article						Robust L1 PCA; EM algorithm; Dimensionality reduction	VARIATIONAL INFERENCE	Further to our recent work on the robust L1 PCA we introduce a new version of robust PCA model based on the so-called multivariate Laplace distribution (called L1 distribution) proposed in Eltoft et al. [2006. On the multivariate Laplace distribution. IEEE Signal Process. Lett. 13(5), 300-303]. Due to the heavy tail and high component dependency characteristics of the multivariate L1 distribution, the proposed model is expected to be more robust against data outliers and fitting component dependency. Additionally. we demonstrate how a variational approximation scheme enables effective inference of key parameters in the probabilistic multivariate L1-PCA model. By doing so, a tractable Bayesian inference can be achieved based on the variational EM-type algorithm. (C) 2008 Elsevier B.V. All rights reserved.	[Gao, Junbin] Charles Sturt Univ, Sch Comp Sci, Bathurst, NSW 2795, Australia; [Kwan, Paul W.; Guo, Yi] Univ New England, Sch Sci & Technol, Armidale, NSW 2351, Australia	Gao, JB (reprint author), Charles Sturt Univ, Sch Comp Sci, Bathurst, NSW 2795, Australia.	jbgao@csu.edu.au; kwan@turing.une.edu.au; yguo4@turing.une.edu.au	Guo, Yi/B-3594-2010				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Baccini A, 1996, ST CLASS DAT ANAL, P359; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Gao JB, 2008, NEURAL COMPUT, V20, P555, DOI 10.1162/neco.2007.11-06-397; ARCHAMBEAU C, 2005, TEHSIS U CATHOLIQUE; Archambeau C., 2006, P 23 INT C MACH LEAR; DELATORRE F, 2001, INT C COMPUTER VISIO, V52, P362; Ding C., 2006, P 23 INT C MACH LEAR; Eltoft T, 2006, IEEE SIGNAL PROC LET, V13, P300, DOI 10.1109/LSP.2006.870353; GUO Y, 2008, IEEE T PATT IN PRESS; Ke Q., 2005, P CVPR, P739, DOI 10.1109/CVPR.2005.309; KHAN Z, 2004, GITGVU0411; Ng A. Y., 2004, P INT C MACH LEARN; Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081; PONTIL M, 1998, 1651 MIT AL LAB; RIDDER DD, 2003, BMVC 2003, P319; RUBIN D, 2006, ENCY STAT SCI, V4, P272; RUYMGAART FH, 1981, J MULTIVARIATE ANAL, V11, P485, DOI 10.1016/0047-259X(81)90091-9; Tipping M, 1999, J ROYAL STAT SOC B, V61, P611; Tipping ME, 2005, NEUROCOMPUTING, V69, P123, DOI 10.1016/j.neucom.2005.02.016	20	3	3	2	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	JAN	2009	72	4-6			SI		1242	1249		10.1016/j.neucom.2008.01.027		8	Computer Science, Artificial Intelligence	Computer Science	407NQ	WOS:000263372000059		
J	Carroll, MK; Cecchi, GA; Rish, I; Garg, R; Rao, AR				Carroll, Melissa K.; Cecchi, Guillermo A.; Rish, Irina; Garg, Rahul; Rao, A. Ravishankar			Prediction and interpretation of distributed neural activity with sparse models	NEUROIMAGE			English	Article							RESONANCE-IMAGING FMRI; VARIABLE SELECTION; WORKING-MEMORY; REGRESSION; CORTEX; LASSO	We explore to what extent the combination of predictive and interpretable modeling can provide new insights for functional brain imaging. For this, we apply a recently introduced regularized regression technique, the Elastic Net, to the analysis of the PBAIC 2007 competition data. Elastic Net regression controls via one parameter the number of voxels in the resulting model, and via another the degree to which correlated voxels are included. We find that this method produces highly predictive models of fMRI data that provide evidence for the distributed nature of neural function. We also use the flexibility of Elastic Net to demonstrate that model robustness can be improved without compromising predictability, in turn revealing the importance of localized clusters of activity. Our findings highlight the functional significance of patterns of distributed clusters of localized activity, and underscore the importance of models that are both predictive and interpretable. (C) 2008 Elsevier Inc. All rights reserved.	[Cecchi, Guillermo A.; Rish, Irina; Garg, Rahul; Rao, A. Ravishankar] IBM Corp, Thomas J Watson Res Ctr, Computat Biol Ctr, Yorktown Hts, NY 10598 USA; [Carroll, Melissa K.] Princeton Univ, Dept Comp Sci, Princeton, NJ 08540 USA	Cecchi, GA (reprint author), IBM Corp, Thomas J Watson Res Ctr, Computat Biol Ctr, Yorktown Hts, NY 10598 USA.	gcecchi@us.ibm.com					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; Cox DD, 2003, NEUROIMAGE, V19, P261, DOI 10.1016/S1053-8119(03)00049-1; FORMAN SD, 1995, MAGNET RESON MED, V33, P636, DOI 10.1002/mrm.1910330508; Callicott JH, 1999, CEREB CORTEX, V9, P20, DOI 10.1093/cercor/9.1.20; Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005; Calhoun V. D., 2003, 4 INT S IND COMP AN; CHIGIREV D, 2006, 12 HBM M FLOR IT; de Fockert JW, 2001, SCIENCE, V291, P1803, DOI 10.1126/science.1056496; Hoerl A., 1988, ENCY STAT SCI, V8, P129; Okabe A., 2000, SPATIAL TESSELATIONS; *PITTSB EBC GROUP, 2007, PBAIC HOM; Sjostrand K., 2005, MATLAB IMPLEMENTATIO; Ulfarsson MO, 2007, I S BIOMED IMAGING, P460, DOI 10.1109/ISBI.2007.356888; Weisberg S., 1980, APPL LINEAR REGRESSI	21	72	72	0	7	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119			NEUROIMAGE	Neuroimage	JAN 1	2009	44	1					112	122		10.1016/j.neuroimage.2008.08.020		11	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	392KF	WOS:000262300900012	18793733	
J	Lipovetsky, S				Lipovetsky, Stan			PCA and SVD with nonnegative loadings	PATTERN RECOGNITION			English	Article						Principal component analysis; Singular value decomposition; Exponential; Logit; Multinomial parameterization; Positive and sparse loadings; Perron-Frobenius theory	SINGULAR-VALUE DECOMPOSITION; PRINCIPAL COMPONENT ANALYSIS; MATRIX FACTORIZATION; RIDGE-REGRESSION; LEAST-SQUARES; LASSO	Principal component analysis (PCA) and Singular Value decomposition (SVD) are widely used in multivariate statistical analysis for data reduction. The work considers exponential, logic, and multinomial parameterization of the eigenvectors' elements that always yields nonnegative loadings of shares for variable aggregation. In contrast to regular PCA and SVD, matrix decomposition by the positive shares shows explicitly which variables and with which percent are composed into each group, so what is each variable Contribution to data approximation. The least Squares objective of matrix fit is reduced to Rayleigh quotient for variational description of the eigenvalues. Eigenvectors with the nonlinear parameterization can be found in Newton - Raphson optimizing procedure. Numerical examples compare the classical and nonnegative loadings results, with interpretation by the Perron-Frobenius theory for each subset of variables identified by sparse loading vectors. (C) 2008 Elsevier Ltd. All rights reserved.	GfK Custom Res N Amer, Minneapolis, MN 55427 USA	Lipovetsky, S (reprint author), GfK Custom Res N Amer, 8401 Golden Valley Rd, Minneapolis, MN 55427 USA.	stan.lipovetsky@gfk.com					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fogel P, 2007, BIOINFORMATICS, V23, P44, DOI 10.1093/bioinformatics/btl550; Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; Pauca VP, 2006, LINEAR ALGEBRA APPL, V416, P29, DOI 10.1016/j.laa.2005.06.025; Drineas P, 2004, MACH LEARN, V56, P9, DOI 10.1023/B:MACH.0000033113.59016.96; Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; [Anonymous], 1999, S PLUS 2000; Efron B, 2004, ANN STAT, V32, P407; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Pearson K, 1901, PHILOS MAG, V2, P559; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; BELLMAN R., 1960, INTRO MATRIX ANAL; Berry M. W., 2005, Computational & Mathematical Organization Theory, V11, DOI 10.1007/s10588-005-5380-5; Bishop C., 2006, PATTERN RECOGNITION; CARRE A, 1986, J MACROMOL SCI CHEM, VA23, P1, DOI 10.1080/00222338608063372; Chambers J. M., 1992, STAT MODELS S; Clogg Clifford C., 1995, HDB STAT MODELING SO, DOI New York; Elden L, 2007, FUND ALGORITHMS, V4, pIX; Gantmacher F. R., 1959, APPL THEORY MATRICES; Golub G., 1996, MATRIX COMPUTATIONS; Harville DA, 1997, MATRIX ALGEBRA STAT; Hastie T., 2001, ELEMENTS STAT LEARNI; Hochstenbach ME, 2004, BIT, V44, P721, DOI 10.1007/s10543-004-5244-2; Hotelling H, 1936, PSYCHOMETRIKA, V1, P27, DOI 10.1007/BF02287921; KACIAK E, 1990, J MARKETING RES, V27, P455, DOI 10.2307/3172630; Kazantsev S.G., 2004, J INVERSE ILL-POSE P, V12, P245, DOI 10.1163/1569394042215865; LEVI Y, 2006, MOL PHYS, V104, P1227; Lipovetsky S., 2007, J MODERN APPL STAT M, V6, P219; Lipovetsky S, 2005, J MOD APPL STAT METH, V4, P63; Lipovetsky S, 2007, MODEL ASSISTED STAT, V2, P71; Lipovetsky S, 2002, APPL STOCH MODEL BUS, V18, P347, DOI 10.1002/asmb.462; Lipovetsky S, 2005, PATTERN RECOGN, V38, P1099, DOI 10.1016/j.patcog.2005.01.010; Lipovetsky S, 2006, MATH COMPUT MODEL, V44, P304, DOI 10.1016/j.mcm.2006.01.017; LIPOVETSKY S, 1994, MULTIPLE CRITERIA DE, P275; Lynn HS, 2000, J AM STAT ASSOC, V95, P561, DOI 10.2307/2669399; Marcus M., 1964, SURVEY MATRIX THEORY; McCullagh P, 1997, GEN LINEAR MODELS; Pavoine S, 2004, J THEOR BIOL, V228, P523, DOI 10.1016/j.jtbi.2004.02.014; Rousson V, 2004, J ROY STAT SOC C-APP, V53, P539, DOI 10.1111/j.1467-9876.2004.05359.x; Salton G. M., 1988, AUTOMATIC TEXT PROCE; SHUGAN SM, 1987, J MARKETING RES, V24, P1, DOI 10.2307/3151749; Sinha I, 1998, J MARKETING RES, V35, P236, DOI 10.2307/3151851; STEENKAMP JBEM, 1994, J MARKETING RES, V31, P15, DOI 10.2307/3151943; Weingessel Andreas, 2003, Int J Neural Syst, V13, P307, DOI 10.1142/S0129065703001650; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	48	11	12	1	6	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	JAN	2009	42	1					68	76		10.1016/j.patcog.2008.06.025		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	365WB	WOS:000260439000007		
S	Raman, S; Roth, V		Denzler, J; Notni, G; Sube, H		Raman, Sudhir; Roth, Volker			Sparse Bayesian Regression for Grouped Variables in Generalized Linear Models	PATTERN RECOGNITION, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	31st DAGM Symposium on Pattern Recognition	SEP 09-11, 2009	Jena, GERMANY	OLYMPUS Europe Fdn Sci Life, STIFT Thuringia, MVTec Software GmbH, Telekom Lab, Allied Vis Technol, Desko GmbH, Jenoptik AG, Optonet e V			LASSO	A fully Bayesian framework for sparse regression in generalized linear models is introduced. Assuming that a natural group structure exists on the domain of predictor variables, sparsity conditions are applied to these variable groups in order to be able to explain the observations with simple and interpretable models. We introduce a general family of distributions which imposes a flexible amount of sparsity on variable groups. This model overcomes the problems associated with insufficient sparsity of traditional selection methods in high-dimensional spaces. The fully Bayesian inference mechanism allows us to quantify the uncertainty in the regression coefficient estimates. The general nature of the framework makes it applicable to a wide variety of generalized linear models with minimal modifications. An efficient MCMC algorithm is presented to sample from the posterior. Simulated experiments validate the strength of this new class of sparse regression models. When applied to the problem of splice site prediction on DNA sequence data, the method identifies key interaction terms of sequence positions which help in identifying "true" splice sites.	[Raman, Sudhir; Roth, Volker] Univ Basel, Dept Comp Sci, CH-4056 Basel, Switzerland	Raman, S (reprint author), Univ Basel, Dept Comp Sci, Bernoullistr 16, CH-4056 Basel, Switzerland.	sudhir.raman@unibas.ch; volker.roth@unibas.ch					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Meier L, 2008, J R STAT SOC B, V70, P53; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; Yeo G, 2004, J COMPUT BIOL, V11, P377, DOI 10.1089/1066527041410418; CARON F, 2008, ICML 2008, V1, P88; EVERITT BS, 1997, ANAL CONTINGENCY TAB; Figueiredo M. A. T., 2001, P IEEE INT C COMP VI, V1, P35; Fink D., 1995, COMPENDIUM CONJUGATE; Gelman A., 1995, BAYESIAN DATA ANAL; Green PE, 2004, STAT PAP, V45, P33, DOI 10.1007/BF02778268; MCCULLAGHAND P, 1983, GEN LINEAR MODELS; Raftery A., 1992, STAT SCI, V7, P493, DOI DOI 10.1214/SS/1177011143; ROTH V., 2008, ICML, P848; Seshadri V., 1993, INVERSE GAUSSIAN DIS; Yuan ZH, 2006, SCI CHINA SER B, V49, P67, DOI 10.1007/s11426-004-0106-y	16	2	2	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-03797-9	LECT NOTES COMPUT SC			2009	5748						242	251				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPK79	WOS:000279102000025		
J	Lee, SI; Dudley, AM; Drubin, D; Silver, PA; Krogan, NJ; Pe'er, D; Koller, D				Lee, Su-In; Dudley, Aimee M.; Drubin, David; Silver, Pamela A.; Krogan, Nevan J.; Pe'er, Dana; Koller, Daphne			Learning a Prior on Regulatory Potential from eQTL Data	PLOS GENETICS			English	Article							CYTOPLASMIC PROCESSING BODIES; SINGLE-NUCLEOTIDE POLYMORPHISMS; QUANTITATIVE TRAIT LOCUS; SACCHAROMYCES-CEREVISIAE; GENE-EXPRESSION; MESSENGER-RNAS; TRANSCRIPTION FACTORS; GENOMICS APPROACH; GLOBAL ANALYSIS; BUDDING YEAST	Genome-wide RNA expression data provide a detailed view of an organism's biological state; hence, a dataset measuring expression variation between genetically diverse individuals (eQTL data) may provide important insights into the genetics of complex traits. However, with data from a relatively small number of individuals, it is difficult to distinguish true causal polymorphisms from the large number of possibilities. The problem is particularly challenging in populations with significant linkage disequilibrium, where traits are often linked to large chromosomal regions containing many genes. Here, we present a novel method, Lirnet, that automatically learns a regulatory potential for each sequence polymorphism, estimating how likely it is to have a significant effect on gene expression. This regulatory potential is defined in terms of "regulatory features''-including the function of the gene and the conservation, type, and position of genetic polymorphisms-that are available for any organism. The extent to which the different features influence the regulatory potential is learned automatically, making Lirnet readily applicable to different datasets, organisms, and feature sets. We apply Lirnet both to the human HapMap eQTL dataset and to a yeast eQTL dataset and provide statistical and biological results demonstrating that Lirnet produces significantly better regulatory programs than other recent approaches. We demonstrate in the yeast data that Lirnet can correctly suggest a specific causal sequence variation within a large, linked chromosomal region. In one example, Lirnet uncovered a novel, experimentally validated connection between Puf3-a sequence-specific RNA binding protein-and P-bodies-cytoplasmic structures that regulate translation and RNA stability as well as the particular causative polymorphism, a SNP in Mkt1, that induces the variation in the pathway.	[Lee, Su-In; Koller, Daphne] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Dudley, Aimee M.] Inst Syst Biol, Seattle, WA USA; [Drubin, David; Silver, Pamela A.] Harvard Univ, Sch Med, Dept Syst Biol, Boston, MA USA; [Krogan, Nevan J.] Univ Calif San Francisco, Dept Mol & Cellular Pharmacol, San Francisco, CA 94143 USA; [Pe'er, Dana] Columbia Univ, Dept Biol Sci, New York, NY 10027 USA	Lee, SI (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	koller@cs.stanford.edu		Pe'er, Dana/0000-0002-9259-8817; Dudley, Aimee/0000-0003-3644-0625	NIH/NHGRI Genome Scholar/Faculty Transition; U. S. Department of Energy Genomes to Life; National Science Foundation [DBI-0345474]; Burroughs Welcome Fund CASI; NIGMS Center of Excellence; NRSA; NIH; Sandler Family Fellowship	This work was supported by an NIH/NHGRI Genome Scholar/Faculty Transition award and U. S. Department of Energy Genomes to Life Grant (AD), National Science Foundation Award DBI-0345474 (SL and DK), Burroughs Welcome Fund CASI award and an NIGMS Center of Excellence grant (DP), an NRSA postdoctoral fellowship (DD), funding from the NIH (PS), and a Sandler Family Fellowship (NJK).	Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Stranger BE, 2007, NAT GENET, V39, P1217, DOI 10.1038/ng2142; Tu ZD, 2006, BIOINFORMATICS, V22, pE489, DOI 10.1093/bioinformatics/btl234; Brengues M, 2005, SCIENCE, V310, P486, DOI 10.1126/science.1115791; Dudley AM, 2002, P NATL ACAD SCI USA, V99, P7554, DOI 10.1073/pnas.112683499; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Steinmetz LM, 2002, NATURE, V416, P326, DOI 10.1038/416326a; Ptacek J, 2005, NATURE, V438, P679, DOI 10.1038/nature04187; Giaever G, 2002, NATURE, V418, P387, DOI 10.1038/nature00935; Schuldiner M, 2005, CELL, V123, P507, DOI 10.1016/j.cell.2005.08.031; MacIsaac KD, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-113; Collins SR, 2007, NATURE, V446, P806, DOI 10.1038/nature05649; Man O, 2007, NAT GENET, V39, P415, DOI 10.1038/ng1967; Brachmann CB, 1998, YEAST, V14, P115; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; Van Driessche N, 2005, NAT GENET, V37, P471, DOI 10.1038/ng1545; Schadt EE, 2003, NATURE, V422, P297, DOI 10.1038/nature01482; Frazer KA, 2007, NATURE, V449, P851, DOI 10.1038/nature06258; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Yvert G, 2003, NAT GENET, V35, P57, DOI 10.1038/ng1222; Ashburner M, 2000, NAT GENET, V25, P25; Lyons TJ, 2000, P NATL ACAD SCI USA, V97, P7957, DOI 10.1073/pnas.97.14.7957; Deutschbauer AM, 2005, NAT GENET, V37, P1333, DOI 10.1038/ng1674; Ideker T, 2000, J COMPUT BIOL, V7, P805, DOI 10.1089/10665270050514945; Sheth U, 2003, SCIENCE, V300, P805, DOI 10.1126/science.1082320; Hu ZZ, 2007, NAT GENET, V39, P683, DOI 10.1038/ng2012; Chen YQ, 2008, NATURE, V452, P429, DOI 10.1038/nature06757; Efron B, 2004, ANN STAT, V32, P407; Brudno M, 2003, GENOME RES, V13, P721, DOI 10.1101/gr.926603; Brem RB, 2002, SCIENCE, V296, P752, DOI 10.1126/science.1069516; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; Brem RB, 2005, P NATL ACAD SCI USA, V102, P1572, DOI 10.1073/pnas.0408709102; Jiang R, 2007, AM J HUM GENET, V81, P346, DOI 10.1086/519747; Resch AM, 2007, MOL BIOL EVOL, V24, P1821, DOI 10.1093/molbev/msm100; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Schadt EE, 2005, NAT GENET, V37, P710, DOI 10.1038/ng1589; Harbison CT, 2004, NATURE, V431, P99, DOI 10.1038/nature02800; Bailey T L, 1995, Proc Int Conf Intell Syst Mol Biol, V3, P21; Bao L, 2005, BIOINFORMATICS, V21, P2185, DOI 10.1093/bioinformatics/bti365; Bernard A, 2005, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2005, P459; Bing N, 2005, GENETICS, V170, P533, DOI 10.1534/genetics.105.041103; Chua G, 2006, P NATL ACAD SCI USA, V103, P12045, DOI 10.1073/pnas.0605140103; Coller J, 2005, CELL, V122, P875, DOI 10.1016/j.cell.2005.07.019; Coller JM, 2001, RNA, V7, P1717, DOI 10.1017/S135583820101994X; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Fischer N, 2002, EMBO J, V21, P2788, DOI 10.1093/emboj/21.11.2788; Genovese CR, 2006, BIOMETRIKA, V93, P509, DOI 10.1093/biomet/93.3.509; Gerber AP, 2004, PLOS BIOL, V2, P342, DOI 10.1371/journal.pbio.0020079; HUGHES TR, 2000, CELL, V126, P102; Kulp DC, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-125; LEE SI, 2007, P INT C MACH LEARN I; Lee SI, 2006, P NATL ACAD SCI USA, V103, P14062, DOI 10.1073/pnas.0601852103; Li HQ, 2005, HUM MOL GENET, V14, P1119, DOI 10.1093/hmg/ddi124; Linding R, 2007, CELL, V129, P1415, DOI 10.1016/j.cell.2007.05.052; Liu JD, 2005, NAT CELL BIOL, V7, P719, DOI 10.1038/ncb1274; Nakamura A, 2001, DEVELOPMENT, V128, P3233; Nelson D.L., 2000, LEHNINGER PRINCIPLES; Pe'er Dana, 2002, Bioinformatics, V18 Suppl 1, pS258; Phelps C, 2006, P NATL ACAD SCI USA, V103, P7077, DOI 10.1073/pnas.0510080103; Prendergast JGD, 2007, BMC EVOL BIOL, V7, DOI 10.1186/1471-2148-7-72; Roeder K, 2006, AM J HUM GENET, V78, P243, DOI 10.1086/500026; Rottensteiner H, 1997, EUR J BIOCHEM, V247, P776, DOI 10.1111/j.1432-1033.1997.00776.x; Schadt EE, 2008, PLOS BIOL, V6, P1020, DOI 10.1371/journal.pbio.0060107; Sheff MA, 2004, YEAST, V21, P661, DOI 10.1002/yea.1130; Sheth U, 2006, CELL, V125, P1095, DOI 10.1016/j.cell.2006.04.037; Sinha H, 2006, PLOS GENET, V2, P140, DOI 10.1371/journal.pgen.0020013; Smith JJ, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb1400157; Storey JD, 2005, PLOS BIOL, V3, P1380, DOI 10.1371/journal.pbio.0030267; Suthram S, 2008, MOL SYST BIOL, V4, DOI 10.1038/msb.2008.4; SWANSON MS, 1991, MOL CELL BIOL, V11, P3009; Tadauchi T, 2004, MOL CELL BIOL, V24, P3670, DOI 10.1128/MCB.24.9.3670-3681.2004; Wapinski I, 2007, NATURE, V449, P54, DOI 10.1038/nature06107; WICKNER RB, 1987, J BACTERIOL, V169, P4941; YANG YH, 2002, NORMALIZATION CDNA M; Zhao H, 1998, J BIOL CHEM, V273, P28713, DOI 10.1074/jbc.273.44.28713; ZHU J, 2008, NAT GENET	76	102	103	2	6	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-7390			PLOS GENET	PLoS Genet.	JAN	2009	5	1							e1000358	10.1371/journal.pgen.1000358		24	Genetics & Heredity	Genetics & Heredity	447VW	WOS:000266221100040	19180192	
J	Liu, ZX; Zeng, LH				Liu, ZunXiong; Zeng, LiHui			Regularized Least Squares LDA and Its Application in Text Classification	PROCEEDING OF THE 10TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES			English	Proceedings Paper	10th International Conference on Intelligent Technologies	DEC 12-15, 2009	Guilin, PEOPLES R CHINA		Guangxi Normal Univ	LDA; linear regression; RLS-LDA	DISCRIMINANT-ANALYSIS	Linear Discriminant Analysis (LDA) is a well-known technique for dimensionality reduction and classification, while the classical LDA formulation fails when the total scatter matrix is singular, encountered usually in undersampled problems. In this paper, regularized Least Squares LDA (RLS-LDA) based on the elastic net, is proposed to handle the problems, and the resulting models are robust and sparse. Firstly, the theories about linear regression and regularization are explored, and the equivalence relationship between the least squares formulation and LDA for multi-class classifications under a mild condition is summarized. Secondly, the construction of RLS-LDA is presented. Performance evaluations of these approaches are conducted on benchmark collection of text documents. Results demonstrate the effectiveness of the proposed RLS-LDA and it's the RLS-LDA based on the elastic net that is better than others.	[Liu, ZunXiong; Zeng, LiHui] E China Jiaotong Univ, Sch Informat Engn, Nanchang, Peoples R China	Liu, ZX (reprint author), E China Jiaotong Univ, Sch Informat Engn, Nanchang, Peoples R China.	liuzunx@tom.com; wssycmissyou@163.com					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GUO Y, 2003, REGULARIZED DISCRIMI; Hastie T., 2005, MATH INTELL, V27, P83, DOI DOI 10.1007/BF02985802; YE J, 2007, P 24 INT C MACH LEAR, V227, P1087; Ye JP, 2006, J MACH LEARN RES, V7, P1183; Ye JP, 2005, J MACH LEARN RES, V6, P483; Zou H, 2005, J ROY STAT SOC B, V67, P768, DOI 10.1111/j.1467-9868.2005.00527.x	11	1	1	0	1	ASSUMPTION UNIV, FACULTY SCIENCE & TECHNOLOGY	BANGKOK	RAMKAMHAENG SOI 24, HUAMAK, BANGKAPI, BANGKOK, 10240, THAILAND							2009							206	210				5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	BPG03	WOS:000278794600042		
B	Li, K; Gormley, P; Song, SJ			IEEE	Li, Kang; Gormley, Padhraig; Song, Shiji			Application of l(rho) norm regularization methods for modelling biological systems	PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	JUL 12-15, 2009	Baoding, PEOPLES R CHINA	Hebei Univ, IEEE Syst, Man & Cybernet Soc, Chongqing Univ, S China Univ Technol, Hong Kong Baptist Univ, Hebei Univ Sci & Technol		Systems biology; molecular interaction; Lasso; Bridge; Ridge; linear-in-the-parameter model; dimensionality; regularization; MAPK signal transduction pathway	RIDGE REGRESSION; IDENTIFICATION; SELECTION; LASSO; ULTRASENSITIVITY	In systems biology, molecular interactions are typically modelled using white-box differential equations based on mass action kinetics. Unfortunately, problems with dimensionality can arise when the number of molecular species in the system becomes very large, which make the transparent modelling and behavior simulation extremely difficult or computationally too expensive. As an alternative, data-driven identification of molecular interaction pathways using a black-box approach has recently been investigated. One of the main objectives in building black-box models, which in many cases are linear-in-the-parameters ones, is to produce a sparse model to effectively represent the system behavior. A popular approach is to select model terms one by one from a pool of candidates (basis functions), and an information criterion is then used to stop the selection process. The advantage is the computational efficiency, the disadvantage is that the derived model is not necessarily sparse. Alternative approach is to introduce into the normal loss function a penalty term on the parameters, leading to improved sparseness and generalization performance of the derived model. Moreover, there is a positive probability that the model structure can be accurately picked up among a wide range of possibilities. Generally speaking, there are three l(rho) norm regularization methods, including the Lasso (rho = 1), Ridge (rho = 2) and Bridge (0 < rho < 1). In particular, Lasso has been introduced into computational biology in recent years. This paper investigates the effectiveness of the three (l(rho)) regularization methods on the model identification of the MAPK signal transduction pathway, and simulation results are compared and analyzed.	[Li, Kang; Gormley, Padhraig] Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland	Li, K (reprint author), Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland.	k.li@qub.ac.uk					Alberts B, 2002, MOL BIOL CELL; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Li K, 2006, AUTOMATICA, V42, P1189, DOI 10.1016/j.automatica.2006.03.004; Kitano H, 2002, SCIENCE, V295, P1662, DOI 10.1126/science.1069492; Huang CYF, 1996, P NATL ACAD SCI USA, V93, P10078, DOI 10.1073/pnas.93.19.10078; CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472; Kholodenko BN, 2000, EUR J BIOCHEM, V267, P1583, DOI 10.1046/j.1432-1327.2000.01197.x; GORMLEY P, 2007, SYST SYNTH BIOL, V1; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hong X, 2008, INT J SYST SCI, V39, P925, DOI 10.1080/00207720802083018; Li K, 2005, IEEE T AUTOMAT CONTR, V50, P1211, DOI 10.1109/TAC.2005.852557; Ma S., 2007, BMC BIOINFORMATICS, V8; MARQUARD.DW, 1970, TECHNOMETRICS, V12, P591, DOI 10.2307/1267205; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3	16	0	0	0	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4705-3				2009							3532	3537				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	BQS31	WOS:000281720401304		
S	Wang, YK; Wang, WH; Luan, YH		Shi, R; Fu, WJ; Wang, YQ; Wang, HB		Wang, Yongke; Wang, Wenhui; Luan, Yihui			Comparison of Different Methods for Handling Linkage Disequilibrium in Genetic-Association Analyses via Simulation	PROCEEDINGS OF THE 2009 2ND INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS, VOLS 1-4	International Conference on Biomedical Engineering and Informatics		English	Proceedings Paper	2nd International Conference on Biomedical Engineering and Informatics (BMEI)	OCT 17-19, 2009	Tianjin, PEOPLES R CHINA	IEEE Engn Med & Biol Soc	Tianjin Univ Technol		RIDGE-REGRESSION; LASSO	Multiple makers exhibiting strong linkage disequilibrium (LD) in a single genomic region and a phenotype of interest generate very compelling statistical associations in the large-scale genetic-association studies. LD, especially strong LD, between variations tit neighboring loci can not only make it difficult to discern markers associated with phenotype, but also create difficulties for distinguishing the functionally relevant variations from nonfunctional variations. In this paper, we compared 5 different methods, Boosting, LASSO, Ridge regression, Stepwise and Single locus analysis, for identifying real functional variations in the circumstance of LD exiting in the variations at different loci via simulation. We found that in the case of strong LD between 20 loci, Ridge regression performs the best while in the case of degenerated LD between 500 and 1000 loci, Boosting outperforms other methods.	[Wang, Yongke; Wang, Wenhui; Luan, Yihui] Shandong Univ, Sch Math, Jinan 250100, Peoples R China	Luan, YH (reprint author), Shandong Univ, Sch Math, Jinan 250100, Peoples R China.	yhluan@sdu.edu.cn					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; Efron B, 2004, ANN STAT, V32, P407; BECK M, 2003, ORPHANET ENCY    SEP, P1; Couzin J, 2007, SCIENCE, V316, P820, DOI 10.1126/science.316.5826.820; Draper N, 1981, APPL REGRESSION ANAL; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1975, COMMUN STAT, V4, P105, DOI 10.1080/03610917508548342; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; KRUGLYAK L, 1995, AM J HUM GENET, V56, P1212; Luan YH, 2008, BIOSTATISTICS, V9, P100, DOI 10.1093/biostatistics/kxm015; Malo N, 2008, AM J HUM GENET, V82, P375, DOI 10.1016/j.ajhg.2007.10.012; Ott J., 1991, ANAL HUMAN GENETIC L; Topol EJ, 2007, JAMA-J AM MED ASSOC, V298, P218, DOI 10.1001/jama.298.2.218	14	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1948-2914		978-1-4244-4133-4	INT CONF BIOMED			2009							1428	1432				5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Engineering, Electrical & Electronic	Computer Science; Engineering	BNP62	WOS:000275179901070		
S	Zheng, H; Wang, FG; Xu, JF; Zhou, NF; Qian, MP; Zhu, J; Deng, MH		Shi, R; Fu, WJ; Wang, YQ; Wang, HB		Zheng, Hao; Wang, Fugui; Xu, Jiangfeng; Zhou, Nengfeng; Qian, Minping; Zhu, Ji; Deng, Minghua			Pathway Detection Based on Hierarchical LASSO Regression Model	PROCEEDINGS OF THE 2009 2ND INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS, VOLS 1-4	International Conference on Biomedical Engineering and Informatics		English	Proceedings Paper	2nd International Conference on Biomedical Engineering and Informatics (BMEI)	OCT 17-19, 2009	Tianjin, PEOPLES R CHINA	IEEE Engn Med & Biol Soc	Tianjin Univ Technol			Rapid and accurate identification of potentially interested pathways through the analysis of genome-wide expression profiles remains an important challenge in bioinformatics. Most existing methods are based on hypothesis testing, such as GSEA. These methods mainly focus on individual pathways and rank them based on their individual strengths. However, biological pathways often work together to function. Therefore, it is important to consider their correlations in detection of pathways that are most closely related to the phenotypes. Considering this problem in the framework of variable selection, we propose a hierarchical LASSO regression (HLR) model to detect differentially expressed gene pathways, which automatically takes into account the correlation structure among the genes via regression. This approach is able to both select important gene pathways and remove unimportant genes within selected pathways. Both simulation and real data analysis show promising results.	[Zheng, Hao; Xu, Jiangfeng; Qian, Minping; Deng, Minghua] Peking Univ, Sch Math Sci, Beijing 100871, Peoples R China	Zheng, H (reprint author), Peking Univ, Sch Math Sci, Beijing 100871, Peoples R China.		Deng, Minghua/B-1316-2012				BREIMAN L, 1995, TECHNOMETRICS; EFRON B, 2006, ANN APPL STAT; Fan J., 2001, J AM STAT ASS; FURNIVAL G, 1974, TECHNOMETRICS; GEORGE EI, 2000, J AM STAT ASS; GEORGE EI, 1993, J AM STAT ASS; JORNSTEN R, 2003, BIOINFORMATICS; KIM S, 2005, BMC BIOINFORMATICS; LIU Z, 2007, STAT APPL GENETICS M; LUAN Y, 2007, BIOSTATISTICS; MA S, 2007, BMC BIOINFORMATICS; MAO X, 2005, BIOSTATISTICS; MILLAU J, 2007, MUTATION RES; MOOTHA VK, 2003, NAT GENET; PANG H, 2006, BIOINFORMATICS; SHEN X, 2002, J AM STAT ASS; SUBRAMANIAN A, 2005, P NATL ACAD SCI; TIAN L, 2005, P NATL ACAD SCI; Tibshirani R., 1996, J ROYAL STAT SOC B; TOMFOHR J, 2005, BMC BIOINFORMATICS; WEI Z, 2006, BIOSTATISTICS; Yuan M., 2006, J ROYAL STAT SOC B; Zhao P, 2006, GROUPED HIERARCHICAL; ZHU J, 2004, BIOSTATISTICS; Zou H., 2005, J ROYAL STAT SOC B	25	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1948-2914		978-1-4244-4133-4	INT CONF BIOMED			2009							1893	1899				7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Engineering, Electrical & Electronic	Computer Science; Engineering	BNP62	WOS:000275179901164		
B	Zheng, ZL		Qiu, PH; Yiu, C; Zhang, H; Wen, XB		Zheng, Zhonglong			Sparse Locality Preserving Embedding	PROCEEDINGS OF THE 2009 2ND INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOLS 1-9			English	Proceedings Paper	2nd International Congress on Image and Signal Processing	OCT 17-19, 2009	Tianjin, PEOPLES R CHINA	Tianjin Univ Technol, IEEE Engn Med & Biol Soc			RECOGNITION; EIGENFACES; SELECTION	Linear dimensionality reduction algorithms, such as Principal Component Analysis, Linear Discriminant Analysis and Locality Preserving Projections, have attracted much attention in many fields. However, the embedding results obtained by those algorithms are linear combination of all the original features, which is difficult to be interpreted psychologically and physiologically. This paper proposes a novel technique, called sparse locality preserving embedding, which performs in the lasso regression framework that dimensionality reduction, feature selection and classification are merged into one analysis. Additionally, the algorithm can be performed both in supervised and unsupervised tasks. Experimental results show that our methods are effective and demonstrate much higher performance.	Zhejiang Normal Univ, Dept Comp Sci, Jinhua 321004, Zhejiang, Peoples R China	Zheng, ZL (reprint author), Zhejiang Normal Univ, Dept Comp Sci, Jinhua 321004, Zhejiang, Peoples R China.						Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Blumensath T, 2008, IEEE T SIGNAL PROCES, V56, P2370, DOI 10.1109/TSP.2007.916124; Ji SH, 2008, IEEE T SIGNAL PROCES, V56, P2346, DOI 10.1109/TSP.2007.914345; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; CANDES EJ, 2005, IEEE S FDN COMP SCI, P295; Clemmensen L., 2008, 125 STANF U US DEP S; Elden L., 1977, BIT (Nordisk Tidskrift for Informationsbehandling), V17; Hegde C., 2007, NIPS; Meinshausen N., 2008, ANN STAT, V37, P246; Roweis S., 2000, SCIENCE, V290, P2223; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	16	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4130-3				2009							2668	2672				5	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology; Telecommunications	Computer Science; Imaging Science & Photographic Technology; Telecommunications	BQE82	WOS:000280804301214		
B	Ren, CX; Dai, DQ			IEEE	Ren, Chuan-Xian; Dai, Dao-Qing			Sparse Representation by Adding Noisy Duplicates for Enhanced Face Recognition: An Elastic Net Regularization Approach	PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2			English	Proceedings Paper	Chinese Conference on Pattern Recognition/1st CJK Joint Workshop on Pattern Recognition	NOV 04-06, 2009	Nanjing, PEOPLES R CHINA			Sparse Representation; Noisy Duplicates; Tikhonov Regularization; Elastic-Net Penalty; Face Recognition	DISCRIMINANT-ANALYSIS; SIGNAL RECOVERY; SYSTEMS	Sparse representation for robust face recognition is a novel concept in the pattern analysis and machine learning community. Through the l(1)-minimization model, representing a test sample as the sparse combination of the training dictionary can effectively achieve facial images classification. However, when the number of training samples is relatively small, it is insufficient to give the test sample a sparse representation so that the recognition performance degenerates seriously. In this paper, we present a novel approach that employs the Elastic Net regularized regression model. Experimental results on several databases show that the proposed strategy improves the recognition accuracy.	[Ren, Chuan-Xian] Sun Yat Sen Zhongshan Univ, Ctr Comp Vis, Guangzhou 510275, Guangdong, Peoples R China	Ren, CX (reprint author), Sun Yat Sen Zhongshan Univ, Ctr Comp Vis, Guangzhou 510275, Guangdong, Peoples R China.	renchx@mail2.sysu.edu.cn; stsddq@mail.sysu.edu.cn					Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Bishop C., 1994, NEURAL COMPUTING, V7, P108; Dai DQ, 2007, IEEE T SYST MAN CY B, V37, P1080, DOI 10.1109/TSMCB.2007.895363; Strang G., 1986, LINEAR ALGEBRA ITS A; Yang WH, 2008, IEEE T KNOWL DATA EN, V20, P601, DOI 10.1109/TKDE.2007.190720; 2005, J ROYAL STAT SOC B, V67, P301	15	1	1	0	8	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4199-0				2009							513	517				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BOY30	WOS:000278039800106		
B	Shi, Y; Dai, DQ; Ren, CX; Wu, MY			IEEE	Shi, Yu; Dai, Dao-Qing; Ren, Chuan-Xian; Wu, Meng-Yun			Gene Selection and Visualization Based on Sparse Maximal Margin Features	PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2			English	Proceedings Paper	Chinese Conference on Pattern Recognition/1st CJK Joint Workshop on Pattern Recognition	NOV 04-06, 2009	Nanjing, PEOPLES R CHINA			Sparse Maximum Margin Features; Elastic-Net Regularization; Robust Regression; Gene Selection; Visualization	HIGH-DIMENSIONAL DATA; FEATURE-EXTRACTION; FACE RECOGNITION; CLASSIFICATION; CANCER	Gene selection with interpretation is an important problem in the bioinformatics field. A novel approach called sparse maximal margin features is proposed in this paper for gene subsets selection and visualization. Through transforming an dense eigenvalue decomposition problem into the Elastic-Net regularized sparse regression framework, we introduce sparsity constraint into the coefficients, which is useful to enhance the interpretability of important variables. Moreover, the new method can simultaneously maximize between-class scatter while minimize within-class scatter, and avoid the small sample size problem. The experimental results from gene expression data show that, our method is helpful to select discriminant genes and then provide important foundations for cancer diagnosis.	[Shi, Yu] Sun Yat Sen Zhongshan Univ, Ctr Comp Vis, Guangzhou 510275, Guangdong, Peoples R China	Shi, Y (reprint author), Sun Yat Sen Zhongshan Univ, Ctr Comp Vis, Guangzhou 510275, Guangdong, Peoples R China.	shiyu@mail2.sysu.edu.cn; stsddq@mail.sysu.edu.cn; renchx@mail2.sysu.edu.cn; mc04wmy@mail2.sysu.edu.cn					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Marchionni L, 2008, ANN INTERN MED, V148, P358; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Draminski M, 2008, BIOINFORMATICS, V24, P110, DOI 10.1093/bioinformatics/btm486; Fukunaga K., 1990, INTRO STAT PATTERN R; Jolliffe I., 1986, PRINCIPLE COMPONENT; Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852; Li Yong-zhi, 2007, Journal of System Simulation, V19; Tang YC, 2008, IEEE T INF TECHNOL B, V12, P723, DOI 10.1109/TITB.2008.920787; Yang WH, 2008, IEEE T KNOWL DATA EN, V20, P601, DOI 10.1109/TKDE.2007.190720; Yang WH, 2009, IEEE T SYST MAN CY B, V39, P1002, DOI 10.1109/TSMCB.2008.2010715; Zhuang XS, 2007, PATTERN RECOGN, V40, P1570, DOI 10.1016/j.patcog.2006.11.015; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	15	0	0	0	10	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4199-0				2009							598	602				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BOY30	WOS:000278039800123		
S	Zymnis, A; Boyd, S; Gorinevsky, D			IEEE	Zymnis, A.; Boyd, S.; Gorinevsky, D.			Mixed Linear System Estimation and Identification	PROCEEDINGS OF THE 48TH IEEE CONFERENCE ON DECISION AND CONTROL, 2009 HELD JOINTLY WITH THE 2009 28TH CHINESE CONTROL CONFERENCE (CDC/CCC 2009)	IEEE Conference on Decision and Control		English	Proceedings Paper	Joint 48th IEEE Conference on Decision and Control (CDC) / 28th Chinese Control Conference (CCC)	DEC 15-18, 2009	Shanghai, PEOPLES R CHINA	IEEE, Honeywell, Quanser, United Technologies, Googol Tech, MathWorks, Natl Instruments			INTERIOR-POINT METHOD; REGRESSION	We consider a mixed linear system model, with both continuous and discrete inputs and outputs, described by a coefficient matrix and a set of noise variances. When the discrete inputs and outputs are absent, the model reduces to the usual noise-corrupted linear system. With discrete inputs only, the model has been used in fault estimation, and with discrete outputs only, the system reduces to a probit model. We consider two fundamental problems: Estimating the model input, given the model parameters and the model output; and identifying the model parameters, given a training set of input-output pairs. The estimation problem leads to a mixed Boolean-convex optimization problem, which can be solved exactly when the number of discrete variables is small enough. In other cases the estimation problem can be solved approximately, by solving a convex relaxation, rounding, and possibly, carrying out a local optimization step. The identification problem is convex and so can be exactly solved. Adding l(1) regularization to the identification problem allows us to trade off model fit and model parsimony. We illustrate the identification and estimation methods with a numerical example.	[Zymnis, A.; Boyd, S.; Gorinevsky, D.] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Zymnis, A (reprint author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.	azymnis@stanford.edu; boyd@stanford.edu; gorin@stanford.edu					Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; DEB S, 1995, IEEE AERO EL SYS MAG, V10, P14, DOI 10.1109/62.373993; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zymnis A, 2009, SIGNAL PROCESS, V89, P989, DOI 10.1016/j.sigpro.2008.11.014; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920; Efron B, 2004, ANN STAT, V32, P407; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJ, 1990, GEN ADDITIVE MODELS; Koh KM, 2007, J MACH LEARN RES, V8, P1519; McCullagh P., 1989, GEN LINEAR MODELS; MOORE RE, 1991, COMPUT MATH APPL, V21, P25, DOI 10.1016/0898-1221(91)90158-Z; NOCEDAL J., 1999, NUMERICAL OPTIMIZATI; SACKS IJ, 1985, IEEE T RELIAB, V34, P437; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Zymnis A, 2008, IEEE DECIS CONTR P, P3219; Zymnis A., 2009, COMPRESSED SEN UNPUB	22	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0191-2216		978-1-4244-3872-3	IEEE DECIS CONTR P			2009							1501	1506		10.1109/CDC.2009.5400437		6	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BA5OA	WOS:000336893601163		
S	Li, JT; Jia, YM; Du, JP; Yu, FS			IEEE	Li, Juntao; Jia, Yingmin; Du, Junping; Yu, Fashan			Gene Selection of Multiple Cancer Types via Huberized Multi-class Support Vector Machine	PROCEEDINGS OF THE 48TH IEEE CONFERENCE ON DECISION AND CONTROL, 2009 HELD JOINTLY WITH THE 2009 28TH CHINESE CONTROL CONFERENCE (CDC/CCC 2009)	IEEE Conference on Decision and Control		English	Proceedings Paper	Joint 48th IEEE Conference on Decision and Control (CDC) / 28th Chinese Control Conference (CCC)	DEC 15-18, 2009	Shanghai, PEOPLES R CHINA	IEEE, Honeywell, Quanser, United Technologies, Googol Tech, MathWorks, Natl Instruments		Gene selection; grouping effect; microarray classification; solution path; support vector machine (SVM)	MICROARRAY CLASSIFICATION; VARIABLE SELECTION; REGULARIZATION; REGRESSION; SVM; PATH	This paper proposes a new type of regularization in the context of multi-class support vector machine for simultaneous classification and gene selection. By combining the huberized hinge loss function and the elastic net penalty, the proposed support vector machine can do automatic gene selection and further encourage a grouping effect in the process of building classifiers, thus leading a sparse multi-classifiers with enhanced interpretability. Furthermore, a reasonable correlation between the two regularization parameters is proposed and an efficient solution path algorithm is developed. Experiments of microarray classification are performed on the leukaemia data set to verify the obtained results.	[Li, Juntao; Jia, Yingmin] Beihang Univ BUAA, Dept Syst & Control, Beijing 100191, Peoples R China	Li, JT (reprint author), Beihang Univ BUAA, Dept Syst & Control, Beijing 100191, Peoples R China.	juntaolimail@yahoo.com.cn; ymjia@buaa.edu.cn; junpingdu@126.com; yufs@hpu.edu.cn					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhang HH, 2006, BIOINFORMATICS, V22, P88, DOI 10.1093/bioinformatics/bti736; Zhu J, 2004, ADV NEUR IN, V16, P49; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zhou X, 2007, BIOINFORMATICS, V23, P1106, DOI 10.1093/bioinformatics/btm036; Efron B, 2004, ANN STAT, V32, P407; Wang L, 2008, BIOINFORMATICS, V24, P412, DOI 10.1093/bioinformatics/btm579; Wang L, 2006, STAT SINICA, V16, P589; Bradley P., 1998, P 15 INT C MACH LEAR; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 2004, J MACH LEARN RES, V5, P1391; Lee Y, 2006, STAT SINICA, V16, P391; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Li JT, 2009, P AMER CONTR CONF, P5410, DOI 10.1109/ACC.2009.5160235; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang LF, 2007, J AM STAT ASSOC, V102, P583, DOI 10.1198/016214506000001383; Zhang HH, 2008, ELECTRON J STAT, V2, P149, DOI 10.1214/08-EJS122	24	0	1	1	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0191-2216		978-1-4244-3872-3	IEEE DECIS CONTR P			2009							1520	1525		10.1109/CDC.2009.5399833		6	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BA5OA	WOS:000336893602003		
S	Blackhall, L; Rotkowitz, M			IEEE	Blackhall, Lachlan; Rotkowitz, Michael			Using an Information Filter to Speed Computation of Sparse Parameter Estimates	PROCEEDINGS OF THE 48TH IEEE CONFERENCE ON DECISION AND CONTROL, 2009 HELD JOINTLY WITH THE 2009 28TH CHINESE CONTROL CONFERENCE (CDC/CCC 2009)	IEEE Conference on Decision and Control		English	Proceedings Paper	Joint 48th IEEE Conference on Decision and Control (CDC) / 28th Chinese Control Conference (CCC)	DEC 15-18, 2009	Shanghai, PEOPLES R CHINA	IEEE, Honeywell, Quanser, United Technologies, Googol Tech, MathWorks, Natl Instruments			SELECTION	This paper discusses the development of a recursive estimator which systematically arrives at sparse parameter estimates. Prior work achieved this by utilizing a Gaussian sum filter. This paper shows the relationship between the implementation using a Gaussian sum filter, where the mean and covariance of each component is propagated, and the equivalent representation using an information filter. We see that the information filter representation requires only a single information filter to be updated for each new measurement instead of the exponential number of measurement updates that were required when using the Gaussian sum filter. We thus see that using the information filter provides computational benefits when recursively estimating sparse parameters, reducing running time as well as data storage.	[Blackhall, Lachlan] Australian Natl Univ, Res Sch Informat Sci & Engn, Canberra, ACT 0200, Australia	Blackhall, L (reprint author), Australian Natl Univ, Res Sch Informat Sci & Engn, GPO Box 4, Canberra, ACT 0200, Australia.	lachlan.blackhall@anu.edu.au; mcrotk@unimelb.edu.au					ALSPACH DL, 1972, IEEE T AUTOMAT CONTR, VAC17, P439, DOI 10.1109/TAC.1972.1100034; Anderson B., 2005, OPTIMAL FILTERING; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Stoica P, 2004, IEEE SIGNAL PROC MAG, V21, P36, DOI 10.1109/MSP.2004.1311138; Bierman G. J., 1973, IEEE Transactions on Aerospace and Electronic Systems, VAES-9, DOI 10.1109/TAES.1973.309697; Blackhall L., 2008, P INT FED AUT CONTR; Blackhall L., 2009, P EUR CONTR C; Candes EJ, 2006, INT C MATH; Donoho D. L., 2005, SPARSE NONNEGATIVE S; Griffin J., 2005, ALTERNATIVE PRIOR DI; Mutambara G., 1998, DECENTRALIZED ESTIMA; SORENSON HW, 1971, AUTOMATICA, V7, P465, DOI 10.1016/0005-1098(71)90097-5	12	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0191-2216		978-1-4244-3872-3	IEEE DECIS CONTR P			2009							7238	7243		10.1109/CDC.2009.5400727		6	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BA5OA	WOS:000336893607123		
S	Toth, R; Lyzell, C; Enqvist, M; Heuberger, PSC; Van den Hof, PMJ			IEEE	Toth, R.; Lyzell, C.; Enqvist, M.; Heuberger, P. S. C.; Van den Hof, P. M. J.			Order and Structural Dependence Selection of LPV-ARX Models Using a Nonnegative Garrote Approach	PROCEEDINGS OF THE 48TH IEEE CONFERENCE ON DECISION AND CONTROL, 2009 HELD JOINTLY WITH THE 2009 28TH CHINESE CONTROL CONFERENCE (CDC/CCC 2009)	IEEE Conference on Decision and Control		English	Proceedings Paper	Joint 48th IEEE Conference on Decision and Control (CDC) / 28th Chinese Control Conference (CCC)	DEC 15-18, 2009	Shanghai, PEOPLES R CHINA	IEEE, Honeywell, Quanser, United Technologies, Googol Tech, MathWorks, Natl Instruments		Linear Parameter-Varying; ARX; identification; order selection	VARYING SYSTEMS; IDENTIFICATION	In order to accurately identify Linear Parameter Varying (LPV) systems, order selection of LPV linear regression models has prime importance. Existing identification approaches in this context suffer from the drawback that a set of functional dependencies needs to be chosen a priori for the parametrization of the model coefficients. However in a black-box setting, it has not been possible so far to decide which functions from a given set are required for the parametrization and which are not. To provide a practical solution, a nonnegative garrote approach is applied. It is shown that using only a measured data record of the plant, both the order selection and the selection of structural coefficient dependence can be solved by the proposed method.	[Toth, R.; Heuberger, P. S. C.; Van den Hof, P. M. J.] Delft Univ Technol, Delft Ctr Syst & Control, NL-2628 CD Delft, Netherlands	Toth, R (reprint author), Delft Univ Technol, Delft Ctr Syst & Control, Mekelweg 2, NL-2628 CD Delft, Netherlands.	r.toth@tudelft.nl; lyzell@isy.liu.se; maren@isy.liu.se; p.s.c.heuberger@tudelft.nl; p.m.j.vandenhof@tudelft.nl					BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Bamieh B, 2002, INT J ROBUST NONLIN, V12, P841, DOI 10.1002/rnc.706; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Rugh WJ, 2000, AUTOMATICA, V36, P1401, DOI 10.1016/S0005-1098(00)00058-3; ASTROM KJ, 1971, AUTOMATICA, V7, P123; Butcher M., 2008, P 17 IFAC WORLD C SE, P4018; Doyle J., 1998, ESSENTIALS ROBUST CO; Gevers M., 2008, P 47 IEEE C DEC CONT, P4522; Hsu K., 2008, P INT S COMP AID CON, P846; Khalate A. A., 2009, P 15 IFAC S SYST ID, P162; Ljung L., 2006, SYSTEM IDENTIFICATIO; Ljung L, 1999, SYSTEM IDENTIFICATIO; Lyzell C, 2008, IEEE DECIS CONTR P, P1974; Scherer CW, 1996, INT J ROBUST NONLIN, V6, P929; Toth R, 2009, AUTOMATICA, V45, P1359, DOI 10.1016/j.automatica.2009.01.010; TOTH R, 2008, P 47 IEEE C DEC CONT, P4522; Toth R., 2008, THESIS DELFT U TECHN; Toth Roland, 2007, Proceedings of the European Control Conference 2007 (ECC); van Wingerden JW, 2009, AUTOMATICA, V45, P372, DOI 10.1016/j.automatica.2008.08.015; Verdult V, 2002, AUTOMATICA, V38, P805, DOI 10.1016/S0005-1098(01)00268-0; Wei X., 2006, THESIS J KEPLER U LI; Wei X., 2006, P 14 IFAC S SYST ID, P517	22	7	7	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0191-2216		978-1-4244-3872-3	IEEE DECIS CONTR P			2009							7406	7411		10.1109/CDC.2009.5399551		6	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BA5OA	WOS:000336893607151		
S	Sun, Y; Lin, XD		Wang, HF; Neace, MB; Zhu, YG; Duch, W		Sun, Yan; Lin, Xiaodong			A Regularized Full-factor MGARCH Model	PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION AND MANAGEMENT SCIENCES	Series of Information and Management Sciences		English	Proceedings Paper	8th International Conference on Information and Management Sciences	JUL 20-28, 2009	Kunming, PEOPLES R CHINA	Int Assoc Informat & Management Sci, Tsinghu Univ, Chinese Univ Hong Kong, Waseda Univ, KAIST		GARCH; multivariate; volatility; sparse; penalty	GENERALIZED ARCH	The recent decade saw an increasing interest in the multivariate GARCH model for capturing the dynamics of asset prices. However, the issue of computation efficiency arises as the number of parameters easily explodes with increasing model dimension. In this paper, we developed a regularization technique based on penalized likelihood, which achieves sparse parameter estimation for multivariate GARCH model. We have proved that under mild conditions our estimator is sparse consistent and enjoys "Oracle Property". We provided simulation studies to support these theoretical results. Furthermore, the proposed method is fairly general and can be applied to a large class of stationary multivariate time series models.	[Sun, Yan; Lin, Xiaodong] Univ Cincinnati, Dept Math Sci, Cincinnati, OH 45221 USA		suny2@email.uc.edu; linxd@math.uc.edu					ALEXANDER C, 2000, ISMA CTR MASTERING R, V2; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; ENGLE RF, 1995, ECONOMET THEOR, V11, P122; Bickel PJ, 2008, ANN STAT, V36, P2577, DOI 10.1214/08-AOS600; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Engle RF, 2000, ECONOMETRICA, V68, P1, DOI 10.1111/1468-0262.00091; BOLLERSLEV T, 1986, J ECONOMETRICS, V31, P307, DOI 10.1016/0304-4076(86)90063-1; BOLLERSLEV T, 1988, J POLITICAL EC, V96; BOLLERSLEV T, 1990, REV ECON STAT, V72, P498, DOI 10.2307/2109358; Campbell JY, 1997, ECONOMETRICS FINANCI; ENGLE R, 2004, ECONOMETRICA, V50, P987; FAN J, 2001, JASA, V96; HAFNER CM, 2006, ASYMPTOTIC THEORY FA; KAROUI E, ANN STAT IN PRESS; LANNE M, 2005, 63 HECER; NG LL, 1991, J FINANC, V46, P1507, DOI 10.2307/2328869; Sheppard K, 2001, THEORETICAL EMPIRICA; SUN Y, 2009, REGULARIZATION STATI; Vrontos I.D., 2003, ECONOMET J, V6, P312, DOI 10.1111/1368-423X.t01-1-00111	19	0	0	0	5	CALIFORNIA POLYTECHNIC STATE UNIV	SAN LUIS OBISPO	CAL POLY, SAN LUIS OBISPO, CA 93407 USA	1539-2023			SER INF MANAGE SCI			2009	8						933	936				4	Business; Computer Science, Interdisciplinary Applications; Education & Educational Research; Engineering, Industrial; Management; Operations Research & Management Science	Business & Economics; Computer Science; Education & Educational Research; Engineering; Operations Research & Management Science	BLL17	WOS:000270433200184		
J	Fu, HZ; Zhu, C; Dellandrea, E; Bichot, CE; Chen, LM		Zhang, YJ		Fu, Huanzhang; Zhu, Chao; Dellandrea, Emmanuel; Bichot, Charles-Edmond; Chen, Liming			Visual Object Categorization via Sparse Representation	PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009)			English	Proceedings Paper	5th International Conference on Image and Graphics	SEP 20-23, 2009	Xian, PEOPLES R CHINA	China Soc Image & Graph, Xian Univ Technol, NW Univ, Shaanxi Prov Key Lab Speech & Image Informat Proc, Natl Nat Sci Fdn China, TOYOU FEIJI Elect Co, CPS, IEEE Comp Soc	NW Polytech Univ		ATOMIC DECOMPOSITION; INVERSE PROBLEMS; IMAGE FEATURES; SCALE; CLASSIFICATION; RECOGNITION; SELECTION	In this paper, we consider the problem of classifying a real world image to the corresponding object class based on its visual content via sparse representation, which is originally used as a powerful tool for acquiring, representing and compressing high-dimensional signals. Assuming the intuitive hypothesis that an image could be represented by a linear combination of the training images from the same class, we propose a novel approach for visual object categorization in which a sparse representation of the image is first of all obtained by solving a l(1) (or l(0))-minimization problem and then fed into a traditional classifier such as Support Vector Machine (SVM) to finally perform the specified task. Experimental results obtained on the SIMPLIcity database have shown that this new approach can improve the classification performance compared to standard SVM using directly features extracted from the image.	[Fu, Huanzhang; Zhu, Chao; Dellandrea, Emmanuel; Bichot, Charles-Edmond; Chen, Liming] Univ Lyon, Ecole Cent Lyon, LIRIS, CNRS,UMR5205, F-69134 Lyon, France	Fu, HZ (reprint author), Univ Lyon, Ecole Cent Lyon, LIRIS, CNRS,UMR5205, F-69134 Lyon, France.	huanzhang.fu@ec-lyon.fr; chao.zhu@ec-lyon.fr; emmanuel.dellandrea@ec-lyon.fr; charles-edmond.bichot@ec-lyon.fr; liming.chen@ec-lyon.fr					AGARWAL S, 2002, ECCV, V4, P113; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Bellman R.E., 1961, ADAPTIVE CONTROL PRO; Chang C.-C., 2001, LIB SUPPORT VECTOR M; Cristianini N., 2000, INTRO SUPPORT VECTOR; Dance C., 2004, ECCV INT WORKSH STAT; Dikmen M., 2008, ICPR, P1; Elad M., 2006, IEEE COMP SOC C COMP, V1, P895; Everingham M., 2008, PASCAL VISUAL OBJECT; Fergus R., 2003, IEEE COMP SOC C COMP, V2; Lazebnik S., 2006, IEEE C COMP VIS PATT, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Lazebnik S., 2004, BRIT MACH VIS C, V2, P959; Li F., 2005, P 2005 IEEE COMP SOC, P524; Mairal Julien, 2008, SIAM Multiscale Modeling and Simulation, V7, DOI 10.1137/070697653; Mairal J, 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587652; Malioutov D., 2005, P IEEE INT C AC SPEE, V5, P733, DOI 10.1109/ICASSP.2005.1416408; MARSZALEK M, 2007, VIS REC WORKSH CONJ; NIBLACK W, 1993, QBIC PROJECT QUERYIN, V1908, P173; Olshausen BA, 2001, ADV NEUR IN, V13, P887; Pati Y. C., 1993, P 27 AS C SIGN SYST, V1, P40, DOI DOI 10.1109/ACSSC.1993.342465; PERRONIN F, 2006, EUR C COMP VIS GRAZ, V4, P464; Rao S.R., 2008, IEEE C COMP VIS PATT, P1; Rodriguez F., 2007, SPARSE REPRESENTATIO; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206; TAKALA V, 2005, 14 SCAND C IM AN, P882; Wright J., 2009, P IEEE; Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1	45	1	1	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3883-9				2009							943	948		10.1109/ICIG.2009.100		6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	BPA19	WOS:000278326900170		
B	Hamasuna, Y; Endo, Y; Miyamoto, S		Carvalho, JP; Kaymak, DU; Sousa, JMC		Hamasuna, Yukihiro; Endo, Yasunori; Miyamoto, Sadaaki			On Tolerant Fuzzy c-Means Clustering with L(1)-Regularization	PROCEEDINGS OF THE JOINT 2009 INTERNATIONAL FUZZY SYSTEMS ASSOCIATION WORLD CONGRESS AND 2009 EUROPEAN SOCIETY OF FUZZY LOGIC AND TECHNOLOGY CONFERENCE			English	Proceedings Paper	Joint International-Fuzzy-Systems-Association World Congress/European-Society-Fuzzy-Logic-and-Technology Conference	JUL 20-24, 2009	Lisbon, PORTUGAL	Int Fuzzy Syst Assoc, European Soc Fuzzy Log & Technol		fuzzy c-means clustering; L(1)-regularization; optimization; tolerance; uncertainty		We have proposed tolerant fuzzy c-means clustering (TFCM) from the viewpoint of handling data more flexibly. This paper presents a new type of tolerant fuzzy c-means clustering with L(1)-regularization. L(1)-regularization is well-known as the most successful techniques to induce sparseness. The proposed algorithm is different from the viewpoint of the sparseness for tolerance vector. In the original concept of tolerance, a tolerance vector attributes to each data. This paper develops the concept to handle data flexibly, that is, a tolerance vector attributes not only to each data but also each cluster. First, the new concept of tolerance is introduced into optimization problems. These optimization problems are based on conventional fuzzy c-means clustering (FCM). Second, the optimization problems with tolerance are solved by using Karush-Kuhn-Tucker conditions and an optimization method for L(1)-regularization. Third, new clustering algorithms are constructed based on the explicit optimal solutions. Finally, the effectiveness of the proposed algorithm is verified through some numerical examples.	[Hamasuna, Yukihiro] Univ Tsukuba, Doctoral Program Risk Engn, Tsukuba, Ibaraki 3058573, Japan	Hamasuna, Y (reprint author), Univ Tsukuba, Doctoral Program Risk Engn, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.	yhama@soft.risk.tsukuba.ac.jp; endo@risk.tsukuba.ac.jp; miyamoto@risk.tsukuba.ac.jp					WILLIAMS PM, 1995, NEURAL COMPUT, V7, P117, DOI 10.1162/neco.1995.7.1.117; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Bezdek J.C., 1981, PATTERN RECOGNITION; Endo Y., 2005, P INT S NONL THEOR I, P345; Hamasuna Y., 2008, J JAPAN SOC FUZZY TH, V20, P388, DOI 10.3156/jsoft.20.388; HAMASUNA Y, J ADV COMPU IN PRESS; Hasegawa Y, 2007, LECT NOTES ARTIF INT, V4617, P237; Kazama J, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P137; Miyamoto S., 1997, P 7 INT FUZZ SYST AS, VII, P86; Murata R., 2006, J ADV COMPUTATIONAL, V10, P673; Ngai W.K, 2006, P 6 INT C DAT MIN IC, P436; Takata O., 2000, J JAPAN SOC FUZZY TH, V12, P686; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Tsuda K., 2006, P 23 INT C MACH LEAR, P953, DOI 10.1145/1143844.1143964	14	0	0	0	0	EUROPEAN SOC FUZZY LOGIC & TECHNOLOGY	LINZ	JOHANNES KEPLER UNIV, INST BIOINFORMATICS,, LINZ, A-4040, AUSTRIA			978-989-95079-6-8				2009							1152	1157				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Operations Research & Management Science; Mathematics, Applied	Automation & Control Systems; Computer Science; Operations Research & Management Science; Mathematics	BPL78	WOS:000279170600201		
J	Hartmann, A; Zeeck, A; van der Kooij, AJ				Hartmann, A.; Zeeck, A.; van der Kooij, A. J.			Severity of Bulimia Nervosa Measurement and Classification into Health or Pathology	PSYCHOPATHOLOGY			English	Article						Bulimia nervosa, severity; Transformation of variables; Predictor selection	CLINICAL-SIGNIFICANCE; STRUCTURED INTERVIEW; EATING-DISORDERS; DSM-IV; PSYCHOTHERAPY; DEPRESSION; REMISSION; RELAPSE; ICD-10; SIAB	Aims: In order to identify the most important components of the severity of bulimia nervosa (as well as identifying clinical cases), we explored the relation between dimensional and categorical assessment. This was achieved by studying the performance of variables from standard instruments (measuring specific and general psychopathology) in predicting an expert rating of overall syndrome severity. Method: In total, 213 cases were selected (across the whole range of severity). We applied regression with optimal scaling to model nonlinear relations in the data, and the lasso method with bootstrapping for predictor selection. The best model contained 2 scales of the Eating Disorders Inventory ('bulimia' and 'drive for thinness') and the frequency of the binges. The sensitivity and specificity of case classification using the obtained model was determined. Results: The model can predict the probability of being a clinical case at a rate of 88%. The presented statistical methods are innovative and promising approaches that can help researchers and clinicians to better define sets of variables for treatment evaluation and outcome studies. Conclusion: The results indicate that severity and outcome in bulimia nervosa should be determined by measuring both cognitive and behavioral aspects of the symptoms. Copyright (C) 2008 S. Karger AG, Basel	[Hartmann, A.; Zeeck, A.] Univ Freiburg, Dept Psychosomat Med & Psychotherapy, DE-79104 Freiburg, Germany; [van der Kooij, A. J.] Leiden Univ, Data Theory Grp, Leiden, Netherlands	Zeeck, A (reprint author), Univ Freiburg, Dept Psychosomat Med & Psychotherapy, Hauptstr 8, DE-79104 Freiburg, Germany.	almut.zeeck@uniklinik-freiburg.de	Hartmann, Armin/H-4855-2013	Hartmann, Armin/0000-0002-4158-6576	Department of Data Theory	Leiden University holds the copyright of the procedures in the SPSS package Categories, and the Department of Data Theory receives the royalties.	American Psychiatric Association, 1994, DIAGN STAT MAN MENT; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; JACOBSON NS, 1984, BEHAV THER, V15, P336, DOI 10.1016/S0005-7894(84)80002-7; Casper R C, 1998, Depress Anxiety, V8 Suppl 1, P96, DOI 10.1002/(SICI)1520-6394(1998)8:1+<96::AID-DA15>3.0.CO;2-4; Cassin SE, 2005, CLIN PSYCHOL REV, V25, P895, DOI 10.1016/j.cpr.2005.04.012; Clausen L, 2004, SCAND J PSYCHOL, V45, P247, DOI 10.1111/j.1467-9450.2004.00401.x; Clausen L, 2004, INT J EAT DISORDER, V36, P296, DOI 10.1002/eat.20043; COOPER PJ, 1986, BRIT J PSYCHIAT, V148, P268, DOI 10.1192/bjp.148.3.268; Derogatis L. R, 1977, SCL 90 R ADM SCORING; EFRON BE, 1983, J AM STAT ASSOC, V78, P313; Fairburn CG, 2003, J CONSULT CLIN PSYCH, V71, P103, DOI 10.1037/0022-006X.71.1.103; Fichter M, 2001, EUR PSYCHIAT, V16, P38, DOI 10.1016/S0924-9338(00)00534-4; FICHTER MM, 1991, INT J EAT DISORDER, V10, P571, DOI 10.1002/1098-108X(199109)10:5<571::AID-EAT2260100510>3.0.CO;2-J; Fichter MM, 1998, INT J EAT DISORDER, V24, P227, DOI 10.1002/(SICI)1098-108X(199811)24:3<227::AID-EAT1>3.0.CO;2-O; Fichter MM, 1997, INT J EAT DISORDER, V22, P361; Franke GH, 2002, SYMPTOM CHECKLISTE D; Gamer DM, 1991, EATING DISORDER INVE; Gifi A, 1990, NONLINEAR MULTIVARIA; Halmi KA, 2002, ARCH GEN PSYCHIAT, V59, P1105, DOI 10.1001/archpsyc.59.12.1105; JACOBSON NS, 1991, J CONSULT CLIN PSYCH, V59, P12, DOI 10.1037//0022-006X.59.1.12; Jacobson NS, 1999, J CONSULT CLIN PSYCH, V67, P300, DOI 10.1037/0022-006X.67.3.300; Judd CM, 1989, DATA ANAL MODEL COMP; LEVY AB, 1989, AM J PSYCHIAT, V146, P162; Meermann R, 1987, THERAPIE MAGERSUCHT; Meulman J. J., 1999, SPSS CATEGORIES 10 0; Meulman J.J., 2004, SPSS CATEGORIES 13 0; Olmsted MP, 2005, INT J EAT DISORDER, V38, P1, DOI 10.1002/eat.20144; Pratt J. W., 1987, P 2 INT C STAT, P245; ROUNSAVILLE BJ, 2002, RES AGENDA DSM 4; TOBIN DL, 1995, INT J EAT DISORDER, V18, P359, DOI 10.1002/1098-108X(199512)18:4<359::AID-EAT2260180409>3.0.CO;2-A; VANDERKOOIJ A, 2008, ACCURACY REGRESSION; VANDERKOOIJ A, 2008, REGULARIZATION UNPUB; VANDERKOOIJ A, 2004, SPSS CATEGORIES 13 0, P107	33	4	4	1	7	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	0254-4962			PSYCHOPATHOLOGY	Psychopathology		2009	42	1					22	31		10.1159/000173700		10	Psychiatry	Psychiatry	395UJ	WOS:000262548700003	19023231	
J	Hartmann, A; Van der Kooij, AJ; Zeeck, A				Hartmann, Armin; Van der Kooij, Anita J.; Zeeck, Almut			Exploring nonlinear relations: Models of clinical decision making by regression with optimal scaling	PSYCHOTHERAPY RESEARCH			English	Article						statistical methodology; mental health services research; aptitude-treatment interaction research; nonlinear transformations; predictor selection	NONORTHOGONAL PROBLEMS; COGNITIVE THERAPY; RIDGE REGRESSION; SUDDEN GAINS; PSYCHOTHERAPY; DEPRESSION	In explorative regression studies, linear models are often applied without questioning the linearity of the relations between the predictor variables and the dependent variable, or linear relations are taken as an approximation. In this study, the method of regression with optimal scaling transformations is demonstrated. This method does not require predefined nonlinear functions and results in easy-to-interpret transformations that will show the form of the relations. The method is illustrated using data from a German multicenter project on the indication criteria for inpatient or day clinic psychotherapy treatment. The indication criteria to include in the regression model were selected with the Lasso, which is a tool for predictor selection that overcomes the disadvantages of stepwise regression methods. The resulting prediction model indicates that treatment status is (approximately) linearly related to some criteria and nonlinearly related to others.	[Hartmann, Armin; Zeeck, Almut] Univ Hosp Freiburg, D-79104 Freiburg, Germany; [Van der Kooij, Anita J.] Leiden Univ, Data Theory Grp, Leiden, Germany	Hartmann, A (reprint author), Univ Hosp Freiburg, Hauptstr 8, D-79104 Freiburg, Germany.	armin.hartmann@uniklinik-freiburg.de	Hartmann, Armin/H-4855-2013	Hartmann, Armin/0000-0002-4158-6576			Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Howard KI, 1996, AM PSYCHOL, V51, P1059, DOI 10.1037//0003-066X.51.10.1059; HOWARD KI, 1993, J CONSULT CLIN PSYCH, V61, P678, DOI 10.1037/0022-006X.61.4.678; Hardy GE, 2005, J CONSULT CLIN PSYCH, V73, P59, DOI 10.1037/0022-006X.73.1.59; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; Efron B, 1993, INTRO BOOTSTRAP; Franke GH, 2002, SYMPTOM CHECKLISTE D; Gifi A, 1990, NONLINEAR MULTIVARIA; HOERL AE, 1970, TECHNOMETRICS, V12, P69, DOI 10.2307/1267352; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Judd CM, 1989, DATA ANAL MODEL COMP; KOPTA SM, 1994, J CONSULT CLIN PSYCH, V62, P1009, DOI 10.1037/0022-006X.62.5.1009; Lange C, 2002, Z PSYCHOSOM MED PSYC, V48, P256; Lutz W, 2002, PSYCHOTHER RES, V12, P427, DOI 10.1093/ptr/12.4.427; *MATH SOFT INC, 1999, S PLUS US MAN; MEULMAN JJ, 1999, SPPS CATEGORIES 10 0; MEULMAN JJ, 2000, INT C MEAS MULT AN B; MEULMAN JJ, 2008, SPPS CATEGORIES 17 0; Pratt J. W., 1987, P 2 INT C STAT, P245; R Development Core Team, 2007, R LANG ENV STAT COMP; SAS Institute Inc, 1999, SAS STAT 9 2 US GUID; *SPSS INC, 2008, SPSS CAT 17 0; Tang TZ, 2007, J CONSULT CLIN PSYCH, V75, P404, DOI 10.1037/0022-006X.75.3.404; Tasca GA, 2006, PSYCHOTHER RES, V16, P499, DOI 10.1080/10503300600593359; Thompson B, 2001, J EXP EDUC, V70, P80; Van der Kooij A. J., 2007, THESIS LEIDEN U; VANDERKOOIJ A, 2008, REGULARIZATION UNPUB; VANDERKOOIJ AJ, 2008, PREDICTION ACC UNPUB; WIETERSHEIM JV, 1989, DIAGNOSTICA, V35, P359; YOUNG FW, 1976, PSYCHOMETRIKA, V41, P505, DOI 10.1007/BF02296972; ZEECK A, 2009, PSYCHOTHERAPIE PSYCH, DOI DOI 10.1055/S-0029-1208175; Zeeck A, 2006, J PERS DISORD, V20, P22, DOI 10.1521/pedi.2006.20.1.22	33	9	9	4	8	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND	1050-3307	1468-4381		PSYCHOTHER RES	Psychother. Res.		2009	19	4-5					482	492		10.1080/10503300902905939		11	Psychology, Clinical	Psychology	551KT	WOS:000274207900012	20183402	
B	Cheng, X; Tian, Y; Wang, SL; Li, BS		Zhu, K; Zhang, H		Cheng Xiang; Tian Yuan; Wang SuLi; Li Busheng			A Robust Hybrid of Lasso and LARR	RECENT ADVANCE IN STATISTICS APPLICATION AND RELATED AREAS, VOLS I AND II			English	Proceedings Paper	2nd Conference of the International-Institute-of-Applied-Statistics-Studies	JUL 24-29, 2009	Qingdao, PEOPLES R CHINA	Int Inst Appl Stat Studies, Appl Stat Inst Shandong Prov, 2009 IIASS Conf Comm		LARR-lasso; LARR; Lasso; Regression; Subset Selection	MODEL SELECTION	Algorithms such as lasso and locally adjusted robust regressor (LARR) are of great interest because of their resulted sparse models for interpretation in addition to prediction. In this paper, we combine these two classical ideas together to produce LARR-lasso. Compared with the LARR regression, LARR-lasso can do parameter estimation and variable selection simultaneously. Compared with the traditional lasso, LARR-lasso is resistant to heavy-tailed errors or outliers in the response. Through the local linear approximation to the non-concave penalty functions, the problem of precision matrix estimation is recast as a sequence of penalized likelihood problems with a weighted L 1 penalty. Our estimation schemes are applied to two real datasets. Simulation experiments and asymptotic theory are used to justify our proposed methods.	[Cheng Xiang; Tian Yuan; Wang SuLi; Li Busheng] Informat Engn Inst Jingdezhen Ceram Inst, Jingdezhen 333000, Peoples R China	Cheng, X (reprint author), Informat Engn Inst Jingdezhen Ceram Inst, Jingdezhen 333000, Peoples R China.						Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; GUO GD, 2008, LOCALLY ADJUSTED ROB, P1; Leng CL, 2006, STAT SINICA, V16, P1273	8	0	0	0	1	AUSSINO ACAD PUBL HOUSE	MARRICKVILLE	PO BOX 893, MARRICKVILLE, NSW 2204 00000, AUSTRALIA			978-0-9806057-3-0				2009							1989	1992				4	Mathematics, Applied; Statistics & Probability	Mathematics	BOD81	WOS:000276338200345		
J	Liu, Z; Vandenberghe, L				Liu, Zhang; Vandenberghe, Lieven			INTERIOR-POINT METHOD FOR NUCLEAR NORM APPROXIMATION WITH APPLICATION TO SYSTEM IDENTIFICATION	SIAM JOURNAL ON MATRIX ANALYSIS AND APPLICATIONS			English	Article						semidefinite programming; interior-point methods; nuclear norm approximation; matrix rank minimization; system identification; subspace algorithm	TOTAL LEAST-SQUARES; FACTORIZATION METHOD; IMAGE STREAMS; SEMIDEFINITE; OPTIMIZATION; MINIMIZATION; MATRICES; MOTION; SHAPE	The nuclear norm (sum of singular values) of a matrix is often used in convex heuristics for rank minimization problems in control, signal processing, and statistics. Such heuristics can be viewed as extensions of l(1)-norm minimization techniques for cardinality minimization and sparse signal estimation. In this paper we consider the problem of minimizing the nuclear norm of an affine matrix-valued function. This problem can be formulated as a semidefinite program, but the reformulation requires large auxiliary matrix variables, and is expensive to solve by general-purpose interior-point solvers. We show that problem structure in the semidefinite programming formulation can be exploited to develop more efficient implementations of interior-point methods. In the fast implementation, the cost per iteration is reduced to a quartic function of the problem dimensions and is comparable to the cost of solving the approximation problem in the Frobenius norm. In the second part of the paper, the nuclear norm approximation algorithm is applied to system identification. A variant of a simple subspace algorithm is presented in which low-rank matrix approximations are computed via nuclear norm minimization instead of the singular value decomposition. This has the important advantage of preserving linear matrix structure in the low-rank approximation. The method is shown to perform well on publicly available benchmark data.	[Liu, Zhang; Vandenberghe, Lieven] Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA	Liu, Z (reprint author), Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA.	zhang@ee.ucla.edu; vandenbe@ee.ucla.edu			NSF [ECS-0524663, ECCS-0824003]; Northrop Grumman	This research was supported by the NSF under grants ECS-0524663 and ECCS-0824003 and by a Northrop Grumman Ph.D. fellowship.	Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Viberg M, 1995, AUTOMATICA, V31, P1835, DOI 10.1016/0005-1098(95)00107-5; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; VANOVERSCHEE P, 1994, AUTOMATICA, V30, P75, DOI 10.1016/0005-1098(94)90230-5; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Nesterov YE, 1997, MATH OPER RES, V22, P1, DOI 10.1287/moor.22.1.1; Tutuncu RH, 2003, MATH PROGRAM, V95, P189, DOI 10.1007/s10107-002-0347-5; Benson S.J., 2005, ANLMCSTM277; Benson SJ, 2008, ACM T MATH SOFTWARE, V34, P1, DOI 10.1145/1356052.1356057; Borchers B, 1999, OPTIM METHOD SOFTW, V11-2, P613, DOI 10.1080/10556789908805765; Cai J-F, 2008, SINGULAR VALUE THRES; Candes E.J., IEEE T INFO IN PRESS; CANDES EJ, FDN COMPUTA IN PRESS; CANDES EJ, P IEEE UNPUB; Dahl J., 2008, CVXOPT PYTHON PACKAG; De Moor B., 1997, Journal A, V38; De Moor B., 1988, P IEEE ICASSP NY US, P2244; DEMOOR B, 1994, IEEE T SIGNAL PROCES, V42, P3104, DOI 10.1109/78.330370; Elden L, 2007, FUND ALGORITHMS, V4, pIX; Fazel M, 2004, P AMER CONTR CONF, P3273; Fazel M., 2002, THESIS STANFORD U ST; Fazel M., 2001, P AM CONTR C, V6, P4734, DOI 10.1109/ACC.2001.945730; Fujisawa K, 1997, MATH PROGRAM, V79, P235, DOI 10.1007/BF02614319; Genin Y, 2003, SIAM J MATRIX ANAL A, V25, P57, DOI 10.1137/S0895479803374840; Hastie T., 2001, ELEMENTS STAT LEARNI; Hiriart-Urruty J.-B., 1993, GRUNDLEHREN MATH WIS, V306; Larimore W. E., 1990, P 29 IEEE C DEC CONT, V2, P596; Ljung L, 1999, SYSTEM IDENTIFICATIO; MA S, MATH PROG A IN PRESS; Markovsky I, 2005, IEEE T AUTOMAT CONTR, V50, P1490, DOI 10.1109/TAC.2005.856643; Morita T, 1997, IEEE T PATTERN ANAL, V19, P858, DOI 10.1109/34.608289; Nesterov Y., 2004, INTRO LECT CONVEX OP; RECHT B, 2008, P 47 IEEE C DEC CONT, P3065; Recht B., SIAM REV IN PRESS; Roh T, 2006, SIAM J OPTIMIZ, V16, P939, DOI 10.1137/040612646; SHOR NZ, 1985, SPRINGER SER COMPUT; Srebro N., 2004, LEARNING MATRIX FACT; Todd MJ, 1998, SIAM J OPTIMIZ, V8, P769, DOI 10.1137/S105262349630060X; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tseng P., 2008, ACCELERATED PR UNPUB; Vandenberghe L., 2004, CONVEX OPTIMIZATION; VERHAEGEN M, 1994, AUTOMATICA, V30, P61, DOI 10.1016/0005-1098(94)90229-1; Yamashita M, 2003, OPTIM METHOD SOFTW, V18, P491, DOI 10.1080/1055678031000118482	49	89	94	1	8	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	0895-4798			SIAM J MATRIX ANAL A	SIAM J. Matrix Anal. Appl.		2009	31	3					1235	1256		10.1137/090755436		22	Mathematics, Applied	Mathematics	519WN	WOS:000271800100021		
J	Fornasier, M; Schonlieb, CB				Fornasier, Massimo; Schoenlieb, Carola-Bibiane			SUBSPACE CORRECTION METHODS FOR TOTAL VARIATION AND l(1)-MINIMIZATION	SIAM JOURNAL ON NUMERICAL ANALYSIS			English	Article						domain decomposition method; subspace corrections; convex optimization; parallel computation; discontinuous solutions; total variation minimization; degenerate elliptic PDEs; l(1)-minimization; image and signal processing	TOTAL VARIATION MINIMIZATION; LINEAR INVERSE PROBLEMS; DOMAIN DECOMPOSITION; SIGNAL RECOVERY; SPARSITY CONSTRAINTS; ITERATIVE METHODS; ALTERNATING PROJECTIONS; UNCERTAINTY PRINCIPLES; IMAGE-RESTORATION; CONVERGENCE	This paper is concerned with the numerical minimization of energy functionals in Hilbert spaces involving convex constraints coinciding with a seminorm for a subspace. The optimization is realized by alternating minimizations of the functional on a sequence of orthogonal subspaces. On each subspace an iterative proximity-map algorithm is implemented via oblique thresholding, which is the main new tool introduced in this work. We provide convergence conditions for the algorithm in order to compute minimizers of the target energy. Analogous results are derived for a parallel variant of the algorithm. Applications are presented in domain decomposition methods for degenerate elliptic PDEs arising in total variation minimization and in accelerated sparse recovery algorithms based on l(1)-minimization. We include numerical examples which show efficient solutions to classical problems in signal and image processing.	[Fornasier, Massimo] Austrian Acad Sci, Johann Radon Inst Computat & Appl Math RICAM, A-1040 Vienna, Austria; [Schoenlieb, Carola-Bibiane] Ctr Math Sci, DAMTP, Cambridge CB3 0WA, England	Fornasier, M (reprint author), Austrian Acad Sci, Johann Radon Inst Computat & Appl Math RICAM, Altenbergerstr 69, A-1040 Vienna, Austria.	massimo.fornasier@oeaw.ac.at; c.b.s.schonlieb@damtp.cam.ac.uk			King Abdullah University of Science and Technology (KAUST) [KUK-I1-007-43]	This work was based on work supported by Award KUK-I1-007-43, made by King Abdullah University of Science and Technology (KAUST).	AMBROSIO L., 2000, OXFORD MATH MONOGRAP; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI 10.1109/TIP.2002.1014998; Weiss P, 2009, SIAM J SCI COMPUT, V31, P2047, DOI 10.1137/070696143; Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Carstensen C, 1997, NUMER LINEAR ALGEBR, V4, P177, DOI 10.1002/(SICI)1099-1506(199705/06)4:3<177::AID-NLA106>3.3.CO;2-2; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258; Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Fornasier M, 2008, SIAM J NUMER ANAL, V46, P577, DOI 10.1137/0606668909; Aubert G., 2002, MATH PROBLEMS IMAGE; Aubert G, 1997, SIAM J NUMER ANAL, V34, P1948, DOI 10.1137/S003614299529230X; Barbu V, 1986, CONVEXITY OPTIMIZATI; Bauschke H.H., 1997, CONT MATH, V204, P1; Bauschke HH, 2003, T AM MATH SOC, V355, P3433, DOI 10.1090/S0002-9947-03-03136-2; BRAMBLE JH, 1991, MATH COMPUT, V57, P1; Bredies K, 2008, J FOURIER ANAL APPL, V14, P813, DOI 10.1007/s00041-008-9041-1; Bruck RE, 1977, HOUSTON J MATH, V3, P459; Candes E., 2007, J FOURIER ANAL APPL, V14, P877; Candes E. J., 2006, INT C MATH, V3, P1433; CHAMBOLLE A, 2008, 0819 UCLA CAM; Chan T.F., 1994, ACTA NUMERICA, P61; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; Darbon J, 2005, LECT NOTES COMPUT SC, V3522, P351; Daubechies I, 2008, J FOURIER ANAL APPL, V14, P764, DOI 10.1007/s00041-008-9039-8; Daubechies I, 2007, INVERSE PROBL IMAG, V1, P29; Dobson DC, 1997, SIAM J NUMER ANAL, V34, P1779, DOI 10.1137/S003614299528701X; DONOHO DL, 1989, SIAM J APPL MATH, V49, P906, DOI 10.1137/0149053; DONOHO DL, 1992, SIAM J APPL MATH, V52, P577, DOI 10.1137/0152031; Eke land I., 1976, STUDIES MATH ITS APP, V1; Engl H., 1996, MATH APPL, V375; EVANS L. C., 1992, MEASURE THEORY FINE; FORNASIER M, 2009, CONVERGENT OVERLAPPI; Fornasier M, 2007, INVERSE PROBL, V23, P2505, DOI 10.1088/0266-5611/23/6/014; Fornasier M, 2008, APPL COMPUT HARMON A, V25, P187, DOI 10.1016/j.acha.2007.10.005; Goldstein T., 2008, 0829 UCLA CAM; LEE YJ, 2003, 14 INT C DOM DEC MET, P315; Lions PL, 1988, P 1 INT S DOM DEC ME, P1; Loris I, 2009, INVERSE PROBL, V25, DOI 10.1088/0266-5611/25/3/035008; NABBEN R, 2005, 051103 TEMPL U DEP M; Quarteroni A., 1999, NUMER MATH SCI COMPU; Rockafellar R. T., 1998, GRUNDLEHREN MATH WIS, V317; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; Tai XC, 2002, MATH COMPUT, V71, P105; Tai X.-C., 2001, MATH COMPUT, V71, DOI 10.1090/S0025-5718-01-01344-8; TAYLOR HL, 1979, GEOPHYSICS, V44, P39, DOI 10.1190/1.1440921; Vese L, 2001, APPL MATH OPT, V44, P131, DOI 10.1007/s00245-001-0017-7; Vonesch C, 2009, IEEE T IMAGE PROCESS, V18, P509, DOI 10.1109/TIP.2008.2008073; Xu JC, 2002, J AM MATH SOC, V15, P573, DOI 10.1090/S0894-0347-02-00398-3; XU JC, 1992, SIAM REV, V34, P581, DOI 10.1137/1034116	61	16	16	0	0	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	0036-1429			SIAM J NUMER ANAL	SIAM J. Numer. Anal.		2009	47	5					3397	3428		10.1137/070710779		32	Mathematics, Applied	Mathematics	518WY	WOS:000271727700009		
J	Lu, ZS				Lu, Zhaosong			SMOOTH OPTIMIZATION APPROACH FOR SPARSE COVARIANCE SELECTION	SIAM JOURNAL ON OPTIMIZATION			English	Article						sparse covariance selection; nonsmooth strictly concave maximization; smooth minimization	GRAPHICAL MODELS; MINIMIZATION; CONVEX; LASSO	In this paper we first study a smooth optimization approach for solving a class of nonsmooth strictly concave maximization problems whose objective functions admit smooth convex minimization reformulations. In particular, we apply Nesterov's smooth optimization technique [Y. E. Nesterov, Dokl. Akad. Nauk SSSR, 269 (1983), pp. 543-547; Y. E. Nesterov, Math. Programming, 103 (2005), pp. 127-152] to their dual counterparts that are smooth convex problems. It is shown that the resulting approach has O(1 root epsilon) iteration complexity for finding an epsilon-optimal solution to both primal and dual problems. We then discuss the application of this approach to sparse covariance selection that is approximately solved as an l(1)-norm penalized maximum likelihood estimation problem, and also propose a variant of this approach which has substantially outperformed the latter one in our computational experiments. We finally compare the performance of these approaches with other first-order methods, namely, Nesterov's O(1/epsilon) smooth approximation scheme and block-coordinate descent method studied in [A. d'Aspremont, O. Banerjee, and L. El Ghaoui, SIAM J. Matrix Anal. Appl., 30 (2008), pp. 56-66; J. Friedman, T. Hastie, and R. Tibshirani, Biostatistics, 9 (2008), pp. 432-441] for sparse covariance selection on a set of randomly generated instances. It shows that our smooth optimization approach substantially outperforms the first method above, and moreover, its variant substantially outperforms both methods above.	Simon Fraser Univ, Dept Math, Burnaby, BC V5A 1S6, Canada	Lu, ZS (reprint author), Simon Fraser Univ, Dept Math, Burnaby, BC V5A 1S6, Canada.	zhaosong@sfu.ca			NSERC; SFU President's Research Grant	Department of Mathematics, Simon Fraser University, Burnaby, BC, V5A 1S6, Canada (zhaosong @sfu.ca). This author was supported in part by NSERC Discovery Grant and SFU President's Research Grant.	AKAIKE JK, 1973, P 2 INT S INF THEOR, P267; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Auslender A, 2006, SIAM J OPTIMIZ, V16, P697, DOI 10.1137/S1052623403427823; Banerjee O., 2006, ICML 06, P89; BILMES JA, 2000, P IEEE INT C AC SPEE, V2, P1009; Chen P, 1998, STUD INTERF SCI, V6, P61; DAHL J, 2004, MAXIMUM LIKELIHOOD E; Dahl J, 2008, OPTIM METHOD SOFTW, V23, P501, DOI 10.1080/10556780802102693; D'Aspremont A, 2008, SIAM J MATRIX ANAL A, V30, P56, DOI 10.1137/060670985; DASPREMONT A, 2006, COVSEL 1 ORDER METHO; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; Dobra A., 2004, BAYESIAN COVARIANCE; Donoho DL, 2005, P NATL ACAD SCI USA, V102, P9446, DOI 10.1073/pnas.0502269102; FRIEDMAN J, 2007, GLASSO GRAPHICAL LAS; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; Jones B, 2005, STAT SCI, V20, P388, DOI 10.1214/088342305000000304; Nesterov Yu. E., 1983, Doklady Akademii Nauk SSSR, V269; Nesterov Y, 2005, SIAM J OPTIMIZ, V16, P235, DOI 10.1137/S1052623403422285; Nesterov Y. E., 1994, INTERIOR POINT POLYN	25	26	26	0	3	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	1052-6234			SIAM J OPTIMIZ	SIAM J. Optim.		2009	19	4					1807	1827		10.1137/070695915		21	Mathematics, Applied	Mathematics	421IV	WOS:000264353500013		
B	Angelosante, D; Grossi, E; Giannakis, GB; Lops, M			IEEE	Angelosante, D.; Grossi, E.; Giannakis, G. B.; Lops, M.			SPARSITY-AWARE ESTIMATION OF CDMA SYSTEM PARAMETERS	SPAWC: 2009 IEEE 10TH WORKSHOP ON SIGNAL PROCESSING ADVANCES IN WIRELESS COMMUNICATIONS			English	Proceedings Paper	10th IEEE Workshop on Signal Processing Advances in Wireless Communications	JUN 21-24, 2009	Perugia, ITALY	IEEE			CHANNEL ESTIMATION	The number of active users, their timing offsets, and their (possibly dispersive) channels with the access point are decisive parameters for wireless code division multiple access (CDMA). Estimating them as accurately as possible using as short as possible training sequences can markedly improve error performance as well as the capacity of CDMA systems. The fresh look advocated here permeates benefits from recent advances in variable selection (VS) and compressive sampling (CS) approaches to multiuser communications by casting estimation of these parameters as a sparse linear regression problem. Novel estimators are developed by exploiting two forms of sparsity present: the first emerging from user (in) activity, and the second because the actual nonzero parameters are very few relative to the number of candidate user delays and channel taps. Simulations demonstrate an order of magnitude gains in performance when sparsity-aware estimators of CDMA parameters are compared to sparsity-agnostic standard least-squares based alternatives.	[Angelosante, D.; Giannakis, G. B.] Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA	Angelosante, D (reprint author), Univ Minnesota, Dept ECE, Minneapolis, MN 55455 USA.						Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; BAZERQUE JA, 2008, P AS C SIGN SYST COM; Buzzi S, 2003, IEEE T SIGNAL PROCES, V51, P545, DOI 10.1109/TSP.2002.806987; Chen Y, 1998, NONCON OPTIM ITS APP, V20, P1; Cotter SF, 2002, IEEE T COMMUN, V50, P374, DOI 10.1109/26.990897; Kim S, 2004, IEEE SIGNAL PROC LET, V11, P12, DOI 10.1109/LSP.2003.819349; MOON TK, 1994, IEEE T COMMUN, V42, P2553, DOI 10.1109/26.310615; Strom EG, 1996, IEEE T COMMUN, V44, P84, DOI 10.1109/26.476100; TAUBOCK G, 2008, P IEEE C AC SPEECH S; XIE ZH, 1993, IEEE T COMMUN, V41, P1208, DOI 10.1109/26.231964	12	2	2	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3695-8				2009							697	701				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BNI87	WOS:000274650700141		
J	Lin, HZ; Yip, PSF; Chen, F				Lin, Huazhen; Yip, Paul S. F.; Chen, Feng			ESTIMATING THE POPULATION SIZE FOR A MULTIPLE LIST PROBLEM WITH AN OPEN POPULATION	STATISTICA SINICA			English	Article						Drug abusers; local polynomial; multiple-list; open population	CAPTURE-RECAPTURE EXPERIMENTS; LOCAL ESTIMATING EQUATIONS; RECORD SYSTEMS ESTIMATION; NONPARAMETRIC REGRESSION; MULTINOMIAL MODELS; VARIABLE SELECTION; SAMPLE COVERAGE; LIKELIHOOD; INFERENCE; POISSON	A semiparametric method using a local polynomial is proposed to estimate the population size at a specific time from multiple lists of an open population. The asymptotic distribution for the proposed estimators is derived. Simulation studies show that the proposed procedure works much better than existing methods. In addition, we provide a simple and efficient method to deal with the variable selection problem in a log-linear model when the number of the lists is large. The method is applied to estimate the number of drug-abusers in Hong Kong over the period 1977-1997.	[Lin, Huazhen] Sichuan Univ, Sch Math, Chengdu 610064, Peoples R China; [Yip, Paul S. F.] Univ Hong Kong, Dept Social Work & Social Adm, Hong Kong, Hong Kong, Peoples R China; [Chen, Feng] Univ New S Wales, Sch Math & Stat, Sydney, NSW 2052, Australia	Lin, HZ (reprint author), Sichuan Univ, Sch Math, Chengdu 610064, Peoples R China.	huazhenlin@hotmail.com; sfpyip@hku.hk; feng.chen@unsw.edu.au	Chen, Feng/B-5366-2009	Chen, Feng/0000-0002-9646-3338	Fund of National Natural Science of China [Grant 10771148]	Lin's research was supported in part by the Fund of National Natural Science (Grant 10771148) of China. The authors thank the Editors, an associate editor, and a referee for their valuable comments that have led to a significant improvement of this paper.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FAN JQ, 1992, J AM STAT ASSOC, V87, P998, DOI 10.2307/2290637; CORMACK RM, 1989, BIOMETRICS, V45, P395, DOI 10.2307/2531485; CHAO A, 1992, J AM STAT ASSOC, V87, P210, DOI 10.2307/2290471; CORMACK RM, 1991, BIOMETRIKA, V78, P911; Fan JQ, 2006, ANN STAT, V34, P290, DOI 10.1214/009053605000000796; Fan JQ, 2002, ANN STAT, V30, P74; FIENBERG SE, 1972, BIOMETRIKA, V59, P591, DOI 10.2307/2334810; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; Huggins RM, 1999, BIOMETRICS, V55, P387, DOI 10.1111/j.0006-341X.1999.00387.x; YIP PSF, 1995, AM J EPIDEMIOL, V142, P1059; YIP PSF, 1995, AM J EPIDEMIOL, V142, P1047; POLLARD D, 1991, ECONOMET THEOR, V7, P186; Rao C. R., 1973, LINEAR STAT INFERENC; Ruppert D, 1997, J AM STAT ASSOC, V92, P1049, DOI 10.2307/2965570; SANATHAN.L, 1972, ANN MATH STAT, V43, P142, DOI 10.1214/aoms/1177692709; SANDLAND RL, 1984, BIOMETRIKA, V71, P27, DOI 10.1093/biomet/71.1.27; Yang HC, 2003, STAT SINICA, V13, P673; Yang HC, 2003, BIOMETRICS, V59, P365, DOI 10.1111/1541-0420.00043; Huggins R, 2003, J STAT PLAN INFER, V113, P699, DOI 10.1016/S0378-3758(02)00093-9; YIP PSF, 1991, COMMUNICATION STAT T, V6, P2045	23	1	1	1	4	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405			STAT SINICA	Stat. Sin.	JAN	2009	19	1					177	196				20	Statistics & Probability	Mathematics	397VJ	WOS:000262690000015		
J	Engler, D; Li, Y				Engler, David; Li, Yi			Survival Analysis with High-Dimensional Covariates: An Application in Microarray Studies	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						survival analysis; microarray; elastic net; variable selection	PROPORTIONAL HAZARDS MODEL; FAILURE TIME MODEL; VARIABLE SELECTION; CENSORED-DATA; ADAPTIVE LASSO; REGRESSION	Use of microarray technology often leads to high-dimensional and low-sample size (HDLSS) data settings. A variety of approaches have been proposed for variable selection in this context. However, only a small number of these have been adapted for time-to-event data where censoring is present. Among standard variable selection methods shown both to have good predictive accuracy and to be computationally efficient is the elastic net penalization approach. In this paper, adaptations of the elastic net approach are presented for variable selection both under the Cox proportional hazards model and under an accelerated failure time (AFT) model. Assessment of the two methods is conducted through simulation studies and through analysis of microarray data obtained from a set of patients with diffuse large B-cell lymphoma where time to survival is of interest. The approaches are shown to match or exceed the predictive performance of a Cox-based and an AFT-based variable selection method. The methods are moreover shown to be much more computationally efficient than their respective Cox- and AFT-based counterparts.	[Engler, David] Brigham Young Univ, Provo, UT 84602 USA; [Li, Yi] Harvard Univ, Cambridge, MA 02138 USA; [Li, Yi] Dana Farber Canc Inst, Boston, MA 02115 USA	Engler, D (reprint author), Brigham Young Univ, Provo, UT 84602 USA.	engler@byu.edu; yili@jimmy.harvard.edu					Akaike H., 1973, P 2 INT S INF THEOR, P267; Sha NJ, 2006, BIOINFORMATICS, V22, P2262, DOI 10.1093/bioinformatics/btl362; Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; BUCKLEY J, 1979, BIOMETRIKA, V66, P429; Heagerty PJ, 2000, BIOMETRICS, V56, P337, DOI 10.1111/j.0006-341X.2000.00337.x; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; COX DR, 1972, J R STAT SOC B, V34, P187; Datta S, 2007, BIOMETRICS, V63, P259, DOI 10.1111/j.1541-0420.2006.00660.x; Datta S., 2005, STAT METHODOL, V2, P65, DOI 10.1016/j.stamet.2004.11.003; Fan JG, 2001, SHIJIE HUAREN XIAOHU, V9, P6; GHOSH S, 2007, PR0701 IUPUI; Gui J., 2005, PACIFIC S BIOCOMPUTI, V10, P272; HASTIE T, 1990, BIOMETRICS, V46, P1005, DOI 10.2307/2532444; Huang J, 2002, BIOMETRICS, V58, P781, DOI 10.1111/j.0006-341X.2002.00781.x; Huang J, 2006, BIOMETRICS, V62, P813, DOI 10.1111/j.1541-0420.2006.00562.x; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; Li H., 2003, PAC S BIOC, P65; Lu WB, 2007, STAT MED, V26, P3771, DOI 10.1002/sim.2833; SEGAL MR, 2005, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; VERWEIJ PJM, 1993, STAT MED, V12, P2305, DOI 10.1002/sim.4780122407; Wang HQ, 2007, ANTIOXID REDOX SIGN, V9, P553, DOI 10.1089/ars.2006.1524; Wang S, 2008, BIOMETRICS, V64, P132, DOI 10.1111/j.1541-0420.2007.00877.x; WEI LJ, 1992, STAT MED, V11, P1871, DOI 10.1002/sim.4780111409; WU CSP, 1995, J STAT COMPUT SIM, V51, P97, DOI 10.1080/00949659508811626; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037; ZOU H, 2009, ANN STAT IN PRESS	35	10	10	0	3	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2009	8	1							14	10.2202/1544-6115.1423		24	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	408NB	WOS:000263440600014		
J	Graf, AC; Bauer, P				Graf, Alexandra C.; Bauer, Peter			Model Selection Based on FDR-Thresholding Optimizing the Area under the ROC-Curve	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						variable selection; FDR; ROC-curve; cross validation	FALSE DISCOVERY RATE; RANK CORRELATION ESTIMATOR; LASSO; RATES	We evaluate variable selection by multiple tests controlling the false discovery rate (FDR) to build a linear score for prediction of clinical outcome in high-dimensional data. Quality of prediction is assessed by the receiver operating characteristic curve (ROC) for prediction in independent patients. Thus we try to combine both goals: prediction and controlled structure estimation. We show that the FDR-threshold which provides the ROC-curve with the largest area under the curve (AUC) varies largely over the different parameter constellations not known in advance. Hence, we investigated a new cross validation procedure based on the maximum rank correlation estimator to determine the optimal selection threshold. This procedure (i) allows choosing an appropriate selection criterion, (ii) provides an estimate of the FDR close to the true FDR and (iii) is simple and computationally feasible for rather moderate to small sample sizes. Low estimates of the cross validated AUC (the estimates generally being positively biased) and large estimates of the cross validated FDR may indicate a lack of sufficiently prognostic variables and/or too small sample sizes. The method is applied to an oncology dataset.	[Graf, Alexandra C.; Bauer, Peter] Med Univ Vienna, Vienna, Austria	Graf, AC (reprint author), Med Univ Vienna, Vienna, Austria.	alexandra.graf@meduniwien.ac.at; peter.bauer@meduniwien.ac.at			Austrian Science Fund (FWF) [P18698-n15]	This work was supported by the Austrian Science Fund (FWF) no. P18698-n15. We thank Martin Posch for valuable comments.	Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Bauer P, 2008, STAT MED, V27, P1565, DOI 10.1002/sim.3090; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Jeffery IB, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-359; Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; HAN AK, 1987, J ECONOMETRICS, V35, P303, DOI 10.1016/0304-4076(87)90030-3; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; SHERMAN RP, 1993, ECONOMETRICA, V61, P123, DOI 10.2307/2951780; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Moreno RP, 2005, INTENS CARE MED, V31, P1345, DOI 10.1007/s00134-005-2763-5; Bauer P., 1988, STATISTICS, V19, P39, DOI 10.1080/02331888808802068; Genovese C, 2004, ANN STAT, V32, P1035, DOI 10.1214/009053604000000283; Li L, 2007, J BIOPHARM STAT, V17, P883, DOI 10.1080/10543400701514056; NTZANI EE, 2003, LANCET, V362, P157; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Pepe MS, 2006, BIOMETRICS, V62, P221, DOI 10.1111/j.1541-0420.2005.00420.x; Pepe MS, 2003, STAT EVALUATION MED; R DEVELOPMENT CORE TEAM, 2005, R FDN STAT COMP; Tian E, 2003, NEW ENGL J MED, V349, P2483, DOI 10.1056/NEJMoa030847	20	2	2	1	1	WALTER DE GRUYTER & CO	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-6302			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2009	8	1							31	10.2202/1544-6115.1462		22	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	465QI	WOS:000267601500006		
J	Lebre, S				Lebre, Sophie			Inferring Dynamic Genetic Networks with Low Order Independencies	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						dynamic Bayesian networks; graphical modeling; directed acyclic graphs; conditional independence; networks inference; time series modeling	SACCHAROMYCES-CEREVISIAE; REGULATORY NETWORKS; MICROARRAY DATA; BAYESIAN NETWORKS; EXPRESSION DATA; REGRESSION; ASSOCIATIONS; DISCOVERY; SELECTION; MODELS	In this paper, we introduce a novel inference method for dynamic genetic networks which makes it possible to face a number of time measurements n that is much smaller than the number of genes p. The approach is based on the concept of a low order conditional dependence graph that we extend here in the case of dynamic Bayesian networks. Most of our results are based on the theory of graphical models associated with the directed acyclic graphs (DAGs). In this way, we define a minimal DAG G which describes exactly the full order conditional dependencies given in the past of the process. Then, to face with the large p and small n estimation case, we propose to approximate DAG G by considering low order conditional independencies. We introduce partial qth order conditional dependence DAGs G((q)) and analyze their probabilistic properties. In general, DAGs G((q)) differ from DAG G but still reflect relevant dependence facts for sparse networks such as genetic networks. By using this approximation, we set out a non-Bayesian inference method and demonstrate the effectiveness of this approach on both simulated and real data analysis. The inference procedure is implemented in the R package 'G1DBN' freely available from the R archive (CRAN).	Univ Evry Val Dessonne, CNRS, Lab Stat & Genome, UMR 8071, Evry, France	Lebre, S (reprint author), Univ Evry Val Dessonne, CNRS, Lab Stat & Genome, UMR 8071, Evry, France.	s.lebre@imperial.ac.uk					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; [Anonymous], SUPPLEMENTARY MAT; Zou M, 2005, BIOINFORMATICS, V21, P71, DOI 10.1093/bioinformatics/bth463; Smith SM, 2004, PLANT PHYSIOL, V136, P2687, DOI 10.1104/pp.104.044347; Tsai HK, 2005, P NATL ACAD SCI USA, V102, P13532, DOI 10.1073/pnas.0505874102; de la Fuente A, 2004, BIOINFORMATICS, V20, P3565, DOI 10.1093/bioinformatics/bth445; Butte AJ, 2000, P NATL ACAD SCI USA, V97, P12182, DOI 10.1073/pnas.220392197; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Efron B, 2004, ANN STAT, V32, P407; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Beal MJ, 2005, BIOINFORMATICS, V21, P349, DOI 10.1093/bioinformatics/bti014; Castelo R, 2006, J MACH LEARN RES, V7, P2621; Cox D.R., 1996, MULTIVARIATE DEPENDE; Edwards D, 1995, INTRO GRAPHICAL MODE; Efron B., 2005, LOCAL FALSE DISCOVER; FOX J, 2002, R S PLUS COMPANION A; Friedman N, 1998, P 14 C UNC ART INT, P139; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Imoto S, 2002, P PAC S BIOC, V7, P175; Imoto Seiya, 2003, J Bioinform Comput Biol, V1, P231, DOI 10.1142/S0219720003000071; Kim Sun Yong, 2003, Briefings in Bioinformatics, V4, P228, DOI 10.1093/bib/4.3.228; Kim S, 2004, BIOSYSTEMS, V75, P57, DOI 10.1016/j.biosystems.2004.03.004; Lauritzen SL, 1996, OXFORD STAT SCI SERI; LEBRE S, 2001, G1DBN PACKAGE PERFOR; Magwene PM, 2004, GENOME BIOL, P5; Meek C, 1995, P 11 ANN C UNC ART I; Murphy K, 1999, MODELLING GENE EXPRE; Murphy K. P., 2001, COMPUTING SCI STAT, V33; Ong Irene M, 2002, Bioinformatics, V18 Suppl 1, pS241; Opgen-Rhein R, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S2-S3; PEARL J., 1988, PROBABILISTIC REASON; Perrin BE, 2003, BIOINFORMATICS, V19, pS138; Rangel C, 2004, BIOINFORMATICS, V20, P1361, DOI 10.1093/bioinformatics/bth093; Schafer J., 2005, STAT APPL GENETICS M, V4; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; Spirtes P., 1993, CAUSATION PREDICTION; Steuer R, 2003, BIOINFORMATICS, V19, P1019, DOI 10.1093/bioinformatics/btg120; Sugimoto Naoya, 2004, Genome Inform, V15, P121; Teixeira MC, 2006, NUCLEIC ACIDS RES, V34, pD446, DOI 10.1093/nar/gkj013; Toh H, 2002, J BIOL PHYS, V28, P449, DOI 10.1023/A:1020337311471; Toh H, 2002, BIOINFORMATICS, V18, P287, DOI 10.1093/bioinformatics/18.2.287; Waddell PJ, 2000, GENOME INFORM, V11, P83; Waddell P J, 2000, Genome Inform Ser Workshop Genome Inform, V11, P129; Wang JB, 2003, BIOINFORMATICS, V19, P2210, DOI 10.1093/bioinformatics/btg298; Whittaker J, 1990, GRAPHICAL MODELS APP; Wille A, 2006, STAT APPL GENET MOL, P4; Wille A., 2004, GENOME BIOL, V5; Wu X., 2003, ACM SIGKDD WORKSH DA, V3, P63; XU FX, 2004, PAC S BIOC, P581	51	26	28	0	4	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2009	8	1							9	10.2202/1544-6115.1294		40	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	408NB	WOS:000263440600001		
J	Li, SY; Lu, Q; Fu, WJ; Romero, R; Cui, YH				Li, Shaoyu; Lu, Qing; Fu, Wenjiang; Romero, Roberto; Cui, Yuehua			A Regularized Regression Approach for Dissecting Genetic Conflicts that Increase Disease Risk in Pregnancy	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						complex disease; genetic conflicts; genomic imprinting; maternal-fetal genotype incompatibility; penalized mixture logistic regression	FOR-GESTATIONAL-AGE; INTRAUTERINE GROWTH RESTRICTION; PENALIZED LOGISTIC-REGRESSION; FETAL-GROWTH; IMPRINTED GENES; MFG TEST; ASSOCIATION; DEFINITION; EXPRESSION; MORBIDITY	Human diseases developed during pregnancy could be caused by the direct effects of both maternal and fetal genes, and/or by the indirect effects caused by genetic conflicts. Genetic conflicts exist when the effects of fetal genes are opposed by the effects of maternal genes, or when there is a conflict between the maternal and paternal genes within the fetal genome. The two types of genetic conflicts involve the functions of different genes in different genomes and are genetically distinct. Differentiating and further dissecting the two sets of genetic conflict effects that increase disease risk during pregnancy present statistical challenges, and have been traditionally pursued as two separate endeavors. In this article, we develop a unified framework to model and test the two sets of genetic conflicts via a regularized regression approach. Our model is developed considering real situations in which the paternal information is often completely missing; an assumption that fails most of the current family-based studies. A mixture model-based penalized logistic regression is proposed for data sampled from a natural population. We develop a variable selection procedure to select significant genetic features. Simulation studies show that the model has high power and good false positive control under reasonable sample sizes and disease allele frequency. A case study of small for gestational age (SGA) is provided to show the utility of the proposed approach. Our model provides a powerful tool for dissecting genetic conflicts that increase disease risk during pregnancy, and offers a testable framework for the genetic conflict hypothesis previously proposed.	[Li, Shaoyu; Lu, Qing; Fu, Wenjiang; Cui, Yuehua] Michigan State Univ, E Lansing, MI 48824 USA; [Romero, Roberto] NIH, NICHD, Bethesda, MD USA	Li, SY (reprint author), Michigan State Univ, E Lansing, MI 48824 USA.	lishaoyu@stt.msu.edu; qlu@epi.msu.edu; fuw@epi.msu.edu; prbchiefstaff@med.wayne.edu; cui@stt.msu.edu			NSF [DMS-0707031]; Eunice Kennedy Shriver National Institute of Child Health and Human Developmen; NIH; DHHS	The authors thank the editor and two anonymous referees for their constructive comments and useful suggestions that greatly improved the manuscript. This work was supported in part by NSF grant DMS-0707031 and by the Intramural Research Program of the Eunice Kennedy Shriver National Institute of Child Health and Human Development, NIH, DHHS. Address for correspondence: Dr. Yuehua Cui, Department of Statistics & Probability, Michigan State University, East Lansing, MI 48824.	Weinberg CR, 1998, AM J HUM GENET, V62, P969, DOI 10.1086/301802; LEE AH, 1988, COMMUN STAT SIMULAT, V17, P1231, DOI 10.1080/03610918808812723; Hao K, 2004, HUM MOL GENET, V13, P683, DOI 10.1093/hmg/ddh091; Morison IM, 2005, TRENDS GENET, V21, P457, DOI 10.1016/j.tig.2005.06.008; Park MY, 2008, BIOSTATISTICS, V9, P30, DOI 10.1093/biostatistics/kxm010; Constancia M, 2004, NATURE, V432, P53, DOI 10.1038/432053a; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; KAUNITZ AM, 1985, OBSTET GYNECOL, V65, P605; Devlin B, 1999, BIOMETRICS, V55, P997, DOI 10.1111/j.0006-341X.1999.00997.x; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Tycko B, 2002, J CELL PHYSIOL, V192, P245, DOI 10.1002/jcp.10129; Bernstein IM, 2000, AM J OBSTET GYNECOL, V182, P198, DOI 10.1016/S0002-9378(00)70513-8; Buyske S, 2008, EUR J HUM GENET, V16, P783, DOI 10.1038/ejhg.2008.74; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; Dunger DB, 2006, HORM RES, V65, P34, DOI 10.1159/000091504; Efron B, 1993, INTRO BOOTSTRAP; Fu WJ, 2005, J STAT PLAN INFER, V131, P333, DOI 10.1016/j.jspi.2004.03.001; Gardosi J, 2006, HORM RES, V65, P15, DOI 10.1159/000091501; GRAY RJ, 1992, J AM STAT ASSOC, V87, P942, DOI 10.2307/2290630; HAIG D, 2004, TROPHOBLAST RES, V18, pS10; HAIG D, 1993, Q REV BIOL, V68, P495, DOI 10.1086/418300; HAIG D, 2004, PLACENTA SA, V25; Hanson RL, 2001, AM J HUM GENET, V68, P951, DOI 10.1086/319508; Hastie TJ, 1990, GEN ADDITIVE MODELS; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hsieh HJ, 2006, GENET EPIDEMIOL, V30, P333, DOI 10.1002/gepi.20148; Hsieh HJ, 2006, HUM HERED, V62, P165, DOI 10.1159/000096444; Hu YQ, 2007, GENETICS, V175, P1489, DOI 10.1534/genetics.106.058461; Isles AR, 2005, EARLY HUM DEV, V81, P73, DOI 10.1016/j.earlhumdev.2004.10.006; Lamb KA, 1998, MOL REPROD DEV, V51, P218; Lu Q, 2008, AM J HUM GENET, V82, P641, DOI 10.1016/j.ajhg.2007.12.025; LYNCH M, 1998, GEN ANAL QUANTITATIV; MCCULLAGH P, 1989, GEN LINEAR MODELS CH; Minassian SL, 2005, GENET EPIDEMIOL, V28, P83, DOI 10.1002/gepi.20027; Odent M, 2001, MedGenMed, V3, P2; Parimi N, 2008, BMC MED GENET, V9, DOI 10.1186/1471-2350-9-60; PAZ I, 1995, OBSTET GYNECOL, V85, P452; Pfeifer K, 2000, AM J HUM GENET, V67, P777, DOI 10.1086/303101; Saenger P, 2007, ENDOCR REV, V28, P219, DOI 10.1210/er.2006-0039; Shete S, 2005, HUM HERED, V59, P26, DOI 10.1159/000084734; Shete S, 2002, AM J HUM GENET, V70, P751, DOI 10.1086/338931; Sinsheimer JS, 2003, GENET EPIDEMIOL, V24, P1, DOI 10.1002/gepi.10211; Tabano S, 2006, PEDIATR RES, V59, P250, DOI 10.1203/01.pdr.0000199441.62045.a1; TAYLOR DJ, 1989, BRIT J OBSTET GYNAEC, V96, P789, DOI 10.1111/j.1471-0528.1989.tb03317.x; VILLAR J, 1990, AM J OBSTET GYNECOL, V163, P151; Wang LF, 2007, BIOINFORMATICS, V23, P1486, DOI 10.1093/bioinformatics/btm125; Wollmann HA, 1998, HORM RES, V49, P1, DOI 10.1159/000053079; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046	49	13	13	2	4	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-6302	1544-6115		STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2009	8	1							45	10.2202/1544-6115.1474		30	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	513IP	WOS:000271316200002		
J	Parkhomenko, E; Tritchler, D; Beyene, J				Parkhomenko, Elena; Tritchler, David; Beyene, Joseph			Sparse Canonical Correlation Analysis with Application to Genomic Data Integration	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						canonical correlation; sparseness; data integration	HUMAN GENE-EXPRESSION; LINKAGE; LASSO	Large scale genomic studies with multiple phenotypic or genotypic measures may require the identification of complex multivariate relationships. In multivariate analysis a common way to inspect the relationship between two sets of variables based on their correlation is canonical correlation analysis, which determines linear combinations of all variables of each type with maximal correlation between the two linear combinations. However, in high dimensional data analysis, when the number of variables under consideration exceeds tens of thousands, linear combinations of the entire sets of features may lack biological plausibility and interpretability. In addition, insufficient sample size may lead to computational problems, inaccurate estimates of parameters and non-generalizable results. These problems may be solved by selecting sparse subsets of variables, i.e. obtaining sparse loadings in the linear combinations of variables of each type. In this paper we present Sparse Canonical Correlation Analysis (SCCA) which examines the relationships between two types of variables and provides sparse solutions that include only small subsets of variables of each type by maximizing the correlation between the subsets of variables of different types while performing variable selection. We also present an extension of SCCA - adaptive SCCA. We evaluate their properties using simulated data and illustrate practical use by applying both methods to the study of natural variation in human gene expression.	[Parkhomenko, Elena; Beyene, Joseph] Univ Toronto, Hosp Sick Children, Res Inst, Toronto, ON M5S 1A1, Canada; [Tritchler, David] SUNY Buffalo, Univ Toronto, Ontario Canc Inst, Buffalo, NY 14260 USA	Parkhomenko, E (reprint author), Univ Toronto, Hosp Sick Children, Res Inst, Toronto, ON M5S 1A1, Canada.	elena@utstat.toronto.edu; tritchle@uhnres.utoronto.ca; joseph@utstat.toronto.edu			Natural Sciences and Engineering Research Council of Canada (NSERC); Mathematics of Information Technology and Complex Systems (MITACS); Canadian Institute of Health Research (CIHR) [84392]; Genome Canada through the Ontario Genomics Institute; Genetic Analysis Workshop [R01 GM031575, HG002386]	This work was partially supported by grants from the Natural Sciences and Engineering Research Council of Canada (NSERC), the Mathematics of Information Technology and Complex Systems (MITACS), Canadian Institute of Health Research (CIHR)(grant number 84392), and Genome Canada through the Ontario Genomics Institute. The data collection was funded by Genetic Analysis Workshop grant, R01 GM031575, as well as HG002386. We are grateful to Shelley Bull, Michael Escobar and Angelo Canty for many helpful comments and suggestions.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Cheung VG, 2005, NATURE, V437, P1365, DOI 10.1038/nature04244; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; COMMENGES D, 1994, GENET EPIDEMIOL, V11, P189, DOI 10.1002/gepi.1370110208; GOOD IJ, 1969, TECHNOMETRICS, V11, P828; Johnstone I. M., 2004, SPARSE PRINCIPAL COM; Mardia KV, 1979, MULTIVARIATE ANAL; MEINSHAUSEN N, 2004, VARIABLE SELECTION H; Morley M, 2004, NATURE, V430, P743, DOI 10.1038/nature02797; Parkhomenko Elena, 2007, BMC Proc, V1 Suppl 1, pS119; Tritchler D, 2003, BIOMETRICS, V59, P382, DOI 10.1111/1541-0420.00045; Vinod H. D., 1976, J ECONOMETRICS, V4, P147, DOI 10.1016/0304-4076(76)90010-5; Waaijenborg S., 2008, STAT APPL GENETICS M, V7; Waaijenborg Sandra, 2007, BMC Proc, V1 Suppl 1, pS122; Wegelin J. A., 2000, SURVEY PARTIAL LEAST; WOLD H, 1985, PARTIAL LEAST SQUARE, P581; Wold H., 1982, SYSTEMS INDIRECT O 2, P1; Zou H., 2004, J COMPUT GRAPH STAT, V15, P2006	20	35	36	2	15	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2009	8	1							1	10.2202/1544-6115.1406		36	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	408NB	WOS:000263440600011		
J	Qin, LX; Satagopan, JM				Qin, Li-Xuan; Satagopan, Jaya M.			Normalization Method for Transcriptional Studies of Heterogeneous Samples - Simultaneous Array Normalization and Identification of Equivalent Expression	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						gene expression; normalization; mixture models; Fisher's information	GENE-EXPRESSION; OLIGONUCLEOTIDE ARRAYS; DNA MICROARRAY; TRANSFORMATIONS; ANTAGONIST; VARIANCE; ERROR; MODEL	Normalization is an important step in the analysis of microarray data of transcription profiles as systematic non-biological variations often arise from the multiple steps involved in any transcription profiling experiment. Existing methods for data normalization often assume that there are few or symmetric differential expression, but this assumption does not always hold. Alternatively, non-differentially expressed genes may be used for array normalization. However, it is unknown at the outset which genes are non-differentially expressed. In this paper we propose a hierarchical mixture model framework to simultaneously identify non-differentially expressed genes and normalize arrays using these genes. The Fisher's information matrix corresponding to array effects is derived, which provides useful intuition for guiding the choice of array normalization method. The operating characteristics of the proposed method are evaluated using simulated data. The simulations conducted under a wide range of parametric configurations suggest that the proposed method provides a useful alternative for array normalization. For example, the proposed method has better sensitivity than median normalization under modest prevalence of differentially expressed genes and when the magnitudes of over-expression and under-expression are not the same. Further, the proposed method has properties similar to median normalization when the prevalence of differentially expressed genes is very small. Empirical illustration of the proposed method is provided using a liposarcoma study from MSKCC to identify genes differentially expressed between normal fat tissue versus liposarcoma tissue samples.	[Qin, Li-Xuan; Satagopan, Jaya M.] Mem Sloan Kettering Canc Ctr, New York, NY 10021 USA	Qin, LX (reprint author), Mem Sloan Kettering Canc Ctr, New York, NY 10021 USA.	qinl@mskcc.org; satagopj@mskcc.org			NIH [2P01CA047179-15A2]; Clinical and Translation Science Center at Weill Cornell Medical College [UL1RR024996]	We thank two anonymous reviewers for insightful comments. We also thank Dr. Sam Singer at MSKCC for providing the liposarcoma data. This work was supported in part by NIH grants 2P01CA047179-15A2 (LXQ) and UL1RR024996 of the Clinical and Translation Science Center at Weill Cornell Medical College (LXQ and JS).	Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lipshutz RJ, 1999, NAT GENET, V21, P20, DOI 10.1038/4447; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Kendziorski CM, 2003, STAT MED, V22, P3899, DOI 10.1002/sim.1548; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; HANLEY JA, 1982, RADIOLOGY, V143, P29; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Thellin O, 1999, J BIOTECHNOL, V75, P291, DOI 10.1016/S0168-1656(99)00163-7; Muller CR, 2007, INT J CANCER, V121, P199, DOI 10.1002/ijc.22643; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15; ATKINSON A, 2008, PLOTS TRANSFORMATION; BARONE MV, 1994, GENE DEV, V8, P453, DOI 10.1101/gad.8.4.453; CARROLL RJ, 1980, J ROY STAT SOC B MET, V42, P71; Chibon F, 2004, GENE CHROMOSOME CANC, V40, P32, DOI 10.1002/gcc.20012; Durbin BP, 2004, BIOINFORMATICS, V20, P660, DOI 10.1093/bioinformatics/btg464; Gauthier A, 2003, J BIOL CHEM, V278, P11945, DOI 10.1074/jbc.M212989200; Guo Y, 2008, CANCER RES, V68, P3350, DOI 10.1158/0008-5472.CAN-07-3220; Hastie T., 2001, ELEMENTS STAT LEARNI; Hoerl A.E, 1962, CHEM ENG PROGR, V58, P54; Huber W., 2003, STAT APPL GENET MOL, V2, DOI 10.2202/1544-6115.1008; LaTulippe E, 2002, CANCER RES, V62, P4499; LOUIS TA, 1982, J ROY STAT SOC B MET, V44, P226; Nguyen DV, 2002, BIOMETRICS, V58, P701, DOI 10.1111/j.0006-341X.2002.00701.x; Purdom E, 2005, STAT APPL GENET MO B, V4; Reilly C, 2003, J AM STAT ASSOC, V98, P868, DOI 10.1198/016214503000000800; Robinson G. K., 1991, STAT SCI, V6, P15, DOI DOI 10.1214/SS/1177011926; Rocke DM, 2001, J COMPUT BIOL, V8, P557, DOI 10.1089/106652701753307485; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Singer S, 2007, CANCER RES, V67, P6626, DOI 10.1158/0008-5472.CAN-07-0584; Zhao YD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1176/1471-2105-6-28	32	3	3	1	1	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2009	8	1							10	10.2202/1544-6115.1339		25	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	408NB	WOS:000263440600003		
J	Tuglus, C; van der Laan, MJ				Tuglus, Catherine; van der Laan, Mark J.			Modified FDR Controlling Procedure for Multi-Stage Analyses	STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY			English	Article						false discovery rate; modified FDR; targeted maximum likelihood	CLASSIFICATION; DISCOVERY	Multiple testing has become an integral component in genomic analyses involving microarray experiments where a large number of hypotheses are tested simultaneously. However, before applying more computationally intensive methods, it is often desirable to complete an initial truncation of the variable set using a simpler and faster supervised method such as univariate regression. Once such a truncation is completed, multiple testing methods applied to any subsequent analysis no longer control the appropriate Type I error rates. Here we propose a modified marginal Benjamini & Hochberg step-up FDR controlling procedure for multi-stage analyses (FDR-MSA), which correctly controls Type I error in terms of the entire variable set when only a subset of the initial set of variables is tested. The method is presented with respect to a variable importance application. As the initial subset size increases, we observe convergence to the standard Benjamini & Hochberg step-up FDR controlling multiple testing procedures. We demonstrate the power and Type I error control through simulation and application to the Golub Leukemia data from 1999.	[Tuglus, Catherine; van der Laan, Mark J.] Univ Calif Berkeley, Berkeley, CA 94720 USA	Tuglus, C (reprint author), Univ Calif Berkeley, Berkeley, CA 94720 USA.	ctuglus@berkeley.edu; laan@stat.berkeley.edu			NIH National Institute of Allergy and Infectious Diseases [R01 A1074345-01]	This work was done under the grant for Targeted Empirical Super Learning in HIV Research, funding through NIH National Institute of Allergy and Infectious Diseases; Award number R01 A1074345-01.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BEMBOM O, 2007, U C BERKELEY DIVISIO; Breiman L., 1984, CLASSIFICATION REGRE; EFRON R, LARS R PACKAGE; OCONNOR M, POLYMARS R PACKAGE P; POLLARD KS, 2005, STAT BIOL HLTH SERIE; SINISI SE, 2004, U C BERKELEY DIVISIO; TUGLUS C, 2008, U C BERKELEY D UNPUB; VANDERLAAN M, 2006, U C BERKELEY DIVISIO; VANDERLAAN MJ, 2007, U C BERKELEY DIVISIO; VANDERLAAN MJ, 2005, U C BERKELEY DIVISIO	15	2	2	1	1	BERKELEY ELECTRONIC PRESS	BERKELEY	2809 TELEGRAPH AVENUE, STE 202, BERKELEY, CA 94705 USA	1544-6115			STAT APPL GENET MOL	Stat. Appl. Genet. Mol. Biol.		2009	8	1							12	10.2202/1544-6115.1397		17	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Mathematical & Computational Biology; Mathematics	408NB	WOS:000263440600008		
J	Wu, YC; Liu, YF				Wu, Yichao; Liu, Yufeng			Stepwise multiple quantile regression estimation using non-crossing constraints	STATISTICS AND ITS INTERFACE			English	Article						Constraints; non-crossing; quantile regression; RKHS; variable selection	SUPPORT VECTOR MACHINES; SMOOTHING SPLINES; SHRINKAGE; SELECTION; SURVIVAL; CURVES; LASSO	Quantile regression is an important statistical tool for statistical modeling. It has been widely used in various fields including econometrics, medicine, and bioinformatics. Despite its popularity in practice, individually estimated quantile regression functions often cross each other and consequently violate the basic properties of quantiles. In this paper we propose a new method for estimating multiple quantile regression functions without crossing. Both linear and kernel quantile regression models are considered. Several numerical examples are presented to illustrate competitive performance of the proposed method.	[Wu, Yichao] N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA; [Liu, Yufeng] Univ N Carolina, Dept Stat & Operat Res, Carolina Ctr Genome Sci, Chapel Hill, NC 27599 USA	Wu, YC (reprint author), N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA.	wu@stat.ncsu.edu; yfliu@email.unc.edu			NSF [DMS-0905561, DMS-0606577, DMS-0747575]	Wu's research was support in part by NSF grant DMS-0905561.Liu's research was supported in part by NSF grants DMS-0606577 and DMS-0747575.	KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; He XM, 1998, J ROY STAT SOC B, V60, P537, DOI 10.1111/1467-9868.00138; Wang HS, 2007, J BUS ECON STAT, V25, P347, DOI 10.1198/073500106000000251; Li YJ, 2008, J COMPUT GRAPH STAT, V17, P163, DOI 10.1198/106186008X289155; Koenker R, 2001, J AM STAT ASSOC, V96, P458, DOI 10.1198/016214501753168172; Yu KM, 2003, J ROY STAT SOC D-STA, V52, P331, DOI 10.1111/1467-9884.00363; Wu YC, 2007, J AM STAT ASSOC, V102, P974, DOI 10.1198/016214507000000617; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; COLE TJ, 1992, STAT MED, V11, P1305, DOI 10.1002/sim.4780111005; He XM, 1997, AM STAT, V51, P186, DOI 10.2307/2685417; Heagerty PJ, 1999, J ROY STAT SOC C-APP, V48, P533, DOI 10.1111/1467-9876.00170; HENDRICKS W, 1992, J AM STAT ASSOC, V87, P58, DOI 10.2307/2290452; Koenker R, 2001, J ECON PERSPECT, V15, P143, DOI 10.1257/jep.15.4.143; KOENKER R, 1994, BIOMETRIKA, V81, P673; Koenker R, 2005, QUANTILE REGRESSION; Li YJ, 2007, J AM STAT ASSOC, V102, P255, DOI 10.1198/016214506000000979; NEOCLEOUSA T, 2007, STAT PROBABILITY LET, V78, P1226; Takeuchi I, 2006, J MACH LEARN RES, V7, P1231; Yang S, 1999, J AM STAT ASSOC, V94, P137, DOI 10.2307/2669689; Yuan M, 2006, COMPUT STAT DATA AN, V50, P813, DOI 10.1016/j.csda.2004.10.008	22	10	10	1	5	INT PRESS BOSTON, INC	SOMERVILLE	PO BOX 43502, SOMERVILLE, MA 02143 USA	1938-7989			STAT INTERFACE	Stat. Interface		2009	2	3					299	310				12	Mathematical & Computational Biology; Mathematics, Interdisciplinary Applications	Mathematical & Computational Biology; Mathematics	660NN	WOS:000282650400005		
J	Breheny, P; Huang, JA				Breheny, Patrick; Huang, Jian			Penalized methods for bi-level variable selection	STATISTICS AND ITS INTERFACE			English	Article						High-dimensional data; Grouping structure; Minimax concave penalty; Local coordinate descent algorithms; Genetic association studies	MODEL SELECTION; REGRESSION; LASSO; OPTIMIZATION; LIKELIHOOD; SHRINKAGE	In many applications, covariates possess a grouping structure that can be incorporated into the analysis to select important groups as well as important members of those groups. This work focuses on the incorporation of grouping structure into penalized regression. We investigate the previously proposed group lasso and group bridge penalties as well as a novel method, group MCP, introducing a framework and conducting simulation studies that shed light on the behavior of these methods. To fit these models, we use the idea of a locally approximated coordinate descent to develop algorithms which are fast and stable even when the number of features is much larger than the sample size. Finally, these methods are applied to a genetic association study of age-related macular degeneration.	[Huang, Jian] Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA; [Breheny, Patrick] Univ Kentucky, Dept Biostat, Lexington, KY 40506 USA	Huang, JA (reprint author), Univ Iowa, Dept Stat & Actuarial Sci, Iowa City, IA 52242 USA.	jian-huang@uiowa.edu			U.S. National Cancer Institute [R01CA120988]; U.S. National Science Foundation [DMS-0805670]; National Institute of General Medical Sciences [T32GM077973]	The authors would like to thank Rob Mullins for the genetic association data analyzed in Section 5. They also would like to thank the referee for constructive comments that helped to clarify several points in the paper. Jian Huang was supported in part by grant R01CA120988 from the U.S. National Cancer Institute and award DMS-0805670 from the U.S. National Science Foundation. Patrick Breheny was supported by grant T32GM077973 from the National Institute of General Medical Sciences.	Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Meier L, 2008, J R STAT SOC B, V70, P53; Zou H, 2008, ANN STAT, V36, P1509, DOI 10.1214/009053607000000802; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Wu TT, 2008, ANN APPL STAT, V2, P224, DOI 10.1214/07-AOAS147; Breiman L, 1996, ANN STAT, V24, P2350; Friedman J., 2008, REGULARIZATION PATHS; Hastie T., 2001, ELEMENTS STAT LEARNI; HUANG J, 2007, 376 U IOW DEP STAT A; Nelder JA, 1999, GEN LINEAR MODELS; Zhang C. H., 2007, 2007003 RUTG U DEP S; ZHAO P, 2006, 703 U CAL DEP STAT; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	21	26	27	0	1	INT PRESS BOSTON, INC	SOMERVILLE	PO BOX 43502, SOMERVILLE, MA 02143 USA	1938-7989			STAT INTERFACE	Stat. Interface		2009	2	3					369	380				12	Mathematical & Computational Biology; Mathematics, Interdisciplinary Applications	Mathematical & Computational Biology; Mathematics	660NN	WOS:000282650400011		
J	Li, B; Yu, QZ				Li, Bin; Yu, Qingzhao			Robust and sparse bridge regression	STATISTICS AND ITS INTERFACE			English	Article						Coordinate descent; DC programming; Huber loss; Local linear approximation; Regularization	NONCONCAVE PENALIZED LIKELIHOOD; LEAST ANGLE REGRESSION; VARIABLE SELECTION; ORACLE PROPERTIES; LASSO; MODELS; ALGORITHMS; SHRINKAGE; TOOLS	It is known that when there are heavy-tailed errors or outliers in the response, the least squares methods may fail to produce a reliable estimator. In this paper, we proposed a generalized Huber criterion which is highly flexible and robust for large errors. We applied the new criterion to the bridge regression family, called robust and sparse bridge regression (RSBR). However, to get the RSBR solution requires solving a nonconvex minimization problem, which is a computational challenge. On the basis of recent advances in difference convex programming, coordinate descent algorithm and local linear approximation, we provide an efficient computational algorithm that attempts to solve this nonconvex problem. Numerical examples show the proposed RSBR algorithm performs well and suitable for large-scale problems.	[Li, Bin] Louisiana State Univ, Dept Expt Stat, Baton Rouge, LA 70803 USA; [Yu, Qingzhao] Louisiana State Univ, Hlth Sci Ctr, Sch Publ Hlth, Baton Rouge, LA 70803 USA	Li, B (reprint author), Louisiana State Univ, Dept Expt Stat, Baton Rouge, LA 70803 USA.	bli@lsu.edu; qyu@lsuhsc.edu					Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Liu YF, 2005, J COMPUT GRAPH STAT, V14, P219, DOI 10.1198/106186005X37238; An LTH, 1997, J GLOBAL OPTIM, V11, P253; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; [Anonymous], 2001, J OPTIMIZ THEORY APP, DOI DOI 10.1023/A:1017501703105; Wu YC, 2007, J AM STAT ASSOC, V102, P974, DOI 10.1198/016214507000000617; Zou H, 2008, ANN STAT, V36, P1509, DOI 10.1214/009053607000000802; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Wu TT, 2008, ANN APPL STAT, V2, P224, DOI 10.1214/07-AOAS147; Buhlmann P, 2008, ANN STAT, V36, P1534, DOI 10.1214/07-AOS0316A; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Friedman J. H., 2003, IMPORTANCE SAMPLED L; He XM, 2000, BIOMETRIKA, V87, P675, DOI 10.1093/biomet/87.3.675; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Huber P. J., 1981, ROBUST STAT; Maronna R. A., 2006, ROBUST STAT THEORY M; Meng XL, 2008, ANN STAT, V36, P1542, DOI 10.1214/07-AOS0316B; Pace RK, 1997, STAT PROBABIL LETT, V33, P291; Rosset S, 2004, ANN STAT, V32, P469; Vapnik V., 1998, STAT LEARNING THEORY; WANG H, 2006, J BUSINESS EC STAT, V11, P1	28	4	4	3	4	INT PRESS BOSTON, INC	SOMERVILLE	PO BOX 43502, SOMERVILLE, MA 02143 USA	1938-7989	1938-7997		STAT INTERFACE	Stat. Interface		2009	2	4					481	491				11	Mathematical & Computational Biology; Mathematics, Interdisciplinary Applications	Mathematical & Computational Biology; Mathematics	660NT	WOS:000282651000010		
J	Tian, GL; Fang, HB; Liu, ZQ; Tan, MT				Tian, Guo-Liang; Fang, Hong-Bin; Liu, Zhenqiu; Tan, Ming T.			Regularized (bridge) logistic regression for variable selection based on ROC criterion	STATISTICS AND ITS INTERFACE			English	Article						AUC; EM algorithm; Lasso regression; Logistic regression; MM algorithm; ROC; Variable/feature selection	LEAST ANGLE REGRESSION; LASSO; CONSTRAINTS; ARRAYS	It is well known that the bridge regression (with tuning parameter less or equal to 1) gives asymptotically unbiased estimates of the nonzero regression parameters while shrinking smaller regression parameters to zero to achieve variable selection. Despite advances in the last several decades in developing such regularized regression models, issues regarding the choice of penalty parameter and the computational methods for models fitting with parameter constraints even for bridge linear regression are still not resolved. In this article, we first propose a new criterion based on an area under the receiver operating characteristic (ROC) curve (AUC) to choose the appropriate penalty parameter as opposed to the conventional generalized cross-validation criterion. The model selected by the AUC criterion is shown to have better predictive accuracy while achieving sparsity simultaneously. We then approach the problem from a constrained parameter model and develop a fast minorization-maximization (MM) algorithm for non-linear optimization with positivity constraints for model fitting. This algorithm is further applied to bridge regression where the regression coefficients are constrained with l(p)-norm with the level of p selected by data for binary responses. Examples of prognostic factors and gene selection are presented to illustrate the proposed method.	[Tian, Guo-Liang] Univ Hong Kong, Dept Stat & Actuarial Sci, Hong Kong, Hong Kong, Peoples R China; [Fang, Hong-Bin; Liu, Zhenqiu; Tan, Ming T.] Univ Maryland, Greenebaum Canc Ctr, Div Biostat, Baltimore, MD 21201 USA	Tian, GL (reprint author), Univ Hong Kong, Dept Stat & Actuarial Sci, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.	gltian@hku.hk			ACS [IRG-97-153-07]	This research was supported in part by ACS Institutional Research Grants IRG-97-153-07. The authors thank the editor and the referees for their constructive comments.	Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Malioutov D, 2005, IEEE T SIGNAL PROCES, V53, P3010, DOI 10.1109/TSP.2005.850882; Knight K, 2000, ANN STAT, V28, P1356; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Efron B, 2004, ANN STAT, V32, P407; CRAVEN P, 1979, NUMER MATH, V31, P377; BOHNING D, 1988, ANN I STAT MATH, V40, P641, DOI 10.1007/BF00049423; de Leeuw J, 2006, COMPUT STAT DATA AN, V50, P21, DOI 10.1016/j.csda.2004.07.010; EFRON B., 1993, INTRO BOOT STRAP; Fan JQ, 2002, ANN STAT, V30, P74; GROENEN PJF, 2003, 200309 ER U EC I; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie T., 1990, GENERALIZED ADDITIVE; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; Liu CH, 2000, J AM STAT ASSOC, V95, P109, DOI 10.2307/2669531; Liu ZQ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1248; Madigan D, 2004, ANN STAT, V32, P465; MALLOWS CL, 1995, TECHNOMETRICS, V37, P362, DOI 10.2307/1269729; Pepe MS, 2003, STAT EVALUATION MED; Stine RA, 2004, ANN STAT, V32, P475; TAN M, 2003, DEV MODERN STAT RELA, P53; Tan M, 2007, STAT SINICA, V17, P945; WAHBA G, 2007, JOINT STAT M SALT LA	28	4	4	1	3	INT PRESS BOSTON, INC	SOMERVILLE	PO BOX 43502, SOMERVILLE, MA 02143 USA	1938-7989			STAT INTERFACE	Stat. Interface		2009	2	4					493	502				10	Mathematical & Computational Biology; Mathematics, Interdisciplinary Applications	Mathematical & Computational Biology; Mathematics	660NT	WOS:000282651000011		
J	Barrat, S; Tabbone, S				Barrat, Sabine; Tabbone, Salvatore			Classification and automatic annotation extension of images using a Bayesian network	TRAITEMENT DU SIGNAL			French	Article						Probabilistic graphical models; Bayesian networks; variable selection; image classification; image annotation	SELECTION; REGRESSION; ALGORITHM	The rapid growth of Internet and multimedia information has shown a need in the development of multimedia information retrieval techniques, especially in image retrieval. We can distinguish two main trends. The first one, called "text-based image retrieval", consists in applying text-retrieval techniques from fully annotated images. The text describes high-level concepts but this technique presents some drawbacks: it requires a tedious work of annotation. Moreover, annotations could be ambiguous because two users can use different keywords to describe a same image. Consequently some approaches have proposed to useWordnet in order to reduce these potential ambiguities. The second approach, called "content-based image retrieval" is a younger field. These methods rely on visual features (color, texture or shape) computed automatically, and retrieve images using a similarity measure. However, the obtained performances are not really acceptable, except in the case of well-focused corpus. In order to improve the recognition, a solution consists in combining visual and semantic information. In many vision problems, instead of having fully annotated training data, it is easier to obtain just a subset of data with annotations, because it is less restrictive for the user. This paper deals with modeling, classifying, and annotating weakly annotated images. More precisely, we propose a scheme for image classification optimization, using a joint visual-text clustering approach and automatically extending image annotations. The proposed approach is derived from the probabilistic graphical model theory and dedicated for both tasks of weakly-annotated image classification and annotation. We consider an image as weakly annotated if the number of keywords defined for it is less than the maximum defined in the ground truth. Thanks to their ability to manage missing values, a probabilistic graphical model has been proposed to represent weakly annotated images. We propose a probabilistic graphical model based on a Gaussian-Mixtures and Multinomial mixture. The visual features are estimated by the Gaussian mixtures and the keywords by a Multinomial distribution. Therefore, the proposed model does not require that all images be annotated: when an image is weakly annotated, the missing keywords are considered as missing values. Besides, our model can automatically extend existing annotations to weakly-annotated images, without user intervention. The uncertainty around the association between a set of keywords and an image is tackled by a joint probability distribution (defined from Gaussian-Mixtures and Multinomial mixture) over the dictionary of keywords and the visual features extracted from our collection of images. Moreover, in order to solve the dimensionality problem due to the large dimensions of visual features, we have adapted a variable selection method. Results of visual-textual classification, reported on a database of images collected from the Web, partially and manually annotated, show an improvement of about 32.3% in terms of recognition rate against only visual information classification. Besides the automatic annotation extension with our model for images with missing keywords outperforms the visual-textual classification of about 6.8%. Finally the proposed method is experimentally competitive with the state-of-art classifiers.	[Barrat, Sabine; Tabbone, Salvatore] Univ Nancy, LORIA UMR7503, F-54506 Vandoeuvre Les Nancy, France	Barrat, S (reprint author), Univ Nancy, LORIA UMR7503, BP 239, F-54506 Vandoeuvre Les Nancy, France.	barrat@loria.fr; tabbone@loria.fr					KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Efron B, 2004, ANN STAT, V32, P407; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; BENITEZ AB, 2002, IEEE INT C MULT EXP, V1, P189; Blei DM, 2003, SIGIR 03, P127; Breiman L., 2001, MACH LEARN, P5; Chang C., 2001, LIBSVM LIB SUPPORT V; DENOEUX T, 2007, P 56 SESS INT STAT I; Devijver P., 1982, PATTERN RECOGNITION; Duda R. O., 2001, PATTERN CLASSIFICATI; FENG SL, 2004, CVPR 04, V2, P1002; Gao Y., 2006, ACM MULTIMEDIA, P901; GROSKY WI, 2001, SOFSEM 01, P33; Gunes V, 2003, INT J PATTERN RECOGN, V17, P1303, DOI 10.1142/S0218001403002897; JIN R, 2004, MULTIMEDIA 04, P892; Jordan M., 1999, LEARNING GRAPHICAL M; KHERFI ML, 2004, ICPR 2004, V2, P961; Kim JH, 1983, IJCAI 83, P190; PICCARDI M, 2008, ICPR 08, P1; ROBERT C, 1997, DECISION THEORETIC M; RUI X, 2007, MULTIMEDIA 07, P585; TABBONE S, 2002, ICPR 02, V2, P200; Terrades O., 2007, ICDAR, V1, P227; Terrades O. R., 2009, PATTERN ANAL MACHINE, V31, P1630; Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647; Wendling L, 2008, LECT NOTES COMPUT SC, V5342, P947, DOI 10.1007/978-3-540-89689-0_98; Yang C., 2006, CVPR, P2057; ZHANG R, 2005, P 10 IEEE INT C COMP, V1, P846	34	0	0	0	5	PRESSES UNIV GRENOBLE	GRENOBLE	1041 RUE DES RESIDENCES, GRENOBLE, 38040, FRANCE	0765-0019			TRAIT SIGNAL	Trait. Signal		2009	26	5			SI		339	352				14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	606TO	WOS:000278450900003		
S	Daud, H; Sagayan, V; Yahya, N; Najwati, W		Zaman, HB; Robinson, P; Petrou, M; Olivier, P; Schroder, H; Shih, TK		Daud, Hanita; Sagayan, Vijanth; Yahya, Noorhana; Najwati, Wan			Modeling of Electromagnetic Waves Using Statistical and Numerical Techniques	VISUAL INFORMATICS: BRIDGING RESEARCH AND PRACTICE	Lecture Notes in Computer Science		English	Proceedings Paper	1st International Visual Informatics Conference	NOV 11-13, 2009	Kuala Lumpur, MALAYSIA	Univ Kebangsaan Malaysia, Univ Malaya, Univ Teknologi PETRONAS, Univ Utara Malaysia, Univ Sains Malaysia, Univ Putra Malaysia, Univ Teknologi Malaysia, Univ Teknologi MARA, Univ Malaysia Sarawak, Univ Pertahanan Nasional Malaysia, Univ Tunku Abdul Rahman, Multimedia Univ, Malaysian Informat Technol Soc, Multimedia Corp Malaysia, Malaysian Res Educ Network, Malaysian Inst Microelect		EM Waves; Regression; Spline Interpolation; Amplitude; Sum Square Error; Homogeneous		This paper presents a comparative study on the modeling of Electromagnetic (EM) waves using statistical and numerical techniques using MATLAB software. Authors focused only on amplitude modeling of EM waves at 0.25Hz frequency. The models using statistical and numerical techniques have been developed and sum square errors have been calculated and comparative studies have been made to find the best technique. First order and second order regressions were used for statistical models and polynomial curve fitting and spline interpolation were used for numerical technique. Results from these techniques were compared and we have found that spline interpolation gave the most fitted model to the EM wave amplitude.	[Daud, Hanita; Sagayan, Vijanth; Yahya, Noorhana] Univ Teknol PETRONAS, Fundamental & Appl Sci Dept, Tronoh 31750, Perak, Malaysia	Daud, H (reprint author), Univ Teknol PETRONAS, Fundamental & Appl Sci Dept, Tronoh 31750, Perak, Malaysia.	hanita_daud@petronas.com.my					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; [Anonymous], 2010, MATLAB LANGUAGE TECH; CHATTERJEE S, 1986, STAT SCI; Eidesmo T., 2002, SEA BED LOGGING SBL; HASNADAR Z, 2000, ELECTROMAGNETIC FIEL; LAVERGNAT J, 2000, RADIO WAVES PROPAGAT; Mosteller F., 1997, DATA ANAL REGRESSION; Warnick KF, 2005, IEEE ANTENN PROPAG M, V47, P111, DOI 10.1109/MAP.2005.1608751; Weiland T., 1977, ELECT COMMUNICATIONS, V31; ZAHN M, 1997, ELECTROMAGNETIC FIEL	10	0	0	1	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-05035-0	LECT NOTES COMPUT SC			2009	5857						686	695				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPM47	WOS:000279287600065		
J	Bialek, A; Forbes, A; Goodman, T; Montgomery, R; Rides, M; van der Heijden, G; van der Voet, H; Polder, G; Overvliet, K			IMEKO	Bialek, Agnieszka; Forbes, Alistair; Goodman, Teresa; Montgomery, Ruth; Rides, Martin; van der Heijden, Gerie; van der Voet, Hilko; Polder, Gerrit; Overvliet, Krista			MODEL DEVELOPMENT TO PREDICT PERCEIVED DEGREE OF NATURALNESS	XIX IMEKO WORLD CONGRESS: FUNDAMENTAL AND APPLIED METROLOGY, PROCEEDINGS			English	Proceedings Paper	19th IMEKO World Congress	SEP 06-12, 2009	Lisbon, PORTUGAL			regression; sensory metrology; perception		This paper presents the development of a mathematical model to predict the perception of naturalness for a range of materials, based on an understanding of the relationship between the physical attributes of the material and the human sensory inputs. The work is being carried out under an European Union project called 'Measurement of Naturalness' (MONAT), which focuses on understanding the relationships between the physical properties of natural and synthetic materials and the visual and tactile sensory processes that lead to perceptual judgments of naturalness. Integral to the project is the development of novel measurement facilities with dynamic ranges and sensitivities that are relevant for the human sensory systems. The input data to the model are derived from psychophysical and physical studies on pre-selected wood, textile and stone samples.	[Bialek, Agnieszka; Forbes, Alistair; Goodman, Teresa; Montgomery, Ruth; Rides, Martin] NPL, London, England	Bialek, A (reprint author), NPL, London, England.	teresa.goodman@npl.co.uk; gerie.vanderheijden@wur.nl; krista.overvliet@gmail.com	van der Voet, Hilko/A-4073-2013				Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; GOODMAN T, 2008, MEASUREMENT IN PRESS; MONTGOMERY R, 2008, MEASURING PHYS VISUA; Overvliet K. E., 2008, MEASURING PERCEPTION; VANDERVOET H, 1994, CHEMOMETR INTELL LAB, V25, P313, DOI 10.1016/0169-7439(94)85050-X; WHITAKER TA, 2008, NATURAL TRUTH CONTRI	6	1	1	0	1	IMEKO	BUDAPEST	PO BOX 457, H-1371 5 BUDAPEST, HUNGARY			978-963-88410-0-1				2009							2124	2129				6	Instruments & Instrumentation	Instruments & Instrumentation	BNU31	WOS:000275561600399		
J	Gonzalez-Recio, O; Gianola, D; Rosa, GJM; Weigel, KA; Kranis, A				Gonzalez-Recio, Oscar; Gianola, Daniel; Rosa, Guilherme J. M.; Weigel, Kent A.; Kranis, Andreas			Genome-assisted prediction of a quantitative trait measured in parents and progeny: application to food conversion rate in chickens	GENETICS SELECTION EVOLUTION			English	Article							WIDE SELECTION; GENETIC VALUE; DAIRY-CATTLE; MODEL; BROILERS; HERITABILITY; ASSOCIATION; PERFORMANCE; JACKKNIFE; MORTALITY	Accuracy of prediction of yet-to-be observed phenotypes for food conversion rate (FCR) in broilers was studied in a genome-assisted selection context. Data consisted of FCR measured on the progeny of 394 sires with SNP information. A Bayesian regression model (Bayes A) and a semi-parametric approach (Reproducing kernel Hilbert Spaces regression, RKHS) using all available SNPs (p = 3481) were compared with a standard linear model in which future performance was predicted using pedigree indexes in the absence of genomic data. The RKHS regression was also tested on several sets of pre-selected SNPs (p = 400) using alternative measures of the information gain provided by the SNPs. All analyses were performed using 333 genotyped sires as training set, and predictions were made on 61 birds as testing set, which were sons of sires in the training set. Accuracy of prediction was measured as the Spearman correlation ((r) over bar (S)) between observed and predicted phenotype, with its confidence interval assessed through a bootstrap approach. A large improvement of genome-assisted prediction (up to an almost 4-fold increase in accuracy) was found relative to pedigree index. Bayes A and RKHS regression were equally accurate ((r) over bar (S) = 0.27) when all 3481 SNPs were included in the model. However, RKHS with 400 pre-selected informative SNPs was more accurate than Bayes A with all SNPs.	[Gonzalez-Recio, Oscar; Gianola, Daniel; Rosa, Guilherme J. M.; Weigel, Kent A.] Univ Wisconsin, Dept Dairy Sci, Madison, WI 53706 USA; [Gianola, Daniel] Univ Wisconsin, Dept Anim Sci, Madison, WI 53706 USA; [Kranis, Andreas] Aviagen Ltd, Newbridge, Scotland	Gonzalez-Recio, O (reprint author), Univ Wisconsin, Dept Dairy Sci, Madison, WI 53706 USA.	gonzalez.oscar@inia.es; gianola@ansci.wisc.edu; grosa@wisc.edu; kweigel@facstaff.wisc.edu; akranis@aviagen.com	Rosa, Guilherme/G-3862-2011		Babcock Institute for International Dairy Research and Development; NSF [DMS-NSF DMS-044371]; National Association of Animal Breeders (Columbia, MO)	The authors wish to thank S Avendano (Aviagen Ltd.) for providing the data and comments, and A Legarra for discussion on computing matters. The first author thanks the financial support from the Babcock Institute for International Dairy Research and Development at the University of Wisconsin-Madison. The Wisconsin Agriculture Experiment Station, grant NSF DMS-NSF DMS-044371 and Aviagen Limited are acknowledged for support to D Gianola. K Weigel acknowledges the National Association of Animal Breeders (Columbia, MO) for partial financial support.	EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; HENDERSON CR, 1975, BIOMETRICS, V31, P423, DOI 10.2307/2529430; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hirschhorn JN, 2005, NAT REV GENET, V6, P95, DOI 10.1038/nrg1521; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; Andreescu C, 2007, GENETICS, V177, P2161, DOI 10.1534/genetics.107.082206; Meuwissen THE, 2001, GENETICS, V157, P1819; Dekkers J C M, 2004, J Anim Sci, V82 E-Suppl, pE313; EFRON B, 1981, BIOMETRIKA, V68, P589, DOI 10.1093/biomet/68.3.589; EWENS WJ, 2005, STAT METHODS BIOINFO, P49; Fernando RL, 2007, ACTA AGR SCAND A-AN, V57, P192, DOI 10.1080/09064700801959395; Gaya LG, 2006, POULTRY SCI, V85, P837; Gianola D, 2008, GENETICS, V178, P2289, DOI 10.1534/genetics.107.084285; Gianola D, 2006, GENETICS, V173, P1761, DOI 10.1534/genetics.105.049510; GIANOLA D, 1986, J ANIM SCI, V63, P217; Gonzalez-Recio O, 2008, GENETICS, V178, P2305, DOI 10.1534/genetics.107.084293; Guillaume F, 2008, GENET SEL EVOL, V40, P91, DOI 10.1051/gse:2007036; JANSS LLG, 1999, P COMP CATTL BREED W, P62; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Lee Y., 2002, NONLINEAR ESTIMATION, P125; LEGARRA A, 2007, P 58 ANN M EUR ASS A; Legarra A, 2008, J DAIRY SCI, V91, P360, DOI 10.3168/jds.2007-0403; Long N, 2007, J ANIM BREED GENET, V124, P377; MISZTAL I, 1987, J DAIRY SCI, V70, P716; Muir WM, 2007, J ANIM BREED GENET, V124, P342; PYM RAE, 1979, BRIT POULTRY SCI, V20, P73, DOI 10.1080/00071667908416551; Schaeffer LR, 2006, J ANIM BREED GENET, V123, P218, DOI 10.1111/j.1439-0388.2006.00595.x; Sorensen DA, 2002, LIKELIHOOD BAYESIAN, P588; ter Braak CJF, 2005, GENETICS, V170, P1435, DOI 10.1534/genetics.105.040469; Varona L, 2007, GENETICS, V177, P1791, DOI 10.1534/genetics.107.077818; Wahba G., 1990, SPLINE MODEL OBSERVA; Wahba G., 1999, ADV KERNEL METHODS S, P68; WASSERMAN L, 2006, ALL NONPARAMETRIC ST, P55; Wong GKS, 2004, NATURE, V432, P717, DOI 10.1038/nature03156; Xu SZ, 2003, GENETICS, V163, P789; Ye X, 2006, POULTRY SCI, V85, P1555; Zhang W, 2003, POULTRY SCI, V82, P1075	37	32	35	2	5	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	0999-193X			GENET SEL EVOL	Genet. Sel. Evol.	JAN 5	2009	41								3	10.1186/1297-9686-41-3		10	Agriculture, Dairy & Animal Science; Genetics & Heredity	Agriculture; Genetics & Heredity	437LC	WOS:000265488000003	19284693	
J	Binder, H; Schumacher, M				Binder, Harald; Schumacher, Martin			Incorporating pathway information into boosting estimation of high-dimensional risk prediction models	BMC BIOINFORMATICS			English	Article							NETWORK-CONSTRAINED REGULARIZATION; GENOMIC DATA; VARIABLE SELECTION; REGRESSION-MODELS; GENE ONTOLOGY; SURVIVAL; LASSO	Background: There are several techniques for fitting risk prediction models to high-dimensional data, arising from microarrays. However, the biological knowledge about relations between genes is only rarely taken into account. One recent approach incorporates pathway information, available, e. g., from the KEGG database, by augmenting the penalty term in Lasso estimation for continuous response models. Results: As an alternative, we extend componentwise likelihood-based boosting techniques for incorporating pathway information into a larger number of model classes, such as generalized linear models and the Cox proportional hazards model for time-to-event data. In contrast to Lasso-like approaches, no further assumptions for explicitly specifying the penalty structure are needed, as pathway information is incorporated by adapting the penalties for single microarray features in the course of the boosting steps. This is shown to result in improved prediction performance when the coefficients of connected genes have opposite sign. The properties of the fitted models resulting from this approach are then investigated in two application examples with microarray survival data. Conclusion: The proposed approach results not only in improved prediction performance but also in structurally different model fits. Incorporating pathway information in the suggested way is therefore seen to be beneficial in several ways.	[Binder, Harald; Schumacher, Martin] Univ Med Ctr Freiburg, Dept Med Biometry & Biostat, D-79104 Freiburg, Germany; [Binder, Harald] Univ Freiburg, Freiburg Ctr Data Anal & Modeling, D-79104 Freiburg, Germany	Binder, H (reprint author), Univ Med Ctr Freiburg, Dept Med Biometry & Biostat, Stefan Meier Str 26, D-79104 Freiburg, Germany.	binderh@fdm.uni-freiburg.de; ms@imbi.uni-freiburg.de	Binder, Harald/C-7413-2009	Binder, Harald/0000-0002-5666-8662	Deutsche Forschungsgemeinschaft (DFG)	We gratefully acknowledge support from Deutsche Forschungsgemeinschaft (DFG Forschergruppe FOR 534).	Buhlmann P, 2007, STAT SCI, V22, P477, DOI 10.1214/07-STS242; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Bild AH, 2006, NATURE, V439, P353, DOI 10.1038/nature04296; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Ashburner M, 2000, NAT GENET, V25, P25; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; BINDER H, 2008, STAT APPL GENET MOL, P7; Binder H, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-14; Binder H, 2008, BIOINFORMATICS, V24, P2566, DOI 10.1093/bioinformatics/btn412; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Gerds TA, 2007, BIOMETRICS, V63, P1283, DOI 10.1111/j.1541-0420.2007.00832.x; Goeman JJ, 2008, BIOINFORMATICS, V24, P537, DOI 10.1093/bioinformatics/btm628; Li CY, 2008, BIOINFORMATICS, V24, P1175, DOI 10.1093/bioinformatics/btn081; Luan YH, 2008, BIOSTATISTICS, V9, P100, DOI 10.1093/biostatistics/kxm015; McCullagh P., 1989, GENERALIZED LINEAR M, VSecond; Schumacher M, 2007, BIOINFORMATICS, V23, P1768, DOI 10.1093/bioinformatics/btm232; Tutz G, 2006, BIOMETRICS, V62, P961, DOI 10.1111/j.1541-0420.2006.00578.x; Tutz G, 2007, COMPUT STAT DATA AN, V51, P6044, DOI 10.1016/j.csda.2006.11.041; Wei P, 2008, BIOINFORMATICS, V24, P404, DOI 10.1093/bioinformatics/btm612; Wei Z, 2007, BIOSTATISTICS, V8, P265, DOI 10.1093/biostatistics/kxl007; Wei Z, 2008, ANN APPL STAT, V2, P408, DOI 10.1214/07-AOAS145	27	31	31	1	6	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JAN 13	2009	10								18	10.1186/1471-2105-10-18		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	416KY	WOS:000264006200001	19144132	
J	Le Cao, KA; Martin, PGP; Robert-Granie, C; Besse, P				Le Cao, Kim-Anh; Martin, Pascal G. P.; Robert-Granie, Christele; Besse, Philippe			Sparse canonical methods for biological data integration: application to a cross-platform study	BMC BIOINFORMATICS			English	Article							PRINCIPAL COMPONENT ANALYSIS; LEAST-SQUARES REGRESSION; CO-INERTIA ANALYSIS; EXPRESSION; CANCER; METABOLITE; SHRINKAGE; SELECTION; LASSO	Background: In the context of systems biology, few sparse approaches have been proposed so far to integrate several data sets. It is however an important and fundamental issue that will be widely encountered in post genomic studies, when simultaneously analyzing transcriptomics, proteomics and metabolomics data using different platforms, so as to understand the mutual interactions between the different data sets. In this high dimensional setting, variable selection is crucial to give interpretable results. We focus on a sparse Partial Least Squares approach (sPLS) to handle two-block data sets, where the relationship between the two types of variables is known to be symmetric. Sparse PLS has been developed either for a regression or a canonical correlation framework and includes a built-in procedure to select variables while integrating data. To illustrate the canonical mode approach, we analyzed the NCI60 data sets, where two different platforms (cDNA and Affymetrix chips) were used to study the transcriptome of sixty cancer cell lines. Results: We compare the results obtained with two other sparse or related canonical correlation approaches: CCA with Elastic Net penalization (CCA-EN) and Co-Inertia Analysis (CIA). The latter does not include a built-in procedure for variable selection and requires a two-step analysis. We stress the lack of statistical criteria to evaluate canonical correlation methods, which makes biological interpretation absolutely necessary to compare the different gene selections. We also propose comprehensive graphical representations of both samples and variables to facilitate the interpretation of the results. Conclusion: sPLS and CCA-EN selected highly relevant genes and complementary findings from the two data sets, which enabled a detailed understanding of the molecular characteristics of several groups of cell lines. These two approaches were found to bring similar results, although they highlighted the same phenomenons with a different priority. They outperformed CIA that tended to select redundant information.	[Le Cao, Kim-Anh; Robert-Granie, Christele] INRA, Stn Ameliorat Genet Anim, UR 631, F-31326 Castanet Tolosan, France; [Le Cao, Kim-Anh; Besse, Philippe] Univ Toulouse, Inst Math, F-31062 Toulouse, France; [Le Cao, Kim-Anh; Besse, Philippe] CNRS, UMR 5219, F-31062 Toulouse, France; [Martin, Pascal G. P.] INRA, UR 66, Lab Pharmacol & Toxicol, F-31931 Toulouse, France	Le Cao, KA (reprint author), INRA, Stn Ameliorat Genet Anim, UR 631, F-31326 Castanet Tolosan, France.	k.lecao@imb.uq.edu.au; Pascal.Martin@toulouse.inra.fr; Christele.Robert-Granie@toulouse.inra.fr; philippe.besse@math.univ-toulouse.fr	Le Cao, Kim-Anh/B-6637-2013	Le Cao, Kim-Anh/0000-0003-3923-1116			Yang J, 2008, DEV CELL, V14, P818, DOI 10.1016/j.devcel.2008.05.009; Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439; Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Shen HP, 2008, J MULTIVARIATE ANAL, V99, P1015, DOI 10.1016/j.jmva.2007.06.007; [Anonymous], 1976, APPL STAT, DOI DOI 10.2307/2347233; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; Butte AJ, 2000, P NATL ACAD SCI USA, V97, P12182, DOI 10.1073/pnas.220392197; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Calvano SE, 2005, NATURE, V437, P1032, DOI 10.1038/nature03985; Bylesjo M, 2007, PLANT J, V52, P1181, DOI 10.1111/j.1365-313X.2007.03293.x; CHUN H, 2007, SPARSE PARTIAL LEAST; COMBES S, 2008, MEAT SCI IN PRESS; Culhane AC, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-59; DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X; DOLEDEC S, 1994, FRESHWATER BIOL, V31, P277, DOI 10.1111/j.1365-2427.1994.tb01741.x; Fredman P, 2003, BIODRUGS, V17, P155, DOI 10.2165/00063030-200317030-00002; GITTINS R, 1985, CANONICAL ANAL REV A; GONZALEZ I, 2008, J BIOL SYST IN PRESS; Gonzalez I., 2008, J STAT SOFTWARE, V23; Juliano RL, 2004, BIOCHEM SOC T, V32, P443, DOI 10.1042/BST0320443; Kramer N, 2007, COMPUTATION STAT, V22, P249, DOI 10.1007/s00180-007-0038-z; Le Cao KA, 2008, STAT APPL GENET MOL, V7; LORBER A, 1987, J CHEMOMETR, V1, P13; PORTOUKALIAN J, 1979, EUR J BIOCHEM, V94, P19, DOI 10.1111/j.1432-1033.1979.tb12866.x; Tenenhaus M., 1998, REGRESSION PLS THEOR; Thioulouse J, 1997, STAT COMPUT, V7, P75, DOI 10.1023/A:1018513530268; Vijayendran C, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-4-r72; Vinod H. D., 1976, J ECONOMETRICS, V4, P147, DOI 10.1016/0304-4076(76)90010-5; Waaijenborg S, 2008, STAT APPL GENET MOL, V7; Wegelin J., 2000, 371 U WASH DEP STAT; Wold H., 1966, MULTIVARIATE ANAL; Wold S., 2004, PLS METHOD PARTIAL L; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	36	34	34	0	15	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JAN 26	2009	10								34	10.1186/1471-2105-10-34		17	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	416LF	WOS:000264006900001	19171069	
J	van Vliet, MH; Wessels, LFA; Reinders, MJT				van Vliet, Martin H.; Wessels, Lodewyk F. A.; Reinders, Marcel J. T.			Knowledge driven decomposition of tumor expression profiles	BMC BIOINFORMATICS			English	Article	9th Asia Pacific Bioinformatics Conference	JAN 13-16, 2009	Beijing, PEOPLES R CHINA		Tsinghua Univ		HUMAN BREAST-TUMORS; MOLECULAR PORTRAITS; CANCER; SIGNATURES; GENES; MAP	Background: Tumors have been hypothesized to be the result of a mixture of oncogenic events, some of which will be reflected in the gene expression of the tumor. Based on this hypothesis a variety of data-driven methods have been employed to decompose tumor expression profiles into component profiles, hypothetically linked to these events. Interpretation of the resulting data-driven components is often done by post-hoc comparison to, for instance, functional groupings of genes into gene sets. None of the data-driven methods allow the incorporation of that type of knowledge directly into the decomposition. Results: We present a linear model which uses knowledge driven, pre-defined components to perform the decomposition. We solve this decomposition model in a constrained linear least squares fashion. From a variety of options, a lasso-based solution to the model performs best in linking single gene perturbation data to mouse data. Moreover, we show the decomposition of expression profiles from human breast cancer samples into single gene perturbation profiles and gene sets that are linked to the hallmarks of cancer. For these breast cancer samples we were able to discern several links between clinical parameters, and the decomposition weights, providing new insights into the biology of these tumors. Lastly, we show that the order in which the Lasso regularization shrinks the weights, unveils consensus patterns within clinical subgroups of the breast cancer samples. Conclusion: The proposed lasso-based constrained least squares decomposition provides a stable and relevant relation between samples and knowledge-based components, and is thus a viable alternative to data-driven methods. In addition, the consensus order of component importance within clinical subgroups provides a better molecular characterization of the subtypes.	[van Vliet, Martin H.; Wessels, Lodewyk F. A.; Reinders, Marcel J. T.] Delft Univ Technol, Informat & Commun Theory Grp, Fac Elect Engn Math & Comp Sci, NL-2628 CD Delft, Netherlands; [van Vliet, Martin H.; Wessels, Lodewyk F. A.] Netherlands Canc Inst, Dept Mol Biol, Bioinformat & Stat Grp, NL-1066 CX Amsterdam, Netherlands	van Vliet, MH (reprint author), Delft Univ Technol, Informat & Commun Theory Grp, Fac Elect Engn Math & Comp Sci, Mekelweg 4, NL-2628 CD Delft, Netherlands.	M.H.vanVliet@TUDelft.nl; L.F.A.Wessels@TUDelft.nl; M.J.T.Reinders@TUDelft.nl					Acharya CR, 2008, JAMA-J AM MED ASSOC, V299, P1574, DOI 10.1001/jama.299.13.1574; Anders CK, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001373; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Sjoblom T, 2006, SCIENCE, V314, P268, DOI 10.1126/science.1133427; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Creighton CJ, 2006, CANCER RES, V66, P3903, DOI 10.1158/0008-5472.CAN-05-4363; Ashburner M, 2000, NAT GENET, V25, P25; Mootha VK, 2003, NAT GENET, V34, P267, DOI 10.1038/ng1180; Lamb J, 2006, SCIENCE, V313, P1929, DOI 10.1126/science.1132939; Hanahan D, 2000, CELL, V100, P57, DOI 10.1016/S0092-8674(00)81683-9; Segal E, 2004, NAT GENET, V36, P1090, DOI 10.1038/ng1434; Bild A, 2005, P NATL ACAD SCI USA, V102, P15278, DOI 10.1073/pnas.0507477102; Bild AH, 2006, NAT REV CANCER, V6, P735, DOI 10.1038/nrc1976; Chuang HY, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100180; Golub G., 1996, MATRIX COMPUTATIONS; Gong Y, 2007, LANCET ONCOL, V8, P203, DOI 10.1016/S1470-2045(07)70042-6; Hastie T., 2001, ELEMENTS STAT LEARNI; Hess KR, 2006, J CLIN ONCOL, V24, P4236, DOI 10.1200/JCO.2006.05.6861; Hu ZY, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-96; Karnaugh Maurice, 1953, AIEE T, V72, P593; Kreike B, 2007, BREAST CANCER RES, V9, DOI 10.1186/bcr1771; *MOS, MOS VERS 5 0 REV 60; TESCHENDORFF AE, 2007, PLOS COMPUT BIOL, V9, pE161; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vastrik I, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-3-r39; CHIP COMP UTILITY	29	1	1	0	0	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JAN 30	2009	10								S20	10.1186/1471-2105-10-S1-S20		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	439BN	WOS:000265601900020	19208120	
J	Zheng, H; Hang, XY; Zhu, J; Qian, MP; Qu, WB; Zhang, CG; Deng, MH				Zheng, Hao; Hang, Xingyi; Zhu, Ji; Qian, Minping; Qu, Wubin; Zhang, Chenggang; Deng, Minghua			REMAS: a new regression model to identify alternative splicing events from exon array data	BMC BIOINFORMATICS			English	Article	9th Asia Pacific Bioinformatics Conference	JAN 13-16, 2009	Beijing, PEOPLES R CHINA		Tsinghua Univ		MICROARRAYS	Background: Alternative splicing (AS) is an important regulatory mechanism for gene expression and protein diversity in eukaryotes. Previous studies have demonstrated that it can be causative for, or specific to splicing-related diseases. Understanding the regulation of AS will be helpful for diagnostic efforts and drug discoveries on those splicing-related diseases. As a novel exon-centric microarray platform, exon array enables a comprehensive analysis of AS by investigating the expression of known and predicted exons. Identifying of AS events from exon array has raised much attention, however, new and powerful algorithms for exon array data analysis are still absent till now. Results: Here, we considered identifying of AS events in the framework of variable selection and developed a regression method for AS detection (REMAS). Firstly, features of alternatively spliced exons were scaled by reasonably defined variables. Secondly, we designed a hierarchical model which can represent gene structure and transcriptional influence to exons, and the lasso type penalties were introduced in calculation because of huge variable size. Thirdly, an iterative two-step algorithm was developed to select alternatively spliced genes and exons. To avoid negative effects introduced by small sample size, we ranked genes as parameters indicating their AS capabilities in an iterative manner. After that, both simulation and real data evaluation showed that REMAS could efficiently identify potential AS events, some of which had been validated by RT-PCR or supported by literature evidence. Conclusion: As a new lasso regression algorithm based on hierarchical model, REMAS has been demonstrated as a reliable and effective method to identify AS events from exon array data.	[Zheng, Hao; Qian, Minping; Deng, Minghua] Peking Univ, LMAM, Sch Math Sci, Beijing 100871, Peoples R China; [Zheng, Hao; Qian, Minping; Deng, Minghua] Peking Univ, Ctr Theoret Biol, Beijing 100871, Peoples R China; [Hang, Xingyi; Qu, Wubin; Zhang, Chenggang] Beijing Inst Radiat Med, State Key Lab Proteom, Beijing 100850, Peoples R China; [Zhu, Ji] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA	Deng, MH (reprint author), Peking Univ, LMAM, Sch Math Sci, Beijing 100871, Peoples R China.	porcupine.hao@gmail.com; hangxy@bmi.ac.cn; jizhu@umich.edu; qianmp@math.pku.edu.cn; quwubin@mail.com; zhangcg@bmi.ac.cn; dengmh@math.pku.edu.cn	Zhang, Chenggang/B-1480-2009; Deng, Minghua/B-1316-2012; Deng, Minghua/B-5430-2012	Zhang, Chenggang/0000-0002-4521-3304; 			Anastassiou D, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-1-r2; Pruitt KD, 2005, NUCLEIC ACIDS RES, V33, pD501, DOI 10.1093/nar/gki025; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Modrek B, 2002, NAT GENET, V30, P13, DOI 10.1038/ng0102-13; Clark TA, 2002, SCIENCE, V296, P907, DOI 10.1126/science.1069415; Ule J, 2005, NAT GENET, V37, P844, DOI 10.1038/ng1610; Wang GS, 2007, NAT REV GENET, V8, P749, DOI 10.1038/nrg2164; Clark TA, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-4-r64; CLINE MS, 2005, BIOINFORMATICS, V21, P1107; Cuperlovic-Culf M, 2006, OMICS, V10, P344, DOI 10.1089/omi.2006.10.344; Davletov B, 2004, NAT STRUCT MOL BIOL, V11, P4, DOI 10.1038/nsmb0104-4; French PJ, 2007, CANCER RES, V67, P5635, DOI 10.1158/0008-5472.CAN-06-2869; GARDINA P, 2006, BMC GENOMICS, V7; Johnson JM, 2003, SCIENCE, V302, P2141, DOI 10.1126/science.1090100; KAPUR K, 2007, GENOME BIOL, V8; LE K, 2004, NUCL ACIDS RES, V32; Pan Q, 2004, MOL CELL, V16, P929, DOI 10.1016/j.molcel.2004.12.004; Shai O, 2006, BIOINFORMATICS, V22, P606, DOI 10.1093/bioinformatics/btk028; XING Y, 2008, RNA; Xing Y, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000088; Yeakley JM, 2002, NAT BIOTECHNOL, V20, P353, DOI 10.1038/nbt0402-353; YEO GWM, 2005, GENOME BIOL, V6	22	3	5	0	8	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JAN 30	2009	10								S18	10.1186/1471-2105-10-S1-S18		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	439BN	WOS:000265601900018	19208117	
J	Koltchinskii, V				Koltchinskii, Vladimir			Sparsity in penalized empirical risk minimization	ANNALES DE L INSTITUT HENRI POINCARE-PROBABILITES ET STATISTIQUES			English	Article						Empirical risk; Penalized empirical risk; l(p)-penalty; Sparsity; Oracle inequalities	LOCAL RADEMACHER COMPLEXITIES; ORACLE INEQUALITIES; MODEL SELECTION; LASSO; REGRESSION; RECONSTRUCTION; RECOVERY; ERROR	Let (X, Y) be a random couple in S x T with unknown distribution P. Let (X-1, Y-1),..., (X-n, Y-n) be i.i.d. copies of (X, Y). P-n being their emrical distribution. Let h(1),..., h(N) : S bar right arrow [- 1, 1] be a dictionary consisting of N functions. For lambda is an element of R-N. denote f(lambda) := Sigma(N)(j=1); lambda(j)h(j). Let l: T x R bar right aroow R be a given loss function, which is convex with respect to the second variable. Denote (l center dot f)(x, y) := l(y; f(x)). We study the following penalized empirical risk minimization problem (lambda) over cap (epsilon) := (lambda is an element of RN)argmin[P-n(l center dot f(lambda)) + epsilon parallel to lambda parallel to(p)(lp)], which is an empirical version of the problem (lambda) over cap (epsilon) :=argmin[P-n(l center dot f(lambda)) + epsilon parallel to lambda parallel to(p)(lp)] (here epsilon >= 0 is a regularization parameter; lambda(0) corresponds to epsilon = 0). A number of regression and classification problems fit this general framework. We are interested in the case when p >= 1, but it is close enough to 1 (so that p - 1 is of the order 1/log N, or smaller). We show that the "sparsity" of lambda(epsilon) implies the "sparsity" of (lambda) over cap (epsilon) and study the impact of "sparsity" on bounding the excess risk P(l center dot f((lambda) over cap epsilon)) - P(l center dot f(lambda 0)) of solutions of empirical risk minimization problems.	Georgia Inst Technol, Sch Math, Atlanta, GA 30332 USA	Koltchinskii, V (reprint author), Georgia Inst Technol, Sch Math, Atlanta, GA 30332 USA.	vlad@math.gatech.edu					Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Rudelson M, 2005, INT MATH RES NOTICES, P4019; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Koltchinskii V, 2005, ANN STAT, V33, P1455, DOI 10.1214/009053605000000228; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Barron A, 1999, PROBAB THEORY REL, V113, P301, DOI 10.1007/s004400050210; Bartlett PL, 2005, ANN STAT, V33, P1497, DOI 10.1214/009053605000000282; Bunea F, 2007, ANN STAT, V35, P1674, DOI 10.1214/009053606000001587; Bunea F, 2007, ELECTRON J STAT, V1, P169, DOI 10.1214/07-EJS008; CANDES E, 2005, P 46 ANN IEEE S FDN, P295; Catoni O., 2004, STAT LEARNING THEORY; Donoho D. L., 2004, MOST LARGE UNDERDETE; GEER V, 2008, ANN STAT, V36, P614; Koltchinskii V, 2006, ANN STAT, V34, P2593, DOI 10.1214/009053606000001019; KOLTCHINSKII V, 2005, OB REP M STAT PROB M; LEDOUX M., 1991, PROBABILITY BANACH S; Massart P, 2007, LECT NOTES MATH, V1896, P1, DOI 10.1007/978-3-540-48503-2; Massart P., 2000, ANN FAC SCI TOULOUSE, V9, P245; Mendelson S, 2007, GEOM FUNCT ANAL, V17, P1248, DOI 10.1007/s00039-007-0618-7; Nemirovski A., 2001, LECT MODERN CONVEX O; NEMIROVSKI A, 2000, ECOLE PROBABILITES S, V28, P85; TSYBAKOV A, 2003, LECT NOTES ARTIFICIA, V2777; VAART V, 1996, WEAK CONVERGENCE EMP; Yang Y, 2000, ANN STAT, V28, P75, DOI 10.1214/aos/1016120365; Yang YH, 2004, BERNOULLI, V10, P25, DOI 10.3150/bj/1077544602	30	37	37	0	6	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0246-0203			ANN I H POINCARE-PR	Ann. Inst. Henri Poincare-Probab. Stat.	FEB	2009	45	1					7	57		10.1214/07-AIHP146		51	Statistics & Probability	Mathematics	421PE	WOS:000264370000002		
J	Boysen, L; Kempe, A; Liebscher, V; Munk, A; Wittich, O				Boysen, Leif; Kempe, Angela; Liebscher, Volkmar; Munk, Axel; Wittich, Olaf			CONSISTENCIES AND RATES OF CONVERGENCE OF JUMP-PENALIZED LEAST SQUARES ESTIMATORS	ANNALS OF STATISTICS			English	Article						Jump detection; adaptive estimation; penalized maximum likelihood; approximation spaces; change-point analysis; multiscale resolution analysis; Potts functional; nonparametric regression; regressogram; Skorokhod topology; variable selection	LARGE UNDERDETERMINED SYSTEMS; NONPARAMETRIC REGRESSION; BAYESIAN RESTORATION; SMOOTH REGRESSION; WAVELET SHRINKAGE; CHANGE-POINTS; SELECTION; EQUATIONS; SEQUENCE	We study the asymptotics for jump-penalized least squares regression aiming at approximating a regression function by piecewise constant functions. Besides conventional consistency and convergence rates of the estimates in L(2)([0, 1)) our results cover other metrics like Skorokhod metric on the space of cadlag functions and uniform metrics on C([0, 1]). We will show that these estimators are in an adaptive sense rate optimal over certain classes of "approximation spaces." Special cases are the class of functions of bounded variation (piecewise) Holder continuous functions of order 0 < alpha <= 1 and the class of step functions with a finite but arbitrary number of jumps. In the latter setting, we will also deduce the rates known from change-point analysis for detecting the jumps. Finally, the issue of fully automatic selection of the smoothing parameter is addressed.	[Boysen, Leif; Munk, Axel] Univ Gottingen, Inst Stat Math, D-37073 Gottingen, Germany; [Kempe, Angela] GSF, Natl Res Ctr Environm, Inst Biomath & Biometry, D-85764 Neuherberg, Germany; [Liebscher, Volkmar] Ernst Moritz Arndt Univ Greifswald, Dept Math & Comp Sci, D-17487 Greifswald, Germany; [Wittich, Olaf] Tech Univ Eindhoven, Dept Math & Comp Sci, NL-5600 MB Eindhoven, Netherlands	Boysen, L (reprint author), Univ Gottingen, Inst Stat Math, Maschmuhlenweg 8-10, D-37073 Gottingen, Germany.	boysen@math.uni-goettingen.de; kempe@gsf.de; volkmar.liebscher@uni-greifswald.de; munk@math.uni-goettingen.de; O.Wittich@tue.nl			Georg Lichtenberg program; DFG	Supported by DFG Grant "Statistical Inverse Problems under Qualitative Shape Constraints." AMS 2000 subject classifications. Primary 62G05, 62G20; secondary 41A10, 41A25.	Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577; Davies PL, 2001, ANN STAT, V29, P1, DOI 10.1214/aos/996986501; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Aurich V., 1995, P 17 DAGM S, P538; Billingsley P, 1969, CONVERGENCE PROBABIL; Birge L, 2007, PROBAB THEORY REL, V138, P33, DOI 10.1007/s00440-006-0011-8; Blake A., 1987, VISUAL RECONSTRUCTIO; Boysen L., 2007, IMS LECT NOTES SERIE, V55, P65; Braun JV, 2000, BIOMETRIKA, V87, P301, DOI 10.1093/biomet/87.2.301; BURCHARD HG, 1975, J APPROX THEORY, V14, P128, DOI 10.1016/0021-9045(75)90084-2; Chaudhuri P, 2000, ANN STAT, V28, P408; CHRISTENSEN J, 1996, PREV VET MED, P54; Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100; Dal Maso G., 1993, INTRO GAMMA CONVERGE; DeVore R. A., 1998, Acta Numerica, V7, DOI 10.1017/S0962492900002816; DeVore R.A., 1993, CONSTRUCTIVE APPROXI; Donoho DL, 1997, ANN STAT, V25, P1870, DOI 10.1214/aos/1069362377; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Eubank RL, 1999, NONPARAMETRIC REGRES; Fithr H., 2006, DOCUMENT IMAGE COMPR, P179; FREDKIN DR, 1992, BIOMETRICS, V48, P427, DOI 10.2307/2532301; FRIEDRICH F, 2005, THESIS I BIOMATHEMAT; FRIEDRICH F, 2008, J COMPUT GRAPH STAT, V17, P1; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Godtliebsen F., 1997, J NONPARAMETR STAT, V8, P21, DOI 10.1080/10485259708832713; HALL P, 1992, TECHNOMETRICS, V34, P429, DOI 10.2307/1268942; Hampel F. R., 1986, ROBUST STAT; Hess C, 1996, ANN STAT, V24, P1298; HINKLEY DV, 1970, BIOMETRIKA, V57, P1; Kohler M, 1999, STAT PROBABIL LETT, V43, P49, DOI 10.1016/S0167-7152(98)00245-4; KUNSCH HR, 1994, ANN I STAT MATH, V46, P1, DOI 10.1007/BF00773588; Leeb H, 2008, J ECONOMETRICS, V142, P201, DOI 10.1016/j.jeconom.2007.05.017; Loader CR, 1996, ANN STAT, V24, P1667; Mammen E, 1997, ANN STAT, V25, P387; Muller HG, 1999, ANN STAT, V27, P299; MULLER HG, 1992, ANN STAT, V20, P737, DOI 10.1214/aos/1176348654; Petrov V. V., 1975, SUMS INDEPENDENT RAN; Polzehl J, 2003, ANN STAT, V31, P30; POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106; SHAO QM, 1995, P AM MATH SOC, V123, P575, DOI 10.2307/2160916; Spokoiny VG, 1998, ANN STAT, V26, P1356; TOMKINS JW, 1974, Z WAHRSCH VERW GEBIE, V30, P303; Tukey J., 1961, P 4 BERK S MATH STAT, V1, P681; van de Geer S., 2001, MATH METH STAT, V10, P355; Winkler G., 2005, JAHRESBER DTSCH MATH, V107, P57; Winkler G, 2002, J NONPARAMETR STAT, V14, P203, DOI 10.1080/10485250290003407; YAO YC, 1989, SANKHYA SER A, V51, P370; YAO YC, 1988, STAT PROBABIL LETT, V6, P181, DOI 10.1016/0167-7152(88)90118-6	52	21	21	1	4	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	FEB	2009	37	1					157	183		10.1214/07-AOS558		27	Statistics & Probability	Mathematics	404CT	WOS:000263129000006		
J	Meinshausen, N; Yu, B				Meinshausen, Nicolai; Yu, Bin			LASSO-TYPE RECOVERY OF SPARSE REPRESENTATIONS FOR HIGH-DIMENSIONAL DATA	ANNALS OF STATISTICS			English	Article						Shrinkage estimation; lasso; high-dimensional data; sparsity	MODEL SELECTION; ADAPTIVE LASSO; REGRESSION; NOISE; ASYMPTOTICS; DANTZIG	The Lasso is an attractive technique for regularization and variable selection for high-dimensional data, where the number of predictor variables p(n) is potentially much larger than the number of samples n. However, it was recently discovered that the sparsity pattern of the Lasso estimator can only be asymptotically identical to the true sparsity pattern if the design matrix satisfies the so-called irrepresentable condition. The latter condition can easily be violated in the presence of highly correlated variables. Here we examine the behavior of the Lasso estimators if the irrepresentable condition is relaxed. Even though the Lasso cannot recover the correct sparsity pattern, we show that the estimator is still consistent in the l(2)-norm sense for fixed designs under conditions on (a) the number s(n) Of nonzero components of the vector beta(n) and (b) the minimal singular values of design matrices that are induced by selecting small subsets of variables. Furthermore, a rate of convergence result is obtained on the l(2) error with an appropriate choice of the smoothing parameter. The rate is shown to be optimal under the condition of bounded maximal and minimal sparse eigenvalues. Our results imply that, with high probability, all important variables are selected. The set of selected variables is a meaningful reduction on the original set of variables. Finally, our results are illustrated with the detection of closely adjacent frequencies, a problem encountered in astrophysics.	[Meinshausen, Nicolai] Univ Oxford, Dept Stat, Oxford OX1 3TG, England; [Yu, Bin] Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Meinshausen, N (reprint author), Univ Oxford, Dept Stat, 1 S Parks Rd, Oxford OX1 3TG, England.	meinshausen@stats.ox.ac.uk; yu@stat.berkeley.edu			DFG (Deutsche Forschungsgemeinschaft); Guggenheim fellowship;  [NSF DMS-06-05165 (06-08)];  [NSF DMS-03-036508 (03-05)];  [ARO W911NF-05-1-0104 (05-07)]	Supported by DFG (Deutsche Forschungsgemeinschaft).Supported in part by a Guggenheim fellowship and Grants NSF DMS-06-05165 (06-08), NSF DMS-03-036508 (03-05) and ARO W911NF-05-1-0104 (05-07).	Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Paul D, 2007, STAT SINICA, V17, P1617; Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Meinshausen N, 2007, COMPUT STAT DATA AN, V52, P374, DOI 10.1016/j.csda.2006.12.019; Meier L, 2008, J R STAT SOC B, V70, P53; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Band Johnson W, 2001, HDB GEOMETRY BANACH, V1, P317, DOI 10.1016/S1874-5849(01)80010-3; BICKEL P, 2008, ANN STAT IN PRESS; Bunea F, 2007, ANN STAT, V35, P1674, DOI 10.1214/009053606000001587; BUNEA F, 2006, ELECT J STAT, P169; Cornish NJ, 2005, PHYS REV D, V72, DOI 10.1103/PhysRevD.72.043005; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Fuchs JJ, 2005, IEEE T INFORM THEORY, V51, P3601, DOI 10.1109/TIT.2005.855614; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; Hall P, 2000, BIOMETRIKA, V87, P545, DOI 10.1093/biomet/87.3.545; Hannan EJ, 1989, J TIME SER ANAL, V10, P13, DOI 10.1111/j.1467-9892.1989.tb00012.x; Joshi RL, 1995, IEEE T CIRC SYST VID, V5, P515, DOI 10.1109/76.475894; LoPresto S. M., 1997, Proceedings DCC '97. Data Compression Conference (Cat. No.97TB100108), DOI 10.1109/DCC.1997.582045; Meinshausen N, 2007, ANN STAT, V35, P2373, DOI 10.1214/009053607000000460; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Pojmanski G, 2002, ACTA ASTRONOM, V52, P397; SCARGLE JD, 1982, ASTROPHYS J, V263, P835, DOI 10.1086/160554; UMSTATTER R, 2005, CLASSICAL QUANTUM GR, V22, P901; Valdes-Sosa PA, 2005, PHILOS T ROY SOC B, V360, P969, DOI 10.1098/rstb.2005.1654; VANDEGEER S, 2006, ANN STAT, V36, P614; WAINWRIGHT M, 2006, ARXIVMATHST0605740; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037; Zhao P, 2007, J MACH LEARN RES, V8, P2701	41	123	126	3	14	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	FEB	2009	37	1					246	270		10.1214/07-AOS582		25	Statistics & Probability	Mathematics	404CT	WOS:000263129000009		
J	Caner, M				Caner, Mehmet			LASSO-TYPE GMM ESTIMATOR	ECONOMETRIC THEORY			English	Article							MODEL SELECTION; VARIABLE SELECTION; SHRINKAGE	This paper proposes the least absolute shrinkage and selection operator-type (Lasso-type) generalized method of moments (GMM) estimator. This Lasso-type estimator is formed by the GMM objective function with the addition of a penalty term. The exponent of the penalty term in the regular Lasso estimator is equal to one. However, the exponent of the penalty term in the Lasso-type estimator is less than one in the analysis here. The magnitude of the exponent is reduced to avoid the asymptotic bias. This estimator selects the correct model and estimates it simultaneously. In other words, this method estimates the redundant parameters as zero in the large samples and provides the standard GMM limit distribution for the estimates of the nonzero parameters in the model. The asymptotic theory for our estimator is nonstandard. We conduct a simulation study that shows that the Lasso-type GMM correctly selects the true model much more often than the Bayesian information Criterion (BIC) and another model selection procedure based on the GMM objective function.	N Carolina State Univ, Dept Econ, Raleigh, NC 27695 USA	Caner, M (reprint author), N Carolina State Univ, Dept Econ, 4168 Nelson Hall, Raleigh, NC 27695 USA.	mcaner@ncsu.edu					Andrews Donald W. K., 1994, HDB ECONOMETRICS, V4, P2247, DOI 10.1016/S1573-4412(05)80006-6; Andrews DWK, 2001, J ECONOMETRICS, V101, P123, DOI 10.1016/S0304-4076(00)00077-4; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Breiman L, 1996, ANN STAT, V24, P2350; CANER M, 2006, PRETEST HIGHER ORDER; Chao JC, 1999, J ECONOMETRICS, V91, P227, DOI 10.1016/S0304-4076(98)00077-3; Fan JQ, 2002, ANN STAT, V30, P74; Hahn J, 2002, ECON LETT, V75, P325, DOI 10.1016/S0165-1765(01)00622-X; KABAILA P, 1995, ECONOMET THEOR, V11, P537; Kleibergen F, 2005, ECONOMETRICA, V73, P1103, DOI 10.1111/j.1468-0262.2005.00610.x; KNIGHT K, 2007, SHRINKAGE ESTIMATION; Leeb H, 2006, ECONOMET THEOR, V22, P69, DOI 10.1017/S0266466606060038; Newey W. K., 1994, HDB ECONOMETRICS, V4, P2111, DOI DOI 10.1016/S1573-4412(05)80005-4; Newey WK, 2003, ECONOMETRICA, V71, P1565, DOI 10.1111/1468-0262.00459; POTSCHER BM, 1994, DISTRIBUTION E UNPUB; POTSCHER BM, 1991, ECONOMET THEOR, V7, P163; SMITH RJ, 1992, ECONOMETRICA, V60, P973, DOI 10.2307/2951576; Stock JH, 2000, ECONOMETRICA, V68, P1055, DOI 10.1111/1468-0262.00151; Van der Vaart A., 1996, WEAK CONVERGENCE EMP	23	16	17	0	6	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0266-4666			ECONOMET THEOR	Economet. Theory	FEB	2009	25	1					270	290		10.1017/S0266466608090099		21	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Statistics & Probability	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	399MQ	WOS:000262804400009		
J	Cedersund, G; Roll, J				Cedersund, Gunnar; Roll, Jacob			Systems biology: model based evaluation and comparison of potential explanations for given biological data	FEBS JOURNAL			English	Review						data analysis; explanations; hypothesis testing; mathematical modeling; statistical testing; systems biology	LIKELIHOOD RATIO TESTS; NONSTANDARD CONDITIONS; ASYMPTOTIC PROPERTIES; BIOCHEMICAL-MODELS; HYPOTHESES; IDENTIFICATION; SELECTION	Systems biology and its usage of mathematical modeling to analyse biological data is rapidly becoming an established approach to biology. A crucial advantage of this approach is that more information can be extracted from observations of intricate dynamics, which allows nontrivial complex explanations to be evaluated and compared. In this minireview we explain this process, and review some of the most central available analysis tools. The focus is on the evaluation and comparison of given explanations for a given set of experimental data and prior knowledge. Three types of methods are discussed: (a) for evaluation of whether a given model is sufficiently able to describe the given data to be nonrejectable; (b) for evaluation of whether a slightly superior model is significantly better; and (c) for a general evaluation and comparison of the biologically interesting features in a model. The most central methods are reviewed, both in terms of underlying assumptions, including references to more advanced literature for the theoretically oriented reader, and in terms of practical guidelines and examples, for the practically oriented reader. Many of the methods are based upon analysis tools from statistics and engineering, and we emphasize that the systems biology focus on acceptable explanations puts these methods in a nonstandard setting. We highlight some associated future improvements that will be essential for future developments of model based data analysis in biology.	[Cedersund, Gunnar] Linkoping Univ, Dept Cell Biol, SE-58185 Linkoping, Sweden; [Roll, Jacob] Linkoping Univ, Dept Elect Engn, SE-58185 Linkoping, Sweden	Cedersund, G (reprint author), Linkoping Univ, Dept Cell Biol, SE-58185 Linkoping, Sweden.	gunnar@ibk.liu.se			BioSim Network of Excellence	GC was supported by the BioSim Network of Excellence, and wishes to thank Jens Timmer (University of Freiburg, Germany) for helpful discussions and references.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Akaike H, 1981, TRENDS PROGR SYSTEM; Anguelova M, 2007, IET SYST BIOL, V1, P230, DOI 10.1049/iet-syb:20060081; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; SHAPIRO A, 1985, BIOMETRIKA, V72, P133, DOI 10.1093/biomet/72.1.133; Kreutz C, 2007, BIOINFORMATICS, V23, P2747, DOI 10.1093/bioinformatics/btm397; SELF SG, 1987, J AM STAT ASSOC, V82, P605, DOI 10.2307/2289471; CHANT D, 1974, BIOMETRIKA, V61, P291, DOI 10.1093/biomet/61.2.291; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Muller TG, 2004, J ROY STAT SOC C-APP, V53, P557, DOI 10.1111/j.1467-9876.2004.05148.x; Timmer J, 2004, INT J BIFURCAT CHAOS, V14, P2069, DOI 10.1142/S0218127404010461; Ashyraliyev M, 2009, FEBS J, V276, P886, DOI 10.1111/j.1742-4658.2008.06844.x; Kreutz C, 2009, FEBS J, V276, P923, DOI 10.1111/j.1742-4658.2008.06843.x; Swameye I, 2003, P NATL ACAD SCI USA, V100, P1028, DOI 10.1073/pnas.0237333100; Kitano H, 2002, NATURE, V420, P206, DOI 10.1038/nature01254; Teusink B, 2000, EUR J BIOCHEM, V267, P5313, DOI 10.1046/j.1432-1327.2000.01527.x; Di Ventura B, 2006, NATURE, V443, P527, DOI 10.1038/nature05127; Baltagi BH, 2001, COMPANION THEORETICA, P279; BARBOUR IG, 2002, RELIG SCI HIST CONT; CEDERSUND G, 2006, THESIS DEPT ELECT EN; Cedersund G, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000096; CHERNOFF H, 1954, ANN MATH STAT, V25, P573, DOI 10.1214/aoms/1177728725; COX DR, 1962, J ROY STAT SOC B, V24, P406; Cox DR, 1961, P 4 BERK S MATH STAT, V1, P105; DEUTSCH D, 1998, FABRIC REALITY SCI P, pCH9; Dochain D, 2001, DYNAMIC MODELING EST; Efron B., 1993, MONOGRAPHS STAT APPL; Efron B., 1987, JACKKNIFE BOOTSTRAP; Godfrey LG, 2007, ECON LETT, V94, P408, DOI 10.1016/j.econlet.2006.08.031; Goldman N, 2000, SYST BIOL, V49, P652; GUT A, 1991, INTERMEDIATE COURSE; Hall Peter, 1992, BOOTSTRAP EDGEWORTH; Hastie T., 2001, ELEMENTS STAT LEARNI; Hawking S W., 1988, BRIEF HIST TIME; HINDE J, 1992, ADV GLIM STAT MODELL; Hinkley D. V., 1997, BOOTSTRAP METHODS TH; Hynne F., 2001, Biophysical Chemistry, V94, P121, DOI 10.1016/S0301-4622(01)00229-0; Kanji G. K., 1994, 100 STAT TESTS; Kim S, 1998, REV ECON STUD, V65, P361, DOI 10.1111/1467-937X.00050; Klipp E, 2005, SYSTEMS BIOLOGY IN PRACTICE: CONCEPTS, IMPLEMENTATION AND APPLICATION, P1, DOI 10.1002/3527603603; Kuhn T, 1962, STRUCTURE SCI REVOLU; Ljung L, 1999, SYSTEM IDENTIFICATIO; MILLER JJ, 1977, ANN STAT, V5, P746, DOI 10.1214/aos/1176343897; MULLER TG, 2002, THESIS FREIBURG U GE; NOCEDAL J., 1999, NUMERICAL OPTIMIZATI; PETTERSSON T, 2008, THESIS LINKOPING U S; Popper K., 1963, CONJECTURES REFUTATI; Schmidt H, 2006, BIOINFORMATICS, V22, P514, DOI 10.1093/bioinformatics/bti799; SCHORK N, 1992, EXPLORING LIMITS BOO; Sedoglavic A, 2002, J SYMB COMPUT, V33, P735, DOI 10.1006/jsco.2002.0532; Segel I. H., 1975, ENZYME KINETICS; Sheskin D. J., 1997, HDB PARAMETRIC NONPA; VUONG QH, 1989, ECONOMETRICA, V57, P307, DOI 10.2307/1912557; Wah B. W., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, DOI 10.1142/S0218213000000033; WILLIAMS DA, 1970, BIOMETRICS, V28, P23; HALL P, 1991, BIOMETRICS, V47, P757, DOI 10.2307/2532163; Winkelmann R., 2003, ECONOMETRIC ANAL COU, V4th	57	45	46	2	7	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1742-464X	1742-4658		FEBS J	FEBS J.	FEB	2009	276	4					903	922		10.1111/j.1742-4658.2008.06845.x		20	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	397MN	WOS:000262666900003	19215297	
J	Xu, CW; Wang, XF; Li, ZK; Xu, SZ				Xu, Chenwu; Wang, Xuefeng; Li, Zhikang; Xu, Shizhong			Mapping QTL for multiple traits using Bayesian statistics	GENETICS RESEARCH			English	Article							QUANTITATIVE TRAITS; BINARY TRAITS; ENTIRE GENOME; LOCI; SHRINKAGE; MARKERS; REGRESSION; CROSSES; MODEL	The value of a new crop species is usually judged by the overall performance of multiple traits. Therefore, in most quantitative trait locus (QTL) mapping experiments, researchers tend to collect phenotypic records for multiple traits. Some traits may vary continuously and others may vary in a discrete fashion. Although mapping QTLs jointly for multiple traits is more efficient than mapping QTLs separately for individual traits, the latter is still commonly practised in QTL mapping. This is primarily due to the lack of efficient statistical methods and computer software packages to implement the methods. Mapping multiple QTLs simultaneously in a single multivariate model has not been available, especially when categorical traits are involved. In the present study, we developed a Bayesian method to map QTLs of the entire genome for multiple traits with continuous, discrete or both types of phenotypic distribution. Instead of using the reversible jump Markov chain Monte Carlo (MCMC) for model selection, we adopt a parameter shrinkage approach to estimate the genetic effects of all marker intervals. We demonstrate the method by analysing a set of Simulated data with both continuous and discrete traits. We also apply the method to mapping QTLs responsible for multiple disease resistances to the blast fungus of rice. A computer program written in SAS/IML that implements the method is freely available, on request, to academic researchers.	[Xu, Shizhong] Univ Calif Riverside, Dept Bot & Plant Sci, Riverside, CA 92521 USA; [Xu, Chenwu; Wang, Xuefeng] Yangzhou Univ, Minist Educ, Key Lab Plant Funct Genom, Jiangsu Prov Key Lab Crop Genet & Physiol, Yangzhou 225009, Peoples R China; [Li, Zhikang] Int Rice Res Inst, Manila, Philippines; [Li, Zhikang] Chinese Acad Agr Sci, Beijing 100081, Peoples R China	Xu, SZ (reprint author), Univ Calif Riverside, Dept Bot & Plant Sci, Riverside, CA 92521 USA.	xu@genetics.ucr.edu			National Basic Research Program of China [2006CB101700]; National Science Foundation [DBI-0345205]; USDA National Research Initiative Competitive Grants Program [2007-35300-18285]	This research wits supported by the National Basic Research Program of China (grant number 2006CB101700) to C.X. and by the National Science Foundation (grant number DBI-0345205) and the USDA National Research Initiative Competitive Grants Program (USDA CSREES 2007-35300-18285) to S.X.	LINDLEY DV, 1972, J ROY STAT SOC B, V34, P1; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Kao CH, 1999, GENETICS, V152, P1203; Meuwissen THE, 2001, GENETICS, V157, P1819; Banerjee S, 2008, GENETICS, V179, P2275, DOI 10.1534/genetics.108.088427; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Huang H, 2007, GENETICS, V176, P2529, DOI 10.1534/genetics.106.064980; HUANG J, 2003, AM J HUM GENET, V72, P946; JIANG CJ, 1995, GENETICS, V140, P1111; Jiang CJ, 1997, GENETICA, V101, P47, DOI 10.1023/A:1018394410659; Knott SA, 2000, GENETICS, V156, P899; Kopp A, 2003, GENETICS, V163, P771; Korol AB, 2001, GENETICS, V157, P1789; Korsgaard IR, 2003, GENET SEL EVOL, V35, P159, DOI 10.1051/gse:2003002; Lynch M, 1998, GENETICS DATA ANAL Q; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Park T., 2005, BAYESIAN LASSO; Ronin YI, 1999, GENETICS, V151, P387; Wang H, 2005, GENETICS, V170, P465, DOI 10.1534/genetics.104.039354; Williams JT, 1999, AM J HUM GENET, V65, P1134, DOI 10.1086/302570; Xu CW, 2005, GENETICS, V169, P1045, DOI 10.1534/genetics.103.019406; XU S, 2002, QUANTITATIVE TRAIT L; Xu SH, 2007, GENETICS, V177, P1255, DOI 10.1534/genetics.107.077487; Xu SZ, 2007, GENETICS, V175, P1955, DOI 10.1534/genetics.106.066571; Xu SZ, 2007, BIOMETRICS, V63, P513, DOI 10.1111/j.1541-0420.2006.00711.x; Xu SZ, 2003, GENETICS, V163, P789; Xu SZ, 2000, P NATL ACAD SCI USA, V97, P14542, DOI 10.1073/pnas.250235197; Yang RQ, 2007, GENETICS, V176, P1169, DOI 10.1534/genetics.106.064279; Yang RQ, 2006, GENETICS, V173, P2339, DOI 10.1534/genetics.105.054775; Yi NJ, 2004, GENETICS, V167, P967, DOI 10.1534/genetics.104.026286; Yi NJ, 2000, GENETICS, V155, P1391; Zeng ZB, 2005, GENETICA, V123, P25, DOI 10.1007/s10709-004-2705-0	33	9	9	2	3	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0016-6723	1469-5073		GENET RES	Genet. Res.	FEB	2009	91	1					23	37		10.1017/S0016672308009956		15	Genetics & Heredity	Genetics & Heredity	419NM	WOS:000264226300004	19220929	
J	Zhou, SH; Lafferty, J; Wasserman, L				Zhou, Shuheng; Lafferty, John; Wasserman, Larry			Compressed and Privacy-Sensitive Sparse Regression	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						Capacity of multiple-antenna channels; compressed sensing; high-dimensional regression; lasso; l(1) regularization; privacy; sparsity	SIGNAL RECOVERY; SELECTION; LASSO; SYSTEMS	Recent research has studied the role of sparsity in high-dimensional regression and signal reconstruction, establishing theoretical limits for recovering sparse models. This line of work shows that l(1)-regularized least squares regression can accurately estimate a sparse linear model from noisy examples in high dimensions. We study a variant of this problem where the original n input variables are compressed by a random linear transformation to m << n examples in p dimensions, and establish conditions under which a sparse linear model can be successfully recovered from the compressed data. A primary motivation for this compression procedure is to anonymize the data and preserve privacy by revealing little information about the original data. We characterize the number of projections that are required for l(1)-regularized compressed regression to identify the nonzero coefficients in the true model with probability approaching one, a property called "sparsistence." We also show that l(1)-regularized compressed regression asymptotically predicts as well as an oracle linear model, a property called "persistence." Finally, we characterize the privacy properties of the compression procedure, establishing upper bounds on the mutual information between the compressed and uncompressed data that decay to zero.	[Zhou, Shuheng] ETH, CH-8092 Zurich, Switzerland; [Lafferty, John] Carnegie Mellon Univ, Dept Comp Sci, Machine Learning Dept, Pittsburgh, PA 15213 USA; [Lafferty, John; Wasserman, Larry] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15213 USA	Zhou, SH (reprint author), ETH, CH-8092 Zurich, Switzerland.	zhou@stat.math.ethz.ch; lafferty@cs.cmu.edu; larry@stat.cmu.edu			National Science Foundation [CCF-0625879]	This work was supported in part by the National Science Foundation under Grant CCF-0625879. The material in this paper was presented in part at The 21st Annual Conference on Neural Information Processing Systems, Vancouver, BC, Canada, December 2007.	Agrawal D., 2001, P 20 ACM SIGMOD SIGA, P247, DOI DOI 10.1145/375551.375602; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Efron B, 2004, ANN STAT, V32, P407; SHANNON CE, 1949, AT&T TECH J, V28, P656; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Marzetta TL, 1999, IEEE T INFORM THEORY, V45, P139, DOI 10.1109/18.746779; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; WYNER AD, 1975, AT&T TECH J, V54, P1355; DALENIUS T, 1977, J STAT PLAN INFER, V1, P73, DOI 10.1016/0378-3758(77)90007-6; Dalenius T, 1977, STATISTISKTIDSKRIFT, V5, P429; DAVENPORT M, 2006, 0610 TREE RIFC U EL; DAVENPORT M, 2007, P COMPUTATIONAL IMAG, V6498, P153; DUARTE M, 2006, P IEEE INT C AC SPEE, P305; Duncan G., 1991, STAT SCI, V6, P219, DOI 10.1214/ss/1177011681; Dwork Cynthia, 2007, Proceedings of the 39th Annual ACM Symposium on Theory of Computing. STOC'07, DOI 10.1145/1250790.1250804; Dworsky A, 2006, J SOC SERV RES, V33, P1, DOI 10.1300/J079v33n02_01; Greenshtein E, 2004, BERNOULLI, V10, P971, DOI 10.3150/bj/1106314846; HAUPT J, 2006, P AS C SIGN SYST COM, P1430; Horn R. A., 1990, MATRIX ANAL; Johnson W, 1984, P C MOD AN PROB, P189; Johnstone I. M., 2004, SPARSE PRINCIPAL COM; Johnstone IM, 2001, INST MATH S, V36, P399, DOI 10.1214/lnms/1215090080; Lafferty J, 2008, ANN STAT, V36, P28, DOI 10.1214/009053607000000811; Liu K, 2006, IEEE T KNOWL DATA EN, V18, P92; MEINHAUSEN N, 2006, 720 U CAL BERK DEP S; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190; Sanil A., 2004, P 10 ACM SIGKDD INT, P677, DOI 10.1145/1014052.1014139; Telatar I. E., 1999, EUROPEAN T TELECOMMU, V10, P585, DOI DOI 10.1002/ETT.4460100604; Ting Daniel, 2008, International Journal of Information and Computer Security, V2, DOI 10.1504/IJICS.2008.016823; WAINWRIGHT M, 2007, ADV NEURAL INFORM PR, V19; WAINWRIGHT MJ, 2006, 709 U CAL BERK DEP S; ZHAO P, 2007, J MACH LEARN RES, V7, P2541	37	12	13	1	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	FEB	2009	55	2					846	866		10.1109/TIT.2008.2009605		21	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	407OZ	WOS:000263375500028		
J	Tseng, P				Tseng, Paul			Further Results on Stable Recovery of Sparse Overcomplete Representations in the Presence of Noise	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						Basis pursuit; l(1)-norm minimization; greedy algorithm; matching pursuit; mutual coherence; overcomplete representation; sparse representation	GREEDY ALGORITHMS; UNCERTAINTY PRINCIPLES; SIGNAL RECONSTRUCTION; BASES; REGULARIZATION; APPROXIMATION; DICTIONARIES	Sparse overcomplete representations have attracted much interest recently for their applications to signal processing. In a recent work, Donoho, Elad, and Temlyakov (2006) showed that, assuming sufficient sparsity of the ideal underlying signal and approximate orthogonality of the overcomplete dictionary, the sparsest representation can be found, at least approximately if not exactly, by either an orthogonal greedy algorithm or by l(1)-norrn minimization subject to a noise tolerance constraint. In this paper, we sharpen the approximation bounds under more relaxed conditions. We also derive analogous results for a stepwise projection algorithm.	Univ Washington, Dept Math, Seattle, WA 98195 USA	Tseng, P (reprint author), Univ Washington, Dept Math, Seattle, WA 98195 USA.	tseng@math.washington.edu			National Science Foundation [DMS-0511283]	This work was supported by the National Science Foundation under Grant DMS-0511283.	Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475; Gilbert AC, 2003, SIAM PROC S, P243; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Barron AR, 2008, ANN STAT, V36, P64, DOI 10.1214/009053607000000631; Chen Y, 1998, NONCON OPTIM ITS APP, V20, P1; DAVIS RH, 1994, J RELIG HEALTH, V33, P7, DOI 10.1007/BF02354494; DeVore RA, 1996, ADV COMPUT MATH, V5, P173, DOI 10.1007/BF02124742; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Donoho D. L., 2006, SPARSE SOLUTION UNDE; DONOHO DL, 2006, MOST LARGE UNDERDETE; Friedlander MP, 2008, SIAM J OPTIMIZ, V18, P1326, DOI 10.1137/060675320; Fuchs JJ, 2005, IEEE T INFORM THEORY, V51, P3601, DOI 10.1109/TIT.2005.855614; Fuchs JJ, 2004, IEEE T INFORM THEORY, V50, P1341, DOI 10.1109/TIT.2004.828141; Golub G. H., 1985, MATRIX COMPUTATIONS; Pati Y. C., 1993, P 27 AS C SIGN SYST, V1, P40, DOI DOI 10.1109/ACSSC.1993.342465; Rockafellar R.T., 1970, CONVEX ANAL; Sardy S, 2000, J COMPUT GRAPH STAT, V9, P361, DOI 10.2307/1390659; STROMTEJSEN P, 2003, P HLTH BUILD 2003 SI, V3, P257; Temlyakov VN, 2000, ADV COMPUT MATH, V12, P213, DOI 10.1023/A:1018917218956; TSENG P, 1992, MATH PROGRAM, V56, P301, DOI 10.1007/BF01580904	33	10	10	3	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	FEB	2009	55	2					888	899		10.1109/TIT.2008.2009812		12	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	407OZ	WOS:000263375500031		
J	Su, CT; Hsiao, YH				Su, Chao-Ton; Hsiao, Yu-Hsiang			Multiclass MTS for Simultaneous Feature Selection and Classification	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Classification; feature selection; multiclass problem; Mahalanobis-Taguchi system (MTS); weighted Mahalanobis distance; Gram-Schmidt orthogonalization process; gestational diabetes mellitus	SUPPORT VECTOR MACHINES; MAHALANOBIS-TAGUCHI SYSTEM; NEURAL-NETWORKS; ROBUSTNESS; REGRESSION; DISTANCE; WOMEN; RISK; SETS	Multiclass Mahalanobis-Taguchi system (MMTS), the extension of MTS, is developed for simultaneous multiclass classification and feature selection. In MMTS, the multiclass measurement scale is constructed by establishing an individual Mahalanobis space for each class. To increase the validity of the measurement scale, the Gram-Schmidt process is performed to mutually orthogonalize the features and eliminate the multicollinearity. The important features are identified using the orthogonal arrays and the signal-to-noise ratio, and are then used to construct a reduced model measurement scale. The contribution of each important feature to classification is also derived according to the effect gain to develop a weighted Mahalanobis distance which is finally used as the distance metric for the classification of MMTS. Using the reduced model measurement scale, an unknown example will be classified into the class with minimum weighted Mahalanobis distance considering only the important features. For evaluating the effectiveness of MMTS, a numerical experiment is implemented, and the results show that MMTS outperforms other well-known algorithms not only on classification accuracy but also on feature selection efficiency. Finally, a real case about gestational diabetes mellitus is studied, and the results indicate the practicality of MMTS in real-world applications.	[Su, Chao-Ton; Hsiao, Yu-Hsiang] Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, Hsinchu 30013, Taiwan	Su, CT (reprint author), Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, Engn Bldg 1,101,Sec 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.	ctsu@mx.nthu.edu.tw; Adrian.iem88@nctu.edu.tw			National Science Council of Taiwan [NSC-972221-E-007-089-MY3]	This work was supported in part by the National Science Council of Taiwan, under Contract NSC-972221-E-007-089-MY3.	ANAND R, 1995, IEEE T NEURAL NETWOR, V6, P117, DOI 10.1109/72.363444; Ou GB, 2007, PATTERN RECOGN, V40, P4, DOI 10.1016/j.patcog.2006.04.041; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Walczak B, 1999, CHEMOMETR INTELL LAB, V47, P1, DOI 10.1016/S0169-7439(98)00200-7; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Efron B, 2004, ANN STAT, V32, P407; Asharaf S., 2007, P 24 INT C MACH LEAR; Barger MK, 2006, J MIDWIFERY WOM HEAL, V51, P222, DOI 10.1016/j.jmwh.2006.02.001; Chang C., 2001, LIBSVM LIB SUPPORT V; Cho NH, 2006, DIABETES RES CLIN PR, V71, P177, DOI 10.1016/j.diabres.2005.06.003; Cun Y. L., 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Das P, 2007, COMP MATER SCI, V38, P671, DOI 10.1016/j.commatsci.2006.05.022; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Duda R. O., 2001, PATTERN CLASSIFICATI; Jugulum Rajesh, 2002, MAHALANOBIS TAGUCHI; Justin C. W. D., 1997, J INTELL INF SYST, V9, P57; KALOUSIS A, 2005, P 5 IEEE INT C DAT M; Kim H, 1995, OMEGA-INT J MANAGE S, V23, P637, DOI 10.1016/0305-0483(95)00036-4; KJOS SL, 1995, DIABETES, V44, P586, DOI 10.2337/diabetes.44.5.586; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Lam W, 1999, IEEE T KNOWL DATA EN, V11, P865; Li XB, 2002, COMMUNICATIONS INFOR, V2, P53; Liu H., 2001, INSTANCE SELECTION C; Masulli F, 2000, LECT NOTES COMPUT SC, V1857, P107; METZGER BE, 1993, DIABETES CARE, V16, P1598, DOI 10.2337/diacare.16.12.1598; Patterson D., 1996, ARTIFICIAL NEURAL NE; Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753706; Riho T, 2005, IEEE T SEMICONDUCT M, V18, P561, DOI 10.1109/TSM.2005.858499; Scholkopf B., 2002, LEARNING KERNELS; Selvi ST, 2000, PATTERN RECOGN LETT, V21, P721, DOI 10.1016/S0167-8655(00)00027-1; Shami M, 2007, SPEECH COMMUN, V49, P201, DOI 10.1016/j.specom.2007.01.006; SHIH I, 2003, P 20 INT C MACH LEAR; Srinivasaraghavan J, 2006, INT J ADV MANUF TECH, V29, P1159, DOI 10.1007/s00170-005-0004-2; Su CT, 2007, IEEE T KNOWL DATA EN, V19, P1321, DOI 10.1109/TKDE.2007.190623; Taguchi G., 2005, TAGUCHIS QUALITY ENG; Taguchi G, 2001, MAHALANOBIS TAGUCHI; TIAN Y, 2005, P 5 INT C COMP INF T, P18; Vapnik V., 1998, STAT LEARNING THEORY; Weston J, 1998, CSDTR9804; Wichern D. W., 1998, APPL MULTIVARIATE ST; Woodall WH, 2003, TECHNOMETRICS, V45, P1, DOI 10.1198/004017002188618626; WU J, 2004, P 3 INT C MACH LEARN, V5, P3201; ZHANG H, 2005, UCBEECS20056 U CAL D	48	16	16	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2009	21	2					192	205		10.1109/TKDE.2008.128		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	385KT	WOS:000261813800003		
J	Wright, J; Yang, AY; Ganesh, A; Sastry, SS; Ma, Y				Wright, John; Yang, Allen Y.; Ganesh, Arvind; Sastry, S. Shankar; Ma, Yi			Robust Face Recognition via Sparse Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; feature extraction; occlusion and corruption; sparse representation; compressed sensing; l(1)-minimization; validation and outlier rejection	LARGE UNDERDETERMINED SYSTEMS; LINEAR-SUBSPACES; SIGNAL RECOVERY; MODEL SELECTION; DISTORTION; EQUATIONS; LASSO	We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by l(1)-minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly computed. Unconventional features such as downsampled images and random projections perform just as well as conventional features such as Eigenfaces and Laplacianfaces, as long as the dimension of the feature space surpasses certain threshold, predicted by the theory of sparse representation. This framework can handle errors due to occlusion and corruption uniformly by exploiting the fact that these errors are often sparse with respect to the standard (pixel) basis. The theory of sparse representation helps predict how much occlusion the recognition algorithm can handle and how to choose the training images to maximize robustness to occlusion. We conduct extensive experiments on publicly available databases to verify the efficacy of the proposed algorithm and corroborate the above claims.	[Wright, John; Ganesh, Arvind; Ma, Yi] Univ Illinois, Coordinated Sci Lab, Urbana, IL 61801 USA; [Yang, Allen Y.; Sastry, S. Shankar] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Wright, J (reprint author), Univ Illinois, Coordinated Sci Lab, 1308 W Main St, Urbana, IL 61801 USA.	jnwright@uiuc.edu; yang@eecs.berkeley.edu; abalasu2@uiuc.edu; sastry@eecs.berkeley.edu; yima@uiuc.edu			US National Science Foundation (NSF) [CAREER IIS-0347456, NSF CRS-EHS-0509151, NSF CCF-TF-0514955, ONR YIP N00014-05-1-0633, NSF ECCS07-01676, NSF IIS 07-03756];  [ARO MURI W911NF-06-1-0076]	The authors would like to thank Dr. Harry Shum, Dr. Xiaoou Tang and many others at the Microsoft Research, Asia, for helpful and informative discussions on face recognition, during their visit there in Fall 2006. They also thank Professor Harm Derksen and Prof. Michael Wakin of the University of Michigan, Professor Robert Fossum and Yoav Sharon of the University of Illinois for the advice and discussions on polytope geometry and sparse representation. This work was partially supported by the Grants ARO MURI W911NF-06-1-0076, US National Science Foundation (NSF) CAREER IIS-0347456, NSF CRS-EHS-0509151, NSF CCF-TF-0514955, ONR YIP N00014-05-1-0633, NSF ECCS07-01676, and NSF IIS 07-03756.	Achlioptas D, 2001, P ACM S PRINC DAT SY, P274, DOI DOI 10.1109/TIT.2006.885507; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Park BG, 2005, IEEE T PATTERN ANAL, V27, P1982; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Wang HT, 2004, PROC CVPR IEEE, P498; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Baraniuk R., 2007, FDN COMPUTATIONAL MA; Baraniuk R., 2007, CONSTRUCTIVE APPROXI; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI 10.1145/502512.502546; Candes E., 2005, L1 MAGIC RECOVERY SP; Candes E., 2006, P INT C MATH; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; Donoho D., 2005, 20054 STANF U DEP ST; DONOHO D, 2007, COUNTING FACES RANDO; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Donoho D., 2006, FAST SOLUTION L1 NOR; Donoho D. L., 2000, AMS MATH CHALLENGES; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Duda R. O., 2001, PATTERN CLASSIFICATI; Geiger D., 1999, INT J COMPUTER VISIO, V33; Ho J., 2003, P IEEE C COMP VIS PA, V1, DOI DOI 10.1109/CVPR.2003.1211332; Huang Ke, 2006, NEURAL INFORM PROCES; Kaski S., 1998, P IJCNN 98 INT JOINT, V1, P413; Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977; Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li S.Z., 2001, P IEEE C COMP VIS PA, P1; Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725; MacWilliams F. J., 1981, THEORY ERROR CORRECT; Martinez A., 1998, 24 CVC; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Pentland A., 1994, P IEEE C COMP VIS PA; PHILLIPS P, 2006, 7408 NISTIR NIST; RAUHUT H, 2007, IEEE T INFO IN PRESS; SANJA F, 2006, IEEE T PATTERN ANAL, V28; Savvides M, 2006, P C COMP VIS PATT RE; Serre T., 2006, THESIS MIT; SHARON Y, 2007, UILUENG072208; TURK M, 1991, P IEEE INT C COMP VI; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Vapnik V., 2000, NATURE STAT LEARNING; Zass R., 2006, P NEUR INF PROC SYST; ZHAO W, 2003, ACM COMPUT SURV, P458	59	1909	2229	73	300	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					210	227		10.1109/TPAMI.2008.79		18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	385XL	WOS:000261846800002	19110489	
J	Joshi, S; Boyd, S				Joshi, Siddharth; Boyd, Stephen			Sensor Selection via Convex Optimization	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						Convex optimization; experiment design; sensor selection	ORBIT MODAL IDENTIFICATION; D-OPTIMAL DESIGNS; PLACEMENT; ALGORITHM; SYSTEMS	We consider the problem of choosing a set of k sensor measurements, from a set or m possible or potential sensor measurements, that minimizes the error in estimating some parameters. Solving this problem by evaluating the performance for each of the ((m)(k)) possible choices or sensor measurements is not practical unless m and k are small. In this paper, we describe a heuristic, based on convex optimization, for approximately solving this problem. Our heuristic gives a subset selection as well as a bound on the best performance that can be achieved by any selection of k sensor measurements. There is no guarantee that the gal) between the performance of the chosen subset and the performance bound is always small, but numerical experiments suggest that the gap is small in many cases. Our heuristic method requires on the order of m(3) operations; for m = 1000 possible sensors, we can carry out sensor selection in a few seconds on a 2-GHz personal computer.	[Joshi, Siddharth; Boyd, Stephen] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Joshi, S (reprint author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.	sidj@stanford.edu; boyd@stanford.edu					Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; WYNN HP, 1972, J ROY STAT SOC B, V34, P133; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Sun P, 2004, OPER RES, V52, P690, DOI 10.1287/opre.1040.0115; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; Lobo MS, 2007, ANN OPER RES, V152, P341, DOI 10.1007/s10479-006-0145-1; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; YAO L, 1993, AIAA J, V31, P1922, DOI 10.2514/3.11868; Bian F., 2006, P 5 INT C INF PROC S, P11, DOI 10.1145/1127777.1127783; Chu M, 2002, INT J HIGH PERFORM C, V16, P293; CRARY S, 1995, P 8 INT C SOL STAT S, V2; Debouk R, 2002, DISCRETE EVENT DYN S, V12, P417, DOI 10.1023/A:1019770124060; Dolia A. N., 2004, P 7 INT C SIGN IM PR, P73; Durrant-Whyte H., 1995, DATA FUSION SENSOR M; ERTIN E, 2003, P IPSN, V3; Fedorov V. V., 1972, THEORY OPTIMAL EXPT; Feldman J., 2003, P 41 ALL C COMM CONT, P1; GIRAUD C, 1995, P IEEE RSJ INT C INT, V2; GRANT M, 2007, CVX VERSION 1 1 MATL; GUESTRIN C, 2005, NEAR OPTIMAL SENSOR; Gupta V, 2006, AUTOMATICA, V42, P251, DOI 10.1016/j.automatica.2005.09.016; HASSIBI A, 1998, P 37 IEEE C DEC CONT, V1; Hovland G., 1997, P IEEE INT C ROB AUT, V1, P272, DOI 10.1109/ROBOT.1997.620050; Isler Volkan, 2005, P 4 INT S INF PROC S; Jiang SB, 2003, IEEE T AUTOMAT CONTR, V48, P369, DOI 10.1109/TAC.2003.809144; John R., 1975, TECHNOMETRICS, V17, P15, DOI 10.2307/1267995; KALANDROS M, 1998, P AM CONTR C, V5; KAMMER DC, 1991, J GUID CONTROL DYNAM, V14, P251, DOI 10.2514/3.20635; Kincaid RK, 2002, COMPUT OPER RES, V29, P701, DOI 10.1016/S0305-0548(01)00048-X; Kookos IK, 1999, IND ENG CHEM RES, V38, P4299, DOI 10.1021/ie9902737; Luo ZQ, 2004, SIAM J OPTIMIZ, V14, P1140, DOI 10.1137/S1052623403421498; MILLER AJ, 1994, APPL STAT-J ROY ST C, V43, P669, DOI 10.2307/2986264; Motwani R., 1995, RANDOMIZED ALGORITHM; MUTAPCIC A, 2007, CUTTING SET METHODS; NGUYEN NK, 1992, COMPUT STAT DATA AN, V14, P489, DOI 10.1016/0167-9473(92)90064-M; OSHMAN Y, 1994, IEEE T AERO ELEC SYS, V30, P307, DOI 10.1109/7.272256; Pukelsheim F, 2006, CLASS APPL MATH, V50, P1, DOI 10.1137/1.9780898719109; Rowaihy H., 2007, P SPIE, V6562; VANDENBERGHE L., 1997, P 1997 IEEE ACM INT, P252; Vandenberghe L., 2004, CONVEX OPTIMIZATION; Wang H., 2004, P 3 INT S INF PROC S, P36, DOI 10.1145/984622.984628; WELCH WJ, 1982, TECHNOMETRICS, V24, P41, DOI 10.2307/1267576; Zhao F, 2002, IEEE SIGNAL PROC MAG, V19, P61; Zhao F., 2004, WIRELESS SENSOR NETW	45	160	164	5	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-587X	1941-0476		IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	FEB	2009	57	2					451	462		10.1109/TSP.2008.2007095		12	Engineering, Electrical & Electronic	Engineering	404OB	WOS:000263161500004		
J	Chen, X; Wang, LL				Chen, Xi; Wang, Lily			Integrating Biological Knowledge with Gene Expression Profiles for Survival Prediction of Cancer	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						gene expression; gene ontology; microarrays; pathway analysis; survival prediction	B-CELL LYMPHOMA; NEGATIVE BREAST-CANCER; REGRESSION-MODELS; PATIENT SURVIVAL; PATHWAY ANALYSIS; CLASSIFICATION; METASTASIS; LASSO; CLASSIFIERS; SIGNATURE	Due to the large variability in survival times between cancer patients and the plethora of genes on microarrays unrelated to outcome, building accurate prediction models that are easy to interpret remains a challenge. In this paper, we propose a general strategy for improving performance and interpretability of prediction models by integrating gene expression data with prior biological knowledge. First, we link gene identifiers in expression dataset with gene annotation databases such as Gene Ontology (GO). Then we construct "supergenes" for each gene category by summarizing information from genes related to outcome using a modified principal component analysis (PCA) method. Finally, instead of using genes as predictors, we use these supergenes representing information from each gene category as predictors to predict survival outcome. In addition to identifying gene categories associated with outcome, the proposed approach also carries out additional within-category selection to select important genes within each gene set. We show, using two real breast cancer microarray datasets, that the prediction models constructed based on gene sets (or pathway) information outperform the prediction models based on expression values of single genes, with improved prediction accuracy and interpretability.	[Chen, Xi] Cleveland Clin, Dept QHS, Cleveland, OH 44195 USA; [Wang, Lily] Vanderbilt Univ, Dept Biostat, Nashville, TN USA	Chen, X (reprint author), Cleveland Clin, Dept QHS, 9500 Euclid Ave, Cleveland, OH 44195 USA.	chenx3@ccf.org			NHLBI SCCOR [1-P50-HL-077107]; NICHD [5P30-HD015052-25]; NIH [1P50-MH078028-01A1]	X. C. was supported in part by NHLBI SCCOR grant 1-P50-HL-077107. L. W. was supported in part by NICHD grant 5P30-HD015052-25 and NIH grant 1P50-MH078028-01A1.	Amlal H, 2006, CANCER RES, V66, P3706, DOI 10.1158/00008-5472.CAN-05-2744; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Schmidt M, 2008, CANCER RES, V68, P5405, DOI 10.1158/0008-5472.CAN-07-5206; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Ashburner M, 2000, NAT GENET, V25, P25; Mootha VK, 2003, NAT GENET, V34, P267, DOI 10.1038/ng1180; Tan YX, 2005, NUCLEIC ACIDS RES, V33, P56, DOI 10.1093/nar/gki144; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Segal E, 2004, NAT GENET, V36, P1090, DOI 10.1038/ng1434; Miller LD, 2005, P NATL ACAD SCI USA, V102, P13550, DOI 10.1073/pnas.0506230102; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Heagerty PJ, 2000, BIOMETRICS, V56, P337, DOI 10.1111/j.0006-341X.2000.00337.x; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Arakawa H, 2005, CELL DEATH DIFFER, V12, P1057, DOI 10.1038/sj.cdd.4401601; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; CHEN X, 2008, BIOINFORMATICS, V24, P2479; Chuang HY, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100180; COX DR, 1972, J R STAT SOC B, V34, P187; Dumont N, 2000, BREAST CANCER RES, V2, P125, DOI 10.1186/bcr44; Ma SG, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-60; Manoli T, 2006, BIOINFORMATICS, V22, P2500, DOI 10.1093/bioinformatics/btl424; Muraoka-Cook RS, 2005, CLIN CANCER RES, V11, P937; Nguyen DV, 2002, BIOINFORMATICS, V18, P1625, DOI 10.1093/bioinformatics/18.12.1625; Park MY, 2007, BIOSTATISTICS, V8, P212, DOI 10.1093/biostatistics/kxl002; Reubi JC, 2001, CANCER RES, V61, P4636; Segal E., 2005, NAT GENET, V37, P38; Segal MR, 2006, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; Simon R, 2006, J NATL CANCER I, V98, P1169, DOI 10.1093/jnci/djj364; Tai F, 2007, BIOINFORMATICS, V23, P1775, DOI 10.1093/bioinformatics/btm234; Teschendorff AE, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-8-r157; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang L, 2008, PLOS GENET, V4, DOI 10.1371/journal.pgen.1000115; Wei Z, 2007, BIOSTATISTICS, V8, P265, DOI 10.1093/biostatistics/kxl007; Yu JX, 2007, BMC CANCER, V7, DOI 10.1186/1471-2407-7-182	44	26	26	0	7	MARY ANN LIEBERT INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277			J COMPUT BIOL	J. Comput. Biol.	FEB	2009	16	2					265	278		10.1089/cmb.2008.12TT		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	403BS	WOS:000263057400012	19183004	
J	Ni, XS; Huo, XM				Ni, Xuelei Sherry; Huo, Xiaoming			Another look at Huber's estimator: A new minimax estimator in regression with stochastically bounded noise	JOURNAL OF STATISTICAL PLANNING AND INFERENCE			English	Article						Huber's estimator; Regression; Asymptotic minimax estimator		Huber's estimator has had a long lasting impact, particularly on robust statistics. It is well known that Linder certain conditions, Huber's estimator is asymptotically minimax. A moderate generalization in rederiving Huber's estimator shows that Huber's estimator is not the only choice. We develop an alternative asymptotic minimax estimator and name it regression with stochastically bounded noise (RSBN). Simulations demonstrate that RSBN is slightly better in performance, although it is unclear how to justify such an improvement theoretically. We propose two numerical Solutions: an iterative numerical solution, which is extremely easy to implement and is based on the proximal point method: and a solution by applying state-of-the-art nonlinear optimization software packages, e.g., SNOPT. Contribution: the generalization of the variational approach is interesting and should be useful in deriving other asymptotic rnininnax estimators in other problems. (C) 2008 Elsevier B.V. All rights reserved.	[Ni, Xuelei Sherry] Kennesaw State Univ, Dept Math & Stat, Kennesaw, GA 30144 USA; [Huo, Xiaoming] Georgia Inst Technol, Sch Ind & Syst Engn, Atlanta, GA 30332 USA	Ni, XS (reprint author), Kennesaw State Univ, Dept Math & Stat, Kennesaw, GA 30144 USA.	xni2@kennesaw.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Berlinet A, 2000, J STAT PLAN INFER, V89, P243, DOI 10.1016/S0378-3758(99)00218-9; Bloomfield P, 1976, FOURIER ANAL TIME SE; Dodge Y., 1987, STAT DATA ANAL BASED; ELLIS SP, 1992, J AM STAT ASSOC, V87, P143, DOI 10.2307/2290462; GILL PE, 1998, USERS GUIDE SNOPT 5; Hampel F., 1986, WILEY SERIES PROBABI; Huber P. J., 1981, WILEY SERIES PROBABI; HUBER PJ, 1977, ROBUST STAT PROCEDUR, V27; HUO X, 2005, RSBN REGRESSION STOC; Lehmann E. L., 1991, THEORY POINT ESTIMAT; Li W, 1998, SIAM J OPTIMIZ, V8, P457, DOI 10.1137/S1052623495293160; MICHELOT C, 1994, APPL MATH OPT, V30, P203, DOI 10.1007/BF01189455; NI XS, 2005, THESIS GEORGIA I TEC; Vanderbei R. J., 1996, LINEAR PROGRAMMING	16	0	0	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3758			J STAT PLAN INFER	J. Stat. Plan. Infer.	FEB 1	2009	139	2					503	515		10.1016/j.jspi.2008.03.040		13	Statistics & Probability	Mathematics	378UD	WOS:000261348600035		
J	Zhang, B; Li, H; Riggins, RB; Zhan, M; Xuan, J; Zhang, Z; Hoffman, EP; Clarke, R; Wang, Y				Zhang, Bai; Li, Huai; Riggins, Rebecca B.; Zhan, Ming; Xuan, Jianhua; Zhang, Zhen; Hoffman, Eric P.; Clarke, Robert; Wang, Yue			Differential dependency network analysis to identify condition-specific topological changes in biological networks	BIOINFORMATICS			English	Article							EMBRYONIC STEM-CELLS; GENE-EXPRESSION DATA; ESTROGEN-RECEPTOR-ALPHA; BREAST-CANCER; REGULATORY NETWORKS; VARIABLE SELECTION; ANTIESTROGEN RESISTANCE; BAYESIAN NETWORKS; SYSTEMS BIOLOGY; MICROARRAY DATA	Motivation: Significant efforts have been made to acquire data under different conditions and to construct static networks that can explain various gene regulation mechanisms. However, gene regulatory networks are dynamic and condition-specific; under different conditions, networks exhibit different regulation patterns accompanied by different transcriptional network topologies. Thus, an investigation on the topological changes in transcriptional networks can facilitate the understanding of cell development or provide novel insights into the pathophysiology of certain diseases, and help identify the key genetic players that could serve as biomarkers or drug targets. Results: Here, we report a differential dependency network (DDN) analysis to detect statistically significant topological changes in the transcriptional networks between two biological conditions. We propose a local dependency model to represent the local structures of a network by a set of conditional probabilities. We develop an efficient learning algorithm to learn the local dependency model using the Lasso technique. A permutation test is subsequently performed to estimate the statistical significance of each learned local structure. In testing on a simulation dataset, the proposed algorithm accurately detected all the genes with network topological changes. The method was then applied to the estrogen-dependent T-47D estrogen receptor-positive (ER+) breast cancer cell line datasets and human and mouse embryonic stem cell datasets. In both experiments using real microarray datasets, the proposed method produced biologically meaningful results. We expect DDN to emerge as an important bioinformatics tool in transcriptional network analyses. While we focus specifically on transcriptional networks, the DDN method we introduce here is generally applicable to other biological networks with similar characteristics.	[Zhang, Bai; Xuan, Jianhua; Wang, Yue] Virginia Polytech Inst & State Univ, Dept Elect & Comp Engn, Arlington, VA 22203 USA; [Li, Huai; Zhan, Ming] NIA, Bioinformat Unit, RRB, NIH, Baltimore, MD 21224 USA; [Riggins, Rebecca B.; Clarke, Robert] Georgetown Univ, Dept Oncol Physiol & Biophys, Washington, DC 20057 USA; [Riggins, Rebecca B.; Clarke, Robert] Georgetown Univ, Lombardi Comprehens Canc Ctr, Washington, DC 20057 USA; [Zhang, Zhen] Johns Hopkins Med Inst, Dept Pathol, Baltimore, MD 21231 USA; [Hoffman, Eric P.] Childrens Natl Med Ctr, Med Genet Res Ctr, Washington, DC 20010 USA	Wang, Y (reprint author), Virginia Polytech Inst & State Univ, Dept Elect & Comp Engn, Arlington, VA 22203 USA.		Clarke, Robert/A-6485-2008	Clarke, Robert/0000-0002-9278-0854	National Institutes of Health [CA109872, EB000830, CA096483, CA86323, NS29525]; Department of Defense Breast Cancer Research Program [BC030280]	Funding: National Institutes of Health (CA109872, EB000830, CA096483, CA86323 and NS29525, partial); Department of Defense Breast Cancer Research Program BC030280. IRP/NIA/NIH (to H.L. and M.Z.).	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hood L, 2004, SCIENCE, V306, P640, DOI 10.1126/science.1104635; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Kitano H, 2002, SCIENCE, V295, P1662, DOI 10.1126/science.1069492; Sato N, 2003, DEV BIOL, V260, P404, DOI 10.1016/S0012-1606(03)00256-2; Howell A, 2006, ENDOCR-RELAT CANCER, V13, P689, DOI 10.1677/erc.1.00846; Clarke R, 2008, NAT REV CANCER, V8, P37, DOI 10.1038/nrc2294; Choi JK, 2005, BIOINFORMATICS, V21, P4348, DOI 10.1093/bioinformatics/bti722; Segal E, 2003, NAT GENET, V34, P166, DOI 10.1038/ng1165; Sun Y, 2007, GENOMICS, V89, P22, DOI 10.1016/j.ygeno.2006.09.010; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Friedman N, 2004, SCIENCE, V303, P799, DOI 10.1126/science.1094068; Efron B, 2004, ANN STAT, V32, P407; Shmulevich I, 2002, BIOINFORMATICS, V18, P261, DOI 10.1093/bioinformatics/18.2.261; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; Beyer A, 2007, NAT REV GENET, V8, P699, DOI 10.1038/nrg2144; Ding LH, 2003, NUCLEIC ACIDS RES, V31, P5266, DOI 10.1093/nar/gkg731; Efron B, 1993, INTRO BOOTSTRAP; Englebienne P., 2002, CHRONIC FATIGUE SYND; Fang Y, 2004, BIOCHEM BIOPH RES CO, V323, P269, DOI 10.1016/j.bbrc.2004.08.100; Felekkis KN, 2005, MOL CANCER RES, V3, P32; Fuller TF, 2007, MAMM GENOME, V18, P463, DOI 10.1007/s00335-007-9043-3; Gomez BP, 2007, FASEB J, V21, P4013, DOI 10.1096/fj.06-7990com; Gompel A, 2000, STEROIDS, V65, P593, DOI 10.1016/S0039-128X(00)00172-0; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Iwakoshi NN, 2003, IMMUNOL REV, V194, P29, DOI 10.1034/j.1600-065X.2003.00057.x; Kadie C., 2000, J MACHINE LEARNING R, V1, P49; Kim H, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-165; Kostka Dennis, 2004, Bioinformatics, V20 Suppl 1, pi194, DOI 10.1093/bioinformatics/bth909; KUO MT, 2007, BREAST CANC CHEMOSEN, P23; Li CY, 2008, BIOINFORMATICS, V24, P1175, DOI 10.1093/bioinformatics/btn081; Li H, 2008, FRONT BIOSCI-LANDMRK, V13, P263, DOI 10.2741/2677; Liao JC, 2003, P NATL ACAD SCI USA, V100, P15522, DOI 10.1073/pnas.2136632100; Lin CY, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-9-r66; Liu CC, 2006, NUCLEIC ACIDS RES, V34, P4069, DOI 10.1093/nar/gkl583; Liu Y, 2006, BMC DEV BIOL, V6, DOI 10.1186/1471-213X/6/20; Luscombe NM, 2004, NATURE, V431, P308, DOI 10.1038/nature02782; Pratt MAC, 2003, MOL CELL BIOL, V23, P6887, DOI 10.1128/MCB.23.19.6887-6900.2003; Qiu P, 2007, BIOINFORMATICS, V23, P198, DOI 10.1093/bioinformatics/btl553; Qiu P, 2005, BIOINFORMATICS, V21, P3114, DOI 10.1093/bioinformatics/bti483; Rangel C, 2004, BIOINFORMATICS, V20, P1361, DOI 10.1093/bioinformatics/bth093; Riggins RB, 2005, VITAM HORM, V71, P201, DOI 10.1016/S0083-6729(05)71007-4; Riggins RB, 2007, CANCER LETT, V256, P1, DOI 10.1016/j.canlet.2007.03.016; Riggins RB, 2003, J BIOL CHEM, V278, P28264, DOI 10.1074/jbc.M303535200; Sanna MG, 2002, MOL CELL BIOL, V22, P1754, DOI 10.1128/MCB.22.6.1754-1766.2002; Schrecengost RS, 2007, CANCER RES, V67, P6174, DOI 10.1158/0008-5472.CAN-06-3455; Somai S, 2003, INT J CANCER, V105, P607, DOI 10.1002/ijc.11147; Sun Y, 2006, CRIT REV EUKAR GENE, V16, P211; Tozlu S, 2006, ENDOCR-RELAT CANCER, V13, P1109, DOI 10.1677/erc.1.01120; Van den Bulcke T, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-43; Van Agthoven T, 2006, BREAST CANCER RES TR, V100, pS37; Viatour P, 2003, LEUKEMIA, V17, P1349, DOI 10.1038/sj.leu.2402982; Wang DY, 2004, MOL ENDOCRINOL, V18, P402, DOI 10.1210/me.2003-0202; Watson M, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-509; Wei Z, 2007, BIOINFORMATICS, V23, P1537, DOI 10.1093/bioinformatics/btm129; Zhan M, 2005, CELL BIOCHEM BIOPHYS, V43, P379, DOI 10.1385/CBB:43:3:379; Zhan M, 2008, FRONT BIOSCI-LANDMRK, V13, P276, DOI 10.2741/2678	59	37	38	0	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	FEB 15	2009	25	4					526	532		10.1093/bioinformatics/btn660		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	408AS	WOS:000263406000016	19112081	
J	Trendafilov, NT; Vines, K				Trendafilov, Nickolay T.; Vines, Karen			Simple and interpretable discrimination	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							PRINCIPAL COMPONENTS; VARIABLE SELECTION; LASSO	A number of approaches have been proposed for constructing alternatives to principal components that are more easily interpretable, while still explaining considerable part of the data variability. One such approach is employed in order to produce interpretable canonical variates and explore their discrimination behavior, which is more complicated as orthogonality with respect to the within-groups sums-of-squares matrix is involved. The proposed simple and interpretable canonical variates are an optimal choice between good and sparse approximation to the original ones, rather than identifying the variables that dominate the discrimination. The numerical algorithms require low computational cost, and are illustrated on the Fisher's iris data and on moderately large real data. (C) 2008 Elsevier B.V. All rights reserved.	[Trendafilov, Nickolay T.; Vines, Karen] Open Univ, Dept Math & Stat, Milton Keynes MK7 6AA, Bucks, England	Trendafilov, NT (reprint author), Open Univ, Dept Math & Stat, Milton Keynes MK7 6AA, Bucks, England.	N.Trendafilov@open.ac.uk; S.K.Vines@open.ac.uk					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; RENCHER AC, 1992, AM STAT, V46, P217, DOI 10.2307/2685219; Chipman HA, 2005, J APPL STAT, V32, P969, DOI 10.1080/02664760500168648; Dhillon IS, 2002, COMPUT STAT DATA AN, V41, P59, DOI 10.1016/S0167-9473(02)00144-5; Fisher RA, 1936, ANN EUGENIC, V7, P179; Golub G., 1996, MATRIX COMPUTATIONS; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Jolliffe IT, 2000, J COMPUT GRAPH STAT, V9, P689, DOI 10.2307/1391088; Krzanowski W. J., 2003, PRINCIPLES MULTIVARI; KRZANOWSKI WJ, 1995, J CHEMOMETR, V9, P509, DOI 10.1002/cem.1180090608; Rousson V, 2004, J ROY STAT SOC C-APP, V53, P539, DOI 10.1111/j.1467-9876.2004.05359.x; Tebbens JD, 2007, COMPUT STAT DATA AN, V52, P423, DOI 10.1016/j.csda.2007.02.001; Trendafilov NT, 2007, COMPUT STAT DATA AN, V51, P3718, DOI 10.1016/j.csda.2006.12.046; Trendafilov NT, 2006, COMPUT STAT DATA AN, V50, P242, DOI 10.1016/j.csda.2004.07.017; VINES SK, 2000, APPL STAT, V49, P441; Wood M, 2005, J AGR BIOL ENVIR ST, V10, P321, DOI 10.1198/108571105X58540	17	3	3	1	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	FEB 15	2009	53	4					979	989		10.1016/j.csda.2008.11.018		11	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	411CX	WOS:000263626700015		
J	Daye, ZJ; Jeng, XJ				Daye, Z. John; Jeng, X. Jessie			Shrinkage and model selection with correlated variables via weighted fusion	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							LARGE COVARIANCE MATRICES; NONORTHOGONAL PROBLEMS; WAVELET SHRINKAGE; RIDGE REGRESSION; MICROARRAY DATA; LASSO	In this paper, we propose the weighted fusion, a new penalized regression and variable selection method for data with correlated variables. The weighted fusion can potentially incorporate information redundancy among correlated variables for estimation and variable selection. Weighted fusion is also useful when the number of predictors p is larger than the number of observations n. It allows the selection of more than n variables in a motivated way. Real data and simulation examples show that weighted fusion can improve variable selection and prediction accuracy. Published by Elsevier B.V.	[Daye, Z. John; Jeng, X. Jessie] Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA	Daye, ZJ (reprint author), Purdue Univ, Dept Stat, W Lafayette, IN 47907 USA.	zdaye@stat.purdue.edu; zheng4@stat.purdue.edu			NSF [DMS-0639980]; Ross Fellowship; Department of Statistics, Purdue University; Rosen Center for Advanced Computing of Information Technology at Purdue	The authors are very grateful to Jayanta K. Ghosh, jian Zhang, Ji Zhu, and Michael Yu Zhu for helpful comments and discussions. In addition, we thank Mary Ellen Bock, Jiashun Jin, and Jun Xie for brief but fruitful discussions. Appreciation also goes to two reviewers and the associate editor for very helpful suggestions. Xinge Jessie jeng is supported by a grant from NSF (DMS-0639980) and Zhongyin John Daye by Ross Fellowship. Computing resources and support were provided by the Department of Statistics, Purdue University, and the Rosen Center for Advanced Computing of Information Technology at Purdue.	Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Bickel PJ, 2008, ANN STAT, V36, P199, DOI 10.1214/009053607000000758; Wong F, 2003, BIOMETRIKA, V90, P809, DOI 10.1093/biomet/90.4.809; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Bovelstad HM, 2007, BIOINFORMATICS, V23, P2080, DOI 10.1093/bioinformatics/btm305; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Wang L, 2006, STAT SINICA, V16, P589; BICKEL P, 2008, ANN STAT IN PRESS; Buhlmann P, 2006, ANN STAT, V34, P559, DOI 10.1214/009053606000000092; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; ELKAROUI N, 2007, ANN STAT IN PRESS; Fan J., 2006, P INT C MATH, P595; Harrell FE, 2001, REGRESSION MODELING; HOERL AE, 1970, TECHNOMETRICS, V12, P69, DOI 10.2307/1267352; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; HURVICH CM, 1998, J R STAT SOC B, V60; Kim Y, 2004, P 21 INT C MACH LEAR; Kutner MH, 2005, APPL LINEAR STAT MOD; LAM C, 2007, SPARSISTENCY R UNPUB; Land S. R., 1996, VARIABLE FUSION NEW; LI C, 2008, NETWORK CONSTRAINED; Park MY, 2007, BIOSTATISTICS, V8, P212, DOI 10.1093/biostatistics/kxl002; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Rothman A., 2008, 477 U MICH DEP STAT; ROTHMAN A, 2007, 467 U MICH DEP STAT; Tukey J. W., 1977, DATA ANAL REGRESSION; TUTZ G, 2006, 486 U MUNCH; Weisberg S., 1985, APPL LINEAR REGRESSI; Wu WB, 2003, BIOMETRIKA, V90, P831, DOI 10.1093/biomet/90.4.831; Yu B, 2007, TECHNOMETRICS, V49, P237, DOI 10.1198/004017007000000254; Zhao P, 2007, J MACH LEARN RES, V8, P2701	41	19	21	1	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473	1872-7352		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	FEB 15	2009	53	4					1284	1298		10.1016/j.csda.2008.11.007		15	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	411CX	WOS:000263626700043		
J	Annest, A; Bumgarner, RE; Raftery, AE; Yeung, KY				Annest, Amalia; Bumgarner, Roger E.; Raftery, Adrian E.; Yeung, Ka Yee			Iterative Bayesian Model Averaging: a method for the application of survival analysis to high-dimensional microarray data	BMC BIOINFORMATICS			English	Article							GENE-EXPRESSION DATA; PARTIAL LEAST-SQUARES; B-CELL LYMPHOMA; FEATURE-SELECTION; PREDICT SURVIVAL; MARKER GENES; MOLECULAR CLASSIFICATION; CANCER CLASSIFICATION; LUNG ADENOCARCINOMA; PATIENT SURVIVAL	Background: Microarray technology is increasingly used to identify potential biomarkers for cancer prognostics and diagnostics. Previously, we have developed the iterative Bayesian Model Averaging (BMA) algorithm for use in classification. Here, we extend the iterative BMA algorithm for application to survival analysis on high-dimensional microarray data. The main goal in applying survival analysis to microarray data is to determine a highly predictive model of patients' time to event (such as death, relapse, or metastasis) using a small number of selected genes. Our multivariate procedure combines the effectiveness of multiple contending models by calculating the weighted average of their posterior probability distributions. Our results demonstrate that our iterative BMA algorithm for survival analysis achieves high prediction accuracy while consistently selecting a small and cost-effective number of predictor genes. Results: We applied the iterative BMA algorithm to two cancer datasets: breast cancer and diffuse large B-cell lymphoma (DLBCL) data. On the breast cancer data, the algorithm selected a total of 15 predictor genes across 84 contending models from the training data. The maximum likelihood estimates of the selected genes and the posterior probabilities of the selected models from the training data were used to divide patients in the test (or validation) dataset into high-and low-risk categories. Using the genes and models determined from the training data, we assigned patients from the test data into highly distinct risk groups (as indicated by a p-value of 7.26e-05 from the log-rank test). Moreover, we achieved comparable results using only the 5 top selected genes with 100% posterior probabilities. On the DLBCL data, our iterative BMA procedure selected a total of 25 genes across 3 contending models from the training data. Once again, we assigned the patients in the validation set to significantly distinct risk groups (p-value = 0.00139). Conclusion: The strength of the iterative BMA algorithm for survival analysis lies in its ability to account for model uncertainty. The results from this study demonstrate that our procedure selects a small number of genes while eclipsing other methods in predictive performance, making it a highly accurate and cost-effective prognostic tool in the clinical setting.	[Bumgarner, Roger E.; Yeung, Ka Yee] Univ Washington, Dept Microbiol, Seattle, WA 98195 USA; [Annest, Amalia] Univ Washington, Inst Technol Comp & Software Syst, Tacoma, WA 98402 USA; [Raftery, Adrian E.] Univ Washington, Dept Stat, Seattle, WA 98195 USA	Yeung, KY (reprint author), Univ Washington, Dept Microbiol, Box 358070, Seattle, WA 98195 USA.	amanu@u.washington.edu; rogerb@u.washington.edu; raftery@stat.washington.edu; kayee@u.washington.edu	Bumgarner, Roger/K-3531-2015	Bumgarner, Roger/0000-0002-8168-6985	NIH-NHLBI [P50 HL073996]; NIH-NIAID [U54 AI057141]; NIH-NCRR [R24 RR021863-01A1, 1 UL1 RR 025014-01]; NIH-NIDCR [R01 DE012212-06]; Merck; NIH-NICHD [1R01HDO54511-01A1]; NSF [IIS0534094, ATM0724721]; Office of Naval Research [N00014-01-1-0745]; NIH-NCI [K25CA106988]; NIH-NIGMS [R01GM084163-01A1]	We would like to thank Drs. Isabelle Bichindaritz, Donald Chinn, Steve Hanks, Ian Painter, Deanna Petrochilos, and Chris Volinsky. Bumgarner is funded by NIH-NHLBI P50 HL073996, NIH-NIAID U54 AI057141, NIH-NCRR R24 RR021863-01A1, NIH-NIDCR R01 DE012212-06, NIH-NCRR 1 UL1 RR 025014-01, and a generous basic research grant from Merck. Raftery is supported by NIH-NICHD 1R01HDO54511-01A1, NSF IIS0534094, NSF ATM0724721, and Office of Naval Research grant N00014-01-1-0745. Yeung is supported by NIH-NCI K25CA106988 and NIH-NIGMS .	Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Alizadeh A, 1999, COLD SPRING HARB SYM, V64, P71, DOI 10.1101/sqb.1999.64.71; Hoeting JA, 1999, STAT SCI, V14, P382; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; Sotiriou C, 2003, P NATL ACAD SCI USA, V100, P10393, DOI 10.1073/pnas.1732912100; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; Raponi M, 2006, CANCER RES, V66, P7466, DOI 10.1158/0008-5472.CAN-06-1191; [Anonymous], 1997, BLOOD, V89, P3909; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Bovelstad HM, 2007, BIOINFORMATICS, V23, P2080, DOI 10.1093/bioinformatics/btm305; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Yeung KY, 2005, BIOINFORMATICS, V21, P2394, DOI 10.1093/bioinformatics/bti319; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Jiang HY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-81; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; CAI T, 2008, BIOMETRICS IN PRESS; CHEN C, 2003, NUCL SCI S C REC 200, V4, P2468; Chow ML, 2001, PHYSIOL GENOMICS, V5, P99; COX DR, 1972, J R STAT SOC B, V34, P187; Datta S, 2007, BIOMETRICS, V63, P259, DOI 10.1111/j.1541-0420.2006.00660.x; DERKSEN S, 1992, BRIT J MATH STAT PSY, V45, P265; DRAPER D, 1995, J R STAT SOC B, V57, P45; Geman D., 2004, STAT APPL GENET MOL, V3, P1; Hosmer D. W., 2008, APPL SURVIVAL ANAL R; Hu H., 2006, P AUSTR DAT MIN C AU, P33; Huang J, 2006, BIOMETRICS, V62, P813, DOI 10.1111/j.1541-0420.2006.00562.x; Huang T. M., 2006, STUDIES COMPUTATIONA, V17; Kaderali L, 2006, BIOINFORMATICS, V22, P1495, DOI 10.1093/bioinformatics/btl103; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; Kotsiantis S B, 2007, Informatica, V31; KUO L, 1992, NATO ADV SCI I E-APP, V211, P11; Lai C, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-235; Langley P., 1994, P AAAI FALL S REL, P140; Li HZ, 2004, BIOINFORMATICS, V20, P208, DOI 10.1093/bioinformatics/bth900; LI J, 2007, 1 INT C BIOINF BIOM, P264; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Liu H, 2008, CH CRC DATA MIN KNOW, P3; Lu Y, 2006, PLOS MED, V3, P2229, DOI 10.1371/journal.pmed.0030467; Madigan D. M., 1994, J AM STAT ASSOC, V89, P1335; Motoda H., 1998, FEATURE SELECTION KN; Nguyen DV, 2002, BIOINFORMATICS, V18, P1625, DOI 10.1093/bioinformatics/18.12.1625; Prentice RL, 1980, STAT ANAL FAILURE TI; Raftery AE, 1996, BIOMETRIKA, V83, P251, DOI 10.1093/biomet/83.2.251; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; Silva PJS, 2005, PATTERN RECOGN LETT, V26, P1444, DOI 10.1016/j.patrec.2004.11.017; TAPLIN RH, 1993, J ROY STAT SOC B MET, V55, P829; TAPLIN RH, 1994, BIOMETRICS, V50, P764, DOI 10.2307/2532790; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vijver MJ, 2002, NEW ENGL J MED, V347, P1999; Volinsky C., 1997, APPL STAT, V46, P443; Volinsky CT, 2000, BIOMETRICS, V56, P256, DOI 10.1111/j.0006-341X.2000.00256.x; Witten I., 2005, DATA MINING PRACTICA; Xu L, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-275; Xu L, 2005, BIOINFORMATICS, V21, P3905, DOI 10.1093/bioinformatics/bti647; Yu JJ, 2007, NEOPLASIA, V9, P292, DOI 10.1593/neo.07121; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037	63	8	8	0	4	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	FEB 26	2009	10								72	10.1186/1471-2105-10-72		17	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	427GA	WOS:000264766600001	19245714	
J	Benjamini, Y; Gavrilov, Y				Benjamini, Yoav; Gavrilov, Yulia			A SIMPLE FORWARD SELECTION PROCEDURE BASED ON FALSE DISCOVERY RATE CONTROL	ANNALS OF APPLIED STATISTICS			English	Article						Linear regression; multiple testing; random oracle	ADAPTIVE MODEL SELECTION; VARIABLE SELECTION; REGRESSION; SHRINKAGE	We propose the use of if new false discovery rate (FDR) controlling procedure as a model selection penalized method, and compare its performance to that of other penalized methods over a wide range of realistic settings: nonorthogonal design matrices, moderate and large pool of explanatory variables, and both sparse and nonsparse models, in the sense that they may include a small and large fraction of the potential variables (and even all). The comparison is done by a comprehensive simulation Study, using a quantitative framework for performance comparisons in the form of empirical minimaxity relative to a "random oracle": the oracle model selection performance oil data dependent forward selected family of potential models. We show that FDR based procedures have good performance, and in particular the newly proposed method, emerges as having empirical minimax performance. Interestingly, using FDR level of 0.05 is a global best.	[Benjamini, Yoav; Gavrilov, Yulia] Tel Aviv Univ, Dept Stat & Operat Res, IL-69978 Tel Aviv, Israel	Benjamini, Y (reprint author), Tel Aviv Univ, Dept Stat & Operat Res, IL-69978 Tel Aviv, Israel.	ybenja@post.tau.ac.il; gyulia@post.tau.ac.il	Benjamini, Yoav/C-4219-2008		US-Israel Binational Science Foundation [1999441]; US National Institute of Health	Supported by US-Israel Binational Science Foundation Grant 1999441 and a US National Institute of Health grant.	Abramovich F., 1995, LECT NOTES STAT, V103, P5; Akaike H., 1973, 2 INT S INF THEOR, P267; Andrews D. F., 1972, ROBUST ESTIMATES LOC; Shen XT, 2002, J AM STAT ASSOC, V97, P210, DOI 10.1198/016214502753479356; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Johnstone IM, 2005, ANN STAT, V33, P1700, DOI 10.1214/009053605000000345; Gavrilov Y, 2009, ANN STAT, V37, P619, DOI 10.1214/07-AOS586; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Genovese C, 2002, J ROY STAT SOC B, V64, P499, DOI 10.1111/1467-9868.00347; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; BENJAMIN Y, 2009, SIMPLE FORWARD SEL S; Benjamini Y, 2006, BIOMETRIKA, V93, P491, DOI 10.1093/biomet/93.3.491; Benjamini Y, 2000, J EDUC BEHAV STAT, V25, P60, DOI 10.3102/10769986025001060; Bickel P., 2008, HIERARCHICAL SELECTI; BICKEL P, 2008, ANN STAT IN PRESS; BIRGE L, 2001, GEN CP CRITERION GAU; Cochran W.G., 1977, SAMPLING TECHNIQUES; Draper N. R., 1998, APPL REGRESSION ANAL; FINNER H, 2009, ANN STAT IN PRESS; Foster DP, 2004, J AM STAT ASSOC, V99, P303, DOI 10.1198/016214504000000287; George EI, 2000, BIOMETRIKA, V87, P731, DOI 10.1093/biomet/87.4.731; Sarkar SK, 2002, ANN STAT, V30, P239, DOI 10.1214/aos/1015362192; Tibshirani R, 1999, J ROY STAT SOC B, V61, P529, DOI 10.1111/1467-9868.00191; Yuan M, 2007, J ROY STAT SOC B, V69, P329, DOI 10.1111/j.1467-9868.2007.00591.x	30	15	15	1	2	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	MAR	2009	3	1					179	198		10.1214/08-AOAS194		20	Statistics & Probability	Mathematics	522EA	WOS:000271979400008		
J	Foster, SD; Verbyla, AP; Pitchford, WS				Foster, Scott D.; Verbyla, Arunas P.; Pitchford, Wayne S.			ESTIMATION, PREDICTION AND INFERENCE FOR THE LASSO RANDOM EFFECTS MODEL	AUSTRALIAN & NEW ZEALAND JOURNAL OF STATISTICS			English	Article						hierarchical model; LASSO; marginal likelihood; prediction distribution; variance parameters	REGRESSION; SHRINKAGE; SELECTION; RIDGE	The least absolute shrinkage and selection operator (LASSO) can be formulated as a random effects model with an associated variance parameter that can be estimated with other components of variance. In this paper, estimation of the variance parameters is performed by means of an approximation to the marginal likelihood of the observed outcomes. The approximation is based on an alternative but equivalent formulation of the LASSO random effects model. Predictions can be made using point summaries of the predictive distribution of the random effects given the data with the parameters set to their estimated values. The standard LASSO method uses the mode of this distribution as the predictor. It is not the only choice, and a number of other possibilities are defined and empirically assessed in this article. The predictive mode is competitive with the predictive mean (best predictor), but no single predictor performs best across in all situations. Inference for the LASSO random effects is performed using predictive probability statements, which are more appropriate under the random effects formulation than tests of hypothesis.	[Foster, Scott D.; Verbyla, Arunas P.; Pitchford, Wayne S.] Univ Adelaide, Sch Agr Food & Wine, Glen Osmond, SA 5064, Australia; [Verbyla, Arunas P.] CSIRO Math & Informat Sci, Glen Osmond, SA 5064, Australia	Foster, SD (reprint author), CSIRO Math & Informat Sci, GPO Box 1538, Hobart, Tas 7001, Australia.	scott.foster@csiro.au	foster, scott/E-9311-2010; 	Pitchford, Wayne/0000-0002-5213-3978			ANDREWS DF, 1974, J ROY STAT SOC B MET, V36, P99; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; LINDLEY DV, 1972, J ROY STAT SOC B, V34, P1; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Foster SD, 2007, J AGR BIOL ENVIR ST, V12, P300, DOI 10.1198/108571107X200396; Foster SD, 2008, COMPUTATION STAT, V23, P217, DOI 10.1007/s00180-007-0033-4; Gelman A., 1995, TEXTS STAT SCI; Grandvalet Y, 1999, ADV NEUR IN, V11, P445; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; KIIVERI HT, 2003, LECT NOTES MONOGRAPH, V30, P127; Kotz S, 2001, LAPLACE DISTRIBUTION; Miller A., 2002, MONOGRAPHS STAT APPL, V95; Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657; Robinson G. K., 1991, STAT SCI, V6, P15, DOI DOI 10.1214/SS/1177011926; Searle S. R., 1992, VARIANCE COMPONENTS; STAMEY TA, 1989, J UROLOGY, V141, P1076; Yuan M, 2005, J AM STAT ASSOC, V100, P1215, DOI 10.1198/016214505000000367	17	2	2	0	1	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1369-1473	1467-842X		AUST NZ J STAT	Aust. N. Z. J. Stat.	MAR	2009	51	1					43	61		10.1111/j.1467-842X.2008.00526.x		19	Statistics & Probability	Mathematics	417GN	WOS:000264064600003		
J	Bondell, HD; Reich, BJ				Bondell, Howard D.; Reich, Brian J.			Simultaneous Factor Selection and Collapsing Levels in ANOVA	BIOMETRICS			English	Article; Proceedings Paper	7th BIRTHA Conference on Informal Empire	JAN 26-27, 2007	Bristol, ENGLAND	Bristol Inst Res Humanities & Arts, British Acad, Soc Latin Amer Studies, UoB, Ctr Study Colonial & Postcolonial Soc, UoB, Fac Arts, UoB, Sch Modern Languages	Univ Bristol	ANOVA; Grouping; Multiple comparisons; Oracle property; Shrinkage; Variable selection	VARIABLE SELECTION; REGRESSION SHRINKAGE; ORACLE PROPERTIES; MODEL SELECTION; LASSO	When performing an analysis of variance, the investigator often has two main goals: to determine which of the factors have a significant effect on the response, and to detect differences among the levels of the significant factors. Level comparisons are done via a post-hoc analysis based on pairwise differences. This article proposes a novel constrained regression approach to simultaneously accomplish both goals via shrinkage within a single automated procedure. The form of this shrinkage has the ability to collapse levels within a factor by setting their effects to be equal, while also achieving factor selection by zeroing out entire factors. Using this approach also leads to the identification of a structure within each factor, as levels can be automatically collapsed to form groups. In contrast to the traditional pairwise comparison methods, these groups are necessarily nonoverlapping so that the results are interpretable in terms of distinct subsets of levels. The proposed procedure is shown to have the oracle property in that asymptotically it performs as well as if the exact structure were known beforehand. A simulation and real data examples show the strong performance of the method.	[Bondell, Howard D.; Reich, Brian J.] N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA	Bondell, HD (reprint author), N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA.	bondell@stat.ncsu.edu					Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Bondell HD, 2008, BIOMETRICS, V64, P115, DOI 10.1111/j.1541-0420.2007.00843.x; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; SCOTT AJ, 1974, BIOMETRICS, V30, P507, DOI 10.2307/2529204; BAUTISTA MG, 1997, J AGR BIOL ENVIR ST, V2, P179, DOI 10.2307/1400402; BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466; CALINSKI T, 1985, BIOMETRICS, V41, P39, DOI 10.2307/2530641; Cleveland W. S., 1993, VISUALIZING DATA; COX DR, 1982, SCAND J STAT, V9, P147; Fisher R. A., 1971, DESIGN EXPT; IMMER F. R., 1934, JOUR AMER SOC AGRON, V26, P403; Nobile A, 2000, BIOMETRIKA, V87, P15, DOI 10.1093/biomet/87.1.15; Shao J, 1997, STAT SINICA, V7, P221; Venables WN, 2002, MODERN APPL STAT S; Wu YJ, 2007, J AM STAT ASSOC, V102, P235, DOI 10.1198/016214506000000843; Yang YH, 2005, BIOMETRIKA, V92, P937, DOI 10.1093/biomet/92.4.937; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	25	18	18	1	7	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0006-341X			BIOMETRICS	Biometrics	MAR	2009	65	1					169	177		10.1111/j.1541-0420.2008.01061.x		9	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	420RS	WOS:000264307500019	18510652	
J	Wang, L				Wang, Lan			Wilcoxon-type generalized Bayesian information criterion	BIOMETRIKA			English	Article						bic; Bayesian information criterion; Consistency of model selection; Heavier-tailed distribution; L(2) risk; Rank; Wilcoxon inference	NONCONCAVE PENALIZED LIKELIHOOD; QUANTITATIVE TRAIT LOCI; LINEAR-MODEL; REGRESSION-COEFFICIENTS; SELECTION; RANKS; HYPOTHESES	We develop a generalized Bayesian information criterion for regression model selection. The new criterion relaxes the usually strong distributional assumption associated with Schwarz's bic by adopting a Wilcoxon-type dispersion function and appropriately adjusting the penalty term. We establish that the Wilcoxon-type generalized bic preserves the consistency of Schwarz's bic without the need to assume a parametric likelihood. We also show that it outperforms Schwarz's bic with heavier-tailed data in the sense that asymptotically it can yield substantially smaller L(2) risk. On the other hand, when the data are normally distributed, both criteria have similar L(2) risk. The new criterion function is convex and can be conveniently computed using existing statistical software. Our proposal provides a flexible yet highly efficient alternative to Schwarz's bic; at the same time, it broadens the scope of Wilcoxon inference, which has played a fundamental role in classical nonparametric analysis.	Univ Minnesota, Sch Stat, Minneapolis, MN 55455 USA	Wang, L (reprint author), Univ Minnesota, Sch Stat, 313 Ford Hall,224 Church St SE, Minneapolis, MN 55455 USA.	lan@stat.umn.edu			U. S. National Science Foundation	would like to thank Professor D. M. Titterington, an associate editor, a referee, Edsel Pena and Vance Berger for their valuable and constructive comments. This research was supported by a grant from the U. S. National Science Foundation.	NISHII R, 1984, ANN STAT, V12, P758, DOI 10.1214/aos/1176346522; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; JAECKEL LA, 1972, ANN MATH STAT, V43, P1449, DOI 10.1214/aoms/1177692377; KASS RE, 1995, J AM STAT ASSOC, V90, P928, DOI 10.2307/2291327; TIERNEY L, 1986, J AM STAT ASSOC, V81, P82, DOI 10.2307/2287970; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Broman KW, 2002, J R STAT SOC B, V64, P641, DOI 10.1111/1467-9868.00354; Burnham K. P., 2002, MODEL SELECTION MULT; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Hettmansperger TP, 1998, ROBUST NONPARAMETRIC; HETTMANSPERGER TP, 1983, J AM STAT ASSOC, V78, P885, DOI 10.2307/2288200; JURECKOV.J, 1971, ANN MATH STAT, V42, P1328, DOI 10.1214/aoms/1177693245; Konishi S, 2004, BIOMETRIKA, V91, P27, DOI 10.1093/biomet/91.1.27; Lazar NA, 2003, BIOMETRIKA, V90, P319, DOI 10.1093/biomet/90.2.319; MCKEAN JW, 1980, J ROY STAT SOC B MET, V42, P366; MCKEAN JW, 1978, BIOMETRIKA, V65, P571; MCKEAN JW, 1976, COMMUN STAT A-THEOR, V5, P693, DOI 10.1080/03610927608827388; PETTITT AN, 1982, J ROY STAT SOC B MET, V44, P234; Raftery AE, 1996, BIOMETRIKA, V83, P251, DOI 10.1093/biomet/83.2.251; Shi PD, 1998, J ROY STAT SOC B, V60, P551, DOI 10.1111/1467-9868.00139; Siegmund D, 2004, BIOMETRIKA, V91, P785, DOI 10.1093/biomet/91.4.785; Sievers GL, 2004, J STAT COMPUT SIM, V74, P821, DOI 10.1080/00949650310001596381; Terpstra J, 2005, J STAT SOFTW, V14, P1; Volinsky CT, 2000, BIOMETRICS, V56, P256, DOI 10.1111/j.0006-341X.2000.00256.x; Weisberg S., 2005, APPL LINEAR REGRESSI; WHITE H, 1981, J AM STAT ASSOC, V76, P419, DOI 10.2307/2287845; Zhan XJ, 2007, COMPUT STAT DATA AN, V51, P5077, DOI 10.1016/j.csda.2006.02.018	28	7	7	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0006-3444			BIOMETRIKA	Biometrika	MAR	2009	96	1					163	173		10.1093/biomet/asn060		11	Biology; Mathematical & Computational Biology; Statistics & Probability	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics	408AT	WOS:000263406100012		
J	Zhang, CM; Jiang, Y; Shang, ZF				Zhang, Chunming; Jiang, Yuan; Shang, Zuofeng			New aspects of Bregman divergence in regression and classification with parametric and nonparametric estimation	CANADIAN JOURNAL OF STATISTICS-REVUE CANADIENNE DE STATISTIQUE			English	Article						Asymptotic normality; Bayes optimal rule; consistency; local polynomial regression; loss function; prediction error	MODELS; ERROR	In statistical learning, regression and classification concern different types of the output variables, and the predictive accuracy is quantified by different loss functions. This article explores new aspects of Bregman divergence (BD), a notion which unifies nearly all of the commonly used loss functions in regression and classification. The authors investigate the duality between BD and its generating function. They further establish, under the framework of BD, asymptotic consistency and normality of parametric and nonparametric regression estimators, derive the lower bound of their asymptotic covariance matrices, and demonstrate the role that parametric and nonparametric regression estimation play in the performance of classification procedures and related machine learning techniques. These theoretical results and new numerical evidence show that the choice of loss function affects estimation procedures, whereas has an asymptotically relatively negligible impact on classification performance. Applications of BD to statistical model building and selection with non-Gaussian responses are also illustrated. The Canadian Journal of Statistics 37: 119-139; 2009 (C) 2009 Statistical Society of Canada	[Zhang, Chunming; Jiang, Yuan; Shang, Zuofeng] Univ Wisconsin, Dept Stat, Madison, WI 53706 USA	Zhang, CM (reprint author), Univ Wisconsin, Dept Stat, Madison, WI 53706 USA.	cmzhang@stat.wisc.edu			National Science Foundation; Wisconsin Alumni Research Foundation	The research is supported in part by National Science Foundation grants and Wisconsin Alumni Research Foundation. The authors are grateful to the Editor, Associate Editor, and two anonymous referees for insightful comments and Suggestions.	ALTUN Y, 2006, P 19 ANN C LEARN THE, P139; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 1998, ANN STAT, V26, P801; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; HASTIE T, 1993, J ROY STAT SOC B MET, V55, P757; Azoury KS, 2001, MACH LEARN, V43, P211, DOI 10.1023/A:1010896012157; Banerjee A, 2005, IEEE T INFORM THEORY, V51, P2664, DOI 10.1109/TIT.2005.850145; Bregman L. M., 1967, USSR COMP MATH MATH, V7, P620; Efron B, 2004, J AM STAT ASSOC, V99, P619, DOI 10.1198/016214504000000692; EFRON B, 1986, J AM STAT ASSOC, V81, P461, DOI 10.2307/2289236; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; Grunwald PD, 2004, ANN STAT, V32, P1367, DOI 10.1214/009053604000000553; HASTIE T, 2001, ELEMENIS STAT LEARNI; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307424; LAFFERTY J, 1997, P CAN WORKSH INF THE; Lafferty J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307422; NGUYEN X, 2008, ANN STAT IN PRESS; Schapire R., 2002, MSRI WORKSH NONL EST; Shen XT, 2003, J AM STAT ASSOC, V98, P724, DOI 10.1198/016214503000000639; TIBSHIRANI R, 1987, J AM STAT ASSOC, V82, P559, DOI 10.2307/2289465; WEDDERBURN RWM, 1974, BIOMETRIKA, V61, P439, DOI 10.1093/biomet/61.3.439; ZHANG CM, 2007, 1127 U WISC DEP STAT	25	3	3	1	2	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0319-5724			CAN J STAT	Can. J. Stat.-Rev. Can. Stat.	MAR	2009	37	1					119	139				21	Statistics & Probability	Mathematics	432DV	WOS:000265114600009		
J	Wheeler, DC				Wheeler, David C.			Simultaneous coefficient penalization and model selection in geographically weighted regression: the geographically weighted lasso	ENVIRONMENT AND PLANNING A			English	Article							LEAST ANGLE REGRESSION; TOOLS	In the field of spatial analysis, the interest of some researchers in modeling relationships between variables locally has led to the development of regression models with spatially varying coefficients. One such model that has been widely applied is geographically weighted regression (GWR). In the application of GWR, marginal inference on the spatial pattern of regression coefficients is often of interest, as is, less typically, prediction and estimation of the response variable. Empirical research and simulation studies have demonstrated that local correlation in explanatory variables can lead to estimated regression coefficients in GWR that are strongly correlated and, hence, problematic for inference on relationships between variables. The author introduces a penalized form of GWR, called the 'geographically weighted lasso' (GWL) which adds a constraint on the magnitude of the estimated regression coefficients to limit the effects of explanatory-variable correlation. The GWL also performs local model selection by potentially shrinking some of the estimated regression coefficients to zero in some locations of the study area. Two versions of the GWL are introduced: one designed to improve prediction of the response variable, and one more oriented toward constraining regression coefficients for inference. The results of applying the GWL to simulated and real datasets show that this method stabilizes regression coefficients in the presence of collinearity and produces lower prediction and estimation error of the response variable than does GWR and another constrained version of GWR-geographically weighted ridge regression.	Emory Univ, Dept Biostat, Rollins Sch Publ Hlth, Atlanta, GA 30322 USA	Wheeler, DC (reprint author), Emory Univ, Dept Biostat, Rollins Sch Publ Hlth, 1518 Clifton Rd,NE 3rd Floor, Atlanta, GA 30322 USA.	dcwheel@sph.emory.edu					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Brunsdon C, 1996, GEOGR ANAL, V28, P281; Efron B, 2004, ANN STAT, V32, P407; Anselin L., 1988, SPATIAL ECONOMETRICS; Anselin L., 2004, ADV SPATIAL ECONOMET, P241; Banerjee S., 2004, HIERARCHICAL MODELIN; Belsley D.A., 1991, CONDITIONING DIAGNOS; Burnham K. P., 2004, MODEL SELECTION MULT; CASETTI E, 1972, GEOGR ANAL, V4, P81; Congdon P., 2003, J GEOGRAPHICAL SYSTE, V5, P161, DOI 10.1007/s10109-003-0099-7; Efron B, 2004, ANN STAT, V32, P494; Farber S, 2007, J GEOGR SYST, V9, P371, DOI 10.1007/s10109-007-0051-3; Fotheringham AS., 2002, GEOGRAPHICALLY WEIGH; Gelfand AE, 2003, J AM STAT ASSOC, V98, P387, DOI 10.1198/016214503000170; Grandvalet Y., 1998, ICANN 98, V1, P201; Hastie T., 2001, ELEMENTS STAT LEARNI; Loader C., 1999, LOCAL REGRESSION LIK; Martinez A. R., 2002, COMPUTATIONAL STAT H; Neter J., 1996, APPL LINEAR REGRESSI; Paez A, 2002, ENVIRON PLANN A, V34, P733, DOI 10.1068/a34110; Tiefeldsdorf M, 2005, J GEOGRAPHICAL SYSTE, V7, P161, DOI DOI 10.1007/S10109-005-0155-6; Waller LA, 2007, STOCH ENV RES RISK A, V21, P573, DOI 10.1007/s00477-007-0139-9; WHEELER D, 2006, THESIS OHIO STATE U; Wheeler DC, 2007, ENVIRON PLANN A, V39, P2464, DOI 10.1068/a38325; Wheeler DC, 2007, J GEOGR SYST, V9, P145, DOI 10.1007/s10109-006-0040-y	27	28	31	4	16	PION LTD	LONDON	207 BRONDESBURY PARK, LONDON NW2 5JN, ENGLAND	0308-518X			ENVIRON PLANN A	Environ. Plan. A	MAR	2009	41	3					722	742		10.1068/a40256		21	Environmental Studies; Geography	Environmental Sciences & Ecology; Geography	426UZ	WOS:000264734900014		
J	Yi, NJ; Banerjee, S				Yi, Nengjun; Banerjee, Samprit			Hierarchical Generalized Linear Models for Multiple Quantitative Trait Locus Mapping	GENETICS			English	Article							EXPERIMENTAL CROSSES; BAYESIAN MODEL; SELECTION APPROACH; ENTIRE GENOME; REGRESSION; MARKERS; QTL; LASSO; FRAMEWORK; BARLEY	We develop hierarchical generalized linear models and computationally efficient algorithms for genomewide analysis of quantitative trait loci (QTL) for various types of phenotypes ill experimental crosses. The proposed models can fit it large number of effects, including covariates, main effects of numerous loci, and gene-gene (epistasis) and gene-environment. (G X E) interactions. The key to the approach is the use of continuous prior distribution oil coefficients that favors sparseness ill the filled model and facilitates computation. We develop it fast expectation-maximization (EM) algorithm to fit models by estimating posterior modes of coefficients. We incorporate our algorithm into the iteratively weighted least squares For classical generalized linear models as implemented ill the package R. We propose a model search strategy, to build a parsimonious model. Our method takes advantage of the special correlation structure in QTL (lata. Simulation studies demonstrate reasonable power to detect true effects, while controlling the rate of false positives. We illustrate with three real data sets and compare our method to existing methods for multilple-QTL. mapping. Our method has been implemented in our freely available package R/qtlbim (www.qtlbim.org), providing a valuable addition to our previous Markov chain Monte Carlo (MCMC) approach.	[Yi, Nengjun] Univ Alabama, Dept Biostat, Sect Stat Genet, Birmingham, AL 35294 USA; [Banerjee, Samprit] Cornell Univ, Weill Med Coll, Dept Publ Hlth, Div Biostat & Epidemiol, New York, NY 10021 USA	Yi, NJ (reprint author), Univ Alabama, Dept Biostat, Sect Stat Genet, Birmingham, AL 35294 USA.	nyi@ms.soph.uab.edu			National Institutes of Health [R01 GN4069430]; Clinical and Transnational Sciences Center [UL1-RR024996]	This work wassupported by National Institutes of Health grant R01 GN4069430 to NX. and partially supported by Clinical and Transnational Sciences Center grant UL1-RR024996 to S.B.	Broman KW, 2003, BIOINFORMATICS, V19, P889, DOI 10.1093/bioinformatics/btg112; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; Kao CH, 1999, GENETICS, V152, P1203; Carlborg O, 2004, NAT REV GENET, V5, P618, DOI 10.1038/nrg1407; Efron B, 2004, ANN STAT, V32, P407; Meuwissen THE, 2001, GENETICS, V157, P1819; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Baierl A, 2006, GENETICS, V173, P1693, DOI 10.1534/genetics.105.048108; BAO K, 2004, BIOINFORMATICS, V20, P3423; Bogdan M, 2004, GENETICS, V167, P989, DOI 10.1534/genetics.103.021683; Boyartchuk VL, 2001, NAT GENET, V27, P259, DOI 10.1038/85812; Broman KW, 2002, J R STAT SOC B, V64, P641, DOI 10.1111/1467-9868.00354; Broman KW, 2003, GENETICS, V163, P1169; Diao GQ, 2004, GENETICS, V168, P1689, DOI 10.1534/genetics.103.023903; Figueiredo MAT, 2003, IEEE T PATTERN ANAL, V25, P1150, DOI 10.1109/TPAMI.2003.1227989; Gelman A., 2003, BAYESIAN DATA ANAL; GELMAN A, 2008, ANN APPL ST IN PRESS; GRIFFIN JE, 2007, BAYESIAN ADAPTIVE LA; HALEY CS, 1992, HEREDITY, V69, P315; Jiang CJ, 1997, GENETICA, V101, P47, DOI 10.1023/A:1018394410659; Jin CF, 2007, J AM STAT ASSOC, V102, P56, DOI 10.1198/016214506000000834; KHVERI H, 2003, I MATH STAT LECT NOT, V40, P127; McCullagh P., 1989, GEN LINEAR MODELS; R Development Core Team, 2006, R LANG ENV STAT COMP; ter Braak CJF, 2005, GENETICS, V170, P1435, DOI 10.1534/genetics.105.040469; Tinker NA, 1996, CROP SCI, V36, P1053; Xu SZ, 2007, GENETICS, V175, P1955, DOI 10.1534/genetics.106.066571; Xu SZ, 2007, BIOMETRICS, V63, P513, DOI 10.1111/j.1541-0420.2006.00711.x; Xu SZ, 2003, GENETICS, V163, P789; Yandell BS, 2007, BIOINFORMATICS, V23, P641, DOI 10.1093/bioinformatics/btm011; Yi N, 2008, HEREDITY, V100, P240, DOI 10.1038/sj.hdy.6801074; Yi NJ, 2007, GENETICS, V176, P1865, DOI 10.1534/genetics.107.071365; Yi NJ, 2004, GENETICS, V167, P967, DOI 10.1534/genetics.104.026286; Yi NJ, 2007, GENETICS, V176, P1855, DOI 10.1534/genetics.107.071142; Yi NJ, 2005, GENETICS, V170, P1333, DOI 10.1534/genetics.104.040386; Yi NJ, 2008, GENETICS, V179, P1045, DOI 10.1534/genetics.107.085589; Yi NJ, 2006, GENET RES, V87, P45, DOI 10.1017/S0016672306007944; Zeng ZB, 2005, GENETICS, V169, P1711, DOI 10.1534/genetics.104.035857; Zhang YM, 2005, HEREDITY, V95, P96, DOI 10.1038/sj.hdy.6800702	40	43	44	0	8	GENETICS	BALTIMORE	428 EAST PRESTON ST, BALTIMORE, MD 21202 USA	0016-6731			GENETICS	Genetics	MAR	2009	181	3					1101	1113		10.1534/genetics.108.099556		13	Genetics & Heredity	Genetics & Heredity	499IU	WOS:000270213500027	19139143	
J	Loris, I				Loris, Ignace			On the performance of algorithms for the minimization of l(1)-penalized functionals	INVERSE PROBLEMS			English	Article							LINEAR INVERSE PROBLEMS; REGRESSION; SELECTION; RECOVERY	The problem of assessing the performance of algorithms used for the minimization of an l(1)-penalized least-squares functional, for a range of penalty parameters, is investigated. A criterion that uses the idea of 'approximation isochrones' is introduced. Five different iterative minimization algorithms are tested and compared, as well as two warm-start strategies. Both well-conditioned and ill-conditioned problems are used in the comparison, and the contrast between these two categories is highlighted.	Vrije Univ Brussels, Dept Math, B-1050 Brussels, Belgium	Loris, I (reprint author), Vrije Univ Brussels, Dept Math, Pleinlaan 2, B-1050 Brussels, Belgium.	igloris@vub.ac.be			VUB [GOA-62]; FWO-Vlaanderen [G.0564.09N]	Part of this work was done as a post-doctoral research fellow for the F. W. O-Vlaanderen (Belgium) at the Vrije Universiteit Brussel and part of it was done as 'Francqui Foundation intercommunity post-doctoral researcher' at Departement de Mathematique, Universite Libre de Bruxelles. Discussions with Ingrid Daubechies and Christine De Mol are gratefully acknowledged. The author acknowledges the financial support of the VUB through the GOA-62 grant, and of the FWO-Vlaanderen through grant G.0564.09N, and wishes to thank the referees for their constructive comments.	Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Combettes PL, 1997, IEEE T IMAGE PROCESS, V6, P493, DOI 10.1109/83.563316; Efron B, 2004, ANN STAT, V32, P407; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; BECK A, 2009, SIAM J IMAG IN PRESS; Daubechies I, 2008, J FOURIER ANAL APPL, V14, P764, DOI 10.1007/s00041-008-9039-8; Donoho D., 2007, SPARSE LAB; FIGUEIREDO MAT, 2008, IEEE J SEL TOP SIGNA, V1, P586; Hale E. T., 2007, FIXED POINT CONTINUA; Loris I, 2008, COMPUT PHYS COMMUN, V179, P895, DOI 10.1016/j.cpc.2008.07.010; Loris I, 2007, GEOPHYS J INT, V170, P359, DOI 10.1111/j.1365-246X.2007.03409.x; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; SJOSTRAND K, 2005, MATLAB IMPLEMANTATIO	17	28	29	2	3	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0266-5611			INVERSE PROBL	Inverse Probl.	MAR	2009	25	3							035008	10.1088/0266-5611/25/3/035008		16	Mathematics, Applied; Physics, Mathematical	Mathematics; Physics	403DC	WOS:000263061500008		
J	Leng, CL; Wang, HS				Leng, Chenlei; Wang, Hansheng			On General Adaptive Sparse Principal Component Analysis	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						Adaptive lasso; BIC; GAS-PCA; LARS; Lasso; SAS-PCA; S-PCA	REGRESSION SHRINKAGE; VARIABLE SELECTION; ORACLE PROPERTIES; LASSO	The method of sparse principal component analysis (S-PCA) proposed by Zou, Hastie, and Tibshirani (2006) is an attractive approach to obtain sparse loadings in principal component analysis (PCA). S-PCA was motivated by reformulating PCA as a least-squares problem so that a lasso penalty on the loading coefficients can be applied. In this article, we propose new estimates to improve S-PCA in the following two aspects. First, we propose a method of simple adaptive sparse principal component analysis (SAS-PCA), which uses the adaptive lasso penalty (Zou 2006; Wang, Li, and Jiang 2007) instead of the lasso penalty in S-PCA. Second, we replace the least-squares objective function in S-PCA by a general least-squares objective function. This formulation allows us to study many related sparse PCA estimators under a unified theoretical framework and leads to the method of general adaptive sparse principal component analysis (GAS-PCA). Compared with SAS-PCA, GAS-PCA enjoys much improved finite sample performance. In addition, we show that, when a BIC-type criterion is used for selecting the tuning parameters, the resulting estimates are consistent in variable selection. Numerical studies are conducted to compare the finite sample performance of various competing methods. Datasets and computer code are available in the online supplements.	[Leng, Chenlei] Natl Univ Singapore, Dept Stat & Appl Probabil, Singapore 117548, Singapore; [Wang, Hansheng] Peking Univ, Guanghua Sch Management, Beijing 100871, Peoples R China	Leng, CL (reprint author), Natl Univ Singapore, Dept Stat & Appl Probabil, Singapore 117548, Singapore.	stalc@nus.edu.sg; hansheng@gsm.pku.edu.cn			NSFC [10771006]	The authors are very grateful to the editor, the associate editor, and two referees for their careful reading and constructive comments, which have led to a substantial improvement of the manuscript. Leng's research is supported in part by NUS grants and Wang's research is supported in part by NSFC grain 10771006.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Wang HS, 2007, J BUS ECON STAT, V25, P347, DOI 10.1198/073500106000000251; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Wang H, 2007, BIOMETRIKA, V94, P553, DOI 10.1093/biomet/asm053; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; Johnson R. A., 2003, APPL MULTIVARIATE ST; Leng CL, 2006, STAT SINICA, V16, P1273; Shen H., 2007, J MULTIVARIATE ANAL, V99, P1015; Wang HS, 2007, J AM STAT ASSOC, V102, P1039, DOI 10.1198/016214507000000509; Wang HS, 2007, J ROY STAT SOC B, V69, P63; Yang YH, 2005, BIOMETRIKA, V92, P937, DOI 10.1093/biomet/92.4.937; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	15	12	14	3	10	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	MAR	2009	18	1					201	215		10.1198/jcgs.2009.0012		15	Statistics & Probability	Mathematics	477GE	WOS:000268506000012		
J	Chen, YH; Garcia, EK; Gupta, MR; Rahimi, A; Cazzanti, L				Chen, Yihua; Garcia, Eric K.; Gupta, Maya R.; Rahimi, Ali; Cazzanti, Luca			Similarity-based Classification: Concepts and Algorithms	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						similarity; dissimilarity; similarity-based learning; indefinite kernels	SUPPORT VECTOR MACHINES; PAIRWISE DATA; MAXIMUM-ENTROPY; FEATURES; REPRESENTATIONS; SELECTION; COMMON	This paper reviews and extends the field of similarity-based classification, presenting new analyses, algorithms, data sets, and a comprehensive set of experimental results for a rich collection of classification problems. Specifically, the generalizability of using similarities as features is analyzed, design goals and methods for weighting nearest-neighbors for similarity-based learning are proposed, and different methods for consistently converting similarities into kernels are compared. Experiments on eight real data sets compare eight approaches and their variants to similarity-based learning.	[Chen, Yihua; Garcia, Eric K.; Gupta, Maya R.] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; [Rahimi, Ali] Intel Res, Seattle, WA 98105 USA; [Cazzanti, Luca] Univ Washington, Appl Phys Lab, Seattle, WA 98105 USA	Chen, YH (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.	YHCHEN@U.WASHINGTON.EDU; GARCIAER@U.WASHINGTON.EDU; GUPTA@EE.WASHINGTON.EDU; ALI.RAHIMI@INTEL.COM; LUCA@APL.WASHINGTON.EDU			United States Office of Naval Research; Intel	This work was funded by the United States Office of Naval Research and Intel.	ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Liao L, 2003, J COMPUT BIOL, V10, P857, DOI 10.1089/106652703322756113; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/0033-295X.84.4.327; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; HIGHAM NJ, 1988, LINEAR ALGEBRA APPL, V103, P103, DOI 10.1016/0024-3795(88)90223-6; Asuncion A., 2007, UCI MACHINE LEARNING; Balcan MF, 2008, MACH LEARN, V72, P89, DOI 10.1007/s10994-008-5059-5; BALCAN MF, 2008, P ANN C LEARN THEOR; Bartlett P. L., 2002, J MACHINE LEARNING R, V3, P463; Borg I., 2005, MODERN MULTIDIMENSIO; Cazzanti L., 2007, P INT C MACH LEARN; CAZZANTI L, 2007, THESIS U WASHINGTON; Cazzanti L, 2008, PATTERN RECOGN, V41, P2289, DOI 10.1016/j.patcog.2008.01.005; Chen J., 2008, P INT C MACH LEARN; Cristianini N., 2000, INTRO SUPPORT VECTOR; Driskell J. E., 2008, IDENTIFICATION INCOM; Duda R. O., 2001, PATTERN CLASSIFICATI; Fei-Fei L., 2004, P IEEE COMP SOC C CO; FENG S, 2007, P IEEE WORKSH STAT S; Friedlander MP, 2006, IEEE T INFORM THEORY, V52, P238, DOI 10.1109/TIT.2005.860448; GATI I, 1984, COGNITIVE PSYCHOL, V16, P341, DOI 10.1016/0010-0285(84)90013-6; Goldstone R. L., 2003, COMPREHENSIVE HDB PS, V4, P599; GOYAL N, 2008, P ACM S WEB SEARCH D; GRAEPEL T, 1998, ADV NEURAL INFORM PR; GRAEPEL T, 1999, P INT C ART NEUR NET; Grauman K, 2007, J MACH LEARN RES, V8, P725; Gupta MR, 2006, IEEE T PATTERN ANAL, V28, P766, DOI 10.1109/TPAMI.2006.101; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; Hastie T., 2001, ELEMENTS STAT LEARNI; Hochreiter S, 2006, NEURAL COMPUT, V18, P1472, DOI 10.1162/neco.2006.18.6.1472; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Knebel T, 2008, NEURAL COMPUT, V20, P271, DOI 10.1162/neco.2008.20.1.271; Laub J, 2006, PATTERN RECOGN, V39, P1815, DOI 10.1016/j.patcog.2006.04.016; Laub J, 2004, J MACH LEARN RES, V5, P801; LIPMAN DJ, 1985, SCIENCE, V227, P1435, DOI 10.1126/science.2983426; Lowe D. G., 2004, INT J COMPUT VISION, V60; LUSS R, 2007, ADV NEURAL INFORM PR; ONG C, 2004, P INT C MACH LEARN; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Pekalska E., 2001, J MACHINE LEARNING R, V2, P175; Philips S., 2006, P IEEE OCEANS C; Platt J. C., 1998, ADV NEURAL INFORM PR; Rifkin R., 2002, THESIS MIT; Roth V, 2003, IEEE T PATTERN ANAL, V25, P1540, DOI 10.1109/TPAMI.2003.1251147; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Scholkopf B., 2002, LEARNING KERNELS SUP; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tien Lin H., 2003, STUDY SIGMOID KERNEL; TVERSKY A, 1982, PSYCHOL REV, V89, P123, DOI 10.1037/0033-295X.89.2.123; GATI I, 1982, J EXP PSYCHOL HUMAN, V8, P325, DOI 10.1037//0096-1523.8.2.325; WANG L, 2007, P INT C MACH LEARN; Wu G., 2005, ANAL TRANSFORMATION; ZHANG H, 2006, P IEEE COMP SOC C CO; Zhu X., 2005, THESIS CARNEGIE MELL	60	76	76	1	2	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAR	2009	10						747	776				30	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	507BI	WOS:000270824500009		
J	Langford, J; Li, LH; Zhang, T				Langford, John; Li, Lihong; Zhang, Tong			Sparse Online Learning via Truncated Gradient	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						truncated gradient; stochastic gradient descent; online learning; sparsity; regularization; Lasso	LINEAR FUNCTIONS; DESCENT	We propose a general method called truncated gradient to induce sparsity in the weights of online-learning algorithms with convex loss functions. This method has several essential properties: 1. The degree of sparsity is continuous-a parameter controls the rate of sparsification from no sparsification to total sparsification. 2. The approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular L(1)-regularization method in the batch setting. We prove that small rates of sparsification result in only small additional regret with respect to typical online-learning guarantees. 3. The approach works well empirically. We apply the approach to several data sets and find for data sets with large numbers of features, substantial sparsity is discoverable.	[Langford, John] Yahoo Res, New York, NY USA; [Li, Lihong] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ USA; [Zhang, Tong] Rutgers State Univ, Dept Stat, Piscataway, NJ USA	Langford, J (reprint author), Yahoo Res, New York, NY USA.	JL@YAHOO-INC.COM; LIHONG@CS.RUTGERS.EDU; TONGZ@RCI.RUTGERS.EDU			NSF [DMS-0706805]	Partially supported by NSF grant DMS-0706805.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Asuncion A., 2007, UCI MACHINE LEARNING; Balakrishnan S, 2008, J MACH LEARN RES, V9, P313; Carpenter B, 2008, LAZY SPARSE STOCHAST, P1; CesaBianchi N, 1996, IEEE T NEURAL NETWOR, V7, P604, DOI 10.1109/72.501719; CHU CT, 2008, ADV NEURAL INFORM PR, V20; Dekel O., 2005, ADV NEURAL INFORM PR, V18, P259; DUCHI J, 2008, ONLINE BATCH L UNPUB; Duchi J., 2008, P 25 INT C MACH LEAR, P272, DOI DOI 10.1145/1390156.1390191; Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612; LANGFORD J, 2007, VOWPAL WABBIT FAST O; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; LITTLESTONE N, 1995, COMPUT COMPLEX, V5, P1, DOI 10.1007/BF01277953; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR; Sjostrand K., 2005, MATLAB IMPLEMENTATIO; Zhang T, 2004, P 21 INT C MACH LEAR, P919; Zinkevich M., 2003, P 20 INT C MACH LEAR, P928	19	33	42	2	3	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAR	2009	10						777	801				25	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	507BI	WOS:000270824500010		
J	Tseng, P; Yun, S				Tseng, P.; Yun, S.			Block-Coordinate Gradient Descent Method for Linearly Constrained Nonsmooth Separable Optimization	JOURNAL OF OPTIMIZATION THEORY AND APPLICATIONS			English	Article						Nonsmooth optimization; Linear constraints; Support vector machines; Bilevel optimization; l(1)-regularization; Coordinate gradient descent; Global convergence; Linear convergence rate; Complexity bound	SUPPORT VECTOR MACHINES; CONTINUOUSLY DIFFERENTIABLE FUNCTION; TIME DECOMPOSITION ALGORITHMS; CONVEX FUNCTION; MINIMIZATION; CONVERGENCE; REGRESSION; SHRINKAGE; ROBUST; LASSO	We consider the problem of minimizing the weighted sum of a smooth function f and a convex function P of n real variables subject to m linear equality constraints. We propose a block-coordinate gradient descent method for solving this problem, with the coordinate block chosen by a Gauss-Southwell-q rule based on sufficient predicted descent. We establish global convergence to first-order stationarity for this method and, under a local error bound assumption, linear rate of convergence. If f is convex with Lipschitz continuous gradient, then the method terminates in O(n (2)/epsilon) iterations with an epsilon-optimal solution. If P is separable, then the Gauss-Southwell-q rule is implementable in O(n) operations when m=1 and in O(n (2)) operations when m > 1. In the special case of support vector machines training, for which f is convex quadratic, P is separable, and m=1, this complexity bound is comparable to the best known bound for decomposition methods. If f is convex, then, by gradually reducing the weight on P to zero, the method can be adapted to solve the bilevel problem of minimizing P over the set of minima of f+delta (X) , where X denotes the closure of the feasible set. This has application in the least 1-norm solution of maximum-likelihood estimation.	[Tseng, P.] Univ Washington, Dept Math, Seattle, WA 98195 USA; [Yun, S.] Natl Univ Singapore, Dept Math, Singapore 117548, Singapore	Tseng, P (reprint author), Univ Washington, Dept Math, Seattle, WA 98195 USA.	tseng@math.washington.edu; matys@nus.edu.sg			National Science Foundation [DMS-0511283]	This research was supported by the National Science Foundation, Grant No. DMS-0511283.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Chen PH, 2006, IEEE T NEURAL NETWOR, V17, P893, DOI 10.1109/TNN.2006.875973; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; [Anonymous], 2001, J OPTIMIZ THEORY APP, DOI DOI 10.1023/A:1017501703105; Meier L, 2008, J R STAT SOC B, V70, P53; LUO ZQ, 1992, SIAM J CONTROL OPTIM, V30, P408, DOI 10.1137/0330025; Tseng P, 2009, MATH PROGRAM, V117, P387, DOI 10.1007/s10107-007-0170-0; Grippo L, 2000, OPER RES LETT, V26, P127, DOI 10.1016/S0167-6377(99)00074-7; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Berman P., 1993, COMPLEXITY NUMERICAL, P33; Bertsekas D., 1999, NONLINEAR PROGRAMMIN; BRUCKER P, 1984, OPER RES LETT, V3, P163, DOI 10.1016/0167-6377(84)90010-5; Fletcher R., 1987, PRACTICAL METHODS OP; Friedlander MP, 2008, SIAM J OPTIMIZ, V18, P1326, DOI 10.1137/060675320; FUKUSHIMA M, 1981, INT J SYST SCI, V12, P989, DOI 10.1080/00207728108963798; FUKUSHIMA M, 1990, MATH PROGRAM, V49, P231, DOI 10.1007/BF01588789; Gill P. E., 1981, PRACTICAL OPTIMIZATI; Hush D, 2003, MACH LEARN, V51, P51, DOI 10.1023/A:1021877911972; Hush D, 2006, J MACH LEARN RES, V7, P733; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kiwiel KC, 2007, J OPTIMIZ THEORY APP, V134, P549, DOI 10.1007/s10957-007-9259-0; KIWIEL KC, 1986, J OPTIMIZ THEORY APP, V48, P437, DOI 10.1007/BF00940570; LIN CJ, 2007, J OPTIM THE IN PRESS; List N, 2005, LECT NOTES COMPUT SC, V3559, P308, DOI 10.1007/11503415_21; Luo Zhi-Quan, 1993, ANN OPER RES, V46, P157, DOI 10.1007/BF02096261; LUO ZQ, 1993, MATH OPER RES, V18, P846, DOI 10.1287/moor.18.4.846; Mangasarian OL, 1999, IEEE T NEURAL NETWOR, V10, P1032, DOI 10.1109/72.788643; MEGIDDO N, 1993, OPER RES LETT, V13, P203, DOI 10.1016/0167-6377(93)90041-E; MINE H, 1981, J OPTIMIZ THEORY APP, V33, P9, DOI 10.1007/BF00935173; NOCEDAL J., 1999, NUMERICAL OPTIMIZATI; Ortega JM, 2000, ITERATIVE SOLUTION N; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rockafellar R. T., 1998, VARIATIONAL ANAL; ROCKAFELLAR R. T., 1984, NETWORK FLOWS MONOTR; Rockafellar R.T., 1970, CONVEX ANAL; ROCKAFELLAR RT, 1967, COMBINATORIAL MATH I, P104; Sardy S, 2004, J COMPUT GRAPH STAT, V13, P283, DOI 10.1198/1061860043434; TSENG P, 2007, COMPUT OPTI IN PRESS; Tseng P, 2001, MATH OPER RES, V26, P221, DOI 10.1287/moor.26.2.221.10557; Zenios S., 1997, PARALLEL OPTIMIZATIO	42	25	29	2	7	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0022-3239			J OPTIMIZ THEORY APP	J. Optim. Theory Appl.	MAR	2009	140	3					513	535		10.1007/s10957-008-9458-3		23	Operations Research & Management Science; Mathematics, Applied	Operations Research & Management Science; Mathematics	408FE	WOS:000263420100009		
J	Wang, HS				Wang, Hansheng			Rank reducible varying coefficient model	JOURNAL OF STATISTICAL PLANNING AND INFERENCE			English	Article						BIC; Dimension reduction; Semiparametric estimation; Rank reducible varying coefficient model; Varying coefficient model	DIMENSION REDUCTION; LINEAR-MODELS; EFFICIENT ESTIMATION; VARIABLE SELECTION; ORACLE PROPERTIES; LONGITUDINAL DATA; REGRESSION; INFERENCES; LIKELIHOOD; LASSO	We propose in this article a novel dimension reduction method for varying coefficient models. The proposed method explores the rank reducible structure of those varying coefficients, hence, can do dimension reduction and serniparametric estimation, simultaneously. As a result, the new method not only improves estimation accuracy but also facilitates practical interpretation. To determine the structure dimension, a consistent BIC criterion is developed. Numerical experiments are also presented. (c) 2008 Elsevier B.V. All rights reserved.	Peking Univ, Beijing 100871, Peoples R China	Wang, HS (reprint author), Peking Univ, Beijing 100871, Peoples R China.	hansheng@gsm.pku.edu.cn					Li B, 2005, ANN STAT, V33, P1580, DOI 10.1214/009053605000000192; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Huang JHZ, 2002, BIOMETRIKA, V89, P111, DOI 10.1093/biomet/89.1.111; Fan JQ, 2000, J ROY STAT SOC B, V62, P303, DOI 10.1111/1467-9868.00233; Fan JQ, 2005, BERNOULLI, V11, P1031, DOI 10.3150/bj/1137421639; Fan JQ, 2000, SCAND J STAT, V27, P715, DOI 10.1111/1467-9469.00218; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; HASTIE T, 1993, J ROY STAT SOC B MET, V55, P757; Cai ZW, 2000, J AM STAT ASSOC, V95, P888, DOI 10.2307/2669472; Fan JQ, 1999, ANN STAT, V27, P1491; Fan JQ, 2003, J ROY STAT SOC B, V65, P57, DOI 10.1111/1467-9868.00372; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; KONG E, 2006, BIOMETRIKA, V94, P217; Li LX, 2007, BIOMETRIKA, V94, P615, DOI 10.1093/biomet/asm043; LI R, 2006, NONPARAMETRIC ECONOM; Li R, 2008, ANN STAT, V36, P261, DOI 10.1214/009053607000000604; MACK YP, 1982, Z WAHRSCHEINLICHKEIT, V61, P405, DOI 10.1007/BF00539840; Xia YC, 2004, BIOMETRIKA, V91, P661, DOI 10.1093/biomet/91.3.661; Xia YC, 2006, ECONOMET THEOR, V22, P1112, DOI 10.1017/S0266466606060531; Xia YC, 1999, J AM STAT ASSOC, V94, P1275, DOI 10.2307/2669941; Xia YC, 2007, ANN STAT, V35, P2654, DOI 10.1214/009053607000000352; Xia YC, 2002, J ROY STAT SOC B, V64, P363, DOI 10.1111/1467-9868.03411; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	25	0	0	2	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3758			J STAT PLAN INFER	J. Stat. Plan. Infer.	MAR 1	2009	139	3					999	1011		10.1016/j.jspi.2008.06.004		13	Statistics & Probability	Mathematics	389AE	WOS:000262061300025		
J	Rothman, AJ; Levina, E; Zhu, J				Rothman, Adam J.; Levina, Elizaveta; Zhu, Ji			Generalized Thresholding of Large Covariance Matrices	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						Covariance; High-dimensional data; Regularization; Thresholding; Sparsity	NONCONCAVE PENALIZED LIKELIHOOD; PRINCIPAL COMPONENTS; WAVELET SHRINKAGE; ORACLE PROPERTIES; SELECTION; LASSO; REGULARIZATION	We propose a new class of generalized thresholding operators that combine thresholding with shrinkage, and Study generalized thresholding of the sample covariance matrix in high dimensions. Generalized thresholding of the covariance matrix has good theoretical properties and carries almost no computational burden. We obtain in explicit convergence rate in the operator norm that shows the tradeoff between the sparsity of the true model, dimension, and the sample size, and shows that generalized thresholding is consistent over a large class of models as long as the dimension p and the sample size it satisfy log p/n -> 0. In addition, we show that generalized thresholding has the "sparsistency" property, meaning it estimates true zeros a, zeros with probability tending to 1, and, under an additional mild condition, is sign consistent for nonzero elements. We show that generalized thresholding covers, as special cases, hard and soft thresholding, smoothly clipped absolute deviation, and adaptive lasso, and compare different types of generalized thresholding in a simulation study and in an example of gene clustering from a microarray experiment with tumor tissues.	[Rothman, Adam J.; Levina, Elizaveta; Zhu, Ji] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA	Rothman, AJ (reprint author), Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA.	ajrothma@umich.edu; elevina@umich.edu; jizhu@umich.edu			National Science Foundation [DMS-0505424, DMS-0805798, DMS-0505432, DMS-0705532]	Elizaveta Levina's research is supported in part by grants from the National Science Foundation (NSF, DMS-0505424 and DMS-0805798). Ji Zhu's research is supported in part by grants from the NSF (DMS-0505432and DMS-0705532). The authors thank all Associate Editor and two referees for helpful suggestions	BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Antoniadis A, 2001, J AM STAT ASSOC, V96, P939, DOI 10.1198/016214501753208942; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Bickel PJ, 2008, ANN STAT, V36, P199, DOI 10.1214/009053607000000758; Rothman AJ, 2008, ELECTRON J STAT, V2, P494, DOI 10.1214/08-EJS176; Bickel PJ, 2008, ANN STAT, V36, P2577, DOI 10.1214/08-AOS600; Bickel PJ, 2004, BERNOULLI, V10, P989, DOI 10.3150/bj/1106314847; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Johnstone IM, 2001, ANN STAT, V29, P295, DOI 10.1214/aos/1009210544; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; D'Aspremont A, 2008, SIAM J MATRIX ANAL A, V30, P56, DOI 10.1137/060670985; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; El Karoui N, 2008, ANN STAT, V36, P2717, DOI 10.1214/07-AOS559; Fan J., 1997, J ITALIAN STAT ASS, V6, P131; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2008, J R STAT SOC B, V70, P679, DOI 10.1111/j.1467-9868.2008.00654.x; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; Furrer R, 2007, J MULTIVARIATE ANAL, V98, P227, DOI 10.1016/j.jmva.2006.08.003; Golub G., 1989, MATRIX COMPUTATIONS; Hastie T, 2000, GENOME BIOL, V1, P1, DOI DOI 10.1186/GB-2000-1-2-RESEARCH0003; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; KRZANOWSKI WJ, 1979, J AM STAT ASSOC, V74, P703, DOI 10.2307/2286995; LAM C, 2008, SPARSISTENCY RATES C; Levina E, 2008, ANN APPL STAT, V2, P245, DOI 10.1214/07-AOAS139; WAGAMAN AS, 2007, 472 U MICH; Wu WB, 2003, BIOMETRIKA, V90, P831, DOI 10.1093/biomet/90.4.831	30	62	62	2	8	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	MAR	2009	104	485					177	186		10.1198/jasa.2009.0101		10	Statistics & Probability	Mathematics	425PI	WOS:000264649200019		
J	Chen, YH; Chatterjee, N; Carroll, RJ				Chen, Yi-Hau; Chatterjee, Nilanjan; Carroll, Raymond J.			Shrinkage Estimators for Robust and Efficient Inference in Haplotype-Based Case-Control Studies	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						Empirical Bayes; Genetic epidemiology; LASSO (Least Absolute Shrinkage and Selection Operator); Model averaging; Model robustness; Model selection	GENE-ENVIRONMENT INDEPENDENCE; REGRESSION-MODEL; LINKAGE PHASE; GENOTYPE DATA; LIKELIHOOD; SELECTION; ASSOCIATIONS; TRAITS; TESTS; RISK	Case-control association studies often aim to investigate the role of genes and gene-environment interactions in terms of the underlying haplotypes (i.e., the combinations of alleles at multiple genetic loci along chromosomal regions). The goal of this article is to develop robust but efficient approaches to the estimation of disease odds-ratio parameters associated with haplotypes and haplotype-environment interactions. We consider "shrinkage" estimation techniques that can adaptively relax the model assumptions of Hardy-Weinberg-Equilibrium and gene-environment independence required by recently proposed efficient "retrospective" methods. Our proposal involves first development of a novel retrospective approach to the analysis of case-control data, one that is robust to the nature of the gene-environment distribution in the underlying population. Next, it involves shrinkage of the robust retrospective estimator toward a more precise, but model-dependent, retrospective estimator using novel empirical Bayes and penalized regression techniques. Methods for variance estimation are proposed based on asymptotic theories. Simulations and two data examples illustrate both the robustness and efficiency of the proposed methods.	[Chatterjee, Nilanjan] NCI, Div Canc Epidemiol & Genet, NIH, Dept Hlth & Human Serv, Rockville, MD 20852 USA; [Carroll, Raymond J.] Texas A&M Univ, Dept Stat, College Stn, TX 77843 USA		yhchen@stat.sinica.edu.tw; chattern@mail.nih.gov; carroll@stat.tamu.edu			National Science Council of ROC [95-2118-M-001-022-MY3]; National Heart Lung and Blood Institute [RO1HL091172-01]; National Cancer Institute [CA57030, CA104620]; King Abdullah University of Science and Technology (KAUST) [KUS-CI-016-04]	Chen's research was supported by the National Science Council of ROC (NSC 95-2118-M-001-022-MY3). Chatterjee's research was supported by a gene-environment initiative grant from the National Heart Lung and Blood Institute (RO1HL091172-01) and by the Intramural Research Program of the National Cancer Institute. Carroll's research was supported by grants from the National Cancer Institute (CA57030, CA104620) and by Award Number KUS-CI-016-04, made by King Abdullah University of Science and Technology (KAUST). The authors thank the editor, associate editor, and referees for their helpful comments.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Schaid DJ, 2002, AM J HUM GENET, V70, P425, DOI 10.1086/338688; Epstein MP, 2003, AM J HUM GENET, V73, P1316, DOI 10.1086/380204; Hjort NL, 2003, J AM STAT ASSOC, V98, P879, DOI 10.1198/016214503000000828; Chang-Claude J, 2002, CANCER EPIDEM BIOMAR, V11, P698; Chatterjee N, 2007, J ROY STAT SOC B, V69, P123, DOI 10.1111/j.1467-9868.2007.00580.x; Chatterjee N, 2005, BIOMETRIKA, V92, P399, DOI 10.1093/biomet/92.2.399; Claeskens G, 2007, BIOMETRIKA, V94, P249, DOI 10.1093/biomet/asm034; Clark AG, 2004, GENET EPIDEMIOL, V27, P321, DOI 10.1002/gepi.20025; Gohagan JK, 2000, CONTROL CLIN TRIALS, V21, p251S, DOI 10.1016/S0197-2456(00)00097-0; Hastie T., 2001, ELEMENTS STAT LEARNI; Lake SL, 2003, HUM HERED, V55, P56, DOI 10.1159/000071811; Lehmann E. L., 1983, THEORY POINT ESTIMAT; Li SSY, 2003, BIOSTATISTICS, V4, P513, DOI 10.1093/biostatistics/4.4.513; Lin SK, 2006, MOL DIVERS, V10, P1, DOI 10.1007/s11030-006-5684-5; Moslehi R, 2006, PHARMACOGENOMICS, V7, P819, DOI 10.2217/14622416.7.6.819; MUKHERJEE B, GENETIC EPIDEMIOLOGY; Mukherjee B, 2008, BIOMETRICS, V64, P685, DOI 10.1111/j.1541-0420.2007.00953.x; PRENTICE RL, 1979, BIOMETRIKA, V66, P403, DOI 10.1093/biomet/66.3.403; Satten GA, 2004, GENET EPIDEMIOL, V27, P192, DOI 10.1002/gepi.20020; Schaid DJ, 2004, GENET EPIDEMIOL, V27, P348, DOI 10.1002/gepi.20037; Spinka C, 2005, GENET EPIDEMIOL, V29, P108, DOI 10.1002/gepi.20085; Stram DO, 2003, HUM HERED, V55, P179, DOI 10.1159/000073202; Wallenstein S, 1998, GENET EPIDEMIOL, V15, P173, DOI 10.1002/(SICI)1098-2272(1998)15:2<173::AID-GEPI5>3.3.CO;2-8; Zhao LP, 2003, AM J HUM GENET, V72, P1231, DOI 10.1086/375140	26	27	27	2	5	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	MAR	2009	104	485					220	233		10.1198/jasa.2009.0104		14	Statistics & Probability	Mathematics	425PI	WOS:000264649200023		
J	Liang, H; Li, RZ				Liang, Hua; Li, Runze			Variable Selection for Partially Linear Models With Measurement Errors	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						Errors-in-variable; Error-free; Error-prone; Local linear regression; Quantile regression; smoothly clipped absolute deviation	QUANTILE REGRESSION; ESTIMATORS; LIKELIHOOD	This article focuses on variable selection for partially linear models when the covariates are measured with additive errors. We propose two classes of variable selection procedures, penalized least squares and penalized quantile regression, using the nonconvex penalized principle. The first procedure corrects the bias in the loss function caused by the measurement error by applying the so-called correction-for-attenuation approach, whereas the second procedure corrects the bias by using orthogonal regression. The sampling properties for the two procedures are investigated. The rate of convergence and the asymptotic normality of the resulting estimates are established. We further demonstrate that, with proper choices of the penalty functions and the regularization parameter, the resulting estimates perform asymptotically as well as an oracle property. Choice of smoothing parameters is also discussed. Finite sample performance of the proposed variable selection procedures is assessed by Monte Carlo simulation studies. We further illustrate the proposed procedures by an application.	[Liang, Hua] Univ Rochester, Dept Biostat & Computat Biol, Rochester, NY 14642 USA; [Li, Runze] Penn State Univ, Dept Stat, University Pk, PA 16802 USA; [Li, Runze] Penn State Univ, Methodol Ctr, University Pk, PA 16802 USA	Liang, H (reprint author), Univ Rochester, Dept Biostat & Computat Biol, 601 Elmwood Ave, Rochester, NY 14642 USA.	hliang@bst.rochester.-edu; rli@stat.psu.edu	Li, Runze/C-5444-2013	Li, Runze/0000-0002-0154-2202	NIH/NIAID [A162247, A159773]; NSF [DMS-0806097, DMS-034886]; National Institute on Drug Abuse (NIDA) [P50 DA10075]	Liang's research was partially supported by NIH/NIAID grants A162247 and A159773 and NSF grant DMS-0806097. Li's research was supported by a National Institute on Drug Abuse (NIDA) grant P50 DA10075 and NSF grant DMS-034886. The authors thank the editor, an associate editor, and two reviewers for their constructive comments and suggestions. They also thank John Dziak and Jeanne Holden-Wiltse for their editorial assistance. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIDA or the National Institutes of Health.	AKAIKE H, 1973, BIOMETRIKA, V60, P255, DOI 10.1093/biomet/60.2.255; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Hoeting JA, 1999, STAT SCI, V14, P382; Raftery AE, 1997, J AM STAT ASSOC, V92, P179, DOI 10.2307/2291462; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Wang H, 2007, BIOMETRIKA, V94, P553, DOI 10.1093/biomet/asm053; MADANSKY A, 1959, J AM STAT ASSOC, V54, P173, DOI 10.2307/2282145; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Fan JQ, 2008, J ROY STAT SOC B, V70, P849, DOI 10.1111/j.1467-9868.2008.00674.x; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Berger JO, 1996, J AM STAT ASSOC, V91, P109, DOI 10.2307/2291387; Bellman R.E., 1961, ADAPTIVE CONTROL PRO; Breiman L, 1996, ANN STAT, V24, P2350; Bunea F, 2004, CAN J STAT, V32, P105, DOI 10.2307/3315936; Bunea F, 2004, ANN STAT, V32, P898, DOI 10.1214/009053604000000247; Carroll R.J., 2006, MEASUREMENT ERROR NO; Carroll RJ, 1998, CAN J STAT, V26, P467, DOI 10.2307/3315770; Cheng CL, 1999, STAT REGRESSION MEAS; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; Fang K, 1990, SYMMETRIC MULTIVARIA; FOSTER DP, 1994, ANN STAT, V22, P1947, DOI 10.1214/aos/1176325766; Fuller W. A., 1987, MEASUREMENT ERROR MO; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; Glesers LJ, 1992, J AM STAT ASSOC, V87, P696, DOI 10.2307/2290207; He XM, 2000, STAT SINICA, V10, P129; He XM, 1996, ANN STAT, V24, P2608, DOI 10.1214/aos/1032181172; HOCKING RR, 1976, BIOMETRICS, V32, P1, DOI 10.2307/2529336; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; HUNTER DR, 2000, J COMPUT GRAPH STAT, V9, P60, DOI 10.2307/1390613; Jiang WX, 2007, ANN STAT, V35, P1487, DOI 10.1214/009053607000000019; Koenker R, 2005, QUANTILE REGRESSION; Li RZ, 1997, J COMPUT GRAPH STAT, V6, P435, DOI 10.2307/1390745; Liang H, 2007, BIOMETRIKA, V94, P185, DOI 10.1093/biomet/asm010; LIANG H, 2008, VARIABLE SELECTION P; Liang H, 1999, ANN STAT, V27, P1519; Lindley D. V, 1947, J R STAT SOC B, VS9, P219; Ma YY, 2006, J AM STAT ASSOC, V101, P1465, DOI 10.1198/016214506000000519; Mack Y., 1982, Z WAHRSCH VERW GEBIE, V60, P405; MITCHELL TJ, 1988, J AM STAT ASSOC, V83, P1023, DOI 10.2307/2290129; NEWEY WK, 1994, ECONOMETRICA, V62, P1349, DOI 10.2307/2951752; PAN WQ, 2008, BIOMETRICS IN PRESS; Ruppert D, 1995, J AM STAT ASSOC, V90, P1257, DOI 10.2307/2291516; Wang NY, 1998, J AM STAT ASSOC, V93, P249, DOI 10.2307/2669621	45	39	48	5	13	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	0162-1459	1537-274X		J AM STAT ASSOC	J. Am. Stat. Assoc.	MAR	2009	104	485					234	248		10.1198/jasa.2009.0127		15	Statistics & Probability	Mathematics	425PI	WOS:000264649200024		
J	Fryzlewicz, P; Ombao, H				Fryzlewicz, Piotr; Ombao, Hernando			Consistent Classification of Nonstationary Time Series Using Stochastic Wavelet Representations	JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION			English	Article						Evolutionary wavelet spectrum; Nondecimated wavelet transform; Nonstationary processes; Supervised learning	LOCALLY STATIONARY-PROCESSES; DISCRIMINANT-ANALYSIS; SLEX MODEL; SPECTRA; SELECTION; LASSO	Consider the situation when we have training data containing many time series having known group membership and testing data with unknown group membership. The goals are to find timescale features (using training data) that can best separate the groups, and to use these highly discriminant features to classify test data. We propose a method for classification using a bias-corrected nondecimated wavelet transform. Wavelets are ideal for identifying highly discriminant local time and scale features. The observed signals will be treated as realizations of locally stationary wavelet processes, under which we define and rigorously estimate the evolutionary wavelet spectrum (timescale decomposition of variance). The evolutionary wavelet spectrum, which contains the second-moment information on the signals, is used as the classification signature. For each test time series, we compute the empirical wavelet spectrum and its divergence from the wavelet spectrum of each group. The test time series is then assigned to the group to which it is the least dissimilar. Under the locally stationary wavelet framework, we rigorously demonstrate that the classification procedure is consistent (i.e., misclassification probability goes to zero at the rate that is inversely proportional to divergence between the evolutionary wavelet spectra). The method is illustrated using,seismic signals (earthquake vs. explosion events) and is demonstrated to work very well in simulation studies.	[Fryzlewicz, Piotr] Univ Bristol, Dept Math, Bristol BS8 1TW, Avon, England; [Ombao, Hernando] Brown Univ, Ctr Stat Sci, Providence, RI 02909 USA	Fryzlewicz, P (reprint author), Univ Bristol, Dept Math, Bristol BS8 1TW, Avon, England.	p.z.fryzlewicz@bristol.ac.uk; ombao@stat.brown.edu					Shumway RH, 2003, STAT PROBABIL LETT, V63, P307, DOI 10.1016/S0167-7152(03)00095-6; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Ombao HC, 2001, J AM STAT ASSOC, V96, P543, DOI 10.1198/016214501753168244; Ombao H, 2002, ANN I STAT MATH, V54, P171, DOI 10.1023/A:1016130108440; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Fryzlewicz P, 2003, ANN I STAT MATH, V55, P737, DOI 10.1007/BF02523391; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Nason GP, 2000, J ROY STAT SOC B, V62, P271, DOI 10.1111/1467-9868.00231; Dahlhaus R, 1997, ANN STAT, V25, P1; Fryzlewicz P, 2006, J ROY STAT SOC B, V68, P611, DOI 10.1111/j.1467-9868.2006.00558.x; Biau G, 2005, IEEE T INFORM THEORY, V51, P2163, DOI 10.1109/TIT.2005.847705; BLANDFORD R, 1993, AFTACTR93044 HQ PATR; Chandler G, 2006, J AM STAT ASSOC, V101, P240, DOI 10.1198/016214505000000899; Dahlhaus R, 1996, STOCH PROC APPL, V62, P139, DOI 10.1016/0304-4149(95)00090-9; Fryzlewicz P, 2007, J AM STAT ASSOC, V102, P1318, DOI 10.1198/016214507000000860; Huang HY, 2004, J AM STAT ASSOC, V99, P763, DOI 10.1198/016214504000001105; Kakizawa Y, 1998, J AM STAT ASSOC, V93, P328, DOI 10.2307/2669629; Mallat S, 1998, ANN STAT, V26, P1; Meyer FG, 2003, IEEE T MED IMAGING, V22, P933, DOI 10.1109/TMI.2003.815869; PRIESTLEY MB, 1965, J ROY STAT SOC B, V27, P204; Sakiyama K, 2004, J MULTIVARIATE ANAL, V90, P282, DOI 10.1016/j.jmva.2003.08.002; Shumway R.H., 2006, TIME SERIES ANAL ITS; Vannucci M, 2005, CHEMOMETR INTELL LAB, V77, P139, DOI 10.1016/j.chemolab.2004.10.009; Vidakovic B, 1999, STAT MODELING WAVELE; von Sachs R., 1997, 516 STANF U DEP STAT	25	5	5	2	3	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0162-1459			J AM STAT ASSOC	J. Am. Stat. Assoc.	MAR	2009	104	485					299	312		10.1198/jasa.2009.0110		14	Statistics & Probability	Mathematics	425PI	WOS:000264649200029		
J	Baker, D; Friswell, MI				Baker, D.; Friswell, M. I.			Determinate structures for wing camber control	SMART MATERIALS & STRUCTURES			English	Article							STATIC SHAPE CONTROL; COMPLIANT MECHANISMS; MORPHING AIRCRAFT; ROTOR AIRFOIL; OPTIMIZATION; DESIGN; PERFORMANCE; PLACEMENT; SELECTION	An investigation of truss structures for the purpose of creating a continuously variable camber trailing edge device for an aircraft wing is presented. By creating structures that are both statically and kinematically determinate and then substituting truss elements for actuators, it is possible to impose structural deflection without inducing member stress. A limited number of actuators with limited strain capabilities are located within the structure in order to achieve a target deflected shape starting from an initially symmetric profile. Two objective functions are used to achieve this: a geometric objective for which the target displacement is fixed and a shape objective for which the target displacement is dependent on the surface shape of the targeted aerofoil. The proposed shape objective function is able to offer improvements over the geometric objective by removing some of the constraints applied to the targeted structure joint locations. Four methods for selecting the location of a set of actuators are compared, namely exhaustive search, a genetic algorithm, stepwise forward selection (SFS) and incremental forward selection (IFS). Both SFS and IFS are variations of regression methods for subset selection; in each case an approach has been created to allow the imposing of upper and lower bounds on the search space. It is shown that the genetic algorithm is well suited to addressing the problem of optimally locating a set of actuators; however, regression methods, particularly IFS, can provide a rapid tool suitable for addressing large selection problems.	[Baker, D.; Friswell, M. I.] Univ Bristol, Dept Aerosp Engn, Bristol BS8 1TR, Avon, England	Baker, D (reprint author), Univ Bristol, Dept Aerosp Engn, Queens Bldg, Bristol BS8 1TR, Avon, England.	m.i.friswell@bristol.ac.uk	Friswell, Michael/B-5581-2009	Friswell, Michael/0000-0003-4677-7395	European Commission; MEXT [CT-2003-002690]; EPSRC	The authors acknowledge funding from the European Commission through the Marie Curie Excellence Grant MEXT-CT-2003-002690 and from the EPSRC.	Kudva JN, 2004, J INTEL MAT SYST STR, V15, P261, DOI 10.1177/1045389X04042796; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hastie T, 2007, ELECTRON J STAT, V1, P1, DOI 10.1214/07-EJS004; Anusonti-Inthra P, 2005, AIAA J, V43, P1684, DOI 10.2514/1.1519; BARTSMITH H, 2003, P ASME INT MECH ENG; BOLONKIN A, 1999, 206586 NASA; CHEN GS, 1991, AIAA J, V29, P1327, DOI 10.2514/3.10739; Gandhi F, 2008, AIAA J, V46, P142, DOI 10.2514/1.24476; GILBERT WW, 1981, J AIRCRAFT, V18, P597, DOI 10.2514/3.57533; Goldberg D.E., 1989, GENETIC ALGORITHMS S; HAFTKA RT, 1985, COMPUT STRUCT, V20, P575, DOI 10.1016/0045-7949(85)90105-1; Hetrick J.A., 2007, 48 AIAA ASME ASCE AH; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kota S, 2003, P SOC PHOTO-OPT INS, V5054, P24, DOI 10.1117/12.483869; Kudva JN, 1999, P SOC PHOTO-OPT INS, V3674, P230, DOI 10.1117/12.351561; Lucato SLD, 2005, SMART MATER STRUCT, V14, P869, DOI 10.1088/0964-1726/14/4/047; Miller A. J., 1990, SUBSET SELECTION REG; MONNER HP, 2000, Patent No. 6164599; MUELLER D, 1997, Patent No. 6152405; PELLEGRINO S, 1986, INT J SOLIDS STRUCT, V22, P409, DOI 10.1016/0020-7683(86)90014-4; Ramrakhyani DS, 2005, J AIRCRAFT, V42, P1615; Saggere L, 1999, AIAA J, V37, P572, DOI 10.2514/2.775; Sanders B, 2003, J AIRCRAFT, V40, P94, DOI 10.2514/2.3062; Symons DD, 2005, J MECH PHYS SOLIDS, V53, P1855, DOI 10.1016/j.jmps.2005.02.011; Wadley HNG, 2003, COMPOS SCI TECHNOL, V63, P2331, DOI 10.1016/S0266-3538(03)00266-5	25	7	7	0	6	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0964-1726			SMART MATER STRUCT	Smart Mater. Struct.	MAR	2009	18	3							035014	10.1088/0964-1726/18/3/035014		13	Instruments & Instrumentation; Materials Science, Multidisciplinary	Instruments & Instrumentation; Materials Science	409GJ	WOS:000263493900014		
J	Everingham, YL; Smyth, CW; Inman-Bamber, NG				Everingham, Y. L.; Smyth, C. W.; Inman-Bamber, N. G.			Ensemble data mining approaches to forecast regional sugarcane crop production	AGRICULTURAL AND FOREST METEOROLOGY			English	Article						Predict; Forward stagewise; Simulation; Top-down; Machine learning; Lasso	SOUTHERN-OSCILLATION INDEX; MODEL; YIELD; REGRESSION; AUSTRALIA	Accurate yield forecasts are pivotal for the success of any agricultural industry that plans or sells ahead of the annual harvest. Biophysical models that integrate information about crop growing conditions can give early insight about the likely size of a crop. At a point scale, where highly detailed knowledge about environmental and management conditions are known, the performance of reputable crop modelling approaches like APSIM have been well established. However, regional growing conditions tend not to be homogenous. Heterogeneity is common in many agricultural systems, and particularly in sugarcane systems. To overcome this obstacle, hundreds of model settings ('models' for convenience) that represent different environmental and management conditions were created for Ayr, a major sugarcane growing region in north eastern Australia. Statistical data mining methods that used ensembles were used to select and assign weights to the best models. One technique, called a lasso approximation produced the best results. This procedure, produced a predictive correlation (gamma(cv) of 0.71 when predicting end of season sugarcane yields some 4 months prior to the start of the harvest season, and 10 months prior to harvest completion. This continuous forecasting methodology based on statistical ensembles represents a considerable improvement upon previous research where only categorical forecast predictions had been employed. Crown Copyright (C) 2008 Published by Elsevier B.V. All rights reserved.	[Everingham, Y. L.] James Cook Univ, Sch Math Phys & Informat Technol, Townsville, Qld 4814, Australia; [Inman-Bamber, N. G.] CSIRO Sustainable Ecosyst, Davies Lab, Townsville, Qld 4814, Australia; [Smyth, C. W.] Kyoto Univ Gokasho, Disaster Prevent Res Inst, Kyoto 6110011, Japan	Everingham, YL (reprint author), James Cook Univ, Sch Math Phys & Informat Technol, Townsville, Qld 4814, Australia.	yvette.everingham@jcu.edu.au	everingham, yvette/A-8399-2012; Cerqueira, Leandro/D-4484-2012; 	Everingham, Yvette/0000-0002-2583-4365			Jones JW, 2003, EUR J AGRON, V18, P235, DOI 10.1016/S1161-0301(02)00107-7; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Keating BA, 1999, FIELD CROP RES, V61, P253, DOI 10.1016/S0378-4290(98)00167-1; Bastiaanssen WGM, 2003, AGR ECOSYST ENVIRON, V94, P321, DOI 10.1016/S0167-8809(02)00034-8; Efron B, 2004, ANN STAT, V32, P407; SHORTER R, 1991, EXP AGR, V27, P155, DOI 10.1017/S0014479700018810; Bezuidenhout CN, 2007, AGR SYST, V92, P39, DOI 10.1016/j.agsy.2006.03.002; Bezuidenhout C. N., 2005, Climate Research, V30, P239; Doblas-Reyes FJ, 2006, CLIMATE RES, V33, P19, DOI 10.1098/rstb/2005/1754; Everingham YL, 2007, AUST J AGR RES, V58, P87, DOI 10.1071/AR05443; Everingham YL, 2003, INT J CLIMATOL, V23, P1211, DOI 10.1002/joc.920; Friedman J. H., 2003, IMPORTANCE SAMPLED L; Hansen JW, 2004, AGR FOREST METEOROL, V127, P77, DOI 10.1016/j.agrformet.2004.07.005; Hansen JW, 2004, AGR FOREST METEOROL, V125, P143, DOI 10.1016/j.agrformat.2004.02.006; Hansen JW, 2000, AGR SYST, V65, P43, DOI 10.1016/S0308-521X(00)00025-1; Hastie T., 2001, ELEMENTS STAT LEARNI; Inman-Bamber N. G., 2005, Proceedings of the 2005 Conference of the Australian Society of Sugar Cane Technologists held at Bundaberg, Queensland, Australia, 3-6 May 2005, P170; INMANBAMBER NG, 2004, P AUSTR SOC SUG CAN; Knutti R, 2002, NATURE, V416, P719, DOI 10.1038/416719a; Krogh A, 1995, ADV NEURAL INFORM PR; KUHNEL I, 1994, AUST J AGR RES, V45, P1557, DOI 10.1071/AR9941557; Martelli PL, 2003, BIOINFORMATICS, V19, pi205, DOI 10.1093/bioinformatics/btg1027; Mevik BH, 2004, J CHEMOMETR, V18, P498, DOI 10.1002/cem.895; Park SE, 2005, FIELD CROP RES, V92, P305, DOI 10.1016/j.fcr.2005.01.025; Potgieter AB, 2005, AGR FOREST METEOROL, V132, P143, DOI 10.1016/j.agrformet.2005.07.009; Ye XJ, 2006, ECOL MODEL, V198, P426, DOI 10.1016/j.ecolmodel.2006.06.001; Zhang P, 2005, AGR FOREST METEOROL, V132, P344, DOI 10.1016/j.agrformet.2005.09.004	28	8	9	3	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0168-1923			AGR FOREST METEOROL	Agric. For. Meteorol.	MAR 11	2009	149	3-4					689	696		10.1016/j.agrformet.2008.10.018		8	Agronomy; Forestry; Meteorology & Atmospheric Sciences	Agriculture; Forestry; Meteorology & Atmospheric Sciences	417MI	WOS:000264079700024		
J	Budinska, E; Gelnarova, E; Schimek, MG				Budinska, Eva; Gelnarova, Eva; Schimek, Michael G.			MSMAD: a computationally efficient method for the analysis of noisy array CGH data	BIOINFORMATICS			English	Article							DNA COPY NUMBER; COMPARATIVE GENOMIC HYBRIDIZATION; CHRONIC LYMPHOCYTIC-LEUKEMIA; HIGH-RESOLUTION ANALYSIS; CIRCULAR BINARY SEGMENTATION; CELL LUNG-CANCER; REARRANGEMENTS; MICROARRAYS; REGRESSION; MODEL	Motivation: Genome analysis has become one of the most important tools for understanding the complex process of cancerogenesis. With increasing resolution of CGH arrays, the demand for computationally efficient algorithms arises, which are effective in the detection of aberrations even in very noisy data. Results: We developed a rather simple, non-parametric technique of high computational efficiency for CGH array analysis that adopts a median absolute deviation concept for breakpoint detection, comprising median smoothing for pre-processing. The resulting algorithm has the potential to outperform any single smoothing approach as well as several recently proposed segmentation techniques. We show its performance through the application of simulated and real datasets in comparison to three other methods for array CGH analysis.	[Budinska, Eva; Gelnarova, Eva; Schimek, Michael G.] Masaryk Univ, Inst Biostat & Anal, Brno 62500, Czech Republic; [Schimek, Michael G.] Med Univ Graz, Inst Med Informat Stat & Documentat, A-8036 Graz, Austria	Budinska, E (reprint author), Masaryk Univ, Inst Biostat & Anal, Kamenice 126-3, Brno 62500, Czech Republic.		Budinska, Eva/F-2698-2011	Budinska, Eva/0000-0002-9004-9187	Ministry of Health of the Czech Republic [NR/9076-4, NR/9484-3]	Ministry of Health of the Czech Republic-Internal Grant Agency (NR/9076-4; NR/9484-3)	SolinasToldo S, 1997, GENE CHROMOSOME CANC, V20, P399, DOI 10.1002/(SICI)1098-2264(199712)20:4<399::AID-GCC12>3.0.CO;2-I; Lai WR, 2005, BIOINFORMATICS, V21, P3763, DOI 10.1093/bioinformatics/bti611; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Andersson R, 2008, BIOINFORMATICS, V24, P751, DOI 10.1093/bioinformatics/btn003; Tibshirani R, 2008, BIOSTATISTICS, V9, P18, DOI 10.1093/biostatistics/kxm013; Venkatraman ES, 2007, BIOINFORMATICS, V23, P657, DOI 10.1093/bioinformatics/btl646; Snijders AM, 2001, NAT GENET, V29, P263, DOI 10.1038/ng754; Hupe P, 2004, BIOINFORMATICS, V20, P3413, DOI 10.1093/bioinformatics/bth418; Pinkel D, 1998, NAT GENET, V20, P207, DOI 10.1038/2524; Olshen AB, 2004, BIOSTATISTICS, V5, P557, DOI 10.1093/biostatistics/kxh008; Pollack JR, 2002, P NATL ACAD SCI USA, V99, P12963, DOI 10.1073/pnas.162471999; Babicka L, 2006, CANCER GENET CYTOGEN, V168, P22, DOI 10.1016/j.cancergencyto.2005.11.017; Berrieman HK, 2004, BRIT J CANCER, V90, P900, DOI 10.1038/sj.bjc.6601569; Eilers PHC, 2005, BIOINFORMATICS, V21, P1146, DOI 10.1093/bioinformatics/bti148; Fink SR, 2006, CANCER GENET CYTOGEN, V167, P177, DOI 10.1016/j.cancergencyto.2006.01.005; Fridlyand J, 2004, J MULTIVARIATE ANAL, V90, P132, DOI 10.1016/j.jmva.2004.02.008; Garnis C, 2006, INT J CANCER, V118, P1556, DOI 10.1002/ijc.21491; GUHA S, 2006, WORKING PAPER SERIES; Hsu L, 2005, BIOSTATISTICS, V6, P211, DOI 10.1093/biostatistics/kxi004; Huang J, 2007, BIOINFORMATICS, V23, P2463, DOI 10.1093/bioinformatics/btm359; Jong K, 2003, LECT NOTES COMPUT SC, V2611, P54; Li YJ, 2007, BIOINFORMATICS, V23, P2470, DOI 10.1093/bioinformatics/btm364; Marioni JC, 2006, BIOINFORMATICS, V22, P1144, DOI 10.1093/bioinformatics/btl089; Nakao K, 2004, CARCINOGENESIS, V25, P1345, DOI 10.1093/carcin/bgh134; Novak U, 2002, BLOOD, V100, P1787; Pfeifer D, 2007, BLOOD, V109, P1202, DOI 10.1182/blood-2006-07-034256; Picard F., 2005, BMC BIOINFORMATICS, V6, P1; Picard F, 2007, BIOMETRICS, V63, P758, DOI 10.1111/j.1541-0420.2006.00729.x; R Development Core Team, 2007, R LANG ENV STAT COMP; SCHIMEK MG, 1988, COMPSTAT 1998, P37; Schwaenen C, 2004, P NATL ACAD SCI USA, V101, P1039, DOI 10.1073/pnas.0304717101; Shah S, 2006, BIOINFORMATICS, V22, P431; Stjernqvist S, 2007, BIOINFORMATICS, V23, P1006, DOI 10.1093/bioinformatics/btm059; Wang P, 2005, BIOSTATISTICS, V6, P45, DOI 10.1093/biostatistics/kxh017; Whittaker E, 1923, P EDINBURGH MATH SOC, V41, P63, DOI DOI 10.1017/S001309150000359X; Willenbrock H, 2005, BIOINFORMATICS, V21, P4084, DOI 10.1093/bioinformatics/bti677	36	5	5	0	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	MAR 15	2009	25	6					703	713		10.1093/bioinformatics/btp022		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	418ZT	WOS:000264189600002	19147666	
J	Wu, TT; Chen, YF; Hastie, T; Sobel, E; Lange, K				Wu, Tong Tong; Chen, Yi Fang; Hastie, Trevor; Sobel, Eric; Lange, Kenneth			Genome-wide association analysis by lasso penalized logistic regression	BIOINFORMATICS			English	Article							LINKAGE DISEQUILIBRIUM; LOGIC REGRESSION	Motivation: In ordinary regression, imposition of a lasso penalty makes continuous model selection straightforward. Lasso penalized regression is particularly advantageous when the number of predictors far exceeds the number of observations. Method: The present article evaluates the performance of lasso penalized logistic regression in case-control disease gene mapping with a large number of SNPs (single nucleotide polymorphisms) predictors. The strength of the lasso penalty can be tuned to select a predetermined number of the most relevant SNPs and other predictors. For a given value of the tuning constant, the penalized likelihood is quickly maximized by cyclic coordinate ascent. Once the most potent marginal predictors are identified, their two-way and higher order interactions can also be examined by lasso penalized logistic regression. Results: This strategy is tested on both simulated and real data. Our findings on coeliac disease replicate the previous SNP results and shed light on possible interactions among the SNPs.	[Sobel, Eric; Lange, Kenneth] Univ Calif Los Angeles, Dept Human Genet, Los Angeles, CA 90095 USA; [Lange, Kenneth] Univ Calif Los Angeles, Dept Biomath, Los Angeles, CA 90095 USA; [Hastie, Trevor] Stanford Univ, Dept Biostat, Stanford, CA 94305 USA; [Chen, Yi Fang; Hastie, Trevor] Stanford Univ, Dept Stat, Stanford, CA 94305 USA; [Wu, Tong Tong] Univ Maryland, Dept Epidemiol & Biostat, College Pk, MD 20742 USA	Lange, K (reprint author), Univ Calif Los Angeles, Dept Human Genet, Los Angeles, CA 90095 USA.				USPHS [GM53275, MH59490]	USPHS (GM53275, MH59490 to K. L. in part).	Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Park MY, 2008, BIOSTATISTICS, V9, P30, DOI 10.1093/biostatistics/kxm010; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Balding DJ, 2006, NAT REV GENET, V7, P781, DOI 10.1038/nrg1916; Nyholt DR, 2004, AM J HUM GENET, V74, P765, DOI 10.1086/383251; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Wu TT, 2008, ANN APPL STAT, V2, P224, DOI 10.1214/07-AOAS147; Ayers KL, 2008, BIOINFORMATICS, V24, P1596, DOI 10.1093/bioinformatics/btn236; CLAERBOU.JF, 1973, GEOPHYSICS, V38, P826, DOI 10.1190/1.1440378; FRIEDMAN I, 2008, REGULARIZED PATHS GE; FRIEDMAN J, 2007, ANN APPL STAT, V2, P302; Kimmel G, 2006, AM J HUM GENET, V79, P481, DOI 10.1086/507317; Koh KM, 2007, J MACH LEARN RES, V8, P1519; Kooperberg C, 2005, GENET EPIDEMIOL, V28, P157, DOI 10.1002/gepi.20042; Lange K., 2004, OPTIMIZATION; Lazzeroni LC, 1998, HUM HERED, V48, P67, DOI 10.1159/000022784; Lee S.-I., 2006, P 21 NAT C ART INT; Liang Y., 2008, STAT SURVEYS, V2, P43; Malo N, 2008, AM J HUM GENET, V82, P375, DOI 10.1016/j.ajhg.2007.10.012; Nijenhuis A, 1978, COMBINATORIAL ALGORI; Park M. Y., 2007, L1 REGULARIZATION PA, P304; SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087; Schwender H, 2008, BIOSTATISTICS, V9, P187, DOI 10.1093/biostatistics/kxm024; SHA F, 2007, LECT NOTES COMPUTER; Shi Weiliang, 2007, BMC Proc, V1 Suppl 1, pS60; Shi W., 2006, 1131 U WISC; SHI W, 2008, 1141 U WISC; TAYLOR HL, 1979, GEOPHYSICS, V44, P39, DOI 10.1190/1.1440921; Uh Hae-Won, 2007, BMC Proc, V1 Suppl 1, pS114; VANHEEL D, 2007, NAT GENET, V397, P827	32	191	198	4	20	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	MAR 15	2009	25	6					714	721		10.1093/bioinformatics/btp041		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	418ZT	WOS:000264189600003	19176549	
J	Shriner, D; Yi, NJ				Shriner, Daniel; Yi, Nengjun			Deviance information criterion (DIC) in Bayesian multiple QTL mapping	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							QUANTITATIVE TRAIT LOCI; CHAIN MONTE-CARLO; MODEL SELECTION APPROACH; EXPERIMENTAL CROSSES; VARIABLE SELECTION; IDENTIFICATION; PARAMETERS; SHRINKAGE; FRAMEWORK; GENOME	Mapping multiple quantitative trait loci (QTL) is commonly viewed as a problem of model selection. Various model selection criteria have been proposed, primarily in the non-Bayesian framework. The deviance information criterion (DIC) is the most popular criterion for Bayesian model selection and model comparison but has not been applied to Bayesian multiple QTL mapping. A derivation of the DIC is presented for multiple interacting QTL models and calculation of the DIC is demonstrated using posterior samples generated by Markov chain Monte Carlo (MCMC) algorithms. The DIC measures posterior predictive error by penalizing the fit of a model (deviance) by its complexity, determined by the effective number of parameters. The effective number of parameters simultaneously accounts for the sample size, the cross design, the number and lengths of chromosomes, covariates, the number of QTL, the type of QTL effects, and QTL effect sizes. The DIC provides a computationally efficient way to perform sensitivity analysis and can be used to quantitatively evaluate if including environmental effects, gene-gene interactions, and/or gene-environment interactions in the prior specification is worth the extra parameterization. The DIC has been implemented in the freely available package R/qtlbim, which greatly facilitates the general usage of Bayesian methodology for genome-wide interacting QTL analysis. (C) 2008 Elsevier B.V. All rights reserved.	[Shriner, Daniel; Yi, Nengjun] Univ Alabama Birmingham, Dept Biostat, Sect Stat Genet, Birmingham, AL 35294 USA	Shriner, D (reprint author), RPHB 327,1530 3rd Ave S, Birmingham, AL 35294 USA.	dshriner@ms.soph.uab.edu					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hoeting JA, 1999, STAT SCI, V14, P382; Zeng ZB, 1999, GENET RES, V74, P279, DOI 10.1017/S0016672399004255; Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644; KASS RE, 1995, J AM STAT ASSOC, V90, P928, DOI 10.2307/2291327; Heath SC, 1997, AM J HUM GENET, V61, P748, DOI 10.1086/515506; MADIGAN D, 1994, J AM STAT ASSOC, V89, P1535, DOI 10.2307/2291017; van der Linde A, 2005, STAT NEERL, V59, P45; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Baierl A, 2006, GENETICS, V173, P1693, DOI 10.1534/genetics.105.048108; Ball RD, 2001, GENETICS, V159, P1351; Bogdan M, 2004, GENETICS, V167, P989, DOI 10.1534/genetics.103.021683; Broman KW, 2002, J R STAT SOC B, V64, P641, DOI 10.1111/1467-9868.00354; Congdon P., 2006, BAYESIAN STAT MODELL; Fikse WF, 2003, J DAIRY SCI, V86, P1821, DOI 10.3168/jds.S0022-0302(03)73768-0; GAFFNEY PJ, 2001, THESIS U WISCONSIN; Gelman A., 2004, BAYESIAN DATA ANAL; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; HOESCHELE I, 2001, HDB STAT GENETICS, P599; Jeffreys H., 1961, THEORY PROBABILITY; Legarra A, 2005, LIVEST PROD SCI, V93, P205, DOI 10.1016/j.livprodsci.2004.10.008; Narita A, 2004, GENET SEL EVOL, V36, P415, DOI 10.1051/gse:2004009; Rekaya R, 2003, J DAIRY SCI, V86, P1837, DOI 10.3168/jds.S0022-0302(03)73770-9; Satagopan JM, 1996, GENETICS, V144, P805; SATAGOPAN JM, 1996, GEN AN QUANT TRAITS; Sen S, 2001, GENETICS, V159, P371; Sillanpaa MJ, 1998, GENETICS, V148, P1373; Spiegelhalter DJ, 2002, J ROY STAT SOC B, V64, P583, DOI 10.1111/1467-9868.00353; Stephens DA, 1998, BIOMETRICS, V54, P1334, DOI 10.2307/2533661; van der Linde A, 2004, TEST, V13, P85; Wang H, 2005, GENETICS, V170, P465, DOI 10.1534/genetics.104.039354; Xu SZ, 2007, BIOMETRICS, V63, P513, DOI 10.1111/j.1541-0420.2006.00711.x; Xu SZ, 2003, GENETICS, V163, P789; Yandell BS, 2007, BIOINFORMATICS, V23, P641, DOI 10.1093/bioinformatics/btm011; Yi NJ, 2003, GENETICS, V165, P867; Yi NJ, 2002, GENET RES, V79, P185, DOI 10.1017/S0016672301005511; Yi NJ, 2007, GENETICS, V176, P1865, DOI 10.1534/genetics.107.071365; Yi NJ, 2004, GENETICS, V167, P967, DOI 10.1534/genetics.104.026286; Yi NJ, 2005, GENETICS, V170, P1333, DOI 10.1534/genetics.104.040386; Yi NJ, 2003, GENETICS, V164, P1129; Zhang M, 2005, GENETICS, V169, P2305, DOI 10.1534/genetics.104.034181	43	4	4	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473	1872-7352		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAR 15	2009	53	5			SI		1850	1860		10.1016/j.csda.2008.01.016		11	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	427AH	WOS:000264751000030		
J	Verzelen, N; Villers, F				Verzelen, N.; Villers, F.			Tests for Gaussian graphical models	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							SELECTION; REGRESSION; NETWORKS; LASSO	Gaussian graphical models are promising tools for analysing genetic networks. In many applications, biologists have some knowledge of the genetic network and may want to assess the quality of their model using gene expression data. This is why one introduces a novel procedure for testing the neighborhoods of a Gaussian graphical model. It is based on the connection between the local Markov property and conditional regression of a Gaussian random variable. Adapting recent results on tests for high-dimensional Gaussian linear models, one proves that the testing procedure inherits appealing theoretical properties. Besides, it applies and is computationally feasible in a high-dimensional setting: the number of nodes may be much larger than the number of observations. A large part of the study is devoted to illustrating and discussing applications to simulated data and to biological data. (C) 2008 Elsevier B.V. All rights reserved.	[Villers, F.] INRA, F-78352 Jouy En Josas, France; [Verzelen, N.] Univ Paris 11, Math Lab, F-91405 Orsay, France; [Verzelen, N.] Univ Paris 11, INRIA Saclay, Equipe SELECT, F-91405 Orsay, France	Villers, F (reprint author), INRA, F-78352 Jouy En Josas, France.	fanny.villers@jouy.inra.fr					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Drton M, 2008, J STAT PLAN INFER, V138, P1179, DOI 10.1016/j.jspi.2007.05.035; Efron B, 2004, ANN STAT, V32, P407; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; DAUDIN JJ, 2006, RR5840 INRIA; Drton M, 2007, STAT SCI, V22, P430, DOI 10.1214/088342307000000113; Edwards D., 2000, INTRO GRAPHICAL MODE; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; Kishino H, 2000, Genome Inform Ser Workshop Genome Inform, V11, P83; Lauritzen S. L., 1996, GRAPHICAL MODELS; Sachs K, 2005, SCIENCE, V308, P523, DOI 10.1126/science.1105809; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062; TO H, 2002, BIOINFORMATICS, V18, P287; VERZELEN N, 2007, ARXIVMATHST07112119; Wille A., 2006, STAT APPL GENETICS M, V5; WILLE A, GENOME BIOL, V5; WU X, 2003, P ACM SIGKDD WORKSH, V3, P63	18	4	4	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAR 15	2009	53	5					1894	1905		10.1016/j.csda.2008.09.022		12	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	427AH	WOS:000264751000034		
J	Baraud, Y; Giraud, C; Huet, S				Baraud, Yannick; Giraud, Christophe; Huet, Sylvie			GAUSSIAN MODEL SELECTION WITH AN UNKNOWN VARIANCE	ANNALS OF STATISTICS			English	Article						Model selection; penalized criterion; AIC; FPE; BIC; AMDL; variable selection; change-points detection; adaptive estimation	REGRESSION; SHRINKAGE; LASSO	Let Y be a Gaussian vector whose components are independent with a common unknown variance. We consider the problem of estimating the mean p of Y by model selection. More precisely, we start with a collection S = {S(m), m is an element of M} of linear subspaces of R(n) and associate to each of these the least-squares estimator of mu on S(m). Then, we use a data driven penalized criterion in order to select one estimator among these. Our first objective is to analyze the performance of estimators associated to classical criteria such as FPE, AIC, BIC and AMDL. Our second objective is to propose better penalties that are versatile enough to take into account both the complexity of the collection S and the sample size. Then we apply those to solve various statistical problems such as variable selection, change point detections and signal estimation among others. Our results are based on a nonasymptotic risk bound with respect to the Euclidean loss for the selected estimator. Some analogous results are also established for the Kullback loss.	[Baraud, Yannick; Giraud, Christophe] Univ Nice Sophia Antipolis, Lab J A Dieudonne, F-06108 Nice 02, France; [Huet, Sylvie] INRA MIAJ, F-78352 Jouy En Josas, France	Baraud, Y (reprint author), Univ Nice Sophia Antipolis, Lab J A Dieudonne, Parc Valrose, F-06108 Nice 02, France.	yannick.baraud@unice.fr; Christophe.Giraud@polytechnique.edu; sylvie.huet@jouy.inra.fr					AKAIKE H, 1970, ANN I STAT MATH, V22, P203, DOI 10.1007/BF02506337; Akaike H., 1973, 2 INT S INF THEOR, P267; Laurent B, 2000, ANN STAT, V28, P1302; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; AKAIKE H, 1978, ANN I STAT MATH, V30, P9, DOI 10.1007/BF02480194; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Efron B, 2004, ANN STAT, V32, P407; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; BARAUD Y, 2007, ARXIVMATH0701250; Baraud Y, 2003, ANN STAT, V31, P225; Barron A, 1999, PROBAB THEORY REL, V113, P301, DOI 10.1007/s004400050210; BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; Birge L., 1997, FESTSCHRIFT LUCIEN C, P55, DOI 10.1007/978-1-4612-1880-7_4; Birge L, 2007, PROBAB THEORY REL, V138, P33, DOI 10.1007/s00440-006-0011-8; Birge L., 2001, J EUR MATH SOC, V3, P203, DOI 10.1007/s100970100031; Huet S, 2006, ESAIM-PROBAB STAT, V10, P164, DOI 10.1051/ps:2006004; IBRAGIMOV IA, 1981, ZAP NAUCHA SEMIN LOM, V108, P73; Lebarbier E, 2005, SIGNAL PROCESS, V85, P717, DOI 10.1016/j.sigpro.2004.11.012; McQuarrie ADR, 1998, REGRESSION TIMES SER; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; BARRON AR, 1991, NATO ADV SCI I C-MAT, V335, P561; Saito N., 1994, WAVELETS GEOPHYSICS, P299	27	17	17	0	4	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	APR	2009	37	2					630	672		10.1214/07-AOS573		43	Statistics & Probability	Mathematics	437PX	WOS:000265500500004		
J	Xie, HL; Huang, J				Xie, Huiliang; Huang, Jian			SCAD-PENALIZED REGRESSION IN HIGH-DIMENSIONAL PARTIALLY LINEAR MODELS	ANNALS OF STATISTICS			English	Article						Asymptotic normality; high-dimensional data; oracle property; penalized estimation; semiparametric models; variable selection	VARIABLE SELECTION; LASSO; CONVERGENCE; ESTIMATORS; RATES; LIKELIHOOD	We consider the problem of simultaneous variable selection and estimation in partially linear models with a divergent number of covariates in the linear part, under the assumption that the vector of regression coefficients is sparse. We apply the SCAD penalty to achieve sparsity in the linear part and use polynomial splines to estimate the nonparametric component. Under reasonable conditions, it is shown that consistency in terms of variable selection and estimation can be achieved simultaneously for the linear and nonparametric components. Furthermore, the SCAD-penalized estimators of the nonzero coefficients are shown to have the asymptotic oracle property, in the sense that it is asymptotically normal with the same means and covariances that they would have if the zero coefficients were known in advance. The finite sample behavior of the SCAD-penalized estimators is evaluated with simulation and illustrated with a data set.	[Xie, Huiliang] Univ Miami, Dept Management Sci, Coral Gables, FL 33124 USA; [Huang, Jian] Univ Iowa, Dept Stat & Agr Sci, Iowa City, IA 52242 USA	Xie, HL (reprint author), Univ Miami, Dept Management Sci, Coral Gables, FL 33124 USA.	h.xie@miami.edu; jian-huang@uiowa.edu					ENGLE RF, 1986, J AM STAT ASSOC, V81, P310, DOI 10.2307/2289218; Knight K, 2000, ANN STAT, V28, P1356; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Huang J, 2008, ANN STAT, V36, P587, DOI 10.1214/009053607000000875; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Berndt E. R., 1991, PRACTICE ECONOMETRIC; CHEN H, 1988, ANN STAT, V16, P136, DOI 10.1214/aos/1176350695; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; HECKMAN NE, 1986, J ROY STAT SOC B MET, V48, P244; Huang J, 1999, ANN STAT, V27, P1536, DOI 10.1214/aos/1017939141; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Kim Y, 2006, STAT SINICA, V16, P375; ROBINSON PM, 1988, ECONOMETRICA, V56, P931, DOI 10.2307/1912705; SCHUMAKER L, SPLINE FUNCTIONS BAS; SPECKMAN P, 1988, J ROY STAT SOC B MET, V50, P413; STONE CJ, 1985, ANN STAT, V13, P689, DOI 10.1214/aos/1176349548; van de Geer SA, 2008, ANN STAT, V36, P614, DOI 10.1214/009053607000000929; Wahba G., 1990, SPLINE MODELS OBSERV; Wahba G, 1984, STAT ANAL TIME SERIE, P319; Wang S., 1993, INEQUALITIES MATRIX; Zhang CH, 2008, ANN STAT, V36, P1567, DOI 10.1214/07-AOS520	27	49	54	2	5	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	APR	2009	37	2					673	696		10.1214/07-AOS580		24	Statistics & Probability	Mathematics	437PX	WOS:000265500500005		
J	Binder, H; Allignol, A; Schumacher, M; Beyersmann, J				Binder, Harald; Allignol, Arthur; Schumacher, Martin; Beyersmann, Jan			Boosting for high-dimensional time-to-event data with competing risks	BIOINFORMATICS			English	Article							SUBDISTRIBUTION HAZARDS; SURVIVAL ANALYSIS; CROSS-VALIDATION; MODELS; REGRESSION; CLASSIFICATION	Motivation: For analyzing high-dimensional time-to-event data with competing risks, tailored modeling techniques are required that consider the event of interest and the competing events at the same time, while also dealing with censoring. For low-dimensional settings, proportional hazards models for the subdistribution hazard have been proposed, but an adaptation for high-dimensional settings is missing. In addition, tools for judging the prediction performance of fitted models have to be provided. Results: We propose a boosting approach for fitting proportional subdistribution hazards models for high-dimensional data, that can e.g. incorporate a large number of microarray features, while also taking clinical covariates into account. Prediction performance is evaluated using bootstrap.632 estimates of prediction error curves, adapted for the competing risks setting. This is illustrated with bladder cancer microarray data, where simultaneous consideration of both, the event of interest and competing events, allows for judging the additional predictive power gained from incorporating microarray measurements.	[Binder, Harald; Allignol, Arthur; Beyersmann, Jan] Univ Freiburg, Freiburg Ctr Data Anal & Modeling, D-79104 Freiburg, Germany; [Binder, Harald; Allignol, Arthur; Schumacher, Martin; Beyersmann, Jan] Univ Med Ctr Freiburg, Inst Med Biometry & Med Informat, D-79104 Freiburg, Germany	Binder, H (reprint author), Univ Freiburg, Freiburg Ctr Data Anal & Modeling, Eckerstr 1, D-79104 Freiburg, Germany.	binderh@fdm.uni-freiburg.de	Binder, Harald/C-7413-2009	Binder, Harald/0000-0002-5666-8662	Deutsche Forschungsgemeinschaft (DFG) [FOR 534]	We gratefully acknowledge support from Deutsche Forschungsgemeinschaft (DFG Forschergruppe FOR 534).	Andersen P., 1993, STAT MODELS BASED CO; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Gui J, 2005, BIOINFORMATICS, V21, P3001, DOI 10.1093/bioinformatics/bti422; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Graf E, 1999, STAT MED, V18, P2529; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Buhlmann P, 2003, J AM STAT ASSOC, V98, P324, DOI 10.1198/016214503000125; AALEN OO, 1978, SCAND J STAT, V5, P141; Gerds TA, 2006, BIOMETRICAL J, V48, P1029, DOI 10.1002/bimj.200610301; PEPE MS, 1993, STAT MED, V12, P737, DOI 10.1002/sim.4780120803; Fine JP, 1999, J AM STAT ASSOC, V94, P496, DOI 10.2307/2670170; Bender R, 2005, STAT MED, V24, P1713, DOI 10.1002/sim.2059; Beyersmann J, 2008, BIOSTATISTICS, V9, P765, DOI 10.1093/biostatistics/kxn009; Beyersmann J, 2007, STAT MED, V26, P5360, DOI 10.1002/sim.3006; BINDER H, 2008, STAT APPL GENET MOL, P7; Binder H, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-14; Dyrskjot L, 2007, CLIN CANCER RES, V13, P3545, DOI 10.1158/1078-0432.CCR-06-2940; Gerds TA, 2007, BIOMETRICS, V63, P1283, DOI 10.1111/j.1541-0420.2007.00832.x; Latouche A, 2007, STAT MED, V26, P965, DOI 10.1002/sim.2600; SCHOOP R, 2008, THESIS U FREIBURG; Schumacher M, 2007, BIOINFORMATICS, V23, P1768, DOI 10.1093/bioinformatics/btm232; VERWEIJ PJM, 1993, STAT MED, V12, P2305, DOI 10.1002/sim.4780122407	23	16	17	0	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	APR 1	2009	25	7					890	896		10.1093/bioinformatics/btp088		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	425QI	WOS:000264651800008	19244389	
J	Lauter, J; Horn, F; Rosolowski, M; Glimm, E				Laeuter, Juergen; Horn, Friedernann; Rosolowski, Maciej; Glimm, Ekkehard			High-dimensional data analysis: Selection of variables, data compression and graphics - Application to gene expression	BIOMETRICAL JOURNAL			English	Article; Proceedings Paper	International Conference on Statistics and Life Science	MAR 10-13, 2008	Munich, GERMANY	Int Biomet Soc, European Network		Data compression; Gene expression analysis; High-dimensional tests; Multivariate analysis; Selection of variables	B-CELL LYMPHOMA; MULTIVARIATE TESTS; REGRESSION; HYPOTHESES; LASSO; SETS	The paper presents effective and mathematically exact procedures for selection of variables which are applicable in cases with a very high dimension as, for example, in gene expression analysis. Choosing sets of variables is an important method to increase the power of the statistical conclusions and to facilitate the biological interpretation. For the construction of sets, each single variable is considered as the centre of potential sets of variables. Testing for significance is carried out by means of the Westfall-Young principle based on resampling or by the parametric method of spherical tests. The particular requirements for statistical stability are taken into account; each kind of overfitting is avoided. Thus, high power is attained and the familywise type I error can be kept in spite of the large dimension. To obtain graphical representations by heat maps and curves, a specific data compression technique is applied. Gene expression data from B-cell lymphoma patients serve for the demonstration of the procedures.	[Laeuter, Juergen; Horn, Friedernann] Univ Leipzig, IZBI, D-04107 Leipzig, Germany; [Laeuter, Juergen] Otto Von Guericke Univ, D-39114 Magdeburg, Germany; [Horn, Friedernann] Univ Leipzig, Fac Med, Inst Clin Immunol & Transfus Med, D-04103 Leipzig, Germany; [Horn, Friedernann; Rosolowski, Maciej] Univ Leipzig, Fac Med, Interdisciplinary Ctr Clin Res IZKF, D-04103 Leipzig, Germany; [Rosolowski, Maciej] Univ Leipzig, Fac Med, IMISE, D-04107 Leipzig, Germany; [Glimm, Ekkehard] Novartis Pharma AG, CH-4056 Basel, Switzerland	Lauter, J (reprint author), Univ Leipzig, IZBI, Hartelstr 16-18, D-04107 Leipzig, Germany.	juergen.laeuter@med.ovgu.de					ANDERSON JA, 1982, BIOMETRIKA, V69, P123, DOI 10.1093/biomet/69.1.123; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; FURNIVAL GM, 1974, TECHNOMETRICS, V16, P499, DOI 10.2307/1267601; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Bild AH, 2006, NATURE, V439, P353, DOI 10.1038/nature04296; Efron B, 2004, ANN STAT, V32, P407; GABRIEL KR, 1971, BIOMETRIKA, V58, P453, DOI 10.2307/2334381; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Boxer LM, 2001, ONCOGENE, V20, P5595, DOI 10.1038/sj.onc.1204595; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; DUDOIT SJ, 2002, MULTIPLE HYPOTHESIS; Goeman JJ, 2008, BIOINFORMATICS, V24, P537, DOI 10.1093/bioinformatics/btm628; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hommel G, 2005, BIOMETRICAL J, V47, P554, DOI 10.1002/bimj.200410118; Hummel M, 2006, NEW ENGL J MED, V354, P2419, DOI 10.1056/NEJMoa055351; Kropf S, 2002, BIOMETRICAL J, V44, P789, DOI 10.1002/1521-4036(200210)44:7<789::AID-BIMJ789>3.0.CO;2-#; Kropf S., 2000, HOCHDIMENSIONALE MUL; Lauter J, 1998, ANN STAT, V26, P1972; LAUTER J, 1996, BIOMETR J, V40, P1015; Lauter J, 2005, STAT NEERL, V59, P298, DOI 10.1111/j.1467-9574.2005.00290.x; LAUTER J, 2007, LEIPZIG BIOINFORMATI, V15; LAUTER J, 1998, ANN STAT, V27, P1441; Lauter J, 1996, BIOMETRICS, V52, P964, DOI 10.2307/2533057; Lauter J, 1996, BIOMETRICAL J, V38, P5; TIBSHIRANI R, 2006, ARXIVMATH0608061V1MA; WASSERMAN L, 2007, ARXIV07041139V1MATHS; Westfall P. H., 1993, RESAMPLING BASED MUL; Westfall P.H., 2004, IMS LECT NOTES MONOG, V47, P143	29	11	11	1	4	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0323-3847	1521-4036		BIOMETRICAL J	Biom. J.	APR	2009	51	2			SI		235	251		10.1002/bimj.200800207		17	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	442UW	WOS:000265867100002	19358215	
J	De Mol, C; De Vito, E; Rosasco, L				De Mol, Christine; De Vito, Ernesto; Rosasco, Lorenzo			Elastic-net regularization in learning theory	JOURNAL OF COMPLEXITY			English	Article						Learning; Regularization; Sparsity; Elastic net	ADAPTIVE ESTIMATION; MODEL SELECTION; LASSO; REGRESSION; ALGORITHMS; CONSTRAINT	Within the framework of statistical learning theory we analyze in detail the so-called elastic-net regularization scheme proposed by Zou and Hastie [H. Zou,T. Hastie, Regularization and variable selection via the elastic net, J. R. Stat. Soc. Ser. B, 67(2) (2005) 301-320] for the selection of groups of correlated variables. To investigate the statistical properties of this scheme and in particular its consistency properties, we set up a suitable mathematical framework. Our setting is random-design regression where we allow the response variable to be vector-valued and we consider prediction functions which are linear combinations of elements (features) in an infinite-dimensional dictionary. Under the assumption that the regression function admits a sparse representation on the dictionary, we prove that there exists a particular "elastic-net representation" of the regression function such that, if the number of data increases, the elastic-net estimator is consistent not only for prediction but also for variable/feature selection. Our results include finite-sample bounds and an adaptive scheme to select the regularization parameter. Moreover, using convex analysis tools, we derive an iterative thresholding algorithm for computing the elastic-net solution which is different from the optimization procedure originally proposed in the above-cited work. (C) 2009 Elsevier Inc. All rights reserved.	[Rosasco, Lorenzo] MIT, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA; [De Mol, Christine] Univ Libre Bruxelles, Dept Math, B-1050 Brussels, Belgium; [De Mol, Christine] Univ Libre Bruxelles, ECARES, B-1050 Brussels, Belgium; [De Vito, Ernesto] Univ Genoa, Dipartimento Sci Architettura, I-16123 Genoa, Italy; [De Vito, Ernesto] Ist Nazl Fis Nucl, Sez Genova, I-16146 Genoa, Italy; [Rosasco, Lorenzo] Univ Genoa, Dipartimento Informat & Sci Infromaz, I-16146 Genoa, Italy	Rosasco, L (reprint author), MIT, Ctr Biol & Computat Learning, 43 Vassar St, Cambridge, MA 02139 USA.	demol@ulb.ac.be; devito@dima.unige.it; lrosasco@mit.edu	De Vito, Ernesto/K-6354-2015; 	De Vito, Ernesto/0000-0002-4320-3292; rosasco, lorenzo/0000-0003-3098-383X	"Action de Recherche Concertee" [Nb 02/07-281]; National Bank of Belgium BNB; FIRB Project [RBIN04PARL]; EU [IST-2004-027749];  [VUB-GOA 62]	We thank Alessandro Verri for helpful suggestions and discussions. Christine De Mol acknowledges support by the "Action de Recherche Concertee" Nb 02/07-281, the VUB-GOA 62 grant and the National Bank of Belgium BNB; she is also grateful to the DISI, Universita di Genova for hospitality during a semester in which the present work was initiated. Ernesto De Vito and Lorenzo Rosasco have been partially Supported by the FIRB project RBIN04PARL and by the EU Integrated Project Health-e-Child IST-2004-027749.	Amato U, 2006, STAT COMPUT, V16, P37, DOI 10.1007/s11222-006-5283-4; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Knight K, 2000, ANN STAT, V28, P1356; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Micchelli CA, 2005, NEURAL COMPUT, V17, P177, DOI 10.1162/0899766052530802; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Efron B, 2004, ANN STAT, V32, P407; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Pereverzev S, 2005, SIAM J NUMER ANAL, V43, P2060, DOI 10.1137/S00361429034338419; Fornasier M, 2008, SIAM J NUMER ANAL, V46, P577, DOI 10.1137/0606668909; Argyriou A., 2007, ADV NEURAL INFORM PR, V19, P41; BALDASSARRE L, 2008, P ICPR 2008 TAMP FL; BARLA A, 2008, ESANN 2008; Barron AR, 2008, ANN STAT, V36, P64, DOI 10.1214/009053607000000631; Bauer F, 2005, EUR J APPL MATH, V16, P303, DOI 10.1017/S095679205006236; Bauer F, 2007, J COMPLEXITY, V23, P52, DOI 10.1016/j.jco.2006.07.001; Bunea F, 2006, P 19 ANN C LEARN THE, P379; Caponnetto A, 2008, J MACH LEARN RES, V9, P1615; Caponnetto A, 2007, FOUND COMPUT MATH, V7, P331, DOI 10.1007/S10208-006-0196-8; Carmeli C, 2006, ANAL APPL, V4, P377, DOI 10.1142/S0219530506000838; DEMOL C, J COMP BIOL IN PRESS; Destrero A, 2009, IEEE T IMAGE PROCESS, V18, P188, DOI 10.1109/TIP.2008.2007610; Destrero Augusto, 2009, Computational Management Science, V6, DOI 10.1007/s10287-008-0070-7; DESTRERO A, 2007, P ACCV07, P881; DEVITO E, 2008, 275CSAIL BCL MIT; Ekeland I., 1983, CHICAGO LECT MATH; Greenshtein E, 2006, ANN STAT, V34, P2367, DOI 10.1214/009053606000000768; KOLTCHINSKII V, 2009, PROBAB STAT, V45, P7; LEPSKII OV, 1990, THEOR PROBAB APPL+, V35, P454, DOI 10.1137/1135065; Loubes JM, 2002, STAT NEERL, V56, P454, DOI 10.1111/1467-9574.00212; Owen AB, 2007, CONTEMP MATH, V443, P59; Pinelis I., 1994, ANN PROBAB, V22, P1679, DOI DOI 10.1214/A0P/1176988477; Pinelis I. F., 1985, THEOR PROBAB APPL, V30, P143; Smale S, 2007, CONSTR APPROX, V26, P153, DOI 10.1007/s00365-006-0659-y; Tarigan B, 2006, BERNOULLI, V12, P1045, DOI 10.3150/bj/1165269150; van de Geer SA, 2008, ANN STAT, V36, P614, DOI 10.1214/009053607000000929; Wahba G., 1990, CBMS NSF REGIONAL C, V59; Wellner J. A., 1996, SPRINGER SERIES STAT; Yurinsky V., 1995, LECT NOTES MATH, V1617	44	30	30	3	8	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0885-064X			J COMPLEXITY	J. Complex.	APR	2009	25	2					201	230		10.1016/j.jco.2009.01.002		30	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	434WA	WOS:000265303600007		
J	Saigo, H; Nowozin, S; Kadowaki, T; Kudo, T; Tsuda, K				Saigo, Hiroto; Nowozin, Sebastian; Kadowaki, Tadashi; Kudo, Taku; Tsuda, Koji			gBoost: a mathematical programming approach to graph classification and regression	MACHINE LEARNING			English	Article						Graph mining; Mathematical programming; Classification; Regression; QSAR	SUPPORT VECTOR MACHINES; LARGE DIVERSE SET; COLUMN GENERATION; SELECTION; KERNELS	Graph mining methods enumerate frequently appearing subgraph patterns, which can be used as features for subsequent classification or regression. However, frequent patterns are not necessarily informative for the given learning problem. We propose a mathematical programming boosting method (gBoost) that progressively collects informative patterns. Compared to AdaBoost, gBoost can build the prediction rule with fewer iterations. To apply the boosting method to graph data, a branch-and-bound pattern search algorithm is developed based on the DFS code tree. The constructed search space is reused in later iterations to minimize the computation time. Our method can learn more efficiently than the simpler method based on frequent substructure mining, because the output labels are used as an extra information source for pruning the search space. Furthermore, by engineering the mathematical program, a wide range of machine learning problems can be solved without modifying the pattern search algorithm.	[Saigo, Hiroto; Nowozin, Sebastian; Tsuda, Koji] Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; [Kadowaki, Tadashi] Kyoto Univ, Inst Chem Res, Bioinformat Ctr, Uji, Kyoto 6110011, Japan; [Kudo, Taku] Google Japan Inc, Shibuya Ku, Tokyo 1508512, Japan	Saigo, H (reprint author), Max Planck Inst Biol Cybernet, Spemannstr 38, D-72076 Tubingen, Germany.	hiroto.saigo@tuebingen.mpg.de					Abiteboul S, 2000, DATA WEB RELATIONS S; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; du Merle O, 1999, DISCRETE MATH, V194, P229, DOI 10.1016/S0012-365X(98)00213-1; Ratsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Shi LM, 2001, J CHEM INF COMP SCI, V41, P186, DOI 10.1021/ci000066d; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Hong H, 2003, SAR QSAR ENVIRON RES, V14, P373, DOI 10.1080/10629360310001623962; BORGWARDT KM, 2006, BIOINFORMATICS S1, V21, P47; BRINGMANN B, 2006, 10 EUR C PRINC PRACT, P55; Cai L., 2004, ACM 13 C INF KNOWL M, P78; Cohen WW, 1995, P 12 INT C MACH LEAR, P115, DOI 10.1.1.50.8204; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Durbin R., 1998, BIOL SEQUENCE ANAL P; FRANK E, 1998, P 15 INT C MACH LEAR, P114; Frohlich H, 2006, QSAR COMB SCI, V25, P317, DOI 10.1002/qsar.200510135; Gartner T, 2003, P 16 ANN C LEARN THE, P129; Gasteiger J, 2003, CHEMOINFORMATICS TXB; Hamada M, 2006, BIOINFORMATICS, V22, P2480, DOI 10.1093/bioinformatics/btl431; Helma C, 2004, J CHEM INF COMP SCI, V44, P1402, DOI 10.1021/ci034254q; Horvath T., 2004, P 10 ACM SIGKDD INT, P158, DOI 10.1145/1014052.1014072; Inokuchi A, 2005, P 4 IEEE INT C DAT M, P415; James CA, 2004, DAYLIGHT THEORY MANU; Kashima H., 2003, P 20 INT C MACH LEAR, P321; Kazius J, 2006, J CHEM INF MODEL, V46, P597, DOI 10.1021/ci0503715; Kudo T., 2005, ADV NEURAL INFORM PR, V17, P729; Le Quoc V., 2006, P 23 INT C MACH LEAR, P521, DOI 10.1145/1143844.1143910; Luenberger D. G., 1969, OPTIMIZATION VECTOR; Mahe P, 2005, J CHEM INF MODEL, V45, P939, DOI 10.1021/ci050039t; Mahe P, 2006, J CHEM INF MODEL, V46, P2003, DOI 10.1021/ci060138m; Morishita S, 2000, P 19 ACM SIGACT SIGM, P226, DOI 10.1145/335168.335226; MORISHITA S, 2001, DISCOVERY SCI, P471; Nijssen S, 2004, P 10 ACM SIGKDD INT, P647, DOI 10.1145/1014052.1014134; Quinlan J., 1993, C4 5 PROGRAMS MACHIN; Ralaivola L, 2005, NEURAL NETWORKS, V18, P1093, DOI 10.1016/j.neunet.2005.07.009; Saigo H., 2006, INT WORKSH MIN LEARN, P85; Scholkopf B., 2002, LEARNING KERNELS SUP; TAKABAYASHI K, 2006, P INT WORKSH MIN LEA, P205; Vandenberghe L., 2004, CONVEX OPTIMIZATION; WALE N, 2006, P 2006 IEEE INT C DA, P678; Yan X, 2002, GSPAN GRAPH BASED SU; Yan X., 2002, P 2002 IEEE INT C DA, P721; Yuan C, 2003, PROC CVPR IEEE, P419	45	23	25	1	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	APR	2009	75	1					69	89		10.1007/s10994-008-5089-z		21	Computer Science, Artificial Intelligence	Computer Science	411TO	WOS:000263673800004		
J	Lipovetsky, S				Lipovetsky, Stan			Linear regression with special coefficient features attained via parameterization in exponential, logistic, and multinomial-logit forms	MATHEMATICAL AND COMPUTER MODELLING			English	Article						Multiple regression model; Predictors' impact; Exponential; Logistic; Multinomial parameterization	RIDGE-REGRESSION; COLLINEARITY; LASSO	Multiplelinearregression withspecial properties of its coefficients parameterized by exponent, logit, andmultinomial functionsisconsidered.To obtain alwayspositive coefficientsthe exponential parameterization is applied. To getcoefficients in an assigned range,the logistic parameterization isused. Such coefficientspermitusto evaluate the impactof individual predictorsinthe model. Thecoefficients obtainedbythe multinomial log it parameterization equal the shares of the predictors, which is useful for interpretation of their influence. The considered regression models are constructed by nonlinear optimization techniques, haves table solutions and good quality of fit, have simple structure of the linear aggregates,demonstrate highpredictive ability, and suggest a convenientway to identify the mainpredictors. (C) 2009 Elsevier Ltd. Allrights reserved	GfK Custom Res N Amer, Minneapolis, MN 55427 USA	Lipovetsky, S (reprint author), GfK Custom Res N Amer, 8401 Golden Valley Rd, Minneapolis, MN 55427 USA.	stan.lipovetsky@gfk.com					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; Efron B, 2004, ANN STAT, V32, P407; Becker S, 1988, P 1988 CONN MOD SUMM, P29; Bender E.A., 2000, MATH METHODS ARTIFIC; Bishop C., 2006, PATTERN RECOGNITION; Brown PJ, 1994, MEASUREMENT REGRESSI; Chambers J. M., 1992, STAT MODELS S; Clogg Clifford C., 1995, HDB STAT MODELING SO, DOI New York; EHRENBERG ASC, 1982, J ROY STAT SOC A STA, V145, P364, DOI 10.2307/2981869; Grapentine A, 1997, MARK RES, V9, P11; Hastie T., 2001, ELEMENTS STAT LEARNI; Hastie TJT RJ, 1997, GEN ADDITIVE MODELS; HOERL AE, 1975, COMMUN STAT, V4, P105, DOI 10.1080/03610917508548342; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Lipovetsky S, 2001, APPL STOCH MODEL BUS, V17, P319, DOI 10.1002/asmb.446; Lipovetsky S, 2001, COMPUT OPER RES, V28, P1333, DOI 10.1016/S0305-0548(00)00043-5; Lipovetsky S., 2007, J MODERN APPL STAT M, V6, P219; LIPOVETSKY S, 2007, P JOINT STAT M AM ST, P2313; Lipovetsky S, 2009, PATTERN RECOGN, V42, P68, DOI 10.1016/j.patcog.2008.06.025; Lipovetsky S, 2007, MODEL ASSISTED STAT, V2, P71; Lipovetsky S, 2003, APPL STOCH MODEL BUS, V19, P291, DOI 10.1002/asmb.503; Lipovetsky S, 2006, MATH COMPUT MODEL, V44, P304, DOI 10.1016/j.mcm.2006.01.017; LIPOVETSKY S, 2003, INT J MATH ED SCI TE, V34, P771, DOI 10.1080/0020739031000148895; MASON CH, 1991, J MARKETING RES, V28, P268, DOI 10.2307/3172863; MathSoft, 1999, S PLUS 2000; McCullagh P, 1997, GEN LINEAR MODELS; Rao C. R., 1973, LINEAR STAT INFERENC; Weisberg S., 1985, APPL LINEAR REGRESSI; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	30	7	7	0	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0895-7177	1872-9479		MATH COMPUT MODEL	Math. Comput. Model.	APR	2009	49	7-8					1427	1435		10.1016/j.mcm.2008.11.013		9	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	414VI	WOS:000263892900016		
J	Carrera, J; Rodrigo, G; Jaramillo, A				Carrera, Javier; Rodrigo, Guillermo; Jaramillo, Alfonso			Model-based redesign of global transcription regulation	NUCLEIC ACIDS RESEARCH			English	Article							ESCHERICHIA-COLI K-12; GENE-EXPRESSION DATA; MICROARRAY EXPERIMENTS; MUTUAL INFORMATION; NETWORK INFERENCE; ALGORITHM; PROFILES; PATTERNS; SYSTEMS; RECONSTRUCTION	Synthetic biology aims to the design or redesign of biological systems. In particular, one possible goal could be the rewiring of the transcription regulation network by exchanging the endogenous promoters. To achieve this objective, we have adapted current methods to the inference of a model based on ordinary differential equations that is able to predict the network response after a major change in its topology. Our procedure utilizes microarray data for training. We have experimentally validated our inferred global regulatory model in Escherichia coli by predicting transcriptomic profiles under new perturbations. We have also tested our methodology in silico by providing accurate predictions of the underlying networks from expression data generated with artificial genomes. In addition, we have shown the predictive power of our methodology by obtaining the gene profile in experimental redesigns of the E. coli genome, where rewiring the transcriptional network by means of knockouts of master regulators or by upregulating transcription factors controlled by different promoters. Our approach is compatible with most network inference methods, allowing to explore computationally future genome-wide redesign experiments in synthetic biology.	[Jaramillo, Alfonso] Ecole Polytech, CNRS, Biochim Lab, F-91128 Palaiseau, France; [Carrera, Javier; Rodrigo, Guillermo] Univ Politecn Valencia, CSIC, Inst Biol Mol & Celular Plantas, Valencia 46022, Spain; [Carrera, Javier] Univ Politecn Valencia, Inst Aplicac Tecnol Informat & Comunicac Avanzada, Valencia 46022, Spain; [Jaramillo, Alfonso] Univ Evry Val Essonne Genopole, CNRS, Epigenom Project, F-91034 Evry, France	Jaramillo, A (reprint author), Ecole Polytech, CNRS, Biochim Lab, Route Saclay, F-91128 Palaiseau, France.	alfonso.jaramillo@polytechnique.fr	Jaramillo, Alfonso/G-4257-2013	Jaramillo, Alfonso/0000-0002-6313-9689	Spanish Ministry of Education and Science [TIN 2006-12860]; Structural Funds of the European Regional Development Fund; EU grants BioModularH2 [FP6-NEST, 043340]; EMERGENCE [FP6-EST, 043338]; ATIGE Genopole/UEVE; MIT-France grants; Conselleria d'Educacio de la Generalitat Valenciana [BFPI 2007/160]; EMBO Short-term fellowship [ASTF-343.00-2007]	Spanish Ministry of Education and Science (ref. TIN 2006-12860); Structural Funds of the European Regional Development Fund; EU grants BioModularH2 (FP6-NEST contract 043340) and EMERGENCE (FP6-EST contract 043338); ATIGE Genopole/UEVE and the MIT-France grants; Graduate fellowship from the Conselleria d'Educacio de la Generalitat Valenciana (ref. BFPI 2007/160 to G. R.) and an EMBO Short-term fellowship (ref. ASTF-343.00-2007 to G. R.). HPC-Europa programme. Funding for open access charge: EU grant BioModularH2 FP6-NEST-043340.	*AFF, 1999, AFF MICR SUIT US GUI; ALTMAN DG, 1994, BRIT MED J, V308, P1552; ALTMAN DG, 1994, BRIT MED J, V309, P102; Steuer R, 2002, BIOINFORMATICS, V18, pS231; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Faith JJ, 2008, NUCLEIC ACIDS RES, V36, pD866, DOI 10.1093/nar/gkm815; Margolin AA, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S7; Yu J, 2004, BIOINFORMATICS, V20, P3594, DOI 10.1093/bioinformatics/bth448; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Behrens J, 1996, NATURE, V382, P638, DOI 10.1038/382638a0; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Hucka M, 2003, BIOINFORMATICS, V19, P524, DOI 10.1093/bioinformatics/btg015; Ihmels J, 2002, NAT GENET, V31, P370, DOI 10.1038/ng941; Price MN, 2005, NUCLEIC ACIDS RES, V33, P880, DOI 10.1093/nar/gki232; Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Bansal M, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100120; De Jong H, 2002, J COMPUT BIOL, V9, P67, DOI 10.1089/10665270252833208; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Sprinzak D, 2005, NATURE, V438, P443, DOI 10.1038/nature04335; Bar-Joseph Z, 2004, BIOINFORMATICS, V20, P2493, DOI 10.1093/bioinformatics/bth283; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Bonneau R, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-5-r36; Butte AJ, 2000, PAC S BIOC, V5, P415; Cohen JP, 2003, APPL MULTIPLE REGRES; Covert MW, 2004, NATURE, V429, P92, DOI 10.1038/nature02456; Daub CO, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-118; D'haeseleer P, 2000, BIOINFORMATICS, V16, P707, DOI 10.1093/bioinformatics/16.8.707; di Bernardo D, 2005, NAT BIOTECHNOL, V23, P377, DOI 10.1038/nbt1075; Dongarra J.J., 1979, LINPACK USERS GUIDE; Faith JJ, 2007, PLOS BIOL, V5, P54, DOI 10.1371/journal.pbio.0050008; Fujita A, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-39; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Gray R. M., 1990, ENTROPY INFORM THEOR; Husmeier D, 2003, BIOINFORMATICS, V19, P2271, DOI 10.1093/bioinformatics/btg313; Isalan M, 2008, NATURE, V452, P840, DOI 10.1038/nature06847; Karp PD, 2002, NUCLEIC ACIDS RES, V30, P56, DOI 10.1093/nar/30.1.56; Long J, 2008, BIOINFORMATICS, V24, P132, DOI 10.1093/bioinformatics/btm529; Meyer Patrick E, 2007, EURASIP J Bioinform Syst Biol, P79879, DOI 10.1155/2007/79879; Mordelet F, 2008, BIOINFORMATICS, V24, pi76; Reiss DJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-280; Sabatti C, 2002, NUCLEIC ACIDS RES, V30, P2886, DOI 10.1093/nar/gkf388; Salgado H, 2006, NUCLEIC ACIDS RES, V34, pD394, DOI 10.1093/nar/gkj156; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Steinke F, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-51; Stewart V, 2005, J BACTERIOL, V187, P6928, DOI 10.1128/JB.187.20.6928-6935.2005	48	21	21	0	7	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048			NUCLEIC ACIDS RES	Nucleic Acids Res.	APR	2009	37	5							e38	10.1093/nar/gkp022		11	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	421YU	WOS:000264395000004	19188257	
J	Yang, JY; Peng, YG; Xu, WL; Dai, QH				Yang JingYu; Peng YiGang; Xu WenLi; Dai QiongHai			Ways to sparse representation: An overview	SCIENCE IN CHINA SERIES F-INFORMATION SCIENCES			English	Review						sparse representation; redundant dictionary; redundant transform; nonlinear approximation; matching pursuit; basis pursuit; iterative shrinkage	LINEAR INVERSE PROBLEMS; REDUNDANT REPRESENTATIONS; MATCHING PURSUIT; ALGORITHM; DICTIONARIES; SELECTION; RECONSTRUCTION; APPROXIMATION; DECOMPOSITION; MINIMIZATION	Many algorithms have been proposed to find sparse representations over redundant dictionaries or transforms. This paper gives an overview of these algorithms by classifying them into three categories: greedy pursuit algorithms, l (p) norm regularization based algorithms, and iterative shrinkage algorithms. We summarize their pros and cons as well as their connections. Based on recent evidence, we conclude that the algorithms of the three categories share the same root: l (p) norm regularized inverse problem. Finally, several topics that deserve further investigation are also discussed.	[Yang JingYu; Peng YiGang; Xu WenLi; Dai QiongHai] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Yang, JY (reprint author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	yangjy@gmail.com			Joint Research Fund for Overseas Chinese Young Scholars of the National Natural Science Foundation of China [60528004]; Key Project of the National Natural Science Foundation of China [60528004]	Supported by the Joint Research Fund for Overseas Chinese Young Scholars of the National Natural Science Foundation of China (Grant No. 60528004) and the Key Project of the National Natural Science Foundation of China (Grant No. 60528004)	Fischer S, 2006, IEEE T IMAGE PROCESS, V15, P265, DOI 10.1109/TIP.2005.860614; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031; DAVIS G, 1994, OPT ENG, V33, P2183, DOI 10.1117/12.173207; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300; Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475; Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251; Efron B, 2004, ANN STAT, V32, P407; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255; BLUMENSATH T, 2004, ITERATIVE THRESHOLDI; Candes E., 2000, CURVES SURFACES, P105; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; COTTER S, 2001, P INT C AC SPEECH SI, P3933; Daubechies I, 2007, INVERSE PROBL IMAG, V1, P29; DeVore RA, 1998, NONLINEAR APPROXIMAT, P51; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Donoho D., 2006, FAST SOLUTION L1 NOR; Donoho D. L., 2006, SPARSE SOLUTION UNDE; Elad M, 2006, IEEE T INFORM THEORY, V52, P5559, DOI 10.1109/TIT.2006.885522; FADILI MJ, 2006, ASTRONOMICAL DATA AN; Fadili MJ, 2009, COMPUT J, V52, P64, DOI 10.1093/comjnl/bxm055; FIGUEIREDO MA, 2007, GRADIENT PROJECTION; Ventura RMFI, 2006, IEEE T IMAGE PROCESS, V15, P726, DOI 10.1109/TIP.2005.860596; Fischer S., 2001, Proceedings 11th International Conference on Image Analysis and Processing, DOI 10.1109/ICIAP.2001.957047; Gribonval R, 2001, IEEE T SIGNAL PROCES, V49, P994, DOI 10.1109/78.917803; Herrity K. K., 2006, P IEEE INT C AC SPEE, V3, P624; Huggins PS, 2007, IEEE T SIGNAL PROCES, V55, P3760, DOI 10.1109/TSP.2007.894287; Jost P, 2006, IEEE T SIGNAL PROCES, V54, P4685, DOI 10.1109/TSP.2006.882080; Mallat S., 1998, WAVELET TOUR SIGNAL; Neff R, 2002, IEEE T CIRC SYST VID, V12, P13, DOI 10.1109/76.981842; Pati Y. C., 1993, P 27 AS C SIGN SYST, V1, P40, DOI DOI 10.1109/ACSSC.1993.342465; Pece AEC, 2002, J MATH IMAGING VIS, V17, P89, DOI 10.1023/A:1020677318841; Pennec E. L., 2005, IEEE T IMAGE PROCESS, V14, P423; Reeves T. H., 2002, Proceedings 2002 International Conference on Image Processing (Cat. No.02CH37396), DOI 10.1109/ICIP.2002.1039041; SHARON Y, 2007, COMPUTATION RELAXATI; Starck JL, 2003, SIGNAL PROCESS, V83, P2279, DOI 10.1016/S0165-1684(03)00150-6; Wang BB, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/42761; YANG JY, 2007, P IEEE INT S CIRC SY, P297; YANG JY, 2009, TSINGHUA SC IN PRESS, V14; Zhang CM, 2005, CHINESE SCI BULL, V50, P2672, DOI 10.1360/982004-81	51	14	21	5	25	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1009-2757			SCI CHINA SER F	Sci. China Ser. F-Inf. Sci.	APR	2009	52	4					695	703		10.1007/s11432-009-0045-5		9	Computer Science, Information Systems	Computer Science	429ME	WOS:000264923700013		
J	Hall, P; Lee, ER; Park, BU				Hall, Peter; Lee, Eun Ryung; Park, Byeong U.			BOOTSTRAP-BASED PENALTY CHOICE FOR THE LASSO, ACHIEVING ORACLE PERFORMANCE	STATISTICA SINICA			English	Article						Adaptive inference; bootstrap; m-out-of-n bootstrap; optimality properties; prediction; regression; variable selection	LARGE UNDERDETERMINED SYSTEMS; ATOMIC DECOMPOSITION; NONNEGATIVE GARROTE; VARIABLE SELECTION; WAVELET SHRINKAGE; BASIS PURSUIT; MINIMIZATION; LIKELIHOOD; EQUATIONS	In theory, if penalty parameters are chosen appropriately then the lasso can eliminate unnecessary variables in prediction problems, and improve the performance of predictors based on the variables that remain. However, standard methods for tuning-parameter choice, for example techniques based on the bootstrap or cross-validation, are not sufficiently accurate to achieve this level of precision. Until Zou's (2006) proposal for an inversely-weighted lasso, this difficulty led to speculation that it might not be possible to achieve oracle performance using the lasso. In the present paper we show that a straight forward application of the m-out-of-n bootstrap produces adaptive penalty estimates that confer oracle properties on the lasso. The application is of interest in its own right since, unlike many uses of the m-out-of-n bootstrap, it is not designed to estimate a non-normal distribution; the limiting distributions of regression parameter estimators are normal. Instead, the m-out-of-n bootstrap overcomes the tendency of the standard bootstrap to confound the errors committed in determining whether or not a parameter value is zero, with estimation errors for nonzero parameters.	[Hall, Peter] Univ Melbourne, Dept Math & Stat, Melbourne, Vic 3010, Australia; [Lee, Eun Ryung; Park, Byeong U.] Seoul Natl Univ, Dept Stat, Seoul 151747, South Korea	Hall, P (reprint author), Univ Melbourne, Dept Math & Stat, Melbourne, Vic 3010, Australia.	halpstat@ms.unimelb.edu.au; silverryuee@gmail.com; bupark2000@gmail.com			Australian Research Council; Korea Science and Engineering Foundation(KOSEF); Korea government (MOST) [R01-2007000-10143-0]	Research of Hall was supported by an Australian Research Council grant. Research of Park was supported by the Korea Science and Engineering Foundation(KOSEF) grant funded by the Korea government (MOST) (No. R01-2007000-10143-0).	BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Knight K, 2000, ANN STAT, V28, P1356; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Ferris MC, 2004, OPTIM METHOD SOFTW, V19, P577, DOI 10.1080/1055678042000221719; GAO HY, 1998, J COMPUT GRAPH STAT, V7, P469, DOI DOI 10.2307/1390677; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Petrov V. V., 1975, SUMS INDEPENDENT RAN; Tropp JA, 2005, IEEE T INFORM THEORY, V51, P1568, DOI 10.1109/TIT.2005.844057	17	10	10	1	4	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405	1996-8507		STAT SINICA	Stat. Sin.	APR	2009	19	2					449	471				23	Statistics & Probability	Mathematics	437EK	WOS:000265469000004		
J	Wu, YC; Liu, YF				Wu, Yichao; Liu, Yufeng			VARIABLE SELECTION IN QUANTILE REGRESSION	STATISTICA SINICA			English	Article						DCA; LASSO; oracle; quantile regression; SCAD; variable selection	NONCONCAVE PENALIZED LIKELIHOOD; PROPORTIONAL HAZARDS MODEL; SUPPORT VECTOR MACHINES; ORACLE PROPERTIES; LONGITUDINAL DATA; ADAPTIVE LASSO; GROWTH CHARTS; ASYMPTOTICS; PARAMETERS; ALGORITHMS	After its inception in Koenker and Bassett (1978), quantile regression has become an important and widely used technique to study the whole conditional distribution of a response variable and grown into an important tool of applied statistics over the last three decades. In this work, we focus oil the variable selection aspect of penalized quantile regression. Under some mild conditions, we demonstrate the oracle properties of the SCAD and adaptive-LASSO penalized quantile regressions. For the SCAD penalty, despite its good asymptotic properties, the corresponding optimization problem is non-convex and, as a result, much harder to solve. In this work, we take advantage of the decomposition of the SCAD penalty function as the difference of two convex functions and propose to solve the corresponding optimization using the Difference Convex Algorithm (DCA).	[Wu, Yichao] N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA; [Liu, Yufeng] Univ N Carolina, Dept Stat & Operat Res, Chapel Hill, NC 27599 USA	Wu, YC (reprint author), N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA.	wu@stat.ncsu.edu; yfliu@email.unc.edu			NSF [DMS-06-06577, R01-CM07261]	We would like to thank Professor Jianqing Fan for his helpful comments and suggestions. This research is partially supported by NSF grant DMS-06-06577 and NIH grant R01-CM07261.	KOENKER R, 1978, ECONOMETRICA, V46, P33, DOI 10.2307/1913643; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Wang HS, 2007, J BUS ECON STAT, V25, P347, DOI 10.1198/073500106000000251; Liu YF, 2005, J COMPUT GRAPH STAT, V14, P219, DOI 10.1198/106186005X37238; An LTH, 1997, J GLOBAL OPTIM, V11, P253; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zhang HH, 2006, BIOINFORMATICS, V22, P88, DOI 10.1093/bioinformatics/bti736; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Koenker R, 2001, J AM STAT ASSOC, V96, P458, DOI 10.1198/016214501753168172; Wu YC, 2007, J AM STAT ASSOC, V102, P974, DOI 10.1198/016214507000000617; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2; Breiman L, 1996, ANN STAT, V24, P2350; FAN J, 2006, SURE INDEPENDE UNPUB; Fan J., 1997, J ITALIAN STAT ASS, V6, P131; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Fan JQ, 2002, ANN STAT, V30, P74; Fan JQ, 2004, J AM STAT ASSOC, V99, P710, DOI 10.1198/0162145040000001060; GEYER CJ, 1994, ANN STAT, V22, P1993, DOI 10.1214/aos/1176325768; He XM, 2000, J MULTIVARIATE ANAL, V73, P120, DOI 10.1006/jmva.1999.1873; HENDRICKS W, 1992, J AM STAT ASSOC, V87, P58, DOI 10.2307/2290452; Hoerl A., 1988, ENCY STAT SCI, V8, P129; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Knight K, 1999, CAN J STAT, V27, P497, DOI 10.2307/3316107; Kocherginsky M, 2005, J COMPUT GRAPH STAT, V14, P41, DOI 10.1198/106186005X27563; Koenker R, 2001, J ECON PERSPECT, V15, P143, DOI 10.1257/jep.15.4.143; KOENKER R, 1994, BIOMETRIKA, V81, P673; Koenker R, 2005, QUANTILE REGRESSION; Koenker R, 2004, J MULTIVARIATE ANAL, V91, P74, DOI 10.1016/j.jmva.2004.05.006; LI Y, 2005, J COMPUT GR IN PRESS; Li YJ, 2007, J AM STAT ASSOC, V102, P255, DOI 10.1198/016214506000000979; Liu SJ, 2005, SIAM PROC S, P1; Liu YF, 2007, J COMPUT GRAPH STAT, V16, P782, DOI 10.1198/106186007X255676; POLLARD D, 1991, ECONOMET THEOR, V7, P186; Wang HX, 2007, J AM STAT ASSOC, V102, P104, DOI 10.1198/016214506000001220; Wei Y, 2006, STAT MED, V25, P1369, DOI 10.1002/sim.2271; Wei Y, 2006, ANN STAT, V34, P2069, DOI 10.1214/009053606000000623; Yang S, 1999, J AM STAT ASSOC, V94, P137, DOI 10.2307/2669689; Zhang HH, 2007, BIOMETRIKA, V94, P691, DOI 10.1093/biomet/asm037; ZOU H, 2007, ANN STAT IN PRESS	43	64	66	2	9	STATISTICA SINICA	TAIPEI	C/O DR H C HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN	1017-0405			STAT SINICA	Stat. Sin.	APR	2009	19	2					801	817				17	Statistics & Probability	Mathematics	437EK	WOS:000265469000022		
J	Shimamura, T; Imoto, S; Yamaguchi, R; Fujita, A; Nagasaki, M; Miyano, S				Shimamura, Teppei; Imoto, Seiya; Yamaguchi, Rui; Fujita, Andre; Nagasaki, Masao; Miyano, Satoru			Recursive regularization for inferring gene networks from time-course gene expression profiles	BMC SYSTEMS BIOLOGY			English	Article							REGULATORY NETWORKS; VARIABLE SELECTION; MODEL SELECTION; REGRESSION SHRINKAGE; ROBUST REGRESSION; LASSO	Background: Inferring gene networks from time-course microarray experiments with vector autoregressive (VAR) model is the process of identifying functional associations between genes through multivariate time series. This problem can be cast as a variable selection problem in Statistics. One of the promising methods for variable selection is the elastic net proposed by Zou and Hastie (2005). However, VAR modeling with the elastic net succeeds in increasing the number of true positives while it also results in increasing the number of false positives. Results: By incorporating relative importance of the VAR coefficients into the elastic net, we propose a new class of regularization, called recursive elastic net, to increase the capability of the elastic net and estimate gene networks based on the VAR model. The recursive elastic net can reduce the number of false positives gradually by updating the importance. Numerical simulations and comparisons demonstrate that the proposed method succeeds in reducing the number of false positives drastically while keeping the high number of true positives in the network inference and achieves two or more times higher true discovery rate (the proportion of true positives among the selected edges) than the competing methods even when the number of time points is small. We also compared our method with various reverse-engineering algorithms on experimental data of MCF-7 breast cancer cells stimulated with two ErbB ligands, EGF and HRG. Conclusion: The recursive elastic net is a powerful tool for inferring gene networks from time-course gene expression profiles.	[Shimamura, Teppei; Imoto, Seiya; Yamaguchi, Rui; Fujita, Andre; Nagasaki, Masao; Miyano, Satoru] Univ Tokyo, Ctr Human Genome, Inst Med Sci, Minato Ku, Tokyo 1088639, Japan	Shimamura, T (reprint author), Univ Tokyo, Ctr Human Genome, Inst Med Sci, Minato Ku, 4-6-1 Shirokanedai, Tokyo 1088639, Japan.	shima@ims.u-tokyo.ac.jp; imoto@ims.u-tokyo.ac.jp; ruiy@ims.u-tokyo.ac.jp; afujita@ims.u-tokyo.ac.jp; masao@ims.u-tokyo.ac.jp; miyano@ims.u-tokyo.ac.jp			RIKEN; MEXT, Japan	We are grateful to Dr. Rainer Opgen-Rhein for providing the R program code of the James-Stein procedure and to anonymous reviewers for many constructive comments and suggestions. This work was supported by the Next-Generation Supercomputer Project under RIKEN and MEXT, Japan. The computational resource was also provided by the Super Computer System, Human Genome Center, Institute of Medical Science, University of Tokyo.	Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wang HS, 2007, J BUS ECON STAT, V25, P347, DOI 10.1198/073500106000000251; Yuan M, 2007, J ROY STAT SOC B, V69, P143, DOI 10.1111/j.1467-9868.2007.00581.x; Yeung MKS, 2002, P NATL ACAD SCI USA, V99, P6163, DOI 10.1073/pnas.092576199; Wang HS, 2008, COMPUT STAT DATA AN, V52, P5277, DOI 10.1016/j.csda.2008.05.006; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Fan JQ, 2008, J ROY STAT SOC B, V70, P849, DOI 10.1111/j.1467-9868.2008.00674.x; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Ballman KV, 2004, BIOINFORMATICS, V20, P2778, DOI 10.1093/bioinformatics/bth327; Basso K, 2005, NAT GENET, V37, P382, DOI 10.1038/ng1532; Breiman L, 1996, ANN STAT, V24, P2350; Csardi G., IGRAPH REFERENCE MAN; di Bernardo D, 2005, NAT BIOTECHNOL, V23, P377, DOI 10.1038/nbt1075; Faith JJ, 2007, PLOS BIOL, V5, P54, DOI 10.1371/journal.pbio.0050008; Fujita A, 2007, BMC SYST BIOL, V1, DOI 10.1186/1752-0509-1-39; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Granger C.W.J., 1969, ECONOMETRICA, V37, P424, DOI DOI 10.2307/1912791; HURVICH CM, 1991, BIOMETRIKA, V78, P521; Imoto S, 2006, PAC S BIOC, V11, P559; Leng CL, 2006, STAT SINICA, V16, P1273; Meyer PE, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-461; Meyer Patrick E, 2007, EURASIP J Bioinform Syst Biol, P79879, DOI 10.1155/2007/79879; Miller A, 2002, SUBSET SELECTION REG, V2nd; Nagasaki Masao, 2003, Appl Bioinformatics, V2, P181; Nagashima T, 2007, J BIOL CHEM, V282, P4045, DOI 10.1074/jbc.M608653200; *NCBI, GSE6462 NCBI; Opgen-Rhein R, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S2-S3; Shimamura T, 2007, GENOME INFORM SER, V19, P142; SUGIURA N, 1978, COMMUN STAT A-THEOR, V7, P13, DOI 10.1080/03610927808827599; Tamada Yoshinori, 2005, Genome Inform, V16, P182; Wang Y, 2006, BIOINFORMATICS, V22, P2413, DOI 10.1093/bioinformatics/btl396; ZHANG H, 2006, BIOMETRIKA, V94, P691; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127; TRANSPATH PATHWAY DA; CELL ILLUSTRATOR	38	18	19	1	4	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1752-0509			BMC SYST BIOL	BMC Syst. Biol.	APR 22	2009	3								41	10.1186/1752-0509-3-41		13	Mathematical & Computational Biology	Mathematical & Computational Biology	458CB	WOS:000266989200001	19386091	
J	Healy, BC; Engler, D				Healy, Brian C.; Engler, David			Modeling disease-state transition heterogeneity through Bayesian variable selection	STATISTICS IN MEDICINE			English	Article						Bayesian variable selection; Markov transition models; multinomial logit models; Multiple sclerosis	MULTIPLE-SCLEROSIS; PROGRESSION; DISABILITY; TIME	In many diseases, Markov transition models are useful in describing transitions between discrete disease states. Often the probability of transitioning from one state to another varies widely across subjects. This heterogeneity is driven, in part, by a possibly unknown number of previous disease states and by potentially complex relationships between clinical data and these states. We propose use of Bayesian variable selection in Markov transition models to allow estimation of subject-specific transition probabilities. Our approach simultaneously estimates the order of the Markov process and the transition-specific covariate effects. The methods are assessed using Simulation studies and applied to model disease-state transition on the expanded disability status scale (EDSS) in multiple sclerosis (MS) patients from the Partners MS Center in Boston, MA. The proposed methodology is shown to accurately identify complex covariate-transition relationships in simulations and identifies a clinically significant interaction between relapse history and EDSS history in MS patients. Copyright (C) 2009 John Wiley & Sons, Ltd.	[Healy, Brian C.] Harvard Univ, Brigham & Womens Hosp, Sch Med, Dept Neurol,Partners MS Ctr, Boston, MA 02115 USA; [Healy, Brian C.] Massachusetts Gen Hosp, Ctr Biostat, Boston, MA 02114 USA; [Engler, David] Brigham Young Univ, Dept Stat, Provo, UT 84602 USA	Engler, D (reprint author), 223 TMCB, Provo, UT 84602 USA.	engler@byu.edu			Partners MS Center	We would like to thank Micha Mandel and the reviewers for helpful comments, and the Partners MS Center for access to the data and funding this research.	ALBERT PS, 1994, BIOMETRICS, V50, P51, DOI 10.2307/2533196; KURTZKE JF, 1983, NEUROLOGY, V33, P1444; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Hoeting JA, 1999, STAT SCI, V14, P382; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Bock R. D., 1975, MULTIVARIATE STAT ME; Chipman H, 2001, IMS LECT NOTES MONOG, V38, P67; Clyde M., 1999, BAYESIAN INFERENCE W, P309; Compston A, 2006, MCALPINES MULTIPLE S, V4th; de Leeuw J, 2007, HDB MULTILEVEL ANAL; Diggle P. J., 1994, ANAL LONGITUDINAL DA; Erkanli A, 2001, STAT MED, V20, P755, DOI 10.1002/sim.702; Foulkes AS, 2003, J AM STAT ASSOC, V98, P859, DOI 10.1198/016214503000000792; Gauthier SA, 2006, AUTOIMMUN REV, V5, P532, DOI 10.1016/j.autrev.2006.02.012; Gauthier SA, 2007, NEUROLOGY, V68, P2059, DOI 10.1212/01.wnl.0000264890.97479.b1; George EI, 1997, STAT SINICA, V7, P339; Geweke J., 1996, BAYESIAN STAT, V5, P609; MANDEL M, 2008, BIOSTATISTICS, DOI DOI 10.1093/BIOSTATISTICS/KXN008; Mandel M, 2007, J AM STAT ASSOC, V102, P1254, DOI 10.1198/016214507000000059; Sung MJ, 2007, STAT MED, V26, P3000, DOI 10.1002/sim.2775; Tuchler R, 2008, J COMPUT GRAPH STAT, V17, P76, DOI 10.1198/106186008X289849; Yuan M, 2005, J AM STAT ASSOC, V100, P1215, DOI 10.1198/016214505000000367; Zeghnoun A, 2003, ENVIRONMETRICS, V14, P271, DOI 10.1002/env.585	24	3	3	0	1	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	0277-6715			STAT MED	Stat. Med.	APR 30	2009	28	9					1353	1368		10.1002/sim.3545		16	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Medicine, Research & Experimental; Statistics & Probability	Mathematical & Computational Biology; Public, Environmental & Occupational Health; Medical Informatics; Research & Experimental Medicine; Mathematics	434YG	WOS:000265309600003	19206077	
J	Wu, MC; Zhang, LS; Wang, ZX; Christiani, DC; Lin, XH				Wu, Michael C.; Zhang, Lingsong; Wang, Zhaoxi; Christiani, David C.; Lin, Xihong			Sparse linear discriminant analysis for simultaneous testing for the significance of a gene set/pathway and gene selection	BIOINFORMATICS			English	Article							SKELETAL-MUSCLE; EXPRESSION; INSULIN; LIVER; METABOLISM; DIMENSION; OBESE	Motivation: Pathway and gene set-based approaches for the analysis of gene expression pro. ling experiments have become increasingly popular for addressing problems associated with individual gene analysis. Since most genes are not differently expressed, existing gene set tests, which consider all the genes within a gene set, are subject to considerable noise and power loss, a concern exacerbated in studies in which the degree of differential expression is moderate for truly differentially expressed genes. For a significantly differentially expressed pathway, it is also of substantial interest to select important genes that drive the differential expression of the pathway. Methods: We develop a unified framework to jointly test the significance of a pathway and to select a subset of genes that drive the significant pathway effect. To achieve dimension reduction and gene selection, we decompose each gene pathway into a single score by using a regularized form of linear discriminant analysis, called sparse linear discriminant analysis (sLDA). Testing for the significance of the pathway effect proceeds via permutation of the sLDA score. The sLDA-based test is compared with competing approaches with simulations and two applications: a study on the effect of metal fume exposure on immune response and a study of gene expression profiles among Type II Diabetes patients. Results: Our results show that sLDA-based testing provides a powerful approach to test for the significance of a differentially expressed pathway and gene selection.	[Wu, Michael C.; Zhang, Lingsong; Lin, Xihong] Harvard Univ, Sch Publ Hlth, Dept Biostat, Boston, MA 02115 USA; [Wang, Zhaoxi; Christiani, David C.] Harvard Univ, Sch Publ Hlth, Dept Environm Hlth, Boston, MA 02115 USA	Lin, XH (reprint author), Harvard Univ, Sch Publ Hlth, Dept Biostat, 655 Huntington Ave, Boston, MA 02115 USA.				National Cancer Institute [R37-CA-76404, R01-CA-074386]	National Cancer Institute (R37-CA-76404 and R01-CA-074386, in parts).	Ahn J, 2007, BIOMETRIKA, V94, P760, DOI 10.1093/biomet/asm050; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tian L, 2005, P NATL ACAD SCI USA, V102, P13544, DOI 10.1073/pnas.0506577102; Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102; Goeman JJ, 2004, BIOINFORMATICS, V20, P93, DOI 10.1093/bioinformatics/btg382; Goeman JJ, 2007, BIOINFORMATICS, V23, P980, DOI 10.1093/bioinformatics/btm051; Draghici S, 2003, GENOMICS, V81, P98, DOI 10.1016/S0888-7543(02)00021-6; Ashburner M, 2000, NAT GENET, V25, P25; Mootha VK, 2003, NAT GENET, V34, P267, DOI 10.1038/ng1180; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628; FENG J, 2003, ADV DATA MINING MODE, V15, P25; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fung Eric S, 2007, Bioinformation, V2, P230; Hittel DS, 2005, DIABETES, V54, P1283, DOI 10.2337/diabetes.54.5.1283; LEMIEUX G, 1984, CAN J PHYSIOL PHARM, V62, P70; Li C, 2001, GENOME BIOL, V2; Maniratanachote R, 2005, TOXICOLOGY, V216, P15, DOI 10.1016/j.tox.2005.07.012; MARCUS F, 1980, J BIOL CHEM, V255, P2481; Morral N, 2007, J LIPID RES, V48, P1499, DOI 10.1194/jlr.M700090-JLR200; Nakanishi N, 2004, DIABETES CARE, V27, P1427, DOI 10.2337/diacare.27.6.1427; OH H, 2005, INVEST OPHTH VIS SCI, V46, P426; PARKS WC, 1982, BIOCHEM J, V208, P333; Tomfohr J, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-225; WU M, 2008, 2 GROUP CLASSIFICATI; Yang X, 2002, DIABETOLOGIA, V45, P1584, DOI 10.1007/s00125-002-0905-7	29	30	32	2	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803	1460-2059		BIOINFORMATICS	Bioinformatics	MAY 1	2009	25	9					1145	1151		10.1093/bioinformatics/btp019		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	437YR	WOS:000265523300008	19168911	
J	Wang, ZT; Tan, SH				Wang, Zitian; Tan, Shaohua			Identifying idiosyncratic stock return indicators from large financial factor set via least angle regression	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Risk-return modeling; Variable selection; Financial factor analysis; LARS	SELECTION; LASSO; RISK	Identifying important indicating factors for expected level of stock return has been one of the central problems in modern finance. Researchers have worked on different candidate sets of indicators from different perspectives, but there has not been a consensus reached on which factors to be included in the model. in this paper, based on relative complete information from a large set of factors from US financial reports, we use least angle regression (LARS) to select a sparse and relatively stable set of indicators for predicting stock return. The use of LARS is consistent with the theoretically well developed economic theory arbitrage pricing model. The empirical results offer new insights of the well-known indicators from the previous studies and discover new important factors. (C) 2008 Elsevier Ltd. All rights reserved.	[Wang, Zitian; Tan, Shaohua] Peking Univ, Dept Intelligence Sci, Beijing 100871, Peoples R China	Wang, ZT (reprint author), Peking Univ, Dept Intelligence Sci, Beijing 100871, Peoples R China.	wzt@cis.pku.edu.cn					Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Campbell JY, 1998, J PORTFOLIO MANAGE, V24, P11, DOI 10.3905/jpm.24.2.11; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Efron B, 2004, ANN STAT, V32, P407; Bodie Z., 2005, INVESTMENTS, V6th; Chatfield C., 2004, ANAL TIME SERIES INT; Chu HH, 2009, EXPERT SYST APPL, V36, P165, DOI 10.1016/j.eswa.2007.09.037; Daniel K, 1997, J FINANC, V52, P1, DOI 10.2307/2329554; Enke D, 2005, EXPERT SYST APPL, V29, P927, DOI 10.1016/j.eswa.2005.06.024; Fama E., 1992, J FINANC, P427; FAMA EF, 1993, J FINANC ECON, V33, P3, DOI 10.1016/0304-405X(93)90023-5; Fan J., 2005, NONLINEAR TIME SERIE; KOTHARI SP, 1995, J FINANC, V50, P185, DOI 10.2307/2329243; LAI RK, 2008, EXPERT SYSTEMS APPL, V36, P3761; Lettau M, 2001, J FINANC, V56, P815, DOI 10.1111/0022-1082.00347; Quah TS, 1999, EXPERT SYST APPL, V17, P295, DOI 10.1016/S0957-4174(99)00041-X; ROSS SA, 1976, J ECON THEORY, V13, P341, DOI 10.1016/0022-0531(76)90046-6; SHARPE WF, 1964, J FINANC, V19, P425, DOI 10.2307/2977928; Sharpe WF, 2007, PRINC LECT FINANC, P1; Stock J. H., 2002, J AM STAT ASSOC, V97, P147	20	2	2	2	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	MAY	2009	36	4					8350	8355		10.1016/j.eswa.2008.10.018		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	423WX	WOS:000264528600117		
J	Guo, W; Lin, SL				Guo, Wei; Lin, Shili			Generalized Linear Modeling with Regularization for Detecting Common Disease Rare Haplotype Association	GENETIC EPIDEMIOLOGY			English	Article						whole genome association study; interacting effects between haplotype blocks; dimension reduction; regularization/LASSO; case-control design	UNPHASED GENOTYPE DATA; NUCLEOTIDE-POLYMORPHISM HAPLOTYPES; TRAIT ASSOCIATIONS; SNP HAPLOTYPES; LUNG-CANCER; INFERENCE; LIKELIHOOD; LASSO; ATTRIBUTES; SELECTION	Whole genome association Studies (WGAS) have surged in popularity in recent years as technological advances have made large-scale genotyping more feasible and as new exciting results offer tremendous hope and optimism. The logic of WGAS rests upon the common disease/common variant (CD/CV) hypothesis. Detection of association under the common disease/rare variant (CD/RV) scenario is much harder, and the current practices of WGAS may be under-power without large enough sample sizes. In this article, we propose a generalized linear model with regularization (rGLM) approach for detecting disease-haplotype association using unphased single nucleotide polymorphisms data that is applicable to both CD/CV and CD/RV scenarios. We borrow a dimension-reduction method from the data mining and statistical learning literature, but use it for the purpose of weeding out haplotypes that are not associated with the disease so that the associated haplotypes, especially those that are rare, can stand Out and be accounted for more precisely. By using high-dimensional data analysis techniques, which are frequently employed in microarray analyses, interacting effects among haplotypes in different blocks can be investigated without much concern about the sample size being overwhelmed by the number of haplotype combinations. Our simulation study demonstrates the gain in power for detecting associations with moderate sample sizes. For detecting association under CD/RV, regression type methods such as that implemented in hapassoc may fail to provide coefficient estimates for rare associated haplotypes, resulting in a loss of power compared to rGLM. Furthermore, our results indicate that rGLM can uncover the associated variants much more frequently than can hapassoc. Genet. Epidemiol. 33:308-316, 2009. (C) 2008 Wiley-Liss, Inc.	[Guo, Wei; Lin, Shili] Ohio State Univ, Dept Stat, Columbus, OH 43210 USA; [Lin, Shili] Ohio State Univ, Math Biosci Inst, Columbus, OH 43210 USA	Lin, SL (reprint author), Ohio State Univ, Dept Stat, 1958 Neil Ave, Columbus, OH 43210 USA.	shili@stat.osu.edu			National Institutes of Health [NS046696]; National Science Foundation [DMS-0112050]; Biomedical Research and Technology Transfer [05-062]	Contract grant sponsor: National Institutes of Health; Contract grant number: NS046696; Contract grant sponsor: National Science Foundation; Contract grant number: DMS-0112050; Contract grant sponsor: Biomedical Research and Technology Transfer; Contract grant number: 05-062.	Akaike H., 1973, 2 INT S INF THEOR, P267; Akey J, 2001, EUR J HUM GENET, V9, P292; AMOS CI, 2008, NAT GENET; Zhao JH, 2000, HUM HERED, V50, P133, DOI 10.1159/000022901; Zaykin DV, 2002, HUM HERED, V53, P79, DOI 10.1159/000057986; Morris RW, 2002, GENET EPIDEMIOL, V23, P221, DOI 10.1002/gepi.10200; Durrant C, 2004, AM J HUM GENET, V75, P35, DOI 10.1086/422174; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Schaid DJ, 2002, AM J HUM GENET, V70, P425, DOI 10.1086/338688; Fallin D, 2001, GENOME RES, V11, P143, DOI 10.1101/gr.148401; Epstein MP, 2003, AM J HUM GENET, V73, P1316, DOI 10.1086/380204; Li Y, 2007, AM J HUM GENET, V80, P705, DOI 10.1086/513205; Tzeng JY, 2005, GENET EPIDEMIOL, V28, P220, DOI 10.1002/gepi.20063; Burkett K, 2006, J STAT SOFTW, V16, P1; Rosenberg PS, 2006, STAT MED, V25, P3134, DOI 10.1002/sim.2407; Molitor J, 2003, AM J HUM GENET, V73, P1368, DOI 10.1086/380415; Becker T, 2004, AM J HUM GENET, V75, P561, DOI 10.1086/424390; Burkett K, 2004, HUM HERED, V57, P200, DOI 10.1159/000081447; Chanock SJ, 2008, NATURE, V452, P537, DOI 10.1038/452537a; Gorlov IP, 2008, AM J HUM GENET, V82, P100, DOI 10.1016/j.ajhg.2007.09.006; Horel A. E., 1970, TECHNOMETRICS, V12, P55; Hung RJ, 2008, NATURE, V452, P633, DOI 10.1038/nature06885; PRENTICE RL, 1979, BIOMETRIKA, V66, P403, DOI 10.1093/biomet/66.3.403; Purcell S, 2007, AM J HUM GENET, V81, P559, DOI 10.1086/519795; RISCH N, 1996, SCIENCE, V273, P1517; Satten GA, 2004, GENET EPIDEMIOL, V27, P192, DOI 10.1002/gepi.20020; Seltman H, 2003, GENET EPIDEMIOL, V25, P48, DOI 10.1002/gepi.10246; Souverein OW, 2006, HUM HERED, V61, P104, DOI 10.1159/000093476; STONE M, 1974, J R STAT SOC B, V36, P111; Stram DO, 2003, HUM HERED, V55, P27, DOI 10.1159/000071807; Thorgeirsson TE, 2008, NATURE, V452, P638, DOI 10.1038/nature06846; van de Geer SA, 2008, ANN STAT, V36, P614, DOI 10.1214/009053607000000929; Weir B, 1996, GENETIC DATA ANAL; Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127	36	25	26	0	2	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0741-0395			GENET EPIDEMIOL	Genet. Epidemiol.	MAY	2009	33	4					308	316		10.1002/gepi.20382		9	Genetics & Heredity; Public, Environmental & Occupational Health	Genetics & Heredity; Public, Environmental & Occupational Health	440UJ	WOS:000265724900004	19025789	
J	de los Campos, G; Naya, H; Gianola, D; Crossa, J; Legarra, A; Manfredi, E; Weigel, K; Cotes, JM				de los Campos, Gustavo; Naya, Hugo; Gianola, Daniel; Crossa, Jose; Legarra, Andres; Manfredi, Eduardo; Weigel, Kent; Cotes, Jose Miguel			Predicting Quantitative Traits With Regression Models for Dense Molecular Markers and Pedigree	GENETICS			English	Article							GENOMIC-ASSISTED PREDICTION; COMPLEX TRAITS; GENETIC VALUE; PLANT-POPULATIONS; BAYESIAN LASSO; SELECTION; ASSOCIATION; MICE; INFORMATION; SHRINKAGE	The availability of genomewide dense markers brings opportunities and challenges to breeding programs. An important question concerns the ways in which dense markers and pedigrees, together with phenotypic records, should be used to arrive at predictions of genetic values for complex traits. If a large number of markers are included in a regression model, marker-specific shrinkage of regression coefficients may be needed. For this reason, the Bayesian least. absolute shrinkage and selection operator (LASSO) (BL) appears to be an interesting approach for fitting marker effects in a regression model. This article adapts the BL to arrive at a regression model where markers, pedigrees, and covariates other than markers are considered jointly Connections between BL and other marker-based regression models are discussed, and the sensitivity of BL with respect to the choice of prior distributions assigned to key parameters is evaluated using simulation. The proposed model was fitted to two data sets from wheat and mouse Populations, and evaluated using cross-validation methods. Results indicate that inclusion of markers in the regression further improved the predictive ability of models. An R program that implements the proposed model is freely available.	[de los Campos, Gustavo; Gianola, Daniel] Univ Wisconsin, Dept Anim Sci, Madison, WI 53706 USA; [Weigel, Kent] Univ Wisconsin, Dept Dairy Sci, Madison, WI 53706 USA; [Naya, Hugo] Inst Pasteur, Bioinformat Unit, Montevideo 11400, Uruguay; [Crossa, Jose; Cotes, Jose Miguel] CIMMYT, Crop Res Informat Lab, Biometr & Stat Unit, Int Maize & Wheat Improvement Ctr, Mexico City 06600, DF, Mexico; [Legarra, Andres; Manfredi, Eduardo] INRA, Stn Ameliorat Genet Anim, UR SAGA 631, F-31326 Castanet Tolosan, France	de los Campos, G (reprint author), Univ Wisconsin, Dept Anim Sci, 1675 Observ Dr, Madison, WI 53706 USA.	gdeloscampos@wisc.edu	Legarra, Andres/G-9451-2012	Legarra, Andres/0000-0001-8893-7620	Wisconsin Agriculture Experiment Station [DMS-NSF DMS-044371]; Midi-Pyrennees Region, France	We greatly appreciate suggestions of two anonymous reviewers and of the Associate Editor. The Wellcome Trust Center for Human Genetics, Oxford, is gratefully acknowledged for making the mouse data available at http://gscan.well.ox.ac.uk. Vivi Arief from the School of Land Crop and Food Sciences of the University of Queensland, Australia, is thanked for assembling the historical wheat phenotypic and molecular marker data and for computing additive relationships between wheat lines. Financial support by the Wisconsin Agriculture Experiment Station, grant DMS-NSF DMS-044371, and by the Chaire D'Excellence Pierre de Fermat programme of the Midi-Pyrennees Region, France, is acknowledged.	ANDREWS DF, 1974, J ROY STAT SOC B MET, V36, P99; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Habier D, 2007, GENETICS, V177, P2389, DOI 10.1534/genetics.107.081190; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; Wang WYS, 2005, NAT REV GENET, V6, P109, DOI 10.1038/nrg1522; Meuwissen THE, 2001, GENETICS, V157, P1819; Bink MCAM, 2002, THEOR APPL GENET, V104, P751, DOI 10.1007/s00122-001-0796-x; Bink MCAM, 2008, EUPHYTICA, V161, P85, DOI 10.1007/s10681-007-9516-1; Chhikara R. S., 1989, INVERSE GAUSSIAN DIS; Crossa J, 2007, GENETICS, V177, P1889, DOI 10.1534/genetics.107.078659; DELOSCAMPOS G, 2009, J ANIM SCI IN PRESS; FERNANDO RL, 1989, GENET SEL EVOL, V21, P467, DOI 10.1051/gse:19890407; Fernando RL, 2007, ACTA AGR SCAND A-AN, V57, P192, DOI 10.1080/09064700801959395; Gianola D, 2008, GENETICS, V178, P2289, DOI 10.1534/genetics.107.084285; Gianola D, 2006, GENETICS, V173, P1761, DOI 10.1534/genetics.105.049510; Gianola D, 2003, GENETICS, V163, P347; HANS C, 2008, 810 OH STAT U DEP ST; Legarra A, 2008, GENETICS, V180, P611, DOI 10.1534/genetics.108.088575; McLaren CG, 2005, PLANT PHYSIOL, V139, P637, DOI 10.1104/pp.105.063438; Plummer M., 2008, CODA OUTPUT ANAL DIA; R Development Core Team, 2008, R LANG ENV STAT COMP; ROSA GJM, 1999, INT S AN BREED GEN V, P133; ter Braak CJF, 2006, COMPUT STAT DATA AN, V51, P1232, DOI 10.1016/j.csda.2006.06.011; ter Braak CJF, 2005, GENETICS, V170, P1435, DOI 10.1534/genetics.105.040469; Valdar W, 2006, NAT GENET, V38, P879, DOI 10.1038/ng1840; Valdar W, 2006, GENETICS, V174, P959, DOI 10.1534/genetics.106.060004; Xu SZ, 2003, GENETICS, V163, P789; Yi NJ, 2008, GENETICS, V179, P1045, DOI 10.1534/genetics.107.085589	28	150	153	5	32	GENETICS	BALTIMORE	428 EAST PRESTON ST, BALTIMORE, MD 21202 USA	0016-6731			GENETICS	Genetics	MAY	2009	182	1					375	385		10.1534/genetics.109.101501		11	Genetics & Heredity	Genetics & Heredity	499IX	WOS:000270213800032	19293140	
J	Wainwright, MJ				Wainwright, Martin J.			Sharp Thresholds for High-Dimensional and Noisy Sparsity Recovery Using l(1)-Constrained Quadratic Programming (Lasso)	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article; Proceedings Paper	44th Annual Allerton Conference on Communication, Control and Computing	SEP 27-29, 2006	Monticello, IL			Compressed sensing; convex relaxation; high-dimensional inference; l(1)-constraints; model selection; phase transitions; sparse approximation; signal denoising; subset selection	LARGE UNDERDETERMINED SYSTEMS; VARIABLE SELECTION; REPRESENTATIONS; REGRESSION; EQUATIONS; BASES; PAIRS	The problem of consistently estimating the sparsity pattern of a vector beta* is an element of R-p based on observations contaminated by noise arises in various contexts, including signal denoising, sparse approximation, compressed sensing, and model selection. We analyze the behavior of l(1)-constrained quadratic programming (QP), also referred to as the Lasso, for recovering the sparsity pattern. Our main result is to establish precise conditions on the problem dimension p, the number k of nonzero elements in beta* and the number of observations v. that are necessary and sufficient for sparsity pattern recovery using the Lasso. We first analyze the case of observations made using deterministic design matrices and sub-Gaussian additive noise, and provide sufficient conditions for support recovery and l(infinity)-error bounds, as well as results showing the necessity of incoherence and bounds on the minimum value. We then turn to the case of random designs, in which each row of the design is drawn from a N(0, Sigma) ensemble. For a broad class of Gaussian ensembles satisfying mutual incoherence conditions, we compute explicit values of thresholds 0 < theta(l)(Sigma) <= theta(u) (Sigma) < +infinity with the following properties: for any delta > 0, if n > 2 (theta(u) + delta)k log (p - k), then the Lasso succeeds in recovering the sparsity pattern with probability converging to one for large problems, whereas for n < 2(theta(l) - delta)k log(p - k), then the probability of successful recovery converges to zero. For the special case of the uniform Gaussian ensemble (Sigma = I-p (x) (p)), we show that theta(l) = theta(u) = 1, so that the precise threshold n = 2k log(p - k) is exactly determined.	[Wainwright, Martin J.] Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA; [Wainwright, Martin J.] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Wainwright, MJ (reprint author), Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA.						Tropp JA, 2006, IEEE T INFORM THEORY, V52, P1030, DOI 10.1109/TIT.2005.864420; Knight K, 2000, ANN STAT, V28, P1356; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Candes E, 2007, ANN STAT, V35, P2313, DOI 10.1214/009053606000001523; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Efron B, 2004, ANN STAT, V32, P407; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430; Band Johnson W, 2001, HDB GEOMETRY BANACH, V1, P317, DOI 10.1016/S1874-5849(01)80010-3; Bertsekas DP, 1995, NONLINEAR PROGRAMMIN; Buldygin V. V., 2000, METRIC CHARACTERIZAT; Chen Y, 1998, NONCON OPTIM ITS APP, V20, P1; DeVore R.A., 1993, CONSTRUCTIVE APPROXI; DONOHO DL, 2008, J AM MATH SOC    JUL; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131; Feuer A, 2003, IEEE T INFORM THEORY, V49, P1579, DOI 10.1109/TIT.2003.811926; Fuchs JJ, 2005, IEEE T INFORM THEORY, V51, P3601, DOI 10.1109/TIT.2005.855614; GRAY RM, 1990, TOEPLITZ CIRCULANT M; Hiriart-Urruty J. B., 1993, CONVEX ANAL MINIMIZA, VI; JOHNSTONE I, 2001, IMS LECT NOTES, V37, P399; Laurent B., 1998, ANN STAT, V28, P1303; LEDOUX M., 1991, PROBABILITY BANACH S; Ledoux M, 2001, CONCENTRATION MEASUR; MALIOUTOV D, 2004, P IEEE INT C AC SPEE, V2, P793; Miller A. J., 1990, SUBSET SELECTION REG; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; WAINWRIGHT MJ, 2006, P NIPS C VANC BC CAN; WAINWRIGHT MJ, 2006, 709 U CAL BERK DEP S; WAINWRIGHT MJ, 2007, 725 U CAL BERK DEP S; WANG W, 2008, IEEE INT S INF THEOR	37	198	198	2	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	MAY	2009	55	5					2183	2202		10.1109/TIT.2009.2016018		20	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	440PU	WOS:000265713000019		
J	ter Braak, CJF				ter Braak, Cajo J. F.			Regression by L-1 regularization of smart contrasts and sums (ROSCAS) beats PLS and elastic net in latent variable model	JOURNAL OF CHEMOMETRICS			English	Article						PLS; penalized regression; LASSO; elastic net; latent variable model; generalized fused LASSO	LEAST-SQUARES REGRESSION; LINEAR-REGRESSION; STATISTICAL VIEW; SELECTION; SHRINKAGE; LASSO; TOOLS	This paper proposes a regression method, ROSCAS, which regularizes smart contrasts and sums of regression coefficients by an L, penalty. The contrasts and sums are based on the sample correlation matrix of the predictors and are suggested by a latent variable regression model. The contrasts express the idea that a priori correlated predictors should have similar coefficients. The method has excellent predictive performance in situations, where there are groups of predictors with each group representing an independent feature that influences the response. In particular, when the groups differ in size, ROSCAS can outperform LASSO, elastic net, partial least squares (PLS) and ridge regression by a factor of two or three in terms of mean squared error. In other simulation setups and on real data, ROSCAS performs competitively. Copyright (C) 2009 John Wiley & Sons, Ltd.	Univ Wageningen & Res Ctr, NL-6700 AC Wageningen, Netherlands	ter Braak, CJF (reprint author), Univ Wageningen & Res Ctr, Box 100, NL-6700 AC Wageningen, Netherlands.	cajo.terbraak@wur.nl	ter Braak, Cajo/G-7006-2011	ter Braak, Cajo/0000-0002-0414-8745			WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Swierenga H, 1999, CHEMOMETR INTELL LAB, V49, P1, DOI 10.1016/S0169-7439(99)00028-3; Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Tibshirani R, 2005, J ROY STAT SOC B, V67, P91, DOI 10.1111/j.1467-9868.2005.00490.x; Efron B, 2004, ANN STAT, V32, P407; Breiman L, 1996, ANN STAT, V24, P2350; Butler NA, 2000, J ROY STAT SOC B, V62, P585, DOI 10.1111/1467-9868.00252; DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X; DEJONG S, 1995, J CHEMOMETR, V9, P323, DOI 10.1002/cem.1180090406; Engel B, 2006, ANIM SCI, V82, P919, DOI 10.1017/ASC2006104; Friedman JH, 2004, GRADIENT DIRECTED RE; HASTIE T, 2007, LARS PACKAGE 0 9 7 L; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Martens H., 1992, MULTIVARIATE CALIBRA; Marx BD, 1999, TECHNOMETRICS, V41, P1, DOI 10.2307/1270990; R Development Core Team, 2006, R LANG ENV STAT COMP; Rue H., 2005, GAUSSIAN MARKOV RAND; Wehrens R., 2006, PLS PACKAGE 2 0 0 MU; West M., 2003, BAYESIAN STAT, P723; Whittakers J., 1984, APPL STAT-J ROY ST C, V33, P52, DOI DOI 10.2307/2347663; WISE BM, 2000, PLS TOOLBOX 2 1, P346; WOLD H, 1984, PLS REGRESSION; WOLD S, 1993, TECHNOMETRICS, V35, P136, DOI 10.2307/1269657; Zellner A, 1986, BAYESIAN INFERENCE D, P233; ZOU H, 2005, ELASTIC NET PACKAGE	28	3	3	1	2	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0886-9383	1099-128X		J CHEMOMETR	J. Chemometr.	MAY-JUN	2009	23	5-6					217	228		10.1002/cem.1213		12	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	465YJ	WOS:000267626400001		
J	De Mol, C; Mosci, S; Traskine, M; Verri, A				De Mol, Christine; Mosci, Sofia; Traskine, Magali; Verri, Alessandro			A Regularized Method for Selecting Nested Groups of Relevant Genes from Microarray Data	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						gene expression; machine learning; recognition of genes and regulatory elements	EXPRESSION DATA; CLASSIFICATION; CANCER; REGRESSION; LASSO; BIOINFORMATICS	Gene expression analysis aims at identifying the genes able to accurately predict biological parameters like, for example, disease subtyping or progression. While accurate prediction can be achieved by means of many different techniques, gene identification, due to gene correlation and the limited number of available samples, is a much more elusive problem. Small changes in the expression values often produce different gene lists, and solutions which are both sparse and stable are difficult to obtain. We propose a two-stage regularization method able to learn linear models characterized by a high prediction performance. By varying a suitable parameter these linear models allow to trade sparsity for the inclusion of correlated genes and to produce gene lists which are almost perfectly nested. Experimental results on synthetic and microarray data confirm the interesting properties of the proposed method and its potential as a starting point for further biological investigations.	[Mosci, Sofia; Verri, Alessandro] Univ Genoa, DISI, Genoa, Italy; [Mosci, Sofia] Univ Genoa, DIFI, Genoa, Italy; [De Mol, Christine; Traskine, Magali] Univ Libre Brussels, Dept Math, Brussels, Belgium; [De Mol, Christine] Univ Libre Brussels, ECARES, Brussels, Belgium	Mosci, S (reprint author), Univ Genoa, DISI, Via Dodecaneso 35, Genoa, Italy.	mosci@disi.unige.it			EU [IST-2004-027749]; FIRB [RBIN04PARL]; EU STREP; Action de Recherche Concertee [02/07-281]; VUB-GOA [62]	We are indebted to Annalisa Barla, Ernesto De Vito, Sayan Mukherjee, and Lorenzo Rosasco for many stimulating discussions and useful suggestions. This work has been partially supported by the EU Integrated Project Health-e-Child (IST-2004-027749), by the FIRB project LEAP (RBIN04PARL), the EU STREP grant COMBIO, an "Action de Recherche Concertee" (Nb 02/07-281), and a VUB-GOA grant (Nb 62).	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Bild AH, 2006, NATURE, V439, P353, DOI 10.1038/nature04296; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Ma S, 2008, BRIEF BIOINFORM, V9, P392, DOI 10.1093/bib/bbn027; Segal MR, 2003, J COMPUT BIOL, V10, P961, DOI 10.1089/106652703322756177; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Gordon GJ, 2002, CANCER RES, V62, P4963; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Bertero M., 1998, INTRO INVERSE PROBLE; Breiman L., 1984, CLASSIFICATION REGRE; De Mol C, 2009, J COMPLEXITY, V25, P201, DOI 10.1016/j.jco.2009.01.002; Engl H., 1996, REGULARIZATION INVER; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Furlanello C, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-54; Ghosh D, 2005, J BIOMED BIOTECHNOL, P147, DOI 10.1155/JBB.2005.147; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Kohavi R, 1997, ARTIF INTELL, V1, P273; Leng CL, 2006, STAT SINICA, V16, P1273; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Segal MR, 2006, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; Vert JP, 2007, KERNEL METHODS IN BIOENGINEERING, SIGNAL AND IMAGE PROCESSING, P42; Westons J, 2000, FEATURE SELECTION SV, P668	30	10	10	0	0	MARY ANN LIEBERT, INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277	1557-8666		J COMPUT BIOL	J. Comput. Biol.	MAY	2009	16	5					677	690		10.1089/cmb.2008.0171		14	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	451ZG	WOS:000266508800003	19432538	
J	Hossain, S; Doksum, KA; Ahmed, SE				Hossain, S.; Doksum, Kjell A.; Ahmed, S. Ejaz			Positive shrinkage, improved pretest and absolute penalty estimators in partially linear models	LINEAR ALGEBRA AND ITS APPLICATIONS			English	Article; Proceedings Paper	16th International Workshop on Matrices and Statistics	2007	Windsor, CANADA	Univ Windsor, Fields Inst Res Math Sci, Univ Windsor, Ctr Stat Consulting, Res & Learning Serv		Asymptotic risk; Kernel smoothing; Regression model; Semiparametric least squares; Semiparametric LASSO; Stein type shrinkage	SEMIPARAMETRIC REGRESSION; CONVERGENCE-RATES; LIKELIHOOD; COMPONENTS; SELECTION	Shrinkage estimators of a partially linear regression parameter vector are constructed by shrinking estimators in the direction of the estimate which is appropriate when the regression parameters are restricted to a linear subspace. We investigate the asymptotic properties of positive Stein-type and improved pretest semiparametric estimators under quadratic loss. Under an asymptotic distributional quadratic risk criterion, their relative dominance picture is explored analytically. It is shown that positive Stein-type semiparametric estimators perform better than the usual Stein-type and least square semiparametric estimators and that an improved pretest semiparametric estimator is superior to the usual pretest semiparametric estimator. We also consider an absolute penalty type estimator for partially linear models and give a Monte Carlo simulation comparisons of positive shrinkage, improved pretest and the absolute penalty type estimators. The comparison shows that the shrinkage method performs better than the absolute penalty type estimation method when the dimension of the parameter space is much larger than that of the linear subspace. (C) 2009 Elsevier Inc. All rights reserved.	[Hossain, S.] Univ Alberta, Dept Publ Hlth Sci, Edmonton, AB T6G 2G3, Canada; [Doksum, Kjell A.] Univ Wisconsin, Dept Stat, Madison, WI 53706 USA; [Ahmed, S. Ejaz] Univ Windsor, Dept Math & Stat, Windsor, ON N9B 3P4, Canada	Hossain, S (reprint author), Univ Alberta, Dept Publ Hlth Sci, Edmonton, AB T6G 2G3, Canada.	mhossain@ualberta.ca					Ahmed SE, 2007, AUST NZ J STAT, V49, P435, DOI 10.1111/j.1467-842X.2007.00493.x; Ahmed SE, 1999, LINEAR ALGEBRA APPL, V289, P3, DOI 10.1016/S0024-3795(97)10003-9; Ahmed S.E., 2001, LECT NOTES STAT, V148, P103; ENGLE RF, 1986, J AM STAT ASSOC, V81, P310, DOI 10.2307/2289218; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Bancroft TA, 1944, ANN MATH STAT, V15, P190, DOI 10.1214/aoms/1177731284; Hamilton SA, 1997, J MULTIVARIATE ANAL, V60, P1, DOI 10.1006/jmva.1996.1642; Bowman A.W., 1997, APPL SMOOTHING TECHN; Bunea F, 2004, ANN STAT, V32, P898, DOI 10.1214/009053604000000247; CHEN H, 1988, ANN STAT, V16, P136, DOI 10.1214/aos/1176350695; CHEN H, 1994, ANN STAT, V22, P211, DOI 10.1214/aos/1176325366; Chen S., 1994, BASIS PURSUIT; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; DONALD SG, 1994, J MULTIVARIATE ANAL, V50, P30, DOI 10.1006/jmva.1994.1032; EUBANK RL, 1990, J MULTIVARIATE ANAL, V32, P70, DOI 10.1016/0047-259X(90)90072-P; Fan JQ, 1998, ANN STAT, V26, P943; Gao J, 1997, COMMUN STAT-THEOR M, V26, P787, DOI 10.1080/03610929708831950; GAO JT, 1995, STAT PROBABIL LETT, V25, P153, DOI 10.1016/0167-7152(94)00217-V; GAO JT, 1995, COMMUN STAT THEORY, V24, P1985, DOI 10.1080/03610929508831598; HA W, 2000, PARTIALLY LINEAR MOD; HECKMAN NE, 1986, J ROY STAT SOC B MET, V48, P244; Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.2307/1390807; Liang H, 2004, J AM STAT ASSOC, V99, P357, DOI 10.1198/016214504000000421; Liang H, 1999, COMMUN STAT-THEOR M, V28, P2025, DOI 10.1080/03610929908832403; RICE J, 1986, STAT PROBABIL LETT, V4, P203, DOI 10.1016/0167-7152(86)90067-2; ROBINSON PM, 1988, ECONOMETRICA, V56, P931, DOI 10.2307/1912705; Saleh A. K., 2006, THEORY PRELIMINARY T; Schick A, 1998, J TIME SER ANAL, V19, P575, DOI 10.1111/1467-9892.00109; SCHICK A, 1994, STAT PROBABIL LETT, V21, P371, DOI 10.1016/0167-7152(94)00034-4; Schick A, 1996, STOCH PROC APPL, V61, P339, DOI 10.1016/0304-4149(95)00093-3; SCLOVE SL, 1972, ANN MATH STAT, V43, P1481, DOI 10.1214/aoms/1177692380; Shi J, 2000, J MULTIVARIATE ANAL, V72, P132, DOI 10.1006/jmva.1999.1866; SHI PD, 1995, STATISTICS, V26, P27, DOI 10.1080/02331889508802465; SPECKMAN P, 1988, J ROY STAT SOC B MET, V50, P413; Wang QH, 2004, J AM STAT ASSOC, V99, P334, DOI 10.1198/016214504000000449; Xue HQ, 2004, J AM STAT ASSOC, V99, P346, DOI 10.1198/016214504000000313	36	6	6	1	3	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0024-3795	1873-1856		LINEAR ALGEBRA APPL	Linear Alg. Appl.	MAY 1	2009	430	10			SI		2749	2761		10.1016/j.laa.2008.12.015		13	Mathematics, Applied; Mathematics	Mathematics	437FU	WOS:000265473000016		
J	DeMiguel, V; Garlappi, L; Nogales, FJ; Uppal, R				DeMiguel, Victor; Garlappi, Lorenzo; Nogales, Francisco J.; Uppal, Raman			A Generalized Approach to Portfolio Optimization: Improving Performance by Constraining Portfolio Norms	MANAGEMENT SCIENCE			English	Article						portfolio choice; covariance matrix estimation; estimation error; shrinkage estimator; norm constraints	VARIANCE-EFFICIENT PORTFOLIOS; SELECTION; RISK; DIVERSIFICATION; COVARIANCES; BOOTSTRAP; WEIGHTS; CHOICE; LASSO	We provide a general framework for finding portfolios that perform well out-of-sample in the presence of estimation error. This framework relies on solving the traditional minimum-variance problem but subject to the additional constraint that the norm of the portfolio-weight vector be smaller than a given threshold. We show that our framework nests as special cases the shrinkage approaches of Jagannathan and Ma (Jagannathan, R., T. Ma. 2003. Risk reduction in large portfolios: Why imposing the wrong constraints helps. J. Finance 58 1651 1684) and Ledoit and Wolf (Ledoit, O., M. Wolf. 2003. Improved estimation of the covariance matrix of stock returns with an application to portfolio selection. J. Empirical Finance 10 603-621, and Ledoit, O., M. Wolf. 2004. A well-conditioned estimator for large-dimensional covariance matrices. J. Multivariate Anal. 88 365-411) and the 1/N portfolio studied in DeMiguel et al. (DeMiguel, V., L. Garlappi, R. Uppal. 2009. Optimal versus naive diversification: How inefficient is the 1/N portfolio strategy? Rev. Financial Stud. 22 1915-1953). We also use our framework to propose several new portfolio strategies. For the proposed portfolios, we provide a moment-shrinkage interpretation and a Bayesian interpretation where the investor has a prior belief on portfolio weights rather than on moments of asset returns. Finally, we compare empirically the out-of-sample performance of the new portfolios we propose to 10 strategies in the literature across five data sets. We find that the norm-constrained portfolios often have a higher Sharpe ratio than the portfolio strategies in Jagannathan and Ma (2003), Ledoit and Wolf (2003, 2004), the 1/N portfolio, and other strategies in the literature, such as factor portfolios.	[DeMiguel, Victor; Uppal, Raman] London Business Sch, London NW1 4SA, England; [Garlappi, Lorenzo] Univ Texas Austin, McCombs Sch Business, Austin, TX 78712 USA; [Nogales, Francisco J.] Univ Carlos III Madrid, Madrid 28911, Spain	DeMiguel, V (reprint author), London Business Sch, London NW1 4SA, England.	avmiguel@london.edu; lorenzo.garlappi@mccombs.utexas.edu; fcojavier.nogales@uc3m.es; ruppal@london.edu					BEST MJ, 1991, REV FINANC STUD, V4, P315, DOI 10.1093/rfs/4.2.315; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Ledoit O, 2004, J MULTIVARIATE ANAL, V88, P365, DOI 10.1016/S0047-259X(03)00096-4; Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; DeMiguel V, 2009, REV FINANC STUD, V22, P1915, DOI 10.1093/rfs/hhm075; FAMA EF, 1992, J FINANC, V47, P427, DOI 10.2307/2329112; CHOPRA VK, 1993, J PORTFOLIO MANAGE, V19, P6, DOI 10.3905/jpm.1993.409440; MERTON RC, 1980, J FINANC ECON, V8, P323, DOI 10.1016/0304-405X(80)90007-0; POLITIS DN, 1994, J AM STAT ASSOC, V89, P1303, DOI 10.2307/2290993; BRANDT MW, 2005, PARAMETRIC PORTFOLIO; Brandt MW, 1999, J FINANC, V54, P1609, DOI 10.1111/0022-1082.00162; Britten-Jones M, 1999, J FINANC, V54, P655, DOI 10.1111/0022-1082.00120; Broadie M., 1993, Annals of Operations Research, V45, DOI 10.1007/BF02282040; Campbell JY, 1997, ECONOMETRICS FINANCI; Chan LKC, 1999, REV FINANC STUD, V12, P937, DOI 10.1093/rfs/12.5.937; Chopra V. K., 1993, J INVESTING, V8, P51; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; ELTON EJ, 1973, J FINANC, V28, P1203, DOI 10.2307/2978758; FIACCO A. V., 1968, NONLINEAR PROGRAMMIN; FROST PA, 1986, J FINANC QUANT ANAL, V21, P293, DOI 10.2307/2331043; FROST PA, 1988, J PORTFOLIO MANAGE, V15, P29, DOI 10.3905/jpm.1988.409181; GREEN RC, 1992, J FINANC, V47, P1785, DOI 10.2307/2328996; Hastie T., 2001, ELEMENTS STAT LEARNI; HERSHEY RD, 2007, NY TIMES        0708; Hoerl A. E., 1970, TECHNOMETRICS, V8, P27; Jagannathan R, 2003, J FINANC, V58, P1651, DOI 10.1111/1540-6261.00580; JAMES W, 1961, P 4 BERK S PROB STAT, V1, P452; JORION P, 1991, J BANK FINANC, V15, P717, DOI 10.1016/0378-4266(91)90094-3; JORION P, 1986, J FINANC QUANT ANAL, V21, P279, DOI 10.2307/2331042; JORION P, 1985, J BUS, V58, P259, DOI 10.1086/296296; Lauprete G.J., 2001, THESIS MIT CAMBRIDGE; Lauprete GJ, 2002, METRIKA, V55, P139, DOI 10.1007/s001840200193; Ledoit 0., 2003, J EMPIR FINANC, V10, P603, DOI DOI 10.1016/S0927-5398(03)00007-0; Ledoit O, 2008, J EMPIR FINANC, V15, P850, DOI 10.1016/j.jempfin.2008.03.002; Litterman R., 2003, MODERN INVESTMENT MA; Markowitz H, 1952, J FINANC, V7, P77, DOI 10.2307/2975974; Michaud R. O., 1989, FINANCIAL ANAL J, V45, P31, DOI DOI 10.2469/FAJ.V45.N1.31; NOCEDAL J., 1999, NUMERICAL OPTIMIZATI; Phatak A, 2002, J CHEMOMETR, V16, P361, DOI 10.1002/cem.728; STEIHAUG T, 1983, SIAM J NUMER ANAL, V20, P626, DOI 10.1137/0720042; TU J, 2009, J FINANCIAL IN PRESS; Welsch RE, 2007, REVSTAT-STAT J, V5, P97; Wold H., 1975, PERSPECTIVES PROBABI, P520; 2007, ECONOMIST       0628	45	83	86	6	38	INFORMS	HANOVER	7240 PARKWAY DR, STE 310, HANOVER, MD 21076-1344 USA	0025-1909			MANAGE SCI	Manage. Sci.	MAY	2009	55	5					798	812		10.1287/mnsc.1080.0986		15	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	444WQ	WOS:000266011700008		
J	Greenland, S				Greenland, Sander			Relaxation Penalties and Priors for Plausible Modeling of Nonidentified Bias Sources	STATISTICAL SCIENCE			English	Article						Bias; biostatistics; causality; epidemiology; measurement error; misclassification; observational studies; odds ratio; relative risk; risk analysis; risk assessment; selection bias; validation	GENERALIZED LINEAR-MODELS; INFANT-DEATH-SYNDROME; EPIDEMIOLOGIC RESEARCH; BAYESIAN PERSPECTIVES; SENSITIVITY-ANALYSIS; OBSERVATIONAL DATA; SYSTEMATIC-ERRORS; DIAGNOSTIC-TESTS; MAGNETIC-FIELDS; GOLD STANDARD	In designed experiments and surveys, known laws or design features provide checks on the most relevant aspects of a model and identify the target parameters. In contrast, in most observational studies in the health and social sciences, the primary study data do not identify and may not even bound target parameters. Discrepancies between target and analogous identified parameters (biases) are then of paramount concern, which forces a major shift in modeling strategies. Conventional approaches are based on conditional testing of equality constraints, which correspond to implausible point-mass priors. When these constraints are not identified by available data, however, no such testing is possible. In response, implausible constraints can be relaxed into penalty functions derived from plausible prior distributions. The resulting models can be fit within familiar full or partial likelihood frameworks. The absence of identification renders all analyses part of a sensitivity analysis. In this view, results from single models are merely examples of what might be plausibly inferred. Nonetheless, just one plausible inference may suffice to demonstrate inherent limitations of the data. Points are illustrated with misclassified data from a study of sudden infant death syndrome. Extensions to confounding, selection bias and more complex data structures are outlined.	[Greenland, Sander] Univ Calif Los Angeles, Dept Epidemiol, Los Angeles, CA 90095 USA; [Greenland, Sander] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Greenland, S (reprint author), Univ Calif Los Angeles, Dept Epidemiol, Los Angeles, CA 90095 USA.	lesdomes@ucla.edu					Brumback BA, 2004, STAT MED, V23, P749, DOI 10.1002/sim.1657; Scharfstein DO, 1999, J AM STAT ASSOC, V94, P1096, DOI 10.2307/2669923; Neath AA, 1997, AM STAT, V51, P225, DOI 10.2307/2684892; Greenland S, 2007, INT J EPIDEMIOL, V36, P195, DOI 10.1093/ije/dyl289; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Lawlor DA, 2004, LANCET, V363, P1724, DOI 10.1016/S0140-6736(04)16260-0; Johnson WO, 2001, AM J EPIDEMIOL, V153, P921, DOI 10.1093/aje/153.9.921; JOSEPH L, 1995, AM J EPIDEMIOL, V141, P263; Greenland S, 2006, INT J EPIDEMIOL, V35, P765, DOI 10.1093/ije.dyi312; HUI SL, 1980, BIOMETRICS, V36, P167, DOI 10.2307/2530508; Fortes C, 2008, INT J EPIDEMIOL, V37, P1018, DOI 10.1093/ije/dyn132; Baker SG, 1996, BIOMETRICS, V52, P362, DOI 10.2307/2533174; Bedrick EJ, 1996, J AM STAT ASSOC, V91, P1450, DOI 10.2307/2291571; Bishop Y.V.V., 1975, DISCRETE MULTIVARIAT; BOX GEP, 1980, J ROY STAT SOC A STA, V143, P383, DOI 10.2307/2982063; BROSS IDJ, 1967, J CHRON DIS, V20, P487, DOI 10.1016/0021-9681(67)90080-X; Bull SB, 2007, STAT MED, V26, P903, DOI 10.1002/sim.2518; Carroll R.J., 2006, MEASUREMENT ERROR NO; Copas J, 1999, J ROY STAT SOC A STA, V162, P95, DOI 10.1111/1467-985X.00123; COX DR, 1975, BIOMETRIKA, V62, P651, DOI 10.1093/biomet/62.3.651; DEELY JJ, 1981, J AM STAT ASSOC, V76, P833, DOI 10.2307/2287578; DREWS CD, 1990, INT J EPIDEMIOL, V19, P405, DOI 10.1093/ije/19.2.405; Eddy DM, 1992, METAANALYSIS CONFIDE; ESPELAND MA, 1987, BIOMETRICS, V43, P1001, DOI 10.2307/2531553; Gelfand AE, 1999, J AM STAT ASSOC, V94, P247, DOI 10.2307/2669699; Geneletti S, 2009, BIOSTATISTICS, V10, P17, DOI 10.1093/biostatistics/kxn010; Goubar A, 2008, J R STAT SOC A STAT, V171, P541, DOI 10.1111/j.1467-985X.2007.00537.x; Greenland S, 2003, J AM STAT ASSOC, V98, P47, DOI 10.1198/01621450338861905; GREENLAND S, 2007, J STAT PLAN INFER, V138, P528; GREENLAND S, 1994, STAT MED, V13, P989, DOI 10.1002/sim.4780131002; Greenland S, 2006, RISK ANAL, V26, P471, DOI 10.1111/j.1539-6924.2006.00754; GREENLAND S, 1992, STAT MED, V11, P219, DOI 10.1002/sim.4780110208; Greenland S, 2009, INT J EPIDEMIOL, V38, P1662, DOI 10.1093/ije/dyp278; Greenland S, 2003, EPIDEMIOLOGY, V14, P300, DOI 10.1097/00001648-200305000-00009; Greenland S, 2003, BIOMETRICS, V59, P92, DOI 10.1111/1541-0420.00011; GREENLAND S, 2004, EPIDEMIOLOGY, V15, P519; Greenland S, 2000, BIOMETRICS, V56, P915, DOI 10.1111/j.0006-341X.2000.00915.x; Greenland S, 2005, BIOMETRICS, V61, P920, DOI 10.1111/j.0006-341X.2005.454_6.x; Greenland S, 2008, MODERN EPIDEMIOLOGY, P345; Greenland S, 2007, STAT MED, V26, P3578, DOI 10.1002/sim.2788; Greenland S, 2005, J ROY STAT SOC A STA, V168, P267, DOI 10.1111/j.1467-985X.2004.00349.x; Gustafson P, 2006, BIOMETRICS, V62, P760, DOI 10.1111/j.1541-0420.2005.00510.x; Gustafson P, 2003, MEASUREMENT ERROR MI; GUSTAFSON P, 2010, INTERVAL ES IN PRESS; Gustafson P, 2005, STAT SCI, V20, P111, DOI 10.1214/088342305000000098; Gustafson P, 2001, BIOMETRICS, V57, P598, DOI 10.1111/j.0006-341X.2001.00598.x; Hastie TJ, 1990, GEN ADDITIVE MODELS; HASTIF T, 2001, ELEMENTS STAT LEARNI; Higgins JPT, 2002, INT J EPIDEMIOL, V31, P96, DOI 10.1093/ije/31.1.96; Jones MC, 2004, TEST, V13, P1, DOI 10.1007/BF02602999; KADANE JB, 1993, STATISTICIAN, V42, P415, DOI 10.2307/2348475; KADANE JB, 1993, STATISTICIAN, V45, P539; KRAUS JF, 1989, INT J EPIDEMIOL, V18, P113, DOI 10.1093/ije/18.1.113; Lash TL, 2003, EPIDEMIOLOGY, V14, P451, DOI 10.1097/01.EDE.0000071419.41011.cf; LEAMER EE, 1974, J AM STAT ASSOC, V69, P122, DOI 10.2307/2285510; Leonard T., 1999, BAYESIAN METHODS; Little R., 2002, STAT ANAL MISSING DA; Lyles RH, 2002, BIOMETRICS, V58, P1034, DOI 10.1111/j.0006-341X.2002.1034_1.x; Maldonado G, 2008, J EPIDEMIOL COMMUN H, V62, P655, DOI 10.1136/jech.2007.063909; McCandless LC, 2007, STAT MED, V26, P2331, DOI 10.1002/sim.2711; McLachlan G. J., 1997, EM ALGORITHMS EXTENS; Messer K, 2008, STAT MED, V27, P6332, DOI 10.1002/sim.3458; MOLENBERGHS G, 2001, APPL STAT, V50, P15; MOLITOR J, 2008, J R STAT SOC A GEN, V172, P615; Phillips CV, 2003, EPIDEMIOLOGY, V14, P459, DOI 10.1097/01.ede.0000072106.65262.ae; ROBINS J.M, 2000, IMA VOL MATH APPL, V116, P1; Rosenbaum P.R., 2002, OBSERVATIONAL STUDIE; Rosenbaum PR, 1999, STAT SCI, V14, P259, DOI 10.1214/ss/1009212410; Samaniego FJ, 1996, J AM STAT ASSOC, V91, P733, DOI 10.2307/2291668; Scharfstein DO, 2003, BIOSTATISTICS, V4, P495, DOI 10.1093/biostatistics/4.4.495; SMALL DS, 2009, ANN APPL ST IN PRESS; TITTERINGTON DM, 1985, INT STAT REV, V53, P141, DOI 10.2307/1402932; Turner RM, 2009, J R STAT SOC A STAT, V172, P21, DOI 10.1111/j.1467-985X.2008.00547.x; Vansteelandt S, 2006, STAT SINICA, V16, P953; WALKER AM, 1982, BIOMETRICS, V38, P1025, DOI 10.2307/2529883; Welton NJ, 2009, J ROY STAT SOC A STA, V172, P119, DOI 10.1111/j.1467-985X.2008.00548.x; WERLER MM, 1989, AM J EPIDEMIOL, V129, P415; WHITE JE, 1982, AM J EPIDEMIOL, V115, P119; YANAGAWA T, 1984, BIOMETRIKA, V71, P191, DOI 10.1093/biomet/71.1.191	79	20	20	0	5	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0883-4237			STAT SCI	Stat. Sci.	MAY	2009	24	2					195	210		10.1214/09-STS291		16	Statistics & Probability	Mathematics	550XF	WOS:000274166300002		
J	Barutcuoglu, Z; Airoldi, EM; Dumeaux, V; Schapire, RE; Troyanskaya, OG				Barutcuoglu, Zafer; Airoldi, Edoardo M.; Dumeaux, Vanessa; Schapire, Robert E.; Troyanskaya, Olga G.			Aneuploidy prediction and tumor classification with heterogeneous hidden conditional random fields	BIOINFORMATICS			English	Article							COMPARATIVE GENOMIC HYBRIDIZATION; ARRAY CGH DATA; BREAST-CANCER; EXPRESSION; AMPLIFICATION; PROGRESSION; CARCINOMAS; SELECTION; ONCOGENE; GROWTH	Motivation: The heterogeneity of cancer cannot always be recognized by tumor morphology, but may be reflected by the underlying genetic aberrations. Array comparative genome hybridization (array-CGH) methods provide high-throughput data on genetic copy numbers, but determining the clinically relevant copy number changes remains a challenge. Conventional classification methods for linking recurrent alterations to clinical outcome ignore sequential correlations in selecting relevant features. Conversely, existing sequence classification methods can only model overall copy number instability, without regard to any particular position in the genome. Results: Here, we present the heterogeneous hidden conditional random field, a new integrated array-CGH analysis method for jointly classifying tumors, inferring copy numbers and identifying clinically relevant positions in recurrent alteration regions. By capturing the sequentiality as well as the locality of changes, our integrated model provides better noise reduction, and achieves more relevant gene retrieval and more accurate classification than existing methods. We provide an efficient L(1)-regularized discriminative training algorithm, which notably selects a small set of candidate genes most likely to be clinically relevant and driving the recurrent amplicons of importance. Our method thus provides unbiased starting points in deciding which genomic regions and which genes in particular to pursue for further examination. Our experiments on synthetic data and real genomic cancer prediction data show that our method is superior, both in prediction accuracy and relevant feature discovery, to existing methods. We also demonstrate that it can be used to generate novel biological hypotheses for breast cancer.	[Barutcuoglu, Zafer; Airoldi, Edoardo M.; Schapire, Robert E.; Troyanskaya, Olga G.] Princeton Univ, Dept Comp Sci, Princeton, NJ 08540 USA; [Airoldi, Edoardo M.; Troyanskaya, Olga G.] Princeton Univ, Lewis Sigler Inst Integrat Genom, Carl Icahn Lab, Princeton, NJ 08544 USA; [Dumeaux, Vanessa] Univ Tromso, Inst Community Med, Tromso, Norway	Troyanskaya, OG (reprint author), Princeton Univ, Dept Comp Sci, 35 Olden St, Princeton, NJ 08540 USA.		Airoldi, Edoardo/A-8575-2009				Albertson DG, 2006, TRENDS GENET, V22, P447, DOI 10.1016/j.tig.2006.06.007; Albertson DG, 2000, NAT GENET, V25, P144, DOI 10.1038/75985; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.2307/2006193; Lai WR, 2005, BIOINFORMATICS, V21, P3763, DOI 10.1093/bioinformatics/bti611; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Wessels LFA, 2002, CANCER RES, V62, P7110; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Huang JM, 2007, GENE CHROMOSOME CANC, V46, P745, DOI 10.1002/gcc.20459; Snijders AM, 2005, ONCOGENE, V24, P4232, DOI 10.1038/sj.onc.1208601; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Chin K, 2006, CANCER CELL, V10, P529, DOI 10.1016/j.ccr.2006.10.009; Pollack JR, 2002, P NATL ACAD SCI USA, V99, P12963, DOI 10.1073/pnas.162471999; Beitzinger M, 2008, EMBO J, V27, P792, DOI 10.1038/emboj.2008.13; Brown LA, 2006, GYNECOL ONCOL, V100, P264, DOI 10.1016/j.ygyno.2005.08.026; Han SH, 2003, ONCOGENE, V22, P4035, DOI 10.1038/sj.onc.1206610; HEIM S, 1989, ADV CANCER RES, V52, P1, DOI 10.1016/S0065-230X(08)60209-2; Jonsson G, 2005, CANCER RES, V65, P7612, DOI 10.1158/0008-5472.CAN-05-0570; Kim Y., 2004, ICML 04, P60; Liu ZQ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1248; Myers CL, 2004, BIOINFORMATICS, V20, P3533, DOI 10.1093/bioinformatics/bth440; Nag A, 2004, CANCER RES, V64, P8152, DOI 10.1158/0008-5472.CAN-04-2598; Qi Y., 2005, P 10 INT WORKSH ART, P269; Rapaport F., 2008, BIOINFORMATICS, V24, P375; Rocke DM, 2001, J COMPUT BIOL, V8, P557, DOI 10.1089/106652701753307485; Rueda OM, 2007, PLOS COMPUT BIOL, V3, P1115, DOI 10.1371/journal.pcbi.0030122; Shah SP, 2007, BIOINFORMATICS, V23, pI450, DOI 10.1093/bioinformatics/btm221; TASKAR B, 2004, ADV NEU INFOR P SYS, V16, P51; van Beers EH, 2006, BREAST CANCER RES, V8, DOI 10.1186/bcr1510; Yi CH, 2007, AM J PATHOL, V170, P1535, DOI 10.2353/ajpath.2007.060478	29	2	2	0	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	MAY 15	2009	25	10					1307	1313		10.1093/bioinformatics/btn585		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	443ZY	WOS:000265950600015	19052061	
J	Lu, ZH				Lu, Zeng-Hua			Covariate selection in mixture models with the censored response variable	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article							EM ALGORITHM; NORMAL-DISTRIBUTIONS; DEPENDENT-VARIABLES; MAXIMUM-LIKELIHOOD; COMPONENTS; INFORMATION; HOMOGENEITY; MEMBERSHIP; IMPACT; MALES	This paper formulates a mixture model for modeling unobserved heterogeneity of explanatory mechanism. Our model allows for different sets of regressors and/or different interactions among the same regressors in different regression regimes. The model is demonstrated with particular interest to the censored dependent variable. A two-step procedure is proposed for model identification. The first step is to identify the number of regression regimes with each regime, including all regressors. The second step is to select regressors in the regression regimes. The results of our simulation studies suggest that the procedure works well. Two microeconometric applications are provided. (C) 2009 Elsevier B.V. All rights reserved.	Univ S Australia, Sch Math & Stat, Adelaide, SA 5001, Australia	Lu, ZH (reprint author), Univ S Australia, Sch Math & Stat, City West,GPO Box 2471, Adelaide, SA 5001, Australia.	zen.lu@unisa.edu.au			Australian Research Council's Discovery [DP0666677]	This research was supported in part by the Australian Research Council's Discovery project grant DP0666677. We thank the associate editor and two referees for their constructive comments, which have led to a significant improvement of the presentation.	AMEMIYA T, 1981, J ECON LIT, V19, P1483; Keane MP, 1997, J POLIT ECON, V105, P473, DOI 10.1086/262080; HECKMAN J, 1984, ECONOMETRICA, V52, P271, DOI 10.2307/1911491; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; Zhu HT, 2006, ANN STAT, V34, P1545, DOI 10.1214/009053606000000380; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Arcidiacono P, 2003, ECONOMETRICA, V71, P933, DOI 10.1111/1468-0262.00431; DAY NE, 1969, BIOMETRIKA, V56, P463, DOI 10.2307/2334652; Nagin D, 1999, CHILD DEV, V70, P1181, DOI 10.1111/1467-8624.00086; TOBIN J, 1958, ECONOMETRICA, V26, P24, DOI 10.2307/1907382; Roeder K, 1999, J AM STAT ASSOC, V94, P766, DOI 10.2307/2669989; MENG XL, 1991, J AM STAT ASSOC, V86, P899, DOI 10.2307/2290503; Gilleskie DB, 1998, ECONOMETRICA, V66, P1, DOI 10.2307/2998539; Biernacki C, 1997, COMPUTING SCI STAT, V29, P451; BLUNDELL RW, 1989, REV ECON STUD, V56, P37, DOI 10.2307/2297748; Breiman L, 1996, ANN STAT, V24, P2350; BUCKLIN RE, 1995, J MARKETING RES, V32, P66, DOI 10.2307/3152111; Cameron SV, 2001, J POLIT ECON, V109, P455, DOI 10.1086/321014; Cameron SV, 1998, J POLIT ECON, V106, P262, DOI 10.1086/250010; Chambaz A, 2006, ANN STAT, V34, P1166, DOI 10.1214/009053606000000344; Charnigo R, 2004, J AM STAT ASSOC, V99, P488, DOI 10.1198/016214504000000494; Chen HF, 2004, J ROY STAT SOC B, V66, P95, DOI 10.1111/j.1467-9868.2004.00434.x; Dasgupta A, 1998, J AM STAT ASSOC, V93, P294, DOI 10.2307/2669625; Eckstein Z, 1999, ECONOMETRICA, V67, P1295, DOI 10.1111/1468-0262.00081; FAIR RC, 1978, J POLIT ECON, V86, P45, DOI 10.1086/260646; FAIR RC, 1977, ECONOMETRICA, V45, P1723, DOI 10.2307/1913962; Feng ZD, 1996, J ROY STAT SOC B MET, V58, P609; Greene W, 2005, J ECONOMETRICS, V126, P269, DOI 10.1016/j.jeconom.2004.05.003; Greene WH, 2003, ECONOMETRIC ANAL; GUPTA S, 1994, J MARKETING RES, V31, P128, DOI 10.2307/3151952; HATHAWAY RJ, 1985, ANN STAT, V13, P795, DOI 10.1214/aos/1176349557; Keribin C., 2000, SANKHYA A, V62, P49, DOI [10.2307/25051289, DOI 10.2307/25051289]; KIEFER NM, 1978, ECONOMETRICA, V46, P427, DOI 10.2307/1913910; LEROUX BG, 1992, ANN STAT, V20, P1350, DOI 10.1214/aos/1176348772; LOUIS TA, 1982, J ROY STAT SOC B MET, V44, P226; Mc Lachlan G.J., 1997, EM ALGORITHM EXTENSI; Miller A, 2002, SUBSET SELECTION REG, V2nd; Orea L., 2004, EMPIR ECON, V29, P169, DOI [10.1007/s00181-003-0184-2, DOI 10.1007/S00181-003-0184-2]; Peel D, 2000, FINITE MIXTURE MODEL; QUANDT RE, 1978, J AM STAT ASSOC, V73, P730, DOI 10.2307/2286266; ROEDER K, 1994, J AM STAT ASSOC, V89, P487, DOI 10.2307/2290850; Swait J, 2003, J BUS ECON STAT, V21, P80, DOI 10.1198/073500102288618784; Thompson TJ, 1998, J ROY STAT SOC C-APP, V47, P393; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; TSIONAS EG, 2004, ECONOMET J, V7, P389; Wong CS, 2001, J AM STAT ASSOC, V96, P982, DOI 10.1198/016214501753208645; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060	49	1	1	1	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	MAY 15	2009	53	7					2710	2723		10.1016/j.csda.2009.01.010		14	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	429FZ	WOS:000264907600025		
J	Ko, Y; Zhai, CX; Rodriguez-Zas, S				Ko, Younhee; Zhai, ChengXiang; Rodriguez-Zas, Sandra			Inference of gene pathways using mixture Bayesian networks	BMC SYSTEMS BIOLOGY			English	Article							CIRCADIAN CLOCK; HONEY-BEE; MODEL	Background: Inference of gene networks typically relies on measurements across a wide range of conditions or treatments. Although one network structure is predicted, the relationship between genes could vary across conditions. A comprehensive approach to infer general and condition-dependent gene networks was evaluated. This approach integrated Bayesian network and Gaussian mixture models to describe continuous microarray gene expression measurements, and three gene networks were predicted. Results: The first reconstructions of a circadian rhythm pathway in honey bees and an adherens junction pathway in mouse embryos were obtained. In addition, general and condition-specific gene relationships, some unexpected, were detected in these two pathways and in a yeast cell-cycle pathway. The mixture Bayesian network approach identified all (honey bee circadian rhythm and mouse adherens junction pathways) or the vast majority (yeast cell-cycle pathway) of the gene relationships reported in empirical studies. Findings across the three pathways and data sets indicate that the mixture Bayesian network approach is well-suited to infer gene pathways based on microarray data. Furthermore, the interpretation of model estimates provided a broader understanding of the relationships between genes. The mixture models offered a comprehensive description of the relationships among genes in complex biological processes or across a wide range of conditions. The mixture parameter estimates and corresponding odds that the gene network inferred for a sample pertained to each mixture component allowed the uncovering of both general and condition-dependent gene relationships and patterns of expression. Conclusion: This study demonstrated the two main benefits of learning gene pathways using mixture Bayesian networks. First, the identification of the optimal number of mixture components supported by the data offered a robust approach to infer gene relationships and estimate gene expression profiles. Second, the classification of conditions and observations into groups that support particular mixture components helped to uncover both gene relationships that are unique or common across conditions. Results from the application of mixture Bayesian networks substantially augmented the understanding of gene networks and demonstrated the added-value of this methodology to infer gene networks.	[Zhai, ChengXiang; Rodriguez-Zas, Sandra] Univ Illinois, Inst Genom Biol, Urbana, IL 61801 USA; [Rodriguez-Zas, Sandra] Univ Illinois, Dept Anim Sci, Urbana, IL 61801 USA; [Ko, Younhee; Zhai, ChengXiang] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Rodriguez-Zas, S (reprint author), Univ Illinois, Inst Genom Biol, Urbana, IL 61801 USA.	younko@illinois.edu; czhai@illinois.edu; rodrgzzs@uiuc.edu			NIH/NIGMS [1R01GM068946-01]; NSF/ITR [0428472]; NIH NIDA [5P30DA018310-039003]	We would like to thank Heather Adams, Jaebum Kim and Bruce Southey for useful comments. The support of NIH/NIGMS (Grant Number: 1R01GM068946-01), NSF/ITR (Grant Number: 0428472) and, NIH NIDA (Grant Number: 5P30DA018310-039003) are greatly appreciated.	Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Cyran SA, 2003, CELL, V112, P329, DOI 10.1016/S0092-8674(03)00074-6; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Bloom J, 2007, NAT REV MOL CELL BIO, V8, P149, DOI 10.1038/nrm2105; Bilmes JA, 1998, TUTORIAL EM ALGORITH; Blair RC, 2008, BIOSTATISTICS HLTH S; BLAND JM, 1995, BRIT MED J, V310, P633; Boutilier C, 1996, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P115; Braunewell S, 2007, J THEOR BIOL, V245, P638, DOI 10.1016/j.jtbi.2006.11.012; Cobb BR, 2006, INT J APPROX REASON, V41, P257, DOI 10.1016/j.ijar.2005.06.002; DAVIES S, 2000, UNCERTAINTY ARTIFICI, P168; Friedman N, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P196; Hartemink A J, 2001, Pac Symp Biocomput, P422; Hartemink Alexander J, 2002, Pac Symp Biocomput, P437; Heckerman David, 1999, LEARNING GRAPHICAL M, P301; Hocking R. R., 1976, BIOMETRICS, P32; Hoyle DC, 2002, BIOINFORMATICS, V18, P576, DOI 10.1093/bioinformatics/18.4.576; Imoto Seiya, 2002, Pac Symp Biocomput, P175; Khondoker MR, 2006, BIOINFORMATICS, V22, P215, DOI 10.1093/bioinformatics/bti790; Ko Y., 2007, IEEE BIBM INT C BIOI, P362; KURUOGLU EE, 2007, IEEE SIU 15 SIGN PRO, P1; Liu Y, 2005, IEEE ACM T COMPUT BI, V2, P62; Mc Lachlan G.J., 1997, EM ALGORITHM EXTENSI; Needham CJ, 2007, PLOS COMPUT BIOL, V3, P1409, DOI 10.1371/journal.pcbi.0030129; Newman MEJ, 2007, P NATL ACAD SCI USA, V104, P9564, DOI 10.1073/pnas.0610537104; Nicholas M., 1953, J CHEM PHYS, V21, P1087; Pe'er D, 2001, Bioinformatics, V17 Suppl 1, pS215; Purdom E, 2005, STAT APPL GENET MO B, V4; Rodriguez-Zas SL, 2006, BMC GENOMICS, V7, DOI 10.1186/1471-2164-7-233; Rodriguez-Zas SL, 2008, REPRODUCTION, V135, P213, DOI 10.1530/REP-07-0391; Rodriguez-Zas SL, 2008, REPRODUCTION, V135, P129, DOI 10.1530/REP-07-0426; Rubin EB, 2006, GENOME RES, V16, P1352, DOI 10.1101/gr.5094806; Tomshine J, 2006, BIOPHYS J, V91, P3196, DOI 10.1529/biophysj.106.083485; VLADIMIR AK, 2001, EURASIP J APPL SIG P, V1, P285; Werhli Adriano V., 2008, Journal of Bioinformatics and Computational Biology, V6, P543, DOI 10.1142/S0219720008003539; Werhli AV, 2007, STAT APPL GENET MOL, V6; Whitfield CW, 2006, P NATL ACAD SCI USA, V103, P16068, DOI 10.1073/pnas.0606909103; Yokoyama S, 2001, MOL BIOL CELL, V12, P1595	41	9	9	0	2	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1752-0509			BMC SYST BIOL	BMC Syst. Biol.	MAY 19	2009	3								54	10.1186/1752-0509-3-54		16	Mathematical & Computational Biology	Mathematical & Computational Biology	472PT	WOS:000268144800001	19454027	
J	Chu, JH; Weiss, ST; Carey, VJ; Raby, BA				Chu, Jen-hwa; Weiss, Scott T.; Carey, Vincent J.; Raby, Benjamin A.			A graphical model approach for inferring large-scale networks integrating gene expression and genetic polymorphism	BMC SYSTEMS BIOLOGY			English	Article							GENOMICS; DISEASE; ASSOCIATION; MICROARRAY	Background: Graphical models (e.g., Bayesian networks) have been used frequently to describe complex interaction patterns and dependent structures among genes and other phenotypes. Estimation of such networks has been a challenging problem when the genes considered greatly outnumber the samples, and the situation is exacerbated when one wishes to consider the impact of polymorphisms (SNPs) in genes. Results: Here we describe a multistep approach to infer a gene-SNP network from gene expression and genotyped SNP data. Our approach is based on 1) construction of a graphical Gaussian model (GGM) based on small sample estimation of partial correlation and false-discovery rate multiple testing; 2) extraction of a subnetwork of genes directly linked to a target candidate gene of interest; 3) identification of cis-acting regulatory variants for the genes composing the subnetwork; and 4) evaluating the identified cis-acting variants for trans-acting regulatory effects of the target candidate gene. This approach identifies significant gene-gene and gene-SNP associations not solely on the basis of gene co-expression but rather through whole-network modeling. We demonstrate the method by building two complex gene-SNP networks around Interferon Receptor 12B2 (IL12RB2) and Interleukin 1B (IL1B), two biologic candidates in asthma pathogenesis, using 534,290 genotyped variants and gene expression data on 22,177 genes from total RNA derived from peripheral blood CD4+ lymphocytes from 154 asthmatics. Conclusion: Our results suggest that graphical models based on integrative genomic data are computationally efficient, work well with small samples, and can describe complex interactions among genes and polymorphisms that could not be identified by pair-wise association testing.	[Chu, Jen-hwa] Harvard Univ, Sch Med, Channing Lab,Ctr Genom Med, Brigham & Womens Hosp,Div Pulm & Crit Care Med, Boston, MA 02115 USA	Chu, JH (reprint author), Harvard Univ, Sch Med, Channing Lab,Ctr Genom Med, Brigham & Womens Hosp,Div Pulm & Crit Care Med, Boston, MA 02115 USA.	stjhc@channing.harvard.edu; restw@channing.harvard.edu; stvjc@channing.harvard.edu; rebar@channing.harvard.edu			NHLBI; National Heart, Lung and Blood Institute [U01 HL075419, U01 HL65899, P01 HL083069, T32 HL07427]; National Institutes of Health; NIH/NHLBI [R01 HL086601, N01 HR16049, K08 HL074193]	We thank all subjects for their ongoing participation in this study. We acknowledge the CAMP investigators and research team, supported by NHLBI, for collection of CAMP Genetic Ancillary Study data. All work on data collected from the CAMP Genetic Ancillary Study was conducted at the Channing Laboratory of the Brigham and Women's Hospital and Harvard Medical School under appropriate CAMP policies and human subject's protections. The CAMP Genetics Ancillary Study is supported by U01 HL075419, U01 HL65899, P01 HL083069, and T32 HL07427 from the National Heart, Lung and Blood Institute, National Institutes of Health. We thank Drs. Andy Liu and Stanley Szefler (National Jewish, Denver CO), Nadia Hansel, Greg Diette and Franklin Adkinson (Johns Hopkins, Baltimore MD), and Karen DeMuth, Robert Strunk and Mario Castro (Washington University, St. Louis MO) for their assistance in collection of CD4+ lymphocytes and RNA extraction. We thank Chris Allaire, Barbara Klanderman, and Stephanie Metje for their assistance with sample collection and processing. This work is supported by the NIH/NHLBI grants R01 HL086601 (Raby) and N01 HR16049 (Weiss). Dr. Raby is recipient of a Mentored Clinical Scientist Development Award from NHLBI/NIH (K08 HL074193).	Stranger BE, 2007, NAT GENET, V39, P1217, DOI 10.1038/ng2142; Goh KI, 2007, P NATL ACAD SCI USA, V104, P8685, DOI 10.1073/pnas.0701361104; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Du P, 2008, BIOINFORMATICS, V24, P1547, DOI 10.1093/bioinformatics/btn224; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Bouwmeester T, 2004, NAT CELL BIOL, V6, P97, DOI 10.1038/ncb1086; Butte AJ, 2000, P NATL ACAD SCI USA, V97, P12182, DOI 10.1073/pnas.220392197; Jansen RC, 2001, TRENDS GENET, V17, P388, DOI 10.1016/S0168-9525(01)02310-1; Schadt EE, 2005, NAT GENET, V37, P710, DOI 10.1038/ng1589; Dixon AL, 2007, NAT GENET, V39, P1202, DOI 10.1038/ng2109; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; GENTLEMAN R, 2008, FILTER GENES; Hansel NN, 2005, J LAB CLIN MED, V145, P263, DOI 10.1016/j.lab.2005.02.010; Hogan SP, 1998, EUR J IMMUNOL, V28, P413; Li Y, 2007, J IMMUNOL, V179, P8322; Opgen-Rhein R, 2007, BMC SYSTEMS BIOL, V1; Schafer J, 2007, STAT APPL GENET MOL, V4; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062	18	13	13	0	1	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1752-0509			BMC SYST BIOL	BMC Syst. Biol.	MAY 27	2009	3								55	10.1186/1752-0509-3-55		9	Mathematical & Computational Biology	Mathematical & Computational Biology	458CW	WOS:000266992200001	19473523	
J	Kerber, RA; O'Brien, E; Cawthon, RM				Kerber, Richard A.; O'Brien, Elizabeth; Cawthon, Richard M.			Gene expression profiles associated with aging and mortality in humans	AGING CELL			English	Article						aging; cell cycle; cell lines; CEU; gene expression; longevity	GENOME-WIDE ASSOCIATION; TELOMERE LENGTH; LONGEVITY GENES; BLOOD-CELLS; LIFE-SPAN; REGRESSION; PHENOTYPES; SURVIVAL; LINKAGE; DISCOVERY	We investigated the hypothesis that gene expression profiles in cultured cell lines from adults, aged 57-97 years, contain information about the biological age and potential longevity of the donors. We studied 104 unrelated grandparents from 31 Utah CEU (Centre d'Etude du Polymorphisme Humain - Utah) families, for whom lymphoblastoid cell lines were established in the 1980s. Combining publicly available gene expression data from these cell lines, and survival data from the Utah Population Database, we tested the relationship between expression of 2151 always-expressed genes, age, and survival of the donors. Approximately 16% of 2151 expression levels were associated with donor age: 10% decreased in expression with age, and 6% increased with age. Cell division cycle 42 (CDC42) and CORO1A exhibited strong associations both with age at draw and survival after draw (multiple comparisons-adjusted Monte Carlo P-value < 0.05). In general, gene expressions that increased with age were associated with increased mortality. Gene expressions that decreased with age were generally associated with reduced mortality. A multivariate estimate of biological age modeled from expression data was dominated by CDC42 expression, and was a significant predictor of survival after blood draw. A multivariate model of survival as a function of gene expression was dominated by CORO1A expression. This model accounted for approximately 23% of the variation in survival among the CEU grandparents. Some expression levels were negligibly associated with age in this cross-sectional dataset, but strongly associated with inter-individual differences in survival. These observations may lead to new insights regarding the genetic contribution to exceptional longevity.	[Kerber, Richard A.] Dept Oncol Sci, Salt Lake City, UT 84112 USA; [Kerber, Richard A.; O'Brien, Elizabeth] Univ Utah, Huntsman Canc Inst, Salt Lake City, UT 84112 USA; [Cawthon, Richard M.] Univ Utah, Dept Human Genet, Salt Lake City, UT 84112 USA	Kerber, RA (reprint author), Univ Louisville, Sch Publ Hlth & Informat Sci, Louisville, KY 40292 USA.	rich.kerber@louisville.edu	Kerber, Richard/B-8038-2009		NIH [R01-AG022095, R21-AG030034]	We thank Geri Mineau, Alison Fraser and Janice Conrads at the Huntsman Cancer Institute's Pedigree and Population Resource for collection of survival and cause of death data from the Utah Population Database; and Mark Leppert and Missy Dixon of the Utah Genetic Reference Project for additional collection of survival data, and Ray White, Ken Boucher, and Ken Smith for valuable discussions of this work. We would also like to thank Richard Spielman and Vivian Cheung and colleagues for making the CEU family gene expression data publicly available. This work was supported by NIH grant R01-AG022095 (K. Smith, P.I.), NIH grant R21-AG030034 (R. Cawthon, P.I.), and the Huntsman Cancer Foundation. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Liu WM, 2002, BIOINFORMATICS, V18, P1593, DOI 10.1093/bioinformatics/18.12.1593; Reiner A, 2003, BIOINFORMATICS, V19, P368, DOI 10.1093/bioinformatics/btf877; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Powers RW, 2006, GENE DEV, V20, P174, DOI 10.1101/gad.1381406; Almasy L, 1998, AM J HUM GENET, V62, P1198, DOI 10.1086/301844; Kerber RA, 2001, J GERONTOL A-BIOL, V56, pB130; Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436; Puca AA, 2001, P NATL ACAD SCI USA, V98, P10505, DOI 10.1073/pnas.181337598; Cawthon RM, 2003, LANCET, V361, P393, DOI 10.1016/S0140-6736(03)12384-7; Schadt EE, 2003, NATURE, V422, P297, DOI 10.1038/nature01482; Cheung VG, 2005, NATURE, V437, P1365, DOI 10.1038/nature04244; Efron B, 2007, ANN APPL STAT, V1, P107, DOI 10.1214/07-AOAS101; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Efron B, 2004, ANN STAT, V32, P407; WHITE R, 1985, NATURE, V313, P101, DOI 10.1038/313101a0; Beekman M, 2006, J GERONTOL A-BIOL, V61, P355; Brown MD, 2006, TRENDS CELL BIOL, V16, P242, DOI 10.1016/j.tcb.2006.03.002; Cheung VG, 2003, NAT GENET, V33, P422, DOI 10.1038/ng1094; Cheung VG, 2002, NAT GENET, V32, P522, DOI 10.1038/ng1036; Dai MH, 2005, NUCLEIC ACIDS RES, V33, DOI 10.1093/nar/gni179; DAUSSET J, 1990, GENOMICS, V6, P575, DOI 10.1016/0888-7543(90)90491-C; Dustin ML, 2006, SCIENCE, V313, P767, DOI 10.1126/science.1131714; Fisher R.A., 1932, STAT METHODS RES WOR; Foger N, 2006, SCIENCE, V313, P839, DOI 10.1126/science.1130563; Geesaman BJ, 2003, P NATL ACAD SCI USA, V100, P14115, DOI 10.1073/pnas.1936249100; Goring HHH, 2007, NAT GENET, V39, P1208, DOI 10.1038/ng2119; Hamilton B, 2005, GENE DEV, V19, P1544, DOI 10.1101/gad.1308205; Haraldsson MK, 2008, IMMUNITY, V28, P40, DOI 10.1016/j.immuni.2007.11.023; Li BB, 2003, MOL BIOL CELL, V14, P5060, DOI 10.1091/E03-06-0403; Liu HF, 2007, BIOINFORMATICS, V23, P2385, DOI 10.1093/bioinformatics/btm360; Lunetta KL, 2007, BMC MED GENET, V8, DOI 10.1186/1471-2350-8-S1-S13; Mathers JC, 2006, MECH AGEING DEV, V127, P584, DOI 10.1016/j.mad.2006.01.018; Mecham BH, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh071; Merrill RM, 2003, ANN EPIDEMIOL, V13, P704, DOI 10.1016/S1047-2797(03)00063-2; Monks SA, 2004, AM J HUM GENET, V75, P1094, DOI 10.1086/426461; Morley M, 2004, NATURE, V430, P743, DOI 10.1038/nature02797; Mueller P, 2008, NAT IMMUNOL, V9, P424, DOI 10.1038/ni1570; Nebel A, 2005, P NATL ACAD SCI USA, V102, P7906, DOI 10.1073/pnas.0408670102; Ruchaud S, 2007, NAT REV MOL CELL BIO, V8, P798, DOI 10.1038/nrm2257; Ryder MI, 2004, ORAL MICROBIOL IMMUN, V19, P39, DOI 10.1046/j.0902-0055.2003.00110.x; Segal MR, 2006, BIOSTATISTICS, V7, P268, DOI 10.1093/biostatistics/kxj006; Seong KH, 2001, BIOGERONTOLOGY, V2, P209, DOI 10.1023/A:1011517325711; Shiow LR, 2008, NAT IMMUNOL, V9, P1307, DOI 10.1038/ni.1662; Stranger BE, 2005, PLOS GENET, V1, P695, DOI 10.1371/journal.pgen.0010078; Svenson U, 2008, CANCER RES, V68, P3618, DOI 10.1158/0008-5472.CAN-07-6497; THERNEAU TM, 2007, MIXED EFFECT COX MOD; van Leeuwen DM, 2005, TOXICOL SCI, V86, P200, DOI 10.1093/toxsci/kfi168; Wang L, 2007, P NATL ACAD SCI USA, V104, P1248, DOI 10.1073/pnas.0609149104; Wilson CL, 2004, BIOTECHNIQUES, V36, P498; Wu ZJ, 2005, J COMPUT BIOL, V12, P882, DOI 10.1089/cmb.2005.12.882; Wylie JE, 2003, TRENDS BIOTECHNOL, V21, P113, DOI 10.1016/S0167-7799(02)00039-2; Yang J, 2007, BLOOD, V110, P2034, DOI 10.1182/blood-2007-02-073700; Zhang W, 2007, PHARMACOGENET GENOM, V17, P447, DOI 10.1097/FPC.0b013e3280121ffe	53	16	16	0	5	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1474-9718			AGING CELL	Aging Cell	JUN	2009	8	3					239	250		10.1111/j.1474-9726.2009.00467.x		12	Cell Biology; Geriatrics & Gerontology	Cell Biology; Geriatrics & Gerontology	450RE	WOS:000266417700003	19245677	
J	Fan, JQ; Feng, Y; Wu, YC				Fan, Jianqing; Feng, Yang; Wu, Yichao			NETWORK EXPLORATION VIA THE ADAPTIVE LASSO AND SCAD PENALTIES	ANNALS OF APPLIED STATISTICS			English	Article						Adaptive LASSO; covariance selection; Gaussian concentration graphical model; genetic network; LASSO; precision matrix; SCAD	NONCONCAVE PENALIZED LIKELIHOOD; GAUSSIAN CONCENTRATION GRAPHS; COVARIANCE-SELECTION; VARIABLE SELECTION; ORACLE PROPERTIES; MODEL SELECTION; BREAST-CANCER; CLASSIFICATION; CHEMOTHERAPY; DOXORUBICIN	Graphical models are frequently used to explore networks, such as genetic networks, among a set of variables. This is usually carried out via exploring the sparsity of the precision matrix of the variables under consideration. Penalized likelihood methods are often used in such explorations. Yet, positive-definiteness constraints of precision matrices make the optimization problem challenging. We introduce nonconcave penalties and the adaptive LASSO penalty to attenuate the bias problem in the network estimation. Through the local linear approximation to the nonconcave penalty functions, the problem of precision matrix estimation is recast as a sequence of penalized likelihood problems with a weighted L(1) penalty and solved using the efficient algorithm of Friedman et al. [Biostatistics 9 (2008) 432-441]. Our estimation schemes are applied to two real datasets. Simulation experiments and asymptotic theory are used to justify our proposed methods.	[Fan, Jianqing; Feng, Yang] Princeton Univ, Dept Operat Res & Financial Engn, Princeton, NJ 08544 USA; [Wu, Yichao] N Carolina State Univ, Dept Stat, Raleigh, NC 27695 USA	Fan, JQ (reprint author), Princeton Univ, Dept Operat Res & Financial Engn, Princeton, NJ 08544 USA.		Feng, Yang/D-3329-2015	Feng, Yang/0000-0001-7746-7598	NIH [R01-GM072611, DMS-07-04337, DMS-0714554]	Supported in part by NIH Grant R01-GM072611 and NSF Grants DMS-07-04337 and DMS-0714554.	Fan JQ, 2008, ANN STAT, V36, P2605, DOI 10.1214/07-AOS504; Drton M, 2004, BIOMETRIKA, V91, P591, DOI 10.1093/biomet/91.3.591; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Shen HP, 2005, APPL STOCH MODEL BUS, V21, P251, DOI 10.1002/asmb.598; Wong F, 2003, BIOMETRIKA, V90, P809, DOI 10.1093/biomet/90.4.809; Rothman AJ, 2008, ELECTRON J STAT, V2, P494, DOI 10.1214/08-EJS176; Li HZ, 2006, BIOSTATISTICS, V7, P302, DOI 10.1093/biostatistics/kxj008; Zou H, 2008, ANN STAT, V36, P1509, DOI 10.1214/009053607000000802; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Yuan M, 2007, BIOMETRIKA, V94, P19, DOI 10.1093/biomet/asm018; Breiman L, 1996, ANN STAT, V24, P2350; D'Aspremont A, 2008, SIAM J MATRIX ANAL A, V30, P56, DOI 10.1137/060670985; Dobra A, 2004, J MULTIVARIATE ANAL, V90, P196, DOI 10.1016/j.jmva.2004.02.009; Edwards D., 2000, INTRO GRAPHICAL MODE; Efron B, 2004, ANN STAT, V32, P409; Fan J., 1997, J ITALIAN STAT ASS, V6, P131; FAN J, 2008, NETWORK EXPLORATIO S; Fan JQ, 2004, ANN STAT, V32, P928, DOI 10.1214/009053604000000256; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; Hess KR, 2006, J CLIN ONCOL, V24, P4236, DOI 10.1200/JCO.2006.05.6861; Huang JZ, 2006, BIOMETRIKA, V93, P85, DOI 10.1093/biomet/93.1.85; Hunter DR, 2005, ANN STAT, V33, P1617, DOI 10.1214/009053605000000200; Kuerer HM, 1999, J CLIN ONCOL, V17, P460; LAM C, 2008, SPARSISTENCY R UNPUB; Levina E, 2008, ANN APPL STAT, V2, P245, DOI 10.1214/07-AOAS139; Lin S. P., 1985, MULTIVARIATE ANAL, P411; Mardia KV, 1979, MULTIVARIATE ANAL; Schafer J, 2005, BIOINFORMATICS, V21, P754, DOI 10.1093/bioinformatics/bti062	33	60	61	2	8	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	JUN	2009	3	2					521	541		10.1214/08-AOAS215		21	Statistics & Probability	Mathematics	522EC	WOS:000271979600002		
J	Pan, W				Pan, Wei			Network-based multiple locus linkage analysis of expression traits	BIOINFORMATICS			English	Article							VARIABLE SELECTION; TRANSCRIPTIONAL REGULATION; MODEL SELECTION; GENOMIC DATA; EXPERIMENTAL CROSSES; STATISTICAL-METHODS; REGRESSION; YEAST; REGULARIZATION; IDENTIFICATION	Motivation: We consider the problem of multiple locus linkage analysis for expression traits of genes in a pathway or a network. To capitalize on co-expression of functionally related genes, we propose a penalized regression method that maps multiple expression quantitative trait loci (eQTLs) for all related genes simultaneously while accounting for their shared functions as specified a priori by a gene pathway or network. Results: An analysis of a mouse dataset and simulation studies clearly demonstrate the advantage of the proposed method over a standard approach that ignores biological knowledge of gene networks.	Univ Minnesota, Sch Publ Hlth, Div Biostat, Minneapolis, MN 55455 USA	Pan, W (reprint author), Univ Minnesota, Sch Publ Hlth, Div Biostat, A460 Mayo Bldg,MMC 303, Minneapolis, MN 55455 USA.				National Institutes of Health [GM081535, HL65462]	National Institutes of Health (GM081535 and HL65462).	Broman KW, 2003, BIOINFORMATICS, V19, P889, DOI 10.1093/bioinformatics/btg112; Lee I, 2004, SCIENCE, V306, P1555, DOI 10.1126/science.1099511; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Conlon EM, 2003, P NATL ACAD SCI USA, V100, P3339, DOI 10.1073/pnas.0630591100; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Schadt EE, 2003, NATURE, V422, P297, DOI 10.1038/nature01482; Ashburner M, 2000, NAT GENET, V25, P25; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; GEORGE EI, 1993, J AM STAT ASSOC, V88, P881, DOI 10.2307/2290777; Efron B, 2004, ANN STAT, V32, P407; Brem RB, 2002, SCIENCE, V296, P752, DOI 10.1126/science.1069516; Aten JE, 2008, BMC SYST BIOL, V2, DOI 10.1186/1752-0509-2-34; Bogdan M, 2004, GENETICS, V167, P989, DOI 10.1534/genetics.103.021683; Breiman L, 1996, ANN STAT, V24, P2350; Broman KW, 2002, J R STAT SOC B, V64, P641, DOI 10.1111/1467-9868.00354; Faith JJ, 2007, PLOS BIOL, V5, P54, DOI 10.1371/journal.pbio.0050008; Fraser AG, 2004, NAT GENET, V36, P559, DOI 10.1038/ng1370; Gelfond JAL, 2007, BIOMETRICS, V63, P1108, DOI 10.1111/j.1541-0420.2007.00778.x; Ghazalpour A, 2006, PLOS GENET, V2, P1182, DOI 10.1371/1journal.pgen.0020130; Jia ZY, 2007, GENETICS, V176, P611, DOI 10.1534/genetics.106.065599; JIANG CJ, 1995, GENETICS, V140, P1111; Kendziorski C, 2006, MAMM GENOME, V17, P509, DOI 10.1007/s00335-005-0189-6; Kendziorski CM, 2006, BIOMETRICS, V62, P19, DOI 10.1111/j.1541-0420.2005.00437.x; Kliebenstein DJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-308; Lan H, 2006, PLOS GENET, V2, P51, DOI 10.1371/journal.pgen.0020006; Lan H, 2003, GENETICS, V164, P1607; Li CY, 2008, BIOINFORMATICS, V24, P1175, DOI 10.1093/bioinformatics/btn081; Li HQ, 2006, HUM MOL GENET, V15, P481, DOI 10.1093/hmg/ddi462; Li Na, 2007, BMC Proc, V1 Suppl 1, pS117; Liu B, 2008, GENETICS, V178, P1763, DOI 10.1534/genetics.107.080069; Neto EC, 2008, GENETICS, V179, P1089, DOI 10.1534/genetics.107.085167; PAN W, 2009, BIOMETRICS IN PRESS; PAN W, 2006, APPL STAT, V55, P301; Salgado H, 2004, NUCLEIC ACIDS RES, V32, pD303, DOI 10.1093/nar/gkh140; Sen S, 2001, GENETICS, V159, P371; Storey JD, 2005, PLOS BIOL, V3, P1380, DOI 10.1371/journal.pbio.0030267; Tseng GC, 2007, BIOINFORMATICS, V23, P2247, DOI 10.1093/bioinformatics/btm320; Wei P, 2008, IEEE ACM T COMPUT BI, V5, P401, DOI 10.1109/TCBB.2007.1062; Wei P, 2008, BIOINFORMATICS, V24, P404, DOI 10.1093/bioinformatics/btm612; Wei Z, 2007, BIOINFORMATICS, V23, P1537, DOI 10.1093/bioinformatics/btm129; Xu SZ, 2007, BIOMETRICS, V63, P513, DOI 10.1111/j.1541-0420.2006.00711.x; Xu SZ, 2003, GENETICS, V163, P789; Yi NJ, 2003, GENETICS, V164, P1129; Zhang YM, 2005, HEREDITY, V95, P96, DOI 10.1038/sj.hdy.6800702; ZHAO P, 2006, ANN STAT IN PRESS; ZHAO P, 2004, 678 UC BERK DEP STAT; ZOU W, 2007, MULTIPLE INTERVAL MA	49	9	9	3	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JUN 1	2009	25	11					1390	1396		10.1093/bioinformatics/btp177		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	446GG	WOS:000266109500008	19336446	
