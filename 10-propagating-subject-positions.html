<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Machine Learning: Archaeology of a Data Practice</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Machine Learning: Archaeology of a Data Practice">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Machine Learning: Archaeology of a Data Practice" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Machine Learning: Archaeology of a Data Practice" />
  
  
  

<meta name="author" content="Adrian Mackenzie">


<meta name="date" content="2017-03-25">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="9-regularizing-and-materializing-objects.html">
<link rel="next" href="11-conclusion-out-of-the-data.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="1-acknowledgments.html"><a href="1-acknowledgments.html"><i class="fa fa-check"></i><b>1</b> Acknowledgments</a></li>
<li class="chapter" data-level="2" data-path="2-preface.html"><a href="2-preface.html"><i class="fa fa-check"></i><b>2</b> Preface</a></li>
<li class="chapter" data-level="3" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html"><i class="fa fa-check"></i><b>3</b> Introduction: Into the Data</a><ul>
<li class="chapter" data-level="3.1" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#three-accumulations-settings-data-and-devices"><i class="fa fa-check"></i><b>3.1</b> Three accumulations: settings, data and devices</a></li>
<li class="chapter" data-level="3.2" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#who-or-what-is-a-machine-learner"><i class="fa fa-check"></i><b>3.2</b> Who or what is a machine learner?</a></li>
<li class="chapter" data-level="3.3" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#algorithmic-control-to-the-machine-learners"><i class="fa fa-check"></i><b>3.3</b> Algorithmic control to the machine learners?</a></li>
<li class="chapter" data-level="3.4" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#the-archaeology-of-operations"><i class="fa fa-check"></i><b>3.4</b> The archaeology of operations</a></li>
<li class="chapter" data-level="3.5" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#asymmetries-in-common-knowledge"><i class="fa fa-check"></i><b>3.5</b> Asymmetries in common knowledge</a></li>
<li class="chapter" data-level="3.6" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#what-cannot-be-automated"><i class="fa fa-check"></i><b>3.6</b> What cannot be automated?</a></li>
<li class="chapter" data-level="3.7" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#different-fields-in-machine-learning"><i class="fa fa-check"></i><b>3.7</b> Different fields in machine learning?</a></li>
<li class="chapter" data-level="3.8" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#the-diagram-in-critical-thought"><i class="fa fa-check"></i><b>3.8</b> The diagram in critical thought</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html"><i class="fa fa-check"></i><b>4</b> Diagramming machines</a><ul>
<li class="chapter" data-level="4.1" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#we-dont-have-to-write-programs"><i class="fa fa-check"></i><b>4.1</b> ‘We don’t have to write programs’?</a></li>
<li class="chapter" data-level="4.2" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-elements-of-machine-learning"><i class="fa fa-check"></i><b>4.2</b> The elements of machine learning</a></li>
<li class="chapter" data-level="4.3" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#who-reads-machine-learning-textbooks"><i class="fa fa-check"></i><b>4.3</b> Who reads machine learning textbooks?</a></li>
<li class="chapter" data-level="4.4" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#r-a-matrix-of-transformations"><i class="fa fa-check"></i><b>4.4</b> <code>R</code>: a matrix of transformations</a></li>
<li class="chapter" data-level="4.5" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-obdurate-mathematical-glint-of-machine-learning"><i class="fa fa-check"></i><b>4.5</b> The obdurate mathematical glint of machine learning</a></li>
<li class="chapter" data-level="4.6" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#cs229-2007-returning-again-and-again-to-certain-features"><i class="fa fa-check"></i><b>4.6</b> CS229, 2007: returning again and again to certain features</a></li>
<li class="chapter" data-level="4.7" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-visible-learning-of-machine-learning"><i class="fa fa-check"></i><b>4.7</b> The visible learning of machine learning</a></li>
<li class="chapter" data-level="4.8" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-diagram-of-an-operational-formation"><i class="fa fa-check"></i><b>4.8</b> The diagram of an operational formation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html"><i class="fa fa-check"></i><b>5</b> Vectorisation and its consequences</a><ul>
<li class="chapter" data-level="5.1" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#vector-space-and-geometry"><i class="fa fa-check"></i><b>5.1</b> Vector space and geometry</a></li>
<li class="chapter" data-level="5.2" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#mixing-places"><i class="fa fa-check"></i><b>5.2</b> Mixing places</a></li>
<li class="chapter" data-level="5.3" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#truth-is-no-longer-in-the-table"><i class="fa fa-check"></i><b>5.3</b> Truth is no longer in the table?</a></li>
<li class="chapter" data-level="5.4" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#the-epistopic-fault-line-in-tables"><i class="fa fa-check"></i><b>5.4</b> The epistopic fault line in tables</a></li>
<li class="chapter" data-level="5.5" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#surface-and-depths-the-problem-of-volume-in-data"><i class="fa fa-check"></i><b>5.5</b> Surface and depths: the problem of volume in data</a></li>
<li class="chapter" data-level="5.6" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#vector-space-expansion"><i class="fa fa-check"></i><b>5.6</b> Vector space expansion</a></li>
<li class="chapter" data-level="5.7" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#drawing-lines-in-a-common-space-of-transformation"><i class="fa fa-check"></i><b>5.7</b> Drawing lines in a common space of transformation</a></li>
<li class="chapter" data-level="5.8" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#implicit-vectorization-in-code-and-infrastructures"><i class="fa fa-check"></i><b>5.8</b> Implicit vectorization in code and infrastructures</a></li>
<li class="chapter" data-level="5.9" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#lines-traversing-behind-the-light"><i class="fa fa-check"></i><b>5.9</b> Lines traversing behind the light</a></li>
<li class="chapter" data-level="5.10" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#the-vectorised-table"><i class="fa fa-check"></i><b>5.10</b> The vectorised table?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html"><i class="fa fa-check"></i><b>6</b> Machines finding functions</a><ul>
<li class="chapter" data-level="6.1" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#learning-functions"><i class="fa fa-check"></i><b>6.1</b> Learning functions</a></li>
<li class="chapter" data-level="6.2" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#supervised-unsupervised-reinforcement-learning-and-functions"><i class="fa fa-check"></i><b>6.2</b> Supervised, unsupervised, reinforcement learning and functions</a></li>
<li class="chapter" data-level="6.3" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#which-function-operates"><i class="fa fa-check"></i><b>6.3</b> Which function operates?</a></li>
<li class="chapter" data-level="6.4" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#what-does-a-function-learn"><i class="fa fa-check"></i><b>6.4</b> What does a function learn?</a></li>
<li class="chapter" data-level="6.5" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#observing-with-curves-the-logistic-function"><i class="fa fa-check"></i><b>6.5</b> Observing with curves: the logistic function</a></li>
<li class="chapter" data-level="6.6" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#the-cost-of-curves-in-machine-learning"><i class="fa fa-check"></i><b>6.6</b> The cost of curves in machine learning</a></li>
<li class="chapter" data-level="6.7" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#curves-and-the-variation-in-models"><i class="fa fa-check"></i><b>6.7</b> Curves and the variation in models</a></li>
<li class="chapter" data-level="6.8" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#observing-costs-losses-and-objectives-through-optimisation"><i class="fa fa-check"></i><b>6.8</b> Observing costs, losses and objectives through optimisation</a></li>
<li class="chapter" data-level="6.9" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#gradients-as-partial-observers"><i class="fa fa-check"></i><b>6.9</b> Gradients as partial observers</a></li>
<li class="chapter" data-level="6.10" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#the-power-to-learn"><i class="fa fa-check"></i><b>6.10</b> The power to learn</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html"><i class="fa fa-check"></i><b>7</b> Probabilisation and the Taming of Machines}</a><ul>
<li class="chapter" data-level="7.1" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#data-reduces-uncertainty"><i class="fa fa-check"></i><b>7.1</b> Data reduces uncertainty?</a></li>
<li class="chapter" data-level="7.2" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#machine-learning-as-statistics-inside-out"><i class="fa fa-check"></i><b>7.2</b> Machine learning as statistics inside out</a></li>
<li class="chapter" data-level="7.3" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#distributed-probabilities"><i class="fa fa-check"></i><b>7.3</b> Distributed probabilities</a></li>
<li class="chapter" data-level="7.4" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#naive-bayes-and-the-distribution-of-probabilities"><i class="fa fa-check"></i><b>7.4</b> Naive Bayes and the distribution of probabilities</a></li>
<li class="chapter" data-level="7.5" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#spam-when-foralln-is-too-much"><i class="fa fa-check"></i><b>7.5</b> Spam: when <span class="math inline">\(\forall{N}\)</span> is too much?</a></li>
<li class="chapter" data-level="7.6" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#the-improbable-success-of-the-naive-bayes-classifier"><i class="fa fa-check"></i><b>7.6</b> The improbable success of the Naive Bayes classifier</a></li>
<li class="chapter" data-level="7.7" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#ancestral-probabilities-in-documents-inference-and-prediction"><i class="fa fa-check"></i><b>7.7</b> Ancestral probabilities in documents: inference and prediction</a></li>
<li class="chapter" data-level="7.8" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#statistical-decompositions-bias-variance-and-observed-errors"><i class="fa fa-check"></i><b>7.8</b> Statistical decompositions: bias, variance and observed errors</a></li>
<li class="chapter" data-level="7.9" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html#does-machine-learning-construct-a-new-statistical-reality"><i class="fa fa-check"></i><b>7.9</b> Does machine learning construct a new statistical reality?</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-patterns-and-differences.html"><a href="8-patterns-and-differences.html"><i class="fa fa-check"></i><b>8</b> Patterns and differences</a><ul>
<li class="chapter" data-level="8.1" data-path="8-patterns-and-differences.html"><a href="8-patterns-and-differences.html#splitting-and-the-growth-of-trees"><i class="fa fa-check"></i><b>8.1</b> Splitting and the growth of trees</a></li>
<li class="chapter" data-level="8.2" data-path="8-patterns-and-differences.html"><a href="8-patterns-and-differences.html#differences-in-recursive-partitioning"><i class="fa fa-check"></i><b>8.2</b> 1984: Differences in recursive partitioning</a></li>
<li class="chapter" data-level="8.3" data-path="8-patterns-and-differences.html"><a href="8-patterns-and-differences.html#limiting-differences"><i class="fa fa-check"></i><b>8.3</b> Limiting differences</a></li>
<li class="chapter" data-level="8.4" data-path="8-patterns-and-differences.html"><a href="8-patterns-and-differences.html#the-successful-dispersion-of-the-support-vector-machine"><i class="fa fa-check"></i><b>8.4</b> The successful dispersion of the support vector machine</a></li>
<li class="chapter" data-level="8.5" data-path="8-patterns-and-differences.html"><a href="8-patterns-and-differences.html#differences-blur"><i class="fa fa-check"></i><b>8.5</b> Differences blur?</a></li>
<li class="chapter" data-level="8.6" data-path="8-patterns-and-differences.html"><a href="8-patterns-and-differences.html#bending-the-decision-boundary"><i class="fa fa-check"></i><b>8.6</b> Bending the decision boundary</a></li>
<li class="chapter" data-level="8.7" data-path="8-patterns-and-differences.html"><a href="8-patterns-and-differences.html#instituting-patterns"><i class="fa fa-check"></i><b>8.7</b> Instituting patterns</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html"><i class="fa fa-check"></i><b>9</b> Regularizing and materializing objects}</a><ul>
<li class="chapter" data-level="9.1" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html#genomic-referentiality-and-materiality"><i class="fa fa-check"></i><b>9.1</b> Genomic referentiality and materiality</a></li>
<li class="chapter" data-level="9.2" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html#the-genome-as-threshold-object"><i class="fa fa-check"></i><b>9.2</b> The genome as threshold object</a></li>
<li class="chapter" data-level="9.3" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html#genomic-knowledges-and-their-datasets"><i class="fa fa-check"></i><b>9.3</b> Genomic knowledges and their datasets</a></li>
<li class="chapter" data-level="9.4" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html#the-advent-of-wide-dirty-and-mixed-data"><i class="fa fa-check"></i><b>9.4</b> The advent of ‘wide, dirty and mixed’ data</a></li>
<li class="chapter" data-level="9.5" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html#cross-validating-machine-learning-in-genomics"><i class="fa fa-check"></i><b>9.5</b> Cross-validating machine learning in genomics</a></li>
<li class="chapter" data-level="9.6" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html#proliferation-of-discoveries"><i class="fa fa-check"></i><b>9.6</b> Proliferation of discoveries</a></li>
<li class="chapter" data-level="9.7" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html#variations-in-the-object-or-in-the-machine-learner"><i class="fa fa-check"></i><b>9.7</b> Variations in the object or in the machine learner?</a></li>
<li class="chapter" data-level="9.8" data-path="9-regularizing-and-materializing-objects.html"><a href="9-regularizing-and-materializing-objects.html#whole-genome-functions"><i class="fa fa-check"></i><b>9.8</b> Whole genome functions</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html"><i class="fa fa-check"></i><b>10</b> Propagating subject positions}</a><ul>
<li class="chapter" data-level="10.1" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#propagation-across-human-machine-boundaries"><i class="fa fa-check"></i><b>10.1</b> Propagation across human-machine boundaries</a></li>
<li class="chapter" data-level="10.2" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#competitive-positioning"><i class="fa fa-check"></i><b>10.2</b> Competitive positioning</a></li>
<li class="chapter" data-level="10.3" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#a-privileged-machine-and-its-diagrammatic-forms"><i class="fa fa-check"></i><b>10.3</b> A privileged machine and its diagrammatic forms</a></li>
<li class="chapter" data-level="10.4" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#varying-subject-positions-in-code"><i class="fa fa-check"></i><b>10.4</b> Varying subject positions in code</a></li>
<li class="chapter" data-level="10.5" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#the-subjects-of-a-hidden-operation"><i class="fa fa-check"></i><b>10.5</b> The subjects of a hidden operation</a></li>
<li class="chapter" data-level="10.6" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#algorithms-that-propagate-errors"><i class="fa fa-check"></i><b>10.6</b> Algorithms that propagate errors</a></li>
<li class="chapter" data-level="10.7" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#competitions-as-examination"><i class="fa fa-check"></i><b>10.7</b> Competitions as examination</a></li>
<li class="chapter" data-level="10.8" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#superimposing-power-and-knowledge"><i class="fa fa-check"></i><b>10.8</b> Superimposing power and knowledge</a></li>
<li class="chapter" data-level="10.9" data-path="10-propagating-subject-positions.html"><a href="10-propagating-subject-positions.html#ranked-subject-positions"><i class="fa fa-check"></i><b>10.9</b> Ranked subject positions</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-conclusion-out-of-the-data.html"><a href="11-conclusion-out-of-the-data.html"><i class="fa fa-check"></i><b>11</b> Conclusion: Out of the Data}</a><ul>
<li class="chapter" data-level="11.1" data-path="11-conclusion-out-of-the-data.html"><a href="11-conclusion-out-of-the-data.html#machine-learners"><i class="fa fa-check"></i><b>11.1</b> 250,000 machine learners</a></li>
<li class="chapter" data-level="11.2" data-path="11-conclusion-out-of-the-data.html"><a href="11-conclusion-out-of-the-data.html#a-summary-of-the-argument"><i class="fa fa-check"></i><b>11.2</b> A summary of the argument</a></li>
<li class="chapter" data-level="11.3" data-path="11-conclusion-out-of-the-data.html"><a href="11-conclusion-out-of-the-data.html#in-situ-hybridization"><i class="fa fa-check"></i><b>11.3</b> In-situ hybridization</a></li>
<li class="chapter" data-level="11.4" data-path="11-conclusion-out-of-the-data.html"><a href="11-conclusion-out-of-the-data.html#critical-operational-practice"><i class="fa fa-check"></i><b>11.4</b> Critical operational practice?</a></li>
<li class="chapter" data-level="11.5" data-path="11-conclusion-out-of-the-data.html"><a href="11-conclusion-out-of-the-data.html#obstacles-to-the-work-of-freeing-machine-learning"><i class="fa fa-check"></i><b>11.5</b> Obstacles to the work of freeing machine learning</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-references.html"><a href="12-references.html"><i class="fa fa-check"></i><b>12</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning: Archaeology of a Data Practice</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="propagating-subject-positions" class="section level1">
<h1><span class="header-section-number">10</span> Propagating subject positions}</h1>
<p></p>
<blockquote>
<p>If a proposition, a sentence, a group of signs can be called ‘statement,’ it is not therefore because, one day, someone happened to speak them or put them into some concrete form of writing; it is because the position of the subject can be assigned <span class="citation">(Foucault <a href="#ref-Foucault_1972">1972</a>, 95)</span> </p>
</blockquote>
<blockquote>
<p>Generalization error is what we care about <span class="citation">(<em>Lecture 9 | Machine Learning (Stanford)</em> <a href="#ref-Ng_2008f">2008</a>)</span></p>
</blockquote>
<blockquote>
<p><em>Predict if an online bid is made by a machine or a human</em>, ‘Facebook Recruiting IV: Human or Robot?’ <span class="citation">(Kaggle <a href="#ref-Kaggle_2015e">2015</a><a href="#ref-Kaggle_2015e">d</a>)</span></p>
</blockquote>
<p>Who is the subject of machine learning?  In early 2002, while carrying out an ethnographic study of ‘extreme programming,’ a software development methodology popular at that time <span class="citation">(Mackenzie and Monk <a href="#ref-Mackenzie_2004">2004</a>)</span>, I spent several months visiting a company in Manchester developing software for call centres. The software was to manage ‘knowledge’ in call centres such that any query from a caller could be readily answered by staff who would query a knowledge management system to find answers to the query.  This system was marketed on the promise of machine learning. It relied on an artificial neural network that learned to match queries and responses over time.  A taciturn neural network expert, Vlad, sat in a different part of the room from the developers working on the databases and the web interfaces. Vlad’s work on the neural network was at the core of the knowledge management system yet outside the orbit of the software development team and its agile software development processes. The rest of the team generally regarded Vlad and the neural net as an esoteric, temperamental yet powerful component, a hidden node we might say, of the knowledge management system.</p>
<p>As we have seen with <code>kittydar</code>, the position of machine learners is changing. They are no longer exotic or specialized, but banal or occasionally spectacular. Hilary Mason, who was Chief Scientist at bitly.com (an online service that shortens URLs), outlined an everyday machine learning subject position at a London conference in 2012 called ‘Bacon: Things Developers Love’: </p>
<blockquote>
<p>You have all of these things that are different – engineering, infrastructure, mathematics and computer science, curiosity and an understanding of human behaviour – that is something that usually falls under the social sciences. At the intersection of all these things are wonderful people. But we’re starting to develop something new, and that is - not that all of these things have not been done for a very long time - but we are only just now building systems where people, individual people, have all of these tools in one package, in one mind. (Hilary Mason, Chief Scientist, bitly.com) <span class="citation">(Mason <a href="#ref-Mason_2012">2012</a>)</span></p>
</blockquote>
<p>These ‘things that are different,’ what I have been calling an operational formation, assign subject positions. In what ways does machine learning assign subject positions? In front of an audience of several hundred software developers, Mason describes shifts in the work of programming associated with the growth of large amounts of data associated with ‘human behaviour.’ At the centre of this shift stand ‘wonderful people’ who combine practices and knowledges of communication infrastructure, technology, statistics, and ‘human behaviour’ through curiosity and technical skills. Mason was, in effect, telling her audience of software developers who they could become in relation to expansive changes occurring around and in their work.  The title of her talk was ‘machine learning for hackers’, and her audience were those hackers or programmers whose coding and programming attention may have been previously trained on web interfaces or database queries, but was now drawn towards machine learning. A change in programming practice and a shift towards machine learning was, she implied, the key to programmers becoming the wonderful people, agents of their own time, capable of doing what is only now just possible because it is all together in ‘one package, one mind.’</p>
<p>Neural nets stand at an intersection of infrastructure and cognition, and then propagate subject positions forwards and backwards. Their operations encourage and eleict competitively ranking as an ordering that not only compares human and machines, but subject positions more generally.</p>
<div id="propagation-across-human-machine-boundaries" class="section level2">
<h2><span class="header-section-number">10.1</span> Propagation across human-machine boundaries</h2>
<p>The concatenation of ‘one package, one mind’ does not definitively allocate agency to people or things. (A ‘package’ after all is another name for a library of code.) Mason adumbrates the outline of a subject position located at the intersection of network infrastructure, mathematics and human behaviour.<a href="#fn89" class="footnoteRef" id="fnref89"><sup>89</sup></a> Mason, herself one of <em>Fortune</em> magazines ‘Top 40 under 40’ business leaders to watch <span class="citation">(CNN <a href="#ref-CNN_2011">2011</a>)</span> and also featured in <em>Glamour</em>, a teenage fashion magazine <span class="citation">(Mason <a href="#ref-Mason_2012">2012</a>)</span>, might personify such a ‘wonderful person.’  She is not a lone example. In mid-2016 Google announced a comprehensive program to re-train its software developers as machine learners <span class="citation">(Levy <a href="#ref-Levy_2016">2016</a>)</span>.<a href="#fn90" class="footnoteRef" id="fnref90"><sup>90</sup></a></p>
<p>‘It is the privileged machine in this context that creates its marginalized human others’ writes Lucy Suchman in her account of the encounters that ‘effect “persons” and “machines” as distinct entities’ <span class="citation">(Suchman <a href="#ref-Suchman_2006">2006</a>, 269)</span>.   While Mason and other relatively well-known human machine learners are not exactly marginalized (just the opposite, they achieve minor celebrity status in some cases), Suchman recommends ‘recognition of the particularities of bodies and artifacts, of the cultural-historical practices through which human-machine differences are (re-)iteratively drawn, and of the possibilities for and politics of redistribution across the human machine boundary’ (285). The intersections that machine learners currently occupy are heavily re-distributional. In almost every instance, machine learners claim to do something that humans alone, no matter how expert, could not. Does the re-distribution of engineering, mathematics, curiosity, infrastructure and ‘something that usually falls under the social sciences’ (but perhaps no longer does so?) both energise subjects (‘its a pretty exciting time to be in any of these things’) and assign them a marginal albeit still pivotal position in relation to privileged machines?</p>
<p>Machine learner subject positions are the topic of this chapter. I focus on artificial neural networks, or neural nets, in their various forms ranging from the multilayer perceptron (MLP) to the convolutional neural nets (CNN), recurrent neural nets (RNN) and deep belief networks of many recent deep learning projects (particularly in machine learning competitions, as discussed below <span class="citation">(Dahl <a href="#ref-Dahl_2013">2013</a>)</span>).  in exploring the re-drawing of subject-machine positions.  Neural nets propagate between infrastructures, engineering and human behaviour (as Mason puts it), re-drawing human-machine differences, sometimes making it hard to seen what subject position they entail, where subjects are located or what they say, see and do.</p>
<p>Like other machine learners, neural nets re-draw human-machine differences. Geoffrey Hinton, Simon Osindero and Yee-Why Teh  writing in <em>Neural Computation</em> in 2006 described a ‘fast learning algorithm for deep belief nets’ <span class="citation">(Hinton, Osindero, and Teh <a href="#ref-Hinton_2006a">2006</a>)</span>. Their description, whilst mostly couched in terms of conditional distributions, model parameters, and error rates, also contains a section entitled ‘Looking into the Mind of a Neural Network’ (1545-1546). In that section, they describe how they used their deep belief network to <em>generate</em> rather than classify images.<a href="#fn91" class="footnoteRef" id="fnref91"><sup>91</sup></a> In the process they were able to see what the ‘associative memory has in mind’ (1545). The term ‘mind,’ they comment, ‘is not intended to be metaphorical’ (1546) because the neural net in question has a distributed memory of the digits it has seen. Put slightly more formally, ‘the network has a full generative model, so it is easy to look into its mind - we simply generate an image from its high-level representations’ (1529).  ‘Looking,’ as often the case in machine learning, takes the form of diagramming a pattern, partition or strain in the data.</p>
<p>The substitution of ‘mind’ and model reproduces many aspects of the figure of artificial intelligence (which has typically relied on rule-based or symbolic reasoning), but the appearance of ‘mind’ in the form of a generative model (see chapter <a href="#ch:probability"><strong>??</strong></a>) suggests a rather different subject position. Archaeologically, the description of subject positions entails more than giving voice the existential threat of artificial intelligence.. It first of all entails multiple positions linked to different groupings and statements in the operational formation. As I will suggest, neural nets are particularly interesting because they re-draw human-machine boundaries through a combination of feeding-forward of potentials and propagating backwards of differences specifically concerned with images. Similarly, the practice of machine learning shifts subject positions in a backward and forward movement. It propagates potentializing optimism even as it undercuts the very differences that give rise to that optimism.</p>
<pre><code>                     techniques year</code></pre>
<p>1 reliability 2009 2 bug prediction 2009 3 machine learning 2009 4 feature selection 2009 5 <NA> 2008 6 automatic document classification 2008 [1] 510216 3 discipline techniques year 1 statistics <NA> 2009 2 statistics <NA> 2008 3 statistics <NA> 2007 4 statistics distribution quantile 2003 5 statistics linear discriminant 2003 6 statistics monotone transformation 2003 [1] “neural network” “clustering”<br />
[3] “k mean” “feature selection”<br />
[5] “decision tree” “genetic algorithm”<br />
[7] “ensexpectation maximizationble” “pattern recognition”<br />
[9] “naive bayes” “random forest”<br />
[11] “feature extraction” “association rule”<br />
[13] “sexpectation maximizationi” “time serie”<br />
[15] “maximum likelihood” “rough set”<br />
[17] “algorithm” “knowledge discovery”<br />
[19] “sexpectation maximizationantic” “nearest neighbor”<br />
<img src="_main_files/figure-html/nn_de-1.png" width="1152" /></p>

<p>Almost every machine learning class, textbook, demonstration, and in recent years, machine learning competitions at some point turns to neural nets. Neural nets display, however, some instability in the research literature. Figure @ref(fig:disc_tech) shows the most frequent keywords for technical publications across the three main disciplinary domains inhabited by machine learners. While neural nets rank very high in computer science and engineering disciplines (appearing just after support vector machines), they do not appear in the statistics literature until in the rankings. The prominence of neural nets on the engineering side of machine learning suggests a specific enunciative mapping. </p>
<p>Neural nets are often described from a deeply split perspective. At some moments, the description turns towards human subjects, or at least, the brains of human subjects. At other other moments, neural nets turn towards the vectorisation of data.  Neural nets constantly oscillate between brain and information infrastructure. In some ways, they renew long-standing cybernetic hopes of bring brains and computation together in models of computational intelligence and agency <span class="citation">(Hayles <a href="#ref-Hayles_1999">1999</a>)</span>.  Although they stem from a biological inspiration (dating at least back to the work by McCulloch and Pitts in the 1940s <span class="citation">(Halpern <a href="#ref-Halpern_2015">2015</a>; Wilson <a href="#ref-Wilson_2010">2010</a>)</span>), they gain traction first in the 1980s and then again from mid-2000s onwards, as ways of dealing with changing computational infrastructures, and the difficulties of capitalising on infrastructure that is powerful but hard to control. In the course of fifty years, their serial re-invention – from perceptron via neural net to deep belief net – triply re-distributes subject positions amidst infrastructural re-configurations and vectorisation.  </p>
<p>For instance, writing in the 1980s, David Ackley, Geoffrey Hinton (an important figure in the inception of neural nets over several decades),  and Terrence Sejnowski link neuroscience and semiconductors: </p>
<blockquote>
<p>Evidence about the architecture of the brain and the potential of the new VLSI technology have led to a resurgence of interest in “connectionist” systems … that store their long-term knowledge as the strengths of the connections between simple neuron-like processing elements. These networks are clearly suited to tasks like vision that can be performed efficiently in parallel networks which have physical connections in just the places where processes need to communicate. … The more difficult problem is to discover parallel organizations that do not require so much problem-dependent information to be built into the architecture of the network <span class="citation">(Ackley, Hinton, and Sejnowski <a href="#ref-Ackley_1985">1985</a>, 147–48)</span>.</p>
</blockquote>
<p>Alignments and diagrammatic overlaps between brain and ‘new VSLI [Very Large Scale Integrated] technology’ – semiconductor chips – architectures sought to reproduce the plasticity of neuronal networks in the parallel distributed processing enabled by very densely packed semiconductor circuits.  The problem here was how to organize these connections without hardwiring domain specificity into ‘the architecture of the network.’ How could the architectures adapt to the problem in hand?</p>
<p>We saw in chapter <a href="#ch:diagram"><strong>??</strong></a> that the psychologist Frank Rosenblatt’s perceptron <span class="citation">(Rosenblatt <a href="#ref-Rosenblatt_1958">1958</a>)</span> first implemented McCulloch and Pitts’ cybernetic vision of neurones as models of computation <span class="citation">(Edwards <a href="#ref-Edwards_1996">1996</a>)</span> .  While the computer science research on the perceptron wilted under criticism from artificial intelligence experts such as Marvin Minsky (Minsky famously showed that a perceptron cannot learn the logical exclusive OR or <code>XOR</code> function; <span class="citation">(Minsky and Papert <a href="#ref-Minsky_1969">1969</a>)</span>),  cognitive psychologists such as David Rumelhart, Geoffrey Hinton and Ronald Williams persisted with perceptrons, seeking to generalize their operations by connecting them together in networks (also known as multilayer perceptrons). In the mid-1980s, they developed the back-propagation algorithm  <span class="citation">(Rumelhart, Hinton, and Williams <a href="#ref-Rumelhart_1985">1985</a>; Hinton <a href="#ref-Hinton_1989">1989</a>)</span>, a way of adjusting the connections – known as weights or parameters –  between nodes (neurones) in the network in response to features in the data (see Figure <a href="#fig:rumelhart1985"><strong>??</strong></a>).</p>
<p>The back-propagation algorithm directly addressed the problem of learning to modify network organization without reliance on problem-dependent architectures, and in without having to program them in.  Effectively, it constructs an architecture of generalization. While cognition, and the idea that machines would be cognitive (rather than say, mechanical, calculative, or rule-based) mesmerised research work in artificial intelligence for several decades, the development of the back-propagation algorithm as a way for a set of connected computational nodes to learn came with explicit infrastructural resonances.</p>
<p>The resonances between computational architectures and human cognition (centred on vision) became much more palpable from around 2006 when ‘deep belief nets’ appeared as a way of training many-layered neural nets implemented on much large computational platforms <span class="citation">(Hinton, Osindero, and Teh <a href="#ref-Hinton_2006a">2006</a>)</span>. These resonances continue to echo today and indeed attract much attention.<a href="#fn92" class="footnoteRef" id="fnref92"><sup>92</sup></a> Like the advent of VSLI in the early 1980s, the vast concentrations of processing units in contemporary data centres (hundreds of thousands of cores as we saw in the case of Google Compute in the previous chapter <a href="#ch:genome"><strong>??</strong></a>) and in the graphics cards  developed for high-end gaming and video rendering (GPUs for PC gaming now typically have a thousand and sometimes several thousand cores) pose the problem of organizing infrastructure so that processes can communicate with each other. Machine learners have become just as important as loose or mutable infrastructural orders as epistemic instruments.</p>

<p>Oscillating between cognition and infrastructures, between people and machines, neural nets suggest a way of thinking not only about how ‘long-term knowledge’ takes shape today, but about subject positions associated with machine learning.   As infrastructural reorganization takes place around learning, and around the production of statements by machine learners, both human and non-human machine learners are assigned new positions. These positions are sometimes hierarchical and sometimes dispersed. The machine learner subject position is a highly relational one rather than a single concentrated form of expertise (as we might find in a clinical oncologist, biostatistician or geologist). Because machine learners vectorize, optimize, probabilise, differentiate and refer, what counts as agency, skill, action, experience and learning shifts constantly. It is intimately bound and connected to transforms in infrastructure, variations in referentiality (such as we have seen in the construction of the vector space), and competing forms of accumulation or positivity. As Suchman suggests, examining privileged machines such as neural nets is a way to pay attention to the dispersed and somewhat disconnected sites from which subjects program, observe, design and respond to machine learners.</p>
</div>
<div id="competitive-positioning" class="section level2">
<h2><span class="header-section-number">10.2</span> Competitive positioning</h2>
<p>How do neural nets come to oscillate between different subject positions? The ranking of keywords in table @ref(tab:tech_disc) suggests that machine learning as an operational knowledge formation attributes a privileged and constitutive function to neural nets. Neural nets concurrently spread into many difference disciplines: cognitive science, computer science, linguistics, adaptive control engineering, psychology, finance, operations research, etc., and particularly statistics and computer science during the 1980-1990s. This dendritic growth did not just popularise machine learning. It brought engineering and statistics together more strongly. Ethem Alpaydin, a computer scientist, writes: </p>
<blockquote>
<p>Perhaps the most important contribution of research on neural networks is this synergy that bridged various disciplines, especially statistics and engineering. It is thanks to this that the field of machine learning is now well established <span class="citation">(Alpaydin <a href="#ref-Alpaydin_2010">2010</a>, 274)</span>.</p>
</blockquote>
<p>The forms of this field-making bridging are various.<a href="#fn93" class="footnoteRef" id="fnref93"><sup>93</sup></a> The primary meeting point of different disciplines has perhaps been the machine learning competitions of the 1990s that pitted neural nets against other machine learners such as support vector machine. Many of these competitions focused on vision-related problems such as recognising handwritten numerals. The handwritten digits used in these competitions, particularly the Neural Information Processing System workshops and KDD Cup (Knowledge Discovery and Data Mining) <span class="citation">(KDD <a href="#ref-KDD_2013">2013</a>)</span>, all come from the <code>mnist</code> dataset and during the 1990s, much effort focused on crafting neural nets to recognise these 60,000 or so handwritten digits.</p>
<p><em>Elements of Statistical Learning</em> devotes a lengthy section to the analysis of image recognition competitions that began in the early 1990s and continue today. Like Alpaydin, it affirms the coordinating effect of these competitions on the development of machine learning:</p>
<blockquote>
<p>This problem captured the attention of the machine learning and neural network community for many years, and has remained a benchmark problem in the field <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 404)</span>.</p>
</blockquote>
<p>As Hastie and co-authors observe, ‘at this point the digit recognition datasets became test beds for every new learning procedure, and researchers worked hard to drive down the error rates’ <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 408–9)</span>. During the 1990s, zipcodes on envelopes (the set of handwritten digits we have already seen in chapter <a href="#ch:pattern"><strong>??</strong></a>, the <code>mnist</code> datasets <span class="citation">(LeCun and Cortes <a href="#ref-LeCun_2012">2012</a>)</span>) became a primary focus of learning.   The many competitions focused on the <code>mnist</code> dataset are, I suggest, a form of demonstration and testing of machines and people that propagate machine-human differences in machine learning. </p>
<p>Although they brought statistics and computer science closer, neural networks have had a somewhat problematic position in machine learning. Even in relation to the paradigmatic handwritten digit recognition problem, neural nets struggled to gain purchase precisely because a human subject position remained intimately interwoven into their operation. On the one hand, their analogies and figurations as sophisticated neuronal-style models suggested cognitive capacities surpassing the more geometrical, algebraic and statistically grounded machine learners such as linear discriminant analysis, logistic regression, or decision trees. On the other hand, the density and complexity of their architecture made them difficult to train. Neural nets could easily overfit  the data. As <em>Elements of Statistical Learning</em> puts it, it required ‘pioneering efforts to handcraft the neural network to overcome some these deficiencies…, which ultimately led to the state of the art in neural network performance’ <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 404)</span>. It is rare to find the word ‘handcraft’ in machine learning literature. The operational premise of most machine learners is that machine learning works without handcrafting, or that it automates what had previously been programmed by hand.   Somewhat ironically, the competition to automate recognition of handwritten digits, the traces that epitomise movements of hands, entailed much handcrafting and recognition of variations in performances of the machine.</p>
<p>The unstable position of subjects in relation to neural nets are frequently discussed in contrasting terms by machine learners themselves.<a href="#fn94" class="footnoteRef" id="fnref94"><sup>94</sup></a> They often point to a transformation in the work of machine learning:</p>
<blockquote>
<p>Neural networks went out of fashion for a while in the 90s - 2005 because they are hard to train and other techniques like SVMs beat them on some problems. Now people have figured out better methods for training deep neural networks, requiring far fewer problem-specific tweaks. You can use the same pretraining whether you want a neural network to identify whose handwriting it is or if you want to decipher the handwriting, and the same pretraining methods work on very different problems. Neural networks are back in fashion and have been outperforming other methods, and not just in contests <span class="citation">(Zare <a href="#ref-Zare_2012">2012</a>)</span>.</p>
</blockquote>
<p>The somewhat vacillating presence of neural nets in the machine learning literature itself finds parallels in the movements of individual machine learners. Yann Le Cun’s work on optical character recognition during 1980-1990s is said to have discovered the back-propagation algorithm at the same time as Rumelhart, Hinton and Williams <span class="citation">(Rumelhart, Hinton, and Williams <a href="#ref-Rumelhart_1986">1986</a>)</span>. His implementations in <code>LeNet</code> won many research machine learning competitions during the 1990s. In 2007, Andrew Ng could casually observe that neural nets <em>were</em> the best, but in 2014, Le Cun find himself working on machine learning at Facebook <span class="citation">(Gomes <a href="#ref-Gomes_2014">2014</a>)</span>.  Similarly, the cognitive psychologist Geoffrey Hinton’s involvement in the early 1980s work on connectionist learning procedures in neural nets and subsequently on ‘deep learning nets’ <span class="citation">(Hinton and Salakhutdinov <a href="#ref-Hinton_2006">2006</a>)</span> delivers him to Google in 2013. </p>
<p>Trajectories between academic research and industry are not unusual for machine learners. Many of the techniques in machine learning have been incorporated into companies later acquired by other larger companies. Even if there is no spin-off company to be acquired, machine learners themselves have been assigned key positions in many industry settings. Corinna Cortes, co-inventor with Vladimir Vapnik of the support vector machine, heads research at Google New York . In 2011, Ng led a neural net-based project at Google that had, among other things, detected cats in millions of hours of Youtube videos.<a href="#fn95" class="footnoteRef" id="fnref95"><sup>95</sup></a> Ng himself in 2014 began work as chief scientist for the Chinese search engine, Baidu leading a team of AI researchers specializing in ‘deep learning,’ the contemporary incarnation of neural nets <span class="citation">(Hof <a href="#ref-Hof_2014">2014</a>)</span> .   In recent years, (2012-2015), work on neural nets has again intensified, most prominently in association with social media platforms, but also in the increasingly common speech and face recognition systems found in everyday services and devices. Many of these neural nets are like <code>kittydar</code> , but implemented on a much larger and more distributed scale (for instance, in classifying videos on Youtube). In contemporary machine learning competitions, as we will see, neural nets again surface as intersectional machines, re-distributing differences between humans and machines.</p>
</div>
<div id="a-privileged-machine-and-its-diagrammatic-forms" class="section level2">
<h2><span class="header-section-number">10.3</span> A privileged machine and its diagrammatic forms</h2>
<p>What accounts for the somewhat uneven fortunes of the neural net amongst machine learners? The unevenness of their performance, from limited curiosity in the late 1960s to handcrafted best-in-class performer in the machine learning image classification competitions of the 1990s, from second best competitor in late 1990s to the spectacular promise of deep belief networks amidst the ‘awesome materiality’ of social media image streams in 2012, suggests that some powerful dynamics or becomings are in play around them. These dynamics are not easily understood in terms of celebrity machine learners (human and non-human) suddenly rising to prominent or privileged positions in the research departments of social media platforms.<a href="#fn96" class="footnoteRef" id="fnref96"><sup>96</sup></a> Nor does it make sense to attribute the rising fortunes of the neural net to the algorithms themselves, as if some decisive advance occurred in algorithms.</p>
<p>The algorithms such as back-propagation used in neural nets have not, as we will see, been radically transformed in their core operations since the 1980s, and even then, the algorithms themselves (principally gradient descent ) were not new. There have been important changes in scale (similar to those described in the previous chapter in the case of the <code>RF-ACE</code> algorithm and Google Compute), but as is often the case in machine learning, their proliferation occurs through re-distributions of knowledge and infrastructure associated with altered subject positions. While machine learners in their machine form can be assigned a privileged position in the transformations of knowledge and action, human machine learners are not exactly marginalized, at least in celebrated cases such as Ng, Le Cun, Hinton and others. Rather, we can see varying subject positions emerging in relation to specific devices and data forms (images, sounds, documents) in specific sites (social media platforms and mobiles devices in particular).</p>
<p>A varying subject position surfaces in the operational architecture of neural nets. Despite differences in diagrammatic form, neural net share much with other machine learners. The language of brain, neurones and cognition associated with neural net covers over their much more familiar vector space and function-finding optimisations they rely on. Diagrammatic groupings and lines of movement operate in neural nets to expand their architecture in alignment with a series of well-established transformations. ‘The central idea,’ write Hastie and co-authors, ‘is to extract linear combinations of the inputs as derived features, and then model the target as a nonlinear function of these features. The result is a powerful learning method, with widespread applications in many fields’ <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 389)</span>. The ‘central idea’ can be seen in the algebraic expressions that Hastie and co-authors provide for the basic neural net model:</p>

<blockquote>
<p>where <span class="math inline">\(Z = (Z_1 , Z_2, ..., Z_M )\)</span>, and <span class="math inline">\(T = (T_1 , T_2 ,..., T_K )\)</span>. The activation function <span class="math inline">\(\sigma(v)\)</span> is usually chosen to be the sigmoid <span class="math inline">\(\sigma(v) = 1/(1 + e - v )\)</span></p>
</blockquote>
<blockquote>
<p><span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 392)</span></p>
</blockquote>
<p>Equation  diagrams some familiar elements as well as some novelty. Some elements of the neural net are already familiar from linear models. The neural networks transform data in a vector space denoted by <span class="math inline">\(X\)</span>. That is common to nearly all machine learners. They make use of the non-linear sigmoid function  that lies at the heart of one of the main linear classifiers used in machine learning, logistic regression. Their training and learning processes have come to rely on the same kinds of cost, loss or error functions  we have seen in other machine learners. </p>
<p>The apparently increasing power of neural nets to learn (to see, to find, to classify, to rank, to predict) owes much to diagrammatic substitutions that recombine operations of past machine learners in new intersections. These movements appear in the equations. Equation  has three lines rather than one, and this layering and its diagonal patterns of indexical referencing running between subscripts distinguishes neural nets from the linear models it assembles. </p>

<p>Whereas the standard linear model  shown in Equation  indexes a single vector space <span class="math inline">\(X_j\)</span> and approximates it using a single function <span class="math inline">\(\hat{Y}\)</span> by searching for the values of the parameters <span class="math inline">\(\beta_j\)</span> that best incline a flat plane through the data, the three lines shown in equation  are woven through each other much more consecutively. Each lines derives ‘features’ from the line above, adding layers to the network. So-called ‘hidden layers,’ such as line two of equation  repeatedly transform the vector space inside the model itself. Each node, <span class="math inline">\(1..K\)</span>, adds a new dimension to this internal vector space. In many layered deep learning neural nets, the dimensionality of the vector space vastly expands.  Much hinges on the unobstrusive sigmoid function operator written as <span class="math inline">\(\sigma\)</span>: ‘a neural network can be thought of as a nonlinear generalization of the linear model, both for regression and classification. By introducing the nonlinear transformation <span class="math inline">\(\sigma\)</span>, it greatly enlarges the class of linear models’ <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 394)</span>. <span class="math inline">\(\sigma\)</span>, it seems, allows neural nets to generalize beyond the linear model.<a href="#fn97" class="footnoteRef" id="fnref97"><sup>97</sup></a></p>
</div>
<div id="varying-subject-positions-in-code" class="section level2">
<h2><span class="header-section-number">10.4</span> Varying subject positions in code</h2>
<p>The operational diagram of neural nets, I would suggest, ascribes subject positions associated with it. How does that happen? Some familiar diagrammatic operations immediately appear in almost any actual example of a neural net. In the code vignette shown below, the dataset is a spreadsheet of information about passengers of the Titanic. The <code>titanic</code> dataset, like <code>iris</code> or <code>boston</code> is often used in contemporary machine learning pedagogy.  It is for instance, the main training dataset used by (kaggle.com)[<a href="http://kaggle.com" class="uri">http://kaggle.com</a>], an online machine learning competition site I will discuss below . The first few lines of the <code>R</code> code load the dataset and transform it into vector space. For instance, variables such as <code>sex</code> that take values such as <code>male</code> and <code>female</code> become vectors of <code>1</code> and <code>0</code> in a new variable <code>sexmale</code>.</p>

<p>The line of the code that constructs a neural net using the <code>neuralnet</code> library <span class="citation">(Fritsch and Guenther <a href="#ref-Fritsch_2012">2012</a>)</span> closely resembles the lines of code used to construct linear models for the <code>prostate</code> data (see chapter <a href="#ch:vector"><strong>??</strong></a>). The <code>R</code> formula for the neural net looks very similar to other machine learners such as logistic regression. It models whether someone <code>survived</code> the wreck of the Titanic in terms of their age, class of fare (<code>pclass</code>), sex, number of siblings/spouse (<code>sibsp</code>), number of parents/children (<code>parch</code>) and port of departure:</p>
<p><code>survived ~ age +pclass + fare + sexmale + sibsp + parch + embarkedC + embarkedQ + embarkedS</code></p>
<p><code>R</code> model formula express the response or target variable <code>survived</code> as a combination of other variables. In this case, the plus sign <code>+</code> indicates that the combination is linear or additive. If this model formula looks so similar to other machine learning techniques we have been discussing, what do neural networks add? Why did and do so many machine learners turn to them?</p>
<p>Perhaps the only distinctive feature of the code listing  appears in the expression <code>hidden = 3.</code> This architectural feature does not appear in the model formula in the <code>R</code> code but does, as we have already seen, operate in the lines of equation . These ‘hidden units’ are key to neural net since they construct the ‘derived features’ that the model learns from the input data <span class="math inline">\(X\)</span>.</p>
<p>How many nodes are hidden and in what topology matters less than the existence of operation that allows their topology to be configured in an encounter with data. The novelty of this operation was central to research into neural nets. As Rumelhart, Winton and Williams announce the algorithm in a letter to <em>Nature</em> in 1986 entitled ‘Learning representations by back-propagating errors’ :</p>
<blockquote>
<p>We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure <span class="citation">(Rumelhart, Hinton, and Williams <a href="#ref-Rumelhart_1986">1986</a>, 533)</span>. </p>
</blockquote>
<p>Again, despite the persistent reference to biology, the description of the ‘new learning procedure’ sound more like machine learning. There is talk of minimizing a measure of difference between actual and desire output vectors (optimizing through a cost or loss function), as well as mention of ‘features’ and ‘weights’ (usually a synonym for model parameters: ‘the neural network model has unknown parameters, often called weights, and we seek values for them that make the model fit the training data well’ <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 395)</span>). The novelty, however, consists in the ‘hidden’ units whose interactions ‘represent important features.’ In other words, the flat additive combination of features expressed in the <code>R</code> model formula above does not convey the interactions of these units. (As Hastie and co-authors put it, ‘the units in the middle of the network, computing the derived features <span class="math inline">\(Z_m\)</span>, are called hidden units because the values <span class="math inline">\(Z_m\)</span> are not directly observed’ <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 393)</span>.) These units can only viably interact in the neural nets because the back-propagation algorithm offers a way to create ‘useful, new features’ from the data. But because they interact through back-propagation, the hidden units ‘capture’ regularities in the ‘task domain’ and thereby do what counts as cognition in the connectionist philosophies associated with neural nets (see the PDP group’s work <span class="citation">(McClelland and Rumelhart <a href="#ref-McClelland_1986">1986</a>)</span>).</p>
<p>The hidden layers lend a network form to machine learning. The final diagrammatic form in which neural nets appear is the network. Network graphs already appeared in Rosenblatt’s perceptron work <span class="citation">(Rosenblatt <a href="#ref-Rosenblatt_1958">1958</a>)</span>, but they ramify tremendously in the aftermath of back-propagation. Almost every book and article relating to neural net presents some version of the diagram shown in Figure @ref(fig:titanic_net).</p>
<pre><code>## NULL</code></pre>
<pre><code>## png 
##   2</code></pre>

<p>Although the network topology of the model appears in many more complicated forms, it diagrams several operations. First, it presents a surface – the input layer – that indexes something in the world.   The input layer, shown as <span class="math inline">\(X\)</span> in the algebraic diagram of equation , suggests receptive or recording surface (for instance, a camera). Early neural net papers on the handwritten digital recognition problem sometimes describe cameras mounted above tables focused on images <span class="citation">(LeCun et al. <a href="#ref-LeCun_1989">1989</a>)</span>. Second, it presents an output layer that can contain single or multiple nodes, the <span class="math inline">\(k\)</span> of equation . In the <code>titanic</code> examples, a single target node appears (survived or not). In the <code>MNIST</code> handwritten digit recognition models, there are usually ten output nodes, one for each of the digits 0 … 9. Third, the network diagram exhibits ordered forms of movement. Data and calculation propagate from left to right or vice-versa. (Sometimes the networks are rotated, and the flow is vertical, but still bi-directional). Bi-directional hierarchical movement is key to the back-propagation algorithm in feed-forward and more complicated recurrent and convolutional neural nets.  Fourth, it renders visible in principle the vital hidden nodes. Without the hidden nodes, neural nets collapse into linear models. With the hidden nodes, the <span class="math inline">\(Z_m\)</span> of the equations , neural nets, like some other machine learners we have discussed such as support vector machines, effectively expand the vector space by constructing new dimensions in it. The derived features or ‘learned representations’ (to use the language of <span class="citation">(Rumelhart, Hinton, and Williams <a href="#ref-Rumelhart_1986">1986</a>)</span>) can expand indefinitely, according to different network topologies. </p>
</div>
<div id="the-subjects-of-a-hidden-operation" class="section level2">
<h2><span class="header-section-number">10.5</span> The subjects of a hidden operation</h2>
<p>How do the diagrammatic forms of the basic model equations, the network diagram and the operational code comprising the privileged machine at work recognising handwritten digits or classifying the passengers on the Titanic, assign subject positions? How would we describe the figure of human machine learner in this setting? Is the human machine learner like Vlad, the former Eastern European mathematician tending the training of a neural net at the heart of the call centre knowledge management system, or more like Heather Arthur, the programmer who wrote <code>kittydar</code>? </p>
<p>When in <em>The Archaeology of Knowledge</em>, Foucault presents the ‘position of the subject’  as an anchor point for the power-laden, knowledge forming enunciative functions, he does not identify it as a unifying point grounded in interiority, in intentionality or even in single speaking position or voice (that of <em>the</em> machine learning expert, for instance). On the contrary, ‘various enunciative modalities manifest his [sic] dispersion’ <span class="citation">(Foucault <a href="#ref-Foucault_1972">1972</a>, 54)</span>. Positions derive from operations that determine statements that become a kind of law for the subject.</p>
<p>As Foucault puts it, in a mathematical example and a conceptual formulation that broadly anticipates accounts of performativity, </p>
<blockquote>
<p>in each case the position of the subject is linked to the existence of an operation that is both determined and present; in each case, the subject of the statement is also the subject of the operation (he who establishes the definition of a straight line is also he who states it; he who posits the existence of a finite series is also, and at the same time, he who states it) ; and in each case, the subject links, by means of this operation and the statement in which it is embodied, his future statements and operations (as an enunciating subject, he accepts this statement as his own law) <span class="citation">(Foucault <a href="#ref-Foucault_1972">1972</a>, 94–95)</span>.</p>
</blockquote>
<p>Foucault’s examples here include subjects who say things like ‘I call straight any series of points that …’: just such statements operate in machine learning. The <em>operation</em> is crucial, since it connects many different practices and techniques (function finding, optimisation, transformation of data into the vector space, mobilisation of probability distributions as a kind of rule of existence for learnable situations, etc.) that accompany, ornament, armour and diagram the statement.</p>
<p>Foucault posits, therefore, a subject-positioning circularity between the operation and accompanying statement: the subject of the statement is also the subject of the operation. The provisional coincidence of operation and statement defines a subject position, with some agency and subjects machine learners to future operations. The process might be formalised for any machine learner as follows: the diagrammatic operations of the machine learner support the production of statements; these operations become a way of producing future statements to the extent that the subject of the operation is <em>also</em> the subject of the statement. The assignation of a subject position occurs in this forward and backward, feed-forwarding and back-propagating movement between operation and statement.  </p>
</div>
<div id="algorithms-that-propagate-errors" class="section level2">
<h2><span class="header-section-number">10.6</span> Algorithms that propagate errors</h2>
<p>The distinctive feature of neural nets, at least in their ordinary ‘vanilla’ forms, consists in their use of a series or chain of gradient descent operations to minimise errors by adjusting the weights (or parameters) of all the nodes (or linear models) comprising the network. Adjusting the parameters of the nodes in the neural net hardly seems a striking achievement. If we, however, look more closely at the way in which the ‘internal representations’ <span class="citation">(Rumelhart, Hinton, and Williams <a href="#ref-Rumelhart_1986">1986</a>, 536)</span> are iteratively constructed in neural nets, something more interesting begins to emerge from the forwards and backwards movement of this algorithm.  Does an algorithm such as back-propagation diagram the slippery coincidence of subject of operation and subject of statement in machine learning?</p>
<p>The subject-positioning zone of slippage between statement and operation appears as error.  Although the gap between operation and statement might seem small, there are many slippages and divergences in it. A minor statements such as ‘we see that Net-5 does the best, having errors of only 1.6%, compared to 13% for the “vanilla” network Net-2’ <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 407)</span> bears within it, in its coupling to all the operations comprising ‘Net-5,’ a set of determinations, sites and relations for variously positioned subjects.  (These might include machine learners, such as Hinton or Le Cun, but also U.S. Postal workers, whose work must have more ore less disappeared as automatic mail sorting improved). In any concrete situation, in relation to any specific machine learner, the diagrammatic operations and statements will position subjects in specific ways. There is no simple referent here, no simple object gripped or seen by a knowing or controlling subject, since on this account, the operations and statements in their dispersions, accumulations and distributions overflow any simple dyadic relation between a subject-object or human-machine/world.</p>
<p>As we have seen in chapter <a href="#ch:function"><strong>??</strong></a>, error rates, training error, test error, generalization error, validation error are just some of the errors that criss-cross between human and machine learners. Errors render operations as statements. While not all of these errors figure directly in the algorithms, the learning procedure of most machine learners derives from the way they update model parameters in the light of statements of errors. Every machine learner makes different determinations in relation to model parameters and errors. We have already seen something of the forward movement that runs between the input layer and the output layer with its classificatory statements. Equations  imply data moving a succession of layers and their nodes. Conversely, the back-propagating phase of a neural net move from output towards input layer updating weights of various nodes in the light of differences between predicted and known outputs.  </p>

<blockquote>
<p><span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 396)</span></p>
</blockquote>
<p>Many different parameters figure in the back-propagation functions shown in equations . They include measures of error (<span class="math inline">\(R\)</span>), values of the weights or parameters in various layers of the models (<span class="math inline">\(\beta\)</span>, <span class="math inline">\(\alpha\)</span>), variables that count the number of iterations the model has performed (<span class="math inline">\(r\)</span>, <span class="math inline">\(r+1\)</span>) and the functional operators such as summation (<span class="math inline">\(\sum\)</span>) and partial differentiation (<span class="math inline">\(\partial\)</span>). The usual indexical relations to vector space appear in <span class="math inline">\(N\)</span>, the number of rows or observations, as well as <span class="math inline">\(K\)</span>, the number of outputs and <span class="math inline">\(M\)</span>, the number of nodes in the hidden layer. Partial derivatives express the sensitivity of errors with respect to the weights or parameters of the nodes.  In the densely iconic and indexical diagram of equation , the interweaving of the subscripts in the two lines show how values of the model parameters of the first two lines of equation  update as the model is trained on the input data. The two lines of equation  specify how first the values of the parameters <span class="math inline">\(\beta_{km}\)</span> of the <span class="math inline">\(K\)</span> nodes of the output layer should be altered in the light of the difference between the actual and expected output values, and then how the weights <span class="math inline">\(\alpha_{km}\)</span> of the <span class="math inline">\(M\)</span> nodes of the hidden layers should be adjusted. Once these are adjusted, the forward movement defined by equations  begins again. In adjusting weights in the layers, back-propagation always starts at the outputs, and travels back into the net towards the input layer at the bottom (or left hand side in diagram @ref(fig:titanic_net).</p>
<p>‘It is as if the error propagates from the output <em>y</em> back to the inputs and hence the name <em>back-propagation</em> was coined’ writes Alpaydin <span class="citation">(Alpaydin <a href="#ref-Alpaydin_2010">2010</a>, 250)</span>. As in any gradient descent operation (see chapter <a href="#ch:function"><strong>??</strong></a>), a rate parameter (here <span class="math inline">\(\gamma\)</span>) regulates the speed of descent. If <span class="math inline">\(\gamma\)</span> is too large, the gradient descent might jump over a valley that contains the absolute minimum error; if <span class="math inline">\(\gamma\)</span> is too small, then the descent is too slow for fast machine learning. In some versions of neural net, the value of <span class="math inline">\(\gamma\)</span> changes each at iteration <span class="math inline">\(r\)</span> of the model.<a href="#fn98" class="footnoteRef" id="fnref98"><sup>98</sup></a> </p>
</div>
<div id="competitions-as-examination" class="section level2">
<h2><span class="header-section-number">10.7</span> Competitions as examination</h2>
<p>More or less directly, the observation of error rates converging towards minimum values assigns a subject position the role of controlling hyper-parameters such as <span class="math inline">\(\gamma\)</span>, the learning rate. This seems a drastic curtailment of agency. The related feed-forward and back-propagation of errors focuses the machine learner subject, the ‘wonderful people’ of Hilary Mason’s exhortation to developers, on error. At almost every step of its development as a field and in almost every aspect of its operation, competitions to observe and rank error rates bring human and machine learners together. In competitions, errors are not purely epistemic.  They circulate within a wider economy of competitive optimisation that connect them to power, value and agency dynamics. The learning of machine learning takes place in examinations that rank both human and non-human machine learners according to error rates.  What can we learn from such competitions about subject positions in machine learning?</p>
<p>Backwards and forwards movement between human and machine machine learners characterises competitions run by <a href="http://www.kaggle.com">Kaggle</a>. Kaggle organizationally implements a parallel architecture machine learning process by back-propagating errors to hidden nodes embodied in individual competitors who, in principle at least, are not connected to each other, but only to the layers and nodes of Kaggle itself as a platform. In comparison to the research-oriented machine learning competitions such as the annual (KDD Cup)[<a href="http://www.sigkdd.org/kddcup/index.php" class="uri">http://www.sigkdd.org/kddcup/index.php</a>]<span class="citation">(KDD <a href="#ref-KDD_2013">2013</a>)</span> run by the Association of Computing Machinery (ACM) Special Interest Group on Knowledge Discovery and Data Mining, the NIPS (Neural Information Processing Systems) Challenges, the ImageNet Large Scale Visual Recognition Challenge <span class="citation">(ILSVRC <a href="#ref-ILSVRC_2014">2014</a>)</span> or the International Conference on Machine Learning (ICML)[<a href="http://machinelearning.org/icml.html" class="uri">http://machinelearning.org/icml.html</a>], the Kaggle competitions attract a wide range of academic, industry, commercial and individual entries. </p>
<p>Competitors no doubt enter these competitions for various reasons, not the least of which is their employment prospects or the promotion of their machine learning products (for instance, the winner of a major competition, the Heritage Health Fund Prize in 2012 uses that prize to promote the data mining software made by his company (Tiberius)[Tiberius.biz]; an entrant in the Hewlett ‘Automated Essay Competition’ again in 2012 included Pacific Metrics, a US company whose automated essay scoring products were already in use in U.S. schools; while Pacific Metrics did not win the competition, it acquired the winning machine learner and incorporated it into its products <span class="citation">(Kaggle <a href="#ref-Kaggle_2012">2012</a>)</span>). Kaggle.com is effectively a recruitment agency for machine learners <span class="citation">(Kaggle <a href="#ref-Kaggle_2015d">2015</a><a href="#ref-Kaggle_2015d">c</a>)</span>. Some competitions have recruitment opportunities as the prize. For instance, several competitions sponsored by Facebook have positions as data scientist at Facebook as the prize:</p>
<blockquote>
<p>Ever wonder what it’s like to work at Facebook? Facebook and Kaggle are launching an Engineering competition for 2015. Trail blaze your way to the top of the leader board to earn an opportunity at interviewing for a role as a software engineer, working on world class Machine Learning problems <span class="citation">(Kaggle <a href="#ref-Kaggle_2015">2015</a><a href="#ref-Kaggle_2015">b</a>)</span> </p>
</blockquote>
<p>While most employment agencies rely on CVs (curriculum vitae), Kaggle operates more like feed-forward and back-propagation between multiple competitions as a way of optimising its ranking of machine learners. </p>
<p>The competition organizers list three injunctions: download (the data), build (a model), and submit (an entry or many entries to the competition). Leader-boards and individual rankings within the Kaggle’s “world’s largest community of data scientists” <span class="citation">(Kaggle <a href="#ref-Kaggle_2015b">2015</a><a href="#ref-Kaggle_2015b">a</a>)</span>,<a href="#fn99" class="footnoteRef" id="fnref99"><sup>99</sup></a> allow clients –corporations mostly – to ‘harness the “cognitive surplus”’ <span class="citation">(Kaggle <a href="#ref-Kaggle_2015c">2015</a><a href="#ref-Kaggle_2015c">e</a>)</span>. The figure also shows some of the typical diversity of the several hundred machine learning competitions that Kaggle has staged since 2011: diabetic retinopathy and west Nile virus prediction competition appear next to search results relevance or context ad clicks competitions. As we have seen frequently, accumulation, aggregation and proximity, whether accidental or constructed, between very disparate entities suggests that machine learners possess epistemic mobility not readily available to the domain experts (in diabetes, virology, information retrieval or search engine optimisation).</p>

<p>Like a neural network with many layers and nodes, competitions subject competitors (several hundred thousand in Kaggle) to ranking and indeed prediction based on the generalization error  of the models that they submit to the competition. The leader-board, which displays current rankings of competitors in a given competition, is the visual form of this error-based ranking:</p>
<blockquote>
<p>The leaderboard is a central fixture of the Kaggle experience. It provides context to the incredible work accomplished by the Kaggle data science community. To a competitor, the leaderboard is a dynamic, living, action-filled battle. Tactics come to life. Individuals leapfrog over each other. Teams merge and blend submissions. Some submit early and often, attempting to build up insurmountable leads. Others bide time, waiting to pounce minutes before the buzzer with their finest of forests. We see the joys of regularization and the agony of overfitting. … It’s thousands of hours of collective human toil <span class="citation">(Kaggle <a href="#ref-Kaggle_2015c">2015</a><a href="#ref-Kaggle_2015c">e</a>)</span></p>
</blockquote>
<p>The dynamics of ranking, and the experience of being ranked here arise from a fairly simple mechanism. Entrants in a given competition download two datasets, a training dataset that includes labels for all the response variables, and a test dataset that does not include the labels. In principle, competitors construct machine learners using the training dataset, use their machine learner to predict labels for the test dataset, and then upload the predicted labels to Kaggle as a submission to the competition. The Kaggle platform then calculates a ranking based on the generalization error in the test labels.<a href="#fn100" class="footnoteRef" id="fnref100"><sup>100</sup></a> Competitors optimise their entries against each other, but the competition overall functions as a kind of general optimization process in which many hidden nodes adjust their treatment to the training data as scores and rankings propagate through via the leaderboard system. The very stylised injunction to download-model-submit many times effectively creates an algorithmic process in which many hidden nodes operate in parallel to produce predictions. </p>
</div>
<div id="superimposing-power-and-knowledge" class="section level2">
<h2><span class="header-section-number">10.8</span> Superimposing power and knowledge</h2>
<p>It would be possible to explore in much greater ethnographic depth the practices of Kaggle competitors, the spectrum of participants (ranging from undergraduate student teams through to retired scientists, from hedge fund financial analysts to physicists), and the ways in which the topics of competitions relate to different scientific, governmental and commercial problems. Here I am interested mainly in the form of the competition as a test or examination centred on errors. The competitions take the form of examinations that set a problem, define some limits or constraints on its solution, and create a space that qualifies, ranks and displays the work of individuals or groups according to rates of generalization error (the error that arises when a machine learner encounters new data). </p>
<p>Machine learning competitions instance practices of examination that Foucault described in <em>Discipline and Punish</em>:</p>
<blockquote>
<p>The examination combines the techniques of an observing hierarchy and those of a normalizing judgement. … It establishes over individuals a visibility through which one differentiates them and judges them. That is why, in all the mechanisms of discipline, the examination is highly ritualized. In it are combined the ceremony of power and the form of the experiment, the deployment of force and the establishment of truth. At the heart of the procedures of discipline, it manifests the subjection of those who are perceived as objects and the objectification of those who are subjected. The superimposition of the power relations and knowledge relations assumes in the examination all its visible brilliance <span class="citation">(Foucault <a href="#ref-Foucault_1977">1977</a>, 183–85)</span>. </p>
</blockquote>
<p>The disciplinary form of the examination of errors links statements and operations. Examinations combine ceremony, ritual, experiment, force and truth in subject and object positioning operations.  The consolidation of machine learning as a data practice today in competitions occurs via a much more pervasive practice of examining and testing. The forms of visibility created by competitions individualize and normalize machine learners (often by proper names), and optimise extractions of force, time, propensities and aptitudes.</p>

<p>In many Kaggle competitions (some titles are shown in table @ref(tab:kaggle_competitions)), winning entries come from machine learners working together.  In the National Data Science Bowl competition of 2015, competitors were asked to classify images of more than 100 species of plankton. The winning team comprised seven graduate and post-doctoral researchers from Ghent University, Belgium. In a jointly written blog account of their winning entry, team ‘Deep Sea’ describe something of the construction of the deep learning models they built. These were convolutional neural nets, neural nets in which elements of the network only ‘look’ at overlapping tiles of the input images: </p>
<blockquote>
<p>We started with a fairly shallow models by modern standards (~ 6 layers) and gradually added more layers when we noticed it improved performance (it usually did). Near the end of the competition, we were training models with up to 16 layers. The challenge, as always, was balancing improved performance with increased overfitting <span class="citation">(Dieleman <a href="#ref-Dieleman_2015a">2015</a>)</span>.</p>
</blockquote>
<p>Like many of the entrants in image-based classification competitions such as the ImageNet Large Scale Visual Recognition Challenge <span class="citation">(ILSVRC <a href="#ref-ILSVRC_2014">2014</a>)</span>, ‘Deep Sea’ built their machine learner in several stages, first deriving features  from the data by creating various layers that looked for common features across various scales, rotations and other transformations of the plankton images, and then adding neural net layers to classify those derived features using the labels supplied in the training set. In this respect, and in almost perfect synchrony with the deep learning teams at Google, Facebook and many other places, ‘Deep Sea’ combined supervised and unsupervised learning techniques . The lower convolutional layers that process the images are strictly speaker unsupervised because they make no use of the known labels or categories of the plankton; the upper layers are supervised because they make use of the labels in the normal back-propagation process of neural net training.</p>
<p>In comparison to the plain or ‘vanilla’ neural nets discussed above, deep belief networks involve many more parameters, stages of observation and modelling, configuration of hardware and infrastructural arrangements and comparison of results. ‘Deep Sea’ describe the architecture of one of their more successful models:</p>
<blockquote>
<p>It has 13 layers with parameters (10 convolutional, 3 fully connected) and 4 spatial pooling layers. The input shape is (32, 1, 95, 95), in bc01 order (batch size, number of channels, height, width). The output shape is (32, 121). For a given input, the network outputs 121 probabilities that sum to 1, one for each class.</p>
</blockquote>
<p>They go on to describe the different layers – cyclic slice, convolutional, spatial pooling – that derive features from the data or augmenting it (by examining overlapping tiles, by rotating or scaling the images, so that any given image, is ‘seen’ in a number of different ways, and the model learns to detect these variations). The combination of diverse layers in a stratified model introduces a range of learners into the operation, just as Kaggle itself networks many machine learners through its competitions.</p>
<p>A massive parallel computation allows ‘deep’ learning. Infrastructure and cognition entwine heavily here, since the very possibility of training large many-layered neural nets depends heavily on vectorised transformations of image data. Probably few other competitors in this competition would have had access to the Tesla K40 or ‘NVIDIA GTX 980 Superclocked’ GPU cards that ‘Deep Sea’ relied on.<a href="#fn101" class="footnoteRef" id="fnref101"><sup>101</sup></a>  Even with that intensive computational resource, their models required ‘between 24 and 48 hours to reach convergence.’ They constructed around 300 models. Because of the plethora of models with different architectures and parameters, ‘we had to select how many and which models to use in the final blend’ <span class="citation">(Dieleman <a href="#ref-Dieleman_2015a">2015</a>)</span>. As is often the case, competition engenders populations of machine learners whose aggregate tendencies model optimum performance.<a href="#fn102" class="footnoteRef" id="fnref102"><sup>102</sup></a> The ‘DeepSea’ team might epitomise machine learning subject positions. Like the ‘wonderful people’ described by Hilary Mason, they bring together infrastructure, engineering, mathematics/statistics and some knowledge of human behaviour (although the knowledge of human behaviour in this case might have more to do with what other Kaggle competitors might be doing, as well as an awareness of cutting edge research leaders in image recognition techniques).</p>
</div>
<div id="ranked-subject-positions" class="section level2">
<h2><span class="header-section-number">10.9</span> Ranked subject positions</h2>
<p>‘DeepSea’ built models that classify images of more than a hundred kinds of plankton with few errors. In driving down error rates more than the hundreds of other competitors, they occupy a privileged subject position at the conjunction of operation and the statements in machine learning. Machine learners such as deep belief nets adjust and align subject positions through their many convolutional layers. They supplant, for instance, the skilled configuration of feature engineering  that characterised work on decision trees, linear regressions, support vector machines and predecessor neural nets (and appears as a key element in figure @ref(fig:disc_tech)). Similarly, they absorb the professional skills of Go players in training models that win against the best human players <span class="citation">(Silver et al. <a href="#ref-Silver_2016">2016</a>)</span>.  The subject position of a machine learner occupies a zone of diagrammatic slippage between statements and operations. </p>
<p>The various subject positions that might speak of, observe, question or decide about machine learning are neither unified or fixed. As the models grow, for instance, they test the capacity of human machine learners to understand how models transform data. Perhaps more profoundly, the growth of neural nets exhibits the deeply competitive imperative that imbues much machine learning practice, and in many way machine learning practice. This competition is not always explicit or overt, but it almost transpires in the form of a test or examination.</p>
<p>Neural nets re-iteratively draw human-machine learning differences. Their own ups and downs, the merging and blending of statistics, computer science and cognitive science they afford, and their potential to drive down error or learn features  from data given enough data derives less from some exotic mathematical abstraction or encompassing algorithm, and more from competitively accumulated layers and connections between units of modelling. The oscillating movement of the central algorithm – feed-forward and back-propagation – is instructive. Because it propagates errors to all elements of the network, and every element in the network adjusts its weights in trying to minimise error, layers can multiply on many scales.  The predictive power of the model derives from the networked collective of elementary machine learners driven to optimise their error rates. So too, the competitive examinations that today generalize machine learning as a data practice predicate the ongoing potential of hidden layers – machine learners – to collectively learn from their rankings in tests of error.</p>
<p>As it disperses subject positions, the back-propagation of errors or optimisation also animates optimism about machine learning.<a href="#fn103" class="footnoteRef" id="fnref103"><sup>103</sup></a>  Machine learning hovers in potentiality because neural nets and their kin assimilate and adjust their weights in response to changes in infrastructures and in the generalization of operations to newly adjacent domains. Machine learners generate optimism through and about optimisation, an optimisation that is predictive, prospective and anticipatory. But this adjusting of weights carried out through the propagation of errors is also inherently a ranking or examination. </p>
<p>Human and machine learner differences can be re-drawn in two different directions. In one direction, machine learning operations assign a subject position focused on error rates. Vlad in his corner observing the neural nets occupied such a position.  In the other direction, the subjects who operate the neural net in order to fit a model find themselves deeply caught up in a network of machine learners connected into parallel and layered architectures and operations. This feeding-forward, however, is regularized or narrowed down through examination and error, through back-propagation on various scales that ranks and filters machine learners according to their error rates. In this direction, the practice of training and testing generalization error that has long guided the supervision of machine learners becomes a mechanisms for adjusting subject positions of human machine learners. Some will be wonderful people, some will remain remote like Vlad, and some will optimistically re-learn in order to change their ranking. </p>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-Foucault_1972">
<p>Foucault, Michel. 1972. <em>The Archaeology of Knowledge and the Discourse on Language</em>. Translated by Allan Sheridan-Smith. New York: Pantheon Books.</p>
</div>
<div id="ref-Ng_2008f">
<p><em>Lecture 9 | Machine Learning (Stanford)</em>. 2008. <a href="https://www.youtube.com/watch?v=tojaGtMPo5U&amp;feature=youtube_gdata_player" class="uri">https://www.youtube.com/watch?v=tojaGtMPo5U&amp;feature=youtube_gdata_player</a>.</p>
</div>
<div id="ref-Kaggle_2015e">
<p>Kaggle. 2015d. “Description - Facebook Recruiting IV: Human or Robot? | Kaggle.” <a href="https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot" class="uri">https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot</a>.</p>
</div>
<div id="ref-Mackenzie_2004">
<p>Mackenzie, Adrian, and Simon Monk. 2004. “From Cards to Code: How Extreme Programming Re-Embodies Programming as a Collective Practice.” <em>Computer Supported Cooperative Work (CSCW)</em> 13 (1): 91–117.</p>
</div>
<div id="ref-Mason_2012">
<p>Mason, Hilary. 2012. “Hilary Mason - Machine Learning for Hackers.” June 6. <a href="http://vimeo.com/43547079" class="uri">http://vimeo.com/43547079</a>.</p>
</div>
<div id="ref-CNN_2011">
<p>CNN. 2011. “40 Under 40: Ones to Watch.” <em>CNNMoney</em>. <a href="http://money.cnn.com/galleries/2011/news/companies/1110/gallery.40_under_40_ones_to_watch.fortune/" class="uri">http://money.cnn.com/galleries/2011/news/companies/1110/gallery.40_under_40_ones_to_watch.fortune/</a>.</p>
</div>
<div id="ref-Levy_2016">
<p>Levy, Steven. 2016. “How Google Is Remaking Itself as a ‘Machine Learning First’ Company.” <em>Medium</em>. June 32. <a href="https://backchannel.com/how-google-is-remaking-itself-as-a-machine-learning-first-company-ada63defcb70#.fj3u7o3t2" class="uri">https://backchannel.com/how-google-is-remaking-itself-as-a-machine-learning-first-company-ada63defcb70#.fj3u7o3t2</a>.</p>
</div>
<div id="ref-Suchman_2006">
<p>Suchman, Lucy. 2006. <em>Human and Machine Reconfigurations: Plans and Situated Actions</em>. 2nd ed. Cambridge University Press.</p>
</div>
<div id="ref-Dahl_2013">
<p>Dahl, George. 2013. “Deep Learning How I Did It: Merck 1st Place Interview.” <em>No Free Hunch</em>. <a href="http://blog.kaggle.com/2012/11/01/deep-learning-how-i-did-it-merck-1st-place-interview/" class="uri">http://blog.kaggle.com/2012/11/01/deep-learning-how-i-did-it-merck-1st-place-interview/</a>.</p>
</div>
<div id="ref-Hinton_2006a">
<p>Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. 2006. “A Fast Learning Algorithm for Deep Belief Nets.” <em>Neural Computation</em> 18 (7): 1527–54. doi:<a href="https://doi.org/10.1162/neco.2006.18.7.1527">10.1162/neco.2006.18.7.1527</a>.</p>
</div>
<div id="ref-Hayles_1999">
<p>Hayles, N. Katherine. 1999. <em>How We Became Posthuman : Virtual Bodies in Cybernetics, Literature, and</em>. Chicago, Ill. ; London: University of Chicago Press.</p>
</div>
<div id="ref-Halpern_2015">
<p>Halpern, Orit. 2015. <em>Beautiful Data</em>. Durham, N.C: Duke University Press.</p>
</div>
<div id="ref-Wilson_2010">
<p>Wilson, Elizabeth A. 2010. <em>Affect and Artificial Intelligence</em>. University of Washington Press.</p>
</div>
<div id="ref-Ackley_1985">
<p>Ackley, David H., Geoffrey E. Hinton, and Terrence J. Sejnowski. 1985. “A Learning Algorithm for Boltzmann Machines.” <em>Cognitive Science</em> 9 (1): 147–69. <a href="http://www.sciencedirect.com/science/article/pii/S0364021385800124" class="uri">http://www.sciencedirect.com/science/article/pii/S0364021385800124</a>.</p>
</div>
<div id="ref-Rosenblatt_1958">
<p>Rosenblatt, F. 1958. “The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.” <em>Psychological Review</em> 65 (6): 386–408. doi:<a href="https://doi.org/10.1037/h0042519">10.1037/h0042519</a>.</p>
</div>
<div id="ref-Edwards_1996">
<p>Edwards, Paul N. 1996. <em>The Closed World : Computers and the Politics of Discourse in Cold War</em>. Inside Technology. Cambridge, MA; London: MIT Press.</p>
</div>
<div id="ref-Minsky_1969">
<p>Minsky, Marvin, and Seymour Papert. 1969. “Perceptron: An Introduction to Computational Geometry.” <em>The MIT Press, Cambridge, Expanded Edition</em> 19: 88.</p>
</div>
<div id="ref-Rumelhart_1985">
<p>Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. 1985. “Learning Internal Representations by Error Propagation.” DTIC Document. <a href="http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA164453" class="uri">http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA164453</a>.</p>
</div>
<div id="ref-Hinton_1989">
<p>Hinton, Geoffrey E. 1989. “Connectionist Learning Procedures.” <em>Artificial Intelligence</em> 40 (1): 185–234. <a href="http://www.sciencedirect.com.ezproxy.lancs.ac.uk/science/article/pii/0004370289900490" class="uri">http://www.sciencedirect.com.ezproxy.lancs.ac.uk/science/article/pii/0004370289900490</a>.</p>
</div>
<div id="ref-Alpaydin_2010">
<p>Alpaydin, Ethem. 2010. <em>Introduction to Machine Learning</em>. Cambridge, Massachusetts; London: MIT Press.</p>
</div>
<div id="ref-KDD_2013">
<p>KDD. 2013. “Call For KDD Cup.” <a href="http://www.kdd.org/kdd2013/call-for-cup" class="uri">http://www.kdd.org/kdd2013/call-for-cup</a>.</p>
</div>
<div id="ref-Hastie_2009">
<p>Hastie, Trevor, Robert Tibshirani, and Jerome H. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. 2nd edition. New York: Springer.</p>
</div>
<div id="ref-LeCun_2012">
<p>LeCun, Yann, and Corinna Cortes. 2012. “MNIST Handwritten Digit Database, Yann LeCun, Corinna Cortes and Chris Burges.” <a href="http://yann.lecun.com/exdb/mnist/" class="uri">http://yann.lecun.com/exdb/mnist/</a>.</p>
</div>
<div id="ref-Zare_2012">
<p>Zare, Douglas. 2012. “Difference Between Logistic Regression and Neural Networks - Cross Validated.” <em>CrossValidated</em>. December 7. <a href="http://stats.stackexchange.com/questions/43538/difference-between-logistic-regression-and-neural-networks" class="uri">http://stats.stackexchange.com/questions/43538/difference-between-logistic-regression-and-neural-networks</a>.</p>
</div>
<div id="ref-Rumelhart_1986">
<p>Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. 1985. “Learning Internal Representations by Error Propagation.” DTIC Document. <a href="http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA164453" class="uri">http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA164453</a>.</p> 1986. “Learning Representations by Back-Propagating Errors.” <em>Nature</em> 323 (6088): 533–36. doi:<a href="https://doi.org/10.1038/323533a0">10.1038/323533a0</a>.</p>
</div>
<div id="ref-Gomes_2014">
<p>Gomes, Lee. 2014. “Machine-Learning Maestro Michael Jordan on the Delusions of Big Data and Other Huge Engineering Efforts - IEEE Spectrum.” October 3. <a href="http://spectrum.ieee.org/robotics/artificial-intelligence/machinelearning-maestro-michael-jordan-on-the-delusions-of-big-data-and-other-huge-engineering-efforts" class="uri">http://spectrum.ieee.org/robotics/artificial-intelligence/machinelearning-maestro-michael-jordan-on-the-delusions-of-big-data-and-other-huge-engineering-efforts</a>.</p>
</div>
<div id="ref-Hinton_2006">
<p>Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. 2006. “Reducing the Dimensionality of Data with Neural Networks.” <em>Science</em> 313 (5786): 504–7. <a href="http://www.sciencemag.org/content/313/5786/504.short" class="uri">http://www.sciencemag.org/content/313/5786/504.short</a>.</p>
</div>
<div id="ref-Hof_2014">
<p>Hof, Robert D. 2014. “Chinese Search Giant Baidu Thinks AI Pioneer Andrew Ng Can Help It Challenge Google and Become a Global Power.” <em>MIT Technology Review</em>. August 14. <a href="http://www.technologyreview.com/featuredstory/530016/a-chinese-internet-giant-starts-to-dream/" class="uri">http://www.technologyreview.com/featuredstory/530016/a-chinese-internet-giant-starts-to-dream/</a>.</p>
</div>
<div id="ref-Fritsch_2012">
<p>Fritsch, Stefan, and Frauke Guenther. 2012. <em>Neuralnet: Training of Neural Networks</em>. <a href="http://CRAN.R-project.org/package=neuralnet" class="uri">http://CRAN.R-project.org/package=neuralnet</a>.</p>
</div>
<div id="ref-McClelland_1986">
<p>McClelland, James L., and David E. Rumelhart. 1986. <em>Parallel Distributed Processing. Explorations in the Microstructure of Cognition</em>. Vol. 1. Cambridge, MA &amp; London: MIT Press.</p>
</div>
<div id="ref-LeCun_1989">
<p>LeCun, Yann, Bernhard Boser, John S. Denker, Donnie Henderson, Richard E. Howard, Wayne Hubbard, and Lawrence D. Jackel. 1989. “Backpropagation Applied to Handwritten Zip Code Recognition.” <em>Neural Computation</em> 1 (4): 541–51. <a href="http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541" class="uri">http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541</a>.</p>
</div>
<div id="ref-ILSVRC_2014">
<p>ILSVRC. 2014. “ImageNet Large Scale Visual Recognition Competition 2014 (ILSVRC2014).” <a href="http://www.image-net.org/challenges/LSVRC/2014/" class="uri">http://www.image-net.org/challenges/LSVRC/2014/</a>.</p>
</div>
<div id="ref-Kaggle_2012">
<p>Kaggle. 2012. “The Hewlett Foundation: Automated Essay Scoring | Kaggle.” <a href="https://www.kaggle.com/c/asap-aes" class="uri">https://www.kaggle.com/c/asap-aes</a>.</p>
</div>
<div id="ref-Kaggle_2015d">
<p>Kaggle. 2015c. “Data Science Jobs Forum | Kaggle.” <a href="https://www.kaggle.com/jobs" class="uri">https://www.kaggle.com/jobs</a>.</p>
</div>
<div id="ref-Kaggle_2015">
<p>Kaggle. 2015b. “Competitions | Kaggle.” <a href="https://www.kaggle.com/solutions/competitions" class="uri">https://www.kaggle.com/solutions/competitions</a>.</p>
</div>
<div id="ref-Kaggle_2015b">
<p>Kaggle. 2015a. “About | Kaggle.” <a href="https://www.kaggle.com/about" class="uri">https://www.kaggle.com/about</a>.</p>
</div>
<div id="ref-Kaggle_2015c">
<p>Kaggle. 2015e. “Description - Leaping Leaderboard Leapfrogs | Kaggle.” <a href="https://www.kaggle.com/c/leapfrogging-leaderboards" class="uri">https://www.kaggle.com/c/leapfrogging-leaderboards</a>.</p>
</div>
<div id="ref-Foucault_1977">
<p>Foucault, Michel. 1977. <em>Discipline and Punish: The Birth of the Prison</em>. Translated by Allan Sheridan-Smith. New York: Vintage.</p>
</div>
<div id="ref-Dieleman_2015a">
<p>Dieleman, Sander. 2015. “Classifying Plankton with Deep Neural Networks.” <em>Sander Dieleman</em>. <a href="http://benanne.github.io/2015/03/17/plankton.html" class="uri">http://benanne.github.io/2015/03/17/plankton.html</a>.</p>
</div>
<div id="ref-Silver_2016">
<p>Silver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, et al. 2016. “Mastering the Game of Go with Deep Neural Networks and Tree Search.” <em>Nature</em> 529 (7587): 484–89. <a href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html" class="uri">http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="89">
<li id="fn89"><p>In earlier work on machine learning <span class="citation">(Mackenzie <a href="#ref-Mackenzie_2013">2013</a><a href="#ref-Mackenzie_2013">b</a>)</span>, I presented programmers as agents of anticipation, suggesting that the turn to machine learning amongst programmers could be useful in understanding how predictivity was being done amidst broader shift to the regime of anticipation described by Vincenne Adams, Michelle Murphy and Adele Clarke <span class="citation">(Adams, Murphy, and Clarke <a href="#ref-Adams_2009">2009</a>)</span>. Subsequently developments in machine learning, even just in the last three years, confirm that view, but in this chapter and in this book more generally, I focus less on transformations in programming practice and software development, and more on the asymmetries of different machine learner subjects in relation to infrastructures and knowledge.<a href="10-propagating-subject-positions.html#fnref89">↩</a></p></li>
<li id="fn90"><p>Other figures we might follow include Claudia Perlich, Andrew Ng, Geoffrey Hinton, Corinna Cortez, Daphne Koller, Christopher Bishop, Yann LeCun, or Jeff Hammerbacher. Although some women’s names appear here, in any such list, men’s names are much more likely to appear. This is no accident. <a href="10-propagating-subject-positions.html#fnref90">↩</a></p></li>
<li id="fn91"><p>In the case of this paper, and many others related to neural nets, the images are of hand-written digits. These digits have an almost constitutive role, as I discuss in this chapter.<a href="10-propagating-subject-positions.html#fnref91">↩</a></p></li>
<li id="fn92"><p>Although mainstream media accounts of machine learning are not the focus of my interest here, it is hard to ignore the extraordinary level of interest that deep learning projects and techniques have attracted in the last few years. Articles have appeared in all the usual places – <em>The New York Times</em> <span class="citation">(Markoff <a href="#ref-Markoff_2012">2012</a>)</span>, <em>Wired</em><span class="citation">(Garling <a href="#ref-Garling_2015">2015</a>)</span>, or <em>The Guardian</em> <span class="citation">(Arthur <a href="#ref-Arthur_2015">2015</a>)</span>. In many of these accounts, machine learning and neural nets in particular appear both in the guise of the existential threat of artificial intelligence and as a mundane device (for instance, speech recognition on a mobile phone). The spectacular character of deep learning could be analysed in terms like that of the genomes discussed in chapter <a href="#ch:genome"><strong>??</strong></a>. In both cases, the advent and transformation of these machine learners is closely linked to networked platforms (such as Google, Facebook, Yahoo and Microsoft) and their efforts to encompass within their services as many elements of experience, exchange, communication and power as possible. Deep learning machine learners currently focus mostly on images (photographs and video) and sounds (speech and music), and usually attempt to locate and label objects, words or genres. <a href="10-propagating-subject-positions.html#fnref92">↩</a></p></li>
<li id="fn93"><p>We saw some use of neural nets in genomics in the previous chapter (<a href="#ch:genome"><strong>??</strong></a>). The initial publication of the <code>SRBCT</code> microarray dataset in <span class="citation">(Khan et al. <a href="#ref-Khan_2001">2001</a>)</span> relied on neural nets. <a href="10-propagating-subject-positions.html#fnref93">↩</a></p></li>
<li id="fn94"><p>Neural nets also receive uneven attention in the machine learning literature. In Andrew Ng’s Stanford CS229 lectures from 2007, they receive somewhat short shrift: around 30 minutes of discussion in Lecture 6, in between Naive Bayes classifiers and several weeks of lectures on support vector machines <span class="citation">(<em>Lecture 6 | Machine Learning (Stanford)</em> <a href="#ref-Ng_2008b">2008</a>)</span>. As he introduces a video of an autonomous vehicle steered by a neural net after a 20 minute training session with a human driver, Ng comments that ‘neural nets were the best for many years.’  The lectures quickly moves on to the successor, support vector machines. In <em>Elements of Statistical Learning</em>, a whole chapter appears on the topic, but prefaced by a discussion of the antecedent statistical method of ‘projection pursuit regression.’ The inception of ‘projection pursuit’ is dated to 1974, and thus precedes the 1980s work on neural nets that was to receive so much attention. In <em>An Introduction to Statistical Learning with Applications in R</em>, a book whose authors include Hastie and Tibshirani, neural nets are not discussed and indeed not mentioned <span class="citation">(James et al. <a href="#ref-James_2013">2013</a>)</span>. Textbooks written by computer scientists such as Ethem Alpaydin’s <em>Introduction to Machine Learning</em> do usually include at least a chapter on them, sometimes under different titles such as ‘multi-layer perceptrons’ <span class="citation">(Alpaydin <a href="#ref-Alpaydin_2010">2010</a>)</span>. Willi Richert and Luis Pedro Coelho’s <em>Building Machine Learning Systems with Python</em> likewise does not mention them <span class="citation">(Richert and Coelho <a href="#ref-Richert_2013">2013</a>)</span>. Cathy O’Neil and Rachel Schutt’s <em>Doing Data Science</em> mentions them but does not discuss them <span class="citation">(Schutt and O’Neil <a href="#ref-Schutt_2013">2013</a>)</span>, whereas both Brett Lantz’s <em>Machine Learning with R</em> <span class="citation">(Lantz <a href="#ref-Lantz_2013">2013</a>)</span> and Matthew Kirk’s <em>Thoughtful Machine Learning</em> <span class="citation">(Kirk <a href="#ref-Kirk_2014">2014</a>)</span> devote chapters to them. In the broader cannon of machine learning texts, the computer scientist Christopher Bishop’s heavily cited books on pattern recognition dwell extensively on neural nets <span class="citation">(Bishop and others <a href="#ref-Bishop_1995">1995</a>; Bishop <a href="#ref-Bishop_2006">2006</a>)</span>. Amongst statisticians, Brian Ripley’s <em>Pattern Recognition and Neural Networks</em> <span class="citation">(Ripley <a href="#ref-Ripley_1996">1996</a>)</span>, also highly cited, placed a great deal of emphasis on them. But these textbooks stand out against a pointillistic background of hundreds of thousands of scientific publications mentioning or making use of neural nets since the late 1980s in the usual litany of fields – atmospheric sciences, biosensors, botany, power systems, water resource management, internal medicine, etc. This swollen publication tide attests to some kind of formation or configuration of knowledge invested in these particular techniques, perhaps more so than other I have discussed so far ( logistic regression, support vector machine, decision trees, random forests, linear discriminant analysis, etc.).<a href="10-propagating-subject-positions.html#fnref94">↩</a></p></li>
<li id="fn95"><p>Unlike the cats detected by <code>kittydar,</code> the software discussed in the introduction to this book, the Google experiment did not use supervised learning. The deep learning approach was unsupervised <span class="citation">(Markoff <a href="#ref-Markoff_2012">2012</a>)</span>. That is, the neural nets were not trained using labelled images of cats.<a href="10-propagating-subject-positions.html#fnref95">↩</a></p></li>
<li id="fn96"><p>In any case, social media and search engines cannot be understood apart from the machine learning techniques that have been thoroughly woven through them since their inception. Hence <em>Elements of Statistical Learning</em> devotes several pages to Google’s famous <em>PageRank</em> algorithm, describing it as an unsupervised learner <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 576–78)</span>. <a href="10-propagating-subject-positions.html#fnref96">↩</a></p></li>
<li id="fn97"><p>Recent work on deep belief networks replaces the sigmoid function with other non-linear functions that subtly alter the way layers of neural nets relate to each other. See <span class="citation">(Glorot and Bengio <a href="#ref-Glorot_2010">2010</a>)</span> for an account of changing training practices in neural nets.<a href="10-propagating-subject-positions.html#fnref97">↩</a></p></li>
<li id="fn98"><p>If back-propagation was formulated in the 1980s (and indeed, was already known in 1960), what do we learn from its current re-iterations? Given the effort that went into crafting neural nets to recognise handwritten digits during the 1980s and 1990s, what does the revival of neural nets suggest about machine learning as feed-forward/back-propagation operation? From the early publications such as <span class="citation">(Rumelhart, Hinton, and Williams <a href="#ref-Rumelhart_1985">1985</a>)</span> on, the layered composition of the model has been linked to architectural considerations. As Hastie and co-authors write:</p><blockquote><p>The advantages of back-propagation are its simple, local nature. In the back propagation algorithm, each hidden unit passes and receives information only to and from units that share a connection. Hence it can be implemented efficiently on a parallel architecture computer <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie_2009">2009</a>, 397)</span>.</p></blockquote><p>These practical considerations have different significance in different settings. Some of the current iterations of neural nets in deep learning rely on massively parallel computing architectures (for instance, Andrew Ng’s GoogleX Youtube video project). Yet the information sharing that happens during back-propagation might also encompass the human others of neural nets. The efficient parallel implementation in computing architecture affects, I would suggest, human and non-human machine learners in different ways. <a href="10-propagating-subject-positions.html#fnref98">↩</a></p></li>
<li id="fn99"><p>At the time of writing, Kaggle claims around 320,000 competitors.<a href="10-propagating-subject-positions.html#fnref99">↩</a></p></li>
<li id="fn100"><p>Kaggle itself has the actual labels for the test dataset. Entrants monitor the leaderboard and attempt to improve their rankings by making new submissions with improved or altered models. The many entries that participants sometimes submit to the competitions suggest that rankings, and their visibility operate like the loss functions that optimise the fit of a subject position to an operational formation. <a href="10-propagating-subject-positions.html#fnref100">↩</a></p></li>
<li id="fn101"><p>As another competitor in the National Data Science Bowl mentions:</p><blockquote><p>One example is here the Kaggle plankton detection competition. At first I thought about entering the competition as I might have a huge advantage through my 4 GPU system. I reasoned I might be able to train a very large convolutional net in a very short time – one thing that others cannot do because they lack the hardware <span class="citation">(Dettmers <a href="#ref-Dettmers_2015">2015</a>)</span></p></blockquote><p>Hardware parallelism and vectorization, at least in the area of deep learning, seems to matter more than the ability to test, examine, observe or invest new model configurations. <a href="10-propagating-subject-positions.html#fnref101">↩</a></p></li>
<li id="fn102"><p>On the command line, <code>git clone https://github.com/benanne/kaggle-ndsb</code> makes a copy of the model code. The code in that github repository gives some idea of the mosaic of techniques, configurations, variations and tests undertaken by ‘DeepSea.’<a href="10-propagating-subject-positions.html#fnref102">↩</a></p></li>
<li id="fn103"><p>The cultural theorist Lauren Berlant describes optimism as an ‘operation’:</p><blockquote><p>The surrender to the return to the scene where the object hovers in its potentialities is the operation of optimism as an affective form <span class="citation">(Berlant <a href="#ref-Berlant_2007">2007</a>, 20)</span></p></blockquote><p>Berlant’s complicated formulation brings together surrender, return, scene, object, potentialities and affective form. These movements, places and things might be understood as purely psychic or semiotic processes. But optimism as an asignifying diagrammatic operation also plays out across the manifold surfaces of algorithms, datasets, models, platforms and ranking systems associated with machine learning as a competitive examination. <a href="10-propagating-subject-positions.html#fnref103">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="9-regularizing-and-materializing-objects.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="11-conclusion-out-of-the-data.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
