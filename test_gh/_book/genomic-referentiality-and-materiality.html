<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regularizing-and-materializing-objects.html">
<link rel="next" href="the-genome-as-threshold-object.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i><b>1</b> Acknowledgments</a></li>
<li class="chapter" data-level="2" data-path="conclusion-out-of-the-data.html"><a href="conclusion-out-of-the-data.html"><i class="fa fa-check"></i><b>2</b> Conclusion: Out of the Data}</a></li>
<li class="chapter" data-level="3" data-path="machine-learners.html"><a href="machine-learners.html"><i class="fa fa-check"></i><b>3</b> 250,000 machine learners</a></li>
<li class="chapter" data-level="4" data-path="a-summary-of-the-argument.html"><a href="a-summary-of-the-argument.html"><i class="fa fa-check"></i><b>4</b> A summary of the argument</a></li>
<li class="chapter" data-level="5" data-path="in-situ-hybridization.html"><a href="in-situ-hybridization.html"><i class="fa fa-check"></i><b>5</b> In-situ hybridization</a></li>
<li class="chapter" data-level="6" data-path="critical-operational-practice.html"><a href="critical-operational-practice.html"><i class="fa fa-check"></i><b>6</b> Critical operational practice?</a></li>
<li class="chapter" data-level="7" data-path="obstacles-to-the-work-of-freeing-machine-learning.html"><a href="obstacles-to-the-work-of-freeing-machine-learning.html"><i class="fa fa-check"></i><b>7</b> Obstacles to the work of freeing machine learning</a></li>
<li class="chapter" data-level="8" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i><b>8</b> Preface</a></li>
<li class="chapter" data-level="9" data-path="introduction-into-the-data.html"><a href="introduction-into-the-data.html"><i class="fa fa-check"></i><b>9</b> Introduction: Into the Data</a></li>
<li class="chapter" data-level="10" data-path="three-accumulations-settings-data-and-devices.html"><a href="three-accumulations-settings-data-and-devices.html"><i class="fa fa-check"></i><b>10</b> Three accumulations: settings, data and devices</a></li>
<li class="chapter" data-level="11" data-path="who-or-what-is-a-machine-learner.html"><a href="who-or-what-is-a-machine-learner.html"><i class="fa fa-check"></i><b>11</b> Who or what is a machine learner?</a></li>
<li class="chapter" data-level="12" data-path="algorithmic-control-to-the-machine-learners.html"><a href="algorithmic-control-to-the-machine-learners.html"><i class="fa fa-check"></i><b>12</b> Algorithmic control to the machine learners?</a></li>
<li class="chapter" data-level="13" data-path="the-archaeology-of-operations.html"><a href="the-archaeology-of-operations.html"><i class="fa fa-check"></i><b>13</b> The archaeology of operations</a></li>
<li class="chapter" data-level="14" data-path="asymmetries-in-common-knowledge.html"><a href="asymmetries-in-common-knowledge.html"><i class="fa fa-check"></i><b>14</b> Asymmetries in common knowledge</a></li>
<li class="chapter" data-level="15" data-path="what-cannot-be-automated.html"><a href="what-cannot-be-automated.html"><i class="fa fa-check"></i><b>15</b> What cannot be automated?</a></li>
<li class="chapter" data-level="16" data-path="different-fields-in-machine-learning.html"><a href="different-fields-in-machine-learning.html"><i class="fa fa-check"></i><b>16</b> Different fields in machine learning?</a></li>
<li class="chapter" data-level="17" data-path="the-diagram-in-critical-thought.html"><a href="the-diagram-in-critical-thought.html"><i class="fa fa-check"></i><b>17</b> The diagram in critical thought</a></li>
<li class="chapter" data-level="18" data-path="diagramming-machines.html"><a href="diagramming-machines.html"><i class="fa fa-check"></i><b>18</b> Diagramming machines}</a></li>
<li class="chapter" data-level="19" data-path="we-dont-have-to-write-programs.html"><a href="we-dont-have-to-write-programs.html"><i class="fa fa-check"></i><b>19</b> ‘We don’t have to write programs’?</a></li>
<li class="chapter" data-level="20" data-path="the-elements-of-machine-learning.html"><a href="the-elements-of-machine-learning.html"><i class="fa fa-check"></i><b>20</b> The elements of machine learning</a></li>
<li class="chapter" data-level="21" data-path="who-reads-machine-learning-textbooks.html"><a href="who-reads-machine-learning-textbooks.html"><i class="fa fa-check"></i><b>21</b> Who reads machine learning textbooks?</a></li>
<li class="chapter" data-level="22" data-path="r-a-matrix-of-transformations.html"><a href="r-a-matrix-of-transformations.html"><i class="fa fa-check"></i><b>22</b> <code>R</code>: a matrix of transformations</a></li>
<li class="chapter" data-level="23" data-path="the-obdurate-mathematical-glint-of-machine-learning.html"><a href="the-obdurate-mathematical-glint-of-machine-learning.html"><i class="fa fa-check"></i><b>23</b> The obdurate mathematical glint of machine learning</a></li>
<li class="chapter" data-level="24" data-path="cs229-2007-returning-again-and-again-to-certain-features.html"><a href="cs229-2007-returning-again-and-again-to-certain-features.html"><i class="fa fa-check"></i><b>24</b> CS229, 2007: returning again and again to certain features</a></li>
<li class="chapter" data-level="25" data-path="the-visible-learning-of-machine-learning.html"><a href="the-visible-learning-of-machine-learning.html"><i class="fa fa-check"></i><b>25</b> The visible learning of machine learning</a></li>
<li class="chapter" data-level="26" data-path="the-diagram-of-an-operational-formation.html"><a href="the-diagram-of-an-operational-formation.html"><i class="fa fa-check"></i><b>26</b> The diagram of an operational formation</a></li>
<li class="chapter" data-level="27" data-path="vectorisation-and-its-consequences.html"><a href="vectorisation-and-its-consequences.html"><i class="fa fa-check"></i><b>27</b> Vectorisation and its consequences}</a></li>
<li class="chapter" data-level="28" data-path="vector-space-and-geometry.html"><a href="vector-space-and-geometry.html"><i class="fa fa-check"></i><b>28</b> Vector space and geometry</a></li>
<li class="chapter" data-level="29" data-path="mixing-places.html"><a href="mixing-places.html"><i class="fa fa-check"></i><b>29</b> Mixing places</a></li>
<li class="chapter" data-level="30" data-path="truth-is-no-longer-in-the-table.html"><a href="truth-is-no-longer-in-the-table.html"><i class="fa fa-check"></i><b>30</b> Truth is no longer in the table?</a></li>
<li class="chapter" data-level="31" data-path="the-epistopic-fault-line-in-tables.html"><a href="the-epistopic-fault-line-in-tables.html"><i class="fa fa-check"></i><b>31</b> The epistopic fault line in tables</a></li>
<li class="chapter" data-level="32" data-path="surface-and-depths-the-problem-of-volume-in-data.html"><a href="surface-and-depths-the-problem-of-volume-in-data.html"><i class="fa fa-check"></i><b>32</b> Surface and depths: the problem of volume in data</a></li>
<li class="chapter" data-level="33" data-path="vector-space-expansion.html"><a href="vector-space-expansion.html"><i class="fa fa-check"></i><b>33</b> Vector space expansion</a></li>
<li class="chapter" data-level="34" data-path="drawing-lines-in-a-common-space-of-transformation.html"><a href="drawing-lines-in-a-common-space-of-transformation.html"><i class="fa fa-check"></i><b>34</b> Drawing lines in a common space of transformation</a></li>
<li class="chapter" data-level="35" data-path="implicit-vectorization-in-code-and-infrastructures.html"><a href="implicit-vectorization-in-code-and-infrastructures.html"><i class="fa fa-check"></i><b>35</b> Implicit vectorization in code and infrastructures</a></li>
<li class="chapter" data-level="36" data-path="lines-traversing-behind-the-light.html"><a href="lines-traversing-behind-the-light.html"><i class="fa fa-check"></i><b>36</b> Lines traversing behind the light</a></li>
<li class="chapter" data-level="37" data-path="the-vectorised-table.html"><a href="the-vectorised-table.html"><i class="fa fa-check"></i><b>37</b> The vectorised table?</a></li>
<li class="chapter" data-level="38" data-path="machines-finding-functions.html"><a href="machines-finding-functions.html"><i class="fa fa-check"></i><b>38</b> Machines finding functions}</a></li>
<li class="chapter" data-level="39" data-path="learning-functions.html"><a href="learning-functions.html"><i class="fa fa-check"></i><b>39</b> Learning functions</a></li>
<li class="chapter" data-level="40" data-path="supervised-unsupervised-reinforcement-learning-and-functions.html"><a href="supervised-unsupervised-reinforcement-learning-and-functions.html"><i class="fa fa-check"></i><b>40</b> Supervised, unsupervised, reinforcement learning and functions</a></li>
<li class="chapter" data-level="41" data-path="which-function-operates.html"><a href="which-function-operates.html"><i class="fa fa-check"></i><b>41</b> Which function operates?</a></li>
<li class="chapter" data-level="42" data-path="what-does-a-function-learn.html"><a href="what-does-a-function-learn.html"><i class="fa fa-check"></i><b>42</b> What does a function learn?</a></li>
<li class="chapter" data-level="43" data-path="observing-with-curves-the-logistic-function.html"><a href="observing-with-curves-the-logistic-function.html"><i class="fa fa-check"></i><b>43</b> Observing with curves: the logistic function</a></li>
<li class="chapter" data-level="44" data-path="the-cost-of-curves-in-machine-learning.html"><a href="the-cost-of-curves-in-machine-learning.html"><i class="fa fa-check"></i><b>44</b> The cost of curves in machine learning</a></li>
<li class="chapter" data-level="45" data-path="curves-and-the-variation-in-models.html"><a href="curves-and-the-variation-in-models.html"><i class="fa fa-check"></i><b>45</b> Curves and the variation in models</a></li>
<li class="chapter" data-level="46" data-path="observing-costs-losses-and-objectives-through-optimisation.html"><a href="observing-costs-losses-and-objectives-through-optimisation.html"><i class="fa fa-check"></i><b>46</b> Observing costs, losses and objectives through optimisation</a></li>
<li class="chapter" data-level="47" data-path="gradients-as-partial-observers.html"><a href="gradients-as-partial-observers.html"><i class="fa fa-check"></i><b>47</b> Gradients as partial observers</a></li>
<li class="chapter" data-level="48" data-path="the-power-to-learn.html"><a href="the-power-to-learn.html"><i class="fa fa-check"></i><b>48</b> The power to learn</a></li>
<li class="chapter" data-level="49" data-path="n-forallboldsymbolx-probabilisation-and-the-taming-of-machines.html"><a href="n-forallboldsymbolx-probabilisation-and-the-taming-of-machines.html"><i class="fa fa-check"></i><b>49</b> <span class="math inline">\(N = \forall\boldsymbol{X}\)</span> Probabilisation and the Taming of Machines}</a></li>
<li class="chapter" data-level="50" data-path="data-reduces-uncertainty.html"><a href="data-reduces-uncertainty.html"><i class="fa fa-check"></i><b>50</b> Data reduces uncertainty?</a></li>
<li class="chapter" data-level="51" data-path="machine-learning-as-statistics-inside-out.html"><a href="machine-learning-as-statistics-inside-out.html"><i class="fa fa-check"></i><b>51</b> Machine learning as statistics inside out</a></li>
<li class="chapter" data-level="52" data-path="distributed-probabilities.html"><a href="distributed-probabilities.html"><i class="fa fa-check"></i><b>52</b> Distributed probabilities</a></li>
<li class="chapter" data-level="53" data-path="naive-bayes-and-the-distribution-of-probabilities.html"><a href="naive-bayes-and-the-distribution-of-probabilities.html"><i class="fa fa-check"></i><b>53</b> Naive Bayes and the distribution of probabilities</a></li>
<li class="chapter" data-level="54" data-path="spam-when-foralln-is-too-much.html"><a href="spam-when-foralln-is-too-much.html"><i class="fa fa-check"></i><b>54</b> Spam: when <span class="math inline">\(\forall{N}\)</span> is too much?</a></li>
<li class="chapter" data-level="55" data-path="the-improbable-success-of-the-naive-bayes-classifier.html"><a href="the-improbable-success-of-the-naive-bayes-classifier.html"><i class="fa fa-check"></i><b>55</b> The improbable success of the Naive Bayes classifier</a></li>
<li class="chapter" data-level="56" data-path="ancestral-probabilities-in-documents-inference-and-prediction.html"><a href="ancestral-probabilities-in-documents-inference-and-prediction.html"><i class="fa fa-check"></i><b>56</b> Ancestral probabilities in documents: inference and prediction</a></li>
<li class="chapter" data-level="57" data-path="statistical-decompositions-bias-variance-and-observed-errors.html"><a href="statistical-decompositions-bias-variance-and-observed-errors.html"><i class="fa fa-check"></i><b>57</b> Statistical decompositions: bias, variance and observed errors</a></li>
<li class="chapter" data-level="58" data-path="does-machine-learning-construct-a-new-statistical-reality.html"><a href="does-machine-learning-construct-a-new-statistical-reality.html"><i class="fa fa-check"></i><b>58</b> Does machine learning construct a new statistical reality?</a></li>
<li class="chapter" data-level="59" data-path="patterns-and-differences.html"><a href="patterns-and-differences.html"><i class="fa fa-check"></i><b>59</b> Patterns and differences</a></li>
<li class="chapter" data-level="60" data-path="splitting-and-the-growth-of-trees.html"><a href="splitting-and-the-growth-of-trees.html"><i class="fa fa-check"></i><b>60</b> Splitting and the growth of trees</a></li>
<li class="chapter" data-level="61" data-path="differences-in-recursive-partitioning.html"><a href="differences-in-recursive-partitioning.html"><i class="fa fa-check"></i><b>61</b> 1984: Differences in recursive partitioning</a></li>
<li class="chapter" data-level="62" data-path="limiting-differences.html"><a href="limiting-differences.html"><i class="fa fa-check"></i><b>62</b> Limiting differences</a></li>
<li class="chapter" data-level="63" data-path="the-successful-dispersion-of-the-support-vector-machine.html"><a href="the-successful-dispersion-of-the-support-vector-machine.html"><i class="fa fa-check"></i><b>63</b> The successful dispersion of the support vector machine</a></li>
<li class="chapter" data-level="64" data-path="differences-blur.html"><a href="differences-blur.html"><i class="fa fa-check"></i><b>64</b> Differences blur?</a></li>
<li class="chapter" data-level="65" data-path="bending-the-decision-boundary.html"><a href="bending-the-decision-boundary.html"><i class="fa fa-check"></i><b>65</b> Bending the decision boundary</a></li>
<li class="chapter" data-level="66" data-path="instituting-patterns.html"><a href="instituting-patterns.html"><i class="fa fa-check"></i><b>66</b> Instituting patterns</a></li>
<li class="chapter" data-level="67" data-path="regularizing-and-materializing-objects.html"><a href="regularizing-and-materializing-objects.html"><i class="fa fa-check"></i><b>67</b> Regularizing and materializing objects}</a></li>
<li class="chapter" data-level="68" data-path="genomic-referentiality-and-materiality.html"><a href="genomic-referentiality-and-materiality.html"><i class="fa fa-check"></i><b>68</b> Genomic referentiality and materiality</a></li>
<li class="chapter" data-level="69" data-path="the-genome-as-threshold-object.html"><a href="the-genome-as-threshold-object.html"><i class="fa fa-check"></i><b>69</b> The genome as threshold object</a></li>
<li class="chapter" data-level="70" data-path="genomic-knowledges-and-their-datasets.html"><a href="genomic-knowledges-and-their-datasets.html"><i class="fa fa-check"></i><b>70</b> Genomic knowledges and their datasets</a></li>
<li class="chapter" data-level="71" data-path="the-advent-of-wide-dirty-and-mixed-data.html"><a href="the-advent-of-wide-dirty-and-mixed-data.html"><i class="fa fa-check"></i><b>71</b> The advent of ‘wide, dirty and mixed’ data</a></li>
<li class="chapter" data-level="72" data-path="cross-validating-machine-learning-in-genomics.html"><a href="cross-validating-machine-learning-in-genomics.html"><i class="fa fa-check"></i><b>72</b> Cross-validating machine learning in genomics</a></li>
<li class="chapter" data-level="73" data-path="proliferation-of-discoveries.html"><a href="proliferation-of-discoveries.html"><i class="fa fa-check"></i><b>73</b> Proliferation of discoveries</a></li>
<li class="chapter" data-level="74" data-path="variations-in-the-object-or-in-the-machine-learner.html"><a href="variations-in-the-object-or-in-the-machine-learner.html"><i class="fa fa-check"></i><b>74</b> Variations in the object or in the machine learner?</a></li>
<li class="chapter" data-level="75" data-path="whole-genome-functions.html"><a href="whole-genome-functions.html"><i class="fa fa-check"></i><b>75</b> Whole genome functions</a></li>
<li class="chapter" data-level="76" data-path="propagating-subject-positions.html"><a href="propagating-subject-positions.html"><i class="fa fa-check"></i><b>76</b> Propagating subject positions}</a></li>
<li class="chapter" data-level="77" data-path="propagation-across-human-machine-boundaries.html"><a href="propagation-across-human-machine-boundaries.html"><i class="fa fa-check"></i><b>77</b> Propagation across human-machine boundaries</a></li>
<li class="chapter" data-level="78" data-path="competitive-positioning.html"><a href="competitive-positioning.html"><i class="fa fa-check"></i><b>78</b> Competitive positioning</a></li>
<li class="chapter" data-level="79" data-path="a-privileged-machine-and-its-diagrammatic-forms.html"><a href="a-privileged-machine-and-its-diagrammatic-forms.html"><i class="fa fa-check"></i><b>79</b> A privileged machine and its diagrammatic forms</a></li>
<li class="chapter" data-level="80" data-path="varying-subject-positions-in-code.html"><a href="varying-subject-positions-in-code.html"><i class="fa fa-check"></i><b>80</b> Varying subject positions in code</a></li>
<li class="chapter" data-level="81" data-path="the-subjects-of-a-hidden-operation.html"><a href="the-subjects-of-a-hidden-operation.html"><i class="fa fa-check"></i><b>81</b> The subjects of a hidden operation</a></li>
<li class="chapter" data-level="82" data-path="algorithms-that-propagate-errors.html"><a href="algorithms-that-propagate-errors.html"><i class="fa fa-check"></i><b>82</b> Algorithms that propagate errors</a></li>
<li class="chapter" data-level="83" data-path="competitions-as-examination.html"><a href="competitions-as-examination.html"><i class="fa fa-check"></i><b>83</b> Competitions as examination</a></li>
<li class="chapter" data-level="84" data-path="superimposing-power-and-knowledge.html"><a href="superimposing-power-and-knowledge.html"><i class="fa fa-check"></i><b>84</b> Superimposing power and knowledge</a></li>
<li class="chapter" data-level="85" data-path="ranked-subject-positions.html"><a href="ranked-subject-positions.html"><i class="fa fa-check"></i><b>85</b> Ranked subject positions</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="genomic-referentiality-and-materiality" class="section level1">
<h1><span class="header-section-number">68</span> Genomic referentiality and materiality</h1>
<blockquote>
<p><code>gaagctccac accagccatt acaaccctgc caatctcaag cacctgcctc tacaggtacc</code> <span class="citation">[@NCBI_2016]</span></p>
</blockquote>
<p>By contrast with industry, commerce, media and government, where much that happens is obscured from view, the great virtue or genomic science is the relative openness of its workings and its resolute insistence on DNA as the primary form of data. The fact that data practices are relatively generic and accessible means that critical research into transformations associated with genomic data and knowledge can accompany nearly every aspect of practice. </p>
<p>Genomic data exhibits some specific features. The first concerns what I earlier called data strain.  Genome data, a tiny fragment of which is shown above, inflates the vector space. Genomics generates new versions of the now familiar problems of data dimensionality. The abundance, diffusion, heterogeneity or impaction of genomic data thwarts its examination, tabulation, and regulated circulation. Genomics data also presents unusual ratios of accumulation and sparsity. Clinical genomics in particular generates datasets that are lavishly furnished with ‘features’ but often quite meagrely supplied with clinical cases or ‘observations’. In the shorthand typical of machine learning terminology, <span class="math inline">\(p\)</span> is larger than <span class="math inline">\(N\)</span>: ‘the number of features <span class="math inline">\(p\)</span> is much larger than the number of observations <span class="math inline">\(N\)</span>, often written <span class="math inline">\(p\gg N\)</span>’ <span class="citation">[@Hastie_2009, 649]</span>. This strains statistical methods that rely on the <span class="math inline">\(\forall{\boldsymbol{X}}\)</span> ‘Law of Large Numbers’ <span class="citation">[@Hacking_1990, 99-104]</span>, which holds that the accuracy of statistics tends to increase with more observations. </p>
<p>Since the early nineteenth century, biology and cognate disciplines have sought to explore problems of time, genesis, duration, activity and process in a very broad spectrum of living things. Contemporary genomics seeks to elicit, as many commentators have noted, knowledge of biological, evolutionary, biomedical and environmental processes from the long DNA sequences comprising genomes. The primary ‘object’ in genomics is a <span class="math inline">\(\forall{\boldsymbol{X}}\)</span> data form, the genome, the full complement of DNA in an organism. Genomes vary in size from the 2000 DNA base pairs of a virus, the 3.2 Gb (gigabase pairs) of humans through to the 130 Gb of the lung fish. The founding premise of genomic science is that a dataset comprising the complete sequence of DNA potentially re-bases knowledge of many different biological processes, ranging from evolution (phylogeny), development (ontogeny), metabolism, structure and pathology.  If nothing else, genome comparison promises knowledge of the 3.8 billion years of evolution of species differences and population diversity.  In all of these respects, DNA sequences have since at least the 1980s served as the common substrate for many different scientific experiments, technical developments, cyber-infrastructures and needless to say, biological imaginaries oriented around the problems of control.<a href="#fn79" class="footnoteRef" id="fnref79"><sup>79</sup></a></p>
<p>The genomic premise has an ineluctably promissory association with knowledge economy.  Prior to the whole genome sequencing projects initiated in the 1990s, biologists had never worked with genomes only with selected DNA sequences, especially those associated with genes and the proteins that they code. By contrast, the genome, with all its repeated, redundant, and slightly varying patterns of DNA, bears the traces of long evolutionary mixing and constitutes a hyper-complex functional process whose exquisite sensitivity to changing conditions – a slight change in light reaching a leaf cascades can be traced in patterns of DNA transcription – forms an extreme case for any operational sense of function. The functioning of genomes symbolises a deeply interconnected relationality in life sciences, and becomes the test case for the learning capacities of machine learners.<a href="#fn80" class="footnoteRef" id="fnref80"><sup>80</sup></a> </p>
<p>As referentials, genomes pose a problem of unregulated abundance and seeming homogeneity. DNA sequences exist in great abundance (in databases, and increasingly, from the cheaper and more compact sequencing instruments), yet even determining how DNA sequence fragments should be ordered in a genome – let alone how they make sense as some biological function – is much harder. DNA sequences are assembled as genomes and genomic datasets via statistical models.   ‘Genome assembly continues to be one of the central problems of bioinformatics’ write the authors of a recent scientific review of the techniques of constructing whole genomes from DNA sequencer data <span class="citation">[@Henson_2012]</span>. Even the elementary data form of the genome as DNA base pairs is a highly algorithmic construct. No existing sequencing technology produces a genome as a single sequence, as a vector (in the sense described in chapter ). Instead, sequencing produces random sets of sequence fragments of various lengths that have to be assembled into a complete genome algorithmically. <a href="#fn81" class="footnoteRef" id="fnref81"><sup>81</sup></a></p>
<p>Between pre-genomic and post-genomic science, the status of significant differences in genomes shifted.  Pre-HGP biology understood the significant differences between individual organisms largely in terms of gene alleles responsible for variations in phenotypes. Biological differences, and disease in particular, stemmed from different forms of genes. Understanding disease meant finding the disease genes. Even prominent proponents of genomics, such as Leroy Hood, writing of ‘Biology and Medicine in the Twenty-First Century’ in 1991, envisaged genomics as a way of simplifying ‘the task of finding disease genes’ <span class="citation">[@Hood_1992,138]</span>. Across the life sciences, genes were the object of much way of annotation, labelling and description. Two decades after the inception of whole genome sequencing, genomes present a different image of variation. According to Nikolas Rose, writing more recently, ‘there is no normal human genome; variation is the norm’ <span class="citation">[@Rose_2009, 75]</span>.   ‘In this new configuration’, he writes, ‘what is required is not a binary judgment of normality and pathology, but a constant modulation of the relations between biology and forms of life, in the light of genomic knowledge.’ The emphasis in Rose’ formulation falls on ‘constant modulation’ of the relations between biology and forms of life. If post-genomic science departs from the understanding that there is no single genome but many genomes, then according to Rose, variation itself becomes of primary interest. Pursuit of variation remakes the genome into ‘a form whose only object is the inseparability of distinct variations’ <span class="citation">[@Deleuze_1994, 21]</span>. </p>
<p>Whatever knowledge subsequently derives from a genome (genes, mutations, evolutionary relationships, variations associated with disease, heredity or individual identity), genomic data and hence the genome itself as a scientific hyperobject  is deeply probabilistic. From assembly onwards, through the ancestral probabilisation embodied in heavily-used biological databases, the indelible errors, the entangled reliances on accumulated biological knowledges make genomes a particularly challenging site of machine learning activity.</p>
<p><em>Elements of Statistical Learning</em>’s invocation of DNA-related data, therefore, is no arbitrarily chosen example amidst the general proliferation of settings, domains, cases and examples typically found in machine learning pedagogy. In multiple dimensions and directions, genomics – the scientific project of operating on the whole DNA complement of organisms – is a tightly coupled referential for machine learning even if relatively few machine learners have, to date, managed to work with whole genome sequence data. The relatively long-established referential entanglement (at least 25 years, and perhaps more) of genomics and machine learning is strategically important in the generalization of machine learning, in the processes whereby techniques, with their specific forms of articulation, statement and making-visible, propagate into multiple, once-disparate settings.<a href="#fn82" class="footnoteRef" id="fnref82"><sup>82</sup></a>  Like social media platforms or retail spaces with their many visitors, genomes, I would suggest, provoke a multiplicity of machine learners to bind to them like antibodies to an antigen (or an allergen). Genomes function as regularizing hyperobjects for machine learning. </p>
</div>
<div class="footnotes">
<hr />
<ol start="79">
<li id="fn79"><p>A large and very diverse social science and humanities literature now exists around genomics. I draw on some of that literature as general background here, especially <span class="citation">[@SunderRajan_2006; @Thacker_2005a; @Stevens_2011; @Leonelli_2014]</span> and <span class="citation">[@Haraway_1997]</span>, but largely do not address it directly.<a href="genomic-referentiality-and-materiality.html#fnref79">↩</a></p></li>
<li id="fn80"><p>As data forms, genomes have a problematic mode of existence. They resemble cat images on the internet. As a data form, genomes are remarkably homogeneous. They are one-dimensional strings of letters corresponding to the well-known four nucleic acids (<code>g</code>, <code>a</code>, <code>t</code>, <code>c</code>).  While many earlier tabulations of variation, difference, groups, types and relations are woven through the life sciences, genomes have for the last several decades mesmerised biological sciences as a way of analysing and re-distributing the confused multiplicities associated with living things. The raw data for genomes comes from the sequencing of DNA obtained from various organisms - viruses, bacteria, plants, fish, animals and humans. The sequencing of DNA, especially DNA that encodes the proteins that pervade biological processes, that structure tissues or assemble in complicated metabolic pathways, has been the concern first of molecular biology (mainly in the 1970s-1990s) and more recently genomics (post-1990). In molecular biology, DNA sequences were carefully elicited (using the experimental techniques for instance of Sanger sequencing) and then compared with already known sequences of DNA to identify similarities that might have biology significance (for instance, evolution from a common ancestor). In genomics, DNA sequences generally originate from increasingly high-throughput sequencers that output massive datasets (see <span class="citation">[@Stevens_2013; @Mackenzie_2015]</span>. Given both the accumulated store of already sequenced DNA and the increasingly viable practices of sequencing all of the DNA in a given organism, genomics has promised a much wider and more detailed understanding of biological complexity than any previous life science had been able to obtain. With genomes in hand, biologists for the first time would be in a position to build models of entire domains of biology, domains that previously could only be explored through painstaking experiments targeting specific cells, molecules, biochemical reactions and networks. The vast yet somewhat dispersed knowledges of the life sciences might be re-ordered and aligned on a new very extensive yet quite homogeneous backbone of the genome read out as billions of DNA base pairs.<a href="genomic-referentiality-and-materiality.html#fnref80">↩</a></p></li>
<li id="fn81"><p>Whole genome assembly as reported for the initial draft of the human genome in 2001 <span class="citation">[@Venter_2001;@Lander_2001]</span> or for the model biological organism, <em>Drosophila</em> <span class="citation">[@Myers_2000]</span> was not at the time understood as a machine learning problem. The task of whole genome assembly from DNA fragments was seen as probabilistic in the sense that the aim is to assemble the often millions of short sequence fragments in an order that is most likely to occur. Even prior to the first full human genome assembly, genomic science had made heavy use of probabilistic models in aligning DNA (and protein amino acid) sequences. Richard Durbin, Sean Eddy, Anders Krogh and Graeme Mitchison’s highly cited <em>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids</em> <span class="citation">[@Durbin_1998]</span> was based almost entirely on Hidden Markov Models, a way of modelling a sequence of states that <em>Elements of Statistical Learning</em> treats at chapter length (see <span class="citation">[@Hastie_2009, Chapter 17]</span>).  While sequence alignment was regarded as a deeply algorithmic and statistical problem in the former volume, it is not at all formulated in the language of machine learning. There is little discussion of cost functions, vector spaces, optimisation, problems of generalization, supervised or unsupervised learning. On the other, David Haussler, a key bioinformatician in the first draft of the human genome in his work explicitly sought to bring machine learning methods to bear on biology, and continues to do so. See <span class="citation">[@Zerbino_2012]</span> for a review of the relevance of machine learning to genomic science. The practical problem here is that genomes contain swathes of duplicated regions that make assembling sequences in good order a severe challenge. While sequence alignment algorithms have long used algorithmic approaches (known as dynamic programming) to score the similarity between two given DNA sequences, assembling the millions of DNA sequences produced by contemporary sequencers has necessitated entirely new techniques (shifting, for instance, from the overlap-layout-consensus model to the de Bruijn graph-based path models <span class="citation">[@Pevzner_2001]</span>.  <a href="genomic-referentiality-and-materiality.html#fnref81">↩</a></p></li>
<li id="fn82"><p>Signal processing is another such domain. Many of the techniques now prominent in machine learning developed in parallel in signal processing, where the encoding and decoding of signals has long been seen as a problem of pattern recognition amenable to statistical calculation. In some specific cases, such as Hidden Markov Models, the same techniques seem to appear almost simultaneously in very disparate domains. Hidden Markov Models appear in genomics (as part of the problem of sequence alignment) at the same time as the begin to appear in digital signal processing for wireless communication and video image compression <span class="citation">[@Mackenzie_2010a]</span> and above all, in speech recognition <span class="citation">[@Rabiner_1989]</span>.  <a href="genomic-referentiality-and-materiality.html#fnref82">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regularizing-and-materializing-objects.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-genome-as-threshold-object.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
