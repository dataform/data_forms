<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Machine Learning: Archaeology of a Data Practice</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Machine Learning: Archaeology of a Data Practice">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Machine Learning: Archaeology of a Data Practice" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Machine Learning: Archaeology of a Data Practice" />
  
  
  

<meta name="author" content="Adrian Mackenzie">


<meta name="date" content="2016-12-10">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="22-the-vectorised-table.html">
<link rel="next" href="24-learning-functions.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="1-acknowledgments.html"><a href="1-acknowledgments.html"><i class="fa fa-check"></i><b>1</b> Acknowledgments</a></li>
<li class="chapter" data-level="2" data-path="2-preface.html"><a href="2-preface.html"><i class="fa fa-check"></i><b>2</b> Preface</a></li>
<li class="chapter" data-level="3" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html"><i class="fa fa-check"></i><b>3</b> Introduction: Into the Data</a><ul>
<li class="chapter" data-level="3.1" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#three-accumulations-settings-data-and-devices"><i class="fa fa-check"></i><b>3.1</b> Three accumulations: settings, data and devices</a></li>
<li class="chapter" data-level="3.2" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#who-or-what-is-a-machine-learner"><i class="fa fa-check"></i><b>3.2</b> Who or what is a machine learner?</a></li>
<li class="chapter" data-level="3.3" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#algorithmic-control-to-the-machine-learners"><i class="fa fa-check"></i><b>3.3</b> Algorithmic control to the machine learners?</a></li>
<li class="chapter" data-level="3.4" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#the-archaeology-of-operations"><i class="fa fa-check"></i><b>3.4</b> The archaeology of operations</a></li>
<li class="chapter" data-level="3.5" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#asymmetries-in-common-knowledge"><i class="fa fa-check"></i><b>3.5</b> Asymmetries in common knowledge</a></li>
<li class="chapter" data-level="3.6" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#what-cannot-be-automated"><i class="fa fa-check"></i><b>3.6</b> What cannot be automated?</a></li>
<li class="chapter" data-level="3.7" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#different-fields-in-machine-learning"><i class="fa fa-check"></i><b>3.7</b> Different fields in machine learning?</a></li>
<li class="chapter" data-level="3.8" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#the-diagram-in-critical-thought"><i class="fa fa-check"></i><b>3.8</b> The diagram in critical thought</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-we-dont-have-to-write-programs.html"><a href="4-we-dont-have-to-write-programs.html"><i class="fa fa-check"></i><b>4</b> ‘We don’t have to write programs’?</a></li>
<li class="chapter" data-level="5" data-path="5-the-elements-of-machine-learning.html"><a href="5-the-elements-of-machine-learning.html"><i class="fa fa-check"></i><b>5</b> The elements of machine learning</a></li>
<li class="chapter" data-level="6" data-path="6-who-reads-machine-learning-textbooks.html"><a href="6-who-reads-machine-learning-textbooks.html"><i class="fa fa-check"></i><b>6</b> Who reads machine learning textbooks?</a></li>
<li class="chapter" data-level="7" data-path="7-r-a-matrix-of-transformations.html"><a href="7-r-a-matrix-of-transformations.html"><i class="fa fa-check"></i><b>7</b> <code>R</code>: a matrix of transformations</a></li>
<li class="chapter" data-level="8" data-path="8-the-obdurate-mathematical-glint-of-machine-learning.html"><a href="8-the-obdurate-mathematical-glint-of-machine-learning.html"><i class="fa fa-check"></i><b>8</b> The obdurate mathematical glint of machine learning</a></li>
<li class="chapter" data-level="9" data-path="9-cs229-2007-returning-again-and-again-to-certain-features.html"><a href="9-cs229-2007-returning-again-and-again-to-certain-features.html"><i class="fa fa-check"></i><b>9</b> CS229, 2007: returning again and again to certain features</a></li>
<li class="chapter" data-level="10" data-path="10-the-visible-learning-of-machine-learning.html"><a href="10-the-visible-learning-of-machine-learning.html"><i class="fa fa-check"></i><b>10</b> The visible learning of machine learning</a></li>
<li class="chapter" data-level="11" data-path="11-the-diagram-of-an-operational-formation.html"><a href="11-the-diagram-of-an-operational-formation.html"><i class="fa fa-check"></i><b>11</b> The diagram of an operational formation</a></li>
<li class="chapter" data-level="12" data-path="12-vectorisation-and-its-consequences.html"><a href="12-vectorisation-and-its-consequences.html"><i class="fa fa-check"></i><b>12</b> Vectorisation and its consequences}</a></li>
<li class="chapter" data-level="13" data-path="13-vector-space-and-geometry.html"><a href="13-vector-space-and-geometry.html"><i class="fa fa-check"></i><b>13</b> Vector space and geometry</a></li>
<li class="chapter" data-level="14" data-path="14-mixing-places.html"><a href="14-mixing-places.html"><i class="fa fa-check"></i><b>14</b> Mixing places</a></li>
<li class="chapter" data-level="15" data-path="15-truth-is-no-longer-in-the-table.html"><a href="15-truth-is-no-longer-in-the-table.html"><i class="fa fa-check"></i><b>15</b> Truth is no longer in the table?</a></li>
<li class="chapter" data-level="16" data-path="16-the-epistopic-fault-line-in-tables.html"><a href="16-the-epistopic-fault-line-in-tables.html"><i class="fa fa-check"></i><b>16</b> The epistopic fault line in tables</a></li>
<li class="chapter" data-level="17" data-path="17-surface-and-depths-the-problem-of-volume-in-data.html"><a href="17-surface-and-depths-the-problem-of-volume-in-data.html"><i class="fa fa-check"></i><b>17</b> Surface and depths: the problem of volume in data</a></li>
<li class="chapter" data-level="18" data-path="18-vector-space-expansion.html"><a href="18-vector-space-expansion.html"><i class="fa fa-check"></i><b>18</b> Vector space expansion</a></li>
<li class="chapter" data-level="19" data-path="19-drawing-lines-in-a-common-space-of-transformation.html"><a href="19-drawing-lines-in-a-common-space-of-transformation.html"><i class="fa fa-check"></i><b>19</b> Drawing lines in a common space of transformation</a></li>
<li class="chapter" data-level="20" data-path="20-implicit-vectorization-in-code-and-infrastructures.html"><a href="20-implicit-vectorization-in-code-and-infrastructures.html"><i class="fa fa-check"></i><b>20</b> Implicit vectorization in code and infrastructures</a></li>
<li class="chapter" data-level="21" data-path="21-lines-traversing-behind-the-light.html"><a href="21-lines-traversing-behind-the-light.html"><i class="fa fa-check"></i><b>21</b> Lines traversing behind the light</a></li>
<li class="chapter" data-level="22" data-path="22-the-vectorised-table.html"><a href="22-the-vectorised-table.html"><i class="fa fa-check"></i><b>22</b> The vectorised table?</a></li>
<li class="chapter" data-level="23" data-path="23-machines-finding-functions.html"><a href="23-machines-finding-functions.html"><i class="fa fa-check"></i><b>23</b> Machines finding functions}</a></li>
<li class="chapter" data-level="24" data-path="24-learning-functions.html"><a href="24-learning-functions.html"><i class="fa fa-check"></i><b>24</b> Learning functions</a></li>
<li class="chapter" data-level="25" data-path="25-supervised-unsupervised-reinforcement-learning-and-functions.html"><a href="25-supervised-unsupervised-reinforcement-learning-and-functions.html"><i class="fa fa-check"></i><b>25</b> Supervised, unsupervised, reinforcement learning and functions</a></li>
<li class="chapter" data-level="26" data-path="26-which-function-operates.html"><a href="26-which-function-operates.html"><i class="fa fa-check"></i><b>26</b> Which function operates?</a></li>
<li class="chapter" data-level="27" data-path="27-what-does-a-function-learn.html"><a href="27-what-does-a-function-learn.html"><i class="fa fa-check"></i><b>27</b> What does a function learn?</a></li>
<li class="chapter" data-level="28" data-path="28-observing-with-curves-the-logistic-function.html"><a href="28-observing-with-curves-the-logistic-function.html"><i class="fa fa-check"></i><b>28</b> Observing with curves: the logistic function</a></li>
<li class="chapter" data-level="29" data-path="29-the-cost-of-curves-in-machine-learning.html"><a href="29-the-cost-of-curves-in-machine-learning.html"><i class="fa fa-check"></i><b>29</b> The cost of curves in machine learning</a></li>
<li class="chapter" data-level="30" data-path="30-curves-and-the-variation-in-models.html"><a href="30-curves-and-the-variation-in-models.html"><i class="fa fa-check"></i><b>30</b> Curves and the variation in models</a></li>
<li class="chapter" data-level="31" data-path="31-observing-costs-losses-and-objectives-through-optimisation.html"><a href="31-observing-costs-losses-and-objectives-through-optimisation.html"><i class="fa fa-check"></i><b>31</b> Observing costs, losses and objectives through optimisation</a></li>
<li class="chapter" data-level="32" data-path="32-gradients-as-partial-observers.html"><a href="32-gradients-as-partial-observers.html"><i class="fa fa-check"></i><b>32</b> Gradients as partial observers</a></li>
<li class="chapter" data-level="33" data-path="33-the-power-to-learn.html"><a href="33-the-power-to-learn.html"><i class="fa fa-check"></i><b>33</b> The power to learn</a></li>
<li class="chapter" data-level="34" data-path="34-probabilisation-and-the-taming-of-machines.html"><a href="34-probabilisation-and-the-taming-of-machines.html"><i class="fa fa-check"></i><b>34</b> Probabilisation and the Taming of Machines}</a></li>
<li class="chapter" data-level="35" data-path="35-data-reduces-uncertainty.html"><a href="35-data-reduces-uncertainty.html"><i class="fa fa-check"></i><b>35</b> Data reduces uncertainty?</a></li>
<li class="chapter" data-level="36" data-path="36-machine-learning-as-statistics-inside-out.html"><a href="36-machine-learning-as-statistics-inside-out.html"><i class="fa fa-check"></i><b>36</b> Machine learning as statistics inside out</a></li>
<li class="chapter" data-level="37" data-path="37-distributed-probabilities.html"><a href="37-distributed-probabilities.html"><i class="fa fa-check"></i><b>37</b> Distributed probabilities</a></li>
<li class="chapter" data-level="38" data-path="38-naive-bayes-and-the-distribution-of-probabilities.html"><a href="38-naive-bayes-and-the-distribution-of-probabilities.html"><i class="fa fa-check"></i><b>38</b> Naive Bayes and the distribution of probabilities</a></li>
<li class="chapter" data-level="39" data-path="39-spam-when-foralln-is-too-much.html"><a href="39-spam-when-foralln-is-too-much.html"><i class="fa fa-check"></i><b>39</b> Spam: when <span class="math inline">\(\forall{N}\)</span> is too much?</a></li>
<li class="chapter" data-level="40" data-path="40-the-improbable-success-of-the-naive-bayes-classifier.html"><a href="40-the-improbable-success-of-the-naive-bayes-classifier.html"><i class="fa fa-check"></i><b>40</b> The improbable success of the Naive Bayes classifier</a></li>
<li class="chapter" data-level="41" data-path="41-ancestral-probabilities-in-documents-inference-and-prediction.html"><a href="41-ancestral-probabilities-in-documents-inference-and-prediction.html"><i class="fa fa-check"></i><b>41</b> Ancestral probabilities in documents: inference and prediction</a></li>
<li class="chapter" data-level="42" data-path="42-statistical-decompositions-bias-variance-and-observed-errors.html"><a href="42-statistical-decompositions-bias-variance-and-observed-errors.html"><i class="fa fa-check"></i><b>42</b> Statistical decompositions: bias, variance and observed errors</a></li>
<li class="chapter" data-level="43" data-path="43-does-machine-learning-construct-a-new-statistical-reality.html"><a href="43-does-machine-learning-construct-a-new-statistical-reality.html"><i class="fa fa-check"></i><b>43</b> Does machine learning construct a new statistical reality?</a></li>
<li class="chapter" data-level="44" data-path="44-patterns-and-differences.html"><a href="44-patterns-and-differences.html"><i class="fa fa-check"></i><b>44</b> Patterns and differences</a></li>
<li class="chapter" data-level="45" data-path="45-splitting-and-the-growth-of-trees.html"><a href="45-splitting-and-the-growth-of-trees.html"><i class="fa fa-check"></i><b>45</b> Splitting and the growth of trees</a></li>
<li class="chapter" data-level="46" data-path="46-differences-in-recursive-partitioning.html"><a href="46-differences-in-recursive-partitioning.html"><i class="fa fa-check"></i><b>46</b> 1984: Differences in recursive partitioning</a></li>
<li class="chapter" data-level="47" data-path="47-limiting-differences.html"><a href="47-limiting-differences.html"><i class="fa fa-check"></i><b>47</b> Limiting differences</a></li>
<li class="chapter" data-level="48" data-path="48-the-successful-dispersion-of-the-support-vector-machine.html"><a href="48-the-successful-dispersion-of-the-support-vector-machine.html"><i class="fa fa-check"></i><b>48</b> The successful dispersion of the support vector machine</a></li>
<li class="chapter" data-level="49" data-path="49-differences-blur.html"><a href="49-differences-blur.html"><i class="fa fa-check"></i><b>49</b> Differences blur?</a></li>
<li class="chapter" data-level="50" data-path="50-bending-the-decision-boundary.html"><a href="50-bending-the-decision-boundary.html"><i class="fa fa-check"></i><b>50</b> Bending the decision boundary</a></li>
<li class="chapter" data-level="51" data-path="51-instituting-patterns.html"><a href="51-instituting-patterns.html"><i class="fa fa-check"></i><b>51</b> Instituting patterns</a></li>
<li class="chapter" data-level="52" data-path="52-regularizing-and-materializing-objects.html"><a href="52-regularizing-and-materializing-objects.html"><i class="fa fa-check"></i><b>52</b> Regularizing and materializing objects}</a></li>
<li class="chapter" data-level="53" data-path="53-genomic-referentiality-and-materiality.html"><a href="53-genomic-referentiality-and-materiality.html"><i class="fa fa-check"></i><b>53</b> Genomic referentiality and materiality</a></li>
<li class="chapter" data-level="54" data-path="54-the-genome-as-threshold-object.html"><a href="54-the-genome-as-threshold-object.html"><i class="fa fa-check"></i><b>54</b> The genome as threshold object</a></li>
<li class="chapter" data-level="55" data-path="55-genomic-knowledges-and-their-datasets.html"><a href="55-genomic-knowledges-and-their-datasets.html"><i class="fa fa-check"></i><b>55</b> Genomic knowledges and their datasets</a></li>
<li class="chapter" data-level="56" data-path="56-the-advent-of-wide-dirty-and-mixed-data.html"><a href="56-the-advent-of-wide-dirty-and-mixed-data.html"><i class="fa fa-check"></i><b>56</b> The advent of ‘wide, dirty and mixed’ data</a></li>
<li class="chapter" data-level="57" data-path="57-cross-validating-machine-learning-in-genomics.html"><a href="57-cross-validating-machine-learning-in-genomics.html"><i class="fa fa-check"></i><b>57</b> Cross-validating machine learning in genomics</a></li>
<li class="chapter" data-level="58" data-path="58-proliferation-of-discoveries.html"><a href="58-proliferation-of-discoveries.html"><i class="fa fa-check"></i><b>58</b> Proliferation of discoveries</a></li>
<li class="chapter" data-level="59" data-path="59-variations-in-the-object-or-in-the-machine-learner.html"><a href="59-variations-in-the-object-or-in-the-machine-learner.html"><i class="fa fa-check"></i><b>59</b> Variations in the object or in the machine learner?</a></li>
<li class="chapter" data-level="60" data-path="60-whole-genome-functions.html"><a href="60-whole-genome-functions.html"><i class="fa fa-check"></i><b>60</b> Whole genome functions</a></li>
<li class="chapter" data-level="61" data-path="61-propagating-subject-positions.html"><a href="61-propagating-subject-positions.html"><i class="fa fa-check"></i><b>61</b> Propagating subject positions}</a></li>
<li class="chapter" data-level="62" data-path="62-propagation-across-human-machine-boundaries.html"><a href="62-propagation-across-human-machine-boundaries.html"><i class="fa fa-check"></i><b>62</b> Propagation across human-machine boundaries</a></li>
<li class="chapter" data-level="63" data-path="63-competitive-positioning.html"><a href="63-competitive-positioning.html"><i class="fa fa-check"></i><b>63</b> Competitive positioning</a></li>
<li class="chapter" data-level="64" data-path="64-a-privileged-machine-and-its-diagrammatic-forms.html"><a href="64-a-privileged-machine-and-its-diagrammatic-forms.html"><i class="fa fa-check"></i><b>64</b> A privileged machine and its diagrammatic forms</a></li>
<li class="chapter" data-level="65" data-path="65-varying-subject-positions-in-code.html"><a href="65-varying-subject-positions-in-code.html"><i class="fa fa-check"></i><b>65</b> Varying subject positions in code</a></li>
<li class="chapter" data-level="66" data-path="66-the-subjects-of-a-hidden-operation.html"><a href="66-the-subjects-of-a-hidden-operation.html"><i class="fa fa-check"></i><b>66</b> The subjects of a hidden operation</a></li>
<li class="chapter" data-level="67" data-path="67-algorithms-that-propagate-errors.html"><a href="67-algorithms-that-propagate-errors.html"><i class="fa fa-check"></i><b>67</b> Algorithms that propagate errors</a></li>
<li class="chapter" data-level="68" data-path="68-competitions-as-examination.html"><a href="68-competitions-as-examination.html"><i class="fa fa-check"></i><b>68</b> Competitions as examination</a></li>
<li class="chapter" data-level="69" data-path="69-superimposing-power-and-knowledge.html"><a href="69-superimposing-power-and-knowledge.html"><i class="fa fa-check"></i><b>69</b> Superimposing power and knowledge</a></li>
<li class="chapter" data-level="70" data-path="70-ranked-subject-positions.html"><a href="70-ranked-subject-positions.html"><i class="fa fa-check"></i><b>70</b> Ranked subject positions</a></li>
<li class="chapter" data-level="71" data-path="71-conclusion-out-of-the-data.html"><a href="71-conclusion-out-of-the-data.html"><i class="fa fa-check"></i><b>71</b> Conclusion: Out of the Data}</a></li>
<li class="chapter" data-level="72" data-path="72-machine-learners.html"><a href="72-machine-learners.html"><i class="fa fa-check"></i><b>72</b> 250,000 machine learners</a></li>
<li class="chapter" data-level="73" data-path="73-a-summary-of-the-argument.html"><a href="73-a-summary-of-the-argument.html"><i class="fa fa-check"></i><b>73</b> A summary of the argument</a></li>
<li class="chapter" data-level="74" data-path="74-in-situ-hybridization.html"><a href="74-in-situ-hybridization.html"><i class="fa fa-check"></i><b>74</b> In-situ hybridization</a></li>
<li class="chapter" data-level="75" data-path="75-critical-operational-practice.html"><a href="75-critical-operational-practice.html"><i class="fa fa-check"></i><b>75</b> Critical operational practice?</a></li>
<li class="chapter" data-level="76" data-path="76-obstacles-to-the-work-of-freeing-machine-learning.html"><a href="76-obstacles-to-the-work-of-freeing-machine-learning.html"><i class="fa fa-check"></i><b>76</b> Obstacles to the work of freeing machine learning</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning: Archaeology of a Data Practice</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machines-finding-functions" class="section level1">
<h1><span class="header-section-number">23</span> Machines finding functions}</h1>
<p></p>
<blockquote>
<p>Because of a gradient that no doubt characterizes our cultures, discursive formations are constantly becoming epistemologized <span class="citation">[@Foucault_1972, 195]</span> </p>
</blockquote>
<p>‘All knowledge,’ hypothesises Pedro Domingos, ‘past, present,and future can be derived from data by a single, universal learning algorithm’ <span class="citation">[@Domingos_2015a, 25]</span>.   How will the ‘single, universal’ algorithm learn, how will it ‘epistemologize,’ to use Foucault’s term, ‘our cultures’?</p>
<p>In practice, the opening pages of machine learning textbooks often warn or enthuse about the profusion of techniques, algorithms, tools and machines.  ‘The first problem facing you’, cautions Domingos readers of the <em>Communications of the ACM</em>, ‘is the bewildering variety of learning algorithms available. Which one to use? There are literally thousands available, and hundreds more are published each year <span class="citation">[@Domingos_2012, 1]</span>.  ’The literature on machine learning is vast, as is the overlap with the relevant areas of statistics and engineering’ echoes David Barber in <em>Bayesian Reasoning and Machine Learning</em><span class="citation">[@Barber_2011,4]</span>; ‘statistical learning refers to a vast set of tools for understanding data’ writes James and co-authors in an <em>Introduction to Statistical Learning with R</em> <span class="citation">[@James_2013,1]</span>; or writing in in <em>Statistical Learning for Biomedical Data</em> the biostatisticians James Malley, Karen Malley and Sinisa Pajevic ‘freely admit that many machines studied in this text are somewhat mysterious, though powerful engines’ <span class="citation">[@Malley_2011, 257]</span>. In <em>Thoughtful Machine Learning</em> Matthew Kirk exacerbates the situation: ‘flexibility is also what makes machine learning daunting. It can solve many problems, but how do we know whether we’re solving the right problem, or actually solving it in the first place?’ <span class="citation">[@Kirk_2014, ix]</span>.  The prefatory comments from Domingos, Barber, James, Malley and Kirk suggest a rampant even weed-like abundance of machine learners, as does the 700 or so pages of <em>Elements of Statistical Learning</em>. Much learning of machine learning work, at least for machine learners, concerns not so much implementation of particular techniques (neural network, decision tree, support vector machine, logistic regression, etc.), but rather navigating the maze of methods and variations that might be relevant to a particular situation.  How does this dual effect of profuse accumulation and the ideal a single, universal machine learner arise and hold together?</p>

<p></p>
<p>The machine learners I have just cited present that profusion as a problem of the piling up of techniques. As the authors of textbooks and how-to-manuals, they attempt to manage it by providing, indexes, maps and guides to the bewildering variety of machine learners. <em>Elements of Statistical Learning</em> deploys tables, overviews, theories of statistical modelling, model assessment and comparison techniques to aid in navigating them.</p>
<p>Parallel and complementary mappings accompany software libraries. The visual map of machine learning techniques shown in Figure  comes from a machine learning library written in <code>Python,</code> <code>scikit-learn</code> <span class="citation">[@Pedregosa_2011]</span>.  This software library is widely used in industry, research and commerce. In contrast to the pedagogical expositions, theoretical accounts or guides to reference implementation, or the many overlapping packages in <code>R</code>, code libraries such as <code>scikit-learn</code> order the range of techniques by offering recipes and maps for the use of the <em>functions</em> the libraries supply.  The branches in the figure lay down paths through the profusion of techniques as a decision tree.<a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a>  </p>
<p>The architecture of software libraries itself classifies and orders machine learners. <code>Scikit-learn</code> for instance comprises a number of sub-packages. Modules such as <code>lda</code> (linear discriminant analysis), <code>svm</code> (support vector machine) or <code>neighbors</code> (<em>k</em> nearest neighbours) point to well-known machine learners, whilst <code>cross-validation</code> or <code>feature_selection</code> refer to ways of testing models or transforming data respectively. These divisions, maps and classifications help order the techniques, but they obscure the process that first generates a competing profusion of machine learners.</p>
<p>If, as I have suggested earlier, we understand knowledge in terms of the radically re-conceptualised statements that Foucault described in <em>The Archaeology of Knowledge</em>, then statements comprise various units (sentences, series, tables, propositions, diagrams, equations, numbers) mapped to a field of objects, subject positions and domains of coordinations and reuse by an enunciative function <span class="citation">[@Foucault_1972, 106]</span>. Confronted by a profusion of machine learners and the idea of a single, universal machine learning, an archaeological analysis attends to the enunciative function that multiplies meanings and operations.</p>
<p>We might understand the enunciative function  as the generative process that proliferates machine learners. The listing and mapping of accumulated techniques, whether in the form of textbooks such as <em>Elements of Statistical Learning</em> or a code library such as <code>scikit-learn</code>, together with the many attempts to unify them (Domingo’s ‘single, universal algorithm’, <code>scikit-learn</code>‘s map, <em>Elements of Statistical Learning</em>’s statistical theory) suggests a commonality in the production of statements. As I will argue in this chapter, there are so many techniques, algorithms and ways of deriving knowledge from data in machine learning because statements are actually rare in this operational formation. ’Because statements are rare,’ writes Foucault, ‘they are collected in unifying totalities, and the meanings to be found in them are multiplied’ <span class="citation">[@Foucault_1972, 120]</span>. </p>
</div>
<div class="footnotes">
<hr />
<ol start="33">
<li id="fn33"><p>Similarly, for <code>R</code> code, the <em>Comprehensive R Archive Network</em> tabulates key libraries of <code>R</code> code in a machine learning ‘task view’ <span class="citation">[@Hothorn_2014]</span>. <a href="23-machines-finding-functions.html#fnref33">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="22-the-vectorised-table.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="24-learning-functions.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
