# Conclusion: Out of the Data

## overview

 - how many things I couldn't include in the book
 - what it felt to write it -- working with all the code and various other problems
 - how it remained a kind of handicraft, not a social labour

## todo
- overview of the parts, and the chapters
- the media-science-government
- I use media as shorthand for media in general: they are things or infrastructures, which are also things, and things are media (Lash & Lury)


## text from proposal

The conclusion draws together the main threads running through the previous chapter, and sets out a series of questions and provocations for thinking with data. Crucially, the conclusion will stand back from the much more hands-on approach to data and data practice adopted in the preceding chapters in order to think more about we -- social scientists, humanities scholars -- might invent or create in the midst of data. While this book has a critical angle to it (so many claims about and beliefs in data plainly deserve critique for their conservative and naive approach to things), it is principally concerned with conceptual invention through doing things with data. The work of learning about machine learning, and learning about it in a way that is deeply embodied or practically embodied, brings with it altered ways of thinking about, questioning and integrating what is happening to data more generally. It highlights the key argument that has run through the book about the plural dimensionality of data as it is aggregated, tabulated, summarised and modelled in contemporary data and signal processes, and as well as the extraordinary mobility or kinetic energy of generic machine learning methods. In discussing the shifting dimensionality of data, and the kinetics of methods, the conclusion will attempt to sketch out how some promising ways of thinking with data might proceed. 

## What is 'into the data' about?

This book has sought to provide an account of several dozen techniques, algorithms and procedures that run deeply through contemporary sciences, government, media and business. Many tensions and forces run through these techniques since they are said to be crucial to knowledge, to value and to power. The account offered in the preceding pages has not sought to list or delineate the plurality of applications, setting, implementations and variations in machine learning operates. Typically, humanities and social science research does focus on specific cases, and sometimes a list of cases, and it usually offers these cases as examplars, as a kind of training set that can be used for the purpose of generalization. The neural networks, the support vector machines, the linear regressions, the random forests and Naive Bayes classifiers are multiplying and generalizing. The several hundred thousand scientific articles that run underneath my discussion embody the process of generalizing the techniques, and these articles are no doubt only a limited institutional sample of the effervescing foam that bears these techniques further into everyday infrastructures of media, energy, government, commerce and manufacture. (The great virtue of scientific publication, even in a time where science is so bound up with technoscientific  enterprises, remains in the visibility its publications afford.) The point here, however, is that such lists of applications and implementations would be both symptomatic and inadequate in accounting for the movement of these techniques, perhaps in the same way that a list of recommended products on Amazon.com's website both 

When we think of data as a 

# Is there any hope for machine learning?
### What to do

-  Three observations then about the significance of machine learning:
	-  its ubiquity in science, business and government renders it a key contemporary control practice, that differs in powerful yet subtle ways from existing ways of knowing, predicting, anticipating or controlling
	- its mobility as a cluster of methods has strongly performative effects -- parts of the world are heavily re-configured through it, whether in the banal forms of intelligence apparent in smart devices (text prediction, gesture recognition, voice recognition, etc), or in the financial torsions induced by algorithmic trading. 
	- the mobility of its methods has no clear boundaries. The spread of machine learning into social sciences and humanities has started. Much of our research already implicitly depends on it (google search, etc). The question is how we move in relation to machine learning. It could be the cultural analytics route as propounded by Lev Manovich and others in the digital humanities; it could be the big data computational social science of US political scientists such as Gary King; or it could be more like the abundant hackathons that try to repurpose adn reinvest data with meaning or insights for the benefit of NGOs and charities. 
		
- Machine learning is a hard field to get into in some ways for social science and humanities researchers. There are lots of statistical, mathematical and infrastructural subleties to deal with. On the one hand, it is becoming enormously available and increasingly as Thrift would say, part of the contemporary time-space signature. Myriad mundane examples could be given. On the other hand, to get into it, to occupy the fluxing dimensionality of the data is  technically difficult, and conceptually challenging and sometimes boring. It takes very significant investments in time and attention (for instance, going through 27 hours of Youtube lectures with lots of equations written on blackboards is not trivial). 

- But I am suggesting that getting into it analytically and practically by whatever might be worthwhile, at least for some people for several reasons:
1. It offers  a way of accompanying the fluxing dimensionality of data. In _Modes of Thought_, Alfred North Whitehead writes:

>Perhaps our knowledge is distorted unless we can comprehend its essential connection with happenings which involve spatial relationships of fifteen dimensions [@whitehead_modes_1958, 78]
		

In this passage, Whitehead's choice of 15 is arbitrary. I guess it just refers to a spatiality that it is hard for to imagine, even though we no doubt inhabit it from time. From the standpoint of machine learning, we often do move through high dimensional spaces. Many machine learning techniques seek to reduce the dimensionality of spatial relationships in data. These would include the many dimensional reduction strategies. But others seek to expand the dimensionality of data. And the feild as a whole tends to augment rather than diminish data dimensionality. Certain techniques artificially inject infinite dimensional spaces into the models in order to find hyperplanes that separate data. 
	
2. Like all sciences and technologies, machine learning must contain zones of slippage, inconsistency or friction where things can happen. While it might not be us as researchers who occupy or can identify those zones most easily, in making sense of machine learning all the way down, and pointing to the structures, processes or relations at play, we help free up the possibilities of gaming the models. And actually, who else is going to do it? That is, machine learning provides a way to contest the asymmetrical distributions of agency admidst re-dimensioned infrastructures.  

3. To some extent, as researchers we are encountering a version of the quandary I posed at the outset: what happens if you have all the data? The question is how we are going to comprehend 15D happenings, especially when a good number of those dimensions are occluded from us.  A couple of scenarios occur to me here:

- using machine learning to impute what kind of machine learning is going on in a given setting - these could involve either labelling what techniques are likely being used, or actively experimenting with ways of perturbing the model (as for instance, the many machine learning-based attempts to do search engine optimizination do). 'Gaming the model' means figuring out how it is likely to work, and then using that to perturb it. 
- using machine learning techniques as a way of thinking about differences, movement, shape and change

4. Bowker and Star suggested that we needed a kind of science to deal with classification systems: 

> The sheer density of the collisions of classification schemes in our lives calls for a new kind of science, a new set of metaphors, linking traditional social science and computer and information science. We need a topography of things such as the distribution of ambiguity.  ...  It will also use the best of object-oriented programming and other areas of computer science to describe this territory. [@Bowker_1999, 31]



## Is there any hope for machine learning?


