Conclusion: Out of the Data
===========================

## overview

 - how many things I couldn't include in the book
 - what it felt to write it -- working with all the code and various other problems
 - how it remained a kind of handicraft, not a social labour

## todo
- what if this book was a model -- what kind of model would it be
- overview of the parts, and the chapters
- the media-science-government
- I use media as shorthand for media in general: they are things or infrastructures, which are also things, and things are media (Lash & Lury)
- why I haven't done critique of surveillance, etc? Or of the hype?
- what does it add to have this concrete account of abstraction?
- what does it add to have followed some of the infrastructures, implementations, etc 
- what happened to the affective/psychoanalytic/movement in thought?
- the praxiography -- writing code as practice that allows something about movement to be contoured and perhaps countered. 


## text from proposal

The conclusion draws together the main threads running through the previous chapter, and sets out a series of questions and provocations for thinking with data. Crucially, the conclusion will stand back from the much more hands-on approach to data and data practice adopted in the preceding chapters in order to think more about we -- social scientists, humanities scholars -- might invent or create in the midst of data. While this book has a critical angle to it (so many claims about and beliefs in data plainly deserve critique for their conservative and naive approach to things), it is principally concerned with conceptual invention through doing things with data. The work of learning about machine learning, and learning about it in a way that is deeply embodied or practically embodied, brings with it altered ways of thinking about, questioning and integrating what is happening to data more generally. It highlights the key argument that has run through the book about the plural dimensionality of data as it is aggregated, tabulated, summarised and modelled in contemporary data and signal processes, and as well as the extraordinary mobility or kinetic energy of generic machine learning methods. In discussing the shifting dimensionality of data, and the kinetics of methods, the conclusion will attempt to sketch out how some promising ways of thinking with data might proceed. 

## If this book were a predictive model, what would it predict?

Could a book function as a predictive model, or as a classifier? The problem with machine learning in general is that it is often quite predictable. I can say this now, after a couple of hundred pages of writing on machine learning, most of which has suggested the need to look to such techniques as ways of making sense of contemporary forms of knowledge, power, value and experience, without denigrating it too much. The level of imitation, duplications, copying and reproduction associated with the techniques is rather striking. (For instance, in Chapter 4, we saw how Naive Bayes classifiers are almost demonstrated on spam classification problems.) The scientific and engineering literature, with its really frequent variations on similar themes, suggests that imitation and copying are very much  at the heart of the movements I have been describing. But machine learning is not entirely predictable. The advent of specific techniques (support vector machine, neural network, decision tree, random forest, logistic regression or expectation maximization, MCMC) are not entirely unanticipated, but in themselves they are not direct imitations. [HERE]
## What is 'into the data' about?

This book has sought to provide an account of several dozen techniques, algorithms and procedures that run deeply through contemporary sciences, government, media and business. Many tensions and forces run through these techniques since they are said to be crucial to knowledge, to value and to power. The account offered in the preceding pages has not sought to list or delineate the plurality of applications, setting, implementations and variations in machine learning operates. Typically, humanities and social science research does focus on specific cases, and sometimes a list of cases, and it usually offers these cases as examplars, as a kind of training set that can be used for the purpose of generalization. The neural networks, the support vector machines, the linear regressions, the random forests and Naive Bayes classifiers are multiplying and generalizing. The several hundred thousand scientific articles that run underneath my discussion embody the process of generalizing the techniques. They constitute a dynamic substrate on which the techniques multiply and reproduce. These articles are no doubt only a limited institutional sample of the effervescing foam that bears these techniques further into everyday infrastructures of media, energy, government, commerce and manufacture. (The great virtue of scientific publication, even in a time where science is so bound up with technoscientific  enterprises, remains in the visibility its publications afford.) The point here, however, is that such lists of applications and implementations would be both symptomatic and inadequate in accounting for the movement of these techniques, perhaps in the same way that a list of recommended products on Amazon.com's website both evokes associations and also covers over the ways in which recommendations come about.

When we think of data as a place (a _topos_) or as a corpus (a body), then  machine learning techniques either constitute forms of movement that recognise patterns and associations, and that attribute classifications through dividing or clustering. The three main modes of this movement -- drawing lines through high-dimensional clouds of points, finding rules that divide and separate mixtures of features, or alternately, constructing models that generate the data using shaped flows of random numbers  -- entwine with each other over time. They make a tangled bank of techniques that ramble over many different slopes and surfaces.  These forms of movement together  comprise a moving substratum of techniques on which other forms of organization, scientific, economic, cultural and political life take root. The techniques are generative, I have suggested, of unfamiliar forms, patterns and associations. What they generate, however, may not be easily recognisable because they are not operating entirely within existing allocations or distributions of power.
The indications of these generative processes are legion. Amongst the mundane ones are simply the re-shaping of datasets, from the few columns and hundreds of rows of Fisher's `iris` dataset to the hundreds of millions or billions of rows found in contemporary datasets. If for Fisher, measurements of an iris sepal and an iris petal in a field yielded data that would pose challenging classification problems, today it is more likely that a million digital camera images of irises would be the dataset that a classifier algorithm would have to move through. The much-discussed changes in the extent of data do not tell us much about the forms of movement that accompany and arguably propel the re-scaling. The virtualization of computational processes in cloud computing, the increasingly parallel architectures of data processing, the expansive and accommodating options for storage of data in almost any form: many of these development bear the traces of the machine learning techniques, and the vectorised spaces they rely on. The ongoing transformation of digital infrastructures and perhaps the way in which they are taking shape increasingly as data processes stems from the techniques and the movements they impel. Numbers, words, images and things have long been arranged in tables, but the forms of order now running across those tables are no longer the comparisons and contrasts of the classical tabulations found in the early modern Europe, nor the statistical tabulations that accompany the growth of the nation-states or the accounting tables that accompany the rise of corporations in the nineteenth century, or even the lists, tables and arrays that routed flows of information and signals during the electronic age with its media. While arrays have grown in size, the actual number of rows is less important than the ways in which machine learning techniques traverse them as pluri-dimensional manifolds. They make 'inner products.'
## Is there any hope for machine learning?
Back in an earlier chapter, I posed the question: by unwinding some of the convoluted multiplications that generate contemporary multiples do we get closer to the concrete value-situations (the term is A.N. Whitehead's) that connect value and feeling? The question here, and I find it troubling, is whether it really makes sense to treat experience literally as a topological space of transformations (as [@Massumi_2002, 184] suggests we might, and whether those transformations occur in the realm of the techniques we have been discussing. At various points in the preceding pages, various types of transformation have been described. These transformations, sometimes written in the form of mathematics, sometimes written in `python` or `R` code or shown in data graphics, have been very typical ones. They mostly project numbers into high-dimensional vector-spaces, and then  move through those spaces along lines or across surfaces defined by mappings or functions such as probability distributions, such as metrics of similarity or purity, or optimisation procedures such as gradient descent or least squares.
No matter matter how inventive, unexpected or indeed predictable these forms of movement might be, the question remains how they intersect or encounter the affectively charged encounters with others, with things, with authority, with sensation, with authority, with experts, with knowledge, with decisions or with violence. The powerful movements of the techniques through data renders them the province of science, corporations, media platforms and  governments. But the fact that they can be written and practiced, even in close proximity to the relatively infrastructurally-disconnected form of a book suggests that their movement is not limited to or confined to the power-laden scenes of many of their contemporary usages. The fact  that the USA's  National Security Agency can handle so many phone calls and internet traffic in its data centres by use of machine learning [@Hickins, 2013] should not deflect attention away from the many mundane appearances of machine learning in the world. The existence of `kittydar`, the cat face recognition demonstration, is not easily dismissed. In short, the increasingly praxiographic mode of existence of these techniques potentially generates more diverse forms of relationality in the same way that the working-through of symptoms can work in therapeutic settings to reactivate forgotten or excluded possibilities. [HERE]
When we glimpse something of the infrastructural contortions occasioned by, for instance, the need to produce inner products (matrix multiplication) on a large scale, then the ## What to do Three observations then about the significance of machine learning: -  its ubiquity in science, business and government renders it a key contemporary control practice, that differs in powerful yet subtle ways from existing ways of knowing, predicting, anticipating or controlling - its mobility as a cluster of methods has strongly performative effects -- parts of the world are heavily re-configured through it, whether in the banal forms of intelligence apparent in smart devices (text prediction, gesture recognition, voice recognition, etc), or in the financial torsions induced by algorithmic trading. - the mobility of its methods has no clear boundaries. The spread of machine learning into social sciences and humanities has started. Much of our research already implicitly depends on it (google search, etc). The question is how we move in relation to machine learning. It could be the cultural analytics route as propounded by Lev Manovich and others in the digital humanities; it could be the big data computational social science of US political scientists such as Gary King; or it could be more like the abundant hackathons that try to repurpose adn reinvest data with meaning or insights for the benefit of NGOs and charities. - Machine learning is a hard field to get into in some ways for social science and humanities researchers. There are lots of statistical, mathematical and infrastructural subleties to deal with. On the one hand, it is becoming enormously available and increasingly as Thrift would say, part of the contemporary time-space signature. Myriad mundane examples could be given. On the other hand, to get into it, to occupy the fluxing dimensionality of the data is  technically difficult, and conceptually challenging and sometimes boring. It takes very significant investments in time and attention (for instance, going through 27 hours of Youtube lectures with lots of equations written on blackboards is not trivial). - But I am suggesting that getting into it analytically and practically by whatever might be worthwhile, at least for some people for several reasons: 1. It offers  a way of accompanying the fluxing dimensionality of data. In _Modes of Thought_, Alfred North Whitehead writes: >Perhaps our knowledge is distorted unless we can comprehend its essential connection with happenings which involve spatial relationships of fifteen dimensions [@whitehead_modes_1958, 78] In this passage, Whitehead's choice of 15 is arbitrary. I guess it just refers to a spatiality that it is hard for to imagine, even though we no doubt inhabit it from time. From the standpoint of machine learning, we often do move through high dimensional spaces. Many machine learning techniques seek to reduce the dimensionality of spatial relationships in data. These would include the many dimensional reduction strategies. But others seek to expand the dimensionality of data. And the feild as a whole tends to augment rather than diminish data dimensionality. Certain techniques artificially inject infinite dimensional spaces into the models in order to find hyperplanes that separate data. 2. Like all sciences and technologies, machine learning must contain zones of slippage, inconsistency or friction where things can happen. While it might not be us as researchers who occupy or can identify those zones most easily, in making sense of machine learning all the way down, and pointing to the structures, processes or relations at play, we help free up the possibilities of gaming the models. And actually, who else is going to do it? That is, machine learning provides a way to contest the asymmetrical distributions of agency admidst re-dimensioned infrastructures.  
3. To some extent, as researchers we are encountering a version of the quandary I posed at the outset: what happens if you have all the data? The question is how we are going to comprehend 15D happenings, especially when a good number of those dimensions are occluded from us.  A couple of scenarios occur to me here:

- using machine learning to impute what kind of machine learning is going on in a given setting - these could involve either labelling what techniques are likely being used, or actively experimenting with ways of perturbing the model (as for instance, the many machine learning-based attempts to do search engine optimizination do). 'Gaming the model' means figuring out how it is likely to work, and then using that to perturb it. 
- using machine learning techniques as a way of thinking about differences, movement, shape and change

4. Bowker and Star suggested that we needed a kind of science to deal with classification systems: 

> The sheer density of the collisions of classification schemes in our lives calls for a new kind of science, a new set of metaphors, linking traditional social science and computer and information science. We need a topography of things such as the distribution of ambiguity.  ...  It will also use the best of object-oriented programming and other areas of computer science to describe this territory. [@Bowker_1999, 31]






