
\chapter{Conclusion: Out of the Data}
\label{ch:conclusion}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  results='hide', warning=FALSE, message=FALSE, dev='pdf')

library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
library(ggplot2)
library(stringr)
library(xtable)
options(xtable.comment = FALSE)
simpleCap <- function(x) {
    s <- strsplit(x, " |-")[[1]]
    return (paste(toupper(substring(s, 1,1)), tolower(substring(s, 2)), sep="", collapse=" "))
  }
```
> `These diagrams of the diagrammatic domains,  they kernel together in localization. `

> `In this contrusion of major forms of invention in natures in machine learning techniques, inter-places, leveraged in and distributed.`

I began this book with a question: if machine learning is transforming the production of knowledge, might the practice of critical thought itself change, whether in its empirical or theoretical dimensions? The sentences above are the products of a generative model \index{model!generative} trained on the raw text of this book. Without any model of syntax, any dictionary of words or terms, relying purely on character sequences as probability distributions, the neural network that sampled these sentences out of its own unsupervised model of the book vectorised as data was primed with starting text of '`If `.' \index{machine learner!neural network} 'Diagrams of the diagrammatic domains,' kernelling together in localization, a 'contrusion' of major forms of invention in natures, in machine learning techniques, leveraged in and distributed in inter-places: all of that has been put quite well by the generative model, a two-layer 'long short term memory' neural net [@Karpathy_2016].  

If a book could be a machine learner or a generative model, then I hope this one might generate or multiply the range of practices it observes in the worlds of data. In such a model, a model that would learn machine learning in order to diagram a diagrammatic domain, the predictions would figure less as statements that rank, order and classify, than as a technology of critical thought, a means of effecting a certain number of transformative operations on one's own conduct, thinking and ways of being in order to attain some state of critical understanding. 

Affective elements have a long-standing connection with computation.  Elizabeth Wilson's study, _Affect and Artificial Intelligence_ [@Wilson_2010], draws on a combination of psychoanalytic, psychological and archival materials discussing the work of key figures in the early history of artificial intelligence such as Alan Turing on intelligent machinery,  Warren McCulloch and Walter Pitts on neural nets, and recent examples of affective computing and robots such as the MIT robot Kismet. \index{Wilson, Elizabeth!on artificial intelligence} Her framing of the psychic nexus with machines such as the perceptron is provocative:
    
    > Sometimes machines are the very means by which we can stay alive psychically, and they can  just as readily be a means for affective expansion and amplification as for affective attenuation. This is especially the case of computational machines [@Wilson_2010, 30].

Under what conditions do machines and for present purposes, computational machines, become 'the very means we can stay alive psychically'? Wilson  addresses this question by positing 'some kind of intrinsic affinity, some kind of intuitive alliance between the machinic and the affective, between calculation and feeling' (31), and suggesting that the 'one of the most important challenges will be to operationalize affectivity in ways that facilitate pathways of introjection between humans and machines' (31). \index{operational formation!affect in} Introjection, the process of bringing the world within self is, according to psychoanalytic accounts of subjectivity, crucial to the formation of 'a stable subject position' (25). Wilson envisages introjection of machine processes as a good, not as a failure or attenuation of relation to the world. While I tend to go in the same direction as Wilson in relation to affective expansion, I don't tend to see that expansion as unfolding from introjection, but rather from an intensification of diagrammatic processes. \index{diagram!affect of}

The work of at least 230,800 human machine learners (the number of unique authors listed in the corpus of machine learning research literature I have been drawing on)\index{machine learner!number of}, a new kind of operational formation jells in machine learning. People and things, knowledge and power, combine in novel forms. Understanding the distribution and production of elements that make up this emerging common space of decision, classification, prediction and anticipation matters contemporary critical thought in its engagement with power, production, conduct, communication, ways of being and thinking, materiality and experience.

Let us take 146,000 scientific articles, publications and books as statements concerning operations occurring in a variety of sites, modes, and settings connected in the operational formation we are discussing.\index{operational formation}. In contrast to Foucault's discursive formations, operational formations function  less by reference to the statements of a subject (the expert, the engineer, the doctor, the patient, the judge, the teacher, the student), and with greater reference to the statements generated in a human-machine interaction (for instance, the sentences generated by the RNN model above). The machine-human mixing in operational formations is highly variable, dynamic and mutable, sometimes planing through code, sometimes diagrammed in visible forms such as graphs and tables, and often ramifying through infrastructures. \index{statement!human-machine}.  

## Summary of the argument

Let me resume the argument of the book, an argument that comprising seven major facets or planes. In chapter \ref{ch:diagram}, I suggested that we should consider both the formal, mathematical abstraction  and certain transformations in the production of software associated with machine learning as diagrammatic processes that organise and assemble human-machine relations \index{human-machine relations}  amidst a great accumulation of statements, figures, techniques, constructs, datasets and code implementations derived from many settings. The positivity \index{positivity} of machine learning, its specific forms of accumulation, regularity and rarety do not attest to the power of algorithms but rather lend  liveliness to the field by concentrating expressions from many regions. 

Chapter \ref{ch:vector} examined the practices of vectorising data, situating machine learners themselves in an organised, dimensioned space accommodating an increasing repertoire of movements and transformations operating on vectors. Vectorisation subsumes many differences in data. It is a practice of working with data \index{vectorisation} to accommodate all differences within an expanding dimensional space, a space in which data is under the strain of smooth surfaces, straight lines, regular curves and hyper-planes. \index{data!strain} Both in terms of infrastructure and epistemic cultures, the vector space vectorises abstractions and concretisation \index{abstraction!see concretisation}, and affords an augmentation and idealisation of spaces inside data. NEED MORE HERE.

What happens to control in machine learning? If information and computation can be understood as responding to a crisis in control, what do machine learners do? In chapter \ref{ch:function}, we discussed how learning might be understood as an experimental process that relays between operation and observation in optimising functions that predict and classify.  Viewed as an experimental relay, optimisation includes partial observers. NEED MORE HERE

An important and wide-reaching critical strand of work in humanities and social sciences over the last few decades has focused on populations, collectives, knowledge and power. Having all the data, chapter \ref{ch:probability} suggested, is not the principal stake in contemporary data cultures. Instead, the probabilisation \index{probabilisation} of both data and machine learners in populations suggests some of the axes of power-knowledge developing in machine learning. 

What happens to differences amidst vectorisation, learning as optimisation, probabilisation and the generalized diagrammatic abstraction of machine learning? \index{differences}. Treated  as pattern, chapter \ref{ch:pattern}, differences bifurcate between infinitesimal graduation and rigid decision boundaries, sometimes blurring or overlapping, and sometimes distributed into inaccessibly high-dimensional inner data spaces.

Rather than any new materiality, I have pointed to transformations in referentiality associated with machine learning. The topic of chapter \ref{ch:genome} was  a particular contemporary scientific object, genomes. I argued there that as a data form, genomic sequence data provoke re-use, transcription and transmission of classifications and predictions. 

Finally, chapter \ref{ch:subject} explored the subject position of machine learners. The argument here concerned human-machine differences and the dispersion of subject positions through operations that alter those differences. NEED MORE HERE 

## The broader stack

Beyond these facets of the argument concerning abstraction, inclusion, control, multiplicity, differences, materiality and subject positions, another argument shaped discussion in the preceding chapters, one that affects much of the writing. A central problem for critical thought today (and by critical thought I mean post-Foucaultian engagements with the events that constitute us subjects of what we say, do and think \index{critical thought}) concerns how to engage with operational formations. To an even greater extant than the discursive formations that Foucault and many subsequent scholars have analysed, operational formations in production, communication, and the regulation of conduct become the field in which the work of ethics and politics takes place.  \index{operational formation!compared to discursive formation}  

The problem of engagement with operational formations is not so much how to gain control, or challenge the asymmetries of access and control that loom so large in them (Facebook can machine learn exponentially more patterns than I can), but to begin to grasp the forms of change that are possible and desirable. Broadly following Foucault's emphasis in his later work on care of the self, I have proposed such changes in terms of technologies of self, in terms of operations effected on ways of thinking, living and being in order to transform oneself in the interests of limited experience of freedom. \index{technologies of self!machine learning as} 

Under what conditions could something like care of the self and technologies of the self have any purchase, relevance or even toehold in the operational formation of machine learning? Five elements, it seems to me, need to be assembled in order to think through that conjunction. The recognition of ourselves as subjects of machine learning is an elementary archaeological task. Whether in relation to knowledge, communication (in the broadest sense), conduct or ways of living, this recognition relies on a description of practices associated with differences, multiplicities, materialities, knowledges and control. Second, as I have endeavoured to emphasise in describing machine learning as an operational formation, the liveliness of machine learning should be understood as a localisation of power-knowledge relations, or a primary field of expressions issuing from many parts (to paraphrase Whitehead \index{Whitehead, A.N.}). 'They kernel together in localization' as my recurrent neural network \index{machine learner!neural network!recurrent} puts it. Third, while the accumulating plethora of techniques, applications and sites is neither unified by a master algorithm or by a latent, underlying meaning, it does demonstrate regularities and point of indetermination or slippage. Fourth, understood as a field of the expression of many parts, an operational formation can also be site of collective individuation. Participating in a collective, individual subjects, far from losing whatever defines their unique or essential identity, gain the chance to individuate, at least in part, the share of pre-individual reality that marks the collective within them. Fifth, by participating in a collective, even an operational formation, individuals may transform themselves (in order to attain certain states or experiences), but also  affect the collective itself. 

Whether this might affect the internet filter bubble [@Pariser_2011], the 'stack to come' [@Bratton_2016], digital citizenship [@Isin_2015], the character of work [@Brynjolfsson_2014], the fabric of experience [@Hansen_2015] or what counts as knowledge [@Bowker_2014] is hard to say.    As an operational formation, machine learning does not determine anything in its operations. Foucault writes that 'archaeology describes the different spaces of dissension' [@Foucault_1972, 152] \index{archaeology!spaces of dissension}. These spaces of dissension, it seems to me, form a field in which initiatives, individuations and technologies of the self might articulate a certain number of transformative operations. 

## Critical operational practice?

Under what conditions would that practice maximisation be divergent rather than convergent? It might not result in infinitely expanded $N=all$-type infrastructures subsuming all data. 

The path I've taken here combines writing (a discursive practice) and coding (an operational practice). Writing about machine learning is a practice of diagrammatically mapping the re-iterative drawing of human-machine relations in code, and in particular, in coding that learns from data.  While not the path that everyone would or should want to take, for me moving into the data like or as a machine learner perhaps allows writing to become more diagrammatic. 'Between the figure and the text we must admit a whole series of crisscrossings' wrote Foucault [@Foucault_1972, 66]. Datasets, scientific and engineering publications, textbooks such as _Elements of Statistical Learning_, software libraries and packages, spectacular demonstrations comprise a whole series of crisscrossings. 

I've read articles and books, downloaded data and software libraries, watched Youtube lectures and presentations, configured and written bits of code and text, made plots and diagrams, and done much configuration work across various platforms (Github.com, linux, Google Compute, `R`, `python` and `ipython`).   Amidst all of this data practice, there is no reason to assume that learning machine learning is solely the performance of a conscious subject. When we look at an equation repeatedly, when we try to comply with the machine learning injunction to 'find a useful approximation $\hat(f)(x)$ to the function $f(x)$ that underlies the predictive relationship between input and output' [@Hastie_2009, 28] by writing code to cross-validate a model, the 'learning' may not be entirely that of a conscious human subject but also of human-machine assemblage. To the extent that it is archaeological, the operational, diagrammatic writing runs along the axis of knowledge/practice, not knowledge/consciousness. \index{archaeology!writing practice} 

HERE

For present purposes, I have been treating datasets as a kind of texts and the machine learning as the crisscrossing that move data into various figures, moving the data into various forms of visibility and across epistemological, infrastructural, referential and experiential thresholds. \index{diagrammatic!writing}

Machine learning is an uneasy mixture of massively repeated and familiar forms, and something that is not easily understood. On the one hand, the level of imitation, duplications, copying and reproduction associated with the techniques suggests that a process of remaking the world according to particular forms is in process (for instance, in chapter \ref{ch:probability}  we saw how Naive Bayes classifiers are almost demonstrated on spam classification problems.) The scientific and engineering literature, with its really frequent variations on similar themes, suggests that imitation and copying are very much  at the heart of the movements I have been describing. This is nothing new. It would be strange of these techniques were not subject to imitation and emulation. That imitation is predictable, we expect it and can account for it sociologically.[^8.2] Some symptoms of these imitative fluxes can be found in the scientific and engineering literature.  As we have seen, work on image and video classification, on text and speech, on gene interaction prediction or above all, on predictions of relations or associations between people and things (usually commodities, but not always) is striking in its persevering homogeneity. Moreover, the powerful aspirations evident amongst large media platforms such as Baidu, Google  and Facebook to re-ground machine learning in the project of artificial intelligence amidst social media or web page-related data  in many ways continues business as usual for computer scientists [@Gulcehre_2014].  

In the closing pages of _The Archaeology of Knowledge_, Foucault writes:

>the positivities that I have tried to establish must not be understood as a set of determinations imposed from the outside on the thought of individuals, or inhabiting it from the inside, in advance as it were; they constitute rather the set of conditions in accordance with which a practice is exercised, in accordance with which that practices gives rise to partially or totally new statements, and in accordance with which it can be modified. These positivities are no so much limitations imposed on the initiative of subjects as the field in which that initiative is articulated [@Foucault_1972, 208-209]. \index{positivity}

Here Foucault refers to the restricted freedom that discursive practices and formations open for us. It is increasingly difficult for science, media, government and business to think and act outside data. The generalization of machine learning frames statements and makes things visible today. And yet Foucault is quite clear that amidst the positivities of knowledge production, knowing the conditions, setting out the rules, and identifying the relations that striate the density and complexity of practice is a pre-condition to any transformations in practice. 


At a deeper level, the techniques often engage with the world in somewhat predictable ways. Their intuitions of shape are largely governed by a set of fairly basic practical forms. The phenomenologist, Edmund Husserl, describes something similar in _The Origin of Geometry_:

>First to be singled out from the thing-shapes are surfaces -- more or less "smooth," more or less perfect surfaces; edges, more or less rough or fairly "even"; in other words, more or less pure lines, angles, more or less perfect points; then again, among the lines, for examples, straight lines are especially preferred, and among surfaces, the even surfaces. ... Thus the production of even surfaces and their perfection (polishing) always plays its role in praxis [@Derrida_1989, 178] \index{Husserl, Edmund!on surface thing-shape}

Husserl attempts to describe something of the way in which forms such as circles, triangles, squares, lines,and points became objects of geometrical practice, but a similar polishing and smoothing of surfaces is certainly taking place today in the thing-shapes we call data.[^8.1] The strong alignment to lines and smooth surfaces plays out in many of the optimisation techniques, and in the graphs of machine learning performance. Whatever else is happening in the functional mappings traced out in the algorithms, lines, curves and surfaces bring with them powerful and predictable order to the operation of the techniques.

As a data practice, however, machine learning is not entirely predictable. Machine learners,  as we have seen, vary too much, they are biased, they overfit, they underfit, or they fail to generalise.  The meta-techniques of cross-validation, bagging or ROC curves attempt to restore order. New machine learners arise from diagrammatic superimposition of existing practices or procedures. Neural networks are like a massively proliferating nest of perceptrons.  Moreover, machine learning techniques often repeat something familiar by very different means (think of how `kittydar` treats photographs, or how a decision tree is legible but often unfamiliar). The event, then, resides less in either something intrinsic to devices operating as algorithmic models, or in something about the domains and places in which the devices operate (biomedicine, state security and intelligence agencies, finance, business, commerce, science, etc). Perhaps it is a rather more modest event in which the tending of abstractions through estimation,  optimisation, high-dimensional vectorisation, probabilistic mixing of latent and feature  variables, and imputation unevenly replace existing ontological and epistemic norms of verification, objectification, and attribution. \index{machine learning!unpredictable operation of}

I have been less interested in treating these techniques as the predictable re-animation of alienated reason, and more inclined to look for those elements in machine learning that diagrammatically abstract away from structures of representations, subjectification or indeed physicalization associated with platforms, services and products (for instance, the interminable implementations of document classifiers, sentiment analyses, or image labelling, or handwritten digit recognition, or autonomous navigation, etc.). Like Anne-Marie Mol's 'praxiography,' which seeks to maintain reality multiples in describing practice [@Mol_2003, 6], the description of machine learning as data practice intends to  sustain the multiple of reality by identifying the practices that make it multiple. \index{Mol, Anne-Marie!on praxiography} \index{data practice!as multiple} 

[^8.1]: In the essay on the origin of geometry, Husserl goes on to develop an account of how geometry opens up the possibility of a universality and infinite progress in knowledge constitutive of European civilization. Much of this sounds very problematic today, even if practically speaking the expansion of the styles of thought and practice Husserl was describing seems to confirm his account. The problem, to state it as plainly as possible, is that hardly anyone today thinks that geometry is a universal, not least because of the proliferation of mathematical thought and its production of alternative geometries. \index{geometry!Husserl on universality of}

[^8.2]: Accounts that might do this can be found in science and technology studies, particularly in actor-network theory versions, as well as in recent social and cultural theory that, for instance, draws on the work of the 19th century French sociologist, Gabriele Tarde [@Tarde_1902; @Borch_2005].
