
\chapter{ Out of the Data}
\label{ch:conclusion}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  results='hide', warning=FALSE, message=FALSE, dev='pdf')

library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
library(ggplot2)
library(stringr)
library(xtable)
options(xtable.comment = FALSE)
simpleCap <- function(x) {
    s <- strsplit(x, " |-")[[1]]
    return (paste(toupper(substring(s, 1,1)), tolower(substring(s, 2)), sep="", collapse=" "))
  }
```

If a new kind of operational reality is broadly coming into view through formations such as machine learning, formations in which people and things, knowledge and power, recombine in novel forms, then understanding the distribution of elements that make up this emerging common space of decision, classification, prediction and anticipation matters vitally. In the closing pages of _The Archaeology of Knowledge_, Foucault writes:

>the positivities that I have tried to establish must not be understood as a set of determinations imposed from the outside on the thought of individuals, or inhabiting it from the inside, in advance as it were; they constitute rather the set of conditions in accordance with which a practice is exercised, in accordance with which that practices gives rise to partially or totally new statements, and in accordance with which it can be modified. These positivities are no so much limitations imposed on the initiative of subjects as the field in which that initiative is articulated [@Foucault_1972, 208-209]. \index{positivity}

Here Foucault refers to the restricted freedom that discursive practices and formations open for us. It is increasingly difficult for science, media, government and business to think and act outside data. The generalization of machine learning frames statements and makes things visible today. And yet Foucault is quite clear that amidst the positivities of knowledge production, knowing the conditions, setting out the rules, and identifying the relations that striate the density and complexity of practice is a pre-condition to any transformations in practice. 

I've read articles and books, downloaded data and software libraries, watched Youtube lectures and presentations, configured and written bits of code and text, made plots and diagrams, and done much configuration work across various platforms (Github.com, linux, Google Compute, `R`, `python` and `ipython`).   Amidst all of this data practice, there is no reason to assume that learning machine learning is something that a person does as a conscious subject. When we look at an equation, when we try to comply with the machine learning injunction to 'find a useful approximation $\hat(f)(x)$ to the function $f(x)$ that underlies the predictive relationship between input and output' [@Hastie_2009, 28], the 'learning' may not be entirely that of a proper human subject. The material-semiotic dynamic does not readily map onto the forms of subjectivity, sense-making and experience that we typically take as anchor points for our life in the world. 

I see writing about that learning as a practice of diagrammatically mapping the re-iterative drawing of human-machine relations.  Moving into the data like or as a machine learner perhaps allows writing to become more diagrammatic. 'Between the figure and the text we must admit a whole series of crisscrossings' wrote Foucault [@Foucault_1972, 66]. For present purposes, I have been treating datasets as a kind of texts and the machine learning as the crisscrossing that move data into various figures, moving the data into various forms of visibility and across epistemological, infrastructural, referential and experiential thresholds. \index{diagrammatic!writing}

After a couple of hundred weeks spending time with machine learners, some of which time has been mired in technical articles or the mathematics entries in Wikipedia, some of which has lost in a kind of dazzled and maybe naive immersion in technical configuration work, and some of which has been attempting to look to such techniques as ways of re-figuring contemporary forms of knowledge, power, value and experience, it seems to me that machine learning is an uneasy mixture of massively repeated and familiar forms, and something that is not easily understood. On the one hand, the level of imitation, duplications, copying and reproduction associated with the techniques suggests that a process of remaking the world according to particular forms is in process (for instance, in chapter \ref{ch:probability}  we saw how Naive Bayes classifiers are almost demonstrated on spam classification problems.) The scientific and engineering literature, with its really frequent variations on similar themes, suggests that imitation and copying are very much  at the heart of the movements I have been describing. This is nothing new. It would be strange of these techniques were not subject to imitation and emulation. That imitation is predictable, we expect it and can account for it sociologically.[^8.2] Some symptoms of these imitative fluxes can be found in the scientific and engineering literature.  As we have seen, work on image and video classification, on text and speech, on gene interaction prediction or above all, on predictions of relations or associations between people and things (usually commodities, but not always) is striking in its persevering homogeneity. Moreover, the powerful aspirations evident amongst large media platforms such as Baidu, Google  and Facebook to re-ground machine learning in the project of artificial intelligence amidst social media or web page-related data  in many ways continues business as usual for computer scientists [@Gulcehre_2014].  

At a deeper level, the techniques often engage with the world in somewhat predictable ways. Their intuitions of shape are largely governed by a set of fairly basic practical forms. The phenomenologist, Edmund Husserl, describes something similar in _The Origin of Geometry_:

>First to be singled out from the thing-shapes are surfaces -- more or less "smooth," more or less perfect surfaces; edges, more or less rough or fairly "even"; in other words, more or less pure lines, angles, more or less perfect points; then again, among the lines, for examples, straight lines are especially preferred, and among surfaces, the even surfaces. ... Thus the production of even surfaces and their perfection (polishing) always plays its role in praxis [@Derrida_1989, 178] \index{Husserl, Edmund!on surface thing-shape}

Husserl attempts to describe something of the way in which forms such as circles, triangles, squares, lines,and points became objects of geometrical practice, but a similar polishing and smoothing of surfaces is certainly taking place today in the thing-shapes we call data.[^8.1] The strong alignment to lines and smooth surfaces plays out in many of the optimisation techniques, and in the graphs of machine learning performance. Whatever else is happening in the functional mappings traced out in the algorithms, lines, curves and surfaces bring with them powerful and predictable order to the operation of the techniques.

As a data practice, however, machine learning is not entirely predictable. Machine learners,  as we have seen, vary too much, they are biased, they overfit, they underfit, or they fail to generalise.  The meta-techniques of cross-validation, bagging or ROC curves attempt to restore order. New machine learners arise from diagrammatic superimposition of existing practices or procedures. Neural networks are like a massively proliferating nest of perceptrons.  Moreover, machine learning techniques often repeat something familiar by very different means (think of how `kittydar` treats photographs, or how a decision tree is legible but often unfamiliar). The event, then, resides less in either something intrinsic to devices operating as algorithmic models, or in something about the domains and places in which the devices operate (biomedicine, state security and intelligence agencies, finance, business, commerce, science, etc). Perhaps it is a rather more modest event in which the tending of abstractions through estimation,  optimisation, high-dimensional vectorisation, probabilistic mixing of latent and feature  variables, and imputation unevenly replace existing ontological and epistemic norms of verification, objectification, and attribution. \index{machine learning!unpredictable operation of}

I have been less interested in treating these techniques as the predictable re-animation of alienated reason, and more inclined to look for those elements in machine learning that diagrammatically abstract away from structures of representations, subjectification or indeed physicalization associated with platforms, services and products (for instance, the interminable implementations of document classifiers, sentiment analyses, or image labelling, or handwritten digit recognition, or autonomous navigation, etc.). Like Anne-Marie Mol's 'praxiography,' which seeks to maintain reality multiples in describing practice [@Mol_2003, 6], the description of machine learning as data practice intends to  sustain the multiple of reality by identifying the practices that make it multiple. \index{Mol, Anne-Marie!on praxiography} \index{data practice!as multiple} If a book could be a machine learner, then this one might be a generative model that seeks to maximise the range of practices it observes around the data. This reality maximisation might be entropic rather than convergent. It might not result in infinitely expanded $N=all$-type infrastructures subsuming all data. In such a model, a model that would learn machine learning in order to intensify the abstraction , the features would figure less as techniques than as diagrams and diagrammatic process.  

[^8.1]: In the essay on the origin of geometry, Husserl goes on to develop an account of how geometry opens up the possibility of a universality and infinite progress in knowledge constitutive of European civilization. Much of this sounds very problematic today, even if practically speaking the expansion of the styles of thought and practice Husserl was describing seems to confirm his account. The problem, to state it as plainly as possible, is that hardly anyone today thinks that geometry is a universal, not least because of the proliferation of mathematical thought and its production of alternative geometries. \index{geometry!Husserl on universality of}

[^8.2]: Accounts that might do this can be found in science and technology studies, particularly in actor-network theory versions, as well as in recent social and cultural theory that, for instance, draws on the work of the 19th century French sociologist, Gabriele Tarde [@Tarde_1902; @Borch_2005].
