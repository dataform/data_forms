\chapter*{Operations and diagrams}


## alternate title - diagrams and asignifying machine
- Personify techniques of vectorization
- People vectorize techniques
- Techniques personify vectorization

- intro to the inner product space, vector space

The following chapters ideally would be read in parallel. While they have distinct concerns -- with transformations in the structure of data, in the patterns that guide thinking, in the realities of probability, and in the forms of sense-making occurring around models -- they are entwined. The reality of machine learners is a mixed and highly additive one in which computer science, programming practice, visual objects such as diagrams and plots, mathematical forms and techniques, statistical practice and statistical statements and data infrastructures mingle. Historically, it is difficult to disentangle developments in statistics from developments in physics, law and medicine, and this situation persists in machine learning today. 
The following four chapters address forms of algorithmic movement in large spaces -- vector spaces.  The chapters describe very commonly used machine learning techniques such as logistic regression, neural networks, decision trees, random forests, support vector machines,  naive Bayes classifiers and topic models. These techniques are very widely known, heavily used in many scientific, industry, commercial and media settings. They are the topic of any number of textbooks, online tutorials, video lectures. Even when they are not the objects of attentions, they are often unobtrusively working in the background of scientific research or new technologies.

For instance, as I write this in 2014, headlines around the world describe a new blood test  that can predict the onset of Alzheimer's disease well before any existing test. The blood test targets metabolites associated with Alzheimers, and as the paper in _Nature Medicine_ describes it without much further comment,  'metabolites defining the participant groups were selected using the least absolute shrinkage and selection operator (LASSO) penalty' [@Mapstone_2014, 2]. The following three (CHECK THIS) chapters seek to characterise these techniques  in terms of how they move through data. 

As a preliminary characterisation, we might say that three major forms of movement generate  the background hum of the machines learning. Much of machine learning departs from a geometrical intuition in which data populates $n$-dimensional Euclidean spaces, and algorithms test if lines or planes either fit the distribution of points in space, or more or less cleanly divide different parts of data from each other. It measures distances in order to do this.  A second probabilistic intuition animates many machine learning techniques to construct statistical models of the random processes that gave rise to the data. Here the data is generated by random variables more or less interacting with each other. Probability distributions variously shape random variables, and complicated topographies  that arise as different distributions conjoin or intersect. In this statistical space, machine learning models seek to track, traverse or map the curves, peaks and valley of the complicated joint distributions. Finally, a decisionist/rule-oriented technique move through data by constructing rules that classify and cut the space 'piecewise.' This mode of moving through the data is less geometrical and less statistically-oriented, but also somewhat more easily understood since the rules take the form of a series of (usually) binary decisions. 

The geometric, probabilistic and decisionist forms of movement feed into each other, borrow from each other, and with various abstractions can be converted into each other. It is common to find machine learning techniques presented and implemented in terms of one or more of them.  For our purposes, it is useful to think of them as forms of movement in a double sense. They figure and configure data [TBA: Suchman on this]. They literally figure the graphic and diagrammatic forms associated with machine learning: lines, planes, curves, and trees often appear. They configure data in the sense that they set up the ways in which data is going to move. A second sense of movement concerns the techniques themselves. They exist and perhaps contribution to the creation of a transverse space of techniques moving between scientific disciplines, domains and communities. This transverse movement is not homogeneous or consistent. The geometrical, probabilistic and decisionist forms move differently.


## References

wark
toscano
