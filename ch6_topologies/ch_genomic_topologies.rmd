
\chapter{ Re-scaling and shifting objects with machine learning}
\label{ch:genome}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  results='hide', warning=FALSE, message=FALSE, dev='pdf')
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
library(ggplot2)
library(stringr)
library(xtable)
options(xtable.comment = FALSE)
simpleCap <- function(x) {
    s <- strsplit(x, " |-")[[1]]
    return (paste(toupper(substring(s, 1,1)), tolower(substring(s, 2)), sep="", collapse=" "))
  }
```

The opening pages of _Elements of Statistical Learning_ present four vignettes  -- spam email classification, handwritten digit recognition, prostate cancer risk and 'DNA Expression Microarrays' --  and list five examples (document classification, image recognition, risk of heart attack, stock price prediction, risk factors for prostate cancer, and glucose estimates for diabetics) [@Hastie_2009, 1-7].  The last vignette attracts a whole page colour figure -- a heatmap -- of microarray data [@Hastie_2009, 7][^6.22] \index{data!DNA microarray}.  DNA, genes, genomics and proteomics then more or less disappear from view for the next 503 hundred pages of the book (aside from a brief mention in the context of cross-validation), only to reappear somewhat suddenly in a discussion of unsupervised machine learning techniques (k-means, agglomerative and hierarchical clustering; Chapter 14, where the DNA microarray data is re-analysed using hierarchical clustering\index{machine learner!hierarchical clustering}), and then again, and much more resoundingly, in a final chapter (Chapter 18) new to the second edition of the book, on 'High Dimensional Problems.' Apart from one example where the Hastie and co-authors develop a document classifier for their journal articles, every example in the added Chapter 18 comes from genomic science, a scientific field that largely begins to take a recognisable shape in the late 1990s as both sequence data and high-throughput DNA-analysis devices, particularly microarrays, become widely available. \index{genomics!importance in machine learning} Alongside spam filtering, image or handwriting recognition, genomic research into biological processes has a strongly referential effect on machine learning. It 'forms the place, the condition, the field of emergence, the authority to differentiate between individuals or objects, states of things and relations that are brought into play by the statement itself; it defines the possibilities of appearance and delimitation of that which gives meaning to the sentence, a value as truth to the proposition' [@Foucault_1992, 91]. \index{referential!entanglement}

This referential entanglement happens in several different ways. The first concerns what I earlier called data strain. \index{data!strain} Genome data volume fully inflates the common vector space. Genomics generates new versions of the now familiar problems of data dimensionality. It produces data whose abundance, diffusion, heterogeneity or impaction thwarts its examination, tabulation, and regulated circulation. Sometimes genomics data exhibits unusual mixtures of accumulation and sparsity. Clinical genomics in particular generates datasets that are lavishly furnished with 'features' but often quite meagrely supplied with clinical cases or 'observations'. In the shorthand typical of machine learning terminology, $p$ is larger than $N$: 'the number of features $p$ is much larger than the number of observations $N$, often written $p\gg N$' [@Hastie_2009, 649]. This strains statistical methods that rely on the 'Law of Large Numbers' [@Hacking_1990, 99-104], which holds that the accuracy of statistics tends to increase with more observations.  \index{statistics!Law of Large Numbers}

The second referential entanglement comes from the _positivity_ of genomes themselves. Genomics seeks to know and understand problems of time, genesis, duration, activity and process in a very broad spectrum of living things. But it seeks to do so, as many commentators have noted, by concentrating and coalescing different operational, algorithmic and mathematical senses of function (see chapter \ref{ch:function}). \index{posivity}. The operational sense of function matters most here, since biological function, a deeply interconnected relationality in life sciences, becomes the test case for the learning capacities of machine learners. 

Hastie and co-author's invocation of DNA-related data is no arbitrarily chosen example amidst the general proliferation of settings, domains, cases and examples typically found in machine learning pedagogy.  In multiple dimensions and directions, genomics -- the scientific project of operating on the whole DNA complement of organisms -- is a nearest neighbour, a tightly adjacent territory of machine learning. This relatively long-established proximity (at least 25 years, and perhaps more) of genomics and DNA-based data  is strategically important in the diagrammatic generalization or diagrammatization of  machine learning, in the processes whereby the diagrammatic forms configured around these techniques, with their specific forms of articulation, statement and making-visible, propagate into multiple, once-disparate settings.[^6.21] \index{diagram!diagrammatization!as generalization}

Genomes, I would suggest, provoke a multiplicity of  machine learners to bind to them like antibodies to an antigen (or an allergen). At the same time, machine learners profoundly re-configure the economically charged fields of biomedicine and biological research and generate new modes of action, accounting, testing, and examining biological processes (metabolism, development, disease), relations (species, evolutionary, commensual),  and functions (reproduction, digestion, photosynthesis, immunity, circulation, etc.).  Wide-ranging infrastructural, institutional, professional and financial arrangements follow along new paths constructed by machine learning, with its epistopological transformations, its function-finding, its regimes of probabilistic, decisionistic and re-patterned engagement with data.

## The positivity of the genome

```{r genome_in_ml}
q = 'select TI, PY, TC, DE, WC from basic_refs where PY >= 1990 order by TC desc limit 5000'
res = dbGetQuery(con, q)
res$DE = tolower(res$DE)
de = unlist(str_split(res$DE, '; '))
det = as.data.frame(sort(table(de), decreasing=TRUE), rowNames = NULL)
det$keyword = rownames(det)
colnames(det) = c('freq', 'keyword')
dtt = xtable(head(det,50), label = 'tab:top_keywords', caption = 'Most common author-supplied keywords from the 5000 cited research publications in machine learning, 1990-2015')
terms= read.csv('techniques.csv', header=FALSE)
colnames(terms) = c('keyword', 'technique')
techniques =terms$keyword[terms$technique=='y']
actual_topics  = det[-which(det$keyword %in% techniques)]
top_topics = as.data.frame(sort(table(actual_topics), decreasing=TRUE))
res$WC = tolower(res$WC)
wc = unlist(str_split(res$WC, '; '))
wct = as.data.frame(sort(table(wc), decreasing=TRUE), rowNames = NULL)
wct$keyword = rownames(wct)
colnames(wct) = c('freq', 'discipline')

wtt = xtable(head(wct,20), label = 'tab:top_discp', caption = 'The top 20 disciplines of the top 5000 cited research publications in machine learning, 1990-2015')
print(wtt, type='latex')
```

In research done on machine learning during 1990-2015, biology, and particularly molecular and then genomic biology, has a very high profile in the research publications. (See table \ref{tab:top_discp}.) After the leading machine learning disciplines (computer science, electronic engineering and statistics), molecular biology, genomics and bioinformatics attract most academic journal citations and publications associated with machine learning. Half of the most cited research literature has a biomedical or life science referentiality. This may be because genomes and human disease in particular, are premiere hyperobjects like the human brain, dark matter, global climate or fundamental particles in contemporary sciences. \index{hyperobject} \index{genome!as hyperobject} But it might also be the case -- and I will pursue this line of argument here -- that genomes, with all their operational and functional complexity, takes shape in concert with machine learning. In terms of contemporary biological knowledge production, the transformation of biology into a data-intensive science  [@Hey_2009; @McNally_2012] is tightly entangled with machine learning. 

In the generalization of machine learning, genomics and the genome referential mark a threshold of epistemologization. \index{epistemologization! threshold of}  Genomes are both a challenge to the capacity of machine learning to produce scientific knowledge (as distinct from say the unstable commercial knowledge of a credit risk model), and a way of validating machine learning  as a life-death relevant biomedical knowledge practice. Genomes also provide the pretext for vectorizing infrastructural re-configurations such as computational clusters, grids, arrays and clouds. \index{vectorization!infrastructural} For instance,  the Google Compute Engine, a globally addressable ensemble of computers typical of recent distributed commercial computing architectures,  was briefly turned over to exploration of cancer genomics during 2012, and publicly demonstrated at the annual Google I/O conference. \index{Google!I/O Conference, 2012}  Midway through the demonstration, in which a human genome is visualized as a ring in 'Circos' form (see figure \ref:fig:circos} [@Krzywinski_2009]),  the speaker, Urs Hölzle, Senior Vice President of Infrastructure at Google 'then went even further and scaled the application to run on 600,000 cores across Google’s global data centers' [@GoogleInc.2012]. \index{Google!Google Compute Engine} The audience clapped as the annular diagram of a human genome was decorated with a rapidly increasing number of cross-links, accompanied by a snapping sound as it appeared. The world's '3rd largest supercomputer', as it was called by TechCrunch, a prominent technology blog,  'learns associations between genomic features' [@Anthony_2012]. Note the language of machine learning: it 'learns ... associations between features.' We are in the midst of many such demonstrations of 'scaling applications' of data in the pursuit of associations between 'features.'[^6.0]

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/circos.pdf}
        \caption[A human genome diagrammed using the Circos]{A human genome diagrammed using the Circos form. The many tracks of this diagram support a range of graphic forms including scatterplots, heatmaps and histograms all anchored to the ideogram of the 23 chromosomes of the human genome. }
  \label{fig:circos}
\end{figure} \index{graphic!Circo diagram}

The I/O conference audience, largely comprising software developers, could hardly be expected to have a detailed interest in what was being shown on the screen. Their interest was steered toward the immediate availability of  computing power: from 10,000 to 600,000 cores in a few seconds. Such drastic infrastructural re-scaling attests to the provocative form of the genomic referential. The principal chain of associations validated by the genomics demonstration was, presumably, something more indexical: genome=>complexity=>cancer/disease=>life/death=>important. Yet the Google Compute demonstration is, I would suggest, typical of how genomes, genes, proteins and biological sciences more generally, have supply positivity to machine learning \index{positivity}. This positivity is only  hinted at in the Google I/O keynote address in Hölzle's talk of genomic features, gene expression and patient attributes.  The only concrete indication of how what was happening in the demonstration related to machine learning  was one mention of the RF-ACE (Random Forest- Artificial Contrasts with Ensembles) algorithm.  Google's press release emphasises epistemic values:

>it allows researchers to visually explore associations between factors such as gene expression, patient attributes, and mutations - a tool that will ultimately help find better ways to cure cancer. The primary computation that Google Compute Engine cluster performs is the RF-ACE code, a sophisticated machine learning algorithm which learns associations between genomic features, using an input matrix provided by ISB (Institute for Systems Biology). When running on the 10,000 cores on Google Compute Engine, a single set of association can be computed in seconds rather than ten minutes, the time it takes when running on ISB’s own cluster of nearly 1000 cores. The entire computation can be completed in an hour, as opposed to 15 hours [@GoogleInc.2012].

Amidst this mire of fairly technical computing jargon, we might observe that Google applies an algorithm developed by engineers at Intel Corporation and Amazon to genomic datasets provided by the Institute of Systems Biology, Seattle, a doyen of big-data genomics. The RF-ACE algorithm (a further development of Breiman's random forests discussed in chapter \ref{ch:pattern}) literally re-draws a diagram of the genome, and re-draws it increasingly rapidly as the demonstration scales up to 10,000 cores (or CPUs). \index{machine learner!RF-ACE}  A diagram that normally appears statically on-screen or on the printed page of a scientific publication is now animated by an algorithmic process. This confluence of commerce (Amazon), industry (Intel), media (Google) and genomic science (ISB) exemplifies the diagrammatic generalization of machine learning.

In none of these demonstrations and examples, whether they come from _Elements of Statistical Learning_ or from Google Compute Engine, does the object of the knowledge -- genomes, genes, proteins -- need to figure in terms of its original discipline or scientific field (typically cancer biology). The de-coupled 'positivity' of the genome,  to use Michel Foucault's term from _The Archaeology of Knowledge_, functions as a matrix from which propositions are generated. \index{positivity!as basis of propositions} As Foucault writes:

>To analyse positivities is to show in accordance with which rules a discursive practice may form groups of objects, enunciations, concepts, or theoretical choices. The elements thus formed do not constitute a science, with a defined structure of ideality; their system of relations is certainly less strict; but neither are they items of knowledge piled up one on top of another, derived from heterogeneous experiments, traditions, or discoveries, and linked only by the identity of the subject that possesses them. They are that on the basis of which coherent (or incoherent) propositions are built up, more or less exact descriptions developed, verifications carried out, theories deployed. They form the precondition of what is later revealed and which later functions as an item of knowledge or an illusion, an accepted truth or an exposed error, a definitive acquisition or an obstacle surmounted [@Foucault_1972, 181-2]

In the case, the positivity of RF-ACE and its scaled-up demonstration on Google Compute consists in the system of relations it groupwise assembles between cancer patients, vectorised infrastructures and predictive classifications. Similarly, the treatment of DNA microarray data in the slightly earlier examples found in _Elements of Statistical Learning_ does not principally concern cancer biology as such, but much more the way a group of elements are assembled so as to permit the production of propositions that cross the threshold of scientificity if configured in relation to experimental practices and scientific literatures, but may just as well posit different forms of governmental, market-focused, organisational or managerial operations.[^6.9]


## The advent of 'wide, dirty and mixed' data

The plurality of applications can sometimes make it seem that machine learning docks in the different domains, and then proceeds to administer learning algorithms to existing knowledges practices wherever it finds them. The law of generalization here would seem to be an epistemic _terra nullius_ doctrine, in which existing knowledge titles are rapidly extinguished by  algorithmic processes. We have seen previously that ancestral communities of probabilisation orient the generalization of machine learning (see chapter \ref{ch:probability}). The research literature published on machine learning since the early 1990s clusters around several main problems -- image recognition, document classification, and segmenting market behaviour (as in, working out what advertisement to show, or whether someone is likely to a buy a particular product, etc.). These problems position machine learning amidst regimes of visibility,  the production of economic value, and the regularities of statements (or put in more Foucaultean terms, amidst life, labour and language; see [@Foucault_1992]). Where, amidst these major regularities, does molecular biology or genomics (arguably the successor of molecular biology) fit? Almost all of the major  machine learners, albeit supervised or unsupervised, discriminative or generative, parametric or non-parametric, substantial research activity during the last two or so decades cross-validate their statements with genomics. \index{cross-validation!referentiality of} (The difference between the first and second editions of  _Elements of Statistical Learning_ attests to that tendency.) 

We can see this cross-validation at work in the treatment of genomic data in _Elements of Statistical Learning_. As to the former problem of dimensionality, both the RF-ACE cancer biology demonstration and  the DNA microarray data extensively modelled in the final chapter of  _Elements of Statistical Learning_ address some elementary problems associated with genomic data. If we turn back to the `iris` dataset [@Fisher_1936], perhaps the most heavily used pedagogical dataset in the literature, it is strikingly obvious that the data does not provoke the infrastructural contortions associated with Google Compute, or for that matter, the highly sophisticated and quite subtle treatment of gene expression we find in genomics-related machine learning. 

```{r iris, echo=FALSE, message=FALSE, cache=TRUE,  fig.cap ="Fisher's iris dataset, 1936",comment=NA, size='smallsize'} 
    library(xtable)
	data(iris)
    tab = xtable(iris[1:5,], label='iris_sample', caption="First 5 rows of Fisher's `iris` dataset")
	print(tab)
```

It is usual, in working with `iris,` to construct machine learners that use the variables from the first four columns shown in \ref{tab:iris_sample} to infer the value of the `Species` variable (as seen in Chapter 5, where a decision tree was constructed using this same dataset). The measurements of petals and sepals of the irises of the Gaspé Peninsula in Novia Scotia, and their classification into different species is perhaps a typical mid-twentieth century biological procedure. The technique of linear discriminant analysis that Fisher demonstrated as a way of classifying the species of iris continues in use, but the shape and texture of contemporary datasets differs greatly from what we see in this table. Even in the excerpt shown in Table \ref{tab:iris_sample}, we can see that it is quite narrow as it has only a few columns, the data is nearly all of one type (measurements of lengths and widths), and the data is clean (there are no missing values). The data is tightly contained in the table. `Iris` is typical of classic statistics, and much  biological data prior to genomics in its relatively homogeneity and distinct partitioning. \index{dataset!iris}

If `iris` is the conventional form, how does a genomic dataset differ? One clue comes from descriptions of the RF-ACE algorithm, first published in 2009. RF_ACE is attempts to  deal with 'modern data sets' that are 'wide, dirty, mixed with both numerical and categorical predictors, and may contain interactive effects that require complex models' [@Tuv_2009, 1341]. Such algorithms and the 'wide, dirty, mixed' datasets they work on have a distinctive texture, which, I would suggest,  we should try to grasp if we want to understand how genomic data has become a lightning rod for machine learning. More clues come from the various treatments of DNA microarray data in _Elements of Statistical Learning_. \index{data!wide, dirty, mixed}  Hastie and co-authors introduce one microarray dataset they use in this way:

>The data in our next example form a matrix of 2308 genes (columns) and 63 samples (rows), from a set of microarray experiments. Each expression value is a log-ratio log(R/G). R is the amount of gene-specific RNA in the target sample that hybridizes to a particular (gene-specific) spot on the microarray, and G is the corresponding amount of RNA from a reference sample. The samples arose from small, round blue-cell tumors (SRBCT) found in children, and are classified into four major types: BL (Burkitt lymphoma), EWS (Ewing’s sarcoma), NB (neuroblastoma), and RMS (rhabdomyosarcoma). There is an additional test data set of 20 observations. We will not go into the scientific background here [@Hastie_2009, 651]

Note that while the number of samples (~80) in the small round blue-cell tumors (`SRBT`) [@Khan_2001]  dataset is less than the number of flowers measured in `iris,` the number of variables presented by the columns in the table (2308) is much greater. \index{dataset!SRBCT} Hastie and co-authors, like the Google I/O demonstration,  do not 'go into the scientific background.' Scientific knowledge _per se_ is not the central concern in machine learning, but the positivity of knowledge is important.\index{science!knowledge!positivity of} The original publication of this dataset in 2001 [@Khan_2001] also made use of machine learning techniques (neural networks, a major topic in the next chapter \ref{ch:subjects}), but precisely in order to address the diagnostic difficulties of distinguishing different types of such tumors without resort to new experiments or biological knowledge.[^6.1]

```{r microarray, results='asis'}
library(xtable)
library(datamicroarray)
tab1 = xtable(describe_data(), label='microarray_data', caption ='Microarray datasets used in machine learning')
data('khan')
tab = xtable(head(khan[[1]], 5), label='srbct', caption='Small round blue-cell tumour data sample (Khan, 2001)')
print(tab, type='latex')
```

The sample of the `SRBCT` data shown in Table \ref{tab:srbct} does not readily accommodate the wide table of this dataset. Unlike `iris`, the thousands of variables simply cannot be displayed on a page or screen. _Wide_ datasets are quite common in machine learning settings generally, but particularly common in genomics where in a given study there might only be a relatively small number of biological samples but a huge amount of sequencer or microarray data for each sample. This wide dimensionality of the data is common. Note too that while _Elements of Statistical Learning_ picks up the `SRBCT` dataset from biomedical research ([@Khan_2001] appears in the journal _Nature Medicine_), many other similar datasets appear in the machine learning literature. Much genomic data shares this generic feature of width.[^6.70]


[^6.70]: Importantly, as discussed in Chapter \ref{ch:diagram} (in terms of the diagonalization running between different elements of code, data, mathematical functions and indexical signs) and in Chapter \ref{ch:vector} (in terms of the auratic power of datasets), the fact that these datasets can be so readily loaded and accessed via bioinformatic infrastructures using code written in `R` or `Python` is also a notable feature of their advent in the machine learning literature.  Even a social science researcher can quickly write programs to retrieve this data. It attests to  several decades, if not longer, work on databases, web and network infrastructures, and analytical software, all, almost without exception, driven by the desire for aggregation, integration, archiving and annotation of sequence data that first became highly visible in the Human Genome Project of the 1990s.  The brevity of these lines of code that retrieve and load datasets -- half a dozen statements in `R`, no more -- suggests we are dealing with a high-sedimented set of practices, not something that has to be laboriously articulated, configured or artificed. Code brevity almost always signposts  highly-trafficked routes in contemporary network cultures. \index{code!brevity of}  Without describing in any great detail the topography of databases, protocols and standards woven by and weaving through bioinformatics, the ready invocation of genomic datasets suggests that the mixed, dirty, wide datasets fed to algorithms such as RF-ACE or analysed in [@Hastie_2009] derives from the layered couplings and interweaving of scientific publications and scientific databases developed by biological science over the last three decades. As the code shows, sequence and other genomic data   are available to scientists not only as users searching for something in particular and  retrieving specific data, but to scientists as programmers developing  ways of connecting up, gathering and integrating many different data points into to produce the wide ( many-columned), mixed (different types of data), and dirty (missing data, data that is 'noisy') datasets, datasets whose heterogeneous and often awkward topography then elicits and invites algorithmic treatment.




[^6.22]: I have discussed the history of heatmaps and their place in contemporary science in other work [@Mackenzie_2013c].

[^6.21]: Signal processing is another such domain. Many of the techniques now prominent in machine learning developed in parallel in signal processing, where the encoding and decoding of signals has long been seen as a problem of pattern recognition amenable to statistical calculation. In some specific cases, such as Hidden Markov Models, the same techniques seem to appear almost simultaneously in very disparate domains. Hidden Markov Models appear in genomics (as part of the problem of sequence alignment) at the same time as the begin to appear in digital signal processing for wireless communication and video image compression [@Mackenzie_2010a] and above all, in speech recognition [@Rabiner_1989]. \index{signal processing!relation to machine learning}

[^6.0]: A second significant and equally prestigious example of this infrastructural re-scaling might be IBM Corporation's 'cognitive computing platform,'  Watson. Watson, a distributed computing platform centred on machine learning, is hard to delineate or easily describe since it exists in a seemingly highly variable form. Its uses in genomics, pharmaceutical discovery,  clinical trials and cooking are heavily promoted by IBM [@IBM_2014]. Another would be Amazon Web Services various cloud computing services, some of which have been heavily used by genomic scientists. 

[^6.9]: In their account of the surprisingly slow shift of microarrays towards clinical practice, Paul Keating and Alberto Cambrosio identify statistics as a kind of bottleneck:

    >The handling and processing of the massive data generated by microarrays has made bioinformatics a must, but has not exempted the domain from becoming answerable to statistical requirements. The centrality of statistical analysis emerged diachronically, as the field moved into the clinical domain, and is re-specified synchronically depending on the kind of experiments one carries out [@Keating_2012,49].

    What Keating and Cambrosio describe as 'becoming answer to statistical requirements' I would suggest also entails a transformation of statistical requirements in a new operational diagram that reduces some of the frictions associated with existing statistical practice. This operational diagram is machine learning.  \index{statistics!biomedical!changes in} \index{Keating, Paul!on microarrays} \index{Cambrosio, Albert!on microarrays}

[^6.1]: Khan and co-authors write: 

    > Gene-expression profiling using cDNA microarrays permits a simultaneous analysis of multiple markers, and has been used to categorize cancers into subgroups 5–8 . However, despite the many statistical techniques to analyze gene-expression data, none so far has been rigorously tested for their ability to accurately distinguish cancers belonging to several diagnostic categories [@Khan_2001, 673] 

