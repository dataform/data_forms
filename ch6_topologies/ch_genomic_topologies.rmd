
# 6. The biological testing of machine learning 

> Because of a gradient that no doubt characterizes our cultures, discursive formations are constantly becoming epistemologized [@Foucault_1972, 195]

In the opening pages of _Elements of Statistical Learning_, a number of vignettes appear. They include document classification, image recognition, risk of heart attack, stock price prediction and risk factors of prostate cancer, and glucose estimates for diabetics. Four examples are discussed in more detail: spam email classification, handwritten digit recognition, prostate cancer risk and lastly 'DNA Expression Microarrays' [@Hastie_2009, 23]. The latter vignette attracts a whole page colour figure -- a heatmap -- of microarray data [@Hastie_2009, 24].  DNA, genes, genomics and proteomics then more or less disappear from view for 500 hundred pages of the book (aside from a brief mention in the context of cross-validation), only to reappear somewhat suddenly in a discussion of unsupervised machine learning techniques (k-means, agglomerative and hierarchical clustering; Chapter 14), and then again, and much more resoundingly, in a final chapter (Chapter 18) new to the second edition of the book, on 'High Dimensional Problems.' This chapter highlights biological processes and genomic applications as key challenges for machine learning since they  generate datasets that are lavishly furnished with variables but often quite meagrely supplied with cases. In the shorthand of typical machine learning terminology, $p$ is larger than $N$: 'the number of features $p$ is much larger than the number of observations $N$ , often written $p>>N$' [@Hastie_2009, 649]. Apart from one example where the Hastie and co-authors develop a document classifier for their journal articles, every example in the added Chapter 18 comes from genomic science, a scientific field that largely adopts its contemporary form in the early 1990s. 

Hastie and co_author's invocation of DNA-related data is no arbitrarily chosen example amidst the general proliferation of illustrations typically found in machine learning pedagogy. If we turn to the research done on machine learning during 1990-2010, biology, and particularly molecular and then genomic biology, has a very high profile. After computer science and statistics, molecular biology, genomics and bioinformatics are by far the most heavily represented disciplines visible in academic journal publications associated with machine learning. In terms of contemporary biological knowledge production, the transformation of biology into a data intensive science is tightly entangled with machine learning. Genomics, I would suggest, is an antigen that provokes a multiplicity of  machine learners to act on it. 

```{r disciplines,  engine='python', results='asis', echo=FALSE, warning=FALSE, message=FALSE}

import tabulate
import ml_lit_anal as ml
import pandas as pd
import collections
df = ml.load_records('data/machine_learning_WOS/')
df = ml.clean_topics(df)
df = ml.clean_fields(df)
all_fields = sorted([e for el in df.fields.dropna() for e in el])
fset = set(all_fields)
field_counts = {e:all_fields.count(e) for e in fset}
field_counts_sorted = sorted(field_counts.iteritems(), key=lambda(k,v):(-v,k))


```

At the same time, and reciprocally, the incursion of  machine learners profoundly re-configures the highly economically charged fields of biomedicine and biological sciences more generally, and generates new modes of action, accounting, testing, examining and sorting biological processes.  Wide-ranging infrastructural, institutional, professional and financial arrangements unfold along new paths constructed by the modes of operation of machine learning, with its epistopological transformations, its function-finding, its regimes of probabilistic, decisionistic and geometrical engagement with data. In multiple dimensions and directions, genomics -- the project of operating on the whole DNA complement of organisms -- is a nearest neighbour, a tightly adjacent territory to machine learning. This relatively long-established proximity (at least 25 years, and perhaps more) means that genomics and DNA-based data  is strategically important in the generalization of  machine learning, in the processes whereby the diagrammatic forms configured around these techniques, with their specific forms of articulation, statement and making-visible, propagate into multiple, once-disparate settings.  

In the generalization of machine learning, genomics appears with  multiple valencies. Genomes are both a challenge to the capacity of machine learning to produce scientific (as distinct from say the merely commercial knowledge of a credit risk model), and a way of validating machine learning  as a life-death relevant knowledge practice.  The Google Compute Engine, a globally-distributed ensemble of computers,  was briefly turned over to exploration of cancer genomics during 2012, and publicly demonstrated during the annual Google I/O conference. Midway through the demonstration, in which a human genome is visualized as a ring in 'Circos' form [@Krzywinski_2009,]  the speaker, Urs Hölzle, Senior Vice President of Infrastructure at Google 'then went even further and scaled the application to run on 600,000 cores across Google’s global data centers' [@GoogleInc._2012]. The audience clapped as the annular diagram of a human genome was decorated with a rapidly increasing number of cross-links, accompanied by a snapping sound. The world's '3rd largest supercomputer', as it was called by TechCrunch, a prominent technology blog,  'learns associations between genomic features' [@Anthony_2012]. Note the language of machine learning appearing here: it 'learns ... associations between features.' We are in the midst of many such demonstrations of 'scaling applications' of data in the pursuit of associations between 'features.'[^1]

[^1]: A second significant example, equally prestigious, might be IBM Corporation's 'cognitive computing platform,'  Watson. Watson, a distributed computing platform centred on machine learning, is hard to delineate or easily describe since it exists in a seemingly highly variable form. Its uses in genomics, pharmaceutical discovery and clinical trials are heavily promoted by IBM [@IBM_2014]

The I/O conference audience, largely comprising software developers, could hardly be expected to have a detailed interest in what was being shown on the screen. Their interest was steered toward the immediate availability of huge computing power: from 10,000 to 600,000 cores in a few seconds. The principal chain of associations validated by the genomics demonstration was, presumably, something like: genome=>complexity=>cancer/disease=>life/death=>important. Yet the Google Compute demonstration is, I would suggest, typical of how genomes, genes, proteins and biological sciences more generally, have important enunciative functions in machine learning. This transformation is only  hinted at in the Google I/O keynote address in Hölzle's talk of genomic features, gene expression and patient attributes.  The only concrete indication of how what was happening in the demonstration related to machine learning  was one mention of the RF-ACE (Random Forest- Artificial Contrasts with Ensembles) algorithm.  Google's press release emphasises epistemic values:

>it allows researchers to visually explore associations between factors such as gene expression, patient attributes, and mutations - a tool that will ultimately help find better ways to cure cancer. The primary computation that Google Compute Engine cluster performs is the RF-ACE code, a sophisticated machine learning algorithm which learns associations between genomic features, using an input matrix provided by ISB (Institute for Systems Biology). When running on the 10,000 cores on Google Compute Engine, a single set of association can be computed in seconds rather than ten minutes, the time it takes when running on ISB’s own cluster of nearly 1000 cores. The entire computation can be completed in an hour, as opposed to 15 hours [@GoogleInc._2012].

Amidst this mire of fairly technical computing jargon, we might observe that Google applies here an algorithm developed by engineers at Intel Corporation and Amazon to genomic datasets provided by the Institute of Systems Biology, Seattle, a doyen of big-data genomics. The RF-ACE algorithm (a further development of Breiman's random forests discussed in Chapter 5) literally re-draws a diagram of the genome, and re-draws it increasingly rapidly as the demonstration scales up to 10,000 cores (or CPUs).  A diagram that normally appears statically on-screen or on the printed page is now animated by an algorithmic process. This confluence of commerce (Amazon), industry (Intel), media (Google) and genomic science (ISB) is, I suggest, symptomatic of the generalization of machine learning. In none of these demonstrations and examples, whether they come from _Elements of Statistical Learning_ or from Google Compute Engine, does the object of the knowledge -- genomes, genes, proteins -- actually appear in the terms of their own disciplines or scientific field (typically cancer biology). The 'positivity,' to use Michel Foucault's term from _The Archaeology of Knowledge_, as the matrix from which propositions are developed. As Foucault writes:

>To analyse positivities is to show in accordance with which rules a discursive practice may form groups of objects, enunciations, concepts, or theoretical choices. The elements thus formed do not constitute a science, with a defined structure of ideality; their system of relations is certainly less strict; but neither are they items of knowledge piled up one on top of another, derived from heterogeneous experiments, traditions, or discoveries, and linked only by the identity of the subject that possesses them. They are that on the basis of which coherent (or incoherent) propositions are built up, more or less exact descriptions developed, verifications carried out, theories deployed. They form the precondition of what is later revealed and which later functions as an item of knowledge or an illusion, an accepted truth or an exposed error, a definitive acquisition or an obstacle surmounted [@Foucault_1972, 181-2]

In the case, the positivity of RF-ACE and its scaled-up demonstration on Google Compute consists in the system of relations it permits to develop. Similarly, the treatment of DNA microarray data in the slightly earlier examples found in _Elements of Statistical Learning_ does not principally concern the subject of cancer biology, but much more the way a group of elements are assembled so as to permit the production of propositions that may cross the threshold of scientificity if configured in relation to experimental practices and scientific literatures, but may just as well constitute different forms of governmental, market-focused, organisational or managerial knowledges.  

## The advent of 'wide, dirty and mixed' data

The plurality of applications can sometimes make it seem that machine learning docks in the different domains, and then proceeds to administer learning algorithms to existing knowledges practices wherever it finds them. The mode of generalization here would seem to be an epistemic _terra nullius_ doctrine, in which existing knowledge titles are rapidly extinguished by their algorithmic treatment. The case of genomics suggest that matters are more complicated. The research literature published on machine learning since the early 1990s clusters around several main problems -- image recognition, document classification, and segmenting market behaviour (as in, working out what advertisement to show, or whether someone is likely to a buy a particular product, etc.). These problems position machine learning amidst regimes of visibility, the regularities of statements, and the production of economic value. Where, amidst these major problems, does molecular biology or genomics (arguably the successor of molecular biology) fit? For almost any of the major  machine learning techniques, albeit supervised or unsupervised, discriminative or generative, parametric or non-parametric, substantial research activity during the last two or so decades bridges across to genomics. (The difference between the first and second editions of  _Elements of Statistical Learning_ is largely attributable the style of problems associated with genomic data.) The entanglements between genomics and machine learning display two aspects. The first of these is a new version of the now familiar problem of data dimensionality, data whose abundance, diffusion, heterogeneity or impaction thwarts its examination, tabulation, and regulated circulation. Genomic data epitomises these problems. The second of these is the problem of time, genesis, duration, activity and process that generates transient events, events in which sequence and above all becoming matter. This latter problem animates the frequent invocation of cancer datasets in the machine learning literature (particularly [@Golub_1999; @Khan_2002]). 

As to the former problem of dimensionality, both the RF-ACE cancer biology demonstration and  the DNA microarray data extensively modelled in the final chapter of  _Elements of Statistical Learning_ address some elementary problems associated with genomic data. If we turn back to the `iris` dataset [@Fisher_1936], perhaps the most heavily used pedagogical dataset in the literature, it is strikingly obvious that the data does not provoke the infrastructural contortions associated with Google Compute, or for that matter, the highly sophisticated and quite subtle treatment of gene expression we find in genomics-related machine learning. 

```{r iris, echo=FALSE, message=FALSE, cache=TRUE,  fig.cap ="Fisher's iris dataset, 1936",comment=NA, size='smallsize'} 
    library(xtable)
	data(iris)
    tab = xtable(iris[1:5,], label='iris_sample', caption="First 5 rows of Fisher's `iris` dataset")
	print(tab)

```
It is usual, in working with `iris,` to construct machine learners that use the variables from the first four columns shown in \ref{tab:iris_sample} to infer the value of the `Species` variable (as seen in Chapter 5, where a decision tree was constructed using this same dataset). The measurements of petals and sepals of the irises of the Gaspé Peninsula in Novia Scotia, and their classification into different species is perhaps a typical mid-twentieth century biological procedure. The technique of linear discriminant analysis that Fisher demonstrated as a way of classifying the species of iris continues in use, but the shape and texture of contemporary datasets differs greatly from what we see in this table. Even in the excerpt shown in Table \ref{tab:iris_sample}, we can see that it is quite narrow as it has only a few columns, the data is nearly all of one type (measurements of lengths and widths), and the data is clean (there are no missing values). The data is tightly contained in the table. `Iris` is typical of classic statistics, and much  biological data prior to genomics in its relatively homogeneity and distinct partitioning.

If `iris` is the conventional form, how does a genomic dataset differ? One clue comes from descriptions of the RF-ACE algorithm, first published in 2009. RF_ACE is attempts to  deal with 'modern data sets' that are 'wide, dirty, mixed with both numerical and categorical predictors, and may contain interactive effects that require complex models' [@Tuv_2009, 1341]. Such algorithms and the datasets they work on have a distinctive texture, which, I would suggest,  we should try to grasp if we want to understand how genomic data has become a lightning rod for machine learning. More clues come from the various treatments of DNA microarray data in _Elements of Statistical Learning_.  Hastie and co-authors introduce one microarray dataset they use in this way:

>The data in our next example form a matrix of 2308 genes (columns) and 63 samples (rows), from a set of microarray experiments. Each expression value is a log-ratio log(R/G). R is the amount of gene-specific RNA in the target sample that hybridizes to a particular (gene-specific) spot on the microarray, and G is the corresponding amount of RNA from a reference sample. The samples arose from small, round blue-cell tumors (SRBCT) found in children, and are classified into four major types: BL (Burkitt lymphoma), EWS (Ewing’s sarcoma), NB (neuroblastoma), and RMS (rhabdomyosarcoma). There is an additional test data set of 20 observations. We will not go into the scientific background here [@Hastie_2009, 651]

Note that while the number of samples (~80) in the small round blue-cell tumors (`SRBT`) [@Khan_2001]  dataset is less than the number of flowers measured in `iris,` the number of variables presented by the columns in the table (2308) is much greater. Hastie and co-authors, like the Google I/O demonstration do not 'go into the scientific background.' This again suggests that scientific knowledge _per se_ is not the central concern in machine learning. We could note too that the original publication of this dataset in 2001 [@Kkan_2001] also made use of machine learning techniques (neural networks), but precisely in order to address the diagnostic difficulties of distinguishing different types of such tumors without resort to new experiments or biological knowledge.[^1.1]

[^1.1]: Khan and co-authors write: 

    > Gene-expression profiling using cDNA microarrays permits a simultaneous analysis of multiple markers, and has been used to categorize cancers into subgroups 5–8 . However, despite the many statistical techniques to analyze gene-expression data, none so far has been rigorously tested for their ability to accurately distinguish cancers belonging to several diagnostic categories [@Khan_2001, 673] 

```{r microarray, results='asis'}
library(xtable)
library(datamicroarray)
tab1 = xtable(describe_data(), label='microarray_data', caption ='Microarray datasets used in machine learning')
data('khan')
tab = xtable(head(khan[[1]], 5), label='srbct', caption='Small round blue-cell tumour data sample (Khan, 2001)')
print(tab)
```

The sample of the `SRBCT` data shown in Table \ref{tab:srbct} does not readily accommodate the wide table of this dataset. Unlike `iris`, the thousands of variables simply cannot be displayed on a page or screen. _Wide_ datasets are quite common in machine learning settings generally, but particularly common in genomics where in a given study there might only be a relatively small number of biological samples but a huge amount of sequencer or microarray data for each sample. This dimensionality of the data is common. Note too that while _Elements of Statistical Learning_ picks up the `SRBCT` dataset from biomedical research ([@Khan_2001] appears in the journal _Nature Medicine_), many other similar datasets appear in the machine learning literature. Table \ref{tab:microarray_data} shows some of the more commonly used cancer microarray data. The dimensions of the genomic data share this generic feature of width. Importantly, as discussed in Chapter 1 (in terms of the diagonalization running between different elements of code, data, mathematical functions and indexical signs) and in Chapter 2 (in terms of the auratic power of datasets), the fact that these datasets can be so readily loaded and accessed via bioinformatic infrastructures using code written in `R` or `Python` is also a notable feature of their advent in the machine learning literature.  The accessibility of genomic datasets is such that even a social science researcher can quickly write programs to retrieve this data. It attests to  several decades, if not longer, work on databases, web and network infrastructures, and analytical software, all, almost without exception, driven by the desire for aggregation, integration, archiving and annotation of sequence data that first became highly visible in the Human Genome Project of the 1990s.  The brevity of these lines of code -- half a dozen statements in `R`, no more -- suggests we are dealing with a high-sedimented set of practices, not something that has to be laboriously articulated, configured or artificed. Code brevity almost always signposts  highly-trafficked routes in contemporary network cultures. Without describing in any great detail the topography of databases, protocols and standards woven by and weaving through bioinformatics, the ready invocation of genomic datasets suggests that the mixed, dirty, wide datasets fed to algorithms such as RF-ACE or analysed in [@Hastie_2009] derives from the layered couplings and interweaving of scientific publications and scientific databases developed by biological science over the last three decades. As the code shows, sequence and other genomic data (and we will see some other types of contemporary genomic data below)  are available to scientists not only as users searching for something in particular and  retrieving specific data, but to scientists as programmers developing  ways of connecting up, gathering and integrating many different data points into to produce the wide ( many-columned), mixed (different types of data), and dirty (missing data, data that is 'noisy') datasets, datasets whose heterogeneous and often awkward topography then elicits and invites algorithmic treatment.

## Machine learning in genomics

Unlike the `iris` data, the `SRBCT` data is highly diagrammatic (see Chapter 1). That is, the columns refer to genes whose levels of expression in different samples are measured by comparison to their levels in a reference sample. The very identification of the several thousand genes whose levels of expression are measured by the microarray experiments already presupposes much preceding work on DNA sequences and their identification as genes. Highly leveraged infrastructures for access to biological data pervade such  datasets. Considered more diagrammatically, genomes in many  ways becomes less linear or flat than the base sequences might suggest. (Even these sequences themselves harbour, as we will see, probabilistic models). The linear sequences of DNA data becomes more mixed and wide partly through the accessibility we have just seen that allows them to be superimposed, annotated and layered. But their shape also changes for a different reason. A recent review in the journal *Genomics* highlights the increasing importance of machine learning techniques:

> High-throughput genomic technologies, including gene expression microarray, single Nucleotideide polymorphism (SNP) array, microRNA array, RNA-seq, ChIP-seq, and whole genome sequencing, are powerful tools that have dramatically changed the landscape of biological research. At the same time, large-scale genomic data present significant challenges for statistical and bioinformatic data analysis as the high dimensionality of genomic features makes the classical regression framework no longer feasible. As well, the highly correlated structure of genomic data violates the independent assumption required by standard statistical models[@Chen_2012, 323].

This kind of commentary on the changing shape, not just the volume, of genomic data is quite common. Such contrasts typically highlight the incompatibility between a surging multiplicity of data forms and the constraints of existing statistical modelling techniques ('standard statistical models'). First of all,  newer instruments or tools such as microarrays and faster sequencers (so-called 'next generation sequencers') loom large [@Mackenzie_2015c]. The tropes of waves, deluges, floods and waves of DNA sequence and microarray data being somewhat washed out, this account instead highlights the 'high dimensionality of genomic features' and the 'highly correlated structures of genomic data.'

The new ways of working with sequence data typically highlight changes in statistical or modelling approaches. So for instance, Chen and co-authors recommend the use of the random forest algorithm because it:

>is highly data adaptive, applies to “large p, small n” problems, and is able to account for correlation as well as interactions among features. This makes RF particularly appealing for high-dimensional genomic data analysis. In this article, we systematically review the applications and recent progresses of RF for genomic data, including prediction and classification, variable selection, pathway analysis, genetic association and epistasis detection, and unsupervised learning [@Chen_2012, 323]

The key terms on the machine-learning-side of this formulation are 'large p, small n', 'high dimensional', 'prediction', 'classification,' 'variable selection' and 'unsupervised learning.' While these terms are widely used in machine-learning research since the early 1990s,  they are becoming increasingly visible in genomics. The key terms on the genomics side of this formulation would perhaps be 'pathway analysis', 'genetic association,' and 'epistasis.' These biological terms point to forms of  relationality typically associated with biologically interesting processes. Epistasis for instance broadly refers to linked gene action, a process that has been difficult to study before high-throughput methods of functional genomics were developed. In contemporary genomic science, these biological processes are increasingly understood in terms of eliciting and modelling the relations between *features* of genomic datasets in order to classify and predict biological outcomes. In between the machine learning and the genomic references appear several statistical terms: 'correlation' and 'interaction.' How does machine learning differ from the statistical practice that has underpinned much of modern biology?

## Making the genome

'Genome assembly continues to be one of the central problems of bioinformatics' write the authors of a recent scientific review of the techniques of constructing whole genomes from DNA sequencer data. The primary 'object' in genomics is a genome, the full complement of DNA in an organism. Genomes vary in size from the 2000 DNA base pairs of a virus, the  3.2 Gb (gigabase pairs) of humans through to the 130 Gb of the lung fish. The founding presupposition of genomic science is that knowing the complete sequence of DNA potentially yields insight into biological processes of many different kinds, ranging from evolution (phylogeny), development (ontogeny), metabolism, structure and pathology. In all of these respects, the DNA sequences have since at least the 1980s served as the common substrate for many different scientific experiments, technical developments, cyber-infrastructures and needless to say, biological imaginaries.[^1.3] This presupposition has an ineluctably promissory aspect since prior to whole genome sequencing projects initiated in the 1990s, biologists had never worked with genomes only with selected DNA sequences, especially those associate with genes and the proteins that they code. 

[^1.3]: A large and very diverse social science and humanities literature now exists around genomics. I draw on some of that literature as general background here, especially [@Rajan_2008; @Thacker_2007; @Stevens_2011] and [@Haraway_1997], but largely do not address it directly.

While many earlier tabulations of variation, difference, groups, types and relations are woven through the life sciences, genomes have for the last several decades mesmerised biological sciences as a way of analysing and re-distributing the confused multiplicities associated with living things. As a data form, genomes are remarkably homogeneous. They are one-dimensional strings of letters corresponding to the well-known four nucleic acids (`g`, `a`, `t`, `c`). The raw data for genomes comes from the sequencing of DNA obtained from various organisms - viruses, bacteria, plants, fish, animals and humans. The sequencing of DNA, especially DNA that encodes the proteins that pervade biological processes, that structure tissues or assemble in complicated metabolic pathways, has been the concern first of molecular biology (mainly in the 1970s-1990s) and more recently  genomics (post-1990). In molecular biology, DNA sequences were carefully elicited (using the experimental techniques for instance of Sanger sequencing) and then compared with already known sequences of DNA to identify similarities that might have biology significance (for instance, evolution from a common ancestor). In genomics, DNA sequences generally originate from increasingly high-throughput sequencers that output massive datasets (see [@Stevens_2013; @Mackenzie_2015b]. Given both the accumulated store of already sequenced DNA and the increasingly viable practices of sequencing all of the DNA in a given organism together, genomics has  promised a much wider and more detailed understanding of biological complexity than any previous life science had been able to obtain. With genomes in hand, biologists for the first time would be in a position to build models of entire domains of biology, domains that previously could only be explored through painstaking experiments targeting specific cells, molecules, biochemical reactions and networks. The vast yet somewhat dispersed knowledges of the life sciences might be re-ordered and aligned on a new very extensive yet quite homogeneous  backbone of the genome read out as billions of DNA base pairs.  

Yet even the elementary data form of the genome as DNA base pairs is a highly algorithmic construct. The very existence of genomes as datasets  that can be downloaded in various forms presupposes their assembly from the fragments of DNA that all sequencing techniques actually process. No existing sequencing technology produces a genome as a dataset. Instead, sequencing produces randomly sets of sequence fragments of various lengths that have to be assembled into a complete genome algorithmically. Whole genome assembly as reported for the initial draft of the human genome in 2001 [@Venter_2001;@Lander_2001] or for the model biological organism, _Drosophila_ [@Myers_2000] were not the products of machine learning in any strict sense. But the problem of whole genome assembly from DNA fragments is probabilistic in the sense that the aim is to assemble the often millions of short sequence fragments in an order that is most likely to occur. Even prior the first full human genome assembly, genomic science had made heavy use of probabilistic models in aligning DNA (and protein amino acid) sequences.[^1.5] The practical problem here is that genomes contain swathes of duplicated regions that make assembling sequences in good  order a severe challenge. While sequence alignment algorithms have long used algorithmic approaches (known as dynamic programming) to score the similarity between two given DNA sequences, assembling the millions of DNA sequences produced by contemporary sequencers has necessitated entirely new techniques (shifting, for instance, from the overlap-layout-consensus model to the de Bruijn graph-based path models [@Pevzer_2001].

[^1.5]: Richard Durbin, Sean Eddy, Anders Krogh and Graeme Mitchison's highly cited _Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids_ [@Durbin_1998] was based almost entirely on hidden Markov Models, a way of modelling a sequence of states that _Elements of Statistical Learning_ treats at chapter length (see [@Hastie_2007, Chapter 17]) in the context of machine learning. While sequence alignment was regarded as a deeply algorithmic and statistical problem in the former volume, it is not at all formulated in the language of machine learning. There is little discussion of cost functions, vector spaces, optimisation, problems of generalization, supervised or unsupervised learning. On the other, David Haussler, a key bioinformatician in the first draft of the human genome in his work explicitly sought to bring  machine learning methods to bear on biology, and continues to do so.  

Despite the intensive work on genome assembly [see [@Henson_2012] for review), all genome assemblers produce errors. Put differently, whatever else might be known on the basis of the genome (genes, mutations, evolutionary relationships, variations associated with disease, heredity or individual identity), the genomic data and hence the genome itself as a scientific object is already deeply structured as a probabilistic model. The assemblers - the algorithmic process producing whole genomes from many fragments -- order sequences according to the same statistical criteria of maximum likelihood used in machine learning models. The rely heavily, moreover, on existing biological databases for reference or anchor points. No matter what assembly algorithm is used, the dependencies on other datasets and other knowledges, the perseverance of errors, and the deeply probabilistic texture of what counts as sequence data remain as key features of genomes. The indelible errors,  the entangled reliances on accumulated biological knowledges and above all this deeply probabilistic rendering of DNA as biological bedrock make genomes a particularly challenging site of machine learning activity.


## The expression of genomes in time

The broader point here is that genomes, as privileged and indeed somewhat singular contemporary scientific objects, were already the product not just of algorithmic or computational rendering, but of algorithms focused on the probabilistic  modelling of a form of linear order -- the sequence -- from which a plurality of processes (evolutionary diversity, ontogeny, metabolism, pathology, etc.) could be derived, typed, grouped, clustered or classified.  The inherently ordered fabric of genomes both bears the trace of something like machine learning (at least in the hidden Markov models used in sequence alignment), and yet occludes that constitution in its ubiquity as sequence data.

There are important differences between the construction of the genome as object of genomic sciences and say, the iris as presented in the `iris` dataset. But the differences and gaps between the genome as biological data and machine learning practice was developing during the 1990s are neither so great as to amount to profound separation nor so small as not to matter. Rather, the genome and machine learning as a knowledge practice began to articulate themselves on each other. 

The analysis of gene expression is symptomatic of this mutual articulation. On the one hand, the genome promises a read out of all the genes in a given organism (~20,000 for humans). On the hand, the activity of these genes in time, or any particular point in the development of an organism, cannot be read from the genome. The overt arrival of machine learning techniques in genomic research was initially largely concerned with this problem of the genes in time, and in fact, nearly all of the analysis of genomic data in _Elements of Statistical Learning_ explicitly deals with various domains of gene expression. 

How does the positivity of machine learning, its specific forms of accumulation and generalization impinge on something like gene expression?  Compared to the algorithmic craft seen in whole genome assembly [@Venter_2001; @Myers_2000; @Pevzner_2001], the handling of DNA-based data in machine learning settings can seem rather crude in their lack of biological referentiality and specificity. Hastie and co-authors say, 'we will not go into the scientific background here.' But in that case, what do they go into?

Like the authors of the original scientific study [@Khan_2001], machine learners treat gene expression profiling largely as a problem of classification. The many gene expression studies seek to discriminate between different conditions, diseases, or pathologies on the basis of differing levels of gene expression. For machine learners, each gene is a variable whose levels of expression in a given sample may help identify what type that sample belongs to. In the case of the `SRBCT` data, the types include lymphomas, sarcomas and neuroblastomas. The immediate problem is with the shape of the data, a shape that owes much to the great accumulation of knowledge associated with molecular biology, and that, as well will see, only becomes more problematic in the later proliferation of sequence data associated with whole genome sequencing.

'Since $p>> N$' write Hastie and co-authors, 'we cannot fit a full linear discriminant analysis (LDA) to the data; some sort of regularization is needed' [@Hastie_2009, 651]. Why cannot standard machine learners such as linear discriminant analysis fit here? What happens when they encounter the wide genomic datasets? 'Some sort of regularization' is needed they add. What is this regularization?  Michel Foucault describes the advent of disciplinary power partly in terms of enclosure or individualizing observation, but also in terms of techniques of supervising, examining and above all, _regularizing_ conduct. He writes:  

>Shift the object and change the scale. Define new tactics in order to reach a target that is now more subtle but also more widely spread in the social body. Find new techniques for adjusting punishment to it and for adapting its effects. Lay down new principles for regularizing, refining, universalizing the art of punishing [@Foucault_1977, 89] 

Foucault's description of the generalization of the techniques of disciplinary power, the formation that emerged in the late 18th century as a way of ordering 'massive or transient pluralities' (143) in Western European societies, resonates with contemporary treatments of data such as microarray gene expression. The 'target,' a term often used in machine learning to describe the type, group or response being modelled, in genomics is often subtle variations (in phylogeny, in pathogenesis), and these variations spread through and indeed define populations (in the sense of species, but also in the sense of the distributions of attributes that constitute the poles of abnormal and normal). Foucault's account of supervision (_surveiller_) and  penalisation as responses to 'popular illegality' [@Foucault_1977, 130] stresses the capillary network of observations, examining, ranking, test and gradation that adapt to the surging multiplicities by ordering them in tables. While the tables of data (see Table \ref{tab:srbct} in the microarray gene expression datasets suggest the persistence of the same technique of ordering multiplicities through partitioned observations, the _cells_ no longer target contain individuals under observation but focus on the  attributes of a multiplicity in movement, the human genome for instance in its many states and functions.  

'Shift the object and change the scale,' Foucault writes. 'Regularize in a way that automatically drops out features that are not contributing to the class predictions,' Hastie and co-authors write [@Hastie_2009, 652]. The new principles of regularizing in machine learning involve (as we have seen in Chapter 3) 'cost function' or techniques of penalization that suppress model complexity, that train models to eliminate features that yield only low predictive weight. In the many different techniques they then introduce -- diagonal linear discriminant analysis, nearest shrunken centroids, linear classifiers with quadratic regularization, regularized discriminant analysis, regularized multinomial logistic regression, support vector classifier -- essentially the same movement occurs as a model is fit. The coefficients or weights of parameters in the model, the $\beta_p$ values, are either reduced ($L_2$ regularization) or eliminated  ($L_1$ regularization) if they contribute little to the predictive accuracy of the machine learner. 

[HERE]

## GWAS and its problems

how are variations associated with individuals?

## Whole genome states

how is the whole repeating mass a functional process?


## Conclusion

I have been suggesting that the genomic data -- beginning with DNA sequences, then levels of gene expression, followed by genome wide association studies of small mutations, and finally by whole genome analyses -- has been a constant antigen in machine learning. Throughout the ongoing development and enrichment of DNA and protein datasets, replete with a vast and quite dynamic bioinformatic infrastructure, machine learning and genomics have been in a reciprocal embrace. For genomics, elementary practices of aligning and comparing sequences were re-configured probabilistically through machine learning models, and almost every development in genomics and related fields such as proteomics follows this pattern. It is hard to imagine contemporary biomedicine, biotechnology, pharmaceutical and environmental science research without this pattern. Some of the most elementary practices in contemporary genomics -- sequence alignment -- were already explicitly formulated as generative models to be constructed using algorithms such as expectation maximization. Cancer, in all its uncontrolled, diffuse and dangerously tumid concentrations, is the target of the most concerted ranking and typing treatments. As we see in the vignettes from  _Elements of Statistical Learning_, the demonstration of Google Compute cloud computing, or for that matter in the myriad publications in both machine learning  and life science journals that make use of support vector machines, neural networks, linear discriminant analysis or random forests, the positivity of machine learning establishes a new set of conditions for the exercise of scientific research, and configures new kinds of statements, new fields of objects (genomes in particular are difficult to conceive without their probabilistic modelling) and, as will be discussed in the next chapter,  subject positions (bioinformaticians, computational biologists, data scientists and others). 

There are different ways of making sense of the implication of machine learning  in genomic and post-genomic science. We might attend to the long-standing and still operative metaphors of DNA as code, program [@Kay_2000], communication system or network, to the rich and diverse development of information retrieval and database systems dedicated to retrieving and annotating biological data of many different kinds (the annual database issue of the journal *Nucleic Acids Research*  lists over 400), to the role of various kinds of system models in systems biology ([@Szallasi_2006]) and dynamic models in biology more generally, to the crucial role played by certain kinds of matching and alignment techniques in  sequencing [@Durbin_1998;@Stevens_2011], to the rise of bioinformatics as a bundle of techniques focused on  cross-linking sequences and annotations, or, stretching further afield, to the attempts to reconfigure DNA and RNA sequences as components that function like digital logic in synthetic biology. In the predictive models of epistasis in GWAS, in standardisation of the predictions of clinical outcomes using *k-nn* models in MACQ-II, and in the self-organizing map of genomic states in ENCODE, we glimpse a set of transformations that are changing the shape of genomic data,  and thereby how genomes matter and what they mean. These examples, while by no means trivial, are inevitably quite limited in their scope. Yet they are not isolated. There are many other such examples. We could look at the large body of work that seeks to elicit sub-types in relation to  diseases, disorder or traits from populations (for example, [@Watson_2007,3]). We could examine the processes of imputation of genotypes that play a key role in firming up the statistical power of GWAS to identify associations (for example, ([@Burton_2007])). 

All of these planes and sites of tabulation and ranking are linked by the positivity of machine learning. Machine learning widely affects the forms of accumulation, the enunciative modalities, and the ordered multiplicities that constitute scientific knowledges. In the biosciences of the last two decades,  it seeks to disaggregate, compartmentalise and rank those aspects of genomes — their confused variations, their manifold spatial and temporal relationality in biological processes — that seem most distant and difficult to derive from the putatively fundamental, monolithic  and hence  tractable order of DNA  sequence data.  As we have seen in the various data excerpts above, that order is largely linear. DNA can be laid down in tracks or grids, aligned and annotated in multiple overlapping database records, but the problem is how this thickened linearity maps onto the  subtle, pervasive and transient forms of temporal and spatial re-shaping in life-forms.  In the feature-rich spaces countenanced by machine learning, we see attempts to embed manifolds in local regions, local linearities. Sometimes these local regions are regions of annotated DNA, as in the ENCODE examples, or non-linear interactions between sets of genes, as in the GWAS analysis of epistasis. At other times, these local regions are forms of life in a more general sense — clinical outcomes or diagnostic tests — as in MACQ-II.

I have emphasised on several occasions the common thread of what could be the termed the ‘genomic curse of dimensionality.’ The genomic sciences are based around the extraction, sorting and ordering of  DNA sequences. Machine learning practices, I have suggested,  begin to construct different dimensional spaces amidst the sequences, lines and tracks of genomes. What perhaps most vexes and animates post-genomic science is the desire to separate out from the DNA sequences variations that matter to both life-forms and forms of life. This vexation generates strenuous infrastructural, technical and conceptual attempts to reorganise and re-conceptualise what it is to know a genome. The machine learning techniques I have discussed  have begun to transform  bioinformatics and biostatistics. To understand machine learning as either as intensification of statistics, as hybridization of bioinformatics and statistics, or as the product of a reciprocal interactive convergence of biology and computing misses some of the important features of the reorganisation of genomics associated with these practices. It misses what machine learning brings from elsewhere to genomics, and it overlooks how the genome itself serves as a showcase, as we saw in the Google I/O demonstration,  of certain much wider transformations in the practices of anticipation and prediction. 

What is at stake in machine learning for post-genomic science or practices of knowing and predicting more generally? An analytical and an ethico-epistemic stake appear here. Foucault writes that 'we should distinguish carefully between _scientific domains_ and _archaeological territories_' [@Foucault_1972, 183]. If knowledge is what we can say within a given discursive formation, and knowledge has the status of knowledge by virtue of the practices that connects objects, field, subjects, statements, and institutions, then sciences are always localized within a field of knowledge that may exceed, and that may mutate in ways that alter resident sciences. Machine learning is just such a formation, I would suggest. Could we pose or address any normative questions by becoming aware of and articulating machine learning in practice  with greater clarity? Genomic science, in what it borrows from and in how it is affected from machine learning, displays some of the tendencies to reduce divergences and to corral differences typical of knowledge economies more generally. The philosopher of science, Isabelle Stengers writes:

>with the knowledge economy, we may have scientists at work everywhere, producing facts with the speed that new sophisticated instruments make possible, but that the way those facts are interpreted will now mostly follow the landscape of settled interests. … We will more and more deal with instrumental knowledge. (Stengers 2011:377)

As we see in the 600,000 cores of Google Compute applied to exploration of associations in cancer genomics using random forests, or the lasso applied to microarray SNP data,  machine learning rapidly produces facts.  Stengers suggests that the risk here is that divergence and unexpected forms of experimental result are somewhat diminished as a result. Machine-learning in genomics might produce a ‘self-organising map’ that poses questions following the 'landscape of settled interests' or *status quo*.  

The very justification for using such techniques is the inordinate difficulty of exploring the many dimensions of genomes otherwise. I have already hinted what I think is one core stake in these shifts. Genomes and genomics are touchstones for wider transformations in many sectors of science, industry, commerce, media and government susceptible to the imperatives of the knowledge economy. In contrast to some of these domains, where much that happens is obscured from view, the great virtue or genomic science is the relative openness of its workings and its dogged insistence on DNA as the generating set. The fact that data practices are relatively generic and accessible means that critical research into transformations associated with data and knowledge economies can accompany nearly every aspect of genomic practice. This is a forensic good. 

