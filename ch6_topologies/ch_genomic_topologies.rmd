
\chapter{ Re-scaling and shifting objects with machine learning}
\label{ch:genome}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  results='hide', warning=FALSE, message=FALSE, dev='pdf')
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
library(ggplot2)
library(stringr)
library(xtable)
options(xtable.comment = FALSE)
simpleCap <- function(x) {
    s <- strsplit(x, " |-")[[1]]
    return (paste(toupper(substring(s, 1,1)), tolower(substring(s, 2)), sep="", collapse=" "))
  }
```

The opening pages of _Elements of Statistical Learning_ present four vignettes  -- spam email classification, handwritten digit recognition, prostate cancer risk and 'DNA Expression Microarrays' --  and list five examples (document classification, image recognition, risk of heart attack, stock price prediction, risk factors for prostate cancer, and glucose estimates for diabetics) [@Hastie_2009, 1-7].  The last of the vignettes attracts a whole page colour figure -- a heatmap -- of microarray data [@Hastie_2009, 7][^6.22] \index{data!DNA microarray}.  DNA, genes, genomics and proteomics then more or less disappear from view for the next 503 hundred pages of the book (aside from a brief mention in the context of cross-validation), only to reappear somewhat suddenly in a discussion of unsupervised machine learning techniques (k-means, agglomerative and hierarchical clustering; Chapter 14, where the DNA microarray data is re-analysed using hierarchical clustering\index{machine learner!hierarchical clustering}), and then again, and much more resoundingly, in a final chapter (Chapter 18) new to the second edition of the book on 'High Dimensional Problems.' Apart from one example where the Hastie and co-authors develop a document classifier for their journal articles, every example in the added Chapter 18 comes from genomic science, a scientific field that largely begins to take a recognisable shape in the late 1990s as both sequence data and high-throughput DNA-analysis devices, particularly microarrays, become widely available. \index{genomics!importance in machine learning} Alongside spam filtering, image or handwriting recognition, genomic research into biological processes has a strongly referential effect on machine learning. It 'forms the place, the condition, the field of emergence, the authority to differentiate between individuals or objects, states of things and relations that are brought into play by the statement itself; it defines the possibilities of appearance and delimitation of that which gives meaning to the sentence, a value as truth to the proposition' [@Foucault_1992, 91]. \index{referential!entanglement}

This referential entanglement happens in several different ways. The first concerns what I earlier called data strain. \index{data!strain} Genome data volume inflates the common vector space. Genomics generates new versions of the now familiar problems of data dimensionality. It produces data whose abundance, diffusion, heterogeneity or impaction thwarts its examination, tabulation, and regulated circulation. Sometimes genomics data exhibits unusual mixtures of accumulation and sparsity. Clinical genomics in particular generates datasets that are lavishly furnished with 'features' but often quite meagrely supplied with clinical cases or 'observations'. In the shorthand typical of machine learning terminology, $p$ is larger than $N$: 'the number of features $p$ is much larger than the number of observations $N$, often written $p\gg N$' [@Hastie_2009, 649]. This strains statistical methods that rely on the 'Law of Large Numbers' [@Hacking_1990, 99-104], which holds that the accuracy of statistics tends to increase with more observations.  \index{statistics!Law of Large Numbers}

The second referential entanglement comes from the _positivity_ of genomes themselves. Since the early nineteenth century, biology and cognate disciplines have sought to know and understand problems of time, genesis, duration, activity and process in a very broad spectrum of living things. But contemporary genomics seeks to do so, as many commentators have noted, by concentrating and coalescing different operational, algorithmic and mathematical senses of function around the long DNA sequences comprising genomes (see chapter \ref{ch:function}). \index{posivity}. The primary 'object' in genomics is a genome, the full complement of DNA in an organism. Genomes vary in size from the 2000 DNA base pairs of a virus, the  3.2 Gb (gigabase pairs) of humans through to the 130 Gb of the lung fish. The founding premise of genomic science is that knowing the complete sequence of DNA potentially yields insight into biological processes of many different kinds, ranging from evolution (phylogeny), development (ontogeny), metabolism, structure and pathology. \index{function!biological} If nothing else, genome comparison promises insights into 3.8 billion years of evolution.  In all of these respects, DNA sequences have since at least the 1980s served as the common substrate for many different scientific experiments, technical developments, cyber-infrastructures and needless to say, biological imaginaries.[^6.3] The genomic premise has an ineluctably promissory aspect since prior to the whole genome sequencing projects initiated in the 1990s, biologists had never worked with genomes only with selected DNA sequences, especially those associate with genes and the proteins that they code. The genome, with all the many duplicated, redundant, and slightly varying patterns of DNA, bears the traces of long evolutionary in-mixation and  constitutes a massive functional process whose exquisite sensitivity to changing conditions -- a slight change in light reaching a leaf cascades can be traced in genomic functions  -- forms a limit case for any operational sense of function. The functioning of genomes symbolises  a deeply interconnected relationality in life sciences, and becomes the test case for the learning capacities of machine learners.[^6.12] 

As referential field for machine learning, genomes pose a problem of reference. DNA sequences exist in great abundance (in databases, and increasingly, from the cheaper and more compact sequencing technologies), yet even determining how DNA sequence fragments can be ordered in the genome -- let alone how they make sense as some biological function -- is much harder.  They are assembled as datasets via statistical models. \index{data!assembly} 'Genome assembly continues to be one of the central problems of bioinformatics' write the authors of a recent scientific review of the techniques of constructing whole genomes from DNA sequencer data [@Henson_2012]. Even the elementary data form of the genome as DNA base pairs is a highly algorithmic construct. No existing sequencing technology produces a genome as a single sequence, as a vector (in the sense described in chapter \ref{ch:vector}).  Instead, sequencing produces randomly sets of sequence fragments of various lengths that have to be assembled into a complete genome algorithmically. Whole genome assembly as reported for the initial draft of the human genome in 2001 [@Venter_2001;@Lander_2001] or for the model biological organism, _Drosophila_ [@Myers_2000] were not at the time understood as machine learning tasks. But the problem of whole genome assembly from DNA fragments was seen as  probabilistic in the sense that the aim is to assemble the often millions of short sequence fragments in an order that is most likely to occur. Even prior to the first full human genome assembly, genomic science had made heavy use of probabilistic models in aligning DNA (and protein amino acid) sequences.[^6.5] The practical problem here is that genomes contain swathes of duplicated regions that make assembling sequences in good  order a severe challenge. While sequence alignment algorithms have long used algorithmic approaches (known as dynamic programming) to score the similarity between two given DNA sequences, assembling the millions of DNA sequences produced by contemporary sequencers has necessitated entirely new techniques (shifting, for instance, from the overlap-layout-consensus model to the de Bruijn graph-based path models [@Pevzner_2001].

Despite the intensive work on genome assembly [see [@Henson_2012] for review), all genome assemblers produce errors. Put differently, whatever else might be known on the basis of the genome (genes, mutations, evolutionary relationships, variations associated with disease, heredity or individual identity), the genomic data and hence the genome itself as a scientific hyperobject \index{hyperobject!genome as} is deeply probabilistic. The assemblers - the algorithmic process producing whole genomes from many fragments -- order sequences according to the same statistical criteria of maximum likelihood used in machine learning models. The rely heavily, moreover, on existing biological databases for reference or anchor points. No matter what assembly algorithm is used, the dependencies on other datasets and other knowledges, the perseverance of errors, and the deeply probabilistic texture of what counts as sequence data remain as key features of genomes. The indelible errors,  the entangled reliances on accumulated biological knowledges and above all the deeply probabilistic rendering of DNA as biological bedrock make genomes a particularly challenging site of machine learning activity.

Hastie and co-author's invocation of DNA-related data, therefore, is no arbitrarily chosen example amidst the general proliferation of settings, domains, cases and examples typically found in machine learning pedagogy.  In multiple dimensions and directions, genomics -- the scientific project of operating on the whole DNA complement of organisms -- is a nearest neighbour, a tightly adjacent territory of machine learning even if relatively few machine learners have, to date, managed to work with whole genome sequence data. This relatively long-established proximity (at least 25 years, and perhaps more) of genomics and DNA-based data  is strategically important in the diagrammatic generalization or diagrammatization of  machine learning, in the processes whereby the diagrammatic forms configured around these techniques, with their specific forms of articulation, statement and making-visible, propagate into multiple, once-disparate settings.[^6.21] \index{diagram!diagrammatization!as generalization} Like social media platforms or retail spaces with their many visitors, genomes, I would suggest, provoke a multiplicity of  machine learners to bind to them like antibodies to an antigen (or an allergen). At the same time, machine learners profoundly re-configure the economically charged fields of biomedicine and biological research and generate new modes of action, accounting, testing, and examining biological processes (metabolism, development, disease), relations (species, evolutionary, commensual),  and functions (reproduction, digestion, photosynthesis, immunity, circulation, etc.).  Wide-ranging infrastructural, institutional, professional and financial arrangements follow along new paths constructed by machine learning, with its epistopological transformations, its function-finding, its regimes of probabilistic, decisionistic and re-patterned engagement with data.

## The positivity of the genome

```{r genome_in_ml}
q = 'select TI, PY, TC, DE, WC from basic_refs where PY >= 1990 order by TC desc limit 5000'
res = dbGetQuery(con, q)
res$DE = tolower(res$DE)
de = unlist(str_split(res$DE, '; '))
det = as.data.frame(sort(table(de), decreasing=TRUE), rowNames = NULL)
det$keyword = rownames(det)
colnames(det) = c('freq', 'keyword')
dtt = xtable(head(det,50), label = 'tab:top_keywords', caption = 'Most common author-supplied keywords from the 5000 cited research publications in machine learning, 1990-2015')
terms= read.csv('techniques.csv', header=FALSE)
colnames(terms) = c('keyword', 'technique')
techniques =terms$keyword[terms$technique=='y']
actual_topics  = det[-which(det$keyword %in% techniques)]
top_topics = as.data.frame(sort(table(actual_topics), decreasing=TRUE))
res$WC = tolower(res$WC)
wc = unlist(str_split(res$WC, '; '))
wct = as.data.frame(sort(table(wc), decreasing=TRUE), rowNames = NULL)
wct$keyword = rownames(wct)
colnames(wct) = c('freq', 'discipline')

wtt = xtable(head(wct,20), label = 'tab:top_discp', caption = 'The top 20 disciplines of the top 5000 cited research publications in machine learning, 1990-2015')
print(wtt, type='latex')
```

In research done on machine learning during 1990-2015, biology, and particularly molecular and then genomic biology, has a very high profile in the research publications. (See table \ref{tab:top_discp}.) After the leading machine learning disciplines (computer science, electronic engineering and statistics), molecular biology, genomics and bioinformatics attract most academic journal citations and publications associated with machine learning. Half of the most cited research literature has a biomedical or life science referentiality. This may be because genomes and human disease in particular, are premiere scientific hyperobjects like the human brain, dark matter, global climate or fundamental particles in contemporary sciences. \index{hyperobject} \index{genome!as hyperobject} But it might also be the case -- and I will pursue this line of argument here -- that genomes, with all their operational and functional complexity, takes shape in concert with machine learning. In terms of contemporary biological knowledge production, the transformation of biology into a data-intensive science  [@Hey_2009; @McNally_2012] is tightly entangled with machine learning in processes of cross-validation. \index{genomics!as cross-validation of machine learning}

In the generalization of machine learning, genomics and the genome referential mark a threshold of epistemologization. \index{referential!epistemologization! threshold of}  Genomes are both a challenge to the capacity of machine learning to produce scientific knowledge (as distinct from say the unstable commercial knowledge of a credit risk model), and a way of validating machine learning  as a life-death relevant knowledge practice. Genomes also provide the pretext for vectorizing infrastructural re-configurations such as computational clusters, grids, arrays and clouds. \index{vectorization!infrastructural} For instance,  the Google Compute Engine, a globally addressable ensemble of computers typical of recent distributed commercial computing architectures,  was briefly turned over to exploration of cancer genomics during 2012, and publicly demonstrated at the annual Google I/O conference. \index{Google!I/O Conference, 2012}  Midway through the demonstration, in which a human genome is visualized as a ring in 'Circos' form (see figure \ref:fig:circos} [@Krzywinski_2009]),  the speaker, Urs Hölzle, Senior Vice President of Infrastructure at Google 'then went even further and scaled the application to run on 600,000 cores across Google’s global data centers' [@GoogleInc.2012]. \index{Google!Google Compute Engine} The audience clapped as the annular diagram of a human genome was decorated with a rapidly increasing number of cross-links, accompanied by a snapping sound as it appeared. The world's '3rd largest supercomputer', as it was called by TechCrunch, a prominent technology blog,  'learns associations between genomic features' [@Anthony_2012]. Note the language of machine learning: it 'learns ... associations between features.' We are in the midst of many such demonstrations of 'scaling applications' of data in the pursuit of associations between 'features.'[^6.0]

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/circos.pdf}
        \caption[A human genome diagrammed using the Circos]{A human genome diagrammed using the Circos form. The many tracks of this diagram support a range of graphic forms including scatterplots, heatmaps and histograms all anchored to the ideogram of the 23 chromosomes of the human genome. }
  \label{fig:circos}
\end{figure} \index{graphic!Circo diagram}

The I/O conference audience, largely comprising software developers, could hardly be expected to have a detailed interest in what was being shown on the screen. Their interest was steered toward the immediate availability of  computing power: from 10,000 to 600,000 cores in a few seconds. Such drastic infrastructural re-scaling attests to the provocative form of the genomic referential. The principal chain of associations validated by the genomics demonstration was, presumably, something more indexical: genome=>complexity=>cancer/disease=>life/death=>important. Yet the Google Compute demonstration is, I would suggest, typical of how genomes, genes, proteins and biological sciences more generally, have supply positivity to machine learning \index{positivity}. This positivity is only  hinted at in the Google I/O keynote address in Hölzle's talk of genomic features, gene expression and patient attributes.  The only concrete indication of how what was happening in the demonstration related to machine learning  was one mention of the RF-ACE (Random Forest- Artificial Contrasts with Ensembles) algorithm.  Google's press release emphasises epistemic values:

>it allows researchers to visually explore associations between factors such as gene expression, patient attributes, and mutations - a tool that will ultimately help find better ways to cure cancer. The primary computation that Google Compute Engine cluster performs is the RF-ACE code, a sophisticated machine learning algorithm which learns associations between genomic features, using an input matrix provided by ISB (Institute for Systems Biology). When running on the 10,000 cores on Google Compute Engine, a single set of association can be computed in seconds rather than ten minutes, the time it takes when running on ISB’s own cluster of nearly 1000 cores. The entire computation can be completed in an hour, as opposed to 15 hours [@GoogleInc.2012].

Amidst this mire of fairly technical computing jargon, we might observe that Google applies an algorithm developed by engineers at Intel Corporation and Amazon to genomic datasets provided by the Institute of Systems Biology, Seattle, a doyen of big-data genomics. The RF-ACE algorithm (a further development of Breiman's random forests discussed in chapter \ref{ch:pattern}) literally re-draws a diagram of the genome, and re-draws it increasingly rapidly as the demonstration scales up to 10,000 cores (or CPUs). \index{machine learner!RF-ACE}  A diagram that normally appears statically on-screen or on the printed page of a scientific publication is now animated by an algorithmic process. This confluence of commerce (Amazon), industry (Intel), media (Google) and genomic science (ISB) exemplifies the diagrammatic generalization of machine learning.

In none of these demonstrations and examples, whether they come from _Elements of Statistical Learning_ or from Google Compute Engine, does the object of the knowledge -- genomes, genes, proteins -- need to figure in terms of its original discipline or scientific field (typically cancer biology). The de-coupled 'positivity' of the genome,  to use Michel Foucault's term from _The Archaeology of Knowledge_, functions as a matrix from which propositions are generated. \index{positivity!as basis of propositions} As Foucault writes:

>To analyse positivities is to show in accordance with which rules a discursive practice may form groups of objects, enunciations, concepts, or theoretical choices. The elements thus formed do not constitute a science, with a defined structure of ideality; their system of relations is certainly less strict; but neither are they items of knowledge piled up one on top of another, derived from heterogeneous experiments, traditions, or discoveries, and linked only by the identity of the subject that possesses them. They are that on the basis of which coherent (or incoherent) propositions are built up, more or less exact descriptions developed, verifications carried out, theories deployed. They form the precondition of what is later revealed and which later functions as an item of knowledge or an illusion, an accepted truth or an exposed error, a definitive acquisition or an obstacle surmounted [@Foucault_1972, 181-2]

In the case, the positivity of RF-ACE and its scaled-up demonstration on Google Compute consists in the system of relations it groupwise assembles between cancer patients, vectorised infrastructures and predictive classifications. Similarly, the treatment of DNA microarray data in the slightly earlier examples found in _Elements of Statistical Learning_ does not principally concern cancer biology as such, but much more the way a group of elements are assembled so as to permit the production of propositions that cross the threshold of scientificity if configured in relation to experimental practices and scientific literatures, but may just as well posit different forms of governmental, market-focused, organisational or managerial operations.[^6.9]


## The advent of 'wide, dirty and mixed' data

The plurality of applications can sometimes make it seem that machine learning docks in the different domains, and then proceeds to administer learning algorithms to existing knowledges practices wherever it finds them. The law of generalization here would seem to be an epistemic _terra nullius_ doctrine, in which existing knowledge titles are rapidly extinguished by  algorithmic processes. We have seen previously that ancestral communities of probabilisation orient the generalization of machine learning (see chapter \ref{ch:probability}). The research literature published on machine learning since the early 1990s clusters around several main problems -- image recognition, document classification, and segmenting market behaviour (as in, working out what advertisement to show, or whether someone is likely to a buy a particular product, etc.). These problems position machine learning amidst regimes of visibility,  the production of economic value, and the regularities of statements (or put in more Foucaultean terms, amidst life, labour and language; see [@Foucault_1992]). Where, amidst these major regularities, does molecular biology or genomics (arguably the successor of molecular biology) fit? Almost all of the major  machine learners, albeit supervised or unsupervised, discriminative or generative, parametric or non-parametric, substantial research activity during the last two or so decades cross-validate their statements with genomics. \index{cross-validation!referentiality of} (The difference between the first and second editions of  _Elements of Statistical Learning_ attests to that tendency.) 

We can see this cross-validation at work in the treatment of genomic data in _Elements of Statistical Learning_. As to the former problem of dimensionality, both the RF-ACE cancer biology demonstration and  the DNA microarray data extensively modelled in the final chapter of  _Elements of Statistical Learning_ address some elementary problems associated with genomic data. If we turn back to the `iris` dataset [@Fisher_1936], perhaps the most heavily used pedagogical dataset in the literature, it is strikingly obvious that the data does not provoke the infrastructural contortions associated with Google Compute, or for that matter, the highly sophisticated and quite subtle treatment of gene expression we find in genomics-related machine learning. 

```{r iris, echo=FALSE, message=FALSE, cache=TRUE,  fig.cap ="Fisher's iris dataset, 1936",comment=NA, size='smallsize'} 
    library(xtable)
	data(iris)
    tab = xtable(iris[1:5,], label='iris_sample', caption="First 5 rows of Fisher's `iris` dataset")
	print(tab)
```

It is usual, in working with `iris,` to construct machine learners that use the variables from the first four columns shown in \ref{tab:iris_sample} to infer the value of the `Species` variable (as seen in Chapter 5, where a decision tree was constructed using this same dataset). The measurements of petals and sepals of the irises of the Gaspé Peninsula in Novia Scotia, and their classification into different species is perhaps a typical mid-twentieth century biological procedure. The technique of linear discriminant analysis that Fisher demonstrated as a way of classifying the species of iris continues in use, but the shape and texture of contemporary datasets differs greatly from what we see in this table. Even in the excerpt shown in Table \ref{tab:iris_sample}, we can see that it is quite narrow as it has only a few columns, the data is nearly all of one type (measurements of lengths and widths), and the data is clean (there are no missing values). The data is tightly contained in the table. `Iris` is typical of classic statistics, and much  biological data prior to genomics in its relatively homogeneity and distinct partitioning. \index{dataset!iris}

If `iris` is the conventional form, how does a genomic dataset differ? One clue comes from descriptions of the RF-ACE algorithm, first published in 2009. RF_ACE is attempts to  deal with 'modern data sets' that are 'wide, dirty, mixed with both numerical and categorical predictors, and may contain interactive effects that require complex models' [@Tuv_2009, 1341]. Such algorithms and the 'wide, dirty, mixed' datasets they work on have a distinctive texture, which, I would suggest,  we should try to grasp if we want to understand how genomic data has become a lightning rod for machine learning. More clues come from the various treatments of DNA microarray data in _Elements of Statistical Learning_. \index{data!wide, dirty, mixed}  Hastie and co-authors introduce one microarray dataset they use in this way:

>The data in our next example form a matrix of 2308 genes (columns) and 63 samples (rows), from a set of microarray experiments. Each expression value is a log-ratio log(R/G). R is the amount of gene-specific RNA in the target sample that hybridizes to a particular (gene-specific) spot on the microarray, and G is the corresponding amount of RNA from a reference sample. The samples arose from small, round blue-cell tumors (SRBCT) found in children, and are classified into four major types: BL (Burkitt lymphoma), EWS (Ewing’s sarcoma), NB (neuroblastoma), and RMS (rhabdomyosarcoma). There is an additional test data set of 20 observations. We will not go into the scientific background here [@Hastie_2009, 651]

Note that while the number of samples (~80) in the small round blue-cell tumors (`SRBT`) [@Khan_2001]  dataset is less than the number of flowers measured in `iris,` the number of variables presented by the columns in the table (2308) is much greater. \index{dataset!SRBCT} Hastie and co-authors, like the Google I/O demonstration,  do not 'go into the scientific background.' Scientific knowledge _per se_ is not the central concern in machine learning. Rather, but the positivity of knowledge is important.\index{science!knowledge!positivity of} The original publication of this dataset in 2001 [@Khan_2001] also made use of machine learning techniques (neural networks, a major topic in the next chapter \ref{ch:subjects}), but precisely in order to address the diagnostic difficulties of distinguishing different types of such tumors without resort to new experiments or biological knowledge.[^6.1]

```{r microarray, results='asis'}
library(xtable)
library(datamicroarray)
tab1 = xtable(describe_data(), label='microarray_data', caption ='Microarray datasets used in machine learning')
data('khan')
tab = xtable(head(khan[[1]], 5), label='srbct', caption='Small round blue-cell tumour data sample (Khan, 2001)')
print(tab, type='latex')
```

The sample of the `SRBCT` data shown in Table \ref{tab:srbct} does not readily accommodate the wide table of this dataset. Unlike `iris`, the thousands of variables simply cannot be displayed on a page or screen. _Wide_ datasets are quite common in machine learning settings generally, but particularly common in genomics where in a given study there might only be a relatively small number of biological samples but a huge amount of sequencer or microarray data for each sample. This wide dimensionality of the data is common. Note too that while _Elements of Statistical Learning_ picks up the `SRBCT` dataset from biomedical research ([@Khan_2001] appears in the journal _Nature Medicine_), many other similar datasets appear in the machine learning literature. Much genomic data shares this generic feature of width.[^6.70]

```{r srbct_cluster, echo=FALSE, message=FALSE}
    library(datamicroarray)
    data('khan')
    xtest = khan$x[-train,]
    ytest = khan$y[-train]
    pr.out = prcomp(khan$x, scale=TRUE)
    sd.data = scale(khan$x)
    data.dist = dist(sd.data)
    #cutting the dendrograms
    hc.out  =hclust(data.dist)
    hc.clusters =cutree(hc.out, 4)
    par(mfrow=c(1,2))
    plot(hclust(data.dist, method='complete'), labels=khan$y, main='complete', xlab='')
    hc.out2 = hclust(dist(pr.out$x[, 1:5]))
    plot(hc.out2, labels = khan$y, xlab='', main='Clustering of principal components')
    dev.off()
    km.out = kmeans(sd.data, 4, nstart=20)
    km.clusters = km.out$cluster
    table(km.clusters)
```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/filename.pdf}
        \caption{Hierarchical clustering of the SBRCT gene expression data}
  \label{fig:sbrct_clust}
\end{figure}

In contrast to the `iris` data, the `SRBCT` data becomes more highly diagrammatic in the sense that it both occludes and diagonally connects many levels of practice. \index{datasets!diagrammatic character of} The columns in table \ref{tab:sbrct}  refer to genes whose levels of expression in different samples are measured by comparison to their levels in a reference sample. Similarly, the hierarchical clusterings of the data shown in figure \ref{fig:sbrct_clust} The very identification of the several thousand genes whose levels of expression are measured by the microarray experiments presupposes much preceding work on DNA sequences and their identification as protein-coding DNA amidst the highly repetitive vector of the genome sequence. Highly leveraged infrastructures for access to biological data underpin such  datasets. Considered more diagrammatically, genomes in many  ways becomes less linear or flat than the base sequences might suggest. (Even these sequences themselves harbour, as we will see, probabilistic models). The linear sequences of DNA data becomes more mixed and wide partly through the accessibility we have just seen that allows them to be superimposed, annotated and layered. A recent review in the journal *Genomics* highlights the increasing importance of machine learning techniques:

> High-throughput genomic technologies, including gene expression microarray, single Nucleotideide polymorphism (SNP) array, microRNA array, RNA-seq, ChIP-seq, and whole genome sequencing, are powerful tools that have dramatically changed the landscape of biological research. At the same time, large-scale genomic data present significant challenges for statistical and bioinformatic data analysis as the high dimensionality of genomic features makes the classical regression framework no longer feasible. As well, the highly correlated structure of genomic data violates the independent assumption required by standard statistical models[@Chen_2012, 323].

This kind of commentary on the changing shape, not just the volume, of genomic data is quite common. Such contrasts typically highlight the incompatibility between a surging multiplicity of data forms and the constraints of existing statistical modelling techniques ('standard statistical models'). Newer instruments or devices such as microarrays and faster sequencers (so-called 'next generation sequencers') loom large [@Mackenzie_2015c]. The tropes of waves, deluges, floods and waves of DNA sequence and microarray data being somewhat washed out, this account instead highlights the 'high dimensionality of genomic features' and the 'highly correlated structures of genomic data.'

## Regularizing machine learning in genomics

Machine learners working with sequence data typically highlight changes in statistical approaches. So for instance, Chen and co-authors recommend the use of the random forest (RF) algorithm because it:

>is highly data adaptive, applies to “large p, small n” problems, and is able to account for correlation as well as interactions among features. This makes RF particularly appealing for high-dimensional genomic data analysis. In this article, we systematically review the applications and recent progresses of RF for genomic data, including prediction and classification, variable selection, pathway analysis, genetic association and epistasis detection, and unsupervised learning [@Chen_2012, 323] \index{machine learner!random forest!use in genomics}

Familiar machine learning keywords such as  'large p, small n', 'high dimensional', 'prediction', 'classification,' 'variable selection' and 'unsupervised learning' pepper their recommendations. While these terms are widely used in machine-learning research since the early 1990s,  they are becoming increasingly visible in genomics. The key terms on the genomics side of this formulation would perhaps be 'pathway analysis', 'genetic association,' and 'epistasis.' These biological terms point to forms of  relationality typically associated with biologically interesting processes. Epistasis for instance broadly refers to linked gene action, a process that has been difficult to study before high-throughput methods of functional genomics were developed. In contemporary genomic science, these biological processes are increasingly understood in terms of eliciting and modelling the relations between *features* of genomic datasets in order to classify and predict biological outcomes. In between the machine learning and the genomic references appear several statistical terms: 'correlation' and 'interaction.' How does machine learning differ from the statistical practice that has underpinned much of modern biology?

The change concerns a mutual articulation between genomic and machine learning research. The analysis of `SRBCT` gene expression in _Elements of Statistical Learning_ (as introduced above) is symptomatic of this mutual articulation, a cross-validation that epistemologizes both genomics and machine learning. \index{referential!epistemologization!threshold of}  On the one hand, the genomics promises a read out of all the genes in a given organism (~20,000 for humans). On the hand, the pattern of activity of these genes in time, or any particular point in the life of an organism, cannot be read from the genome but only in time-varying expression, the changes in state and the variations in closely similar genomes. The overt arrival of machine learning techniques in genomic research was initially largely concerned with this problem of gene expression in time ( and in fact, nearly all of the analysis of genomic data in _Elements of Statistical Learning_ explicitly deals with various cases of gene expression). \index{dataset!SRBCT}

Compared to the algorithmic craft seen in whole genome assembly [@Venter_2001; @Myers_2000; @Pevzner_2001], the handling of DNA-based data in machine learning settings can seem rather crudely  lacking in biological specificity. Hastie and co-authors almost deprecate scientific knowledge: 'we will not go into the scientific background here.' Like the authors of the original scientific study [@Khan_2001], _Elements of Statistical Learning_  treats gene expression profiling largely as a problem of classification. The many gene expression studies seek to discriminate between different conditions, diseases, or pathologies on the basis of differing levels of gene expression. For machine learners, each gene is a variable whose levels of expression in a given sample may help identify what type that sample belongs to. In the case of the `SRBCT` data, the types include lymphomas, sarcomas and neuroblastomas. 

The shape of the data, a shape that owes much to the great accumulation of knowledge associated with molecular biology, immediately poses problems. This shape, as well will see, only becomes more problematic in the later proliferation of sequence data associated with whole genome sequencing. 'Since $p\gg N$' write Hastie and co-authors, 'we cannot fit a full linear discriminant analysis (LDA) to the data; some sort of regularization is needed' [@Hastie_2009, 651]. \index{machine learner!linear discriminant analysis!not applied to gene expression} Why cannot standard machine learners such as linear discriminant analysis fit here? What happens when machine learners encounter wide genomic datasets? 'Some sort of regularization' is needed they add. \index{machine learning!regularization in}

What is this regularization? Like the re-distribution of randomness into a population of machine learners (see chapter \ref{ch:probability}, regularization governs an potentially unruly plurality through a form of observation.   Michel Foucault describes the advent of disciplinary power partly in terms of enclosure or individualizing observation, but also in terms of techniques of supervising, examining and above all, _regularizing_ conduct. He writes:  

>Shift the object and change the scale. Define new tactics in order to reach a target that is now more subtle but also more widely spread in the social body. Find new techniques for adjusting punishment to it and for adapting its effects. Lay down new principles for regularizing, refining, universalizing the art of punishing [@Foucault_1977, 89] 

Foucault's description of the generalization of the techniques of disciplinary power, the formation that emerged in the late 18th century as a way of ordering 'massive or transient pluralities' (143) in Western European societies, seems a long way from microarray gene expression data. \index{Foucault, Michel!disciplinary power} \index{machine learning!regularization in} Yet the data in many genomic and other settings (transactions, social media, etc.) displays some of the traits -- massive, transient, plural -- that Foucault identifies as key targets of regulation for the operations of disciplinary power. The 'target,' a term often used in machine learning to describe the type, group or response being modelled, in genomics is often subtle variations (in phylogeny, in pathogenesis), and these variations are widely dispersed in genomic data and the populations it stems from.  Foucault's account of supervision (_surveiller_) and  penalisation as responses to 'popular illegality' [@Foucault_1977, 130] stresses the capillary network of observations, examining, ranking, test and gradation that adapt to the surging multiplicities by ordering them in tables. While the tables of data (see Table \ref{tab:srbct} in the microarray gene expression datasets suggest the persistence of the same technique of ordering multiplicities through partitioned observations, the _cells_ no longer target contain individuals under observation but focus on the  attributes of a multiplicity in movement, the human genome for instance in its many functional states.  

'Shift the object and change the scale,' Foucault writes, in describing how partitions, segmentations, forms of enclosure, and above all, ranked classifications: 'discipline is an art of rank, a technique for the transformation of arrangements' [@Foucault_1977, 145]. \index{classification!as ranking} 'Regularize in a way that automatically drops out features that are not contributing to the class predictions,' Hastie and co-authors write [@Hastie_2009, 652] in describing how they deal with some of the problems of too many variables in the microarray datasets. The new principles of regularizing in machine learning involve (as we have seen in chapter \ref{ch:function}) 'cost functions' or techniques of penalization that suppress model complexity, and that train models to eliminate features that yield only low predictive weight. In the many different techniques that _Elements of Statistical Learning_ brings to bear on the problem of gene expression -- diagonal linear discriminant analysis, nearest shrunken centroids, linear classifiers with quadratic regularization, regularized discriminant analysis, regularized multinomial logistic regression, support vector classifier -- essentially the same ordering movement occurs as a model is fit. Regularization re-scales the hyperobject --  the patterns of expression of genes associated with different types of tumours -- by shrinking or dropping the weights of parameters of each gene in the model and examining the effect on the predictions that result. The coefficients or weights of parameters in the model, the $\beta_p$ values, are either reduced ($L_2$ regularization) or eliminated  ($L_1$ regularization) if they contribute little to the predictive accuracy of the machine learner. Learning here takes the form of regularization. \index{machine learning!regularization} 

The somewhat daunting *optimization function* for  one commonly used machine learning technique  called 'lasso regression' is frequently used in genomics. It displays features that might help us grasp how machine learners traverse genomic data. Remember that the linear regression model with its diagonal line or plane running through common vector space provides the underlying intuition for many machine learners. We have seen the function in Equation \ref{eq:lineary_model} several times already in different variations, including logistic regression used for classification of types or groupings.

\begin {equation}
\label {eq:linear_model4}
\hat{Y} = \hat{\beta_0}  + \sum^p_{j=1} X_j \hat{\beta_j}
\end{equation}

In gene expression models, the values of $\beta$ shown in equation \ref{eq:linear_model4} map on to the different levels of expression of the many genes indexed by the columns of the microarray dataset. The model tests whether different patterns of gene expression associated with different tumour types. As we have already seen, the number of combinations of genes associated with different tumour types vastly outweighs the number of samples. Regularization is the process of removing or eliminating many of the possible combinations by limiting the values of $\beta$ that contribute little to the prediction. This is a kind of 'shifting' or 're-scaling' of the object through a training technique. How does this training take place?

The regularized version of the linear regression framework known as 'lasso' -- Least Absolute Shrinkage and Selection Operator --  hinges on the lasso penalty shown in equation \ref{eq:lasso}[^6.7] \index{machine learner!Least Absolute Shrinkage and Selection Operator} 


\begin {equation}
\label {eq:lasso}
\widehat{\beta}^{lasso} = argmin_\beta\left\{ \frac{1}{2}\sum_{i}^{N}{(y_i - \beta_0 - \sum_{j=1}^{p}{x_{ij}\beta_j})^2}+ \lambda \sum_{j=1}^{p} \vert \beta_j \vert \right\}.
\end{equation}
>>	[@Hastie_2009, 68]

Equation \ref{eq:lasso} is notable for the way that it subjects the familiar 'residual sum of squares' way of calculating the coefficients to the 'penalty' carried by the last part of the equation $\sum\limits_i^p\vert\beta_j\vert$. \index{machine learner!Ordinary Least Sum of Squares} As Hastie and co-authors write, 'the lasso does a kind of continuous subset [feature] selection' [@Hastie_2009, 69]. As always $argmin_\beta$ suggests that the algorithm should find the set of values for $\beta$ that minimize the overall value of the function. This is a balancing act in this case between reducing the sum of residuals shown in the first half of the equation, and minimizing the sum of the absolute values of $\beta_j$ in the second part of the function. The overall movements of this feature selection are not difficult to understand, but the point is that the re-shaping of the object proceeds along a diagonal line drawn as the algorithm gradually introduces and scales all of the features in the common vector space $\mathbf{X}$, only allowing those variables or features to remain in the set that help minimize the difference between the predicted response and the actual response. \index{diagrammatic!diagonal} Figure \ref{fig:lasso} makes something of this scaling diagrammatically visible. In this diagram, the various diagonal lines show how values of coefficients grow and sometimes diminish as the `lasso` process runs. Vertical lines show steps as new variables are included in the model with different values of the control parameter $\lambda$. 


```{r lasso, fig.show='hide', echo=FALSE, message=FALSE, warning=FALSE, fig.cap='', dev='pdf', cache=TRUE}
library(lars)
library(datamicroarray)
data(golub)
y = ifelse(golub$y=='ALL', TRUE, FALSE)
l1 = lars(x = golub$x, y, use.Gram=FALSE)
plot(l1, main='')
```

\begin{figure}
  \centering
      \includegraphics[width=1.0\textwidth]{figure/lasso-1.pdf}
        \caption{Shrinkage path of coefficients for Lasso regression on (Golub,1999) leukemia data}
  \label{fig:lasso}
\end{figure}

This intensive testing and selection of features results sometimes radically changes the object. In Figure \ref{fig:lasso},  these changes become a matter of diagrammatic observation. Comparing eight different methods for analyzing the microarray cancer data from [@Ramaswamy_2001], Hastie reports that 'lasso regression (one versus all)' selects 1,429 of the 16,063 genes in the dataset. The shifted-rescaled object, a set of 1400 genes, or in the case of the 'elastic-net penalized multinomial' model that uses only 384 genes, highlights a drastically reduced subset of the original object. 

## The proliferation of discoveries

Despite all the penalization and regularization, machine learning does not stabilise genomes as data objects. In many ways, it gives rise to further difficulties, new sources of error and sometimes new transformations of objects.[^6.401] If on the one hand, machine learners offer to regularize transient multiplicities (such as epistasis in complex genetic disorders), the observation and supervision of machine learners themselves has become necessary in order to validate and normalize their power in clinical practice, in diagnostic settings or in drug research. Within genomics  itself, machine learning figures as a way of correcting for the fact that genomic instruments often produces different results or that genomic knowledge claims shift unpredictably. 

For instance, since microarray data itself suffers from many such problems of variation, the US Food and Drug Administration has since 2003 conducted a study of data analysis techniques for microarrays:  

>The US Food and Drug Administration MicroArray Quality Control (MAQC) project is a community-wide effort to analyze the technical performance and practical use of emerging biomarker technologies (such as DNA microarrays, genome-wide association studies and next generation sequencing) for clinical application and risk/safety assessment [@Parry_2010, 292].

Phase I of the US Federal Drug Administration-led MACQ addressed many issues of data analysis in the context of the clinical applications of gene expression analysis using microarrays. The primary statistical issue there was minimizing the ‘false discovery rate’ [@Slikker_2010,S1], a typical biostatistical problem. In MACQ-II however the focus rested on the construction of predictive models for ‘toxicological and clinical endpoints … and the impact of different methods for analyzing GWAS data’ [@Slikker_2010, 2]. On both the clinical and GWAS fronts, the 36 participating research teams tried out many predictive classifier models. Different machine learning techniques generate different kinds of models, genomic and biomedical researchers are compelled to engage with the many variations in the data. \index{data!variations} \index{dataset!MACQ-II}

\index{machine learner!_k_ nearest neighbours (KNN)} Yet, as we have seen, machine learners themselves juggle major sources of errors (for instance, in the bias-variance tradeoff). In the shift from MACQ-I to MACQ-II, the problem of variations in the predictions produced by the machine learning models moved to center-stage.  The problem of variation arises not because any of the different modelling strategies used in machine learning gene expression datasets are wrong or erroneous, but because every model moves through the ‘feature space’ [@Parry_2010,292] in a different way (as we saw in chapter \ref{ch:pattern}  in discussions of different treatments of dimensionality). In the MACQ-II consortium, the teams were tasked to build 'classifiers' to predict whether a given sample or case belongs to a 'normal' or 'disease' group.  The most popular classifier in the MACQ consortium was the _k_ nearest neighbours model: '[a]mong the 19,779 classification models submitted by 36 teams, 9742 were k-nearest neighbor-based (KNN-based) models (that is, 49.3% of the total) [@Parry_2010, 293]. But, these models varied greatly in their predictions: 'there have been large variations in prediction performance among KNN models submitted by different teams' (293). Not only the genome itself varies, but the machine learners vary. \index{machine learning!error!bias-variance}

What accounts for this variation? First of all, the 33 teams did not build single models. As is the norm in machine learning, they built thousands.  In their attempt to normalise the variations of  their models, one of the research groups in MACQ-II write that ‘for clinical end points and controls from breast cancer, neuroblastoma and multiple myeloma, we systematically generated 463,320 *k-nn* [*k*-nearest neighbour] models by varying feature ranking method, number of features, distance metric, number of neighbors, vote weighting and decision threshold’ [@Parry_2010,292].  The striking feature here is the proliferation of models in an effort to  tame the variations of predictive models. The number of predictive models constructed here rivals the number of SNPs typically assayed by the microarrays. It seems as if not only the dimensions of the data have vastly increased, but the population of models. All data analysis faces the so-called ‘curse of dimensionality’\index{common vector space!dimensionality!curse of} [@Hastie_2009,22], but genomic data is particularly 'cursed' by a high model dimensionality. 

## Variations in the object or in the machine learner: _k_ nearest neighbours models

\index{machine learner!_k_ nearest neighbours}
\begin{figure}
  \centering
      \includegraphics[width=0.99\textwidth]{figure/fix_hodges_excerpt.pdf}
        \caption{The earliest formulation of the _k_ nearest neighbours model from Eveln Fix and Joseph Hodges work [@Fix_1951]}
  \label{fig:fix_excerpt}
\end{figure}

'The method of k-nearest neighbors makes very mild structural assumptions: its predictions are often accurate but can be unstable' write Hastie and co-authors [@Hastie_2009, 23]. The algorithm, first described by Evelyn Fix\index{Fix, Evelyn} and Joseph Hodges working at Berkeley in the early 1950s [@Fix_1951], is extremely simple in mathematical terms.[^6.10] Equation \ref{eq:knn} shows almost the entire algorithm:


\begin {equation}
\label {eq:knn}
\hat{Y(x)} = \frac{1}{k}\sum_{x_i \in N_k(x)}y_i
\end {equation}

'where $N_k(x)$ is the neighbourhood of $x$ defined by the $k$ closest points $x_i$ in the training sample'[@Hastie_2009, 14]. The algorithm effectively takes the average values of points in the neighbourhood, and uses that value to predict the result for a given set of features. As Hastie and co-authors put it, the neighbourhood is just those $k$ points near the case under consideration. The assumption here, as in nearly all machine learners traversing the common vector-space, is that proximity implies similarity. This assumption was formally described in the late 1960s in another highly cited paper [@Cover_1967] on 'Nearest Neighbour Pattern Classification.' Neighbouring points in the vector-space are more similar than those at a distance.  As equation \ref{eq:knn} shows,  _k_ nearest neighbours seems to have only one parameter, the value $k$, the number of neighbours that a given model includes in its definition of a 'neighbourhood.' In contrast to the linear forms of the models (formulated in equations \ref{eq:lasso} or \ref{eq:linear_model}), equation \ref{eq:knn} seems to require little training, supervision or regularization to work as a classifier. While nearly all of the models I have discussed in this and earlier chapters still work with the smooth form of the line or curve as their basic way of separating or connecting, _k_ nearest neighbours models easily generate highly non-linear boundaries wending their way through the data. Because they are not guided by parameters (apart from the value of $k$), these boundaries can be unstable.  

```{r knn, fig.cap='', echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE, comment=NA, fig.show='hide'} 

	library(ElemStatLearn)
	require(class)
    k = c(2,5)
	x <- mixture.example$x
	g <- mixture.example$y
	xnew <- mixture.example$xnew
    
    train = sample(1:length(g), 40)
    xtrain = x[train,]
    ytrain = g[train]

	mod <- class::knn(train=x, test=xnew, cl=g, k[1], prob=TRUE)
	prob <- attr(mod, "prob")
	prob <- ifelse(mod=="1", prob, 1-prob)
	px1 <- mixture.example$px1
	px2 <- mixture.example$px2
	prob <- matrix(prob, length(px1), length(px2))

	mod_b <- class::knn(train=x, test=xnew, cl=g, k[2], prob=TRUE)
	prob_b <- attr(mod_b, "prob")
	prob_b <- ifelse(mod_b=="1", prob_b, 1-prob_b)
	px1_b <- mixture.example$px1
	px2_b <- mixture.example$px2
	prob_b <- matrix(prob_b, length(px1_b), length(px2_b))
    
	par(mar=rep(2,4), mfrow=c(1,2))
	contour(px1, px2, prob, levels=0.5, labels="", xlab="", ylab="", main=paste(k[1],"- nearest neighbour"), axes=FALSE)
	points(x, col=ifelse(g==1, "coral", "cornflowerblue"))
	gd <- expand.grid(x=px1, y=px2)
	points(gd, pch=".", cex=1.2, col=ifelse(prob>0.5, "coral", "cornflowerblue"))
	box()
	contour(px1_b, px2_b, prob_b, levels=0.5, labels="", xlab="", ylab="", main=paste(k[2],"- nearest neighbour"), axes=FALSE)
	points(x, col=ifelse(g==1, "coral", "cornflowerblue"))
	gd <- expand.grid(x=px1_b, y=px2_b)
	points(gd, pch=".", cex=1.2, col=ifelse(prob_b>0.5, "coral", "cornflowerblue"))
	box()

    
    data('khan')
    xtest = khan$x[-train,]
    ytest = khan$y[-train]
    mod_c = knn(khan$x, test = xtest, cl=khan$y, k[1], prob=TRUE)
    
    pr.out = prcomp(khan$x, retx = TRUE, center=TRUE,  scale=TRUE)
    sd.data = scale(khan$x)
	prob_c <- attr(mod_c, "prob")
	prob_c <- ifelse(mod_b=="1", prob, 1-prob)
	px1_b <- mixture.example$px1
	px2_b <- mixture.example$px2
	prob_b <- matrix(prob_b, length(px1_b), length(px2_b))
```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/knn-1.pdf}
        \caption[KNN models for simulated data in two classes]{KNN models for simulated data in two classes. The decision boundary that separates the two classes is non-linear for both versions of the KNN model. For $k=5$, the decision boundary is more non-linear than for $k=b$ }
  \label{fig:knn}
\end{figure}

\index{machine learner!k-nearest neighbours}

Most machine learning techniques embody some way of managing the dimensionality of the feature space, either by effectively reducing that dimensionality (as we saw in the lasso technique, which corrals the numbers of predictive features in the model), or concentrating on localised regions of the feature space, as does *k-nn*. For instance, the *k-nn* models — ‘k-nearest neighbour models’ — analyzed by Parry as part of MACQ-II are widely used because they are the simplest way of the dealing with interactions in an ‘exceedingly large feature space’ [@Parry_2010,292]. In *k-nn*, a training set of observations whose outcomes are known (e.g. clinical endpoints in cancer might be benign or malignant) are used to help classify (and hence predict) the test data.

As we can see from Figure \ref{fig:knn} above, in which data belongs to two classes (normal vs. not-normal), the decision boundaries produced by the algorithm can be unstable. The example shows two models, one for $k=5$ and the other for $k=b$.  Each model examines the relations between `r k` points in deciding whether a particular case belongs to one class or another.  While *k-nn*  finds local clusters and classifies on the basis of an irregular decision boundary, this classificatory power comes at the cost of instability. The more dimensions or features in the dataset, the larger the local neighbourhood needed to capture a fraction of the volume of the data,  and the more likely that most sample points will lie close to the boundary of the sample space, where they will be affected by the neighbouring space. The result is that ‘in high dimensions all feasible training samples sparsely populate the input space’ [@Hastie_2009, 23]. Because *k-nn* allows for non-linear interactions between features, for instance, small differences in the number of points in particular neighbourhoods can drastically affect the boundaries (as we see in comparing the right and left hand plots). These kinds of topological instability account for the propensity of machine learning treatments of feature-rich genomic data to produce accurate but unstable predictions.  We can also see why the MACQ-II team reported in [@Parry_2010] might have ended up  producing 463,000 _k_ nearest neighbour models in an effort to normalise and regulate predictive predictions.  The price of accurate predictivity in genomics is variation in prediction.

## Whole genome functions

Chip cores, SNPS, and models; infrastructural scaling, biological variation and the training of machine learners entwined in a referential entanglement. If genomes are scientific hyperobjects (with all the epistemic, speculative, financial and biopolitical resonances),  what part does machine learning play in the transformation of science?

>Science is concentrated in an area of knowledge it does not absorb and in a formation which is in itself the object of knowledge and not of science. Knowledge (savoir) in general is not science or a even a particular corpus of knowledge [@Deleuze_1988, 19]

I have been suggesting that the genomic data -- beginning with DNA sequences, then levels of gene expression, followed by genome wide association studies of small mutations, and finally by whole genome analyses -- has been a constant $p \gg N$ antigen in machine learning. It is no accident that the techniques of regularization -- the lasso -- of linear models discussed in this chapter came to light, and were first demonstrated on the genomic data produced in the mid-1990s. Throughout the ongoing development and enrichment of DNA and protein sequencing techniques, replete with a vast and quite dynamic bioinformatic infrastructure, machine learning and genomics have been in a reciprocal embrace. Scientists and statisticians traffic between genomics and machine learning at almost every level, ranging from the sequence assembly to testing and analysis of DNA data in clinical settings.  For genomics, elementary practices of aligning and assembling sequences into whole genomes were re-configured probabilistically through machine learning models. Almost every subsequent development in genomics and related fields such as proteomics follows this pattern: an entity whose constitution is thoroughly dependent on prediction or algorithmic classification displays variations and grouping (such as gene expression, the linkage disequilibrium of SNPs, the seeming abundance of junk DNA that is actually functioning, etc.) that attract further efforts to differentiate and classify ever more subtly distributed differences.  It is hard to imagine contemporary biomedicine, biotechnology, pharmaceutical and environmental science research without this pattern. Elementary practices in contemporary genomics such as sequence alignment were explicitly formulated as generative models to be constructed using algorithms such as expectation maximization. Cancer, in all its uncontrolled, diffuse and dangerously tumid concentrations, is the target of the most concerted ranking and typing treatments. As we see in the vignettes from  _Elements of Statistical Learning_, the demonstration of Google Compute cloud computing, or for that matter in the myriad publications in both machine learning  and life science journals that make use of support vector machines, neural networks, linear discriminant analysis or random forests, the positivity of machine learning establishes a new set of conditions for the exercise of scientific research, and configures new kinds of statements, new fields of objects (genomes in particular are difficult to conceive without their probabilistic modelling) and, as will be discussed in the next chapter,  subject positions (bioinformaticians, computational biologists, data scientists and others). \index{machine learning!positivity of}

The machine-learned models flow back through genomic science, reorganising and refocusing research, experiments, databases and funding in subtle but important ways. Between pre-genomic and post-genomic science, the status of significant differences in genomes shifted. Pre-HGP biology understood the significant differences between individual organisms largely in terms of gene alleles responsible for variations in phenotypes. Biological differences, and disease in particular, stemmed from different forms of genes. Understanding disease meant finding the disease genes. Even prominent proponents of genomics, such as Leroy Hood, writing of 'Biology and Medicine in the Twenty-First Century' in 1991, envisaged genomics as a way of simplifying 'the task of finding disease genes' [@Hood_1992,138]. Across the life sciences, genes were the object of much way of annotation, labelling and description. Two decades after the inception of whole genome sequencing, genomes present a different image of variation. According to Nikolas Rose, writing more recently, ‘there is no normal human genome; variation is the norm’ [@Rose_2009, 75]. ‘In this new configuration’, he writes, ‘what is required is not a binary judgment of normality and pathology, but a constant modulation of the relations between biology and forms of life, in the light of genomic knowledge.’ The emphasis in Rose’s formulation falls on ‘constant modulation’ of the relations between biology and forms of life. If post-genomic science departs from the understanding that there is no single genome but many genomes, then according to Rose, variation itself becomes of primary interest. Pursuit of variation remakes the genome into ‘a form whose only object is the inseparability of distinct variations’ [@Deleuze_1994, 21]. 

Machine learning widely affects the forms of accumulation, the enunciative modalities, and the ordered multiplicities that constitute scientific knowledges. In the biosciences of the last two decades,  it seeks to disaggregate, compartmentalise and rank those aspects of genomes — their confused variations, their manifold spatial and temporal relationality in biological processes — that seem most distant and difficult to derive from the putatively linear, monolithic  and hence  tractable order of DNA  sequence data. \index{data!sequence} As we have seen in the various data excerpts above, that order is largely linear. DNA can be laid down in tracks or grids, aligned and annotated in uniquely addressable database records, but the problem of how this extensive vector maps onto the  subtle, pervasive and transient forms of temporal and spatial re-shaping in life-forms remains.  None of the examples of genomic data in _Elements of Statistical Learning_ use whole genome sequences.  In the feature-rich spaces countenanced by machine learning, we see attempts to embed manifolds in local regions, local linearities. Sometimes these local regions are regions of annotated DNA, as in the ENCODE examples, or non-linear interactions between sets of genes, as in the GWAS analysis of epistasis. At other times, these local regions are forms of life in a more general sense — clinical outcomes or diagnostic tests — as in MACQ-II.

I have emphasised on several occasions the common thread of what could be the termed the ‘genomic curse of dimensionality.’ \index{common vector space!dimensionality!curse of} The genomic sciences are based around the extraction, sorting and ordering of  DNA sequences. Machine learning practices, I have suggested,  begin to construct different dimensional spaces amidst the sequences, lines and tracks of genomes. What perhaps most vexes and animates post-genomic science is the desire to separate out from the DNA sequences variations that matter to both life-forms and forms of life. This vexation generates strenuous infrastructural, technical and conceptual attempts to reorganise and re-conceptualise what it is to know a genome. The machine learning techniques I have discussed  have begun to transform  bioinformatics and biostatistics. To understand machine learning as either as intensification of statistics, as hybridization of bioinformatics and statistics, or as the product of a reciprocal interactive convergence of biology and computing misses some of the important features of the reorganisation of genomics associated with these practices. It misses what machine learning brings from elsewhere to genomics, and it overlooks how the genome itself serves as a showcase, as we saw in the Google I/O demonstration,  of certain much wider transformations in the practices of anticipation and prediction. 

What is at stake in approaching machine learning in a scientific setting like genomics? An analytical and an ethico-epistemic stake appear here. Foucault writes that 'we should distinguish carefully between _scientific domains_ and _archaeological territories_' [@Foucault_1972, 183]. If knowledge has the status of knowledge by virtue of the practices that connects objects, field, subjects, statements, and institutions, then sciences are always localized within a field of knowledge that may exceed, and that may mutate in ways that alter resident sciences. Machine learning is just such a formation, I would suggest. Could we pose or address any normative questions by becoming aware of and articulating machine learning in practice  with greater clarity? Genomic science, in its cross-validation with machine learning, displays some of the tendencies to reduce divergences and to corral differences typical of knowledge economies more generally. The philosopher of science, Isabelle Stengers writes:

>with the knowledge economy, we may have scientists at work everywhere, producing facts with the speed that new sophisticated instruments make possible, but that the way those facts are interpreted will now mostly follow the landscape of settled interests. … We will more and more deal with instrumental knowledge. (Stengers 2011:377)

As we see in the 600,000 cores of Google Compute applied to exploration of associations in cancer genomics using random forests, or the lasso applied to microarray SNP data,  machine learning rapidly produces facts.  Stengers suggests that the risk here is that divergence and unexpected forms of experimental result are somewhat diminished as a result. Machine-learning in genomics might produce a ‘self-organising map’ that poses questions following the 'landscape of settled interests' or *status quo*.  

The very justification for using such techniques is the inordinate difficulty of exploring the functioning of genomes otherwise. Genomes and genomics are touchstones for wider transformations in many sectors of science, industry, commerce, media and government susceptible to the imperatives of the knowledge economy. In contrast to some of these domains, where much that happens is obscured from view, the great virtue or genomic science is the relative openness of its workings and its dogged insistence on DNA as the generating set. The fact that data practices are relatively generic and accessible means that critical research into transformations associated with data and knowledge economies can accompany nearly every aspect of genomic practice. 


[^6.70]: Importantly, as discussed in Chapter \ref{ch:diagram} (in terms of the diagonalization running between different elements of code, data, mathematical functions and indexical signs) and in Chapter \ref{ch:vector} (in terms of the auratic power of datasets), the fact that these datasets can be so readily loaded and accessed via bioinformatic infrastructures using code written in `R` or `Python` is also a notable feature of their advent in the machine learning literature.  Even a social science researcher can quickly write programs to retrieve this data. It attests to  several decades, if not longer, work on databases, web and network infrastructures, and analytical software, all, almost without exception, driven by the desire for aggregation, integration, archiving and annotation of sequence data that first became highly visible in the Human Genome Project of the 1990s.  The brevity of these lines of code that retrieve and load datasets -- half a dozen statements in `R`, no more -- suggests we are dealing with a high-sedimented set of practices, not something that has to be laboriously articulated, configured or artificed. Code brevity almost always signposts  highly-trafficked routes in contemporary network cultures. \index{code!brevity of}  Without describing in any great detail the topography of databases, protocols and standards woven by and weaving through bioinformatics, the ready invocation of genomic datasets suggests that the mixed, dirty, wide datasets fed to algorithms such as RF-ACE or analysed in [@Hastie_2009] derives from the layered couplings and interweaving of scientific publications and scientific databases developed by biological science over the last three decades. As the code shows, sequence and other genomic data   are available to scientists not only as users searching for something in particular and  retrieving specific data, but to scientists as programmers developing  ways of connecting up, gathering and integrating many different data points into to produce the wide ( many-columned), mixed (different types of data), and dirty (missing data, data that is 'noisy') datasets, datasets whose heterogeneous and often awkward topography then elicits and invites algorithmic treatment.


[^6.22]: I have discussed the history of heatmaps and their place in contemporary science in other work [@Mackenzie_2013c].

[^6.21]: Signal processing is another such domain. Many of the techniques now prominent in machine learning developed in parallel in signal processing, where the encoding and decoding of signals has long been seen as a problem of pattern recognition amenable to statistical calculation. In some specific cases, such as Hidden Markov Models, the same techniques seem to appear almost simultaneously in very disparate domains. Hidden Markov Models appear in genomics (as part of the problem of sequence alignment) at the same time as the begin to appear in digital signal processing for wireless communication and video image compression [@Mackenzie_2010a] and above all, in speech recognition [@Rabiner_1989]. \index{signal processing!relation to machine learning}

[^6.0]: A second significant and equally prestigious example of this infrastructural re-scaling might be IBM Corporation's 'cognitive computing platform,'  Watson. Watson, a distributed computing platform centred on machine learning, is hard to delineate or easily describe since it exists in a seemingly highly variable form. Its uses in genomics, pharmaceutical discovery,  clinical trials and cooking are heavily promoted by IBM [@IBM_2014]. Another would be Amazon Web Services various cloud computing services, some of which have been heavily used by genomic scientists. 

[^6.9]: In their account of the surprisingly slow shift of microarrays towards clinical practice, Paul Keating and Alberto Cambrosio identify statistics as a kind of bottleneck:

    >The handling and processing of the massive data generated by microarrays has made bioinformatics a must, but has not exempted the domain from becoming answerable to statistical requirements. The centrality of statistical analysis emerged diachronically, as the field moved into the clinical domain, and is re-specified synchronically depending on the kind of experiments one carries out [@Keating_2012,49].

    What Keating and Cambrosio describe as 'becoming answer to statistical requirements' I would suggest also entails a transformation of statistical requirements in a new operational diagram that reduces some of the frictions associated with existing statistical practice. This operational diagram is machine learning.  \index{statistics!biomedical!changes in} \index{Keating, Paul!on microarrays} \index{Cambrosio, Albert!on microarrays}

[^6.1]: Khan and co-authors write: 

    > Gene-expression profiling using cDNA microarrays permits a simultaneous analysis of multiple markers, and has been used to categorize cancers into subgroups 5–8 . However, despite the many statistical techniques to analyze gene-expression data, none so far has been rigorously tested for their ability to accurately distinguish cancers belonging to several diagnostic categories [@Khan_2001, 673] 

[^6.3]: A large and very diverse social science and humanities literature now exists around genomics. I draw on some of that literature as general background here, especially [@SunderRajan_2006; @Thacker_2005a; @Stevens_2011; @Leonelli_2014] and [@Haraway_1997], but largely do not address it directly.

[^6.12]: As data forms, genomes have a problematic mode of existence. They resemble cat images on the internet. As a data form, genomes are remarkably homogeneous. They are one-dimensional strings of letters corresponding to the well-known four nucleic acids (`g`, `a`, `t`, `c`). \index{data!form of!genomic} While many earlier tabulations of variation, difference, groups, types and relations are woven through the life sciences, genomes have for the last several decades mesmerised biological sciences as a way of analysing and re-distributing the confused multiplicities associated with living things. The raw data for genomes comes from the sequencing of DNA obtained from various organisms - viruses, bacteria, plants, fish, animals and humans. The sequencing of DNA, especially DNA that encodes the proteins that pervade biological processes, that structure tissues or assemble in complicated metabolic pathways, has been the concern first of molecular biology (mainly in the 1970s-1990s) and more recently  genomics (post-1990). In molecular biology, DNA sequences were carefully elicited (using the experimental techniques for instance of Sanger sequencing) and then compared with already known sequences of DNA to identify similarities that might have biology significance (for instance, evolution from a common ancestor). In genomics, DNA sequences generally originate from increasingly high-throughput sequencers that output massive datasets (see [@Stevens_2013; @Mackenzie_20bb]. Given both the accumulated store of already sequenced DNA and the increasingly viable practices of sequencing all of the DNA in a given organism, genomics has  promised a much wider and more detailed understanding of biological complexity than any previous life science had been able to obtain. With genomes in hand, biologists for the first time would be in a position to build models of entire domains of biology, domains that previously could only be explored through painstaking experiments targeting specific cells, molecules, biochemical reactions and networks. The vast yet somewhat dispersed knowledges of the life sciences might be re-ordered and aligned on a new very extensive yet quite homogeneous  backbone of the genome read out as billions of DNA base pairs. 


[^6.5]: Richard Durbin, Sean Eddy, Anders Krogh and Graeme Mitchison's highly cited _Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids_ [@Durbin_1998] was based almost entirely on Hidden Markov Models, a way of modelling a sequence of states that _Elements of Statistical Learning_ treats at chapter length (see [@Hastie_2009, Chapter 17]). \index{machine learners!Hidden Markov Model!in genome assembly} While sequence alignment was regarded as a deeply algorithmic and statistical problem in the former volume, it is not at all formulated in the language of machine learning. There is little discussion of cost functions, vector spaces, optimisation, problems of generalization, supervised or unsupervised learning. On the other, David Haussler, a key bioinformatician in the first draft of the human genome in his work explicitly sought to bring  machine learning methods to bear on biology, and continues to do so. See [@Zerbino_2012] for a review of the relevance of machine learning to genomic science.  

[^6.7]: The original publication of the lasso technique in a paper entitled 'Shrinkage and Selection via the Lasso' [@Tibshirani_1996] has been heavily cited in subsequent literature. [Google Scholar](http://scholar.google.co.uk/scholar?hl=en&q=tibshirani+1996+lasso) counts around 13,000 citations. For a paper published in the _Journal of the Royal Statistical Society_, this is surprisingly high, but attests, I would suggest, to the intense interest in renovating linear models for new problems such as image recognition or tumour classification. Somewhat surprisingly, given its heavy usage in other scientists, Andrew Ng's CS229 machine learning  course at Stanford University doesn't mention the lasso. 

[^6.401]: One important difficulty is the increasingly visible presence of variations in genomes. These variations first become visible after the assembly of whole genome sequences. Genomes of individuals of the same species vary in having slightly different versions of the genes (alleles), many of which differ only by single nucleotide base pairs. Whole genome sequencing made these differences, known as single nucleotide polymorphisms (SNPs), much more apparent. They occur in their tens of millions in the human genome (some 100 million are reported in the NCBI dbSNP database). In coding regions, SNPs may occasion changes in protein structure; in non-coding regions that can affect how gene expression occurs or is regulated. Like genes, SNPs can be detected using microarrays. SNP microarrays are commonly used in genome-wide association studies (GWAS) that explore complex genetic traits and conditions. SNP-based DNA microarrays measure the occurrence of millions of SNPs in a given biological sample. \index{genomes!variations!single nucleotide polymorphism (SNP)}

[^6.10]:Fix and Hodges frame their suggestion of the _k_ nearest neighbour model in this way:  'there seems to be a need for discriminative procedures whose validity does not require the amount of knowledge implied by by the normality assumption, the homoscedastic assumption, or any assumption of parametric form. The present paper is, as far as the authors are aware, the first one to attack subproblem (iii): can reasonable discrimination procedures be found which will work even if no parametric form can be assumed?' [@Fix_1951,7]. Subproblem (iii) in this quote refers to the challenge of deciding which of two populations an observed case belongs to if we know nothing about the parameters describing the two populations. \index{machine learner!k-nearest neighbours!history}
