\chapter{Introduction: Into the Data}
\label{ch:introduction}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  warning=FALSE, message=FALSE, dev='pdf')
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
library(ggplot2)
library(stringr)
library(xtable)
options(xtable.comment = FALSE)
```

>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ [@Mitchell_1997,2]. \index{Mitchell, Tom} \index{machine learner!computer program as}

>In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling [@Breiman_2001a,200] \index{Breiman, Leo}

>The key question isn't 'How much will be automated?' It's how we'll conceive of whatever _can't_ be automated at a given time. [@Lanier_2013, 77]

A relatively new field of scientific-engineering devices  has become operational in the last three decades. The field is known by various names -- machine learning, pattern recognition, knowledge discovery, data mining -- and its devices seem to have quickly migrated across scientific disciplines, business and commercial applications, industry, engineering, media, entertainment and government. Heavily dependent on calculation, they are found in breast cancer research, in autonomous vehicles, in insurance risk modelling, in credit transaction processing, in computer gaming, in face and handwriting recognition systems, in astronomy, advanced prosthetics, robots, ornithology, finance and surveillance (see the U.S. Government's `SkyNet` for one example of a machine learning surveillance system [@NationalSecurityAgency_2012]). \index{machine learner!National Security Agency Skynet} Sometimes these devices are understood as _scientific models_, and sometimes they are understood as _operational algorithms_ or machines. In very many scientific fields, publications mention or describe these techniques as part of their analysis of some experimental or observational data (as in the logistic regression classification models found in a huge number of biomedical papers). They anchor the field of 'data science' [@Schutt_2013]. \index{data science!relation to machine learning} Not so recently, they became mundane mechanisms, lying somewhere quite deeply embedded in other systems or gadgets (as in the decision tree models used in some computer game consoles to recognise gestures or the neural networks used to recognise voice commands by search engine services such as `Google Search` \index{Google Search} and `Apple Siri` \index{Apple Siri} [@McMillan_2013]). In other settings, they operate behind the scenes as part of the everyday functioning of services ranging from player ranking in online games to border control face recognition, from  credit scores to advanced full limb prosthetics.  The flexibility or generality of these machine learners, their proliferation and propagation in the world, and the epistemic-operational value accruing to them by virtue of their capacity to 'learn from experience' are the concerns of this book. 

```{r google_trends_load, echo=FALSE, message=FALSE, warning=FALSE}

library(stringr)
df = read.csv('data/google_trends_clean.csv',  header=TRUE,stringsAsFactors=FALSE)
df$week = str_extract(df$Week, '\\d{4}-\\d{2}-\\d{2}')
df = df[, -1]
```

The volume and geography of searches on Google Search provides some evidence of interest in particular search topics over a period of roughly a decade. If we search for terms such as `r colnames(df)[1:5]` on the [Google Trends](http://www.google.com/trends) service \index{Google!Google Trends}, the results for the last decade or so suggest changing interest in these topics. 

```{r google_trends, echo=FALSE, message=FALSE, fig.env=TRUE, fig.cap='', include=FALSE, dpi=600, warning=FALSE}
library(ggplot2)
library(reshape2)
dfm = melt(df, id.vars='week')
g = ggplot(dfm, aes(x=as.Date(week), y=value, group=variable))+ geom_line(aes(linetype=variable)) + geom_smooth(aes(linetype=variable)) + scale_x_date() + xlab('Years') + ylab('Google search volume')
g +  theme(legend.justification=c(1,0), legend.position=c(0.9,0.6), panel.grid.minor=element_blank(),  panel.grid.major=element_blank())
g
```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/google_trends-1.pdf}
        \caption{Google Trends search volume for `machine learning` and related query terms in English, globally 2004-2015}
  \label{fig:google_trends}
\end{figure}

In Figure \ref{fig:google_trends},  two search terms that had a very high search volume in 2004 -- 'artificial intelligence' and 'data mining' \index{artificial intelligence} \index{data mining} -- slowly decline over the years before starting to increase again in the last few years. By contrast, 'machine learning,' 'deep learning,' and 'predictive analytics' tend to increase during that decade. Midway between `artifical intelligence` and `deep learngin`, `machine learning` appears prominently in 2004, loses volume until around 2008, and then gradually rises again so that by mid-2015 it roughly matches the long-standing interests in data-mining and artificial intelligence.[^0.3] In the plot (Figure \ref{fig:google_trends}, the weekly variations in search volume on Google give rise to many spikes in the data. These spikes can be linked to specific invents such as significant press releases, public debates, media attention and film releases. 

The graphics shown in Figure \ref{fig:google_trends} actually draw two lines for each trend. The 'raw' weekly GoogleTrends data -- definitely not raw data, as it has been normalized to a percentage [@Gitelman_2013]  -- appears in the very spiky lines, but a much smoother line shows the general trend. This smoothing line is the work of a statistical model -- a local regression or loess model [@Cleveland_1992] \index{Cleveland, William} developed in the late 1970s \index{local regression}. The line depends on intensive computation and  models (linear regression, _k_ nearest neighbours, \index{k-nearest neighbors} \index{linear regression}). The smoother lines  make the spiky weekly search counts supplied by Google much easier to see. They construct alignments in  the data by replacing the heterogeneous variations with something that unequivocally runs through time with greater regularity. The smoothed lines shade the diagram with a predictive orientation. The lineaments of machine learning already appear in such lines.  How have things been arranged so that smooth lines run through many variations in this data?


```{r cat, engine='python', fig.show='hide', cache=TRUE, echo=FALSE, message=FALSE}

import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import color, exposure
import skimage
im = skimage.io.imread('figure/gray-tabby-cat-with-green-eyes-close-up.jpg')
image = color.rgb2gray(im)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))
ax1.axis('off')
ax1.imshow(image, cmap=plt.cm.gray)
ax1.set_title('Input image')
fd, hog_image = hog(image, orientations=8, pixels_per_cell=(52, 52),
                    cells_per_block=(1, 1), visualise=True)
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))
ax2.axis('off')
ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)
ax2.set_title('Histogram of Oriented Gradients')
plt.savefig('figure/cat_hog.pdf')
```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/cat_hog.pdf}
        \caption[Cat as histogram of gradients]{Close up of cat. The image on the left is already signal processed as JPEG format file. The image on the right is further signal processed using histogram of oriented gradients (HOG) edge detection. \texttt{kittydar} models HOG features.  Photo courtesy photos-public-domain.com}
  \label{fig:cat}
\end{figure}

What does it mean that machine learners  surface in so many different places, from fMRIs to Facebook, from fisheries management to Al Queda courier network monitoring? This book is an attempt to answer that question by describing the general horizon of machine learning as a data practice in its specificity. \index{data!practice} Take the case of `kittydar,` a machine learner in the area of image recognition (see [kittydar](http://harthur.github.io/kittydar)): 'Kittydar is short for kitty radar. Kittydar takes an image (canvas) and tells you the locations of all the cats in the image' [@Arthur_2012] \index{kittydar}. This playful piece of code demonstrates the deployment of a machine learner  in the mundane, not to say banal, domain of cat photos on the internet. \index{image recognition}  Heather Arthur, who developed `kittydar` writes:

>Kittydar first chops the image up into many “windows” to test for the presence of a cat head. For each window, kittydar first extracts more tractable data from the image's data. Namely, it computes the Histogram of Orient Gradients descriptor of the image, using the hog-descriptor(http://github.com/harthur/hog-descriptor) library. This data describes the directions of the edges in the image (where the image changes from light to dark and vice versa) and what strength they are. This data is a vector of numbers that is then fed into a neural network(https://github.com/harthur/brain) which gives a number from 0 to 1 on how likely the histogram data represents a cat. The neural network (the JSON of which is located in this repo) has been pre-trained with thousands of photos of cat heads and their histograms, as well as thousands of non-cats. See the repo for the node training scripts [@Arthur_2012].

This toy example of machine learning data practice finds cat heads in digital photographs. Based on how it locates cats,  we can begin to imagine similar pattern recognition techniques in use in self-driving cars, border security systems,  military robots or wherever there is something to be seen.  `Kittydar` runs in Javascript in a web browser, and only detects the presence of cats that face forward. As Arthur's description  suggests, the software finds cats by cutting the images into smaller windows. For each window, it measures a set of gradients running from  light and dark, and then compares these measurements to the gradients of known cat images (the so-called 'training dataset'). The device associates sudden shifts from light to dark with the regular features on cats' faces. The work of classification according to the simple categories of 'cat' or 'not cat' \index{classification}  is given  either to a neural network (as discussed in chapter \ref{ch:subject}), a typical machine learning technique and one that has recently been heavily developed by researchers at Google [@Le_2011], themselves working on images of cats among other things taken from Youtube videos [@BBC_2012] \index{neural network!see{machine learner!neural net}}, or to a support vector machine, a technique first developed in the 1990s by researchers working at IBM (see chapter \ref{ch:pattern}). \index{support vector machine!see{machine learner!support vector machine}} 

Machine learners range from the mundane to the esoteric, from the miniature to the infrastructural sublime of computational clouds. Like `kittydar`, they often classify, rank, cluster and estimate things.  Their names accumulate and repeat in textbooks, instructional courses, website tutorials, software libraries and code listings: linear regression \index{linear regression}, logistic regression, \index{machine learner!logistic regression} neural networks \index{machine learner!neural net}, linear discriminant analysis \index{machine learner!linear discriminant analysis}, support vector machines, \index{support vector machine} k-means clustering, \index {k-means clustering} decision trees \index{decision tree!see{machine learner!decision tree}, _k_ nearest neighbours, \index{nearest neighbours|see{machine learner!_k_ nearest neighbours}}  random forests, \index{principal component analysis} principal component analysis, or naive Bayes \gls{classifier} \index{machine learner!Naive Bayes} to name just some of the most commonly used. Sometimes they have proper names: `RF-ACE`, `Le-Net5`, or `C4.5`.  These names refer to predictive models and to computational algorithms of various ilk and provenance. Dauntingly intricate practices -- normalization, regularization, cross-validation, feature engineering, feature selection, optimisation \index{data!practices} -- suture datasets into shapes they can recognise. The techniques, algorithms and models are not necessarily startling new or novel. They take shape against a background of more than a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Mathematical constructs drawn from linear algebra,  differential calculus, numerical optimization and probability theory pervade practice in the field. [^0.15] \index{mathematics}

I am focusing on machine learners \index{machine learner|textbf} -- a term that refers to both humans and machines throughout this book --  and not algorithms, databases, infrastructures, or data visualization more generally because the data practices associated with machine learning delimit a specific _positivity_ of knowing. \index{positivity!of knowledge} Limiting the focus  to machine learning involves some risks. On the one hand, single minded focus on machine learning or particular machine learners such as neural nets or linear discriminant analysis \index{linear discriminant analysis|see{machine learner!linear discriminant analysis}} risks  fetishizing or essentializing machine learners as machines or algorithms. To attribute primacy to the algorithm or the predictive model would be to uncritically re-iterate many contemporary performances and representations that privilege machines and marginalize their human others. On the other hand, to favour analysis of the economically, socially, and political charged contexts of machine learning would be to downplay the positivity, the relational potentials and eventfulness that might inhabit their operations. Although vital, a contextual analysis  might lose sight of the transformed things, scales, processes and practices taking shape as machine learners, human and non-human, shade into each other. While `kittydar` locates cats, other  machine learners disaggregate cancer sub-types, patterns of speciation in birds, identify Al-Qaeda operatives or attune the movements of a prosthetic hand to nerve activations in an amputees' residual limb. Power and knowledge, control and positivity mix thoroughly in  machine learning. I find it difficult to separate the novel human-machine relations that have been taking shape in machine learners in their knowledge-making practices from  the systems of control, classification,  decision, power and discrimination they also operate. \index{control} I suspect I'm not alone in that difficulty, and for that reason, I attempt in the chapters that follow to carefully describe practices, knowledges, forms and terrains specific to machine learning. 

Machine learners  today circulate into domains that lie far afield of the eugenic and psychology laboratories, industrial research institutes or specialized engineering settings in which they first took shape (in some cases, such as the linear regression model or principal component analysis, more than a century ago; in others such as support vector machines or random forests, in the last two decades). If they are not exactly new and have diverse genealogies, the question is: does something important happen  as machine learners  shift from being mathematical or engineering techniques to an everyday device that can be generalized to locate cats in digital images, the Higgs boson in particle physics experiments or fraudulent credit card transactions? Does the somewhat unruly generalization of machine learning \index{generalization} across different epistemic, economic, institutional boundaries attest to a re-definition of knowledge, decision and control, a new operational field, \index{Foucault, Michel}\index{operation, field of}  as the philosopher Michel Foucault might put it, for knowledge [@Foucault_1972, 106]?

# All control to the machine learners?

Machine learners operate as programs. Machine learning can be viewed as a change in how programs or the code that controls computer operations are written and operate. From a control perspective,  machine learners continue the 'control revolution'  that arguably has, since the late nineteenth century, programmatically re-configured production, distribution, consumption, and bureaucracy [@Beniger_1986]. \index{control!control revolution}  With the growth of communication networks, the late 20th century suffered a new crisis of control, commensurate with the mid-19th century crisis described by James Beniger  [@Beniger_1986]. Almost all accounts of the operation power of machine learning emphasise its power to automate the control of processes -- border flows, credit fraud, spam email, financial market prices, gene expression, targetted online adverts -- whose unruly or transient multiplicity otherwise evades or confuses us.  

If a new programmatic field of knowledge-control takes shape around machine learning, how would we recognize it? In a study of border control systems, which often use machine learners to do profiling and facial recognition \index{facial recognition},  Louise Amoore advocates attention to calculation and algorithms:

> Surely this must be a primary task for critical enquiry – to uncover and probe the moments that come together in the making of a calculation that will automate all future decisions. To be clear, I am not proposing some form of humanist project of proper ethical judgement, but rather calling for attention to be paid to the specific temporalities and norms of algorithmic techniques that rule out, render invisible, other potential futures [@Amoore_2011]. \index{Amoore, Louise}

As Amoore writes, some potential futures are being 'ruled out' as these devices are put to work. Anna Munster \index{Munster, Anna} puts the challenge more bluntly: 'prediction takes down potential' [@Munster_2013]. I find much to agree with here. Machine learning is a convoluted but nevertheless concrete and historically specific form of calculation \index{calculation|see{mathematics!calculation} (as we will see in exploring algebraic operations in chapter \ref{ch:vector}, in finding and optimising certain mathematical functions in chapter \ref{ch:function} or in characterising and shaping probability distributions in chapter \ref{ch:probability}). It tends to algorithmically mediate future-oriented decisions (although all too often, very near-future decisions)\index{decision}.  It automates, and in many cases, specifically aims to automate that which hitherto appeared impossible to automate. And this automation, with all the investment it attracts (in the form of professional lives, in the form of infrastructures \index{infrastructure}, in research funding, in reorganisation of corporate and government processes, etc.) does rule out some and reinforce other futures. As for consequences, we need only consider some of the many forms of work that have already been affected by or soon could be affected by machine learning. Postal service clerks no longer sort the mail because neural net-based handwriting recognition reads addresses on envelopes \index{handwriting recognition|seealso{digit recognition}}. Locomotives, cars and trucks are already driven by machine learners, and soon driving may not be same occupational cultural it was. Hundreds of occupational categories have to some degree or other machine learners in their near future.[^0.001]

Given the consequential weight of such algorithms and calculations, how do we uncover the moments that come together in them? We might see algorithms as making calculation automatic. In various scholarly and political debates around changes business, media, education, health, government or science, quasi-omnipotent agency has been imputed to algorithms  \index{algorithm!primacy} [@Pasquinelli_2014;@Neyland_2014;@Totaro_2014;@Smith_2013; @Beer_2013;@Fuller_2012;@Wilf_2013; @Barocas_2013; @Gillespie_2014; [@Cheney-Lippold_2011;  @Galloway_2004] or sometimes just 'the algorithm.' The power of algorithms in the social science and humanities literature is understood in different ways, but there is general agreement that algorithms are powerful, or at least, can bear down heavily on people's lives and conduct, re-configuring, for instance, culture as algorithmic [@Hallinan_2014].  In what does this power and increasing prestige consist? What imbues algorithms with power? Is there some general  or 'breakout' feature such as recursivity \index{algorithm!recursivity}) or abstraction \index{abstraction!in algorithms}  that configures contemporary rationality algorithmically? 

Much of the critical literature on algorithms identify mathematical or predictive aspects as the source of their power. For instance, in his discussion of the 'metadata society,' Paolo Pasquinelli proposes that 

> a progressive political agenda for the present is about moving at the same level of abstraction as the algorithm in order to make the patterns of new social compositions and subjectivities emerge. We have to produce new revolutionary institutions out of data and algorithms. If the abnormal returns into politics as a mathematical object, it will have to find its strategy of resistance and organisation, in the upcoming century, in a mathematical way [@Pasquinelli_2015]. \index{Pasquinelli, Paolo}

'Moving at the same level of abstraction as the algorithm' offers some purchase as a formulation, but I find 'the' algorithm, 'the level of abstraction' and 'a mathematical way' all troublesome as ways of qualifying machine learners.  Which algorithm, what kind of abstraction and which mathematical way should we focus on? From the standpoint of diverse  machine learners and the many different person-thing-object-relations they encompass, there is no single a-historical level of abstraction, but something more like a torque and flux of different moments of abstraction at work in generalizing, classifying, circulating and stratifying in the midst of transient and plural multiplicities. [^0.12]  \index{abstraction!algorithm as} 

# The archaeology of a data practice

The coming together of moments in machine learning also have a play in them that notions of  automation \index{automation!limits of} and algorithm do not fully accommodate. Terms such as automation and algorithm over-prune machine learners as forms of data practice. As I will suggest, algorithms, calculations, techniques and data cohere as machine learners in specific ways. This makes them harder to see as devices or indeed in context. While they can be contextualised in industry, science or government, they themselves contextualise data, decisions, classifications and rankings.  Viewed as an ordering practice,   we might analyse how machine learners diagonally weave, layer and leverage techniques, calculations and algorithms in infrastructures, institutions and everyday lives. \index{machine learner!diagrammatic composition of}  With the certain variations in focus (for instance, paying close attention to the substitution and connection of various elements; see chapter \ref{ch:diagram}), could we see some stable forms -- and these often achieve mathematical formalization as they become stable --  amidst the maelstrom of platforms, devices, skills, claims and advocates flowing around them? We might see change that occurs more slowly than what flows around them. \index{mathematics!as stabilisation of practice} Understood as a data practice, we can begin to see the emergence of regularities and forms of order that allow higher levels of abstraction -- the algorithm, the data, the mathematical, indeed, abstraction itself -- to cohere.

If abstractions, mathematics or the algorithm loom large in classification practices today, how do we re-establish their connection to the workings of power without pre-emptively ascribing potency to the mathematical way, to the algorithm or abstraction? In the chapters that follow, I map machine learning data practices in greater empirical and conceptual depth, and develop some terms to describe them less generically (common vector space in Chapter \ref{ch:vector}, partial observer trajectory in Chapter \ref{ch:function},  decision surface in Chapter \ref{ch:pattern}, inverse probabilization in Chapter \ref{ch:probability}), but all of the facets I describe cluster around the problem of understanding how an almost banal, not esoteric, operation is repeated, borrowed, copied and diffused in so many settings.

If we understand machine learning as a specific data practice, then the forms of order that result from it also become more tangible. Nearly all machine learners can classify things. They are often simply called  'classifiers.'  `Kittydar` classifies images as cats,  but categorisation and classification applies much more generally.[^0.007] Many machine learners predict categories, levels, rankings, and values (for instance, prices or risks -- see Chapter \ref{ch:genome}). In his account of media power, Nick Couldry highlights the importance of categories and categorisation:

>_Category_ is a key mechanism whereby certain types of ordered (often 'ritualized') practice produce power by enacting and embodying categories that serve to mark and divide up the world in certain ways. Without _some_ ordering feature of practice, such as 'categories', it is difficult to connect the multiplicity of practice to the workings of power, whether in the media or in any other sphere. By understanding the work of categories, we get a crucial insight into why the social world, in spite of its massive complexity still appears to us as a _common_ world [@Couldry_2012, 62] \index{Couldry, Nick} \index{categories}, \index{power}

The orderings of practice, effected through categories, undergo a great deal of intensification via machine learning. While Couldry does not in this context discuss data mining, machine learning  or predictive analytics, his analysis of categorisation and its contribution to a massively complex but common social world points directly to the order of practice of practice.

Machine learning might be seen as an ordering  practice that marks up and divides the world. The operation of classification or prediction usually depends on a set of training data \index{data!training} whose categories are already known or have been assigned by someone (expert or not). These categories are sometimes simply an existing set of classifications derived from institutionalised or accepted practice. Machine learners also generate new categorical workings or mechanisms of category creation. Sometimes, new sets of categories have been invented or found for a particular purpose. The person who finds themselves paying a different price for a holiday by virtue of some unknown combination of factors including age, credit score, home address, previous travel, or educational qualifications experiences something of the diagrammatic movements. 

From this perspective, the mathematical abstractions, whether they come from calculus, linear algebra, statistics, or topology, maximise regularities. The power of machine learning to find patterns, to classify or predict regugularizes ordering practice. \index{machine learning!regularization}. The different facets of ordering practice I discuss arrange data in certain ways and not others, traverse data along certain lines, curves and surfaces, pay close attention to variations and generalization. These practices precede, prepare, shape and limit the algorithms, the abstractions and their predictions or classifications. 

# Massive asymmetries in a common world

If we see a massive regularization of order occurring in machine learning, what is at stake in trying to think through those practices? They display moments of formalisation (especially mathematical and statistical), circulation (pedagogically and operationally), generalization (encompassing many genera and generic forms of practice) and stratification (the socially, epistemically, economically and sometimes politically or ontologically loaded re-iterative enactment of categories). If that ordering becomes more tangibly thinkable, would it change how would we relate to what we see, feel, sense, hear or think in the face of a contemporary webpage such as  Amazon's that uses Association Rule Mining \index{Association Rule Mining|see{machine learner!\textit{apriori} algorithm}}, an app, a passport control point that matches faces of arriving passengers with images in a database, a computer game, or a genetic test (all settings in which machine learning is likely to be operating)?

The ordering practices of machine learning \index{machine learning!as ordering practice} display some rather stunning uniformities. Some expert practitioners complain of this uniformity.   Jeff Hammerbacher \index{Hammerbacher, Jeff}, previously chief research scientist at Facebook, co-founder of a successful data analytics company called Cloudera, and currently working also on cancer research at Mount Sinai hospital, complained about the spread of machine learning in 2011: 'the of my generation are thinking about how to make people click ads' [@Vance_2011] \index{advertising, online}. Leaving aside debates about the ranking of  'best minds' (see chapter \ref{ch:subjects}),  Hammerbacher was referring to the flourishing use of predictive analytics techniques in online platforms such as Twitter, Google and Facebook, and on websites more generally, whether they be websites that sell things or  advertising space. The mathematical skills of many PhDs from MIT, Stanford or Cambridge were wrangling data in the interests of micro-targeted advertising. As Hammerbacher observers, they were 'thinking about how to make people click ads,' and this 'thinking' mainly took and does take the form of building predictive models that tailored the ads shown on websites to clusters of individual preferences and desires. In thinking about individual people, and indeed, in seeking to figure an individual amidst very large numbers of people (often numbering millions and sometimes hundreds of millions), the 'best minds' were also constructing and operating with the very  forms of abstraction \index{abstraction!equations as} we see in Equation \ref{eq:linear_regression}.

Hammerbacher's unhappiness with ad click prediction resonates in critical responses to machine learning as used in other settings. Some versions of the digital humanities make extensive use of machine learning. \index{digital humanities} To cite one example,  _Macroanalysis: Digital Methods and Literary History_, Matthew Jockers \index{Jockers, Matthew}describes he or  we might relate to one currently popular machine learning or statistical modelling technique, the topic model \index{topic model} (itself the topic of discussion in Chapter \ref{ch:probability}; see also [@Mohr_2013] \index{Mohr, John}):

>   If the statistics are rather too complex to summarize here, I think it is fair to skip the mathematics and focus on the end results. We needn't know how long and hard Joyce sweated over _Ulysses_ to appreciate his genius, and a clear understanding of the LDA machine is not required in order to see the beauty of the result. [@Jockers_2013, 124]

The widely used topic models or Latent Dirichlet Allocation models provide a litmus test of how relations to machine learning is taking shape in the digital humanities. On the one hand, these models promise to make sense of large corpus of documents in terms of underlying themes or 'topics.' Latent topics and latent variables are of much more general interest in predictive modelling and classification (as we will, large document collections have long attracted the interest of machine learners). \index{data!latent variables in} On the other hand, Jockers signals the difficulties of relating to machine learning when he suggests that 'it is fair to skip the mathematics'  for the sake of 'the beauty of the result'. While one part of the humanities and critical social research exhorts closer attention to the mathematical, another averts its gaze in face of their complexity. 

The use of machine learning in digital humanities has not always been received enthusiastically. \index{Galloway, Alex} In a special issue of the journal _Differences: A Journal of Feminist Cultural Studies_ focusing on digital humanities, Alex Galloway makes two observations about the circulation and generalization of these methods in humanities scholarship: 

> When using quantitative methodologies in the academy (spidering, sampling, surveying, parsing, and processing), one must compete broadly with the sorts of media enterprises at work in the contemporary technology sector. A cultural worker who deploys such methods is little more than a lesser Amazon or a lesser Equifax.110 [@Galloway_2014, 110] 

Galloway is critical of the asymmetry between humanities scholars and media enterprises and credit score agencies.  The 'quantitative methodologies' that he refers to as  spidering, sampling, processing and so forth are more or less all epitomised in machine learning techniques (for instance, the Association Rule Mining techniques used by Amazon to recommend purchases, or perhaps the decision tree techniques \index{decision tree} used by the credit-rating systems at Equifax and FICO [@Fico_2015]). Galloway's argument is that the infrastructural scale of these enterprises along with the sometime very large technical workforces they employ to continually develop new predictive techniques dwarfs any gain in efficacy that might accrue to humanities research in its recourse to such methods. 

Even if 'cultural workers' do manage to learn to machine learn, and become adept at re-purposing the techniques in the interests of something other than selling things or generating credit scores, what is to be gained by doing so? Galloway suggests that  they might actually reinforce power asymmetries and exacerbate the ethical and political challenges posed by machine learning:

>But beyond the challenge of unequal talent and resources is the question of critical efficacy. Is it appropriate to deploy positivistic techniques against those self-same positivistic techniques? In a former time, such criticism would not have been valid or even necessary. Marx was writing against a system that laid no specific claims to the apparatus of knowledge production itself—even if it was fueled by a persistent and pernicious form of ideological misrecognition. Yet, today the state of affairs is entirely reversed. The new spirit of capitalism is found in brainwork, self-measurement and self-fashioning, perpetual critique and innovation, data creation and extraction. In short, doing capitalist work and doing intellectual work—of any variety, bourgeois or progressive—are more aligned today than they have ever been [@Galloway_2014, 110]. \index{Galloway, Alex|)}

This perhaps is a more serious charge. The 'techniques' of machine learning are positivist (and hence implicitly at odds with critical thought?), and moreover complicit -- 'aligned' -- with capitalist work. Again, there is something that feels right in the naming of the predicament -- intellectual work of the kind associated with  machine learning -- is definitely at the centre of many governmental, media, business and scientific fields of operation. Increasingly, they anchor the operations of these fields. 

# What cannot be automated? 

Like Galloway, I'm wary of certain deployments of machine learning, particularly the platform-based deployments and their associated sociality [@Gillespie_2010; @VanDijck_2012]. In certain case, they do seem to be 'laying claim to the apparatus of knowledge production.' Yet even amidst the trashy ephemerality of targeted online advertising or the more elevated analytics of literary history, the transformations in knowledge and knowing do not simply align  intellectual work and capitalist work.  Machine learning as a data practice is not simply automating  existing economic relations, even if that reproduction heavily steers its normal practice. While Hammerbacher and Galloway are understandably somewhat dismissive of the existential gratifications and critical efficacy of building targeted advertising systems or document classifiers, the 'deployment' of machine learning is not a finished process, but very much in train, constantly subject to revision, re-configuration and alteration. Could machine learners become engines of difference? Where in the algorithms, calculations, abstractions and regularizing practices of machine learning would differences be re-draw?

Machine learning in journalism, in specific scientific fields, in the humanities, in social sciences, in art, media, government or civil society sometimes overflows the platform-based deployments and their trenchantly positivist usages. A fairly explicit awareness of the operation of machine-learning driven processes is taking shape in some quarters. And this awareness couples critical and practical responses in a situationally aware calculative knowledge-practice, a form of predictive phronesis [@Aristotle_1981]. \index{phronesis!predictive}  For instance, the campaign to re-elect Barack Obama as U.S. President in 2011-12 relied heavily on micro-targetting of voters in the leadup to the election polls [@Issenberg_2012; @Mackenzie_2016a]. In response to the data analytics-driven election campaign run by the US Democrats in support of the 2012 re-election of President Barack Obama, data journalists at the non-profit news organisation _ProPublica_ reverse engineered the machine learning models that allowed the Obama re-election team to target individual votes with campaign messages [@Larsen_2012].   They built their own machine learning model - the 'Message Machine' - using emails sent in by readers and supporters to identify the workings of the Obama campaign team's micro-targetting models. While the algorithmic complexity and data infrastructures used in the Message Machine hardly match those at the disposal of the Obama team, it combines natural language processing (NLP) techniques such as measures of document similarity and machine learning models such as decision trees to disaggregate and map the micro-targetting processes \index{natural language processing}. This kind of reverse engineering work can be found in other quarters. In response to the personalised recommendations generated by streaming media service Netflix, journalists at _The Atlantic_ working with Ian Bogost, a media theorist and programmer \index{Bogost, Ian}, reverse engineered the algorithmic production of around 80,000 micro-genres of cinema used by Netflix [@Madrigal_2014] \index{Netflix}.  While Netflix's system to categorise films relies on much manual classification and tagging with meta-data, the inordinate number of categories they use is typical of the classificatory regimes that are developing in machine learning-based settings.  Certainly, high-profile claims for the power of predictive models to pre-emptively forecast events has come into question. The epidemic predictions of the Google Flu system, a predictive model based on the geography of search engine queries, were wrong on several occasions, mainly because people's online search behaviour changed as a result of coverage [@Lazer_2009; @Butler_2013] \index{Google!Google Flu}.

While these cases may be exceptional achievements, and indeed highlight the suffocating weight of the ad-tech application of machine learning, the proliferation of scientific usage suggests that the generalization of machine learning cannot be reduced to personalized advertising. Despite their many operational deployments, the coming together of algorithm, calculation and technique in a form of data practice is not fully coherent or complete. In order to qualify or specify how machine learners exist in their generality, we would need to specify their operations at a level of abstraction that neither attributes a mathematical essence to them nor frames them as producers of relative surplus value. Finding ways of accommodating their diversity, loose couplings and mutability would mean grasping their operational power and their capacity to create new forms of difference.[^0.91]

# Different abstractions in machine learning?

```{r knowledge_diversity, results='asis', echo=FALSE}

query = 'select * from basic_refs where TI like "%climate%" or DE LIKE "%climate% order by TC desc, PY;"'
res = dbGetQuery(con, query)
res_sample = res[sample.int(nrow(res), 10), ]
res_sample = res_sample[order(res_sample$PY),]
res_sample_show = res_sample[,c('TI', 'PY')]
colnames(res_sample_show) = c('Title', 'Year')
climate_table = xtable(res_sample_show, type='latex', include.rownames=FALSE, align = c("p{0.1\\textwidth}", "p{0.8\\textwidth}",  "p{0.10\\textwidth}"), caption='A small sample of titles of scientific articles that use machine learning in relation to "climate"', label='tab:climate_ml',table.placement="ht")
print(climate_table, include.rownames=FALSE)
```

Table \ref{tab:climate_ml} presents a small sample of scientific literature at the intersection of 'climate' and machine learning. This sample, while no doubt dwarfed by the flood of publications on recommendation systems, targeted advertising or handwriting recognition, is typical of the epistemic atmosphere associated with machine learners. (I return to this topic in Chapter \ref{ch:genome} in discussing how the leveraging of scientific data via predictive models and classifiers deeply affects the fabric and composition of objects of scientific knowledge.) But the longevity and plurality of experiments, variants, alternative techniques, implementations and understandings associated with machine learning makes it difficult to immediately reduce them to capitalist captures of knowledge production.  

```{r machine_learning_over_time, results = 'hide', cache=TRUE, include=FALSE, echo=FALSE}
query = 'select PY, anchor from basic_refs where anchor like "%svm%" order by PY desc, TC desc'
query1 = 'select PY, anchor from basic_refs where anchor like "%naive%" order by PY desc, TC desc'
query2 = 'select PY, anchor from basic_refs where anchor like "%decision_tree%" order by PY desc, TC desc'
query3 = 'select PY, anchor from basic_refs where anchor like "%expect%" order by PY desc, TC desc'
query4 = 'select PY, anchor from basic_refs where anchor like "%random%" order by PY desc, TC desc'
res = dbGetQuery(con, query)
res1 = dbGetQuery(con, query1)
res2 = dbGetQuery(con, query2)
res3 = dbGetQuery(con, query3)
res4 = dbGetQuery(con, query4)
res_all = rbind(res, res1, res2, res3, res4)
g = ggplot(res_all, aes(x=PY, group=anchor, alpha=0.6, linetype=anchor)) + geom_density()
g = g +xlim(1950, 2015)
g = g + xlab('Year of publication') + ylab('Proportion of publications')
g = g + scale_linetype_discrete(name = 'Machine learner', labels = c('Decision tree', 'Expectation Maximisation', 'Support Vector Machine', 'Naive Bayes', 'Random forest'))
g = g + guides(alpha = FALSE) 
g = g +  theme(legend.justification=c(1,0), legend.position=c(0.4,0.6), panel.grid.minor=element_blank(),  panel.grid.major=element_blank())
g
``` 

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{figure/machine_learning_over_time-1.pdf}
    \caption[Machine learners in scientific literature]{Machine learners in scientific literature. The lines in the graph suggest something of the changing fortunes of machine learners over time. The publication data comes from Thomson Reuter's \textit{Web of Science}. Separate searches were run for each machine learner. In these plots, as in the GoogleTrends data, the actual counts of publications have been normalised. In contrast to the GoogleTrend plots, these plots do not show the relative counts of the publications, only their distribution in time. }
  \label{fig:scientific_lit}
\end{figure}

Figure \ref{fig:scientific_lit}  derives from counts of scientific publications that mention particular machine learners in their title, their abstract or keywords. The curves, which are probability density plots, suggest a distribution of statements and operations over time for different techniques. Both the duration and the ebbs and flows of work on specific techniques, platforms, knowledges and power relations is still largely occluded. Like the Google Trends results, the lines shown in Figure \ref{fig:scientific_lit} have been normalised in order to adjust for an overall increase in the volume of scientific publications over the last five decades.\index{scientific publications} Unlike the Google Trends search patterns, the scientific literature displays a much more granular and differentiated texture in which different techniques, different terms over the last half century diverge widely from each other. A quick glance at science shows less homogeneity than Hammerbacher and perhaps Galloway see. 

Given some degree of pluralism in machine learning as a data practice, what level of abstraction usefully specifies it? If the algorithm and the mathematical constrict it too much, what other level of abstraction could we turn to?  Abstraction stands out as one of the most richly developed theoretical resources in the social sciences and humanities. Accounts of abstraction -- Karl Marx's real abstraction, Gilles Deleuze and Félix Guattari's abstract machines, Henri Bergson's lived abstraction, Alfred North Whitehead's fortunate abstraction, or Isabelle Stengers' experimental abstractions -- are not lacking.[^0.301] \index{abstraction!accounts of} Although the  theories of abstraction I have just listed differ in many ways, they all, without exception, array themselves in opposition to any limitation of abstraction to mathematical or modern scientific knowledge in particular. All of them, by often convoluted conceptual paths, seek to retrieve from abstraction something conducive to change, differences and contestation.

Any theory of abstraction faces a real test when confronted by operational practices of abstraction such as machine learning. \index{abstraction!operational practice of} Can a theory of abstraction affirm an operational abstraction without omitting its technical practice? Is machine learning an abstraction we can live with, a lived abstraction as Brian Massumi would call it [@Massumi_2013]? \index{abstraction!lived} I find the question of whether machine learning is a liveable abstraction too hard to answer conclusively. Certainly, accounts of abstraction -- abstract machine, real abstraction for instance -- help make sense of important movements in machine learning. But without grounding these abstractions in the practice of machine learning, it is very hard to sense how it abstracts. Without tracing how number, chance, classification and event come together in it, the texture of its abstraction, and hence any possible sense of its liveable relationality, remains unfelt and unthought. 

# The diagram

Much of this book attempts to identify good levels of abstraction for the data practices of machine learning. The diagram  -- a form of drawing that smooths away many of the frictions and variations in drawing -- anchors much of my account (see chapter \ref{ch:diagram} for a fuller framing). Diagrams practically abstract. They retain a connection to doing things, such as learning,  that other accounts of abstraction sometimes struggle with. Perceptually and technically, they span and indeed criss-cross between human and machine machine learners. They exhibit compositional characteristics of substitution, variation and superimposition, as well as a play or movement amongst their elements. By virtue of its diagrammatic composition, machine learning might bring something new into the worlds it traverses. If machine learners reorganise data, calculation, classification, decision, control and prediction, that might have some precedent. But precedent or novelty would be quite hard to grasp without being able to trace its diagrammatic composition. Similarly, in order to understand the operational forms of power associated with machine learning, the connections  connecting data structures, infrastructures, processors, databases and lives might be traceable in diagonal lines, in overlays, and indeed in the densely operational indexes of mathematical formalisms. For instance, how many cat photos are on the internet? This empirical question might be answerable only through machine learning. `kittydar` would need 300,000 cores on Google Compute Engine for several hours. Similarly, NSA's `Skynet` purports to identify Al-Qaeda couriers in Pakistan, but seems to also detect well-known Al-Jazeera journalists [@NationalSecurityAgency_2012]. Even the existence of such egregious errors or any other claim to know predicated by `Skynet` could be understood as a diagrammatic practice.  \index{machine learner!SkyNet}

Above all, diagrams can be implemented in multiple ways. Using implementations, graphical and mathematical forms, books and the heavy accumulation of scientific publications from many disciplines (for instance, as seen in figure \ref{fig:scientific_lit}),  the book follows six main operations diagrammatically: vectorisation, optimisation, probabilisation, pattern recognition, regularization and propagation. These generic operations compose a diagram of machine learning spanning hardware and software architectures, organizations of data and datasets, practices of designing and testing models, intersections between scientific and engineering disciplines, ongoing historical transformations of notions of pattern, class, rank and order, professional and popular pedagogies, and their associated subject positions. With varying degrees of formalization and consistency, these operations seek to offer an alternative account of machine learning, an account in which some feeling of agency and of affective movement can take route. Where do the operations come from? They as technical processes and practices, sometimes at a quite low level (for instance, vectorisation) and other times widely distributed (for instance, in pedagogy). They become figures when drawn on a diagram. As an abstraction, the diagram of the operational power of  machine learning does not map the footprint of a strategic monolith, but highlights the local relations of force that feed into the generalization and plurality of the field in both its monumental and peripheral variations. These local orderings, distributions, rankings and estimation can support hegemonic platforms, but they may also concatenate in different vectors of movement.  


[^0.91]: Certain strands of social and cultural theory have taken a strong interest in algorithmic processes as operational forms of power. For instance, the sociologist Scott Lash distinguishes  the operational rules found in  algorithms from the regulative and constitutive rules studied by many social scientists:

    >in a society of pervasive media and ubiquitous coding, at stake is a third type of rule, algorithmic, generative rules. ‘Generative’ rules are, as it were, virtuals that generate a whole variety of actuals. They are compressed and hidden and we do not encounter them in the way that we encounter constitutive and regulative rules. Yet this third type of generative rules is more and more pervasive in our social and cultural life of the post-hegemonic order. They do not merely open up opportunity for invention, however. They are also pathways through which capitalist power works, in, for example, biotechnology companies and software giants more generally [@Lash_2007a, 71]. \index{Lash, Scott!on generative rules}

    The term 'generative' is somewhat resonant in the field of machine learning as generative models, models that treat modelling as a problem of specifying the operations or dynamics that could have given rise to the observed data, are extremely important. \index{model!generative} If we consider only Andrew Ng's CS229 machine learning lectures  on Youtube [@Ng_2008] (lectures I discuss in chapter \ref{ch:diagram} and draw on throughout this book), we can see that they introduce generative models in Lecture 5 and 6. \index{Ng, Andrew} Although this seems to be only a small part of the 18 lectures given in the course, later lectures on the expectation maximisation algorithm (12-13), and then on unsupervised learning techniques such as factor analysis and principal component analysis, independent component analysis, are also effectively exploring generative models.  A similar distribution of topics can be found in _Elements of Statistical Machine Learning_[@Hastie_2009].   Generative models, while perhaps slightly less common in practice than discriminative models, nevertheless capture the sense that algorithms are not just implementations of rules for filtering, sorting, or deciding, but carry within them ontological commitments that might actually challenge social theory in interesting ways. In contrast to Lash, I would suggest that the generativity of these algorithms needs to be differentiated from the algorithmic processes that implement rules more generally. Moving into the data via a generative probabilistic model is very different to moving into the data through say a database query. The models, whether generative or discriminative (models  such as decision tree,  logistic regression or even neural networks that are more limited in their probabilistic underpinnings), are more like meta-algorithms that reorganize other algorithmic processes on varying scales. \index{machine learning!generative models in}


[^0.001]: Carl Benedikt Frey and Michael Osborne model the chances of occupational change for 700 occupations using, aptly enough, the machine learning technique of Gaussian Processes [@Frey_2013]. 

[^0.301]: [@McCormack_2012] reviews some of the large literature on abstraction. The differences between different accounts of abstraction will run through many of the following chapters. 

[^0.11]: The machine learning researchers Trevor Hastie, Tibshirani and Jerome Friedman, whom I will often cite in the pages that follow, describe neural networks, for instance in this way:  
    >Projection pursuit and neural network models consist of sums of non-linearly transformed linear models [@Hastie_2009, 18].
    The linear models and their non-linear transforms are hence worth focusing on in some detail and later chapters return to them repeatedly. 

[^0.007]: John Cheney-Lippold offers a quite general overview of categorization work. He writes:  'algorithm ultimately exercises control over
us by harnessing these forces through the creation of relationships between
real-world surveillance data and machines capable of making statistically
relevant inferences about what that data can mean' [@Cheney-Lippold_2011, 178]. \index{classification!algorithms for}. Much of my discussion here seeks to explore the space of 'statistical inference of what that data can mean.'

[^0.3]: It is hard to know who is doing these searches. The data provided by Google Trends includes geography, and it would be interesting to compare the geographies of interest in the different terms over time. 
