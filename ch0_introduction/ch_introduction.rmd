\chapter{Introduction}
\label{ch:introduction}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  warning=FALSE, message=FALSE, dev='pdf')
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
library(ggplot2)
library(stringr)
library(xtable)
options(xtable.comment = FALSE)
```

>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ [@Mitchell_1997,2]. \index{Mitchell, Tom} \index{machine learner!computer program as}

>In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling [@Breiman_2001a,200] \index{Breiman, Leo}

>The key question isn't 'How much will be automated?' It's how we'll conceive of whatever _can't_ be automated at a given time. [@Lanier_2013, 77]

A relatively new field of scientific-engineering devices  has become operational in the last three decades. The field is known by various names -- machine learning, pattern recognition, knowledge discovery, data mining -- and the devices seem to have quickly migrated across scientific disciplines, business and commercial applications, industry, engineering, media, entertainment and government. Heavily dependent on calculation, they are found in breast cancer research, in autonomous vehicles, in insurance risk modelling, in credit transaction processing, in computer gaming, in face and handwriting recognition systems, in astronomy, advanced prosthetics, robots, ornithology, finance and surveillance (see the U.S. Government's `SkyNet` for one example of a machine learning surveillance system [@NationalSecurityAgency_2012]). \index{machine learner!National Security Agency Skynet} Sometimes these devices are understood as _scientific models_, and sometimes they are understood as _operational algorithms_ or machines. In very many scientific fields, publications mention or describe these techniques as part of their analysis of some experimental or observational data (as in the logistic regression classification models found in a huge number of biomedical papers). They anchor the field of 'data science' [@Schutt_2013]. \index{data science!relation to machine learning} Not so recently, they became mundane mechanisms, lying somewhere quite deeply embedded in other systems or gadgets (as in the decision tree models used in some computer game consoles to recognise gestures or the neural networks used to recognise voice commands by search engine services such as Google Search and Apple Siri [@McMillan_2013] ). In many operational settings, they operate behind the scenes as part of the everyday functioning of services ranging from player ranking in online games to border control face recognition, from  credit scores to advanced full limb prosthetics.  The flexibility or plasticity of these machine learners, their proliferation and propagation in the world, and the epistemic-operational value accruing to them by virtue of their capacity to 'learn from experience' are the concerns of this book. 

```{r cat, engine='python', fig.show='hide', cache=TRUE, echo=FALSE, message=FALSE}

import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import color, exposure
import skimage
im = skimage.io.imread('figure/gray-tabby-cat-with-green-eyes-close-up.jpg')
image = color.rgb2gray(im)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))
ax1.axis('off')
ax1.imshow(image, cmap=plt.cm.gray)
ax1.set_title('Input image')
fd, hog_image = hog(image, orientations=8, pixels_per_cell=(52, 52),
                    cells_per_block=(1, 1), visualise=True)
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))
ax2.axis('off')
ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)
ax2.set_title('Histogram of Oriented Gradients')
plt.savefig('figure/cat_hog.pdf')
```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/cat_hog.pdf}
        \caption[Cat as histogram of gradients]{Close up of cat. The image on the left is already signal processed as JPEG format file. The image on the right is further signal processed using histogram of oriented gradients (HOG) edge detection. \texttt{kittydar} models HOG features.  Photo courtesy photos-public-domain.com}
  \label{fig:cat}
\end{figure}

What does it mean that machine learners  surface in so many different places, from fMRIs to Facebook, from fisheries management to Al Queda courier network monitoring? This book is an attempt to answer that question by describing the general horizon and field of practice associated with machine learning. \index{data!practice} Take the case of `kittydar,` a machine learner in the area of image recognition (see [kittydar](http://harthur.github.io/kittydar)): 'Kittydar is short for kitty radar. Kittydar takes an image (canvas) and tells you the locations of all the cats in the image' [@Arthur_2012] \index{kittydar}. This playful piece of code demonstrates the deployment of a machine learner  in the mundane, not to say banal, domain of cat photos on the internet. \index{image recognition}  Heather Arthur, who developed `kittydar` writes:

>Kittydar first chops the image up into many “windows” to test for the presence of a cat head. For each window, kittydar first extracts more tractable data from the image's data. Namely, it computes the Histogram of Orient Gradients descriptor of the image, using the hog-descriptor(http://github.com/harthur/hog-descriptor) library. This data describes the directions of the edges in the image (where the image changes from light to dark and vice versa) and what strength they are. This data is a vector of numbers that is then fed into a neural network(https://github.com/harthur/brain) which gives a number from 0 to 1 on how likely the histogram data represents a cat. The neural network (the JSON of which is located in this repo) has been pre-trained with thousands of photos of cat heads and their histograms, as well as thousands of non-cats. See the repo for the node training scripts [@Arthur_2012].

This toy example of machine learning data practice finds cat heads in digital photographs, but we can easily imagine similar pattern recognition techniques in use in self-driving cars, border security systems,  military robots or wherever there is something to be seen.  `Kittydar` runs in Javascript in a web browser, and only detects the presence of cats that face forward. As Arthur's description  suggests, the software finds cats by cutting the images into smaller windows. For each window, it measures a set of gradients running from  light and dark, and then compares these gradients to the gradients of known cat images (the training set). The intuition here is that edges and sudden shifts from light to dark are associated with the features on a cats in a fairly regular pattern. The work of classification according to the simple categories of 'cat' or 'not cat' \index{classification}  is either given  to a neural network (as discussed in chapter \ref{ch:subject}), a typical machine learning technique and one that has recently been heavily developed by researchers at Google [@Le_2011], themselves working on images of cats among other things taken from Youtube videos [@BBC_2012] \index{neural network!see{machine learner!neural net}}, or to a support vector machine, a technique first developed in the 1990s by researchers working at IBM (see chapter \ref{ch:pattern}). \index{support vector machine!see{machine learner!support vector machine}} 

Machine learners range from the mundane to the esoteric, from the miniature to the infrastructural sublime of computational clouds. Like `kittydar`, they often classify, rank, cluster and estimate things.  Their names accumulate and repeat in textbooks, instructional courses, website tutorials, software libraries and code listings: linear regression \index{linear regression}, logistic regression, \index{machine learner!logistic regression} neural networks \index{machine learner!neural net}, linear discriminant analysis \index{machine learner!linear discriminant analysis}, support vector machines, \index{support vector machine} k-means clustering, \index {k-means clustering} decision trees \index{decision tree!see{machine learner!decision tree}, _k_ nearest neighbours, \index{nearest neighbours|see{machine learner!_k_ nearest neighbours}}  random forests, \index{principal component analysis} principal component analysis, or naive Bayes classifier \index{machine learner!Naive Bayes} to name just some of the most commonly used. Sometimes they have proper names: `RF-ACE`, `Le-Net5`, or `C4.5`.  These names refer to predictive models and to computational algorithms of various ilk and provenance. A dauntingly intricate panoply of modelling and data practices -- normalization, regularization, cross-validation, feature engineering, feature selection, optimisation \index{data!preparation} -- that suture datasets into shapes they can recognise. Those techniques of preparation and evaluation of data themselves span a field of infrastructural vectors ranging from lists and tables of data in files and spreadsheets through to intricately engineered mechanisms for storing and retrieving large amounts of data such as databases, filestores, archives and computational clusters. The techniques, algorithms and models are not necessarily startling new or novel. They take shape against a background of more than a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Formidable mathematical constructs drawn from linear algebra, vector spaces, differential calculus, numerical optimization and probability theory heavily stratify practice in the field. [^0.15] \index{mathematics}

I am focusing on machine learners \index{machine learner|textbf} -- a term that refers to both humans and machines throughout this book --  and not algorithms, databases, infrastructures, or data visualization more generally because the data practices associated with machine learning delimit a specific _positivity_ of knowing that matters more generally. \index{positivity!of knowledge} Limiting the focus  to machine learning involves some risks. On the one hand, single minded focus on machine learning or particular machine learners such as neural nets or linear discriminant analysis \index{linear discriminant analysis|see{machine learner!linear discriminant analysis}} risks  fetishizing or essentializing machine learners as machines or algorithms. To attribute primacy to the algorithm or the predictive model would be to uncritically re-iterate many contemporary performances and representations that privilege machines and marginalize their human others. On the other hand, to favour analysis of the economically, socially, and political charged contexts of machine learning would be to downplay the positivity, the relational potentials and eventfulness that might inhabit their operations. Although vital, a contextual analysis  might lose sight of the transformed things, scales, processes and practices taking shape as machine learners, human and non-human, shade into each other. While `kittydar` locates cats, other  machine learners disaggregate cancer sub-types, patterns of speciation in birds, identify Al-Qaeda operatives or attune the movements of a prosthetic hand to nerve activations in an amputees' residual limb. Power and knowledge, control and positivity mix thoroughly in  machine learning. 

# All control to the machine learners?

I find it difficult to separate the novel human-machine relations that have been taking shape in machine learners in their knowledge-making practices from  the systems of control, classification,  decision, power and discrimination they also operate. \index{control} I suspect I'm not alone in that difficulty, and for that reason, I attempt in the chapters that follow to carefully describe practices, knowledges, forms and terrains specific to machine learning. Many machine learners operate as programs, and machine learning can be viewed as a change in how programs or the code that controls computer operations are written. From a control perspective,  machine learners continue the 'control revolution'  that arguably has, since the late nineteenth century, programmatically re-configured production, distribution, consumption, and bureaucracy [@Beniger_1986]. \index{control!control revolution}  With the growth of communication networks, the late 20th century suffered a new crisis of control, commensurate with the mid-19th century crisis described by James Beniger  [@Beniger_1986]. Almost all accounts of the operation power of machine learning emphasise its power to automate the control of processes -- border flows, credit fraud, spam email, financial market prices, gene expression, targetted online adverts -- whose unruly or transient multiplicity otherwise evades or confuses us.  

Machine learners  today circulate into domains that lie far afield of the eugenic and psychology laboratories, industrial research institutes or specialized engineering settings in which they first took shape (in some cases, such as the linear regression model or principal component analysis, more than a century ago; in others such as support vector machines or random forests, in the last two decades). If they are not exactly new and have diverse genealogies, the question is: does something important happen  as machine learners  shift from being mathematical or engineering techniques to an everyday device that can be generalized to locate cats in digital images, the Higgs boson in particle physics experiments or fraudulent credit card transactions? Does the somewhat unruly generalization of machine learning \index{generalization} across different epistemic, economic, institutional geographies attest to a re-definition of knowledge, decision and control, a new operational field, \index{Foucault, Michel}\index{operation, field of}  as the philosopher Michel Foucault might put it, for knowledge [@Foucault_1972, 106]?

# Calculation, algorithm and technique come together?

If a new programmatic field of knowledge-control takes shape around machine learning, how would we recognize it? In a study of border control systems, which often use machine learners to do profiling and facial recognition \index{facial recognition},  Louise Amoore advocates attention to calculation and algorithms:

> Surely this must be a primary task for critical enquiry – to uncover and probe the moments that come together in the making of a calculation that will automate all future decisions. To be clear, I am not proposing some form of humanist project of proper ethical judgement, but rather calling for attention to be paid to the specific temporalities and norms of algorithmic techniques that rule out, render invisible, other potential futures [@Amoore_2011]. \index{Amoore, Louise}

As Amoore writes, some potential futures are being 'ruled out' as these devices are put to work. Anna Munster \index{Munster, Anna} puts the challenge more bluntly: 'prediction takes down potential' [@Munster_2013]. I find much to agree with here. Machine learning is a convoluted but nevertheless concrete and historically specific form of calculation \index{calculation|see{mathematics!calculation} (as we will see in exploring algebraic operations in chapter \ref{ch:vector}, in finding and optimising certain mathematical functions in chapter \ref{ch:function} or in characterising and shaping probability distributions in chapter \ref{ch:probability}). It tends to algorithmically mediate future-oriented decisions (although all too often, very near-future decisions)\index{decision}.  It automates, and in many cases, specifically aims to automate that which hitherto appeared impossible to automate. And this automation, with all the investment it attracts (in the form of professional lives, in the form of infrastructures \index{infrastructure}, in research funding, in reorganisation of corporate and government processes, etc.) does rule out some and reinforce other futures. As for consequences, we need only consider some of the many forms of work that have already been affected by or soon could be affected by machine learning. Postal service clerks no longer sort the mail because neural net-based handwriting recognition reads addresses on envelopes \index{handwriting recognition|seealso{digit recognition}}. Locomotives, cars and trucks are already driven by machine learners, and soon driving may not be same occupational cultural it was. Hundreds of occupational categories have to some degree or other machine learners in their near future.[^0.001]

Given the consequential weight of such algorithms and calculations, how do we uncover the moments that come together in them? In various scholarly and political debates around changes business, media, education, health, government or science, quasi-omnipotent agency has been imputed to algorithms  \index{algorithm!primacy} [@Pasquinelli_2014;@Neyland_2014;@Totaro_2014;@Smith_2013; @Beer_2013;@Fuller_2012;@Wilf_2013; @Barocas_2013; @Gillespie_2014; @Galloway_2004] \index{Gillespie, Tarleton} or sometimes just 'the algorithm.' The power of algorithms in the social science and humanities literature is understood in different ways, but there is general agreement that these techniques are powerful, or at least, can bear down heavily on people's lives and conduct. In what does this power consist? What imbues algorithms with power? Is there some general  or 'breakout' feature such as recursivity \index{algorithm!recursivity}) or abstraction \index{abstraction!in algorithms}  that configures contemporary rationality algorithmically?






The coming together of moments in machine learning have a play in them that neither the notion of _technique_ \index{technique!limits of} nor that of automation \index{automation!limits of}, nor that of algorithm fully accommodate. Each of these terms -- calculation, automation and algorithm -- somewhat misses the specific temporalities of machine learners as forms of data practice. As I will suggest, algorithms, calculations and techniques cohere as machine learners only diagrammatically.  Viewed as diagrams, we might analyse how machine learners diagonally weave, layer and leverage techniques, calculations and algorithms in infrastructures, institutions and everyday lives. \index{machine learner!diagrammatic composition of}  Understood as diagrams (see chapter \ref{ch:diagram}), we might see some stable forms amidst the maelstrom of platforms, devices, skills, claims and advocates flowing around them. We might see change that occurs more slowly than what flows around them.  To give a simple instance of this diagrammatic stability, the idea of a separating line or decision plane has ordered classificatory movements through data since the 1930s when the British statistician R.A. Fisher developed linear discriminant analysis [@Fisher_1936]. \index{machine learner!linear discriminant analysis} 

At the same time, we surely must recognise that the coming together of algorithm, calculation and technique, all of which should be specified in greater detail, in a form of data practice, is not fully coherent or complete. By virtue of their diagrammatic composition, they might bring something new into the worlds they traverse. They reorganise data, calculation, classification, decision, control and prediction in ways that might have some precedent, but are nevertheless quite hard to grasp without a nuanced understanding of their diagrammatic composition. How would we access that?

We might understand the play in the diagram, or the space for the advent of something, in terms of discovery or invention by abstraction. \index{diagram!as abstraction} Machine learners propose to create knowledge (exactly what kind of knowledge is open to debate) that would be otherwise difficult or even impossible to produce.  For instance, how many cat photos are on the internet? This empirical question might be answerable only through machine learning. `kittydar` would need 300,000 cores on Google Compute Engine for several hours. Similarly, NSA's `Skynet` purports to identify Al-Qaeda couriers in Pakistan, but seems to also detect well-known Al-Jazeera journalists [@NationalSecurityAgency_2012]. Leaving aside errors for the moment (error will be a major topic in several later chapters), the claim to know differently or better pivots on abstraction, and mathematical abstraction in particular.

Amidst available framings for the recognition of the hitherto unseen, abstraction stands out as one of the most richly developed theoretical resources. Accounts of abstraction -- Karl Marx's real abstraction, Gilles Deleuze and Félix Guattari's abstract machines, Henri Bergson's lived abstraction, Alfred North Whitehead's fortunate abstraction, or Isabelle Stengers' experimental abstractions -- are not lacking.[^0.301] \index{abstraction!accounts of} Although the philosophical theories of abstraction I have just listed differ in many ways, they all, without exception, array themselves in opposition to any limitation of abstraction to mathematical or modern scientific knowledge in particular. All of them, by often convoluted conceptual paths,  seek to retrieve from abstraction something conducive to change, differences and contestation.

Any theory of abstraction faces a real test when confronted by operational practices of abstraction such as machine learning. \index{abstraction!operational practice of} Can it affirm abstraction without othering the technical practice of abstraction? Is machine learning an abstraction we can live with, a lived abstraction as Brian Massumi would call it [@Massumi_2013]? \index{abstraction!lived} I find the question of whether machine learning is a liveable abstraction too hard to answer conclusively. Certainly, accounts of abstraction -- abstract machine, real abstraction for instance -- help make sense of important movements in machine learning. But without grounding these abstractions in the practice of machine learning, it is very hard to make sense of how it abstracts. Without tracing how number, chance, classification and event come together in it, the texture of its abstraction, and hence any possible sense of its liveable relationality, remains unfelt and unthought. 

# The archaeology of a data practice




to add -- machine learning pulls big data into being; what are the precedents in trying to make sense of such things -- algorithms, epistemic objects, network society, feed forward, etc. Go back to Foucault to try to find propositions that help excavate the knowledges of order, distribution, ranking and estimation shaping up here.

[^0.001]: Carl Benedikt Frey and Michael Osborne model the chances of occupational change for 700 occupations using, aptly enough, the machine learning technique of Gaussian Processes [@Frey_2013]. 

[^0.301]: [@McCormack_2012] reviews some of the large literature on abstraction. The differences between different accounts of abstraction will run through many of the following chapters. 
