# Introduction
\label{ch:introduction}

## Introduction - a decisive change in the place of prediction

>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ 2.  [@Mitchell_1997, 2]

>In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling [@Breiman_2001a,200].

>The key question isn't 'How much will be automated?' It's how we'll conceive of whatever _can't_ be automated at a given time. [@Lanier_2013, 77]

A relatively new field of scientific-engineering devices  have become much more visible in the last three decades. The field is known by various names -- machine learning, pattern recognition, knowledge discovery, data mining -- and the devices are scattered across scientific disciplines, business and commercial applications, industry, engineering and government. Heavily dependent on calculation, they are found in breast cancer research, in autonomous vehicles, in insurance risk modelling, in credit transaction processing, in computer gaming, in face and handwriting recognition systems, in astronomy, ornithology, finance and surveillance. Sometimes these techniques are understood as _scientific models_, and sometimes they are understood as _operational algorithms_ or machines. In very many scientific fields, publications mention or describe these techniques as part of their analysis of some experimental or observational data (as in the logistic regression classification models found in a huge number of biomedical papers). They often become quasi-automatic mechanisms, lying somewhere quite deeply embedded in other systems or device (as in the decision tree models used in some computer game consoles or the neural networks used to recognise gestures on a touch screen). In many operational settings, they operate behind the scenes as part of the everyday functioning of devices and services ranging from player ranking in online games to border control face recognition, from  credit scores to advanced full limb prosthetics.  The flexibility or plasticity of these machine learners, their proliferation and propagation in the world, and the epistemic-operational value accruing to them by virtue of their capacity to 'learn from experience' are the concerns of this book. What kind of equivalence allows these techniques to work in so many different places?

```{r cat, engine='python', fig.show='hide', cache=TRUE, echo=FALSE, message=FALSE}

import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import color, exposure
import skimage
im = skimage.io.imread('gray-tabby-cat-with-green-eyes-close-up.jpg')
image = color.rgb2gray(im)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))
ax1.axis('off')
ax1.imshow(image, cmap=plt.cm.gray)
ax1.set_title('Input image')
fd, hog_image = hog(image, orientations=8, pixels_per_cell=(52, 52),
                    cells_per_block=(1, 1), visualise=True)
# Rescale histogram for better display
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))
ax2.axis('off')
ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)
ax2.set_title('Histogram of Oriented Gradients')
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),
                    #cells_per_block=(1, 1), visualise=True)
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(32, 32),
                    #cells_per_block=(1, 1), visualise=True)
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(62, 62),
                    #cells_per_block=(1, 1), visualise=True)
plt.savefig('cat_hog.pdf')


```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/cat_hog.pdf}
        \caption{Close up of cat. The image on the left is already signal processed as JPEG format file. The image on the right is further signal processed using histogram of oriented gradients (HOG) edge detection. \texttt{kittydar} models HOG features.  Photo courtesy photos-public-domain.com}
  \label{fig:cat}
\end{figure}

Take the case of `kittydar,` a small demonstration of machine learning techniques in the area of computer vision (see [kittydar](http://harthur.github.io/kittydar)): 'Kittydar is short for kitty radar. Kittydar takes an image (canvas) and tells you the locations of all the cats in the image' [@Arthur_2012] \index{kittydar}. This playful piece of software demonstrates the deployment of computer vision in the mundane, not to say banal, domain of cat photos on the internet. Heather Arthur, who developed `kittydar` writes:

>Kittydar first chops the image up into many “windows” to test for the presence of a cat head. For each window, kittydar first extracts more tractable data from the image's data. Namely, it computes the Histogram of Orient Gradients descriptor of the image, using the hog-descriptor(http://github.com/harthur/hog-descriptor) library. This data describes the directions of the edges in the image (where the image changes from light to dark and vice versa) and what strength they are. This data is a vector of numbers that is then fed into a neural network(https://github.com/harthur/brain) which gives a number from 0 to 1 on how likely the histogram data represents a cat. The neural network (the JSON of which is located in this repo) has been pre-trained with thousands of photos of cat heads and their histograms, as well as thousands of non-cats. See the repo for the node training scripts [@Arthur_2012].

This toy example of machine learning finds cat heads in digital photographs, but we can easily imagine similar techniques in use in self-driving cars, border security systems,  military robots or wherever there is something to be seen. `Kittydar` runs in Javascript in a web browser, and can only really detect the presence of cats that are facing forward. As the description provided by Arthur suggests, the software finds cats by chopping up the images into smaller windows. For each window, it measures a set of gradients running from  light and dark, and then compares these gradients to the gradients of known cat images (the training set). The intuition here is that edges and sudden shifts from light to dark are associated with the features on a cats in a fairly regular pattern. The work of classification is either given  to a neural network (as discussed in chapter \ref{ch:subject}), a typical machine learning technique and one that has recently been heavily developed by researchers at Google [@Le_2011], themselves working on images of cats among other things taken from Youtube videos [@BBC_2012] \index{neural network}, or to a support vector machine, a technique first developed in the 1990s by researchers working at IBM (see chapter \ref{ch:pattern}). \index{support vector machine} 

The names of these techniques accumulate and have been re-iterated in many textbooks, instructional courses, website tutorials and descriptions: linear regression \index{linear regression}, logistic regression, \index{logistic regression} neural networks \index{neural net}, linear discriminant analysis \index{linear discriminant analysis}, support vector machines, \index{support vector machine} k-means clustering, \index {k-means clustering} decision trees \index{decision trees}, _k_ nearest neighbours, \index{nearest neighbours}  random forests, \index{principal component analysis} principal component analysis, or naive Bayes classifier \index{Naive Bayes} to name just some of the most commonly used. These names refer to predictive models and to computational algorithms of various ilk and provenance. They are shadowed by a dauntingly intricate panoply of modelling and data preparation practices -- normalization, regularization, cross-validation, feature engineering, feature selection -- that suture their use. Those techniques of preparation and evaluation of data themselves rely on a gamut of infrastructural forms ranging from lists and tables of data in files and spreadsheets through to intricately engineered mechanisms for storing and retrieving large amounts of data such as databases, filestores, archives and computational clusters. The techniques, algorithms and models are not necessarily startling new or novel. They take shape against a background of a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Formidable mathematical constructs drawn from linear algebra, vector spaces, differential calculus, numerical optimization and probability theory heavily stratify practice in the field. 

I am focusing on these machine learners -- a term that refers to both humans and machines throughout this book --  and not data practices or algorithms in general, or databases, infrastructures, or data visualization, etc. This focus is a calculated risk. On the one hand, any single minded focus on machine learning or particular machine learners such as neural nets or linear discriminant analysis risks hypostasising, fetishizing or essentializing machine learners as machines or algorithms. To attribute primacy to the algorithm or the predictive model would be to uncritically reproduce many contemporary performances and representations that privilege machines and marginalize their human others. On the other hand, to steer away from the devices and machines in favour of analysis of their social uses and economically, socially, and political charged contexts would be to downplay their technicity [@Mackenzie_2002a], their relational potentials, eventfulness and materialities. I aim to follow a narrow ridge that traverses both the novel human-machine relations that have been taking shape in machine learning in its knowledge-making operations and offers a view of the forms of control, decision, power and discrimination configured by machine learners. Regardless of the spectacle associated with predictive models (and announcements of this predictive or classificatory power have been frequent in recent years),  they do today circulate into domains that lie far afield of the laboratories, experimental or engineering settings in which they first took shape (in some cases, more than a century ago; in others, in the last two decades). If they are not exactly new and have diverse genealogies, the question is: does something important happen  as machine learners  shift from being mathematical or engineering specialisms to an everyday device that can be generalized to locate cats in digit images, the Higgs boson in particle physics or credit fraud detection, or blackboxed, reverse engineered, disseminated, and taught to see cats? Does the somewhat unruly generalization of machine learning across different epistemic, economic, institutional geographies attest to a re-definition of knowledge, decision and control, or a new operational field,\index{Foucault, Michel}\index{operation, field of}  as the philosopher Michel Foucault terms, for knowledge [@Foucault_1972, 106]? 

## All power to the algorithms?

In various debates and discussions of changes in business, media, education, health, government or science, quasi-omnipotent agency has been imputed to algorithms, often with very little discussion of their specific modes of existence. These techniques are powerful, or at least, can bear down heavily on people's lives and conduct. This power does not however inhere in the algorithms themselves, or in any general features (such as recursivity). We need to understand how things have been arranged so that so much runs through the algorithms in order to understand their apparent power, and their power to multiply and propagate. In the context of her study of border control systems, which often use profiling and facial recognition techniques based on machine learning,  Louise Amoore writes:

> Surely this must be a primary task for critical enquiry – to uncover and probe the moments that come together in the making of a calculation that will automate all future decisions. To be clear, I am not proposing some form of humanist project of proper ethical judgement, but rather calling for attention to be paid to the specific temporalities and norms of algorithmic techniques that rule out, render invisible, other potential futures [@Amoore_2011]. \index{Amoore, Lousie}

I find much to agree with here. Machine learning is a convoluted form of calculation (as we will see in exploring algebraic operations in chapter \ref{ch:vector}, in finding and optimising certain mathematical functions in chapter \ref{ch:function} or in characterising and shaping probability distributions in chapter \ref{ch:probability}). It is very much concerned to algorithmically mediate future-oriented decisions (although all too often, very near-future decisions).  It makes heavy use of automation, and in many ways, takes pride in its capacity to automate that which hitherto appeared impossible to automate. And this automation, with all the investment it attracts (in the form of professional lives, in the form of infrastructures, in research funding, in reorganisation of corporate and government processes, etc.) does rule out other futures. We need only think of the many forms of work that have already been affected by machine learning. Postal workers no longer sort the mail because neural net-based handwriting recognition reads addresses on envelopes. Cars and trucks are already driven by machine learners, and soon driving may not be same work it was. These are mundane occupational changes, but places of work and their associated lives have already shifted in various ways around them.  

And yet, the coming together of moments in the making of these calculations have a play in them that the notion of _technique_ does not fully recognise. We need to analyse how these techniques are woven through infrastructures, institutions and everyday lives. The algorithms and techniques of machine learning, it is important to point out, cohere as machine learners only HERE are actually far more stable than the maelstrom of platforms, devices, skills, claims and advocates around them. They do change but more slowly than what flows around them. At the same time, we surely must recognise that these techniques bring something new into the worlds they move through. They profoundly reorganise numbers, calculation, classification and prediction in ways that might have some precedent, but are nevertheless quite hard to grasp. Without  a way to make sense of these decisive changes in the nature of number, chance, classification and event, we cannot fully make sense of how worlds take shape. A new topology of difference is forming with the capacity to foster some forms of life and not others. As Amoore writes, some potential futures are being 'ruled out' as these devices are put to work. Anna Munster puts the challenge more starkly:'prediction takes down potential' [@Munster_2013]. \index{Munster, Anna}

