\chapter{Introduction}
\label{ch:introduction}



```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  warning=FALSE, message=FALSE, dev='pdf')
```

## Introduction - a decisive change in the place of prediction

>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ [@Mitchell_1997,2]. \index{Mitchell, Tom}

>In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling [@Breiman_2001a,200] \index{Breiman, Leo}

>The key question isn't 'How much will be automated?' It's how we'll conceive of whatever _can't_ be automated at a given time. [@Lanier_2013, 77]

A relatively new field of scientific-engineering devices  has become operational in the last three decades. The field is known by various names -- machine learning, pattern recognition, knowledge discovery, data mining -- and the devices are scattered across scientific disciplines, business and commercial applications, industry, engineering, media, entertainment and government. Heavily dependent on calculation, they are found in breast cancer research, in autonomous vehicles, in insurance risk modelling, in credit transaction processing, in computer gaming, in face and handwriting recognition systems, in astronomy, ornithology, finance and surveillance. Sometimes these techniques are understood as _scientific models_, and sometimes they are understood as _operational algorithms_ or machines. In very many scientific fields, publications mention or describe these techniques as part of their analysis of some experimental or observational data (as in the logistic regression classification models found in a huge number of biomedical papers). More recently, they have become quasi-automatic mechanisms, lying somewhere quite deeply embedded in other systems or device (as in the decision tree models used in some computer game consoles used to recognise gestures or the neural networks used to recognise voice commands by search engine services such as Google Search [@McMillan_2013] ). In many operational settings, they operate behind the scenes as part of the everyday functioning of devices and services ranging from player ranking in online games to border control face recognition, from  credit scores to advanced full limb prosthetics.  The flexibility or plasticity of these machine learners, their proliferation and propagation in the world, and the epistemic-operational value accruing to them by virtue of their capacity to 'learn from experience' are the concerns of this book. What kind of equivalence allows these techniques to work in so many different places? 

```{r cat, engine='python', fig.show='hide', cache=TRUE, echo=FALSE, message=FALSE}

import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import color, exposure
import skimage
im = skimage.io.imread('figure/gray-tabby-cat-with-green-eyes-close-up.jpg')
image = color.rgb2gray(im)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))
ax1.axis('off')
ax1.imshow(image, cmap=plt.cm.gray)
ax1.set_title('Input image')
fd, hog_image = hog(image, orientations=8, pixels_per_cell=(52, 52),
                    cells_per_block=(1, 1), visualise=True)
# Rescale histogram for better display
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))
ax2.axis('off')
ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)
ax2.set_title('Histogram of Oriented Gradients')
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),
                    #cells_per_block=(1, 1), visualise=True)
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(32, 32),
                    #cells_per_block=(1, 1), visualise=True)
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(62, 62),
                    #cells_per_block=(1, 1), visualise=True)
plt.savefig('figure/cat_hog.pdf')

```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/cat_hog.pdf}
        \caption[Cat as histogram of gradients]{Close up of cat. The image on the left is already signal processed as JPEG format file. The image on the right is further signal processed using histogram of oriented gradients (HOG) edge detection. \texttt{kittydar} models HOG features.  Photo courtesy photos-public-domain.com}
  \label{fig:cat}
\end{figure}

Take the case of `kittydar,` a small demonstration of machine learning techniques in the area of computer vision (see [kittydar](http://harthur.github.io/kittydar)): 'Kittydar is short for kitty radar. Kittydar takes an image (canvas) and tells you the locations of all the cats in the image' [@Arthur_2012] \index{kittydar}. This playful piece of software demonstrates the deployment of computer vision in the mundane, not to say banal, domain of cat photos on the internet. Heather Arthur, who developed `kittydar` writes:

>Kittydar first chops the image up into many “windows” to test for the presence of a cat head. For each window, kittydar first extracts more tractable data from the image's data. Namely, it computes the Histogram of Orient Gradients descriptor of the image, using the hog-descriptor(http://github.com/harthur/hog-descriptor) library. This data describes the directions of the edges in the image (where the image changes from light to dark and vice versa) and what strength they are. This data is a vector of numbers that is then fed into a neural network(https://github.com/harthur/brain) which gives a number from 0 to 1 on how likely the histogram data represents a cat. The neural network (the JSON of which is located in this repo) has been pre-trained with thousands of photos of cat heads and their histograms, as well as thousands of non-cats. See the repo for the node training scripts [@Arthur_2012].

This toy example of machine learning finds cat heads in digital photographs, but we can easily imagine similar techniques in use in self-driving cars, border security systems,  military robots or wherever there is something to be seen. `Kittydar` runs in Javascript in a web browser, and can only really detect the presence of cats that are facing forward. As the description provided by Arthur suggests, the software finds cats by chopping up the images into smaller windows. For each window, it measures a set of gradients running from  light and dark, and then compares these gradients to the gradients of known cat images (the training set). The intuition here is that edges and sudden shifts from light to dark are associated with the features on a cats in a fairly regular pattern. The work of classification according to the simple categories of 'cat' or 'not cat' \index{classification}  is either given  to a neural network (as discussed in chapter \ref{ch:subject}), a typical machine learning technique and one that has recently been heavily developed by researchers at Google [@Le_2011], themselves working on images of cats among other things taken from Youtube videos [@BBC_2012] \index{neural network}, or to a support vector machine, a technique first developed in the 1990s by researchers working at IBM (see chapter \ref{ch:pattern}). \index{support vector machine} 

The names of these techniques accumulate and have been re-iterated in many textbooks, instructional courses, website tutorials and descriptions: linear regression \index{linear regression}, logistic regression, \index{logistic regression} neural networks \index{neural net}, linear discriminant analysis \index{linear discriminant analysis}, support vector machines, \index{support vector machine} k-means clustering, \index {k-means clustering} decision trees \index{decision trees}, _k_ nearest neighbours, \index{nearest neighbours}  random forests, \index{principal component analysis} principal component analysis, or naive Bayes classifier \index{Naive Bayes} to name just some of the most commonly used. These names refer to predictive models and to computational algorithms of various ilk and provenance. They are shadowed by a dauntingly intricate panoply of modelling and data preparation practices -- normalization, regularization, cross-validation, feature engineering, feature selection -- that suture their use. Those techniques of preparation and evaluation of data themselves rely on a gamut of infrastructural forms ranging from lists and tables of data in files and spreadsheets through to intricately engineered mechanisms for storing and retrieving large amounts of data such as databases, filestores, archives and computational clusters. The techniques, algorithms and models are not necessarily startling new or novel. They take shape against a background of a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Formidable mathematical constructs drawn from linear algebra, vector spaces, differential calculus, numerical optimization and probability theory heavily stratify practice in the field. 

I am focusing on these machine learners \index{machine learner|textbf} -- a term that refers to both humans and machines throughout this book --  and not data practices or algorithms in general, or databases, infrastructures, or data visualization, etc. This focus is a calculated risk. On the one hand, any single minded focus on machine learning or particular machine learners such as neural nets or linear discriminant analysis \index{linear discriminant analysis} risks hypostasising, fetishizing or essentializing machine learners as machines or algorithms. To attribute primacy to the algorithm or the predictive model would be to uncritically re-iterate many contemporary performances and representations that privilege machines and marginalize their human others. On the other hand, to steer away from the devices and machines in favour of analysis of their social uses and economically, socially, and political charged contexts would be to downplay their technicity [@Mackenzie_2002a]\index{technicity}, their relational potentials, eventfulness and materialities.

I aim to follow a narrow ridge that both traverses the novel human-machine relations that have been taking shape in machine learning in its knowledge-making operations *and * offers a view of the forms of control, decision, power and discrimination configured by machine learners. Regardless of the disorienting degree of media spectacle associated with predictive models (and announcements of this predictive or classificatory power have been frequent in recent years),  they do today circulate into domains that lie far afield of the laboratories, experimental or engineering settings in which they first took shape (in some cases, more than a century ago; in others, in the last two decades). If they are not exactly new and have diverse genealogies, the question is: does something important happen  as machine learners  shift from being mathematical or engineering specialisms to an everyday device that can be generalized to locate cats in digit images, the Higgs boson in particle physics experiments or credit fraud detection, or blackboxed, reverse engineered, disseminated, and taught to see cats? Does the somewhat unruly generalization of machine learning \index{generalization} across different epistemic, economic, institutional geographies attest to a re-definition of knowledge, decision and control, a new operational field,\index{Foucault, Michel}\index{operation, field of}  as the philosopher Michel Foucault terms, for knowledge [@Foucault_1972, 106]? Or, is this generalization a vast hyperobjectifying error? 

## All power to the algorithms?

In various scholarly and political debates around changes business, media, education, health, government or science, quasi-omnipotent agency has been imputed to algorithms  \index{algorithm!primacy} [@Pasquinelli_2014;@Neyland_2014;@Totaro_2014;@Beer_2013;@Fuller_2012;@Wilf_2013; @Barocas_2013; @Gillespie_2014; @Galloway_2004] \index{Gillespie, Tarleton}. The power of algorithms in the academic literature are understood in different ways, but there is general agreement that these techniques are powerful, or at least, can bear down heavily on people's lives and conduct. In what does this power consist? What imbues algorithms with power? Is there some general  or 'breakout' feature such as recursivity\index{recursivity}) that configures contemporary rationality algorithmically?

```{r google_trends_load, echo=FALSE, message=FALSE, warning=FALSE}

library(stringr)
df = read.csv('data/google_trends_clean.csv',  header=TRUE,stringsAsFactors=FALSE)
df$week = str_extract(df$Week, '\\d{4}-\\d{2}-\\d{2}')
df = df[, -1]
```

Scholarly interest in algorithms occurs amidst more general media culture interest in the topic. The volume and geography of searches on Google Search provides some evidence of interest in particular search topics over a period of roughly a decade. If we search for terms such as `r colnames(df)[1:5]` on the [Google Trends](http://www.google.com/trends) service \index{Google Trends}, the results for the last decade or so suggest both increasing and decreasing interest in these topics. 

```{r google_trends, echo=FALSE, message=FALSE, fig.env=TRUE, fig.cap='', include=FALSE, dpi=600, warning=FALSE}
library(ggplot2)
library(reshape)
dfm = melt(df, id.vars='week')
g = ggplot(dfm, aes(x=as.Date(week), y=value, group=variable))+ geom_line(aes(linetype=variable)) + geom_smooth(aes(linetype=variable)) + scale_x_date() + xlab('Years') + ylab('Google search volume')
g +  theme(legend.justification=c(1,0), legend.position=c(0.9,0.6), panel.grid.minor=element_blank(),  panel.grid.major=element_blank())

```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/google_trends-1.pdf}
        \caption{Google Trends search volume for `machine learning` and related query terms in English, globally 2004-2015}
  \label{fig:google_trends}
\end{figure}

Note in Figure \ref{fig:google_trends} that the two search terms that had a very high search volume in 2004 -- 'artificial intelligence' and 'data mining' \index{artificial intelligence} \index{data mining} -- display a relative decline over the years before starting to increase again in the last few years. By contrast, 'machine learning,' 'deep learning,' and 'predictive analytics' tend to increase during that decade. `Machine learning` interestingly appears prominently in 2004, loses volume until around 2008, and then gradually rises again so that by mid-2015 it roughly matches the long-standing interests in data-mining and artificial intelligence.[^0.3] In the plot (Figure \ref{fig:google_trends}, the weekly variations in search volume on Google give rise to many spikes in the data. These spikes can be linked to specific invents such as significant press releases, public debates, media attention and film releases. 

[^0.3]: It is hard to know who is doing these searches. The data provided by Google Trends includes geography, and it would be interesting to compare the geographies of interest in the different terms over time. 

The graphics shown Figure \ref{fig:google_trends} actually draw two lines for each trend. The 'raw' weekly GoogleTrends data -- definitely not raw, as it has been normalized to a percentage [@Gitelman_2013] appears in the very spiky lines, but a much smoother line shows the general trend. This smoothing line is the product of a statistical model -- a local regression or loess model [@Cleveland_1992] \index{Cleveland, William} developed in the late 1970s \index{local regression} -- that depends on some intensive computation and a variety of machine learning techniques (linear regression, _k_ nearest neighbours, \index{k-nearest neighbors, linear regression}. These smoother lines seem to make the spiky weekly search counts supplied by Google much easier to see. They construct alignments in  the data by replacing the heterogeneous variations with something that unequivocally runs through time. The smoothed lines already shade the diagram with a predictive orientation, in the same way that the histogram of oriented gradients already shaped the digital photograph in Figure \ref{fig:cat} towards the task of classification.  We need to understand how things have been arranged so that much runs like a smooth line through particular topics such as 'machine learning' or 'deep learning.' 

## Mod the algorithms?

The analytical challenge here is to modify or 'mod' algorithms enough to print or `cat`[^0.2]  something of what happens in their reality-directing operation. How would one do that? In the context of her study of border control systems, which often use profiling and facial recognition \index{facial recognition} techniques based on machine learning,  Louise Amoore writes:

[^0.2]: `cat`: the 'catenate' file utility found on many computer operating systems that outputs the contents of a file or any stream of data.

> Surely this must be a primary task for critical enquiry – to uncover and probe the moments that come together in the making of a calculation that will automate all future decisions. To be clear, I am not proposing some form of humanist project of proper ethical judgement, but rather calling for attention to be paid to the specific temporalities and norms of algorithmic techniques that rule out, render invisible, other potential futures [@Amoore_2011]. \index{Amoore, Lousie}

I find much to agree with here. Machine learning is a convoluted but nevertheless concrete and historically specific form of calculation \index{calculation|(} (as we will see in exploring algebraic operations in chapter \ref{ch:vector}, in finding and optimising certain mathematical functions in chapter \ref{ch:function} or in characterising and shaping probability distributions in chapter \ref{ch:probability}). It is very much concerned to algorithmically mediate future-oriented decisions (although all too often, very near-future decisions)\index{decision}.  It makes heavy use of automation, and in many ways, takes pride in its capacity to automate that which hitherto appeared impossible to automate. And this automation, with all the investment it attracts (in the form of professional lives, in the form of infrastructures \index{infrastructure}, in research funding, in reorganisation of corporate and government processes, etc.) does rule out some futures. We need only think of the many forms of work that have already been affected by machine learning. Postal workers no longer sort the mail because neural net-based handwriting recognition reads addresses on envelopes \index{handwriting recognition|seealso{digit recognition}}. Cars and trucks are already driven by machine learners, and soon driving may not be same work it was. These are mundane occupational changes, but places of work and their associated lives have already shifted in various ways around them.  

And yet, the coming together of moments in the making of these calculations have a play in them that the notion of _technique_ \index{technique} does not fully recognise if it isolates the technique from the diagrams, formalisms, transformations, trajectories, and fields attached to it. We need to analyse how machine learners weave techniques through infrastructures, institutions and everyday lives \index{machine learner}. The algorithms and techniques of machine learning, it is important to point out, cohere as machine learners only are actually far more stable than the maelstrom of platforms, devices, skills, claims and advocates around them. They do change but more slowly than what flows around them. At the same time, we surely must recognise that these techniques bring something new into the worlds they move through. They profoundly reorganise numbers, calculation, classification and prediction in ways that might have some precedent, but are nevertheless quite hard to grasp. Without  a way to make sense of these decisive changes in the nature of number, chance, classification and event, we cannot fully make sense of how worlds take shape. A new topology of difference is forming with the capacity to foster some forms of life and not others. As Amoore writes, some potential futures are being 'ruled out' as these devices are put to work. Anna Munster puts the challenge more starkly:'prediction takes down potential' [@Munster_2013]. \index{Munster, Anna}

## Moments in learning to classify

How should one uncover what flows through an algorithm, the moments that come together,  as it makes a calculation? Four moments  -- I understand moment as both a temporal marker and as a specific force acting around a reference point (as in torque) -- seem important to me: *formalisation; circulation; generalization; and stratification.* In the chapters that follow, I map these moments in greater empirical and conceptual depth, and develop some terms to describe them less generically (common vector space in Chapter \ref{ch:vector}, partial observer trajectory in Chapter \ref{ch:function}, generative discriminant in Chapter \ref{ch:probability}, decision surface in Chapter \ref{ch:decision},  error propagation in Chapter \ref{ch:subjects}), but  let us take a preliminary look at the interacting moments of the predictive calculations done by machine learners. In the early pages of a book on machine learning that I shall return to frequently [@Hastie_2009], the following equations appear:

\begin {equation}
\label{eq:linear_regression}
\hat{Y} = \beta_0 + \sum_{j=1}^{p}X_j\hat{\beta}_j
\end {equation}
\index{@S$\sum$}
\index{@Y$\hat{Y}$}

\begin {equation}
\label{eq:linear_regression_inner_product}
\hat{Y} = X^T\hat{\beta}
\end {equation}
\index{@T$\X^{T}$}

They are a rather harsher introduction than the cat, but these two equations \ref{eq:linear_regression} and \ref{eq:linear_regression_inner_product}, which more or less express the same thing (the second is known as the 'inner product' \index{inner product} form),  are anchor points of the classifying work done by `kittydar`  and the lines that smooth the spiky data in the Google Trends plot shown in Figure \ref{fig:google_trends}. They both express the 'linear regression model' \index{linear regression} albeit using slightly different formalisms. Every character of these equations, as well as a set of conventions that more or less indirectly govern how the different characters and symbols relate to each other and how they track out into the world, is perhaps worth attending to.  I will describe in more detail below how several different machine learning practices of formalisation intersect in these formal expressions. I don't expect that these somewhat abstract  formalisms are immediately understandable to everyone, and for readers who are not familiar with the techniques I am describing, it may be difficult to even look at these mathematical formalisms for very long without thinking that they have something better to do. They have taken me several years to get used to. In the interests of the tracking the calculations that move through machine learning  I propose to look at these expressions as a diagram (see Chapter \ref{ch:diagram}) \index{diagram}, with an eye for how each of the letters and symbols indicates a movement in some direction, an operation that connects, accumulates or separates either numbers or sets of numbers. Importantly, to preempt discussion that will be the subject of later chapters, both the neural networks and support vector machines to be found in `kittydar` derive from combinations and accumulations of these anchoring formalisms.[^0.11]\index{calculation|)}

[^0.11]: The machine learning researchers Trevor Hastie, Tibshirani and Jerome Friedman, whom I will often cite in the pages that follow, describe neural networks, for instance in this way:  
    >Projection pursuit and neural network models consist of sums of non-linearly transformed linear models [@Hastie_2009, 18].
    The linear models and their non-linear transforms are hence worth focusing on in some detail and later chapters return to them repeatedly. 

How are the expressions shown in Equations \ref{eq:linear_model} and \ref{eq:linear_regression_inner_product} read by machine learners (bearing in mind I use that term indiscriminately to include people and machines)? The *learning* of machine learning is part of the reality-making power of these operations. The learning of these formalisations has become surprisingly popular in recent years (hence the upward curve on the 'machine learning' Google Trend). Erstwhile Stanford professor of computer science Andrew Ng \index{Ng, Andrew} delivered a set of lectures on machine learning in 2008 that were uploaded to Youtube [@Ng_2008]. The lectures effectively begin by talking about the formalisms  of Equation \ref{eq:linear_regression} and Ng spends much time developing them through mathematical derivations, worked examples and references to relevant scientific literature and significant events in the field.  At the time of writing, they have been viewed by more than 0.5 million people. We don't how these people viewed Ng's lectures, nor what they did with them, but the fact that a set of lectures given to post-graduates on predictive modelling attracts so many viewers certainly attests to a contagious interest in  learning to machine learn.  (In later chapters, I return often to these pedagogical materials, and especially to the non-academic or translational accounts of machine learning written by and for software developers or non-machine learning experts. )

Implementations of machine learning algorithms and techniques have proliferated in software libraries,  many of which are open source. Code operationalises formalisation in ways that textbooks and lectures cannot. Available as software libraries, packages and online web services, and described, discussed and debated in many print and online formats, machine learners are heavily involved in writing and reading code. The entwining of machine learning with the practical specificities of code engenders surprising moments of *circulation.* `kittydar` exemplifies this circulation in which machine learners drift through the archipelagos of software development and coding, landing up in very far-scattered locations (such as a web browser). Similarly, if we turn to contemporary fields of knowledge production, the engineering and scientific literature that either explicitly develops or draws machine learning  in the last two decades mounts up to several hundred thousand publications (see Chapter \ref{ch:diagram} )  and probably several million more publications in scattered scientific fields (including increasingly many humanities and social sciences) indirectly make use of them. This is both forensically useful and a challenge to analyse. 

HERE

While these kinds of formalisms can readily be found in textbooks or on whiteboards and blackboards, and lecture slide presentations, their implementations in software are heavily proliferating in the world. Where they travel is sometimes hard to know. As the techniques circulate more widely, they *generalize* into quite diverse niches of contemporary life. While the linear models shown in Equations \ref{eq:linear_model} and \ref{eq:linear_regression_inner_product} forms of awareness of the techniques hybridise with the techniques, so that new forms of agency arise. The ways in which people use the techniques in journalism, in the humanities, in social sciences, in art, media, government or civil society overflows the scientific literature and these overflows are not easily seen. Many discussions of 'Big Data,' -- a term I'm planning  to mostly ignore -- don't even mention the pivotal role played by machine learning and suchlike techniques, and this omission makes it much harder to  the accompanying forms of practical awareness, and the new senses of agency that goes alongside that awareness. For instance, if a programmer working on a website incorporates a predictive algorithm to classify users of the website and to vary the what they see on the basis of that classification [@Segaran_2007], what they make in that work is quite different from what might have been done by a web developer in 2000. Say they make use of a Naive Bayes predictive model to classify whether someone visiting a website is likely to be high income or interested in computer games, and then display different banners or advertisements accordingly. The typical machine learning classifier depends on a set of training data whose categories have already been assigned by someone. These categories are sometimes simply an existing set of classifications derived from institutionalised or accepted practice. Sometimes, whole new sets of categories have been invented for a particular purpose. Occasionally, the classifications are 'purely' algorithmic and rely on no direct human intervention (as for instance in many face recognition systems that simply suggest whether a particular has been seen before). Across this spectrum of possible classificatory regimes, there is always some way in which these algorithmics are counting, sorting, ordering and classifying in ways that cut across or cross-section lives. The person who finds themselves paying a different price for a holiday by virtue of some unknown combination of factors including age, credit score, home address, previous travel, or educational qualifications is defined differently by that. 

Hardly politicised or power-sensitive, there is a diffuse but nonetheless collective form of awareness emerging around machine learning techniques. As these techniques have propagated from various specialised setting where they first took shape, as they have been taken up and repurposed  in new settings, and particularly as they have become near popular topics of discussion amongst software developers, information architects and chief technology officers, their capacity to classify, to predict, to cluster or order traits of people, things and events have become the focus of close scrutiny and interest. This interest can be seen in the many training and instructional materials associated with the techniques. 



>_Category_ is a key mechanism whereby certain types of ordered (often 'ritualized') practice produce power by enacting and embodying categories that serve to mark and divide up the world in certain ways. Without _some_ ordering feature of practice, such as 'categories', it is difficult to connect the multiplicity of practice to the workings of power, whether in the media or in any other sphere. By understanding the work of categories, we get a crucial insight into why the social world, in spite of its massive complexity still appears to us as a _common_ world [@Couldry_2012, 62]
