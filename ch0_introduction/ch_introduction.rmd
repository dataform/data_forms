\chapter{Introduction}
\label{ch:introduction}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  warning=FALSE, message=FALSE, dev='pdf')
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
library(ggplot2)
library(stringr)
library(xtable)
options(xtable.comment = FALSE)
```

>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ [@Mitchell_1997,2]. \index{Mitchell, Tom} \index{machine learner!computer program as}

>In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling [@Breiman_2001a,200] \index{Breiman, Leo}

>The key question isn't 'How much will be automated?' It's how we'll conceive of whatever _can't_ be automated at a given time. [@Lanier_2013, 77]

A relatively new field of scientific-engineering devices  has become operational in the last three decades. The field is known by various names -- machine learning, pattern recognition, knowledge discovery, data mining -- and the devices seem to have quickly migrated across scientific disciplines, business and commercial applications, industry, engineering, media, entertainment and government. Heavily dependent on calculation, they are found in breast cancer research, in autonomous vehicles, in insurance risk modelling, in credit transaction processing, in computer gaming, in face and handwriting recognition systems, in astronomy, advanced prosthetics, robots, ornithology, finance and surveillance (see the U.S. Government's `SkyNet` for one example of a machine learning surveillance system [@NationalSecurityAgency_2012]). \index{machine learner!National Security Agency Skynet} Sometimes these devices are understood as _scientific models_, and sometimes they are understood as _operational algorithms_ or machines. In very many scientific fields, publications mention or describe these techniques as part of their analysis of some experimental or observational data (as in the logistic regression classification models found in a huge number of biomedical papers). They anchor the field of 'data science' [@Schutt_2013]. \index{data science!relation to machine learning} Not so recently, they became mundane mechanisms, lying somewhere quite deeply embedded in other systems or gadgets (as in the decision tree models used in some computer game consoles to recognise gestures or the neural networks used to recognise voice commands by search engine services such as Google Search and Apple Siri [@McMillan_2013] ). In many operational settings, they operate behind the scenes as part of the everyday functioning of services ranging from player ranking in online games to border control face recognition, from  credit scores to advanced full limb prosthetics.  The flexibility or plasticity of these machine learners, their proliferation and propagation in the world, and the epistemic-operational value accruing to them by virtue of their capacity to 'learn from experience' are the concerns of this book. 

```{r cat, engine='python', fig.show='hide', cache=TRUE, echo=FALSE, message=FALSE}

import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import color, exposure
import skimage
im = skimage.io.imread('figure/gray-tabby-cat-with-green-eyes-close-up.jpg')
image = color.rgb2gray(im)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))
ax1.axis('off')
ax1.imshow(image, cmap=plt.cm.gray)
ax1.set_title('Input image')
fd, hog_image = hog(image, orientations=8, pixels_per_cell=(52, 52),
                    cells_per_block=(1, 1), visualise=True)
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))
ax2.axis('off')
ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)
ax2.set_title('Histogram of Oriented Gradients')
plt.savefig('figure/cat_hog.pdf')
```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/cat_hog.pdf}
        \caption[Cat as histogram of gradients]{Close up of cat. The image on the left is already signal processed as JPEG format file. The image on the right is further signal processed using histogram of oriented gradients (HOG) edge detection. \texttt{kittydar} models HOG features.  Photo courtesy photos-public-domain.com}
  \label{fig:cat}
\end{figure}

What does it mean that machine learners  surface in so many different places, from fMRIs to Facebook, from fisheries management to Al Queda courier network monitoring? This book is an attempt to answer that question by describing the general horizon of machine learning as a data practice in its specificity. \index{data!practice} Take the case of `kittydar,` a machine learner in the area of image recognition (see [kittydar](http://harthur.github.io/kittydar)): 'Kittydar is short for kitty radar. Kittydar takes an image (canvas) and tells you the locations of all the cats in the image' [@Arthur_2012] \index{kittydar}. This playful piece of code demonstrates the deployment of a machine learner  in the mundane, not to say banal, domain of cat photos on the internet. \index{image recognition}  Heather Arthur, who developed `kittydar` writes:

>Kittydar first chops the image up into many “windows” to test for the presence of a cat head. For each window, kittydar first extracts more tractable data from the image's data. Namely, it computes the Histogram of Orient Gradients descriptor of the image, using the hog-descriptor(http://github.com/harthur/hog-descriptor) library. This data describes the directions of the edges in the image (where the image changes from light to dark and vice versa) and what strength they are. This data is a vector of numbers that is then fed into a neural network(https://github.com/harthur/brain) which gives a number from 0 to 1 on how likely the histogram data represents a cat. The neural network (the JSON of which is located in this repo) has been pre-trained with thousands of photos of cat heads and their histograms, as well as thousands of non-cats. See the repo for the node training scripts [@Arthur_2012].

This toy example of machine learning data practice finds cat heads in digital photographs, but we can easily imagine similar pattern recognition techniques in use in self-driving cars, border security systems,  military robots or wherever there is something to be seen.  `Kittydar` runs in Javascript in a web browser, and only detects the presence of cats that face forward. As Arthur's description  suggests, the software finds cats by cutting the images into smaller windows. For each window, it measures a set of gradients running from  light and dark, and then compares these gradients to the gradients of known cat images (the training set). The intuition here is that edges and sudden shifts from light to dark are associated with the features on a cats in a fairly regular pattern. The work of classification according to the simple categories of 'cat' or 'not cat' \index{classification}  is either given  to a neural network (as discussed in chapter \ref{ch:subject}), a typical machine learning technique and one that has recently been heavily developed by researchers at Google [@Le_2011], themselves working on images of cats among other things taken from Youtube videos [@BBC_2012] \index{neural network!see{machine learner!neural net}}, or to a support vector machine, a technique first developed in the 1990s by researchers working at IBM (see chapter \ref{ch:pattern}). \index{support vector machine!see{machine learner!support vector machine}} 

Machine learners range from the mundane to the esoteric, from the miniature to the infrastructural sublime of computational clouds. Like `kittydar`, they often classify, rank, cluster and estimate things.  Their names accumulate and repeat in textbooks, instructional courses, website tutorials, software libraries and code listings: linear regression \index{linear regression}, logistic regression, \index{machine learner!logistic regression} neural networks \index{machine learner!neural net}, linear discriminant analysis \index{machine learner!linear discriminant analysis}, support vector machines, \index{support vector machine} k-means clustering, \index {k-means clustering} decision trees \index{decision tree!see{machine learner!decision tree}, _k_ nearest neighbours, \index{nearest neighbours|see{machine learner!_k_ nearest neighbours}}  random forests, \index{principal component analysis} principal component analysis, or naive Bayes classifier \index{machine learner!Naive Bayes} to name just some of the most commonly used. Sometimes they have proper names: `RF-ACE`, `Le-Net5`, or `C4.5`.  These names refer to predictive models and to computational algorithms of various ilk and provenance. A dauntingly intricate panoply of modelling and data practices -- normalization, regularization, cross-validation, feature engineering, feature selection, optimisation \index{data!preparation} -- that suture datasets into shapes they can recognise. Those techniques of preparation and evaluation of data themselves span a field of infrastructural vectors ranging from lists and tables of data in files and spreadsheets through to intricately engineered mechanisms for storing and retrieving large amounts of data such as databases, filestores, archives and computational clusters. The techniques, algorithms and models are not necessarily startling new or novel. They take shape against a background of more than a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Formidable mathematical constructs drawn from linear algebra, vector spaces, differential calculus, numerical optimization and probability theory heavily stratify practice in the field. [^0.15] \index{mathematics}

I am focusing on machine learners \index{machine learner|textbf} -- a term that refers to both humans and machines throughout this book --  and not algorithms, databases, infrastructures, or data visualization more generally because the data practices associated with machine learning delimit a specific _positivity_ of knowing. \index{positivity!of knowledge} Limiting the focus  to machine learning involves some risks. On the one hand, single minded focus on machine learning or particular machine learners such as neural nets or linear discriminant analysis \index{linear discriminant analysis|see{machine learner!linear discriminant analysis}} risks  fetishizing or essentializing machine learners as machines or algorithms. To attribute primacy to the algorithm or the predictive model would be to uncritically re-iterate many contemporary performances and representations that privilege machines and marginalize their human others. On the other hand, to favour analysis of the economically, socially, and political charged contexts of machine learning would be to downplay the positivity, the relational potentials and eventfulness that might inhabit their operations. Although vital, a contextual analysis  might lose sight of the transformed things, scales, processes and practices taking shape as machine learners, human and non-human, shade into each other. While `kittydar` locates cats, other  machine learners disaggregate cancer sub-types, patterns of speciation in birds, identify Al-Qaeda operatives or attune the movements of a prosthetic hand to nerve activations in an amputees' residual limb. Power and knowledge, control and positivity mix thoroughly in  machine learning. I find it difficult to separate the novel human-machine relations that have been taking shape in machine learners in their knowledge-making practices from  the systems of control, classification,  decision, power and discrimination they also operate. \index{control} I suspect I'm not alone in that difficulty, and for that reason, I attempt in the chapters that follow to carefully describe practices, knowledges, forms and terrains specific to machine learning. 

Machine learners  today circulate into domains that lie far afield of the eugenic and psychology laboratories, industrial research institutes or specialized engineering settings in which they first took shape (in some cases, such as the linear regression model or principal component analysis, more than a century ago; in others such as support vector machines or random forests, in the last two decades). If they are not exactly new and have diverse genealogies, the question is: does something important happen  as machine learners  shift from being mathematical or engineering techniques to an everyday device that can be generalized to locate cats in digital images, the Higgs boson in particle physics experiments or fraudulent credit card transactions? Does the somewhat unruly generalization of machine learning \index{generalization} across different epistemic, economic, institutional geographies attest to a re-definition of knowledge, decision and control, a new operational field, \index{Foucault, Michel}\index{operation, field of}  as the philosopher Michel Foucault might put it, for knowledge [@Foucault_1972, 106]?

# All control to the machine learners?

Machine learners operate as programs. Machine learning can be viewed as a change in how programs or the code that controls computer operations are written and operate. From a control perspective,  machine learners continue the 'control revolution'  that arguably has, since the late nineteenth century, programmatically re-configured production, distribution, consumption, and bureaucracy [@Beniger_1986]. \index{control!control revolution}  With the growth of communication networks, the late 20th century suffered a new crisis of control, commensurate with the mid-19th century crisis described by James Beniger  [@Beniger_1986]. Almost all accounts of the operation power of machine learning emphasise its power to automate the control of processes -- border flows, credit fraud, spam email, financial market prices, gene expression, targetted online adverts -- whose unruly or transient multiplicity otherwise evades or confuses us.  

If a new programmatic field of knowledge-control takes shape around machine learning, how would we recognize it? In a study of border control systems, which often use machine learners to do profiling and facial recognition \index{facial recognition},  Louise Amoore advocates attention to calculation and algorithms:

> Surely this must be a primary task for critical enquiry – to uncover and probe the moments that come together in the making of a calculation that will automate all future decisions. To be clear, I am not proposing some form of humanist project of proper ethical judgement, but rather calling for attention to be paid to the specific temporalities and norms of algorithmic techniques that rule out, render invisible, other potential futures [@Amoore_2011]. \index{Amoore, Louise}

As Amoore writes, some potential futures are being 'ruled out' as these devices are put to work. Anna Munster \index{Munster, Anna} puts the challenge more bluntly: 'prediction takes down potential' [@Munster_2013]. I find much to agree with here. Machine learning is a convoluted but nevertheless concrete and historically specific form of calculation \index{calculation|see{mathematics!calculation} (as we will see in exploring algebraic operations in chapter \ref{ch:vector}, in finding and optimising certain mathematical functions in chapter \ref{ch:function} or in characterising and shaping probability distributions in chapter \ref{ch:probability}). It tends to algorithmically mediate future-oriented decisions (although all too often, very near-future decisions)\index{decision}.  It automates, and in many cases, specifically aims to automate that which hitherto appeared impossible to automate. And this automation, with all the investment it attracts (in the form of professional lives, in the form of infrastructures \index{infrastructure}, in research funding, in reorganisation of corporate and government processes, etc.) does rule out some and reinforce other futures. As for consequences, we need only consider some of the many forms of work that have already been affected by or soon could be affected by machine learning. Postal service clerks no longer sort the mail because neural net-based handwriting recognition reads addresses on envelopes \index{handwriting recognition|seealso{digit recognition}}. Locomotives, cars and trucks are already driven by machine learners, and soon driving may not be same occupational cultural it was. Hundreds of occupational categories have to some degree or other machine learners in their near future.[^0.001]

Given the consequential weight of such algorithms and calculations, how do we uncover the moments that come together in them? We might see algorithms as making calculation automatic. In various scholarly and political debates around changes business, media, education, health, government or science, quasi-omnipotent agency has been imputed to algorithms  \index{algorithm!primacy} [@Pasquinelli_2014;@Neyland_2014;@Totaro_2014;@Smith_2013; @Beer_2013;@Fuller_2012;@Wilf_2013; @Barocas_2013; @Gillespie_2014; [@Cheney-Lippold_2011;  @Galloway_2004] or sometimes just 'the algorithm.' The power of algorithms in the social science and humanities literature is understood in different ways, but there is general agreement that these techniques are powerful, or at least, can bear down heavily on people's lives and conduct, re-configuring, for instance, culture as algorithmic [@Hallinan_2014].  In what does this power consist? What imbues algorithms with power? Is there some general  or 'breakout' feature such as recursivity \index{algorithm!recursivity}) or abstraction \index{abstraction!in algorithms}  that configures contemporary rationality algorithmically? 

Much of the critical literature on algorithms identify their mathematical or predictive aspects as the source of their power. For instance, in his discussion of the 'metadata society,' Paolo Pasquinelli proposes that 

> a progressive political agenda for the present is about moving at the same level of abstraction as the algorithm in order to make the patterns of new social compositions and subjectivities emerge. We have to produce new revolutionary institutions out of data and algorithms. If the abnormal returns into politics as a mathematical object, it will have to find its strategy of resistance and organisation, in the upcoming century, in a mathematical way [@Pasquinelli_2015]. \index{Pasquinelli, Paolo}

'Moving at the same level of abstraction as the algorithm' offers some purchase as a formulation, but I find 'the' algorithm, 'the level of abstraction' and 'a mathematical way' all troublesome as ways of qualifying machine learners.  Which algorithm, what kind of abstraction and which mathematical way should we focus on? From the standpoint of diverse  machine learners and the many different person-thing-object-relations they encompass, there is no single level of abstraction, but something more like the torque and flux of different moments of abstraction at work in generalizing, classifying, circulating and stratifying in the midst of transient and plural multiplicities. [^0.12]  \index{abstraction!algorithm as} 

# The archaeology of a data practice

The coming together of moments in machine learning have a play in them that notions of _technique_ \index{technique!limits of}, automation \index{automation!limits of}, algorithm or mathematical calculation do not fully accommodate. Each of these terms -- technique, automation, algorithm, calculation -- somewhat misses the specific temporalities of machine learners as forms of data practice. As I will suggest, algorithms, calculations, techniques and data cohere as machine learners in specific ways. This makes them harder to see as devices or indeed in context. While they can be contextualised in industry, science or government, they themselves contextualise data, decisions, classifications and rankings.  Viewed as an ordering practice,   we might analyse how machine learners diagonally weave, layer and leverage techniques, calculations and algorithms in infrastructures, institutions and everyday lives. \index{machine learner!diagrammatic composition of}  With the certain variations in focus (for instance, paying close attention to the substitution and connection of various diagrams; see chapter \ref{ch:diagram}), could we see some stable forms -- and these often achieve mathematical formalization as they become stable --  amidst the maelstrom of platforms, devices, skills, claims and advocates flowing around them? We might see change that occurs more slowly than what flows around them. \index{mathematics!as stabilisation of practice}

Understood as a data practice, we can begin to see the emergence of regularities and forms of order that allow higher levels of abstraction -- the algorithm, the data, the mathematical, indeed, abstraction itself -- to cohere. Nearly all machine learners can classify things. They are often simply called  'classifiers.'  `Kittydar` does this,  but categorisation and classification applies much more generally.[^0.007] Many machine learners predict categories, levels, rankings, and values (for instance, prices or risks -- see Chapter \ref{ch:genome}). In his account of media power, Nick Couldry highlights the importance of categories and categorisation:

>_Category_ is a key mechanism whereby certain types of ordered (often 'ritualized') practice produce power by enacting and embodying categories that serve to mark and divide up the world in certain ways. Without _some_ ordering feature of practice, such as 'categories', it is difficult to connect the multiplicity of practice to the workings of power, whether in the media or in any other sphere. By understanding the work of categories, we get a crucial insight into why the social world, in spite of its massive complexity still appears to us as a _common_ world [@Couldry_2012, 62] \index{Couldry, Nick} \index{categories}, \index{power}

The orderings of practice, effected through categories, undergo a great deal of intensification via machine learning. While Couldry does not in this context discuss data mining, machine learning  or predictive analytics, his analysis of categorisation and its contribution to a massively complex but common social world points directly to the order of practice of practice.

Machine learning might be seen as an ordering of category practice that mark up and divide the world. The operation of classification or prediction usually depends on a set of training data \index{data!training} whose categories are already known or have been assigned by someone (expert or not). These categories are sometimes simply an existing set of classifications derived from institutionalised or accepted practice. Machine learners also generate new categorical workings or mechanisms of category creation. Sometimes, new sets of categories have been invented or found for a particular purpose. The person who finds themselves paying a different price for a holiday by virtue of some unknown combination of factors including age, credit score, home address, previous travel, or educational qualifications experiences something of the diagrammatic movements. 

If abstractions, mathematics or the algorithm loom large in classification practices today, how do we re-establish their connection to the workings of power without pre-emptively ascribing potency to the mathematical way, to the algorithm or abstraction? In the chapters that follow, I map machine learning data practices in greater empirical and conceptual depth, and develop some terms to describe them less generically (common vector space in Chapter \ref{ch:vector}, partial observer trajectory in Chapter \ref{ch:function},  decision surface in Chapter \ref{ch:pattern}, inverse probabilization in Chapter \ref{ch:probability}), but all of the facets I describe cluster around the problem of understanding how an almost banal, not esoteric, operation is repeated, borrowed, copied and diffused in so many settings.

From this perspective, the mathematical abstractions, whether they come from calculus, linear algebra, statistics, or topology, maximise the repetition of regularities. The power of machine learning to find patterns, to classify or predict depends on a highly regularized form of ordering practice. \index{machine learning!regularization}. The different facets of ordering practice I discuss arrange data in certain ways and not others, traverse data along certain lines, curves and surfaces, pay close attention to variations and generalization. These practices precede, prepare, shape and limit the algorithms, the abstractions and their predictions or classifications. 

# Massive asymmetries in a common world

If we see a massive regularization of order occurring in machine learning, what is at stake in trying to think through those practices? They display moments of formalisation (especially mathematical and statistical), circulation (pedagogically and operationally), generalization (encompassing many genera and generic forms of practice) and stratification (the socially, epistemically, economically and sometimes politically or ontologically loaded re-iterative enactment of categories). Can we analyse, disentangle and situate these moments in terms of their relative forces, accumulations, points of attachment, locations and projections? Even if that ordering becomes more tangibly thinkable, would it change how would we relate to what we see, feel, sense, hear or think in the face of a contemporary webpage such as  Amazon's that uses Association Rule Mining \index{Association Rule Mining|see{machine learner!\textit{apriori} algorithm}}, an app, a passport control point that matches faces of arriving passengers with images in a database, a computer game, or a genetic test (all settings in which machine learning is likely to be operating)?

The ordering practices of machine learning \index{machine learning!as ordering practice} yield some rather stunning uniformities. Some expert practitioners complain of this uniformity.   Jeff Hammerbacher \index{Hammerbacher, Jeff}, previously chief research scientist at Facebook, co-founder of a successful data analytics company called Cloudera, and currently working also on cancer research at Mount Sinai hospital, complained about the use of machine learning in 2011: 'the best minds of my generation are thinking about how to make people click ads' [@Vance_2011] \index{advertising, online}. While much hinges on what is meant by 'best minds,' Hammerbacher was referring to the flourishing use of predictive analytics techniques in online platforms such as Twitter, Google and Facebook, and on websites more generally, whether they be websites that sell things or  advertising space. The 'best minds,' however they were ranked, presumably included PhDs from MIT, Stanford or Cambridge whose mathematical skills were wrangling data in the interests of micro-targeted advertising. As Hammerbacher observers, they were 'thinking about how to make people click ads,' and this 'thinking' mainly took and does take the form of building predictive models that tailored the ads shown on websites to clusters of individual preferences and desires. In thinking about individual people, and indeed, in seeking to figure an individual amidst very large numbers of people (often numbering millions and sometimes hundreds of millions), the 'best minds' were also constructing and operating with the very  forms of abstraction \index{abstraction!equations as} we see in Equation \ref{eq:linear_regression}.

Does Hammerbacher's unhappiness with ad click prediction resonates in critical responses to machine learning as used in other settings? Some versions of the digital humanities make extensive use of machine learning. \index{digital humanities} To cite one example,  _Macroanalysis: Digital Methods and Literary History_, Matthew Jockers \index{Jockers, Matthew}describes he or  we might relate to one currently popular machine learning or statistical modelling technique, the topic model \index{topic model} (itself the topic of discussion in Chapter \ref{ch:probability}; see also [@Mohr_2013] \index{Mohr, John}):

>   If the statistics are rather too complex to summarize here, I think it is fair to skip the mathematics and focus on the end results. We needn't know how long and hard Joyce sweated over _Ulysses_ to appreciate his genius, and a clear understanding of the LDA machine is not required in order to see the beauty of the result. [@Jockers_2013, 124]

The widely used topic models or Latent Dirichlet Allocation models provide a litmus test of how relations to machine learning is taking shape in the digital humanities. On the one hand, these models promise to make sense of large corpus of documents in terms of underlying themes or 'topics.' Latent topics and latent variables are of much more general interest in predictive modelling and classification (as we will, large document collections have long attracted the interest of machine learners). \index{data!latent variables in} On the other hand, Jockers signals the difficulties of relating to machine learning when he suggests that 'it is fair to skip the mathematics'  for the sake of 'the beauty of the result'. While one part of the humanities and critical social research exhorts closer attention to the mathematical, another averts its gaze in face of their complexity. 

The use of machine learning in digital humanities has not always been received enthusiastically. \index{Galloway, Alex} In a special issue of the journal _Differences: A Journal of Feminist Cultural Studies_ focusing on digital humanities, Alex Galloway makes two observations about the circulation and generalization of these methods in humanities scholarship: 

> When using quantitative methodologies in the academy (spidering, sampling, surveying, parsing, and processing), one must compete broadly with the sorts of media enterprises at work in the contemporary technology sector. A cultural worker who deploys such methods is little more than a lesser Amazon or a lesser Equifax.110 [@Galloway_2014, 110] 

Galloway is critical of the asymmetry between humanities scholars and media enterprises and credit score agencies.  The 'quantitative methodologies' that he refers to as  spidering, sampling, processing and so forth are more or less all epitomised in machine learning techniques (for instance, the Association Rule Mining techniques used by Amazon to recommend purchases, or perhaps the decision tree techniques \index{decision tree} used by the credit-rating systems at Equifax and Fico [@FICO_2015] ). Galloway's argument is that the infrastructural scale of these enterprises along with the sometime very large technical workforces they employ to continually develop new predictive techniques dwarfs any gain in efficacy that might accrue to humanities research in its recourse to such methods. 

Even if 'cultural workers' do manage to learn to machine learn, and become adept at re-purposing the techniques in the interests of something other than selling things or generating credit scores, what is to be gained by doing so? Galloway suggests that in doing so, they might actually reinforce power asymmetries and exacerbate the ethical and political challenges posed by machine learning:

>But beyond the challenge of unequal talent and resources is the question of critical efficacy. Is it appropriate to deploy positivistic techniques against those self-same positivistic techniques? In a former time, such criticism would not have been valid or even necessary. Marx was writing against a system that laid no specific claims to the apparatus of knowledge production itself—even if it was fueled by a persistent and pernicious form of ideological misrecognition. Yet, today the state of affairs is entirely reversed. The new spirit of capitalism is found in brainwork, self-measurement and self-fashioning, perpetual critique and innovation, data creation and extraction. In short, doing capitalist work and doing intellectual work—of any variety, bourgeois or progressive—are more aligned today than they have ever been [@Galloway_2014, 110]. \index{Galloway, Alex|)}

This perhaps is a more serious charge. The 'techniques' of machine learning are positivist (and hence implicitly at odds with critical thought?), and moreover complicit -- 'aligned' -- with capitalist work. Again, there is something that feels right in the naming of the predicament -- intellectual work of the kind associated with  machine learning -- is definitely at the centre of many governmental, media, business and scientific fields of operation. Increasingly, they anchor the operations of these fields. But do we know yet what it is to _deploy_ machine learning, especially if it not, as I have been suggesting the discussion of the four moments of formalisation, circulation, generalization and stratification, anything like a technique but something more like a problematisation \index{problematisation}?

Like Galloway, I'm wary of certain deployments of these techniques, particularly the platform-based deployments and their associated sociality [@Gillespie_2010; @VanDijk_2013]. There have been massive deployments already, and these tend to draw on complex meshing of computer science, mathematics, statistics, and a panoply number of scientific disciplines ranging from acoustics to telecommunications or remote sensing in order to create the classifiers and predictive models mobilised by media, finance, military and government. Indeed something is 'laying claim to the apparatus of knowledge production.' Yet even amidst the trashy ephemerality of targeted online advertising or the more elevated analytics of literary history, the transformations in knowledge and knowing are no simple alignment between intellectual work and capitalist work.  Researchers whether at Baidu or in an English department participate in the iterative re-drawing of relations, categories and differences. Could machine learners become engines of difference? The 'best minds of my generation' have been building engines of difference. While Hammerbacher and Galloway are understandably somewhat dismissive of the existential gratifications and critical efficacy of building targeted advertising systems or document classifiers, their 'deployment' is not a finished product. 

What form of data practice yields  let us take a preliminary look at line-oriented predictive calculations done by machine learners. In the early pages of a highly cited textbook on machine learning that I shall return to frequently [@Hastie_2009], the following equations appear:

\begin {equation}
\label{eq:linear_regression}
\hat{Y} = \beta_0 + \sum_{j=1}^{p}X_j\hat{\beta}_j
\end {equation}
\index{@S$\sum$}
\index{@Y$Y\hat{Y}$}

\begin {equation}
\label{eq:linear_regression_inner_product}
\hat{Y} = X^T\hat{\beta}
\end {equation}
\index{T@$\X^{T}$}

[@Hastie_2009, 11]

These expressions are a rather harsher introduction than the cats. The two equations \ref{eq:linear_regression} and \ref{eq:linear_regression_inner_product}, which more or less express the same thing (the second is known as the 'inner product' \index{inner product} form),  anchors much of the classifying work done by `kittydar`  and the lines that smooth the spiky data in the Google Trends plot shown in Figure \ref{fig:google_trends}. They both express the 'linear regression model' \index{linear regression|see{machine learner!linear regression model}} albeit using slightly different formalisms. Every character of these equations, as well as a set of conventions that more or less indirectly govern how the different characters and symbols relate to each other and how they track out into the world, is worth attending to from both the perspective of generativity (new things or relations in the world) and power (the orderings of conduct). In the interests of the tracking the calculations that move through machine learning  and situating the knowing associated with them,  I propose to look at these expressions as a diagram (see Chapter \ref{ch:diagram}) \index{diagram}. In this diagram,  each of the letters and symbols indicates a movement in some direction, an operation that connects, accumulates or separates either numbers or sets of numbers. Importantly, to preempt discussion that will be the subject of later chapters, both the neural networks and support vector machines to be found in `kittydar` derive from combinations and accumulations of these anchoring formalisms.[^0.11]\index{calculation|)} Hence mathematical expressions powerfully index the calculative moments I wish to analyse here. 

How are the expressions shown in Equations \ref{eq:linear_model} and \ref{eq:linear_regression_inner_product} read by machine learners (bearing in mind I use that term indiscriminately to include people and machines)? The *learning* of machine learning is part of the reality-making power of these operations. The learning of these formalisations has become surprisingly popular in recent years (hence the upward curve on the 'machine learning' Google Trend). Erstwhile Stanford professor of computer science Andrew Ng \index{Ng, Andrew} delivered a set of lectures on machine learning in 2008 that were uploaded to Youtube [@Ng_2008]. The lectures effectively begin by talking about the formalisms  of Equation \ref{eq:linear_regression} and Ng spends much time developing them through mathematical derivations, worked examples and references to relevant scientific literature and significant events in the field.  At the time of writing, they have been viewed by more than 0.5 million people. We don't how these people viewed Ng's lectures, nor what they did with them, but the fact that a set of lectures given to post-graduates on predictive modelling attracts so many viewers attests to a contagious interest in  learning to machine learn.  (In later chapters, I return often to these pedagogical materials, and especially to the non-academic or translational accounts of machine learning written by and for software developers or non-machine learning experts. )

While these kinds of formalisms can readily be found in textbooks or on whiteboards and blackboards, and lecture slide presentations, their implementations in software also proliferate in the world. Where they travel is sometimes hard to know. Implementations of machine learning algorithms and techniques have proliferated in software libraries,  many of which are open source. Code operationalises formalisation in ways that textbooks and lectures cannot. Available as software libraries, packages and online web services, and described, discussed and debated in many print and online formats, machine learners are heavily involved in writing and reading code. The entwining of machine learning with the practical specificities of code engenders surprising moments of *circulation.* `kittydar` exemplifies this circulation in which machine learners drift through the archipelagos of software development and coding, landing up in very far-scattered locations (such as a web browser). Similarly, if we turn to contemporary fields of knowledge production, the engineering and scientific literature that either explicitly develops or draws machine learning  in the last two decades mounts up to several hundred thousand publications (see Chapter \ref{ch:diagram} )  and probably several million more publications in scattered scientific fields (including increasingly many humanities and social sciences) indirectly make use of them. This is both forensically useful and a challenge to analyse. 

As the linear models shown in Equations \ref{eq:linear_model} and \ref{eq:linear_regression_inner_product} circulate in the communicative formalisations of pedagogy and training and in the operational forms of code,  awareness of their diagrammatic play hybridises with operational power ('power has no essence; it is simply operational' [@Deleuze_1988, 27]) so that new forms of agency arise.[^0.91]  For instance, if a programmer working on a website incorporates a predictive algorithm to classify users of the website and to vary the what they see on the basis of that classification (and this started to happen widely sometime around 2005; see, for example, *Programming Collective Intelligence* [@Segaran_2007]), \index{Segaran, Toby} what they make in that work is quite different from what might have been done by a web developer in 2000 as they sought to re-design web pages using a database-driven content system. If they make use of a Naive Bayes predictive model to classify whether someone visiting a website is likely to be high income or interested in computer games, and then display different banners or advertisements accordingly, what changes? 


# The play in the diagram

At the same time, we surely must recognise that the coming together of algorithm, calculation and technique, all of which should be specified in greater detail, in a form of data practice, is not fully coherent or complete. By virtue of their diagrammatic composition, they might bring something new into the worlds they traverse. They reorganise data, calculation, classification, decision, control and prediction in ways that might have some precedent, but are nevertheless quite hard to grasp without a nuanced understanding of their diagrammatic composition. How would we access that?

We might understand the play in the diagram, or the space for the advent of something, in terms of discovery or invention by abstraction. \index{diagram!as abstraction} Machine learners propose to create knowledge (exactly what kind of knowledge is open to debate) that would be otherwise difficult or even impossible to produce.  For instance, how many cat photos are on the internet? This empirical question might be answerable only through machine learning. `kittydar` would need 300,000 cores on Google Compute Engine for several hours. Similarly, NSA's `Skynet` purports to identify Al-Qaeda couriers in Pakistan, but seems to also detect well-known Al-Jazeera journalists [@NationalSecurityAgency_2012]. Leaving aside errors for the moment (error will be a major topic in several later chapters), the claim to know differently or better pivots on abstraction, and mathematical abstraction in particular.

Amidst available framings for the recognition of the hitherto unseen, abstraction stands out as one of the most richly developed theoretical resources. Accounts of abstraction -- Karl Marx's real abstraction, Gilles Deleuze and Félix Guattari's abstract machines, Henri Bergson's lived abstraction, Alfred North Whitehead's fortunate abstraction, or Isabelle Stengers' experimental abstractions -- are not lacking.[^0.301] \index{abstraction!accounts of} Although the philosophical theories of abstraction I have just listed differ in many ways, they all, without exception, array themselves in opposition to any limitation of abstraction to mathematical or modern scientific knowledge in particular. All of them, by often convoluted conceptual paths,  seek to retrieve from abstraction something conducive to change, differences and contestation.

Any theory of abstraction faces a real test when confronted by operational practices of abstraction such as machine learning. \index{abstraction!operational practice of} Can it affirm abstraction without othering the technical practice of abstraction? Is machine learning an abstraction we can live with, a lived abstraction as Brian Massumi would call it [@Massumi_2013]? \index{abstraction!lived} I find the question of whether machine learning is a liveable abstraction too hard to answer conclusively. Certainly, accounts of abstraction -- abstract machine, real abstraction for instance -- help make sense of important movements in machine learning. But without grounding these abstractions in the practice of machine learning, it is very hard to make sense of how it abstracts. Without tracing how number, chance, classification and event come together in it, the texture of its abstraction, and hence any possible sense of its liveable relationality, remains unfelt and unthought. 





to add -- machine learning pulls big data into being; what are the precedents in trying to make sense of such things -- algorithms, epistemic objects, network society, feed forward, etc. Go back to Foucault to try to find propositions that help excavate the knowledges of order, distribution, ranking and estimation shaping up here.

[^0.001]: Carl Benedikt Frey and Michael Osborne model the chances of occupational change for 700 occupations using, aptly enough, the machine learning technique of Gaussian Processes [@Frey_2013]. 

[^0.301]: [@McCormack_2012] reviews some of the large literature on abstraction. The differences between different accounts of abstraction will run through many of the following chapters. 

[^0.11]: The machine learning researchers Trevor Hastie, Tibshirani and Jerome Friedman, whom I will often cite in the pages that follow, describe neural networks, for instance in this way:  
    >Projection pursuit and neural network models consist of sums of non-linearly transformed linear models [@Hastie_2009, 18].
    The linear models and their non-linear transforms are hence worth focusing on in some detail and later chapters return to them repeatedly. 

[^0.007]: John Cheney-Lippold offers a quite general overview of categorization work. He writes:  'algorithm ultimately exercises control over
us by harnessing these forces through the creation of relationships between
real-world surveillance data and machines capable of making statistically
relevant inferences about what that data can mean' [@Cheney-Lippod_2011, 178]. \index{classification!algorithms for}. Much of my discussion here seeks to explore the space of 'statistical inference of what that data can mean.'
