\chapter{Introduction}
\label{ch:introduction}


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  warning=FALSE, message=FALSE, dev='pdf')

library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
res = dbGetQuery(con, statement ="select * from basic_refs limit 10;")
```

## Introduction - a decisive change in the place of prediction

>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ [@Mitchell_1997,2]. \index{Mitchell, Tom}

>In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling [@Breiman_2001a,200] \index{Breiman, Leo}

>The key question isn't 'How much will be automated?' It's how we'll conceive of whatever _can't_ be automated at a given time. [@Lanier_2013, 77]

A relatively new field of scientific-engineering devices  has become operational in the last three decades. The field is known by various names -- machine learning, pattern recognition, knowledge discovery, data mining -- and the devices are scattered across scientific disciplines, business and commercial applications, industry, engineering, media, entertainment and government. Heavily dependent on calculation, they are found in breast cancer research, in autonomous vehicles, in insurance risk modelling, in credit transaction processing, in computer gaming, in face and handwriting recognition systems, in astronomy, ornithology, finance and surveillance. Sometimes these techniques are understood as _scientific models_, and sometimes they are understood as _operational algorithms_ or machines. In very many scientific fields, publications mention or describe these techniques as part of their analysis of some experimental or observational data (as in the logistic regression classification models found in a huge number of biomedical papers). More recently, they have become quasi-automatic mechanisms, lying somewhere quite deeply embedded in other systems or device (as in the decision tree models used in some computer game consoles used to recognise gestures or the neural networks used to recognise voice commands by search engine services such as Google Search [@McMillan_2013] ). In many operational settings, they operate behind the scenes as part of the everyday functioning of devices and services ranging from player ranking in online games to border control face recognition, from  credit scores to advanced full limb prosthetics.  The flexibility or plasticity of these machine learners, their proliferation and propagation in the world, and the epistemic-operational value accruing to them by virtue of their capacity to 'learn from experience' are the concerns of this book. What kind of equivalence allows these techniques to work in so many different places? 

```{r cat, engine='python', fig.show='hide', cache=TRUE, echo=FALSE, message=FALSE}

import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import color, exposure
import skimage
im = skimage.io.imread('figure/gray-tabby-cat-with-green-eyes-close-up.jpg')
image = color.rgb2gray(im)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))
ax1.axis('off')
ax1.imshow(image, cmap=plt.cm.gray)
ax1.set_title('Input image')
fd, hog_image = hog(image, orientations=8, pixels_per_cell=(52, 52),
                    cells_per_block=(1, 1), visualise=True)
# Rescale histogram for better display
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))
ax2.axis('off')
ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)
ax2.set_title('Histogram of Oriented Gradients')
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),
                    #cells_per_block=(1, 1), visualise=True)
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(32, 32),
                    #cells_per_block=(1, 1), visualise=True)
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(62, 62),
                    #cells_per_block=(1, 1), visualise=True)
plt.savefig('figure/cat_hog.pdf')

```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/cat_hog.pdf}
        \caption[Cat as histogram of gradients]{Close up of cat. The image on the left is already signal processed as JPEG format file. The image on the right is further signal processed using histogram of oriented gradients (HOG) edge detection. \texttt{kittydar} models HOG features.  Photo courtesy photos-public-domain.com}
  \label{fig:cat}
\end{figure}

Take the case of `kittydar,` a small demonstration of machine learning techniques in the area of computer vision (see [kittydar](http://harthur.github.io/kittydar)): 'Kittydar is short for kitty radar. Kittydar takes an image (canvas) and tells you the locations of all the cats in the image' [@Arthur_2012] \index{kittydar}. This playful piece of software demonstrates the deployment of computer vision in the mundane, not to say banal, domain of cat photos on the internet. Heather Arthur, who developed `kittydar` writes:

>Kittydar first chops the image up into many “windows” to test for the presence of a cat head. For each window, kittydar first extracts more tractable data from the image's data. Namely, it computes the Histogram of Orient Gradients descriptor of the image, using the hog-descriptor(http://github.com/harthur/hog-descriptor) library. This data describes the directions of the edges in the image (where the image changes from light to dark and vice versa) and what strength they are. This data is a vector of numbers that is then fed into a neural network(https://github.com/harthur/brain) which gives a number from 0 to 1 on how likely the histogram data represents a cat. The neural network (the JSON of which is located in this repo) has been pre-trained with thousands of photos of cat heads and their histograms, as well as thousands of non-cats. See the repo for the node training scripts [@Arthur_2012].

This toy example of machine learning finds cat heads in digital photographs, but we can easily imagine similar techniques in use in self-driving cars, border security systems,  military robots or wherever there is something to be seen. `Kittydar` runs in Javascript in a web browser, and can only really detect the presence of cats that are facing forward. As the description provided by Arthur suggests, the software finds cats by chopping up the images into smaller windows. For each window, it measures a set of gradients running from  light and dark, and then compares these gradients to the gradients of known cat images (the training set). The intuition here is that edges and sudden shifts from light to dark are associated with the features on a cats in a fairly regular pattern. The work of classification according to the simple categories of 'cat' or 'not cat' \index{classification}  is either given  to a neural network (as discussed in chapter \ref{ch:subject}), a typical machine learning technique and one that has recently been heavily developed by researchers at Google [@Le_2011], themselves working on images of cats among other things taken from Youtube videos [@BBC_2012] \index{neural network}, or to a support vector machine, a technique first developed in the 1990s by researchers working at IBM (see chapter \ref{ch:pattern}). \index{support vector machine} 

The names of these techniques accumulate and have been re-iterated in many textbooks, instructional courses, website tutorials and descriptions: linear regression \index{linear regression}, logistic regression, \index{logistic regression} neural networks \index{neural net}, linear discriminant analysis \index{linear discriminant analysis}, support vector machines, \index{support vector machine} k-means clustering, \index {k-means clustering} decision trees \index{decision trees}, _k_ nearest neighbours, \index{nearest neighbours}  random forests, \index{principal component analysis} principal component analysis, or naive Bayes classifier \index{Naive Bayes} to name just some of the most commonly used. These names refer to predictive models and to computational algorithms of various ilk and provenance. They are shadowed by a dauntingly intricate panoply of modelling and data preparation practices -- normalization, regularization, cross-validation, feature engineering, feature selection -- that suture their use. Those techniques of preparation and evaluation of data themselves rely on a gamut of infrastructural forms ranging from lists and tables of data in files and spreadsheets through to intricately engineered mechanisms for storing and retrieving large amounts of data such as databases, filestores, archives and computational clusters. The techniques, algorithms and models are not necessarily startling new or novel. They take shape against a background of a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Formidable mathematical constructs drawn from linear algebra, vector spaces, differential calculus, numerical optimization and probability theory heavily stratify practice in the field. 

I am focusing on these machine learners \index{machine learner|textbf} -- a term that refers to both humans and machines throughout this book --  and not data practices or algorithms in general, or databases, infrastructures, or data visualization, etc. This focus is a calculated risk. On the one hand, any single minded focus on machine learning or particular machine learners such as neural nets or linear discriminant analysis \index{linear discriminant analysis} risks hypostasising, fetishizing or essentializing machine learners as machines or algorithms. To attribute primacy to the algorithm or the predictive model would be to uncritically re-iterate many contemporary performances and representations that privilege machines and marginalize their human others. On the other hand, to steer away from the devices and machines in favour of analysis of their social uses and economically, socially, and political charged contexts would be to downplay their technicity [@Mackenzie_2002a]\index{technicity}, their relational potentials, eventfulness and materialities.

I aim to follow a narrow ridge that both traverses the novel human-machine relations that have been taking shape in machine learning in its knowledge-making operations *and * offers a view of the forms of control, decision, power and discrimination configured by machine learners. Regardless of the disorienting degree of media spectacle associated with predictive models (and announcements of this predictive or classificatory power have been frequent in recent years),  they do today circulate into domains that lie far afield of the laboratories, experimental or engineering settings in which they first took shape (in some cases, more than a century ago; in others, in the last two decades). If they are not exactly new and have diverse genealogies, the question is: does something important happen  as machine learners  shift from being mathematical or engineering specialisms to an everyday device that can be generalized to locate cats in digit images, the Higgs boson in particle physics experiments or credit fraud detection, or blackboxed, reverse engineered, disseminated, and taught to see cats? Does the somewhat unruly generalization of machine learning \index{generalization} across different epistemic, economic, institutional geographies attest to a re-definition of knowledge, decision and control, a new operational field,\index{Foucault, Michel}\index{operation, field of}  as the philosopher Michel Foucault terms, for knowledge [@Foucault_1972, 106]? Or, is this generalization a vast hyperobjectifying error? 

## All power to the algorithms?

In various scholarly and political debates around changes business, media, education, health, government or science, quasi-omnipotent agency has been imputed to algorithms  \index{algorithm!primacy} [@Pasquinelli_2014;@Neyland_2014;@Totaro_2014;@Beer_2013;@Fuller_2012;@Wilf_2013; @Barocas_2013; @Gillespie_2014; @Galloway_2004] \index{Gillespie, Tarleton}. The power of algorithms in the academic literature are understood in different ways, but there is general agreement that these techniques are powerful, or at least, can bear down heavily on people's lives and conduct. In what does this power consist? What imbues algorithms with power? Is there some general  or 'breakout' feature such as recursivity\index{recursivity}) that configures contemporary rationality algorithmically?

```{r google_trends_load, echo=FALSE, message=FALSE, warning=FALSE}

library(stringr)
df = read.csv('data/google_trends_clean.csv',  header=TRUE,stringsAsFactors=FALSE)
df$week = str_extract(df$Week, '\\d{4}-\\d{2}-\\d{2}')
df = df[, -1]
```

Scholarly interest in algorithms occurs amidst more general media culture interest in the topic. The volume and geography of searches on Google Search provides some evidence of interest in particular search topics over a period of roughly a decade. If we search for terms such as `r colnames(df)[1:5]` on the [Google Trends](http://www.google.com/trends) service \index{Google Trends}, the results for the last decade or so suggest both increasing and decreasing interest in these topics. 

```{r google_trends, echo=FALSE, message=FALSE, fig.env=TRUE, fig.cap='', include=FALSE, dpi=600, warning=FALSE}
library(ggplot2)
library(reshape)
dfm = melt(df, id.vars='week')
g = ggplot(dfm, aes(x=as.Date(week), y=value, group=variable))+ geom_line(aes(linetype=variable)) + geom_smooth(aes(linetype=variable)) + scale_x_date() + xlab('Years') + ylab('Google search volume')
g +  theme(legend.justification=c(1,0), legend.position=c(0.9,0.6), panel.grid.minor=element_blank(),  panel.grid.major=element_blank())

```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/google_trends-1.pdf}
        \caption{Google Trends search volume for `machine learning` and related query terms in English, globally 2004-2015}
  \label{fig:google_trends}
\end{figure}

Note in Figure \ref{fig:google_trends} that the two search terms that had a very high search volume in 2004 -- 'artificial intelligence' and 'data mining' \index{artificial intelligence} \index{data mining} -- display a relative decline over the years before starting to increase again in the last few years. By contrast, 'machine learning,' 'deep learning,' and 'predictive analytics' tend to increase during that decade. `Machine learning` interestingly appears prominently in 2004, loses volume until around 2008, and then gradually rises again so that by mid-2015 it roughly matches the long-standing interests in data-mining and artificial intelligence.[^0.3] In the plot (Figure \ref{fig:google_trends}, the weekly variations in search volume on Google give rise to many spikes in the data. These spikes can be linked to specific invents such as significant press releases, public debates, media attention and film releases. 

[^0.3]: It is hard to know who is doing these searches. The data provided by Google Trends includes geography, and it would be interesting to compare the geographies of interest in the different terms over time. 

The graphics shown Figure \ref{fig:google_trends} actually draw two lines for each trend. The 'raw' weekly GoogleTrends data -- definitely not raw, as it has been normalized to a percentage [@Gitelman_2013] appears in the very spiky lines, but a much smoother line shows the general trend. This smoothing line is the product of a statistical model -- a local regression or loess model [@Cleveland_1992] \index{Cleveland, William} developed in the late 1970s \index{local regression} -- that depends on some intensive computation and a variety of machine learning techniques (linear regression, _k_ nearest neighbours, \index{k-nearest neighbors, linear regression}. These smoother lines seem to make the spiky weekly search counts supplied by Google much easier to see. They construct alignments in  the data by replacing the heterogeneous variations with something that unequivocally runs through time. The smoothed lines already shade the diagram with a predictive orientation, in the same way that the histogram of oriented gradients already shaped the digital photograph in Figure \ref{fig:cat} towards the task of classification.  We need to understand how things have been arranged so that much runs like a smooth line through particular topics such as 'machine learning' or 'deep learning.' 

## Mod the algorithms?

The analytical challenge here is to modify or 'mod' algorithms enough to print or `cat`[^0.2]  something of what happens in their reality-directing operation. How would one do that? In the context of her study of border control systems, which often use profiling and facial recognition \index{facial recognition} techniques based on machine learning,  Louise Amoore writes:

[^0.2]: `cat`: the 'catenate' file utility found on many computer operating systems that outputs the contents of a file or any stream of data.

> Surely this must be a primary task for critical enquiry – to uncover and probe the moments that come together in the making of a calculation that will automate all future decisions. To be clear, I am not proposing some form of humanist project of proper ethical judgement, but rather calling for attention to be paid to the specific temporalities and norms of algorithmic techniques that rule out, render invisible, other potential futures [@Amoore_2011]. \index{Amoore, Lousie}

I find much to agree with here. Machine learning is a convoluted but nevertheless concrete and historically specific form of calculation \index{calculation|(} (as we will see in exploring algebraic operations in chapter \ref{ch:vector}, in finding and optimising certain mathematical functions in chapter \ref{ch:function} or in characterising and shaping probability distributions in chapter \ref{ch:probability}). It is very much concerned to algorithmically mediate future-oriented decisions (although all too often, very near-future decisions)\index{decision}.  It makes heavy use of automation, and in many ways, takes pride in its capacity to automate that which hitherto appeared impossible to automate. And this automation, with all the investment it attracts (in the form of professional lives, in the form of infrastructures \index{infrastructure}, in research funding, in reorganisation of corporate and government processes, etc.) does rule out some futures. We need only think of the many forms of work that have already been affected by machine learning. Postal workers no longer sort the mail because neural net-based handwriting recognition reads addresses on envelopes \index{handwriting recognition|seealso{digit recognition}}. Cars and trucks are already driven by machine learners, and soon driving may not be same work it was. These are mundane occupational changes, but places of work and their associated lives have already shifted in various ways around them.  

And yet, the coming together of moments in the making of these calculations have a play in them that the notion of _technique_ \index{technique} does not fully recognise if it isolates the technique from the diagrams, formalisms, transformations, trajectories, and fields attached to it. We need to analyse how machine learners weave techniques through infrastructures, institutions and everyday lives \index{machine learner}. The algorithms and techniques of machine learning, it is important to point out, cohere as machine learners only are actually far more stable than the maelstrom of platforms, devices, skills, claims and advocates around them. They do change but more slowly than what flows around them. At the same time, we surely must recognise that these techniques bring something new into the worlds they move through. They profoundly reorganise numbers, calculation, classification and prediction in ways that might have some precedent, but are nevertheless quite hard to grasp. Without  a way to make sense of these decisive changes in the nature of number, chance, classification and event, we cannot fully make sense of how worlds take shape. A new topology of difference is forming with the capacity to foster some forms of life and not others. As Amoore writes, some potential futures are being 'ruled out' as these devices are put to work. Anna Munster puts the challenge more starkly:'prediction takes down potential' [@Munster_2013]. \index{Munster, Anna}

## Moments in learning to classify

How should one uncover what flows through an algorithm, the moments that come together,  as it makes a calculation? Four moments  -- I understand moment as both a temporal marker and as a specific force acting around a reference point (as in torque) -- seem important to me: *formalisation; circulation; generalization; and stratification.* In the chapters that follow, I map these moments in greater empirical and conceptual depth, and develop some terms to describe them less generically (common vector space in Chapter \ref{ch:vector}, partial observer trajectory in Chapter \ref{ch:function}, generative discriminant in Chapter \ref{ch:probability}, decision surface in Chapter \ref{ch:decision},  error propagation in Chapter \ref{ch:subjects}), but  let us take a preliminary look at the interacting moments of the predictive calculations done by machine learners. In the early pages of a highly cited textbook on machine learning that I shall return to frequently [@Hastie_2009], the following equations appear:

\begin {equation}
\label{eq:linear_regression}
\hat{Y} = \beta_0 + \sum_{j=1}^{p}X_j\hat{\beta}_j
\end {equation}
\index{@S$\sum$}
\index{@Y$Y\hat{Y}$}

\begin {equation}
\label{eq:linear_regression_inner_product}
\hat{Y} = X^T\hat{\beta}
\end {equation}
\index{T@$\X^{T}$}

[@Hastie_2009, 11]

These expressions are a rather harsher introduction than the cat, but the two equations \ref{eq:linear_regression} and \ref{eq:linear_regression_inner_product}, which more or less express the same thing (the second is known as the 'inner product' \index{inner product} form),  are anchor points of both the classifying work done by `kittydar`  and the lines that smooth the spiky data in the Google Trends plot shown in Figure \ref{fig:google_trends}. They both express the 'linear regression model' \index{linear regression} albeit using slightly different formalisms. Every character of these equations, as well as a set of conventions that more or less indirectly govern how the different characters and symbols relate to each other and how they track out into the world, is perhaps worth attending to.  I will describe in more detail below how several different machine learning practices of formalisation intersect in these formal expressions. I don't expect that these somewhat abstract  formalisms are immediately understandable to everyone, and for readers who are not familiar with the techniques I am describing, it may be difficult to even look at these mathematical formalisms for very long without thinking that they have something better to do. They have taken me several years to get used to. In the interests of the tracking the calculations that move through machine learning  and situating the knowledge associated with them I propose to look at these expressions as a diagram (see Chapter \ref{ch:diagram}) \index{diagram}, with an eye for how each of the letters and symbols indicates a movement in some direction, an operation that connects, accumulates or separates either numbers or sets of numbers. Importantly, to preempt discussion that will be the subject of later chapters, both the neural networks and support vector machines to be found in `kittydar` derive from combinations and accumulations of these anchoring formalisms.[^0.11]\index{calculation|)}

[^0.11]: The machine learning researchers Trevor Hastie, Tibshirani and Jerome Friedman, whom I will often cite in the pages that follow, describe neural networks, for instance in this way:  
    >Projection pursuit and neural network models consist of sums of non-linearly transformed linear models [@Hastie_2009, 18].
    The linear models and their non-linear transforms are hence worth focusing on in some detail and later chapters return to them repeatedly. 

How are the expressions shown in Equations \ref{eq:linear_model} and \ref{eq:linear_regression_inner_product} read by machine learners (bearing in mind I use that term indiscriminately to include people and machines)? The *learning* of machine learning is part of the reality-making power of these operations. The learning of these formalisations has become surprisingly popular in recent years (hence the upward curve on the 'machine learning' Google Trend). Erstwhile Stanford professor of computer science Andrew Ng \index{Ng, Andrew} delivered a set of lectures on machine learning in 2008 that were uploaded to Youtube [@Ng_2008]. The lectures effectively begin by talking about the formalisms  of Equation \ref{eq:linear_regression} and Ng spends much time developing them through mathematical derivations, worked examples and references to relevant scientific literature and significant events in the field.  At the time of writing, they have been viewed by more than 0.5 million people. We don't how these people viewed Ng's lectures, nor what they did with them, but the fact that a set of lectures given to post-graduates on predictive modelling attracts so many viewers attests to a contagious interest in  learning to machine learn.  (In later chapters, I return often to these pedagogical materials, and especially to the non-academic or translational accounts of machine learning written by and for software developers or non-machine learning experts. )

While these kinds of formalisms can readily be found in textbooks or on whiteboards and blackboards, and lecture slide presentations, their implementations in software are heavily proliferating in the world. Where they travel is sometimes hard to know. Implementations of machine learning algorithms and techniques have proliferated in software libraries,  many of which are open source. Code operationalises formalisation in ways that textbooks and lectures cannot. Available as software libraries, packages and online web services, and described, discussed and debated in many print and online formats, machine learners are heavily involved in writing and reading code. The entwining of machine learning with the practical specificities of code engenders surprising moments of *circulation.* `kittydar` exemplifies this circulation in which machine learners drift through the archipelagos of software development and coding, landing up in very far-scattered locations (such as a web browser). Similarly, if we turn to contemporary fields of knowledge production, the engineering and scientific literature that either explicitly develops or draws machine learning  in the last two decades mounts up to several hundred thousand publications (see Chapter \ref{ch:diagram} )  and probably several million more publications in scattered scientific fields (including increasingly many humanities and social sciences) indirectly make use of them. This is both forensically useful and a challenge to analyse. 

The techniques circulate more widely, and they *generalize* into quite diverse niches of contemporary life. (I will have much more to say about these processes of generalization at various points, since they affect infrastructures, experience, knowledge, and sense of potential.) As the linear models shown in Equations \ref{eq:linear_model} and \ref{eq:linear_regression_inner_product} circulate in the communicative formalisations of pedagogy and training and in the operational forms of code,  awareness of their diagrammatic play hybridises with operational power [@Lash_2007] \index{Lash, Scott}, so that new forms of agency arise. For instance, if a programmer working on a website incorporates a predictive algorithm to classify users of the website and to vary the what they see on the basis of that classification (and this started to happen widely sometime around 2005; see, for example, *Programming Collective Intelligence* [@Segaran_2007]), \index{Segaran, Toby} what they make in that work is quite different from what might have been done by a web developer in 2000 as they sought to re-design web pages using a database-driven content system. If they make use of a Naive Bayes predictive model to classify whether someone visiting a website is likely to be high income or interested in computer games, and then display different banners or advertisements accordingly, what changes? 

The typical machine learning classifier categorises things. We saw this already with `kittydar,` but it applies much more generally. Many machine learners predict levels, rankings, and values (for instance, prices or risks -- see Chapter \ref{ch:genome}). The operation of classification or prediction usually depends on a set of training data \index{data!training} whose categories are already known or have been assigned by someone (expert or not). These categories are sometimes simply an existing set of classifications derived from institutionalised or accepted practice. Sometimes, whole new sets of categories have been invented for a particular purpose. Across this spectrum of possible classificatory regimes, there is always some way in which machine learners  count, sort, order and classify in ways that *stratify* or cross-section lives. The person who finds themselves paying a different price for a holiday by virtue of some unknown combination of factors including age, credit score, home address, previous travel, or educational qualifications is defined differently by that. In his account of media power, Nick Couldry highlights the importance of categories and categorisation:

>_Category_ is a key mechanism whereby certain types of ordered (often 'ritualized') practice produce power by enacting and embodying categories that serve to mark and divide up the world in certain ways. Without _some_ ordering feature of practice, such as 'categories', it is difficult to connect the multiplicity of practice to the workings of power, whether in the media or in any other sphere. By understanding the work of categories, we get a crucial insight into why the social world, in spite of its massive complexity still appears to us as a _common_ world [@Couldry_2012, 62] \index{Couldry, Nick} \index{categories}, \index{power}

The orderings of practice, effected through categories, undergo a great deal of intensification via machine learning. While Couldry does not in this context discuss data mining, machine learning  or predictive analytics, his analysis of categorisation and its contribution to a massively complex but common social world points directly to the moment of stratification. 

## Massive asymmetries in a common world

If moments of formalisation (especially mathematical and statistical), circulation (pedagogically and operationally), generalization (encompassing many genera and generic forms of practice) and stratification (the socially, epistemically, economically and sometimes politically loaded re-iterative deployment of categories) come together in the making of machine learners, and we can analyse, disentangle and situate these moments in terms of their relative forces, accumulations, points of attachment, locations and projections, then how would we relate to what we see, feel, sense, hear or think in the face of a contemporary webpage such as  Amazon's that uses Association Rule Mining \index{Association Rule Mining|seealso \textit{apriori} algorithm}, an app, a passport control point that matches faces of arriving passengers with images in a database, a computer game, or a genetic test (all settings in which machine learning is likely to be operating)?

A key observation -- and this flows directly from the stratifying moment of machine learning -- is the rather stunning uniformity of what is being done. Not everyone, even amongst expert practitioners, likes how machine learning circulates and generalizes.  Jeff Hammerbacher \index{Hammerbacher, Jeff}, previously chief research scientist at Facebook, co-founder of a successful data analytics company called Cloudera, and currently working also on cancer research at Mount Sinai hospital, complained about where the movement of the techniques  was heading in 2011: 'the best minds of my generation are thinking about how to make people click ads' [@Vance_2011] \index{advertising, online}. While much hinges on what is meant by 'best minds,' Hammerbacher was referring to the incredible growth in the use of predictive analytics techniques anchored in these formalisms in online platforms such as Twitter, Google and Facebook, and on websites more generally, whether they be websites that sell things or websites that sell advertising space. The 'best minds,' however they were ranked, presumably included PhDs from MIT, Stanford or Cambridge whose mathematical skills were wrangling data in the interests of micro-targetted advertising. As Hammerbacher observers, they were 'thinking about how to make people click ads,' and this 'thinking' mainly took and does take the form of building predictive models that tailor the ads shown on websites to individual preferences and desires. In thinking about individual people, and indeed, in seeking to figure an individual amidst very large numbers of people (often numbering millions and sometimes hundreds of millions), the 'best minds' were also constructing and operating with the very  forms of abstraction we see in Equation \ref{eq:linear_regression}.

Hammerbacher's unhappiness with ad click prediction resonates in critical responses to machine learning as used in the digital humanities. (That term itself occasions much debate, which I do not discus here). Some versions of the digital humanities make extensive use of machine learning. \index{digital humanities} In _Macroanalysis: Digital Methods and Literary History_, Matthew Jockers \index{Jockers, Matthew}describes he or  we might relate to one currently popular machine learning or statistical modelling technique, the topic model \index{topic model} (itself the topic of discussion in Chapter \ref{ch:probability}; see also [@Mohr_2013] \index{Mohr, John}):

>   If the statistics are rather too complex to summarize here, I think it is fair to skip the mathematics and focus on the end results. We needn't know how long and hard Joyce sweated over _Ulysses_ to appreciate his genius, and a clear understanding of the LDA machine is not required in order to see the beauty of the result. [@Jockers_2013, 124]

The widely used topic models or Latent Dirichlet Allocation models provide a litmus test of how relations to machine learning is taking shape in the digital humanities. On the one hand, these models promise to make sense of large corpus of documents in terms of underlying themes or 'topics,' and this is a problem of much more general interest (as we will, large document collections have long attracted the interest of machine learners). On the other hand, Jockers signals the difficulties of relating to machine learning when he suggests that 'it is fair to skip the mathematics'  for the sake of 'the beauty of the result'. Recourse to these methods has not always been received enthusiastically. \index{Galloway, Alex|(} In a special issue of the journal _Differences: A Journal of Feminist Cultural Studies_ focusing on digital humanities, Alex Galloway makes two observations about the circulation and generalization of these methods in humanities scholarship: 

>When using quantitative methodologies in the academy (spidering, sampling, surveying, parsing, and processing), one must compete broadly with the sorts of media enterprises at work in the contemporary technology sector. A cultural worker who deploys such methods is little more than a lesser Amazon or a lesser Equifax.110 [@Galloway_2014, 110] 

This is a critical observation: digital humanities machine learners pit themselves against much larger media or business enterprises. The 'quantitative methodologies' that he describes here in terms of spidering and so forth are more or less all epitomised in machine learning techniques (for instance, the Association Rule Mining techniques used by Amazon to recommend purchases, or perhaps the decision tree techniques \index{decision tree} used by the credit-rating systems at Equifax). Galloway's argument is that the infrastructural scale of these enterprises along with the sometime very large technical workforces they employ to continually develop new predictive techniques dwarfs any gain in efficacy that might accrue to humanities research in its recourse to such methods.   This is probably right, but somewhat of a truism. Critical scholarship has long occupied a relatively low position in the power gradients associated with print, electronic and digital media.

Even if 'cultural workers' do manage to learn to machine learn, and become adept at re-purposing the techniques in the interests of something other than selling things or generating credit scores, what is to be gained by doing so? Galloway suggests that doing so might actually reinforce power asymmetries and exacerbate the ethical and political challenges we face:

>But beyond the challenge of unequal talent and resources is the question of critical efficacy. Is it appropriate to deploy positivistic techniques against those self-same positivistic techniques? In a former time, such criticism would not have been valid or even necessary. Marx was writing against a system that laid no specific claims to the apparatus of knowledge production itself—even if it was fueled by a persistent and pernicious form of ideological misrecognition. Yet, today the state of affairs is entirely reversed. The new spirit of capitalism is found in brainwork, self-measurement and self-fashioning, perpetual critique and innovation, data creation and extraction. In short, doing capitalist work and doing intellectual work—of any variety, bourgeois or progressive—are more aligned today than they have ever been [@Galloway_2014, 110].

\index{Galloway, Alex|)}

This perhaps is a more serious charge. The 'techniques' of machine learning are positivist (and hence implicitly at odds with critical thought?), and moreover complicit -- 'aligned' -- with capitalist work. Again, there is something that feels right in the naming of the predicament -- intellectual work of the kind associated with  machine learning -- is definitely at the centre of many governmental, media, business and scientific fields of operation. Increasingly, they anchor the operations of these fields. But do we know yet what it is to _deploy_ machine learning, especially if it not, as I have been suggesting the discussion of the four moments of formalisation, circulation, generalization and stratification, anything like a technique but something more like a problematisation \index{problematisation}?

Like Galloway, I'm wary of certain deployments of these techniques, particularly the platform-based deployments. There have been massive deployments already, and these tend to draw on complex meshing of computer science, mathematics, statistics, and a panoply number of scientific disciplines ranging from acoustics to telecommunications or remote sensing with classifiers and predictive models mobilised by media, finance, military and government suggests that something is 'laying claim to the apparatus of knowledge production.' Yet even amidst the trashy ephemerality of targeted online advertising or the more elevated analytics of literary history, fundamental shifts might occur.  Researchers whether at Baidu or in an English department participate in the iterative re-drawing of relations, categories and differences. Could machine learners become engines of difference? The 'best minds of my generation' have been building engines of difference. While Hammerbacher and Galloway are understandably somewhat dismissive of the existential gratifications and critical efficacy of building targeted advertising systems or document classifiers, their 'deployment' is not a finished product. 

## Critical efficacies in a common world

HERE

In what circumstances would any critical efficacy accumulate around machine learning? Not all classification work is done in the name of buying and selling things, or flattening differences into highly capitalised forms of order.  Some of the ways in which people have started to use the techniques in journalism, in the humanities, in social sciences, in art, media, government or civil society overflow the platform-based deployments and the trenchantly positivist uses found in some scientific fields. A fairly explicit awareness of the operation of machine-learning driven processes is taking shape in some quarters. And this awareness couples critical and practical responses. For instance, the campaign to re-elect Barack Obama as U.S. President in 2011-12 relied heavily on micro-targetting of voters in the leadup to the election polls [@Issenberg_2012; @Mackenzie_2016a]. In response to the data analytics-driven election campaign run by the US Democrats in support of the 2012 re-election of President Barack Obama, data journalists at the non-profit news organisation _ProPublica_ reverse engineered the machine learning models that the Obama re-election team used to target individual votes with campaign messages [@Larsen_2012].   They built their own machine learning model - the 'Message Machine' - using emails sent in by readers and supporters to identify the workings of the Obama campaign team's micro-targetting models. While the algorithmic complexity and data infrastructures used in the Message Machine hardly match those at the disposal of the Obama team, it makes uses of natural language processing (NLP) techniques such as measures of document similarity and machine learning models such as decision trees to disaggregate and map the micro-targetting processes. This kind of reverse engineering work can be found in other quarters. In response to the personalised recommendations generated by streaming media service Netflix, journalists at _The Atlantic_ working with Ian Bogost, a media theorist and programmer, reverse engineered the algorithmic production of around 80,000 micro-genres of cinema used by Netflix [@Madrigal_2014].  While Netflix's system to categorise films relies on much manual classification and tagging with meta-data, the inordinate number of categories they use is typical of the classificatory regimes that are developing in machine learning-based settings.  Certainly, high-profile claims for the power of predictive models to pre-emptively forecast events has come into question. The epidemic predictions of the Google Flu system, a predictive model based on the geography of search engine queries, were wrong on several occasions, mainly because people's online search behaviour changed as a result of coverage [@Lazer_2009; @Butler_2013]. In each of these cases -- reverse engineering political campaign machinery, reverse engineering a film recommendation system, and analysing the shortcomings of a radically different form of epidemiological model -- something is also being critiqued (for its opacity, for its apparent pervasive reach, or simply for its failures), but something is also being made. Making these models shares something with the click predictions. They also contribute to the engineering of the emerging topologies of difference. The critical and practical responses to pervasive prediction do not occupy a different world to the machine learning proponents. They largely move in the same terrain in terms of how they think about numbers, data, probability, and prediction. They largely share the same abstractions -- vector spaces, the geometric line or plane, the cost or error functions widely used to optimize models, or statistical measures or  error, accuracy, specificity, etc.  They also undoubtedly share common infrastructures, but these infrastructureschange much more rapidly as new data formats, database architectures, software libraries and programming languages come and go. 

Many discussions of 'Big Data,' -- a term I'm planning  to mostly eschew on the basis that it's currency is limited and its semantics polyvalent -- don't even mention the pivotal role played by machine learning, and this omission makes it much harder to  evaluate the accompanying forms of practical awareness, and the new senses of agency associated with machine learning. Not always politicised or power-sensitive, there is a diffuse but nonetheless collective form of awareness emerging around machine learning techniques. As these techniques have propagated from various specialised setting where they first took shape, as they have been taken up and repurposed  in new settings, and particularly as they have become near popular topics of discussion amongst software developers, information architects and chief technology officers, their capacity to classify, to predict, to cluster or order traits of people, things and events have become the focus of close scrutiny and interest. This interest can be seen in the many training and instructional materials associated with the techniques. 

A more emphatic version of the relation to modelling comes from the Alex 'Sandy' Pentland. In his recent book on social physics, Pentland calls for a dialogue between 'our human intuition and the big data statistics':

> With the arrival of dense, continuous data and modern computation, we can now map out the details of society and build mathematical models of them. But these raw mathematical models are very far beyond most humans' understandings. They have too many variables and the relationships are too complex for the poor human mind. [@Pentland_2014, 188]

This is somewhat alarming in a different way. Rather than saying we need to infer probabilities, Pentland suggests that these models are 'very far beyond most humans' understandings.' The news is not all bad, as Pentland goes on to suggest a dialogue:

> There needs to be a dialogue between our human intuition and the big data statistics, something that is not built into most of our management systems today. ... A new language, one that goes beyond markets and classes and captures how detailed connections between people determine change will help us develop this understanding [@Pentland_2014, 189]




