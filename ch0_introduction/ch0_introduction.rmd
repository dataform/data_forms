
## from proposal

The introduction will begin with several relatively familiar  examples drawn from a variety of fields over the last decade or so -- handwriting recognition, face recognition, autonomous robots [@thrun_stanley_2006], credit card checks, and cancer prognosis. It will highlight these examples as symptoms of the wide-ranging investments in knowledge, control, prediction and decision-making associated with data flows, and at the same time, suggest how these tracking some of the transformations might elicit changes in how humanities and social science researchers understand their own work. 

These examples  will also provide a preliminary overview of the techniques of machine learning discussed in the book -- supervised and unsupervised learning, the differences between classification, regression, and clustering and important notions such as learning and prediction. They will also highlight  constrasts between disciplines such as computer science and statistics that develop machine learning techniques, as well as illustrate the overlaps  between data-mining, pattern recognition, knowledge discovery, artificial intelligence, machine learning etc. Practically, these examples will also implicitly present some fo the methods used in the subsequent chapters, including the role of databases, data structures, code constructs, diagrams, and algorithms  in typical scientific and industry practices of modelling.

These examples will also stage some of  wider questions in the book  about the promise of data. These include the oft-mentioned 'end of theory' prediction (Chris Anderson, _Wired_ magazine, 2008), and the many claims and controversies about data analytics, machine learning and the 'power of big data' in physical, life and social sciences, in business, government and industry.  Claims  about  power of data, and responses to these claims  -- ranging from downright skepticism to enthusiastic embrace --  will be discussed here with an eye on what these debates about data  mean for research practices in the social sciences and humanities themselves in terms of their topics of research and how they do research.

Finally, the introduction will sketch the themes of 'in the data' and  'modes of machine thought,' drawing on a range of work drawn from pragmatist philosophers such as C.S. Peirce (abduction and diagrams), William James on experience [@james_essays_1996],  John Dewey on 'reconstruction' [@dewey_reconstruction_1957], Alfred N. Whitehead on 'abstraction' [@whitehead_modes_1958] and from recent social and cultural theory  such as Isabelle Stengers on experiment [@stengers_experimenting_2008]; Gilles Deleuze & Felix Guattari on scientific functions, and [@deleuze_what_1994]; Celia Lury on topology [@lury_introduction_2012]). In order to contextualise forms of data thought, the introduction will also sketch some points of departure drawn from software studies work on algorithms and databases, science studies work on calculation, statistics, number, device, image and diagram,  as well as accounts of subjectivity, experience [@berlant, 2007] or [@murphie, 2010] and materiality cross-cutting all of the above. This spectrum of work from across disciplines provide  scaffolding and departure points for much of the book. 


## overview

- the topology of difference - how that is made through ads; how resistance affirms the same
- humanities and social science responses -
    - Arendt on the externalisation of human mental structures; 
    - Bourdieu on the habitus needed; 
    - Marx: Virno on grammar:, etc
- action-promise-prediction vs making/labour/work
    - collective life as cooperative potentials, as relational nexus, becomes the focus of work; 
- how to inhabit these modes of abstraction differently -- the curious assymmetry of the massive aggregates coming into being and the hyper-subindividual focus of prediction ('specious precision')
    - 'into': different senses of that - to go into, to put into, a transition, going in, an interiority
    - the triple dimensional space -- vector-space/function-finding/probability-prediction
    - reparative reading? 
    - regime of numericality -- from calculation to what plurality

## to do
- bring in materials from warwick talk
- say why I am focusing on machine learning and not data more generally -- databases, infrastructures, visualization, etc. - i.e. it is essential but opaque; it is the most slow-moving and tectonic aspect of what is happening with data; it has high levels of abstraction and generates many different potentials; it is a challenge for any re-thinking of what social sciences and critical humanities will do with data.
- recursiveness of this text
- the role of industry -- machine learning as industrial
- the difference between ML and IR, data-mining, - use IR book, use mining massive datasets; use db books to show this
- make the distinction between supervised and unsupervised, classifiers and predictions
- the literature on digital sociology; methods
- the form of writing; finding oneself experimenting with code and data
- trying to find experiments and experiences
-  the ml literature -- how the terms takes shape -- use ipython notebooks for that. machine learning as very loose assemblage; how it coalesces; etc. 
-  I can't cover all the algorithms, techniques, settings
-  FICO, DunneRaby -- huge amounts happening in these commercial spaces that I haven't investigate. Could be done through patent literature .... 
-  the development of machine learning out of AI -- shift from rule-based experts (cd Suchman; Collins  on this); visible in early textbooks (Tom Mitchell); decisive role of pattern recognition approaches focused on images (Bishop 1996 on this); Donald Michie for even earlier
-  the identificatino of ML and data-mining and predictive analytics
-  provenance of _iris_ dataset - -Fisher (1936) and Gaspe Peninsula, W.E. Anderson
- order of things -- big picture stuff on transdisciplinary episteme
- section on the digital humanities debate -- use Liu, and articles from _Differences_ 2014 to do this; + Hall; key points here in notes on Galloway's article. Contrast this with the attempts to conceptualise new forms of number and value in Latour, in Tarde, in STS, in Deleuze, etc.  -- I have PDFs of all these
- Arendt on statistics and praxis (nothing can happen the more predictive we become) vs Virno on the introjection of communicative praxis into poiesis and production vs ... SEE Notes files on both of these

## quotes to use
it follows that if one's object is an anthropological account of a problematization, then one's informants will differ from each other. The challenge lies in finding an experiential and experimental site that would provide a contemporary instance. 87 Rabinow

What I am attempting to do is to reflect on how it might be possible to transfigure elements of the equipment of modern method into a  form of modern meditation, and to bring the benefits and effects of that transformation to bear on enquiry. Rabinow 12 -  used this already in ch2 intro
source code
source code itself often offers inroads in alien phenomenology -- particular when carpentered to reveal the internal experience of withdrawn units, Bogost

the challenge, which I deem a materialist challenge, is that whatever the mess and perplexity that may result, we should resist the temptation to pick and choose among practices Stengers, wondering, 2011, 379

"The sheer density of the collisions of classification schemes in our lives calls for a new kind of science, a new set of metaphors, linking traditional social science and computer and information science. We need a topography of things such as the distribution of ambiguity.  ...  It will also use the best of object-oriented programming and other areas of computer science to describe this territory" [@bowker_sorting_1999, 31].



Quotes from Lanier



## examples to use
- [@le_building_2011] -- paper on the cat videos 
- google mines the knowledge graph
- the facebook paper
- the breast cancer paper
-  https://github.com/harthur/kittydar 'Kittydar is short for kitty radar. Kittydar takes an image (canvas) and tells you the locations of all the cats in the image'
- DARPA challenges



## Quotes from technical sources


## Introduction - a decisive change in the place of prediction

>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ 2.  [@Mitchell_1997, 2]

>In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling [@Breiman_2001a,200]

A relatively new set of scientific-engineering techniques of abstraction  have taken shape in the last three decades. The field of these techniques is known by various names -- machine learning, pattern recognition, knowledge discovery, data mining -- and they are scattered across scientific disciplines, business and commercial applications, industry, engineering and government. Heavily dependent on calculation, they are found in breast cancer research, in autonomous vehicles, in insurance risk modelling, in credit transaction processing, in computer gaming, in face and handwriting recognition systems, in astronomy, ornithology, finance and surveillance. Sometimes these techniques are understood as _scientific models_, and sometimes they are understood as _operational algorithms_. In very many scientific fields, publications mention or describe these techniques as part of their analysis of some experimental or observational data (as in the logistic regression classification models found in a huge number of biomedical papers). They often become quasi-automatic devices, lying somewhere quite deeply embedded in other systems or device (as in the decision tree models used in some computer game consoles or the neural networks used to recognise gestures on a touch screen). In many operational settings, they operate behind the scenes as part of the everyday functioning of devices and services ranging from player ranking in online games to boroder control face recognition, from  credit scores to advanced full limb prosthetics.  The flexibility or plasticity of these techniques, their proliferation and propagation in the world, and the epistemic-operational value accruing to them by virtue of their capacity to 'learn from experience' are the concerns of this book. What kind of equivalence allows these techniques to work in so many different places?

The names of these techniques can be found in many textbooks, instructional courses, website tutorials and descriptions: linear regression, logistic regression, neural networks, linear discriminant analysis, support vector machines, k-means clustering, decision trees, random forests, principal component analysis, or naive Bayes classifier. These names refer to predictive models and to computational algorithms of various ilk. They are shadowed by a wider panoply of modelling and data preparation techniques -- normalization, regularization, cross-validation, feature engineering, feature selection -- that augment their use in practice. The techniques, algorithms and models have arisen in the course of a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Sometimes formidable mathematical constructs drawn from linear algebra, vector spaces, differential calculus and probability theory run through them. But these formidable abstractions encounter today a novel situation in their direct applications to domains that lie far afield of the laboratory or engineering settings in which they first took shape (in many cases, more than a century ago).

Something important is changing here as predictive modelling shifts from a mathematical or engineering specialism to an everyday device that can be blackboxed, reverse engineered, disseminated, or taught . I am focusing on these machine learning techniques and not data practices or algorithms more generally -- databases, infrastructures, visualization, etc. - for several reasons. In various debates and discussions of changes in business, media, government or science, quasi-omnipotent agency has been imputed to algorithms, often with very little discussion of their specific modes of existence. In my view, these techniques are powerful, or at least, can bear down heavily on people's lives and conduct. This power does not however inhere in the algorithms themselves. We need to understand how things have been arranged so that so much runs through the algorithms in order to understand their apparent power, and their power to multiply and propagate themselves in the world. We need to analyse how these techniques are situated in relation to infrastructures, institutions and everyday lives. At the same time, it is important to recognise that these techniques are bringing something new into the world. They profoundly the reorganise numbers, calculation, classification and prediction in ways that might have some precedent, but are nevertheless quite hard to grasp. Without  a way to make sense of these decisive changes in the nature of number, chance, classification and event, we cannot fully make sense of how worlds take shape. A new topology of difference is forming.  


## Growing saturation by abstractions

Jeff Hammerbacher, erstwhile chief research scientist at Facebook, co-founder of a successful data analytics company called Cloudera, and currently working also on cancer research at Mount Sinai hospital, quipped in 2011, 'the best minds of my generation are thinking about how to make people click ads' [@Vance_2011]. He was referring to the incredible growth in the use of predictive analytics techniques in online platforms such as Twitter, Google and Facebook. The 'best minds,' however they were ranked, presumably included PhDs from MIT, Stanford or Cambridge whose mathematical skills were wrangling data in the interests of micro-targetted advertising. As Hammerbacher observers, they were 'thinking about how to make people click ads,' and this 'thinking' mainly took and does take the form of building predictive models that tailor the ads shown on websites to individual preferences and desires. In thinking about individual people, and indeed, in often seeking to figure an individual amidst very large numbers of people (often numbering millions and sometimes hundreds of millions), the 'best minds' were also constructing and operating with new forms of abstraction. Implicitly, these abstractions embodied forms of collective life, but not necessarily sorted or classified according to the categories and stratifications that have organised political, social and economic in the 20th century. Even amidst the trashy ephemerality of targetted online advertising, fundamental shifts can be occurring.  To lesser or greater extents, these researchers participate in the construction of  models of subjectivity, of desire, of belonging, of identity, of inclusion and difference that do not map directly onto existing topologies of difference. Perhaps more importantly,  they are also engines of all these things. The 'best minds of my generation' have been building engines of difference. While Hammerbacher is understandably somewhat dismissive of the value of building targetted advertising systems, there is no doubt that these systems are not only valuable commercial systems, but that the process of putting them to work influences classification and prediction much more widely. Acts of buying and selling things are highly social scenes and very much worth analysing as forms of social practice.  

Hardly politicised or power-sensitive, there is a diffuse but nonetheless collective form of awareness associated with machine learning techniques. As these techniques have propagated from various specialised setting where they first took shape, as they have been taken up and repurposed  in new settings, and particularly as they have become near popular topics of discussion amongst software developers, information architects and chief technolog officers, their capacity to classify, to predict, to cluster or order traits of people, things and events have become the focus of close scrutiny and interest. This interest can be seen in the many training and instructional materials associated with the techniques. An erstwhile professor of computer science Andrew Ng delivered a set of lectures on machine learning in 2008 that were uploaded to Youtube [@Ng_2008], which at the time of writing have been viewed by more than 0.5 million people. We don't how they viewed Ng's technical presentations, nor what they did with them, but the fact that a set of lectures given to post-graduates on predictive modelling attracts so many viewers certainly attests to a contagious interest in these techniques. Implementations of machine learning algorithms and techniques have proliferated in software libraries. Available as software libraries, packages and online webservices, the techniques can float through the archipelagas of software development and coding, landing up in very far-scattered locations. Whether or not they move far, and what difference they make where they end up is not always easy to establish. The engineering and scientific literature on these techniques in the last two decades alone mounts up to several hundred thousand publications explicitly dealing with the techniques, and probably several million more in scattered scientific fields indirectly make use of them. As the techniques circulate more widely, and become settle in quite diverse niches of contemporary life, forms of awareness of the techniques hybridise with the techniques, so that new forms of agency arise. The ways in which people use the techniques in journalism, in the humanities, in social sciences, in art, media, government or civil society overflows the scientific literature and these overflows are not easily seen. Many discussions of 'Big Data,' -- a term I'd like to mostly ignore -- don't even mention the pivotal role played by machine learning and suchlike techniques, and this omission makes it much harder to  the accompanying forms of practical awareness, and the new senses of agency that goes alongside that awareness. For instance, if a programmer working on a website incorporates a predictive algorithm to classify users of the website and to vary the what they see on the basis of that classification [@Segaran_2007], what they make in that work is quite different from what might have been done by a web developer in 2000. Say they make use of a Naive Bayes predictive model to classify whether someone visiting a website is likely to be high income or interested in computer games, and then display different banners or advertisements accordingly. The typical machine learning classifier depends on a set of training data whose categories have already been assigned by someone. These categories are sometimes simply an existing set of classifications derived from institutionalised or accepted practice. Sometimes, whole new sets of categories have been invented for a particular purpose. Occasionally, the classifications are 'purely' algorithmic and rely on no direct human intervention (as for instance in many face recognition systems that simply suggest whether a particular has been seen before). Across this spectrum of possible classificatory regimes, there is always some way in which these algorithmics are counting, sorting, ordering and classifying in ways that cut across or cross-section lives. The person who finds themselves paying a different price for a holiday by virtue of some unknown combination of factors including age, credit score, home address, previous travel, or educational qualifications is defined differently by that.  

A much more explicit awareness of the operation of machine-learning driven processes is taking shape in some quarters. And this awareness couples critical and practical responses. For instance, the campaign to re-elect Barack Obama as U.S. President in 2011-12 relied heavily on micro-targetting of voters in the leadup to the election polls [@Issenberg_2012]. In reponse to the data analytics-driven election campaign run by the US Democrats in support of the 2012 re-election of President Barack Obama, data journalists at the non-profit news organisation _ProPublica_ reverse engineered the machine learning models that the Obama re-election team used to target individual votes with campaign messages [@Larsen_2012].   They built their own machine learning model - the 'Message Machine' - using emails sent in by readers and supporters to identify the workings of the Obama campaign team's micro-targetting models. While the algorithmic complexity and data infrastructures used in the Message Machine hardly match those at the disposal of the Obama team, it makes uses of natural language processing (NLP) techniques such as measures of document similarity and machine learning models such as decision trees to disaggregate and map the micro-targetting processes. This kind of reverse engineering work can be found in other quarters. In response to the personalised recommendations generated by streaming media service Netflix, journalists at _The Atlantic_ working with Ian Bogost, a media theorist and programmer, reverse engineered the algorithmic production of around 80,000 micro-genres of cinema used by Netflix [@Madrigal_2014].  While Netflix's system to categorise films relies on much manual classification and tagging with meta-data, the inordinate number of categories they use is typical of the classificatory regimes that are developing in machine learning-based settings.  Certainly, high-profile claims for the power of predictive models to pre-emptively forecast events has come into question. The epidemic predictions of the Google Flu system, a predictive model based on the geography of search engine queries, were wrong on several occasions, mainly because people's online search behaviour changed as a result of coverage [@Lazer_2009; @Butler_2013]. In each of these cases -- reverse engineering political campaign machinery, reverse engineering a film recommendation system, and analysing the shortcomings of a radically different form of epidemiological model -- something is also being critiqued (for its opacity, for its apparent pervasive reach, or simply for its failures), but something is also being made. Making these models shares something with the click predictions. They also contribute to the engineering of the emerging topologies of difference. The critical and practical responses to pervasive prediction do not occupy a different world to the machine learning proponents. They largely move in the same terrain in terms of how they think about numbers, data, probability, and prediction. They largely share the same abstractions -- vector spaces, the geometric line or plane, the cost or error functions widely used to optimize models, or statistical measures or  error, accuracy, specificity, etc.  They also undoubtedly share common infrastructures, but these infrastructureschange much more rapidly as new data formats, database architectures, software libraries and programming languages come and go. 

It is still very difficult, however, to move between a general awareness of the algorithmic saturation of science, business, commerce, government and media and the specificities of different settings in which they might operate. It is hard, moreover, to disentangle what belongs to the algorithms from what belongs to the domain in which they operate. The real problem here is that machine learning techniques, like many other algorithmic constructs, are often quite generic and can be mobilised in very different settings without essentially changing. The potency of algorithmic practice attests less to some algorithmic essence and more to the mobility afforded by their generic character. I see the problem of understanding the power of algorithms or models such as neural networks as primarily a matter of delineating how this generic character has taken shape.  What we lack is some way of moving between the abstract and generic character of the algorithms themselves and their mundane and farflung concrete implementations and applications. Without that, it remains difficult to get a sense of what is stake in their adoption or implementation in various settings. 

## The historical and social lives of abstractions

$$Y\hat = \Beta^T\boldX$$

Several different forms of reappraisal might be possible here. The conventional one, at least for social science and humanities, is to locate the sources of their potency, currency, and particularly their apparent transcendence or universality in processes of abstraction epitomised by the functin written above. This function, one of the mainstay formalisms of machine learning, and to be found in myriad variations, epitomises in formal terms all the problems and potentials we are going to encounter. Understandings of the sources of the problems and potentials vary according to different philosophical starting points. For twentieth century European philosophers such as Martin Heidegger or Hannah Arendt, decisive transformations in the underpinnings of Western thought occurred in the Scientific Revolution. The advent of algebra and experiment together generated shifts in ontology that profoundly configure modern science and technology. While it might seem a little historically remote to be discussing early modern science in the context of machine learning, solid continuities connect them. More detailed discussion of them has to wait until later chapters, but they include differential calculus (for instance, as used in important optimisation techniques such gradient descent), the probability distribution functions (such as the Gaussian, the Poisson, the Dirichelet, and the Bernoulli distributions), the Lagrangian drawn from classical mechanics formulation of optimization problems, etc. The mathematical techniques of machine learning are not necessarily highly advanced mathematics, but well established mathematical techniques are more intensively deployed there. 

What is happening via these mathematical modes of thought? In standard critical accounts of the development of modern science, these developments are not usually framed as purely intellectual or abstract developments.  It is certainly not a purely intellectual or abstract development, since it does something practical in the world. This is often understood in terms of experiment. For instance, in _The Human Condition_, Hannah Arendt wrote:

> What is decisive is the entirely un-Platonic subjection of geometry to algebraic treatment, which discloses the modern idea of reducing terrestrial sense data and movements to mathematical symbols. Without this non-spatial symbolic language Newton would not have been able to unite astronomy and physics into a single science, or to put it another way, to formulate a law of gravitation where the same equation will cover the movements of heavenly bodies in the sky and motion of terrestrial bodies on earth. Even then it was clear that modern mathematics, in an already breathtaking development, had discovered the amazing human faculty to grasp in symbols those dimensions and concepts which at most had been thought of as negations and limitations of the mind, because their immensity seemed to transcend the minds of mere mortals, ... Yet even more significant than this possibility -- to reckon with entities which could not be "seen" by the eye of mind -- was the fact that the new mental instrument, in this respect even newer and more significant than all the scientific tools it helped to devise, opened the way for altogether novel mode of meeting and approaching nature in experiment [@Arendt_1998, 265]

Here Arendt frames most of modern science and technology as a combination of algebra and experimental practice engaging with the world ('terrestrial sense data and movement') through technical operations on a 'non-spatial symbolic language.' Similar formulations can be found in Edmund Husserl, Martin Heidegger, Maurice Merleau-Ponty, and with certain key modifications in Max Weber or Theodore Adorno. Much social, cultural and political thought shares this treatment of the Scientific Revolution even if they are not explicitly engaged with problems of science and technology. While not startlingly novel, many of Arendt's descriptions of how geometry was re-constituted algebraically, and how algebraic manipulations opened new ground for experimental encounters with natural phenomena, strongly resonate with machine learning techniques. In those techniques too, as we will, constant conversions between geometric, algebraic and statistical or experimental processes occur. Arendt's account of the algebraic reformulation of geometry barely mention calculus or statistics or indeed many other important mathematical developments, but the underlying argument that a kind of turning-inside-out of the 'structure of the human mind' occurred in this process also resonates with machine learning. There is an interesting explanation of all this: 

>With the rise of modernity, mathematics does not simply enlarge its content or reach out into the infinite to become applicable to the immensity of an infinite and infinitely growing, expanding universe, but ceases to be concerned with appearances at all. ... it becomes instead the science of the structure of the human mind [@Arendt_1998, 266]

Arendt understands the mathematical techniques of modern science as externalisations of something that  already belonged to human mental faculties. She suggests that the ongoing development of increasingly counter-intuitive abstractions characteristic of modern mathematical thought (especially around notions such as infinity and limits) can be understood as a turning inward from the world into the 'structure of the human  mind,' 'eye of mind' or 'mental instrument.' (This slightly odd formulation points to the phenomenology's influences on  Arendt.)  'Mathematics succeeded', she writes, 'in reducing and translating all that man is not into patterns which are identical with human, mental structures' (266). The assumption here, and it remains broadly speaking phenomenological in character, is that mathematical abstractions become powerful by virtue of their distance from the fluxing mobility of perception. They wrench experience away from its proximity and entwining with the world, and replace it with the flattened product of distance: 'under this condition of remoteness, every assemblage of things is transformed into a mere multitude' (267). It would be worth thinking more about this 'mere multitude' since that, I suggest, is the primary terrain on which most machine learning, data mining and pattern recognition operates. [TBA - linkage on the pattern recogntion] But this remote perspective derives, on the other hand,  from an almost introspective fixation on patterns derived from 'human, mental patterns.' Some might say that machine learning and pattern recognitions do precisely that today, but in an even more forceful way. In other words, many of these algorithmic techniques rely on mathematical operations and abstractions that are themselves externalised mental structures. 

Arendt's discussion of the nexus of algebra and experiment, and  its 'reducing all appearances through the force inherent in distance' (267) in _On the Human Condition_ is largely framed by the atom bomb and the forms of science associated with nuclear weapons. Machine learning techniques have strong roots in this world, and some of the Cold War optimisation, modelling and simulation problems that these techniques were meant to address remain forcefully in place today. But this analysis hardly seems to relate to the extraordinary proliferation and propagation of decision trees, random forests, logistic regression models, neural networks and support vector machines in sciences, media, government, security and so forth. Can we understand all of these implementations and adoptions of predictive and pattern-finding practices as driven by the externalisation of human mental structures, with its accompanying distance-mediated forcing of things into 'mere multitudes'? Does externalisation account for saturation?

I'm not suggesting that we ascribe everything in these techniques to the externalisation of human structures. In any case, a crucial problem remains. Machine learning techniques may be somewhat experimental. At times, especially in more research-oriented applications, machine learning practitioners set up experiments. And there is a strong tensions between the often less-experimental claims of the advocates of these techniques in industry, commerce or government, and the more experimental practices of researchers. But in either case, something has been added to the externalisation that mathematical science had already pursued. How is that the several century-long externalisation of human mental structures is currently being re-externalised in technical systems? If 'learning' occurs in machine learning techniques, if machine learning algorithms 'do better' than humans at finding patterns in certain settings (principally those characterised by vast 'mere multitude' data sets), then how can we understand that double or secondary externalisation of mental structures? Is this another level or dimension of externalisation? 

These kinds of almost topological shifts in abstractions and their shifting place in the world are very difficult to address in the almost purely philosophical voice such as Arendt's [^3]. Although Arendt certainly does not attribute any universal or trans-historical status to the development of modern science, she does largely regard this development as a homogeneous, indeed monolithic structuring processes. The externalisation of mental structures is an historical process, and it powerfully reorganises the three fundamental modalities of labouring, making and acting that Arendt sees as defining the human condition. Especially in its promotion of _process_ ahead of things, mathematical abstractions potentially pervade all other activities. Hand in hand with that, _making_, and particularly scientific-technological making, supplants the historically generative processes of acting.  

In the contemporary world, Arendt attributes this capacity to act (as in act historically or to unleash processes that result in unexpected courses of events) to scientists: 

> The capacity for action, as least in the sense of the releasing of processes, is still with us, although it has become the exclusive prerogative of the scientists, who have enlarged the realm of human affaire to the point of extinguishing the time-honored protective dividing line between nature and the human world [@Arendt_1998, 323-324]. 

We need to account for the externalisation of the externalised mental structures in different ways. One way is to become a bit more sociological about who or what does the externalising. Rather than 'humans' in general, we might pay more attention to particular groups of people in order to explore how particular ways of thinking and ways of making things become more or less tenable.

[^3]: Although Arendt pays a great deal of attention to labour, life, making, and politics, it is difficult ot see how she would make sense of something like machine learning except as an ongoing development of the modernity.  She writes about finding patterns in the 'mere multitude' that results from algebraic-geometrical transformations in somewhat dismissive terms:

>Under this condition of remoteness, every assemblage of things is transformed into a mere multitude, and every multitude, no matter how disorder, incoherent, and confused, will fall into certain patterns and configurations possessing the same validity and no more significance than the mathematical curve, which as Leibniz once remarked, can always be found between points thrown at random on a piece of paper [@Arendt_1998,  267]. 


## The social practice of abstraction

How would we think about how particular groups of people in different places do something and are themselves affected by doing something with these techniques? This brings us to a second quite different mode of abstraction: abstraction as economic process. In an important methodological footnote in Volume 1 of _Capital_, Karl Marx suggests that one should always examines machines with an eye on the way the machine has picked up and transformed some hand tool. Machines may contain may hand tools [@Marx_1986, 353]. Amidst the machine learning techniques we will see, many hand implements and instruments can be found. The mathematical formalism of some of them should not confuse the issue too much. These algorithms and mathematical functions at work in these techniques are forms of movement and gesture akin to those done with a hammer or a ruler or a knife. They shape, they align, and they cut. Although the cuts, shapes or aggregates they make have less palpable presence than a brick, a loaf of broad or a shirt, the products of these techniques do have a fabric and texture to them to that bears the marks of the implements and the gestures that made them. It would need further discussion to make that case concretely, but for the moment I'm asking you to accept on faith that the predictions of neural network differ qualitative and quantitatively from those produced by a support vector machine.  It almost goes without saying, although I will have much more to say about this - the work of getting machines to work according to abstractions --  in pages that follow, the production of predictions or descriptions via machine learning techniques does entail much hand work. Here the question that interests me at the moment is how we understand the resort to these machines from the standpoint of economic abstraction. 

The mode of abstraction that Marx and Marxist theory described in some much detail, and with painstaking attention to small details (such as how wear and tear on the spindles of a cotton mills figures in the price of cotton), attempts to understand how value aggregates in the great accumulations of wealth characteristic of contemporary capitalism. The key point for our purposes is that abstraction in a capitalist mode of production entails a constant readjustment of the relative amounts of value that derive from what people do together as they work in various settings to make things that can be sold, and the amount that those people are paid for what they do. As Marx writes, the 'starting point of capitalism is the assumption that all labour is collective' [@Marx_1986, 306][TBA - get the quote], and much of the economic development of capitalism comprise amassing people in close proximity (as in cities) in order to increase their collective power. Industrialisation for instances assembles people in places where their potential for cooperation can be concentrated, channelled and focused on specific ends (such as, for instance, producing things more cheaply in a factory). At the same time, the concrete forms of cooperation or 'social labour' (309) that take shape in these concentrated collectives (workshops, factories, etc) lends itself to many further transformations. It renders visible in one place precisely points of intervention or engagement in the process of production amenable to transformation.   Automation for instance can focus on those forms of movements that are most common: putting things in a line, making a circular hole, or making a straight line (363). The deepest transformation taking place concerns the effects of the superintending, adjusting and tuning of the cooperative power of social labour: 'a productive power immanent to capital appears' writes Marx (313), and this productive power concretises itself in manufacturing processes that are intensely calculative as they realize that cooperation can be systematised and rendered calculable in a multitude of ways (rates of production, efficiency, relative comparison of different divisions of labour, etc.). A series of somewhat recursive processes also can take hold of the system of production as measures and calculations of specific rates, speeds, energies and costs supplant much more diffuse measures of production.  In factories for instance, the power of cooperation blends with machinery to such a degree that the factory often becomes a single vast machine (an assembly line, for instance) comprising many non-living and living parts whose cooperation is in many respects simplified because the intellectual-cognitive component has been re-distributed heavily in the direction of the machines, as well as the engineers and technicians who make and control them. 

Obviously the Cyclopean rivet presses of the Manchester foundries described by Marx lie a long way from the neural networks, logistic regression models and decision trees of contemporary machine learning as deployed for instance by Jeff Hammerbacher working on data analytics at Facebook or Andrew Ng working on image classification at the Google Brain in California. While the scales of movement, the concatenation and ordering of living bodies together with systems of machines differ greatly, direct parallels run between the 19th century factories described by Marx and those we can see taking shape around machine learning. Here too there is a concern with straight lines, with the strength of things, with making things happen at higher speed, and of finding places where what was previously done by hand can be replaced by something done by a machine. Even if the  lines and curves are now drawn through masses of data points rather than through a lump of cast iron, even if the shaping is done using parameters on a decision tree rather than the levers of a lathe, there is something akin to factory industrialisation occurring in machine learning. And if that parallel holds at all, then we might expect to find some other associated changes at work.  

## Machine learning as introjection

The major point of divergence was already signalled by Arendt's description of science and engineer, when she said that scientists and engineers are almost the only people who act. This point has been generalized by recent Marxist theorists such as Paolo Virno. He writes, for instance:

>Contemporary labor has introjected into itself many characteristics which originally marked the experience of politics. Poiesis has taken on numerous aspects of praxis. [@Virno_2004, 50] 

Like Arendt, Virno suggests that something has shifted in contemporary capitalism in which what formerly took place in one arena has been taken -- Virno uses the psychoanlytic term 'introjection' -- into another. This is not necessarily the first such decisive shift. Arendt had already described how in the seventheenth century the previously rather minor sphere of _society_  assumed great importance as a public place in which many previously disparate practices and groups found themselves suddenly side by side. 

>Since the rise of society, since the admission of household and housekeeping activities to the public realm, an irrestible tendency to grow, to devour the older realms of the political and private as well as the more recently established shpere of intimacy , has been one of the outstanding characteristics of the new realm [@Arendt_1998, 45].



Tt bit of vhe focus for the moment is on what happens between people when they work together. There are very different ways of working together. Mostly today, people work together in organisational forms such as corporations or institutions pervaded by corporate forms. The forms of work they do together may involve making things (as in a factory), but more often will mean providing services to other people (teaching them, nursing them, cleaning for them, transporting, feeding them, etc). All of this seems a long way from machine learning, but  Jeff Hammerbacher's complaint about PhD's spending their lives trying to predict who will click on an online ad suggests that production and reproduction through the consumption of goods and services is not so very far from the concerns of machine learning as we might think.  Again, as in Arendt's account, I'm taking a very broad historical perspective on machine learning. For what happens in capitalism, according to Karl Marx in _Capital Volume 1_ is that the co-operative or relational processes that almost spontaneously take shape when people work together become principles for the organisation of a division of labour that allows production systems like factories to appear, and at the same time, makes a place for a constantly steeper gradient of automation to begin to interweave itself within the co-operative relationalities. Marx describes  [@Marx_1986] 'all well-developed forms of capitalist production' as  'forms of cooperation' [@Marx_1986, 372], and the fact that these forms of cooperation can be reorganised, reconfigured and constantly transformed allows the historical process of the development of capitalism. 




>The collective experience, the life of the group, is not, as we usually believe, the sphere within which the salient traits of a singular individual diminish or disappear; on the contrary, it is the terrain of a new and more radical individuation. By participating in a collective, the subject, far from surrendering the most unique individual traits, has the opportunity to individuate, at least in part, the share of pre-individual reality which all individuals carry within themselves. ... Only within the collective, certain not within the isolated subject, can perception, language and productive forces take on the shape of an individuated experience.[@Virno_2004, 79]

Something similar can be found in the very different mode of explanation of the potency of mathematical abstractions in sociological thought. Pierre Bourdieu, for instance, situates mathematical abstractions in the space between embodied skills and knowledges (the habitus of mathematicians) and symbolic systems possessing forms of closure:

>The experience of the transcendence of scientific objects, especially mathematical ones, that essentialist theories invoke is the particular form of _illusio_ which arises in the relationship between agents possessing the habitus socially required by the field and symbolic systems capable of imposing their demands on those who perceive them and operate them, and endowed with an autonomy closely linked to that of the field (which explains why the sense of transcendent necessity rises with the capital of accumulated resources and the qualifications demanded for entry) [@Bourdieu_2000, 113-114].

While experience of transcendence are not heavily emphasised in machine learning, much of Bourdieu's account of transcendence resonates with the ways in which these techniques are learned and practiced. Unlike more mundane techniques and technical configurations, these techniques involve some relatively formidable mathematical abstractions, and these abstractions, as we will discuss below, promise certain kinds of autonomy or quasi-autonomous action (for instance, they 'learn'). At the same time, the habitus -- the embodied skills in judging, perceiving, acting -- necessary to develop and apply these techniques is a matter of much discussion and debate (for instance in the many perseverant pronouncements about the need for people who can analyse the data), depends on people internalising 'symbolic systems' (linear algebra, probability and statistics, etc) that 'demand' the world be approached in some ways and not others (for instance, as a problem whose solutions can be found through processes of optimization). As in Arendt's account of the efficacy of mathematics in the world as an effect of distance, and of putting oneself at such a distance from things that mathematical functions can be seen operating everywhere, Bourdieu's account of mathematical transcendence -- its capacity to operate in many different times and places without changing -- depends on a relation between agents and symbolic systems. 

The problem of moving between the algorithms and their culturally saturated feedback loops matters because of the powerful grip these techniques have on contemporary data practice. While many of the intuitions underlying these techniques are relatively simple (for instance, the idea of drawing a line through a group of points as a way of describing the main tendency in a dataset), there are many differences in how these techniques work. 

>When an object – a geometrical space, for example – is scientifically constructed by functions, its philosophical concept, which is by no means given in the function, must still be discovered [@Deleuze_1994, 117].

In what ways do what computers do with data today change how we think about what we do? This slightly loopy question invites many possible responses. But I'm principally interested here in an increasingly widespread form of computation known variously as machine learning, pattern recognition, knowledge discovery, data mining or predictive analytics. Each of these terms comes from slightly different quarters, and they overlap with each other at many points. In general, however, all of them attest to the growth of a set of techniques concerned with working with data. These techniques are almost the sole focus of this book. The techniques assembled under the name machine learning are hardly new. Some of them date back more than a century, and the bulk of them are decades old. The breadth and scale of their application in recent years is somewhat astonishing. In the last few years, they have quickly become staple techniques in science, business, government, entertainment and media. 

## The existing work

Databases and information infrastructures have been discussed widely in various settings, but often without reference to underlying computational abstractions. Moreover, the techniques of machine learning have received little critical attention, even though they have been pervasively threaded through infrastructures, devices and data practices. This threading  is rather opaque. It is the most slow-moving and tectonic aspect of what is currently happening with data, yet these techniques entail relatively high levels of abstraction. It would be possible to understand many changes in data-driven businesses, infrastructures and science in terms of the potentials implicit to these techniques. For instance, the seemingly obvious trend to collect and analyse more data is not simply a case of more is better. The performance of certain models and algorithms, as measured in terms of error rates, depends on the amount of data they have to work with. Attempts to optimise algorithmic performance, as we will see, generate demand for more data. More generally, the transformations associated with these techniques, I will suggest,  generates many different potentials, and lays down challenges for any re-thinking of what social sciences and critical humanities will do with data.


