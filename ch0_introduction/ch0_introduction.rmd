# Introduction: Into the Data

## from proposal

The introduction will begin with several relatively familiar  examples drawn from a variety of fields over the last decade or so -- handwriting recognition, face recognition, autonomous robots [@thrun_stanley_2006], credit card checks, and cancer prognosis. It will highlight these examples as symptoms of the wide-ranging investments in knowledge, control, prediction and decision-making associated with data flows, and at the same time, suggest how these tracking some of the transformations might elicit changes in how humanities and social science researchers understand their own work. 

These examples  will also provide a preliminary overview of the techniques of machine learning discussed in the book -- supervised and unsupervised learning, the differences between classification, regression, and clustering and important notions such as learning and prediction. They will also highlight  constrasts between disciplines such as computer science and statistics that develop machine learning techniques, as well as illustrate the overlaps  between data-mining, pattern recognition, knowledge discovery, artificial intelligence, machine learning etc. Practically, these examples will also implicitly present some fo the methods used in the subsequent chapters, including the role of databases, data structures, code constructs, diagrams, and algorithms  in typical scientific and industry practices of modelling.

These examples will also stage some of  wider questions in the book  about the promise of data. These include the oft-mentioned 'end of theory' prediction (Chris Anderson, _Wired_ magazine, 2008), and the many claims and controversies about data analytics, machine learning and the 'power of big data' in physical, life and social sciences, in business, government and industry.  Claims  about  power of data, and responses to these claims  -- ranging from downright skepticism to enthusiastic embrace --  will be discussed here with an eye on what these debates about data  mean for research practices in the social sciences and humanities themselves in terms of their topics of research and how they do research.

Finally, the introduction will sketch the themes of 'in the data' and  'modes of machine thought,' drawing on a range of work drawn from pragmatist philosophers such as C.S. Peirce (abduction and diagrams), William James on experience [@james_essays_1996],  John Dewey on 'reconstruction' [@dewey_reconstruction_1957], Alfred N. Whitehead on 'abstraction' [@whitehead_modes_1958] and from recent social and cultural theory  such as Isabelle Stengers on experiment [@stengers_experimenting_2008]; Gilles Deleuze & Felix Guattari on scientific functions, and [@deleuze_what_1994]; Celia Lury on topology [@lury_introduction_2012]). In order to contextualise forms of data thought, the introduction will also sketch some points of departure drawn from software studies work on algorithms and databases, science studies work on calculation, statistics, number, device, image and diagram,  as well as accounts of subjectivity, experience [@berlant, 2007] or [@murphie, 2010] and materiality cross-cutting all of the above. This spectrum of work from across disciplines provide  scaffolding and departure points for much of the book. 


## overview

- 'into': different senses of that - to go into, to put into, a transition, going in, an interiority
- 

## to do
- bring in materials from warwick talk
- say why I am focusing on machine learning and not data more generally -- databases, infrastructures, visualization, etc. - i.e. it is essential but opaque; it is the most slow-moving and tectonic aspect of what is happening with data; it has high levels of abstraction and generates many different potentials; it is a challenge for any re-thinking of what social sciences and critical humanities will do with data.
- recursiveness of this text
- the role of industry -- machine learning as industrial
- the difference between ML and IR, data-mining, - use IR book, use mining massive datasets; use db books to show this
- make the distinction between supervised and unsupervised, classifiers and predictions
- the literature on digital sociology; methods
- the form of writing; finding oneself experimenting with code and data
- trying to find experiments and experiences
-  the ml literature -- how the terms takes shape -- use ipython notebooks for that. machine learning as very loose assemblage; how it coalesces; etc. 
-  I can't cover all the algorithms, techniques, settings
-  FICO, DunneRaby -- huge amounts happening in these commercial spaces that I haven't investigate. Could be done through patent literature .... 
-  the development of machine learning out of AI -- shift from rule-based experts (cd Suchman; Collins  on this); visible in early textbooks (Tom Mitchell); decisive role of pattern recognition approaches focused on images (Bishop 1996 on this); Donald Michie for even earlier
-  the identificatino of ML and data-mining and predictive analytics
-  provenance of _iris_ dataset - -Fisher (1936) and Gaspe Peninsula, W.E. Anderson
- order of things -- big picture stuff on transdisciplinary episteme
- section on the digital humanities debate -- use Liu, and articles from _Differences_ 2014 to do this; + Hall; key points here in notes on Galloway's article. Contrast this with the attempts to conceptualise new forms of number and value in Latour, in Tarde, in STS, in Deleuze, etc.  -- I have PDFs of all these
- Arendt on statistics and praxis (nothing can happen the more predictive we become) vs Virno on the introjection of communicative praxis into poiesis and production vs ... SEE Notes files on both of these

## quotes to use
it follows that if one's object is an anthropological account of a problematization, then one's informants will differ from each other. The challenge lies in finding an experiential and experimental site that would provide a contemporary instance. 87 Rabinow

What I am attempting to do is to reflect on how it might be possible to transfigure elements of the equipment of modern method into a  form of modern meditation, and to bring the benefits and effects of that transformation to bear on enquiry. Rabinow 12 -  used this already in ch2 intro
source code
source code itself often offers inroads in alien phenomenology -- particular when carpentered to reveal the internal experience of withdrawn units, Bogost

the challenge, which I deem a materialist challenge, is that whatever the mess and perplexity that may result, we should resist the temptation to pick and choose among practices Stengers, wondering, 2011, 379

"The sheer density of the collisions of classification schemes in our lives calls for a new kind of science, a new set of metaphors, linking traditional social science and computer and information science. We need a topography of things such as the distribution of ambiguity.  ...  It will also use the best of object-oriented programming and other areas of computer science to describe this territory" [@bowker_sorting_1999, 31].


Quotes from Lanier



# examples to use
- [@le_building_2011] -- paper on the cat videos 
- the facebook paper
- the breast cancer paper


## Quotes from technical sources

_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ 2.  [@Mitchell_1997, 2]

In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling. [@breiman_statistical_2001, 200]

## Introduction
>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ 2.  [@Mitchell_1997, 2]
>When an object – a geometrical space, for example – is scientifically constructed by functions, its philosophical concept, which is by no means given in the function, must still be discovered [@Deleuze_1994, 117].

This book concerns a set of scientific objects

In what ways do what computers do with data today change how we think about what we do? This slightly loopy question invites many possible responses. But I'm principally interested here in an increasingly widespread form of computation known variously as machine learning, pattern recognition, knowledge discovery, data mining or predictive analytics. Each of these terms comes from slightly different quarters, and they overlap with each other at many points. In general, however, all of them attest to the growth of a set of techniques concerned with working with data. These techniques are almost the sole focus of this book. The techniques assembled under the name machine learning are hardly new. Some of them date back more than a century, and the bulk of them are decades old. The breadth and scale of their application in recent years is somewhat astonishing. In the last few years, they have quickly become staple techniques in science, business, government, entertainment and media. 
The names of these techniques can be found in many textbooks, instructional courses, website tutorials and descriptions: linear regression, logistic regression, neural networks, linear discriminant analysis, support vector machines, k-means clustering, decision trees, random forests, principal component analysis, or naive Bayes classifier. These names refer to predictive models and to computational algorithms of various ilk. They are shadowed by a wider panoply of modelling and data preparation techniques -- normalization, regularization, cross-validation, feature engineering, feature selection -- that augment their use in practice. The techniques, algorithms and models have arisen in the course of a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Powerful mathematical abstractions such as linear algebra, vector space, differential calculus and probability theory run through them. But these formidable abstractions encounter today a novel situation in their direct applications to domains that lie far afield of the laboratory or engineering settings in which they first took shape. A cultural saturation of algorithms and a politically loaded awareness of their operation is taking shape in some quarters. What this book seeks to do is to offer some way of moving between the abstract and formal character of the algorithms themselves and their mundane and farflung concrete implementations and applications.
The problem of moving between the algorithms and their culturally saturated feedback loops matters because of the powerful grip these techniques have on contemporary data practice. While many of the intuitions underlying these techniques are relatively simple (for instance, the idea of drawing a line through a group of points as a way of describing the main tendency in a dataset), there are many differences in how these techniques work. 
