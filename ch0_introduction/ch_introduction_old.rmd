# Introduction
\label{ch:introduction}

## from proposal

The introduction will begin with several relatively familiar  examples drawn from a variety of fields over the last decade or so -- handwriting recognition, face recognition, autonomous robots [@Thrun_2006], credit card checks, and cancer prognosis. It will highlight these examples as symptoms of the wide-ranging investments in knowledge, control, prediction and decision-making associated with data flows, and at the same time, suggest how these tracking some of the transformations might elicit changes in how humanities and social science researchers understand their own work. 

These examples  will also provide a preliminary overview of the techniques of machine learning discussed in the book -- supervised and unsupervised learning, the differences between classification, regression, and clustering and important notions such as learning and prediction. They will also highlight  constrasts between disciplines such as computer science and statistics that develop machine learning techniques, as well as illustrate the overlaps  between data-mining, pattern recognition, knowledge discovery, artificial intelligence, machine learning etc. Practically, these examples will also implicitly present some fo the methods used in the subsequent chapters, including the role of databases, data structures, code constructs, diagrams, and algorithms  in typical scientific and industry practices of modelling.

These examples will also stage some of  wider questions in the book  about the promise of data. These include the oft-mentioned 'end of theory' prediction (Chris Anderson, _Wired_ magazine, 2008), and the many claims and controversies about data analytics, machine learning and the 'power of big data' in physical, life and social sciences, in business, government and industry.  Claims  about  power of data, and responses to these claims  -- ranging from downright skepticism to enthusiastic embrace --  will be discussed here with an eye on what these debates about data  mean for research practices in the social sciences and humanities themselves in terms of their topics of research and how they do research.

Finally, the introduction will sketch the themes of 'in the data' and  'modes of machine thought,' drawing on a range of work drawn from pragmatist philosophers such as C.S. Peirce (abduction and diagrams), William James on experience [@James_1996],  John Dewey on 'reconstruction' [@Dewey_1957], Alfred N. Whitehead on 'abstraction' [@Whitehead_1958] and from recent social and cultural theory  such as Isabelle Stengers on experiment [@Stengers_2008]; Gilles Deleuze & Felix Guattari on scientific functions, and [@Deleuze_1994]; Celia Lury on topology [@Lury_2012]). In order to contextualise forms of data thought, the introduction will also sketch some points of departure drawn from software studies work on algorithms and databases, science studies work on calculation, statistics, number, device, image and diagram,  as well as accounts of subjectivity, experience [@Berlant_2007] or [@Murphie_2010] and materiality cross-cutting all of the above. This spectrum of work from across disciplines provide  scaffolding and departure points for much of the book. 


## overview

- the topology of difference - how that is made through ads; how resistance affirms the same
- humanities and social science responses to abstractions -
    - Arendt on the externalisation of human mental structures; 
    - Marx: Virno on grammar:, etc
- action-promise-prediction vs making/labour/work
    - collective life as cooperative potentials, as relational nexus, becomes the focus of work; 
- the problem of critical efficacy
    - Amoore on politics and ethics
    - galloway on relative weakness and entanglement
- how to inhabit these modes of abstraction differently -- the curious assymmetry of the massive aggregates coming into being and the hyper-subindividual focus of prediction ('specious precision')
    - Bourdieu on the habitus needed; 
    - the physico-mathematical equivalence event approach
    - the triple dimensional space -- vector-space/function-finding/probability-prediction
    - regime of numericality -- from calculation to what plurality -- some Badiou and some Parisi here?
- implications for this political

## to do

- what is the main story mean -- is it the point down 2 -- how to get a grip?
- the overlap between signal processing and machine learning  -- including my own work on this -- means that the data itself is not given freely: machine learning  has already gone into the data; and that's why we have so many images for instance in kittydar -- compression, loss compression in particular, 514; Shannon coding theory [@Gersho_1992] on signal compression
- how do we get a grip on these methods that does not leave us lesser amazons? key narrative: book is an attempt to develop a way of making sense of things that are consistently mystified, hyped, etc
- book could be seen as a history of a lineage of computational culture associated with knowledge, and with shifts in knowledge, rather than information, communication, control, etc. 
- into the data: this is a question and a form of movement: what is put into the data, rather than what comes out of it; 
- masculinity? write large -- hegemonic? fixity in face of much change; hard to see past this in the literature
-the problem of focusing on the algorithm - does it reproduce the power hierarchy of computer science
- the restructuring of the table -- to include the Foucault discussion of tables
- make the point about machine learning being somewhat reducible to each other (with enough contortions), and that means it is not necessary to cover everything
- the structure of the book in terms of media, science and government; the structure of the book in terms of life, labour and language
- bring in materials from warwick talk
- add stengers on abstraction from invention of modern science
- see potential as predictable, question the bifurcation between abstract and concrete;
- how is difference being done differently
- use presentations nodes from transforming data workshop
- is it a matter of taking the machine perspectives; 
- say why I am focusing on machine learning and not data more generally -- databases, infrastructures, visualization, etc. - i.e. it is essential but opaque; it is the most slow-moving and tectonic aspect of what is happening with data; it has high levels of abstraction and generates many different potentials; it is a challenge for any re-thinking of what social sciences and critical humanities will do with data.
- the role of industry -- machine learning as industrial and maybe link this to the labour question
- the difference between ML and IR, data-mining, - use IR book, use mining massive datasets; use db books to show this
- make the distinction between supervised and unsupervised, classifiers and predictions
- the literature on digital sociology; methods
- the form of writing; finding oneself experimenting with code and data
- trying to find experiments and experiences
-  the ml literature -- how the terms takes shape -- use ipython notebooks for that. machine learning as very loose assemblage; how it coalesces; etc. 
-  I can't cover all the algorithms, techniques, settings, but this abundance, and description of it is part of the phenomena and the practice;
-  FICO, DunneRaby, Teradata -- huge amounts happening in these commercial spaces that I haven't investigate. Could be done through patent literature .... 
-  the development of machine learning out of AI -- shift from rule-based experts (cd Suchman; Collins  on this); visible in early textbooks (Tom Mitchell); decisive role of pattern recognition approaches focused on images (Bishop 1996 on this); Donald Michie for even earlier
-  the identificatino of ML and data-mining and predictive analytics
-  provenance of _iris_ dataset - -Fisher (1936) and Gaspe Peninsula, W.E. Anderson
- order of things -- big picture stuff on transdisciplinary episteme
- section on the digital humanities debate -- use Liu, and articles from _Differences_ 2014 to do this; + Hall; key points here in notes on Galloway's article. Contrast this with the attempts to conceptualise new forms of number and value in Latour, in Tarde, in STS, in Deleuze, etc.  -- I have PDFs of all these
- Arendt on statistics and praxis (nothing can happen the more predictive we become) vs Virno on the introjection of communicative praxis into poiesis and production vs ... SEE Notes files on both of these
- really important to see that these abstractions move through the data, pulling features and relations from aggregates in order to create probabilistic or decisionistic classifications and projects. The experience of personalization that has become so mundane is largely predictive and a product of an abstraction, and not the reflection of any individual tracking as such. 
- add Totaro, Gillespie and Neyland, and Italian people: on algorithms
- add Whitehead on abstraction: 
    A second  and related emphasis comes from the work of the early twentieth century Alfred North Whitehead. Despite his fame as co-author with Bertrand Russell of _Principia Mathematica_, a tome whose Latinate title attests to its weighty ambitions,  Whitehead's later work in books such as _The Concept of Nature_ [@Whitehead_2013], _Science and the Modern World_ [@Whitehead_1970] and _Modes of Thought_ [@Whitehead_1956] on how scientific and mathematical abstractions are embodied is highly relevant to thinking about machine learning [^5]. Whitehead is comprehensively critical of certain tendencies in modern science (the pervasive 'fallacy of misplaced concreteness' that treats abstractions as pre-given foundations; the reduction of space-time to discrete  exterior locations, etc), but he is very enthusiastic about the potential for better abstractions. While his affirmative account of enhanced abstractions is voiced in terminology that takes some getting used to, the broad point can be grasped. Here he writes about better abstractions as energy enhancing:

    > But this enhancement of energy presupposes that the abstraction is preserved with its adequate relevance to the concrete sense of value-attainment from which it is derived. In this way, the effect of the abstraction stimulates the vividness and depth of the whole of experience. [@Whitehead_1956,169]

    The enhancement of energy Whitehead talks about here is concerned with the 'fortunate use of abstractions' (169). Machine learning and  much work with data today can be seen as a form of abstraction (as can much of science). The crucial question for Whitehead, however, is how to abstract well. Like Mol, he advocates keeping abstractions together ('preserved with its adequate relevance') with something like practice (' to the concrete sense of value-attainment from which it is derived'). Like Mol too, the virtue of this bundling together of abstractions with their concrete sense affects the 'whole of the experience.' Abstractions can make experience more vivid or deep if they are aligned and assembled connectively. Here I pin some methodological hope on Whitehead's work as a way to experiment with abstraction as stimulant and enrichment, not as reduction or pale imitation. 


## quotes to use

source code
source code itself often offers inroads in alien phenomenology -- particular when carpentered to reveal the internal experience of withdrawn units, Bogost

the challenge, which I deem a materialist challenge, is that whatever the mess and perplexity that may result, we should resist the temptation to pick and choose among practices Stengers, wondering, 2011, 379

"The sheer density of the collisions of classification schemes in our lives calls for a new kind of science, a new set of metaphors, linking traditional social science and computer and information science. We need a topography of things such as the distribution of ambiguity.  ...  It will also use the best of object-oriented programming and other areas of computer science to describe this territory" [@Bowker_1999, 31].



It is also what is ethical about political life – that it is difficult, to decide is difficult, and that whether mathematician "deciding the best set of rules", software analyst "refining the algorithm", or border guard "engaging action", a decision that is not simply the reading off of risk flag or protocol can only proceed without recourse to what is projected in the flags, maps and scores of the data derivative. [@Amoore_2011]



## examples to use
- google mines the knowledge graph
- google mines the cats on youtube -- norvig presentation at Singularity -- see video in my sbd folder
- hilary mason talking about realtime search -- see video in my sbd folder
- the facebook paper
- DARPA challenges
- supply chain logistics -- MIT + au la la -- online retail; maceys presentation


## Introduction - a decisive change in the place of prediction

>_Definition_: A computer program is said to **learn** from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, improves with experience $E$ 2.  [@Mitchell_1997, 2]

>In the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new community—often called machine learning—that is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling [@Breiman_2001a,200].

>The key question isn't 'How much will be automated?' It's how we'll conceive of whatever _can't_ be automated at a given time. [@Lanier_2013, 77]

A relatively new field of scientific-engineering devices  have become much more visible in the last three decades. The field is known by various names -- machine learning, pattern recognition, knowledge discovery, data mining -- and the devices are scattered across scientific disciplines, business and commercial applications, industry, engineering and government. Heavily dependent on calculation, they are found in breast cancer research, in autonomous vehicles, in insurance risk modelling, in credit transaction processing, in computer gaming, in face and handwriting recognition systems, in astronomy, ornithology, finance and surveillance. Sometimes these techniques are understood as _scientific models_, and sometimes they are understood as _operational algorithms_ or machines. In very many scientific fields, publications mention or describe these techniques as part of their analysis of some experimental or observational data (as in the logistic regression classification models found in a huge number of biomedical papers). They often become quasi-automatic mechanisms, lying somewhere quite deeply embedded in other systems or device (as in the decision tree models used in some computer game consoles or the neural networks used to recognise gestures on a touch screen). In many operational settings, they operate behind the scenes as part of the everyday functioning of devices and services ranging from player ranking in online games to border control face recognition, from  credit scores to advanced full limb prosthetics.  The flexibility or plasticity of these machine learners, their proliferation and propagation in the world, and the epistemic-operational value accruing to them by virtue of their capacity to 'learn from experience' are the concerns of this book. What kind of equivalence allows these techniques to work in so many different places?

```{r cat, engine='python', fig.show='hide', cache=TRUE, echo=FALSE, message=FALSE}

import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import color, exposure
import skimage
im = skimage.io.imread('gray-tabby-cat-with-green-eyes-close-up.jpg')
image = color.rgb2gray(im)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))
ax1.axis('off')
ax1.imshow(image, cmap=plt.cm.gray)
ax1.set_title('Input image')
fd, hog_image = hog(image, orientations=8, pixels_per_cell=(52, 52),
                    cells_per_block=(1, 1), visualise=True)
# Rescale histogram for better display
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))
ax2.axis('off')
ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)
ax2.set_title('Histogram of Oriented Gradients')
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),
                    #cells_per_block=(1, 1), visualise=True)
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(32, 32),
                    #cells_per_block=(1, 1), visualise=True)
#fd, hog_image = hog(image, orientations=8, pixels_per_cell=(62, 62),
                    #cells_per_block=(1, 1), visualise=True)
plt.savefig('cat_hog.pdf')


```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/cat_hog.pdf}
        \caption{Close up of cat. The image on the left is already signal processed as JPEG format file. The image on the right is further signal processed using histogram of oriented gradients (HOG) edge detection. \texttt{kittydar} models HOG features.  Photo courtesy photos-public-domain.com}
  \label{fig:cat}
\end{figure}

Take the case of `kittydar,` a small demonstration of machine learning techniques in the area of computer vision (see [kittydar](http://harthur.github.io/kittydar)): 'Kittydar is short for kitty radar. Kittydar takes an image (canvas) and tells you the locations of all the cats in the image' [@Arthur_2012] \index{kittydar}. This playful piece of software demonstrates the deployment of computer vision in the mundane, not to say banal, domain of cat photos on the internet. Heather Arthur, who developed `kittydar` writes:

>Kittydar first chops the image up into many “windows” to test for the presence of a cat head. For each window, kittydar first extracts more tractable data from the image's data. Namely, it computes the Histogram of Orient Gradients descriptor of the image, using the hog-descriptor(http://github.com/harthur/hog-descriptor) library. This data describes the directions of the edges in the image (where the image changes from light to dark and vice versa) and what strength they are. This data is a vector of numbers that is then fed into a neural network(https://github.com/harthur/brain) which gives a number from 0 to 1 on how likely the histogram data represents a cat. The neural network (the JSON of which is located in this repo) has been pre-trained with thousands of photos of cat heads and their histograms, as well as thousands of non-cats. See the repo for the node training scripts [@Arthur_2012].

This toy example of machine learning finds cat heads in digital photographs, but we can easily imagine similar techniques in use in self-driving cars, border security systems,  military robots or wherever there is something to be seen. `Kittydar` runs in Javascript in a web browser, and can only really detect the presence of cats that are facing forward. As the description provided by Arthur suggests, the software finds cats by chopping up the images into smaller windows. For each window, it measures a set of gradients running from  light and dark, and then compares these gradients to the gradients of known cat images (the training set). The intuition here is that edges and sudden shifts from light to dark are associated with the features on a cats in a fairly regular pattern. The work of classification is either given  to a neural network (as discussed in chapter \ref{ch:subject}), a typical machine learning technique and one that has recently been heavily developed by researchers at Google [@Le_2011], themselves working on images of cats among other things taken from Youtube videos [@BBC_2012] \index{neural network}, or to a support vector machine, a technique first developed in the 1990s by researchers working at IBM (see chapter \ref{ch:pattern}). \index{support vector machine} 

The names of these techniques accumulate and have been re-iterated in many textbooks, instructional courses, website tutorials and descriptions: linear regression \index{linear regression}, logistic regression, \index{logistic regression} neural networks \index{neural net}, linear discriminant analysis \index{linear discriminant analysis}, support vector machines, \index{support vector machine} k-means clustering, \index {k-means clustering} decision trees \index{decision trees}, _k_ nearest neighbours, \index{nearest neighbours}  random forests, \index{principal component analysis} principal component analysis, or naive Bayes classifier \index{Naive Bayes} to name just some of the most commonly used. These names refer to predictive models and to computational algorithms of various ilk and provenance. They are shadowed by a dauntingly intricate panoply of modelling and data preparation practices -- normalization, regularization, cross-validation, feature engineering, feature selection -- that suture their use. Those techniques of preparation and evaluation of data themselves rely on a gamut of infrastructural forms ranging from lists and tables of data in files and spreadsheets through to intricately engineered mechanisms for storing and retrieving large amounts of data such as databases, filestores, archives and computational clusters. The techniques, algorithms and models are not necessarily startling new or novel. They take shape against a background of a century of work in mathematics, statistics, computer science as well as various scientific fields ranging from anthropology to zoology. Formidable mathematical constructs drawn from linear algebra, vector spaces, differential calculus, numerical optimization and probability theory heavily stratify practice in the field. 

I am focusing on these machine learners -- a term that refers to both humans and machines throughout this book --  and not data practices or algorithms in general, or databases, infrastructures, or data visualization, etc. This focus is a calculated risk. On the one hand, any single minded focus on machine learning or particular machine learners such as neural nets or linear discriminant analysis risks hypostasising, fetishizing or essentializing machine learners as machines or algorithms. To attribute primacy to the algorithm or the predictive model would be to uncritically reproduce many contemporary performances and representations that privilege machines and marginalize their human others. On the other hand, to steer away from the devices and machines in favour of analysis of their social uses and economically, socially, and political charged contexts would be to downplay their technicity [@Mackenzie_2002a], their relational potentials, eventfulness and materialities. I am to follow a narrow ridge that both traverses both the novel human-machine relations that have been taking shape in machine learning in its knowledge-making operations and offers a view of the forms of control, decision, power and discrimination configured by machine learners. Regardless of the spectacle associated with predictive models (and announcements of this predictive or classificatory power have been frequent in recent years),  they do today circulate into domains that lie far afield of the laboratories, experimental or engineering settings in which they first took shape (in some cases, more than a century ago; in others, in the last two decades). If they are not exactly new and have diverse genealogies, the question is: does something important happen  as machine learners  shift from being mathematical or engineering specialisms to an everyday device that can be generalized to locate cats in digit images, the Higgs boson in particle physics or credit fraud detection, or blackboxed, reverse engineered, disseminated, and taught to see cats? Does the somewhat unruly generalization of machine learning across different epistemic, economic, institutional geographies attest to a re-definition of knowledge, decision and control, or a new operational field, as the philosopher Michel Foucault terms, for knowledge [@Foucault_1972, 106]? 

## All power to the algorithms?

In various debates and discussions of changes in business, media, education, health, government or science, quasi-omnipotent agency has been imputed to algorithms, often with very little discussion of their specific modes of existence. These techniques are powerful, or at least, can bear down heavily on people's lives and conduct. This power does not however inhere in the algorithms themselves, or in any general features (such as recursivity). We need to understand how things have been arranged so that so much runs through the algorithms in order to understand their apparent power, and their power to multiply and propagate themselves in the world. In the context of her study of border control systems, Louise Amoore writes:

> Surely this must be a primary task for critical enquiry – to uncover and probe the moments that come together in the making of a calculation that will automate all future decisions. To be clear, I am not proposing some form of humanist project of proper ethical judgement, but rather calling for attention to be paid to the specific temporalities and norms of algorithmic techniques that rule out, render invisible, other potential futures [@Amoore_2011]. \index{Amoore, Lousie}

We need to analyse how these techniques are situated in relation to infrastructures, institutions and everyday lives. The algorithms and techniques of machine learning, it is important to point out, are actually far more stable than the maelstrom of platforms, devices, skills, claims and advocates around them. They do change but more slowly than what flows around them. At the same time, we surely must recognise that these techniques bring something new into the worlds they move through. They profoundly reorganise numbers, calculation, classification and prediction in ways that might have some precedent, but are nevertheless quite hard to grasp. Without  a way to make sense of these decisive changes in the nature of number, chance, classification and event, we cannot fully make sense of how worlds take shape. A new topology of difference is forming with the capacity to foster some forms of life and not others. As Amoore writes, some potential futures are being 'ruled out' as these devices are put to work. Anna Munster puts the challenge more starkly:'prediction takes down potential' [@Munster_2013]. \index{Munster, Anna}

## Growing saturation by abstractions

\begin {equation}
\label{eq:linear_regression}
\hat{Y} = \beta_0 + \sum_{j=1}^{p}X_j\hat{\beta}_j
\end {equation}

\begin {equation}
\label{eq:linear_regression_inner_product}
\hat{Y} = X^T\hat{\beta}
\end {equation}

They are a rather harsher introduction than the kittens, but these two equations \ref{eq:linear_regression} and \ref{eq:linear_regression_inner_product}, which more or less express the same thing,  are anchor points of the abstractions at the core of `kittydar.` Every character of these equations, as well as a set of conventions that more or less indirectly govern how the different characters and symbols relate to each other and how they track out into the world, bear the trace of the burgeoning practices of abstraction I'm describing. I will describe in more detail below how several different practices of abstraction intersect in these formal expressions. I don't expect that these abstractions are immediately understandable to everyone, and for readers who are not familiar with the techniques I am describing, it may be difficult to even look at these mathematical formalisms for very long without thinking that they have something better to do. In the interests of the different abstractions that run through it, I propose to look at these expressions quite closely, with an eye for how each of the letters and symbols stands in for processes. Importantly, to preempt discussion that will be the subject of later chapters, both the neural networks and support vector machines to be found in `kittydar` derive from combinations and accumulations of these anchoring formalisms.[^11]

[^11]: The machine learning researchers Trevor Hastie, Tibshirani and Jerome Friedman, whom I will often cite in the pages that follow, describe neural networks, for instance in this way:  
    >Projection pursuit and neural network models consist of sums of non-linearly transformed linear models [@Hastie_2009, 18].
    The linear models and their non-linear transforms are hence worth focusing on in some detail and later chapters return to them repeatedly. 

While these kinds of formalisms can readily be found in textbooks or on whiteboards and blackboards, and lecture slide presentations, their implementations in software are heavily proliferating in the world. Where they travel is sometimes hard to know. Not everyone, even amongst expert practitioners, likes their proliferation. Jeff Hammerbacher, erstwhile chief research scientist at Facebook, co-founder of a successful data analytics company called Cloudera, and currently working also on cancer research at Mount Sinai hospital, complained about where the movement of the techniques  was heading in 2011: 'the best minds of my generation are thinking about how to make people click ads' [@Vance_2011]. While much hinges on what is meant by 'best minds,' Hammerbacher was rightly referring to the incredible growth in the use of predictive analytics techniques anchored in these formalisms in online platforms such as Twitter, Google and Facebook, and on websites more generally, whether they be websites that sell things or websites that sell advertising space. The 'best minds,' however they were ranked, presumably included PhDs from MIT, Stanford or Cambridge whose mathematical skills were wrangling data in the interests of micro-targetted advertising. As Hammerbacher observers, they were 'thinking about how to make people click ads,' and this 'thinking' mainly took and does take the form of building predictive models that tailor the ads shown on websites to individual preferences and desires. In thinking about individual people, and indeed, in seeking to figure an individual amidst very large numbers of people (often numbering millions and sometimes hundreds of millions), the 'best minds' were also constructing and operating with the very  forms of abstraction we see in \ref{eq:linear_regression}. Implicitly, these abstractions have been reconfigured as processual elements of collective life,  but of collectives that are  not necessarily sorted or classified according to the categories and stratifications that have organised political, social and economic in the 20th century. Even amidst the trashy ephemerality of targetted online advertising, fundamental shifts occur.  To lesser or greater extents, through their abstractive work, these researchers participate in the construction of  models of subjectivity, of desire, of belonging, of identity, of inclusion and difference that do not map directly onto existing topologies of difference. Perhaps more importantly,  these models are also engines of difference. The 'best minds of my generation' have been building engines of difference. While Hammerbacher is understandably somewhat dismissive of the existential gratifications of building targetted advertising systems, there is no doubt that these systems are not only valuable commercial systems, but that the process of putting them to work influences classification and prediction much more widely. Acts of buying and selling things are highly social scenes and very much worth analysing as forms of social practice.  

Hardly politicised or power-sensitive, there is a diffuse but nonetheless collective form of awareness emerging around machine learning techniques. As these techniques have propagated from various specialised setting where they first took shape, as they have been taken up and repurposed  in new settings, and particularly as they have become near popular topics of discussion amongst software developers, information architects and chief technolog officers, their capacity to classify, to predict, to cluster or order traits of people, things and events have become the focus of close scrutiny and interest. This interest can be seen in the many training and instructional materials associated with the techniques. Erstwhile Stanford professor of computer science Andrew Ng delivered a set of lectures on machine learning in 2008 that were uploaded to Youtube [@Ng_2008]. The lectures effectively begin by talking about these formalisms \ref{eq:linear_regression} and spend much time developing them.  At the time of writing, thay have been viewed by more than 0.5 million people. We don't how they viewed Ng's technical presentations, nor what they did with them, but the fact that a set of lectures given to post-graduates on predictive modelling attracts so many viewers certainly attests to a contagious interest in these techniques. Implementations of machine learning algorithms and techniques have proliferated in software libraries. Available as software libraries, packages and online webservices, the techniques can float through the archipelagas of software development and coding, landing up in very far-scattered locations. Whether or not they move far, and what difference they make where they end up is not always easy to establish. The engineering and scientific literature on these techniques in the last two decades alone mounts up to several hundred thousand publications explicitly dealing with the techniques, and probably several million more in scattered scientific fields indirectly make use of them. As the techniques circulate more widely, and become settle in quite diverse niches of contemporary life, forms of awareness of the techniques hybridise with the techniques, so that new forms of agency arise. The ways in which people use the techniques in journalism, in the humanities, in social sciences, in art, media, government or civil society overflows the scientific literature and these overflows are not easily seen. Many discussions of 'Big Data,' -- a term I'm planning  to mostly ignore -- don't even mention the pivotal role played by machine learning and suchlike techniques, and this omission makes it much harder to  the accompanying forms of practical awareness, and the new senses of agency that goes alongside that awareness. For instance, if a programmer working on a website incorporates a predictive algorithm to classify users of the website and to vary the what they see on the basis of that classification [@Segaran_2007], what they make in that work is quite different from what might have been done by a web developer in 2000. Say they make use of a Naive Bayes predictive model to classify whether someone visiting a website is likely to be high income or interested in computer games, and then display different banners or advertisements accordingly. The typical machine learning classifier depends on a set of training data whose categories have already been assigned by someone. These categories are sometimes simply an existing set of classifications derived from institutionalised or accepted practice. Sometimes, whole new sets of categories have been invented for a particular purpose. Occasionally, the classifications are 'purely' algorithmic and rely on no direct human intervention (as for instance in many face recognition systems that simply suggest whether a particular has been seen before). Across this spectrum of possible classificatory regimes, there is always some way in which these algorithmics are counting, sorting, ordering and classifying in ways that cut across or cross-section lives. The person who finds themselves paying a different price for a holiday by virtue of some unknown combination of factors including age, credit score, home address, previous travel, or educational qualifications is defined differently by that.  

A much more explicit awareness of the operation of machine-learning driven processes is taking shape in some quarters. And this awareness couples critical and practical responses. For instance, the campaign to re-elect Barack Obama as U.S. President in 2011-12 relied heavily on micro-targetting of voters in the leadup to the election polls [@Issenberg_2012]. In reponse to the data analytics-driven election campaign run by the US Democrats in support of the 2012 re-election of President Barack Obama, data journalists at the non-profit news organisation _ProPublica_ reverse engineered the machine learning models that the Obama re-election team used to target individual votes with campaign messages [@Larsen_2012].   They built their own machine learning model - the 'Message Machine' - using emails sent in by readers and supporters to identify the workings of the Obama campaign team's micro-targetting models. While the algorithmic complexity and data infrastructures used in the Message Machine hardly match those at the disposal of the Obama team, it makes uses of natural language processing (NLP) techniques such as measures of document similarity and machine learning models such as decision trees to disaggregate and map the micro-targetting processes. This kind of reverse engineering work can be found in other quarters. In response to the personalised recommendations generated by streaming media service Netflix, journalists at _The Atlantic_ working with Ian Bogost, a media theorist and programmer, reverse engineered the algorithmic production of around 80,000 micro-genres of cinema used by Netflix [@Madrigal_2014].  While Netflix's system to categorise films relies on much manual classification and tagging with meta-data, the inordinate number of categories they use is typical of the classificatory regimes that are developing in machine learning-based settings.  Certainly, high-profile claims for the power of predictive models to pre-emptively forecast events has come into question. The epidemic predictions of the Google Flu system, a predictive model based on the geography of search engine queries, were wrong on several occasions, mainly because people's online search behaviour changed as a result of coverage [@Lazer_2009; @Butler_2013]. In each of these cases -- reverse engineering political campaign machinery, reverse engineering a film recommendation system, and analysing the shortcomings of a radically different form of epidemiological model -- something is also being critiqued (for its opacity, for its apparent pervasive reach, or simply for its failures), but something is also being made. Making these models shares something with the click predictions. They also contribute to the engineering of the emerging topologies of difference. The critical and practical responses to pervasive prediction do not occupy a different world to the machine learning proponents. They largely move in the same terrain in terms of how they think about numbers, data, probability, and prediction. They largely share the same abstractions -- vector spaces, the geometric line or plane, the cost or error functions widely used to optimize models, or statistical measures or  error, accuracy, specificity, etc.  They also undoubtedly share common infrastructures, but these infrastructureschange much more rapidly as new data formats, database architectures, software libraries and programming languages come and go. 

It is still very difficult, however, to move between a general awareness of the algorithmic saturation of science, business, commerce, government and media and the specificities of different settings in which they might operate. It is hard, moreover, to disentangle what belongs to the algorithms from what belongs to the domain in which they operate. The real problem here is that machine learning techniques, like many other algorithmic constructs, are often quite generic and can be mobilised in very diverse settings without essentially changing. The potency of algorithmic practice attests less to some algorithmic essence and more to the mobility or equivalence afforded by their generic character. I see the problem of understanding the power of algorithms or models such as neural networks as primarily a matter of delineating how this generic character has managed to construct equivalences between very different settings.  What we lack is some way of moving between the abstract and generic character of the algorithms themselves and their mundane and farflung concrete implementations and applications. Without that, it remains difficult to get a sense of what is stake in their adoption or implementation in various settings. 

## The historical and social lives of abstractions

Several different forms of reappraisal might be possible here. The conventional one, at least for social science and humanities, is to locate the sources of their potency, currency, and particularly their apparent transcendence or universality in processes of abstraction epitomised by the function written above ~\ref{eq:linear_regression}. This function, one of the mainstay formalisms of machine learning, and to be found in myriad variations, epitomises in formal terms all the problems and potentials we are going to encounter. Understandings of the sources of the problems and potentials vary according to different philosophical starting points. For twentieth century European philosophers such as Martin Heidegger or Hannah Arendt, decisive transformations in the underpinnings of Western thought occurred in the Scientific Revolution. The advent of algebra and experiment together generated shifts in ontology that profoundly configure modern science and technology. While it might seem a little historically remote to be discussing early modern science in the context of machine learning, solid continuities connect them. More detailed discussion of them has to wait until later chapters, but they include differential calculus (for instance, as used in important optimisation techniques such gradient descent), the probability distribution functions (such as the Gaussian, the Poisson, the Dirichelet, and the Bernoulli distributions), the Lagrangian drawn from classical mechanics formulation of optimization problems, etc. The mathematical techniques of machine learning are not necessarily highly advanced mathematics, but well established mathematical techniques are more intensively deployed there. 

What is happening via these mathematical modes of thought? In standard critical accounts of the development of modern science, these developments are not usually framed as purely intellectual or abstract developments.  It is certainly not a purely intellectual or abstract development, since it does something practical in the world. This is often understood in terms of experiment. For instance, in _The Human Condition_, Hannah Arendt wrote:

> What is decisive is the entirely un-Platonic subjection of geometry to algebraic treatment, which discloses the modern idea of reducing terrestrial sense data and movements to mathematical symbols. Without this non-spatial symbolic language Newton would not have been able to unite astronomy and physics into a single science, or to put it another way, to formulate a law of gravitation where the same equation will cover the movements of heavenly bodies in the sky and motion of terrestrial bodies on earth. Even then it was clear that modern mathematics, in an already breathtaking development, had discovered the amazing human faculty to grasp in symbols those dimensions and concepts which at most had been thought of as negations and limitations of the mind, because their immensity seemed to transcend the minds of mere mortals, ... Yet even more significant than this possibility -- to reckon with entities which could not be "seen" by the eye of mind -- was the fact that the new mental instrument, in this respect even newer and more significant than all the scientific tools it helped to devise, opened the way for altogether novel mode of meeting and approaching nature in experiment [@Arendt_1998, 265]

Here Arendt frames most of modern science and technology as a combination of algebra and experimental practice engaging with the world ('terrestrial sense data and movement') through technical operations on a 'non-spatial symbolic language.' Similar formulations can be found in Edmund Husserl, Martin Heidegger, Maurice Merleau-Ponty, and with certain key modifications in Max Weber or Theodore Adorno. Much social, cultural and political thought shares this treatment of the Scientific Revolution even if they are not explicitly engaged with problems of science and technology. While not startlingly novel, many of Arendt's descriptions of how geometry was re-constituted algebraically, and how algebraic manipulations opened new ground for experimental encounters with natural phenomena, strongly resonate with machine learning techniques. In those techniques too, as we will, constant conversions between geometric, algebraic and statistical or experimental processes occur. Arendt's account of the algebraic reformulation of geometry barely mention calculus or statistics or indeed many other important mathematical developments, but the underlying argument that a kind of turning-inside-out of the 'structure of the human mind' occurred in this process also resonates with machine learning. There is an interesting explanation of all this: 

>With the rise of modernity, mathematics does not simply enlarge its content or reach out into the infinite to become applicable to the immensity of an infinite and infinitely growing, expanding universe, but ceases to be concerned with appearances at all. ... it becomes instead the science of the structure of the human mind [@Arendt_1998, 266]

Arendt understands the mathematical techniques of modern science as externalisations of something that  already belonged to human mental faculties. She suggests that the ongoing development of increasingly counter-intuitive abstractions characteristic of modern mathematical thought (especially around notions such as infinity and limits) can be understood as a turning inward from the world into the 'structure of the human  mind,' 'eye of mind' or 'mental instrument.' (This slightly odd formulation points to the phenomenology's influences on  Arendt.)  'Mathematics succeeded', she writes, 'in reducing and translating all that man is not into patterns which are identical with human, mental structures' (266). The assumption here, and it remains broadly speaking phenomenological in character, is that mathematical abstractions become powerful by virtue of their distance from the fluxing mobility of perception. They wrench experience away from its proximity and entwining with the world, and replace it with the flattened product of distance: 'under this condition of remoteness, every assemblage of things is transformed into a mere multitude' (267). It would be worth thinking more about this 'mere multitude' since that, I suggest, is the primary terrain on which most machine learning, data mining and pattern recognition operates. [TBA - linkage on the pattern recogntion] But this remote perspective derives, on the other hand,  from an almost introspective fixation on patterns derived from 'human, mental patterns.' Some might say that machine learning and pattern recognitions do precisely that today, but in an even more forceful way. In other words, many of these algorithmic techniques rely on mathematical operations and abstractions that are themselves externalised mental structures. 

Arendt's discussion of the nexus of algebra and experiment, and  its 'reducing all appearances through the force inherent in distance' (267) in _On the Human Condition_ is largely framed by the atom bomb and the forms of science associated with nuclear weapons. Machine learning techniques have strong roots in this world, and some of the Cold War optimisation, modelling and simulation problems that these techniques were meant to address remain forcefully in place today. But this analysis hardly seems to relate to the extraordinary proliferation and propagation of decision trees, random forests, logistic regression models, neural networks and support vector machines in sciences, media, government, security and so forth. Can we understand all of these implementations and adoptions of predictive and pattern-finding practices as driven by the externalisation of human mental structures, with its accompanying distance-mediated forcing of things into 'mere multitudes'? Does externalisation account for saturation?

I'm not suggesting that we ascribe everything in these techniques to the externalisation of human structures. In any case, a crucial problem remains. Machine learning techniques may be somewhat experimental. At times, especially in more research-oriented applications, machine learning practitioners set up experiments. And there is a strong tensions between the often less-experimental claims of the advocates of these techniques in industry, commerce or government, and the more experimental practices of researchers. But in either case, something has been added to the externalisation that mathematical science had already pursued. How is that the several century-long externalisation of human mental structures is currently being re-externalised in technical systems? If 'learning' occurs in machine learning techniques, if machine learning algorithms 'do better' than humans at finding patterns in certain settings (principally those characterised by vast 'mere multitude' data sets), then how can we understand that double or secondary externalisation of mental structures? Is this another level or dimension of externalisation? 

These kinds of almost topological shifts in abstractions and their shifting place in the world are very difficult to address in the almost purely philosophical voice such as Arendt's [^3]. Although Arendt certainly does not attribute any universal or trans-historical status to the development of modern science, she does largely regard this development as  homogeneous, indeed monolithic structuring processes. The externalisation of mental structures is an historical process, and it powerfully reorganises the three fundamental modalities of labouring, making and acting that Arendt sees as defining the human condition. Especially in its promotion of _process_ ahead of things, mathematical abstractions potentially pervade all other activities. Hand in hand with that, _making_, and particularly scientific-technological making, supplants the historically generative processes of acting.  

In the contemporary world, Arendt attributes this capacity to act (as in act historically or to unleash processes that result in unexpected courses of events) to scientists: 

> The capacity for action, as least in the sense of the releasing of processes, is still with us, although it has become the exclusive prerogative of the scientists, who have enlarged the realm of human affaire to the point of extinguishing the time-honored protective dividing line between nature and the human world [@Arendt_1998, 323-324]. 

We need to account for the externalisation of the externalised mental structures in different ways. One way is to become a bit more sociological about who or what does the externalising. Rather than 'humans' in general, we might pay more attention to particular groups of people in order to explore how particular ways of thinking and ways of making things become more or less tenable.

[^3]: Although Arendt pays a great deal of attention to labour, life, making, and politics, it is difficult ot see how she would make sense of something like machine learning except as an ongoing development of the modernity.  She writes about finding patterns in the 'mere multitude' that results from algebraic-geometrical transformations in somewhat dismissive terms:

    >Under this condition of remoteness, every assemblage of things is transformed into a mere multitude, and every multitude, no matter how disorder, incoherent, and confused, will fall into certain patterns and configurations possessing the same validity and no more significance than the mathematical curve, which as Leibniz once remarked, can always be found between points thrown at random on a piece of paper [@Arendt_1998,  267]. 

## The social practice of abstraction

How would we think about how particular groups of people in different places do something and are themselves affected by doing something with these techniques? This brings us to a second quite different mode of abstraction: abstraction as economic process. In an important methodological footnote in Volume 1 of _Capital_, Karl Marx suggests that one should always examine machines with an eye on the way the machine has picked up and transformed some hand tool. Machines may contain many hand tools [@Marx_1986, 353], attached and connected to other things (motive power, transmission parts, etc). Amidst the machine learning techniques we will see, many hand implements and instruments can be found. The mathematical formalism of some of them should not confuse the issue too much. These algorithms and mathematical functions at work in these techniques are forms of movement and gesture akin to those done with a hammer or a ruler or a knife. They shape, they align, and they cut. Although the cuts, shapes or aggregates they make have less palpable presence than a brick, a loaf of bread or a shirt, the products of these techniques do have a fabric and texture to them to that bears the marks of the implements and the gestures that made them. It would need further discussion to make that case concretely, but for the moment I'm asking you to accept on faith that (a) machine learning techniques are complicated forms of manipulation or hand movement; (b) the style and trajectory of these movements vary quite widely. The predictions of neural networks differ qualitative and quantitatively from those produced by a support vector machine.  And it almost goes without saying, the production of predictions or descriptions via machine learning techniques does entail much hand work. Here the question that interests me at the moment is how we understand the resort to these machines from the standpoint of economic abstraction. 

The mode of abstraction that Marx and Marxist theory described in some much detail, and with painstaking attention to small details (such as how wear and tear on the spindles of a cotton mills figures in the price of cotton), attempts to understand how value aggregates in the great accumulations of wealth characteristic of contemporary capitalism. The key point for our purposes is that abstraction in a capitalist mode of production entails a constant readjustment of the relative amounts of value that derive from what people do together as they work in various settings to make things that can be sold, and the amount that those people are paid for what they do. As Marx writes, the 'starting point of capitalism is the assumption that all labour is collective' [@Marx_1986, 306][TBA - get the quote], and much of the economic development of capitalism comprise amassing people in close proximity (as in cities) in order to increase their collective power. For what happens in capitalism, according to Karl Marx in _Capital Volume 1_ is that the co-operative or relational processes that almost spontaneously take shape when people work together become principles for the organisation of a division of labour that allows production systems like factories to appear. At the same time, bringing people to work together in workshops, manufacturing and then factories makes a place for a constantly steeper gradient of automation to begin to interweave itself within the co-operative relationalities. Marx describes  [@Marx_1986] 'all well-developed forms of capitalist production' as  'forms of cooperation' [@Marx_1986, 372], and the fact that these forms of cooperation can be reorganised, reconfigured and constantly transformed allows the historical process of the development of capitalism. Industrialisation for instance, assembles people in places where their potential for cooperation can be concentrated, channelled and focused on specific ends (such as, for instance, producing things more cheaply in a factory). At the same time, the concrete forms of cooperation or 'social labour' (309) that take shape in these concentrated collectives (workshops, factories, etc) lends itself to many further transformations. It renders visible in one place precisely points of intervention or engagement in the process of production amenable to transformation.   Automation for instance can focus on those forms of movements that are most common: putting things in a line, making a circular hole, or making a straight line (363). The deepest transformation taking place concerns the effects of the superintending, adjusting and tuning of the cooperative power of social labour: 'a productive power immanent to capital appears' writes Marx (313), and this productive power concretises itself in manufacturing processes that are intensely calculative as they realize that cooperation can be systematised and rendered calculable in a multitude of ways (rates of production, efficiency, relative comparison of different divisions of labour, etc.). A series of somewhat recursive processes also can take hold of the system of production as measures and calculations of specific rates, speeds, energies and costs supplant much more diffuse measures of production.  In factories for instance, the power of cooperation blends with machinery to such a degree that the factory often becomes a single vast machine (an assembly line, for instance) comprising many non-living and living parts whose cooperation is in many respects simplified because the intellectual-cognitive component has been re-distributed heavily in the direction of the machines, as well as the engineers and technicians who make and control them. 

Obviously the Cyclopean rivet presses of the Manchester foundries described by Marx lie a long way from the neural networks, logistic regression models and decision trees of contemporary machine learning as deployed for instance by Jeff Hammerbacher working on data analytics at Facebook or Andrew Ng working on image classification at the Google Brain in California. While the scales of movement, the concatenation and ordering of living bodies together with systems of machines differ greatly, direct parallels run between the 19th century factories described by Marx and those we can see taking shape around machine learning. Here too there is a concern with straight lines, with the strength of things, with making things happen at higher speed, and of finding places where what was previously done by hand can be replaced by something done by a machine. Even if the  lines and curves are now drawn through masses of data points rather than through a lump of cast iron, even if the shaping is done using parameters on a decision tree rather than the levers of a lathe, there is something akin to factory industrialisation occurring in machine learning. And if that parallel holds at all, then we might expect to find some other associated changes at work.  

## Machine learning as introjection

The major point of divergence was already signalled by Arendt's description of science and engineer, when she said that scientists and engineers are almost the only people who act. An alternative understanding of this shift has been described in recent Marxist theory. For Marxist theorists like Paolo Virno, contemporary work is distinctively characterised by the incorporation of previously social and communicative processes into the very fabric of production. As we might already deduce from Marx's own writings, which stress the importance of cooperation and collaboration as the underpinning of industrial progress, this reconfiguration  changes the dynamics of politics, making and work. Virno writes:

>Contemporary labor has introjected into itself many characteristics which originally marked the experience of politics. Poiesis has taken on numerous aspects of praxis [@Virno_2004, 50].

Like Arendt, Virno suggests that something has shifted in contemporary capitalism in which what formerly took place in one arena has been taken -- Virno uses the psychoanlytic term 'introjection' -- into another. This is not necessarily the first such decisive shift.[^7] In speaking of _poiesis_ or making, Virno suggests that both what is made and how it is made now look more like the domain of _praxis_ or political action. In _praxis_, according to Virno, something like a publicly organised cooperation occurs. 'This “publicly organized space” - introjected into the labor process – mobilizes attitudes which are traditionally political' [@Virno_2004,  63]. Cooperation is organised by the 'linguistic-cognitive habits' of humans in many settings, but only today does it become the basic of the ongoing development of production (40). It is, however, a crucial one to understand in thinking about the growth of predictive abstractions. The development of contemporary processes of production focuses on what people do together, as they work and as they live. Their lives, the ways in which they live together, ranging from how they move through a crowded street to what websites they visit, or how often they telephone their friends and family, or how their consumption of alcohol relates to their voting practices or where they live: all of these realms of private and public practice has been ingested. 

[^7]: Arendt had already described how in the seventheenth century the previously rather minor sphere of _society_  assumed great importance as a public place in which many previously disparate practices and groups found themselves suddenly side by side. 

    >Since the rise of society, since the admission of household and housekeeping activities to the public realm, an irrestible tendency to grow, to devour the older realms of the political and private as well as the more recently established shpere of intimacy , has been one of the outstanding characteristics of the new realm [@Arendt_1998, 45].

    The historical advent of 'the social' as an important sphere is just one of the transformations in the dynamics of labour, making and acting that Arendt describes in _The Human Condition_, but I largely leave these transformations aside. 


My suggestion here is that a triple abstraction occurs. First, in the mode of abstraction that defines capitalist development, what was previously carried out by people is now carried out by machines. We don't need to read Marx to know that this displacement or replacement of 'variable capital' (labour power) by 'fixed capital' (machines and infrastructure) is constant and seemingly interminable. (Or more technically, the ratio of the production of absolute surplus value to relative surplus value, the value due to people working versus the value produced by the machines doing things faster or more cheaply than people can, is subject to constant revision).  The 'learning' in machine learning often replaces work that done by hand and eye, even the skilled hands and eyes of statisticians or data analysts. Cognitive-linguistic capacities such as identifying patterns or regularities in what people do, either through experience or through much manual effort (such as driving a car, or comparing a photograph in a passport to the person standing of front of you) is done by machines. More importantly, the replacing of practice by automatic movement is very open-ended. Any work whose intricacy or complexity seems to defy automation becomes a particular target of analysis: flying a helicopter upside down, mapping the patterns of nerve activity present in the stump of an amputated limb to the movements of the prosthetic limb, deciding how to price the different items on sale in this year's fashion in comparison to competitors offerings. All of these complicated decisions and practices are the kind of terrain that machine inhabits. The abstraction here concerns the way in which any or all places are more less treated in the same way as problems that machines, configured and steered in the right way, can learn. A second form of abstraction concerns the ways in which machines externalise the cognitive-mental faculties of human thought (as described by Arendt). That abstraction combines historically sedimented habits and practices of making and symbolising space, pattern, order and number with specific practices of computation and calculation. Note that these practices of making and symbolising, at least as they took shape in the last few centuries, were closely tied to the development of capitalism and its machine technologies.  Finally, a third abstraction occurs when these techniques or processes of learning are applied to the public or private configurations of collective life. In this abstraction, patterns of collective life more generally are subjected to the same processes of pattern recognition, prediction and anticipation originally developed in relation to the dynamics of machines. Not only are the sites of production or making subject to learning algorithms, but any domain of daily life where organised practice occurs, any place where people do things together, or where, doing is somehow connected to consuming goods and services, then all of life, not just life in the workplace, becomes part of the terrain of abstraction. In online advertising, for instance, predicting what advertisement to show at what time to what person is tantamount to turning the social life of commodities, and the complex sociality that buying and selling things entails, into a part of another commodity -- the selling of advertising spaces or shows to advertisers. Abstraction of abstraction transforms mundane social interactions into components of models that for instance try to promote the sale of somethings, or the choice of some people. 

This triple abtraction -- labour treated as that which can be interminably abstracted by machines that learn, machines that externalise human mental-cognitive practices, social life treated collectively as process that can be 'experienced' as part of an automated production system -- usually takes hold at particular places in the processes of collective social life. For instance, online advertising occurs at the intersection between the social media practices of communication or social networks and marketing or advertising. At these intersections, the individual traits of an individual or the well-established social functions and roles matter less than the forms of emergence, change or novelty that might support new forms or permutations of abstraction. The doubly abstract development of capital predicates constant invention and novelty, and collective experience, and the forms of individuation it generates are vital components of this development.[^8] Given the presence of triple abstraction in contemporary life, the questions that then arise concern what to do about it. 

[^8]: Virno writes:
    >The collective experience, the life of the group, is not, as we usually believe, the sphere within which the salient traits of a singular individual diminish or disappear; on the contrary, it is the terrain of a new and more radical individuation. By participating in a collective, the subject, far from surrendering the most unique individual traits, has the opportunity to individuate, at least in part, the share of pre-individual reality which all individuals carry within themselves. ... Only within the collective, certain not within the isolated subject, can perception, language and productive forces take on the shape of an individuated experience.[@Virno_2004, 79]

This description of collective experience as individuation draws directly on the work of Gilbert Simondon. While Simonondon's account of collective individuation remains, it seems to me, very useful in understanding the terrain on which machine learning moves, I will not rehearse here his account of technical practices and their part in collective life. See [TBA -- add refs for this]

## The critical efficacy of lesser Amazons

What to do about the processes of contemporary abstraction is a  challenging question, and not one that I'm going to attempt to answer here. At core, the question is a practical one. What does one do with these abstractions? Can they become practical resources for people like artists or writers who make things? Can they become critical instruments in the hands of social researchers trying to make sense of hypercomplex media environments? Do they, in the way they pattern and number the world, prompt new lines of philosophical and conceptual invention about knowing, things and relationalities? The rest of this book is an effort to present some of the different aspects of that challenge, and to delineate what is at stake in responding to them. For the moment, I think it might be possible to sketch some new relations to these abstractions at least in conceptual terms, and to approach them a bit differently if we understand something of their mode of existence. This is to largely anticipate developments that following chapters pursue, but also to focus on two main problems highlighted by Alex Galloway in the context of critical discussion of digital humanities. Galloway makes two points in quick succession:

>When using quantitative methodologies in the academy (spidering, sampling, surveying, parsing, and processing), one must compete broadly with the sorts of media enterprises at work in the contemporary technology sector. A cultural worker who deploys such methods is little more than a lesser Amazon or a lesser Equifax.110 [@Galloway_2014] 

The 'quantitative methodologies' that he describes here in terms of spidering and so forth are more or less all funnelled through machine learning techniques (for instance, the Association Rule Mining techniques used by Amazon to recommend purchases, or whatever techniques used by the credit-rating systems at Equifax). Galloway's argument is that the infrastructural scale of these enterprises along with the sometime very large technical workforces they employ to continually develop new predictive techniques means that any critical appropriation of the techniques is bound to be relatively weak. 

Even if 'cultural workers' do manage to learn to machine learn, and become adept at re-purposing the techniques in the interests of something other than selling things or generating credit scores, what is to be gained by doing so? Galloway suggests that doing so might not actually answer to the ethical and political challenges we face:

>But beyond the challenge of unequal talent and resources is the question of critical efficacy. Is it appropriate to deploy positivistic techniques against those self-same positivistic techniques? In a former time, such criticism would not have been valid or even necessary. Marx was writing against a system that laid no specific claims to the apparatus of knowledge production itself—even if it was fueled by a persistent and pernicious form of ideological misrecognition. Yet, today the state of affairs is entirely reversed. The new spirit of capitalism is found in brainwork, self-measurement and self-fashioning, perpetual critique and innovation, data creation and extraction. In short, doing capitalist work and doing intellectual work—of any variety, bourgeois or progressive—are more aligned today than they have ever been [@Galloway_2014].

Added to relative weakness, complicity or harmonisation with the 'new spirit of capitalism' does not sound like an attractive option for critical or constructive thought. Although Marx himself was relatively heavily invested in quantifying the abstractions of the capitalist mode of production, his situation was different to ours where, as Galloway writes and as we have already seen from Arendt, Virno and others, intellectual work and value creation are entangled. 

No doubt some deep tensions affect any engagement with these processes, including the issues of relative weakness and inevitable appropriation. I am not sure, however, that the question of critical efficacy can be quickly settled. Although there are no great reasons to be very optimistic about machine learning as an engine of difference, there are a number of 'efficacies' associated with machine learning that I think might be worth exploring. These include differentiating alignments in machine learning. Are the use of topic models by a digital humanist [@Mohr_2013], the use of association rule mining by Amazon and the use of k-means clustering to identify breast cancer sub-types [@Curtin_2012] equivalent? The possibility of identifying tumour sub-types is an empirically different setting than a product recommendation system, and offers different potentials for critical thought that can only be developed by working out how the same techniques can be aligned quite differently in different settings.[^13]

[^13]:  We might not in passing that Marx himself had a complicated relation to his contemporary apparatus of knowledge production. In some ways, as the painstaking calculation of rates of production of surplus value, profit, etc in _Capital Volume 1_ show, Marx was writing against the calculations of value propounded by political economists of his time, many of whom were active supporters of factory owners in their opposition to any shortening of the working day. Marx also, as is well known, was an avid reader of Darwin, was heavily influenced by 19th thermodynamics and biological understandings of biochemistry and metabolism. In short, the critical work Marx undertook was itself the precursor of the reversal of the situation that Galloway describes.

If we do manage to do that, then the follow-on question might be whether we can still understand these techniques as positivistic. Is it is positivistic to build and tune a Naive Bayes classifier for spam email or a neural network for cat images like `kittydar`?  What these techniques derive from experience -- the core tenet of positivism is that knowledge derives only from experience -- is a matter for much further discussion. For in  many ways, as we have already glimpsed, the amalgams of linear algebra, differential calculus and probability theory running through the techniques is not only triply abstract, but very much concerned with re-evaluating experience as a machinic process. In any case, it is possible that Galloway uses 'positivism' here simply in the sense of 'quantitative,' in which case we would need to perhaps also appraise what is happening to quantity and number in particular in these techniques. Number today is not what it was (and if we listen to Alain Badiou's admonitions around number: statistics as the 'infinite excrescence' of number, and 'Number is that which through being _organises_ thought.' [@Badiou_2008, 92]), and if number is in transition, then so is quantitative research and positivism.  If cognitively, materially, epistemically and economically, the ground is shifting around these techniques, then we do not yet know what possible critical efficacy they might  potentially hold.  In fact, more to the point, we do not yet know what it means for contemporary capitalism to saturate itself with predictive mechanisms. 

## The contemporary experience of mathematical objects and events

Given all the discussion of abstraction in various modes, and then the problems of responding to machine learning techniques in ways that do not just participate in people buying things, how do we pursue some of the affirmative potentials in machine learning. The approach that I think might work best lies at the intersection of the machine learning practice, social science research, software cultures and philosophical thought. Certainly the chapters that follow draw on and attempt to link all of these domains both in analysing them and at times analysing the tensions between them. Perhaps the most immediate tension arises from the contrast between the apparent transcendant mathematical formalism of these techniques and the different ecologies of practice in which they appear. If you turn your attention back to \ref{eq:linear_regression} or \ref{eq:linear_regression_inner_product}, what you see there will depend on a couple of different things. Sociologically speaking, if you find them baffling or opaque, that means you are not endowed with what the field of machine learning requires of those who wish to engage with the practices of prediction. In other words, what you see in those formalisms can be explained in terms of who you are. As Pierre Bourdieu writes:  

>The experience of the transcendence of scientific objects, especially mathematical ones, that essentialist theories invoke is the particular form of _illusio_ which arises in the relationship between agents possessing the habitus socially required by the field and symbolic systems capable of imposing their demands on those who perceive them and operate them, and endowed with an autonomy closely linked to that of the field (which explains why the sense of transcendent necessity rises with the capital of accumulated resources and the qualifications demanded for entry) [@Bourdieu_2000, 113-114].

In this slightly convoluted formulation, Bourdieu points to the way in which mathematical formulations can appear to transcend normal life by virtue of the way in which they arise at the confluence of two materially different entities -- people who have embodied a set of practical techniques related to mathematics, statistics and in this case, computer science -- and the field of machine learning (standing at the intersections of statistics, mathematics, and computer science) in which these kinds of scientific objects \ref{eq:linear_regression} attest to a kind of generalizability that promises ongoing relevance.  The _illusio_ Bourdieu refers to here is slightly less prominent in machine learning than it might be, say, in quantum physics or other highly mathematico-physical sciences whose symbolic systems have been so powerfully developed that many proponents feel compelled to speak of laws of nature or fundamental principles. While claims to fundamental insight are not abundant in machine learning, I think we should be careful whenever they arise. They not take the form of claims to natural law, but they might, for instance, attribute agency to machines in ways that make it harder to engage with them (for instance, by claiming that machine 'learn'). Both the chilling effect of mathematical formalism for some people, and their attraction for others needs to be gauged in relation to the socially acquired habitus that modulates those reactions. 

While experience of transcendence are not heavily emphasised in machine learning, much of Bourdieu's account of transcendence resonates with the ways in which these techniques are learned and practiced. Unlike more mundane techniques and technical configurations, these techniques involve some relatively formidable mathematical abstractions, and these abstractions, as we will discuss below, promise certain kinds of autonomy or quasi-autonomous action (for instance, they 'learn'). At the same time, the habitus -- the embodied skills in judging, perceiving, acting -- necessary to develop and apply these techniques is a matter of much discussion and debate (for instance in the many perseverant pronouncements about the need for people who can analyse the data), depends on people internalising 'symbolic systems' (linear algebra, probability and statistics, etc) that 'demand' the world be approached in some ways and not others (for instance, as a problem whose solutions can be found through processes of optimization). As in Arendt's account of the efficacy of mathematics in the world as an effect of distance, and of putting oneself at such a distance from things that mathematical functions can be seen operating everywhere, Bourdieu's account of mathematical transcendence -- its capacity to operate in many different times and places without changing -- depends on a relation between agents and symbolic systems. 

Even if we do manage to recognise the experience of scientific objects in that way suggested by Bourdieu, this clearly does not exhaust our relationship to them. They can be differentiated according to how they exist in the world. In her account of how we might better understand the development of physics over the last three centuries without resort to loaded terms such as determinism or law, Isabelle Stengers describes how one particular type of abstraction came to exist in the world as new types of being [@Stengers_1997a]. Her analysis of a key mathematical formalism of late 18th century physics -- the Lagrangian -- exemplifies this treatment of techniques of abstraction in terms of their specificity and eventuality. The Lagrangian, which still underpins the important support vector machine technique (discussed in Chapter 4), is according to Stengers a kind of machine, a 'physico-mathematical factish' [faitiche physico-mathematique], or 'a machine to put into equivalence endowed with the power to confer a unique form on the diversity of empirical situations' (68-69).[^9] Stengers' emphasis on the ways in which particular techniques such as the Lagrangian [TBA -- a way of what?] create equivalences is not meant to essentialise techniques or particular modes of abstraction. On the contrary, her goal is to highlight some of the ways in which such techniques are practiced, and the inventions that arise as practitioners pursue visions of unified form amidst so many divergences and anomalies. From this perspective, abstractions and modes of abstraction might create equivalences (for instance, as in the $=$ sign in \ref{eq:linear_regression}) that seem unlikely. Stengers describes how 'physicists, in the name of unitary vision of a world intelligible in terms of laws' forged 'categories that were always more audacious, always more in rupture with accepted notions of time, space or causality' [@Stengers_1997a, 130].[^10]

In some ways, what Stengers suggests in relation to the role of the Lagrangian abstraction of mechanics applies even more powerfully to machine learning techniques. Not only do they draw on many of the same mathematical formalisms -- the Langrangian, the differential calculus, linear algebra, and then the 18-19th century apparatus of probablity and statistics -- they also aim to cover many different situations in equivalent ways. As we will say, the variety of empirical situations that might be covered by a typical machine learning technique such as a neural network or a Naive Bayes classifier is diverse and this diversity is aligned around the equivalence of the $=$ sign in the functions characterise the different situations involved. If the history of modern physics can be seen as the ongoing development of that 'Lagrangian event' (in Hamiltonian mechanics and then quantum mechanics, in thermodynamics or economics), what does it mean for the same physico-mathematical forms to now surface in situations of machine learning? The reappearance of the Lagrangian in  the context of support vector machines does not entail a complete generalization of the technique. Rather it attests to the way in which certain situations can be reconfigured as then the ways in which contemporary recapitulations of that event. We need to understand how this reconfiguration can occur. In the case of the Lagrangian in physics, Stengers writes: 'in effect, if there had been the creation of a language of dynamics, it is very much because there were 'privileged cases' whose behaviour exhibited singularity which conferred its operational power on the sign '=' (128)[^11]. The power of machine learning, in this view, does not result from any fundamental pattern or order in the world, but rather from the construction of a machine to create equivalences that submit empirically diverse situations to a single way of posing a problem. In terms of critical efficacy, this power is what both the scientific and business uptake of machine learning techniques seek. At the same time, because it is a powerful way of framing problems, the machinery to create equivalences can itself create 'ruptures with accepted notions.' This admittedly is not what we first see as when we received another personalised advertisement, or when we realise that the prices see for particular goods have been generated by pricing algorithms at work in the supply chain logistics system. On the other hand, it might be there when we see how the algorithms work in different circumstances.

This points to a second zone of emergence concerning the location of machine learning techniques. We saw with  `kittydar` that sophisticated non-linear models can be superimposed in order to detect cats in photographs. The point however of `kittydar` is not that algorithms can see cats. They probably have been able to do that for quite a while. The important point is that algorithms running in Javascript code in a webbrowser can detect cats in images. The deployment or mobilisation of neural networks in the world is the event here since it suggests that software cultures, by which I mean the teeming plurality of coding and software development practices that connect up, configure, and energise the contemporary fields of devices, are beginning to engage in probabilistic and predictive programming. The transcendental effect here is transformed into something relatively banal or mundane perhaps. This transformation, however, is just what might generate powerful divergent potentials, forms of unanticipated equivalence. Machine learning in the wild might just generate surprises. It might be eventful. Some of the recent work of Shinseungback Kimyonghun, an artist collective working with machine learning algorithms for computer vision in South Korea, illustrate this point nicely. They took `kittydar` and tested it against a stream of photographs of human faces from the photo-sharing Flickr.com to produce the work ['cat-human'](http://ssbkyh.com/works/cat_human/). As the images in Figure 2 show, `kittydar` finds some faces look like cats. (And conversely, face recognition algorithms sometimes see cats as people.) Trivial thought it may, the equivalences between cats and people attests to the kinds of events that might take place in playing, working and associating with machine learning. 

[^11]: En effect, s'il y a eu creation du langage dynamique, c'est bel at bein parce qu'il y avait des <<cas privilegies>> dont le comportement _exhibait_ la singularite qui a confere son pouvoir operationnnel au sign =. [@Stengers_1997a, 128].

[^9]: >Un noveau type d'etre de venir au monde, ce que j'ai appele un 'faitiche physico-mathematique': une machine a mettre en equivalence douee do puvoir do confere une forme unique a las diversite des situation empiriques. A ce nouvel etre correspond une nouvelle [@Stengers_1997a, 68-69]

[^10]: > Sans elle, il est difficle de comprendre le caractere inventif de la pratique de ces physiciens qui, au nome d'une vision unitaire do'u monde intelligible en termes de lois, forgent avec la plus grande liberte de categories toujours plus audacieuses, toujours plus en rupture avec les notions communes d'espace, de temps ou de cause. [@Stengers_1997a,130]

[HERE] -- go on to also discuss D@G on concepts and functions. 
>Why look at technique? Le pouvoir de la dyanmique n'est pas celui d'une vision, c'est celui de la machine a creer des equivalences qui soumet la diversite empirique a une mise en probleme unique. 71


## To include?

Something similar can be found in the very different mode of explanation of the potency of mathematical abstractions in sociological thought. Pierre Bourdieu, for instance, situates mathematical abstractions in the space between embodied skills and knowledges (the habitus of mathematicians) and symbolic systems possessing forms of closure:
  There are very different ways of working together. Mostly today, people work together in organisational forms such as corporations or institutions pervaded by corporate forms. The forms of work they do together may involve making things (as in a factory), but more often will mean providing services to other people (teaching them, nursing them, cleaning for them, transporting, feeding them, etc). All of this seems a long way from machine learning, but  Jeff Hammerbacher's complaint about PhD's spending their lives trying to predict who will click on an online ad suggests that production and reproduction through the consumption of goods and services is not so very far from the concerns of machine learning as we might think.  Again, as in Arendt's account, I'm taking a very broad historical perspective on machine learning. 




The problem of moving between the algorithms and their culturally saturated feedback loops matters because of the powerful grip these techniques have on contemporary data practice. While many of the intuitions underlying these techniques are relatively simple (for instance, the idea of drawing a line through a group of points as a way of describing the main tendency in a dataset), there are many differences in how these techniques work. 

>When an object – a geometrical space, for example – is scientifically constructed by functions, its philosophical concept, which is by no means given in the function, must still be discovered [@Deleuze_1994, 117].

In what ways do what computers do with data today change how we think about what we do? This slightly loopy question invites many possible responses. But I'm principally interested here in an increasingly widespread form of computation known variously as machine learning, pattern recognition, knowledge discovery, data mining or predictive analytics. Each of these terms comes from slightly different quarters, and they overlap with each other at many points. In general, however, all of them attest to the growth of a set of techniques concerned with working with data. These techniques are almost the sole focus of this book. The techniques assembled under the name machine learning are hardly new. Some of them date back more than a century, and the bulk of them are decades old. The breadth and scale of their application in recent years is somewhat astonishing. In the last few years, they have quickly become staple techniques in science, business, government, entertainment and media. 


Databases and information infrastructures have been discussed widely in various settings, but often without reference to underlying computational abstractions. Moreover, the techniques of machine learning have received little critical attention, even though they have been pervasively threaded through infrastructures, devices and data practices. This threading  is rather opaque. It is the most slow-moving and tectonic aspect of what is currently happening with data, yet these techniques entail relatively high levels of abstraction. It would be possible to understand many changes in data-driven businesses, infrastructures and science in terms of the potentials implicit to these techniques. For instance, the seemingly obvious trend to collect and analyse more data is not simply a case of more is better. The performance of certain models and algorithms, as measured in terms of error rates, depends on the amount of data they have to work with. Attempts to optimise algorithmic performance, as we will see, generate demand for more data. More generally, the transformations associated with these techniques, I will suggest,  generates many different potentials, and lays down challenges for any re-thinking of what social sciences and critical humanities will do with data.


## References

