<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Machine Learning: Archaeology of a Data Practice</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Machine Learning: Archaeology of a Data Practice">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Machine Learning: Archaeology of a Data Practice" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Machine Learning: Archaeology of a Data Practice" />
  
  
  

<meta name="author" content="Adrian Mackenzie">


<meta name="date" content="2016-12-10">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="9-patterns-and-differences.html">
<link rel="next" href="11-propagating-subject-positions.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="1-acknowledgments.html"><a href="1-acknowledgments.html"><i class="fa fa-check"></i><b>1</b> Acknowledgments</a></li>
<li class="chapter" data-level="2" data-path="2-preface.html"><a href="2-preface.html"><i class="fa fa-check"></i><b>2</b> Preface</a></li>
<li class="chapter" data-level="3" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html"><i class="fa fa-check"></i><b>3</b> Introduction: Into the Data</a><ul>
<li class="chapter" data-level="3.1" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#three-accumulations-settings-data-and-devices"><i class="fa fa-check"></i><b>3.1</b> Three accumulations: settings, data and devices</a></li>
<li class="chapter" data-level="3.2" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#who-or-what-is-a-machine-learner"><i class="fa fa-check"></i><b>3.2</b> Who or what is a machine learner?</a></li>
<li class="chapter" data-level="3.3" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#algorithmic-control-to-the-machine-learners"><i class="fa fa-check"></i><b>3.3</b> Algorithmic control to the machine learners?</a></li>
<li class="chapter" data-level="3.4" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#the-archaeology-of-operations"><i class="fa fa-check"></i><b>3.4</b> The archaeology of operations</a></li>
<li class="chapter" data-level="3.5" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#asymmetries-in-common-knowledge"><i class="fa fa-check"></i><b>3.5</b> Asymmetries in common knowledge</a></li>
<li class="chapter" data-level="3.6" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#what-cannot-be-automated"><i class="fa fa-check"></i><b>3.6</b> What cannot be automated?</a></li>
<li class="chapter" data-level="3.7" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#different-fields-in-machine-learning"><i class="fa fa-check"></i><b>3.7</b> Different fields in machine learning?</a></li>
<li class="chapter" data-level="3.8" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#the-diagram-in-critical-thought"><i class="fa fa-check"></i><b>3.8</b> The diagram in critical thought</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html"><i class="fa fa-check"></i><b>4</b> Diagramming machines}</a><ul>
<li class="chapter" data-level="4.1" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#we-dont-have-to-write-programs"><i class="fa fa-check"></i><b>4.1</b> ‘We don’t have to write programs’?</a></li>
<li class="chapter" data-level="4.2" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-elements-of-machine-learning"><i class="fa fa-check"></i><b>4.2</b> The elements of machine learning</a></li>
<li class="chapter" data-level="4.3" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#who-reads-machine-learning-textbooks"><i class="fa fa-check"></i><b>4.3</b> Who reads machine learning textbooks?</a></li>
<li class="chapter" data-level="4.4" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#r-a-matrix-of-transformations"><i class="fa fa-check"></i><b>4.4</b> <code>R</code>: a matrix of transformations</a></li>
<li class="chapter" data-level="4.5" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-obdurate-mathematical-glint-of-machine-learning"><i class="fa fa-check"></i><b>4.5</b> The obdurate mathematical glint of machine learning</a></li>
<li class="chapter" data-level="4.6" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#cs229-2007-returning-again-and-again-to-certain-features"><i class="fa fa-check"></i><b>4.6</b> CS229, 2007: returning again and again to certain features</a></li>
<li class="chapter" data-level="4.7" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-visible-learning-of-machine-learning"><i class="fa fa-check"></i><b>4.7</b> The visible learning of machine learning</a></li>
<li class="chapter" data-level="4.8" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-diagram-of-an-operational-formation"><i class="fa fa-check"></i><b>4.8</b> The diagram of an operational formation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html"><i class="fa fa-check"></i><b>5</b> Vectorisation and its consequences}</a><ul>
<li class="chapter" data-level="5.1" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#vector-space-and-geometry"><i class="fa fa-check"></i><b>5.1</b> Vector space and geometry</a></li>
<li class="chapter" data-level="5.2" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#mixing-places"><i class="fa fa-check"></i><b>5.2</b> Mixing places</a></li>
<li class="chapter" data-level="5.3" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#truth-is-no-longer-in-the-table"><i class="fa fa-check"></i><b>5.3</b> Truth is no longer in the table?</a></li>
<li class="chapter" data-level="5.4" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#the-epistopic-fault-line-in-tables"><i class="fa fa-check"></i><b>5.4</b> The epistopic fault line in tables</a></li>
<li class="chapter" data-level="5.5" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#surface-and-depths-the-problem-of-volume-in-data"><i class="fa fa-check"></i><b>5.5</b> Surface and depths: the problem of volume in data</a></li>
<li class="chapter" data-level="5.6" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#vector-space-expansion"><i class="fa fa-check"></i><b>5.6</b> Vector space expansion</a></li>
<li class="chapter" data-level="5.7" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#drawing-lines-in-a-common-space-of-transformation"><i class="fa fa-check"></i><b>5.7</b> Drawing lines in a common space of transformation</a></li>
<li class="chapter" data-level="5.8" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#implicit-vectorization-in-code-and-infrastructures"><i class="fa fa-check"></i><b>5.8</b> Implicit vectorization in code and infrastructures</a></li>
<li class="chapter" data-level="5.9" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#lines-traversing-behind-the-light"><i class="fa fa-check"></i><b>5.9</b> Lines traversing behind the light</a></li>
<li class="chapter" data-level="5.10" data-path="5-vectorisation-and-its-consequences.html"><a href="5-vectorisation-and-its-consequences.html#the-vectorised-table"><i class="fa fa-check"></i><b>5.10</b> The vectorised table?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html"><i class="fa fa-check"></i><b>6</b> Machines finding functions}</a><ul>
<li class="chapter" data-level="6.1" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#learning-functions"><i class="fa fa-check"></i><b>6.1</b> Learning functions</a></li>
<li class="chapter" data-level="6.2" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#supervised-unsupervised-reinforcement-learning-and-functions"><i class="fa fa-check"></i><b>6.2</b> Supervised, unsupervised, reinforcement learning and functions</a></li>
<li class="chapter" data-level="6.3" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#which-function-operates"><i class="fa fa-check"></i><b>6.3</b> Which function operates?</a></li>
<li class="chapter" data-level="6.4" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#what-does-a-function-learn"><i class="fa fa-check"></i><b>6.4</b> What does a function learn?</a></li>
<li class="chapter" data-level="6.5" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#observing-with-curves-the-logistic-function"><i class="fa fa-check"></i><b>6.5</b> Observing with curves: the logistic function</a></li>
<li class="chapter" data-level="6.6" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#the-cost-of-curves-in-machine-learning"><i class="fa fa-check"></i><b>6.6</b> The cost of curves in machine learning</a></li>
<li class="chapter" data-level="6.7" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#curves-and-the-variation-in-models"><i class="fa fa-check"></i><b>6.7</b> Curves and the variation in models</a></li>
<li class="chapter" data-level="6.8" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#observing-costs-losses-and-objectives-through-optimisation"><i class="fa fa-check"></i><b>6.8</b> Observing costs, losses and objectives through optimisation</a></li>
<li class="chapter" data-level="6.9" data-path="6-machines-finding-functions.html"><a href="6-machines-finding-functions.html#gradients-as-partial-observers"><i class="fa fa-check"></i><b>6.9</b> Gradients as partial observers</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-the-power-to-learn.html"><a href="7-the-power-to-learn.html"><i class="fa fa-check"></i><b>7</b> The power to learn</a></li>
<li class="chapter" data-level="8" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html"><i class="fa fa-check"></i><b>8</b> Probabilisation and the Taming of Machines}</a><ul>
<li class="chapter" data-level="8.1" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#data-reduces-uncertainty"><i class="fa fa-check"></i><b>8.1</b> Data reduces uncertainty?</a></li>
<li class="chapter" data-level="8.2" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#machine-learning-as-statistics-inside-out"><i class="fa fa-check"></i><b>8.2</b> Machine learning as statistics inside out</a></li>
<li class="chapter" data-level="8.3" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#distributed-probabilities"><i class="fa fa-check"></i><b>8.3</b> Distributed probabilities</a></li>
<li class="chapter" data-level="8.4" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#naive-bayes-and-the-distribution-of-probabilities"><i class="fa fa-check"></i><b>8.4</b> Naive Bayes and the distribution of probabilities</a></li>
<li class="chapter" data-level="8.5" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#spam-when-foralln-is-too-much"><i class="fa fa-check"></i><b>8.5</b> Spam: when <span class="math inline">\(\forall{N}\)</span> is too much?</a></li>
<li class="chapter" data-level="8.6" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#the-improbable-success-of-the-naive-bayes-classifier"><i class="fa fa-check"></i><b>8.6</b> The improbable success of the Naive Bayes classifier</a></li>
<li class="chapter" data-level="8.7" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#ancestral-probabilities-in-documents-inference-and-prediction"><i class="fa fa-check"></i><b>8.7</b> Ancestral probabilities in documents: inference and prediction</a></li>
<li class="chapter" data-level="8.8" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#statistical-decompositions-bias-variance-and-observed-errors"><i class="fa fa-check"></i><b>8.8</b> Statistical decompositions: bias, variance and observed errors</a></li>
<li class="chapter" data-level="8.9" data-path="8-probabilisation-and-the-taming-of-machines.html"><a href="8-probabilisation-and-the-taming-of-machines.html#does-machine-learning-construct-a-new-statistical-reality"><i class="fa fa-check"></i><b>8.9</b> Does machine learning construct a new statistical reality?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-patterns-and-differences.html"><a href="9-patterns-and-differences.html"><i class="fa fa-check"></i><b>9</b> Patterns and differences</a><ul>
<li class="chapter" data-level="9.1" data-path="9-patterns-and-differences.html"><a href="9-patterns-and-differences.html#splitting-and-the-growth-of-trees"><i class="fa fa-check"></i><b>9.1</b> Splitting and the growth of trees</a></li>
<li class="chapter" data-level="9.2" data-path="9-patterns-and-differences.html"><a href="9-patterns-and-differences.html#differences-in-recursive-partitioning"><i class="fa fa-check"></i><b>9.2</b> 1984: Differences in recursive partitioning</a></li>
<li class="chapter" data-level="9.3" data-path="9-patterns-and-differences.html"><a href="9-patterns-and-differences.html#limiting-differences"><i class="fa fa-check"></i><b>9.3</b> Limiting differences</a></li>
<li class="chapter" data-level="9.4" data-path="9-patterns-and-differences.html"><a href="9-patterns-and-differences.html#the-successful-dispersion-of-the-support-vector-machine"><i class="fa fa-check"></i><b>9.4</b> The successful dispersion of the support vector machine</a></li>
<li class="chapter" data-level="9.5" data-path="9-patterns-and-differences.html"><a href="9-patterns-and-differences.html#differences-blur"><i class="fa fa-check"></i><b>9.5</b> Differences blur?</a></li>
<li class="chapter" data-level="9.6" data-path="9-patterns-and-differences.html"><a href="9-patterns-and-differences.html#bending-the-decision-boundary"><i class="fa fa-check"></i><b>9.6</b> Bending the decision boundary</a></li>
<li class="chapter" data-level="9.7" data-path="9-patterns-and-differences.html"><a href="9-patterns-and-differences.html#instituting-patterns"><i class="fa fa-check"></i><b>9.7</b> Instituting patterns</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html"><i class="fa fa-check"></i><b>10</b> Regularizing and materializing objects}</a><ul>
<li class="chapter" data-level="10.1" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html#genomic-referentiality-and-materiality"><i class="fa fa-check"></i><b>10.1</b> Genomic referentiality and materiality</a></li>
<li class="chapter" data-level="10.2" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html#the-genome-as-threshold-object"><i class="fa fa-check"></i><b>10.2</b> The genome as threshold object</a></li>
<li class="chapter" data-level="10.3" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html#genomic-knowledges-and-their-datasets"><i class="fa fa-check"></i><b>10.3</b> Genomic knowledges and their datasets</a></li>
<li class="chapter" data-level="10.4" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html#the-advent-of-wide-dirty-and-mixed-data"><i class="fa fa-check"></i><b>10.4</b> The advent of ‘wide, dirty and mixed’ data</a></li>
<li class="chapter" data-level="10.5" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html#cross-validating-machine-learning-in-genomics"><i class="fa fa-check"></i><b>10.5</b> Cross-validating machine learning in genomics</a></li>
<li class="chapter" data-level="10.6" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html#proliferation-of-discoveries"><i class="fa fa-check"></i><b>10.6</b> Proliferation of discoveries</a></li>
<li class="chapter" data-level="10.7" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html#variations-in-the-object-or-in-the-machine-learner"><i class="fa fa-check"></i><b>10.7</b> Variations in the object or in the machine learner?</a></li>
<li class="chapter" data-level="10.8" data-path="10-regularizing-and-materializing-objects.html"><a href="10-regularizing-and-materializing-objects.html#whole-genome-functions"><i class="fa fa-check"></i><b>10.8</b> Whole genome functions</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html"><i class="fa fa-check"></i><b>11</b> Propagating subject positions}</a><ul>
<li class="chapter" data-level="11.1" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#propagation-across-human-machine-boundaries"><i class="fa fa-check"></i><b>11.1</b> Propagation across human-machine boundaries</a></li>
<li class="chapter" data-level="11.2" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#competitive-positioning"><i class="fa fa-check"></i><b>11.2</b> Competitive positioning</a></li>
<li class="chapter" data-level="11.3" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#a-privileged-machine-and-its-diagrammatic-forms"><i class="fa fa-check"></i><b>11.3</b> A privileged machine and its diagrammatic forms</a></li>
<li class="chapter" data-level="11.4" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#varying-subject-positions-in-code"><i class="fa fa-check"></i><b>11.4</b> Varying subject positions in code</a></li>
<li class="chapter" data-level="11.5" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#the-subjects-of-a-hidden-operation"><i class="fa fa-check"></i><b>11.5</b> The subjects of a hidden operation</a></li>
<li class="chapter" data-level="11.6" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#algorithms-that-propagate-errors"><i class="fa fa-check"></i><b>11.6</b> Algorithms that propagate errors</a></li>
<li class="chapter" data-level="11.7" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#competitions-as-examination"><i class="fa fa-check"></i><b>11.7</b> Competitions as examination</a></li>
<li class="chapter" data-level="11.8" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#superimposing-power-and-knowledge"><i class="fa fa-check"></i><b>11.8</b> Superimposing power and knowledge</a></li>
<li class="chapter" data-level="11.9" data-path="11-propagating-subject-positions.html"><a href="11-propagating-subject-positions.html#ranked-subject-positions"><i class="fa fa-check"></i><b>11.9</b> Ranked subject positions</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-conclusion-out-of-the-data.html"><a href="12-conclusion-out-of-the-data.html"><i class="fa fa-check"></i><b>12</b> Conclusion: Out of the Data}</a><ul>
<li class="chapter" data-level="12.1" data-path="12-conclusion-out-of-the-data.html"><a href="12-conclusion-out-of-the-data.html#machine-learners"><i class="fa fa-check"></i><b>12.1</b> 250,000 machine learners</a></li>
<li class="chapter" data-level="12.2" data-path="12-conclusion-out-of-the-data.html"><a href="12-conclusion-out-of-the-data.html#a-summary-of-the-argument"><i class="fa fa-check"></i><b>12.2</b> A summary of the argument</a></li>
<li class="chapter" data-level="12.3" data-path="12-conclusion-out-of-the-data.html"><a href="12-conclusion-out-of-the-data.html#in-situ-hybridization"><i class="fa fa-check"></i><b>12.3</b> In-situ hybridization</a></li>
<li class="chapter" data-level="12.4" data-path="12-conclusion-out-of-the-data.html"><a href="12-conclusion-out-of-the-data.html#critical-operational-practice"><i class="fa fa-check"></i><b>12.4</b> Critical operational practice?</a></li>
<li class="chapter" data-level="12.5" data-path="12-conclusion-out-of-the-data.html"><a href="12-conclusion-out-of-the-data.html#obstacles-to-the-work-of-freeing-machine-learning"><i class="fa fa-check"></i><b>12.5</b> Obstacles to the work of freeing machine learning</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning: Archaeology of a Data Practice</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regularizing-and-materializing-objects" class="section level1">
<h1><span class="header-section-number">10</span> Regularizing and materializing objects}</h1>
<p></p>
<blockquote>
<p>Science is concentrated in an area of knowledge it does not absorb and in a formation which is in itself the object of knowledge and not of science.<span class="citation">[@Deleuze_1988, 19]</span> </p>
</blockquote>
<p>What is the materiality of machine learning?  The opening pages of <em>Elements of Statistical Learning</em> present four somewhat excessive objects – spam email, handwritten digits, prostate cancer, and ‘DNA Expression Microarrays’ – and list six examples (document classification, image recognition, risk of heart attack, stock price prediction, risk factors for prostate cancer, and glucose estimates for diabetics) <span class="citation">[@Hastie_2009, 1-7]</span>. What happens to things like prostate cancer, handwritten digits or stock prices when machine learners ply them? Although machine learning occurs in the thick of a control crisis <span class="citation">[@Beniger_1986]</span> (as suggested in chapter ), I will suggest here machine learning also occasions viscous multi-temporal and inter-objectively distributed enactments of things such as financial markets, media platforms, chronic diseases and living things. These are all hyperobjects  that epistemically, infrastructurally, economically and socially individuate through machine learning.</p>
<p>The last of the vignettes, the DNA microarray, comes from the life sciences. It attracts a whole page colour figure – a heatmap.<span class="citation">[@Hastie_2009, 7]</span><a href="#fn77" class="footnoteRef" id="fnref77"><sup>77</sup></a> .  DNA, genes, genomics and proteomics then more or less disappear from view for the next 503 hundred pages of the book (aside from a brief mention in the context of cross-validation), only to abruptly reappear in a discussion of unsupervised machine learning techniques (k-means, agglomerative and hierarchical clustering; Chapter 14, where the DNA microarray data is re-analysed using hierarchical clustering), and then again, and much more extensively, in a final chapter (Chapter 18) new to the second edition of the book on ‘High Dimensional Problems.’ Apart from one passage where the Hastie and co-authors develop a document classifier for their own journal articles, every example in the added Chapter 18 comes from genomic science, a scientific field that largely begins to take a recognisable shape in the late 1990s as both sequence data and high-throughput DNA-analysis devices, particularly microarrays, become widely available. </p>
<p>Operational formations usually encompass scientific fields. Alongside the operational problems of spam email filtering, image or handwriting recognition, scientific research into biological processes constitutes a major reference point and, I will suggest, an axis of materialisation for machine learning. In the archaeology of its operational formation, we could say that the scientific domain of genomics has a strongly referential effect on machine learning. What is a ? For Foucault, a referential ‘forms the place, the condition, the field of emergence, the authority to differentiate between individuals or objects, states of things and relations that are brought into play by the statement itself; it defines the possibilities of appearance and delimitation of that which gives meaning to the sentence, a value as truth to the proposition’ <span class="citation">[@Foucault_1992, 91]</span>.  For Foucault, a referential forms an integral part of the enunciative function, the mapping of sites, subject positions, enunciative modalities, forms of accumulation and differentiation at work in the production of statements. </p>
<p>Why does the referential of machine learning matter? When hyperobjects are machine learned, they are re-constituted (in vector space, as optimisation problems, as probability distributions and patterns of difference). Conversely, as I will suggest in this chapter, they become a site of materialization, cross-validation and regularization for machine learning in its production of knowledge. But that referential status, which authorises and imbues statements with value, comes at a cost. The plurality or multiplicity of the hyperobject – genomes, stock prices, etc. – will be regularized and ranked, re-used and transcribed by machine learners over and over to lend coherence to the operational formation and its system of statements.</p>
<div id="genomic-referentiality-and-materiality" class="section level2">
<h2><span class="header-section-number">10.1</span> Genomic referentiality and materiality</h2>
<blockquote>
<p><code>gaagctccac accagccatt acaaccctgc caatctcaag cacctgcctc tacaggtacc</code> <span class="citation">[@NCBI_2016]</span></p>
</blockquote>
<p>By contrast with industry, commerce, media and government, where much that happens is obscured from view, the great virtue or genomic science is the relative openness of its workings and its resolute insistence on DNA as the primary form of data. The fact that data practices are relatively generic and accessible means that critical research into transformations associated with genomic data and knowledge can accompany nearly every aspect of practice. </p>
<p>Genomic data exhibits some specific features. The first concerns what I earlier called data strain.  Genome data, a tiny fragment of which is shown above, inflates the vector space. Genomics generates new versions of the now familiar problems of data dimensionality. The abundance, diffusion, heterogeneity or impaction of genomic data thwarts its examination, tabulation, and regulated circulation. Genomics data also presents unusual ratios of accumulation and sparsity. Clinical genomics in particular generates datasets that are lavishly furnished with ‘features’ but often quite meagrely supplied with clinical cases or ‘observations’. In the shorthand typical of machine learning terminology, <span class="math inline">\(p\)</span> is larger than <span class="math inline">\(N\)</span>: ‘the number of features <span class="math inline">\(p\)</span> is much larger than the number of observations <span class="math inline">\(N\)</span>, often written <span class="math inline">\(p\gg N\)</span>’ <span class="citation">[@Hastie_2009, 649]</span>. This strains statistical methods that rely on the <span class="math inline">\(\forall{\boldsymbol{X}}\)</span> ‘Law of Large Numbers’ <span class="citation">[@Hacking_1990, 99-104]</span>, which holds that the accuracy of statistics tends to increase with more observations. </p>
<p>Since the early nineteenth century, biology and cognate disciplines have sought to explore problems of time, genesis, duration, activity and process in a very broad spectrum of living things. Contemporary genomics seeks to elicit, as many commentators have noted, knowledge of biological, evolutionary, biomedical and environmental processes from the long DNA sequences comprising genomes. The primary ‘object’ in genomics is a <span class="math inline">\(\forall{\boldsymbol{X}}\)</span> data form, the genome, the full complement of DNA in an organism. Genomes vary in size from the 2000 DNA base pairs of a virus, the 3.2 Gb (gigabase pairs) of humans through to the 130 Gb of the lung fish. The founding premise of genomic science is that a dataset comprising the complete sequence of DNA potentially re-bases knowledge of many different biological processes, ranging from evolution (phylogeny), development (ontogeny), metabolism, structure and pathology.  If nothing else, genome comparison promises knowledge of the 3.8 billion years of evolution of species differences and population diversity.  In all of these respects, DNA sequences have since at least the 1980s served as the common substrate for many different scientific experiments, technical developments, cyber-infrastructures and needless to say, biological imaginaries oriented around the problems of control.<a href="#fn78" class="footnoteRef" id="fnref78"><sup>78</sup></a></p>
<p>The genomic premise has an ineluctably promissory association with knowledge economy.  Prior to the whole genome sequencing projects initiated in the 1990s, biologists had never worked with genomes only with selected DNA sequences, especially those associated with genes and the proteins that they code. By contrast, the genome, with all its repeated, redundant, and slightly varying patterns of DNA, bears the traces of long evolutionary mixing and constitutes a hyper-complex functional process whose exquisite sensitivity to changing conditions – a slight change in light reaching a leaf cascades can be traced in patterns of DNA transcription – forms an extreme case for any operational sense of function. The functioning of genomes symbolises a deeply interconnected relationality in life sciences, and becomes the test case for the learning capacities of machine learners.<a href="#fn79" class="footnoteRef" id="fnref79"><sup>79</sup></a> </p>
<p>As referentials, genomes pose a problem of unregulated abundance and seeming homogeneity. DNA sequences exist in great abundance (in databases, and increasingly, from the cheaper and more compact sequencing instruments), yet even determining how DNA sequence fragments should be ordered in a genome – let alone how they make sense as some biological function – is much harder. DNA sequences are assembled as genomes and genomic datasets via statistical models.   ‘Genome assembly continues to be one of the central problems of bioinformatics’ write the authors of a recent scientific review of the techniques of constructing whole genomes from DNA sequencer data <span class="citation">[@Henson_2012]</span>. Even the elementary data form of the genome as DNA base pairs is a highly algorithmic construct. No existing sequencing technology produces a genome as a single sequence, as a vector (in the sense described in chapter ). Instead, sequencing produces random sets of sequence fragments of various lengths that have to be assembled into a complete genome algorithmically. <a href="#fn80" class="footnoteRef" id="fnref80"><sup>80</sup></a></p>
<p>Between pre-genomic and post-genomic science, the status of significant differences in genomes shifted.  Pre-HGP biology understood the significant differences between individual organisms largely in terms of gene alleles responsible for variations in phenotypes. Biological differences, and disease in particular, stemmed from different forms of genes. Understanding disease meant finding the disease genes. Even prominent proponents of genomics, such as Leroy Hood, writing of ‘Biology and Medicine in the Twenty-First Century’ in 1991, envisaged genomics as a way of simplifying ‘the task of finding disease genes’ <span class="citation">[@Hood_1992,138]</span>. Across the life sciences, genes were the object of much way of annotation, labelling and description. Two decades after the inception of whole genome sequencing, genomes present a different image of variation. According to Nikolas Rose, writing more recently, ‘there is no normal human genome; variation is the norm’ <span class="citation">[@Rose_2009, 75]</span>.   ‘In this new configuration’, he writes, ‘what is required is not a binary judgment of normality and pathology, but a constant modulation of the relations between biology and forms of life, in the light of genomic knowledge.’ The emphasis in Rose’ formulation falls on ‘constant modulation’ of the relations between biology and forms of life. If post-genomic science departs from the understanding that there is no single genome but many genomes, then according to Rose, variation itself becomes of primary interest. Pursuit of variation remakes the genome into ‘a form whose only object is the inseparability of distinct variations’ <span class="citation">[@Deleuze_1994, 21]</span>. </p>
<p>Whatever knowledge subsequently derives from a genome (genes, mutations, evolutionary relationships, variations associated with disease, heredity or individual identity), genomic data and hence the genome itself as a scientific hyperobject  is deeply probabilistic. From assembly onwards, through the ancestral probabilisation embodied in heavily-used biological databases, the indelible errors, the entangled reliances on accumulated biological knowledges make genomes a particularly challenging site of machine learning activity.</p>
<p><em>Elements of Statistical Learning</em>’s invocation of DNA-related data, therefore, is no arbitrarily chosen example amidst the general proliferation of settings, domains, cases and examples typically found in machine learning pedagogy. In multiple dimensions and directions, genomics – the scientific project of operating on the whole DNA complement of organisms – is a tightly coupled referential for machine learning even if relatively few machine learners have, to date, managed to work with whole genome sequence data. The relatively long-established referential entanglement (at least 25 years, and perhaps more) of genomics and machine learning is strategically important in the generalization of machine learning, in the processes whereby techniques, with their specific forms of articulation, statement and making-visible, propagate into multiple, once-disparate settings.<a href="#fn81" class="footnoteRef" id="fnref81"><sup>81</sup></a>  Like social media platforms or retail spaces with their many visitors, genomes, I would suggest, provoke a multiplicity of machine learners to bind to them like antibodies to an antigen (or an allergen). Genomes function as regularizing hyperobjects for machine learning. </p>
</div>
<div id="the-genome-as-threshold-object" class="section level2">
<h2><span class="header-section-number">10.2</span> The genome as threshold object</h2>

<p>During 1990-2015, biology, and particularly molecular and then genomic biology, has a very high visibility in the machine learning research literature. (See table .) After the leading machine learning disciplines (computer science, electronic engineering and statistics), molecular biology, genomics and bioinformatics attract most academic journal citations and publications associated with machine learning. Half of the most cited research literature has a biomedical or life science referentiality. This may be because genomes and human disease in particular, are premiere scientific hyperobjects like the human brain, dark matter, global climate or fundamental particles in contemporary sciences.   But it might also be the case – and I will pursue this line of argument here – that genomes, with all their operational and functional complexity, come into play, are potentialized and regulated, and take on promissory epistemic value as zones of collective individuation through machine learning. In terms of contemporary biological knowledge production, the transformation of biology into a data-intensive science <span class="citation">[@Hey_2009; @McNally_2012]</span> is tightly entangled with machine learning in processes of cross-validation. </p>
<p>In the generalization of machine learning, the genomic referential marks a threshold of materialization.   The archaeological approach to materiality is somewhat unusual. Given his interest in the formation of statements, Foucault understands materiality as a regulatory process operating in an enunciative function. Foucault writes:</p>
<blockquote>
<p>The rule of materiality that statements necessarily obey is therefore of the order of the institution rather than of the spatio-temporal localization; it defines possibilities of reinscription and transcription (but also thresholds and limits) , rather than limited and perishable individualities <span class="citation">[@Foucault_1972, 103]</span> </p>
</blockquote>
<p>In the archaeology of an operational formation, locating specific practices, places and times of reinscription, transcription, and possibilities of reuse carries more weight more than any direct conceptual account of materiality.  What would materiality in this sense mean for machine learning?</p>
<p>Genomes are both a challenge to the capacity of machine learning to produce scientific knowledge  (as distinct from say the unstable commercial knowledge of a credit risk model), and a cross-validation of machine learning as a life-death relevant knowledge practice. Genomes first of all authorize infrastructural vectorizations such as computational clusters, grids, arrays and clouds.  For instance, the Google Compute Engine, a globally addressable ensemble of computers typical of recent distributed commercial computing architectures, was briefly turned over to exploration of cancer genomics during 2012, and publicly demonstrated at the annual Google I/O conference.  Midway through the demonstration, in which a human genome is visualized as a ring in ‘Circos’ form (see figure  <span class="citation">[@Krzywinski_2009]</span>), the speaker, Urs Hölzle, Senior Vice President of Infrastructure at Google ‘then went even further and scaled the application to run on 600,000 cores across Google’s global data centers’ <span class="citation">[@GoogleInc.2012]</span>.  The audience clapped as the annular diagram of a human genome was decorated with a rapidly increasing number of cross-links, accompanied by a snapping sound as it appeared. The world’s ‘3rd largest supercomputer’, as it was called by <em>TechCrunch</em>, a prominent technology blog, ‘learns associations between genomic features’ <span class="citation">[@Anthony_2012]</span>. Note the language of machine learning: it ‘learns … associations between features.’ We are in the midst of many such demonstrations of ‘scaling applications’ of data in the pursuit of associations between ‘features.’<a href="#fn82" class="footnoteRef" id="fnref82"><sup>82</sup></a></p>

<p></p>
<p>The I/O conference audience, largely comprising software developers, could hardly be expected to have a detailed interest in cancer genomics. Their interest was steered toward the immediate availability of computing power: from 10,000 to 600,000 cores in a few seconds.  Such drastic infrastructural re-scaling attests to the provocation of the genomic referential. The Google Compute demonstration is, I would suggest, typical of how genomes, genes, proteins and biological sciences more generally, authorize differentiation of individuals, events and things through machine learning. This differentiation is only hinted at in the Google I/O keynote address in Hölzle’s talk of genomic features, gene expression and patient attributes.</p>
<p>The only concrete indication of how what was happening in the demonstration related to machine learning was one mention of the <code>RF-ACE</code> (Random Forest- Artificial Contrasts with Ensembles) algorithm. Google’s press release emphasises the distribution of learning across an infrastructure:</p>
<blockquote>
<p>The primary computation that Google Compute Engine cluster performs is the <code>RF-ACE</code> code, a sophisticated machine learning algorithm which learns associations between genomic features, using an input matrix provided by ISB (Institute for Systems Biology). When running on the 10,000 cores on Google Compute Engine, a single set of association can be computed in seconds rather than ten minutes, the time it takes when running on ISB’s own cluster of nearly 1000 cores. The entire computation can be completed in an hour, as opposed to 15 hours <span class="citation">[@GoogleInc.2012]</span>.</p>
</blockquote>
<p>Google re-purposes an algorithm developed by engineers at Intel Corporation and Amazon,  and draws on genomic datasets provided by the Institute of Systems Biology, Seattle, a doyen of big-data genomics. The demonstration animates the <code>RF-ACE</code> (a further development of Breiman’s random forests discussed in chapter ) by re-drawing a diagram of the genome, and re-draws it increasingly rapidly as the demonstration scales up to 10,000 cores (or CPUs).  A diagram that normally appears statically on-screen or on the printed page of a scientific publication is now animated by an algorithmic process. This confluence of commerce (Amazon), industry (Intel), media (Google) and genomic science (ISB) exemplifies the re-inscriptive or transcriptive materiality of machine learning. </p>
</div>
<div id="genomic-knowledges-and-their-datasets" class="section level2">
<h2><span class="header-section-number">10.3</span> Genomic knowledges and their datasets</h2>
<p>In the infrastructural materiality of these demonstrations and examples, whether they come from <em>Elements of Statistical Learning</em> or from Google Compute Engine, the object of knowledge – genomes, genes, proteins – does not figure in terms of its original discipline or scientific field (typically cancer biology). The scaled-up demonstration of <code>RF-ACE</code> on Google Compute assembles only a general system of references between cancer patients, vectorised infrastructures and predictive classifications. Similarly, the treatment of DNA microarray data in the slightly earlier examples found in <em>Elements of Statistical Learning</em> does not principally concern cancer biology as such, but much more the way a group of elements are assembled so as to permit the production of propositions that cross the threshold of scientificity. They may just as well cross different thresholds of knowledge in governmental, market-focused, organisational or managerial operations.<a href="#fn83" class="footnoteRef" id="fnref83"><sup>83</sup></a></p>
<p>The plurality of applications can sometimes make it seem that machine learning arrives at the borders of different domains, and then proceeds to colonise local knowledges practices. The rule of materiality here would seem to be an epistemic <em>terra nullius</em> appropriation, in which existing knowledge forms are rapidly extinguished by machine learners. We have seen previously that ancestral communities of probabilisation orient the generalization of machine learning (see chapter ).  Research literature published on machine learning since the early 1990s clusters around problems of plethoric excess – image recognition, document classification, market behaviour (as in, working out what advertisement to show, or whether someone is likely to a buy a particular product, etc.). These problems position machine learning amidst regimes of communication, the production of economic value, and the regularities of statements (or put in more Foucaultean terms, amidst life, labour and language; see <span class="citation">[@Foucault_1992]</span>). Where, amidst these major regularities, does genomics (arguably the successor of molecular biology) fit? Almost all of the major machine learners, albeit supervised or unsupervised, discriminative or generative, parametric or non-parametric, substantial research activity during the last two or so decades cross-validate their statements with genomics. </p>
</div>
<div id="the-advent-of-wide-dirty-and-mixed-data" class="section level2">
<h2><span class="header-section-number">10.4</span> The advent of ‘wide, dirty and mixed’ data</h2>
<p>We can see this referential cross-validation at work in the shape of genomic data. The DNA microarray data extensively modelled in the final chapter of <em>Elements of Statistical Learning</em> highlights some elementary problems of shape associated with genomic data. The <code>iris</code> dataset <span class="citation">[@Fisher_1936]</span>, perhaps the most heavily used pedagogical dataset in the literature, does not provoke the infrastructural contortions associated with Google Compute, or for that matter, the highly sophisticated and quite subtle treatment of gene expression we find in genomics-related machine learning.</p>

<p>It is usual, in working with <code>iris,</code> to construct machine learners that use the variables from the first four columns shown in table  to infer the value of the <code>Species</code> response variable (as seen in Chapter 5, where a decision tree was constructed using this same dataset). The measurements of petals and sepals of the irises of the Gaspé Peninsula in Novia Scotia, and their classification into different species is perhaps a typical mid-twentieth century biological procedure. Even in the excerpt shown in Table , we can see that it is quite narrow as it has only a few columns, the data is nearly all of one type (measurements of lengths and widths), and the data is clean (there are no missing values). <code>Iris</code> is typical of classic statistics and much biological data prior to genomics in its relatively homogeneity and distinct partitioning. </p>
<p>If <code>iris</code> is the conventional statistical form, how does a genomic dataset differ? One clue comes from descriptions of the <code>RF-ACE</code> algorithm, first published in 2009. RF_ACE is attempts to deal with ‘modern data sets’ that are ‘wide, dirty, mixed with both numerical and categorical predictors, and may contain interactive effects that require complex models’ <span class="citation">[@Tuv_2009, 1341]</span>. Such algorithms and the ‘wide, dirty, mixed’ datasets they work on have an irregular texture, which, I would suggest, we should try to grasp if we want to understand how genomic data constitutes a complex volume ‘in which heterogeneous regions are superposed’ <span class="citation">[@Foucault_1972, 128]</span>. Clues to the irregularity of genomic data come from the various treatments of DNA microarray data in <em>Elements of Statistical Learning</em>. </p>
<p>Hastie and co-authors introduce one microarray dataset they use in this way:</p>
<blockquote>
<p>The data in our next example form a matrix of 2308 genes (columns) and 63 samples (rows), from a set of microarray experiments. Each expression value is a log-ratio log(R/G). R is the amount of gene-specific RNA in the target sample that hybridizes to a particular (gene-specific) spot on the microarray, and G is the corresponding amount of RNA from a reference sample. The samples arose from small, round blue-cell tumors (SRBCT) found in children, and are classified into four major types: BL (Burkitt lymphoma), EWS (Ewing’s sarcoma), NB (neuroblastoma), and RMS (rhabdomyosarcoma). There is an additional test data set of 20 observations. We will not go into the scientific background here <span class="citation">[@Hastie_2009, 651]</span></p>
</blockquote>
<p>Note that while the number of samples (~80) in the small round blue-cell tumors (<code>SRBT</code>) <span class="citation">[@Khan_2001]</span> dataset is less than the number of flowers measured in <code>iris,</code> the number of variables presented by the columns in the table (2308) is much greater.  Hastie and co-authors, like the Google I/O demonstration, do not ‘go into the scientific background.’ Scientific knowledge <em>per se</em> is not the central concern in machine learning. Rather, genomic data as a field or emergence and differentiation in the production of statements matters. The original publication of this dataset in 2001 <span class="citation">[@Khan_2001]</span> also made use of machine learning techniques (neural networks, a major topic in the next chapter ), precisely in order to address the diagnostic problem of distinguishing different tumors types without resort to new experiments or biological knowledge.<a href="#fn84" class="footnoteRef" id="fnref84"><sup>84</sup></a></p>

<p>The sample of the <code>SRBCT</code> data shown in table  does not readily accommodate the width of the dataset. Unlike <code>iris</code>, the thousands of variables simply cannot be displayed on a page or screen. <em>Wide</em> datasets are quite common in machine learning settings generally, but particularly common in genomics where in a given study there might only be a relatively small number of biological samples but a huge amount of sequencer or microarray data for each sample. Much genomic data shares this generic feature of width.<a href="#fn85" class="footnoteRef" id="fnref85"><sup>85</sup></a></p>

<p>In contrast to the direct measurements of petals and sepals in the <code>iris</code> data, the <code>SRBCT</code> data incorporates and diagonally connects many levels of practice.  The columns in table  refer to genes whose levels of expression in different samples are measured and then grouped by comparison to their levels in a reference sample (see the hierarchical clustering  of the data shown in figure .) Even the identification of the several thousand genes whose levels of expression are measured by the microarray experiments presupposes much preceding work on DNA sequences and the identification of protein-coding DNA regions amidst the highly repetitive vector of the genome sequence. Highly leveraged infrastructures for access to biological data underpin such datasets. Considered more diagrammatically, genomes in many ways becomes less linear or flat than the bare base DNA sequences might suggest.</p>
</div>
<div id="cross-validating-machine-learning-in-genomics" class="section level2">
<h2><span class="header-section-number">10.5</span> Cross-validating machine learning in genomics</h2>
<p>The linear sequences of DNA data mix and diffuse partly through the archival accumulation that allows them to be superimposed, annotated and layered, but also through the many efforts to traverse their expanded volume using classifiers and predictive models. A recent review in the journal <em>Genomics</em> highlights the increasing bearing of machine learning techniques on genomic science:</p>
<blockquote>
<p>High-throughput genomic technologies, including gene expression microarray, single Nucleotideide polymorphism (SNP) array, microRNA array, RNA-seq, ChIP-seq, and whole genome sequencing, are powerful tools that have dramatically changed the landscape of biological research. At the same time, large-scale genomic data present significant challenges for statistical and bioinformatic data analysis as the high dimensionality of genomic features makes the classical regression framework no longer feasible. As well, the highly correlated structure of genomic data violates the independent assumption required by standard statistical models<span class="citation">[@Chen_2012, 323]</span>.  </p>
</blockquote>
<p>Commentary on the ‘highly correlated structure,’ not just the volume, of genomic data, points to another referential operation concerning the differentiation of things.  Many such statements highlight the incompatibility between a surging multiplicity of data forms and the constraints of existing statistical modelling techniques (‘standard statistical models’). So for instance, Chen and co-authors recommend the use of the random forest (RF) because it:</p>
<blockquote>
<p>is highly data adaptive, applies to “large p, small n” problems, and is able to account for correlation as well as interactions among features. This makes RF particularly appealing for high-dimensional genomic data analysis, … including prediction and classification, variable selection, pathway analysis, genetic association and epistasis detection, and unsupervised learning <span class="citation">[@Chen_2012, 323]</span> </p>
</blockquote>
<p>Familiar machine learning vectorisation keywords such as ‘large p, small n’ and ‘high dimensional’ pepper their recommendations. But the key terms on the genomics side of this formulation would perhaps be ‘pathway analysis’, ‘genetic association,’ and ‘epistasis.’ Such biological terms point to forms of relationality associated with biologically interesting processes. Epistasis for instance broadly refers to linked gene action, a process that has been difficult to study before high-throughput methods of functional genomics brought shifting patterns of gene expression to light.  In contemporary genomic science, these biological processes are increasingly understood in terms of eliciting and modelling the relations between <em>features</em> of genomic datasets in order to classify and predict biological outcomes.</p>
<p>How does machine learning differ from the statistical practice that has underpinned much of modern biology? The analysis of <code>SRBCT</code> gene expression in <em>Elements of Statistical Learning</em> is symptomatic of a mutual articulation, a cross-validation that entangles genomics and machine learning.  The overt arrival of machine learning techniques in genomic research was initially largely concerned with the problem of variations in gene expression ( and in fact, nearly all of the analysis of genomic data in <em>Elements of Statistical Learning</em> explicitly deals with various cases of gene expression).  On the one hand, the genomics data promises legibility of all the genes in a given organism (~20,000 for humans). On the hand, the pattern of activity of these genes in time, or any particular point in the life of an organism, cannot be read from the genome but only in time-varying expression, the changes in state and the variations in closely similar genomes. </p>
<p>Compared to the refined algorithmic craft of whole genome assembly <span class="citation">[@Venter_2001; @Myers_2000; @Pevzner_2001]</span>, the handling of the problem of gene expression in machine learning settings can seem rather crudely lacking in biological specificity. Hastie and co-authors almost deprecate scientific knowledge: ‘we will not go into the scientific background here.’ Like the authors of the original scientific study <span class="citation">[@Khan_2001]</span>, <em>Elements of Statistical Learning</em> treats gene expression profiling largely as a problem of learning to classify differences in disease or other health-related conditions. The many gene expression studies seek to discriminate between different conditions, diseases, or pathologies on the basis of differing levels of gene expression. For machine learners, each gene is a variable whose levels of expression in a given sample may help identify what type that sample belongs to. In the case of the <code>SRBCT</code> data, the types include lymphomas, sarcomas and neuroblastomas.</p>
<p>Like Chen, <em>Elements of Statistical Learning</em> begins by addressing the problem of the shape of the data. ‘Since <span class="math inline">\(p\gg N\)</span>’ write Hastie and co-authors, ‘we cannot fit a full linear discriminant analysis (LDA) to the data; some sort of regularization is needed’ <span class="citation">[@Hastie_2009, 651]</span>.   What is this ? Like the re-distribution of classification into a randomised population of machine learners (see chapter , regularization governs an potentially unruly plurality through a form of training and observation. Michel Foucault describes the advent of disciplinary power partly in terms of enclosure or individualizing observation, but also in terms of techniques of supervising, examining and above all, <em>regularizing</em> conduct. He writes:</p>
<blockquote>
<p>Shift the object and change the scale. Define new tactics in order to reach a target that is now more subtle but also more widely spread in the social body. Find new techniques for adjusting punishment to it and for adapting its effects. Lay down new principles for regularizing, refining, universalizing the art of punishing <span class="citation">[@Foucault_1977, 89]</span> </p>
</blockquote>
<p>Foucault’s description of regularization as a technique of disciplinary power – the formation that emerged in the late 18th century as a way of ordering ‘massive or transient pluralities’ (143) in Western European societies – seems a long way from microarray gene expression data.   Yet the data in genomic and other referentials (transactions, social media, etc.) displays some of the traits – massiveness, transience, plurality – that Foucault identifies as key targets of regulation for the operations of disciplinary power focused on the social body or populations.  The ‘target,’ a term often used in machine learning to describe the type, group or response being modelled, in genomics is often subtle variations (in gene expression, in phylogeny, in pathogenesis), and these variations are widely dispersed in genomic sequence data and in the populations it stems from.  Foucault’s account of supervision (<em>surveiller</em>) and penalisation as disciplinary techniques responding to ‘popular illegality’ <span class="citation">[@Foucault_1977, 130]</span> dwells on the capillary network of observations, examining, ranking, test and gradation that adapt to the surging multiplicities by ordering them in tables. While the tables of data (see Table  in the microarray gene expression datasets suggest the persistence of the same technique of ordering multiplicities through partitioned observations, the <em>cells</em> no longer target contain individuals under observation but focus on the attributes of a multiplicity in movement, the human genome for instance in its many functional states. </p>
<p>‘Shift the object and change the scale,’ Foucault writes, in describing how partitions, segmentations, forms of enclosure, and above all, ranked classifications target a more subtly distributed nexus of relations in disciplinary power. Often understood in terms of enclosure and surveillance, disciplinary power, according to Foucault, operates through ranking: ‘discipline is an art of rank, a technique for the transformation of arrangements’ <span class="citation">[@Foucault_1977, 145]</span>.  ‘Regularize in a way that automatically drops out features that are not contributing to the class predictions,’ Hastie and co-authors write <span class="citation">[@Hastie_2009, 652]</span> in describing how regularization deals with the problem of too many variables in the microarray datasets. In the many different techniques that <em>Elements of Statistical Learning</em> brings to bear on the problem of gene expression – diagonal linear discriminant analysis, nearest shrunken centroids, linear classifiers with quadratic regularization, regularized discriminant analysis, regularized multinomial logistic regression, support vector classifier – essentially the same ordering movement occurs. Regularization re-scales the excessive potential relations of the hyperobject – the patterns of expression of genes associated with different types of tumours – by shrinking or dropping the weights of parameters of each gene in the model and examining the effect on the predictions that result. The coefficients or weights of parameters in the model, the <span class="math inline">\(\beta_p\)</span> values, are ranked by importance, and then either reduced (<span class="math inline">\(L_2\)</span> regularization) or eliminated (<span class="math inline">\(L_1\)</span> regularization) if they contribute little to the predictive accuracy of the machine learner. Learning here takes the form of regularization.  </p>
<p>A technique called ‘lasso regression’ displays features that might help us grasp how machine learners regularize genomic data.  Remember that the linear regression model with its diagonal line or plane running through vector space provides the underlying intuition for many machine learners. We have seen the function in Equation  several times already in different variations, including logistic regression used for classification of types or groupings.</p>

<p>In gene expression models, the values of <span class="math inline">\(\beta\)</span> shown in equation  map on to the different levels of expression of the many genes indexed by the <span class="math inline">\(p\)</span> columns of the microarray dataset. The model tests how different patterns of gene expression associate with different tumour types. As we have already seen, the number of combinations of genes associated with different tumour types vastly outweighs the number of samples.</p>
<p>The regularized version of the linear regression framework known as ‘lasso’ – Least Absolute Shrinkage and Selection Operator – introduces a different form of training and observation of model construction. This train hinges on the lasso penalty shown in equation <a href="#fn86" class="footnoteRef" id="fnref86"><sup>86</sup></a> </p>

<blockquote>
<blockquote>
<p><span class="citation">[@Hastie_2009, 68]</span></p>
</blockquote>
</blockquote>
<p>Equation  is notable for the way that it subjects the familiar ‘residual sum of squares’ way of calculating the coefficients to the ‘penalty’ carried by the last part of the equation <span class="math inline">\(\sum\limits_i^p\vert\beta_j\vert\)</span>.  As Hastie and co-authors write, ‘the lasso does a kind of continuous subset [feature] selection’ <span class="citation">[@Hastie_2009, 69]</span>. As always <span class="math inline">\(argmin_\beta\)</span> suggests that the algorithm should optimise the set of values for <span class="math inline">\(\beta\)</span> that minimize the overall value of the function. It balances the costs of reducing the sum of residual errors shown in the first half of the equation, and minimizing the sum of the absolute values of the model parameters <span class="math inline">\(\beta_j\)</span> in the second part of the function. The optimizing double movement re-shapes its expression of the data along a diagonal line drawn as the algorithm gradually introduces and scales all of the features in the vector space <span class="math inline">\(\mathbf{X}\)</span>, only allowing those variables or features to remain in the set that help minimize the difference between the predicted response and the actual response.  (Figure  makes something of this scaling diagrammatically visible. In this diagram, the various diagonal lines show how values of coefficients grow and sometimes diminish as the <code>lasso</code> process runs. Vertical lines show steps as new variables are included in the model with different values of the control parameter <span class="math inline">\(\lambda\)</span>. )</p>

<p>Regularization sometimes radically changes the object. In Figure , these changes become a matter of diagrammatic observation. Comparing eight different methods for analyzing the microarray cancer data from <span class="citation">[@Ramaswamy_2001]</span>, Hastie reports that ‘lasso regression (one versus all)’ selects 1,429 of the 16,063 genes in the dataset. The shifted-rescaled object, a set of 1400 genes, or in the case of the ‘elastic-net penalized multinomial’ model that uses only 384 genes, highlights a drastically reduced subset of the original object. A regularized genome of 384 genes suggest a much more targeted set of interventions than 16,000.</p>
</div>
<div id="proliferation-of-discoveries" class="section level2">
<h2><span class="header-section-number">10.6</span> Proliferation of discoveries</h2>
<p>Despite all the infrastructural cross-validation and regularization of plural expression, machine learning does not stabilise genomes as data objects. In many ways, it gives rise to further transformations and variations, and new sources of error.<a href="#fn87" class="footnoteRef" id="fnref87"><sup>87</sup></a> If on the one hand, machine learners offer to regularize transient multiplicities (such as gene expression in complex disorders), on the other hand, within genomics itself, machine learning exhibits considerable epistemic instability that itself needs to be regulated. </p>
<p>For instance, the US Food and Drug Administration has since 2003 conducted a study of data analysis techniques for microarray data:</p>
<blockquote>
<p>The US Food and Drug Administration MicroArray Quality Control (MAQC) project is a community-wide effort to analyze the technical performance and practical use of emerging biomarker technologies (such as DNA microarrays, genome-wide association studies and next generation sequencing) for clinical application and risk/safety assessment <span class="citation">[@Parry_2010, 292]</span>. </p>
</blockquote>
<p>Phase I of the US Federal Drug Administration-led MAQC addressed many issues of data analysis in the context of the clinical applications of gene expression analysis using microarrays. The primary statistical issue there was minimizing the ‘false discovery rate’ <span class="citation">[@Slikker_2010,S1]</span>, a typical biostatistical problem.  In its second phase known as MAQC-II starting in 2007, however, the focus rested on the construction of predictive models for ‘toxicological and clinical endpoints … and the impact of different methods for analyzing GWAS data’ <span class="citation">[@Slikker_2010, 2]</span>. On both the clinical and GWAS fronts, the 36 participating research teams tried out many predictive classifier models.  </p>
<p> In the shift from MAQC-I to MAQC-II, the problem of variations in the predictions produced by the machine learning models moved to center-stage. The problem of variation arises not because any of the different modelling strategies used in machine learning gene expression datasets are wrong or erroneous, but because every model transforms the ‘feature space’ <span class="citation">[@Parry_2010,292]</span> in a different way (as we saw in chapter  in discussions of different treatments of dimensionality). In the MAQC-II consortium, teams were tasked to build ‘classifiers’ to predict whether a given sample or case belongs to a ‘normal’ or ‘disease’ group. The most popular classifier in the MAQC consortium was the <em>k</em> nearest neighbours model: ‘[a]mong the 19,779 classification models submitted by 36 teams, 9742 were k-nearest neighbor-based (KNN-based) models (that is, 49.3% of the total) <span class="citation">[@Parry_2010, 293]</span>. But, these models varied greatly in their predictions: ’there have been large variations in prediction performance among KNN models submitted by different teams’ (293). Not only the genome itself varies, but the population of machine learners show variations. </p>
<p>What accounts for this variation? First of all, the teams did not build single models. As is the norm in machine learning, they iterated over thousands. In their attempt to normalise the variations of their models, one of the research groups in MAQC-II write that ‘for clinical end points and controls from breast cancer, neuroblastoma and multiple myeloma, we systematically generated 463,320 <em>k-nn</em> [<em>k</em>-nearest neighbour] models by varying feature ranking method, number of features, distance metric, number of neighbors, vote weighting and decision threshold’ <span class="citation">[@Parry_2010,292]</span>. A striking proliferation of models on a population-scale strives to tame the variations of predictive models. The number of predictive models constructed here rivals the number of SNPs typically assayed by the microarrays. It seems as if not only the dimensions of the data have vastly increased, but the population of models. This population exhibits many of the problems of variation, irregularity, transience and plurality found in the genomic referential itself. </p>
</div>
<div id="variations-in-the-object-or-in-the-machine-learner" class="section level2">
<h2><span class="header-section-number">10.7</span> Variations in the object or in the machine learner?</h2>

<p>‘The method of k-nearest neighbors makes very mild structural assumptions: its predictions are often accurate but can be unstable’ write Hastie and co-authors <span class="citation">[@Hastie_2009, 23]</span>. The algorithm, first described by Evelyn Fix and Joseph Hodges working at Berkeley in the early 1950s <span class="citation">[@Fix_1951]</span>, is extremely simple in mathematical terms.<a href="#fn88" class="footnoteRef" id="fnref88"><sup>88</sup></a> Equation  shows almost the entire algorithm: </p>

<p>‘where <span class="math inline">\(N_k(x)\)</span> is the neighbourhood of <span class="math inline">\(x\)</span> defined by the <span class="math inline">\(k\)</span> closest points <span class="math inline">\(x_i\)</span> in the training sample’<span class="citation">[@Hastie_2009, 14]</span>. The algorithm effectively takes the average values of points in the neighbourhood <span class="math inline">\(N_k\)</span>, and uses that value to predict the result (a classification or a prediction) for a given point or instance. As Hastie and co-authors put it, the neighbourhood is just those <span class="math inline">\(k\)</span> points near the case under consideration. The assumption here, as in nearly all machine learners transforming the vector space, is that proximity in vector space implies similarity in class or grouping.  This assumption was formally described in the late 1960s in another highly cited paper <span class="citation">[@Cover_1967]</span> on ‘Nearest Neighbour Pattern Classification.’ Neighbouring points in the vector-space are more similar than those at a distance. As equation  shows, <em>k</em> nearest neighbours seems to have only one parameter, the value <span class="math inline">\(k\)</span>, the number of neighbours that a given model includes in its definition of a ‘neighbourhood.’ In contrast to the linear forms of the models (formulated in equations  or ), equation  seems to require little training, supervision or regularization to work as a classifier. While nearly all of the models discussed in this and earlier chapters work with a smooth functional form of the line or curve as their basic way of transforming vector space, <em>k</em> nearest neighbours generates highly non-linear boundaries wending their way through the data. Because they are not guided by parameters (apart from the value of the hyper-parameter <span class="math inline">\(k\)</span>), these boundaries can be unstable.</p>

<p></p>
<p>Even when data belongs to two classes (e.g. <code>normal</code> vs. <code>not-normal</code>), decision boundaries produced by <em>k</em>-nn can be unstable. The example in figure  shows two models, one for <span class="math inline">\(k=5\)</span> and the other for <span class="math inline">\(k=2\)</span>. Each model examines the relations between 2, 5 points in deciding whether a particular case belongs to one class or another. While <em>k-nn</em> constructs local clusters and traces out an irregular decision boundary, this classificatory power comes at the cost of instability. (This is another version of the bias-variance decomposition of machine learner errors discussed in chapter .)</p>
<p>More data, or wider data exacerbates the instability. As dimensions or features in the dataset increase, the local neighbourhood needed to capture a fraction of the volume of the data expands. It becomes more likely that most sample points will lie close to the boundary of the sample space, where they will be affected by the neighbouring space. The result is that ‘in high dimensions all feasible training samples sparsely populate the input space’ <span class="citation">[@Hastie_2009, 23]</span>. Because <em>k-nn</em> allows for non-linear interactions between features, for instance, small differences in the number of points in particular neighbourhoods can drastically affect some stretches of the boundaries (as we see in comparing the right and left hand plots in figure ). These kinds of topological instability account for the propensity of machine learning treatments of feature-rich genomic data to produce accurate but unstable predictions. We can begin to see how a MAQC-II team might have produced 463,000 <em>k</em> nearest neighbour models in an effort to normalise and regulate predictive predictions. The price of accurate predictivity in genomics is variation in prediction.</p>
</div>
<div id="whole-genome-functions" class="section level2">
<h2><span class="header-section-number">10.8</span> Whole genome functions</h2>
<p>Cores, microarrays, SNPS,and many models; infrastructural scaling, biological variation and the populations of unruly machine learners entwine in referential entanglement. If genomes are scientific hyperobjects (with epistemic, speculative, financial and biopolitical resonances), what part does their referential cros-validation with machine learning play in the transformation of knowledge?</p>
<p>Genomic data – beginning with DNA sequences, then levels of gene expression, followed by genome wide association studies of small mutations – has been a constant <span class="math inline">\(p \gg N\)</span> antigen in machine learning. Techniques of regularization – the lasso – of linear models discussed in this chapter came to light, and were first demonstrated on genomic data produced in the mid-1990s. Throughout the ongoing development and enrichment of DNA and protein sequencing techniques, replete with a vast and quite dynamic bioinformatic infrastructure, machine learning and genomics have been cross-validating in practice. Scientists, statisticians, datasets and machine learners traffic between genomics and machine learning at almost every level, ranging from the sequence assembly to testing and analysis of DNA data in clinical settings. In genomics, elementary practices of aligning and assembling sequences into whole genomes were re-configured probabilistically through machine learning models.</p>
<p>Almost every subsequent development in genomics (and related fields such as proteomics) follows a referential flow of materializing transcription, infrastructural cross-validation, and regularizing differentiation.  An entity whose constitution is thoroughly dependent on prediction or algorithmic classification displays variations and grouping (such as gene expression, the linkage disequilibrium of SNPs, the seeming abundance of junk DNA that is actually functional, etc.) that attract further efforts to differentiate, regularize, and classify ever more subtly distributed differences. Elementary practices in contemporary genomics such as sequence alignment were explicitly formulated as generative models to be constructed using algorithms such as expectation maximization. As we see in the vignettes from <em>Elements of Statistical Learning</em>, the demonstration of Google Compute cloud computing, or for that matter in the myriad publications in both machine learning and life science journals that make use of support vector machines, neural networks, linear discriminant analysis or random forests, machine learning establishes a new set of conditions for the exercise of scientific research, and configures new kinds of statements, new types of objects (genomes in particular are difficult to conceive without their probabilistic modelling) and, as will be discussed in the next chapter, subject positions (bioinformaticians, computational biologists, data scientists and others). </p>
<p>What is at stake in approaching machine learning in a scientific setting like genomics? Foucault writes that ‘we should distinguish carefully between <em>scientific domains</em> and <em>archaeological territories</em>’ <span class="citation">[@Foucault_1972, 183]</span>.  Knowledge stems from the practices that connects objects, field, subjects, statements, and institutions. Sciences are always localized within a field of knowledge that may exceed, and mutate in ways that alter, local sciences. Science, for Foucault and perhaps for science studies more generally, needs knowledge practices that exceed, surround and indeed do something different to science. Machine learning is just such an operational formation.</p>
<p>Could we pose or address any normative questions by becoming aware of and articulating machine learning with science with greater clarity? Genomic science, in its cross-validation with machine learning, displays some of the tendencies to reduce divergences and to corral differences typical of knowledge economies more generally. The philosopher of science, Isabelle Stengers writes:</p>
<blockquote>
<p>with the knowledge economy, we may have scientists at work everywhere, producing facts with the speed that new sophisticated instruments make possible, but that the way those facts are interpreted will now mostly follow the landscape of settled interests. … We will more and more deal with instrumental knowledge. (Stengers 2011:377)  </p>
</blockquote>
<p>As we see in the 600,000 cores of Google Compute applied to exploration of associations in cancer genomics using random forests, or the lasso applied to microarray SNP data, machine learning rapidly produces facts. Stengers suggests that the risk here is that divergence and unexpected forms of experimental result are somewhat diminished as a result. Machine-learning in genomics might produce a ‘self-organising map’ that poses questions following the ‘landscape of settled interests’ or <em>status quo</em>.</p>
<p>I see matters as slightly more complicated than an instrumental production of knowledge. In the biosciences of the last two decades, machine learning seeks to disaggregate, compartmentalise and rank those aspects of genomes — their confused variations, their manifold spatial and temporal relationality in biological processes — that seem most distant and difficult to derive from putatively linear, monolithic and searchable DNA sequence data. DNA can be laid down in tracks or grids, aligned and annotated in uniquely addressable database records, but the problem of how this extensive vector maps onto the subtle, pervasive and transient forms of temporal and spatial re-shaping in life-forms remains. None of the examples of genomic data in <em>Elements of Statistical Learning</em> use whole genome. In the feature-rich spaces countenanced by machine learning, we see attempts to embed manifolds in local regions, local linearities. Sometimes these local regions are regions of annotated DNA, or non-linear interactions between sets of genes, as in the GWAS analysis of epistasis. At other times, these local regions are forms of life in a more general sense — clinical outcomes or diagnostic tests — as in MAQC-II.</p>
<p>The enunciative function of machine learning inscribes the possibility of genomes as multi-temporal, inter-connected expressions of variation. Such regularizing and potentializing of things on new infrastructural, collective and domain-specific scales outstrips instrumental purposes. In <em>The Archaeology of Knowledge</em>, Foucault describes discourse as ‘controlled, selected, organised and redistributed according to a certain number of procedures, whose role is to avert its powers and its dangers, to cope with chance events, to evade its ponderous, awesome materiality’ <span class="citation">[@Foucault_1972,216]</span>. Something similar flows through operational formations such as machine learning in their entanglements with sciences. Controlling, selecting and organizing, it almost inadvertently affirms a ponderous, ‘awesome’ materiality of data practice.  </p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="77">
<li id="fn77"><p>I have discussed the history of heatmaps and their place in contemporary science in other work <span class="citation">[@Mackenzie_2013c]</span>.<a href="10-regularizing-and-materializing-objects.html#fnref77">↩</a></p></li>
<li id="fn78"><p>A large and very diverse social science and humanities literature now exists around genomics. I draw on some of that literature as general background here, especially <span class="citation">[@SunderRajan_2006; @Thacker_2005a; @Stevens_2011; @Leonelli_2014]</span> and <span class="citation">[@Haraway_1997]</span>, but largely do not address it directly.<a href="10-regularizing-and-materializing-objects.html#fnref78">↩</a></p></li>
<li id="fn79"><p>As data forms, genomes have a problematic mode of existence. They resemble cat images on the internet. As a data form, genomes are remarkably homogeneous. They are one-dimensional strings of letters corresponding to the well-known four nucleic acids (<code>g</code>, <code>a</code>, <code>t</code>, <code>c</code>).  While many earlier tabulations of variation, difference, groups, types and relations are woven through the life sciences, genomes have for the last several decades mesmerised biological sciences as a way of analysing and re-distributing the confused multiplicities associated with living things. The raw data for genomes comes from the sequencing of DNA obtained from various organisms - viruses, bacteria, plants, fish, animals and humans. The sequencing of DNA, especially DNA that encodes the proteins that pervade biological processes, that structure tissues or assemble in complicated metabolic pathways, has been the concern first of molecular biology (mainly in the 1970s-1990s) and more recently genomics (post-1990). In molecular biology, DNA sequences were carefully elicited (using the experimental techniques for instance of Sanger sequencing) and then compared with already known sequences of DNA to identify similarities that might have biology significance (for instance, evolution from a common ancestor). In genomics, DNA sequences generally originate from increasingly high-throughput sequencers that output massive datasets (see <span class="citation">[@Stevens_2013; @Mackenzie_2015]</span>. Given both the accumulated store of already sequenced DNA and the increasingly viable practices of sequencing all of the DNA in a given organism, genomics has promised a much wider and more detailed understanding of biological complexity than any previous life science had been able to obtain. With genomes in hand, biologists for the first time would be in a position to build models of entire domains of biology, domains that previously could only be explored through painstaking experiments targeting specific cells, molecules, biochemical reactions and networks. The vast yet somewhat dispersed knowledges of the life sciences might be re-ordered and aligned on a new very extensive yet quite homogeneous backbone of the genome read out as billions of DNA base pairs.<a href="10-regularizing-and-materializing-objects.html#fnref79">↩</a></p></li>
<li id="fn80"><p>Whole genome assembly as reported for the initial draft of the human genome in 2001 <span class="citation">[@Venter_2001;@Lander_2001]</span> or for the model biological organism, <em>Drosophila</em> <span class="citation">[@Myers_2000]</span> was not at the time understood as a machine learning problem. The task of whole genome assembly from DNA fragments was seen as probabilistic in the sense that the aim is to assemble the often millions of short sequence fragments in an order that is most likely to occur. Even prior to the first full human genome assembly, genomic science had made heavy use of probabilistic models in aligning DNA (and protein amino acid) sequences. Richard Durbin, Sean Eddy, Anders Krogh and Graeme Mitchison’s highly cited <em>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids</em> <span class="citation">[@Durbin_1998]</span> was based almost entirely on Hidden Markov Models, a way of modelling a sequence of states that <em>Elements of Statistical Learning</em> treats at chapter length (see <span class="citation">[@Hastie_2009, Chapter 17]</span>).  While sequence alignment was regarded as a deeply algorithmic and statistical problem in the former volume, it is not at all formulated in the language of machine learning. There is little discussion of cost functions, vector spaces, optimisation, problems of generalization, supervised or unsupervised learning. On the other, David Haussler, a key bioinformatician in the first draft of the human genome in his work explicitly sought to bring machine learning methods to bear on biology, and continues to do so. See <span class="citation">[@Zerbino_2012]</span> for a review of the relevance of machine learning to genomic science. The practical problem here is that genomes contain swathes of duplicated regions that make assembling sequences in good order a severe challenge. While sequence alignment algorithms have long used algorithmic approaches (known as dynamic programming) to score the similarity between two given DNA sequences, assembling the millions of DNA sequences produced by contemporary sequencers has necessitated entirely new techniques (shifting, for instance, from the overlap-layout-consensus model to the de Bruijn graph-based path models <span class="citation">[@Pevzner_2001]</span>.  <a href="10-regularizing-and-materializing-objects.html#fnref80">↩</a></p></li>
<li id="fn81"><p>Signal processing is another such domain. Many of the techniques now prominent in machine learning developed in parallel in signal processing, where the encoding and decoding of signals has long been seen as a problem of pattern recognition amenable to statistical calculation. In some specific cases, such as Hidden Markov Models, the same techniques seem to appear almost simultaneously in very disparate domains. Hidden Markov Models appear in genomics (as part of the problem of sequence alignment) at the same time as the begin to appear in digital signal processing for wireless communication and video image compression <span class="citation">[@Mackenzie_2010a]</span> and above all, in speech recognition <span class="citation">[@Rabiner_1989]</span>.  <a href="10-regularizing-and-materializing-objects.html#fnref81">↩</a></p></li>
<li id="fn82"><p>A second significant and equally prestigious example of this infrastructural re-scaling might be IBM Corporation’s ‘cognitive computing platform,’ Watson. Watson, a distributed computing platform centred on machine learning, is hard to delineate or easily describe since it exists in a seemingly highly variable form. Its uses in genomics, pharmaceutical discovery, clinical trials and cooking are heavily promoted by IBM <span class="citation">[@IBM_2014]</span>. Another would be Amazon Web Services various cloud computing services, some of which have been heavily used by genomic scientists.<a href="10-regularizing-and-materializing-objects.html#fnref82">↩</a></p></li>
<li id="fn83"><p>In their account of the surprisingly slow shift of microarrays towards clinical practice, Paul Keating and Alberto Cambrosio identify statistics as a kind of bottleneck:</p><blockquote><p>The handling and processing of the massive data generated by microarrays has made bioinformatics a must, but has not exempted the domain from becoming answerable to statistical requirements. The centrality of statistical analysis emerged diachronically, as the field moved into the clinical domain, and is re-specified synchronically depending on the kind of experiments one carries out <span class="citation">[@Keating_2012,49]</span>.</p></blockquote><p>What Keating and Cambrosio describe as ‘becoming answer to statistical requirements’ I would suggest also entails a transformation of statistical requirements in a new operational diagram that reduces some of the frictions associated with existing statistical practice. This operational diagram is machine learning.   <a href="10-regularizing-and-materializing-objects.html#fnref83">↩</a></p></li>
<li id="fn85"><p>Importantly, as discussed in Chapter  (in terms of the diagonalization running between different elements of code, data, mathematical functions and indexical signs) and in Chapter  (in terms of the auratic power of datasets), the fact that these datasets can be so readily loaded and accessed via bioinformatic infrastructures using code written in <code>R</code> or <code>Python</code> is also a notable feature of their advent in the machine learning literature. Even a social science researcher can quickly write programs to retrieve this data. It attests to several decades, if not longer, work on databases, web and network infrastructures, and analytical software, all, almost without exception, driven by the desire for aggregation, integration, archiving and annotation of sequence data that first became highly visible in the Human Genome Project of the 1990s. The brevity of these lines of code that retrieve and load datasets – half a dozen statements in <code>R</code>, no more – suggests we are dealing with a high-sedimented set of practices, not something that has to be laboriously articulated, configured or artificed. Code brevity almost always signposts highly-trafficked routes in contemporary network cultures.  Without describing in any great detail the topography of databases, protocols and standards woven by and weaving through bioinformatics, the ready invocation of genomic datasets suggests that the mixed, dirty, wide datasets fed to algorithms such as <code>RF-ACE</code> or analysed in <span class="citation">[@Hastie_2009]</span> derives from the layered couplings and interweaving of scientific publications and scientific databases developed by biological science over the last three decades. As the code shows, sequence and other genomic data are available to scientists not only as users searching for something in particular and retrieving specific data, but to scientists as programmers developing ways of connecting up, gathering and integrating many different data points into to produce the wide ( many-columned), mixed (different types of data), and dirty (missing data, data that is ‘noisy’) datasets, datasets whose heterogeneous and often awkward topography then elicits and invites algorithmic treatment.<a href="10-regularizing-and-materializing-objects.html#fnref85">↩</a></p></li>
<li id="fn86"><p>The original publication of the lasso technique in a paper entitled ‘Shrinkage and Selection via the Lasso’ <span class="citation">[@Tibshirani_1996]</span> has been heavily cited in subsequent literature. <a href="http://scholar.google.co.uk/scholar?hl=en&amp;q=tibshirani+1996+lasso">Google Scholar</a> counts around 13,000 citations. For a paper published in the <em>Journal of the Royal Statistical Society</em>, this is surprisingly high, but attests, I would suggest, to the intense interest in renovating linear models for new problems such as image recognition or tumour classification. Somewhat surprisingly, given its heavy usage in other scientists, Andrew Ng’s CS229 machine learning course at Stanford University doesn’t mention the lasso.<a href="10-regularizing-and-materializing-objects.html#fnref86">↩</a></p></li>
<li id="fn87"><p>One important difficulty is the increasingly visible presence of variations in genomes. These variations first become visible after the assembly of whole genome sequences. Genomes of individuals of the same species vary in having slightly different versions of the genes (alleles), many of which differ only by single nucleotide base pairs. Whole genome sequencing made these differences, known as single nucleotide polymorphisms (SNPs), much more apparent. They occur in their tens of millions in the human genome (some 100 million are reported in the NCBI dbSNP database). In coding regions, SNPs may occasion changes in protein structure; in non-coding regions that can affect how gene expression occurs or is regulated. Like genes, SNPs can be detected using microarrays. SNP microarrays are commonly used in genome-wide association studies (GWAS) that explore complex genetic traits and conditions. SNP-based DNA microarrays measure the occurrence of millions of SNPs in a given biological sample. <a href="10-regularizing-and-materializing-objects.html#fnref87">↩</a></p></li>
<li id="fn88"><p>Fix and Hodges frame their suggestion of the <em>k</em> nearest neighbour model in this way: ‘there seems to be a need for discriminative procedures whose validity does not require the amount of knowledge implied by by the normality assumption, the homoscedastic assumption, or any assumption of parametric form. The present paper is, as far as the authors are aware, the first one to attack subproblem (iii): can reasonable discrimination procedures be found which will work even if no parametric form can be assumed?’ <span class="citation">[@Fix_1951,7]</span>. Subproblem (iii) in this quote refers to the challenge of deciding which of two populations an observed case belongs to if we know nothing about the parameters describing the two populations. <a href="10-regularizing-and-materializing-objects.html#fnref88">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="9-patterns-and-differences.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="11-propagating-subject-positions.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
