# 4.  $N = all$: machine learning gets all the data

## structure

- hacking on how statistics became real -- tables of numbers; retrofitting of laws as regularities; the role of the social; constant crossover between medicine, state and science, 
- the fact that machine learning books are full of stats, but the traditional stats of hypothesis testing, tests of significance, measures of uncertainty or variation although some of this appears.
- statistical mechanisms in the service of something else -- follows on from argument about functions as partial observers and as things in the world (code) -- statistics becomes a device to order the progress of machines; and the laws that matter -- law of large of numbers; the normal distribution -- become techniques of controlling the proliferation of movements. 
- not so much the deluge of tables giving rise to statistical laws, measurement preceding regularity, but ....

## Introduction

In the final pages of _The Taming of Chance_, the philosopher Ian Hacking describes the work of the geodesic philosopher C.S. Peirce in terms of a twin affirmation of chance. On the one hand, Peirce, following the work of the psychophysicist Gustav Fechner and before him the astronomer-sociologist Adolphe Quetelet, makes the normal curve into an underlying reality.[^4.1] The 'personal equation,' the variation in measurements made by any observer, become 'a reality underneath the phenomena of consciousness' [@Hacking_1990, 205]. At the same time, and in order to show the underlying reality of the curve, 'Peirce deliberately used the properties of chance devices to introduce a new level of control into his experimentation. Control not by getting rid of chance fluctuations, but by adding some more' [@Hacking_1990, 205]. Peirce's belief in absolute chance, 'a universe of chance' as Hacking puts it, came in the way of a series of 'realization' of curves, in which first social, then biological and finally psychological variations were all understood as evidence of a generative function, the normal distribution or Gaussian function. In the century or so since, what happened to the thorough-going affirmation of statistical thought and probabilistic practice epitomised by Peirce? Hacking stresses that he does not understand Peirce as the precursor or the innovator of twentieth century statistical thought (Hacking's _Taming of Chance_ ends at 1900), but rather as 'the first philosopher completely to internalize the way chance had been tamed in the nineteenth century' (215). What would the equivalent philosopher-machine learner internalize today? What would such persons, working in science or media or government, hold firm in relation to chance, probability and statistics? 

[^4.1]: The historian of statistics Stephen Stigler provides a lengthy account of Fechner's work [@Stigler_1986].  TBA -- in what chapter?

In a broad sense, the setting that concerned Peirce in his work at the U.S. Government Coast Survey in the 1870s does not differ greatly from the setting that machine learners encounter. In the opening lines of the First Edition of _Elements of Statistical Learning_, Hastie, Tibshirani and Friedman write:

>The field of Statistics is constantly challenged by the problems that science and industry brings to its door. In the early days, these problems often came from agricultural and industrial experiments and were relatively small in scope [@Hastie_2009, xi]

At the end of the preface, they also cite, we might note in passing, Hacking's work: 'The quiet statisticians have changed our world' [@Hastie_2009, xii]. With some justification, we might ask therefore: what difference do the 'vast amounts of data ... generated in many fields' (xi) make to what machine learners internalize of their world? This question of what kind of world becomes thinkable through machine learning can be addressed partly by contrasting the 'taming of chance' achieved during the eighteenth and nineteenth centuries, and the statistical practices of machine learning today. Is machine learning a further taming of chance? What role does randomness and probability play in machine learning?

The broadest claim associated with statistical machine learning might be the simple expression shown in:

\begin {equation}
\label {eq:linear_model}
N = \forall X
\end {equation}


In Equation \ref{eq:n_all}, $N$ refers to the number of observations (and hence the size of the dataset), the symbol $\forall$ means 'all' since this is the level of inclusion which many fields of knowledge in science, government, media, commerce and industry envisage, and $X$ refers to the data itself arrayed in common vector space. Note that this expression leaves some things out. $Y$, the response variable, for instance, may or may not be known.  While statistical techniques and practices have appeared in previous chapters, I focus here  on changes in probability practices associated with machine learning, and in particular, $N = \forall $X, the claim that with all the data, statistical thinking and the potentials of the statistical reasoning fundamentally change. The claim that with $N=\forall X$ everything changes has been widely discussed.[^4.2]  Viktor Mayer-SchÃ¶nberger and Kenneth Cukier's _Big Data: A Revolution That Will Transform How We Live, Work and Think_  present this shift in many different ways in the course of the vignettes and comparisons that have become typical of the data revolution genre. In a chapter entitled 'More,' they sketch the transition from data practices reliant on sampling to data practices that deal with all the data:

>Using all the data makes it possible to spot connections and details that are otherwise cloaked in the vastness of the information. For instance, the detection of credit card fraud works by looking for anomalies, and the best way to find them is to crunch all the data rather than a sample [@Mayer-Schonberger_2013, 2013,  27]

In the several hundred pages that follow in _Big Data_, the problem of how to 'crunch all the data' is never really discussed. While they mention the role of social network theory (30), 'sophisticated computational analysis' (55),  'predictive analytics' (58) and 'correlations' (7),  and they do say that 'the revolution' is 'about applying math to huge quantities of data in order to infer probabilities' (12), any further consideration of specific techniques of data crunching or the math is largely left aside. This is not to criticize a book that sets out to describe trends affecting business and government for a general readership, but without a sense of how statistical thinking animates almost all salient features of crunching the data and particularly the predictions, it becomes hard to see how the 'revolution' takes place. In other words, the shift from $N=n$ (some of the data) to $N=\forall X$ does not occur without other transpositions and rearrangements that do not simply concern choices about how much data to use, but also concern how data is given in the world and how it is thinkable.[^4.3] Following Hacking's core argument about how nineteenth century statistics transformed measurements (for instance, the mean as average of all measured values) into real quantities (for instance, mean as the ideal or abstract property of a population; e.g. life expectancy), we might see this shift between $n$ and $\forall X$, a shift very much animating and dependent on  machine learning, as an event akin to the advent of the Normal distribution (and indeed, $\mathnormal{N}$ is a standard symbol for the Normal distribution in statistics textbooks) as a way of thinking about populations and the control of populations [@Hacking_1975, 108]. Aligning the development of machine learning with the longer duration of statistical thinking might allow us in short to gauge a little better what is changing and where. 

[^4.2]: Rob Kitchin provides a very useful overview of these claims in [@Kitchin_2014]. While I will not analyse the claims about 'big data' in specific cases in any great detail, I  

[^4.3]: Part of this development has already been related in the previous chapter on 'learning' and function estimation. That chapter avoided any real discussion of statistical thought. Instead it explored the various sense of function and function finding that underpin machine learning. But much of that function finding and approximation garners referential weight through the statistical practices and modes of thought that accompany them. 

## Multiple distributions in machine learning

Error is a useful bridge between the history of statistics and machine learning. One of Hacking's core arguments in _The Taming of Chance_ is that modern statistical thought transposed what had been initial a way of thinking about errors in measurement, and particularly astronomical observations, into real quantities, typically described the normal distribution. This transposition or inversion relied on several intermediate steps passing through probability calculus (particularly the work of Jacob Bernoulli and the binomial or heads-tails probability distribution), on large numbers of measurements (the most famous being the chest measurements of soldiers in Scottish regiments, but these were only one flurry amidst an avalanche of numbers in the 1830-1840s), on an idea of many independent but minute causes producing events (particularly as developed in medicine but also in studies of crime), and the law of errors applying to measurements made by, amongst others, astronomers [@Hacking_1990, 111-112]. As Hacking points out, coins, suicides, crime, chest measurements, and astronomical observations all come together in a picture of statistical stability which remains, although somewhat blurred, indelibly legible in contemporary statistical thought. All of this seems a long way from machine learning, and historically, the work of figures such as Poisson, Laplace, Quetelet and even Galton, is well-removed. In terms of tables and functions (the concerns of the preceding two chapters), the distance is not so great. There is greater variety in tables (partly due to the common vector space) and in functions, but the entwining or even swapping between what relates to an observation and what concerns the real, continues. Machine learners engage in that swapping or re-distributing of numbers all the time. Viewed from the standpoint of a Hacking, machine learning re-invents the invention of modern statistical thinking since it takes back the 'real quantities' that modern statistics had attributed to the populations of the world and puts them into devices. When Hastie and co-authors write (as we saw in the last chapter) 'our goal is to find a useful approximation $\hat(f)(x)$ to the function $f(x)$ that underlies the predictive relationship between input and output' [@Hastie_2009, 28], they invoke the 'real quantities' first elaborated and articulated by statistical thinkers such as Quetelet. 

The major structuring differences in machine learning as a field of knowledge-practice show the marks of this commitment to the reality of the statistical. 

----        -----
supervised  unsupervised
generative  discriminative
parametric  non-parametric
prediction  inference
bias        variance
-----------------------------------

Table: Structuring differences in machine learning


Every text on machine learning is structured by this basic set of contrasts or indeed oppositions. The contrasts shown in \ref{table:} all have a statistical facet and sometime anchoring  to them. Some refer to variations and errors (bias and variance), some refer to the underpinning statistical intuition in particular techniques (e.g. Naive Bayes or Latent Dirichlet Allocation are generative models whereas logistic regression or support vector machines are discriminative), and others indicate different kinds of statistical knowledge (prediction seeks to anticipate while inference seeks to interpret, etc.). These broad structuring differences reach down deeply into the architecture, the diagrams, the practices, statements and visual objects and computer code associated with $N=\forall X$. Because they  anchor basic elements of  machine learning, a much more profuse set of techniques and formalisms derived from statistics more generally populate the field and organise its knowledge of its own techniques and its orientation to the worlds of industry, agriculture, earth science, genomics, etc. Reading and working with machine learning techniques usually means encountering and responding to some of that statistical apparatus drawn from statistics, but these are not typically the statistical tests of significance or variation. In contrast to a statistics textbook as the widely used _Basic Practice of Statistics_ [@Moore_2009] or even a more advanced guide such as _All of Statistics_ [@Wasserman_2003], where statistics (t-test, chi-squared test, etc.) hypothesis testing, and analysis of uncertainties (confidence intervals, etc) order the exposition, the machine learning texts invoke a thoroughly probabilistic conceptual apparatus, without much of the practice found in statistics. Statistical underpinnings may be fundamental, but this does not mean that  machine learners simply automate statistics.[^4.4]

[^4.4]: Leo Breiman writing in 2001 during the heyday of academic development of machine learning argues, describes the 'two cultures' of statistics: 'in the past fifteen years, the growth in algorithmic modeling applications and methodology has been rapid. It has occurred largely outside statistics in a new communityâoften called machine learningâthat is mostly young computer scientists (Section 7). The advances, particularly over the last five years, have been startling' [@Breiman_2001a, 200].

One inescapable linkage runs through the ubiquitous yet diverse species of functions known as probability distributions. 
Probability distributions are a common way of showing and  talking about _random variables_ in statistics. The curves shown in Figure 2 could refer to almost anything (the chances of rain at different times of day in Lancaster, the seasonal variation in precipitation, etc.). These distributions appear in countless shapes and forms in scientific, government and popular literature of many different kinds. Statistical graphics have a rich history and semiology that I do not discuss here (see [@Bertin_1983]). Perhaps the most famous function or mapping is the normal or Gaussian distribution:

\begin {equation}
\label {eq:gaussian_distribution}
f(x;\mu, \sigma^2) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}
\end {equation}


The  function shown in equation (\ref{eq:gaussian_distribution}) is the so-called normal or Gaussian distribution. Its  mathematics were intensively worked over during the late eighteenth and early nineteenth centuries in what has been termed 'one of the major success stories in the history of science' [@Stigler_1986, 158], and it has a power-laden biopolitical history closely tied with knowledges and governing of  national and other  populations in terms of morality, health, and wealth (see [@Hacking_1975, 113-124]. The key symbols here include $\mu$, the mean and $\sigma$, the variance, a number that describes how widely dispersed the values of the variable, $x$ are. These two parameters together describe the shape of the curve. Given $\mu$ and $\sigma$, it become possible to map different outcomes to probabilities. Put more statistically, viewed in terms of functions such as the Gaussian distribution, events become random variables. Following the kind of definition that we find in a standard statistics textbook, every variable potentially becomes a function: 'a random variable is a mapping that assigns a real number to each outcome' [@Wasserman_2003,19]. The possibility of treating all variables as random variables, that is, as probability distributions was a significant historical achievement, but one that continues to develop. We might note the real power of probability distributions when conceptualised as real quantities in the world, not epiphemonal by-products of inaccuracies in our observations or measuring devices. For instance, given the normal distribution, it is possible, under certain circumstances, to effectively subjectify someone on the spot. If an educational psychologist indicates to someone that their intelligence lies towards the left-hand side of the normal curve peak in Figure 2 (and hence less than the population mean), they quickly render them somehow subject to a potentially institutionally and economically consequential trajectory. This is not a recent development. Since its inception in the social physics of Quetelet as a way of referring to a property of populations, the normal curve has promised or threatened to support the re-shaping and control of populations (in terms of health, morality and wealth). Since then, probability distributions and their corresponding curves have multiplies. Subsequent statisticians used dozens of different probability distributions to map continuous and discrete variations to real numbers. Other probability distributions abound â normal (Gaussian), uniform, Cauchy exponential, gamma, beta,  hypergeometric, binomial, Poisson, chi-squared, Dirichlet, Boltzmann-Gibbs distributions, etc. (see [@NIST_2012] for a gallery of distributions) â because outcomes occur in widely differing patterns. The  queuing times at airport check-ins do not, for instance, easily fit a normal distribution. Queues are usually modelled using a Poisson distribution, which unfortunately for travellers, distributes waiting times very differently.  Similarly, it might be better to think of the probability of rain today in Lancaster in terms of a Poisson distribution that models that queue of clouds in the Atlantic just waiting to land on the northwest coast of England. Rather than addressing the question of if it will rain or not, a Poisson-based model might address the question of how soon.

If functions such as equation (\ref{eq:gaussian_distribution}) have persisted for so long as operational underpinnings, what happen to them in machine learning? The pages of a book such as _Elements of Statistical Learning_ show many signs of this ongoing re-distribution of distributions. At a broad level, we could simply note their abundance. Hastie and co-authors diversely invoke probability distributions. They speak of 'Gaussian mixtures,' 'bivariate Gaussian distributions,' standard Gaussian,' 'Gaussian kernels,' 'Gaussian errors', 'Gaussian assumptions,' 'Gaussian errors,' 'Gaussian noise,' 'Gaussian radial basis function,' 'Gaussian variables,' 'Gaussian densities,' 'Gaussian process,' and so forth. The term 'normal' appears in an even wider spectrum of similar guises, but they uniformly entail treating events, things, properties or attributes as probability distributions. The wide distribution of the Gaussian function does not mean that one function, the Gaussian probability density function reigns supreme above all machine learners. While heavily reliant on the normal distribution, much machine learning seeks to loosen that reliance by, for instance, developing _non-parametric models_,  


The diverse curves of probability distributions â and we will see below some reasons why we can expect them to proliferate in certain settings â attests to the variety of ways in which events might be mapped to real numbers. Despite  the sometime forbidding mathematical equations, the term *distribution* emphasises a quite material or tangible way of thinking about how events or possible outcomes vary. The underlying probability distribution is in principle âunobservableâ as such, but a probability density function is the closest reality we have to whatever process generated  all the variations in data gathered through experiments and observations. From a probabilistic perspective, the taks of machine learning is to estimate the parameters (the mean $\mu$ and variance $\sigma$ in the case of Gaussian curve) that shape of the curve of the probability distribution. Given the shape of that curve, many inferences and predictions become possible. The probability distribution function is a crucial control surface for machine learning understood as a form of movement through data. 

## Naive Bayes

What does this mean in practice? The mathematical expression for one of the most ubiquitous of all machine learning classifiers is:

\begin {equation}
\label {eq:naive_bayes}
f_j(X) = \prod_{k=1}^{p}f_{jk}(X_k)
\end {equation}

[@Hastie_2009, 211]

Some machine learning techniques are so simple that they can be implemented in a few lines of code. Their simplicity, however, belies their power. The function shown above \ref{eq:naive_bayes} is about the simplest one to be found in most machine textbooks. It expresses the Naive Bayes classifier, one of the most popular machine learning algorithms, even though it is more than 50 years old [@Hand_2001]. While \ref{eq:naive_bayes} does not set out all the steps in transforming some training data into a predictive model, the lines of code needed to do this are similarly brief. In _Doing Data Science_, Rachel Schutt and Cathy O'Neill furnish a bash script (that is, command line instructions) to download a well-known email dataset and build a Naive Bayes classifier for spam:

[HERE]

There is some new operating terminology in this chapter (terms such as random variable, probability distribution and likelihood).  While I attempt to be both mathematically and conceptually concise in my use of these terms, the terms themselves are somewhat troubled by the transformations I'm describing. The underpinnings of taken-for-granted and everyday statistical such as random variable or probability are not immune from change. Like all technical formalisms they took hold at a certain practical and historical conjuncture that will not and perhaps already does not hold entirely still. As the philosophy Ian Hacking suggests in his discussion of early 20th century changes in probability in _The Taming of Chance_,

>By the 1930s, however, the world teemed with frequencies, and the 'objective' notion would come to seem more important than the 'subjective' one for the rest of the century -- simply because there were so many more frequencies to be known [@Hacking_1990, 97].

I'm suggesting that we countenance a scene in which multiple different probability practices stack on top of each other in a somewhat untamed way. Amidst these, random variables and their associated probability distributions particularly concern us. As we will see, the power of the transformation in probability associated with machine learning algorithms resides in their capacity to draw in many more relations, features and components of data in support of a probabilistic outcome. When things are best described as probability distributions, they take on a different form of temporal and multiplicative existence, and this no longer easily attributed to either 'subjective' or 'objective' probability, or to a shift in balance between the long-standing poles of 'subjective' and 'objective' probability. A probabilistically generated airline seat price attracts different kinds of transactions than a fixed priced seat. Similarly, a probabilistically generated tumour classification implies different modes of responsiveness and care. Gaining some understanding of the concrete arrangements of forces in these probabilistic modes might allow us to account for the ways in which certain methods -- Bayesian inference is a striking example of transverse momentum of methods across fields  -- go on the move, or why certain problems -- automatic text classification, image recognition, etc -- suddenly hove into feasibility.

The chapter traces two important implications of probabilistic model for machine learning. First, because it is so computationally intensive, MCMC and Bayesian inference, although statistically powerful, are difficult to apply to many dimensional datasets. So Bayesian computation iconically figures the limits of contemporary data practices, with their ambitions to incorporate all available data into calculation. Second, in certain ways this technique challenges us to re-evaluate how we think about numbers. By following some of the ways numbers circulate through MCMC algorithms, we can discern to a semiotic-material faultline running through contemporary number formations. Numbers semiotically and materially embrace both events and degrees of belief. If numbers are crucial in the data economy, then instabilities in their mode of existence will affect much of what happens to data. While much of the machine learning taking place in commercial and operational settings is decidedly non-Bayesian, the popularity of MCMC and Bayesian approaches in contemporary sciences suggests a tension in what counts as number.

[HERE]

Certain strands of social and cultural theory have taken a strong interest in algorithmic processes. For instance, the sociologist Scott Lash distinguishes  the operational rules found in  algorithms from the regulative and constitutive rules in many social settings and studied by social scientists:

>in a society of pervasive media and ubiquitous coding, at stake is a third type of rule, algorithmic, generative rules. âGenerativeâ rules are, as it were, virtuals that generate a whole variety of actuals. They are compressed and hidden and we do not encounter them in the way that we encounter constitutive and regulative rules. Yet this third type of generative rules is more and more pervasive in our social and cultural life of the post-hegemonic order. They do not merely open up opportunity for invention, however. They are also pathways through which capitalist power works, in, for example, biotechnology companies and software giants more generally [@Lash_2007a, 71].

The term 'generative' is somewhat resonant in the field of machine learning as generative models, models that treat modelling as a problem of specifying the operations or dynamics that could have given rise to the observed data, are extremely important. If we consider only Andrew Ng's CS229 machine learning lectures  on Youtube [@Ng_2008], we can see that they introduce generative models in Lecture 5 and 6. Although this seems to be only a small part of the 18 lectures given in the course, later lectures on the expectation maximisation algorithm (12-13), and then on unsupervised learning techniques such as factor analysis and principal component analysis, independent component analysis, are also effectively exploring generative models.  A similar distribution of topics can be found in _Elements of Statistical Machine Learning_[@Hastie_2009].   Generative models, while perhaps slightly less common in practice than discriminative models, nevertheless capture the sense that algorithms are not just implementations of rules for filtering, sorting, or deciding, but carry within them ontological commitments that might actually challenge social theory in interesting ways. In contrast to Lash, I would suggest that the generativity of these algorithms needs to be differentiated from the algorithmic processes that implement rules more generally. Moving into the data via a generative probabilistic model is very different to moving into the data through say a database query. The models, whether generative or discriminative (models  such as decision tree,  logistic regression or even neural networks that are more limited in their probabilistic underpinnings), are more like meta-algorithms that reorganize other algorithmic processes on varying scales. 
## References
