# 5. Splitting, propagating and hyper-planing: patterns of movement in data 

The contemporary form of knowledge as pattern-finding 
Finding patterns in data
Movements in machine learning: patterns of generalization
Dimensional exuberance and pattern recognition in movement

```{r echo=FALSE} 
library(knitr)
opts_chunk$set(results='asis', message=FALSE, warnings=FALSE, cache=TRUE)
```
## todo

- diagrams -- the rpart diagram and trees; iris version?
- what happens in code here -- the inner product; the recursive, the backprop algorithm ... 
- what happens to knowledge -- knowledge understood in Foucaultean sense as savoir;  the discursive practices that criss words and things

## structure

- decision tree, neural network and svm -- 1960 - 2000

## Introduction

We have seen the emergence of the common vector space and its epistopological transformations, the multiplication of functions and their entwined partial observers, and then the re-distribution of probability in statistical devices that both populate world and transform machine learners into populations. Across the vectors, functions, and distributions a  diagram of  machine learning weaves and knots many points of emergence, continuity and conjunction. Formidable accumulations of infrastructure, devices and expertise pivot around machine learning (as we will see in Part II). On several occasions problems of the density and mass of techniques, research literature, algorithms and code have appeared. What in this diagram and in the forest-like growth of techniques, projects, applications and proponents allows us to make sense of its dynamism? Via three highly developed and heavily used machine learners  -- decision trees, neural networks, and support vector machines  -- that more or less mesmerised the machine learning scientific literature between 1980-2000, some relatively novel and somewhat discontinuous forms of movement into and through data were initiated. These movements, which we might characterise as _splitting_, _propagating_ and _hyper-planing_ -- continue to fiercely animate machine learners in producing newer techniques (random forests, deep belief nets), intensifying their application, and perhaps more importantly, re-configuring what counts as knowledge.

These three techniques have not been chosen randomly. They appear in the machine learning scientific publications of the last three decades as the most important novelties of these decades. They also, as we will see, loom large in various contemporary enunciations of machine learning as a way of knowing (for instance, in the popular machine learning  books such as _Machine Learning for Hackers_[@Conway_2012] or _Doing Data Science_ [@Schutt_2013]). The machine learning literature bristles with references to papers in statistics, computer science, mathematics, artificial intelligence and a swathe of related scientific fields. It ingests substantial supplies of knowledge and practice coming from the social sciences, insurance and actuarial practice, and marketing research. A very rough citation analysis of the research literature indicates that  the top 20 most cited publications in the field refer either to decision trees [@Quinlan_1986; @Breiman_1984], support vector machines [@Vapnik_1999; @Cortes_1995],  machine learning pedagogy [@Mitchell_1997], an early textbook written by a computer scientist; Witten, a textbook and software package on data mining using Java [@Witten_2005]; a textbook on pattern recognition dating from the 1970s [@Duda_2012], a tutorial on an error control technique (ROC - Receiver Operating Characteristics, first developed by the US military during WWII) and somewhat lower, another well-known textbook, this time on neural networks [@Bishop_2006]. While I do not place too much weight on citation counts, since they develop for different reasons over time and display discipline-specific tendencies, the spectrum of references here show a variety of investments in machine learning. They range from highly theoretical general accounts of the nature of machine learning (Mitchell, Duda) to detailed concrete implementations of techniques (Witten). Some focus on very specific techniques such as decision trees (Breiman, Quinlan) or support vector machines (Cortes) or neural networks (Bishop).

Across all of these differences, a striking _positivity_ takes shape. I understand positivity, partly in the sense of 'positivism' -- a theory that knowledge is based on observation -- and positive in the sense proposed by Michel Foucault in _The Archaeology of Knowledge_, a book that unexpectedly and anachronistically resonates with much that takes place in machine learning:

>To describe a group of statements not as the closed, plethoric totality of a meaning, but as an incomplete, fragmented figure; to describe a group of statements not with reference to the interiority of an intention, a thought, or a subject, but in accordance with the dispersion of an exteriority; to describe a group of statements, in order to rediscover not the moment or the trace of their origin, but the specific forms of an accumulation, is certainly not to uncover an interpretation, to discover a foundation, or to free constituent acts; nor is it to decide on a rationality, or to embrace a teleology. It is to establish what I am quite willing to call a positivity [@Foucault_1972, 125].

Foucault frequently refers to positivity in those passages where he discuss the set of conditions configuring how practices occur, and how statements relating to those practice arise. Note that the situations in which he invokes positivity involve accumulations or plethora of statements whose coherence or unity does not lie in any origin, intention, rationality, subjectivity, ideology or teleology. Positivities enable accumulations without deriving them from underlying unities. Foucault's acceptance of 'positivity,' in spite of the risk of attracting criticism, pivots on his interest in, and practical commitment to, accumulating observations. A positivity is a way of describing 'a group of statements' that may be quite dispersed, discontinuous, and unevenly distributed because they make up 'a population of events in the space of discourse in general' [@Foucault_1972, 27]. If _The Archaeology of Knowledge_ is a book concerned with the tissue of relations between things, what is said, what is done and what counts as knowledge (scientific or not) in practice, then the persistent and at times forceful reiteration of _dispersion_ and _discontinuity_ might seem strangely counterintuitive. But Foucault's insistence on discourse as something irreducible to logic, language, intention, rationality, experience, historical origin or narrative, and as the way in which 'statements' ('a graph, a growth curve, an age pyramid, a distribution cloud are all statements' (82)), strategies, concepts, objects, archives and knowledges come together in 'discursive formations' is an attempt to resist any resort to a hidden order or concealed origin that critical thought could uncover or interpret. 

This commitment to a positivity of accumulation helps, somewhat paradoxically, in a field such as machine learning whose many different forms, techniques, statements, institutions, values and associations entangle with each other. The three techniques that anchor this chapter are at once perhaps the most distinctive machine learning achievements of the late twentieth century, at least judging by the citational and implementational interest they attract, yet at the same time seem quite heterogeneous and dispersed. At certain times, they come together (for instance, in machine learning competitions discussed in chapter 8; or in certain formalizations such as machine learning  theory or in graphs of the bias-variance decomposition discussed in the previous chapter; or in the pedagogy of machine learning discussed in chapter 1 [@Ng_2008c; @Ng_2008d, @Ng_2008h]). We might understand their heterogeneity in terms of 'enunciative modalities' [@Foucault_1972, 54]   -- that is, in terms of the different ways in which they give rise to statements. Each of the  machine learners generates statements, but from different places, by somewhat different individuals, and by the different situations they that are able 'to occupy in relation to the various domains or groups of objects' [@Foucault_1972, 52]. While drawing on Foucault in exploring the positivity of machine learning, I tend to see these enunciative modalities as distributed across people and things. As always, machine learner is a composite term for this distribution. 

## Splitting or recursive binary partitioning and the growth of trees

> Mastering the details of tree growth and management is an excellent way to understand the activities of learning machine generally [@Malley_2011, 118].

The enunciative modality of the decision tree partly relates to the observability and comprehensibility of machine learning. As the quote from a biomedical textbook on machine learning suggests, decision trees promise an understanding of machine learning. As we will see, not all machine learners readily supports observation or comprehension. The cost of comprehensibility, however, is a certain highly restricted movement through the data, a movement that has been difficult to stabilise and control. As _Elements of Statistical Learning_ puts it: 'tree-based methods partition the feature space into a set of rectangles, and then fit a simple model (like a constant) in each one. They are conceptually simple yet powerful' [@Hastie_2009, 305]. Tree-based methods are supervised learning techniques as they require the data in to either be labelled with a class or to have some outcome value. The feature space (or common vector space of the data) can be mixed. Because the method cuts the feature space into a tiled surface, the features can be continuous or discontinuous. The 'simple models' that tree methods construct each inhabit one of the rectangular regions or partitions of the feature space.

```{r aid, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE, comment=NA , fig.cap='Early uses of the Automatic Interaction Detector'} 
    library(xtable)
    aid_df = '../ml_lit/data/morgan_sonquist_WOS'
    files <- dir(aid_df,full.names=TRUE)
    recs <-lapply(files, read.csv, sep='\t', header=TRUE, as.is=TRUE, quote='', row.names=NULL)  
    aid_df <-do.call( rbind, recs )
    colnames(aid_df)[1:52] <- colnames(aid_df)[2:53]
    colnames(aid_df)[1] <-'PT'
    aid_df$TI = tolower(aid_df$TI)
    aid_df = aid_df[order(aid_df$PY, decreasing=FALSE),]
   print(xtable(head(label="References to Morgan and Sonquist's Automatic Interaction Detector", aid_df[,c('TI', 'PY' ,'TC')],10)))
```

Work on classification and regression techniques using decision tree goes back to the  early 1960s when social scientists James Morgan and John Sonquist at the University of Michigan's Institute for Social Research were attempting to analyse increasingly large social survey datasets [@Morgan_1963].  As Dan Steinberg describes in his brief history of decision trees [@Steinberg_2009, 180], the  'automatic interaction detector' (AID) as it was known, sought to automate the practice of data analysts looking for interactions between different variables. The variety and sheer optimism of subsequent applications of these prototype decision tree techniques  is striking.  In the 1960s and 1970s, papers that drew on the AID paper or use AID techniques can be found, as table \ref{table:aid} shows, in education, politics, economics, population control, advertising, mass media and family planning. 

A decade after initial work, the AID was the object of trenchant criticism by statisticians and others. Writing in the 1970s, statisticians in the bebavioural sciences such as Hillel Einhorn at the University of Chicago castigated the use of such techniques.   The criticisms stemmed partly from  a general distrust of 'purely empirical methods', and scepticism in relation to their positivity:

> The purely empirical approach is particularly dangerous in an age when computers and packaged programs are readily available, since there is temptation to substitute immediate empirical analysis for more analytic thought and theory building. It is also probably too much to hope that a majority of researchers will take the time to find out how and why a particular program works. The chief interest will continue to be in the output-the results-with as little delay as possible [@Einhorn_1972, 368]

Einhorn discusses AID alongside other  techniques such as factor analysis and multi-dimensional scaling (both still widely used) before concluding 'it should be clear that proceeding without a theory and with powerful data analytic techniques can lead to large numbers of Type I errors' [@Einhorn_1972, 378]. His specific objections to AID are  particularly focused on the problematic power of the technique: 'it may make sense out of "noise"' (369). Consequently, researchers easily misuse the technique: they 'overfit' the data, and do not pay enough attention to issues of validation (369-370). Most of these criticisms can be seen as expressing conventional statistical reservations. Similarly the British marketing researcher Peter Doyle, criticising the use of AID in assessing store performance and site selection by operation researchers, complained that searching for patterns in data using small data sets was bound to lead to spurious results and the decision trees, although intuitively appealing (that is, they could be easily interpreted), were afflicted with arbitrariness: 'a second variable may be almost as discriminating as the one chosen, but if the program is made to split on this, quite a different tree occurs' [@Doyle_1973, 465-466].  These objections and resistances to early decision trees echo today in discussions around pattern recognition, knowledge discovery and data-mining in science and commerce.    The problem of what computers do to the analysis of empirical data is long-standing. 

As Einhorn expected, it was too much to hope that all researchers would take time to investigate how a particular program works. Some researchers however did take time, years in fact, to investigate how decision trees work. As a result, writing in 2008, Hastie, Tibshirani and Friedman, who could hardly by accused of not understanding decision trees,  happily recommend decision trees as the best off-the-shelf classifier:  'of all the well-known learning methods, decision trees comes closest to meeting the requirements for serving as an off-the-shelf procedure for data-mining' [@Hastie_2009, 352]. We might wonder here, however, whether they damn with faint praise, since 'off-the-shelf' suggests pre-packaged, and commodified, and the term 'data-mining' itself is not without negative connotations. As for its commercial realities, in 2013, Salford Systems, the purveyors of the leading contemporary commercial decision tree software, `CART`, could claim:

 > CART is the ultimate classification tree that has revolutionized the entire field of advanced analytics and inaugurated the current era of data mining. CART, which is continually being improved, is one of the most important tools in modern data mining. Others have tried to copy CART but no one has succeeded as evidenced by unmatched accuracy, performance, feature set, built-in automation and ease of use. [Salford Systems](http://www.salford-systems.com/products/cart)

What happened between 1973 and 2013?  Decision trees somehow travelled from the statistically murky waters of the social science departments and business schools in the early 1970s to inaugurate the 'current era of datamining' (which the scientific literature suggests starts in the early 1990s). This was not only a commercial innovation. As the earlier citation from U.S. National Institutes of Health biostatisticians Malley, Malley and Pajevic indicates, decision trees now enjoy high regard even in biomedical research, a setting where statistical rigour is highly encouraged for life and death reasons. The happy situation of decision trees four decades on suggests some kind of threshold was crossed in which the epistemological, statistical, or algorithmic ('built-in automation') power of the technique altered substantially. 

## 1984: Cutbacks on recursive partitioning

The third author of _Elements of Statistical Learning_, Jerome Friedman, worked at the  U.S. Department of Energy's Stanford Linear Accelerator during the late 1970s. Friedman  was  instrumental in rescuing  decision trees from the ignominy of profligate ease of use and pure empiricism they had endured since the late  1960s. The reorganisation and statistical retrofitting of the decision tree was not a single or focused effort. During the 1980s, statisticians such  as Friedman and Leo Breiman renovated the decision tree as a statistical tool [@Breiman_1984] at the same time as  computer scientists such as  Ross Quinlan in Sydney were re-implementing decision trees guided by an  artificial intelligence-based formalisation as rule-based induction technique [@Quinlan_1986].[^5.1] This uneasy parallel effort between computer science and statistics  still characterises machine learning today. Both statisticians and computer scientists  do and use the same techniques, but often with the computer scientists focusing on optimisation and algorithmic automation and the statisticians inventing novel formalizations. The fateful embrace of statistics and computer science, the disciplinary binary that vectorizes machine learning, has been generative in the retrieval of the decision tree. 

[^5.1]: Quinlan's papers  and book on versions of the decision tree (`ID3` and `c4.5`) are both amongst the top ten the most highly cited references in the machine literature itself. Google Scholar reports over 20,00 citations of the Quinlan's book _C4.5: Programs for Machine Learning_ [@Quinlan_1993]. Several years ago,  `C4.5` was voted the top data mining algorithm [@Wu_2008]. While I don't discuss Quinlan's work in much detail here, we should note as a computer scientist, Quinlan takes a much more rule-based approach to decision tree that Breiman and co-authors. 

An initial symptom of the transformation of the technique appears in a name. The term 'decision tree,' although still widely used in the research literature and machine learner  parlance was replaced by 'classification and regression tree' during the late 1970s and 1980s. The terms 'classification and regression tree' is sometimes contracted to 'CART,' and that term strictly speaking refers to a computer program described in [@Breiman_1984] as well as the title of that highly-cited monograph. As we have seen in previous chapters, regression and classification designate the two main sides of machine learning practice, and their concatenation with 'tree' attests to the renovation of the 1960-70's style approaches.

As usual, the implementation of machine learning techniques in `R`  offers one path into  their wider circulation. This path, by virtue of `R`'s statistical provenance perhaps favours the statistical side of decision tree practice, but that nevertheless has certain forensic virtues not offered by commercial or closed-source software often produced by computer scientists.  In this case, the name of   one long-standing and widely-used `R` package itself attests to something: `rpart` is a contraction of 'recursive partitioning' and this term generally describes how the decision tree algorithm works [@Therneau_2015].  'Cart,' on the other hand, is a registered trademark of Salford Systems, the software company mentioned above, who sell the leading commercial implementation of classification and regression trees. Hence, the `R` package `rpart` cannot call itself the more obvious name `cart, ` and instead invokes the algorithmic process it relies on: recursive partitioning. (Other `R` packages such as `party` [@Hothorn_2006] and `tree` [@Ripley_2014] also use recursive partitioning, but with various tweaks and optimisations that I leave aside here.)


[HERE -- bring in the examples] 

## Propagating or forwards and backwards in the network

## Hyper-planing or dimensional growth saves linear movement


