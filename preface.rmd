# Preface

## todo
- talk about the various meanings of 'into' : what is put in, a movement inwards, into as in like, a historical transition; link to James on conjunctions
- talking about unlearning  -- and what that might mean
- the look of this book -- it imitates its objects in certain ways -- typographically, diagrammatically, and infrastructurally ... 
- talk about the github site, and how to run the book
- the key datasets --- a set of 400k abstracts from all disciplines in the wos
- the typographic conventions used in this book -- follow Venables and Ripley


## Writing code about code: scientific software and executable papers

I've been writing code for years [@Mackenzie_2006]. But writing code was nearly always something  distant from writing about code.  Only recently, owing mainly to developments in ways of analysing and publishing scientific data, have I found ways to write about code while coding. This looping between writing code and writing about code brings about sometimes generative, sometimes frustrating encounters with various scientific knowledge (mathematics, statistics, computer science), with infrastructures on many scales (ranging across networks, databases here and there, hardware and platforms of various kinds, as well as interfaces) and many domains. At many points in researching the book, I digressed a long way into quite technical domains of statistical inference, probability theory, linear algebra, dynamic models as well as database design and data standards. Not all of the code I've written in implementing machine learning models or in reconstructing certain data practices is included in this text, just as not all of the words I've written in trying to construct arguments or think about data practices has been included. Much has been cut away and left on the ground (although the `git` repository of the book preserves many traces of the writing). So, like the recipe books, cookbooks, how-tos, tutorials and other documentations I have read, the code, the graphics and the prose have been tidied here. Many of the exploratory forays are lost and almost forgotten.  Nevertheless, the several years I have spent  writing about data practice has felt substantially different to any other project by virtue of a strong coupling between code in text, and text in code. Practically, this is made possible by working on code and text within the the same file, in the same text editor (not a word processing package). Switching between writing  `R` and  Python code (about which I say more below) to retrieve data, to transform it, to produce graphics, to construct models or some kind of graphic image, and within the same file be writing academic prose, might be one way to write more praxiographically about data and machine learning in particular.

The capacity to begin to mix  text, code and images depends on an ensemble of software tools that differ somewhat from the typical social scientist or humanities researchers' software toolkit of word processor, bibliographic software, image editor and web browser. In particular, it relies on software packages in `R` such as the '`knitr`' [@Xie_2013; @Xie_2012] and in python, the `ipython` notebook environment [@Perez_2007, as well as plain text editing software. Both have been developed by scientists and statisticians in the name of 'reproducible research.' Many examples of this form of writing can be found on the web: see [IPython Notebook Viewer](http://nbviewer.ipython.org/) for a sample of these. These packages are designed to allow a combination of code written in `R`, python or other programming languages, scientific text (including mathematical formula) and images to be included, and importantly, executed together. In order to do this, they typically combine some form of text formatting or 'markup,' that ranges from very simple formatting conventions (for instance, the 'Markdown' format used in this book is much less complicated than HTML, and uses markup conventions readable as plain text and modelled on email [@Gruber_2004];) to the highly technical (LaTeX, the de-facto scientific publishing format or 'document preparation system' [@Lamport_1986] elements of which are also used here to convey mathematical expressions). They add to that blocks of code and inline code fragments that are executed as the text is formatted in order to produce results that are shown in the text or inserted as figures in the text. 

There are a few different ways of weaving together text, computation and images together.  Each suffers from different limitations. In `ipython`, a scientific computing platform dating from 2005 [@Perez_2007] and used across a range of scientific settings, interactive visualization and plotting, as well as access to operating system functions are brought together in a `Python` programming environment. Especially in using the `ipython` notebook, where editing text and editing code is all done in the same window, and the results of changes to code can be seen immediately, practices of working with data can be directly woven together with writing about practice. By contrast, `knitr` generates documents by combining text passages and the results (graphs, calculations, tabulations of data) of code interleaved between the text into one output document. When `knitr` runs, it executes the code and inserts the results (calculations, text, images) in the flow of text. Practically, this means that the text editor used to write code and text, remains somewhat separate from the software that executes the code. By contrast, `ipython` combines text and `Python` code more continuously, but at the cost of editing and writing code and text in a browser window. Most of the conveniences and affordances of text editing software is lost.   While `ipython` focuses on interactive computation, `knitr` focuses on bringing together scientific document formatting and computation. From the perspective of praxiography, given that both can include code written in other languages (that is, python code can be processed by `knitr`, and `R` code executed in `ipython`), the differences are not crucially important [^3]. This whole book could have been written using just Python, since Python is a popular general purpose programming language, and many statistical, machine learning and data analysis libraries have been written for Python. Widely used Python modules such as NumPy, SciPy, Scikit-learn, open-cv or Pandas  allow anything  done in `R` to be done in Python. It is difficult to generalise about the differences between the two programming languages.  I have used both, sometimes to  highlight  tensions between the somewhat more research-oriented `R` and the more  practical applications typical of Python, and sometimes because code in one language is more easily understood than the other.  
 
While I have read textbooks on machine learning and statistics, how-to books on data analysis, data-mining and machine learning, as well as myriad online documents, research papers, and help files (alongside the work of other scholars, philosophers, anthropologists, sociologists, and media theorists),  I've also attempted  to bring the writing of code and writing about code into proximity in order to see if that proximity or mixture of writing code and writing words makes a practical and a praxiographic difference. If recent theories of code and software as forms of speech, expression or performative utterance are right [@Cox_2012;@Coleman_2012], it should. But how does it make a difference?   Already at various points in this text, different written materials have been juxtaposed, and that is completely normal, indeed, almost unavoidable in any writing. Any textual form is somewhat woven. The question is how weaving through  code in one domain of contemporary technical practice, machine learning, answers the methodological injunctions of keeping the practices present (Mol), maintaining the 'concrete sense of value-attainment' (Whitehead) or allowing 'affective expansion' (Wilson). How does this bring  practices more directly into awareness? 

