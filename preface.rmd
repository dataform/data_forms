# Preface

This book is not an ethnography although it has an ethnographic situation. If it has a field site, it lies close to the places where the writing was done -- in universities, on campuses, in classrooms and online training courses (including MOOCs), and then amidst the books, documents, websites, software manuals and documentation,  and a rather vast accumulation of scientific publications.

Readers familiar with textbooks in computer science and statistics can see the traces of this site in some typographic conventions drawn from the fields I write about. Important conventions include:

1. Typesetting all code and names of devices in a san serif font like `this`;
2. Typesetting all data and the names of datasets in a sans serif font like `this`;
3. Presenting formulae, functions, and equations using the bristling indexicality of mathematical typography

Why emulate the apparatus of science and engineering publication in this way? Social science and humanities researchers normally, even when they are observant participants in their field sites, rarely experience a coincidence between their own writing practices and those of their object of research. The object of study in this book is a knowledge practice that documents itself in code, equations, diagrams and statements circulated in articles, books and various online formats (blogs, wikis, software repositories). 

A dense feedback signal runs through the many propositions, formulations, diagrams, equations, citations and images in this book. I've been writing code for years [@Mackenzie_2006]. Writing code was nearly always something  distant from writing about code.  Recent  developments in ways of analysing and publishing scientific data bring coding and writing closer together, such that implementing things can be done almost  in the same space as writing about those things. This looping between writing code and writing about code brings about sometimes generative, sometimes frustrating, encounters with various scientific knowledge (mathematics, statistics, computer science), with infrastructures on many scales (ranging across networks, databases here and there, hardware and platforms of various kinds, as well as interfaces) and many domains. At many points in researching the book, I digressed a long way into quite technical domains of statistical inference, probability theory, linear algebra, dynamic models as well as database design and data standards. Much of the code I've written in implementing machine learning models or in reconstructing certain data practices does not appear in this text, just as not all of the words I've written in trying to construct arguments or think about data practices has been included. Much has been cut away and left on the ground (although the `git` repository of the book preserves many traces of the writing; see [https://github.com/datapractice/machinelearning](https://github.com/datapractice/machinelearning)). So, like the recipe books, cookbooks, how-tos, tutorials and other documentations I have read, the code, the graphics and the prose have been tidied here. Many exploratory forays are lost and almost forgotten.  Nevertheless, the several years I have spent  writing about data practice has felt substantially different to any other project by virtue of a strong coupling between code in text, and text in code. Practically, this is made possible by working on code and text within the same file, in the same text editor (not a word processing package). Switching between writing  `R` and  Python code (about which I say more below) to retrieve data, to transform it, to produce graphics, to construct models or some kind of graphic image, and within the same file be writing academic prose, might be one way to write about machine learning as a data practice. 

The capacity to mix  text, code and images depends on an ensemble of software tools that differ somewhat from the typical social scientist or humanities researchers' software toolkit of word processor, bibliographic software, image editor and web browser. In particular, it relies on software packages in the `R` programming language such as the '`knitr`' [@Xie_2013; @Xie_2012] and in python, the `ipython` notebook environment [@Perez_2007]. Both have been developed by scientists and statisticians in the name of 'reproducible research.' Many examples of this form of writing can be found on the web: see [IPython Notebook Viewer](http://nbviewer.ipython.org/) for a sample of these. These packages are designed to allow a combination of code written in `R`, python or other programming languages, scientific text (including mathematical formula) and images to be included, and importantly, executed together. In order to do this, they typically combine some form of text formatting or 'markup,' that ranges from very simple formatting conventions (for instance, the 'Markdown' format used in this book is much less complicated than HTML, and uses markup conventions readable as plain text and modelled on email [@Gruber_2004];) to the highly technical (LaTeX, the de-facto scientific publishing format or 'document preparation system' [@Lamport_1986] elements of which are also used here to convey mathematical expressions). They add to that blocks of code and inline code fragments that are executed as the text is formatted in order to produce results that are shown in the text or inserted as figures in the text.[^P1] \index{programming languages!as mode of writing}

In making use of the equipment created by the people I study,  I've attempted  to bring the writing of code and writing about code-like operations into proximity. Does  proximity or mixing of writing code and writing words makes a practical difference to an account of practice?  If recent theories of code and software as forms of speech, expression or performative utterance are right [@Cox_2012;@Coleman_2012], it should. But how does it make a difference? The question is how weaving through  code in one domain of contemporary technical practice, machine learning, confirm to  the methodological injunction to keep the practices present,  to maintain a concrete sense of abstraction  or allow an affective expansion in relation to machines? 

[^P1]: There are a few different ways of weaving together text, computation and images together.  Each suffers from different limitations. In `ipython`, a scientific computing platform dating from 2005 [@Perez_2007] and used across a range of scientific settings, interactive visualization and plotting, as well as access to operating system functions are brought together in a `Python` programming environment. Especially in using the `ipython` notebook, where editing text and editing code is all done in the same window, and the results of changes to code can be seen immediately, practices of working with data can be directly woven together with writing about practice. By contrast, `knitr` generates documents by combining text passages and the results (graphs, calculations, tabulations of data) of code interleaved between the text into one output document. When `knitr` runs, it executes the code and inserts the results (calculations, text, images) in the flow of text. Practically, this means that the text editor used to write code and text, remains somewhat separate from the software that executes the code. By contrast, `ipython` combines text and `Python` code more continuously, but at the cost of editing and writing code and text in a browser window. Most of the conveniences and affordances of text editing software is lost.   While `ipython` focuses on interactive computation, `knitr` focuses on bringing together scientific document formatting and computation. From the perspective of praxiography, given that both can include code written in other languages (that is, python code can be processed by `knitr`, and `R` code executed in `ipython`), the differences are not crucially important [^P3]. This whole book could have been written using just Python, since Python is a popular general purpose programming language, and many statistical, machine learning and data analysis libraries have been written for Python. Widely used Python modules such as NumPy, SciPy, Scikit-learn, open-cv or Pandas  allow anything  done in `R` to be done in Python. It is difficult to generalise about the differences between the two programming languages.  I have used both, sometimes to  highlight  tensions between the somewhat more research-oriented `R` and the more  practical applications typical of Python, and sometimes because code in one language is more easily understood than the other.  \index{programming languages!R} \index{programming languages!Python}
