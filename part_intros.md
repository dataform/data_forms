# Part 1: Data forms of thought and vectoral spaces

- Personify techniques of vectorization
- People vectorize techniques
- Techniques personify vectorization

- intro to the inner product space, vector space

The following three chapters address forms of algorithmic movement in large spaces -- vector spaces.  The chapters describe very commonly used machine learning techniques such as logistic regression, neural networks, decision trees, random forests, support vector machines, and naive Bayes classifiers. These techniques are very widely known, heavily used in many scientific, industry, commercial and media settings. They are the topic of any number of textbooks, online tutorials, video lectures. Even when they are not the objects of attentions, they are often unobtrusively working in the background of scientific research or new technologies. For instance, as I write this in 2014, headlines around the world describe a new blood test  that can predict the onset of Alzheimer's disease well before any existing test. The blood test targets metabolites associated with Alzheimers, and as the paper in _Nature Medicine_ describes it without much further comment,  'metabolites defining the participant groups were selected using the least absolute shrinkage and selection operator (LASSO) penalty' [@mapstone_plasma_2014, 2]. The following three (CHECK THIS) chapters seek to cluster and classify these techniques  in terms of how they move through data. 

Three major forms of movement, albeit problematic ones, stand out against  the background hum of the machines learning. Much of machine learning departs from a geometrical intuition in which data populates $n$-dimensional Euclidean spaces, and algorithms test if lines or planes either fit the distribution of points in space, or more or less cleanly divide different parts of data from each other. It measures distances in order to do this.  A second probabilistic intuition animates many machine learning techniques to construct statistical models of the random processes that gave rise to the data. Here the data is generated by random variables more or less interacting with each other. Probability distributions variously shape random variables, and complicated topographies  that arise as different distributions conjoin or intersect. In this statistical space, machine learning models seek to track, traverse or map the curves, peaks and valley of the complicated joint distributions. Finally, a decisionist/rule-oriented technique move through data by constructing rules that classify and cut the space 'piecewise.' This mode of moving through the data is less geometrical and less statistically-oriented, but also somewhat more easily understood since the rules take the form of a series of (usually) binary decisions. 

The geometric, probabilistic and decisionist forms of movement feed into each other, borrow from each other, and with various abstractions can be converted into each other. All of them, however, inhabit 
### References

wark
toscano



# Part 2: Modes of ordering

- large brain
- deep reconstruction
- distribution - liveness and learning

## References

- Howard, Norvig, Ayasda person