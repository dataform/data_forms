<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Machine Learning: Archaeology of a Data Practice</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Machine Learning: Archaeology of a Data Practice">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Machine Learning: Archaeology of a Data Practice" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Machine Learning: Archaeology of a Data Practice" />
  
  
  

<meta name="author" content="Adrian Mackenzie">


<meta name="date" content="2016-12-10">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="28-genomic-knowledges-and-their-datasets.html">
<link rel="next" href="30-cross-validating-machine-learning-in-genomics.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="1-acknowledgments.html"><a href="1-acknowledgments.html"><i class="fa fa-check"></i><b>1</b> Acknowledgments</a></li>
<li class="chapter" data-level="2" data-path="2-preface.html"><a href="2-preface.html"><i class="fa fa-check"></i><b>2</b> Preface</a></li>
<li class="chapter" data-level="3" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html"><i class="fa fa-check"></i><b>3</b> Introduction: Into the Data</a><ul>
<li class="chapter" data-level="3.1" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#three-accumulations-settings-data-and-devices"><i class="fa fa-check"></i><b>3.1</b> Three accumulations: settings, data and devices</a></li>
<li class="chapter" data-level="3.2" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#who-or-what-is-a-machine-learner"><i class="fa fa-check"></i><b>3.2</b> Who or what is a machine learner?</a></li>
<li class="chapter" data-level="3.3" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#algorithmic-control-to-the-machine-learners"><i class="fa fa-check"></i><b>3.3</b> Algorithmic control to the machine learners?</a></li>
<li class="chapter" data-level="3.4" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#the-archaeology-of-operations"><i class="fa fa-check"></i><b>3.4</b> The archaeology of operations</a></li>
<li class="chapter" data-level="3.5" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#asymmetries-in-common-knowledge"><i class="fa fa-check"></i><b>3.5</b> Asymmetries in common knowledge</a></li>
<li class="chapter" data-level="3.6" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#what-cannot-be-automated"><i class="fa fa-check"></i><b>3.6</b> What cannot be automated?</a></li>
<li class="chapter" data-level="3.7" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#different-fields-in-machine-learning"><i class="fa fa-check"></i><b>3.7</b> Different fields in machine learning?</a></li>
<li class="chapter" data-level="3.8" data-path="3-introduction-into-the-data.html"><a href="3-introduction-into-the-data.html#the-diagram-in-critical-thought"><i class="fa fa-check"></i><b>3.8</b> The diagram in critical thought</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html"><i class="fa fa-check"></i><b>4</b> Diagramming machines}</a><ul>
<li class="chapter" data-level="4.1" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#we-dont-have-to-write-programs"><i class="fa fa-check"></i><b>4.1</b> ‘We don’t have to write programs’?</a></li>
<li class="chapter" data-level="4.2" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-elements-of-machine-learning"><i class="fa fa-check"></i><b>4.2</b> The elements of machine learning</a></li>
<li class="chapter" data-level="4.3" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#who-reads-machine-learning-textbooks"><i class="fa fa-check"></i><b>4.3</b> Who reads machine learning textbooks?</a></li>
<li class="chapter" data-level="4.4" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#r-a-matrix-of-transformations"><i class="fa fa-check"></i><b>4.4</b> <code>R</code>: a matrix of transformations</a></li>
<li class="chapter" data-level="4.5" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-obdurate-mathematical-glint-of-machine-learning"><i class="fa fa-check"></i><b>4.5</b> The obdurate mathematical glint of machine learning</a></li>
<li class="chapter" data-level="4.6" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#cs229-2007-returning-again-and-again-to-certain-features"><i class="fa fa-check"></i><b>4.6</b> CS229, 2007: returning again and again to certain features</a></li>
<li class="chapter" data-level="4.7" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-visible-learning-of-machine-learning"><i class="fa fa-check"></i><b>4.7</b> The visible learning of machine learning</a></li>
<li class="chapter" data-level="4.8" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-diagram-of-an-operational-formation"><i class="fa fa-check"></i><b>4.8</b> The diagram of an operational formation</a></li>
<li class="chapter" data-level="4.9" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#vectorisation-and-its-consequences"><i class="fa fa-check"></i><b>4.9</b> Vectorisation and its consequences}</a></li>
<li class="chapter" data-level="4.10" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#vector-space-and-geometry"><i class="fa fa-check"></i><b>4.10</b> Vector space and geometry</a></li>
<li class="chapter" data-level="4.11" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#mixing-places"><i class="fa fa-check"></i><b>4.11</b> Mixing places</a></li>
<li class="chapter" data-level="4.12" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#truth-is-no-longer-in-the-table"><i class="fa fa-check"></i><b>4.12</b> Truth is no longer in the table?</a></li>
<li class="chapter" data-level="4.13" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-epistopic-fault-line-in-tables"><i class="fa fa-check"></i><b>4.13</b> The epistopic fault line in tables</a></li>
<li class="chapter" data-level="4.14" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#surface-and-depths-the-problem-of-volume-in-data"><i class="fa fa-check"></i><b>4.14</b> Surface and depths: the problem of volume in data</a></li>
<li class="chapter" data-level="4.15" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#vector-space-expansion"><i class="fa fa-check"></i><b>4.15</b> Vector space expansion</a></li>
<li class="chapter" data-level="4.16" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#drawing-lines-in-a-common-space-of-transformation"><i class="fa fa-check"></i><b>4.16</b> Drawing lines in a common space of transformation</a></li>
<li class="chapter" data-level="4.17" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#implicit-vectorization-in-code-and-infrastructures"><i class="fa fa-check"></i><b>4.17</b> Implicit vectorization in code and infrastructures</a></li>
<li class="chapter" data-level="4.18" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#lines-traversing-behind-the-light"><i class="fa fa-check"></i><b>4.18</b> Lines traversing behind the light</a></li>
<li class="chapter" data-level="4.19" data-path="4-diagramming-machines.html"><a href="4-diagramming-machines.html#the-vectorised-table"><i class="fa fa-check"></i><b>4.19</b> The vectorised table?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html"><i class="fa fa-check"></i><b>5</b> Machines finding functions}</a><ul>
<li class="chapter" data-level="5.1" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#learning-functions"><i class="fa fa-check"></i><b>5.1</b> Learning functions</a></li>
<li class="chapter" data-level="5.2" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#supervised-unsupervised-reinforcement-learning-and-functions"><i class="fa fa-check"></i><b>5.2</b> Supervised, unsupervised, reinforcement learning and functions</a></li>
<li class="chapter" data-level="5.3" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#which-function-operates"><i class="fa fa-check"></i><b>5.3</b> Which function operates?</a></li>
<li class="chapter" data-level="5.4" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#what-does-a-function-learn"><i class="fa fa-check"></i><b>5.4</b> What does a function learn?</a></li>
<li class="chapter" data-level="5.5" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#observing-with-curves-the-logistic-function"><i class="fa fa-check"></i><b>5.5</b> Observing with curves: the logistic function</a></li>
<li class="chapter" data-level="5.6" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#the-cost-of-curves-in-machine-learning"><i class="fa fa-check"></i><b>5.6</b> The cost of curves in machine learning</a></li>
<li class="chapter" data-level="5.7" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#curves-and-the-variation-in-models"><i class="fa fa-check"></i><b>5.7</b> Curves and the variation in models</a></li>
<li class="chapter" data-level="5.8" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#observing-costs-losses-and-objectives-through-optimisation"><i class="fa fa-check"></i><b>5.8</b> Observing costs, losses and objectives through optimisation</a></li>
<li class="chapter" data-level="5.9" data-path="5-machines-finding-functions.html"><a href="5-machines-finding-functions.html#gradients-as-partial-observers"><i class="fa fa-check"></i><b>5.9</b> Gradients as partial observers</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-the-power-to-learn.html"><a href="6-the-power-to-learn.html"><i class="fa fa-check"></i><b>6</b> The power to learn</a></li>
<li class="chapter" data-level="7" data-path="7-probabilisation-and-the-taming-of-machines.html"><a href="7-probabilisation-and-the-taming-of-machines.html"><i class="fa fa-check"></i><b>7</b> Probabilisation and the Taming of Machines}</a></li>
<li class="chapter" data-level="8" data-path="8-data-reduces-uncertainty.html"><a href="8-data-reduces-uncertainty.html"><i class="fa fa-check"></i><b>8</b> Data reduces uncertainty?</a></li>
<li class="chapter" data-level="9" data-path="9-machine-learning-as-statistics-inside-out.html"><a href="9-machine-learning-as-statistics-inside-out.html"><i class="fa fa-check"></i><b>9</b> Machine learning as statistics inside out</a></li>
<li class="chapter" data-level="10" data-path="10-distributed-probabilities.html"><a href="10-distributed-probabilities.html"><i class="fa fa-check"></i><b>10</b> Distributed probabilities</a></li>
<li class="chapter" data-level="11" data-path="11-naive-bayes-and-the-distribution-of-probabilities.html"><a href="11-naive-bayes-and-the-distribution-of-probabilities.html"><i class="fa fa-check"></i><b>11</b> Naive Bayes and the distribution of probabilities</a></li>
<li class="chapter" data-level="12" data-path="12-spam-when-foralln-is-too-much.html"><a href="12-spam-when-foralln-is-too-much.html"><i class="fa fa-check"></i><b>12</b> Spam: when <span class="math inline">\(\forall{N}\)</span> is too much?</a></li>
<li class="chapter" data-level="13" data-path="13-the-improbable-success-of-the-naive-bayes-classifier.html"><a href="13-the-improbable-success-of-the-naive-bayes-classifier.html"><i class="fa fa-check"></i><b>13</b> The improbable success of the Naive Bayes classifier</a></li>
<li class="chapter" data-level="14" data-path="14-ancestral-probabilities-in-documents-inference-and-prediction.html"><a href="14-ancestral-probabilities-in-documents-inference-and-prediction.html"><i class="fa fa-check"></i><b>14</b> Ancestral probabilities in documents: inference and prediction</a></li>
<li class="chapter" data-level="15" data-path="15-statistical-decompositions-bias-variance-and-observed-errors.html"><a href="15-statistical-decompositions-bias-variance-and-observed-errors.html"><i class="fa fa-check"></i><b>15</b> Statistical decompositions: bias, variance and observed errors</a></li>
<li class="chapter" data-level="16" data-path="16-does-machine-learning-construct-a-new-statistical-reality.html"><a href="16-does-machine-learning-construct-a-new-statistical-reality.html"><i class="fa fa-check"></i><b>16</b> Does machine learning construct a new statistical reality?</a></li>
<li class="chapter" data-level="17" data-path="17-patterns-and-differences.html"><a href="17-patterns-and-differences.html"><i class="fa fa-check"></i><b>17</b> Patterns and differences</a></li>
<li class="chapter" data-level="18" data-path="18-splitting-and-the-growth-of-trees.html"><a href="18-splitting-and-the-growth-of-trees.html"><i class="fa fa-check"></i><b>18</b> Splitting and the growth of trees</a></li>
<li class="chapter" data-level="19" data-path="19-differences-in-recursive-partitioning.html"><a href="19-differences-in-recursive-partitioning.html"><i class="fa fa-check"></i><b>19</b> 1984: Differences in recursive partitioning</a></li>
<li class="chapter" data-level="20" data-path="20-limiting-differences.html"><a href="20-limiting-differences.html"><i class="fa fa-check"></i><b>20</b> Limiting differences</a></li>
<li class="chapter" data-level="21" data-path="21-the-successful-dispersion-of-the-support-vector-machine.html"><a href="21-the-successful-dispersion-of-the-support-vector-machine.html"><i class="fa fa-check"></i><b>21</b> The successful dispersion of the support vector machine</a></li>
<li class="chapter" data-level="22" data-path="22-differences-blur.html"><a href="22-differences-blur.html"><i class="fa fa-check"></i><b>22</b> Differences blur?</a></li>
<li class="chapter" data-level="23" data-path="23-bending-the-decision-boundary.html"><a href="23-bending-the-decision-boundary.html"><i class="fa fa-check"></i><b>23</b> Bending the decision boundary</a></li>
<li class="chapter" data-level="24" data-path="24-instituting-patterns.html"><a href="24-instituting-patterns.html"><i class="fa fa-check"></i><b>24</b> Instituting patterns</a></li>
<li class="chapter" data-level="25" data-path="25-regularizing-and-materializing-objects.html"><a href="25-regularizing-and-materializing-objects.html"><i class="fa fa-check"></i><b>25</b> Regularizing and materializing objects}</a></li>
<li class="chapter" data-level="26" data-path="26-genomic-referentiality-and-materiality.html"><a href="26-genomic-referentiality-and-materiality.html"><i class="fa fa-check"></i><b>26</b> Genomic referentiality and materiality</a></li>
<li class="chapter" data-level="27" data-path="27-the-genome-as-threshold-object.html"><a href="27-the-genome-as-threshold-object.html"><i class="fa fa-check"></i><b>27</b> The genome as threshold object</a></li>
<li class="chapter" data-level="28" data-path="28-genomic-knowledges-and-their-datasets.html"><a href="28-genomic-knowledges-and-their-datasets.html"><i class="fa fa-check"></i><b>28</b> Genomic knowledges and their datasets</a></li>
<li class="chapter" data-level="29" data-path="29-the-advent-of-wide-dirty-and-mixed-data.html"><a href="29-the-advent-of-wide-dirty-and-mixed-data.html"><i class="fa fa-check"></i><b>29</b> The advent of ‘wide, dirty and mixed’ data</a></li>
<li class="chapter" data-level="30" data-path="30-cross-validating-machine-learning-in-genomics.html"><a href="30-cross-validating-machine-learning-in-genomics.html"><i class="fa fa-check"></i><b>30</b> Cross-validating machine learning in genomics</a></li>
<li class="chapter" data-level="31" data-path="31-proliferation-of-discoveries.html"><a href="31-proliferation-of-discoveries.html"><i class="fa fa-check"></i><b>31</b> Proliferation of discoveries</a></li>
<li class="chapter" data-level="32" data-path="32-variations-in-the-object-or-in-the-machine-learner.html"><a href="32-variations-in-the-object-or-in-the-machine-learner.html"><i class="fa fa-check"></i><b>32</b> Variations in the object or in the machine learner?</a></li>
<li class="chapter" data-level="33" data-path="33-whole-genome-functions.html"><a href="33-whole-genome-functions.html"><i class="fa fa-check"></i><b>33</b> Whole genome functions</a></li>
<li class="chapter" data-level="34" data-path="34-propagating-subject-positions.html"><a href="34-propagating-subject-positions.html"><i class="fa fa-check"></i><b>34</b> Propagating subject positions}</a></li>
<li class="chapter" data-level="35" data-path="35-propagation-across-human-machine-boundaries.html"><a href="35-propagation-across-human-machine-boundaries.html"><i class="fa fa-check"></i><b>35</b> Propagation across human-machine boundaries</a></li>
<li class="chapter" data-level="36" data-path="36-competitive-positioning.html"><a href="36-competitive-positioning.html"><i class="fa fa-check"></i><b>36</b> Competitive positioning</a></li>
<li class="chapter" data-level="37" data-path="37-a-privileged-machine-and-its-diagrammatic-forms.html"><a href="37-a-privileged-machine-and-its-diagrammatic-forms.html"><i class="fa fa-check"></i><b>37</b> A privileged machine and its diagrammatic forms</a></li>
<li class="chapter" data-level="38" data-path="38-varying-subject-positions-in-code.html"><a href="38-varying-subject-positions-in-code.html"><i class="fa fa-check"></i><b>38</b> Varying subject positions in code</a></li>
<li class="chapter" data-level="39" data-path="39-the-subjects-of-a-hidden-operation.html"><a href="39-the-subjects-of-a-hidden-operation.html"><i class="fa fa-check"></i><b>39</b> The subjects of a hidden operation</a></li>
<li class="chapter" data-level="40" data-path="40-algorithms-that-propagate-errors.html"><a href="40-algorithms-that-propagate-errors.html"><i class="fa fa-check"></i><b>40</b> Algorithms that propagate errors</a></li>
<li class="chapter" data-level="41" data-path="41-competitions-as-examination.html"><a href="41-competitions-as-examination.html"><i class="fa fa-check"></i><b>41</b> Competitions as examination</a></li>
<li class="chapter" data-level="42" data-path="42-superimposing-power-and-knowledge.html"><a href="42-superimposing-power-and-knowledge.html"><i class="fa fa-check"></i><b>42</b> Superimposing power and knowledge</a></li>
<li class="chapter" data-level="43" data-path="43-ranked-subject-positions.html"><a href="43-ranked-subject-positions.html"><i class="fa fa-check"></i><b>43</b> Ranked subject positions</a></li>
<li class="chapter" data-level="44" data-path="44-conclusion-out-of-the-data.html"><a href="44-conclusion-out-of-the-data.html"><i class="fa fa-check"></i><b>44</b> Conclusion: Out of the Data}</a></li>
<li class="chapter" data-level="45" data-path="45-machine-learners.html"><a href="45-machine-learners.html"><i class="fa fa-check"></i><b>45</b> 250,000 machine learners</a></li>
<li class="chapter" data-level="46" data-path="46-a-summary-of-the-argument.html"><a href="46-a-summary-of-the-argument.html"><i class="fa fa-check"></i><b>46</b> A summary of the argument</a></li>
<li class="chapter" data-level="47" data-path="47-in-situ-hybridization.html"><a href="47-in-situ-hybridization.html"><i class="fa fa-check"></i><b>47</b> In-situ hybridization</a></li>
<li class="chapter" data-level="48" data-path="48-critical-operational-practice.html"><a href="48-critical-operational-practice.html"><i class="fa fa-check"></i><b>48</b> Critical operational practice?</a></li>
<li class="chapter" data-level="49" data-path="49-obstacles-to-the-work-of-freeing-machine-learning.html"><a href="49-obstacles-to-the-work-of-freeing-machine-learning.html"><i class="fa fa-check"></i><b>49</b> Obstacles to the work of freeing machine learning</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning: Archaeology of a Data Practice</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-advent-of-wide-dirty-and-mixed-data" class="section level1">
<h1><span class="header-section-number">29</span> The advent of ‘wide, dirty and mixed’ data</h1>
<p>We can see this referential cross-validation at work in the shape of genomic data. The DNA microarray data extensively modelled in the final chapter of <em>Elements of Statistical Learning</em> highlights some elementary problems of shape associated with genomic data. The <code>iris</code> dataset <span class="citation">[@Fisher_1936]</span>, perhaps the most heavily used pedagogical dataset in the literature, does not provoke the infrastructural contortions associated with Google Compute, or for that matter, the highly sophisticated and quite subtle treatment of gene expression we find in genomics-related machine learning.</p>

<p>It is usual, in working with <code>iris,</code> to construct machine learners that use the variables from the first four columns shown in table  to infer the value of the <code>Species</code> response variable (as seen in Chapter 5, where a decision tree was constructed using this same dataset). The measurements of petals and sepals of the irises of the Gaspé Peninsula in Novia Scotia, and their classification into different species is perhaps a typical mid-twentieth century biological procedure. Even in the excerpt shown in Table , we can see that it is quite narrow as it has only a few columns, the data is nearly all of one type (measurements of lengths and widths), and the data is clean (there are no missing values). <code>Iris</code> is typical of classic statistics and much biological data prior to genomics in its relatively homogeneity and distinct partitioning. </p>
<p>If <code>iris</code> is the conventional statistical form, how does a genomic dataset differ? One clue comes from descriptions of the <code>RF-ACE</code> algorithm, first published in 2009. RF_ACE is attempts to deal with ‘modern data sets’ that are ‘wide, dirty, mixed with both numerical and categorical predictors, and may contain interactive effects that require complex models’ <span class="citation">[@Tuv_2009, 1341]</span>. Such algorithms and the ‘wide, dirty, mixed’ datasets they work on have an irregular texture, which, I would suggest, we should try to grasp if we want to understand how genomic data constitutes a complex volume ‘in which heterogeneous regions are superposed’ <span class="citation">[@Foucault_1972, 128]</span>. Clues to the irregularity of genomic data come from the various treatments of DNA microarray data in <em>Elements of Statistical Learning</em>. </p>
<p>Hastie and co-authors introduce one microarray dataset they use in this way:</p>
<blockquote>
<p>The data in our next example form a matrix of 2308 genes (columns) and 63 samples (rows), from a set of microarray experiments. Each expression value is a log-ratio log(R/G). R is the amount of gene-specific RNA in the target sample that hybridizes to a particular (gene-specific) spot on the microarray, and G is the corresponding amount of RNA from a reference sample. The samples arose from small, round blue-cell tumors (SRBCT) found in children, and are classified into four major types: BL (Burkitt lymphoma), EWS (Ewing’s sarcoma), NB (neuroblastoma), and RMS (rhabdomyosarcoma). There is an additional test data set of 20 observations. We will not go into the scientific background here <span class="citation">[@Hastie_2009, 651]</span></p>
</blockquote>
<p>Note that while the number of samples (~80) in the small round blue-cell tumors (<code>SRBT</code>) <span class="citation">[@Khan_2001]</span> dataset is less than the number of flowers measured in <code>iris,</code> the number of variables presented by the columns in the table (2308) is much greater.  Hastie and co-authors, like the Google I/O demonstration, do not ‘go into the scientific background.’ Scientific knowledge <em>per se</em> is not the central concern in machine learning. Rather, genomic data as a field or emergence and differentiation in the production of statements matters. The original publication of this dataset in 2001 <span class="citation">[@Khan_2001]</span> also made use of machine learning techniques (neural networks, a major topic in the next chapter ), precisely in order to address the diagnostic problem of distinguishing different tumors types without resort to new experiments or biological knowledge.<a href="#fn84" class="footnoteRef" id="fnref84"><sup>84</sup></a></p>

<p>The sample of the <code>SRBCT</code> data shown in table  does not readily accommodate the width of the dataset. Unlike <code>iris</code>, the thousands of variables simply cannot be displayed on a page or screen. <em>Wide</em> datasets are quite common in machine learning settings generally, but particularly common in genomics where in a given study there might only be a relatively small number of biological samples but a huge amount of sequencer or microarray data for each sample. Much genomic data shares this generic feature of width.<a href="#fn85" class="footnoteRef" id="fnref85"><sup>85</sup></a></p>

<p>In contrast to the direct measurements of petals and sepals in the <code>iris</code> data, the <code>SRBCT</code> data incorporates and diagonally connects many levels of practice.  The columns in table  refer to genes whose levels of expression in different samples are measured and then grouped by comparison to their levels in a reference sample (see the hierarchical clustering  of the data shown in figure .) Even the identification of the several thousand genes whose levels of expression are measured by the microarray experiments presupposes much preceding work on DNA sequences and the identification of protein-coding DNA regions amidst the highly repetitive vector of the genome sequence. Highly leveraged infrastructures for access to biological data underpin such datasets. Considered more diagrammatically, genomes in many ways becomes less linear or flat than the bare base DNA sequences might suggest.</p>
</div>
<div class="footnotes">
<hr />
<ol start="85">
<li id="fn85"><p>Importantly, as discussed in Chapter  (in terms of the diagonalization running between different elements of code, data, mathematical functions and indexical signs) and in Chapter  (in terms of the auratic power of datasets), the fact that these datasets can be so readily loaded and accessed via bioinformatic infrastructures using code written in <code>R</code> or <code>Python</code> is also a notable feature of their advent in the machine learning literature. Even a social science researcher can quickly write programs to retrieve this data. It attests to several decades, if not longer, work on databases, web and network infrastructures, and analytical software, all, almost without exception, driven by the desire for aggregation, integration, archiving and annotation of sequence data that first became highly visible in the Human Genome Project of the 1990s. The brevity of these lines of code that retrieve and load datasets – half a dozen statements in <code>R</code>, no more – suggests we are dealing with a high-sedimented set of practices, not something that has to be laboriously articulated, configured or artificed. Code brevity almost always signposts highly-trafficked routes in contemporary network cultures.  Without describing in any great detail the topography of databases, protocols and standards woven by and weaving through bioinformatics, the ready invocation of genomic datasets suggests that the mixed, dirty, wide datasets fed to algorithms such as <code>RF-ACE</code> or analysed in <span class="citation">[@Hastie_2009]</span> derives from the layered couplings and interweaving of scientific publications and scientific databases developed by biological science over the last three decades. As the code shows, sequence and other genomic data are available to scientists not only as users searching for something in particular and retrieving specific data, but to scientists as programmers developing ways of connecting up, gathering and integrating many different data points into to produce the wide ( many-columned), mixed (different types of data), and dirty (missing data, data that is ‘noisy’) datasets, datasets whose heterogeneous and often awkward topography then elicits and invites algorithmic treatment.<a href="29-the-advent-of-wide-dirty-and-mixed-data.html#fnref85">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="28-genomic-knowledges-and-their-datasets.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="30-cross-validating-machine-learning-in-genomics.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
