# Optimising machine learners

## Introduction
In an article in _Subjectivity_, Vinciane Adams, Michelle Murphy and Adele Clarke urge consideration of the contemporary time in terms of 'regimes of anticipation' [@adams_anticipation_2009]. In a discussion that bears some affinities to Nigel Thrift's _Knowing Capitalism_ [@thrift_knowing_2005], they suggest we are witnessing and are subject to a wide-ranging shift from regimes of truth to regimes of anticipation:  'anticipation ... emerges at a moment of actuarial saturation, when one realizes that the sciences of the actual can be abandoned or ignored to be replaced by a knowledge that the truth about the future can be known by way of the speculative forecast, itself relying on proliferating modes of prediction' [@adams_anticipation_2009,247]. Their characterisation of anticipation is expansive and nuanced. It highlights how the feeling of what happens, and orientations to the future are affected by modes of speculation authorised by anticipation. While they describe the implications most directly in terms of biomedicine and technosciences, versions of what they describe can also be found in finance, security, marketing, media and entertainment. Anticipation is comprehensively fractalised through all these domains in ways that are interlinked, imitative and often entangled. Given their panoramic viewpoint, Adams et. al. offer much less detail how the anticipation regime is actually done in practice. Drawing on C.S. Peirce, they say anticipation works through a form of _abduction_, which involves the process of 'reasoning temporally from data gathered about the past to simulations or probabilistic anticipations of the future that in turn demand action in the present' [@adams_anticipation_2009, 255]. Prediction is perhaps the most highly valued abductive operation. While not all anticipation is completely predictive (for instance, promises or hopes are anticipatory without being necessarily predictive), and not all abduction is predictive, simulations and predictions are key components of the regime of anticipation.

In several respects, the practices of programmers are instructive. First of all, the shift from 'regimes of truth to regimes of anticipation in which anticipation is formed through modes of prediction ' (260) relies on and is legible in software and software development practices. Software is one place where abductive reasoning is rendered operational and perhaps contested. Knowledge, truth, speculation and prediction are practically re-configured through programming and coding. Secondly, when Adams et.al. say '*one realizes* that knowledges of the actual can be replaced by modes of prediction' [emphasis added], the 'one' remains an impersonal pronoun. Software developers, I suggest, are one of the groups who personify direct awareness of the regime of anticipation and some of its associated problems. They build predictive systems increasingly targetted on individual actions, sentiments and desires rather than stratified population aggregates (and we will see some predictive systems in the vignettes below). Implementing such systems brings with it the realization that they might apply to oneself. One might realize that one's own actions, behaviours, desires and belief can be predicted. To inhabit the regime of anticipation as a predictive practitioner or as an agent of anticipation puts prediction and anticipation in a tightly coupled recursive loop. From those loops, and the technical practices they involve, we might learn more about living in anticipation.

## Software: from program to machine learning

It is well-known that software and code connects people, things, systems, places and events. For reasons I will not discuss in much detail, these trajectories are often convoluted and multiple. The sub-field of software studies [@mackenzie_cutting_2006; @fuller_software_2007; @berry_philosophy_2011; @chun_programmed_2011] as well as the field of science and technology studies have developed various ways of mapping and tracking these trajectories by observing coding practices as well as tracking tropes and figures of control and power through software. Related work by anthropologists highlights the social practices and norms associated with software development, particularly in free and open source software [@coleman_code_2009; @kelty_two_2008]. There is an increasing volume of critical work on software and code [@mackenzie_codes_2011]. In much of the extant work, analysis of algorithms, data structures and protocols have been antidotes to overly general talk about information society, network cultures or digital economy. In general, studies of software have argued that by including  technical objects and operations such as algorithms, data structures or protocols [@galloway_protocol_2004] in the analysis, we gain much stronger insight into  how software accrues agential force or cultural value. 

This chapter shares that starting point, although it adds one thing:  I focus here on how programmers as agents in the regime of anticipation also act on themselves in machine learning. The paper draws on presentations by software developers at industry conferences such as 'Predictive Analytics World' for  programmers and software developers; it describes online programming competitions to write predictive systems, and it traces some links between programming practices and academic research in academic disciplines such as statistics and computer science. I read these events and practices against a wider background of media reports and gray literature on software and programming. Although I have not done ethnographic field research, I have participated in several machine learning competitions as a competitor, and in particular, made extensive use of a programming language called R that is popular in machine learning. 

There are possibly a range of subject positions available to agents of anticipation, from prominent software developers who enjoy mainstream media attention to individuals whose participation in on-line forums is the only evidence we have of their work on predictive software. Here are the words of Hilary Mason, Chief Scientist at bitly.com (a social media platform), at a London conference in 2012 called 'Bacon: Things Developers Love':

>You have all of these things that are different – engineering, infrastructure, mathematics and computer science, curiosity and an understanding of human behaviour – that is something that usually falls under the social sciences. At the intersection of all these things are wonderful people. But we're starting to develop something new, and that is - not that all of these things have not been done for a very long time - but we are only just now building systems where people, individual people, have all of these tools in one package, in one mind. And there are lots of reasons this is happening now. But its a pretty exciting time to be in any of these things. (Hilary Mason, Chief Scientist, bitly.com) [@bacon_hilary_2012]

In front of an audience of several hundred software developers, she describes shifts in the work of programming associated with the growth of large amounts of data associated with 'human behaviour.' At the centre of this shift stand 'wonderful people' who combine practices and knowledges of communication infrastructure, technology, statistics, and 'human behaviour' through curiosity and technical skills.  Mason was, in effect, telling her audience of software developers who they should become. The title of her talk was 'machine learning for hackers', and her audience were those hackers or programmers. A change in programming practice - 'machine learning' - is the key to programmers becoming the wonderful people, agents of their own time, capable of doing what is only now just possible because it is all together in 'one package, one mind.' Here, I would tentatively suggest, Mason adumbrates the outline of an agent of anticipation, someone at the intersection of network infrastructure, mathematics and human behaviour. Mason, one of _Fortune_ magazines 'Top 40 under 40' business leaders to watch [@cnn_40_2011] also featured in _Glamour_, a teenage fashion magazine [@mason_im_2011], personifies such a wonderful person.

The actual technical practices Mason goes on to describe in her talk all revolve around machine learning. Machine learning itself stands at the intersection of computer science and statistics. Machine learning is closely entangled with the regime of anticipation. In its contemporary manifestations, this field hardly resembles its origins in the older computer science project of artificial intelligence (AI). The long-standing AI question of how to get machines to 'learn' is less important in machine learning today [TBA - refs]. Rather, machine-learning is largely focused on optimizing the predictive power of statistical models. In contrast to the many imaginings of artificial intelligence as some form of omniscient expert, the mundane and increasingly pervasive use of machine learning in diverse domains of social media, finance, security, many natural, clinical and engineering sciences, is largely in the service of increased *predictivity*. By predictivity, I refer not to  prediction as such, but to the scope and diversity of prediction. Predictivity is gauged less by verification, than by optimisation. In typical machine learning approaches, machines predict by rapidly assaying many statistical models in order to select optimal combinations of the variables found in large datasets. Large datasets are produced by online practice, by high-throughput research projects in the physical, life, clinical and field sciences, or by the proliferating networked mobile devices such as smart phones. In these increasingly diverse data flows, where the possible combinations or aggregations of data are difficult to manage, finding signals amidst noise is difficult. Standard programming techniques of sorting, indexing, counting, and searching have built the information retrieval systems that both support and trigger these data flows. But these standard programming techniques are ineffective in marshalling order amidst so-called 'big data.' The scale of the data not only calls for different infrastructures (the data centre, the cloud, the 'cluster'), but for different forms of programming thought and practice. Machine learning still has to be programmed by someone, but it is programmed differently. We can learn quite a lot about how prediction works in  the regime of anticipation by examining these shifts. 

## R: programming as intersectional practice

Mason speaks of having many different things in 'one package, one mind' for the first time. While I am interested in the 'one mind,' I start with a version of the 'one package', which I exemplify in terms of a  programming language called R [@r_development_core_team_r_2010]. A programming language, and in particular a statistical programming language such as R, might not be of immediate general interest to all readers.  What is legible in R, and other similar technical platforms, are how  predictive predictive practices come together to implement the regime of anticipation. By empirically exploring a particular way of programming _abductively_,(rather than Java, Python, or some other   programming language widely used in software development) we might access some of the profound transformations in statistical practice associated with machine learning. Much contemporary statistical research and practice, including machine learning - is carried out in R. The history of statistics has been closely studied [@hacking_taming_1990; @stigler_history_1986; @daston_how_1994; @desrosieres_politics_1998; @porter_trust_1996]. Historians have detailed the intimate entanglement of statistics with notions of population, normality, race, and intelligence, to name a few. But the transformation of statistics as a set of empirical techniques focused on population and governmentality into machine learning as a generic set of domain-agnostic predictive practices is much more recent. In the last two decades, machine learning has quickly propagated across various domains, and is now widely used in scientific, government and commercial settings, sometimes under different names such as data mining or predictive analytics, but also in a bewildering variety of largely obscure minor ways. Contemporary incarnations of machine learning are increasingly interwoven with social media in ways that impinge on millions if not billions of people's everyday actions, perceptions, habits and practices (as we will see in the vignettes drawn from Facebook and Google below). Some of this is legible in the ecology of practice clustered around R, and can be tracked there in detail.

Investment of time and effort to learning programming languages tells us something about how programmers see themselves and identify themselves to other programmers. The growth of R epitomises a shift in programming cultures. Like many others, R is an open source programming language, a computing environment and a cluster of code libraries focused on statistics.  R itself is almost 15 years old, roughly the same age as popular programming languages Java or Python, and it inherits much from an earlier statistical computing language, S, developed in the 1980s. In the last few years R has attracted much more wider commercial interest [@muenchen_popularity_2011]. As evidenced by the bulging blogroll at R-bloggers.com, R has also become much more than a tool to do laboratory data analysis or to teach statistics. R as programming language and R as comprehensively networked archive of data analysis packages (approximately 3000 in CRAN – Comprehensive R Archive Network [@cran_comprehensive_2010]) have become a thriving ecology of  predictive practice. In R, statistical methods, data manipulation tricks, data extraction techniques and code for graphics and visualization rapidly move laterally between diverse fields of high and low sciences, industry, government and media. Code and scripts, often very quickly traverse research, commercial and non-commercial operational settings. In the R, statistics is clearly in the service of traditional domains of governmentality or the biopolitics of population, but also in the service of entertainment and finance. R, with its several thousand packages, with its cross-platform builds, and with its very rapid absorption of the latest advances in statistical technique, data structures, and sources of data fields (twitter feeds, googleVis, pubmed API, World Bank data, etc.) offers a guiding thread to contemporary practices of anticipation. The centripetal flow of methods in R is itself one sign of exuberant optimism about data more generally, an excitement that largely directly embraces shifts towards a regime of anticipation, and more my purposes, the increasing visibility of R is exemplifies a 'system where ... individual people have all these tools in one package'. 


## Predictive Analytics World, 2009

In contrast to the largely research ethos in which R originated, at the 'Predictive Analytics World' conference, San Francisco in February 2009, high-end analytics software vendors– Spotfire, SAS, IBM, Oracle – are on hand alongside various businesses that use prediction such as Google and Facebook [@prediction_impact_inc_predictive_2009]. Although not explicitly articulated as such, the common theme of this conference is prediction for profit. The papers and presentation at this conference all focus in one way or another on increasing predictivity in social media, or online commerce. In the 'Encounters with R' session, run by the Bay Area UseR! Group, the panel of speakers come from Google, Facebook and Revolution Incorporated, a company set up to commercialise a version of the open source statistics programming language and platform R. The speakers are all R programmers and they talk about how they use R to work on data gathered in their respective enterprises.

The first speaker, a Google 'economics group' researcher, Bo Cowgill, sketches how Google uses 'prediction methods' to refine their search engine offering so that people  more often find what they want.  His talk locates the usage of R at Google firmly in the domain of machine learning. 'We don't use R in production', comments Cowgill, 'and we don't use R to pull data, but a huge use is in tuning models and classifiers.' Google uses 'tons of different classifiers throughout its business' Cowgill continues, and 'the features used by those classifiers will be generated by R'. 'Google is also very into analysing experiments and doing randomised tests ... you know to change the color of the ad text, or something like that,and R is used a lot to analyse those.'  Predicting and experimenting with what people want from search queries or from ads entails constructing models and finding 'features.' Although Cowgill's description of R again tells us little about how what specific models are made or what goes into them, his  description of 'classifiers' and 'finding features' at Google refers to common general predictive problems addressed in machine learning. Classifiers - machine learning processes that assign cases to categories -- abound in machine learning applications. Similarly, the desire to optimize prediction, often by small incremental amounts such as 5%,  leads to intense attention to the problem of 'feature selection,' which means finding those variables in  a model that have higher predictive power.

While Google's use of R to build classifiers or select features seems very generic (it  seems as if Cowgill is reluctant to disclose much detail), the Facebook speaker, Itamar Rosenn, describes on a single prediction problem in details. After a boom year in 2007, Facebook noticed in early 2008 that the 'users were dropping at a faster rate'. Rosenn describes how the first extensive use of R in 2008 by the Facebook analytics team to do predictive work focused on the problem of user retention. The Facebook data analyst, Itamar Rosenn, describes how Facebook statistically models it's users using R: 'we use R about 15% of the time and almost exclusively for exploratory data analyses.' A basic question for Facebook is whether a given individual will come back to Facebook after registering. Although hundreds of millions of people register, how many people actually do anything on Facebook? A second question or 'predictive task', to use Rosenn's words, is 'how do we predict the level of activity the users had on Facebook if they stayed, where level of activity is number of sessions, total session time, number of actions, where action is posting a photo, or writing on somebody's wall or commenting on somebody's action' [@prediction_impact_inc_predictive_2009]. Facebook's business depends on 'user retention', which means people visiting Facebook.com often. 

The technical practices used to predict what individuals will do can both tell us how people are materialised as a bundle of features, and how the people that practice predictivity - the programmers and data analysts- implement prediction. Rosenn introduces the use of R at Facebook in terms of too much data: Facebook has diverese data on hundreds of millions of users. In many machine learning settings, the problem is not simply too many individuals or members of the population, but choosing which of the many different kinds of data can  be used predictively. In their use of R, the Facebook analysts acknowledge that this problem has no easy solution. Therefore, in modelling whether users would return to Facebook, Rosenn and his co-workers drew on an R software package called lars. The lars package, standing for "Least Angle Regression," was developed in 2007 by statistical machine learning researchers at Stanford University, and in particular, by a leading figure in the field of machine learning, Trevor Hastie [@hastie_elements_2009]. The relevant scientific publications date from 2004 [@efron_least_2004]. One year later in  2008, Facebook was already using _lars_ to model user responsiveness, and to predict who will return to Facebook and who won't. The shift from scientific publication by academic statisticians to code in R and then to code at Facebook is rapid. It only takes a few years before a purely research-driven undertaking, lars, ends up affecting what people are doing in social media. Again, in an indication of the vortext of predictive practices associated with machine learning, R users such as Rosenn actively move these methods between academic and commercial work.  

How _lars_ selects relevant 'features' that best predict user actions can also tell us something about modes of prediction. To explore retention amongst Facebook's users, Rosen looked closely at everything that happens to a person on the site after registration. Facebook users are characterised by hundreds of variables, only some of which are classical demographic ones such as age, sex or occupation. This abundance of variables is both  The *Least Angle Regression* approach is used as a way of selecting amongst many possible models of the data at hand. As the authors of the original LARS algorithm write, 'typically we have available a large collection of possible covariates from which we hope to select a parsimonious set for the efficient prediction of a response variable. Least Angle Regression (LARS), a new model selection algorithm, is a useful and less greedy version of traditional forward selection methods' [@efron_least_2004]. Similarly Rosenn: 'the reason that lars was useful is that our dataset has a huge number of variables.' In other words, the Least Angle Regression technique allows them to try many different combinations of variables captured from user data and user activity on the site, and quickly choose an optimum combination. The 'response variable' they seek – whether someone will return to Facebook after registering – is estimated not by simply building a model that predicts, but trying very many predictive models in an algorithmically controlled order. As is typical in machine learning approaches,  Least Angle Regression  automatically builds and tests many different models in order to minimise the  chances of some sub-optimal result. In this case, a sub-optimal result would be to select a model of user behaviour that did not effectively predict whether a given user will return to Facebook. In the regime of anticipation, predictivity comes from validating every possible combination of circumstances against the criteria of prediction error.
 
The results of Rosenn's modelling work apply to software developers as agents of anticipations. A good predictor for someone returning to the site was playing with '3rd party apps': 'if the user started incorporating our platform and 3rd party features into their daily usage early on, this was a sign of user who understands the site and is going to do a lot of activity.' The best predictor, hardly surprisingly, of someone returning to site often is whether they are 'reached out to by a large number of people.' Facebook is, after all, social media. But if people 'spend too much time interacting with apps, and not actually communicating with people, they're probably not going to find too much value in the site.' That is, they 'drop off.' In other words, if you spend too much time playing with software - as programmers do - and not with people, you are not as likely to return to your Facebook page.

## Kaggle: what will programmers do?

We could understand the predictive practices discussed by Hilary Mason or at 'Predictive Analytics World' as simply another attempt to tap into the  economic value of data produced by sciences, media, government and commerce. But as I have suggested above, technical practices also shape the subjectivity of their practitioners. How would such a process be legible? In regimes of anticipation, programmers construct models that predict what people will do. As we have just seen, they bring to bear largely statistical models that transform tables of data on events, actions, behaviours, beliefs and desires into correlations, clusters, classes, imputed values, inferences and scores of various kinds. These mathematico-regulatory constructs are operational forms of anticipation. But despite their seemingly incontestable abstraction, the forms of programmed anticipation have their own fluidity, lability and mutability. While statistical machine learning methods and techniques promise predictivity, the proliferation of techniques and methods risks shattering the very possibility of control. In a sense, the very reason a programming language such as R excites software developers – it makes available so many statistical machine learning methods that promise to corral data – also potentially undermines their investment in it. There is so much code, there are so many packages, so many different ways of modelling and visualizing a given situation, each with its own advantages and disadvantages. The tension here between aggressive control over data in the name of anticipation, and the potential for open-ended free association in data is quite marked.

From this perspective, it should come as no surprise that machine learning itself as a predictive practice has become a matter of prediction and optimisation. In machine learning and data mining, as in many other domains, competitions are one way that highly technical challenges are addressed. Often these competition are associated with academic events such as conferences. Sometimes they are associated with programmer recruitment, as in the 'Google Code jam' [@google_google_2012] that each year attracts tens of thousands of programmers. Increasingly, programming work is also allocated through competitive outsourcing sites such as Topcoder, 'the world's largest competitive commmunity for software development and digital creation' [@topcoder_inc_topcoder_2012]. A social media platform called 'Kaggle' stages machine learning competitions [@kaggle_inc_description_2011].  The list of competitions on Kaggle provides a general snapshot of anticipatory projects in the world of big data. Kaggle sponsors data-mining or statistical analysis competitions ranging across health data, chess ratings, tourism, grant application outcomes, dark matter, essay scoring and the progression of HIV infections. Like bitly.com's Hilary Mason, Kaggle's founder and CEO, Anthony Goldbloom, attracts media attention. In 2012, he was one of _Forbes_ magazines '30 under 30' leading technology entrepreneurs [@barrett_30_2012]. 

In 2011, the data blog Dataist.com sponsored a Kaggle machine learning competition called 'R Package Recommendation Engine.' In the case of the 'R Package Recommendation Engine' competition, competitors were supplied with meta-data from the R CRAN repository describing which of the several thousand R packages available there were installed by 52 R users. Competitors were tasked to use this so-called 'training data' to build a predictive model of what programmers would do with R. Having modelled this sample population, competitors were meant to predict what packages would be installed by another a much larger group of R users, describing in the 'test data.' The underlying idea here is that a 'recommendation engine' suggest to new users of R  what R packages they should install. The predictions produced by the 'R Package Recommendation Engine' would in some ways, however modestly, address an object - machine learning - that is problematically multiple and open-ended. In this competition, what programmers do as they install - and perhaps use - R packages become features or predictors for a machine learning problem.  It seems then that one response to the newly acquired popularity of R in the regime of anticipation is an attempt to re-anchor it in the stabilizing form of a machine learning model. In other words, the possibility of the divergent, free-associating play of methods in R is reorganised by machine learning to predict what programmers will want. Predictive practice can be applied to the agents of anticipation themselves.

Winners of Kaggle competitions often write statements describing what they did to win. The winner of the 'R Package Recommendation Engine' competition, under the name 'OneOldDog,' describes himself as 'a computer scientist with over 48 years of programming experience and more than 25 years doing machine learning and predictive analytics. Now that I am retired from full-time employment, I have endeavored to keep my skills sharp by participating in machine learning and data mining contests' [@kaggle_inc_dave_2011]. OneOldDog goes onto to describe how he used the 'same core forecasting technology that I've employed in other contests.' The third placed competitor, 'lib-GUNDAM,' is in a very different situation: 'I recently got my Bachelor degree from National Taiwan University (NTU). ... Noticing that the machine learning society lacks software on various kinds of algorithms that may be beneficial to our daily life, I am now developing pieces of tools that compile various state-of-the-art algorithms performing well in many data or contests. One of these pieces is lib-GUNDAM' [@kaggle_inc_how_2011]. Using his software lib-GUNDAM, lib-GUNDAM managed to develop a successful model to predict what software packages other programmers should use. The contrast between OneOldDog and lib-GUNDAM is marked by differences in age, differences in software production (old vs fresh code), reasons for participation (keep skills sharp vs the needs of 'the machine learning society'). If OneOldDog's enthusiastic participation (he made 55 different models) seems to be a return to a familiar scene (more than 25 years of machine learning), lib-GUNDAM  he/she writes code 'beneficial to our daily life' because it is 'state-of-the-art.'

There are other examples of this recursive application of predictive practice to agents of anticipation. For instance, a later competition at Kaggle was sponsored by Facebook, under the banner 'Facebook Recruiting Competition: Show Them Your Talent Not Your Resume' [@kaggle_inc_description_2012]. Given a dataset of describing friend-relations between the people ('a directed social graph'), the challenge is 'to make ranked predictions for each user in the test set of which other users they would want to follow' [@kaggle_inc_description_2012]. The prize for this competition is not money, but a job interview at Facebook. This is another case where the agents of anticipation, those who implement predictivity, show how they are in turn subjectified through their own attachments.  In both cases - the package recommendation competition or the Facebook recruitment competition - there is a striking symmetry between the situation faced by Facebook users, and R programmers, the 'useRs'. Once the practices of programming are also processed in a predictive analytics recommendation engine, unruly predictive practices can be brought into the regime of anticipation itself. This is both stultifying and exciting since it places programmers themselves in the same impasse as all the other inhabitants of regimes of anticipation. UseRs become more like users with calculable response rates and retention ratios. Self-abductively, useR!s become users. 

## Conclusion

[@adams_anticipation_2009] write: 'anticipation is rapidly reconfiguring technoscientific and biomedical practices as a totalizing orientation' (248). The subject-form of programming experiences both excitement and threat from machine learning. We see in the conferences, the presentations, and in the machine learning competitions the operation of exuberant attachments and burgeoning affirmations of machine learning as predictive practice. Machine learning appears there as an object of desire or 'a cluster of promises' [@berlant_nearly_2007,2]. The voices and people that I have drawn on this chapter - Bo McGill, Itamar Rosenn, David Smith, OneOldDog, lib-GUNDAM, or Hilary Mason - are the more or less prominent proponents of this optimism. In her address to the London Dataweek Conference, Hilary Mason, sought to motivate the audience of developers, hackers and programmers by describing them as the 'wonderful people' who bring together mathematics, statistics, programming, curiosity and an understanding of human behaviour. 

Highlighting the temporality of regimes of anticipation, [@adams_anticipation_2009] repurpose C.S Peirce's notion of abduction. For Peirce, abduction is making a hypothesis to account for data [@peirce_essential_1998, 102]. But for Adams, Murphie and Clarke, 'abduction thrives in the vibrations between the is and the ought, consummately modern yet augmented by anticipation in ways that undermine the certainties on which modernity thrives' [@adams_anticipation_2009, 255]. Here abductive reasoning is less about certainties, and more about optimising predictions. The question I have been pursuing, however, is what it means to implement or practice abduction in the name of anticipation. Machine learning, I have been suggesting, is a generically abductive practice in the sense that it remains agnostic in relation to field of application, and makes no claims about certainties, only about the potential of prediction, predictivity. As we have seen, abductive processes can be applied by programmers to themselves in a process of self-abduction.

Exploration of technical practices helps understand processes of subjectivation in two senses. First, a new technical practice acts as a cluster of promises. Second, when we follow technical operations, such as the implementation of a predictive model or a classifier, we select features of technical practice to attend to, and we find ways of connecting them to other zones of contemporary life. The connections we make between these practices and lives are largely about showing how investments in conventional forms can readily adopt a semblance of newness or novelty, yet whose realization encounters frictions, obstacles, slippages and delays attest to a plurality of related differences. This chapter has attempted to make some connections between promise and existing convention. In describing the encounter between promises of newness and conventions in machine learning, we address the question: what does it mean for people to live abductively? 

While machine learning is reassuringly and glowingly presented as a solution to the contemporary problem of making sense of lives lived at the intersection of infrastructures, media, sciences and markets, it also suffers failures. Programming machine learning is hard. Mason describes work in this area as wearing: 'this is a field where we have hit a wall, diminished, developed again, hit another wall, diminished, developed again' [@bacon_hilary_2012]. The cost of attachment to predictive practice is a wearing rhythm that Hilary Mason describes as hitting a wall, and being diminished. It is  worthwhile, I suggest, thinking about what the internalisation of abduction means for subjectivity. What does the banality of competing for a job interview using machine learning to predict future friendships say about subject formation? Rather than simply a positional swap in which the knowing subject becomes the object of abductive knowing, lived abduction might intensify an impasse associated with the regime of anticipation.  Here it seems that programmers engage in self-abduction. The generic predictive capacity of machine learning can be turned in almost any direction, including on programmers themselves. This _might_ be a more general situation, not something specific to programmers working on contemporary data flows. The cultural theorist Lauren Berlant describes the 'space of time' of cruel optimism and its exuberant attachments as 'a white noise machine that provides assurance that what seems like threat ... is, after all, a rhythm people can enter into while they're dithering, tottering, bargaining, testing, or otherwise being worn out by the promises that they have attached to in this world' [@berlant_nearly_2007, 23]. Optimism about optimisation through machine learning may well help programmers get into that rhythm.

I have sought here, in descriptions of contemporary machine learning, to articulate a position that is neither simply critical or conformist, but dispassionately sympathetic to the problems of privilege enjoyed by 'the wonderful people', software developers as agents of anticipation. Like many similar actors - experts, managers, bureaucrats, scientists, including social scientists - the programmers I have been describing often live conventionally privileged lives. They inhabit material trajectories that vibrate to the rhythms of anticipation. Their desirable skills bind them rather tightly to the intersection of infrastructures, sciences, markets and behaviours.  At times, they also almost unwittingly engage in transformations of the positions they occupy. Programmers tend to encounter this possibility as they implement predictivity in the regime of anticipation. Their burdensome privilege directly exposes them to abduction, including the possibility of self-abduction.  But there are  other ways of inhabiting these material trajectories that are not directly subsumed by the regime of anticipation. Again, software developers, as they struggle with the proliferation of machine learning techniques, are interesting test cases here. Insofar as they make something like machine learning just part of their toolkit, into one set of relatively banal techniques amongst others, they can begin to open up something that deviates from anticipation. It is hard to imagine - or anticipate - what un-anticipatory regimes will look like. No doubt programmers alone cannot make a good life. Yet there is perhaps some hope that in making machine learning so much more banal, so much more  ordinary in their work, they also make anticipation more transparent, more problematic, less monolithic and less demanding on our time.

## References


