PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT	PM
B	Ishibuchi, H; Nakashima, T; Nii, M		Smith, MH; Gruver, WA; Hall, LO		Ishibuchi, H; Nakashima, T; Nii, M			Learning of neural networks with GA-based instance selection	JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5			English	Proceedings Paper	9th International-Fuzzy-Systems-Association World Congress/20th North-American-Fuzzy-Information-Processing-Society, International Conference	JUL 25-28, 2001	VANCOUVER, CANADA	Int Fuzzy Syst Assoc, N Amer Fuzzy Informat Proc Soc, IEEE Syst, Man & Cybernet Soc, IEEE, Neural Networks Council			GENETIC ALGORITHMS; SET	We examine the effect of instance and feature selection on the generalization ability of trained neural networks for pattern classification problems. Before the learning of neural networks, a genetic-algorithm-based instance and feature selection method is applied for reducing the size of training data. Nearest neighbor classification is used for evaluating the classification ability of subsets of training data in instance and feature selection. Neural networks are trained by the selected subset (i.e., reduced training data). In this paper, we first explain our GA-based instance and feature selection method. Then we examine the effect of instance and feature selection on the generalization ability of trained neural networks through computer simulations on various artificial and real-world pattern classification problems.	Univ Osaka Prefecture, Dept Ind Engn, Sakai, Osaka 5998531, Japan	Ishibuchi, H (reprint author), Univ Osaka Prefecture, Dept Ind Engn, Gakuen Cho 1-1, Sakai, Osaka 5998531, Japan.						CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Goldberg D. E., 1989, GENETIC ALGORITHMS S; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ishibuchi H., 2001, INSTANCE SELECTION C, P95; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Weiss SM, 1991, COMPUTER SYSTEMS LEA; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	13	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7078-3				2001							2102	2107				6	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BT52S	WOS:000173245100371		
J	Al-Ammar, AS; Barnes, RM				Al-Ammar, AS; Barnes, RM			Supervised cluster classification using the original n-dimensional space without transformation into lower dimension	JOURNAL OF CHEMOMETRICS			English	Article						supervised cluster analysis; direct clustering in original space	MILK	A novel supervised classification algorithm, direct clustering in n-dimensional space (DCNS), was developed for difficult data sets where conventional methods of supervised clustering are expected to fail. The method is based, when applied on >3-dimensional spaces, on an algorithm that performs special treatment on the measurement space, so that the treated space can allow a computer-aided clustering methodology similar to that used by human vision, However, unlike other techniques that reduce the dimensionality of the space, the proposed method preserves the original dimensions while performing a computer-simulated human vision clustering in the original n-dimensional space. Thus the overlap between clusters that results from the dimensionality reduction is eliminated. The proposed method was applied to two real data sets. The results are compared with those obtained using principal component analysis (PCA), an artificial neural network (ANN), and the k-nearest-neighbor (KNN) technique. On one data set containing only two clusters, the DCNS algorithm gives better cluster separation than the other three methods. However, when all four methods were applied on the second data set, containing eight different clusters, PCA, ANN and KNN were unable to give useful cluster separation, while the DCNS method was able to separate all clusters and classify the unknown points successfully with their corresponding clusters. The DCNS technique is able to perform other important cluster analysis tasks, such as testing the discriminatory power of a variable, selecting one variable from many, and conducting preliminary unsupervised clustering. Copyright (C) 2000 John Wiley & Sons, Ltd.	Univ Massachusetts, Lederle Grad Res Ctr Towers, Dept Chem, Amherst, MA 01003 USA	Barnes, RM (reprint author), Univ Massachusetts, Lederle Grad Res Ctr Towers, Dept Chem, Box 34510, Amherst, MA 01003 USA.						Amarasiriwardena D, 1997, CAN J ANAL SCI SPECT, V42, P69; Beebe K. R., 1998, CHEMOMETRICS PRACTIC, P56; BEEBE KR, 1998, CHEMOMETRICS PRACTIC, P180; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMINE D, 1993, J CHEMOMETR, V7, P227, DOI 10.1002/cem.1180070402; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; HOFFMAN K, 1975, ANAL EUCLIDEAN SPACE, P153; KOHNEN T, 1982, BIOL CYBERN, V43, P59; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; Lutter C, 1998, CHEMOSPHERE, V37, P1761, DOI 10.1016/S0045-6535(98)00241-0; MARESDEN JE, 1974, ELEMENTARY CLASSICAL, P61; MEGLEN RR, 1991, J CHEMOMETR, V5, P163, DOI 10.1002/cem.1180050305; Watanabe S., 1985, PATTERN RECOGNITION; Werbos P. J., 1982, System Modeling and Optimization. Proceedings of the 10th IFIP Conference; Wold S., 1977, ACS SYM SER, V52, P243, DOI DOI 10.1021/BK-1977-0052.CH012; ZHU EY, 1993, CHEM J CHINESE U, V14, P621; ZUPAN J, 1993, NEURAL NETWORKS CHEM, P171	17	2	3	0	1	JOHN WILEY & SONS LTD	W SUSSEX	BAFFINS LANE CHICHESTER, W SUSSEX PO19 1UD, ENGLAND	0886-9383			J CHEMOMETR	J. Chemometr.	JAN	2001	15	1					49	67		10.1002/1099-128X(200101)15:1<49::AID-CEM631>3.0.CO;2-2		19	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	397VR	WOS:000166718900005		
S	Romero, E; Raymackers, JM; Macq, B; Cuisenaire, O			IEEE; IEEE; IEEE	Romero, E; Raymackers, JM; Macq, B; Cuisenaire, O			Automatic fibrosis quantification by using a k-NN classificator	PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-4: BUILDING NEW BRIDGES AT THE FRONTIERS OF ENGINEERING AND MEDICINE	PROCEEDINGS OF ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY		English	Proceedings Paper	23rd Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society	OCT 25-28, 2001	ISTANBUL, TURKEY	Natl Sci Fdn, TUBITAK, Sci & Tech Res Ctr Turkey, ISIK Univ, COMNET, EREL Techno Grp, GUZEL SANATLAR Printinghouse, JOHNSON&JOHNSON Med, PFIZER, SIEMENS Med, TURKCELL Iletism Hizmetler A S, ALSTOM Elect Ltd Co, GANTEK Technol & SUN Microsyst, TURCOM Co Grp		automatic morphometry; fibrosis morphometry; muscle measurements; k-NN	MUSCULAR-DYSTROPHY; EFFICIENT	This work presents an automatic algorithm to measure fibrosis in muscle sections of mdx mice, a mutant species used as a model of the Duchenne dystrophy. The algorithm described herein automatically segments three different tissues: Muscle cell tissue (MT), Pure collagen fiber deposit (CD) and cellular infiltrates surrounded by loose collagen deposit (CI), by using a statistical classifier based on the k-Nearest Neighbour (k-NN) decision rule in the RGB color space. The algorithm is trained by selecting a number of correctly classified pixels from each class. The k-NN rule classifies other pixels in the class that is most represented among the k nearest training samples in the RGB space, which is efficiently implemented with a fast k-distance transform algorithm. All extracted areas are quantified in absolute (mum(2)) and relative (%) values. For validation of this method, the different tissues were manually segmented and their quantifications statistically compared with those obtained automatically. Statistical analysis showed inter-operator variability in manual segmentation. Automatic quantifications of the same areas did not differ significantly from their mean manual evaluations. In conclusion, this method produce fast, reliable and reproducible results.	Univ Catholique Louvain, Commun & Remote Sensing Lab, Louvain, Belgium	Romero, E (reprint author), Univ Catholique Louvain, Commun & Remote Sensing Lab, Louvain, Belgium.		RAYMACKERS, JEAN-MARC/I-6079-2015	RAYMACKERS, JEAN-MARC/0000-0003-4377-8966			BELKASIM SO, 1992, PATTERN RECOGN, V25, P1269, DOI 10.1016/0031-3203(92)90028-H; CORNELIO F, 1984, ANN NEUROL, V16, P694, DOI 10.1002/ana.410160612; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUISENAIRE O, 2000, P 10 EUR SIGN PROC C, P1365; CULLEN MJ, 1975, J NEUROL SCI, V24, P179, DOI 10.1016/0022-510X(75)90232-4; Emery AEH, 1993, DUCHENNE MUSCULAR DY; FIEDMAN J, 1975, IEEE T COMPUT, V24, P1000; FIX E, 1951, AF41128131 USAF SCH; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GUNDERSEN HJG, 1988, APMIS, V96, P379; HAGEMAN ATM, 1993, J NEUROL SCI, V115, P95, DOI 10.1016/0022-510X(93)90072-7; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JIANG QY, 1993, PATTERN RECOGN LETT, V14, P531, DOI 10.1016/0167-8655(93)90101-I; MARKESBERY WR, 1977, NEUROLOGY, V27, P727; Nyengaard JR, 1999, J AM SOC NEPHROL, V10, P1100; REMUZZI A, 1995, KIDNEY INT, V48, P155, DOI 10.1038/ki.1995.279; Romano LA, 1996, J HISTOTECHNOL, V19, P121; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0; Weibel ER, 1989, STEREOLOGICAL METHOD	20	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1094-687X		0-7803-7211-5	P ANN INT IEEE EMBS			2001	23		1-4				2609	2612				4	Cardiac & Cardiovascular Systems; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Neurosciences	Cardiovascular System & Cardiology; Computer Science; Engineering; Neurosciences & Neurology	BV41G	WOS:000178871900710		
B	Marsh, R		Arabnia, HR		Marsh, R			Improved correlation target rejection using neural net post-processing	PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS I AND II			English	Proceedings Paper	International Conference on Imaging Science, Systems, and Technology (CISST 2001)	JUN 25-28, 2001	LAS VEGAS, NV	Comp Sci Res, Educ & Applicat Press, Int Technol Inst, Korea Informat Processing Soc, World Acad Sci Informat Technol, PACT Corp		optical correlation; matched filters; pattern recognition; neural networks	INVARIANT PATTERN-RECOGNITION; CIRCULAR HARMONIC EXPANSION; FOURIER-MELLIN DESCRIPTORS; TRANSFORMS; ALGORITHM; ROTATION; NETWORKS	An improvement on the scale and rotation tolerant correlation inethodfirst proposed by Casesent and Psaltis[1] is presented. In computer simulations, using a target set of 26 scaled and rotated objects (1820 images total), a non-target set of 10 scaled and rotated objects (700 images total), the system accurately identified targets with 88.4% accuracy and rejected non-targets with 95.6% accuracy, We preprocess the target and reference images with a centering algorithm, a log-polar transform, and a modified median filter. The resulting image data is correlated using a typical 4-f correlator and post-processed by a neural network.	Univ N Dakota, Dept Comp Sci, Grand Forks, ND 58201 USA	Marsh, R (reprint author), Univ N Dakota, Dept Comp Sci, Grand Forks, ND 58201 USA.						AGUI T, 1991, SPIE, V1606, P188; Altmann J., 1987, Journal of Information Processing and Cybernetics, V23; APICELLA A, 1989, P SOC PHOTO-OPT INS, V1092, P252; BOOTH JJ, 1995, P SOC PHOTO-OPT INS, V2490, P108; BROUSIL JK, 1967, IEEE TRANS ELECTRON, VEC16, P818, DOI 10.1109/PGEC.1967.264726; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156; COTTRELL DM, 1987, APPL OPTICS, V26, P3755, DOI 10.1364/AO.26.003755; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta B, 1996, J I EL TELECOM ENG, V42, P3; Goodman J. W., 1968, INTRO FOURIER OPTICS; GRACE AE, 1991, PATTERN RECOGN LETT, V12, P635, DOI 10.1016/0167-8655(91)90018-H; HORNER JL, 1984, APPL OPTICS, V23, P812; HSU YN, 1982, APPL OPTICS, V21, P4016, DOI 10.1364/AO.21.004016; HSU YN, 1982, APPL OPTICS, V21, P4012, DOI 10.1364/AO.21.004012; JUELL P, 2000, P INT C IM SCI SYST; KUMAR BVKV, 1992, APPL OPTICS, V31, P4773, DOI 10.1364/AO.31.004773; MARSH R, 1990, Patent No. 07545013; MEHANIAN C, 1991, SPIE, V1471, P200; MINNIX JI, 1991, VISUAL COMMUNICATION, V1606, P241; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Pratt W. K., 1978, DIGITAL IMAGE PROCES, P526; Schalkoff R. J., 1989, DIGITAL IMAGE PROCES, P279; SCHILS GF, 1988, J OPT SOC AM A, V5, P1309, DOI 10.1364/JOSAA.5.001309; SHENG Y, 1986, J OPT SOC AM A, V3, P771, DOI 10.1364/JOSAA.3.000771; SHENG YL, 1991, J OPT, V22, P223, DOI 10.1088/0150-536X/22/5/003; THORNTON AL, 1997, 6 INT C IM PROC ITS; TITCHMARSH EC, 1959, INTRO THEORY FOURIER; VANDERLUGT A, 1964, IEEE T INFORMATION T, V10, P130; WALSH TR, 1990, OPT ENG, V29, P1052; WHALEN AD, 1971, DETECTION SIGNALS NO, P167; Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0; Zell A., 1995, SNNS STUTTGART NEURA	33	0	0	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-892512-74-2				2001							419	425				7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BT32W	WOS:000172651200068		
J	Tomppo, E; Korhonen, KT; Heikkinen, J; Yli-Kojola, H				Tomppo, E; Korhonen, KT; Heikkinen, J; Yli-Kojola, H			Multi-source inventory of the forests of the Hebei Forestry Bureau, Heilongjiang, China.	SILVA FENNICA			English	Article						forest inventory; satellite images; k-nearest neighbour method; models; China		A multi-source forest inventory method is applied to the estimation of forest resources in the area of the Hebei Forest Bureau in Heilongjiang province in North-East China. A stratified systematic cluster sampling design was utilised in field measurements. The design was constructed on the basis of information from earlier stand-level inventories, aerial orthophotographs, experiences from other sampling inventories and the available budget. Sample tree volumes were estimated by means of existing models. New models were constructed and their parameters estimated for tallied tree volumes and volume increments. The estimates for the area of the Bureau were computed from field measurements. and for the areas of the forest farms estimated from field measurements and satellite images. A k-nearest neighbour method was utilised. This method employing satellite image data makes it possible to estimate all variables, particularly for smaller areas than that possible using field measurements only. The methods presented, or their modifications, could also be applied to the planning and realisation of forest inventories elsewhere in Temperate or Boreal zones. The inventory in question gave an estimate of 114 m(3)/ha (the multi-source inventory 119 m(3)/ha) instead of 72 m(3)/ha as previously estimated from available information. Totally nineteen tree species, genera of species or tree species groups were identified (Appendix 1). The forests were relatively young, 60% of them younger than 40 years and 85% younger than 60 years.	Finnish Forest Res Inst, FIN-00170 Helsinki, Finland	Tomppo, E (reprint author), Finnish Forest Res Inst, Uninioninkatu 40 A, FIN-00170 Helsinki, Finland.	erkki.tomppo@metla.fi					Cochran W. G., 1977, SAMPLING TECHNIQUES, V3rd; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; CUNIA T, 1987, ESTIMATION TRESS BIO, P37; DUDANI SA, 1976, IEEE T SYST MAN CYB, V6, P121; European Commission, 1997, STUD EUR FOR INF COM; KILKKI P, 1987, REMOTE SENSING AIDED, P209; KORHONEN KT, 1990, SILVA FENNICA, V25, P77; KORHONEN KT, 1993, UNPUB FIELD INSTRUCT; KUJALA M, 1980, FOLIA FORESTALIA, V441; LAPPI J, 1991, SAMPLE PLOT SIZE STA; Loetsch F, 1973, FOREST INVENTORY, V2; MATEM B, 1947, MEDDELANDEN FRAN STA, V36; MATEM B, 1986, LECT NOTES STAT, V36; PAIVINEN R, 1987, PUBLICATIONS SCI, V11; Poso S., 1978, COMMUNICATIONES I FO, V93; Poso S., 1972, COMMUNICATIONES I FO, V76; Ranneby B., 1987, STUDIA FORESTALIA SU, V177; RANNEBY B, 1981, 21 SWED U AGR SCI SE; SALMINEN S, 1985, SILVA FENNICA, V19, P226; Schreuder HT, 1993, SAMPLING METHODS MUL; SVENSSON SA, 1988, 46 SWED U AGR SCI DE; TOMPPO E, 1998, FOLIA FORESTALIA B, V2, P293; TOMPPO E, 1997, STUDY EUROPEAN FORES, P145; TOMPPO E, 1996, IUFRO 20 WORLD C 6 1; Tomppo E., 1991, INT ARCH PHOTOGRAMME, V28, P419; TOMPPO E, 1994, INVENTORY RESULTS HE	27	20	22	0	1	FINNISH SOC FOREST SCIENCE-NATURAL RESOURCES INST FINLAND	VANTAA	PO BOX 18, FI-01301 VANTAA, FINLAND	0037-5330	2242-4075		SILVA FENN	Silva. Fenn.		2001	35	3					309	328		10.14214/sf.587		20	Forestry	Forestry	482NH	WOS:000171581900005		
B	Vuori V; Laaksonen, J; Oja, E; Kangas, J			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Vuori, V; Laaksonen, J; Oja, E; Kangas, J			Speeding up on-line recognition of handwritten characters by pruning the prototype set	SIXTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, PROCEEDINGS			English	Proceedings Paper	6th International Conference on Document Analysis and Recognition (ICDAR)	SEP 10-13, 2001	SEATTLE, WA	Int Assoc Pattern Recognit				This work describes a prototype-based online handwritten character recognition system and a two-phase recognition scheme aimed to speed up the recognition. In the first phase, the prototype set is pruned and ordered on the basis of preclassification performed with heavily down-sampled characters and prototypes. In the second phase, the final classification is perforated without down-sampling by using the reduced set of prototypes. Two down-sampling methods, a linear and nonlinear one, have been analyzed to see their properties regarding the recognition time and accuracy.	Helsinki Univ Technol, Lab Comp & Informat Sci, FIN-02015 Helsinki, Finland	Vuori V (reprint author), Helsinki Univ Technol, Lab Comp & Informat Sci, POB 5400, FIN-02015 Helsinki, Finland.	vuokko.vuori@hut.fi; jorma.laaksonen@hut.fi; erkki.oja@hut.fi; jari.a.kangas@nokia.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRANKISH C, 1995, P ACM CHI 95 C HUM F; Kohonen T., 1997, SPRINGER SERIES INFO, V30; LAAKSONEN J, 1998, P INT C ART NEUR NET, P245; LaLomia M.J., 1994, P ACM CHI 94 HUM FAC, P107; MACKENZIE IS, 1994, INT J HUM-COMPUT ST, V41, P775, DOI 10.1006/ijhc.1994.1081; Sankoff D, 1983, TIME WARPS STRING ED; Vuori V., 2000, P 7 INT WORKSH FRONT, P13; Vuori V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791907; VUORI V, 1999, THESIS HELSINKI U TE; Webster RG, 1998, PATTERN RECOGN, V31, P193, DOI 10.1016/S0031-3203(97)00036-8	11	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1263-1				2001							501	505				3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BT06N	WOS:000171845000096		
J	Vaid, TP; Burl, MC; Lewis, NS				Vaid, TP; Burl, MC; Lewis, NS			Comparison of the performance of different discriminant algorithms in analyte discrimination tasks using an array of carbon black-polymer composite vapor detectors	ANALYTICAL CHEMISTRY			English	Article							PATTERN-RECOGNITION; CLASSIFICATION	An array of 20 compositionally different carbon black-polymer composite chemiresistor vapor detectors was challenged under laboratory conditions to discriminate between a pair of extremely similar pure analytes (H2O and D2O), compositionally similar mixtures of pairs of compounds, and low concentrations of vapors of similar chemicals. Several discriminant algorithms were utilized, including it nearest neighbors (kNN, with K = 1), linear discriminant analysis (LDA, or Fisher's linear discriminant), quadratic discriminant analysis (QDA), regularized discriminant analysis (RDA, a hybrid of LDA and QDA), partial least squares, and soft independent modeling of class analogy (SIMCA). H2O and D2O were perfectly classified by most of the discriminants when a separate training and test set was used. As expected, discrimination performance decreased as the analyte concentration decreased, and performance decreased as the composition of the analyte mixtures became more similar. RDA was the overall best-performing discriminant, and LDA was the best-performing discriminant that did not require several cross-validations for optimization.	CALTECH, Div Chem & Chem Engn, Pasadena, CA 91125 USA	Lewis, NS (reprint author), CALTECH, Div Chem & Chem Engn, Pasadena, CA 91125 USA.		Vaid, Thomas/G-9523-2012				AEBERHARD S, 1993, J CHEMOMETR, V7, P99, DOI 10.1002/cem.1180070204; Albert KJ, 2000, CHEM REV, V100, P2595, DOI 10.1021/cr980102w; BURNS JA, 1993, CHEM REV, V93, P2583, DOI 10.1021/cr00024a001; CAREY WP, 1987, ANAL CHEM, V59, P1529, DOI 10.1021/ac00138a010; CAREY WP, 1986, ANAL CHEM, V58, P3077, DOI 10.1021/ac00127a037; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Doleman BJ, 1998, P NATL ACAD SCI USA, V95, P5442, DOI 10.1073/pnas.95.10.5442; Doleman BJ, 1998, ANAL CHEM, V70, P4177, DOI 10.1021/ac971204+; Duda R. O., 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FRANK I E, 1989, Journal of Chemometrics, V3, P463, DOI 10.1002/cem.1180030304; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; Livingstone D., 1995, DATA ANAL CHEM APPL; Lonergan MC, 1996, CHEM MATER, V8, P2298, DOI 10.1021/cm960036j; LORBER A, 1986, ANAL CHEM, V58, P1167, DOI 10.1021/ac00297a042; Severin EJ, 2000, ANAL CHEM, V72, P658, DOI 10.1021/ac9910278; VAID T, UNPUB; WEAST RC, 1986, CRC HDB CHEM PHYSICS; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wold S., 1977, ACS SYM SER, V52, P243, DOI DOI 10.1021/BK-1977-0052.CH012; Wu W, 1996, ANAL CHIM ACTA, V329, P257, DOI 10.1016/0003-2670(96)00142-0	23	35	35	2	8	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700			ANAL CHEM	Anal. Chem.	JAN 15	2001	73	2					321	331		10.1021/ac000792f		11	Chemistry, Analytical	Chemistry	391QE	WOS:000166366000028	11199985	
J	Wong, KD; Cox, DC				Wong, KD; Cox, DC			Two-state pattern-recognition handoffs for corner-turning situations	IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY			English	Article						handoffs; handovers; land mobile radio cellular systems; land mobile radio propagation factors; pattern recognition	ALGORITHMS	Handoff algorithms are used in wireless cellular systems to decide when and to which base station to handoff. Traditional handoff algorithms generally cannot keep both the average number of unnecessary handoffs and the handoff decision delay low. They do not exploit the relative constancy of path loss and shadow fading effects at any given location around a base station. However, handoff algorithms with both a negligible number of unnecessary handoffs and a negligible decision delay can be realized by exploiting this information. One example is the set of handoff algorithms using pattern recognition introduced in previous work. In this paper, we describe how pattern-recognition handoff algorithms can be applied to the problem of turning a corner. This can be used as part of an integrated pattern-recognition handoff algorithm or together with a traditional handoff algorithm, in which case the pattern recognition handles only the special cases like turning a corner.	Telecordia Technol, Red Bank, NJ 07701 USA; Stanford Univ, Ctr Telecommun, Stanford, CA 94305 USA	Wong, KD (reprint author), Telecordia Technol, Red Bank, NJ 07701 USA.						AMITAY N, 1992, IEEE T VEH TECHNOL, V41, P337, DOI 10.1109/25.182582; AUSTIN MD, 1994, IEEE T VEH TECHNOL, V43, P549, DOI 10.1109/25.312791; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GREENSTEIN LJ, 1992, IEEE COMMUN MAG, V30, P76, DOI 10.1109/35.210359; Jakes W. C., 1974, MICROWAVE MOBILE COM; Kennemann O., 1994, P 6 NORD SEM DIG MOB, P195; LOTSE F, 1990, P IEEE VEH TECHN C O, P539; MATURINOLOZOYA H, 1994, P VEH TECH C 94 STOC, P96, DOI 10.1109/VETEC.1994.345157; MURASE A, 1991, P VTC 91, P524; Nadler M., 1993, PATTERN RECOGNITION; NARASIMHAN R, 1998, P IEEE INT S PERS IN; PRAKASH R, 1998, P IEEE INT S PERS IN; Ramo S., 1965, FIELDS WAVES COMMUNI; *RES DEV CTR RAD S, 1993, PERS HAND PHON SYST; Santucci F, 2000, IEEE T COMMUN, V48, P231, DOI 10.1109/26.823556; STEELE R, 1995, IEEE COMMUN MAG  JAN, V33; Verdone R, 1998, ELECTRON LETT, V34, P950, DOI 10.1049/el:19980718; VIJAYAN R, 1993, IEEE T VEH TECHNOL, V42, P351, DOI 10.1109/25.231888; WHITTEKER JH, 1988, IEEE T VEH TECHNOL, V37; WONG D, 2000, IEEE J SEL AREA COMM, V18, P1301; Wong D, 1999, IEEE T VEH TECHNOL, V48, P956, DOI 10.1109/25.765026	21	6	6	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0018-9545			IEEE T VEH TECHNOL	IEEE Trans. Veh. Technol.	MAR	2001	50	2					354	363		10.1109/25.923048		10	Engineering, Electrical & Electronic; Telecommunications; Transportation Science & Technology	Engineering; Telecommunications; Transportation	433ZQ	WOS:000168791000002		
J	Priebe, CE				Priebe, CE			Olfactory classification via interpoint distance analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ensemble classifiers; combining classifiers; nonparametric; nearest-neighbor; interpoint distance; rank statistic; subsample statistic; functional data; artificial nose; electronic nose; analytical chemistry; chemometrics	SYSTEM	Detection of the presence of a single prespecified chemical analyte at low concentration in complex backgrounds is a difficult application for chemical sensors. This article considers a database of artificial nose observations designed specifically to allow for the investigation of chemical sensor data analysis performance on the problem of trichloroethylene (TCE) detection. We consider an approach to this application which uses an ensemble of subsample classifiers based on interpoint distances. Experimental results are presented indicating that our nonparametric methodology is a useful tool in olfactory classification.	Johns Hopkins Univ, Whiting Sch Engn, Dept Math Sci, Baltimore, MD 21218 USA	Priebe, CE (reprint author), Johns Hopkins Univ, Whiting Sch Engn, Dept Math Sci, Baltimore, MD 21218 USA.		Priebe, Carey E./A-3305-2010				Bickel PJ, 1977, MATH STAT BASIC IDEA; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; David H.A., 1970, ORDER STAT; Devroye L., 1996, PROBABILISTIC THEORY; Dickinson TA, 1996, NATURE, V382, P697, DOI 10.1038/382697a0; Dietterich TG, 1997, AI MAG, V18, P97; FRIEDMAN JH, 1996, UNPUB ANOTHER APPROA; GUITIERREZOSUNA R, 1998, IEEE SPECTRUM, V35; Hastie T, 1998, ANN STAT, V26, P451; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T. J., 1990, GEN ADDITIVE MODELS; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Jones MC, 1995, KERNEL SMOOTHING; Kaplan G, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.669973; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Maa JF, 1996, ANN STAT, V24, P1069; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Nagle HT, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.715180; PRIEBE CE, 2000, P STAT COMP SECT AM; Priebe CE, 1999, COMMUN STAT-THEOR M, V28, P2871, DOI 10.1080/03610929908832454; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; Ripley BD, 1996, PATTERN RECOGNITION; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Skalak D., 1997, THESIS U MASSACHUSET; Stern P, 1999, SCIENCE, V286, P703, DOI 10.1126/science.286.5440.703; Vapnik V. N., 1995, NATURE STAT LEARNING; White J, 1996, ANAL CHEM, V68, P2191, DOI 10.1021/ac9511197; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Xie JD, 2000, J NONPARAMETR STAT, V12, P661, DOI 10.1080/10485250008832827; 1998, IEEE SPECTRUM, V35, P22	35	11	11	2	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					404	413		10.1109/34.917575		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	421MJ	WOS:000168067900006		
J	Mitchell, HB; Schaefer, PA				Mitchell, HB; Schaefer, PA			A "soft" K-Nearest Neighbor voting scheme	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							SIMILARITY MEASURES; FUZZY VALUES; ALGORITHM; OPERATOR	The K-Nearest Neighbor (K-NN) voting scheme is widely used in problems requiring pattern recognition or classification. In this voting scheme an unknown pattern is classified according to the classifications of its K nearest neighbors. If a majority of the K nearest neighbors have a given classification C*, then the unknown pattern is also given the classification C*. Although the scheme works well it is sensitive to the number of nearest neighbors, K, which is used. In this paper we describe a fuzzy K-NN voting scheme in which effectively the value of K varies automatically according to the local density of known patterns. We find that the new scheme consistently outperforms the traditional K-NN algorithm. (C) 2001 John Wiley & Sons, Inc.	Elta Elect Ind Ltd, Intelligence Ctr Dept, Ashdod, Israel	Mitchell, HB (reprint author), Elta Elect Ind Ltd, Intelligence Ctr Dept, Ashdod, Israel.						BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; CHEN SM, 1995, FUZZY SET SYST, V72, P79; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN, P1; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R O, 2001, PATTERN CLASSIFICATI; Fukunaga K., 1993, HDB PATTERN RECOGNIT, P33; Jozwik A, 1983, PATTERN RECOGN LETT, V1, P287, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIM YK, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P1673, DOI 10.1109/FUZZY.1995.409901; KISSIOV VT, 1992, FUZZY SET SYST, V49, P323, DOI 10.1016/0165-0114(92)90284-B; KITTLER J, 1981, PATTERN RECOGN, V13, P245, DOI 10.1016/0031-3203(81)90101-1; Liao TW, 1997, FUZZY SET SYST, V92, P289, DOI 10.1016/S0165-0114(96)00176-5; Mitchell HB, 2000, INT J INTELL SYST, V15, P317, DOI 10.1002/(SICI)1098-111X(200004)15:4<317::AID-INT4>3.0.CO;2-J; PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4; PAPPIS CP, 1995, FUZZY SET SYST, V75, P135, DOI 10.1016/0165-0114(95)00023-E; Schaefer PA, 1999, INT J INTELL SYST, V14, P123, DOI 10.1002/(SICI)1098-111X(199902)14:2<123::AID-INT1>3.3.CO;2-5; Schalkoff R.J., 1992, PATTERN RECOGNITION; WANG XZ, 1995, FUZZY SET SYST, V73, P259, DOI 10.1016/0165-0114(94)00308-T; Webb A, 1999, STAT PATTERN RECOGNI; Yang MS, 1998, IEEE T SYST MAN CY B, V28, P461, DOI 10.1109/3477.678652; 1967, IEEE T CIRCUITS SY 1, V44, P622	23	11	12	1	1	JOHN WILEY & SONS INC	NEW YORK	605 THIRD AVE, NEW YORK, NY 10158-0012 USA	0884-8173			INT J INTELL SYST	Int. J. Intell. Syst.	APR	2001	16	4					459	468		10.1002/int.1018		10	Computer Science, Artificial Intelligence	Computer Science	419PJ	WOS:000167957300002		
J	Granger, E; Rubin, MA; Grossberg, S; Lavoie, P				Granger, E; Rubin, MA; Grossberg, S; Lavoie, P			A What-and-Where fusion neural network for recognition and tracking of multiple radar emitters	NEURAL NETWORKS			English	Article						radar; electronic support measures; pattern recognition; data fusion; neural network; ARTMAP; Kalman filter	ARTMAP; CATEGORIZATION; CLASSIFICATION; ARCHITECTURE; SEQUENCES; MAPS	A neural network recognition and tracking system is proposed for classification of radar pulses in autonomous Electronic Support Measure systems. Radar type information is considered with position-specific information from active emitters in a scene. Type-specific parameters of the input pulse stream are fed to a neural network classifier trained on samples of data collected in the field. Meanwhile, a clustering algorithm is used to separate pulses from different emitters according to position-specific parameters of the input pulse stream. Classifier responses corresponding to different emitters are separated into tracks, or trajectories, one per active emitter, allowing for more accurate identification of radar types based on multiple views of emitter data along each emitter trajectory. Such a What-and-Where fusion strategy is motivated by a similar subdivision of labor in the brain. The fuzzy ARTMAP neural network is used to classify streams of pulses according to radar type using their functional parameters. Simulation results obtained with a radar pulse data set indicate that fuzzy ARTMAP compares favorably to several other approaches when performance is measured in terms of accuracy and computational complexity. Incorporation into fuzzy ARTMAP of negative match tracking (from ARTMAP-IC) facilitated convergence during training with this data set. Other modifications improved classification of data that include missing input pattern components and missing training classes. Fuzzy ARTMAP was combined with a bank of Kalman filters to group pulses transmitted from different emitters based on their position-specific parameters, and with a module to accumulate evidence from fuzzy ARTMAP responses corresponding to the track defined for each emitter. Simulation results demonstrate that the system provides a high level of performance on complex, incomplete and overlapping radar data. (C) 2001 Elsevier Science Ltd. All rights reserved.	Boston Univ, Dept Cognit & Neural Syst, Boston, MA 02215 USA; Def Res Estab, Dept Natl Def, Ottawa, ON K1A 0Z4, Canada; Ecole Polytech, Dept Elect & Comp Engn, Montreal, PQ H3C 3A7, Canada; Boston Univ, Ctr Adapt Syst, Boston, MA 02215 USA	Grossberg, S (reprint author), Boston Univ, Dept Cognit & Neural Syst, 677 Beacon St, Boston, MA 02215 USA.						Anderberg M. R., 1973, CLUSTER ANAL APPL; ANDERSON JA, 1990, P IEEE, V78, P1646, DOI 10.1109/5.58358; BALOCH AA, 1991, NEURAL NETWORKS, V4, P271, DOI 10.1016/0893-6080(91)90067-F; Bar-Shalom Y., 1993, ESTIMATION TRACKING; Bensaid AM, 1996, PATTERN RECOGN, V29, P859, DOI 10.1016/0031-3203(95)00120-4; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blackman S. S., 1986, MULTIPLE TARGET TRAC; Bradski G, 1995, NEURAL NETWORKS, V8, P1053, DOI 10.1016/0893-6080(95)00053-4; BRADSKI G, 1994, BIOL CYBERN, V71, P469, DOI 10.1007/BF00198465; BROWNE JPR, 1998, ELECT WARFARE; CARPENTER GA, 1997, INTELLIGENT ENG SYST, V7, P23; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; CARPENTER GA, 1995, IEEE T NEURAL NETWOR, V6, P805, DOI 10.1109/72.392245; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1997, P INT C NEUR NETW, V3, P1459, DOI 10.1109/ICNN.1997.614010; Carpenter GA, 1998, NEURAL NETWORKS, V11, P323, DOI 10.1016/S0893-6080(97)00067-1; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; CARPENTER KE, 1992, HARVARD LIBR BULL, V3, P5; Chandra V., 1988, Proceedings of the Twentieth Southeastern Symposium on System Theory (Cat. No.88CH2553-6), DOI 10.1109/SSST.1988.17025; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davies G J, 1982, J Orthop Sports Phys Ther, V3, P164; DERMIRIZ A, 1999, INTELLIGENT ENG SYST, V9, P809; Dubes R.C., 1988, ALGORITHMS CLUSTERIN; Duda R. O., 1973, PATTERN CLASSIFICATI; FILHO ADM, 1994, P INT RAD C, P470; Fukunaga K., 1990, INTRO STAT PATTERN R; GHAHRAMANI Z, 1994, 1509 MIT A I LAB; GRANGER E, 1999, INTELLIGENT ENG SYST, V9, P3; GRANGER E, 2000, P INT JOINT C NEUR N, V4, P35; Granger E, 1999, ADV NEUR IN, V11, P875; GRANT PM, 1982, P I ELECTR ENG, V129, P621; Gray R. M., 1984, IEEE ASSP Magazine, V1, DOI 10.1109/MASSP.1984.1162229; Grossberg S, 2000, TRENDS COGN SCI, V4, P233, DOI 10.1016/S1364-6613(00)01464-9; Helstrom C. W., 1995, ELEMENTS SIGNAL DETE; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; KAMGARPARSI B, 1996, NRLFR5720NRL969803; MALONEY PS, 1989, P IEEE INT C NEUR NE, V1, P289; MARDIA HK, 1989, IEE PROC-F, V136, P149; MEILER PP, 1990, FEL90B023 TNO PHYS E; Pape D. R., 1997, Proceedings of the SPIE - The International Society for Optical Engineering, V3160, DOI 10.1117/12.283939; Parra L, 1996, NEURAL COMPUT, V8, P260, DOI 10.1162/neco.1996.8.2.260; PEDRYCZ W, 1985, PATTERN RECOGN LETT, V3, P13, DOI 10.1016/0167-8655(85)90037-6; ROE AL, 1994, P 7 INT C IND ENG AP, P565; ROGERS JAV, 1985, P I ELECTR ENG, V132, P621; Rubin D. B., 1987, STAT ANAL MISSING DA; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Schleher D. C., 1999, ELECT WARFARE INFORM; SCHLEHER DC, 1986, INTRO ELECT WARFACE; SCIORTINO JC, 1997, NAV ENG J, P73; SELF A, 1991, AGARD 91, V9, P1; Specht D. F., 1989, Wescon/89. Conference Record; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Tsui J. B., 1986, MICROWAVE RECEIVERS; WANG EK, 1991, ELECTROANAL, V3, P1, DOI 10.1002/elan.1140030102; WILEY RG, 1993, ELECT INTELLIGENCE A; WILKINSON MA, 1985, P I ELECTR ENG, V132, P229; Williamson JR, 1997, NEURAL COMPUT, V9, P1517, DOI 10.1162/neco.1997.9.7.1517; Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8	59	27	33	1	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	APR	2001	14	3					325	344		10.1016/S0893-6080(01)00019-3		20	Computer Science, Artificial Intelligence	Computer Science	426DN	WOS:000168334700006	11341569	
J	Katila, M; Tomppo, E				Katila, M; Tomppo, E			Selecting estimation parameters for the Finnish multisource National Forest Inventory	REMOTE SENSING OF ENVIRONMENT			English	Article						nonparametric estimation; satellite images; multisource forest inventory; stratification Cross-validation; training data selection	NEIGHBOR; AREA	The paper examines the selection of parameters for the nonparametric k-NN estimation method that is used in the Finnish multisource National Forest Inventory (MS-NFI). The MS-NFI utilises NFI field plot data, optical area satellite images and digital maps and produces forest variable estimates from the single pixel level up to the national level. The most important parameters to be selected are: the distance metric, the number of the nearest neighbours, ii, parameters related to the digital elevation model, stratification of the image data, as well as the width of the moving geographical horizontal and vertical reference areas (HRAs and VRAs). The root mean square errors (RMSEs) and significance of biases at pixel level were evaluated in order to find optimal parameters. A leave-one-out cross-validation method was applied. The emphasis is placed on the search for moving geographical HRAs and VRAs, as well as in the stratification of the field plots and the satellite images on the basis of auxiliary data. Stratification reduces the bias of the estimates significantly within each strata. With the current sampling intensity of the Finnish national forest inventory, a geographical HRA with a radius of 40-50 km was found optimal for the total volume estimates and for volumes by tree species in the mineral land map stratum. On the average, there was a sufficient number of field plots to cover the variation of forest variables within the image area to be analysed. The inclusion of field plot data beyond this area introduced bias to the estimates. For the peatland strata, a wider reference area, 60-90 km, was needed. A VRA together with topographic correction of the digital values of images, reduced the standard error of the volume estimates in Northern Finland. (C) 2001 Elsevier Science Inc. All rights reserved.	Finnish Forest Res Inst, FIN-00170 Helsinki, Finland	Katila, M (reprint author), Finnish Forest Res Inst, Unioninkatu 40 A, FIN-00170 Helsinki, Finland.						ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CURRAN PJ, 1986, PHOTOGRAMM ENG REM S, V52, P229; EISELE FA, 1997, 1997 M WALL PRIZ S 1, P71; *FINN FOR RES I, 1999, FINN STAT YB FOR; FRANCOLOPEZ H, 2000, IN PRESS REMOTE SENS; Gjertsen A.K., 2000, REMOTE SENSING FORES, P167; HAGNER O, 1997, 29 SWED U AGR SCI DE; Katila M, 2000, CAN J FOREST RES, V30, P1329, DOI 10.1139/cjfr-30-8-1329; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KILKKI P, 1987, REMOTE SENSING AIDED, P2089; LINTON O, 1998, ENCY STAT SCI UPDATE, V2, P470; MOEUR M, 1995, FOREST SCI, V41, P337; Nilsson M., 1997, THESIS SWEDISH U AGR; Poso S, 1999, SILVA FENN, V33, P41, DOI 10.14214/sf.669; RAO JNK, 1998, ENCY STAT SCI UPDATE, V2, P621; Seppala M., 1980, FENNIA, V158, P41; Tokola T, 1996, INT J REMOTE SENS, V17, P2333; TOKOLA T, 1998, THESIS U JOENS; Tokola T, 1999, CAN J FOREST RES, V29, P303, DOI 10.1139/cjfr-29-3-303; Tokola Timo, 1997, Silva Fennica, V31, P67; TOMPPO E, 1996, NEW THRUSTS FOREST I, V1, P27; TOMPPO E, 1998, FOLIA FORESTALIA B, V2, P293; Tomppo E., 1992, ACTA FOR FENN, V229, P1; Tomppo E., 1998, FOLIA FORESTALIA B, V4B, P619; TOMPPO E, 1999, FOLIA FOR HELSINKI, V2, P389; Tomppo E, 1999, SCAND J FOREST RES, V14, P182; TOMPPO E, 1997, STUDY EUROPEAN FORES, V2, P145; Tomppo E., 1987, Proceedings of the 5th Scandinavian Conference on Image Analysis; Tomppo E., 1991, INT ARCH PHOTOGRAMME, V28, P419; TOMPPO E, 1992, INT ARCH PHOTOGRA 7B, V29, P671	31	110	113	0	7	ELSEVIER SCIENCE INC	NEW YORK	655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010 USA	0034-4257			REMOTE SENS ENVIRON	Remote Sens. Environ.	APR	2001	76	1					16	32		10.1016/S0034-4257(00)00188-7		17	Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology	421JN	WOS:000168061400002		
J	Bainbridge, D; Bell, T				Bainbridge, D; Bell, T			The challenge of optical music recognition	COMPUTERS AND THE HUMANITIES			English	Article						optical music recognition; musical data acquisition; document image analysis; pattern recognition		This article describes the challenges posed by optical music recognition - a topic in computer science that aims to convert scanned pages of music into an on-line format. First, the problem is described: then a generalised framework for software is presented that emphasises key stages that must be solved: staff line identification, musical object location, musical feature classification, and musical semantics. Next, significant research projects in the area are reviewed, showing how each fits the generalised framework. The article concludes by discussing perhaps the most open question in the field: how to compare the accuracy and success of rival systems, highlighting certain steps that help ease the task.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand; Univ Canterbury, Dept Comp Sci, Christchurch, New Zealand	Bainbridge, D (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.			Bainbridge, David/0000-0002-0603-5728			Alphonce B., 1988, P SMALL COMP ARTS, P8; ANSTINCE J, 1996, THESIS U CANTERBURY; BAINBRIDGE D, 1994, NZ SCI MONTHLY, V5, P10; BAINBRIDGE D, 1996, P 19 AUSTR COMP SCI, P308; BAINBRIDGE D, 1997, HDB CHARACTER RECOGN, P583; BAINBRIDGE D, 1994, 0594 TRCOSC U CANT D; Bainbridge D., 1997, THESIS U CANTERBURY; Bainbridge D., 1997, P 6 INT C IM PROC IT, P756; BAINBRIDGE D, P IEEE DAT COMPR C, P208; BAINBRIDGE D, 1994, 0694 TRCOSC U CANT D; BAINBRIDGE D, 1994, 2 U CANT; BAINOV D, 1995, PROCEEDINGS OF THE FIFTH INTERNATIONAL COLLOQUIUM ON DIFFERENTIAL EQUATIONS, P23; Baird H. S., 1992, STRUCTURED DOCUMENT; BAUMANN S, 1992, SERIES MACHINE PERCE, V5, P363; Blostein D., 1992, STRUCTURED DOCUMENT, P405; Boyle RD, 1988, COMPUTER VISION 1 CO; BULIS A, 1992, P INT COMP MUS C, P110; Bunke H., 1997, HDB CHARACTER RECOGN; BUNKE H, 1982, IEEE T PATTERN ANAL, V4, P574; Carter N. P., 1992, STRUCTURED DOCUMENT, P456; CARTER NP, 1994, P SOC PHOTO-OPT INS, V2181, P279, DOI 10.1117/12.171115; CARTER NP, 1992, SERIES MACHINE PERCE, V5, P352; CARTER NP, 1990, P INT ASS PATT REC W, P482; Carter N. P., 1992, Machine Vision and Applications, V5, DOI 10.1007/BF02627000; CARTER NP, 1994, COMPUTING MUSICOLOGY, V9, P152; CARTER NP, 1993, STANM87 DEP MUS; CARTER NP, 1989, THESIS U SURREY GUIL; Clarke A. T., 1988, P COMP MUS RES C LAN, P84; COUASNON B, 1994, INT ASS PATT REC WOR, P15; COUASNON B, 1997, THESIS IRISA FRANCE; COUASNON B, 1995, 3 INT C PRACT APPL P, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fahmy H., 1991, P 1 INT C DOC AN REC, V1, P70; FAHMY H, 1992, SERIES MACHINE PERCE, V5, P373; Foley J.D., 1990, COMPUTER GRAPHICS PR, V2nd; FUJINAGA I, 1989, PROCEEDINGS : 1989 INTERNATIONAL COMPUTER MUSIC CONFERENCE, NOVEMBER 2-5, P113; FUJINAGA I, 1991, P INT COMP MUS C MON, P66; FUJINAGA I, 1992, P INT COMP MUS C SAN, P117; FUJINAGA I, 1989, P 1 INT C MUS PERC C, P87; FUJINAGA I, 1992, SPIE, V1785, P210; Fujinaga I., 1988, THESIS MCGILL U MONT; FUJINAGA I, 1991, COMPUTERS MUSIC RES, V3, P139; FUJINAGA I, 1997, THESIS MCGILL U MONT; FUJINAGA I, 1989, COMPUTERS MUSIC RES, V1, P161; GLASS S, 1989, THESIS U CANTERBURY; HAKEN L, 1993, COMPUT MUSIC J, V17, P43, DOI 10.2307/3680942; HEUSSENSTAMM G, 1987, NORTON MANUAL MUSCI; Kassler M., 1972, PERSPECT NEW MUSIC, V11, P250, DOI 10.2307/832471; KATO H, 1990, P IAPR WORKSH SYNT S, P231; MATSUSHIM AT, 1985, B SCI ENG RES LAB, V112, P25; MCGEE W, 1991, COMPUT HUMANITIES, V25, P47; MODAYUR BR, 1995, MUSER PROTOYPE MUSIC; Ng KC, 1996, IMAGE VISION COMPUT, V14, P39, DOI 10.1016/0262-8856(95)01038-6; NG KC, 1995, THESIS U LEEDS LEEDS; NG KC, 1995, P 11 C MUS INF BOL I, P167; Pavlidis T., 1982, ALGORITHMS GRAPHICS; PRERAU DS, 1971, P FALL JOINT COMP C; PRERAU DS, 1970, THESIS MIT CAMBRIDGE; PRERAU DS, 1975, COMPUT HUMANITIES, V9, P25, DOI 10.1007/BF02404318; PRERAU DS, 1971, THESIS MIT CAMBRIDGE; Pruslin D, 1966, THESIS MIT CAMBRIDGE; READ G, 1974, MUSIC NOTATION MANUA; REED T, 1995, THESIS U CALGARY CAN; ROACH JW, 1988, PATTERN RECOGN, V21, P33, DOI 10.1016/0031-3203(88)90069-6; ROADS C, 1986, COMPUT MUSIC J, V10, P39, DOI 10.2307/3679483; ROSS T, 1970, ART MUSIC ENGRAVING; Russ J, 1992, IMAGE PROCESSING HDB; SELFRIDGEFIELD E, 1994, COMPUTING MUSICOLOGY, V9, P109; Witten I.H., 1994, MANAGING GIGABYTES C; Wolman J, 1992, P INT COMP MUS C SAN, P125; YADID O, 1992, P INT COMP MUS C SAN, P128	71	27	29	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0010-4817			COMPUT HUMANITIES	Comput. Humanit.	MAY	2001	35	2					95	121		10.1023/A:1002485918032		27	Computer Science, Interdisciplinary Applications	Computer Science	415QF	WOS:000167733600002		
J	Goyache, F; del Coz, JJ; Quevedo, JR; Lopez, S; Alonso, J; Ranilla, J; Luaces, O; Alvarez, I; Bahamonde, A				Goyache, F; del Coz, JJ; Quevedo, JR; Lopez, S; Alonso, J; Ranilla, J; Luaces, O; Alvarez, I; Bahamonde, A			Using artificial intelligence to design and implement a morphological assessment system in beef cattle	ANIMAL SCIENCE			English	Article						artificial intelligence; beef cattle; linear type; machine learning	LINEAR TYPE TRAITS; UDDER TRAITS; DAIRY EWES; HERD LIFE	In this paper a methodology is developed to improve the design and implementation of a linear morphological system in beef cattle using artificial intelligence. The proposed process involves an iterative mechanism where type traits are successively defined and computationally represented using knowledge engineering methodologies, scored by a set of trained human experts and finally, analysed by means of four reputed machine learning algorithms. The results thus achieved serve as feed back to the next iteration in order to improve the accuracy and efficacy of the proposed assessment system. A sample of 260 conformation records of the Asturiana de los Valles beef cattle breed is shown to illustrate the methodology. Three sources of inconsistency were detected: (a) the existence of different interpretations of the trait's definition, increasing the subjectivity of the assessment; (b) the narrow range of variation of some of the anatomical traits assessed; (c) the inclusion of some complex traits in the assessment system. In this sense, the reopening of the evaluated Asturiana de los Valles assessment system is recommended. In spite of the difficulty of collecting data from live animals, further implications of the artificial intelligence systems on morphological assessment are pointed out.	SERIDA CENSYRA Somio, E-33203 Gijon, Asturias, Spain; Univ Oviedo, Ctr Inteligencia Artificia, E-33271 Gijon, Asturias, Spain	Goyache, F (reprint author), SERIDA CENSYRA Somio, C Camino de los Claveles 604, E-33203 Gijon, Asturias, Spain.		Alvarez, Isabel/B-7814-2011; Ranilla, Jose/E-8012-2013; del Coz, Juan/K-7952-2014; Goyache, Felix/B-7764-2009; Alonso, Jaime/I-2448-2015	Luaces-Rodriguez, Oscar/0000-0001-8476-9412; Ranilla, Jose/0000-0003-2941-3741; del Coz, Juan/0000-0002-4288-3839; Goyache, Felix/0000-0002-6872-1045; Alonso, Jaime/0000-0001-9718-4683			*ASS NAZ ALL BOV I, 1997, RAZZ CHIAN; Bahamonde A, 1997, LECT NOTES COMPUT SC, V1240, P536; BERG RT, 1979, NUEVOS CONCEPTOS SOB; BROTHERSTONE S, 1994, ANIM PROD, V59, P183; BROTHERSTONE S, 1991, ANIM PROD, V53, P279; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; delaFuente LF, 1996, LIVEST PROD SCI, V45, P171, DOI 10.1016/0301-6226(96)00003-6; DELCOZ JJ, 1999, P 8 C AS ESP INT ART, V1, P117; del Coz JJ, 1999, LECT NOTES COMPUT SC, V1606, P527; FERNANDEZ G, 1995, J DAIRY SCI, V78, P842; GOYACHE F, 1999, FEDERACION ESPANOLA, V16, P8; *INT COMM AN REC, 1995, REC GUID APP INT AGR; Linko S, 1998, TRENDS FOOD SCI TECH, V9, P3, DOI 10.1016/S0924-2244(97)00002-2; LOPEZ S, 2000, REV IBEROAMERICANA I, V10, P5; Luaces O, 1999, LECT NOTES COMPUT SC, V1606, P497; Michalski R. S., 1998, MACHINE LEARNING DAT; Nilsson N. J., 1998, ARTIFICIAL INTELLIGE; PIETERSMA D, 1999, P 2 EUR C EUR FED IN, P669; QUEVEDO JR, 1999, P 8 C AS ESP INT ART, V1, P64; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 2000, CUBIST RELEASE 1 08; QUINLAN JR, 1993, P 10 INT MACH LEARN; Rich E, 1991, ARTIFICIAL INTELLIGE; SHI MJ, 1993, GENET SEL EVOL, V25, P177, DOI 10.1051/gse:19930205; SHORT TH, 1992, J DAIRY SCI, V75, P1987; Vallejo M., 1993, Archivos de Zootecnia, V42, P29; Vukasinovic N, 1997, LIVEST PROD SCI, V49, P227, DOI 10.1016/S0301-6226(97)00014-6; Wang Y., 1997, P EUR C MACH LEARN U; Yang XZ, 1999, T ASAE, V42, P1063	29	13	13	1	1	BRITISH SOC ANIMAL SCIENCE	PENICUIK	PUBLICATIONS DEPT, PO BOX 3, PENICUIK EH26 ORZ, MIDLOTHIAN, SCOTLAND	1357-7298			ANIM SCI	Anim. Sci.	AUG	2001	73		1				49	60				12	Agriculture, Dairy & Animal Science	Agriculture	460PG	WOS:000170317200006		
J	Liu, HF; Lussier, YA; Friedman, C				Liu, HF; Lussier, YA; Friedman, C			Disambiguating ambiguous biomedical terms in biomedical narrative text: An unsupervised method	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						natural language processing; word sense disambiguation; corpus-based machine learning; MedLEE; UMLS; MEDLINE	SPECIAL ISSUE; LANGUAGE	With the growing use of Natural Language Processing (NLP) techniques for information extraction and concept indexing in the biomedical domain, a method that quickly and efficiently assigns the correct sense of an ambiguous biomedical term in a given context is needed concurrently. The current status of word sense disambiguation (WSD) in the biomedical domain is that handcrafted rules are used based on contextual material. The disadvantages of this approach are (i) generating WSD rules manually is a time-consuming and tedious task, (ii) maintenance of rule sets becomes increasingly difficult over time, and (iii) handcrafted rules are often incomplete and perform poorly in new domains comprised of specialized vocabularies and different genres of text. This paper presents a two-phase unsupervised method to build a WSD classifier for an ambiguous biomedical term W The first phase automatically creates a sense-tagged corpus for W, and the second phase derives a classifier for W using the derived sense-tagged corpus as a training set. A formative experiment was performed, which demonstrated that classifiers trained on the derived sense-tagged corpora achieved an overall accuracy of about 97%, with greater than 90% accuracy for each individual ambiguous term. (C) 2001 Elsevier Science (USA).	CUNY Grad Sch & Univ Ctr, Div Comp Sci, New York, NY 10016 USA; CUNY Queens Coll, Dept Comp Sci, New York, NY USA; Columbia Univ Coll Phys & Surg, Dept Med Informat, New York, NY 10032 USA	Liu, HF (reprint author), CUNY Grad Sch & Univ Ctr, Div Comp Sci, New York, NY 10016 USA.						Aronson A. R., 1994, P RIAO 94, P197; BLOOM D, 2000, BJU INT, P1; BRUCE R, P ACL, V32, P139; BRUCE R, 1994, P ACL, V32, P139; Campbell D A, 2001, Proc AMIA Symp, P90; CARDIE C, P NAT C AI, V11, P798; CHEUNG T, 1999, AM HEART J, V134, P726; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004; Duda R. O., 1973, PATTERN CLASSIFICATI; ESCUDERO G, 2000, P 14 EUR C ART INT E, P421; Fellbaum Christiane, 1998, WORDNET ELECT LEXICA; Friedman C, 2000, Proc AMIA Symp, P270; Friedman C, 2001, Proc AMIA Symp, P189; FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161; Friedman C, 1998, METHOD INFORM MED, V37, P334; Gale William, 1992, P 4 INT C THEOR METH, P101; HRIPCSAK G, 1995, ANN INTERN MED, V122, P681; Ide N, 1998, COMPUT LINGUIST, V24, P1; Johnson SB, 1999, J AM MED INFORM ASSN, V6, P205; Kilgarriff A, 2000, COMPUT HUMANITIES, V34, P1, DOI 10.1023/A:1002619001915; Knirsch CA, 1998, INFECT CONT HOSP EP, V19, P94; Leacock C, 1998, COMPUT LINGUIST, V24, P147; LEACOCK C, 1993, P ARPA WORKSH HUM LU; LI M, T NEURAL NETW, V11, P647; Liu H, 2001, Proc AMIA Symp, P393; MOONEY RJ, 1996, P EMNLP, V1, P82; NADKAMI P, 2001, J AM MED INFORM ASSN, V80, P80; NG HT, 1996, P ACL, V34, P40; NG HT, 1997, AI MAGAZINE      WIN, P45; NG HT, 1997, P EMNLP2; Reis BY, 2001, J BIOMED INFORM, V34, P15, DOI 10.1006/jbin.2001.1005; Rindflesch T C, 1994, Proc Annu Symp Comput Appl Med Care, P240; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; ROTH L, 2000, P AMIA ANN FALL S 20, P1124; STEVENSON M, 1999, P INT JOINT C AI; *US DHHS NIH NAT L, UMLS KNOWL SOURC; YAROWSKY D, 1994, P ACL, V32, P88; YAROWSKY D, P ACL, V32, P88	39	31	32	2	4	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	AUG	2001	34	4					249	261		10.1006/jbin.2001.1023		13	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	541RX	WOS:000174998900002	11977807	
J	Skubalska-Rafajlowicz, E				Skubalska-Rafajlowicz, E			Data compression for pattern recognition based on space-filling curve pseudo-inverse mapping	NONLINEAR ANALYSIS-THEORY METHODS & APPLICATIONS			English	Article; Proceedings Paper	3rd World Congress of Nonlinear Analysts Catania	JUL 19-26, 2000	SICILY, ITALY			space-filling curves; pattern recognition; data compression	VECTOR QUANTIZATION	A new class of methods of data compression for pattern recognition in multidimensional space is discussed. These methods combine the space-filling curve based transformation of multidimensional data into the unit interval and pattern recognition algorithms in one dimension. This transformation yield the powerful reduced complexity pattern recognition method.	Wroclaw Tech Univ, Inst Engn Cybernet, PL-50370 Wroclaw, Poland	Skubalska-Rafajlowicz, E (reprint author), Wroclaw Tech Univ, Inst Engn Cybernet, Wyspianskiego 27, PL-50370 Wroclaw, Poland.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diamantini C, 1998, IEEE T NEURAL NETWOR, V9, P174, DOI 10.1109/72.655039; Fukunaga K., 1972, INTRO STAT PATTERN R; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Hilbert D., 1891, MATH ANN, V38, P459, DOI [10.1007/BF01199431, DOI 10.1007/BF01199431]; Kohonen T., 1995, SELF ORG MAPS; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; PATRICK EA, 1968, IEEE T COMPUT, VC 17, P949, DOI 10.1109/TC.1968.226443; Peano G., 1890, MATH ANN, V36, P157, DOI [10.1007/BF01199438, DOI 10.1007/BF01199438]; PLATZMAN LK, 1989, J ACM, V36, P719, DOI 10.1145/76359.76361; QUWEIDER MK, 1995, IEEE SIGNAL PROCESSI, V2, P170; RITTER H, 1991, IEEE T NEURAL NETWOR, V2, P173, DOI 10.1109/72.80310; Sagan H., 1994, SPACE FILLING CURVES; Sierpinski W, 1912, B ACAD SCI CRACOW A, V1912, P463; SKUBALSKARAFAJL.E, 1996, P 13 ICPR VIENN AUST, P221; SKUBALSKARAFAJL.E, P 4 C NEUR NETW THEI, P226; SKUBALSKARAFAJL.E, 1999, UNPUB PATTERN RECOGN; SKUBALSKARAFAJL.E, P 3 C NEUR NETW THEI, P161; STEELE JM, 1989, OPER RES LETT, V8, P237; YAIR E, 1992, IEEE T SIGNAL PROCES, V40, P294, DOI 10.1109/78.124940; ZADOR PL, 1982, IEEE T INFORM THEORY, V28, P139, DOI 10.1109/TIT.1982.1056490; Zheng Y, 1996, IEEE T NEURAL NETWOR, V7, P87	23	4	4	1	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0362-546X			NONLINEAR ANAL-THEOR	Nonlinear Anal.-Theory Methods Appl.	AUG	2001	47	1	1				315	326		10.1016/S0362-546X(01)00179-1		12	Mathematics, Applied; Mathematics	Mathematics	466BX	WOS:000170625400030		
J	Sansone, C; Tortorella, F; Vento, M				Sansone, C; Tortorella, F; Vento, M			A classification reliability driven reject rule for multi-expert systems	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						classification; multi-expert systems; reliability; reject option; classification cost	HANDWRITTEN NUMERALS; CLASSIFIERS; RECOGNITION; COMBINATION	In this paper we propose a reject rule applicable to a Multi-Expert System (MES). The rule is adaptive to the given domain and allows the achievement of the best trade-off between reject and error rates as a function of the costs attributed to errors and rejects in the considered application. The results of the method axe particularly effective since the method does not rely on particular statistical assumptions, as other reject rules. An experimental analysis carried out on publicly available databases is reported together with a comparison with other methods present in the literature.	Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy; Univ Cassino, Dipartimento Automazione Elettromagnetismo Ingn I, I-03043 Cassino, FR, Italy	Sansone, C (reprint author), Univ Naples Federico II, Dipartimento Informat & Sistemist, Via Claudio 21, I-80125 Naples, Italy.		Tortorella, Francesco/F-5964-2010; 	Tortorella, Francesco/0000-0002-5033-9323; Sansone, Carlo/0000-0002-8176-6950			ACKERMANN B, 1996, IAM96002 U BERN I IN; BATTITI R, 1994, NEURAL NETWORKS, V7, P691, DOI 10.1016/0893-6080(94)90046-9; Blake C, 1998, UCI REPOSITORY MACHI; Bloch I, 1996, IEEE T SYST MAN CY A, V26, P52, DOI 10.1109/3468.477860; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; CORDELLA LP, 1995, IEEE T NEURAL NETWOR, V6, P1140, DOI 10.1109/72.410358; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Stefano C, 2000, IEEE T SYST MAN CY C, V30, P84, DOI 10.1109/5326.827457; DESTEFANO C, 1995, P 9 SCAND C IM AN, P1123; Foggia P, 1999, PATTERN RECOGN, V32, P1435, DOI 10.1016/S0031-3203(98)00169-1; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P608, DOI 10.1109/34.601248; HECTHNIELSEN R, 1990, NEUROCOMPUTING; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; KANG H, 1997, P 4 INT C DOC AN REC, V2, P870; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; LAM L, 1995, PATTERN RECOGN LETT, V16, P945, DOI 10.1016/0167-8655(95)00050-Q; LEE DS, 1995, P 3 INT C DOC AN REC, P42; Pudil P., 1992, P 11 IAPR INT C PATT, V2, P92; Rahman AFR, 1998, PATTERN RECOGN, V31, P1255, DOI 10.1016/S0031-3203(97)00161-1; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	27	6	6	0	3	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 912805, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	SEP	2001	15	6					885	904		10.1142/S0218001401001210		20	Computer Science, Artificial Intelligence	Computer Science	484GJ	WOS:000171681600001		
J	Roy, K; Sengupta, C; De, AU				Roy, K; Sengupta, C; De, AU			Theoretical aspects of rational drug design - An overview	JOURNAL OF SCIENTIFIC & INDUSTRIAL RESEARCH			English	Review							ISC-PEM-MO; CARBONIC-ANHYDRASE INHIBITORS; MATRIX-METALLOPROTEINASE INHIBITORS; MINIMUM ENERGY CONFORMATIONS; CUM-PREFERRED CONFORMATIONS; CANCER RECEPTOR SITE(S); STATE ATOM INDEX; MOLECULAR CONNECTIVITY; BIOLOGICAL-ACTIVITY; LIPID-PEROXIDATION	The major techniques of drug discovery processes for the past thirty years have been summarized. However, because of rapid advances in information technology and emergence of plethora of newer techniques, e.g., PCMM, UPGMA, MMG, FALS, MMFF, etc., this short review obviously does not give an exhaustive coverage. The paper summarizes different approaches of rational drug design methods with a primary focus on quantitative structure-activity relationship QSAR) and molecular modelling studies. Apart from an overview of classical QSAR tools (Hansch approach, Fujita-Ban modification of Free Wilson model and topological schemes) and different mathematical methods of QSAR, different components of molecular modelling including techniques of computational chemistry (quantum and molecular mechanical approaches) are briefly discussed. Various receptor-dependent and receptor-independent 3-D QSAR methods and techniques like protein modelling, de novo ligand design and receptor mapping are also summarized. Some other trends in recent drug development process like mass ligand screening, recombinant DNA technology, peptidomimetics, oligonucleotide therapeutics, cabohydrate based drug design, and prodrug design are also mentioned.	Jadavpur Univ, Dept Pharmaceut Technol, Div Med & Pharmaceut Chem, Drug Theoret Lab, Kolkata 700032, W Bengal, India	De, AU (reprint author), Jadavpur Univ, Dept Pharmaceut Technol, Div Med & Pharmaceut Chem, Drug Theoret Lab, Kolkata 700032, W Bengal, India.	kunalroy_in@yahoo.com; audjupt@yahoo.com	Roy, Kunal/B-1673-2009	Roy, Kunal/0000-0003-4486-8074			AOYAMA T, 1990, J MED CHEM, V33, P2583, DOI 10.1021/jm00171a037; APPELT K, 1997, STRUCTURE BASED DRUG, P1; ARANDA A, 1973, CR ACAD SCI C CHIM, V276, P1301; BABALAN AT, 1980, STERIC FIT QUANTITAT; Balant LP, 1995, BURGERS MED CHEM, V1, P949; BALDWIN JJ, 1989, J MED CHEM, V32, P2510, DOI 10.1021/jm00132a003; BEASLEY JG, 1969, BIOCHIM BIOPHYS ACTA, V178, P175, DOI 10.1016/0005-2744(69)90144-2; BENCT LZ, 1996, GOODMAN GILMANS PHAR, P3; Benet L. Z, 1996, GOODMAN GILMANS PHAR, P1707; BROUGHTON BJ, 1975, J MED CHEM, V18, P1117, DOI 10.1021/jm00245a014; Christen WG, 1999, P ASSOC AM PHYSICIAN, V111, P16, DOI 10.1046/j.1525-1381.1999.09231.x; CHRISTOFFERSEN RE, 1995, BURGERS MED CHEM DRU, V1, P9; COLLOUS T, 1973, DISCRIMINANT ANAL AP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMER RD, 1978, QUANTITATIVE STRUCTU; CRIPPEN GM, 1982, MOL PHARMACOL, V22, P11; Crooke ST, 1995, BURGERS MED CHEM DRU, V1, P863; CURRIN RT, 1990, TRANSPLANTATION, V50, P1076; DANIELS TD, 1982, WILSON GISVOLDS TXB, P5; DAVIS AM, 1995, ADV COMPUTER ASSISTE, P39; De A. K., 1997, Biomedicine, V17, P99; DE AU, 2001, INDIAN J PHARM ED, V35, P71; DE AU, 1977, J INDIAN CHEM SOC, V54, P1071; DE AU, 1979, INDIAN J CHEM B, V17, P261; DE AU, 1978, INDIAN J CHEM B, V16, P716; DE AU, 1979, INDIAN J CHEM B, V18, P172; DE AU, 1981, INDIAN J CHEM B, V20, P58; DE AU, 1979, INDIAN J CHEM B, V16, P57; DE AU, 1982, INDIAN J CHEM B, V21, P430; DE AU, 1980, INDIAN J CHEM B, V19, P787; DE AU, 1978, INDIAN J CHEM B, V16, P1104; DE K, 2000, INDIAN J PHARM SCI, V62, P343; DIRMLA JP, 1979, J MED CHEM, V22, P1118; DOWEYKO AM, 1988, J MED CHEM, V31, P1396, DOI 10.1021/jm00402a025; Duran B. S., 1974, CLUSTER ANAL SURVEY; DUTTA H, 1909, INDIAN J BIOCH BIOPH, V33, P76; DUTTA H, 1993, INDIAN J BIOCHEM BIO, V30, P128; DUTTA H, 1991, INDIAN J BIOCHEM BIO, V28, P210; ESTERBAUER H, 1988, ISI ATLAS-BIOCHEM, V1, P311; Farland J. W. Mc, 1995, CHEMOMETRIC METHODS, P295; Franke R., 1995, CHEMOMETRIC METHODS, P113, DOI 10.1002/9783527615452.ch4; FREE SM, 1964, J MED CHEM, V7, P395, DOI 10.1021/jm00334a001; FUJITA T, 1971, J MED CHEM, V14, P148, DOI 10.1021/jm00284a016; Gaziano JM, 1999, P ASSOC AM PHYSICIAN, V111, P2, DOI 10.1046/j.1525-1381.1999.09229.x; GOLDENDER VE, 1980, DRUG DESIGN, V9, P300; GOOD AC, 1993, J MED CHEM, V36, P433, DOI 10.1021/jm00056a002; Goodman M., 1995, BURGERS MED CHEM DRU, V1, P803; GREER J, 1994, J MED CHEM, V37, P1035, DOI 10.1021/jm00034a001; Gund P., 1977, PROGR MOL SUBCELLULA, V11, P117; Gupta P, 1998, J APPL TOXICOL, V18, P317, DOI 10.1002/(SICI)1099-1263(1998090)18:5<317::AID-JAT514>3.0.CO;2-U; Gutteridge J. M. C., 1994, ANTIOXIDANTS NUTR HL; HALL LH, 1991, QUANT STRUCT-ACT REL, V10, P43, DOI 10.1002/qsar.19910100108; HALL LH, 1975, J PHARM SCI, V64, P1974, DOI 10.1002/jps.2600641215; HALL LH, 1977, TETRAHEDRON, V33, P1953, DOI 10.1016/0040-4020(77)80383-9; HALLIWELL B, 1991, DRUGS, V42, P569, DOI 10.2165/00003495-199142040-00003; Halliwell B, 1989, FREE RADICALS BIOL M; Hammett L. P., 1940, PHYSICAL ORGANIC CHE, P184; HANSCH C, 1995, EXPORING QSAR STRUCT; HANSCH C, 1964, J AM CHEM SOC, V86, P1616, DOI 10.1021/ja01062a035; HARPER NJ, 1971, ADV DRUG RES, V6, P53; HENKEL JG, 1995, PRINCIPLES MED CHEM, P58; HILPERT K, 1994, J MED CHEM, V37, P3889, DOI 10.1021/jm00049a008; HIRSCHMANN R, 1995, NEW PERSPECTIVES IN DRUG DESIGN, P1; Hodes L., 1979, ACS SYM SER, V112, P583; HODGKIN EE, 1993, J COMPUT AID MOL DES, V7, P515, DOI 10.1007/BF00124360; HOLLAND JH, 1992, SCI AM, V267, P66; HOLLOWAY MK, 1995, J MED CHEM, V38, P305, DOI 10.1021/jm00002a012; HOPFINGER AJ, 1980, J AM CHEM SOC, V102, P7196, DOI 10.1021/ja00544a005; HOPFINGER AJ, 1981, INTERMOLECULAR FORCE, P431; Hopfinger A.J., 1997, PRACTICAL APPL COMPU, P105; HUBEL S, 1980, PHARMAZIE, V35, P424; Ip SP, 1996, BIOCHEM PHARMACOL, V52, P1687, DOI 10.1016/S0006-2952(96)00517-5; JAIN AN, 1994, J MED CHEM, V37, P2315, DOI 10.1021/jm00041a010; JAMBHEKAR SS, 1995, PRINCIPLES MED CHEM, P12; JOLIFFE IJ, 1986, PRINCIAL COMPONENT A; JORGENSE.EC, 1965, J MED CHEM, V8, P533, DOI 10.1021/jm00328a029; KAKEYA N, 1969, CHEM PHARM BULL, V17, P1010; KAKEYA N, 1969, CHEM PHARM BULL, V17, P2558; KALE RK, 1990, RADIAT PHYS CHEM, V36, P361; KATAKURA S, 1993, BIOCHEM BIOPH RES CO, V197, P965, DOI 10.1006/bbrc.1993.2573; KAUFMAN JJ, 1975, INT J QUANTUM CHEM, P35; Kearsley S. K., 1990, TETRAHEDRON COMPUT M, V3, P615, DOI 10.1016/0898-5529(90)90162-2; KEMPF DJ, 1995, P NATL ACAD SCI USA, V92, P2484, DOI 10.1073/pnas.92.7.2484; KIER LB, 1970, MOL ORBITAL STUDIES; KIER LB, 1980, J PHARM SCI, V69, P807, DOI 10.1002/jps.2600690717; KIER LB, 1976, J PHARM SCI, V65, P1806, DOI 10.1002/jps.2600651228; Kier LB, 1986, MOL CONNECTIVITY STR; Kier LB, 1997, MED CHEM RES, V7, P394; KIER LB, 1995, CHEMOMETRIC METHODS, V2, P39; KIER LB, 1976, J PHARM SCI, V65, P1226, DOI 10.1002/jps.2600650824; KIER LB, 1975, J PHARM SCI, V64, P1971, DOI 10.1002/jps.2600641214; Kier L.B., 1976, MOL CONNECTIVITY CHE; KIRSCHNER GL, 1979, DRUG DESIGN, V8, P73; Kitiyakara C, 1998, CURR OPIN NEPHROL HY, V7, P531, DOI 10.1097/00041552-199809000-00008; Kubinyi H, 1993, QSAR HANSCH ANAL REL; Kubinyi H., 1995, BURGERS MED CHEM DRU, P497; Kumar KV, 1999, TRANSPLANTATION, V67, P1065, DOI 10.1097/00007890-199904150-00022; Lai YL, 1998, J CARDIOVASC PHARM, V32, P714, DOI 10.1097/00005344-199811000-00006; Lebedev A. A., 1996, Eksperimental'naya i Klinicheskaya Farmakologiya, V59, P28; Lee IM, 1999, P ASSOC AM PHYSICIAN, V111, P10, DOI 10.1046/j.1525-1381.1999.09230.x; LEHNINGER AL, 1993, PRINCIPLES BIOCH, P268; LINDQUIST RN, 1975, DRUG DESIGN, V5, P24; Luo XP, 1997, BBA-MOL BASIS DIS, V1360, P45; MAGEE PS, 1990, QUANT STRUCT-ACT REL, V9, P202, DOI 10.1002/qsar.19900090304; Malinowski E.R., 1980, FACTOR ANAL CHEM; MANALLACK DT, 1995, ADV COMPUTER ASSISTE, P293; MARDEROSIAN AHD, 1995, REMINGTON SCI PRACTI, V1, P809; MARSHALL GR, 1995, BURGERS MED CHEM DRU, P573; MARTIN A, 1999, PHYSICAL PHARM, P512; Martin YC, 1978, QUANTITATIVE DRUG DE; MARTIN YC, 1974, NEUROPSYCHOPHARMACOL, P37; MARTIN YC, 1982, STRATEGY DRUG RES, V4, P269; Mathison IW, 1989, PRINCIPLES MED CHEM, P49; MICHEL HJ, 1978, QUANTITATIVE STRUCTU, P89; MONTERO JL, 1974, CR ACAD SCI C CHIM, V279, P809; Montgomery J. A., 1993, Drugs of the Future, V18, P887; Montgomery John A., 1994, Perspectives in Drug Discovery and Design, V2, P205, DOI 10.1007/BF02171744; MORIGUCHI I, 1977, CHEM PHARM BULL, V25, P2800; MURCKO MA, 1997, PRACTICAL APPL COMPU, P305; MURRAY WJ, 1975, J PHARM SCI, V64, P1978, DOI 10.1002/jps.2600641216; MUSSER JH, 1995, BURGERS MED CHEM DRU, V1, P901; Nagy A, 1996, FREE RADICAL BIO MED, V20, P567, DOI 10.1016/0891-5849(95)02046-2; Navia MA, 1992, CURR OPIN STRUC BIOL, V2, P202, DOI 10.1016/0959-440X(92)90147-Y; O'Brien PM, 2000, J MED CHEM, V43, P156, DOI 10.1021/jm9903141; ORTIZ AR, 1995, J MED CHEM, V38, P2681, DOI 10.1021/jm00014a020; PAL DK, 1989, INDIAN J CHEM B, V28, P261; PAL DK, 1990, INDIAN J CHEM B, V29, P451; PAL DK, 1992, INDIAN J CHEM B, V31, P109; PAL DK, 1988, INDIAN J CHEM B, V27, P734; PANDEYA SN, 1998, INTRO DRUG DESIGN, P39; PARKHOMENKO AE, 1996, TERAPEVT ARKH, V65, P47; PEITSCH MC, 1997, PRACTICAL APPL COMPU, P227; PURCELL WP, 1965, BIOCHIM BIOPHYS ACTA, V105, P201; Purcell W.P., 1973, STRATEGY DRUG DESIGN; RAINER F, 1984, THEORETICAL DRUG DES, V7; RANDIC M, 1975, J AM CHEM SOC, V97, P6609, DOI 10.1021/ja00856a001; REMERS WA, 1974, J MED CHEM, V17, P729, DOI 10.1021/jm00253a014; RIPKA WC, 1997, STRUCTURE BASED DRUG, P265; Ross EM, 1996, GOODMAN GILMANS PHAR, P29; ROUOT B, 1977, J PHARMACOL-PARIS, V8, P95; Roy K., 1999, Indian Journal of Pharmaceutical Sciences, V61, P44; Roy K., 2000, Indian Journal of Pharmaceutical Sciences, V62, P46; Roy K., 1999, Indian Journal of Pharmaceutical Sciences, V61, P76; ROY K, 2000, DRUG DESIGN DISCOVER, V17, P483; Roy K, 1999, INDIAN J CHEM B, V38, P1194; Roy K, 1999, INDIAN J CHEM B, V38, P664; Roy K, 1999, INDIAN J CHEM B, V38, P942; Roy K, 2000, Acta Pol Pharm, V57, P385; Roy K, 2001, INDIAN J CHEM B, V40, P209; Roy K., 1998, Indian Journal of Pharmaceutical Sciences, V60, P153; Roy K, 2001, Drug Des Discov, V17, P199; Roy K, 2000, J INDIAN CHEM SOC, V77, P428; Roy Kunal, 2000, Indian Journal of Experimental Biology, V38, P580; Roy K, 2001, INDIAN J CHEM B, V40, P129; ROY K, 2001, IN PRESS INDIAN J B, V40; Roy K, 2001, Drug Des Discov, V17, P207; Saha A, 2000, Acta Pol Pharm, V57, P441; Saha A, 2001, J INDIAN CHEM SOC, V78, P92; Saha A., 2000, Indian Journal of Pharmaceutical Sciences, V62, P115; SCHONFELD JV, 1997, CELL MOL LIFE SCI, V53, P917; Scozzafava A, 2000, J MED CHEM, V43, P1858, DOI 10.1021/jm990594k; Sengupta Mita, 1993, Indian Journal of Experimental Biology, V31, P21; SENGUPTA M, 1995, INDIAN J BIOCHEM BIO, V32, P302; SESTANJ K, 1984, J MED CHEM, V27, P255, DOI 10.1021/jm00369a003; SEYDEL J. K., 1979, CHEM STRUKTUR BIOL A; SEYDEL JK, 1971, ARZNEI-FORSCHUNG, V21, P187; SINGAL PK, 1995, J MOL CELL CARDIOL, V27, P1055, DOI 10.1016/0022-2828(95)90074-8; SPELLMEYER DC, 1997, PRACTICAL APPL COMPU, P165; STACEY NH, 1980, TOXICOL APPL PHARM, V53, P470, DOI 10.1016/0041-008X(80)90359-2; SURESH C, 1999, EVERYMANS SCI, V33, P149; SWEETMAN PM, 1995, BURGERS MED CHEM DRU, V1, P697; Tarin J, 1998, REPROD NUTR DEV, V38, P499, DOI 10.1051/rnd:19980502; THIBAUT U, 1993, 3D QSAR DRUG DESIGN, P661; TOLLENAERE JP, 1976, EUR J MED CHEM, V11, P298; TOPLISS JG, 1972, J MED CHEM, V15, P394, DOI 10.1021/jm00274a017; Touroutoglou N, 1996, CLIN CANCER RES, V2, P227; TRIPATHY KD, 1988, ESSENTIALS MED PHARM, P180; TRIPATHY KD, 1999, ESSENTIALS MED PHARM, P36; TUTE MS, 1995, PRINCIPLES MED CHEM, P50; VANDEWATERBEEMD H, 1995, CHEMOMETRIC METHODS, P283; Venuti M.C., 1995, BURGERS MED CHEM DRU, P661; WALTERS DE, 1994, J MED CHEM, V37, P2527, DOI 10.1021/jm00042a006; WANG CH, 1995, NEW PERSPECTIVES DRU, P35; Weaver W., 1949, MATH THEORY COMMUNIC; WEINSTEIN H, 1974, CHEM BIOCH REACTIVIT, P493; WILLIAMS M, 1995, BURGERS MED CHEM DRU, V1, P349; WILLIAMS M, 1990, DRUG DISCOVERY TECHN, P129; Wilson R. J., 1972, INTRO GRAPH THEORY; WISE M, 1986, MOL GRAPHICS DRUG DE, P183; WOHL JA, 1970, MOL ORBITAL STUDIES, P262; Wold S., 1984, CHEMOMETRICS MATH ST, P17; Wold S., 1995, CHEMOMETRIC METHODS, P196; ZANGER M, 1985, REMINGTONS PHARM SCI, P435; ZIMMERMAN JJ, 1989, PRINCIPLES MED CHEM, P49	194	7	7	0	6	NATL INST SCIENCE COMMUNICATION-NISCAIR	NEW DELHI	DR K S KRISHNAN MARG, PUSA CAMPUS, NEW DELHI 110 012, INDIA	0022-4456	0975-1084		J SCI IND RES INDIA	J. Sci. Ind. Res.	SEP	2001	60	9					699	716				18	Engineering, Multidisciplinary	Engineering	470WM	WOS:000170894300001		
J	Pal, SK; Bandyopadhyay, S; Murthy, CA				Pal, SK; Bandyopadhyay, S; Murthy, CA			Genetic classifiers for remotely sensed images: comparison with standard methods	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article							CLASSIFICATION ACCURACY; PATTERN-CLASSIFICATION; ALGORITHMS	In this article the effectiveness of some recently developed genetic algorithm-based pattern classifiers was investigated in the domain of satellite imagery which usually have complex and overlapping class boundaries. Landsat data, SPOT image and IRS image are considered as input. The superiority of these classifiers over k-NN rule, Bayes' maximum likelihood classifier and multilayer perceptron (MLP) for partitioning different landcover types is established. Results based on producer's accuracy (percentage recognition score), user's accuracy and kappa values are provided. Incorporation of the concept of variable length chromosomes and chromosome discrimination led to superior performance in terms of automatic evolution of the number of hyperplanes for modelling the class boundaries, and the convergence time. This non-parametric classifier requires very little a priori information, unlike k-NN rule and MLP (where the performance depends heavily on the value of k and the architecture, respectively), and Bayes' maximum likelihood classifier (where assumptions regarding the class distribution functions need to be made).	Indian Stat Inst, Machine Intelligence Unit, Kolkata 700035, W Bengal, India	Pal, SK (reprint author), Indian Stat Inst, Machine Intelligence Unit, 203 BT Rd, Kolkata 700035, W Bengal, India.	sankar@isical.ac.in; sanghami@isical.ac.in; murthy@isical.ac.in					Bandyopadhyay S, 1998, PATTERN RECOGN LETT, V19, P1171, DOI 10.1016/S0167-8655(98)00097-X; Bandyopadhyay S, 1998, INFORM SCIENCES, V104, P293, DOI 10.1016/S0020-0255(97)00069-8; CONGALTON RG, 1983, PHOTOGRAMM ENG REM S, V49, P1671; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L. D., 1991, HDB GENETIC ALGORITH; Dayhoff J. E., 1990, NEURAL NETWORK ARCHI; Fukunaga K., 1972, INTRO STAT PATTERN R; GELSEMA ES, 1995, SPECIAL ISSUE GENETI, V16; Goldberg D., 1989, COMPLEX SYSTEMS, V3, P493; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Gonzalez R. C., 1974, PATTERN RECOGNITION; *NRSA, 1986, IRS DATA USERS HDB; PAL A, 1993, INF SCI, V67, P189; PAL A, 1990, THESIS INDIAN STAT I; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; Pal S.K, 1996, GENETIC ALGORITHMS P; Richards J. A., 1993, REMOTE SENSING DIGIT; ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223; SCHRIEVER JR, 1995, PHOTOGRAMM ENG REM S, V61, P321	19	29	33	0	5	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161	1366-5901		INT J REMOTE SENS	Int. J. Remote Sens.	SEP 10	2001	22	13					2545	2569		10.1080/01431160120325		25	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	464WU	WOS:000170557000008		
J	Holst, M; Irle, A				Holst, M; Irle, A			Nearest neighbor classification with dependent training sequences	ANNALS OF STATISTICS			English	Article						nearest neighbor classification; asymptotic risk; dependent training samples	DENSITY-ESTIMATION; CONSISTENCY; REGRESSION	The asymptotic classification risk for nearest neighbor procedures is well understood in the case of i.i.d. training sequences. In this article, we generalize these results to a class of dependent models including hidden Markov models. In the case where the observed patterns have Lebesgue densities, the asymptotic risk takes the same expression as in the i.i.d. case. For discrete distributions, we show that the asymptotic risk depends on the rule used for breaking ties of equal distances.	Univ Kiel, Math Seminar, D-24908 Kiel, Germany	Holst, M (reprint author), Univ Kiel, Math Seminar, Ludewig Meyn Str 4, D-24908 Kiel, Germany.						Adams TM, 1998, ANN PROBAB, V26, P794; Bickel PJ, 1998, ANN STAT, V26, P1614; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B., 1991, NEAREST NEIGHBOR CLA; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Devroye L., 1996, PROBABILISTIC THEORY; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; Fix E., 1951, DISCRIMINATORY ANAL; Fix E., 1952, DISCRIMINATORY ANAL; GYORFI L, 1992, COMPUT STAT DATA AN, V14, P437, DOI 10.1016/0167-9473(92)90059-O; Gyorfi L., 1989, LECT NOTES STAT, V60; Huang X. D., 1990, HIDDEN MARKOV MODELS; Irle A, 1997, J MULTIVARIATE ANAL, V60, P123, DOI 10.1006/jmva.1996.1647; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Leadbetter M. R., 1983, EXTREMES RELATED PRO; MacDonald I. L., 1997, HIDDEN MARKOV OTHER; Morvai G, 1996, ANN STAT, V24, P370; Nobel AB, 1998, IEEE T INFORM THEORY, V44, P537, DOI 10.1109/18.661503; SHANNON CE, 1951, AT&T TECH J, V30, P50; Smith D K, 1994, Qual Health Care, V3, P75, DOI 10.1136/qshc.3.2.75; Snapp RR, 1998, ANN STAT, V26, P850; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Wheeden R. L., 1977, MEASURE INTEGRAL	26	2	2	0	8	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	OCT	2001	29	5					1424	1442				19	Statistics & Probability	Mathematics	513DB	WOS:000173361700010		
J	Picard, RW; Vyzas, E; Healey, J				Picard, RW; Vyzas, E; Healey, J			Toward machine emotional intelligence: Analysis of affective physiological state	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						emotion recognition; physiological patterns; feature selection; Fisher Projection; affective computing; emotional intelligence	FACIAL EXPRESSIONS; FEATURE-SELECTION; IMAGE-ANALYSIS; FACE	The ability to recognize emotion is one of the hallmarks of emotional intelligence, an aspect of human intelligence that has been argued to be even more important than mathematical and verbal intelligences. This paper proposes that machine intelligence needs to include emotional intelligence and demonstrates results toward this goal: developing a machine's ability to recognize human affective state given four physiological signals. We describe difficult Issues unique to obtaining reliable affective data and collect a large set of data from a subject trying to elicit and experience each of eight emotional states, daily, over multiple weeks. This paper presents and compares multiple algorithms for feature-based recognition of emotional state from this data. We analyze four physiological signals that exhibit problematic day-to-day variations: The features of different emotions on the same day tend to cluster more tightly than do the features of the same emotion on different days. To handle the daily variations, we propose new features and algorithms and compare their performance, We find that the technique of seeding a Fisher Projection with the results of Sequential Floating Forward Search improves the performance of the Fisher Projection and provides the highest recognition rates reported to date for classification of affect from physiology: 81 percent recognition accuracy on eight classes of emotion, including neutral.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; MIT, Media Lab, Cambridge, MA 02139 USA	Picard, RW (reprint author), MIT, Media Lab, 20 Ames St, Cambridge, MA 02139 USA.						Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614; Bartlett MS, 1999, PSYCHOPHYSIOLOGY, V36, P253, DOI 10.1017/S0048577299971664; BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037//0022-3514.37.11.2049; Cacioppo J. T., 2000, HDB EMOTIONS, P173; CACIOPPO JT, 1990, AM PSYCHOL, V45, P16, DOI 10.1037/0003-066X.45.1.16; Cannon WB, 1927, AM J PSYCHOL, V39, P106, DOI 10.2307/1415404; Chen L. S., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670976; CLYNES DM, 1977, SENTICS TOUCH EMOTIO; Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Damasio Antonio, 1994, DESCARTES ERROR EMOT; Dawson M. D., 1990, PRINCIPLES PSYCHOPHY, P295; De Silva L. C., 1997, Proceedings of ICICS, 1997 International Conference on Information, Communications and Signal Processing. Theme: Trends in Information Systems Engineering and Wireless Multimedia Communications (Cat. No.97TH8237), DOI 10.1109/ICICS.1997.647126; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Duda R. O., 1973, PATTERN CLASSIFICATI; EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338; ESSA I, 1997, P WORKSH PERC US INT, P45; ESSA IA, 1995, THESIS MIT MED LAB; Fridlund AJ, 1983, SOCIAL PSYCHOPHYSIOL, P243; Goleman D., 1995, EMOTIONAL INTELLIGEN; HAMA H, 1990, PERCEPT MOTOR SKILL, V70, P371; HANSEN J, 1999, P INT C AC SPEECH SI; Healey J., 1998, P WORKSH PERC US INT; HEALEY J, 1998, P IEEE INT C AC SPEE; HEALEY JA, 2000, 526 MIT; Huang TS, 1998, P ATR WORKSH VIRT CO; IZARD CE, 1993, PSYCHOL REV, V100, P68, DOI 10.1037//0033-295X.100.1.68; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; James W., 1992, W JAMES WRITINGS 187, P350; Keltner D., 2000, HDB EMOTIONS, P236; LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037//0003-066X.50.5.372; LeDoux J. E., 1996, EMOTIONAL BRAIN; LYYKEN DT, 1971, PSYCHOPHYSIOLOGY, V8, P656; LYYKEN DT, 1966, PSYCHOPHYSIOLOGICAL, V66, P481; Oppenheim A. V., 1989, DISCRETE TIME SIGNAL; Picard R. W., 1997, AFFECTIVE COMPUTING; Picard Rosalind, 1997, PERSONAL TECHNOLOGIE, V1, P231, DOI 10.1007/BF01682026; POLZIN T, 2000, THESIS SCH COMP SCI; PUDIL P, 1994, IMAGE VISION COMPUT, V12, P193, DOI 10.1016/0262-8856(94)90072-8; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Reeves B., 1996, MEDIA EQUATION; Salovey P., 1990, IMAGINATION COGNITIO, V9, P185, DOI DOI 10.2190/DUGG-P24E-52WK-6CDG; SCHACHTER S, 1964, ADV EXP SOC PSYCHOL, V1, P49, DOI 10.1016/S0065-2601(08)60048-9; SCHEIRER J, 2001, IN PRESS INTERACTION; Scherer K.R., 1981, SPEECH EVALUATION PS, P189; SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570; Sigman M., 1997, CHILDREN AUTISM DEV; VYZAS E, 1998, P AAAI 1998 FALL S E; VYZAS E, 1999, P EM BAS AG ARCH 3 I, P135; WINTON WM, 1984, J EXP SOC PSYCHOL, V20, P195, DOI 10.1016/0022-1031(84)90047-7; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414	51	492	517	7	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1175	1191		10.1109/34.954607		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	482QK	WOS:000171586600011		
J	Divakaran, A; Radhakrishnan, R; Peker, KA				Divakaran, A; Radhakrishnan, R; Peker, KA			Video summarization using descriptors of motion activity: A motion activity based approach to key-frame extraction from video shots	JOURNAL OF ELECTRONIC IMAGING			English	Article							CLUSTERING METHODS; REPRESENTATION; VALIDITY	We describe a video summarization technique that uses motion descriptors computed in the compressed domain, It can either speed up conventional color-based video summarization techniques, or rapidly generate a key-frame based summary by itself. The basic hypothesis of the work is that the intensity of motion activity of a video segment is a direct indication of its "summarizability," which we experimentally verify using the MPEG-7 [MPEG-7 Visual Committee Draft URL: http.,//www.cselt.it/mpeg/working documents.htm official MPEG site] motion activity descriptor and the fidelity measure proposed in H. S. Chang, S. Sull, and S. U. Lee, "Efficient video indexing scheme for content-based retrieval, " IEEE Trans, Circuits Syst. Video Technol. 9(8), (1999). Note that the compressed domain extraction of motion activity intensity is much simpler than the color-based calculations. We are thus able to quickly identify easy to summarize segments of a video sequence since they have a low intensity of motion activity. We are able to easily summarize these segments by simply choosing their first frames. We can then apply conventional color-based summarization techniques to the remaining segments. We thus speed up color-based summarization by reducing the number of segments processed. Our results also motivate a simple and novel key-frame extraction technique that relies on a motion activity based nonuniform sampling of the frames. Our results indicate that it can either be used by itself or to speed up color-based techniques as explained earlier. (C) 2001 SPIE and IS&T.	Mitsubishi Elect Res Labs, Murray Hill, NJ 07834 USA; Polytech Univ, Brooklyn, NY 11201 USA	Divakaran, A (reprint author), Mitsubishi Elect Res Labs, 571 Cent Ave, Murray Hill, NJ 07834 USA.						AIGRAIN P, 1995, P SOC PHOTO-OPT INS, V2417, P35, DOI 10.1117/12.206061; [Anonymous], 2001, JTC1SC29WG11N4062 IS; AOKI H, 1996, P ACM MULT 96 BOST M; BEDNAR JB, 1984, IEEE T ACOUST SPEECH, V32, P145, DOI 10.1109/TASSP.1984.1164279; Bezdek J. C., 1981, PATTERN RECOGNITION; Boreczky J. S., 1998, P INT C AC SPEECH SI, V6, P3741, DOI 10.1109/ICASSP.1998.679697; Butler S, 1996, SIGNAL PROCESS-IMAGE, V8, P269, DOI 10.1016/0923-5965(95)00052-6; Cios K. J., 1998, DATA MINING METHODS; COLL DC, 1976, IEEE T COMMUN, V27, P1201; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EICKELER S, 1999, P ICASSP PHOEN MAR, V6, P2999; FERMAN AM, 1998, P SOC PHOTO-OPT INS, V3312, P71; Ferman AM, 1998, J VIS COMMUN IMAGE R, V9, P336, DOI 10.1006/jvci.1998.0402; FERMAN AM, UNPUB IEEE T IMAGE P; FERMAN AM, 1999, P IEEE ICIP KOB JAP; Fischer S., 1995, P ACM MULT 95 SAN FR, P295, DOI 10.1145/217279.215283; Gonzalez R. C., 1974, PATTERN RECOGNITION; Han J. H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), DOI 10.1109/CVPR.1999.784711; Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162; ISENHOUR JP, 1975, AV COMMUN REV, V23, P69; *ISO IEC, 2001, JTC1SC29WG11N4002 IS; *ISO IEC, 2001, JTC1SC29WG11N3966 IS; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Kasturi R., 1991, COMPUTER VISION PRIN, P469; Kawin Bruce, 1987, MOVIES WORK; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kuncheva LI, 1998, INT J UNCERTAIN FUZZ, V6, P437, DOI 10.1142/S0218488598000355; MARTIENZ JM, 2001, JTC1SC29WG11N4031 IS; MILLERSON G, 1990, TECHNIQUE TELEVISION; *MPEG7 VID GROUP, 1999, JTC1SC29WG11N2466 IS; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; Salt Barry, 1992, FILM STYLE TECHNOLOG; VASCONCELOS N, 1998, P IEEE INT C IM PROC, V3, P153, DOI 10.1109/ICIP.1998.999006; W3C, 2001, XML SCHEM; WOLF W, 1997, P ICASSP, V4, P2609; WORTH S, 1968, AV COMMUN REV, V16, P121; Xie X.L., 1991, IEEE T PAMI, V3, P841, DOI DOI 10.1109/34.85677; Yeung M. M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.546973; YEUNG MM, 1995, P SOC PHOTO-OPT INS, V2417, P399, DOI 10.1117/12.206067; Yeung M.M., 1995, INT C IM PROC, V1, P338; Zhang H. J., 1993, ACM MULTIMEDIA SYSTE, V1, P10; Zhong D, 1996, PROC SPIE, V2670, P239, DOI 10.1117/12.234800	42	17	18	1	4	I S & T - SOC IMAGING SCIENCE TECHNOLOGY	SPRINGFIELD	7003 KILWORTH LANE, SPRINGFIELD, VA 22151 USA	1017-9909			J ELECTRON IMAGING	J. Electron. Imaging	OCT	2001	10	4					909	929		10.1117/1.1406507		21	Engineering, Electrical & Electronic; Optics; Imaging Science & Photographic Technology	Engineering; Optics; Imaging Science & Photographic Technology	495RY	WOS:000172355200008		
J	Sbai, EH				Sbai, EH			Cluster analysis by adaptive rank-order filters	PATTERN RECOGNITION			English	Article						cluster analysis; mode; probability density function (pdf); rank-order; entropy	MORPHOLOGY	An adaptive filter is proposed for detecting the modes of underlying probability density function of the data. The adaptive procedure is based on the selection of an appropriate rank order according to the local measurements of the entropy of the density function. The approach requires no a priori information about the structure of the data set but it is governed by the sampling parameter. Experiments demonstrate the usefulness of the filter. (C) 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Univ Moulay Ismail, Ecole Super Technol, Meknes 50006, Morocco	Sbai, EH (reprint author), Univ Moulay Ismail, Ecole Super Technol, Route Agouray,BP 3103, Meknes 50006, Morocco.						BOVIK AC, 1983, IEEE T ACOUST SPEECH, V31, P1342, DOI 10.1109/TASSP.1983.1164247; Brink AD, 1996, PATTERN RECOGN LETT, V17, P29, DOI 10.1016/0167-8655(95)00096-8; CACOULLOS T, 1966, ANN I STAT MATH, V18, P178; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1977, Proceedings of the International Conference on Cybernetics and Society; David H. A., 1980, ORDER STAT; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L., 1985, NONPARAMETRIC DENSIT; DUDA RO, 1965, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; GOIN JE, 1982, PATTERN RECOGN, V15, P263, DOI 10.1016/0031-3203(82)90077-2; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Justusson B.J., 1981, 2 DIMENSIONAL DIGITA, V2, P161; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; POSTAIRE JG, 1982, IEEE T PATTERN ANAL, V4, P663; POSTAIRE JG, 1993, IEEE T PATTERN ANAL, V15, P170, DOI 10.1109/34.192490; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3, P163; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Serra J., 1982, IMAGE ANAL MATH MORP; SHANNON CE, 1904, MATH THEORY COMMUNUC; VASSEUR CPA, 1980, IEEE T SYST MAN CYB, V10, P145; ZHANG RD, 1994, PATTERN RECOGN, V27, P135, DOI 10.1016/0031-3203(94)90023-X	26	2	2	0	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	OCT	2001	34	10					2015	2027		10.1016/S0031-3203(00)00130-8		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	462JP	WOS:000170417200012		
J	Li, WB; Friedland, W; Pomplun, E; Jacob, P; Paretzke, HG; Lassmann, M; Reiners, C				Li, WB; Friedland, W; Pomplun, E; Jacob, P; Paretzke, HG; Lassmann, M; Reiners, C			Track structures and dose distributions from decays of I-131 and I-125 in and around water spheres simulating micrometastases of differentiated thyroid cancer	RADIATION RESEARCH			English	Article							MONTE-CARLO SIMULATION; INTERNALIZING ANTIBODIES; RADIOACTIVE IODINE; I125 SEED; RADIATION; CARCINOMA; DOSIMETRY; RADIONUCLIDES; RADIOIODINE; THERAPY	The disintegration of the radionuclides I-131 and I-125 and the subsequent charged-particle tracks left behind in water (as a model substance for a biological cell) are simulated by the Monte Carlo track structure simulation code PARTRAC, using new inelastic electron scattering cross sections for condensed water. Every photon and electron emitted was followed in detail, event by event, down to 10 eV. From the spatial information on the track structures, absorbed dose distributions per I-131 and I-121 decay were calculated in and around water spheres simulating micrometastases as well as in the tissue surrounding such metastases. These radionuclides were assumed to be distributed uniformly inside spheres of different diameters (0.01, 0.03, 0.1, 0.3, 1.0 and 3.0 nun). The respective electron degradation spectra, the nearest-neighbor distance distributions between inelastic events, and the distance distributions for all activations for both iodine radionuclides were calculated. The absorbed fractions of the initial electron energies, absorbed doses and energy depositions, and single-event distributions, F-1(epsilon), inside the six water spheres described above and in the surrounding tissue were also calculated. The absorbed doses per decay inside the six water spheres, i.e., the calculated S values (listed from 0.01 to 3.0 nun), were 6.8 x 10(-4), 7.2 x 10(-5), 5.5 x 10(-6), 4.9 x 10(-7), 3.1 x 10(-8) and 1.8 x 10(-9) Gy Bq(-1) s(-1) for I-131, and 3.4 x 10(-3), 1.7 x 10(-4), 5.1 x 10(-6), 2.0 x 10(-1), 5.6 x 10(-9) and 2.2 x 10(-11) Gy Bq(-1) s(-1) for I-125. It is concluded that in the treatment of thyroid cancer, the geometrical track structure properties of I-125 might be superior to those of I-131 in micrometastases with diameters less than 0.1 nun; however, in this medical context, many other factors also have to be considered. (C) 2001 by Radiation Research Society.	Inst Radiat Protect, Natl Res Ctr Environm & Hlth, GSF, D-85764 Neuherberg, Germany	Li, WB (reprint author), Inst Radiat Protect, Natl Res Ctr Environm & Hlth, GSF, D-85764 Neuherberg, Germany.		Lassmann, Michael/B-2284-2013; Li, Weibo/M-7475-2013				AKABANI G, 1991, J NUCL MED, V32, P835; BEARDEN JA, 1967, REV MOD PHYS, V39, P125, DOI 10.1103/RevModPhys.39.125; Behr TM, 2000, EUR J NUCL MED, V27, P753, DOI 10.1007/s002590000272; Behr TM, 1998, INT J CANCER, V76, P738, DOI 10.1002/(SICI)1097-0215(19980529)76:5<738::AID-IJC20>3.0.CO;2-Z; BEHRENS H, 1969, LANDOLTBORNSTEIN NUM, V4; BEIERWALTES WH, 1978, SEMIN NUCL MED, V8, P95, DOI 10.1016/S0001-2998(78)80010-5; BEIERWALTES WH, 1979, SEMIN NUCL MED, V9, P151, DOI 10.1016/S0001-2998(79)80023-9; BEIERWALTES WH, 1978, SEMIN NUCL MED, V8, P79, DOI 10.1016/S0001-2998(78)80009-9; BENUA RS, 1962, AMER J ROENTGENOL RA, V87, P171; BERGER MJ, 1971, DISTRIBUTION ABSORBE; BOOZ J, 1987, RADIAT ENVIRON BIOPH, V26, P151, DOI 10.1007/BF01211409; BURNS GS, 1988, MED PHYS, V15, P56, DOI 10.1118/1.596151; CHARLTON DE, 1981, RADIAT RES, V87, P10, DOI 10.2307/3575537; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS WG, 1983, PHYS MED BIOL, V28, P1251, DOI 10.1088/0031-9155/28/11/005; DALE RG, 1983, MED PHYS, V10, P176, DOI 10.1118/1.595297; DILLMAN MJ, 1980, TM6689 ORNL; Dingfelder M, 1998, RADIAT PHYS CHEM, V53, P1; Dottorini ME, 1997, J NUCL MED, V38, P669; Evans R. D, 1956, ATOMIC NUCL; Friedland W, 1998, RADIAT RES, V150, P170, DOI 10.2307/3579852; Goddu S, 1997, MIRD CELLULAR S VALU; GODDU SM, 1994, J NUCL MED, V35, P521; Govindan SV, 2000, J NUCL MED, V41, P2089; Hartman T, 2000, INT J RADIAT ONCOL, V46, P1025, DOI 10.1016/S0360-3016(99)00476-9; HENSS S, 1992, BIOPHYSICAL MODELLIN, P67; *ICRP, 1983, PUBLICATION ICRP, V38; *ICRU, 1998, 60 ICRU INT COMM RAD; *ICRU, 1983, 36 ICRU INT COMM RAD; *ICRU, 1997, 56 INT COMM RAD UN M; JUNGERMAN JA, 1984, INT J APPL RADIAT IS, V35, P883, DOI 10.1016/0020-708X(84)90025-5; KONOPINSKY EJ, 1965, ALPHA BETA GAMMA RAY, V2, P1327; KRISHNASWAMY V, 1978, RADIOLOGY, V126, P489; LING CC, 1985, MED PHYS, V12, P652, DOI 10.1118/1.595689; LOEVINGER R., 1988, MIRD PRIMER ABSORBED; LOEVINGE.R, 1968, PHYS MED BIOL, V13, P205, DOI 10.1088/0031-9155/13/2/306; MAXON HR, 1992, J NUCL MED, V33, P1132; Maxon HR, 1997, THYROID, V7, P183, DOI 10.1089/thy.1997.7.183; *NAT NUCL DAT CTR, 1998, NUCL STRUCT DEC DAT; Paretzke H.G., 1987, KINETICS NONHOMOGENE, P89; POMPLUN E, 1987, RADIAT RES, V111, P533, DOI 10.2307/3576938; REINERS C, 1996, THYR ID MERCK EUR TH, P89; REINERS CHR, 1999, RAD THYROID CANC, P407; ROSSI HH, 1996, MICRODOSIMETRY ITS A; SAENGER EL, 1979, SEMIN NUCL MED, V9, P72, DOI 10.1016/S0001-2998(79)80038-0; SCHLESINGER T, 1989, RADIOTHER ONCOL, V14, P35, DOI 10.1016/0167-8140(89)90006-6; SCHLUMBERGER M, 1987, J CLIN ENDOCR METAB, V65, P1088; SINCLAIR WK, 1956, BRIT J RADIOL, V29, P36; SISSON J, 1997, THYROID, V7, P312; Stabin MG, 1996, J NUCL MED, V37, P538; SYNDER WS, 1975, ABSORBED DOSE PER UN; VASSILOPOULOUSELLIN R, 1993, CANCER, V71, P1348, DOI 10.1002/1097-0142(19930215)71:4<1348::AID-CNCR2820710429>3.0.CO;2-3; WU CS, 1965, ALPHA BETA GAMMA RAY, V2, P1365	53	19	21	0	0	RADIATION RESEARCH SOC	OAK BROOK	820 JORIE BOULEVARD, OAK BROOK, IL 60523 USA	0033-7587			RADIAT RES	Radiat. Res.	OCT	2001	156	4					419	429		10.1667/0033-7587(2001)156[0419:TSADDF]2.0.CO;2		11	Biology; Biophysics; Radiology, Nuclear Medicine & Medical Imaging	Life Sciences & Biomedicine - Other Topics; Biophysics; Radiology, Nuclear Medicine & Medical Imaging	478DE	WOS:000171327000010	11554854	
J	Sadek, AW; Smith, BL; Demetsky, MJ				Sadek, AW; Smith, BL; Demetsky, MJ			A prototype case-based reasoning system for real-time freeway traffic routing	TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES			English	Article						case-based reasoning; real-time traffic routing; intelligent transportation systems; artificial intelligence; decision support systems	ASSIGNMENT; MODEL	With the recent advances in communications and information technology, real-time traffic routing has emerged as a promising approach to alleviating congestion. Existing approaches to developing real-time routing strategies, however, have limitations. This study examines the potential for using case-based reasoning (CBR). an emerging artificial intelligence paradigm, to overcome such limitations. CBR solves new problems by reusing solutions of similar past problems. To illustrate the feasibility of the approach, the study develops and evaluates a prototype CBR routing system for the interstate network in Hampton Roads, Virginia. Cases for building the system's case-base are generated using a heuristic dynamic traffic assignment (DTA) model designed for the region. Using a second set of cases, the study evaluates the performance of the prototype system by comparing its solutions to those of the DTA model. The evaluation results demonstrate that the prototype system is capable of running in real-time, and of producing high quality solutions using case-bases of reasonable size. (C) 2001 Elsevier Science Ltd. All rights reserved.	Univ Vermont, Dept Civil & Environm Engn, Burlington, VT 05405 USA; Univ Virginia, Dept Civil Engn, Charlottesville, VA 22903 USA	Sadek, AW (reprint author), Univ Vermont, Dept Civil & Environm Engn, 213-B Votey, Burlington, VT 05405 USA.						Aerde M. V., 1988, TRANSPORT RES A-POL, V22A, P435; AAMODT A, 1994, AI COMMUN, V7, P39; Blumentritt C. W., 1981, 232 NCHRP TRB NAT RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIESZ TL, 1989, OPER RES, V37, P893, DOI 10.1287/opre.37.6.893; GUPTA A, 1992, TRANSPORT RES REC, V1358, P60; JAYAKRISHNAN R, 1995, TRANSPORT RES C-EMER, V3, P51, DOI 10.1016/0968-090X(94)00015-W; KHATTAK A, 1996, TRANSPORTATION RES C, V3, P267; Kirkpatrick S., 1983, SCIENCE, V220; LAFORTUNE S, 1993, TRANSPORT RES B-METH, V27, P451, DOI 10.1016/0191-2615(93)90017-5; MADANAT SM, 1996, TRANSPORT RES REC, V1537, P98, DOI 10.3141/1537-14; Mahmassani H, 1993, LARGE URBAN SYSTEMS, P91; Merchant D. K., 1978, Transportation Science, V12, DOI 10.1287/trsc.12.3.183; PAPAGEORGIOU M, 1990, TRANSPORT RES B-METH, V24, P471, DOI 10.1016/0191-2615(90)90041-V; PEETA S, 1995, TRANSPORT RES C-EMER, V3, P83, DOI 10.1016/0968-090X(94)00016-X; RAN B, 1993, OPER RES, V41, P192, DOI 10.1287/opre.41.1.192; RITCHIE SG, 1991, TRANSPORT RES REC, V1320, P7; SADEK AW, 1998, TRANSPORTATION RES R, V1651; SADEK AW, 1999, IN PRESS TRANSPORTAT; Smith B.L., 1994, TRANSPORT RES REC, V1453, P98; Smith B.L., 1996, TRANSPORT RES REC, V1554, P136, DOI 10.3141/1554-17; WATSON I, 1995, P 1 UK WORKSH SALF U, P1; WETTSCHERECK D, 1995, P 1 INT C CAS BAS RE, P359	23	11	12	0	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0968-090X			TRANSPORT RES C-EMER	Transp. Res. Pt. C-Emerg. Technol.	OCT	2001	9	5					353	380		10.1016/S0968-090X(00)00046-2		28	Transportation Science & Technology	Transportation	462XK	WOS:000170444900004		
S	Wada, Y; Kasuga, H; Sumita, K		Kasturi, R; Laurendeau, D; Suen, C		Wada, Y; Kasuga, H; Sumita, K			An evolutionary approach for the generation of diversiform characters using a handwriting model	16TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL III, PROCEEDINGS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	16th International Conference on Pattern Recognition (ICPR)	AUG 11-15, 2002	QUEBEC CITY, CANADA	Int Assoc Pattern Recognit, Canadian Image Processing & Pattern Recognit Soc, Ctr Rech Informat Montreal, Matrox Imaging, Ind & Commerce Quebec, Rech, Sci & Technol Quebec, Microsoft Res, Bell, Lab Vis & Syst Numer, Comp Vis & Syst Lab, Ctr Pattern Recognit & Machine Intelligence, Ctr Etudes Reconnaissance Formes & Intelligence Artificielle, Scribers, Coreco Imaging, Precarn			ARM	In pattern recognition, a large number of diversiform characters is necessary to train / test a handwritten character recognition system. However it is not easy to collect a large number of natural samples. The artificial diversification of characters has been suggested as one means of collecting a variety of characters[1]. In this paper, we show that a handwriting model can be applied to the diversification of characters. The characters diversified by the model can be used as a database of character images for training / testing purposes. Wada & Kawato's handwriting model [2] is based on an optimal principle and the feature space of the characters includes sets of via-points extracted from actual handwritten characters. The handwriting model can be used to generate a variety of characters by changing via point information. In this paper we propose a method for generating a large variety of characters by changing via-point information based on a genetic algorithm and we show that the accuracy of a handwritten character recognition system that uses the characters generated by the proposed method as the training data, is equivalent to that of a system composed by using natural data.	Nagaoka Univ Technol, Nagaoka, Niigata 94021, Japan	Wada, Y (reprint author), Nagaoka Univ Technol, 1603-1, Nagaoka, Niigata 94021, Japan.		Wada, Yasuhiro/D-2587-2011	Wada, Yasuhiro/0000-0003-0268-8921			COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELMAN S, 1987, BIOL CYBERN, V57, P25, DOI 10.1007/BF00318713; FLASH T, 1985, J NEUROSCI, V5, P1688; Ghosh D, 1999, PATTERN RECOGN, V32, P907, DOI 10.1016/S0031-3203(98)00114-9; GLUCKSMAN H, 1967, IEEE COMP C, P138; HASE H, 1988, IEICE T D, V71, P1048; Iijima T., 1973, P 1 INT JOINT C PATT, P50; ISHII K, 1983, IEICE D, V66, P1270; Nakano E, 1999, J NEUROPHYSIOL, V81, P2140; Nilsson NJ, 1965, LEARNING MACHINES; Plamondon R, 1998, BIOL CYBERN, V78, P119, DOI 10.1007/s004220050419; WADA Y, 1995, BIOL CYBERN, V73, P3, DOI 10.1007/BF00199051	12	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-1695-X	INT C PATT RECOG			2002							131	134				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BV12Q	WOS:000177887100032		
S	Paredes, R; Vidal, E; Keysers, D		Kasturi, R; Laurendeau, D; Suen, C		Paredes, R; Vidal, E; Keysers, D			An evaluation of the WPE algorithm using tangent distance.	16TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITON, VOL IV, PROCEEDINGS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	16th International Conference on Pattern Recognition (ICPR)	AUG 11-15, 2002	QUEBEC CITY, CANADA	Int Assoc Pattern Recognit, Canadian Image Processing & Pattern Recognit Soc, Ctr Rech Informat Montreal, Matrox Imaging, Ind & Commerce Quebec, Rech, Sci & Technol Quebec, Microsoft Res, Bell, Lab Vis & Syst Numer, Comp Vis & Syst Lab, Ctr Pattern Recognit & Machine Intelligence, Ctr Etudes Reconnaissance Formes & Intelligence Artificielle, Scribers, Coreco Imaging, Precarn		editing; condensing; Nearest Neighbour; weighted prototypes; tangent distance		Weighting Prototype Editing (WPE) is a novel approach to edit a given set of prototypes so that the resulting set can outperform the original one in terms of the Nearest Neighbor (NN) classification accuracy This technique is applied in this work along with tin interesting dissimilarity measure between pixel maps, known as Tangent Distance (TD). Experiments on the USPS handwriting digits benchmark corpus are presented, with results showing the capability of the WPE to improve the already good results based on TD NN classification.	Univ Politecn Valencia, Inst Tecnol Informat, E-46071 Valencia, Spain	Paredes, R (reprint author), Univ Politecn Valencia, Inst Tecnol Informat, E-46071 Valencia, Spain.	rparedes@iti.upv.es; evidal@iti.upv.es; keysers@I6.Informatik.RWTH-Aachen.DE					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DEVROYE G, 1995, PROBABILISTIC THEORY; KEYSERS D, 2001, LNCS, V2167, P263; Keysers D., 2000, P 15 INT C PATT REC, V2, P38, DOI 10.1109/ICPR.2000.906014; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; PAREDES R, 2000, 15 INT C PATT REC 15; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	11	2	2	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-1695-X	INT C PATT RECOG			2002							48	51				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BV12R	WOS:000177887500011		
S	Demiros, I; Antonopoulos, V; Georgantopoulos, B; Triantafyllou, Y; Piperidis, S			IEEE; IEEE; IEEE; IEEE	Demiros, I; Antonopoulos, V; Georgantopoulos, B; Triantafyllou, Y; Piperidis, S			Connectionist models for sentence-based text extracts	2001 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-5: E-SYSTEMS AND E-MAN FOR CYBERNETICS IN CYBERSPACE	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics (SMC)	OCT 07-10, 2001	TUCSON, AZ	IEEE, Raytheon		summarization; term extraction; statistical filtering; self-organizing maps; neural networks		This paper addresses the problem of creating a summary by extracting a set of sentences that are likely to represent the content of a document. A small scale experiment is conducted leading to the compilation of an evaluation corpus for the Greek language. Two models of sentence extraction are then described, along the lines of shallow linguistic analysis, feature combination and machine learning. Both models are based on term extraction and statistical filtering. After extracting the individual features of the text, we apply them to two neural networks that classify each sentence depending on its feature vector, the term weight being the feature with the best discriminant capacity. A three-layer feedforward network trained with the highly popular backpropagation algorithm and a competitive learning self-organizing reap characterized by the formation of a topographic map, both trained on a small manually annotated corpus of summaries, perform the sentence extraction task. Both methods could be used for rapid light information retrieval-oriented summarization.	Inst Language & Speech Proc, Athens 15125, Greece	Demiros, I (reprint author), Inst Language & Speech Proc, Artemidos 6 & Epidavrou, Athens 15125, Greece.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aone Chinatsu, 1998, P 36 ANN M ASS COMP, P62; Barzilay R., 1997, P ACL WORKSH INT SCA, P10; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2000, TIMBL; EDMUNDSO.HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519; FIRMIN T, 1998, ADV AUTOMATIC TEXT S, P325; FUM D, 1985, P 9 INT JOINT C ART, P840; GAVRILIDOU M, 1999, LREI62048; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Jones K. S., 1998, ADV AUTOMATIC TEXT S, P1; KOHONEN T, 1989, SELF ORGANIZATION AS; Kohonen T., 2000, IEEE T NEURAL NETWOR, V11; Kupiec J., 1995, P 18 ACM SIGIR C, P88; LEHNERT W, 1981, 7 INT JOINT C ART IN; LIN X, 1991, P ANN INT CM SIGIR C; LUHN HP, 1958, IBM J RES DEV, V2, P159; Marcu D., 1997, ACL EACL 97 SUMM WOR, P82; MITCHELL T, 1997, MACHINGE LEARNING; Mittal V., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); MORRIS A, 1998, ADV AUTOMATIC TEXT S, P305; MYAENG SH, 1998, ADV AUATOMATIC TEXT, P61; Nguyen D., 1990, P INT JOINT C NEUR N; PIPERIDIS S, 1999, ASLIB TRANSLATING CO; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SKOUSEN R, 1989, ANAL MODELING LANGUA; STANFILL C, 1986, COMMUN ACM, V29, P1212; TEUFEL S, 1998, ADV AUTOMATIC TEXT S, P155; Zechner K., 1996, P 16 INT C COMP LING, P986	29	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		0-7803-7087-2	IEEE SYS MAN CYBERN			2002							2648	2653				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BU92K	WOS:000177404200464		
B	Tsiriga, V; Virvou, M			IEEE; IEEE	Tsiriga, V; Virvou, M			Dynamically initializing the student model in a web-based language tutor	2002 FIRST INTERNATIONAL IEEE SYMPOSIUM INTELLIGENT SYSTEMS, VOL 1, PROCEEDINGS			English	Proceedings Paper	1st International IEEE Symposium on Intelligent Systems	SEP 10-12, 2002	VARNA, BULGARIA	IEEE Control Syst Soc, IEEE Instrumentat & Measurement Soc, IEEE Reg 8, Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, IEE IM CS SMC Joint Chapter Bulgaria, IEEE Sect Bulgaria, ICT Dev Agcy, EUNITE		intelligent tutoring systems; student model initialization; distance weighted k-nearest neighbor; stereotypes	MULTISTRATEGY	In this paper we describe the method for initializing the student model in a Web-based language tutor. This tutor is an Intelligent Tutoring System (ITS) that operates on the WWW and aims at teaching non-native speakers the domain of the passive voice of the English language. It uses an innovative combination of stereotypes and the distance weighted k-nearest neighbor algorithm to initialize the model of a new student. In particular, the student is first assigned to a stereotype category concerning her/his knowledge level based on her/his performance on a preliminary test. The system then initializes all aspects of the student model using the distance weighted k-nearest neighbor algorithm among the students that belong to the same stereotype category with the new student. The basic idea of the algorithm is to weigh the contribution of each of the neighbor students according to their distance from the new student; the distance between students is calculated based on a similarity measure. In our case the similarity measure is estimated taking into account the students' mother tongue, how careful they are when solving exercises, as well as their knowledge of other languages. This information is acquired directly by the student at her/his first interaction with the system.	Univ Piraeus, Dept Informat, Piraeus 18534, Greece	Tsiriga, V (reprint author), Univ Piraeus, Dept Informat, 80 Karaoli & Dimitriou St, Piraeus 18534, Greece.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Baffes P., 1996, Journal of Artificial Intelligence in Education, V7; Ballim A., 1991, User Modeling and User-Adapted Interaction, V1, DOI 10.1007/BF00158951; Burton R. R., 1982, INTELLIGENT TUTORING, P157; CHIN DN, 1989, USER MODELS DIALOG S, P74; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Emde W., 1996, P 13 INT C MACH LEAR, P122; Hoppe H. U., 1994, Journal of Artificial Intelligence in Education, V5; Huang X., 1991, USER MODEL USER-ADAP, V1, P87, DOI 10.1007/BF00158953; Kay J, 2000, LECT NOTES COMPUT SC, V1839, P19; Kono Y., 1994, Journal of Artificial Intelligence in Education, V5; Langley P., 1984, P NATIONAL C ARTIFIC, P193; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; MICHAUD LN, 2001, P 8 INT C US MOD SON, P14; Mitchell T. M., 1997, MACHINE LEARNING; Murphy M., 1997, P 6 INT C US MOD, P301; Rich E., 1979, COGNITIVE SCI, V3, P329, DOI DOI 10.1207/515516709C0G0304_3; RICH E, 1983, INT J MAN MACH STUD, V18, P199, DOI 10.1016/S0020-7373(83)80007-8; Sison R., 1998, INT J ARTIFICIAL INT, V9, P128; Sison R, 1998, USER MODEL USER-ADAP, V8, P103, DOI 10.1023/A:1008225015395; Sison RC, 2000, MACH LEARN, V38, P157, DOI 10.1023/A:1007690108308; SLEEMAN D, 1987, ARTIFICIAL INTELIGEN; Virvou M, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P131; Weber G., 1997, P 6 INT C US MOD, P289; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	27	0	0	0	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7601-3				2002							138	143				6	Computer Science, Artificial Intelligence	Computer Science	BW08J	WOS:000180818600024		
B	Lazzerini, B; Marcelloni, F		Zakharevich, VG; Kureichik, VM		Lazzerini, B; Marcelloni, F			K-NN algorithm based on neural similarity	2002 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE SYSTEMS, PROCEEDINGS			English	Proceedings Paper	IEEE International Conference on Artificial Intelligence Systems (ICAIS 2002)	SEP 05-10, 2002	DIVNOMORSKOE, RUSSIA	IEEE Comp Soc, Minist Educ Russian Federat, Taganrog State Univ Radio Engn, World Federat Sof Comp, Russian Assoc Artificial Intelligence, Russian Fdn Basic Res, Russian Acad Nat Sci				The aim of this paper is to present a k-nearest neighbour (k-NN) classifier based on a neural model of the similarity measure between data. After a preliminary phase of supervised learning for similarity determination, we use the neural similarity measure to guide the k-NN rule. Experiments on both synthetic and real-world data show that the similarity-based k-NN rule outperforms the Euclidean distance-based k-NN rule.	Univ Pisa, Dipartimento Ingn Informaz, I-56122 Pisa, Italy	Lazzerini, B (reprint author), Univ Pisa, Dipartimento Ingn Informaz, Via Diotisalvi 2, I-56122 Pisa, Italy.						Aha D.W., 1998, FEATURE EXTRACTION C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; Jain AK, 1999, ACM COMPUT SURV, V31, P265; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; MICHALSKI RS, 1983, IEEE T PATTERN ANAL, V5, P396; PEDYCZ W, 2001, P 2 INT WORKSH SOFT; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	9	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1733-1				2002							67	70				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	BV23P	WOS:000178285500014		
B	Vasilic, S; Kezunovic, M			IEEE; IEEE	Vasilic, S; Kezunovic, M			An improved neural network algorithm for classifying the transmission line faults	2002 IEEE POWER ENGINEERING SOCIETY WINTER MEETING, VOLS 1 AND 2, CONFERENCE PROCEEDINGS			English	Proceedings Paper	Winter Meeting of the IEEE-Power-Engineering-Society	JAN 27-31, 2002	NEW YORK, NY	IEEE Power Engn Soc		clustering methods; electromagnetic transients; neural networks; pattern classification; power system faults; protective relaying; testing; training.	NETS	This study introduces a new concept of artificial intelligence based algorithm for classifying the faults in power system networks. This classification identifies the exact type and zone of the fault. The algorithm is based on unique type of neural network specially developed to deal with large set of highly dimensional input data. An improvement of the algorithm is proposed by implementing various steps of input signal preprocessing, through the selection of parameters for analog filtering, and values for the data window and sampling frequency. In addition, an advanced technique for classification of the test patterns is discussed and the main advantages comparing to previously used nearest neighbor classifier are shown.	Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA	Vasilic, S (reprint author), Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA.						BALL GH, 1967, BEHAV SCI, V12, P345; *CAN EMTP US GROUP, 1992, ALT TRANS PROGR ATP; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kezunovic M, 1997, ENG INTELL SYST ELEC, V5, P185; KEZUNOVIC M, 2001, CIGRE SC 34 C SIB RO; KEZUNOVIC M, 1995, ELECTR POW SYST RES, V34, P109, DOI 10.1016/0378-7796(95)00962-X; Kezunovic M, 1996, IEEE COMPUT APPL POW, V9, P42, DOI 10.1109/67.539846; KEZUNOVIC M, 2001, IEEE PORT POW TECH C; KOHONEN T, 1997, SELF ORG MAPS, P426; *MATHW INC, 1999, US MATLAB; PAO YH, 1992, IEEE T POWER SYST, V7, P878, DOI 10.1109/59.141799; PAO YH, 1989, ADAPTIVE PATTERN REC, P309; Udren EA, 1997, IEEE T POWER DELIVER, V12, P134, DOI 10.1109/61.568233	14	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7322-7				2002							918	923				6	Energy & Fuels; Engineering, Multidisciplinary	Energy & Fuels; Engineering	BV37Q	WOS:000178748500179		
B	Inakoshi, H; Ando, T; Sato, A; Okamoto, S			IEEE; IEEE	Inakoshi, H; Ando, T; Sato, A; Okamoto, S			Discovery of emerging patterns from nearest neighbors	2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	NOV 04-05, 2002	BEIJING, PEOPLES R CHINA	IEEE, SMC, Hebei Univ, Machine Learning Ctr				In this paper, we propose a scalable classifier that uses jumping emerging patterns (JEPs), which are combinations of values that occur in one class. The original classifier, DeEPs, is an instance-based classifier that operates on all instances in real-time. It discovers maximal patterns that occur throughout the entire database and identifies JEPs by using these patterns. The necessary computational effort, though, is likely to increase when DeEPs is applied to a large database. Our proposed classifier operates on the nearest neighbors of a test instance. This reduction of instances improves scalability as the database volume increases. Moreover, our classifier imposes a restriction regarding JEPs discovery, so that it excludes patterns that cannot be identified as either correct JEPs or JEPs caused by the maximal patterns missing from nearest neighbors. These probably incorrect JEPs are specialized with additional items and participate in class determination. Our classifier performs significantly faster with these two enhancements, while it remains as accurate as the original classifier.	Fujitsu Labs Ltd, Mihama Ku, Chiba 2618588, Japan	Inakoshi, H (reprint author), Fujitsu Labs Ltd, Mihama Ku, 9-3 Nakase 1 Chome, Chiba 2618588, Japan.						Agrawal R, 1994, P 20 INT C VER LARG; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dong G. Z., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Langley P., 1992, P 10 NAT C ART INT, P223; LI J, 2000, DEEPS NEW INSTANCE B; Li J., 2000, P 17 INT C MACH LEAR, P551; OKAMOTO S, 1997, P 2 INT C CAS BAS RE, P349; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN	10	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7508-4				2002							1920	1925				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BW27J	WOS:000181396300419		
B	van den Bosch, A; Buchholz, S			ACL	van den Bosch, A; Buchholz, S			Shallow parsing on the basis of words only: A case study	40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE			English	Proceedings Paper	40th Annual Meeting of the Association-for-Computational-Linguistics	JUL 07-12, 2002	Philadelphia, PA	Assoc Computat Linguist, Assoc Computat Linguist, N Amer Chapter, Linguist Data Consortium, Microsoft Res, Sun, 240 Teragram, AT&T, BASIS Technol, BBN Technologies, LexisNexis, Cornell	Univ Penn			We describe a case study in which a memory-based learning algorithm is trained to simultaneously chunk sentences and assign grammatical function tags to these chunks. We compare the algorithm's performance on this parsing task with varying training set sizes (yielding learning curves) and different input representations. In particular we compare input consisting of words only, a variant that includes word form information for low-frequency words, gold-standard POS only, and combinations of these. The word-based shallow parser displays an apparently log-linear increase in performance, and surpasses the flatter POS-based curve at about 50,000 sentences of training data. The low-frequency variant performs even better, and the combinations is best. Comparative experiments with a real POS tagger produce lower results. We argue that we might not need an explicit intermediate POS-tagging step for parsing when a sufficient amount of training material is available and word form information is used for low-frequency words.	Tilburg Univ, ILK Computat Linguist & AI, NL-5000 LE Tilburg, Netherlands			van den Bosch, Antal/G-5072-2011	van den Bosch, Antal/0000-0003-2493-656X			Abney S., 1991, PRINCIPLE BASED PARS, P257; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AITMOKHTAR S, 1997, P ACL 97 WORKSH INF; ARGAMON S, 1998, P COLING ACL MONTR C, P67; BANKO M, 2001, P 39 ANN M 10 C EUR; Brill Eric, 1993, THESIS U PENNSYLVANI; BUCHHOLZ S, 1999, P JOINT SIGDAT C EMP, P239; Charniak Eugene, 2000, P 1 C N AM CHAPT ASS, P132; CHRUCH KW, 1988, P 2 APPL NLP ACL; Collins M., 1996, P 34 ANN M ASS COMP; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 1999, P CONLL BERG NORW; Daelemans W., 1996, P 4 WORKSH VER LARG, P14; DAELEMANS W, 1997, 9 EUR C MACH LEARN P, P29; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Daelemans W., 2001, TIMBL TILBURG MEMORY; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; EISNER J, 1997, P 16 INT C COMP LING; FERRO L, 1999, P 3 COMP NAT LANG LE, P43; LI X, 2001, P 5 COMP NAT LANG LE; Marcus M. P., 1994, COMPUTATIONAL LINGUI, V19, P313; MUNOZ M, 1999, P 1999 JOINT SIGDAT, P168; Pollard C., 1987, CSLI LECT NOTES, V1; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ramshaw L.A., 1995, P 3 WORKSH VER LARG, P82; Ratnaparkhi A., 1996, P C EMP METH NAT LAN; Ratnaparkhi A, 1997, P 2 C EMP METH NAT L, P1; Sang E.F.T.K., 2000, P CONLL 2000 LLL 200, P127; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA; Veenstra J., 2000, P CONLL 2000 LLL 200, P157; WEISS SM, 1991, COMPUTER SYSTEMS THA; ZAVREL J, 1997, P 7 BELG DUTCH C MAC, pR20	34	0	0	0	1	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA			1-55860-883-4				2002							433	440				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAP07	WOS:000223096700055		
B	Yoshioka, H; Shirato, Y; Toyoda, I; Umehira, M			IEEE; IEEE; IEEE	Yoshioka, H; Shirato, Y; Toyoda, I; Umehira, M			A fast modulation recognition technique using nearest neighbor rules with optimized threshold for modulation classification in Rayleigh fading channels	5TH INTERNATIONAL SYMPOSIUM ON WIRELESS PERSONAL MULTIMEDIA COMMUNICATIONS, VOLS 1-3, PROCEEDINGS			English	Proceedings Paper	5th International Symposium on Wireless Personal Multimedia Communications	OCT 27-30, 2002	HONOLULU, HI	Yokosuka Res Pk, CRL, IEEE, Lucent Technologies		automatic modulation recognition; threshold for symbol selection; Rayleigh fading channels; Nearest Neighbor (NN) rules		This paper describes a fast modulation recognition technique for use in Rayleigh fading channels. To achieve fast and accurate modulation recognition, we propose the optimum threshold for symbol selection in fading channels. The result is a 20% reduction in recognition time with high recognition accuracy.								COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Higashida Y., 1988, Transactions of the Institute of Electronics, Information and Communication Engineers B, VJ71B; ISHII H, 1998, RCS9871 IEICE; ROLAND C, 2001, IST MOBILE COMMUNICA; TAIRA S, 2000, P VTC2000 SPR, V3, P1717; Umebayashi K., 2000, P PIMRC 2000, V1, P43; YOSHIOKA H, 2001, P ISSSE 01 TOK JAP, P212	7	0	0	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7442-8				2002							1049	1052				4	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BV58Q	WOS:000179449100210		
S	Meir, R; Ratsch, G		Mendelson, S; Smola, AJ		Meir, R; Ratsch, G			An introduction to boosting and leveraging	ADVANCED LECTURES ON MACHINE LEARNING	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	Summer School on Advanced Lectures on Machine Learning	FEB 11-22, 2002	CANBERRA, AUSTRALIA	Res Sch Informat Sci & Engn, Natl Inst Engn & Informat Sci	AUSTRALIAN NATL UNIV		INFORMATION CRITERION; LOGISTIC-REGRESSION; MODEL SELECTION; VECTOR MACHINES; DECISION TREES; ALGORITHMS; NETWORKS; GRADIENT; DESCENT; BOUNDS	We provide an introduction to theoretical and practical aspects of Boosting and Ensemble learning, providing a useful reference for researchers in the field of Boosting as well as for those seeking to enter this fascinating area of research. We begin with a short background concerning the necessary learning theoretical foundations of weak learners and their linear combinations. We then point out the useful connection between Boosting and the Theory of Optimization, which facilitates the understanding of Boosting and later on enables us to move on to new Boosting algorithms, applicable to a broad spectrum of problems. In order to increase the relevance of the paper to practitioners, we have added remarks, pseudo code, "tricks of the trade", and algorithmic considerations where appropriate. Finally, we illustrate the usefulness of Boosting algorithms by giving an overview of some existing applications. The main ideas are illustrated on the problem of binary classification, although several extensions are discussed.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; Australian Natl Univ, Res Sch Informat Sci & Engn, Canberra, ACT 0200, Australia	Meir, R (reprint author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	rmeir@ee.technion.ac.il; Gunnar.Raetsch@anu.edu.au					ABNEY S, 1999, P JOINT SIGDAT C EMP; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Anthony M, 1999, NEURAL NETWORK LEARN; Antos A., 2002, J MACHINE LEARNING R, V3, P73; ASLAM JA, 2000, P COLT SAN FRANC; AUDRINO F, 2002, IN PRESS J COMPUTATI; BARNES JP, 1999, THESIS AUSTR NATL U; BARTLETT P, 2002, LECT NOTES COMPUT SC, V2375, P44; BARTLETT PL, 2002, IN PRESS J MACHI OCT; Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bauschke H. H., 1997, J CONVEX ANAL, V4, P27; BENDAVID S, 2001, P 14 ANN C COMP LEAR, P507; Schwenk H, 2000, NEURAL COMPUT, V12, P1869, DOI 10.1162/089976600300015178; Bennet K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; BENNETT KP, 1993, OPTIMIZATION METHODS, V3, P27; BENNETT KP, 2002, P ICML; BERTONI A, 1997, LNCS, V5, P343; Bertsekas DP, 1995, NONLINEAR PROGRAMMIN; Bishop C.M., 1995, NEURAL NETWORKS PATT; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; Bradley P. S., 1998, P 15 INT C MACH LEAR, P82; Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI 10.1016/0041-5553(67)90040-7; BREIMAN L, 504 U CAL BERK STAT; Breiman L., 2000, SOME INFINITY THEORY; Breiman L., 1997, 460 U CAL STAT DEP; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BSHOUTY N, 2002, IN PRESS JMLR, P107; BUHLMANN P, 2001, 605 UC BERK STAT DEP; BUHLMANN P, 2002, J AM STAT ASS; Campbell C, 2001, ADV NEUR IN, V13, P395; CARMICHAEL J, 1990, EPRI J ELECT POWER R; Censor Y, 1997, NUMERICAL MATH SCI C; CESABIANCHI N, 1994, IEEE T INFORM THEORY, V40, P1215, DOI 10.1109/18.335953; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chen S., 1995, 479 STANF U DEP STAT; COHEN WW, 1998, ADV NEURAL INFORMATI, V10; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; COMINETTI R, 1994, JOTA, V83; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; Crammer K., 2000, P 13 ANN C COMP LEAR, P35; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; Demiriz A., 2002, J MACHINE LEARNING, V46, P225; DETTLING M, 2002, USE BOOSTING TUMOR C; Devroye L., 1996, APPL MATH, V31; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; DOMINGO C, 2000, P COLT SAN FRANC; DRUCKER H, 1994, NEURAL COMPUTATION, V6; Drucker H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000352; Duffy N., 2000, P 13 ANN C COMP LEAR, P208; Duffy N, 2000, ADV NEUR IN, V12, P258; DUFFY N, 2000, BOOSTING METHODS REG; Duffy N, 1999, LECT NOTES ARTIF INT, V1572, P18; ELYANIV R, 2002, P 13 EUR C MACH LEAR; Escudero G, 2000, LECT NOTES ARTIF INT, V1810, P129; Feller W, 1968, INTRO PROBABILITY TH; FISHER DH, 1997, IMPROVING REGRESSORS; Frean Marcus, 1998, SIMPLE COST FUNCTION; FREUND Y, 1994, LNCS; Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238163; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Freund Y, 1999, GAME ECON BEHAV, V29, P79, DOI 10.1006/game.1999.0738; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1998, P ICML; FRIEDMAN J, TECHNICAL REPORT DEP; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN J, 2000, ANN STAT, V2, P375; Friedman J, 1999, STOCHASTIC GRADIENT; Friedman J. H., 1999, GREEDY FUNCTION APPR; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FRISCH KR, 1955, COMMUNICATION   0513; GRAEPEL T, 1999, P ICANN 99, V1, P304; GRANDVALET Y, 2001, P ICANN VIENN AUSTR; GRANDVALET Y, 2001, LECT NOTES COMPUTER; Grove A., 1998, P 15 NAT C ART INT; Guruswami V., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307429; HART W, 1992, P IEEE, V80; Haruno M, 1999, MACH LEARN, V34, P131, DOI 10.1023/A:1007597902467; Hastie T., 2001, SPRINGER SERIES STAT; Hastie T. J., 1990, MONOGRAPHS STAT APPL, V43; HAUSSLER D, 1992, INFORM COMPUT, V100, P78, DOI 10.1016/0890-5401(92)90010-D; Haykin S., 1998, NEURAL NETWORKS COMP, V2nd; Helmbold DP, 1999, IEEE T NEURAL NETWOR, V10, P1291, DOI 10.1109/72.809075; HERBRICH R, 2000, P ANN C COMP LEARN T, P304; HERBRICH R, 2002, ADAPTIVE COMPUTATION, V7; Herbrich R., 2002, JMLR, V3, P175; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; Huang F. J., 2000, P 4 IEEE INT C AUT F, P245; Iyer R. D., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354794; James W., 1961, 4TH P BERK S MATH ST, V1, P361; JIANG W, 2001, P 18 INT C MACH LEAR; Johnson D. S., 1978, Theoretical Computer Science, V6, DOI 10.1016/0304-3975(78)90006-3; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KEARNS M, 1994, J ACM, V41, P67, DOI 10.1145/174644.174647; Kearns M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237994; Kearns M. J., 1994, INTRO COMPUTATIONAL; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307424; Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612; Kivinen J, 1997, ARTIF INTELL, V97, P325, DOI 10.1016/S0004-3702(97)00039-8; Kiwiel KC, 1998, APPL MATH OPT, V38, P239, DOI 10.1007/s002459900090; KOLTCHINSKII V, 2002, ANN STAT, V30; KRIEGER A, 2001, P 18 ICML; Lafferty J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307422; LEBANON G, NCTR2001098 NEUROCOL; LEBANON G, 2002, IN PRESS ADV NEURAL, V14; LeCun Y.A., 1995, P INT C ART NEUR NET, V2, P53; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; LITTLESTONE N, 1995, COMPUT COMPLEX, V5, P1, DOI 10.1007/BF01277953; Luenberger D. G., 1984, LINEAR NONLINEAR PRO, VAuflage, P2; LUGOSI G, 2002, LECT NOTES ARTIF INT, V2375, P303; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; Mangasarian OL, 1999, OPER RES LETT, V24, P15, DOI 10.1016/S0167-6377(98)00049-2; MANNOR S, 2001, P 14 ANN C COMP LEAR, P461; MANNOR S, 2002, LECT NOTES COMPUT SC, V2375, P319; Mannor S, 2002, MACH LEARN, V48, P219, DOI 10.1023/A:1013959922467; MASON L, 1999, THESIS AUSTR NATL U; MASON L, 1998, IMPROVED GEN EXPLICI; Mason L, 1999, ADV LARGE MARGIN CLA; Mason L, 2000, ADV NEUR IN, P221; Matousek J., 1999, GEOMETRIC DISCREPANC; Meir R., 2000, P 13 ANN C COMP LEAR, P190; MEIR R, 2002, UNPUB DATA DEPENDENT; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; MERLER S, 2001, LNCS, V2096, P32; MOODY JE, 1992, ADV NEUR IN, V4, P847; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; MURATA N, 1994, IEEE T NEURAL NETWOR, V5, P865, DOI 10.1109/72.329683; NOCK R, 2002, LNAI, V2430; ONODA T, 2000, P NC 2000 BERL; Onoda T., 1998, P INT C ART NEUR NET, P195; OSULLIVAN J, 2000, P 17 ICML; OZA N, 2001, P KDD 01; Pietra Stephen Della, 2001, CMUCS01109 SCH COMP; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Quinlan J.R, 1992, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1996, LECT NOTES COMPUTER, V1160, P143; RATSCH G, 2002, GI EDITION LECT NOTE, V2, P125; RATSCH G, 2002, IN PRESS ADV NEURAL, V14; RATSCH G, 2002, LECT NOTES ARTIF INT, V2375, P319; RATSCH G, 1998, THESIS U POTSDAM; RATSCH G, NCTR1998021 NEUROCOL; Ratsch G., 2002, MACH LEARN, V48, P193; RATSCH G, 2000, 119 GMD; RATSCH G, NCTR2001098 NEUROCOL; RATSCH G, NCTR2000085 NEUROCOL; RATSCH G, 2001, 98 ROYAL HOLL COLL; RATSCH G, 2003, IN PRESS NIPS, V15; Ratsch G., 2000, P 13 ANN C COMP LEAR; RATSCH G, 2002, IN PRESS IEEE PAMI, V24; Ratsch G, 2000, ADV NEUR IN, P207; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Ratsch G., 2001, THESIS U POTSDAM POT; RATSCH G, 2002, NIPS, V14; Ridgeway G., 1999, P ART INT STAT, P152; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Robert C. P., 1994, BAYESIAN CHOICE DECI; ROCHERY M, 2002, INT C ACC SPEECH SIG; Rockafellar R.T., 1970, PRINCETON LANDMARKS; SCHAPIRE R, 1998, P 21 ANN INT C RES D; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire R. E., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279960; Schapire RE, 1999, P 16 INT JOINT C ART; Schapire R.E., 2002, WORKSH NONL EST CLAS; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SCHAPIRE RE, 2002, P P 19 INT CLASS MAC; Schapire Robert E., 1997, MACH LEARN P 14 INT, P313; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Scholkopf B., 2002, LEARNING KERNELS; SCHOLKOPF B, 1999, 87 TR MICR RES; SERVEDIO R, 2001, P 14 ANN C COMP LEAR, P473; SERVEDIO RA, 2000, P COLT SAN FRANC, P148; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; SHAWETAYLOR J, 2000, ADV LARGE MARGIN CLA, P247; Shawe-Taylor J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307470; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; SHAWETAYLOR J, 2001, NCTR2000082 NEUROCOL; Singer Y, 2000, ADV NEUR IN, V12, P610; Sofer A, 1996, LINEAR NONLINEAR PRO; Tax DM J, 1999, P EUR S ART NEUR NET, P251; Thollard F, 2002, LECT NOTES ARTIF INT, V2430, P431; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Tsuda K, 2002, IEEE T NEURAL NETWOR, V13, P70, DOI 10.1109/72.977272; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Van der Vaart A., 1996, WEAK CONVERGENCE EMP; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; von Neumann J, 1928, MATH ANN, V100, P295; WALKER MA, 2001, P 2 ANN M N AM CHAPT; Zemel RS, 2001, ADV NEUR IN, V13, P696; ZHANG T, 2001, RC22155 IBM RES; Zhang T, 2002, MACH LEARN, V46, P91, DOI 10.1023/A:1012498226479; ZHANG T, 2002, ADV NEURAL INFORMATI, V14; ZHANG T, 2002, SEQUENTIAL GREEDY AP; Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X	211	114	113	0	14	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-00529-3	LECT NOTES ARTIF INT			2002	2600						118	183				66	Computer Science, Artificial Intelligence; Statistics & Probability	Computer Science; Mathematics	BW57Z	WOS:000182487800004		
S	Bernado, E; Llora, X; Garrell, JM		Lanzi, P; Stolzmann, W; Wilson, SW		Bernado, E; Llora, X; Garrell, JM			XCS and GALE: A comparative study of two learning classifier systems on data mining	ADVANCES IN LEARNING CLASSIFIER SYSTEMS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Workshop on Learning Classifier Systems	JUL 07-08, 2001	SAN FRANCISCO, CALIFORNIA				ALGORITHMS	This paper compares the learning performance, in terms of prediction accuracy, of two genetic-based learning systems, XCS and GALE, with six well-known learning algorithms, coming from instance based learning, decision tree induction, rule-learning, statistical modeling and support vector machines. The experiments, performed on several datasets, show the suitability of the genetic-based learning classifier systems for classification tasks. Both XCS and GALE significantly achieved better results than IB1 and Naive Bayes. Besides, any method could not outperform XCS and GALE significantly.	Engn & Arquitectura La Salle, Barcelona 08022, Spain	Bernado, E (reprint author), Engn & Arquitectura La Salle, Psg Bonanova 8, Barcelona 08022, Spain.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Altenberg L., 1994, FDN GENETIC ALGORITH, P23; Blake C, 1998, UCI REPOSITORY MACHI; BONELLI P, 1991, 4 INT C GEN ALG ICGA, P288; BUTZ MV, 2000, 2000017 ILLIGAL U IL; CANTUPAZ E, 2000, GENETIC EVOLUTIONARY, P1053; Conover WJ., 1971, PRACTICAL NONPARAMET, P206; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DIEFERSON LA, 2000, WORKSH DAT MIN EV CO, P89; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; FLOCKHART IW, 1995, 10 EPCC AIKMS GA MIN; Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Goldberg D. E., 1989, GENETIC ALGORITHMS S; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Han Jiawei, 2001, DATA MINING CONCEPTS; HARTLEY A, 1999, P GEN EV COMP C 1999, P266; Holland J. H., 1978, PATTERN DIRECTED INF, P313; Holland JH, 1986, MACHINE LEARNING ART, P593; HOLLAND JH, 1975, ADAPTATION NATURAL A; Holmes J., 1997, P 7 INT C GEN ALG IC, P426; HOLMES JH, 2000, 3 INT WORKSH LEARN C; Janikow C. Z., 1993, MACH LEARN, V13, P198; John G. H., 1995, 11 C UNC ART INT, P338; Kovacs T., 1999, P GEN EV COMP C GECC, P329; Kovacs T., 1997, SOFT COMPUTING ENG D, P59; Koza J., 1992, GENETIC PROGRAMMING; LANZI PL, 1999, P GEN EV COMP C GECC, P353; LLORA X, 2000, P GEN EV COMP C GECC, P868; LLORA X, 2001, IN PRESS P 18 INT C; LLORA X, 2001, IN PRESS P GEN EV CO; LLORA X, 2000, P LEARN 00 WORKSH; Marti J, 1998, P SOC PHOTO-OPT INS, V3338, P1215, DOI 10.1117/12.310849; MARTIN JK, 1996, 9621 U CAL DEP INF C; MARTINEZ E, 1996, 8 MED EL C IND APPL, P1067; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Platt J., 1998, ADV KERNEL METHODS S; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Saxon S, 2000, LEARNING CLASSIFIER, P223; Smith S. F., 1983, P 8 INT JOINT C ART, P422; WILSON SW, 1999, 9911 PRED DYN; WILSON SW, 2000, 3 INT WORKSH LEARN C; WILSON SW, 1999, FESTSCHRIFT HONOR JH; WILSON SW, 1998, GEN PROGR P 3 ANN C; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; Witten I.H., 2000, DATA MINING PRACTICA	49	46	46	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-43793-2	LECT NOTES ARTIF INT			2002	2321						115	132				18	Computer Science, Artificial Intelligence	Computer Science	BW13N	WOS:000180978300008		
S	Domeniconi, C; Gunopulos, D		Dietterich, TG; Becker, S; Ghahramani, Z		Domeniconi, C; Gunopulos, D			Adaptive nearest neighbor classification using support vector machines	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 14, VOLS 1 AND 2	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	15th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 03-08, 2001	VANCOUVER, CANADA				REGRESSION	The nearest neighbor technique is a simple and appealing method to address classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. We propose a technique that computes a locally flexible metric by means of Support Vector Machines (SVMs). The maximum margin boundary found by the SVM is used to determine the most discriminant direction over the query's neighborhood. Such direction provides a local weighting scheme for input features. We present experimental evidence of classification performance improvement over the SVM algorithm alone and over a variety of adaptive learning schemes, by using both simulated and real data sets.	Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA	Domeniconi, C (reprint author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.						Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; BELLMAN BE, 1961, ADAPTIVE CONTROL PRO; Brown M., 1999, KNOWLEDGE BASED ANAL; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2000, ADV NEURAL INFORMATI; DOMENICONI C, 2001, UCRCSE0104 DEP COMP; Duda R. O., 1973, PATTERN CLASSIFICATI; Friedman JH, 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Joachims T., 1998, P EUR C MACH LEARN; Joachims T., 1999, ADV KERNEL METHODS S; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Osuna E., 1997, P COMP VIS PATT REC; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	16	3	3	0	1	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-04208-8	ADV NEUR IN			2002	14						665	672				8	Computer Science, Artificial Intelligence	Computer Science	BV95T	WOS:000180520100083		
S	Vincent, P; Bengio, Y		Dietterich, TG; Becker, S; Ghahramani, Z		Vincent, P; Bengio, Y			K-Local hyperplane and convex distance nearest neighbor algorithms	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 14, VOLS 1 AND 2	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	15th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 03-08, 2001	VANCOUVER, CANADA					Guided by an initial idea of building a complex (non linear) decision surface with maximal local margin in input space, we give a possible geometrical intuition as to why K-Nearest Neighbor (KNN) algorithms often perform more poorly than SVMs on classification tasks. We then propose modified K-Nearest Neighbor algorithms to overcome the perceived problem. The approach is similar in spirit to Tangent Distance, but with invariances inferred from the local neighborhood rather than prior knowledge. Experimental results on real world classification tasks suggest that the modified KNN algorithms often give a dramatic improvement over standard KNN and perform as well or better than SVMs.	Univ Montreal, Dept IRO, Montreal, PQ H3C 3J7, Canada	Vincent, P (reprint author), Univ Montreal, Dept IRO, CP 6128, Montreal, PQ H3C 3J7, Canada.						ATKESON CG, 1996, ARTIFICIAL INTELLIGE; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Chapelle O, 2001, ADV NEUR IN, V13, P416; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Friedman J., 1994, 113 STANF U STAT DEP; Hastie T, 1996, ADV NEUR IN, V8, P409; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; ORMONEIT D, 2000, ADV NEURAL INFORMATI, V12; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SIMARD P, 1998, LECT NOTES COMPUTER, V1524; Tong S., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Vapnik V. N., 1995, NATURE STAT LEARNING; ZHANG B, 2001, HPL200189	16	53	54	0	0	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258		0-262-04208-8	ADV NEUR IN			2002	14						985	992				8	Computer Science, Artificial Intelligence	Computer Science	BV95T	WOS:000180520100123		
J	Chung, TP; Laramie, JM; Province, M; Cobb, JP				Chung, TP; Laramie, JM; Province, M; Cobb, JP			Functional genomics of critical illness and injury	CRITICAL CARE MEDICINE			English	Review						genomics; profiling; sepsis; networks; bioinformatics; microarray	MICROARRAY GENE-EXPRESSION; DNA ARRAYS; SEPSIS; DISCOVERY; PATTERNS		Washington Univ, Sch Med, Dept Surg,Cellular Injury & Adaptat Lab, Burn Trauma & Surg Crit Care Sect, St Louis, MO 63110 USA; Washington Univ, Sch Med, Div Biostat, St Louis, MO 63110 USA	Cobb, JP (reprint author), Washington Univ, Sch Med, Dept Surg,Cellular Injury & Adaptat Lab, Burn Trauma & Surg Crit Care Sect, Campus Box 8109,660 S Euclid Ave, St Louis, MO 63110 USA.						Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; BAKER CC, 1983, SURGERY, V94, P331; Bezdek J. C., 1981, PATTERN RECOGNITION; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BROWN PO, 1999, OBSERVING LIVING GEN; Buchman TG, 2001, SHOCK, V16, P248, DOI 10.1097/00024382-200116040-00002; Cheung VG, 1999, NAT GENET, V21, P15, DOI 10.1038/4439; CHUNG TP, 2001, ABSTR SHOCK S1, V15, P26; COBB JP, 2002, IN PRESS CRIT CARE M; COBB JP, 2001, BROAD SCALE SPLENIC; Cobb JP, 2001, SHOCK, V16, P264; Cobb JP, 2001, SHOCK, V15, P165; COBB JP, 2000, SHOCK S2, V13, P32; Collins FS, 2001, JAMA-J AM MED ASSOC, V285, P540, DOI 10.1001/jama.285.5.540; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deitch EA, 1998, SHOCK, V9, P1, DOI 10.1097/00024382-199801000-00001; Dhanasekaran SM, 2001, NATURE, V412, P822, DOI 10.1038/35090585; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; EVERITT B, 1974, CLUSTER ANAL, V122; Fields S, 1999, P NATL ACAD SCI USA, V96, P8825, DOI 10.1073/pnas.96.16.8825; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gaasterland T, 2000, NAT GENET, V24, P204, DOI 10.1038/73392; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hieter P, 1997, SCIENCE, V278, P601, DOI 10.1126/science.278.5338.601; Hotchkiss RS, 1997, CRIT CARE MED, V25, P1298, DOI 10.1097/00003246-199708000-00015; Ideker T, 2001, SCIENCE, V292, P929, DOI 10.1126/science.292.5518.929; Jeong H, 2001, NATURE, V411, P41, DOI 10.1038/35075138; Jeong H, 2000, NATURE, V407, P651; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kohonen T., 1995, SELF ORGANIZING MAPS; KOUSTOVA E, 2001, SHOCK S1, V15, P26; LANDER ES, 2001, NATURE GENETICS S, V21, P3; Lee MLT, 2000, P NATL ACAD SCI USA, V97, P9834, DOI 10.1073/pnas.97.18.9834; Lockhart DJ, 2000, NATURE, V405, P827, DOI 10.1038/35015701; Mir KU, 2000, TRENDS GENET, V16, P63, DOI 10.1016/S0168-9525(99)01947-2; Risch NJ, 2000, NATURE, V405, P847, DOI 10.1038/35015718; Rizzo WB, 1999, AM J HUM GENET, V65, P1547, DOI 10.1086/302681; Sander C, 2000, SCIENCE, V287, P1977, DOI 10.1126/science.287.5460.1977; Schadt EE, 2000, J CELL BIOCHEM, V80, P192; Sherlock G, 2000, CURR OPIN IMMUNOL, V12, P201, DOI 10.1016/S0952-7915(99)00074-6; Spengler SJ, 2000, SCIENCE, V287, P1221, DOI 10.1126/science.287.5456.1221; Staudt LM, 2000, ANNU REV IMMUNOL, V18, P829, DOI 10.1146/annurev.immunol.18.1.829; Sun L, 1999, J CLIN ONCOL, V17, P3753; WEINSTEIN JN, 1998, SCIENCE, V282, P627; Young RA, 2000, CELL, V102, P9, DOI 10.1016/S0092-8674(00)00005-2; Zien A, 2001, BIOINFORMATICS, V17, P323; 2001, NATURE MED, V7, P751	48	24	26	1	2	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	0090-3493			CRIT CARE MED	Crit. Care Med.	JAN	2002	30	1		1			S51	S57		10.1097/00003246-200201001-00007		7	Critical Care Medicine	General & Internal Medicine	516VG	WOS:000173577000007	11782561	
S	Toussaint, G		Akiyama, J; Kano, M		Toussaint, G			Open problems in geometric methods for instance-based learning	DISCRETE AND COMPUTATIONAL GEOMETRY	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th Japanese Conference on Discrete and Computational Geometry (JCDCG 2002)	DEC 06-09, 2002	TOKYO, JAPAN	Tokai Univ			RELATIVE NEIGHBORHOOD GRAPH; PATTERN CLASSIFICATION; ALGORITHMS; RULE	In the typical approach to instance-based learning, random data (the training set of patterns) are collected and used to design a decision rule (classifier). One of the most well known such rules is the k-nearest-neighbor decision rule in which an unknown pattern is classified into the majority class among its k nearest neighbors in the training set. In the past fifty years many approaches have been proposed to improve the performance of this rule. More recently geometric methods have been found to be the best. Here we mention a variety of open problems of a computational geometric nature that arize in these methods. To provide some context and motivation for these open problems we briefly describe the methods and list some key references.	McGill Univ, Sch Comp Sci, Montreal, PQ, Canada	Toussaint, G (reprint author), McGill Univ, Sch Comp Sci, Montreal, PQ, Canada.	godfried@cs.mcgill.ca					Aha D. W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ANDRADE DV, 2001, P 13 CAN C COMP GEOM; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BRIGHTON H, 1999, PRINCIPLES DATA MINI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L., 1996, PROBABILISTIC THEORY; Duda R O, 2001, PATTERN CLASSIFICATI; Ekin O, 1999, INFOR, V37, P337; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GODFRIED T, 1980, P 5 S OP RES U KOLN, P425; GOODMAN LA, 1954, J AM STAT ASSOC, P723; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; ICHINO M, 1985, PATTERN RECOGN, V18, P161, DOI 10.1016/0031-3203(85)90040-8; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Liotta G, 1998, COMP GEOM-THEOR APPL, V10, P1, DOI 10.1016/S0925-7721(97)00018-7; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; OROURKE J, 1997, HDB DISCRETE COMPUTA, P797; PATERSON MS, 1992, LECT NOTES COMPUT SC, V623, P416; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; SEBBAN M, 2001, P 18 INT C MACH LEAR; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; SU TH, 1991, COMPUTING, V46, P121, DOI 10.1007/BF02239166; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; TOUSSAINT GT, 2002, INTERFACE 2002; TOUSSAINT GT, 1980, ELECTRON LETT, V16, P860, DOI 10.1049/el:19800611; TOUSSAINT GT, 1974, P 2 INT JOINT C PATT, P27; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; Toussaint G. T., 1979, Proceedings of COMPSAC the IEEE Computer Society's Third International Computer Software and Applications Conference; Toussaint G. T., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface; Vapnik V., 1998, STAT LEARNING THEORY; WILFONG G, 1991, P 7 ANN ACM S COMP G, P224, DOI 10.1145/109648.109673; Wilson D.R., 1997, MACH LEARN, P404; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	43	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20776-7	LECT NOTES COMPUT SC			2002	2866						273	283				11	Computer Science, Theory & Methods; Mathematics	Computer Science; Mathematics	BY30M	WOS:000188862800029		
B	Zhang, B; Srihari, SN			IEEE; IEEE	Zhang, B; Srihari, SN			A fast algorithm for finding k-nearest neighbors with non-metric dissimilarity	EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS			English	Proceedings Paper	8th International Workshop on Frontiers in Handwriting Recognition	AUG 06-08, 2002	ONTARIO, CANADA	Univ Buffalo, CEDAR, Microsoft, Siemens, Hitachi, Motorola, US Postal Serv, A2iA, Int Assoc Pattern Recognit				Fast nearest neighbor (NN)finding has been extensively studied. While some fast NN algorithms using metrics rely on the essential properties of metric spaces, the others using non-metric measures fail for large-size templates. However in some applications with very large size templates, the best performance is achieved by NN methods based on the dissimilarity measures resulting in a special space where computations cannot be pruned by the algorithms based-on the triangular inequality. For such NN methods, the existing fast algorithms except condensing algorithms are not applicable. In this paper, a fast hierarchical search algorithm is proposed to find k-NNs using a non-metric measure in a binary feature space, Experiments with handwritten digit recognition show that the new algorithm reduces on average dissimilarity computations by more than 90% while losing the accuracy by less than 0.1%, with a 10% increase in memory.	SUNY Buffalo, CEDAR, Dept Comp Sci & Engn, Buffalo, NY 14228 USA	Zhang, B (reprint author), SUNY Buffalo, CEDAR, Dept Comp Sci & Engn, Buffalo, NY 14228 USA.						BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; Cha SH, 2002, PATTERN RECOGN, V35, P515, DOI 10.1016/S0031-3203(01)00032-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUNKUNAGA K, 1975, IEEE T COMPUT, V24, P750; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; TUBBS JD, 1989, PATTERN RECOGN, V22, P359, DOI 10.1016/0031-3203(89)90045-9	8	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1692-0				2002							13	18				4	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BV03S	WOS:000177665000002		
S	Pimentel, CF; da Fonseca, MJ; Jorge, JA		Blostein, D; Kwon, YB		Pimentel, CF; da Fonseca, MJ; Jorge, JA			Experimental evaluation of a trainable scribble recognizer for calligraphic interfaces	GRAPHICS RECOGNITION: ALGORITHMS AND APPLICATIONS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	4th International Workshop on Graphics Recognition	SEP 07-08, 2001	KINGSTON, CANADA	Int Assoc Pattern Recognit, TC 10, Queens Univ, Comp Sci & Engn Res Informat Ctr, Xero Fdn, Commun & Informat Technol Ontario				This paper describes a trainable recognizer for hand-drawn sketches using geometric features. We compare three different learning algorithms and select the best approach in terms of cost-performance ratio. The algorithms employ classic machine-learning techniques using a clustering approach. Experimental results show competing performance (95.1%) with the non-trainable recognizer (95.8%) previously developed, with obvious gains in flexibility and expandability. In addition, we study both their classification and learning performance with increasing number of examples per class.	Univ Tecn Lisboa, IST, Dept Engn Informat, P-1049001 Lisbon, Portugal	Pimentel, CF (reprint author), Univ Tecn Lisboa, IST, Dept Engn Informat, Av Rovisco Pais, P-1049001 Lisbon, Portugal.	pimentelcesar@hotmail.com; mjf@inesc.pt; jaj@inesc.pt	Fonseca, Manuel J./D-5120-2011; Jorge, Joaquim/C-5596-2008	Fonseca, Manuel J./0000-0002-3559-828X; Jorge, Joaquim/0000-0001-5441-4637			APTE A, 1993, P UIST 93 ATL GA; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOYCE JE, 1985, SIAM J COMPUT, V14, P134, DOI 10.1137/0214011; Cestnik B., 1990, P EUR C ART INT, P147; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Domingos Pedro, 1996, P 13 INT C MACH LEAR, P105; Duda R. O., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FAYYAD UM, 1991, THESIS U MICHIGAN; Fonseca MJ, 2001, PATTERN RECOGN LETT, V22, P1311, DOI 10.1016/S0167-8655(01)00076-9; FREEMAN H, 1975, COMMUN ACM, V18, P409, DOI 10.1145/360881.360919; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; LITTLESTONE N, 1991, UCSCCRL9128 COMP ENG; MALERBA D, 1995, LEARNING DATA AI STA; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; O'Rourke J., 1998, COMPUTATIONAL GEOMET; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J R, 1983, MACHINE LEARNING ART; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; QUINLAN JR, 1987, J OPER RES SOC, V38, P347; RUBINE DH, 1991, SIGGRAPH 91 C P ACM; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669	24	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-44066-6	LECT NOTES COMPUT SC			2002	2390						81	91				11	Computer Science, Theory & Methods	Computer Science	BW27B	WOS:000181394100007		
B	Wang, PF; Mosley, C		Wang, L; Rajapakse, JC; Fukushima, K; Lee, SY; Yao, X		Wang, PF; Mosley, C			Associative memory neural networks for information retrieval of text word pairs	ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING: COMPUTATIONAL INTELLIGENCE FOR THE E-AGE			English	Proceedings Paper	9th International Conference on Neural Information Processing	NOV 18-22, 2002	SINGAPORE, SINGAPORE	Asia Pacific Neural Network Assembly, Singapore Neurosci Assoc, SEAL & FSKD Conf Steering Comm, Nanyang Technol Univ, Sch Elect & Electr Engn			ALGORITHM	Natural language information processing remains a challenge in Linguistics. Existing methods for retrieval of text often use stemming to retain common roots and base recall on these root words [1,4,5,9]. This requires the removal of stop words, e.g., numbers, symbols, high frequency bid low semantic weight words, thereby precluding phrases using these words [2]. In addition stemming is a morphologic approach that cannot readily process homonyms, synonyms and certain inflectional and derived forms [4.5]. Machine learning approaches assign words to categories [5,6,7,81, but application to a large corpus remains in debate [4]. For this study, we describe the application of the Cortronic theory and methods developed by Robert Hecht-Nielsen [2.3] to information retrieval of text word pairs. Hecht-Nielsen's theories build on associative memory artificial neural networks (AMNNs) introduced by Steinbuch [10] and extended by Willshaw et al. [ 11] especially in regards sparseness [2,3]. The AADNs are used to process a large corpus without excluding stop words, and retain the joint probability of mutual occurrences that allows rapid retrieval of word pairs. This AMNN approach includes three key components: representation of arbitrary objects (words), learning and knowledge accumulation based on measurement of co-occurrence and use of all the learned knowledge to produce (predict) the missing word in a phrase.	SSC SD, Marine Environm Qual Branch, San Diego, CA 92152 USA	Wang, PF (reprint author), SSC SD, Marine Environm Qual Branch, Code 2362, San Diego, CA 92152 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HECHTNIELSEN R, 2002, NEURALSCIENCE AI END; HECHTNIELSEN R, 2002, NEUROCOMPUTING; Hull DA, 1996, J AM SOC INFORM SCI, V47, P70; Jurafsky D., 2000, SPEECH LANGUAGE PROC; KIM JY, 1994, SOFTWARE PRACT EXPER, V24, P79, DOI 10.1002/spe.4380240105; Krovetz R., 1993, P 16 ANN INT ACM SIG, P191, DOI 10.1145/160688.160718; MOONEY RJ, 1995, MACH LEARN, V19, P79, DOI 10.1007/BF00994661; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; STEINBUCH K, 1961, KYBERNETIK, V1, P36, DOI 10.1007/BF00293853; WILLSHAW DJ, 1969, NATURE, V222, P960, DOI 10.1038/222960a0	11	0	0	0	4	NANYANG TECHNOLOGICAL UNIV	SINGAPORE	NANYANG AVENUE, SINGAPORE 639815, SINGAPORE			981-04-7524-1				2002							2200	2203				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BW69E	WOS:000182832400450		
B	Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM			IEEE; IEEE	Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM			Comparison of wavelet-based methods for the prognosis of failures in electric motors	IEEE POWER ELECTRONICS IN TRANSPORATION			English	Proceedings Paper	7th Workshop on Power Electronics in Transportation	OCT 24-25, 2002	AUBURN HILL, MI	IEEE Power Electr Soc, IEEE SE Michigan Sect, Soc Automot Engineers, IEEE Vehicular Technol Soc		fault prognosis; wavelets; DC motors		The ability to give a prognosis for failure of a system is an invaluable tool and can be applied to electric motors. In this paper, three wavelet based methods have been developed that achieve this goal. Wavelet and filter bank theory, the nearest neighbor rule, and linear discriminant functions are reviewed. A framework for the development of a fault detection and classification algorithm based on the coefficients calculated from the discrete wavelet transform and using clustering is described. An experimental setup based on RT-Linux is described and results from testing are presented, verifying the analysis.	Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48823 USA	Zanardelli, WG (reprint author), Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48823 USA.						Burrus C. S., 1998, INTRO WAVELETS WAVEL; Calvert T., 1974, CLASSIFICATION ESTIM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727; ZANARDELLI WG, 2000, THESIS MICHIGAN STAT; ZANARDELLI WG, 2001, IEEE INT S DIAGN EL, P591	7	2	2	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7492-4				2002							61	67				7	Engineering, Electrical & Electronic; Transportation Science & Technology	Engineering; Transportation	BW20N	WOS:000181178100009		
S	Bao, YG; Du, XY; Ishii, N		Yin, H; Allinson, N; Freeman, R; Keane, J; Hubbard, S		Bao, YG; Du, XY; Ishii, N			Combining feature selection with feature weighting for k-NN classifier	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2002	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Conference on Intelligent Data Engineering and Automated Learning	AUG 12-14, 2002	MANCHESTER, ENGLAND	Univ Manchester Inst Sci & Technol			LEARNING ALGORITHMS	The k-nearest neighbor (k-NN) classification is a simple and effective classification approach. However, it suffers from over-sensitivity problem due to irrelevant and noisy features. In this paper, we propose an algorithm to improve the effectiveness of k-NN by combining these two approaches. Specifically, we select all relevant features firstly, and then assign a weight to each one. Experimental results show that our algorithm achieves the highest accuracy or near to the highest accuracy on all test datasets. It also achieves higher generalization accuracy compared with the well-known algorithms IB1-4 and C4.5.	Nagoya Inst Technol, Dept Intelligence & Comp Sci, Nagoya, Aichi 4668555, Japan; Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China	Bao, YG (reprint author), Nagoya Inst Technol, Dept Intelligence & Comp Sci, Nagoya, Aichi 4668555, Japan.		ruc, comp_xinxi/E-4212-2012				AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Aha D.W., 1998, FEATURE EXTRACTION C; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AHA DW, 1994 WORKSH TR WS 94; AYAN NF, 1999, 8 TURK S ART INT NEU; BAO YG, 6 INT C SOFT COMP II, P452; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Cardie C, 2000, MACH LEARN, V41, P85, DOI 10.1023/A:1007665204628; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KOHAVI R, ECML 97; LEE KC, 1999, LECT NOTES ARTIF INT, V1574, P138; Merz C, 1998, UCI REPOSITORY MACHI; Pawlak Z., 1991, ROUGH SETS THEORETIC; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877	16	1	1	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-44025-9	LECT NOTES COMPUT SC			2002	2412						461	468				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BY01R	WOS:000187252500069		
J	Santinelli, A; Mazzucchelli, R; Colanzi, P; Tinca, A; Montironi, R				Santinelli, A; Mazzucchelli, R; Colanzi, P; Tinca, A; Montironi, R			Image processing, diagnostic information extraction and quantitative assessment in pathology	JOURNAL OF CELLULAR AND MOLECULAR MEDICINE			English	Article						image analysis; pathology; quantitation	PROSTATIC INTRAEPITHELIAL NEOPLASIA; NUCLEAR CHROMATIN TEXTURE; LESIONS; CANCER; ADENOCARCINOMA; PREDICTION; CARCINOMA; NETWORKS; SURVIVAL; SYSTEM	As we enter the information age we hold strong beliefs in the benefits of digital technology applied to pathology: numerical representation offers objectivity. Digital knowledge may indeed lead to significant information discovery, and, processing systems might be designed to allow a true evolution of capabilities. Questions arise whether the methodology underlying quantitative analysis provides the information that we need and whether it is appropriate for some of the problems encountered in diagnostic and prognostic histopathology. While one certainly would not dispute the value of statistical procedures, the clinical needs call for individual patient targeted prognosis.	Univ Ancona, Sch Med, Dept Pathol & Lab, Ancona, Italy	Montironi, R (reprint author), Univ Ancona, Sch Med, Osped Reg, Inst Pathol Anat & Histopathol, I-60020 Ancona, Italy.						BARTELS PH, 1995, PATHOLOGICA, V87, P115; Bartels PH, 1998, ANAL QUANT CYTOL, V20, P397; BARTELS PH, 1992, ANAL QUANT CYTOL, V14, P459; Bartels PH, 1996, EUR UROL, V30, P222; Bartels PH, 2001, PROSTATE, V48, P144, DOI 10.1002/pros.1093; Bartels PH, 1998, ANAL QUANT CYTOL, V20, P407; BARTELS PH, 1995, PATHOL RES PRACT, V191, P945; Bartels PH, 1998, ANAL QUANT CYTOL, V20, P389; Becker R. L. Jr., 1995, Pathologica (Genoa), V87, P246; Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; da Silva VD, 1999, ANAL QUANT CYTOL, V21, P113; Dukes CE, 1932, J PATHOL BACTERIOL, V35, P323, DOI 10.1002/path.1700350303; Hamilton PW, 1999, ANAL QUANT CYTOL, V21, P283; IRINOPOULOU T, 1993, ANAL QUANT CYTOL, V15, P341; JASS J, 1987, LANCET, V1, P1333; Jorgensen T, 1996, CYTOMETRY, V24, P277, DOI 10.1002/(SICI)1097-0320(19960701)24:3<277::AID-CYTO11>3.0.CO;2-N; Mairinger T, 1999, PROSTATE, V41, P12; Mazzucchelli R, 2001, ANTICANCER RES, V21, P1157; MONTIRONI R, 1995, PATHOL RES PRACT, V191, P917; MONTIRONI R, 2000, J UROL PATH, V12, P133, DOI 10.1385/JUP:12:3:133; Montironi R, 1997, J CLIN PATHOL, V50, P775, DOI 10.1136/jcp.50.9.775; POMANTE R, 1998, ACTA UROL ITAL, V12, P331	23	5	5	0	1	CAROL DAVILA UNIV PRESS	BUCHARESST	8 EROILOR SANITARI BLVD, BUCHARESST 76241, ROMANIA	1582-1838			J CELL MOL MED	J. Cell. Mol. Med.	JAN-MAR	2002	6	1					93	106		10.1111/j.1582-4934.2002.tb00314.x		14	Cell Biology; Medicine, Research & Experimental	Cell Biology; Research & Experimental Medicine	544JW	WOS:000175155300008	12003672	
B	Oliveira, PM; Lobo, V; Barroso, V; Moura-Pires, F			IEEE; IEEE; IEEE	Oliveira, PM; Lobo, V; Barroso, V; Moura-Pires, F			Detection and classification of underwater transients with data driven methods based on time-frequency distributions and non-parametric classifiers	OCEANS 2002 MTS/IEEE CONFERENCE & EXHIBITION, VOLS 1-4, CONFERENCE PROCEEDINGS			English	Proceedings Paper	MTS/IEEE Oceans 2002 Conference	OCT 29-31, 2002	BILOXI, MS	Marine Technol Soc, IEEE, OES			NEAREST	Due to the complexity of underwater transients and background interference, model based approaches to transient detection/classification are often not practical. This has motivated an interest for data-driven, model-free methods. One such method was presented in [2] and modified in [1], where it was applied to the detection of underwater transients. In this article, we will extend that approach, to allow its use in the more demanding environment of a brown water environment, where background noise is constituted by a multitude of different interferences, non-white, and highly non-stationary. Also, the assumption of linear separability amongst the transients and the background noise in the time-frequency or related domains will be discarded, leading to the use of an additional classifier stage. A technique to minimize the number of prototypes on this classifier will be presented. The developed methods are used to detect and classify real underwater transients, recorded off the Portuguese coast. Estimation of the overall error rate of the method is obtained using cross-validation with the available data set, showing that these methods can effectively be used in real environment situations.	Escola Naval, Alfeite, P-2800 Almada, Portugal	Oliveira, PM (reprint author), Escola Naval, Alfeite, P-2800 Almada, Portugal.		Lobo, Victor/D-2513-2010; 	Lobo, Victor/0000-0002-0149-3367; Barroso, Victor/0000-0002-9261-9155			AHA DW, 1997, ARTIFICIAL INTELLIGE, V11; Bax E, 2000, IEEE T INFORM THEORY, V46, P2746, DOI 10.1109/18.887892; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L., 1984, CLASSIFICATION REGRE; Cohen L., 1995, TIME FREQUENCY ANAL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNNINGHAM GS, 1994, IEEE T SIGNAL PROCES, V42, P1496, DOI 10.1109/78.286965; Dasarathy B. V., 1991, NEAREST NEIGHBOR PAT; Duda R O, 2001, PATTERN CLASSIFICATI; Fix E., 1951, DISCRIMINATORY ANAL, P261; FLANDRIN P, 1988, IEEE T ACOUST SPEECH, V36, P1377, DOI 10.1109/29.90365; JONES DL, P 1995 IEEE INT C AC, P1033; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; LOBO V, 1998, WCCI WORLD C COMP IN; Nock R, 2001, PATTERN RECOGN LETT, V22, P407, DOI 10.1016/S0167-8655(00)00133-1; OLIVEIRA PM, 2000, P MTS IEEE OC 2000 A; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	17	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7534-3				2002							12	16				5	Acoustics; Engineering, Ocean; Engineering, Electrical & Electronic; Instruments & Instrumentation; Imaging Science & Photographic Technology	Acoustics; Engineering; Instruments & Instrumentation; Imaging Science & Photographic Technology	BW53J	WOS:000182293200003		
B	Yager, RR			IEEE; IEEE	Yager, RR			Prototype reasoning and knowledge creation using granular objects	PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2			English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	MAY 12-17, 2002	HONOLULU, HI	IEEE, IEEE Neural Network Soc				We introduce a general framework which we call prototype based reasoning. We explain its role as a technology for knowledge discovery We look at some types of prototype based reasoning systems. First we consider nearest neighbor based systems. We then look at fuzzy rule based models and view these as prototype based reasoning. This unified perspective allows us to extend the capabilities of fuzzy modeling technology in a number of directions.	Iona Coll, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 2001, PTTERN CLASSIFICATIO; YAGER RR, 2001, MII2111 ION COLL MAC; Yager R. R., 2001, International Journal of Fuzzy Systems, V3	4	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7280-8				2002							680	684				5	Computer Science, Artificial Intelligence	Computer Science	BU95M	WOS:000177476600121		
B	Hullermeier, E			IEEE; IEEE	Hullermeier, E			Exploiting similarity and experience in decision making	PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2			English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	MAY 12-17, 2002	HONOLULU, HI	IEEE, IEEE Neural Network Soc				The idea of case-based decision making has recently been proposed as an alternative to expected utility theory. A case-based decision maker learns by storing already experienced decision problems, along with a rating of the results. Whenever a new problem needs to be solved, possible actions are assessed on the basis of experience from similar situations in which these actions have already been applied. In this paper, we consider case-based decision making within the context of instance-based learning, which is a special type of machine learning method. This consideration makes us suggest alternative case-based decision principles. These principles are motivated from a computational point of view and characterized axiomatically. Moreover, the possibility of applying case-based decision making in approximate reasoning is briefly touched on.	Univ Dortmund, Dept Comp Sci, D-4600 Dortmund, Germany	Hullermeier, E (reprint author), Univ Dortmund, Dept Comp Sci, D-4600 Dortmund, Germany.						Allais M, 1953, ECONOMETRICA, V21, P503, DOI 10.2307/1907921; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; ELLSBERG D, 1961, Q J ECON, V75, P643, DOI 10.2307/1884324; Gilboa I, 1997, ECON THEORY, V9, P47, DOI 10.1007/BF01213442; Gilboa I, 1998, ECAI 1998: 13TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P706; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; Gilboa I, 1996, GAME ECON BEHAV, V15, P1, DOI 10.1006/game.1996.0056; MARCH J, 1958, ORGANIZATIONS; Savage LJ, 1954, FDN STAT; Shepard D, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; Simon H., 1957, MODELS MAN; Tversky A., 1986, J BUS, V59, P251, DOI DOI 10.1086/296365; Von Neumann J., 1953, THEORY GAMES EC BEHA	14	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7280-8				2002							729	734				6	Computer Science, Artificial Intelligence	Computer Science	BU95M	WOS:000177476600130		
B	Domeniconi, C; Gunopulos, D		Grossman, R; Han, J; Motwani, R; Kumar, V; Mannila, H		Domeniconi, C; Gunopulos, D			Efficient local flexible nearest neighbor classification	PROCEEDINGS OF THE SECOND SIAM INTERNATIONAL CONFERENCE ON DATA MINING	SIAM PROCEEDINGS SERIES		English	Proceedings Paper	2nd SIAM International Conference on Data Mining (SDM 02)	APR 11-13, 2002	ARLINGTON, VA	SIAM			REGRESSION	The nearest neighbor technique is a simple and appealing method to address classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. The employment of a local adaptive metric becomes crucial in order to keep class conditional probabilities close to uniform, and therefore to minimize the bias of estimates. We propose a technique that computes a locally flexible metric by means of Support Vector Machines (SVMs). The maximum margin boundary found by the SVM is used to determine the most discriminant direction over the query's neighborhood. Such direction provides a local weighting scheme for input features. We present experimental evidence, together with a formal justification, of classification performance improvement over the SVM algorithm alone and over a variety of adaptive learning schemes, by using both simulated and real data sets. Moreover, the proposed method has the important advantage of superior efficiency over the most competitive technique used in our experiments.	Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA	Domeniconi, C (reprint author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.						Aha D. W., 1997, ARTIF INTELL, V11, P1; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bellman R., 1961, ADAPTIVE CONTROL PRO; Brown M., 1999, KNOWLEDGE BASED ANAL; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2000, ADV NEURAL INFORMATI, V13; DOMENICONI C, 2001, ADV NEURAL INFORMATI, V14; Duda R. O., 1973, PATTERN CLASSIFICATI; Friedman JH, 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Ho T. K., 1998, LECT NOTES COMPUTER, P640; Joachims T., 1998, P EUR C MACH LEARN; Joachims T., 1999, ADV KERNEL METHODS S; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Osuna E., 1997, P COMP VIS PATT REC; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING	23	0	0	0	1	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			0-89871-517-2	SIAM PROC S			2002							353	369				17	Computer Science, Artificial Intelligence	Computer Science	BU81X	WOS:000177123500021		
S	Sanchez, JS; Barandela, R; Ferri, FJ		Escrig, MT; Toledo, F; Golobardes, E		Sanchez, JS; Barandela, R; Ferri, FJ			On filtering the training prototypes in nearest neighbour classification	TOPICS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th Catalonian Conference on Artificial Intelligence	OCT 24-25, 2002	CASTELLON, SPAIN	Asociacio Catalana Intelligencia Artificial, British Petr Oil Castellon, Univ Jaume I, Dept Ingn Ciencia Computadores, Fdn Caixa Castello Bancaixa, Generalitat Valenciana, Minist Educ & Ciencia			LEARNING ALGORITHMS; SELECTION; CLASSIFIERS; DESIGN; GRAPHS; RULE	Filtering (or editing) is mainly effective in improving the classification accuracy of the Nearest Neighbour (NN) rule, and also in reducing its storage and computational requirements. This work reviews some well-known editing algorithms for NN classification and presents alternative approaches based on combining the NN and the, Nearest Centroid Neighbourhood of a sample. Finally, an empirical analysis over real data sets is provided.	U Jaume I, Dept Llenguatges & Sistemes Informat, Castello 12071, Spain; Inst Tecnol Toluca, Metepec 52140, Mexico; Univ Valencia, Dept Informat, E-46100 Burjassot, Valencia, Spain	Sanchez, JS (reprint author), U Jaume I, Dept Llenguatges & Sistemes Informat, Castello 12071, Spain.		Ferri, Francesc/L-7216-2014	Ferri, Francesc/0000-0002-1543-3568			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Barandela R, 2000, LECT NOTES COMPUT SC, V1876, P621; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P11, DOI 10.1016/0167-8655(95)00093-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; FERRI FJ, 1998, LECT NOTES COMPUTER, V1451, P620; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Hand DJ, 1997, CONSTRUCTION ASSESSM; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; Liu H., 1998, FEATURE SELECTION KN; Merz C, 1998, UCI REPOSITORY MACHI; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	33	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-00011-9	LECT NOTES ARTIF INT			2002	2504						239	248				10	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	BW66V	WOS:000182749300021		
J	Devi, VS; Murty, MN				Devi, VS; Murty, MN			An incremental prototype set building technique	PATTERN RECOGNITION			English	Article						pattern classification; prototype selection; supervised learning; k-nearest neighbour	NEAREST	This paper deals with the task of finding a set of prototypes from the training set. A reduced set is obtained which is used instead of the training set when nearest neighbour classification is used. Prototypes are added in an incremental fashion, where at each step of the algorithm, the number of prototypes selected keeps on increasing. The number of patterns in the training data classified correctly also keeps on increasing till all patterns are classified properly. After this, a deletion operator is used where some prototypes which are not so useful are removed. This method has been used to obtain the prototypes for a variety of benchmark data sets and results have been presented. (C) 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India; Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Murty, MN (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Murphy P. M., 1994, UCI REPOSITORY MACHI; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SUSHEELA V, 2000, SOFT COMPUTING IMAGE; Swonger C., 1972, FRONTIERS PATTERN RE, P511	10	23	23	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	FEB	2002	35	2					505	513				9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	507AV	WOS:000173005000017		
J	Holz, HJ; Loew, MH				Holz, HJ; Loew, MH			Validation of relative feature importance using natural data	PATTERN RECOGNITION LETTERS			English	Article						feature analysis; classifier-independent; discriminatory power; feature selection; non-parametric		Feature analysis for classification is based on the discriminatory power of features. In previous research, we have presented a metric called relative feature importance (RFI) for measuring the non-parametric discriminatory power (NPDP) of features, RFI has been shown to correctly rank features for a variety of artificial data sets. In this work, we validate RFI on natural data, using several natural data sets. (C) 2002 Elsevier Science B.V. All rights reserved.	Calif State Univ Hayward, Dept Math & Comp Sci, Hayward, CA 94542 USA; George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA	Holz, HJ (reprint author), Calif State Univ Hayward, Dept Math & Comp Sci, Hayward, CA 94542 USA.						Blackard J.A., 1998, THESIS COLORADO STAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671; Gelsema ES, 1996, PATTERN RECOGN LETT, V17, P1047, DOI 10.1016/0167-8655(96)00068-2; GELSEMA ES, 1994, PATTERN RECOGNITION, V4; Holz HJ, 1997, PATTERN RECOGN LETT, V18, P1219, DOI 10.1016/S0167-8655(97)00118-9; Holz H. J., 1996, Applied Parallel Computing. Computation in Physics, Chemistry and Engineering Science. Second International Workshop, PARA '95. Proceedings; HOLZ HJ, 1994, PATTERN RECOGN, V4, P473; HOLZ HJ, 1999, THESIS G WASHINGTON; Kohavi R., 1996, P 2 INT C KNOWL DISC, P202	10	0	0	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB	2002	23	4					367	380	PII S0167-8655(01)00170-2	10.1016/S0167-8655(01)00170-2		14	Computer Science, Artificial Intelligence	Computer Science	524BM	WOS:000173992100004		
J	Hofmann, WK; de Vos, S; Elashoff, D; Gschaidmeier, H; Hoelzer, D; Koeffler, HP; Ottmann, OG				Hofmann, WK; de Vos, S; Elashoff, D; Gschaidmeier, H; Hoelzer, D; Koeffler, HP; Ottmann, OG			Relation between resistance of Philadelphia-chromosome-positive acute lymphoblastic leukaemia to the tyrosine kinase inhibitor ST1571 and gene-expression profiles: a gene-expression study	LANCET			English	Article							CELL-LINES; MICROARRAY; STI571; SENSITIVITY; ACTIVATION; MECHANISM; LEUKEMIA; CANCER	Background The ABL tyrosine kinase inhibitor STI571 is a promising agent for treatment of advanced Philadelphia-chromosome-positive (Ph+) acute lymphoblastic leukaemia. However, resistance to this drug develops within a few months in most patients. We aimed to predict resistance to STI571. Methods Total RNA was extracted from 25 bone-marrow samples from 19 patients with Ph+ acute lymphoblastic leukaemia who were enrolled into a phase 11 study. 17 samples were obtained before STI571 treatment was started: ten from individuals who were classified as good responders to STI571 (sensitive), and seven from individuals who did not to respond to STI571 (primary resistance). Eight samples were obtained from patients during treatment with STI571. We analysed six matched samples, which were obtained before and during treatment with STI571. Oligonucleotide microarray analysis of samples was done with high-density microarrays. Findings We identified 95 genes whose expression could be used to predict sensitivity of leukaemic cells to STI571. On this basis, all the STI571-sensitive samples could clearly be distinguished from the resistant cases. 56 highly differentially expressed genes were identified in leukaemic cells that were secondarily resistant to STI571. Resistant leukaemic cells expressed high levels of Bruton's tyrosine kinase and two ATP synthetases (ATP5A1 and ATP5C1), and showed significantly reduced expression of the proapoptotic gene BAK1 and the cell-cycle control gene p15 INK4b, Interpretation We have shown the clinical relevance of gene expression data for the pretreatment assessment of acute lymphoblastic leukaemia. Our results have implications for future clinical studies of tyrosine kinase inhibitors.	Univ Hosp, Dept Haematol & Oncol, D-60596 Frankfurt, Germany; Univ Calif Los Angeles, Sch Med, Cedars Sinai Res Inst, Div Haematol & Oncol, Los Angeles, CA USA; Univ Calif Los Angeles, Sch Med, Dept Pathol, Los Angeles, CA 90024 USA; Univ Calif Los Angeles, Sch Publ Hlth, Dept Biostat, Los Angeles, CA 90024 USA; Novartis Pharma AG, Nurnberg, Germany	Hofmann, WK (reprint author), Univ Hosp, Dept Haematol & Oncol, Theodor Stern Kai 7, D-60596 Frankfurt, Germany.						Barthe C, 2001, Science, V293, P2163; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeRisi J, 2000, FEBS LETT, V470, P156, DOI 10.1016/S0014-5793(00)01294-1; Desiderio S, 1997, CURR OPIN IMMUNOL, V9, P534, DOI 10.1016/S0952-7915(97)80107-0; Druker BJ, 1996, NAT MED, V2, P561, DOI 10.1038/nm0596-561; Druker BJ, 2001, NEW ENGL J MED, V344, P1031, DOI 10.1056/NEJM200104053441401; Druker BJ, 2001, NEW ENGL J MED, V344, P1038, DOI 10.1056/NEJM200104053441402; Goldman JM, 2001, NEW ENGL J MED, V344, P1084, DOI 10.1056/NEJM200104053441409; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gorre ME, 2001, SCIENCE, V293, P876, DOI 10.1126/science.1062538; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hochhaus A, 2001, SCIENCE, V293, P2163; Hofmann WK, 2001, BLOOD, V98, P787, DOI 10.1182/blood.V98.3.787; Honda H, 1998, BLOOD, V91, P2067; Huettner CS, 2000, NAT GENET, V24, P57; Kaminski N, 2000, P NATL ACAD SCI USA, V97, P1778, DOI 10.1073/pnas.97.4.1778; Knight ZA, 2000, BLOOD, V96, P4003; Komatani H, 2001, CANCER RES, V61, P2827; Kudoh K, 2000, CANCER RES, V60, P4161; le Coutre P, 2000, BLOOD, V95, P1758; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Mahon FX, 2000, BLOOD, V96, P1070; Ottmann OG, 2000, BLOOD, V96, p828A; PUISSANT C, 1990, BIOTECHNIQUES, V8, P148; Satterthwaite AB, 2000, P NATL ACAD SCI USA, V97, P6687, DOI 10.1073/pnas.110146697; Takata M, 1996, J EXP MED, V184, P31, DOI 10.1084/jem.184.1.31; Voehringer DW, 2000, P NATL ACAD SCI USA, V97, P2680, DOI 10.1073/pnas.97.6.2680; Weisberg E, 2000, BLOOD, V95, P3498; Wilson Michael, 1999, Proceedings of the National Academy of Sciences of the United States of America, V96, P12833, DOI 10.1073/pnas.96.22.12833	29	152	160	1	3	LANCET LTD	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	0140-6736			LANCET	Lancet	FEB 9	2002	359	9305					481	486		10.1016/S0140-6736(02)07678-X		6	Medicine, General & Internal	General & Internal Medicine	520ML	WOS:000173785600011	11853794	
J	Cha, GH; Zhu, XM; Petkovic, D; Chung, CW				Cha, GH; Zhu, XM; Petkovic, D; Chung, CW			An efficient indexing method for nearest neighbor searches in high-dimensional image databases	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						dimensionality curse; image database; indexing method; nearest neighbor (NN) search	ALGORITHM	Nearest neighbor (NN) search is emerging as an important search paradigm in a variety of applications in which objects are represented as vectors of d numeric features. However, despite decades of efforts, except for the filtering approach such as the VA-file [31], the current solutions to find exact kNNs are far from satisfactory for large d. The filtering approach represents vectors as compact approximations and by first scanning these smaller approximations, only a small fraction of the real vectors are visited. In this paper, we introduce the local polar coordinate file (LPC-file) using the filtering approach for nearest-neighbor searches in high-dimensional image databases. The basic idea is to partition the vector space into rectangular cells and then to approximate vectors by polar coordinates on the partitioned local cells. The LPC information significantly enhances the discriminatory power of the approximation. To demonstrate the effectiveness of the LPC-file, we conducted extensive experiments and compared the performance with the VA-file and the sequential scan by using synthetic and real data sets. The experimental results demonstrate that the LPC-file outperforms both of the VA-file and the sequential scan in total elapsed time and in the number of disk accesses and that the LPC-file is robust in both "good" distributions (such as random) and "bad" distributions (such as skewed and clustered).	Tonymyong Univ Informat Technol, Dept Multimedia Engn, Pusan 608711, South Korea; eLance com, Sunnyvale, CA 94086 USA; Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea; IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Cha, GH (reprint author), Tonymyong Univ Informat Technol, Dept Multimedia Engn, Pusan 608711, South Korea.	ghcha@tmic.tit.ac.kr; xzhu@elance.com; dragutin@vmware.com; chungcw@islab.kaist.ac.kr	Chung, Chin-Wan/C-2029-2011				Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; ATKINSON MD, 1986, COMMUN ACM, V29, P996, DOI 10.1145/6617.6621; BECHTOLD S, 1998, P ACM SIGMOD INT C M, P142; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Cha GH, 1998, MULTIMED TOOLS APPL, V6, P263, DOI 10.1023/A:1009608331551; Comer D., 1979, ACM COMPUT SURV, V11, P121, DOI 10.1145/356770.356776; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Duda R. O., 1973, PATTERN CLASSIFICATI; Fayyad U., 1996, ADV KNOWLEDGE DISCOV; Flickner M., 1995, IEEE COMPUT, P23; HASTIE T, 1995, P 1 INT C KNOWL DISC, P142; Henrich A, 1998, PROC INT CONF DATA, P362, DOI 10.1109/ICDE.1998.655799; Horowitz E., 1995, FUNDAMENTALS DATA ST; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kanth K.V. Ravi, 1998, P ACM SIGMOD INT C M, P166; Katayama N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Knuth D.E., 1973, ART COMPUTER PROGRAM; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; Lin K, 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; MEGIDDO N, 1997, 10093 IBM RJ ALM RES; MIYAHARA M, 1992, P SPIE VIS COMMUN IM, V1001, P650; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; Ponceleon D., 1998, Proceedings ACM Multimedia 98, DOI 10.1145/290747.290760; Roussopoulos N., 1995, P ACM SIGMOD INT C M, P71, DOI DOI 10.1145/223784.223794; SALTON G, 1983, INTRO MODERN INFORMA; SHEPHERD J, 1999, P IS T SPIE C STOR R, V7, P350; STRANG G, 1980, LINEAR ALGEBRA ITS A; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; ZEZULA P, 1998, VLDB J, V7, P294	32	36	42	0	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210			IEEE T MULTIMEDIA	IEEE Trans. Multimedia	MAR	2002	4	1					76	87	PII S1520-9210(02)01399-8			12	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	524CY	WOS:000173995500008		
J	Liu, H; Motoda, H				Liu, H; Motoda, H			On issues of instance selection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material							ALGORITHMS		Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA; Osaka Univ, Inst Sci & Ind Res, Osaka, Japan	Liu, H (reprint author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.						Aha D. W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAEZAYATES R, 1999, MORDEN INFORMATION R; BLOEDORN E, 1998, FEATURE EXTRACTION C, P51; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; BREIMAN L, 1984, STAT SIGNAL PROCESSI, P191; Breiman L., 1984, CLASSIFICATION REGRE; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.-L., 1974, IEEE T COMPUTERS, VC-23; Chaudhuri S, 1998, P ACM SIGMOD INT C M, P436, DOI 10.1145/276304.276343; Cochran W. G., 1977, SAMPLING TECHNIQUES, V3rd; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devlin B., 1997, DATA WAREHOUSE ARCHI; Domingo C, 2002, DATA MIN KNOWL DISC, V6, P131, DOI 10.1023/A:1014091514039; DUMOUCHEL W, 1999, P 5 ACM C KNOWL DISC; Everitt B., 1974, CLUSTER ANAL; Fayyad U, 1996, ADV KNOWLEDGE DISCOV, P495; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1007/BF00114265; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1994, AAAI FALL S SERIES, P85; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; HARRISJONES C, 1997, AMSCATWP97118; Hussain F., 1999, TRC699 NAT U SING SC; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; KIVINEN J, 1994, SIGMOD PODS 94, P77; Langley P., 1996, ELEMENTS MACHINE LEA; Lewis D., 1994, P 17 ANN INT ACM SIG, P3; Lewis D.D., 1994, P 11 INT C MACH LEAR, P148; Liu H., 1998, FEATURE EXTRACTION C; Liu H., 1998, FEATURE SELECTION KN; Madigan D, 2002, DATA MIN KNOWL DISC, V6, P173, DOI 10.1023/A:1014095614948; McCallum A., 1998, P 15 INT C MACH LEAR, P350; Mitchell T. M., 1997, MACHINE LEARNING; PIATETSKYSHAPIR.G, 1984, ACM SIGMOD C, P256; PROVOST F, 1999, P 5 ACM C KNOWL DISC; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; REINARTZ T, 1999, LNAI, V1623; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Scholkopf B., 1995, P 1 INT C KNOWL DISC, P252; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; SMITH P, 1998, INTO STAT; Syed N. A., 1999, P 5 ACM SIGKDD INT C, P317, DOI 10.1145/312129.312267; SZALAY A, 1999, SCI AM; Utogoff P, 1989, MACH LEARN, V4, P161; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V. N., 1995, NATURE STAT LEARNING; Weiss S. M., 1998, PREDICTIVE DATA MINI; Weiss SM, 1991, COMPUTER SYSTEMS LEA	57	68	72	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810			DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					115	130		10.1023/A:1014056429969		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600001		
J	Brighton, H; Mellish, C				Brighton, H; Mellish, C			Advances in instance selection for instance-based learning algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						instance-based learning; instance selection; forgetting; pruning	NEAREST-NEIGHBOR RULE; CLASSIFICATION	The basic nearest neighbour classifier suffers from the indiscriminate storage of all presented training instances. With a large database of instances classification response time can be slow. When noisy instances are present classification accuracy can suffer. Drawing on the large body of relevant work carried out in the past 30 years, we review the principle approaches to solving these problems. By deleting instances, both problems can be alleviated, but the criterion used is typically assumed to be all encompassing and effective over many domains. We argue against this position and introduce an algorithm that rivals the most successful existing algorithm. When evaluated on 30 different problems, neither algorithm consistently outperforms the other: consistency is very hard. To achieve the best results, we need to develop mechanisms that provide insights into the structure of class definitions. We discuss the possibility of these mechanisms and propose some initial measures that could be useful for the data miner.	Univ Edinburgh, Dept Theoret & Appl Linguist, Language Evolut & Computat Res Unit, Edinburgh EH8 9LL, Midlothian, Scotland; Univ Edinburgh, Dept Artificial Intelligence, Edinburgh EH1 1HN, Midlothian, Scotland	Brighton, H (reprint author), Univ Edinburgh, Dept Theoret & Appl Linguist, Language Evolut & Computat Res Unit, Edinburgh EH8 9LL, Midlothian, Scotland.	henryb@ling.ed.ac.uk; chrism@dai.ed.ac.uk	Brighton, Henry/A-3504-2011				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; BRIGHTON H, 1996, THESIS U EDINBURGH S; BRIGHTON H, 1997, UNPUB GEOMETRIC CRIT; BRIGHTON H, 1997, THESIS U EDINBURGH S; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; Cameron-Jones R. M., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 1997, P 9 EUR C MACH LEARN, P29; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Domingos P., 1995, P 14 INT JOINT C ART, P1226; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Holte RC, 1989, P 11 INT JOINT C ART, P813; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; Kolodner J. L., 1993, CASE BASED REASONING; MARKOVITCH S, 1993, MACH LEARN, V10, P113, DOI 10.1007/BF00993503; Markovitch S., 1988, P 5 INT C MACH LEARN, P459; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Salganicoff M, 1993, P 10 INT C MACH LEAR, P276; SALZBERG S, 1991, MACH LEARN, V6, P227; Sebban M, 1999, LECT NOTES ARTIF INT, V1704, P184; SMYTH B, 1995, INT JOINT C ART INT, V1, P377; Swonger C., 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VANDENBOSCH A, 1998, P NEMLAP3 CONLL98, P195, DOI 10.3115/1603899.1603933; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WILSON DR, 1997, MACH LEARN P 14 INT; Zhang J., 1992, P 9 INT MACH LEARN C, P470	32	188	199	3	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810			DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					153	172		10.1023/A:1014043630878		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600003		
J	Ranilla, J; Bahamonde, A				Ranilla, J; Bahamonde, A			FAN: Finding Accurate iNductions	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES			English	Article						machine learning; classification rules; minimum distance; induction from examples	LEARNING ALGORITHMS; NEAREST-NEIGHBOR	In this paper we present a machine-learning algorithm that computes a small set of accurate and interpretable rules. The decisions of these rules can be straight-forwardly explained as the conclusions drawn by a case-based reasoner. Our system is named FAN, an acronym for finding accurate inductions. It starts from a collection of training examples and produces propositional rules able to classify unseen cases following a minimum-distance criterion in their evaluation procedure. In this way, we combine the advantages of instance-based algorithms and the conciseness of rule (or decision-tree) inducers, The algorithm followed by FAN can be seen as the result of successive steps of pruning heuristics. The main tool employed is that of the impurity level, a measure of the classification quality of a rule, inspired by a similar measure used in IB3. Finally, a number of experiments were conducted with standard benchmark datasets of the UCI repository to test the performance of our system, successfully comparing FAN with a wide collection of machine-learning algorithms. (C) 2002 Elsevier Science Ltd. All rights reserved.	Univ Oviedo, Ctr Artificial Intelligence, Gijon 33271, Spain	Ranilla, J (reprint author), Univ Oviedo, Ctr Artificial Intelligence, Campus Viesques, Gijon 33271, Spain.		Ranilla, Jose/E-8012-2013	Ranilla, Jose/0000-0003-2941-3741			Aha D. W., 1990, THESIS U CALIFORNIA; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAHAMONDE A, 1994, INT J COMPUT MATH, V54, P127, DOI 10.1080/00207169408804346; Blake C, 1998, UCI REPOSITORY MACHI; BOTANA F, 1995, INT J HUM-COMPUT ST, V42, P137, DOI 10.1006/ijhc.1995.1006; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Clark P, 1991, P 5 EUR WORK SESS LE, P151; Cohens W, 1995, P 12 INT C MACH LEAR, P115; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; del Coz JJ, 1999, LECT NOTES COMPUT SC, V1606, P527; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P, 1996, MACH LEARN, V24, P141; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Furnkranz J, 1997, MACH LEARN, V27, P139, DOI 10.1023/A:1007329424533; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohonen T., 1995, SELF ORGANIZING MAPS; Luaces O, 1999, LECT NOTES COMPUT SC, V1606, P497; LUACES O, 1998, LECT NOTES ARTIF INT, V1416, P448; MCCARTHY J, 1980, ARTIF INTELL, V13, P27, DOI 10.1016/0004-3702(80)90011-9; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Pratt W.K., 1991, DIGITAL IMAGE PROCES, V2nd; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1983, MACHINE LEARNING ART, V1, P463; RANILLA J, 1998, REV IBEROAMERICANA I, V4, P4; RANILLA J, 1995, P 6 C AS ESP INT ART, P225; Rendell L., 1986, Machine Learning, V1, DOI 10.1007/BF00114117; Salzberg S.L., 1990, LEARNING NESTED GEN; SPIEGEL MR, 1970, ESTADISTICA; Thrun S., 1991, CSCMU91197; Ventura D., 1995, P 10 INT S COMP INF, P443; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	37	12	12	0	0	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	1071-5819			INT J HUM-COMPUT ST	Int. J. Hum.-Comput. Stud.	APR	2002	56	4					445	474		10.1006/ijhc.1002		30	Computer Science, Cybernetics; Ergonomics; Psychology, Multidisciplinary	Computer Science; Engineering; Psychology	564VR	WOS:000176334700004		
J	Billsus, D; Clifford, AB; Evans, G; Gladish, B; Pazzani, M				Billsus, D; Clifford, AB; Evans, G; Gladish, B; Pazzani, M			Adaptive interfaces for ubiquitous web access	COMMUNICATIONS OF THE ACM			English	Article							USER	The invention of the movable type printing press launched the information age by making the mass distribution of information both feasible and economical. Newspapers, magazines, shopping catalogs, restaurant guides, and classified advertisements can trace their origins to the printing process. Five and a half centuries of technological progress in communications networks, protocols, computers, and user interface design led to the Web, online publishing, and e-commerce. Consumers and businesses have access to-vast stores of information. All this information, however, used to be accessible only while users were tethered to a computer at home or in an office. Wireless data and voice access to-this vast store allows unprecedented access to information from any location at any time.	AdaptiveInfo, Irvine, CA USA	Billsus, D (reprint author), AdaptiveInfo, Irvine, CA USA.						Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781; Billsuss D., 1998, P 15 INT C MACH LEAR, P46; Buchanan G., 2001, P 10 INT C WORLD WID, P673, DOI 10.1145/371920.372181; CHEVERST K, 2002, COMMUN ACM, V45; CLAYPOOL M, 2000, P INT C INT US INT S, P33; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; KOBSA A, 2002, COMMUN ACM, V45; MAES P, 1994, COMMUN ACM, V37; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; 杨云峰, 1999, [西安公路交通大学学报, Journal of Xian Highway University], P67	12	79	79	1	2	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0001-0782			COMMUN ACM	Commun. ACM	MAY	2002	45	5					34	38				5	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	544NC	WOS:000175165600014		
J	Stewart, B				Stewart, B			Predicting project delivery rates using the Naive-Bayes classifier	JOURNAL OF SOFTWARE MAINTENANCE AND EVOLUTION-RESEARCH AND PRACTICE			English	Article						software effort estimation; Bayesian networks; machine learning; model trees; neural networks	SOFTWARE	The importance of accurate estimation of software development effort is well recognized in software engineering. In recent years, machine learning approaches have been studied as possible alternatives to more traditional software cost estimation methods. The objective of this paper is to investigate the utility of the machine learning algorithm known as the Naive-Bayes classifier for estimating software project effort. We present empirical experiments with the Benchmark 6 data set from the International Software Benchmarking Standards Group to estimate project delivery rates and compare the performance of the Naive-Bayes approach to two other machine learning methods model trees and neural networks. A project delivery rate is defined as the number of effort hours per function point. The approach described is general and can be used to analyse not only software development data but also data on software maintenance and other types of software engineering. The paper demonstrates that the Naive-Bayes classifier has a potential to be used as an alternative machine learning tool for software development effort estimation. Copyright (C) 2002 John Wiley Sons, Ltd.	Univ Western Sydney, Sch Comp & Informat Technol, Penrith S DC, NSW 1797, Australia	Stewart, B (reprint author), Univ Western Sydney, Sch Comp & Informat Technol, Campbelltown Campus,Locked Bag 1797, Penrith S DC, NSW 1797, Australia.						ALBRECHT AJ, 1983, IEEE T SOFTWARE ENG, V9, P639, DOI 10.1109/TSE.1983.235271; Bishop C.M., 1995, NEURAL NETWORKS PATT; Boehm B, 1981, SOFTWARE ENG EC; Breiman L., 1984, CLASSIFICATION REGRE; Briand L. C., 1999, Proceedings of the 1999 International Conference on Software Engineering (IEEE Cat. No.99CB37002), DOI 10.1109/ICSE.1999.841022; BRIAND LC, 1992, IEEE T SOFTWARE ENG, V18, P931, DOI 10.1109/32.177363; Castillo E., 1997, EXPERT SYSTEMS PROBA; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowell R. G., 1999, PROBABILISTIC NETWOR; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Goldberg D. E., 1989, GENETIC ALGORITHMS S; JENSEN FV, INTRO BAYESIAN NETWO; JORGENSEN M, 1995, IEEE T SOFTWARE ENG, V21, P674, DOI 10.1109/32.403791; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Motoda H., 1998, FEATURE EXTRACTION C; Neapolitan R.E., 1990, PROBABILISTIC REASON; Pearl J, 1988, PROBABILISTIC REASON; Pfleeger S. L., 1998, SOFTWARE ENG THEORY; PUTNAM LH, 1978, IEEE T SOFTWARE ENG, V4, P345, DOI 10.1109/TSE.1978.231521; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Shepperd M, 1997, IEEE T SOFTWARE ENG, V23, P736, DOI 10.1109/32.637387; Shin M, 2000, IEEE T SOFTWARE ENG, V26, P567; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Witten I.H., 2000, DATA MINING PRACTICA	26	9	9	3	4	JOHN WILEY & SONS LTD	W SUSSEX	BAFFINS LANE CHICHESTER, W SUSSEX PO19 1UD, ENGLAND	1532-060X			J SOFTW MAINT EVOL-R	J. Softw. Maint. Evol.-Res. Pract.	MAY-JUN	2002	14	3					161	179		10.1002/smr.250		19	Computer Science, Software Engineering	Computer Science	568UM	WOS:000176563100002		
J	Bloch, DA; Olshen, RA; Walker, MG				Bloch, DA; Olshen, RA; Walker, MG			Risk estimation for classification trees	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						.632 bootstrap; empirical Bayes; Breiman's method	CONSISTENT NONPARAMETRIC REGRESSION; LEARNING-TESTING METHODS; FOLD CROSS-VALIDATION; ALGORITHM; CART	This article is a study of techniques for bias reuction of estimates of risk both globally and within terminal nodes of CART R classification trees. In Section 5.4 of Classification and Regression Trees, Leo Breiman presented an estimator that has two free parameters. An empirical Bayes method was put forth for estimating them. Here we explain why the estimator should be successful in the many examples for which it is. We give numerical evidence from simulations in the two-class case with attention to ordinary resubstitution and seven other methods of estimation. There are 14 sampling distributions, all but one simulated and the remaining concerning E. coli promoter regions. We report on varying minimum node sizes of the trees prior probabilities and misclassification costs; and, when relevant, the numbers of bootstraps or cross-validations. A variation of Breiman's method in which repeated cross-validation is employed to estimate global rates of misclassification was the most accurate from among the eight methods. Exceptions are cases for which the Bayes risk of the Bayes rule is small, For them, either a local bootstrap.632 estimate or Breiman's method modified to use a bootstrap estimate of the global misclassification rate is most accurate.	Stanford Univ, Sch Med, Dept Hlth Res & Policy, Stanford, CA 94305 USA; Walker Biosci, Sunnyvale, CA 94087 USA	Bloch, DA (reprint author), Stanford Univ, Sch Med, Dept Hlth Res & Policy, Stanford, CA 94305 USA.						Anderson T. W., 1966, MULTIVARIATE ANAL, P5; Bishop Y., 1975, DISCRETE MULTIVARIAT; BLOCH DA, 1989, J AM STAT ASSOC, V84, P897, DOI 10.2307/2290064; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRENT RP, 1971, COMPUT J, V14, P422, DOI 10.1093/comjnl/14.4.422; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; BURMAN P, 1990, SANKHYA SER A, V52, P314; CLARK L. A., 1992, STAT MODELS S, P377; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAWFORD SL, 1989, INT J MAN MACH STUD, V31, P197, DOI 10.1016/0020-7373(89)90027-8; Dannegger F, 2000, STAT MED, V19, P475, DOI 10.1002/(SICI)1097-0258(20000229)19:4<475::AID-SIM351>3.0.CO;2-V; Donoho DL, 1997, ANN STAT, V25, P1870, DOI 10.1214/aos/1069362377; EFRON B, 1982, SIAM NSF CBMS MONOGR, V38; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GOLDMAN L, 1988, NEW ENGL J MED, V318, P798; GORDON L, 1984, J MULTIVARIATE ANAL, V15, P147, DOI 10.1016/0047-259X(84)90022-8; HARLEY CB, 1987, NUCLEIC ACIDS RES, V15, P2343, DOI 10.1093/nar/15.5.2343; Hastie T., 1990, SHRINKING TREES; KARLIN S, 1958, ANN MATH STAT, V29, P406, DOI 10.1214/aoms/1177706620; KUELBS J, 1980, ANN PROBAB, V8, P405, DOI 10.1214/aop/1176994716; Lehmann E. L., 1983, THEORY POINT ESTIMAT; Lugosi G, 1996, ANN STAT, V24, P687; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Tibshirani R, 1993, INTRO BOOTSTRAP; WALKER MG, 1992, THESIS STANFORD U ST; ZHANG P, 1993, ANN STAT, V21, P299, DOI 10.1214/aos/1176349027	30	7	7	1	4	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	JUN	2002	11	2					263	288		10.1198/106186002760180509		26	Statistics & Probability	Mathematics	561RX	WOS:000176157400001		
J	Barkol, O; Rabani, Y				Barkol, O; Rabani, Y			Tighter lower bounds for nearest neighbor search and related problems in the cell probe model	JOURNAL OF COMPUTER AND SYSTEM SCIENCES			English	Article; Proceedings Paper	32nd Annual ACM Symposium on Theory of Computing	JUN 21-23, 2000	PORTLAND, OREGON				ALGORITHM	We prove new lower bounds for nearest neighbor search in the Hamming cube. Our lower bounds are for randomized, two-sided error, algorithms in Yao's cell probe model. Our bounds are in the form of a tradeoff among the number of cells, the size of a cell, and the search time. For example, suppose we are searching among n points in the d dimensional cube, we use poly(n, d) cells, each containing poly(d, log n) bits. We get a lower bound of Omega(d/log n) on the search time, a significant improvement over the recent bound of Omega(log d) of Borodin et al. This should be contrasted with the upper bound of D(log log d) for approximate search (and O(1) for a decision version of the problem; our lower bounds hold in that case). By previous results, the bounds for the cube imply similar bounds for nearest neighbor search in high dimensional Euclidean space, and for other geometric problems. (C) 2002 Elsevier Science (USA).	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Barkol, O (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.						Agarwal P. K., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/129712.129763; AJTAI M, 1999, NONLINEAR TIME LOWER; Ajtai M., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301424; Alon N., 1992, PROBABILISTIC METHOD; ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Beame P., 1998, Proceedings 39th Annual Symposium on Foundations of Computer Science (Cat. No.98CB36280), DOI 10.1109/SFCS.1998.743453; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; Miltersen P. B., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195415; Chakrabarti A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301325; CLARKSON A, 1994, P 10 SCG, P160; CLARKSON KL, 1988, SIAM J COMPUT, V17, P830, DOI 10.1137/0217052; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Berg Mark, 1997, COMPUTATIONAL GEOMET; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Duda R. O., 1973, PATTERN CLASSIFICATI; FAGIN R, 1998, P PODS; Flickner M., 1995, IEEE COMPUT, P23; Gersho A., 1991, VECTOR QUANTIZATION; HASTIE T, 1995, 1 INT C KNOWL DISC D; INDYK P, IN PRESS SODA 2000; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kleinberg J.M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; MATOUSEK J, 1991, PROCEEDINGS - 32ND ANNUAL SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, P207, DOI 10.1109/SFCS.1991.185370; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; Miltersen P. B., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, DOI 10.1145/225058.225093; PENTLAND A, 1994, P SPIE C STOR RETR I, V2; Salton G., 1989, AUTOMATIC TEXT PROCE; SMEULDERS AWM, 1996, P 1 WORKSH IM DAT MU; Yao A.C., 1985, P 17 ANN ACM S THEOR, P163, DOI 10.1145/22145.22163; YAO ACC, 1981, J ACM, V28, P615, DOI 10.1145/322261.322274	36	8	8	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-0000			J COMPUT SYST SCI	J. Comput. Syst. Sci.	JUN	2002	64	4					873	896		10.1006/jcss.2002.1831		24	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	571ME	WOS:000176720500007		
J	Pekalska, E; Duin, RPW				Pekalska, E; Duin, RPW			Dissimilarity representations allow for building good classifiers	PATTERN RECOGNITION LETTERS			English	Article						similarity representations; normal density-based classifiers		In this paper, a classification task on dissimilarity representations is considered. A traditional way to discriminate between objects represented by dissimilarities is the nearest neighbor method. It suffers, however, from a number of limitations, i.e., high computational complexity, a potential loss of accuracy when a small set of prototypes is used and sensitivity to noise. To overcome these shortcomings, we propose to use a normal density-based classifier constructed on the same representation. We show that such a classifier, based on a weighted combination of dissimilarities, can significantly improve the nearest neighbor rule with respect to the recognition accuracy and computational effort. (C) 2002 Elsevier Science B.V. All rights reserved.	Delft Univ Technol, Appl Phys Lab, Pattern Recognit Grp, NL-2628 CJ Delft, Netherlands	Pekalska, E (reprint author), Delft Univ Technol, Appl Phys Lab, Pattern Recognit Grp, Lorentzweg 1, NL-2628 CJ Delft, Netherlands.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Dubuisson M. P., 1994, P 12 INT C PATT REC, V1, P566, DOI DOI 10.1109/ICPR.1994.576361; Duda R O, 2001, PATTERN CLASSIFICATI; Duin R.P.W., 2000, P 15 INT C PATT REC, V2, P1, DOI 10.1109/ICPR.2000.906006; Duin RPW, 1999, PATTERN RECOGN LETT, V20, P1175, DOI 10.1016/S0167-8655(99)00085-9; Edelman S., 1999, REPRESENTATION RECOG; Fukunaga K., 1990, INTRO STAT PATTERN R; Goldstone R.L., 1999, MIT ENCY COGNITIVE S, P763; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOUTEPEN J, 1994, 2 PLEN WORKSH ECA AM; HOUTEPEN J, 1994, 2 AALB S CHROM AN SE; HOUTEPEN J, 1994, THESIS DELFT U TECHN, P1; PEKALSKA E, 2000, P 15 INT C PATT REC, V2, P12, DOI 10.1109/ICPR.2000.906008; Pekalska E, 2001, ELECTRON LETT, V37, P159, DOI 10.1049/el:20010121; Ripley BD, 1996, PATTERN RECOGNITION; Vapnik V., 1998, STAT LEARNING THEORY; WHARTON CM, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P588; Wilson C., 1992, HANDPRINTED CHARACTE	20	97	99	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2002	23	8					943	956	PII S0167-8655(02)00024-7	10.1016/S0167-8655(02)00024-7		14	Computer Science, Artificial Intelligence	Computer Science	540AU	WOS:000174906500005		
J	Nugroho, AS; Kuroyanagi, S; Iwata, A				Nugroho, AS; Kuroyanagi, S; Iwata, A			A solution for imbalanced training sets problem by CombNET-II and its application on fog forecasting	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						neural network; CombNET-II; self-growing algorithm; imbalanced training sets problem; fog forecasting		Studies on artificial neural network have been conducted for a long time, and its contribution has been shown in many fields. However, the application of neural networks in the real world domain is still a challenge, since nature does not always provide the required satisfactory conditions. One example is the class size unbalanced condition in which one class is heavily under-represented compared to another class. This condition is often found in the real world domain and presents several difficulties for algorithms that assume the balanced condition of the classes. In this paper, we propose a method for solving problems posed by imbalanced training sets by applying the modified large-scale neural network "CombNET-II." CombNET-II consists of two types of neural networks. The first type is a one-layer vector quantization neural network to turn the problem into a more balanced condition. The second type consists of several modules of three-layered multilayer perceptron trained by backpropagation for finer classification. CombNET-II combines the two types of neural networks to solve the problem effectively within a reasonable time. The performance is then evaluated by turning the model into a practical application for a fog forecasting problem. Fog forecasting is an imbalanced training sets problem, since the probability of fog appearance in the observation location is very low. Fog events should be predicted every 30 minutes based on the observation of meteorological conditions. Our experiments showed that CombNET-II could achieve a high prediction rate compared to the k-nearest neighbor classifier and the three-layered multilayer perceptron trained with BP. Part of this research was presented in the 1999 Fog Forecasting Contest sponsored by Neurocomputing Technical Croup of IEICE, Japan; and CombNET-II achieved the highest accuracy among the participants.	Nagoya Inst Technol, Dept Elect & Comp Engn, Nagoya, Aichi 4668555, Japan	Nugroho, AS (reprint author), Nagoya Inst Technol, Dept Elect & Comp Engn, Nagoya, Aichi 4668555, Japan.						ANTO SN, 1999, P 1999 IEICE GEN C Y, P323; Bishop C.M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANTAS AS, 2000, P IJCNN2000, V4, P435, DOI 308154337,12,1; Duda R. O., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Funkunaga K., 1990, INTRO STAT PATTERN R; HOTTA K, 1992, IEICE T D, V75, P545; JAPKOWICZ N, 2000, INT WORKSH LEARN IMB; Japkowicz N., 2000, P 2000 INT C ART INT, V1, P111; KAWAJIRI H, 1998, P 4 EANN GIBR JUN, P40; Kubat M., 1997, P 14 INT C MACH LEAR, P179; 1999 FOG FORECASTING	13	9	11	0	0	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532			IEICE T INF SYST	IEICE Trans. Inf. Syst.	JUL	2002	E85D	7					1165	1174				10	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	581YU	WOS:000177323400011		
J	Lazzerini, B; Marcelloni, F				Lazzerini, B; Marcelloni, F			Classification based on neural similarity	ELECTRONICS LETTERS			English	Article								Following the approach of extracting similarity metrics directly from labelled data, a standard back-propagation neural network is adopted to determine a degree of similarity between pairs of input points. The similarity computed by the network is then used to guide a k-NN classifier, which associates a label with an unknown pattern based on the k most similar points. Experimental results on both synthetic and real-world data sets show that the similarity-based k-NN rule outperforms the Euclidean distance-based k-NN rule.	Univ Pisa, Dipartimento Ingn Informaz, I-56122 Pisa, Italy	Lazzerini, B (reprint author), Univ Pisa, Dipartimento Ingn Informaz, Via Diotisalvi 2, I-56122 Pisa, Italy.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; Jain AK, 1999, ACM COMPUT SURV, V31, P265; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; MICHALSKI RS, 1983, IEEE T PATTERN ANAL, V5, P396; PEDRYCZ W, 2001, P 2 INT WORKSH SOFT, P60	6	2	2	2	2	IEE-INST ELEC ENG	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	0013-5194			ELECTRON LETT	Electron. Lett.	JUL 18	2002	38	15					810	812		10.1049/el:20020549		3	Engineering, Electrical & Electronic	Engineering	582FM	WOS:000177339100031		
J	Gora, G; Wojna, A				Gora, G; Wojna, A			RIONA: A new classification system combining rule induction and instance-based learning	FUNDAMENTA INFORMATICAE			English	Article						machine learning; instance-based learning; rule induction; nearest neighbour method		The article describes a method combining two widely-used empirical approaches to learning from examples: rule induction and instance-based learning. In our algorithm (RIONA) decision is predicted not on the basis of the whole support set of all rules matching a test case. but the support set restricted to a neighbourhood of a test case. The size of the optimal neighbourhood is automatically induced during the learning phase. The empirical study shows the interesting fact that it is enough to consider a small neighbourhood to achieve classification accuracy comparable to an algorithm considering the whole learning set. The combination of k-NN and a rule-based algorithm results in a significant acceleration of the algorithm using all minimal rules. Moreover, the presented classifier has high accuracy for both kinds of domains: more suitable for k-NN classifiers and more suitable for rule based classifiers.	Warsaw Univ, Inst Informat, PL-02097 Warsaw, Poland	Gora, G (reprint author), Warsaw Univ, Inst Informat, Banacha 2, PL-02097 Warsaw, Poland.						A Skowron, 1995, P 2 JOINT ANN C INF, P34; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bazan JG, 1998, P 1 INT C ROUGH SETS, P521; BAZAN JG, 2000, P 2 INT C ROUGH SETS, P106; Biberman Y., 1994, P 9 EUR C MACH LEARN, P49; Bishop C.M., 1996, NEURAL NETWORKS PATT; Blake C, 1998, UCI REPOSITORY MACHI; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1996, MACH LEARN, V24, P141; Duda R. O., 1973, PATTERN CLASSIFICATI; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; GOLDING AR, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P22; GORA G, 2002, P 3 INT C ROUGH SETS; GORA G, 2002, P 13 EUR C MACH LEAR; Grzymala- Busse J. W., 1992, INTELLIGENT DECISION, P3; GRZYMALABUSSE JW, 1998, ROUGH SETS KNOWLEDGE, V1, P366; GRZYMALABUSSE JW, 1997, P 6 INT S INT INF SY, P149; LI J, 2001, DEEPS NEW INSTANCE B; LI J, 2001, 5 PAC AS C KNOWL DIS, P455; Li J, 2000, P 4 EUR C PRINC PRAC, P191; Maneewongvatana S., 2001, P INT C COMP SCI ICC, P842; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Mitchell T. M., 1997, MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Skowron A, 1992, INTELLIGENT DECISION, P331; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wettschereck D, 1994, THESIS OREGON STATE	31	32	34	2	4	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968			FUND INFORM	Fundam. Inform.	AUG	2002	51	4					369	390				22	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	630EM	WOS:000180094600003		
J	Gyorfi, L; Schafer, D; Walk, H				Gyorfi, L; Schafer, D; Walk, H			Relative stability of global errors of nonparametric function estimators	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						nonparametric density estimation; nonparametric regression estimation; relative stability	NEIGHBOR PATTERN-CLASSIFICATION; HISTOGRAM DENSITY-ESTIMATION; ASYMPTOTIC NORMALITY; L1 CONVERGENCE; REGRESSION; EQUIVALENCE; CONSISTENCY; THEOREM; RATES	This paper presents relative stability properties of various nonparametric density estimators (histogram, kernel estimates) and of regression estimators (partitioning, kernel, and nearest neighbor estimates). In density estimation, let E(n) denote the L(1) error of an estimate calculated from n data, whereas in regression estimation, the L(2) error of the estimate is used. Sufficient conditions for E(n)/E{E(n)} --> 1 in probability are provided. If this limit holds, the asymptotic behavior of the random error E(n) can be characterized by its expectation E{E(n)}, and one may apply, for example, the established rate-of-convergence results for E{E(n)}.	Tech Univ Budapest, Dept Comp Sci & Informat Theory, H-1521 Budapest, Hungary; Univ Stuttgart, Fachbereich Math, D-70511 Stuttgart, Germany	Gyorfi, L (reprint author), Tech Univ Budapest, Dept Comp Sci & Informat Theory, H-1521 Budapest, Hungary.	gyorfi@szit.bme.hu; schaefdk@mathematik.uni-stuttgart.de; walk@mathematik.uni-stuttgart.de					ABOUJAOUDE S, 1976, ANN I H POINCARE B, V12, P213; ABOUJAOUDE S, 1977, THESIS U PARIS 6 PAR; BEIRLANT J, 1994, CAN J STAT, V22, P309, DOI 10.2307/3315594; Beirlant J, 1998, J STAT PLAN INFER, V71, P93, DOI 10.1016/S0378-3758(98)00008-1; Beirlant J, 1998, J NONPARAMETR STAT, V9, P197, DOI 10.1080/10485259808832742; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; DEVROYE L, 1983, ANN STAT, V11, P896, DOI 10.1214/aos/1176346255; DEVROYE L, 1989, J STAT PLAN INFER, V23, P71, DOI 10.1016/0378-3758(89)90040-2; DEVROYE L, 1988, PROBAB THEORY REL, V77, P521, DOI 10.1007/BF00959615; Devroye L., 1985, NONPARAMETRIC DENSIT; DEVROYE L, 1983, P 4 PANN S MATH STAT, P67; DEVROYE L, 1991, NATO ADV SCI I C-MAT, V335, P31; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; EFRON B, 1981, ANN STAT, V9, P586, DOI 10.1214/aos/1176345462; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GYORFI L, 2002, IN PRESS DISTRIBUTIO; GYORFI L, 1991, NATO ADV SCI I C-MAT, V335, P329; HALL P, 1984, J MULTIVARIATE ANAL, V14, P1, DOI 10.1016/0047-259X(84)90044-7; HOLSTROM L, 1992, J MULTIVARIATE ANAL, V40, P245; KRZYZAK A, 1986, IEEE T INFORM THEORY, V32, P668, DOI 10.1109/TIT.1986.1057226; LUGOSI G, 2002, PRINCIPLES NONPARAME, P5; Nadaraya E., 1964, THEOR PROBAB APPL, V9, P141, DOI DOI 10.1137/1109020; NADARAYA EA, 1970, THEOR PROBAB APPL+, V15, P134, DOI 10.1137/1115015; Reiss R-D, 1989, APPROXIMATE DISTRIBU; SPIEGELMAN C, 1980, ANN STAT, V8, P240, DOI 10.1214/aos/1176344950; STEELE JM, 1986, ANN STAT, V14, P753, DOI 10.1214/aos/1176349952; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; TUKEY JW, 1961, P 4 BERK S, P681; TUKEY JW, 1947, ANN MATH STAT, V18, P529, DOI 10.1214/aoms/1177730343; Watson G. S., 1964, SANKHYA A, V26, P359	34	1	1	3	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	AUG	2002	48	8					2230	2242		10.1109/TIT.2002.800491		13	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	576JJ	WOS:000177000400008		
J	Yager, RR				Yager, RR			Using fuzzy methods to model nearest neighbor rules	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						fuzzy methods; IOWA; nearest neighbor models	OPERATOR; FUSION	The basic principle used in the construction of nearest neighbor models is discussed. The induced OWA (IOWA) operators are shown to provide a useful formal structure for building nearest neighbor models. A methodology for learning IOWA operator nearest neighbor models is described. Various types of nearest neighbor rules are investigated including those based on a linguistic specification. The situation in which the value of interest lies in an ordinal set is also considered. It is shown that the weighted median provides a useful tool for constructing nearest neighbor rules in this case.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				Bezdek J. C., 1999, FUZZY MODELS ALGORIT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1990, NEAREST NEIGHBOR NN; Duda R. O., 1973, PATTERN CLASSIFICATI; Filev D, 1998, FUZZY SET SYST, V94, P157, DOI 10.1016/S0165-0114(96)00254-0; FILEV D, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P468, DOI 10.1109/FUZZY.1994.343740; FUKUNAGA K, 1991, STAT PATTERN RECOGNI; Kacprzyk J., 1997, ORDERED WEIGHTED AVE; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; MITCHELL H, 1997, P INT C FUZZ LOG APP, P39; Mitchell HB, 2000, INT J INTELL SYST, V15, P317, DOI 10.1002/(SICI)1098-111X(200004)15:4<317::AID-INT4>3.0.CO;2-J; Torra V., 1999, MATHWARE SOFT COMPUT, V6, P249; Yager R. R., 1999, COMPUTING WORDS INFO, V1, P50; Yager R. R., 1987, FUZZY SETS APPL SELE; Yager RR, 1997, INT J GEN SYST, V26, P239, DOI 10.1080/03081079708945181; Yager RR, 1997, ORDERED WEIGHTED AVERAGING OPERATORS, P41; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789; Yager RR, 1998, INT J APPROX REASON, V18, P35, DOI 10.1016/S0888-613X(97)10003-2; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; ZADEH LA, 1999, COMPUTING WORDS INFO, V1; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904	22	15	16	0	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2002	32	4					512	525	PII S 1083-4419(02)04349-2	10.1109/TSMCB.2002.1018770		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	574VA	WOS:000176909200011	18238147	
J	Bartnikas, R				Bartnikas, R			Partial discharges - Their mechanism, detection and measurement	IEEE TRANSACTIONS ON DIELECTRICS AND ELECTRICAL INSULATION			English	Review							GAS-INSULATED SUBSTATIONS; MULTILAYER PERCEPTRON TECHNIQUE; FREQUENCY SPECTRUM ANALYSIS; COMPUTER-AIDED MEASUREMENT; GENERATOR STATOR WINDINGS; PD PATTERN-RECOGNITION; SHORT AIR GAPS; NEURAL-NETWORK; POWER TRANSFORMERS; DIELECTRIC LIQUIDS	Different partial discharge (PD) detection and measurement procedures suitable for use on cables, capacitors, transformers and rotating machines are examined and compared. Both narrow and wide bandwidth PD detectors are considered; particular attention is given in regard to their suitability to different types of electrical apparatus and cable specimens under test as well as their applicability to discharge site location and their capability to detect different forms of PD. A rather substantial portion of the discussion is devoted to the use of intelligent machines as applied to PD pattern recognition in terms of either PD pulse-height/discharge epoch (phase) distributions or discharge pulse shape attributes.	Inst Rech Hydro Quebec, Varennes, PQ J3X 1S1, Canada	Bartnikas, R (reprint author), Inst Rech Hydro Quebec, 1800 Montee Ste Julie, Varennes, PQ J3X 1S1, Canada.						*AEIC, 1993, AEIC CS795 SPEC CROS; *AEIC, 1994, AEIC CS595 SPEC CROS; *AEIC, 1996, AEIC CS695 SPEC ETHY; Ahmed NH, 1998, IEEE T DIELECT EL IN, V5, P181, DOI 10.1109/94.671927; ALLEN DJ, 1973, PUBL 1, V94, P65; ANDERSON JG, 1956, AIEE T POWER APPARAT, V75, P1193; [Anonymous], 2000, 14342000 IEEE; BOGGS SA, 1992, IEEE T POWER DELIVER, V7, P499; [Anonymous], 2862000 IEEE; *ANSI, C6831976 ANSI; *ANSI, C6321987 ANSI; ASHWANDEN T, 1998, P CIGR PAR; *ASTM, 2001, ASTM BOOK STAND, V10; AUDOLI A, 1990, 1990 IEEE INT S EL I, P379; AUDOLI A, 1992, 1992 IEEE INT S EL I, P359; AUDOLI A, 1991, 3 IEEE INT C PROP AP; AUSTIN J, 1976, IEEE T ELECTR INSUL, V11, P129, DOI 10.1109/TEI.1976.297920; BAGHURST AH, 1985, C EL INS DIEL PHEN O, P471; Bapt JC, 1974, C EL INS DIEL PHEN N, P282; BAPT JC, 1975, 1975 S INT TECHN HAU, P276; BARTNIKAS R, UNPUB MULTISTRESS AG; BARTNIKA.R, 1969, ARCH ELEKTROTECH, V52, P348, DOI 10.1007/BF01573780; BARTNIKAS R, 1975, IEEE T POWER AP SYST, VPA94, P716, DOI 10.1109/T-PAS.1975.31899; BARTNIKA.R, 1973, IEEE T INSTRUM MEAS, VIM22, P403, DOI 10.1109/TIM.1973.4314196; BARTNIKAS R, 1962, THESIS MCGILL U MONT; Bartnikas R., 1968, British Journal of Applied Physics (Journal of Physics D), V1; Bartnikas R., 1976, 1976 IEEE International Symposium on Electrical Insulation; BARTNIKAS R, 1979, STP ASTM, V669; BARTNIKAS R, 1995, IEEE T DIELECT EL IN, V2, P557, DOI 10.1109/94.407021; BARTNIKAS R, 1999, POWER COMMUNICATION; BARTNIKAS R, 1990, IEEE T ELECTR INSUL, V25, P111, DOI 10.1109/14.45238; BARTNIKAS R, 1987, STP ASTM, V926; BARTNIKAS R, 1994, MONOGRAPH, V2; BARTNIKAS R, 1987, IEEE T ELECTR INSUL, V22, P629, DOI 10.1109/TEI.1987.299011; Bartnikas R, 1963, IEEE T POWER APPAR S, V82, P366; BARTNIKAS R, 1983, IEEE T ELECTR INSUL, V18, P458, DOI 10.1109/TEI.1983.298686; BARTNIKA.R, 1971, IEEE T ELECTR INSUL, VEI 6, P63, DOI 10.1109/TEI.1971.299156; BARTNIKA.R, 1965, IEEE T POWER AP SYST, VPA84, P770; BARTNIKAS R, 1992, IEEE T ELECTR INSUL, V27, P3, DOI 10.1109/14.123436; BARTNIKA.R, 1969, J APPL PHYS, V40, P1974, DOI 10.1063/1.1657880; BARTNIKA.R, 1968, IEEE T ELECTR INSUL, VEI 3, P91, DOI 10.1109/TEI.1968.299037; BARTNIKAS R, 1983, STP ASTM, V783; BARTNIKA.R, 1972, IEEE T ELECTR INSUL, VEI 7, P3, DOI 10.1109/TEI.1972.299182; BARTNIKA.R, 1966, REV SCI INSTRUM, V37, P1245, DOI 10.1063/1.1720468; BARTNIKAS R, 1966, P CIGR PAR; BARTNIKAS R, 1993, IEEE T ELECTR INSUL, V28, P956, DOI 10.1109/14.249369; Bartnikas R., 1969, IEEE Transactions on Instrumentation and Measurement, VIM-18, DOI 10.1109/TIM.1969.4313834; BARTNIKA.R, 1973, IEEE T ELECTR INSUL, VEI 8, P2, DOI 10.1109/TEI.1973.299235; BARTNIKAS R, 1992, IEEE T PLASMA SCI, V20, P487, DOI 10.1109/27.163585; BEALE R, 1985, NEURAL COMPUTING INT; BENGSTSSON T, 1997, 10 INT S HV ENG MONT, V4, P115; BEYER M, 1982, IEEE T POWER APPARAT, V101, P3451; BHIMANI BV, 1961, AIEE T POWER APPARAT, V80, P148; BIDHENDI HN, 1997, P 10 INT S HIGH VOLT, P87; Blokhintsev I, 1999, IEEE T ENERGY CONVER, V14, P930, DOI 10.1109/60.815010; BOGGS SA, 1982, IEEE T POWER AP SYST, V101, P1935, DOI 10.1109/TPAS.1982.317482; BOGGS SA, 1981, IEEE T POWER AP SYST, V100, P3969, DOI 10.1109/TPAS.1981.316992; BORSI H, 1993, IEEE T ELECTR INSUL, V28, P1007, DOI 10.1109/14.249374; Borsi H, 2000, IEEE T DIELECT EL IN, V7, P21, DOI 10.1109/94.839337; BORSI H, 1992, IEEE T ELECTR INSUL, V27, P1118, DOI 10.1109/14.204862; BOYERS DG, 1982, APPL PHYS LETT, V41, P28, DOI 10.1063/1.93310; BOZZO R, 1996, 1996 IEEE INT S EL I, P389; BOZZO R, 1993, IEEE T ELECTR INSUL, V28, P1050, DOI 10.1109/14.249378; Brauer I, 2000, PHYS REV LETT, V84, P4104, DOI 10.1103/PhysRevLett.84.4104; BREAZEAL W, 1995, PHYS REV E, V52, P1503, DOI 10.1103/PhysRevE.52.1503; BROMLEY JC, 1982, DOBL C APR 20 BOST; BROWN RD, 1965, IEEE T POWER AP SYST, VPA84, P667; Buchalla H, 1995, PROCEEDINGS: ELECTRICAL ELECTRONICS INSULATION CONFERENCE AND ELECTRICAL MANUFACTURING & COIL WINDING CONFERENCE, P613, DOI 10.1109/EEIC.1995.482503; CACCIARI M, 1995, IEE P-SCI MEAS TECH, V142, P102, DOI 10.1049/ip-smt:19951634; Cacciari M, 1995, IEEE T DIELECT EL IN, V2, P1166, DOI 10.1109/94.484322; CACHIN C, 1995, IEEE T DIELECT EL IN, V2, P578, DOI 10.1109/94.407023; CAMPBELL SR, 1994, IEEE T ENERGY CONVER, V9, P281, DOI 10.1109/60.300147; Candela R, 2000, IEEE T DIELECT EL IN, V7, P87, DOI 10.1109/94.839345; Carminati E, 2000, IEEE T DIELECT EL IN, V7, P440, DOI 10.1109/94.848934; Carminati E, 2001, IEEE T INSTRUM MEAS, V50, P1413, DOI 10.1109/19.963218; CHURCH HF, 1972, ELECTRA, V21, P30; *CIGR, 1971, ELECTRA PARIS, P13; COLE HA, 1976, NUCL INSTRUMENTA NOV, P551; Contin A, 2000, IEEE T DIELECT EL IN, V7, P48, DOI 10.1109/94.839341; CONTIN A, 1995, MATER ENG, V6, P345; Contin A, 1998, IEEE T DIELECT EL IN, V5, P110, DOI 10.1109/94.660784; CONTIN A, 1993, IEEE T ELECTR INSUL, V28, P1032; Montanari GC, 2000, IEEE T DIELECT EL IN, V7, P30, DOI 10.1109/94.839338; COSTELLO DA, 1969, IEEE C REC 69 CNPWR, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox E., 1994, FUZZY SYSTEMS HDB; Craggs J.D, 1953, ELECT BREAKDOWN GASE; DAKIN TW, 1979, STP ASTM, V669; DAKIN TW, 1960, AIEE T, V79, P648; DAKIN TW, 1969, IEEE T POWER AP SYST, VPA88, P251, DOI 10.1109/TPAS.1969.292314; DAWES CL, 1926, AIEE T, V45, P141; DENSLEY RJ, 1994, IEEE T POWER DELIVER, V9, P559, DOI 10.1109/61.277729; DEVINS JC, 1984, IEEE T ELECTR INSUL, V19, P475, DOI 10.1109/TEI.1984.298770; DEVINS JC, 1962, C EL INS DIEL PHEN N, P97; Dubois D., 1980, FUZZY SETS SYSTEMS T; Duda R. O., 1973, PATTERN CLASSIFICATI; EAGER GS, 1969, IEEE T POWER AP SYST, VPA88, P342, DOI 10.1109/TPAS.1969.292455; EAGER GS, 1967, IEEE T POWER AP SYST, VPA86, P10, DOI 10.1109/TPAS.1967.291773; EICHHORN RM, 1983, STP ASTM, V783; EIGEN D, 1966, Patent No. 3466537; EMERY FT, 1981, IEEE T POWER AP SYST, V100, P4974, DOI 10.1109/TPAS.1981.316465; EMERY FT, 1980, IEEE T POWER AP SYST, V99, P2232, DOI 10.1109/TPAS.1980.319853; Ficker T, 2001, IEEE T DIELECT EL IN, V8, P220, DOI 10.1109/94.919935; Field F.H., 1957, ELECT IMPACT PHENOME; Forster E. O., 1994, MONOGRAPH ASTM, V3; FORSTER EO, 1993, IEEE T ELECTR INSUL, V28, P941, DOI 10.1109/14.249367; FORSTER EO, 1990, J PHYS D, V23, P1606; FRUTH B, 1994, IEEE INT C PROP APPL, P578; FRUTH B, 1997, 4 VOLT C NOV 12 14 C; FRUTH B, 1989, 6 INT S H V ENG NEW; FRUTH B, 1990, P CIGR PAR; FRUTH B, 1992, IEEE T ELECTR INSUL, V27, P60, DOI 10.1109/14.123441; FRUTH BA, 1996, 1996 IEEE INT S EL I, P397; FRUTH BA, 1994, 1994 IEEE INT S EL I, P296; FUHR J, 1993, IEEE T ELECTR INSUL, V28, P1057, DOI 10.1109/14.249379; GAILHOFER C, 1974, ELECTRA PARIS; GALAND L, 1971, REV G N RALE LECTRIC, V80, P399; Gallant S. I., 1993, NEURAL NETWORK LEARN; GANGER B, 1967, BROWN BOVERI REV, P355; GARCIACOLON VR, 2002, 2002 IEEE INT S EL I, P57; GISH H, 1990, INT CONF ACOUST SPEE, P1361, DOI 10.1109/ICASSP.1990.115636; GOMEZGARCIA M, 1987, IEEE T ELECTR INSUL, V22, P199; GOMEZGARCIA M, 1990, IEEE T ELECTR INSUL, V25, P688; GOODING FH, 1957, AIEE T POWER APPARAT, V16, P999; FRUTH BA, 1995, IEE P-SCI MEAS TECH, V142, P22, DOI 10.1049/ip-smt:19951643; GROSS DW, 2002, 2002 IEEE INT S EL I, P570; GRUNEWALD P, 1994, P CIGR PAR; GULSKI E, 1993, IEEE T ELECTR INSUL, V28, P969, DOI 10.1109/14.249370; GULSKI E, 1993, IEEE T ELECTR INSUL, V28, P984, DOI 10.1109/14.249372; GULSKI E, 1992, IEEE T ELECTR INSUL, V27, P82, DOI 10.1109/14.123443; Gulski E, 2000, IEEE T DIELECT EL IN, V7, P95, DOI 10.1109/94.839346; GULSKI E, 1995, IEEE T DIELECT EL IN, V4, P630; GUPTA MM, 1988, FUZZY LOGIC KNOWLEDG; GUTFLEISCH F, 1995, IEEE T DIELECT EL IN, V2, P729, DOI 10.1109/94.469970; HAESSIG M, 2000, IEEE INT S EL INS AN; HAMPTON BF, 1992, CIGR GEN SESS PAR; HANTOUCHE C, 1992, IEEE INT S EL INS JU, P401; HANTOUCHE C, 1993, IEEE T ELECTR INSUL, V28, P1025, DOI 10.1109/14.249376; HAROLDSEN S, 1968, P CIGR PAR; HARROLD RT, 1970, IEEE T POWER AP SYST, VPA89, P1591, DOI 10.1109/TPAS.1970.292806; HARROLD RT, 1971, IEEE T POWER AP SYST, VPA90, P2339, DOI 10.1109/TPAS.1971.293082; HARROLD RT, 1973, IEEE T POWER AP SYST, VPA92, P187, DOI 10.1109/TPAS.1973.293612; HARROLD RT, 1970, IEEE T POWER AP SYST, VPA89, P1584, DOI 10.1109/TPAS.1970.292805; HARROLD RT, 1979, STP ASTM, V669; HARROLD RT, 1979, IEEE T POWER AP SYST, V98, P444, DOI 10.1109/TPAS.1979.319380; HENNINGSEN CG, 1996, IEEE TRANSM DISTR C; HENRIKSEN M, 1986, IEEE T ENERGY CONVER, V1, P161; HERBST I, 1993, CIGR S BERL; HIKITA M, 1990, IEEE T ELECTR INSUL, V25, P453, DOI 10.1109/14.55716; HOLBOLL JT, 1992, IEEE T S ELECTR INSU, P354; HOUGEN LR, 1960, NATURE, V188, P577, DOI 10.1038/188577a0; HOWELLS E, 1978, IEEE T POWER AP SYST, V97, P1538, DOI 10.1109/TPAS.1978.354646; HOZUMI N, 1992, IEEE T ELECTR INSUL, V27, P550, DOI 10.1109/14.142718; HUCKER T, 1995, IEEE T DIELECT EL IN, V2, P544, DOI 10.1109/94.407020; HUDON C, 1990, 1990 IEEE INT S EL I, P153; Hudon C., 2001, Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference (Cat. No.01CH37264), DOI 10.1109/EEIC.2001.965753; HUDON C, 1991, CEIDP IEEE C REC 91, P237; Hudon C, 1995, IEEE T DIELECT EL IN, V2, P1083, DOI 10.1109/94.484310; Hush DR, 1993, IEEE SIGNAL PROC MAG, V10, P8, DOI 10.1109/79.180705; *ICEA, 1980, ICEA PUBL; *IEC, 1987, IEC PUBL 2, V871; *IEC, 1987, IEC PUBL 1, V871; *IEC, 1996, IEC SPEC 60270; *IEC, 1967, IEC SPEC 70; *IEEE, C571241991 IEEE; *IEEE, 1992, C571131991 IEEE; JAMES RE, 1986, IEEE T ELECTR INSUL, V21, P629, DOI 10.1109/TEI.1986.348968; JAMES RE, 1989, IEEE T ELECTR INSUL, V24, P657, DOI 10.1109/14.34201; Johnson John J S, 1951, AIEE T POWER APPARAT, V70, P1998; Johnson J.S., 1951, AIEE T, V70, P1993; JOHNSON JS, 1951, AIEE T POWER APPARAT, V70, P749; JONES SL, 1990, IEEE INT S EL INS TO, P106, DOI 10.1109/ELINSL.1990.109719; JUDD MD, 1995, IEE P-SCI MEAS TECH, V142, P237, DOI 10.1049/ip-smt:19951699; KATSUTA G, 1992, IEEE T POWER DELIVER, V7, P1068, DOI 10.1109/61.141815; KELEN A, 1995, IEEE T DIELECT EL IN, V2, P529, DOI 10.1109/94.407018; KELEN A, 1995, IEEE T DIELECT EL IN, V2, P780, DOI 10.1109/94.469975; KELEN A, 1976, P CIGR PAR; KELLEY EF, 1989, IEEE T ELECTR INSUL, V24, P1109, DOI 10.1109/14.46345; KIM YJ, 2002, 2002 IEEE INT S EL I, P5; KIM YJ, 1992, IEEE T ELECTR INSUL, V27, P1026, DOI 10.1109/14.256478; KITAMURA Y, 1985, IEEE C ELECTR INSUL, P485; KNAPP CH, 1990, IEEE T POWER DELIVER, V5, P859, DOI 10.1109/61.53094; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1988, SELF ORG ASS MEMORY; KONIG D, 1972, P CIGR, V1, P74; Kranz HG, 2000, IEEE T DIELECT EL IN, V7, P12, DOI 10.1109/94.839336; KRANZ HG, 1993, IEEE T ELECTR INSUL, V28, P1016, DOI 10.1109/14.249375; KRANZ HG, 1992, IEEE T ELECTR INSUL, V27, P93, DOI 10.1109/14.123444; KRIVDA A, 1995, IEEE T DIELECT EL IN, V2, P889, DOI 10.1109/94.469983; KRIVDA A, 1995, IEEE T DIELECT EL IN, V2, P796, DOI 10.1109/94.469976; Kung SY, 1993, DIGITAL NEURAL NETWO; KURRER R, 1994, GASEOUS DIELECTRICS, V7, P557; KURTZ M, 1980, P CIGR PAR; Kurtz M., 1973, ONTARIO HYDRO RES Q, V25, P1; KURTZ M, 1979, IEEE T POWER AP SYST, V98, P1596, DOI 10.1109/TPAS.1979.319475; KURTZ M, 1978, 1978 IEEE INT S EL I, P73; Lalitha EM, 2000, IEEE T DIELECT EL IN, V7, P40, DOI 10.1109/94.839339; Lemke E., 1976, Elektrie, V30; LESAINT O, 1991, IEEE T ELECTR INSUL, V26, P941; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; Lloyd BA, 1999, IEEE T ENERGY CONVER, V14, P1131, DOI 10.1109/60.815038; LUNDGAARD LE, 1990, IEEE T POWER DELIVER, V5, P1751, DOI 10.1109/61.103670; LYLES JF, 1988, IEEE T ENERGY CONVER, V3, P824, DOI 10.1109/60.9358; Mandelbrot B., 1983, FRACTAL GEOMETRY NAT; MASHIKIAN MS, 1994, IEEE T POWER DELIVER, V9, P620, DOI 10.1109/61.296237; MASHIKIAN MS, 1992, IEEE T ELECTR INSUL, V27, P37, DOI 10.1109/14.123439; MASON JH, 1951, P I ELECTR ENG, V98, P44; MAYOUX C, 1995, IEEE T DIELECT EL IN, V2, P641; MAYOUX C, 1973, J APPL PHYS, V44, P3940, DOI 10.1063/1.1662876; MAYOUX C, 1977, IEEE T ELECTR INSUL, V12, P153, DOI 10.1109/TEI.1977.297969; MAYOUX CJ, 1976, IEEE T ELECTR INSUL, V11, P139, DOI 10.1109/TEI.1976.297921; MAZROUA AA, 1995, IEEE T POWER DELIVER, V10, P92, DOI 10.1109/61.368411; MAZROUA AA, 1994, IEEE T DIELECT EL IN, V1, P1119, DOI 10.1109/94.368651; MAZROUA AA, 1993, IEEE T ELECTR INSUL, V28, P1082, DOI 10.1109/14.249382; MAZZETTI C, 1992, IEEE T ELECTR INSUL, V27, P445, DOI 10.1109/14.142705; MCMAHON EJ, 1959, AIEE T COMMUNICATI 1, V78, P654; MEGAHED IY, 1975, IEEE T ELECTR INSUL, VEI10, P69, DOI 10.1109/TEI.1975.297865; Meijer S, 1998, IEEE T DIELECT EL IN, V5, P830, DOI 10.1109/94.740764; MENDEL JM, 1995, P IEEE, V83, P245; MILLER R, 1979, IEEE T ELECTR INSUL, V12, P127; MING Y, 2002, 2002 IEEE INT S EL I, P9; Miralai S. F., 2000, PLASMAS POLYM, V5, P63, DOI 10.1023/A:1009531831404; MIRALAI SF, 2000, LOW TEMPERATURE PLAS, V1, P33; MONNETTE E, 1999, P 14 INT S PLASM CHE, V1, P991; MORHUIS PHF, 1995, P IEE SCI MEASUREMEN, V142, P62; MORIN R, 1999, P IEEE TRANSM DISTR; Morin R, 2000, IEEE T ENERGY CONVER, V15, P149, DOI 10.1109/60.866992; MORIN R, 1991, IEEE TRANSM DISTR C; MORSHUIS P, 1995, IEEE T DIELECT EL IN, V2, P744, DOI 10.1109/94.469971; MORSHUIS PHF, 1990, J PHYS D APPL PHYS, V23, P1562, DOI 10.1088/0022-3727/23/12/012; Nakanishi Y., 1993, Electrical Engineering in Japan, V113, DOI 10.1002/eej.4391130806; Narbut P., 1965, IEEE Transactions on Power Apparatus and Systems, VPAS-84; *NEMA, 1071964R1971 NEMA; NIEMEYER L, 1995, IEEE T DIELECT EL IN, V2, P510, DOI 10.1109/94.407017; Nikonov V, 2001, IEEE T PLASMA SCI, V29, P866, DOI 10.1109/27.974972; Nikonov V, 2001, J PHYS D APPL PHYS, V34, P2979, DOI 10.1088/0022-3727/34/19/308; NOVAK JP, 1995, IEEE T DIELECT EL IN, V2, P724, DOI 10.1109/94.469969; NOVAK JP, 1990, IEEE T PLASMA SCI, V18, P775, DOI 10.1109/27.62342; NOVAK JP, 1988, J APPL PHYS, V64, P1767, DOI 10.1063/1.341773; NOVAK JP, 1988, J PHYS D APPL PHYS, V21, P896, DOI 10.1088/0022-3727/21/6/006; NOVAK JP, 1991, IEEE T PLASMA SCI, V19, P95, DOI 10.1109/27.106802; Novak JP, 2000, IEEE T DIELECT EL IN, V7, P146, DOI 10.1109/94.839353; NOVAK JP, 1987, J APPL PHYS, V62, P3605, DOI 10.1063/1.339263; OKAMOTO T, 1986, IEEE T ELECTR INSUL, V21, P1015, DOI 10.1109/TEI.1986.349017; OLIVER BM, 1954, P IRE I RADIO EN MTT, V2, P1686; ORCHARD RA, 1995, NRCERB1015; OSVATH P, 1995, IEEE T DIELECT EL IN, V2, P685, DOI 10.1109/94.407033; PALMER AJ, 1974, APPL PHYS LETT, V25, P138, DOI 10.1063/1.1655412; PEARSON JS, 1991, IEEE T ELECTR INSUL, V26, P469, DOI 10.1109/14.85119; POMPILI M, 1995, IEEE T DIELECT EL IN, V2, P602, DOI 10.1109/94.407025; Pompili M, 1998, IEEE T DIELECT EL IN, V5, P402, DOI 10.1109/94.689430; Pompili M, 2000, IEEE T DIELECT EL IN, V7, P113, DOI 10.1109/94.839348; Pompili M, 2002, IEEE T DIELECT EL IN, V9, P104, DOI 10.1109/94.983893; POVEY EH, 1979, STP ASTM, V669; PULTRUM E, 1995, P JICABLE, P662; QUINN GE, 1940, AIEE T, V59, P709; RADU I, 2002, P INT C HIGH PRESS L; Raether H., 1964, ELECT AVALANCHES BRE; Rayner E.H., 1912, Journal of the Institution of Electrical Engineers, V49; REYNOLDS EH, 1958, C EL INS DIEL PHEN N; Robinson D.M., 1935, Journal of the Institution of Electrical Engineers, V77; ROBINSON DM, 1936, DIELECTRIC PHENOMENA; ROTH A, 1927, HOCHSPANGSTECHNIK; ROWNTREE P, 1991, J PHYS CHEM-US, V95, P4902, DOI 10.1021/j100165a054; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salama MMA, 2002, IEEE T NEURAL NETWOR, V13, P446, DOI 10.1109/72.991430; Salama MMA, 2000, IEEE T DIELECT EL IN, V7, P118, DOI 10.1109/94.839349; SANCHE L, 1993, IEEE T ELECTR INSUL, V28, P789, DOI 10.1109/14.237742; SATISH L, 1995, IEEE T DIELECT EL IN, V2, P352, DOI 10.1109/94.395421; SCHERING H, 1924, ISOLIERSTOFFE ELEKTR; SEDDING HG, 1991, IEEE T ENERGY CONVER, V6, P700, DOI 10.1109/60.103644; Simpson P. K., 1990, ARTIFICIAL NEURAL SY; SMITH LE, 1970, 37 ANN INT C DOBL CL; STARR WT, 1956, Patent No. 2750562; Steel Z, 1996, J Gambl Stud, V12, P3, DOI 10.1007/BF01533186; STEINER JP, 1992, IEEE T ELECTR INSUL, V27, P44, DOI 10.1109/14.123440; Stone G. C., 1995, IEEE Transactions on Dielectrics and Electrical Insulation, V2, DOI 10.1109/94.407027; Stone G, 2000, IEEE T DIELECT EL IN, V7, P6, DOI 10.1109/94.839335; STONE GC, 1995, IEEE T DIELECT EL IN, V2, P567, DOI 10.1109/94.407022; STONE GC, 1992, IEEE T ELECTR INSUL, V27, P70, DOI 10.1109/14.123442; STONGE H, 1978, EL938 EPRI; SUZUKI H, 1992, IEEE T ELECTR INSUL, V27, P543, DOI 10.1109/14.142717; Tangen K.O., 1964, Elektrotechnische Zeitschrift. Ausgabe A: Zentralblatt fur Elektrotechnik, V85; THEONG AT, 1968, P CIGR PAR; THOENG AT, 1973, C PUBL 1, V94; TIMPERLEY JE, 1989, PROCEEDINGS OF THE 19TH ELECTRICAL ELECTRONICS INSULATION CONFERENCE, P300, DOI 10.1109/EEIC.1989.208246; TIMPERLEY JE, 1983, IEEE T POWER AP SYST, V102, P693, DOI 10.1109/TPAS.1983.318030; TRAIN D, 1974, IEEE T POWER AP SYST, VPA93, P1909, DOI 10.1109/TPAS.1974.293843; TYKOCINER JT, 1933, U ILLINOIS B, V49; TYKOCINER JT, 1933, U ILLINOIS B, V50; VAILLANCOURT GH, 1985, IEEE T POWER AP SYST, V104, P900, DOI 10.1109/TPAS.1985.319091; van Breen HJ, 2002, IEEE T DIELECT EL IN, V9, P140, DOI 10.1109/94.983898; VANBRUNT RJ, 1991, IEEE T ELECTR INSUL, V26, P902, DOI 10.1109/14.99099; VANBRUNT RJ, 1993, IEEE T ELECTR INSUL, V28, P905, DOI 10.1109/14.249364; VONGLAHN P, 1995, IEEE T DIELECT EL IN, V2, P590, DOI 10.1109/94.407024; VORA JP, 1965, IEEE T POWER AP SYST, VPA84, P707; VOSS RE, 1985, SEALING PHENOMENA DI; WAGNER H, 1977, IEEE T ELECTR INSUL, V12, P395, DOI 10.1109/TEI.1977.297990; WARD BH, 1992, IEEE T POWER DELIVER, V7, P469; Watson PK, 1998, IEEE T DIELECT EL IN, V5, P344, DOI 10.1109/94.689423; WEEKS WL, 1982, IEEE T POWER AP SYST, V101, P2328, DOI 10.1109/TPAS.1982.317461; WERLE P, 2002, 2002 IEEE INT S EL I, P166; WERTHEIMER MR, NATO APPL SCI SERIES; Whitehead S., 1953, DIELECTRIC BREAKDOWN; WICHMANN A, 1987, CIGR S 05 87 VIENN; WILSON A, 1991, P IEE A, V138, P153; WOLTER KD, 1987, STP ASTM, V926; Zondervan JP, 2000, IEEE T DIELECT EL IN, V7, P59, DOI 10.1109/94.839342	308	127	148	9	33	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1070-9878			IEEE T DIELECT EL IN	IEEE Trns. Dielectr. Electr. Insul.	OCT	2002	9	5					763	808		10.1109/TDEI.2002.1038663		46	Engineering, Electrical & Electronic; Physics, Applied	Engineering; Physics	609KB	WOS:000178901200023		
J	Wu, YQ; Ianakiev, K; Govindaraju, V				Wu, YQ; Ianakiev, K; Govindaraju, V			Improved k-nearest neighbor classification	PATTERN RECOGNITION			English	Article						k-nearest neighbor classification; pattern classification; classifier; template condensing; preprocessing		k-nearest neighbor (k-NN) classification is a well-known decision rule that is widely used in pattern classification. However, the traditional implementation of this method is computationally expensive. In this paper we develop two effective techniques, namely, template condensing and preprocessing, to significantly speed up k-NN classification while maintaining the level of accuracy. Our template condensing technique aims at "sparsifying" dense homogeneous clusters of prototypes of any single class. This is implemented by iteratively eliminating patterns which exhibit high attractive capacities. Our preprocessing technique filters a large portion of prototypes which are unlikely to match against the unknown pattern. This again accelerates the classification procedure considerably, especially in cases where the dimensionality of the feature space is high. One of our case studies shows that the incorporation of these two techniques to k-NN rule achieves a seven-fold speed-up without sacrificing accuracy. CD 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	SUNY Buffalo, Ctr Excellence Pattern Anal & Recognit, Buffalo, NY 14228 USA	Wu, YQ (reprint author), Univ Illinois, Comp & Syst Res Lab 139, 1308 W Main St, Urbana, IL 61801 USA.						BELKASIM SO, 1992, PATTERN RECOGN, V25, P1269, DOI 10.1016/0031-3203(92)90028-H; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; DUDANI SA, 1991, DISTANCE WEIGHTED K, P92; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SRIKANTAN G, 1994, THESIS STATE U NEW Y; Srikantan G, 1996, PATTERN RECOGN, V29, P1147, DOI 10.1016/0031-3203(95)00146-8	14	42	45	1	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	OCT	2002	35	10					2311	2318	PII S0031-3203(01)00132-7	10.1016/S0031-3203(01)00132-7		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	583FR	WOS:000177396500024		
J	Hofmann, WK; de Vos, S; Komor, M; Hoelzer, D; Wachsman, W; Koeffler, HP				Hofmann, WK; de Vos, S; Komor, M; Hoelzer, D; Wachsman, W; Koeffler, HP			Characterization of gene expression of CD34(+) cells from normal and myelodysplastic bone marrow	BLOOD			English	Article							MICROARRAY ANALYSIS; APOPTOSIS; IDENTIFICATION; DIFFERENTIATION; CLASSIFICATION; PROLIFERATION; HEMATOPOIESIS; ACTIVATION; RESISTANCE; ONCOGENE	Gene patterns of expression in purified CD34(+) bone marrow cells from 7 patients with low-risk myelodysplastic syndrome (MDS) and 4 patients with high-risk MDS were compared with expression data from CD34+ bone marrow cells from 4 healthy control subjects. CD34 cells were isolated by magnetic cell separation, and high-density oligonucleotide microarray analysis was performed. For confirmation, the expression of selected genes was analyzed by real-time polymerase chain reaction. Class membership prediction analysis selected 11 genes. Using the expression profile of these genes, we were able to discriminate patients with low-risk from patients with high-risk MDS and both patient groups from the control group by hierarchical clustering (Spearman confidence). The power of these 11 genes was verified by applying the algorithm to an unknown test set containing expression data from 8 additional patients with MDS (3 at low risk, 5 at high risk). Patients at low risk could be distinguished from those at high risk by clustering analysis. In low-risk MDS, we found that the retinoic-acid-induced gene (RAI3), the radiation-inducible, immediate-early response gene (IEX1), and the stress-induced phosphoprotein 1 (STIP1) were down-regulated. These data suggest that CD34(+) cells from patients with low-risk MDS lack defensive proteins, resulting in their susceptibility to cell damage. In summary, we propose that gene expression profiling may have clinical relevance for risk evaluation in MDS at the time of initial diagnosis. Furthermore, this study provides evidence that in MDS, hematopoietic stem cells accumulate defects that prevent normal hematopoiesis.	Univ Hosp, Dept Hematol Oncol, D-60596 Frankfurt, Germany; Cedars Sinai Res Inst, Div Hematol Oncol, Los Angeles, CA USA; Univ Calif Los Angeles, Sch Med, Dept Pathol, Los Angeles, CA 90024 USA; VASDHS, Res Serv, San Diego, CA USA; Univ Calif San Diego, Sch Med, Div Hematol Oncol, La Jolla, CA 92093 USA; Univ Calif San Diego, Sch Med, Ctr Canc, La Jolla, CA 92093 USA	Hofmann, WK (reprint author), Univ Hosp, Dept Hematol, Theodor Stern Kai 7, D-60596 Frankfurt, Germany.						Bennett JM, 2000, INT J HEMATOL, V72, P131; Bulyk ML, 2001, P NATL ACAD SCI USA, V98, P7158, DOI 10.1073/pnas.111163698; Bustin SA, 2000, J MOL ENDOCRINOL, V25, P169, DOI 10.1677/jme.0.0250169; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeRisi J, 2000, FEBS LETT, V470, P156, DOI 10.1016/S0014-5793(00)01294-1; De Vos J, 2001, BLOOD, V98, P771, DOI 10.1182/blood.V98.3.771; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Greenberg P, 1997, BLOOD, V89, P2079; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hofmann WK, 1999, EXP HEMATOL, V27, P395, DOI 10.1016/S0301-472X(98)00077-0; Hofmann WK, 2001, BLOOD, V98, P787, DOI 10.1182/blood.V98.3.787; Kalina U, 2000, EXP HEMATOL, V28, P1158, DOI 10.1016/S0301-472X(00)00527-0; Kaminski N, 2000, P NATL ACAD SCI USA, V97, P1778, DOI 10.1073/pnas.97.4.1778; Khan J, 1999, P NATL ACAD SCI USA, V96, P13264, DOI 10.1073/pnas.96.23.13264; Kitagawa M, 1997, LEUKEMIA, V11, P2049, DOI 10.1038/sj.leu.2400844; Kondratyev AD, 1996, CANCER RES, V56, P1498; Lee YT, 2001, BLOOD, V98, P1914, DOI 10.1182/blood.V98.6.1914; Miyazato A, 2001, BLOOD, V98, P422, DOI 10.1182/blood.V98.2.422; Neiman PE, 2001, P NATL ACAD SCI USA, V98, P6378, DOI 10.1073/pnas.111144898; Novitzky N, 2000, EXP HEMATOL, V28, P941, DOI 10.1016/S0301-472X(00)00489-6; Parker JE, 2000, BLOOD, V96, P3932; Parker JE, 1998, BRIT J HAEMATOL, V101, P220; Peters UR, 1999, CANCER RES, V59, P4233; Preisler HD, 2001, LEUKEMIA, V15, P1589, DOI 10.1038/sj.leu.2402211; Schmidt JV, 2000, GENE DEV, V14, P1997; Shetty V, 2000, BLOOD, V96, P1388; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Voehringer DW, 2000, P NATL ACAD SCI USA, V97, P2680, DOI 10.1073/pnas.97.6.2680; Wu MX, 1998, SCIENCE, V281, P998, DOI 10.1126/science.281.5379.998; Zhao RB, 2000, GENE DEV, V14, P981	31	146	155	0	3	AMER SOC HEMATOLOGY	WASHINGTON	1900 M STREET. NW SUITE 200, WASHINGTON, DC 20036 USA	0006-4971			BLOOD	Blood	NOV 15	2002	100	10					3553	3560		10.1182/blood.V100.10.3553		8	Hematology	Hematology	613YE	WOS:000179158500017	12411319	
J	Chien, JT; Wu, CC				Chien, JT; Wu, CC			Discriminant waveletfaces and nearest feature classifiers for face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						discriminant waveletface; nearest feature classifier; face recognition	CLASSIFICATION	Feature extraction, discriminant analysis, and classification rule are three crucial issues for face recognition. This paper presents hybrid approaches to handle three issues together. For feature extraction, we apply the multiresolution wavelet transform to extract waveletface. We also perform the linear discriminant analysis on waveletfaces to reinforce discriminant power. During classification, the nearest feature plane (NFP) and nearest feature space (NFS) classifiers are explored for robust decision in presence of wide facial variations. Their relationships to conventional nearest neighbor and nearest feature line classifiers are demonstrated. In the experiments, the discriminant waveletface incorporated with the NFS classifier achieves the best face recognition performance.	Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan	Chien, JT (reprint author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.	jtchien@mail.ncku.edu.tw					Averbuch Amir, 1996, IEEE T IMAGE PROCESS, V5; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; CHENG Y, 1991, SPIE P INTELLIGENT R, V10, P85; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Etemad K., 1996, P INT C AC SPEECH SI, P2148; Fisher RA, 1938, ANN EUGENIC, V8, P376; Foltyniewicz R., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.546715; Fukunaga K., 1990, INTRO STAT PATTERN R; GOLDSTEI.AJ, 1971, PR INST ELECTR ELECT, V59, P748, DOI 10.1109/PROC.1971.8254; KOUZANI AZ, 1997, P IEEE C SYST MAN CY, P1614; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Lin SH, 1997, IEEE T NEURAL NETWOR, V8, P114; LIU C, 2000, P INT C PATTERN RECO, V1, P249; Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Nefian AV, 1998, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.1998.678085; Rao R. M., 1998, WAVELET TRANSFORMS I; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Zhang J, 1997, P IEEE, V85, P1423	22	222	251	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1644	1649				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	618YA	WOS:000179444600008		
J	Achiron, A; Gicquel, S; Miron, S; Faibel, M				Achiron, A; Gicquel, S; Miron, S; Faibel, M			Brain MRI lesion load quantification in multiple sclerosis: A comparison between automated multispectral and semi-automated thresholding computer-assisted techniques	MAGNETIC RESONANCE IMAGING			English	Article						MRI; multiple sclerosis; lesions; quantification	VOLUME MEASUREMENTS; SEGMENTATION; IMAGES; INTRAOBSERVER; INTEROBSERVER	Brain magnetic resonance imaging (MRI) lesion volume measurement is an advantageous tool for assessing disease burden in multiple sclerosis (MS). We have evaluated two computer-assisted techniques: MSA multispectral automatic technique that is based on bayesian classification of brain tissue and NIH image analysis technique that is based on local (lesion by lesion) thresholding, to establish reliability and repeatability values for each technique. Brain MRIs were obtained for 30 clinically definite relapsing-remitting MS patients using a 2.0 Tesla MR scanner with contiguous, 3 mm thick axial, T1, T2 and PD weighted modalities. Digital (Dicom 3) images were analyzed independently by three observers; each analyzed the images twice, using the two different techniques (Total 360 analyses). Accuracy of lesion load measurements using phantom images of known volumes showed significantly better results for the MSA multispectral technique (p < 0.001). The mean intra-and inter-observer variances were, respectively, 0.04 +/- 0.4 (range 0.04-0.13), and 0.09 +/- 0.6 (range 0.01-0.26) for the multispectral MSA analysis technique, 0.24 +/- 2.27 (range 0.23-0.72) and 0.33 +/- 3.8 (range 0.47-1.36) for the NIH threshold technique. These data show that the MSA multispectral technique is significantly more accurate in lesion volume measurements, with better results of within and between observers' assessments, and the lesion load measurements are not influenced by increased disease burden. Measurements by the MSA multispectral technique were also faster and decreased analysis time by 43%. The MSA multispectral technique is a promising tool for evaluating MS patients. Non-biased recognition and delineation algorithms enable high accuracy, low intra-and inter-observer variances and fast assessment of MS related lesion load. (C) 2002 Elsevier Science Inc. All rights reserved.	Chaim Sheba Med Ctr, Multiple Sclerosis Ctr, IL-52621 Tel Hashomer, Israel; Chaim Sheba Med Ctr, Neuroradiol Unit, IL-52621 Tel Hashomer, Israel	Achiron, A (reprint author), Chaim Sheba Med Ctr, Multiple Sclerosis Ctr, IL-52621 Tel Hashomer, Israel.						ARDEKANI BA, 1994, J COMPUT ASSIST TOMO, V18, P963, DOI 10.1097/00004728-199411000-00022; Atkins MS, 1998, IEEE T MED IMAGING, V17, P98, DOI 10.1109/42.668699; Bobroff S, 1999, MAGN RESON IMAGING, V17, P783, DOI 10.1016/S0730-725X(99)00010-7; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; COLLINS DL, 1994, J COMPUT ASSIST TOMO, V18, P192; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ege BM, 2000, COMPUT METH PROG BIO, V62, P165, DOI 10.1016/S0169-2607(00)00065-1; Filippi M, 1995, BRAIN, V118, P1593, DOI 10.1093/brain/118.6.1593; Filippi M, 1995, BRAIN, V118, P1601, DOI 10.1093/brain/118.6.1601; Gasperini C, 2001, MULT SCLER, V7, P27, DOI 10.1191/135245801672817145; GONZALEZ CF, 1994, J NEUROIMAGING, V4, P188; Grimaud J, 1996, MAGN RESON IMAGING, V14, P495, DOI 10.1016/0730-725X(96)00018-5; Francis G, 2001, NEUROLOGY, V56, P1628; Johnston B, 1996, IEEE T MED IMAGING, V15, P154, DOI 10.1109/42.491417; KAMBER M, 1995, IEEE T MED IMAGING, V14, P442, DOI 10.1109/42.414608; Lampinen J, 2001, NEURAL NETWORKS, V14, P257, DOI 10.1016/S0893-6080(00)00098-8; LI SZ, 1994, MAGN RESON IMAGING, V12, P1079, DOI 10.1016/0730-725X(94)91240-W; Miller DH, 1998, BRAIN, V121, P3, DOI 10.1093/brain/121.1.3; MITCHELL JR, 1994, JMRI-J MAGN RESON IM, V4, P197, DOI 10.1002/jmri.1880040218; Molyneux PD, 1998, J NEUROL NEUROSUR PS, V65, P42, DOI 10.1136/jnnp.65.1.42; PANNIZZO F, 1992, MAGNET RESON MED, V24, P90, DOI 10.1002/mrm.1910240110; PATY DW, 1993, NEUROLOGY, V43, P662; POSER CM, 1983, ANN NEUROL, V13, P227, DOI 10.1002/ana.410130302; Press W. H., 1994, NUMERICAL RECIPES C; SANDOR T, 1991, INT J BIOMED COMPUT, V29, P133, DOI 10.1016/0020-7101(91)90004-X; Simon JH, 1997, AM J NEURORADIOL, V18, P580; SUZUKI H, 1991, COMPUT MED IMAG GRAP, V15, P233, DOI 10.1016/0895-6111(91)90081-6; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; Van Leemput K, 2001, IEEE T MED IMAGING, V20, P677, DOI 10.1109/42.938237; Vinitski S, 1997, MAGNET RESON MED, V37, P457, DOI 10.1002/mrm.1910370325; WICKS DAG, 1992, NEURORADIOLOGY, V34, P475; Zijdenbos Alex P., 1994, Critical Reviews in Biomedical Engineering, V22, P401	32	20	21	1	3	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0730-725X			MAGN RESON IMAGING	Magn. Reson. Imaging	DEC	2002	20	10					713	720	PII S0730-725X(02)00606-9	10.1016/S0730-725X(02)00606-9		8	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	648NK	WOS:000181157300003	12591567	
S	Sanz, PJ; Marin, R; Sanchez, JS			IEEE; IEEE	Sanz, PJ; Marin, R; Sanchez, JS			Fast object recognition methods for the UJI online robot	2003 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, CONFERENCE PROCEEDINGS	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics (SMC 03)	OCT 05-08, 2003	WASHINGTON, D.C.	IEEE, Syst, Man & Cybernet Soc		object recognition; online robots; neural networks		Within the context of online robots, a considerable amount of research has traditionally focused on the global system functionality, including the way of interaction between the user and the robot. Recent results in different robotics areas have demonstrated the potential of a number of techniques from the Pattern Recognition and Machine Learning domains, although very few work has been specifically addressed to online robots, where the object recognition is directly performed by the user. In this paper, we investigate the feasibility of using a neural network approach to object recognition in the context of online robots, and discuss the main advantages over the application of statistical learning methods. Some experiments with the UJI (Universitat Jaume I) online robot evaluate the performance of different neural network implementations, comparing it to that of some distance-based object recognition algorithms.	Jaume I Univ, Dept Comp Sci, Castellon de La Plana, Spain	Sanz, PJ (reprint author), Jaume I Univ, Dept Comp Sci, Castellon de La Plana, Spain.	sanzp@ieee.org; rmarin@icc.uji.es; sanchez@uji.es	Marin, Raul/B-4704-2008; 	Marin, Raul/0000-0002-2340-4126; Sanchez Garreta, Jose Salvador/0000-0003-1053-4658			Baruch J. E. F., 1994, P 2 INT C WORLD WID; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1990, NEAREST NEIGHBOUR NN; Duda R. O., 1973, PATTERN CLASSIFICATI; FERWORN A, 1999, P IASTED C ROB APPL, P158; Goldberg K., 1995, P ACM SIGGRAPH, P135; GOLDBERG K, 1995, IEEE INT CONF ROBOT, P654, DOI 10.1109/ROBOT.1995.525358; GOLDBERG S, 1998, IROS 98 WORKSH WEB R, P55; Holmstrom L, 1997, IEEE T NEURAL NETWOR, V8, P5, DOI 10.1109/72.554187; HU M, 1962, IRE T INFORM THEOR, V8, P179; Marin R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013644; Marin R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013643; MCKEE GT, 1996, ROBOTICS MACHINE PER, V5; PAULO E, 1996, P IEEE INT C ROB AUT, P1250; Preece J., 1994, HUMAN COMPUTER INTER; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Saucy P, 2000, IEEE ROBOT AUTOM MAG, V7, P41, DOI 10.1109/100.833574; Schalkoff R.J., 1992, PATTERN RECOGNITION; Schulz D, 2000, IEEE ROBOT AUTOM MAG, V7, P48, DOI 10.1109/100.833575; SIMMONS R, 1998, P IROS 98 WORKSH WEB, P43	21	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		0-7803-7952-7	IEEE SYS MAN CYBERN			2003							2791	2796				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Robotics	Automation & Control Systems; Computer Science; Robotics	BX83D	WOS:000186578600456		
B	Chang, F; Lin, CC; Lin, WH			IEEE	Chang, F; Lin, CC; Lin, WH			A two-stage classification method for vector pattern matching problems	2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	NOV 02-05, 2003	Xian, PEOPLES R CHINA	IEEE Syst, Man & Cybernet Tech Comm Cybernet, Hebei Univ, NW Polytech Univ		disambiguation; learning mechanism; nearest neighbor; support vector machines; template; vector; pattern matching		In this paper, we propose a new method to classify unknown objects into a large number of possible patterns (classes) and thereby solve vector-matching problems. The core of this method is a learning mechanism that reduces a huge amount of training samples into a highly condensed set of templates. When used in a testing process, these templates hold target patterns within the nearest K templates for almost all unknown objects, where K is a small number (2 or 3, for example). This learning mechanism also produces an extremely small set of confusing pairs, in opposition to all N(N-1)/2 possible pairs, where N is the total number of patterns. These pairs are further processed by a disambiguation procedure that improves the overall performance of the pattern classifier. This learning method thus suggests a two-stage online process for classifying unknown objects. The first stage reduces the number of possible candidates to a few candidates and the second stage identifies the target patterns out of these candidates.	Acad Sinica, Inst Informat Sci, Taipei, Taiwan	Chang, F (reprint author), Acad Sinica, Inst Informat Sci, Taipei, Taiwan.						Burges C. J. C., 1998, KNOWLEDGE DISCOVERY, V2; Chang C.-C., LIBSVM LIB SUPPORT V; CHANG F, UNPUB IEEE T PATTERN; Cherkassky V., 1998, LEARNING DATA; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; HSU CW, 2000, IEEE T NEURAL NETWOR, V13, P415; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; Reilly DL, 1990, INTRO NEURAL ELECT N; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Vapnik V. N., 1995, NATURE STAT LEARNING	12	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7865-2				2003							3022	3027				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BY61C	WOS:000189420700605		
B	Wang, Z; Hu, WD; Yu, WX			IEEE	Wang, Z; Hu, WD; Yu, WX			A quick evidential classification algorithm based on K-nearest neighbor rule	2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	NOV 02-05, 2003	Xian, PEOPLES R CHINA	IEEE Syst, Man & Cybernet Tech Comm Cybernet, Hebei Univ, NW Polytech Univ		theory of evidence; testing of evidence consistency; conflict among evidences; k-nearest neighbor rule; quick evidential classification algorithm; superball searching		Under the frame of Dempster-Shafer theory of evidence, a distance function to depict comparability between evidences is constructed according to the conflict among evidences, which is for the case that the origin of few evidences is uncertain. In order to conquer these disadvantages of traditional quick k-nearest neighbor(k-NN) classification algorithm, this paper proposes a quick k-NN evidence classification algorithm-super-ball search evidence classification(ab. S-BSEC) algorithm based on near neighbor searching. Simulation results show that this method is superior to the traditional k-NN algorithm in terms of the recognition speed under the same recognition rate and k, and super-ball algorithm is not sensitive to searching order of training sample.	Natl Univ Def Technol, ATR State Key Lab, Changsha 410073, Peoples R China	Wang, Z (reprint author), Natl Univ Def Technol, ATR State Key Lab, Changsha 410073, Peoples R China.						BIAN Z, 1988, PATTERN RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1991, NEAREST NEIGHBOR NOR; HE You, 2000, MULTISENSOR INFORMAT; Llinas J., 1990, MULTISENSOR DATA FUS; LOWRANCE JD, 1983, 307 SRI INT ART INT; THIERRY D, 1995, IEEE T SYST MAN CYB, V25, P804; WANG FL, 1983, FDN PATTERN RECOGNIT; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	9	0	0	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7865-2				2003							3248	3252				5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BY61C	WOS:000189420700650		
B	Droettboom, M		Marshall, CC; Henry, G; Delcambre, L		Droettboom, M			Correcting broken characters in the recognition of historical printed documents	2003 JOINT CONFERENCE ON DIGITAL LIBRARIES, PROCEEDINGS			English	Proceedings Paper	Joint Conference on Digital Libraries	MAY 27-31, 2003	HOUSTON, TX	IEEE TC Digital Lib, ACM SIGIR, ACM SIGWEB, Coalit Networked Informat, DELOS, Amer Soc Informat Sci & Technol	RICE UNIV			This paper presents a new technique for dealing with broken characters, one of the major challenges in the optical character recognition (OCR) of degraded historical printed documents. A technique based on graph combinatorics is used to rejoin the appropriate connected components. It has been applied to real data with successful results.	Johns Hopkins Univ, Digital Knowledge Ctr, Baltimore, MD 21218 USA	Droettboom, M (reprint author), Johns Hopkins Univ, Digital Knowledge Ctr, 3400 N Charles St, Baltimore, MD 21218 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Droettboom M., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries; FUJINAGA I, 1991, INT COMP MUSIC C, P66; HARDING SM, 1997, EUR C DIG LIB, P345; Kass M., 1987, INT C COMP VIS, P259; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; 1799, STAT ACCOUNTS SCOTLA	7	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1939-3				2003							364	366		10.1109/JCDL.2003.1204889		3	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	BW95C	WOS:000183728000051		
B	Marsi, E; Reynaert, M; van den Bosch, A; Daelemans, W; Hoste, V			ACL	Marsi, E; Reynaert, M; van den Bosch, A; Daelemans, W; Hoste, V			Learning to predict pitch accents and prosodic boundaries in Dutch	41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE			English	Proceedings Paper	41st Annual Meeting of the Association-for-Computational-Linguistics	JUL 07-12, 2003	Sapporo, JAPAN	Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR			LANGUAGE	We train a decision tree inducer (CART) and a memory-based classifier (MBL) on predicting prosodic pitch accents and breaks in Dutch text, on the basis of shallow, easy-to-compute features. We train the algorithms on both tasks individually and on the two tasks simultaneously. The parameters of both algorithms and the selection of features are optimized per task with iterative deepening, an efficient wrapper procedure that uses progressive sampling of training data. Results show a consistent significant advantage of MBL over CART, and also indicate that task combination can be done at the cost of little generalization score loss. Tests on cross-validated data and on held-out data yield F-scores of MBL on accent placement of 84 and 87, respectively, and on breaks of 88 and 91, respectively. Accent placement is shown to outperform an informed baseline rule; reliably predicting breaks other than those already indicated by intra-sentential punctuation, however, appears to be more challenging.	Tilburg Univ, ILK Computat Linguist & AI, NL-5000 LE Tilburg, Netherlands			van den Bosch, Antal/G-5072-2011; Daelemans, Walter/N-5785-2014	van den Bosch, Antal/0000-0003-2493-656X; 			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BLACK AW, 1995, P SPRING M ACOUSTIC; Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cutler A, 1997, LANG SPEECH, V40, P141; DAELEMANS W, 2002, ILK02010 ILK TILB U; Daelemans W., 1996, P 4 WORKSH VER LARG, P14; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Daelemans W., 2002, P 3 INT C LANG RES E, P755; FIX, 1981, 4 USAF SCH AV MED; HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C; Koehn P, 2000, INT CONF ACOUST SPEE, P1289, DOI 10.1109/ICASSP.2000.861813; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Ladd D.R., 1996, INTONATIONAL PHONOLO; MARSI GJ, 2002, P INT C SPOK LANG PR, P1273; PAN, 2000, P 35 ANN M ASS COMP; Pan Shimei, 1999, P EMNLP VLC 99; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; Rijsbergen CJV, 1979, INFORMATION RETRIEVA, V2nd; Salton G., 1989, AUTOMATIC TEXT PROCE; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Taylor P., 1999, EDINBURGH SPEECH TOO; Taylor P, 1998, COMPUT SPEECH LANG, V12, P99, DOI 10.1006/csla.1998.0041; VANHERWIJNEN OM, 2001, P EUR 2001 SCAND, V1, P529; WANG MQ, 1997, COMPUTER SPEECH LANG, V6, P175	25	0	0	1	3	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA			1-932432-09-4				2003							489	496				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAP08	WOS:000223097500062		
B	Park, SB; Zhang, BT			ACL	Park, SB; Zhang, BT			Text chunking by combining hand-crafted rules and memory-based learning	41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE			English	Proceedings Paper	41st Annual Meeting of the Association-for-Computational-Linguistics	JUL 07-12, 2003	Sapporo, JAPAN	Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR				This paper proposes a hybrid of hand-crafted rules and a machine learning method for chunking Korean. In the partially free word-order languages such as Korean and Japanese, a small number of rules dominate the performance due to their well-developed postpositions and endings. Thus, the proposed method is primarily based on the rules, and then the residual errors are corrected by adopting a memory-based machine learning method. Since the memory-based learning is an efficient method to handle exceptions in natural language processing, it is good at checking whether the estimates are exceptional cases of the rules and revising them. An evaluation of the method yields the improvement in F-score over the rules or various machine learning methods alone.	Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151744, South Korea							Cherkassky V., 1998, LEARNING DATA CONCEP; *CONLL, 2000, SHAR TASK COMP NAT L; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Daelemans W., 2001, TIMBL TILBURG MEMORY; Golding AR, 1996, ARTIF INTELL, V87, P215, DOI 10.1016/0004-3702(95)00120-4; Joachims T., 1998, MAKING LARGE SCALE S; KIM KC, 1995, J KISS, V22, P1384; Kudoh T., 2000, P CONLL 2000 LLL 200, P142; PARK SB, 2001, P 19 INT C COMPUTER, P225; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; RAMSHAW L, 1995, P 3 ACL WORKSH VER L, P80; SHIN HP, 1999, P C HANG KOR LANG IN, P240; YOON JT, 1999, CSTR99139 KAIST CORP; Zhang T., 2001, P 39 ANN M ASS COMP, P539, DOI 10.3115/1073012.1073081	15	0	0	0	0	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA			1-932432-09-4				2003							497	504				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAP08	WOS:000223097500063		
S	Vogt, P		Banzhaf, W; Christaller, T; Dittrich, P; Kim, JT; Ziegler, J		Vogt, P			THSim v3.2: The talking heads simulation tool	ADVANCES IN ARTIFICIAL LIFE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th European Conference on Artifical Life	SEP 14-17, 2003	DORTMUND, GERMANY	Deutsch Forsch Gemeinsch, European Network Excellence Evolut Computat, Univ Dortmund e V, Gesell Freunde, Gesell Informat e V, Univ Dortmund, Westfal Ind Museum			EVOLUTION; EMERGENCE; LANGUAGE	The field of language evolution and computation may benefit from using efficient and robust simulation tools that are based on widely exploited principles within the field. The tool presented in this paper is one that could fulfil such needs. The paper presents an overview of the tool - THSim v3.2 - and discusses some research questions that can be investigated with it.	Tilburg Univ, NL-5000 LE Tilburg, Netherlands; Univ Edinburgh, Language Evolut & Computat Res Unit, Edinburgh EH8 9YL, Midlothian, Scotland	Vogt, P (reprint author), Tilburg Univ, POB 90153, NL-5000 LE Tilburg, Netherlands.						Batali J., 1998, APPROACHES EVOLUTION; Brighton H, 2002, ARTIF LIFE, V8, P25, DOI 10.1162/106454602753694756; Cangelosi A, 1998, CONNECT SCI, V10, P83; Cangelosi Angelo, 2002, SIMULATING EVOLUTION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; HURFORD JR, 1989, LINGUA, V77, P187, DOI 10.1016/0024-3841(89)90015-6; KAPLAN F, 2000, THESIS LAB INFORMATI; Kirby S, 2001, IEEE T EVOLUT COMPUT, V5, P102, DOI 10.1109/4235.918430; KIRBY S, 2002, ARTIFICIAL LIFE, V8; Oliphant M, 1999, ADAPT BEHAV, V7, P371, DOI 10.1177/105971239900700309; Smith ADM, 2001, LECT NOTES ARTIF INT, V2159, P381; STEELS L., 1999, TALKING HEADS EXPT, V1; STEELS L, 1996, ANIMALS ANIMATS, V4; Vogt P., 2003, J ARTIFICIAL SOC SOC, V6, P1; VOGT P, 2003, P EUR SUMM SCH LOG L; Vogt P., 2000, EVOLUTION COMMUNICAT, V4, P89	17	3	3	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20057-6	LECT NOTES ARTIF INT			2003	2801						535	544				10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	BX96C	WOS:000187009400057		
S	Huang, CC; Lee, HM		Berthold, MR; Lenz, HJ; Bradley, E; Kruse, R; Borgelt, C		Huang, CC; Lee, HM			A novel partial-memory learning algorithm based on grey relational structure	ADVANCES IN INTELLIGENT DATA ANALYSIS V	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Symposium on Intelligent Data Analysis	AUG 28-30, 2003	BERLIN, GERMANY				NEAREST NEIGHBOR RULE; CLASSIFICATION	In instance-based learning, the storage of instances must increase along with the number of training instances. In addition, it usually takes too much time to classify an unseen instance because all training instances have to be considered in determining the 'nearness' between instances. This paper proposes a novel partial-memory learning method based on the grey relational structure. That is, only some of the training instances are adopted for classification. The relationships among instances are first determined according to the grey relational structure. In this relational structure, the inward edges of each training instance, indicating how many times each instance is used as the nearest neighbor or neighbors in determining the class labels of other instances, can be found. This approach excludes the training instances with no or few inward edges for learning. By using the proposed approach, new instances can be classified with a few training instances. Five datasets are used for demonstrating the performance of the proposed approach. Experimental results indicate that the classification accuracy can be maintained when most of the training instances are pruned prior to learning. Meanwhile, the number of remained training instances is comparable to that of other existing pruning techniques.	Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan; Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Huang, CC (reprint author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng Julong, 1989, Journal of Grey Systems, V1; Deng J., 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; Fix E., 1951, 4 USAF SCH AV MED; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HUANG CC, 2002, P 2002 UK WORKSH COM; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; LIN CT, 1999, J GREY SYSTEM, V4, P359; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE M, 1974, J R STAT SOC B, V36, P111; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	18	1	1	0	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40813-4	LECT NOTES COMPUT SC			2003	2810						68	75				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BX67Y	WOS:000186104900007		
S	Kim, YS; Chang, JH; Zhang, BT		Whang, KY; Jeon, J; Shim, K; Srivastava, J		Kim, YS; Chang, JH; Zhang, BT			An empirical study on dimensionality optimization in text mining for linguistic knowledge acquisition	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR 30-MAY 02, 2003	SEOUL, SOUTH KOREA	Adv Informat Technol Res Ctr, KAIST, Stat Res Ctr Complex Syst, SNU, Korea Informat Sci Soc, Korean Datamining Soc, USAF, Off Sci Res, Asian Off Aerosp Res & Dev, ACM SIGKDD		knowledge acquisition; text mining; Latent Semantic Analysis; probabilistic latent semantic analysis; target word selection		In this paper, we try to find empirically the optimal dimensionality in data-driven models, Latent Semantic Analysis (LSA) model and Probabilistic Latent Semantic Analysis (PLSA) model. These models are used for building linguistic semantic knowledge which could be used in estimating contextual semantic similarity for the target word selection in English-Korean machine translation. We also facilitate k-Nearest Neighbor learning algorithm. We diversify our experiments by analyzing the covariance between the value of k in k-NN learning and accuracy of selection, in addition to that between the dimensionality and the accuracy. While we could not find regular tendency of relationship between the dimensionality and the accuracy, however, we could find the optimal dimensionality having the most sound distribution of data during experiments.	Hallym Univ, Div Informat & Telecommun Engn, Kang Won 200702, South Korea; Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151744, South Korea	Kim, YS (reprint author), Hallym Univ, Div Informat & Telecommun Engn, Kang Won 200702, South Korea.						BAIN L, 1987, INTRO PROBABILITY MA, P179; BERRY M, 1993, CS93194 U TENN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hofmann T., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312649; KIM Y, 2002, P 19 INT C COMP LING, P453; KIM Y, 2001, MACHINE TRANSLATION, V16, P89, DOI 10.1023/A:1014540107013; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259	7	4	4	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-04760-3	LECT NOTES ARTIF INT			2003	2637						111	116				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	BX23S	WOS:000184716000011		
S	Mountrakis, G; Agouris, P		Hadzilacos, T; Manolopoulos, Y; Roddick, JF; Theodoridis, Y		Mountrakis, G; Agouris, P			Learning similarity with fuzzy functions of adaptable complexity	ADVANCES IN SPATIAL AND TEMPORAL DATABASES, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Symposium on Advances in Spatial and Temporal Databases	JUL 24-27, 2003	SANTORINI ISL, GREECE	Microsoft, MDS Marathon Data Syst, Comp Technol Inst, Univ Piraeus				A common approach in database queries involves the multidimensional representation of objects by a set of features. These features are compared to the query representation and then combined together to produce a total similarity metric. In this paper we introduce a novel technique for similarity learning within features (attributes) by manipulating fuzzy membership functions (FMFs) of different complexity. Our approach is based on a gradual complexity increase adaptable to problem requirements. The underlying idea is that less adaptable functions will act as approximations for more complex ones. We begin by interpolating a set of planes in the training dataset and due to linearity we get a fast first impression of the underlying complexity. We proceed to interpolate two asymmetrical sigmoidal functions whose initial approximations are calculated from the plane properties. If satisfactory accuracy is not achieved we provide advanced modeling capabilities by investigating FMFs parameters and convolving their output with additional functions.	Univ Maine, Natl Ctr Geog Informat & Anal, Dept Spatial Informat Sci & Engn, Orono, ME 04469 USA	Mountrakis, G (reprint author), Univ Maine, Natl Ctr Geog Informat & Anal, Dept Spatial Informat Sci & Engn, 348 Boardman Hall, Orono, ME 04469 USA.						Agrawal R., 1993, P 4 INT C FDN DAT OR, P69; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Batchelor B., 1978, PATTERN RECOGN, P71; Berchtold S., 1997, P ACM SIGMOD INT C M, P564, DOI 10.1145/253260.253407; Byoung-Kee Yi, 2000, P 26 INT C VER LARG, P385; CARKACIOGLU A, 2002, P INT C IM PROC, P405; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Ishii N., 1998, Proceedings. IEEE International Joint Symposia on Intelligence and Systems (Cat. No.98EX174), DOI 10.1109/IJSIS.1998.685412; Lim JH, 2001, IEEE T KNOWL DATA EN, V13, P846; Mandl T, 2000, NEURAL COMPUT APPL, V9, P280, DOI 10.1007/s005210070005; Mitaim S., 1997, Proceeding. IEEE International Forum on Research and Technology Advances in Digital Libraries. -ADL'97- (Cat. No.97TB100126), DOI 10.1109/ADL.1997.601197; Nadler M., 1993, PATTERN RECOGNITION; Papadias D, 1999, INT J GEOGR INF SCI, V13, P93, DOI 10.1080/136588199241373; PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4; Rafiei D., 1997, P ACM SIGMOD INT C M, P13, DOI 10.1145/253260.253264; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Vlachos M., 2002, Proceedings 13th International Workshop on Database and Expert Systems Applications. DEXA 2002; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103	19	1	1	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40535-6	LECT NOTES COMPUT SC			2003	2750						412	429				18	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BX40Z	WOS:000185178500024		
S	Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G		Dehne, F; Sack, JR; Smid, M		Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G			Output-sensitive algorithms for computing nearest-neighbour decision boundaries	ALGORITHMS AND DATA STRUCTURES, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Workshop on Algorithms and Data Structures (WADS 2003)	JUL 30-AUG 01, 2003	OTTAWA, CANADA		CARLETON UNIV		CONVEX-HULL ALGORITHM	Given a set R of red points and a set, B of blue points, the nearest-neighbour decision rule classifies a new point q as red (respectively, blue) if the closest point to q in R U B comes from R (respectively, B). This rule implicitly partitions space into a red set and a blue set that are separated by a red-blue decision boundary. In this paper we develop output-sensitive algorithms for computing this decision boundary for point sets on the line and in R-2. Both algorithms run in time O(n log k), where k is the number of points that contribute to the decision boundary. This running time is the best possible when parameterizing with respect to n and k.	Univ New Brunswick, Fac Comp Sci, New Brunswick, NJ USA; MIT, Cambridge, MA 02139 USA; Univ Illinois, Dept Comp Sci, Chicago, IL 60680 USA; Free Univ Brussels, Charge Rech FNRS, Brussels, Belgium; Carleton Univ, Sch Comp Sci, Ottawa, ON K1S 5B6, Canada; McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2T5, Canada	Bremner, D (reprint author), Univ New Brunswick, Fac Comp Sci, New Brunswick, NJ USA.		Erickson, Jeff/J-5887-2013	Erickson, Jeff/0000-0002-5253-2282			Ben-Or M, 1983, P 15 ANN ACM S THEOR, P80, DOI 10.1145/800061.808735; Bhattacharya BK, 1997, J ALGORITHM, V25, P177, DOI 10.1006/jagm.1997.0869; Blum M., 1973, Journal of Computer and System Sciences, V7, DOI 10.1016/S0022-0000(73)80033-9; Chan TM, 1996, DISCRETE COMPUT GEOM, V16, P361, DOI 10.1007/BF02712873; Chan TM, 1997, DISCRETE COMPUT GEOM, V18, P433, DOI 10.1007/PL00009327; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1978, PATTERN RECOGN, V10, P41, DOI 10.1016/0031-3203(78)90047-X; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DOBKIN DP, 1983, THEOR COMPUT SCI, V27, P241, DOI 10.1016/0304-3975(82)90120-7; DOBKIN DP, 1985, J ALGORITHM, V6, P381, DOI 10.1016/0196-6774(85)90007-0; Hoare C. A. R., 1961, CACM, V4, P321, DOI 10.1145/366622.366644; KIRKPATRICK D, 1983, SIAM J COMPUT, V12, P28, DOI 10.1137/0212002; KIRKPATRICK DG, 1986, SIAM J COMPUT, V15, P287, DOI 10.1137/0215021; Preparata F. P., 1985, COMPUTATIONAL GEOMET; Shamos M. I., 1975, P 7 ANN ACM S THEOR, P224, DOI 10.1145/800116.803772; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; Toussaint G. T., 1984, P COMP SCI STAT 16 S; TOUSSAINT GT, 2003, UNPUB PROXIMITY GRAP; Wenger R, 1997, ALGORITHMICA, V17, P322, DOI 10.1007/BF02523195	19	3	3	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40545-3	LECT NOTES COMPUT SC			2003	2748						451	461				11	Computer Science, Theory & Methods	Computer Science	BX52R	WOS:000185605300039		
S	Yang, JY; Yang, MQ; Ersoy, OK		Kaynak, O; Alpaydin, E; Oja, E; Xu, L		Yang, JY; Yang, MQ; Ersoy, OK			Exploring protein functional relationships using genomic information and data mining techniques	ARTIFICAIL NEURAL NETWORKS AND NEURAL INFORMATION PROCESSING - ICAN/ICONIP 2003	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	Joint International Conference on Artificial Neural Networks (ICANN)/International on Neural Information Processing (ICONIP)	JUN 26-29, 2002	ISTANBUL, TURKEY	Bogazici Univ Fdn, USAF, European Off Aerosp Res & Dev, Turkish Sci & Tech Res Council				An approach that uses both supervised and unsupervised learning methods for exploring protein functional relationships is reported; we refer to this as Maximum Contrast (MC) tree. The tree is constructed by performing a hierarchical decomposition of the feature space; this step is performed regardless of complex nature of protein functions, i.e. it performs this decomposition even without knowledge of the protein functional class labels. In order to test our algorithm, we have constructed a library of Protein Phylogenetic Profiles for the proteins in the yeast Saccharomyces Cerevisiae with 60 species. Results showed our algorithm compares favorably to other classification algorithms such as the decision tree algorithms C4.5, C5, and to support vector machines.	Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Yang, JY (reprint author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.						Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Choe W, 2000, BIOINFORMATICS, V16, P1062, DOI 10.1093/bioinformatics/16.12.1062; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ERSOY OK, 1995, IEEE T NEURAL NETWOR, V6, P1037, DOI 10.1109/72.410348; ERSOY OK, 1998, ALGORITHM ARCHITECTU, P364; Marcotte EM, 1999, NATURE, V402, P83; PAVLIDIS P, J COMPUTATIONAL BIOL, V9, P401; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Vert Jean-Philippe, 2002, Bioinformatics, V18 Suppl 1, pS276; YANG J, 2002, INTELLIGENG ENG SYST, V12, P733	11	1	1	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40408-2	LECT NOTES COMPUT SC			2003	2714						1073	1080				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BX47F	WOS:000185378100128		
J	Li, JY; Liu, HQ; Downing, JR; Yeoh, AEJ; Wong, LS				Li, JY; Liu, HQ; Downing, JR; Yeoh, AEJ; Wong, LS			Simple rules underlying gene expression profiles of more than six subtypes of acute lymphoblastic leukemia (ALL) patients	BIOINFORMATICS			English	Article							CLASSIFICATION; PREDICTION; DISCOVERY; PATTERNS	Motivations and Results: For classifying gene expression profiles or other types of medical data, simple rules are preferable to non-linear distance or kernel functions. This is because rules may help us understand more about the application in addition to performing an accurate classification. In this paper, we discover novel rules that describe the gene expression profiles of more than six subtypes of acute lymphoblastic leukemia (ALL) patients. We also introduce a new classifier, named PCL, to make effective use of the rules. PCL is accurate and can handle multiple parallel classifications. We evaluate this method by classifying 327 heterogeneous ALL samples. Our test error rate is competitive to that of support vector machines, and it is 71% better than C4.5, 50% better than Naive Bayes, and 43% better than k-nearest neighbour. Experimental results on another independent data sets are also presented to show the strength of our method.	Labs Informat Technol, Singapore 119613, Singapore; St Jude Childrens Res Hosp, Memphis, TN 38105 USA; Natl Univ Singapore, Singapore 119074, Singapore	Li, JY (reprint author), Labs Informat Technol, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@lit.a-star.edu.sg	Wong, Limsoon/E-5033-2010; Yeoh, Allen/D-9663-2015	Wong, Limsoon/0000-0003-1241-5441; 			Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dong G. Z., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Langley P., 1992, P 10 NAT C ART INT, P223; Li J., 2000, P 17 INT C MACH LEAR, P551; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Liu H., 1995, P IEEE 7 INT C TOOLS, P338; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Witten H.I., 2000, DATA MINING PRACTICA; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	14	57	67	0	2	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JAN	2003	19	1					71	78		10.1093/bioinformatics/19.1.71		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	636PA	WOS:000180463900011	12499295	
B	Li, J; Li, DD; Khoja, JA; Liang, QL; Manry, MT; Prabhu, VK		Heiter, G		Li, J; Li, DD; Khoja, JA; Liang, QL; Manry, MT; Prabhu, VK			Overcoming co-channel interference in TDMA systems using SOM equalizer	BOSTON 2003 RADIO & WIRELESS RAWCON CONFERENCE, PROCEEDINGS			English	Proceedings Paper	IEEE Radio and Wireless Conference (RAWCON 2003)	AUG 10-13, 2003	BOSTON, MA	IEEE Microware Theory & Tech Soc, IEEE Boston Sect, IEEE Commun Soc			CHANNEL EQUALIZATION	This paper studies the co-channel interference (CCI) problem for time-division-multiple-access (TDMA) cellular mobile communication system with burst transmission. We present a method using self-organizing-map (SOM) to overcome CCI for such a system. The SOM is realized as a classification equalizer with a decision feedback adaptive filter. An extremely small number of unique words (UWs) is utilized to initialize the SOM equalizer. Simulation results show that the bit error rate (BER) of our proposed method is much better than that of the recently proposed nearest neighbor classification equalizer.	Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA	Li, J (reprint author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.						CHEN S, 1992, SIGNAL PROCESS, V28, P91, DOI 10.1016/0165-1684(92)90067-7; Chen S, 1996, IEE P-COMMUN, V143, P219, DOI 10.1049/ip-com:19960612; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Jakes W., 1993, MICROWAVE MOBILE COM; Kohonen T., 1995, SELFORGANIZING MAPS; Liang QL, 2000, IEEE T CIRCUITS-II, V47, P1419, DOI 10.1109/82.899635; Rappaport T. S., 1996, WIRELESS COMMUNICATI; Savazzi P, 1998, IEEE J SEL AREA COMM, V16, P1640, DOI 10.1109/49.737633; XIANG ZJ, 1994, IEEE T SIGNAL PROCES, V42, P2470	9	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7829-6				2003							123	126				4	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BX45A	WOS:000185329800031		
S	Woon, FL; Knight, B; Petridis, M		Ashley, KD; Bridge, DG		Woon, FL; Knight, B; Petridis, M			Case base reduction using solution-space metrics	CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th International Conference on Case-Bases Reasoning (ICCBR 2003)	JUN 23-26, 2003	TRONDHEIM, NORWAY	Kaidara Software, Empolis & Norwegian, Univ Sci & Technol, Dept Comp & Informat Sci			NEAREST NEIGHBOR RULE; LEARNING ALGORITHMS; BENDS	In this paper we propose a case base reduction technique which uses a metric defined on the solution space. The technique utilises the Generalised Shepard Nearest Neighbour (GSNN) algorithm to estimate nominal or real valued solutions in case bases with solution space metrics. An overview of GSNN and a generalised reduction technique, which subsumes some existing decremental methods, such as the Shrink algorithm, are presented. The reduction technique is given for case bases in terms of a measure of the importance of each case to the predictive power of the case base. A trial test is performed on two case bases of different kinds, with several metrics proposed in the solution space. The tests show that GSNN can out-perforin standard nearest neighbour methods on this set. Further test results show that a case-removal order proposed based on a GSNN error function can produce a sparse case base with good predictive power.	Tunku Abdul Rahman Coll, Sch Arts & Sci, Kuala Lumpur, Malaysia; Univ Greenwich, Sch Comp & Math Sci, London SE10 9LS, England	Woon, FL (reprint author), Tunku Abdul Rahman Coll, Sch Arts & Sci, Kuala Lumpur, Malaysia.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Cameron-Jones R. M., 1995, P 8 AUSTR JOINT C AR, P99; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Hanson R, 2002, P I MECH ENG E-J PRO, V216, P143, DOI 10.1243/095440802320225284; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kalman H, 2000, POWDER TECHNOL, V112, P244, DOI 10.1016/S0032-5910(00)00298-9; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KNIGHT B, 2003, IN PRESS P 18 INT JO; Kolodner J. L., 1993, CASE BASED REASONING; Mitchell T. M., 1997, MACH LEARN, P230; RICHTER M, ICCBR 2001; Salamo M, 2002, LECT NOTES ARTIF INT, V2416, P365; Shepard D, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; Smyth B., 1995, P 14 INT JOINT C ART, P377; Smyth B, 1998, LECT NOTES ARTIF INT, V1488, P208; Smyth B, 1999, LECT NOTES ARTIF INT, V1650, P329; Watson I., 1997, APPL CASE BASED REAS; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WITTEN IH, 2000, PRACTICAL MACHINE LE, P125; Yang Q, 2001, COMPUT INTELL, V17, P250, DOI 10.1111/0824-7935.00143	23	0	0	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40433-3	LECT NOTES ARTIF INT			2003	2689						652	664				13	Computer Science, Artificial Intelligence	Computer Science	BX29X	WOS:000184854300049		
B	Gregson, DJ; Li, KF; Fu, W		Olivier, G; Pierre, S; Sood, VK		Gregson, DJ; Li, KF; Fu, W			Fault detection using phenomenological models	CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS: TOWARD A CARING AND HUMANE TECHNOLOGY			English	Proceedings Paper	15th IEEE Canadian Conference on Electrical and Computer Engineering	MAY 04-07, 2003	MONTREAL, CANADA	IEEE, IEEE Canada, IEEE Eastern Canada Council, IEEE Montreal, St Maurice & Quebec Sect, Ecole Polytech Montreal, Manitoba HVDC Res Ctr, Cooperat Etudiante Ecole Polytech, John Wiley & Sons Canada, McGraw Hill Ryerson Ltd, Cheneliere McGraw Hill, Oxford Univ Press, Presses Int Polytech		fault detection; system modeling; behavioural modeling; outlier analysis		There exist many different established approaches to detect system faults. This paper discusses the various system models and the associated fault detection techniques. Specifically, phenomenological models are presented in detail. Fault detection using principal components analysis and the cluster and classify method is illustrated with real operational data from an electrically powered vehicle.	Quester Tangent Corp, Sidney, BC, Canada	Gregson, DJ (reprint author), Quester Tangent Corp, Sidney, BC, Canada.						AGRAWAL R, 1993, P FODO C; Barnett V., 1994, OUTLIERS STAT DATA, V3rd; Bishop C.M., 1995, NEURAL NETWORKS PATT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRYAN FJ, 1988, MULTIVARIATE STAT ME; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dym C. L., 1991, KNOWLEDGE BASED SYST; Fahlman S. E., 1990, CMUCS90100 SCH COMP; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Han Jiawei, 2001, DATA MINING CONCEPTS; Keravnou E. T., 1986, COMPETENT EXPERT SYS; Pouliezos A. D., 1994, REAL TIME FAULT MONI; PRESTON J, 2002, OBJECTIVE MEASURES A; RINNER B, 1996, THESIS GRAZ U TECHNO; SIDDALL JN, 1990, EXPERT SYSTEMS ENG; SIMULA O, 1998, ANAL MODELING COMPLE	16	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7781-8				2003							855	859				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic; Optics; Telecommunications	Computer Science; Engineering; Optics; Telecommunications	BX59A	WOS:000185776300199		
S	Ferrer-Troyano, LJ; Aguilar-Ruiz, JS; Riquelme, JC		Sloot, PMA; Abramson, D; Bogdanov, AV; Dongarra, JJ; Zomaya, AY; Gorbachev, YE		Ferrer-Troyano, LJ; Aguilar-Ruiz, JS; Riquelme, JC			Empirical evaluation of the difficulty of finding a good value of k for the nearest neighbor	COMPUTATIONAL SCIENCE - ICCS 2003, PT II, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Conference on Computational Science (ICCS 2003)	JUN 02-04, 2003	MELBOURNE, AUSTRALIA	Univ Amsterdam, Hewlett Packard, Springer Verlag, Netherlands Inst St Petersburg, Russian Federat, Minist Ind, Sci & Technol, Govt St Petersburg, Comm Sci & High Educ, St Petersburg State Tech Univ, Inst High Performance Comp & Informat Syst, IBM Australia, Microsoft, Cray Inc, Dolphin Interconnect, Microway, Etnus, ceanet, NAG, Pallas GmbH		nearest neighbor; local adaptive nearest neighbor	CLASSIFICATION	As an analysis of the classification accuracy bound for the Nearest Neighbor technique, in this work we have studied if it is possible to find a good value of the parameter k for each example according to their attribute values. Or at least, if there is a pattern for the parameter k in the original search space. We have carried out different approaches based on the Nearest Neighbor technique and calculated the prediction accuracy for a group of databases from the UCI repository. Based on the experimental results of our study, we can state that, in general, it is not possible to know a priori a specific value of k to correctly classify an unseen example.	Univ Sevilla, Dept Comp Sci, Seville 41012, Spain	Ferrer-Troyano, LJ (reprint author), Univ Sevilla, Dept Comp Sci, Avenida Reina Mercedes S-N, Seville 41012, Spain.		Riquelme, Jose/E-6451-2010; Aguilar-Ruiz, Jesus/L-9135-2014; 	Riquelme, Jose/0000-0002-8243-2186; Ferrer Troyano, Francisco Javier/0000-0003-2448-2940			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Blake C, 1998, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FERRER FJ, 2001, P 10 PORT C ART INT; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; STONE M, 1974, J R STAT SOC B, V36, P111; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1994, ADV NEURAL INFORMATI, P184; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	13	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40195-4	LECT NOTES COMPUT SC			2003	2658						766	773				8	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BX28K	WOS:000184831800083		
S	Cardenes, R; Warfield, SK; Macias, EM; Santana, JA; Ruiz-Alzola, J		MorenoDiaz, R; Pichler, F		Cardenes, R; Warfield, SK; Macias, EM; Santana, JA; Ruiz-Alzola, J			An efficient algorithm for multiple sclerosis lesion segmentation from brain MRI	COMPUTER AIDED SYSTEMS THEORY - EUROCAST 2003	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	9th International Workshop on Computer Aided Systems Theory	FEB 24-28, 2003	LAS PALMAS GC, SPAIN				FINDING NEAREST NEIGHBORS; ARBITRARY DIMENSIONS; CLASSIFICATION	We propose a novel method for the segmentation of Multiple Sclerosis (MS) lesions in MRI. The method is based on a three-step approach: first a conventional k-NN classifier is applied to pre-classify gray matter (CM), white matter (WM), cerebro-spinal fluid (CSF) and MS lesions from a set of prototypes selected by an expert. Second, the classification of problematic patterns is resolved computing a fast distance transformation (DT) algorithm from the set of prototypes in the Euclidean space defined by the MRI dataset. Finally, a connected component filtering algorithm is used to remove lesion voxels not connected to the real lesions. This method uses distance information together with intensity information to improve the accuracy of lesion segmentation and, thus, it is specially useful when MS lesions have similar intensity values than other tissues. It is also well suited for interactive segmentations due to its efficiency. Results are shown on real MRI data as wall as on a standard database of synthetic images.	Univ Las Palmas de Gran Canaria, Dept Ingn Telemat, Las Palmas Gran Canaria, Spain; Harvard Univ, Sch Med, Cambridge, MA 02138 USA; Brigham & Womens Hosp, Dept Radiol, Boston, MA 02115 USA; Univ Las Palmas de Gran Canaria, Med Technol Ctr, Las Palmas Gran Canaria, Spain	Cardenes, R (reprint author), Univ Las Palmas de Gran Canaria, Dept Ingn Telemat, Las Palmas Gran Canaria, Spain.	ruben@ctm.ulpgc.es; warfield@bwh.harvard.edu; elsa@dit.ulpgc.es; jaruelio@ctm.ulpgc.es; jruiz@ctm.ulpgc.es	Warfield, Simon/B-3352-2009; Macias Lopez, Elsa/D-3295-2011	Macias Lopez, Elsa/0000-0002-9085-8398			Aurenhammer F, 2000, HANDBOOK OF COMPUTATIONAL GEOMETRY, P201, DOI 10.1016/B978-044482537-7/50006-1; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; Cocosco C. A., 1997, NEUROIMAGE, V5, P425; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUISENAIRE O, 2000, P 10 EUR SIGN PROC C, P1365; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; Duda R. O., 1973, PATTERN CLASSIFICATI; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; JIANG QY, 1993, PATTERN RECOGN LETT, V14, P531, DOI 10.1016/0167-8655(93)90101-I; KAUS M, 2000, THESIS BERLIN; Okabe A., 1992, SPATIAL TESSELATIONS; RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4; VERWER BJH, 1989, IEEE T PATTERN ANAL, V11, P425, DOI 10.1109/34.19041; Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0; Warfield SK, 2000, MED IMAGE ANAL, V4, P43, DOI 10.1016/S1361-8415(00)00003-7	17	6	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20221-8	LECT NOTES COMPUT SC			2003	2809						542	551				10	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Automation & Control Systems; Computer Science; Imaging Science & Photographic Technology	BY16G	WOS:000188006400049		
S	Li, JY; Ng, SK; Wong, LS		Calvanese, D; Lenzerini, M; Motwani, R		Li, JY; Ng, SK; Wong, LS			Bioinformatics adventures in database research	DATABASE THEORY ICDT 2003, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	9th International Conference on Database Theory (ICDT)	JAN 08-10, 2003	SIENA, ITALY	Univ Roma, Dipartimento Informat Sistemist			COLLECTION TYPES; QUERY LANGUAGES; HUMAN GENOME; DISCOVERY; CLASSIFICATION; PREDICTION; GENE; SYSTEM	Informatics has helped launch molecular biology into the genomic era. It appears certain that informatics will remain a major contributor to molecular biology in the post-genome era. We discuss here data integration and datamining in bioinformatics, as well as the role that database theory played in these topics. We also describe LIMS as a third key topic in bioinformatics where advances in database system and theory can be very relevant.	Labs Informat Technol, Singapore 119613, Singapore	Li, JY (reprint author), Labs Informat Technol, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@lit.a-star.edu.sg; skng@lit.a-star.edu.sg; limsoon@lit.a-star.edu.sg	Wong, Limsoon/E-5033-2010	Wong, Limsoon/0000-0003-1241-5441			Agrawal R., VLDB 94, P487; Baker PG, 1998, CURR OPIN BIOTECH, V9, P54, DOI 10.1016/S0958-1669(98)80084-0; BAYARDO RJ, SIGMOD 98, P85; BUNEMAN P, 1995, THEOR COMPUT SCI, V149, P3, DOI 10.1016/0304-3975(95)00024-Q; Buneman P., 1994, SIGMOD Record, V23; CHEN J, IN PRESS BIOINFORMAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAMAS L, POPL 82, P207; Davidson S. B., 1997, International Journal on Digital Libraries, V1; *DOE, 1993, DOE INF SUMM M REP; DONG G, KDD 99, P15; FAYYAD UM, IJCAI 93, P1022; Gerhold D, 1999, TRENDS BIOCHEM SCI, V24, P168, DOI 10.1016/S0968-0004(99)01382-1; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Haas LM, 2001, IBM SYST J, V40, P489; Hatzigeorgiou AG, 2002, BIOINFORMATICS, V18, P343, DOI 10.1093/bioinformatics/18.2.343; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; JAESCHKE G, PODS 82, P124; KOZAK M, 1987, NUCLEIC ACIDS RES, V15, P8125, DOI 10.1093/nar/15.20.8125; LANGLEY P, AAAI 92, P223; LI J, PKDD 02, P325; LI J, 2002, IN PRESS BIOINFORMAT; LI J, ICML 00, P551; Libkin L, 1997, J COMPUT SYST SCI, V55, P241, DOI 10.1006/jcss.1997.1523; Liu H., 1995, P IEEE 7 INT C TOOLS, P338; MAKINOUCHI A, VLDB 77, P447; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; PAPAKONSTANTINO.Y, ICDE 95, P251; PEARSON PL, 1992, NUCLEIC ACIDS RES, V20, P2201; Pedersen AG, 1997, ISMB, V5, P226; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schuler GD, 1996, METHOD ENZYMOL, V266, P141; Searls DB, 2000, DRUG DISCOV TODAY, V5, P135, DOI 10.1016/S1359-6446(99)01457-9; Thomas S. J., 1986, ADV COMPUTING RES, V3, P269; Vapnik V. N., 1995, NATURE STAT LEARNING; Wadler P., 1992, MATH STRUCTURES COMP, V2, P461; WONG L, BIBE 00, P21; Wong L., 2000, J FUNCTIONAL PROGRAM, V10, P19, DOI 10.1017/S0956796899003585; Wong L, 1996, J COMPUT SYST SCI, V52, P495, DOI 10.1006/jcss.1996.0037; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; ZENG F, IN PRESS GIW 02; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	43	1	1	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-00323-1	LECT NOTES COMPUT SC			2003	2572						31	46				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BW31N	WOS:000181548600003		
B	van Herwijnen, O; Terken, J; van den Bosch, A; Marsi, E			ACL	van Herwijnen, O; Terken, J; van den Bosch, A; Marsi, E			Learning PP attachment for filtering prosodic phrasing	EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE			English	Proceedings Paper	10th Conference of the European Chapter of the Association-for-Computational-Linguistics (EACL 2003)	APR 12-17, 2003	Budapest, HUNGARY	Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc				We explore learning prepositional-phrase attachment in Dutch, to use it as a filter in prosodic phrasing. From a syntactic treebank of spoken Dutch we extract instances of the attachment of prepositional phrases to either a governing verb or noun. Using cross-validated parameter and feature selection, we train two learning algorithms, IB1 and RIPPER, on making this distinction, based on unigram and bigram lexical features and a cooccurrence feature derived from WWW counts. We optimize the learning on noun attachment, since in a second stage we use the attachment decision. for blocking the incorrect placement of phrase boundaries before prepositional phrases attached to the preceding noun. On noun attachment, IB1 attains an F-score of 82; RIPPER an F-score of 78. When used as a filter for prosodic phrasing, using attachment decisions from IB1 yields the best improvement on precision (by six points to 71) on phrase boundary placement.	Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands			van den Bosch, Antal/G-5072-2011	van den Bosch, Antal/0000-0003-2493-656X			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BEAR J, 1990, P 28 C ASS COMP LING, P17, DOI 10.3115/981823.981826; BRILL E, 1994, P 15 ANN C COMP LING; Charniak Eugene, 2000, P 1 C N AM CHAPT ASS, P132; Church K. W., 1990, COMPUTATIONAL LINGUI, V16, P22; Cohen William W., 1995, P 12 INT C MACH LEAR; COLLINS M, 1995, P 3 WORKSH VER LARG; Collins M., 1996, P 34 ANN M ASS COMP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; DAELEMANS W, 2002, ILK0210 TILB U; Dunning T., 1993, Computational Linguistics, V19; FRANZ A, 1996, LECT NOTES ARTIF INT, V1040, P188; Hindle D., 1993, Computational Linguistics, V19; MARSI E, 1997, PROGR SPEECH SYNTHES, P477; PAARDEKOOPER PC, 1977, ABN BEKNOPTE ABN SYN; Ratnaparkhi A, 1997, P 2 C EMP METH NAT L, P1; RATNAPARKHI A, 1994, P ARPA WORKSH HUM LA; SANDERMAN A, 1996, THESIS EINDHOVEN U T; Sanderman AA, 1997, LANG SPEECH, V40, P391; Selkirk E., 1984, PHONOLOGY SYNTAX REL; van der Wouden T., 2002, P 3 INT C LANG RES E, P768; VANHERWIJNEN OM, 2001, P EUR 2001 SCAND, V2, P959; VANHERWIJNEN OM, 2001, P EUR 2001 SCAND, V1, P529; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA; VOLK M, 2000, P KONVENS 2000, P151; ZAVREL J, 1997, P WORKSH COMP NAT LA, P136	27	0	0	0	1	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA			1-932432-00-0				2003							139	146				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Computer Science; Linguistics	BAN69	WOS:000222995200019		
J	Gilboa, I; Schmeidler, D				Gilboa, I; Schmeidler, D			Inductive inference: An axiomatic approach	ECONOMETRICA			English	Article						case-based reasoning; case-based decision theory; prediction; maximum likelihood; kernel functions; kernel classification	DECISION-THEORY	A predictor is asked to rank eventualities according to their plausibility, based on past cases. We assume that she can form a ranking given any memory that consists of finitely many past cases. Mild consistency requirements on these rankings imply that they have a numerical representation via a matrix assigning numbers to eventuality-case pairs, as follows. Given a memory, each eventuality is ranked according to the sum of the numbers in its row, over cases in memory. The number attached to an eventuality-case pair can be interpreted as the degree of support that the past case lends to the plausibility of the eventuality. Special instances of this result may be viewed as axiomatizing kernel methods for estimation of densities and for classification problems. Interpreting the same result for rankings of theories or hypotheses, rather than of specific eventualities, it is shown that one may ascribe to the predictor subjective conditional probabilities of cases given theories, such that her rankings of theories agree with rankings by the likelihood functions.	Tel Aviv Univ, Eitan Berglas Sch Econ, IL-69978 Tel Aviv, Israel; Tel Aviv Univ, Recanati Sch Business, IL-69978 Tel Aviv, Israel; Yale Univ, Cowles Fdn, New Haven, CT 06520 USA; Tel Aviv Univ, Dept Stat, IL-69978 Tel Aviv, Israel; Ohio State Univ, Dept Econ, Columbus, OH 43210 USA	Gilboa, I (reprint author), Tel Aviv Univ, Eitan Berglas Sch Econ, IL-69978 Tel Aviv, Israel.						Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Finetti B., 1937, ANN I H POINCARE, V7, P1; Devroye L., 1996, PROBABILISTIC THEORY; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 2149004 USAF SCH AV; Forsyth R., 1986, MACHINE LEARNING APP; Gilboa I, 1997, ECON THEORY, V9, P47, DOI 10.1007/BF01213442; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; GILBOA L, 2001, THEORY CASE BASED DE; GILBOA L, 1999, 3199 FOERD I EC RES; GILBOA L, 2002, MATH OPER RES, V27, P68; Hacking Ian, 1975, EMERGENCE PROBABILIT; Hume D., 1748, ENQUIRY HUMAN UNDERS; MYERSON RB, 1995, SOC CHOICE WELFARE, V12, P59; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Ramsey Frank P., 1931, FDN MATH OTHER LOGIC; Riesbeck C. K., 1989, INSIDE CASE BASED RE; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Royall R., 1966, THESIS STANFORD U ST; Savage LJ, 1954, FDN STAT; Schank R. G., 1986, EXPLANATION PATTERNS; Scott D.W., 1992, MULTIVARIATE DENSITY; Silverman BW, 1986, DENSITY ESTIMATION S; STONE C, 1977, ANN STAT, V5, P689; YOUNG HP, 1975, SIAM J APPL MATH, V28, P824, DOI 10.1137/0128067	26	25	25	0	4	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	0012-9682			ECONOMETRICA	Econometrica	JAN	2003	71	1					1	26		10.1111/1468-0262.00388		26	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Statistics & Probability	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	637ZQ	WOS:000180543900001		
J	Uchimura, S; Watanabe, M; Hamamoto, Y				Uchimura, S; Watanabe, M; Hamamoto, Y			On the optimization of a Gabor filter-based feature extractor for handwritten character recognition	ELECTRONICS AND COMMUNICATIONS IN JAPAN PART III-FUNDAMENTAL ELECTRONIC SCIENCE			English	Article						handwritten character recognition; Gabor parameter optimization; energy function method; response surface method; two-stage searches	CLASSIFICATION	In order to use the Gabor feature extraction system in the real world, the problem of optimizing the Gabor parameters must be resolved. In the conventional optimization method, several candidates are prepared, the error rate for them is found through experimentation, and the parameters which give the lowest recognition error rates are taken to be optimal values. However, in the conventional method, setting the candidate values so that they are certain to include optimal values is a common problem. In this paper, the authors evaluate from the standpoint of the optimalness of the solutions and computational burden the optimization methods (two-stage conventional method, response surface method, and energy function method) that address the problems of the conventional method. (C) 2003 Wiley Periodicals, Inc.	Yamaguchi Univ, Fac Engn, Ube, Yamaguchi 7558611, Japan	Uchimura, S (reprint author), Yamaguchi Univ, Fac Engn, Ube, Yamaguchi 7558611, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Funkunaga K., 1990, INTRO STAT PATTERN R; HAMAMOTO Y, 1994, J IEICE, V77, P853; Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5; Hamamoto Y., 1996, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ79D-II; HEIDEMANN G, 1996, P 13 INT C PATT REC, V4, P70; Iri M., 1985, COMMON SENSE NUMERIC; JAIN AK, 1992, PATTERN RECOGN, V25, P1459, DOI 10.1016/0031-3203(92)90120-8; Jolly MPD, 1996, IEEE T PATTERN ANAL, V18, P293; KONDO Y, 1967, STAT METHODS ENG; OKUNO C, 1969, METHODS PLANNING EXP; Press W. H., 1993, NUMERICAL RECIPES C, V2nd; SAITO Y, 1978, DENSOKENI REPORT, V42, P385; TAGUCHI G, 1977, METHODS PLANNING EXP, V2; UCHIMURA S, 1996, PRMU9628 IEICE; UCHIMURA S, 1998, PRMU97225 IEICE	17	0	0	0	3	SCRIPTA TECHNICA-JOHN WILEY & SONS	NEW YORK	605 THIRD AVE, NEW YORK, NY 10158 USA	1042-0967			ELECTRON COMM JPN 3	Electron. Commun. Jpn. Pt. III-Fundam. Electron. Sci.		2003	86	12					27	37		10.1002/ecjc.10140		11	Engineering, Electrical & Electronic	Engineering	694EM	WOS:000183760900003		
S	Ben Hamza, A; Krim, H		Rangarajan, A; Figueiredo, M; Zerubia, J		Ben Hamza, A; Krim, H			Image registration and segmentation by maximizing the Jensen-Renyi divergence	ENERGY MINIMIZATION METHODS IN COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	JUL 07-09, 2003	LISBON, PORTUGAL	Int Assoc Pattern Recognit, Inst Superior Tecn, Inst Telecommun			CLASSIFICATION	Information theoretic measures provide quantitative entropic divergences between two probability distributions or data sets. In this paper, we analyze the theoretical properties of the Jensen-Renyi divergence which is defined between any arbitrary number of probability distributions. Using the theory of majorization, we derive its maximum value, and also some performance upper bounds in terms of the Bayes risk and the asymptotic error of the nearest neighbor classifier. To gain further insight into the robustness and the application of the Jensen-Renyi divergence measure in imaging, we provide substantial numerical experiments to show the power of this entopic measure in image registration and segmentation.	N Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA	Ben Hamza, A (reprint author), N Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA.		Ben Hamza, Abdessamad/G-4571-2013				ALI SM, 1966, J ROY STAT SOC B, V28, P131; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1996, PROBABILISTIC THEORY; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Gomez JF, 2000, NEURAL NETWORKS, V13, P1; HE Y, 2000, P SPIE, V4116; HE Y, 2003, IEEE T SIGNAL PROCES, V51; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355; Jensen J. R., 1996, INTRO DIGITAL IMAGE; KATURI R, 1991, COMPUTER VISION PRIN; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Marshall A.W., 1979, INEQUALITIES THEORY; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; RENYI A, 1961, MEASURES ENTROPY INF, V2, P525; Roman-Roldan R, 1998, PHYS REV LETT, V80, P1344, DOI 10.1103/PhysRevLett.80.1344; STOICA R, 1998, IEEE INT C IM PROC C; VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938; VIOLA P, 1997, INT J COMPUT VISION, V24, P173	21	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40498-8	LECT NOTES COMPUT SC			2003	2683						147	163				17	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BX35F	WOS:000185041700010		
S	Behnke, S				Behnke, S			Hierarchical neural networks for image interpretation - Introduction	HIERARCHICAL NEURAL NETWORKS FOR IMAGE INTERPRETATION	Lecture Notes in Computer Science		English	Article							PRIMARY VISUAL-CORTEX; NONNEGATIVE MATRIX FACTORIZATION; LONG-TERM DEPENDENCIES; HUMAN FACE DETECTION; PATTERN-RECOGNITION; BELIEF PROPAGATION; GRADIENT DESCENT; SHAPE REPRESENTATION; LEARNING ALGORITHMS; OBJECT-RECOGNITION		Int Comp Sci Inst, Berkeley, CA 94704 USA	Behnke, S (reprint author), Int Comp Sci Inst, 1947 Ctr Str, Berkeley, CA 94704 USA.		Behnke, Sven/B-5509-2013	Behnke, Sven/0000-0002-5040-7525			ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; AMARI SI, 1977, BIOL CYBERN, V27, P77, DOI 10.1007/BF00337259; ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; Arena P, 2002, INT J CIRC THEOR APP, V30, P349, DOI 10.1002/cta.203; *ASME, 1986, PITN BOW MOD M POST; Atiya AF, 2000, IEEE T NEURAL NETWOR, V11, P697, DOI 10.1109/72.846741; Baker S., 2002, IEEE T PATTERN ANAL, V24; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Balya D, 2002, INT J CIRC THEOR APP, V30, P363, DOI 10.1002/cta.204; Barlow H B, 1972, Perception, V1, P371, DOI 10.1068/p010371; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Barthlott W, 1997, PLANTA, V202, P1, DOI 10.1007/s004250050096; BATTITI R, 1992, NEURAL COMPUT, V4, P141, DOI 10.1162/neco.1992.4.2.141; BAUMGARTE V, 2001, P INT C ENG REC SYST; BEHNKE S, 1997, P INT C NEUR NETW IC, V3, P1391, DOI 10.1109/ICNN.1997.613997; BEHNKE S, 2001, LECT NOTES ARTIF INT, V2103, P125; BEHNKE S, 1998, P INT JOINT C NEUR N, V2, P820; Behnke S, 2000, LECT NOTES ARTIF INT, V1856, P186; BEHNKE S, 1998, P 3 INT WORKSH NEUR, P39; BEHNKE S, 1998, P INT C ART NEUR NET, V2, P567; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bellman R., 1961, ADAPTIVE CONTROL PRO; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Beyer K., 1999, P 7 INT C DAT THEOR, P217; BIEHL M, 1995, J PHYS A-MATH GEN, V28, P643, DOI 10.1088/0305-4470/28/3/018; Bierling M., 1988, P SOC PHOTO-OPT INS, P942; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; BOGACZ R, 1999, P 3 INT C COGN NEUR; Boynton GM, 1999, VISION RES, V39, P257, DOI 10.1016/S0042-6989(98)00113-8; Breiman L., 1984, CLASSIFICATION REGRE; Bullier J, 2001, TRENDS COGN SCI, V5, P369, DOI 10.1016/S1364-6613(00)01730-7; BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851; CAMINITI R, 1996, VISION MOVEMENT MECH; Carpenter G. A., 1991, PATTERN RECOGNITION; Chua L. O., 2001, CELLULAR NEURAL NETW; CHUA LO, 1993, IEEE T CIRCUITS-I, V40, P147, DOI 10.1109/81.222795; COIFMAN RR, 1994, NATO ADV SCI INST SE, V442, P363; COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; DAUBECHES I, 1992, CBMS NSF SERIES APPL, V61; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; De Bonet J. S., 1997, COMPUTER GRAPHICS, P361; Dell'Acqua F, 2002, IEEE T PATTERN ANAL, V24, P569, DOI 10.1109/34.993564; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; De Weerd P, 1998, VISION RES, V38, P2721, DOI 10.1016/S0042-6989(97)00432-X; Dill M, 1998, PERCEPT PSYCHOPHYS, V60, P65, DOI 10.3758/BF03211918; Doniger GM, 2000, J COGNITIVE NEUROSCI, V12, P615, DOI 10.1162/089892900562372; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; ECKHORN R, 1988, BIOL CYBERN, V60, P121, DOI 10.1007/BF00202899; EDK D, 2002, LNCS, V2415, P284; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Elad M, 1999, IEEE T IMAGE PROCESS, V8, P387, DOI 10.1109/83.748893; ElHihi S, 1996, ADV NEUR IN, V8, P493; EMILE HL, 1990, SIMULATED ANNEALING; Fahlman S. E., 1988, P 1988 CONN MOD SUMM, P38; FAN Y, 2000, OPTICAL ENG, V38, P2894; FECHNER GT, 1858, ABK K GES WISSENS MP, P4; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Fletcher R, 1976, LECT NOTES MATH, V506, P73; Fletcher R, 1987, PRACTICAL METHODS OP, V2nd; Foldiak P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.194; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; FOLDIAK P, 2002, HDB BRAIN THEORY NEU; FRANZ C, 1889, ARCH ANATOMIE PHYS S, V2, P263; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790414; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; FREUND Y, 1992, ADV NEUR IN, V4, P912; Frey BJ, 1998, ADV NEUR IN, V10, P479; FREY BJ, 1997, COMPUTATIONAL BIOL M; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gabor D., 1946, Journal of the Institution of Electrical Engineers. III. Radio and Communication Engineering, V93; GARRIS MD, 1992, NIST SPECIAL DATABAS, V3; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GIESE MA, 1998, KLUWER INT SERIES EN, V469; Govindaraju V, 1996, INT J COMPUT VISION, V19, P129, DOI 10.1007/BF00055801; Grossberg S, 1999, SPATIAL VISION, V12, P163, DOI 10.1163/156856899X00102; Grossberg S, 2001, CEREB CORTEX, V11, P37, DOI 10.1093/cercor/11.1.37; GROTHER PJ, 1993, 5209 NISTIR NIST; Haag J, 1997, J NEUROSCI, V17, P4809; Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326; Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072; Hahnloser RLT, 1998, NEURAL NETWORKS, V11, P691, DOI 10.1016/S0893-6080(98)00012-4; Hart P. E., 1973, PATTERN RECOGNITION; Hebb D, 1949, ORG BEHAV; HEISELE B, 2000, 1687 MIT AI LAB; Heisenberg W., 1927, Zeitschrift fur Physik, V43, DOI 10.1007/BF01397280; Henkel RD, 1998, ADV NEUR IN, V10, P808; Hertzmann A, 2001, COMP GRAPH, P327; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hjelmas E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hopfield IJ, 2000, P NATL ACAD SCI USA, V97, P13919; Hopfield JJ, 2001, P NATL ACAD SCI USA, V98, P1282, DOI 10.1073/pnas.031567098; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; Igel C, 2003, NEUROCOMPUTING, V50, P105, DOI 10.1016/S0925-2312(01)00700-7; ITO M, 1995, J NEUROPHYSIOL, V73, P218; Jaeger H., 2001, 148 GMD GERM NAT RES; Jeng SH, 1998, PATTERN RECOGN, V31, P273, DOI 10.1016/S0031-3203(97)00048-4; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; Johnson SP, 1996, COGNITIVE DEV, V11, P161, DOI 10.1016/S0885-2014(96)90001-5; JOHNSON SP, 2000, P 12 INT C INF STUD; JUALESZ B, 1984, DYNAMIC ASPECTS NEOC, P585; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Kalman R. E., 1960, T ASME D, V82, P35, DOI DOI 10.1115/1.3662552; Kandel E. R., 2000, PRINCIPLES NEURAL SC; KANIZSA GK, 1989, ORG VISION; Kapasi UJ, 2002, PR IEEE COMP DESIGN, P282, DOI 10.1109/ICCD.2002.1106783; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI DOI 10.1007/BF00133570; KELLMAN PJ, 1983, COGNITIVE PSYCHOL, V15, P483, DOI 10.1016/0010-0285(83)90017-8; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; KNIERIM JJ, 1992, J NEUROPHYSIOL, V67, P961; Koch C., 1995, VISION CHIPS IMPLEME; Koffka K., 1935, PRINCIPLES GESTALT P; Kohonen T., 1984, SPRINGER SERIES INFO, V8; KOKARAM AC, 1998, P SPIE C BAYES INF I, P212; KROGH A, 1992, ADV NEUR IN, V4, P950; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; LAMME VAF, 1995, J NEUROSCI, V15, P1605; Lawrence S, 2000, IEEE T KNOWL DATA EN, V12, P126, DOI 10.1109/69.842255; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; LECUN Y, 1990, ADV NEURAL INFORMATI, V2; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Yann, 1994, MNIST DATABASE HANDW; Lee CH, 1996, PATTERN RECOGN, V29, P1877, DOI 10.1016/0031-3203(96)00036-2; Lee DD, 2001, ADV NEUR IN, V13, P556; Lee DD, 1999, NATURE, V401, P788; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Legenstein RA, 2001, ADV NEUR IN, V13, P259; Li ZP, 2001, NEURAL COMPUT, V13, P1749, DOI 10.1162/08997660152469332; Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9; LINAN G, 2001, P 27 EUR SOL STAT CI, P216; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; LOVELL DR, 1994, THESIS U QUEENSLAND; MAAS W, 2001, UNPUB REAL TIME COMP; Maio D, 2000, PATTERN RECOGN, V33, P1525, DOI 10.1016/S0031-3203(99)00130-2; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; MALLADI R, 1995, P NATL ACAD SCI USA, V92, P7046, DOI 10.1073/pnas.92.15.7046; MALLAT S, 1989, IEEE T PATTERN ANAL, V2, P7; Mallat S., 1992, IEEE T PATTERN ANAL, V14, P7; Marr D, 1982, VISION COMPUTATIONAL; Mayraz G, 2001, ADV NEUR IN, V13, P953; McEliece RJ, 1998, IEEE J SEL AREA COMM, V16, P140, DOI 10.1109/49.661103; MERON E, 1992, PHYS REP, V218, P1, DOI 10.1016/0370-1573(92)90098-K; Messer K., 1999, P 2 INT C AUD VID BA, P72; Minsky M., 1969, PERCEPTRONS INTRO CO; Mitchell T. M., 1997, MACHINE LEARNING; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Møller M, 1993, Int J Neural Syst, V4, P15, DOI 10.1142/S0129065793000031; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; NAKAYAMA K, 1990, PERCEPTION, V19, P497, DOI 10.1068/p190497; NAZIR T A, 1990, Spatial Vision, V5, P81, DOI 10.1163/156856890X00011; Neumann H, 1999, BIOL CYBERN, V81, P425, DOI 10.1007/s004220050573; NEWTON I, 1664, METHODUS FLUXIONUM S; Nyquist H., 1928, T AIEE, V47, P617; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; OTOOLE A, 1995, P INT WORKSH AUT FAC, P326; PALM G, 1980, BIOL CYBERN, V36, P19, DOI 10.1007/BF00337019; Parveen S, 2002, ADV NEUR IN, V14, P1189; Pascual-Leone A, 2001, SCIENCE, V292, P510, DOI 10.1126/science.1057099; Pasemann F, 1998, NETWORK-COMP NEURAL, V9, P495, DOI 10.1088/0954-898X/9/4/006; Pasupathy A, 2001, J NEUROPHYSIOL, V86, P2505; Pearl J, 1988, PROBABILISTIC REASON; Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0; Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Raizada R., 2001, VIS COGN, V8, P341; RAMACHER U, 2001, P EUR SOL STAT CIRC; Ramsden BM, 2001, CEREB CORTEX, V11, P648, DOI 10.1093/cercor/11.7.648; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rao RPN, 1999, VISION RES, V39, P1963, DOI 10.1016/S0042-6989(98)00279-X; REED IS, 1960, J SOC IND APPL MATH, V8, P300, DOI 10.1137/0108018; REICHER GM, 1969, J EXP PSYCHOL, V81, P275, DOI 10.1037/h0027768; Reynolds JH, 1999, NEURON, V24, P19, DOI 10.1016/S0896-6273(00)80819-3; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rojas R., 1996, NEURAL NETWORKS SYST; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Roska B, 2001, NATURE, V410, P583, DOI 10.1038/35069068; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salomon R, 1996, NEURAL NETWORKS, V9, P589; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; SARDANA HK, 1994, PATTERN RECOGN, V27, P109, DOI 10.1016/0031-3203(94)90021-3; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; Schneiderman H., 2000, P IEEE C COMP VIS PA; Senseman DM, 2002, J NEUROPHYSIOL, V87, P1499, DOI 10.1152/jn.00475.2001; Seung HS, 1998, ADV NEUR IN, V10, P654; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Siegel M, 2000, J COMPUT NEUROSCI, V8, P161, DOI 10.1023/A:1008973215925; SIEGELMANN HT, 1995, J COMPUT SYST SCI, V50, P132, DOI 10.1006/jcss.1995.1013; SILVA FM, 1990, LECT NOTES COMPUT SC, V412, P110; Simoncelli E, 1996, P IEEE INT C IM PROC; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; SINGER W, 1995, ANNU REV NEUROSCI, V18, P555, DOI 10.1146/annurev.neuro.18.1.555; Smith R, 1998, ANN ONCOL, V9, P6; Smola P., 2002, LEARNING KERNELS SUP; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Somers DC, 1998, CEREB CORTEX, V8, P204, DOI 10.1093/cercor/8.3.204; STEMMLER M, 1995, SCIENCE, V269, P1877, DOI 10.1126/science.7569930; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Super H, 2001, NAT NEUROSCI, V4, P304, DOI 10.1038/85170; Sutton R.S., 1998, REINFORCEMENT LEARNI; TAYA R, 1995, PERCEPTION, V24, P685, DOI 10.1068/p240685; Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), DOI 10.1109/AFGR.2000.840612; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; THORPE SJ, 1998, TRENDS RES, P333; Tibshirani R, 1993, INTRO BOOTSTRAP; TOLLENAERE T, 1990, NEURAL NETWORKS, V3, P520; Treisman A, 1977, ATTENTION PERFORM, P333; Tsodyks MV, 1997, P NATL ACAD SCI USA, V94, P719, DOI 10.1073/pnas.94.2.719; TURNER MR, 1986, BIOL CYBERN, V55, P71; VanRullen R, 2001, NEUROCOMPUTING, V38, P1003, DOI 10.1016/S0925-2312(01)00445-3; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Vijayakumar S., 2001, Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180), DOI 10.1109/IROS.2001.976418; VONHUNDELSHAUSE.F, 2002, LECT NOTES ARTIF INT, V2377, P374; Weber E.H., 1834, PULSU RESORPTIONE AU; WEISS SM, 1990, COMPUTERS SYSTEMS LE; Wellner J, 1998, INFORMATION PROCESSING IN CELLS AND TISSUES, P295; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270; WILSON CL, 1993, NEURAL NETWORKS SIGN, V3, P485; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; WISKOTT L, 2003, IN PRESS PROBLEMS SY; Wong ROL, 1999, ANNU REV NEUROSCI, V22, P29, DOI 10.1146/annurev.neuro.22.1.29; Yedidia JS, 2001, ADV NEUR IN, V13, P689; Yow KC, 1997, IMAGE VISION COMPUT, V15, P713, DOI 10.1016/S0262-8856(97)00003-6	243	1	1	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40722-7	LECT NOTES COMPUT SC			2003	2766						1	+				210	Computer Science, Theory & Methods	Computer Science	BX63P	WOS:000185939800001		
J	Apte, CV; Hong, SJ; Natarajan, R; Pednault, EPD; Tipu, FA; Weiss, SM				Apte, CV; Hong, SJ; Natarajan, R; Pednault, EPD; Tipu, FA; Weiss, SM			Data-intensive analytics for predicting modeling	IBM JOURNAL OF RESEARCH AND DEVELOPMENT			English	Article							INFORMATION; RULES	The Data Abstraction Research Group was formed in the early 1990s, to bring focus to the work of the Mathematical Sciences Department in the emerging area of knowledge discovery and data mining (KD & DM). Most activities in this group have been performed in the technical area of predictive modeling, roughly at the intersection of machine learning, statistical modeling, and database technology. There has been a major emphasis on using business and industrial problems to motivate the research agenda. Major accomplishments include advances in methods for feature analysis, rule-based pattern discovery, and probabilistic modeling, and novel solutions for insurance risk management, targeted marketing, and text mining. This paper presents an overview of the group's major technical accomplishments.	IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Apte, CV (reprint author), IBM Corp, Div Res, Thomas J Watson Res Ctr, POB 218, Yorktown Hts, NY 10598 USA.						APTE C, 1996, RC20271 IBM TJ WATS; Apte C., 1994, P 17 ANN INT ACM SIG, P23; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; Apte C., 2001, P 7 ACM SIGKDD INT C, P408, DOI 10.1145/502512.502573; APTE C, 1995, ADV KNOWLEDGE DISCOV, P541; Apte C, 1999, IEEE INTELL SYST APP, V14, P49, DOI 10.1109/5254.809568; Apte CV, 2002, IBM SYST J, V41, P438; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fayyad U.M., 1995, ADV KNOWLEDGE DISCOV; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; HONG S, 1996, P ISIS 96, P10; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; HONG SJ, 2001, P 3 INT C DAT WAR KN, P131; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P709; Indurkhya N., 2001, P 7 ACM SIGKDD INT C, P287, DOI 10.1145/502512.502553; Iyengar V. S., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347110; James M., 1985, CLASSIFICATION ALGOR; Michie D., 1994, MACHINE LEARNING NEU; Ripley BD, 1996, PATTERN RECOGNITION; Scheffe H., 1959, ANAL VARIANCE; WEISS SM, 2000, P 17 INT C MACH LEAR, P1135; Weiss SM, 1999, IEEE INTELL SYST APP, V14, P63, DOI 10.1109/5254.784086; Weiss SM, 1991, COMPUTER SYSTEMS LEA; WEISS SM, 2001, RC22061 IBM TJ WATS; Weiss S.M., 2001, P 5 EUR C PRINC DAT, P484; Weiss SM, 2000, IEEE INTELL SYST APP, V15, P57, DOI 10.1109/5254.850828; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	29	9	9	0	3	IBM CORP	ARMONK	OLD ORCHARD RD, ARMONK, NY 10504 USA	0018-8646			IBM J RES DEV	IBM J. Res. Dev.	JAN	2003	47	1					17	23				7	Computer Science, Hardware & Architecture; Multidisciplinary Sciences	Computer Science; Science & Technology - Other Topics	636VW	WOS:000180478800003		
J	Sakkis, G; Androutsopoulos, I; Paliouras, G; Karkaletsis, V; Spyropoulos, CD; Stamatopoulos, P				Sakkis, G; Androutsopoulos, I; Paliouras, G; Karkaletsis, V; Spyropoulos, CD; Stamatopoulos, P			A memory-based approach to anti-spam filtering for mailing lists	INFORMATION RETRIEVAL			English	Article						text categorization; machine learning; unsolicited commercial e-mail; spam	LEARNING ALGORITHMS; TEXT CATEGORIZATION; CLASSIFICATION	This paper presents an extensive empirical evaluation of memory-based learning in the context of anti-spam filtering, a novel cost-sensitive application of text categorization that attempts to identify automatically unsolicited commercial messages that flood mailboxes. Focusing on anti-spam filtering for mailing lists, a thorough investigation of the effectiveness of a memory-based anti-spam filter is performed using a publicly available corpus. The investigation includes different attribute and distance-weighting schemes, and studies on the effect of the neighborhood size, the size of the attribute set, and the size of the training corpus. Three different cost scenarios are identified, and suitable cost-sensitive evaluation functions are employed. We conclude that memory-based anti-spam filtering for mailing lists is practically feasible, especially when combined with additional safety nets. Compared to a previously tested Naive Bayes filter, the memory-based filter performs on average better, particularly when the misclassification cost for non-spam messages is high.	Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece; Athens Univ Econ & Business, Dept Informat, GR-10434 Athens, Greece; Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece; Univ Athens, Dept Informat, GR-15771 Athens, Greece	Sakkis, G (reprint author), Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece.	gsakis@iit.demokritos.gr; ion@aueb.gr; paliourg@iit.demokritos.gr; vangelis@iit.demokritos.gr; costass@iit.demokritos.gr; T.Stamatopoulos@di.uoa.gr					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Andren N, 2000, J STRATEGIC STUD, V23, P167; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P9; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P1; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Cohen W.W., 1996, P AAAI SPRING S MACH, P18; Cohen WW, 1999, ACM T INFORM SYST, V17, P141, DOI 10.1145/306686.306688; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cranor LF, 1998, COMMUN ACM, V41, P74, DOI 10.1145/280324.280336; DAELEMANS W, 2000, TIMBL TILBURG MEMORY; Daelemans W, 1997, ARTIF INTELL REV, V11, P407, DOI 10.1023/A:1006506017891; Duda R. O., 1973, PATTERN CLASSIFICATI, P10; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; GIRAUDCARRIER C, 1995, THEO DECI L, V15, P341; Hall RJ, 1998, COMMUN ACM, V41, P88, DOI 10.1145/272287.272329; HIDALGO JMG, 2000, 4 COMP NAT LANG LEAR, P99; HULL DA, 2000, NIST SP, P35; Joachims T, 1997, P 14 INT C MACH LEAR, P143; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lang K., 1995, P 12 INT C MACH LEAR, P331; Lewis D. D., 1995, P 18 ANN INT ACM SIG, P246, DOI 10.1145/215206.215366; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Mitchell T. M., 1997, MACHINE LEARNING; PANTEL P, 1998, AAAI WORKSH MAD WISC; Payne TR, 1997, APPL ARTIF INTELL, V11, P1, DOI 10.1080/088395197118325; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rocchio J J, 1971, SMART RETRIEVAL SYST, P313; Sahami M., 1998, AAAI WORKSH MAD WISC, P55; Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SALTON G, 1983, INTRO MODERN INFORMA; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SEBASTIANI F, 2001, IEIB4311999 CONS NAZ; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; WETTSCHERECK D, 1995, AIC95012 NAV RES LAB; Wettschereck D, 1994, THESIS OREGON STATE; WILSON DR, 1997, THESIS B YOUNG U; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yang Y., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; ZAVREL J, 1997, P 7 BELG DUTCH C MAC	44	84	89	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-4564			INFORM RETRIEVAL	Inf. Retr.	JAN	2003	6	1					49	73		10.1023/A:1022948414856		25	Computer Science, Information Systems	Computer Science	660FM	WOS:000181823200003		
B	Boullart, L; Sette, S; Wyns, B; Baeten, D; Hoffman, I; De Keyser, F		Ruano, AE; Ruano, MG; Fleming, PJ		Boullart, L; Sette, S; Wyns, B; Baeten, D; Hoffman, I; De Keyser, F			Prediction of arthritis using a modified Kohonen mapping and case based learning	INTELLIGENT CONTROL SYSTEMS AND SIGNAL PROCESSING 2003	IFAC PROCEEDINGS SERIES		English	Proceedings Paper	IFAC International Conference on Intelligent Control Systems and Signal Processing	APR 08-11, 2003	FARO, PORTUGAL	Int Federat Automat Control, IEEE, Int Fuzzy Syst Assoc, Neural Networks Soc	UNIV ALGARVE	classification; neural network models; case based learning; threshold; self-organizing systems; medical applications	RHEUMATOID-ARTHRITIS	Rheumatoid arthritis (RA) and spondyloarthropathy (SpA) are the two most frequent forms of chronic autoimmune arthritis. These diseases lead to important inflammatory symptoms resulting in an important functional impairment. In this paper we apply a topological mapping combined with a case based learning evaluation criterion to predict early arthritis. The first part presents a brief introduction to the problem and self-learning neural networks while the second part of this paper will apply this technique together with a case based learning evaluation criterion to diagnostic classification. Finally the paper shows that the Kohonen neural network achieves good performance that exceeds the results of other neural network approaches and decision trees. Copyright (C) 2003 IFAC.	State Univ Ghent, Fac Sci Appl, Dept Elect Energy Syst & Automat, Ghent, Belgium	Boullart, L (reprint author), State Univ Ghent, Fac Sci Appl, Dept Elect Energy Syst & Automat, Ghent, Belgium.						ALI Z, 2000, INTELLIGENT CONTROL; Baeten D, 1999, CLIN RHEUMATOL, V18, P434, DOI 10.1007/s100670050134; Baeten D, 2000, ANN RHEUM DIS, V59, P945, DOI 10.1136/ard.59.12.945; Baeten D, 2001, ARTHRITIS RHEUM, V44, P2255, DOI 10.1002/1529-0131(200110)44:10<2255::AID-ART388>3.0.CO;2-#; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; LOH WY, 2002, QUICK UNBIASED EFFIC; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SEIBEN G, 1994, ACTA NEUROCHIRUGICA, P193; SETTE S, 1995, TEXT RES J, V65, P196, DOI 10.1177/004051759506500402; SPYROS GT, 1997, METHODS APPL INTELLI; TOMAS H, 1997, NEUROCONTROL IND CON	12	0	0	0	0	PERGAMON-ELSEVIER SCIENCE LTD	KIDLINGTON	THE BOULEVARD, LANGFORD LANE,, KIDLINGTON OX5 1GB, OXFORD, ENGLAND			0-08-044088-6	IFAC P SER			2003							43	48				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BY50Q	WOS:000189390000008		
B	Yager, RR		BouchonMeunier, B; Foulloy, L; Yager, RR		Yager, RR			Prototype based reasoning and fuzzy modeling	INTELLIGENT SYSTEMS FOR INFORMATION PROCESSING: FROM REPRESENTATION TO APPLICATIONS			English	Proceedings Paper	9th International Conference on Information Processing and Management of Uncertainty in Knowledge Based Systems	JUL 01-05, 2002	ANNECY, FRANCE			fuzzy modeling; fuzzy measures; nearest neighbor principle; information fusion		We introduce the methodology of prototype based reasoning and discuss its role as a technology for supplying missing information about some object based on known information about related objects. We show that nearest neighbor based systems and fuzzy rule based models are examples of prototype based reasoning. This perspective allows us to extend the capabilities of fuzzy modeling technology in a number of directions. One such extension discussed here is to suggest a method for fusing multiple fuzzy systems models.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D., 1988, POSSIBILITY THEORY; Duda R O, 2001, PATTERN CLASSIFICATI; MAMDANI EH, 1974, P I ELECTR ENG, V121, P1585; MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2; MUROFUSHI T, 1999, FUZZY MEASURES INTEG, P3; Nguyen H.T., 1998, FUZZY SYSTEMS MODELI; Sugeno M., 1977, FUZZY AUTOMATA DECIS, P89; Sugeno M., 1974, THESIS TOKYO I TECHN; YAGER RR, 1993, FUZZY SET SYST, V55, P255, DOI 10.1016/0165-0114(93)90252-D; Yager R.R., 1994, ESSENTIALS FUZZY MOD; YAGER RR, 2001, MII2111 MACH INT I I; YGER RR, 2001, P ATL S COMP BIOL GE, P92; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575	14	0	0	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS			0-444-51379-5				2003							167	178		10.1016/B978-044451379-3/50013-3		12	Computer Science, Artificial Intelligence	Computer Science	BY37T	WOS:000189131300013		
J	Grumberg, O; Livne, S; Markovitch, S				Grumberg, O; Livne, S; Markovitch, S			Learning to order BDD variables in verification	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							BINARY DECISION DIAGRAMS; FORMAL VERIFICATION; OBDDS; ALGORITHM	The size and complexity of software and hardware systems have significantly increased in the past years. As a result, it is harder to guarantee their correct behavior. One of the most successful methods for automated verification of finite-state systems is model checking. Most of the current model-checking systems use binary decision diagrams (BDDs) for the representation of the tested model and in the verification process of its properties. Generally, BDDs allow a canonical compact representation of a boolean function (given an order of its variables). The more compact the BDD is, the better performance one gets from the verifier. However, finding an optimal order for a BDD is an NP-complete problem. Therefore, several heuristic methods based on expert knowledge have been developed for variable ordering. We propose an alternative approach in which the variable ordering algorithm gains "ordering experience" from training models and uses the learned knowledge for finding good orders. Our methodology is based on offline learning of pair precedence classifiers from training models, that is, learning which variable pair permutation is more likely to lead to a good order. For each training model, a number of training sequences are evaluated. Every training model variable pair permutation is then tagged based on its performance on the evaluated orders. The tagged permutations are then passed through a feature extractor and are given as examples to a classifier creation algorithm. Given a model for which an order is requested, the ordering algorithm consults each precedence classifier and constructs a pair precedence table which is used to create the order. Our algorithm was integrated with SMV, which is one of the most widely used verification systems. Preliminary empirical evaluation of our methodology, using real benchmark models, shows performance that is better than random ordering and is competitive with existing algorithms that use expert knowledge. We believe that in sub-domains of models (alu, caches, etc.) our system will prove even more valuable. This is because it features the ability to learn sub-domain knowledge, something that no other ordering algorithm does.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Grumberg, O (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.						AKERS SB, 1978, IEEE T COMPUT, V27, P509; AZIZ A, 1994, P 31 DES AUT C, P283, DOI 10.1145/196244.196379; Beer I., 1996, P 33 DES AUT C, P655, DOI 10.1145/240518.240642; BERN J, 1995, P 32 ACM IEEE DES AU, P408, DOI 10.1145/217474.217563; Bollig B, 1996, IEEE T COMPUT, V45, P993, DOI 10.1109/12.537122; BOLLIG B, 1995, P INT WORKSH LOG SYN; Breiman L., 1984, CLASSIFICATION REGRE; Brglez F, 1989, P INT S CIRC SYST IS, P1924; BROOS P, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P651; Bryant RE, 1986, IEEE T COMPUT, VC-35, P8; Butler K. M., 1991, P 28 ACM IEEE DES AU, P417, DOI 10.1145/127601.127705; Chamberlain R. D., 1995, P 32 IEEE ACM DES AU, P139, DOI 10.1145/217474.217520; Chung P.-Y., 1993, [Proceedings] 1993 IEEE International Symposium on Circuits and Systems, DOI 10.1109/ISCAS.1993.394067; CLARKE EM, 1986, ACM T PROGR LANG SYS, V8, P244, DOI 10.1145/5397.5399; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Drechsler R, 1996, IEE P-COMPUT DIG T, V143, P364, DOI 10.1049/ip-cdt:19960789; Drechsler R., 1998, Proceedings 1998 Design and Automation Conference. 35th DAC. (Cat. No.98CH36175), DOI 10.1109/DAC.1998.724466; Duda R. O., 1973, PATTERN CLASSIFICATI; Even G, 1998, ALGORITHMICA, V20, P151, DOI 10.1007/PL00009191; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; FRIEDMAN SJ, 1987, P 24 DES AUT C DAC M, P151; FUJII H, 1993, P INT C COMP AID DES, P38, DOI 10.1109/ICCAD.1993.580028; FUJITA M, 1995, P INT WORKSH LOG SYN, P596; FUJITA M, 1993, IEEE T COMPUT AID D, V12, P6, DOI 10.1109/43.184839; Fujita M., 1988, P IEEE INT C COMP AI, P2; Hunt Earl B, 1966, EXPT INDUCTION; Ishiura N., 1991, P INT C COMP AID DES, P472; Iyer MA, 1996, IEEE T VLSI SYST, V4, P295, DOI 10.1109/92.502203; JAIN J, 1998, P INT C COMP AID DES, P631, DOI 10.1145/288548.289099; Karp R. M., 1972, COMPLEXITY COMPUTER, P85; Kaufmann M, 1997, PR IEEE COMP DESIGN, P25, DOI 10.1109/ICCD.1997.628845; KONUK H, 1993, P 11 IEEE VLSI TEST, P85; Lindenbaum M., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Long D. E., 1995, Proceedings 13th IEEE VLSI Test Symposium (Cat. No.95TH8068), DOI 10.1109/VTEST.1995.512610; Malik S., 1988, P INT C COMP AID DES, P6; McMillan K. L., 1993, SYMBOLIC MODEL CHECK; MEINEL C, 1998, LECT NOTES COMPUTER, V1521, P419; Meinel C, 1997, PR IEEE COMP DESIGN, P338, DOI 10.1109/ICCD.1997.628892; Meinel C., 1997, Proceedings 1997. Design Automation Conference, 34th DAC; MERCER MR, 1992, P 29 DES AUT C DAC; Minato S., 1990, P 27 ACM IEEE DES AU, P52; Nakamura K., 1998, P ICCAD 98 NOV, P392, DOI 10.1145/288548.289059; Panda S., 1995, P INT C COMP AID DES, P74, DOI 10.1109/ICCAD.1995.479994; Panda S., 1994, P INT C COMP AID DES, P628; Parker D.B, 1985, TR47 MIT CTR COMP RE; QUEILLE JP, 1981, LNCS, V137, P337; Quinlan J. R., 1979, Expert Systems in the Micro-Electronic Age. Proceedings of the 1979 AISB Summer School; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rudell R., 1993, P INT C COMP AID DES, P42, DOI 10.1109/ICCAD.1993.580029; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; Touati H. J., 1990, P INT C COMP AID DES, P130; Utgoff P. E., 1987, Proceedings of the Fourth International Workshop on Machine Learning; UTGOFF PE, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P596; Wahba A, 1995, LECT NOTES COMPUT SC, V987, P171; Widrow B., 1960, 1960 IRE WESCON CONV, P96; ZHUANG N, 1996, P IEEE INT S CIRC SY, V3, P414	58	11	11	1	1	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757			J ARTIF INTELL RES	J. Artif. Intell. Res.		2003	18						83	116				34	Computer Science, Artificial Intelligence	Computer Science	640VG	WOS:000180708200001		
J	Priebe, CE; Marchette, DJ; DeVinney, JG; Socolinsky, DA				Priebe, CE; Marchette, DJ; DeVinney, JG; Socolinsky, DA			Classification using class cover catch digraphs	JOURNAL OF CLASSIFICATION			English	Article						classification; random graph; class cover; prototype selection		We present a semiparametric mixture methodology for classification which involves modelling the class-conditional discriminant regions via collections of balls. The number, location, and size of the balls are determined adaptively through consideration of dominating sets for class cover catch digraphs based on proximity between training observations. Performance comparisons are presented on synthetic and real examples versus k-nearest neighbors, Fisher's linear discriminant and support vector machines. We demonstrate that the proposed semiparametric classifier has performance approaching that of the optimal parametric classifier in cases for which the optimal is available for comparison.	Johns Hopkins Univ, Dept Math Sci, Baltimore, MD 21218 USA; USN, Ctr Surface Warfare, Dahlgren, VA 22448 USA; Ctr Comp Sci, Bowie, MD 20715 USA; Equinox Corp, Baltimore, MD 21202 USA	Priebe, CE (reprint author), Johns Hopkins Univ, Dept Math Sci, Baltimore, MD 21218 USA.		Priebe, Carey E./A-3305-2010				ARORA S, 1997, HARDNESS APPROXIMATI; Chvatal V., 1979, Mathematics of Operations Research, V4, DOI 10.1287/moor.4.3.233; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASRATHY BV, 2000, P 15 INT C PATT REC, V2, P692; DeVinney J, 2003, THESIS J HOPKINS U B; DEVINNEY JG, 2002, IN PRESS COMPUTING S, P24; DEVINNEY JG, 2001, UNPUB CLASS COVER CA; Devroye L., 1996, PROBABILISTIC THEORY; Duda R O, 2001, PATTERN CLASSIFICATI; FRIEDMAN JH, 1996, UNPUB ANOTHER APPROA; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Hastie T, 1998, ANN STAT, V26, P451; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Jain A. K., 1996, IEEE COMPUTER    MAR, P31; Joachims T., 1999, ADV KERNEL METHODS S; Karonski M, 1999, COMB PROBAB COMPUT, V8, P131, DOI 10.1017/S0963548398003459; Karp R., 1972, REDUCIBILITY COMBINA; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Lebourgeois F., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547426; Maa JF, 1996, ANN STAT, V24, P1069; MAEHARA H, 1984, J GRAPH THEOR, V8, P431, DOI 10.1002/jgt.3190080312; Marchette DJ, 2003, PATTERN RECOGN, V36, P45, DOI 10.1016/S0031-3203(02)00042-0; OLSON T, 2001, IN PRESS MATH PROGRA; PAREKH AK, 1991, INFORM PROCESS LETT, V39, P237, DOI 10.1016/0020-0190(91)90021-9; Priebe CE, 2001, STAT PROBABIL LETT, V55, P239, DOI 10.1016/S0167-7152(01)00129-8; PRIEBE CE, 1999, CISST 99, P397; Priebe CE, 2001, COMPUT STAT DATA AN, V35, P475, DOI 10.1016/S0167-9473(00)00017-7; SCHOLKOPF B, 2001, NEURAL COMPUT, V13, P7; Skalak D., 1997, THESIS U MASSACHUSET; SMITH DL, 1995, P SOC PHOTO-OPT INS, V2496, P404, DOI 10.1117/12.211337; SOCOLINSKY DA, 2003, 634 J HOPK U DEP MAT; Vapnik V. N., 1995, NATURE STAT LEARNING; WITHERSPOON NH, 1995, P SOC PHOTO-OPT INS, V2496, P500, DOI 10.1117/12.211346	34	20	21	1	1	SPRINGER-VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	0176-4268			J CLASSIF	J. Classif.		2003	20	1					3	23		10.1007/s00357-003-0003-7		21	Mathematics, Interdisciplinary Applications; Psychology, Mathematical	Mathematics; Psychology	680KG	WOS:000182976000001		
S	Haykin, S		Ablameyko, S; Gori, M; Goras, L; Piuri, V		Haykin, S			Impact of neural networks on signal processing and communications	LIMITATIONS AND FUTURE TRENDS IN NEURAL COMPUTATION	NATO SCIENCE SERIES, SUB-SERIES III: COMPUTER AND SYSTEMS SCIENCES		English	Proceedings Paper	NATO Advanced Research Workshop on Limitations and Future Trends in Neural Computation	OCT 22-24, 2001	Siena, ITALY	NATO			PATTERN-CLASSIFICATION; SYSTEMS	Signal-processing and communication environments are characterized by two common characteristics: nonstationarity and non-Gaussianity, which make adaptive and learning systems a natural tool for dealing with these environments. In this chapter, we first discuss performance ingredients that are basic to the operation of adaptive and learning systems This discussion sets the stage for the following topics: Linear adaptive filters configured around a single computational unit. Autoregressive models for data parameterization and spectral analysis. Target tracking in an environment dominated by clutter (e.g., radar backscatter from an ocean environment) Learning the dynamics of a nonstationary environment, with particular emphasis given to recurrent multilayer perceptrons and related open research problems.	McMaster Univ, Hamilton, ON, Canada	Haykin, S (reprint author), McMaster Univ, Hamilton, ON, Canada.						ABUMOSTAFA YS, 1995, NEURAL COMPUT, V7, P639, DOI 10.1162/neco.1995.7.4.639; ALEXANDER ST, 1993, IEEE T SIGNAL PROCES, V41, P20, DOI 10.1109/TSP.1993.193124; BELLINI S, 1994, BLIND DECONVOLUTION, pCH2; Benesty J., 2001, ADV NETWORK ACOUSTIC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FELDKAMP LA, 2001, P 11 YAL WORKSH AD L, P78; FELDKAMP LA, 2001, INT JOINT C NEUR NET; Hassibi B, 2001, IEEE T AUTOMAT CONTR, V46, P309, DOI 10.1109/9.905700; Hassibi B, 1996, IEEE T SIGNAL PROCES, V44, P267, DOI 10.1109/78.485923; HAYKIN S, UNPUB P IEEE; Haykin S, 2001, IEEE SIGNAL PROC MAG, V18, P6, DOI 10.1109/MSP.2001.939832; Haykin S, 1998, P IEEE, V86, P2325, DOI 10.1109/5.726792; Haykin S., 2001, ADAPTIVE FILTER THEO; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Huber P.J., 1981, ROBUST STAT; JULIER SJ, 1997, 11 S AER DEF SENS SI; Kay S. M., 1988, MODERN SPECTRAL ESTI; KELLER JB, 1976, AM MATH MON, V83, P107, DOI 10.2307/2976988; KIRSCH A, 1996, INTRO MATH THEORY IN; Kohenen T., 1997, SELF ORG MAPS; Lanczos C., 1964, LINEAR DIFFERENTIAL; LO JT, 2001, ADAPTIVE VS ACCOMMOD, P1279; LUCKY RW, 1966, AT&T TECH J, V45, P255; NORGARD M, 2000, ADV DERIVATIVE FREE; PATEL G, 2001, KALMAN FILTERING NEU, pCH3; Pearl J, 1988, PROBABILISTIC REASON; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; PRISTLEY MB, 1981, SPECTRAL ANAL TIME S; PUSKORIUS GV, 1994, IEEE T NEURAL NETWOR, V5, P279, DOI 10.1109/72.279191; Schlogl A., 2000, ELECTROENCEPHALOGRAM; SONTAG ED, 1996, RECURRENT NEURAL NET; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Wan E.A., 2001, KALMAN FILTERING NEU; Widrow B., 1960, IRE WESCON CONV RE 4, P96; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270	35	0	0	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1387-6694		1-58603-324-7	NATO SC S SS III C S			2003	186						95	114				20	Computer Science, Artificial Intelligence	Computer Science	BY84E	WOS:000189476100005		
S	Sebban, M; Suchier, HM		Lavrac, N; Gamberger, D; Blockeel, H; Todorovski, L		Sebban, M; Suchier, HM			On boosting improvement: Error reduction and convergence speed-up	MACHINE LEARNING: ECML 2003	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	14th European Conference on Machine Learning	SEP 22-26, 2003	CAVTAT, CROATIA	Croatian Minist Sci & Technol, Slovenian Minist Educ, Sci & Sports, Knowledge Discovery Network Excellence			ALGORITHM; MAJORITY	Boosting is not only the most efficient ensemble learning method in practice, but also the one based on the most robust theoretical properties. The adaptive update of the sample distribution, which tends to increase the weight of the misclassified examples, allows to improve the performance of any learning algorithm. However, its ability to avoid overfitting has been challenged when boosting is applied to noisy data. This situation is frequent with the modern databases, built thanks to new data acquisition technologies, such as the Web. The convergence speed of boosting is also penalized on such databases, where there is a large overlap of probability density functions of the classes to learn (large Bayesian error). In this article, we propose a slight modification of the weight update rule of the algorithm ADABOOST. We show that by exploiting an adaptive measure of a local entropy, computed from a neighborhood graph built on the examples, it is possible to identify not only the outliers but also the examples located in the Bayesian error region. Taking into account this information, we correct the weight of the examples to improve the boosting performances. A broad experimental study shows the interest of our new algorithm, called iADABOOST.	Univ St Etienne, EURISE, F-42023 St Etienne 2, France	Sebban, M (reprint author), Univ St Etienne, EURISE, 23 Rue Dr Paul Michelon, F-42023 St Etienne 2, France.						Breiman L., 1996, 460 U CAL DEP STAT; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T.G., 1999, MACH LEARN, P1; DOMINGO C, 2000, 3 ANN C COMP LEARN T, P180; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1996, 13 INT C MACH LEARN, P148; Friedman J., 1998, ADDITIVE LOGISTIC RE; KWEK S, 2002, 13 EUR C MACH LEARN, P245; MACLIN R, 1998, AAAI IAAI, P700; Merz C.J., UCI REPOSITORY MACHI; NOCK R, 2002, 13 EUR C MACH LEARN; Nock R, 2001, PATTERN RECOGN LETT, V22, P413, DOI 10.1016/S0167-8655(00)00137-9; PREPARATA F, 1985, PATTERN RECOGNITION; RATSCH G, 1998, C NIPS; Schapire R. E., 1990, MACHINE LEARNING; SCHAPIRE RE, 1998, 11 ANN C COMP LEARN, P80; Schapire RE, 1998, ANN STAT, V26, P1651; SEBBAN M, 2003, J MACHINE LEARNING R; WILSON D, 1998, MACHINE LEARNING	23	0	0	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-20121-1	LECT NOTES ARTIF INT			2003	2837						349	360				12	Computer Science, Artificial Intelligence	Computer Science	BX96X	WOS:000187061900032		
B	Mill, J; Inoue, A		Walker, EL		Mill, J; Inoue, A			An application of fuzzy support vectors	NAFIPS'2003: 22ND INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS PROCEEDINGS			English	Proceedings Paper	22nd International Conference of the North-American-Fuzzy-Information-Processing-Society (NAFIPS)	JUL 24-26, 2003	CHICAGO, IL	IEEE Syst, Man & Cybernet Soc, IEEE, N Amer Fuzzy Informat Proc Soc				Support Vector Machines (SVMs) are a recently introduced Machine Learning technique. SVMs approach binary classification by attempting to find a hyperplane that separates the two categories of training vectors. This hyperplane is expressed as a function of a subset of the training vectors. These vectors are called support vectors. In this paper, we present a method of fuzzifying support vectors based off of the results of an SVM induction. We then propose a method of enhancing SVM induction using these fuzzy support vectors. We finish by presenting a computational example using the IRIS data set.	Spokane Falls Community Coll, Spokane, WA 99224 USA	Mill, J (reprint author), Spokane Falls Community Coll, Spokane, WA 99224 USA.						ABE S, 2001, UNPUB SUPPORT VECTOR; Blake C, 1998, UCI REPOSITORY MACHI; CHRISTIANINI N., 2000, INTRO SUPPORT VECTOR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T, 1998, P EUR C MACH LEARN E; JOACHIMS T, 2001, P INT C MACH LEARN; Klir G. J., 1995, FUZZY SETS FUZZY LOG; MILL J, 2002, THESIS E WASHINGTON; MILLER P, 2003, MIDW C ART INT COGN; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V. N., 1995, NATURE STAT LEARNING	12	0	0	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7918-7				2003							302	306				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BX38N	WOS:000185095000055		
B	Bian, HY; Mazlack, L		Walker, EL		Bian, HY; Mazlack, L			Fuzzy-rough nearest-neighbor classification approach	NAFIPS'2003: 22ND INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS PROCEEDINGS			English	Proceedings Paper	22nd International Conference of the North-American-Fuzzy-Information-Processing-Society (NAFIPS)	JUL 24-26, 2003	CHICAGO, IL	IEEE Syst, Man & Cybernet Soc, IEEE, N Amer Fuzzy Informat Proc Soc			PREDICTION	This paper proposes a new fuzzy-rough nearest-neighbor (NN1) approach based on the fuzzy-rough sets theory. This approach is more suitable to be used under partially exposed and unbalanced data set compared with crisp NN and fuzzy NN approach. Then the new method is applied to China listed company financial distress prediction, a typical classification task under partially exposed and unbalanced learning space. Results suggest that the compared with crisp and fuzzy nearest neighbor classification methods, this method provides more accurate prediction result under this research design.	Univ Cincinnati, ECECS Dept, Appl AI Lab, Cincinnati, OH 45221 USA	Bian, HY (reprint author), Univ Cincinnati, ECECS Dept, Appl AI Lab, Cincinnati, OH 45221 USA.						Altman E., 1993, CORPORATE FINANCIAL; Bezdek J. C., 1981, PATTERN RECOGNITION; Bian HY, 2002, P IASTED INT S ART I, P160; BIAN HY, 2002, THESIS CITY U HONG K; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dimitras AI, 1996, EUR J OPER RES, V90, P487, DOI 10.1016/0377-2217(95)00070-4; DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107; Duda R. O., 1973, PATTERN CLASSIFICATI; Estes W. K., 1994, CLASSIFICATION COGNI, V22; Keasey K., 1991, BRIT J MANAGE, V2, P89, DOI 10.1111/j.1467-8551.1991.tb00019.x; Keller J. M., 1985, IEEE T SYSTEMS MAN C, V15; Lin FY, 2001, KNOWL-BASED SYST, V14, P189, DOI 10.1016/S0950-7051(01)00096-X; Mitchell HB, 2001, INT J INTELL SYST, V16, P459, DOI 10.1002/int.1018; Murphy P.M., UCI REPOSITORY MACHI	14	1	1	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7918-7				2003							500	505				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BX38N	WOS:000185095000089		
S	Jankowski, N		Rutkowski, L; Kacprzyk, J		Jankowski, N			Discrete quasi-gradient features weighting algorithm	NEURAL NETWORKS AND SOFT COMPUTING	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	6th International Conference on Neural Networks and Soft Computing	JUN 11-15, 2002	ZAKOPANE, POLAND	Polish Neural Network Soc				A new method of feature weighting, useful also for feature extraction has been described. It is quite efficient and gives quite accurate results. Weighting algorithm may be used with any kind of learning algorithm. The weighting algorithm with k-nearest neighbors model was used to estimate the best feature base for a given distance measure. Results obtained with this algorithm clearly show its superior performance in several benchmark tests.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Ul Grudziadska 5, PL-87100 Torun, Poland.						Almuallim H., 1992, Proceedings of the Ninth Biennial Conference of the Canadian Society for Computational Studies of Intelligence; Bishop C.M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dash M., 1997, INTELLIGENT DATA ANA, V1; DUCH W, 1998, NEURAL PROCESS LETT, V7, P1; Duch W., 1999, INT JOINT C NEUR NET, P742; DUDA RO, 1997, PATTER CLASSIFICATIO; FERNANDEZ M, 1999, 5 INT WORK C ART NAT, P477; Grabczewski K., 2000, NEURAL NETWORKS SOFT, P202; JANKOWSKI N, 1999, THESIS NICHOLAS COPE; Merz C, 1998, UCI REPOSITORY MACHI; Schiffmann W., 1993, P EUR S ART NEUR NET, P97; WEISS SM, 1990, READINGS MACHINE; WILSON DR, 1996, INT C ART INT EXP SY, P11; WILSON DR, 1997, THESIS DEPT COMPUTER; ZARNDT F, 1995, THESIS DEPT COMPUTER	16	0	0	0	0	PHYSICA-VERLAG GMBH & CO	HEIDELBERG	TIERGARTENSTR 17, D-69121 HEIDELBERG, GERMANY	1615-3871		3-7908-0005-8	ADV SOFT COMP			2003							194	199				6	Computer Science, Artificial Intelligence	Computer Science	BW57F	WOS:000182433900026		
J	Chater, N; Oaksford, M; Nakisa, R; Redington, M				Chater, N; Oaksford, M; Nakisa, R; Redington, M			Fast, frugal, and rational: How rational norms explain behavior	ORGANIZATIONAL BEHAVIOR AND HUMAN DECISION PROCESSES			English	Review							TRACE MEMORY MODEL; DECISION-MAKING; NONCOMPENSATORY MODELS; COGNITIVE ARCHITECTURE; INDIVIDUAL-DIFFERENCES; WORD RECOGNITION; SYMBOLIC MODEL; INFORMATION; EXPECTATIONS; LIKELIHOOD	Much research on judgment and decision making has focussed on the adequacy of classical rationality as a description of human reasoning. But more recently it has been argued that classical rationality should also be rejected even as normative standards for human reasoning. For example, Gigerenzer and Goldstein (1996) and Gigerenzer and Todd (1999a) argue that reasoning involves "fast and frugal" algorithms which are not justified by rational norms, but which succeed in the environment. They provide three lines of argument for this view, based on: (A) the importance of the environment; (B) the existence of cognitive limitations; and (C) the fact that an algorithm with no apparent rational basis, Take-the-Best, succeeds in an judgment task (judging which of two cities is the larger; based on lists of features of each city). We reconsider (A)-(C), arguing that standard patterns of explanation in psychology and the social and biological sciences, use rational norms to explain why simple cognitive algorithms can succeed. We also present new computer simulations that compare Take-the-Best with other cognitive models (which use connectionist, exemplar-based, and decision-tree algorithms). Although Take-the-Best still performs well, it does not perform noticeably better than the other models. We conclude that these results provide no strong reason to prefer Take-the-Best over alternative cognitive models. (C) 2003 Elsevier Science (USA). All rights reserved.	Univ Warwick, Dept Psychol, Coventry CV4 7AL, W Midlands, England; Cardiff Univ, Sch Psychol, Cardiff CF1 3YG, S Glam, Wales; Univ Oxford, Dept Expt Psychol, Oxford OX1 3UD, England	Chater, N (reprint author), Univ Warwick, Dept Psychol, Coventry CV4 7AL, W Midlands, England.	nick.chater@warwick.ac.uk		Oaksford, Mike/0000-0003-3383-3642			AKERLOF GA, 1985, AM ECON REV, V75, P708; Allais M, 1953, ECONOMETRICA, V21, P503, DOI 10.2307/1907921; Anderson J., 1983, ARCHITECTURE COGNITI; Anderson J. R., 1990, ADAPTIVE CHARACTER T; ANDERSON JR, 1991, PSYCHOL SCI, V2, P396, DOI 10.1111/j.1467-9280.1991.tb00174.x; ANDERSON JR, 1989, PSYCHOL REV, V96, P703, DOI 10.1037/0033-295X.96.4.703; ANDERSON JR, 1991, BEHAV BRAIN SCI, V14, P471; ANDERSON NH, 1981, FDN INFORMATION INTE; ANSCOMBE FJ, 1963, ANN MATH STAT, V34, P199, DOI 10.1214/aoms/1177704255; ARROW KJ, 1996, RATIONAL FDN EC BEHA; ASHBY FG, 1995, J MATH PSYCHOL, V39, P216, DOI 10.1006/jmps.1995.1021; Ayton P, 1997, CAH PSYCHOL COGN, V16, P39; Ayton P, 2000, BEHAV BRAIN SCI, V23, P666, DOI 10.1017/S0140525X00233438; Barkow Jerome H., 1992, ADAPTED MIND EVOLUTI; Berger J. O., 1995, STAT DECISION THEORY; BERNADO JM, 1995, BAYESIAN THEORY; BRAINE MDS, 1978, PSYCHOL REV, V85, P1, DOI 10.1037//0033-295X.85.1.1; Broder A, 2000, J EXP PSYCHOL LEARN, V26, P1332, DOI 10.1037/0278-7393.26.5.1332; Brown GDA, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P121; BRUNNER D, 1992, ANIM BEHAV, V44, P597, DOI 10.1016/S0003-3472(05)80289-1; BRUNSWICK E, 1934, WAHRNEHMUNG GEGENSTA; BULLINARIA JA, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P84; Chater N., 1993, RATIONALITY, P31; Chater N, 2000, SYNTHESE, V122, P93, DOI 10.1023/A:1005272027245; CHATER N, 1990, COGNITION, V34, P93, DOI 10.1016/0010-0277(90)90033-G; Chater N., 1998, RATIONAL MODELS COGN, P21; Chater N, 1996, PSYCHOL REV, V103, P566, DOI 10.1037/0033-295X.103.3.566; Chater N., 1998, RATIONALITY UNCERTAI; Oaksford M., 1991, Mind and Language, V6, DOI 10.1111/j.1468-0017.1991.tb00173.x; CHATER N, 1995, CONNECTIONIST MODELS, P207; Cheng PW, 1997, PSYCHOL REV, V104, P367, DOI 10.1037//0033-295X.104.2.367; CHERNIAK Christopher, 1986, MINIMAL RATIONALITY; Chew S. H., 1983, ECONOMETRICA, V51, P1065; Chomsky Noam, 1980, RULES REPRESENTATION; Christiansen M. H., 1999, COGNITIVE SCI, V23; Christiansen Morten H., 2001, CONNECTIONIST PSYCHO; COHEN LJ, 1981, BEHAV BRAIN SCI, V4, P317; Colman Andrew M., 1995, GAME THEORY ITS APPL; COLTHEART M, 1993, PSYCHOL REV, V100, P589, DOI 10.1037/0033-295X.100.4.589; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAWFORD CB, 1987, SOCIOBIOLOGY PSYCHOL; CYERT RM, 1974, J POLIT ECON, V82, P521, DOI 10.1086/260210; Czerlinski J., 1999, SIMPLE HEURISTICS MA, P97; Davidson D., 1984, INQUIRIES TRUTH INTE; DAWES RM, 1974, PSYCHOL BULL, V81, P95, DOI 10.1037/h0037613; DECANIO SJ, 1979, Q J ECON, V93, P47, DOI 10.2307/1882597; Dhami MK, 2001, J BEHAV DECIS MAKING, V14, P141, DOI 10.1002/bdm.371; DHAMI MK, 2002, THINK REASONING, V7, P5; Dougherty MRP, 1999, PSYCHOL REV, V106, P180, DOI 10.1037/0033-295X.106.1.180; DUDA RO, 1973, PATTERNS CLASSIFICAT; EINHORN HJ, 1970, PSYCHOL BULL, V73, P221, DOI 10.1037/h0028695; EINHORN HJ, 1975, ORGAN BEHAV HUM PERF, V13, P171, DOI 10.1016/0030-5073(75)90044-6; EINHORN HJ, 1971, ORGAN BEHAV HUM PERF, V6, P1, DOI 10.1016/0030-5073(71)90002-X; ELLSBERG D, 1961, Q J ECON, V75, P643, DOI 10.2307/1884324; Elster J, 1986, RATIONAL CHOICE; Evans J. S. B, 1989, BIAS HUMAN REASONING; EVANS JSBT, 1993, HUMAN REASONING; EVANS JST, 1997, CAHIERS PSYCHOL COGN, V16, P1; FISHBURN PC, 1983, J ECON THEORY, V31, P293, DOI 10.1016/0022-0531(83)90079-0; FLOOD MM, 1958, MANAGE SCI, V5, P5, DOI 10.1287/mnsc.5.1.5; FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5; Frey B. J., 1998, GRAPHICAL MODELS MAC; FRIEDMAN M., 1953, METHODOLOGY POSITIVE; Friedman N., 1996, P 12 C UNC ART INT, P252; Gallistel C. R., 1990, ORG LEARNING; GANZACH Y, 1995, PSYCHOL BULL, V118, P422, DOI 10.1037//0033-2909.118.3.422; Garey M. R., 1979, COMPUTERS INTRACTABI; Gibson J. J., 1979, ECOLOGICAL APPROACH; GIGERENZER G, 1988, J EXP PSYCHOL HUMAN, V14, P513, DOI 10.1037/0096-1523.14.3.513; Gigerenzer G., 1987, COGNITION INTUITIVE; Gigerenzer G, 2001, DAHL WS ENV, P1; Gigerenzer G, 1996, PSYCHOL REV, V103, P650, DOI 10.1037//0033-295X.103.4.650; GIGERENZER G, 1995, PSYCHOL REV, V102, P684, DOI 10.1037//0033-295X.102.4.684; Gigerenzer G., 2000, ADAPTIVE THINKING RA; Gigerenzer G., 1999, SIMPLE HEURISTICS MA; Gigerenzer G., 1999, SIMPLE HEURISTICS MA, P75; Gigerenzer G, 2001, DAHL WS ENV, P37; Gigerenzer G., 1999, SIMPLE HEURISTICS MA, P141; Gigerenzer G, 1999, SIMPLE HEURISTICS MA, P3; Gigerenzer G., 1999, SIMPLE HEURISTICS MA, P37; GOOD IJ, 1971, FDN STAT INFERENCE; Hahn U, 1998, COGNITION, V65, P197, DOI 10.1016/S0010-0277(97)00044-9; HAMMOND KR, 1965, PSYCHOL REV, V72, P215, DOI 10.1037/h0021798; Harsanyi J. C., 1988, GEN THEORY EQUILIBRI; Hertwig R, 2000, BEHAV BRAIN SCI, V23, P678, DOI 10.1017/S0140525X00363439; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; HINTZMAN DL, 1988, PSYCHOL REV, V95, P528, DOI 10.1037/0033-295X.95.4.528; HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037//0033-295X.93.4.411; HINTZMAN DL, 1984, BEHAV RES METH INS C, V16, P96; Inhelder B., 1958, GROWTH LOGICAL THINK; INTRATOR N, 1993, ADV NEURAL INFORMATI, V5, P3; Jeannerod M, 1988, NEURAL BEHAV ORG GOA; JUSLIN P, 2001, UNPUB PROBABILITIES; KACELNIK A, 1998, RATIONAL MODELS COGN, P54; Kahneman D., 1982, JUDGMENT UNCERTAINTY; KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185; Kolodner J. L., 1993, CASE BASED REASONING; Kreps DM, 1990, COURSE MICROECONOMIC; Kripke S. A, 1982, WITTGENSTEIN RULES P; Ledyard J. O., 1995, HDB EXPT EC, P111; LEEUWENBERG E, 1988, PSYCHOL REV, V95, P485, DOI 10.1037//0033-295X.95.4.485; LIBBY R, 1976, ORGAN BEHAV HUM PERF, V16, P1, DOI 10.1016/0030-5073(76)90002-7; LINDLEY DV, 1956, ANN MATH STAT, V27, P986, DOI 10.1214/aoms/1177728069; LING CX, 1994, COGNITIVE SCI, V18, P595, DOI 10.1207/s15516709cog1804_3; LING CX, 1993, COGNITION, V49, P235, DOI 10.1016/0010-0277(93)90006-H; LOEWENSTEIN G., 1992, CHOICE TIME, P3, DOI DOI 10.1037/A0019486; LOOMES G, 1982, ECON J, V92, P805, DOI 10.2307/2232669; MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037//0033-295X.101.4.676; MACHINA MJ, 1982, ECONOMETRICA, V39, P277; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MACLEOD P, 1998, INTRO CONNECTIONIST; Marr D, 1982, VISION; Martignon L., 1999, SIMPLE HEURISTICS MA, P169; Martignon L., 1999, SIMPLE HEURISTICS MA, P119; Massaro D. W., 1987, SPEECH PERCEPTION EA; May KO, 1954, ECONOMETRICA, V22, P1, DOI 10.2307/1909827; Maynard Smith J., 1973, Nature London, V246, P15; McCloskey's Deirdre, 1985, RHETORIC EC; McDermott D., 1987, Computational Intelligence, V3, DOI 10.1111/j.1467-8640.1987.tb00183.x; McFarland D., 1981, QUANTITATIVE ETHOLOG; Meehl P. E, 1954, CLIN VERSUS STAT PRE; MESSICK DM, 1991, GAME EQUILIBRIUM MOD, V1, P304; Minsky M., 1969, PERCEPTRONS INTRO CO; MORTON J, 1969, PSYCHOL REV, V76, P165, DOI 10.1037/h0027366; MOVELLAN JR, 1995, PDPCNS954 CARN MELL; Movellan JR, 1996, PROCEEDINGS OF THE EIGHTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P381; MUTH JF, 1961, ECONOMETRICA, V29, P315, DOI 10.2307/1909635; Nash JF, 1950, ECONOMETRICA, V18, P155, DOI 10.2307/1907266; NEAL RM, 1993, ADV NEURAL INFORMATI, V5, P475; NELSON R, 1982, EVOLUTIONARY THEORY; Newell A., 1991, UNIFIED THEORIES COG; NEWELL A, 1982, ARTIF INTELL, V18, P87, DOI 10.1016/0004-3702(82)90012-1; NEWELL BR, 2001, UNPUB TAKE BEST LOOK; NOSOFSKY RM, 1990, J MATH PSYCHOL, V34, P393, DOI 10.1016/0022-2496(90)90020-A; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; Oaksford M., 1990, AI & Society, V4, DOI 10.1007/BF01889765; OAKSFORD M, 1994, PSYCHOL REV, V101, P608, DOI 10.1037//0033-295X.101.4.608; Oaksford M., 1998, RATIONAL MODELS COGN; Oaksford M., 1995, Thinking & Reasoning, V1, DOI 10.1080/13546789508251501; Over D. E., 1996, RATIONALITY REASONIN; PARIS J, 1992, UNCERTAIN REASONERS; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Payne JW, 1996, ORGAN BEHAV HUM DEC, V66, P131, DOI 10.1006/obhd.1996.0044; PAYNE JW, 1976, ORGAN BEHAV HUM PERF, V16, P366, DOI 10.1016/0030-5073(76)90022-2; PAYNE JW, 1988, J EXP PSYCHOL LEARN, V14, P534, DOI 10.1037//0278-7393.14.3.534; Payne JW, 1990, INSIGHTS DECISION MA, P129; Payne J.W., 1993, ADAPTIVE DECISION MA; Pearl J, 1988, PROBABILISTIC REASON; PERSSON M, 1999, UNPUB ECOLOGICAL RAT; Pinker S., 1998, MIND WORKS; Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56; POMERANTZ JR, 1987, HDB PERCEPTION HUMAN, V2; Pylyshyn Z. W., 1987, ROBOTS DILEMMA FRAME; Quine W. V. O., 1960, WORD OBJECT; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; REINER R, 1995, MIND MACH, V5, P373, DOI 10.1007/BF00974751; Rescorla R. A., 1972, CLASSICAL CONDITION, P64, DOI DOI 10.1016/J.COGPSYCH.2004.11.001; Rips L. J., 1994, PSYCHOL PROOF; Roth AE, 1996, RATIONAL FOUNDATIONS OF ECONOMIC BEHAVIOUR, P198; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; Samuelson P, 1937, REV ECON STUD, V4, P155, DOI DOI 10.2307/2967612; Savage LJ, 1954, FDN STAT; SAWYER J, 1966, PSYCHOL BULL, V66, P178, DOI 10.1037/h0023624; SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523; Shanks D. R., 1995, PSYCHOL ASS LEARNING; SHANKS DR, 1995, Q J EXP PSYCHOL-A, V48, P257; SHEPARD RN, 1967, DECISION MAKING, P257; Simon H., 1992, EC BOUNDED RATIONALI; SIMON HA, 1959, AM ECON REV, V49, P253; Stanovich K. E., 1999, WHO RATIONAL STUDIES; Stanovich K. E., 1998, THINK REASONING, V4, P289, DOI [DOI 10.1080/135467898394094, 10.1080/135467898394094]; Stanovich K. E., 1998, THINK REASONING, V4, P193; Stanovich KE, 2000, BEHAV BRAIN SCI, V23, P645, DOI 10.1017/S0140525X00003435; Stanovich KE, 1998, J EXP PSYCHOL GEN, V127, P161, DOI 10.1037/0096-3445.127.2.161; Stein E., 1996, GOOD REASON RATIONAL; Stephens D.W., 1986, FORAGING THEORY; STICK SP, 1990, FRAGMENTATION REASON; TARABAN R, 1988, J MEM LANG, V27, P597, DOI 10.1016/0749-596X(88)90011-3; TODD IA, 1993, ANIM BEHAV, V46, P765, DOI 10.1006/anbe.1993.1254; Todd P., 1999, SIMPLE HEURISTICS MA, P357; TVERSKY A, 1972, PSYCHOL REV, V79, P281, DOI 10.1037/h0032955; Tversky A., 1986, J BUS, V59, P251, DOI DOI 10.1086/296365; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; TVERSKY A, 1969, PSYCHOL REV, V76, P31, DOI 10.1037/h0026750; Van Damme Eric, 1991, STABILITY PERFECTION; vanderHelm PA, 1996, PSYCHOL REV, V103, P429, DOI 10.1037/0033-295X.103.3.429; VANS JST, 1982, PSYCHOL DEDUCTIVE RE; Von Helmholtz H., 1910, TREATISE PHYSL OPTIC, VIII; Von Neumann J, 1944, THEORY GAMES EC BEHA; Weber E. U., 1995, PSYCHOL LEARN MOTIV, V32, P33, DOI [10.1016/S0079-7421(08)60307-2, DOI 10.1016/50079-7421(08)60307-2]	193	62	62	4	14	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0749-5978			ORGAN BEHAV HUM DEC	Organ. Behav. Hum. Decis. Process.	JAN	2003	90	1					63	86		10.1016/S0749-5978(02)00508-3		24	Psychology, Applied; Management; Psychology, Social	Psychology; Business & Economics	668UU	WOS:000182312200005		
J	Bagui, SC; Bagui, S; Pal, K; Pal, NR				Bagui, SC; Bagui, S; Pal, K; Pal, NR			Breast cancer detection using rank nearest neighbor classification rules	PATTERN RECOGNITION			English	Article						classification rules; rank nearest neighbor rules; nearest neighbor rules; breast masses; breast cancer detection; cell nucleus; mean texture; worst mean area; error rate; Bayes error rate	DISCRIMINANT-ANALYSIS; NUCLEAR FEATURES; DIAGNOSIS; CYTOLOGY	In this article, we propose a new generalization of the rank nearest neighbor (RNN) rule for multivariate data for diagnosis of breast cancer. We study the performance of this rule using two well known databases and compare the results with the conventional k-NN rule. We observe that this rule performed remarkably well, and the computational complexity of the proposed k-RNN is much less than the conventional k-NN rule. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Indian Stat Inst, Elect & Commun Sci Unit, Kolkata 700035, W Bengal, India; Univ W Florida, Dept Math & Stat, Pensacola, FL 32514 USA; Univ W Florida, Dept Comp Sci, Pensacola, FL 32514 USA	Pal, NR (reprint author), Indian Stat Inst, Elect & Commun Sci Unit, 203 BT Rd, Kolkata 700035, W Bengal, India.	nikhil@isical.ac.in					ANDERSON TW, 1966, P 1 INT S AN; BAGUI SC, 1995, PATTERN RECOGN LETT, V16, P601, DOI 10.1016/0167-8655(95)80006-F; BAGUI SC, 1998, STATIST, V16, P181; Bennet K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cramer H, 1946, MATH METHODS STAT; DASGUPTA S, 1980, SANKHYA A, V42, P219; DENGLER J, 1993, IEEE T MED IMAGING, V12, P634, DOI 10.1109/42.251111; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; Fix E., 1951, 4 US AIR FORC SCH AV; Johnson R, 1998, APPL MULTIVARIATE ST; KARSSEMEIJER N, 1998, DIGITAL MAMOGRAPHY; Mangasarian OL, 1990, SIAM NEWS, V23, P1; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; RANDLES RH, 1978, J AM STAT ASSOC, V73, P379, DOI 10.2307/2286669; SHEN L, 1994, IEEE T MED IMAGING, V13, P263; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; Street William Nick, 1993, IS T SPIE 1993 INT S, V1905, P861; WOLBERG WH, 1995, HUM PATHOL, V26, P792, DOI 10.1016/0046-8177(95)90229-5; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; WOLBERG WH, 1994, CANCER LETT, V77, P163, DOI 10.1016/0304-3835(94)90099-X; Zhang J., 1992, P 9 INT MACH LEARN C, P470	22	17	17	1	2	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	JAN	2003	36	1					25	34	PII S0031-3202(02)00044-4	10.1016/S0031-3203(02)00044-4		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	612XP	WOS:000179101000003		
S	Barandela, R; Sanchez, JS; Garcia, V; Ferri, FJ		Perales, FJ		Barandela, R; Sanchez, JS; Garcia, V; Ferri, FJ			Learning from imbalanced sets through resampling and weighting	PATTERN RECOGNITION AND IMAGE ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st Iberian Conference on Pattern Recognition and Image Analysis	JUN 04-06, 2003	MALLORCA, SPAIN	MCyT, Int Assoc Pattern Recognit, European Union, Conselleria Innovacio Energia	UNIV ILLES BALEARS, DEPT CIENCIES MATH & INFORMAT			The problem of imbalanced training sets in supervised pattern recognition methods is receiving growing attention. Imbalanced training sample means that one class is represented by a large number of examples while the other is represented by only a few. It has been observed that this situation, which arises in several practical situations, may produce an important deterioration of the classification accuracy, in particular with patterns belonging to the less represented classes. In the present paper, we introduce a new approach to design an instance-based classifier in such imbalanced environments.	Inst Tecnol Toluca, Metepec 52140, Mexico; Dept Llenguatges Sistemas Informat, Castello 12071, Spain; Univ Valencia, Dept Informat, E-46100 Burjassot, Spain; Inst Geog, Havana, Cuba	Barandela, R (reprint author), Inst Tecnol Toluca, Av Tecnol SN, Metepec 52140, Mexico.		Ferri, Francesc/L-7216-2014; 	Ferri, Francesc/0000-0002-1543-3568; Sanchez Garreta, Jose Salvador/0000-0003-1053-4658; Garcia, Vicente/0000-0003-2820-2918			Barandela R., 2001, P 9 SPAN S PATT REC, P103; Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; CHAWLA NV, 2000, J ARTIFICIAL INTELLI, V16, P321; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Eavis T, 2000, LECT NOTES ARTIF INT, V1822, P280; Ezawa K, 1996, P 13 INT C MACH LEAR, P139; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FERRI FJ, 1998, LECT NOTES COMPUTER, V1451, P620; Gordon D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00317.x; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Lewis D.D., 1994, P 11 INT C MACH LEAR, P148; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Swets J., 2000, SCI AM, P82; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Woods K. S., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000698	24	2	2	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40217-9	LECT NOTES COMPUT SC			2003	2652						80	88				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BX28N	WOS:000184832300010		
B	Li, J; Liang, QL; Manry, MT		Gong, K; Niu, ZH		Li, J; Liang, QL; Manry, MT			Adaptive channel equalization for satellite communications with multipath based on unsupervised learning algorithm	PIMRC 2003: 14TH IEEE 2003 INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS PROCEEDINGS, VOLS 1-3 2003			English	Proceedings Paper	14th IEEE International Symposium on Personal, Indoor and Mobile Radio Communications	SEP 07-10, 2003	BEIJING, PEOPLES R CHINA	Chinese Inst Elect, King Coll London, Tsinghua Univ, IEEE Beijing Sect, EiC, IEE, IEEE Commun Soc		equalization; satillite cominmnication; NNC; unsupervised learining; TDMA	INTERFERENCE; NETWORKS	Channel equalization has been revealed to be a classification problem by some recent applications of clustering and neural network techniques. In this paper a new unsupervised learning (clustering) algorithm, adaptive nearest neighbor classifier (ANNC) is presented for channel equalization. ANNC can mine more channel characteristics than the recently proposed nearest neighbor (NNC) classifier. The proposed method is applied to a time-division-multiple-access (TDMA) satellite communication system with burst digital transmission. The improvement of the proposed algorithm over the recently reported NNC approach is clearly demonstrated.	Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA	Li, J (reprint author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.						BENELLI G, 1991, P INT C GLOBECOM 91, P1469; CHEN S, 1993, IEEE T NEURAL NETWOR, V4, P570, DOI 10.1109/72.238312; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVELLA R, 1989, IEEE J SEL AREA COMM, V7, P122, DOI 10.1109/49.16853; Duda R. O., 1999, PATTERN CLASSIFICATI; FORNEY GD, 1972, IEEE T INFORM THEORY, V18, P363, DOI 10.1109/TIT.1972.1054829; Hussain A, 1997, IEEE T COMMUN, V45, P1358, DOI 10.1109/26.649741; JADES WC, 1993, MICROWAVE MOBILE COM; KECHRIOTIS G, 1994, IEEE T NEURAL NETWOR, V5, P267, DOI 10.1109/72.279190; LIANG Q, 2002, IEEE 55 VEH TECHN C, V4, P1869; LIANG Q, 2002, P IEEE GLOB 02 TAIP; Liang QL, 2000, IEEE T FUZZY SYST, V8, P551; SAVAZZI P, 2000, IEEE J SEL AREA COMM, V16, P418; SKLLAR B, 1997, IEEE COMMUN MAG, V35, P148	14	0	0	0	0	PUBLISHING HOUSE ELECTRONICS INDUSTRY	BEIJING	PO BOX 173 WANSHOU ROAD, BEIJING 100036, PEOPLES R CHINA			7-5053-5066-8				2003							730	734				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BY28C	WOS:000188739500151		
B	Lisboa, FOSS; Nicoletti, MD; Ramer, A		Nasaoui, O; Frigui, H; Keller, JM		Lisboa, FOSS; Nicoletti, MD; Ramer, A			Experiencing fuzzy exemplar-based classifier systems	PROCEEDINGS OF THE 12TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)		English	Proceedings Paper	12th IEEE International Conference on Fuzzy Systems	MAY 25-28, 2003	ST LOUIS, MO	IEEE, IEEE Neural Networks Soc				The NGE model (implemented by EACH) is an incremental form of inductive learning from examples that generalizes a given training set into hypotheses represented as a set of hyperrectangles in an n-dimensional Euclidean space. The NGE algorithm can be considered a descendent of either NN or KNN algorithms. This paper focuses on a fuzzy version of the NGE algorithm, aiming at comparing its performance with a fuzzy version of the NN algorithm and, of the KNN algorithm.	USP, IFSC, BR-13560970 Sao Carlos, SP, Brazil	Lisboa, FOSS (reprint author), USP, IFSC, BR-13560970 Sao Carlos, SP, Brazil.		Lisboa, Flavia/I-6767-2012				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Klir G. J., 1995, FUZZY SETS FUZZY LOG; KOLODNER J, 1984, RETRIEVAL ORGANIZATI; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Merz C, 1998, UCI REPOSITORY MACHI; Sadegh-Zadeh K, 1999, ARTIF INTELL MED, V15, P309, DOI 10.1016/S0933-3657(98)00060-8; SALZBERG S, 1991, MACH LEARN, V6, P252; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5	11	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7810-5	IEEE INT CONF FUZZY			2003							90	95				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BW87V	WOS:000183448800016		
B	Auephanwiriyakul, S		Nasaoui, O; Frigui, H; Keller, JM		Auephanwiriyakul, S			A linguistic K-nearest prototype with an application to management surveys	PROCEEDINGS OF THE 12TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)		English	Proceedings Paper	12th IEEE International Conference on Fuzzy Systems	MAY 25-28, 2003	ST LOUIS, MO	IEEE, IEEE Neural Networks Soc			FUZZY	For many years, one of the, problems in pattern recognition is classification. There are many methods' that deal with this type of problem. The data sets are sometimes in the binary form (real number) and represented by vectors of binary numbers (real numbers) although there are uncertainties in the data, e.g., data collected in management questionnaires. In this paper, we developed a linguistic K-nearest prototype algorithm with vectors of fuzzy numbers as inputs. This algorithm is based on the extension principle and the decomposition theorem. We apply this algorithm to linguistic vectors derived from a set of thirty-nine subjects answering questions about students' satisfaction with communication to their university.	Chiang Mai Univ, Dept Comp Engn, Chiang Mai 50200, Thailand	Auephanwiriyakul, S (reprint author), Chiang Mai Univ, Dept Comp Engn, Chiang Mai 50200, Thailand.						ADRIAN A, 1998, P IEEE INT C SYST MA, P2144; AUEPHANWIRIYAKU.S, 2002, IEEE INT C FUZZ SYST, P1321; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dong W., 1985, CIVIL ENG SYSTEMS, V2, P201, DOI 10.1080/02630258508970407; DONG WM, 1987, FUZZY SET SYST, V21, P183, DOI 10.1016/0165-0114(87)90163-1; Dubois D., 1980, FUZZY SETS SYSTEMS T; Duda R. O., 1973, PATTERN CLASSIFICATI; KALEVA O, 1984, FUZZY SET SYST, V12, P215, DOI 10.1016/0165-0114(84)90069-1; Keller J. M., 2000, P 9 IEEE INT C FUZZ, P387; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Klir G. J., 1995, FUZZY SETS FUZZY LOG; KRAMOSIL I, 1975, KYBERNETIKA, V11, P336; Mares M., 1994, COMPUTATION FUZZY QU; Mizumoto M., 1979, ADV FUZZY SET THEORY, P153; Moore R.E., 1966, INTERVAL ANAL; Yager R. R., 1978, P CDC, P1435; Zadeh L., 1973, IEEE T SYS MAN CYB, V3	17	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7810-5	IEEE INT CONF FUZZY			2003							784	788				5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BW87V	WOS:000183448800136		
B	Gupta, MR; Gray, RM			IEEE	Gupta, MR; Gray, RM			Reducing bias in supervised learning	PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING			English	Proceedings Paper	12th IEEE Workshop on Statistical Signal Processing	SEP 28-OCT 01, 2003	St Louis, MO	IEEE Signal Proc Soc, DARPA, USAF Res Lab, Off Naval Res, Natl Sci Fdn				Nonparametric statistical supervised learning methods often suffer from bias caused by non-uniformity of the probability distribution of training samples. We discuss this problem and propose a new nonparametric neighborhood method for classification and estimation that significantly reduces the bias. Simulations exemplify the advantages, and theoretical results are noted.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA	Gupta, MR (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.						Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Gray R. M., 1997, P COMPR COMPL SEQ C, P172; Gupta M. R., 2003, THESIS STANFORD U ST; Hastie T, 2001, ELEMENTS STAT LEARNI; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Kang H.R., 1997, COLOR TECHNOLOGY ELE; KOHONEN T, 1988, 2ND P IEEE INT C NEU, V1, P61; OBRIEN D, 2003, P INT C IM P; Rovatti R, 1998, IEEE T COMPUT, V47, P894, DOI 10.1109/12.707591; Wu N., 1997, MAXIMUM ENTROPY METH	12	3	3	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7997-7				2003							482	485				4	Computer Science, Information Systems; Mathematics, Interdisciplinary Applications; Imaging Science & Photographic Technology; Telecommunications	Computer Science; Mathematics; Imaging Science & Photographic Technology; Telecommunications	BY73T	WOS:000189451000134		
S	Jankowski, N			IEEE; IEEE	Jankowski, N			Discrete feature weighting & selection algorithm	PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS 2003, VOLS 1-4	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUL 20-24, 2003	PORTLAND, OR	Int Neural Network Soc, IEEE Neural Networks Soc				A new method of feature weighting, useful also for feature selection has been described. It is quite efficient and gives quite accurate results. In general weighting algorithm may be used with any kind of learning algorithm. The weighting algorithm with k-nearest neighbors model was used to estimate the optimal feature base for a given distance measure. Results obtained with this algorithm clearly show its superior performance in several benchmark tests.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Ul Grudziadzka 5, PL-87100 Torun, Poland.		Jankowski, Norbert/H-1071-2014				ADAMCZAK R, 1997, 3 C NEUR NETW THEIR, P65; Almuallim H., 1992, Proceedings of the Ninth Biennial Conference of the Canadian Society for Computational Studies of Intelligence; Bennett K.P., 1997, SUPPORT VECTOR MACHI; Bishop C.M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dash M., 1997, INTELLIGENT DATA ANA, V1; DUCH W, 1998, NEURAL PROCESS LETT, V7, P1; Duch W., 1999, INT JOINT C NEUR NET, P742; DUDA RO, 1997, PATTER CLASSIFICATIO; FERNANDEZ M, 1999, 5 INT WORK C ART NAT, P477; Grabczewski K., 2000, NEURAL NETWORKS SOFT, P202; JANKOWSKI N, 1999, THESIS N COPERNICUS; Merz C, 1998, UCI REPOSITORY MACHI; Michie D., 1994, MACHINE LEARNING NEU; Schiffmann W., 1993, P EUR S ART NEUR NET, P97; SHANG N, 1996, P ICONIP 96; Ster B., 1996, P INT C ENG APPL NEU, P427; Weiss S.M., 1990, READINGS MACHINE LEA; WILSON DR, 1997, THESIS B YOUNG U; WILSON DR, 1996, INT C ART INT EXP SY, P11; ZARNDT F, 1995, THESIS B YOUNG U	21	3	3	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-7898-9	IEEE IJCNN			2003							636	641				6	Computer Science, Artificial Intelligence	Computer Science	BX30P	WOS:000184903300116		
S	Timar, G; Balya, D; Szatmari, I; Rekeczky, C			IEEE; IEEE	Timar, G; Balya, D; Szatmari, I; Rekeczky, C			Feature guided visual attention with topographic array processing and neural network-based classification	PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS 2003, VOLS 1-4	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUL 20-24, 2003	PORTLAND, OR	Int Neural Network Soc, IEEE Neural Networks Soc			CNN; PARALLEL; MACHINE	Biological systems are constantly engulfed in sensory input that must be processed. Attention has evolved to cut down on the magnitude of the input and enable the agent to analyze the most important parts of the information. This is especially true for the visual system where the appropriate field of view and scale must be determined. Our system receives a video flow with considerably higher resolution than the resolution of the cellular neural net based visual microprocessor that computes the topographic features of the input. This process requires a dynamic positioning of the processing window in the video flow. We have developed a fast attention and selection algorithm that allows the system to choose the field of view and scale (zoom) level for the next frame based on the features computed from the current frame and the output of the ART or NNC-based classifiers. The algorithmic framework and the hardware architecture of the system are presented along with experimental chip results for several video flows recorded in flying vehicles.	Hungarian Acad Sci, Inst Comp & Automat, Anal & Neural Comp Lab, H-1111 Budapest, Hungary	Timar, G (reprint author), Hungarian Acad Sci, Inst Comp & Automat, Anal & Neural Comp Lab, Kende U 13-17, H-1111 Budapest, Hungary.						*AN COMP LTD, 2002, AL PRO R2 3; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; Chua LO, 1997, INT J BIFURCAT CHAOS, V7, P2219, DOI 10.1142/S0218127497001618; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ESPEJO S, 1998, P 5 INT C EL CIRC SY, P203; Kaufman L., 1990, FINDING GROUPS DATA; LINAN G, 2001, EUR C CIRC THEOR DES, P345; Niebur E, 1998, ATTENTIVE BRAIN, P163; Rekeczky C, 1999, J VLSI SIG PROCESS S, V23, P373, DOI 10.1023/A:1008153320440; Roska B, 2001, NATURE, V410, P583, DOI 10.1038/35069068; ROSKA T, 1993, IEEE T CIRCUITS-II, V40, P163, DOI 10.1109/82.222815; THAKOOR S, 2002, ARTIFICIAL LIFE, V8; WERBLIN F, 1995, INT J CIRC THEOR APP, V23, P541, DOI 10.1002/cta.4490230602; ZARANDY A, 2003, IN PRESS IEEE J CIRC	15	2	2	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-7898-9	IEEE IJCNN			2003							1492	1496				5	Computer Science, Artificial Intelligence	Computer Science	BX30P	WOS:000184903300272		
B	Zeng, XC; Martinez, T			IEEE; IEEE	Zeng, XC; Martinez, T			A noise filtering method using neural networks	SCIMA 2003: IEEE INTERNATIONAL WORKSHOP ON SOFT COMPUTING TECHNIQUES IN INSTRUMENTATION, MEASUREMENT AND RELATED APPLICATIONS			English	Proceedings Paper	IEEE International Workshop on Soft Computing Techniques in Instrumentation, Measurement and Related Applications	MAY   17, 2003	PROVO, UT	IEEE Instrumentat & Measurement Soc	BRIGHAM YOUNG UNIV		NEAREST NEIGHBOR RULE; LEARNING ALGORITHMS; CLASSIFICATION	During the data collecting and labeling process it is possible for noise to. be introduced into a data set. As a result, the quality of the data set degrades and experiments and inferences derived from the data set become less reliable. In this paper we present an algorithm, called ANR (automatic noise reduction), as a filtering mechanism to identify and remove noisy data items whose classes have been mislabeled The underlying mechanism behind ANR is based on a framework of multi-layer artificial neural networks. ANR assigns each data item a soft class label in the form of a class probability vector, which is initialized to the original class label and can be modified during training. When the noise level is reasonably small (< 30%), the non-noisy data is dominant in determining the network architecture and its output, and thus a mechanism for correcting mislabeled data can be provided by aligning class probability vector with the network output. With a learning procedure for class probability vector based on its difference from the network output, the probability of a mislabeled class gradually becomes smaller while that of the correct class becomes larger, which eventually causes a correction of mislabeled data after sufficient training. After training, those data items whose classes have been relabeled are then treated as noisy data and removed from the data set. We evaluate the performance of the ANR based on 12 data sets drawn from the UCI data repository. The results show that ANR is capable of identifying a significant portion of noisy data. An average increase in accuracy of 24.5% can be achieved at a noise level of 25% by using ANR as a training data filter for a nearest neighbor classifier, as compared to the one without using ANR.	Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Zeng, XC (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.						Aha D. W., 1989, P 11 INT JOINT C ART, P794; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; Gamberger D., 1996, P 7 INT WORKSH ALG L, P199; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; John G. H., 1995, P 1 INT C KNOWL DISC, P174; Merz C. J., 1996, UCI REPOSITORY MACHI; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Teng C. M., 1999, P 16 INT C MACH LEAR, P239; TENG CM, 2000, LECT NOTES AI; WILSON D, 1972, IEEE T SYST MAN CYB, V6, P448; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WILSON DR, 1997, MACH LEARN, P403; Winston P. H., 1975, PSYCHOL COMPUTER VIS; Zeng X., 2001, INTELL DATA ANAL, V5, P491	20	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-7711-7				2003							26	31				6	Computer Science, Artificial Intelligence	Computer Science	BX02K	WOS:000183992100005		
B	Shibata, T; Kato, T; Wada, T		Wu, XD; Tuzhilin, A; Shavlik, J		Shibata, T; Kato, T; Wada, T			K-D decision tree: An accelerated and memory efficient nearest neighbor classifier	THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	MELBOURNE, FL	IEEE Comp Soc TCCI, IEEE Comp Soc TCPAMI			RULE; ALGORITHM	Most nearest neighbor (NN) classifiers employ NN search algorithms for the acceleration. However, NN classification does not always require the NN search. Based on this idea, we propose a novel algorithm named k-d decision tree (KDDT). Since KDDT uses Voronoi condensed prototypes, it is less memory consuming than naive NN classifiers. We have confirmed that KDDT is much faster than NN search based classifiers through the comparative, experiment (from 9 to 369 times faster).	Wakayama Univ, Fac Syst Engn, Wakayama, Japan	Shibata, T (reprint author), Wakayama Univ, Fac Syst Engn, Wakayama, Japan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AHA W, 1989, P 11 IJCAI, P794; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BENTLEY L, 1975, COMMUNICATIONS ACM, V18; BHATTACHARYA RS, 1981, INT S INF THEOR SANT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; Vapnik V. N., 1995, NATURE STAT LEARNING	14	1	1	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1978-4				2003							641	644				4	Computer Science, Artificial Intelligence	Computer Science	BY34Z	WOS:000188999400102		
B	Zhu, HW; Basir, O		Wu, XD; Tuzhilin, A; Shavlik, J		Zhu, HW; Basir, O			A K-NN associated fuzzy evidential reasoning classifier with adaptive neighbor selection	THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	MELBOURNE, FL	IEEE Comp Soc TCCI, IEEE Comp Soc TCPAMI				The paper presents a fuzzy evidential reasoning algorithm in light of the Dempster-Shafer evidence theory and the K-nearest neighbor algorithm for pattern classification. Given an input pattern to be classified, each of its K nearest neighbors is viewed as an evidence source, in terms of a fuzzy evidence structure. The distance between the input pattern and each of its K nearest neighbors is used for mass determination while the contextual information of the nearest neighbor in the training sample space is formulated by a fuzzy set in determining a fuzzy focal element. Therefore, pooling evidence provided by neighbors is realized by a fuzzy evidential reasoning, where feature selection is further considered through ranking and adaptive combination of neighbors. A fast implementation scheme of the fuzzy evidential reasoning is also developed. Experimental results of classifying multi-channel remote sensing images have shown that the proposed approach outperforms the K-nearest neighbor (K-NN) algorithm [1], the fuzzy K-nearest neighbor (F-KNN) algorithm [2], the evidence-theoretic Knearest neighbor (E-KNN) algorithm [3], and the fuzzy extended version of E-KNN (FE-KNN) [4], in terms of the classification accuracy and insensitivity to the number K of nearest neighbors.	Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada	Zhu, HW (reprint author), Univ Waterloo, Dept Syst Design Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Giacinto G, 2000, PATTERN RECOGN LETT, V21, P385, DOI 10.1016/S0167-8655(00)00006-4; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Shafer G., 1976, MATH THEORY EVIDENCE; ZHU H, 2003, P 5 IEEE INT S COMP; Zouhal L.M., 1997, P 2 INT ICSC S FUZZ, P294	7	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-1978-4				2003							709	712				4	Computer Science, Artificial Intelligence	Computer Science	BY34Z	WOS:000188999400119		
J	Roggo, Y; Duponchel, L; Huvenne, JP				Roggo, Y; Duponchel, L; Huvenne, JP			Comparison of supervised pattern recognition methods with McNemar's statistical test - Application to qualitative analysis of sugar beet by near-infrared spectroscopy	ANALYTICA CHIMICA ACTA			English	Article						classification; supervised pattern recognition method; McNemar's test; NIRS; sugar beet	PROBABILISTIC NEURAL NETWORKS; CLASSIFICATION; SPECTRA; ALGORITHMS; REGRESSION; EXCIPIENTS; NEIGHBOR; HOLMES	The application of supervised pattern recognition methodology is becoming important within chemistry. The aim of the study is to compare classification method accuracies by the use of a McNemar's statistical test. Three qualitative parameters of sugar beet are studied: disease resistance (DR), geographical origins and crop periods. Samples are analyzed by near-infrared spectroscopy (NIRS) and by wet chemical analysis (WCA). Firstly, the performances of eight well-known classification methods on NIRS data are compared: Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN) method, Soft Independent Modeling of Class Analogy (SIMCA), Discriminant Partial Least Squares (DPLS), Procrustes Discriminant Analysis (PDA), Classification And Regression Tree (CART), Probabilistic Neural Network (PNN) and Learning Vector Quantization (LVQ) neural network are computed. Among the three data sets, SIMCA, DPLS and PDA have the highest classification accuracies. LDA and KNN are not significantly different. The non-linear neural methods give the less accurate results. The three most accurate methods are linear, non-parametric and based on modeling methods. Secondly, we want to emphasize the power of near-infrared reflectance data for sample discrimination. McNemar's tests compare classification developed with WCA or with NIRS data. For two of the three data sets, the classification results are significantly improved by the use of NIRS data. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Sci & Technol, CNRS, UMR 8516, Lab Spectrochim Infrarouge & Raman, F-59655 Villeneuve Dascq, France	Roggo, Y (reprint author), Univ Sci & Technol, CNRS, UMR 8516, Lab Spectrochim Infrarouge & Raman, Batiment C5, F-59655 Villeneuve Dascq, France.		roggo, yves/F-2214-2011; 	roggo, yves/0000-0003-3509-7642			Alsberg BK, 1997, ANAL CHIM ACTA, V348, P389, DOI 10.1016/S0003-2670(97)00064-0; Armanino C, 2002, ANAL CHIM ACTA, V454, P315, DOI 10.1016/S0003-2670(01)01548-3; BARHAM D, 1972, ANALYST, V97, P142, DOI 10.1039/an9729700142; BARNES RJ, 1989, APPL SPECTROSC, V43, P772, DOI 10.1366/0003702894202201; Breiman L., 1984, CLASSIFICATION REGRE; BUCCI R, 2002, J AGR FOOD CHEM, V20, P413; Burnham AJ, 1996, J CHEMOMETR, V10, P31, DOI 10.1002/(SICI)1099-128X(199601)10:1<31::AID-CEM398>3.0.CO;2-1; Candolfi A, 1999, J PHARMACEUT BIOMED, V21, P115, DOI 10.1016/S0731-7085(99)00125-9; CANDOLFI A, 1998, J PHARM BIOMED ANAL, V16, P1229; Cappelli C, 2002, COMPUT STAT DATA AN, V38, P285, DOI 10.1016/S0167-9473(01)00044-5; Chapman WW, 2001, J BIOMED INFORM, V34, P4, DOI 10.1006/jbin.2001.1000; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demuth H., 2001, NEURAL NETWORK TOOLB; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Everitt B. S., 1977, ANAL CONTINGENCY TAB; Fisher RA, 1935, DESIGN EXPT; *FOSS, 2001, MAN UT FOSS FRANC SU; Gonzalez-Arjona D, 2001, CHEMOMETR INTELL LAB, V57, P133, DOI 10.1016/S0169-7439(01)00128-9; Gonzalez-Arjona D, 1999, ANAL CHIM ACTA, V381, P257, DOI 10.1016/S0003-2670(98)00764-8; Gonzalez-Arjona D, 1999, TALANTA, V49, P189, DOI 10.1016/S0039-9140(98)00354-3; *ICUMSA, 1994, 61 ICUMSA GS; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1989, SELF ORG ASSOCIATIVE; Kramer K, 2000, ANAL CHIM ACTA, V420, P155, DOI 10.1016/S0003-2670(00)00877-1; Martens H., 1989, MULTIVARIATE CALIBRA; MARTIN M, 1996, ANAL CHIM ACTA, V350, P191; Massart D. L., 1988, CHEMOMETRICS TXB; Osborn B.G., 1993, PRACTICAL NIR SPECTR; PALLARA A, 1992, STAT APPL, V4, P255; Pomeranz Y., 1994, FOOD ANAL THEORY PRA; Roggo Y, 2002, J NEAR INFRARED SPEC, V10, P137; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; Sharaf M. A., 1986, CHEMOMETRICS, P228; Simon L, 2001, BIOCHEM ENG J, V7, P41, DOI 10.1016/S1369-703X(00)00102-9; Smola N, 2000, ANAL CHIM ACTA, V410, P203, DOI 10.1016/S0003-2670(99)00891-0; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; STAHLE L, 1987, Journal of Chemometrics, V1, P185, DOI 10.1002/cem.1180010306; TAN C, 2002, INFORM PROCESS MANAG, V38, P329; Tenenhaus M., 1998, REGRESSION PLS; VANDEGINSTE G, 1988, HDB CHEMOMETRICS QUA, P207; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wu W, 1997, ANAL CHIM ACTA, V349, P253, DOI 10.1016/S0003-2670(97)00285-7	45	53	55	1	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670			ANAL CHIM ACTA	Anal. Chim. Acta	FEB 3	2003	477	2					187	200	PII S0003-2670(02)01422-8	10.1016/S0003-2670(02)01422-8		14	Chemistry, Analytical	Chemistry	636CR	WOS:000180437400002		
J	Emrahoglu, N; Yegingil, I; Pestemalci, V; Senkal, O; Kandirmaz, HM				Emrahoglu, N; Yegingil, I; Pestemalci, V; Senkal, O; Kandirmaz, HM			Comparison of a new algorithm with the supervised classifications	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article								In this study, a new classification algorithm in which only the selected pixels have been attempted to be classified (selected pixels classification: SPC) has been introduced and compared with the well known supervised classification methods such as maximum likelihood, minimum distance, nearest neighbour and condensed nearest neighbour. To examine the algorithm, Landsat Thematic Mapper (TM) data have been used to classify the crop cover in the selected region. It is clearly demonstrated that the SPC method has the higher accuracy with comparable CPU times.	Cukurova Univ, Dept Phys, Adana, Turkey	Emrahoglu, N (reprint author), Cukurova Univ, Dept Phys, Adana, Turkey.						BENELLI G, 1987, WORKSH REM SENS TECH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; ENGVALL JL, 1977, REMOTE SENS ENVIRON, V6, P303, DOI 10.1016/0034-4257(77)90050-5; Fix E., DISCRIMINATORY ANAL; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hansen M, 1996, INT J REMOTE SENS, V17, P1075; HART PE, 1968, IEEE T INFORMATION T, V14, P516; Hord R. M., 1982, DIGITAL IMAGE PROCES; INCE F, 1986, INT J REMOTE SENS, V8, P1829; LEE T, 1985, INT J REMOTE SENS, V6, P75; PESTEMALCI V, 1996, TURKISH J PHYS, V20, P490; RICHARDS JA, 1984, REMOTE SENS ENVIRON, V16, P35, DOI 10.1016/0034-4257(84)90025-7	13	8	8	2	8	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161			INT J REMOTE SENS	Int. J. Remote Sens.	FEB 20	2003	24	4					649	655		10.1080/01431160210145597		7	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	653EK	WOS:000181422100003		
J	Chang, DH; Kothari, R; Islam, S				Chang, DH; Kothari, R; Islam, S			Classification of soil texture using remotely, sensed brightness temperature over the southern great plains	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						artificial neural network (ANN); remote sensing; soil moisture; soil texture	PHYSICAL-PROPERTIES; NEURAL-NETWORK; INFORMATION; LANDSCAPE; SCALE; WATER; MODEL	This study explores the use of artificial neural networks (ANNs) models and brightness temperature from the Southern Great Plains in the United States to classify soil into different textures. Previous studies using ANN models and brightness temperature in a single drying cycle suggested that they might contain sufficient features to classify soil into three categories. To classify soil into more than three groups and to explore the limits of classification accuracy, this paper suggests the use of multiple-drying-cycle brightness temperature data. We have performed several experiments with feed-forward neural network (FFNN) models, and the results suggest that the maximum achievable classification accuracy through the use of multiple-drying-cycle brightness temperature is about 80%. It appears that the rapidly changing space-time evolution of brightness temperature will restrict the FFNN model performance. Motivated by these observations, we have used a simple prototype-based classifier, known as the 1-NN model, and achieved 86% classification accuracy for six textural groups. A comparison of error regions predicted by both models suggests that for the given input representation maximum achievable accuracy for classification into six soil texture types is about 93%.	Chaiyang Univ Technol, Dept Environm Engn, Wufeng, Taiwan; Chaiyang Univ Technol, Grad Inst Environm Engn & Management, Wufeng, Taiwan; IBM Corp, India Res Lab, New Delhi 110016, India; Univ Cincinnati, Dept Civil & Environm Engn, Cincinnati Earth Syst Sci Program, Cincinnati, OH 45221 USA	Chang, DH (reprint author), Chaiyang Univ Technol, Dept Environm Engn, Wufeng, Taiwan.						BAND LE, 1995, HYDROL PROCESS, V9, P401, DOI 10.1002/hyp.3360090312; Bishop C.M., 1996, NEURAL NETWORKS PATT; Burke EJ, 1997, WATER RESOUR RES, V33, P1689, DOI 10.1029/97WR01000; CAMILLO PJ, 1986, IEEE T GEOSCI REMOTE, V24, P930, DOI 10.1109/TGRS.1986.289708; Chang DH, 2000, REMOTE SENS ENVIRON, V74, P534, DOI 10.1016/S0034-4257(00)00144-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Hollenbeck KJ, 1996, WATER RESOUR RES, V32, P139, DOI 10.1029/95WR02916; Jackson T. J., 1995, REMOTE SENS ENVIRON, V53, P27; Jackson TJ, 1999, IEEE T GEOSCI REMOTE, V37, P2136, DOI 10.1109/36.789610; KONDO J, 1990, J APPL METEOROL, V29, P385, DOI 10.1175/1520-0450(1990)029<0385:APOEFB>2.0.CO;2; Levenberg K., 1944, Quarterly of Applied Mathematics, V2; MARQUARDT D, 1963, SIAM J APPL MATH, V11, P231; Mattikalli NM, 1998, WATER RESOUR RES, V34, P2289, DOI 10.1029/98WR00553; Miller D. A., 1998, EARTH INTERACTIONS, V2; Mitiche A, 1996, INT J PATTERN RECOGN, V10, P393, DOI 10.1142/S0218001496000268; RODRIGUEZ-ITURBE I, 1995, GEOPHYS RES LETT, V22, P2757, DOI 10.1029/95GL02779; Zhu AX, 2000, WATER RESOUR RES, V36, P663, DOI 10.1029/1999WR900315; Zhu AX, 1997, GEODERMA, V77, P217, DOI 10.1016/S0016-7061(97)00023-2	19	9	10	0	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	MAR	2003	41	3					664	674		10.1109/TGRS.2003.809935		11	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	678MQ	WOS:000182871300016		
J	Riquelme, JC; Aguilar-Ruiz, JS; Toro, M				Riquelme, JC; Aguilar-Ruiz, JS; Toro, M			Finding representative patterns with ordered projections	PATTERN RECOGNITION			English	Article						data mining; preprocessing techniques; pattern analysis; axis-parallel classifiers		This paper presents a new approach to finding representative patterns for dataset editing. The algorithm patterns by ordered projections (POP), has some interesting characteristics: important reduction of the number of instances from the dataset; lower computational cost (Theta(mn log n)) with respect to other typical algorithms due to the absence of distance calculations; conservation of the decision boundaries, especially from the point of view of the application of axis-parallel classifiers. POP works well in practice with both continuous and discrete attributes. The performance of POP is analysed in two ways: percentage of reduction and classification. POP has been compared to IB2, ENN and SHRINK concerning the percentage of reduction and the computational cost. In addition, we have analysed the accuracy of k-NN and C4.5 after applying the reduction techniques. An extensive empirical study using datasets with continuous and discrete attributes from the UCI repository shows that POP is a valuable preprocessing method for the later application of any axis-parallel learning algorithm. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Univ Seville, Tech Sch Comp Sci & Engn, Dept Comp Sci, E-41012 Seville, Spain	Aguilar-Ruiz, JS (reprint author), Univ Seville, Dept Lenguajes & Sistemas Informat, Avda Reina Mercedes S-N, E-41012 Seville, Spain.		Riquelme, Jose/E-6451-2010; Aguilar-Ruiz, Jesus/L-9135-2014	Riquelme, Jose/0000-0002-8243-2186; 			Aguilar J, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P771; AGUILARRUIZ JS, 2000, P 14 EUR C ART INT B, P251; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOARE CAR, 1962, COMPUT J, V5, P10, DOI 10.1093/comjnl/5.1.10; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KLEE V, 1980, ARCH MATH, V34, P75, DOI 10.1007/BF01224932; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	15	25	25	0	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	APR	2003	36	4					1009	1018	PII S0031-3203(02)00119-X	10.1016/S0031-3203(02)00119-X		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	638NR	WOS:000180577600014		
J	Okamoto, S; Yugami, N				Okamoto, S; Yugami, N			Effects of domain characteristics on instance-based learning algorithms	THEORETICAL COMPUTER SCIENCE			English	Article						instance-based learning; k-nearest neighbor classifier; average-case analysis; expected accuracy; optimal value of k	AVERAGE-CASE ANALYSIS	This paper presents average-case analyses of instance-based learning algorithms. The algorithms analyzed employ a variant of k-nearest neighbor classifier (k-NN). Our analysis deals with a monotone m-of-n target concept with irrelevant attributes, and handles three types of noise: relevant attribute noise, irrelevant attribute noise, and class noise. We formally represent the expected classification accuracy of k-NN as a function of domain characteristics including the number of training instances, the number of relevant and irrelevant attributes, the threshold number in the target concept, the probability of each attribute, the noise rate for each type of noise, and k. We also explore the behavioral implications of the analyses by presenting the effects of domain characteristics on the expected accuracy of k-NN and on the optimal value of k for artificial domains. (C) 2002 Elsevier Science B.V. All rights reserved.	Fujitsu Labs, Mihama Ku, Chiba 2138588, Japan	Okamoto, S (reprint author), Fujitsu Labs, Mihama Ku, 1-9-3 Nakase, Chiba 2138588, Japan.						Aha D. W., 1989, P 11 INT JOINT C ART, P794; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALBERT MK, 1991, P 9 NAT C ART INT, P553; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; DASARATHY BV, 1991, NORMS NN PATTERN CLA; Duda R. O., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, 4 USAF SCH AV MED; GOLEA M, 1993, NEURAL COMPUT, V5, P767, DOI 10.1162/neco.1993.5.5.767; HAUSSLER D, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1101; HIRSCHBERG D, 1992, P 9 INT C MACH LEARN, P206; Iba W., 1992, P 9 INT C MACH LEARN, P233; Langley P., 1999, P 16 INT C MACH LEAR, P220; Langley P., 1992, P 10 NAT C ART INT, P223; Langley P., 1993, P 13 INT JOINT C ART, P889; Murphy P.M., 1991, P 8 INT WORKSH MACH, P183; Okamoto S., 1996, P 13 INT C MACH LEAR, P355; OKAMOTO S, 2000, P 17 INT C MACH LEAR, P695; OKAMOTO S, 1997, P 15 INT JOINT C ART, P238; OKAMOTO S, 1995, LECT NOTES ARTIF INT, V1013, P253; PAZZANI MJ, 1992, MACH LEARN, V9, P349, DOI 10.1007/BF00994111; PITT L, 1988, J ACM, V35, P965, DOI 10.1145/48014.63140; Rachlin J., 1994, P 11 INT MACH LEARN, P242; Reischuk R, 1999, LECT NOTES COMPUT SC, V1563, P414; SALZBERG S, 1991, P 12 INT JOINT C ART, P705; SALZBERG S, 1995, IEEE T PATTERN ANAL, V17, P599, DOI 10.1109/34.387506; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WALTZ DL, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1117; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	33	8	8	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975			THEOR COMPUT SCI	Theor. Comput. Sci.	APR 4	2003	298	1					207	233	PII S0304-3975(02)00424-3	10.1016/S0304-3975(02)00424-3		27	Computer Science, Theory & Methods	Computer Science	663GH	WOS:000181997500010		
J	Marcelloni, F				Marcelloni, F			Feature selection based on a modified fuzzy C-means algorithm with supervision	INFORMATION SCIENCES			English	Article						feature selection; fuzzy C-means; k-nearest neighbors; supervised learning	GENETIC ALGORITHM	In this paper we propose a new approach to feature selection based on a modified fuzzy C-means algorithm with supervision (MFCMS). MFCMS completes the unsupervised learning of classical fuzzy C-means with labeled patterns. The labeled patterns allow MFCMS to accurately model the shape of each cluster and consequently to highlight the features which result to be particularly effective to characterize a cluster. These features are distinguished by a low variance of their values for the patterns with a high membership degree to the cluster. If, with respect to these features, the distance between the prototype of the cluster and the prototypes of the other clusters is high, then these features have the property of discriminating between the cluster and the other clusters. To take these two aspects into account, for each cluster and each feature, we introduce a purposely defined index: the higher the value of the index, the higher the discrimination capability of the feature for the cluster. We execute MFCMS on the training set considering all patterns as labeled. Then, we retain the features which are associated, at least for one cluster, with an index larger than a threshold T. We applied MFCMS to several real-world pattern classification benchmarks. We used the well-known k-nearest neighbors as learning algorithm. We show that feature selection performed by MFCMS achieved an improvement in generalization on all data sets. (C) 2002 Elsevier Science Inc. All rights reserved.	Univ Pisa, Dipartimento Ingn Informaz Elettr Informat Teleco, I-56122 Pisa, Italy	Marcelloni, F (reprint author), Univ Pisa, Dipartimento Ingn Informaz Elettr Informat Teleco, Via Diotisalvi 2, I-56122 Pisa, Italy.						AHA DW, 1996, ARTIFICIAL INTELLIGE; ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; ALMUALLIM H, 1992, P 9 NAT C ART INT, P547; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Bezdek J. C., 1981, PATTERN RECOGNITION; Bezdek J. C., 1999, FUZZY MODELS ALGORIT; Caruana R., 1994, P 11 INT C MACH LEAR, P28; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Doak J., 1992, EVALUATION FEATURE S; Domingos P, 1997, ARTIF INTELL REV, V11, P227; Duran B. S., 1974, CLUSTER ANAL SURVEY; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1007/BF00114265; FOROUTAN I, 1987, IEEE T SYST MAN CYB, V17, P187, DOI 10.1109/TSMC.1987.4309029; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Gustafson D., 1979, ADV FUZZY SET THEORY, P605; Hall Mark A, 2000, P 17 INT C MACH LEAR, P359; Hoppner F., 1999, FUZZY CLUSTER ANAL; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; John G., 1994, P 11 INT C MACH LEAR, P121; Kaufman L., 1990, FINDING GROUPS DATA; KELLER A, P 1999 EUSFLAT ESTYL, P497; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kononenko I., 1994, P EUR C MACH LEARN, P171; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Lanzi PL, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P537, DOI 10.1109/ICEC.1997.592369; LOWE D, 1985, NEURAL COMPUT, V7, P72; Moore A. W., 1994, P 11 INT C MACH LEAR, P190; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Pedrycz W, 2002, PATTERN RECOGN, V35, P825, DOI 10.1016/S0031-3203(01)00102-9; PEDRYCZ W, 1985, PATTERN RECOGN LETT, V3, P13, DOI 10.1016/0167-8655(85)90037-6; Pedrycz W, 1997, IEEE T SYST MAN CY B, V27, P787, DOI 10.1109/3477.623232; Pudil P, 1998, IEEE INTELL SYST APP, V13, P66, DOI 10.1109/5254.671094; Pudil P., 1994, PATTERN RECOGN, V15, P1119; Ravi TV, 1999, PATTERN RECOGN LETT, V20, P659, DOI 10.1016/S0167-8655(99)00027-6; RHEE FCH, 1999, P 1999 IEEE FUZZ SYS, P1266; RICHELDI M, 1996, P 2 INT C KNOWL DISC, P379; Schlimmer J. C., 1993, P 10 INT C MACH LEAR, P284; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Yang J., 1998, FEATURE EXTRACTION C; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z	42	25	28	1	3	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	MAY	2003	151						201	226		10.1016/S0020-0255(02)00402-4		26	Computer Science, Information Systems	Computer Science	666ZL	WOS:000182206300010		
J	Mattioni, BE; Kauffman, GW; Jurs, PC; Custer, LL; Durham, SK; Pearl, GM				Mattioni, BE; Kauffman, GW; Jurs, PC; Custer, LL; Durham, SK; Pearl, GM			Predicting the genotoxicity of secondary and aromatic amines using data subsetting to generate a model ensemble	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							ASSISTED STRUCTURE-ACTIVITY; MOLECULAR-STRUCTURE; HETEROAROMATIC AMINES; CHEMICAL CARCINOGENS; BIOLOGICAL-ACTIVITY; GENETIC ALGORITHMS; MUTAGENIC POTENCY; ACUTE TOXICITY; QSAR TREATMENT; STATE INDEXES	Binary quantitative structure-activity relationship (QSAR) models are developed to classify a data set of 334 aromatic and secondary amine compounds as genotoxic or nongenotoxic based on information calculated solely from chemical structure. Genotoxic endpoints for each compound were determined using the SOS Chromotest in both the presence and absence of an S9 rat liver homogenate. Compounds were considered genotoxic if assay results indicated a positive genotoxicity hit for either the S9 inactivated or S9 activated assay. Each compound in the data set was encoded through the calculation of numerical descriptors that describe various aspects of chemical structure (e.g. topological, geometric, electronic, polar surface area). Furthermore, five additional descriptors that focused on the secondary and aromatic nitrogen atoms in each molecule were calculated specifically for this study. Descriptor subsets were examined using a genetic algorithm search engine interfaced with a k-Nearest Neighbor fitness evaluator to find the most information-rich subsets, which ultimately served as the final predictive models. Models were chosen for their ability to minimize the total number of misclassifications, with special attention given to those models that possessed fewer occurrences of positive toxicity hits being misclassified as nontoxic (false negatives). In addition, a subsetting procedure was used to form an ensemble of models using different combinations of compounds in the training and prediction sets. This was done to ensure that consistent results could be obtained regardless of training set composition. The procedure also allowed for each compound to be externally validated three times by different training set data with the resultant predictions being used in a "majority rules" voting scheme to produce a consensus prediction for each member of the data set. The individual models produced an average training set classification rate of 71.6% and an average prediction set classification rate of 67.7%. However, the model ensemble was able to correctly classify the genotoxicity of 72.2% of all prediction set compounds.	Penn State Univ, Dept Chem, University Pk, PA 16802 USA; Bristol Myers Squibb Co, Princeton, NJ 08453 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, 152 Davey Lab, University Pk, PA 16802 USA.						Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; ASHBY J, 1988, MUTAT RES, V204, P17, DOI 10.1016/0165-1218(88)90114-0; ASHBY J, 1982, CARCINOGENESIS, V3, P1277, DOI 10.1093/carcin/3.11.1277; Bacha PA, 2002, J CHEM INF COMP SCI, V42, P1104, DOI 10.1021/ci020366q; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Basak SC, 2001, J CHEM INF COMP SCI, V41, P671, DOI 10.1021/ci000126f; BENIGNI R, 1994, ENVIRON MOL MUTAGEN, V24, P208, DOI 10.1002/em.2850240310; Benigni R, 1998, ENVIRON MOL MUTAGEN, V32, P75, DOI 10.1002/(SICI)1098-2280(1998)32:1<75::AID-EM9>3.0.CO;2-A; Benigni R, 2002, MUTAT RES-REV MUTAT, V511, P191, DOI 10.1016/S1383-5742(02)00008-X; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Cash GG, 2001, MUTAT RES-GEN TOX EN, V491, P31, DOI 10.1016/S1383-5718(00)00167-4; CHIGNELL CF, 1983, STRUCTURE ACTIVITY C; CHOU JT, 1979, J MED CHEM, V22, P792, DOI 10.1021/jm00193a008; Colvin ME, 1998, MUTAT RES-FUND MOL M, V400, P479, DOI 10.1016/S0027-5107(98)00073-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cronin M T, 2000, Curr Opin Drug Discov Devel, V3, P292; DEBNATH AK, 1992, ENVIRON MOL MUTAGEN, V19, P37, DOI 10.1002/em.2850190107; DEWAR MJS, 1985, J AM CHEM SOC, V107, P3902, DOI 10.1021/ja00299a024; Durham S K, 2001, Curr Opin Drug Discov Devel, V4, P110; Eldred DV, 1999, SAR QSAR ENVIRON RES, V10, P75, DOI 10.1080/10629369908039170; Eldred DV, 1999, CHEM RES TOXICOL, V12, P670, DOI 10.1021/tx980273w; ENSLEIN K, 1994, MUTAT RES, V305, P47, DOI 10.1016/0027-5107(94)90125-2; FINK SI, 1980, FARMACO-ED SCI, V35, P965; Franke R, 2001, CARCINOGENESIS, V22, P1561, DOI 10.1093/carcin/22.9.1561; Greene N, 2002, ADV DRUG DELIVER REV, V54, P417, DOI 10.1016/S0169-409X(02)00012-1; Gupta S, 1999, J CHEM INF COMP SCI, V39, P272, DOI 10.1021/ci980073q; Hammett LP, 1937, J AM CHEM SOC, V59, P96, DOI 10.1021/ja01280a022; Hatch FT, 2001, ENVIRON MOL MUTAGEN, V38, P268, DOI 10.1002/em.10028; HIBBERT DB, 1993, CHEMOMETR INTELL LAB, V19, P277, DOI 10.1016/0169-7439(93)80028-G; HOFNUNG M, 1988, ANN NY ACAD SCI, V534, P817, DOI 10.1111/j.1749-6632.1988.tb30169.x; *IND U, MOPAC V 6 0; Johnson DE, 2000, DRUG DISCOV TODAY, V5, P445, DOI 10.1016/S1359-6446(00)01559-2; JOHNSON SR, 1997, COMPUTER ASSISTED LE; Jurs P, 1979, COMPUTER ASSISTED DR; JURS PC, 1983, FUND APPL TOXICOL, V3, P343, DOI 10.1016/S0272-0590(83)80002-5; Karelson M, 2000, MOL SIMULAT, V24, P229, DOI 10.1080/08927020008022373; Katritzky AR, 1996, J PHYS CHEM-US, V100, P10400, DOI 10.1021/jp953224q; KAUFFMAN GW, 2002, THESIS PENNSYLVANIA; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P1, DOI 10.1002/qsar.19860050102; Kier LB, 1986, MOL CONNECTIVITY STR; KIER LB, 1990, PHARMACEUT RES, V7, P801, DOI 10.1023/A:1015952613760; KIER LB, 1985, QUANT STRUCT-ACT REL, V4, P109, DOI 10.1002/qsar.19850040303; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P7, DOI 10.1002/qsar.19860050103; Kier L.B., 1976, MOL CONNECTIVITY CHE; KLOPMAN G, 1984, J AM CHEM SOC, V106, P7315, DOI 10.1021/ja00336a004; KLOPMAN G, 1985, ENVIRON HEALTH PERSP, V61, P269, DOI 10.2307/3430077; KUGLERSTEIGMEIER ME, 1989, MUTAT RES, V211, P279, DOI 10.1016/0027-5107(89)90011-0; LEWIS DFW, 1992, REV COMPUTATIONAL CH; Liu SS, 1998, J CHEM INF COMP SCI, V38, P387, DOI 10.1021/ci970109z; LUCASIUS CB, 1993, CHEMOMETR INTELL LAB, V19, P1, DOI 10.1016/0169-7439(93)80079-W; LUKE BT, 1994, J CHEM INF COMP SCI, V34, P1279, DOI 10.1021/ci00022a009; Maran U, 1999, QUANT STRUCT-ACT REL, V18, P3, DOI 10.1002/(SICI)1521-3838(199901)18:1<03::AID-QSAR3>3.0.CO;2-P; Matthews EJ, 2000, J MOL GRAPH MODEL, V18, P605; Meyer H., 1899, N-S ARCH EXP PATH PH, V42, P109; Mitchell T, 2001, Curr Opin Drug Discov Devel, V4, P314; MOSIER PD, 2003, IN PRESS CHEM RES TO; Newcomb M, 2000, ACCOUNTS CHEM RES, V33, P449, DOI 10.1021/ar960058b; OVERTON E, 2001, STUDIEN NARKOSEN; Pearl Greg M., 2001, Current Topics in Medicinal Chemistry, V1, P247, DOI 10.2174/1568026013395074; PEARLMAN RS, 1980, PHYSICAL CHEM PROPER; Pimentel G. C., 1960, HYDROGEN BOND; QUILLARDET P, 1993, MUTAT RES, V297, P235, DOI 10.1016/0165-1110(93)90019-J; QUINN FR, 1981, J MED CHEM, V24, P636, DOI 10.1021/jm00137a031; Rekker R. F., 1977, HYDROPHOBIC FRAGMENT; Richard AM, 1998, MUTAT RES-FUND MOL M, V400, P493, DOI 10.1016/S0027-5107(98)00068-2; SANDERSON DM, 1991, HUM EXP TOXICOL, V10, P261; Serra JR, 2003, CHEM RES TOXICOL, V16, P153, DOI 10.1021/tx020077w; Serra JR, 2001, CHEM RES TOXICOL, V14, P1535, DOI 10.1021/tx010101q; STANTON DT, 1990, ANAL CHEM, V62, P2323, DOI 10.1021/ac00220a013; STEWART JJP, 1990, J COMPUT AID MOL DES, V4, P1, DOI 10.1007/BF00128336; STOUCH TR, 1985, ENVIRON HEALTH PERSP, V61, P329, DOI 10.2307/3430083; STUPER AJ, 1977, CHEMOMETRICS THEORY; Sutton MD, 2000, ANNU REV GENET, V34, P479, DOI 10.1146/annurev.genet.34.1.479; Taft R. W., 1956, STERIC EFFECTS ORGAN; Tetko IV, 2001, J CHEM INF COMP SCI, V41, P1407, DOI 10.1021/ci010368v; TOPLISS JG, 1979, J MED CHEM, V22, P1238, DOI 10.1021/jm00196a017; Vinogradov S.N., 1971, HYDROGEN BONDING; WESSEL MD, 1997, THESIS PENNSYLVANIA; WIENER H, 1947, J AM CHEM SOC, V69, P17, DOI 10.1021/ja01193a005; WOO YT, 1995, TOXICOL LETT, V79, P219, DOI 10.1016/0378-4274(95)03373-S; YUAN M, 1980, TOXICOL APPL PHARM, V52, P294, DOI 10.1016/0041-008X(80)90117-9; YUTA K, 1981, J MED CHEM, V24, P241, DOI 10.1021/jm00135a003	83	37	38	4	11	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338			J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	MAY-JUN	2003	43	3					949	963		10.1021/ci034013i		15	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	684LR	WOS:000183209300026	12767154	
J	James, GM				James, GM			Variance and bias for general loss functions	MACHINE LEARNING			English	Article						bias; variance; prediction error; loss function	REGRESSION	When using squared error loss, bias and variance and their decomposition of prediction error are well understood and widely used concepts. However, there is no universally accepted definition for other loss functions. Numerous attempts have been made to extend these concepts beyond squared error loss. Most approaches have focused solely on 0-1 loss functions and have produced significantly different definitions. These differences stem from disagreement as to the essential characteristics that variance and bias should display. This paper suggests an explicit list of rules that we feel any "reasonable" set of definitions should satisfy. Using this framework, bias and variance definitions are produced which generalize to any symmetric loss function. We illustrate these statistics on several loss functions with particular emphasis on 0-1 loss. We conclude with a discussion of the various definitions that have been proposed in the past as well as a method for estimating these quantities on real data sets.	Univ So Calif, Marshall Sch Business, Los Angeles, CA 90089 USA	James, GM (reprint author), Univ So Calif, Marshall Sch Business, Los Angeles, CA 90089 USA.						Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, 460 U CAL BERK STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich T. G., 1995, P 12 INT C MACH LEAR, P313; DOMINGOS P, 2000, P 17 INT C MACH LEAR; EFRON B, 1978, J AM STAT ASSOC, V73, P113, DOI 10.2307/2286531; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, DISCRIMINATORY ANAL; Freund Y., 1996, MACHINE LEARNING; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN J, 1996, BIAS VARIANCE 0 1 LO; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Heskes T, 1998, NEURAL COMPUT, V10, P1425, DOI 10.1162/089976698300017232; KOHAVI R, 1996, MACHINE LEARNING; Schapire RE, 1998, ANN STAT, V26, P1651; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Tibshirani R, 1993, INTRO BOOTSTRAP; Tibshirani Robert, 1996, BIAS VARIANCE PREDIC; Wolpert DH, 1997, NEURAL COMPUT, V9, P1211, DOI 10.1162/neco.1997.9.6.1211	21	40	40	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	MAY	2003	51	2					115	135		10.1023/A:1022899518027		21	Computer Science, Artificial Intelligence	Computer Science	656YM	WOS:000181638700001		
J	Sebban, M; Nock, R; Lallich, S				Sebban, M; Nock, R; Lallich, S			Stopping criterion for boosting-based data reduction techniques: From binary to multiclass problems	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article; Proceedings Paper	18th International Conference on Machine Learning	JUN 28-JUL 01, 2001	WILLIAMSTOWN, MASSACHUSETTS				NEAREST NEIGHBOR RULE; CLASSIFICATION	So far, boosting has been used to improve the quality of moderately accurate learning algorithms, by weighting and combining many of their weak hypotheses into a final classifier with theoretically high accuracy. In a recent work (Sebban, Nock and Lallich, 2001), we have attempted to adapt boosting properties to data reduction techniques. In this particular context, the objective was not only to improve the success rate, but also to reduce the time and space complexities due to the storage requirements of some costly learning algorithms, such as nearest-neighbor classifiers. In that framework, each weak hypothesis, which is usually built and weighted from the learning set, is replaced by a single learning instance. The weight given by boosting defines in that case the relevance of the instance, and a statistical test allows one to decide whether it can be discarded without damaging further classification tasks. In Sebban, Nock and Lallich (2001), we addressed problems with two classes. It is the aim of the present paper to relax the class constraint, and extend our contribution to multiclass problems. Beyond data reduction, experimental results are also provided on twenty-three datasets, showing the benefits that our boosting-derived weighting rule brings to weighted nearest neighbor classifiers.	Univ St Etienne, Fac Sci, Eurise, F-42023 St Etienne 2, France; French W Indies & Guiana Univ, Dept Sci, GRIMAAG, Schoelcher 97275, Martinique; Univ Lyon 2, Dept Econ, ERIC, F-69676 Bron, France	Sebban, M (reprint author), Univ St Etienne, Fac Sci, Eurise, F-42023 St Etienne 2, France.						Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Breiman L., 1984, CLASSIFICATION REGRE; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1998, ANN STAT, V26, P451; John G., 1994, P 11 INT C MACH LEAR, P121; Koller D., 1996, P 13 INT C MACH LEAR, P284; Merz C. J., 1996, UCI REPOSITORY MACHI; NOCK R, 2000, P INT C ALG LEARN TH, P224; Nock R., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000453; Nock R, 2001, PATTERN RECOGN LETT, V22, P413, DOI 10.1016/S0167-8655(00)00137-9; Schapire R. E., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279960; Schapire RE, 1998, ANN STAT, V26, P1651; Sebban M., 2000, P 17 INT C MACH LEAR, P855; Sebban M., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference; Sebban M., 2001, P 18 INT C MACH LEAR, P505; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; Vapnik V. N., 1982, ESTIMATION DEPENDENC; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	25	3	3	2	3	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAY 15	2003	3	4-5					863	885		10.1162/jmlr.2003.3.4-5.863		23	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	714RA	WOS:000184926200011		
J	Cai, YD; Chou, KC				Cai, YD; Chou, KC			Nearest neighbour algorithm for predicting protein subcellular location by combining functional domain composition and pseudo-amino acid composition	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						hybrid algorithm; proteins subcellular location; functional domain composition; pseudo-amino acid composition; bioinformatics; proteomics	SUPPORT VECTOR MACHINES; PROKARYOTIC PROTEINS; STRUCTURAL CLASSES; SITES	In this paper, based on the approach by combining the "functional domain composition" [K.C. Chou, Y.D. Cai, J. Biol. Chem. 277 (2002) 45765] and the pseudo-amino acid composition [K.C. Chou, Proteins Struct. Funct. Genet. 43 (2001) 246; Correction Proteins Struct. Funct. Genet. 2044 (2001) 2060], the Nearest Neighbour Algorithm (NNA) was developed for predicting the protein subcellular location. Very high success rates were observed, suggesting that such a hybrid approach may become a useful high-throughput tool in the area of bioinformatics and proteomics. (C) 2003 Elsevier Science (USA). All rights reserved.	Chinese Acad Sci, Shanghai Res Ctr Biotechnol, Shanghai 200233, Peoples R China; Pfizer Inc, Upjohn Labs, Kalamazoo, MI 49007 USA	Cai, YD (reprint author), UMIST, Biomol Sci Dept, POB 88, Manchester M60 1QD, Lancs, England.		Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Cai Yu-Dong, 2000, Molecular Cell Biology Research Communications, V4, P172, DOI 10.1006/mcbr.2001.0269; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou KC, 1998, BIOCHEM BIOPH RES CO, V252, P63, DOI 10.1006/bbrc.1998.9498; CHOU KC, 2003, IN PRESS PROTEINS ST; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; CHOU KC, 2002, PROTEIN PEPTIDE SCI, V3, P615; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Claros MG, 1997, CURR OPIN STRUC BIOL, V7, P394, DOI 10.1016/S0959-440X(97)80057-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng ZP, 2001, INT J BIOL MACROMOL, V28, P255, DOI 10.1016/S0141-8130(01)00121-0; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; Murvai J, 2001, NUCLEIC ACIDS RES, V29, P58, DOI 10.1093/nar/29.1.58; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	35	79	84	0	4	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	MAY 30	2003	305	2					407	411		10.1016/S0006-291X(03)00775-7		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	681RH	WOS:000183048800031	12745090	
J	Vogt, P				Vogt, P			Anchoring of semiotic symbols	ROBOTICS AND AUTONOMOUS SYSTEMS			English	Article						anchoring problem; symbol grounding problem; physical grounding; adaptive language games; semiotics		This paper presents arguments for approaching the anchoring problem using semiotic symbols. Semiotic symbols are defined by a triadic relation between forms, meanings and referents, thus having an implicit relation to the real world. Anchors are formed between these three elements rather than between 'traditional' symbols and sensory images. This allows an optimization between the form (i.e. the 'traditional' symbol) and the referent. A robotic experiment based on adaptive language games illustrates how the anchoring of semiotic symbols can be achieved in a bottom-up fashion. The paper concludes that applying semiotic symbols is a potentially valuable approach toward anchoring. (C) 2003 Elsevier Science B.V. All rights reserved.	Univ Maastricht, Inst Knowledge & Agent Technol, NL-6200 MD Maastricht, Netherlands	Vogt, P (reprint author), Univ Maastricht, Inst Knowledge & Agent Technol, POB 616, NL-6200 MD Maastricht, Netherlands.						Belpaeme T, 2002, THESIS VRIJE U BRUSS; BILLARD A, 2001, IMITATION ANIMALS AR; Bowerman Melissa, 2001, LANGUAGE ACQUISITION; Brooks R. A., 1990, Robotics and Autonomous Systems, V6, DOI 10.1016/S0921-8890(05)80025-9; Coradeschi S., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deacon Terrence, 1997, SYMBOLIC SPECIES; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; Jung D, 2000, AUTON ROBOT, V8, P269, DOI 10.1023/A:1008929609573; Ogden Charles K., 1923, MEANING MEANING STUD; Peirce C. S., 1931, COLLECTED PAPERS, VI-VIII; Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4; Siskind JM, 2001, J ARTIF INTELL RES, V15, P31; STEELS L, 1996, P INT C MULT SYST; STEELS L, 1996, ANIMALS ANIMALS, V4; Steels L., 2000, EVOLUTION COMMUNICAT, V4, P3; Steels L., 1997, P 4 EUR C ART LIF; Tomasello M., 1999, CULTURAL ORIGINS HUM; Vogt P., 2002, COGNITIVE SYSTEMS RE, V3, P429, DOI DOI 10.1016/S1389-0417(02)00051-7; Vogt P, 2000, THESIS VRIJE U BRUSS; VOGT P, 2002, P 14 BELG NETH ART I, P331; Vogt P., 2000, EVOLUTION COMMUNICAT, V4, P89; Wittgenstein L, 1958, PHILOS INVESTIGATION; YANCO H, 1993, ANIMALS ANIMATS, V2, P478	24	30	30	2	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0921-8890			ROBOT AUTON SYST	Robot. Auton. Syst.	MAY 31	2003	43	2-3					109	120	PII S0921-8890(02)00353-6	10.1016/S0921-8890(02)00353-6		12	Automation & Control Systems; Computer Science, Artificial Intelligence; Robotics	Automation & Control Systems; Computer Science; Robotics	677WB	WOS:000182830800004		
J	Kudo, M; Masuyama, N; Toyama, J; Shimbo, M				Kudo, M; Masuyama, N; Toyama, J; Shimbo, M			Simple termination conditions for k-nearest neighbor method	PATTERN RECOGNITION LETTERS			English	Article						pattern recognition; the k-nearest neighbor method; branch-and-bound algorithm; termination condition	ALGORITHM; SEARCH	The main problem with k-nearest neighbor (k-NN) method is that the computational cost in the search process is proportional to the size of the training samples. Many search algorithms have been proposed to cope with this problem. In this study, we consider some conditions for terminating the search procedure when the true k-NNs have been found in the middle of the search, and we present, as an example, a procedure in the branch-and-bound algorithm. These conditions do not always work for a certain sample, but they reduce the computational cost on average. (C) 2002 Elsevier Science B.V. All rights reserved.	Hokkaido Univ, Grad Sch Engn, Div Syst & Informat Engn, Kita Ku, Sapporo, Hokkaido 0608628, Japan; Hokkaido Informat Univ, Fac Informat Media, Ebetsu, Hokkaido 0698585, Japan	Kudo, M (reprint author), Hokkaido Univ, Grad Sch Engn, Div Syst & Informat Engn, Kita Ku, Kita 13,Nishi 8, Sapporo, Hokkaido 0608628, Japan.		Kudo, Mineichi/B-9973-2011				BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Berchtold S., 1998, P 14 IEEE C DAT ENG, P23; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Califano A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139656; CHANG CC, 1993, PATTERN RECOGN LETT, V14, P625, DOI 10.1016/0167-8655(93)90047-H; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P268; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Guttman A., 1984, ACM SIGMOD, P47; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kleinberg J.M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; MURPHY PM, 1991, UCI REPOSITORY MACHI; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; Wolfson H.J., 1990, P 1 EUR C COMP VIS, P526	21	4	6	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2003	24	9-10					1203	1213	PII S0167-8655(02)00302-1	10.1016/S0167-8655(02)00302-1		11	Computer Science, Artificial Intelligence	Computer Science	652FJ	WOS:000181368900009		
J	Yager, RR				Yager, RR			Induced aggregation operators	FUZZY SETS AND SYSTEMS			English	Article; Proceedings Paper	EUROFUSE Workshop on Preference Modelling and Applications	APR 25-27, 2001	GRANADA, SPAIN			IOWA operator; OWA aggregation operators; best yesterday models		We introduce the induced ordered weighted averaging (IOWA) operator. In these operators the argument ordering process is guided by a variable called the order inducing value. A procedure for learning the weights from data is described. We suggest a number of applications of these induced OWA aggregation operators. First we show its possibilities in modeling nearest-neighbor rules. Next it is applied to the aggregation of complex objects such as matrices. It is also used to establish a new class of information fusion models called "best yesterday models". Finally, we extend the idea of order induced aggregation to the Choquet aggregation resulting in what we call the induced Choquet ordered averaging (I-COA) operator. (C) 2002 Elsevier Science B.V. All rights reserved.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, 715 N Ave, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENNEBERG D., 1994, NONADDITIVE MEASURE; Filev D, 1998, FUZZY SET SYST, V94, P157, DOI 10.1016/S0165-0114(96)00254-0; Grabisch M., 1999, FUZZY MEASURES INTEG; Kacprzyk J., 1997, ORDERED WEIGHTED AVE; Sugeno M., 1977, FUZZY AUTOMATA DECIS, P89; Sugeno M., 1987, P 2 IFSA C TOK; Yager R. R., 1998, P FUZZ IEEE WORLD C, P123; Yager RR, 2002, IEEE T SYST MAN CY B, V32, P512, DOI 10.1109/TSMCB.2002.1018770; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; Yager RR, 1998, PROCEEDINGS OF THE IEEE/IAFE/INFORMS 1998 CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR FINANCIAL ENGINEERING (CIFER), P220, DOI 10.1109/CIFER.1998.690125; Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789; YAGER RR, 2001, P ATL S COMP BIOL GE, P92	13	152	170	1	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114			FUZZY SET SYST	Fuzzy Sets Syst.	JUL 1	2003	137	1					59	69	PII S0165-0114(02)00432-3	10.1016/S0165-0114(02)00432-3		11	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	693YQ	WOS:000183746300006		
J	Singh, S				Singh, S			PRISM - A novel framework for pattern recognition	PATTERN ANALYSIS AND APPLICATIONS			English	Article						cells; classification complexity; data compactness; feature selection; hypercuboids; PRISM	CLASSIFICATION; COMPLEXITY; INFORMATION; PROBABILITY; SELECTION; ERROR	In this paper, we introduce a new model of solving pattern recognition tasks called PRISM (Pattern Recognition using Information Slicing Method). The main concept behind PRISM is the slicing of information through multiple planes across different feature axes to generate a number of cells. The number of cells created and their volume depends upon the number partitions per axes. In this context we define resolution as the number of partitions per axes. In this paper, we make the following contributions. First, we provide a brief survey of the class separability measures and feature partitioning schemes used for pattern recognition. Secondly, we define the PRISM framework and the algorithm for data assignment to cells. Thirdly, we detail four important concepts in PRISM: purity, neighbourhood separability, collective entropy, and data compactness. The first two measures define the data complexity, the next measure relates to uncertainty, and the last measure defines the alternative to statistical data variance in the PRISM framework. Fourthly, we investigate the variability in the estimates of these measures depending on the placement of partitions on each feature axis. Finally, we give an overview of experimental successes achieved with PRISM in the areas of classification complexity estimation and feature selection.	Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England	Singh, S (reprint author), Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England.						Ben-Bassat M., 1982, HDB STATISTICS, VII, P773, DOI 10.1016/S0169-7161(82)02038-0; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; BOHM C, 2001, ACM COMPUT SURV; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHERNOFF A, 1966, ANN I STAT MATH, V18, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Feldman DP, 1998, PHYS LETT A, V238, P244, DOI 10.1016/S0375-9601(97)00855-4; Fisher A., 1923, MATH THEORY PROBABIL; FIX E, 1949, 2149004 USAF SCH AV; FOLEY JD, 1987, COMPUTER GRAPHICS PR; Fukunaga K., 1990, INTRO STAT PATTERN R; GLICK N, 1973, ANN I STAT MATH, V25, P373, DOI 10.1007/BF02479383; Ho TK, 2000, LECT NOTES COMPUT SC, V1857, P97; Hunter G. M., 1978, THESIS PRINCETON U P; ITTNER A, 1997, P 7 INT FUZZ SYST AS; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; Kishore JK, 2001, INFORM SCIENCES, V131, P65, DOI 10.1016/S0020-0255(00)00081-5; KOHN A, 1976, PATTERN RECOGN, V29, P873; Kon MA, 2000, NEURAL NETWORKS, V13, P365, DOI 10.1016/S0893-6080(00)00015-0; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; Loftsgaarden D., 1965, ANN MATH STAT, P1049; MADDOX J, 1990, NATURE, V344, P705; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Perlin K., 1989, Computer Graphics, V23; Pierson W., 1998, THESIS OHIO STATE U; PIERSON WE, 2002, UNPUB IEEE T PATT AN; PIERSON WE, 1998, P SPIE C AUT TARG RE; RAHMAN AFR, 1998, P INT C IM AN PROC, P893; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; SANCHO JL, 1996, P IEE C MATH SIGN PR; SANCHO JL, 1996, INTELLIGENT METHODS; SINGH S, 2003, IN PRESS IEEE T SYST; SINGH S, 2003, IN PRESS IEEE T PATT; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137; Therrien C.W, 1989, DECISION ESTIMATION; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; Vapnik V., 1998, STAT LEARNING THEORY; WALLACE CS, 1968, COMPUT J, V11, P185; WILLIAMS AC, 1997, SPIE INT S OPT ENG; WU Y, 2001, LNCS, V2013, P222; XIE Q, 1993, IEEE T PATTERN ANAL, P1326; Young Tzay Y., 1986, HDB PATTERN RECOGNIT; ZHAO M, 1999, P INT JOINT C NEUR N, V3, P1631	46	9	9	1	1	SPRINGER-VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1433-7541			PATTERN ANAL APPL	Pattern Anal. Appl.	JUL	2003	6	2					134	149		10.1007/s10044-002-0186-2		16	Computer Science, Artificial Intelligence	Computer Science	711TU	WOS:000184757800004		
J	Hullermeier, E				Hullermeier, E			Possibilistic instance-based learning	ARTIFICIAL INTELLIGENCE			English	Article						possibility theory; fuzzy set theory; machine learning; instance-based learning; nearest neighbor classification; probability	NEIGHBOR CLASSIFICATION RULE; NEAREST NEIGHBORS; DENSITY-FUNCTION; NATURAL LANGUAGES; ALGORITHMS; RECOGNITION; KNOWLEDGE	A method of instance-based learning is introduced which makes use of possibility theory and fuzzy sets. Particularly, a possibilistic version of the similarity-guided extrapolation principle underlying the instance-based learning paradigm is proposed. This version is compared to the commonly used probabilistic approach from a methodological point of view. Moreover, aspects of knowledge representation such as the modeling of uncertainty are discussed. Taking the possibilistic extrapolation principle as a point of departure, an instance-based learning procedure is outlined which includes the handling of incomplete information, methods for reducing storage requirements and the adaptation of the influence of stored cases according to their typicality. First theoretical and experimental results showing the efficiency of possibilistic instance-based learning are presented as well. (C) 2003 Elsevier B.V. All rights reserved.	Univ Marburg, Dept Math & Comp Sci, D-35032 Marburg, Germany	Hullermeier, E (reprint author), Univ Marburg, Dept Math & Comp Sci, D-35032 Marburg, Germany.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Aha D. W., 1997, LAZY LEARNING; Aha D. W., 1989, P 6 INT WORKSH MACH, P387; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; Bezdek J. C., 1981, PATTERN RECOGNITION; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bradley R., 1979, POSSIBLE WORLDS; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Cohen L.J., 1989, INTRO PHILOS INDUCTI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; DAVIES LJ, 1988, SYSTEMS PRACTICE, V1, P11, DOI 10.1007/BF01059886; de Mantaras RL, 1998, DATA KNOWL ENG, V25, P99; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DIXON JK, 1979, IEEE T SYST MAN CYB, V9, P617, DOI 10.1109/TSMC.1979.4310090; Domingos P, 1996, MACH LEARN, V24, P141; Domingos P., 1995, P 14 INT JOINT C ART, P1226; Dubois D., 1988, POSSIBILITY THEORY; DUBOIS D, 1986, EUR J OPER RES, V25, P345, DOI 10.1016/0377-2217(86)90266-3; Dubois D., 2000, Journal of Logic, Language and Information, V9, DOI 10.1023/A:1008370109997; Dubois D., 1998, HDB DEFEASIBLE REASO, V1, P169; Dubois D., 2000, Advances in Case-Based Reasoning. 5th European Workshop, EWCBR 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1898); Dubois D, 1998, INT J INTELL SYST, V13, P345, DOI 10.1002/(SICI)1098-111X(199804)13:4<345::AID-INT3>3.3.CO;2-I; DUBOIS D, 2000, SOFT COMPUTING CASE, P47; Dubois D., 1992, P 1 IEEE INT C FUZZ, P821; Dubois D, 2002, IEEE T FUZZY SYST, V10, P322, DOI 10.1109/TFUZZ.2002.1006435; DUBOIS D, 2002, LECT NOTES ARTIF INT, V2275, P1; Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8; DUBOIS D, 1992, FUZZY SET SYST, V49, P65, DOI 10.1016/0165-0114(92)90110-P; Dubois D., 2001, LECT NOTES ARTIF INT, V2143, P522; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1991, NEAREST NEIGHBOR NN; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HULLERMEIER E, 1999, P IJCAI 99, P248; HULLERMEIER E, 2002, P ECAI 2002 15 EUR C, P360; Hume David, 1999, ENQUIRY CONCERNING H; Jones MC, 1995, KERNEL SMOOTHING; Jozwik A, 1983, PATTERN RECOGN LETT, V1, P287, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kibler D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00315.x; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; Kolodner J. L., 1993, CASE BASED REASONING; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; LEWIS DK, 1973, J PHILOS LOGIC, P2; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; McKenna E., 2000, P 14 EUR C ART INT, P60; Mitchell T.M., 1980, CBMTR117 RUTG U; Niiniluoto Ilkka, 1988, ANALOGICAL REASONING, P271; PARTHASARATHY G, 1990, IEEE T SYST MAN CYB, V20, P715, DOI 10.1109/21.57285; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; Quinlan J .R., 1989, P 6 INT WORKSH MACH, P164; Quinlan R, 1993, P 10 INT C MACH LEAR, P236; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; SANCHEZ E, 1978, INFORM SCIENCES, V15, P45, DOI 10.1016/0020-0255(78)90021-X; Shafer G., 1976, MATH THEORY EVIDENCE; Shepard D, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; Silverman BW, 1986, DENSITY ESTIMATION S; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; VAPNIK VN, 1998, STATLEARNING THEORY; Weisbrod J., 1998, Soft Computing, V2, DOI 10.1007/s005000050037; Wess S., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WILSON DR, 1997, THESIS B YOUNG U PRO; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; ZADEH LA, 1978, INT J MAN MACH STUD, V10, P395, DOI 10.1016/S0020-7373(78)80003-0; Zhang J., 1992, P 9 INT MACH LEARN C, P470; Zhang JP, 1997, ARTIF INTELL REV, V11, P175, DOI 10.1023/A:1006500703083	85	12	12	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702			ARTIF INTELL	Artif. Intell.	AUG	2003	148	1-2					335	383		10.1016/S0004-3702(03)00019-5		49	Computer Science, Artificial Intelligence	Computer Science	713LY	WOS:000184860500011		
J	Wojna, A				Wojna, A			Center-based indexing in vector and metric spaces	FUNDAMENTA INFORMATICAE			English	Article							COMBINING RULE INDUCTION; ALGORITHM; CLASSIFICATION; RIONA; TREES	The paper addresses the problem of indexing data for k nearest neighbors (k-nn) search. Given a collection of data objects and a similarity measure the searching goal is to find quickly the k most similar objects to a given query object. We present a top-down indexing method that employs a widely used scheme of indexing algorithms. It starts with the whole set of objects at the root of an indexing tree and iteratively splits data at each level of indexing hierarchy. In the paper two different data models are considered. In the first, objects are represented by vectors from a multi-dimensional vector space. The second, more general, is based on an assumption that objects satisfy only the axioms of a metric space. We propose an iterative k-means algorithm for tree node splitting in case of a vector space and an iterative k-approximate-centers algorithm in case when only a metric space is provided. The experiments show that the iterative k-means splitting procedure accelerates significantly k-nn searching over the one-step procedure used in other indexing structures such as GNAT, SS-tree and M-tree and that the relevant representation of a tree node is an important issue for the performance of the search process. We also combine different search pruning criteria used in BST, GHT nad GNAT structures into one and show that such a combination outperforms significantly each single pruning criterion. The experiments are performed for benchmark data sets of the size up to several hundreds of thousands of objects. The indexing tree with the k-means splitting procedure and the combined search criteria is particularly effective for the largest tested data sets for which this tree accelerates searching up to several thousands times.	Warsaw Univ, Inst Informat, PL-02097 Warsaw, Poland	Wojna, A (reprint author), Warsaw Univ, Inst Informat, Ul Banacha 2, PL-02097 Warsaw, Poland.	wojna@mimuw.edu.pl					Aggarwal C. C., 2001, P 8 INT C DAT THEOR, P420; Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Finkel R. A., 1974, Acta Informatica, V4, DOI 10.1007/BF00288933; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Beyer K., 1999, P 7 INT C DAT THEOR, P217; Biberman Y., 1994, P 9 EUR C MACH LEARN, P49; Blake C, 1998, UCI REPOSITORY MACHI; Brin S., 1995, P 21 INT C VER LARG, P574; CHAVEZ E, 1999, TRDCC993 U CHIL DEP; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1996, MACH LEARN, V24, P141; Duda R. O., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Gora G, 2002, FUND INFORM, V51, P369; Gora G, 2002, LECT NOTES ARTIF INT, V2430, P111; Guttman A, 1984, P ACM SIGMOD INT C M, P47; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; Katayama N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Lin K, 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; Mitchell T. M., 1997, MACHINE LEARNING; NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586; Robinson J. J., 1981, Paper, 32nd Annual Meeting of the European Association for Animal Production; SALZBERG S, 1991, MACH LEARN, V2, P229; Savares S.M., 2001, P 1 SIAM INT C DAT M, P1; SELLIS T, 1987, P 13 INT C VER LARG, P574; SKOWRON A, 2003, ROUGH SET EXPLORATIO; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; VELOSO M, 1994, PLANNING LEARNING AN; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Wettschereck D, 1994, THESIS OREGON STATE; White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202; WOJNA A, 2003, P 3 IEEE INT C DAT M; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311	40	6	7	0	10	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968			FUND INFORM	Fundam. Inform.	AUG	2003	56	3					285	310				26	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	752PU	WOS:000187177000005		
J	Steele, BM; Patterson, DA; Redmond, RL				Steele, BM; Patterson, DA; Redmond, RL			Toward estimation of map accuracy without a probability test sample	ENVIRONMENTAL AND ECOLOGICAL STATISTICS			English	Article						classification; discriminant analysis; posterior probabilities; spatial data	REMOTELY-SENSED DATA; ERROR RATE ESTIMATION; THEMATIC CLASSIFICATION ACCURACY; LAND-COVER; CROSS-VALIDATION; INFORMATION; CLASSIFIERS; MISCLASSIFICATION; VEGETATION; DESIGN	The time and effort required of probability sampling for accuracy assessment of large-scale land cover maps often means that probability test samples are not collected. Yet, map usefulness is substantially reduced without reliable accuracy estimates. In this article, we introduce a method of estimating the accuracy of a classified map that does not utilize a test sample in the usual sense, but instead estimates the probability of correct classification for each map unit using only the classification rule and the map unit covariates. We argue that the method is an improvement over conventional estimators, though it does not eliminate the need for probability sampling. The method also provides a new and simple method of constructing accuracy maps. We illustrate some of problems associated with accuracy assessment of broad-scale land cover maps, and our method, with a set of nine Landsat Thematic Mapper satellite image-based land cover maps from Montana and Wyoming, USA.	Univ Montana, Dept Math Sci, Missoula, MT 59812 USA; Univ Montana, Wildlife Spatial Anal Lab, Montana Cooperat Wildlife Res Unit, Missoula, MT 59812 USA	Steele, BM (reprint author), Univ Montana, Dept Math Sci, Missoula, MT 59812 USA.						ARNO SF, 1979, INT218 USDA FOR SERV; BASFORD KE, 1985, J AM STAT ASSOC, V80, P286, DOI 10.2307/2287884; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CAMPBELL JB, 1981, PHOTOGRAMM ENG REM S, V47, P355; Carpenter GA, 1999, REMOTE SENS ENVIRON, V70, P326, DOI 10.1016/S0034-4257(99)00051-6; CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B; CONGALTON RG, 1988, PHOTOGRAMM ENG REM S, V54, P587; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DR, 1958, BIOMETRIKA, V45, P562, DOI 10.1093/biomet/45.3-4.562; Cressie N., 1993, STAT SPATIAL DATA; DAWID AP, 1982, J AM STAT ASSOC, V77, P605, DOI 10.2307/2287720; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; FISHER PF, 1994, PHOTOGRAMM ENG REM S, V60, P905; Fix E., 1951, 4 US AIR FORC SCH AV; Foody GM, 1996, INT J REMOTE SENS, V17, P1317; GANESALINGAM S, 1980, PATTERN RECOGN, V12, P405, DOI 10.1016/0031-3203(80)90016-3; GLICK N, 1978, PATTERN RECOGN, V10, P211, DOI 10.1016/0031-3203(78)90029-8; GOPAL S, 1994, PHOTOGRAMM ENG REM S, V60, P181; GRIFFITH DA, 1999, SPATIAL ACCURACY ASS; Hammond TO, 1996, INT J REMOTE SENS, V17, P1261; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; Hand DJ, 1997, CONSTRUCTION ASSESSM; Hastie T, 2001, ELEMENTS STAT LEARNI; KARTIKEYAN B, 1994, INT J REMOTE SENS, V15, P1037; KRZANOWSKI WJ, 2001, J APPL STAT, V5, P585; Kyriakidis PC, 2001, ENVIRON ECOL STAT, V8, P311, DOI 10.1023/A:1012778302005; Lee TCM, 2000, J AM STAT ASSOC, V95, P259, DOI 10.2307/2669543; Ma ZK, 2001, PHOTOGRAMM ENG REM S, V67, P295; McIver DK, 2002, REMOTE SENS ENVIRON, V81, P253, DOI 10.1016/S0034-4257(02)00003-2; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; NEMANI R, 1993, INT J REMOTE SENS, V14, P2519; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Ripley BD, 1996, PATTERN RECOGNITION; SCHAVIO RA, 2000, INT STAT REV, V68, P295; Steele BM, 2001, INT J REMOTE SENS, V22, P3143, DOI 10.1080/01431160152558297; Steele BM, 1998, REMOTE SENS ENVIRON, V66, P192, DOI 10.1016/S0034-4257(98)00061-3; STEELE BM, IN PRESS P 33 S INT; Steele BM, 2000, REMOTE SENS ENVIRON, V74, P545, DOI 10.1016/S0034-4257(00)00145-0; Steele BM, 2000, STAT COMPUT, V10, P349, DOI 10.1023/A:1008933626919; Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7; Stehman SV, 2000, REMOTE SENS ENVIRON, V72, P35, DOI 10.1016/S0034-4257(99)00090-5; Stehman SV, 1998, REMOTE SENS ENVIRON, V64, P331, DOI 10.1016/S0034-4257(98)00010-8; STEHMAN SV, 1995, INT J REMOTE SENS, V16, P589; Stuckens J, 2000, REMOTE SENS ENVIRON, V71, P282, DOI 10.1016/S0034-4257(99)00083-8; Tibshirani R, 1993, INTRO BOOTSTRAP; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; Vogelmann JE, 1998, ENVIRON MONIT ASSESS, V51, P415, DOI 10.1023/A:1005996900217; WATSON DF, 1985, GEO-PROCESSING, V2, P315; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516; ZHU Z, 1999, SPATIAL ACCURACY ASS	50	14	14	1	6	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1352-8505			ENVIRON ECOL STAT	Environ. Ecol. Stat.	SEP	2003	10	3					333	356		10.1023/A:1025111108050		24	Environmental Sciences; Mathematics, Interdisciplinary Applications; Statistics & Probability	Environmental Sciences & Ecology; Mathematics	711AQ	WOS:000184715300003		
J	Okazaki, N; Matsuo, Y; Matsumura, N; Ishizuka, M				Okazaki, N; Matsuo, Y; Matsumura, N; Ishizuka, M			Sentence extraction by spreading activation through sentence similarity	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						summarization; extraction; sentence similarity; spreading activation		Although there has been a great deal of research on automatic summarization, most methods rely on statistical methods, disregarding relationships between extracted textual segments. We propose a novel method to extract a set of comprehensible sentences which centers on several key points to ensure sentence connectivity. It features a similarity network from documents with a lexical dictionary, and spreading activation to rank sentences. We show evaluation results of a multi-document summarization system based on the method participating in a competition of summarization, TSC (Text Summarization Challenge) task, organized by the third NTCIR project.	Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138656, Japan; AIST Tokyo Waterfront, Cyber Assist Res Ctr, Tokyo 1350064, Japan	Okazaki, N (reprint author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138656, Japan.						Barzilay R, 2002, J ARTIF INTELL RES, V17, P35; Barzilay R., 1997, P ACL WORKSH INT SCA, P10; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037//0033-295X.82.6.407; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDMUNDSO.HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519; FUKUMOTO J, 1997, PACLING 97; FUKUSHIMA T, 2002, 3 NTCIR WORKSH M 1, P87; KANDPAL HC, 2001, J OPT A-PURE APPL OP, V3, P1; LUHN HP, 1958, IBM J RES DEV, V2, P159; Mani I., 1999, Information Retrieval, V1, DOI 10.1023/A:1009930203452; Mani I., 2001, AUTOMATIC SUMMARIZAT; Mitra M., 1997, INFORMATION PROCESSI, V32, P53; Morris J., 1991, Computational Linguistics, V17; NAGAO K, 1998, P 17 INT C COMP LING; OKAZAKI N, 2002, 3 NTCIR WORKSH M 5, P39; OKUMURA M, 1994, P COLING 94, V2, P75; Salton G., 1989, AUTOMATIC TEXT PROCE; Stein GC, 2000, COMPUT INTELL, V16, P606, DOI 10.1111/0824-7935.00131	19	5	5	0	5	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532			IEICE T INF SYST	IEICE Trans. Inf. Syst.	SEP	2003	E86D	9					1686	1694				9	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	720TL	WOS:000185276000027		
J	Preston, JM; Kirlin, RL				Preston, JM; Kirlin, RL			Comment on "Acoustic seabed classification: improved statistical method"	CANADIAN JOURNAL OF FISHERIES AND AQUATIC SCIENCES			English	Editorial Material							HABITATS; SYSTEM		Quester Tangent Corp, Sidney, BC V8L 5Y8, Canada; Univ Victoria, Dept Elect & Comp Engn, Victoria, BC V8W 3P6, Canada	Preston, JM (reprint author), Quester Tangent Corp, 201 9865 W Saanich Rd, Sidney, BC V8L 5Y8, Canada.						Anderson JT, 2002, ICES J MAR SCI, V59, P156, DOI 10.1006/jmsc.2001.1126; ANDERSON JT, 2001, SPATIAL PROCESSES MA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ellingsen KE, 2002, ICES J MAR SCI, V59, P825, DOI 10.1006/jmsc.2002.1198; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Legendre P, 2002, CAN J FISH AQUAT SCI, V59, P1085, DOI 10.1139/F02-096; Morrison MA, 2001, J SEA RES, V46, P233, DOI 10.1016/S1385-1101(01)00089-2; PRESTON JM, 2001, P MTS IEEE OC 2001 O	8	14	15	1	4	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA, ONTARIO K1A 0R6, CANADA	0706-652X			CAN J FISH AQUAT SCI	Can. J. Fish. Aquat. Sci.	OCT	2003	60	10					1299	1300		10.1139/F03-131		2	Fisheries; Marine & Freshwater Biology	Fisheries; Marine & Freshwater Biology	743LN	WOS:000186573400011		
J	Kleinberg, J				Kleinberg, J			Bursty and hierarchical structure in streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th ACM/SIGKDD International Conference on Knowledge Discovery and Data Mining	JUL, 2002	EDMONTON, CANADA	ACM, SIGKDD		data stream algorithms; text mining; Markov source models		A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time. E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale. Underlying much of the text mining work in this area is the following intuitive premise-that the appearance of a topic in a document stream is signaled by a "burst of activity," with certain features rising sharply in frequency as the topic emerges. The goal of the present work is to develop a formal approach for modeling such " bursts," in such a way that they can be robustly and efficiently identified, and can provide an organizational framework for analyzing the underlying content. The approach is based on modeling the stream using an infinite-state automaton, in which bursts appear naturally as state transitions; it can be viewed as drawing an analogy with models from queueing theory for bursty network traffic. The resulting algorithms are highly efficient, and yield a nested representation of the set of bursts that imposes a hierarchical structure on the overall stream. Experiments with e-mail and research paper archives suggest that the resulting structures have a natural meaning in terms of the content that gave rise to them.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Kleinberg, J (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Agrawal R., 1995, P INT C DAT ENG; AIGRAIN P, 1996, MULTIMEDIA TOOLS APP, V3; Allan J., 1998, P DARPA BROADC NEWS; ALLAN J, 1998, P SIGIR INT C INF RE; ANICK D, 1982, BELL SYST TECH J, V61; BECKER K, 2000, P 15 BRAZ S DAT; Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214; Berghel H, 1997, COMMUN ACM, V40, P11, DOI 10.1145/256175.256176; BIRRELL A, 1997, PACHYDERM E MAIL SYS; BLANTON T, 1995, WHITE HOUSE E MAIL; BOONE G, 1998, P 2 INT C AUT AG; CHARIKAR M, 2002, P 29 INT C AUT LANG; Chatfield C, 1996, ANAL TIME SERIES INT; Chatman S., 1978, STORY DISCOURSE NARR; CHUDOVA D, 2001, KDD WORKSH TEMP DAT; Cohen W., 1996, P AAAI SPRING S MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EHRICH R, 1976, IEEE T COMPUT, V25, P7; ELWALID A, 1993, IEEE ACM T NETWORKIN, V1; FINE S, 1998, MACHINE LEARNING, V32; Forster Edward M., 1927, ASPECTS NOVEL; FP KELLY, 1996, STOCHASTIC NETWORKS; Garofalakis M., 2002, ACM SIGMOD INT C MAN; GAY G, 2001, ED TECHNOLOGY SOC, V4; Genette G., 1988, NARRATIVE DISCOURSE; Genette G., 1980, NARRATIVE DISCOURSE; Grosz B., 1986, COMPUTATIONAL LINGUI, V12; GRUBER T, HYPERMAIL; GURALNIK V, 1999, INT C KNOWL DISC DAT; HAN J, 1998, P INT C KNOWL DISC D; Hand D, 2001, PRINCIPLES DATA MINI; Havre S., 2000, P IEEE S INF VIS; HAWKINS D, 1976, APPL STAT, V25; HECKEL B, 1997, P WORKSH NEW PAR INF; Helfman J.I., 1995, ISHMAIL IMMEDIATE ID; Horvitz E., 1999, P ACM C HUM FACT COM; HUDSON DJ, 1966, J AM STAT ASSOC, V61, P1097, DOI 10.2307/2283203; KEOGH E, 1997, P INT C KNOWL DISC D; LAST M, 2001, IEEE T SYSTEMS MAN B, V31; LAVRENKO V, 2000, KDD 2000 WORKSH TEXT; LEWIS DD, 1997, INF P MANAGEMENT, V33; LUKESH SS, 1999, 1 MONDAY, V4; Maes P., 1994, Communications of the ACM, V37, DOI 10.1145/176789.176792; MANNILA H, 2001, P INT C KNOWL DISC D; MARKUS ML, 1994, ACM T INFORM SYST, V12, P119, DOI 10.1145/196734.196738; MARTIN R, 2001, KDD WKSHP TEMP DAT M; MILLER N, 1998, P IEEE VISUALIZATION; Moore R. W., 2000, D LIB MAGAZINE, V6; MURPHY K, 2001, ADV NEURAL INFORMATI, V14; OLSEN F, 1999, CHRONICLE HIGHE 0824; Payne TR, 1997, APPL ARTIF INTELL, V11, P1, DOI 10.1080/088395197118325; POLLOCK S, 1988, ACM T INFORM SYST, V6, P232, DOI 10.1145/45945.214327; Rabiner L.R., 1989, P IEEE, V77; REDMOND M, 1998, P AAAI WORKSH CAS BA; RENNIE J, 2000, P KDD WORKSH TEXT MI; Sahami M., 1998, P AAAI WORKSH LEARN; Schneier B., 1996, APPL CRYPTOGRAPHY, V2nd; SCOTT S, 1998, THESIS HARVARD U; SCOTT SL, 2002, MARKOV MODULATED POI; SEGAL R, 2000, P INT C MACH LEARN; SEGAL R, 1999, P INT C AUT AG; SHAW S, 1990, IEEE T ACOUSTICS SPE, V38, P2; Swan R, 1999, P 8 INT C INF KNOWL; SWAN R, 2000, P SIGIR INT C INF RE; SWAN R, 2000, KDD 2000 WORKSH TEXT; WHITTAKER S, 1996, P ACM SIGCHI C HUM F; WONG P, 2000, P IEEE INFORMATION V; YANG Y, 2000, P SIGIR INT C INF RE; YANG Y, 1998, P SIGIR INT C INF RE; GOGGLE ZEITGEIST SEA	70	84	93	13	40	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810			DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2003	7	4					373	397		10.1023/A:1024940629314		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	704UM	WOS:000184358900003		
J	Raymer, ML; Doom, TE; Kuhn, LA; Punch, WF				Raymer, ML; Doom, TE; Kuhn, LA; Punch, WF			Knowledge discovery in medical and biological datasets using a hybrid Bayes classifier/evolutionary algorithm	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article; Proceedings Paper	IEEE International Symposium on Bio-Informatic and Biomedcial Engineering	NOV 08-10, 2000	WASHINGTON, D.C.	IEEE		bioinformatics; evolutionary computing; genetic algorithms; pattern recognition	K-NEAREST-NEIGHBORS; GENETIC ALGORITHMS; FEATURE-SELECTION; LIGAND INTERACTIONS; WATER-MOLECULES; BOUND ALGORITHM; HYDROGEN-BONDS; DRUG DESIGN; PROTEINS; CLASSIFICATION	A key element of bioinformatics research is the extraction of meaningful information from large experimental data-sets. Various approaches, including statistical and graph theoretical methods, data mining, and computational pattern recognition, have been applied to this task with varying degrees of success. Using a novel classifier based on the Bayes discriminant function, we present a hybrid algorithm that employs feature selection and extraction to isolate salient features from large medical and other biological data sets. We have previously shown that a genetic algorithm coupled with a k-nearest-neighbors classifier performs well in extracting information about protein-water binding from X-ray crystallographic protein structure data. The effectiveness of the hybrid EC-Bayes classifier is demonstrated to distinguish the features of this data set that are the most statistically relevant and to weight these features appropriately to aid in the prediction of solvation sites.	Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA; Michigan State Univ, Dept Biochem, E Lansing, MI 48824 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Raymer, ML (reprint author), Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.		Raymer, Michael/G-3398-2013	Raymer, Michael/0000-0003-2649-0792			ABOLA EE, 1987, PROTEIN DATA BANK CR, P107; Aeberhard S., 1992, 9202 J COOK U N QUEE; AEBERHARD S, 1992, 9201 J COOK U N QUEE; BAKER EN, 1984, PROG BIOPHYS MOL BIO, V44, P97, DOI 10.1016/0079-6107(84)90007-5; BAYES T, 1763, PHIL T ROY SOC, V53; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Blake C, 1998, UCI REPOSITORY MACHI; Cestnik G., 1987, PROGR MACHINE LEARNI, P31; CONNOLLY ML, 1983, SCIENCE, V221, P709, DOI 10.1126/science.6879170; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Diaconis P., 1983, SCI AM, V248; Domingos Pedro, 1996, P 13 INT C MACH LEAR, P105; Duda R. O., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HOBOHM U, 1992, PROTEIN SCI, V1, P409; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain A. K., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JAYNES ET, 1968, IEEE T SYST SCI CYB, VSSC4, P227, DOI 10.1109/TSSC.1968.300117; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; KUHN LA, 1992, J MOL BIOL, V228, P13, DOI 10.1016/0022-2836(92)90487-5; Kuhn LA, 1995, PROTEINS, V23, P536, DOI 10.1002/prot.340230408; Mao J., 1994, P 12 INT C PATT REC, P622; MARCHAND A, 1983, AM J CLIN PATHOL, V80, P369; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768; PITT WR, 1993, J COMPUT CHEM, V14, P1007, DOI 10.1002/jcc.540140902; Poornima CS, 1995, J COMPUT AID MOL DES, V9, P500, DOI 10.1007/BF00124321; Poornima CS, 1995, J COMPUT AID MOL DES, V9, P513, DOI 10.1007/BF00124322; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; QUINLAN JR, 1986, MACHINE LEARNING ART, P149; QUINLAN JR, 1986, P 2 AUSTR C APPL EXP; Raymer M.L., 1997, P 7 INT C GEN ALG IC, P561; RAYMER ML, 2001, UNPUB PROTEIN ENG; Raymer ML, 1997, J MOL BIOL, V265, P445, DOI 10.1006/jmbi.1996.0746; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1); TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306; VAFAIE H, 1998, FEATURE EXTRACTION C, P307; VEDANI A, 1991, J AM CHEM SOC, V113, P5860, DOI 10.1021/ja00015a049; WADE RC, 1993, J MED CHEM, V36, P140, DOI 10.1021/jm00053a018; WEISS S, 1990, EMPIRICAL COMP PATTE; Weiss S., 1989, P 11 INT JOINT C ART, P781; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; YANG J, 1998, P INT JOINT C NEUR N; Yang J., 1998, FEATURE EXTRACTION C, P117	52	27	28	0	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2003	33	5					802	813		10.1109/TSMCB.2003.816922		12	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	724PN	WOS:000185496100009	18238233	
J	Podsiadlo, P; Stachowiak, GW				Podsiadlo, P; Stachowiak, GW			Fractal-wavelet based classification of tribological surfaces	WEAR			English	Article; Proceedings Paper	10th Nordic Symposium on Tribology (NORDTRIB 2002)	JUN 09-12, 2002	STOCKHOLM, SWEDEN			fractal-wavelet analysis; surface classification; tribological surfaces	TEXTURE CLASSIFICATION; WEAR; MORPHOLOGY; INSPECTION; DISTANCE; FILTERS	Classification of the topography of freshly machined, worn and damaged surfaces (e.g. damaged by adhesion, scoring, abrasion, pitting) is still a problem in machine failure analysis. Tribological surfaces often exhibit both a multiscale nature (i.e. different length scales of surface features) and a non-stationary nature (i.e. features which are superimposed on each other and located at different positions on a surface). The most widely used approaches to surface classification are based on the Fourier transform or statistical functions and parameters. Often these approaches are inadequate and provide incorrect classification of the tribological surfaces. The main reason is that these techniques fail to simultaneously capture the multiscale nature and the non-stationary nature of the surface data. A new method, called a hybrid fractal-wavelet method, has recently been developed for the characterization of tribological surfaces in a multiscale and non-stationary manner. In contrast to other methods, this method combines both the wavelets' inherent ability to characterize surfaces at each individual scale and the fractals' inherent ability to characterize surfaces in a scale-invariant manner. The application of this method to the classification of artificially generated fractal and tribological surfaces (e.g. worn surfaces) is presented in this paper. The newly developed method has been further modified to better suit tribological surface data, including a new measure of differences between initial and decoded images. The accuracy of this method in the classification of surfaces was assessed. (C) 2003 Elsevier Science B.V All rights reserved.	Univ Western Australia, Sch Mech Engn, Tribol Lab, Crawley, WA 6009, Australia	Podsiadlo, P (reprint author), Univ Western Australia, Sch Mech Engn, Tribol Lab, Crawley, WA 6009, Australia.						Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796; Baddeley A. J., 1992, ROBUST COMPUTER VISI, P59; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; Brislawn CM, 1996, APPL COMPUT HARMON A, V3, P337, DOI 10.1006/acha.1996.0026; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; Cho U, 2000, TRIBOL INT, V33, P461, DOI 10.1016/S0301-679X(00)00074-8; Coquin D, 2001, PATTERN RECOGN LETT, V22, P1483, DOI 10.1016/S0167-8655(01)00104-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HUANG Z, 2000, P INT C PATT REC, V3, P913; Kun Xu, 1997, Engineering Applications of Artificial Intelligence, V10; Mallat S., 1999, TOUR SIGNAL PROCESSI; Myshkin NK, 1997, WEAR, V203, P658, DOI 10.1016/S0043-1648(96)07432-7; Podsiadlo P, 2000, WEAR, V242, P160, DOI 10.1016/S0043-1648(00)00416-6; Podsiadlo P, 2002, TRIBOL LETT, V13, P241, DOI 10.1023/A:1021059108478; PODSIADLO P, 2001, TRIBOLOGY SERIES, V39, P697; Podsiadlo P, 2000, TRIBOLOGY SERIES, V38, P546; RAMAMOORTHY B, 1993, WEAR, V167, P155, DOI 10.1016/0043-1648(93)90320-L; ROYLANCE BJ, 1992, LUBR ENG, V48, P940; Russ J.C., 1994, FRACTAL SURFACES; Singh S, 2001, PATTERN RECOGN, V34, P1601, DOI 10.1016/S0031-3203(00)00099-6; Stachowiak GB, 2001, WEAR, V249, P201, DOI 10.1016/S0043-1648(01)00557-9; Stachowiak GW, 2001, WEAR, V249, P194, DOI 10.1016/S0043-1648(01)00562-2; Thomas TR, 1999, WEAR, V232, P41, DOI 10.1016/S0043-1648(99)00128-3; Tsai DM, 2000, INT J ADV MANUF TECH, V16, P474; Tsai DM, 1999, PATTERN RECOGN, V32, P389, DOI 10.1016/S0031-3203(98)00077-6; Wiltschi K, 2000, MACH VISION APPL, V12, P113, DOI 10.1007/s001380050130	26	15	17	1	2	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0043-1648			WEAR	Wear	OCT	2003	254	11					1189	1198		10.1016/S0043-1648(03)00333-8		10	Engineering, Mechanical; Materials Science, Multidisciplinary	Engineering; Materials Science	723UA	WOS:000185448900019		
J	Ross, ME; Zhou, XD; Song, GC; Shurtleff, SA; Girtman, K; Williams, WK; Liu, HC; Mahfouz, R; Raimondi, SC; Lenny, N; Patel, A; Downing, JR				Ross, ME; Zhou, XD; Song, GC; Shurtleff, SA; Girtman, K; Williams, WK; Liu, HC; Mahfouz, R; Raimondi, SC; Lenny, N; Patel, A; Downing, JR			Classification of pediatric acute lymphoblastic leukemia by gene expression profiling	BLOOD			English	Article							MLL TRANSLOCATIONS; PCR ANALYSIS; PRE-B; CANCER; REARRANGEMENTS; PREDICTION; DISCOVERY; E2A-PBX1; CHILDREN; SURVIVAL	Contemporary treatment of pediatric acute lymphoblastic leukemia (ALL) requires the assignment of patients to specific risk groups. We have recently demonstrated that expression profiling of leukemic blasts can accurately identify the known prognostic subtypes of ALL, including T-cell lineage ALL (T-ALL), E2A-PBX1, TEL-AML1, MLL rearrangements, BCR-ABL, and hyperdiploid karyotypes with more than 50 chromosomes. As the next step toward developing this methodology into a frontline diagnostic tool, we have now analyzed leukemic blasts from 132 diagnostic samples using higher density oligonucleotide arrays that allow the interrogation of most of the identified genes in the human genome. Nearly 60% of the newly identified subtype discriminating genes are novel markers not identified in our previous study, and thus should provide new insights into the altered biology underlying these leukemias. Moreover, a proportion of the newly selected genes are highly ranked as class discriminators, and when incorporated into class-predicting algorithms resulted in an overall diagnostic accuracy of 97%. The performance of an array containing the identified discriminating genes should now be assessed in frontline clinical trials in order to determine the accuracy, practicality, and cost effectiveness of this methodology in the clinical setting. (Blood. 2003; 102:2951-2959) (C) 2003 by The American Society of Hematology.	St Jude Childrens Res Hosp, Dept Pathol, Dept Hematol Oncol, Memphis, TN 38105 USA; St Jude Childrens Res Hosp, Hartwell Ctr Bioinformat & Biotechnol, Memphis, TN 38105 USA	Downing, JR (reprint author), St Jude Childrens Res Hosp, Dept Pathol, Dept Hematol Oncol, 332 N Lauderdale St, Memphis, TN 38105 USA.	jim.downing@stjude.org					Advani AS, 2002, LEUKEMIA RES, V26, P713, DOI 10.1016/S0145-2126(01)00197-7; Andersson A, 2001, LEUKEMIA, V15, P1293, DOI 10.1038/sj.leu.2402189; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cuthbert G, 2000, GENE CHROMOSOME CANC, V29, P180, DOI 10.1002/1098-2264(2000)9999:9999<::AID-GCC1016>3.0.CO;2-K; Downing JR, 2002, CANCER CELL, V2, P437, DOI 10.1016/S1535-6108(02)00211-8; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Ferrando AA, 2000, SEMIN HEMATOL, V37, P381, DOI 10.1016/S0037-1963(00)90018-0; Friedmann A M, 2000, Oncologist, V5, P321, DOI 10.1634/theoncologist.5-4-321; Fu XY, 1999, ONCOGENE, V18, P4920, DOI 10.1038/sj.onc.1202874; Fullwood Y, 1999, J BIOL CHEM, V274, P31553, DOI 10.1074/jbc.274.44.31553; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Harrison CJ, 2001, BRIT J HAEMATOL, V113, P3, DOI 10.1046/j.1365-2141.2001.02643.x; Horvat S, 2001, GENOMICS, V72, P209, DOI 10.1006/geno.2000.6441; Irminger-Finger I, 2002, INT J BIOCHEM CELL B, V34, P582, DOI 10.1016/S1357-2725(01)00161-3; Kasof GM, 2001, J BIOL CHEM, V276, P3238, DOI 10.1074/jbc.M003670200; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Maloney KW, 2000, LEUKEMIA, V14, P2276, DOI 10.1038/sj.leu.2401965; MARTINEZCLIMENT JA, 1995, LEUKEMIA, V9, P1299; McWhirter JR, 1999, P NATL ACAD SCI USA, V96, P11464, DOI 10.1073/pnas.96.20.11464; Moos PJ, 2002, CLIN CANCER RES, V8, P3118; PLATT J, 1999, ADV KEMEL METHODS SU, P105; Pui CH, 2000, LEUKEMIA, V14, P2286, DOI 10.1038/sj.leu.2401938; Pui CH, 1998, NEW ENGL J MED, V339, P605; Pui CH, 2001, LANCET ONCOL, V2, P597, DOI 10.1016/S1470-2045(01)00516-2; RAIMONDI SC, 1993, BLOOD, V81, P2237; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; SALLAN SE, 1980, BLOOD, V55, P395; SATHER HN, 1986, MED PEDIATR ONCOL, V14, P166, DOI 10.1002/mpo.2950140311; Schoch C, 2002, P NATL ACAD SCI USA, V99, P10008, DOI 10.1073/pnas.142103599; Schrappe M, 2000, BLOOD, V95, P3310; Silverman LB, 2001, BLOOD, V97, P1211, DOI 10.1182/blood.V97.5.1211; Smith M, 1996, J CLIN ONCOL, V14, P18; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van Dongen JJM, 1999, LEUKEMIA, V13, P1901, DOI 10.1038/sj.leu.2401592; Whittock NV, 2000, BIOCHEM BIOPH RES CO, V276, P454, DOI 10.1006/bbrc.2000.3500; Witten H.I., 2000, DATA MINING PRACTICA; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	38	349	359	1	5	AMER SOC HEMATOLOGY	WASHINGTON	1900 M STREET. NW SUITE 200, WASHINGTON, DC 20036 USA	0006-4971			BLOOD	Blood	OCT 15	2003	102	8					2951	2959		10.1182/blood-2003-01-0338		9	Hematology	Hematology	731HB	WOS:000185877300045	12730115	
J	Luaces, O; Bahamonde, A				Luaces, O; Bahamonde, A			Inflating examples to obtain rules	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							NEAREST-NEIGHBOR; LEARNING ALGORITHMS; CLASSIFICATION	A new machine learning system is presented in this article. It is called INNER and induces classification rules from a set of training examples. The process followed by this system starts with the random selection of a subset of examples that are iteratively inflated in order to cover the surroundings provided that they are inhabited by examples of the same class, thus becoming rules that will be applied by means of a partial matching mechanism. The rules so obtained can be seen as clusters of examples and represent clear evidence to support explanations about their future classifications and may be used to build intelligent advisors. The whole algorithm can be seen as a set of elastic transformations of examples and rules and produces concise, accurate rule sets, as is experimentally demonstrated in the final section of the article. (C) 2003 Wiley Periodicals, Inc.	Univ Oviedo, Artificial Intelligence Ctr, Gijon 33271, Spain	Luaces, O (reprint author), Univ Oviedo, Artificial Intelligence Ctr, Campus Viesques, Gijon 33271, Spain.			Luaces-Rodriguez, Oscar/0000-0001-8476-9412			Aha D. W., 1990, THESIS U CALIFORNIA; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bahamonde A, 1997, LECT NOTES COMPUT SC, V1240, P536; BAHAMONDE A, 1994, INT J COMPUT MATH, V54, P127, DOI 10.1080/00207169408804346; Blake C, 1998, UCI REPOSITORY MACHI; BOTANA F, 1995, INT J HUM-COMPUT ST, V42, P137, DOI 10.1006/ijhc.1995.1006; Breslow LA, 1997, KNOWL ENG REV, V12, P1, DOI 10.1017/S0269888997000015; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P, 1991, P 5 EUR WORK SESS LE, P151; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; del Coz JJ, 1999, LECT NOTES COMPUT SC, V1606, P527; Domingos P, 1996, MACH LEARN, V24, P141; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Holte RC, 1989, P 11 INT JOINT C ART, P813; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohonen T., 1995, SPRINGER SERIES INFO; Luaces O, 1999, LECT NOTES COMPUT SC, V1606, P497; LUACES O, 2000, REV IBEROAMERICANA I, V9, P38; LUACES O, 1998, LECT NOTES ARTIF INT, V1416, P448; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ranilla J, 2002, INT J HUM-COMPUT ST, V56, P445, DOI 10.1006/ijhc.1002; RANILLA J, 1998, REV IBEROAMERICANA I, V4, P4; Salzberg S.L., 1990, LEARNING NESTED GEN; SPIEGEL MR, 1970, ESTADISTICA; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Thrun S., 1991, CSCMU91197; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WNEK J, 1990, COMP LEARNING PARADI	32	9	9	0	0	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0884-8173			INT J INTELL SYST	Int. J. Intell. Syst.	NOV	2003	18	11					1113	1143		10.1002/int.10132		31	Computer Science, Artificial Intelligence	Computer Science	731UU	WOS:000185905500002		
J	Bressan, M; Vitria, J				Bressan, M; Vitria, J			Nonparametric discriminant analysis and nearest neighbor classification	PATTERN RECOGNITION LETTERS			English	Article						nearest neighbors classifier; nonparametric discriminant analysis; face recognition	RECOGNITION	Nonparametric discriminant analysis (NDA), opposite to other nonparametric techniques, has received little or no attention within the pattern recognition community. Nearest neighbor classification (NN) instead, has a well established position among other classification techniques due to its practical and theoretical properties. In this paper, we observe that when we seek a linear representation adapted to improve NN performance, what we obtain not surprisingly is quite close to NDA. Since a hierarchy is provided on the extracted features it also serves as a dimensionality reduction technique that preserves NN performance. Experiments evaluate and compare NN classification using our proposed representation against more classical feature extraction techniques. (C) 2003 Elsevier B.V. All rights reserved.	Univ Autonoma Barcelona, CVC, Bellaterra 08193, Barcelona, Spain; Univ Autonoma Barcelona, Dept Informat, Bellaterra 08193, Barcelona, Spain	Bressan, M (reprint author), Univ Autonoma Barcelona, CVC, Bellaterra 08193, Barcelona, Spain.		Vitria, Jordi/C-7072-2008	Vitria, Jordi/0000-0003-1484-539X			Blake C, 1998, UCI REPOSITORY MACHI; Bressan M, 2003, PATTERN RECOGN, V36, P691, DOI 10.1016/S0031-3203(02)00104-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1990, NN PATTERN CLASSIFIC; Devijver P. A., 1982, PATTERN RECOGNITION; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, DISCRIMINATORY ANAL; FOGARTY TC, 1992, MACH LEARN, V9, P387, DOI 10.1007/BF00994113; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Martinez A., 1998, 24 COMP VIS CTR; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X	14	64	70	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	NOV	2003	24	15					2743	2749		10.1016/S0167-8655(03)00117-X		7	Computer Science, Artificial Intelligence	Computer Science	713LN	WOS:000184859600022		
J	Singh, S				Singh, S			Multiresolution estimates of classification complexity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; classification complexity; feature space partitioning	PATTERN-CLASSIFICATION; PROBABILITY; RECOGNITION; INFORMATION; ERROR	In this paper, we study two measures of classification complexity based on feature space partitioning: "purity" and "neighborhood separability." The new measures of complexity are compared with probabilistic distance measures and a number of other nonparametric estimates of classification complexity on a total of 10 databases from the University of Calfornia, Irvine, (UCl) repository.	Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England	Singh, S (reprint author), Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England.	s.singh@ex.ac.uk					BENBESSAT M, 1982, HDB STAT, P773; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; BOHM C, 2001, ACM SURVEYS; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHERNOFF A, 1966, ANN I STAT MATH, V18, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Fisher A., 1923, MATH THEORY PROBABIL; FIX E, 1949, 2149004 US AIR FORC; FOLEY JD, 1987, COMPUTER GRAPHICS PR; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; Fukunaga K., 1990, INTRO STAT PATTERN R; GLICK N, 1973, ANN I STAT MATH, V25, P373, DOI 10.1007/BF02479383; Ho T. K., 2000, P 15 INT C PATT REC, P43; Ho TK, 2000, LECT NOTES COMPUT SC, V1857, P97; Ho TK, 1998, COMPUT VIS IMAGE UND, V70, P101, DOI 10.1006/cviu.1998.0624; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; HO TK, 2001, P 2 INT WORKSH MULT, P53; HO TK, 1994, INT C PATT RECOG, P178; Hunter G., 1978, THESIS PRINCETON U; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; Kishore JK, 2001, INFORM SCIENCES, V131, P65, DOI 10.1016/S0020-0255(00)00081-5; Kohn AF, 1996, PATTERN RECOGN, V29, P873, DOI 10.1016/0031-3203(95)00122-0; Loftsgaarden D., 1965, ANN MATH STAT, P1049; MADDOX J, 1990, NATURE, V344, P705; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Perlin K., 1989, Computer Graphics, V23; PIERSON WE, UNPUB USE BOUNDARY M; PIERSON WE, 1998, THESIS OHIO STAT U; PIERSON WE, 1998, P SPIE C AUT TARG RE, V7; RAHMAN AFR, 1998, P INT C IM AN PROC, P893; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; SANCHO JL, 1996, P IEE C MATHS SIGN P; SANCHO JL, 1996, SIGNAL PROCESSING CO; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; SINGH S, 2002, P 15 INT C PATTERN R, V2, P144; SINGH S, 2003, PATTERN ANAL APPL, V6; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137; Therrien C.W, 1989, DECISION ESTIMATION; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; VAPNIK VN, 1998, STAT LEARNING THEOER; WALLACE CS, 1968, COMPUT J, V11, P185; WILLIAMS AC, 1997, P SPIE ITN S OPT ENG; XIE Q, 1993, IEEE T PATTERN ANAL, P1326; Young Tzay Y., 1986, HDB PATTERN RECOGNIT	47	29	29	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1534	1539		10.1109/TPAMI.2003.1251146		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	746UA	WOS:000186765000003		
J	Nock, R; Sebban, M; Bernard, D				Nock, R; Sebban, M; Bernard, D			A simple locally adaptive nearest neighbor rule with application to pollution forecasting	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						machine learning; case-based reasoning; neighborhood; pollution forecasting	CLASSIFICATION	In this paper, we propose a thorough investigation of a nearest neighbor rule which we call the "Symmetric Nearest Neighbor (sNN) rule". Basically, it symmetrises the classical nearest neighbor relationship from which are computed the points voting for some instances. Experiments on 29 datasets, most of which are readily available, show that the method significantly outperforms the traditional Nearest Neighbors methods. Experiments on a domain of interest related to tropical pollution normalization also show the greater potential of this method. We finally discuss the reasons for the rule's efficiency, provide methods for speeding-up the classification time, and derive from the sNN rule a reliable and fast algorithm to fix the parameter k in the k-NN rule, a longstanding problem in this field.	Univ Antilles Guyane, Grimaag Dept Sci Interfac, F-97275 Schoelcher, France; Univ St Etienne, Eurise Dept Informat, F-42023 St Etienne 2, France	Nock, R (reprint author), Univ Antilles Guyane, Grimaag Dept Sci Interfac, Campus Schoelcher,BP 7209, F-97275 Schoelcher, France.	rnock@martinique.univ-ag.fr; Marc.Sebban@univ-st-etienne.fr; dbernard@univ-ag.fr					BERNARD D, 1995, MAR POLLUT BULL, V30, P619, DOI 10.1016/0025-326X(95)00085-2; Blake C, 1998, UCI REPOSITORY MACHI; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DRAKOPOULOS JA, 1995, P 12 INT C MACH LEAR, P203; FIX E, 1951, TR2149004 USAF SCH A; Freidman J., 1997, ACM T MATH SOFTWARE, V3, P209; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Friedman JH, 1994, FLEXIBLE METRIC NEAR; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HARWOOD D, 1987, PATTERN RECOGN LETT, V6, P155, DOI 10.1016/0167-8655(87)90002-X; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; KNAPP RR, 1998, UVMCS19980101 U VERM; Nock R, 2001, PATTERN RECOGN LETT, V22, P413, DOI 10.1016/S0167-8655(00)00137-9; Okamoto S., 1996, P 13 INT C MACH LEAR, P355; PALAU AM, 1998, P 14 INT C PATT REC, V1; Venkatesh S. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130396; Wilson D.R., 1997, P 14 INT C MACH LEAR, P404; Yanilos P., 1993, P 4 ANN ACM SIGACT S, P311	20	6	6	2	3	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 912805, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	DEC	2003	17	8					1369	1382		10.1142/S0218001403002952		14	Computer Science, Artificial Intelligence	Computer Science	766KR	WOS:000188376000005		
J	Markou, M; Singh, S				Markou, M; Singh, S			Novelty detection: a review - part 1: statistical approaches	SIGNAL PROCESSING			English	Review						novelty detection review; statistical approaches; Gaussian mixture models; hidden Markov models; KNN; Parzen density estimation; string matching; clustering	REJECT OPTION; CLASSIFICATION; OUTLIERS; NETWORK; SYSTEM	Novelty detection is the identification of new or unknown data or signal that a machine learning system is not aware of during training. Novelty detection is one of the fundamental requirements of a good classification or identification system since sometimes the test data contains information about objects that were not known at the time of training the model. In this paper we provide state-of-the-art review in the area of novelty detection based on statistical approaches. The second part paper details novelty detection using neural networks. As discussed, there are a multitude of applications where novelty detection is extremely important including signal processing, computer vision, pattern recognition, data mining, and robotics. (C) 2003 Elsevier B.V. All rights reserved.	Univ Exeter, PANN Res, Dept Comp Sci, Exeter EX4 4PT, Devon, England	Markou, M (reprint author), Univ Exeter, PANN Res, Dept Comp Sci, Exeter EX4 4PT, Devon, England.						BAKER LD, 1999, HIERARCHICAL PROBABI; Barnett V., 1994, OUTLIERS STAT DATA, V3rd; BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; Bishop C., 1994, P IEE C VIS IM SIGN, P217; BROTHERTON T, 1998, P IJCNN C ANCH MAY; CAMPBELL C, 2001, ADV NIPS, V14; CARPENTER GA, 1997, P INT C NEUR NETW, V3, P1459, DOI 10.1109/ICNN.1997.614010; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; CORDELLA LP, 1995, IEEE T NEURAL NETWOR, V6, P1140, DOI 10.1109/72.410358; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta D., 1996, P INT C INT SYST REN; DASGUPTA D, 2001, CS01001 U MEMPH DIV; Dasgupta D., 2000, P IEEE INT C SYST MA, V1, P125; Dasgupta D., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004386; Desforges MJ, 1998, P I MECH ENG C-J MEC, V212, P687, DOI 10.1243/0954406981521448; Duda R O, 2001, PATTERN CLASSIFICATI; Elad M, 2002, PATTERN RECOGN LETT, V23, P1459, DOI 10.1016/S0167-8655(02)00106-X; Fisher RA, 1928, P CAMB PHILOS SOC, V24, P180; Foggia P, 1999, PATTERN RECOGN, V32, P1435, DOI 10.1016/S0031-3203(98)00169-1; Forrest S., 1994, Proceedings of 1994 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.94CH3444-7), DOI 10.1109/RISP.1994.296580; Fumera G, 2000, PATTERN RECOGN, V33, P2099, DOI 10.1016/S0031-3203(00)00059-5; Guh RS, 1999, ARTIF INTELL ENG, V13, P413, DOI 10.1016/S0954-1810(99)00022-9; Guttormsson S. E., 1999, IEEE T ENERGY CONVER, V14; HANSEN LK, 2000, P IEEE ICASSP 2000, V6, P3494; Hansen L. K., 1997, Open Systems & Information Dynamics, V4, DOI 10.1023/A:1009643503022; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HICKINBOTHAM SJ, 2000, P IEEE IJCNN COM IT; Japkowicz N., 1995, P 14 JOINT C ART INT, P518; Jiang MF, 2001, PATTERN RECOGN LETT, V22, P691, DOI 10.1016/S0167-8655(00)00131-8; King S., 2002, P 2002 INT C CONTR A, V1, P221, DOI DOI 10.1109/CCA.2002.1040189; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Lauer M., 2001, P 12 EUR C MACH LEAR, P300; LAURIKKALA J, 2000, INTELLIGENT DATA ANA; MANIKOPOULOS C, 2002, IEEE COMM MAG    OCT, V40; MANSON G, 2001, P 4 INT C DAM ASS ST; Manson G., 2002, P IES C SWANS UK; MANSON G, 2000, P 7 INT S SMART STRU; Nairac A, 1999, INTEGR COMPUT-AID E, V6, P53; Nairac A., 1997, P 5 IEE INT C ART NE, P227; ODIN T, 2000, P COMADEN C HOUST TX; Parra L, 1996, NEURAL COMPUT, V8, P260, DOI 10.1162/neco.1996.8.2.260; Pizzi NJ, 2001, ARTIF INTELL MED, V21, P263, DOI 10.1016/S0933-3657(00)00095-6; ROBERTS S, 1994, NEURAL COMPUT, V6, P270, DOI 10.1162/neco.1994.6.2.270; Roberts SJ, 1999, IEE P-VIS IMAGE SIGN, V146, P124, DOI 10.1049/ip-vis:19990428; ROBERTS SJ, 2002, P 1 INT C ADV MED SI, P166; Ruotolo R., 1997, P 5 PAN AM C APPL ME; SAUNDERS R, 2000, P ARTIFICIAL INTELLI; SCARTH GB, 1995, P INT SOC MAGN RES M, P238; SINGH S, 2003, IN PRESS IEEE T KNOW; Spence C, 2001, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P3; Stefano C. D., 2000, IEEE T SYST MAN CYB, V30, P84; TARAKANOV A, 2002, P C EV COMP CEC 02, V1, P938, DOI 10.1109/CEC.2002.1007051; Tarassenko L., 1999, IEE Colloquium on Condition Monitoring Machinery, External Structures and Health (Ref. No. 1999/034); Tarassenko L, 1995, P 4 IEE INT C ART NE, V4, P442; Tax D M J, 2000, INT C PATT REC, V2; Tax D. M. J., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings; Webb A, 1999, STAT PATTERN RECOGNI; Wei Fan, 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989509; Yamanishi K., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347160; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y, 2002, INT C KNOWL DISC DAT; Yang Yiming, 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953; YEUNG DY, 2002, P INT C PATT REC QUE; YEUNG DY, 2002, PATTERN RECOGN, V36, P229	64	405	424	9	67	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684			SIGNAL PROCESS	Signal Process.	DEC	2003	83	12					2481	2497		10.1016/j.sigpro.2003.018		17	Engineering, Electrical & Electronic	Engineering	739KY	WOS:000186346000001		
J	Dzeroski, S; Drumm, D				Dzeroski, S; Drumm, D			Using regression trees to identify the habitat preference of the sea cucumber (Holothuria leucospilota) on Rarotonga, Cook Islands	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	3rd European Ecological Modelling Conference	SEP 10-15, 2001	DUBROVNIK, CROATIA			machine learning; tropical marine ecology; habitat preference; sea cucumber		In the Pacific Islands, invertebrates including sea cucumbers are among the most valuable and vulnerable inshore fisheries resources. As human activities continue to force substantial impacts on coral reef ecosystems, the management of inshore fisheries has become an increasingly important priority. Knowledge of the distribution, biology and habitat requirements of a species can significantly enhance conservation efforts. The sea cucumber (Holothuria leucospilota) forms an important part of the traditional subsistence fishery on Rarotonga, Cook Islands, yet little is known of this species' present spatial distribution and abundance around the island. We apply two machine learning approaches and a classical statistical approach to predict the number of sea cucumber individuals from site characteristics. The machine learning methods used are induction of regression trees and instance-based learning. These are compared to the classical statistical approach of linear regression. The most accurate predictions are obtained using instance-based learning, while the most understandable descriptions are obtained using regression tree induction. (C) 2003 Elsevier B.V. All rights reserved.	Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia; Univ Otago, Dept Marine Sci, Dunedin, New Zealand	Dzeroski, S (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova 39, Ljubljana 1000, Slovenia.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalzell P, 1996, OCEANOGR MAR BIOL, V34, P395; DASARATHY BV, 1990, NORMS NN PATTERN CLA; Fielding A. H., 1999, MACHING LEARNING MET; Frank E., 1999, DATA MINING PRACTICA; LEK S, 1999, ECOL MODEL, V120; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Recknagel F, 2001, ECOL MODEL, V146, P1, DOI 10.1016/S0304-3800(01)00291-5; Sperduto MB, 1996, PHOTOGRAMM ENG REM S, V62, P1269; WANG Y, 1997, P POST PAP EUR C MAC; ZHOU Q, 2000, BOOK ABSTRACTS	13	33	34	1	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800			ECOL MODEL	Ecol. Model.	DEC 15	2003	170	2-3					219	226		10.1016/S0304-3800(03)00229-1		8	Ecology	Environmental Sciences & Ecology	756JB	WOS:000187461000011		
B	Yin, TK; Chiu, NT			IEEE Comp Soc	Yin, TK; Chiu, NT			Discrimination between alzheimer's dementia and controls by automated analysis of statistical parametric maps of Tc-99m-HMPAO-SPECT volumes	BIBE 2004: FOURTH IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS			English	Proceedings Paper	4TH IEEE Symposium on Bioinformatics and Bioengineering (BIBE 2004)	MAY 19-21, 2004	Tai Chung, TAIWAN	IEEE Comp Soc, IEEE Neural Networks Soc, Taichung Healthcare & Management Univ, Minist Educ, Natl Sci Council, Inst Informat Ind			CEREBRAL BLOOD-FLOW; PHOTON-EMISSION-TOMOGRAPHY; REFERENCE REGION; DISEASE; SPECT; BRAIN; QUANTIFICATION; DIAGNOSIS; PERFUSION; CHOICE	Alzheimer's disease is a chronic degenerative disease of the central nervous system. Clinically early detection of Alzheimer's disease is helpful in taking care of the patients. The nuclear imaging method, single-photon emission computed tomography (SPECT), is a useful tool in analyzing the cerebral blood flow. Most common regional abnormalities for Alzheimer's disease are symmetric or asymmetric bilateral temporal or parietal hypoperfusion, or frontal hypoperfusion. Statistical Parametric Mapping (SPM) is employed to do pre-processing of SPECT volumes. Due to its effectiveness, easiness and fastness, SPM has been widely applied to the diagnosis and function research of brain diseases. The proposed system can provide a quantitatively automatic analysis of the SPECT volumes. The selection of three variables based on the statistical parametric t maps between Alzheimer's and normal volumes are proposed Then an optimal linear classifier is applied to discriminate between these two group of volumes. In statistical pattern recognition, the Bayes error the overlap among different class densities, is the smallest possible error in the current measurement space. Due to the effectiveness of the variable selection, the simple optimal linear classifier achieves a near-Bayes error ratio. The sensitivity and specificity of the proposed method are 88% and 90%, respectively. With the high sensitivity and specificity performance, the proposed automatic analysis of brain SPECT volumes can assist in the clinical practice of radiologists.	Chia Nan Univ Pharm & Sci, Dept Management Informat Sci, Tainan, Taiwan	Yin, TK (reprint author), Chia Nan Univ Pharm & Sci, Dept Management Informat Sci, Tainan, Taiwan.						BRUN A, 1981, HISTOPATHOLOGY, V5, P549, DOI 10.1111/j.1365-2559.1981.tb01818.x; Claus JJ, 1999, EUR J NUCL MED, V26, P265, DOI 10.1007/s002590050387; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devous MD, 2002, EUR J NUCL MED MOL I, V29, P1685, DOI 10.1007/s000259-002-0967-2; Elgh E, 2002, EUR J NUCL MED MOL I, V29, P1140, DOI 10.1007/s00259-002-0829-y; Friston K. J., 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; FRISTON KJ, 1991, J CEREBR BLOOD F MET, V11, P690; Friston K. J., 1994, HUMAN BRAIN MAPPING, V1, P214; FRISTON KJ, 1995, HUMAN BRAIN MAPPING, V2, P165; Fukunaga K., 1990, STAT PATTERN RECOGNI; Goethals I, 2002, EUR J NUCL MED MOL I, V29, P975, DOI 10.1007/s00259-002-0872-8; Haykin S., 1994, NEURAL NETWORKS COMP; Holmes AP, 1996, J CEREBR BLOOD F MET, V16, P7; IIDA H, 1994, J NUCL MED, V35, P2019; KUHL DE, 1982, J NUCL MED, V23, P196; METZ CE, 1986, INVEST RADIOL, V21, P720; OHNISHI T, 1995, J NUCL MED, V36, P1163; Penedo MG, 1998, IEEE T MED IMAGING, V17, P872, DOI 10.1109/42.746620; PETERSON DW, 1966, IEEE T INFORM THEORY, V12, P380, DOI 10.1109/TIT.1966.1053913; Pickut BA, 1999, PSYCHIAT RES-NEUROIM, V90, P103, DOI 10.1016/S0925-4927(99)00004-9; POLINE JB, 1993, J CEREBR BLOOD F MET, V13, P425; Rajapakse JC, 2001, IEEE T BIO-MED ENG, V48, P1186, DOI 10.1109/10.951522; Salmon E, 2000, HUM BRAIN MAPP, V10, P39, DOI 10.1002/(SICI)1097-0193(200005)10:1<39::AID-HBM50>3.0.CO;2-B; Signorini M, 1999, NEUROIMAGE, V9, P63, DOI 10.1006/nimg.1998.0381; Sjobeck M, 2001, DEMENT GERIATR COGN, V12, P211, DOI 10.1159/000051260; SOKOLOFF L, 1981, FED PROC, V40, P2311; Soonawala D, 2002, NEUROIMAGE, V17, P1193, DOI 10.1006/nimg.2002.1259; STONE M, 1974, J R STAT SOC B, V36, P111; STROTHER SC, 1995, J CEREBR BLOOD F MET, V15, P738; SYED GMS, 1992, NUCL MED COMMUN, V13, P811, DOI 10.1097/00006231-199211000-00007; Talairach J., 1988, CO PLANAR STEREOTAXI; TALBOT PR, 1994, EUR J NUCL MED, V21, P503; TERRY RD, 1994, ALZHEIMER DIS; WANG GJ, 1994, J NUCL MED, V35, P1457; WORSLEY KJ, 1992, J CEREBR BLOOD F MET, V12, P900	35	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2173-8				2004							183	190				8	Biochemistry & Molecular Biology; Computer Science, Interdisciplinary Applications; Medicine, Research & Experimental	Biochemistry & Molecular Biology; Computer Science; Research & Experimental Medicine	BAH58	WOS:000222238200025		
B	Goldschmidt, RR; Passos, EL; Godoy, RA; Schettini, F; Paolino, A		Chu, HW; Savoie, M; Sanchez, B		Goldschmidt, RR; Passos, EL; Godoy, RA; Schettini, F; Paolino, A			Assistance in selecting KDD algorithms	International Conference on Computing, Communications and Control Technologies, Vol 1, Proceedings			English	Proceedings Paper	International Conference on Computing, Communications and Control Technologies (CCCT 2004)	AUG 14-17, 2004	Austin, TX	Univ Texas Austin, Int Inst Informat & System, IEEE Comp Soc, Venezuela Chapter, Inter Amer Org Higher Educ		knowledge discovery in databases; knowledge discovery assistance; ranking data mining algorithms		Knowledge Discovery in Databases, or KDD for short, is a non-trivial process of identifying useful patterns in huge databases. It is an interactive and iterative process that involves several steps with many decisions being made by users. A new and fertile research area, referenced in the present work as KDD Assistance, is concerned about the development of computational mechanisms that help men in making decisions in KDD processes. An important step in KDD process concerns the choice of which data mining algorithm(s) should be used in new databases. The present work aims at evaluating a ranking algorithm based approach. Given a new database, such approach takes algorithms' past performance in similar databases into consideration in order to indicate which algorithms should be tried on first. A computational tool to implement this approach was developed and is described in detail. Experiments with six classification algorithms and several databases are reported.	PUC Rio NUPAC, Ctr Cidade, Escola Ciencias Exatas & Tecnol, ICA Computat Intelligence Lab, Rio De Janeiro, Brazil	Goldschmidt, RR (reprint author), PUC Rio NUPAC, Ctr Cidade, Escola Ciencias Exatas & Tecnol, ICA Computat Intelligence Lab, Rio De Janeiro, Brazil.						BRAZDIL P, 2003, MACHINE LEARNING, V50; Brodley CE., 1993, P 10 INT C MACH LEAR; CID D, 2001, P 2 C LOG ART INT RO, V2, P81; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ENGELS P, 1998, P 13 EUR C ART INT; FAYYAD UM, 1996, COMMUN ACM, P27; GOLDSCHMIDT R, 2002, IC AI 02 INT C AI LA; GOLDSCHMIDT R, 2003, THESIS PONTIFICIA U; GOLDSCHMIDT R, 2003, CLEI 03 C LAT INF LA; GONCALVES LB, 2001, THESIS PONTIFICIA U; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Michie D., 1994, MACHINE LEARNING NEU; NEAVE H, 1992, DISTRIBUTIONS FREE T; Quinlan J. R., 1993, PROGRAMS MACHINE LEA, Vfirst; Weiss S. M., 1998, PREDICTIVE DATA MINI; Wolpert D. H., 1996, SFITR9502010	16	0	0	0	0	INT INST INFORMATICS & SYSTEMICS	ORLANDO	14269 LORD BARCLAY DR, ORLANDO, FL 32837 USA			980-6560-17-5				2004							12	17				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BBV04	WOS:000227981900003		
B	Li, J; Liang, QL; Manry, MT			ieee	Li, J; Liang, QL; Manry, MT			Co-channel interference suppression with model simplification in TDMA systems	2004 IEEE 15TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1-4, PROCEEDINGS			English	Proceedings Paper	15th IEEE International Symposium on Personal, Indoor, Mobile, Radio Communications (PIMRC 2004)	SEP 05-08, 2004	Barcelona, SPAIN	IEEE		mobile communication; co-channel interference; TDMA; learning vector quantization	EQUALIZER	This paper studies the co-channel interference (CCI) problem for time-division-multiple-access (TDMA) cellular mobile communication systems with burst transmission. We present a method using Learn Vector Quantization (LVQ) to cancel CCI for such systems. The model of the overall CCo is significantly simplified based on that of the individual CCI. The LVQ is realized as a classification equalizer with a decision feedback adaptive filter. An extremely small number of unique words (UWs) is utilized to initialize the LVQ equalizer. Simulation results show that the bit error rate (BER) of our proposed method is much better than that of the recently proposed nearest neighbor classification (NNC) equalizer.	Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA	Li, J (reprint author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.						Anderson B. D. O., 1979, OPTIMAL FILTERING; BENELLI G, 1991, P INT C GLOBECOM 91, P1469; CHEN S, 1992, SIGNAL PROCESS, V28, P91, DOI 10.1016/0165-1684(92)90067-7; Chen S, 1996, IEE P-COMMUN, V143, P219, DOI 10.1049/ip-com:19960612; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVELLA R, 1989, IEEE J SEL AREA COMM, V7, P122, DOI 10.1109/49.16853; FORNEY GD, 1972, IEEE T INFORM THEORY, V18, P363, DOI 10.1109/TIT.1972.1054829; GERSHO A, 1982, IEEE T INFORM THEORY, V28, P157, DOI 10.1109/TIT.1982.1056457; Jakes W., 1993, MICROWAVE MOBILE COM; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1990, P INT JOINT C NEUR N, P545; LI J, 2004, IN PRESS P ICASSP 20; Liang QL, 2000, IEEE T CIRCUITS-II, V47, P1419, DOI 10.1109/82.899635; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Rappaport T. S., 1996, WIRELESS COMMUNICATI; SAVAZZI P, 2000, IEEE J SEL AREA COMM, V16, P418; SKLLAR B, 1997, IEEE COMMUN MAG, V35, P148	17	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8523-3				2004							1302	1306				5	Telecommunications	Telecommunications	BBH14	WOS:000225483300253		
B	Wang, YJ; Guan, L			IEEE	Wang, YJ; Guan, L			An investigation of speech-based human emotion recognition	2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING			English	Proceedings Paper	6th IEEE Workshop on Multimedia Signal Processing	SEP 29-OCT 01, 2004	Siena, ITALY	IEEE Signal Proc Soc, Multimedia Signal Proc Tech Comm, Univ Degli Studi di Siena, Monte dei Paschi de Siena				This paper presents our recent work on recognizing human emotion from speech signal. The proposed recognition system was tested over a language, speaker, and context independent emotional speech database. Prosodic, Mel-Frequency Cepstral Coefficient (MFCC),. features are extracted from the and formant frequency speech utterances. We perform feature selection by using stepwise method based on Mahalanobis distance. The selected features are used to classify the speeches into their corresponding emotional classes. Different classification algorithms including Maximum Likelihood Classifier (MLC), Gaussian Mixture Model (GMM), Neural Network (NN), K-nearest Neighbors (K-NN), and Fisher's Linear Discriminant Analysis (FLDA) are compared in this study. The recognition results show that FLDA gives the best recognition accuracy by using the selected features.	Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON M5B 2K3, Canada	Wang, YJ (reprint author), Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON M5B 2K3, Canada.						BHATTI MW, 2004, IEEE ISCAS VANC 0523; Bilmes J. A., 1998, ICSITR97021; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HIRST D, 1992, TALKING MACHINE THEO; KWON O, 2003, EMOTION RECOGNITION; LEE CM, 2002, P INT C MULT EXP	6	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8578-0				2004							15	18				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BBC43	WOS:000224752800004		
B	Li, HF; Zhang, KS; Jiang, T			IEEE Comp Soc	Li, HF; Zhang, KS; Jiang, T			Minimum entropy clustering and applications to gene expression analysis	2004 IEEE COMPUTATIONAL SYSTEMS BIOINFORMATICS CONFERENCE, PROCEEDINGS			English	Proceedings Paper	IEEE Computational Systems Bioinformatics Conference (CSB 2004)	AUG 16-19, 2004	Stanford, CA	IEEE Comp Soc, Hewlett-Packard Co, Coop Platinum, BioMed Cent, Off Sci, US DOE			DENSITY-FUNCTION; PATTERNS; CRITERIA; NETWORK	Clustering is a common methodology for analyzing the gene expression data. In this paper, we present a new clustering algorithm from an information-theoretic point of view. First, we propose the minimum entropy (measured on a posteriori probabilities) criterion, which is the conditional entropy of clusters given the observations. Fano's inequality indicates that it could be a good criterion for clustering. We generalize the criterion by replacing Shannon's entropy with Havrda-Charvat's structural a-entropy. Interestingly, the minimum entropy criterion based on structural a-entropy is equal to the probability error of the nearest neighbor method when alpha = 2. This is another evidence that the proposed criterion is good for clustering. With a nonparametric approach for estimating a posteriori probabilities, an efficient iterative algorithm is then established to minimize the entropy. The experimental results show that the clustering algorithm performs significantly better than k-means/medians, hierarrhical clustering, SOM, and EM in terms of adjusted Rand index. Particularly, our algorithm performs very well even when the correct number of clusters is unknown. In addition, most clustering algorithms produce poor partitions in presence of outliers while our method can correctly reveal the structure of data and effectively identify outliers simultaneously.	Univ Calif Riverside, Riverside, CA 92521 USA	Li, HF (reprint author), Univ Calif Riverside, Riverside, CA 92521 USA.						Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda R. O., 1973, PATTERN CLASSIFICATI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Everitt B. S., 2001, CLUSTER ANAL, V5th; FRALEY C, 2002, 415R U WASH DEP STAT; Fukunaga K., 1990, INTRO STAT PATTERN R; Han J., 2000, DATA MINING CONCEPTS; Havrda J., 1967, KYBERNETIKA, V3, P30; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Ideker T, 2001, SCIENCE, V292, P929, DOI 10.1126/science.292.5518.929; Jain A. K., 1988, ALGORITHMS CLUSTERIN; KAPUR J, 1994, MEASURES INFORMATION; Kapur J. N., 1967, MATH SEMINAR, V4, P78; Kohonen Teuvo, 2001, SELF ORGANIZING MAPS; Li M., 1997, INTRO KOLMOGOROV COM; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MILLIGAN GW, 1986, MULTIVAR BEHAV RES, V21, P441, DOI 10.1207/s15327906mbr2104_5; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Renyi A., 1961, 4TH P BERK S MATH ST, P547; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Shannon E. C., 1948, BELL SYST TECH J, V27, P623; Tavazoie S, 1999, NAT GENET, V22, P281; Yeung KY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-5-r34; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763	30	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2194-0				2004							142	151				10	Biotechnology & Applied Microbiology; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Genetics & Heredity	Biotechnology & Applied Microbiology; Computer Science; Genetics & Heredity	BAX76	WOS:000224127800015		
B	Zheng, WM; Zou, CR; Zhao, L			IEEE	Zheng, WM; Zou, CR; Zhao, L			Face recognition using two novel nearest neighbor classifiers	2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS: DESIGN AND IMPLEMENTATION OF SIGNAL PROCESSING SYSTEMS INDUSTRY TECHNOLOGY TRACKS MACHINE LEARNING FOR SIGNAL PROCESSING MULTIMEDIA SIGNAL PROCESSING SIGNAL PROCESSING FOR EDUCATION			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing	MAY 17-21, 2004	Montreal, CANADA	IEEE Signal Proc Soc, IEEE			FEATURE LINE METHOD; CLASSIFICATION; RETRIEVAL	In this paper, two novel classifiers based on locally nearest neighborhood rule, called nearest neighbor line (NNL) and nearest neighbor plane (NNP), are presented for face recognition. The underlying idea of both classifiers is the local linear combination technique that has been previously used in locally linear embedding (LLE) for nonlinear dimension reduction. Comparison to other linear combination based classifiers such as the nearest feature line (NFL) and the nearest feature plane (NFP), the proposed method takes much lower computation cost. Furthermore, the experimental results on the ORL face database have shown that the performance of both proposed methods are competitive to the NFL and NFP in face classification.	Southeast Univ, Res Ctr Learning Sci, Nanjing 210096, Jiangsu, Peoples R China	Zheng, WM (reprint author), Southeast Univ, Res Ctr Learning Sci, Nanjing 210096, Jiangsu, Peoples R China.						BICHSEL M, 1994, CVGIP-IMAG UNDERSTAN, V59, P254, DOI 10.1006/cviu.1994.1019; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Li SZ, 1998, PROC CVPR IEEE, P839, DOI 10.1109/CVPR.1998.698702; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; Saul L. K., 2001, INTRO LOCALLY LINEAR; ULHMAN S, 1991, IEEE T PAMI, V13, P992	12	0	0	0	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA							2004							725	728				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Telecommunications	Computer Science; Engineering; Imaging Science & Photographic Technology; Telecommunications	BAH10	WOS:000222179700182		
B	Fuentealba, C; Simon, C; Choffel, D; Charpentier, P; Masson, D			IEEE	Fuentealba, C; Simon, C; Choffel, D; Charpentier, P; Masson, D			Wood products identification by internal characteristics readings	2004 IEEE International Conference on Industrial Technology (ICIT), Vols. 1- 3			English	Proceedings Paper	IEEE International Conference on Industrial Technology (ICIT)	DEC 08-10, 2004	Hammamet, TUNISIA	IEEE		wood product; automatic identification; traceability; k-nearest neighbors		The traceability of products is an ever growing demand of quality for many areas. In the manufacturing process, traceability is required to follow-up all the production cycle of the product. Consequently, product traceability can result in a great control of the production process, thus allows improving control of production tools and reacting to their deficiencies. For wood industries, implementation of current identification techniques is not easy, due to the extremely variable nature of the wood and the particular features of the manufacturing process. In this article, we implement a traceability tool within a manufacturing process using the intrinsic characteristics of the wood product. The goal is to achieve an individual identification of products. We use a microwave sensor to obtain a unique signature of the product and then we develop its identification. Thus, the identification process on the basis of a numerical product signature can be considered as a discrimination problem as for the nearest neighbor method. We evaluate the error rate of identification by a Monte Carlo simulation of the process. This work shows the high potential of developing an identification system based on the use of the intrinsic characteristics of product.	CRAN, Fac Sci, F-54506 Vandoeuvre Les Nancy, France	Fuentealba, C (reprint author), CRAN, Fac Sci, BP 239, F-54506 Vandoeuvre Les Nancy, France.						CHARPENTIER P, 2003, FOREST PRODUCTS J, V53; CHAXEL F, 2002, P IEEE INT C SYST MA, V4; Chiorescu S, 2003, FOREST PROD J, V53, P78; CHOFFEL D, 2001, P 10 IFAC S INF CONT; CHOFFEL D, 1992, P 1 SEM SCANN TECHN; CHOFFEL D, 1999, P SPIE MACH VIS SYST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GUZENDA R, 2000, 12 INT S NOND TEST W; JAIN A, 2000, COMMUNICATIONS ACM, V43; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4; Menard M, 2001, FUZZY SET SYST, V122, P363, DOI 10.1016/S0165-0114(00)00052-X; PARKER JR, 2002, P VIS INT 2002 CALG, P27; SASAKI Y, 2000, 12 INT S NOND TEST W; SIMON C, 1997, P BRAZ S DOC IM AN, P261; TANAKA T, 2000, 12 INT S NOND TEST W; TORGONIKOV GI, 1992, DIELECTRIC PROPERTIE; WALKER JCF, 1992, PRIMARY WOOD PROCESS	18	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8662-0				2004							763	768				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BCW39	WOS:000231537500136		
S	Figueira, LB; Nicoletti, MD			IEEE	Figueira, LB; Nicoletti, MD			Evaluating the effects of distance metrics on a NGE-based system	2004 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN & CYBERNETICS, VOLS 1-7	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-13, 2004	The Hague, NETHERLANDS	IEEE		NGE learning; distance metrics; HVDM; IVDM; WVDM	LEARNING ALGORITHMS; NEAREST-NEIGHBOR; CLASSIFICATION	The Nested Generalized Exemplar (NGE) model (implemented by EACH algorithm) is an incremental form of inductive learning from examples that generalizes a given training set into hypotheses represented as a set of hyper-rectangles in an n-dimensional Euclidean space. NGE depends heavily on the distance Metric used in both processes, learning and classification. This work investigates the impact on the predictive accuracy of the learnt concepts by NGE as a consequence of using three new heterogeneous distance functions namely HVDM, IVDM and WVDM, instead of the Euclidean distance metric originally proposed. The paper presents and analyses the results of experiments in various domains using the Euclidean and the three heterogeneous distance functions.	Unif Fed San Carlos, Dept Comp Sci, Sao Carlos, SP, Brazil	Figueira, LB (reprint author), Unif Fed San Carlos, Dept Comp Sci, Sao Carlos, SP, Brazil.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Merz C, 1998, UCI REPOSITORY MACHI; SALZBERG S, 1991, MACH LEARN, V6, P252; SALZBERG SL, 1989, THESIS HARVARD U CAM; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WOLPERT DH, 92035001 SFI TR NM	12	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		0-7803-8566-7	IEEE SYS MAN CYBERN			2004							3395	3401		10.1109/ICSMC.2004.1400867		7	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Robotics	Automation & Control Systems; Computer Science; Robotics	BBP32	WOS:000226863300572		
S	Snchez, JS; Sotoca, JM; Pla, F			IEEE	Snchez, JS; Sotoca, JM; Pla, F			Efficient nearest neighbor classification with data reduction and fast search algorithms	2004 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN & CYBERNETICS, VOLS 1-7	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-13, 2004	The Hague, NETHERLANDS	IEEE		classification; nearest neighbor; data reduction; fast search algorithm	PATTERN-CLASSIFICATION; RULE	The Nearest Neighbor classfier is one of the most popular non-parametric classification methods. It is very simple, intuitive and accurate in a great variety of real-world applications. Despite its simplicity and effectiveness, practical use of this decision rule has been historically limited due to its high storage requirements and the computational costs involved. In order to overcome these drawbacks, it is possible either to employ fast search algorithms or to use a training set size reduction scheme. The present paper provides a comparative analysis of fast search algorithms and data reduction techniques to assess their pros and cons from both theoretical and practical viewpoints.	Univ Jaume 1, Dept Llenguatges & Sist Informt, E-12071 Castellon de La Plana, Spain	Snchez, JS (reprint author), Univ Jaume 1, Dept Llenguatges & Sist Informt, Av Sos Baynat S-N, E-12071 Castellon de La Plana, Spain.						ALINAT P, 1993, 5516 ROARS ESPRIT; Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kim SW, 2003, PATTERN RECOGN, V36, P1083, DOI 10.1016/S0031-3203(02)00115-2; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Merz C, 1998, UCI REPOSITORY MACHI; MIC L, 1996, PATTERN RECOGN, V17, P731; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311	26	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		0-7803-8566-7	IEEE SYS MAN CYBERN			2004							4757	4762				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Robotics	Automation & Control Systems; Computer Science; Robotics	BBP32	WOS:000226863300801		
S	Zeng, XC; Martinez, TR			ieee	Zeng, XC; Martinez, TR			Feature weighting using neural networks	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council			LEARNING ALGORITHMS	In this work we propose a feature weighting method for classification tasks by extracting relevant information from a trained neural network. This method weights an attribute based on strengths (weights) of related links in the neural network, in which an important feature is typically connected to strong links and has more impact on the outputs. This method is applied to feature weighting for the nearest neighbor classifier and is tested on 15 real-world classification tasks. The results show that it can improve the nearest neighbor classifier on 14 of the 15 tested tasks, and also outperforms the neural network on 9 tasks.	Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Zeng, XC (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Breiman L., 1984, CLASSIFICATION REGRE; Cardie C., 1993, P 10 INT C MACH LEAR, P25; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; John G., 1994, P 11 INT C MACH LEAR, P121; Ling CX, 1997, INT J PATTERN RECOGN, V11, P405, DOI 10.1142/S0218001497000184; Merz C. J., 1996, UCI REPOSITORY MACHI; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	9	2	2	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-8359-1	IEEE IJCNN			2004							1327	1330				4	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900230		
S	Anguita, D; Ridella, S; Rivieccio, F; Zunino, R; Amerio, S; Lazzizzera, I			ieee	Anguita, D; Ridella, S; Rivieccio, F; Zunino, R; Amerio, S; Lazzizzera, I			Model selection in top quark tagging with a support vector classifier	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council				The problem of tagging a Top Quark generation event in data coming from the Collider Detector at Fermilab is here considered and tackled through the use of a Support Vector Machine Classifier. In order to select a fitting model, a twofold procedure has been adopted. The SVC hyperparameters have been selected through the bootstrap technique and then an additional tuning of the bias value and the error relevance has been performed by means both of a Purity Vs. Efficiency curve and of the AUC value. The generalization capability of the model has been evaluated using the Maximal Discrepancy criterion.	Univ Genoa, Dept Biophys & Elect Engn, DIBE, I-16145 Genoa, Italy	Anguita, D (reprint author), Univ Genoa, Dept Biophys & Elect Engn, DIBE, Via Opera Pia 11A, I-16145 Genoa, Italy.		Lazzizzera, Ignazio/E-9678-2015; 	Lazzizzera, Ignazio/0000-0001-5092-7531; Anguita, Davide/0000-0001-7523-5291			ABACHI S, 1997, UNPUB PHYS REV LETT; Abe F, 1997, PHYS REV LETT, V79, P1992, DOI 10.1103/PhysRevLett.79.1992; Anguita D, 2003, NEUROCOMPUTING, V55, P109, DOI 10.1016/S0925-2312(03)00430-2; Anguita D, 2000, NEURAL PROCESS LETT, V11, P51, DOI 10.1023/A:1009636300083; Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CORTES C, 2004, ADV NEURAL INFORMATI, V16; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X; Efron B, 1993, MONOGRAPHS STAT APPL; EGAN JP, 1975, SIGNAL DETECTION THE; Fisher RA, 1936, ANN EUGENIC, V7, P179; GUYON I, ONLINE SVM APPL LIST; LAENEN E, 1994, PHYS LETT B, V321, P254, DOI 10.1016/0370-2693(94)90473-1; PARISI G, 1978, PHYS LETT B, V74, P65, DOI 10.1016/0370-2693(78)90061-8; SIDOTI A, 1999, THESIS U TRENTO; SJOSTRAND T, 1986, COMPUT PHYS COMMUN, V39, P347, DOI 10.1016/0010-4655(86)90096-2; VANNEREM P, 1999, P AIHENP 99; Vapnik V., 1998, STAT LEARNING THEORY	19	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		0-7803-8359-1	IEEE IJCNN			2004							2059	2064				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900356		
S	Chakrabarti, A; Regev, O			ieee computer society	Chakrabarti, A; Regev, O			An optimal randomised cell probe lower bound for approximate nearest neighbour searching	45TH ANNUAL IEEE SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, PROCEEDINGS	ANNUAL IEEE SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE		English	Proceedings Paper	45th Annual IEEE Symposium on Foundations of Computer Science	OCT 17-19, 2004	Rome, ITALY	IEEE Comp Soc, Tech Soc Fdn Comp			PROTEIN SECONDARY STRUCTURE; PREDICTION	We consider the approximate nearest neighbour search problem on the Hamming Cube {0, 1}(d). We show that a randomised cell probe algorithm that uses polynomial storage and word size d(O(1)) requires a worst case query time of Omega (log log d/log log log d). The approximation factor may be as loose as 2(log1-eta) (d) for any fixed eta > 0. This generalises an earlier result [5] on the deterministic complexity of the same problem and, more importantly, fills a major gap in the study of this problem since all earlier lower bounds either did not allow randomisation [5, 18] or did not allow approximation [4, 2, 15]. We also give a cell probe algorithm which proves that our lower bound is optimal. Our proof uses a lower bound on the round complexity of the related communication problem. We show, additionally, that considerations of bit complexity alone cannot prove any nontrivial cell probe lower bound for the problem. This shows that the Richness Technique [20] used in a lot of recent research around this problem would not have helped here. Our proof is based on information theoretic techniques for communication complexity, a theme that has been prominent in recent research [6, 1, 23, 14]. In particular we make heavy use of the round elimination and message compression ideas in the recent work of Sen [23] and Jain, Radhakrishnan, and Sen [14], and also introduce a new technique which we call message switching.	Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA	Chakrabarti, A (reprint author), Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.						Barkol O., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335350; Bar-Yossef Z., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181944; BEAME P, 2003, COMMUNICATION; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; Miltersen P. B., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195415; Chakrabarti A., 2001, Proceedings 42nd IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2001.959901; Chakrabarti A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301325; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Duda R. O., 1973, PATTERN CLASSIFICATI; FREDMAN ML, 1984, J ACM, V31, P538, DOI 10.1145/828.1884; Har-Peled S., 2001, Proceedings 42nd IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2001.959884; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Jain R., 2003, P 30 INT C AUT LANG, P300; Jayram T.S., 2003, P 35 ANN ACM S THEOR, P667; Klauck H., 2001, P 33 ANN ACM S THEOR, P124, DOI 10.1145/380752.380786; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; LIU D, 2003, UNPUB STRONG LOWER B; Miltersen PB, 1998, J COMPUT SYST SCI, V57, P37, DOI 10.1006/jcss.1998.1577; Miltersen P. B., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, DOI 10.1145/225058.225093; Overmars M., 2000, COMPUTATIONAL GEOMET, V2nd; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; SALTON G, 1983, INTRO MODERN INFORMA; Sen P., 2003, Proceedings 18th IEEE Annual Conference on Computational Complexity; Yao AC, 1977, P 18 ANN IEEE S FDN, P222, DOI DOI 10.1109/SFCS.1977.24; YAO ACC, 1981, J ACM, V28, P615, DOI 10.1145/322261.322274; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464	28	3	3	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0272-5428		0-7695-2228-9	ANN IEEE SYMP FOUND			2004							473	482		10.1109/FOCS.2004.12		10	Computer Science, Theory & Methods	Computer Science	BBF37	WOS:000225221700049		
S	Quang, LS; Bao, HT		Dai, H; Srikant, R; Zhang, C		Quang, LS; Bao, HT			A conditional probability distribution-based dissimilarity measure for categorial data	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th Pacific/Asia Conference on Advances in Knowledge Discovery and Data Mining	MAY 26-28, 2004	Sydney, AUSTRALIA	NICIA, SAS, Univ Technol Sydney, Deakin Univ		dissimilarity measures; categorical data; conditional probability; hypothesis testing		Measuring the similarity between objects described by categorical attributes is a difficult task because no relations between categorical values can be mathematically specified or easily established. In the literature, most similarity (dissimilarity) measures for categorical data consider the similarity of value pairs by considering whether or not these two values are identical. In these methods, the similarity (dissimilarity) of a non-identical value pair is simply considered 0 (1). In this paper, we introduce a dissimilarity measure for categorical data by imposing association relations between non-identical value pairs of an attribute based on their relations with other attributes. The key idea is to measure the similarity between two values of a categorical attribute by the similarities of the conditional probability distributions of other attributes conditioned on these two values. Experiments with a nearest neighbor algorithm demonstrate the merits of our proposal in real-life data sets.	Japan Adv Inst Sci & Technol, Sch Knowledge Sci, Tatsunokuchi, Ishikawa 9231292, Japan	Quang, LS (reprint author), Japan Adv Inst Sci & Technol, Sch Knowledge Sci, Tatsunokuchi, Ishikawa 9231292, Japan.	quag@jaist.ac.jp; bao@jaist.ac.jp					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALBERT ML, 1983, QUANTITATIVE APPL SO, V32; BATAGELJ V, 1995, J CLASSIFICATION, V12; BAULIEU FB, 1989, J CLASSIF, P233; BLAKE CL, 1998, REPOSITORY MACHNINE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; GOWER JC, 1986, J CLASSIF, P5; HUANG Z, 1988, DATA MIN KNOWL DISC, V2, P283; HUBALEK Z, 1982, BIOL REV, V57, P669, DOI 10.1111/j.1469-185X.1982.tb00376.x; KAUFMANN L, 1987, STAT DATA ANAL BASED, V405, P87; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; KULLBACK S, 1959, INFORMATION THEORY S; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; NENE SA, 1997, IEEETPAMI IEEE T PAT, V19	16	0	0	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22064-X	LECT NOTES ARTIF INT			2004	3056						580	589				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAF29	WOS:000221955100067		
S	Li, JY; Ramamohanarao, K		Dai, H; Srikant, R; Zhang, C		Li, JY; Ramamohanarao, K			A tree-based approach to the discovery of diagnostic biomarkers for ovarian cancer	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th Pacific/Asia Conference on Advances in Knowledge Discovery and Data Mining	MAY 26-28, 2004	Sydney, AUSTRALIA	NICIA, SAS, Univ Technol Sydney, Deakin Univ		decision trees; committee method; ovarian cancer; biomarkers; classification	CLASSIFICATION; PREDICTION	Computational diagnosis of cancer is a classification problem, and it has two special requirements on a learning algorithm: perfect accuracy and small number of features used in the classifier. This paper presents our results on an ovarian cancer data set. This data set is described by 15154 features, and consists of 253 samples. Each sample is referred to a woman who suffers from ovarian cancer or who does not have. In fact, the raw data is generated by the so-called mass spectrosmetry technology measuring the intensities of 15154 protein or peptide-features in a blood sample for every woman. The purpose is to identify a small subset of the features that can be used as biomarkers to separate the two classes of samples with high accuracy. Therefore, the identified features can be potentially used in routine clinical diagnosis for replacing labour-intensive and expensive conventional diagnosis methods. Our new tree-based method can achieve the perfect 100% accuracy in 10-fold cross validation on this data set. Meanwhile, this method also directly outputs a small set of biomarkers. Then we explain why support vector machines, naive bayes, and k-nearest neighbour cannot fulfill the purpose. This study is also aimed to elucidate the communication between contemporary cancer research and data mining techniques.	Inst Infocomm Res, Singapore 119613, Singapore; Univ Melbourne, Dept CSSE, Melbourne, Vic 3010, Australia	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@i2r.a-star.edu.sg; rao@cs.mu.oz.au					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Duda R. O., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Freund Y., 1996, INT C MACH LEARN, P148; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Huiqing Liu, 2002, GENOME INFORMATICS, P51; JINYAN L, 2003, P ICDM, P585; JULIA D, 2001, NATURE REV CANC, V3, P267; Langley P., 1994, P 10 C UNC ART INT, P399; LI JY, 2003, BIOINFORMATICS, V19, P1193; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Quinlan J. R., 1993, C45 PROGRAMS MACHINE; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	18	0	0	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22064-X	LECT NOTES ARTIF INT			2004	3056						682	691				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAF29	WOS:000221955100078		
S	Sierra, B; Lazkano, E; Martinez-Otzeta, JM; Astigarraga, A		Webb, GI; Yu, X		Sierra, B; Lazkano, E; Martinez-Otzeta, JM; Astigarraga, A			Combining Bayesian networks, k nearest neighbours algorithm and attribute selection for gene expression data analysis	AI 2004: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	17th Annual Australian Conference on Artificial Intelligence	DEC 04-06, 2004	Cairns, AUSTRALIA		Cent Queensland Univ		FEATURE SUBSET-SELECTION; CLASSIFICATION; DISCOVERY; CANCER	In the last years, there has been a large growth in gene expression profiling technologies, which are expected to provide insight into cancer related cellular processes. Machine Learning algorithms, which are extensively applied in many areas of the real world, are not still popular in the Bioinformatics community. We report on the successful application of the combination of two supervised Machine Learning methods, Bayesian Networks and k Nearest Neighbours algorithms, to cancer class prediction problems in three DNA microarray datasets of huge dimensionality (Colon, Leukemia and NCI-60). The essential gene selection process in microarray domains is performed by a sequential search engine and after used for the Bayesian Network model learning. Once the genes are selected for the Bayesian Network paradigm, we combine this paradigm with the well known K NN algorithm in order to improve the classification accuracy.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, E-20080 San Sebastian, Spain	Sierra, B (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, POB 649, E-20080 San Sebastian, Spain.	ccpsiarb@si.ehu.es	Martinez-Otzeta, Jose Maria/K-6464-2014	Martinez-Otzeta, Jose Maria/0000-0001-5015-1315			Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; BLANCO R, 2004, INT J PATTERN RECOGN; Chickering D. M., 2002, J MACHINE LEARNING R, V3, P507; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Doak J., 1992, CSE9218 U CAL DAV; Friedman N., 1996, AAAI IAAI, V2, P1277; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; INZA I, 2002, IN PRESS J INTELLIGE; JENSEN F, 2001, BAYESIAN NETWORKS DE; Kittler J., 1978, Pattern Recognition and Signal Processing; KOHAVI R, 1995, P INT JOINT C ART IN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; Lazkano E, 2003, LECT NOTES ARTIF INT, V2902, P171; LI L, 2000, P 1 C CRIT ASS MICR, pA6061; LI W, 2000, P 1 C CRIT ASS MICR; Liu H., 1998, FEATURE SELECTION KN; Mitchell T. M., 1997, MACHINE LEARNING; PEARL J, 1987, ARTIF INTELL, V32, P247; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; ROMERO D, 2004, INT J PATTERN RECOGN, V18, P45; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHANNON CE, 1948, AT&T TECH J, V27, P379; Sierra B, 2001, ARTIF INTELL MED, V22, P233, DOI 10.1016/S0933-3657(00)00111-1; Sierra B, 1998, ARTIF INTELL MED, V14, P215, DOI 10.1016/S0933-3657(98)00024-4; Xing E., 2001, P 18 INT C MACH LEAR, P601	30	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-24059-4	LECT NOTES ARTIF INT			2004	3339						86	97				12	Computer Science, Artificial Intelligence	Computer Science	BBM32	WOS:000226133600008		
S	Sucahyo, YG; Gopalan, RP		Webb, GI; Yu, X		Sucahyo, YG; Gopalan, RP			Building a more accurate classifier based on strong frequent patterns	AI 2004: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	17th Annual Australian Conference on Artificial Intelligence	DEC 04-06, 2004	Cairns, AUSTRALIA		Cent Queensland Univ			The classification problem in data mining is to discover models from training data for classifying unknown instances. Associative classification builds the classifier rules using association rules and it is more accurate compared to previous methods. In this paper, a new method named CSFP that builds a classifier from strong frequent patterns without the need to generate association rules is presented. We address the rare item problem by using a partitioning method. Rules generated are stored using a compact data structure named CP-Tree and a series of pruning methods are employed to discard weak frequent patterns. Experimental results show that our classifier is more accurate than previous associative classification methods as well as other state-of-the-art non-associative classifiers.	Curtin Univ Technol, Dept Comp, Bentley, WA 6102, Australia	Sucahyo, YG (reprint author), Curtin Univ Technol, Dept Comp, Kent St, Bentley, WA 6102, Australia.	sucahyoy@cs.curtin.edu.au; raj@cs.curtin.edu.au					AGRAWAL R, 1993, P ACM SIGMOD WASH; COHEN W, 1995, P ICML TAH CITY CA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG G, 1999, P 2 INT C DISC SCI T; Duda R O, 2001, PATTERN CLASSIFICATI; Fayyad U., 1993, P IJCAI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GOPALAN RP, 2004, P SIAM INT WORKSH HP; KOHAVI R, 1994, MLC MACHINE LEARNING, P740; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; LI W, 2001, P IEEE ICDM SAN JOS; LIU B, 2000, P PKDD 2000 LYON FRA; LIU B, 1998, P ACM SIGKDD NEW YOR; MERETAKIS D, 1999, P ACM SIGKDD SAN DIE; QUINTANA JR, 1992, REV IBEROAMERICANA P, V1, P5; Yin X., 2003, P SIAM INT C DAT MIN; ZHANG X, P IDEAL HONG KONG	17	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-24059-4	LECT NOTES ARTIF INT			2004	3339						1036	1042				7	Computer Science, Artificial Intelligence	Computer Science	BBM32	WOS:000226133600098		
J	Kos, G; Krska, R; Lohninger, H; Griffiths, PR				Kos, G; Krska, R; Lohninger, H; Griffiths, PR			A comparative study of mid-infrared diffuse reflection (DR) and attenuated total reflection (ATR) spectroscopy for the detection of fungal infection on RWA2-corn	ANALYTICAL AND BIOANALYTICAL CHEMISTRY			English	Article						attenuated total reflection; diffuse reflection; mid-infrared spectroscopy; comparison study; cereals; mycotoxins	PARTICLE-SIZE MORPHOLOGY; CARBOHYDRATE SYSTEMS; SAMPLE DILUTION; MYCOTOXINS; CEREALS; SPECTRA; WHEAT; CORN; CHROMATOGRAPHY; TRICHOTHECENES	An investigation into the rapid detection of mycotoxin-producing fungi on corn by two mid-infrared spectroscopic techniques was undertaken. Corn samples from a single genotype (RWA2, blanks, and contaminated with Fusarium graminearum) were ground, sieved and, after appropriate sample preparation, subjected to mid-infrared spectroscopy using two different accessories (diffuse reflection and attenuated total reflection). The measured spectra were evaluated with principal component analysis (PCA) and the blank and contaminated samples were classified by cluster analysis. Reference data for fungal metabolites were obtained with conventional methods. After extraction and clean-up, each sample was analyzed for the toxin deoxynivalenol (DON) by gas chromatography with electron capture detection (GC-ECD) and ergosterol (a parameter for the total fungal biomass) by high-performance liquid chromatography with diode array detection (HPLC-DAD). The concentration ranges for contaminated samples were 880-3600 mug/kg for ergosterol and 300-2600 mug/kg for DON. Classification efficiency was 100% for ATR spectra. DR spectra did not show as obvious a clustering of contaminated and blank samples. Results and trends were also observed in single spectra plots. Quantification using a PLS1 regression algorithm showed good correlation with DON reference data, but a rather high standard error of prediction (SEP) with 600 mug/kg (DR) and 490 mug/kg (ATR), respectively, for ergosterol. Comparing measurement procedures and results showed advantages for the ATR technique, mainly owing to its ease of use and the easier interpretation of results that were better with respect to classification and quantification.	IFA Tulln, Inst Agrobiotechnol, Ctr Analyt Chem, A-3430 Tulln, Austria; Vienna Univ Technol, Div Analyt Chem, Inst Chem Technol & Analyt, A-1060 Vienna, Austria; Univ Idaho, Dept Chem, Moscow, ID 83844 USA	Krska, R (reprint author), IFA Tulln, Inst Agrobiotechnol, Ctr Analyt Chem, Konrad Lorenz Str 20, A-3430 Tulln, Austria.			Kos, Gregor/0000-0001-7076-3802			*AFNOR, 1991, V18112 AFNOR NF, P1; BECHTEL DB, 1985, CEREAL CHEM, V62, P191; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; D'Mello JPF, 1999, ANIM FEED SCI TECH, V80, P183, DOI 10.1016/S0377-8401(99)00059-0; European Commission, 2000, SANCO192500REV1 DGSA, P1; *GIPSA, 2002, GRAIN FUNG DIS MYC R; GORDON SH, 1993, BIOTECHNOL ADV, V11, P665, DOI 10.1016/0734-9750(93)90035-L; Gordon SH, 1997, INT J FOOD MICROBIOL, V35, P179, DOI 10.1016/S0168-1605(96)01217-2; GREENE RV, 1992, J AGR FOOD CHEM, V40, P1144, DOI 10.1021/jf00019a011; HOCHSTEINER W, 2001, TIERARZTL MONATSSCHR, P342; *ISO, 1994, ISOTC34SC10N508; Kos G, 2003, ANAL CHEM, V75, P1211, DOI 10.1021/ac0260903; Krska R, 2001, FRESEN J ANAL CHEM, V371, P285, DOI 10.1007/s002160100992; Langseth W, 1998, J CHROMATOGR A, V815, P103, DOI 10.1016/S0021-9673(98)00388-4; LOHNINGER H, 2000, DATALAB PROGRAM STAT; LOHNINGER H, 1999, TEACHME DATA ANAL; Marquardt RR, 1996, ANIM FEED SCI TECH, V58, P77, DOI 10.1016/0377-8401(95)00875-6; Miller JD, 1994, MYCOTOXINS GRAIN COM; MIRAGLIA M, 1998, MYCOTOXINS PHYCOTOXI; Naes T., 2002, USER FRIENDLY GUIDE; OLINGER JM, 1993, APPL SPECTROSC, V47, P695, DOI 10.1366/0003702934067054; OLINGER JM, 1993, APPL SPECTROSC, V47, P687, DOI 10.1366/0003702934066965; OTTO M, 1997, CHEMOMETRIE; PARK DL, 1989, J ASSOC OFF ANA CHEM, V72, P399; Pittet A, 1998, REV MED VET-TOULOUSE, V149, P479; SCHWADORF K, 1989, J ASSOC OFF ANA CHEM, V72, P457; SEITZ LM, 1977, CEREAL CHEM, V54, P1201; Smith J. E., 1991, MYCOTOXINS ANIMAL FO; Stuchebryukov SD, 1997, OPT COMMUN, V140, P36, DOI 10.1016/S0030-4018(97)00143-0; TRUCKSESS MW, 1995, J AOAC INT, V78, P135; Weingaertner J, 1997, FRESEN J ANAL CHEM, V357, P1206, DOI 10.1007/s002160050332; WHEELER BC, 1993, P 15 INT C I EL EL E, P7037; Wilson RH, 1999, TRAC-TREND ANAL CHEM, V18, P85, DOI 10.1016/S0165-9936(98)00107-1	33	26	26	3	10	SPRINGER-VERLAG HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1618-2642			ANAL BIOANAL CHEM	Anal. Bioanal. Chem.	JAN	2004	378	1					159	166		10.1007/s00216-003-2245-y		8	Biochemical Research Methods; Chemistry, Analytical	Biochemistry & Molecular Biology; Chemistry	752DW	WOS:000187132600033	14551669	
S	Jankowski, N; Grochowski, M		Rutkowski, L; Siekmann, J; Tadeusiewicz, R; Zadeh, LA		Jankowski, N; Grochowski, M			Comparison of instances seletion algorithms I. Algorithms survey	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING - ICAISC 2004	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	7th International Conference on Artificial Intelligence and Soft Computing	JUN 07-11, 2004	Zakopane, POLAND	Polish Neural Network Soc, Czestochowa Univ Technol, Dept Comp Engn			NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS	Several methods were proposed to reduce the number of instances (vectors) in the learning set. Some of them extract only bad vectors while others try to remove as many instances as possible without significant degradation of the reduced dataset for learning. Several strategies to shrink training sets axe compared here using different neural and machine learning classification algorithms. In part H (the accompanying paper) results on benchmarks databases have been presented.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Ul Grudziadzka 5, PL-87100 Torun, Poland.	norbert@phys.uni.torun.pl; grochu@phys.uni.torun.pl	Grochowski, Marek/D-6342-2014; Jankowski, Norbert/H-1071-2014				ADAMCZAK R, 1997, 3 C NEUR NETW THEIR, P65; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bhattacharya B., 1981, INT S INF THEOR SANT; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cameron-Jones R. M., 1995, P 8 AUSTR JOINT C AR, P99; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 1997, PATTER CLASSIFICATIO, V2; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GRABCZEWSKI K, 1999, 4 C NEUR NETW THEIR, P203; Grochowski M., 2003, THESIS N COPERNICUS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JANKOWSKI N, 1997, 7 INT C ART NEUR NET, P385; Jankowski N., 2000, NEURAL NETWORKS SOFT, P209; Kohonen T., 1986, TKKFA601 HELS U TECH; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SCHOLKOPF B, 2002, LEARNNG KERNELS; Skalak D. B., 1994, INT C MACH LEARN, P293; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	20	36	36	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22123-9	LECT NOTES ARTIF INT			2004	3070						598	603				6	Computer Science, Artificial Intelligence	Computer Science	BAH85	WOS:000222325200090		
B	Vogt, P		Pollack, J; Bedau, M; Husbands, P; Ikegami, T; Watson, RA		Vogt, P			Minimum cost and the emergence of the Zipf-Mandelbrot law	Artificial Life IX			English	Proceedings Paper	9th International Conference on the Simulation and Synthesis of Artificial Life (ALIFE9)	SEP 12-15, 2004	Boston, MA	Int Soc Artificial Life, Brandeis Univ				This paper illustrates how the Zipf-Mandelbrot law can emerge in language as a result of minimising the cost of categorising sensory images. The categorisation is based on the discrimination game in which sensory stimuli are categorised at different hierarchical layers of increasing density. The discrimination game is embedded in a variant of the language game model, called the selfish game, which in turn is embedded in the framework of iterated learning. The results indicate that a tendency to communicate in general terms, which is less costly, can contribute to the emergence of the Zipf-Mandelbrot law.	Univ Edinburgh, Language Evolut & Computat Res Unit, Edinburgh, Midlothian, Scotland	Vogt, P (reprint author), Univ Edinburgh, Language Evolut & Computat Res Unit, Edinburgh, Midlothian, Scotland.						Cancho RFI, 2003, P NATL ACAD SCI USA, V100, P788, DOI 10.1073/pnas.0335980100; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gardenfors Peter, 2000, CONCEPTUAL SPACES; Gunther R, 1996, INT J THEOR PHYS, V35, P395, DOI 10.1007/BF02083823; Kirby S., 2002, LINGUISTIC EVOLUTION; LI WT, 1992, IEEE T INFORM THEORY, V38, P1842, DOI 10.1109/18.165464; Lloyd B. B., 1978, COGNITION CATEGORIZA; Mandelbrot B., 1953, COMMUN THEORY, P503; MILLER GA, 1957, AM J PSYCHOL, V70, P311, DOI 10.2307/1419346; Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7; SMITH ADM, 2003, ARTIF LIFE, V9, P559; SMITH K, IN PRESS J THEORETIC; STEELS L, 1996, P INT C MUTL AG SYST; Steels L., 2002, TRANSITION LANGUAGE; TULLO C, 2003, LANGUAGE EVOLUTION C; VOGT P, 2003, ADV ARTIFICIAL LIFE; VOGT P, 2004, P BEN 2004; VOGT P, 2004, P EV, V5; Vogt P., 2000, EVOLUTION COMMUNICAT, V4, P89; Zipf G. K., 1949, HUMAN BEHAV PRINCIPL	20	1	1	0	2	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA			0-262-66183-7				2004							214	219				6	Biology; Computer Science, Artificial Intelligence	Life Sciences & Biomedicine - Other Topics; Computer Science	BCV06	WOS:000231382900035		
S	Kosar, K; Lhotska, L; Krajca, V		Barreiro, JM; MartinSanchez, F; Maojo, V; Sanz, F		Kosar, K; Lhotska, L; Krajca, V			Classification of long-term EEG recordings	BIOLOGICAL AND MEDICAL DATA ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Symposium on Biological and Medical Data Analysis (ISBMDA)	NOV   18, 2004	Barcelona, SPAIN				ADAPTIVE SEGMENTATION; SEIZURE DETECTION	Computer assisted processing of long-term EEG recordings is gaining a growing importance. To simplify the work of a physician, that must visually evaluate long recordings, we present a method for automatic processing of EEG based on learning classifier. This method supports the automatic search of long-term EEG recording and detection of graphoelements - signal parts with characteristic shape and defined diagnostic value. Traditional methods of detection show great percent of error caused by the great variety of non-stationary EEG. The idea of this method is to break down the signal into stationary sections called segments using adaptive segmentation and create a set of normalized discriminative features representing segments. The groups of similar patterns of graphoelements form classes used for the learning of a classifier. Weighted features are used for classification performed by modified learning classifier fuzzy k-Nearest Neighbours. Results of classification describe classes of unknown segments. The implementation of this method was experimentally verified on a real EEG with the diagnosis of epilepsy.	Czech Tech Univ, Gerstner Lab, Prague 16627 6, Czech Republic; Univ Hosp Bulovka, Prague 18081 8, Czech Republic	Kosar, K (reprint author), Czech Tech Univ, Gerstner Lab, Technicka 2, Prague 16627 6, Czech Republic.	1hotska@fel.cvut.cz; krajca@fnb.cz					Agarwal R, 1998, ELECTROEN CLIN NEURO, V107, P44, DOI 10.1016/S0013-4694(98)00009-1; BODENSTEIN G, 1977, P IEEE, V65, P642, DOI 10.1109/PROC.1977.10543; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVEY BLK, 1989, MED BIOL ENG COMPUT, V27, P365, DOI 10.1007/BF02441427; GUTMAN J, 1982, ELECTROENCEPHALOGR C, V83, P271; HORNERO R, 1999, IEEE ENG MED BIOL, P73; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KRAJCA V, 1992, LEKAR TECHNIKA, V2, P28; KRAJCA V, 1991, INT J BIOMED COMPUT, V28, P71, DOI 10.1016/0020-7101(91)90028-D; Mayer-Kress Gottfried, 1994, Integrative Physiological and Behavioral Science, V29, P205, DOI 10.1007/BF02691325; PETROSIAN A, 1995, P SOC PHOTO-OPT INS, V2569, P189, DOI 10.1117/12.217574; PLOTKIN EI, P CCECE 21 SEPT 1992; QU H, 1993, ELECTROEN CLIN NEURO, V86, P79, DOI 10.1016/0013-4694(93)90079-B; Smith S. W., 1997, DIGITAL SIGNAL PROCE; VARRI A, 1988, DIGITAL PROCESSING E; Weng W, 1996, NEURAL NETWORKS, V9, P1223, DOI 10.1016/0893-6080(96)00032-9	16	5	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23964-2	LECT NOTES COMPUT SC			2004	3337						322	332				11	Biochemistry & Molecular Biology; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Medical Informatics	Biochemistry & Molecular Biology; Computer Science; Medical Informatics	BBM23	WOS:000226129700033		
S	Park, SB; Chang, JH; Zhang, BT		Gelbukh, A		Park, SB; Chang, JH; Zhang, BT			Korean compound noun decomposition using syllabic information only	COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Conference on Intelligent Text Processing and Computational Linguistics	FEB 15-21, 2004	Seoul, SOUTH KOREA	Assoc Computat Linguist				The compound nouns are freely composed in Korean, since it is possible to concatenate independent nouns without a postposition. Therefore, the systems that handle compound nouns such as machine translation and information retrieval have to decompose them into single nouns for the further correct analysis of texts. This paper proposes the GECORAM (GEneralized COmbination of Rule-based learning And Memory-based learning) algorithm for Korean compound noun decomposition using only syllabic information. The merit of rule-based learning algorithms is high comprehensibility, but they shows low performance in many application tasks. To tackle this problem, GECORAM combines the rule-based learning and memory-based learning. According to the experimental results, GECORAM shows higher accuracy than rule-based learning or memory-based learning alone.	Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151744, South Korea	Park, SB (reprint author), Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151744, South Korea.	sbpark@bi.snu.ac.kr; jhchang@bi.snu.ac.kr; btzhang@bi.snu.ac.kr					Abney S., 1999, P 1999 JOINT SIGDAT, P38; Brill E, 1995, COMPUT LINGUIST, V21, P543; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Cohens W, 1995, P 12 INT C MACH LEAR, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W., 2001, TIMBL TILBURG MEMORY; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; KANG SS, 1998, J KISS, V25, P172; LEE JW, 1999, P MT SUMM 7, P427; PARK SB, 2003, P 41 ANN M ASS COMP, P497; QUINLAN R, 1995, P 12 INT C MACH LEAR, P464; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; SHIM KS, 1999, P 3 CHIN KOR JOINT S, P106; YOON BH, 1997, KISS J, V24, P900	16	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-21006-7	LECT NOTES COMPUT SC			2004	2945						146	157				12	Computer Science, Information Systems; Computer Science, Theory & Methods; Language & Linguistics	Computer Science; Linguistics	BY59Y	WOS:000189417900018		
S	Moon, J; Shon, T; Seo, J; Kim, J; Seo, J		Aykanat, C; Dayar, T; Korpeoglu, I		Moon, J; Shon, T; Seo, J; Kim, J; Seo, J			An approach for spam E-mail detection with support vector machine and n-gram indexing	COMPUTER AND INFORMATION SCIENCES - ISCIS 2004, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	19th International Symposium on Computer and Information Sciences (ISCIS 2004)	OCT 27-29, 2004	Kemer Antalya, TURKEY	Bilkent Univ, Dept Comp Engn, Inst Elect & Elect Engineers Turkey Sect, Working Grp, Int Federat Informat Proc, Sci & Tech Res Council Turkey				Many solutions have been deployed to prevent harmful effects from spam mail. Typical methods are either pattern matching using the keyword or method using the probability such as naive Bayesian method. In this paper, we proposed a classification method of spam mail from normal mail using support vector machine, which has excellent performance in binary pattern classification problems. Especially, the proposed method efficiently practices a learning procedure with a word dictionary by the n-gram. In the conclusion, we showed our proposed method being superior to others in the aspect of comparing performance.	Korea Univ, Ctr Informat Secur Technol, Seoul 136701, South Korea; ETRI, Natl Secur Res Inst, Taejon, South Korea; Samsung Elect Co, Suwon, South Korea	Moon, J (reprint author), Korea Univ, Ctr Informat Secur Technol, Seoul 136701, South Korea.	jsmoon@korea.ac.kr; 743zh2k@korea.ac.kr; seojt@etri.re.kr; sky45k@korea.ac.kr; korea002@korea.ac.kr					Androutsopoulos I., 2000, 23 ANN INT ACM SIGIR, P160; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Campbell C., 1998, SIMPLE LEARNING ALGO; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTIANINI N, 2000, SUPPORT VECTOR MACHI, P33; ION A, 2000, PKDD 2000, P1; JOACHIMS T, MYSVM SUPPORTS VECTO; Joachims T, 1998, EUR C MACH LEARN ECM, P137; JOONHO L, 1996, KOREAN SOC INFORMATI, V7, P47; MEHRAN S, 1998, AAA198 WORKSH LEARN; PONTIL M, 1997, 152 CBCL; Ruping S., 2000, MYSVM MANUAL; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Vapnik V. N., 1995, NATURE STAT LEARNING	15	2	2	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23526-4	LECT NOTES COMPUT SC			2004	3280						351	362				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BBE06	WOS:000225096700036		
S	Claus, D; Fitzgibbon, AW		Pajdla, T; Matas, J		Claus, D; Fitzgibbon, AW			Reliable fiducial detection in natural scenes	COMPUTER VISION - ECCV 2004, PT 4	Lecture Notes in Computer Science		English	Article; Proceedings Paper	8th European Conference on Computer Vision	MAY 11-14, 2004	Prague, CZECH REPUBLIC	Business Informat Grp as, Camea spol sro, Casablanca INT sro, ECVision, Microsoft Res, Miracle Network sro, Neovision sro, Toyota			NEIGHBOR; SPACE	Reliable detection of fiducial targets in real-world images is addressed in this paper. We show that even the best existing schemes are fragile when exposed to other than laboratory imaging conditions, and introduce an approach which delivers significant improvements in reliability at moderate computational cost. The key to these improvements is in the use of machine learning techniques, which have recently shown impressive results for the general object detection problem, for example in face detection. Although fiducial detection is an apparently simple special case, this paper shows why robustness to lighting, scale and foreshortening can be addressed within the machine learning framework with greater reliability than previous, more ad-hoc, fiducial detection schemes.	Univ Oxford, Dept Engn Sci, Oxford OX1 3BN, England	Claus, D (reprint author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3BN, England.	dclaus@robots.ox.ac.uk; awf@robots.ox.ac.uk					Berchtold S, 1998, PROC INT CONF DATA, P209, DOI 10.1109/ICDE.1998.655779; Bruckstein AM, 2000, INT J COMPUT VISION, V39, P131, DOI 10.1023/A:1008123110489; CHO Y, 1998, P IEEE VRAIS; CLAUS D, 2004, VIDEO BASED SURVEYIN; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; Cover T., 1967, IEEE T INFORM THEORY, V13, P57; Duda R O, 2001, PATTERN CLASSIFICATI; Efrat A, 1994, INT J COMPUT GEOM AP, V4, P403, DOI 10.1142/S0218195994000227; Harris C., 1988, P 4 ALV VIS C, P147; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kato H., 1999, IWAR 99, P85; KLEIN G, 2002, P BRIT MACH VIS C BM, V2, P787; Lopez-De-Ipina D, 2002, PERS UBIQUIT COMPUT, V6, P206, DOI 10.1007/s007790200020; MALBEZIN P, 2002, 1 INT AR TOOLK WORKS; MELLOR JP, 1995, 1544 AI MIT; NAIMARK L, 2002, ISMAR; NEUMANN U, 1995, IEEE VIRT REAL ANN I, P189; Owen C.B., 2002, 1 IEEE INT AUGM REAL, P98; Rekimoto J., 2000, P DARE; RIPLEY BD, 1997, SIMCAT; Scharstein D, 2001, IMAGE VISION COMPUT, V19, P763, DOI 10.1016/S0262-8856(00)00105-0; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; State A., 1996, SIGGRAPH 96, P429; Viola P., 2001, P CVPR; Welch G., 1999, P ACM S VIRT REAL SO, P1, DOI 10.1145/323663.323664; Wellner P. D., 1993, EPC1993110 XER; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	27	6	6	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-21981-1	LECT NOTES COMPUT SC			2004	2034						469	480				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAC35	WOS:000221523800038		
S	Ma, HF; Doermann, D		Smith, EHB; Hu, J; Allan, J		Ma, HF; Doermann, D			Word level script identification for scanned document images	DOCUMENT REGOGNITION AND RETRIEVAL XI	Proceedings of SPIE		English	Proceedings Paper	Conference on Document Recognition and Retrieval XI	JAN 21-22, 2004	San Jose, CA	Soc Imaging Sci & Technol, SPIE		script identification; support vector machines (SVM); Gaussian mixture model (GMM); k-nearest; neighbor (k-NN); gabor filter	CLASSIFICATION; RECOGNITION; NETWORKS	In this paper, we compare the performance of three classifiers used to identify the script of words in scanned document images. In both training and testing, a Gabor filter is applied and 16 channels of features are extracted. Three classifiers (Support Vector Machines (SVM), Gaussian Mixture Model (GMM) and k-Nearest-Neighbor (k-NN)) are used to identify different scripts at the word level (glyphs separated by white space). These three classifiers are applied to a variety of bilingual dictionaries and their performance is compared. Experimental results show the capability of Gabor filter to capture script features and the effectiveness of these three classifiers for script identification at the word level.	Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA	Ma, HF (reprint author), Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA.	hfma@umiacs.umd.edu; doermann@umiacs.umd.edu					BLANZ V, 1996, ICANN, P251; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DOERMANN D, 2002, SPIE C DOC REC RETR, P37; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Ittner D.J., 1993, ICDAR 93, P336; Joachims T., 1999, ADV KERNEL METHODS S, P41; MA H, 2003, SPIE C DOC REC RETR, P179; Ma HF, 2003, SEVENTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS, P968; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; SCHMIDT M, 1996, INTERFACE 96 P SYDN; SIBUN P, 1994, P 4 C APPL NAT LANG, P115; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; Waked B, 1998, IEEE SYS MAN CYBERN, P4470; Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192	19	0	0	0	7	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5199-1	PROC SPIE			2004	5296						124	135				12	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BY62S	WOS:000189424500016		
B	Yang, Y; Zheng, CX; Lin, P		Wei, D; Wang, H; Peng, ZY; Kara, A		Yang, Y; Zheng, CX; Lin, P			Image thresholding based on spatially weighted fuzzy C-means clustering	FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS			English	Proceedings Paper	4th International Conference on Computer and Information Technology	SEP 14-16, 2004	Wuhan, PEOPLES R CHINA	Wuhan Univ, Univ Aizu, Natl Nat Sci Fdn China, IEEE Engn Med & Biol Soc			ENTROPY; HISTOGRAM; PARTITION	In this paper, a novel spatially weighted fuzzy c-means (SWFCM) clustering algorithm for image thresholding is presented. The algorithm is formulated by incorporating the spatial neighborhood information into the standard FCM clustering algorithm. Two improved implementations of the k-nearest neighbor (k-NN) algorithm are developed for calculating the weight in the SWFCM algorithm so as to improve the performance of image thresholding. To speed up the FCM algorithm, the iteration is carried out with the statistical gray level histogram of image instead of the conventional whole data of image. Some comparisons with classical thresholding algorithm and fuzzy thresholding algorithm are also given in this paper. Experimental results on both synthetic and real images are given to demonstrate the effectiveness of the proposed algorithm. In addition, due to the neighborhood model, the proposed method is more tolerant to noise.	Xian Jiaotong Univ, Educ Minist, Key Lab Biomed Informat Engn, Inst Biomed Engn, Xian 710049, Peoples R China	Yang, Y (reprint author), Xian Jiaotong Univ, Educ Minist, Key Lab Biomed Informat Engn, Inst Biomed Engn, Xian 710049, Peoples R China.						ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; Bezdek J. C., 1981, PATTERN RECOGNITION; Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELSTEIN WA, 1984, MED PHYS, V11, P180, DOI 10.1118/1.595484; Fu S.K., 1981, PATTERN RECOGN, V13, P3; Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6; JULIUS TT, 1974, PATTERN RECOGNITION; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; Otsu N., 1978, IEEE T SYST MAN CYB, V8, P62; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743	14	1	2	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2216-5				2004							184	189				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BBB01	WOS:000224461900029		
S	Zhou, Y; Goldman, S		Khoshgoftaar, TM		Zhou, Y; Goldman, S			Democratic co-learning	ICTAI 2004: 16TH IEEE INTERNATIONALCONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	16th IEEE International Conference on Tools with Artificial Intelligence	NOV 15-17, 2004	Boca Raton, FL	IEEE Comp Soc, Informat Technol Res Inst, Wright State Univ, Florida Atlantic Univ			CLASSIFICATION; ALGORITHM; EM	For many machine learning applications it is important to develop algorithms that use both labeled and unlabeled data. We present democratic co-learning in which multiple algorithms instead of multiple views enable learners to label data for each other Our technique leverages off the fact that different learning algorithms have different inductive biases and that better predictions can be made by the voted majority. We also present democratic priority sampling, a new example selection method for active learning.	Univ S Alabama, Sch Comp & Informat Sci, Mobile, AL 36688 USA	Zhou, Y (reprint author), Univ S Alabama, Sch Comp & Informat Sci, Mobile, AL 36688 USA.						Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagan I., 1995, P 12 INT C MACH LEAR, P150; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Goldman S, 2000, P 17 INT C MACH LEAR, P327; Lewis D., 1994, P 17 ANN INT ACM SIG, P3; MUSLEA I, 2001, IJCAI 01 WORKSH TEXT; Muslea I., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Nigam K., 2000, 9 INT C INF KNOWL MA, P86; PHILIP KC, 1998, J INTELLIGENT INTEGR, V8, P5; PHILIP KC, 1996, P 9 FLOR AL RES S, P151; Quinlan R., 1986, MACH LEARN, V1, P81; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; ZHOU ZH, 2004, P 15 EUR C MACH LEAR	19	39	42	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		0-7695-2236-X	PROC INT C TOOLS ART			2004							594	602				9	Computer Science, Artificial Intelligence	Computer Science	BBI06	WOS:000225597000078		
S	Xie, ZP; Hsu, W; Lee, ML		Khoshgoftaar, TM		Xie, ZP; Hsu, W; Lee, ML			Mode committee: A novel ensemble method by clustering and local learning	ICTAI 2004: 16TH IEEE INTERNATIONALCONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	16th IEEE International Conference on Tools with Artificial Intelligence	NOV 15-17, 2004	Boca Raton, FL	IEEE Comp Soc, Informat Technol Res Inst, Wright State Univ, Florida Atlantic Univ			CLASSIFICATION	Ensemble methods have proved effective to achieve higher accuracy. Some simple ensemble methods, such as Bagging, work well with unstable base algorithms, but fail with stable ones. The reason is that such methods achieve higher accuracy by reducing only the variance of the base algorithms. It does not touch the bias. Here, we propose a novel ensemble method, Mode Committee, intended to work for both stable and unstable base algorithms. It first derive a new algorithm, called mode competitor, from given base algorithm, with the help of k-modes clustering method and the local learning strategy. Randomness is injected into each mode competitor by the process of random seeding. The aim of deriving mode competitor is to reduce the bias with the possible increasing variance. Then, multiple mode competitors form a committee and vote on the decision of new example, with the aim to reduce the variance of mode competitors. Such an arithmetic framework has been materialized by two base algorithms, the unstable C4.5 and the stable naive Bayes. Extensive empirical results demonstrate this method's superiority, and further analysis by bias-variance decomposition reveals that it is due to the low-bias of mode competitors.	Fudan Univ, Dept CIT, Shanghai 200433, Peoples R China	Xie, ZP (reprint author), Fudan Univ, Dept CIT, Shanghai 200433, Peoples R China.						Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake C, 1998, UCI REPOSITORY MACHI; Breiman L., 1996, 460 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; KOHAVI R, 1996, P 13 INT C MACH LEAR, P313; Maclin R., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Xie ZP, 2003, PROC INT C TOOLS ART, P522; Zheng Z., 1998, P 10 EUR C MACH LEAR, P196; Zhou ZH, 2002, KNOWL-BASED SYST, V15, P515, DOI 10.1016/S0950-7051(02)00038-2	16	0	1	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		0-7695-2236-X	PROC INT C TOOLS ART			2004							628	633				6	Computer Science, Artificial Intelligence	Computer Science	BBI06	WOS:000225597000082		
S	Bao, YG; Ishii, N; Du, XY		Yang, ZR; Everson, R; Yin, H		Bao, YG; Ishii, N; Du, XY			Combining multiple k-nearest neighbor classifiers using different distance functions	INTELLIGENT DAA ENGINEERING AND AUTOMATED LEARNING IDEAL 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2004)	AUG 25-27, 2004	Execter, ENGLAND	Execter Univ, Comp Sci Dept, IEEE Neural Networks Soc, Springer Verlag				The k-nearest neighbor (KNN) classification is a simple and effective classification approach. However, improving performance of the classifier is still attractive. Combining multiple classifiers is an effective technique for improving accuracy. There are many general combining algorithms, such as Bagging, Boosting, or Error Correcting Output Coding that significantly improve the classifier such as decision trees, rule learners, or neural networks. Unfortunately, these combining methods do not improve the nearest neighbor classifiers. In this paper we present a new approach to combine multiple KNN classifiers based on different distance funtions, in which we apply multiple distance functions to improve the performance of the k-nearest neighbor classifier. The proposed algorithm seeks to increase generalization accuracy when compared to the basic k-nearest neighbor algorithm. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository. The results show that the proposed algorithm improves the performance of the k-nearest neighbor classification.	Aichi Informat Syst, Aichi, Japan; Aichi Inst Technol, Aichi, Japan; Renmin Univ China, Beijing, Peoples R China	Bao, YG (reprint author), Aichi Informat Syst, Aichi, Japan.	baoyg@yahoo.com.cn; ishii@aitech.ac.ip; Duyong@mail.ruc.edu.cn					BAO Y, 2002, P 5 INT C DISC SCI, P361; BAO Y, 2002, P 3 INT C INT DAT EN, P461; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ITQON S, 2000, J IECI, V2, P23; Merz C, 1998, UCI REPOSITORY MACHI; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tapia R.A., 1978, NONPARAMETRIC PROBAB; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	11	8	8	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22881-0	LECT NOTES COMPUT SC			2004	3177						634	641				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAV07	WOS:000223701300093		
S	Everson, RM; Fieldsend, JE		Yang, ZR; Everson, R; Yin, H		Everson, RM; Fieldsend, JE			A variable metric probabilistic k-nearest-neighbours classifier	INTELLIGENT DAA ENGINEERING AND AUTOMATED LEARNING IDEAL 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2004)	AUG 25-27, 2004	Execter, ENGLAND	Execter Univ, Comp Sci Dept, IEEE Neural Networks Soc, Springer Verlag				k-nearest neighbour (k-nn) model is a simple, popular classifier. Probabilistic k-nn is a more powerful variant in which the model is cast in a Bayesian framework using (reversible jump) Markov chain Monte Carlo methods to average out the uncertainy over the model parameters. The k-nn classifier depends crucially on the metric used to determine distances between data points. However, scalings between features, and indeed whether some subset of features is redundant, are seldom known a priori. Here we introduce a variable metric extension to the probabilistic k-nn classifier, which permits averaging over all rotations and scalings of the data. In addition, the method permits automatic rejection of irrelevant features. Examples are provided on synthetic data, illustrating how the method can deform feature space and select salient features, and also on real-world data.	Univ Exeter, Dept Comp Sci, Exeter, Devon, England	Everson, RM (reprint author), Univ Exeter, Dept Comp Sci, Exeter, Devon, England.						Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Denison DGT, 2002, BAYESIAN METHODS NON; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; Green P, 1995, BIOMETRIKA, V82; HOLMES CC, 2002, J ROYAL STAT SOC B, V64, P1; Larget B, 1999, MOL BIOL EVOL, V16, P750; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Sykacek P, 2000, ADV NEUR IN, V12, P638	9	4	4	0	25	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22881-0	LECT NOTES COMPUT SC			2004	3177						654	659				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAV07	WOS:000223701300096		
B	Figueira, LB; Nicoletti, MD		Srimani, PK		Figueira, LB; Nicoletti, MD			Choosing the initial set of exemplars when learning with an NGE-based system	ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS			English	Proceedings Paper	International Conference on Information Technology - Coding and Computing	APR 05-07, 2004	Las Vegas, NV	IEEE Comp Soc				In the original proposal of the NGE (Nested Generalized Exemplar) system, the induction of a concept is based on an initial set of training examples (named seeds) that are randomly chosen. The number of examples in this set is arbitrary, generally determined by the user of the system. It can be seen empirically, that the final results are influenced by the initial choice of the seeds. The work described in this paper proposes and investigates other alternative methods for choosing seeds and empirically evaluates their impact on the learning results in seven knowledge domains, as far as accuracy and number of expressions describing the concepts are concerned. In spite of the additional time investment associated with using a clustering method and, assuming that accuracy of the induced concept is of major importance, experiments have shown that choosing the initial set of seeds as the center of clusters can be the best option.	UFSCar, Dept Comp Sci, Sao Carlos, SP, Brazil	Figueira, LB (reprint author), UFSCar, Dept Comp Sci, Sao Carlos, SP, Brazil.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BLAKE EKC, 1998, UCI REPOSITORY; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; NETO LGP, 2003, ICMLA 03, P193; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779	6	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2108-8				2004							193	197		10.1109/ITCC.2004.1286630		5	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAA56	WOS:000221353100044		
J	Muhlenbach, F; Lallich, S; Zighed, DA				Muhlenbach, F; Lallich, S; Zighed, DA			Identifying and handling mislabelled instances	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article; Proceedings Paper	13th International Symposium on Methodologies for Intelligent Systems (ISMIS 2002)	JUN 27-29, 2002	LYON, FRANCE	Univ Claude Bernard Lyon 1, Univ Lumiere Lyon 2, Inst Natl Sci Appl Lyon		supervised learning; mislabelled data; geometrical neighbourhood; filtering; removing instances; relabelling instances	LEARNING ALGORITHMS; CLASSIFICATION; OUTLIERS	Data mining and knowledge discovery aim at producing useful and reliable models from the data. Unfortunately some databases contain noisy data which perturb the generalization of the models. An important source of noise consists of mislabelled training instances. We offer a new approach which deals with improving classification accuracies by using a preliminary filtering procedure. An example is suspect when in its neighbourhood defined by a geometrical graph the proportion of examples of the same class is not significantly greater than in the database itself. Such suspect examples in the training data can be removed or relabelled. The filtered training set is then provided as input to learning algorithms. Our experiments on ten benchmarks of UCI Machine Learning Repository using 1-NN as the final algorithm show that removal gives better results than relabelling. Removing allows maintaining the generalization error rate when we introduce from 0 to 20% of noise on the class, especially when classes are well separable. The filtering method proposed is finally compared to the relaxation relabelling schema.	Univ Lyon 2, ERIC Lab, F-69676 Bron, France	Muhlenbach, F (reprint author), Univ Lyon 2, ERIC Lab, Batiment L,5 Ave Pierre Mendes France, F-69676 Bron, France.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Barnett V., 1984, OUTLIERS STAT DATA; BECKMAN RJ, 1983, TECHNOMETRICS, V25, P119, DOI 10.2307/1268541; Blake C, 1998, UCI REPOSITORY MACHI; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Cliff A. D., 1981, SPATIAL PROCESSES MO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ELFVING T, 1982, COMPUT VISION GRAPH, V20, P158, DOI 10.1016/0146-664X(82)90042-9; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267; Jain A. K., 1988, ALGORITHMS CLUSTERIN; John G. H., 1995, P 1 INT C KNOWL DISC, P174; KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; LALLICH S, 2003, RSTI RIA ECA, V17, P399; Lallich S, 2002, LECT NOTES ARTIF INT, V2366, P5; LARGERON C, 1991, THESIS U LYON 1; MILLIGAN GW, 1988, J CLASSIF, V5, P181, DOI 10.1007/BF01897163; Mood AM, 1940, ANN MATH STAT, V11, P367, DOI 10.1214/aoms/1177731825; MORAN PAP, 1948, J ROY STAT SOC B MET, P246; MUHLENBACH F, 2002, ECA, V1, P155; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; Wald A, 1940, ANN MATH STAT, V11, P147, DOI 10.1214/aoms/1177731909; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZIGHED DA, 2001, ACT 8 C SOC FRANC CL, P356; Zighed D. A., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); ZIGHED DA, 1990, TRAITEMENT SIGNAL, V2, P213; ZIGHED DA, 1999, APPRENTISSAGE AUTOMA, P85	32	36	40	0	5	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902			J INTELL INF SYST	J. Intell. Inf. Syst.	JAN	2004	22	1					89	109		10.1023/A:1025832930864		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	725ZC	WOS:000185571500006		
S	Mitani, Y; Fujita, Y; Matsunaga, N; Hamarnoto, Y		Negoita, MG; Howlett, RJ; Jain, LC		Mitani, Y; Fujita, Y; Matsunaga, N; Hamarnoto, Y			A study on nonparametric classifiers for a CAD system of diffuse lung opacities in thin-section computed tomography images	KNOWLEDGE-BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Knowledge-Based Intelligent Information and Engineering Systems	SEP, 2004	Wellington, NEW ZEALAND	Royal Soc New Zealand, IPENZ, New Zealand Trade & Enterprise, Telecom, Allied Telesyn, Positively Wellington Business	Wellington Inst Technol			The classification of diffuse lung opacities in thin-section computed tomography (HRCT) images is an important step for developing a computer-aided diagnosis(CAD) system. In practical situations such that the ratio of the dimensionality to the training sample size per a class is small, the design of a CAD system for classifying diffuse lung opacities is considered to be one of difficult tasks. In this paper, we examine the classification performance of nonparametric classifiers for a CAD system of diffuse lung opacities in practical situations.	Ube Natl Coll Technol, Ube, Yamaguchi 7558555, Japan; Yamaguchi Univ, Fac Engn, Ube, Yamaguchi 7558611, Japan; Yamaguchi Univ, Sch Med, Ube, Yamaguchi 7558505, Japan	Mitani, Y (reprint author), Ube Natl Coll Technol, Ube, Yamaguchi 7558555, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; Fukunaga K., 1990, INTRO STAT PATTERN R; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; MITANI Y, 2002, KNOWLEDGE BASED IN 1, V82, P121; MITANI Y, 2000, P 4 INT C KNOWL BAS, V2, P780; MITANI Y, 2003, IEEE EMBS AS PAC C B; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1	11	0	0	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23318-0	LECT NOTES COMPUT SC			2004	3213						608	613				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BBB75	WOS:000224585300084		
B	Figueira, LB; Lisboa, FOSS; Nicoletti, MD		Dick, S; Kurgan, L; Musilek, P; Pedrycz, W		Figueira, LB; Lisboa, FOSS; Nicoletti, MD			Learning fuzzy hyper-rectangles with instance and neural based methods	NAFIPS 2004: ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, VOLS 1AND 2: FUZZY SETS IN THE HEART OF THE CANADIAN ROCKIES			English	Proceedings Paper	Annual Meeting of the North-American-Fuzzy-Information-Processing-Society	JUN 27-30, 2004	Banff, CANADA	Amer Fuzzy Informat Proc Soc				The NGE model is an instance-based inductive learning method that generalizes a given training set into hypotheses represented as a set of hyper-rectangles in a n-dimensional Euclidean space. The RuleNet model does exactly the same thing, but using a neural network algorithm. This paper focuses on a fuzzy version of both algorithms aiming at comparing their performances.	UFSCar, Dept Comp Sci, BR-13565905 Sao Carlos, SP, Brazil	Figueira, LB (reprint author), UFSCar, Dept Comp Sci, BR-13565905 Sao Carlos, SP, Brazil.		Lisboa, Flavia/I-6767-2012				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Klir G. J., 1995, FUZZY SETS FUZZY LOG; Merz C, 1998, UCI REPOSITORY MACHI; Nauck D, 1997, FDN NEURO FUZZY SYST; Nicoletti MD, 1998, LECT NOTES ARTIF INT, V1532, P427; Sadegh-Zadeh K, 1999, ARTIF INTELL MED, V15, P309, DOI 10.1016/S0933-3657(98)00060-8; SALISBOA FOS, 2003, 12 IEEE INT C FUZZ S, V1, P90; SALZBERG S, 1991, MACH LEARN, V6, P252; SALZBERG SL, 1989, THESIS HARVARD U CAM; TSCHICHOLDGURMA, 1995, THESIS ETH ZURICH; TschicholdGurman N, 1997, FUZZY SET SYST, V85, P287, DOI 10.1016/0165-0114(95)00351-7	11	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8376-1				2004							462	467				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAR86	WOS:000223305100088		
B	Kobayashi, T; Nakagawa, M			IEEE Comp Soc	Kobayashi, T; Nakagawa, M			Pattern recognition by distributed coding: Test and analysis of the power space similarity method	NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS			English	Proceedings Paper	9th International Workshop on Frontiers in Handwriting Recognition (IWFHR-9 2004)	OCT 26-29, 2004	Tokyo, JAPAN	Hitachi, IBM, Fujitsu Lab, NEC, Toshiba, Microsoft, Int Assoc Pattern Recognit				This paper considers pattern recognition methods using distributed coding. These methods permit rapid learning from a large number of training samples; their recognition speed is high regardless of the size of the learning samples. This paper presents both basic algorithm and extended algorithms. Experiments with a large database of off-line handwritten numeric patterns are then described using the power space similarity method, being a type of distributed coding. Finally the effectiveness of the technique is considered.	Tokyo Univ Agr & Technol, Grad Sch Technol, Tokyo 1848588, Japan	Kobayashi, T (reprint author), Tokyo Univ Agr & Technol, Grad Sch Technol, 2-24-16 Nakacho, Tokyo 1848588, Japan.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Kanerva P., 1988, SPARSE DISTRIBUTED M; KOBAYASHI T, 1997, Patent No. 5689584; MURATA N, 2002, PRMU200297 IEICE, P37; SHIBATA T, 2003, TECHNICAL REPORT IEI, V103, P85	7	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2187-8				2004							389	394		10.1109/IWFHR.2004.83		6	Computer Science, Artificial Intelligence	Computer Science	BBG81	WOS:000225462900065		
S	Roumani, AM; Skillicorn, DB		Meersman, R; Tari, Z; Corsaro, A; Herrero, P; Perez, MS; Radenkovic, M; Robles, V; Santoro, C; Albani, A; Turowski, K; Jarrar, M; Gangemi, A; Duval, E; Spyns, P; Palinginis, A		Roumani, AM; Skillicorn, DB			Large-scale resource selection in grids	ON THE MOVE TO MEANINGFUL INTERNET SYSTEMS 2004: OTM 2004 WORKSHOPS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	On the Move Confederated International Workshop and Conference	OCT 25-29, 2004	Agia Napa, CYPRUS	RMIT Univ, Sch Comp Sci & Informat Technol, Vrije Univ Brussel, Dept Comp Sci		computational grid; distributed resource allocation; nearest neighbor search; multidimensional search; high dimensional data space; Singular Value Decomposition	ALGORITHM	Grid resource selection requires matching job requirements to available resources. This is a difficult problem when the number of attributes for each resource is large. We present an algorithm that uses the Singular Value Decomposition to encode each resource's proper-ties by a single value. Jobs are matched by using the same encoding to produce a value that can be rapidly compared to those of the resources. We show that reasonable matches can be found in time O(m log n) where n is the number of resources and in the number of attributes for which a job might have requirements. This is in contrast to "approximate nearest neighbor" techniques which require either time or storage exponential in in.	Queens Univ, Sch Comp, Kingston, ON, Canada	Roumani, AM (reprint author), Queens Univ, Sch Comp, Kingston, ON, Canada.	roumani@cs.queensu.ca; skill@cs.queensu.ca					Agarwal P. K., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/129712.129763; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Arya S., 1995, Proceedings of the Eleventh Annual Symposium on Computational Geometry, DOI 10.1145/220279.220315; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Berry MW, 1996, NUMER LINEAR ALGEBR, V3, P301; CLARKSON KL, 1988, SIAM J COMPUT, V17, P830, DOI 10.1137/0217052; Clarkson K. L., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, DOI 10.1145/177424.177609; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; Cover T., 1967, IEEE T INFORM THEORY, V13, P57; de Berg Mark, 1997, COMPUTATIONAL GEOMET; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Fayyad U., 1996, ADV KNOWLEDGE DISCOV; Flickner M., 1995, IEEE COMPUT, P23; FOSTER I, 1999, INT WORKSH QUALITY S; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Gersho A., 1991, VECTOR QUANTIZATION; GLOBUS, 2003, US MULT I RES EFF SE; Golub G. H., 1993, MATRIX COMPUTATIONS; KLEINBERG JM, 1997, P 29 ACM S THEOR COM; MATOUSEK J, 1991, P 32 IEEE S FDN COMP; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Yao A.C., 1985, P 17 ANN ACM S THEOR, P163, DOI 10.1145/22145.22163	25	0	0	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23664-3	LECT NOTES COMPUT SC			2004	3292						154	164				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BBD43	WOS:000225021000033		
S	Okazaki, N; Matsuo, Y; Ishizuka, M		Zhang, C; Guesgen, HW; Yeap, WK		Okazaki, N; Matsuo, Y; Ishizuka, M			Coherent arrangement of sentences extracted from multiple newspaper articles	PRICAI 2004: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2004)	AUG 09-13, 2004	Auckland, NEW ZEALAND	Univ Auckland, Inst Informat Technol Res, USAF Off Sci Res, Asian Off Aerosp Res & Dev, Auckland Univ Technol, Franz Inc				Multi-document summarization is a challenge to information overload problem to provide a condensed text for a number of documents. Most multi-document summarization systems make use of extraction techniques (e.g., important sentence extraction) and compile a summary from the selected information. However, sentences gathered from multiple sources are not organized as a comprehensible text. Therefore, it is important to consider sentence ordering of extracted sentences in order to reconstruct discourse structure in a summary. We propose a novel method to plan a coherent arrangement of sentences extracted from multiple newspaper articles. Results of our experiment show that sentence reordering has a discernible effect on summary readability. The results also shows significant improvement on sentence arrangement compared to former methods.	Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, Tokyo 1138656, Japan; AIST Tokyo Waterfront, Cyber Assist Res Ctr, Koto Ku, Tokyo 1350064, Japan	Okazaki, N (reprint author), Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.	okazaki@miv.t.u-tokyo.ac.jp					Barzilay R, 2002, J ARTIF INTELL RES, V17, P35; Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.291025; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HIRAO T, 2004, IN PRESS 4 NTCIR WOR; Hobbs J.R., 1990, CSLI LECT NOTES, V21; Hume D, 1748, PHILOS ESSAYS HUMAN; Lapata Mirella, 2003, P 41 M ASS COMP LING, P545; MANI I, 2003, P HLT NAACL03; Mani I., 2000, P 38 ANN M ASS COMP, P69, DOI 10.3115/1075218.1075228; Mann W, 1988, TEXT, V8, P243, DOI 10.1515/text.1.1988.8.3.243; OKAZAKI N, 2004, IN PRESS 4 NTCIR WOR	11	4	4	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22817-9	LECT NOTES ARTIF INT			2004	3157						882	891				10	Computer Science, Artificial Intelligence	Computer Science	BAU59	WOS:000223633300093		
S	Vijay, PA; Murty, MN; Subramanian, DK		Kittler, J; Petrou, M; Nixon, M		Vijay, PA; Murty, MN; Subramanian, DK			An efficient technique for protein sequence clustering and classification	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 2	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc			In this paper, a technique to reduce time and space during protein se quene clustering and classification is presente d. During training and testing phase, the similarity score value between a pair of sequences is determined by sele cting a portion of the sequence inste ad of the entire sequence. It is like sele cting a subset of featur es for sequence data sets. The experimental results of the proposed method shows that the classification accuracy (CA) using the prototyp es generate d/used do not degrade much but the tr aining and testing time are reduc ed significantly. Thus the experimental results indicate that the similarity score need not b e calculated by considering the entire length of the sequence for achieving a good CA. Even sp ace requir ement is reduc ed during execution phase. We have tested this using K-medians, Supervised K-medians and Nearest Neighbour Classifier (NNC) techniques.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Vijay, PA (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HENIKOFF S, 1994, GENOMICS, V19, P97, DOI 10.1006/geno.1994.1018; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JASON TL, 1994, NUCLEIC ACIDS RES, V6, P559; KRIVENTSEVA EV, 2001, NUCLEIC ACIDS RES, P29; MARTINEZ HCD, 2003, PATTERN RECOGN, V3, P173; Mount D. W., 2002, BIOINFORMATICS SEQUE; PETER C, 2000, COMPUTATIONAL MOL BI; SHARAN R, 2000, P 8 ISMB; Somervuo P., 2000, P 3 INT C DISC SCI, P76; VIJAYA PA, 2003, P IEEE TENCON AS PAC, P409; VIJAYA PA, 2003, P 5 ICAPR, P129; XIAOQUIN H, 1991, ADV APPL MATH, V12, P337; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; YONA G, 2000, NUCLEIC ACIDS RES, P28	15	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2128-2	INT C PATT RECOG			2004							447	450		10.1109/ICPR.2004.1334254		4	Computer Science, Artificial Intelligence	Computer Science	BAW22	WOS:000223877400109		
S	Paredes, R; Vidal, E		Kittler, J; Petrou, M; Nixon, M		Paredes, R; Vidal, E			Learning prototypes and distances (LPD). A prototype reduction technique based on nearest neighbor error minimization	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 3	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc	nearest neighbor condensing; weighted dissimilarity distances	FACE DETECTION; CLASSIFICATION; RECOGNITION	A prototype reduction algorithm is proposed which simultaneous train both a reduced set of prototypes and a suitable local metric for these prototypes. Starting with an initial selection of a small number of prototypes, it iteratively adjusts both the position (features) of these prototypes and the corresponding local-metric weights. The resulting prototypes/metric combination minimizes a suitable estimation of the classification error probability. Good performance of this algorithm is assessed through experiments with a number of benchmark data sets and through a real two-class classification task which consists of detecting human faces in unrestricted-background pictures.	Univ Politecn Valencia, Dept Sistemas Informat & Computac, Valencia, Spain	Paredes, R (reprint author), Univ Politecn Valencia, Dept Sistemas Informat & Computac, Valencia, Spain.						Blake CL, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PAREDES R, 2003, THESIS DSIC UPV; PAREDES R, 2000, 15 INT C PATT REC 15; Peng J, 2002, P IEEE INT C PATT RE; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Titsias MK, 2003, IEEE T PATTERN ANAL, V25, P924, DOI 10.1109/TPAMI.2003.1206521	13	2	2	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2128-2	INT C PATT RECOG			2004							442	445		10.1109/ICPR.2004.1334561		4	Computer Science, Artificial Intelligence	Computer Science	BAW25	WOS:000223879500108		
S	Kato, T; Wada, T		Kittler, J; Petrou, M; Nixon, M		Kato, T; Wada, T			Direct condensing: An efficient Voronoi condensing algorithm for nearest neighbor classifiers	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 3	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc			Voronoi condensing reduces training patterns of nearest neighbor classifiers without changing the classification boundaries. This method plays important roles not only in the nearest neighbor classifiers but also in the other classifiers such as the support vector machines, because the resulting prototype patterns involve support vectors in many cases. However, previous algorithms for Voronoi condensing were computationally inefficient in general Pattern Recognition tasks. This is because they use proximity graphs for entire training patters, which require computational time exponentially for the dimension of pattern space. For solving this problem, we proposed an efficient algorithm for Voronoi condensing named direct condensing that does not require the entire proximity graphs of training patterns. We confirmed that direct condensing efficiently calculates Voronoi condensed prototypes in high dimension (from 2 to 20 dimensions).	Wakayama Univ, Dept Comp & Commun Sci, Wakayama 6408510, Japan	Kato, T (reprint author), Wakayama Univ, Dept Comp & Commun Sci, 930 Sakaedani, Wakayama 6408510, Japan.						AHA DW, 1991, CASE BASED REASONING, P147; BARDFORD C, 1996, ACM T MATH SOFTWARE, V22, P469; BHATTACHARYA, 1981, INT S INF THEOR SANT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Shibata T, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P641; Vapnik V., 1998, STAT LEARNING THEORY	9	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2128-2	INT C PATT RECOG			2004							474	477		10.1109/ICPR.2004.1334569		4	Computer Science, Artificial Intelligence	Computer Science	BAW25	WOS:000223879500116		
S	Viswanath, P; Murty, MN; Bhatnagar, S		Kittler, J; Petrou, M; Nixon, M		Viswanath, P; Murty, MN; Bhatnagar, S			A pattern synthesis technique with an efficient nearest neighbor classifier for binary pattern recognition	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc			Important factors affecting the efficiency and performance of the nearest neighbor classifier (NNC) are space, classification time requirements and for high dimensional data, due to the curse of dimensionality, the training set size should be large. In this paper we propose novel techniques to improve the performance of NNC and at the same time to reduce its computational burden. A compact representation of the training set along with an efficient NNC which does implicit pattern synthesis is presented. A comparison of empirical results is made with relevant methods.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Viswanath, P (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Efron B., 1979, ANN STAT, V1, P1, DOI 10.1214/aos/1176344552; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814	4	2	2	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2128-2	INT C PATT RECOG			2004							416	419				4	Computer Science, Artificial Intelligence	Computer Science	BAW23	WOS:000223878400101		
S	Franco, A; Maltoni, D; Nanni, L		Kittler, J; Petrou, M; Nixon, M		Franco, A; Maltoni, D; Nanni, L			Reward-punishment editing	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc		NEAREST NEIGHBOR RULES	In this work a novel editing technique is proposed. The basic idea of the algorithm is to reward patterns that contribute to a correct classification and to punish those that provide a wrong one. Reward-punishment is performed according to two criteria: the former operates at very local level while the latter analyses the training set at coarser scales in a multi-resolution fashion. A score is calculated for each pattern according to the two criteria and patterns whose score is lower than a predefined threshold are edited out. Experiments carried out on two difficult classification problems show the superiority of this method with respect to other well known approaches.	Univ Bologna, DEIS, IEIIT, CNR, I-40136 Bologna, Italy	Franco, A (reprint author), Univ Bologna, DEIS, IEIIT, CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.						BARANDELA R, 2000, JOINT IAPR INT WORKS, P621; Bezdek J. C., 1981, PATTERN RECOGNITION; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; PARADES R, 2000, P INT C PATT REC ICP, V2, P25; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; Watson C., 1992, NIST SPECIAL DATABAS; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	10	1	1	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2128-2	INT C PATT RECOG			2004							424	427		10.1109/ICPR.2004.1333793		4	Computer Science, Artificial Intelligence	Computer Science	BAW23	WOS:000223878400103		
S	Liu, W; Wang, YH; Li, SZ; Tan, TN		Kittler, J; Petrou, M; Nixon, M		Liu, W; Wang, YH; Li, SZ; Tan, TN			Nearest intra-class space classifier for face recognition	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc			In this paper we propose a novel classification method, called nearest intra-class space (NICS), for face recognition. In our method, the distribution of face patterns of each person is represented by the intra-class space to capture all intra-class variations. Then, a regular principal subspace is derived from each intra-class space using principal component analysis. The classification is based on the nearest weighted distance, combining distance-from-subspace and distance-in-subspace, between the query face and each intra-class subspace. Experimental results show that the NICS classifier outperforms other classifiers in terms of recognition performance.	Chinese Acad Sci, Inst Automat, NLPR, Beijing, Peoples R China	Liu, W (reprint author), Chinese Acad Sci, Inst Automat, NLPR, POB 2728, Beijing, Peoples R China.						Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; MOGHADDAM B, 1998, ADV NEURAL INFORMATI, V11, P910; Oja E., 1983, SUBSPACE METHODS PAT; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG XG, 2000, P INT C COMP VIS, V1, P679	7	4	4	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2128-2	INT C PATT RECOG			2004							495	498				4	Computer Science, Artificial Intelligence	Computer Science	BAW23	WOS:000223878400119		
B	Du, WW; Zhao, QF		DelPobil, AP		Du, WW; Zhao, QF			An improved R-4-rule for evolutionary learning of NN-NILP	Proceedings of the Eighth IASTED International Conference on Artificial Intelligence and Soft Computing			English	Proceedings Paper	8th IASTED International Conference on Artificial Intelligence and Soft Computing	SEP 01-03, 2004	Marbella, SPAIN	Int Assoc Sci & Technol Dev, TC Artificial Intelligence & Expert, IASTED, TC Soft Comp, World Modelling & Simulat Forum		the R-4-rule; nearest neighbor based multilayer perceptron (NN-MLP); pattern recognition; learning vector quantization; and neural networks	NEIGHBOR PATTERN-CLASSIFICATION; RULE	To design the nearest-neighbor-based multilayer perceptron (NN-MLP) efficiently, we have proposed a non-genetic evolutionary algorithm called the W-rule. Experimental results obtained so far show that the W-rule can produce the smallest or nearly smallest networks with high generalization ability by iteratively performing four basic operations: recognition, remembrance, (r) under bar eduction, and review. To use this algorithm, however, we must specify several parameters properly, and this is often not easy. In this paper, we try to improve the usability of the R-4-rule by reducing the number of parameters. The efficiency of the improved algorithm is verified through experiments with several public databases.	Univ Aizu, Aizu Wakamatsu 9658580, Japan	Du, WW (reprint author), Univ Aizu, Aizu Wakamatsu 9658580, Japan.						CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; Chang E. I., 1991, ADV NEURAL INFORMATI, V3, P797; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Mitchell Tom, MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; QUINLAN JR, 1988, IEEE COMPUT, V21, P77; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; ZHAO QF, 1994, P IEICE KAUR WORKSH, P121; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762	14	0	0	0	0	ACTA PRESS	CALGARY	B6, STE 101, 2509 DIEPPE AVE SW, CALGARY, ALBERTA T3E 7J9, CANADA			0-88986-452-7				2004							238	242				5	Computer Science, Artificial Intelligence	Computer Science	BCB30	WOS:000228486200042		
B	Poyhonen, S; Conti, M; Cavallini, A; Montanari, GC; Filippetti, F			IEEE	Poyhonen, S; Conti, M; Cavallini, A; Montanari, GC; Filippetti, F			Insulation defect localization through partial discharge measurements and numerical classification	Proceedings of the IEEE-ISIE 2004, Vols 1 and 2			English	Proceedings Paper	IEEE International Symposium on Industrial Electronics	MAY 04-07, 2004	Ajaccio, FRANCE	IEEE		partial discharges; insulation systems; defect localization; support vector machine	PATTERN-CLASSIFICATION	Partial discharge (PD) analysis is a fundamental tool to guide decision making in electrical insulation diagnosis for condition based maintenance. In this paper, PD signals are analyzed to localize defects in insulation systems. The task of automatic defect localization with respect to electrodes has a wide range of industrial applications. In fact, depending on the apparatus type., risk assessment is remarkably affected by defect location with respect to the electrodes. In this study.. various parameters are first extracted from PD distributions., and statistical analysis is performed to select the most significant parameters concerning localization. Then, the localization process is carried out through numerical classification. Three different classification methods are compared to find the best approach for this application. Comparing a k-nearest neighbor classifier, a probabilistic neural network and a support vector machine (SVM) based classifier, the best results are gained with SVM. although the former two are simpler to implement and easier to tune. SVM based classification has not been applied in PD analysis before this research.	Helsinki Univ Technol, Control Engn Lab, Helsinki, Finland	Poyhonen, S (reprint author), Helsinki Univ Technol, Control Engn Lab, Helsinki, Finland.						Cavallini A, 2003, IEEE T DIELECT EL IN, V10, P216, DOI 10.1109/TDEI.2003.1194102; CAVALLINI A, 2002, P IEEE C EL INS DIEL, P698; Contin A, 2002, IEEE T DIELECT EL IN, V9, P335, DOI 10.1109/TDEI.2002.1007695; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI, V1st; Danikas MG, 2003, ELECTR ENG, V85, P87, DOI 10.1007/s00202-002-0151-5; Filippetti F, 2000, IEEE T IND ELECTRON, V47, P994, DOI 10.1109/41.873207; *IEC, 2001, PART DISCH MEAS; Krzanowski W. J., 1988, PRINCIPLES MULTIVARI; Rahman MKA, 2000, IEE P-SCI MEAS TECH, V147, P7, DOI 10.1049/ip-smt:20000074; Salama MMA, 2000, IEEE T DIELECT EL IN, V7, P118, DOI 10.1109/94.839349; SATISH L, 1995, IEEE T DIELECT EL IN, V2, P352, DOI 10.1109/94.395421; Specht D. F., 1988, P IEEE INT C NEURAL, V1, P525; WENZEL D, 1994, P IEEE INT S EL INS, P233, DOI 10.1109/ELINSL.1994.401523	14	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-8304-4				2004							417	422				6	Automation & Control Systems; Engineering, Industrial; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BDG38	WOS:000233365800074		
B	Long, JD; Stoecklin, S; Schwartz, DG; Patel, MK		Hamza, MH		Long, JD; Stoecklin, S; Schwartz, DG; Patel, MK			Adaptive similarity metrics in case-based reasoning	Proceedings of the Sixth IASTED International Conference on Intelligent Systems and Control			English	Proceedings Paper	6th IASTED International Conference on Intelligent Systems and Control	AUG 23-25, 2004	Honolulu, HI	Int Assoc Sci & Technol Dev, Tech Comm Control, Tech Comm Intelligent Syst & Control		case-based reasoning; metadata architecture; similarity measures		A similarity measure is a critical component in any case-based reasoning (CBR) system. It compares two cases with respect to their "features," with each feature using a separate "comparator." The results of the comparators are combined according to some rule to give an overall measure of the similarity between the given cases. Previous works have described a CBR framework that can easily be instantiated to provide a case-based reasoner for virtually any problem domain. This uses an "adaptive," or "reflective'' software architecture wherein case features are associated with their comparators dynamically via run-time references to metadata. New instances of the framework are created simply by changing the metadata. No reprogramming is required. In this paper, we extend this concept to allow for dynamic selection also of feature-comparator combination rules. This makes the framework more adaptive by eliminating, the need to reprogram it for each such new rule. The overall effect is that the entire similarity measure is described by metata. The approach is illustrated via an example.	Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA	Long, JD (reprint author), Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA.						AAMODT A, 1994, AI COMMUN, V7, P39; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GAO L, P 2002 ACM INT C MAN; Han J., 2000, DATA MINING CONCEPTS; Kaufman L., 1990, FINDING GROUPS DATA; LOUIS SJ, 1999, P GEN EV COMP C ORL; SCHWARTZ DG, 2002, 5 INT C INF FUS IF 0; SISTLA AP, 1997, IEEE INT C DAT ENG A; Snort Open Source Network Intrusion Prevention and Detection System (IDS/IPS), SNORT OPEN SOURCE NE; YODER J, 2001, ACM SIGPLAN NOTICES; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	11	0	1	0	0	ACTA PRESS	CALGARY	B6, STE 101, 2509 DIEPPE AVE SW, CALGARY, ALBERTA T3E 7J9, CANADA			0-88986-436-5				2004							260	265				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Operations Research & Management Science	Automation & Control Systems; Computer Science; Operations Research & Management Science	BCC26	WOS:000228556100046		
S	Yang, Y; Zheng, CX; Lin, P		Sanfeliu, A; Trinidad, JFM; Ochoa, JAC		Yang, Y; Zheng, CX; Lin, P			Image thresholding via a modified fuzzy c-means algorithm	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	9th Iberoamerican Congress on Pattern Recognition	OCT 16-29, 2004	Puebla, MEXICO	Inst Cybernet, Math & Phys Cuba, Ctr Applicat Adv Technol Cuba, Univ La Salle, Mexico, Autonomous Univ Puebla, Int Assoc Patern Recognit, Cuban Assoc Pattern Recognit, Portuguese Assoc Pattern Recognit, Spanish Assoc Pattern Recognit & Image Anal, SIGPR SBC, Mexican Assoc Comp Vis, Neurocomp & Robit			ENTROPY; HISTOGRAM; PARTITION	In this paper, a modified fuzzy c-means (FCM) algorithm named weighted fuzzy c-means (WFCM) algorithm for image thresholding is presented. The algorithm is developed by incorporating the spatial neighborhood information into the standard FCM clustering algorithm. The weight indicates the spatial influence of the neighboring pixels on the centre pixel, which is derived from the k-nearest neighbor (k-NN) algorithm and is modified in two aspects so as to improve its property in the WFCM algorithm. To speed up the algorithm, the iteration in FCM algorithm is carried out with the statistical gray level histogram of image instead of the conventional whole data of image. The performance of the algorithm is compared with those of an existing fuzzy thresholding algorithm and widely applied between variance and entropy methods. Experimental results on both synthetic and real images are given to demonstrate the proposed algorithm is effective and efficient. In addition, due to the neighborhood model, our method is more tolerant to noise.	Xian Jiaotong Univ, Key Lab Biomed Informat Engn, Educ Minist, Inst Biomed Engn, Xian 710049, Peoples R China	Yang, Y (reprint author), Xian Jiaotong Univ, Key Lab Biomed Informat Engn, Educ Minist, Inst Biomed Engn, Xian 710049, Peoples R China.	greatyyy765@sohu.com					Bezdek J. C., 1981, PATTERN RECOGNITION; Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELSTEIN WA, 1984, MED PHYS, V11, P180, DOI 10.1118/1.595484; Fu S.K., 1981, PATTERN RECOGN, V13, P3; Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6; JULIUS TT, 1974, PATTERN RECOGNITION; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743	13	3	3	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-23527-2	LECT NOTES COMPUT SC			2004	3287						589	596				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BBE01	WOS:000225085900074		
B	Cheng, MY; Cheung, SC; Tse, TH		Ehrich, HD; Schewe, KD		Cheng, MY; Cheung, SC; Tse, TH			Towards the application of classification techniques to test and identify faults in multimedia systems	QSIC 2004: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON QUALITY SOFTWARE			English	Proceedings Paper	4th International Conference on Quality Software	SEP 08-09, 2004	Braunschweig, GERMANY	Tech Univ Braunschweig, Inst Informat Syst, Univ Hong Kong, Software Engn Grp, Swinburne Univ Technol, Ctr Software Engn		software testing; multimedia; classification; Bayesian networks; k-nearest neighbor; neural networks	SYNCHRONIZATION	The advances in computer and graphic technologies have led to the popular use of multimedia for information exchange. However multimedia systems are difficult to test. A major reason is that these systems generally exhibit fuzziness in their temporal behaviors. The fuzziness is caused by the existence of non-deterministic factors in their runtime environments, such as system load and network traffic. It complicates the analysis of test results. The problem is aggravated when a test involves the synchronization of different multimedia streams as well as variations in system loading. In this paper, we conduct an empirical study on the testing and fault-identification of multimedia systems by treating the issue as a classification problem. Typical classification techniques, including Bayesian networks, k-nearest neighbor and neural networks, are experimented with the use of X-Smiles, an open source multimedia authoring tool supporting the Synchronized Multimedia Integration Language (SMIL). The encouraging result of our study, which is based only on five attributes, shows that our proposal can achieve an accuracy of 57.6 to 79.2% in identifying the types of fault in environments where common cause variations are present. A further improvement Of 7.6% is obtained via normalization.	Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Tse, TH (reprint author), Univ Hong Kong, Dept Comp Sci, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.		Tse, T.H./C-6590-2008	Tse, T.H./0000-0002-0460-8377			ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; ARBACH L, 2003, P IEEE CAN C EL COMP, V3, P1441; Baek S, 2000, ELECTRON LETT, V36, P1821, DOI 10.1049/el:20001249; Beizer B., 1990, SOFTWARE TESTING TEC; Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691; BUJA A, IN PRESS J COMPUTATI; Chen TY, 2003, INFORM SOFTWARE TECH, V45, P1, DOI 10.1016/S0950-5849(02)00129-5; Cheung SC, 2001, P 12 INT S SOFTW REL, P210; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fix E., 1952, 11 USAF SCH AV MED; Groenen P. J. F., 1993, MAJORIZATION APPROAC; Guojun Lu, 1996, COMMUNICATION COMPUT; LEE J, 1990, IEEE T GEOSCI REMOTE, V28, P846, DOI 10.1109/36.58972; LITTLE TDC, 1990, IEEE J SEL AREA COMM, V8, P413, DOI 10.1109/49.53017; Liu J.N.K., 1999, P IEEE INT C SYST MA, V3, P429; Mitchell T. M., 1997, MACHINE LEARNING; Padberg F, 2004, IEEE T SOFTWARE ENG, V30, P17, DOI 10.1109/TSE.2004.1265733; Russell E. L., 2000, DATA DRIVEN TECHNIQU; SU JL, 2001, P 23 ANN INT C IEEE, V4, P3824; ZIV H, 1997, BAYESIAN NETWORK CON; Ziv H., 1997, Proceedings International Conference on Software Maintenance (Cat. No.97CB36119), DOI 10.1109/ICSM.1997.624236	21	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2207-6				2004							32	40				9	Computer Science, Software Engineering	Computer Science	BBA88	WOS:000224457200005		
S	Skowron, A; Wojna, A		Tsumoto, S; Slowinski, R; Komorowski, J; GrzymalaBusse, JW		Skowron, A; Wojna, A			K nearest neighbor classification with local induction of the simple value difference metric	ROUGH SETS AND CURRENT TRENDS IN COMPUTING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Routh Sets and Current Trends in Computing	JUN 01-05, 2004	Uppsala, SWEDEN		Uppsala Univ			The classical k nearest neighbor (k-nn) classification assumes that a fixed global metric is defined and searching for nearest neighbors is always based on this global metric. In the paper we present a model with local induction of a metric. Any test object induces a local metric from the neighborhood of this object and selects k nearest neighbors according to this locally induced metric. To induce both the global and the local metric we use the weighted Simple Value Difference Metric (SVDM). The experimental results show that the proposed classification model with local induction of a metric reduces classification error up to several times in comparison to the classical k-nn method.	Warsaw Univ, Fac Math Informat & Mech, PL-02097 Warsaw, Poland	Skowron, A (reprint author), Warsaw Univ, Fac Math Informat & Mech, Ul Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl; wojna@mimuw.edu.pl					Blake C, 1998, UCI REPOSITORY MACHI; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2002, P 2 SIAM INT C DAT M; Domingos P, 1996, MACH LEARN, V24, P141; Duda R. O., 1973, PATTERN CLASSIFICATI; FRIEDMAN J, 1994, 113 DEP STAT STANF U; Gora G, 2002, FUND INFORM, V51, P369; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Mitchell T. M., 1997, MACHINE LEARNING; PAWLAK Z, 1991, ROUGH SETS THEOERETI; Skowron A., 2003, ROUGH NEURAL COMPUTI, P43; Vapnik V., 1998, STAT LEARNING THEORY; Wojna A, 2003, FUND INFORM, V56, P285	14	4	4	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22117-4	LECT NOTES ARTIF INT			2004	3066						229	234				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAH82	WOS:000222323600027		
B	Hao, YL; Quirchmayr, G; Stumptner, M		Chen, J		Hao, YL; Quirchmayr, G; Stumptner, M			MOUCLAS mining on well logging data	SERVICE SYSTEMS AND SERVICE MANAGEMENT - PROCEEDINGS OF ICSSSM '04, VOLS 1 AND 2			English	Proceedings Paper	International Conference on Service Systems and Service Management	JUL 19-21, 2004	Beijing, PEOPLES R CHINA	IEEE Syst, Man & Cybernet Soc, Tsinghua Univ, Sch Econ & Management		data mining; MOUCLAS pattern; oil/gas formation identification		Oil/gas formation identification is one of the most costly and challenging tasks of the service IT community in petroleum industry, where the petroleum database contains such records (or attributes) as various types of well logging data whose values are all quantitative. This paper proposes a novel data mining algorithm for the classification over quantitative data, based on a new pattern called MOUCLAS (MOUntain function based CLASsification) Patterns. The aim of the study is to apply MOUCLAS mining on the well logging data for purpose of oil/gas formation identification. From data mining point of view, the motivation of the study is to develop an association rule based classifier, which can has any number of predicates in the antecedent and overcome the limitation caused by the discretization method, for quantitative attributes by the concepts of clustering. An illustration of using well logging data for oil/gas formation identification is presented in the paper. MOUCLAS is ideally suitable to derive the implicit relationship between measured values (well logging data) and properties to be predicted (oil/gas formation or not). As a hybrid of classification and clustering and association rules mining, our approach have several advantages which are (1) it has a solid mathematical foundation and compact mathematical description of classifiers, (2) it does not require discretization, (3) it is robust when handling noisy or incomplete data in high dimensional data space, (4) it is not sensitive to the order of input items and it scales linearly with the size of input.				Stumptner, Markus/B-5558-2009				AMINZADEH F, 1996, GCSEPFM, P1; Balan B., 1995, 30978 SPE; Chiu S., 1994, J INTELLIGENT FUZZY, V2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOUGHERTY J, 1995, P 12 INT C MACH LEAR, P94; Ellis D.V., 1987, WELL LOGGING EARTH S; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; Han J., 2000, DATA MINING CONCEPTS; Hinneburg A., 1998, KNOWLEDGE DISCOVERY, P58; Jinyan Li, 2001, KNOWL INF SYST, V3, P131, DOI DOI 10.1007/PL00011662; LENT B, 1997, ICDE, P220; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rider M., 1996, GEOLOGICAL INTERPRET; SKIKANT R, 1996, SIG MOD 96, P1; Yager R., 1994, J INTELL FUZZY SYST, V2, P209	18	0	0	0	3	INTERNATIONAL ACADEMIC PUBLISHERS LTD	HONG KONG	UNIT 1205, 12 FLOOR, SINO PLAZA, 255 GLOUCESTER ROAD, HONG KONG 00000, CAUSEWAY BAY, PEOPLES R CHINA			7-5062-6821-3				2004							475	479				5	Computer Science, Artificial Intelligence; Management; Operations Research & Management Science	Computer Science; Business & Economics; Operations Research & Management Science	BAV84	WOS:000223847800095		
S	Naude, JJ; van Wyk, MA; van Wyk, BJ		Fred, A; Caelli, T; Duin, RPW; Campilho, A; DeRidder, D		Naude, JJ; van Wyk, MA; van Wyk, BJ			Geneneralized variable-kernel similarity metric learning	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th International Workshop on Structural and Syntactic Pattern Recognition/5th International Conference on Statistical Techniques in Pattern Recognition	AUG 18-20, 2004	Lisbon, PORTUGAL	Inst Telecommun, Inst Super Tecn, Int Assoc Pattern Recognit, Fund Luso-Amer Desenvolvimento				Proximity-based classifiers such as RBF-networks and nearest-neighbour classifiers are notoriously sensitive to the metric used to determine distance between samples. In this paper a method for learning such a metric from training data is presented. This algorithm is a generalization of the so called Variable-Kernel Similarity Metric (VSM) Learning, originally proposed by Lowe and is therefore known as Generalized Variable-Kernel Similarity Metric (GVSM) learning. Experimental results show GVSM to be superior to VSM for extremely noisy or cross-correlated data.	Rand Afrikaans Univ, Johannesburg, South Africa; Kentron Dynam, Centurion, South Africa; Tshwane Univ Technol, French S African Tech Inst Elect, Pretoria, South Africa	Naude, JJ (reprint author), Rand Afrikaans Univ, Auckland Pk, Johannesburg, South Africa.	hannes.naude@kentron.co.za; mavw@fsatie.ac.za; ben.van.wyk@fsatie.ac.za					BEIS J, 1997, C COMP VIS PATT REC, P1000; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061	6	0	0	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22570-6	LECT NOTES COMPUT SC			2004	3138						788	796				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAS89	WOS:000223398900086		
S	Kudo, M; Imai, H; Tanaka, A; Murai, T		Fred, A; Caelli, T; Duin, RPW; Campilho, A; DeRidder, D		Kudo, M; Imai, H; Tanaka, A; Murai, T			A nearest neighbor method using bisectors	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th International Workshop on Structural and Syntactic Pattern Recognition/5th International Conference on Statistical Techniques in Pattern Recognition	AUG 18-20, 2004	Lisbon, PORTUGAL	Inst Telecommun, Inst Super Tecn, Int Assoc Pattern Recognit, Fund Luso-Amer Desenvolvimento			ALGORITHM; RULE	A novel algorithm for finding the nearest neighbor was proposed. According to the development of modern technology, the demand is increasing in large-scale datasets with a large number of samples and a large number of features. However, almost all sophisticated algorithms proposed so far are effective only in a small number of features, say, up to 10. This is because in a high-dimensional space many pairs of samples share a same distance. Then the naive algorithm outperforms the others. In this study, we considered to utilize a sequential information of distances obtained by the examined training samples. Indeed, a combinatorial information of examined samples was used as bisectors between possible pairs of them. With this algorithm, a query is processed in O(alphabetand) for n samples in a d-dimensional space and for alpha,beta < 1, in expense of a preprocessing time and space in O(n(2)). We examined the performance of the algorithm.	Hokkaido Univ, Grad Sch Engn, Div Syst & Informat Engn, Kita Ku, Sapporo, Hokkaido 0608628, Japan	Kudo, M (reprint author), Hokkaido Univ, Grad Sch Engn, Div Syst & Informat Engn, Kita Ku, Kita 13,Nishi 8, Sapporo, Hokkaido 0608628, Japan.	mine@main.eng.hokudai.ac.jp; imai@main.eng.hokudai.ac.jp; takira@main.eng.hokudai.ac.jp; murahiko@main.eng.hokudai.ac.jp	Kudo, Mineichi/B-9973-2011				Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; CHANG CC, 1993, PATTERN RECOGN LETT, V14, P625, DOI 10.1016/0167-8655(93)90047-H; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P268; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KLINBERG J, 1997, P 29 ACM S THEOR COM, P599; KUDO M, 2003, PATTERN RECOGN, V24, P1213; MANEEWONGVATANA S, 2001, P 7 WORKSH ALG DAT S, P276; MURPHY PM, 1991, UCI REPOSITORY MACHI	12	0	0	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-22570-6	LECT NOTES COMPUT SC			2004	3138						885	893				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAS89	WOS:000223398900097		
J	Nguyen, SH; Bazan, J; Skowron, A; Nguyen, HS				Nguyen, SH; Bazan, J; Skowron, A; Nguyen, HS			Layered learning for concept synthesis	TRANSACTIONS ON ROUGH SETS I	LECTURE NOTES IN COMPUTER SCIENCE		English	Article						concept synthesis; hierarchical schema; layered learning; rough sets	GRANULES; WORDS	We present a hierarchical scheme for synthesis of concept approximations based on given data and domain knowledge. We also propose a solution, founded on rough set theory, to the problem of constructing the approximation of higher level concepts by composing the approximation of lower level concepts. We examine the effectiveness of the layered learning approach by comparing it with the standard learning approach. Experiments are carried out on artificial data sets generated by a road traffic simulator.	Polish Japanese Inst Informat Technol, PL-02008 Warsaw, Poland; Univ Rzeszow, Inst Math, PL-35959 Rzeszow, Poland; Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland	Nguyen, SH (reprint author), Polish Japanese Inst Informat Technol, Koszykowa 86, PL-02008 Warsaw, Poland.	hoa@mimuw.edu.pl; bazan@mimuw.edu.pl; skowron@mimuw.edu.pl; son@mimuw.edu.pl	Nguyen, Hung Son /I-7452-2012				Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; BARWISE J, 1997, TRACTS THEORETICAL C, V44; Bazan J, 2003, LECT NOTES ARTIF INT, V2639, P181; Bazan J. G., 1998, ROUGH SETS KNOWLEDGE, V1, P321; Bazan J.G., 2001, LECT NOTES ARTIF INT, V2005, P106; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIREDMAN J, 2001, ELEMENTS STAT LEARNI; Grzymala-Busse J. W., 1997, Fundamenta Informaticae, V31; Kloesgen Willi, 2002, HDB KNOWLEDGE DISCOV; Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; Mitchell T. M., 1998, MACHINE LEARNING; Pal S.K., 2003, ROUGH NEURAL COMPUTI; Pawlak Z, 1991, SYSTEM THEORY KNOWLE, V9; Poggio T., 2003, NOTICES AMS, V50, P537; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; Polkowski L, 2001, COMPUT INTELL, V17, P472, DOI 10.1111/0824-7935.00159; Polkowski L., 1999, COMPUTING WORDS INFO, P201; SKOWRON A, INFORMATION GRANULES, P43; Skowron A, 1992, HDB APPL ADV ROUGH S, V11, P331; Skowron A, 2001, INT J INTELL SYST, V16, P57, DOI 10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y; Skowron A, 2001, FUND INFORM, V47, P337; Skowron A, 2003, STUD FUZZ SOFT COMP, V125, P13; Skowron A, 2002, ADV SOFT COMP, P338; Skowron Andrzej, 2001, P 2 AS PAC C INT AG, P28; Stone Peter, 2000, LAYERED LEARNING MUL; Wroblewski J., 1998, LECT NOTES ARTIF INT, V1424, P402; Zadeh LA, 2001, AI MAG, V22, P73; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904	28	54	54	0	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743			LECT NOTES COMPUT SC			2004	3100						187	208				22	Computer Science, Theory & Methods	Computer Science	BAR28	WOS:000223234300009		
J	Takagi, N; Kikuchi, H; Mukaidono, M				Takagi, N; Kikuchi, H; Mukaidono, M			Applications of fuzzy logic functions to knowledge discovery in databases	TRANSACTIONS ON ROUGH SETS II	LECTURE NOTES IN COMPUTER SCIENCE		English	Article							CLASSIFICATION	This chapter is a summary of knowledge discovery algorithms that take an input of training examples of target knowledge, and output a fuzzy logic formula that best fits the training examples. The execution is done in three steps; first, the given mapping is divided into some Q-equivalent classes; second, the distances between the mapping and each local fuzzy logic function are calculated by a simplified logic formula; and last, the shortest distance is obtained by a modified graph-theoretic algorithm. After a fundamental algorithm for fitting is provided, fuzzy logic functions are applied to a more practical example of classification problem, in which expressiveness of fuzzy logic functions is examined for a well-known machine learning database.	Toyama Prefectural Univ, Dept Elect & Informat, Toyama 9390398, Japan; Tokai Univ, Dept Informat Media Technol, Hiratsuka, Kanagawa 2591292, Japan; Meiji Univ, Dept Comp Sci, Tama Ku, Kawasaki, Kanagawa 2148571, Japan	Takagi, N (reprint author), Toyama Prefectural Univ, Dept Elect & Informat, Toyama 9390398, Japan.						Bezdek J. C., 1981, PATTERN RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fayyad U., 1996, ADV KNOWLEDGE DISCOV; Grabisch M, 1992, P 2 INT C FUZZ LOG N, P659; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; KANDEL A, 1980, IEEE T COMPUT, V29, P986; KANDEL A, 1973, IEEE T COMPUT, VC 22, P826; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIKUCHI H, 1991, P INT FUZZ ENG S, V1, P91; LEE RCT, 1971, INFORM CONTROL, V19, P417, DOI 10.1016/S0019-9958(71)90684-X; LIU CH, 1985, P IEEE 15 INT S MULT, P182; MUKAIDONO M, 1975, IECE T D, V58, P150; MUKAIDONO M, 1975, IECE T D, V58, P748; MUKAIDONO M, 1987, ANAL FUZZY INFORM, P213; Mukaidono M., 1979, Proceedings of the Ninth International Symposium on Multiple-Valued Logic; ROSS KA, 1988, DISCRETE MATH; Rumelhart D.E., 1989, PARALLEL DISTRIBUTED; UMANO M, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P2113, DOI 10.1109/FUZZY.1994.343539; WEISS SM, 1991, COMPUTER SYSTEMS LEA, P51	19	0	0	0	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743			LECT NOTES COMPUT SC			2004	3135						107	128				22	Computer Science, Theory & Methods	Computer Science	BBV25	WOS:000228008900007		
J	Tsiriga, V; Virvou, M				Tsiriga, V; Virvou, M			A framework for the initialization of student models in Web-based intelligent tutoring systems	USER MODELING AND USER-ADAPTED INTERACTION			English	Article						initialization; machine learning for user modeling; stereotypes; student modeling; Web-based intelligent tutoring systems	ADAPTIVE HYPERMEDIA; USER MODELS; CLASSIFICATION; TOOL	Initializing a student model for individualized tutoring in educational applications is a difficult task, since very little is known about a new student. On the other hand, fast and efficient initialization of the student model is necessary. Otherwise the tutoring system may lose its credibility in the first interactions with the student. In this paper we describe a framework for the initialization of student models in Web-based educational applications. The framework is called ISM. The basic idea of ISM is to set initial values for all aspects of student models using an innovative combination of stereotypes and the distance weighted k-nearest neighbor algorithm. In particular, a student is first assigned to a stereotype category concerning her/ his knowledge level of the domain being taught. Then, the model of the new student is initialized by applying the distance weighted k-nearest neighbor algorithm among the students that belong to the same stereotype category with the new student. ISM has been applied in a language learning system, which has been used as a test-bed. The quality of the student models created using ISM has been evaluated in an experiment involving classroom students and their teachers. The results from this experiment showed that the initialization of student models was improved using the ISM framework.	Univ Piraeus, Dept Informat, Piraeus 18534, Greece	Tsiriga, V (reprint author), Univ Piraeus, Dept Informat, 80 Karaoli & Dimitriou St, Piraeus 18534, Greece.	vtsir@unipi.gr; mvirvou@unipi.gr					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aimeur E, 2002, LECT NOTES COMPUT SC, V2363, P718; AIMEUR E, 2001, P INT C COMP AID LEA, P51; Albrecht F., 2000, Journal of Interactive Learning Research, V11; Alpert S. R., 1999, INT J ARTIFICIAL INT, V10, p183 ; Baffes P., 1996, Journal of Artificial Intelligence in Education, V7; Beck JE, 2000, LECT NOTES COMPUT SC, V1839, P584; BEESON MJ, 1989, P 4 INT C AI ED IOS, P9; BONTCHEVA K, 2002, LECT NOTES COMPUTER, V2347, P69; Brusilovsky P., 1998, Journal of Computing and Information Technology - CIT, V6; Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964; Burton R. R., 1982, INTELLIGENT TUTORING, P157; Chiu BC, 1998, USER MODEL USER-ADAP, V8, P131; Chin DN, 2001, USER MODEL USER-ADAP, V11, P181, DOI 10.1023/A:1011127315884; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DASILVA P, 1998, P 2 WORKSH AD HYP HY, P35; DASILVA P, 1997, P WEBNET 97 WORLD C, P959; De Bra P, 2000, CYBERPSYCHOL BEHAV, V3, P71; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Emde W., 1996, P 13 INT C MACH LEAR, P122; GAROFALAKIS J, 2002, P IEEE INT C ADV LEA, P28; GURER DW, 1995, P AAAI SPR S REPR ME, P51; Guzman E, 2002, LECT NOTES COMPUT SC, V2363, P739; Heift T., 2001, INT J ARTIFICIAL INT, V12, P310; Heift T, 2000, LECT NOTES COMPUT SC, V1839, P354; HENZE N, 2001, INT J ARTIFICIAL INT, V12, P325; Hoppe H. U., 1994, Journal of Artificial Intelligence in Education, V5; Hothi J., 1998, P 2 WORKSH AD HYP HY, P45; Kay J, 2000, LECT NOTES COMPUT SC, V1839, P19; Kobsa A, 2001, KNOWL ENG REV, V16, P111, DOI 10.1017/S0269888901000108; KURHILA J, 2001, P 10 INT PEG2001 C, P194; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Mitchell T. M., 1997, MACHINE LEARNING; MORIARTY C, 2001, P 2 DELOS NETW EXC W; Murphy M., 1997, P 6 INT C US MOD, P301; Nwana H. S., 1991, User Modeling and User-Adapted Interaction, V1, DOI 10.1007/BF00158950; Ogata H, 2001, COMPUT EDUC, V37, P225, DOI 10.1016/S0360-1315(01)00048-3; Okazaki Y., 1996, ED TECHNOLOGY RES, V19, P35; PALIOURAS G, 1909, P 7 INT C US MOD CIS, P169; Rich E., 1979, COGNITIVE SCI, V3, P329, DOI DOI 10.1207/515516709C0G0304_3; RICH E, 1983, INT J MAN MACH STUD, V18, P199, DOI 10.1016/S0020-7373(83)80007-8; SCHWAB I, 2002, KUNSTLICHE INTELLIGE, V3, P5; SISON R, 1998, J ARTIFICIAL INTELLI, V9, P128; Sison R, 1998, USER MODEL USER-ADAP, V8, P103, DOI 10.1023/A:1008225015395; Sison RC, 2000, MACH LEARN, V38, P157, DOI 10.1023/A:1007690108308; SLEEMAN D, 1987, ARTIFICIAL INTELLIGE; Tchetagni JMP, 2002, LECT NOTES COMPUT SC, V2363, P708; Tsiriga V., 2002, P 2002 1 INT IEEE S, V1, P138, DOI 10.1109/IS.2002.1044243; TSIRIGA V, P 2002 IEEE INT C SY; Vassileva J, 1997, FR ART INT, V39, P498; Virvou M., 2001, Proceedings IEEE International Conference on Advanced Learning Technologies, DOI 10.1109/ICALT.2001.943878; Virvou M, 1999, USER MODEL USER-ADAP, V9, P321, DOI 10.1023/A:1008385523066; Virvou M, 2001, LECT NOTES ARTIF INT, V2109, P158; Weber G., 1997, P 6 INT C US MOD, P289; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	56	23	24	1	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-1868			USER MODEL USER-ADAP	User Model. User-Adapt. Interact.		2004	14	4					289	316		10.1023/B:USER.0000043396.14788.cc		28	Computer Science, Cybernetics	Computer Science	857ZE	WOS:000224158800001		
J	Karacali, B; Ramanath, R; Snyder, WE				Karacali, B; Ramanath, R; Snyder, WE			A comparative analysis of structural risk minimization by support vector machines and nearest neighbor rule	PATTERN RECOGNITION LETTERS			English	Article						nearest neighbor; structural risk minimization; support vector machines; kernel operator; prototype selection	CLASSIFICATION; ALGORITHMS; SEARCH	Support vector machines (SVMs) are by far the most sophisticated and powerful classifiers available today. However, this robustness and novelty in approach come at a large computational cost. On the other hand, nearest neighbor (NN) classifiers provide a simple yet robust approach that is guaranteed to converge to a result. In this paper, we present a technique that combines these two classifiers by adopting a NN rule-based structural risk minimization classifier. Using synthetic and real data, the classification technique is shown to be more robust to kernel conditions with a significantly lower computational cost than conventional SVMs. Consequently, the proposed method provides a powerful alternative to SVMs in applications where computation time and accuracy are of prime importance. Experimental results indicate that the NNSRM formulation is not only computationally less expensive, but also much more robust to varying data representations than SVMs. (C) 2003 Elsevier B.V. All rights reserved.	N Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA; Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA	Ramanath, R (reprint author), N Carolina State Univ, Dept Elect & Comp Engn, Box 7911, Raleigh, NC 27695 USA.						BHATTACKARYA B, 1998, P IEEE INT C PATT RE, V1, P238, DOI 10.1109/ICPR.1998.711125; Blake C, 1998, UCI REPOSITORY MACHI; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHIDANANDAGOWDA K, 1979, IEEE T INFORM THEORY, V25, P488; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Devijver P. A., 1982, PATTERN RECOGNITION; FARACHCOLTON M, 1999, 40 ANN S FDN COMP SC; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Joachims T., 1999, ADV KERNEL METHODS S; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Osuna E., 1997, P COMP VIS PATT REC; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Scholkopf B., 1999, ADV KERNEL METHODS S; Scholkopf B., 2000, ADV NEURAL INFORM PR, V13, P301; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VAPNIK V, 1997, ADV NEURAL INFORMATI, V9; Vapnik V. N., 1998, ADAPTIVE LEARNING SY; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Yu K, 2002, NEURAL PROCESS LETT, V15, P147, DOI 10.1023/A:1015244902967	23	10	11	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN 5	2004	25	1					63	71		10.1016/j.patrec.2003.09.002		9	Computer Science, Artificial Intelligence	Computer Science	757GN	WOS:000187554800006		
J	Belacel, N; Boulassel, MR				Belacel, N; Boulassel, MR			Multicriteria fuzzy classification procedure PROCFTN: methodology and medical application	FUZZY SETS AND SYSTEMS			English	Article						multicriteria decision aid; classification; fuzzy sets; fuzzy binary relations; scoring function; astrocytic tumour; medical diagnosis	ASSIGNMENT METHOD; DIAGNOSIS; CRITERIA	In this paper, we introduce a new classification procedure for assigning objects to predefined classes, named PROCFTN. This procedure is based on a fuzzy scoring function for choosing a subset of prototypes, which represent the closest resemblance with an object to be assigned. It then applies the majority-voting rule to assign an object to a class. We also present a medical application of this procedure as an aid to assist the diagnosis of central nervous system tumours. The results are compared with those obtained by other classification methods, reported on the same data set, including decision tree, production rules, neural network, k nearest neighbor, multilayer perceptron and logistic regression. Our results are very encouraging and show that the multicriteria decision analysis approach can be successfully used to help medical diagnosis. Crown Copyright (C) 2003 Published by Elsevier B.V. All rights reserved.	Natl Res Council Canada, Inst Informat Technol E Business, E Hlth Grp, St John, NB E2L 2Z6, Canada; McGill Univ, Montreal Chest Inst, Immunodeficiency Serv, Montreal, PQ H3A 2T5, Canada	Belacel, N (reprint author), Natl Res Council Canada, Inst Informat Technol E Business, E Hlth Grp, POB 69000,127 Carleton St, St John, NB E2L 2Z6, Canada.	nabil.belacel@nrc-cnrc.gc.ca; rachid.boulasse@muhc.mcgill.ca					BANERJEE A, 1993, FUZZY SETS SYSTEMS, V53, P295; BARRETT CR, 1990, FUZZY SET SYST, V34, P197, DOI 10.1016/0165-0114(90)90159-4; BARTELS PH, 1989, ANAL QUANT CYTOL, V11, P1; Belacel N, 2001, COMPUT METH PROG BIO, V64, P145, DOI 10.1016/S0169-2607(00)00100-0; BELACEL N, 1999, THESIS FREE U BRUSSE; Belacel N, 2000, EUR J OPER RES, V125, P175, DOI 10.1016/S0377-2217(99)00192-7; Belacel N., 1999, INNOV TECH BIOL MED, V20, P239; Belacel N, 2001, ARTIF INTELL MED, V21, P201, DOI 10.1016/S0933-3657(00)00086-5; BLACK PM, 1991, NEW ENGL J MED, V324, P1555, DOI 10.1056/NEJM199105303242205; BOUYSSOU D, 1991, P INT WORKSH MULT DE, P16; Bouyssou D., 1992, MULTIPLE CRITERIA DE, P93; BURGER PC, 1985, CANCER, V56, P1106, DOI 10.1002/1097-0142(19850901)56:5<1106::AID-CNCR2820560525>3.0.CO;2-2; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOUR NN; DECAESTECKER C, 1995, J NEUROPATH EXP NEUR, V54, P371, DOI 10.1097/00005072-199505000-00010; DECAESTECKER C, 1997, THESIS FREE U BRUSSE; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; Fodor J., 1994, FUZZY PREFERENCE MOD; FODOR J, 1998, USE FUZZY PREFERENCE, P69; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; Greco S., 1999, ADV MULTIPLE CRITERI; Jelonek J., 1994, P 1 NAT C NEUR NETW, P268; Kandel E, 1991, PRINCIPLES NEURAL SC, V3rd; Kleihues P, 1993, HISTOLOGICAL TYPING; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Orlovsky S. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90001-5; Perny P, 1998, ANN OPER RES, V80, P137, DOI 10.1023/A:1018907729570; PERNY P, 1992, THESIS PARIS DAUPHIN; PERNY P, 1992, FUZZY SET SYST, V49, P33, DOI 10.1016/0165-0114(92)90108-G; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; ROUBENS M, 1989, EUR J OPER RES, V40, P309, DOI 10.1016/0377-2217(89)90423-2; ROY B., 1996, MULTICRITERIA METHOD; BRANS JP, 1985, MANAGE SCI, V31, P647, DOI 10.1287/mnsc.31.6.647; Vincke P, 1992, MULTICRITERIA DECISI; WEI Y, 1992, THESIS PARIS DAUPHIN; WEISS SM, 1991, COMPUTER SYSTEMS THA	37	16	16	0	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114			FUZZY SET SYST	Fuzzy Sets Syst.	JAN 16	2004	141	2					203	217		10.1016/S0165-0114(03)00022-8		15	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	761NJ	WOS:000187914600003		
J	Devillez, A				Devillez, A			Four fuzzy supervised classification methods for discriminating classes of non-convex shape	FUZZY SETS AND SYSTEMS			English	Article						classes of non-convex shape; fuzzy classification; fuzzy logic; possibility theory; supervised classification	PATTERN-CLASSIFICATION; RECOGNITION; ALGORITHM; RULES	Our work deals with modelling and optimising industrial processes such as metal cutting with high-speed machining. In this field we have chosen to use fuzzy supervised classification methods in order to design a diagnosis system or a process-monitoring module. The problem, we currently meet, concerns the shape of the classes, we generally obtain. These shapes are often non-convex and non-separable by a hyperplane. For these reasons, we focus on fuzzy supervised classification methods in order to discriminate these classes. The choice of a method is not obvious and we perform a comparative study. The two classical methods tested were the fuzzy K-nearest-neighbours method and a method based on distributed fuzzy rules. Furthermore, we propose two adaptations of the fuzzy pattern matching algorithm called fuzzy pattern matching with exponential function and fuzzy pattern matching multidensity. After some refresher on supervised classification, the four tested methods are detailed and compared according to the following criteria: quality of the discrimination, computation time and ability to decide. The response of each classifier is illustrated by membership level curves and the quality of diagnosis is studied by the introduction of membership and ambiguity rejects. (C) 2003 Elsevier B.V. All rights reserved.	Univ Metz, LPMM, CNRS,UMR 7554, Inst Super Genie Mecan & Prod, F-57045 Metz 1, France	Devillez, A (reprint author), Univ Metz, LPMM, CNRS,UMR 7554, Inst Super Genie Mecan & Prod, Ile Saulcy, F-57045 Metz 1, France.	deviliez@lpmm.univ-metz.fr					Baldwin JF, 1997, INT J INTELL SYST, V12, P523, DOI 10.1002/(SICI)1098-111X(199707)12:7<523::AID-INT3>3.0.CO;2-N; Baldwin JF, 1999, INT J APPROX REASON, V22, P109, DOI 10.1016/S0888-613X(99)00016-X; BELLOIR F, 1999, THESIS U REIMS CHAMP; Bezdek J. C., 1981, PATTERN RECOGNITION; Bezdek J.C., 1991, FUZZY MODELS PATTERN; Billaudel P, 1999, INT J APPROX REASON, V20, P1; BREHELIN L, 1995, ETUDE TAUX ERREUR BA; Breiman L., 1984, CLASSIFICATION REGRE, P43; Broomhead D. S., 1988, Complex Systems, V2; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVILLEZ A, 1998, CESA 98 IEEE SYSTEMS, V4, P902; DEVILLEZ A, 2002, WSEAS T CIRCUITS, V1, P94; DEVILLEZ A, 1999, THESIS U REIMS CHAMP; DEVILLEZ A, 1999, MATH INFORM SCI HUM, V147, P71; DUBOIS D, 1988, FUZZY SET SYST, V28, P313, DOI 10.1016/0165-0114(88)90038-3; DUBOIS D., 1987, THEORIE POSSIBILITES; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; DUBUISSON B., 1990, DIAGNOSTIC RECONNAIS; FRELICOT C, 1993, 12 WORLD C INT FED A; FRELICOT C, 1995, P EUFIT 95 AACH GERM; Gascuel O, 1998, INT J PATTERN RECOGN, V12, P517, DOI 10.1142/S0218001498000336; Grabisch M, 1996, EUR J OPER RES, V89, P445, DOI 10.1016/0377-2217(95)00176-X; GRABISCH M, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, P47, DOI 10.1109/FUZZY.1992.258678; GRABISCH M, 1995, INT JOINT C 4 IEEE I, P145; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; ISHIBUCHI H, 1992, FUZZY SET SYST, V52, P21, DOI 10.1016/0165-0114(92)90032-Y; ISHIBUCHI H, 1993, FUZZY SET SYST, V59, P295, DOI 10.1016/0165-0114(93)90474-V; Janikow CZ, 1996, INFORM SCIENCES, V89, P275, DOI 10.1016/0020-0255(95)00239-1; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN F, 1998, THESIS U REIMS CHAMP; Masson M.-H., 1996, RAIRO-APII-JESA Journal Europeen des Systemes Automatises, V30; NAGY G, 1968, PR INST ELECTR ELECT, V56, P836, DOI 10.1109/PROC.1968.6414; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; SHANAHAN JG, 2000, SOFT COMPUTING KNOWL; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5; Zadeh Lotfi A., 1965, FUZZY SETS INFORM CO, V8, P338, DOI DOI 10.1016/S0019-9958(65)90241-X	37	7	7	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114			FUZZY SET SYST	Fuzzy Sets Syst.	JAN 16	2004	141	2					219	240		10.1016/S0165-0114(03)00265-3		22	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	761NJ	WOS:000187914600004		
J	Liu, WX; Zheng, NN				Liu, WX; Zheng, NN			Learning sparse features for classification by mixture models	PATTERN RECOGNITION LETTERS			English	Article						non-negative matrix factorization; classification; mixture models; sparse features; Lp norm	MATRIX FACTORIZATION; RECOGNITION	Non-negative matrix factorization (NMF) can discover sparse features for classification via mixture models and the sparseness of features controls the learning rate of the basis function parameters. But the original NMF in which the basis vectors are unit ones in L-1 norm, does not increase the sparseness of learned features. This paper generalizes NMF to L-p-NMF where the basis vectors are unit ones in L-p norm. Experiments demonstrate how p affects the sparseness of learned features and the final classification accuracy. And the results show that L-2-NMF is superior one for practical implementation. (C) 2003 Elsevier B.V. All rights reserved.	Xian Jiaotong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China	Liu, WX (reprint author), Xian Jiaotong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; LEE DD, 2001, ADV NEURAL INFORAMAT, V13; Lee DD, 1999, NATURE, V401, P788; LI SZ, 2001, P IEEE INT C COMP VI; LIU WG, 2002, EXISTING NEW ALGORIT; McLachlan G., 2000, FINITE MIXTURE MODEL; McLachlan G. J., 1988, MIXTURE MODELS INFER; *MIT CTR BIOL COMP, CBCL FAC DAT; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; SAUL LK, 2002, ADV NEURAL INFORMATI, V14; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71	13	12	15	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN 19	2004	25	2					155	161		10.1016/j.patrec.2003.09.007		7	Computer Science, Artificial Intelligence	Computer Science	759CD	WOS:000187720000002		
J	Yager, RR				Yager, RR			Choquet aggregation using order inducing variables	INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS			English	Article						ordered aggregation; OWA operators; fusion; fuzzy sets; nearest neighbor methods	FUZZY MEASURES; OWA OPERATORS	We discuss the OWA and Choquet integral aggregation operators and point out the central role the ordering operation plays in these operators. We extend the capabilities of the Choquet integral aggregation by allowing the ordering to be induced by some values other then those being aggregated. This allows us to consider an induced Choquet Choquet integral aggregation operator. We look at the properties of this operator. We then look at its applications Among the applications considered are aggregations guided by linguistic and other ordinal structures. We look at the use of induced aggregation in nearest neighbor methods. We also consider the Choquet aggregation of complex objects such as matrices and vectors.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.	yager@panix.com	Yager, Ronald/A-2960-2013				Choquet G., 1953, ANN I FOURIER GRENOB, V5, P131; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1990, NORMS NN PATTERN CLA; DENNEBERG D., 1994, NONADDITIVE MEASURE; Grabisch M., 1999, FUZZY MEASURES INTEG; Grabisch M, 1997, ORDERED WEIGHTED AVERAGING OPERATORS, P73; Kacprzyk J., 1997, ORDERED WEIGHTED AVE; Mitchell HB, 2000, INT J INTELL SYST, V15, P317, DOI 10.1002/(SICI)1098-111X(200004)15:4<317::AID-INT4>3.0.CO;2-J; MUROFUSHI T, 1999, FUZZY MEASURES INTEG, P3; MUROFUSHI T, 1989, FUZZY SET SYST, V29, P201, DOI 10.1016/0165-0114(89)90194-2; Schaefer PA, 1999, INT J INTELL SYST, V14, P123, DOI 10.1002/(SICI)1098-111X(199902)14:2<123::AID-INT1>3.3.CO;2-5; SIGENO M, 1977, FUZZY AUTOMATA DECIS, P89; Yager R. R., 1998, P FUZZ IEEE WORLD C, P123; YAGER RR, 1993, FUZZY SET SYST, V59, P125, DOI 10.1016/0165-0114(93)90194-M; Yager RR, 2002, IEEE T SYST MAN CY B, V32, P512, DOI 10.1109/TSMCB.2002.1018770; YAGER RR, 1992, INT J MAN MACH STUD, V37, P103, DOI 10.1016/0020-7373(92)90093-Z; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; Yager RR, 1998, PROCEEDINGS OF THE IEEE/IAFE/INFORMS 1998 CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR FINANCIAL ENGINEERING (CIFER), P220, DOI 10.1109/CIFER.1998.690125; Yager RR, 2000, IEEE T FUZZY SYST, V8, P453, DOI 10.1109/91.868951; Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789; YAGER RR, 2001, P ATL S COMP BIOL GE, P92; YAGER RR, 1997, INCULSION IMPORTANCE, P41; ZADEH LA, 1999, P EUROFUSE SIC C 199, P1; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904	25	42	43	0	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 912805, SINGAPORE	0218-4885			INT J UNCERTAIN FUZZ	Int. J. Uncertainty Fuzziness Knowl.-Based Syst.	FEB	2004	12	1					69	88		10.1142/S0218488504002667		20	Computer Science, Artificial Intelligence	Computer Science	811YL	WOS:000220807100007		
J	Lee, Y; Wahba, G; Ackerman, SA				Lee, Y; Wahba, G; Ackerman, SA			Cloud classification of satellite radiance data by multicategory support vector machines	JOURNAL OF ATMOSPHERIC AND OCEANIC TECHNOLOGY			English	Article							MODIS	Two-category support vector machines (SVMs) have become very popular in the machine learning community for classification problems and have recently been shown to have good optimality properties for classification purposes. Treating multicategory problems as a series of binary problems is common in the SVM paradigm. However, this approach may fail under a variety of circumstances. The multicategory support vector machine (MSVM), which extends the binary SVM to the multicategory case in a symmetric way, and has good theoretical properties, has recently been proposed. The proposed MSVM in addition provides a unifying framework when there are either equal or unequal misclassification costs, and when there is a possibly nonrepresentative training set. Illustrated herein is the potential of the MSVM as an efficient cloud detection and classification algorithm for use in Earth Observing System models, which require knowledge of whether or not a radiance profile is cloud free. If the profile is not cloud free, it is valuable to have information concerning the type of cloud, for example, ice or water. The MSVM has been applied to simulated MODIS channel data to classify the radiance profiles as coming from clear sky, water clouds, or ice clouds, and the results are promising. It can be seen in simple examples, and application to Moderate Resolution Imaging Spectroradiometer (MODIS) observations, that the method is an improvement over channel-by-channel partitioning. It is believed that the MSVM will be a very useful tool for classification problems in atmospheric sciences.	Univ Wisconsin, Dept Stat, Madison, WI 53706 USA; Ohio State Univ, Dept Stat, Columbus, OH 43210 USA; Univ Wisconsin, Dept Atmospher & Ocean Sci, Madison, WI USA	Wahba, G (reprint author), Univ Wisconsin, Dept Stat, 1210 W Dayton St, Madison, WI 53706 USA.	wahba@stat.wisc.edu	Lee, Yoonkyung/K-4360-2015	Lee, Yoonkyung/0000-0002-5756-6588			Ackerman SA, 1998, J GEOPHYS RES-ATMOS, V103, P32141, DOI 10.1029/1998JD200032; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ferris MC, 1999, COMPUT OPTIM APPL, V12, P207, DOI 10.1023/A:1008636318275; Heidinger AK, 2002, J ATMOS OCEAN TECH, V19, P586, DOI 10.1175/1520-0426(2002)019<0586:UMTECC>2.0.CO;2; Key JR, 1998, COMPUT GEOSCI, V24, P443, DOI 10.1016/S0098-3004(97)00130-1; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; LEE Y, 2002, 1064 U WISC DEP STAT; Lee Y., 2001, COMPUTING SCI STAT, V33, P498; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; LEE Y, 2002, 1062 U WISC DEP STAT; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Lin Y., 1999, 1014 U WISC DEP STAT; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; Mangasarian O. L., 1994, CLASSICS APPL MATH, V10; OSULLIVAN F, 1986, J AM STAT ASSOC, V81, P96, DOI 10.2307/2287973; Platnick S, 2003, IEEE T GEOSCI REMOTE, V41, P459, DOI 10.1109/TGRS.2002.808301; Scholkopf B., 1999, ADV KERNEL METHODS S; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Smola P., 2002, LEARNING KERNELS SUP; STRABALA KI, 1994, J APPL METEOROL, V33, P212, DOI 10.1175/1520-0450(1994)033<0212:CPIFD>2.0.CO;2; Vapnik V., 1998, STAT LEARNING THEORY; Wahba G, 2002, P NATL ACAD SCI USA, V99, P16524, DOI 10.1073/pnas.242574899; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; Wahba G, 2000, ADV NEUR IN, P297; WAHBA G, 1994, ADV NEURAL INFORMATI, V6, P415; Wahba G, 1990, CBMS NSF REGIONAL C, V59; Wahba G, 1995, ANN STAT, V23, P1865	27	27	28	5	11	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	0739-0572			J ATMOS OCEAN TECH	J. Atmos. Ocean. Technol.	FEB	2004	21	2					159	169		10.1175/1520-0426(2004)021<0159:CCOSRD>2.0.CO;2		11	Engineering, Ocean; Meteorology & Atmospheric Sciences	Engineering; Meteorology & Atmospheric Sciences	780PT	WOS:000189391100002		
J	Teoh, A; Samad, SA; Hussain, A				Teoh, A; Samad, SA; Hussain, A			Nearest neighbourhood classifiers in a bimodal biometric verification system fusion decision scheme	JOURNAL OF RESEARCH AND PRACTICE IN INFORMATION TECHNOLOGY			English	Article						biometrics; face verification; speaker verification; k-NN classifiers	SPEAKER RECOGNITION; IDENTIFICATION; FACE; AUTHENTICATION; CLASSIFICATION; ALGORITHM	Identity verification systems that use a mono modal biometrics always have to contend with sensor noise and limitations of feature extractor and matching. However combining information from different biometrics modalities may well provide higher and more consistent performance levels. A robust yet simple scheme can fuse the decisions produced by the individual biometric experts. In this paper, k-Nearest Neighbourhood (k-NN) based classifiers are adopted in the decision fusion module for the face and speech experts. k-NN rule owes much of its popularity in pattern recognition community to its simplicity and good performance in practical application. Besides that, k-NN may also provide a ternary decision scheme which is rarely found in other classifiers. The fusion decision schemes considered are voting-, modified- and theoretic evidence of k-NN classifiers based on Dempster-Shafer theory. The performances of these k-NN classifiers are evaluated in both balanced and unbalanced conditions and compared with other classification approaches such as sum rule, voting techniques and Multilayer Perceptron on a bimodal database.	Multimedia Univ, FIST, Melaka 75450, Malaysia; Univ Kebangsaan Malaysia, Fac Engn, Elect Elect & Syst Engn Dept, Bangi, Malaysia	Teoh, A (reprint author), Multimedia Univ, FIST, Melaka 75450, Malaysia.	bjteoh@mmu.edu.my; salina@eng.ukm.my; aini@eng.ukm.my	Teoh, Andrew Beng Jin/F-4422-2010; Hussain, Aini/G-4074-2011				Bigun E., 1997, P 1 INT C AUD VID BA, P327; BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560; Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714; CHOUDHURY T, 1999, 2 INT C AUD BIOM PER, P176; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dieckmann U, 1997, PATTERN RECOGN LETT, V18, P827, DOI 10.1016/S0167-8655(97)00063-9; Duc B, 1997, LECT NOTES COMPUT SC, V1206, P311; Duda R. O., 1973, PATTERN CLASSIFICATI; HELLMAN MF, 1970, IEEE T SYST MAN CYB, V6, P155; Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Martin R., 1994, P 7 EUR SIGN PROC C, P1182; MOGHADDAM B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P786; *OL RES LAB, 2000, DAT FAC; *OTAGO, 2000, OT SPEECH CORP; Pigeon S, 1998, P SOC PHOTO-OPT INS, V3314, P166, DOI 10.1117/12.304683; Rabiner L., 1993, FUNDAMENTALS SPEECH; ROLI F, 2002, P 3 INT WORKSH MCS 2; Ross A., 2001, P 3 INT C AUD VID BA, P354; SAKOE H, 1971, P 7 INT C AC, V20, pC13; SAMAD SA, 2001, P INT C INF TECHN MU; Samad S. A., 2001, Proceedings of the Sixth International Symposium on Signal Processing and its Applications (Cat.No.01EX467), DOI 10.1109/ISSPA.2001.950224; SANDERSON C, 2001, DIGIT DATABASE 1 0 M; Shafer G., 1976, MATH THEORY EVIDENCE; Turk L, 1999, AEROSP SCI TECHNOL, V3, P71, DOI 10.1016/S1270-9638(99)80031-5; VERLINDE P, 1999, 2 INT C AUD VID BAS; Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805; WILPON JG, 1985, IEEE T ACOUST SPEECH, V33, P587, DOI 10.1109/TASSP.1985.1164581; YACOUB SB, 1999, P 2 INT C AUD VID BA, P25; Zilovic MS, 1997, IEEE T SPEECH AUDI P, V5, P84, DOI 10.1109/89.554274	31	7	7	0	4	AUSTRALIAN COMPUTER SOC INC	SYDNEY	PO BOX Q534, QVB POST OFFICE, SYDNEY, NSW 1230, AUSTRALIA	1443-458X			J RES PRACT INF TECH	J. Res. Pract. Inf. Technol.	FEB	2004	36	1					47	62				16	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	806VE	WOS:000220460600005		
J	Li, JY; Dong, GZ; Ramamohanarao, K; Wong, LS				Li, JY; Dong, GZ; Ramamohanarao, K; Wong, LS			DeEPs: A new instance-based lazy discovery and classification system	MACHINE LEARNING			English	Article						instance-based; emerging patterns; borders; lazy learning; classification	LEARNING ALGORITHMS; NEAREST-NEIGHBOR; PATTERNS	Distance is widely used in most lazy classification systems. Rather than using distance, we make use of the frequency of an instance's subsets of features and the frequency-change rate of the subsets among training classes to perform both knowledge discovery and classification. We name the system DeEPs. Whenever an instance is considered, DeEPs can efficiently discover those patterns contained in the instance which sharply differentiate the training classes from one to another. DeEPs can also predict a class label for the instance by compactly summarizing the frequencies of the discovered patterns based on a view to collectively maximize the discriminating power of the patterns. Many experimental results are used to evaluate the system, showing that the patterns are comprehensible and that DeEPs is accurate and scalable.	Inst Infocomm Res, Singapore 119613, Singapore; Wright State Univ, Dept CSE, Dayton, OH 45435 USA; Univ Melbourne, Dept CSSE, Parkville, Vic 3052, Australia	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@i2r.a-star.edu.sg; gdong@cs.wright.edu; rao@cs.mu.oz.au; limsoon@i2r.a-star.edu.sg	Wong, Limsoon/E-5033-2010	Wong, Limsoon/0000-0003-1241-5441			Agrawal R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Aha D. W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C., 1998, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR PAT; Datta P., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; DATTA P, 1997, MACH LEARN, P75; Devroye L., 1996, PROBABILISTIC THEORY; Domingos P, 1996, MACH LEARN, V24, P141; Dong G., 1998, P 2 PAC AS C KNOWL D, P72; Dong G., 1999, P 2 INT C DISC SCI, P30; Dong G. Z., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Duda R. O., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; HILDERMAN RJ, 2001, P 5 PAC AS C KNOWL D, P247; HIRSH H, 1994, MACH LEARN, V17, P5, DOI 10.1007/BF00993863; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Jinyan Li, 2001, KNOWL INF SYST, V3, P131, DOI DOI 10.1007/PL00011662; KEUNG CK, 2000, P 4 PAC AS C KNOWL D, P142; Klemettinen M, 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; KUBAT M, 2000, MACH LEARN, P503; Langley P., 1992, P 10 NAT C ART INT, P223; Langley P., 1993, P 13 INT JOINT C ART, P889; Li J., 2001, THESIS U MELBOURNE; LI J, 2001, 5 PAC AS C KNOWL DIS, P455; Li J, 2000, P 4 EUR C PRINC PRAC, P191; Li J., 2000, P 17 INT C MACH LEAR, P551; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Liu B., 1998, P 4 INT C KNOWL DISC, P80; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Mitchell T. M., 1977, P 5 INT JOINT C ART, P305; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Sahar S, 1999, P 5 ACM SIGKDD INT C, P332, DOI 10.1145/312129.312272; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Sebag M., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, P323; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WILSON DR, 1997, MACH LEARN, P403; ZHANG JP, 1992, MACHINE LEARNING /, P470	48	48	51	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	FEB	2004	54	2					99	124		10.1023/B:MACH.0000011804.08528.7d		26	Computer Science, Artificial Intelligence	Computer Science	762XB	WOS:000188006900001		
J	Lindenbaum, M; Markovitch, S; Rusakov, D				Lindenbaum, M; Markovitch, S; Rusakov, D			Selective sampling for nearest neighbor classifiers	MACHINE LEARNING			English	Article						active learning; selective sampling; nearest neighbor; random field	LEARNING ALGORITHMS; CLASSIFICATION	Most existing inductive learning algorithms work under the assumption that their training examples are already tagged. There are domains, however, where the tagging procedure requires significant computation resources or manual labor. In such cases, it may be beneficial for the learner to be active, intelligently selecting the examples for labeling with the goal of reducing the labeling cost. In this paper we present LSS-a lookahead algorithm for selective sampling of examples for nearest neighbor classifiers. The algorithm is looking for the example with the highest utility, taking its effect on the resulting classifier into account. Computing the expected utility of an example requires estimating the probability of its possible labels. We propose to use the random field model for this estimation. The LSS algorithm was evaluated empirically on seven real and artificial data sets, and its performance was compared to other selective sampling algorithms. The experiments show that the proposed algorithm outperforms other methods in terms of average error rate and stability.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Lindenbaum, M (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	mic@cs.technion.ac.il; shaulm@cs.technion.ac.il; rusakov@cs.technion.ac.il					Adler R. J., 1981, GEOMETRY RANDOM FIEL; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; Blake C, 1998, UCI REPOSITORY MACHI; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Cohn D.A., 1995, ADV NEURAL INFORM PR, V7, P705; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagan I., 1995, P 12 INT C MACH LEAR, P150; DAVIS DT, 1992, P IJCNN, V1, P676, DOI 10.1109/IJCNN.1992.287109; DeGroot MH, 1986, PROBABILITY STAT, V2nd; Duda R. O., 1973, PATTERN CLASSIFICATI; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; Fedorov VV, 1972, THEORY OPTIMAL EXPT; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; HASENJAGER M, 1996, LECT NOTES COMPUTER, V1112, P501; Hasenjager M, 1998, NEURAL PROCESS LETT, V7, P107, DOI 10.1023/A:1009688513124; Lang K, 1988, P 1988 CONN MOD SUMM, P52; Lewis D.D., 1994, P 11 INT C MACH LEAR, P148; Lindenbaum M., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); MacKay D., 1998, NATO ASI SERIES F, V168, P133; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; Moores AW, 1998, P 15 INT C MACH LEAR, P386; Murthy SK, 1995, P 14 INT JOINT C ART, P1025; Papoulis A., 1991, PROBABILITY RANDOM V, V3rd; RAYCHAUDHURI T, 1995, IEEE ICNN, V3, P1338; Russell S., 1995, ARTIFICIAL INTELLIGE; SEUNG HS, 1992, P 5 ANN ACM WORKSH C; Smyth B, 1999, LECT NOTES ARTIF INT, V1650, P329; TAN M, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P854; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wong E., 1985, STOCHASTIC PROCESSES; Zhang JP, 1997, ARTIF INTELL REV, V11, P175, DOI 10.1023/A:1006500703083	34	59	63	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	FEB	2004	54	2					125	152		10.1023/B:MACH.0000011805.60520.fe		28	Computer Science, Artificial Intelligence	Computer Science	762XB	WOS:000188006900002		
J	Podsiadlo, P; Stachowiak, GW				Podsiadlo, P; Stachowiak, GW			Classification of tribological surfaces without surface parameters	TRIBOLOGY LETTERS			English	Article						classification; dissimilarity measure; tribological surfaces	SUPPORT VECTOR MACHINES; PATTERN-CLASSIFICATION; DISTANCE; RECOGNITION; ROUGHNESS; NETWORKS; WEAR	Quantitative measures are obtained from images of tribological surfaces. Based on these data, decisions are made regarding manufacturing and maintenance processes, machine-condition monitoring and failure analysis of engineering components. These decisions are often guided by an automated pattern recognition system. Components of this system are: surface topography data acquisition, surface characterization, surface classification and performance evaluation. The characterization and classification of tribological surfaces are major challenges that make the development of a reliable pattern-recognition system difficult. The reasons are that: (i) tribological surfaces often exhibit a non-stationary and multiscale nature, while most surface characterization methods currently used work well with surface data exhibiting a stationary random process, (ii) changes in topography that might occur between the interacting surfaces usually need to be known in advance, and (iii) the selection of surface parameters that separate different classes of surfaces is usually time-consuming and cumbersome. Because of these difficulties, characterization and classification methods which do not use surface parameters have been developed. In the classification methods, a measure of dissimilarity (e.g., Euclidean distance) calculated between a surface to be classified and already classified surfaces was used, instead of surface parameters. The unclassified surface was assigned to the class ( of classified surfaces) with the lowest value of dissimilarity measure. The suitability of different classifiers; such as k-nearest neighbour classifier, linear-discriminant-analysis based classifiers and different dissimilarity measures; for the classification of tribological surface topographies ( without the need for surface parameters) is investigated in this paper. Recent developments in this area, i. e., a fractal measure and a hybrid fractal-wavelet measure, are also discussed. The most suitable method for the classification of tribological surfaces has been selected.	Univ Western Australia, Sch Mech & Mat Engn, Tribol Lab, Crawley, WA 6009, Australia	Stachowiak, GW (reprint author), Univ Western Australia, Sch Mech & Mat Engn, Tribol Lab, Crawley, WA 6009, Australia.						ARKADEV AG, 1996, COMPUTERS PATTERN RE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COCHET W, 1997, OPER RES, V45, P213; Coquin D, 2001, PATTERN RECOGN LETT, V22, P1483, DOI 10.1016/S0167-8655(01)00104-0; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Di Gesu V, 1999, PATTERN RECOGN LETT, V20, P207, DOI 10.1016/S0167-8655(98)00115-9; DONG WP, 2000, DEV METHODS CHARACTE; Duin RPW, 1999, PATTERN RECOGN LETT, V20, P1175, DOI 10.1016/S0167-8655(99)00085-9; Duin RPW, 1998, KYBERNETIKA, V34, P399; Fisher Y., 1995, FRACTAL IMAGE COMPRE; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028; Niu YM, 1998, J MANUF SCI E-T ASME, V120, P807, DOI 10.1115/1.2830224; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Pekalska E., 2001, J MACHINE LEARNING R, V2, P175; Podsiadlo P, 2002, TRIBOL LETT, V13, P241, DOI 10.1023/A:1021059108478; PODSIADLO P, 2003, IN PRESS WEAR; PODSIADLO P, 2001, TRIBOLOGY SERIES, V39, P697; Podsiadlo P, 2000, TRIBOLOGY SERIES, V38, P546; RAMAMOORTHY B, 1993, WEAR, V167, P155, DOI 10.1016/0043-1648(93)90320-L; Rosenfeld A, 2000, INT J IMAG SYST TECH, V11, P101, DOI 10.1002/1098-1098(2000)11:2<101::AID-IMA1>3.0.CO;2-J; Stachowiak GB, 2001, WEAR, V249, P201, DOI 10.1016/S0043-1648(01)00557-9; Stachowiak GW, 2001, WEAR, V249, P194, DOI 10.1016/S0043-1648(01)00562-2; Subrahmanyam M, 1997, TRIBOL INT, V30, P739, DOI 10.1016/S0301-679X(97)00056-X; Tan T, 2002, PATTERN RECOGN, V35, P1371, DOI 10.1016/S0031-3203(01)00125-X; Thomas TR, 1998, INT J MACH TOOL MANU, V38, P405, DOI 10.1016/S0890-6955(97)00084-9; Tsai DM, 1999, PATTERN RECOGN, V32, P389, DOI 10.1016/S0031-3203(98)00077-6; Webb A, 1999, STAT PATTERN RECOGNI; Wu YQ, 2002, PATTERN RECOGN, V35, P2311, DOI 10.1016/S0031-3203(01)00132-7	30	6	6	1	2	KLUWER ACADEMIC/PLENUM PUBL	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1023-8883			TRIBOL LETT	Tribol. Lett.	FEB	2004	16	1-2					163	171		10.1023/B:TRIL.0000009726.17576.b5		9	Engineering, Chemical; Engineering, Mechanical	Engineering	756ZU	WOS:000187516300019		
J	Wyns, B; Boullart, L; Sette, S; Baeten, D; Hoffman, I; De Keyser, F				Wyns, B; Boullart, L; Sette, S; Baeten, D; Hoffman, I; De Keyser, F			Prediction of arthritis using a modified Kohonen mapping and case based reasoning	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						classification; neural network models; case based reasoning; threshold; self-organizing systems; medical applications	SELF-ORGANIZING MAP; RHEUMATOID-ARTHRITIS; DIAGNOSIS	Rheumatoid arthritis and spondyloarthropathy are the two most frequent forms of chronic autoimmune arthritis. These diseases lead to important inflammatory symptoms resulting in an important functional impairment. In this paper we apply a topological mapping combined with a case based reasoning evaluation criterion to predict early arthritis. The first part presents a brief introduction to the problem and self-learning neural networks while the second part of this paper will apply this technique together with a case based reasoning evaluation criterion to diagnostic classification. Finally the paper shows that the Kohonen neural network achieves good performance that exceeds the results of other neural network approaches and decision trees. (C) 2004 Elsevier Ltd. All rights reserved.	State Univ Ghent, Dept Elect Energy Syst & Automat, B-9052 Zwijnaarde, Belgium; Hogesch W Vlaanderen, ICT, B-8500 Kortrijk, Belgium; State Univ Ghent Hosp, Dept Rheumatol, B-9000 Ghent, Belgium	Wyns, B (reprint author), State Univ Ghent, Dept Elect Energy Syst & Automat, Technol Pk 913, B-9052 Zwijnaarde, Belgium.	bart.wyns@ugent.be					Baeten D, 1999, CLIN RHEUMATOL, V18, P434, DOI 10.1007/s100670050134; Baeten D, 2000, ANN RHEUM DIS, V59, P945, DOI 10.1136/ard.59.12.945; Baeten D, 2001, ARTHRITIS RHEUM, V44, P2255, DOI 10.1002/1529-0131(200110)44:10<2255::AID-ART388>3.0.CO;2-#; Chen DR, 2000, ULTRASOUND MED BIOL, V26, P405, DOI 10.1016/S0301-5629(99)00156-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Henson DB, 1997, ARTIF INTELL MED, V10, P99, DOI 10.1016/S0933-3657(97)00388-6; Hrycej T., 1997, NEUROCONTROL IND CON; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; LOH WY, 2002, QUICK UNBIASED EFFIC; LOH WY, 1997, STAT SINICA, V10, P15; Markey MK, 2003, ARTIF INTELL MED, V27, P113, DOI 10.1016/S0933-3657(03)00003-4; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SETTE S, 1995, TEXT RES J, V65, P196, DOI 10.1177/004051759506500402; SIEBEN G, 1994, ACTA NEUROCHIR, V129, P193, DOI 10.1007/BF01406504; TROFESTAS SG, 1997, METHODS APPL INTELLI; Vercauteren L., 1990, P INT NEUR NETW C PA, P387; Zilouchian A., 2000, INTELLIGENT CONTROL	17	4	4	0	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976			ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	MAR	2004	17	2					205	211		10.1016/j.engappai.2004.02.007		7	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	821BL	WOS:000221434400008		
J	Garcia-Gomez, JM; Vidal, U; Marti-Bonmati, L; Galant, J; Sans, N; Robles, M; Casacuberta, F				Garcia-Gomez, JM; Vidal, U; Marti-Bonmati, L; Galant, J; Sans, N; Robles, M; Casacuberta, F			Benign/malignant classifier of soft tissue tumors using MR imaging	MAGNETIC RESONANCE MATERIALS IN PHYSICS BIOLOGY AND MEDICINE			English	Article						magnetic resonance imaging; soft tissue tumor; pattern recognition; clinical decision support systems; artificial neural networks; support vector machine; K-Nearest neighbor	SUPPORT VECTOR MACHINES; ARTIFICIAL NEURAL-NETWORK; BREAST-CANCER; PREDICTION; MALIGNANCY; MICROCALCIFICATIONS	This article presents a pattern-recognition approach to the soft tissue tumors (STT) benign/ malignant character diagnosis using magnetic resonance (MR) imaging applied to a large multicenter database. Objective: To develop and test an automatic classifier of STT into benign or malignant by using classical MR imaging findings and epidemiological information. Materials and methods: A database of 430 patients (62% benign and 38% malignant) from several European multicenter registers. There were 61 different histologies (36 with benign and 25 with malignant nature). Three pattern-recognition methods (artificial neural networks, support vector machine, k-nearest neighbor) were applied to learn the discrimination between benignity and malignancy based on a defined MR imaging findings protocol. After the systems had learned by using training samples (with 302 cases), the clinical decision support system was tested in the diagnosis of 128 new STT cases. Results: An 88-92% efficacy was obtained in a not-viewed set of tumors using the pattern-recognition techniques. The best results were obtained with a back-propagation artificial neural network. Conclusion: Benign vs. malignant STT discrimination is accurate by using pattern-recognition methods based on classical MR image findings. This objective tool will assist radiologists in STT grading.	Hosp Univ Dr Peset, Serv Radiol, Valencia 46017, Spain; Univ Politecn Valencia, BET, E-46071 Valencia, Spain; Hosp San Juan Alicante, Serv Radiol, Alicante, Spain; CHU Purpan, Dept Radiol, Toulouse, France; Univ Politecn Valencia, DSIC, ITI, E-46071 Valencia, Spain	Garcia-Gomez, JM (reprint author), Hosp Univ Dr Peset, Serv Radiol, Avda Gaspar Aguilar 90, Valencia 46017, Spain.	Luis.Marti@uv.es	Marti-Bonmati, Luis/A-1147-2015; 	Marti-Bonmati, Luis/0000-0002-8234-010X; Robles, Montserrat/0000-0002-7705-1389			Abdolmaleki P, 1997, Radiat Med, V15, P283; Abdolmaleki P, 2001, CANCER LETT, V171, P183, DOI 10.1016/S0304-3835(01)00508-0; Baker JA, 1996, RADIOLOGY, V198, P131; Bazzani A, 2001, PHYS MED BIOL, V46, P1651, DOI 10.1088/0031-9155/46/6/305; Bishop C.M., 1995, NEURAL NETWORKS PATT; CHANG RF, 2003, ULTRASOUN MED BIOL, V10, P189; Chang RF, 2003, ULTRASOUND MED BIOL, V29, P679, DOI 10.1016/S0301-5629(02)00788-3; Chen DR, 2002, ULTRASOUND MED BIOL, V28, P1301, DOI 10.1016/S0301-5629(02)00620-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Schepper AM, 2000, EUR RADIOL, V10, P213, DOI 10.1007/s003300050037; Dhawan AP, 1996, IEEE T MED IMAGING, V15, P246, DOI 10.1109/42.500063; Duda R O, 2001, PATTERN CLASSIFICATI; FLOYD CE, 1994, CANCER, V74, P2944, DOI 10.1002/1097-0142(19941201)74:11<2944::AID-CNCR2820741109>3.0.CO;2-F; Galant J, 2003, EUR RADIOL, V13, P337, DOI 10.1007/s0030-002-1463-6; GALANT J, 1998, THESIS U MH DEALICAN; GARCIAGOMEZ JM, 2002, P 19 ANN M EUR SOC M, P274; GURNEY JW, 1995, RADIOLOGY, V196, P823; JOACHIMS T, 2002, SVM LIGHT V4 00 SUPP; Lisboa PJG, 2002, NEURAL NETWORKS, V15, P11, DOI 10.1016/S0893-6080(01)00111-3; Liu HX, 2003, J CHEM INF COMP SCI, V43, P900, DOI 10.1021/ci0256438; Lu C, 2003, ARTIF INTELL MED, V28, P281, DOI 10.1016/S0933-3657(03)00051-4; MALDONADO JA, 2001, P 23 ANN ITN C IEEE; May DA, 1997, SKELETAL RADIOL, V26, P2; MOULTON JS, 1995, AM J ROENTGENOL, V164, P1191; Bosanquet N, 1999, LANCET, V353, P1381; Sahiner B, 1996, IEEE T MED IMAGING, V15, P598, DOI 10.1109/42.538937; Sboner A, 2003, ARTIF INTELL MED, V27, P29, DOI 10.1016/S0933-3657(02)00087-8; Segal NH, 2003, AM J PATHOL, V163, P691, DOI 10.1016/S0002-9440(10)63696-6; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; SHORTLIFFE E, 2000, MED INFORMATICS COMP; Underwood J, 2001, ST HEAL T, V84, P561; VANBEMMEL JH, 1997, HDB MED INFORMATICS, P239; VANDERLEI J, 1997, HDB MED INFORMATICS, P261; VIDAL C, 2002, P 9 C SOC ESP INF SA, P207; Weatherall P T, 1995, Magn Reson Imaging Clin N Am, V3, P669; Zell A., 1995, STUTTGART NEURAL NET	36	4	4	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0968-5243			MAGN RESON MATER PHY	Magn. Reson. Mat. Phys. Biol. Med.	MAR	2004	16	4					194	201		10.1007/s10334-003-0023-7		8	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	818BF	WOS:000221219900006	14999563	
J	Burroni, M; Corona, R; Dell'Eva, G; Sera, F; Bono, R; Puddu, P; Perotti, R; Nobile, F; Andreassi, L; Rubegni, P				Burroni, M; Corona, R; Dell'Eva, G; Sera, F; Bono, R; Puddu, P; Perotti, R; Nobile, F; Andreassi, L; Rubegni, P			Melanoma computer-aided diagnosis: Reliability and feasibility study	CLINICAL CANCER RESEARCH			English	Article							PIGMENTED SKIN-LESIONS; ARTIFICIAL NEURAL-NETWORK; DIGITAL EPILUMINESCENCE MICROSCOPY; FINITE-SAMPLE SIZE; MALIGNANT-MELANOMA; 7-POINT CHECKLIST; IMAGE-ANALYSIS; ABCD RULE; DERMOSCOPY ANALYSIS; PATTERN-ANALYSIS	Background Differential diagnosis of melanoma from melanocytic nevi is often not straightforward. Thus, a growing interest has developed in the last decade in the automated analysis of digitized images obtained by epiluminescence microscopy techniques to assist clinicians in differentiating early melanoma from benign skin lesions. Purpose: The aim of this study was to evaluate diagnostic accuracy provided by different statistical classifiers on a large set of pigmented skin lesions grabbed by four digital analyzers located in two different dermatological units. Experimental Design: Images of 391melanomas and 449 melanocytic nevi were included in the study. A linear classifier was built by using the method of receiver operating characteristic curves to identify a threshold value for a fixed sensitivity of 95%. A K-nearest-neighbor classifier, a non-parametric method of pattern recognition, was constructed using all available image features and trained for a sensitivity of 98% on a large exemplar set of lesions. Results: On independent test sets of lesions, the linear classifier and the K-nearest-neighbor classifier produced a mean sensitivity of 95% and 98% and a mean specificity of 78% and of 79%, respectively. Conclusions: In conclusion, our study suggests that computer-aided differentiation of melanoma from benign pigmented lesions obtained with DB-Mips is feasible and, above all, reliable. In fact, the same instrumentations used in different units provided similar diagnostic accuracy. Whether this would improve early diagnosis of melanoma and/or reducing unnecessary surgery needs to be demonstrated by a randomized clinical trial.	Univ Siena, Policlin Le Scotte, Ist Sci Dermatol, Dept Dermatol, I-53100 Siena, Italy; Italian Canc League, Siena, Italy; Ist Dermopat Immacolata, Rome, Italy	Rubegni, P (reprint author), Univ Siena, Policlin Le Scotte, Ist Sci Dermatol, Dept Dermatol, Via Laterina 8, I-53100 Siena, Italy.	rubegni@unisi.it	Sera, Francesco/C-8176-2011				Andreassi L, 1999, ARCH DERMATOL, V135, P1459, DOI 10.1001/archderm.135.12.1459; Argenziano G, 1998, ARCH DERMATOL, V134, P1563, DOI 10.1001/archderm.134.12.1563; ASCIERTO PA, 2003, INT J ONCOL, V2, P1209; Bafounta ML, 2001, ARCH DERMATOL, V137, P1343; Bauer P, 2000, MELANOMA RES, V10, P345, DOI 10.1097/00008390-200008000-00005; Bellman R., 1961, ADAPTIVE CONTROL PRO; Binder M, 2000, MELANOMA RES, V10, P556, DOI 10.1097/00008390-200012000-00007; BINDER M, 1995, ARCH DERMATOL, V131, P286, DOI 10.1001/archderm.131.3.286; Binder M, 1998, MELANOMA RES, V8, P261, DOI 10.1097/00008390-199806000-00009; BINDER M, 1994, BRIT J DERMATOL, V130, P460, DOI 10.1111/j.1365-2133.1994.tb03378.x; Carli P, 1998, EUR J CANCER PREV, V7, P397, DOI 10.1097/00008469-199810000-00005; Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CURLEY RK, 1989, BRIT MED J, V299, P16; DECOSTE SD, 1993, ARCH DERMATOL, V129, P57, DOI 10.1001/archderm.129.1.57; Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004; DUVIVIER AWP, 1991, CLIN EXP DERMATOL, V16, P344, DOI 10.1111/j.1365-2230.1991.tb00397.x; ERCAL F, 1994, IEEE T BIO-MED ENG, V41, P837, DOI 10.1109/10.312091; FRIEDMAN RJ, 1985, CA-CANCER J CLIN, V35, P130, DOI 10.3322/canjclin.35.3.130; GREEN A, 1994, J AM ACAD DERMATOL, V31, P958; GRIN CM, 1990, ARCH DERMATOL, V126, P763, DOI 10.1001/archderm.126.6.763; Gutkowicz-Krusin D., 1997, SKIN RES TECHNOL, P15, DOI 10.1111/j.1600-0846.1997.tb00154.x; HALL PN, 1995, BRIT J DERMATOL, V132, P325, DOI 10.1111/j.1365-2133.1995.tb08664.x; HEALSMITH MF, 1994, BRIT J DERMATOL, V130, P48, DOI 10.1111/j.1365-2133.1994.tb06881.x; KOH HK, 1990, CANCER, V65, P375, DOI 10.1002/1097-0142(19900115)65:2<375::AID-CNCR2820650233>3.0.CO;2-Z; MACKIE RM, 1990, BRIT MED J, V301, P1005; Mardia K. V., 1979, MULTIVARIATE ANAL; MCGOVERN TW, 1992, J DERMATOL SURG ONC, V18, P22; Menzies SW, 1996, ARCH DERMATOL, V132, P1178, DOI 10.1001/archderm.132.10.1178; NACHBAR F, 1994, J AM ACAD DERMATOL, V30, P551; HALL WH, 1992, JAMA-J AM MED ASSOC, V268, P1314; PEHAMBERGER H, 1993, J INVEST DERMATOL, V100, pS356, DOI 10.1038/jid.1993.63; Pizzichetta MA, 2001, ARCH DERMATOL, V137, P1376; Rigel DS, 2000, CA-CANCER J CLIN, V50, P215, DOI 10.3322/canjclin.50.4.215; Rubegni P, 2002, J INVEST DERMATOL, V119, P471, DOI 10.1046/j.1523-1747.2002.01835.x; Rubegni P, 2002, INT J CANCER, V101, P576, DOI 10.1002/ijc.10620; Sahiner B, 2000, MED PHYS, V27, P1509, DOI 10.1118/1.599017; SCHINDEWOLF T, 1993, ANAL QUANT CYTOL, V15, P1; SEIDENARI S, 1999, MELANOMA RES, V9, P63; Seidenari S, 1999, MELANOMA RES, V9, P163, DOI 10.1097/00008390-199904000-00009; Sober Arthur J., 1994, Journal of Dermatology (Tokyo), V21, P885; SOYER H, 2001, ATLAS BASED CONSENSU; STANGANELLI I, 1995, J AM ACAD DERMATOL, V33, P584, DOI 10.1016/0190-9622(95)91275-4; STEINER A, 1987, ANTICANCER RES, V7, P433; STEINER A, 1987, J AM ACAD DERMATOL, V17, P584, DOI 10.1016/S0190-9622(87)70240-0; Swets J. A., 1992, EVALUATION DIAGNOSTI; Whited JD, 1998, JAMA-J AM MED ASSOC, V279, P696, DOI 10.1001/jama.279.9.696	47	46	46	0	1	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432			CLIN CANCER RES	Clin. Cancer Res.	MAR 15	2004	10	6					1881	1886		10.1158/1078-0432.CCR-03-0039		6	Oncology	Oncology	804ZW	WOS:000220337600003	15041702	
J	Mechanda, SM; Baum, BR; Johnson, DA; Arnason, JT				Mechanda, SM; Baum, BR; Johnson, DA; Arnason, JT			Analysis of diversity of natural populations and commercial lines of Echinacea using AFLP	CANADIAN JOURNAL OF BOTANY-REVUE CANADIENNE DE BOTANIQUE			English	Article						Echinacea; population genetic analysis; multivariate analysis; AFLP band homologies	FRAGMENT LENGTH POLYMORPHISM; BUFFALOGRASS BUCHLOE-DACTYLOIDES; GENETIC-RELATIONSHIPS; RAPD VARIATION; MARKERS; ASTERACEAE; CULTIVARS; LACTUCA; CLASSIFICATION; DISCRIMINATION	An analysis of diversity of Echinacea native to North America, using amplified fragment length polymorphism (AFLP(R)), was carried out to complement a previously undertaken taxonomic revision of Echinacea that employed multivariate morphometrics. A total of 53 940 AFLP fragments, of which 40 455 were polymorphic, were scored on 435 individual plants from 58 populations consisting of 10 individuals per population. The resulting polymorphism was sufficient to distinguish each plant. A monomorphic AFLP band and a polymorphic AFLP band that migrated a the same position, taken from samples of four species and eight varieties, were cloned, and multiple clones were sequenced. The polymorphic band at the same position across fragments was not identical, with identity as low as 23% compared with 50% identity of the monomorphic band, both of which were at the 100% threshold of sequence similarity. Thus, the AFLP banding profiles, irrespective of their sequence identity, were treated as phenotypes for population genetic, discriminant, and phylogenetic analyses. Variance components within populations and among populations within species were of equal magnitude, but the partitioned variation was slightly higher among varieties than among populations within varieties. Since no species-specific or variety-specific AFLP fingerprints were found, canonical discriminant analysis was conducted, resulting in support for four species but not for the varieties. Similar results were obtained with cluster and principal coordinate analyses, based on genetic distances. To achieve identification using AFLP fingerprints, various classificatory analyses were performed, followed by bootstrapping for validation. An example to identify an unknown plant at the species level with a minimum of 10 AFLP fragments, with greater than 82% overall correct classification, is provided. Phylogenetic analysis of all 435 individuals supported only Echinacea purpurea (L.) Moench and Echinacea laevigata (C.L. Boynton & Beadle) as separate entities, and only the three Echinacea atrorubens varieties and Echinacea pallida var. tennesseensis (Beadle) Binns, B.R. Baum Arnason.	Agr & Agri Food Canada, Ottawa, ON K1A 0C6, Canada; Univ Ottawa, Dept Biol, Ottawa, ON K1N 6N5, Canada	Baum, BR (reprint author), Agr & Agri Food Canada, Neatby Bldg,960 Carling Ave, Ottawa, ON K1A 0C6, Canada.	baumbr@agr.gc.ca					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Anderson T. W., 1984, INTRO MULTIVARIATE S, V2nd; Backeljau T, 1995, CLADISTICS, V11, P119; Badr A, 2002, CAN J BOT, V80, P962, DOI [10.1139/B02-084, 10.1139/b02-084]; Baum BR, 2001, PHYTOCHEMISTRY, V56, P543, DOI 10.1016/S0031-9422(00)00425-8; Binns SE, 2002, SYST BOT, V27, P610; BLUMENTHAL M, 1992, WHOLE FOODS      JUN, P20; Bonnema G, 2002, GENOME, V45, P217, DOI 10.1139/G01-145; Borchers AT, 2000, AM J CLIN NUTR, V72, P339; Brevoort P, 1995, HERBALGRAM, V36, P49; Breyne P, 1999, MOL GEN GENET, V261, P627; Buntjer JB, 2002, HEREDITY, V88, P46, DOI 10.1038/sj/hyd/6800007; CLARK AG, 1993, MOL BIOL EVOL, V10, P1096; COART E, 2002, THEOR APPL GENET, V1108, P1; COCHRAN WG, 1961, BIOMETRICS, V17, P10, DOI 10.2307/2527493; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Doyle J. L. ., 1987, PHYTOCHEMISTRY B, V19, P11; DROOGENBROECK BV, 2002, THEOR APPL GENET, V105, P1; El Rabey H, 2002, PLANT BIOLOGY, V4, P1; EXCOFFIER L, 1992, GENETICS, V131, P479; Foster S., 1991, ECHINACEA NATURES IM; Ganter PF, 2000, CAN J MICROBIOL, V46, P967, DOI 10.1139/cjm-46-11-967; Giannasi N, 2001, MOL ECOL, V10, P419, DOI 10.1046/j.1365-294x.2001.01220.x; GILBERT ES, 1968, J AM STAT ASSOC, V63, P1399, DOI 10.2307/2285893; Gobert V, 2002, AM J BOT, V89, P2017, DOI 10.3732/ajb.89.12.2017; Guan Shukui, 2002, Applied and Environmental Microbiology, V68, P2690, DOI 10.1128/AEM.68.6.2690-2698.2002; Hedren M, 2001, AM J BOT, V88, P1868, DOI 10.2307/3558363; Hill M, 1996, THEOR APPL GENET, V93, P1202, DOI 10.1007/BF00223451; HOBBS C, 1994, HERBALGRAM, V30, P33; Hodkinson TR, 2002, ANN BOT-LONDON, V89, P627, DOI 10.1093/aob/mcf091; HUFF DR, 1993, THEOR APPL GENET, V86, P927, DOI 10.1007/BF00211043; IPEK M, 2003, PLANT ANIMAL GENOME, V11; Jones CJ, 1997, MOL BREEDING, V3, P381, DOI 10.1023/A:1009612517139; Kapteyn J, 2002, THEOR APPL GENET, V105, P369, DOI 10.1007/s00122-002-0960-y; Kardolus JP, 1998, PLANT SYST EVOL, V210, P87, DOI 10.1007/BF00984729; Keim P, 1997, J BACTERIOL, V179, P818; KIM DH, 2003, PLANT ANIMAL GENOME, V11; Koopman WJM, 1996, ACTA BOT NEERL, V45, P211; Koopman WJM, 2000, EUPHYTICA, V116, P151, DOI 10.1023/A:1004086503349; Koopman WJM, 2001, AM J BOT, V88, P1881, DOI 10.2307/3558364; KRZANOWSKI WJ, 1975, J AM STAT ASSOC, V70, P782, DOI 10.2307/2285437; Kshirsagar A. M., 1972, MULTIVARIATE ANAL; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Lombard V, 2000, CROP SCI, V40, P1417; Mace ES, 1999, THEOR APPL GENET, V99, P626, DOI 10.1007/s001220051277; MACE ES, 1999, THEOR APPL GENET, V99, P534; MANTEL N, 1967, CANCER RES, V27, P209; MCGREGOR R L, 1968, University of Kansas Science Bulletin, V48, P113; Mechanda SM, 2004, GENOME, V47, P15, DOI 10.1139/G03-094; Mengistu LW, 2000, THEOR APPL GENET, V101, P70, DOI 10.1007/s001220051451; Miller M. P., 1997, TOOLS POPULATION GEN; Mueller UG, 1999, TRENDS ECOL EVOL, V14, P389, DOI 10.1016/S0169-5347(99)01659-6; NEI M, 1972, AM NAT, V106, P283, DOI 10.1086/282771; NEI M, 1973, P NATL ACAD SCI USA, V70, P3321, DOI 10.1073/pnas.70.12.3321; Nicholas K.B., 1997, GENEDOC TOOL EDITING; Nilsson NO, 1999, PLANT BREEDING, V118, P327, DOI 10.1046/j.1439-0523.1999.00390.x; Ogden R, 2002, MOL ECOL, V11, P437, DOI 10.1046/j.0962-1083.2001.01442.x; PEAKALL R, 1995, MOL ECOL, V4, P135, DOI 10.1111/j.1365-294X.1995.tb00203.x; Pimentel R. A., 1979, MORPHOMETRICS MULTIV; Powell W, 1996, MOL BREEDING, V2, P225, DOI 10.1007/BF00564200; Quagliaro J, 2001, J HERED, V92, P38; RAAMSDONK LWD, 2000, THEOR APPL GENET, V100, P1000; Rao C.R., 1952, ADV STAT METHODS BIO; Reamon-Buttner SM, 1999, CHROMOSOME RES, V7, P297, DOI 10.1023/A:1009231031667; ROHLF FJ, 2000, NTSYSPC NUMERICAL AX; Roldan-Ruiz I, 2001, THEOR APPL GENET, V103, P1138, DOI 10.1007/s001220100571; Sambrook J., 1988, MOL CLONING LAB MANU; SAS Institute, 2002, SAS STAT US GUID VER; SCHNEITER R, 2001, RRD MOLEC CELL BIO 1, V2, P1; Semagn K, 2000, THEOR APPL GENET, V101, P1145, DOI 10.1007/s001220051591; SNOW R, 1963, STAIN TECHNOL, V38, P9; SOKAL ROBERT R., 1958, UNIV KANSAS SCI BULL, V38, P1409; Soleimani VD, 2002, CAN J PLANT SCI, V82, P35; Steiger DL, 2002, THEOR APPL GENET, V105, P209, DOI 10.1007/s00122-002-0939-8; SWOFFORD DL, 1999, PAUP PHYLOGENETIC AN; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Tomkins JP, 2001, THEOR APPL GENET, V102, P489, DOI 10.1007/s001220051672; TYLER VE, 1993, ACS SYM SER, V534, P25; URBATSCH LE, 1995, SYST BOT, V20, P28, DOI 10.2307/2419630; Urbatsch LE, 2000, SYST BOT, V25, P539, DOI 10.2307/2666695; van den Berg RG, 2002, THEOR APPL GENET, V105, P1109, DOI 10.1007/s00122-002-1054-6; VOS P, 1995, NUCLEIC ACIDS RES, V23, P4407, DOI 10.1093/nar/23.21.4407; Wong A, 2001, GENOME, V44, P677, DOI 10.1139/gen-44-4-677; Yeh Francis C., 1997, Belgian Journal of Botany, V129, P157; ZANDE L, 1995, J EVOLUTION BIOL, V8, P645	86	10	10	2	4	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA, ONTARIO K1A 0R6, CANADA	0008-4026			CAN J BOT	Can. J. Bot.-Rev. Can. Bot.	APR	2004	82	4					461	484		10.1139/B04-006		24	Plant Sciences	Plant Sciences	829GL	WOS:000222035300006		
J	Roncaglia, A; Elmi, I; Dori, L; Rudan, M				Roncaglia, A; Elmi, I; Dori, L; Rudan, M			Adaptive K-NN for the detection of air pollutants with a sensor array	IEEE SENSORS JOURNAL			English	Article						benzene, toluene and xylene (BTX); CO; gas mixtures; K-nn classification; NO2; quantitative analysis; SnO2 sensors	ARTIFICIAL NEURAL-NETWORK; GAS SENSORS; PATTERN CLASSIFICATION; POLLUTION; SYSTEM	The field of air-quality monitoring is gaining increasing interest, with regard to both indoor environment and air-pollution control in open space. This work introduces a pattern recognition technique based on adaptive K-nn applied to a multisensor system, optimized for the recognition of some relevant tracers for air pollution in outdoor environment, namely benzene, toluene, and xylene (BTX), NO2, and CO. The pattern-recognition technique employed aims at recognizing the target gases within an air sample of unknown composition and at estimating their concentrations. It is based on PCA and K-nn classification with an adaptive vote technique based on the gas concentrations of the training samples associated to the K-neighbors. The system is tested in a controlled environment composed of synthetic air with a fixed humidity rate (30%) at concentrations in the ppm range for BTX and NO2, in the range of 10 ppm for CO. The pattern recognition technique is experimented on a knowledge base composed of a limited number of samples (130), with the adoption of a leave-one-out procedure in order to estimate the classification probability. In these conditions, the system demonstrates the capability to recognize the presence of the target gases in controlled conditions with a high hit-rate. Moreover, the concentrations of the individual components of the test samples are successfully estimated for BTX and NO2 in more than 80% of the considered cases, while a lower hit-rate (69%) is reached for CO.	Italian Natl Res Council, IMM, CNR, I-40129 Bologna, Italy; Univ Bologna, DEIS, I-40136 Bologna, Italy; ARCES, I-40136 Bologna, Italy	Roncaglia, A (reprint author), Italian Natl Res Council, IMM, CNR, I-40129 Bologna, Italy.	alberto.roncaglia@imm.cnr.it	Elmi, Ivan /O-6590-2014; Roncaglia, Alberto/N-6218-2014	Elmi, Ivan /0000-0002-0235-3358; Roncaglia, Alberto/0000-0001-9819-7603			ALVES JSG, 1999, SENSOR ACTUAT B-CHEM, V59, P69; Becker T, 2000, SENSOR ACTUAT B-CHEM, V69, P108, DOI 10.1016/S0925-4005(00)00516-5; BRASINI F, 1989, SENSOR ACTUAT B-CHEM, V69, P219; Brunet J, 2001, THIN SOLID FILMS, V391, P308, DOI 10.1016/S0040-6090(01)01001-X; COCHEO V, 1999, AIR QUALITY EUROPE C, P172; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DORI L, 1997, P EUROSENSORS 11 C W, P21; Dori L, 2000, SENSOR MATER, V12, P163; ELMI I, 2000, P 13 EUR C SOL STAT, V14; Fukunaga K., 1990, INTRO STAT PATTERN R; Hong HK, 2000, SENSOR ACTUAT B-CHEM, V66, P49, DOI 10.1016/S0925-4005(99)00460-8; HORNER G, 1990, SENSOR ACTUAT B-CHEM, V2, P173, DOI 10.1016/0925-4005(90)85002-G; KANAL L, 1971, PATTERN RECOGN, V3, P225, DOI 10.1016/0031-3203(71)90013-6; LACHENBRUCH P, 1968, TECHNOMETR, V13, P1; Lu Y, 2000, ANAL CHIM ACTA, V417, P101, DOI 10.1016/S0003-2670(00)00922-3; Martin MA, 2001, SENSOR ACTUAT B-CHEM, V77, P468, DOI 10.1016/S0925-4005(01)00736-5; Negri RM, 2001, SENSOR ACTUAT B-CHEM, V75, P172, DOI 10.1016/S0925-4005(01)00543-3; Mayer H, 1999, ATMOS ENVIRON, V33, P4029, DOI 10.1016/S1352-2310(99)00144-2; Mitrovics J, 1998, ACCOUNTS CHEM RES, V31, P307, DOI 10.1021/ar970064n; Oyabu T, 1997, SENSOR MATER, V9, P177; Platt U., 1994, AIR MONITORING SPECT, P27; RONCAGLIA A, 2001, P ISOEN WASH DC MAR, P170; ROVATTI R, 1995, NEURAL COMPUT, V7, P594, DOI 10.1162/neco.1995.7.3.594; SBERVEGLIERI G, 1992, SENSOR ACTUAT B-CHEM, V6, P239, DOI 10.1016/0925-4005(92)80062-3	24	3	4	0	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1530-437X			IEEE SENS J	IEEE Sens. J.	APR	2004	4	2					248	256		10.1109/JSEN.2004.823653		9	Engineering, Electrical & Electronic; Instruments & Instrumentation; Physics, Applied	Engineering; Instruments & Instrumentation; Physics	802IS	WOS:000220157800012		
J	Zhang, B; Srihari, SN				Zhang, B; Srihari, SN			Fast k-nearest neighbor classification using cluster-based trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest neighbor classification; nonmetrics; metrics; cluster tree	ALGORITHM; SEARCH; RECOGNITION; REPRESENTATION; RULE	Most fast k-nearest neighbor (k-NN) algorithms exploit metric properties of distance measures for reducing computation cost and a few can work effectively on both metric and nonmetric measures. We propose a cluster-based tree algorithm to accelerate k-NN classification without any presuppositions about the metric form and properties of a dissimilarity measure. A mechanism of early decision making and minimal side-operations for choosing searching paths largely contribute to the efficiency of the algorithm. The algorithm is evaluated through extensive experiments over standard NIST and MNIST databases.	Univ Calif Los Angeles, Sch Med, Dept Human Genet, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Sch Med, Dept Biostat, Los Angeles, CA 90095 USA; SUNY Buffalo, CEDAR, Dept Comp Sci & Engn, Amherst, NY 14228 USA	Zhang, B (reprint author), Univ Calif Los Angeles, Sch Med, Dept Human Genet, Los Angeles, CA 90095 USA.	binzhang@mednet.ucla.edu; srihari@cedar.buffalo.edu					BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hunttenlocher D., 1997, IEEE T PATTERN ANAL, V19, P1; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Puzicha J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790412; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TUBBS JD, 1989, PATTERN RECOGN, V22, P359, DOI 10.1016/0031-3203(89)90045-9; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; ZHANG B, 2003, P JCIS INT C COMP VI	23	51	61	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					525	528				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	801NO	WOS:000220102800009	15382657	
J	Kamp, JF; Poirier, F; Doignon, P				Kamp, JF; Poirier, F; Doignon, P			Interaction with in-vehicle electronic systems: A complete description of a neural network approach	NEURAL PROCESSING LETTERS			English	Article						dynamic vector quantization; handwritten character recognition; in-vehicle system; industrial application; k-nearest neighbour classifier; man-machine interaction; touchpad; winner takes all NN		Interaction with in-vehicle systems (car phones, traffic information, route guidance, etc) becomes a very difficult task since the control devices are often reduced to small switches and push-buttons. To solve the problem, a new input interface is proposed, based on character recognition. The paper describes in detail how a simple neural network can be applied down to the level of an industrial realization to provide a reliable user-machine interface. The industrial application is that of character recognition where characters are drawn with the finger on a small touchpad. Compared with the nearest neighbour method, the neural network solution has slightly better recognition rate, is faster and requires less memory space. The design of the recognition system is given and results of an experiment made on a driving simulator are presented.	Univ Bretagne Sud, Lab VALORIA, Ctr Rech Y Coppens, F-56000 Vannes, France; Renault, Technoctr, F-78288 Guyancourt, France	Kamp, JF (reprint author), Univ Bretagne Sud, Lab VALORIA, Ctr Rech Y Coppens, Campus Tohann, F-56000 Vannes, France.	jean-francois.kamp@univ-ubs.fr; franck.poirier@univ-ubs.fr; philippe.doignon@renault.fr					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; GARCIASALICETTI S, 1996, ACT 4 C NAT ECR DOC, P15; Greenstein J. S., 1988, HDB HUMAN COMPUTER I; GUYON I, 1991, PATTERN RECOGN, V24, P105, DOI 10.1016/0031-3203(91)90081-F; Harel D., 1987, SCI COMPUTER PROGRAM, V8; Holmstrom L, 1997, IEEE T NEURAL NETWOR, V8, P5, DOI 10.1109/72.554187; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1990, P INT JOINT C NEUR N, P545; Kohonen T., 1988, NEURAL NETWORKS, V1, P303; Paelke G. M., 1993, Proceedings of the Human Factors and Ergonomics Society 37th Annual Meeting. Designing for Diversity; POIRIER F, 1991, P 2 EUR C SPEECH COM, V2, P1003; POIRIER F, 1991, ARTIFICIAL NEURAL NE, V2, P1333; TADJ C, 1993, P 3 EUR C SPEECH COM, V2, P1009; WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7; YAMAMOTO T, 1999, P 6 ANN WORLD C INT	17	0	0	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621			NEURAL PROCESS LETT	Neural Process. Lett.	APR	2004	19	2					109	129		10.1023/B:NEPL.0000023422.16224.cf		21	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	811HM	WOS:000220763000002		
J	Huang, CC; Lee, HM				Huang, CC; Lee, HM			A grey-based nearest neighbor approach for missing attribute value prediction	APPLIED INTELLIGENCE			English	Article						missing attribute values; grey-based nearest neighbor approach; grey relational analysis; the nearest neighbor concept	CLASSIFICATION; ALGORITHM	This paper proposes a grey-based nearest neighbor approach to predict accurately missing attribute values. First, grey relational analysis is employed to determine the nearest neighbors of an instance with missing attribute values. Accordingly, the known attribute values derived from these nearest neighbors are used to infer those missing values. Two datasets were used to demonstrate the performance of the proposed method. Experimental results show that our method outperforms both multiple imputation and mean substitution. Moreover, the proposed method was evaluated using five classification problems with incomplete data. Experimental results indicate that the accuracy of classification is maintained or even increased when the proposed method is applied for missing attribute value prediction.	Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan; Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Huang, CC (reprint author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bertino E, 1998, MULTIMEDIA SYST, V6, P2, DOI 10.1007/s005300050072; Blake C, 1998, UCI REPOSITORY MACHI; Buntine W. L., 1991, Complex Systems, V5; Cestnik B., 1987, PROGR MACHINE LEARNI, P31; Cleary John G., 1995, P 12 INT C MACH LEAR, P108; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Deng Julong, 1989, Journal of Grey Systems, V1; Deng J., 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; DIXON JK, 1979, IEEE T SYST MAN CYB, V9, P617, DOI 10.1109/TSMC.1979.4310090; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, 2149004 USAF SCH AV; Freund Y., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279985; Freund Y., 1999, P 16 INT C MACH LEAR, P124; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Huang C.C., 2002, P UK WORKSH COMP INT; John G.H., 1995, P 11 C UNC ART INT, P338; King G, 2001, AM POLIT SCI REV, V95, P49; KOHAVI R, 1995, EUR C MACH LEARN; LIN CT, 1999, J GREY SYSTEM, V4, P359; MICHALSKI RS, 1980, INT J POLICY ANAL IN, V4; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J .R., 1989, P 6 INT WORKSH MACH, P164; REICH Y, 1990, P 1 INT WORKSH FORM, P330; Rubin D. B., 1987, MULTIPLE IMPUTATION; SALZBERG S, 1988, TR1088 HARV U CTR RE; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE M, 1974, J R STAT SOC B, V36, P111; Watson C. J., 1993, STAT MANAGEMENT EC; Witten I.H., 2000, DATA MINING PRACTICA; WU JH, 1999, J GREY SYST, V3, P287	35	14	19	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X			APPL INTELL	Appl. Intell.	MAY-JUN	2004	20	3					239	252		10.1023/B:APIN.0000021416.41043.0f		14	Computer Science, Artificial Intelligence	Computer Science	806CG	WOS:000220411400004		
J	Wyns, B; Sette, S; Boullart, L; Baeten, D; Hoffman, IEA; De Keyser, F				Wyns, B; Sette, S; Boullart, L; Baeten, D; Hoffman, IEA; De Keyser, F			Prediction of diagnosis in patients with early arthritis using a combined Kohonen mapping and instance-based evaluation criterion	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						Kohonen neural networks; case-based reasoning; prediction system; decision support systems; chronic autoimmune arthritis	SELF-ORGANIZING MAP; RHEUMATOID-ARTHRITIS; CLASSIFICATION; SPONDYLOARTHROPATHY; SYNOVIUM	Rheumatoid arthritis (RA) and spondyloarthropathy (SpA) are the two most frequent forms of chronic autoimmune arthritis. These diseases lead to important inflammatory symptoms resulting in an important functional impairment. This paper introduces a self-organizing artificial neural network combined with a case-based reasoning evaluation criterion to predict diagnosis in patients with early arthritis. Results show that 47.2% of the sample space can be predicted with an accuracy of 84.0% and attaining a high confidence level. 37.7% of the sample space is classified with an overall accuracy of 65.0%. The remaining group was labeled as "undetermined". A general prediction accuracy of 75.6% is reached, exceeding the performance of other approaches such as a backpropagation neural network and the Quest decision tree program. Furthermore, by using this new method, more specifically case-based reasoning, as a helpful tool to classify patients with early arthritis, the possibility of a confidence measure is given, indicating a degree of "belief" of the system in its results. This is often an important feature when dealing with diagnosis in human patients. (C) 2004 Elsevier B.V. All rights reserved.	Ghent Univ, Fac Sci Appl, Dept Elect Energy Syst & Automat, B-9000 Ghent, Belgium; Ghent Univ, Fac Sci Appl, Dept Text, B-9000 Ghent, Belgium; Ghent Univ Hosp, Fac Med, Dept Rheumatol, B-9000 Ghent, Belgium	Wyns, B (reprint author), Ghent Univ, Fac Sci Appl, Dept Elect Energy Syst & Automat, Technol Pk 913, B-9000 Ghent, Belgium.	bart.wyns@ugent.be					Anderson J.A., 1989, NEUROCOMPUTING FDN R; Arnett FC, 1988, ARTHRITIS RHEUM, V31, P315; Baeten D, 2000, ARTHRITIS RHEUM, V43, P1233, DOI 10.1002/1529-0131(200006)43:6<1233::AID-ANR6>3.0.CO;2-9; Baeten D, 1999, CLIN RHEUMATOL, V18, P434, DOI 10.1007/s100670050134; BAETEN D, 2002, CLIN RHEUMATOL, V21, P447; Baeten D, 2000, ANN RHEUM DIS, V59, P945, DOI 10.1136/ard.59.12.945; Baeten D, 2002, J PATHOL, V196, P343, DOI 10.1002/path.1044; Baeten D, 2001, ARTHRITIS RHEUM, V44, P2255, DOI 10.1002/1529-0131(200110)44:10<2255::AID-ART388>3.0.CO;2-#; BOULLAR L, 2003, P IFAC INT C INT CON, P55; Chen DR, 2000, ULTRASOUND MED BIOL, V26, P405, DOI 10.1016/S0301-5629(99)00156-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOUGADOS M, 1991, ARTHRITIS RHEUM, V34, P1218, DOI 10.1002/art.1780341003; HECTHNIELSEN R, 1989, NEUROCOMPUTING; Henson S, 1999, FOOD CONTROL, V10, P99, DOI 10.1016/S0956-7135(98)00162-5; HOKELA T, 1999, SPECIAL ISSUE IJCAI; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; Leake D. B., 1996, CASE BASED REASONING; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; Loh WY, 1997, STAT SINICA, V7, P815; MANICKAM S, 2000, IEEE TENCON 2000, P24; Markey MK, 2003, ARTIF INTELL MED, V27, P113, DOI 10.1016/S0933-3657(03)00003-4; Mitchell T. M., 1997, MACHINE LEARNING; OTTE G, 1990, MUSCLE NERVE, V10, P982; Patterson D., 1996, ARTIFICIAL NEURAL NE; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SETTE S, 1995, TEXT RES J, V65, P196, DOI 10.1177/004051759506500402; SIEBEN G, 1994, ACTA NEUROCHIR, V129, P193, DOI 10.1007/BF01406504; VANDENBOSCH F, 2001, J RHEUMATOL, V28, P2	28	11	11	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	MAY	2004	31	1					45	55		10.1016/j.artmed.2004.01.002		11	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	832GS	WOS:000222256000003	15182846	
J	Cai, YD; Chou, KC				Cai, YD; Chou, KC			Predicting subcellular localization of proteins in a hybridization space	BIOINFORMATICS			English	Article							AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; LOCATION PREDICTION; SORTING SIGNALS; SEQUENCE; RESOURCE; SITES	Motivation: The localization of a protein in a cell is closely correlated with its biological function. With the number of sequences entering into databanks rapidly increasing, the importance of developing a powerful high-throughput tool to determine protein subcellular location has become self-evident. In view of this, the Nearest Neighbour Algorithm was developed for predicting the protein subcellular location using the strategy of hybridizing the information derived from the recent development in gene ontology with that from the functional domain composition as well as the pseudo amino acid composition. Results: As a showcase, the same plant and non-plant protein datasets as investigated by the previous investigators were used for demonstration. The overall success rate of the jackknife test for the plant protein dataset was 86%, and that for the non-plant protein dataset 91.2%. These are the highest success rates achieved so far for the two datasets by following a rigorous cross-validation test procedure, suggesting that such a hybrid approach (particularly by incorporating the knowledge of gene ontology) may become a very useful high-throughput tool in the area of bioinformatics, proteomics, as well as molecular cell biology.	UMIST, Biomol Sci Dept, Manchester M60 1QD, Lancs, England; Gordon Life Sci Inst, San Diego, CA 92130 USA; TRIBD, Tianjin, Peoples R China	Cai, YD (reprint author), UMIST, Biomol Sci Dept, POB 88, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; BLOBEL G, 1976, BIOCHEM BIOPH RES CO, V68, P1, DOI 10.1016/0006-291X(76)90001-2; Cai Yu-Dong, 2000, Molecular Cell Biology Research Communications, V4, P172, DOI 10.1006/mcbr.2001.0269; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou JJ, 1998, CELL, V94, P171, DOI 10.1016/S0092-8674(00)81417-8; Chou JJ, 1999, CELL, V96, P615, DOI 10.1016/S0092-8674(00)80572-3; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Claros MG, 1997, CURR OPIN STRUC BIOL, V7, P394, DOI 10.1016/S0959-440X(97)80057-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng ZP, 2001, INT J BIOL MACROMOL, V28, P255, DOI 10.1016/S0141-8130(01)00121-0; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Letunic I, 2002, NUCLEIC ACIDS RES, V30, P242, DOI 10.1093/nar/30.1.242; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Vlahovicek K, 2002, NUCLEIC ACIDS RES, V30, P273, DOI 10.1093/nar/30.1.273; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	37	58	62	0	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	MAY 1	2004	20	7					1151	1156		10.1093/bioinformatics/bth054		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	816WJ	WOS:000221139700018	14764553	
J	Lee, C; Lee, J; Lee, C				Lee, C; Lee, J; Lee, C			Korean adult male voxel model KORMAN segmented from magnetic resonance images	MEDICAL PHYSICS			English	Article						voxel; human model; construction; dosimetry; magnetic resonance	MONTE-CARLO CALCULATIONS; PHANTOM; SYSTEM	A voxel model of Korean adult male, KORMAN, was developed by processing whole-body magnetic resonance (MR) images of a healthy volunteer who represents an approximately average Korean in height and weight. Layer by layer the MR images were semi-automatically segmented and indexed using a graphic software and digitizer to construct data arrays consisting of 250 X 120 X 170 voxels of a size of 2 X 2 X 10 mm(3). To assess the utility of the model, some illustrative dosimetric calculations were made to obtain organ absorbed doses and effective doses to the KORMAN placed in broad parallel photon fields with energies ranging from 0.05 to 10 MeV. The results were compared with those based on the medical internal radiation dose (MIRD)-type models given in ICRP74. The effective doses of ICRP74 were higher than those of KORMAN with percent differences ranging from 6% (LLAT, 10 MeV) to 30% (PA, 0.05 MeV). Significant differences of more than 40% were observed in organ absorbed doses for some organs including bone surface (AP), stomach (PA), and testes (LAT) for low photon energy. These are mainly caused by difference in trunk thickness between MIRD-type model and KORMAN, and differences in organ positions in the body. (C) 2004 American Association of Physicists in Medicine.	Hanyang Univ, Innovat Technol Ctr Radiat Safety, Seoul 133791, South Korea; Univ Florida, Dept Radiol & Nucl Med, Gainesville, FL 32611 USA	Lee, C (reprint author), Hanyang Univ, Innovat Technol Ctr Radiat Safety, HIT Bldg,17 Haengdang, Seoul 133791, South Korea.	cslee@itrs.hanyang.ac.kr; cslee@itrs.hanyang.ac.kr					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristy M., 1980, ORNLNUREGTM367; Cristy M, 1987, ORNLTM8381VI; Dimbylow PJ, 1995, P INT WORKSH VOX PHA, P1; GIBBS SJ, 1984, ORAL SURG ORAL MED O, V58, P347, DOI 10.1016/0030-4220(84)90066-5; HWANG JML, 1975, ORNL5046; ICRP, 2003, ICRP PUBL, V89; ICRP, 1975, ICRP PUBL, V23; ICRP, 1996, ICRP PUBL, V74, P3; ICRP, 1991, ICRP PUBL, V60; ICRU, 1984, 44 ICRU; International Commission on Radiological Protection (ICRP), 1993, ICRP PUBL, V67; Kramer R, 1982, S885 GSF; Kramer R, 2003, PHYS MED BIOL, V48, P1239, DOI 10.1088/0031-9155/48/10/301; LAURIE SW, 2002, LACP02408 LOS AL NAT; LEE J, 2002, P 1 AS OC C RAD PROT, P122; LIGIER Y, 1994, M D COMPUT, V11, P212; Nipper JC, 2002, PHYS MED BIOL, V47, P3143, DOI 10.1088/0031-9155/47/17/307; Saito K, 2001, RADIAT ENVIRON BIOPH, V40, P69, DOI 10.1007/s004110000082; SNYDER WS, 1969, J NUCL MED, V10; TANAKA G-I, 1989, Nippon Acta Radiologica, V49, P344; WILLIAMS G, 1986, PHYS MED BIOL, V31, P449, DOI 10.1088/0031-9155/31/4/010; Xu XG, 2000, HEALTH PHYS, V78, P476, DOI 10.1097/00004032-200005000-00003; Yoriyaz H, 2000, MED PHYS, V27, P1555, DOI 10.1118/1.599021; ZANKL M, 1995, RADIAT PROT DOSIM, V57, P393; Zankl M, 2001, RADIAT ENVIRON BIOPH, V40, P153, DOI 10.1007/s004110100094; Zankl M, 2002, PHYS MED BIOL, V47, P2367, DOI 10.1088/0031-9155/47/14/301; ZANKL M, 1988, RADIAT ENVIRON BIOPH, V27, P154; ZUBAL IG, 1994, MED PHYS, V21, P299	29	24	26	0	2	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405			MED PHYS	Med. Phys.	MAY	2004	31	5					1017	1022		10.1118/1.1689013		6	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	821EX	WOS:000221444300010	15191287	
J	Cai, YD; Doig, AJ				Cai, YD; Doig, AJ			Prediction of Saccharomyces cerevisiae protein functional class from functional domain composition	BIOINFORMATICS			English	Article							MULTIPLE SEQUENCE ALIGNMENT; YEAST GENOME; DATABASE; FAMILIES; CLASSIFICATION; IDENTIFICATION; ALGORITHM; PATTERNS; RESOURCE; FEATURES	Motivation: A key goal of genomics is to assign function to genes, especially for orphan sequences. Results: We compared the clustered functional domains in the SBASE database to each protein sequence using BLASTP. This representation for a protein is a vector, where each of the non-zero entries in the vector indicates a significant match between the sequence of interest and the SBASE domain. The machine learning methods nearest neighbour algorithm (NNA) and support vector machines are used for predicting protein functional classes from this information. We find that the best results are found using the SBASE-A database and the NNA, namely 72% accuracy for 79% coverage. We tested an assigning function based on searching for InterPro sequence motifs and by taking the most significant BLAST match within the dataset. We applied the functional domain composition method to predict the functional class of 2018 currently unclassified yeast open reading frames.	UMIST, Dept Biomol Sci, Manchester M60 1QD, Lancs, England	Doig, AJ (reprint author), UMIST, Dept Biomol Sci, POB 88, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk; Andrew.Doig@umist.ac.uk		Doig, Andrew/0000-0003-0346-2270			Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 2000, BIOINFORMATICS, V16, P1145, DOI 10.1093/bioinformatics/16.12.1145; Attwood TK, 2000, NUCLEIC ACIDS RES, V28, P225, DOI 10.1093/nar/28.1.225; Bachinsky AG, 2000, BIOINFORMATICS, V16, P358, DOI 10.1093/bioinformatics/16.4.358; Bateman A, 2000, NUCLEIC ACIDS RES, V28, P263, DOI 10.1093/nar/28.1.263; BURBIDGE R, 2000, P AISB 00 S ART INT, P1; Corpet F, 1999, NUCLEIC ACIDS RES, V27, P263, DOI 10.1093/nar/27.1.263; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dandekar T, 1998, TRENDS BIOCHEM SCI, V23, P324, DOI 10.1016/S0968-0004(98)01274-2; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Dujon B, 1998, ELECTROPHORESIS, V19, P617, DOI 10.1002/elps.1150190427; Eisenberg D, 2000, NATURE, V405, P823, DOI 10.1038/35015694; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Goffeau A, 1996, SCIENCE, V274, P563; Goffeau A, 1996, SCIENCE, V274, P546, DOI 10.1126/science.274.5287.546; Gracy J, 1998, BIOINFORMATICS, V14, P164, DOI 10.1093/bioinformatics/14.2.164; Hegyi H, 1999, J MOL BIOL, V288, P147, DOI 10.1006/jmbi.1999.2661; Henikoff S, 1999, BIOINFORMATICS, V15, P471, DOI 10.1093/bioinformatics/15.6.471; Hofmann K, 1999, NUCLEIC ACIDS RES, V27, P215, DOI 10.1093/nar/27.1.215; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; JOACHIMS T, 1999, INT C MACH LEARN ICM, P700; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kasuya A, 1999, J MOL BIOL, V286, P1673, DOI 10.1006/jmbi.1999.2581; King RD, 2000, YEAST, V17, P283, DOI 10.1002/1097-0061(200012)17:4<283::AID-YEA52>3.0.CO;2-F; King RD, 2001, BIOINFORMATICS, V17, P445, DOI 10.1093/bioinformatics/17.5.445; Marcotte EM, 2000, CURR OPIN STRUC BIOL, V10, P359, DOI 10.1016/S0959-440X(00)00097-X; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Marcotte EM, 1999, NATURE, V402, P83; Mewes HW, 1997, NATURE, V387, P7; Mewes HW, 1999, NUCLEIC ACIDS RES, V27, P44, DOI 10.1093/nar/27.1.44; MORRISON R, 2003, UNPUB; Mulder NJ, 2003, NUCLEIC ACIDS RES, V31, P315, DOI 10.1093/nar/gkg046; Nevill-Manning CG, 1998, P NATL ACAD SCI USA, V95, P5865, DOI 10.1073/pnas.95.11.5865; OLIVER SG, 1997, GENOME DIGEST, V4, P4; Overbeek R, 1999, P NATL ACAD SCI USA, V96, P2896, DOI 10.1073/pnas.96.6.2896; Pearson WR, 1996, METHOD ENZYMOL, V266, P227; Pellegrini M, 2001, CURR OPIN CHEM BIOL, V5, P46, DOI 10.1016/S1367-5931(00)00165-4; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Perez AJ, 2002, COMP FUNCT GENOM, V3, P423, DOI 10.1002/cfg.208; Ponting CP, 1999, NUCLEIC ACIDS RES, V27, P229, DOI 10.1093/nar/27.1.229; Skolnick J, 2000, TRENDS BIOTECHNOL, V18, P34, DOI 10.1016/S0167-7799(99)01398-0; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; Vlahovicek K, 2002, NUCLEIC ACIDS RES, V30, P273, DOI 10.1093/nar/30.1.273; Zagulski M, 1998, ACTA BIOCHIM POL, V45, P627	48	32	35	1	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	MAY 22	2004	20	8					1292	1300		10.1093/bioinformatics/bth085		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	822QY	WOS:000221556100011	14976029	
J	Levendovszky, J; Fancsali, A				Levendovszky, J; Fancsali, A			Real-time call admission control for packet-switched networking by cellular neural networks	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS			English	Article						call admission control (CAC); cellular neural network (CNN); set separation	CNN; UNIVERSAL; MACHINE	In this paper, novel call admission control (CAC) algorithms are developed based on cellular neural networks. These algorithms can achieve high network utilization by performing CAC in real-time, which is imperative in supporting quality of service (QoS) communication over packet-switched networks. The proposed solutions are of basic significance in access technology where a subscriber population (connected to the Internet via an access module) needs to receive services. In this case, QoS can only be preserved by admitting those user configurations which will not overload the access module. The paper treats CAC as a set separation problem where the separation surface is approximated based on a training set. This casts CAC as an image processing task in which a complex admission pattern is to be recognized from a couple of initial points belonging to the training set. Since CNNs can implement any propagation models to explore complex patterns, CAC can then be carried out by a CNN. The major challenge is to find the proper template matrix which yields high network utilization. On the other hand, the proposed method is also capable of handling three-dimensional separation surfaces, as in a typical access scenario there are three traffic classes (e.g., two type of Internet access and one voice over asymmetric digital subscriber line.	Budapest Univ Technol & Econ, Dept Telecommun, H-1117 Budapest, Hungary	Levendovszky, J (reprint author), Budapest Univ Technol & Econ, Dept Telecommun, H-1117 Budapest, Hungary.	levendov@hit.bme.hu	Levendovszky, Janos/F-5062-2013; 	Levendovszky, Janos/0000-0003-1406-442X			BAKAMDIS SG, 1993, P IEEE INT C AC SPEE, V5, P658; CHUA LO, 1993, IEEE T CIRCUITS-I, V40, P289, DOI 10.1109/81.224308; CHUA LO, 1993, IEEE T CIRCUITS-I, V40, P147, DOI 10.1109/81.222795; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FANCSALI A, 2001, P POL CZECH HUNG WOR; Fantacci R, 1999, IEEE T CIRCUITS-I, V46, P1457, DOI 10.1109/81.809547; HIRAMATSU A, 1994, NEURAL NETWORKS TELE; HUI JY, 1988, IEEE J SEL AREA COMM, V6, P1598, DOI 10.1109/49.12887; LEVENDOVSZKY J, 1995, C579 COPERNICUS; LEVENDOVSZKY J, 1995, J COMMUN DED ATM NET, V47, P19; LEVENDOVSZKY J, 1999, P 2 INT C ATM JUN 21, P195; Linan G, 1999, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON MICROELECTRONICS FOR NEURAL, FUZZY AND BIO-INSPIRED SYSTEMS, MICORNEURO'99, P61, DOI 10.1109/MN.1999.758847; Petras I, 2000, PROCEEDINGS OF THE 2000 6TH IEEE INTERNATIONAL WORKSHOP ON CELLULAR NEURAL NETWORKS AND THEIR APPLICATIONS (CNNA 2000), P3, DOI 10.1109/CNNA.2000.876810; Rekeczky C, 1999, J VLSI SIG PROCESS S, V23, P373, DOI 10.1023/A:1008153320440; ROSKA T, 1993, IEEE T CIRCUITS-II, V40, P163, DOI 10.1109/82.222815; WISMER DA, 1978, SYSTEM SCI ENG	16	3	3	0	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1057-7122			IEEE T CIRCUITS-I	IEEE Trans. Circuits Syst. I-Regul. Pap.	JUN	2004	51	6					1172	1183		10.1109/TCSI.2004.826207		12	Engineering, Electrical & Electronic	Engineering	828YY	WOS:000222010900013		
J	Zheng, WM; Zhao, L; Zou, CR				Zheng, WM; Zhao, L; Zou, CR			Locally nearest neighbor classifiers for pattern classification	PATTERN RECOGNITION			English	Article						pattern classification; nearest feature line; nearest neighbor line	FACE RECOGNITION	In this paper, two novel classifiers based on locally nearest neighborhood rule, called nearest neighbor line and nearest neighbor plane, are presented for pattern classification. Comparison to nearest feature line and nearest feature plane, the proposed methods take much lower computation cost and achieve competitive performance. (C) 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Southeast Univ, Dept Radio Engn, Engn Res Ctr Informat Proc & Applicat, Nanjing 210096, Jiangsu, Peoples R China	Zheng, WM (reprint author), Southeast Univ, Dept Radio Engn, Engn Res Ctr Informat Proc & Applicat, Nanjing 210096, Jiangsu, Peoples R China.	wenming_zheng@seu.edu.cn					Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323	4	63	65	0	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	JUN	2004	37	6					1307	1309		10.1016/j.patcog.2003.11.004		3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	822PW	WOS:000221553100018		
J	Yin, TK; Chiu, NT				Yin, TK; Chiu, NT			A computer-aided diagnosis for distinguishing Tourette's syndrome from chronic tic disorder in children by a fuzzy system with a two-step minimization approach	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						AI approaches; biosignal interpretation and diagnostic systems; fuzzy systems; signal and image processing	PERFUSION; TECHNETIUM-99M-HMPAO; CHILDHOOD; SPECT	Tourette's syndrome, no longer considered as a rare and unusual disease, is the most severe tic disorder in children. Early differential diagnosis between Tourette's syndrome and chronic tic disorder is difficult but important because proper and early medical therapy can improve the child's condition. Brain single-photon emission computed tomography (SPECT) perfusion imaging with technetium-99m hexamethylpropylene amine oxime is a method to distinguish these two diseases. In this paper, a fuzzy system called characteristic-point-based fuzzy inference system (CPFIS) is proposed to help radiologists perform computer-aided diagnosis (CAD). The CPFIS consists of SPECT-volume processing, input-variables selection, characteristic-points (CPs) derivation, and parameter tuning of the fuzzy system. Experimental results showed that the major fuzzy rules from the obtained CPs match the major patterns of Tourette's syndrome and chronic tic disorder in perfusion imaging. If any case that was diagnosed as chronic tic by the radiologist but as Tourette's syndrome by the CPFIS was taken as Tourette's syndrome, then the accuracy of the radiologist was increased from 87.5% (21 of 24) without the CPFIS to 91.7% (22 of 24) With the CPFIS. All 17 cases of Tourette's syndrome, which is more severe than chronic tic disorder, were correctly classified. Although the construction and application process of the proposed method is complete, more samples should be used and tested in order to design a universally effective CAD without small sample-size concerns in this research.	Chia Nan Univ Pharm & Sci, Dept Management Informat Sci, Tainan, Taiwan; Natl Cheng Kung Univ, Coll Med, Dept Nucl Med, Tainan, Taiwan	Yin, TK (reprint author), Chia Nan Univ Pharm & Sci, Dept Management Informat Sci, Tainan, Taiwan.	qtkyin@mail.chna.edu.tw					Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; Chiu NT, 2001, EUR J NUCL MED, V28, P183, DOI 10.1007/s002590000402; CLEMENTZ GL, 1988, AM FAM PHYSICIAN, V38, P163; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EAPEN V, 1994, BRIT J PSYCHIAT, V164, P708; Fukunaga K., 1990, INTRO STAT PATTERN R; Gordon I, 1996, NUCL MED COMMUN, V17, P1021, DOI 10.1097/00006231-199612000-00004; Haykin S., 1994, NEURAL NETWORKS COMP; Klieger PS, 1997, J NUCL MED, V38, P188; Kompoliti K, 1998, MOVEMENT DISORD, V13, P477, DOI 10.1002/mds.870130317; LACEY DJ, 1986, CLIN PEDIATR, V25, P433, DOI 10.1177/000992288602500901; Lampreave JL, 1998, J NUCL MED, V39, P624; Lin FJ, 2001, ZOOL STUD, V40, P199; Luenberger D. G., 1989, LINEAR NONLINEAR PRO; METZ CE, 1986, INVEST RADIOL, V21, P720; MORIARTY J, 1995, BRIT J PSYCHIAT, V167, P249, DOI 10.1192/bjp.167.2.249; Moriarty J, 1997, PSYCHOL MED, V27, P737, DOI 10.1017/S0033291796004072; Penedo MG, 1998, IEEE T MED IMAGING, V17, P872, DOI 10.1109/42.746620; PHILLIPS DS, 1978, BASIC STAT HLTH SCI; SIEG KG, 1993, CLIN NUCL MED, V18, P255, DOI 10.1097/00003072-199303000-00022; Tailairach J, 1988, COPLANAR STEREOTAXIC; YIN TK, 2001, P 6 C ART INT APPL K, P652; Yu SY, 2000, IEEE T MED IMAGING, V19, P115	23	7	8	0	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294			IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	JUL	2004	51	7					1286	1295		10.1109/TBME.2004.827954		10	Engineering, Biomedical	Engineering	830ON	WOS:000222132200024	15248548	
J	Martinoia, S; Massobrio, P; Bove, M; Massobrio, G				Martinoia, S; Massobrio, P; Bove, M; Massobrio, G			Effect of skull resistivity on the spatial resolutions of EEG and MEG (vol 51, pg 859, 2004)	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Correction							LA-TOURETTES-SYNDROME; PERFUSION; TECHNETIUM-99M-HMPAO; DIAGNOSIS; DISORDERS; CHILDHOOD; SYSTEM; SPECT		Univ Genoa, Dept Biophys & Elect Engn, Neuroengn & Bionanotechnol Grp, I-16145 Genoa, Italy; Univ Genoa, Sect Human Physiol, Dept Expt Med, Genoa, Italy	Martinoia, S (reprint author), Univ Genoa, Dept Biophys & Elect Engn, Neuroengn & Bionanotechnol Grp, Via Opera Pia 11A, I-16145 Genoa, Italy.	giaser@dibe.unige.it; Paolo.Massobrio@ingegneria.studenti.unige.it; bove@dibe.unige.it; biofet@dibe.unige.it	Martinoia, Sergio/H-1863-2011				Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; Chiu NT, 2001, EUR J NUCL MED, V28, P183, DOI 10.1007/s002590000402; CLEMENTZ GL, 1988, AM FAM PHYSICIAN, V38, P163; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EAPEN V, 1994, BRIT J PSYCHIAT, V164, P708; Fukunaga K., 1990, INTRO STAT PATTERN R; Gordon I, 1996, NUCL MED COMMUN, V17, P1021, DOI 10.1097/00006231-199612000-00004; Haykin S., 1994, NEURAL NETWORKS COMP; Klieger PS, 1997, J NUCL MED, V38, P188; Kompoliti K, 1998, MOVEMENT DISORD, V13, P477, DOI 10.1002/mds.870130317; LACEY DJ, 1986, CLIN PEDIATR, V25, P433, DOI 10.1177/000992288602500901; Lampreave JL, 1998, J NUCL MED, V39, P624; LIN CT, 1991, IEEE T COMPUT, V40, P1320, DOI 10.1109/12.106218; Luenberger D. G., 1989, LINEAR NONLINEAR PRO; Martinoia S, 2004, IEEE T BIO-MED ENG, V51, P859, DOI 10.1109/TBME.2004.826607; METZ CE, 1986, INVEST RADIOL, V21, P720; MORIARTY J, 1995, BRIT J PSYCHIAT, V167, P249, DOI 10.1192/bjp.167.2.249; Moriarty J, 1997, PSYCHOL MED, V27, P737, DOI 10.1017/S0033291796004072; Penedo MG, 1998, IEEE T MED IMAGING, V17, P872, DOI 10.1109/42.746620; PHILLIPS DS, 1978, BASIC STAT HLTH SCI; SIEG KG, 1993, CLIN NUCL MED, V18, P255, DOI 10.1097/00003072-199303000-00022; Tailairach J, 1988, COPLANAR STEREOTAXIC; YIN TK, 2001, P 6 C ART INT APPL K, P652; Yu SY, 2000, IEEE T MED IMAGING, V19, P115	24	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294			IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	JUL	2004	51	7					1295	1295		10.1109/TBME.2004.832417		1	Engineering, Biomedical	Engineering	830ON	WOS:000222132200025		
J	Pan, F; Wang, BY; Hu, X; Perrizo, W				Pan, F; Wang, BY; Hu, X; Perrizo, W			Comprehensive vertical sample-based KNN/LSVM classification for gene expression analysis	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						data mining; k-nearest neighbor; support vector machine; feature selection; P-tree; gene expression; machine learning	CONSISTENCY; PREDICTION; ALGORITHMS; CANCER	Classification analysis of microarray gene expression data has been widely used to uncover biological features and to distinguish closely related cell types that often appear in the diagnosis of cancer. However, the number of dimensions of gene expression data is often very high, e.g., in the hundreds or thousands. Accurate and efficient classification of such high-dimensional data remains a contemporary challenge. In this paper, we propose a comprehensive vertical sample-based KNN/LSVM classification approach with weights optimized by genetic algorithms for high-dimensional data. Experiments on common gene expression datasets demonstrated that our approach can achieve high accuracy and efficiency at the same time. The improvement of speed is mainly related to the vertical data representation, P-tree,(1) and its optimized logical algebra. The high accuracy is due to the combination of a KNN majority voting approach and a local support vector machine approach that makes optimal decisions at the local level. As a result, our approach could be a powerful tool for high-dimensional gene expression data analysis. (C) 2004 Elsevier Inc. All rights reserved.	N Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA; Rockefeller Univ, Lab Struct Microbiol, New York, NY 10021 USA	Pan, F (reprint author), N Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA.	fei.pan@ndsu.nodak.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Cover T. M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; DING Q, 2002, ACM S APPL COMPUT, P11; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EISEN MB, 1995, P NATL ACAD SCI USA, P14863; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Goldberg D.E., 1991, FDN GENETIC ALGORITH, V1, P69; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; MANGASARIAN OL, 1999, 9903 U WISC COMP SCI; Mitchell T. M., 1997, MACHINE LEARNING; MOORE DS, 1977, ANN STAT, V5, P143, DOI 10.1214/aos/1176343747; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; PERERA A, 2003, SIGKDD EXPLOR, V4, P108; PERRIZO W, 2001, NDSUCSORTR011; Vapnik V. N., 1995, NATURE STAT LEARNING; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15	22	15	15	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	AUG	2004	37	4					240	248		10.1016/j.jbi.2004.07.003		9	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	863VZ	WOS:000224592800003	15465477	
J	Li, JY; Ong, HL				Li, JY; Ong, HL			Feature space transformation for better understanding biological and medical classifications	JOURNAL OF RESEARCH AND PRACTICE IN INFORMATION TECHNOLOGY			English	Article							ACUTE LYMPHOBLASTIC-LEUKEMIA; GENE-EXPRESSION PROFILES; PATTERNS; CANCER	Recently published gene expression profiles and proteomic mass/charge ratios are extremely high-dimensional data. Though support vector machines can well learn the inner relationship of the data for classification, the non-linear kernel functions pose an obstacle to explain the prediction reasons to non-specialists. In this paper, we study the problem of feature space transformation for easy interpretability of classification results. Each new feature is a combination of multiple original features provided that the new feature captures a large percentage of one class of data, but sharply discriminates the data in the other class. Under the description of new features, training or test data are clearly class-separable. We also discuss a more sophisticated rule-based method, called PCL, for classification. PCL provides easily explainable classification scores for us to better understand the predictions and the test data themselves. Visualization is also used to enhance the understanding of the classifier output. We use rich examples to demonstrate our main points.	Inst Infocomm Res, Singapore 119613, Singapore	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@i2r.a-star.edu.sg; hweeleng@i2r.a-star.edu.sg					Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG G, 1999, P 5 ACM SIGKDD INT C, P3; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Li J, 2002, SER INF MANAGE SCI, V1, P325; Li J., 2000, P 17 INT C MACH LEAR, P551; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	12	0	0	0	0	AUSTRALIAN COMPUTER SOC INC	SYDNEY	PO BOX Q534, QVB POST OFFICE, SYDNEY, NSW 1230, AUSTRALIA	1443-458X			J RES PRACT INF TECH	J. Res. Pract. Inf. Technol.	AUG	2004	36	3					131	144				14	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	849UB	WOS:000223565300002		
J	Mountrakis, G; Stefanidis, A; Schlaisich, I; Agouris, P				Mountrakis, G; Stefanidis, A; Schlaisich, I; Agouris, P			Supporting quality-based image retrieval through user preference learning	PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING			English	Article							UNCERTAINTY; SIMILARITY; ALGORITHM; ERROR	It is common for modem geospotial libraries to contain multiple datasets that cover the same area but differ only in some specific quality attributes (e.g., resolution and precision). This is affecting the concept of content-based geospatial queries, as simple coverage-based query mechanisms (e.g., declaring a specific area of interest) as well as theme-based query mechanisms (e.g., requesting a black and white aerial photo or multispectral satellite imagery) are rendered inadequate to identify and access specific datasets in such collections. In this paper we introduce a novel approach to handle data quality attributes in geospatial queries. Our approach is characterized by the ability to model and learn user preferences, thus establishing user profiles that allow us to customize image queries for improving their functionality in a constantly diversifying geospatial user community.	Univ Maine, Dept Spatial Informat Sci & Engn, Orono, ME 04469 USA; Univ Maine, Natl Ctr Geog Informat & Anal, Orono, ME 04469 USA	Mountrakis, G (reprint author), Univ Maine, Dept Spatial Informat Sci & Engn, 348 Boardman Hall, Orono, ME 04469 USA.	giorgos@spatial.maine.edu; tony@spatial.maine.edu; isolde@spatial.maine.edu; peggy@spatial.maine.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bastin L, 2002, COMPUT GEOSCI-UK, V28, P337, DOI 10.1016/S0098-3004(01)00051-6; BEARD MK, 1997, GEOGRAPHIC INFORMATI, P280; BENNETT DA, 1996, CARTOGR GEOGR INF SC, V23, P3, DOI 10.1559/152304096782512177; BUTTENFIELD B, 1994, VISUALIZATION IN GEOGRAPHICAL INFORMATION SYSTEMS, P150; Buttenfield B. P., 1993, CARTOGRAPHICA, V30, P1, DOI 10.3138/232H-6766-3723-5114; BUTTENFIELD BP, 1991, AUT 10 AM C SURV MAP, P423; CAMPBELL G, 1994, FIG C MELB AUSTR, V20; Carkacioglu A, 2002, IEEE IMAGE PROC, P405; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis TJ, 1997, COMPUT GEOSCI, V23, P397, DOI 10.1016/S0098-3004(97)00012-5; Doucette P, 2001, ISPRS J PHOTOGRAMM, V55, P347, DOI 10.1016/S0924-2716(01)00027-2; Duckham M., 2000, Spatial Cognition and Computation, V2, DOI 10.1023/A:1015527221658; Evans BJ, 1997, COMPUT GEOSCI, V23, P409, DOI 10.1016/S0098-3004(97)00011-3; FEGEAS RG, 1992, CARTOGR GEOGR INFORM, V19, P278, DOI 10.1559/152304092783762209; Fisher P. F., 1999, GEOGRAPHICAL INFORMA, V1, P191; Goode M. R., 1999, INT S SPAT DAT QUAL, P1; HUNTER GJ, 1995, PHOTOGRAMM ENG REM S, V61, P529; Lim JH, 2001, IEEE T KNOWL DATA EN, V13, P846; Ma WY, 1998, J AM SOC INFORM SCI, V49, P633, DOI 10.1002/(SICI)1097-4571(1998)49:7<633::AID-ASI5>3.3.CO;2-R; MacEachren A.M., 1992, CARTOGRAPHIC PERSPEC, V13, P10; Mandl T, 2000, NEURAL COMPUT APPL, V9, P280, DOI 10.1007/s005210070005; McGranaghan M, 1993, CARTOGRAPHICA, V30, P8, DOI 10.3138/310V-0067-7570-6566; MITAIM S, 1997, 4 INT FOR RES TECHN, P25; Mountrakis G, 2003, LECT NOTES COMPUT SC, V2750, P412; Muller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5; *NIST, 1992, FED INF PROC STAND; Paradis J., 1994, URISA Journal, V6; Unwin DJ, 1995, PROG HUM GEOG, V19, P549, DOI 10.1177/030913259501900408; Veregin H., 1999, GEOGRAPHICAL INFORMA, V1, P177; Walker P. A., 1988, International Journal of Geographical Information Systems, V2, DOI 10.1080/02693798808927909; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103	33	0	0	2	3	AMER SOC PHOTOGRAMMETRY	BETHESDA	5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA	0099-1112			PHOTOGRAMM ENG REM S	Photogramm. Eng. Remote Sens.	AUG	2004	70	8					973	981				9	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	843JH	WOS:000223074300011		
J	Sboner, A; Bauer, P; Zumiani, G; Eccher, C; Blanzieri, E; Forti, S; Cristofolini, M				Sboner, A; Bauer, P; Zumiani, G; Eccher, C; Blanzieri, E; Forti, S; Cristofolini, M			Clinical validation of an automated system for supporting the early diagnosis of melanoma	SKIN RESEARCH AND TECHNOLOGY			English	Article						computer-aided diagnosis; decision support system; digital dermoscopy	PIGMENTED SKIN-LESIONS; ARTIFICIAL NEURAL-NETWORK; EPILUMINESCENCE MICROSCOPY; IMAGE-ANALYSIS; CUTANEOUS MELANOMA; PATTERN-ANALYSIS; CLASSIFICATION	Background: Early diagnosis and surgical excision is the most effective treatment of melanoma. Well-trained dermatologists reach a high level of diagnostic accuracy with good sensitivity and specificity. Their performances increase using some technical aids as digital epiluminescence microscopy. Several studies describe the development of computerized systems whose aim is supporting dermatologists in the early diagnosis of melanoma. In many cases, the performances of those systems were comparable to those of dermatologists. However, this cannot tell us whether a system is able to support dermatologists. Actually, the computerized system might correctly recognize the same lesions that the dermatologist does, without providing them any useful advice and therefore being useless in recognizing early malignant lesions. Purpose: We present a novel approach to enhance dermatologists' performances in the diagnosis of early melanoma. We provide results of our evaluation of a computerized system combined with dermatologists. Methods: A Multiple-Classifier system was developed on a set of 152 cases and combined to a group of eight dermatologists to support them by improving their sensitivity. Results: The eight dermatologists have average sensitivity and specificity values of 0.83 and 0.66, respectively. The Multiple-Classifier system performs as well as the eight dermatologists (sensitivity range: 0.75-0.86; specificity range: 0.64-0.89). The combination with the dermatologists shows an average improvement of 11% (P=0.022) of dermatologists' sensitivity. Conclusion: Our results suggest that an automated system can be effective in supporting dermatologists because it recognizes different malignant melanomas with respect to the dermatologists.	IRST, ITC, Ctr Sci & Technol Res, I-38050 Trent, Italy; Santa Chiara Hosp, Dept Dermatol, Trent, Italy; Lega Italiana Lotta Contro & Tumori, Sez Trentina, Trent, Italy	Sboner, A (reprint author), IRST, ITC, Ctr Sci & Technol Res, Via Somma 18, I-38050 Trent, Italy.	sboner@itc.it	Sboner, Andrea/C-6487-2008	Sboner, Andrea/0000-0001-6915-3070			BAUER P, 2000, MELANOMA RES, V10, P1; Binder M, 2000, MELANOMA RES, V10, P556, DOI 10.1097/00008390-200012000-00007; Binder M, 1998, MELANOMA RES, V8, P261, DOI 10.1097/00008390-199806000-00009; BINDER M, 1994, BRIT J DERMATOL, V130, P460, DOI 10.1111/j.1365-2133.1994.tb03378.x; BISHOF L, 1999, NEW APPROACHES MED I, V3474, P130; Breiman L., 1984, CLASSIFICATION REGRE; BRESLOW A, 1970, ANN SURG, V172, P902, DOI 10.1097/00000658-197011000-00017; CASCINELLI N, 1992, MELANOMA RES, V2, P167; CHAN PK, 1999, MACHINE LEARNING, V36; CLEMENTE CG, 1998, MELANOMA NEVI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristofolini M, 1997, SKIN RES TECHNOL, V3, P23, DOI 10.1111/j.1600-0846.1997.tb00155.x; Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; ERCAL F, 1994, IEEE T BIO-MED ENG, V41, P837, DOI 10.1109/10.312091; GREEN A, 1994, J AM ACAD DERMATOL, V31, P958; KOH HK, 1991, NEW ENGL J MED, V325, P171, DOI 10.1056/NEJM199107183250306; Lavrac N, 1999, ARTIF INTELL MED, V16, P3, DOI 10.1016/S0933-3657(98)00062-1; NACHBAR F, 1994, J AM ACAD DERMATOL, V30, P551; Pehamberger H, 1993, J INVEST DERMATOL, V100, p356S; PEHAMBERGER H, 1987, J AM ACAD DERMATOL, V17, P571, DOI 10.1016/S0190-9622(87)70239-4; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rubegni P, 2002, SKIN RES TECHNOL, V8, P276, DOI 10.1034/j.1600-0846.2001.00350.x; Sboner A, 2003, ARTIF INTELL MED, V27, P29, DOI 10.1016/S0933-3657(02)00087-8; SBONER A, 2001, TECHNOL HEALTHCARE, V9, P354; Seidenari S, 1999, MELANOMA RES, V9, P163, DOI 10.1097/00008390-199904000-00009; SHINDENWOLF T, 1993, INT ACAD CYTOL ANAL, V15, P1; Stolz W, 1994, COLOR ATLAS DERMATOS; TAKIWAKI H, 1995, J AM ACAD DERMATOL, V32, P600, DOI 10.1016/0190-9622(95)90344-5; Woods R. E., 2002, DIGITAL IMAGE PROCES; ZSOLT BA, 1997, DERMATOL CLIN, V15, P79	31	11	11	0	0	BLACKWELL MUNKSGAARD	COPENHAGEN	35 NORRE SOGADE, PO BOX 2148, DK-1016 COPENHAGEN, DENMARK	0909-752X			SKIN RES TECHNOL	Skin Res. Technol.	AUG	2004	10	3					184	192		10.1111/j.1600-0846.2004.00066.x		9	Dermatology	Dermatology	832RV	WOS:000222285600008	15225269	
J	Shi, HL; Paolucci, U; Vigneau-Callahan, KE; Milbury, PE; Matson, WR; Kristal, BS				Shi, HL; Paolucci, U; Vigneau-Callahan, KE; Milbury, PE; Matson, WR; Kristal, BS			Development of biomarkers based on diet-dependent metabolic serotypes: Practical issues in development of expert system-based classification models in metabolomic studies	OMICS-A JOURNAL OF INTEGRATIVE BIOLOGY			English	Article							FEMALE; RATS	Dietary restriction (DR)-induced changes in the serum metabolome may be biomarkers for physiological status (e.g., relative risk of developing age-related diseases such as cancer). Megavariate analysis (unsupervised hierarchical cluster analysis [HCA]; principal components analysis [PCA]) of serum metabolites reproducibly distinguish DR from ad libitum fed rats. Component-based approaches (i.e., PCA) consistently perform as well as or better than distance-based metrics (i.e., HCA). We therefore tested the following: (A) Do identified subsets of serum metabolites contain sufficient information to construct mathematical models of class membership (i.e., expert systems)? (B) Do component-based metrics out-perform distance-based metrics? Testing was conducted using KNN (k-nearest neighbors, supervised HCA) and SIMCA (soft independent modeling of class analogy, supervised PCA). Models were built with single cohorts, combined cohorts or mixed samples from previously studied cohorts as training sets. Both algorithms over-fit models based on single cohort training sets. KNN models had >85% accuracy within training/test sets, but were unstable (i.e., values of k could not be accurately set in advance). SIMCA models had 100% accuracy within all training sets, 89% accuracy in test sets, did not appear to over-fit mixed cohort training sets, and did not require post-hoc modeling adjustments. These data indicate that (i) previously defined metabolites are robust enough to construct classification models (expert systems) with SIMCA that can predict unknowns by dietary category; (ii) component-based analyses outperformed distance-based metrics; (iii) use of over-fitting controls is essential; and (iv) subtle inter-cohort variability may be a critical issue for high data density biomarker studies that lack state markers.	Cornell Univ, Coll Med, Burke Med Res Inst, Dementia Res Serv, White Plains, NY 10605 USA; ESA Inc, Chelmsford, MA USA; Tufts Univ, USDA, Human Nutr Res Ctr Aging, Antioxidants Res Lab, Boston, MA 02111 USA; Cornell Univ, Coll Med, Dept Biochem & Neurosci, White Plains, NY 10605 USA	Kristal, BS (reprint author), Cornell Univ, Coll Med, Burke Med Res Inst, Dementia Res Serv, 785 Mamaroneck Ave, White Plains, NY 10605 USA.	Bkristal@burke.org					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kristal BS, 1994, MODULATION AGING PRO, P1; MATSON WR, 1984, CLIN CHEM, V30, P1477; McCay CM, 1935, J NUTR, V10, P63; MILBURY PE, 1997, COULOMETRIC ARRAY DE, P125; Paolucci U, 2004, OMICS, V8, P209, DOI 10.1089/omi.2004.8.209; Paolucci U, 2004, OMICS, V8, P221, DOI 10.1089/omi.2004.8.221; Shi HL, 2002, J NUTR, V132, P1031; Shi HL, 2002, J NUTR, V132, P1039; VIGNEAUCALLAHAN KE, 2001, J NUTR, pS924; WEINDRUCH R, 1988, RETARDATION AGING DI; Willett WC, 1999, NEW ENGL J MED, V341, P427, DOI 10.1056/NEJM199908053410607; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5	13	20	24	0	1	MARY ANN LIEBERT INC	LARCHMONT	2 MADISON AVENUE, LARCHMONT, NY 10538 USA	1536-2310			OMICS	OMICS	FAL	2004	8	3					197	208		10.1089/omi.2004.8.197		12	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	867IQ	WOS:000224836700003	15669713	
J	Cai, YD; Chou, KC				Cai, YD; Chou, KC			Predicting 22 protein localizations in budding yeast	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						gene ontology; functional domain composition; pseudo-amino acid composition; GO-FunD-PseAA predictor; InterPro database; hybrid space; nearest neighbor algorithm	AMINO-ACID-COMPOSITION; SUBCELLULAR LOCATION PREDICTION; STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; GENE ONTOLOGY; SITES; CLASSIFICATION; SEQUENCE	According to the recent experiments, proteins in budding yeast can be distinctly classified into 22 subcellular locations. Of these proteins, some bear the multi-locational feature, i.e., occur in more than one location. However, so far all the existing methods in predicting protein subcellular location were developed to deal with only the mono-locational case where a query protein is assumed to belong to one, and only one, subcellular location. To stimulate the development of subcellular location prediction, an augmentation procedure is formulated that will enable the existing methods to tackle the multi-locational problem as well. It has been observed thru a jackknife cross-validation test that the success rate obtained by the augmented GO-FnD-PseAA algorithm [BBRC 320 (2004) 1236] is overwhelmingly higher than those by the other augmented methods. It is anticipated that the augmented GO-FunD-PseAA predictor will become a very useful tool in predicting protein subcellular localization for both basic research and practical application. (C) 2004 Elsevier Inc. All rights reserved.	Univ Manchester, Dept Biomol Sci, Manchester M60 1QD, Lancs, England; Gordon Life Sci Inst, San Diego, CA 92130 USA; TIBDD, Tianjin, Peoples R China	Cai, YD (reprint author), Univ Manchester, Dept Biomol Sci, POB 88, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk; kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; Chou KC, 2004, J CELL BIOCHEM, V91, P1085, DOI 10.1002/jcb.20083; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou P Y, 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	31	40	42	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	OCT 15	2004	323	2					425	428		10.1016/j.bbrc.2004.08.113		4	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	856WS	WOS:000224076900010	15369769	
J	Liu, D				Liu, D			A strong lower bound for approximate nearest neighbor searching	INFORMATION PROCESSING LETTERS			English	Article						computational geometry; approximate nearest neighbor searching; lower bound	HIGH-DIMENSIONAL SPACES; ALGORITHM	We prove a lower bound of d(1-o(1)) on the query time for any deterministic algorithms that solve approximate nearest neighbor searching in Yao's cell probe model. Our result greatly improves the best previous lower bound for this problem, which is Omega (loglogd/logloglogd) [A. Chakrabarti et al., in: Proc. 31 st Ann. ACM S ymp. Theory of Computing, 1999, pp. 305-311]. Our proof is also much simpler than the proof of A. Chakrabarti et al. (C) 2004 Elsevier B.V All rights reserved.	Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA	Liu, D (reprint author), Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA.	dingliu@cs.princeton.edu					Agarwal P. K., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/129712.129763; ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Barkol O., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335350; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; Miltersen P. B., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195415; Chakrabarti A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301325; CHAKRABARTI A, 2002, THESIS PRINCETON U; Chan T. M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, DOI 10.1145/262839.263001; Chazelle B., 2000, DISCREPANCY METHOD R; CLARKSON KL, 1988, SIAM J COMPUT, V17, P830, DOI 10.1137/0217052; Clarkson K. L., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, DOI 10.1145/177424.177609; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1982, HDB STAT, V2; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Edelsbrunner H, 1987, ALGORITHMS COMBINATO; Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275488; Flickner M., 1995, IEEE COMPUT, P23; Harper L.H., 1966, J COMBINATORIAL THEO, V1, P385, DOI 10.1016/S0021-9800(66)80059-5; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kleinberg J.M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; Miltersen PB, 1998, J COMPUT SYST SCI, V57, P37, DOI 10.1006/jcss.1998.1577; Yao A.C., 1985, P 17 ANN ACM S THEOR, P163, DOI 10.1145/22145.22163; YAO ACC, 1981, J ACM, V28, P615, DOI 10.1145/322261.322274	27	14	14	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0020-0190			INFORM PROCESS LETT	Inf. Process. Lett.	OCT 16	2004	92	1					23	29		10.1016/j.ipl.2004.06.001		7	Computer Science, Information Systems	Computer Science	853PH	WOS:000223839000004		
J	Linnell, TA; Deravi, F				Linnell, TA; Deravi, F			Mapping vector accumulator: fractal domain feature for character recognition	ELECTRONICS LETTERS			English	Article								A new feature is presented which is calculated directly from the fractal-compressed form of images. The performance of this feature is analysed by using it in the training of standard classifiers for a character recognition problem. The feature is shown to be translation invariant, giving it an advantage over methods that use pixels or compressed data directly.	Univ Kent, Dept Elect, Canterbury, Kent, England	Linnell, TA (reprint author), Univ Kent, Dept Elect, Canterbury, Kent, England.	tristan.linnell@iee.org	Deravi, Farzin/E-7190-2013	Deravi, Farzin/0000-0003-0885-437X			COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher Y, 1994, FRACTAL IMAGE COMPRE; Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028; Parzen E., 1962, ANN MATH STAT, V33, P1064	4	4	4	0	1	IEE-INST ELEC ENG	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	0013-5194			ELECTRON LETT	Electron. Lett.	OCT 28	2004	40	22					1406	1407		10.1049/el:20046478		2	Engineering, Electrical & Electronic	Engineering	871CL	WOS:000225106800014		
J	Wang, H; Bell, D				Wang, H; Bell, D			Extended k-nearest neighbours based on evidence theory	COMPUTER JOURNAL			English	Article							TRANSFERABLE BELIEF MODEL; DEMPSTER-SHAFER THEORY; CLASSIFICATION RULE; PATTERN-RECOGNITION; APPROXIMATION; CLASSIFIERS; COMBINATION	An evidence theoretic classification method is proposed in this paper. In order to classify a pattern we consider its neighbours, which are taken as parts of a single source of evidence to support the class membership of the pattern. A single mass function or basic belief assignment is then derived, and the belief function and the pignistic ('betting rates') probability function can be calculated. Then the (posterior) conditional pignistic probability function is calculated and used to decide the class label for the pattern. It is shown that such a classifier extends the standard majority voting based k-nearest neighbour classifier, and it is an approximation to the optimal Bayes classifier. In experiments this classifier performed as well as or better than the voting and distance weighted k-nearest neighbours classifiers with best k, and its performance became stable when the number of neighbours considered was >4.	Univ Ulster, Sch Comp & Math, Coleraine BT52 1SA, Londonderry, North Ireland; Queens Univ Belfast, Sch Comp Sci, Belfast BT7 1NN, Antrim, North Ireland	Wang, H (reprint author), Univ Ulster, Sch Comp & Math, Coleraine BT52 1SA, Londonderry, North Ireland.	h.wang@ulster.ac.uk; da.bell@qub.ac.uk					BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Bauer M, 1997, INT J APPROX REASON, V17, P217, DOI 10.1016/S0888-613X(97)00013-3; BENNETT P, 2003, IN PRESS INFORMATION; Bennett P. N., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Buxton BF, 2001, MEAS CONTROL-UK, V34, P229; Chang C. -C., 2004, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Denoeux T, 2002, INT J APPROX REASON, V31, P77, DOI 10.1016/S0888-613X(02)00073-7; Denoeux T, 2001, INT J UNCERTAIN FUZZ, V9, P437, DOI 10.1016/S0218-4885(01)00088-0; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 1951, DISCRIMINARY ANAL NO; Hand D, 2001, PRINCIPLES DATA MINI; HARMANEC D, 1999, UNCERTAINTY ARTIFICI, V15, P271; Hull D. A., 1996, P 19 ANN INT ACM SIG, P279, DOI 10.1145/243199.243275; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KITTLER J, 2001, LNCS, V2096; KITTLER J, 2000, LNCS, V1857; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; LAM W, 2001, P 24 ANN INT ACM SIG, P303, DOI 10.1145/383952.384011; Larkey Leah S., 1996, P SIGIR 96 19 ACM IN, P289, DOI 10.1145/243199.243276; Li YH, 1998, COMPUT J, V41, P537, DOI 10.1093/comjnl/41.8.537; LOWRANCE JD, 1986, P AAAI 86 PHIL AUG, V2, P896; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; PIATETSKYSHAPIR.G, 2003, POLL WHAT DATA MININ; Shafer G., 1976, MATH THEORY EVIDENCE; SMETS P, 1990, IEEE T PATTERN ANAL, V12, P447, DOI 10.1109/34.55104; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smets P., 1998, HDB DEFEASIBLE REASO, V1, P267; TESSEM B, 1993, ARTIF INTELL, V61, P315, DOI 10.1016/0004-3702(93)90072-J; Wilson N, 2000, HANDBOOK OF DEFEASIBLE REASONING AND UNCERTAINTY MANAGEMENT SYSTEMS, VOL 5, P421; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yang Y., 2000, P 17 INT C MACH LEAR, P1167; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	36	4	4	0	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0010-4620			COMPUT J	Comput. J.	NOV	2004	47	6					662	672		10.1093/comjnl/47.6.662		11	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	865LE	WOS:000224703800004		
J	Hansen, ME; Carstensen, JM				Hansen, ME; Carstensen, JM			Density-based retrieval from high-similarity image databases	PATTERN RECOGNITION			English	Article						density based; identification; density estimation; image retrieval	COLOR	Many image classification problems can fruitfully be thought of as image retrieval in a "high similarity image database" (HSID) characterized by being tuned towards a specific application and having a high degree of visual similarity between entries that should be distinguished. We introduce a method for HSID retrieval using a similarity measure based on a linear combination of Jeffreys-Matusita distances between distributions of local (pixelwise) features estimated from a set of automatically and consistently defined image regions. The weight coefficients are estimated based on optimal retrieval performance. Experimental results on the difficult task of visually identifying clones of fungal colonies grown in a petri dish and categorization of pelts show a high retrieval accuracy of the method when combined with standardized sample preparation and image acquisition. (C) 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Tech Univ Denmark, DK-2800 Lyngby, Denmark	Hansen, ME (reprint author), Tech Univ Denmark, Bldg 321, DK-2800 Lyngby, Denmark.	meh@imm.dtu.dk	Hansen, Michael/C-9028-2011	Hansen, Michael/0000-0001-7879-2106			ANDROUTSOS D, 1998, DISTANCE MEASURES CO; Bishop C.M., 1995, NEURAL NETWORKS PATT; CARSON C, 1997, CVPR97 WORKSH CONT B; CINQUE L, 1999, COLOR BASED IMAGE RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450; Dorge T, 2000, J MICROBIOL METH, V41, P121, DOI 10.1016/S0167-7012(00)00142-1; FUKANAGA K, 1990, INTRO PATTERN RECOGN; Hastie T., 2002, ELEMENTS STAT LEARNI; IZENMAN AJ, 1991, J AM STAT ASSOC, V86, P205, DOI 10.2307/2289732; Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3; Kankanhalli MS, 1999, PATTERN RECOGN LETT, V20, P109, DOI 10.1016/S0167-8655(98)00100-7; Mirmehdi M, 2000, IEEE T PATTERN ANAL, V22, P142, DOI 10.1109/34.825753; Pitt JI, 1979, GENUS PENICILLIUM IT; Raper KB, 1949, MANUAL PENICILLIA; Ripley BD, 1996, PATTERN RECOGNITION; Roussopoulos N., 1995, P ACM SIGMOD INT C M, P71, DOI DOI 10.1145/223784.223794; Sonka M., 1994, IMAGE PROCESSING ANA	18	11	13	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	NOV	2004	37	11					2155	2164		10.1016/j.patcog.2004.02.018		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	848XI	WOS:000223501000005		
B	Mujica-V, VE; Sisalem, D; Popescu-Zeletin, R		Skowron, A; Barthes, JP; Jain, L; Sun, R; MorizetMahoundeaux, P; Liu, J; Zhong, N		Mujica-V, VE; Sisalem, D; Popescu-Zeletin, R			Evolving biosciences in multi-agent systems	2005 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, Proceedings			English	Proceedings Paper	International Conference on Intelligent Agent Technology	SEP 19-22, 2005	Compiegne, FRANCE	IEEE Comp Soc, Web Intelligence Consortium, Assoc Comp Machinery	Compiegne Univ Technol		AD HOC NETWORKS	This paper proposes a strong research interest in afield related to bioinformatics and computational biology in a Multi-Agent System (MAS). We promote the use of evolutionary computation within intelligent Multi-Agent Systems taking particularly the enhancement of the NEUron Routing ALgorithm (NEURAL) in Mobile Ad Hoc Network (AMNET). More precisely, we develop an intelligent mobile agent called the NEURAL Agent which significantly improves the performance of NEURAL. Results demonstrated that the NEURAL Agent leads to significant benefits in the average end-to-end delay and the packet delivery ratio of the routing protocol.	Fraunhofer FOKUS Inst, Berlin, Germany	Mujica-V, VE (reprint author), Fraunhofer FOKUS Inst, Berlin, Germany.						BERKELEY U, 1998, NETWORK SIMULATOR; Broch J., 1998, 4 ANN ACM IEEE INT C, P85; Costa-Requena J, 2004, WIREL NETW, V10, P367, DOI 10.1023/B:WINE.0000028541.95473.79; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hass Z. J., 2001, IEEE ACM T NETWORK, V9, P427; Kohonen T., 2001, SELF ORG MAPS; MUJICA VVE, 2005, P 3 INT S MOD OPT MO; Perkins CE, 2001, IEEE PERS COMMUN, V8, P16, DOI 10.1109/98.904895; REHABI Y, 2005, P 10 IEEE S COMP COM; Sycara KP, 1998, AI MAG, V19, P79	10	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2416-8				2005							148	151				4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDI55	WOS:000233623100026		
S	Mignani, AG; Ciaccheri, L; Smith, PR; Cimato, A; Attilio, C; Huertas, R; Latorre, MM; Bertho, AC; O'Rourke, B; McMillan, ND		Voet, M; Willsch, R; Ecke, W; Jones, J; Culshaw, B		Mignani, AG; Ciaccheri, L; Smith, PR; Cimato, A; Attilio, C; Huertas, R; Latorre, MM; Bertho, AC; O'Rourke, B; McMillan, ND			Scattered colorimetry and multivariate data processing as an objective tool for liquid mapping	17th International Conference on Optical Fibre Sensors, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	17th International Conference on Optical Fibre Sensors	MAY 23-27, 2005	Brugge, BELGIUM	I D FOS Res, Fibre Opt Sensors & Sensing Syst, European Off Aerosp Res & Dev, USAF Res Lab, Network Excellence Micro Opt, SCK CEN, Belgian Nucl Res Ctr, FWO, FNRS, Export Flanders, Flanders Foreign Investment Off, ESF, European Opt Soc, Inst Phys, IEEE, SPIE, Inst Measurement & Control UK, IEEE LEOS, Opt Soc Amer, AMA German Sensor Technol Assoc, DGaO German Soc Appl Opt, OptecNet German Network Competence Opt Photon Technologies, Sensors Web Portal		liquid mapping; colorimetry; scattering; turbidity		Scattered colorimetry, i.e., multi-angle and multi-wavelength absorption spectroscopy performed in the visible spectral range, was used to map three kinds of liquids: extra virgin olive oils, frying oils, and detergents in water. By multivariate processing of the spectral data, the liquids could be classified according to their intrinisic characteristics: geographic area of extra virgin olive oils, degradation of frying oils, and surfactant types and mixtures in water.	CNR, IFAC, Dept Optoelect & Photon, I-50127 Florence, Italy	Mignani, AG (reprint author), CNR, IFAC, Dept Optoelect & Photon, Via Panciatichi 64, I-50127 Florence, Italy.						ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA	4	4	4	2	3	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5855-4	P SOC PHOTO-OPT INS			2005	5855		1-2				38	41		10.1117/12.623388		4	Instruments & Instrumentation; Optics	Instruments & Instrumentation; Optics	BCV71	WOS:000231443000009		
B	Madani, K; Chebira, A; Rybnik, M; Bouyoucef, EK			IEEE	Madani, Kurosh; Chebira, Abdennasser; Rybnik, Mariusz; Bouyoucef, El-Khier			Tree-like multiple neural network models generator with a complexity estimation based decomposer	2005 IEEE INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS: TECHNOLOGY AND APPLICATIONS	IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems-Technology and Applications-IDAACS		English	Proceedings Paper	3rd IEEE Intelligent Data Acquisition and Advanced Computing Systems	SEP 05-07, 2005	Sofia, BULGARIA	IEEE, Inst Comp Informat Technol, Ternopil Acad Natl Econ, Tech Univ Sofia, Fac Comp Syst & Control, Univ Sofia, Ternopil Acad Natl Econ, IEEE Instrumentat & Measurement Soc, Sci & Technol Ctr, IEEE Bulgaria Sect, IEEE Comp Chapter Bulgaria Sect		Artificial Neural Networks; complexity estimation; self-organization; intelligent decomposer; universal information processing	PATTERN-CLASSIFICATION; INFORMATION	In this article we present a self organizing hybrid modular approach that is aimed at reduction of processing task complexity by decomposition of an initially complex problem into a set of simpler sub-problems. This approach hybridizes Artificial Neural Networks based artificial intelligence and complexity estimation loops in order to reach a higher level intelligent processing capabilities. In consequence, our approach mixtures learning, complexity estimation and specialized data processing modules in order to achieve a higher level self-organizing modular intelligent information processing system. Experimental results validating the presented approach are reported and discussed.	Univ Paris 12, Senart Inst Technol, Signal & Intelligent Syst Lab, Intelligence Instrumentat & Syst Div I2S, F-77127 Lieusaint, France	Madani, K (reprint author), Univ Paris 12, Senart Inst Technol, Signal & Intelligent Syst Lab, Intelligence Instrumentat & Syst Div I2S, Av Pierre Point, F-77127 Lieusaint, France.	madani@univ-paris12.fr; chebira@univ-paris12.fr					Arbib MA, 2003, HDB BRAIN THEORY NEU; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; BRUSKE J, 1995, ADV NEURAL INFORMATI, V7, P497; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHERNOFF A, 1966, ANN I STAT MATH, V18, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FISHER A, 2000, MATH THEORY PROBABIL; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; Fukunaga K., 1990, INTRO STAT PATTERN R; GOONATILAKE S, INTELLIGENT HYBRID S, P1; Ho TK, 1998, COMPUT VIS IMAGE UND, V70, P101, DOI 10.1006/cviu.1998.0624; HO TK, 2000, LECT NOTES COMPUTER; JOLLIFEE IT, 1986, PRINCIPLE COMPONENT; Jordan MI, 1995, NEURAL NETWORKS, V8, P1409, DOI 10.1016/0893-6080(95)00014-3; Kohn AF, 1996, PATTERN RECOGN, V29, P873, DOI 10.1016/0031-3203(95)00122-0; Kohonen T., 1988, SELF ORG ASS MEMORY; Krogh A., 1994, ADV NEURAL INFORMATI, V7, P231; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; MADANI K, 2000, PKDD 2000; MADANI K, 2003, LNCS SERIES, P382; MADDOX J, 1990, NATURE, V344, P705; MATUSITA K, 1967, ANN I STAT MATH, V19, P181, DOI 10.1007/BF02911675; Murray-Smith R., 1997, MULTIPLE MODEL APPRO; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pierson W., 1998, THESIS OHIO STATE U; RAHMAN AFR, 1998, P INT C IM AN PROC, P893; SANG KK, NEURAL INFORM PROCES, V7, P497; Singh S., 2003, IEEE T PATTERN ANAL; Sridhar DV, 1999, NEURAL NETWORKS, V12, P915, DOI 10.1016/S0893-6080(99)00030-1; TAKESHITA T, 1987, T IEICE, P567	30	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-7803-9445-2	INT WORKSH INT DATA			2005							60	65		10.1109/IDAACS.2005.282942		6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Instruments & Instrumentation	Computer Science; Instruments & Instrumentation	BFW78	WOS:000245169600013		
B	Li, YG; Huang, JJ; Zhang, WD; Zhang, XL			IEEE	Li, Yuangui; Huang, Jinjie; Zhang, Weidong; Zhang, Xiaolei			New prototype selection rule integrated condensing with editing process for the nearest neighbor rules	2005 IEEE International Conference on Industrial Technology - (ICIT), Vols 1 and 2			English	Proceedings Paper	IEEE International Conference on Industrial Technology (ICIT)	DEC 14-17, 2005	Hong Kong, PEOPLES R CHINA	IEEE			LEARNING ALGORITHMS; CLASSIFICATION; DESIGN	A new prototype selection method was proposed to reduce the training set for the nearest neighbor rule. The method aimed to integrate the advantage of editing and condensing method, and it only selects the points in class boundary into prototype set. It used information contained in internal points to 'clean' or edit overlapping and noise of training set, then condensing process which only keeps border points was used to obtain prototype set. Computational results show that it can obtain satisfactory performance and higher condensing rate than popular instance reduction algorithm.	Shanghai Jiao Tong Univ, Automat Dept, Shanghai 200030, Peoples R China	Li, YG (reprint author), Shanghai Jiao Tong Univ, Automat Dept, Shanghai 200030, Peoples R China.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Biberman Y., 1994, P 9 EUR C MACH LEARN, P49; Blake CL, UCI REPOSITORY MACHI; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Devijver P. A., 1982, PATTERN RECOGNITION; Domeniconi C., 2001, ADV NEURAL INFORM PR, V14, P665; Domingos P., 1995, P 14 INT JOINT C ART, P1226; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Nadler M., 1993, PATTERN RECOGNITION; TOUSSAINT G, 2002, P INTERFACE 2002 34, P83; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	17	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9483-6				2005							1014	1018				5	Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Engineering, Mechanical	Computer Science; Engineering	BEO65	WOS:000238482500177		
B	Zhang, Z; Xu, X; Huang, T			IEEE	Zhang, Z; Xu, X; Huang, T			Indecisive classifier	2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2			English	Proceedings Paper	IEEE International Conference on Multimedia and Expo (ICME)	JUL 06-08, 2005	Amsterdam, NETHERLANDS	IEEE				Nearest neighbor classification expects the class conditional probabilities to be locally constant. The assumption becomes invalid in high dimension due to the curse-of-dimensionality. Severe bias can be introduced under this condition when using nearest neighbor rule. We propose an adaptive nearest neighbor classification method "indecisive classifier" to minimize bias and variance by avoiding decision making in some hard-decision region. As a result, better classification performance can be expected in some scenario such as video based face recognition.	Univ Illinois, Urbana, IL 61801 USA	Zhang, Z (reprint author), Univ Illinois, Urbana, IL 61801 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DJOUADI A, 1998, PAMI, V20; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E., 1952, 11 USAF SCH AV MED; FUKUNAGA K, 1973, INFORM THEORY, V19; HASTIE T, 1996, PAMI, V18; HASTIE T, 2001, ELEMENTS STAT LEARNI, P427; PENG J, 2004, PAMI, V26; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758	9	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9331-7				2005							570	573				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDO93	WOS:000234623800143		
S	Liu, W; Fan, W; Wang, YH; Tan, TN			IEEE	Liu, W; Fan, W; Wang, YH; Tan, TN			Local manifold matching for face recognition	2005 International Conference on Image Processing (ICIP), Vols 1-5	IEEE International Conference on Image Processing (ICIP)		English	Proceedings Paper	IEEE International Conference on Image Processing (ICIP 2005)	SEP 11-14, 2005	Genoa, ITALY	IEEE				In this paper, we propose a novel classication method, called local manifold matching (LMM), for face recognition. LMM has great representational capacity of available prototypes and is based on the local linearity assumption that each data point and its k nearest neighbors from the same class lie on a linear manifold locally embedded in the image space. We present a supervised local manifold learning algorithm for learning all locally linear manifold structures. Then we propose the nearest manifold criterion for the classication in which the query feature point is assigned to the most matching face manifold. Experimental results show that kernel PCA incorporated with the LMM classier achieves the best face recognition performance.	Chinese Acad Sci, Inst Automat, NLPR, Beijing 100080, Peoples R China	Liu, W (reprint author), Chinese Acad Sci, Inst Automat, NLPR, Beijing 100080, Peoples R China.						Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cover T., 1967, IEEE T INFORM THEORY, V13, P57; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; YANG MH, 2000, P IEEE INT C IM PROC	7	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		0-7803-9134-9	IEEE IMAGE PROC			2005							1589	1592				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BDW08	WOS:000235773302010		
B	Markowska-Kaczmar, U; Kubacki, P		Kwasnicka, H; Paprzycki, M		Markowska-Kaczmar, U; Kubacki, P			Support vector machines in handwritten digits classification	5th International Conference on Intelligent Systems Design and Applications, Proceedings			English	Proceedings Paper	5th International Conference on Intelligent Systems Design and Applications (ISDA 2005)	SEP 08-10, 2005	Wroclaw, POLAND	World Federat Soft Comp, European Soc Fuzzy Log & Technol, European Neural Network Soc, Warsaw Sch Social Psychol, Polish Minist Sci Res & Informat Technol				In the paper our approach to classify handwritten digits by using Support Vector Machines is described. Because of the unsatisfying, long time of training of SVM we propose to apply k-nearest neighbours algorithm with Manhattan distance to obtain reduced size of training set having a hope that this hybrid method does not make the significantly worse results of recognition, The aim of presented further experiments was to verify this assumption.	Wroclaw Tech Univ, Inst Appl Informat, PL-50370 Wroclaw, Poland	Markowska-Kaczmar, U (reprint author), Wroclaw Tech Univ, Inst Appl Informat, Wyb Wyspinanskiego 27, PL-50370 Wroclaw, Poland.						ABOUMOUSTAFA KT, 1967, PATTERN RECOGN, V5, P923; Cheong S., 2004, NEURAL INFORM PROCES, V2, P47; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESTEFANO C, 1994, P IEEE C MAN SYST CY, P759; LINLIN H, 2004, NEUROCOMPUTING, V5, P197; Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3206(03)00085-2; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Rabiner L.R., 1990, READINGS SPEECH RECO, P267	8	0	0	2	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2286-6				2005							406	411		10.1109/ISDA.2005.87		6	Computer Science, Artificial Intelligence	Computer Science	BDE37	WOS:000233058700069		
J	Vogt, P				Vogt, P			On the acquisition and evolution of compositional languages: Sparse input and the productive creativity of children	ADAPTIVE BEHAVIOR			English	Article; Proceedings Paper	16th Annual Meeting of the Human-Behavior-and-Evolution-Society (HBES)	JUL 21-25, 2004	Berlin, GERMANY	Human Behav & Evolut Soc		evolution of language; language acquisition; compositionality; iterated learning; language games	SIGN-LANGUAGE; EMERGENCE; COLOR	This paper investigates the productive creativity of children in a computational model of the emergence and evolution of compositional structures in language. In previous models it was shown that compositional structures can emerge in language when the language is transmitted from one generation to the next through a transmission bottleneck. Due to the fact that in these models language is transmitted only in a vertical direction where adults only speak to children and children only listen, this bottleneck needs to be imposed by the experimenter. In the current study, this bottleneck is removed and instead of having a vertical transmission of language, the language is-in most simulations-transmitted horizontally (i.e., any agent can speak to any other agent). It is shown that Such a horizontal transmission scenario does not need an externally imposed bottleneck, because the children face an implicit bottleneck when they start speaking early in life. The model is compared with the recent development of Nicaraguan Sign Language, where it is observed that children are a driving force for inventing grammatical (or compositional) structures, possibly due to a sparseness of nput (i.e., an implicit bottleneck). The results show that in the studied model children are indeed the creative driving force for the emergence and stable evolution of compositional languages, thus suggesting that this implicit bottleneck may-in part-explain why children are so typically good at acquiring language and, moreover, why they may have been the driving force for the emergence of grammar in language.	Univ Edinburgh, Language Evolut & Computat Res Unit, Sch Philosophy Psychol & Language Sci, Edinburgh EH8 9LL, Midlothian, Scotland	Vogt, P (reprint author), Univ Edinburgh, Language Evolut & Computat Res Unit, Sch Philosophy Psychol & Language Sci, 40 George Sq, Edinburgh EH8 9LL, Midlothian, Scotland.						BELPAEME T, 2005, ADAPTIVE BEHAV; BICKERTON D, 1984, BEHAV BRAIN SCI, V7, P173; Bickerton Derek, 1990, LANGUAGE SPECIES; Bloom P., 2000, CHILDREN LEARN MEANI; Braine M.D.S., 1971, LEARNING LANGUAGE; Brighton H, 2002, ARTIF LIFE, V8, P25, DOI 10.1162/106454602753694756; BRISCOE EJ, 2002, LINGUISTICS EVOLUTIO; Cangelosi Angelo, 2002, SIMULATING EVOLUTION; Cavalli-Sforza L. L., 1981, CULTURAL TRANSMISSIO; CHOMSKY N, 1980, BEHAV BRAIN SCI, V3, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Darwin C., 1968, ORIGIN SPECIES; Deacon Terrence, 1997, SYMBOLIC SPECIES; DEJONG ED, 1999, P 5 EUR C ART LIF, P689; Frege G., 1892, COLLECTED PAPERS MAT, P182; Gardenfors Peter, 2000, CONCEPTUAL SPACES; GILBERT N, 2005, P AISB 2005 SOC INSP, P57; Goldin-Meadow S., 1982, LANG ACQUIS, P51; Jackendoff R, 1999, TRENDS COGN SCI, V3, P272, DOI 10.1016/S1364-6613(99)01333-9; Kegl J., 1989, P 4 ANN M PAC LING C; Kirby S, 2001, IEEE T EVOLUT COMPUT, V5, P102, DOI 10.1109/4235.918430; Kirby S., 2002, LINGUISTIC EVOLUTION; Lieven E, 2003, J CHILD LANG, V30, P333, DOI 10.1017/S0305000903005592; Peters A. M., 1983, UNITS LANGUAGE ACQUI; PINKER S, 1990, BEHAV BRAIN SCI, V13, P707; PRIGOGINE I, 1984, ORDER CHAOS; Sankoff Gillian, 1973, KIVUNG, V6, P32; Sebba Mark, 1997, CONTACT LANGUAGES PI; Senghas A, 2004, SCIENCE, V305, P1779, DOI 10.1126/science.1100199; Senghas A, 2001, PSYCHOL SCI, V12, P323, DOI 10.1111/1467-9280.00359; SMITH ADM, 2005, ADAPTIVE BEHAV; Smith K, 2003, LECT NOTES ARTIF INT, V2801, P507; Smith K, 2003, ADV COMPLEX SYST, V6, P537, DOI 10.1142/S0219525903001055; STEELS L., 1996, P 2 INT C MULT SYST, P338; Steels L, 2005, BEHAV BRAIN SCI, V28, P469; Steels L., 1996, ANIMALS ANIMATS, P562; STEELS L., 2002, TRANSITION LANGUAGE, P252; STEELS L., 2004, P ANN M ASS COMP LIN, P9, DOI 10.3115/1218955.1218957; Tomasello M, 2000, COGNITION, V74, P209, DOI 10.1016/S0010-0277(99)00069-4; van Zaanen M., 2000, P 18 INT C COMP LING, P961; Vogt P, 2003, LECT NOTES ARTIF INT, V2801, P535; Vogt P, 2005, BEHAV BRAIN SCI, V28, P509; VOGT P, 2005, P AISB 2005 SOC INS; VOGT P, IN PRESS P IJCAI 05; Vogt P, 2005, ARTIF INTELL, V167, P206, DOI 10.1016/j.artint.2005.04.010; VOGT P, 2005, P EUR C COMPL SYST E; Wray A, 1998, LANG COMMUN, V18, P47, DOI 10.1016/S0271-5309(97)00033-5; Zipf G. K., 1949, HUMAN BEHAV PRINCIPL	48	13	13	0	2	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1059-7123			ADAPT BEHAV	Adapt. Behav.		2005	13	4					325	346		10.1177/105971230501300403		22	Computer Science, Artificial Intelligence; Psychology, Experimental; Social Sciences, Interdisciplinary	Computer Science; Psychology; Social Sciences - Other Topics	990KC	WOS:000233740700006		
S	Divina, F; Vogt, P		Capcarrere, MS; Freitas, AA; Bentley, PJ; Johnson, CG; Timmis, J		Divina, F; Vogt, P			Perceptually grounded lexicon formation using inconsistent knowledge	ADVANCES IN ARTIFICAL LIFE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th European Conference on Artificial Life	SEP 05-09, 2005	Canterbury, ENGLAND				EVOLUTION	Typically, multi-agent models for studying the evolution of perceptually grounded lexicons assume that agents perceive the same set of objects, and that there is either joint attention, corrective feedback or cross-situational learning. In this paper we address these two assumptions, by introducing a new multi-agent model for the evolution of perceptually grounded lexicons, where agents do not perceive the same set of objects, and where agents receive a cue to focus their attention to objects, thus simulating a Theory of Mind. In addition, we vary the amount of corrective feedback provided to guide learning word-meanings. Results of simulations show that the proposed model is quite robust to the strength of these cues and the amount of feedback received.	Tilburg Univ, Computat Linguist & AI Sect, NL-5000 LE Tilburg, Netherlands; Univ Edinburgh, LEC Unit, Edinburgh EH8 9YL, Midlothian, Scotland	Divina, F (reprint author), Tilburg Univ, Computat Linguist & AI Sect, NL-5000 LE Tilburg, Netherlands.	F.Divina@uvt.nl; paulv@ling.ed.ac.uk					Akhtar N., 1999, FIRST LANG, V19, P347, DOI DOI 10.1177/014272379901905703; Bloom P., 2000, CHILDREN LEARN MEANI; Chouinard MM, 2003, J CHILD LANG, V30, P637, DOI 10.1017/S0305000903005701; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GONG T, 2004, LIFE, V9; HURFORD JR, 1989, LINGUA, V77, P187, DOI 10.1016/0024-3841(89)90015-6; Kirby S, 2001, IEEE T EVOLUT COMPUT, V5, P102, DOI 10.1109/4235.918430; Oliphant M, 1999, ADAPT BEHAV, V7, P371, DOI 10.1177/105971239900700309; Quine W. V. O., 1960, WORD OBJECT; SMITH ADM, 2003, ARTIF LIFE, V9, P559; STEELS L, 1996, SAB96; Steels L., 1997, P 4 EUR C ART LIF CA; STEELS L, 2002, TRANSITION LANGUAGE, P214; Steels L., 1997, EVOLUTION COMMUNICAT, V1, P1, DOI 10.1075/eoc.1.1.02ste; Tomasello M., 1999, CULTURAL ORIGINS HUM; VOGT P, 2003, THSIM V3 2 TALK HEAD, P535; VOGT P, 2003, J ARTIFICIAL SOC SOC, V6, P1; VOGT P, 2005, P AISB 200K SOC INSP, P80; VOGT P, 2005, IN PRESS BEHAV BRAIN; Vogt P., 2000, EVOLUTION COMMUNICAT, V4, P89	20	0	0	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28848-1	LECT NOTES ARTIF INT			2005	3630						644	654				11	Computer Science, Artificial Intelligence	Computer Science	BDH67	WOS:000233583100065		
S	Angiulli, F		Famili, AF; Kok, JN; Pena, JM; Siebes, A; Feelders, A		Angiulli, F			Condensed nearest neighbor data domain description	ADVANCES IN INTELLIGENT DATA ANALYSIS VI, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Symposium on Intelligent Data Analysis	SEP 08-10, 2005	Madrid, SPAIN				CONVERGENCE; RULE	A popular method to discriminate between normal and abnormal data is based on accepting test objects whose nearest neighbors distances in a reference data set lie within a certain threshold. In this work we investigate the possibility of using as reference set a subset of the original data set. We discuss relationship between reference set size and generalization, and show that finding the minimum cardinality reference consistent subset is intractable. Then, we describe an algorithm that computes a reference consistent subset with only two reference set passes. Experimental results confirm the effectiveness of the approach.	CNR, ICAR, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), CNR, ICAR, Via Pietro Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.	angiulli@icar.cnr.it					Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Breunig M., 2000, P ACM INT C MAN DAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L., 1996, PROBABILISTIC THEORY; Eskin Eleazar, 2002, APPL DATA MINING COM; FIX E, 1951, 5 USAF SCH AV MED; Garey M.R., 1979, COMPUTER INTRACTABIL; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ramaswami S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Scholkopf B., 1995, P INT C KNOWL DISC D, P251; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; Tax D. M. J., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.906164; Tax DM J, 1999, P EUR S ART NEUR NET, P251; TOUSSAINT M, 2002, SOCS025 MCGILL U; Vapnik V., 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; YPMA A, 1998, P ICANN	20	1	1	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28795-7	LECT NOTES COMPUT SC			2005	3646						12	23				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDA54	WOS:000232273600002		
S	Wang, JG; Neskovic, P; Cooper, LN		Wang, L; Chen, K; Ong, YS		Wang, JG; Neskovic, P; Cooper, LN			Locally determining the number of neighbors in the k-nearest neighbor rule based on statistical confidence	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			CLASSIFICATION; REGRESSION	The k-nearest neighbor rule is one of the most attractive pattern classification algorithms. In practice, the value of k is usually determined by the cross-validation method. In this work, we propose a new method that locally determines the number of nearest neighbors based on the concept of statistical confidence. We define the confidence associated with decisions that are made by the majority rule from a finite number of observations and use it as a criterion to determine the number of nearest neighbors needed. The new algorithm is tested on several realworld datasets and yields results comparable to those obtained by the knearest neighbor rule. In contrast to the k-nearest neighbor rule that uses a fixed number of nearest neighbors throughout the feature space, our method locally adjusts the number of neighbors until a satisfactory level of confidence is reached. In addition, the statistical confidence provides a natural way to balance the trade-off between the reject rate and the error rate by excluding patterns that have low confidence levels.	Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA.	jigang@brown.edu; pedja@brown.edu; Leon_Cooper@brown.edu					Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Fix E., 1951, 4 USAF SCH AV MED; Friedman J., 1994, 113 STANF U STAT DEP; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	11	0	0	0	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						71	80				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400009		
S	Li, YG; Hu, ZH; Cai, YZ; Zhang, WD		Wang, L; Chen, K; Ong, YS		Li, YG; Hu, ZH; Cai, YZ; Zhang, WD			Support vector based prototype selection method for nearest neighbor rules	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			LEARNING ALGORITHMS; CLASSIFICATION	The Support vector machines derive the class decision hyper planes from a few, selected prototypes, the support vectors (SVs) according to the principle of structure risk minimization, so they have good generalization ability. We proposed a new prototype selection method based on support vectors for nearest neighbor rules. It selects prototypes only from support vectors. During classification, for unknown example, it can be classified into the same class as the nearest neighbor in feature space among all the prototypes. Computational results show that our method can obtain higher reduction rate and accuracy than popular condensing or editing instance reduction method.	Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200030, Peoples R China	Li, YG (reprint author), Shanghai Jiao Tong Univ, Dept Automat, 1954 Huashan Rd, Shanghai 200030, Peoples R China.	li_yuangui@sjtu.edu.cn.edu; huhzh@sjtu.edu.cn.edu; yzcai@sjtu.edu.cn.edu; wdzhang@sjtu.edu.cn.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; BURGES CJC, 1997, NEURAL INF PROCESSIN, V9; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Burges C.J.C., 1996, 13 INT C MACH LEARN, P71; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Kecman V., 2001, LEARNING SOFT COMPUT; KEERTHI SS, 2001, NEURAL COMPUT, V13, P37; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; LeCun Y., 1995, P INT C ART NEUR NET, P53; TOUSSAINT G, 2002, P INTERFACE 2002 34, P83; Vapnik V. N., 1995, NATURE STAT LEARNING; Vapnik V. N., 1982, ESTIMATION DEPENDENC; Vapnik VN, 1974, THEORY PATTERN RECOG; VISHWANATHAN SVN, 2001, HYBRID INF SYSTEMS, P19; Wang L., 2005, SUPPORT VECTOR MACHI; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	19	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						528	535				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400068		
S	Wang, C; Chen, YQ		Wang, L; Chen, K; Ong, YS		Wang, C; Chen, YQ			Improving Nearest Neighbor classification with simulated gravitational collapse	ADVANCES IN NATURAL COMPUTATION, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			PROTOTYPES; RULE	The performance of the Nearest Neighbor classifier drops significantly with the increase of the overlapping of the distribution of different classes. To overcome this drawback, we propose to simulate the physical process of gravitational collapse to trim the boundaries of the distribution of each class to reduce overlapping. The proposed simulated gravitational collapse(SGC) algorithm is tested on 7 real-world data sets. Experimental results show that the nearest prototype classifier based on SGC outperforms conventional NN and k-NN classifiers.	Fudan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China	Chen, YQ (reprint author), Fudan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China.	chenyq@fudan.edu.cn					BEZDEK JC, 2000, INT J INTELL SYST, V16, P1445; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HITTER GL, 1976, IEEE T INFORMATION T, V21, P665; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; LAVIGNA A, 1990, THESIS U MARYLAND; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Murphy P. M., 1994, UCI REPOSITORY MACHI; WILSON DL, 1972, IEEE T SYST MAN CYB, V2, P403	15	5	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28320-X	LECT NOTES COMPUT SC			2005	3612						845	854				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA32	WOS:000232246700104		
S	Lu, CD; Zhang, TY; Zhang, W; Yang, G		Wang, J; Liao, X; Wang, J		Lu, CD; Zhang, TY; Zhang, W; Yang, G			An experimental evaluation of linear and kernel-based classifiers for face recognition	ADVANCES IN NEURAL NETWORKS - ISNN 2005, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Symposium on Neural Networks	MAY 30-JUN 01, 2005	Chongqing, PEOPLES R CHINA	Chongqing Univ, SW Normal Univ, Chongqing Univ, Posts& Telecommun, SW Agr Univ, Chongqing Educ Coll, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Natl Nat Sci Fdn China, K C Wong Educ Fdn Hong Kong				This paper presents the results of a comparative study of linear and kernel-based methods for face recognition. We focus mainly on the experimental comparison of classification methods, i.e. Nearest Neighbor, Linear Support Vector Machine, Kernel based Nearest Neighbor and Nonlinear Support Vector Machine. Some interesting conclusions can be obtained after all of these methods are performed on two well-known database, i.e. ORL, YALE Face Database, respectively.	Xian Jiaotong Univ, Dept Informat & Commun Engn, Xian 710059, Shaanxi, Peoples R China; Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA; Xian Inst Post & Telecommun, Dept Commun, Xian 710059, Shaanxi, Peoples R China	Lu, CD (reprint author), Xian Jiaotong Univ, Dept Informat & Commun Engn, Xian 710059, Shaanxi, Peoples R China.	congdelu@mailst.xjtu.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Gupta H., 2002, Proceedings Sixth IEEE Workshop on Applications of Computer Vision (WACV 2002), DOI 10.1109/ACV.2002.1182137; LI J, 2003, P 2003 IEEE INT C AC, V3, P121; LIU Q, 2002, P 5 IEEE INT C AUT F, P187; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik V, 2000, NATURE STAT LEARNING; Yu K, 2002, NEURAL PROCESS LETT, V15, P147, DOI 10.1023/A:1015244902967	9	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-25913-9	LECT NOTES COMPUT SC			2005	3497						124	130				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN40	WOS:000230167200021		
S	Mulligan, JB		Bebis, G; Boyle, R; Koracin, D; Parvin, B		Mulligan, JB			A tree-structured model of visual appearance applied to gaze tracking	ADVANCES IN VISUAL COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Symposium on Visual Computing	DEC 05-07, 2005	Lake Tahoe, NV	UNR, DRI, LBNL, NASA Ames, intel, Digital Persona, Equinox				In some computer vision applications, we may need to analyze large numbers of similar frames depicting various aspects of an event. In this situation, the appearance may change significantly within the sequence, hampering efforts to track particular features. Active shape models [1] offer one approach to this problem, by "learning" the relationship between appearance and world-state from a small set of hand-labeled training examples. In this paper we propose a method for partitioning the input image set which addresses two problems: first, it provides an automatic method for selecting a set of training images for hand-labeling; second, it results in a partitioning of the image space into regions suitable for local model adaptation. Repeated application of the partitioning procedure results in a tree-structured representation of the image space. The resulting structure can be used to define corresponding neighborhoods in the shape model parameter space; a new image may be processed efficiently by first inserting it into the tree, and then solving for model parameters within the corresponding restricted domain. The ideas are illustrated with examples from an outdoor gaze-tracking application.	NASA, Ames Res Ctr, Moffett Field, CA 94035 USA	Mulligan, JB (reprint author), NASA, Ames Res Ctr, Moffett Field, CA 94035 USA.						Carpenter RH, 1977, MOVEMENTS EYES; Christoudias CM, 2005, PROC CVPR IEEE, P1067; Cootes T.F., 2001, P SOC PHOTO-OPT INS, P236, DOI 10.1117/12.431093; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; Gersho A., 1992, VECTOR QUANTIZATION; Kowler E, 1990, EYE MOVEMENTS THEIR; Ohno T., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319	9	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30750-8	LECT NOTES COMPUT SC			2005	3804						303	312				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BDP92	WOS:000234830800037		
J	Gibert, K; Sanchez-Marre, M; Flores, X				Gibert, K; Sanchez-Marre, M; Flores, X			Cluster discovery in environmental databases using GESCONDA: The added value of comparisons	AI COMMUNICATIONS			English	Article; Proceedings Paper	4th Workshop on Binding Environmental Sciences and Artificial Intelligence	AUG 22-23, 2004	Valencia, SPAIN			knowledge acquisition and management; clustering; cluster validation; data mining; machine learning; environmental databases; statistical modelling; wastewater treatment plant	KNOWLEDGE DISCOVERY	Clustering techniques have a great importance in knowledge discovery because they can find out new groups or clusters of objects within databases. Thus, they are unsupervised learning methods, very useful when facing unknown, unlabelled and ill-structured databases, as environmental databases are. In this paper, different clustering algorithms are analyzed and compared. They are used on a real environmental data set in order to study their impact in characterizing states in this kind of domains. The comparison of the methods is undertaken using the system GESCONDA, which is a prototype of a data mining tool. Environmental data used in this paper are from a Catalan wastewater treatment plant and refers to different variables of the plant at different spatial points along 149 days.	Tech Univ Catalonia, Dept Stat & Operat Res, Barcelona, Spain; Tech Univ Catalonia, Knowledge Engn & Machine Learning Grp, Barcelona, Spain; Univ Girona, Lab Engn Quim & Ambiental, Girona, Spain	Gibert, K (reprint author), Tech Univ Catalonia, Dept Stat & Operat Res, Barcelona, Spain.	karina.gibert@upc.edu	Sanchez-Marre, Miquel/A-8569-2011; 	Sanchez-Marre, Miquel/0000-0001-9848-5779			ADRIANS P, 1998, DATA MINING; Ball GH., 1965, ISODATA NOVEL METHOD; BRATKO I, 2000, ANAL ENV DATA MACHIN; Comas J, 2001, AI COMMUN, V14, P45; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMYANOV V, 2000, 2 ICSC S NEUR COMP N, P647; DUBES R, 1980, ADV COMPUTERS, V19; Frank E., 1999, DATA MINING PRACTICA; GIBERT K, 2004, T 2 BIENN M INT ENV, V1, P51; Gibert K, 1997, MATHWARE SOFT COMPUT, V4, P251; Gibert K, 1998, COMPUT SIST, V1, P213; Gibert K, 1998, LECT NOTES ARTIF INT, V1510, P83; GIBERT K, 2003, LNCS, P2905; GIMENO JM, PRACTICAL APPL DATA; Kanevski M, 2004, ENVIRON MODELL SOFTW, V19, P845, DOI 10.1016/j.envsoft.2003.03.004; MORABITO FC, 2001, NATO ADV RES WORKSH; NAKHAEIZADEH G, 1996, IFCS, V1, P17; ROUX M, 1985, ALGORITHMS CLASSIFIC; SANCHEZMARRE M, 2002, 1 INT C INT EMS SOC, P420; Sokal Robert, 1963, PRINCIPLES NUMERICAL; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967	21	3	3	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126			AI COMMUN	AI Commun.		2005	18	4					319	331				13	Computer Science, Artificial Intelligence	Computer Science	986HE	WOS:000233439900008		
B	Zhao, QF		Shih, TK; Shibata, Y		Zhao, QF			Design smart NNTrees based on the R-4-rule	AINA 2005: 19th International Conference on Advanced Information Networking and Applications, Vol 2			English	Proceedings Paper	19th International Conference on Advanced Information Networking and Applications	MAR 28-30, 2005	Taipei, TAIWAN	IEEE Comp Soc Tech Comm Distributed Proc, Tamkang Univ, Asian Off Aerosp Res & Dev, USA Asian Res Off			NEIGHBOR PATTERN-CLASSIFICATION; DECISION TREES; ALGORITHM; MLP	Neural network tree (NNTree) is a hybrid learning model with the overall structure being a decision tree (DT), and each non-terminal node containing an expert neural network (ENN). Generally speaking, NNTrees outperform conventional DTs because more complex and possibly better features can be extracted by the ENNs. So far we have studied several genetic algorithms (GAs) for designing the NNTrees. These algorithms are computationally expensive, and the NNTrees obtained are often very large. In this paper, we propose a new approach based on the R-4-rule, which is a non-genetic evolutionary algorithm proposed by the author several years ago. The key point is to propose a heuristic method for defining the teacher signals for the examples assigned to a non-terminal node. Once the teacher signals are defined, the ENNs can be trained quickly using the R-4-rule. Experiments with several public databases show that the new approach can produce smart NNTrees quickly and effectively.	Univ Aizu, Aizu Wakamatsu 9658580, Japan	Zhao, QF (reprint author), Univ Aizu, Aizu Wakamatsu 9658580, Japan.						Brieman L, 1984, CLASSIFICATION REGRE; Carpenter GA, 1988, IEEE COMPUT, V21, P77; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; HENRICHO.EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Lu C, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P518; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MIZUNO S, 2002, P 4 AS PAC C SIM EV, P573; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SETHI IK, 1990, P IEEE, V78, P1605, DOI 10.1109/5.58346; TAKEDA T, 2003, INT C HYBR INT SYST; TAKEDA T, 2003, P INNS IEEE INT JOIN; ZHAO QF, 2004, P IEEE INT C SYST MA; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240; ZHAO QF, 2000, NC200057 IEICE	23	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2249-1				2005							547	551				5	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	BCH23	WOS:000229285400119		
S	Waagen, D; Shah, N; Ordaz, M; Cassabaum, M		Zeinio, EG; Garber, FD		Waagen, D; Shah, N; Ordaz, M; Cassabaum, M			Random subspaces and SAR classification efficacy	Algorithms for Synthetic Aperture Radar Imagery XII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Algorithms for Symthetic Aperture Radar Imagery XII	MAR 28-31, 2005	Orlando, FL			random projections; dimensionality reduction; distance preserving projections; synthetic aperture radar; classification	SET	The 'curse of dimensionality' has limited the application of statistical modeling techniques to low-dimensional spaces, but typical data usually resides in high-dimensional spaces (at least initially, for instance images represented as arrays of pixel values). Indeed, approaches such as Principal Component Analysis and Independent Component Analysis attempt to extract a set of meaningful linear projections while minimizing interpoint distance distortions. The counterintuitive yet effective random projections approach of Johnson and Lindenstrauss defines a sample-based dimensionality reduction technique with probabilistically provable distortion bounds. We investigate and report on the relative efficacy of two random projection techniques for Synthetic Aperture Radar images in a classification setting.								Bingham Ella, 2001, P 7 ACM SIGKDD INT C, P245, DOI 10.1145/502512.502546; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1999, TR99066; DASGUPTA S, 2000, P UNCERTAINTY ARTIFI; DEYROYE L, 1996, PROBABILISITIC THEOR; DUDA RO, 2001, PATTERN CALSSIFICATI; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; FRIEDMAN J, 1979, ANAL STAT, V7; Fukunaga K., 1990, INTRO STAT PATTERN R; Han P, 2003, P IEEE ICASSP, VII, P429; Hastie T, 2001, ELEMENTS STAT LEARNI; HERO AO, 2002, IEEE SIGNAL PROC SEP, P85; Johnson W. B., 1984, CONT MATH, V1, P189; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757; Ross T, 1998, P SOC PHOTO-OPT INS, V3370, P566, DOI 10.1117/12.321859; Scott D.W., 1992, MULTIVARIATE DENSITY; SILVERMAN BW, 1986, DENISTY ESTIMATION; Zhao Q, 2001, IEEE T AERO ELEC SYS, V37, P643, DOI 10.1109/7.937475	20	0	0	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5793-0	P SOC PHOTO-OPT INS			2005	5808						257	268		10.1117/12.602523		12	Computer Science, Interdisciplinary Applications; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCU80	WOS:000231335900026		
S	Woon, FL; Knight, B; Petridis, M; Patel, M		MunozAvila, H; Ricci, F		Woon, FL; Knight, B; Petridis, M; Patel, M			CBE-conveyor: A case-based reasoning system to assist engineers in designing conveyor systems	CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th International Conference on Case-Based Reasoning	AUG 23-26, 2005	Chicago, IL	Kaidara Software, Empolis, Naval Res Lab, PricewaterhouseCooper, AAAI			PREDICTION	In this paper, we address the use of CBR in collaboration with numerical engineering models. This collaborative combination has a particular application in engineering domains where numerical models are used. We term this domain "Case Based Engineering" (CBE), and present the general architecture of a CBE system. We define and discuss the general characteristics of CBE and the special problems which arise. These are: the handling of engineering constraints of both continuous and nominal kind; interpolation over both continuous and nominal variables, and conformability for interpolation. In order to illustrate the utility of the method proposed, and to provide practical examples of the general theory, the paper describes a practical application of the CBE architecture, known as CBE-CONVEYOR, which has been implemented by the authors. Pneumatic conveying is an important transportation technology in the solid bulks conveying industry. One of the major industry concerns is the attrition of powders and granules during pneumatic conveying. To minimize the fraction of particles during pneumatic conveying, engineers want to know what design parameters they should use in building a conveyor system. To do this, engineers often run simulations in a repetitive manner to find appropriate input parameters. CBE-Conveyor is shown to speed up conventional methods for searching for solutions, and to solve problems directly that would otherwise require considerable intervention from the engineer.	Univ Greenwich, Sch Comp & Math Sci, London SE10 9LS, England	Woon, FL (reprint author), Univ Greenwich, Sch Comp & Math Sci, London SE10 9LS, England.	f.woon@gre.ac.uk; b.knight@gre.ac.uk; m.petridis@gre.ac.uk; m.patel@gre.ac.uk					BERGMANN R, 2001, P 9 GERM WORKSH CAS; Chapelle P, 2004, ADV POWDER TECHNOL, V15, P31, DOI 10.1163/15685520460740052; CHATTERJEE N, 1994, LECT NOTES ARTIF INT, V837, P221; CHEETHAM W, 2001, P INT C CAS BAS REAS, P589; CHEETHAM W, 1997, P 2 INT C CAS BAS RE, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kalapanidas E, 2001, ENVIRON MODELL SOFTW, V16, P263, DOI 10.1016/S1364-8152(00)00072-4; Kalman H, 2000, POWDER TECHNOL, V112, P244, DOI 10.1016/S0032-5910(00)00298-9; KNIGHT B, 2004, P 24 SPEC GROUP ART, P73; KNIGHT B, 2003, P 18 INT JOINT C ART, P1347; Kolodner J. L., 1993, CASE BASED REASONING; Schwabacher M, 1998, AI EDAM, V12, P173; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; WEINBERGER CB, 1986, POWDER TECHNOL, V48, P19, DOI 10.1016/0032-5910(86)80060-2; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WOON F, 2003, P 5 INT C CAS BAS RE, P652	16	3	3	0	12	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28174-6	LECT NOTES ARTIF INT			2005	3620						640	651				12	Computer Science, Artificial Intelligence	Computer Science	BDF64	WOS:000233274900048		
S	Hsu, CC; Yang, CY; Yang, JS				Hsu, CC; Yang, CY; Yang, JS			Associating kNN and SVM for higher classification accuracy	COMPUTATIONAL INTELLIGENCE AND SECURITY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	International Conference on Computational Intelligence and Security	DEC 15-19, 2005	Xi'an, PEOPLES R CHINA	IEEE Computat Intelligence, Hong Kong Chapter, Xidian Univ, Hong Kong Baptist Univ, Natl Nat Sci Fdn China, Guangdong Univ Technol				The paper proposed a hybrid two-stage method of support vector machines (SVM) to increase its performance in classification accuracy. In this model, a filtering stage of the k nearest neighbor (kNN) rule was employed to collect information from training observations and re-evaluate balance weights for the observations based on their influences. The balance weights changed the policy of the discrete class label. A novel idea of real-valued class labels for transferring the balance weights was therefore proposed. Embedded in the class label, the weights given as the penalties of the uncertain outliers in the classification were considered in the quadratic programming of SVM, and produced a different hyperplane with higher accuracy. The adoption of kNN rule in the filtering stage has the advantage to distinguish the uncertain outliers in an independent way. The results showed that the classification accuracy of the hybrid model was higher than that of the classical SVM.	No Taiwan Inst Sci & Technol, Dept Mech Engn, Taipei, Taiwan; Tamkang Univ, Dept Mech & Electromech Engn, Taipei, Taiwan	Hsu, CC (reprint author), No Taiwan Inst Sci & Technol, Dept Mech Engn, 2 Xue Yuan Rd, Taipei, Taiwan.	692342792@s92.tku.edu.tw; cy.yang@ntist.edu.tw; 096034@mail.tku.edu.tw					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; HETTICH S, 1999, UCI KD ARCH; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yang CY, 2004, LECT NOTES COMPUT SC, V3173, P506	7	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30818-0	LECT NOTES ARTIF INT			2005	3801						550	555				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDQ19	WOS:000234873700080		
S	Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Wang, ZH; Qu, YL				Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Wang, ZH; Qu, YL			An improved kNN algorithm - Fuzzy kNN	COMPUTATIONAL INTELLIGENCE AND SECURITY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	International Conference on Computational Intelligence and Security	DEC 15-19, 2005	Xi'an, PEOPLES R CHINA	IEEE Computat Intelligence, Hong Kong Chapter, Xidian Univ, Hong Kong Baptist Univ, Natl Nat Sci Fdn China, Guangdong Univ Technol				As a simple, effective and nonparametric classification method, kNN algorithm is widely used in text classification. However, there is an obvious problem: when the density of training data is uneven it may decrease the precision of classification if we only consider the sequence of first k nearest neighbors but do not consider the differences of distances. To solve this problem, we adopt the theory of fuzzy sets, constructing a new membership function based on document similarities. A comparison between the proposed method and other existing kNN methods is made by experiments. The experimental results show that the algorithm based on the theory of fuzzy sets (fkNN) can promote the precision and recall of text categorization to a certain degree.	Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China; Nipissing Univ, Dept Comp Sci, North Bay, ON P1B 8L7, Canada	Shang, WQ (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	shangwenqian@hotmail.com; haibinz@npissingu.ca					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gao Xin-Bo, 2000, Acta Electronica Sinica, V28; HEVISEOK L, 2002, P 9 INT C NEUR INF P, P732; IWAYAMA M, 1995, 18 ANN INT ACM SIGIR, P273; MASAND B, 1992, 15 ANN INT ACM SIGIR; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; van Rijsbergen CJ, 1979, INFORM RETRIEVAL, V2nd; WANG J, 2000, J COMPUTER RES DEV B, V37, P518; YANG Y, 1999, 22 ANN INT ACM SIGIR; YU J, 2003, CHINESE J COMPUTERS, V26, P969; ZHAO S, 1987, METHOD FUZZY MATH PA	11	3	3	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-30818-0	LECT NOTES ARTIF INT			2005	3801						741	746				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDQ19	WOS:000234873700109		
S	Hacid, H; Zighed, AD		Andersen, KV; Debenham, J; Wagner, R		Hacid, H; Zighed, AD			An effective method for locally neighborhood graphs updating	DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	16th International Workshop on Database and Expert Systems Applications	AUG 22-26, 2005	Copenhagen, DENMARK	Danish Minist Sci, Technol & Innov, DEXA Assoc, Austrian Comp Soc, Res Inst Appl Knowledge Proc, FAW Software Engn GmbH	Copenhagen Business Sch		VECTOR QUANTIZATION; ALGORITHM	Neighborhood graphs are an effective and very widespread technique in several fields. But; in spite of the neighborhood graphs interest, their construction algorithms suffer from a very high complexity what prevents their implementation for great data volumes processing applications. With this high complexity the update)update task is also affected. These structures constitute actually a possible representation of the point location problem in a multidimensional spaced. The point location on an axis can be solved by a binary research. This same problem in the plan can be solved by using a voronol diagram but when dimension becomes higher, the location becomes, more complex and difficult to manage. We propose in this paper, an effective method for point location in a multidimensional space with an aim of effectively and quickly updating neighborhood graphs.	Univ Lyon 2, ERIC Lab, F-69676 Bron, France	Hacid, H (reprint author), Univ Lyon 2, ERIC Lab, 5,Ave Pierre Mendes France, F-69676 Bron, France.	hhacid@eric.univ-lyon2.fr; Abdelkader.Zighed@univ-lyon2.fr					Anderson E., 1935, B AM IRIS SOC, V59, P2; Berchtold S., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263671; BREIMAN L, 1984, WADSWORTH INT GROUP, P43; BEI CD, 1985, IEEE T COMMUN, V33, P1132; Cost R. S., 1993, MACH LEARN, V10, P57; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; Cover T., 1967, IEEE T INFORM THEORY, V13, P57; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; Fisher RA, 1936, ANN EUGENIC, V7, P179; Flickner M., 1995, IEEE COMPUT, P23; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; GABRIEL KR, 1969, SYST ZOOL, V18, P259, DOI 10.2307/2412323; GERSHO A, 1991, VECTOR QUATIZATION S; GUAN L, 1992, PATTERN RECOGN LETT, V13, P693, DOI 10.1016/0167-8655(92)90098-K; HETTICH S, 1998, UCI REPOSITORY MACIN; KATAJAINEN J, 1988, COMPUTING, V40, P147, DOI 10.1007/BF02247943; LEE CH, 1994, IEE P-VIS IMAGE SIGN, V141, P143, DOI 10.1049/ip-vis:19941140; LI KI, 1994, VLDB J, V3, P517; Preparata F. P., 1985, COMPUTATIONAL GEOMET; SMITH WS, 1989, THESIS PRINCETON U; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; TOUSSAINT GT, 1991, MCCS91224; White DA, 1996, P SOC PHOTO-OPT INS, V2670, P62, DOI 10.1117/12.234810	24	7	7	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28566-0	LECT NOTES COMPUT SC			2005	3588						930	939				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BCY26	WOS:000231849800091		
S	Zachery, KN; Schultz, GM; Collins, LM		Harmon, RS; Broach, JT; Holloway, JH		Zachery, KN; Schultz, GM; Collins, LM			Force Protection Demining System (FPDS) detection subsystem	Detection and Remediation Technologies for Mines and Minelike Targets X, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Detection and Remediation Technologies for Mines and Minelike Targets X	MAR 28-APR 01, 2005	Orlando, FL	SPIE		landmine detection; GPSAR; EMI; sensor fusion	FEATURE-SELECTION; CLASSIFICATION; ASSIGNMENT; ALGORITHM; NETWORK	This study describes the U.S. Army Force Protection Demining System (FPDS); a remotely-operated, multisensor platform developed for reliable detection and neutralization of both anti-tank and anti-personnel landmines. The ongoing development of the prototype multisensor detection subsystem is presented, which integrates an advanced electromagnetic pulsed-induction array and ground penetrating synthetic aperture radar array on a single standoff platform. The FPDS detection subsystem is mounted on a robotic rubber-tracked vehicle and incorporates an accurate and precise navigation/positioning module making it well suited for operation in varied and irregular terrains. Detection sensors are optimally configured to minimize interference without loss in sensitivity or performance. Mine lane test data acquired from the prototype sensors are processed to extract signal- and image-based features for automatic target recognition. Preliminary results using optimal feature and classifier selection indicate the potential of the system to achieve high probabilities of detection while minimizing false alarms. The FPDS detection software system also exploits modern multi-sensor data fusion algorithms to provide real-time detection and discrimination information to the user.	Appl Res Associates Inc, Raleigh, NC USA	Zachery, KN (reprint author), Appl Res Associates Inc, Raleigh, NC USA.						ANDREWS A, 1999, E2416 IDA, P103; BAERTLEIN B, 2001, P UXO COUNT FOR ORL; BERTSEKAS DP, 1990, INTERFACES, V20, P133, DOI 10.1287/inte.20.4.133; BINS J, 2001, INT C COMP VIS VANC, V2, P159; *BRTRC, COUNT TEST MAN SYST; BUFGES C, 1998, DATA MIN KNOWL DISC, V2, P121; CANDY BH, 1996, Patent No. 5576624; CANDY BH, 1990, Patent No. 4894618; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAS Y, 2001, 19719E EUR COMM JOIN, P128; DAS Y, 1990, IEEE T GEOSCI REMOTE, V28, P278, DOI 10.1109/36.54354; Duin RPW, 2007, PRTOOLS4 MATLAB TOOL; Fisher RA, 1936, ANN EUGENIC, V7, P179; Gader P, 2004, IEEE T GEOSCI REMOTE, V42, P2522, DOI 10.1109/TGRS.2004.837333; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6; GOLUB G, 1990, MATRIX COMPUTATIONS, P581; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KRISHNAPURAM B, 2003, P 7 ANN INT C COMP M; Laws KI, 1980, SPIE IMAGE PROCESSIN, V238, P376; LI Q, 2003, IEEE INT C DAT MIN, P163; MACDONALD J, 2003, WEAVER ALTERNATIVES, P335; Molina L. C., 2002, IEEE INT C DAT MIN M, P306; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Raghu PP, 1998, IEEE T NEURAL NETWOR, V9, P516, DOI 10.1109/72.668893; SAMADZADEGAN F, FUSION TECNIQUES REM; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tourassi GD, 2001, MED PHYS, V28, P2394, DOI 10.1118/1.1418724; UNAY D, STEM END CALYX DETEC; *US DOD, 2000, LANDM CAS REP DEM IN, P138; *US GAO, 1996, GAONSIAD95197; VANDERHEIJDEN F, 2004, CLASSIFICATION PARAM, P423; XU X, 2002, IEEE ICIP; ZACHERY R, 2000, COMMUNICATION; Zhang Y, 2003, IEEE T GEOSCI REMOTE, V41, P1005, DOI 10.1109/TGRS.2003.810922	39	0	0	2	3	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5779-5	P SOC PHOTO-OPT INS			2005	5794		1-2				1018	1029		10.1117/12.603021		12	Engineering, Multidisciplinary; Physics, Applied	Engineering; Physics	BCR67	WOS:000230951400101		
B	Jaeger, S; Ma, HF; Doermann, D			IEEE Computer Society	Jaeger, S; Ma, HF; Doermann, D			Identifying script on word-level with informational confidence	EIGHTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, PROCEEDINGS			English	Proceedings Paper	8th International Conference on Document Analysis and Recognition (ICDAR 2005)	AUG 29-SEP 01, 2005	Seoul, SOUTH KOREA	ABBYY Software House, BK 21 Sch Informat Technol KAIST, Elect & Telecommun Res Inst, Hitachi Cent Res Lab, IBM Corp, Int Assoc Pattern Recognit, Korea Adv Inst Sci & Technol, Korea Informat Sci Soc, Korea Sci & Engn Fdn, Minist Informat & Commun, Inst Informat Assessment, Microsoft			DOCUMENT IMAGES; CLASSIFICATION; RECOGNITION	In this paper we present a multiple classifier system for script identification. Applying a Gabor filter analysis of textures on word-level, our system identifies Latin and non-Latin words in bilingual printed documents. The classfier system comprises four different architectures based on nearest neighbors, weighted Euclidean distances, Gaussian mixture models, and support vector machines. We report results for Arabic, Chinese, Hindi, and Korean script. Moreover we show that combining informational confidence values using sum-rule can consistently outperform the best single recognition rate.	Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA	Jaeger, S (reprint author), Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA.	jaeger@umiacs.umd.edu; hfma@umiacs.umd.edu; doermann@umiacs.umd.edu					Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; Jaeger S, 2004, INT C PATT RECOG, P216, DOI 10.1109/ICPR.2004.1334062; Jaeger S., 2004, Proceedings. Ninth International Workshop on Frontiers in Handwriting Recognition; Joachims T., 1999, ADV KERNEL METHODS S, P41; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Ma H., 2004, P INT C DOC REC RETR, P178; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; SHANNON CE, 1948, AT&T TECH J, V27, P379; SIBUN P, 1994, P 4 C APPL NAT LANG, P115; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; TAN C, 1999, INT S INT MULT DIST, P59; Waked B, 1998, IEEE SYS MAN CYBERN, P4470; Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192	16	5	5	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2420-6				2005							416	420		10.1109/ICDAR.2005.134		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCZ12	WOS:000232022600082		
B	Yin, TK; Chiu, NT		Krishnapuram, R; Pal, N		Yin, TK; Chiu, NT			Fuzzy patterns and classification of functional brain images for the diagnosis of Alzheimer's disease	FUZZ-IEEE 2005: Proceedings of the IEEE International Conference on Fuzzy Systems: BIGGEST LITTLE CONFERENCE IN THE WORLD	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	MAY 22-25, 2005	Reno, NV	IEEE, IEEE Neural Networks Soc			COMPUTER-AIDED DIAGNOSIS; CEREBRAL BLOOD-FLOW; MINIMIZATION APPROACH; NEURAL-NETWORK; C-MEANS; SYSTEM; SEGMENTATION; ALGORITHM; SPECT	Alzheimer's disease is a chronic degenerative disease of the central nervous system. Most common regional abnormalities for Alzheimer's disease are symmetric or asymmetric bilateral temporal or parietal hypoperfusion. Single-photon emission computed tomography (SPECT) is a useful tool in analyzing hypoperfusion in patients with Alzheimer's disease. The aim of this research is to provide a quantitatively automatic analysis of the SPECT scans for the diagnosis of Alzheimer's disease. A characteristic-point-based fuzzy inference classifier (CPFIC) is proposed to perform two-class classification. The closeness matrix is defined to determine the closeness between training samples, and constrained minimizations are used to systematically train the CPFIC. For comparison, experiments on nearest neighbor method and support vector machine (SVM) were also performed. In error rates, the proposed CPFIC is better than nearest neighbor method, but worse than SVM method. Although the CPFIC did not perform better than SVM in error rates, the summarizing information embedded in the patterns on characteristic points can complement SVM to provide more information to radiologists.	Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan	Yin, TK (reprint author), Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.						Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHANG CC, 2001, LIBSVM LIBR SUPPORT; Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; Chuang KH, 1999, IEEE T MED IMAGING, V18, P1117; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; Devous MD, 2002, EUR J NUCL MED MOL I, V29, P1685, DOI 10.1007/s000259-002-0967-2; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friston K. J., 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Friston K. J., 1994, HUMAN BRAIN MAPPING, V1, P214; FRISTON KJ, 1995, HUMAN BRAIN MAPPING, V2, P165; Haykin S., 1994, NEURAL NETWORKS COMP; IIDA H, 1994, J NUCL MED, V35, P2019; KUHL DE, 1982, J NUCL MED, V23, P196; Lee EW, 1998, IEEE T PATTERN ANAL, V20, P562; LIN CT, 1991, IEEE T COMPUT, V40, P1320, DOI 10.1109/12.106218; Luenberger D. G., 1989, LINEAR NONLINEAR PRO; OHNISHI T, 1995, J NUCL MED, V36, P1163; Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752; Sato K, 1996, IEEE T NUCL SCI, V43, P3230, DOI 10.1109/23.552723; SOKOLOFF L, 1981, FED PROC, V40, P2311; STONE M, 1974, J R STAT SOC B, V36, P111; Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; TERRY RD, 1994, ALZHEIMER DIS; Tolias YA, 1998, IEEE T MED IMAGING, V17, P263, DOI 10.1109/42.700738; Verma B, 2001, IEEE T INF TECHNOL B, V5, P46, DOI 10.1109/4233.908389; WANG GJ, 1994, J NUCL MED, V35, P1457; Yin TK, 2004, IEEE T FUZZY SYST, V12, P250, DOI 10.1109/TFUZZ.2004.825088; Yin TK, 2004, IEEE T BIO-MED ENG, V51, P1286, DOI 10.1109/TBME.2004.827954; Yin TK, 2004, IEEE T MED IMAGING, V23, P639, DOI 10.1109/TMI.2004.826355	32	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9158-6	IEEE INT CONF FUZZY			2005							161	166				6	Computer Science, Artificial Intelligence	Computer Science	BCR92	WOS:000230981000028		
S	Zhang, JP; Li, SZ; Wang, J		Wang, L; Jin, Y		Zhang, JP; Li, SZ; Wang, J			Geometrical probability covering algorithm	FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Fuzzy Systems and Knowledge Discovery	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtan Univ, IEEE Circuits & Syst Soc, IEEE Computat IntelligenceSoc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artifiical Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia-Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc Chine, Hunan Comp Federat			CLASSIFICATION	In this paper, we propose a novel classification algorithm, called geometrical probability covering (GPC) algorithm, to improve classification ability. On the basis of geometrical properties of data, the proposed algorithm first forms extended prototypes through computing means of any two prototypes in the same class. Then Gaussian kernel is employed for covering the geometrical structure of data and used as a local probability measurement. By computing the sum of the probabilities that a new sample to be classified to the set of prototypes and extended prototypes, the classified criterion based on the global probability measurement is achieved. The proposed GPC algorithm is simple but powerful, especially, when training samples are sparse and small size. Experiments on several databases show that the proposed algorithm is promising. Also, we explore other potential applications such as outlier removal with the proposed GPC algorithm.	Fudan Univ, Dept Comp Sci & Engn, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China; Chinese Acad Sci, Inst Automat, Key Lab Complex Syst & Intelligence Sci, Beijing 100080, Peoples R China; Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China; Chinese Acad Sci, Inst Automat, Ctr Biometr & Secur Res, Beijing 100080, Peoples R China	Zhang, JP (reprint author), Fudan Univ, Dept Comp Sci & Engn, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China.	jpzhang@fudan.edu.cn; szli@nlpr.ia.ac.cn; junping.zhang@mail.ia.ac.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANIEL L, 1996, IEEE T PATTERN ANAL, V18, P831; Dasarathy B. V., 1991, NN PATTERN CLASSIFIC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda R O, 2001, PATTERN CLASSIFICATI; Fraley C., 2000, 380 U WASH; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; MICHAEL JL, 1999, IEEE T PATTERN ANAL, V21, P1357; Murphy P. M., 1994, UCI REPOSITORY MACHI; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Samaria F., 1994, THESIS U CAMBRIDGE; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wechsler H., 1998, NATO ASI SERIES F, V163, P446; ZHANG J, 2004, 6 IEEE INT C AUT FAC; Zhang J., 2004, LNCS, V3338, P209; Zhang J., 2004, INTELLIGENT MULTIMED	16	0	0	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28312-9	LECT NOTES ARTIF INT			2005	3613						223	231				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDA15	WOS:000232217900029		
S	Du, H; Chen, YQ		Wang, L; Jin, Y		Du, H; Chen, YQ			Pattern classification using rectified nearest feature line segment	FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Fuzzy Systems and Knowledge Discovery	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtan Univ, IEEE Circuits & Syst Soc, IEEE Computat IntelligenceSoc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artifiical Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia-Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc Chine, Hunan Comp Federat			FACE RECOGNITION; CLASSIFIERS; RETRIEVAL	This paper proposes a new classification method termed Rectified Nearest Feature Line Segment (RNFLS). It overcomes the drawbacks of the original Nearest Feature Line (NFL) classifier and possesses a novel property that centralizes the probability density of the initial sample distribution, which significantly enhances the classification ability. Another remarkable merit is that RNFLS is applicable to complex problems such as two-spirals, which the original NFL cannot deal with properly. Experimental comparisons with NFL, NN(Nearest Neighbor), k-NN and NNL (Nearest Neighbor Line) using artificial and real-world datasets demonstrate that RNFLS offers the best performance.	Fudan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China	Chen, YQ (reprint author), Fudan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China.	chenyq@fudan.edu.cn					Blake C, 1998, UCI REPOSITORY MACHI; Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chen JH, 2004, PATTERN RECOGN, V37, P1913, DOI 10.1016/j.patcog.2003.12.003; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	9	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28331-5	LECT NOTES ARTIF INT			2005	3614		2				81	90				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDA17	WOS:000232218400011		
S	Zheng, WM; Zou, CR; Zhao, L		Wang, L; Jin, Y		Zheng, WM; Zou, CR; Zhao, L			Generalized locally nearest neighbor classifiers for object classification	FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Fuzzy Systems and Knowledge Discovery	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtan Univ, IEEE Circuits & Syst Soc, IEEE Computat IntelligenceSoc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artifiical Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia-Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc Chine, Hunan Comp Federat			PATTERN-CLASSIFICATION	In this paper, we extend the locally nearest neighbor classifiers to tackle the nonlinear classification problems via the kernel trick. The better performance is confirmed by the handwritten zip code digits classification experiments on the US Postal Service (USPS) database.	Southeast Univ, Res Ctr Sci & Learning, Nanjing 210096, Jiangsu, Peoples R China; Southeast Univ, Engn Res Ctr Informat Proc & Applicat, Nanjing 210096, Jiangsu, Peoples R China	Zheng, WM (reprint author), Southeast Univ, Res Ctr Sci & Learning, Nanjing 210096, Jiangsu, Peoples R China.	wenming_zheng@seu.edu.cn; cairong@seu.edu.cn; zhaoli@seu.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHOLKOPF B, P 1 INT C KNOWL DISC; Vapnik V. N., 1995, NATURE STAT LEARNING; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	7	1	1	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28331-5	LECT NOTES ARTIF INT			2005	3614		2				95	99				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDA17	WOS:000232218400013		
S	Zhou, CY; Chen, YQ		Wang, L; Jin, Y		Zhou, CY; Chen, YQ			Nearest neighbor classification using cam weighted distance	FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Fuzzy Systems and Knowledge Discovery	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtan Univ, IEEE Circuits & Syst Soc, IEEE Computat IntelligenceSoc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artifiical Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia-Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc Chine, Hunan Comp Federat				Nearest Neighbor (NN) classification assumes class conditional probabilities to be locally constant, and suffers from bias in high dimensions with a small sample set. In this paper, we propose a novel cam weighted distance to ameliorate the curse of dimensionality. Different from the existing neighbor-based methods, which only analyze a small space emanating from the query sample, the proposed nearest neighbor classification using cam weighted distance (CamNN) optimizes the distance measure based on the analysis of the inter-prototype relationships. Experiments show that CamNN significantly outperforms one nearest neighbor classification (1-NN) and k-nearest neighbor classification (k-NN) in most benchmarks, while its computational complexity is competitive with 1-NN classification.	Fudan Univ, Dept Comp Sci & Engn, Sch Informat Sci & Engn, Shanghai 200433, Peoples R China	Zhou, CY (reprint author), Fudan Univ, Dept Comp Sci & Engn, Sch Informat Sci & Engn, Shanghai 200433, Peoples R China.	chenyq@fudan.edu.cn					DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P1087, DOI 10.1109/34.42839; Hart P., 1988, IEEE T INFORM THEORY, V13, P21; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; JEROME H, 1999, FRIEDMAN FLEXIBLE ME; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	8	0	0	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28331-5	LECT NOTES ARTIF INT			2005	3614		2				100	109				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDA17	WOS:000232218400014		
J	Li, LB; Jiang, W; Li, X; Moser, KL; Guo, Z; Du, L; Wang, QJ; Topol, EJ; Wang, Q; Rao, S				Li, LB; Jiang, W; Li, X; Moser, KL; Guo, Z; Du, L; Wang, QJ; Topol, EJ; Wang, Q; Rao, S			A robust hybrid between genetic algorithm and support vector machine for extracting an optimal feature gene subset	GENOMICS			English	Article						feature gene selection; genetic algorithm; support vector machine; microarray	EXPRESSION DATA; SAMPLE CLASSIFICATION; MICROARRAY DATA; SELECTION; PATTERNS; PREDICTION; CANCER	Development of a robust and efficient approach for extracting useful information from microarray data continues to be a significant and challenging task. Microarray data are characterized by a high dimension, high signal-to-noise ratio, and high correlations between genes, but with a relatively small sample size. Current methods for dimensional reduction can further be improved for the scenario of the presence of a single (or a few) high influential gene(s) in which its effect in the feature subset would prohibit inclusion of other important genes. We have formalized a robust gene selection approach based on a hybrid between genetic algorithm and support vector machine. The major goal of this hybridization was to exploit fully their respective merits (e.g., robustness to the size of solution space and capability of handling a very large dimension of feature genes) for identification of key feature genes (or molecular signatures) for a complex biological phenotype. We have applied the approach to the microarray data of diffuse large B cell lymphoma to demonstrate its behaviors and properties for mining the high-dimension data of genome-wide gene expression profiles. The resulting classifier(s) (the optimal gene subset(s)) has achieved the highest accuracy (99%) for prediction of independent microarray samples in comparisons with marginal filters and a hybrid between genetic algorithm and K nearest neighbors. (C) 2004 Elsevier Inc. All rights reserved.	Cleveland Clin Fdn, Dept Cardiovasc Med, Cleveland, OH 44195 USA; Cleveland Clin Fdn, Dept Mol Cardiol, Cleveland, OH 44195 USA; Harbin Med Coll, Dept Bioinformat, Harbin 150086, Peoples R China; Tongji Univ, Coll Biol Sci & Technol, Shanghai 200092, Peoples R China; Harbin Inst Technol, Dept Comp Sci, Harbin 150080, Peoples R China; Univ Minnesota, Inst Human Genet, Dept Med, Minneapolis, MN 55455 USA; Chinese Peoples Liberat Army Gen Hosp, Inst Otolaryngol, Dept Otorhinolaryngol Head & Neck Surg, Beijing 100853, Peoples R China	Li, X (reprint author), Cleveland Clin Fdn, Dept Cardiovasc Med, 9500 Euclid Ave, Cleveland, OH 44195 USA.	Lixia@ems.hrbmu.edu.cn; raos@ccf.org		Topol, Eric/0000-0002-1478-4729			Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ashburner M, 2000, NAT GENET, V25, P25; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Brusco MJ, 2003, BRIT J MATH STAT PSY, V56, P83, DOI 10.1348/000711003321645359; Burke HB, 2000, MOL DIAGN, V5, P349, DOI 10.1054/modi.2000.19562; Cai CZ, 2003, MATH BIOSCI, V185, P111, DOI 10.1016/S0025-5564(03)00096-8; Chen XW, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P504; Chilingaryan A, 2002, MATH BIOSCI, V176, P59, DOI 10.1016/S0025-5564(01)00105-5; Cho SJ, 2002, J CHEM INF COMP SCI, V42, P927, DOI 10.1021/ci010247v; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis RE, 2001, J EXP MED, V194, P1861, DOI 10.1084/jem.194.12.1861; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GILBERT ES, 1969, BIOMETRICS, V25, P505, DOI 10.2307/2528902; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GUO Z, 2001, ANAL MED DATA INTRO; Hall MA, 1998, CORRELATION BASED FE; HOLTE RC, 2001, P 14 BIENN C CAN SOC, P57; Houck CR, 1997, EVOL COMPUT, V5, P31, DOI 10.1162/evco.1997.5.1.31; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Ji XL, 2003, FEBS LETT, V542, P125, DOI 10.1016/S0014-5793(03)00363-6; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LI L, 2003, LIFE SCI RES, V7, P372; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li X, 2004, NUCLEIC ACIDS RES, V32, P2685, DOI 10.1093/nar/gkh563; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; Park P J, 2001, Pac Symp Biocomput, P52; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Schliep A., 2003, BIOINFORMATICS, V19, pi255; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Stefanini FM, 2000, BIOINFORMATICS, V16, P923, DOI 10.1093/bioinformatics/16.10.923; Szabo A, 2003, BIOSTATISTICS, V4, P555, DOI 10.1093/biostatistics/4.4.555; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Tsamardinos I., 2003, 9 INT WORKSH ART INT; XING EP, 2001, P 18 INT C SAN FRANC	37	52	57	0	2	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0888-7543			GENOMICS	Genomics	JAN	2005	85	1					16	23		10.1016/j.ygeno.2004.09.007		8	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	886XA	WOS:000226265100002	15607418	
B	de Castro, PAD; Santoro, DM; Camargo, HA; Nicoletti, MC		Ishikawa, M; Hashimoto, S; Paprzycki, M; Barakova, E; Yoshida, K; Koppen, M; Corne, DW; Abraham, A		de Castro, PAD; Santoro, DM; Camargo, HA; Nicoletti, MC			Improving a Pittsburgh learnt fuzzy rule base using feature subset selection	HIS'04: Fourth International Conference on Hybrid Intelligent Systems, Proceedings			English	Proceedings Paper	4th International Conference on Hybrid Intelligent Systems (HIS 04)	DEC 05-08, 2004	Kitakyushu, JAPAN	IEEE Comp Soc, Computat Intelligence Soc, IEEE, Syst Man, & Cybernet Soc, BMFSA, SOFT, Int Fuzzy Syst Assoc, City Kitakyushu, World Federat Soft Comp		feature subset selection; Pittsburgh approach; fuzzy rule bases; C-Focus; Relief-E; wrapper methods; hybrid systems	CLASSIFICATION	This paper investigates the problem of feature subset selection as a pre-processing step to a method which learns fuzzy rule bases using genetic algorithm (GA) implementing the Pittsburgh approach. Four feature subset selection methods are investigated in the context of learning fuzzy rule bases. Two of them are filter methods namely, the Relief-E and the C-Focus. The other two are wrapper methods using GA as their search process; one implements the instance-based method 1-NN and the other, the constructive neural network algorithm DistAl. Results of the experiments conducted in three domains are presented and discussed; they show that methods which learn fuzzy rule bases can benefit from feature subset selection methods.	DC UFSCar, BR-13565905 Sao Carlos, SP, Brazil	de Castro, PAD (reprint author), DC UFSCar, BR-13565905 Sao Carlos, SP, Brazil.		Camargo, Heloisa/C-4501-2012; Castro, Pablo Dalbem/G-1190-2011	Castro, Pablo Dalbem/0000-0002-1809-2869			ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; ARAUZO A, 2003, P 7 ONL WORLD C SOFT, P225; Bezdek J. C., 1981, PATTERN RECOGNITION; BLUM A, 1997, ARTIF INTELL, V10, P245; Cordon O., 2001, Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569), DOI 10.1109/NAFIPS.2001.943725; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; John G., 1994, P 11 INT C MACH LEAR, P121; Kira K., 1992, P 10 NAT C ART INT, P129; Kononenko I., 1994, P EUR C MACH LEARN, P171; Langley P., 1994, P AAAI FALL S REL NE; Merz C, 1998, UCI REPOSITORY MACHI; Smith S. F., 1980, THESIS U PITTSBURGH; YANG J, 1998, FEATURE EXTRACTION C, pCH8; Yang J., 1999, INTELLIGENT DATA ANA, V3, P53; Yuan YF, 1996, FUZZY SET SYST, V84, P1, DOI 10.1016/0165-0114(95)00302-9	16	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2291-2				2005							180	185				6	Computer Science, Artificial Intelligence	Computer Science	BBW91	WOS:000228181100029		
B	Babu, TR; Murty, MN; Agrawal, VK		Ishikawa, M; Hashimoto, S; Paprzycki, M; Barakova, E; Yoshida, K; Koppen, M; Corne, DW; Abraham, A		Babu, TR; Murty, MN; Agrawal, VK			Adaptive boosting with leader based learners for classification of large handwritten data	HIS'04: Fourth International Conference on Hybrid Intelligent Systems, Proceedings			English	Proceedings Paper	4th International Conference on Hybrid Intelligent Systems (HIS 04)	DEC 05-08, 2004	Kitakyushu, JAPAN	IEEE Comp Soc, Computat Intelligence Soc, IEEE, Syst Man, & Cybernet Soc, BMFSA, SOFT, Int Fuzzy Syst Assoc, City Kitakyushu, World Federat Soft Comp				Boosting is a general method for improving the accuracy of a learning algorithm. AdaBoost, short form for Adaptive Boosting method, consists of repeated use of a weak or a base learning algorithm to find corresponding weak hypothesis by adapting to the error rates of the individual weak hypotheses. A large, complex handwritten data is under study. A repeated use of weak learner on the huge data results in large. amount of processing time. In view of this, instead of using the entire training data for learning, we propose to use only prototypes. Further in the current work, the base learner consists of a nearest neighbour classifier that employs prototypes generated using "leader" clustering algorithm. The leader algorithm is a single pass algorithm and is linear in terms of time as well as computation complexity. The prototype set alone is used as training data. In the process of developing an algorithm, domain knowledge of the Handwritten data, which is under study, is made use of With the fusion of clustering, prototype selection, AdaBoost and Nearest Neighbour classifier a very high classification accuracy, which is better than reported earlier on the considered data, is obtained in less number of iterations. The procedure integrates clustering outcome in terms of prototypes with boosting.	Indian Inst Sci, Dept CSA, Bangalore 560012, Karnataka, India	Babu, TR (reprint author), Indian Inst Sci, Dept CSA, Bangalore 560012, Karnataka, India.						Babu TR, 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NEAREST NEIGHBOUR CL; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAIN A, 2000, IEEE T PAMI, V22, P40; JAIN A, 1999, ACM COMPUTING SURVEY, V32; Kaufman L., 1989, FINDING GROUPS DATA; Kearns M., 1988, TR1488 HARV U AIK CO; KEARNS M, 1994, J ACM, V41, P67, DOI 10.1145/174644.174647; Murphy P. M., 1994, UCI REPOSITORY MACHI; Schapire R E, 1999, P ALGORITHMIC LEARNI; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SCHAPIRE RE, 2002, MSRI WORKSH NONLINEA; Spath H., 1980, CLUSTER ANAL ALGORIT; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Viaene S, 2004, IEEE T KNOWL DATA EN, V16, P612, DOI 10.1109/TKDE.2004.1277822; VISWANATH P, 2004, IN PRESS PUBLICATION	18	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2291-2				2005							326	331				6	Computer Science, Artificial Intelligence	Computer Science	BBW91	WOS:000228181100053		
B	Jankowski, N; Grabczewski, K		Nedjah, N; Mourelle, LM; Vellasco, MMB; Abraham, A; Koppen, M		Jankowski, N; Grabczewski, K			Heterogenous committees with competence analysis	HIS 2005: 5th International Conference on Hybrid Intelligent Systems, Proceedings			English	Proceedings Paper	5th International Conference on Hybrid Intelligent Systems	NOV 06-09, 2005	Rio de Janeiro, BRAZIL	Operador Nacl Sistema Eletr, Coordenac Aperfeicoament Pessoal Nivel Super, Brazilian Comp Soc, Brazilian Soc Automat, IEEE Syst Man & Cygernet Soc, Int Fuzzy Syst Assoc, European Neural Network Soc, European Soc Fuzzy Log & Technol, World Federat Soft Comp, Pontific Univ Catol Rio deJaneiro				We explore some new types of committees in search of hybrid models successful in many different classification benchmarks. To provide a reliable comparison of the ensembles we restrict the task to some constant configuration of committee members for each benchmark. We were looking for new types of committees which, in such configuration, would be as much accurate and stable as possible. The paper focuses on some ideas of heterogenous committees with different ways of their members competence estimation. Heterogenous committee members adapt in different ways and are able to solve different problems. Measuring the competence of committee members helps in making competent and accurate decisions.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Grudziadzka 5, PL-87100 Torun, Poland.		Grabczewski, Krzysztof/F-3574-2014; Jankowski, Norbert/H-1071-2014				Bishop C.M., 1995, NEURAL NETWORKS PATT; Boser B. E., 1992, P 5 ANN ACM WORKSH C; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L., 1998, Neural Networks and Machine Learning. Proceedings; Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUCH W, 2002, ADV SOFT COMPUTING, P412; Duda R.O., 1997, PATTERN CLASSIFICATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J., 2001, ELEMENTS STAT LEARNI; GRABCZEWSKI K, 2004, FEATURE EXTRACTION F; Grabczewski K, 1999, P 4 C NEUR NETW THEI, P203; Grabczewski K, 2000, P 5 C NEUR NETW THEI, P201; JACOBS RA, 1991, NEURAL COMPUTATION, V79; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kuncheva L.I., 2003, MACHINE LEARNING, V51; MACLIN R, 1998, P AAAI; Merz C, 1998, UCI REPOSITORY MACHI; Mitchell T. M., 1997, MACHINE LEARNING; Quinlan J. R., 1993, PROGRAMS MACHINE LEA, Vfirst; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; SEEWALD AK, 2001, ADV INTELLIGENT DATA; TING KM, 1997, P 15 INT JOIN C ART; Vapnik V. N., 1995, NATURE STAT LEARNING; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zenko B., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989601	26	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2457-5				2005							417	422				6	Computer Science, Artificial Intelligence	Computer Science	BDN06	WOS:000234402500069		
S	Robinson, S; Polak, JW			TRB	Robinson, S; Polak, JW			Modeling urban link travel time with inductive loop detector data by using the k-NN method	INFORMATION SYSTEMS AND TECHNOLOGY	TRANSPORTATION RESEARCH RECORD		English	Article; Proceedings Paper	84th Annual Meeting of the Transportation-Research-Board	JAN 09-13, 2005	Washington, DC	US Dept Transportat, US Fed Aviat Adm, US Fed Highway Adm, US Fed Motor Carrier Safety Adm, US Fed Railroad Adm, US Fed Transit Adm, US Natl Highway Traff Safety Adm, US Res & Innovat Technol Adm, NASA, USA Corps Engineers, US Coast Guard, US DOE, US EPA, Transportat Res Board, Transportat Dept 50 States, Puerto Rico & District Columbia			NONPARAMETRIC REGRESSION; SPEED	The need to measure urban link travel time (ULTT) is becoming increasingly important for network management and traveler information provision. This paper proposes the use of the k nearest neighbors (k-NN) technique to estimate ULTT with the use of single loop inductive loop detector (ILD) data. Real-world data from London is used. This paper explores the sensitivity of travel time estimates to various k-NN design parameters. It rinds that the k-NN method is not particularly sensitive to the distance metric, although care must be taken in selecting the right combination of local estimation method (LEM) and value of k. A robust LEM should be used. The optimized k-NN model is found to provide more accurate estimates than other ULTT methods. To obtain a more accurate estimate of ULTT, a potential application of this approach could be to aggregate GPS probe vehicle ULTT records from different times but the same underlying travel time distribution.	Univ London Imperial Coll Sci Technol & Med, Dept Civil & Environm Engn, Ctr Transport Studies, London SW7 2AZ, England	Robinson, S (reprint author), Univ London Imperial Coll Sci Technol & Med, Dept Civil & Environm Engn, Ctr Transport Studies, Exhibit Rd, London SW7 2AZ, England.						ANDERSON J, 1997, IEEE C INT TRANSP SY; BAJWA SI, 2003, 21 AUSTR ROAD RES BO; BAJWA SI, 2003, 10 WORLD C INT TRANS; Barbosa HM, 2000, TRANSPORT RES A-POL, V34, P103, DOI 10.1016/S0965-8564(98)00067-6; BEGON C, 2004, THESIS IMPERIAL COLL; Chens C, 2003, TRANSPORT RES REC, V1855, P160, DOI 10.3141/1855-20; Cherrett T, 2001, P I CIVIL ENG-TRANSP, V147, P23; Clark S, 2003, J TRANSP ENG-ASCE, V129, P161, DOI 10.1061/(ASCE)0733-947X(2003)129:2(161); Coifman B, 2001, TRANSPORT RES A-POL, V35, P863, DOI 10.1016/S0965-8564(00)00028-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; DAILEY DJ, 1993, TRANSPORT RES B-METH, V27, P97, DOI 10.1016/0191-2615(93)90002-R; Dailey DJ, 1999, TRANSPORT RES B-METH, V33, P313, DOI 10.1016/S0191-2615(98)00037-X; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DAVIS GA, 1991, J TRANSP ENG-ASCE, V117, P178, DOI 10.1061/(ASCE)0733-947X(1991)117:2(178); Devijver P. A., 1982, PATTERN RECOGNITION; FIX E, 1952, 11 USAF SCH AV MED, P280; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Fukunaga K., 1990, INTRO STAT PATTERN R; Gault H. E., 1981, 37 U NEWC TRANSP OP; Guhnemann A., 2004, 10 WORLD C TRANSP RE; Handley S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Hardie W., 1990, APPL NONPARAMETRIC R; Hodges J., 1951, 4 USAF SCH AV MED, P261; Ishimaru J. M., 1999, FLOW EVALUATION DESI; Kittler J., 1978, Pattern Recognition and Signal Processing; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Liu H., 1998, FEATURE SELECTION KN; *MATHSW LTD, 2000, MATLAB REL 12 US DOC; OSWALD K, 2000, UVACEITS014 G MAS U; PALACHARLA P, 1995, P 2 WORLD C INT TRAN, V1, P112; PAPAGIANNI S, 2003, THESIS IMPERIAL COLL; Park D, 1999, J TRANSP ENG-ASCE, V125, P515, DOI 10.1061/(ASCE)0733-947X(1999)125:6(515); Petty KF, 1998, TRANSPORT RES A-POL, V32, P1, DOI 10.1016/S0965-8564(97)00015-3; QI Y, 2004, TRANSPORT RES REC, V1879, P89, DOI 10.3141/1879-11; ROBINSON S, IN PRESS J TRANSPORT; ROBINSON S, 2004, 36 ANN C U TRANSP ST; ROBINSON SJP, 2004, 10 WORLD C TRANSP RE; Simonoff J. S., 1996, SMOOTHING METHODS ST; Sisiopiku V., 1994, TRAVEL TIME ESTIMATI; Smith BL, 1997, J TRANSP ENG-ASCE, V123, P261, DOI 10.1061/(ASCE)0733-947X(1997)123:4(261); Smith BL, 2002, TRANSPORT RES C-EMER, V10, P303, DOI 10.1016/S0968-090X(02)00009-8; Srinivasan KK, 1996, TRANSPORT RES REC, V1537, P15, DOI DOI 10.3141/1537-03; Turner S., 1998, FHWAPL98035; Van der Zijpp N.J., 1997, TRANSPORT RES REC, V1607, P87, DOI 10.3141/1607-13; van Lint H., 2004, RELIABLE TRAVEL TIME; Wardrop J.G, 1968, TRAFFIC ENG CONTROL, V11, P528; WIGGINS AE, 1999, HELSINKI JOURNEY TIM; Xie C., 2004, 83 ANN M TRANSP RES; You J, 2000, TRANSPORT RES C-EMER, V8, P231, DOI 10.1016/S0968-090X(00)00012-7; ZHANG M, 1998, ESTIMATING ARTERIAL	51	10	10	3	8	TRANSPORTATION RESEARCH BOARD NATL RESEARCH COUNCIL	WASHINGTON	500 FIFTH ST, NW, WASHINGTON, DC 20001 USA	0361-1981		0-309-09409-7	TRANSPORT RES REC			2005		1935					47	56				10	Computer Science, Interdisciplinary Applications; Engineering, Civil; Transportation Science & Technology	Computer Science; Engineering; Transportation	BEG15	WOS:000237194200006		
S	Bao, YG; Tsuchiya, E; Ishii, N; Du, XY		Gallagher, M; Hogan, J; Maire, F		Bao, YG; Tsuchiya, E; Ishii, N; Du, XY			Classification by instance-based learning algorithm	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING IDEAL 2005, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2005)	JUL 06-08, 2005	Brisbane, AUSTRALIA	Univ Queensland				The basic k-nearest-neighbor classification algorithm works well in many domains but has several shortcomings. This paper proposes a tolerant instance-based learning algorithm TIBL and it ' s combining method by simple voting of TIBL, which is an integration of genetic algorithm, tolerant rough sets and k-nearest neighbor classification algorithm. The proposed algorithms seek to reduce storage requirement and increase generalization accuracy when compared to the basic k-nearest neighbor algorithm and. other learning models. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository. The results show that TIBL algorithm and it ' s combining method, improve the performance of the k-nearest neighbor classification, and also achieves higher generalization accuracy than other popular machine learning algorithms.	Renmin Univ China, Sch Informat, Beijing, Peoples R China		baoyg@yahoo.com.cn; eisuke@hm.aitai.ne.jp; ishii@in.aitech.ac.jp; duyong@mail.ruc.edu.cn	ruc, comp_xinxi/E-4212-2012				AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Guvenir H. A., 1997, P 12 INT S COMP INF, P44; Merz C.J., UCI REPOSITORY MACHI; Pawlak Z., 1991, ROUGH SETS THEORETIC; Rachlin J., 1994, P 11 INT MACH LEARN, P242; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103	8	9	9	0	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26972-X	LECT NOTES COMPUT SC			2005	3578						133	140				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BCR09	WOS:000230878800018		
S	Shi, ZZ; Luo, P; Hao, YL; Li, GH; Stumptner, M; He, Q; Quirchmayr, G		Shi, Z; He, Q		Shi, ZZ; Luo, P; Hao, YL; Li, GH; Stumptner, M; He, Q; Quirchmayr, G			Intelligent technology for well logging analysis	INTELLIGENT INFORMATION PROCESSING II	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	2nd International Conference on Intelligent Information Processing	OCT 21-23, 2004	Beijing, PEOPLES R CHINA	IFIP TC12, WG12 3		intelligent technology; well log analysis; data mining; MOUCLAS algorithm		Well logging analysis plays an essential role in petroleum exploration and exploitation. It is used to identify the pay zones of gas or oil in the reservoir formations. This paper applies intelligent technology for well logging analysis, particular combining data mining and expert system together, and proposes an intelligent system for well log analysis called IntWeL Analyzer in terms of data mining platform MSMiner and expert system tool OKPS. The architecture of IntWeL Analyzer and data mining algorithms, including Ripper algorithm and MOUCLAS algorithm are also presented. MOUCLAS is based on the concept of the fuzzy set membership function that gives the new approach a solid mathematical foundation and compact mathematical description of classifiers. The aim of the study is the use of intelligent technology to interpret the pay zones from well logging data for the purpose of reservoir characterization. This approach is better than conventional techniques for well logging interpretation that cannot discover the correct relation between the well logging data and the underlying property of interest.	Chinese Acad Sci, Comp Technol Inst, Beijing 100080, Peoples R China	Shi, ZZ (reprint author), Chinese Acad Sci, Comp Technol Inst, Beijing 100080, Peoples R China.		Stumptner, Markus/B-5558-2009				AMINZADEH F, 1996, FUTURE GEOSCIENCE TE, P1; CLIFFORD A, 1991, P 8 INT WORKSH MACH, P389; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG G, 1999, P 5 ACM SIGKDD; LENT B, 1997, ICDE, P220; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Quinlan J. R., 1993, PROGRAMS MACHINE LEA, Vfirst; SHI ZZ, 2004, OKPS EXPERT SYSTEM D; SHI ZZ, 2002, MSMINER DATA MINING; WILLIAM W, 1995, P 12 INT C LAK TAH C	11	1	1	0	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736		0-387-23151-X	INT FED INFO PROC			2005	163						373	382		10.1007/0-387-23152-8_48		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBJ45	WOS:000225784400048		
S	Kawatsure, T; Zhao, QF			IEEE	Kawatsure, T; Zhao, QF			Inducing multivariate decision trees with the R(4)-rule	INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOL 1-4, PROCEEDINGS	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-12, 2005	Waikoloa, HI	IEEE Syst, Man & Cybernet Soc		machine learning; pattern recognition; multivariate decision trees; nearest neighbor classifier; the R(4)-rule	NEIGHBOR PATTERN-CLASSIFICATION; MLP	Decision tree (DT) is often considered as a comprehensible learning model. If the data set is large, however the induced DT may be too large to understand. Currently, we have proposed a non-genetic evolutionary algorithm called R(4)-rule for producing the smallest nearest neighbor classifiers (NNCs). In this paper we propose two new approaches for inducing DTs with the R(4)-rule. The DTs considered here are multivariate, and there is an NNC with two or more prototypes in each non-terminal node. In the first method, the prototypes are found directly from the training set. In the second method, the prototypes are found from the data assigned to each non-terminal node. Using these methods, we can induce more compact and more comprehensible DTs. The efficiency and efficacy of the methods are verified through experiments with several public databases.	Univ Aizu, Aizu Wakamatsu, Japan	Kawatsure, T (reprint author), Univ Aizu, Aizu Wakamatsu, Japan.	m5081132@u-aizu.ac.jp; qf-zhao@u-aizu.ac.jp					Brieman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Endou T., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004417; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; KAWATSURE T, 2003, 2003129 IEICE PRMU; Oates T., 1997, P 14 INT C MACH LEAR, P254; Oka S., 2000, P 4 JAP AUSTR JOINT, P128; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Shirasaka M., 1998, P 2 AS PAC C SIM EV; Tanigawa T., 2000, P GEN EV COMP C GECC, P1047; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240	13	0	0	0	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		0-7803-9298-1	IEEE SYS MAN CYBERN			2005							3593	3598				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BDT16	WOS:000235210803100		
J	Cai, YD; Chou, KC				Cai, YD; Chou, KC			Using functional domain composition to predict enzyme family classes	JOURNAL OF PROTEOME RESEARCH			English	Article						classification of enzyme commission; enzymatic attribute; functional domain composition; 20% threshold cutoff; nearest neighbor predictor; bioinformatics; proteomics	PROTEIN STRUCTURAL CLASS; AMINO-ACID-COMPOSITION; SECONDARY STRUCTURE PREDICTION; SUBCELLULAR LOCATION; NEURAL-NETWORKS; FOLDING TYPES; CLASSIFICATION; ALGORITHM; SEQUENCE; DATABASE	According to their main EC (Enzyme Commission) numbers, enzymes are classified into the following 6 main classes: oxidoreductases, transferases, hydrolases, lyases, isomerases, and ligases. A new method has been developed to predict the enzymatic attribute of proteins by introducing the functional domain composition to formulate a given protein sequence. The advantage by doing so is that both the sequence-order-related features and the function-related features are naturally incorporated in the predictor. As a demonstration, the jackknife cross-validation test was performed on a dataset that consists of proteins with only less than 20% sequence identity to each other in order to get rid of any homologous bias. The overall success rate thus obtained was 85% in identifying the enzyme family classes (including the identification of nonenzyme protein sequences as well). The success rate is significantly higher than those obtained by the other methods on such a stringent dataset. This indicates that using the functional domain composition to represent protein samples for statistical prediction is indeed very promising, and will become a powerful tool in bioinformatics and proteomics.	Univ Manchester, Inst Sci & Technol, Biomol Sci Dept, Manchester M60 1QD, Lancs, England; Gordon Life Sci Inst, San Diego, CA 92130 USA; TIBDD, Tianjin, Peoples R China	Cai, YD (reprint author), Univ Manchester, Inst Sci & Technol, Biomol Sci Dept, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk; kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; Cai CZ, 2004, PROTEINS, V55, P66, DOI 10.1002/prot.20045; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou P Y, 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELEAGE G, 1987, PROTEIN ENG, V1, P289, DOI 10.1093/protein/1.4.289; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; KNELLER DG, 1990, J MOL BIOL, V214, P171, DOI 10.1016/0022-2836(90)90154-E; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Webb EC, 1992, ENZYME NOMENCLATURE; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	29	36	38	0	4	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893			J PROTEOME RES	J. Proteome Res.	JAN-FEB	2005	4	1					109	111		10.1021/pr049835p		3	Biochemical Research Methods	Biochemistry & Molecular Biology	901MQ	WOS:000227287000013	15707365	
J	Hall, P; Samworth, RJ				Hall, P; Samworth, RJ			Properties of bagged nearest neighbour classifiers	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Bayes risk; bootstrap; classification error; cross-validation; density; discrimination; error rate; marked point process; Poisson process; prediction; regret; statistical learning; without-replacement sampling; with-replacement sampling	CROSS-VALIDATION; DENSITY-ESTIMATION; SAMPLE-SIZE; CLASSIFICATION; ERROR; DISCRIMINATION; REGRESSION; RULE	It is shown that bagging, a computationally intensive method, asymptotically improves the performance of nearest neighbour classifiers provided that the resample size is less than 69% of the actual sample size, in the case of with-replacement bagging, or less than 50% of the sample size, for without-replacement bagging. However, for larger sampling fractions there is no asymptotic difference between the risk of the regular nearest neighbour classifier and its bagged version. In particular, neither achieves the large sample performance of the Bayes classifier. In contrast, when the sampling fractions converge to 0, but the resample sizes diverge to infinity, the bagged classifier converges to the optimal Bayes rule and its risk converges to the risk of the latter. These results are most readily seen when the two populations have well-defined densities, but they may also be derived in other cases, where densities exist in only a relative sense. Cross-validation can be used effectively to choose the sampling fraction. Numerical calculation is used to illustrate these theoretical properties.	Univ Cambridge, Ctr Math Sci, Stat Lab, Cambridge CB3 0WB, England; Australian Natl Univ, Canberra, ACT, Australia	Samworth, RJ (reprint author), Univ Cambridge, Ctr Math Sci, Stat Lab, Wilberforce Rd, Cambridge CB3 0WB, England.	r.j.samworth@statslab.cam.ac.uk					Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Bickel PJ, 1997, STAT SINICA, V7, P1; BREIMAN L, 1999, 547 U CAL DEP STAT; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buhlmann P, 2002, ANN STAT, V30, P927; BUJA A, 2000, UNPUB EFFECT BAGGING; BUJA A, 2000, UNPUB SMOOTHING EFFE; Cover T. M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daley D., 1988, INTRO THEORY POINT P; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; Devroye L., 1996, PROBABILISTIC THEORY; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Fix E., 1951, 4 US AIR FORC SCH AV; FRANCOIS J, 2001, INFORMATION PROCESSI, V1, P111; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 2000, UNPUB BAGGING NONLIN; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; GUERRASALCEDO C, 1999, P GEN EV COMP C, V1, P236; HALL P, 1989, STAT PROBABIL LETT, V8, P109, DOI 10.1016/0167-7152(89)90002-3; Hand DJ, 1981, DISCRIMINATION CLASS; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; HO TK, 1998, P 14 INT C PATT REC, P545; Jiang WX, 2002, ANN STAT, V30, P51, DOI 10.1214/aos/1015362184; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; KUNCHEVA LI, 2002, INFORM FUSION, P245; Larkey Leah S., 1996, P SIGIR 96 19 ACM IN, P289, DOI 10.1145/243199.243276; Lugosi G, 1996, ANN STAT, V24, P687; Mammen E., 1992, LECT NOTES STAT, V77; MARRON JS, 1983, ANN STAT, V11, P1142; MIELNICZUK J, 1989, J STAT PLAN INFER, V23, P53, DOI 10.1016/0378-3758(89)90039-6; MOLLINEDA RA, 2000, P 4 WRLD MULT SYST C, V7, P640; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Schapire RE, 1998, ANN STAT, V26, P1651; Skurichina M, 2002, LECT NOTES COMPUT SC, V2364, P62; Skurichina M, 1998, PATTERN RECOGN, V31, P909, DOI 10.1016/S0031-3203(97)00110-6; Steele BM, 2000, STAT COMPUT, V10, P349, DOI 10.1023/A:1008933626919; STOLLER DS, 1954, J AM STAT ASSOC, V49, P770, DOI 10.2307/2281538; Yang JH, 1999, ORG LETT, V1, P11, DOI 10.1021/ol9900010; ZEMKE S, 1997, P ART NEUR NETW ENG, P1067	46	17	17	0	2	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	1369-7412			J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2005	67		3				363	379		10.1111/j.1467-9868.2005.00506.x		17	Statistics & Probability	Mathematics	937CQ	WOS:000229902600003		
S	Ferrandiz, S; Boulle, M		Perner, P; Imilya, A		Ferrandiz, S; Boulle, M			Supervised evaluation of dataset partitions: Advantages and practice	MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINDS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Data Minining in Pattern Recognition	JUL 09-11, 2005	Leipzig, GERMANY					In the context of large databases, data preparation takes a greater importance : instances and explanatory attributes have to be carefully selected. In supervised learning, instances partitioning techniques have been developped for univariate representations, leading to precise and comprehensible evaluations of the amount of information contained in an attribute, with respect to the target attribute. Still, the multivariate case remains unstated. In this paper, we describe the partitioning intrinsic convenience for data preparation and we settle a framework for supervised partitioning. A new evaluation criterion of labelled objects partitions, which is based on Minimum Description Length principle, is then set and tested on real and synthetic data sets.	France Telecom R&D, F-22307 Lannion, France; Univ Caen, GREYC, F-14032 Caen, France	Ferrandiz, S (reprint author), France Telecom R&D, 2 Ave Pierre Marzin, F-22307 Lannion, France.	sylvain.ferrandiz@francetelecom.com; marc.boulle@francetelecom.com					BOULLE M, 2004, DATA MINING, V5, P199; Breiman L., 1984, CLASSIFICATION REGRE; CHAPMAN P, 2000, CRISP DM 1 0 STEP BY; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Kass GV, 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; KERBER R, 1991, 10 INT C ART INT, P123; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; McQueen J., 1967, 5TH BERK S MATH STAT, V1, P281; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; ZIGHED DA, 2001, 8 RENC SFC, P356	14	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26923-1	LECT NOTES ARTIF INT			2005	3587						600	609				10	Computer Science, Artificial Intelligence	Computer Science	BCR27	WOS:000230895100059		
S	Ferrandiz, S; Boulle, M		Perner, P; Imilya, A		Ferrandiz, S; Boulle, M			Multivariate discretization by recursive supervised bipartition of graph	MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Data Mining in Pattern Recognition	JUL 09-11, 2005	Leipzig, GERMANY					In supervised learning, discretization of the continuous explanatory attributes enhances the accuracy of decision tree induction algorithms and naive Bayes classifier. Many discretization methods have been developped, leading to precise and comprehensible evaluations of the amount of information contained in one single attribute with respect to the target one. In this paper, we discuss the multivariate notion of neighborhood, extending the univariate notion of interval. We propose an evaluation criterion of bipartitions, which is based on the Minimum Description Length (MDL) principle [1], and apply it recursively. The resulting discretization method is thus able to exploit correlations between continuous attributes. Its accuracy and robustness are evaluated on real and synthetic data sets.	France Telecom R&D, F-22307 Lannion, France; Univ Caen, GREYC, F-14032 Caen, France	Ferrandiz, S (reprint author), France Telecom R&D, 2,Ave Pierre Marzin, F-22307 Lannion, France.	sylvain.ferrandiz@francetelecom.com; marc.boulle@francetelecom.com					Bay S. D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347159; Blake CL, UCI REPOSITORY MACHI; BOULLE M, 2004, BAYESIAN APPROACH SU, P199; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; KERBER R, 1991, 10 INT C ART INT, P123; Kwedlo W, 1999, LECT NOTES ARTIF INT, V1704, P392; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5	11	7	7	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26923-1	LECT NOTES ARTIF INT			2005	3587						253	264				12	Computer Science, Artificial Intelligence	Computer Science	BCR27	WOS:000230895100025		
S	Hendrickx, I; van den Bosch, A		Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Hendrickx, I; van den Bosch, A			Hybrid algorithms with instance-based classification	MACHINE LEARNING: ECML 2005, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD			LEARNING ALGORITHMS	In this paper we aim to show that instance-based classification can replace the classifier component of a rule learner and of maximum-entropy modeling, thereby improving the generalization accuracy of both algorithms. We describe hybrid algorithms that combine rule learning models and maximum-entropy modeling with instance-based classification. Experimental results show that both hybrids are able to outperform the parent algorithm. We analyze and compare the overlap in errors and the statistical bias and variance of the hybrids, their parent algorithms, and a plain instance-based learner. We observe that the successful hybrid algorithms have a lower statistical bias component in the error than their parent algorithms; the fewer errors they make are also less systematic.	Tilburg Univ, ILK Computat Linguist & AI, NL-5000 LE Tilburg, Netherlands	Hendrickx, I (reprint author), Tilburg Univ, ILK Computat Linguist & AI, POB 90153, NL-5000 LE Tilburg, Netherlands.	i.h.e.hendrickx@uvt.nl; antalb@uvt.nl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; Brill Eric, 1998, P COLING ACL 98, P191; Cohens W, 1995, P 12 INT C MACH LEAR, P115; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W., 2004, ILK0402 TILB U; Domingos P, 1996, MACH LEARN, V24, P141; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Guiasu S., 1985, MATH INTELLIGENCER, V7; Hendy I.L., 2004, P 1L BELG DUTCH C AR, P19; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.2307/2006193; Sebag M., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; Ting K. M., 1994, Proceedings of the 7th Australian Joint Conference on Artificial Intelligence. Artificial Intelligence. AI'94. Sowing the Seeds for the Future; van der Veen A-J, 2004, P WORKSH ADV IND RUL, P1, DOI 10.1109/SAM.2004.1502901; VANDENBOSCH A, 2004, P 16 BELG DUTCH C AR, P219; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	19	8	8	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29243-8	LECT NOTES ARTIF INT			2005	3720						158	169				12	Computer Science, Artificial Intelligence	Computer Science	BDF41	WOS:000233235200019		
B	Koukal, T; Schneider, W; Suppan, F		Oluic, M		Koukal, T; Schneider, W; Suppan, F			Radiometric-topographic normalization in mountainous terrain for Landsat-TM-based forest parameter assessment by the kNN method	NEW STRATEGIES FOR EUROPEAN REMOTE SENSING			English	Proceedings Paper	24th Symposium of the European-Association-of-Remote-Sensing-Laboratories (EARSeL)	MAY 25-27, 2004	Dubrovnik, CROATIA	European Assoc Remote Sensing Labs		forest inventory; radiornetric-topographic normalization; kNN		The kNN method of combining a terrestrial forest inventory with remote sensing image analysis is applied in mountainous terrain. This poses problems of radiometric-topographic normalization, which are addressed in this paper. The SCS (sun-canopy-sensor) method, extended for including diffuse sky radiation, is found to be particularly suited for this. Estimating parameters of radiometric-topographic correction algorithms (such as the ratio of direct sun radiation and diffuse sky radiation in case of the extended SCS method) from the image itself by regression of forest pixels arbitrarily selected at different topographic conditions relies on the assumption that the forest pixels selected at different irradiation conditions represent (in the statistical average) identical forest conditions. This assumption can hardly be proved to be valid. The estimation of this ratio by tuning within the kNN cross-validation procedure, on the other hand, represents a sound method, making use of the large amount of forest information available from terrestrial forest inventories. The practicability of this method depends on the number and thematic distribution of field plots on one single scene, for which homogenous atmospheric conditions can be assumed.	BOKU Univ Natl Resources & Appl Life Sci, Dept Landscape Spatial Sci & Infrastruct, Inst Surveying Remote Sensing & Land Informat, Vienna, Austria	Koukal, T (reprint author), BOKU Univ Natl Resources & Appl Life Sci, Dept Landscape Spatial Sci & Infrastruct, Inst Surveying Remote Sensing & Land Informat, Vienna, Austria.						COLBY JD, 1991, PHOTOGRAMM ENG REM S, V57, P531; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Efron B., 1993, MONOGRAPHS STAT APPL, V57; Gu D, 1998, REMOTE SENS ENVIRON, V64, P166, DOI 10.1016/S0034-4257(97)00177-6; ITTEN KL, 1992, REMOTE SENSING SERIE, P18; KILKKI P, 1987, REMOTE SENSING AIDED, P209; SMITH JA, 1980, PHOTOGRAMM ENG REM S, V46, P1183; Teillet P. M., 1982, Canadian Journal of Remote Sensing, V8; TOMPPO E, 1993, ILV S NAT FOR INV IU	9	1	1	2	2	MILLPRESS SCIENCE PUBLISHERS	ROTTERDAM	PO BOX 84118, 3009 CC ROTTERDAM, NETHERLANDS			90-5966-003-X				2005							239	246				8	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	BCD88	WOS:000228786900029		
J	Yang, Y; Zheng, CX; Lin, P				Yang, Y; Zheng, CX; Lin, P			Fuzzy clustering with spatial constraints for image thresholding	OPTICA APPLICATA			English	Article						image thresholding; fuzzy c-means; k-nearest neighbor; fuzzy thresholding	ENTROPY; PARTITION; HISTOGRAM	Image thresholding plays an important role in image segmentation. This paper presents a novel fuzzy clustering based image thresholding technique, which incorporates the spatial neighborhood information into the standard fuzzy c-means (FCM) clustering algorithm. The prior spatial constraint, which is defined as weight in this paper, is inspired-by the k-nearest neighbor (k-NN) algorithm and is modified from two aspects in order to improve the performance of image thresholding. The algorithm is. initialized by a fast FCM algorithm,. in which the iteration is carried out with the statistical gray level histogram of image instead of the conventional whole data of image; therefore its convergence is fast. Extensive experiment results and both qualitative and quantitative comparative studies with several existing methods on the thresholding of some synthetic and real images illustrate the effectiveness and robustness of the proposed algorithm.	Xian Jiaotong Univ, Inst Biomed Engn, Educ Minist, Key Lab Biomed Informat Engn, Xian 710049, Peoples R China	Yang, Y (reprint author), Xian Jiaotong Univ, Inst Biomed Engn, Educ Minist, Key Lab Biomed Informat Engn, Xian 710049, Peoples R China.	greatyyy765@sohu.com					ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; Bezdek J. C., 1981, PATTERN RECOGNITION; BRINK AD, 1992, PATTERN RECOGN, V25, P803, DOI 10.1016/0031-3203(92)90034-G; CHEN WT, 1994, PATTERN RECOGN, V27, P885, DOI 10.1016/0031-3203(94)90154-6; Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1; Chi Z., 1996, FUZZY ALGORITHMS APP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELSTEIN WA, 1984, MED PHYS, V11, P180, DOI 10.1118/1.595484; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; Gong JA, 1998, PATTERN RECOGN, V31, P295, DOI 10.1016/S0031-3203(97)00043-5; Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6; JULIUS TT, 1974, PATTERN RECOGNITION; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI [10.1117/1.1631315, 10.1117/1.16313161]; Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743	19	0	0	0	0	TECHNICAL UNIV WROCLAW	WROCLAW	WYBRZEZE WYSPIANSKIEGO 27, EXPORT-IMPORT DIVISION, 50-370 WROCLAW, POLAND	0078-5466			OPT APPL	Opt. Appl.		2005	35	4					943	954				12	Optics	Optics	045VO	WOS:000237771000034		
S	Sheridan, C; O'Farrell, M; Lewis, E; Lyons, WB; Flanagan, C; Jackman, N		Byrne, HJ; Lewis, E; MacCraith, BD; McGlynn, E; McLaughlin, JA; OSullivan, GD; Ryder, AG; Walsh, JE		Sheridan, C; O'Farrell, M; Lewis, E; Lyons, WB; Flanagan, C; Jackman, N			Comparison of k-NN, backpropagation and self-organising map classification methods using an optical fibre based sensor system utilised in an industrial large scale oven	Opto-Ireland 2005: Optical Sensing and Spectroscopy	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Opto-Ireland 2005 Conference	APR 05-06, 2005	Dublin, IRELAND	SPIE Europe, Enterprise Ireland, Sci Fdn Ireland, Failte Ireland		optical fibre sensor; self-organising map; k-NN; Artificial Neural Network		This paper reports on three methods of classifying the spectral data from an optical fibre based sensor system as used in the food industry. The first method uses a feed-forward back-propagation Artificial Neural Network; the second method involves using Kohonen Self-Organising Maps while the third method is k-Nearest Neighbour analysis. The sensor monitors the food colour online as the food cooks by examining the reflected light from both the surface and the core of the product. The combination of using Principal Component Analysis and Backpropagation Neural Networks has been successfully investigated previously. In this paper, results obtained using all three classifiers are presented and compared. The Principal Components used to train each classifier are evaluated from data that generate a "colourscale" comprising six colour classifications. This scale has been developed to allow several products of similar colour to be tested using a single network that had been trained using the colourscale. The results presented show that both the neural network and the Self-Organising Map approach perform comparably, while the k-NN method tested under-performs the other two.	Univ Limerick, Dept Elect & Comp Engn, Limerick, Ireland	Sheridan, C (reprint author), Univ Limerick, Dept Elect & Comp Engn, Limerick, Ireland.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Kohenen T., 2001, SELF ORG MAPS; Kohenon T, 1990, P IEEE, V78, P1464; OFARRELL M, 2003, P IEEE, V1, P368, DOI 10.1109/ICSENS.2003.1278960; Schalkoff R.J., 1992, PATTERN RECOGNITION; SHERIDAN C, 2004, P 14 ART NEUR NETW E, V14, P879	7	0	0	0	5	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5811-2	P SOC PHOTO-OPT INS			2005	5826						706	713		10.1117/12.619555		8	Instruments & Instrumentation; Optics; Spectroscopy	Instruments & Instrumentation; Optics; Spectroscopy	BCT93	WOS:000231202200075		
S	Pham, TD		Singh, S; Singh, M; Apte, C; Perner, P		Pham, TD			An optimally weighted fuzzy k-NN algorithm	PATTERN RECOGNITION AND DATA MINING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Conference on Advances in Pattern Recognition	AUG 22-25, 2005	Bath, ENGLAND				GENE-EXPRESSION DATA; CLASSIFICATION; CANCER	The nearest neighbor rule is a non-parametric approach and has been widely used for pattern classification. The k-nearest neighbor (k-NN) rule assigns crisp memberships of samples to class labels; whereas the fuzzy k-NN neighbor rule replaces crisp memberships with fuzzy memberships. The membership assignment by the conventional fuzzy k-NN algorithm has a disadvantage in that it depends on the choice of some distance function, which is not based on any principle of optimality. To overcome this problem, we introduce in this paper a computational scheme for determining optimal weights to be combined with different fuzzy membership grades for classification by the fuzzy k-NN approach. We show how this optimally weighted fuzzy k-NN algorithm can be effectively applied for the classification of microarray-based cancer data.	James Cook Univ N Queensland, Bioinformat Appl Res Ctr, Sch Informat Technol, Townsville, Qld 4811, Australia	Pham, TD (reprint author), James Cook Univ N Queensland, Bioinformat Appl Res Ctr, Sch Informat Technol, Townsville, Qld 4811, Australia.	tuan.pham@jcu.edu.au					ABLAVSKY V, 2003, P 7 INT C DOC AN REC, V2, P750; Baoli L, 2004, ACM T ASIAN LANGUAGE, V3, P215, DOI 10.1145/1039621.1039623; Bezdek J. C., 1981, PATTERN RECOGNITION; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; GINNEKEN BV, 2004, P 17 INT C PATT REC, V3, P718; Guo GD, 2004, LECT NOTES COMPUT SC, V2945, P559; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Isaaks E.H., 1989, INTRO APPL GEOSTATIS; Journel A.G., 1978, MINING GEOSTATISTICS; Journel AG, 1996, DERIVING CONDITIONAL; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; PALIWAL KK, 1983, IEEE T PATTERN ANAL, V5, P229; Tokola T, 1996, INT J REMOTE SENS, V17, P2333; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Zhou XB, 2004, J BIOMED INFORM, V37, P249, DOI 10.1016/j.jbi.2004.07.009	18	4	4	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-28757-4	LECT NOTES COMPUT SC			2005	3686						239	247				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA34	WOS:000232247900026		
S	Mollineda, RA; Sanchez, JS; Sotoca, JM		Marques, JS; PerezdelaBlanca, N; Pina, P		Mollineda, RA; Sanchez, JS; Sotoca, JM			Data characterization for effective prototype selection	PATTERN RECOGNITION AND IMAGE ANALYSIS, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd Iberian Conference on Pattern Recongnition and Image Analysis	JUN 07-09, 2005	Estoril, PORTUGAL	Fund Oriente, Fund Cienc Tecnol, HP Portugal, Inst Syst & Robotics, Int Assoc Pattern Recognit			NEAREST-NEIGHBOR RULE; CLASSIFICATION; ALGORITHMS	The Nearest Neighbor classifier is one of the most popular supervised classification methods. It is very simple, intuitive and accurate in a great variety of real-world applications. Despite its simplicity and effectiveness, practical use of this rule has been historically limited due to its high storage requirements and the computational costs involved, as well as the presence of outliers. In order to overcome these drawbacks, it is possible to employ a suitable prototype selection scheme, as a way of storage and computing time reduction and it usually provides some increase in classification accuracy. Nevertheless, in some practical cases prototype selection may even produce a degradation of the classifier effectiveness. From an empirical point of view, it is still difficult to know a priori when this method will provide an appropriate behavior. The present paper tries to predict how appropriate a prototype selection algorithm will result when applied to a particular problem, by characterizing data with a set of complexity measures.	Univ Jaume 1, Dept Llenguatges & Sistemes Informat, E-12071 Castellon de La Plana, Spain	Mollineda, RA (reprint author), Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Av Sos Baynat S-N, E-12071 Castellon de La Plana, Spain.	mollined@uji.es; sanchez@uji.es; sotoca@uji.es		Sanchez Garreta, Jose Salvador/0000-0003-1053-4658			Bernado-Mansilla E., 2004, P 17 INT C PATT REC, V1, P136; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Devijver P. A., 1982, PATTERN RECOGNITION; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Kim SW, 2003, PATTERN RECOGN, V36, P1083, DOI 10.1016/S0031-3203(02)00115-2; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	15	25	25	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-26154-0	LECT NOTES COMPUT SC			2005	3523						27	34				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCM80	WOS:000230027000004		
B	Dai, JY; Lee, J; Wang, MC		Arabnia, HR		Dai, JY; Lee, J; Wang, MC			Analytical modeling of data mining process based on distributed tuple space	PDPTA '05: Proceedings of the 2005 International Conference on Parallel and Distributed Processing Techniques and Applications, Vols 1-3			English	Proceedings Paper	International Conference on Parallel and Distributed Processing Techniques and Applications	JUN 27-30, 2005	Las Vegas, NV			data mining; tuple space; parallel processing; analytical modeling		The explosive growth in data volume imposes a big challenge to traditional data mining process in that data mining algorithms tend to be computationally intensive. Parallel and distributed data mining provides an attractive solution to the large scale data mining process. Message passing based parallel computing has been widely used in diverse applications such as scientific computing, ray tracing, simulation, and recently data mining. In this paper, we will present an alternative approach based on distributed tuple space that we contend provides more convenient and efficient parallel data mining framework. Then, we describe the associated analytical performance models to investigate the scalability of the proposed architecture over the cluster computing environment. We also present the experimental results for an exemplary data mining algorithm, k nearest neighbor.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA	Dai, JY (reprint author), Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.						ARAUJO DLA, 2000, P 2000 GEN EV COMP W, P89; CHEUNG DW, 1999, HIGH PERFORMANCE DAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAI JY, 2005, 13 HIGH PERF COMP S; DHILLON IS, 1999, WORKSH LARG SCAL PAR, P245; Freeman E, 1999, JAVASPACES PRINCIPLE; Freitas A. A., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; GELERNTER D, 1985, ACM T PROGR LANG SYS, V7, P80, DOI 10.1145/2363.2433; Gropp W., 1995, USING MPI PORTABLE P; GUPTA A, 1993, J PARALLEL DISTR COM, V19, P234, DOI 10.1006/jpdc.1993.1107; LEE JH, 2004, INT C PAR DISTR COMP; MEIRA W, 1995, 589 U ROCH COMP SCI; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; WYCKOFF P, 1998, IBM SYSTEM J, V37; ZAKI MJ, 1999, 15 INT C DAT ENG SYD; NIH GENETIC SEQUENCE; 2004, KDDCUP; 1994, IEEE WORLD C COMPUTA, V4, P2052; MPICH PORTABLE IMPLE; 1999, KDDCUP; 1992, J PARALLEL DISTRIBUT, V14, P260	21	0	0	1	2	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-61-0				2005							1135	1141				7	Computer Science, Theory & Methods	Computer Science	BDY80	WOS:000236257900167		
B	Dai, JY; Lee, J; Wang, MC		Arabnia, HR		Dai, JY; Lee, J; Wang, MC			Efficient parallel data mining for massive datasets: Parallel random forests classifier	PDPTA '05: Proceedings of the 2005 International Conference on Parallel and Distributed Processing Techniques and Applications, Vols 1-3			English	Proceedings Paper	International Conference on Parallel and Distributed Processing Techniques and Applications	JUN 27-30, 2005	Las Vegas, NV			data mining; parallel processing; random forests; cluster computing		Data mining refers to the process of finding hidden patterns inside a large dataset. While improving the accuracy of those algorithms has been the main focus of past research, massive dataset size imposes another challenge. Parallel and distributed processing techniques have been applied to data mining algorithms to make them scalable. In this paper, we discuss a new emerging data mining algorithm, random forests, and its parallelization based on VCluster, a portable parallel runtime system we have developed for a cluster of multiprocessors. Random forests is an ensemble of many decision trees and the classification is performed by majority voting by those decision trees. We also present the experimental results on the performance of parallel random forests approach.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA	Dai, JY (reprint author), Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.						ARAUJO DLA, 2000, P 2000 GEN EV COMP W, P89; Barbara D., 1997, B TECHNICAL COMMITTE, V20, P3; BAUER E, 1999, MACHINE LEARNING; Breiman L, 1998, ANN STAT, V26, P801; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHEUNG DW, 1999, HIGH PERFORMANCE DAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dhillon Inderjit S., 1999, LARGE SCALE PARALLEL, P245; EUILHON H, 1999, DATA MIN KNOWL DISC, V3, P237; Freitas A. A., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; HAN JW, 2000, DATA MINING CONCEPTS, P5; Kass GV, 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; LEE JH, 2004, INT C PAR DISTR COMP; LEE JH, 2005, INT C PAR DISTR PROC; LEE JH, 2005, 19 EUR SIM MULT PERF; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; ZAKI MJ, 1999, 15 INT C DAT ENG SYD; 1994, IEEE WORLD C COMP IN, V4, P2052	22	0	0	0	1	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA			1-932415-61-0				2005							1142	1148				7	Computer Science, Theory & Methods	Computer Science	BDY80	WOS:000236257900168		
B	Wang, LJ; Wang, XL; Chen, QC			IEEE	Wang, LJ; Wang, XL; Chen, QC			GA-based feature subset clustering for combination of multiple nearest neighbors classifiers	Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9			English	Proceedings Paper	4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	Canton, PEOPLES R CHINA	IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany		nearest neighbor classifier (NNC); majority voting rule; multiple-classifier combination; feature subset clustering; GA		Nearest Neighbor Classifier (NNC) is stable to the change of the training data set while sensitive to the variation of the feature set. The combination of multiple NNCs on different subsets of features may outperform the standard NNC. In this paper, we develop a new method called FC-MNNC based on feature subset clustering for combining multiple NNCs to obtain better performance than that using a single NNC. In this method, GA is used for clustering features to form different feature subsets according to the combination classification accuracy. Multiple NNCs based on the corresponding feature subsets are parallel and independent to classify one pattern. The final decision is aggregated by majority voting rule, which is a simple and efficient technique. To demonstrate the performance of FC-MNNC, we select four UCI databases in our experiments. The proposed FC-MNNC is compared with (i) standard NNC, (ii) feature selection using GA in individual NNC and (iii) feature subset selection using GA in multiple NNCs. The experimental results show that the accuracy of FC-MNNC is better than that of the standard NNC and feature selection using GA in individual classifier. The performance of FC-MNNC is not worse than that of feature subset selection using GA in multiple NNCs. It is also demonstrated that FC-MNNC is robust to irrelevant features.	Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150001, Peoples R China	Wang, LJ (reprint author), Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150001, Peoples R China.						Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; [Anonymous], UCI REPOSITORY MACHI; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Hart P., 1988, IEEE T INFORM THEORY, V13, P21; Jain A. K., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Kuncheva LI, 2000, IEEE T EVOLUT COMPUT, V4, P327, DOI 10.1109/4235.887233; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Langley P., 1993, P 13 INT JOINT C ART, P889; Mitchell T. M., 2003, MACHINE LEARNING; Skalak D., 1997, THESIS U MASSACHUSET; Vishwath P., 2004, Information fusion, P239	14	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9091-1				2005							2982	2987				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BDT94	WOS:000235325604073		
B	Wang, JG; Neskovic, P; Cooper, LN			IEEE	Wang, JG; Neskovic, P; Cooper, LN			An adaptive nearest neighbor algorithm for classification	Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9			English	Proceedings Paper	4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	Canton, PEOPLES R CHINA	IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany		classification; nearest neighbor rule; curse of dimensionality; statistical confidence	REGRESSION	The k-nearest neighbor rule is one of the simplest and most attractive pattern classification algorithms. It can be interpreted as an empirical Bayes classifier based on the estimated a posteriori probabilities from the k nearest neighbors. The performance of the k-nearest neighbor rule relies on the locally constant a posteriori probability assumption. This assumption, however, becomes problematic in high dimensional spaces due to the curse of dimensionality. In this paper we introduce a locally adaptive nearest neighbor rule. Instead of using the Euclidean distance to locate the nearest neighbors, the proposed method takes into account the effective influence size of each training example and the statistical confidence with which the label of each training example can be trusted. We test the new method on real-world benchmark datasets and compare it with the standard k-nearest neighbor rule and the support vector machines. The experimental results confirm the effectiveness of the propose method.	Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA.						Blake CL, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E., 1951, 4 USAF SCH AV MED RA; FRIEDMAN J, 1994, 113 U STAT DEP; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	10	2	4	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9091-1				2005							3069	3074				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BDT94	WOS:000235325604089		
B	Marchiori, E; Heegaard, NHH; West-Nielsen, M; Jimenez, CR			IEEE	Marchiori, E; Heegaard, NHH; West-Nielsen, M; Jimenez, CR			Feature selection for classification with proteomic data of mixed quality	Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology			English	Proceedings Paper	2nd IEEE Symposium on Computational Intelligence in Bioformatics and Computational Biology	NOV 14-15, 2005	La Jolla, CA	IEEE Computat Intelligence Soc			PROSTATE-CANCER; OVARIAN-CANCER; SERUM; PATTERNS; ALGORITHMS	In this paper we assess experimentally the performance of two state-of-the-art feature selection methods, called RFE and RELIEF, when used for classifying pattern proteomic samples of mixed quality. The data are generated by spiking human sera to artificially create differentiable sample groups, and by handling samples at different storage temperature. We consider two type of classifiers: support vector machines (SVM) and k-nearest neighbour (kNN). Results of leave-one-out cross validation (LOOCV) experiments indicate that RELIEF selects more stable feature subsets than RFE over the runs, where the selected features are mainly spiked ones. However, RFE outperforms RELIEF in terms of (average LOOCV) accuracy, both when combined with SVM and kNN. Perfect LOOCV accuracy is obtained by RFE combined with INN. Almost all the samples that are wrongly classified by the algorithms have high storage temperature. The results of experiments on this data indicate that when samples of mixed quality are analyzed computationally, feature selection of only relevant (spiked) features does not necessarily correspond to highest accuracy of classification.	Vrije Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands	Marchiori, E (reprint author), Vrije Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands.						Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI, V1st; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Evgeniou T, 2004, MACH LEARN, V55, P71, DOI 10.1023/B:MACH.0000019805.88351.60; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Issaq HJ, 2003, ANAL CHEM, V75, p148A, DOI 10.1021/ac031249c; John G. H., 1994, INT C MACH LEARN, P121; JONG K, 2004, IEEE S COMP INT BIOI; Kira K., 1992, 10 NAT C ART INT, P129; Li JN, 2002, CLIN CHEM, V48, P1296; LIE H, 1998, INT SERIES ENG COMPU; Liu Huiqing, 2002, Genome Inform, V13, P51; Marshall E, 2004, SCIENCE, V306, P630, DOI 10.1126/science.306.5696.630; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Mitchell T. M., 1997, MACHINE LEARNING; OH IS, 2002, 16 INT C PATT REC IC; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; Ransohoff DF, 2005, J NATL CANCER I, V97, P315, DOI 10.1093/jnci/dji054; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Rendell L. A., 1992, INT C MACH LEARN, P249; Vapnik V., 1998, STAT LEARNING THEORY; WESTNIELSEN M, 2005, ANAL CHEM; XING E, 2003, PRACTICAL APPROACH M; Yu L., 2003, ICML, P856; 2003, PNAS, V100, P14666	29	4	4	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9387-2				2005							385	391				7	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BDU91	WOS:000235518600054		
B	Thulasiram, RK; Bamgbade, AY		Blair, S; Chakraborty, U; Chen, SH; Cheng, HD; Chiu, DKY; Das, S; Denker, G; Duro, R; Romay, MG; Hung, D; Kerre, EE; VaLeong, H; Lu, CT; Lu, J; Maguire, L; Ngo, CW; Sarfraz, M; Tseng, C; Tsumoto, S; Ventura, D; Wang, PP; Yao, X; Zhang, CN; Zhang, K		Thulasiram, RK; Bamgbade, AY			Application of an instance based learning algorithm for predicting stock market index	Proceedings of the 8th Joint Conference on Information Sciences, Vols 1-3			English	Proceedings Paper	8th Joint Conference on Information Sciences (JCIS 2005)	JUL 21-26, 2005	Salt Lake City, UT	Duke Univ, Utah State Univ, San Jose State Univ, Harbin Inst Technol				This paper presents application of an instance based learning (IBL) algorithm for predicting stock index price changes. The objective is to determine the feasibility of stockprice prediction using the IB3 variant of the IBL algorithms. Various testing proportions and normalization methods were experimented to obtain good predictions. The results obtained are promising.	Univ Manitoba, Dept Comp Sci, Winnipeg, MB, Canada	Thulasiram, RK (reprint author), Univ Manitoba, Dept Comp Sci, Winnipeg, MB, Canada.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; APOSTOLOS PR, 1995, NEURAL NETWORKS CAPI; *B GOV FED RES SYS, FED RES STAT REL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hogg R.V., 2001, PROBABILITY STAT INF; Kovalerchuk B., 2000, DATA MINING FINANCE; OLIKER S, 1997, NONLINEAR FINANCIAL, P183; WEIGEND AS, 1997, DECISION TECHNOLOGIE	8	0	0	0	0	JOINT CONFERENCE INFORMATION SCIENCES	DURHAM	2709 MONTGOMERY ST, DURHAM, NC 27705 USA							2005							1110	1113				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI96	WOS:000233670801134		
B	Alizon, F; Shooter, S; Simpson, T			ASME	Alizon, Fabrice; Shooter, Steve; Simpson, Timothy			Introduction of the reuse method: Retrieving knowledge from existing product designs	Proceedings of the ASME Design Engineering Division 2005, Pts A and B			English	Proceedings Paper	ASME International Mechanical Engineering Congress and Exposition	NOV 05-11, 2005	Orlando, FL	ASME, Proc Ind Div, ASME, Rail Transportat Div, ASME, Noise Control & Acoust Div, ASME, Triol Div, ASME, Pressure Vessels & Piping Div, ASME, Bioengn Div, ASME, Mat Div, ASME, Appl Mech Div, ASME, Fluids Engn Div, ASME, Micro Elect Mech Syst Div, ASME, Heat Transfer Div, ASME, Nucl Engn Div, ASME, Power Div, ASME, Solar Energy Div, ASME, Safety Engn & Risk Anal Div, ASME, Technol & Soc Div, ASME, Adv Energy Syst Div, ASME, Aerosp Div, ASME, Comp & Informat Engn Div			CLASSIFICATION; INFORMATION	In today's marketplace, most products must better satisfy customers' needs in the shortest time and be competitively priced. In this context, the reuse of knowledge about the targeted product is critical for developing potential product platforms. One can facilitate the reuse of existing knowledge to achieve a desired design by establishing a method that considers the layout of modules (or components) with identified flow interfaces, volume and the fundamental functional description. The problem grows with the number of candidate modules and with information-rich descriptions. The proposed REUSE (Reuse Existing Unit for Shape and Efficiency) Method greatly facilitates this search by filtering candidates based on their similarity to desired characteristics and their performance efficiency. By reusing existing information from components and modules, this approach allows the detailed specification of cost (e.g., investment and production cost for a module) along with other desired characteristics. This method applies to the complete product realization enterprise from conception through product launch. It also enables traceability of design decisions to help capture rationale and justification. A case study involving a family of cameras illustrates the proposed method.	Bucknell Univ, Dept Mech Engn, Lewisburg, PA 17837 USA	Alizon, F (reprint author), Bucknell Univ, Dept Mech Engn, Lewisburg, PA 17837 USA.						Akoumianakis D, 1997, EXPERT SYST APPL, V12, P225, DOI 10.1016/S0957-4174(96)00097-8; ALIZON F, 2002, P FAIM; BRADLEY SR, 1993, ASME C DES THEOR MET, V53, P139; Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROFT WB, 1979, J DOC, V35, P285, DOI 10.1108/eb026683; CULLEY SJ, 1992, P I MECH ENG B-J ENG, V206, P253, DOI 10.1243/PIME_PROC_1992_206_082_02; Culley SJ, 1999, P I MECH ENG B-J ENG, V213, P203, DOI 10.1243/0954405991517371; Deutschman A. D., 1975, MACHINE DESIGN; DIPILLO PJ, 1976, COMMUN STAT A-THEOR, V5, P843; Fogel L. J., 1966, ARTIFICIAL INTELLIGE; French MJ, 1993, J ENG DESIGN, V4, P267, DOI 10.1080/09544829308914786; JAYNES ET, 1967, CONFIDENCE INTERVALS, V2, P175; NANDA J, IN PRESS J COMPUTING; Pahl G., 1984, ENG DESIGN; ROY B., 1996, MULTICRITERIA METHOD; Roy B., 1993, ECONOMICA PARIS; ROY B, 1991, THEOR DECIS, V31, P49, DOI 10.1007/BF00134132; Shooter SB, 2000, ENG COMPUT-GERMANY, V16, P178, DOI 10.1007/s003660070004; SHOOTER SB, 2004, P ASME DETC; Sivaloganathan S, 1999, P I MECH ENG B-J ENG, V213, P641, DOI 10.1243/0954405991517092; Stone RB, 2000, J MECH DESIGN, V122, P359, DOI 10.1115/1.1289637; Szykman S, 2001, COMPUT AIDED DESIGN, V33, P545, DOI 10.1016/S0010-4485(01)00053-7; THEVENOT HJ, IN PRESS J ENG DESIG; TROUSSE B, 1993, ADVANCED TECHNOLOGIES, P451; VOGWELL J, 1991, P I MECH ENG B-J ENG, V205, P11, DOI 10.1243/PIME_PROC_1991_205_045_02; WEBBER SJ, 1994, THESIS U BATH; WOOD TJ, 1994, THESIS U BATH; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	29	0	0	0	1	AMER SOC MECHANICAL ENGINEERS	NEW YORK	THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA			0-7918-4215-0				2005							335	343				9	Engineering, Mechanical	Engineering	BFI29	WOS:000241987200038		
B	Owotoki, P; Mayer-Lindenberg, F		Turau, V; Weyer, C		Owotoki, P; Mayer-Lindenberg, F			Comprehensible hierarchical intelligent (CHI) framework for monitoring and preventive maintenance of aircraft systems	Proceedings of the Third International Workshop on Intelligent Solutions in Embedded Systems			English	Proceedings Paper	3rd International Workshop on Intelligent Solutions in Embedded Systems (WISES 05)	MAY   20, 2005	Hamburg, GERMANY		Hamburg Univ Technol		ORGANIZATION	The peculiarities of the aircraft monitoring and maintenance domain are described and shortcomings of the current monitoring methodology are revealed. It is also shown why a new approach using computational intelligence models, as a replacement for the current BITE models, is paramount. In section 2 a brief review of developments in computational intelligence research is given. After which we present the comprehensible hierarchical intelligent framework, as a conceptual non monolithic intelligent approach utilizing distributed CI models for monitoring. Finally we conclude with discussions on the implementation and justification for our approach and direction for future work.	Tech Univ Hamburg, Dept Distributed Syst, D-2100 Hamburg, Germany	Owotoki, P (reprint author), Tech Univ Hamburg, Dept Distributed Syst, D-2100 Hamburg, Germany.						AHA DW, 1989, P 4 INT WORKSH MACH, P27; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AAMODT A, 1994, AI COMMUN, V7, P39; Breiman L, 1984, CART CLASSIFICATION; BROOKS RA, 1998, P 15 NAT C ART INT A; Buchanan B. G., 1984, RULE BASED EXPERT SY; BUNTINE W, 1989, P 6 INT WORKSH MACH, P94; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; Chan P. K., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); CHEN HC, 1992, IEEE T SYST MAN CYB, V22, P885, DOI 10.1109/21.179830; Cios K, 2002, KNOWLEDGE DISCOVERY; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAENEN BC, 2002, COMPUTATIONAL INTELL; Domingos P, 1996, MACH LEARN, V24, P141; Fayyad U., 1996, P 2 INT C KNOWL DISC, P82; Feigenbaum E. A, 1977, INT JOINT C ART INT, P1014; Grossberg S., 1982, STUDIES MIND BRAIN; Hayes-Roth Frederick, 1983, BUILDING EXPERT SYST; HOLLAND JH, 1975, ADAPTATION NATURAL A; Holsheimer M., 1994, CSR9406 CWI; HONG J, 1986, UIUCDCSF86949; Koza J., 1992, GENETIC PROGRAMMING; KUBAT M, 1997, MACHINE LEARNING DAT, P3; MITCHELL TM, 1980, TR117 RUTG U COMP SC; NEWELL A, 1956, IRE T INFORM THEOR, V2, P61, DOI 10.1109/TIT.1956.1056797; Newell A, 1960, P INT C INF PROC, P256; PARSAYE K, 1989, INTELLIGENT DATABASE; QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, MACHINE LEARNING, V1, P1086; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salzberg S.L., 1990, LEARNING NESTED GEN; SANTOS E, 1996, AFITENTR9601; SCHAFFER C, 1995, P 11 INT C MACH LEAR, P259; SHAPIRO GP, 1989, WORKSH KNOWL DISC RE; TSAKONAS A, 2002, INT C SETN02 THESS G; Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069; WELBANK M, 1983, REV KNOWLEDGE ACQUIS; Willis WD, 2004, SENSORY MECH SPINAL, V1; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zadeh Lotfi A., 1965, FUZZY SETS INFORM CO, V8, P338, DOI DOI 10.1016/S0019-9958(65)90241-X; ZIMMERMANN HJ, 2002, ADV COMP INTELLIG LE	46	0	0	0	1	HAMBURG UNIV TECHNOLOGY	HAMBURG	HAMBURG UNIV, HAMBURG, D-21073, GERMANY			3-902463-03-1				2005							175	184				10	Computer Science, Artificial Intelligence	Computer Science	BCP46	WOS:000230544200017		
B	Knight, B; Woon, FL		Bramer, M; Coenen, F; Allen, T		Knight, B; Woon, FL			Case based adaptation using interpolation over nominal values	RESEARCH AND DEVELOPMENT IN INTELLIGENT SYSTEMS XXI	BCS CONFERENCE SERIES		English	Proceedings Paper	24th SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence (AI-2004)	DEC 12-15, 2004	Cambridge, ENGLAND	British Comp Soc Specialist Grp Artificial Intelligence			SCATTERED DATA; SETS	In this paper we propose a method for interpolation over a set of retrieved cases in the adaptation phase of the case-based reasoning cycle. The method has two advantages over traditional systems: the first is that it can predict "new" instances, not yet present in the case base; the second is that it can predict solutions not present in the retrieval set. The method is a generalisation of Shepard's Interpolation method, formulated as the minimisation of an error function defined in terms of distance metrics in the solution and problem spaces. We term the retrieval algorithm the Generalised Shepard Nearest Neighbour (GSNN) method. A novel aspect of GSNN is that it provides a general method for interpolation over nominal solution domains. The method is illustrated in the paper with reference to the Irises classification problem. It is evaluated with reference to a simulated nominal value test problem, and to a benchmark case base from the travel domain. The algorithm is shown to out-perform conventional nearest neighbour methods on these problems. Finally, GSNN is shown to improve in efficiency when used in conjunction with a diverse retrieval algorithm.	Univ Greenwich, CMS, London SE18 6PF, England	Knight, B (reprint author), Univ Greenwich, CMS, London SE18 6PF, England.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; FRANKE R, 1980, INT J NUMER METH ENG, V15, P1691, DOI 10.1002/nme.1620151110; KNIGHT B, 2003, P 18 INT JOINT C ART, P1347; Lazzaro D, 2002, J COMPUT APPL MATH, V140, P521, DOI 10.1016/S0377-0427(01)00485-X; LENZ M, 1996, P 3 EUR WORKSH CAS B, P219; Mitchell T. M., 1997, SERIES COMPUTER SCI; RAMOS GA, 2001, P IASTED INT C VISUA, P219; Shepard D, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; Smyth B., 2001, P 4 INT C CAS BAS RE, P347; SMYTH B, 2003, P 18 INT JOINT C ART, P127; SMYTH B, 1998, P 4 EUR WORKSH CAS B, P208; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	14	1	1	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES			1-85233-907-1	BCS CONFERENCE S			2005							73	86		10.1007/1-84628-102-4_6		14	Computer Science, Artificial Intelligence	Computer Science	BBP52	WOS:000226889800006		
S	Milner, GM		Carapezza, EM		Milner, GM			Detection/classification/quantification of chemical agents using an array of surface acoustic wave (SAW) devices	Sensors, and Command, Control, Communications, and Intelligence (C31) Technologies for Homeland Security and Homeland Defense IV, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Sensors, and Command, Control, Communications, and Intelligence (C31) Technologies for Homeland Security and Homeland Defense IV	MAR 28-APR 01, 2005	Orlando, FL			chemical warfare agent (CWA) detection / classification / quantification; toxic industrial chemicals (TICS); surface acoustic wave (SAW) arrays; signal processing		ChemSentry (TM) is a portable system used to detect, identify, and quantify chemical warfare (CW) agents. Electro chemical (EC) cell sensor technology is used for blood agents and an array of surface acoustic wave (SAW) sensors is used for nerve and blister agents. The combination of the EC cell and the SAW array provides sufficient sensor information to detect, classify and quantify all CW agents of concern using smaller, lighter, lower cost units. Initial development of the SAW array and processing was a key challenge for ChemSentry (TM) requiring several years of fundamental testing of polymers and coating methods to finalize the sensor array design in 2001. Following the finalization of the SAW array, nearly three (3) years of intensive testing in both laboratory and field environments were required in order to gather sufficient data to fully understand the response characteristics. Virtually unbounded permutations of agent characteristics and environmental characteristics must be considered in order to operate against all agents and all environments of interest to the U.S. military and other potential users of ChemSentry (TM). The resulting signal processing design matched to this extensive body of measured data (over 8,000 agent challenges and 10,000 hours of ambient data) is considered to be a significant advance in state-of-the-art for CW agent detection.	BAE Syst, Integrated Def Solut, Austin, TX 78725 USA	Milner, GM (reprint author), BAE Syst, Integrated Def Solut, 6500 Tracor Ln, Austin, TX 78725 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Farley J. U., 1975, J ECONOMETRICS, V3, P297, DOI 10.1016/0304-4076(75)90037-8	2	5	6	1	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-5763-9	P SOC PHOTO-OPT INS			2005	5778		1-2				305	316		10.1117/12.611372		12	Engineering, Multidisciplinary	Engineering	BCR48	WOS:000230925700032		
B	Ishii, N; Tsuchiya, E; Bao, YG; Yamaguchi, N		Lee, R; Lee, KW; Malloy, B		Ishii, N; Tsuchiya, E; Bao, YG; Yamaguchi, N			Combining classification improvements by ensemble processing	Third ACIS International Conference on Software Engineering Research, Managment and Applications, Proceedings			English	Proceedings Paper	3rd International Conference on Software Engineering Research, Management and Applications	AUG 11-13, 2005	Mt Pleasant, MI		Cent Michigan Univ	data mining; artificial intelligence; knowledge discovery		The k-nearest neighbor (KNN) classification is a simple and effective classification approach. However improving performance of the classifier is still attractive. Combining multiple classifiers is an effective technique for improving accuracy. There are many general combining algorithms, such as Bagging, Boosting, or Error Correcting Output Coding that significantly improve the classifier such as decision trees, rule learners, or neural networks. Unfortunately, these combining methods developed do not improve the nearest neighbor classifiers. In this paper first, we present a new approach to combine multiple KNN classifiers based on different distance functions, in which we apply multiple distance functions to improve the performance of the k-nearest neighbor classifier Second, we develop a combining method, in which the weights of the distance function, are learnt by genetic algorithm. Finally, combining classifiers in error correcting output coding, are discussed The proposed algorithms seek to increase generalization accuracy when compared to the basic k-nearest neighbor algorithm. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository. The results show that the proposed algorithms improve the performance of the k-nearest neighbor classification.								BAO Y, 2002, P 5 INT C DISC SCI, P361; Bao YG, 2002, LECT NOTES COMPUT SC, V2412, P461; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ITQON S, 2000, J IECI, V2, P23; Merz C, 1998, UCI REPOSITORY MACHI; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tapia R.A., 1978, NONPARAMETRIC PROBAB; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YAMAGUCHI Y, 2004, SYSTEMS COMPUTERS JA, V35, P9	12	0	0	3	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2297-1				2005							240	246				7	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BCX73	WOS:000231789000031		
S	Wojna, A		Peters, JF; Skowron, A		Wojna, A			Analogy-based reasoning in classifier construction	TRANSACTIONS ON ROUGH SETS IV	Lecture Notes in Computer Science		English	Article						analogy-based reasoning; case-based reasoning; k nearest neighbors; similarity measure; distance based indexing; hybrid decision system; local metric induction	NEAREST-NEIGHBOR CLASSIFICATION; COMBINING RULE INDUCTION; LEARNING ALGORITHMS; SCIENCE; SYSTEM; RIONA; TREES	Analogy-based reasoning methods in machine learning make it possible to reason about properties of objects on the basis of similarities between objects. A specific similarity based method is the k nearest neighbors (k-nn) classification algorithm. In the k-nn algorithm, a decision about a new object x is inferred on the basis of a fixed number k of the objects most similar to x in a given set of examples. The primary contribution of the dissertation is the introduction of two new classification models based on the k-nn algorithm. The first model is a hybrid combination of the k-nn algorithm with rule induction. The proposed combination uses minimal consistent rules defined by local reducts of a set of examples. To make this combination possible the model of minimal consistent rules is generalized to a metric-dependent form. An effective polynomial algorithm implementing the classification model based on minimal consistent rules has been proposed by Bazan. We modify this algorithm in such a way that after addition of the modified algorithm to the k-nn algorithm the increase of the computation time is inconsiderable. For some tested classification problems the combined model was significantly more accurate than the classical k-nn classification algorithm. For many real-life problems it is impossible to induce relevant global mathematical models from available sets of examples. The second model proposed in the dissertation is a method for dealing with such sets based on locally induced metrics. This method adapts the notion of similarity to the properties of a given test object. It makes it possible to select the correct decision in specific fragments of the space of objects. The method with local metrics improved significantly the classification accuracy of methods with global models in the hardest tested problems. The important issues of quality and efficiency of the k-nn based methods are a similarity measure and the performance time in searching for the most similar objects in a given set of examples, respectively. In this dissertation both issues are studied in detail and some significant improvements are proposed for the similarity measures and for the search methods found in the literature.	Warsaw Univ, Inst Informat, PL-02097 Warsaw, Poland	Wojna, A (reprint author), Warsaw Univ, Inst Informat, Banacha 2, PL-02097 Warsaw, Poland.	wojna@mimuw.edu.pl					Aggarwal C. C., 2001, P 8 INT C DAT THEOR, P420; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ajdukiewicz K., 1974, LOGIKA PRAGMATYCZNA; BAZAN JG, 1998, LNCS, V1424, P521; Bazan J.G., 2001, LECT NOTES ARTIF INT, V2005, P106; Bazan JG, 2004, LECT NOTES ARTIF INT, V3066, P592; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Bellman Richard, 1957, DYNAMIC PROGRAMMING; Finkel R. A., 1974, Acta Informatica, V4, DOI 10.1007/BF00288933; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Beyer K., 1999, P 7 INT C DAT THEOR, P217; Biberman Y., 1994, P 9 EUR C MACH LEARN, P49; BISHOP CM, 1996, NEURAL NETWORKSH PAT; Blake C, 1998, UCI REPOSITORY MACHI; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Brin S., 1995, P 21 INT C VER LARG, P574; CHAVEZ E, TRDCC993 U CHILE; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2002, P 2 SIAM INT C DAT M; Domingos P, 1996, MACH LEARN, V24, P141; Duda R. O., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5; Fisher R.A., 1925, METRON, V5, P3; Fix E., 1951, 4 USAF SCH AV MED RA; Friedman J., 2001, ELEMENTS STAT LEARNI; FRIEDMAN J, 1997, 113 STANF U DEP STAT; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; Golding AR, 1996, ARTIF INTELL, V87, P215, DOI 10.1016/0004-3702(95)00120-4; Gora G, 2002, FUND INFORM, V51, P369; Gora G, 2002, LECT NOTES ARTIF INT, V2475, P405; Gora G, 2002, LECT NOTES ARTIF INT, V2430, P111; Grzymala-Busse J. W., 1992, HDB APPL ADV ROUGH S, P3; Guttman A, 1984, P ACM SIGMOD INT C M, P47; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Jensen F. V., 1996, INTRO BAYESIAN NETWO; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; Katayama N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Kira K., 1992, P 9 INT C MACH LEARN; Kleinberg J, 2004, J ACM, V51, P263, DOI 10.1145/972639.972644; Klosgen W., 2002, HDB DATA MINING KNOW; Kononenko I., 1994, LECT NOTES ARTIF INT, V784, P171; Leake D. B., 1996, CASE BASED REASONING; Li J, 2001, P 5 PAC AS C KNOWL D, P455; LI J, 2003, IN PRESS MACHINE LEA; Lin K, 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Luce D., 1957, GAMES DECISIONS; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Mitchell T. M., 1997, MACHINE LEARNING; NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586; Pawlak Z., 1991, ROUGH SETS THEORETIC; POLKOWSKI L, 1997, ROUGH SETS DATA MINI, P259; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Robinson J. J., 1981, Paper, 32nd Annual Meeting of the European Association for Animal Production; Rosenblueth A., 1943, PHILOS SCI, V10, P18, DOI DOI 10.1086/286788; Russell S. J., 1989, USE KNOWLEDGE ANALOG; SALZBERG S, 1991, MACH LEARN, V2, P229; Savares S.M., 2001, P 1 SIAM INT C DAT M, P1; SELLIS T, 1987, P 13 INT C VER LARG, P574; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; Skowron A, 2004, LECT NOTES ARTIF INT, V3066, P229; Skowron A., ROUGH SET EXPLORATIO; Skowron A., 2003, ROUGH NEURAL COMPUTI, P43; Skowron A, 1992, INTELLIGENT DECISION, P331; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Student Gosset WS, 1908, BIOMETRIKA, V6, P1, DOI DOI 10.1093/BIOMET/6.1.1; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Vapnik V., 1998, STAT LEARNING THEORY; VELOSO M, 1994, PLANNING LEARNING AN; Von Neumann J, 1944, THEORY GAMES EC BEHA; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Wettschereck D, 1994, THESIS OREGON STATE; White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202; Wiener N, 1948, CYBERNETICS; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Wojna A, 2003, FUND INFORM, V56, P285; WOJNA AG, 2000, THESIS WARSAW U; WOJNA AG, 2003, P 3 IEEE INT C DAT M, P681; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445; Wroblewski J., 1998, LECT NOTES ARTIF INT, V1424, P402; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Zavrel J., 1997, P 7 BELG DUTCH C MAC, P139	96	19	19	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-29830-4	LECT NOTES COMPUT SC			2005	3700						277	374				98	Computer Science, Theory & Methods	Computer Science	BDN26	WOS:000234424800011		
J	Sanz, PJ; Marin, R; Sanchez, JS				Sanz, PJ; Marin, R; Sanchez, JS			Including efficient object recognition capabilities in online robots: From a statistical to a neural-network classifier	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						incremental learning; neural networks; object recognition; online robots		For those situations in which the user wants to interact with the system by using, for example, voice commands, it would be convenient to refer to the objects by their names (e.g., "cube") instead of other types of interactions (e.g., "grasp object 1"). Thus, automatic object recognition is the first step in order to acquire a higher level of interaction between the user and the robot. Nevertheless, applying object recognition techniques when the camera images are being transmitted through the web is not an easy task. In this situation, images cannot have a very high resolution, which affects enormously the recognition process due to the inclusion of more errors while digitalizing the real image. Some experiments with the Universitat Jaume I Online Robot evaluate the performance of different neural-network implementations, comparing it to that of some distance-based object recognition algorithms. Results will show which combination of object features, and algorithms (both statistical and neural networks) is more appropriate to our purpose in terms of both effectiveness and computing time.	Jaume Univ 1, Dept Comp Sci, E-12071 Castellon de La Plana, Spain; Jaume Univ 1, Programming Languages Dept, E-12071 Castellon de La Plana, Spain	Sanz, PJ (reprint author), Jaume Univ 1, Dept Comp Sci, E-12071 Castellon de La Plana, Spain.	sanzp@uji.es; nnarin@uji.es; sanchez@uji.es	Marin, Raul/B-4704-2008; 	Marin, Raul/0000-0002-2340-4126; Sanchez Garreta, Jose Salvador/0000-0003-1053-4658			Baruch J. E. F., 1994, P 2 INT C WORLD WID; CHEN SC, 1994, J GASTROEN HEPATOL, V9, P1, DOI 10.1111/j.1440-1746.1994.tb01207.x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1990, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; FERWORN A, 1999, P IASTED C ROB APPL, P158; Goldberg K., 1995, P ACM SIGGRAPH, P135; GOLDBERG K, 1995, IEEE INT CONF ROBOT, P654, DOI 10.1109/ROBOT.1995.525358; GOLDBERG S, 1998, P IEEE IROS 98 WORKS, P55; Holmstrom L, 1997, IEEE T NEURAL NETWOR, V8, P5, DOI 10.1109/72.554187; HU M, 1962, IRE T INFORM THEOR, V8, P179; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Marin R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013644; Marin R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013643; MCKEE GT, 1996, ROBOTICS MACHINE PER, V5; PAULO E, 1999, P IEEE INT C ROB AUT, P1250; Preece J., 1994, HUMAN COMPUTER INTER; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Saucy P, 2000, IEEE ROBOT AUTOM MAG, V7, P41, DOI 10.1109/100.833574; Schalkoff R.J., 1992, PATTERN RECOGNITION; Schulz D, 2000, IEEE ROBOT AUTOM MAG, V7, P48, DOI 10.1109/100.833575; SIMMONS R, 1998, P IROS 98 WORKSH WEB, P43	22	4	4	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1094-6977	1558-2442		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	FEB	2005	35	1					87	96		10.1109/TSMCC.2004.840055		10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	889YU	WOS:000226479600009		
J	Li, J; Manry, MT; Yu, CH; Wilson, DR				Li, J; Manry, MT; Yu, CH; Wilson, DR			Prototype classifier design with pruning	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article; Proceedings Paper	17th International FLAIRS Conference	MAY 17-19, 2004	Miami Beach, FL	FLAIRS		prototype selection; nearest neighbor classifier; editing; condensing; instance-based learning; pruning technology	NEAREST-NEIGHBOR RULE; CASE-BASE MAINTENANCE; LEARNING ALGORITHMS; PATTERN-CLASSIFICATION	Algorithms reducing the storage requirement of the nearest neighbor classifier (NNC) can be divided into three main categories: Fast searching algorithms, Instance-based learning algorithms and Prototype based algorithms. We propose an algorithm, LVQPRU, for pruning NNC prototype vectors and a compact classifier with good performance is obtained. The basic condensing algorithm is applied to the initial prototypes to speed up the learning process. The learning vector quantization (LVQ) algorithm is utilized to fine tune the remaining prototypes during each pruning iteration. We evaluate LVQPRU on several data sets along with 12 other algorithms using ten-fold cross-validation. Simulation results show that the proposed algorithm has high generalization accuracy and good storage reduction ratios.	Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA; Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Li, J (reprint author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.	li@wcn.uta.edu; randy@axon.cs.byu.edu					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Batchelor B. G., 1978, PATTERN RECOGNITION; Biberman Y., 1994, P 9 EUR C MACH LEARN, P49; Cameron-Jones R. M., 1995, P 8 AUSTR JOINT C AR, P99; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GERSHO A, 1982, IEEE T INFORM THEORY, V28, P157, DOI 10.1109/TIT.1982.1056457; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GONG W, 1994, PROGR NEURAL NETWORK, V2, P253; Hassoun Mohamad H., 1995, FUNDAMENTALS ARTIFIC; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Kohonen T., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), DOI 10.1109/IJCNN.1990.137622; Kohonen T., 1995, SELF ORG MAPS; Kubat M., 2000, P 17 INT C MACH LEAR, P503; LI J, 2004, P 17 INT C FLOR AI R, P706; Merz C. J., 1996, UCI REPOSITORY MACHI; Nock R., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000453; PAPADIMITRIOU HC, 1980, LECT NOTES COMPUTER, V85, P470; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Portinale L, 2001, COMPUT INTELL, V17, P263, DOI 10.1111/0824-7935.00144; ROZSYPAL A, 2001, P 18 INT C MACH LEAR, P449; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Sebban M., 2002, J MACHINE LEARNING R, V3, P863; Sebban M., 2001, P 18 INT C MACH LEAR, P505; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STEPHEN LC, 1994, J INTELL FUZZY SYST, V2, P267; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; Vapnik V. N., 1995, NATURE STAT LEARNING; Wan E A, 1990, IEEE Trans Neural Netw, V1, P303, DOI 10.1109/72.80269; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson D.R., 1997, P 14 INT C MACH LEAR, P404; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; YAGER RR, 1994, IEEE T SYST MAN CYB, V24, P1279, DOI 10.1109/21.299710; Yang Q, 2001, COMPUT INTELL, V17, P250, DOI 10.1111/0824-7935.00143; Zubek V.B., 2002, P 19 INT C MACH LEAR, P27	40	8	8	1	2	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130			INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	FEB-APR	2005	14	1-2					261	280		10.1142/S0218213005002090		20	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	986SA	WOS:000233468800015		
J	Muller, KR; Ratsch, G; Sonnenburg, S; Mika, S; Grimm, M; Heinrich, N				Muller, KR; Ratsch, G; Sonnenburg, S; Mika, S; Grimm, M; Heinrich, N			Classifying 'drug-likeness' with kernel-based learning methods	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							SUPPORT VECTOR MACHINE; CLASSIFICATION; COEFFICIENTS	In this article we report about a successful application of modern machine learning technology, namely Support Vector Machines, to the problem of assessing the 'drug-likeness' of a chemical from a given set of descriptors of the Substance. We were able to drastically improve the recent result by Byvatov et al. (2003) on this task and achieved an error rate of about 7% on unseen compounds using Support Vector Machines. We see a very high potential of such machine learning techniques for a variety of computational chemistry problems that occur in the drug discovery and drug design process.	Fraunhofer FIRST, D-12489 Berlin, Germany; Univ Potsdam, D-14482 Potsdam, Germany; Max Planck Soc, Friedrich Miescher Lab, D-72076 Tubingen, Germany; Idalab GmbH, D-10117 Berlin, Germany; Schering AG, Computat Chem, D-13342 Berlin, Germany	Sonnenburg, S (reprint author), Fraunhofer FIRST, Kekulestr 7, D-12489 Berlin, Germany.	soeren.sonnenburg@first.fraunhofer.de	Ratsch, Gunnar/B-8182-2009; Sonnenburg, Soeren/F-2230-2010; Muller, Klaus/C-3196-2013				Bennet K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; Boser B. E., 1992, P 5 ANN ACM WORKSH C; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVILLERS J, 1996, PRINCIPLES QSAR DRUG, V2; Fisher RA, 1936, ANN EUGENIC, V7, P179; Gasteiger J., 1999, NEURAL NETWORKS CHEM; GHOSE AK, 1986, J COMPUT CHEM, V7, P565, DOI 10.1002/jcc.540070419; GRAEPEL T, 1999, P ICANN 99, V1, P304; Metz C.E., 1978, SEMINARS NUCL MED, V8; MIKA S, 2001, ADV NEURAL INFORMATI, V13; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; ORR G, 1998, SPRINGER LNCS, V1524; Peterson KL, 2000, REV COMP CH, V16, P53, DOI 10.1002/9780470125939.ch2; Quinlan J.R, 1992, C4 5 PROGRAMS MACHIN; Sadowski J, 1998, J MED CHEM, V41, P3325, DOI 10.1021/jm9706776; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Vapnik V. N., 1995, NATURE STAT LEARNING; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; 1996, AVAILABLE CHEM DIREC; 1966, WORLD DRUG INDEX WDI	25	52	53	2	4	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	MAR-APR	2005	45	2					249	253		10.1021/ci049737o		5	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	911PZ	WOS:000228018000005	15807485	
J	Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM				Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM			Wavelet-based methods for the prognosis of mechanical and electrical failures in electric motors	MECHANICAL SYSTEMS AND SIGNAL PROCESSING			English	Article						fault prognosis; wavelets; d.c. motors	FAULT-DETECTION; NEURAL-NETWORK; DC MOTOR; CLASSIFICATION; DIAGNOSIS	The ability to give a prognosis for failure of a system is a valuable tool and can be applied to electric motors. In this paper, three wavelet-based methods have been developed that achieve this goal. Wavelet and filter bank theory, the nearest-neighbour rule, and linear discriminant functions are reviewed. A framework for the development of a fault detection and classification algorithm based on the coefficients calculated from the discrete wavelet transform and using clustering is described. An experimental set-up based on RT-Linux is described and results from testing are presented, verifying the analysis. (C) 2003 Elsevier Ltd. All rights reserved.	Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48824 USA; Ford Motor Co, Dearborn, MI 48121 USA	Zanardelli, WG (reprint author), Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48824 USA.	zanardel@egr.msu.edu					Burrus C. S., 1998, INTRO WAVELETS WAVEL; Calvert T., 1974, CLASSIFICATION ESTIM; Chen D, 2002, MECH SYST SIGNAL PR, V16, P695, DOI 10.1006/ymssp.1488; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Liu XQ, 2000, IEEE T IND ELECTRON, V47, P1021; Moseler O, 2000, IEEE T IND ELECTRON, V47, P1015, DOI 10.1109/41.873209; Nejjari H, 2000, IEEE T IND APPL, V36, P730, DOI 10.1109/28.845047; Paya BA, 1997, MECH SYST SIGNAL PR, V11, P751, DOI 10.1006/mssp.1997.0090; Wang WJ, 2001, MECH SYST SIGNAL PR, V15, P685, DOI 10.1006/mssp.2000.1369; Webb AR, 2002, STAT PATTERN RECOGNI; ZANARDELLI WG, 2000, THESIS MICHIGAN STAT; Zanardelli WG, 2002, IEEE POWER ELECTRONICS IN TRANSPORATION, P61; ZANARDELLI WG, 2001, IEEE INT S DIAGN EL, P591	14	19	24	0	1	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0888-3270			MECH SYST SIGNAL PR	Mech. Syst. Signal Proc.	MAR	2005	19	2					411	426		10.1016/j.umssp.2003.10.002		16	Engineering, Mechanical	Engineering	858NH	WOS:000224198000012		
J	Garrow, AG; Agnew, A; Westhead, DR				Garrow, AG; Agnew, A; Westhead, DR			TMB-Hunt: An amino acid composition based method to screen proteomes for beta-barrel transmembrane proteins	BMC BIOINFORMATICS			English	Article							OUTER-MEMBRANE PROTEINS; GRAM-NEGATIVE BACTERIA; DATA-BANK; SUBCELLULAR LOCATIONS; CRYSTAL-STRUCTURE; SIGNAL PEPTIDES; PREDICTION; IDENTIFICATION; CLASSIFICATION; ARCHITECTURE	Background: Beta-barrel transmembrane (bbtm) proteins are a functionally important and diverse group of proteins expressed in the outer membranes of bacteria ( both gram negative and acid fast gram positive), mitochondria and chloroplasts. Despite recent publications describing reasonable levels of accuracy for discriminating between bbtm proteins and other proteins, screening of entire genomes remains troublesome as these molecules only constitute a small fraction of the sequences screened. Therefore, novel methods are still required capable of detecting new families of bbtm protein in diverse genomes. Results: We present TMB-Hunt, a program that uses a k-Nearest Neighbour (k-NN) algorithm to discriminate between bbtm and non-bbtm proteins on the basis of their amino acid composition. By including differentially weighted amino acids, evolutionary information and by calibrating the scoring, an accuracy of 92.5% was achieved, with 91% sensitivity and 93.8% positive predictive value (PPV), using a rigorous cross-validation procedure. A major advantage of this approach is that because it does not rely on beta-strand detection, it does not require resolved structures and thus larger, more representative, training sets could be used. It is therefore believed that this approach will be invaluable in complementing other, physicochemical and homology based methods. This was demonstrated by the correct reassignment of a number of proteins which other predictors failed to classify. We have used the algorithm to screen several genomes and have discussed our findings. Conclusion: TMB-Hunt achieves a prediction accuracy level better than other approaches published to date. Results were significantly enhanced by use of evolutionary information and a system for calibrating k-NN scoring. Because the program uses a distinct approach to that of other discriminators and thus suffers different liabilities, we believe it will make a significant contribution to the development of a consensus approach for bbtm protein detection.	Univ Leeds, Sch Biochem & Microbiol, Leeds LS2 9JT, W Yorkshire, England	Westhead, DR (reprint author), Univ Leeds, Sch Biochem & Microbiol, Leeds LS2 9JT, W Yorkshire, England.	bmbagg@bmb.leeds.ac.uk; A.M.Agnew@leeds.ac.uk; D.R.Westhead@leeds.ac.uk					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Andrade MA, 1998, J MOL BIOL, V276, P517, DOI 10.1006/jmbi.1997.1498; Bagos PG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-29; Bagos PG, 2004, NUCLEIC ACIDS RES, V32, pW400, DOI 10.1093/nar/gkh417; Bairoch A, 2005, NUCLEIC ACIDS RES, V33, pD154, DOI 10.1093/nar/gki070; Barker GC, 1999, GENE, V229, P131, DOI 10.1016/S0378-1119(99)00039-6; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Berven FS, 2004, NUCLEIC ACIDS RES, V32, pW394, DOI 10.1093/nar/gkh351; Bigelow HR, 2004, NUCLEIC ACIDS RES, V32, P2566, DOI 10.1093/nar/gkh580; Bitter W, 2003, ARCH MICROBIOL, V179, P307, DOI 10.1007/s00203-003-0541-8; BRENNAN PJ, 1995, ANNU REV BIOCHEM, V64, P29, DOI 10.1146/annurev.bi.64.070195.000333; Busch W, 2002, CRIT REV BIOCHEM MOL, V37, P287, DOI 10.1080/10409230290771528; Casadei R, 2003, GENE, V321, P185, DOI 10.1016/S0378-1119(03)00835-7; Casadio R, 2002, FEBS LETT, V520, P1, DOI 10.1016/S0014-5793(02)02758-8; Casadio R, 2003, PROTEIN SCI, V12, P1158, DOI 10.1110/ps.0223603; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chimento DP, 2003, NAT STRUCT BIOL, V10, P394, DOI 10.1038/nsb914; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eiben AE, 2002, INFORM PROCESS LETT, V82, P1, DOI 10.1016/S0020-0190(02)00204-1; ETZOLD T, 1993, COMPUT APPL BIOSCI, V9, P49; EVERETT KDE, 1995, J BACTERIOL, V177, P877; Faller M, 2004, SCIENCE, V303, P1189, DOI 10.1126/science.1094114; Fichera ME, 1997, NATURE, V390, P407, DOI 10.1038/37132; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Gardy JL, 2005, BIOINFORMATICS, V21, P617, DOI 10.1093/bioinformatics/bti057; Gobert GN, 2003, INT J PARASITOL, V33, P1561, DOI 10.1016/S0020-7519(03)00255-8; Gromiha MM, 2004, J COMPUT CHEM, V25, P762, DOI 10.1002/jcc.10386; Liu Q, 2003, COMPUT BIOL CHEM, V27, P69, DOI 10.1016/S0097-8485(02)00051-7; Liu Q, 2003, COMPUT BIOL CHEM, V27, P355, DOI 10.1016/S1476-9271(02)00085-3; Martelli Pier Luigi, 2002, Bioinformatics, V18 Suppl 1, pS46; Moller S, 2000, BIOINFORMATICS, V16, P1159, DOI 10.1093/bioinformatics/16.12.1159; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; Nielsen H, 1998, Proc Int Conf Intell Syst Mol Biol, V6, P122; Noguchi T, 2001, NUCLEIC ACIDS RES, V29, P219, DOI 10.1093/nar/29.1.219; Oomen CJ, 2004, EMBO J, V23, P1257, DOI 10.1038/sj.emboj.7600148; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Postle K, 2000, NAT STRUCT BIOL, V7, P527, DOI 10.1038/76726; Rost B, 1996, PROTEIN SCI, V5, P1704; Schleiff E, 2003, PROTEIN SCI, V12, P748, DOI 10.1110/ps.0237503; Schulz GE, 2000, CURR OPIN STRUC BIOL, V10, P443, DOI 10.1016/S0959-440X(00)00120-2; Song LZ, 1996, SCIENCE, V274, P1859, DOI 10.1126/science.274.5294.1859; Thanassi DG, 2002, J BACTERIOL, V184, P6260, DOI 10.1128/JB.184.22.6260-6269.2002; Tusnady GE, 2004, BIOINFORMATICS, V20, P2964, DOI 10.1093/bioinformatics/bth340; van den Berg B, 2004, SCIENCE, V304, P1506, DOI 10.1126/science.1097524; Viklund H, 2004, PROTEIN SCI, V13, P1908, DOI 10.1110/ps.04625404; Wimley WC, 2003, CURR OPIN STRUC BIOL, V13, P404, DOI 10.1016/S0959-440X(03)00099-X; Wimley WC, 2002, PROTEIN SCI, V11, P301, DOI 10.1110/ps.29402; Yau WM, 1998, BIOCHEMISTRY-US, V37, P14713, DOI 10.1021/bi980809c; Ye JQ, 2004, EMBO J, V23, P3187, DOI 10.1038/sj.emboj.7600330; Zhai YF, 2002, PROTEIN SCI, V11, P2196, DOI 10.1110/ps.0209002; ZHANG CT, 1992, PROTEIN SCI, V1, P401; NCBI FTP	58	36	38	0	1	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAR 15	2005	6								56	10.1186/1471-2105-6-56		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	915YC	WOS:000228346600001	15769290	
J	Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G				Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G			Output-sensitive algorithms for computing nearest-neighbour decision boundaries	DISCRETE & COMPUTATIONAL GEOMETRY			English	Article							CONVEX-HULL ALGORITHM	Given a set R of red points and a set B of blue points, the nearest-neighbour decision rule classifies a new point q as red (respectively, blue) if the closest point to q in R boolean OR B comes from R (respectively, B). This rule implicitly partitions space into a red set and a blue set that are separated by a red-blue decision boundary. In this paper we develop output-sensitive algorithms for computing this decision boundary for point sets on the line and in R-2. Both algorithms run in time O(n log k), where k is the number of points that contribute to the decision boundary. This running time is the best possible when parameterizing with respect to n and k.	Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada; MIT, Comp Sci Lab, Cambridge, MA 02139 USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Polytech Univ, Dept Comp & Informat Sci, MetroTech Ctr 6, Brooklyn, NY 11201 USA; Free Univ Brussels, FNRS, Charge Rech, B-1050 Brussels, Belgium; Carleton Univ, Sch Comp Sci, Ottawa, ON K1S 5BL, Canada; McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada	Bremner, D (reprint author), Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada.	bremner@unb.ca; edemaine@mit.edu; jeffe@cs.uiuc.edu; jiacono@poly.edu; stefan.langerman@ulb.ac.be; morin@cs.carleton.ca; godfried@cs.mcgill.ca	Erickson, Jeff/J-5887-2013	Erickson, Jeff/0000-0002-5253-2282			Ben-Or M, 1983, P 15 ANN ACM S THEOR, P80, DOI 10.1145/800061.808735; Bhattacharya BK, 1997, J ALGORITHM, V25, P177, DOI 10.1006/jagm.1997.0869; Blum M., 1973, Journal of Computer and System Sciences, V7, DOI 10.1016/S0022-0000(73)80033-9; Chan TM, 1996, DISCRETE COMPUT GEOM, V16, P361, DOI 10.1007/BF02712873; Chan TM, 1997, DISCRETE COMPUT GEOM, V18, P433, DOI 10.1007/PL00009327; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1978, PATTERN RECOGN, V10, P41, DOI 10.1016/0031-3203(78)90047-X; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DOBKIN DP, 1983, THEOR COMPUT SCI, V27, P241, DOI 10.1016/0304-3975(82)90120-7; DOBKIN DP, 1985, J ALGORITHM, V6, P381, DOI 10.1016/0196-6774(85)90007-0; Hoare C. A. R., 1961, CACM, V4, P321, DOI 10.1145/366622.366644; KIRKPATRICK D, 1983, SIAM J COMPUT, V12, P28, DOI 10.1137/0212002; KIRKPATRICK DG, 1986, SIAM J COMPUT, V15, P287, DOI 10.1137/0215021; Preparata F. P., 1985, COMPUTATIONAL GEOMET; Shamos M. I., 1975, P 7 ANN ACM S THEOR, P224, DOI 10.1145/800116.803772; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; TOUSSAINT GT, 2003, MANUSCRIPT; TOUSSAINT GT, 1984, P COMP SCI STAT 16 S, P97; Wenger R, 1997, ALGORITHMICA, V17, P322, DOI 10.1007/BF02523195	19	37	38	0	4	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0179-5376			DISCRETE COMPUT GEOM	Discret. Comput. Geom.	APR	2005	33	4					593	604		10.1007/s00454-004-1152-0		12	Computer Science, Theory & Methods; Mathematics	Computer Science; Mathematics	917XM	WOS:000228502600003		
J	Vasilic, S; Kezunovic, M				Vasilic, S; Kezunovic, M			Fuzzy ART neural network algorithm for classifying the power system faults	IEEE TRANSACTIONS ON POWER DELIVERY			English	Article						adaptive resonance theory; clustering methods; fuzzy logic; learning systems; neural networks; pattern classification; power system faults; protective relaying; testing; training	TRANSMISSION-LINES; DISTANCE PROTECTION; CLASSIFICATION; IMPLEMENTATION; DESIGN; NETS; TIME	This paper introduces advanced pattern recognition algorithm for classifying the transmission line faults, based on combined use of neural network and fuzzy logic. The approach utilizes self-organized, supervised Adaptive Resonance Theory (ART) neural network with fuzzy decision rule applied on neural network outputs to improve algorithm selectivity for a variety of real events not necessarily anticipated during training. Tuning of input signal preprocessing steps and enhanced supervised learning are implemented, and their influence on the algorithm classification capability is investigated. Simulation results show improved algorithm recognition capabilities when compared to a previous version of ART algorithm for each of the implemented scenarios.	Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA	Vasilic, S (reprint author), Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA.	svasilic@yahoo.com; kezunov@ee.tamu.ed					Aggarwal RK, 1999, IEEE T POWER DELIVER, V14, P1250, DOI 10.1109/61.796214; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bo ZQ, 1997, IEEE T POWER DELIVER, V12, P106, DOI 10.1109/61.568230; Butler KL, 1997, IEE P-GENER TRANSM D, V144, P429, DOI 10.1049/ip-gtd:19971433; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalstein T, 1996, IEEE T POWER DELIVER, V11, P740, DOI 10.1109/61.489330; DALSTEIN T, 1995, IEEE T POWER DELIVER, V10, P1002, DOI 10.1109/61.400828; Dash PK, 2001, IEEE T POWER DELIVER, V16, P68, DOI 10.1109/61.905593; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Fitton DS, 1996, IEEE T POWER DELIVER, V11, P748, DOI 10.1109/61.489331; Fernandez ALO, 2002, IEEE T POWER DELIVER, V17, P894, DOI 10.1109/TPWRD.2002.803734; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; *IEEE, 2000, IEEE GUID PROT REL A; Jongepier AG, 1997, IEEE T POWER DELIVER, V12, P97, DOI 10.1109/61.568229; Keerthipala WWL, 1997, ELECTR POW SYST RES, V42, P109, DOI 10.1016/S0378-7796(96)01185-6; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kezunovic M, 1996, ENG INTELL SYST ELEC, V4, P57; KEZUNOVIC M, 1995, ELECTR POW SYST RES, V34, P109, DOI 10.1016/0378-7796(95)00962-X; Kezunovic M, 1996, IEEE COMPUT APPL POW, V9, P42, DOI 10.1109/67.539846; Kohonen T, 2001, SELF ORG MAPS, V3rd, P501; Lewiss W, 1947, AIEE T, V66, P694; Lin WM, 2001, IEEE T POWER DELIVER, V16, P473; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; PAO YH, 1992, IEEE T POWER SYST, V7, P878, DOI 10.1109/59.141799; PAO YH, 1989, ADAPTIVE PATTERN REC, P309; Poeltl A, 1999, IEEE T POWER DELIVER, V14, P1269, DOI 10.1109/61.796217; Powell M.J.D., 1987, ALGORITHMS APPROXIMA, P143; Pradhan AK, 2001, ELECTR POW SYST RES, V60, P1, DOI 10.1016/S0378-7796(01)00150-X; RISTANOVIC D, 2001, P 33 N AM POW S COLL, P470; Sanaye-Pasand M, 1999, IEEE T POWER DELIVER, V14, P782, DOI 10.1109/61.772315; SIDHU TS, 1995, IEEE T POWER DELIVER, V10, P697, DOI 10.1109/61.400862; Song YH, 1997, ELECTR POW SYST RES, V43, P125, DOI 10.1016/S0378-7796(97)01168-1; Udren EA, 1997, IEEE T POWER DELIVER, V12, P134, DOI 10.1109/61.568233; VASILIC S, 2002, P 14 POW SYST COMP C, V42, P1; Vasilic S., 2002, P IEEE POW ENG SOC P, V2, P918; VASILIC S, 2001, P IEEE POW ENG SOC T; WAN EA, 1990, P INT JOINT C NEUR N, P575; Wang HS, 1998, IEEE T POWER DELIVER, V13, P1093; Websper S, 1999, IEE P-GENER TRANSM D, V146, P209, DOI 10.1049/ip-gtd:19990232; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; 2002, USING MATLAB; 1992, ALTERNATIVE TRANSIEN	44	45	50	1	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0885-8977			IEEE T POWER DELIVER	IEEE Trans. Power Deliv.	APR	2005	20	2	2				1306	1314		10.1109/TPWRD.2004.834676		9	Engineering, Electrical & Electronic	Engineering	912RC	WOS:000228096100012		
J	Deshpande, U; Gupta, A; Basu, A				Deshpande, U; Gupta, A; Basu, A			Performance enhancement of a contract net protocol based system through instance-based learning	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						contract net protocol (CNP); distributed problem solving; instance-based learning (IBL); multiagent systems	COMMUNICATION	The contract net protocol (CNP) is a widely used coordination mechanism in multiagent systems. It has a lot of communication overhead due to the broadcast of the task announcements. The performance of the CNP degrades drastically when the number of communicating agents and the number of tasks announced increases. Hence, it has problems of scalability. In order to overcome this limitation, an instance-based learning (IBL) mechanism is designed that uses previously stored instances in order to select a target agent. This avoids the expensive bidding process. The scheme is implemented in a simulated distributed hospital system where the CNP is used for resource sharing across hospitals. Experimental results demonstrate that with the incorporation of the IBL, the system performance improves significantly. The system is better scalable with respect to the number of tasks.	VNIT, Nagpur, Maharashtra, India; Indian Inst Technol, Kharagpur 721302, W Bengal, India	Deshpande, U (reprint author), VNIT, Nagpur, Maharashtra, India.	uad@vnitnagpur.ac.in; agupta@cse.iitkgp.ernet.in; anupam@cse.iitkgp.ernet.in					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS R, 1983, ARTIF INTELL, V20, P63, DOI 10.1016/0004-3702(83)90015-2; Decker K, 2000, AUTON AGENT MULTI-AG, V3, P133, DOI 10.1023/A:1010074611407; Decker KS, 1995, P 1 INT C MULT SYST, P73; DECKER KS, 1995, THESIS UMASSACHUSETT; Deshpande U, 2004, IEEE T SYST MAN CY B, V34, P1299, DOI 10.1109/TSMCB.2003.818535; Deshpande U, 2004, APPL SOFT COMPUT, V5, P101, DOI 10.1016/j.asoc.2004.06.001; DESHPANDE U, 2002, IITKGPCSEAB20021; DESHPANDE U, 2002, P 10 INT C COOP INF, P503; Duda R. O., 1973, PATTERN CLASSIFICATI; DURFEE EH, 2001, IEEE COMPUT, V34, P39; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Hertz J, 1991, INTRO THEORY NEURAL; JOHASZ Z, 2002, P 2 INT WORKSH AG BA; Mitchell T. M., 1997, MACHINE LEARNING; Ohko T, 1997, LECT NOTES ARTIF INT, V1221, P242; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAMAMRITHAM K, 1989, IEEE T COMPUT, V38, P1110, DOI 10.1109/12.30866; RANA OF, 2000, AUTONOMOUS AGENTS 20; Sen S., 1999, MULTIAGENT SYSTEMS M; SMITH RG, 1980, IEEE T COMPUT, V29, P1104; Terabe M, 1997, LECT NOTES ARTIF INT, V1221, P168; WATSON I, 1994, KNOWL ENG REV, V9, P327; Yager R. R., 1981, DECISION SCI, V12, P589, DOI 10.1111/j.1540-5915.1981.tb00111.x; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	26	6	9	1	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2005	35	2					345	358		10.1109/TSMCB.2004.842256		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	907WD	WOS:000227747900015	15828662	
J	Yang, CY; Chou, JJ				Yang, CY; Chou, JJ			A comparative evaluation approach for the classification of rotifers with modified non-parametric kNN	IMAGE AND VISION COMPUTING			English	Article						biological identification; microscopic rotifer image; k-nearest-neighbor rule; pattern recognition; classification; modified model	PATTERN-RECOGNITION; MOMENT INVARIANTS	In this study-aimed to achieve optimal accuracy in the classification of rotifers according to the number of eggs carried-several modifications to the basic kNN method have been proposed and assessed. Six distinct kNN rules as well as several additional hybrid models were, in fact, devised or employed and their precision compared. Meanwhile, the data sets used in the evaluation of each of these methods were acquired from rotifer images generated via the shape moments approach. Both the original data sets and the edited ones, formed by removing outliers from the originals, were used in the evaluation of these adjusted models. Through a process of comparative evaluation, several of the modified algorithms proposed-comprising both individual and hybrid models-were found to perform better overall than the classical kNN method. Refinements related to class-size weighting, in particular, were shown to heighten the accuracy of the classical kNN model considerably. Close evaluation of the various models created revealed kNN-CCS and F-kNN-CCS, in their application to the edited data sets, to be the most reliable individual modified and hybrid models respectively, with levels of accuracy greater than 95%. (C) 2004 Elsevier B.V. All rights reserved.	Natl Taiwan Univ, Dept Bioind Mechatron Engn, Taipei 106, Taiwan; No Taiwan Inst Sci & Technol, Dept Mech Engn, Taipei 112, Taiwan	Chou, JJ (reprint author), Natl Taiwan Univ, Dept Bioind Mechatron Engn, 1 Roosevelt Rd,Sect 4, Taipei 106, Taiwan.	jjchou@ntu.edu.tw		Yang, Chan-Yun/0000-0001-5329-6368			COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, IEEE COMPUTER SOC; Dasarathy B. V., 1977, Proceedings of the International Conference on Cybernetics and Society; Duda R O, 2001, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fukunaga K., 1990, INTRO STAT PATTERN R; HOFF F H, 1997, PLANKTON CULTURE MAN; HU M, 1962, IRE T INFORM THEOR, V8, P179; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; LI YJ, 1992, PATTERN RECOGN, V25, P723, DOI 10.1016/0031-3203(92)90135-6; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; SCHALFOFF JR, 1992, PATTERN RECOGNITION; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yang CY, 2000, AQUACULT ENG, V24, P33, DOI 10.1016/S0144-8609(00)00065-0	14	3	3	1	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0262-8856			IMAGE VISION COMPUT	Image Vis. Comput.	APR 1	2005	23	4					427	439		10.1016/j.imavis.2004.11.004		13	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	900NR	WOS:000227222100006		
J	Toussaint, G				Toussaint, G			Geometric proximity graphs for improving nearest neighbor methods in instance-based learning and data mining	INTERNATIONAL JOURNAL OF COMPUTATIONAL GEOMETRY & APPLICATIONS			English	Article; Proceedings Paper	International Conference on Computational Science and Its Applications (ICCSA 2003)3rd International Workshop on Computational Geometry and Applications (CGA 2003)	MAY 18-21, 2003MAY 18-21, 2003	MONTREAL, CANADAMontreal, CANADA	CERCA, IBM Canada, IBM, United States, Heuchera Technol, Pallas, Queens Univ Belfast, SHARCNET, Soc Ind & Appl Math, Springer Verlag		instance-based learning; proximity graphs; nearest-neighbor methods; data mining	PIECEWISE-LINEAR CLASSIFIERS; PATTERN-CLASSIFICATION PERCEPTRONS; NEURAL-NETWORK; PROTOTYPE OPTIMIZATION; VECTOR QUANTIZATION; GENETIC ALGORITHMS; FINDING PROTOTYPES; FEATURE-SELECTION; OUTLIER DETECTION; AUTOMATED DESIGN	In the typical nonparametric approach to classification in instance-based learning and data mining, random data (the training set of patterns) are collected and used to design a decision rule (classifier). One of the most well known such rules is the k-nearest-neighbor decision rule (also known as lazy learning) in which an unknown pattern is classified into the majority class among its k nearest neighbors in the training set. Several questions related to this rule have received considerable attention over the years. Such questions include the following. How can the storage of the training set be reduced without degrading the performance of the decision rule? How should the reduced training set be selected to represent the different classes? How large should k be? How should the value of k be chosen? Should all k neighbors be equally weighted when used to decide the class of an unknown pattern? If not, how should the weights be chosen? Should all the features (attributes) we weighted equally and if not how should the feature weights be chosen? What distance metric should be used? How can the rule be made robust to overlapping classes or noise present in the training data? How can the rule be made invariant to scaling of the measurements? How can the nearest neighbors of a new point be computed efficiently? What is the smallest neural network that can implement nearest neighbor decision rules? Geometric proximity graphs such as Voronoi diagrams and their many relatives provide elegant solutions to these problems, as well as other related data mining problems such as outlier detection. After a non-exhaustive review of some of the classical canonical approaches to these problems, the methods that use proximity graphs are discussed, some new observations are made, and open problems are listed.	McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada	Toussaint, G (reprint author), McGill Univ, Sch Comp Sci, 3480 Univ St,McConnell Engn Bldg,Room 318, Montreal, PQ H3A 2A7, Canada.	godfried@cs.mcgill.ca					AGUILAR JS, 2000, P 14 EUR C ART INT B, P215; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Aha D. W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALOUPIS G, 2001, P 13 CAN C COMP GEOM, P21; Aloupis G, 2002, COMPUT STAT DATA AN, V40, P223, DOI 10.1016/S0167-9473(02)00032-4; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; ANDERSON TW, 1966, P 1 INT S MULT AN; ANDRADE DV, 2001, P 13 CAN C COMP GEOM; Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Arya S, 1996, DISCRETE COMPUT GEOM, V16, P155, DOI 10.1007/BF02716805; AVESANI P, 1999, P INT WORKSH SIM SEA; AVIS D, 1982, ANN NY ACAD SCI, V440, P323; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Bandyopadhyay D., 2004, P 15 ACM SIAM S DISC, P410; Baram Y, 2000, PATTERN RECOGN, V33, P177, DOI 10.1016/S0031-3203(99)00050-3; Baras JS, 1999, IEEE T INFORM THEORY, V45, P1911, DOI 10.1109/18.782112; Barnett V., 1994, OUTLIERS STAT DATA, V3rd; BARREIS ER, 1989, EXEMPLAR BASED KNOWL; BAY SD, 2003, P ACM C KNOWL DISC D; BELUR V, 1994, IEEE T SYST MAN CYB, V24, P511; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Bermejo S, 1999, PATTERN RECOGN, V32, P2077, DOI 10.1016/S0031-3203(99)00120-X; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; BHATTACHARYA B, 1998, P 14 INT C PATT REC, V1; BHATTACHARYA B, 2005, P 55 SESS INT STAT I; BHATTACHARYA BK, 1982, THESIS MCGILL U; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BOSE NK, 1993, IEEE T NEURAL NETWOR, V4, P778, DOI 10.1109/72.248455; Boyer E, 2000, MATH COMPUT MODEL, V32, P1071, DOI 10.1016/S0895-7177(00)00191-6; Breiman L., 1984, CLASSIFICATION REGRE; Bremner D, 2003, LECT NOTES COMPUT SC, V2748, P451; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BRIGHTON H, 2001, INSTANCE SELECTION C, P1; BRIGHTON H, 1999, PRINCIPLES DATA MINI; Brito MR, 1997, STAT PROBABIL LETT, V35, P33, DOI 10.1016/S0167-7152(96)00213-1; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; Burges CJC, 1997, ADV NEUR IN, V9, P375; Burges C.J.C., 1996, P 13 INT C MACH LEAR, P71; Bustos B., 2001, P 21 INT C CHIL COMP, P33; CANO JR, 2004, PATTERN RECOGNITION; Caruana R., 1994, P 11 INT C MACH LEAR, P28; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CERVERON V, 1998, LECT NOTES COMPUTER, P248; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CHANG IE, 1991, ADV NEURAL INFORMATI, V3, P797; CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; CHEN JH, 2005, INT J APPROXIMATE RE; Chen YQ, 1997, IEEE T CIRCUITS-I, V44, P622; CLARKSON KL, 1997, P 29 ANN ACM S THEOR, P609, DOI 10.1145/258533.258655; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; DASARATHY B, 1978, PATTERN RECOGN, V10, P41, DOI 10.1016/0031-3203(78)90047-X; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Dasarathy B. V., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.906169; DASGUPTA S, 1980, SANKHYA A, V42, P219; Datta P., 1997, P 14 NAT C ART INT, P82; DEBERG M, 2002, 18 EUR WORKSH COMP G; Decaestecker C, 1997, PATTERN RECOGN, V30, P281, DOI 10.1016/S0031-3203(96)00072-6; DECAESTECKER C, 1994, P 1994 IEEE INT C NE, P263; de Mantaras RL, 1998, DATA KNOWL ENG, V25, P99; Devi VS, 2002, PATTERN RECOGN, V35, P505; Devijver P. A., 1982, PATTERN RECOGNITION; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; DEVINNEY J, IN PRESS DISCRETE AP; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1988, COMPUT MATH APPL, V15, P53, DOI 10.1016/0898-1221(88)90071-5; Devroye L., 1996, PROBABILISTIC THEORY; Devroye L. P., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing; Devroye L., 1991, NEAREST NEIGHBOR PAT, P101; Djouadi A, 1998, IEEE T PATTERN ANAL, V20, P567, DOI 10.1109/34.682188; Downs T., 2001, J MACHINE LEARNING R, V2, P293; Duda R O, 2001, PATTERN CLASSIFICATI; Duda R. O., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; DWYER R, 1993, TR9321 N CAR STAT U; DWYER RA, 1995, COMP GEOM-THEOR APPL, V5, P155, DOI 10.1016/0925-7721(94)00025-Q; DWYER RA, 1991, DISCRETE COMPUT GEOM, V6, P343, DOI 10.1007/BF02574694; Ekin O, 1999, INFOR, V37, P337; ESAT I, 1999, P 6 INT C NEUR INF P, V1, P366; ESKIN E, 2002, DATA MINING SECURITY; Fix E., 1951, 4 USAF SCH AV MED; Florek K., 1951, C MATH, V2, P282; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Friedman JH, 1994, FLEXIBLE METRIC NEAR; FUKUDA K, 2000, FREQUENTLY ASKED QUE; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Gavrilova ML, 2002, J SUPERCOMPUT, V22, P87, DOI 10.1023/A:1014310721543; GAZULA S, 1995, IEEE T PATTERN ANAL, V17, P1239, DOI 10.1109/34.476519; Gentile C, 2001, IEEE T NEURAL NETWOR, V12, P1227, DOI 10.1109/72.950151; GLICK N, 1978, PATTERN RECOGN, V10, P211, DOI 10.1016/0031-3203(78)90029-8; GOODMAN LA, 1954, J AM STAT ASSOC, P723; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; GROCHOWSKI M, 2004, LECT NOTES COMPUTER, P580; GUIBAS L, 1994, INTUITIVE GEOMETRY, P131; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; Hawkins D. M., 1980, IDENTIFICATION OUTLI; He ZY, 2004, EXPERT SYST APPL, V27, P681, DOI 10.1016/j.eswa.2004.07.002; HEATH D, 1993, COMP GEOM-THEOR APPL, V3, P289, DOI 10.1016/0925-7721(93)90019-3; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; HOULE ME, 2003, RT0517 IBM TOK RES L; Hoya T, 1998, IEEE T SIGNAL PROCES, V46, P2574, DOI 10.1109/78.709550; Huang YS, 2002, PATTERN RECOGN, V35, P1237, DOI 10.1016/S0031-3203(01)00124-8; HUANG YS, 1995, PATTERN RECOGN LETT, V16, P77, DOI 10.1016/0167-8655(94)00070-J; HUBER PJ, 1972, ANN MATH STAT, V43, P1041, DOI 10.1214/aoms/1177692459; ICHINO M, 1985, PATTERN RECOGN, V18, P161, DOI 10.1016/0031-3203(85)90040-8; Indyk P., 1998, P 30 ANN ACM S THEOR; Jain A. K., 1991, P INT JOINT C NEUR N, P515; Jain A. K., 1988, ALGORITHMS CLUSTERIN; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Jankowski N., 2004, LECT NOTES COMPUTER, P598; Jardine N, 1971, MATH TAXONOMY; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Jiang Y, 2004, LECT NOTES COMPUT SC, V3173, P356; KARACALI B, 2002, IEEE T NEURAL NETWOR, V14, P127; KEUNG CK, 2000, P 4 PAC AS C KNOWL D, P142; KIBLER D, 1988, P 3 EUR WORK SESS LE, P63; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KIM SW, 2003, IN PRESS PATTERN REC, V36; Kirkpatrick D. G., 1985, COMP GEOM-THEOR APPL, P217; Kleinberg J.M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Kohonen T., 1995, SELF ORG MAP; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; Korn F., 2000, P ACM SIGMOD INT C M, P201, DOI DOI 10.1145/342009.335415; KORN F, 2002, P 28 VLDB C HONG KON; Krishna K, 2000, IEEE T NEURAL NETWOR, V11, P1361, DOI 10.1109/72.883447; Kubat M., 2000, P 17 INT C MACH LEAR, P503; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; LALLICH S, 2005, APPL STOCHASTIC MODE; Lam W, 2002, PATTERN RECOGN, V35, P1491, DOI 10.1016/S0031-3203(01)00131-5; Lee CH, 1999, KNOWL-BASED SYST, V12, P363, DOI 10.1016/S0950-7051(99)00041-6; Limas MC, 2004, DATA MIN KNOWL DISC, V9, P171, DOI 10.1023/B:DAMI.0000031630.50685.7c; Ling CX, 1997, ARTIF INTELL REV, V11, P255, DOI 10.1023/A:1006560730186; Liotta G, 1998, COMP GEOM-THEOR APPL, V10, P1, DOI 10.1016/S0925-7721(97)00018-7; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Madigan D, 2002, DATA MIN KNOWL DISC, V6, P173, DOI 10.1023/A:1014095614948; Maheshwari A., 2002, P 14 CAN C COMP GEOM, P128; MARKOVITCH S, 1993, MACH LEARN, V10, P113, DOI 10.1007/BF00993503; MARTINEZHINAREJOS, 2003, PATTERN RECOGN LETT, V24, P173; MASS W, 2000, NEURAL COMPUT, V12, P2519; MASS W, 2000, ADV NEURAL INFOMATIO, V12; MATHAI A, 1975, BASIC CONCEPT INFORM; MATUSITA K, 1967, ANN I STAT MATH, V19, P181, DOI 10.1007/BF02911675; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; MCMORRIS FR, 2000, CONRR NUMER, V142, P149; Michael TS, 1999, MATH COMPUT MODEL, V29, P45, DOI 10.1016/S0895-7177(99)00061-8; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Mitiche A, 2001, NEURAL NETWORKS, V14, P575, DOI 10.1016/S0893-6080(01)00035-1; MOLLINEDA RA, 2002, IN PRESS PATTERN REC, V35; Moreno-Seco F, 2003, PATTERN RECOGN LETT, V24, P47, DOI 10.1016/S0167-8655(02)00187-3; MUHLENBACH F, 2004, P DISC SCE BERL HEID, P314; Muhlenbach F, 2004, J INTELL INF SYST, V22, P89, DOI 10.1023/A:1025832930864; MURPHY O, 1995, INFORM SCIENCES, V83, P133, DOI 10.1016/0020-0255(94)00066-K; MURPHY OJ, 1990, P IEEE, V78, P1595, DOI 10.1109/5.58344; Nilsson N. J., 1990, MATH FDN LEARNING MA; NOCK R, 2000, P INT C ALG LEARN TH, P224; Nock R., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000453; O'Rourke J., 1998, COMPUTATIONAL GEOMET; Okabe A., 1992, SPATIAL TESSELLATION; Olshen R., 1977, ANN STAT, V5, P632; OROURKE J, 1997, HDB DISCRETE COMPUTA, P797; OTTMANN T, 1995, 12 ANN S THEOR ASP C, P562; Pal NR, 1997, PATTERN RECOGN, V30, P847, DOI 10.1016/S0031-3203(96)00127-6; PANKAJ K, 1998, ADV DISCRETE COMPUTA; PAPADIMITRIOU C, 1980, AUTOMATA LANGUAGES P, V85, P470; PARK Y, 1989, J CLASSIF, V6, P195, DOI 10.1007/BF01908599; PARK Y, 1990, PATTERN RECOGN, V23, P1393, DOI 10.1016/0031-3203(90)90086-Z; PARK YH, 1991, P IEEE INT JOINT C N, P2386, DOI 10.1109/IJCNN.1991.170745; PATERSON MS, 1992, LECT NOTES COMPUT SC, V623, P416; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; PIERRE A, 1980, 5 INT C PATT REC MIA, P72; Porter WA, 1995, J FRANKLIN I, V332B, P155, DOI 10.1016/0016-0032(95)00032-9; PRIEBE C, 1998, 585 J HOPK U; PRIEBE CE, 2002, 15 J HOPK U; Priebe CE, 2001, STAT PROBABIL LETT, V55, P239, DOI 10.1016/S0167-7152(01)00129-8; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; RADKE JD, 1988, COMPUTATIONAL MORPHO, P105; Ramasubramanian V, 1997, DIGIT SIGNAL PROCESS, V7, P260, DOI 10.1006/dspr.1997.0300; Ramaswami S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Rao SV, 2001, PATTERN RECOGN, V34, P2163, DOI 10.1016/S0031-3203(00)00144-8; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Rosin PL, 1998, NEUROCOMPUTING, V20, P155, DOI 10.1016/S0925-2312(98)00008-3; Royall R., 1966, THESIS STANFORD U ST; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; SALZBERG S, 1995, IEEE T PATTERN ANAL, V17, P599, DOI 10.1109/34.387506; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; Saradhi VV, 2001, PATTERN RECOGN, V34, P1047, DOI 10.1016/S0031-3203(00)00043-1; Schiavo RA, 2000, INT STAT REV, V68, P295, DOI 10.2307/1403415; SCHILLING MF, 1986, J AM STAT ASSOC, V81, P799, DOI 10.2307/2289012; SCUTURICI M, 2003, P 8 IB AM C PATT REC, P144; SCUTURICI M, 2005, J EXPT THEORETICAL A, P1; SEBBAN M, 2001, P 18 INT C MACH LEAR; SEBBAN M, 1998, APPRENTISSAGE PRINCI, P139; Sebban M, 2002, PATTERN RECOGN, V35, P835, DOI 10.1016/S0031-3203(01)00084-X; Sebban M, 1999, LECT NOTES ARTIF INT, V1704, P184; SEIDEL R, 1991, DIMACS SER DISCRETE, V4, P517; SEN S, 1995, P 14 INT JOINT C ART, V1, P725; Shamos M. I., 1975, P 7 ANN ACM S THEOR, P224, DOI 10.1145/800116.803772; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Skalak D.B., 1993, P AAAI 93 CAS BAS RE, P64; SKLANSKY J, 1980, IEEE T PATTERN ANAL, V2, P101; Skurichina M, 2000, IEEE T NEURAL NETWOR, V11, P504, DOI 10.1109/72.839019; Smyth B., 1995, P 14 INT JOINT C ART, P377; SMYTH SG, 1992, IEEE T NEURAL NETWOR, V3, P329, DOI 10.1109/72.125875; SOSS M, 1999, P 11 CAN C COMP GEOM, P43; SOSS M, 1998, P 10 CAN C COMP GEOM, P108; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STANOI I, 2002, ACM WORKSH RES ISS D; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; SU TH, 1991, COMPUTING, V46, P121, DOI 10.1007/BF02239166; Subhash C. B., 2003, PATTERN RECOGN, V36, P25; Syed N. A., 1999, P 5 ACM C KNOWL DISC, P272, DOI 10.1145/312129.312245; TAHANI H, 1996, P ICASSP, P3446; Tenmoto H, 1998, PATTERN RECOGN, V31, P1627, DOI 10.1016/S0031-3203(98)00016-8; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; TOUSSAINT GT, 1977, IEEE T SYST MAN CYB, V7, P300; Toussaint G. T., 1988, COMPUTATIONAL MORPHO, P229; TOUSSAIN.GT, 1971, IEEE T INFORM THEORY, V17, P618, DOI 10.1109/TIT.1971.1054686; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; TOUSSAINT GT, 1978, IEEE T SYST MAN CYB, V8, P482; TOUSSAINT GT, 1994, PATTERN RECOGN LETT, V15, P797, DOI 10.1016/0167-8655(94)90007-8; TOUSSAINT GT, 1980, ELECTRON LETT, V16, P860, DOI 10.1049/el:19800611; TOUSSAINT GT, 1974, ANN I STAT MATH, V26, P389, DOI 10.1007/BF02479834; TOUSSAINT GT, 1975, IEEE T INFORM THEORY, V21, P99, DOI 10.1109/TIT.1975.1055311; TOUSSAINT GT, 1974, P C MEAS INF THEIR A; TOUSSAINT GT, 1974, P 2 INT JOINT C PATT, P27; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; Toussaint G. T., 1972, Information Processing Letters, V1, DOI 10.1016/0020-0190(72)90049-X; Toussaint G. T., 1979, Proceedings of COMPSAC the IEEE Computer Society's Third International Computer Software and Applications Conference; TOUSSAINT GT, 1980, P 5 S OP RES U KOLN, P425; Toussaint G. T., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface; TOUSSAINT GT, 1977, P IEEE, V65, P275, DOI 10.1109/PROC.1977.10469; TOUSSAINT GT, 1974, P S STAT REL TOP OTT; TSENG YH, 1995, IEEE T COMPUT, V44, P601; Tukey JW, 1974, P INT C MATH VANC, P523; URQUHART R, 1982, PATTERN RECOGN, V15, P173, DOI 10.1016/0031-3203(82)90069-3; VAIDYA PM, 1989, DISCRETE COMPUT GEOM, V4, P101, DOI 10.1007/BF02187718; VAJDA I, 1969, METHODOLOGIES PATTER, P509; Vapnik NV, 1998, STAT LEARNING THEORY; VINCENT P, 2001, 1197 U DEP IRO U MON; WAGNER TJ, 1973, IEEE T INFORM THEORY, V19, P696, DOI 10.1109/TIT.1973.1055059; Wettschereck D., 1995, P 1 INT C CAS BAS RE; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILFONG G, 1991, P 7 ANN ACM S COMP G, P224, DOI 10.1145/109648.109673; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson D.R., 1997, P 14 INT C MACH LEAR, P404; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; WONG MA, 1982, J AM STAT ASSOC, V77, P841, DOI 10.2307/2287316; Wu YQ, 2002, PATTERN RECOGN, V35, P2311, DOI 10.1016/S0031-3203(01)00132-7; YAN H, 1993, PATTERN RECOGN, V26, P317, DOI 10.1016/0031-3203(93)90040-4; YANG CJ, 2002, P 7 INT DAT ENG APPL; Yen CW, 2004, PATTERN RECOGN LETT, V25, P725, DOI 10.1016/j.patrec.2004.01.012; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhang HB, 2002, PATTERN RECOGN, V35, P1481, DOI 10.1016/S0031-3203(01)00137-6; Zhang J., 1992, P 9 INT MACH LEARN C, P470; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; Zighed D. A., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); ZIGHED DA, 2005, APPL STOCHASTIC MODE	291	24	24	2	10	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-1959			INT J COMPUT GEOM AP	Int. J. Comput. Geom. Appl.	APR	2005	15	2					101	150		10.1142/S0218195905001622		50	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	925WX	WOS:000229085300002		
J	Amador, JJ				Amador, JJ			Markov random field approach to region extraction using Tabu Search	JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION			English	Article						Markov random field; Gibbs distribution; Tabu Search; region extraction	IMAGE INTERPRETATION; HEURISTICS; MODELS	This paper describes a region extraction algorithm based on the concept of Markov random fields. Markov random fields (MRFs) are characterized by using a Gibbs Distribution which equates back to the MRF. A heuristically developed energy functional is presented and used with the MRF in an efficient and accurate manner. Since the MRF used in this work is defined using the polar coordinate system, a very large search space exists for radial lengths and sites. To aid in pursuing these radial sites, a combinatorial optimization technique known as Tabu Search is exploited. Also provided is an extensive empirical study on aerial imagery and parts detection, in addition to a final discussion and description of future work. (c) 2004 Elsevier Inc. All rights reserved.	John F Kennedy Space Ctr, NASA, Kennedy Space Ctr, FL 32899 USA	Amador, JJ (reprint author), John F Kennedy Space Ctr, NASA, Kennedy Space Ctr, FL 32899 USA.	Jose.J.Amador@nasa.gov					AKSOY S, 1999, IEEE COMP SOC C COMP, V1, P63; ALSULTAN KS, 1995, PATTERN RECOGN, V28, P1443, DOI 10.1016/0031-3203(95)00022-R; Ball GH., 1965, ISODATA NOVEL METHOD; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Blake A., 2000, ACTIVE CONTOURS; Canny J, 1986, PAMI, V8, P679; Castleman K. R., 1996, DIGITAL IMAGE PROCES; Costa L. D. F., 2001, SHAPE ANAL CLASSIFIC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMARIUC B, 1997, 13 INT C DIG SIGN PR, V2, P857; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; DELAGNES P, 1996, 13 INT C PATT REC, V2, P800; Duda R. O., 1973, PATTERN CLASSIFICATI; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Glover F., 1997, TABU SEARCH; GLOVER F, 1990, INTERFACES, V20, P74, DOI 10.1287/inte.20.4.74; Glover JA, 1989, EDUC PSYCHOL REV, V1, P1, DOI 10.1007/BF01326547; GUNSEL B, 1994, 12 IAPR INT C VIS SI, V2, P173; HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI DOI 10.1007/BF00133570; LI SZ, 1994, IEEE COMP SOC C COMP, P63; MANIEZZO V, 1995, EUR J OPER RES, V81, P188, DOI 10.1016/0377-2217(93)E0128-K; MARGALIT A, 1990, COMPUT VISION GRAPH, V51, P219, DOI 10.1016/0734-189X(90)90001-C; MODESTINO JW, 1992, IEEE T PATTERN ANAL, V14, P606, DOI 10.1109/34.141552; Nadabar SG, 1996, IEEE T PATTERN ANAL, V18, P326, DOI 10.1109/34.485560; Pirlot M, 1996, EUR J OPER RES, V92, P493, DOI 10.1016/0377-2217(96)00007-0; Roberts L. G., 1965, OPTICAL ELECTROOPTIC, P159; SCHLUTER D, 2000, INT C IM PROC, V2, P100; SINCLAIR M, 1993, COMPUT OPER RES, V20, P687, DOI 10.1016/0305-0548(93)90056-O; Tomasi C, 1998, IEEE T PATTERN ANAL, V20, P333, DOI 10.1109/34.667890	30	2	2	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1047-3203			J VIS COMMUN IMAGE R	J. Vis. Commun. Image Represent.	APR	2005	16	2					134	158		10.1016/j.vcir.2004.06.002		25	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	915VY	WOS:000228340700002		
J	Wang, M; Chen, S				Wang, M; Chen, S			Enhanced FMAM based on empirical kernel map	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						associative memory; empirical kernel map; face recognition; fuzzy mathematics; morphological neural networks	MORPHOLOGICAL MEMORIES; NEURAL-NETWORKS; RECOGNITION; ALGORITHMS	The existing morphological auto-associative memory models based on the morphological operations, typically including morphological auto-associative memories (auto-MAM) proposed by Ritter et al. and our fuzzy morphological auto-associative memories (auto-FMAM), have many attractive advantages such as unlimited storage capacity, one-shot recall speed and good noise-tolerance to single erosive or dilative noise. However, they suffer from the extreme vulnerability to noise of mixing erosion and dilation, resulting in great degradation on recall performance. To overcome this shortcoming, we focus on FMAM and propose an enhance FMAM (EFMAM) based on the empirical kernel map. Although it is simple, EFMAM can significantly improve the auto-FMAM with respect to the recognition accuracy under hybrid-noise and computational effort. Experiments conducted on the thumbnail-sized faces (28 x 23 and 14 x 11) scaled from the ORL database show the average accuracies of 92%, 90%, and 88% with 40 classes under 10%, 20%, and 30% randomly generated hybrid-noises, respectively, which are far higher than the auto-FMAM (67%, 46%, 31%) under the same noise levels.	Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China	Wang, M (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.	wm_wangmin@yahoo.com.cn; s.chen@nuaa.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Edelman S., 1999, REPRESENTATION RECOG; Gader PD, 2000, PATTERN RECOGN, V33, P935, DOI 10.1016/S0031-3203(99)00156-9; Goldstone R. L, 1999, MIT ENCY COGNITIVE S; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Morejon RA, 2004, IEEE T NEURAL NETWOR, V15, P874, DOI 10.1109/TNN.2004.828769; Pessoa LFC, 2000, PATTERN RECOGN, V33, P945, DOI 10.1016/S0031-3203(99)00157-0; Raducanu B, 2003, J MATH IMAGING VIS, V19, P113, DOI 10.1023/A:1024725414204; Ritter G., 1996, P 13 INT C PATT REC, V4, P709; Ritter GX, 1998, IEEE T NEURAL NETWOR, V9, P281, DOI 10.1109/72.661123; Ritter GX, 2003, IEEE T NEURAL NETWOR, V14, P282, DOI 10.1109/TNN.2003.809427; Scholkopf B, 2002, LECT NOTES ARTIF INT, V2430, P511; Scholkopf B., 2002, LEARNING KERNELS; Sussner P, 2003, J MATH IMAGING VIS, V19, P81, DOI 10.1023/A:1024721313295; SUSSNER P, 2003, P INT JOINT C NEUR N, V1, P236, DOI 10.1109/IJCNN.2003.1223350; Van Hulle MM, 2004, IEEE T NEURAL NETWOR, V15, P850, DOI 10.1109/TNN.2004.828763; Wang Min, 2003, Acta Electronica Sinica, V31; WHARTON CM, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P588; Won YG, 1997, IEEE T NEURAL NETWOR, V8, P1195	19	19	26	2	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2005	16	3					557	564		10.1109/TNN.2005.847839		8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	923KX	WOS:000228909900005	15940986	
J	Pati, PB; Ramakrishnan, AG				Pati, PB; Ramakrishnan, AG			OCR in Indian scripts: A survey	IETE TECHNICAL REVIEW			English	Article							PRINTED BILINGUAL DOCUMENTS; NEAREST NEIGHBOR RULE; HIDDEN MARKOV-MODELS; CHARACTER-RECOGNITION; MACHINE RECOGNITION; PATTERN-CLASSIFICATION; TELUGU CHARACTERS; TEXT RECOGNITION; DEVANAGARI; SYSTEM	India is a multi-lingual country. A significantly large number of scripts are used to represent these languages. A desire of vision researchers is to develop an integrated Optical Character Recognition (OCR) system which will be able to process all such scripts. Such a development, if objectified, will not only enable faster flow of information across the country, but also have a profound impact on its scientific and economic development. Courageous endeavors have been successfully made towards the development of a system capable of recognizing machine-printed, or hand-written characters and/or numerals. However, most Indian scripts do not have an integrated OCR system. Further the development of a unified system which is capable of processing all Indian scripts is still a dream. This article presents a survey of the current literature on the development of OCR's in Indian scripts. Reviewing the basics of and the motivation towards the development of OCR system, the article analyzes the various methodologies employed in general purpose pattern recognition system. A critical analysis of the work towards OCR system in Indian languages, with pointers towards possible future work is also presented.	Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Pati, PB (reprint author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.	pati@ee.iisc.ernet.in; ramkiag@ee.iisc.ernet.in	Ramakrishnan, A/B-8317-2013	Ramakrishnan, A/0000-0002-3646-1955			ALBADR B, 1995, SIGNAL PROCESS, V41, P49, DOI 10.1016/0165-1684(94)00090-M; Antani S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791813; Aparna KG, 2002, LECT NOTES COMPUT SC, V2423, P53; ASHWIN TV, 2000, THESIS INDIAN I SCI; Bansal V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791811; BATI PB, 2000, P INT C INF TECH, P227; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Bishnu A., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791809; Bishop C.M., 1995, NEURAL NETWORKS PATT; Burges C. J. C., 1998, DATA MIN KNOWL DISC, V2, P955; CHANDRASEKARAN M, 1984, J IETE INDIA, V30, P150; CHANDRASEKARAN M, 1984, P INT C SYST MAN CYB, V2, P786; Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2; CHAUDHURI BB, 1991, J IETE, V37, P499; CHAUDHURI BB, 2001, P 6 INT C DOC AN REC, P406; CHINNUSWAMY P, 1980, PATTERN RECOGN, V12, P131; Cho WY, 1995, PATTERN RECOGN, V28, P1941; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dhanya D, 2002, LECT NOTES COMPUT SC, V2423, P13; DHANYA D, 2001, THESIS INDIAN I SCI; Dhanya D, 2002, LECT NOTES COMPUT SC, V2423, P25; Dhanya D, 2002, SADHANA-ACAD P ENG S, V27, P73, DOI 10.1007/BF02703313; Duda R. O., 1973, PATTERN CLASSIFICATI; DUTTA A, 1993, PATTERN RECOGN, V26, P1757, DOI 10.1016/0031-3203(93)90174-U; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOIN JE, 1984, IEEE T PATTERN ANAL, V6, P379; GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; Hu JY, 1996, IEEE T PATTERN ANAL, V18, P1039; HYVARINEN A, 1997, NEURAL COMPUT, V9, P183; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274; KARNIK RR, 1909, P 5 INT C DOC AN REC, P669; Kumar BV, 2002, LECT NOTES COMPUT SC, V2423, P37; KUMAR BV, 2002, THESIS INDIAN I SCI; Lehal GS, 2000, P 15 INT C PATT REC, P557, DOI 10.1109/ICPR.2000.906135; LEHAL GS, 1999, VIVEK, V12, P212; Lehal G. S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791746; LPPMANN R, 1987, IEEE ASSP MAGAZINE, V4; MAHATA K, 2000, THESIS INDIAN I SCI; Marr D, 1982, VISION COMPUTATIONAL; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; Mohanty S, 1998, INT J PATTERN RECOGN, V12, P1007, DOI 10.1142/S0218001498000555; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N; NEGI A, 1999, INT WORKSH PERF EV I; Pal U., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791810; PATI NK, 2003, P INT C INF TECH, P590; PATI PB, 2000, THESIS INDIAN I SCI; Pati PB, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P123; PRAVIN LM, 1999, THESIS INDIAN I SCI; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rajasekaran S., 1977, COMPUTER GRAPHICS IM, V6, P335, DOI 10.1016/0146-664X(77)90028-4; RAMAKRISHNAN AG, 2001, P TAM INT, P165; SEONGWHAN L, 1987, IEEE T PATTERN ANAL, V18, P1045; Sethi I. K., 1976, Journal of the Institution of Electronics and Telecommunication Engineers, V22; SETHI IK, 1977, PATTERN RECOGN, V9, P69, DOI 10.1016/0031-3203(77)90017-6; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; SINHA RMK, 1979, IEEE T SYST MAN CYB, V9, P435; Sinha R. M. K., 1987, Journal of the Institution of Electronics and Telecommunication Engineers, V33; SINHA RMK, 1987, PATTERN RECOGN, V20, P475, DOI 10.1016/0031-3203(87)90075-6; SIROMONEY G, 1978, PATTERN RECOGN, V10, P243, DOI 10.1016/0031-3203(78)90032-8; SIRONONEY G, 1983, IEEE T SYSTEMS MAN C, V13; Srinivasan S. H., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791812; SUKHASWAMI MB, 1995, INT J NEURAL SYST, V6, P317, DOI 10.1142/S0129065795000238; TOMEK I, 1976, IEEE T SYSTEMS MAN C, V6; Murthy CNSG, 1998, NEURAL NETWORKS, V11, P315	69	3	3	1	3	INST ELECTRONICS TELECOMMUNICATION ENGINEERS	NEW DELHI	2 INSTITUTIONAL AREA, LODI ROAD, NEW DELHI 110 003, INDIA	0256-4602			IETE TECH REV	IETE Tech. Rev.	MAY-JUN	2005	22	3					217	227				11	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	984IY	WOS:000233297700007		
J	Graepel, T; Herbrich, R				Graepel, T; Herbrich, R			PAC-Bayesian compression bounds on the prediction error of learning algorithms for classification	MACHINE LEARNING			English	Article						classification; error bounds; sample compression; PAC-Bayes; kernel classifiers	MACHINE	We consider bounds on the prediction error of classification algorithms based on sample compression. We refine the notion of a compression scheme to distinguish permutation and repetition invariant and nonpermutation and repetition invariant compression schemes leading to different prediction error bounds. Also, we extend known results on compression to the case of non-zero empirical risk. We provide bounds on the prediction error of classifiers returned by mistake-driven online learning algorithms by interpreting mistake bounds as bounds on the size of the respective compression scheme of the algorithm. This leads to a bound on the prediction error of perceptron solutions that depends on the margin a support vector machine would achieve on the same training sample. Furthermore, using the property of compression we derive bounds on the average prediction error of kernel classifiers in the PAC-Bayesian framework. These bounds assume a prior measure over the expansion coefficients in the data-dependent kernel expansion and bound the average prediction error uniformly over subsets of the space of expansion coefficients.	Microsoft Res, Cambridge, England; Univ Southampton, Sch Elect & Comp Sci, Southampton, Hants, England	Graepel, T (reprint author), Microsoft Res, Cambridge, England.	thoreg@microsoft.com; rherb@microsoft.com					Bartlett P.L., 1998, ADV KERNEL METHODS S, P43; Cannon A, 2002, J MACH LEARN RES, V2, P335, DOI 10.1162/153244302760200650; CESABIANCHI N, 2002, ADV NEURAL INFORMATI, V14; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FLOYD S, 1995, MACH LEARN, V27, P1; Graepel T., 2000, P 13 ANN C COMP LEAR, P298; Herbrich R, 2002, IEEE T INFORM THEORY, V48, P3140, DOI 10.1109/TIT.2002.805090; HERBRICH R., 2001, LEARNING KERNEL CLAS; Herbrich R., 2002, JMLR, V3, P175; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; LANGFORD J, 2003, ADV NEURAL INFORMATI, V15, P439; Littlestone N., 1986, RELATING DATA COMPRE; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Littlestone N., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory; MARCHAND M, 2001, P 18 INT C MACH LEAR, P345; McAllester D. A., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307435; McAllester D. A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279989; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; SHAWETAYLOR J, 2001, NC2TR1997013 U LOND, V1, P211; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik V., 1998, STAT LEARNING THEORY; VITANYI P, 1997, P EUR C MACH LEARN, P14; WARMUTH M, 2003, P ANN C COMP LEARN T; WYNER AD, 1992, IEEE T INFORMATION T, V4, P415	28	8	8	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	MAY	2005	59	1-2					55	76		10.1007/s10994-005-0462-7		22	Computer Science, Artificial Intelligence	Computer Science	922HW	WOS:000228828700003		
J	Jones, LC; Tefferi, A; Vuong, PT; Desmond, JC; Hofmann, WK; Koeffler, HP				Jones, LC; Tefferi, A; Vuong, PT; Desmond, JC; Hofmann, WK; Koeffler, HP			Detection of aberrant gene expression in CD34(+) hematopoietic stem cells from patients with agnogenic myeloid metaplasia using oligonucleotide microarrays	STEM CELLS			English	Article						hematopoietic stem cells; agnogenic myeloid metaplasia; aberrant gene expression	BONE-MARROW; IDIOPATHIC MYELOFIBROSIS; CLINICAL CORRELATIONS; PROGNOSTIC-FACTORS; BREAST-CANCER; MEGAKARYOCYTES; GROWTH; DIFFERENTIATION; CLASSIFICATION; PREDICTION	Agnogenic myeloid metaplasia (AMM) is a clonal stem cell disorder that leads to ineffective hematopoiesis, bone marrow fibrosis, and extramedullary hematopoiesis. The molecular mechanisms underlying the development of this syndrome are currently unknown. Therefore, the aim of this study was to characterize aberrant gene expression in CD34(+) hematopoietic stem cells from patients with AMM. We used oligonucleotide microarrays to analyze gene expression profiles in CD34(+) hematopoietic stem cells from patients with AMM compared with expression in CD34(+) cells from healthy individuals. We identified 95 highly differentially expressed genes (48 upregulated and 47 downregulated) that are potentially involved in regulating abnormal hematopoietic proliferation and differentiation and confirmed many of them by quantitative polymerase chain reaction. Using; class membership prediction analysis, we identified 75 genes whose expression profiles can accurately differentiate AMM samples from the controls. Using these 75 genes, we were able to discriminate patients with AMM from the controls by hierarchical clustering (Spearman's confidence correlation). The predictive power of these genes was verified by applying the algorithm to an unknown test set containing expression data from eight additional CD34(+) samples (four AMM, four control). Our results indicate that a subset of genes may be used to differentiate patients with AMM from healthy individuals. Furthermore, we identify 95 genes whose aberrant expression may be involved in AMM.	Univ Calif San Francisco, Div Lab Med, San Francisco, CA 94143 USA; Mayo Clin & Mayo Fdn, Div Hematol & Internal Med, Rochester, MN 55905 USA; Univ Calif Los Angeles, Sch Med, Cedars Sinai Med Ctr, Div Hematol Oncol, Los Angeles, CA USA; Univ Hosp, Dept Hematol, Frankfurt, Germany	Jones, LC (reprint author), Univ Calif San Francisco, Div Lab Med, 513 Parnassus Ave,S864, San Francisco, CA 94143 USA.	letetia@itsa.ucsf.edu					Abdallah BM, 2004, J BONE MINER RES, V19, P841, DOI 10.1359/JBMR.040118; Bock O, 2004, EUR J HAEMATOL, V72, P239, DOI 10.1046/j.0902-4441.2003.00204.x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dupriez B, 1996, BLOOD, V88, P1013; Giraudier S, 2002, BLOOD, V100, P2932, DOI 10.1182/blood-2002-02-0485; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Graf L, 2001, BIOL BLOOD MARROW TR, V7, P486, DOI 10.1053/bbmt.2001.v7.pm11669215; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hofmann WK, 2002, BLOOD, V100, P3553, DOI 10.1182/blood.V100.10.3553; Hofmann WK, 2001, BLOOD, V98, P787, DOI 10.1182/blood.V98.3.787; Huang CC, 2004, J PATHOL, V202, P172, DOI 10.1002/path.1505; Kenney AM, 2003, DEVELOPMENT, V130, P15, DOI 10.1242/dev.00182; Kvasnicka HM, 1997, CANCER, V80, P708, DOI 10.1002/(SICI)1097-0142(19970815)80:4<708::AID-CNCR9>3.0.CO;2-I; MARTYRE MC, 1994, BRIT J HAEMATOL, V88, P9, DOI 10.1111/j.1365-2141.1994.tb04970.x; Mesa RA, 1999, BLOOD, V94, p115A; Mesa RA, 2000, BLOOD, V96, P3374; Mesa RA, 1999, AM J HEMATOL, V61, P10, DOI 10.1002/(SICI)1096-8652(199905)61:1<10::AID-AJH3>3.0.CO;2-I; Ng YY, 2004, J LEUKOCYTE BIOL, V75, P314, DOI 10.1189/jlb.0603287; Pellagatti A, 2003, CANCER RES, V63, P3940; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Smith BD, 2001, CURR OPIN ONCOL, V13, P91, DOI 10.1097/00001622-200103000-00002; Steidl U, 2002, BLOOD, V99, P2037, DOI 10.1182/blood.V99.6.2037; Tefferi A, 2000, NEW ENGL J MED, V342, P1255, DOI 10.1056/NEJM200004273421706; TERRERI A, 2001, BRIT J HAEMATOL, V113, P763; THIELE J, 1992, VIRCHOWS ARCH A, V421, P33, DOI 10.1007/BF01607136; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; Vannucchi AM, 2002, BLOOD, V100, P1123, DOI 10.1182/blood-2002-06-1913; Voehringer DW, 2000, P NATL ACAD SCI USA, V97, P2680, DOI 10.1073/pnas.97.6.2680; YAN XQ, 1995, BLOOD, V86, P4025	30	13	14	0	0	ALPHAMED PRESS	MIAMISBURG	ONE PRESTIGE PLACE, STE 290, MIAMISBURG, OH 45342-3758 USA	1066-5099			STEM CELLS	Stem Cells	MAY	2005	23	5					631	637		10.1634/stemcells.2004-0131		7	Cell & Tissue Engineering; Biotechnology & Applied Microbiology; Oncology; Cell Biology; Hematology	Cell Biology; Biotechnology & Applied Microbiology; Oncology; Hematology	925AZ	WOS:000229025200004	15849170	
J	Cai, YD; Zhou, GP; Chou, KC				Cai, YD; Zhou, GP; Chou, KC			Predicting enzyme family classes by hybridizing gene product composition and pseudo-amino acid composition	JOURNAL OF THEORETICAL BIOLOGY			English	Article						classification of enzyme commission; gene ontology; enzymatic attribute; quasi sequence-order effect; nearest neighbor predictor; bioinformatics; proteomics	SUBCELLULAR LOCATION PREDICTION; STRUCTURAL CLASS PREDICTION; FOLDING TYPES; PROTEINS; ONTOLOGY; DATABASE	A: new method has been developed to predict the enzymatic attribute of proteins by hybridizing the gene product composition and pseudo amino acid composition. As a demonstration, a working dataset was generated with a cutoff of 60% sequence identity to avoid redundancy and bias in statistical prediction. The dataset thus constructed contains 39 989 protein sequences, of which 27 469 are non-enzymes and 12 520 enzymes that were further classified into 6 enzyme family classes according to their 6 main EC (Enzyme Con mission) numbers (2314 are oxidoreductases, 3653 transferases, 3246 hydrolases, 1307 lyases, 676 isomerases,and 1324 ligases). The overall success rate by the jackknife test for the identification between enzyme and non-enzyme was 94%, and that for the identification among the 6 enzyme family classes was 98%. It is anticipated that, with the rapid increase of protein sequences entering into databanks, the current method will become a useful automated tool in identifying the enzymatic attribute of a newly found protein sequence. (C) 2004 Elsevier Ltd. All rights reserved.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Tianjin Normal Univ, Tianjin Inst Bioinformat & Drug Discovery, Tianjin 300074, Peoples R China; Harvard Univ, Sch Med, Beth Israel Med Ctr, Boston, MA 02115 USA; Univ Manchester, Inst Sci & Technol, Biomol Sci Dept, Manchester M60 1QD, Lancs, England	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Mar, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Alberts B., 1994, MOL BIOL CELL; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; CHOU KC, 1994, J BIOL CHEM, V269, P22014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Webb EC, 1992, ENZYME NOMENCLATURE; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	25	56	56	0	1	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193			J THEOR BIOL	J. Theor. Biol.	MAY 7	2005	234	1					145	149		10.1016/j.jtbi.200.11.017		5	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	902NB	WOS:000227362700014	15721043	
J	Cano, JR; Herrera, F; Lozano, M				Cano, JR; Herrera, F; Lozano, M			Stratification for scaling up evolutionary prototype selection	PATTERN RECOGNITION LETTERS			English	Article						stratification; scaling up; evolutionary algorithms; prototype selection	LEARNING ALGORITHMS; GENETIC ALGORITHM; RULE; REDUCTION	Evolutionary algorithms has been recently used for prototype selection showing good results. An important problem that we can find is the scaling up problem that appears evaluating the Evolutionary Prototype Selection algorithms in large size data sets. In this paper, we offer a proposal to solve the drawbacks introduced by the evaluation of large size data sets using evolutionary prototype selection algorithms. In order to do this we have proposed a combination of stratified strategy and CHC as representative evolutionary algorithm model. This study includes a comparison between our proposal and other non-evolutionary prototype selection algorithms combined with the stratified strategy. The results show that stratified evolutionary prototype selection consistently outperforms the non-evolutionary ones, the main advantages being: better instance reduction rates, higher classification accuracy and reduction in resources consumption. &COPY; 2004 Elsevier B.V. All rights reserved.	Univ Granada, ETSI Infomat, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain; Univ Jaen, Dept Comp Sci, Jaen 23700, Spain	Cano, JR (reprint author), Univ Granada, ETSI Infomat, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	jrcano@decsai.ugr.es; herrera@decsai.ugr.es; lozano@decsai.ugr.es	Herrera, Francisco/C-6856-2008; Lozano Marquez, Manuel/B-1848-2012; Cano de Amo, Jose-Ramon/L-7494-2014	Herrera, Francisco/0000-0002-7283-312X; Cano de Amo, Jose-Ramon/0000-0001-9150-4113			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116829; Back Thomas, 1997, HDB EVOLUTIONARY COM; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eshelman L. J., 1991, FDN GENETIC ALGORITH, V1, P265; FORREST S, 1993, MACH LEARN, V13, P285, DOI 10.1023/A:1022626114466; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Goldberg D. E., 1989, GENETIC ALGORITHMS S; HART PE, 1968, IEEE T INFORM THEORY, V18, P431; Kibbler D, 1987, P 4 INT WORKSH MACH, P24; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Merz C. J., 1996, UCI REPOSITORY MACHI; NAKASHIMA T, 1998, P INT C EV COMP, P709; Ravindra Babu T., 2001, Pattern Recognition, V34; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Shinn-Ying Ho, 2002, Pattern Recognition Letters, V23, DOI 10.1016/S0167-8655(02)00109-5; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403	21	48	49	1	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAY 15	2005	26	7					953	963		10.1016/j.patrec.2004.09.043		11	Computer Science, Artificial Intelligence	Computer Science	923WR	WOS:000228940700010		
J	Nitschke, G				Nitschke, G			Emergence of cooperation: State of the art	ARTIFICIAL LIFE			English	Review						emergence; cooperative behavior; swarm intelligence; RoboCup soccer; pursuit-evasion	QUADRATIC ASSIGNMENT PROBLEM; PREDATOR-PREY INTERACTIONS; EVOLVING CONTROLLERS; MULTIAGENT SYSTEMS; SELF-ORGANIZATION; PHYSICAL ROBOTS; SOCIAL INSECTS; SOCCER SERVER; ANT COLONIES; EVOLUTION	This review presents a review of prevalent results within research pertaining to emergent cooperation in biologically inspired artificial social systems. Results reviewed maintain particular reference to biologically inspired design principles, given that current mathematical and empirical tools have provided only a partial insight into elucidating mechanisms responsible for emergent cooperation, and then only in systems of an abstract nature. ThiS review, aims to provide an overview of important and disparate research contributions that investigate utilization of biologically inspired concepts such as emergence, evolution, and self-organization as a means of attaining cooperation in artificial social systems. An introduction and overview of emergent cooperation in artificial life is presented, followed by 2 survey of emergent cooperation in swarm-based systems, the pursuit-evasion domain, and RohoCup soccer. The final section draws conclusions regarding future directions of emergent cooperation as a problem-solving methodology that is potentially applicable in a wide range of problem domains. Within each of these sections and their respective themes of research, the mechanisms deemed to he responsible for emergent cooperation are elucidated and their key limitations highlighted. The review concludes that Current studies in emergent cooperative behavior Are limited by a hick of situated and embodied approaches, and I)v the research infancy of current biologically inspired design approaches. Despite these limiting factors, emergent cooperation maintains considerable future potential in a wide variety of application domains where systems composed of many interacting components must cooperatively perform Unanticipated global tasks.	Vrije Univ Amsterdam, Dept Comp Sci, Computat Intelligence Grp, NL-1081 HV Amsterdam, Netherlands	Nitschke, G (reprint author), Vrije Univ Amsterdam, Dept Comp Sci, Computat Intelligence Grp, Boelelaan 1081A, NL-1081 HV Amsterdam, Netherlands.	nitschke@cs.vu.nl					ADAMI C, 1994, 10638 CALTECH KELL R; Akiyama Eizo, 1995, Artificial Life, V2, P293; Alami R, 1998, IEEE ROBOT AUTOM MAG, V5, P36, DOI 10.1109/100.667325; AMAT J, 1995, P 4 INT S EXP ROB, P40; ANGELINE PJ, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P264; ANGELINE PJ, 1994, P 4 ART LIF  C, P353; AOKI I, 1982, B JPN SOC SCI FISH, V48, P1081; Arkin R., 1999, IEEE T ROBOTIC AUTOM, V14, P926; ARKIN R, 1999, ARTIFICIAL INTELLIGE; Arkin R. C., 1998, BEHAV BASED ROBOTICS; ASADA M, 1994, P AAAI 94 WORKSH AI, P16; AVOURIS NM, 1992, DISTRIBUTED ARTIFICI; AXELROD R, 1981, SCIENCE, V211, P1390, DOI 10.1126/science.7466396; Axelrod R., 1984, EVOLUTION COOPERATIO; Axelrod R., 1987, GENETIC ALGORITHMS S; BALDASSARRE G, 2002, P INT WORKSH SELF OR, P11; BECKERS R, 1992, J THEOR BIOL, V159, P397, DOI 10.1016/S0022-5193(05)80686-1; Beckers R., 1994, ARTIF LIFE, P181; Benda M., 1986, BCSG201028 BOEING AI; Bonabeau E, 1997, TRENDS ECOL EVOL, V12, P188, DOI 10.1016/S0169-5347(97)01048-3; Bonabeau E, 1998, J THEOR BIOL, V195, P157, DOI 10.1006/jtbi.1998.0789; BONABEAU E, 1994, ARTIF LIFE, V4, P307; BONABEAU F, 1998, SWARM INTELLIGENCE N; BONGARD JC, 2003, MORPHOFUNCTIONAL MAC; Braitenberg V, 1984, VEHICLES EXPT SYNTHE; BREDER CM, 1954, ECOLOGY, V35, P129; Brooks R. A., 1989, Journal of the British Interplanetary Society, V42; Brooks R. A., 1990, Robotics and Autonomous Systems, V6, DOI 10.1016/S0921-8890(05)80025-9; BRYANT B, 2003, P 2003 C EV COMP; Cao YU, 1997, AUTON ROBOT, V4, P7, DOI 10.1023/A:1008855018923; Chaimowicz L., 2001, P IEEE INT C ROB AUT, P2292; Colomi A, 1991, P 1 EUR C ART LIF, P134; COLORNI A, 1992, PARALLEL PROBLEM SOLVING FROM NATURE, 2, P509; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CULLEN JM, 1965, ANIM BEHAV, V13, P534, DOI 10.1016/0003-3472(65)90117-X; Deneubourg J. L., 1991, P EUR C ART LIF ECAL, P123; Deneubourg J.L., 1990, ANIMALS ANIMATS, P356; DENEUBOURG JL, 1989, ETHOL ECOL EVOL, V1, P295; Deneubourg J.-L., 1987, Experientia Supplementum (Basel), V54, P177; Denzinger J., 1996, P ICMAS 96 KYOT, P48; Di Caro G, 1998, J ARTIF INTELL RES, V9, P317; DIECKMANN U, 1995, J THEOR BIOL, V176, P91, DOI 10.1006/jtbi.1995.0179; DIPIETRO A, 2002, GECCO 2002 P GEN EV, P1065; Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585892; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; DORIGO M, 1995, INTELL AUTOM SOFT CO, V1, P29; Drogoul A, 1995, ARTIFICIAL SOCIETIES, P190; DROGOUL A, 1992, PRACTICE AUTONOMOUS, P161; DROGOUL A, 1992, DISTRIBUTED ARTIFICI, P53; Drogoul A., 1992, P375; DUGATKIN LA, 1990, J THEOR BIOL, V142, P123, DOI 10.1016/S0022-5193(05)80017-7; Epstein J M, 1996, GROWING ARTIFICIAL S; FLOREANO D, 1997, GENETIC PROGRAMMING; FLOREANO D, 1997, P 4 EUR C ART LIF; FLOREANO D, 2000, EVOLUTIONARY ROBOTIC; Floreano D, 2000, NEURAL NETWORKS, V13, P431, DOI 10.1016/S0893-6080(00)00032-0; Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X; FRUTIGER DR, 2002, P 5 INT C CLIMB WALK, P619; Gambardella LM, 1999, J OPER RES SOC, V50, P167, DOI 10.1057/palgrave.jors.2600676; Gomez F., 2003, THESIS U TEXAS AUSTI; GOMEZ F, 2001, AI02292 U TEX COMP S; Gomez F, 1997, ADAPT BEHAV, V5, P317, DOI 10.1177/105971239700500305; GOSS S, 1989, NATURWISSENSCHAFTEN, V76, P579, DOI 10.1007/BF00462870; Grefenstette J. J., 1988, Machine Learning, V3, DOI 10.1007/BF00113898; Gutowitz H., 1993, P 3 EUR C ART LIF, P10; Hackwood S., 1992, Proceedings. 1992 IEEE International Conference on Robotics And Automation (Cat. No.92CH3140-1), DOI 10.1109/ROBOT.1992.220268; Hackwood S., 1991, Proceedings IROS '91. IEEE/RSJ International Workshop on Intelligent Robots and Systems '91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), DOI 10.1109/IROS.1991.174658; Harvey I, 1997, ROBOT AUTON SYST, V20, P205, DOI 10.1016/S0921-8890(96)00067-X; HARVEY I, 1997, P INT S ART LIF ROB, P18; Haynes T., 1995, P 1 INT C MULT SYST, P450; Haynes T., 1996, INT J COMPUT INTELL, V1, P1; Haynes T., 1997, P 2 ANN C GEN PROGR, P162; Haynes T., 1996, Adaption and Learning in Multi-Agent Systems. IJCAI '95 Workshop. Proceedings; HAYNES T, 1995, P 6 INT C GEN ALG, P271; HIEBELER D, 1994, P DEC SUPP 2001 ADV, P20; Hirsch M.W., 1974, DIFFERENTIAL EQUATIO; Holland J. H., 1992, ADAPTATION NATURAL A; *HOUS BOOKS LTD, 2000, DICT BIOL; HSU W, 2001, P 4 EUR C GEN PROGR, P291; HSU WH, 2002, GENETIC EVOLUTIONARY, P764; HUANG J, 1995, APPL ARTIF INTELL, V9, P401, DOI 10.1080/08839519508945482; Iba H, 1998, INFORM SCIENCES, V108, P181, DOI 10.1016/S0020-0255(97)10055-X; IBA H, 1996, PARALLEL PROBLEM SOL, P23; IJSPEERT A, 1999, COOPERATION EXPLORAT; JAMZAD M, 2000, ROBOCUP 99 ROBOT SOC, V3, P61; JBA H, 1997, P IEEE INT C EV COMP, P13; Jennings N., 1995, P 1 INT C MULT SYST, P423; JENNINGS NR, 1995, ARTIF INTELL, V75, P195, DOI 10.1016/0004-3702(94)00020-2; JOHNSON P, 1994, AUTON ROBOT, V2, P43; Keller L, 1998, NATURE, V394, P573, DOI 10.1038/29064; Keller L, 1999, BIOSCIENCE, V49, P899, DOI 10.2307/1313649; KIM J, 1996, P MICR WORLD CUP SOC; Kitano H., 1998, Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146), DOI 10.1109/ROBOT.1998.680735; Kitano H, 1997, AI MAG, V18, P73; Kitano H, 2000, ADV ROBOTICS, V13, P723; KORF RE, 1992, 11 INT WORKSH DISTR, P183; Koza J. R., 1992, P 1 EUR C ART LIF, P110; KRAUS S, 1997, ARTIF INTELL, V94, P80; KUBE C, 1999, ROBOTICS AUTONOMOUS, V1, P20; Kube C. Ronald, 1993, Adaptive Behavior, V2, P189, DOI 10.1177/105971239300200204; Kube CR, 1997, AUTON ROBOT, V4, P53, DOI 10.1023/A:1008859119831; LEVY R, 1992, DECENTRALIZED ARTIFI, V3, P129; Luke S., 1998, ROBOCUP 97 ROBOT SOC, P398; Maniezzo V, 1999, IEEE T KNOWL DATA EN, V11, P769, DOI 10.1109/69.806935; MATARIC M, 1997, J EXPT THEORETICAL A, V9, P62; Mataric M, 1996, ROBOT AUTON SYST, V19, P67, DOI 10.1016/S0921-8890(96)00034-6; Matarie M., 1992, ANIMALS ANIMATS, V2, P432; Matsubara H., 1996, Adaptation, Coevolution and Learning in Multiagent Systems. Papers from the 1996 AAAI Symposium (TR SS-96-01); MCCAULEY E, 1993, AM NAT, V142, P412, DOI 10.1086/285547; Meeden L.A., 1998, SOFT COMPUTING INTEL, P215; MILLER G, 1994, CSRP311 U SUSS SCH C, V1; Mitchell T. M., 1997, MACHINE LEARNING; MITSUMOTO N, 1995, IEEE INT CONF ROBOT, P2187, DOI 10.1109/ROBOT.1995.525584; MONDADA F, 2002, 12SLSASTI SWISS FED; Mondada F., 1993, P 3 INT S EXP ROB, P501; Montana DJ, 1995, EVOL COMPUT, V3, P199, DOI 10.1162/evco.1995.3.2.199; MORIARTY D, 1997, THESIS U TEX DEP COM; Moriarty DE, 1997, EVOL COMPUT, V5, P373; Nishimura Shin I., 1997, Artificial Life, V3, P243, DOI 10.1162/artl.1997.3.4.243; NODA I, 2001, AUTON AGENT MULTI-AG, V7, P101; NODA I, 1996, P 4 PAC RIM INT C AR, P570; Noda I, 1998, APPL ARTIF INTELL, V12, P233, DOI 10.1080/088395198117848; NOLFI S, 2003, ECRIM NEW, V53, P25; NOLFI S, 2000, EVOROBOT 1 1 1SER MA; Nolfi S., 2003, APPL EVOLUTIONARY CO, P581; Oliphant M., 1994, P 4 ART LIF WORKSH, P349; PARKER L, 1994, ADV ROBOTICS, V11, P305; Parker LE, 1999, NEUROCOMPUTING, V28, P75, DOI 10.1016/S0925-2312(98)00116-7; PARKER LE, 1994, P ASCE SPEC C ROB CH, P131; Parker LE, 1999, INTELL AUTOM SOFT CO, V5, P5; Perez-Uribe A, 2003, LECT NOTES ARTIF INT, V2801, P128; Pfeifer R., 1999, UNDERSTANDING INTELL; QUINN M, 2002, INT WORKSH BIOL INSP; Quinn M, 2003, PHILOS T ROY SOC A, V361, P2321, DOI 10.1098/rsta.2003.1258; QUINN M, 2002, 515 U SUSS SCH COGN; RAY T, 2001, ATRHIP15; Reynolds C., 1987, COMPUT GRAPH, V21, P25, DOI DOI 10.1145/37402.37406; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Sahota M. K., 1995, IEEE INT C SYST MAN, P3690; Sandholm TW, 1997, ARTIF INTELL, V94, P99, DOI 10.1016/S0004-3702(97)00030-1; Singh M. P, 1990, P 9 EUR C ART INT, p604~609; STONE M, 1999, P SPIE SENS FUS DEC, V2, P134; Stone P, 1998, APPL ARTIF INTELL, V12, P165, DOI 10.1080/088395198117811; STONE P, 1998, P 2 INT C AUT AG ACM, P110; Stone P., 1998, RoboCup-97: Robot Soccer. World Cup I; Stone P, 1999, ARTIF INTELL, V110, P241, DOI 10.1016/S0004-3702(99)00025-9; Stone P, 1998, INT J HUM-COMPUT ST, V48, P83, DOI 10.1006/ijhc.1997.0162; STONE P, 2002, P 18 INT C MACH LEAR, P537; Sutton R. S., 1998, INTRO REINFORCEMENT; Theraulaz G, 1995, J THEOR BIOL, V177, P381, DOI 10.1006/jtbi.1995.0255; Trianni V, 2003, LECT NOTES ARTIF INT, V2801, P865; Van Valen L.M, 1973, EVOL THEORY, V1, P1, DOI DOI 10.1017/CBO9781139173179; VELOSO M, 1999, ROBOCUP 98 ROBOT SOC, V2, P77; Veloso M, 2000, ADV ROBOTICS, V13, P753; VELOSO M, 1995, ROBOCUP 98 ROBOT SOC, V2, P491; Watson R. A., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.781944; WERNER GM, 1993, P 2 INT C SIM AD BEH, P393; WHITESON S, 2003, P GEN EV COMP C, P356; WILSON EO, 1985, SCIENCE, V228, P1489, DOI 10.1126/science.228.4707.1489; YONG C, 2001, A101287 U TEX DEP CO; ZAERA N, 1996, NOT EVOLVING COLLECT; Zlatev J, 2001, MIND MACH, V11, P155, DOI 10.1023/A:1011218919464	162	8	10	2	14	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	1064-5462	1530-9185		ARTIF LIFE	Artif. Life	SUM	2005	11	3					367	396		10.1162/1064546054407194		30	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	944LX	WOS:000230431600008	16053576	
J	Habrard, A; Bernard, M; Sebban, M				Habrard, A; Bernard, M; Sebban, M			Detecting irrelevant subtrees to improve probabilistic learning from tree-structured data	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	1st International Workshop on Mining Graphs, Trees and Sequences	SEP   10, 2003	Cavtat, CROATIA			data reduction; tree-structured data; noisy data; stochastic tree automata	LANGUAGES; INFERENCE; GRAMMARS	In front of the large increase of the available amount of structured data (such as XML documents), many algorithms have emerged for dealing with tree-structured data. In this article, we present a probabilistic approach which aims at a priori pruning noisy or irrelevant subtrees in a set of trees. The originality of this approach, in comparison with classic data reduction techniques, comes from the fact that only a part of a tree (i.e. a subtree) can be deleted, rather than the whole tree itself. Our method is based on the use of confidence intervals, on a partition of subtrees, computed according to a given probability distribution. We propose an original approach to assess these intervals on tree-structured data and we experimentally show its interest in the presence of noise.	Univ St Etienne, EURISE, F-42023 St Etienne 2, France	Habrard, A (reprint author), Univ St Etienne, EURISE, 23,Rue Dr Paul Michelson, F-42023 St Etienne 2, France.	amaury.habrard@univ-st-etienne.fr; marc.bernard@univ-st-etienne.fr; marc.sebban@univ-st-etienne.fr					Abe N, 1997, MACH LEARN, V29, P275, DOI 10.1023/A:1007477814995; Agrawal R, 1994, P 20 INT C VER LARG; Amoth TR, 2001, MACH LEARN, V44, P211, DOI 10.1023/A:1010971904477; BERNARD M, 1999, 9 INT C IND LOG PROG; Blake C.L., 1998, U CALIFORNIA IRVINE; Brown P. F., 1992, Computational Linguistics, V18; Calera-Rubio J, 1998, INFORM PROCESS LETT, V68, P283, DOI 10.1016/S0020-0190(98)00172-0; Carrasco RC, 2001, MACH LEARN, V44, P185, DOI 10.1023/A:1010836331703; CARRASCO RC, 2002, IN PRESS PATTERN REC; CHAUDHURI R, 1986, J ACM, V33, P702, DOI 10.1145/6490.214099; Comon H., 1997, TREE AUTOMATA TECHNI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERAEDT L, 2000, 4 EUR C PRINC PRACT; DUPONT P, 1994, LNAI, V862; GARCIA P, 1993, DSICII4793 U POL VAL; Gecseg F., 1984, TREE AUTOMATA; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; GOLDMAN SA, 1999, 10 ALG LEARN THEOR C, P1720; HABRARD A, 2003, P 9 C ART INT MED EU, P2780; HABRARD A, 2002, 6 INT C GRAMM INF IC, P2484; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; John G.H., 1994, 11 INT C MACH LEARN; KILPELAINEN P, 1992, A19926 U HELS DEP CO; KING RD, 1995, NEW GENERAT COMPUT, V13, P411; KNUUTILA T, 1994, THEOR COMPUT SCI, V129, P337, DOI 10.1016/0304-3975(94)90033-7; KOSALA R, 2002, 6 EUR C PRINC PRACT, P2431; KOSALA R, 2003, P 18 INT JOINT C ART; LYNGSO R, 1999, 7 INT C INT SYST MOL; MIYAHARA T, 2002, PAKDD 2002 TAIP TAIW; NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001; Nijssen S., 2003, P 1 INT WORKSH MIN G; NOCK R, 2000, INT C ALG LEARN THEO; RICOJUAN J, 2002, ICGI 2002 SPRING VER, P2484; RICOJUAN J, 2000, ICGI 2000 LISB PORT, P1891; SAKAKIBARA Y, 1992, INFORM COMPUT, V97, P23, DOI 10.1016/0890-5401(92)90003-X; TERMIER A, 2002, INT C DAT MIN ICDM 0; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZAKI MJ, 2002, P 8 INT C KNOWL DISC	38	0	0	0	11	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968			FUND INFORM	Fundam. Inform.	JUN	2005	66	1-2					103	130				28	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	020YC	WOS:000235948300006		
J	Biau, G; Bunea, F; Wegkamp, MH				Biau, G; Bunea, F; Wegkamp, MH			Functional classification in Hilbert spaces	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						classification; Fourier expansion; nearest neighbor rule; universal consistency	DISCRIMINANT-ANALYSIS; MODEL	Let X be a random variable taking values in a separable Hilbert space X, with label Y is an element of {0, 1}. We establish universal weak consistency of a nearest neighbor-type classifier based on n independent copies (X-i, Y-i) of the pair (X, Y), extending the classical result of Stone to infinite-dimensional Hilbert spaces. Under a mild condition on the distribution of X, we also prove strong consistency. We reduce the infinite dimension of X by considering only the first d coefficients of a Fourier series expansion of each X-i, and then we perform k-nearest neighbor classification in R-d. Both the dimension and the number of neighbors are automatically selected from the data using a simple data-splitting device. An application of this technique to a signal discrimination problem involving speech recordings is presented.	Univ Montpellier 2, Inst Math & Modelisat Montpellier, CNRS, UMR 5149,Equipe Probabil & Stat, F-34095 Montpellier, France; Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA	Biau, G (reprint author), Univ Montpellier 2, Inst Math & Modelisat Montpellier, CNRS, UMR 5149,Equipe Probabil & Stat, CC 051, F-34095 Montpellier, France.	biau@math.umv-mqmp2.fr; flori@stat.fsu.edu; wegkamp@stat.fsu.edu					ABRAHAM C, 2005, KERNEL RULE FUNCTION; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BOUCHERON S, IN PRESS ESAIM PROBA; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarthy B., 1991, NEAREST NEIGHBOR NN; Devroye L., 1996, PROBABILISTIC THEORY; DIABONIANG S, 2001, NONPARAMETRIC REGRES; Ferraty F, 2003, CR MATH, V336, P1025, DOI 10.1016/S1631-073X(03)00239-5; Ferraty F, 2002, COMPUTATION STAT, V17, P545, DOI 10.1007/s001800200126; Ferraty F, 2003, COMPUT STAT DATA AN, V44, P161, DOI 10.1016/S0167-9473(03)00032-X; Fix E., 1951, 4 USAF SCH AV MED; FIX E, 1991, NEAREST NEIGHBOR NN, P32; Fix E., 1952, 2149004 USAF SCH AV; Hall P, 2001, TECHNOMETRICS, V43, P1, DOI 10.1198/00401700152404273; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; HENGARTNER N, 2002, J ROYAL STAT SOC B, V64, P1; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Mardia K. V., 1979, MULTIVARIATE ANAL; Pollard D., 2002, CAMBRIDGE SERIES STA; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; Ramsay J.O., 2002, APPL FUNCTIONAL DATA; SANSONE G, 1969, ORTHOGONAL FUNCTIONS; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; SZEGO G, 1959, ORTHOGONAL POLYNOMIA, V32; Zygmund A, 1959, TRIGONOMETRIC SERIES, V1	28	46	47	1	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	JUN	2005	51	6					2163	2172		10.1109/TIT.2005.847705		10	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	930XY	WOS:000229451600017		
J	Gao, QB; Wang, ZZ; Yan, C; Du, YH				Gao, QB; Wang, ZZ; Yan, C; Du, YH			Prediction of protein subcellular location using a combined feature of sequence	FEBS LETTERS			English	Article						protein subcellular location; combined feature; amino acid composition; dipeptide composition; physicochemical property; nearest neighbor; jackknife test	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; SECONDARY STRUCTURE-CONTENT; SORTING SIGNALS; TRANSMEMBRANE PROTEINS; LOCALIZATION SITES; PEPTIDES; REPRESENTATION	To understand the structure and function of a protein , an important task is to know where it occurs in the cell. Thus, a computational method for properly predicting the subcellular location of proteins would be significant in interpreting the original data produced by the large-scale genome sequencing projects. The present work tries to explore an effective method for extracting features from protein primary sequence and find a novel measurement of similarity among proteins for classifying a protein to its proper subcellular location. We considered four locations in eukaryotic cells and three locations in prokaryotic cells, which have been investigated by several groups in the past. A combined feature of primary sequence defined as a 430D (dimensional) vector was utilized to represent a protein, including 20 amino acid compositions, 400 dipeptide compositions and 10 physicochemical properties. To evaluate the prediction performance of this encoding scheme, a jackknife test based on nearest neighbor algorithm was employed. The prediction accuracies for cytoplasmic, extracellular, mitochondrial, and nuclear proteins in the former dataset were 86.3%, 89.2%, 73.5% and 89.4%, respectively, and the total prediction accuracy reached 86.3%. As for the prediction accuracies of cytoplasmic, extracellular, and periplasmic proteins in the latter dataset, the prediction accuracies were 97.4%, 860/0, and 79.7, respectively, and the total prediction accuracy of 92.5% was achieved. The results indicate that this method outperforms some existing approaches based on amino acid composition or amino acid composition and dipeptide composition. (c) 2005 Published by Elsevier B.V. on behalf of the Federation of European Biochemical Societies.	Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China	Gao, QB (reprint author), Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China.	gqb_kd@yahoo.com.cn	Gao, Qing-Bin/G-9825-2011				Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, P414; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; CORNETTE JL, 1987, J MOL BIOL, V195, P659, DOI 10.1016/0022-2836(87)90189-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Feng ZP, 2002, INT J BIOCHEM CELL B, V34, P298, DOI 10.1016/S1357-2725(01)00121-2; Fujiwara Y, 2001, Genome Inform, V12, P103; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kim S, 2004, BIOINFORMATICS, V20, P40, DOI 10.1093/bioinformatics/btg368; Lio P, 2000, BIOINFORMATICS, V16, P376, DOI 10.1093/bioinformatics/16.4.376; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; Nair R, 2003, PROTEINS, V53, P917, DOI 10.1002/prot.10507; Nair R, 2004, NUCLEIC ACIDS RES, V32, pW517, DOI 10.1093/nar/gkh441; Nair Rajesh, 2002, Bioinformatics, V18 Suppl 1, pS78; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; Nielsen H, 1999, PROTEIN ENG, V12, P3, DOI 10.1093/protein/12.1.3; Nielsen H., 1998, Proceedings Sixth International Conference on Intelligent Systems for Molecular Biology; Pan YX, 2005, ACTA BIOCH BIOPH SIN, V37, P88, DOI 10.1111/j.1745-7270.2005.00013.x; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Rost B, 1996, PROTEIN SCI, V5, P1704; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2005, AMINO ACIDS, V28, P29, DOI 10.1007/s00726-004-0154-9; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	53	67	67	1	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0014-5793			FEBS LETT	FEBS Lett.	JUN 20	2005	579	16					3444	3448		10.1016/j.febslet.2005.05.021		5	Biochemistry & Molecular Biology; Biophysics; Cell Biology	Biochemistry & Molecular Biology; Biophysics; Cell Biology	939AV	WOS:000230045400015	15949806	
J	Domeniconi, C; Gunopulos, D; Peng, J				Domeniconi, C; Gunopulos, D; Peng, J			Large margin nearest neighbor classifiers	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						feature relevance; margin; nearest neighbor classification; support vector machines (SVMs)	SUPPORT VECTOR MACHINES; CLASSIFICATION; REGRESSION	The nearest neighbor technique is a simple and appealing approach to addressing classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. The employment of a locally adaptive metric becomes crucial in order to keep class conditional probabilities close to uniform, thereby minimizing the bias of estimates. We propose a technique that computes a locally flexible metric by means of support vector machines (SVMs). The decision function constructed by SVMs is used to determine the most discriminant direction in a neighborhood around the query. Such a direction provides a local feature weighting scheme. We formally show that our method increases the margin in the weighted space where classification takes place. Moreover, our method has the important advantage of online computational efficiency over competing locally adaptive techniques for nearest neighbor classification. We demonstrate the efficacy of our method using both real and simulated data.	George Mason Univ, Informat & Software Engn Dept, Fairfax, VA 22030 USA; Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA; Tulane Univ, Elect Engn & Comp Sci Dept, New Orleans, LA 70118 USA	Domeniconi, C (reprint author), George Mason Univ, Informat & Software Engn Dept, Fairfax, VA 22030 USA.	carlotta@ise.gmu.edu; dg@cs.ucr.edu; jp@eecs.tulane.edu					Aha D. W., 1997, ARTIF INTELL, V11, P1; AKAHO S, 2002, P 6 KERN MACH WORKSH, P1; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bellman R., 1961, ADAPTIVE CONTROL PRO; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R. O., 1973, PATTERN CLASSIFICATI; Friedman JH, 1994, FLEXIBLE METRIC NEAR; Hardy G. H., 1973, INEQUALITIES; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Ho T. K., 1998, LECT NOTES COMPUTER, P640; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Peng J, 2003, IEEE T NEURAL NETWOR, V14, P940, DOI 10.1109/TNN.2003.813835; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rifkin R, 2004, J MACH LEARN RES, V5, P101; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING	28	40	43	1	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JUL	2005	16	4					899	909		10.1109/TNN.2005.849821		11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	945MC	WOS:000230505600011	16121731	
J	Raicharoen, T; Lursinsap, C				Raicharoen, T; Lursinsap, C			A divide-and-conquer approach to the pairwise opposite class-nearest neighbor (POC-NN) algorithm	PATTERN RECOGNITION LETTERS			English	Article						pattern classification; nearest neighbor rule; prototype selection; prototype replacement	RULE; CLASSIFICATION	This paper presents a new method based on divide-and-conquer approach to the selection and replacement of a set of prototypes from the training set for the nearest neighbor rule, This method aims at reducing the computational time and the memory space as well as the sensitivity of the order and the noise of the training data. A reduced prototype set contains Pairwise Opposite Class-Nearest Neighbor (POC-NN) prototypes which are close to the decision boundary and used instead of the training patterns. POC-NN prototypes are obtained by recursively iterative separation and analysis of the training data into two regions until each region is correctly grouped and classified, The separability is determined by the POC-NN prototypes essential to define the locations of all separating hyperplaries, Our method is fast and order independent. The number of prototypes and the overfitting of the model can be reduced by the User, The experimental results signify the effectiveness of this technique and its performance in both accuracy and prototype rate as well as in training time to those obtained by classical nearest neighbor techniques. (c) 2005 Elsevier B.V. All rights reserved.	Chulalongkorn Univ, Fac Sci, Adv Virtual & Intelligent Comp Ctr AVIC, Dept Math, Bangkok 10330, Thailand	Raicharoen, T (reprint author), Chulalongkorn Univ, Fac Sci, Adv Virtual & Intelligent Comp Ctr AVIC, Dept Math, Bangkok 10330, Thailand.	thanapant@avic.sc.chula.ac.th; lchidcha@chula.ac.th					Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Devi VS, 2002, PATTERN RECOGN, V35, P505; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L., 1996, PROBABILISTIC THEORY; Duda R O, 2001, PATTERN CLASSIFICATI; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HART PE, 1966, SEL66016; Hastie T., 2001, SPRINGER SERIES STAT; Hayter AJ, 2002, PROBABILITY STAT ENG; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; McClave JT, 2001, STAT BUSINESS EC; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T. M., 1997, MACHINE LEARNING; Murphy P. M., 1994, UCI REPOSITORY MACHI; RITTER GL, 1975, IEEE T INFORM THEORY, V23, P1179; ROOBAERT D, 2000, P IEEE INT WORKSH NE; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOUSSAINT G, 2002, P 34 S COMP STAT MON; TOUSSAINT GT, 1994, PATTERN RECOGN LETT, V15, P797, DOI 10.1016/0167-8655(94)90007-8; *USPS, 1994, MACH LEARN NEUR STAT; Vapnik V., 1998, STAT LEARNING THEORY; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	30	14	17	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL 15	2005	26	10					1554	1567		10.1016/j.patrec.2005.01.003		14	Computer Science, Artificial Intelligence	Computer Science	938MF	WOS:000230006800015		
J	Prank, K; Schulze, E; Eckert, O; Nattkemper, TW; Bettendorf, M; Maser-Gluth, C; Sejnowski, TJ; Grote, A; Penner, E; von zur Muhlen, A; Brabant, G				Prank, K; Schulze, E; Eckert, O; Nattkemper, TW; Bettendorf, M; Maser-Gluth, C; Sejnowski, TJ; Grote, A; Penner, E; von zur Muhlen, A; Brabant, G			Machine learning approaches for phenotype-genotype mapping: predicting heterozygous mutations in the CYP21B gene from steroid profiles	EUROPEAN JOURNAL OF ENDOCRINOLOGY			English	Article							CONGENITAL ADRENAL-HYPERPLASIA; ARTIFICIAL NEURAL NETWORKS; PCR-BASED DIAGNOSIS; 21-HYDROXYLASE DEFICIENCY; STEROID-21-HYDROXYLASE; CLASSIFICATION; INTRON-2; WOMEN	Objective: Non-linear relations between multiple biochemical parameters are the basis for the diagnosis of many diseases. Traditional linear analytical methods are not reliable predictors. Novel nonlinear techniques are increasingly used to improve the diagnostic accuracy of automated data interpretation. This has been exemplified in particular for the classification and diagnostic prediction of cancers based on expression profiling data. Our objective was to predict the genotype from complex biochemical data by comparing the performance of experienced clinicians to traditional linear analysis, and to novel non-linear analytical methods. Design and methods: As a model, we used a well-defined set of interconnected data consisting of unstimulated serum levels of steroid intermediates assessed in 54 subjects heterozygous for a mutation of the 21-hydroxylase gene (CYP21B) and in 43 healthy controls. Results: The genetic alteration was predicted from the pattern of steroid levels with an accuracy of 39% by clinicians and of 64% by linear analysis. In contrast, non-linear analysis, such as self-organizing artificial neural networks, support vector machines, and nearest neighbour classifiers, allowed for higher accuracy up to 83%. Conclusions: The successful application of these non-linear adaptive methods to capture specific biochemical problems may have generalized implications for biochemical testing in many areas. Nonlinear analytical techniques such as neural networks, support vector machines, and nearest neighbour classifiers may serve as an important adjunct to the decision process of a human investigator not ' trained ' in a specific complex clinical or laboratory setting and may aid them to classify the problem more directly.	Univ Bielefeld, Int NRW Grad Sch Bioinformat, D-33615 Bielefeld, Germany; Univ Bielefeld, Genome Res Ctr Biotechnol, D-33615 Bielefeld, Germany; Hannover Med Sch, D-30625 Hannover, Germany; Mol Genet Lab Raue, D-69121 Heidelberg, Germany; Hannover Med Sch, Dept Visceral & Transplantat Surg, D-30623 Hannover, Germany; Hannover Med Sch, Dept Clin Endocrinol, D-30623 Hannover, Germany; Univ Bielefeld, Fac Technol, Appl Neuroinformat Grp, D-33615 Bielefeld, Germany; Univ Heidelberg, Dept Pediat, D-69120 Heidelberg, Germany; Univ Heidelberg, Dept Pharmacol, D-69120 Heidelberg, Germany; Salk Inst, Howard Hughes Med Inst, San Diego, CA 92186 USA; Salk Inst, Computat Neurobiol Lab, San Diego, CA 92186 USA	Prank, K (reprint author), Univ Bielefeld, Int NRW Grad Sch Bioinformat, D-33615 Bielefeld, Germany.	klaus.prank@cebitec.uni-bielefeld.de					Azziz R, 1997, FERTIL STERIL, V68, P183; Baxt WG, 1996, LANCET, V347, P12, DOI 10.1016/S0140-6736(96)91555-X; BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blanche H, 1997, HUM GENET, V101, P56, DOI 10.1007/s004390050586; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2; Day DJ, 1996, HUM MOL GENET, V5, P2039, DOI 10.1093/hmg/5.12.2039; Dhanasekaran SM, 2001, NATURE, V412, P822, DOI 10.1038/35090585; FIET J, 1994, ANN CLIN BIOCHEM, V31, P56; GRUNWALD K, 1990, GYNECOL ENDOCRINOL, V4, P287, DOI 10.3109/09513599009024983; KEERTHI SS, 1999, CD9914 TR NAT U SING; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1982, BIOL CYBERN, V44, P135, DOI 10.1007/BF00317973; KOZOWER M, 1974, J CLIN ENDOCR METAB, V38, P407; Martinerie J, 1998, NAT MED, V4, P1173, DOI 10.1038/2667; MARTINETZ T, 1994, NEURAL NETWORKS, V7, P507, DOI 10.1016/0893-6080(94)90109-0; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; MOREIRA AC, 1992, J CLIN ENDOCR METAB, V74, P198, DOI 10.1210/jc.74.1.198; NEW MI, 1994, J STEROID BIOCHEM, V48, P15, DOI 10.1016/0960-0760(94)90246-1; Platt J., 1998, ADV KERNEL METHODS S; Ratsch G., 1999, NEURAL NETWORKS SIGN, V9, P41, DOI DOI 10.1109/NNSP.1999.788121; Schulze E, 1998, ENDOCR RES, V24, P637; SCHULZE E, 1995, ENDOCR RES, V21, P359; SPEISER PW, 2003, ENGLAND J MED, V21, P776; Tarassenko L., 1998, GUIDE NEURAL COMPUTI; Vapnik V. N., 1995, NATURE STAT LEARNING; WILSON RC, 1995, J CLIN ENDOCR METAB, V80, P2322, DOI 10.1210/jc.80.8.2322	30	3	3	0	1	BIO SCIENTIFICA LTD	BRISTOL	EURO HOUSE, 22 APEX COURT WOODLANDS, BRADLEY STOKE, BRISTOL BS32 4JT, ENGLAND	0804-4643			EUR J ENDOCRINOL	Eur. J. Endocrinol.	AUG	2005	153	2					301	305		10.1530/eje.1.01957		5	Endocrinology & Metabolism	Endocrinology & Metabolism	961YS	WOS:000231698400016	16061837	
J	Zhu, HW; Basir, O				Zhu, HW; Basir, O			An adaptive fuzzy evidential nearest neighbor formulation for classifying remote sensing images	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						adaptive fuzzy evidential reasoning; Dempster-Shafer evidence theory (DSET); image classification; K-nearest neighbor algorithm; remote sensing	DEMPSTER-SHAFER THEORY; SUPERVISED CLASSIFICATION; BELIEF STRUCTURES; NEURAL-NETWORKS; SENSED DATA; SELECTION; CLASSIFIERS; RULE; UNCERTAINTY; ALGORITHMS	The paper presents a novel adaptive fuzzy evidential nearest neighbor formulation for classifying remotely sensed images. The formulation combines the generalized fuzzy version of the Dempster-Shafer evidence theory (DSET) and the K-nearest neighbor (KNN) algorithm. Each of the K nearest neighbors provides evidence on the belongingness of the input pattern to be classified, and it is evaluated based on a measure of disapproval to achieve the adaptive capability during the classification process. The disapproval measure quantifies the lack of support with respect to the belongingness of the input pattern to a given class. Pieces of evidence are ranked based on their degree of disapproval and fused in a sequential manner. The pignistic Shannon entropy is used to estimate the degree of consensus among pieces of evidence provided by nearest neighbors and as a criterion for terminating the evidence fusion process. The paper reports the results of experimental work conducted to evaluate the proposed classification scheme using real multichannel remote sensing images. As will be demonstrated using the experimental results, the proposed classification scheme demonstrated robust performance and outperformed commonly used methods such as the K-nearest neighbor algorithm of Cover and Hart (1967), the fuzzy K-nearest neighbor algorithm of Keller et aL (1985), the evidence-theoretic K-nearest neighbor algorithm of Denoex (1995), and its fuzzy version of Zouhal and Denoex (1997). The performance of these techniques is examined with respect to the K-parameter and classification accuracy.	Univ Waterloo, Dept Elect & Comp Engn, Pattern Anal & Machine Intelligence Res Grp, Waterloo, ON N2L 3G1, Canada	Zhu, HW (reprint author), Univ Waterloo, Dept Elect & Comp Engn, Pattern Anal & Machine Intelligence Res Grp, Waterloo, ON N2L 3G1, Canada.	h4zhu@engmail.uwaterloo.ca; obasir@uwaterloo.ca	Zhu, Howard/E-7683-2010				Aminzadeh F., 1994, SOFT COMPUTING FUZZY; Binaghi E, 1999, INT J INTELL SYST, V14, P559, DOI 10.1002/(SICI)1098-111X(199906)14:6<559::AID-INT2>3.0.CO;2-#; Binaghi E, 1997, IEEE T GEOSCI REMOTE, V35, P326, DOI 10.1109/36.563272; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1179, DOI 10.1109/36.752239; Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P429, DOI 10.1109/36.823938; CONGALTON RG, 1986, IEEE T GEOSCI REMOTE, V24, P169, DOI 10.1109/TGRS.1986.289546; COPPIN PR, 1994, IEEE T GEOSCI REMOTE, V32, P918, DOI 10.1109/36.298020; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dubois D., 1982, FUZZY INFORM DECISIO, P167; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fabre S, 2002, IEEE T GEOSCI REMOTE, V40, P1997, DOI 10.1109/TGRS.2002.805143; Fix E., 1951, 4 USAF SCH AV MED; Foody GM, 2000, COMPUT GEOSCI-UK, V26, P469, DOI 10.1016/S0098-3004(99)00125-9; Giacinto G, 2000, PATTERN RECOGN LETT, V21, P385, DOI 10.1016/S0167-8655(00)00006-4; Giacinto G, 2000, ELECTRON LETT, V36, P420, DOI 10.1049/el:20000374; H' egarat-Mascle S.L., 1997, IEEE T GEOSCI REMOTE, V35, P1018; Hastie T, 2001, ELEMENTS STAT LEARNI; HUDSON WD, 1987, PHOTOGRAMM ENG REM S, V53, P421; ISHIZUKA M, 1982, INFORM SCIENCES, V28, P179, DOI 10.1016/0020-0255(82)90047-0; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T., 1995, LVQ PAK LEARNING VEC; OGAWA H, 1985, INT J MAN MACH STUD, V22, P295, DOI 10.1016/S0020-7373(85)80005-5; PAOLA JD, 1995, IEEE T GEOSCI REMOTE, V33, P981, DOI 10.1109/36.406684; SERPICO SB, 1995, IEEE T GEOSCI REMOTE, V33, P562, DOI 10.1109/36.387573; Serpico SB, 1996, PATTERN RECOGN LETT, V17, P1331, DOI 10.1016/S0167-8655(96)00090-6; Shafer G., 1976, MATH THEORY EVIDENCE; SINGH A, 1989, INT J REMOTE SENS, V10, P989; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smits PC, 2002, IEEE T GEOSCI REMOTE, V40, P801, DOI 10.1109/TGRS.2002.1006354; Solaiman B, 1999, IEEE T GEOSCI REMOTE, V37, P1316, DOI 10.1109/36.763295; WANG F, 1990, IEEE T GEOSCI REMOTE, V28, P194, DOI 10.1109/36.46698; Wirth N., 1986, ALGORITHMS DATA STRU; YAGER RR, 1982, INFORM SCIENCES, V28, P45, DOI 10.1016/0020-0255(82)90031-7; Yager RR, 1996, INT J APPROX REASON, V14, P127, DOI 10.1016/0888-613X(96)00092-8; YAGER RR, 1995, IEEE T SYST MAN CYB, V25, P1221, DOI 10.1109/21.398683; YEN J, 1990, IEEE T SYST MAN CYB, V20, P559, DOI 10.1109/21.57269; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; ZHU H, 2003, P 10 IEEE INT C EL C, P1070; ZHU H, 2003, P 7 JOINT C INF SCI, P26; Zouhal L.M., 1997, P 2 INT ICSC S FUZZ, P294	43	32	32	1	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	AUG	2005	43	8					1874	1889				16	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	949BX	WOS:000230761000018		
J	Wong, JWH; Cartwright, HM				Wong, JWH; Cartwright, HM			Deterministic projection by growing cell structure networks for visualization of high-dimensionally datasets	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						random projection; growing cell structure networks; high-dimensionality data; data visualization; feature transformation; topology preserving maps; self-organizing maps; clinical proteomics dataset	PROTEOMIC PATTERNS; LINDENSTRAUSS; JOHNSON; CANCER; SERUM; MAPS	Recent advances in clinical proteomics data acquisition have led to the generation of datasets of high complexity and dimensionality. We present here a visualization method for high-dimensionality datasets that makes use of neuronal vectors of a trained growing cell structure (GCS) network for the projection of data points onto two dimensions. The use of a GCS network enables the generation of the projection matrix deterministically rather than randomly as in random projection. Three datasets were used to benchmark the performance and to demonstrate the use of this deterministic projection approach in real-life scientitic applications. Comparisons are made to an existing self-organizing map projection method and random projection. The results suggest that deterministic projection outperforms existing methods and is suitable for the visualization of datasets of very high dimensionality. (c) 2005 Elsevier Inc. All rights reserved.	Univ Oxford, Dept Chem, Phys & Theoret Chem Lab, Oxford OX1 3QZ, England	Wong, JWH (reprint author), Univ Oxford, Dept Chem, Phys & Theoret Chem Lab, S Parks Rd, Oxford OX1 3QZ, England.	jason.wong@chem.ox.ac.uk	Wong, Jason/A-9466-2008	Wong, Jason/0000-0003-2953-7728			Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4; Arriaga R. I., 1999, P 40 ANN S FDN COMP, P616; Bingham E., 2001, ACM SIGKDD INT C KNO, P245; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta S, 2003, RANDOM STRUCT ALGOR, V22, P60, DOI 10.1002/rsa.10073; Dasgupta S., 2000, P 16 C UNC ART INT, P143; Ferguson PL, 2003, ANNU REV BIOPH BIOM, V32, P399, DOI 10.1146/annurev.biophys.32.110601.141854; Fern X.Z., 2003, P 20 INT C MACH LEAR, P186, DOI Proc. 20th Int. Conf. Machine Learning; Forina M, 1991, PARVUS EXTENDIBLE PA; Fritzke B., 1993, ADV NEURAL INFORMATI, V5, P123; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; Goldberg D. E., 1989, GENETIC ALGORITHMS S; GROUB GH, 1989, MATRIX COMP; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Jackson JE, 1991, USERS GUIDE PRINCIPA; Johnson W. B., 1984, CONT MATH, V1, P189; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; KASKI S, 1999, P INT JOINT C NEUR N, P413; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171; ULTSCH A, 1990, INTERNATIONAL NEURAL NETWORK CONFERENCE, VOLS 1 AND 2, P305; Wu Zheng, 2003, Int J Neural Syst, V13, P353, DOI 10.1142/S0129065703001662	26	4	5	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	AUG	2005	38	4					322	330		10.1016/j.jbi.2005.02.002		9	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	959JO	WOS:000231514200010	16084474	
J	Viswanath, P; Murty, MN; Bhatnagar, S				Viswanath, P; Murty, MN; Bhatnagar, S			Overlap pattern synthesis with an efficient nearest neighbor classifier	PATTERN RECOGNITION			English	Article						nearest neighbor classifier; pattern synthesis; compact representation; data mining	ERROR RATE ESTIMATION; BOOTSTRAP	Nearest neighbor (NN) classifier is the most popular non-parametric classifier. It is a simple classifier with no design phase and shows good performance. Important factors affecting the efficiency and performance of NN classifier are (i) memory required to store the training set, (ii) classification time required to search the nearest neighbor of a given test pattern, and (iii) due to the curse of dimensionality the number of training patterns needed by it to achieve a given classification accuracy becomes prohibitively large when the dimensionality of the data is high. In this paper, we propose novel techniques to improve the performance of NN classifier and at the same time to reduce its computational burden. These techniques are broadly based on: (i) overlap based pattern synthesis which can generate a larger number of artificial patterns than the number of input patterns and thus can reduce the curse of dimensionality effect, (ii) a compact representation of the given set of training patterns called overlap pattern graph (OLP-graph) which can be incrementally built by scanning the training set only once and (iii) an efficient NN classifier called OLP-NNC which directly works with OLP-graph and does implicit overlap based pattern synthesis. A comparison based on experimental results is given between some of the relevant classifiers. The proposed schemes are suitable for applications dealing with large and high dimensional datasets like those in data mining. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Bhatnagar, S (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	viswanath@csa.iisc.ernet.in; mnn@csa.iisc.ernet.in; shalabh@csa.iisc.ernet.in					Ananthanarayana VS, 2001, PATTERN RECOGN, V34, P2249, DOI 10.1016/S0031-3203(01)00028-0; Babu TR, 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Draper D., 1994, P 10 C UNC ART INT, P170; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fix E., 1952, 11 USAF SCH AV MED; Fix E., 1951, 4 USAF SCH AV MED; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Han J., 2000, P ACM SIGMOD INT C M; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jain A. K., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Kozlov A. V., 1995, P 11 ANN C UNC ART I, P376; Murphy P. M., 1994, UCI REPOSITORY MACHI; TIAN Z, 1996, P ACM SIGMOD INT C M; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516	22	6	6	1	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	AUG	2005	38	8					1187	1195		10.1016/j.patcog.2004.10.007		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	933YW	WOS:000229669900004		
J	Shen, HB; Chou, KC				Shen, HB; Chou, KC			Using optimized evidence-theoretic K-nearest neighbor classifier and pseudo-amino acid composition to predict membrane protein types	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						evidence theory; KNN classifier; pseudo-amino acid composition; type-I membrane protein; type-II membrane protein; multipass transmembrane protein; lipid-chain-anchored membrane protein; GPI-anchored membrane protein	FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; SUBCELLULAR LOCATION PREDICTION; SORTING SIGNALS; FOLDING TYPES; LOCALIZATION; REPRESENTATION; SPACE; RULE	Knowledge of membrane protein type often provides crucial hints toward determining the function of an uncharacterized membrane protein. With the avalanche of new protein sequences emerging during the post-genomic era, it is highly desirable to develop an automated method that can serve as a high throughput tool in identifying the types of newly found membrane proteins according to their primary sequences, so as to timely make the relevant annotations on them for the reference usage in both basic research and drug discovery. Based on the concept of pseudo-amino acid composition [K.C. Chou, Proteins: Struct. Funct. Genet. 43 (2001) 246255; Erratum: Proteins: Struct. Funct. Genet. 44 (2001) 60] that has made it possible to incorporate a considerable amount of sequence-order effects by representing a protein sample in terms of a set of discrete numbers, a novel predictor, the so-called "optimized evidence-theoretic K-nearest neighbor" or "OET-KNN" classifier, was proposed. It was demonstrated via the self-consistency test, jackknife test, and independent dataset test that the new predictor, compared with many previous ones, yielded higher success rates in most cases. The new predictor can also be used to improve the prediction quality for, among many other protein attributes, structural class, subcellular localization, enzyme family class, and G-protein coupled receptor type. The OET-KNN classifier will be available as a web-server at www.pami.sjtu.edu.cn/kcchou. (c) 2005 Elsevier Inc. All rights reserved.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Alberts B., 1994, MOL BIOL CELL; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2004, J THEOR BIOL, V226, P373, DOI 10.1016/j.jtbi.2003.08.015; Cai YD, 2001, J BIOMOL STRUCT DYN, V18, P607; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2005, BIOCHEM BIOPH RES CO, V327, P845, DOI 10.1016/j.bbrc.2004.12.069; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; CHOU KC, 2004, J CELL BIOCHEM, V1291, P1085; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2005, BIOCHEM BIOPH RES CO, V329, P1362, DOI 10.1016/j.bbrr.2005.02.098; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou P Y, 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng ZP, 2000, J PROTEIN CHEM, V19, P269, DOI 10.1023/A:1007091128394; LODISH H, 1995, MOL CELL BIOL, pCH3; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Shafer G., 1976, MATH THEORY EVIDENCE; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2005, AMINO ACIDS, V28, P29, DOI 10.1007/s00726-004-0154-9; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	51	118	121	2	8	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	AUG 19	2005	334	1					288	292		10.1016/j.bbrc.2005.06.087		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	948MH	WOS:000230719400040	16002049	
J	Veenman, CJ; Reinders, MJT				Veenman, CJ; Reinders, MJT			The nearest subclass classifier: A compromise between the nearest mean and nearest neighbor classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; regularization; cross-validation; prototype selection	LEARNING ALGORITHMS; NEURAL NETWORKS; RULE; SELECTION; DESIGN; PROTOTYPES; SUBSET; BIAS; ABSTRACTION; SEPARATION	We present the Nearest Subclass Classifier (NSC), which is a classification algorithm that unifies the flexibility of the nearest neighbor classifier with the robustness of the nearest mean classifier. The algorithm is based on the Maximum Variance Cluster algorithm and, as such, it belongs to the class of prototype- based classifiers. The variance constraint parameter of the cluster algorithm serves to regularize the classifier, that is, to prevent overfitting. With a low variance constraint value, the classifier turns into the nearest neighbor classifier and, with a high variance parameter, it becomes the nearest mean classifier with the respective properties. In other words, the number of prototypes ranges from the whole training set to only one per class. In the experiments, we compared the NSC with regard to its performance and data set compression ratio to several other prototype- based methods. On several data sets, the NSC performed similarly to the k-nearest neighbor classifier, which is a well-established classifier in many domains. Also concerning storage requirements and classification speed, the NSC has favorable properties, so it gives a good compromise between classification performance and efficiency.	Delft Univ Technol, Dept Mediamat, NL-2600 GA Delft, Netherlands	Veenman, CJ (reprint author), Delft Univ Technol, Dept Mediamat, POB 5031, NL-2600 GA Delft, Netherlands.	C.J.Veenman@ewi.tudelft.nl; M.J.T.Reinders@ewi.tudelft.nl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bezdek J. C., 1981, PATTERN RECOGNITION; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; Blake C, 1998, UCI REPOSITORY MACHI; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Dunn J. C., 1974, Journal of Cybernetics, V4; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Fisher RA, 1936, ANN EUGENIC, V7, P179; Ganti V, 1999, COMPUTER, V32, P38, DOI 10.1109/2.781633; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Glover F., 1997, TABU SEARCH; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 2001, ELEMENTS STAT LEARNI; Henery R. J., 1994, MACHINE LEARNING NEU, P107; Hodges J., 1951, 4 USAF SCH AV MED, P261; HOERL AE, 1970, TECHNOMETRICS, V12, P55; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen T., 1990, P INT JOINT C NEUR N, P545; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1999, IEEE T NEURAL NETWOR, V10, P1142, DOI 10.1109/72.788653; Lam W, 2002, PATTERN RECOGN, V35, P1491, DOI 10.1016/S0031-3203(01)00131-5; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Swonger C., 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Veenman CJ, 2002, IEEE T PATTERN ANAL, V24, P1273, DOI 10.1109/TPAMI.2002.1033218; Veenman CJ, 2003, IEEE T IMAGE PROCESS, V12, P304, DOI 10.1109/TIP.2002.806256; WILFONG G, 1991, P 7 ANN ACM S COMP G, P224, DOI 10.1145/109648.109673; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson D.R., 1997, P 14 INT C MACH LEAR, P404; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193	54	61	62	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1417	1429		10.1109/TPAMI.2005.187		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	944XB	WOS:000230463300005	16173185	
J	Allouche, MK; Moulin, B				Allouche, MK; Moulin, B			Amalgamation in cartographic generalization using Kohonen's feature nets	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article						amalgamation; cartographic generalization; Kohonen's feature nets	GESTALT	Empirical observations of the way cartographers deal with generalization problems lead to the hypothesis that they first detect patterns of anomalies in the cartographic data set and then eliminate anomalies by transforming the data. Automatically identifying patterns of anomalies on the map is a difficult task when using GIS functions or traditional algorithmic approaches. Techniques based on the use of neural networks have been widely used in artificial intelligence in order to solve pattern-recognition problems. In this paper, we explore how Kohonen-type neural networks can be used to deal with map generalization applications in which the main problem is to identify high-density regions that include cartographic elements of the same type. We also propose an algorithm to replace cartographic elements located in a region by its surrounding polygon. The use of this type of neural network permitted us to generate different levels of grouping according to the chosen zoom-scale on the map. These levels correspond to a multiple representation of the generalized cartographic elements. As an illustration, we apply our approach to the automatic replacement of a group of houses represented as a set of very close points in the original data set, by a polygon representing the corresponding urban area in the generalized map.	Def Res & Dev Canada, Val Belair, PQ G3J 1X5, Canada; Univ Laval, Dept Comp Sci, Ste Foy, PQ G1K 7P4, Canada; Univ Laval, Res Ctr Geomat, Ste Foy, PQ G1K 7P4, Canada	Allouche, MK (reprint author), Def Res & Dev Canada, 2459 Blvd,Pie XI N, Val Belair, PQ G3J 1X5, Canada.	mohamad.allouche@drdc-rddc.gc.ca	Wright, Dawn/A-4518-2011	Wright, Dawn/0000-0002-2997-7611			*ACI, 1973, DICT MULT TERM TECHN; AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; ANDERS KH, 1999, SMATI 99 SEMANTIC MO; Anderson J.A, 1995, INTRO NEURAL NETWORK; ARMSTRONG MP, 1991, MAP GEN MAKING RULES, P86; BERGERON M, 1993, VOCABULAIRE GEOMATIQ; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bundy G. L., 1995, GIS GEN METHODOLOGY, P106; Cichocki A., 1993, NEURAL NETWORKS OPTI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Fausett L. V, 1994, FUNDAMENTALS NEURAL; Friedman M, 1999, INTRO PATTERN RECOGN; Goldberg D. E., 1989, GENETIC ALGORITHMS S; GRUNREICH D, 1992, 3 EUR C EXH GEOGR IN; HARRIE L, 2000, INT ARCH PHOTOGRAM B, V4, P348; HINTON G E, 1992, Scientific American, V267, P144; KELLER S, 1994, 6 INT S SPAT DAT HAN; Kohonen T., 1995, HDB BRAIN THEORY NEU, P537; Kohonen T., 1984, SELF ORG ASS MEMORY; Kohonen T., 1996, SOM PAK SELF ORG MAP; LAGRANGE JP, 1993, DT930538 I GEOGR NAT; MCMASTER RB, 1991, GIS LIS C ATL GA; McMaster R.B., 1992, GEN DIGITAL CARTOGRA; POHL I, 1969, BIDIRECTIONAL HEURES, P111; RIDDE D, 1996, SHARED WEIGHTS NEURA; Ripley BD, 1996, PATTERN RECOGNITION; Ross IC, 1955, MANAGE SCI, V1, P251, DOI 10.1287/mnsc.1.3-4.251; RUAS A, 1999, MODELE GEN DONNEES G; Rumelhart D.E., 1986, EXPLORATIONS MICROST, V1, P318; Sadahiro Y., 1997, CARTOGRAPHICA, V34, P49, DOI 10.3138/Y308-2422-8615-1233; SAVAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660; Sester M., 2000, INT ARCH PHOTOGRA B4, V33, P931; SESTER M, 2000, GISCIENCE 2000; SHLEGEL A, 1995, 17 INT CART C BARC E, P2211; Weibel R., 1998, 8 INT S SPAT DAT HAN, P214; WEIBEL R, 1995, 2 INT C SPAT INF THE, P141; Weibel R., 1991, MAP GEN MAKING RULES, P172; WEIBEL R, 1998, GEN SPATIAL DATA DEA; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	40	6	10	2	8	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816			INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	SEP-OCT	2005	19	8-9					899	914		10.1080/13658810500161211		16	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	975KM	WOS:000232661400003		
J	De Mantaras, RL; Mcsherry, D; Bridge, D; Leake, D; Smyth, B; Craw, S; Faltings, B; Maher, ML; Cox, MT; Forbus, K; Keane, M; Aamodt, A; Watson, I				De Mantaras, RL; Mcsherry, D; Bridge, D; Leake, D; Smyth, B; Craw, S; Faltings, B; Maher, ML; Cox, MT; Forbus, K; Keane, M; Aamodt, A; Watson, I			Retrieval, reuse, revision and retention in case-based reasoning	KNOWLEDGE ENGINEERING REVIEW			English	Review							NEAREST-NEIGHBOR RULE; RECOMMENDER SYSTEMS; SPECIAL-ISSUE; MAINTENANCE; EXPLANATION; SIMILARITY; KNOWLEDGE; ANALOGY; CLASSIFICATION; STRATEGIES	Case-based reasoning (CBR) is an approach to problem solving that emphasizes the role of prior experience during future problem solving (i.e., new problems are solved by reusing and if necessary adapting the solutions to similar problems that were solved in the past). It has enjoyed considerable success in a wide variety of problem solving tasks and domains. Following a brief overview of the traditional problem-solving cycle in CBR, we examine the cognitive science foundations of CBR and its relationship to analogical reasoning. We then review a representative selection of CBR research in the past few decades on aspects of retrieval, reuse, revision and retention.	CSIC, Artificial Intelligence Res Inst, Bellaterra 08193, Spain; Univ Ulster, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland; Natl Univ Ireland Univ Coll Cork, Dept Comp Sci, Cork, Ireland; Indiana Univ, Dept Comp Sci, Bloomington, IN 47405 USA; Natl Univ Ireland Univ Coll Dublin, Sch Comp & Informat Sci, Dublin 4, Ireland; Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland; Swiss Fed Inst Technol, AI Lab, CH-1015 Lausanne, Switzerland; Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia; BBN Technol, Cambridge, MA 02138 USA; Northwestern Univ, Dept EECS, Evanston, IL 60208 USA; Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7034 Trondheim, Norway; Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand	De Mantaras, RL (reprint author), CSIC, Artificial Intelligence Res Inst, Campus UAB, Bellaterra 08193, Spain.	mantaras@iiia.csic.es; dmg.mcsherry@ulster.ac.uk; d.bridge@cs.ucc.ie; leake@cs.indiana.edu; Barry.Smyth@ucd.ie; S.Craw@comp.rgu.ac.uk; Boi.Faltings@epfl.ch; marym@it.usyd.edu.au; mcox@bbn.com; forbus@northwestern.edu; mark.keane@ucd.ie; agnar.aamodt@idi.ntnu.no; ian@cs.auckland.ac.nz	Forbus, Kenneth/B-7146-2009; 	Craw, Susan/0000-0003-1870-0323			Aamodt A., 2004, P 7 EUR C CAS BAS RE, P1; Aamodt A., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; Aha D., 2000, APPL INTELL, V14, P9; Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aleven V, 2003, ARTIF INTELL, V150, P183, DOI 10.1016/S0004-3702(03)00105-X; AAMODT A, 1994, AI COMMUN, V7, P39; ARCOS JL, 1997, P INT C CAS BAS REAS, P279; ARCOS JL, 1997, CSIC MONOGRAPHIES A, V3; Arcos JL, 2001, APPL INTELL, V14, P115, DOI 10.1023/A:1008311209823; ASHLEY KD, 1991, INT J MAN MACH STUD, V34, P753, DOI 10.1016/0020-7373(91)90011-U; ASHLEY KD, 1997, P IJCAI 97 NAG JAP, P335; ASHLEY KD, 1989, P 11 INT JOINT C ART, P537; ASHLEY KD, 1992, P 10 NAT C ART INT A, P654; Bergmann R., 2002, EXPERIENCE MANAGEMEN; BERGMANN R, 1998, P 4 EUR WORKSH CAS B, P25; BERGMANN R, 1999, P 7 GERM WORKSH CAS; BERGMANN R, 2001, P 9 GERM WORKSH CAS; BOGAERTS S, 2004, P 7 EUR C CAS BAS RE, P62; BONZANO A, 1997, P 2 INT C CAS BAS RE, P291; Borner K., 1993, P 1 EUR WORKSH CAS B, P197; BRANTING LK, 1991, INT J MAN MACH STUD, V34, P797, DOI 10.1016/0020-7373(91)90012-V; BRIDGE D, 2002, P 6 EUR C CAS BAS RE, P43; Bridge D, 2002, ARTIF INTELL REV, V18, P269, DOI 10.1023/A:1020743321429; Brown M. G., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; Bunke Horst, 1993, P 1 EUR WORKSH CAS B, P106; Carbonell J., 1986, MACHINE LEARNING ART, VII, P371; Champin P., 2003, P 5 INT C CAS BAS RE, P80; Cohen P. R., 1985, HEURISTIC REASONING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox MT, 1999, ARTIF INTELL, V112, P1, DOI 10.1016/S0004-3702(99)00047-8; Craw S, 2001, COMPUT INTELL, V17, P346, DOI 10.1111/0824-7935.00149; CUNNINGHAM P, 2003, P 5 INT C CAS BAS RE, P122; de Mantaras RL, 2002, AI MAG, V23, P43; DOMESHEK E, 1992, THESIS NW U EVANSTON; Doyle D., 2004, P 7 EUR C CAS BAS RE, P157; Emde W., 1996, P 13 INT C MACH LEAR, P122; Falkenhainer B., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Faltings B, 1996, COMPUT AIDED DESIGN, V28, P207, DOI 10.1016/0010-4485(95)00027-5; FALTINGS B, 1997, P ICCBR 97, P611; FALTINGS B, 1997, ISSUES APPL CASE BAS, P39; Ferrario MA, 2001, COMPUT INTELL, V17, P315, DOI 10.1111/0824-7935.00147; Forbus K. D., 2003, Proceedings of the Fifteenth Innovative Applications of Artificial Intelligence Conference; Forbus KD, 2001, ANALOGICAL MIND, P23; FORBUS KD, 1995, COGNITIVE SCI, V19, P141, DOI 10.1207/s15516709cog1902_1; FORBUS KD, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P313; Fox S, 2001, J EXP THEOR ARTIF IN, V13, P63, DOI 10.1080/09528130010029794; Fox S, 1995, P 14 INT JOINT C ART, P391; FRANCIS AG, 1995, P 8 EUR C MACH LEARN, P138; FUCHS B, 1999, P 3 INT C CAS BAS RE, P118; GABEL T, 2004, P 7 EUR C CAS BAS RE, P169; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GENTNER D, 1993, COGNITIVE PSYCHOL, V25, P524, DOI 10.1006/cogp.1993.1013; GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1207/s15516709cog0702_3; GENTNER D, 1991, PROGRAM OF THE THIRTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P504; Gentner D., 2001, ANALOGICAL MIND PERS; GICK ML, 1980, COGNITIVE PSYCHOL, V12, P306, DOI 10.1016/0010-0285(80)90013-4; GOEL A, 1991, P DARPA CAS BAS REAS, P109; GOEL AK, 1989, P DARPA WORKSH CAS B, P100; Gomez de Silva Garza A., 2000, P ART INT DES C, P393; HAMMOND KJ, 1990, ARTIF INTELL, V45, P173, DOI 10.1016/0004-3702(90)90040-7; Hammond K. J., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Hanney K., 1997, P 2 INT C CAS BAS RE, P359; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hummel JE, 1997, PSYCHOL REV, V104, P427, DOI 10.1037//0033-295X.104.3.427; IGLEZAKIS I, 2004, P 7 EUR C CAS BAS RE, P227; JANTKE KP, 1994, P JAHRESTAGUNG GES K, P29; Jarmulak J., 2001, P 17 INT JOINT C ART, P1011; KASS A, 1986, EXPLANATION PATTERNS, P232; KASS A, 1989, P CAS BAS REAS WORKS, P119; Keane M. T., 1994, COGNITIVE SCI, V18, P287; KEANE MT, 1988, P 3 EUR WORK SESS LE; KOKINOV B, 2003, ENCY COGNITIVE SCI, P113; Kolodner J., 1996, CASE BASED REASONING, P349; Kolodner J. L., 1993, CASE BASED REASONING; KOLODNER JL, 1994, BELIEFS REASONING DE; Kolodner JL, 2003, J LEARN SCI, V12, P495, DOI 10.1207/S15327809JLS1204_2; Koton P, 1988, P AAAI 88, P256; Larkey LB, 2003, COGNITIVE SCI, V27, P781, DOI 10.1016/S0364-0213(03)00066-1; Leake D, 2005, ARTIF INTELL REV, V24, P103, DOI 10.1007/s10462-005-4606-8; Leake D., 1996, CASE BASED REASONING, P3; LEAKE D, 2000, P 5 EUR WORKSH CAS B, P161; Leake D. B., 1996, CASE BASED REASONING; Leake D. B., 1995, P 1 INT C CAS BAS RE, P229; Leake D.B, 1992, EVALUATING EXPLANATI; Leake D.B., 1997, P 14 NAT C ART INT, P674; Leake DB, 1998, COMPANION COGNITIVE, P465; LEAKE DB, 1991, COGNITIVE SCI, V15, P509, DOI 10.1207/s15516709cog1504_2; Leake DB, 2001, COMPUT INTELL, V17, P193, DOI 10.1111/0824-7935.00139; LEAKE DB, 1999, P 3 INT C CAS BAS RE, P218; Leake D. B., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, DOI 10.1142/S0218213004001508; LEI C, 1999, P 3 INT C CAS BAS RE, P233; LENZ M, 1996, P 3 EUR WORKSH CAS B, P219; Lenz M., 1998, CASE BASED REASONING; Markman AB, 2001, ANNU REV PSYCHOL, V52, P223, DOI 10.1146/annurev.psych.52.1.223; MARKOVITCH S, 1993, MACH LEARN, V10, P113, DOI 10.1007/BF00993503; Mcginty L., 2003, P 5 INT C CAS BAS RE, P276; Mckenna E., 1999, P 3 INT C CAS BAS RE, P343; McKenna E., 2001, P 21 BCS SGES INT C, P97; McKenna E., 2000, P 14 EUR C ART INT, P60; MCKENNA E, 2000, P 5 EUR WORKSH CAS B, P186; MCSHERRY D, 2004, P 7 EUR C CAS BAS RE, P331; McSherry D, 2001, APPL INTELL, V14, P65, DOI 10.1023/A:1008355024844; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; McSherry D., 2003, P 18 INT JOINT C ART, P121; McSherry D., 2001, P 17 INT JOINT C ART; McSherry D, 2001, COMPUT INTELL, V17, P331, DOI 10.1111/0824-7935.00148; MCSHERRY D, 1999, P 16 INT JOINT C ART, P222; McSherry D., 2002, P 6 EUR C CAS BAS RE, P219; MCSHERRY D, 1998, P 4 EUR WORKSH CAS B, P184; MCSHERRY D, 2000, KNOWL-BASED SYST, V13, P65; Mcsherry D., 2003, P 5 INT C CAS BAS RE, P291; McSherry D, 2004, KNOWL-BASED SYST, V17, P113, DOI 10.1016/j.knosys.2004.03.006; MCSHERRY D, 2001, P 4 INT C CAS BAS RE, P392; MCSHERRY D, 2004, P 7 EUR C CAS BAS RE, P317; MINTON S, 1990, ARTIF INTELL, V42, P363, DOI 10.1016/0004-3702(90)90059-9; Mougouie B., 2002, P 6 EUR C CAS BAS RE, P249; MUNOZAVILA H, 1996, P 3 EUR WORKSH CAS B, P280; Munoz-Avila H, 2001, COMPUT INTELL, V17, P280, DOI 10.1111/0824-7935.00145; Nick M, 2001, COMPUT INTELL-US, V17, P364, DOI 10.1111/0824-7935.00150; ONTANON S, 2003, P 5 INT C CAS BAS RE, P392; OSBORNE HR, 1996, P 3 EUR WORKSH CAS B, P309; OSBORNE HR, 1997, P 2 INT C CAS BAS RE, P235; PATEL VL, 1986, COGNITIVE SCI, V10, P91, DOI 10.1207/s15516709cog1001_4; Plaza E., 1995, P 1 INT C CAS BAS RE, P265; PORTER BW, 1990, ARTIF INTELL, V45, P229, DOI 10.1016/0004-3702(90)90041-W; Portinale L, 2001, COMPUT INTELL, V17, P263, DOI 10.1111/0824-7935.00144; PURVIS L, 1995, P 1 INT C CAS BAS RE, P289; RACINE K, 1997, P 2 INT C CAS BAS RE, P553; Ramscar M, 2003, COGNITIVE SCI, V27, P41, DOI 10.1016/S0364-0213(02)00113-1; Reinartz T, 2001, COMPUT INTELL-US, V17, P214, DOI 10.1111/0824-7935.00141; RICHARDSON MJ, 1992, PRACTICAL PLACER MINING, P1; Riesbeck C. K., 1989, INSIDE CASE BASED RE; Rissland E. L., 1984, P 4 NAT C ART INT, P288; RISSLAND EL, 1991, INT J MAN MACH STUD, V34, P839, DOI 10.1016/0020-7373(91)90013-W; Salamo MGolobardesE, 2002, P 6 EUR C CAS BAS RE, P365; SCHAAF JW, 1996, P 3 EUR WORKSH CAS B, P362; Schank R., 1990, 1 NW U I LEARN SCI; Schank R., 1977, SCRIPTS PLANS GOALS; Schank R., 1982, DYNAMIC MEMORY THEOR; Schank R. C., 1994, INSIDE CASE BASED EX; Schank R. C., 1994, J LEARN SCI, V3, P305; Schank R. G., 1986, EXPLANATION PATTERNS; SCHANK RC, 1989, ARTIF INTELL, V40, P353, DOI 10.1016/0004-3702(89)90053-2; SHIMAZU H, 1996, P 13 NAT C ART INT, V1, P690; SHIU SCK, 2001, COMPUT INTELL, V17, P214; SIMOUDIS E, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P310; Smyth B, 1998, P 11 INT C IND ENG A, P507; Smyth B., 1995, P 14 INT JOINT C ART, P377; Smyth B., 1996, P392; Smyth B., 2001, P 4 INT C CAS BAS RE, P347; Smyth B, 1998, ARTIF INTELL, V102, P249, DOI 10.1016/S0004-3702(98)00059-9; SMYTH B, 1998, P 4 EUR WORKSH CAS B, P208; Smyth B, 2001, COMPUT INTELL-US, V17, P235, DOI 10.1111/0824-7935.00142; Smyth B, 2001, KNOWL-BASED SYST, V14, P155, DOI 10.1016/S0950-7051(01)00092-2; Smyth B., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; SMYTH B, 2000, P 11 EUR C MACH LEAR, P357; SMYTH B, 1995, P 1 INT C CAS BAS RE, P313; Smyth B, 1996, KNOWL-BASED SYST, V9, P127, DOI 10.1016/0950-7051(95)01024-6; SORMO F, 2005, ARTIF INTELL, V24, P103; Sormo F., 2004, P ECCBR 2004 WORKSH, P165; Stahl A., 2003, P 5 INT C CAS BAS RE, P537; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; SURMA J, 1998, P 4 EUR WORKSH CAS B, P233; TARTAKOVSKI A, 2004, P 7 EUR C CAS BAS RE, P404; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Tomek I., 1976, IEEE T SYST MAN CYB, V7, P679; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/0033-295X.84.4.327; VELOSO M, 1994, MACH LEARN, V4, P523; VELOSO M, 1994, PLANNING LEARNING AN; Watson I., 1997, APPL CASE BASED REAS; Wess S., 1993, P 1 EUR WORKSH CAS B, P167; Wettschereck D., 1995, P 1 INT C CAS BAS RE, P347; Wilke W., 1997, P 5 GERM WORKSH CAS, P235; WILKE W, 1996, P 3 EUR WORKSH CAS B, P460; Wilson DC, 2001, COMPUT INTELL-US, V17, P196, DOI 10.1111/0824-7935.00140; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson D.R., 1997, P 14 INT C MACH LEAR, P403; WIRATUNGA N, 2002, P 6 EUR C CAS BAS RE, P423; WIRATUNGA N, 2003, P 5 INT C CAS BAS RE, P637; WOLVERTON M, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P56; WOON F, 2003, P 5 INT C CAS BAS RE, P652; Yang Q, 2001, COMPUT INTELL, V17, P250, DOI 10.1111/0824-7935.00143; Zhu J, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P234	184	65	65	1	16	CAMBRIDGE UNIV PRESS	NEW YORK	40 WEST 20TH ST, NEW YORK, NY 10011-4211 USA	0269-8889			KNOWL ENG REV	Knowl. Eng. Rev.	SEP	2005	20	3					215	240		10.1017/S0269888906000646		26	Computer Science, Artificial Intelligence	Computer Science	049PF	WOS:000238027800004		
J	Bencic-Nagale, S; Walt, DR				Bencic-Nagale, S; Walt, DR			Extending the longevity of fluorescence-based sensor arrays using adaptive exposure	ANALYTICAL CHEMISTRY			English	Article							ARTIFICIAL NOSE; ANTIFADING AGENTS; PH SENSOR; DISCRIMINATION; RECOGNITION; DESIGN; SYSTEM; DEVICE; FILMS	Fluorescent microbead sensor arrays were prepared to determine sensor array longevity. Sensor longevity is limited by photobleaching of the dyes attached to the microbeads and presents one of the biggest drawbacks of most fluorescent dye-based arrays. Responses of an array of organic vapor sensors were acquired for 2 weeks to evaluate the sensor performance over time. Photobleaching effects were overcome in two ways: (1) by limiting the excitation light power and gradually increasing the power at a rate comparable to the sensor photobleaching rates and (2) by illuminating subsections of the array through an optical slit. Both approaches extended the longevity of a sensor array. During the longevity study, the sensor arrays were employed to test their ability to correctly distinguish between responses to seven vapors. A high classification accuracy (99.8%) was obtained after 17 700 exposures for vapor responses collected over two weeks using only similar to 8% of the array's surface area.	Tufts Univ, Dept Chem, Medford, MA 02155 USA	Walt, DR (reprint author), Tufts Univ, Dept Chem, Medford, MA 02155 USA.	david.walt@tufts.edu					AGAYN V, 1993, IMMUNOMETHODS, V3, P112, DOI 10.1006/immu.1993.1045; Albert KJ, 2001, ENVIRON SCI TECHNOL, V35, P3193, DOI 10.1021/es010829t; Albert KJ, 2000, ANAL CHEM, V72, P1947, DOI 10.1021/ac991397w; Albert KJ, 2003, ANAL CHEM, V75, P4161, DOI 10.1021/ac0264776; Albert KJ, 2000, CHEM REV, V100, P2595, DOI 10.1021/cr980102w; Albert KJ, 2001, ANAL CHEM, V73, P2501, DOI 10.1021/ac001137a; BARNARD SM, 1991, SCIENCE, V251, P927, DOI 10.1126/science.2000492; Bencic S, 2004, P SOC PHOTO-OPT INS, V5269, P83, DOI 10.1117/12.516085; Berrios M, 1999, METHOD ENZYMOL, V307, P55; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dickinson TA, 1999, ANAL CHEM, V71, P2192, DOI 10.1021/ac981457i; FREUND MS, 1995, P NATL ACAD SCI USA, V92, P2652, DOI 10.1073/pnas.92.7.2652; GARDNER JW, 1999, ELECT NOTES PRINCIPL; Grate JW, 2000, CHEM REV, V100, P2627, DOI 10.1021/cr980094j; Hartmann P, 2000, ANAL CHEM, V72, P2828, DOI 10.1021/ac9914723; Kermis HR, 2002, BIOTECHNOL PROGR, V18, P1047, DOI 10.1021/bp0255560; KRENIK KD, 1989, J IMMUNOL METHODS, V117, P91, DOI 10.1016/0022-1759(89)90122-1; Lonergan MC, 1996, CHEM MATER, V8, P2298, DOI 10.1021/cm960036j; Otto M., 1999, CHEMOMETRICS STAT CO; Shortreed M, 1996, ANAL CHEM, V68, P4015, DOI 10.1021/ac9605253; Song A, 1997, ANAL CHEM, V69, P863, DOI 10.1021/ac960917+; Sotzing GA, 2000, ANAL CHEM, V72, P3181, DOI 10.1021/ac991079x; Stitzel SE, 2003, J AM CHEM SOC, V125, P3684, DOI 10.1021/ja028239y; Stitzel SE, 2001, ANAL CHEM, V73, P5266, DOI 10.1021/ac010111w; Stitzel SE, 2002, P SOC PHOTO-OPT INS, V4575, P132, DOI 10.1117/12.456916; Tabacco MB, 1999, ANAL CHEM, V71, P154, DOI 10.1021/ac980513c; TAKAYAMA R, 1990, SENSOR ACTUAT A-PHYS, V22, P508; Udrea F, 1996, MICROELECTR J, V27, P449, DOI 10.1016/0026-2692(95)00112-3; White J, 1998, BIOL CYBERN, V78, P245, DOI 10.1007/s004220050430; White J, 1996, ANAL CHEM, V68, P2191, DOI 10.1021/ac9511197; Witten I. H., 2000, DATA MINING; Xu Z, 1998, J BIOMED MATER RES, V39, P9, DOI 10.1002/(SICI)1097-4636(199801)39:1<9::AID-JBM2>3.0.CO;2-U; Yang JS, 1998, J AM CHEM SOC, V120, P5321, DOI 10.1021/ja9742996	33	29	30	1	5	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700			ANAL CHEM	Anal. Chem.	OCT 1	2005	77	19					6155	6162		10.1021/ac0505021		8	Chemistry, Analytical	Chemistry	972HA	WOS:000232443700019	16194073	
J	Gao, QB; Wang, ZZ				Gao, QB; Wang, ZZ			Using nearest feature line and tunable nearest neighbor methods for prediction of protein subcellular locations	COMPUTATIONAL BIOLOGY AND CHEMISTRY			English	Article						nearest feature line; tunable nearest neighbor; subcellular location; amino acid composition; pattern classification; jackknife test	AMINO-ACID-COMPOSITION; SIGNAL PEPTIDES; TRANSMEMBRANE PROTEINS; PATTERN-CLASSIFICATION; LOCALIZATION SITES; SORTING SIGNALS; SEQUENCE; IDENTIFICATION	The subcellular location of a protein is closely correlated with it biological function. In this paper, two new pattern classification methods termed as Nearest Feature Line (NFL) and Tunable Nearest Neighbor (TNN) have been introduced to predict the subcellular location of proteins based on their amino acid composition alone. The simulation experiments were performed with the jackknife test on a previously constructed data set, which consists of 2427 eukaryotic and 997 prokaryotic proteins. All protein sequences in the data set fall into four eukaryotic subcellular locations and three prokaryotic subcellular locations. The NFL classifier reached the total prediction accuracies of 82.5% for the eukaryotic proteins and 91.0% for the prokaryotic proteins. The TNN classifier reached the total prediction accuracies of 83.6 and 92.2%, respectively. It is clear that high prediction accuracies have been achieved. Compared with Support Vector Machine (SVM) and Nearest Neighbor methods, these two methods display similar or even higher prediction accuracies. Hence, we conclude that NFL and TNN can be used as complementary methods for prediction of protein subcellular locations. (c) 2005 Elsevier Ltd. All rights reserved.	Natl Univ Def Technol, Inst Automat, Changsha 410073, Hunan, Peoples R China	Gao, QB (reprint author), Natl Univ Def Technol, Inst Automat, Changsha 410073, Hunan, Peoples R China.	gqb_kd@yahoo.com.cn	Gao, Qing-Bin/G-9825-2011				Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, P414; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Fujiwara Y, 2001, Genome Inform, V12, P103; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Graves PR, 2002, MICROBIOL MOL BIOL R, V66, P39, DOI 10.1128/MMBR.66.1.39-63.2002; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Lio P, 2000, BIOINFORMATICS, V16, P376, DOI 10.1093/bioinformatics/16.4.376; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; Nielsen H, 1999, PROTEIN ENG, V12, P3, DOI 10.1093/protein/12.1.3; Nielsen H., 1998, Proceedings Sixth International Conference on Intelligent Systems for Molecular Biology; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Rost B, 1996, PROTEIN SCI, V5, P1704; Vapnik V., 1998, STAT LEARNING THEORY; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; Zhou YL, 2004, LECT NOTES COMPUT SC, V3175, P204	34	15	16	0	2	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1476-9271			COMPUT BIOL CHEM	Comput. Biol. Chem.	OCT	2005	29	5					388	392		10.1016/j.compbiolchem.2005.08.002		5	Biology; Computer Science, Interdisciplinary Applications	Life Sciences & Biomedicine - Other Topics; Computer Science	987TK	WOS:000233540000009	16213794	
J	Yin, TK				Yin, TK			A characteristic-point-based fuzzy inference classifier by a closeness matrix	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						Bayes error; characteristic point; classifier; closeness matrix; fuzzy inference system	LA-TOURETTES SYNDROME; C-MEANS ALGORITHM; NEURAL NETWORKS; DIAGNOSIS; LOGIC; TECHNETIUM-99M-HMPAO; SEGMENTATION; COMPLEXITY; CHILDHOOD; PERFUSION	In this paper, a characteristic-point-based fuzzy inference classifier (CPFIC) is proposed to perform two-class classification. Through fuzzy interpolation, a subset of classified samples can be taken as representatives of all samples. They are called characteristic points (CPs). A closeness matrix representing the closeness of two samples in a same class is proposed in selecting CPs. By solving a number of constrained minimizations, the CPFIC is systematically built. Experiments were conducted on four classification problems with known Bayes errors, two benchmark classification problems, and a real-world application used in our research. The CPFIC performs well in accuracy evaluations in all the seven experiments. The summarizing abilities from the CPs into the linguistic descriptions of the fuzzy rule bases were also demonstrated in these examples.	Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan	Yin, TK (reprint author), Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.	tkyin@nuk.edu.tw					Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338; Auephanwiriyakul S, 2002, IEEE T FUZZY SYST, V10, P563, DOI 10.1109/TFUZZ.2002.803492; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; Blake C, 1998, UCI REPOSITORY MACHI; Chen JL, 2000, IEEE T FUZZY SYST, V8, P730; Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; Chuang KH, 1999, IEEE T MED IMAGING, V18, P1117; CLEMENTZ GL, 1988, AM FAM PHYSICIAN, V38, P163; Cormen T. H., 1992, INTRO ALGORITHMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; Dave RN, 2002, IEEE T FUZZY SYST, V10, P713, DOI 10.1109/TFUZZ.2002.805899; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902; FUKUDA K, 1989, TRENDS PHARM SCI S, V11, P4; Fukunaga K., 1990, STAT PATTERN RECOGNI; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Gordon I, 1996, NUCL MED COMMUN, V17, P1021, DOI 10.1097/00006231-199612000-00004; Hathaway RJ, 2001, IEEE T SYST MAN CY B, V31, P735, DOI 10.1109/3477.956035; Haykin S., 1994, NEURAL NETWORKS COMP; Karayiannis NB, 1997, IEEE T FUZZY SYST, V5, P622, DOI 10.1109/91.649915; Kaymak U, 2002, IEEE T FUZZY SYST, V10, P705, DOI 10.1109/TFUZZ.2002.805901; Klieger PS, 1997, J NUCL MED, V38, P188; Kolen JF, 2002, IEEE T FUZZY SYST, V10, P263, DOI 10.1109/91.995126; Kuncheva LI, 2003, IEEE T FUZZY SYST, V11, P729, DOI 10.1109/TFUZZ.2003.819842; LACEY DJ, 1986, CLIN PEDIATR, V25, P433, DOI 10.1177/000992288602500901; Lampreave JL, 1998, J NUCL MED, V39, P624; Lee EW, 1998, IEEE T PATTERN ANAL, V20, P562; Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536; LEUNBERGER DG, 1989, LINEAR NONLINEAR PRO; LIN CT, 1991, IEEE T COMPUT, V40, P1320, DOI 10.1109/12.106218; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; MORIARTY J, 1995, BRIT J PSYCHIAT, V167, P249, DOI 10.1192/bjp.167.2.249; Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752; Sato K, 1996, IEEE T NUCL SCI, V43, P3230, DOI 10.1109/23.552723; SIEG KG, 1993, CLIN NUCL MED, V18, P255, DOI 10.1097/00003072-199303000-00022; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; STONE M, 1974, J R STAT SOC B, V36, P111; Theodoridis S., 1999, PATTERN RECOGNITION; Tolias YA, 1998, IEEE T MED IMAGING, V17, P263, DOI 10.1109/42.700738; Verma B, 2001, IEEE T INF TECHNOL B, V5, P46, DOI 10.1109/4233.908389; Wang JS, 2002, IEEE T FUZZY SYST, V10, P790, DOI 10.1109/TFUZZ.2002.805880; Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29; Young Tzay Y., 1986, HDB PATTERN RECOGNIT; ZADEH LA, 1994, IEEE SOFTWARE, V11, P48, DOI 10.1109/52.329401; 2001, SPM99	46	2	2	1	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1063-6706			IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	OCT	2005	13	5					673	687		10.1109/TFUZZ.2005.856558		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	974PT	WOS:000232604600009		
J	Ghosh, AK; Chaudhuri, P; Murthy, CA				Ghosh, AK; Chaudhuri, P; Murthy, CA			On visualization and aggregation of nearest neighbor classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian strength function; misclassification rates; multiscale visualization; neighborhood parameter; posterior probability; prior distribution; weighted averaging	CLASSIFICATION	Nearest neighbor classification is one of the simplest and most popular methods for statistical pattern recognition. A major issue in k-nearest neighbor classification is how to find an optimal value of the neighborhood parameter k. In practice, this value is generally estimated by the method of cross-validation. However, the ideal value of k in a classification problem not only depends on the entire data set, but also on the specific observation to be classified. Instead of using any single value of k, this paper studies results for a finite sequence of classifiers indexed by k. Along with the usual posterior probability estimates, a new measure, called the Bayesian measure of strength, is proposed and investigated in this paper as a measure of evidence for different classes. The results of these classifiers and their corresponding estimated misclassification probabilities are visually displayed using shaded strips. These plots provide an effective visualization of the evidence in favor of different classes when a given data point is to be classified. We also propose a simple weighted averaging technique that aggregates the results of different nearest neighbor classifiers to arrive at the final decision. Based on the analysis of several benchmark data sets, the proposed method is found to be better than using a single value of k.	Indian Stat Inst, Theoret Studies & Math Unit, Kolkata 700108, W Bengal, India; Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, W Bengal, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Studies & Math Unit, 203 BT Rd, Kolkata 700108, W Bengal, India.	anilkghosh@rediffmail.com; probal@isical.ac.in; murthy@isical.ac.in					Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Breiman L, 1998, ANN STAT, V26, P801; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FRIEDMAN JH, 1996, FLEXIBLE METRIC NEAR; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Fukunaga K., 1990, INTRO STAT PATTERN R; GHOSH AK, 2003, P 5 INT C ADV PATT R, P89; GHOSH AK, TECHNOMETRICS; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Hodges J., 1951, 4 USAF SCH AV MED, P261; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Hopcroft J. E., 1974, DESIGN ANAL COMPUTER, V1st; Johnson R., 1992, APPL MULTIVARIATE ST, V3th; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; PAIK M, 2004, STAT APPL GENETICS M, V3; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Ripley BD, 1996, PATTERN RECOGNITION; Schapire RE, 1998, ANN STAT, V26, P1651; SHALAK DB, 1996, THESIS U MASSACHUSET; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9	40	19	21	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1592	1602		10.1109/TPAMI.2005.204		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	953OM	WOS:000231086700007	16237994	
J	Li, F; Wechsler, H				Li, F; Wechsler, H			Open set face recognition using transduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; confidence; credibility; data fusion; information quality; Kolmogorov complexity; face recognition; open set recognition; performance evaluation; PSEI (pattern specific error inhomogeneities); randomness deficiency; strangeness; face surveillance; (multiclass) transduction; watch list; clustering; outlier detection	CLASSIFICATION	This paper motivates and describes a novel realization of transductive inference that can address the Open Set face recognition task. Open Set operates under the assumption that not all the test probes have mates in the gallery. It either detects the presence of some biometric signature within the gallery and finds its identity or rejects it, i.e., it provides for the "none of the above" answer. The main contribution of the paper is Open Set TCM-kNN (Transduction Confidence Machine-k Nearest Neighbors), which is suitable for multiclass authentication operational scenarios that have to include a rejection option for classes never enrolled in the gallery. Open Set TCM-kNN, driven by the relation between transduction and Kolmogorov complexity, provides a local estimation of the likelihood ratio needed for detection tasks. We provide extensive experimental data to show the feasibility, robustness, and comparative advantages of Open Set TCM-kNN on Open Set identification and watch list (surveillance) tasks using challenging FERET data. Last, we analyze the error structure driven by the fact that most of the errors in identification are due to a relatively small number of face patterns. Open Set TCM-kNN is shown to be suitable for PSEI (pattern specific error inhomogeneities) error analysis in order to identify difficult to recognize faces. PSEI analysis improves biometric performance by removing a small number of those difficult to recognize faces responsible for much of the original error in performance and/ or by using data fusion.	George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Li, F (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	fli@cs.gmu.edu; wechsler@cs.gmu.edu					Bailliere E. B., 2003, P AUD VID BAS BIOM P, P625; BENGIO S, 2001, 0121 IDIAPRR EUR PRO; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Bolle R.M., 2004, GUIDE BIOMETRICS; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Conover WJ, 1980, PRACTICAL NONPARAMET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daugman J, 1997, IEEE T PATTERN ANAL, V19, P675, DOI 10.1109/34.598225; Doddington G., 1998, P ICSLD98 NOV, P1351; Furui S, 1997, PATTERN RECOGN LETT, V18, P859, DOI 10.1016/S0167-8655(97)00073-1; Gammerman A., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998); GROTHER P, 2004, 7083 NISTIR; Jain A. K., 1999, BIOMETRICS PERSONAL; Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102; Joachims T., 1999, P 16 INT C MACH LEAR, V99, P200; JUSZCZAK P, 2004, P 17 INT C PATT REC; Krogel MA, 2004, MACH LEARN, V57, P61, DOI 10.1023/B:MACH.0000035472.73496.0c; KUKAR M, 2002, P 13 EUR C MACH LEAR; Li M., 1997, INTRO KOLMOGOROV COM; LIU C, 2004, BIOMETRIC AUTHENTICA; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Mak MW, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P107, DOI 10.1109/ISIMP.2001.925343; Melluish T., 2001, TYPICALNESS FRAMEWOR; Mitchell T. M., 1999, P 6 INT C COGN SCI; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; PANKANTI S, 2002, P 16 INT C PATT REC; Phillips P.J., 2003, FACE RECOGNITION VEN; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; PROEDROU K, 2001, CLRCTR0102 U LOND RO; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; ROSS A, 2004, PATTERN RECOGN, V24, P2115; Saunders C., 1999, P 16 INT JOINT C ART; SNELICK R, 2003, P 5 INT C MULT INT; Tong S, 2000, J MACHINE LEARNING R, V2, P45, DOI DOI 10.1162/153244302760185243; Vapnik V, 2000, NATURE STAT LEARNING; Vapnik V., 1998, STAT LEARNING THEORY; VOVK V, 1999, P 16 INT C MACH LEAR; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	38	43	45	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1686	1697				12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	963SN	WOS:000231826300001	16285369	
J	Xiao, YD; Clauset, A; Harris, R; Bayram, E; Santago, P; Schmitt, JD				Xiao, YD; Clauset, A; Harris, R; Bayram, E; Santago, P; Schmitt, JD			Supervised self-organizing maps in drug discovery. 1. Robust behavior with overdetermined data sets	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							NEURAL-NETWORK; QSAR	The utility of the supervised Kohonen self-organizing map was assessed and compared to several statistical methods used in QSAR analysis. The self-organizing map (SOM) describes a family otnonlinear, topology preserving mapping methods with attributes of both vector quantization and clustering that provides Visualization options unavailable with other nonlinear methods. In contrast to most chemometric methods, the supervised SOM (sSOM) is shown to be relatively insensitive to noise and feature redundancy. Additionally, sSOMs can make use of descriptors having only nominal linear correlation with the tar et property. Results herein are contrasted to partial least squares, stepwise Multiple linear regression, the genetic functional algorithm, and genetic partial least Squares, collectively referred to throughout as the "standard methods". The k-nearest neighbor (kNN) classification method was also performed to provide a direct comparison with a different classification method. The widely studied dihydrofolate reductase (DHFR) inhibition data set of Hansch and Silipo is Used to evaluate the ability of sSOMs to classify unknowns as a function of increasing class resolution. The contribution of the sSOM neighborhood kernel to its predictive ability is assessed in two experiments: ( 1) training with the k-rneans Clustering limit, where the neighborhood radius is zero throughout the training regimen, and (2) training the sSOM until the neighborhood radius is reduced to zero. Results demonstrate that sSOMs provide more accurate predictions than standard linear QSAR methods.	Targacept Inc, Mol Design Grp, Winston Salem, NC 27101 USA; Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA; Wake Forest Univ, Sch Biomed Engn & Sci, Virginia Tech, Winston Salem, NC 27157 USA	Schmitt, JD (reprint author), Targacept Inc, Mol Design Grp, 200 E 1st St,Suite 300, Winston Salem, NC 27101 USA.	jeff.schmitt@targacept.com					*ACC INC, 2003, CER 2 MOD ENV REL 4; Anderberg M. R., 1973, CLUSTER ANAL APPL; ANZALI S, 1998, USE SELF ORGANIZING, P273; Espinosa G, 2002, J CHEM INF COMP SCI, V42, P343, DOI 10.1021/ci010329j; BAYRAM E, 2004, J COMPUT AID MOL DES, P483; Bellman R., 1961, ADAPTIVE CONTROL PRO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Draper N R, 1966, APPL REGRESSION ANAL, P407; GASTEIGER J, 1993, ANGEW CHEM INT EDIT, V32, P503, DOI 10.1002/anie.199305031; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; HANSCH C, 1969, ACCOUNTS CHEM RES, V2, P232, DOI 10.1021/ar50020a002; Kaski S., 1997, ACTA POLYTECHNICA SC, V82, P57; Kohonen T, 1998, NEUROCOMPUTING, V21, P1, DOI 10.1016/S0925-2312(98)00030-7; Kohonen T., 1984, P 7 INT C PATT REC, P182; Kohonen Teuvo, 2001, SELF ORGANIZING MAPS; KOVALISHYN VV, 2000, P EUR S QUANT STRUCT, V12, P444; LARRY L, 2000, ACS NAT M WASH DC AU; LEARDI R, 1992, J CHEMOMETR, V6, P267, DOI 10.1002/cem.1180060506; LINDBERG W, 1983, ANAL CHEM, V55, P643, DOI 10.1021/ac00255a014; *MATHW INC, MATL 6 5; *MDL INF SYST INC, QSARIS 1 1; Polanski J, 2003, J CHEM INF COMP SCI, V43, P2081, DOI 10.1021/ci0341181; Polanski J, 2000, ACTA BIOCHIM POL, V47, P37; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P4; ROSE VS, 1991, QUANT STRUCT-ACT REL, V10, P6, DOI 10.1002/qsar.19910100103; SILIPO C, 1975, J AM CHEM SOC, V97, P6849, DOI 10.1021/ja00856a042; VANDERPUTTEN P, 1996, THESIS UTRECHT U NL; ZUPAN J, 1999, NEURAL NETWORK DRUG	28	20	20	4	9	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	NOV-DEC	2005	45	6					1749	1758		10.1021/ci0500839		10	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	989QS	WOS:000233689400039	16309281	
J	Agrawal, M; Gupta, N; Shreelekshmi, R; Murty, MN				Agrawal, M; Gupta, N; Shreelekshmi, R; Murty, MN			Efficient pattern synthesis for nearest neighbour classifier	PATTERN RECOGNITION			English	Article						pattern synthesis; prototyping; classification; clustering; partitioning		Synthetic pattern generation is one of the strategies to overcome the curse of dimensionality, but it has its own drawbacks. Most of the synthetic pattern generation techniques take more time than simple classification. In this paper, we propose a new strategy to reduce the time and memory requirements by applying prototyping as an intermediate step in the synthetic pattern generation technique. Results show that through the proposed strategy, classification can be done much faster without compromising much in terms of classification accuracy, in fact for some cases it gives better accuracy in lesser time. The classification time and accuracy can be balanced according to available memory and computing power of a system to get the best possible results. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India; Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Murty, MN (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	monu@csa.iisc.ernet.in; neha@ee.iisc.ernet.in; lekshmi@csa.iisc.ernet.in; mnm@csa.iisc.ernet.in					Babu TR, 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Viswanath P., 2004, INFORM FUSION, V5, P239, DOI 10.1016/j.inffus.2004.02.003	3	2	2	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	NOV	2005	38	11					2200	2203		10.1016/j.patcog.2005.03.029		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	967TB	WOS:000232113000034		
J	Li, XR; Wu, FC; Hu, ZY; Luo, AL				Li, XR; Wu, FC; Hu, ZY; Luo, AL			A novel spectral classifier based on coherence measure	SPECTROSCOPY AND SPECTRAL ANALYSIS			Chinese	Article						coherence measure; knowledge discovery; active galactic nucleus(AGNs); active galaxies(AGs); principal component analysis(PCA); k-nearest neighbor(KNN)	ULTRAVIOLET; GALAXIES	Classification and discovery of new types of celestial bodies from voluminous celestial spectra are two important issues in astronomy, and these two issues are treated separately in the literature to our knowledge. In the present paper, a novel coherence measure is introduced which can effectively measure the coherence of a new spectrum of unknown type with the training samples located within its neighbourhood, then a novel classifier is designed based on this coherence measure. The proposed classifier is capable of carrying out spectral classification and knowledge discovery simultaneously. In particular, it can effectively deal with the situation where different types of training spectra exist within the neighbourhood of a new spectrum, and the traditional k-nearest neighbour method usually fails to reach a correct classification. The satisfactory performance for classification. and knowledge discovery has been obtained by the proposed novel classifier over active galactic nucleus(AGNs) and active galaxies(AGs) data.	Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China; Chinese Acad Sci, Natl Astron Observ, Beijing 100012, Peoples R China	Li, XR (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China.						CALZETTI D, 1994, ASTROPHYS J, V429, P582, DOI 10.1086/174346; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA R O, 2003, PATTERN CLASSIFICATI, P568; Kendall M. G., 1966, ADV THEORY STAT, V3; Kinney AL, 1996, ASTROPHYS J, V467, P38, DOI 10.1086/177583; LI ZW, 2000, ASTROPHYSICS; MURTAGH F, 1987, MULTIVARIATE ANAL; Qin DM, 2003, SPECTROSC SPECT ANAL, V23, P182; zhao-qi Bian, 2000, PATTERN RECOGN, P235	9	3	4	0	0	BEIJING UNIV PRESS	BEIJING	HAIDIAN-QU, BEIJING 100871, PEOPLES R CHINA	1000-0593			SPECTROSC SPECT ANAL	Spectrosc. Spectr. Anal.	NOV	2005	25	11					1889	1892				4	Spectroscopy	Spectroscopy	990NM	WOS:000233750500040		
J	O'Farrell, M; Lewis, E; Flanagan, C; Lyons, W; Jackman, N				O'Farrell, M; Lewis, E; Flanagan, C; Lyons, W; Jackman, N			Comparison of k-NN and neural network methods in the classification of spectral data from an optical fibre-based sensor system used for quality control in the food industry	SENSORS AND ACTUATORS B-CHEMICAL			English	Article; Proceedings Paper	18th European Conference on Solid-State Transducers	SEP 13-15, 2004	Rome, ITALY		St Thomas Univ	k-nearest neighbour; neural network; backpropagation; principal component analysis; optical fibre sensor; spectroscopy; visible light; classification; food industry; process control; cooking		This paper investigates simplifying the classification technique of an optical fibre sensor based system designed for the online quality control of food being cooked in a large-scale industrial oven by monitoring the product as it cooks. The system measures the colour of the food product as it cooks by examining the reflected visible light from the surface as well as in the core of the product. Accurate classification has been previously obtained using a multi layer perceptron (MLP) with a backpropagation learning algorithm and principal component analysis (PCA) as a method of feature extraction but the k-nearest neighbour (k-NN) method is investigated in order to simplify the classification techniques, especially since principal component analysis already generates disjoint clusters. Two products are used to illustrate the principal of the method of this investigation, namely minced beef burgers and pastry although it is equally applicable to many other food products. In this investigation experimentally obtained spectral data was taken from the surface of the food and then analysed allowing direct comparison of the two classification methods. Results show that although the neural network proved superior when the input spectra deviated slightly in shape from the spectra used in training, the k-NN classifier may have prove advantageous in applications where there is less deviation in the sampled product spectrum. (c) 2005 Elsevier B.V. All rights reserved.	Univ Limerick, Dept Elect & Comp Engn, Limerick, Ireland; Food Design Applicat Ltd, Limerick, Ireland	O'Farrell, M (reprint author), Univ Limerick, Dept Elect & Comp Engn, Limerick, Ireland.	marion.ofarrell@ul.ie	Lewis, Elfed/H-5125-2013	Lewis, Elfed/0000-0003-4174-7090			Beckonert O, 2003, ANAL CHIM ACTA, V490, P3, DOI 10.1016/S0003-2670(03)00060-6; Conde C., 2003, Proceedings 12th International Conference on Image Analysis and Processing; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Drouhard JP, 1996, PATTERN RECOGN, V29, P415, DOI 10.1016/0031-3203(95)00092-5; DROUHARD JP, 1995, P 3 INT C DOC AN REC, V2, P807, DOI 10.1109/ICDAR.1995.602024; ISHIZAWA H, 2000, P 17 IEEE INTSTR MEA, V3, P1524, DOI 10.1109/IMTC.2000.848727; MIGNANI AG, 2003, SENSOR ACTUAT B-CHEM, P157; MIGNANI AG, 2004, P EUROPTRODE, V7, P217; Muhammed H. H., 2002, Proceedings 31st Applied Imagery Pattern Recognition Workshop From color to Hyperspectral: Advancements in Spectral Imagery Exploitation. AIPR 2002; OFARRELL M, IN PRESS IEEE SENS J; O'Farrell M, 2005, SENSOR ACTUAT B-CHEM, V107, P104, DOI 10.1016/j.snb.2004.09.050; OFARRELL M, 2003, INT J SMART ENG SYST, V5, P409, DOI 10.1080/10255810390243719; POTTIER I, 1994, P IEEE WORLD C COMP, V5, P2948, DOI 10.1109/ICNN.1994.374701; Schalkoff R.J., 1992, PATTERN RECOGNITION; SWATLAND HJ, 1989, CAN I FOOD SC TECH J, V22, P390	15	16	16	1	2	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0925-4005			SENSOR ACTUAT B-CHEM	Sens. Actuator B-Chem.	NOV 11	2005	111				SI		354	362		10.1016/j.snb.2005.02.003		9	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	977RM	WOS:000232820900056		
J	Mignani, AG; Ciaccheri, L; Cimato, A; Attilio, C; Smith, PR				Mignani, AG; Ciaccheri, L; Cimato, A; Attilio, C; Smith, PR			Spectral nephelometry for the geographic classification of Italian extra virgin olive oils	SENSORS AND ACTUATORS B-CHEMICAL			English	Article; Proceedings Paper	18th European Conference on Solid-State Transducers	SEP 13-15, 2004	Rome, ITALY		St Thomas Univ	absorption spectroscopy; olive oil; nephelometry; scattering		Extra virgin olive oils from different regions of Italy, both made in artisan manner and industrially produced, were analyzed by means of multi-angle and multi-wavelength absorption spectroscopy in the visible spectral range, and were then compared with other edible oils. A multivariate processing of the spectral data produced maps of oils clustered according to oil type and geographic origin. (c) 2005 Elsevier B.V. All rights reserved.	CNR, Inst Appl Phys Nello Cararra, Opt & Photon Dept, I-50127 Florence, Italy; CNR, IVALSA, I-50019 Sesto Fiorentino, FI, Italy; Univ Loughborough, Dept Elect & Elect Engn, Loughborough, Leics, England	Mignani, AG (reprint author), CNR, Inst Appl Phys Nello Cararra, Opt & Photon Dept, Via Panciatichi 64, I-50127 Florence, Italy.	a.g.mignani@ifac.cnr.it					ADAMS M, 1995, CHEMOMETRICS ANAL SP, pCH3; Alessandri S, 1999, GRASAS ACEITES, V50, P369; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cresti M., 1996, Advances in Horticultural Science, V10, P105; Harwood JL, 1999, HDB OLIVE OIL; Mignani AG, 2003, SENSOR ACTUAT B-CHEM, V90, P157, DOI 10.1016/S0925-4005(03)00101-1; VANDEGINSTE BGM, 1998, HDB CHEMOMETRICS QUA, pCH17	8	19	19	1	2	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0925-4005			SENSOR ACTUAT B-CHEM	Sens. Actuator B-Chem.	NOV 11	2005	111				SI		363	369		10.1016/j.snb.2005.03.023		7	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	977RM	WOS:000232820900057		
J	Shen, HB; Chou, KC				Shen, HB; Chou, KC			Predicting protein subnuclear location with optimized evidence-theoretic K-nearest classifier and pseudo amino acid composition	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						nucleus; nuclear proteins; subnuclear location; gene products; evidence theory; KNN classifier; Dempster's rule; pseudo amino acid; composition; jackknife test	STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; SUBCELLULAR LOCATION; FOLDING TYPES; LOCALIZATION; RULE	The nucleus is the brain of eukaryotic cells that guides the life processes of the cell by issuing key instructions. For in-depth understanding of the biochemical process of the nucleus, the knowledge of localization of nuclear proteins is very important. With the avalanche of protein sequences generated in the post-genomic era, it is highly desired to develop an automated method for fast annotating the subnuclear locations for numerous newly found nuclear protein sequences so as to be able to timely utilize them for basic research and drug discovery. In view of this, a novel approach is developed for predicting the protein subnuclear location. It is featured by introducing a powerful classifier, the optimized evidence-theoretic K-nearest classifier, and using the pseudo amino acid composition [K.C. Chou, PROTEINS: Structure, Function, and Genetics, 43 (2001) 246], which can incorporate a considerable amount of sequence-order effects, to represent protein samples. As a demonstration, identifications were performed for 370 nuclear proteins among the following 9 subnuclear locations: (1) Cajal body, (2) chromatin, (3) heterochromatin, (4) nuclear diffuse, (5) nuclear pore, (6) nuclear speckle, (7) nucleolus, (8) PcG body, and (9) PML body. The overall success rates thus obtained by both the re-substitution test and jackknife cross-validation test are significantly higher than those by existing classifiers on the same working dataset. It is anticipated that the powerful approach may also become a useful high throughput vehicle to bridge the huge gap occurring in the post-genomic era between the number of gene sequences in databases and the number of gene products that have been functionally characterized. The OET-KNN classifier will be available at www.pami.sjtu.edu.cn/people/hbshen. (c) 2005 Elsevier Inc. All rights reserved.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1994, J BIOL CHEM, V269, P22014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dellaire G, 2003, NUCLEIC ACIDS RES, V31, P328, DOI 10.1093/nar/gkg018; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; SHFER G, 1976, MATH THEORY EVIDENCE; Vapnik V., 1998, STAT LEARNING THEORY; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	30	112	120	1	8	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	NOV 25	2005	337	3					752	756		10.1016/j.bbrc.2005.09.117		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	978YY	WOS:000232910300002	16213466	
J	Le, SQ; Ho, TB				Le, SQ; Ho, TB			An association-based dissimilarity measure for categorical data	PATTERN RECOGNITION LETTERS			English	Article						dissimilarity measures; categorical data; conditional probability distribution; hypothesis testing; nearest neighbor	SIMILARITY; COEFFICIENTS; CLASSIFICATION; DIVERGENCE; ENTROPY	In this paper, we propose a novel method to measure the dissimilarity of categorical data. The key idea is to consider the dissimilarity between two categorical values of an attribute as a combination of dissimilarities between the conditional probability distributions of other attributes given these two values. Experiments with real data show that our dissimilarity estimation method improves the accuracy of the popular nearest neighbor classifier. (c) 2005 Elsevier B.V. All rights reserved.	Japan Adv Inst Sci & Technol, Sch Knowledge Sci, Tatsunokuchi, Ishikawa 9231292, Japan	Ho, TB (reprint author), Japan Adv Inst Sci & Technol, Sch Knowledge Sci, Tatsunokuchi, Ishikawa 9231292, Japan.	quang@jaist.ac.jp; bao@jaist.ac.jp	Le, Quang/A-4861-2012	Le, Quang/0000-0001-7881-618X			ALBERT ML, 1983, QUANTITATIVE APPL SO, V32; BATAGELJ V, 1995, J CLASSIF, V12, P73, DOI 10.1007/BF01202268; BAULIEU FB, 1989, J CLASSIF, V6, P233, DOI 10.1007/BF01908601; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Carvalho F.A.T., 1998, DATA SCI CLASSIFICAT, P370; de Carvalho F.A.T., 1994, STUDIES CLASSIFICATI, V5, P387; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Fisher R, 1950, STAT METHODS RES WOR; GOODALL DW, 1966, BIOMETRICS, V22, P882, DOI 10.2307/2528080; GOWDA KC, 1992, IEEE T SYST MAN CYB, V22, P368, DOI 10.1109/21.148412; GOWDA KC, 1991, PATTERN RECOGN LETT, V12, P259; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; HUBALEK Z, 1982, BIOL REV, V57, P669, DOI 10.1111/j.1469-185X.1982.tb00376.x; ICHINO M, 1994, IEEE T SYST MAN CYB, V24, P698, DOI 10.1109/21.286391; Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI DOI 10.1111/J.1469-8137.1912.TB05611.X; Krantz D.H., 1971, FDN MEASUREMENT; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; KULLBACK S, 1959, INFORMATION THEORY S; LANCASTER HO, 1949, BIOMETRIKA, V36, P370, DOI 10.2307/2332674; Liebetrau A. M., 1983, MEASURES ASS; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; Rached Z, 2001, IEEE T INFORM THEORY, V47, P1553, DOI 10.1109/18.923736; RUSSELL PAUL F., 1940, JOUR MALARIA INST INDIA, V3, P153; Sokal Robert, 1963, PRINCIPLES NUMERICAL	28	6	7	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC	2005	26	16					2549	2557		10.1016/j.patrec.2005.06.002		9	Computer Science, Artificial Intelligence	Computer Science	984LU	WOS:000233307200006		
S	Lou, Z; Jin, Z		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Lou, Zhen; Jin, Zhong			Novel adaptive nearest neighbor classifiers based on hit-distance	18th International Conference on Pattern Recognition, Vol 3, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ			PATTERN-CLASSIFICATION; FACE RECOGNITION	In this paper a novel idea of distance, Hit-Distance, was firstly introduced to generalize the representational capacity of available prototypes. Novel adaptive nearest neighbor classifiers based on Hit-Distance were then proposed Experiments were performed on 8 benchmark datasets from the UCI Machine Learning Repository. It was shown that the proposed classifiers performed much better than the classical nearest neighbor classifier (NN) and the nearest feature line method (NFL), the nearest feature plane method (NFP), the nearest neighbor line method (NNL) and the nearest neighbor plane method (NNP).	Nanjing Univ Sci & Technol, Dept Comp Sci, Nanjing 210094, Peoples R China	Lou, Z (reprint author), Nanjing Univ Sci & Technol, Dept Comp Sci, Nanjing 210094, Peoples R China.						Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freedman D, 2002, IEEE T PATTERN ANAL, V24, P1349, DOI 10.1109/TPAMI.2002.1039206; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Newman D.J., UCI REPOSITORY MACHI; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	6	4	4	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2521-0	INT C PATT RECOG			2006							87	90				4	Computer Science, Artificial Intelligence	Computer Science	BFB29	WOS:000240705600021		
S	Shu, Y; Chao, Z		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Shu Yang; Chao Zhang			Regression Nearest Neighbor in face recognition	18th International Conference on Pattern Recognition, Vol 3, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ			CLASSIFICATION	In this paper, we introduce a Regression Nearest Neighbor framework for general classification tasks. To alleviate potential problems caused by nonlinearity, we propose a kernel regression nearest neighbor (KRNN) algorithm and its convex counterpart (CKRNN) as two specific extensions of nearest neighbor algorithm and present a fast and useful kernel selection method correspondingly. Comprehensive analysis and extensive experiments are used to demonstrate the effectiveness of our methods in real face datasets.	Peking Univ, Natl Lab Machine Percept, Beijing 100871, Peoples R China	Shu, Y (reprint author), Peking Univ, Natl Lab Machine Percept, Beijing 100871, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fung G., 2001, P KDD 2001; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; LI S, 1998, INT C COMP VIS PATT; PENG J, 2004, IEEE T PATTERN ANAL, V26; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Poggio T., 2003, NOTICES AMS, V50, P537; Scholkopf B., 2002, LEARNING KERNELS; Sim T., 2002, INT C AUT FAC GEST R; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; VICENT P, 2001, NEURAL INFORM PROCES; YANG C, 2004, NEURAL INFORM PROCES	14	0	0	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2521-0	INT C PATT RECOG			2006							515	518				4	Computer Science, Artificial Intelligence	Computer Science	BFB29	WOS:000240705600123		
S	Andra, S; Nagy, G		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Andra, Srinivas; Nagy, George			Combining dichotomizers for MAP field classification	18th International Conference on Pattern Recognition, Vol 4, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ				A new method for combining dichotomizers like SVMs is proposed for classifying multi-class pattern fields. The novelty lies in the estimation of the style-constrained posterior field class probabilities from the frequencies of the training patterns in the regions of the feature space engendered by the pairwise decision boundaries of the dichotomizers. We show that on simulated data, this non-parametric field classifier is nearly optimal. On scanned printed digits, its accuracy is comparable to that of state-of-the-art style classifiers.	Rensselaer Polytech Inst, DocLab, ECSE, Troy, NY 12180 USA	Andra, S (reprint author), Rensselaer Polytech Inst, DocLab, ECSE, Troy, NY 12180 USA.						ANDRA S, 2005, COMBINING DICHOTOMIZ; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Gunter S, 2004, LECT NOTES COMPUT SC, V3138, P583; Lam L., 1997, HDB CHARACTER RECOGN, P79; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Sarkar M, 2005, THER DRUG MONIT, V27, P1, DOI 10.1097/00007691-200502000-00001; SAVICKY P, 2003, P 5 INT S INT DAT AN; Vapnik V., 1998, STAT LEARNING THEORY; Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19; VEERAMACHANENI S, 2003, P 6 INT C DOC AN REC, P1060; ZASLAVSKY T, 1975, MEM AM MATH SOC, V1, P154; ZHANG X, 2006, P SPIE ELECT IMAGING, V6067; ZHANG X, 2006, INT C PATTERN RECOGN	15	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651		0-7695-2521-0	INT C PATT RECOG			2006							210	214				5	Computer Science, Artificial Intelligence	Computer Science	BFB30	WOS:000240707600051		
S	Tahir, MA; Bouridane, A			IEEE	Tahir, Muhammad Atif; Bouridane, Ahmed			An FPGA based coprocessor for cancer classification using nearest neighbour classifier	2006 IEEE International Conference on Acoustics, Speech and Signal Processing, Vols 1-13	International Conference on Acoustics Speech and Signal Processing (ICASSP)		English	Proceedings Paper	31st IEEE International Conference on Acoustics, Speech and Signal Processing	MAY 14-19, 2006	Toulouse, FRANCE	IEEE Signal Proc Soc				This paper discusses the suitability of reconfigurable computing to speedup classification problems using Nearest Neighbour (1NN) classifier. 1NN classifier is widely used in the literature especially in real-time applications such as face recognition, on-line hand-written character recognition and medical applications where the performance enhancement in terms of speed is desirable. To evaluate the effectiveness of our implementation on Field Programmable Gate Arrays (FPGAs), experiments were carried out on two medical data sets. Results have shown that the classification accuracy is exactly same for both FPGAs and microprocessor (mu P) based solutions with FPGA has superior speed performances.	Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.						Bensaali F, 2005, IEE P-CIRC DEV SYST, V152, P236, DOI 10.1049/ip-cds:20040838; Blake CL, UCI REPOSITORY MACHI; Bouridane A, 1999, J SYST ARCHITECT, V45, P809, DOI 10.1016/S1383-7621(98)00040-X; Chellappa R., 1995, P IEEE, V83, P5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROOKES D, 2000, IEE P VIS IM SIGN PR; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Ferrari A, 2000, PATTERN RECOGN, V33, P2083, DOI 10.1016/S0031-3203(99)00192-2; LIPMAN A, 1997, IEEE T VLSI, V5; Michie D., 1994, MACHINE LEARNING NEU; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; TAHIR MA, 2004, LECT NOTES COMPUTER, P771; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tahir MA, 2005, ANALOG INTEGR CIRC S, V43, P205, DOI 10.1007/s10470-005-6793-2; TZIONAS PG, 1994, IEEE T VLSI, V2; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; ZHOU P, 1998, P 9 BRIT MACH VIS C	17	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-0468-1	INT CONF ACOUST SPEE			2006							3463	3466				4	Acoustics; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Acoustics; Computer Science; Engineering; Imaging Science & Photographic Technology	BFZ22	WOS:000245559904041		
S	Shie, JD; Chen, SM			IEEE	Shie, Jen-Da; Chen, Shyi-Ming			A new approach for handling classification problems based on fuzzy information gain measures	2006 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-5	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	JUL 16-21, 2006	Vancouver, CANADA	IEEE			MEMBERSHIP FUNCTIONS; TRAINING INSTANCES; RULES; SELECTION; FEATURES; ENTROPY	In this paper, we present a new method for handling classification problems based on fuzzy information gain measures. First, we propose a fuzzy information gain measure of a feature with respect to a set of training instances. Then, based on the proposed fuzzy information gain measure, we present an algorithm for constructing membership functions, calculating the class degree of each subset of training instances with respect to each class and calculating the fuzzy entropy of each subset of training instances, where each subset of training instances contains a part of the training instances whose values of a specific feature fall in the support of a specific fuzzy set of this feature. Finally, we propose an evaluating function for. classifying testing instances. The proposed method can deal with both numeric and nominal features. It gets higher average classification accuracy rates than the existing methods.	Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Shie, JD (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.	smchen@et.ntust.edu.tw					BAIM PW, 1988, IEEE T PATTERN ANAL, V10, P888, DOI 10.1109/34.9110; BANERJI RB, 1964, GEN SYST, V9, P135; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Chen SM, 2003, CYBERNET SYST, V34, P217, DOI 10.1080/01969720390184399; Chen S.M., 2005, P 2005 IEEE INT C FU, P183, DOI 10.1109/FUZZY.2005.1452390; Chen SM, 2005, CYBERNET SYST, V36, P397, DOI 10.1080/01969720490929562; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; Hartigan JA, 2002, J ROYAL STAT SOC C, V28, P100, DOI DOI 10.2307/2346830; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; John G.H., 1995, P 11 C UNC ART INT, P338; KOSKO B, 1986, INFORM SCIENCES, V40, P165, DOI 10.1016/0020-0255(86)90006-X; Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536; Luca A.D., 1972, INFORM CONTR, V20, P301, DOI DOI 10.1016/S0019-9958(72)90199-4; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Mitchell T. M., 1997, MACHINE LEARNING; ONGKOWIJAYA BT, 2004, P 7 INT C SIGN PROC, P663; Platt J, 1999, P 13 ANN C NEUR INF, P557; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Ramesh VE, 1999, PATTERN RECOGN, V32, P217, DOI 10.1016/S0031-3203(98)00141-1; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SHANNON CE, 1948, AT&T TECH J, V27, P379; Wu TP, 1999, IEEE T SYST MAN CY B, V29, P25, DOI 10.1109/3477.740163; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5	29	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584		978-0-7803-9488-9	IEEE INT CONF FUZZY			2006							939	946				8	Computer Science, Artificial Intelligence	Computer Science	BFR68	WOS:000244063601068		
S	Zhao, Q			IEEE	Zhao, Qiangfu			Inducing NNC-Trees quickly	2006 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-6, PROCEEDINGS	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 08-11, 2006	Taipei, TAIWAN	IEEE Syst, Man & Cybernet Soc, Minist Educ, Natl Sci Council, Natl Taipei Univ Technol, Natl Chiao Tung Univ			NEIGHBOR PATTERN-CLASSIFICATION; HIERARCHICAL-CLASSIFICATION	An NNC-Tree is a decision tree (DT) with each non-terminal node containing a nearest neighbor classifier (NNC). Compared with the axis-parallel decision trees (APDTs), NNC-Trees are more comprehensible for large problems, because the decision rules corresponding to the trees are simpler. Currently, the author has proposed an algorithm for inducing NNC-Trees based on the R(4)-rule. However, compared with C4.5, which is a popular program for inducing APDTs, the computation of our algorithm is relatively expensive. This paper proposes two methods for reducing the computational cost. The efficiency of the proposed methods is verified through experiments on three public databases.	Univ Aizu, Grad Sch, Dept Informat Syst, Aizu Wakamatsu, Japan	Zhao, Q (reprint author), Univ Aizu, Grad Sch, Dept Informat Syst, Aizu Wakamatsu, Japan.	qf-zhao@u-aizu-ac.jp					Adams RG, 1999, NEURAL NETWORKS, V12, P541, DOI 10.1016/S0893-6080(99)00010-6; BASAK J, 2005, IEEE T KNOWL DATA EN, V7, P121; Brieman L, 1984, CLASSIFICATION REGRE; Cantu-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; LI T, 1993, NEUROCOMPUTING, V5, P119, DOI 10.1016/0925-2312(93)90032-X; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Oates T., 1997, P 14 INT C MACH LEAR, P254; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; ZHAO QF, 2006, IN PRESS IEEE T SY B; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240	13	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4244-0099-7	IEEE SYS MAN CYBERN			2006							2784	2789		10.1109/ICSMC.2006.385295		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	BGK85	WOS:000248078503015		
B	Blanzieri, E; Melgani, F			IEEE	Blanzieri, Enrico; Melgani, Farid			An Adaptive SVM Nearest Neighbor Classifier for Remotely Sensed Imagery	2006 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS 1-8	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 31-AUG 04, 2006	Denver, CO	IEEE, IEEE Geosci & Remote Sensing Soc, Canadian Remote Sensing Soc, NASA, NOAA, Off Naval Res, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Ball Aerosp & Technologies Corp, Cooperat Inst Res Atmosphere, Colorado State Univ, Univ Colorado, Int Union Radio Sci		image classification; k-nearest neighbor algorithm; kernel methods; support vector machines	SENSING IMAGES	In this paper, we propose an extension of the kNN classifier based on the maximum margin principle. The proposed method is based on the idea to classify a given unlabeled sample by first finding its k nearest training samples. Then, a local partition of the feature space is carried out by means of local SVM decision boundaries determined after training a multiclass SVM classifier on the k training samples considered. The labeling of the unknown sample is done by looking at the local decision region it belongs to. The resulting global decision boundaries throughout the entire feature space are piecewise linear. The entire process can be however kernelized through the determination of the k nearest training samples in the kernel space by using a distance function simply reformulated on the basis of the adopted kernel. To illustrate the performance of the proposed method, an experimental analysis on different remote sensing data sets is reported and discussed.	[Blanzieri, Enrico; Melgani, Farid] Univ Trent, Dept Informat & Commun Technol, I-38050 Trento, Italy	Blanzieri, E (reprint author), Univ Trent, Dept Informat & Commun Technol, Via Sommarive 14, I-38050 Trento, Italy.	blanzier@dit.unitn.it; melgani@dit.unitn.it					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 2001, 4 USAF SCH AV MED, P261; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Vapnik V., 1998, STAT LEARNING THEORY; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874	7	12	12	3	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-7803-9509-1	INT GEOSCI REMOTE SE			2006							3931	3934		10.1109/IGARSS.2006.1008		4	Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Geology; Remote Sensing; Imaging Science & Photographic Technology	BIN08	WOS:000260989402194		
S	Solomatine, DP; Maskey, M; Shrestha, DL			IEEE	Solomatine, Dimitri. P.; Maskey, Mahesh; Shrestha, Durga Lal			Eager and lazy learning methods in the context of hydrologic forecasting	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE			ARTIFICIAL NEURAL NETWORKS; MODEL TREES; RIVER; PREDICTION	Computational intelligence techniques are becoming popular in hydrologic forecasting. Primarily these are eager learning methods. Lazy (instance-based) learning (IBL) has received relatively little attention, and the present paper explores the applicability of these methods. Their performance is compared with that of neural networks, M5 model trees, regression trees. A flow forecasting problem was solved along with the five benchmark problems. Results showed that one of the IBL methods, the locally weighted regression, especially if used with the Gaussian kernel function, often is more accurate than the eager learning methods.	Inst Water Educ, UNESCO IHE, NL-2601 DA Delft, Netherlands	Solomatine, DP (reprint author), Inst Water Educ, UNESCO IHE, POB 3015, NL-2601 DA Delft, Netherlands.	d.solomatine@unesco-ihe.org; maheshmaskey@yahoo.com; d.shrestha@unesco-ihe.org	Shrestha, Durga/B-5610-2013	Shrestha, Durga/0000-0002-5545-1736			Abrahart RJ, 2000, HYDROL PROCESS, V14, P2157, DOI 10.1002/1099-1085(20000815/30)14:11/12<2157::AID-HYP57>3.0.CO;2-S; AHA DW, 1991, MACH LEARN, P37; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BLALE CL, 1998, UCI REPOSITORY MACHI; Bray M, 2004, J HYDROINFORM, V6, P265; CLEVELAND WS, 1994, 953 AT T BELL LAB ST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dibike YB, 2001, PHYS CHEM EARTH PT B, V26, P1, DOI 10.1016/S1464-1909(01)85005-X; FEDOROV VV, 1993, NONPARAMETRIC STAT, V2, P355; GALEATI G, 1990, HYDROLOG SCI J, V35, P79, DOI 10.1080/02626669009492406; Gasser T., 1979, SMOOTHING TECHNIQUES, P23; Govindaraju RS, 2001, ARTIFICIAL NEURAL NE; HSU KL, 1995, WATER RESOUR RES, V31, P2517, DOI 10.1029/95WR01955; KARLSSON M, 1987, WATER RESOUR RES, V23, P1300, DOI 10.1029/WR023i007p01300; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Minns AW, 1996, HYDROLOG SCI J, V41, P399, DOI 10.1080/02626669609491511; Mitchell T. M., 1997, MACHINE LEARNING; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; QUINLAN JR, 1993, P ML 93 SAN MAT CA; Scott D.W., 1992, MULTIVARIATE DENSITY; Shamseldin AY, 1996, J HYDROL, V179, P353, DOI 10.1016/0022-1694(95)02833-1; SHRESTHA DL, 2006, NEURAL COMPUTATION, V18; SHRESTHA I, 2003, THESIS IHE DELFT; Solomatine D. P., 2005, ENCY HYDROLOGICAL SC; Solomatine DP, 2004, J HYDROL ENG, V9, P491, DOI 10.1061/(ASCE)1084-0699(2004)9:6(491); Solomatine DP, 2003, HYDROLOG SCI J, V48, P399, DOI 10.1623/hysj.48.3.399.45291; Solomatine DP, 2006, NEURAL NETWORKS, V19, P215, DOI 10.1016/j.neunet.2006.01.008; Toth E, 2000, J HYDROL, V239, P132, DOI 10.1016/S0022-1694(00)00344-9; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; Witten I.H., 2000, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	31	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							4847	4853				7	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125909002		
S	Specht, DF			IEEE	Specht, Donald F.			GRNN with double clustering	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE			NEURAL NETWORK	The hybrid combination of three techniques has yielded a pattern recognition and estimation technique with greatly improved training speed, orders-of-magnitude speed improvement for testing and readout, and sometimes improved accuracy as well. It is useful for problems with high dimensionality and noisy data. The techniques used are clustering, kernel regression with adaptive parameters, a second level of clustering, and the formation of a binary decision tree. When previous versions of General Regression Neural Networks have been used as the system identification component for control systems, the most important problem has been that the estimation speed limits the iteration time in the feedback loop. The new hybrid technique was designed specifically to overcome this limitation.	Lockheed Martin Corp, Adv Technol Ctr, Palo Alto, CA 94304 USA	Specht, DF (reprint author), Lockheed Martin Corp, Adv Technol Ctr, 3251 Hanover St, Palo Alto, CA 94304 USA.	don.specht@lmco.com					BURRASCANO P, 1991, IEEE T NEURAL NETWOR, V2, P458, DOI 10.1109/72.88165; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRANTI P, 2000, IEEE T IMAGE PROCESS, V9; Nadaraya E., 1964, THEOR PROBAB APPL, V9, P141, DOI DOI 10.1137/1109020; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Press W. H., 1988, NUMERICAL RECIPES C; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264666; Specht D. F., 1992, P IEEE INT JOINT C N; SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934; SPECHT DF, 1995, FUZZ LOGIC NEURAL NE; SPECHT DF, 1968, N6829513 NASA; SPECHT DF, 1994, IEEE INT C NEUR NETW; SPECHT DF, 2004, Patent No. 6787747; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Watson G. S., 1964, SANKHYA A, V26, P359	16	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-0-7803-9490-2	IEEE IJCNN			2006							5074	5079				6	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125909035		
B	Rozman, D; Brezak, M; Petrovic, I		Lavoie, M; AlHaddad, K; Lagace, PJ		Rozman, D.; Brezak, M.; Petrovic, I.			Parquet sorting and grading based on color and texture analyses	2006 IEEE International Symposium on Industrial Electronics, Vols 1-7			English	Proceedings Paper	IEEE International Symposium on Industrial Electronics	JUL 09-13, 2006	Montreal, CANADA	IEEE Ind Elect Soc, ABB Canada, Ecol Technol Superieure			CLASSIFICATION; INSPECTION; FEATURES; WOOD	In this paper a computer vision algorithm for automatic parquet slab sorting is described, as a part of a real time automatic parquet slab sorting system. Various computer vision algorithms and methods for automatic visual inspection and automatic classification have been analyzed. Developed algorithm consists of three main stages: color analysis, texture analysis and defects detection. The color analysis is based on the percentile values obtained from the cumulative histogram of the image and texture analysis is based on the second order statistical features obtained from gray level co-occurrence matrix. Detection of defects is implemented as the segmentation method, based on the adaptive binary threshold algorithm, which is based on a local square regions and connected component analysis methods. This way we have achieved a very accurate classifying process with about 90 percent of accuracy, which greatly outstands results of human inspector, that are about 60-70 percent.	Univ Zagreb, Fac Elect & Comp Engn, Dept Comp Engn Automat, Zagreb 41000, Croatia	Rozman, D (reprint author), Univ Zagreb, Fac Elect & Comp Engn, Dept Comp Engn Automat, Zagreb 41000, Croatia.						CONNERS RW, 1983, IEEE T PATTERN ANAL, V5, P573; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1989, PAMI, P421; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Iivarinen J, 2000, P SOC PHOTO-OPT INS, V4197, P140, DOI 10.1117/12.403757; Kauppinen H., 1999, THESIS U OULU OULU; KAUPPINEN H, 2000, P 15 INT C PATT REC, V4, P803, DOI 10.1109/ICPR.2000.903039; MAENPAA T, 2004, PATTERN RECOGN, V8, P1629; NEWMAN TS, 1995, COMPUT VIS IMAGE UND, V61, P231, DOI 10.1006/cviu.1995.1017; Pan JS, 2004, IEICE T FUND ELECTR, VE87A, P961; PETKOVIC T, 2002, P ERK 2002, P283; Silven O, 1996, INT J PATTERN RECOGN, V10, P83, DOI 10.1142/S0218001496000086; VANOTTERLOO PJ, 1978, PR, P281	13	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0496-4				2006							655	660		10.1109/ISIE.2006.295538		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BFS70	WOS:000244382901029		
B	Wang, Q; Kulkarni, SR; Verdu, S			IEEE	Wang, Qing; Kulkarni, Sanjeev R.; Verdu, Sergio			A nearest-neighbor approach to estimating divergence between continuous random vectors	2006 IEEE International Symposium on Information Theory, Vols 1-6, Proceedings			English	Proceedings Paper	IEEE International Symposium on Information Theory	JUL 09-14, 2006	Seattle, WA	IEEE Informat Theory Soc, USN, Dept Navy Sci & Technol, Microsoft, Natl Sci Fdn			CONSISTENT	A method for divergence estimation between multidimensional distributions based on nearest neighbor distances is proposed. Given i.i.d. samples, both the bias and the variance of this estimator are proven to vanish as sample sizes go to infinity. In experiments on high-dimensional data, the nearest neighbor approach generally exhibits faster convergence compared to previous algorithms based on partitioning.	Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA	Wang, Q (reprint author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.						BENTLEY J. L., 1975, COMMUN ACM, V18, P509; BHATTACH.PK, 1967, ANN MATH STAT, V38, P1770, DOI 10.1214/aoms/1177698611; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASU T, 2006, IN PRESS P 38 S INT; DEVROYE L, 1996, PROBABLISTIC THEORY; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Feller W, 1970, INTRO PROBABILITY TH; Fix E., 1951, DISCRIMINATORY ANAL; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Goldberger J, 2003, P 9 IEEE INT C COMP, V1, P487, DOI [DOI 10.1109/ICCV.2003.1238387, 10.1109/ICCV.2003.1238387]; HINNEBURG A, 2000, P 26 VLDB C CAIR EGY; Johnson DH, 2001, J COMPUT NEUROSCI, V10, P47, DOI 10.1023/A:1008968010214; Kozachenko L. F., 1987, Problems of Information Transmission, V23; Kraskov A, 2004, PHYS REV E, V69, DOI [10.1103/PhysRevD.69.043502, 10.1103/PhysRevD.69.023502]; KRISHNAMURTHY B, 2005, P 1 IEEE WORKSH NETW; Kulkarni SR, 2002, IEEE T INFORM THEORY, V48, P2785, DOI 10.1109/TIT.2002.802611; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Liu C., 2003, P IEEE C COMP VIS PA, P1; Loeve M., 1977, PROBABILITY THEORY; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MATHIASSEN JR, 2002, P 7 EUR C COMP VIS 3, P133; Ramirez J, 2004, IEEE SIGNAL PROC LET, V11, P266, DOI 10.1109/LSP.2003.821762; Tsybakov AB, 1996, SCAND J STAT, V23, P75; VICTOR JD, 2002, PHYS REV E, V66, P51903; WANG Q, 2005, BIAS REDUCTION DIVER; Wang Q, 2005, IEEE T INFORM THEORY, V51, P3064, DOI 10.1109/TIT.2005.853314	28	2	2	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0505-3				2006							242	246		10.1109/ISIT.2006.261842		5	Telecommunications	Telecommunications	BFX53	WOS:000245289700051		
S	van der Laan, DJ; Maas, MC; Schaart, DR; Bruyndonckx, P; Lamaitre, C; van Eijk, CWE			IEEE	van der Laan, D. J. (Jan); Maas, Marnix C.; Schaart, Dennis R.; Bruyndonckx, Peter; Lamaitre, Cedric; van Eijk, Carel W. E.			Spatial Resolution in Position-Sensitive Monolithic Scintillation Detectors	2006 IEEE NUCLEAR SCIENCE SYMPOSIUM CONFERENCE RECORD, VOL 1-6	IEEE Nuclear Science Symposium Conference Record		English	Proceedings Paper	15th International Workshop on Room-Temperature Semiconductor X- and Gamma-Ray Detectors/ 2006 IEEE Nuclear Science Symposium	OCT 29-NOV 04, 2006	San Diego, CA	IEEE			PET DETECTORS	Monolithic scintillation detectors are very promising for high resolution and high sensitivity positron emission tomography. These detectors consist of a few cubic centimeters of scintillating material coupled to one or more position-sensitive APD arrays. The entry point of an impinging annihilation photon is estimated from the light distribution on the APD pixels. In this paper, a model will be derived that predicts the line spread function of these detectors. This model includes the influences of the finite width of the measurement beam, scatter of radiation inside the detector, light yield and intrinsic energy resolution of the scintillator, quantum efficiency, gain and excess noise factor of the avalanche photo-diode arrays, and electronic noise. With this model a better understanding of the behavior of the detector is possible, which can make optimization more efficient.	[van der Laan, D. J. (Jan); Maas, Marnix C.; Schaart, Dennis R.; van Eijk, Carel W. E.] Delft Univ Technol, NL-2629 JB Delft, Netherlands	van der Laan, DJ (reprint author), Delft Univ Technol, Mekelweg 15, NL-2629 JB Delft, Netherlands.	d.j.vanderlaan@tudelft.nl	Schaart, Dennis/C-7136-2014	Schaart, Dennis/0000-0002-3199-5608			Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8; Barrett H H, 2004, FDN IMAGE SCI; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; MAAS MC, 2005, IEEE NUCL SCI S, V4, P2017, DOI 10.1109/NSSMIC.2005.1596729; Stuart A., 1991, KENDALLS ADV THEORY, V2; van der Laan DJJ, 2006, IEEE T NUCL SCI, V53, P1063, DOI 10.1109/TNS.2006.873710	8	1	1	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1082-3654		978-1-4244-0561-9	IEEE NUCL SCI CONF R			2006							2506	2510		10.1109/NSSMIC.2006.354420		5	Engineering, Electrical & Electronic; Physics, Applied	Engineering; Physics	BUC53	WOS:000288875602124		
B	Huang, CC; Chang, HY; Yang, CH		Cheung, YM; Wang, Y; Lium, H		Huang, Chi-Chun; Chang, Hsin-Yun; Yang, Cheng-Hong			A novel grey-based feature ranking method for feature subset selection	2006 International Conference on Computational Intelligence and Security, Pts 1 and 2, Proceedings			English	Proceedings Paper	International Conference on Computational-Intelligence and Security	NOV 03-06, 2006	Guangzhou, PEOPLES R CHINA	IEEE Hong Kong Computat Intelligence Chapter, Guangdong Univ Technol, Xidian Univ, Hong Kong Baptist Univ, Jian Univ			ALGORITHMS; CLASSIFICATION	In this paper, a novel grey-based feature ranking method for feature subset selection is proposed. Experiments performed on various application domains are reported to demonstrate the performance of the proposed approach. It can be easily seen that the proposed approach yields high performance and is helpful for pattern classification.	Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan	Huang, CC (reprint author), Natl Kaohsiung Marine Univ, Dept Informat Management, 142 Hai Jhuan Rd, Kaohsiung 811, Taiwan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Blake CL, UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1990, NEAREST NEIGHBOUR NN; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Deng Julong, 1989, Journal of Grey Systems, V1; Deng J., 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; Duda R. O., 1973, PATTERN CLASSIFICATI; HUANG CC, IN PRESS APPL INTELL; John G., 1994, P 11 INT C MACH LEAR, P121; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Liu H., 1998, FEATURE SELECTION KN; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Mitchell T. M., 1998, MACHINE LEARNING; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Watson C. J., 1993, STAT MANAGEMENT EC	20	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0604-3				2006							129	132		10.1109/ICCIAS.2006.294105		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFP93	WOS:000243679800026		
B	Yang, CY; Hsu, CC; Yang, JS		Cheung, YM; Wang, Y; Lium, H		Yang, Chan-Yun; Hsu, Che-Chang; Yang, Jr-Syu			A novel SVM to improve classification for heterogeneous learning samples	2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS			English	Proceedings Paper	International Conference on Computational-Intelligence and Security	NOV 03-06, 2006	Guangzhou, PEOPLES R CHINA	IEEE Hong Kong Computat Intelligence Chapter, Guangdong Univ Technol, Xidian Univ, Hong Kong Baptist Univ, Jian Univ				The paper proposes a model merging a nonparametric k-nearest-neighbor (kNN) method into an underlying support vector machine (SVM) to produce an instance-dependent loss function. In this model, a filtering stage of the kNN searching was employed to collect information from training examples and produced a set of emphasized weights which can be If distributed to every example by a class of real-valued class labels. The emphasized weights changed the policy of the equal-valued impacts of the training examples and permitted a more efficient way to utilize the information behind the training examples with various significance levels. Due to the property of estimating density locally, the kNN method has the advantage to distinguish the heterogeneous examples from the regular examples by merely considering the situation of the examples themselves. The paper shows the model is promising with both the theoretical derivations and consequent experimental results.	No Taiwan Inst Sci & Technol, Dept Mech Engn, Taipei 112, Taiwan	Yang, CY (reprint author), No Taiwan Inst Sci & Technol, Dept Mech Engn, 2 Xue Yuan Rd, Taipei 112, Taiwan.	cy.yang@ntist.edu.tw; 692342792@s92.tku.edu.tw; 096034@mail.tku.edu.tw					Bartlett P. L., 2003, 638 UC BERK DEP STAT; BREIMAN L, 1996, 460 UC BERK DEP STAT; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Fukunaga K., 1990, STAT PATTERN RECOGNI; Hastie T, 2001, ELEMENTS STAT LEARNI; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yang CY, 2004, LECT NOTES COMPUT SC, V3173, P506	14	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0604-3				2006							172	175				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFP93	WOS:000243679800036		
B	Kangkan, K; Kruatrachue, B			IEEE	Kangkan, Kamonnat; Kruatrachue, Boontee			Minimal consistent subset selection as integer nonlinear programming problem	2006 International Symposium on Communications and Information Technologies,Vols 1-3			English	Proceedings Paper	International Symposium on Communications and Information Technologies	OCT 18-20, 2006	Bangkok, THAILAND			prototype selection; minimal consistent subset; consistency; nearest neighbor rule	NEAREST-NEIGHBOR RULE; SET COVERING PROBLEM; CLASSIFICATION; ALGORITHM; SEARCH; DESIGN	The minimal consistent subset selection is a solution of high computational demands problem of the nearest neighbor decision system. This paper presents a new approach that aims to make the problem more clearly by stating it as a constrained optimization problem, called "integer nonlinear programming problem (INLP)". In this context, we propose method that formulates the minimal consistent subset selection problem as 0-1 integer nonlinear programming problem. We show experimental result of the minimal consistent subset of "IRIS Dataset", obtained by solving its constrained optimization model. The results obtained suggest that the approach offers exactly optimal solution of the problem.	King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok, Thailand	Kangkan, K (reprint author), King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok, Thailand.						Anderson E., 1935, B AM IRIS SOC, V59, P2; BARTH P, 1995, MPI952003 MAXPL I IN; Beasley JE, 1996, EUR J OPER RES, V94, P392, DOI 10.1016/0377-2217(95)00159-X; BEASLEY JE, 1990, NAV RES LOG, V37, P151, DOI 10.1002/1520-6750(199002)37:1<151::AID-NAV3220370110>3.0.CO;2-2; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; Caprara A, 1999, OPER RES, V47, P730, DOI 10.1287/opre.47.5.730; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Fortet R., 1960, REV FRANCAISE RECHER, V4, P17; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Li J., 2004, J MATH MODELLING ALG, V3, P263, DOI 10.1023/B:JMMA.0000038619.69509.bf; MOLLINEDA RA, 2000, P 4 WORLD MULT SYST; TAHA HA, 1972, MANAGE SCI B-APPL, V18, pB328; TAHA HA, 1992, OPERTATIONS RES INTR, P333	18	0	0	0	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-0-7803-9740-8				2006							922	926				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BGI18	WOS:000247284400185		
B	Jirina, M; Jirina, M			IEEE	Jirina, Marcel; Jirina, Marcel, Jr.			Simple and effective probability density estimation and classification	2006 SICE-ICASE INTERNATIONAL JOINT CONFERENCE, VOLS 1-13			English	Proceedings Paper	SICE-ICASE International Joint Conference	OCT 18-21, 2006	Busan, SOUTH KOREA	SICE, ICASE		multivariate data; classification; probability distribution mapping function; power approximation		A mapping is introduced which maps the true distribution to a function of distances. The approximation of this function in the form of a suitable power of the distance is presented. The exponent in this approximation is used for probability density estimation in high-dimensional spaces and for classification.	Inst Comp Sci ASCR, Prague, Czech Republic	Jirina, M (reprint author), Inst Comp Sci ASCR, Prague, Czech Republic.	jirina@fbmi.cvut.cz; jirina@fbmi.cvut.cz	Jirina, Marcel/B-2846-2014				Bishop C.M., 1995, NEURAL NETWORKS PATT; *CART, CART METH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUA RO, 2000, PATTERN CLASSIFICATI; Gama J, 2003, THEOR COMPUT SCI, V292, P417, DOI 10.1016/S0304-3975(02)00179-2; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; HAKL F., 2005, ATLCOMPHYS2005044 CE; Hinneburg A., 2000, P 26 INT C VER LARG, P506; Silverman BW, 1986, DENSITY ESTIMATION S; *STATS INC, 2005, STATISTICA DAT AN SO	10	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-89-950038-4-8				2006							2122	2123				2	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Automation & Control Systems; Computer Science; Engineering; Robotics	BGE04	WOS:000246237602049		
B	Umamaheswari, K; Sumathi, S; Sivanandam, SN; Anburajan, KKN			IEEE	Umamaheswari, K.; Sumathi, S.; Sivanandam, S. N.; Anburajan, K. K. N.			Efficient finger print image classification and recognition using neural network data mning	2007 International Conference of Signal Processing, Communications and Networking, Vols 1 and 2			English	Proceedings Paper	International Conference on Signal Processing, Communications and Networks	FEB 22-24, 2007	Chennai, INDIA	IEEE		finger print recognition; neural network; and K nearest neighbor algorithms; data mining		This paper deals with the fingerprint classification and recognition system, which consists of extracting and matching of minutiae from the input image. The necessity for Security in fields such as improving airport security, strengthening the national borders, in travel documents, in preventing ID theft has brought the need to develop an able and efficient method for correct classification of personnel authentication. Fingerprints are the first biometric science used widely for the validation and verifications of entry into specific task, which is more reliable, efficient and accurate. Despite finger print recognition being reliable it has disadvantages such as very low recognition rate, low accuracy rate, total time of recovery and data insufficiency. To address above problem a novel Data Mining technique, Neuro Nearest Neighbour based fingerprint classification and recognition, is introduced which boosts the classification rate. The proposed method consists of different stages such as image enhancement, line detector based feature extraction, neural network classification using Learning vector quantization and Back propagation networks. The proposed system is trained and tested on Fingerprint Database obtained from the University of Bologna Italy, which consists of 900 samples. The exact image is recognized precisely from the classified database rather than the original set of database using Crisp K-Nearest Neighbour algorithm that increases recognition accuracy and reduction in time.	PSG Coll Technol, Coimbatore, Tamil Nadu, India	Umamaheswari, K (reprint author), PSG Coll Technol, Coimbatore, Tamil Nadu, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1991, NEAREST NEIGHBOUR PA; Hong L., 1996, P 1 IEEE WACV SAR FL, P202; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIM YK, 2004, IEEE T ARTIFICIAL IN, V6; Lee HC, 1991, ADV FINGERPRINT TECH; LIN H, 2004, IEEE T PATTERN ANAL, V20; RAO CV, 1980, IEEE T PATTERN ANAL, V2, P23231, DOI UNSP 223231; SHAH PSS, 2004, IEEE T SYSTEMS MAN C, V34; Sumathi S., 2005, INTRO NEURAL NETWORK; Wilson C. L., 1994, Journal of Artificial Neural Networks, V1	13	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0996-9				2006							426	432				7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BGH70	WOS:000247031300086		
S	Xiao, SS; Wu, YX		Tan, J		Xiao, Song-Shan; Wu, Yong-Xing			Rotation-invariant texture analysis using radon and Fourier transforms	4th International Symposium on Instrumentation Science and Technology (ISIST' 2006)	JOURNAL OF PHYSICS CONFERENCE SERIES		English	Proceedings Paper	4th International Symposium on Instrumentation Science and Technology (ISIST '2006)	AUG 08-12, 2006	Harbin, PEOPLES R CHINA	ICMI, NSFC, CSM, CIS, HIT, IC-CSM		texture analysis; rotation invariant; Radon transform Fourier transform	CLASSIFICATION	Texture analysis is a basic issue in image processing and computer vision, and how to attain the Rotation-invariant texture characterization is a key problem. This paper proposes a rotation-invariant texture analysis technique using Radon and Fourier transform. This method uses Radon transform to convert rotation to translation, then utilizes the Fourier transform and takes the modules of the Fourier transform of these functions to make the translation invariant. A k-nearest-neighbor rule is employed to classify textures images. The proposed method is robust to additive white noise as a result of summing pixel values to generate projections in the Radon transform step. To test and evaluate the method, several different kinds of experiments are employed. Experiments results show the feasibility of the proposed method and its robustness to additive white noise.	Tianjin Univ, Coll Precis Instruments & Optoelect Engn, Tianjin 300072, Peoples R China	Xiao, SS (reprint author), Tianjin Univ, Coll Precis Instruments & Optoelect Engn, Tianjin 300072, Peoples R China.						Bracewell, 1995, 2 DIMENSIONAL IMAGIN; BRODATZ P, 1966, PHOTOGRAPHIC ALBUM A; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Greenspan H., 1994, P IEEE INT C IM PROC; HALEY GM, 1995, P IEEE INT C IM PROC; KOUROSH, 2005, IEEE TRANSFORMS IMAG, V14; Kuthirummal S, 2004, PATTERN RECOGN, V37, P739, DOI 10.1016/j.patcog.2003.06.002; Lahajnar F, 2003, PATTERN RECOGN LETT, V24, P1151, DOI 10.1016/S0167-8655(02)00285-4; Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7	10	2	2	2	2	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1742-6588			J PHYS CONF SER			2006	48		1-2				1459	1464		10.1088/1742-6596/48/1/268		6	Instruments & Instrumentation; Physics, Applied	Instruments & Instrumentation; Physics	BGU20	WOS:000250567100267		
S	Aguilar-Ruiz, JS; Nepomuceno, JA; Diaz-Diaz, N; Nepomuceno, I		Ali, M; Dapoigny, R		Aguilar-Ruiz, Jesus S.; Nepomuceno, Juan A.; Diaz-Diaz, Norberto; Nepomuceno, Isabel			A measure for data set editing by ordered projections	ADVANCES IN APPLIED ARTICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	19th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems	JUN 27-30, 2006	Annecy, FRANCE	Univ Savoie, Dept Comp Sci, Int Soc Appl Intelligence, LISTIC/ESIA, AIAA, ACM SIGART, AFIA, CSCSI/SCEIO, ECCAI, ENNS, INNS, JSAI, TAAI, Texas State Univ			NEAREST-NEIGHBOR RULE	In this paper we study a measure, named weakness of an example, which allows us to establish the importance of an example to find representative patterns for the data set editing problem. Our approach consists in reducing the database size without losing information, using algorithm patterns by ordered projections. The idea is to relax the reduction factor with a new parameter, A, removing all examples of the database whose weakness verify a condition over this A. We study how to establish this new parameter. Our experiments have been carried out using all databases from UCI-Repository and they show that is possible a size reduction in complex databases without notoriously increase of the error rate.	Pablo Olavide Univ, Bioinformat Grp Seville, Seville, Spain; Univ Seville, Seville, Spain	Aguilar-Ruiz, JS (reprint author), Pablo Olavide Univ, Bioinformat Grp Seville, Seville, Spain.	direscinf@upo.es; janepo@lsi.us.es; ndiaz@lsi.us.es; isabel@lsi.us.es	Nepomuceno-Chamorro, Isabel /G-4037-2010; Diaz-Diaz, Norberto/G-3309-2013; Aguilar-Ruiz, Jesus/L-9135-2014; 	Nepomuceno-Chamorro, Isabel /0000-0002-4255-7160; Diaz-Diaz, Norberto/0000-0001-8100-8781; Nepomuceno Chamorro, Juan Antonio/0000-0003-2851-951X			AGUILARRUIZ JS, 2000, P 14 EUR C ART INT B, P251; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; Clover T., 1967, IEEE T INFORM THEORY, V13, P21; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOARE CAR, 1962, COMPUT J, V5, P10, DOI 10.1093/comjnl/5.1.10; KLEE V, 1980, ARCH MATH, V34, P75, DOI 10.1007/BF01224932; Neumann J, 2004, LNCS; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; RUIZ R, 2003, LECT NOTES COMPUTER; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; Wilson WW, 2001, RES TRANS E, V6, P1, DOI 10.1016/S0739-8859(01)80004-4	15	1	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-35453-0	LECT NOTES COMPUT SC			2006	4031						1339	1348				10	Computer Science, Artificial Intelligence	Computer Science	BEV62	WOS:000239623800141		
S	Massie, S; Craw, S; Wiratunga, N		RothBerghofer, TR; Goker, MH; Guvenir, HA		Massie, Stewart; Craw, Susan; Wiratunga, Nirmalie			Complexity profiling for informed case-base editing	ADVANCES IN CASE-BASED REASONING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th European Conference on Case-Based Reasoning	SEP 04-07, 2006	Fethiye, TURKEY	DaimlerChrysler, DFKI GmbH, Empolis, Kaidara Software, Microsoft, PricewaterhouseCoopers			NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS	The contents of the case knowledge container is critical to the performance of case-based classification systems. However the knowledge engineer is given little support in the selection of suitable techniques to maintain and monitor the case-base. In this paper we present a novel technique that provides an insight into the structure of a case-base by means of a complexity profile that can assist maintenance decision-making and provide a benchmark to assess future changes to the case-base. We also introduce a complexity-guided redundancy reduction algorithm which uses a local complexity measure to actively retain cases close to boundaries. The algorithm offers control over the balance between maintaining competence and reducing case-base size. The ability of the algorithm to maintain accuracy in a compacted case-base is demonstrated on seven public domain classification datasets.	Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland	Massie, S (reprint author), Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland.	sm@comp.rgu.ac.uk; smc@comp.rgu.ac.uk; nw@comp.rgu.ac.uk		Craw, Susan/0000-0003-1870-0323; Massie, Stewart/0000-0002-5278-4009; Wiratunga, Nirmalie/0000-0003-4040-2496			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; BRIGHTON H, 2001, INSTANCE SELECTION C, P77; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Delany S.J., 2004, P 7 EUR C CAS BAS RE, P128; FRANCIS A, 1993, P WORKSH KNOWL COMP; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; MASSIE S, 2005, P 20 NAT C ART INT, P216; MCKENNA E, 1998, 9 IR C ART INT COGN; McKenna E, 2001, APPL INTELL, V14, P95, DOI 10.1023/A:1008359125752; MCKENNA E, 2000, P 5 EUR WORKSH CAS B, P186; Richter M. M., 1998, Case-based reasoning technology. From foundations to applications; Smyth B., 1995, P 14 INT JOINT C ART, P377; Smyth B., 1996, P392; SMYTH B, 1998, P 4 EUR WORKSH CAS B, P208; SMYTH B, 1999, P 3 INT C CAS BAS RE, P329; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Tomek I., 1976, IEEE T SYST MAN CYB, V7, P679; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	21	7	7	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-36843-4	LECT NOTES ARTIF INT			2006	4106						325	339				15	Computer Science, Artificial Intelligence	Computer Science	BFB81	WOS:000240904600025		
S	Yu, J; Amores, J; Sebe, N; Tian, Q		Hawkes, PW		Yu, Jie; Amores, Jaume; Sebe, Nicu; Tian, Qi			Ranking metrics and evaluation measures	ADVANCES IN IMAGING AND ELECTRON PHYSICS, VOL 144	Advances in Imaging and Electron Physics		English	Review; Book Chapter							IMAGE RETRIEVAL; CLASSIFICATION; SIMILARITY; REPRESENTATION; ALGORITHMS; FEATURES		Univ Texas, Dept Comp Sci, San Antonio, TX 78249 USA; INRIA, IMESIA Res Grp, Rocquencourt, France; Univ Amsterdam, Fac Sci, NL-1012 WX Amsterdam, Netherlands	Yu, J (reprint author), Univ Texas, Dept Comp Sci, San Antonio, TX 78249 USA.						AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; AIGRAIN P, 1987, INT M OPT PUBL STOR, P257; Amores J, 2006, PATTERN RECOGN LETT, V27, P201, DOI 10.1016/j.patrec.2005.08.019; Bar-Hillel A., 2003, P 20 INT C MACH LEAR, P11; CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; DUDA R, 2001, PATTERN CLASSIFICATI, pA3333; FLICKNER M, 1995, IEEE COMPUT, V28, P9; FUKUNAGA K, 1997, IEEE T PATTERN ANAL, V19, P671; GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041; HARALICK R, 1993, COMPUTER ROBOT VISIO, V2, pA3333; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HERTZ T, 2004, IEEE P CVPR, P570; HUBER PJ, 1981, ROBUST STAT, pA3333; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; JOLLIFFE IT, 2002, PRINCIPAL COMPONENT, pA3333; KATO K, 1992, C IM STOR RETR SYST, V1662, P112; LECUN Y, 1998, MNIST DATABASE, pA3333; LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682; MARTINEZ A, 1998, 24 COMP VIS CTR, pA3333; MATAS J, 1999, P INT C PATT REC, P858; Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6; MERZ C, 1998, UCI REPOSITORY MACHI, pA3333; PENG J, 2001, IEEE P CVPR, P940; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Sebe N, 2000, IEEE T PATTERN ANAL, V22, P1132, DOI 10.1109/34.879793; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SMITH JR, 1994, IEEE INT C IM PROC, pA3333; STORK DG, 2004, COMPUTER MANUAL MATL, pA3333; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P1; TANG L, 1994, P NSF ARPA WORKSH PE, pA3333; TIAN Q, 2004, IEEE INT C IM PROC O, pA3333; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/0033-295X.84.4.327; TVERSKY A, 1970, J MATH PSYCHOL, V7, P572, DOI 10.1016/0022-2496(70)90041-6; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WALLACH MA, 1958, PSYCHOL REV, V65, P103, DOI 10.1037/h0042908; Xing EP, 2003, P NIPS, P505; Zakai M., 1964, IEEE T INFORM TH JAN, P94	40	1	1	0	0	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA	1076-5670		0-12-014786-6	ADV IMAG ELECT PHYS	Adv. Imag. Electron Phys.		2006	144						291	316		10.1016/S1076-5670(06)44004-0		26	Physics, Applied	Physics	BFF37	WOS:000241587000004		
S	Zhang, Y; Wu, K; Gao, JF; Vines, P		Lalmas, M; MacFarlane, A; Ruger, S; Tombros, A; Tsikrika, T; Yavlinsky, A		Zhang, Ying; Wu, Ke; Gao, Jianfeng; Vines, Phil			Automatic acquisition of Chinese-English parallel corpus from the web	ADVANCES IN INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	28th European Conference on Information Retrieval (ECIR 2006)	APR   10, 2005-APR 12, 2006	London, ENGLAND	Queen Mary Univ London, City Univ, Engn & Phys Sci Res Council, CEPIS, Google, GCHQ, Microsoft Res, Yahoo Res, Sharp, Apriorie, Lemur Consulting, MMKM, Elsevier	Imperial Coll London, S Kensington			Parallel corpora are a valuable resource for tasks such as cross-language information retrieval and data-driven natural language processing systems. Previously only small scale corpora have been available, thus restricting their practical use. This paper describes a system that overcomes this limitation by automatically collecting high quality parallel bilingual corpora from the web. Previous systems used a single principle feature for parallel web page verification, whereas we use multiple features to identify parallel texts via a k-nearest-neighbor classifier. Our system was evaluated using a data set containing 6500 Chinese-English candidate parallel pairs that have been manually annotated. Experiments show that the use of a k-nearest-neighbors classifier with multiple features achieves substantial improvements over the systems that use any one of these features. The system achieved a precision rate of 95% and a recall rate of 97%, and thus is a significant improvement over earlier work.	RMIT Univ, Melbourne, Vic, Australia; Shanghai Jiao Tong Univ, Shanghai 200030, Peoples R China; Microsoft Res, Redmond, WA 98052 USA	Zhang, Y (reprint author), RMIT Univ, GPO Box 2476V, Melbourne, Vic, Australia.	yzhang@cs.rmit.edu.au; wuke@sjtu.edu.cn; jfgao@microsoft.com; phil@cs.rmit.edu.au					Ballesteros L., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290958; Brown P. F., 1990, Computational Linguistics, V16; CHAU R, 2001, P 1 AS PAC C WEB INT, P340; Chen J., 2004, P 2 WORKSH AUSTR INF, P157; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRANZ M, 2001, P ACM SIGIR C, P398, DOI 10.1145/383952.384037; Kraaij W, 2003, COMPUT LINGUIST, V29, P381, DOI 10.1162/089120103322711587; LOWRANCE R, 1975, J ACM, V22, P177; MCEWAN CJA, 2002, P 24 BCS IRSG EUR C, P303; Nie Jian-Yun, 1999, P 22 ANN INT ACM SIG, P74, DOI 10.1145/312624.312656; Resnik P, 2003, COMPUT LINGUIST, V29, P349, DOI 10.1162/089120103322711578; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403	12	9	10	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33347-9	LECT NOTES COMPUT SC			2006	3936						420	431				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEM01	WOS:000238083200037		
S	Le, SQ; Ho, TB; Vinh, LS		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Le, SQ; Ho, TB; Vinh, LS			Association-based dissimilarity measures for categorical data: Limitation and improvement	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				Measuring the similarity for categorical data is a challenging task in data mining due to the poor structure of categorical data. This paper presents a dissimilarity measure for categorical data based on the relations among attributes. This measure not only has the advantage of value variance but also overcomes the limitations of condition the probability-based measure when applied to databases whose attributes are independent, Experiments with 30 databases also showed that the proposed measure boosted the accuracy of Nearest Neighbor classification in comparison with other tested measures.	Japan Adv Inst Sci & Technol, Tatsunokuchi, Ishikawa 9231292, Japan; LIRMM, Montpellier 5, France; John Von Neumann Inst Comp, Julich, Germany; Amer Museum Nat Hist, New York, NY 10024 USA	Le, SQ (reprint author), Japan Adv Inst Sci & Technol, Tatsunokuchi, Ishikawa 9231292, Japan.	quang@jaist.ac.jp; bao@jaist.ac.jp; vinh@cs.uni-duesseldorf.de	Le, Quang/A-4861-2012	Le, Quang/0000-0001-7881-618X			AONO M, 2004, SURVEY TEXT MINING C, P103; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOODALL DW, 1966, BIOMETRICS, V22, P882, DOI 10.2307/2528080; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; Le SQ, 2005, PATTERN RECOGN LETT, V26, P2549, DOI 10.1016/j.patrec.2005.06.002; LE SQ, 2004, LECT NOTES ARTIF INT, V3056, P580; Liu B., 1998, KNOWLEDGE DISCOVERY, P80	8	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						493	498				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600057		
S	Wang, JG; Neskovic, P; Cooper, LN		Yeung, DS; Liu, ZQ; Wang, XZ; Yan, H		Wang, Jigang; Neskovic, Predrag; Cooper, Leon N.			A statistical confidence-based adaptive nearest neighbor algorithm for pattern classification	ADVANCES IN MACHINE LEARNING AND CYBERNETICS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	Guangzhou, PEOPLES R CHINA	IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany			REGRESSION	The k-nearest neighbor rule is one of the simplest and most attractive pattern classification algorithms. It can be interpreted as an empirical Bayes classifier based on the estimated a posteriori probabilities from the k nearest neighbors. The performance of the k-nearest neighbor rule relies on the locally constant a posteriori probability assumption. This assumption, however, becomes problematic in high dimensional spaces due to the curse of dimensionality. In this paper we introduce a locally adaptive nearest neighbor rule. Instead of using the Euclidean distance to locate the nearest neighbors, the proposed method takes into account the effective influence size of each training example and the statistical confidence with which the label of each training example can be trusted. We test the new method on real-world benchmark datasets and compare it with the standard k-nearest neighbor rule and the support vector machines. The experimental results confirm the effectiveness of the proposed method.	Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA.	jigang@brown.edu; pedja@brown.edu; Leon_Cooper@brown.edu					Blake CL, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E., 1951, 4 USAF SCH AV MED; Friedman J., 1994, 113 STANF U STAT DEP; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	11	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-33584-6	LECT NOTES ARTIF INT			2006	3930						548	557				10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BEN35	WOS:000238282100057		
S	Dai, WY; Yu, Y; Zhang, CL; Han, J; Xue, GR		Yu, JX; Kitsuregawa, M; VaLeong, H		Dai, Wenyuan; Yu, Yong; Zhang, Cong-Le; Han, Jie; Xue, Gui-Rong			A novel web page categorization algorithm based on block propagation using query-log information	ADVANCES IN WEB-AGE INFORMATION MANAGEMENT, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Web-Age Information Management	JUN 17-19, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, City Univ Hong Kong, Hong Kong Baptist Univ, Hong Kong Polytech Univ, Hong Kong Univ Sci & Technol, Univ Hong Kong, Hong Kong Web Soc, Hong Kong Pei Hua Educ Fdn Ltd, IEEE Hong Kong Sect Comp Sci Chapter				Most existing web page classification algorithms, including content-based, link-based, or query-log analysis methods, treat the pages as smallest units. However, web pages usually contain some noisy or biased information which could affect the performance of classification. In this paper, we propose a Block Propagation Categorization (BPC) algorithm which deep mines web structure and views blocks as basic semantic units. Moreover, with query log information, BPC propagates only suitable information (block) among web pages to emphasize their topics. We also optimize the BPC algorithm to significantly speed up the block propagation process, without losing any precision. Our experiments on ODP and MSN search engine log show that BPC achieves a great improvement over traditional approaches.	Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China	Dai, WY (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.	dwyak@apex.sjtu.edu.cn; yyu@apex.sjtu.edu.cn; zhangcongle@apex.sjtu.edu.cn; hanjie@apex.sjtu.edu.cn; grxue@apex.sjtu.edu.cn					Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347176; Chakrabarti S., 2002, MINING WEB DISCOVERI; Chakrabarti S, 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; CHUANG SL, 2003, DECISION SUPPORT SYS, V35; Cohn D, 2001, ADV NEUR IN, V13, P430; Cortes C., 1995, MACH LEARN, V20, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GLOVER EJ, 2002, P WWW 02 INT C WORLD; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; JOACHIMS T, CMUCS96118; LEWIS D, 1991, REPRESENTATION LEARN; LNANG K, 1995, P 12 INT C MACH LEAR, P331; Mitchell T. M., 1997, MACHINE LEARNING; PANTELEEVA N, USING NEIGHBORHOOD I; SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441; Salton G., 1971, SMART RETRIEVAL SYST; Slattery S, 2000, P 17 INT C MACH LEAR, P895; Wang J, 2003, P ACM SIGIR C RES DE, P274; XUE GR, 2004, P 2004 IEEE INT C DA; 杨云峰, 1999, [西安公路交通大学学报, Journal of Xian Highway University], P67; Yang Y., 1997, P 14 INT C MACH LEAR	21	1	1	0	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-35225-2	LECT NOTES COMPUT SC			2006	4016						435	446				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEV90	WOS:000239658700037		
S	Spencer, M; McCullagh, J; Whitfort, T		Sattar, A; Kang, BH		Spencer, Matthew; McCullagh, John; Whitfort, Tim			Clustering data manipulation method for ensembles	AI 2006: Advances in Artificial Intelligence, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	19th Australian Joint Conference on Artificial Intelligence	DEC 04-08, 2006	Hobart, AUSTRALIA			ensemble; data manipulation; clustering		Traditional data manipulation models such as Bagging and Boosting select training cases from throughout the problem space to generate diversity and improve performance. A new data manipulation model is proposed that dynamically assigns specialists to train on difficult clusters of training data. The model allows the expertise of specialists to overlap for difficult regions of the problem.. It has been coupled with a dynamic combination model to exploit the diversity of specialist members. The model has been applied to an environmental problem and has demonstrated that dynamic modelling can enhance both the diversity of members and the accuracy of the ensemble.	La Trobe Univ, Dept Comp Sci & Comp Engn, Bendigo, Vic, Australia	Spencer, M (reprint author), La Trobe Univ, Dept Comp Sci & Comp Engn, Bendigo, Vic, Australia.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; *CLIM CHAN SCI PRO, 2006, STRAT PLAN US CLIM C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); HENDERSON B, 2004, GEODERMA, V124, P383; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Johnston RM, 2003, AUST J SOIL RES, V41, P1021, DOI 10.1071/SR02033; Kuncheva LI, 2003, IBPRIA 1 IB C PATT R, P1126; McQueen J., 1967, 5TH BERK S MATH STAT, V1, P281; Quinlan J. R., 1992, WORLD SCI, P343; SPENCER MJ, 2006, ACST 2006	11	0	0	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-49787-5	LECT NOTES COMPUT SC			2006	4304						1122	1126				5	Computer Science, Artificial Intelligence	Computer Science	BFV69	WOS:000244891200134		
J	Mille, A				Mille, Alain			From case-based reasoning to traces-based reasoning	ANNUAL REVIEWS IN CONTROL			English	Article; Proceedings Paper	9th IFAC Symposium on Automated Systems Based on Human Skill and Knowledge	MAY 22-24, 2006	Nancy, FRANCE	IFAC Tech Comm 9 2		problem solvers; artificial intelligence; knowledge-based systems; knowledge representation	SYSTEMS	CBR is an original At paradigm based on the adaptation of solutions of past problems in order to solve new similar problems. Hence, a case is a problem with its solution and cases are stored in a case library. The reasoning process follows a cycle that facilitates "learning" from new solved cases. This approach can be also viewed as a lazy learning method when applied for task classification. CBR is applied for various tasks as design, planning, diagnosis, information retrieval, etc. The paper is the occasion to go a step further in reusing past Unstructured experience, by considering traces of computer use as experience knowledge containers for situation based problem solving. (C) 2006 Elsevier Ltd. All rights reserved.	Univ Lyon 1, LIRIS, CNRS, UMR 5205, Lyon, France; Univ Lyon 2, Lyon, France	Mille, A (reprint author), Univ Lyon 1, LIRIS, CNRS, UMR 5205, Lyon, France.	alain.mille@liris.cnrs.fr					Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; AAMODT A, 1994, AI COMMUN, V7, P39; BERGMAN R, 2002, EXPERIENCE MANAGEMEN; Bergmann R., 2004, DEV IND CASE BASED R; BRANN DM, 1995, P 1995 INT C SYST MA; CHAMPIN PA, 2003, ICCBR 03 WORKSH STRU, P279; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crevier D, 1993, AI TUMULTUOUS HIST S; Faltings B, 1996, COMPUT AIDED DESIGN, V28, P207, DOI 10.1016/0010-4485(95)00027-5; FUCHS B, 2006, GEN STRATEGY ADAPTAT; FUCHS B, 1995, LECT NOTES ARTIF INT, V1010, P23; HANNEY K, 1995, LECT NOTES ARTIF INT, P461; JURISICA I, 1996, P 5 C DAT KNOWL SYST; Kolodner J., 1985, P IJCAI 85 LOS ANGEL, P284; Kolodner J., 1996, CASE BASED REASONING; Kolodner J. L., 1993, CASE BASED REASONING; Leake D. B., 1996, CASE BASED REASONING; Lenz M., 1998, CASE BASED REASONING; Lopez de Mantaras R., 2006, KNOWL ENG REV, V20, P215; Maher M., 1997, ISSUES APPL CASE BAS; Maher M. L., 1995, CASE BASED REASONING; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; Minsky M, 1974, ARTIFICIAL INTELLIGE; Minsky M., 1975, PSYCHOL COMPUTER VIS; Newell A, 1960, P INT C INF PROC, P256; Portinale L, 2004, ARTIF INTELL, V158, P109, DOI 10.1016/j.artint.2004.05.005; RENAUD J, IN PRESS COLLECTION; Schank R., 1989, INSIDE CASE BASED RE; Schank R., 1982, DYNAMIC MEMORY THEOR; SCHANK RC, 1977, SCRIPTS PLANS GOALS, pCH1; SIMOUDIS E, 1992, IEEE EXPERT, V7, P7, DOI 10.1109/64.163667; THURMAN SDA, 1997, P 1997 IEEE INT C SY; Veloso M, 1996, AI COMMUN, V9, P128; Watson I., 1997, APPL CASE BASED REAS	34	15	16	0	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	1367-5788			ANNU REV CONTROL	Annu. Rev. Control		2006	30	2					223	232		10.1016/j.arcontrol.2006.09.003		10	Automation & Control Systems	Automation & Control Systems	120EG	WOS:000243065900011		
B	Bosin, A; Dessi, N; Pes, B		Ruan, D; DHondt, P; Fantoni, PF; DeCock, M; Nachtegael, M; Kerre, EE		Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara			Learning classifiers for high-dimensional micro-array data	Applied Artificial Intelligence			English	Proceedings Paper	7th International Conference on Fuzzy Logic and Intelligent Technologies in Nuclear Science	AUG 29-31, 2006	Genoa, ITALY				CLASSIFICATION; SELECTION	In this paper, we address the challenging task of learning accurate classifiers from microarray datasets involving a large number of features but only a small number of samples. We present a greedy step-by-step procedure (SSFS) that can be used to reduce the dimensionality of the feature space. We apply the Minimum Description Length principle to the training data for weighting each feature and then select an "Optimal" feature subset by a greedy approach tuned to a specific classifier. The Acute Lymphoblastic Leukemia dataset is used to evaluate the effectiveness of the SSFS procedure in conjunction with different state-of-the-art classification algorithms.	Univ Cagliari, Dept Math & Comp Sci, I-09124 Cagliari, Italy	Bosin, A (reprint author), Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.						Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BOSIN A, 2005, LNAI, V3849; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Golub T.R., 1999, SCIENCE, V286, P531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HARDIMANN G, 2003, MICROARRAY METHODS A; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Liu Huiqing, 2002, Genome Inform, V13, P51; MUKHERJEE S, 2003, CLASSIFYING MICROARR; Vapnik V., 1998, STAT LEARNING THEORY; YARMUS JS, 2003, ABN FAST GREEDY BAYE; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	15	0	0	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			981-256-690-2				2006							593	600		10.1142/9789812774118_0084		8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEU34	WOS:000239525200084		
S	Ben Hariz, S; Elouedi, Z; Mellouli, K		Euzenat, J; Domingue, J		Ben Hariz, Sarra; Elouedi, Zied; Mellouli, Khaled			Clustering approach using belief function theory	ARTIFICIAL INTELLIGENCE: METHODOLOGY, SYSTEMS, AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	12th International Conference on Artificial Intelligence - Methodology, Systems, and Applications	SEP 12-15, 2006	Varna, BULGARIA	Bulgarian Artificial Intelligence Assoc, Inst Informat Technol		machine learning; clustering; K-modes method; uncertainty; belief function theory	CLASSIFICATION; MODEL; RULE	Clustering techniques are considered as efficient tools for partitioning data sets in order to get homogeneous clusters of objects. However, the reality is connected to uncertainty by nature, and these standard algorithms of clustering do not deal with this uncertainty pervaded in their parameters. In this paper we develop a clustering method in an uncertain context based on the K-modes method and the belief function theory. This so-called belief K-modes method (BKM) provides a new clustering technique handling uncertainty in the attribute values of objects in both the clusters' construction task and the classification one.	LARODEC, Inst Super Gest Tunis, Le Bardo 2000, Tunisia	Ben Hariz, S (reprint author), LARODEC, Inst Super Gest Tunis, 41 Ave Liberte, Le Bardo 2000, Tunisia.	sarra.benhariz@gmail.com; zied.eloued@gmx.fr; khaled.mellouli@ihec.rnu.tn					BAUER M, 1993, ARTTIF INTELL, V61, P315; Bosse E., 2001, INFORM FUSION, V2, P91; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Elouedi Z, 2004, IEEE T SYST MAN CY B, V34, P782, DOI 10.1109/TSMCB.2003.817056; Elouedi Z, 2001, INT J APPROX REASON, V28, P91, DOI 10.1016/S0888-613X(01)00045-7; Fixen D., 1997, IEEE T SYST MAN CYB, V27, P96; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain A. K., 1988, ALGORITHMS CLUSTERIN; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Quinlan J. R., 1983, MACHINE LEARNING ART, P463; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED; Shafer G., 1976, MATH THEORY EVIDENCE; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smets P., 1998, HDB DEFEASIBLE REASO, V1, P267; TESSEM B, 1997, INT J APPROX REASON, V17, P217; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	17	9	9	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-40930-0	LECT NOTES COMPUT SC			2006	4183						162	171				10	Computer Science, Artificial Intelligence	Computer Science	BFI88	WOS:000242122400016		
J	Sinha, SK; Fieguth, PW				Sinha, SK; Fieguth, PW			Neuro-fuzzy network for the classification of buried pipe defects	AUTOMATION IN CONSTRUCTION			English	Article						pipeline infrastructure; automated inspection; image processing; segmentation; features; neural network; backpropagation network; neuro-fuzzy projection network	ALGORITHM; SETS	Pipeline infrastructure is decaying at an accelerating rate due to reduced funding and insufficient quality control resulting in poor installation, little or no inspection and maintenance, and a general lack of uniformity and improvement in design, construction and operation practices. The current practice that is being followed to inspect the conditions of pipes is usually time consuming, tedious and expensive. It may also lead to diagnostic errors due to lack of concentration of human operators. Buried pipe defect classification is thus a practical and important pattern classification problem. These defects appear in the form of randomly shaped cracks and holes, broken joints and laterals, and others. This paper proposes a new neuro-fuzzy classifier that combines neural networks and concepts of fuzzy logic for the classification of defects by extracting features in segmented buried pipe images. A comparative evaluation of the K-NN, fuzzy K-NN, conventional backpropagation network, and proposed neuro-fuzzy projection network classifiers is carried out. Among the five neural methods implemented and tested, the proposed neuro-fuzzy classifier performs the best, with classification accuracies around 90% on real concrete pipe images. (c) 2005 Elsevier B.V. All rights reserved.	Penn State Univ, Dept Civil & Environm Engn, University Pk, PA 16802 USA; Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada	Sinha, SK (reprint author), Penn State Univ, Dept Civil & Environm Engn, University Pk, PA 16802 USA.	sunil@engr.psu.edu; pfieguth@uwaterloo.ca					BANKERT RL, 1994, J APPL METEOROL, V33, P909, DOI 10.1175/1520-0450(1994)033<0909:CCOAII>2.0.CO;2; Bezdek J. C., 1981, PATTERN RECOGNITION; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Chae MJ, 2001, J COMPUT CIVIL ENG, V15, P4, DOI 10.1061/(ASCE)0887-3801(2001)15:1(4); CHENG HD, 1996, SPIE P, P140; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dodwell P. C., 1970, VISUAL PATTERN RECOG; DUDA RO, 1970, PATTERN CLASSIFICATI, P271; GNANADESIKAN R, 1977, METHODS STAT DATA AN; Gupta MM, 1979, ADV FUZZY SET THEORY; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hunt E., 1975, ARTIFICIAL INTELLIGE; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Kandel A, 1982, FUZZY TECHNIQUES PAT; Kaseko M. S., 1993, Transportation Research Part C (Emerging Technologies), V1C, DOI 10.1016/0968-090X(93)90002-W; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T., 1995, SELF ORG MAPS; Lin C.T., 1996, NEURO FUZZY SYSTEMS; Mehrotra K., 1997, ELEMENTS ARTIFICIAL; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Moselhi O., 2000, J INFRASTRUCT SYST, P97, DOI [10.1061/(ASCE)1076-0342(2000)6:3(97), DOI 10.1061/(ASCE)1076-0342(2000)6:3]; Moselhi O., 1999, Automation in Construction, V8, DOI 10.1016/S0926-5805(99)00007-2; PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058; Pineda F. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.161; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Powell MJD, 1987, RADIAL BASIS FUNCTIO; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; REYNOLDS AG, 1977, COGNITIVE PSYCHOL; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAFFREY J, 1991, P 1991 INT JOINT C N, V2, P441; Schalkoff R.J., 1992, PATTERN RECOGNITION; SHAIKH MA, 1996, P IGRASS 96, P1105; Sinha SK, 2002, IEEE T NEURAL NETWOR, V13, P393, DOI 10.1109/72.991425; SINHA SK, IN PRESS AUTOMATION; SINHA SK, 2000, THESIS U WATERLOO; SPOEHR KT, 1982, VISUAL INFORMATION P; TELFER B, 1991, P INT JOINT C NEUR N, V2, P89; WARDLE A, 1978, METHOD INFORM MED, V17, P15; Werbos P., 1974, THESIS HARVARD; WILENSKY GD, 1992, P INT JOINT C NEUR N, V2, P358, DOI 10.1109/IJCNN.1992.226961; WINSTON PH, 1977, ARTIFICIAL INTELLIGE; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	42	26	26	0	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0926-5805			AUTOMAT CONSTR	Autom. Constr.	JAN	2006	15	1					73	83		10.1016/j.autcon.2005.02.005		11	Construction & Building Technology; Engineering, Civil	Construction & Building Technology; Engineering	981YU	WOS:000233124700007		
B	Yang, JY; Yang, MQ			IEEE COMPUTER SOC	Yang, Jack Y.; Yang, Mary Qu			Assessing protein function using a combination of supervised and unsupervised learning	BIBE 2006: Sixth IEEE Symposium on Bioinformatics and BioEngineering, Proceedings			English	Proceedings Paper	6th IEEE Syposium on BioInformatics and BioEngineering (BIBE 2006)	OCT 16-18, 2006	Arlington, VA	IEEE Comp Soc, Biol & Artificial Intelligence Soc, ITRI				The determination of protein function using experimental techniques is time-consuming and expensive; the use of machine learning techniques to rapidly assess protein function may be useful in streamlining this process. The problem of assigning functional classes to proteins is complicated by the fact that a single protein can participate in several different pathways and thus can have multiple functions. It follows that the instances in the resulting classification problem can carry multiple class labels. We have developed a tree-based classifier that capable of handling multiply-labeled data: we call the resulting tree a Recursive Maximum-Contrast Tree (RMCT). The name derives from the way in which nodes in the tree are split; this is done by selecting the two training instances with maximum contrast (that is, the two training instances with maximum separation according to some distance measure) and using them as seeds in a clustering algorithm to form a partition of the training instances and hence of the feature space. We test our algorithm on protein phylogenetic profiles generated from 60 completely sequenced genomes, and we compare our results to those achieved using existing algorithms such as support vector machines and decision trees.	Harvard Univ, Sch Med, Dept Radiat Oncol, Boston, MA 02114 USA	Yang, JY (reprint author), Harvard Univ, Sch Med, Dept Radiat Oncol, Boston, MA 02114 USA.						Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; CHO S, 1993, IEEE T CIRCUITS-II, V40, P556, DOI 10.1109/82.257333; CODRINGTON CW, 1997, THESIS PURDUE U; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fix E., 1951, 2149004 USAF SCH AV; Joachims T, 2002, LEARNING CLASSIFY TE; Neuhaus D., 2000, NUCL OVERHAUSER EFFE, V2nd; Pavlidis P., 2001, RECOMB 2001, P249; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan J.R., DATA MINING TOOLS SE; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Vert Jean-Philippe, 2002, Bioinformatics, V18 Suppl 1, pS276; YANG JY, 2003, P ART NEUR NETW ENG; YANG MQ, 2004, P ART NEUR NETW ENG	16	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2727-2				2006							35	41				7	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BFK64	WOS:000242503800005		
S	Chen, TS; Lin, CC; Chiu, YH; Lin, HL; Chen, RC		Huang, DS; Li, K; Irwin, GW		Chen, Tung-Shou; Lin, Chih-Chiang; Chiu, Yung-Hsing; Lin, Hsin-Lan; Chen, Rong-Chang			A new binary classifier: Clustering-launched classification	COMPUTATIONAL INTELLIGENCE, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	International Conference on Intelligent Computing (ICIC)	AUG 16-19, 2006	Kunming, PEOPLES R CHINA	IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Sci Fdn China				One of the powerful classifiers is Support Vector Machine (SVM), which has been successfully applied to many fields. Despite its remarkable achievement, SVM is time-consuming in many situations where the data distribution is unknown, causing it to spend much time on selecting a suitable kernel and setting parameters. Previous studies proposed understanding the data distribution before classification would assist the classification. In this paper, we exquisitely combined with clustering and classification to develop a novel classifier, Clustering-Launched Classification (CLC), which only needs one parameter. CLC employs clustering to group data to characterize the features of the data and then adopts the one-against-the-rest and nearest-neighbor to find the support vectors. In our experiments, CLC is compared with two well-known SVM tools: LIBSVM and mySVM. The accuracy of CLC is comparable to LIBSVM and mySVM. Furthermore, CLC is insensitive to parameter, while the SVM is sensitive, showing CLC is easier to use.	Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung, Taiwan; Natl Taichung Inst Technol, Grad Sch Business Adm, Taichung, Taiwan; Natl Taichung Inst Technol, Dept Logist Engn & Management, Taichung, Taiwan	Chen, RC (reprint author), Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung, Taiwan.	tschen@ntit.edu.tw; s18933102@ntit.edu.tw; s18943108@ntit.edu.tw; s18941113@ntit.edu.tw; rcchens@ntit.edu.tw					Chang C.C., 2001, LIBSVM LIB SUPPORT V; CHANG CC, 2001, LIBSVM LIB SUPPORT V, P20; Chen RC, 2006, INT J PATTERN RECOGN, V20, P227, DOI 10.1142/S0218001406004624; CHEN RC, 2005, LECT NOTES COMPUTER, P916; CHEN RC, 2005, LNCS, P409; CHEN RC, 2004, LECT NOTES COMPUTER, P800; CHEN TS, 2003, P INT C INF CYB SYST, P1532; Chen TS, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P485; Chen T.-S., 2005, P 2005 INT S INT SIG, P405; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNHAM MH, 2003, DATA MING INTRO ADV; Han J., 2000, DATA MINING CONCEPTS; Liang X, 2005, LECT NOTES ARTIF INT, V3584, P761; Newman D., 1998, UCI REPOSITORY MACHI; QIAO H, 2004, P 2004 IEEE RSJ INT, V2, P2015; Roiger R., 2003, DATA MINING TUTORIAL; RUPING S, 2000, MYSVM MANUAL, V8, P21; Sun BY, 2005, IEEE SIGNAL PROC LET, V12, P101, DOI 10.1109/LSP.2004.836938; Vapnik V. N., 1995, NATURE STAT LEARNING; ZHAO XM, 2004, LECT NOTES COMPUTER, P11	20	7	7	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-37274-1	LECT NOTES ARTIF INT			2006	4114						278	283				6	Computer Science, Artificial Intelligence	Computer Science	BEY13	WOS:000240083300035		
S	Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Qu, YL; Dong, HB		Alexandrov, VN; VanAlbada, GD; Sloot, PMA; Dongarra, J		Shang, Wenqian; Huang, Houkuan; Zhu, Haibin; Lin, Yongmin; Qu, Youli; Dong, Hongbin			An adaptive fuzzy kNN text classifier	COMPUTATIONAL SCIENCE - ICCS 2006, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Conference on Computational Science (ICCS 2006)	MAY 28-31, 2006	Reading, ENGLAND	Intel Corp, IBM, SGI, Microsoft Res, EPSRC, Springer, ACET Ctr, Univ Reading, SIAM, IMACS, UK e Sci Programme			NEAREST NEIGHBOR; CATEGORIZATION	In recent years, kNN algorithm is paid attention by many researchers and is proved one of the best text categorization algorithms. Text categorization is according to training set which is assigned class label to decide a new document which is not assigned class label belongs to some kind of document. Until now, kNN algorithm has still some issues to need to study further. Such as: improvement of decision rule; selection of k value; selection of dimensions (i.e. feature set selection); problems of multiclass text categorization; the algorithm's executive efficiency (time and space) etc. In this paper, we mainly focus on improvement of decision rule and dimension selection. We design an adaptive fuzzy kNN text classifier. Here the adaptive indicate the adaptive of dimension selection. The experiment results show that our algorithm is effective and feasible.	Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China	Shang, WQ (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	shangwenqian@hotmail.com; haibinz@npissingu.ca					APTE C, 1998, P C AUT LEARN DISC W, P487; BIAN J, 2000, PATTERN RECOGNITION; Cardoso-Cachopo A, 2003, LECT NOTES COMPUT SC, V2857, P183; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D., 1980, FUZZY SETS SYSTEMS T; Han E.H., 2001, P 5 PAC AS C KNOWL D, P53; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Li B, 2004, ACM T ASIAN LANGUAGE, V3, P215; LIM H, 2002, P 9 INT C NEUR INF P, P731; MASAND B, 1992, 15 ANN INT ACM SIGIR, P59; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Ng H.T., 1997, 20 ANN INT ACM SIGIR, P67; SHANKAR S, 2000, P INT WORKSH MULT DA; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Wiener E, 1995, P 4 ANN S DOC AN INF, P317; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; YANG Y, 1997, EVALUATION STAT APPR, V1, P76; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; ZHAO S, 1987, METHOD FUZZY MATH PA	21	3	3	0	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-34383-0	LECT NOTES COMPUT SC			2006	3993						216	223				8	Computer Science, Theory & Methods	Computer Science	BEO20	WOS:000238417300030		
S	Martinez-Otzeta, JM; Sierra, B; Lazkano, E; Astigarraga, A		Williams, GJ; Simoff, SJ		Martinez-Otzeta, JM; Sierra, B; Lazkano, E; Astigarraga, A			K nearest neighbor edition to guide classification tree learning: Motivation and experimental results	DATA MINING: THEORY, METHODOLOGY, TECHNIQUES, AND APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article						machine learning; supervised classification; classifier combination; classification trees	FEATURE SUBSET-SELECTION; INTENSIVE-CARE-UNIT; BAYESIAN NETWORKS; COMBINATION; CLASSIFIERS; ALGORITHMS	This paper presents a new hybrid classifier that combines the Nearest Neighbor distance based algorithm with the Classification Tree paradigm. The Nearest Neighbor algorithm is used as a preprocessing algorithm in order to obtain a modified training database for the posterior learning of the classification tree structure; experimental section shows the results obtained by the new algorithm; comparing these results with those obtained by the classification trees when induced from the original training data we obtain that the new approach performs better or equal according to the Wilcoxon signed rank statistical test.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, San Sebastian 20018, Spain	Martinez-Otzeta, JM (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, P Manuel Lardizabal 1, San Sebastian 20018, Spain.	ccbmaotj@si.ehu.es	Martinez-Otzeta, Jose Maria/K-6464-2014	Martinez-Otzeta, Jose Maria/0000-0001-5015-1315			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Blake C, 1998, UCI REPOSITORY MACHI; Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowell R. G., 1999, PROBABILISTIC NETWOR; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Dietterich TG, 1997, AI MAG, V18, P97; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; GAMA J, 2000, COMBINING CLASSIFICA; Gunes V, 2003, INT J PATTERN RECOGN, V17, P1303, DOI 10.1142/S0218001403002897; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; Kohavi R, 1996, P 2 INT C KNOWL DISC; Lu Y, 1996, APPL INTELL, V6, P75, DOI 10.1007/BF00117809; MARTIN JK, 1997, MACHINE LEARNING, V28; Martin PD, 2004, HA CL HE PS, V2, P233; Michie D., 1995, MACHINE LEARNING NEU; MINGERS J, 1988, COMPARISON METHODS P, V1; Mitchell T. M., 1997, MACHINE LEARNING; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; PEARL J, 1987, ARTIF INTELL, V32, P245, DOI 10.1016/0004-3702(87)90012-9; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sierra B, 2001, ARTIF INTELL MED, V22, P233, DOI 10.1016/S0933-3657(00)00111-1; Sierra B, 2001, LECT NOTES ARTIF INT, V2101, P20; Sierra B., 2002, Knowledge-Based Intelligent Information Engineering Systems and Allied Technologies. KES 2002; Sierra B, 1999, LECT NOTES ARTIF INT, V1620, P366; STONE M, 1974, J R STAT SOC B, V36, P111; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	32	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-32547-6	LECT NOTES ARTIF INT			2006	3755						53	63				11	Computer Science, Artificial Intelligence	Computer Science	BEB23	WOS:000236545100005		
J	Hao, YL; Quirchmayr, G; Stumptner, M				Hao, YL; Quirchmayr, G; Stumptner, M			Mining MOUCLAS patterns and jumping MOUCLAS patterns to construct classifiers	DATA MINING: THEORY, METHODOLOGY, TECHNIQUES, AND APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article								This paper proposes a mining novel approach which consists of two new data mining algorithms for the classification over quantitative data, based on two new pattern called MOUCLAS (MOUntain function based CLASsification) Patterns and Jumping MOUCLAS Patterns. The motivation of the study is to develop two classifiers for quantitative attributes by the concepts of the association rule and the clustering. An illustration of using petroleum well logging data for oil/gas formation identification is presented in the paper. MPs and JMPs are ideally suitable to derive the implicit relationship between measured values (well logging data) and properties to be predicted (oil/gas formation or not). As a hybrid of classification and clustering and association rules mining, our approach have several advantages which are (1) it has a solid mathematical foundation and compact mathematical description of classifiers, (2) it does not require discretization, (3) it is robust when handling noisy or incomplete data in high dimensional data space.	Univ Vienna, Inst Informat & Wirtschaftsinformat, A-1010 Vienna, Austria		Yalei.Hao@postgrads.unisa.edu.au; Gerald.Quirchmayr@unisa.edu.au; mst@cs.unisa.edu.au	Stumptner, Markus/B-5558-2009				Agrawal R, 1994, P 20 INT C VER LARG, P487; AGRAWAL R, 1998, SIGMOD 98; AHMED KM, 2000, P SIGKDD EXPLORATION, V1, P46; Chiu S., 1994, J INTELLIGENT FUZZY, V2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG G, 1997, INTELLIGENT DATA ANA, P1; DOUGHERTY J, 1995, P 12 INT C MACH LEAR, P94; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fayyad U.M., 1996, ADV KNOWLEDGE DISCOV, P1; Han J., 2000, DATA MINING CONCEPTS; Hinneburg A., 1998, KNOWLEDGE DISCOVERY, P58; Jinyan Li, 2001, KNOWL INF SYST, V3, P131, DOI DOI 10.1007/PL00011662; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LENT B, 1997, ICDE, P220; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; Liu Bing, 1999, P ACM SIGKDD INT C K; Liu H., 1998, FEATURE SELECTION KN; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SARAWAGI W, 1988, INT J PATTERN RECOGN, V2, P197; SKIKANT R, 1996, SIG MOD 96, P1; Yager R., 1994, J INTELL FUZZY SYST, V2, P209	22	0	0	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743			LECT NOTES ARTIF INT			2006	3755						118	129				12	Computer Science, Artificial Intelligence	Computer Science	BEB23	WOS:000236545100010		
S	Naiman, DQ		Kimmel, A; Oluver, B		Naiman, Daniel Q.			Random data set generation to support microarray analysis	DNA MICROARRAYS, PART B: DATABASES AND STATISTICS	Methods in Enzymology		English	Review; Book Chapter							GENE-EXPRESSION; CLASSIFICATION; ASSOCIATION; VALIDATION; DIAGNOSIS; INFERENCE	As microarray analyses become increasingly routine, involving the simultaneous investigation of huge numbers of genes, researchers can easily search for and uncover what appear to be promising patterns in their data. In such circumstances tools are needed to help decide the extent to which these patterns are meaningful or can be explained by chance alone. The purpose of this chapter is to describe examples of the use of microarray analysis for inferential purposes and how validation of inference is addressed by Monte-Carlo techniques, which essentially amounts to investigation of statistical methods on synthetic or random data sets.	Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD USA	Naiman, DQ (reprint author), Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD USA.						Cardon LR, 2001, NAT REV GENET, V2, P91, DOI 10.1038/35052543; Chen M.-H., 2001, MONTE CARLO METHODS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1979, SIAM NSF CBMS MONOGR, V38; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Ernst MD, 2004, STAT SCI, V19, P676, DOI 10.1214/088342304000000396; Fishman G. S., 1996, MONTE CARLO CONCEPTS; FRIEDMAN J, 1996, J DATA MINING KNOWLE, V1, P55; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GEMAN D, 2004, STAT APPL GENET MICR, V3; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hall P, 1992, BOOTSTRAP EDGEWORTH; Hinkley DV, 1997, BOOTSTRAP METHODS TH; Kohavi R., 1996, MACH LEARN P 13 INT; Kreiner T, 2005, AM J HEALTH-SYST PH, V62, P296; KULLDORFF M, 1995, STAT MED, V14, P799, DOI 10.1002/sim.4780140809; LePage R., 1992, EXPLORING LIMITS BOO; Naiman DQ, 2001, J COMPUT GRAPH STAT, V10, P296, DOI 10.1198/10618600152628194; Ott J., 1991, ANAL HUMAN GENETIC L; Parisi M, 2003, SCIENCE, V299, P697, DOI 10.1126/science.1079190; Sham P, 2002, NAT REV GENET, V3, P862, DOI 10.1038/nrg930; Shao J., 1995, JACKKNIFE BOOTSTRAP; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tibshirani R, 1993, INTRO BOOTSTRAP	28	2	2	1	1	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA	0076-6879		978-0-12-182816-5	METHOD ENZYMOL	Methods Enzymol.		2006	411						312	325		10.1016/S0076-6879(06)11016-2		14	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	BFT40	WOS:000244506300016	16939797	
S	Baird, HS; Moll, MA; Nonnemaker, J; Casey, MR; Delorenzo, DL		Taghva, K; Lin, X		Baird, Henry S.; Moll, Michael A.; Nonnemaker, Jean; Casey, Matthew R.; Delorenzo, Don L.			Versatile document image content extraction - art. no. 60670R	Document Recognition and Retrieval XIII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Document Recognition and Retrieval XIII	JAN 18-19, 2006	San Jose, CA	Soc Imaging Sci & Technol, SPIE		Bayes decision theory; classification; k Nearest Neighbors; k-d trees; CART; spatial data structures; computational geometry; hashing	BINARY SEARCH TREES	We offer a preliminary, report on a research pro-ram to investigate versatile algorithms for document image content extraction. that is locating re-ions containing handwriting, machine-print text, graphics, line-art, logos, photographs, noise, etc. To solve this problem in its full generality requires coping with a vast diversity of document and image types. Automatically trainable methods are highly desirable, as well as extremely high speed in order to process large collections. Significant obstacles include the expense of preparing correctly labeled ("ground-truthed") samples, unresolved methodological questions in specifying the domain (e.g. what is a representative collection of document images?), and a lack of consensus among researchers on how to evaluate content-extraction performance. Our research strategy emphasizes versatility first: that is, we concentrate at the outset on designing methods that promise to work across the broadest possible range of cases. This strategy, has several important implications: the classifiers must be trainable in reasonable time on vast data sets: and expensive ground-truthed data sets must be complemented by amplification using generative models. These and other design and architectural issues are discussed. We propose a trainable classification methodology that marries k-d trees and hash-driven table lookup and describe preliminary experiments.	Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18017 USA	Baird, HS (reprint author), Lehigh Univ, Dept Comp Sci & Engn, 19 Mem Dr W, Bethlehem, PA 18017 USA.						BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BENTLEY J. L., 1975, COMMUN ACM, V18, P509; Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M., 2004, P S COMP GEOM; Duda R O, 2001, PATTERN CLASSIFICATI; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; Freidman J. H., 1977, ACM T MATH SOFTWARE, V3, P209, DOI DOI 10.1145/355744.355745; Gionis A., 1999, P 25 INT C VER LARG, P518; Ho TK, 1997, IEEE T PATTERN ANAL, V19, P1067; LEE DT, 1977, ACTA INFORM, V9, P23; Samet H., 1990, DESIGN ANAL SPATIAL; Weber R., 1998, P 24 INT C VER LARG; Yuval G., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90064-8	14	0	0	0	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-6107-5	P SOC PHOTO-OPT INS			2006	6067						R670	R670	60670R	10.1117/12.650359		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEF49	WOS:000237093200025		
J	Gibert, K; Sanchez-Marre, M; Rodriguez-Roda, I				Gibert, K; Sanchez-Marre, M; Rodriguez-Roda, I			GESCONDA: An intelligent data analysis system for knowledge discovery and management in environmental databases	ENVIRONMENTAL MODELLING & SOFTWARE			English	Article						knowledge acquisition and management; data mining; machine learning; environmental databases	CLASSIFICATION; WWTP	In this work the GESCONDA software is presented. It is a tool for intelligent data analysis and implicit knowledge management of databases, with special focus on environmental databases. Differing from existing commercial systems, the more relevant aspects of this proposal are the incorporation of the statistical data filtering and pre-processing in the same software tool together with the intelligent data analysis techniques as well as the interaction of different data mining methods. Either statistical techniques or artificial intelligence techniques or even mixed techniques are combined and used to extract the knowledge contained within data. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Politecn Catalunya, Dept Stat & Operat Res, E-08028 Barcelona, Catalonia, Spain; Univ Politecn Catalunya, Knowledge Engn & Machine Learning Grp, ES-08034 Barcelona, Catalonia, Spain; Univ Girona, Lab Engn Quim & Ambiental, Girona 17071, Catalonia, Spain	Gibert, K (reprint author), Univ Politecn Catalunya, Dept Stat & Operat Res, C Pau Gargallo 5, E-08028 Barcelona, Catalonia, Spain.	karina@eio.upc.es; miquel@lsi.upc.es; ignasi@lequia.udg.es	Sanchez-Marre, Miquel/A-8569-2011; Rodriguez-Roda, Ignasi/D-4817-2015; 	Rodriguez-Roda, Ignasi/0000-0002-8989-9061; Sanchez-Marre, Miquel/0000-0001-9848-5779			Ball GH., 1965, ISODATA NOVEL METHOD; BRATKO I, 2000, ANAL ENV DATA MACHIN; Breiman L., 1984, CLASSIFICATION REGRE; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Comas J, 2001, AI COMMUN, V14, P45; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1996, MACH LEARN, V24, P141; Frank E., 1999, DATA MINING PRACTICA; GIBERT K, 2004, TENDENCIAS MINERIA D, P119; Gibert K, 1998, COMPUT SIST, V1, P213; GIBERT K, 1998, LECT NOTES ARTIF INT, V510, P83; GIBERT K, 2004, 4 ECAI WORKSH BIND E; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Kanevski M, 2004, ENVIRON MODELL SOFTW, V19, P845, DOI 10.1016/j.envsoft.2003.03.004; LEBART, 1985, TRATAMIENTO ESTADIST; MCKUSICK K, 1990, FIA9061812 NASA AM R; MORABITO FC, 2001, NATO ADV RES WORKSH; PHAM, 1995, RULES SIMPLE RULER E, V8; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Rodriguez-Roda I, 2002, WATER SCI TECHNOL, V45, P289; Sanchez M, 1997, APPL INTELL, V7, P147, DOI 10.1023/A:1008202113300; SANCHEZMARRE M, 2002, INTEGRATED ASSESSMEN, V3, P420; Sanchez-Marre M, 1999, ENVIRON MODELL SOFTW, V14, P349, DOI 10.1016/S1364-8152(98)00097-8	25	16	17	3	7	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1364-8152			ENVIRON MODELL SOFTW	Environ. Modell. Softw.	JAN	2006	21	1					115	120		10.1016/j.envsoft.2005.01.004		6	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Sciences	Computer Science; Engineering; Environmental Sciences & Ecology	002SO	WOS:000234631900011		
J	Okun, O; Priisalu, H				Okun, Oleg; Priisalu, Helen			Fast nonnegative matrix factorization and its application for protein fold recognition	EURASIP JOURNAL ON APPLIED SIGNAL PROCESSING			English	Article							NEURAL-NETWORKS; CLASSIFICATION; ALGORITHMS	Linear and unsupervised dimensionality reduction via matrix factorization with nonnegativity constraints is studied. Because of these constraints, it stands apart from other linear dimensionality reduction methods. Here we explore nonnegative matrix factorization in combination with three nearest-neighbor classifiers for protein fold recognition. Since typically matrix factorization is iteratively done, convergence, can be slow. To speed up convergence, we perform feature scaling ( normalization) prior to the beginning of iterations. This results in a significantly ( more than 11 times) faster algorithm. Justification of why it happens is provided. Another modification of the standard nonnegative matrix factorization algorithm is concerned with combining two known techniques for mapping unseen data. This operation is typically necessary before classifying the data in low-dimensional space. Combining two mapping techniques can yield better accuracy than using either technique alone. The gains, however, depend on the state of the random number generator used for initialization of iterations, a classifier, and its parameters. In particular, when employing the best out of three classifiers and reducing the original dimensionality by around 30%, these gains can reach more than 4%, compared to the classification in the original, high-dimensional space. Copyright (C) 2006 Hindawi Publishing Corporation. All rights reserved.	Univ Oulu, Machine Vis Grp, Infotech Oulu, Oulu 90014, Finland; Univ Oulu, Dept Elect & Informat Engn, Oulu 90014, Finland	Okun, O (reprint author), Univ Oulu, Machine Vis Grp, Infotech Oulu, POB 4500, Oulu 90014, Finland.						Behnke S., 2003, P INT JOINT C NEUR N, V4, P2758, DOI 10.1109/IJCNN.2003.1224004; BOLOGNA G, 2002, P 9 INT C NEUR INF P, V5, P2492; BUCIU I, 2004, P 17 INT C PATT REC, V1, P288; CHEN X, 2001, P IEEE COMP SOC C CO, V1, pI1126; Cho YC, 2003, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P633; Chung IF, 2003, LECT NOTES COMPUT SC, V2714, P1159; COMMON P, 1991, P I WORKSH HIGH ORD, P111; Cooper M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P25; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Feng T., 2002, P 2 INT C DEV LEARN, P178; Guillamet D, 2003, PATTERN RECOGN LETT, V24, P1599, DOI 10.1016/S0167-8655(02)00399-9; Guillamet D., 2001, Proceedings 11th International Conference on Image Analysis and Processing, DOI 10.1109/ICIAP.2001.957018; Guillamet D, 2003, PATTERN RECOGN LETT, V24, P2447, DOI 10.1016/S0167-8655(03)00089-8; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Huang CD, 2003, LECT NOTES COMPUT SC, V2714, P1168; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lawrence J, 2004, ACM T GRAPHIC, V23, P496, DOI 10.1145/1015706.1015751; Lee DD, 2001, ADV NEUR IN, V13, P556; Lee DD, 1999, NATURE, V401, P788; LI Y, 2003, P 7 INT S SIGN PROC, V1, P57; Liu W. Z., 2003, P IEEE INT C AC SPEE, V3, P293; Lo Conte L, 2000, NUCLEIC ACIDS RES, V28, P257, DOI 10.1093/nar/28.1.257; Lu J., 2003, P IEEE WIC INT C WEB, P405; Mao Yun, 2004, P 4 ACM SIGCOMM C IN, P278, DOI 10.1145/1028788.1028827; NOVAK M, 2001, P 2001 IEEE C AC SPE, V1, P541; Okun O., 2004, P 11 FINN ART INT C, P207; OKUN O, 2004, P 2 EUR WORKSH DAT M, P47; Okun OG, 2004, Proceedings of the Fourth IASTED International Conference on Visualization, Imaging, and Image Processing, P550; Okun O. G., 2006, Pattern Recognition and Image Analysis, V16, DOI 10.1134/S1054661806010068; Pal NR, 2003, LECT NOTES COMPUT SC, V2714, P1176; Plumbley MD, 2004, IEEE T NEURAL NETWOR, V15, P66, DOI 10.1109/TNN.2003.820672; Rajapakse M., 2003, P 3 INT S IM SIGN PR, V2, P605; Ramanath R, 2003, P 32 APPL IM PATT RE, P33; Saul LK, 2002, ADV NEUR IN, V14, P897; Smaragdis P., 2003, P IEEE WORKSH APPL S, P177, DOI DOI 10.1109/ASPAA.2003.1285860; Tsuge S., 2001, P IEEE INT C SYST MA, V2, P960; Vincent P, 2002, ADV NEUR IN, V14, P985; WANG Y, 2004, P 6 AS C COMP VIS JE; Xu BW, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P273; Yu K, 2002, NEURAL PROCESS LETT, V15, P147, DOI 10.1023/A:1015244902967	42	7	8	1	4	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-8657			EURASIP J APPL SIG P	EURASIP J Appl. Signal Process.		2006									71817	10.1155/ASP/2006/71817		8	Engineering, Electrical & Electronic	Engineering	106DF	WOS:000242080500001		
J	Phan, JH; Quo, CF; Wang, MD				Phan, John H.; Quo, Chang-Feng; Wang, May D.			Functional genomics and proteomics in the clinical neurosciences: data mining and bioinformatics	FUNCTIONAL GENOMICS AND PROTEOMICS IN THE CLINICAL NEUROSCIENCES	PROGRESS IN BRAIN RESEARCH		English	Review							MICROARRAY EXPRESSION DATA; TANDEM MASS-SPECTRA; CROSS-VALIDATION; GENE-EXPRESSION; PATTERN-CLASSIFICATION; CANCER CLASSIFICATION; SELECTION; IDENTIFICATION; NORMALIZATION; ERROR	The goal of this chapter is to introduce some of the available computational methods for expression analysis. Genomic and proteomic experimental techniques are briefly discussed to help the reader understand these methods and results better in context with the biological significance. Furthermore, a case study is presented that will illustrate the use of these analytical methods to extract significant biomarkers from high-throughput microarray data. Genomic and proteomic data analysis is essential for understanding the underlying factors that are involved in human disease. Currently, such experimental data are generally obtained by high-throughput microarray or mass spectrometry technologies among others. The sheer amount of raw data obtained using these methods warrants specialized computational methods for data analysis. Biomarker discovery for neurological diagnosis and prognosis is one such example. By extracting significant genomic and proteomlic biomarkers in controlled experiments, we come closer to understanding how biological mechanisms contribute to neural degenerative diseases such as Alzheimers' and how drug treatments interact with the nervous system. In the biomarker discovery process, there are several computational methods that must be carefully considered to accurately analyze genomic or proteomic data. These methods include quality control, clustering, classification, feature ranking, and validation. Data quality control and normalization methods reduce technical variability and ensure that discovered biomarkers are statistically significant. Preprocessing steps must be carefully selected since they may adversely affect the results of the following expression analysis steps, which generally fall into two categories: unsupervised and supervised. Unsupervised or clustering methods can be used to group similar genomic or proteomic profiles and therefore can elucidate relationships within sample groups. These methods can also assign biomarkers to sub-groups based on their expression profiles across patient samples. Although clustering is useful for exploratory analysis, it is limited due to its inability to incorporate expert knowledge. On the other hand, classification and feature ranking are supervised, knowledge-based machine learning methods that estimate the distribution of biological expression data and, in doing so, can extract important information about these experiments. Classification is closely coupled with feature ranking, which is essentially a data reduction method that uses classification error estimation or other statistical tests to score features. Biomarkers can subsequently be extracted by eliminating insignificantly ranked features. These analytical methods may be equally applied to genetic and proteomic data. However, because of both biological differences between the data sources and technical differences between the experimental methods used to obtain these data, it is important to have a firm understanding of the data sources and experimental methods. At the same time, regardless of the data quality, it is inevitable that some discovered biomarkers are false positives. Thus, it is important to validate discovered biomarkers. The validation process may be slow; yet, the overall biomarker discovery process is significantly accelerated due to initial feature ranking and data reduction steps. Information obtained from the validation process may also be used to refine data analysis procedures for future iteration. Biomarker validation may be performed in a number of ways - bench-side in traditional labs, web-based electronic resources such as gene ontology and literature databases, and clinical trials.	Georgia Inst Technol, Wallace H Coulter Dept Biomed Engn, Atlanta, GA 30322 USA; Emory Univ, Atlanta, GA 30322 USA	Wang, MD (reprint author), Georgia Inst Technol, Wallace H Coulter Dept Biomed Engn, Atlanta, GA 30322 USA.	maywang@bme.gatech.edu					Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Ashburner M, 2000, NAT GENET, V25, P25; Bern M, 2004, BIOINFORMATICS, V20, P49, DOI 10.1093/bioinformatics/bth947; *BIOAN RES GROUP, 2005, PEPTIDESEARCH FINGER; *BIOINF LINKS DIR, 2005, PROT INT PATHW ENZ; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Braga-Neto U, 2004, PATTERN RECOGN, V37, P1267, DOI 10.1016/j.patcog.2003.08.017; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; Bruni R, 2005, J PEPT SCI, V11, P225, DOI 10.1002/psc.595; Cheng C-C., 2001, LIBSVM LIB SUPPORT V; Chilingaryan A, 2002, MATH BIOSCI, V176, P59, DOI 10.1016/S0025-5564(01)00105-5; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P403; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devore Jay L, 2004, PROBABILITY STAT ENG; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Elias JE, 2004, NAT BIOTECHNOL, V22, P214, DOI 10.1038/nbt930; Espina V, 2003, PROTEOMICS, V3, P2091, DOI 10.1002/pmic.200300592; Fields S, 2001, SCIENCE, V291, P1221, DOI 10.1126/science.291.5507.1221; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; Gay S, 2002, PROTEOMICS, V2, P1374, DOI 10.1002/1615-9861(200210)2:10<1374::AID-PROT1374>3.0.CO;2-D; Glish GL, 2003, NAT REV DRUG DISCOV, V2, P140, DOI 10.1038/nrd1011; Goutte C, 1997, NEURAL COMPUT, V9, P1245, DOI 10.1162/neco.1997.9.6.1245; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Ham F. M., 2001, PRINCIPLES NEUROCOMP; HOFFMANN R, 2002, BIOINFORMATICS, V21, P1509; Hubert M, 2004, BIOINFORMATICS, V20, P1728, DOI 10.1093/bioinformatics/bth158; Kim YH, 2004, LECT NOTES COMPUT SC, V3102, P346; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Li JN, 2002, CLIN CHEM, V48, P1296; LIAO M, 2005, BAYSIAN MODELS MACHI; Lipshutz RJ, 1999, NAT GENET, V21, P20, DOI 10.1038/4447; Liu JJ, 2005, BIOINFORMATICS, V21, P2691, DOI 10.1093/bioinformatics/bti419; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Mangiameli P, 1996, EUR J OPER RES, V93, P402, DOI 10.1016/0377-2217(96)00038-0; Mlecnik B, 2005, NUCLEIC ACIDS RES, V33, pW633, DOI 10.1093/nar/gki391; Model Fabian, 2002, Bioinformatics, V18 Suppl 1, pS155; MODLICH O, 2005, J TRANSL MED, V32; Nhat VDM, 2005, LECT NOTES COMPUT SC, V3512, P899; Ni B, 2004, LECT NOTES COMPUT SC, V3242, P1153; Olshen AB, 2002, BIOINFORMATICS, V18, P961, DOI 10.1093/bioinformatics/18.7.961; Pandey A, 2000, NATURE, V405, P837, DOI 10.1038/35015709; Paul TK, 2004, LECT NOTES COMPUT SC, V3102, P414; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Reilly C, 2003, J AM STAT ASSOC, V98, P868, DOI 10.1198/016214503000000800; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Steen H, 2004, NAT REV MOL CELL BIO, V5, P699, DOI 10.1038/nrm1468; Suzuki T, 2000, BIOTECHNIQUES, V29, P332; Szabo A, 2002, MATH BIOSCI, V176, P71, DOI 10.1016/S0025-5564(01)00103-1; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Theilhaber J, 2002, GENOME RES, V12, P165, DOI 10.1101/gr.182601; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang AT, 2005, STAT MED, V24, P2069, DOI 10.1002/sim.2082; Wolkenhauer O, 2002, COMPAR FUNCT GENOM, V3, P375, DOI 10.1002/cfg.192; Yan B, 2005, BIOINFORMATICS, V21, P563, DOI 10.1093/bioinformatics/bti044; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15; Zeeberg BR, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-4-r28; Zien A, 2001, BIOINFORMATICS, V17, P323	63	14	15	4	10	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0079-6123			PROG BRAIN RES			2006	158						83	108		10.1016/S0079-6123(06)58004-5		26	Neurosciences	Neurosciences & Neurology	BGH63	WOS:000247003700004	17027692	
J	Saha, S; Heber, S				Saha, Soma; Heber, Steffen			In silico prediction of yeast deletion phenotypes	GENETICS AND MOLECULAR RESEARCH			English	Article						classification; essential genes; simulated annealing; yeast phenotype		Analysis of gene deletions is a fundamental approach for investigating gene function. We evaluated an algorithm that uses classification techniques to predict the phenotypic effects of gene deletions in yeast. We used a modified simulated annealing algorithm for feature selection and weighting. The selected features with high weights were phylogenetic conservation scores for bacteria, fungi (excluding Ascomycota), Ascomycota (excluding Saccharomyces cerevisiae), plants, and mammals, degree of paralogy, and number of protein-protein interactions. Classification was performed by weighted k-nearest neighbor and with support vector machine algorithms. To demonstrate how this approach might complement existing experimental procedures, we applied our algorithm to predict essential genes and genes causing morphological alterations in yeast.	[Saha, Soma; Heber, Steffen] N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA	Heber, S (reprint author), N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA.	sheber@ncsu.edu					Akerley BJ, 2002, P NATL ACAD SCI USA, V99, P966, DOI 10.1073/pnas.012602299; BAUDIN A, 1993, NUCLEIC ACIDS RES, V21, P3329, DOI 10.1093/nar/21.14.3329; Chen Y, 2005, BIOINFORMATICS, V21, P575, DOI 10.1093/bioinformatics/bti058; Coghlan A, 2000, YEAST, V16, P1131, DOI 10.1002/1097-0061(20000915)16:12<1131::AID-YEA609>3.0.CO;2-F; Coulomb S, 2005, P ROY SOC B-BIOL SCI, V272, P1721, DOI 10.1098/rspb.2005.3128; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gasteiger E, 2003, NUCLEIC ACIDS RES, V31, P3784, DOI 10.1093/nar/gkg563; Giaever G, 2002, NATURE, V418, P387, DOI 10.1038/nature00935; Glover F, 1993, MODERN HEURISTIC TEC, P70; Hashimoto M, 2005, MOL MICROBIOL, V55, P137, DOI 10.1111/j.1365-2958.2004.04386.x; Hubbard T, 2005, NUCLEIC ACIDS RES, V33, pD447, DOI 10.1093/nar/gki138; Janssen P, 2003, BIOINFORMATICS, V19, P1451, DOI 10.1093/bioinformatics/btg161; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kobayashi K, 2003, P NATL ACAD SCI USA, V100, P4678, DOI 10.1073/pnas.0730515100; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krylov DM, 2003, GENOME RES, V13, P2229, DOI 10.1101/gr.1589103; Kuramochi M, 2001, 2ND ANNUAL IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS, P191; Lopez-Bigas N, 2004, NUCLEIC ACIDS RES, V32, P3108, DOI 10.1093/nar/gkh605; Salama NR, 2004, J BACTERIOL, V186, P7926, DOI 10.1128/JB.186.23.7926-7935.2004; Smalley DJ, 2003, TRENDS MICROBIOL, V11, P6, DOI 10.1016/S0966-842X(02)00008-2; Vapnik V., 1999, NATURE STAT LEARNING; von Mering C, 2002, NATURE, V417, P399; WACH A, 1994, YEAST, V10, P1793, DOI 10.1002/yea.320101310; Xenarios Ioannis, 2001, Current Opinion in Biotechnology, V12, P334, DOI 10.1016/S0958-1669(00)00224-X	24	20	20	1	2	FUNPEC-EDITORA	RIBEIRAO PRETO	RUA HUDSON 655, JARDIM CANADA, RIBEIRAO PRETO, SP, BRAZIL	1676-5680			GENET MOL RES	Genet. Mol. Res.		2006	5	1					224	232				9	Biochemistry & Molecular Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Genetics & Heredity	V44OJ	WOS:000203011700027	16755513	
S	Guillas, S; Bertet, K; Ogier, JM		Liu, W; Llados, J		Guillas, Stephanie; Bertet, Karell; Ogier, Jean-Marc			A generic description of the concept lattices' classifier: Application to symbol recognition	GRAPHICS RECOGNITION: TEN YEARS REVIEW AND FUTURE PERSPECTIVES	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Workshop on Graphic Recognition	AUG 25-26, 2005	Hong Kong, PEOPLES R CHINA	City Univ Hong Kong, IAPR, K C Wong Educ Fdn, Hong Kong Web Soc				In this paper, we present the problem of noisy images recognition and in particular the stage of primitives selection in a classification process. We suppose that segmentation and statistical features extraction on documentary images are realized. We describe precisely the use of concept lattice and compare it with a decision tree in a recognition process. From the experimental results, it appears that concept lattice is more adapted to the context of noisy images.	Univ La Rochelle, L3I, F-17042 La Rochelle 1, France	Guillas, S (reprint author), Univ La Rochelle, L3I, Av M Crepeau, F-17042 La Rochelle 1, France.	sguillas@univ-1r.fr; kbertet@univ-1r.fr; jmogier@univ-1r.fr					ADAM S, 1999, ICDAR 99, P45; Bertet K, 2004, DISCRET MATH THEOR C, V6, P315; Birkhoff G., 1967, LATTICE THEORY, VXXV; Bordat J.P., 1986, MATH SCI HUMAINES, V96, P31; BUNKE H, 2000, 15 INT C PATT REC, V2, P117; CANU S, 2005, NATL ICT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Derrode S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P877; Godin R., 1993, OOPSLA, P394; GUNES V, 2000, IJUFKS; KANUNGO T, 1994, IAPR WORKSH MACH VIS, P552; LEFEVRE E, 2000, TRAITEMENT SIGNAL, V17; MILGRAM M., 1993, RECONNAISSANCE FORME; NOURINE L, 1999, 3 INT C ORD ALG APPL; OBIEDKOV S, 2003, 4 INT C JOURN INF ME, P15; TABBONE S, 2003, TECHNIQUE SCI INFORM; Taouil R., 2001, P ICCS 2001 INT WORK, P290; TEAGUE M, 2003, J OPTICAL SOC AM JOS, V70, P920; Tombre K., 2003, Proceedings Seventh International Conference on Document Analysis and Recognition; Wille R., 1999, FORMAL CONCEPT ANAL; GREC	21	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-34711-9	LECT NOTES COMPUT SC			2006	3926						47	60				14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BEX73	WOS:000240036000005		
B	Chen, F; Wu, SX		Li, M		Chen Fen; Wu Shunxiang			The application of classification methods in intrusion detection system	ICCSE'2006: Proceedings of the First International Conference on Computer Science & Education: ADVANCED COMPUTER TECHNOLOGY, NEW EDUCATION			English	Proceedings Paper	1st International Conference on Computer Science and Education (ICCSE 2006)	JUL 27-29, 2006	Xiamen, PEOPLES R CHINA	China Natl Res Council Comp Educ Coll & Univ, IEEE Control Syst Chapter, Singapore, Univ Virginia, Univ Melbourne	Xiamen Univ	intrusion detection; K_Nearest neighbor (KNN); support vector machine (SVM); character selection		Because of the high percent of misinformation in intrusion Detection System, we use classification methods in it in this paper. We mainly introduce the KNN and SVM. Using them we can get ideal result in processing non-structural data. If the dimension of data is not high, KNN can get more ideal result; and SVM can be applicable to the data which dimension is very high. So we create a new model for intrusion detection system based KNN and SVM; and we set a threshold for dimension to decide whether using KNN or SVM. In the end, we make some experiments to compare our system with traditional intrusion detection system.	Xiamen Univ, Dept Automat, Xiamen 361005, Peoples R China	Chen, F (reprint author), Xiamen Univ, Dept Automat, Xiamen 361005, Peoples R China.						CHENG SL, 2005, J WUHAN U, V27, P61; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini Nello, INTRO SUPPORT VECTOR; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; [马传香 Ma Chuanxiang], 2005, [计算机工程, Computer Engineering], V31, P4; Vpanik V., 1995, NATURE STAT LEARNING	6	0	0	0	3	XIAMEN UNIV PRESS	FUJIAN	XIAMEN, FUJIAN, 361005, PEOPLES R CHINA			7-5615-2582-6				2006							586	588				3	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	BFD83	WOS:000241272800138		
B	Shaneck, M; Kim, Y; Kumar, V		Tsumoto, S; Clifton, CW; Zhong, N; Wu, XD; Liu, JM; Wah, BW; Cheung, YM		Shaneck, Mark; Kim, Yongdae; Kumar, Vipin			Privacy preserving nearest neighbor search	ICDM 2006: Sixth IEEE International Conference on Data Mining, Workshops			English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE				Data mining is frequently obstructed by privacy concerns. In many cases data is distributed, and bringing the data together in one place for analysis is not possible due to privacy laws (e.g. HIPAA) or policies. Privacy preserving data mining techniques have been developed to address this issue by providing mechanisms to mine the data while giving certain privacy guarantees. In this work we address the issue of privacy preserving nearest neighbor search, which forms the kernel of many data mining applications. To this end, we present a novel algorithm based on secure multiparty computation primitives to compute the nearest neighbors of records in horizontally distributed data. We show how this algorithm can be used in three important data mining algorithms, namely LOF outlier detection, SNN clustering, and kNN classification.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Shaneck, M (reprint author), Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.						Agrawal R., 2000, P ACM INT C MAN DAT; Breunig M., 2000, P ACM INT C MAN DAT; CHITTI S, 2004, MINING MULTIPLE PRIV; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Du W., 2001, P 17 ANN COMP SEC AP; EVFIMIEVSKI A, 2002, P SIGKDD; Goethals B., 2004, P 7 ANN INT C INF SE; Goldreich O, 2004, FDN CRYPTOGRAPHY, V2; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; JHA S, 2005, P 10 ESORICS; KANTARCIOGLU M, 2004, P 8 EUR C PRINC PRAC; KARGUPTA H, 2003, KNOWLEDGE INFORM SYS; Kumar V., 2003, P SIAM INT C DAT MIN; LINDELL Y, 2000, P ADV CRYPT CRYPTO; MAYER B, 2005, ANN S AM MED INF ASS; SHANECK M, 2006, TR06014 U MINN; Tan P.-N., 2006, INTRO DATA MINING; VAIDYA J, 2004, P 4 IEEE INT C DAT M; VAIDYA J, 2002, P SIGKDD; Vaidya J., 2003, P SIGKDD; ZHAN J, 2005, INT J NETWORK SECURI, V1, P46	21	1	1	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-2702-4				2006							541	545				5	Computer Science, Information Systems	Computer Science	BFZ38	WOS:000245603100099		
B	Zhan, J; Matwin, S		Tsumoto, S; Clifton, CW; Zhong, N; Wu, XD; Liu, JM; Wah, BW; Cheung, YM		Zhan, Justin; Matwin, Stan			A crypto-based approach to privacy-preserving collaborative data mining	ICDM 2006: SIXTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, WORKSHOPS			English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE				To conduct data mining, we often need to collect data from various parties. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. How multiple parties collaboratively conduct data mining without breaching data privacy presents a challenge. In this paper, we propose a formal definition of privacy, develop a solution for privacy-preserving k-nearest neighbor classification which is one of data mining tasks, and show that our solution preserves data privacy according to our definition.	Carnegie Mellon Univ, Heinz Sch, Pittsburgh, PA 15213 USA; Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada	Zhan, J (reprint author), Carnegie Mellon Univ, Heinz Sch, Pittsburgh, PA 15213 USA.	justinzh@andrew.cmu.edu; stan@site.uottawa.ca					Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; CHAUM D, 1985, COMMUN ACM, V28, P1030, DOI 10.1145/4372.4373; CLIFTON C, 2005, IEEE ICDM WORKSH SEC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dolev D., 1991, P 23 ANN ACM S THEOR, P542, DOI 10.1145/103418.103474; Goldreich O, 2004, FDN CRYPTOGRAPHY, V2; LINDELL Y, 2000, LECT NOTES COMPUTER, V1880; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; Rivest R, 1978, FDN SECURE COMPUTATI, P169; ZHAN J, 2006, THESIS U OTTAWA	10	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-2702-4				2006							546	550				5	Computer Science, Information Systems	Computer Science	BFZ38	WOS:000245603100100		
S	Owotoki, P; Manojlovic, N; Mayer-Lindenberg, F; Pasche, E		Clifton, CW; Zhong, N; Liu, JM; Wah, BW; Wu, XD		Owotoki, Peter; Manojlovic, Natasa; Mayer-Lindenberg, Friedrich; Pasche, Erik			A data mining approach for capacity building of stakeholders in integrated flood management	ICDM 2006: Sixth International Conference on Data Mining, Proceedings	IEEE International Conference on Data Mining		English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE				New approaches to managing flood events are increasingly of more relevance due to recent widespread floods and the presumed changes in the climate. These approaches fall under the integrated flood management (IFM) banner and focus not only on flood prevention, but on flood resilience. This paper introduces an application (FLORETO) for IFM that utilizes the data mining approach, in a web based three tier system, devoted to the capacity building of stakeholders as a micro-scale resilience strategy of IFM. The intelligent models, which constitute the business logic in FLORETO, are used to match the input parameters or design criteria, describing properties prone to flooding, to technically justifiable flood mitigation measures. Datasets from the German city of Kellinghusen were collected and intelligent models were built. Satisfactory results have been obtained, which shows the promise of this data mining approach and opens the door for its application for IFM in other regions.	Tech Univ Hamburg, Inst Comp Technol, D-2100 Hamburg, Germany; Tech Univ Hamburg, Inst River & Coastal Engn, D-2100 Hamburg, Germany	Owotoki, P (reprint author), Tech Univ Hamburg, Inst Comp Technol, D-2100 Hamburg, Germany.						AHA DW, 1987, P 4 INT C MACH LEARN, P24; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BUCHANAN BG, 1984, RUL BAS EXP SYST; BUNTINE W, 1989, P 6 INT WORKSH MACH, P94; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAENEN BC, 2002, COMPUTATIONAL INTELL; *ENV AG, 2004, FLOOD PROD GUID HOM; Feigenbaum E. A, 1977, INT JOINT C ART INT, P1014; *FEMA, 2005, ENG PRINC PRACT RETR; Frank E., 2005, DATA MINING PRACTICA; Hayes-Roth Frederick, 1983, BUILDING EXPERT SYST; Jensen F. V., 1996, INTRO BAYESIAN NETWO; PASCHE E, 2004, P URB FLOOD MAN; PASCHE E, 2006, UNPUB HYDROINFORMATI; QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545; Quinlan R., 1986, MACH LEARN, V1, P81; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salzberg S.L., 1990, LEARNING NESTED GEN; SANTOS E, 1996, AFITENTR9601 AIR FOR; SHAPIRO GP, 1989, WORKSH KNOWL DISC RE; WELBANK M, 1983, REV KNOWLEDGE ACQUIS; Zanasi A., 1998, DISCOVERING DATA MIN; ZIMMERMANN H, 2002, ADV COMPUTATIONAL IN	26	0	0	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		978-0-7695-2701-7	IEEE DATA MINING			2006							446	455				10	Computer Science, Information Systems	Computer Science	BFZ37	WOS:000245601900045		
S	Tahir, MA; Smith, J		Clifton, CW; Zhong, N; Liu, JM; Wah, BW; Wu, XD		Tahir, Muhammad Atif; Smith, James			Improving nearest neighbor classifier using Tabu Search and ensemble distance metrics	ICDM 2006: Sixth International Conference on Data Mining, Proceedings	IEEE International Conference on Data Mining		English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE			STATISTICAL PATTERN-RECOGNITION; ALGORITHMS	The nearest-neighbor (NN) classifier has long been used in pattern recognition, exploratory data analysis, and data mining problems. A vital consideration in obtaining good results with this technique is the choice of distance function, and correspondingly which features to consider when computing distances between samples. In this paper a new ensemble technique is proposed to improve the performance of NN classifier The proposed approach combines multiple NN classifiers, where each classifier uses a different distance function and potentially a different set of features (feature vector). These feature vectors are determined for each distance metric using Simple Voting Scheme incorporated in Tabu Search (TS). The proposed ensemble classifier with different distance metrics and different feature vectors (TS-DF/NN) is evaluated using various benchmark data sets from UCI Machine Learning Repository. Results have indicated a significant increase in the performance when compared with various well-known classifiers. Furthermore, the proposed ensemble method is also compared with ensemble classifier using different distance metrics but with same feature vector (with or without Feature Selection (FS)).	Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.						BAO Y, 2004, LNCS, V3177; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake CL, UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R. O., 1973, PATTERN CLASSIFICATI; Frank E., 2005, DATA MINING PRACTICA; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Glover F., 1989, ORSA Journal on Computing, V1; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1993, Annals of Operations Research, V41; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KOHAVI R, 1995, P 8 EUR C MACH LEARN; KORYCINSKI D, 2003, P IEEE INT GEOSC REM; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Michie D., 1994, MACHINE LEARNING NEU; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SAIT SM, 1999, GEN ITERATIVE ALGORI; TAHIR MA, 2004, IEEE P INT C PATT RE; TAHIR MA, 2004, LNCS, V3177; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	26	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		978-0-7695-2701-7	IEEE DATA MINING			2006							1086	1090				5	Computer Science, Information Systems	Computer Science	BFZ37	WOS:000245601900132		
S	Garcia, S; Cano, JR; Herrera, F		Corchado, E; Yin, H; Botti, V; Fyfe, C		Garcia, Salvador; Ramon Cano, Jose; Herrera, Francisco			Incorporating knowledge in evolutionary prototype selection	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2006, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	7th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2006)	SEP 20-23, 2006	Burgos, SPAIN		Univ Burgos		NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; INSTANCE SELECTION; REDUCTION	Evolutionary algorithms has been recently used for prototype selection showing good results. An important problem in prototype selection consist in increasing the size of data sets. This problem can be harmful in evolutionary algorithms by deteriorating the convergence and increasing the time complexity. In this paper, we offer a preliminary proposal to solve these drawbacks. We propose an evolutionary algorithm that incorporates knowledge about the prototype selection problem. This study includes a comparison between our proposal and other evolutionary and non-evolutionary prototype selection algorithms. The results show that incorporating knowledge improves the performance of evolutionary algorithms and considerably reduces time execution.	Univ Granada, Dept Comp Sci & Artificial Intelligence, ETSI Informat, E-18071 Granada, Spain; Univ Jaen, Dept Comp Sci, Jaen 23700, Spain	Garcia, S (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, ETSI Informat, E-18071 Granada, Spain.	salvagl@decsai.ugr.es; jrcano@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008; Garcia, Salvador/N-3624-2013; Cano de Amo, Jose-Ramon/L-7494-2014	Herrera, Francisco/0000-0002-7283-312X; Garcia, Salvador/0000-0003-4494-7565; Cano de Amo, Jose-Ramon/0000-0001-9150-4113			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Baluja S, 1994, POPULATION BASED INC; Cano JR, 2005, PATTERN RECOGN LETT, V26, P953, DOI 10.1016/j.patrec.2004.09.043; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Eshelman L. J., 1990, FDN GENETIC ALGORITH, P265; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Goldberg D. E., 1989, GENETIC ALGORITHMS S; GROCHOWSKI M, 2004, ICAISC, P580; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ishibuchi H, 1999, LECT NOTES ARTIF INT, V1585, P82; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Newman D., 1998, UCI REPOSITORY MACHI; Sheskin DJ, 1997, HDB PARAMETRIC NONPA; Skalak D. B., 1994, INT C MACH LEARN, P293; Smith J. E., 2003, INTRO EVOLUTIONARY C; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	20	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-45485-3	LECT NOTES COMPUT SC			2006	4224						1358	1366				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFG81	WOS:000241790900161		
B	Pateritsas, C; Stafylopatis, A		Mohammadian, M		Pateritsas, Christos; Stafylopatis, Andreas			Independent nearest features memory-based classifier	International Conference on Computational Intelligence for Modelling, Control & Automation Jointly with International Conference on Intelligent Agents, Web Technologies & Internet Commerce, Vol 2, Proceedings			English	Proceedings Paper	International Conference on Computational Intelligence for Modelling, Control and Automation/International Conference on Intelligent Agents Web Technologies and International Commerce	NOV 28-30, 2005	Vienna, AUSTRIA	IEEE Computat Intelligence Soc, European Soc Fuzzy Log & Technol, European Neural Network Soc, Int Assoc Fuzzy Set Management & Econ, Japan Soc Fuzzy Theory & Intelligent Informat, Taiwan Fuzzy Syst Assoc, World Wide Web Business Intelligence, Hungarian Fuzzy Assoc, Univ Canberra			LEARNING ALGORITHMS; NEIGHBOR	The classification task is one of the most important problems in the area of data mining. In this paper we propose a new algorithm for addressing this problem. The main idea derives from the well-known algorithm of k-nearest-neighbors. In the proposed approach, given an unclassified pattern, a set of neighboring patterns is found, but not necessarily using all input feature dimensions. Also, following the concept of the naive Bayesian classifier, independence of input feature dimensions in the outcome of the classification task is assumed. The two concepts are merged in an attempt to take advantage of their good performance features. Experimental results have shown superior performance of the proposed method in comparison with the aforementioned algorithms and their variations.	Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece	Pateritsas, C (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Iroon Polytexneiou 9, Athens 15780, Greece.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Akkus A, 1996, P 13 INT C MACH LEAR, P12; Blake C, 1998, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DEMIROZ G, 1997, LECT NOTES COMPUTER; FAN H, 2003, P 14 AUSTR DAT C AD; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; GUVENIR HA, 1997, P 12 INT S COMP INF; Kononenko I, 1992, INFORMATICA, V16, P1; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; SIRIN I, 1993, CIS9301 BILK U DEP C; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WETTSCHERECK D, 1995, 1 INT C CAS BAS REAS, P347; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YANG Y, 2001, LECT NOTES COMPUTER, P564	20	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7695-2504-0				2006							781	786				6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BEW91	WOS:000239915100129		
B	Alizon, F; Shooter, SB; Simpson, TW		Zhang, D; Khoshgoftaar, TM; Joshi, BD		Alizon, Fabrice; Shooter, Steven B.; Simpson, Timothy W.			Provide relevant knowledge to specify product design project needs	IRI 2006: Proceedings of the 2006 IEEE International Conference on Information Reuse and Integration			English	Proceedings Paper	IEEE International Conference on Information Reuse and Intergration (IRI 2006)	SEP 16-18, 2006	Waikoloa, HI	IEEE			ADVANTAGE	In many of today's industry, knowledge is considered a strategic tool; however, knowledge is involved in so many services with so many facets that it is very complex to effectively manage for competitive advantage. In design, knowledge is recognized as important to improve the decision-making process and the commensurability of the designers' interpretative framework, but how can relevant knowledge be identified among all the knowledge within a company? This study focuses on the early stage of project development when it is important to have a clear understanding of what is known and not known in the company to correctly specify projects (e.g., teams, costs, lead-time, etc.). A method is proposed in this paper to identify knowledge, where it is, and its level of reusability. This method filters a repository to identify and extract relevant knowledge and define its level of reusability. A case study based on a new single-use camera and a repository of 18 single-use cameras is performed to highlight and validate the proposed method.	Bucknell Univ, Lewisburg, PA 17837 USA	Shooter, SB (reprint author), Bucknell Univ, Lewisburg, PA 17837 USA.						ALIZON F, 2006, J COMPUTING INFORM S, V6; ALIZON F, 2002, INT FLEX AUT INT MAN, V1, P134; BARNEY J, 1991, J MANAGE, V17, P99, DOI 10.1177/014920639101700108; BONTIS, 2000, MANAGING ORG KNOWLED; COLLIS D, 1995, HARVARD BUSINESS JUL, P127; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davenport T. H., 1998, WORKING KNOWLEDGE; McEvily SK, 2002, STRATEGIC MANAGE J, V23, P285, DOI 10.1002/smj.223; Polanyi M., 1966, TACIT DIMENSION; Sivaloganathan S, 1999, P I MECH ENG B-J ENG, V213, P641, DOI 10.1243/0954405991517092; Stone RB, 2000, J MECH DESIGN, V122, P359, DOI 10.1115/1.1289637; Thevenot HJ, 2006, J ENG DESIGN, V17, P99, DOI 10.1080/09544820500275693; TROUSSE B, 1993, ADVANCED TECHNOLOGIES, P451; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	14	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			0-7803-9788-6				2006							460	465				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFI82	WOS:000242108800081		
B	Popova, V		Chen, Y; Abraham, A		Popova, Viara			Missing values in monotone data sets	ISDA 2006: Sixth International Conference on Intelligent Systems Design and Applications, Vol 1			English	Proceedings Paper	6th International Conference on Intelligent Systems Design and Applications (ISDA 2006)	OCT 16-18, 2006	Jinan, PEOPLES R CHINA	IEEE Syst Man & Cybernet Soc	Jinan Univ		ROUGH SETS; CLASSIFICATION	This paper explores the problem of missing values in the context of monotone classification. A simple preprocessing method is proposed as an extension of three general approaches for filling in the unknown values (k-nearest neighbour most frequent value and data point multiplication) so that the monotonicity property of the resulting data set is preserved. The results of the first experiments with the algorithms are reported in order to give more insight in how the method works in practice.	Vrije Univ Amsterdam, Dept Artificial Intelligence, NL-1081 HV Amsterdam, Netherlands	Popova, V (reprint author), Vrije Univ Amsterdam, Dept Artificial Intelligence, Boelelaan 1081A, NL-1081 HV Amsterdam, Netherlands.						BENDAVID A, 1995, MACH LEARN, V19, P29, DOI 10.1007/BF00994659; Ben-David A., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00314.x; BIOCH JC, 2002, ERS200234LIS ER RES; Bioch J.C., 2002, P 14 BELG DUTCH C AR, P19; Bioch J.C., 2002, P 12 BELG DUTCH C MA, P3; Bioch JC, 1998, ANN MATH ARTIF INTEL, V24, P69, DOI 10.1023/A:1018993014297; Blake C, 1998, UCI REPOSITORY MACHI; Bioch JC, 2000, LECT NOTES ARTIF INT, V1968, P291; Bohanec M., 1990, SISTEMICA, V1, P145; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; BOROS E, 1997, MATH PROGRAM, V79, P165; CAOVAN K, 2002, UNPUB INT J INTELLIG; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daniels H, 1999, NEURAL COMPUT APPL, V8, P226, DOI 10.1007/s005210050025; DANIELS HAM, 2003, 200330 TILB U; Greco S., 1998, OPERATIONAL TOOLS MA, P121; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; GRZIMALABUSSE JW, 1991, LECT NOTES ARTIF INT, V542, P368; Grzymala-Busse J. W., 2000, P 2 INT C ROUGH SETS, P340; Kononenko I., 1984, EXPT AUTOMATIC LEARN; Liu WZ, 1997, LECT NOTES COMPUT SC, V1280, P527; MAKINO K, 1996, P INT S COOP DAT SYS, P282; Olave M., 1989, EXPERT SYSTEMS PUBLI, P145; POPVOA V, 2005, LECT NOTES ARTIF INT, V3735, P203; Potharst R., 2002, SIGKDD EXPLORATIONS, V4, P1; POTHARST R, 2000, INTELLIGENT DATA ANA, V4, P1; Quinlan J .R., 1989, P 6 INT WORKSH MACH, P164; Wang S., 1994, NEURAL COMPUT APPL, V2, P160, DOI 10.1007/BF01415012	29	0	0	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2528-8				2006							627	632				6	Computer Science, Artificial Intelligence	Computer Science	BFK66	WOS:000242507000115		
J	Davidov, D; Markovitch, S				Davidov, Dmitry; Markovitch, Shaul			Multiple-goal heuristic search	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							ADMISSIBLE HEURISTICS; DISCOVERY; WEB	This paper presents a new framework for anytime heuristic search where the task is to achieve as many goals as possible within the allocated resources. We show the inadequacy of traditional distance-estimation heuristics for tasks of this type and present alternative heuristics that are more appropriate for multiple-goal search. In particular, we introduce the marginal-utility heuristic, which estimates the cost and the benefit of exploring a subtree below a search node. We developed two methods for online learning of the marginal-utility heuristic. One is based on local similarity of the partial marginal utility of sibling nodes, and the other generalizes marginal-utility over the state feature space. We apply our adaptive and non-adaptive multiple-goal search algorithms to several problems, including focused crawling, and show their superiority over existing methods.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Davidov, D (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	DMITRY@CS.TECHNION.AC.IL; SHAULM@CS.TECHNION.AC.IL					BODDY M, 1994, ARTIF INTELL, V67, P245, DOI 10.1016/0004-3702(94)90054-X; BORODIN A, 2001, 10 INT WORLD WID WEB, P415; BOYAN J, 1996, P AAAI WORKSH INT BA, P324; Breiman L., 1984, CLASSIFICATION REGRE; Brin S., 1998, COMPUTER NETWORKS IS, V30, P1; Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3; Cho J, 1998, COMPUT NETWORKS ISDN, V30, P161, DOI 10.1016/S0169-7552(98)00108-1; Cho J., 2000, VLDB 2000; COOPER C, 2002, P 34 ANN ACM S THEOR, P419; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Culberson JC, 1998, COMPUT INTELL, V14, P318, DOI 10.1111/0824-7935.00065; Diligenti M., 2000, 26 INT C VER LARG DA, P527; DOUGLIS F, 1997, USENIX S INT TECHN S, P147; GASSER RU, 1995, THESIS SWISS FEDERAL; Hansen EA, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1229; Haveliwala T.H., 1999, EFFICIENT COMPUTATIO; HELD M, 1970, OPER RES, V18, P1138, DOI 10.1287/opre.18.6.1138; Hirai J., 2000, P 9 INT WORLD WID WE, P277; HOVITZ E, 1990, THESIS STANFORD U; Joachims T, 1997, P 14 INT C MACH LEAR, P143; Kleinberg J.M., 1999, JACM, V46, P5; KORF RE, 2000, NAT C ART INT AAAI, P910; Korf RE, 2002, ARTIF INTELL, V134, P9, DOI 10.1016/S0004-3702(01)00092-3; Kumar R., 2000, P 19 ACM SIGMOD SIGA, P1, DOI 10.1145/335168.335170; Lawrence S, 1998, SCIENCE, V280, P98, DOI 10.1126/science.280.5360.98; MCCALLUM A, 1999, P AAAI SPRING S INT, P28; Menczer F., 2001, P 24 ANN INT ACM SIG, P241, DOI DOI 10.1145/383952.383995; Montgomery D, 2001, DESIGN ANAL EXPT; MOSTOW J, 1989, P IJCAI 89, V1, P701; NAJORK M, 1998, P 7 INT WWW C WWW7, P379; Najork M., 2001, P 10 INT WORLD WID W, P114, DOI DOI 10.1145/371920.371965; PAGE L, 1998, PAGERANK CITATION RI; PANDURANGAN G, 2002, 8 ANN INT COMP COMB, P330; PEARL J, 1982, IEEE T PATTERN ANAL, V4, P392; PRIEDITIS AE, 1993, MACH LEARN, V12, P117, DOI 10.1007/BF00993063; Rennie J., 1999, P 16 INT C MACH LEAR, P335; Russell S. J., 2003, ARTIFICIAL INTELLIGE; RUSSELL SJ, 1991, P IJCAI 91, P213; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Schroedl S, 2005, J ARTIF INTELL RES, V23, P587; UTGOFF P, 1988, 5TH P INT C MACH LEA, P107; Yoshizumi T., 2000, AAAI IAAI, P923; Zhou R, 2003, PROC INT C TOOLS ART, P427; ZHOU R, 2002, P 18 NAT C ART INT A, P975; Zilberstein S, 1996, AI MAG, V17, P73; Zilberstein S, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1008	46	2	2	0	0	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757			J ARTIF INTELL RES	J. Artif. Intell. Res.		2006	26						417	451				35	Computer Science, Artificial Intelligence	Computer Science	077JG	WOS:000240024500002		
J	Oh, JH; Choi, KS; Isahara, H				Oh, Jong-Hoon; Choi, Key-Sun; Isahara, Hitoshi			A comparison of different machine transliteration models	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							INFORMATION-RETRIEVAL	Machine transliteration is a method for automatically converting words in one language into phonetically equivalent ones in another language. Machine transliteration plays an important role in natural language applications such as information retrieval and machine translation, especially for handling proper nouns and technical terms. Four machine transliteration models - grapheme-based transliteration model, phoneme-based transliteration model, hybrid transliteration model, and correspondence-based transliteration model have been proposed by several researchers. To date, however, there has been little research on a framework in which multiple transliteration models can operate simultaneously. Furthermore, there has been no comparison of the four models within the same framework and using the same data. We addressed these problems by 1) modeling the four models within the same framework, 2) comparing them under the same conditions, and 3) developing a way to improve machine transliteration through this comparison. Our comparison showed that the hybrid and correspondence-based models were the most effective and that the four models can be used in a complementary manner to improve machine transliteration performance.	Natl Inst Informat & Commun Technol, Computat Linguist Grp, Seika, Kyoto 6190289, Japan; Korea Adv Inst Sci & Technol, Div Comp Sci, Dept EECS, Taejon 305701, South Korea	Oh, JH (reprint author), Natl Inst Informat & Commun Technol, Computat Linguist Grp, 3-5 Hikaridai, Seika, Kyoto 6190289, Japan.	ROVELLIA@NICT.GO.JP; KSCH0I@CS.KAIST.AC.KR; ISAHARA@NICT.GO.JP	Choi, Key-Sun/C-1978-2011				Aha D., 1991, MACHINE LEARNING, V6; AHA DW, 1997, ARTIF INTELL, V11, P710; Al- Onaizan Y., 2002, P 40 ANN M ASS COMP, P400; ANDERSEN O, 1996, P INT C SPOK LANG PR, P1808; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bilac S., 2004, P IJCNLP 2004, P542; BREEN J, 2003, EDICT JAPANESE ENGLI; Chen Stanley F, 2003, P EUR, P2033; *CMU, 1997, CMU PRON DICT VERS 0; Cover T., 1967, I ELECT ELECT ENG T, P13; DAELEMANS W, 2004, ILK TECHNICAL REPORT; DAELEMANS WMP, 1996, PROGR SPEECH SYNTHES, P77; Damper RI, 1999, COMPUT SPEECH LANG, V13, P155, DOI 10.1006/csla.1998.0117; Devijver P. A., 1982, PATTERN RECOGNITION; Fujii A, 2001, COMPUT HUMANITIES, V35, P389, DOI 10.1023/A:1011856202986; GOTO I, 2003, P MT SUMM 9, P125; Grefenstette G., 2004, P WEB INT, P110; Huang F., 2005, P HUM LANG TECHN C C, P483, DOI 10.3115/1220575.1220636; Jeong KS, 1999, INFORM PROCESS MANAG, V35, P523, DOI 10.1016/S0306-4573(98)00055-7; Jung SY, 2000, P 18 C COMP LING, P383; KANG BJ, 2001, THESIS KAIST; KANG BJ, 2000, P 2 INT C LANG RES E, P1135; KANG IH, 2000, P 18 INT C COMP LING, P418; KIM JJ, 1999, P KOR COGN SCI ASS, P247; Knight K., 1997, P 35 ANN M ASS COMP, P128; Korean Ministry of Culture and Tourism, 1995, ENGL KOR STAND CONV; Lee J. S., 1998, COMPUTER PROCESSING, V12, P17; LEE JH, 1999, THESIS KAIST; LI H, 2004, P ACL 2004, P160; Lin Wei-Hao, 2002, P 6 C NAT LANG LEARN, P139; Manning C., 1999, FDN STAT NATURAL LAN; Meng H., 2001, P AUT SPEECH REC UND, P311; Mitchell T. M., 1997, MACHINE LEARNING; NAM YS, 1997, FOREIGN DICT; Oh Jong-Hoon, 2002, P 19 INT C COMP LING, P758; Pagel V., 1998, P ICSLP, P2015; Qu Y., 2004, P ACL, P183, DOI 10.3115/1218955.1218979; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Stalls B. G., 1998, P COLING ACL WORKSH, P34, DOI 10.3115/1621753.1621760; Zhang L., 2004, MAXIMUM ENTROPY MODE; ZHANG Y, 2005, P 28 ANN INT ACM SIG, P669, DOI 10.1145/1076034.1076182	42	2	2	0	1	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757			J ARTIF INTELL RES	J. Artif. Intell. Res.		2006	27						119	151				33	Computer Science, Artificial Intelligence	Computer Science	096YG	WOS:000241412200001		
J	Dutta, D; Guha, R; Jurs, PC; Chen, T				Dutta, D; Guha, R; Jurs, PC; Chen, T			Scalable partitioning and exploration of chemical spaces using geometric hashing	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	4th Indo-US Workshop on Mathematical Chemistry	JAN 08-12, 2005	Pune, INDIA				MOLECULAR CONNECTIVITY; SHAPE INDEX; PREDICTION; VALIDATION; LIBRARIES; DIVERSITY; GRAPHS	Virtual screening (VS) has become a preferred tool to augment high-throughput screening(1) and determine new leads in the drug discovery process. The core of a VS informatics pipeline includes several data mining algorithms that work on huge databases of chemical compounds containing millions of molecular structures and their associated data. Thus, scaling traditional applications such as classification, partitioning, and outlier detection for huge chemical data sets without a significant loss in accuracy is very important. In this paper, we introduce a data mining framework built on top of a recently developed fast approximate nearest-neighbor-finding algorithm(2) called locality-sensitive hashing (LSH) that can be used to mine huge chemical spaces in a scalable fashion using very modest computational resources. The core LSH algorithm hashes chemical descriptors so that points close to each other in the descriptor space are also close to each other in the hashed space. Using this data structure, one can perform approximate nearest-neighbor searches very quickly, in sublinear time. We validate the accuracy and performance of our framework on three real data sets of sizes ranging from 4337 to 249 071 molecules. Results indicate that the identification of nearest neighbors using the LSH algorithm is at least 2 orders of magnitude faster than the traditional k-nearest-neighbor method and is over 94% accurate for most query parameters. Furthermore, when viewed as a data-partitioning procedure, the LSH algorithm lends itself to easy parallelization of nearest-neighbor classification or regression. We also apply our framework to detect outlying (diverse) compounds in a given chemical space this algorithm is extremely rapid in determining whether a compound is located in a sparse region of chemical space or not, and it is quite accurate when compared to results obtained using principal-component-analysis-based heuristics.	Penn State Univ, Dept Chem, University Pk, PA 16802 USA; Univ So Calif, Dept Computat Biol, Los Angeles, CA 90089 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, University Pk, PA 16802 USA.	pcj@psu.edu					Agrafiotis DK, 2001, J CHEM INF COMP SCI, V41, P159, DOI 10.1021/ci000091j; AMES BN, 1975, MUTAT RES, V31, P347, DOI 10.1016/0165-1161(75)90046-1; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; *CHEM COMP GROUP I, MOL OP ENV; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DATAR M, 2004, SCG 04; DUDA RO, 1998, PATTERN CLASSIFICATI; Ertl P, 2000, J MED CHEM, V43, P3714, DOI 10.1021/jm000942e; GAREY RM, 1979, COMPUTERS INTRACTIBI; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; Gasteiger J., 1978, TETRAHEDRON LETT, V19, P3181; Gasteiger J, 2003, CHEMOINFORMATICS TXB; GIONIS A, 1999, VLDB 99; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; HASTIE T, 2001, INTRO STAT MACHINE L; Jorgensen WL, 2004, SCIENCE, V303, P1813, DOI 10.1126/science.1096361; Kazius J, 2005, J MED CHEM, V48, P312, DOI 10.1021/jm040835a; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P1, DOI 10.1002/qsar.19860050102; KIER LB, 1976, J PHARM SCI, V65, P1806, DOI 10.1002/jps.2600651228; Kier LB, 1986, MOL CONNECTIVITY STR; KIER LB, 1975, J PHARM SCI, V64, P1971, DOI 10.1002/jps.2600641214; KIER LB, 1985, QUANT STRUCT-ACT REL, V4, P109, DOI 10.1002/qsar.19850040303; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P7, DOI 10.1002/qsar.19860050103; Kier L.B., 1976, MOL CONNECTIVITY CHE; *MDL INF SYST INC, MACCS FING; PEARLMAN R, 1998, PERSPECT DRUG DISCOV, P339; Pearlman RS, 1999, J CHEM INF COMP SCI, V39, P28, DOI 10.1021/ci980137x; Schnur D, 1999, J CHEM INF COMP SCI, V39, P36, DOI 10.1021/ci980138p; Stahura FL, 2004, COMB CHEM HIGH T SCR, V7, P259; Voigt JH, 2001, J CHEM INF COMP SCI, V41, P702, DOI 10.1021/ci000150t; WIENER H, 1947, J AM CHEM SOC, V69, P17, DOI 10.1021/ja01193a005; Xu HF, 2003, J CHEM INF COMP SCI, V43, P1933, DOI 10.1021/ci034150f	32	12	15	2	3	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	JAN-FEB	2006	46	1					321	333		10.1021/ci050403o		13	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	008DU	WOS:000235021200036	16426067	
S	Pham, TD; Ran, DT		Gabrys, B; Howlett, RJ; Jain, LC		Pham, Tuan D.; Ran, Dat T.			Image classification by fusion for high-content cell-cycle screening	KNOWLEDGE-BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th International Conference on Knowledge-Based and Intelligent Information and Engineering Systems	OCT 09-11, 2006	Bournemouth, ENGLAND					We present a fuzzy fusion approach for combining cell-phase identification results obtained from multiple classifiers. This approach can improve the classification rates and allows the task of high-content cell-cycle screening more effective for biomedical research in the study of structures and functions of cells and molecules. Conventionally such study requires the processing and analysis of huge amounts of image data, and manual image analysis is very time consuming, thus costly, and also potentially inaccurate and poorly reproducible. The proposed method has been used to combine the results from three classifiers, and the combined result is superior to any of the results obtained from a single classifier.	James Cook Univ N Queensland, Bioinformat Applicat Res Ctr, Townsville, Qld 4811, Australia; James Cook Univ N Queensland, Sch Informat Technol, Townsville, Qld 4811, Australia; Univ Canberra, Sch Informat Sci & Engn, Canberra, ACT 2601, Australia	Pham, TD (reprint author), James Cook Univ N Queensland, Bioinformat Applicat Res Ctr, Townsville, Qld 4811, Australia.	tuan.pham@jcu.edu.au; dat.tran@canberra.edu.au					Bezdek J. C., 1981, PATTERN RECOGNITION; CHEN X, IN PRESS IEEE T BIOM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dunkle R, 2003, DRUG DISCOVERY WORLD, V4, P75; FENG Y, 2002, EUROPEAN PHARM REV, V7, P7; FOX S, 2003, DRUG DISCOVERY WORLD, V5, P21; Hiraoka Y, 1996, CHROMOSOME RES, V4, P173, DOI 10.1007/BF02254954; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; PHAM TD, 2005, P AI 2005 WORKSH LEA, P52; Pham T. D., 2002, Proceedings 2002 IEEE International Conference on Artificial Intelligence Systems (ICAIS 2002), DOI 10.1109/ICAIS.2002.1048051; PHAM TD, 2006, NEURAL STEM CELL RES; SUGEO M, 1974, THESIS TOKYO I TECHN; Tran D., 2000, P FUZZ IEEE C MAY US, V1, P152; Yarrow JC, 2003, COMB CHEM HIGH T SCR, V6, P279	14	2	2	0	95	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-46535-9	LECT NOTES ARTIF INT			2006	4251						524	531				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BFI87	WOS:000242122000064		
J	Sobanski, T; Modrak, I; Nitsch, K; Licznerski, BW				Sobanski, T; Modrak, I; Nitsch, K; Licznerski, BW			Application of sensor dynamic response analysis to improve the accuracy of odour-measuring systems	MEASUREMENT SCIENCE & TECHNOLOGY			English	Article; Proceedings Paper	8th Optoelectronic and Electronic Sensors Conference	JUN 27-30, 2004	Wroclaw, POLAND			sensors response analysis; odour-measuring systems; odour classification	ELECTRONIC NOSE; GAS SENSORS	A system consisting of a matrix of three semiconductor gas sensors was applied to the classification of different orange juices. The sensor matrix responses were sampled in short time intervals. Such responses were processed by discrete wavelet transform (DWT) together with the k-nearest neighbour (kNN) classification algorithm or by the probabilistic neural network (PNN). The obtained results show that both types of signal processing (DWT + kNN and PNN) applied provide very good class separation for time response analysis, while in the case of the static response analysis the correct classification coefficients are much lower. It is shown that the analysis of the sensor's time response can be an efficient way of increasing both the accuracy level and the immunity to external noise in e-nose systems. The possibility of reducing the number of sensors without decreasing the system performance is also demonstrated. Additional experiments have shown that for both processing methods, the results obtained with the dynamic response of a single sensor were better than those reached with the three-sensor array measured in static conditions.	Commiss European Communities, Joint Res Ctr, Inst Hlth & Consumer Protect, I-21020 Ispra, VA, Italy; Wroclaw Tech Univ, Fac Microsyst Elect & Photon, PL-50370 Wroclaw, Poland	Sobanski, T (reprint author), Commiss European Communities, Joint Res Ctr, Inst Hlth & Consumer Protect, I-21020 Ispra, VA, Italy.	tomasz.sobanski@jrc.it					Chimenti M, 2003, MEAS SCI TECHNOL, V14, P815, DOI 10.1088/0957-0233/14/6/315; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; Dutta R, 2003, MEAS SCI TECHNOL, V14, P190, DOI 10.1088/0957-0233/14/2/306; Ionescu R, 2002, SENSOR ACTUAT B-CHEM, V81, P289, DOI 10.1016/S0925-4005(01)00968-6; Ionescu R, 2005, SENSOR ACTUAT B-CHEM, V104, P132, DOI 10.1016/j.snb.2004.05.015; Licznerski BW, 1999, SENSOR ACTUAT B-CHEM, V57, P192, DOI 10.1016/S0925-4005(99)00156-2; LICZNERSKI BW, 2000, MAT 6 K NAUK CZUJN O, P7; Llobet E, 1999, MEAS SCI TECHNOL, V10, P538, DOI 10.1088/0957-0233/10/6/320; MISTI M, 2004, WAVELET TOOLBOX USER; NITSCH K, 2003, P 26 INT SPRING SEM, P389; SOBANSKI T, 2003, P 26 ISSE, P394; Szczurek A, 1999, SENSOR ACTUAT B-CHEM, V58, P427, DOI 10.1016/S0925-4005(99)00105-7; Wasserman P. D., 1993, ADV METHODS NEURAL C, P35; WEIMAR U, 1995, SENSOR ACTUAT B-CHEM, V26, P13, DOI 10.1016/0925-4005(94)01547-U; Weimar U, 1998, SENSOR ACTUAT B-CHEM, V52, P143, DOI 10.1016/S0925-4005(98)00268-8	16	6	6	1	1	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0957-0233			MEAS SCI TECHNOL	Meas. Sci. Technol.	JAN	2006	17	1					1	5		10.1088/0957-0233/17/1/001		5	Engineering, Multidisciplinary; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	007FI	WOS:000234953600002		
J	Ciosek, P; Sobanski, T; Augustyniak, E; Wroblewski, W				Ciosek, P; Sobanski, T; Augustyniak, E; Wroblewski, W			ISE-based sensor array system for classification of foodstuffs	MEASUREMENT SCIENCE & TECHNOLOGY			English	Article; Proceedings Paper	8th Optoelectronic and Electronic Sensors Conference	JUN 27-30, 2004	Wroclaw, POLAND			sensor array; electronic tongue; ion-selective electrodes	PATTERN-RECOGNITION; ELECTRONIC NOSE; BEVERAGES	A system composed of an array of polymeric membrane ion-selective electrodes and a pattern recognition block-a so-called 'electronic tongue'-was used for the classification of liquid samples: milk, fruit juice and tonic. The task of this system was to automatically recognize a brand of the product. To analyze the measurement set-up responses various non-parametric classifiers such as k-nearest neighbours, a feedforward neural network and a probabilistic neural network were used. In order to enhance the classification ability of the system, standard model solutions of salts were measured (in order to take into account any variation in time of the working parameters of the sensors). This system was capable of recognizing the brand of the products with accuracy ranging from 68% to 100% (in the case of the best classifier).	Warsaw Univ Technol, Fac Chem, Warsaw, Poland; Commiss European Communities, Joint Res Ctr, Inst Hlth & Consumer Protect, I-21020 Ispra, VA, Italy; Wroclaw Tech Univ, Dept Elect Microsyst & Photon, PL-50370 Wroclaw, Poland	Ciosek, P (reprint author), Warsaw Univ Technol, Fac Chem, Naokowskiego 3, Warsaw, Poland.	tomasz.sobanski@jrc.it					Chimenti M, 2003, MEAS SCI TECHNOL, V14, P815, DOI 10.1088/0957-0233/14/6/315; Ciosek P, 2004, ANALYST, V129, P639, DOI 10.1039/b401390e; Ciosek P, 2004, SENSOR ACTUAT B-CHEM, V103, P76, DOI 10.1016/j.snb.2004.04.038; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dutta R, 2003, MEAS SCI TECHNOL, V14, P190, DOI 10.1088/0957-0233/14/2/306; He HQ, 2003, MEAS SCI TECHNOL, V14, P1040; Massart D. L., 1988, CHEMOMETRICS TXB; Schaller Emmanuelle, 1998, Lebensmittel-Wissenschaft and Technologie, V31, P305, DOI 10.1006/fstl.1998.0376; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; Wasserman P. D., 1993, ADV METHODS NEURAL C, P35; Wojciechowski K, 2002, CHEM ANAL-WARSAW, V47, P335; Yu XH, 1997, NEURAL NETWORKS, V10, P517, DOI 10.1016/S0893-6080(96)00102-5	12	18	19	1	2	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0957-0233			MEAS SCI TECHNOL	Meas. Sci. Technol.	JAN	2006	17	1					6	11		10.1088/0957-0233/17/1/002		6	Engineering, Multidisciplinary; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	007FI	WOS:000234953600003		
S	Raicharoen, T; Lursinsap, C; Lin, F		King, I; Wang, J; Chan, L; Wang, DL		Raicharoen, Thanapant; Lursinsap, Chidchanok; Lin, Frank			A divide-and-conquer approach to the Pairwise Opposite Class-Nearest Neighbor (POC-NN) algorithm for regression problem	NEURAL INFORMATION PROCESSING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	13th International Conference on Neural Informational Processing	OCT 03-06, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, K C Wong Educ Fdn				This paper presents a method for regression problem based on divide-and-conquer approach to the selection of a set of prototypes from the training set for the nearest neighbor rule. This method aims at detecting and eliminating redundancies in a given data set while preserving the significant data. A reduced prototype set contains Pairwise Opposite Class-Nearest Neighbor (POC-NN) prototypes which are used instead of the whole given data. Before finding POC-NN prototypes, all sampling data have to be separated into two classes by using the criteria through odd and even sampling number of data, then POC-NN prototypes are obtained by iterative separation and analysis of the training data into two regions until each region is correctly grouped and classified. The separability is determined by the POC-NN prototypes essential to define the function approximator for local sampling data locating near these POC-NN prototypes. Experiments and results reported showed the effectiveness of this technique and its performance in both accuracy and prototype rate to those obtained by classical nearest neighbor techniques.	Chulalongkorn Univ, AVIC, Dept Math, Fac Sci, Bangkok 10330, Thailand; Univ Maryland Eastern Shore, Dept Math & Comp Sci, Kiah Hall Princess Anne, MD 21853 USA	Raicharoen, T (reprint author), Chulalongkorn Univ, AVIC, Dept Math, Fac Sci, Bangkok 10330, Thailand.	thanapantr@oit.rtaf.mi.th; lchidcha@chula.ac.th; linibm@attglobal.net					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dierckx P., 1993, MONOGRAPHS NUMERICAL; HART P, 1966, SEL66016 STANF EL LA, P1828; Hastie T, 2001, ELEMENTS STAT LEARNI; LORENZ E, 1963, ATMOS SCI, V26, P639; MACKEY MC, 1997, SCIENCE, P197; MITCHELL T, 1994, MACHINE LEARNING; RAICHAROEN T, 2005, PATTERN RECOGN, V35, P505; Sparrow C., 1982, LORENZ EQUATIONS; WAN E, 1997, INT C NEUR NETW; Yule GU, 1927, PHILOS T R SOC LOND, V226, P267, DOI 10.1098/rsta.1927.0007	11	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-46479-4	LECT NOTES COMPUT SC			2006	4232						765	772				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFG80	WOS:000241790100085		
J	Dounias, G; Bjerregaard, B; Jantzen, J; Tsakonas, A; Ampazis, N; Panagi, G; Panourgias, E				Dounias, G; Bjerregaard, B; Jantzen, J; Tsakonas, A; Ampazis, N; Panagi, G; Panourgias, E			Automated identification of cancerous smears using various competitive intelligent techniques	ONCOLOGY REPORTS			English	Article						computer assisted pap-smear diagnosis; computational intelligence; clustering; feature selection; ANFIS; neuro-fuzzy systems; inductive machine learning; second order neural networks; nearest neighbor classification; genetic programming	TRAINING FEEDFORWARD NETWORKS; CLASSIFICATION; ALGORITHMS	In this study the performance of various intelligent methodologies is compared in the task of pap-smear diagnosis. The selected intelligent methodologies are briefly described and explained, and then, the acquired results are presented and discussed for their comprehensibility and usefulness to medical staff, either for fault diagnosis tasks, or for the construction of automated computer-assisted classification of smears. The intelligent methodologies used for the construction of pap-smear classifiers, are different clustering approaches, feature selection, neuro-fuzzy systems, inductive machine learning, genetic programming, and second order neural networks. Acquired results reveal the power of most intelligent techniques to obtain high quality solutions in this difficult problem of medical diagnosis. Some of the methods obtain almost perfect diagnostic accuracy in test data, but the outcome lacks comprehensibility. On the other hand, results scoring high in terms of comprehensibility are acquired from some methods, but with the drawback of achieving lower diagnostic accuracy. The experimental data used in this study were collected at a previous stage, for the purpose of combining intelligent diagnostic methodologies with other existing, computer imaging technologies towards the construction of an automated smear cell classification device.	Univ Aegean, Dept Financial & Management Engn, Chios 82100, Greece; Herlev Univ Hosp, DK-2730 Herlev, Denmark; Tech Univ Denmark, Oersted DTU Automat, DK-2800 Lyngby, Denmark; Aristotle Univ Salonika, Dept Informat, Artificial Intelligence & Informat Anal Lab, Thessaloniki 54124, Greece; Euroclin Hosp, Dept Radiol, Athens 11521, Greece; Gen Hosp Chios Skilits, Dept Radiol, Chios, Greece	Dounias, G (reprint author), Univ Aegean, Dept Financial & Management Engn, 31 Fostini Str, Chios 82100, Greece.	g.dounias@aegean.gr	Tsakonas, Athanasios/A-3646-2008				Ampazis N, 2002, IEEE T NEURAL NETWOR, V13, P1064, DOI 10.1109/TNN.2002.1031939; Ampazis N, 2004, LECT NOTES COMPUT SC, V3025, P230; ANGELINE PJ, 1996, ADV GENETIC PROGRAMM; Bezdek J. C., 1981, PATTERN RECOGNITION; Byriel J, 1999, THESIS TU DENMARK; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Gustafson E.E., 1979, FUZZY CLUSTERING FUZ, P761; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hoppner F., 1999, FUZZY CLUSTER ANAL; Hunt Earl B, 1966, EXPT INDUCTION; Jain A. K., 1988, ALGORITHMS CLUSTERIN; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; JANTZEN J, 1998, 98H874 TU DNEM; KOSS L, 2000, ARTIFICIAL NEURAL NE, P51; Koza J., 1994, GENETIC PROGRAMMING; Koza J., 1992, GENETIC PROGRAMMING; Liu H., 1998, KLUWER INT SERIES EN; Martin E., 2003, THESIS TU DENMARK; MEISELS A, 1997, CYTOPATHOLOGY UTERUS; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SCHAPIRE R, 1990, MACH LEARN, V2, P197; TSAKONAS A, 2003, ARTIF INTELL MED, V32, P195	24	5	5	0	7	PROFESSOR D A SPANDIDOS	ATHENS	1, S MERKOURI ST, EDITORIAL OFFICE,, ATHENS 116 35, GREECE	1021-335X			ONCOL REP	Oncol. Rep.		2006	15				SI		1001	1006				6	Oncology	Oncology	022OS	WOS:000236066000005	16525690	
S	Mignani, AG; Ciaccheri, L		Culshaw, B; Mignani, AG; Bartelt, H; Jaroszewicz, LR		Mignani, A. G.; Ciaccheri, L.			Belgian beer mapping and digital fingerprinting using color and turbidity assessment - art. no. 61892E	Optical Sensing II	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Optical Sensing II	APR 03-06, 2006	Strasbourg, FRANCE	SPIE Europe, Conseil Gen Bas Rhin, Communaute Urbaine Strasbourg, Reg Alsace, Alsace Dev Agcy		absorption spectroscopy; color; turbidity; beer	CLASSIFICATION	Multi-wavelength and multi-angle absorption spectroscopy performed in the visible spectral range, that is, 'scattered colorimetry', has been used to map a library of 25 diverse and commercially-available Belgian light beers. The resulting map shows four main clusters, relative to blonde, amber, red, and weiss beers, respectively, demonstrating that scattered colorimetry is a valid method for beer authentication and fingerprinting.	CNR IFAC, Sesto Fiorentino, FI, Italy	Mignani, AG (reprint author), CNR IFAC, Via Madonna Piano 10, Sesto Fiorentino, FI, Italy.						ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUBULLE B, 2005, GUIDE BELGIAN BEERS; HUI YH, 1991, DATA SOURCEBOOK FOOD; Jackson M., 2001, GREAT BEERS BELGIUM; Mignani AG, 2005, SENSOR ACTUAT B-CHEM, V111, P363, DOI 10.1016/j.snb.2005.03.023; Mignani AG, 2005, P SOC PHOTO-OPT INS, V5855, P38, DOI 10.1117/12.623388; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA; WEBB T, 2005, GOOD BEER GUIDE BELG	10	0	0	1	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		0-8194-6245-4	P SOC PHOTO-OPT INS			2006	6189						E1892	E1892	61892E	10.1117/12.666908		4	Instruments & Instrumentation; Optics	Instruments & Instrumentation; Optics	BER03	WOS:000238999700074		
S	Srisawat, A; Phienthrakul, T; Kijsirikul, B		Yang, Q; Webb, G		Srisawat, Anantaporn; Phienthrakul, Tanasanee; Kijsirikul, Boonserm			SV-kNNC: An algorithm for improving the efficiency of k-nearest neighbor	PRICAI 2006: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2006)	AUG 07-11, 2006	Guilin, PEOPLES R CHINA					This paper proposes SV-kNNC, a new algorithm for k-Nearest Neighbor (kNN). This algorithm consists of three steps. First, Support Vector Machines (SVMs) are applied to select some important training data. Then, k-mean clustering is used to assign the weight to each training instance. Finally, unseen examples are classified by kNN. Fourteen datasets from the UCI repository were used to evaluate the performance of this algorithm. SV-kNNC is compared with conventional kNN and kNN with two instance reduction techniques: CNN and ENN. The results show that our algorithm provides the best performance, both predictive accuracy and classification time.	Chulalongkorn Univ, Fac Engn, Dept Comp Engn, Bangkok 10330, Thailand	Srisawat, A (reprint author), Chulalongkorn Univ, Fac Engn, Dept Comp Engn, Bangkok 10330, Thailand.	anantaporn.s@student.chula.ac.th; tanasanee@yahoo.com; boonserm.k@chula.ac.th	Kensri, Rattanadda/F-9116-2015				Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JANKOWSKI N, 2004, COMP INSTANCE SELECT, V1, P598; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Mitchell T. M., 1997, MACHINE LEARNING; Vapnik V., 1998, STAT LEARNING THEORY; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	9	5	5	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-36667-9	LECT NOTES ARTIF INT			2006	4099						975	979				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEY22	WOS:000240091500117		
B	Yu, XG; Yu, XP			IEEE	Yu, Xiao-Gao; Yu, Xiao-Peng			The research on an adaptive k-nearest neighbors classifier	Proceedings of 2006 International Conference on Machine Learning and Cybernetics, Vols 1-7			English	Proceedings Paper	5th International Conference on Machine Learning and Cybernetics	AUG 13-16, 2006	Dalian, PEOPLES R CHINA	IEEE Syst Man & Cybernet Soc, Hebei Univ, Hong Kong Polytech Univ, Harbin Inst Technol		nearest neighbor; pattern recognition; hypersphere; classification	ALGORITHM; SEARCH; RULE	k-Nearest neighbor (KNNC) classifier is the most popular non-parametric classifier. But it requires much classification time to search k nearest neighbors of an unlabelled object point, which badly affects its efficiency and performance. In this paper, an adaptive k-nearest neighbors classifier (AKNNC) is proposed. The algorithm can find k nearest neighbors of the unlabelled point in a small hypersphere in order to improve the efficiencies and classify the point. The hypersphere's size can be automatically determined. It requires a quite moderate preprocessing effort, and the cost to classify an unlabelled point is O(ad)+O(k)(1 <= a << n). Our experiment shows the algorithm performance is superior to other known algorithms.	Hubei Univ Econ, Wuhan 430205, Peoples R China; Wuhan Univ, Wuhan 430072, Peoples R China	Yu, XG (reprint author), Hubei Univ Econ, Wuhan 430205, Peoples R China.						Aghbari Z. A., 2005, Data & Knowledge Engineering, V52, DOI 10.1016/j.datak.2004.06.015; Batko M, 2005, LECT NOTES COMPUT SC, V3367, P79; BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; KUAN J, 1997, INT C INF COMM SIGN, P9; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Samet H., 2003, Proceedings 12th International Conference on Image Analysis and Processing; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; YU C, 2002, HIGH DIMENSIONAL IND, V2341, P85; YU XP, 2005, INT C SERV SYST SERV, P1016; ZHANG B, 2004, IEEE T PATTERN ANAL, V26	17	0	1	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			1-4244-0060-0				2006							1241	1246				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	BFE36	WOS:000241452301107		
B	Zhu, M; Chen, WH; Hirdes, J; Stolee, P		Wamkeue, R		Zhu, Mu; Chen, Wenhong; Hirdes, John; Stolee, Paul			Predicting rehabilitation potential with the K-nearest neighbors algorithm: A comparison with the current clinical assessment protocol	Proceedings of the 17th IASTED International Conference on Modelling and Simulation			English	Proceedings Paper	17th IASTED International Conference on Modelling and Simulation	MAY 24-26, 2006	Montreal, CANADA	Int Assoc Sci & Technol Dev, TCMS, World Modelling & Simulat Forum		Bayes' theorem; binary prediction; diagnostic likelihood ratio; interRAI minimum data set; machine learning; modelling and simulation methodologies	MDS	Using data from eight Community Care Access Centres (CCACs) in Ontario, we demonstrate that an automatic, data-driven, machine learning algorithm such as the K-nearest neighbors (KNN) algorithm can predict rehabilitation potential more effectively than the current Clinical Assessment Protocol (CAP). Implications for clinical decision-making and computerized health information systems are discussed.	Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada	Zhu, M (reprint author), Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada.						Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSTL.1763.0053; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hastie T, 2001, ELEMENTS STAT LEARNI; Hirdes J P, 1999, Healthc Manage Forum, V12, P30; Morris JN, 1999, J GERONTOL A-BIOL, V54, pM546, DOI 10.1093/gerona/54.11.M546; MORRIS JN, 1999, PRIMER USE MINIMUM D; Morris JN, 1997, J AM GERIATR SOC, V45, P1017; Pepe MS, 2003, STAT EVALUATION MED; R Development Core Team, 2004, R LANG ENV STAT COMP; Sackett D, 1991, CLIN EPIDEMIOLOGY BA; Stoke P, 2004, GERIATR TODAY J CAN, V7, P38; TREMBLAY M, 2005, PREDICTIVE HLTH POLI	12	0	0	0	0	ACTA PRESS ANAHEIM	ANAHEIM	PO BOX 5124, ANAHEIM, CA 92814-5124 USA			978-0-88986-592-1				2006							110	115				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Automation & Control Systems; Computer Science	BGE91	WOS:000246366600021		
S	Shang, WQ; Zhu, HB; Huang, HK; Qu, Y; Lin, YM			IEEE	Shang, Wenqian; Zhu, Haibin; Huang, Houkuan; Qu, Youli; Lin, Yongmin			The improved ontology kNN algorithm and its application	PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, SENSING AND CONTROL	IEEE International Conference on Networking, Sensing and Control		English	Proceedings Paper	IEEE International Conference on Networking, Sensing and Control	APR 23-25, 2006	Ft Lauderdale, FL	IEEE Syst, Man & Cybernet Soc			NEAREST NEIGHBOR	With the advances of the Web, more and more people, especially business people, use emails to communicate with each other. Hence, how to deal with business emails is becoming more and more important for decision makers, because among these emails, there hides valuable information such as the customer's complaints about a product or the interests of customers to a product. These are important information for a manager to propose marketing policies. In this paper, we develop an improved kNN algorithm----fkNN (fuzz kNN) algorithm based on ontology ideology to classify the emails. After classifying the emails into different classes, we can mine knowledge more easily based on the classified emails. Therefore, the classification effect is very important for mining knowledge further. Fortunately, our improved algorithm behaves much better than other algorithms in classification performance for our email datasets and other datasets.	Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China	Shang, WQ (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.	shangwenqian@hotmail.com; haibinz@nipissingu.ca; hkhuang@center.njtu.edu.cn; quyouli@center.njtu.edu.cn; linyongmin1208@tom.com					COST RS, 2002, IEEE INTELLIGENT JAN, P40; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; LEWIS DD, P 3 ANN S DOC AN INF; SHANG W, 2004, P IEEE C SYST MAN CY, P4084; Stevens R, 2000, BIOINFORMATICS, V16, P184, DOI 10.1093/bioinformatics/16.2.184; SUGUMARAN V, 2002, DATA KHOWL ENG, P251; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; WANG BB, 2002, P 2002 INT C COMM CI, P1230; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y., 1999, INFORMATION RETRIEVA, V1, P76	13	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1810-7869		1-4244-0065-1	IEEE INT C NETW SENS			2006							198	203				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Automation & Control Systems; Computer Science	BER46	WOS:000239057000035		
B	Pham, TD; Tran, DT			IEEE	Pham, Tuan D.; Tran, Dat T.			Gaussian mixture and Markov models for cell-phase classification in microscopic imaging	Proceedings of the 2006 IEEE/SMC International Conference on System of Systems Engineering			English	Proceedings Paper	IEEE/SMC International Conference on System of Systems Engineering	APR 24-26, 2006	Los Angeles, CA	IEEE, SMC		cellular imaging; identification; Gaussian mixture models; Markov models		Studies of drug effects on cancer cells are performed through measuring cell cycle progression such as inter phase, prophase, metaphase and anaphase in individual cells. Such studies require the processing and analysis of huge amounts of image data. Manual image analysis is very time consuming thus costly, potentially inaccurate and poorly reproducible. Stages of an automated cellular imaging analysis consist of segmentation, feature extraction, classification, and tracking of individual cells in a dynamic cellular population. Image classfication of cell phases in a fully automatic manner presents the most difficult task of such analysis. We considered applying several versions of Gaussian mixture and Markov models for automating the classification of cell nuclei in different mitotic phases recorded over a period of twenty-four hours at every fifteen minutes with a time-lapse fluoresence microscopy. The experimental results have shown that the proposed methods are effective and have potential for higher performance.	James Cook Univ N Queensland, Sch Informat Technol, Townsville, Qld 4811, Australia	Pham, TD (reprint author), James Cook Univ N Queensland, Sch Informat Technol, Townsville, Qld 4811, Australia.						[Anonymous], 2005, P IEEE, V93; Bezdek J. C., 1981, PATTERN RECOGNITION; CHEN X, IN PRESS IEEE T BIOM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Dunkle R, 2003, DRUG DISCOVERY WORLD, V4, P75; FENG Y, 2002, EUROPEAN PHARM REV, V7, P7; FOX S, 2003, DRUG DISCOVERY WORLD, V5, P21; Hiraoka Y, 1996, CHROMOSOME RES, V4, P173, DOI 10.1007/BF02254954; Huang X. D., 1990, HIDDEN MARKOV MODELS; Kanda T, 1998, CURR BIOL, V8, P377, DOI 10.1016/S0960-9822(98)70156-3; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Murphy D. B., 2001, FUNDAMENTALS LIGHT M; PHAM TD, 2005, P AI 2005 WORKSH LEA, P52; PHAM TD, 2006, NEURAL STEM CELL RES; RABINER LR, 1983, AT&T TECH J, V62, P1075; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; TRAN D, 2000, P SPOKEN LANGUAGE PR, V1, P421; Tran D., 1999, P IEEE INT C NAFIS, P426; Tran D., 2000, P FUZZ IEEE C MAY US, V1, P152; Yarrow JC, 2003, COMB CHEM HIGH T SCR, V6, P279	21	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0187-1				2006							303	308				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Telecommunications	Automation & Control Systems; Computer Science; Telecommunications	BFZ13	WOS:000245541700053		
B	He, J; Dai, XB; Zhao, XC			IEEE	He, Ji; Dai, Xinbin; Zhao, Xuechun			A systematic computational approach for transcription factor target gene prediction	Proceedings of the 2006 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology			English	Proceedings Paper	IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology	SEP 28-29, 2006	Toronto, CANADA					Computational prediction of transcription factor's binding sites and regulatory target genes has great value to the biological studies of cellular process. Existing practices either look into first-hand gene expression data which could be costly for large scale analysis, or apply statistical or heuristic learning methods to discover potential binding sites which have limited accuracy due to the complexity of the data. Based on well-studied information retrieval theories, this paper proposes a novel systematic approach for transcription factor target gene prediction. The key of the approach is to model the prediction problem as a classification task by representing the features of the sequential data into vector data points in a higher-order domain. The proposed approach has produced satisfactory results in our controlled experiment on Auxin Response Factor (ARF) target gene prediction in Arabidopsis.	Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Grp, Ardmore, OK 73401 USA	He, J (reprint author), Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Grp, 2510 Sam Noble Pkwy, Ardmore, OK 73401 USA.						AKUTSU S, 1998, P 9 ANN ACM SIAM S D; BAILEY TL, 1995, MACH LEARN, V21, P51, DOI 10.1023/A:1022617714621; BILU Y, 2002, ISMB; Cavnar W.B, 1994, P 3 ANN S DOC AN INF, P161; CHEN T, 1999, P 3 ANN RECOMB; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROWDER G, 1996, P 1 IEEE MET C; DASARATHY BV, 1991, NEAREST NIGHBOR NN N; Friedman N., 2000, RECOMB 2000. Proceedings of the Fourth Annual International Conference on Computational Molecular Biology; Goda H, 2004, PLANT PHYSIOL, V134, P1555, DOI 10.1104/pp.103.034736; Good I. J., 1965, ESTIMATION PROBABILI; Goutsias J, 2006, IEEE ACM T COMPUT BI, V3, P57, DOI 10.1109/TCBB.2006.2; HE J, 2003, APPL INTELL, V18, P31; HUFFMAN S, 1996, TREC 4 P; JOCHIMS T, 1998, P EUR C MACH LEARN; LAM W, 1997, P 15 INT JOINT C ART, P745; Liu ZB, 1997, PLANT PHYSIOL, V115, P397, DOI 10.1104/pp.115.2.397; Mandel-Gutfreund Y, 2001, Pac Symp Biocomput, P139; Shannon E. C., 1948, BELL SYST TECH J, V27, P623; TAN AH, 1995, NEURAL NETWORKS, V8, P437, DOI 10.1016/0893-6080(94)00092-Z; Taskar B., 2002, P 18 C UNC ART INT, P485; VANRIJSBERGEN CJ, 1979, INFOR RETIEVAL; Workman CT, 2000, PAC S BIOCOMPUT, V5, P464; Yang Y., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; YANG Y, 1994, 17 ANN INT ACM SIGIR; Yang Y., 1999, 22 ANN INT ACM SIGIR, P42	26	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			1-4244-0623-4				2006							385	391				7	Mathematical & Computational Biology	Mathematical & Computational Biology	BFW23	WOS:000245066100053		
B	Yu, XP; Yu, XG		Yao, Y; Shi, ZZ; Wang, YX; Kinsner, W		Yu, Xiaopeng; Yu, Xiaogao			The research on an adaptive k-nearest neighbors classifier	Proceedings of the Fifth IEEE International Conference on Cognitive Informatics, Vols 1 and 2			English	Proceedings Paper	5th IEEE International Conference on Cognitive Informatics (ICCI 2006)	JUL 17-19, 2006	Beijing, PEOPLES R CHINA	IEEE Comp Soc, Chinese Acad Sci, IEEE ICCI Steering Comm, IJCiNi, IEEE Canada, IEEE CS Press		nearest neighbor; pattern recognition; hypersphere; classification	ALGORITHM; SEARCH; RULE	K-nearest neighbor (KNNC) classifier is the most popular non-parametric classifier. But it requires much classification time to search k nearest neighbors of an unlabelled object point, which badly affects its efficiency and performance. In this paper, an adaptive k-nearest neighbors classifier (AKNNC) is proposed. The algorithm can find k nearest neighbors of the unlabelled point in a small hypersphere in order to improve the efficiencies and classify the point. The hypersphere's size can be automatically determined. It requires a quite moderate preprocessing effort, and the cost to classify an unlabelled point is O(ad) + O(k)(1 <= a << N) . Our experiment shows the algorithm performance is superior to other known algorithms.	Wuhan Univ, Comp Sch, Wuhan 430072, Peoples R China; Hubei Univ Econ, Wuhan 430070, Peoples R China	Yu, XP (reprint author), Wuhan Univ, Comp Sch, Wuhan 430072, Peoples R China.						Al Aghbari Z, 2005, DATA KNOWL ENG, V52, P333, DOI 10.1016/j.datak.2004.06.015; Batko M., 2004, Databases, Information Systems, and Peer-to-Peer Computing. Second International Workshop, DBISP2P 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol.3367); BINZHANG, 2004, IEEE T PATTERN ANAL, V26; BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUI Y, 2002, HIGH DIMENSIONAL IND, V2341, P85; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; KUAN J, 1997, INT C INF COMM SIGN, P9; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Samet H., 2003, Proceedings 12th International Conference on Image Analysis and Processing; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; XIAOPENG Y, 2005, NEW CLUST ALG BAS DI, P1016	17	0	0	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-1-4244-0475-9				2006							535	540				6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BGH41	WOS:000246981800080		
B	Panigrahy, R			SIAM/ACM	Panigrahy, Rina			Entropy based Nearest Neighbor Search in High Dimensions	PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS			English	Proceedings Paper	17th ACM-SIAM Symposium on Discrete Algorithms	JAN, 2006	Miami, FL	ACM SIGACT, SIAM			IMAGE	In this paper we study the problem of finding the approximate nearest neighbor of a query point in the high dimensional space, focusing on the Euclidean space. The earlier approaches use locality-preserving hash functions (that tend to map nearby points to the same value) to construct several hash tables to ensure that the query point hashes to the same bucket as its nearest neighbor in at least one table. Our approach is different we use one (or a few) hash table and hash several randomly chosen points in the neighborhood of the query point showing that at least one of them will hash to the bucket containing its nearest neighbor. We show that the number of randomly chosen points in the neighborhood of the query point q required depends on the entropy of the hash value h(p) of a random point p at the same distance from q at its nearest neighbor, given q and the locality preserving hash function h chosen randomly from the hash family. Precisely, we show that if the entropy I (h(p)vertical bar q, h) = M and g is a bound on the probability that two far-off points will hash to the same bucket, then we can find the approximate nearest neighbor in O(n(rho)) time and near linear (O) over tilde (n) space where p = M/log(l/g). Alternatively we can build a data structure of size O(n1/((1-rho)) to answer queries in 0(d) time. By applying this analysis to the locality preserving hash functions in [17, 21, 6] and adjusting the parameters we show that the c nearest neighbor can be computed in time O(nP) and near linear space where rho approximate to 2.06/c as c becomes large.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Panigrahy, R (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	rinap@cs.stanford.edu					Agarwal P. K., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/129712.129763; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M., 2004, P S COMP GEOM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Dolev D., 1993, Proceedings of the 2nd Israel Symposium on Theory and Computing Systems (Cat. No.93TH0520-7), DOI 10.1109/ISTCS.1993.253486; Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275488; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; HARPELED S, 2001, P S FDN COMP SCI; INDYK P, 2002, ACM S COMP GEOM; Indyk P., 2003, WORKSH STAT COMP THE; Indyk P., 1997, P 29 ANN ACM S THEOR, P618, DOI 10.1145/258533.258656; INDYK P, 2001, HIGH DIMENSIONAL COM; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Indyk P., 2004, HDB DISCRETE COMPUTA, V2nd; Jayram T.S., 2003, P 35 ANN ACM S THEOR, P667; Kleinberg J.M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; Linial N., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237999; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; Salton G., 1989, AUTOMATIC TEXT PROCE; van Rijsbergen C. J., 1990, INFORM RETRIEVAL; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Zolotarev V. M., 1986, TRANSLATIONS MATH MO, V65	28	22	25	0	0	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			978-0-89871-605-4				2006							1186	1195		10.1145/1109557.1109688		10	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BQR14	WOS:000281596300131		
B	Ye, T; Zhu, XF; Li, XY; Li, Y		Beihai, H; Shiya, F; Fangeng, C		Ye Tao; Zhu Xuefeng; Li Xiangyang; Li Yan			Predicting the pulp kappa number with a soft sensor based on the k-nearest neighbor algorithm	Research Progress in Pulping and Papermaking, 2006			English	Proceedings Paper	3rd International Symposium on Emerging Technologies of Pulping and Papermaking	NOV 08-10, 2006	Guangzhou, PEOPLES R CHINA	State Key Lab Pulp & Paper Engn, S China Univ Technol, Natl Nat Sci Fdn China, Tech Assoc Pulp & Paper Ind		soft sensor; neural network; kappa number		Soft sensing models based on supervised learning neural networks were well studied in the recent two decades. The k-Nearest Neighbor (kNN) algorithm is a kind of instance-based learning methods. It locally generalizes a new instance within its neighborhood. This paper proposes a modified kNN regression algorithm based on the dataset editing algorithm and quadratic distance definition, with which a soft sensor is constructed. Finally, the modified kNN algorithm based soft sensor is applied to the Kappa number prediction in the batch KP process.	S China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510640, Peoples R China	Ye, T (reprint author), S China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510640, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GUTTMAN A, 1984, ACM SIGMOD, V13, P47; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Li H, 2000, SOFT SENSING TECHNOL; LI XY, 2001, THESIS S CHINA U TEC; Luo Ming, 2002, Journal of Tsinghua University (Science and Technology), V42; LUO Q, 1998, THESIS GUANGZHOU S C; MCAVOY TJ, 1992, AUTOMATICA, V28, P441, DOI 10.1016/0005-1098(92)90134-2; Mitchell T. M., 2003, MACHINE LEARNING; Yu Jingjiang, 1996, Control Theory & Applications, V13; Zhang Hong-Bin, 2000, Acta Electronica Sinica, V28; [朱学峰 Zhu Xuefeng], 2002, [华南理工大学学报. 自然科学版, Journal of South China University of Technology Natural Sciences], V30, P61	12	0	0	0	5	SOUTH CHINA UNIV TECHNOLOGY PRESS	GUANGZHOU	GUANGZHOU 510641, GUANGDONG, PEOPLES R CHINA			978-7-5623-2514-7				2006							788	791				4	Engineering, Manufacturing; Materials Science, Paper & Wood	Engineering; Materials Science	BFR65	WOS:000244038600160		
B	Yamada, T; Yamashita, K; Ishii, N; Iwata, K		Song, YT; Lu, C	IEEE	Yamada, Takahiro; Yamashita, Kyohei; Ishii, Naohiro; Iwata, Kazunori			Text classification by combining different distance functions with weights	SNPD 2006: Seventh ACIS International Conference on Software Engineering Artificial Intelligence, Networking, and Parallel/Distributed Computing, Proceedings			English	Proceedings Paper	7th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel and Distributed Computing/7th ACIS International Workshop on Self-Assembling Networks	JUN 19-20, 2006	Las Vegas, NV	Int Assoc Comp & Informat Sci, Towson Univ, Cent Michigan Univ				Since data is becoming greatly large in the networks, the machine classification of the text data, is not easy under these computing circumstances. Though the k-nearest neighbor (kNN) classification is a simple and effective classification approach, the improving performance of the classifier is still attractive to cope with the high accuracy processing. In this paper, the WN is improved by applying the different distance functions with weights to measure data from the multi-view points. Then, the weights for the optimization, are computed by the genetic algorithms. After the learning of the trained data, the unknown data is classified by combining the multiple distance functions and ensemble computations of the kNN. In this paper we present a new approach to combine multiple kNN classifiers based on different distance functions, which improve the performance of the k-nearest neighbor method. The proposed combining algorithm shows the higher generalization accuracy when compared to other conventional learning algorithms.	Aichi Inst Technol, Toyota 4700392, Japan	Yamada, T (reprint author), Aichi Inst Technol, 1247 Yachigusa, Toyota 4700392, Japan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAO NY, 2005, LNCS, V3578, P133; BAO Y, 2002, P 5 INT C DISC SCI, P361; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; LANGLEY W, 1992, P 10 NATL C AI, P223; McClelland JL, 1988, EXPLORATIONS PARALLE; Merz C, 1998, UCI REPOSITORY MACHI; Michie D., 1994, MACHINE LEARNING NEU; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	13	3	3	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			0-7695-2611-X				2006							85	90				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BEQ48	WOS:000238913400013		
S	Mico, L; Moreno-Seco, F; Sanchez, JS; Sotoca, JM; Mollineda, RA		Yeung, DY; Kwok, JT; Fred, A; Roli, F; DeRidder, D		Mico, Luisa; Moreno-Seco, Francisco; Sanchez, Jose Salvador; Sotoca, Jose Martinez; Mollineda, Ramon Alberto			On the use of different classification rules in an editing task	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	Joint International Workshop on Structural, Syntactic, and Statistical Pattern Recognition	AUG 17-19, 2006	Hong Kong, PEOPLES R CHINA	Int Assoc Pattern Recognit, Tech Comm TC1 & TC2, Hong Kong Univ Sci & Technol		pattern recognition; classification; nearest neighbor; prototype selection; editing		Editing allows the selection of a representative subset of prototypes among the training sample to improve the performance of a classification task. The Wilson's editing algorithm was the first proposal and then a great variety of new editing techniques have been proposed based on it. This algorithm consists on the elimination of prototypes in the training set that are misclassified using the k-NN rule. From such editing scheme, a general editing procedure can be straightforward derived, where any classifier beyond k-NN can be used. In this paper, we analyze the behavior of this general editing procedure combined with 3 different neighborhood-based classification rules, including k-NN. The results reveal better performances of the 2 other techniques with respect to k-NN in most of cases.	Univ Alacant, Dept Llenguatges & Sistemes Informat, E-03071 Alacant, Spain; Univ Jaume 1, Dept Llenguatges & Sistemes Informat, E-12071 Castello La Plana, Spain	Mico, L (reprint author), Univ Alacant, Dept Llenguatges & Sistemes Informat, E-03071 Alacant, Spain.			Sanchez Garreta, Jose Salvador/0000-0003-1053-4658			BERNARDO E, 2004, P 17 INT C PATT REC, P136; Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P11, DOI 10.1016/0167-8655(95)00093-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; DUDA RO, 1973, PATTERN CLASSFICATIO; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Moreno-Seco F, 2003, LECT NOTES COMPUT SC, V2652, P589; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	10	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		3-540-37236-9	LECT NOTES COMPUT SC			2006	4109						747	754				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEY05	WOS:000240075100082		
B	Horng, SJ; Huang, GC; Luo, WY		Callaos, N; Lesso, W; Ham, C; DellOsso, LF; Li, Z		Horng, Shi-Jinn; Huang, Guan-Chi; Luo, Wen-Yang			Protecting Web server from DDoS attacks using three-layer detection mechanism	WMSCI 2006: 10TH WORLD MULTI-CONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL II, PROCEEDINGS			English	Proceedings Paper	10th World Multi-Conference on Systemics, Cybernetics and Informatics/12th International Conference on Information Systems Analysis and Synthesis	JUL 16-19, 2006	Orlando, FL	Int Inst Informat & System		Distributed Denial of Service Attack; network security; intrusion detection; KNN; entropy-based analysis		According to FBI 2004 Computer Crime and Security Survey Result, Distributed Denial of Service Attack is the second dangerous network attack. The attacker use abnormal activities to consume the system resource or to degrade the performance of network instead of intruding the system itself Currently, Detection mechanisms are researched that is able to detect the abnormal activities when the attackers use the large amount of packets to break the system down in the development of DDoS. However, the changeable frequency mode will be the tendency in the future. In this paper, we proposed the three-layer detection mechanism which can look for the sophisticated attack packets such as the changeable frequency attack mode. Firstly, we will analyze which fields in the packet may be our features. After analyzing, the features will be grouped into detection characteristics of each layer which quantifies the normal service behavior precisely according to their features. It is easy and immediate to detect the abnormal behavior when the attacks occur. We implement our proposed mechanism in the NTUST's Web Server. We will attack the Web server in practice to observe the difference for beginning to end. And our proposed mechanism can reach a higher performance.	[Horng, Shi-Jinn; Huang, Guan-Chi; Luo, Wen-Yang] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Info Engn, TWISC, Taipei, Taiwan	Horng, SJ (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Info Engn, TWISC, Taipei, Taiwan.						A Lawrence, 2004, CSI FBI COMPUTER CRI; AHA DW, 1986, ARTIF INTELL, V29, P241; *CERT RES, 2004 ANN REP; CHAITIN GJ, 1974, J ACM, V21, P403, DOI 10.1145/321832.321839; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Forouzan B. A., 2003, TCP IP PROTOCOL SUIT; Han Jiawei, 2001, DATA MINING CONCEPTS; HOWARD J, 1998, THESIS C MELLON U; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; MACGREGOR JF, 1993, J QUAL TECHNOL, V25, P106; MARKOWSKY G, 1996, J UNIVERS COMPUT SCI, V2, P245; MONTGOMETRY DC, 1997, INTRO STAT QUALITY C; Ryan T., 1989, STAT METHODS QUALITY; Shannon C. E., 1963, MATH THEORY COMMUNIC; YOO I, 2004, INF ASS WORKSH 2004, P74	15	0	0	0	0	INT INST INFORMATICS & SYSTEMICS	ORLANDO	14269 LORD BARCLAY DR, ORLANDO, FL 32837 USA			978-980-6560-67-3				2006							279	284				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BHA56	WOS:000251936800053		
J	Paredes, R; Vidal, E				Paredes, R; Vidal, E			Learning prototypes and distances: A prototype reduction technique based on nearest neighbor error minimization	PATTERN RECOGNITION			English	Article						nearest neighbor; condensing; weighted dissimilarity distances	PATTERN-CLASSIFICATION; RULE	A prototype reduction algorithm is proposed, which simultaneously trains both a reduced set of prototypes and a suitable local metric for these prototypes. Starting with an initial selection of a small number of prototypes, it iteratively adjusts both the position (features) of these prototypes and the corresponding local-metric weights. The resulting prototypes/metric combination minimizes a suitable estimation of the classification error probability. Good performance of this algorithm is assessed through experiments with a number of benchmark data sets and with a real task consisting in the verification of images of human faces. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Politecn Valencia, DSIC, Valencia 46022, Spain	Paredes, R (reprint author), Univ Politecn Valencia, DSIC, Camino Vera S-N, Valencia 46022, Spain.	rparedes@iti.upv.es; evidal@iti.upv.es					Bailly-Bailliere E, 2003, LECT NOTES COMPUT SC, V2688, P625; Blake CL, UCI REPOSITORY MACHI; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, ADV NEUR IN, V8, P409; HOWE N, 1997, LECT NOTES ARTIF INT, P455; Kohavi R., 1997, P 9 EUR C MACH LEARN; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KOHONEN T, 1988, IEEE INT C NEUR NETW, V1, P61; KONONENKO I, 1993, ESTIMATING ATTRIBUTE; KOSTIN A, 2002, COST 275 WORKSH ADV, P9; MARCEL S, 2003, FACE VERIFICATION US; MARCEL S, 2003, SYMMETRIC TRANSFORMA; McLachlan G., 2000, FINITE MIXTURE MODEL; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Paredes R., 2000, P 15 INT C PATT REC, V2, P25, DOI 10.1109/ICPR.2000.906011; Paredes R, 2002, INT C PATT RECOG, P48; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PAREDES R, 2003, THESIS DSIC UPV; PAREDES R, 1999, 8 S NAC REC FORM AN, V1, P437; PENG J, 2004, IEEE T PATTERN ANAL, V26; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Titsias MK, 2003, IEEE T PATTERN ANAL, V25, P924, DOI 10.1109/TPAMI.2003.1206521; Vapnik V., 1998, STAT LEARNING THEORY; Wilson D. R., 1996, Proceedings of the IASTED International Conference. Artificial Intelligence, Expert Systems and Neural Networks	30	36	36	0	2	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	FEB	2006	39	2					180	188		10.1016/j.patcog.2005.06.001		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	988LZ	WOS:000233604000004		
J	Pekalska, E; Duin, RPW; Paclik, P				Pekalska, E; Duin, RPW; Paclik, P			Prototype selection for dissimilarity-based classifiers	PATTERN RECOGNITION			English	Article						dissimilarity; representation; prototype selection; normal density based classifiers; nearest neighbor rule	NEAREST-NEIGHBOR CLASSIFICATION; PATTERN-CLASSIFICATION; KERNEL CLASSIFIER; RULE; REPRESENTATION; RECOGNITION; ALGORITHMS; SEARCH	A conventional way to discriminate between objects represented by dissimilarities is the nearest neighbor method. A more efficient and sometimes a more accurate solution is offered by other dissimilarity-based classifiers. They construct a decision rule based on the entire training set, but they need just a small set of prototypes, the so-called representation set, as a reference for classifying new objects. Such alternative approaches may be especially advantageous for non-Euclidean or even non-metric dissimilarities. The choice of a proper representation set for dissimilarity-based classifiers is not yet fully investigated. It appears that a random selection may work well. In this paper, a number of experiments has been conducted on various metric and non-metric dissimilarity representations and prototype selection methods. Several procedures, like traditional feature selection methods (here effectively searching for prototypes), mode seeking and linear programming are compared to the random selection. In general, we find out that systematic approaches lead to better results than the random selection, especially for a small number of prototypes. Although there is no single winner as it depends on data characteristics, the k-centres works well, in general. For two-class problems, an important observation is that our dissimilarity-based discrimination functions relying on significantly reduced prototype sets (3-10% of the training objects) offer a similar or much better classification accuracy than the best k-NN rule on the entire training set. This may be reached for multi-class data as well, however such problems are more difficult. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Delft Univ Technol, Fac Elect Engn Math & Comp Sci, NL-2628 CD Delft, Netherlands	Pekalska, E (reprint author), Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Mekelweg 4, NL-2628 CD Delft, Netherlands.	e.pekalska@ewi.tudelft.nl; r.p.w.duin@ewi.tudelft.nl; p.paclik@ewi.tudelft.nl					Avesani P., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, DOI 10.1109/DEXA.1999.795170; BERCHTOLD S, 1998, P 14 INT C DAT ENG O; Blake CL, UCI REPOSITORY MACHI; Bradley P. S., 1998, INFORMS Journal on Computing, V10, DOI 10.1287/ijoc.10.2.209; Bunke H., 2001, LNCS, V2013, P1; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790; Corpet F, 2000, NUCLEIC ACIDS RES, V28, P267, DOI 10.1093/nar/28.1.267; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L., 1996, PROBABILISTIC THEORY; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Dubuisson M. P., 1994, P 12 INT C PATT REC, V1, P566, DOI DOI 10.1109/ICPR.1994.576361; Duda R O, 2001, PATTERN CLASSIFICATI; Duin R., 2004, ICPR 2004 WORKSH P C, P43; Duin RPW, 2004, PR TOOLS MATLAB TOOL; Duin RPW, 1998, KYBERNETIKA, V34, P399; Edelman S., 1999, REPRESENTATION RECOG; Goldfarb L, 1985, PROGR PATTERN RECOGN, V2, P241; GRAEPEL T, 1999, P 9 INT C ART NEUR N, P304; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Huang YS, 2002, PATTERN RECOGN, V35, P1237, DOI 10.1016/S0031-3203(01)00124-8; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; Kohonen T., 1995, SELF ORG MAPS; Landgrebe D. A., 2003, SIGNAL THEORY METHOD; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; MacQueen J., 1967, BERK S MATH STAT PRO, P281; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; Mico L, 1998, PATTERN RECOGN LETT, V19, P351, DOI 10.1016/S0167-8655(98)00007-5; Mico L, 1996, PATTERN RECOGN LETT, V17, P731, DOI 10.1016/0167-8655(96)00032-3; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Moreno-Seco F, 2003, PATTERN RECOGN LETT, V24, P47, DOI 10.1016/S0167-8655(02)00187-3; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Paclik P, 2003, REAL-TIME IMAGING, V9, P237, DOI 10.1016/j.rti.2003.09.002; PACLIK P, 2003, P SPECTR IM WORKSH G; Paclik P, 2000, PATTERN RECOGN LETT, V21, P1165, DOI 10.1016/S0167-8655(00)00078-7; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PEKALSKA E, 2005, ASCI DISSERTATION SE, V109; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; PEKALSKA E, 2004, P STRUCT STAT PATT R, P1143; Pekalska E., 2001, J MACHINE LEARNING R, V2, P175; Ramasubramanian V, 2000, PATTERN RECOGN, V33, P1497, DOI 10.1016/S0031-3203(99)00134-X; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; Roth V., 2003, ADV NEURAL INFORM PR, P841; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; Wilson C., 1992, HANDPRINTED CHARACTE; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WILSON DR, 1997, J ARTIF INTELL RES, V6	53	110	112	0	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	FEB	2006	39	2					189	208		10.1016/j.patcog.2005.06.012		20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	988LZ	WOS:000233604000005		
J	Ghosh, AK; Chaudhuri, P; Sengupta, D				Ghosh, AK; Chaudhuri, P; Sengupta, D			Classification using kernel density estimates: Multiscale analysis and visualization	TECHNOMETRICS			English	Article						majority voting; misclassification rates; MISE; optimal bandwidths; p value-type measure; Pairwise coupling; posterior probability; weighted posterior	DISCRIMINANT-ANALYSIS; BANDWIDTH SELECTION; NEURAL-NETWORKS; SCALE-SPACE; REGRESSION; SPLINES; CURVES; VIEW	The use of kernel density estimates in discriminant analysis is quite well known among scientists and engineers interested in statistical pattern recognition. Using a kernel density estimate involves properly selecting the scale of smoothing, namely the bandwidth parameter. The bandwidth that is optimum for the mean integrated square error of a class density estimator may riot always be good for discriminant analysis, where the main emphasis is on the minimization of misclassification rates. On the other hand,, cross-validation-based methods for bandwidth selection, which try to minimize estimated misclassification rates, may require huge computation when there are several competing populations. Besides, such methods usually allow only one bandwidth for each Population density estimate, whereas in a classification problem, the Optimum bandwidth for a class density estimate may vary significantly, depending on its competing class densities and their prior probabilities. Therefore, in a multiclass problem, it would be more meaningful to have different bandwidths for a class density when it is compared with different competing class densities. Moreover, good choice of bandwidths should also depend on the specific observation to be classified. Consequently, instead of concentrating on a single optimum bandwidth for each population density estimate. it is more useful in practice to look at the results for different scales of smoothing for the kernel density estimates. This article presents such a multiscale approach along with a graphical device leading to a more informative discriminant analysis than the usual approach based on a single optimum scale of smoothing for each class density estimate. When there are more than two competing classes, this method splits the problem into a number of two-class problems, which allows the flexibility of using different bandwidths for different pairs of competing classes and at the same time reduces the computational burden that one faces for usual cross-validation-based bandwidth selection in the presence of several competing populations. We present some benchmark examples to illustrate the usefulness of the proposed methodology.	Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, W Bengal, India; Indian Stat Inst, Appl Stat Unit, Kolkata 700108, W Bengal, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, W Bengal, India.	anilkghosh@rediffmail.com; probal@isical.ac.in; sdebasis@isical.ac.in					Bose S, 1996, COMPUT STAT DATA AN, V22, P505, DOI 10.1016/0167-9473(96)00009-6; Breiman L, 1998, ANN STAT, V26, P801; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Chaudhuri P, 2000, ANN STAT, V28, P408; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; Coomans D., 1986, POTENTIAL PATTERN RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijer P. A., 1982, PATTERN RECOGNITION; DUDA R, 2000, PATTERN CLASSIFICATK; FRIDDMAN JH, 1996, ANOTHER APPROACH POL; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Ghosh AK, 2004, STAT SINICA, V14, P457; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; Godtliebsen F, 2004, IMAGE VISION COMPUT, V22, P1093, DOI 10.1016/j.imavis.2004.05.002; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; HALL P, 1983, ANN STAT, V11, P1156; HALL P, 1988, BIOMETRIKA, V75, P541, DOI 10.1093/biomet/75.3.541; HALL P, 1991, BIOMETRIKA, V78, P263; Hall P., 1980, MARTINGALE LIMIT THE; Hand D. J., 1982, KERNEL DISCRIMINANT; Hastie T, 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Hastie T, 1998, ANN STAT, V26, P451; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Jones MC, 1995, KERNEL SMOOTHING; Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; LEE Y, 1989, ADV NEURAL INFORMATI, P168; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Minnotte M. C., 1993, J COMPUT GRAPH STAT, V2, P51, DOI 10.2307/1390955; Minnotte MC, 1998, J COMPUT GRAPH STAT, V7, P239, DOI 10.2307/1390816; MULLER HG, 1984, ANN STAT, V12, P766, DOI 10.1214/aos/1176346523; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; REAVEN GM, 1979, DIABETOLOGIA, V16, P17, DOI 10.1007/BF00423145; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Ripley BD, 1996, PATTERN RECOGNITION; Schapire RE, 1998, ANN STAT, V26, P1651; Scott D.W., 1992, MULTIVARIATE DENSITY; SHEATHER SJ, 1991, J ROY STAT SOC B MET, V53, P683; Silverman BW, 1986, DENSITY ESTIMATION S; STONE CJ, 1984, ANN STAT, V12, P1285, DOI 10.1214/aos/1176346792; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9	49	18	18	0	1	AMER STATISTICAL ASSOC	ALEXANDRIA	732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA	0040-1706	1537-2723		TECHNOMETRICS	Technometrics	FEB	2006	48	1					120	132		10.1198/004017005000000391		13	Statistics & Probability	Mathematics	009RK	WOS:000235129800012		
J	Zhuge, Y; Udupa, JK; Saha, PK				Zhuge, Y; Udupa, JK; Saha, PK			Vectorial scale-based fuzzy-connected image segmentation	COMPUTER VISION AND IMAGE UNDERSTANDING			English	Article						fuzzy connectedness; scale; vectorial image; image segmentation	THRESHOLD SELECTION METHOD; BRAIN MR-IMAGES; INTENSITY INHOMOGENEITIES; OBJECT DEFINITION; ALGORITHMS; MODELS; REGION; QUANTIFICATION; INFORMATION; GRADIENT	This paper presents an extension of previously published theory and algorithms for fuzzy-connected image segmentation. In this approach, a strength of connectedness is assigned to every pair of image elements. This is done by finding the strongest among all possible connecting paths between the two elements in each pair. The strength assigned to a particular path is defined as the weakest affinity between successive pairs of elements along the path. Affinity specifies the degree to which elements hang together locally ill the image. A scale is determined at every element in the image that indicates the size of the largest homogeneous hyperball region centered at the element. In determining affinity between any two elements, all elements within their scale regions are considered. This method has been effectively utilized in several medical applications. In this paper, we generalize this method from scalar images to vectorial images. In a vectorial image, scale is defined as the radius of the largest hyperball contained in the same homogeneous region under a predefined condition of homogeneity of the image vector field. Two different components of affinity, namely homogeneity-based affinity and object-feature-based affinity, are devised in a fully vectorial manner. The original relative fuzzy connectedness algorithm is utilized to delineate a specified object via a competing strategy among multiple objects. We have presented several studies to evaluate the performance of this method based on simulated MR images, 20 clinical MR images, and 250 mathematical phantom images. These studies indicate that the fully vectorial fuzzy connectedness formulation has generally overall better accuracy than the method using some intermediate ad hoc steps to fit the vectorial image to a scalar fuzzy connectedness formulation, and precision and efficiency are similar for these two methods. (c) 2005 Published by Elsevier Inc.	Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA	Udupa, JK (reprint author), Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA.	jay@mipg.upenn.edu	Saha, Punam /F-8833-2011				Beucher S., 1993, MATH MORPHOLOGY IMAG, V12, P433; Bezdek J. C., 1992, FUZZY MODELS PATTERN; BLOCH I, 1993, PATTERN RECOGN LETT, V14, P483, DOI 10.1016/0167-8655(93)90028-C; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503; CHANG YL, 1994, IEEE T IMAGE PROCESS, V3, P868; Cho Z.-H., 1993, FDN MED IMAGING; CHU CC, 1993, IEEE T PATTERN ANAL, V15, P1241; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Falcao AX, 1998, GRAPH MODEL IM PROC, V60, P233, DOI 10.1006/gmip.1998.0475; Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883; Herman GT, 2001, IEEE T PATTERN ANAL, V23, P460, DOI 10.1109/34.922705; IMIELINSKA C, 2001, P MICCAI UTR NETH, V2208, P1048; Jones T., 1997, P INF PROC MED IM, P113; KASS M, 1987, INT J COMPUT VISION, V1, P321; KATO Z, 1999, PNAR9902 CWI; Kaufmann A., 1975, INTRO THEORY FUZZY S, V1; Lei TH, 2001, IEEE T MED IMAGING, V20, P689; LI S, 1995, RANDOM FIELD MODELIN; LIANG ZR, 1994, IEEE T MED IMAGING, V13, P441; LIM YW, 1990, PATTERN RECOGN, V23, P935; Liu JG, 2003, ACAD RADIOL, V10, P13, DOI 10.1016/S1076-6332(03)80783-3; Marroquin JL, 2002, IEEE T MED IMAGING, V21, P934, DOI 10.1109/TMI.2002.803119; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; Moonis G, 2002, AM J NEURORADIOL, V23, P356; MORGENTHALER DG, 1981, IEEE T PATTERN ANAL, V3, P482; Mortensen E. N., 1995, P 22 ANN C COMP GRAP, P191, DOI DOI 10.1145/218380.218442; Nyul LG, 1999, MAGNET RESON MED, V42, P1072, DOI 10.1002/(SICI)1522-2594(199912)42:6<1072::AID-MRM11>3.0.CO;2-M; NYUL LG, 2003, GRAPH MODELS, V64, P259; Nyul LG, 2002, P SOC PHOTO-OPT INS, V4684, P1588, DOI 10.1117/12.467128; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; PEDNEKAR AS, 2003, P IND C COMP VIS GRA, P457; Rajapakse JC, 1998, IMAGE VISION COMPUT, V16, P165, DOI 10.1016/S0262-8856(97)00067-X; ROSENFELD A, 1979, INFORM CONTROL, V40, P76, DOI 10.1016/S0019-9958(79)90353-X; Saha PK, 2001, COMPUT VIS IMAGE UND, V83, P275, DOI 10.1006/cviu.2001.0927; Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; Saha PK, 2001, IEEE T MED IMAGING, V20, P792, DOI 10.1109/42.938247; Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562; Sethian J. A., 1996, LEVEL SET METHODS FA; Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174; TRIVEDI MM, 1986, IEEE T SYST MAN CYB, V16, P589, DOI 10.1109/TSMC.1986.289264; UDUPA JK, 1994, P SOC PHOTO-OPT INS, V2164, P58, DOI 10.1117/12.174042; Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021; Udupa JK, 2002, PROC SPIE, V4684, P266, DOI 10.1117/12.467166; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162; Vanhamel I, 2003, IEEE T IMAGE PROCESS, V12, P617, DOI 10.1109/TIP.2003.811490; WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424; ZHU SC, 1996, IEEE T PATTERN ANAL, V18, P88; Zhuge Y, 2002, P SOC PHOTO-OPT INS, V4684, P1103, DOI 10.1117/12.467067	58	31	32	1	5	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1077-3142			COMPUT VIS IMAGE UND	Comput. Vis. Image Underst.	MAR	2006	101	3					177	193		10.1016/j.cviu.2005.07.009		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	000HY	WOS:000234453100004		
J	Wang, JG; Neskovic, P; Cooper, LN				Wang, JG; Neskovic, P; Cooper, LN			Neighborhood size selection in the k-nearest-neighbor rule using statistical confidence	PATTERN RECOGNITION			English	Article						pattern classification; nearest-neighbor rule; probability of error; statistical confidence	REGRESSION	The k-nearest-neighbor rule is one of the most attractive pattern classification algorithms. In practice. the choice of k is determined by the cross-validation method. In this work, we propose a new method for neighborhood size selection that is based on the concept of statistical confidence. We define the confidence associated with a decision that is made by the majority rule from a finite number of observations and use it as a criterion to determine the number of nearest neighbors needed. The new algorithm is tested on several real-world datasets and yields results comparable to the k-nearest-neighbor rule. However, in contrast to the k-nearest-neighbor rule that uses a fixed number of nearest neighbors throughout the feature space, our method locally adjusts the number of nearest neighbors until a satisfactory level of confidence is reached. In addition, the statistical confidence provides a natural way to balance the trade-off between the reject rate and the error rate by excluding patterns that have low confidence levels. We believe that this property of our method can be of great importance in applications where the confidence with which a decision is made is equally or more important than the overall error rate. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Brown Univ, Inst Brain & Neural Syst, Dept Phys, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Inst Brain & Neural Syst, Dept Phys, POB 1843, Providence, RI 02912 USA.	jigang@physics.brown.edu; pedja@brown.edu; Leon_Cooper@brown.edu					Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Fix E., 1951, 4 USAF SCH AV MED; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WANG J, 2003, JOINT 13 INT C ART N	9	29	33	4	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	MAR	2006	39	3					417	423		10.1016/j.patcog.2005.08.009		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	007PO	WOS:000234981800010		
J	Watanabe, T; Komuro, Y; Kiyomatsu, T; Kanazawa, T; Kazama, Y; Tanaka, J; Tanaka, T; Yamamoto, Y; Shirane, M; Muto, T; Nagawa, H				Watanabe, T; Komuro, Y; Kiyomatsu, T; Kanazawa, T; Kazama, Y; Tanaka, J; Tanaka, T; Yamamoto, Y; Shirane, M; Muto, T; Nagawa, H			Prediction of sensitivity of rectal cancer cells in response to preoperative radiotherapy by DNA microarray analysis of gene expression profiles	CANCER RESEARCH			English	Article							ADJUVANT CHEMOTHERAPY; TUMOR-GROWTH; COLON-CANCER; THROMBOSPONDIN-2; CLASSIFICATION; ANGIOGENESIS; APOPTOSIS; SURVIVAL; THERAPY; LUMICAN	Preoperative radiotherapy has been widely used to improve local control of disease and to improve survival in the treatment of rectal cancer. However, the response to radiotherapy differs among individual tumors. Our objective here was to identify a set of discriminating genes that can be used for characterization and prediction of response to radiotherapy in rectal cancer. Fifty-two rectal cancer patients who underwent preoperative radiotherapy were studied. Biopsy specimens were obtained from rectal cancer before preoperative radiotherapy. Response to radiotherapy was determined by histopathologic examination of surgically resected specimens and classified as responders or nonresponders. By determining gene expression profiles using human U95Av2 Gene Chip, we identified 33 novel discriminating genes of which the expression differed significantly between responders and nonresponders. Using this gene set, we were able to establish a new model to predict response to radiotherapy in rectal cancer with an accuracy of 82.4%. The list of discriminating genes included growth factor, apoptosis, cell proliferation, signal transduction, or cell adhesion-related genes. Among 33 discriminating genes, apoptosis inducers (lumican, thrombospondin 2, and galectin-1) showed higher expression in responders whereas apoptosis inhibitors (cyclophilin 40 and glutathione peroxidase) showed higher expression in nonresponders. The present study suggested the possibility that gene expression profiling may be useful in predicting response to radiotherapy to establish an individualized tailored therapy for rectal cancer. Global expression profiles of responders and nonresponders may provide insights into the development of novel therapeutic targets.	Tokyo Univ Hosp, Dept Surg Oncol, Bunkyo Ku, Tokyo 113, Japan; Chugai Pharmaceut Co Ltd, Prod Res Dept, Kanagawa, Japan; JFCR, Canc Inst Hosp, Kotoh Ku, Tokyo, Japan	Watanabe, T (reprint author), Univ Tokyo, Dept Surg Oncol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138655, Japan.	toshwatanabe@yahoo.co.jp					Arango D, 2005, GASTROENTEROLOGY, V129, P874, DOI 10.1053/j.gastro.2005.06.066; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ghadimi BM, 2005, J CLIN ONCOL, V23, P1826, DOI 10.1200/JCO.2005.00.406; Gouaze V, 2001, MOL PHARMACOL, V60, P488; Horiguchi N, 2003, J BIOCHEM, V134, P869, DOI 10.1093/jb/mvg213; *JAP SOC CANC COL, 1997, RESP ASS NONS TREATM, P77; Kapiteijn E, 2001, NEW ENGL J MED, V345, P638, DOI 10.1056/NEJMoa010580; Kihara C, 2001, CANCER RES, V61, P6474; KOCKENBERY DM, 1993, CELL, V75, P241; LOWE SW, 1994, SCIENCE, V266, P807, DOI 10.1126/science.7973635; Nagawa H, 2001, DIS COLON RECTUM, V44, P1274, DOI 10.1007/BF02234784; Pahlman L, 1997, NEW ENGL J MED, V336, P980; Streit M, 1999, P NATL ACAD SCI USA, V96, P14888, DOI 10.1073/pnas.96.26.14888; Streit M, 2002, CANCER RES, V62, P2004; Troup S, 2003, CLIN CANCER RES, V9, P207; Vuillermoz B, 2004, EXP CELL RES, V296, P294, DOI 10.1016/j.yexcr.2004.02.005; Watanabe T, 2002, SURGERY, V132, P27, DOI 10.1067/msy.2002.125357; Watanabe T, 2001, NEW ENGL J MED, V344, P1196, DOI 10.1056/NEJM200104193441603; Wong YF, 2003, CLIN CANCER RES, V9, P5486	20	111	119	1	5	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	0008-5472			CANCER RES	Cancer Res.	APR 1	2006	66	7					3370	3374		10.1158/0008-5472.CAN-05-3834		5	Oncology	Oncology	030TO	WOS:000236657800008	16585155	
J	Tossavainen, T; Toppila, E; Pyykko, M; Forsman, PM; Juhola, M; Starck, J				Tossavainen, T; Toppila, E; Pyykko, M; Forsman, PM; Juhola, M; Starck, J			Virtual reality in posturography	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						Meniere's disease; postural balance; posturography; virtual reality (VR)	POSTURAL CONTROL; BALANCE; FORCE; COMPENSATION; ENVIRONMENT; SELECTION; CHILDREN	Balance dysfunctions are common, especially among elderly people. Present methods for the diagnosis and evaluation of severity of dysfuntion have limited value. We present a system that makes it easy to implement different visual and mechanical perturbations for clinical investigations of balance and visual-vestibular interaction. The system combines virtual reality visual stimulation with force platform posturography on a moving platform. We evaluate our contruction's utility in a classification task between 33 healthy controls and 77 patients with Meniere's disease, using a series of tests with different visual and mechanical stimuli. Responses of patients and controls differ significantly in parameters computed from stabilograms. We also show that the series of tests achieves a classification accuracy slightly over 80% between controls and patients.	Univ Tampere, Dept Comp Sci, FI-33014 Tampere, Finland; Inst Occupat Hlth, FI-00250 Helsinki, Finland; Univ Tampere, Dept Otolaryngol, FI-33014 Tampere, Finland	Tossavainen, T (reprint author), Univ Tampere, Dept Comp Sci, POB 607, FI-33014 Tampere, Finland.	tt@cs.uta.fi					ALLUM JHJ, 1986, DISORDERS POSTURE GA, P19; Andres R O, 1980, Am J Otolaryngol, V1, P197, DOI 10.1016/S0196-0709(80)80089-5; BLACK FO, 1983, ACTA OTO-LARYNGOL, V95, P199, DOI 10.3109/00016488309130936; Brandt T, 1986, DISORDERS POSTURE GA, P157; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Desmedt J E, 1983, Adv Neurol, V39, P227; DROULEZ J, 1996, DISORDERS POSTURE GA, P83; Eberly D. H., 2001, 3D GAME ENGINE DESIG; ENBOM H, 1991, ANN OTO RHINOL LARYN, V100, P472; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GURFINKEL E V, 1973, Agressologie, V14, P9; HYTONEN M, 1993, ACTA OTO-LARYNGOL, V113, P119, DOI 10.3109/00016489309135778; JACOBSON I, 2001, P ACM VRST2001, P103; JANTTI PO, 1993, PUBLIC HEALTH, V107, P89, DOI 10.1016/S0033-3506(05)80404-4; KALAWSKY RS, 1993, SCI VIRTUAL REALITY, P253; Karlsson A, 2000, CLIN BIOMECH, V15, P365, DOI 10.1016/S0268-0033(99)00096-0; Keshner EA, 2000, J VESTIBUL RES-EQUIL, V10, P207; Kochanek DHU, 1984, P 11 ANN C COMP GRAP, P33, DOI 10.1145/800031.808575; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kramer PD, 1998, J VESTIBUL RES-EQUIL, V8, P363; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Kuno S, 1999, JPN J PHYSIOL, V49, P417, DOI 10.2170/jjphysiol.49.417; LeClair K, 1996, CLIN BIOMECH, V11, P176, DOI 10.1016/0268-0033(95)00027-5; Lee HY, 2004, COMPUT BIOL MED, V34, P719, DOI 10.1016/j.compbiomed.2003.10.004; MAGNUSSON M, 1990, ACTA OTOLARYNGOL STO, V110; Moller T., 1999, REAL TIME RENDERING; Nashner L. M., 1985, VESTIBULAR VISUAL CO, P1; Onell A, 2000, GAIT POSTURE, V12, P7, DOI 10.1016/S0966-6362(00)00053-9; PAULUS WM, 1984, BRAIN, V107, P1143, DOI 10.1093/brain/107.4.1143; PROCHAZKA A, 1980, J PHYSIOL-LONDON, V303, P385; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; PYYKKO I, 1990, AGE AGEING, V19, P215, DOI 10.1093/ageing/19.3.215; Pyykko I, 1999, J VESTIBUL RES-EQUIL, V9, P19; Pyykkö I, 1989, Acta Otolaryngol Suppl, V468, P175; Pyykko I., 2000, AUTOMEDICA, V19, P39; PYYKKO I, 1993, AVIAT SPACE ENVIR ME, P3000; PYYKO I, 2001, CONTROL POSTURE GAIT, P230; Redfern MS, 2001, J ANXIETY DISORD, V15, P81, DOI 10.1016/S0887-6185(00)00043-8; Shoemake K., 1985, P 12 ANN C COMP GRAP, P245, DOI 10.1145/325334.325242; TOSSAVAINEN T, 2004, P MMVR2004, P385; TOSSAVAINEN T, 2001, P 10 WORLD C MED INF, P854; Tossavainen T, 2003, INT J MED INFORM, V70, P277, DOI 10.1016/S1386-5056(03)00034-0; VANASTEN WNJC, 1988, EXP BRAIN RES, V73, P371; VIIRRE E, 1996, IEEE ENG MED BIOL, V69, P41	44	7	9	0	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-7771			IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	APR	2006	10	2					282	292		10.1109/TITB.2005.859874		11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	030ZR	WOS:000236674400009	16617617	
J	Alvarado, GJ; Pedrycz, W; Reformat, M; Kwak, KC				Alvarado, GJ; Pedrycz, W; Reformat, M; Kwak, KC			Deterioration of visual information in face classification using Eigenfaces and Fisherfaces	MACHINE VISION AND APPLICATIONS			English	Article						face recognition; deterioration of visual information; principal component analysis; linear discriminant analysis; Fisherfaces and Eigenfaces; FERET face database	DISCRIMINANT-ANALYSIS; RECOGNITION; ALGORITHMS; PCA; LDA	In the area of biometrics, face classification becomes one of the most appealing and commonly used approaches for personal identification. There has been an ongoing quest for designing systems that exhibit high classification rates and portray significant robustness. This feature becomes of paramount relevance when dealing with noisy and uncertain images. The design of face recognition classifiers capable of operating in presence of deteriorated (noise affected) face images requires a careful quantification of deterioration of the existing approaches vis-a-vis anticipated form and levels of image distortion. The objective of this experimental study is to reveal some general relationships characterizing the performance of two commonly used face classifiers (that is Eigenfaces and Fisherfaces) in presence of deteriorated visual information. The findings obtained in our study are crucial to identify at which levels of noise the face classifiers can still be considered valid. Prior knowledge helps us develop adequate face recognition systems. We investigate several typical models of image distortion such as Gaussian noise, salt and pepper, and blurring effect and demonstrate their impact on the performance of the two main types of the classifiers. Several distance models derived from the Minkowski family of distances are investigated with respect to the produced classification rates. The experimental environment concerns a well-known standard in this area of face biometrics such as the FERET database. The study reports on the performance of the classifiers, which is based on a comprehensive suite of experiments and delivers several design hints supporting further developments of face classifiers.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada	Alvarado, GJ (reprint author), Univ Alberta, Dept Elect & Comp Engn, 9107-116 St, Edmonton, AB, Canada.	gabrielj@ece.ualberta.ca; pedrycz@ece.ualberta.ca; reform@ece.ualberta.ca; kwak@ece.ualberta.ca					Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bolle R.M., 2004, GUIDE BIOMETRICS; Cios Krzysztof J., 2000, DATA MINING METHODS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ekstrom Michael P., 1984, DIGITAL IMAGE PROCES; Er MJ, 2002, IEEE T NEURAL NETWOR, V13, P697, DOI 10.1109/TNN.2002.1000134; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Frey BJ, 1998, PROC CVPR IEEE, P32, DOI 10.1109/CVPR.1998.698584; LIU C, 1998, P IEEE INT C IM PROC, V1, P151; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; McGuire P, 2001, IEEE T NEURAL NETWOR, V12, P625, DOI 10.1109/72.925566; Pentland A, 2000, IEEE COMPUT, P50; Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Ripley BD, 1996, PATTERN RECOGNITION; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), DOI 10.1109/ACV.1994.341300; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; STAINVAS I, 2000, P IEEE 15 INT C PATT, V2, P805, DOI 10.1109/ICPR.2000.906198; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Zhao W., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670971; Zhao W., 2000, P IEEE INT C IM PROC, V1, P41, DOI 10.1109/ICIP.2000.900887	25	1	1	2	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0932-8092			MACH VISION APPL	Mach. Vis. Appl.	APR	2006	17	1					68	82		10.1007/s00138-006-0016-4		15	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	026ZO	WOS:000236382400006		
J	Zhou, CY; Chen, YQ				Zhou, CY; Chen, YQ			Improving nearest neighbor classification with cam weighted distance	PATTERN RECOGNITION			English	Article						classification; nearest neighbors; Cam distribution; distance measure		Nearest neighbor (NN) classification assumes locally constant class conditional probabilities, and suffers from bias in high dimensions with a small sample set. In this paper, we propose a novel cam weighted distance to ameliorate the curse of dimensionality. Different from the existing neighborhood-based methods which only analyze a small space emanating from the query sample, the proposed nearest neighbor classification using the cam weighted distance (CamNN) optimizes the distance measure based on the analysis of inter-prototype relationship. Our motivation comes from the observation that the prototypes are not isolated. Prototypes with different Surroundings should have different effects in the classification. The proposed cam weighted distance is orientation and scale adaptive to take advantage of the relevant information of inter-prototype relationship, so that a better classification performance can be achieved. Experiments show that CamNN significantly Outperforms one nearest neighbor classification (1-NN) and kappa-nearest neighbor classification (kappa-NN) in most benchmarks, while its computational complexity is comparable with that of 1-NN classification. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Fudan Univ, Dept Comp Sci & Engn, Sch Informat Sci & Engn, Shanghai 200433, Peoples R China	Chen, YQ (reprint author), Fudan Univ, Dept Comp Sci & Engn, Sch Informat Sci & Engn, Shanghai 200433, Peoples R China.	cyzhou@fudan.edu.cn; chenyq@fudan.edu.cn					BARNA G, 1988, STAT PATTERN RECOGNI, V61; Bellman R, 1959, IRE T AUTOMATIC CONT, V4, P1, DOI 10.1109/TAC.1959.1104847; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Djouadi A, 1998, IEEE T PATTERN ANAL, V20, P567, DOI 10.1109/34.682188; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; FRIEDMAN J, 1999, FLEXIBLE METRIC NEAR; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P1087, DOI 10.1109/34.42839; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; HART P, 1974, PATTERN CLASSIFICATI; Hart P., 1988, IEEE T INFORM THEORY, V13, P21; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; Peng J, 2003, IEEE T NEURAL NETWOR, V14, P940, DOI 10.1109/TNN.2003.813835; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	16	16	22	3	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	APR	2006	39	4					635	645		10.1016/j.patocog.2005.09.004		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	019TI	WOS:000235859200013		
J	Yu, XJ; Wang, C; Li, YX				Yu, XJ; Wang, C; Li, YX			Classification of protein quaternary structure by functional domain composition	BMC BIOINFORMATICS			English	Article							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINE; SUBCELLULAR-LOCALIZATION; SWISS-PROT; PREDICTION; DATABASE; PFAM; ALIGNMENTS; ALGORITHM; LOCATION	Background: The number and the arrangement of subunits that form a protein are referred to as quaternary structure. Quaternary structure is an important protein attribute that is closely related to its function. Proteins with quaternary structure are called oligomeric proteins. Oligomeric proteins are involved in various biological processes, such as metabolism, signal transduction, and chromosome replication. Thus, it is highly desirable to develop some computational methods to automatically classify the quaternary structure of proteins from their sequences. Results: To explore this problem, we adopted an approach based on the functional domain composition of proteins. Every protein was represented by a vector calculated from the domains in the PFAM database. The nearest neighbor algorithm ( NNA) was used for classifying the quaternary structure of proteins from this information. The jackknife cross-validation test was performed on the non-redundant protein dataset in which the sequence identity was less than 25%. The overall success rate obtained is 75.17%. Additionally, to demonstrate the effectiveness of this method, we predicted the proteins in an independent dataset and achieved an overall success rate of 84.11% Conclusion: Compared with the amino acid composition method and Blast, the results indicate that the domain composition approach may be a more effective and promising high-throughput method in dealing with this complicated problem in bioinformatics.	Chinese Acad Sci, Shanghai Inst Biol Sci, Bioinformat Ctr, Shanghai 200031, Peoples R China; Chinese Acad Sci, Grad Sch, Beijing 100039, Peoples R China; Shanghai Ctr Bioinformat Technol, Shanghai 200235, Peoples R China	Li, YX (reprint author), Chinese Acad Sci, Shanghai Inst Biol Sci, Bioinformat Ctr, 320 Yueyang Rd, Shanghai 200031, Peoples R China.	xjyu@sibs.ac.cn; cwang@sibs.ac.cn; yxli@sibs.ac.cn					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ANFINSEN CB, 1961, P NATL ACAD SCI USA, V47, P1309, DOI 10.1073/pnas.47.9.1309; ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; Bairoch A, 2004, BRIEF BIOINFORM, V5, P39, DOI 10.1093/bib/5.1.39; Bateman A, 2004, NUCLEIC ACIDS RES, V32, pD138, DOI 10.1093/nar/gkh121; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; CHOU KC, 1995, PROTEIN SCI, V4, P1365; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Doyle DA, 1998, SCIENCE, V280, P69, DOI 10.1126/science.280.5360.69; Farmer TB, 1998, J MASS SPECTROM, V33, P697, DOI 10.1002/(SICI)1096-9888(199808)33:8<697::AID-JMS711>3.3.CO;2-8; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Garian R, 2001, BIOINFORMATICS, V17, P551, DOI 10.1093/bioinformatics/17.6.551; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Kim Wan Kyu, 2002, Genome Inform, V13, P42; Klotz I. M., 1975, PROTEINS, V1, P293; KLOTZ IM, 1970, ANNU REV BIOCHEM, V39, P25, DOI 10.1146/annurev.bi.39.070170.000325; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Mardia K. V., 1979, MULTIVARIATE ANAL; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Price N.C., 1994, MECH PROTEIN FOLDING, P160; Song R, 2004, J CHEM INF COMP SCI, V44, P1324, DOI 10.1021/ci034288y; Sonnhammer ELL, 1997, PROTEINS, V28, P405, DOI 10.1002/(SICI)1097-0134(199707)28:3<405::AID-PROT10>3.0.CO;2-L; Sonnhammer ELL, 1998, NUCLEIC ACIDS RES, V26, P320, DOI 10.1093/nar/26.1.320; SUND H, 1966, ANGEW CHEM INT EDIT, V5, P231, DOI 10.1002/anie.196602311; Tretter V, 1997, J NEUROSCI, V17, P2728; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wojcik J., 2001, BIOINFORMATICS S1, V17, P296; Yu XJ, 2004, CHINESE SCI BULL, V49, P2379, DOI 10.1360/982004-142; Zhang SW, 2003, BIOINFORMATICS, V19, P2390, DOI 10.1093/bioinformatics/btg331; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	38	21	21	0	0	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	APR 4	2006	7								187	10.1186/1471-2105-7-187		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	038EN	WOS:000237201700001	16584572	
J	Matsubara, Y; Kikuchi, S; Sugimoto, M; Tomita, M				Matsubara, Yoshiya; Kikuchi, Shinichi; Sugimoto, Masahiro; Tomita, Masaru			Parameter estimation for stiff equations of biosystems using radial basis function networks	BMC BIOINFORMATICS			English	Article							GENETIC ALGORITHMS; NEURAL-NETWORKS; BIOCHEMICAL PATHWAYS; S-SYSTEM; PREDICTION; OPTIMIZATION; TIME; IDENTIFICATION; SELECTION	Background: The modeling of dynamic systems requires estimating kinetic parameters from experimentally measured time-courses. Conventional global optimization methods used for parameter estimation, e. g. genetic algorithms (GA), consume enormous computational time because they require iterative numerical integrations for differential equations. When the target model is stiff, the computational time for reaching a solution increases further. Results: In an attempt to solve this problem, we explored a learning technique that uses radial basis function networks (RBFN) to achieve a parameter estimation for biochemical models. RBFN reduce the number of numerical integrations by replacing derivatives with slopes derived from the distribution of searching points. To introduce a slight search bias, we implemented additional data selection using a GA that searches data-sparse areas at low computational cost. In addition, we adopted logarithmic transformation that smoothes the fitness surface to obtain a solution simply. We conducted numerical experiments to validate our methods and compared the results with those obtained by GA. We found that the calculation time decreased by more than 50% and the convergence rate increased from 60% to 90%. Conclusion: In this work, our RBFN technique was effective for parameter optimization of stiff biochemical models.	Keio Univ, Inst Adv Biosci, Fujisawa, Kanagawa 2528520, Japan; Mitsubishi Space Software Co Ltd, Dept Bioinformat, Amagasaki, Hyogo 6610001, Japan	Kikuchi, S (reprint author), Keio Univ, Inst Adv Biosci, Fujisawa, Kanagawa 2528520, Japan.	yoshiya@sfc.keio.ac.jp; kikuchi@sfc.keio.ac.jp; msugi@sfc.keio.ac.jp; mt@sfc.keio.ac.jp	Kikuchi, Shinichi/A-1681-2010				Agatonovic-Kustrin S, 2003, PHARM RES, V20, P1760, DOI 10.1023/B:PHAM.0000003372.56993.39; Agatonovic-Kustrin S, 2003, PHARMAZIE, V58, P725; Bentele M, 2004, J CELL BIOL, V166, P839, DOI 10.1083/jcb.200404158; Broomhead D. S., 1988, Complex Systems, V2; Chen L, 2000, CONTROL ENG PRACT, V8, P821, DOI 10.1016/S0967-0661(00)00036-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowper MR, 2002, SIGNAL PROCESS, V82, P775, DOI 10.1016/S0165-1684(02)00155-X; Dasarathy B. V., 1991, NEAREST NEIGHBOR PAT; Deb K, 2002, EVOL COMPUT, V10, P371, DOI 10.1162/106365602760972767; Dhar P, 2004, BIOINFORMATICS, V20, P1319, DOI 10.1093/bioinformatics/bth067; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Gear C.W., 1971, NUMERICAL INITIAL VA; Germani M, 2003, CANCER CHEMOTH PHARM, V52, P507, DOI 10.1007/s00280-003-0688-7; Goldberg D. E., 1989, GENETIC ALGORITHMS S; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Hatakeyama M, 2003, BIOCHEM J, V373, P451, DOI 10.1042/BJ20021824; Haykin S., 1994, NEURAL NETWORKS COMP; Isaacs FJ, 2003, P NATL ACAD SCI USA, V100, P7714, DOI 10.1073/pnas.1332628100; Ji W, 2003, IEEE T INF TECHNOL B, V7, P218, DOI 10.1109/TITB.2003.813796; Jianyu Li, 2003, Neural Netw, V16, P729, DOI 10.1016/S0893-6080(03)00083-2; Jonikow CZ, 1991, P 4 INT C GEN ALG, P31; Kalir S, 2004, CELL, V117, P713, DOI 10.1016/j.cell.2004.05.010; Kikuchi S, 2003, BIOINFORMATICS, V19, P643, DOI 10.1093/bioinformatics/btg027; Kimura S, 2004, BIOINFORMATICS, V20, P1646, DOI 10.1093/bioinformatics/bth122; Kimura S, 2005, BIOINFORMATICS, V21, P1154, DOI 10.1093/bioinformatics/bti071; Kutalik Z, 2004, BIOSYSTEMS, V75, P43, DOI 10.1016/j.biosystems.2004.03.007; LARRY JE, 1997, P INT C GEN ALG, P354; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; Maki Y, 2002, GENOME INFORMATICS, V13, P382; Mendes P, 1998, BIOINFORMATICS, V14, P869, DOI 10.1093/bioinformatics/14.10.869; Meng Tan Chee, 2004, In Silico Biol, V4, P293; Michalski R, 1998, COMPUT BIOMED RES, V31, P71, DOI 10.1006/cbmr.1998.1469; Moles CG, 2003, GENOME RES, V13, P2467, DOI 10.1101/gr.1262503; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; NAKAYAMA H, 2001, P INT C ART NEUR NET, P73; Niwa T, 2004, J MED CHEM, V47, P2645, DOI 10.1021/jm0302795; Ono I., 1997, P 7 INT C GEN ALG, P246; ORR MJL, 1995, NEURAL COMPUT, V7, P606, DOI 10.1162/neco.1995.7.3.606; Oyman AI, 2000, EVOL COMPUT, V8, P249, DOI 10.1162/106365600750078772; Park LJ, 1997, MED BIOL ENG COMPUT, V35, P47, DOI 10.1007/BF02510391; Pinchuk RJ, 2000, BIOTECHNOL BIOENG, V67, P19, DOI 10.1002/(SICI)1097-0290(20000105)67:1<19::AID-BIT3>3.0.CO;2-C; Rank E, 2003, SIGNAL PROCESS, V83, P1393, DOI 10.1016/S0165-1684(03)00088-4; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SA B, 1998, NEURAL NETWORKS, V11, P479; SAKUMA H, 2001, P C EV COMP, P553; Someya H, 2002, P GEN EV COMP C, P553; Sugimoto M, 2005, BIOSYSTEMS, V80, P155, DOI 10.1016/j.biosystems.2004.11.003; Swameye I, 2003, P NATL ACAD SCI USA, V100, P1028, DOI 10.1073/pnas.0237333100; Takahashi K, 2004, BIOINFORMATICS, V20, P538, DOI 10.1093/bioinformatics/btg442; Tsai KY, 2005, BIOINFORMATICS, V21, P1180, DOI 10.1093/bioinformatics/bti099; Tsutsui S, 2001, INFORM SCIENCES, V133, P229, DOI 10.1016/S0020-0255(01)00087-1; TSUTSUI S, 1999, P GEN EV COMP C, P73; Tsutsui S, 1998, LECT NOTES COMPUT SC, V1498, P428; Voit EO, 2004, BIOINFORMATICS, V20, P1670, DOI 10.1093/bioinformatics/bth140	54	8	8	0	2	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	APR 27	2006	7								230	10.1186/1471-2105-7-230		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	082VN	WOS:000240415400001	16643665	
J	Gupta, MR; Gray, RM; Olshen, RA				Gupta, MR; Gray, RM; Olshen, RA			Nonparametric supervised learning by linear interpolation with maximum entropy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonparametric statistics; probabilistic algorithms; pattern recognition; maximum entropy; linear interpolation	REGRESSION	Nonparametric neighborhood methods for learning entail estimation of class conditional probabilities based on relative frequencies of samples that are "near-neighbors" of a test point. We propose and explore the behavior of a learning algorithm that uses linear interpolation and the principle of maximum entropy (LIME). We consider some theoretical properties of the LIME algorithm: LIME weights have exponential form; the estimates are consistent; and the estimates are robust to additive noise. In relation to bias reduction, we show that near-neighbors contain a test point in their convex hull asymptotically. The common linear interpolation solution used for regression on grids or look-up-tables is shown to solve a related maximum entropy problem. LIME simulation results support use of the method, and performance on a pipeline integrity classification problem demonstrates that the proposed algorithm has practical value.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; Stanford Univ, Informat Syst Lab, Dept Elect Engn, Stanford, CA 94305 USA; Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Gupta, MR (reprint author), Univ Washington, Dept Elect Engn, Box 352500, Seattle, WA 98195 USA.	gupta@ee.washington.edu; rmgray@stanford.edu; olshen@stanford.edu					BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; BICKEL PJ, 1968, ANN MATH STAT, V39, P442, DOI 10.1214/aoms/1177698408; BICKEL PJ, 1983, ANN PROBAB, V11, P185, DOI 10.1214/aop/1176993668; Breiman L., 1984, CLASSIFICATION REGRE; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; de Guzman M., 1975, DIFFERENTIATION INTE; Devroye L., 1996, PROBABILISTIC THEORY; Fix E., 1951, 4 US AIR FORC SCH AV; FRIEDLANDER MP, 2005, IEEE T INFORM THEORY, V52, P238; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Garsia A.M, 1970, TOPICS ALMOST EVERYW; GORDON L, 1984, J MULTIVARIATE ANAL, V15, P146; Gray R. M., 1990, ENTROPY INFORM THEOR; Gray R. M., 1997, P COMPR COMPL SEQ C, P172; Hastie T, 2001, ELEMENTS STAT LEARNI; HASTIE T, 1993, STAT SCI, V8, P120, DOI 10.1214/ss/1177011002; HESTERBERG TC, 1997, P SECT STAT COMP AM, P34; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; Kang H.R., 1997, COLOR TECHNOLOGY ELE; Kneale W., 1949, PROBABILITY INDUCTIO; KOHONEN T, 1988, IEEE INT C NEUR NETW, V1, P61; Kullback S., 1959, INFORM THEORY STAT; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Lugosi G, 1996, IEEE T INFORM THEORY, V42, P48, DOI 10.1109/18.481777; MACK YP, 1979, J MULTIVARIATE ANAL, V9, P1, DOI 10.1016/0047-259X(79)90065-4; NAJMI A, 1999, THESIS STANFORD U ST; OBRIEN DB, 2003, P IEEE INT C IM PROC; Peirce Charles S., 1956, PHILOS PEIRCE SELECT; Pollard D., 1984, CONVERGENCE STOCHAST; Press WH, 1999, NUMERICAL RECIPES C, V2nd; RICE J, 1984, COMMUN STAT-THEOR M, V13, P893; RIPLEY B, 2001, PATTERN RECOGNITION; Scott D.W., 1992, MULTIVARIATE DENSITY; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; Wu N., 1997, MAXIMUM ENTROPY METH; 2002, MATLAB VERSION 6 1 M	39	17	18	2	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					766	781		10.1109/TPAMI.2006.101		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	020CO	WOS:000235885700008	16640262	
J	Ishikawa, KI; Koyama-Saegusa, K; Otsuka, Y; Ishikawa, A; Kawai, S; Yasuda, K; Suga, T; Michikawa, Y; Suzuki, M; Iwakawa, M; Imai, T				Ishikawa, KI; Koyama-Saegusa, K; Otsuka, Y; Ishikawa, A; Kawai, S; Yasuda, K; Suga, T; Michikawa, Y; Suzuki, M; Iwakawa, M; Imai, T			Gene expression profile changes correlating with radioresistance in human cell lines	INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS			English	Article						radioresistance; gene expression; cancer; microarray analysis	MAMMALIAN-CELLS; IONIZING-RADIATION; HUMAN HOMOLOG; CANCER-CELL; RADIOTHERAPY; APOPTOSIS; RADIOSENSITIVITY; CLASSIFICATION; MICROARRAYS; SENSITIVITY	Purpose: To identify gene expression profiles specific to radioresistance of human cells. Methods and Materials: Global gene expression profiles of a total of 15 tumor and normal fibroblast cell lines were analyzed using DNA microarrays and statistical clustering methods. Initially, six of the cell lines were categorized into radioresistant (RG) or nonradioresistant (NRG) groups according to the radiation dose required to reduce their survival to 10% (D-10). Genes for which expression was specific to each group at 1 or 3 h after irradiation were identified using statistical procedures including analysis of variance and a two-dimensional hierarchical clustering method. The remaining nine cell lines were subjected to the k-nearest neighbor pattern classification. Results: The nine test cell lines were successfully classified by their D-10 value using 46 and 44 genes for which transcription levels had significantly changed at 1 and 3 h after irradiation, respectively. Of these genes, 25 showed altered expression at both time points in the NRG or RG, but independently were unable to classify the test cell lines. Conclusions: Radioresistant cell lines analyzed in this study showed certain radiation-induced changes in gene expression profiles that are different from the profile changes of the more-sensitive cell lines. (c) 2006 Elsevier Inc.	Natl Inst Radiol Sci, Frontier Res Ctr, RadGenom Project, Chiba 2638555, Japan; Natl Inst Radiol Sci, Res Ctr Radiat Safety, Int Space Radiat Lab, Chiba 2638555, Japan	Imai, T (reprint author), Natl Inst Radiol Sci, Frontier Res Ctr, RadGenom Project, 4-9-1 Anagawa, Chiba 2638555, Japan.	imait@nirs.go.jp					Achary MP, 2000, CYTOGENET CELL GENET, V91, P39, DOI 10.1159/000056815; Ambrosini G, 1997, NAT MED, V3, P917, DOI 10.1038/nm0897-917; Ban S, 2005, INT J EXP PATHOL, V86, P231, DOI 10.1111/j.0959-9673.2005.00431.x; Ban S, 2005, J RADIAT RES, V46, P43, DOI 10.1269/jrr.46.43; Berns K, 2004, NATURE, V428, P431, DOI 10.1038/nature02371; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; Chen XF, 2002, CANCER RES, V62, P1213; Chung CH, 2002, NAT GENET, V32, P533, DOI 10.1038/ng1038; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Criswell T, 2003, ONCOGENE, V22, P5813, DOI 10.1038/sj.onc.1206680; DUNNE J, 1995, GENOMICS, V30, P207, DOI 10.1006/geno.1995.9884; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Elbashir SM, 2001, NATURE, V411, P494, DOI 10.1038/35078107; Gudkov AV, 2003, NAT REV CANCER, V3, P117, DOI 10.1038/nrc992; Hahn A, 2000, J BIOL CHEM, V275, P37429, DOI 10.1074/jbc.M000976200; HU MCT, 1987, CELL, V48, P555, DOI 10.1016/0092-8674(87)90234-0; Hughes TR, 2001, NAT BIOTECHNOL, V19, P342, DOI 10.1038/86730; Ito T, 2000, HEPATOLOGY, V31, P1080, DOI 10.1053/he.2000.6496; Iwakawa M, 2004, J RADIAT RES, V45, P423, DOI 10.1269/jrr.45.423; Khodarev NN, 2001, P NATL ACAD SCI USA, V98, P12665, DOI 10.1073/pnas.211443698; Lamande SR, 2002, J BIOL CHEM, V277, P1949, DOI 10.1074/jbc.M109932200; Lee CH, 2004, PHARMACOGENOMICS, V5, P611, DOI 10.1517/14622416.5.6.611; Mackay RI, 1999, RADIOTHER ONCOL, V50, P67, DOI 10.1016/S0167-8140(98)00132-7; Mischel PS, 2004, NAT REV NEUROSCI, V5, P782, DOI 10.1038/nrn1518; Ohnishi K, 2001, INT J HYPERTHER, V17, P415, DOI 10.1080/02656730110063604; Pacheco TR, 1999, GENE, V229, P125, DOI 10.1016/S0378-1119(99)00034-7; Pawlik TM, 2004, INT J RADIAT ONCOL, V59, P928, DOI 10.1016/j.ijrobp.2004.03.005; Perez C. A., 2004, PRINCIPLES PRACTICE; PETERS LJ, 1988, AM J CLIN ONCOL-CANC, V11, P275, DOI 10.1097/00000421-198806000-00005; Rajagopalan D, 2003, BIOINFORMATICS, V19, P1469, DOI 10.1093/bioinformatics/btg202; Roberts CJ, 2000, SCIENCE, V287, P873, DOI 10.1126/science.287.5454.873; SAKAI LY, 1991, J BIOL CHEM, V266, P14763; SAUNDERS S, 1988, J CELL BIOL, V106, P423, DOI 10.1083/jcb.106.2.423; SHIMADA Y, 1992, CANCER, V69, P277, DOI 10.1002/1097-0142(19920115)69:2<277::AID-CNCR2820690202>3.0.CO;2-C; Snyder AR, 2004, CANCER METAST REV, V23, P259, DOI 10.1023/B:CANC.0000031765.17886.fa; Stone EM, 1999, NAT GENET, V22, P199, DOI 10.1038/9722; Suzuki M, 2000, INT J RADIAT ONCOL, V48, P241, DOI 10.1016/S0360-3016(00)00568-X; Suzuki M, 2000, INT J RADIAT BIOL, V76, P1189; Syken J, 1999, P NATL ACAD SCI USA, V96, P8499, DOI 10.1073/pnas.96.15.8499; Szumiel I, 1998, RADIAT RES, V150, P92; Theilhaber J, 2002, GENOME RES, V12, P165, DOI 10.1101/gr.182601; Vallat L, 2003, BLOOD, V101, P4598, DOI 10.1182/blood-2002-06-1743; Voehringer DW, 2000, P NATL ACAD SCI USA, V97, P2680, DOI 10.1073/pnas.97.6.2680; VOGELSTEIN B, 1992, CELL, V70, P523, DOI 10.1016/0092-8674(92)90421-8; WEST CML, 1995, BRIT J RADIOL, V68, P827; West CML, 2005, INT J RADIAT ONCOL, V62, P1264, DOI 10.1016/j.ijrobp.2005.05.001; Xie HQ, 1997, J CELL BIOL, V137, P203, DOI 10.1083/jcb.137.1.203; ZHANG H, 1994, J CELL BIOL, V124, P855, DOI 10.1083/jcb.124.5.855	48	15	15	2	2	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0360-3016			INT J RADIAT ONCOL	Int. J. Radiat. Oncol. Biol. Phys.	MAY 1	2006	65	1					234	245		10.1016/j.ijrobp.2005.12.048		12	Oncology; Radiology, Nuclear Medicine & Medical Imaging	Oncology; Radiology, Nuclear Medicine & Medical Imaging	051LM	WOS:000238162600033	16618578	
J	Baumes, LA				Baumes, LA			MAP: An iterative experimental design methodology for the optimization of catalytic search space structure modeling	JOURNAL OF COMBINATORIAL CHEMISTRY			English	Article							DISCOVERY; SOLIDS	One of the main problems in high-throughput research for materials is still the design of experiments. At early stages of discovery programs, purely exploratory methodologies coupled with fast screening tools should be employed. This should lead to opportunities to find unexpected catalytic results and identify the "groups" of catalyst outputs, providing well-defined boundaries for future optimizations. However, very few new papers deal with strategies that guide exploratory studies. Mostly, traditional designs, homogeneous covering, or simple random samplings are exploited. Typical catalytic output distributions exhibit unbalanced datasets for which an efficient learning is hardly carried out, and interesting but rare classes are usually unrecognized. Here is suggested a new iterative algorithm for the characterization of the search space structure, working independently of learning processes. It enhances recognition rates by transferring catalysts to be screened from "performance-stable" space zones to "unsteady" ones which necessitate more experiments to be well-modeled. The evaluation of new algorithm attempts through benchmarks is compulsory due to the lack of past proofs about their efficiency. The method is detailed and thoroughly tested with mathematical functions exhibiting different levels of complexity. The strategy is not only empirically evaluated, the effect or efficiency of sampling on future Machine Learning performances is also quantified. The minimum sample size required by the algorithm for being statistically discriminated from simple random sampling is investigated.	Max Planck Inst Kohlenforsch, D-45470 Mulheim, Germany; Inst Rech Catalyse, CNRS, F-69626 Villeurbanne, France	Baumes, LA (reprint author), Max Planck Inst Kohlenforsch, Kaiser Wilhelm Pl 1, D-45470 Mulheim, Germany.	baumesl@itq.upv.es	baumes, laurent/E-2175-2013	baumes, laurent/0000-0001-9363-9089			Aha D.W., 1992, P 9 INT C MACH LEARN, P1; BAUMES LA, UNPUB J COMB CHEM; BAUMES LA, 2004, QSAR COMB SCI, V29, P767; BAUMES LA, 2003, LECT NOTES AI LNCS L; BEM DS, 2003, EXPT DESIGN HIGH THR, P89; BLICKLE T, 1995, 6 INT C GEN ALG SAN; CAWSE JN, 2003, EXPT DESIGN COMBINAT, P109; Chakravarti I. M., 1974, HDB METHODS APPL STA, V1, P392; Christensen L.B., 1994, EXPT METHODOLOGY; Cochran W. G., 1989, STAT METHODS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeJong K., 1975, THESIS U MICHIGAN; Deming S. N., 1993, EXPT DESIGN CHEMOMET, V2nd; Farrusseng D, 2003, HIGH-THROUGHPUT ANALYSIS: A TOOL OF COMBINATORIAL MATERIALS SCIENCE, P551; FARRUSSENG D, 2004, 13 ICC PAR FRANC JUL; Farrusseng D, 2005, QSAR COMB SCI, V24, P78, DOI 10.1002/qsar.200420066; Fernandez J, 2002, J PHOTOCH PHOTOBIO A, V151, P213, DOI 10.1016/S1010-6030(02)00153-3; Harmon L, 2003, J MATER SCI, V38, P4479, DOI 10.1023/A:1027325400459; HICKEY RJ, 1992, P 9 INT C MACH LEARN, P196; Klanner C, 2004, ANGEW CHEM INT EDIT, V43, P5347, DOI 10.1002/anie.200460731; Montgomery DC, 1991, DESIGN ANAL EXPT; SAMMUT C, 1990, 7 INT MACH LEARN C A; Senkan S, 2001, ANGEW CHEM INT EDIT, V40, P312, DOI 10.1002/1521-3773(20010119)40:2<312::AID-ANIE312>3.3.CO;2-9; Serra JM, 2003, CATAL TODAY, V81, P425, DOI 10.1016/S0920-5861(03)00142-1; SJOBLOM J, 2004, 11 NORD S CAT OUL FI; STEPHENS MA, 1974, J AM STAT ASSOC, V69, P730, DOI 10.2307/2286009; Thierens D., 1997, P 7 INT C GEN ALG MO, P152; TRIBUS M, 1989, QUAL PROG, V22, P46; Whitley D, 1996, ARTIF INTELL, V85, P245, DOI 10.1016/0004-3702(95)00124-7	29	19	19	0	2	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1520-4766			J COMB CHEM	J. Comb. Chem.	MAY	2006	8	3					304	314		10.1021/cc050130+		11	Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Chemistry; Pharmacology & Pharmacy	039YG	WOS:000237343900007	16676999	
J	Chien, BC; Lin, JY; Yang, WP				Chien, BC; Lin, JY; Yang, WP			A classification tree based on discriminant functions	JOURNAL OF INFORMATION SCIENCE AND ENGINEERING			English	Article; Proceedings Paper	Workshop on Computer Vision, Graphics and Image Processing (CVGIP)	2004	TAIWAN			knowledge discovery; machine learning; genetic programming; classification; discriminant function; decision tree; classifier	SUPPORT VECTOR MACHINES; PATTERN-CLASSIFICATION; NEURAL NETWORKS; FUZZY; RULE	The classification problem is an important topic in knowledge discovery and machine learning. Traditional classification tree methods and their improvements have been discussed widely. This work proposes a new approach to construct decision trees based on discriminant functions which are learned using genetic programming. A discriminant function is a mathematical function for classifying data into a specific class. To learn discriminant functions effectively and efficiently, a distance-based fitness function for genetic programming is designed. After the set of discriminant functions for all classes is generated. a classifier is created as a binary decision tree with the Z-value measure to resolve the problem of ambiguity among discriminant functions. Several popular datasets from the UCI Repository were selected to illustrate the effectiveness of the proposed classifiers by comparing with previous methods. The results show that the proposed classification tree demonstrates high accuracy on the selected datasets.	Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 700, Taiwan; Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 300, Taiwan; Natl Dong Hwa Univ, Dept Informat Management, Hualien 974, Taiwan	Chien, BC (reprint author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 700, Taiwan.						Blake C, 1998, UCI REPOSITORY MACHI; Bojarczuk CC, 1999, P GEN EV COMP C ORL, P953; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; Chen KH, 1997, FUZZY SET SYST, V91, P15, DOI 10.1016/S0165-0114(96)00145-5; Chen YX, 2003, IEEE T FUZZY SYST, V11, P716, DOI 10.1109/TFUZZ.2003.819843; Chien BC, 2002, EXPERT SYST APPL, V23, P31, DOI 10.1016/S0957-4174(02)00025-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R. O., 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FREITAS AA, 1997, P 2 ANN C GEN PROGR, P96; Han Jiawei, 2001, DATA MINING CONCEPTS; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; HECKERMAN D, 1995, COMMUN ACM, V38, P27, DOI 10.1145/203330.203336; Karacali B, 2004, PATTERN RECOGN LETT, V25, P63, DOI 10.1016/j.patrec.2003.09.002; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; Koza J., 1992, GENETIC PROGRAMMING; Koza J.R., 1996, GENETIC PROGRAMMING; Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536; Lee YJ, 2001, COMPUT OPTIM APPL, V20, P5, DOI 10.1023/A:1011215321374; Liu B., 1998, P 4 INT C KNOWL DISC, P80; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Loveard T, 2001, IEEE C EVOL COMPUTAT, P1070, DOI 10.1109/CEC.2001.934310; Mangasarian OL, 1990, SIAM NEWS, V23, P1; Nauck D, 1997, FUZZY SET SYST, V89, P277, DOI 10.1016/S0165-0114(97)00009-2; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654; SHI HB, 2003, P 7 PAC AS C KNOWL D, P265; SINDHWANI V, 2001, P SIAM INT C DAT MIN; SINGLETON A, 1994, BYTE             FEB, P171; STEFAOWSKI J, 2003, P S METH ART INT AI, P297; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang ZH, 2003, LECT NOTES ARTIF INT, V2903, P453; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	35	2	2	0	1	INST INFORMATION SCIENCE	TAIPEI	ACADEMIA SINICA, TAIPEI 115, TAIWAN	1016-2364			J INF SCI ENG	J. Inf. Sci. Eng.	MAY	2006	22	3					573	594				22	Computer Science, Information Systems	Computer Science	047VX	WOS:000237907900008		
J	Shen, HB; Yang, J; Chou, KC				Shen, HB; Yang, J; Chou, KC			Fuzzy KNN for predicting membrane protein types from pseudo-amino acid composition	JOURNAL OF THEORETICAL BIOLOGY			English	Article						fuzzy K-nearest neighbors; pseudo-amino acid composition; type-1; type-2; multi-pass transmembrane; lipid chain-anchored; GPI-anchored	SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; SUBCELLULAR LOCATION PREDICTION; SECONDARY STRUCTURE-CONTENT; SORTING SIGNALS; FOLDING TYPES; CLASSIFICATION; LOCALIZATION; INSIGHTS	Cell membranes are vitally important to the life of a cell. Although the basic structure of biological membrane is provided by the lipid bilayer, membrane proteins perform most of the specific functions. Membrane proteins are putatively classified into five different types. Identification of their types is currently an important topic in bioinformatics and proteomics. In this paper, based on the concept of representing protein samples in terms of their pseudo-amino acid composition (Chou, K.C., 2001. Prediction of protein cellular attributes using pseudo amino acid composition. Proteins: Struct. Funct. Genet. 43, 246-255), the fuzzy K-nearest neighbors (KNN) algorithm has been introduced to predict membrane protein types, and high success rates were observed. It is anticipated that, the current approach, which is based on a branch of fuzzy mathematics and represents a new strategy, may play an important complementary role to the existing methods in this area. The novel approach may also have notable impact on prediction of the other attributes, such as protein structural class, protein subcellular localization, and enzyme family class, among many others. (c) 2005 Elsevier Ltd. All rights reserved.	Gordon Life Sci Inst, Bioinformat & Drug Discovery, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, Bioinformat & Drug Discovery, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Alberts B., 1994, MOL BIOL CELL; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2004, J THEOR BIOL, V226, P373, DOI 10.1016/j.jtbi.2003.08.015; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2004, BIOCHEM BIOPH RES CO, V325, P506, DOI 10.1016/j.bbrc.2004.10.058; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou K.C., 2001, PROTEIN-STRUCT FUNCT, V43, P246; Chou KC, 1998, PROTEINS, V31, P97, DOI 10.1002/(SICI)1097-0134(19980401)31:1<97::AID-PROT8>3.0.CO;2-E; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; CHOU KC, 1992, EUR J BIOCHEM, V207, P429, DOI 10.1111/j.1432-1033.1992.tb17067.x; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2004, BIOCHEM BIOPH RES CO, V319, P433, DOI 10.1016/j.bbrc.2004.05.016; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOCHEM BIOPH RES CO, V329, P1362, DOI 10.1016/j.bbrr.2005.02.098; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; Chou KC, 2004, J PROTEOME RES, V3, P856, DOI 10.1021/pr049931q; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; Chou KC, 2005, J PROTEOME RES, V4, P1413, DOI 10.1021/pr050087t; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2004, BIOCHEM BIOPH RES CO, V316, P636, DOI 10.1016/j.bbrc.2004.02.098; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; CHOU KC, 2001, PROTEIN-STRUCT FUNCT, V44, P43; Chou P Y, 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Feng ZP, 2000, J PROTEIN CHEM, V19, P269, DOI 10.1023/A:1007091128394; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; LODISH H, 1995, MOL CELL BIOL, pCH3; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	55	112	115	0	3	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193			J THEOR BIOL	J. Theor. Biol.	MAY 7	2006	240	1					9	13		10.1016/j.jtbi.2005.08.016		5	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	041YG	WOS:000237492600002	16197963	
J	Gombar, VK; Alberts, JJ; Cassidy, KC; Mattioni, BE; Mohutsky, MA				Gombar, Vijay K.; Alberts, James J.; Cassidy, Kenneth C.; Mattioni, Brian E.; Mohutsky, Michael A.			In Silico Metabolism Studies in Drug Discovery: Prediction of Metabolic Stability	CURRENT COMPUTER-AIDED DRUG DESIGN			English	Article						In silico; ADME; metabolism; metabolic stability; drug discovery; QSAR models; ADME software	RELATIONSHIP 3D/4D-QSAR ANALYSES; HUMAN CYTOCHROME P4502C9; CRYSTAL-STRUCTURE; ACTIVE-SITE; MOLECULAR-DYNAMICS; CYP2C9 INHIBITORS; STATE INDEXES; JOHNS WORT; HOMOLOGY; MODELS	The strategy to screen compounds solely for pharmacological potency and selectivity in the early stages of drug discovery brought the pharmaceutical industry to face the stark reality of disproportionate attrition later in the development stage due to poor drug disposition characteristics. This attrition contributed to the exorbitant costs of discovering and developing drugs. Considering ADME (Absorption, Distribution, Metabolism, and Excretion) characteristics of compounds early in the discovery process can wisely direct resources to compounds that have greater potential to survive the clinical trial stages of drug development. However, experimental determination of ADME characteristics is not practical for large numbers of compounds. Therefore, focus is being centered on bringing in silico approaches earlier in the discovery process to assess ADME properties solely from molecular structure. Given that metabolism is one of the most important of the ADME properties, in this paper we review a number of metabolism in silico tools and models that have potential applications in drug discovery. We then describe a step-by-step process, as practiced in our laboratories, to construct and deploy reliable in silico metabolic stability and other ADME screens. Additionally, we give examples of the application of our metabolic stability in silico screens in scaffold selection, ADME space enrichment, and rationalizing synthesis and testing of compounds in the drug discovery process. Agreements between the experimental and in silico metabolic stability values ranging from 84% to 100% have convinced many discovery project teams to routinely use these in silico models. Finally, we present our ideas on the successful implementation of in silico models and tools for significant impact on drug discovery and development.	[Gombar, Vijay K.; Alberts, James J.; Cassidy, Kenneth C.; Mattioni, Brian E.; Mohutsky, Michael A.] Lilly Corp Ctr, Lilly Res Labs, Indianapolis, IN 46285 USA	Gombar, VK (reprint author), Lilly Corp Ctr, Lilly Res Labs, Indianapolis, IN 46285 USA.	gombarvi@lilly.com					ABRAHAM MH, 1993, CHEM SOC REV, V22, P73, DOI 10.1039/cs9932200073; Afzelius L, 2001, MOL PHARMACOL, V59, P909; Baurin N, 2004, J CHEM INF COMP SCI, V44, P276, DOI 10.1021/ci0341565; BOYLAND E, 1962, ANNU REV PHARMACOL, V2, P129, DOI 10.1146/annurev.pa.02.040162.001021; BRAVI G, 1977, COMPUT AIDED MOL DES, V11, P79; Cashman JR, 1996, DRUG DISCOV TODAY, V1, P209, DOI 10.1016/1359-6446(96)10017-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; Crivori P, 2004, J COMPUT AID MOL DES, V18, P155, DOI 10.1023/B:JCAM.0000035184.11906.c2; deGroot MJ, 1996, CHEM RES TOXICOL, V9, P1079, DOI 10.1021/tx960003i; DELVIN JP, 1996, NETWORK SCI COMBI CH; DIMASI JA, 1995, CLIN PHARMACOL THER, V58, P1, DOI 10.1016/0009-9236(95)90066-7; Draper N.R., 1981, APPL REGRESSION ANAL, V2<SUP>nd</SUP>; *DRUG SAF EV COS I, 2001, DEV WHIT PAP; Ekins S, 2002, DRUG METAB DISPOS, V30, P96, DOI 10.1124/dmd.30.1.96; Ekins S, 1999, J PHARMACOL EXP THER, V291, P424; Ekins S, 2000, DRUG METAB DISPOS, V28, P994; Ekins S, 1999, PHARMACOGENETICS, V9, P477; Gillette JR, 1963, PROGRESS DRUG RESEAR, V6, P11; Gombar VK, 2003, CURR TOP MED CHEM, V3, P1205, DOI 10.2174/1568026033452014; Graupe D., 1997, PRINCIPLES ARTIFICIA; HALL LH, 1995, J CHEM INF COMP SCI, V35, P1039, DOI 10.1021/ci00028a014; HANSCH C, 1973, J MED CHEM, V16, P1207, DOI 10.1021/jm00269a003; Honkakoski P, 2003, ANN MED, V35, P172, DOI 10.1080/07853890310008224; HOUSTON JB, 1994, BIOCHEM PHARMACOL, V47, P1469; Jones JP, 1996, DRUG METAB DISPOS, V24, P1; Kemp CA, 2004, J MED CHEM, V47, P5340, DOI 10.1021/jm049934e; Kier L. B., 1999, MOL STRUCTURE DESCRI; Kirton SB, 2002, PROTEINS, V49, P216, DOI 10.1002/prot.10192; Kitchen DB, 2004, NAT REV DRUG DISCOV, V3, P935, DOI 10.1038/nrd1549; Klaassen CD, 2005, CURR DRUG METAB, V6, P309, DOI 10.2174/1389200054633826; Lantz RJ, 2003, DRUG METAB DISPOS, V31, P1142, DOI 10.1124/dmd.31.9.1142; LEO AJ, 1993, CHEM REV, V93, P1281, DOI 10.1021/cr00020a001; Levy R.H., 2000, METABOLIC DRUG INTER; Lewin JL, 2004, MOL PHARMACEUT, V1, P128, DOI 10.1021/mp049977r; Lewis D, 2001, J LEUKOCYTE BIOL, P72; Lewis DFV, 2000, XENOBIOTICA, V30, P1; Lewis DFV, 1998, XENOBIOTICA, V28, P235; Lewis DFV, 1999, TOXICOLOGY, V133, P1, DOI 10.1016/S0300-483X(98)00149-8; Li AP, 2001, DRUG DISCOV TODAY, V6, P357, DOI 10.1016/S1359-6446(01)01712-3; MATHIEU MP, 2004, PAREXELS PHARM R D S; MCLACHLAN GJ, 1992, DISCRIMINAT ANAL STA; Mestres J, 2005, PROTEINS, V58, P596, DOI 10.1002/prot.20354; Nicolaou K. C., 2002, HDB COMBINATORIAL CH; Park JY, 2003, J MED CHEM, V46, P1645, DOI 10.1021/jm020538a; Pastor M, 2000, J MED CHEM, V43, P3233, DOI 10.1021/jm000941m; Rao S, 2000, J MED CHEM, V43, P2789, DOI 10.1021/jm000048n; Ratti E, 2001, PURE APPL CHEM, V73, P67, DOI 10.1351/pac200173010067; Ridderstrom M, 2001, J MED CHEM, V44, P4072, DOI 10.1021/jm0109107; RODRIGUES DA, 1997, PHARM RES, P1504; Ruschitzka F, 2000, LANCET, V355, P548, DOI 10.1016/S0140-6736(99)05467-7; Schoch GA, 2004, J BIOL CHEM, V279, P9497, DOI 10.1074/jbc.M312516200; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Shen M, 2003, J MED CHEM, V46, P3013, DOI 10.1021/jm020491t; SKOLNICK JL, 1976, JAMA-J AM MED ASSOC, V236, P1382, DOI 10.1001/jama.236.12.1382; Sprague PW, 1995, PERSPECT DRUG DISCOV, V3, P1, DOI 10.1007/BF02174464; STANTON DT, 1990, ANAL CHEM, V62, P2323, DOI 10.1021/ac00220a013; STROBL GR, 1993, J MED CHEM, V36, P1136, DOI 10.1021/jm00061a004; Szklarz GD, 2002, J BIOMOL STRUCT DYN, V20, P155; Szklarz GD, 1998, DRUG METAB DISPOS, V26, P1179; Szklarz GD, 1997, J COMPUT AID MOL DES, V11, P265, DOI 10.1023/A:1007956612081; Tanaka T, 2004, CHEM PHARM BULL, V52, P836, DOI 10.1248/cpb.52.836; Tanaka T, 2004, CHEM PHARM BULL, V52, P830, DOI 10.1248/cpb.52.830; Tarbit MH, 1998, CURR OPIN CHEM BIOL, V2, P411, DOI 10.1016/S1367-5931(98)80017-3; Tetko IV, 2001, J CHEM INF COMP SCI, V41, P1407, DOI 10.1021/ci010368v; Thompson TN, 2000, CURR DRUG METAB, V1, P215, DOI 10.2174/1389200003339018; Todeschini R., 2000, HDB MOL DESCRIPTORS; Vapnik V. N., 1995, NATURE STAT LEARNING; VERONESE ME, 1993, BIOCHEM J, V289, P533; Votano JR, 2005, CURR OPIN DRUG DISC, V8, P32; Wang QM, 2002, DRUG METAB DISPOS, V30, P86, DOI 10.1124/dmd.30.1.86; Watkins RE, 2003, BIOCHEMISTRY-US, V42, P1430, DOI 10.1021/bi0268753; Watkins RE, 2001, SCIENCE, V292, P2329, DOI 10.1126/science.1060762; Wester MR, 2004, J BIOL CHEM, V279, P35630, DOI 10.1074/jbc.M405427200; White RE, 2000, ANNU REV PHARMACOL, V40, P133, DOI 10.1146/annurev.pharmtox.40.1.133; Williams JA, 2004, DRUG METAB DISPOS, V32, P1201, DOI 10.1124/dmd.104.000794; Williams PA, 2003, NATURE, V424, P464, DOI 10.1038/nature01862; Williams PA, 2004, SCIENCE, V305, P683, DOI 10.1126/science.1099736; Windshugel B, 2005, J MOL MODEL, V11, P69, DOI 10.1007/s00894-004-0227-4; Wold H., 1985, ENCY STATISTICAL SCI, V6, P581; Yano JK, 2005, NAT STRUCT MOL BIOL, V12, P822, DOI 10.1038/nsmb971; Yano JK, 2004, J BIOL CHEM, V279, P38091, DOI 10.1074/jbc.C400293200; 1995, TESTA B METABOLISM D	83	4	5	1	2	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4099	1875-6697		CURR COMPUT-AID DRUG	Curr. Comput.-Aided Drug Des.	JUN	2006	2	2					177	188		10.2174/157340906777441726		12	Chemistry, Medicinal; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Computer Science	V17TH	WOS:000207959000008		
J	Maas, MC; van der Laan, DJ; Schaart, DR; Huizenga, J; Brouwer, JC; Bruyndonckx, P; Leonard, S; Lemaitre, C; van Eijk, CWE				Maas, MC; van der Laan, DJ; Schaart, DR; Huizenga, J; Brouwer, JC; Bruyndonckx, P; Leonard, S; Lemaitre, C; van Eijk, CWE			Experimental characterization of monolithic-crystal small animal PET detectors read out by APD arrays	IEEE TRANSACTIONS ON NUCLEAR SCIENCE			English	Article						angle of incidence; avalanche photodiode (APD); depth-of-interaction; monolithic scintillator crystals; nearest neighbor method; positron emission tomography (PET); spatial resolution	NEURAL-NETWORK; DESIGN; SCINTILLATORS; SCANNER	Minimizing dead space is one way to increase the detection efficiency of small-animal PET scanners. By using monolithic scintillator crystals (e.g., 20 mm x 10 mm x 10 mm LSO), loss of efficiency due to inter-crystal reflective material is minimized. Readout of such crystals can be performed by means of one or more avalanche photo-diode (APD) arrays optically coupled to the crystal. The entry point of a gamma photon on the crystal surface can be estimated from the measured distribution of the scintillation light over the APD array(s). By estimating the entry point, correction for the depth-of-interaction (DOI) is automatically provided. We are studying the feasibility of such detector modules. To this end, a 64-channel test setup has been developed. Experiments to determine the effect on the spatial resolution of crystal surface finish and detector geometry have been carried out. The first results of these experiments are presented and compared to simulation results. The crystal surface finish has only a small influence on the spatial resolution. The spatial resolution of 20 mm x 10 nun x 10 mm detectors is significantly better when read out on the front side than when read out on the back side. With a 20 mm x 10 mm x 20 mm crystal coupled to two APD arrays, a very small resolution degradation of only similar to 0.2 min is observed for an incidence angle of 30 degrees compared to normal incidence.	Delft Univ Technol, NL-2629 JB Delft, Netherlands; Vrije Univ Brussels, Inter Univ Inst High Energies, B-1050 Brussels, Belgium	Maas, MC (reprint author), Delft Univ Technol, NL-2629 JB Delft, Netherlands.	m.c.maas@tnw.tudelft.nl	Schaart, Dennis/C-7136-2014; Maas, Marnix/J-5101-2014	Schaart, Dennis/0000-0002-3199-5608; 			ADAM LE, 2000, P IEEE NSS, V3, P17; Antich P, 2002, NUCL INSTRUM METH A, V480, P782, DOI 10.1016/S0168-9002(01)01214-1; Bruyndonckx P, 2003, IEEE T NUCL SCI, V50, P1415, DOI 10.1109/TNS.2003.817348; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; CLEMENT D, 1998, P IEEE NSS, V3, P1448; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Delorme S, 1996, NUCL INSTRUM METH A, V373, P111, DOI 10.1016/0168-9002(95)01511-6; Heinrichs U, 2003, IEEE T NUCL SCI, V50, P1428, DOI 10.1109/TNS.2003.817409; KHODAVERDI M, 2001, P IEEE NSS, V3, P1605; Slates R, 1999, IEEE T NUCL SCI, V46, P565, DOI 10.1109/23.775580; Slates R, 2000, IEEE T NUCL SCI, V47, P1018, DOI 10.1109/23.856541; Tai YC, 2003, PHYS MED BIOL, V48, P1519, DOI 10.1088/0031-9155/48/11/303; VANDERLAAN DJ, 2004, P IEEE NSS MIC, V4, P2417; VANDERLAAN DJ, IN PRESS IEEE T NUCL; van Eijk CWE, 2002, PHYS MED BIOL, V47, pR85, DOI 10.1088/0031-9155/47/8/201	15	42	42	2	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9499			IEEE T NUCL SCI	IEEE Trans. Nucl. Sci.	JUN	2006	53	3	2				1071	1077		10.1109/TNS.2006.873711		7	Engineering, Electrical & Electronic; Nuclear Science & Technology	Engineering; Nuclear Science & Technology	057FP	WOS:000238582000002		
J	Wang, H				Wang, H			Nearest neighbors by neighborhood counting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; machine learning; nearest neighbors; distance; similarity; neighborhood counting measure	CLASSIFICATION	Finding nearest neighbors is a general idea that underlies many artificial intelligence tasks, including machine learning, data mining, natural language understanding, and information retrieval. This idea is explicitly used in the k- nearest neighbors algorithm ( kNN), a popular classification method. In this paper, this idea is adopted in the development of a general methodology, neighborhood counting, for devising similarity functions. We turn our focus from neighbors to neighborhoods, a region in the data space covering the data point in question. To measure the similarity between two data points, we consider all neighborhoods that cover both data points. We propose to use the number of such neighborhoods as a measure of similarity. Neighborhood can be defined for different types of data in different ways. Here, we consider one definition of neighborhood for multivariate data and derive a formula for such similarity, called neighborhood counting measure or NCM. NCM was tested experimentally in the framework of kNN. Experiments show that NCM is generally comparable to VDM and its variants, the state- of- the- art distance functions for multivariate data, and, at the same time, is consistently better for relatively large k values. Additionally, NCM consistently outperforms HEOM ( a mixture of Euclidean and Hamming distances), the " standard" and most widely used distance function for multivariate data. NCM has a computational complexity in the same order as the standard Euclidean distance function and NCM is task independent and works for numerical and categorical data in a conceptually uniform way. The neighborhood counting methodology is proven sound for multivariate data experimentally. We hope it will work for other types of data.	Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland; Univ Metz, LITA, F-57045 Metz, France	Wang, H (reprint author), Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland.	h.wang@ulster.ac.uk					[Anonymous], 2012, WIK FREE ENC; Ash Robert B., 2000, PROBABILITY MEASURE; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Blake C, 1998, UCI REPOSITORY MACHI; Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DOMINGOS P, 1995, P 1995 INT JOINT C A; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Elkan C., 1999, RESULTS KDD 99 CLASS; Fix E., 1951, TR4 US AIR FORC SCH; Gardenfors P., 2000, CONCEPTUAL SPACES GE; Hand D, 2001, PRINCIPLES DATA MINI; HAYASHI H, 2001, OPTIMIZATION NEAREST; MITCHELL TM, 1997, MACHINE LEARING; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; OSBORNE H, 1997, P INT WORKSH SIM CAT, P173; Rachlin J., 1994, P 11 INT MACH LEARN, P242; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Snedecor GW, 2002, STAT METHODS; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Stevens S., 1951, MATH MEASUREMENT PSY; TOWELL GG, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P861; Wang H, 2004, INT J APPROX REASON, V36, P223, DOI 10.1016/j.ijar.2003.10.007; Widdows Dominic, 2004, GEOMETRY AND MEANING; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	29	51	58	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					942	953				12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	031WB	WOS:000236734400008	16724588	
J	Zhao, QF				Zhao, QF			Inducing NNC-Trees with the R-4-rule	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						decision trees; machine learning and understanding; nearest neighbor classifier; neural networks; NNC-trees; R-4-rule	NEIGHBOR PATTERN-CLASSIFICATION; FUZZY DECISION TREES; HIERARCHICAL-CLASSIFICATION; ALGORITHM; RULE; MLP	An NNC-Tree is a decision tree (DT) with each non-terminal node containing a nearest neighbor classifier (NNC). Compared with the conventional axis-parallel DTs (APDTs), the NNC-Trees can be more efficient, because the decision boundary made by an NNC is more complex than an axis-parallel hyperplane. Compared with single-layer NNCs, the NNC-Trees can classify given data in a hierarchical structure that is often useful for many applications. This paper proposes an algorithm for inducing NNC-Trees based on the R-4-rule, which was proposed by tine author for finding the smallest nearest neighbor based multilayer perceptrons (NN-MLPs). There are mainly two contributions here. 1) A heuristic but effective method is given to define the teacher signals (group labels) for the data assigned to each nonterminal node. 2) The R-4-rule is modified so that an NNC with proper size can be designed automatically in each nonterminal node. Experiments with several public databases show that the proposed algorithm can produce NNC-Trees effectively and efficiently.	Univ Aizu, Fukushima 9658580, Japan	Zhao, QF (reprint author), Univ Aizu, Fukushima 9658580, Japan.						Adams RG, 1999, NEURAL NETWORKS, V12, P541, DOI 10.1016/S0893-6080(99)00010-6; Basak J, 2005, IEEE T KNOWL DATA EN, V17, P121, DOI 10.1109/TKDE.2005.11; Basak J, 2004, NEURAL COMPUT, V16, P1959, DOI 10.1162/0899766041336396; Brieman L, 1984, CLASSIFICATION REGRE; Cantu-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GOLEA M, 1990, EUROPHYS LETT, V12, P105; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HENRICHO.EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Janikow CZ, 1998, IEEE T SYST MAN CY B, V28, P1, DOI 10.1109/3477.658573; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kearns M. J., 1994, INTRO COMPUTATIONAL; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; LI T, 1993, NEUROCOMPUTING, V5, P119, DOI 10.1016/0925-2312(93)90032-X; LINDE Y, 1980, IEEE T COMMUN, V28, P1; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MIZUNO S, 2002, P IEEE INT C SYST MA, P239; Murthy S.K., 1994, J ARTIFICIAL INTELLI, V2, P1; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Suarez A, 1999, IEEE T PATTERN ANAL, V21, P1297, DOI 10.1109/34.817409; TAKEDA T, 2003, P INT C HYBR INT SYS, P107; Takeda T, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P513; Tsukimoto H, 2000, IEEE T NEURAL NETWOR, V11, P377, DOI 10.1109/72.839008; XU QZ, 2004, ON LINE J NEURO INF, V3, P77; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; ZHAO QF, 2004, P IEEE INT C SYST MA, P5702; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240	38	3	3	1	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	JUN	2006	36	3					520	533		10.1109/TSMCB.2005.861868		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	050EB	WOS:000238069200004	16761807	
J	Liu, T; Moore, AW; Gray, A				Liu, Ting; Moore, Andrew W.; Gray, Alexander			New algorithms for efficient high-dimensional nonparametric classification	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						ball-tree; k-NN classification	NEAREST-NEIGHBOR CLASSIFICATION; CLASSIFIERS; RULE; DESIGN; TREES	This paper is about non-approximate acceleration of high-dimensional nonparametric operations such as k nearest neighbor classifiers. We attempt to exploit the fact that even if we want exact answers to nonparametric queries, we usually do not need to explicitly find the data points close to the query, but merely need to answer questions about the properties of that set of data points. This offers a small amount of computational leeway, and we investigate how much that leeway can be exploited. This is applicable to many algorithms in nonparametric statistics, memory-based learning and kernel-based learning. But for clarity, this paper concentrates on pure k-NN classification. We introduce new ball-tree algorithms that on real-world data sets give accelerations from 2-fold to 100-fold compared against highly optimized traditional ball-tree-based k-NN. These results include data sets with up to 106 dimensions and 105 records, and demonstrate non-trivial speed-ups while giving exact answers.	Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA	Liu, T (reprint author), Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.	TINGLIU@CS.CMU.EDU; AWM@CS.CMU.EDU; AGRAY@CS.CMU.EDU					Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BAXTER J, 1998, ADV NEURAL INFORM PR, V10; Bay S.D., 1999, UCI KDD ARCH; Cardie Claire, 1997, P 14 INT C MACH LEAR, P57; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CIACCIA P, 1997, P 23 VLDB INT C SEPT; CLARKSON KL, 2002, NEAREST NEIGHBOR SEA; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Deng K., 1995, P 12 INT JOINT C ART, P1233; Devroye L., 1982, NEAREST NEIGHBOR MET, V2; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Draper N.R., 1981, APPL REGRESSION ANAL, V2<SUP>nd</SUP>; Duda R. O., 1973, PATTERN CLASSIFICATI; FALOUTSOS C, 1995, CSTR3514 CARN MELL U; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, DOI 10.1007/BF00962238; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FISHER FP, 1970, P NATL EL C DEC, V26, P481; Flickner M., 1995, IEEE COMPUT, P23; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GIONIS A, 1999, P 25 VLDB C; Gray A. G., 2001, ADV NEURAL INFORM PR; GUTTMAN A, 1984, P 3 ACM SIGACT SIGMO; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HAMMERSLEY JM, 1950, ANN MATH STAT, V21, P447, DOI 10.1214/aoms/1177729805; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; INDYK P, 2001, J COMPUTER SYSTEM SC, V63; KOIVUNE V, 1995, IEEE WORKSH NONL SIG; Komarek P, 2003, ARTIFICIAL INTELLIGE; KREUGEL C, 2003, P 10 ACM C COMP COMM, P251; Lee EW, 1998, IEEE T PATTERN ANAL, V20, P562; LIU T, 2004, P C KNOWL DISC DAT K; Liu Ting, 2004, P NEUR INF PROC SYST; MANEEWONGVATANA S, 2001, P WADS 2001; MOORE AW, 2000, 12 C UNC ART INT; Omachi S., 2000, Systems and Computers in Japan, V31; Omohundro S. M., 1987, Complex Systems, V1; OMOHUNDRO SM, 1991, ADV NEURAL INFORM PR, V3; PALAU AM, 1998, P 14 INT C PATT REC; PEDNAULT EPD, 2000, HANDLING IMBALANCED; PELLEG D, 1999, P 5 INT C KNOWL DISC; Pentland A., 1994, PHOTOBOOK CONTENT BA; Preparata F. P., 1985, COMPUTATIONAL GEOMET; QI Y, 2003, P IEEE INT C MULT EX; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Salton G, 1983, INTRO MODERN INFORM; SETHI IK, 1981, IEEE T SYST MAN CYB, V11, P245; SMEULDERS A, 1996, IMAGE DATABASES MULT; STOLFO S, 1997, CREDIT CARD FRAUD DE; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; ZHANG T, 1996, P 15 ACM SIGACT SIGM; Zheng WF, 2000, J CHEM INF COMP SCI, V40, P185, DOI 10.1021/ci980033m	58	10	11	1	1	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2006	7						1135	1158				24	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152UV	WOS:000245388400010		
J	Everson, RM; Fieldsend, JE				Everson, RM; Fieldsend, JE			Multi-class ROC analysis from a multi-objective optimisation perspective	PATTERN RECOGNITION LETTERS			English	Article						receiver operating characteristic; evolutionary computation; multiple objectives; Pareto optimality; Gini coefficient	CLASSIFICATION; CURVE; AREA; CLASSIFIERS	The receiver operating characteristic (ROC) has become a standard tool for the analysis and comparison of classifiers when the costs of misclassification are unknown. There has been relatively little work, however, examining ROC for more than two classes. Here we discuss and present an extension to the standard two-class ROC for multi-class problems. We define the ROC surface for the Q-class problem in terms of a multi-objective optimisation problem in which the goal is to simultaneously minimise the Q(Q-1) misclassification rates, when the misclassification costs and parameters governing the classifier's behaviour are unknown. We present an evolutionary algorithm to locate the Pareto front-the optimal trade-off surface between misclassifications of different types. The use of the Pareto optimal surface to compare classifiers is discussed and we present a straightforward multi-class analogue of the Gini coefficient. The performance of the evolutionary algorithm is illustrated on a synthetic three class problem, for both k-nearest neighbour and multi-layer perceptron classifiers. (c) 2005 Elsevier B.V. All rights reserved.	Univ Exeter, Dept Comp Sci, Sch Engn Comp Sci & Math, Exeter EH4 4QF, Devon, England	Everson, RM (reprint author), Univ Exeter, Dept Comp Sci, Sch Engn Comp Sci & Math, Harrison Bldg, Exeter EH4 4QF, Devon, England.	R.M.Everson@exeter.ac.uk; J.E.Fieldsend@exeter.ac.uk					Adams NM, 1999, PATTERN RECOGN, V32, P1139, DOI 10.1016/S0031-3203(98)00154-X; Anastasio MA, 1998, IEEE T MED IMAGING, V17, P1089, DOI 10.1109/42.746726; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Coello C. A. C., 1999, Knowledge and Information Systems, V1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deb K., 2001, MULTIOBJECTIVE OPTIM; Duda R. O., 1973, PATTERN CLASSIFICATI; EVERSON RM, 2006, IN PRESS IEEE T EVOL; Fieldsend J., 2005, P ROCML 2005 22 INT, P41; Fieldsend J. E., 2005, P ROCML 2005 22 INT, P49; FIELDSEND JE, 2004, P ROCAI 2004, P37; Fieldsend JE, 2003, IEEE T EVOLUT COMPUT, V7, P305, DOI 10.1109/TEVC.2003.810733; Gijbels I., 1996, LOCAL POLYNOMIAL MOD; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; HERNANDEZORALLO J, 2004, ROC ANAL ARTIFICIAL; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; HOLMES CC, 2002, J ROYAL STAT SOC B, V64, P1; Knowles JD, 2000, EVOL COMPUT, V8, P149, DOI 10.1162/106365600568167; Kupinski MA, 1999, IEEE T MED IMAGING, V18, P675, DOI 10.1109/42.796281; Mossman D, 1999, MED DECIS MAKING, V19, P78, DOI 10.1177/0272989X9901900110; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; SCOTT MJJ, 1998, CUEDFINFENGTR323; Srinivasan A., 1999, PRGTR299 OXF U COMP; Struyf J., 2003, DATA MINING DECISION, P81; Van Veldhuizen DA, 2000, EVOL COMPUT, V8, P125; Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82; ZWEIG MH, 1993, CLIN CHEM, V39, P561	31	39	42	1	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2006	27	8					918	927		10.1016/j.patrec.2005.10.016		10	Computer Science, Artificial Intelligence	Computer Science	041NL	WOS:000237462800008		
J	Oh, JH; Choi, KS				Oh, JH; Choi, KS			An ensemble of transliteration models for information retrieval	INFORMATION PROCESSING & MANAGEMENT			English	Article						machine transliteration; ensemble-based transliteration model; web data; information retrieval; machine learning		Transliteration is used to phonetically translate proper names and technical terms especially from languages in Roman alphabets to languages in non-Roman alphabets such as from English to Korean, Japanese, and Chinese. Because transliterations are usually representative index terms for documents, proper handling of the transliterations is important for an effective information retrieval system. However, there are limitations on handling transliterations depending on dictionary lookup, because transliterations are usually not registered in the dictionary. For this reason, many researchers have been trying to overcome the problem using machine transliteration. In this paper, we propose a method for improving machine transliteration using an ensemble of three different transliteration models. Because one transliteration model alone has limitation on reflecting all possible transliteration behaviors, several transliteration models should be complementary used in order to achieve a high-performance machine transliteration system. This paper describes a method about transliteration production using the several machine transliteration models and transliteration ranking with web data and relevance scores given by each transliteration model. We report evaluation results for our ensemble transliteration model and experimental results for its impact on IR effectiveness. Machine transliteration tests on English-to-Korean transliteration and English-to-Japanese transliteration show that our proposed method achieves 78-80% word accuracy. Information retrieval tests on KTSET and NTCIR-1 test collection show that our transliteration model can improve the performance of an information retrieval system about 10-34%. (c) 2005 Elsevier Ltd. All rights reserved.	Korea Adv Inst Sci & Technol, Korea Terminol Res Ctr Language & Knowledge Engn, KORTERM, Dept EECS,Comp Sci Div, Taejon 305701, South Korea	Oh, JH (reprint author), Natl Inst Informat & Commun Technol, Informat & Network Syst Dept, Computat Linguist Grp, 3-5 Hikaridai Seika Cho, Kyoto 6190289, Japan.	rovellia@nict.go.jp; kschoi@world.kaist.ac.kr	Choi, Key-Sun/C-1978-2011				AH DW, 1997, ARTIF INTELL, V11, P710; Aha D., 1991, MACH LEARN, V6, P3766; Al-Onaizan Y., 2002, P ACL 2002; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bilac S., 2004, P IJCNLP 2004, P542; BREEN J, 2003, EDICT JAPANESE ENGLI; BRILL E, 2001, NIST SPECIAL PUBLICA, P393; *CMU, 1997, CARN MELL U CMU PRON; COLLIER N, 1997, P NAT LANG PROC PAC, P309; Cover TM, 1967, IEEE T INFORM THEORY, V13, P2127, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2002, TIMBLE TIMBL TILBURG; Devijver P. A., 1982, PATTERN RECOGNITION; Fujii A, 2001, COMPUT HUMANITIES, V35, P389, DOI 10.1023/A:1011856202986; Goto I., 2003, P MT SUMM 9, VIX; GREFENSTETTE G, 1999, P ASLIB 99 TRANSL CO, V21; Jeong KS, 1999, INFORM PROCESS MANAG, V35, P523, DOI 10.1016/S0306-4573(98)00055-7; KANDO N, 1999, P 1 NTCIR WORKSH RES; KANG BJ, 2000, P 2 INT C LANG RES E; Kang Byung Ju, 2001, THESIS COMPUTER SCI; KANG IH, 2000, P 18 INT C COMP LING; KIM JL, 1999, P KOR COGN SCI ASS; Knight K, 1997, P 35 ANN M ASS COMP; KUO JS, 2004, PACLIC, V18; Lee J. S., 1998, COMPUTER PROCESSING, V12, P17; LEE JS, 1999, THESIS COMPUTER SCI; LI HZ, 2004, ACL, P159; LI Y, 2005, CORIA 2005 C; Lin Wei-Hao, 2002, P 6 C NAT LANG LEARN, P139; Manning C., 1999, FDN STAT NATURAL LAN; Mitchell T. M., 1997, MACHINE LEARNING; Miyao Y., 2002, P HUM LANG TECHN C H; NAM YS, 1997, FOREIGN DICT; OH JH, 2002, P COLING 2002; PARK YC, 1996, P 23 KISS SPRING C; PAUL O, 2001, P 10 TEXT RETR C TRE; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Salton G., 1989, AUTOMATIC TEXT PROCE; Tsuji K., 2002, International Journal of Computer Processing of Oriental Languages, V15, DOI 10.1142/S0219427902000649; Vapnik V. N., 1995, NATURE STAT LEARNING; Zhang L., 2004, MAXIMUM ENTROPY MODE	41	3	3	0	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0306-4573			INFORM PROCESS MANAG	Inf. Process. Manage.	JUL	2006	42	4					980	1002		10.1016/j.ipm.2005.09.007		23	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	021ST	WOS:000236006600008		
J	Cannas, B; Cau, F; Fanni, A; Sonato, P; Zedda, MK				Cannas, B.; Cau, F.; Fanni, A.; Sonato, P.; Zedda, M. K.		JET-EFDA Contributors	Automatic disruption classification at JET: comparison of dinerent pattern recognition techniques	NUCLEAR FUSION			English	Article; Proceedings Paper	16th Topical Conference on RF Power in Plasmas	APR, 2005	Park City, UT				MHD STABILITY; ASDEX UPGRADE; TOKAMAKS; CLASSIFIERS; PREDICTOR; NETWORKS; LIMITS; MODEL	In this paper, different pattern recognition techniques have been tested in order to implement an automatic tool for disruption classification in a tokamak experiment. The methods considered refer to clustering and classification techniques. In particular, the investigated clustering techniques are self-organizing maps and K-means, while the classification techniques are multi-layer perceptrons, support vector machines, and k- nearest neighbours. Training and testing data have been collected selecting suitable diagnostic signals recorded over 4 years of EFDA-JET experiments. Multi-layer perceptron classifiers exhibited the best performance in classifying mode lock, density limit/high radiated power, H-mode/L-mode transition and internal transport barrier plasma disruptions. This classification performance can be increased using multiple classifiers. In particular the outputs of five multi-layer perceptron classifiers have been combined using multiple classifier techniques in order to obtain a more robust and reliable classification tool, that is presently implemented at JET.	Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy; EURATOM ENEA Assoc, Consorzio RFX, I-35127 Padua, Italy	Cannas, B (reprint author), Univ Cagliari, Dept Elect & Elect Engn, Piazzi Armi, I-09123 Cagliari, Italy.						Mirnov S, 1999, NUCL FUSION, V39, P2251, DOI 10.1088/0029-5515/39/12/303; Borrass K, 2004, NUCL FUSION, V44, P752, DOI 10.1088/0029-5515/44/7/007; Cannas B, 2004, NUCL FUSION, V44, P68, DOI 10.1088/0029-5515/44/1/008; Chang C.C., 2001, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; FIELDING SJ, 1977, NUCL FUSION, V17, P1382, DOI 10.1088/0029-5515/17/6/020; FUMERA G, 2002, LNCS, V2396, P424; Greenwald M., 2002, PLASMA PHYS CONTROL, V44, P27; GREENWALD M, 1988, NUCL FUSION, V28, P2199, DOI 10.1088/0029-5515/28/12/009; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hender TC, 2002, PLASMA PHYS CONTR F, V44, P1143, DOI 10.1088/0741-3335/44/7/306; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; *MATHW, 2001, NEUR NETW TOOLB US M; MURAKAMI M, 1976, NUCL FUSION, V16, P347, DOI 10.1088/0029-5515/16/2/020; NAVE MFF, 1990, NUCL FUSION, V30, P2575, DOI 10.1088/0029-5515/30/12/011; NOLL P, 1985, 11TH P S FUS ENG AUS, V1, P33; Pautasso G, 2002, NUCL FUSION, V42, P100, DOI 10.1088/0029-5515/42/1/314; PAUTASSO G, 1998, ICPP 25 EPS C CONT C, V22, P520; Principe J.C., 2000, NEURAL ADAPTIVE SYST; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Schuller FC, 1995, PLASMA PHYS CONTR F, V37, pA135, DOI 10.1088/0741-3335/37/11A/009; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; TURNER K, 1999, COMBINING ARTIFICIAL, P127; Vapnik V., 1998, STAT LEARNING THEORY; VASANTO J, 1999, P MATLAB DSP C ESP F, P35; WARD DJ, 1992, NUCL FUSION, V32, P1117, DOI 10.1088/0029-5515/32/7/I03; Wesson J., 2004, TOKAMAK; WESSON JA, 1989, NUCL FUSION, V29, P641, DOI 10.1088/0029-5515/29/4/009; Windsor CG, 2005, NUCL FUSION, V45, P337, DOI 10.1088/0029-5515/45/5/004; Wroblewski D, 1997, NUCL FUSION, V37, P725, DOI 10.1088/0029-5515/37/6/I02; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yoshino R, 2003, NUCL FUSION, V43, P1771, DOI 10.1088/0029-5515/43/12/021; ZEDDA MK, 2003, 30 EPS C CONTR FUS A, V27	37	9	9	1	1	INT ATOMIC ENERGY AGENCY	VIENNA	WAGRAMERSTRASSE 5, PO BOX 100, A-1400 VIENNA, AUSTRIA	0029-5515			NUCL FUSION	Nucl. Fusion	JUL	2006	46	7					699	708		10.1088/0029-5515/46/7/002		10	Physics, Fluids & Plasmas; Physics, Nuclear	Physics	069WE	WOS:000239478900017		
J	Hammouche, K; Diaf, M; Postaire, JG				Hammouche, K; Diaf, M; Postaire, JG			A clustering method based on multidimensional texture analysis	PATTERN RECOGNITION			English	Article						cluster analysis; texture; co-occurrence matrices; feature selection	MODE BOUNDARY DETECTION; RANDOM-FIELD MODELS; PATTERN-CLASSIFICATION; SEGMENTATION; RELAXATION; SELECTION; FEATURES; IMAGES	Considering the analogy between image segmentation and cluster analysis, the aim of this paper is to adapt statistical texture measures to describe the spatial distribution of multidimensional observations. The main idea is to consider the cluster cores as domains characterized by their specific textures in the data space. The distribution of the data points is first described as a multidimensional histogram defined on a multidimensional regular array of sampling points. In order to evaluate locally a multidimensional texture, a co-occurrence matrix is introduced, which characterizes the local distribution of the data points in the multidimensional data space. Several local texture features can be computed from this co-occurrence matrix, which accumulates spatial and statistical information on the data distribution in the neighborhoods of the sampling points. Texture features are selected according to their ability to discriminate different distributions of data points. The sampling points where the local underlying texture is evaluated are categorized into different texture classes. The points assigned to these classes tend to form connected components in the data space, which are considered as the cores of the clusters. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Sci & Technol Lille, LAGIS, UMR 8146, CNRS, F-59655 Villeneuve Dascq, France; Univ Mouloud Mammeri, Dept Automat, Tizi Ouzou, Algeria	Postaire, JG (reprint author), Univ Sci & Technol Lille, LAGIS, UMR 8146, CNRS, F-59655 Villeneuve Dascq, France.	Jack-Gerard.Postaire@univ-lille1.fr					ARGENTI F, 1990, IEE PROC-F, V137, P443; Ball G. H., 1965, AD699616 NTIS STANF; BENSLIMANE R, 1996, EUR J AUTOMATION, V30, P1169; Clausi DA, 1998, IEEE T GEOSCI REMOTE, V36, P298, DOI 10.1109/36.655338; Clausi DA, 2002, CAN J REMOTE SENS, V28, P45; Comer ML, 1999, IEEE T IMAGE PROCESS, V8, P408, DOI 10.1109/83.748895; CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; DANKER AJ, 1981, IEEE T PATTERN ANAL, V3, P79; Davis L.S., 1975, COMPUTER GRAPHICS IM, V4, P248, DOI 10.1016/0146-664X(75)90012-X; Devijver P. A., 1982, PATTERN RECOGNITION; Duff I. S., 1986, DIRECT METHODS SPARS; EIGEN DJ, 1974, IEEE T SYST MAN CYB, VSMC4, P284; Haralick R. M., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8; LECOCQ CB, 1991, SYMBOLIC-NUMERIC DATA ANALYSIS AND LEARNING, P173; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Porter R, 1996, IEEE T IMAGE PROCESS, V5, P662, DOI 10.1109/83.491343; POSTAIRE JG, 1982, IEEE T PATTERN ANAL, V4, P663; POSTAIRE JG, 1993, IEEE T PATTERN ANAL, V15, P170, DOI 10.1109/34.192490; POSTAIRE JG, 1989, PATTERN RECOGN, V22, P477, DOI 10.1016/0031-3203(89)90018-6; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3, P163; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/cviu.1993.1024; Sbihi A., 1995, DATA KNOWLEDGE THEOR, P212; SBIHI A, 2000, EUR J AUTOMATION, P247; SBIHI A, 2001, EUR J AUTOMATION, V35, P1073; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; TOUZANI A, 1988, IEEE T PATTERN ANAL, V10, P970, DOI 10.1109/34.9120; TOUZANI A, 1989, PATTERN RECOGN LETT, V9, P1, DOI 10.1016/0167-8655(89)90022-6; WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8	36	4	5	1	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	JUL	2006	39	7					1265	1277		10.1016/j.patcog.2005.11.024		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	043GR	WOS:000237588800005		
J	Shen, HB; Chou, KC				Shen, Hong-Bin; Chou, Kuo-Chen			Ensemble classifier for protein fold pattern recognition	BIOINFORMATICS			English	Article							AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; ENERGETIC APPROACH; STABILITY; SEQUENCE; HELICES; RULE; SCOP; NN	Motivation: Prediction of protein folding patterns is one level deeper than that of protein structural classes, and hence is much more complicated and difficult. To deal with such a challenging problem, the ensemble classifier was introduced. It was formed by a set of basic classifiers, with each trained in different parameter systems, such as predicted secondary structure, hydrophobicity, van der Waals volume, polarity, polarizability, as well as different dimensions of pseudo-amino acid composition, which were extracted from attaining dataset. The operation engine for the constituent individual classifiers was OET-KNN (optimized evidence-theoretic k-nearest neighbors) rule. Their outcomes were combined through a weighted voting to give a final determination for classifying a query protein. The recognition was to find the true fold among the 27 possible patterns. Results: The overall success rate thus obtained was 62% for a testing dataset where most of the proteins have < 25% sequence identity with the proteins used in training the classifier. Such a rate is 6-21% higher than the corresponding rates obtained by various existing NN (neural networks) and SVM (support vector machines) approaches, implying that the ensemble classifier is very promising and might become a useful vehicle in protein science, as well as proteomics and bioinformatics.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Shen, HB (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.	lifesci-sjtu@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Andreeva A, 2004, NUCLEIC ACIDS RES, V32, P226; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1982, J MOL BIOL, V162, P89, DOI 10.1016/0022-2836(82)90163-2; Chou KC, 1997, PROTEINS, V28, P99, DOI 10.1002/(SICI)1097-0134(199705)28:1<99::AID-PROT10>3.0.CO;2-C; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, BIOCHEM BIOPH RES CO, V264, P216, DOI 10.1006/bbrc.1999.1325; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; CHOU KC, 1991, PROTEINS, V9, P280, DOI 10.1002/prot.340090406; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; CHOU KC, 1990, ACCOUNTS CHEM RES, V23, P134, DOI 10.1021/ar00173a003; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; CHOU KC, 1984, J AM CHEM SOC, V106, P3161, DOI 10.1021/ja00323a017; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chung IF, 2003, LECT NOTES COMPUT SC, V2714, P1159; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; FINKELSTEIN AV, 1987, PROG BIOPHYS MOL BIO, V50, P171, DOI 10.1016/0079-6107(87)90013-7; Holm L, 1999, NUCLEIC ACIDS RES, V27, P244, DOI 10.1093/nar/27.1.244; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Shafer G., 1976, MATH THEORY EVIDENCE; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	34	196	203	3	21	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	JUL 15	2006	22	14					1717	1722		10.1093/bioinformatics/btl170		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	073EN	WOS:000239725900006	16672258	
J	Mitani, Y; Hamamoto, Y				Mitani, Y; Hamamoto, Y			A local mean-based nonparametric classifier	PATTERN RECOGNITION LETTERS			English	Article						classifier design; nearest neighbor samples; small training sample size; dimensionality	RECOGNITION	A considerable amount of effort has been devoted to design a classifier in practical situations. In this paper, a simple nonparametric classifier based on the local mean vectors is proposed. The proposed classifier is compared with the I-NN, k-NN, Euclidean distance (ED), Parzen, and artificial neural network (ANN) classifiers in terms of the error rate on the unknown patterns, particularly in small training sample size situations. Experimental results show that the proposed classifier is promising even in practical situations. (c) 2005 Elsevier B.V. All rights reserved.	Ube Natl Coll Technol, Dept Intelligent Syst Engn, Ube, Yamaguchi 7558555, Japan; Yamaguchi Univ, Fac Engn, Ube, Yamaguchi 7558611, Japan	Mitani, Y (reprint author), Ube Natl Coll Technol, Dept Intelligent Syst Engn, 2-14-1 Tokiwadai, Ube, Yamaguchi 7558555, Japan.	mitani@ube-k.ac.jp					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, IEEE COMPUTER SOC PR; Devijver P. A., 1982, PATTERN RECOGNITION; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1969, IEEE T COMPUT, VC 18, P220, DOI 10.1109/T-C.1969.222635; Hamamoto Y, 1996, IEEE T PATTERN ANAL, V18, P571, DOI 10.1109/34.494648; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5; Jain A. K., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Jain A. K., 1988, ALGORITHMS CLUSTERIN; JAIN AK, 1988, PATTTERN RECOGNITION; Mitani Y., 2000, P 15 INT C PATT REC, V2, P773; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1; SCHMIDT WF, 1994, PATTERN RECOGN, V4, P391; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6; Yamamoto K, 1996, IEICE T INF SYST, VE79D, P417	19	37	40	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL 15	2006	27	10					1151	1159		10.1016/j.patrec.2005.12.016		9	Computer Science, Artificial Intelligence	Computer Science	049LP	WOS:000238018200012		
J	Ghosh, AK				Ghosh, Anil K.			On optimum choice of k in nearest neighbor classification	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						accuracy index; Bayesian strength function; cross-validation; misclassification rate; neighborhood parameter; non-informative prior; optimal Bayes risk; posterior probability	DISCRIMINANT-ANALYSIS	A major issue in k-nearest neighbor classification is how to choose the optimum value of the neighborhood parameter k. Popular cross-validation techniques often fail to guide us well in selecting k mainly due to the presence of multiple minimizers of the estimated misclassification rate. This article investigates a Bayesian method in this connection, which solves the problem of multiple optimizers. The utility of the proposed method is illustrated using some benchmark data sets. (C) 2005 Elsevier B.V. All rights reserved.	Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, 203 BT Rd, Kolkata 700108, India.	anilkghosh@rediffmail.com					Anderson T. W., 1984, INTRO MULTIVARIATE S, V2nd; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Friedman J., 1996, ANOTHER APPROACH POL; Friedman JH, 1994, FLEXIBLE METRIC NEAR; Ghosh AK, 2004, STAT SINICA, V14, P457; GHOSH AK, 2005, IN PRESS IEEE T PATT; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastie T, 1998, ANN STAT, V26, P451; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hodges J., 1951, 4 USAF SCH AV MED, P261; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Hopcroft J. E., 1974, DESIGN ANAL COMPUTER, V1st; Johnson R., 1992, APPL MULTIVARIATE ST, V3th; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Paik M., 2004, STAT APPL GENETICS M, V3; Ripley BD, 1996, PATTERN RECOGNITION; Silverman BW, 1986, DENSITY ESTIMATION S; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9	24	24	25	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473	1872-7352		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JUL 20	2006	50	11					3113	3123		10.1016/j.csda.2005.06.007		11	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	055SV	WOS:000238471600010		
J	Lee, JW; Lee, JS; Kang, M; Su, AI; Chang, YT				Lee, Jae Wook; Lee, Jun-Seok; Kang, Mira; Su, Andrew I.; Chang, Young-Tae			Visual artificial tongue for quantitative metal-cation analysis by an off-the-shelf dye array	CHEMISTRY-A EUROPEAN JOURNAL			English	Article						alkali metals; cations; dyes/pigments; hierarchical-cluster analysis; principal-component analysis	MOLECULAR RECOGNITION; SENSOR ARRAYS; WATER	A chemical-probe array composed of 47 off-the-shelf dyes was prepared in solution format (New York Tongue 1: NYT-1) and was tested in the identification and quantitation of 47 cation analytes, including 44 metal ions, in addition to H+, NH4(+), and tetrabutylammonium (TBA). The cation solutions were tested in a series of concentrations and the fold-change in effective absorbance was analyzed by principal-component analysis (PCA), hierarchical-cluster analysis (HCA), and nearest-neighbor decision to determine both identity and quantity of the analytes. Apart from alkali-metal ions (Na+, K+, Li+, Cs+, and Rb+), which behave very similarly to each other due mainly to their low response, most of the cations were clearly distinguishable at 10 mm concentration. The practical detection limit of each analyte was also determined by a sequential dilution and the nearest-neighbor decision method. In the finalized working analyte concentration range (approximately 10 mm down to 0.33 mu m), by considering alkali metals as one analyte group, most of the analytes were correctly identified (99.4%). Furthermore, the success rate at which the concentration of each analyte was correctly determined was also high (96.8 %).	NYU, Dept Chem, New York, NY 10003 USA; Novartis Res Fdn, Genom Inst, San Diego, CA 92121 USA	Chang, YT (reprint author), NYU, Dept Chem, New York, NY 10003 USA.	yt.chang@nyu.edu	Chang, Young-Tae/B-2780-2010; Lee, Jun-Seok/D-8428-2011; 	Chang, Young-Tae/0000-0002-1927-3688; Lee, Jun-Seok/0000-0003-3641-1728; Su, Andrew/0000-0002-9859-4104			Albert KJ, 2000, CHEM REV, V100, P2595, DOI 10.1021/cr980102w; Blalock E., 2003, BEGINNERS GUIDE MICR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Drayna D, 2005, ANNU REV GENOM HUM G, V6, P217, DOI 10.1146/annurev.genom.6.080604.162340; Feigl F., 1972, SPOT TESTS INORGANIC; FEIGL F, 1966, SPOT TESTS ORGANIC A; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Lavigne J. J., 2001, ANGEW CHEM, V113, P3212, DOI 10.1002/1521-3757(20010903)113:17<3212::AID-ANGE3212>3.0.CO;2-T; MARY T, 2003, ANAL CHEM, V75, P4389; Mikami D, 2004, ANAL CHEM, V76, P5726, DOI 10.1021/ac040024e; Miyaji H., 2001, ANGEW CHEM, V113, P158, DOI 10.1002/1521-3757(20010105)113:1<158::AID-ANGE158>3.0.CO;2-J; MUELLERACKERMAN.E, 1995, ANAL METHOD INSTRUM, V3, P182; Prestel H, 2000, FRESEN J ANAL CHEM, V368, P182, DOI 10.1007/s002160000379; Rakow N. A., 2005, ANGEW CHEM, V117, P4604, DOI 10.1002/ange.200500939; Rakow NA, 2005, ANGEW CHEM INT EDIT, V44, P4528, DOI 10.1002/anie.200500939; Suslick KS, 2004, TETRAHEDRON, V60, P11133, DOI 10.1016/j.tet.2004.09.007; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763; Zhang C, 2005, J AM CHEM SOC, V127, P11548, DOI 10.1021/ja052606z	18	31	33	1	11	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	0947-6539			CHEM-EUR J	Chem.-Eur. J.	JUL 24	2006	12	22					5691	5696		10.1002/chem.200600307		6	Chemistry, Multidisciplinary	Chemistry	069XD	WOS:000239481600004	16715541	
J	Park, SB				Park, Seong-Bae			Combining rule-based learning and memory-based learning for automatic word spacing in simple message service	APPLIED SOFT COMPUTING			English	Article						rule-based learning; memory-based learning; combined model and automatic word spacing	NETWORKS	Short message service (SMS) is a widely used service in modern mobile phones that allows users to send or receive short text messages. Current SMS, however, has two problems of inconvenient input and short message length. These problems can be resolved if a phone has an ability of automatic word spacing. This is because users need not put spaces in sending messages and longer messages are possible as they contain no space. Thus, automatic word spacing will be a very useful tool for SMS, if it can be commercially served. The practical issues of implementing it on the devices such as mobile phones are small memory and low computing power of the devices. To tackle these problems, this paper proposes a combined model of rule-based learning and memory-based learning. According to the experimental results, the model shows higher accuracy than rule-based learning or memory-based learning alone. In addition, the generated rules are so small and simple that the proposed model is appropriate for small memory devices. (C) 2005 Elsevier B.V. All rights reserved.	Kyungpook Natl Univ, Dept Comp Engn, Taegu 701702, South Korea	Park, SB (reprint author), Kyungpook Natl Univ, Dept Comp Engn, Taegu 701702, South Korea.	seongbae@knu.ac.kr					Abney S., 1999, P 1999 JOINT SIGDAT, P38; ARAUJO L, 2004, P 5 ANN C INT TEXT P, P81; Brill E, 1995, COMPUT LINGUIST, V21, P543; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Cohens W, 1995, P 12 INT C MACH LEAR, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2001, 0104 ILK TILB U; ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1023/A:1022699029236; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; KANG MY, 2004, P 17 INT C IND ENG A, P290; Kang S., 2000, J KISS, V27, P441; Kang SW, 2004, J MATER SCI-MATER EL, V15, P231, DOI 10.1023/B:JMSE.0000012460.03209.74; Khan MS, 2004, APPL SOFT COMPUT, V4, P423, DOI 10.1016/j.asoc.2004.02.003; KIM KS, 1998, J KISS, V25, P1838; Lawrence S, 2000, IEEE T KNOWL DATA EN, V12, P126, DOI 10.1109/69.842255; Lee D., 2002, P 3 WORKSH AS LANG R, P51; PARK SB, 2004, P 5 ANN C INT TEXT P, P146; PARK SB, 2003, P 41 ANN M ASS COMP, P497; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Quinlan R, 1993, C4 5 PROGRAMS MACHIN	22	2	2	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946			APPL SOFT COMPUT	Appl. Soft. Comput.	AUG	2006	6	4					406	416		10.1016/j.asoc.2005.11.006		11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	107KM	WOS:000242169800008		
J	Gilboa, I; Lieberman, O; Schmeidler, D				Gilboa, Itzhak; Lieberman, Offer; Schmeidler, David			Empirical similarity	REVIEW OF ECONOMICS AND STATISTICS			English	Article							DENSITY-FUNCTION; DECISION-THEORY	An agent is asked to assess a real-valued variable Y-p based on certain characteristics X-p = (X-p(1)..., X-p(m)), and on a database consisting of (X-i(1),..., X-i(m), Y-i) for i = 1,..., n. A possible approach to combine past observations of X and Y with the current values of X to generate an assessment of Y is similarity-weighted averaging. It suggests that the predicted value of Y, (Y) over bar (s)(p), be the weighted average of all previously P observed values Y-i, where the weight of Y-i for every i = 1,..., n, is the similarity between the vector X-p(1),....,X-p(m), associated with Y-p, and the previously observed vector, X-i(l),..., X-m(i). We axiomatize this rule. We assume that, given every database, a predictor has a ranking over possible values, and we show that certain reasonable conditions on these rankings imply that they are determined by the proximity to a similarity-weighted average for a certain similarity function. The axiontatization does not suggest a particular similarity function, or even a particular form of this function. We therefore proceed to suggest that the similarity function be estimated from past observations. We develop tools of statistical inference for parametric estimation of the similarity function, for the case of a continuous as well as a discrete variable. Finally, we discuss the relationship of the proposed method to other methods of estimation and prediction.	Tel Aviv Univ, IL-69978 Tel Aviv, Israel; Yale Univ, New Haven, CT 06520 USA; Tel Aviv Univ, HEC, IL-69978 Tel Aviv, Israel; Ohio State Univ, Columbus, OH 43210 USA	Gilboa, I (reprint author), Tel Aviv Univ, IL-69978 Tel Aviv, Israel.						Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; Billot A, 2005, ECONOMETRICA, V73, P1125, DOI 10.1111/j.1468-0262.2005.00611.x; BILLOT A, 2004, 1485 COWL FDN; CHANT D, 1974, BIOMETRIKA, V61, P291, DOI 10.1093/biomet/61.2.291; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1996, PROBABILISTIC THEORY; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 2149004 USAF SCH AV; Gayer G, 2004, 1493 COWL FDN; Gilboa I, 1997, ECON THEORY, V9, P47, DOI 10.1007/BF01213442; GILBOA I, 2001, THEORY CASE BASED DE; Gilboa I, 2003, ECONOMETRICA, V71, P1, DOI 10.1111/1468-0262.00388; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; Hume D., 1748, ENQUIRY HUMAN UNDERS; LIEBERMAN O, 2005, UNPUB ASYMPTOTIC THE; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Riesbeck C. K., 1989, INSIDE CASE BASED RE; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Schank R. G., 1986, EXPLANATION PATTERNS; Scott D.W., 1992, MULTIVARIATE DENSITY; Silverman BW, 1986, DENSITY ESTIMATION S	21	24	24	2	5	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0034-6535			REV ECON STAT	Rev. Econ. Stat.	AUG	2006	88	3					433	444		10.1162/rest.88.3.433		12	Economics; Social Sciences, Mathematical Methods	Business & Economics; Mathematical Methods In Social Sciences	095TG	WOS:000241330600002		
J	Moguerza, JM; Munoz, A				Moguerza, Javier M.; Munoz, Alberto			Support vector machines with applications	STATISTICAL SCIENCE			English	Article						support vector machines; kernel methods; regularization theory; classification; inverse problems	STATISTICAL PROPERTIES; CLASSIFICATION; NETWORKS; RECOGNITION; CLASSIFIERS; EQUATIONS	Support vector machines (SVMs) appeared in the early nineties as optimal margin classifiers in the context of Vapnik's statistical learning theory. Since then SVMs have been successfully applied to real-world data analysis problems, often providing improved results compared with other techniques. The SVMs operate within the framework of regularization theory by minimizing an empirical risk in a well-posed and consistent way. A clear advantage of the support vector approach is that sparse solutions to classification and regression problems are usually obtained: only a few samples are involved in the determination of the classification or regression functions. This fact facilitates the application of SVMs to problems that involve a large amount of data, such as text processing and bioinformatics tasks. This paper is intended as an introduction to SVMs and their applications, emphasizing their key features. In addition, some algorithmic extensions and illustrative real-world applications of SVMs are shown.	Univ Rey Juan Carlos, Sch Engn, Mostoles 28933, Spain; Univ Carlos III, Dept Stat, Getafe 28903, Spain	Moguerza, JM (reprint author), Univ Rey Juan Carlos, Sch Engn, C Tulipan S-N, Mostoles 28933, Spain.	javier.mogureza@urjc.es; alberto.munoz@uc3m.es					Aizerman M.A., 1964, AUTOMAT REM CONTR, V25, P821; Amari S., 1985, LECT NOTES STAT, V28; Aronszajn N., 1951, P S SPECTR THEOR DIF, P355; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337; Baeza-Yates R., 1999, MODERN INFORMATION R, V1st; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bazaraa M.S., 1993, NONLINEAR PROGRAMMIN; Ben-Hur A., 2001, J MACHINE LEARNING R, V2, P125; Bennett K. P., 2000, SIGKDD EXPLORATIONS, V2, P1; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Breiman L., 1984, CLASSIFICATION REGRE; Chen BJ, 2004, IEEE T POWER SYST, V19, P1821, DOI 10.1109/TPWRS.2004.835679; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; Cressie N., 1993, STAT SPATIAL DATA; Cucker F, 2002, B AM MATH SOC, V39, P1; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Green Peter J., 1999, ENCY STAT SCI, V3, P578; Hastie T, 2001, ELEMENTS STAT LEARNI; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Herbrich R., 2002, LEARNING KERNEL CLAS; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Ivanov V.V., 1976, THEORY APPROXIMATE M; Joachims T, 2002, LEARNING CLASSIFY TE; Kanwal R. P., 1983, GEN FUNCTIONS; KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Lanckriet G. R. G., 2002, P 19 INT C MACH LEAR, P323; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lin Y, 2002, MACH LEARN, V48, P115, DOI 10.1023/A:1013951620650; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; MARTIN I, 2004, LECT NOTES COMPUT SC, V3077, P102; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Moguerza JM, 2002, LECT NOTES COMPUT SC, V2415, P763; Moguerza JM, 2003, MATH PROGRAM, V95, P573, DOI 10.1007/s10107-002-0360-8; Mukherjee S, 2003, LECT NOTES STAT, V171, P111; MUKHERJEE S, 1999, 1653 MIT AI LAB; Muller KR, 1999, ADVANCES IN KERNEL METHODS, P243; Muller P, 1998, NEURAL COMPUT, V10, P749, DOI 10.1162/089976698300017737; Munoz A, 2003, LECT NOTES COMPUT SC, V2714, P217; Munoz A, 2006, IEEE T PATTERN ANAL, V28, P476, DOI 10.1109/TPAMI.2006.52; Munoz A, 2003, LECT NOTES ARTIF INT, V2774, P16; O'Sullivan F., 1986, STAT SCI, V1, P502, DOI 10.1214/ss/1177013525; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; OSUNA E, 1997, P IEEE WORKSH NEUR N, P276; OSUNA E, 1997, 144AI CBCL MIT AI LA; Pavlidis P., 2001, P 5 ANN INT C COMP B, P249, DOI DOI 10.1145/369133.369228; PHILLIPS DL, 1962, J ACM, V9, P84, DOI 10.1145/321105.321114; Platt JC, 2000, ADV NEUR IN, P61; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; POGGIO T, 2001, 198AI CBCL MIT AI LA; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; Ratsch G., 1999, NEURAL NETWORKS SIGN, V9, P41, DOI DOI 10.1109/NNSP.1999.788121; Rosipal R., 2001, J MACHINE LEARNING R, V2, P97; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Smola A.J., 1998, NEUROCOLT2 TECHNICAL; Sollich P, 2002, MACH LEARN, V46, P21, DOI 10.1023/A:1012489924661; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; van Kampen N. G., 1981, STOCHASTIC PROCESSES; VAPNIK VN, 1964, AUTOMAT REM CONTR+, V25, P103; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; WAHBA G, 1985, ANN STAT, V13, P1378, DOI 10.1214/aos/1176349743; Wahba G, 1990, SPLINE MODELS OBSERV; Wahba G., 1980, APPROXIMATION THEORY, P905; Wu S, 2002, NEURAL PROCESS LETT, V15, P59, DOI 10.1023/A:1013848912046	83	61	63	0	8	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0883-4237			STAT SCI	Stat. Sci.	AUG	2006	21	3					322	336		10.1214/088342306000000493		15	Statistics & Probability	Mathematics	130CG	WOS:000243776200003		
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Predicting eukaryotic protein subcellular location by fusing optimized evidence-theoretic K-Nearest Neighbor classifiers	JOURNAL OF PROTEOME RESEARCH			English	Article						cellular networking; organelle; gene ontology; amphiphilic pseudo amino acid composition; OET-KNN; fusion classifier; 25% sequence identity cutoff	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; GENE ONTOLOGY; STRUCTURAL CLASSES; SORTING SIGNALS; LOCALIZATION; CLASSIFICATION; REPRESENTATION; ALGORITHM; SEQUENCES	Facing the explosion of newly generated protein sequences in the post genomic era, we are challenged to develop an automated method for fast and reliably annotating their subcellular locations. Knowledge of subcellular locations of proteins can provide useful hints for revealing their functions and understanding how they interact with each other in cellular networking. Unfortunately, it is both expensive and time-consuming to determine the localization of an uncharacterized protein in a living cell purely based on experiments. To tackle the challenge, a novel hybridization classifier was developed by fusing many basic individual classifiers through a voting system. The "engine" of these basic classifiers was operated by the OET-KNN (Optimized Evidence-Theoretic K-Nearest Neighbor) rule. As a demonstration, predictions were performed with the fusion classifier for proteins among the following 16 localizations: (1) cell wall, (2) centriole, (3) chloroplast, (4) cyanelle, (5) cytoplasm, (6) cytoskeleton, (7) endoplasmic reticulum, (8) extracell, (9) Golgi apparatus, (10) lysosome, (11) mitochondria, (12) nucleus, (13) peroxisome, (14) plasma membrane, (15) plastid, and (16) vacuole. To get rid of redundancy and homology bias, none of the proteins investigated here had g25% sequence identity to any other in a same subcellular location. The overall success rates thus obtained via the jack-knife cross-validation test and independent dataset test were 81.6% and 83.7%, respectively, which were 46 similar to 63% higher than those performed by the other existing methods on the same benchmark datasets. Also, it is clearly elucidated that the overwhelmingly high success rates obtained by the fusion classifier is by no means a trivial utilization of the GO annotations as prone to be misinterpreted because there is a huge number of proteins with given accession numbers and the corresponding GO numbers, but their subcellular locations are still unknown, and that the percentage of proteins with GO annotations indicating their subcellular components is even less than the percentage of proteins with known subcellular location annotation in the Swiss- Prot database. It is anticipated that the powerful fusion classifier may also become a very useful high throughput tool in characterizing other attributes of proteins according to their sequences, such as enzyme class, membrane protein type, and nuclear receptor subfamily, among many others. A web server, called " Euk- OET- PLoc", has been designed at http:// 202.120.37.186/ bioinf/ euk- oet for public to predict subcellular locations of eukaryotic proteins by the fusion OET- KNN classifier.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Alberts B., 1994, MOL BIOL CELL; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Camon E, 2004, NUCLEIC ACIDS RES, V32, pD262, DOI 10.1093/nar/gkh021; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 1997, PROTEINS, V28, P99, DOI 10.1002/(SICI)1097-0134(199705)28:1<99::AID-PROT10>3.0.CO;2-C; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; CHOU KC, 1990, ACCOUNTS CHEM RES, V23, P134, DOI 10.1021/ar00173a003; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREIGHTON TE, 1990, BIOCHEM J, V270, P1; CREIGHTON TE, 1995, CURR BIOL, V5, P353, DOI 10.1016/S0960-9822(95)00070-4; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lee Vivian, 2005, In Silico Biology, V5, P5; LODISH H, 1995, MOL CELL BIOL, pCH3; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; PTITSYN OB, 1980, Q REV BIOPHYS, V13, P339; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Shafer G., 1976, MATH THEORY EVIDENCE; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	48	177	182	1	8	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893			J PROTEOME RES	J. Proteome Res.	AUG 4	2006	5	8					1888	1897		10.1021/pr060167c		10	Biochemical Research Methods	Biochemistry & Molecular Biology	070AW	WOS:000239493700008	16889410	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Hum-PLoc: A novel ensemble classifier for predicting human protein subcellular localization	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						cellular networking; organelle; gene ontology; amphiphilic pseudo amino acid composition; KNN; fusion 25% sequence identity cutoff	AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; SORTING SIGNALS; GENE ONTOLOGY; SEQUENCE; LOCATION	Predicting subcellular localization of human proteins is a challenging problem, especially when unknown query proteins do not have significant homology to proteins of known subcellular locations and when more locations need to be covered. To tackle the challenge, protein samples are expressed by hybridizing the gene ontology (GO) database and amphiphilic pseudo amino acid composition (PseAA). Based on such a representation frame, a novel ensemble classifier, called "Hum-PLoc", was developed by fusing many basic individual classifiers through a voting system. The "engine" of these basic classifiers was operated by the KNN (K-nearest neighbor) rule. As a demonstration, tests were performed with the ensemble classifier for human proteins among the following 12 locations: (1) centriole; (2) cytoplasm; (3) cytoskeleton; (4) endoplasmic reticulum; (5) extracell; (6) Golgi apparatus; (7) lysosome; (8) microsome; (9) mitochondrion; (10) nucleus; (11) peroxisome; (12) plasma membrane. To get rid of redundancy and homology bias, none of the proteins investigated here had >= 25% sequence identity to any other in a same subcellular location. The overall success rates thus obtained via the jackknife cross-validation test and independent dataset test were 81.1% and 85.0%, respectively, which are more than 50% higher than those obtained by the other existing methods on the same stringent datasets. Furthermore, an incisive and compelling analysis was given to elucidate that the overwhelmingly high success rate obtained by the new predictor is by no means due to a trivial utilization of the GO annotations. This is because, for those proteins with "subcellular location unknown" annotation in Swiss-Prot database, most (more than 99%) of their corresponding GO numbers in GO database are also annotated with "cellular component unknown". The information and clues for predicting subcellular locations of proteins are actually buried into a series of tedious GO numbers, just like they are buried into a pile of complicated amino acid sequences although with a different manner and "depth". To dig out the knowledge about their locations, a sophisticated operation engine is needed. And the current predictor is one of these kinds, and has proved to be a very powerful one. The Hum-PLoc classifier is available as a web-server at http://202.120.37.186/bioinf/hum. (c) 2006 Elsevier Inc. All rights reserved.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Alberts B., 1994, MOL BIOL CELL; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou P Y, 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Holm L, 1999, NUCLEIC ACIDS RES, V27, P244, DOI 10.1093/nar/27.1.244; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; LODISH H, 1995, MOL CELL BIOL, pCH3; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	34	195	201	1	6	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	AUG 18	2006	347	1					150	157		10.1016/j.bbrc.2006.06.059		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	065ZC	WOS:000239198000021	16808903	
J	Perez, A; Larranaga, P; Inza, I				Perez, Aritz; Larranaga, Pedro; Inza, Inaki			Supervised classification with conditional Gaussian networks: Increasing the structure complexity from naive Bayes	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						conditional Gaussian network; Bayesian network; naive Bayes; tree augmented naive Bayes; k-dependence Bayesian classifiers; semi naive Bayes; filter; wrapper	FEATURE SUBSET-SELECTION; CLASSIFIERS; VARIANCE; BIAS; KNOWLEDGE; RELEVANCE	Most of the Bayesian network-based classifiers are usually only able to handle discrete variables. However, most real-world domains involve continuous variables. A common practice to deal with continuous variables is to discretize them, with a subsequent loss of information. This work shows how discrete classifier induction algorithms can be adapted to the conditional Gaussian network paradigm to deal with continuous variables without discretizing them. In addition, three novel classifier induction algorithms and two new propositions about mutual information are introduced. The classifier induction algorithms presented are ordered and grouped according to their structural complexity: naive Bayes, tree augmented naive Bayes, k-dependence Bayesian classifiers and semi naive Bayes. All the classifier induction algorithms are empirically evaluated using predictive accuracy, and they are compared to linear discriminant analysis, as a continuous classic statistical benchmark classifier. Besides, the accuracies for a set of state-of-the-art classifiers are included in order to justify the use of linear discriminant analysis as the benchmark algorithm. In order to understand the behavior of the conditional Gaussian network-based classifiers better, the results include bias-variance decomposition of the expected misclassification rate. The study suggests that semi naive Bayes structure based classifiers and, especially, the novel wrapper condensed semi naive Bayes backward, outperform the behavior of the rest of the presented classifiers. They also obtain quite competitive results compared to the state-of-the-art algorithms included. (c) 2006 Elsevier Inc. All rights reserved.	Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, San Sebastian 20080, Spain	Perez, A (reprint author), Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, POB 649, San Sebastian 20080, Spain.	aritz@si.ehu.es; ccplamup@si.ehu.es; inza@si.ehu.es	Larranaga, Pedro/F-9293-2013				ANDERSON FW, 1958, INTRO MULTIVARIATE S; BOTTCHER SG, 2004, THESIS ALLBORG U; Castillo E., 1997, EXPERT SYSTEMS PROBA; Cheng J., 1999, P 15 C UNC ART INT U, P101; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Groot Morris, 1970, OPTIMAL STAT DECISIO; Domingos P., 2000, P 17 INT C MACH LEAR, P231; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R. O., 1973, PATTERN CLASSIFICATI; Dudewicz EJ, 1988, MODERN MATH STAT; EGMONTPETERSON M, 2004, P JOINT IAPR WORKSH, P1034; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher RA, 1936, ANN EUGENIC, V7, P179; Frank E., 2005, DATA MINING PRACTICA; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FRIEDMAN N, 1998, P 15 NAT C MACH LEAR; Geiger D., 1994, LEARNING GAUSSIAN NE; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; German S., 1992, NEURAL COMPUT, V4, P1; Giudici P, 1999, BIOMETRIKA, V86, P785, DOI 10.1093/biomet/86.4.785; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Grossman D., 2004, P 21 INT C MACH LEAR; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M.A., 1997, P 4 INT C NEUR INF P, P855; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Jebara Tony, 2001, THESIS MIT; John G.H., 1995, P 11 C UNC ART INT, P338; Johnson R, 2002, APPL MULTIVARIATE ST; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Keogh E., 1999, P 7 INT WORKSH ART I, P225; KOHAVI R, 1995, THESIS COMPUTER SCI; KOHAVI R, 1996, INT C MACH LEARN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononerko I., 1991, P 6 EUR WORK SESS LE, P206; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; Lauritzen S. L., 1996, GRAPHICAL MODELS; LAURITZEN SL, 1984, F848 AALB U I EL SYS; LAURITZEN SL, 1989, ANN STAT, V17; Liu H., 1998, FEATURE SELECTION KN; Lozano J. A., 2002, ESTIMATION DISTRIBUT; Minsky M., 1961, T I RADIO ENG, V49, P8; Murphy PM, 1995, UCI REPOSITORY MACHI; Neapolitan R. E., 2003, LEARNING BAYESIAN NE; PAZZANI M, 1997, LEARNING DATA ARTIFI, V5, P239; Pearl J, 1988, PROBABILISTIC REASON; Pernkopf F., 2005, P 22 INT C MACH LEAR; Pernkopf F, 2005, PATTERN RECOGN, V38, P1, DOI 10.1016/j.patcog.2004.05.012; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Raina R., 2003, ADV NEURAL INFORM PR, V16; Rosenblatt F., 1959, PRINCIPLES NEURODYNA; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; SNTAFE G, 2005, P 8 EUR C SYMB QUANT, P148; Van der Putten P, 2004, MACH LEARN, V57, P177, DOI 10.1023/B:MACH.0000035476.95130.99; WANG H, 1996, THESIS U ULSTER; Wang H, 1999, IEEE T PATTERN ANAL, V21, P271; YANG Y, 2003, 2003131 MON U SCH CO; Yu L, 2004, J MACH LEARN RES, V5, P1205	64	20	22	1	3	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X			INT J APPROX REASON	Int. J. Approx. Reasoning	SEP	2006	43	1					1	25		10.1016/j.ijar.2006.01.002		25	Computer Science, Artificial Intelligence	Computer Science	079MR	WOS:000240181200001		
J	Zhen, L; Zhong, J				Zhen Lou; Zhong Jin			A novel adaptive hit-distance for pattern recognition	CHINESE JOURNAL OF ELECTRONICS			English	Article						biomimetic pattern recognition; machine learning; nearest neighbor classifier; hit-distance; pattern recognition	FACE RECOGNITION; NEAREST; CLASSIFICATION; CLASSIFIERS	The better the matter is understood, the better the distance between any given point and the matter subspace can be defined, and vice verse. In this paper, a novel idea of distance, Hit-Distance, was proposed to generalize the representational capacity of available prototypes. It is more reasonable to utilize the proposed hit-distance to describe the distance between any given point and any matter subspace. The effectiveness of the proposed distance was indirectly evaluated by some experiments of matter classifications. Experiments were performed on 8 benchmark datasets from the UCI Machine Learning Repository. It was shown that the hit-distance based classifiers performed much better than the classical nearest neighbor classifier (NN), the Nearest feature line method (NFL) and the Nearest feature plane method (NFP).	Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China; Univ Autonoma Barcelona, Ctr Visio Computador, E-08193 Barcelona, Spain	Zhen, L (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.						Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freedman D, 2002, IEEE T PATTERN ANAL, V24, P1349, DOI 10.1109/TPAMI.2002.1039206; Fukunaga K., 1990, INTRO STAT PATTERN R; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Newman D., 1998, UCI REPOSITORY MACHI; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; WANG SJ, 2005, INT C NEUR NETW BRAI, V3, P1487; Wang Shou-jue, 2002, Acta Electronica Sinica, V30; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	10	0	0	2	5	TECHNOLOGY EXCHANGE LIMITED HONG KONG	SHATIN	26-28 AU PUI WAN ST, STE 1102, FO TAN INDUSTRIAL CENTRE, FO TAN, SHATIN, 00000, PEOPLES R CHINA	1022-4653			CHINESE J ELECTRON	Chin. J. Electron.	OCT	2006	15	4A					793	796				4	Engineering, Electrical & Electronic	Engineering	103XJ	WOS:000241920200006		
J	Tahir, MA; Bouridane, A				Tahir, Muhammad Atif; Bouridane, Ahmed			Novel round-robin tabu search algorithm for prostate cancer classification and diagnosis using multispectral imagery	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						feature selection; multispectral images; nearest neighbor (1NN) classifier; prostate cancer diagnosis; round-robin (RR) classification; tabu search (TS)	FEATURE-SELECTION; GENETIC ALGORITHMS; CHROMATIN TEXTURE; CARCINOMA; FEATURES; ADENOCARCINOMA; CLASSIFIERS; BIOPSY; TISSUE	Quantitative cell imagery in cancer pathology has progressed greatly in the last 25 years. The application areas are mainly those in which the diagnosis is still critically reliant upon the analysis of biopsy samples, which remains the only conclusive method for making an accurate diagnosis of the disease. Biopsies are usually analyzed by a trained pathologist who, by analyzing the biopsies under a microscope, assesses the normality or malignancy of the samples submitted. Different grades of malignancy correspond to different structural patterns as well as to apparent textures. In the case Of prostate cancer, four major groups have to be recognized: stroma, benign prostatic hyperplasia, prostatic intraepithelial neoplasia, and prostatic carcinoma. Recently, multispectral imagery has been used to solve this multiclass problem. Unlike conventional RGB color space, multispectral images allow the acquisition of a large number of spectral bands within the visible spectrum, resulting in a large feature vector size. For such a high dimensionality, pattern recognition techniques suffer from the well-known "curse-of-dimensionality" problem. This paper proposes a novel round-robin tabu search (RR-TS) algorithm to address the curse-of-dimensionality for this multiclass problem. The experiments have been carried out on a number of prostate cancer textured multispectral images, and the results obtained have been assessed and compared with previously reported works. The system achieved 98%-100% classification accuracy when testing on two datasets. It outperformed principal component/linear discriminant classifier (PCA-LDA), tabu search/nearest neighbor classifier (TS-1NN), and bagging/boosting with decision tree (C4.5) classifier.	Univ W England, Fac Comp Engn & Math Sci, Bristol BS16 1QY, Avon, England; Queens Univ Belfast, Sch Elect Elect & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland	Tahir, MA (reprint author), Univ W England, Fac Comp Engn & Math Sci, Bristol BS16 1QY, Avon, England.	muhammad.tahir@uwe.ac.uk; a.bouridane@qub.ac.uk					Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; Barshack I, 1999, BRIT J CANCER, V79, P1613, DOI 10.1038/sj.bjc.6690257; Bartels PH, 1998, ANAL QUANT CYTOL, V20, P389; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHRISTEN R, 1993, ANAL QUANT CYTOL, V15, P383; Clark GA, 2000, IEEE T GEOSCI REMOTE, V38, P304, DOI 10.1109/36.823923; CLARK TD, 1987, PROSTATE, V10, P199, DOI 10.1002/pros.2990100303; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Davies S., 1994, P 1994 AAAI FALL S R, P37; Duda R O, 2001, PATTERN CLASSIFICATI; EBLE JN, 1996, UROLOGIC SURG PATHOL; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Fukunaga K., 1990, INTRO STAT PATTERN R; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Glover F., 1989, ORSA Journal on Computing, V1; Glover F., 1990, ORSA Journal on Computing, V2; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jimenez LO, 1998, IEEE T SYST MAN CY C, V28, P39, DOI 10.1109/5326.661089; KHAN SA, 2002, ENG APPL ARTIF INTEL, P327; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; LARSH P, 2002, TECHNOL CANCER RES T, V1, P1; Liu Y., 2002, P INT C INT INF TECH, P169; MINIMO C, 1994, ANAL QUANT CYTOL, V16, P307; MOHLER JL, 1994, ANAL QUANT CYTOL, V16, P415; PITTS DE, 1993, P SPIE MED IMAGING P, P456; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Roula M., 2002, P IEEE INT S BIOM IM, p193 , DOI 10.1109/ISBI.2002.1029226; ROULA MA, 2003, P 7 INT S SIGN PROC, P37; SAIT SM, 2000, ITERATIVE COMPUTER A; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Tahir MA, 2004, INT C PATT RECOG, P335, DOI 10.1109/ICPR.2004.1334201; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tibshirani R, 1993, INTRO BOOTSTRAP; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; YONGGUANG B, LECT NOTES COMPUTER, V3177; Yu SX, 2002, PATTERN RECOGN LETT, V23, P183, DOI 10.1016/S0167-8655(01)00118-0; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2; Zimmerman HJ, 1996, FUZZY SET THEORY ITS	45	10	11	0	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771			IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	OCT	2006	10	4					782	793		10.1109/TITB.2006.879596		12	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	092VH	WOS:000241124900016	17044412	
J	Ghosh, AK; Chaudhuri, P; Murthy, CA				Ghosh, Anil K.; Chaudhuri, Probal; Murthy, C. A.			Multiscale classification using nearest neighbor density estimates	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						bootstrap; cross validation; misclassification rate; multiscale analysis; posterior probability; p-value; weighted averaging	SCALE-SPACE; VISUALIZATION; CLASSIFIERS; VIEW	Density estimates based on k-nearest neighbors have useful applications in nonparametric discriminant analysis. In classification problems, optimal values of k are usually estimated by minimizing the cross-validated misclassification rates. However, these cross-validation techniques allow only one value of k for each population density estimate, while in a classification problem, the optimum value of k for a class may also depend on its competing population densities. Further, it is computationally difficult to minimize the cross-validated error rate when there are several competing populations. Moreover, in addition to depending on the entire training data set, a good choice of k should also depend on the specific observation to be classified. Therefore, instead of using a single value of k for each population density estimate, it is more useful in practice to consider the results for multiple values of k to arrive at the final decision. This paper presents one such approach along with a graphical device, which gives more information about classification results for various choices of k and the related statistical uncertainties present there. The utility of this proposed methodology has been illustrated I using some benchmark data sets.	Australian Natl Univ, Inst Math Sci, Ctr Math & Its Applicat, Canberra, ACT 0200, Australia; Indian Stat Inst, Theoret Stat & Math Univ, Kolkata 700108, India; Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India	Ghosh, AK (reprint author), Australian Natl Univ, Inst Math Sci, Ctr Math & Its Applicat, Canberra, ACT 0200, Australia.	anilkghosh@rediffmail.com; probal@isical.ac.in; murthy@isical.ac.in					Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Chaudhuri P, 2000, ANN STAT, V28, P408; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, DISCRIMINATORY ANAL, P261; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J., 1996, ANOTHER APPROACH POL; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Ghosh AK, 2006, TECHNOMETRICS, V48, P120, DOI 10.1198/004017005000000391; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; Gilks WR, 1996, MARKOV CHAIN MONTE C; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; Hastie T, 1998, ANN STAT, V26, P451; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Johnson R., 1992, APPL MULTIVARIATE ST, V3th; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; McCullagh P., 1989, GEN LINEAR MODELS; Newman D., 1998, UCI REPOSITORY MACHI; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Ripley BD, 1996, PATTERN RECOGNITION; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scott D.W., 1992, MULTIVARIATE DENSITY; Serfling R. S., 1980, APPROXIMATION THEORE; SHALAK DB, 1996, THESIS U MASSACHUSET; Silverman BW, 1986, DENSITY ESTIMATION S; STONE M, 1977, BIOMETRIKA, V64, P29; Tibshirani R, 1993, INTRO BOOTSTRAP; Yager RR, 2002, IEEE T SYST MAN CY B, V32, P512, DOI 10.1109/TSMCB.2002.1018770; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	34	5	12	0	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419	1941-0492		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2006	36	5					1139	1148		10.1109/TSMCB.2006.873186		10	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	087QI	WOS:000240756700014	17036819	
J	Chang, F; Lin, CC; Lu, CJ				Chang, Fu; Lin, Chin-Chin; Lu, Chi-Jen			Adaptive prototype learning algorithms: Theoretical and experimental studies	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						adaptive prototype learning; cluster-based prototypes; consistency; instance-based prototype; pattern classification	ORDERED RISK MINIMIZATION; SUPPORT VECTOR MACHINES; REGRESSION; CLASSIFICATION	In this paper, we propose a number of adaptive prototype learning (APL) algorithms. They employ the same algorithmic scheme to determine the number and location of prototypes, but differ in the use of samples or the weighted averages of samples as prototypes, and also in the assumption of distance measures. To understand these algorithms from a theoretical viewpoint, we address their convergence properties, as well as their consistency under certain conditions. We also present a soft version of APL, in which a non-zero training error is allowed in order to enhance the generalization power of the resultant classifier. Applying the proposed algorithms to twelve UCI benchmark data sets, we demonstrate that they outperform many instance-based learning algorithms, the k-nearest neighbor rule, and support vector machines in terms of average test accuracy.	Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan; Natl Taipei Univ Technol, Dept Elect Engn, Taipei, Taiwan	Chang, F (reprint author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.	FCHANG@IIS.SINICE.EDU.TW; ERIKSON@IIS.SINICA.EDU.TW; CJLU@IIS.SINICA.EDU.TW					Bartlett P., 1999, ADV KERNEL METHODS S; Bezdek J. C., 1981, PATTERN RECOGNITION; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cortes C., 1995, MACH LEARN, V20, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devi VS, 2002, PATTERN RECOGN, V35, P505; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Devroye L., 1996, PROBABILISTIC THEORY; Devroye L., 1985, NONPARAMETRIC DENSIT; Fix E., 1952, 11 USAF SCH AV MED; Fix E., 1951, 4 USAF SCH AV MED; FIX E, 1991, NEAREST NEIGHBOR PAT; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hoppner F., 1999, FUZZY CLUSTER ANAL M; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Kim DW, 2005, PATTERN RECOGN, V38, P607, DOI 10.1016/j.patchog.2004.09.006; Knerr S., 1990, NEUROCOMPUTING ALGOR; KOHONEN T, 1990, ADVANCED NEURAL COMPUTERS, P137; Kohonen T., 1988, SELF ORG ASS MEMORY; LINDE Y, 1980, PATTERN RECOGN, V19, P84; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; MAX J, 1960, IRE T INFORM THEOR, V6, P7, DOI 10.1109/TIT.1960.1057548; Mercer T, 1909, PHILOS T R SOC A, V209, P415; Newman D., 1998, UCI REPOSITORY MACHI; Platt JC, 2000, ADV NEUR IN, V12, P547; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Scholkopf B., 1999, ADV KERNEL METHODS S; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; VAPNIK VN, 1974, AUTOMAT REM CONTR+, V35, P1403; VAPNIK VN, 1974, AUTOMAT REM CONTR+, V35, P1226; Vapnik V. N., 1995, NATURE STAT LEARNING; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wu Z., 2003, 5 INT C COMP INT MUL, P1; ZHAO LC, 1987, J MULTIVARIATE ANAL, V21, P168, DOI 10.1016/0047-259X(87)90105-9	38	11	13	0	3	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	OCT	2006	7						2125	2148				24	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152VQ	WOS:000245390500007		
J	Model, D; Zibulevsky, M				Model, Dmitri; Zibulevsky, Michael			Learning subject-specific spatial and temporal filters for single-trial EEG classification	NEUROIMAGE			English	Article						EEG; brain-computer interface; classification; spatial filters	HAND MOVEMENT; DISCRIMINATION; COMPETITION; DEVICE	There are a wide variety of electroencephalography (EEG) analysis methods. Most of them are based on averaging over multiple trials in order to increase signal-to-noise ratio. The method introduced in this article is a single trial method. Our approach is based on the assumption that the "response of interest" to each task is smooth, and is contained in several sensor channels. We propose a two-stage preprocessing method. In the first stage, we apply spatial filtering by taking weighted linear combinations of the sensor measurements. In the second stage, we perform time-domain filtering. In both steps, we derive filters that maximize a class dissimilarity measure subject to regularizing constraints on the total variation of the average estimated signal (or, alternatively, on the signal's strength in time intervals where it is known to be absent). No other spatial or spectral assumptions with regard to the anatomy or sources were made. (c) 2006 Elsevier Inc. All rights reserved.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Model, D (reprint author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	dmm@tx.technion.ac.il; mzib@ee.technion.ac.il					Anderson CW, 1998, IEEE T BIO-MED ENG, V45, P277, DOI 10.1109/10.661153; Berger H, 1929, ARCH PSYCHIAT NERVEN, V87, P527, DOI 10.1007/BF01797193; Bigman ZB, 2004, BIOL PSYCHOL, V66, P99, DOI 10.1016/j.biopsycho.2003.10.003; Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581; Blankertz B, 2002, ADV NEUR IN, V14, P157; Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chen Y, 1998, NONCON OPTIM ITS APP, V20, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; DUIN RP, 2000, PROTOOLS PATTERN REC; KALCHER J, 1996, MED BIOL ENG COMPUT, V34, P383; Kubler A, 1999, EXP BRAIN RES, V124, P223, DOI 10.1007/s002210050617; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; Muller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8; Obermaier B, 2001, IEEE T NEUR SYS REH, V9, P283, DOI 10.1109/7333.948456; Parra L, 2002, NEUROIMAGE, V17, P223, DOI 10.1006/nimg.2002.1212; Pfurtscheller G, 1997, ELECTROEN CLIN NEURO, V103, P642, DOI 10.1016/S0013-4694(97)00080-1; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Sajda P, 2003, IEEE T NEUR SYS REH, V11, P184, DOI 10.1109/TNSRE.2003.814453; VIDAL J, 1973, ANNU REV BIOPHYS BIO, P157; Wolpaw J. R., 1991, CLIN NEUROPHYSIOL, V78, P252, DOI 10.1016/0013-4694(91)90040-B; WOLPAW JR, 1997, CLIN NEUROPHYSIOL, V146, P529; Zibulevsky M, 2002, NEUROCOMPUTING, V49, P163, DOI 10.1016/S0925-2312(02)00515-5	24	8	9	0	1	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119			NEUROIMAGE	Neuroimage	OCT 1	2006	32	4					1631	1641		10.1016/j.neuroimage.2006.04.224		11	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	090RR	WOS:000240969200012	16828316	
J	Vijaya, PA; Murty, MN; Subramanian, DK				Vijaya, P. A.; Murty, M. Narasimha; Subramanian, D. K.			Efficient median based clustering and classification techniques for protein sequences	PATTERN ANALYSIS AND APPLICATIONS			English	Article						clustering; protein sequences; median strings; sequences; set median; prototypes; feature selection; classification accuracy	STRUCTURE PREDICTION; SECONDARY STRUCTURE; DATABASE; ALGORITHM; STRINGS; SEARCH	In this paper, an efficient K-medians clustering (unsupervised) algorithm for prototype selection and Supervised K-medians (SKM) classification technique for protein sequences are presented. For sequence data sets, a median string/sequence can be used as the cluster/group representative. In K-medians clustering technique, a desired number of clusters, K, each represented by a median string/sequence, is generated and these median sequences are used as prototypes for classifying the new/test sequence whereas in SKM classification technique, median sequence in each group/class of labelled protein sequences is determined and the set of median sequences is used as prototypes for classification purpose. It is found that the K-medians clustering technique outperforms the leader based technique and also SKM classification technique performs better than that of motifs based approach for the data sets used. We further use a simple technique to reduce time and space requirements during protein sequence clustering and classification. During training and testing phase, the similarity score value between a pair of sequences is determined by selecting a portion of the sequence instead of the entire sequence. It is like selecting a subset of features for sequence data sets. The experimental results of the proposed method on K-medians, SKM and Nearest Neighbour Classifier (NNC) techniques show that the Classification Accuracy (CA) using the prototypes generated/used does not degrade much but the training and testing time are reduced significantly. Thus the experimental results indicate that the similarity score does not need to be calculated by considering the entire length of the sequence for achieving a good CA. Even space requirement is reduced during both training and classification.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Vijaya, PA (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	pav@csa.iisc.ernet.in; mnm@csa.iisc.ernet.in; dks@csa.iisc.ernet.in					Bandyopadhyay S, 2005, FUZZY SET SYST, V152, P5, DOI 10.1016/j.fss.2004.10.011; Bolten E, 2001, BIOINFORMATICS, V17, P935, DOI 10.1093/bioinformatics/17.10.935; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Durbin R., 1998, BIOL SEQUENCE ANAL; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; Guralnik V., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989516; Hamamoto Y, 1996, IEEE T PATTERN ANAL, V18, P571, DOI 10.1109/34.494648; HAN E, 1997, P DAT MIN KNOWL DISC; HENIKOFF S, 1994, GENOMICS, V19, P97, DOI 10.1006/geno.1994.1018; HUANG XQ, 1991, ADV APPL MATH, V12, P337, DOI 10.1016/0196-8858(91)90017-D; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31; Kaufman L., 1990, FINDING GROUPS DATA; Knuth D. E., 1998, ART COMPUTER PROGRAM, V3; KOHONEN T, 1985, PATTERN RECOGN LETT, V3, P309, DOI 10.1016/0167-8655(85)90061-3; KRAUSE A, 2002, THESIS BERLIN; Kriventseva EV, 2001, NUCLEIC ACIDS RES, V29, P33, DOI 10.1093/nar/29.1.33; Lo Conte L, 2000, NUCLEIC ACIDS RES, V28, P257, DOI 10.1093/nar/28.1.257; Martinez-Hinarejos CD, 2003, PATTERN RECOGN LETT, V24, P173, DOI 10.1016/S0167-8655(02)00209-X; MCA L, 1996, PATTERN RECOGN LETT, V17, P731; MICA L, 1994, PATTERN RECOGN LETT, V15, P9; Mitra S., 2003, DATA MINING MULTIMED; MORENO F, 2003, PATTERN RECOGN LETT, V22, P1145; Mount D. W., 2002, BIOINFORMATICS SEQUE; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770; Pal S. K., 2004, PATTERN RECOGNITION; PEARSON W, 1999, FASTA PROGRAM PACKAG; PETER C, 2000, COMPUTATIONAL MOL BI; PUJARI A, 2000, DATA MINING TECHNIQU; Ramasubramanian V, 2000, PATTERN RECOGN, V33, P1497, DOI 10.1016/S0031-3203(99)00134-X; Sahni S., 1998, DATA STRUCTURES ALGO; SALZBERG S, 1992, J MOL BIOL, V227, P371, DOI 10.1016/0022-2836(92)90892-N; SCHUTZE H, 2004, SINGLE LINK COMPLETE; Sharan R., 2000, Proceedings. Eighth International Conference on Intelligent Systems for Molecular Biology; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Somervuo P., 2000, P 3 INT C DISC SCI, P76; Spath H., 1980, CLUSTER ANAL ALGORIT; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; VIJAYA PA, 2004, P 17 INT C PATT REC, V2, P447; VIJAYA PA, 2003, P IEEE TENCON AS PAC, P409; VIJAYA PA, 2003, P 5 ICAPR, P129; Vijayalakshmi R, 2001, HYDROMETALLURGY, V61, P75, DOI 10.1016/S0304-386X(00)00159-6; WANG J, 1994, ELECTROANAL, V6, P571, DOI 10.1002/elan.1140060707; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; Yona G, 2000, NUCLEIC ACIDS RES, V28, P49, DOI 10.1093/nar/28.1.49	47	5	5	0	16	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541			PATTERN ANAL APPL	Pattern Anal. Appl.	OCT	2006	9	2-3					243	255		10.1007/s10044-006-0040-z		13	Computer Science, Artificial Intelligence	Computer Science	088SH	WOS:000240830900010		
J	Lozano, M; Sotoca, JM; Sanchez, JS; Pla, F; Pekalska, E; Duin, RPW				Lozano, M.; Sotoca, J. M.; Sanchez, J. S.; Pla, F.; Pekalska, E.; Duin, R. P. W.			Experimental study on prototype optimisation algorithms for prototype-based classification in vector spaces	PATTERN RECOGNITION			English	Article						dissimilarity representation; prototype selection; adaptive condensing; EM algorithm; normal density based classifier; nearest neighbour rule	DISSIMILARITY-BASED CLASSIFICATION; LEARNING ALGORITHMS; CLASSIFIERS; NEIGHBORHOOD; SELECTION	Prototype-based classification relies on the distances between the examples to be classified and carefully chosen prototypes. A small set of prototypes is of interest to keep the computational complexity low, while maintaining high classification accuracy. An experimental study of some old and new prototype optimisation techniques is presented, in which the prototypes are either selected or generated from the given data. These condensing techniques are evaluated on real data, represented in vector spaces, by comparing their resulting reduction rates and classification performance. Usually the determination of prototypes is studied in relation with the nearest neighbour rule. We will show that the use of more general dissimilarity-based classifiers can be more beneficial. An important point in our study is that the adaptive condensing schemes here discussed allow the user to choose the number of prototypes freely according to the needs. If such techniques are combined with linear dissimilarity-based classifiers, they provide the best trade-off of small condensed sets and high classification accuracy. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Juame 1, Dept Lenguajes & Sistemas Informat, Castellon de La Plana 12071, Spain; Delft Univ Technol, Fac Elect Engn Math & Comp Sci, NL-2628 CD Delft, Netherlands; Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England	Lozano, M (reprint author), Univ Juame 1, Dept Lenguajes & Sistemas Informat, Campus Riu Sec, Castellon de La Plana 12071, Spain.	lozano@uji.es; sotoca@uji.es; sanchez@uji.es; pla@uji.es; e.m.pekalska@tudelft.nl; r.p.w.duin@ieee.org		Sanchez Garreta, Jose Salvador/0000-0003-1053-4658			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AINSLIE MC, 2002, 2 WORKSH INT COLL AS, P13; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P11, DOI 10.1016/0167-8655(95)00093-3; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1990, NORMS NN PATTERN CLA; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R O, 2001, PATTERN CLASSIFICATI; Duin RPW, 2004, PR TOOLS MATLAB TOOL; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Hart P.E, 1968, IEEE T INFORMATION T, V14, P505; Kohonen T., 1995, SELF ORG MAPS; KOHONEN T, 1996, LVQ PAK LEARNING VEC; Lozano M, 2004, FR ART INT, V113, P225; LOZANO M, 2004, LECT NOTES ARTIF INT, V3040, P618; McLachlan G. J., 1988, MIXTURE MODELS INFER; McLachlan G J, 1997, EM ALGORITHM EXTENSI; Merz C, 1998, UCI REPOSITORY MACHI; Novovicova J, 1996, IEEE T PATTERN ANAL, V18, P218, DOI 10.1109/34.481557; PACLIK P, 2003, CLASSIFYING SPECTRAL; Paclik P, 2003, REAL-TIME IMAGING, V9, P237, DOI 10.1016/j.rti.2003.09.002; Pekalska E, 2005, SER MACH PERCEPT ART, V64, P1, DOI 10.1142/9789812703170; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Pekalska E, 2004, LECT NOTES COMPUT SC, V3138, P1145; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOUSSAINT GT, 1985, COMPUTER SCI STAT IN; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	35	36	36	1	3	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	OCT	2006	39	10					1827	1838		10.1016/j.patcog.2006.04.005		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	069UV	WOS:000239475000003		
J	Chindaro, S; Sirlantzis, K; Fairhurst, MC				Chindaro, S.; Sirlantzis, K.; Fairhurst, M. C.			ICA-based multi-colour space texture classification system	ELECTRONICS LETTERS			English	Article							FUSION	Presented is a novel method which uses independent component analysis (ICA) for systematically partitioning and combining textural features extracted from different colour spaces, in a multiple classifier based system, for colour texture classification. Results obtained illustrate that the proposed ICA-based feature-partitioning and classifier combination system produces more accurate results compared to a system that combines classifiers applied to features extracted from individual colour spaces.	Univ Kent, Dept Elect, Canterbury CT2 7NT, Kent, England	Chindaro, S (reprint author), Univ Kent, Dept Elect, Canterbury CT2 7NT, Kent, England.	S.Chindaro@kent.ac.uk					Chindaro S, 2005, ELECTRON LETT, V41, P589, DOI 10.1049/el:20050594; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duin R.P.W., 2004, PRTOOLS4 MATLAB TOOL; Fairhurst MC, 2000, IEE P-VIS IMAGE SIGN, V147, P39, DOI 10.1049/ip-vis:20000105; HAVARINEN A, 2001, INDEPENDENT COMPONEN; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; Sangwine SJ, 1998, COLOUR IMAGE PROCESS; Skurichina M, 2005, LECT NOTES COMPUT SC, V3541, P165	9	2	2	1	4	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	0013-5194			ELECTRON LETT	Electron. Lett.	OCT 12	2006	42	21					1208	1210		10.1049/el:20062197		3	Engineering, Electrical & Electronic	Engineering	108IL	WOS:000242233400011		
J	Viswanath, P; Murty, MN; Bhatnagar, S				Viswanath, P.; Murty, M. Narasimha; Bhatnagar, Shalabh			Partition based pattern synthesis technique with efficient algorithms for nearest neighbor classification	PATTERN RECOGNITION LETTERS			English	Article						nearest neighbor classifier; pattern synthesis; artificial patterns; curse of dimensionality	ERROR RATE ESTIMATION; BOOTSTRAP; CLASSIFIERS; FEATURES	Nearest neighbor (NN) classifier is a popular non-parametric classifier. It is conceptually a simple classifier and shows good performance. Due to the curse of dimensionality effect, the size of training set needed by it to achieve a given classification accuracy becomes prohibitively large when the dimensionality of the data is high. Generating artificial patterns can reduce this effect. In this paper, we propose a novel pattern synthesis method called partition based pattern synthesis which can generate an artificial training set of exponential order when compared with that of the given original training set. We also propose suitable faster NN based methods to work with the synthetic training patterns. Theoretically, the relationship between our methods and conventional NN methods is established. The computational requirements of our methods are also theoretically established. Experimental results show that NN based classifiers with synthetic training set can outperform conventional NN classifiers and some other related classifiers. (c) 2006 Elsevier B.V. All rights reserved.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India; Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India	Bhatnagar, S (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	viswanath@iitg.ernet.in; mnm@csa.iisc.ernet.in; shalabh@csa.iisc.ernet.in					Ananthanarayana VS, 2001, PATTERN RECOGN, V34, P2249, DOI 10.1016/S0031-3203(01)00028-0; Babu TR, 2005, LECT NOTES COMPUT SC, V3776, P595; Babu TR, 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fix E., 1952, 11 USAF SCH AV MED; Fix E., 1951, 4 USAF SCH AV MED; FODOR IK, 2002, UCRLID148494 L LIV N; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jain A. K., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Murphy P. M., 1994, UCI REPOSITORY MACHI; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516	21	10	10	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	OCT 15	2006	27	14					1714	1724		10.1016/j.patrec.2006.04.015		11	Computer Science, Artificial Intelligence	Computer Science	085ZP	WOS:000240643200014		
J	Ho, MC; Lin, JJ; Chen, CN; Chen, CC; Lee, H; Yang, CY; Ni, YH; Chang, KJ; Hsu, HC; Hsieh, FJ; Lee, PH				Ho, Ming-Chih; Lin, Jen-Jen; Chen, Chiung-Nien; Chen, Chaur-Chin; Lee, Hsinyu; Yang, Ching-Yao; Ni, Yen-Hsuan; Chang, King-Jen; Hsu, Hey-Chi; Hsieh, Fon-Jou; Lee, Po-Huang			A gene expression profile for vascular invasion can predict the recurrence after resection of hepatocellular carcinoma: A microarray approach	ANNALS OF SURGICAL ONCOLOGY			English	Article						hepatocellular carcinoma; microarray; gene expression; profiling; vascular invasion; liver resection; recurrence	FETOPROTEIN MESSENGER-RNA; PROGNOSTIC-FACTORS; CDNA MICROARRAY; INTRAHEPATIC RECURRENCE; MULTIVARIATE-ANALYSIS; CURATIVE RESECTION; TUMOR-GROWTH; CANCER RISK; LIVER; METASTASIS	Background: Recurrence after hepatocellular carcinoma (HCC) resection is the major obstacle to improved survival. The presence of vascular invasion (VI) in pathology specimens is a well-known unfavorable prognostic factor for HCC recurrence. Though some VI-related genes have been reported, their association with recurrence-free survival is not known. We hypothesized that a gene expression profile for VI can predict the recurrence of HCC after liver resection. Methods: Eighteen patients receiving complete HCC resection were included as a "training group". Genome-wide gene expression profile was obtained for each tumor using a microarray technique. Datasets were subjected to clustering analysis supervised by the presence or absence of VI to obtain 14 discriminative genes. We then applied those genes to execute pattern recognition using the k-Nearest Neighbor (KNN) classification method, and the best model for this VI gene signature to predict recurrence-free survival in the training group was obtained. The resulting model was then tested in an independent "test group" of 35 patients. Results: A 14-gene profile was extracted which could accurately separate ten patients with VI and eight patients without VI in the "training group". In the "test group", significant difference in disease-free survival was found between patients predicted to have and not to have recurrence (P = .02823). In patients with stage_1 disease, this model can also predict outcomes (P = .000205). Conclusions: Using the 14-gene expression profile extracted from microarrays based on the presence of VI can effectively predict recurrence after HCC resection. This approach might facilitate "personalized medicine" for HCC patients after surgical resection.	Natl Taiwan Univ Hosp, Dept Surg, Taipei 100, Taiwan; Natl Taiwan Univ, Angiogenesis Res Ctr, Taipei 10764, Taiwan; Ming Chuan Univ, Dept Appl Stat & Informat Sci, Taipei, Taiwan; Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30043, Taiwan; Natl Taiwan Univ, Dept Life Sci, Taipei 10764, Taiwan; Natl Taiwan Univ Hosp, Dept Pediat, Taipei 10016, Taiwan; Natl Taiwan Univ Hosp, Dept Pathol, Taipei 100, Taiwan; Natl Taiwan Univ Hosp, Dept Obstet & Gynecol, Taipei 100, Taiwan	Lee, PH (reprint author), Natl Taiwan Univ Hosp, Dept Surg, 7 Chung Shan S Rd, Taipei 100, Taiwan.	pohuang@ha.mc.ntu.edu.tw		Ni, Yen-Hsuan/0000-0002-1158-5249; YANG, CHING-YAO/0000-0001-6312-3719; LEE, PO-HUANG/0000-0001-5831-035X			BARBARA L, 1992, HEPATOLOGY, V16, P132, DOI 10.1002/hep.1840160122; Chakraborty A, 2004, UROLOGY, V63, P177, DOI 10.1016/S0090-4295(03)00786-6; Chen X, 2002, MOL BIOL CELL, V13, P1929, DOI 10.1091/mbc.02-02-0023; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deli G, 2005, WORLD J GASTROENTERO, V11, P960; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; ESNAOLA N, 2003, ANN SURG, V238, P7119; Fan ST, 1999, ANN SURG, V229, P322, DOI 10.1097/00000658-199903000-00004; Fukuda S, 2005, HEPATO-GASTROENTEROL, V52, P1163; Hanazaki K, 2001, AM J GASTROENTEROL, V96, P1243; Hermanek P, 1993, TNM S; Hernandez-Rodriguez NA, 1999, LUNG CANCER-J IASLC, V26, P157, DOI 10.1016/S0169-5002(99)00077-X; Honda M, 2001, GASTROENTEROLOGY, V120, P955, DOI 10.1053/gast.2001.22468; Hsu C, 2003, ONCOLOGY-BASEL, V65, P242, DOI 10.1159/000074477; Iizuka N, 2003, LANCET, V361, P923, DOI 10.1016/S0140-6736(03)12775-4; Ijichi M, 2002, HEPATOLOGY, V35, P853, DOI 10.1053/jhep.2002.32100; Ikai Iwao, 2003, Surg Oncol Clin N Am, V12, P65, DOI 10.1016/S1055-3207(02)00082-0; Imamura H, 2003, ARCH SURG-CHICAGO, V138, P1198, DOI 10.1001/archsurg.138.11.1198; Imamura H, 2003, J HEPATOL, V38, P200, DOI 10.1016/S0168-8278(02)00360-4; Jaeck Daniel, 2004, Liver Transpl, V10, pS58, DOI 10.1002/lt.20041; Kaneko S, 2002, ONCOLOGY-BASEL, V62, P69, DOI 10.1159/000048279; Kim IJ, 2004, HUM GENET, V115, P498, DOI 10.1007/s00439-004-1186-7; Macoska JA, 2002, CA-CANCER J CLIN, V52, P50; Mathew J, 1996, J PATHOL, V179, P74; Mengus G, 2005, EMBO J, V24, P2753, DOI 10.1038/sj.emboj.7600748; Mou DC, 2002, BRIT J CANCER, V86, P110, DOI 10.1038/sj.bjc.6600016; Mukunyadzi P, 2003, APPL IMMUNOHISTO M M, V11, P334; NIERODZIK MLR, 1992, CANCER RES, V52, P3267; Okabe H, 2001, CANCER RES, V61, P2129; Palumbo JS, 2001, HAEMOSTASIS, V31, P11; Park J, 2004, PHARMACOGENETICS, V14, P103, DOI 10.1097/01.fpc.0000054153.92680.a3; Park NH, 2001, J CLIN GASTROENTEROL, V33, P397, DOI 10.1097/00004836-200111000-00011; Patt YZ, 2000, AM J CLIN ONCOL-CANC, V23, P319, DOI 10.1097/00000421-200006000-00023; Patt YZ, 2003, J CLIN ONCOL, V21, P421, DOI 10.1200/JCO.2003.10.103; Shirota Y, 2001, HEPATOLOGY, V33, P832, DOI 10.1053/jhep.2001.23003; Sudo T, 2005, BRIT J CANCER, V92, P1754, DOI 10.1038/sj.bjc.6602531; Sun HC, 2003, WORLD J GASTROENTERO, V9, P635; Suzuki K, 1999, INT J ONCOL, V15, P1227; Tackels-Horne D, 2001, CANCER, V92, P395, DOI 10.1002/1097-0142(20010715)92:2<395::AID-CNCR1335>3.0.CO;2-U; Tahara K, 1999, CANCER, V85, P1234, DOI 10.1002/(SICI)1097-0142(19990315)85:6<1234::AID-CNCR4>3.0.CO;2-7; Tamhane A., 1987, MULTIPLE COMP PROCED; Tseng GC, 2001, NUCLEIC ACIDS RES, V29, P2549, DOI 10.1093/nar/29.12.2549; Tsukino H, 2004, CANCER SCI, V95, P977, DOI 10.1111/j.1349-7006.2004.tb03186.x; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vauthey JN, 2002, J CLIN ONCOL, V20, P1527, DOI 10.1200/JCO.20.6.1527; Waguri N, 2003, CLIN CANCER RES, V9, P3004; Westfall Peter H., 1993, RESAMPLING BASED MUL; Wilkens Ludwig, 2002, J Hepatobiliary Pancreat Surg, V9, P304, DOI 10.1007/s005340200034; Witzigmann H, 2002, SURGERY, V131, P34, DOI 10.1067/msy.2002.118954; Xia JL, 1997, J CANCER RES CLIN, V123, P383, DOI 10.1007/s004320050075; Xu L, 2001, CANCER RES, V61, P3176; Xu XR, 2001, P NATL ACAD SCI USA, V98, P15089, DOI 10.1073/pnas.241522398; Yamanaka J, 2000, J GASTROEN HEPATOL, V15, P1192, DOI 10.1046/j.1440-1746.2000.02323.x; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15	54	38	40	0	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1068-9265			ANN SURG ONCOL	Ann. Surg. Oncol.	NOV	2006	13	11					1474	1484		10.1245/s10434-006-9057-1		11	Oncology; Surgery	Oncology; Surgery	116KY	WOS:000242803000017	17009164	
J	Kapil, A; Gudi, RD; Noronha, SB				Kapil, Ankur; Gudi, Ravindra D.; Noronha, Santosh B.			Gene expression profile analysis using discrimination and fuzzy classification methods	ASIA-PACIFIC JOURNAL OF CHEMICAL ENGINEERING			English	Article						microarray; dimensionality; fuzzy simulator; classification	PATTERNS	There is a huge incentive for gene expression analysis and identification of biologically meaningful clusters from microarray data. However, the high dimensionality of the data poses challenges for this task. Here, to reduce this problem of irrelevant dimensions, we consider three different projection methods, viz. principal components analysis (PCA), correspondence analysis (CA), and multiple discriminant analysis (DA). To account for the possibility of pleiotropy, where the expression of certain genes may be related to more than one phenotypical condition, we use fuzzy clustering on the lower dimensional space generated by PCA, CA, and DA. Fuzzy clustering permits partial belonging of an attribute, such as gene expression, to different functionalities and hence is eminently suited for this task. To determine the optimum number of clusters, we evaluate various cluster validity indices. In this paper, we compare these methodologies when applied to the data generated by a genetic network simulator (eXPatGen) and also to the experimental micro array data available for yeast S. cerevisiae. (C) 2006 Curtin University of Technology and John Wiley & Sons, Ltd.	[Kapil, Ankur; Gudi, Ravindra D.; Noronha, Santosh B.] Indian Inst Technol, Dept Chem Engn, Bombay 400076, Maharashtra, India	Gudi, RD (reprint author), Indian Inst Technol, Dept Chem Engn, Bombay 400076, Maharashtra, India.	ravigudi@che.iitb.ac.in					Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Azuaje F., 2002, UNDERSTANDING USING; Babuska Robert, 2001, FUZZY NEURAL CONTROL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fellenberg K, 2001, P NATL ACAD SCI USA, V98, P10781, DOI 10.1073/pnas.181597298; Fischer R.A., 1936, ANN EUGEN, V7, P179; FODOR SPA, 1993, NATURE, V364, P555, DOI 10.1038/364555a0; Gasch AP, 2002, GENOME BIOL, V3; Greenacre M.J, 1993, CORRESPONDENCE ANAL; JAIN A, 1999, ACM COMPUT SURV, V31, P267; KAO KC, 2003, P NATL ACAD SCI USA, V100, P15522; KRESTA JV, 1991, CAN J CHEM ENG, V69, P35; Michaud DJ, 2003, BIOINFORMATICS, V19, P1140, DOI 10.1093/bioinformatics/btg132; Park HS, 2004, LECT NOTES ARTIF INT, V3157, P967; PAVLIDIS P, 2001, P BIOKDD 2001 WORKSH, P15; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Vapnik V., 1998, STAT LEARNING THEORY; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhao LP, 2001, P NATL ACAD SCI USA, V98, P5631, DOI 10.1073/pnas.101013198	20	0	0	0	0	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1932-2143			ASIA-PAC J CHEM ENG	Asia-Pac. J. Chem. Eng.	NOV-DEC	2006	1	1-2					110	121		10.1002/apj.012		12	Engineering, Chemical	Engineering	290NB	WOS:000255128400014		
J	Plaza, E; Ontanon, S				Plaza, Enric; Ontanon, Santiago			Learning collaboration strategies for committees of learning agents	AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS			English	Article						multi-agent learning; committees; meta learning; case based reasoning		A main issue in cooperation in multi-agent systems is how an agent decides in which situations is better to cooperate with other agents, and with which agents does the agent cooperate. Specifically in this paper we focus on multi-agent systems composed of learning agents, where the goal of the agents is to achieve a high accuracy on predicting the correct solution of the problems they encounter. For that purpose, when encountering a new problem each agent has to decide whether to solve it individually or to ask other agents for collaboration. We will see that learning agents can collaborate forming committees in order to improve performance. Moreover, in this paper we will present a proactive learning approach that will allow the agents to learn when to convene a committee and with which agents to invite to join the committee. Our experiments show that learning results in smaller committees while maintaining (and sometimes improving) the problem solving accuracy than forming committees composed of all agents.	CSIC, Artificial Intelligence Res Inst, IIIA, Spanish Counsel Sci Res, Bellaterra 08193, Catalonia, Spain	Ontanon, S (reprint author), Univ Barcelona, Dept Appl Math, MAiA, Gran Via 585, E-08007 Barcelona, Spain.	enric@iiia.csic.es; santi@iiia.csic.es					Aha D. W., 1997, LAZY LEARNING; AAMODT A, 1994, AI COMMUN, V7, P39; Brams S., 1983, APPROVAL VOTING; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CESTNIK B, 1991, LECT NOTES ARTIF INT, V482, P151; Chan P., 1995, P 12 INT C MACH LEAR, P90; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIGNUM F, 2001, LECT NOTES COMPUTER, P150; Dutta P. S., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems; ESTEVA M, 2001, LNAI, V1991; ESTEVA M, IN PRESS INTELLIGENT, V8; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GAMA J, 1998, P 15 INT C MACH LEAR, P206; GOMEZ M, 2004, P 3 INT JOINT C AUT, P144; Leake D. B., 2002, P 15 FLAIRS C MENL P, P106; LEAKE DB, 2001, ICCBR, P321; Mc Ginty L, 2001, LECT NOTES ARTIF INT, V2080, P362; Ontanon S, 2002, LECT NOTES ARTIF INT, V2430, P331; ONTANON S, 2005, P 22 INT C MACH LEAR, P633, DOI 10.1145/1102351.1102431; Ontanon S., 2005, THESIS U AUTONOMA BA; ONTANON S, 2003, INT C MACH LEARN, P576; ONTANON S, 2006, IN PRESS P AAMAS 06; ONTANON S, 2002, 1 INT JOINT C AUT AG; Ontanon S, 2003, LECT NOTES ARTIF INT, V2689, P392; Perrone M. P., 1993, ARTIFICIAL NEURAL NE; Plaza E, 2001, LECT NOTES ARTIF INT, V2080, P437; Plaza E, 2003, LECT NOTES ARTIF INT, V2636, P1; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Wolpert D. H., 1990, LAUR903460; Wooldridge M. J., 1994, P MOD AUT AG MULT AG, P15	31	5	5	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1387-2532			AUTON AGENT MULTI-AG	Auton. Agents Multi-Agent Syst.	NOV	2006	13	3					429	461		10.1007/s10458-006-0015-x		33	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	081KM	WOS:000240316500006		
J	Joseph, A; Fenton, NE; Neil, M				Joseph, A.; Fenton, N. E.; Neil, M.			Predicting football results using Bayesian nets and other machine learning techniques	KNOWLEDGE-BASED SYSTEMS			English	Article						Bayesian nets; machine learning; football		Bayesian networks (BNs) provide a means for representing, displaying, and making available in a usable form the knowledge of experts in a given field. In this paper, we look at the performance of an expert constructed BN compared with other machine learning (ML) techniques for predicting the outcome (win, lose, or draw) of matches played by Tottenham Hotspur Football Club. The period under study was 1995-1997 - the expert BN was constructed at the start of that period, based almost exclusively on subjective judgement. Our objective was to determine retrospectively the comparative accuracy of the expert BN compared to some alternative ML models that were built using data from the two-year period. The additional ML techniques considered were: MC4, a decision tree learner; Naive Bayesian learner; Data Driven Bayesian (a BN whose structure and node probability tables are learnt entirely from data); and a K-nearest neighbour learner. The results show that the expert BN is generally superior to the other techniques for this domain in predictive accuracy. The results are even more impressive for BNs given that, in a number of key respects, the study assumptions place them at a disadvantage. For example, we have assumed that the BN prediction is 'incorrect' if a BN predicts more than one outcome as equally most likely (whereas, in fact, such a prediction would prove valuable to somebody who could place an 'each way' bet on the outcome). Although the expert BN has now long been irrelevant (since it contains variables relating to key players who have retired or left the club) the results here tend to confirm the excellent potential of BNs when they are built by a reliable domain expert. The ability to provide accurate predictions without requiring much learning data are an obvious bonus in any domain where data are scarce. Moreover, the BN was relatively simple for the expert to build and its structure could be used again in this and similar types of problems. (c) 2006 Elsevier B.V. All rights reserved.	Univ London Queen Mary Coll, Comp Sci Dept, London, England	Joseph, A (reprint author), Univ London Queen Mary Coll, Comp Sci Dept, London, England.	adrianj@dcs.qmul.ac.uk; norman@dcs.qmul.ac.uk; martin@dcs.qmul.ac.uk		Fenton, Norman/0000-0003-2924-0510			BRADLEY A, 1994, AUSTR NZ C INT INF S, P37; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FENTON NE, 2000, B IMA, V36, P180; FENTON NE, 2002, IEEE SOFTWARE, V10, P116; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; JOSEPH A, 2005, PREDICTING FOOTBALL; KOHAVI R, 1996, MLC MACHINE LEARNING; MITCHELL TM, 1997, MACHINE LEARNIGN; NEIL M, 2001, IEE COMPUTING CONTRO, V12, P11; Pearl J, 1988, PROBABILISTIC REASON; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RUE H, 1997, PREDICTION RETROSPEC, V10	12	8	8	1	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	NOV	2006	19	7					544	553		10.1016/j.knosys.2006.04.011		10	Computer Science, Artificial Intelligence	Computer Science	113ZQ	WOS:000242636900011		
J	Huang, CC				Huang, Chi-Chun			A novel gray-based reduced NN classification method	PATTERN RECOGNITION			English	Article						gray-based reduced NN classification method; instance pruning; gray relational structure; instance-based learning; pattern classification	NEAREST-NEIGHBOR RULE; PATTERN-CLASSIFICATION; LEARNING ALGORITHMS; PROTOTYPES; ABSTRACTION; PERFORMANCE; CLASSIFIERS; REDUCTION	In pattern recognition, instance-based learning (also known as nearest neighbor rule) has become increasingly popular and can yield excellent performance. In instance-based learning, however, the storage of training set rises along with the number of training instances. Moreover, in such a case, a new, unseen instance takes a long time to classify because all training instances have to be considered when determining the 'nearness' or 'similarity' among instances. This study presents a novel reduced classification method for instance-based learning based on the gray relational structure. Here, only some training instances in the original training set are adopted for the pattern classification tasks. The relationships among instances are first determined according to the gray relational structure. In the relational structure, the inward edoes of each training instance, indicating how many times each instance is considered as the nearest neighbor or neighbors in determining the class labels of other instances can be obtained. This method excludes training instances with no or few inward edges for the pattern classification tasks. By using the proposed instance pruning approach, new instances can be classified with a few training instances. Nine data sets are adopted to demonstrate the performance of the proposed learning approach. Experimental results indicate that the classification accuracy can be maintained when most of the training instances are pruned before learning. Additionally, the number of remained training instances in the proposal presented here is comparable to that of other existing instance pruning techniques. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan	Huang, CC (reprint author), Natl Kaohsiung Marine Univ, Dept Informat Management, 142 Hai Jhuan Rd,Nanzih Dist, Kaohsiung 811, Taiwan.	cchuang@mail.nkmu.edu.tw					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Arshadi N, 2005, IEEE T KNOWL DATA EN, V17, P1127, DOI 10.1109/TKDE.2005.124; Blake C, 1998, UCI REPOSITORY MACHI; BRODER AZ, 1985, IEEE T SYST MAN CYB, V15, P136; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy B. V., 1990, NEAREST NEIGHBOR NN; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; DASARATHY BV, 2000, P 15 INT C PATT REC, P2692; Deng Julong, 1989, Journal of Grey Systems, V1; Deng J., 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; EICK C, 2004, P 4 INT C DAT MIN, P375; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; FIX E, 1951, 2149004 USAF SCH AVI; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; HUANG CC, IN PRESS APPL INTELL; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Lam W, 2002, PATTERN RECOGN, V35, P1491, DOI 10.1016/S0031-3203(01)00131-5; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; LEFEVRE F, 1999, P EUROSPEECH 99, P2733; LIN CT, 1999, J GREY SYSTEM, V4, P359; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SANCHEZ JS, 2004, P INT C SYST MAN CYB, P4757; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE M, 1974, J R STAT SOC B, V36, P111; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhang J., 1992, P 9 INT MACH LEARN C, P470; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	43	6	6	1	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	NOV	2006	39	11					1979	1986		10.1016/j.patcog.2006.05.013		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	079DU	WOS:000240156500003		
J	Gao, QB; Wang, ZZ				Gao, Qing-Bin; Wang, Zheng-Zhi			Classification of G-protein coupled receptors at four levels	PROTEIN ENGINEERING DESIGN & SELECTION			English	Article							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINE; STRUCTURAL CLASS PREDICTION; SECONDARY STRUCTURE-CONTENT; FAST FOURIER-TRANSFORM; SUBCELLULAR LOCATION; HYBRIDIZATION SPACE; PSEAA PREDICTOR; GENE ONTOLOGY; SEQUENCES	G-protein coupled receptors (GPCRs) are transmembrane proteins which via G-proteins initiate some of the important signaling pathways in a cell and are involved in various physiological processes. Thus, computational prediction and classification of GPCRs can supply significant information for the development of novel drugs in pharmaceutical industry. In this paper, a nearest neighbor method has been introduced to discriminate GPCRs from non-GPCRs and subsequently classify GPCRs at four levels on the basis of amino acid composition and dipeptide composition of proteins. Its performance is evaluated on a non-redundant dataset consisted of 1406 GPCRs for six families and 1406 globular proteins using the jackknife test. The present method based on amino acid composition achieved an overall accuracy of 96.4% and Matthew's correlation coefficient (MCC) of 0.930 for correctly picking out the GPCRs from globular proteins. The overall accuracy and MCC were further enhanced to 99.8% and 0.996 by dipeptide composition-based method. On the other hand, the present method has successfully classified 1406 GPCRs into six families with an overall accuracy of 89.6 and 98.8% using amino acid composition and dipeptide composition, respectively. For the subfamily prediction of 1181 GPCRs of rhodopsin-like family, the present method achieved an overall accuracy of 76.7 and 94.5% based on the amino acid composition and dipeptide composition, respectively. Finally, GPCRs belonging to the amine subfamily and olfactory subfamily of rhodopsin-like family were further analyzed at the type level. The overall accuracy of dipeptide composition-based method for the classification of amine type and olfactory type of GPCRs reached 94.5 and 86.9%, respectively, while the overall accuracy of amino acid composition-based method was very low for both subfamilies. In comparison with existing methods in the literature, the present method also displayed great competitiveness. These results demonstrate the effectiveness of our method on identifying and classifying GPCRs correctly. GPCRsIdentifier, a corresponding stand-alone executable program for GPCR identification and classification was also developed, which can be acquired freely on request from the authors for academic purposes.	Natl Univ Def Technol, Inst Automat, Changsha 410073, Hunan, Peoples R China	Gao, QB (reprint author), Natl Univ Def Technol, Inst Automat, Changsha 410073, Hunan, Peoples R China.	qbgao@nudt.edu.cn	Gao, Qing-Bin/G-9825-2011				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; BALDWIN JM, 1994, CURR OPIN CELL BIOL, V6, P180, DOI 10.1016/0955-0674(94)90134-1; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bhasin M, 2005, NUCLEIC ACIDS RES, V33, pW143, DOI 10.1093/nar/gki351; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW383, DOI 10.1093/nar/gkh416; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; Chou KC, 2004, BIOCHEM BIOPH RES CO, V325, P506, DOI 10.1016/j.bbrc.2004.10.058; Chou KC, 2005, J PROTEOME RES, V4, P1681, DOI 10.1021/pr050145a; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2005, BIOCHEM BIOPH RES CO, V327, P845, DOI 10.1016/j.bbrc.2004.12.069; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; Chou KC, 2006, J PROTEOME RES, V5, P316, DOI 10.1021/pr050331g; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2005, J PROTEOME RES, V4, P1413, DOI 10.1021/pr050087t; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Guo YZ, 2005, ACTA BIOCH BIOPH SIN, V37, P759, DOI 10.1111/j.1745-7270.2005.00110.x; Horn F, 2003, NUCLEIC ACIDS RES, V31, P294, DOI 10.1093/nar/gkg103; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, COMPUT BIOL CHEM, V28, P275, DOI 10.1016/j.compbiolchem.2004.08.001; Inoue Y, 2004, COMPUT BIOL CHEM, V28, P39, DOI 10.1016/j.compbiolchem.2003.11.003; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Kim S, 2004, BIOINFORMATICS, V20, P40, DOI 10.1093/bioinformatics/btg368; Lapinsh M, 2002, PROTEIN SCI, V11, P795, DOI 10.1110/ps.2500102; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; Mardia K. V., 1979, MULTIVARIATE ANAL; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Papasaikas PK, 2004, NUCLEIC ACIDS RES, V32, pW380, DOI 10.1093/nar/gkh431; Pearson W R, 2000, Methods Mol Biol, V132, P185; Qian B, 2003, FEBS LETT, V554, P95, DOI 10.1016/S0014-5793(03)01112-8; Sadowski MI, 2003, BIOINFORMATICS, V19, P727, DOI 10.1093/bioinformatics/btg075; SPIEGEL AM, 1992, ENDOCR REV, V13, P536, DOI 10.1210/er.13.3.536; STRADER CD, 1994, ANNU REV BIOCHEM, V63, P101, DOI 10.1146/annurev.biochem.63.1.101; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Teller DC, 2001, BIOCHEMISTRY-US, V40, P7761, DOI 10.1021/bi0155091; Vaidehi N, 2002, P NATL ACAD SCI USA, V99, P12622, DOI 10.1073/pnas.122357199; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Xiao ZJ, 2006, LEUKEMIA RES, V30, P54, DOI 10.1016/j.leukres.2005.05.012; Yabuki Y, 2005, NUCLEIC ACIDS RES, V33, pW148, DOI 10.1093/nar/gki; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	56	64	64	1	5	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1741-0126			PROTEIN ENG DES SEL	Protein Eng. Des. Sel.	NOV	2006	19	11					511	516		10.1093/protein/gzl038		6	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	097DE	WOS:000241426000005	17032692	
J	Tripathi, S; Srinivas, VV; Nanjundiah, RS				Tripathi, Shivam; Srinivas, V. V.; Nanjundiah, Ravi S.			Dowinscaling of precipitation for climate change scenarios: A support vector machine approach	JOURNAL OF HYDROLOGY			English	Review						precipitation; downscaling; climate change; general circulation model (GCM); support vector machine; neural network; hydroclimatology; India	ARTIFICIAL NEURAL-NETWORKS; GENERAL-CIRCULATION MODEL; REGIONAL FLOOD FREQUENCY; INDIAN MONSOON RAINFALL; SENSITIVITY ANALYSIS; LOCAL PRECIPITATION; DOWNSCALING METHODS; CLUSTER-ANALYSIS; NEW-ZEALAND; GCM OUTPUT	The Climate impact studies in hydrology often rely on climate change information at fine spatial resolution. However, general circulation models (GCMs), which are among the most advanced tools for estimating future climate change scenarios, operate on a coarse scale. Therefore the output from a GCM has to be downscaled to obtain the information relevant to hydrologic studies. In this paper, a support vector machine (SVM) approach is proposed for statistical downscaling of precipitation at monthly time scale. The effectiveness of this approach is illustrated through its application to meteorological sub-divisions (MSDs) in India. First, climate variables affecting spatio-temporal variation of precipitation at each MSD in India are identified. Following this, the data pertaining to the identified climate variables (predictors) at each MSD are classified using cluster analysis to form two groups, representing wet and dry seasons. For each MSD, SVM-based downscaling model (DM) is developed for season(s) with significant rainfall using principal components extracted from the predictors as input and the contemporaneous precipitation observed at the MSD as an output. The proposed DM is shown to be superior to conventional downscaling using multi-layer back-propagation artificial neural networks. Subsequently, the SVM-based DM is applied to future climate predictions from the second generation Coupled Global Climate Model (CGCM2) to obtain future projections of precipitation for the MSDs. The results are then analyzed to assess the impact of climate change on precipitation over India. It is shown that SVMs provide a promising alternative to conventional artificial neural networks for statistical downscaling, and are suitable for conducting climate impact studies. (c) 2006 Elsevier B.V. All rights reserved.	Indian Inst Sci, Dept Civil Engn, Bangalore 560012, Karnataka, India; Indian Inst Sci, Ctr Atmospher & Ocean Sci, Bangalore 560012, Karnataka, India	Srinivas, VV (reprint author), Indian Inst Sci, Dept Civil Engn, Bangalore 560012, Karnataka, India.	vvs@civit.iisc.ernet.in					Arnell NW, 2003, J GEOPHYS RES-ATMOS, V108, DOI 10.1029/2002JD002782; ASCE, 2000, J HYDROL ENG, P124, DOI [10.1061/(ASCE)1084-0699(2000)5:2(124), DOI 10.1061/(ASCE)1084-0699(2000)5:2(124)]; ASCE Task Committee, 2000, J HYDROL ENG, V5, P115, DOI DOI 10.1061/(ASCE)1084-0699(2000)5:2(115); Asefa T, 2004, WATER RESOUR RES, V40, DOI 10.1029/2004WR003304; Schwenk H, 2000, NEURAL COMPUT, V12, P1869, DOI 10.1162/089976600300015178; BHASKAR NR, 1989, J WATER RES PL-ASCE, V115, P793; Bianchini M, 1996, NEUROCOMPUTING, V13, P313, DOI 10.1016/0925-2312(95)00032-1; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bouraoui F, 1999, CLIM DYNAM, V15, P153, DOI 10.1007/s003820050274; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buma J, 2000, CLIMATE RES, V15, P69, DOI 10.3354/cr015069; BURN DH, 1989, J WATER RES PL-ASCE, V115, P567; Cannon AJ, 2002, J HYDROL, V259, P136, DOI 10.1016/S0022-1694(01)00581-9; Cannon AJ, 2002, INT J CLIMATOL, V22, P1687, DOI 10.1002/joc.811; Cavazos T, 1997, INT J CLIMATOL, V17, P1069, DOI 10.1002/(SICI)1097-0088(199708)17:10<1069::AID-JOC183>3.0.CO;2-I; CHHABARA BM, 1999, ADV TECHNOLOGIES MET, pCH5; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crane RG, 2002, HUM ECOL RISK ASSESS, V8, P147, DOI 10.1080/20028091056782; Crane RG, 1998, INT J CLIMATOL, V18, P65, DOI 10.1002/(SICI)1097-0088(199801)18:1<65::AID-JOC222>3.0.CO;2-9; CRISTIANININ, 2000, INTRO SUPPORT VECTOR; Dibike YB, 2001, J COMPUT CIVIL ENG, V15, P208, DOI 10.1061/(ASCE)0887-3801(2001)15:3(208); Faucher M, 1999, CLIMATE RES, V11, P173, DOI 10.3354/cr011173; Feng XT, 2004, INT J NUMER ANAL MET, V28, P1141, DOI 10.1002/nag.381; FIX E, 1951, 2149004 US AIR FORC, P261; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Georgakakos KP, 2001, J GEOPHYS RES-ATMOS, V106, P27367, DOI 10.1029/2001JD900125; Gestel T. V., 2004, MACH LEARN, V54, P5; GOVINDARAJU S, 2000, ARTIFICIAL NEURAL NE, P329; Hassan H, 1998, WATER SCI TECHNOL, V37, P177, DOI 10.1016/S0273-1223(98)00022-5; Haupt R. L., 2004, PRACTICAL GENETIC AL, P253; Haykin S., 2003, NEURAL NETWORKS COMP, P842; Hernandez-Espinosa C, 2004, LECT NOTES COMPUT SC, V3213, P677; Hewitson BC, 1996, CLIMATE RES, V7, P85, DOI 10.3354/cr007085; HEWITSON BC, 1992, GEOPHYS RES LETT, V19, P1835, DOI 10.1029/92GL01423; Hush DR, 1993, IEEE SIGNAL PROC MAG, V10, P8, DOI 10.1109/79.180705; Jasper K, 2004, CLIMATE RES, V26, P113, DOI 10.3354/cr026113; Kailas SV, 2000, CURR SCI INDIA, V78, P592; Kalnay E, 1996, B AM METEOROL SOC, V77, P437, DOI 10.1175/1520-0477(1996)077<0437:TNYRP>2.0.CO;2; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Kettle H, 2004, CLIMATE RES, V26, P97, DOI 10.3354/cr026097; Khadam IM, 2004, WATER RESOUR RES, V40, DOI 10.1029/2003WR002939; Kim MK, 2004, INT J CLIMATOL, V24, P777, DOI 10.1002/joc.1029; Kottegoda N.T., 1998, STAT PROBABILITY REL; LAL M, 1995, CURR SCI INDIA, V69, P752; Leggett J, 1992, CLIMATE CHANGE 1992; LIN HT, 2003, STUD SIGMOID KERNELS; LISTER R, 1995, P IEEE INT C NEUR NE, P237; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; MAINI P, 2004, J HYDROL, V228, P170; Mangasarian OL, 1999, IEEE T NEURAL NETWOR, V10, P1032, DOI 10.1109/72.788643; McCarthy J.J., 2001, CLIMATE CHANGE 2001; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Meireles MRG, 2003, IEEE T IND ELECTRON, V50, P585, DOI 10.1109/TIE.2003.812470; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Misson L, 2002, AGR FOREST METEOROL, V111, P265, DOI 10.1016/S0168-1923(02)00039-4; Mpelasoka FS, 2001, INT J CLIMATOL, V21, P1415, DOI 10.1002/joc.617; Neocleous C, 2002, LECT NOTES ARTIF INT, V2308, P300; *NRC, 1998, DEC TO CENT SCAL CLI; Olsson J, 2004, J HYDROL ENG, V9, P1, DOI 10.1061/(ASCE)1084-0699(2004)9:1(1); Osborn TJ, 1997, J CLIMATE, V10, P1885, DOI 10.1175/1520-0442(1997)010<1885:DOARBS>2.0.CO;2; Pai PF, 2005, ELECTR POW SYST RES, V74, P417, DOI 10.1016/j.epsr.2005.01.006; PARTHASARATHY B, 1994, THEOR APPL CLIMATOL, V49, P217, DOI 10.1007/BF00867461; PARTHASARATHY B, 1993, P INDIAN AS-EARTH, V102, P121; Pasquariello G, 2002, INT GEOSCI REMOTE SE, P509; Poulton MM, 2002, GEOPHYSICS, V67, P979, DOI 10.1190/1.1484539; Rupa Kumar K., 1994, Geophysical Research Letters, V21; Rupa Kumar K., 1992, International Journal of Climatology, V12; Sailor DJ, 2000, RENEW ENERG, V19, P359, DOI 10.1016/S0960-1481(99)00056-7; Sastry P. S., 2003, COMPUTING INFORM SCI; Schmidt M, 2003, CLIM RES, V25, P135, DOI 10.3354/cr025135; SCHOLKOPF B, 1998, ADV KERNAL METHODS S; Schoof JT, 2001, INT J CLIMATOL, V21, P773, DOI 10.1002/joc.655; Shannon DA, 1996, S AFR J SCI, V92, P213; SHARMA C, 2003, P YEAR END WORKSH CL, P61; SHIVAM T, 2004, DOWNSCALING GEN CIRC; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Snell SE, 2000, J CLIMATE, V13, P886, DOI 10.1175/1520-0442(2000)013<0886:SIOSAT>2.0.CO;2; Solecki WD, 2004, J ENVIRON MANAGE, V72, P105, DOI 10.1016/j.jenvman.2004.03.014; STONE JV, 1994, P IEEE INT C NEUR NE, P84; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; SUYKENS JAK, 2001, P IEEE INSTR MEAS TE, P287; Tatli H, 2004, INT J CLIMATOL, V24, P161, DOI 10.1002/joc.997; Trigo RM, 1999, CLIMATE RES, V13, P45, DOI 10.3354/cr013045; Turing A, 1950, MIND, V59, P433; Vapnik V. N., 1995, NATURE STAT LEARNING; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; VAPNIK V, 1992, ADV NEUR IN, V4, P831; VAPNIK VN, 1998, STAT LEARNIN THEORY; Weisse R, 2001, CLIMATE RES, V16, P123, DOI 10.3354/cr016123; Wilby RL, 1997, PROG PHYS GEOG, V21, P530, DOI 10.1177/030913339702100403; Wilby RL, 1998, WATER RESOUR RES, V34, P2995, DOI 10.1029/98WR02577; WILBY RL, 1998, J HYDROL, V213, P380; Wilby RL, 2004, GUIDELINES USE CLIMA; Wilby RL, 2000, INT J CLIMATOL, V20, P641, DOI 10.1002/(SICI)1097-0088(200005)20:6<641::AID-JOC501>3.0.CO;2-1; WILLMOTT CJ, 1985, AM CARTOGRAPHER, V12, P5; WILTSHIRE SE, 1986, HYDROLOG SCI J, V31, P335, DOI 10.1080/02626668609491052; Winkler JA, 1997, J CLIMATE, V10, P2514, DOI 10.1175/1520-0442(1997)010<2514:TSODTT>2.0.CO;2; Xu CY, 1999, PROG PHYS GEOG, V23, P229, DOI 10.1177/030913339902300204; Zhang B, 2000, WATER RESOUR RES, V36, P753, DOI 10.1029/1999WR900264; Zhang XC, 2004, SOIL SCI SOC AM J, V68, P1376; ZHENG C, 2004, IEEE C P 5 WORLD C I, P1869	106	126	138	8	32	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0022-1694			J HYDROL	J. Hydrol.	NOV 15	2006	330	3-4					621	640		10.1016/j.jhydrot.2006.04.030		20	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Engineering; Geology; Water Resources	105IN	WOS:000242023700019		
J	Huang, CC; Lee, HM				Huang, Chi-Chun; Lee, Hahn-Ming			An instance-based learning approach based on grey relational structure	APPLIED INTELLIGENCE			English	Article						instance-based learning; grey relational analysis; grey relational structure; pattern classification	PATTERN-CLASSIFICATION; ALGORITHMS; RULES; NETWORK	In instance-based learning, the 'nearness' between two instances-used for pattern classification-is generally determined by some similarity functions, such as the Euclidean or Value Difference Metric (VDM). However, Euclidean-like similarity functions are normally only suitable for domains with numeric attributes. The VDM metrics are mainly applicable to domains with symbolic attributes, and their complexity increases with the number of classes in a specific application domain. This paper proposes an instance-based learning approach to alleviate these shortcomings. Grey relational analysis is used to precisely describe the entire relational structure of all instances in a specific domain. By using the grey relational structure, new instances can be classified with high accuracy. Moreover, the total number of classes in a specific domain does not affect the complexity of the proposed approach. Forty classification problems are used for performance comparison. Experimental results show that the proposed approach yields higher performance over other methods that adopt one of the above similarity functions or both. Meanwhile, the proposed method can yield higher performance, compared to some other classification algorithms.	Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan; Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Huang, CC (reprint author), Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan.	cchuang@mail.nkmu.edu.tw; hmlee@mail.ntust.edu.tw					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; An A, 2003, COMPUT MATH APPL, V45, P737, DOI 10.1016/S0898-1221(03)00034-8; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Blake C, 1998, UCI REPOSITORY MACHI; Brouwer RK, 1997, NEURAL NETWORKS, V10, P529, DOI 10.1016/S0893-6080(96)00087-1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng Julong, 1989, Journal of Grey Systems, V1; Deng J., 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; Elouedi Z, 2001, INT J APPROX REASON, V28, P91, DOI 10.1016/S0888-613X(01)00045-7; Fix E., 1951, 4 USAF SCH AV MED; Freund Y., 1999, P 16 INT C MACH LEAR, P124; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; Hewett R, 2003, DATA KNOWL ENG, V46, P271, DOI 10.1016/S0169-023X(03)00020-X; Hickey RJ, 2001, KNOWL-BASED SYST, V14, P131, DOI 10.1016/S0950-7051(01)00089-2; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Hu YC, 2002, NEUROCOMPUTING, V48, P863, DOI 10.1016/S0925-2312(01)00677-4; Huang CC, 2003, LECT NOTES COMPUT SC, V2810, P68; HUANG CC, 2001, P 2001 NAT COMP S TA, pB153; Huang YP, 1997, FUZZY SET SYST, V87, P265; Hullermeier E, 2003, ARTIF INTELL, V148, P335, DOI 10.1016/S0004-3702(03)00019-5; Ignizio JP, 1996, COMPUT OPER RES, V23, P535, DOI 10.1016/0305-0548(95)00058-5; John G.H., 1995, P 11 C UNC ART INT, P338; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KOHAVI R, 1995, EUR C MACH LEARN, P174; LANGLEY P, 1995, COMMUN ACM, V38, P55; LIN CT, 1999, J GREY SYSTEM, V4, P359; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rachlin J., 1994, P 11 INT MACH LEARN, P242; SALZBERG S, 1988, TR1088 HARV U CTR RE; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE M, 1974, J R STAT SOC B, V36, P111; Tsumoto S, 2003, EXPERT SYST APPL, V24, P189, DOI 10.1016/S0957-4174(02)00142-2; Watson C. J., 1993, STAT MANAGEMENT EC; Watson I, 1999, KNOWL-BASED SYST, V12, P303, DOI 10.1016/S0950-7051(99)00020-9; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I.H., 2000, DATA MINING PRACTICA	41	7	7	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X			APPL INTELL	Appl. Intell.	DEC	2006	25	3					243	251		10.1007/s10489-006-0105-0		9	Computer Science, Artificial Intelligence	Computer Science	102FO	WOS:000241796600001		
J	Abbas, SR; Arif, M				Abbas, Syed Rahat; Arif, Muhammad			Long range time series forecasting by upsampling and using cross-correlation based selection of nearest neighbor	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						time series forecasting; nearest neighbor; multistep-ahead prediction; long range forecasting; cross-correlation	CLASSIFICATION; MODEL	Long range or multistep-ahead time series forecasting is an important issue in various fields of business, science and technology. In this paper, we have proposed a modified nearest neighbor based algorithm that can be used for long range time series forecasting. In the original time series, optimal selection of embedding dimension that can unfold the dynamics of the system is improved by using upsampling of the time series. Zeroth order cross-correlation and Euclidian distance criterion are used to select the nearest neighbor from up-sampled time series. Embedding dimension size and number of candidate vectors for nearest neighbor selection play an important role in forecasting. The size of embedding is optimized by using auto-correlation function (ACF) plot of the time series. It is observed that proposed algorithm outperforms the standard nearest neighbor algorithm. The cross-correlation based criteria shows better performance than Euclidean distance criteria.	PIEAS, Dept Comp & Informat Sci, Islamabad, Pakistan	Abbas, SR (reprint author), PIEAS, Dept Comp & Informat Sci, Islamabad, Pakistan.	rahatabbas@gmail.com; syedmarif2003@yahoo.com					Abraham B, 1983, STAT METHODS FORECAS; ANDERSON OD, 1976, TIME SERIES ANAL FOR; Atiya AF, 1999, IEEE T NEURAL NETWOR, V10, P402, DOI 10.1109/72.750569; BABOVIC V, 2000, 4 INT C HYDR IOW CIT; Chow TWS, 1996, IEEE T POWER SYST, V11, P1736, DOI 10.1109/59.544636; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANGELMAYR G, 1999, APPL SCI NEURAL NETW, V3821, P86; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; Fernandez-Rodriguez F, 1999, INT J FORECASTING, V15, P383, DOI 10.1016/S0169-2070(99)00003-5; Gautama T., 2003, IEEE INT C AC SPEECH, V6, P29; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Marin FJ, 2002, IEE P-GENER TRANSM D, V149, P121, DOI 10.1049/ip-gtd:20020224; Meade N, 2002, INT J FORECASTING, V18, P67, DOI 10.1016/S0169-2070(01)00111-X; MULHERN FJ, 1994, INT J FORECASTING, V10, P191, DOI 10.1016/0169-2070(94)90002-7; OETKEN G, 1975, IEEE T ACOUST SPEECH, VAS23, P301, DOI 10.1109/TASSP.1975.1162686; Principe JC, 1998, P IEEE, V86, P2240, DOI 10.1109/5.726789; Raicharoen T, 2005, PATTERN RECOGN LETT, V26, P1554, DOI 10.1016/j.patrec.2005.01.003; SAUER T, 1993, TIME SERIES PREDICTI, P175; SMALL M, 2002, PHYS REV E, V66, P701; Small M, 2004, PHYSICA D, V194, P283, DOI 10.1016/j.physd.2004.03.006; SMITH BL, 2000, IEEE INT TRANSP SYST; Takens F., 1981, LECT NOTES MATH, V898, P366, DOI DOI 10.1007/BFB0091924; Taylor JW, 2002, IEEE T POWER SYST, V17, P626, DOI 10.1109/TPWRS.2002.800906; Weigend A. S., 1994, TIME SERIES PREDICTI	25	0	0	1	6	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	DEC	2006	20	8					1261	1278		10.1142/S021800140600523X		18	Computer Science, Artificial Intelligence	Computer Science	133CG	WOS:000243988600008		
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Large-scale predictions of gram-negative bacterial protein subcellular locations	JOURNAL OF PROTEOME RESEARCH			English	Article						gram-negative; subcellular compartment; gene ontology; amphiphilic pseudo amino acid composition; fusion; K-nearest neighbor rule	AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; SECONDARY STRUCTURE; SORTING SIGNALS; NEURAL-NETWORKS; GENE ONTOLOGY; LOCALIZATION; SEQUENCE; CLASSIFICATION	Many species of Gram-negative bacteria are pathogenic bacteria that can cause disease in a host organism. This pathogenic capability is usually associated with certain components in Gram-negative cells. Therefore, developing an automated method for fast and reliabe prediction of Gram-negative protein subcellular location will allow us to not only timely annotate gene products, but also screen candidates for drug discovery. However, protein subcellular location prediction is a very difficult problem, particularly when more location sites need to be involved and when unknown query proteins do not have significant homology to proteins of known subcellular locations. PSORT-B, a recently updated version of PSORT, widely used for predicting Gram-negative protein subcellular location, only covers five location sites. Also, the data set used to train PSORT-B contains many proteins with high degrees of sequence identity in a same location group and, hence, may bear a strong homology bias. To overcome these problems, a new predictor, called "Gneg-PLoc", is developed. Featured by fusing many basic classifiers each being trained with a stringent data set containing proteins with strictly less than 25% sequence identity to one another in a same location group, the new predictor can cover eight subcellular locations; that is, cytoplasm, extracellular space, fimbrium, flagellum, inner membrane, nucleoid, outer membrane, and periplasm. In comparison with PSORT-B, the new predictor not only covers more subcellular locations, but also yields remarkably higher success rates. Gneg-PLoc is available as a Web server at http://202.120.37.186/bioinf/Gneg. To support the demand of people working in the relevant areas, a downloadable file is provided at the same Web site to list the results identified by Gneg-PLoc for 49 907 Gram-negative protein entries in the Swiss-Prot database that have no subcellular location annotations or are annotated with uncertain terms. The large-scale results will be updated twice a year to cover the new entries of Gram-negative bacterial proteins and reflect the new development of Gneg-PLoc.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2000, BIOCHIMIE, V82, P783, DOI 10.1016/S0300-9084(00)01161-5; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOCHEM BIOPH RES CO, V329, P1362, DOI 10.1016/j.bbrr.2005.02.098; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; CHOU KC, 1994, J BIOL CHEM, V269, P22014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELEAGE G, 1987, PROTEIN ENG, V1, P289, DOI 10.1093/protein/1.4.289; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Lee S, 2006, PROTEINS, V62, P1107, DOI 10.1002/prot.20821; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; MAO BY, 1994, PROTEIN ENG, V7, P319, DOI 10.1093/protein/7.3.319; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Murvai J, 2001, NUCLEIC ACIDS RES, V29, P58, DOI 10.1093/nar/29.1.58; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Vapnik V., 1998, STAT LEARNING THEORY; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	56	88	90	0	5	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893			J PROTEOME RES	J. Proteome Res.	DEC 1	2006	5	12					3420	3428		10.1021/pr060404b		9	Biochemical Research Methods	Biochemistry & Molecular Biology	111CE	WOS:000242427800020	17137343	
J	Stegers, R; Fekkes, P; Stuckenschmidt, H				Stegers, Ruud; Fekkes, Peter; Stuckenschmidt, Heiner			MusiDB - A personalized search engine for music	JOURNAL OF WEB SEMANTICS			English	Article						MusiDB; search engine for music; MusicBrainz; personalisation; Amazon.com	RECOMMENDER SYSTEMS	The increasing use of structured information on the web demands new ways of searching and integrating data from different sources. In this paper, we focus on the use of unique representations of data objects in terms of public repositories (in this case MusicBrainz) and the use of recommendation mechanisms as a basis for supporting information access. We have implemented a prototypical system with the corresponding functionality in the area of digital music. We discuss the challenges of providing integrated access to structured web resources and the solutions adopted in the MusiDB system. (C) 2005 Elsevier B. V. All rights reserved.	Vrije Univ Amsterdam, NL-1081 HV Amsterdam, Netherlands	Stuckenschmidt, H (reprint author), Vrije Univ Amsterdam, De Boelelaan 1081A, NL-1081 HV Amsterdam, Netherlands.	heiner@cs.vu.nl					Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Breese J S, 1998, P 14 C UNC ART INT, P43; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Cover T., 1967, IEEE T INFORM THEORY, V13, P57; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; GUHA R, 2003, J WEB SEMANT, V1; Guha R. V., 2003, P 12 INT C WORLD WID, P700; Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773; Resnick P., 1997, COMMUNICATIONS ACM, V40; Staab S, 2000, COMPUT NETW, V33, P473, DOI 10.1016/S1389-1286(00)00039-6; SWARTZ A, 2002, IEEE INTELL SYST JAN, P76; Yantis S., 1996, CONVERGING OPERATION, P45, DOI 10.1037/10187-002	12	1	1	0	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1570-8268			J WEB SEMANT	J. Web Semant.	DEC	2006	4	4					267	275		10.1016/j.websem.2005.09.007		9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	176AC	WOS:000247054100004		
J	Lee, JG; Zhang, CS				Lee, Jianguo; Zhang, Changshui			Classification of gene-expression data: The manifold-based metric learning way	PATTERN RECOGNITION			English	Article						gene expression; metric learning; manifold learning; nearest neighbor	SMALL SAMPLES; MICROARRAY; CANCER; PREDICTION; VALIDATION; ALGORITHMS; ERROR	Classification of microarray gene-expression data can potentially help medical diagnosis, and becomes an important topic in bioinformatics. However, microarray data sets are usually of small sample size relative to an overwhelming number of genes. This makes the classification problem fairly challenging. Instance-based learning (IBL) algorithms, such as nearest neighbor (k-NN), are usually the baseline algorithm due to their simplicity. However, practices show that k-NN performs not very well in this field. This paper introduces manifold-based metric learning to improve the performance of IBL methods. A novel metric learning algorithm is proposed by utilizing both local manifold structural information and local discriminant information. In addition, a random subspace extension is also presented. We apply the proposed algorithm to the gene-classification problem in three ways: one in the original feature space, another in the reduced feature space, and the third via the random subspace extension. Statistical evaluation shows that the proposed algorithm can achieve promising results, and gain significant performance improvement over traditional IBL algorithms. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Tsinghua Univ, Dept Automat, Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Lee, JG (reprint author), Tsinghua Univ, Dept Automat, Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	lijg01@mails.tsinghua.edu.cn; zcs@mail.tsinghua.edu.cn					Alon A., 1999, P NATL ACAD SCI USA, V96, P6745; Bar-Hillel A., 2003, P 20 INT C MACH LEAR, P11; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang C. -C., 2004, LIBSVM LIB SUPPORT V; Cover T., 1967, IEEE T INFORM THEORY, V13, P57; Dougherty ER, 2001, COMPAR FUNCT GENOM, V2, P28, DOI 10.1002/cfg.62; Efron B., 1982, JACKKNIFE BOOTSTRAP; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Girolami M, 1998, NEURAL COMPUT, V10, P2103, DOI 10.1162/089976698300016981; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gray A., 1993, MODERN DIFFERENTIAL; Hall M, 2003, IEEE T KNOWL DATA EN, V15, P1; HASTIE T, 1996, IEEE T PATTERN ANAL, V18, P409; Hastie T., 1995, V7, P999; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hollander M, 1999, NONPARAMETRIC STAT M; HSU JC, 1996, MULTIPLE COMPARISON; Iizuka N, 2003, LANCET, V361, P923, DOI 10.1016/S0140-6736(03)12775-4; KIRA K, 1994, P 9 INT C MACH LEARN, P249; LEE J, 2004, P 21 INT C MACH LEAR, P528; LI S, 2000, IEEE T PATTERN ANAL, V22, P135; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Liu H., 1998, FEATURE SELECTION KN; Mackay DJC, 1998, NATO ADV SCI I D-BEH, V89, P175; Mitchell T. M., 1997, MACHINE LEARNING; Nutt CL, 2003, CANCER RES, V63, P1602; Okun O., 2004, P 2 EUR WORKSH DAT M, P51; Pochet N, 2004, BIOINFORMATICS, V20, P3185, DOI 10.1093/bioinformatics/bth383; Salzberg S., 1991, LNCS, V542, P399; Schapire RE, 1998, ANN STAT, V26, P1651; Schultz M, 2004, ADV NEUR IN, V16, P41; Sima C, 2005, BIOINFORMATICS, V21, P1046, DOI 10.1093/bioinformatics/bti081; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; Simard P.Y., 2001, INT J IMAGING SYSTEM, V11, p[181, 194]; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Theilhaber J, 2002, GENOME RES, V12, P165, DOI 10.1101/gr.182601; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1997, NATURE STAT LEARNING; Vincent P, 2002, ADV NEUR IN, V14, P985; WU W, 2005, MC BIOINFORMATICS, V6, P1; Yandell BS, 1997, PRACTICAL DATA ANAL; Zhang Zhihua, 2003, P 18 INT JOINT C ART, P1450	44	17	19	1	6	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	DEC	2006	39	12					2450	2463		10.1016/j.patcog.2006.05.026		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	095OX	WOS:000241318400017		
J	Boniatis, I; Costaridou, L; Cavouras, D; Panagiotopoulos, E; Panayiotakis, G				Boniatis, Ioannis; Costaridou, Lena; Cavouras, Dionisis; Panagiotopoulos, Elias; Panayiotakis, George			A computer-based image analysis method for assessing the severity of hip joint osteoarthritis	NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT			English	Article; Proceedings Paper	3rd International Conference on Imaging Technologies in Biomedical Sciences	SEP 25-29, 2005	Milos, GREECE			hip; osteoarthritis; radiograph; texture analysis; pattern recognition	TEXTURAL FEATURES; CLASSIFICATION	A computer-based image analysis method was developed for assessing the severity of hip osteoarthritis (OA). Eighteen pelvic radiographs of patients with verified unilateral hip OA, were digitized and enhanced employing custom developed software. Two Rots corresponding to osteoarthritic and contralateral-physiological radiographic Hip Joint Spaces (HJSs) were determined on each radiograph. Textural features were extracted from the HJS-ROIs utilizing the run-length matrices and Laws textural measures. A k-Nearest Neighbour based hierarchical tree structure was designed for classifying hips into three OA severity categories labeled as "Normal", "Mild/Moderate", and "Severe". Employing the run-length features, the overall classification accuracy of the hierarchical tree structure was 86.1%. The utilization of Laws' textural measures improved the system classification performance, providing an overall classification accuracy of 94.4%. The proposed method maybe of value to physicians in assessing the severity of hip OA. (c) 2006 Elsevier B.V. All rights reserved.	Univ Patras, Sch Med, Dept Med Phys, Patras 26500, Greece; Inst Educ Technol, Dept Med Instrumentat Technol, Athens 12210, Greece; Univ Patras, Sch Med, Dept Orthopaed, Patras 26500, Greece	Panayiotakis, G (reprint author), Univ Patras, Sch Med, Dept Med Phys, Patras 26500, Greece.	panayiot@upatras.gr					ALTMAN R, 1991, ARTHRITIS RHEUM, V34, P505, DOI 10.1002/art.1780340502; ALTMAN RD, 1987, ARTHRITIS RHEUM, V30, P1214, DOI 10.1002/art.1780301103; AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046; Bocchi L, 1997, MED ENG PHYS, V19, P336, DOI 10.1016/S1350-4533(96)00078-1; Boniatis IS, 2006, BRIT J RADIOL, V79, P232, DOI 10.1259/bjr/87956832; CONROZIER T, 1993, REV RHUM, V60, P105; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Creamer P, 2000, CURR OPIN RHEUMATOL, V12, P450, DOI 10.1097/00002281-200009000-00019; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6; Gonzalez R.C., 2002, DIGITALIMAGE PROCESS; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Ingvarsson T, 2000, ANN RHEUM DIS, V59, P650, DOI 10.1136/ard.59.8.650; Jacobsen S, 2004, OSTEOARTHR CARTILAGE, V12, P704, DOI 10.1016/j.jocaaaa.2004.05.003; KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494; LANE NE, 1993, J RHEUMATOL, V20, P1911; Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238; Ory PA, 2003, BEST PRACT RES CL RH, V17, P495, DOI 10.1016/S1521-6942(03)00022-6; Peterfy CG, 2002, CURR OPIN RHEUMATOL, V14, P590, DOI 10.1097/01.BOR.0000025608.46603.62; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; Spector T D, 1993, Osteoarthritis Cartilage, V1, P203, DOI 10.1016/S1063-4584(05)80325-5; THEODORIDES S, 2003, PATTERN RECOGNITION	23	12	12	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0168-9002			NUCL INSTRUM METH A	Nucl. Instrum. Methods Phys. Res. Sect. A-Accel. Spectrom. Dect. Assoc. Equip.	DEC 20	2006	569	2			SI		610	613		10.1016/j.nima.2006.08.095		4	Instruments & Instrumentation; Nuclear Science & Technology; Physics, Particles & Fields; Spectroscopy	Instruments & Instrumentation; Nuclear Science & Technology; Physics; Spectroscopy	122QK	WOS:000243241300100		
S	Pian, JX; Chai, TY; Wang, H; Su, CY			IEEE	Pian, Jinxiang; Chai, Tianyou; Wang, Hong; Su, Chunyi			Hybrid intelligent forecasting method of the laminar cooling process for hot strip	2007 AMERICAN CONTROL CONFERENCE, VOLS 1-13	Proceedings of the American Control Conference		English	Proceedings Paper	26th American Control Conference	JUL 09-13, 2007	New  York, NY				PARAMETER-ESTIMATION; TEMPERATURE CONTROL; SYSTEMS; TABLE	To overcome the difficulties of frequently varying operating conditions of laminar cooling processes and of measuring the strip temperature in the cooling process online, a hybrid intelligent forecasting approach of the strip temperature was developed, which combines mathematic and hybrid intelligent methods. The proposed approach is based on the hybrid multi-intelligence technology, where the RBF neural networks, CBR and fuzzy logic reasoning have been used to obtain the parameter estimates, with which a desired prediction on the coiling temperatures has been obtained together with the cooling temperature curve in the cooling process. A number of tests using industrial data have been conducted where desired numerical results have been obtained. It has been shown that the proposed algorithm has a high potential of being used to realize an effective control of the whole process.	[Pian, Jinxiang; Chai, Tianyou] Northeastern Univ, Minist Educ, Key Lab Integrated Automat Process Ind, Shenyang, Peoples R China	Pian, JX (reprint author), Northeastern Univ, Minist Educ, Key Lab Integrated Automat Process Ind, Shenyang, Peoples R China.	jxpian@hotmail.com; tychai@mail.neu.edu.cn; hong.wang@manchester.ac.uk; cysu@alcor.concordia.ca					AAMODT A, 1994, AI COMMUN, V7, P39; BADEN N, 1982, CHEM ENG J, V223, P1; Chai Tianyou, 2000, Acta Automatica Sinica, V26; Chai T.-Y., 2002, P 15 IFAC WORLD C BA, P181; Chiu S., 1994, J INTELL FUZZY SYST, V2, P267; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ditzhuijzen G. V., 1993, IEEE T AUTOMAT CONTR, V38, P1060; EVANS JF, 1993, IRON STEEL ENG, P50; FLETCHER R, 1979, IMAJ NUMER ANAL, V7, P371; Guan SP, 2001, IEEE T CONTR SYST T, V9, P348; Guo RM, 1997, IEEE T IND APPL, V33, P304; Haftka R., 1989, STRUCTURAL OPTIMIZAT, V1, P137, DOI 10.1007/BF01637334; Hartman E, 1990, NEURAL COMPUT, V2, P210, DOI 10.1162/neco.1990.2.2.210; Kumar RK, 1997, IEEE T IND APPL, V33, P807; Lawrence WJ, 1996, IRONMAK STEELMAK, V23, P74; Pal SK, 2000, IEEE T NEURAL NETWOR, V11, P366, DOI 10.1109/72.839007; PENG L, 2005, P 2005 IEEE C CONTR, P992; Samaras NS, 1998, IEEE T IND APPL, V34, P1335, DOI 10.1109/28.739019; SCHANK R, 1982, DYNAMIC MEMORY THEOR, P17232; SERAJZADEH S, 2003, ELSEVIER J MAT PROCE, V146, P312; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; TJOA IB, 1991, IND ENG CHEM RES, V30, P376, DOI 10.1021/ie00050a015; UETZ G, 1991, STEEL RES, V62, P216; VARAH JM, 1982, SIAM J SCI STAT COMP, V3, P28, DOI 10.1137/0903003	24	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619		978-1-4244-0988-4	P AMER CONTR CONF			2007							289	294				6	Automation & Control Systems; Engineering, Electrical & Electronic; Engineering, Mechanical	Automation & Control Systems; Engineering	BHD12	WOS:000252258800050		
S	Verron, S; Tiplica, T; Kobi, A			IEEE	Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad			Procedure based on mutual information and bayesian networks for the fault diagnosis of industrial systems	2007 AMERICAN CONTROL CONFERENCE, VOLS 1-13	Proceedings of the American Control Conference		English	Proceedings Paper	26th American Control Conference	JUL 09-13, 2007	New  York, NY				FISHER DISCRIMINANT-ANALYSIS; SUPPORT VECTOR MACHINES; SUPERVISED CLASSIFICATION; MULTIVARIATE	The aim of this paper is to present a new method for process diagnosis using a bayesian network. The mutual information between each variable of the system and the class variable is computed to identify the important variables. To illustrate the performances of this method, we use the Tennessee Eastman Process. For this complex process (51 variables), we take into account three kinds of faults with the minimal recognition error rate objective.	[Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad] Univ Angers, ISTIA, LASQUO, F-49000 Angers, France	Verron, S (reprint author), Univ Angers, ISTIA, LASQUO, F-49000 Angers, France.	sylvain.verron@istia.univ-angers.fr					Bakshi BR, 1998, AICHE J, V44, P1596, DOI 10.1002/aic.690440712; CHARLES HK, 1991, J HOPKINS APL TECH D, V12, P4; Chiang LH, 2004, COMPUT CHEM ENG, V28, P1389, DOI 10.1016/j.compchemeng.2003.10.002; CHIANG LH, 2001, FAULT DETECTION DIAG, P17232; Chiang LH, 2000, CHEMOMETR INTELL LAB, V50, P243, DOI 10.1016/S0169-7439(99)00061-1; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1969, LEARNING PATTERN REC, P17232; DOMINGOS P, 1996, INT C MACH LEARN, P17232; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; DUDA RO, 2001, PATTERN CLASSIFICATI, P17232; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; Hotelling H., 1947, TECHNIQUES STAT ANAL, P111; Inza I, 1999, PATTERN RECOGN LETT, V20, P1201, DOI 10.1016/S0167-8655(99)00095-1; JACKSON JE, 1985, COMMUN STAT-THEOR M, V14, P2657, DOI 10.1080/03610928508829069; JENSEN FV, 1996, INTRO BAYESIAN NETWO, P17232; Kano M, 2002, COMPUT CHEM ENG, V26, P161, DOI 10.1016/S0098-1354(01)00738-4; KONONENKO I, 1991, EUR WORK SESS LEARN, P206; Kruger U, 2004, J PROCESS CONTR, V14, P879, DOI 10.1016/j.jprocont.2004.02.002; Kulkarni A, 2005, COMPUT CHEM ENG, V29, P2128, DOI 10.1016/j.compchemeng.2005.06.006; LANGLEY P, 1992, NAT C ART INT, P17232; LYMAN PR, 1995, COMPUT CHEM ENG, V19, P321, DOI 10.1016/0098-1354(94)00057-U; MACGREGOR H, 1995, CHROMOSOME RES, V3, P3, DOI 10.1007/BF00711155; MASON RL, 1995, J QUAL TECHNOL, V27, P99; MURPHY KP, 2001, COMPUTING SCI STAT P, P17232; PEARL J, 1988, PROBABILISTIC REASON, P17232; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; Ricker NL, 1996, J PROCESS CONTR, V6, P205; SAHAMI M, 1996, 2 INT C KNOWLEDGE DI, P17232; Shannon E. C., 1948, BELL SYST TECH J, V27, P623; SHEWHART WA, 1931, EC CONTROL QUALITY M, P17232; VAPNIK V, 1995, NATURE STAT LEARNING, P17232; Wise BM, 1996, J PROCESS CONTR, V6, P329, DOI 10.1016/0959-1524(96)00009-1; YANG Y, 2003, 131 MON U SCH COMP S, P17232	35	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619		978-1-4244-0988-4	P AMER CONTR CONF			2007							1582	1587				6	Automation & Control Systems; Engineering, Electrical & Electronic; Engineering, Mechanical	Automation & Control Systems; Engineering	BHD12	WOS:000252258801027		
S	Sakagaito, J; Wada, T			IEEE	Sakagaito, Junya; Wada, Toshikazu			Nearest first traversing graph for simultaneous object tracking and recognition	2007 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-8	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO			APPEARANCE	This paper presents a new method for simultaneous object tracking and recognition using object image database. This application requires two searches: search for object appearance stored in the database and that for pose parameters (position, scale, orientation, and so on) of the tracking object in each image frame. For simplifying this problem, we propose a new method, pose parameter embedding (PPE) that transforms the original problem to an appearance search problem. The nearest neighbor (NN) appearance search in this problem has a special property that gradually changing queries are given. For this problem, graph based NN search is suitable, because the preceding search result can be used as the starting point of the next search. Delaunay graph can be used for this search, however, both the graph construction cost and the degree (number of mean edges connected to a vertex) drastically increase in high-dimensional space. Instead, we propose nearest first traversing graph (NFTG) for avoiding these problems. Based on these two techniques, we successfully realized video-rate tracking and recognition.	Wakayama Univ, Fac Syst Engn, Dept Comp & Commun Sci, Wakayama, Japan	Sakagaito, J (reprint author), Wakayama Univ, Fac Syst Engn, Dept Comp & Commun Sci, Wakayama, Japan.	sakajun@vrl.sys.wakayama-u.ac.jp; twada@ieee.org					Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; BOZKAYA T, 1997, 1997 ACM SIGMOD; Brin S., 1995, 21 VLDB C MORG KAUFM, P574; Comaniciu D, 2000, CVPR, V2, P142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HAER G, 1998, IEEE T PATTERN ANAL, V20, P1125; ISARD M, 1996, EUR C COMP VIS, V1, P343; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Okabe A., 2000, SPATIAL TESSELATIONS; YIANILOV PY, 1993, 4 ANN ACM SIAM S DIS	14	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-1179-5	PROC CVPR IEEE			2007							1575	1581				7	Computer Science, Software Engineering; Mathematical & Computational Biology; Remote Sensing; Imaging Science & Photographic Technology	Computer Science; Mathematical & Computational Biology; Remote Sensing; Imaging Science & Photographic Technology	BGT02	WOS:000250382803020		
B	Lumanpauw, E; Pasquier, M; Oentaryo, RJ			IEEE	Lumanpauw, Ernest; Pasquier, Michel; Oentaryo, Richard J.			Generic GA-based meta-level parameter optimization for pattern recognition systems	2007 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-10, PROCEEDINGS	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	IEEE Congress on Evolutionary Computation	SEP 25-28, 2007	Singapore, SINGAPORE	IEEE			FUZZY NEURAL-NETWORK; GENETIC ALGORITHMS; YAGER-INFERENCE	This paper proposes a novel generic meta-level parameter optimization framework to address the problem of determining the optimal parameters of pattern recognition systems. The proposed framework is currently implemented to control the parameters of neuro-fuzzy system, a subclass of pattern recognition system, by employing a genetic algorithm (GA) as the core optimization technique. Two neuro-fuzzy systems i.e., Generic Self-Organizing Fuzzy Neural Network realizing Yager inference (GenSoFNN-Yager) and Reduced Fuzzy Cerebellar Model Articulation Computer realizing the Yager inference (RFCMAC-Yager), are employed as the test prototypes to evaluate the proposed framework. Experimental results on several classification and regression problems have shown the efficacy and robustness of the proposed approach.	[Lumanpauw, Ernest; Pasquier, Michel; Oentaryo, Richard J.] Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore	Lumanpauw, E (reprint author), Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore.	asmbpasquier@ntu.edu.sg	Oentaryo, Richard/M-5948-2014	Oentaryo, Richard/0000-0002-4662-1561			COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Darwin C., 1859, ORIGIN SPECIES MEANS; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Han SS, 1996, PROC INT C TOOLS ART, P200; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Holland J H., 1975, ADAPTATION NATURE AR; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Leung FHF, 2003, IEEE T NEURAL NETWOR, V14, P79, DOI 10.1109/TNN.2002.804317; Lin CJ, 1997, IEEE T FUZZY SYST, V5, P477; Lin C.-T., 1996, NEURAL FUZZY SYSTEMS; Maguire LP, 1998, INFORM SCIENCES, V112, P125, DOI 10.1016/S0020-0255(98)10026-9; Nedler JA, 1965, COMPUT J, V7, P308; Newman D., 1998, UCI REPOSITORY MACHI; OENTARYO RJ, 2006, P IEEE INT JOINT C N, P705; OENTARYO RJ, 2006, THESIS NANYANG TECHN; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; Quek C, 2005, EXPERT SYST APPL, V29, P229, DOI 10.1016/j.eswa.2005.03.001; Richards N, 1998, APPL INTELL, V8, P85, DOI 10.1023/A:1008224732364; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sim J, 2006, IEEE T NEURAL NETWOR, V17, P1394, DOI 10.1109/TNN.2006.880362; Ster B., 1996, P INT C ENG APPL NEU, P427; TRIMMER JD, 1950, RESPONSE PHYS SYSTEM, P13; Tung WL, 2002, IEEE T NEURAL NETWOR, V13, P1075, DOI 10.1109/TNN.2002.1031940; WALL M, 1996, GALIB A C LIB GENTIC	26	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-1339-3	IEEE C EVOL COMPUTAT			2007							1593	1600		10.1109/CEC.2007.4424663		8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHT10	WOS:000256053701025		
B	He, JS; Yang, ZY; Yao, X			IEEE	He, Jingsong; Yang, Zhenyu; Yao, Xin			Hybridisation of evolutionary programming and machine learning with k-nearest neighbor estimation	2007 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-10, PROCEEDINGS	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	IEEE Congress on Evolutionary Computation	SEP 25-28, 2007	Singapore, SINGAPORE	IEEE				Evolutionary programming(EP) focus on the search step size which decides the ability of escaping local minima, however does not touch the issue of search in promising region. Estimation of Distribution Algorithms(EDAs) focus on where the promising region is, however have less consideration about behavior of each individual in solution search algorithms. Since the basic ideas of EP and EDAs are quite different, it is possible to make them reinforce each other. In this paper, we present a hybrid evolutionary framework to make use of both the ideas of EP and EDAs through introducing a mini estimation operator into EP's search cycle. Unlike previous EDAs that use probability density function(PDF), the estimation mechanism used in the proposed framework is the k-nearest neighbor estimation which can perform better with relative small amount of training samples. Our experimental results have shown that the incorporation of machine learning techniques, such as k-nearest neighbor estimation, can improve the performance of evolutionary optimisation algorithms for a large number of benchmark functions.	[He, Jingsong; Yang, Zhenyu; Yao, Xin] Univ Sci & Technol China, Nat Inspired Computat & Applicat Lab, Hefei 230027, Anhui, Peoples R China	He, JS (reprint author), Univ Sci & Technol China, Nat Inspired Computat & Applicat Lab, Hefei 230027, Anhui, Peoples R China.	hjss@ustc.edu.cn; zhyuyang@mail.ustc.edu.cn; X.Yao@cs.bham.ac.uk					Back T, 1993, EVOL COMPUT, V1, P1, DOI 10.1162/evco.1993.1.1.1; BOSNIAN PAN, 2001, P OPT BUILD US PROB, P208; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; FOGEL DB, 1993, CYBERNET SYST, V24, P27, DOI 10.1080/01969729308961697; Fogel D. B., 1991, SYSTEM IDENTIFICATIO; Fogel D. B., 1995, EVOLUTIONARY COMPUTA; Fogel DB, 1992, THESIS U CALIFORNIA; Fogel L. J., 1966, ARTIFICIAL INTELLIGE; GALLAGHER M, 1999, P 1999 GEN EV COMP C, V1, P840; Gehlhaar D., 1996, EVOLUTIONARY PROGRAM, P419; LARRANAGA P, 2001, ESTIMATION DISTRIBUT, P101; LEE CY, 2004, IEEE T EVOLUTIONARY, V8, P456; Li B, 2002, INT J MECH SCI, V44, P987, DOI 10.1016/S0020-7403(02)00021-8; Lu Q, 2005, IEEE T SYST MAN CY C, V35, P195, DOI 10.1109/TSMCC.2004.841914; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pelikan M., 2000, PPSN, V1917, P385; Schwefel H.P., 1995, EVOLUTION OPTIMUM SE; Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82	19	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-1339-3	IEEE C EVOL COMPUTAT			2007							1693	1700				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHT10	WOS:000256053701039		
B	Alippi, C; Roveri, M			IEEE	Alippi, Cesare; Roveri, Manuel			Reducing computational complexity in k-NN based adaptive classifiers	2007 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications			English	Proceedings Paper	IEEE International Conference on Computational Intelligence for Measurement Systems and Applications	JUN 27-29, 2007	Ostuni, ITALY	IEEE			NEAREST-NEIGHBOR RULE; CLASSIFICATION	Integrating new information in intelligent measurement systems during their operational life is always profitable from the accuracy point of view but it generally induces an increment in the complexity of the classifier. Adaptive classifiers, which provide adaptive mechanisms to update their knowledge base over time, are able to exploit fresh information to improve accuracy but, traditionally, do not consider complexity issues. In this paper we propose a design solution for adaptive classifiers able to reduce the computational complexity and the memory requirements of k-NN classifiers by including condensing editing techniques. Moreover, we propose a novel approach for estimating the incoming innovation content which allows us for not including redundant or superfluous information (thus minimizing the knowledge base size).	Politecn Milan, DEI, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, DEI, I-20133 Milan, Italy.						Alippi C, 2006, Proceedings of the 2006 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications, P40; ALIPPI C, 2007, P IEEE INT JOINT C N; Bollani M, 2001, APPL SURF SCI, V175, P379, DOI 10.1016/S0169-4332(01)00129-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fu LM, 1996, IEEE T SYST MAN CY A, V26, P801; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KULKAMI SR, 1994, IEEE T INFORM THEORY, V41, P820; LINGARKAR R, 1990, IEEE T SYST MAN CYB, V20, P606, DOI 10.1109/21.57273; Meir R, 2000, IEEE T NEURAL NETWOR, V11, P323, DOI 10.1109/72.839004; NOZAKI K, 1996, IEEE T FUZZY SYST, V4, P23; Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744; POULSEN RS, 1981, INT S INF THEOR SANT; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P1028; Robertson P, 1999, IEEE INTELL SYST APP, V14, P30, DOI 10.1109/5254.769882; RODRIGUEZ C, 2002, P 16 INT C PATT REC, V3, P98; STOCKER E, 1996, P ICPR, V4, P128; TAN SC, 2000, P TENCON SEPT, V1, P13; WANG EH, 1992, P INT JOINT C NEUR N, V3, P121, DOI 10.1109/IJCNN.1992.227182; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	20	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0823-8				2007							68	71		10.1109/CIMSA.2007.4362541		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Computer Science; Engineering; Remote Sensing; Imaging Science & Photographic Technology	BGW78	WOS:000251008000014		
S	Yu, XP; Yu, XG			IEEE	Yu, Xiaopeng; Yu, Xiaogao			An adaptive algorithm for P2P k-nearest neighbor search in high dimensions	2007 IEEE INTERNATIONAL CONFERENCE ON CONTROL AND AUTOMATION, VOLS 1-7	IEEE International Conference on Control and Automation ICCA		English	Proceedings Paper	IEEE International Conference on Control and Automation	MAY 30-JUN 01, 2007	Guangzhou, PEOPLES R CHINA	IEEE		P2P; k-nearest search; GHT; similarity measurement	CLASSIFICATION; RULE	K-Nearest Neighbors search (KNNS) in high-dimensional feature spaces is an important paradigm in pattern recognition. Existing centralized KNNS does not scale up to large volume of data because the response time is linearly increasing with the size of the searched file. In this article, an adaptive distributed k-nearest neighbor search algorithm (P2PAKNNS) for high dimension data is proposed to further improve the scalability in P2P systems. The idea adopts the generalized hypersphere partitioning and the similarity measure function HDsim((x) over bar, (y) over bar), which can adaptively determines the size of the hypersphere and avoid the problems that L-k-norm leads to the non-contrasting behavior of distance in high dimensional space. By exploiting parallelism in a dynamic network of computers, the query execution scales up very well considering the number of distance computations. The experiments indicate the algorithm is effective.	[Yu, Xiaopeng] Wuhan Univ, Sch Informat Management, Wuhan Inst Technol, Wuhan 430072, Peoples R China	Yu, XP (reprint author), Wuhan Univ, Sch Informat Management, Wuhan Inst Technol, Wuhan 430072, Peoples R China.	myhbwh@163.com; tecom_sam@163.com					Aggarwal C. C., 2001, P 20 ACM SIGMOD SIGA, P256, DOI 10.1145/375551.383213; AGGARWAL CC, 2001, P SIGMOD PODS, V1, P13; BATKO M, 2004, P DELOS WORKSH DIG L, P213; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; Canny J, 2002, P IEEE S SECUR PRIV, P45, DOI 10.1109/SECPRI.2002.1004361; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; Olsson T., 2003, BOOTSTRAPPING DECENT; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9	13	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1948-3449		978-1-4244-0817-7	IEEE INT CONF CON AU			2007							236	241				6	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BHX39	WOS:000257195300047		
S	Fadeev, A; Frigui, H; Kim, DJ; Elmaghraby, A			IEEE	Fadeev, Aleksey; Frigui, Hichem; Kim, Dae-Jin; Elmaghraby, Adel			Transformation of relational features for use with conventional classifiers	2007 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-4	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	JUL 23-26, 2007	London, ENGLAND	IEEE				In this paper, we address the problem of transforming relational features into an Euclidian space so that standard classification methods that assume that data is in a vector form could be used. Our approach has three main steps. First, a relational matrix that represents the pair-wise dissimilarities between all objects is constructed. Second, a fuzzy relational clustering algorithm is used to partition the data into groups of similar objects. Third, the relational data features are mapped to a unit hyper-cube space where each object is represented by its membership vectors in all clusters. The proposed method is validated by comparing the performance of several classifiers with different feature sets on the original and the transformed spaces. We show that the transformed space conserves the discriminative information of the original features. We also show that, using the transformed space, a richer set of standard classifiers could be used.	[Fadeev, Aleksey; Frigui, Hichem; Kim, Dae-Jin; Elmaghraby, Adel] Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY 40292 USA	Fadeev, A (reprint author), Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY 40292 USA.	aleksfadeev@gmail.com; h.frigui@louisville.edu; djkimgo@gmail.com; adel@louisville.edu					BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; Chang C.C., 2001, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dave RN, 2002, IEEE T FUZZY SYST, V10, P713, DOI 10.1109/TFUZZ.2002.805899; Frank E., 2005, DATA MINING PRACTICA; Frigui H, 2006, IEEE T FUZZY SYST, V14, P885, DOI 10.1109/TFUZZ.2006.879981; GUTTMAN L, 1968, PSYCHOMETRIKA, V33; HATHAWAY RJ, 1989, PATTERN RECOGN, V22, P205, DOI 10.1016/0031-3203(89)90066-6; KAUFMAN K, 1990, FINDING GOUPS DATA; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Li J., 2000, P 8 ACM INT C MULT, P147, DOI 10.1145/354384.354452; Manjunath B. S., 2002, INTRO MPEG; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Nasraoui O., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, DOI 10.1142/S021821300000032X; ROBNER Y, 1999, PERCEPTUAL METRICS I; SEN S, 1998, IEEE C FUZZ SYST, P1411; SNEATH PH, 1973, NUMERIAL TAXONOMY	18	0	0	0	0	IEEE, ELECTRON DEVICES SOC & RELIABILITY GROUP	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584		978-1-4244-1209-9	IEEE INT CONF FUZZY			2007							1999	2004				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHD83	WOS:000252371500342		
S	Alippi, C; Roveri, M			IEEE	Alippi, C.; Roveri, M.			Adaptive classifiers in stationary conditions	2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE			NEAREST-NEIGHBOR RULE; DISCRIMINANT-ANALYSIS; CLASSIFICATION; SYSTEMS	Integrating new information in classification systems during their operational life requires adaptive mechanisms able to identify first the presence of valuable information and update then the knowledge base onto which the classifier is configured. In this paper we provide a design solution for adaptive classifiers operating in stationary environments; information provided (whenever available by a supervisor over time) is used to improve the performance of the classification system hence mimicking the asymptotical behavior suggested by the theory. The adaptive classifier relies on k -NNs, here chosen for their learning-free modality (hence easily supporting a real time adaptation mechanism); a novel method is proposed for matching the optimal k (measuring the complexity of the classifier) with the incremental knowledge acquired over time. A large experimental campaign shows the effectiveness of the proposed approach.	[Alippi, C.; Roveri, M.] Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy.						ALIPPI C, P IEEE INT JOINT C N, P5040; ALIPPI C, 2006, P IEEE INT S CIRC SY, P5752; Alippi C, 2006, IEEE T SYST MAN CY C, V36, P649, DOI 10.1109/TSMCC.2005.855508; ALIPPI C, P IEEE INT JOINT C N; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C., UCI MACHINE LEARNING; Bollani M, 2001, APPL SURF SCI, V175, P379, DOI 10.1016/S0169-4332(01)00129-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Fukunaga K., 1972, INTRO STAT PATTERN R; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jackson Q, 2001, IEEE T GEOSCI REMOTE, V39, P2664, DOI 10.1109/36.975001; KEANS M, 1999, NEURAL COMPUT, V11, P1427; Kohlmorgen J, 2000, BIOL CYBERN, V83, P73, DOI 10.1007/s004220000144; KULKAMI SR, 1994, IEEE T INFORM THEORY, V41, P820; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LI P, P IEEE NAT RAD C 199, P372; LINGARKAR R, 1990, IEEE T SYST MAN CYB, V20, P606, DOI 10.1109/21.57273; LU F, 1996, IEEE T SYST MAN CYB, V26, P801; Meir R, 2000, IEEE T NEURAL NETWOR, V11, P323, DOI 10.1109/72.839004; NOZAKI K, 1996, IEEE T FUZZY SYST, V4, P23; Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744; POULSEN RS, 1981, INT S INF THEOR SANT; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P1028; Rizki MM, 2002, IEEE T EVOLUT COMPUT, V6, P594, DOI 10.1109/TEVC.2002.806167; Robertson P, 1999, IEEE INTELL SYST APP, V14, P30, DOI 10.1109/5254.769882; RODRIGUEZ C, 2002, P 16 INT C PATT REC, V3, P98; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; STOCKER E, 1996, P ICPR, V4, P128; STONE C, 1977, ANN STAT, V8, P1348; TAN SC, 2000, P TENCON SEPT, V1, P13; Vapnik V., 1998, STAT LEARNING THEORY; WANG EH, 1992, P INT JOINT C NEUR N, V3, P121, DOI 10.1109/IJCNN.1992.227182; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	35	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1379-9	IEEE IJCNN			2007							1008	1013		10.1109/IJCNN.2007.4371096		6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BHM64	WOS:000254291100176		
S	Kamiya, Y; Ishii, T; Furao, S; Hasegawa, O			IEEE	Kamiya, Youki; Ishii, Toshiaki; Furao, Shen; Hasegawa, Osamu			An online semi-supervised clustering algorithm based on a self-organizing incremental neural network	2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE			PATTERN-CLASSIFICATION; CELL STRUCTURES; MAPS	This paper presents an online semi-supervised clustering algorithm based on a self-organizing incremental neural network (SOINN). Using labeled data and a large amount of unlabeled data, the proposed semi-supervised SOINN (ssSOINN) can automatically learn the topology of input data distribution without any prior knowledge such as the number of nodes or a good network structure; it can subsequently divide the structure into sub-structures as the need arises. Experimental results we obtained for artificial data and real-world data show that the ssSOINN has superior performance for separating data distributions with high-density overlap and that ssSOINN Classifier (S3C) is an efficient classifier.	[Kamiya, Youki; Ishii, Toshiaki] Tokyo Inst Technol, Dept Comp Intelligence & Syst Sci, Tokyo 2268503, Japan	Kamiya, Y (reprint author), Tokyo Inst Technol, Dept Comp Intelligence & Syst Sci, Tokyo 2268503, Japan.	kamiya.y.ab@m.titech.ac.jp; ishii.t.aa@m.titech.ac.jp; frshen@nju.edu.cn; hasegawa.o.aa@m.titech.ac.jp					ANAGNOSTOPOULOS GC, 2003, P IEEE INNS ENNS INT, V3, P1350; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIMITRIADOU E, 2002, P ICANN 02, P571; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; GROSSBERG S, 1976, BIOL CYBERN, V23, P187; HAMKER F, 1997, 197 TU ILM; Hamker FH, 2001, NEURAL NETWORKS, V14, P551, DOI 10.1016/S0893-6080(01)00018-1; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Le Q, 2005, IEEE IJCNN, P3121; Martinetz T, 1993, INT C ART NEUR NETW, P427; Moody J., 1988, P 1988 CONN MOD SUMM, P133; Murphy P. M., 1998, UCI REPOSITORY MACHI; Prudent Y, 2005, IEEE IJCNN, P1211; Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006; ZHANG R, 2006, P ICPR 06, V2, P780	16	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1379-9	IEEE IJCNN			2007							1061	1066		10.1109/IJCNN.2007.4371105		6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BHM64	WOS:000254291101004		
S	Furao, S; Hasegawa, O			IEEE	Furao, Shen; Hasegawa, Osamu			A nearest-neighbor method with self-organizing incremental neural network	2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE			CLASSIFICATION	We introduce a prototype-based nearest-neighbor method that is based on a self-organizing incremental neural network (SOINN). It automatically learns the number of prototypes necessary to determine the decision boundary, and it Is robust to noisy training data. The experiments with artificial datasets and real-world datasets illustrate the efficiency of the proposed method.	[Furao, Shen; Hasegawa, Osamu] Nanjing Univ, Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	Furao, S (reprint author), Nanjing Univ, Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.						Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Hastie T, 2001, ELEMENTS STAT LEARNI; Martinetz T, 1993, INT C ART NEUR NETW, P427; Merz C. J., 1996, UCI REPOSITORY MACHI; PASSERINI A, 2002, P 15 EUR C ART INT; SHEN F, 2005, IEEE COMP SOC INT C; Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	11	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1379-9	IEEE IJCNN			2007							1145	1150		10.1109/IJCNN.2007.4371119		6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BHM64	WOS:000254291101018		
S	Barry, M; Granger, E			IEEE	Barry, M.; Granger, E.			Face recognition in video using a what-and-where fusion neural network	2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE			CLASSIFICATION; TRACKING	A What-and-Where fusion neural network is applied to the recognition of human faces from video sequences. ne spatio-temporal information contained in successive video frames allows to effectively accumulate a classifier's predictions for each person being tracked in an environment. In a particular realization of this network, a fuzzy ARTMAP neural network is used to classify faces detected in each frame, while a bank of Kalman filters; is used to track blobs that contain the extracted faces moving in the environment. Performance of the What-and-Where fusion neural network is compared to that of the fuzzy ARTMAP and k-Nearest-Neighbor (k-NN) classifiers in terms of classification rate, convergence time and compression. In this paper, the impact on performance of setting different region of interest (ROI), of optimizing fuzzy ARTMAP parameters, and of selecting different training subset sizes, is assessed. Simulation results on real-world video sequences indicate that this network can achieve a classification rate that is significantly higher (by approximately 50% in some cases) than that of fuzzy ARTMAP alone, and than that of the k-NN.	[Barry, M.; Granger, E.] Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle, Montreal, PQ H3C 1K3, Canada	Barry, M (reprint author), Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle, 1100 Notre Dame Ouest, Montreal, PQ H3C 1K3, Canada.						CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; CHEN S, 1992, IEEE T NEURAL NETWOR, V3, P698; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Foresti GL, 2000, INT J IMAG SYST TECH, V11, P263, DOI 10.1002/ima.1011; Gorodnichy DO, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P330, DOI 10.1109/CRV.2005.87; Granger E, 2001, NEURAL NETWORKS, V14, P325, DOI 10.1016/S0893-6080(01)00019-3; GRANGER E, 2006, INT JOINT C NEUR NET; LI B, 2001, J OPT SOC AM, V18, P530; LIEANHART R, 2002, INT C IM PROC, V1, P900; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; ZHOU SK, 2004, IEEE T IMAGE PROCESS, V13, P263	11	2	2	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1379-9	IEEE IJCNN			2007							2256	2261		10.1109/IJCNN.2007.4371309		6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BHM64	WOS:000254291102030		
B	Martone, AF; Delp, EJ			IEEE	Martone, Anthony F.; Delp, Edward J.			Characterization of RF devices using two-tone probe signals	2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2			English	Proceedings Paper	14th IEEE/SP Workshop on Statistical Signal Processing	AUG 26-29, 2007	Madison, WI	IEEE, SP		RF devices; forensic characterization; intermodulation distortion; probe signals; circuit models	PATTERN-CLASSIFICATION	This paper describes a method for forensic characterization of RF devices using two-tone probe signals. When transmitted to an RF device, the two-tone signal is affected by nonlinear circuit components such as amplifiers or diodes. The nonlinear components cause intermodulation distortion to the input signal, which is reradiated by the device. Features of the intermodulation distortion products are used to construct a device fingerprint. The fingerprint is then used to characterize the device so that it can be identified from other RF devices.	[Martone, Anthony F.; Delp, Edward J.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Martone, AF (reprint author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.		Delp, Edward/C-3616-2013	Delp, Edward/0000-0002-2909-7323			Babich GA, 1996, IEEE T PATTERN ANAL, V18, P567, DOI 10.1109/34.494647; Breiman L., 1984, CLASSIFICATION REGRE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.-C., LIBSVM LIB SUPPORT V; COMMISSION FC, 2006, PART 15 RADIO FREQ B; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, INTRO STAT PATTERN R; GOLIKOV V, 2001, VEH TECHN C 2001 OCT, V4, P2623; HOFFBECK J, 1995, INT GEOSC REM SENS S, V2, P1023; Khanna N., 2006, DIGIT INVEST, V3, P17, DOI 10.1016/j.diin.2006.06.014; Martone A., 2006, P 2006 IEEE SW S IM, P149; Pedro J. C., 2003, INTERMODULATION DIST; RHYNE GW, 1987, IEEE T MICROW THEORY, V35, P1248, DOI 10.1109/TMTT.1987.1133844	13	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-1197-9				2007							161	165		10.1109/SSP.2007.4301239		5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BHI51	WOS:000253416000034		
B	Vivencio, DP; Hruschka, ER; Nicoletti, MD; dos Santos, EB; Galvao, SDCO			IEEE	Vivencio, Diego P.; Hruschka, Estevarn R., Jr.; Nicoletti, M. do Carmo; dos Santos, Edimilson B.; Galvao, Sebastian D. C. O.			Feature-weighted k-nearest neighbor classifier	2007 IEEE Symposium on Foundations of Computational Intelligence, Vols 1 and 2			English	Proceedings Paper	IEEE Symposium on Foundations of Computational Intelligence	APR 01-05, 2007	Honolulu, HI	IEEE		feature selection; instance-based learning; feature ranking	SELECTION	This paper proposes a feature weighting method based on X-2 statistical test, to be used in conjunction with a k-NN classifier. Results of empirical experiments conducted using data from several knowledge domains are presented and discussed. Forty four out of forty five conducted experiments favoured the feature weighted approach and are empirical evidence that the proposed weighting process based on X-2 is a good weighting strategy.	DC UFSCar, Sao Carlos, SP, Brazil	Vivencio, DP (reprint author), DC UFSCar, Sao Carlos, SP, Brazil.		Hruschka Jr., Estevam/B-1073-2008; Batista dos Santos, Edimilson/G-9014-2012				Aha D. W., 1990, THESIS U CALIFORNIA; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W., 1992, P TWLT3 CONN NAT LAN, P27; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hruschka ER, 2004, LECT NOTES ARTIF INT, V3060, P370; Koller D., 1996, P 13 INT C MACH LEAR, P284; LANGLEY P, 1997, COMPUTATIONAL LEARNI, V4; Langley P., 1993, P 13 INT JOINT C ART, P889; Liu H., 1998, FEATURE SELECTION KN; Merz C, 1998, UCI REPOSITORY MACHI; Mitchell T. M., 1997, MACHINE LEARNING; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Witten IH, 2002, DATA MINING PRACTICA	16	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0703-3				2007							481	486		10.1109/FOCI.2007.371516		6	Computer Science, Artificial Intelligence	Computer Science	BGM60	WOS:000248503700073		
B	Wu, WH; Batalin, MA; Kaiser, WJ; Sarrafzadeh, M; Bui, AAT				Wu, Winston H.; Batalin, Maxim A.; Kaiser, William J.; Sarrafzadeh, Majid; Bui, Alex A. T.			A Novel Method and Testbed for Sensor Management and Patient Diagnosis	2007 JOINT WORKSHOP ON HIGH CONFIDENCE MEDICAL DEVICES, SOFTWARE AND SYSTEMS AND MEDICAL DEVICE PLUG-AND PLAY INTEROPERABILITY			English	Proceedings Paper	Joint Workshop on High Confidence Medical Devices, Software, and Systems/Medical Device Plug-and-Play Interoperability	JUN 25-27, 2007	Cambridge, MA	NSF, AHRO, TATRC, CIMIT, Massachusetts Gen Hosp, Partners			TRIAXIAL ACCELEROMETER; MEDICAL DIAGNOSIS; WEARABLE SENSORS; CLASSIFICATION; SELECTION	Low-cost sensors and wireless systems can now create a constantly vigilant and pervasive monitoring capability at home, at work, and in conventional point-of-care environments. While progress in this area is underway in sensor technology, mobile computing platforms, and data transport, barriers to large scale application remain ahead, particularly in the area of patient disease diagnosis, which generally requires a diverse set of sensors and instruments that are applied at proper times in response to patient state/behavior As these sensors may, be numerous, and may not be worn comfortably and practicably at all times, a solution is required for the systematic selection of sensors at the point of use. We describe the Incremental Diagnosis Method (IDM) system, an embedded decision support system based on Bayesian statistics and decision analysis theory developed to select or deselect available sensors so that the diagnostic certainly of patient condition best improved while the set of sensors used on the patient body is minimized. IDM has been evaluated in a testbed, the Medical Embedded Device for Individualized Care (MEDIC) system, based on standard, ubiquitous wireless platforms. MEDIC supports local sensing and signal processing, autonomous decision support, and remote reconfiguration and control of wearable components. A detailed evaluation of IDM operation and performance for patient gait analysis is also given in this paper Finally, we also discuss the many new opportunities provided by IDM and the related future research introduced by this capability.	[Wu, Winston H.; Batalin, Maxim A.; Kaiser, William J.] Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA	Wu, WH (reprint author), Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA.	winston@ee.ucla.edu; maxim@ee.ucla.edu; kaiser@ee.ucla.edu; majid@cs.ucla.edu; buia@mii.ucla.edu					AMFT O, 2006, P INT WORKSH WEAR IM; ANLIKER U, 2003, IEEE T COMPUTERS; Asada HH, 2003, IEEE ENG MED BIOL, V22, P28, DOI 10.1109/MEMB.2003.1213624; Bao L., 2004, P 2 INT C PERV COMP; Bernardo J. M., 2003, ENCY LIFE SUPPORT SY; *BLUEP XP, BLUET SER AD; *BLUES AD, DAT ACQ CONTR MOD; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Brachinger H., 2002, OPTIMIZATION OPERATI, P933; Brage S, 2005, EUR J CLIN NUTR, V59, P561, DOI 10.1038/sj.ejcn.1602118; Budinger TE, 2003, ANNU REV BIOMED ENG, V5, P383, DOI 10.1146/annurev.bioeng.5.040202.121653; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEY A, 2000, BCHI 2000 WORKSH WHA; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Farringdon J, 2005, LECT NOTES COMPUT SC, V3345, P202; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hall DL, 1997, P IEEE, V85, P6, DOI 10.1109/5.554205; Hastie T, 2001, ELEMENTS STAT LEARNI; Hausdorff J.M., 2005, J NEUROENG REHAB, V2; Hellerstein J. L., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Herzog Almut, 2003, Technol Health Care, V11, P77; HILDEN J, 1984, COMPUT BIOL MED, V14, P429, DOI 10.1016/0010-4825(84)90043-X; Holmquist LE, 2004, IEEE COMPUT GRAPH, V24, P56, DOI 10.1109/MCG.2004.1255810; HOYT R, 2002, BIOMED INFORM ONE DI; HUSEMANN D, 2004, P INT S WEAR COMP IS, P43; HUYNH T, 2005, JOINT SOC EUSAI C OC, P159; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jovanov E., 2005, J NEUROENG REHAB, V2; JOVANOV E, 2003, IEEE ENG MED BIO MAY; Kallio S., 2003, IEEE INT C SYST MAN, P2070; Karantonis DM, 2006, IEEE T INF TECHNOL B, V10, P156, DOI 10.1109/TITB.2005.856864; Kern N., 2003, P EUR S AMB INT, P220; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; KORHONEN I, 2003, P UB 2003 2 INT WORK; Korpipaa P, 2003, PERS UBIQUIT COMPUT, V7, P113, DOI 10.1007/s00779-003-0237-8; Krause A, 2005, P 9 IEEE INT S WEAR; KRAUSE A, 2003, P 7 IEEE INT S WEAR; Laerhoven K. V., 2000, P ISWC2000, P77; LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223; Lorincz K., 2004, IEEE PERVASIVE C OCT; Lucas Peter, 2004, Curr Opin Crit Care, V10, P399, DOI 10.1097/01.ccx.0000141546.74590.d6; Lucas PJF, 2004, ARTIF INTELL MED, V30, P201, DOI 10.1016/j.artmed.2003.11.001; Lukowicz P, 2004, LECT NOTES COMPUT SC, V3001, P18; LUKOWICZ P, 2004, METHODS INF MED, V3; LUKOWICZ P, 2001, IEEE MICRO       MAY, P16; Lymberis A., 2003, P 25 ANN INT C IEEE, P3716; MALAN D, 2004, P MOBISYS WORKSH APP; Marin JM, 2005, HDB STAT; Mathie MJ, 2004, MED BIOL ENG COMPUT, V42, P679, DOI 10.1007/BF02347551; Morgenstern O, 1947, THEORY GAMES EC BEHA; Morris S. J., 2002, P ENG MED BIOL C, V3, P2468; Moy ML, 2003, IEEE ENG MED BIOL, V22, P89, DOI 10.1109/MEMB.2003.1213631; Muhlsteff J., 2004, P 26 ANN INT C IEEE, P2184; Najafi B, 2003, IEEE T BIO-MED ENG, V50, P711, DOI 10.1109/TBME.2003.812189; *NON, NON 4100 BLUET OX; Otto Chris, 2006, J MOBILE MULTIMEDIA, V1; Ouchi K., 2002, Proceedings 22nd International Conference on Distributed Computing Systems Workshops, DOI 10.1109/ICDCSW.2002.1030864; PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532; Pappas IPI, 2004, IEEE SENS J, V4, P268, DOI 10.1109/JSEN.2004.823671; Parkka J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863; Pearl J, 1988, PROBABILISTIC REASON; POLLARD J, 2002, MED INFORM INTERNET, V27, P21927; Quinlan J., 1986, MACH LEARN, V1, P81106; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; Sim I, 2002, J GEN INTERN MED, V17, P302, DOI 10.1046/j.1525-1497.2002.10518.x; SUNG M, 2005, MINIMALLY INVASIVE P; SUNG M, 2005, J NEUROENG REHAB, V2; Sung M, 2005, J COMPUT ASSIST LEAR, V21, P229, DOI 10.1111/j.1365-2729.2005.00130.x; *TEX INSTR INC, EL FRONT END; TROSTER G, 2005, IMIA YB MED INFORM; Winters JM, 2003, IEEE ENG MED BIOL, V22, P56, DOI 10.1109/MEMB.2003.1213627; WU WH, 2006, ARTIFICIAL INT UNPUB; WU WH, 2006, IEEE T INF IN PRESS; Yager RR, 2000, IEEE T SYST MAN CY B, V30, P60, DOI 10.1109/3477.826947; Yu L, 2004, J MACH LEARN RES, V5, P1205; ANALOG DEVICES ADXRS; ANALOG DEVICES ADX13; INTELLISENSE INFORM; LIFESOURCE UC321 BOD	82	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3081-9				2007							76	87		10.1109/HCMDSS-MDPnP.2007.14		12	Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Biomedical	Computer Science; Engineering	BJD66	WOS:000265022300008		
S	Jafari, R; Li, WC; Bajcsy, R; Glaser, S; Sastry, S		Leonhardt, S; Falck, T; Mahonen, P		Jafari, Roozbeh; Li, Wenchao; Bajcsy, Ruzena; Glaser, Steven; Sastry, Shankar			Physical activity monitoring for assisted living at home	4th International Workshop on Wearable and Implantable Body Sensor Networks (BSN 2007)	IFMBE Proceedings		English	Proceedings Paper	4th International Workshop on Wearable and Implantable Body Sensor Networks (BSN 2007)	MAR 26-28, 2007	Aachen, GERMANY		RWTH Aachen Univ	fall detection; movement monitoring; wearable and ubiquitous computing; signal processing		We propose a methodology to determine the occurrence of falls from among other common human movements. The source data is collected by wearable and mobile platforms based on three-axis accelerometers to measure subject kinematics. Our signal processing consists of preprocessing, pattern recognition and classification. One problem with data acquisition is the extensive variation in the morphology of acceleration signals of different patients and under various conditions. We explore several effective key features that can be used for classification of physical movements. Our objective is to enhance the accuracy of movement recognition. We employ classifiers based on neural networks and k-nearest neighbors. Our experimental results exhibit an average of 84% accuracy in movement tracking for four distinct activities over several test subjects.	Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Jafari, R (reprint author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.						Aminian K, 2006, COMPUTATIONAL INTELL; AVONS P, 1988, EUR J CLIN NUTR, V42, P185; BAEK GLJ, 2004, KNOWLEDGE BASED INTE, V3215; Chuanjun L., 2006, REAL TIME CLASSIFICA, V10, P163; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FARGUES MP, 1993, MODELING CLASSIFICAT, V1, P445; Karantonis DM, 2006, IEEE T INF TECHNOL B, V10, P156, DOI 10.1109/TITB.2005.856864; KEMPER HCG, 1977, EUR J APPL PHYSIOL O, V37, P71, DOI 10.1007/BF00421600; Porteus J., 2000, EXPLORING TECHNOLOGI; Ross PE, 2004, IEEE SPECTRUM, V41, P26, DOI 10.1109/MSPEC.2004.1363637; WILSON E, 1994, WORLD C NEUR NETW SA	11	11	11	0	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1680-0737		978-3-540-70993-0	IFMBE PROC			2007	13						213	219				7	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical & Electronic	Computer Science; Engineering	BGF89	WOS:000246511700037		
S	Wang, JJ; Hong, WX; Li, X		Huang, DS; Heutte, L; Loog, M		Wang, Jinjia; Hong, Wenxue; Li, Xin			The new graphical features of star plot for K nearest neighbor classifier	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	3rd International Conference on Intelligent Computing	AUG 21-24, 2007	Qingdao, PEOPLES R CHINA	IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Sci Fdn China		star plot; graphical features; features extraction; K nearest neighbor classifier		The graphical representation or graphical analysis for multidimensional data in multivariate analysis is a very useful method. But it rarely is used to the pattern recognition field. The paper we use the stat plot to represent one observation or sample with multi variances and extract the new graphical features of star plot: sub-area features and sub-barycentre features. The new features are used for the K nearest neighbor classifier (KNN) with leave one out cross validation. Experiments with several standard benchmark data sets show the effectiveness of the new graphical features.	Yanshan Univ, Dept Biomed Engineer, Qinhuangdao 066004, Peoples R China	Wang, JJ (reprint author), Yanshan Univ, Dept Biomed Engineer, Qinhuangdao 066004, Peoples R China.						ANSCOMBE FJ, GRAPHS STAT ANAL, V27, P17; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARINKA BV, 2005, CHEMOMETRICS INTELLI, V75, P31; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Duin R.P.W., 2004, PRTOOLS4 MATLAB TOOL; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Joachims T., 1999, MAKING LARGE SCALE S; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7	8	1	2	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74201-2	LECT NOTES ARTIF INT			2007	4682						926	933				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Operations Research & Management Science	Computer Science; Operations Research & Management Science	BGU28	WOS:000250577100096		
S	Wang, B; Zhang, H		Kobti, Z; Wu, D		Wang, Bin; Zhang, Harry			Probability based metrics for locally weighted naive bayes	Advances in Artificial Intelligence	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	20th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2007	Montreal, CANADA	Canadian Soc Computat Studies Intelligence		LWNB; probability based metrics; IVDM; SF2; SF2LOG; MRM	NEAREST-NEIGHBOR CLASSIFICATION	Locally weighted naive Bayes (LWNB) is a successful instance-based classifier, which first finds the neighbors of the test instance using Euclidean metric, and then builds a naive Bayes model in the local neighborhood. However, Euclidean metric is not the best choice for LWNB. For nominal attributes, Euclidean metric has to order and number the values of attributes, or judge whether the attribute values are identical or not. For numeric attributes, Euclidean metric is not appropriate for different attribute scales and variability, and encounters the problem of attribute value outliers when normalizing values. In this paper, we systematically study probability based metrics, such as Interpolated Value Difference Metric (IVDM), Extended Short and Fukunaga Metric (SF2), SF2 calibrated by logarithm (SF2LOG) and Minimum Risk Metric (MRM), and apply them to LWNB. These probability based metrics can solve the above problems of Euclidean metric since they depend on the difference between the probabilities to evaluate the distances between the instances. We conduct the experiments to compare the performances of LWNB classifiers using Euclidean metric and probability based metrics on UCI datasets. The results show that LWNB classifiers using IVDM outperform the ones using Euclidean metric and other probability based metrics. We also observe that SF2, SF2LOG and MRM do not perform well due to their inaccurate probability estimates. An artificial dataset is built by logical sampling in a Bayesian network, where accurate probability estimates can be produced. We conduct the experiment on the artificial dataset. The results show that SF2, SF2LOG and MRM using accurate probability estimates perform better than Euclidean metric and IVDM in LWNB.	Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Wang, B (reprint author), Univ New Brunswick, Fac Comp Sci, PO Box 4400, Fredericton, NB E3B 5A3, Canada.						Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Frank E., 2003, P C UNC ART INT, P249; Hastie T, 2001, ELEMENTS STAT LEARNI; Henrion M., 1988, UNCERTAINTY ARTIFICI, V2, P317; Knorr E.M., 2001, P 7 ACM SIGKDD INT C, P126, DOI 10.1145/502512.502532; Loader C., 1999, LOCAL REGRESSION LIK; Merz C., 1997, UCI REPOSITORY MACHI; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I.H., 2000, DATA MINING PRACTICA; Zadrozny B., 2002, P 8 ACM SIGKDD INT C, P694, DOI DOI 10.1007/S10994-013-5343-X; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609	16	1	1	0	11	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-72664-7	LECT NOTES COMPUT SC			2007	4509						180	191				12	Computer Science, Artificial Intelligence	Computer Science	BGG73	WOS:000246691800016		
S	Hwang, S; Cho, S		Liu, DR; Fei, SM; Hou, ZG; Zhang, HG; Sun, CY		Hwang, Seongseob; Cho, Sungzoon			Clustering-based reference set reduction for k-nearest neighbor	Advances in Neural Networks - ISNN 2007, Pt 2, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Symposium on Neural Networks (ISNN 2007)	JUN 03-07, 2007	Nanjing, PEOPLES R CHINA	Natl Nat Sci Fdn China, KC Wong Educ Fdn, SE Univ China, Chinese Univ Hong Kong, Univ Illinois, Chicago			PATTERN-CLASSIFICATION; SELECTION; SYSTEMS	Response Modeling is concerned with computing the likelihood of a customer to respond to a marketing campaign. A major problem encountered in response modeling is huge volume of data or patterns. The k-NN has been used in various classification problems for its simplicity and ease of implementation. However, it has not been applied to problems for which fast classification is needed since the classification time rapidly increases as the size of reference set increases. In this paper, we propose a clustering-based preprocessing step in order to reduce the size of reference set. The experimental results showed an 85% decrease in classification time without a loss of accuracy.	Seoul Natl Univ, Seoul 151744, South Korea	Cho, S (reprint author), Seoul Natl Univ, San 56-1, Seoul 151744, South Korea.						Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; EGAN JP, 1975, SIGNAL DETECTION THE; Eick CF, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P375, DOI 10.1109/ICDM.2004.10044; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Golfarelli M, 1997, IEEE T PATTERN ANAL, V19, P786, DOI 10.1109/34.598237; Ha K, 2005, J INTERACT MARK, V19, P17, DOI 10.1002/dir.20028; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; He C, 2004, PATTERN RECOGN, V37, P1085, DOI 10.1016/j.patcog.2004.02.002; Likas A, 2003, PATTERN RECOGN, V36, P451; Malthouse E.C., 2001, J INTERACT MARK, V15, P49, DOI 10.1002/1520-6653(200124)15:1<49::AID-DIR1003>3.3.CO;2-6; Shin HJ, 2006, EXPERT SYST APPL, V30, P746, DOI 10.1016/j.eswa.2005.07.037; Swets JA, 2000, SCI AM, V283, P82; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yu EZ, 2006, EXPERT SYST APPL, V30, P352, DOI 10.1016/j.eswa.2005.07.026	16	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-72392-9	LECT NOTES COMPUT SC			2007	4492						880	888				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BGJ86	WOS:000247831300105		
S	Xiao, Y; Hope, BA; Tien, D		Qiu, GP; Leung, C; Xue, XY; Laurini, R		Xiao, Yi; Hope, Brian A.; Tien, David			Compound geospatial object detection in an aerial image	ADVANCES IN VISUAL INFORMATION SYSTEMS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	9th International Conference on Visual Information Systems	JUN 28-29, 2007	Shanghai, PEOPLES R CHINA		Fudan Univ, Dept Comp Sci & Engn	compound geospatial object detection; knowledge based system	SYSTEM	This paper introduces a knowledge based approach that can be used for the identification of jetty/bridge locations in aerial imagery. With the proposed method, the semantic network formalism to represent declarative knowledge embodied in a jetty/bridge image and the appropriate procedural knowledge, the control procedure was established. A knowledge based system was then introduced through image analysis and interpretation, aiming at accurately locating the desired objects from primary vague identification. With the advanced image processing techniques proposed here, the complexity of using knowledge based system for image analysis is reduced and the proposed method can effectively locate the compound geospatial objects of jetties and bridges.	[Xiao, Yi; Hope, Brian A.; Tien, David] Charles Sturt Univ, Dept Lands, Bathurst, NSW 2795, Australia	Xiao, Y (reprint author), Charles Sturt Univ, Dept Lands, Bathurst, NSW 2795, Australia.						Bhagavathy S, 2006, IEEE T GEOSCI REMOTE, V44, P3706, DOI 10.1109/TGRS.2006.881741; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eakins JP, 2002, PATTERN RECOGN, V35, P3, DOI 10.1016/S0031-3203(01)00038-3; Fradkin M, 2001, COMPUT VIS IMAGE UND, V82, P181, DOI 10.1006/cviu.2001.0917; Gonzalez R. C., 1992, DIGITAL IMAGE PROCES; Heipke C., 1997, INT ARCH PHOTOGRAMME, V32, P47; KNUDSEN T, 2004, P IEEE INT GEOSC REM, V5, P2830; MATSUYAMA T, 1987, IEEE T GEOSCI REMOTE, V25, P305, DOI 10.1109/TGRS.1987.289802; NICOLIN B, 1987, IEEE T GEOSCI REMOTE, V25, P317, DOI 10.1109/TGRS.1987.289803; NIEMANN H, 1990, IEEE T PATTERN ANAL, V12, P883, DOI 10.1109/34.57683; PETERI R, 2003, INT C IMAG PROC, V1, P301; QINT F, 1997, I PHOTOGRAMMETRIC FE, P213; Tupin F, 2003, ISPRS J PHOTOGRAMM, V58, P71, DOI 10.1016/S0924-2716(03)00018-2; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4	15	0	0	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-76413-7	LECT NOTES COMPUT SC			2007	4781						549	558				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHB25	WOS:000252060300053		
S	Takacs, G; Pataki, B		Basili, R; Pazienza, MT		Takacs, Gabor; Pataki, Bela			Nearest local hyperplane rules for pattern classification	AI(ASTERISK)IA 2007: ARTIFICIAL INTELLIGENCE AND HUMAN-ORIENTED COMPUTING	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	10th Congress of the Italian-Association-for-Artificial-Intelligence	SEP 10-13, 2007	Rome, ITALY	Italian Assoc Artificial Intelligence, CELI, ENEA, Exprivia, Fond IBM Italia, Google, Univ Rome, Tor Vergata			RECOGNITION; DISTANCE	Predicting the class of an observation from its nearest neighbors is one of the earliest approaches in pattern recognition. In addition to their simplicity, nearest neighbor rules have appealing theoretical properties, e.g. the asymptotic error probability of the plain 1-nearest-neighbor (NN) rule is at most twice the Bayes bound, which means zero asymptotic risk in the separable case. But given only a finite number of training examples, NN classifiers are often outperformed in practice. A possible modification of the NN rule to handle separable problems better is the nearest local hyperplane (NLH) approach. In this paper we introduce a new way of NLH classification that has two advantages over the original NLH algorithm. First, our method preserves the zero asymptotic risk property, of NN classifiers in the separable case. Second, it usually provides better finite sample performance.	[Takacs, Gabor; Pataki, Bela] Budapest Univ Technol & Econ, Dept Measurement & Informat Syst, H-1117 Budapest, Hungary	Takacs, G (reprint author), Budapest Univ Technol & Econ, Dept Measurement & Informat Syst, Magyar Tudosok Korutja 2, H-1117 Budapest, Hungary.		Pataki, Bela/G-8934-2012; 	Pataki, Bela/0000-0002-0723-1739			Akaho S, 2002, P 9 INT C NEUR INF P, V2, P1069, DOI 10.1109/ICONIP.2002.1198224; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1996, PROBABILISTIC THEORY; Fisher RA, 1936, ANN EUGENIC, V7, P179; Kleinberg J.M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; LECUNN Y, MNIST DATABASE HANDW; Newman D.J., UCI REPOSITORY MACHI; OKUN O, 2004, P 2 EUR WORKSH DAT M, P47; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; Vincent P, 2002, ADV NEUR IN, V14, P985	14	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74781-9	LECT NOTES COMPUT SC			2007	4733						302	313				12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Mathematical & Computational Biology; Robotics	Computer Science; Mathematical & Computational Biology; Robotics	BGW03	WOS:000250857400025		
S	Bosin, A; Dessi, N; Pes, B		Masulli, F; Mitra, S; Pasi, G		Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara			A cost-sensitive approach to feature selection in micro-array data classification	Applications of Fuzzy Sets Theory	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	7th International Workshop on Fuzzy Logic and Applications	JUL 07-10, 2007	Camogli, ITALY	Univ Genova, DISI, IEEE Computat Intelligence Soc, Italian Chapter, Int Neural Network Soc, SIGs Italy & Bioinformat, Bioinformat Italian Soc, Italian Neural Networks Soc, SCIP Working Grp, Univ Studi Milano, DSI, Univ Salerno, DMI, Gruppo Nazl Calcolo Sci		data mining; machine learning; bio-informatics	MODEL	In analyzing gene expression data from rnicro-array, a major challenge is the definition of a feature selection criterion to judge the goodness of a subset of features with respect to a particular classification model. This paper presents a cost-sensitive approach feature selection that focuses on two fundamental requirements: (1) the quality of the features in order to promote the classifier accuracy and (2) the cost of computation due to the complexity that occurs during training and testing the classifier. The paper describes the approach in detail and includes a case study for a publicly available micro-array dataset. Results show that the proposed process yields state-of-art performance and uses only a small fraction of features that are generally used in competitive approaches on the same dataset.	Univ Cagliari, Dipartimento Matemat & Informat, I-09124 Cagliari, Italy	Bosin, A (reprint author), Univ Cagliari, Dipartimento Matemat & Informat, Via Osped 72, I-09124 Cagliari, Italy.						Aikaike H., 1973, P 2 INT S INF THEORY, P267; Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; BOSIN A, 2006, APPL ARTIF INTELL, P29; BOSIN A, 2006, IEA AIE 2006, V4031, P790; BOSIN A, 2006, LNCS, V3849; CHAI X, 2004, LNCS, V3275, P51; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DRAGOS D, 2000, ICML, P583; Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5; Elkan Charles, 2001, P 17 INT JOINT C ART, P973; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; John G. H., 1994, P 11 INT C MACH LEAR; KAI MT, 1998, 2 EUR S PRINC DAT MI, P139; LING CX, 2004, DECISION TRESS MINIM; Liu Huiqing, 2002, Genome Inform, V13, P51; Lo YT, 2001, BIOMETRIKA, V88, P767, DOI 10.1093/biomet/88.3.767; Mukherjee S., 2003, UNDERSTANDING USING; O'Hagan A., 1994, KENDALLS ADV THEOR B, V1st, p2B; Pawitan Y., 2001, ALL LIKELIHOOD STAT; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; STATNIKOV A, 2005, BIOINFORMATICS, V21; Tao L, 2004, BIOINFORMATICS, V20, P2429; Tung WL, 2005, ARTIF INTELL MED, V33, P61, DOI 10.1016/j.artmed.2004.03.009; TURNEY PD, 2000, INT C MACH LEARN WOR, P15; Vapink V, 1998, STAT LEARNING THEORY; VUONG QH, 1989, ECONOMETRICA, V57, P307, DOI 10.2307/1912557; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; YAN L, 2003, ICML, P848; YARMUS JS, 2003, FAST GREEDY BAYESIAN; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; ZUBEK VB, 2002, ICML, P19	31	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-73399-7	LECT NOTES ARTIF INT			2007	4578						571	579				9	Computer Science, Artificial Intelligence	Computer Science	BGK97	WOS:000248082000073		
S	Prijs, M; Peelen, L; Bresser, P; Peek, N		Bellazzi, R; AbuHanna, A; Hunter, J		Prijs, Maurice; Peelen, Linda; Bresser, Paul; Peek, Niels			A nearest neighbor approach to predicting survival time with an application in chronic respiratory disease	Artificial Intelligence in Medicine, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	11th Conference on Artificial Intelligence in Medicine (AIME 2007)	JUL 07-11, 2007	Amsterdam, NETHERLANDS		Univ Amsterdam		CLASSIFICATION; MODELS	The care for patients with chronic and progressive diseases often requires that reliable estimates of their remaining lifetime are made. The predominant method for obtaining such individual prognoses is to analyze historical data using Cox regression, and apply the resulting model to data from new patients. However, the black-box nature of the Cox regression model makes it unattractive for clinical practice. Instead most physicians prefer to relate a new patient to the histories of similar, individual patients that were treated before. This paper presents a prognostic inference method that combines the k-nearest neighbor paradigm with Cox regression. It yields survival predictions for individual patients, based on small sets of similar patients from the past, and can be used to implement a prognostic case-retrieval system. To evaluate the method, it was applied to data from patients with idiopathic interstitial pneumonia, a progressive and lethal lung disease. Experiments pointed out that the method competes well with Cox regression. The best predictive performance was obtained with a neighborhood size of 20.	Univ Amsterdam, Acad Med Ctr, Dept Med Informat, NL-1105 AZ Amsterdam, Netherlands	Prijs, M (reprint author), Univ Amsterdam, Acad Med Ctr, Dept Med Informat, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.						AHA D, 1998, CASE BASE REASONING; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; American Thoracic Society; European Respiratory Society, 2002, AM J RESP CRIT CARE, V165, P277; Anand SS, 2001, METHOD INFORM MED, V40, P18; Bichindaritz I, 2006, ARTIF INTELL MED, V36, P127, DOI 10.1016/j.artmed.2005.10.008; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI [10.1175/1520-0493(1950)078<lessthan>0001:VOFEIT<greaterthan>2.0.CO;2, DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2]; Collard HR, 2003, AM J RESP CRIT CARE, V168, P538, DOI 10.1164/rccm.200211-1311OC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DR, 1972, J R STAT SOC B, V34, P187; Duda R. O., 1973, CLASSIFICATION SCENE; Graf E, 1999, STAT MED, V18, P2529; Hamilton PW, 1999, ANAL QUANT CYTOL, V21, P283; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T, 2001, ELEMENTS STAT LEARNI; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; Latsi PI, 2003, AM J RESP CRIT CARE, V168, P531, DOI 10.1164/rccm.200210-1245OC; PEREZ A, 2003, AM J RESP CELL MO S3, V129, P19; Schmidt R, 2001, INT J MED INFORM, V64, P355, DOI 10.1016/S1386-5056(01)00221-0; Therneau TM, 2000, MODELING SURVIVAL DA	19	0	0	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-73598-4	LECT NOTES ARTIF INT			2007	4594						77	86				10	Computer Science, Artificial Intelligence; Medical Informatics; Medicine, General & Internal	Computer Science; Medical Informatics; General & Internal Medicine	BGL69	WOS:000248222900009		
S	Wu, L; Neskovic, P		MarquesDeSa, J; Alexandre, LA; Duch, W; Mandic, D		Wu, Liang; Neskovic, Predrag			Classifying EEG data into different memory loads across subjects	Artificial Neural Networks - ICANN 2007, Pt 2, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	17th International Conference on Artificial Neural Networks (ICANN 2007)	SEP 09-13, 2007	Oporto, PORTUGAL	European Neural Networks Soc, Int Neural Networks Soc, Japanese Neural Network Soc, IEEE Comp Intelligence Soc, European Assoc Signal & Image Proc, Inst Engenhar Biomed, Univ Beira Interior, Inst Super Engenhar Porto, Reitor Univ Porto, UP, Dept Engenhar Elect Computadores, Inst Politecn Porto, Fund Cienc Tecnol, Fund Luso-Amer Desenvolvimento, Fund Calouste Gulbenkian, Microsoft Res Cambridge Lab, Portugal Telecom			FEATURE-SELECTION; CLASSIFICATION	In this paper we consider the question of whether it is possible to classify n-back EEG data into different memory loads across subjects. To capture relevant information from the EEG signal we use three types of features: power spectrum, conditional entropy, and conditional mutual information. In order to reduce irrelevant and misleading features we use a feature selection method that maximizes mutual information between features and classes and minimizes redundancy among features. Using a selected group of features we show that all classifiers can successfully generalize to the new subject for bands 1-40Hz and 1-60Hz. The classification rates are statistically. significant and the best classification rates, close to 90%, are obtained using conditional entropy features.	Brown Univ, Dept Phys, Providence, RI 02906 USA	Wu, L (reprint author), Brown Univ, Dept Phys, Providence, RI 02906 USA.						Christopher J.C.B., 1998, DATA MIN KNOWL DISC, V2, P121; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HJORTH B, 1975, ELECTROEN CLIN NEURO, V39, P526, DOI 10.1016/0013-4694(75)90056-5; KAPER M, 2004, ENG MED BIOL SOC, P4363; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; SCHRODER M, 2005, EURASIP J APPL SIG P, P3103; WU L, 2007, EUR S ART NEUR NETW, P567	10	0	0	0	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74693-5	LECT NOTES COMPUT SC			2007	4669						149	158				10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BGQ65	WOS:000249783400016		
S	Fayyaz, M; Khan, A; Mujahid, A; Kavokin, A		Mandoiu, I; Zelikovsky, A		Fayyaz, Mudassir; Khan, Asifullah; Mujahid, Adrian; Kavokin, Alex			Using multi level nearest neighbor classifiers for G-protein coupled receptor sub-families prediction	Bioinformatics Research and Applications, Proceedings	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	3rd International Symposium on Bioinformatics Research and Applications	MAY 07-10, 2007	Atlanta, GA			fast fourier transform; G-proteins coupled receptors; multilevel classification; nearest neighbor classifier	FAST FOURIER-TRANSFORM; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINES; HIDDEN MARKOV-MODELS; GPCR RECOGNITION; CLASSIFICATION; SEQUENCE; SUBFAMILIES	Prediction based on the hydrophobicity of the protein yields potentially good classification rate as compared to the other compositions for G-Proteins coupled receptor (GPCR's) families and their respective subfamilies. In the current study, we make use of the hydrophobicity of the proteins in order to obtain a fourier spectrum of the protein sequence, which is then used for classification purpose. The classification of 17 GPCR subfamilies is based on Nearest Neighbor (NN) method, which is employed at two levels. At level-1 classification, the GPCR super-family is recognized and at level-2, the respective sub-families for the predicted super-family are classified. As against Support Vector Machine (SVM), NN approach has shown better performance using both jackknife and independent data set testing. The results are formulated using three performance measures, the Mathew's Correlation Coefficient (MCC), overall accuracy (ACC) and reliability (R) on both training and independent data sets. Comparison of our results is carried out with the overall class accuracies obtained for super-families using existing technique. The multilevel classifier has shown promising performance and has achieved overall ACC and MCC of 97.02% and 0.95 using jackknife test, and 87.50 % and 0.85 for independent data set test respectively.	Fac Comp Sci & Engn, GIK Inst Engn Sci & Technol, Swabi, Pakistan	Fayyaz, M (reprint author), Fac Comp Sci & Engn, GIK Inst Engn Sci & Technol, Swabi, Pakistan.						Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW383, DOI 10.1093/nar/gkh416; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; COSIC I, 1994, IEEE T BIO-MED ENG, V41, P1101, DOI 10.1109/10.335859; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda Richard O., PATTERN CLASSIFICATI, VSecond; Eisenhaber F, 1998, TRENDS CELL BIOL, V8, P69; FAUCHERE JL, 1983, EUR J MED CHEM, V18, P369; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; GRANTHAM R, 1974, SCIENCE, V185, P862, DOI 10.1126/science.185.4154.862; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Guo YZ, 2005, ACTA BIOCH BIOPH SIN, V37, P759, DOI 10.1111/j.1745-7270.2005.00110.x; Hiramoto T, 2002, J PROTEIN CHEM, V21, P537, DOI 10.1023/A:1022429722651; Horn F, 2001, NUCLEIC ACIDS RES, V29, P346, DOI 10.1093/nar/29.1.346; ILMAN AG, GOODMAN GILMANS PHAR; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; Katoh K, 2002, NUCLEIC ACIDS RES, V30, P3059, DOI 10.1093/nar/gkf436; Khan A., 2005, International Journal of Knowledge-Based and Intelligent Engineering Systems, V9; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Lapinsh M, 2002, PROTEIN SCI, V11, P795, DOI 10.1110/ps.2500102; LUDMILA I, 2004, COMBINING PATTERN CL; Majid A., 2006, INT J HYBRID INTELLI, V3, P109; Mandell AJ, 1997, PHYSICA A, V244, P254, DOI 10.1016/S0378-4371(97)00294-X; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; NOVIC M, 1995, J CHEM INF COMP SCI, V35, P454, DOI 10.1021/ci00025a013; Papasaikas PK, 2004, NUCLEIC ACIDS RES, V32, pW380, DOI 10.1093/nar/gkh431; Papasaikas PK, 2003, SAR QSAR ENVIRON RES, V14, P413, DOI 10.1080/10629360310001623999; Shepherd AJ, 2003, PROTEINS, V50, P290, DOI 10.1002/prot.10290; Sonnhammer ELL, 1998, NUCLEIC ACIDS RES, V26, P320, DOI 10.1093/nar/26.1.320; TRAMANTANO A, 2005, 10 MOST WANTED SOLUT	34	1	1	0	17	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-72030-0	LECT N BIOINFORMAT			2007	4463						564	576				13	Biochemistry & Molecular Biology; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BGE97	WOS:000246369100051		
S	Massie, S; Craw, S; Wiratunga, N		Weber, RO; Richter, MM		Massie, Stewart; Craw, Susan; Wiratunga, Nirmalie			When similar problems don't have similar solutions	CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	7th International Conference on Case-Based Reasoning	AUG 13-16, 2007	Belfast, NORTH IRELAND	DFKI, Drexel iSch, empolis, Univ Ulster, Zerosolution			LEARNING ALGORITHMS	The performance of a Case-Based Reasoning system relies on the integrity of its case base but in real life applications the available data used to construct the case base invariably contains erroneous, noisy cases. Automated removal of these noisy cases can improve system accuracy. In addition, error rates for nearest neighbour classifiers can often be reduced by removing cases to give smoother decision boundaries between classes. In this paper we argue that the optimal level of boundary smoothing is domain dependent and, therefore, our approach to error reduction reacts to the characteristics of the domain to set an appropriate level of smoothing. We present a novel, yet transparent algorithm, Threshold Error Reduction, which identifies and removes noisy and boundary cases with the aid of a local complexity measure. Evaluation results confirm it to be superior to benchmark algorithms.	Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland	Massie, S (reprint author), Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland.	sm@comp.rgu.ac.uk; smc@comp.rgu.ac.uk; nw@comp.rgu.ac.uk		Craw, Susan/0000-0003-1870-0323; Massie, Stewart/0000-0002-5278-4009; Wiratunga, Nirmalie/0000-0003-4040-2496			Blake C, 1998, UCI REPOSITORY MACHI; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Mantaras R. Lopez, 2006, KNOWL ENG REV, V20, P215; Delany SJ, 2004, LECT NOTES COMPUT SC, V3155, P128; Maletic J. I., 2000, P C INF QUAL, P200; Massie S, 2006, LECT NOTES ARTIF INT, V4106, P325; MASSIE S, 2005, P 20 NAT C ART INT, P216; Orr K, 1998, COMMUN ACM, V41, P66, DOI 10.1145/269012.269023; Roth-Berghofer TR, 2004, LECT NOTES COMPUT SC, V3155, P389; Smyth B., 1995, P 14 INT JOINT C ART, P377; Smyth B, 2001, COMPUT INTELL-US, V17, P235, DOI 10.1111/0824-7935.00142; SMYTH B, 1999, P 3 INT C CAS BAS RE, P329; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten I.H., 2000, DATA MINING PRACTICA; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8	20	6	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74138-1	LECT NOTES COMPUT SC			2007	4626						92	106				15	Computer Science, Artificial Intelligence	Computer Science	BGQ79	WOS:000249814900007		
S	Yang, CY; Hsu, CC; Yang, JS		Wang, Y; Cheung, YM; Liu, H		Yang, Chan-Yun; Hsu, Che-Chang; Yang, Jr-Syu			Learning SVM with varied example cost: A kNN evaluating approach	COMPUTATIONAL INTELLIGENCE AND SECURITY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	International Conference on Computational-Intelligence and Security	NOV 03-06, 2006	Guangzhou, PEOPLES R CHINA	IEEE Hong Kong Computat Intelligence Chapter, Guangdong Univ Technol, Xidian Univ, Hong Kong Baptist Univ, Jian Univ		learning cost; support vector machine; k nearest neighbor; classification; pattern recognition	CLASSIFICATION; CONSISTENCY	The paper proposes a model merging a non-parametric k-nearest-neighbor (kNN) method into an underlying support vector machine (SVM) to produce an instance-dependent loss function. In this model, a filtering stage of the kNN searching was employed to collect information from training examples and produced a set of emphasized weights which can be distributed to every example by a class of real-valued class labels. The emphasized weights changed the policy of the equal-valued impacts of the training examples and permitted a more efficient way to utilize the information behind the training examples with various sionificance levels. Due to the property of estimating density locally, the kNN method has the advantage to distinguish the heterogeneous examples from the regular examples by merely considering the situation of the examples themselves. The paper shows the model is promising with both the theoretical derivations and consequent experimental results.	[Yang, Chan-Yun] Technol & Sci Inst No Taiwan, Dept Mech Engn, Taipei 112, Taiwan	Yang, CY (reprint author), Technol & Sci Inst No Taiwan, Dept Mech Engn, 2 Xue Yuan Rd, Taipei 112, Taiwan.						Bartlett P.L, 2003, 638 U CAL BERK DEP S; Breiman L., 1996, 460 U CAL BERK DEP S; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Fukunaga K., 1990, STAT PATTERN RECOGNI; Hastie T, 2001, ELEMENTS STAT LEARNI; Hsu CC, 2005, LECT NOTES ARTIF INT, V3801, P550; Lin Y, 2004, STAT PROBABIL LETT, V68, P73, DOI 10.1016/j.spl.2004.03.002; Scholkopf B., 2002, LEARNING KERNELS; Shawe- Taylor J., 2004, KERNEL METHODS PATTE; Steinwart I, 2005, IEEE T INFORM THEORY, V51, P128, DOI 10.1109/TIT.2004.839514; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yang CY, 2004, LECT NOTES COMPUT SC, V3173, P506; Zhang T, 2004, ANN STAT, V32, P56	17	0	0	0	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74376-7	LECT NOTES ARTIF INT			2007	4456						326	335				10	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BGY38	WOS:000251348000035		
B	Thulasiram, RK; Bamgbade, AY		Chen, SH; Wang, PP; Kuo, TW		Thulasiram, Ruppa K.; Bamgbade, Adenike Y.			Application of an instance based learning algorithm for predicting the stock market index	Computational Intelligence in Economics and Finance, Vol II			English	Proceedings Paper	4th International Workshop on Computer Intelligence in Economics and Finance (CIEF 2005)	JUL 21-26, 2005	Salt Lake City, UT			stock market; financial forecasting; computational intelligence; instance based learning; stock price index	CLASSIFICATION	Instance based learning is a class of data mining learning paradigms that applies specific cases or experiences to new situations by matching known cases and experiences with new cases. This paper presents an application of the instance-based learning algorithm for predicting daily stock index price changes of the S&P 500 stock index between October 1995 and September 2000, given the daily changes in the exchange rate of the Canadian Dollar, the Pound Sterling, the French Franc, the Deutsche Mark and the Yen, the monthly changes in the consumer price index, GDP, and the changes in the monthly rates of certificates of deposit. The algorithm is used to predict an increase, decrease or no change in the S&P 500 stock index between a business day and the previous business day. The predictions are carried out using the IB3 variant of the IBL algorithms. The objective is to determine the feasibility of stock price prediction using the IB3 variant of the IBL algorithms. Various testing proportions and normalization methods are experimented with to obtain good predictions.	Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada							AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; APPADOO SS, 2000, FUZZY ALGEBRAIC APPR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowles A, 1937, ECONOMETRICA, V5, P280, DOI 10.2307/1905515; Dixit Avinash K., 1994, INVESTMENT UNDER UNC; HERBERT J, 2005, P CDROM COMP INT EC; Hogg R.V., 2001, PROBABILITY STAT INF; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; KNORR E, 1998, ALGORITHMS MINING DI, P392; KOVALERCHUK B, 2000, DATA MINING USING NE; LEUNG CK, 2005, P CDROM COMP INT EC; LIU Y, 2001, P 2001 IEEE C EV COM, P256; Lo AW, 2000, J AM STAT ASSOC, V95, P629, DOI 10.2307/2669406; MAKRIDAKIS S, 1978, FORECASTING MEHTODS; MENDELBROT B, 2004, MISBEHAVIOR MARKETS; OLIKER S, 1997, FINANCE TECHNOLOGY, P183; Pawlak Z., 1991, ROUGH SETS THEORETIC; RAHMAN MR, 2002, DISTRIBUTED MULTIHRE; RAHMAN MR, 2002, P 14 IASTED INT C PA, P465; REFENSES APN, 1995, NERUAL NETWORKS CAPI; SAMUELSON PA, 1965, IMR-IND MANAG REV, V6, P41; WEIGEND AS, 1997, DECISION TECHNOLOGIE; *YAH, INC YAH FIN HIST PR; Yao J., 1999, INT J THEORETICAL AP, V2, P221, DOI 10.1142/S0219024999000145	24	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY			978-3-540-72820-7				2007							145	155		10.1007/978-3-540-72821-4_9		11	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Economics; Information Science & Library Science; Statistics & Probability	Business & Economics; Computer Science; Information Science & Library Science; Mathematics	BGQ55	WOS:000249778600009		
S	Martin, JAH; de Lope, J		Diaz, RM; Pichler, F; Arencibia, AQ		Antonio Martin, Jose H.; de Lope, Javier			A k-NN based perception scheme for Reinforcement Learning	COMPUTER AIDED SYSTEMS THEORY- EUROCAST 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	11th International Conference on Computer Aided Systems Theory	FEB 12-16, 2007	Las Palmas, SPAIN		Elder Museum Sci & Technol	Reinforcement Learning; k-nearest-neighbors; collective; decision making		A perception scheme for Reinforcement Learning (RL) is developed as a function approximator. The main motivation for the development of this scheme is the need for generalization when the problem to be solved has continuous state variables. We propose a solution to the generalization problem in RL algorithms using a k-nearest-neighbor pattern classification (k-NN). By means of the k-NN technique we investigate the effect of collective decision making as a mechanism of perception and action-selection and a sort of back-propagation of its proportional influence in the action-selection process as the factor that moderate the learning of each decision making unit. A very well known problem is presented as a case study to illustrate the results of this k-NN based perception scheme.	[Antonio Martin, Jose H.] Univ Complutense Madrid, Dept Sistemas Informat & Computac, E-28040 Madrid, Spain	Martin, JAH (reprint author), Univ Complutense Madrid, Dept Sistemas Informat & Computac, E-28040 Madrid, Spain.		Martin H., Jose Antonio/A-2388-2009				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; SUTTON R, 2006, REINFORCEMENT LEARNI; Sutton R. S., 1992, REINFORCEMENT LEARNI; SUTTON RS, 1992, SECS, V173; Sutton R.S., 1998, REINFORCEMENT LEARNI; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	7	3	3	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-75866-2	LECT NOTES COMPUT SC			2007	4739						138	145				8	Computer Science, Theory & Methods	Computer Science	BGZ50	WOS:000251543000018		
J	Zitouni, I				Zitouni, Imed			Backoff hierarchical class n-gram language models: effectiveness to model unseen events in speech recognition	COMPUTER SPEECH AND LANGUAGE			English	Article								In this paper, we introduce the backoff hierarchical class n-gram language models to better estimate the likelihood of unseen n-gram events. This multi-level class hierarchy language modeling approach generalizes the well-known backoff n-gram language modeling technique. It uses a class hierarchy to define word contexts. Each node in the hierarchy,is a class that contains all the words of its descendant nodes. The closer a node to the root, the more general the class (and context) is. We investigate the effectiveness of the approach to model unseen events in speech recognition. Our results illustrate that the proposed technique outperforms backoff n-gram language models. We also study the effect of the vocabulary size and the depth of the class hierarchy on the performance of the approach. Results are presented on Wall Street Journal (WSJ) corpus using two vocabulary set: 5000 words and 20,000 words. Experiments with 5000 word vocabulary, which contain a small numbers of unseen events in the test set, show up to 10% improvement of the unseen event perplexity when using the hierarchical class n-gram language models. With a vocabulary of 20,000 words, characterized by a larger number of unseen events, the perplexity of unseen events decreases by 26%, while the word error rate (WER) decreases by 12% when using the hierarchical approach. Our results suggest that the largest gains in performance are obtained when the test set contains a large number of unseen events. (c) 2006 Elsevier Ltd. All rights reserved.		Zitouni, I (reprint author), IBM Corp, Thomas J Watson Res Ctr, Multilingual NLP, POB 218,20-136, Yorktown Hts, NY 10598 USA.	izitouni@us.ibm.com					BAHL L, 1987, IEEE T ACOUSTICS SPE, V37, P1001; BAI S, 1998, P ICASSP 1998; Bellegarda J., 2000, P IEEE, V88; BILMES JA, 2003, P HLT NAACL CAN MAY; Breiman L., 1984, CLASSIFICATION REGRE; Brown P. F., 1992, Computational Linguistics, V18; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Darken C., 1990, IEEE INNS INT J C NE, V2, P233; DUPONT P, 1997, CMUCS97173; GOODMAN J, 2001, COMPUTER SPEECH  OCT, P403; GUPTA V, 1992, COMPUTER SPEECH LANG, P331; HEEMAN PA, 1999, JOINT SIGDAT C EMP M, P129; Jelinek F., 1990, READINGS SPEECH RECO, P450; KATZ SM, 1987, IEEE T ACOUSTIC SPEE, V35; LI H, 1995, EUR 95 MADR SPAIN; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V281; MILLER JW, 1996, P ICSLP 1996; Rosenfeld R., 2000, P IEEE, V88; SAMUELSSON C, 1999, P ICASSP 1999; SUHM B, 1994, P ICSLP 1994; XU P, 2004, C EMP METH NAT LANG; ZHOU Q, 1997, P IEEE INT C AC SPEE, P1779; ZITOUNI I, 2003, P IEEE ASRU 2003 ST; ZITOUNI I, 2003, P IEEE NLPKE 2003 BE; ZITOUNI I, 2003, P EUR 2003 GEN SWITZ; ZITOUNI L, 2002, P ICSLP 2002 DENV US	27	12	12	0	3	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0885-2308			COMPUT SPEECH LANG	Comput. Speech Lang.	JAN	2007	21	1					88	104		10.1016/j.csl.2006.01.001		17	Computer Science, Artificial Intelligence	Computer Science	102EW	WOS:000241794800005		
